<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Can OOD Object Detectors Learn from Foundation Models?</title>
<!--Generated on Sun Sep  8 17:24:29 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="OOD object detection Synthetic data Open-world data" lang="en" name="keywords"/>
<base href="/html/2409.05162v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S1" title="In Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S2" title="In Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S2.SS0.SSS1" title="In 2 Related Work ‣ Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.0.1 </span>OOD Object Detection</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S2.SS0.SSS2" title="In 2 Related Work ‣ Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.0.2 </span>Open-world Object Detection</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S2.SS0.SSS3" title="In 2 Related Work ‣ Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.0.3 </span>OOD Image Classification</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S2.SS0.SSS4" title="In 2 Related Work ‣ Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.0.4 </span>Foundation Models</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S3" title="In Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Method</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S3.SS0.SSS1" title="In 3 Method ‣ Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.0.1 </span>Preliminary</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S3.SS0.SSS2" title="In 3 Method ‣ Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.0.2 </span>Overview</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S3.SS1" title="In 3 Method ‣ Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Synthesizing Semantic-novel Objects in Scene Images</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S3.SS1.SSS1" title="In 3.1 Synthesizing Semantic-novel Objects in Scene Images ‣ 3 Method ‣ Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.1 </span>Imagining Novel Concepts from ID objects</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S3.SS1.SSS2" title="In 3.1 Synthesizing Semantic-novel Objects in Scene Images ‣ 3 Method ‣ Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.2 </span>Editing Objects on Selected Regions</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S3.SS1.SSS3" title="In 3.1 Synthesizing Semantic-novel Objects in Scene Images ‣ 3 Method ‣ Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.3 </span>Refining Annotation Boxes of Novel Objects</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S3.SS2" title="In 3 Method ‣ Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Mining Hard OOD Samples and Model Training</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S3.SS2.SSS1" title="In 3.2 Mining Hard OOD Samples and Model Training ‣ 3 Method ‣ Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.1 </span>Mining Hard OOD Objects with High Visual Similarities for Training</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S3.SS2.SSS2" title="In 3.2 Mining Hard OOD Samples and Model Training ‣ 3 Method ‣ Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.2 </span>Optimizing ID/OOD Decision Boundary with Synthetic Samples</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S4" title="In Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S4.SS0.SSS1" title="In 4 Experiments ‣ Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.0.1 </span>Datasets</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S4.SS0.SSS2" title="In 4 Experiments ‣ Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.0.2 </span>Metrics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S4.SS0.SSS3" title="In 4 Experiments ‣ Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.0.3 </span>Implementation Details</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S4.SS1" title="In 4 Experiments ‣ Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Main Results on OOD Object Detection</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S4.SS2" title="In 4 Experiments ‣ Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Ablation Study</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S4.SS2.SSS1" title="In 4.2 Ablation Study ‣ 4 Experiments ‣ Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.1 </span>Number of Training Samples</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S4.SS2.SSS2" title="In 4.2 Ablation Study ‣ 4 Experiments ‣ Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.2 </span>Number of Concepts to Imagine</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S4.SS2.SSS3" title="In 4.2 Ablation Study ‣ 4 Experiments ‣ Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.3 </span>SAM-based Refiner</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S4.SS2.SSS4" title="In 4.2 Ablation Study ‣ 4 Experiments ‣ Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.4 </span>Similarity-based Filter</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S4.SS3" title="In 4 Experiments ‣ Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Discussions on Outlier Synthesis</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S4.SS3.SSS1" title="In 4.3 Discussions on Outlier Synthesis ‣ 4 Experiments ‣ Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3.1 </span>Scene-level Editing Matters</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S4.SS3.SSS2" title="In 4.3 Discussions on Outlier Synthesis ‣ 4 Experiments ‣ Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3.2 </span>Context Consistency Matters</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S5" title="In Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Discussion</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S5.SS0.SSS1" title="In 5 Discussion ‣ Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.0.1 </span>What Type of OOD Data Matters?</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S5.SS0.SSS2" title="In 5 Discussion ‣ Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.0.2 </span>How to Synthesize Suitable OOD Data?</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S5.SS0.SSS3" title="In 5 Discussion ‣ Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.0.3 </span>How to Select Suitable OOD Data?</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S5.SS0.SSS4" title="In 5 Discussion ‣ Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.0.4 </span>Broader Impacts</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S6" title="In Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Conclusion</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line"><span class="ltx_note ltx_role_institutetext" id="id1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">institutetext: </span><span class="ltx_text" id="id1.1" style="font-size:90%;">The University of Hong Kong 
<br class="ltx_break"/><span class="ltx_note ltx_role_email" id="id1.1.1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">email: </span>{liujh,wenxin,zhaosz,chenyx,xjqi}@eee.hku.hk</span></span></span>
<br class="ltx_break"/><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/CVMI-Lab/SyncOOD" title="">https://github.com/CVMI-Lab/SyncOOD</a>
</span></span></span></span>
<h1 class="ltx_title ltx_title_document">Can OOD Object Detectors Learn from Foundation Models?</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><span class="ltx_text" id="id1.1.id1" style="font-size:90%;">Jiahui Liu </span>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Xin Wen
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Shizhen Zhao
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yingxian Chen
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Xiaojuan Qi
</span><span class="ltx_author_notes">corresponding author</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id2.id1">Out-of-distribution (OOD) object detection is a challenging task due to the absence of open-set OOD data. Inspired by recent advancements in text-to-image generative models, such as Stable Diffusion, we study the potential of generative models trained on large-scale open-set data to synthesize OOD samples, thereby enhancing OOD object detection. We introduce SyncOOD, a simple data curation method that capitalizes on the capabilities of large foundation models to automatically extract meaningful OOD data from text-to-image generative models. This offers the model access to open-world knowledge encapsulated within off-the-shelf foundation models. The synthetic OOD samples are then employed to augment the training of a lightweight, plug-and-play OOD detector, thus effectively optimizing the in-distribution (ID)/OOD decision boundaries. Extensive experiments across multiple benchmarks demonstrate that SyncOOD significantly outperforms existing methods, establishing new state-of-the-art performance with minimal synthetic data usage.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Keywords: </h6>OOD object detection Synthetic data Open-world data
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="510" id="S1.F1.g1" src="x1.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S1.F1.2.1.1" style="font-size:90%;">Figure 1</span>: </span><span class="ltx_text" id="S1.F1.3.2" style="font-size:90%;">Our pipeline replaces ID objects with semantic-novel yet visual-similar objects for scene-level OOD object synthesis. Middle left: The concepts are imagined by an LLM to ensure semantic separability and rationality, and reformed as text prompts for controllable in-painting using Stable Diffusion. Middle right: During training, only visually similar OOD objects are adopted based on instance-level feature similarity to the original object. A lightweight binary classifier is optimized for OOD detection, and other parts of the detector are kept unchanged.</span></figcaption>
</figure>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Modern object detectors, trained on closed-set data, have achieved remarkable success. However, they often incorrectly and confidently classify out-of-distribution (OOD) object categories as in-distribution (ID) categories in open-world applications <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib10" title="">10</a>]</cite>, raising concerns about their reliability for deployment. To enhance the trustworthiness of object detection, researchers have studied the OOD object detection task, which aims to identify and flag unknown or novel objects as distinct from ID ones <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib3" title="">3</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib42" title="">42</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">The vulnerability of these models to OOD samples stems from their lack of awareness of the unknown open data distribution during training. Consequently, synthesizing OOD samples for model learning has emerged as a major research direction for this task <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib15" title="">15</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib60" title="">60</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib61" title="">61</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib59" title="">59</a>]</cite>. Most existing studies <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib15" title="">15</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib60" title="">60</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib61" title="">61</a>]</cite> concentrate on generating OOD objects in the latent space of an object detection model trained on ID data. These synthesized samples are then used to optimize the decision boundary between ID and OOD data. Alternative approaches include directly synthesizing images by injecting adversarial noise <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib59" title="">59</a>]</cite> or identifying OOD instances from video data <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib14" title="">14</a>]</cite>. While these methods have yielded promising results, they remain limited to a closed-set setting, where the latent space for synthesizing outliers or the data is derived from a closed-set data distribution. Consequently, they may be biased towards the ID dataset, leading to suboptimal performance. Besides, effectively handling the unknown may appear unattainable when the unknown is never fully exploitable. Beyond that, <span class="ltx_text ltx_font_italic" id="S1.p2.1.1">is it possible to learn them from massive open-world data knowledge condensed in foundation models?</span></p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">To this end, we investigate text-to-image generation models trained on a large amount of open-set data, which have demonstrated a superior ability to capture the distribution of data across a wide range of visual concepts, in order to synthesize novel data samples for enhancing OOD detection. Nonetheless, automatically extracting meaningful data from generative models for OOD object detection remains challenging due to the extensive vocabulary space to be explored, the complex scene-level synthesis problem, the need for object-level annotations, and potential distractions from contextual cues.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">We introduce SyncOOD, an automatic data curation process that leverages foundation models as tools to harvest meaningful data from text-to-image generation models for OOD object detection (see Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_tag">1</span></a>).
The process is based on two key observations: 1) Hard OOD samples that are close to the ID data contribute more to learning a better OOD detector, and 2) Context may become a distracting cue for OOD object detection tasks, leading to bias towards contexts. With these observations in mind, the outlier synthesis process is formulated as box-conditioned image in-painting, and driven by Stable Diffusion <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib49" title="">49</a>]</cite> for high-quality controllable editing. The concepts to replace with are imagined by a Large Language Model (LLM) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib1" title="">1</a>]</cite> with the aim of semantic novelty,<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Concepts overlapping with the test data are removed to avoid information leakage.</span></span></span> and the associated bounding box is further refined with SAM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib30" title="">30</a>]</cite>. Automated by foundation models, this data collection pipeline requires minimal human labor, while producing high-quality OOD data.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">In comparison to existing methods for OOD object detection, our core insight is to broaden the model’s exposure to a more extensive range of open-set data and circumvent dataset biases by tapping into the open-world knowledge found in off-the-shelf foundation models. Utilizing generative models also provides us with control over the context of synthesized images and the data distribution. Our comprehensive experiments demonstrate superior performance, emphasizing the untapped potential of text-image-generation models in the context of OOD object detection. Our key contributions are summarized as follows:</p>
</div>
<div class="ltx_para" id="S1.p6">
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">We investigate and unlock the potential of text-to-image generative models trained on large-scale open-set data for synthesizing OOD objects in object detection tasks.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">We introduce an automated data curation process for obtaining controllable, annotated scene-level synthetic OOD images for OOD object detection, which utilizes LLMs for novel concept discovery and visual foundation models for data annotation and filtering.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">We discover that maintaining ID/OOD image context consistency and obtaining more accurate OOD annotation bounding boxes are crucial for synthesized data to be effective in OOD object detection.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i4.p1">
<p class="ltx_p" id="S1.I1.i4.p1.1">Comprehensive experiments on multiple benchmarks demonstrate the effectiveness of our method, as we significantly outperform existing state-of-the-art approaches while using minimal synthetic data.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>
<section class="ltx_subsubsection" id="S2.SS0.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.0.1 </span>OOD Object Detection</h4>
<div class="ltx_para" id="S2.SS0.SSS1.p1">
<p class="ltx_p" id="S2.SS0.SSS1.p1.1">For detecting OOD objects in scene-level images, unlike earlier works that constrain ID samples to a hypothetical distribution <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib12" title="">12</a>]</cite>, it has become a recent trend to explicitly synthesize the outlier data, and incorporate them into training to adjust models’ decision boundaries.
However, due to the complexity of scene-level images, all previous works bypassed photo-realistic outlier synthesis in pixel space, and worked on generating outliers from the model’s latent space <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib15" title="">15</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib60" title="">60</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib61" title="">61</a>]</cite>, adversarial attack <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib59" title="">59</a>]</cite>, or utilizing video data in the wild <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib14" title="">14</a>]</cite>.
In the former, outliers can be sampled from the latent space using a simple Gaussian prior <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib15" title="">15</a>]</cite>, or more advanced generative models like VAE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib61" title="">61</a>]</cite> or diffusion model <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib60" title="">60</a>]</cite>.
Yet their upperbound are commonly limited by the quality of the latent space, and synthesized samples lack interpretability.
Despite this, adversarial samples <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib59" title="">59</a>]</cite> lack semantic diversity, and auxiliary pseudo supervision from videos <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib14" title="">14</a>]</cite> introduces additional requirements to the setting.
Unlike all above, our method applies LLM for OOD concept sampling, and Stable Diffusion for controllable image editing. This decouples the sampling and generation processes, elevates both parts to an unprecedented level, and achieves photo-realistic scene-level OOD image synthesis for the first time.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S2.SS0.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.0.2 </span>Open-world Object Detection</h4>
<div class="ltx_para" id="S2.SS0.SSS2.p1">
<p class="ltx_p" id="S2.SS0.SSS2.p1.1">The fact that real-world applications require object detectors the ability to tackle open categories is also considered in open-world object detection.
The focus of this field includes generalization to domain shifts <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib57" title="">57</a>]</cite>, incremental learning of novel classes <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib39" title="">39</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib43" title="">43</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib27" title="">27</a>]</cite>, and zero-shot classification of open-vocabularies <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib17" title="">17</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib46" title="">46</a>]</cite>.
Meanwhile, some works <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib28" title="">28</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib18" title="">18</a>]</cite> require to distinguish known objects well, be able to detect unknown objects, and finally be able to incrementally learn new objects.
These works provide different perspectives on facing the challenges of real-world applications, which complement OOD object detection as a joint effort, but are out of the scope of this paper.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S2.SS0.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.0.3 </span>OOD Image Classification</h4>
<div class="ltx_para" id="S2.SS0.SSS3.p1">
<p class="ltx_p" id="S2.SS0.SSS3.p1.1">Earlier paradigms for OOD image classification either post hoc adjust models’ confidence score at the testing phase, or apply regularization at models’ training phase.
The former line mainly focuses on the design of score functions, including confidence-based <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib2" title="">2</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib22" title="">22</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib35" title="">35</a>]</cite>, energy-based <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib38" title="">38</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib56" title="">56</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib62" title="">62</a>]</cite>, distance-based <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib34" title="">34</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib47" title="">47</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib50" title="">50</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib51" title="">51</a>]</cite>, gradient-based <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib26" title="">26</a>]</cite>, and approximating Bayesian <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib41" title="">41</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib40" title="">40</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib7" title="">7</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib10" title="">10</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib19" title="">19</a>]</cite> methods.
The latter line of work includes regularizing models to produce lower confidence <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib33" title="">33</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib23" title="">23</a>]</cite>, higher energy <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib38" title="">38</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib29" title="">29</a>]</cite>, or directly shaping latent representations <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib12" title="">12</a>]</cite>.
While outlier synthesis has shown to be effective by <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib15" title="">15</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib54" title="">54</a>]</cite>, these are still generated in the latent space, and a parallel line study utilizing natural images <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib23" title="">23</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib29" title="">29</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib11" title="">11</a>]</cite> from the wild.
Recently, photo-realistic outlier synthesis was first achieved by <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib13" title="">13</a>]</cite> with help from a text-conditioned diffusion model <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib49" title="">49</a>]</cite>.
However, it is not readily applicable for object detection due to the complexity of scene-level images and the requirement for object-level annotations.
In contrast, our work studies under the detection setting and requires outlier synthesis at scene level.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S2.SS0.SSS4">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.0.4 </span>Foundation Models</h4>
<div class="ltx_para" id="S2.SS0.SSS4.p1">
<p class="ltx_p" id="S2.SS0.SSS4.p1.1">The evolution of large language models (LLMs) began with training on web-scale datasets <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib45" title="">45</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib9" title="">9</a>]</cite>, leading to increasingly powerful foundation models <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib4" title="">4</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib6" title="">6</a>]</cite> capable of harnessing vast open-world data. Notable advancements include models <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib1" title="">1</a>]</cite> that interact with users and perform complex tasks like question answering, significantly broadening access to global knowledge. In image generation, diffusion models <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib24" title="">24</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib49" title="">49</a>]</cite> offer robust capabilities in synthesizing realistic content for applications such as image synthesis and inpainting. Additionally, segmentation foundation models like SAM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib30" title="">30</a>]</cite> represent a leap forward in precise image segmentation, benefiting from extensive data training. Foundation models provide diverse data, which provides unlimited potential for learning open-world knowledge from these models <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib55" title="">55</a>]</cite>, where the effectiveness of data <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib53" title="">53</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib63" title="">63</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib21" title="">21</a>]</cite> is also crucial to the downstreaming tasks.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Method</h2>
<section class="ltx_subsubsection" id="S3.SS0.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.0.1 </span>Preliminary</h4>
<div class="ltx_para" id="S3.SS0.SSS1.p1">
<p class="ltx_p" id="S3.SS0.SSS1.p1.8">For OOD object detection, the training set contains only ID scene-level images <math alttext="\textbf{x}^{\text{id}}" class="ltx_Math" display="inline" id="S3.SS0.SSS1.p1.1.m1.1"><semantics id="S3.SS0.SSS1.p1.1.m1.1a"><msup id="S3.SS0.SSS1.p1.1.m1.1.1" xref="S3.SS0.SSS1.p1.1.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS0.SSS1.p1.1.m1.1.1.2" xref="S3.SS0.SSS1.p1.1.m1.1.1.2a.cmml">x</mtext><mtext id="S3.SS0.SSS1.p1.1.m1.1.1.3" xref="S3.SS0.SSS1.p1.1.m1.1.1.3a.cmml">id</mtext></msup><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS1.p1.1.m1.1b"><apply id="S3.SS0.SSS1.p1.1.m1.1.1.cmml" xref="S3.SS0.SSS1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS0.SSS1.p1.1.m1.1.1.1.cmml" xref="S3.SS0.SSS1.p1.1.m1.1.1">superscript</csymbol><ci id="S3.SS0.SSS1.p1.1.m1.1.1.2a.cmml" xref="S3.SS0.SSS1.p1.1.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.SS0.SSS1.p1.1.m1.1.1.2.cmml" xref="S3.SS0.SSS1.p1.1.m1.1.1.2">x</mtext></ci><ci id="S3.SS0.SSS1.p1.1.m1.1.1.3a.cmml" xref="S3.SS0.SSS1.p1.1.m1.1.1.3"><mtext id="S3.SS0.SSS1.p1.1.m1.1.1.3.cmml" mathsize="70%" xref="S3.SS0.SSS1.p1.1.m1.1.1.3">id</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS1.p1.1.m1.1c">\textbf{x}^{\text{id}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS1.p1.1.m1.1d">x start_POSTSUPERSCRIPT id end_POSTSUPERSCRIPT</annotation></semantics></math> with ID objects, annotation bounding boxes <math alttext="\textbf{b}^{\text{id}}" class="ltx_Math" display="inline" id="S3.SS0.SSS1.p1.2.m2.1"><semantics id="S3.SS0.SSS1.p1.2.m2.1a"><msup id="S3.SS0.SSS1.p1.2.m2.1.1" xref="S3.SS0.SSS1.p1.2.m2.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS0.SSS1.p1.2.m2.1.1.2" xref="S3.SS0.SSS1.p1.2.m2.1.1.2a.cmml">b</mtext><mtext id="S3.SS0.SSS1.p1.2.m2.1.1.3" xref="S3.SS0.SSS1.p1.2.m2.1.1.3a.cmml">id</mtext></msup><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS1.p1.2.m2.1b"><apply id="S3.SS0.SSS1.p1.2.m2.1.1.cmml" xref="S3.SS0.SSS1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS0.SSS1.p1.2.m2.1.1.1.cmml" xref="S3.SS0.SSS1.p1.2.m2.1.1">superscript</csymbol><ci id="S3.SS0.SSS1.p1.2.m2.1.1.2a.cmml" xref="S3.SS0.SSS1.p1.2.m2.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.SS0.SSS1.p1.2.m2.1.1.2.cmml" xref="S3.SS0.SSS1.p1.2.m2.1.1.2">b</mtext></ci><ci id="S3.SS0.SSS1.p1.2.m2.1.1.3a.cmml" xref="S3.SS0.SSS1.p1.2.m2.1.1.3"><mtext id="S3.SS0.SSS1.p1.2.m2.1.1.3.cmml" mathsize="70%" xref="S3.SS0.SSS1.p1.2.m2.1.1.3">id</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS1.p1.2.m2.1c">\textbf{b}^{\text{id}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS1.p1.2.m2.1d">b start_POSTSUPERSCRIPT id end_POSTSUPERSCRIPT</annotation></semantics></math>, and semantic labels <math alttext="y" class="ltx_Math" display="inline" id="S3.SS0.SSS1.p1.3.m3.1"><semantics id="S3.SS0.SSS1.p1.3.m3.1a"><mi id="S3.SS0.SSS1.p1.3.m3.1.1" xref="S3.SS0.SSS1.p1.3.m3.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS1.p1.3.m3.1b"><ci id="S3.SS0.SSS1.p1.3.m3.1.1.cmml" xref="S3.SS0.SSS1.p1.3.m3.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS1.p1.3.m3.1c">y</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS1.p1.3.m3.1d">italic_y</annotation></semantics></math>, denoted as <math alttext="\mathcal{D}_{\text{id}}=\left\{(\textbf{x}^{\text{id}},\textbf{b}^{\text{id}},%
\text{y}^{\text{id}})\right\}" class="ltx_Math" display="inline" id="S3.SS0.SSS1.p1.4.m4.1"><semantics id="S3.SS0.SSS1.p1.4.m4.1a"><mrow id="S3.SS0.SSS1.p1.4.m4.1.1" xref="S3.SS0.SSS1.p1.4.m4.1.1.cmml"><msub id="S3.SS0.SSS1.p1.4.m4.1.1.3" xref="S3.SS0.SSS1.p1.4.m4.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS1.p1.4.m4.1.1.3.2" xref="S3.SS0.SSS1.p1.4.m4.1.1.3.2.cmml">𝒟</mi><mtext id="S3.SS0.SSS1.p1.4.m4.1.1.3.3" xref="S3.SS0.SSS1.p1.4.m4.1.1.3.3a.cmml">id</mtext></msub><mo id="S3.SS0.SSS1.p1.4.m4.1.1.2" xref="S3.SS0.SSS1.p1.4.m4.1.1.2.cmml">=</mo><mrow id="S3.SS0.SSS1.p1.4.m4.1.1.1.1" xref="S3.SS0.SSS1.p1.4.m4.1.1.1.2.cmml"><mo id="S3.SS0.SSS1.p1.4.m4.1.1.1.1.2" xref="S3.SS0.SSS1.p1.4.m4.1.1.1.2.cmml">{</mo><mrow id="S3.SS0.SSS1.p1.4.m4.1.1.1.1.1.3" xref="S3.SS0.SSS1.p1.4.m4.1.1.1.1.1.4.cmml"><mo id="S3.SS0.SSS1.p1.4.m4.1.1.1.1.1.3.4" stretchy="false" xref="S3.SS0.SSS1.p1.4.m4.1.1.1.1.1.4.cmml">(</mo><msup id="S3.SS0.SSS1.p1.4.m4.1.1.1.1.1.1.1" xref="S3.SS0.SSS1.p1.4.m4.1.1.1.1.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS0.SSS1.p1.4.m4.1.1.1.1.1.1.1.2" xref="S3.SS0.SSS1.p1.4.m4.1.1.1.1.1.1.1.2a.cmml">x</mtext><mtext id="S3.SS0.SSS1.p1.4.m4.1.1.1.1.1.1.1.3" xref="S3.SS0.SSS1.p1.4.m4.1.1.1.1.1.1.1.3a.cmml">id</mtext></msup><mo id="S3.SS0.SSS1.p1.4.m4.1.1.1.1.1.3.5" xref="S3.SS0.SSS1.p1.4.m4.1.1.1.1.1.4.cmml">,</mo><msup id="S3.SS0.SSS1.p1.4.m4.1.1.1.1.1.2.2" xref="S3.SS0.SSS1.p1.4.m4.1.1.1.1.1.2.2.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS0.SSS1.p1.4.m4.1.1.1.1.1.2.2.2" xref="S3.SS0.SSS1.p1.4.m4.1.1.1.1.1.2.2.2a.cmml">b</mtext><mtext id="S3.SS0.SSS1.p1.4.m4.1.1.1.1.1.2.2.3" xref="S3.SS0.SSS1.p1.4.m4.1.1.1.1.1.2.2.3a.cmml">id</mtext></msup><mo id="S3.SS0.SSS1.p1.4.m4.1.1.1.1.1.3.6" xref="S3.SS0.SSS1.p1.4.m4.1.1.1.1.1.4.cmml">,</mo><msup id="S3.SS0.SSS1.p1.4.m4.1.1.1.1.1.3.3" xref="S3.SS0.SSS1.p1.4.m4.1.1.1.1.1.3.3.cmml"><mtext id="S3.SS0.SSS1.p1.4.m4.1.1.1.1.1.3.3.2" xref="S3.SS0.SSS1.p1.4.m4.1.1.1.1.1.3.3.2a.cmml">y</mtext><mtext id="S3.SS0.SSS1.p1.4.m4.1.1.1.1.1.3.3.3" xref="S3.SS0.SSS1.p1.4.m4.1.1.1.1.1.3.3.3a.cmml">id</mtext></msup><mo id="S3.SS0.SSS1.p1.4.m4.1.1.1.1.1.3.7" stretchy="false" xref="S3.SS0.SSS1.p1.4.m4.1.1.1.1.1.4.cmml">)</mo></mrow><mo id="S3.SS0.SSS1.p1.4.m4.1.1.1.1.3" xref="S3.SS0.SSS1.p1.4.m4.1.1.1.2.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS1.p1.4.m4.1b"><apply id="S3.SS0.SSS1.p1.4.m4.1.1.cmml" xref="S3.SS0.SSS1.p1.4.m4.1.1"><eq id="S3.SS0.SSS1.p1.4.m4.1.1.2.cmml" xref="S3.SS0.SSS1.p1.4.m4.1.1.2"></eq><apply id="S3.SS0.SSS1.p1.4.m4.1.1.3.cmml" xref="S3.SS0.SSS1.p1.4.m4.1.1.3"><csymbol cd="ambiguous" id="S3.SS0.SSS1.p1.4.m4.1.1.3.1.cmml" xref="S3.SS0.SSS1.p1.4.m4.1.1.3">subscript</csymbol><ci id="S3.SS0.SSS1.p1.4.m4.1.1.3.2.cmml" xref="S3.SS0.SSS1.p1.4.m4.1.1.3.2">𝒟</ci><ci id="S3.SS0.SSS1.p1.4.m4.1.1.3.3a.cmml" xref="S3.SS0.SSS1.p1.4.m4.1.1.3.3"><mtext id="S3.SS0.SSS1.p1.4.m4.1.1.3.3.cmml" mathsize="70%" xref="S3.SS0.SSS1.p1.4.m4.1.1.3.3">id</mtext></ci></apply><set id="S3.SS0.SSS1.p1.4.m4.1.1.1.2.cmml" xref="S3.SS0.SSS1.p1.4.m4.1.1.1.1"><vector id="S3.SS0.SSS1.p1.4.m4.1.1.1.1.1.4.cmml" xref="S3.SS0.SSS1.p1.4.m4.1.1.1.1.1.3"><apply id="S3.SS0.SSS1.p1.4.m4.1.1.1.1.1.1.1.cmml" xref="S3.SS0.SSS1.p1.4.m4.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS0.SSS1.p1.4.m4.1.1.1.1.1.1.1.1.cmml" xref="S3.SS0.SSS1.p1.4.m4.1.1.1.1.1.1.1">superscript</csymbol><ci id="S3.SS0.SSS1.p1.4.m4.1.1.1.1.1.1.1.2a.cmml" xref="S3.SS0.SSS1.p1.4.m4.1.1.1.1.1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.SS0.SSS1.p1.4.m4.1.1.1.1.1.1.1.2.cmml" xref="S3.SS0.SSS1.p1.4.m4.1.1.1.1.1.1.1.2">x</mtext></ci><ci id="S3.SS0.SSS1.p1.4.m4.1.1.1.1.1.1.1.3a.cmml" xref="S3.SS0.SSS1.p1.4.m4.1.1.1.1.1.1.1.3"><mtext id="S3.SS0.SSS1.p1.4.m4.1.1.1.1.1.1.1.3.cmml" mathsize="70%" xref="S3.SS0.SSS1.p1.4.m4.1.1.1.1.1.1.1.3">id</mtext></ci></apply><apply id="S3.SS0.SSS1.p1.4.m4.1.1.1.1.1.2.2.cmml" xref="S3.SS0.SSS1.p1.4.m4.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.SS0.SSS1.p1.4.m4.1.1.1.1.1.2.2.1.cmml" xref="S3.SS0.SSS1.p1.4.m4.1.1.1.1.1.2.2">superscript</csymbol><ci id="S3.SS0.SSS1.p1.4.m4.1.1.1.1.1.2.2.2a.cmml" xref="S3.SS0.SSS1.p1.4.m4.1.1.1.1.1.2.2.2"><mtext class="ltx_mathvariant_bold" id="S3.SS0.SSS1.p1.4.m4.1.1.1.1.1.2.2.2.cmml" xref="S3.SS0.SSS1.p1.4.m4.1.1.1.1.1.2.2.2">b</mtext></ci><ci id="S3.SS0.SSS1.p1.4.m4.1.1.1.1.1.2.2.3a.cmml" xref="S3.SS0.SSS1.p1.4.m4.1.1.1.1.1.2.2.3"><mtext id="S3.SS0.SSS1.p1.4.m4.1.1.1.1.1.2.2.3.cmml" mathsize="70%" xref="S3.SS0.SSS1.p1.4.m4.1.1.1.1.1.2.2.3">id</mtext></ci></apply><apply id="S3.SS0.SSS1.p1.4.m4.1.1.1.1.1.3.3.cmml" xref="S3.SS0.SSS1.p1.4.m4.1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S3.SS0.SSS1.p1.4.m4.1.1.1.1.1.3.3.1.cmml" xref="S3.SS0.SSS1.p1.4.m4.1.1.1.1.1.3.3">superscript</csymbol><ci id="S3.SS0.SSS1.p1.4.m4.1.1.1.1.1.3.3.2a.cmml" xref="S3.SS0.SSS1.p1.4.m4.1.1.1.1.1.3.3.2"><mtext id="S3.SS0.SSS1.p1.4.m4.1.1.1.1.1.3.3.2.cmml" xref="S3.SS0.SSS1.p1.4.m4.1.1.1.1.1.3.3.2">y</mtext></ci><ci id="S3.SS0.SSS1.p1.4.m4.1.1.1.1.1.3.3.3a.cmml" xref="S3.SS0.SSS1.p1.4.m4.1.1.1.1.1.3.3.3"><mtext id="S3.SS0.SSS1.p1.4.m4.1.1.1.1.1.3.3.3.cmml" mathsize="70%" xref="S3.SS0.SSS1.p1.4.m4.1.1.1.1.1.3.3.3">id</mtext></ci></apply></vector></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS1.p1.4.m4.1c">\mathcal{D}_{\text{id}}=\left\{(\textbf{x}^{\text{id}},\textbf{b}^{\text{id}},%
\text{y}^{\text{id}})\right\}</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS1.p1.4.m4.1d">caligraphic_D start_POSTSUBSCRIPT id end_POSTSUBSCRIPT = { ( x start_POSTSUPERSCRIPT id end_POSTSUPERSCRIPT , b start_POSTSUPERSCRIPT id end_POSTSUPERSCRIPT , y start_POSTSUPERSCRIPT id end_POSTSUPERSCRIPT ) }</annotation></semantics></math>. The labels of ID objects always belong to a close set with <math alttext="K" class="ltx_Math" display="inline" id="S3.SS0.SSS1.p1.5.m5.1"><semantics id="S3.SS0.SSS1.p1.5.m5.1a"><mi id="S3.SS0.SSS1.p1.5.m5.1.1" xref="S3.SS0.SSS1.p1.5.m5.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS1.p1.5.m5.1b"><ci id="S3.SS0.SSS1.p1.5.m5.1.1.cmml" xref="S3.SS0.SSS1.p1.5.m5.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS1.p1.5.m5.1c">K</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS1.p1.5.m5.1d">italic_K</annotation></semantics></math> categories, denoted as <math alttext="\text{y}^{\text{id}}\in\mathcal{Y}_{\text{id}}" class="ltx_Math" display="inline" id="S3.SS0.SSS1.p1.6.m6.1"><semantics id="S3.SS0.SSS1.p1.6.m6.1a"><mrow id="S3.SS0.SSS1.p1.6.m6.1.1" xref="S3.SS0.SSS1.p1.6.m6.1.1.cmml"><msup id="S3.SS0.SSS1.p1.6.m6.1.1.2" xref="S3.SS0.SSS1.p1.6.m6.1.1.2.cmml"><mtext id="S3.SS0.SSS1.p1.6.m6.1.1.2.2" xref="S3.SS0.SSS1.p1.6.m6.1.1.2.2a.cmml">y</mtext><mtext id="S3.SS0.SSS1.p1.6.m6.1.1.2.3" xref="S3.SS0.SSS1.p1.6.m6.1.1.2.3a.cmml">id</mtext></msup><mo id="S3.SS0.SSS1.p1.6.m6.1.1.1" xref="S3.SS0.SSS1.p1.6.m6.1.1.1.cmml">∈</mo><msub id="S3.SS0.SSS1.p1.6.m6.1.1.3" xref="S3.SS0.SSS1.p1.6.m6.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS1.p1.6.m6.1.1.3.2" xref="S3.SS0.SSS1.p1.6.m6.1.1.3.2.cmml">𝒴</mi><mtext id="S3.SS0.SSS1.p1.6.m6.1.1.3.3" xref="S3.SS0.SSS1.p1.6.m6.1.1.3.3a.cmml">id</mtext></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS1.p1.6.m6.1b"><apply id="S3.SS0.SSS1.p1.6.m6.1.1.cmml" xref="S3.SS0.SSS1.p1.6.m6.1.1"><in id="S3.SS0.SSS1.p1.6.m6.1.1.1.cmml" xref="S3.SS0.SSS1.p1.6.m6.1.1.1"></in><apply id="S3.SS0.SSS1.p1.6.m6.1.1.2.cmml" xref="S3.SS0.SSS1.p1.6.m6.1.1.2"><csymbol cd="ambiguous" id="S3.SS0.SSS1.p1.6.m6.1.1.2.1.cmml" xref="S3.SS0.SSS1.p1.6.m6.1.1.2">superscript</csymbol><ci id="S3.SS0.SSS1.p1.6.m6.1.1.2.2a.cmml" xref="S3.SS0.SSS1.p1.6.m6.1.1.2.2"><mtext id="S3.SS0.SSS1.p1.6.m6.1.1.2.2.cmml" xref="S3.SS0.SSS1.p1.6.m6.1.1.2.2">y</mtext></ci><ci id="S3.SS0.SSS1.p1.6.m6.1.1.2.3a.cmml" xref="S3.SS0.SSS1.p1.6.m6.1.1.2.3"><mtext id="S3.SS0.SSS1.p1.6.m6.1.1.2.3.cmml" mathsize="70%" xref="S3.SS0.SSS1.p1.6.m6.1.1.2.3">id</mtext></ci></apply><apply id="S3.SS0.SSS1.p1.6.m6.1.1.3.cmml" xref="S3.SS0.SSS1.p1.6.m6.1.1.3"><csymbol cd="ambiguous" id="S3.SS0.SSS1.p1.6.m6.1.1.3.1.cmml" xref="S3.SS0.SSS1.p1.6.m6.1.1.3">subscript</csymbol><ci id="S3.SS0.SSS1.p1.6.m6.1.1.3.2.cmml" xref="S3.SS0.SSS1.p1.6.m6.1.1.3.2">𝒴</ci><ci id="S3.SS0.SSS1.p1.6.m6.1.1.3.3a.cmml" xref="S3.SS0.SSS1.p1.6.m6.1.1.3.3"><mtext id="S3.SS0.SSS1.p1.6.m6.1.1.3.3.cmml" mathsize="70%" xref="S3.SS0.SSS1.p1.6.m6.1.1.3.3">id</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS1.p1.6.m6.1c">\text{y}^{\text{id}}\in\mathcal{Y}_{\text{id}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS1.p1.6.m6.1d">y start_POSTSUPERSCRIPT id end_POSTSUPERSCRIPT ∈ caligraphic_Y start_POSTSUBSCRIPT id end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="\mathcal{Y}_{\text{id}}=\left\{\text{y}^{\text{id}}_{1},\text{y}^{\text{id}}_{%
2},...,\text{y}^{\text{id}}_{K}\right\}" class="ltx_Math" display="inline" id="S3.SS0.SSS1.p1.7.m7.4"><semantics id="S3.SS0.SSS1.p1.7.m7.4a"><mrow id="S3.SS0.SSS1.p1.7.m7.4.4" xref="S3.SS0.SSS1.p1.7.m7.4.4.cmml"><msub id="S3.SS0.SSS1.p1.7.m7.4.4.5" xref="S3.SS0.SSS1.p1.7.m7.4.4.5.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS1.p1.7.m7.4.4.5.2" xref="S3.SS0.SSS1.p1.7.m7.4.4.5.2.cmml">𝒴</mi><mtext id="S3.SS0.SSS1.p1.7.m7.4.4.5.3" xref="S3.SS0.SSS1.p1.7.m7.4.4.5.3a.cmml">id</mtext></msub><mo id="S3.SS0.SSS1.p1.7.m7.4.4.4" xref="S3.SS0.SSS1.p1.7.m7.4.4.4.cmml">=</mo><mrow id="S3.SS0.SSS1.p1.7.m7.4.4.3.3" xref="S3.SS0.SSS1.p1.7.m7.4.4.3.4.cmml"><mo id="S3.SS0.SSS1.p1.7.m7.4.4.3.3.4" xref="S3.SS0.SSS1.p1.7.m7.4.4.3.4.cmml">{</mo><msubsup id="S3.SS0.SSS1.p1.7.m7.2.2.1.1.1" xref="S3.SS0.SSS1.p1.7.m7.2.2.1.1.1.cmml"><mtext id="S3.SS0.SSS1.p1.7.m7.2.2.1.1.1.2.2" xref="S3.SS0.SSS1.p1.7.m7.2.2.1.1.1.2.2a.cmml">y</mtext><mn id="S3.SS0.SSS1.p1.7.m7.2.2.1.1.1.3" xref="S3.SS0.SSS1.p1.7.m7.2.2.1.1.1.3.cmml">1</mn><mtext id="S3.SS0.SSS1.p1.7.m7.2.2.1.1.1.2.3" xref="S3.SS0.SSS1.p1.7.m7.2.2.1.1.1.2.3a.cmml">id</mtext></msubsup><mo id="S3.SS0.SSS1.p1.7.m7.4.4.3.3.5" xref="S3.SS0.SSS1.p1.7.m7.4.4.3.4.cmml">,</mo><msubsup id="S3.SS0.SSS1.p1.7.m7.3.3.2.2.2" xref="S3.SS0.SSS1.p1.7.m7.3.3.2.2.2.cmml"><mtext id="S3.SS0.SSS1.p1.7.m7.3.3.2.2.2.2.2" xref="S3.SS0.SSS1.p1.7.m7.3.3.2.2.2.2.2a.cmml">y</mtext><mn id="S3.SS0.SSS1.p1.7.m7.3.3.2.2.2.3" xref="S3.SS0.SSS1.p1.7.m7.3.3.2.2.2.3.cmml">2</mn><mtext id="S3.SS0.SSS1.p1.7.m7.3.3.2.2.2.2.3" xref="S3.SS0.SSS1.p1.7.m7.3.3.2.2.2.2.3a.cmml">id</mtext></msubsup><mo id="S3.SS0.SSS1.p1.7.m7.4.4.3.3.6" xref="S3.SS0.SSS1.p1.7.m7.4.4.3.4.cmml">,</mo><mi id="S3.SS0.SSS1.p1.7.m7.1.1" mathvariant="normal" xref="S3.SS0.SSS1.p1.7.m7.1.1.cmml">…</mi><mo id="S3.SS0.SSS1.p1.7.m7.4.4.3.3.7" xref="S3.SS0.SSS1.p1.7.m7.4.4.3.4.cmml">,</mo><msubsup id="S3.SS0.SSS1.p1.7.m7.4.4.3.3.3" xref="S3.SS0.SSS1.p1.7.m7.4.4.3.3.3.cmml"><mtext id="S3.SS0.SSS1.p1.7.m7.4.4.3.3.3.2.2" xref="S3.SS0.SSS1.p1.7.m7.4.4.3.3.3.2.2a.cmml">y</mtext><mi id="S3.SS0.SSS1.p1.7.m7.4.4.3.3.3.3" xref="S3.SS0.SSS1.p1.7.m7.4.4.3.3.3.3.cmml">K</mi><mtext id="S3.SS0.SSS1.p1.7.m7.4.4.3.3.3.2.3" xref="S3.SS0.SSS1.p1.7.m7.4.4.3.3.3.2.3a.cmml">id</mtext></msubsup><mo id="S3.SS0.SSS1.p1.7.m7.4.4.3.3.8" xref="S3.SS0.SSS1.p1.7.m7.4.4.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS1.p1.7.m7.4b"><apply id="S3.SS0.SSS1.p1.7.m7.4.4.cmml" xref="S3.SS0.SSS1.p1.7.m7.4.4"><eq id="S3.SS0.SSS1.p1.7.m7.4.4.4.cmml" xref="S3.SS0.SSS1.p1.7.m7.4.4.4"></eq><apply id="S3.SS0.SSS1.p1.7.m7.4.4.5.cmml" xref="S3.SS0.SSS1.p1.7.m7.4.4.5"><csymbol cd="ambiguous" id="S3.SS0.SSS1.p1.7.m7.4.4.5.1.cmml" xref="S3.SS0.SSS1.p1.7.m7.4.4.5">subscript</csymbol><ci id="S3.SS0.SSS1.p1.7.m7.4.4.5.2.cmml" xref="S3.SS0.SSS1.p1.7.m7.4.4.5.2">𝒴</ci><ci id="S3.SS0.SSS1.p1.7.m7.4.4.5.3a.cmml" xref="S3.SS0.SSS1.p1.7.m7.4.4.5.3"><mtext id="S3.SS0.SSS1.p1.7.m7.4.4.5.3.cmml" mathsize="70%" xref="S3.SS0.SSS1.p1.7.m7.4.4.5.3">id</mtext></ci></apply><set id="S3.SS0.SSS1.p1.7.m7.4.4.3.4.cmml" xref="S3.SS0.SSS1.p1.7.m7.4.4.3.3"><apply id="S3.SS0.SSS1.p1.7.m7.2.2.1.1.1.cmml" xref="S3.SS0.SSS1.p1.7.m7.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS0.SSS1.p1.7.m7.2.2.1.1.1.1.cmml" xref="S3.SS0.SSS1.p1.7.m7.2.2.1.1.1">subscript</csymbol><apply id="S3.SS0.SSS1.p1.7.m7.2.2.1.1.1.2.cmml" xref="S3.SS0.SSS1.p1.7.m7.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS0.SSS1.p1.7.m7.2.2.1.1.1.2.1.cmml" xref="S3.SS0.SSS1.p1.7.m7.2.2.1.1.1">superscript</csymbol><ci id="S3.SS0.SSS1.p1.7.m7.2.2.1.1.1.2.2a.cmml" xref="S3.SS0.SSS1.p1.7.m7.2.2.1.1.1.2.2"><mtext id="S3.SS0.SSS1.p1.7.m7.2.2.1.1.1.2.2.cmml" xref="S3.SS0.SSS1.p1.7.m7.2.2.1.1.1.2.2">y</mtext></ci><ci id="S3.SS0.SSS1.p1.7.m7.2.2.1.1.1.2.3a.cmml" xref="S3.SS0.SSS1.p1.7.m7.2.2.1.1.1.2.3"><mtext id="S3.SS0.SSS1.p1.7.m7.2.2.1.1.1.2.3.cmml" mathsize="70%" xref="S3.SS0.SSS1.p1.7.m7.2.2.1.1.1.2.3">id</mtext></ci></apply><cn id="S3.SS0.SSS1.p1.7.m7.2.2.1.1.1.3.cmml" type="integer" xref="S3.SS0.SSS1.p1.7.m7.2.2.1.1.1.3">1</cn></apply><apply id="S3.SS0.SSS1.p1.7.m7.3.3.2.2.2.cmml" xref="S3.SS0.SSS1.p1.7.m7.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS0.SSS1.p1.7.m7.3.3.2.2.2.1.cmml" xref="S3.SS0.SSS1.p1.7.m7.3.3.2.2.2">subscript</csymbol><apply id="S3.SS0.SSS1.p1.7.m7.3.3.2.2.2.2.cmml" xref="S3.SS0.SSS1.p1.7.m7.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS0.SSS1.p1.7.m7.3.3.2.2.2.2.1.cmml" xref="S3.SS0.SSS1.p1.7.m7.3.3.2.2.2">superscript</csymbol><ci id="S3.SS0.SSS1.p1.7.m7.3.3.2.2.2.2.2a.cmml" xref="S3.SS0.SSS1.p1.7.m7.3.3.2.2.2.2.2"><mtext id="S3.SS0.SSS1.p1.7.m7.3.3.2.2.2.2.2.cmml" xref="S3.SS0.SSS1.p1.7.m7.3.3.2.2.2.2.2">y</mtext></ci><ci id="S3.SS0.SSS1.p1.7.m7.3.3.2.2.2.2.3a.cmml" xref="S3.SS0.SSS1.p1.7.m7.3.3.2.2.2.2.3"><mtext id="S3.SS0.SSS1.p1.7.m7.3.3.2.2.2.2.3.cmml" mathsize="70%" xref="S3.SS0.SSS1.p1.7.m7.3.3.2.2.2.2.3">id</mtext></ci></apply><cn id="S3.SS0.SSS1.p1.7.m7.3.3.2.2.2.3.cmml" type="integer" xref="S3.SS0.SSS1.p1.7.m7.3.3.2.2.2.3">2</cn></apply><ci id="S3.SS0.SSS1.p1.7.m7.1.1.cmml" xref="S3.SS0.SSS1.p1.7.m7.1.1">…</ci><apply id="S3.SS0.SSS1.p1.7.m7.4.4.3.3.3.cmml" xref="S3.SS0.SSS1.p1.7.m7.4.4.3.3.3"><csymbol cd="ambiguous" id="S3.SS0.SSS1.p1.7.m7.4.4.3.3.3.1.cmml" xref="S3.SS0.SSS1.p1.7.m7.4.4.3.3.3">subscript</csymbol><apply id="S3.SS0.SSS1.p1.7.m7.4.4.3.3.3.2.cmml" xref="S3.SS0.SSS1.p1.7.m7.4.4.3.3.3"><csymbol cd="ambiguous" id="S3.SS0.SSS1.p1.7.m7.4.4.3.3.3.2.1.cmml" xref="S3.SS0.SSS1.p1.7.m7.4.4.3.3.3">superscript</csymbol><ci id="S3.SS0.SSS1.p1.7.m7.4.4.3.3.3.2.2a.cmml" xref="S3.SS0.SSS1.p1.7.m7.4.4.3.3.3.2.2"><mtext id="S3.SS0.SSS1.p1.7.m7.4.4.3.3.3.2.2.cmml" xref="S3.SS0.SSS1.p1.7.m7.4.4.3.3.3.2.2">y</mtext></ci><ci id="S3.SS0.SSS1.p1.7.m7.4.4.3.3.3.2.3a.cmml" xref="S3.SS0.SSS1.p1.7.m7.4.4.3.3.3.2.3"><mtext id="S3.SS0.SSS1.p1.7.m7.4.4.3.3.3.2.3.cmml" mathsize="70%" xref="S3.SS0.SSS1.p1.7.m7.4.4.3.3.3.2.3">id</mtext></ci></apply><ci id="S3.SS0.SSS1.p1.7.m7.4.4.3.3.3.3.cmml" xref="S3.SS0.SSS1.p1.7.m7.4.4.3.3.3.3">𝐾</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS1.p1.7.m7.4c">\mathcal{Y}_{\text{id}}=\left\{\text{y}^{\text{id}}_{1},\text{y}^{\text{id}}_{%
2},...,\text{y}^{\text{id}}_{K}\right\}</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS1.p1.7.m7.4d">caligraphic_Y start_POSTSUBSCRIPT id end_POSTSUBSCRIPT = { y start_POSTSUPERSCRIPT id end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , y start_POSTSUPERSCRIPT id end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … , y start_POSTSUPERSCRIPT id end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_K end_POSTSUBSCRIPT }</annotation></semantics></math>. During inference, for each proposed object from an input scene-level image, it is required to identify whether its category belongs to <math alttext="\mathcal{Y}_{\text{id}}" class="ltx_Math" display="inline" id="S3.SS0.SSS1.p1.8.m8.1"><semantics id="S3.SS0.SSS1.p1.8.m8.1a"><msub id="S3.SS0.SSS1.p1.8.m8.1.1" xref="S3.SS0.SSS1.p1.8.m8.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS1.p1.8.m8.1.1.2" xref="S3.SS0.SSS1.p1.8.m8.1.1.2.cmml">𝒴</mi><mtext id="S3.SS0.SSS1.p1.8.m8.1.1.3" xref="S3.SS0.SSS1.p1.8.m8.1.1.3a.cmml">id</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS1.p1.8.m8.1b"><apply id="S3.SS0.SSS1.p1.8.m8.1.1.cmml" xref="S3.SS0.SSS1.p1.8.m8.1.1"><csymbol cd="ambiguous" id="S3.SS0.SSS1.p1.8.m8.1.1.1.cmml" xref="S3.SS0.SSS1.p1.8.m8.1.1">subscript</csymbol><ci id="S3.SS0.SSS1.p1.8.m8.1.1.2.cmml" xref="S3.SS0.SSS1.p1.8.m8.1.1.2">𝒴</ci><ci id="S3.SS0.SSS1.p1.8.m8.1.1.3a.cmml" xref="S3.SS0.SSS1.p1.8.m8.1.1.3"><mtext id="S3.SS0.SSS1.p1.8.m8.1.1.3.cmml" mathsize="70%" xref="S3.SS0.SSS1.p1.8.m8.1.1.3">id</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS1.p1.8.m8.1c">\mathcal{Y}_{\text{id}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS1.p1.8.m8.1d">caligraphic_Y start_POSTSUBSCRIPT id end_POSTSUBSCRIPT</annotation></semantics></math> or not.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS0.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.0.2 </span>Overview</h4>
<div class="ltx_para" id="S3.SS0.SSS2.p1">
<p class="ltx_p" id="S3.SS0.SSS2.p1.4">As illustrated in <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S1.F1" title="In 1 Introduction ‣ Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">1</span></a>, our outlier synthesis pipeline consists of (1) synthesizing a set of effective photo-realistic scene-level OOD images <math alttext="\textbf{x}^{\text{edit}}" class="ltx_Math" display="inline" id="S3.SS0.SSS2.p1.1.m1.1"><semantics id="S3.SS0.SSS2.p1.1.m1.1a"><msup id="S3.SS0.SSS2.p1.1.m1.1.1" xref="S3.SS0.SSS2.p1.1.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS0.SSS2.p1.1.m1.1.1.2" xref="S3.SS0.SSS2.p1.1.m1.1.1.2a.cmml">x</mtext><mtext id="S3.SS0.SSS2.p1.1.m1.1.1.3" xref="S3.SS0.SSS2.p1.1.m1.1.1.3a.cmml">edit</mtext></msup><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS2.p1.1.m1.1b"><apply id="S3.SS0.SSS2.p1.1.m1.1.1.cmml" xref="S3.SS0.SSS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS0.SSS2.p1.1.m1.1.1.1.cmml" xref="S3.SS0.SSS2.p1.1.m1.1.1">superscript</csymbol><ci id="S3.SS0.SSS2.p1.1.m1.1.1.2a.cmml" xref="S3.SS0.SSS2.p1.1.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.SS0.SSS2.p1.1.m1.1.1.2.cmml" xref="S3.SS0.SSS2.p1.1.m1.1.1.2">x</mtext></ci><ci id="S3.SS0.SSS2.p1.1.m1.1.1.3a.cmml" xref="S3.SS0.SSS2.p1.1.m1.1.1.3"><mtext id="S3.SS0.SSS2.p1.1.m1.1.1.3.cmml" mathsize="70%" xref="S3.SS0.SSS2.p1.1.m1.1.1.3">edit</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS2.p1.1.m1.1c">\textbf{x}^{\text{edit}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS2.p1.1.m1.1d">x start_POSTSUPERSCRIPT edit end_POSTSUPERSCRIPT</annotation></semantics></math>, denoted as <math alttext="\mathcal{D}_{\text{edit}}=\left\{(\textbf{x}^{\text{edit}},\textbf{b}^{\text{%
edit}})\right\}" class="ltx_Math" display="inline" id="S3.SS0.SSS2.p1.2.m2.1"><semantics id="S3.SS0.SSS2.p1.2.m2.1a"><mrow id="S3.SS0.SSS2.p1.2.m2.1.1" xref="S3.SS0.SSS2.p1.2.m2.1.1.cmml"><msub id="S3.SS0.SSS2.p1.2.m2.1.1.3" xref="S3.SS0.SSS2.p1.2.m2.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS2.p1.2.m2.1.1.3.2" xref="S3.SS0.SSS2.p1.2.m2.1.1.3.2.cmml">𝒟</mi><mtext id="S3.SS0.SSS2.p1.2.m2.1.1.3.3" xref="S3.SS0.SSS2.p1.2.m2.1.1.3.3a.cmml">edit</mtext></msub><mo id="S3.SS0.SSS2.p1.2.m2.1.1.2" xref="S3.SS0.SSS2.p1.2.m2.1.1.2.cmml">=</mo><mrow id="S3.SS0.SSS2.p1.2.m2.1.1.1.1" xref="S3.SS0.SSS2.p1.2.m2.1.1.1.2.cmml"><mo id="S3.SS0.SSS2.p1.2.m2.1.1.1.1.2" xref="S3.SS0.SSS2.p1.2.m2.1.1.1.2.cmml">{</mo><mrow id="S3.SS0.SSS2.p1.2.m2.1.1.1.1.1.2" xref="S3.SS0.SSS2.p1.2.m2.1.1.1.1.1.3.cmml"><mo id="S3.SS0.SSS2.p1.2.m2.1.1.1.1.1.2.3" stretchy="false" xref="S3.SS0.SSS2.p1.2.m2.1.1.1.1.1.3.cmml">(</mo><msup id="S3.SS0.SSS2.p1.2.m2.1.1.1.1.1.1.1" xref="S3.SS0.SSS2.p1.2.m2.1.1.1.1.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS0.SSS2.p1.2.m2.1.1.1.1.1.1.1.2" xref="S3.SS0.SSS2.p1.2.m2.1.1.1.1.1.1.1.2a.cmml">x</mtext><mtext id="S3.SS0.SSS2.p1.2.m2.1.1.1.1.1.1.1.3" xref="S3.SS0.SSS2.p1.2.m2.1.1.1.1.1.1.1.3a.cmml">edit</mtext></msup><mo id="S3.SS0.SSS2.p1.2.m2.1.1.1.1.1.2.4" xref="S3.SS0.SSS2.p1.2.m2.1.1.1.1.1.3.cmml">,</mo><msup id="S3.SS0.SSS2.p1.2.m2.1.1.1.1.1.2.2" xref="S3.SS0.SSS2.p1.2.m2.1.1.1.1.1.2.2.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS0.SSS2.p1.2.m2.1.1.1.1.1.2.2.2" xref="S3.SS0.SSS2.p1.2.m2.1.1.1.1.1.2.2.2a.cmml">b</mtext><mtext id="S3.SS0.SSS2.p1.2.m2.1.1.1.1.1.2.2.3" xref="S3.SS0.SSS2.p1.2.m2.1.1.1.1.1.2.2.3a.cmml">edit</mtext></msup><mo id="S3.SS0.SSS2.p1.2.m2.1.1.1.1.1.2.5" stretchy="false" xref="S3.SS0.SSS2.p1.2.m2.1.1.1.1.1.3.cmml">)</mo></mrow><mo id="S3.SS0.SSS2.p1.2.m2.1.1.1.1.3" xref="S3.SS0.SSS2.p1.2.m2.1.1.1.2.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS2.p1.2.m2.1b"><apply id="S3.SS0.SSS2.p1.2.m2.1.1.cmml" xref="S3.SS0.SSS2.p1.2.m2.1.1"><eq id="S3.SS0.SSS2.p1.2.m2.1.1.2.cmml" xref="S3.SS0.SSS2.p1.2.m2.1.1.2"></eq><apply id="S3.SS0.SSS2.p1.2.m2.1.1.3.cmml" xref="S3.SS0.SSS2.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS0.SSS2.p1.2.m2.1.1.3.1.cmml" xref="S3.SS0.SSS2.p1.2.m2.1.1.3">subscript</csymbol><ci id="S3.SS0.SSS2.p1.2.m2.1.1.3.2.cmml" xref="S3.SS0.SSS2.p1.2.m2.1.1.3.2">𝒟</ci><ci id="S3.SS0.SSS2.p1.2.m2.1.1.3.3a.cmml" xref="S3.SS0.SSS2.p1.2.m2.1.1.3.3"><mtext id="S3.SS0.SSS2.p1.2.m2.1.1.3.3.cmml" mathsize="70%" xref="S3.SS0.SSS2.p1.2.m2.1.1.3.3">edit</mtext></ci></apply><set id="S3.SS0.SSS2.p1.2.m2.1.1.1.2.cmml" xref="S3.SS0.SSS2.p1.2.m2.1.1.1.1"><interval closure="open" id="S3.SS0.SSS2.p1.2.m2.1.1.1.1.1.3.cmml" xref="S3.SS0.SSS2.p1.2.m2.1.1.1.1.1.2"><apply id="S3.SS0.SSS2.p1.2.m2.1.1.1.1.1.1.1.cmml" xref="S3.SS0.SSS2.p1.2.m2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS0.SSS2.p1.2.m2.1.1.1.1.1.1.1.1.cmml" xref="S3.SS0.SSS2.p1.2.m2.1.1.1.1.1.1.1">superscript</csymbol><ci id="S3.SS0.SSS2.p1.2.m2.1.1.1.1.1.1.1.2a.cmml" xref="S3.SS0.SSS2.p1.2.m2.1.1.1.1.1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.SS0.SSS2.p1.2.m2.1.1.1.1.1.1.1.2.cmml" xref="S3.SS0.SSS2.p1.2.m2.1.1.1.1.1.1.1.2">x</mtext></ci><ci id="S3.SS0.SSS2.p1.2.m2.1.1.1.1.1.1.1.3a.cmml" xref="S3.SS0.SSS2.p1.2.m2.1.1.1.1.1.1.1.3"><mtext id="S3.SS0.SSS2.p1.2.m2.1.1.1.1.1.1.1.3.cmml" mathsize="70%" xref="S3.SS0.SSS2.p1.2.m2.1.1.1.1.1.1.1.3">edit</mtext></ci></apply><apply id="S3.SS0.SSS2.p1.2.m2.1.1.1.1.1.2.2.cmml" xref="S3.SS0.SSS2.p1.2.m2.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.SS0.SSS2.p1.2.m2.1.1.1.1.1.2.2.1.cmml" xref="S3.SS0.SSS2.p1.2.m2.1.1.1.1.1.2.2">superscript</csymbol><ci id="S3.SS0.SSS2.p1.2.m2.1.1.1.1.1.2.2.2a.cmml" xref="S3.SS0.SSS2.p1.2.m2.1.1.1.1.1.2.2.2"><mtext class="ltx_mathvariant_bold" id="S3.SS0.SSS2.p1.2.m2.1.1.1.1.1.2.2.2.cmml" xref="S3.SS0.SSS2.p1.2.m2.1.1.1.1.1.2.2.2">b</mtext></ci><ci id="S3.SS0.SSS2.p1.2.m2.1.1.1.1.1.2.2.3a.cmml" xref="S3.SS0.SSS2.p1.2.m2.1.1.1.1.1.2.2.3"><mtext id="S3.SS0.SSS2.p1.2.m2.1.1.1.1.1.2.2.3.cmml" mathsize="70%" xref="S3.SS0.SSS2.p1.2.m2.1.1.1.1.1.2.2.3">edit</mtext></ci></apply></interval></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS2.p1.2.m2.1c">\mathcal{D}_{\text{edit}}=\left\{(\textbf{x}^{\text{edit}},\textbf{b}^{\text{%
edit}})\right\}</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS2.p1.2.m2.1d">caligraphic_D start_POSTSUBSCRIPT edit end_POSTSUBSCRIPT = { ( x start_POSTSUPERSCRIPT edit end_POSTSUPERSCRIPT , b start_POSTSUPERSCRIPT edit end_POSTSUPERSCRIPT ) }</annotation></semantics></math>, which contains novel objects and corresponding annotation boxes <math alttext="\textbf{b}^{\text{edit}}" class="ltx_Math" display="inline" id="S3.SS0.SSS2.p1.3.m3.1"><semantics id="S3.SS0.SSS2.p1.3.m3.1a"><msup id="S3.SS0.SSS2.p1.3.m3.1.1" xref="S3.SS0.SSS2.p1.3.m3.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS0.SSS2.p1.3.m3.1.1.2" xref="S3.SS0.SSS2.p1.3.m3.1.1.2a.cmml">b</mtext><mtext id="S3.SS0.SSS2.p1.3.m3.1.1.3" xref="S3.SS0.SSS2.p1.3.m3.1.1.3a.cmml">edit</mtext></msup><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS2.p1.3.m3.1b"><apply id="S3.SS0.SSS2.p1.3.m3.1.1.cmml" xref="S3.SS0.SSS2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS0.SSS2.p1.3.m3.1.1.1.cmml" xref="S3.SS0.SSS2.p1.3.m3.1.1">superscript</csymbol><ci id="S3.SS0.SSS2.p1.3.m3.1.1.2a.cmml" xref="S3.SS0.SSS2.p1.3.m3.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.SS0.SSS2.p1.3.m3.1.1.2.cmml" xref="S3.SS0.SSS2.p1.3.m3.1.1.2">b</mtext></ci><ci id="S3.SS0.SSS2.p1.3.m3.1.1.3a.cmml" xref="S3.SS0.SSS2.p1.3.m3.1.1.3"><mtext id="S3.SS0.SSS2.p1.3.m3.1.1.3.cmml" mathsize="70%" xref="S3.SS0.SSS2.p1.3.m3.1.1.3">edit</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS2.p1.3.m3.1c">\textbf{b}^{\text{edit}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS2.p1.3.m3.1d">b start_POSTSUPERSCRIPT edit end_POSTSUPERSCRIPT</annotation></semantics></math> based on region-level editing from <math alttext="\mathcal{D}_{\text{id}}" class="ltx_Math" display="inline" id="S3.SS0.SSS2.p1.4.m4.1"><semantics id="S3.SS0.SSS2.p1.4.m4.1a"><msub id="S3.SS0.SSS2.p1.4.m4.1.1" xref="S3.SS0.SSS2.p1.4.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS2.p1.4.m4.1.1.2" xref="S3.SS0.SSS2.p1.4.m4.1.1.2.cmml">𝒟</mi><mtext id="S3.SS0.SSS2.p1.4.m4.1.1.3" xref="S3.SS0.SSS2.p1.4.m4.1.1.3a.cmml">id</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS2.p1.4.m4.1b"><apply id="S3.SS0.SSS2.p1.4.m4.1.1.cmml" xref="S3.SS0.SSS2.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS0.SSS2.p1.4.m4.1.1.1.cmml" xref="S3.SS0.SSS2.p1.4.m4.1.1">subscript</csymbol><ci id="S3.SS0.SSS2.p1.4.m4.1.1.2.cmml" xref="S3.SS0.SSS2.p1.4.m4.1.1.2">𝒟</ci><ci id="S3.SS0.SSS2.p1.4.m4.1.1.3a.cmml" xref="S3.SS0.SSS2.p1.4.m4.1.1.3"><mtext id="S3.SS0.SSS2.p1.4.m4.1.1.3.cmml" mathsize="70%" xref="S3.SS0.SSS2.p1.4.m4.1.1.3">id</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS2.p1.4.m4.1c">\mathcal{D}_{\text{id}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS2.p1.4.m4.1d">caligraphic_D start_POSTSUBSCRIPT id end_POSTSUBSCRIPT</annotation></semantics></math> in a fully automated, labor-free way; and (2) select and use the efficient synthetic data to provide pseudo-OOD supervisions for training OOD object detector together with the ID samples in the training set.
Further design of the pipeline requires answering the following questions: (1) how to distill the open-set knowledge embedded in foundation models to scene-level OOD data and (2) how to utilize the synthesized data to regularize the decision boundary and facilitate OOD object detection. We discuss them accordingly in <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S3.SS1" title="3.1 Synthesizing Semantic-novel Objects in Scene Images ‣ 3 Method ‣ Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_tag">Sec.</span> <span class="ltx_text ltx_ref_tag">3.1</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S3.SS2" title="3.2 Mining Hard OOD Samples and Model Training ‣ 3 Method ‣ Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_tag">Sec.</span> <span class="ltx_text ltx_ref_tag">3.2</span></a>.</p>
</div>
<figure class="ltx_figure" id="S3.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="259" id="S3.F2.g1" src="x2.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F2.2.1.1" style="font-size:90%;">Figure 2</span>: </span><span class="ltx_text" id="S3.F2.3.2" style="font-size:90%;">Detailed illustration of our outlier synthesis pipeline. It comprises (a) Instructing an LLM to imagine semantic-novel concepts given ID objects, (b) Editing the selected regions to the expected concepts via prompt-conditioned image inpainting using Stable Diffusion, and (c) Refining the bounding boxes of edited objects using SAM.</span></figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Synthesizing Semantic-novel Objects in Scene Images</h3>
<section class="ltx_subsubsection" id="S3.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.1 </span>Imagining Novel Concepts from ID objects</h4>
<div class="ltx_para" id="S3.SS1.SSS1.p1">
<p class="ltx_p" id="S3.SS1.SSS1.p1.2">As shown in <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S3.F2" title="In 3.0.2 Overview ‣ 3 Method ‣ Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">2</span></a>(a), based on the ID labels <math alttext="\mathcal{Y}_{\text{id}}" class="ltx_Math" display="inline" id="S3.SS1.SSS1.p1.1.m1.1"><semantics id="S3.SS1.SSS1.p1.1.m1.1a"><msub id="S3.SS1.SSS1.p1.1.m1.1.1" xref="S3.SS1.SSS1.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.SSS1.p1.1.m1.1.1.2" xref="S3.SS1.SSS1.p1.1.m1.1.1.2.cmml">𝒴</mi><mtext id="S3.SS1.SSS1.p1.1.m1.1.1.3" xref="S3.SS1.SSS1.p1.1.m1.1.1.3a.cmml">id</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p1.1.m1.1b"><apply id="S3.SS1.SSS1.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p1.1.m1.1.1.1.cmml" xref="S3.SS1.SSS1.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.SSS1.p1.1.m1.1.1.2.cmml" xref="S3.SS1.SSS1.p1.1.m1.1.1.2">𝒴</ci><ci id="S3.SS1.SSS1.p1.1.m1.1.1.3a.cmml" xref="S3.SS1.SSS1.p1.1.m1.1.1.3"><mtext id="S3.SS1.SSS1.p1.1.m1.1.1.3.cmml" mathsize="70%" xref="S3.SS1.SSS1.p1.1.m1.1.1.3">id</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p1.1.m1.1c">\mathcal{Y}_{\text{id}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS1.p1.1.m1.1d">caligraphic_Y start_POSTSUBSCRIPT id end_POSTSUBSCRIPT</annotation></semantics></math> in training set <math alttext="\mathcal{D}_{\text{id}}" class="ltx_Math" display="inline" id="S3.SS1.SSS1.p1.2.m2.1"><semantics id="S3.SS1.SSS1.p1.2.m2.1a"><msub id="S3.SS1.SSS1.p1.2.m2.1.1" xref="S3.SS1.SSS1.p1.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.SSS1.p1.2.m2.1.1.2" xref="S3.SS1.SSS1.p1.2.m2.1.1.2.cmml">𝒟</mi><mtext id="S3.SS1.SSS1.p1.2.m2.1.1.3" xref="S3.SS1.SSS1.p1.2.m2.1.1.3a.cmml">id</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p1.2.m2.1b"><apply id="S3.SS1.SSS1.p1.2.m2.1.1.cmml" xref="S3.SS1.SSS1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p1.2.m2.1.1.1.cmml" xref="S3.SS1.SSS1.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.SSS1.p1.2.m2.1.1.2.cmml" xref="S3.SS1.SSS1.p1.2.m2.1.1.2">𝒟</ci><ci id="S3.SS1.SSS1.p1.2.m2.1.1.3a.cmml" xref="S3.SS1.SSS1.p1.2.m2.1.1.3"><mtext id="S3.SS1.SSS1.p1.2.m2.1.1.3.cmml" mathsize="70%" xref="S3.SS1.SSS1.p1.2.m2.1.1.3">id</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p1.2.m2.1c">\mathcal{D}_{\text{id}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS1.p1.2.m2.1d">caligraphic_D start_POSTSUBSCRIPT id end_POSTSUBSCRIPT</annotation></semantics></math>, we consider that novel concepts that are different from ID categories can be potential candidates for generating OOD objects. The next is to discover novel concepts that offer hard OOD samples sharing high visual similarity with ID samples and being contextually compatible with the scene context for object detection. Rather than relying on human labor to investigate all potential candidates, we leverage the vast knowledge and reasoning capabilities of LLM, GPT-4 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib1" title="">1</a>]</cite> to check the visual similarity and contextual compatibility. This allows us to associate ID objects and promote the conceptualization of possible novel objects to replace existing ID objects through the use of a prompt with in-context examples <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib4" title="">4</a>]</cite> as:</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.SSS1.p2">
<div class="ltx_logical-block ltx_minipage ltx_align_middle" id="S3.SS1.SSS1.p2.1" style="width:433.6pt;">
<div class="ltx_para ltx_noindent" id="S3.SS1.SSS1.p2.1.p1">
<svg class="ltx_picture" height="88.44" id="S3.SS1.SSS1.p2.1.p1.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,88.44) matrix(1 0 0 -1 0 0)"><g fill="#404040" fill-opacity="1.0"><path d="M 0 5.91 L 0 82.54 C 0 85.8 2.64 88.44 5.91 88.44 L 594.09 88.44 C 597.36 88.44 600 85.8 600 82.54 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.0"><path d="M 1.97 5.91 L 1.97 82.54 C 1.97 84.71 3.73 86.47 5.91 86.47 L 594.09 86.47 C 596.27 86.47 598.03 84.71 598.03 82.54 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="60.88" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="S3.SS1.SSS1.p2.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1" style="width:402.3pt;">
<span class="ltx_p" id="S3.SS1.SSS1.p2.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1"><span class="ltx_text" id="S3.SS1.SSS1.p2.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1" style="font-size:90%;">Here is a list containing several objects <math alttext="\mathcal{Y}_{\text{id}}" class="ltx_Math" display="inline" id="S3.SS1.SSS1.p2.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1"><semantics id="S3.SS1.SSS1.p2.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1a"><msub id="S3.SS1.SSS1.p2.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1" xref="S3.SS1.SSS1.p2.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.SSS1.p2.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.2" xref="S3.SS1.SSS1.p2.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.2.cmml">𝒴</mi><mtext id="S3.SS1.SSS1.p2.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.3" xref="S3.SS1.SSS1.p2.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.3a.cmml">id</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p2.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1b"><apply id="S3.SS1.SSS1.p2.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S3.SS1.SSS1.p2.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p2.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.1.cmml" xref="S3.SS1.SSS1.p2.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.SSS1.p2.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.2.cmml" xref="S3.SS1.SSS1.p2.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.2">𝒴</ci><ci id="S3.SS1.SSS1.p2.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.3a.cmml" xref="S3.SS1.SSS1.p2.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.3"><mtext id="S3.SS1.SSS1.p2.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.3.cmml" mathsize="70%" xref="S3.SS1.SSS1.p2.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.3">id</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p2.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1c">\mathcal{Y}_{\text{id}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS1.p2.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1d">caligraphic_Y start_POSTSUBSCRIPT id end_POSTSUBSCRIPT</annotation></semantics></math>. Now, if I provide you an object name, you should return to me objects that are similar to the usage scenario and volume of the provided object but are not in the previous object list. For example, if I give you the word: person, you should respond and only respond: ‘mannequin’, ‘sculpture’, ‘scarecrows’, ‘doll’, ‘puppet’.</span></span>
</span></foreignobject></g></g></svg>
</div>
</div>
</div>
<div class="ltx_para" id="S3.SS1.SSS1.p3">
<p class="ltx_p" id="S3.SS1.SSS1.p3.5">With its robust logical foundation and rich knowledge, the LLM envisions a collection of novel objects for each ID object label, denoted as <math alttext="\mathcal{Y}_{\text{novel}}" class="ltx_Math" display="inline" id="S3.SS1.SSS1.p3.1.m1.1"><semantics id="S3.SS1.SSS1.p3.1.m1.1a"><msub id="S3.SS1.SSS1.p3.1.m1.1.1" xref="S3.SS1.SSS1.p3.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.SSS1.p3.1.m1.1.1.2" xref="S3.SS1.SSS1.p3.1.m1.1.1.2.cmml">𝒴</mi><mtext id="S3.SS1.SSS1.p3.1.m1.1.1.3" xref="S3.SS1.SSS1.p3.1.m1.1.1.3a.cmml">novel</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p3.1.m1.1b"><apply id="S3.SS1.SSS1.p3.1.m1.1.1.cmml" xref="S3.SS1.SSS1.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p3.1.m1.1.1.1.cmml" xref="S3.SS1.SSS1.p3.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.SSS1.p3.1.m1.1.1.2.cmml" xref="S3.SS1.SSS1.p3.1.m1.1.1.2">𝒴</ci><ci id="S3.SS1.SSS1.p3.1.m1.1.1.3a.cmml" xref="S3.SS1.SSS1.p3.1.m1.1.1.3"><mtext id="S3.SS1.SSS1.p3.1.m1.1.1.3.cmml" mathsize="70%" xref="S3.SS1.SSS1.p3.1.m1.1.1.3">novel</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p3.1.m1.1c">\mathcal{Y}_{\text{novel}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS1.p3.1.m1.1d">caligraphic_Y start_POSTSUBSCRIPT novel end_POSTSUBSCRIPT</annotation></semantics></math>, while maintaining the semantic separability between imagined objects and ID objects. We empirically find one in-context example that is sufficient for us to discover novel concepts.
For each ID label <math alttext="i" class="ltx_Math" display="inline" id="S3.SS1.SSS1.p3.2.m2.1"><semantics id="S3.SS1.SSS1.p3.2.m2.1a"><mi id="S3.SS1.SSS1.p3.2.m2.1.1" xref="S3.SS1.SSS1.p3.2.m2.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p3.2.m2.1b"><ci id="S3.SS1.SSS1.p3.2.m2.1.1.cmml" xref="S3.SS1.SSS1.p3.2.m2.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p3.2.m2.1c">i</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS1.p3.2.m2.1d">italic_i</annotation></semantics></math>, we discover <math alttext="M" class="ltx_Math" display="inline" id="S3.SS1.SSS1.p3.3.m3.1"><semantics id="S3.SS1.SSS1.p3.3.m3.1a"><mi id="S3.SS1.SSS1.p3.3.m3.1.1" xref="S3.SS1.SSS1.p3.3.m3.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p3.3.m3.1b"><ci id="S3.SS1.SSS1.p3.3.m3.1.1.cmml" xref="S3.SS1.SSS1.p3.3.m3.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p3.3.m3.1c">M</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS1.p3.3.m3.1d">italic_M</annotation></semantics></math> novel concepts using LLM <math alttext="\textbf{y}^{\text{novel}}_{i}" class="ltx_Math" display="inline" id="S3.SS1.SSS1.p3.4.m4.1"><semantics id="S3.SS1.SSS1.p3.4.m4.1a"><msubsup id="S3.SS1.SSS1.p3.4.m4.1.1" xref="S3.SS1.SSS1.p3.4.m4.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS1.SSS1.p3.4.m4.1.1.2.2" xref="S3.SS1.SSS1.p3.4.m4.1.1.2.2a.cmml">y</mtext><mi id="S3.SS1.SSS1.p3.4.m4.1.1.3" xref="S3.SS1.SSS1.p3.4.m4.1.1.3.cmml">i</mi><mtext id="S3.SS1.SSS1.p3.4.m4.1.1.2.3" xref="S3.SS1.SSS1.p3.4.m4.1.1.2.3a.cmml">novel</mtext></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p3.4.m4.1b"><apply id="S3.SS1.SSS1.p3.4.m4.1.1.cmml" xref="S3.SS1.SSS1.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p3.4.m4.1.1.1.cmml" xref="S3.SS1.SSS1.p3.4.m4.1.1">subscript</csymbol><apply id="S3.SS1.SSS1.p3.4.m4.1.1.2.cmml" xref="S3.SS1.SSS1.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p3.4.m4.1.1.2.1.cmml" xref="S3.SS1.SSS1.p3.4.m4.1.1">superscript</csymbol><ci id="S3.SS1.SSS1.p3.4.m4.1.1.2.2a.cmml" xref="S3.SS1.SSS1.p3.4.m4.1.1.2.2"><mtext class="ltx_mathvariant_bold" id="S3.SS1.SSS1.p3.4.m4.1.1.2.2.cmml" xref="S3.SS1.SSS1.p3.4.m4.1.1.2.2">y</mtext></ci><ci id="S3.SS1.SSS1.p3.4.m4.1.1.2.3a.cmml" xref="S3.SS1.SSS1.p3.4.m4.1.1.2.3"><mtext id="S3.SS1.SSS1.p3.4.m4.1.1.2.3.cmml" mathsize="70%" xref="S3.SS1.SSS1.p3.4.m4.1.1.2.3">novel</mtext></ci></apply><ci id="S3.SS1.SSS1.p3.4.m4.1.1.3.cmml" xref="S3.SS1.SSS1.p3.4.m4.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p3.4.m4.1c">\textbf{y}^{\text{novel}}_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS1.p3.4.m4.1d">y start_POSTSUPERSCRIPT novel end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> of <math alttext="M" class="ltx_Math" display="inline" id="S3.SS1.SSS1.p3.5.m5.1"><semantics id="S3.SS1.SSS1.p3.5.m5.1a"><mi id="S3.SS1.SSS1.p3.5.m5.1.1" xref="S3.SS1.SSS1.p3.5.m5.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p3.5.m5.1b"><ci id="S3.SS1.SSS1.p3.5.m5.1.1.cmml" xref="S3.SS1.SSS1.p3.5.m5.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p3.5.m5.1c">M</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS1.p3.5.m5.1d">italic_M</annotation></semantics></math> concepts.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS1.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.2 </span>Editing Objects on Selected Regions</h4>
<div class="ltx_para" id="S3.SS1.SSS2.p1">
<p class="ltx_p" id="S3.SS1.SSS2.p1.9">With the discovered novel concepts <math alttext="\mathcal{Y}_{\text{novel}}=\{\textbf{y}^{\text{novel}}_{1},\textbf{y}^{\text{%
novel}}_{2},...,\textbf{y}^{\text{novel}}_{K}\}" class="ltx_Math" display="inline" id="S3.SS1.SSS2.p1.1.m1.4"><semantics id="S3.SS1.SSS2.p1.1.m1.4a"><mrow id="S3.SS1.SSS2.p1.1.m1.4.4" xref="S3.SS1.SSS2.p1.1.m1.4.4.cmml"><msub id="S3.SS1.SSS2.p1.1.m1.4.4.5" xref="S3.SS1.SSS2.p1.1.m1.4.4.5.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.SSS2.p1.1.m1.4.4.5.2" xref="S3.SS1.SSS2.p1.1.m1.4.4.5.2.cmml">𝒴</mi><mtext id="S3.SS1.SSS2.p1.1.m1.4.4.5.3" xref="S3.SS1.SSS2.p1.1.m1.4.4.5.3a.cmml">novel</mtext></msub><mo id="S3.SS1.SSS2.p1.1.m1.4.4.4" xref="S3.SS1.SSS2.p1.1.m1.4.4.4.cmml">=</mo><mrow id="S3.SS1.SSS2.p1.1.m1.4.4.3.3" xref="S3.SS1.SSS2.p1.1.m1.4.4.3.4.cmml"><mo id="S3.SS1.SSS2.p1.1.m1.4.4.3.3.4" stretchy="false" xref="S3.SS1.SSS2.p1.1.m1.4.4.3.4.cmml">{</mo><msubsup id="S3.SS1.SSS2.p1.1.m1.2.2.1.1.1" xref="S3.SS1.SSS2.p1.1.m1.2.2.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS1.SSS2.p1.1.m1.2.2.1.1.1.2.2" xref="S3.SS1.SSS2.p1.1.m1.2.2.1.1.1.2.2a.cmml">y</mtext><mn id="S3.SS1.SSS2.p1.1.m1.2.2.1.1.1.3" xref="S3.SS1.SSS2.p1.1.m1.2.2.1.1.1.3.cmml">1</mn><mtext id="S3.SS1.SSS2.p1.1.m1.2.2.1.1.1.2.3" xref="S3.SS1.SSS2.p1.1.m1.2.2.1.1.1.2.3a.cmml">novel</mtext></msubsup><mo id="S3.SS1.SSS2.p1.1.m1.4.4.3.3.5" xref="S3.SS1.SSS2.p1.1.m1.4.4.3.4.cmml">,</mo><msubsup id="S3.SS1.SSS2.p1.1.m1.3.3.2.2.2" xref="S3.SS1.SSS2.p1.1.m1.3.3.2.2.2.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS1.SSS2.p1.1.m1.3.3.2.2.2.2.2" xref="S3.SS1.SSS2.p1.1.m1.3.3.2.2.2.2.2a.cmml">y</mtext><mn id="S3.SS1.SSS2.p1.1.m1.3.3.2.2.2.3" xref="S3.SS1.SSS2.p1.1.m1.3.3.2.2.2.3.cmml">2</mn><mtext id="S3.SS1.SSS2.p1.1.m1.3.3.2.2.2.2.3" xref="S3.SS1.SSS2.p1.1.m1.3.3.2.2.2.2.3a.cmml">novel</mtext></msubsup><mo id="S3.SS1.SSS2.p1.1.m1.4.4.3.3.6" xref="S3.SS1.SSS2.p1.1.m1.4.4.3.4.cmml">,</mo><mi id="S3.SS1.SSS2.p1.1.m1.1.1" mathvariant="normal" xref="S3.SS1.SSS2.p1.1.m1.1.1.cmml">…</mi><mo id="S3.SS1.SSS2.p1.1.m1.4.4.3.3.7" xref="S3.SS1.SSS2.p1.1.m1.4.4.3.4.cmml">,</mo><msubsup id="S3.SS1.SSS2.p1.1.m1.4.4.3.3.3" xref="S3.SS1.SSS2.p1.1.m1.4.4.3.3.3.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS1.SSS2.p1.1.m1.4.4.3.3.3.2.2" xref="S3.SS1.SSS2.p1.1.m1.4.4.3.3.3.2.2a.cmml">y</mtext><mi id="S3.SS1.SSS2.p1.1.m1.4.4.3.3.3.3" xref="S3.SS1.SSS2.p1.1.m1.4.4.3.3.3.3.cmml">K</mi><mtext id="S3.SS1.SSS2.p1.1.m1.4.4.3.3.3.2.3" xref="S3.SS1.SSS2.p1.1.m1.4.4.3.3.3.2.3a.cmml">novel</mtext></msubsup><mo id="S3.SS1.SSS2.p1.1.m1.4.4.3.3.8" stretchy="false" xref="S3.SS1.SSS2.p1.1.m1.4.4.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p1.1.m1.4b"><apply id="S3.SS1.SSS2.p1.1.m1.4.4.cmml" xref="S3.SS1.SSS2.p1.1.m1.4.4"><eq id="S3.SS1.SSS2.p1.1.m1.4.4.4.cmml" xref="S3.SS1.SSS2.p1.1.m1.4.4.4"></eq><apply id="S3.SS1.SSS2.p1.1.m1.4.4.5.cmml" xref="S3.SS1.SSS2.p1.1.m1.4.4.5"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p1.1.m1.4.4.5.1.cmml" xref="S3.SS1.SSS2.p1.1.m1.4.4.5">subscript</csymbol><ci id="S3.SS1.SSS2.p1.1.m1.4.4.5.2.cmml" xref="S3.SS1.SSS2.p1.1.m1.4.4.5.2">𝒴</ci><ci id="S3.SS1.SSS2.p1.1.m1.4.4.5.3a.cmml" xref="S3.SS1.SSS2.p1.1.m1.4.4.5.3"><mtext id="S3.SS1.SSS2.p1.1.m1.4.4.5.3.cmml" mathsize="70%" xref="S3.SS1.SSS2.p1.1.m1.4.4.5.3">novel</mtext></ci></apply><set id="S3.SS1.SSS2.p1.1.m1.4.4.3.4.cmml" xref="S3.SS1.SSS2.p1.1.m1.4.4.3.3"><apply id="S3.SS1.SSS2.p1.1.m1.2.2.1.1.1.cmml" xref="S3.SS1.SSS2.p1.1.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p1.1.m1.2.2.1.1.1.1.cmml" xref="S3.SS1.SSS2.p1.1.m1.2.2.1.1.1">subscript</csymbol><apply id="S3.SS1.SSS2.p1.1.m1.2.2.1.1.1.2.cmml" xref="S3.SS1.SSS2.p1.1.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p1.1.m1.2.2.1.1.1.2.1.cmml" xref="S3.SS1.SSS2.p1.1.m1.2.2.1.1.1">superscript</csymbol><ci id="S3.SS1.SSS2.p1.1.m1.2.2.1.1.1.2.2a.cmml" xref="S3.SS1.SSS2.p1.1.m1.2.2.1.1.1.2.2"><mtext class="ltx_mathvariant_bold" id="S3.SS1.SSS2.p1.1.m1.2.2.1.1.1.2.2.cmml" xref="S3.SS1.SSS2.p1.1.m1.2.2.1.1.1.2.2">y</mtext></ci><ci id="S3.SS1.SSS2.p1.1.m1.2.2.1.1.1.2.3a.cmml" xref="S3.SS1.SSS2.p1.1.m1.2.2.1.1.1.2.3"><mtext id="S3.SS1.SSS2.p1.1.m1.2.2.1.1.1.2.3.cmml" mathsize="70%" xref="S3.SS1.SSS2.p1.1.m1.2.2.1.1.1.2.3">novel</mtext></ci></apply><cn id="S3.SS1.SSS2.p1.1.m1.2.2.1.1.1.3.cmml" type="integer" xref="S3.SS1.SSS2.p1.1.m1.2.2.1.1.1.3">1</cn></apply><apply id="S3.SS1.SSS2.p1.1.m1.3.3.2.2.2.cmml" xref="S3.SS1.SSS2.p1.1.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p1.1.m1.3.3.2.2.2.1.cmml" xref="S3.SS1.SSS2.p1.1.m1.3.3.2.2.2">subscript</csymbol><apply id="S3.SS1.SSS2.p1.1.m1.3.3.2.2.2.2.cmml" xref="S3.SS1.SSS2.p1.1.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p1.1.m1.3.3.2.2.2.2.1.cmml" xref="S3.SS1.SSS2.p1.1.m1.3.3.2.2.2">superscript</csymbol><ci id="S3.SS1.SSS2.p1.1.m1.3.3.2.2.2.2.2a.cmml" xref="S3.SS1.SSS2.p1.1.m1.3.3.2.2.2.2.2"><mtext class="ltx_mathvariant_bold" id="S3.SS1.SSS2.p1.1.m1.3.3.2.2.2.2.2.cmml" xref="S3.SS1.SSS2.p1.1.m1.3.3.2.2.2.2.2">y</mtext></ci><ci id="S3.SS1.SSS2.p1.1.m1.3.3.2.2.2.2.3a.cmml" xref="S3.SS1.SSS2.p1.1.m1.3.3.2.2.2.2.3"><mtext id="S3.SS1.SSS2.p1.1.m1.3.3.2.2.2.2.3.cmml" mathsize="70%" xref="S3.SS1.SSS2.p1.1.m1.3.3.2.2.2.2.3">novel</mtext></ci></apply><cn id="S3.SS1.SSS2.p1.1.m1.3.3.2.2.2.3.cmml" type="integer" xref="S3.SS1.SSS2.p1.1.m1.3.3.2.2.2.3">2</cn></apply><ci id="S3.SS1.SSS2.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS2.p1.1.m1.1.1">…</ci><apply id="S3.SS1.SSS2.p1.1.m1.4.4.3.3.3.cmml" xref="S3.SS1.SSS2.p1.1.m1.4.4.3.3.3"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p1.1.m1.4.4.3.3.3.1.cmml" xref="S3.SS1.SSS2.p1.1.m1.4.4.3.3.3">subscript</csymbol><apply id="S3.SS1.SSS2.p1.1.m1.4.4.3.3.3.2.cmml" xref="S3.SS1.SSS2.p1.1.m1.4.4.3.3.3"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p1.1.m1.4.4.3.3.3.2.1.cmml" xref="S3.SS1.SSS2.p1.1.m1.4.4.3.3.3">superscript</csymbol><ci id="S3.SS1.SSS2.p1.1.m1.4.4.3.3.3.2.2a.cmml" xref="S3.SS1.SSS2.p1.1.m1.4.4.3.3.3.2.2"><mtext class="ltx_mathvariant_bold" id="S3.SS1.SSS2.p1.1.m1.4.4.3.3.3.2.2.cmml" xref="S3.SS1.SSS2.p1.1.m1.4.4.3.3.3.2.2">y</mtext></ci><ci id="S3.SS1.SSS2.p1.1.m1.4.4.3.3.3.2.3a.cmml" xref="S3.SS1.SSS2.p1.1.m1.4.4.3.3.3.2.3"><mtext id="S3.SS1.SSS2.p1.1.m1.4.4.3.3.3.2.3.cmml" mathsize="70%" xref="S3.SS1.SSS2.p1.1.m1.4.4.3.3.3.2.3">novel</mtext></ci></apply><ci id="S3.SS1.SSS2.p1.1.m1.4.4.3.3.3.3.cmml" xref="S3.SS1.SSS2.p1.1.m1.4.4.3.3.3.3">𝐾</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p1.1.m1.4c">\mathcal{Y}_{\text{novel}}=\{\textbf{y}^{\text{novel}}_{1},\textbf{y}^{\text{%
novel}}_{2},...,\textbf{y}^{\text{novel}}_{K}\}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS2.p1.1.m1.4d">caligraphic_Y start_POSTSUBSCRIPT novel end_POSTSUBSCRIPT = { y start_POSTSUPERSCRIPT novel end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , y start_POSTSUPERSCRIPT novel end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … , y start_POSTSUPERSCRIPT novel end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_K end_POSTSUBSCRIPT }</annotation></semantics></math>, the next step is to use them as prompts for the text-to-image generation model to generate an image.
To generate a new image with novel concepts <math alttext="y_{j}\in\textbf{y}^{\text{novel}}_{i}" class="ltx_Math" display="inline" id="S3.SS1.SSS2.p1.2.m2.1"><semantics id="S3.SS1.SSS2.p1.2.m2.1a"><mrow id="S3.SS1.SSS2.p1.2.m2.1.1" xref="S3.SS1.SSS2.p1.2.m2.1.1.cmml"><msub id="S3.SS1.SSS2.p1.2.m2.1.1.2" xref="S3.SS1.SSS2.p1.2.m2.1.1.2.cmml"><mi id="S3.SS1.SSS2.p1.2.m2.1.1.2.2" xref="S3.SS1.SSS2.p1.2.m2.1.1.2.2.cmml">y</mi><mi id="S3.SS1.SSS2.p1.2.m2.1.1.2.3" xref="S3.SS1.SSS2.p1.2.m2.1.1.2.3.cmml">j</mi></msub><mo id="S3.SS1.SSS2.p1.2.m2.1.1.1" xref="S3.SS1.SSS2.p1.2.m2.1.1.1.cmml">∈</mo><msubsup id="S3.SS1.SSS2.p1.2.m2.1.1.3" xref="S3.SS1.SSS2.p1.2.m2.1.1.3.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS1.SSS2.p1.2.m2.1.1.3.2.2" xref="S3.SS1.SSS2.p1.2.m2.1.1.3.2.2a.cmml">y</mtext><mi id="S3.SS1.SSS2.p1.2.m2.1.1.3.3" xref="S3.SS1.SSS2.p1.2.m2.1.1.3.3.cmml">i</mi><mtext id="S3.SS1.SSS2.p1.2.m2.1.1.3.2.3" xref="S3.SS1.SSS2.p1.2.m2.1.1.3.2.3a.cmml">novel</mtext></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p1.2.m2.1b"><apply id="S3.SS1.SSS2.p1.2.m2.1.1.cmml" xref="S3.SS1.SSS2.p1.2.m2.1.1"><in id="S3.SS1.SSS2.p1.2.m2.1.1.1.cmml" xref="S3.SS1.SSS2.p1.2.m2.1.1.1"></in><apply id="S3.SS1.SSS2.p1.2.m2.1.1.2.cmml" xref="S3.SS1.SSS2.p1.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p1.2.m2.1.1.2.1.cmml" xref="S3.SS1.SSS2.p1.2.m2.1.1.2">subscript</csymbol><ci id="S3.SS1.SSS2.p1.2.m2.1.1.2.2.cmml" xref="S3.SS1.SSS2.p1.2.m2.1.1.2.2">𝑦</ci><ci id="S3.SS1.SSS2.p1.2.m2.1.1.2.3.cmml" xref="S3.SS1.SSS2.p1.2.m2.1.1.2.3">𝑗</ci></apply><apply id="S3.SS1.SSS2.p1.2.m2.1.1.3.cmml" xref="S3.SS1.SSS2.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p1.2.m2.1.1.3.1.cmml" xref="S3.SS1.SSS2.p1.2.m2.1.1.3">subscript</csymbol><apply id="S3.SS1.SSS2.p1.2.m2.1.1.3.2.cmml" xref="S3.SS1.SSS2.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p1.2.m2.1.1.3.2.1.cmml" xref="S3.SS1.SSS2.p1.2.m2.1.1.3">superscript</csymbol><ci id="S3.SS1.SSS2.p1.2.m2.1.1.3.2.2a.cmml" xref="S3.SS1.SSS2.p1.2.m2.1.1.3.2.2"><mtext class="ltx_mathvariant_bold" id="S3.SS1.SSS2.p1.2.m2.1.1.3.2.2.cmml" xref="S3.SS1.SSS2.p1.2.m2.1.1.3.2.2">y</mtext></ci><ci id="S3.SS1.SSS2.p1.2.m2.1.1.3.2.3a.cmml" xref="S3.SS1.SSS2.p1.2.m2.1.1.3.2.3"><mtext id="S3.SS1.SSS2.p1.2.m2.1.1.3.2.3.cmml" mathsize="70%" xref="S3.SS1.SSS2.p1.2.m2.1.1.3.2.3">novel</mtext></ci></apply><ci id="S3.SS1.SSS2.p1.2.m2.1.1.3.3.cmml" xref="S3.SS1.SSS2.p1.2.m2.1.1.3.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p1.2.m2.1c">y_{j}\in\textbf{y}^{\text{novel}}_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS2.p1.2.m2.1d">italic_y start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ∈ y start_POSTSUPERSCRIPT novel end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>, we choose to replace existing ID objects in existing images with label <math alttext="y_{i}^{\text{id}}" class="ltx_Math" display="inline" id="S3.SS1.SSS2.p1.3.m3.1"><semantics id="S3.SS1.SSS2.p1.3.m3.1a"><msubsup id="S3.SS1.SSS2.p1.3.m3.1.1" xref="S3.SS1.SSS2.p1.3.m3.1.1.cmml"><mi id="S3.SS1.SSS2.p1.3.m3.1.1.2.2" xref="S3.SS1.SSS2.p1.3.m3.1.1.2.2.cmml">y</mi><mi id="S3.SS1.SSS2.p1.3.m3.1.1.2.3" xref="S3.SS1.SSS2.p1.3.m3.1.1.2.3.cmml">i</mi><mtext id="S3.SS1.SSS2.p1.3.m3.1.1.3" xref="S3.SS1.SSS2.p1.3.m3.1.1.3a.cmml">id</mtext></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p1.3.m3.1b"><apply id="S3.SS1.SSS2.p1.3.m3.1.1.cmml" xref="S3.SS1.SSS2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p1.3.m3.1.1.1.cmml" xref="S3.SS1.SSS2.p1.3.m3.1.1">superscript</csymbol><apply id="S3.SS1.SSS2.p1.3.m3.1.1.2.cmml" xref="S3.SS1.SSS2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p1.3.m3.1.1.2.1.cmml" xref="S3.SS1.SSS2.p1.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.SSS2.p1.3.m3.1.1.2.2.cmml" xref="S3.SS1.SSS2.p1.3.m3.1.1.2.2">𝑦</ci><ci id="S3.SS1.SSS2.p1.3.m3.1.1.2.3.cmml" xref="S3.SS1.SSS2.p1.3.m3.1.1.2.3">𝑖</ci></apply><ci id="S3.SS1.SSS2.p1.3.m3.1.1.3a.cmml" xref="S3.SS1.SSS2.p1.3.m3.1.1.3"><mtext id="S3.SS1.SSS2.p1.3.m3.1.1.3.cmml" mathsize="70%" xref="S3.SS1.SSS2.p1.3.m3.1.1.3">id</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p1.3.m3.1c">y_{i}^{\text{id}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS2.p1.3.m3.1d">italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT id end_POSTSUPERSCRIPT</annotation></semantics></math> instead of finding new locations or generating one image from scratch.
By doing so, we can ensure context compatibility and eliminate distractions from the scene context as it is preserved.
As illustrated in <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S3.F2" title="In 3.0.2 Overview ‣ 3 Method ‣ Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">2</span></a> (b), we use Stable-Diffusion-Inpainting <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib49" title="">49</a>]</cite>, denoted as <math alttext="\text{SDI}(\cdot)" class="ltx_Math" display="inline" id="S3.SS1.SSS2.p1.4.m4.1"><semantics id="S3.SS1.SSS2.p1.4.m4.1a"><mrow id="S3.SS1.SSS2.p1.4.m4.1.2" xref="S3.SS1.SSS2.p1.4.m4.1.2.cmml"><mtext id="S3.SS1.SSS2.p1.4.m4.1.2.2" xref="S3.SS1.SSS2.p1.4.m4.1.2.2a.cmml">SDI</mtext><mo id="S3.SS1.SSS2.p1.4.m4.1.2.1" xref="S3.SS1.SSS2.p1.4.m4.1.2.1.cmml">⁢</mo><mrow id="S3.SS1.SSS2.p1.4.m4.1.2.3.2" xref="S3.SS1.SSS2.p1.4.m4.1.2.cmml"><mo id="S3.SS1.SSS2.p1.4.m4.1.2.3.2.1" stretchy="false" xref="S3.SS1.SSS2.p1.4.m4.1.2.cmml">(</mo><mo id="S3.SS1.SSS2.p1.4.m4.1.1" lspace="0em" rspace="0em" xref="S3.SS1.SSS2.p1.4.m4.1.1.cmml">⋅</mo><mo id="S3.SS1.SSS2.p1.4.m4.1.2.3.2.2" stretchy="false" xref="S3.SS1.SSS2.p1.4.m4.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p1.4.m4.1b"><apply id="S3.SS1.SSS2.p1.4.m4.1.2.cmml" xref="S3.SS1.SSS2.p1.4.m4.1.2"><times id="S3.SS1.SSS2.p1.4.m4.1.2.1.cmml" xref="S3.SS1.SSS2.p1.4.m4.1.2.1"></times><ci id="S3.SS1.SSS2.p1.4.m4.1.2.2a.cmml" xref="S3.SS1.SSS2.p1.4.m4.1.2.2"><mtext id="S3.SS1.SSS2.p1.4.m4.1.2.2.cmml" xref="S3.SS1.SSS2.p1.4.m4.1.2.2">SDI</mtext></ci><ci id="S3.SS1.SSS2.p1.4.m4.1.1.cmml" xref="S3.SS1.SSS2.p1.4.m4.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p1.4.m4.1c">\text{SDI}(\cdot)</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS2.p1.4.m4.1d">SDI ( ⋅ )</annotation></semantics></math>, to perform region-level editing on ID images.
The ID object is denoted as <math alttext="\textbf{x}^{\text{id}}" class="ltx_Math" display="inline" id="S3.SS1.SSS2.p1.5.m5.1"><semantics id="S3.SS1.SSS2.p1.5.m5.1a"><msup id="S3.SS1.SSS2.p1.5.m5.1.1" xref="S3.SS1.SSS2.p1.5.m5.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS1.SSS2.p1.5.m5.1.1.2" xref="S3.SS1.SSS2.p1.5.m5.1.1.2a.cmml">x</mtext><mtext id="S3.SS1.SSS2.p1.5.m5.1.1.3" xref="S3.SS1.SSS2.p1.5.m5.1.1.3a.cmml">id</mtext></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p1.5.m5.1b"><apply id="S3.SS1.SSS2.p1.5.m5.1.1.cmml" xref="S3.SS1.SSS2.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p1.5.m5.1.1.1.cmml" xref="S3.SS1.SSS2.p1.5.m5.1.1">superscript</csymbol><ci id="S3.SS1.SSS2.p1.5.m5.1.1.2a.cmml" xref="S3.SS1.SSS2.p1.5.m5.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.SS1.SSS2.p1.5.m5.1.1.2.cmml" xref="S3.SS1.SSS2.p1.5.m5.1.1.2">x</mtext></ci><ci id="S3.SS1.SSS2.p1.5.m5.1.1.3a.cmml" xref="S3.SS1.SSS2.p1.5.m5.1.1.3"><mtext id="S3.SS1.SSS2.p1.5.m5.1.1.3.cmml" mathsize="70%" xref="S3.SS1.SSS2.p1.5.m5.1.1.3">id</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p1.5.m5.1c">\textbf{x}^{\text{id}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS2.p1.5.m5.1d">x start_POSTSUPERSCRIPT id end_POSTSUPERSCRIPT</annotation></semantics></math>, with its corresponding annotation box <math alttext="\textbf{b}^{\text{id}}" class="ltx_Math" display="inline" id="S3.SS1.SSS2.p1.6.m6.1"><semantics id="S3.SS1.SSS2.p1.6.m6.1a"><msup id="S3.SS1.SSS2.p1.6.m6.1.1" xref="S3.SS1.SSS2.p1.6.m6.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS1.SSS2.p1.6.m6.1.1.2" xref="S3.SS1.SSS2.p1.6.m6.1.1.2a.cmml">b</mtext><mtext id="S3.SS1.SSS2.p1.6.m6.1.1.3" xref="S3.SS1.SSS2.p1.6.m6.1.1.3a.cmml">id</mtext></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p1.6.m6.1b"><apply id="S3.SS1.SSS2.p1.6.m6.1.1.cmml" xref="S3.SS1.SSS2.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p1.6.m6.1.1.1.cmml" xref="S3.SS1.SSS2.p1.6.m6.1.1">superscript</csymbol><ci id="S3.SS1.SSS2.p1.6.m6.1.1.2a.cmml" xref="S3.SS1.SSS2.p1.6.m6.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.SS1.SSS2.p1.6.m6.1.1.2.cmml" xref="S3.SS1.SSS2.p1.6.m6.1.1.2">b</mtext></ci><ci id="S3.SS1.SSS2.p1.6.m6.1.1.3a.cmml" xref="S3.SS1.SSS2.p1.6.m6.1.1.3"><mtext id="S3.SS1.SSS2.p1.6.m6.1.1.3.cmml" mathsize="70%" xref="S3.SS1.SSS2.p1.6.m6.1.1.3">id</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p1.6.m6.1c">\textbf{b}^{\text{id}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS2.p1.6.m6.1d">b start_POSTSUPERSCRIPT id end_POSTSUPERSCRIPT</annotation></semantics></math> serving as the editing mask, and the associated imagined novel concept <math alttext="\textbf{y}^{\text{novel}}" class="ltx_Math" display="inline" id="S3.SS1.SSS2.p1.7.m7.1"><semantics id="S3.SS1.SSS2.p1.7.m7.1a"><msup id="S3.SS1.SSS2.p1.7.m7.1.1" xref="S3.SS1.SSS2.p1.7.m7.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS1.SSS2.p1.7.m7.1.1.2" xref="S3.SS1.SSS2.p1.7.m7.1.1.2a.cmml">y</mtext><mtext id="S3.SS1.SSS2.p1.7.m7.1.1.3" xref="S3.SS1.SSS2.p1.7.m7.1.1.3a.cmml">novel</mtext></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p1.7.m7.1b"><apply id="S3.SS1.SSS2.p1.7.m7.1.1.cmml" xref="S3.SS1.SSS2.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p1.7.m7.1.1.1.cmml" xref="S3.SS1.SSS2.p1.7.m7.1.1">superscript</csymbol><ci id="S3.SS1.SSS2.p1.7.m7.1.1.2a.cmml" xref="S3.SS1.SSS2.p1.7.m7.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.SS1.SSS2.p1.7.m7.1.1.2.cmml" xref="S3.SS1.SSS2.p1.7.m7.1.1.2">y</mtext></ci><ci id="S3.SS1.SSS2.p1.7.m7.1.1.3a.cmml" xref="S3.SS1.SSS2.p1.7.m7.1.1.3"><mtext id="S3.SS1.SSS2.p1.7.m7.1.1.3.cmml" mathsize="70%" xref="S3.SS1.SSS2.p1.7.m7.1.1.3">novel</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p1.7.m7.1c">\textbf{y}^{\text{novel}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS2.p1.7.m7.1d">y start_POSTSUPERSCRIPT novel end_POSTSUPERSCRIPT</annotation></semantics></math> are provided as inputs to the <span class="ltx_text ltx_markedasmath" id="S3.SS1.SSS2.p1.9.1">SDI</span>, which is one of the most successful models for conditional image generation and editing. Thus, an edited image <math alttext="\textbf{x}^{\text{edit}}" class="ltx_Math" display="inline" id="S3.SS1.SSS2.p1.9.m9.1"><semantics id="S3.SS1.SSS2.p1.9.m9.1a"><msup id="S3.SS1.SSS2.p1.9.m9.1.1" xref="S3.SS1.SSS2.p1.9.m9.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS1.SSS2.p1.9.m9.1.1.2" xref="S3.SS1.SSS2.p1.9.m9.1.1.2a.cmml">x</mtext><mtext id="S3.SS1.SSS2.p1.9.m9.1.1.3" xref="S3.SS1.SSS2.p1.9.m9.1.1.3a.cmml">edit</mtext></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p1.9.m9.1b"><apply id="S3.SS1.SSS2.p1.9.m9.1.1.cmml" xref="S3.SS1.SSS2.p1.9.m9.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p1.9.m9.1.1.1.cmml" xref="S3.SS1.SSS2.p1.9.m9.1.1">superscript</csymbol><ci id="S3.SS1.SSS2.p1.9.m9.1.1.2a.cmml" xref="S3.SS1.SSS2.p1.9.m9.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.SS1.SSS2.p1.9.m9.1.1.2.cmml" xref="S3.SS1.SSS2.p1.9.m9.1.1.2">x</mtext></ci><ci id="S3.SS1.SSS2.p1.9.m9.1.1.3a.cmml" xref="S3.SS1.SSS2.p1.9.m9.1.1.3"><mtext id="S3.SS1.SSS2.p1.9.m9.1.1.3.cmml" mathsize="70%" xref="S3.SS1.SSS2.p1.9.m9.1.1.3">edit</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p1.9.m9.1c">\textbf{x}^{\text{edit}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS2.p1.9.m9.1d">x start_POSTSUPERSCRIPT edit end_POSTSUPERSCRIPT</annotation></semantics></math> containing a novel object is obtained as:</p>
</div>
<div class="ltx_para" id="S3.SS1.SSS2.p2">
<table class="ltx_equation ltx_eqn_table" id="S3.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\textbf{x}^{\text{edit}}=\text{SDI}(\textbf{x}^{\text{id}},\textbf{b}^{\text{%
id}},\textbf{y}^{\text{novel}})." class="ltx_Math" display="block" id="S3.E1.m1.1"><semantics id="S3.E1.m1.1a"><mrow id="S3.E1.m1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml"><mrow id="S3.E1.m1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml"><msup id="S3.E1.m1.1.1.1.1.5" xref="S3.E1.m1.1.1.1.1.5.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E1.m1.1.1.1.1.5.2" xref="S3.E1.m1.1.1.1.1.5.2a.cmml">x</mtext><mtext id="S3.E1.m1.1.1.1.1.5.3" xref="S3.E1.m1.1.1.1.1.5.3a.cmml">edit</mtext></msup><mo id="S3.E1.m1.1.1.1.1.4" xref="S3.E1.m1.1.1.1.1.4.cmml">=</mo><mrow id="S3.E1.m1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.3.cmml"><mtext id="S3.E1.m1.1.1.1.1.3.5" xref="S3.E1.m1.1.1.1.1.3.5a.cmml">SDI</mtext><mo id="S3.E1.m1.1.1.1.1.3.4" xref="S3.E1.m1.1.1.1.1.3.4.cmml">⁢</mo><mrow id="S3.E1.m1.1.1.1.1.3.3.3" xref="S3.E1.m1.1.1.1.1.3.3.4.cmml"><mo id="S3.E1.m1.1.1.1.1.3.3.3.4" stretchy="false" xref="S3.E1.m1.1.1.1.1.3.3.4.cmml">(</mo><msup id="S3.E1.m1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E1.m1.1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2a.cmml">x</mtext><mtext id="S3.E1.m1.1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.1.1.1.3a.cmml">id</mtext></msup><mo id="S3.E1.m1.1.1.1.1.3.3.3.5" xref="S3.E1.m1.1.1.1.1.3.3.4.cmml">,</mo><msup id="S3.E1.m1.1.1.1.1.2.2.2.2" xref="S3.E1.m1.1.1.1.1.2.2.2.2.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E1.m1.1.1.1.1.2.2.2.2.2" xref="S3.E1.m1.1.1.1.1.2.2.2.2.2a.cmml">b</mtext><mtext id="S3.E1.m1.1.1.1.1.2.2.2.2.3" xref="S3.E1.m1.1.1.1.1.2.2.2.2.3a.cmml">id</mtext></msup><mo id="S3.E1.m1.1.1.1.1.3.3.3.6" xref="S3.E1.m1.1.1.1.1.3.3.4.cmml">,</mo><msup id="S3.E1.m1.1.1.1.1.3.3.3.3" xref="S3.E1.m1.1.1.1.1.3.3.3.3.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E1.m1.1.1.1.1.3.3.3.3.2" xref="S3.E1.m1.1.1.1.1.3.3.3.3.2a.cmml">y</mtext><mtext id="S3.E1.m1.1.1.1.1.3.3.3.3.3" xref="S3.E1.m1.1.1.1.1.3.3.3.3.3a.cmml">novel</mtext></msup><mo id="S3.E1.m1.1.1.1.1.3.3.3.7" stretchy="false" xref="S3.E1.m1.1.1.1.1.3.3.4.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E1.m1.1.1.1.2" lspace="0em" xref="S3.E1.m1.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.1b"><apply id="S3.E1.m1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1"><eq id="S3.E1.m1.1.1.1.1.4.cmml" xref="S3.E1.m1.1.1.1.1.4"></eq><apply id="S3.E1.m1.1.1.1.1.5.cmml" xref="S3.E1.m1.1.1.1.1.5"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.5.1.cmml" xref="S3.E1.m1.1.1.1.1.5">superscript</csymbol><ci id="S3.E1.m1.1.1.1.1.5.2a.cmml" xref="S3.E1.m1.1.1.1.1.5.2"><mtext class="ltx_mathvariant_bold" id="S3.E1.m1.1.1.1.1.5.2.cmml" xref="S3.E1.m1.1.1.1.1.5.2">x</mtext></ci><ci id="S3.E1.m1.1.1.1.1.5.3a.cmml" xref="S3.E1.m1.1.1.1.1.5.3"><mtext id="S3.E1.m1.1.1.1.1.5.3.cmml" mathsize="70%" xref="S3.E1.m1.1.1.1.1.5.3">edit</mtext></ci></apply><apply id="S3.E1.m1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.3"><times id="S3.E1.m1.1.1.1.1.3.4.cmml" xref="S3.E1.m1.1.1.1.1.3.4"></times><ci id="S3.E1.m1.1.1.1.1.3.5a.cmml" xref="S3.E1.m1.1.1.1.1.3.5"><mtext id="S3.E1.m1.1.1.1.1.3.5.cmml" xref="S3.E1.m1.1.1.1.1.3.5">SDI</mtext></ci><vector id="S3.E1.m1.1.1.1.1.3.3.4.cmml" xref="S3.E1.m1.1.1.1.1.3.3.3"><apply id="S3.E1.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1">superscript</csymbol><ci id="S3.E1.m1.1.1.1.1.1.1.1.1.2a.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.E1.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2">x</mtext></ci><ci id="S3.E1.m1.1.1.1.1.1.1.1.1.3a.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.3"><mtext id="S3.E1.m1.1.1.1.1.1.1.1.1.3.cmml" mathsize="70%" xref="S3.E1.m1.1.1.1.1.1.1.1.1.3">id</mtext></ci></apply><apply id="S3.E1.m1.1.1.1.1.2.2.2.2.cmml" xref="S3.E1.m1.1.1.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.2.2.2.2.1.cmml" xref="S3.E1.m1.1.1.1.1.2.2.2.2">superscript</csymbol><ci id="S3.E1.m1.1.1.1.1.2.2.2.2.2a.cmml" xref="S3.E1.m1.1.1.1.1.2.2.2.2.2"><mtext class="ltx_mathvariant_bold" id="S3.E1.m1.1.1.1.1.2.2.2.2.2.cmml" xref="S3.E1.m1.1.1.1.1.2.2.2.2.2">b</mtext></ci><ci id="S3.E1.m1.1.1.1.1.2.2.2.2.3a.cmml" xref="S3.E1.m1.1.1.1.1.2.2.2.2.3"><mtext id="S3.E1.m1.1.1.1.1.2.2.2.2.3.cmml" mathsize="70%" xref="S3.E1.m1.1.1.1.1.2.2.2.2.3">id</mtext></ci></apply><apply id="S3.E1.m1.1.1.1.1.3.3.3.3.cmml" xref="S3.E1.m1.1.1.1.1.3.3.3.3"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.3.3.3.3.1.cmml" xref="S3.E1.m1.1.1.1.1.3.3.3.3">superscript</csymbol><ci id="S3.E1.m1.1.1.1.1.3.3.3.3.2a.cmml" xref="S3.E1.m1.1.1.1.1.3.3.3.3.2"><mtext class="ltx_mathvariant_bold" id="S3.E1.m1.1.1.1.1.3.3.3.3.2.cmml" xref="S3.E1.m1.1.1.1.1.3.3.3.3.2">y</mtext></ci><ci id="S3.E1.m1.1.1.1.1.3.3.3.3.3a.cmml" xref="S3.E1.m1.1.1.1.1.3.3.3.3.3"><mtext id="S3.E1.m1.1.1.1.1.3.3.3.3.3.cmml" mathsize="70%" xref="S3.E1.m1.1.1.1.1.3.3.3.3.3">novel</mtext></ci></apply></vector></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.1c">\textbf{x}^{\text{edit}}=\text{SDI}(\textbf{x}^{\text{id}},\textbf{b}^{\text{%
id}},\textbf{y}^{\text{novel}}).</annotation><annotation encoding="application/x-llamapun" id="S3.E1.m1.1d">x start_POSTSUPERSCRIPT edit end_POSTSUPERSCRIPT = SDI ( x start_POSTSUPERSCRIPT id end_POSTSUPERSCRIPT , b start_POSTSUPERSCRIPT id end_POSTSUPERSCRIPT , y start_POSTSUPERSCRIPT novel end_POSTSUPERSCRIPT ) .</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS1.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.3 </span>Refining Annotation Boxes of Novel Objects</h4>
<div class="ltx_para" id="S3.SS1.SSS3.p1">
<p class="ltx_p" id="S3.SS1.SSS3.p1.4">Due to the randomness in diffusion models, the attributes of edited objects, such as their quality, volume, and localization, may not match the original object box. To address this issue, as depicted in <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S3.F2" title="In 3.0.2 Overview ‣ 3 Method ‣ Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">2</span></a> (c), we design an efficient and effective refiner based on SAM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib30" title="">30</a>]</cite> to obtain refined accurate bounding boxes on novel objects.
First, for an edited image <math alttext="\textbf{x}^{\text{edit}}" class="ltx_Math" display="inline" id="S3.SS1.SSS3.p1.1.m1.1"><semantics id="S3.SS1.SSS3.p1.1.m1.1a"><msup id="S3.SS1.SSS3.p1.1.m1.1.1" xref="S3.SS1.SSS3.p1.1.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS1.SSS3.p1.1.m1.1.1.2" xref="S3.SS1.SSS3.p1.1.m1.1.1.2a.cmml">x</mtext><mtext id="S3.SS1.SSS3.p1.1.m1.1.1.3" xref="S3.SS1.SSS3.p1.1.m1.1.1.3a.cmml">edit</mtext></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS3.p1.1.m1.1b"><apply id="S3.SS1.SSS3.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS3.p1.1.m1.1.1.1.cmml" xref="S3.SS1.SSS3.p1.1.m1.1.1">superscript</csymbol><ci id="S3.SS1.SSS3.p1.1.m1.1.1.2a.cmml" xref="S3.SS1.SSS3.p1.1.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.SS1.SSS3.p1.1.m1.1.1.2.cmml" xref="S3.SS1.SSS3.p1.1.m1.1.1.2">x</mtext></ci><ci id="S3.SS1.SSS3.p1.1.m1.1.1.3a.cmml" xref="S3.SS1.SSS3.p1.1.m1.1.1.3"><mtext id="S3.SS1.SSS3.p1.1.m1.1.1.3.cmml" mathsize="70%" xref="S3.SS1.SSS3.p1.1.m1.1.1.3">edit</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS3.p1.1.m1.1c">\textbf{x}^{\text{edit}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS3.p1.1.m1.1d">x start_POSTSUPERSCRIPT edit end_POSTSUPERSCRIPT</annotation></semantics></math> with the editing mask <math alttext="\textbf{b}^{\text{id}}" class="ltx_Math" display="inline" id="S3.SS1.SSS3.p1.2.m2.1"><semantics id="S3.SS1.SSS3.p1.2.m2.1a"><msup id="S3.SS1.SSS3.p1.2.m2.1.1" xref="S3.SS1.SSS3.p1.2.m2.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS1.SSS3.p1.2.m2.1.1.2" xref="S3.SS1.SSS3.p1.2.m2.1.1.2a.cmml">b</mtext><mtext id="S3.SS1.SSS3.p1.2.m2.1.1.3" xref="S3.SS1.SSS3.p1.2.m2.1.1.3a.cmml">id</mtext></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS3.p1.2.m2.1b"><apply id="S3.SS1.SSS3.p1.2.m2.1.1.cmml" xref="S3.SS1.SSS3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS3.p1.2.m2.1.1.1.cmml" xref="S3.SS1.SSS3.p1.2.m2.1.1">superscript</csymbol><ci id="S3.SS1.SSS3.p1.2.m2.1.1.2a.cmml" xref="S3.SS1.SSS3.p1.2.m2.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.SS1.SSS3.p1.2.m2.1.1.2.cmml" xref="S3.SS1.SSS3.p1.2.m2.1.1.2">b</mtext></ci><ci id="S3.SS1.SSS3.p1.2.m2.1.1.3a.cmml" xref="S3.SS1.SSS3.p1.2.m2.1.1.3"><mtext id="S3.SS1.SSS3.p1.2.m2.1.1.3.cmml" mathsize="70%" xref="S3.SS1.SSS3.p1.2.m2.1.1.3">id</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS3.p1.2.m2.1c">\textbf{b}^{\text{id}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS3.p1.2.m2.1d">b start_POSTSUPERSCRIPT id end_POSTSUPERSCRIPT</annotation></semantics></math>, we use a padding area extended from <math alttext="\textbf{b}^{\text{id}}" class="ltx_Math" display="inline" id="S3.SS1.SSS3.p1.3.m3.1"><semantics id="S3.SS1.SSS3.p1.3.m3.1a"><msup id="S3.SS1.SSS3.p1.3.m3.1.1" xref="S3.SS1.SSS3.p1.3.m3.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS1.SSS3.p1.3.m3.1.1.2" xref="S3.SS1.SSS3.p1.3.m3.1.1.2a.cmml">b</mtext><mtext id="S3.SS1.SSS3.p1.3.m3.1.1.3" xref="S3.SS1.SSS3.p1.3.m3.1.1.3a.cmml">id</mtext></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS3.p1.3.m3.1b"><apply id="S3.SS1.SSS3.p1.3.m3.1.1.cmml" xref="S3.SS1.SSS3.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS3.p1.3.m3.1.1.1.cmml" xref="S3.SS1.SSS3.p1.3.m3.1.1">superscript</csymbol><ci id="S3.SS1.SSS3.p1.3.m3.1.1.2a.cmml" xref="S3.SS1.SSS3.p1.3.m3.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.SS1.SSS3.p1.3.m3.1.1.2.cmml" xref="S3.SS1.SSS3.p1.3.m3.1.1.2">b</mtext></ci><ci id="S3.SS1.SSS3.p1.3.m3.1.1.3a.cmml" xref="S3.SS1.SSS3.p1.3.m3.1.1.3"><mtext id="S3.SS1.SSS3.p1.3.m3.1.1.3.cmml" mathsize="70%" xref="S3.SS1.SSS3.p1.3.m3.1.1.3">id</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS3.p1.3.m3.1c">\textbf{b}^{\text{id}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS3.p1.3.m3.1d">b start_POSTSUPERSCRIPT id end_POSTSUPERSCRIPT</annotation></semantics></math> as the prompt and employ SAM to output the instance mask with highest confidence <math alttext="\textbf{m}^{\text{SAM}}" class="ltx_Math" display="inline" id="S3.SS1.SSS3.p1.4.m4.1"><semantics id="S3.SS1.SSS3.p1.4.m4.1a"><msup id="S3.SS1.SSS3.p1.4.m4.1.1" xref="S3.SS1.SSS3.p1.4.m4.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS1.SSS3.p1.4.m4.1.1.2" xref="S3.SS1.SSS3.p1.4.m4.1.1.2a.cmml">m</mtext><mtext id="S3.SS1.SSS3.p1.4.m4.1.1.3" xref="S3.SS1.SSS3.p1.4.m4.1.1.3a.cmml">SAM</mtext></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS3.p1.4.m4.1b"><apply id="S3.SS1.SSS3.p1.4.m4.1.1.cmml" xref="S3.SS1.SSS3.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS3.p1.4.m4.1.1.1.cmml" xref="S3.SS1.SSS3.p1.4.m4.1.1">superscript</csymbol><ci id="S3.SS1.SSS3.p1.4.m4.1.1.2a.cmml" xref="S3.SS1.SSS3.p1.4.m4.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.SS1.SSS3.p1.4.m4.1.1.2.cmml" xref="S3.SS1.SSS3.p1.4.m4.1.1.2">m</mtext></ci><ci id="S3.SS1.SSS3.p1.4.m4.1.1.3a.cmml" xref="S3.SS1.SSS3.p1.4.m4.1.1.3"><mtext id="S3.SS1.SSS3.p1.4.m4.1.1.3.cmml" mathsize="70%" xref="S3.SS1.SSS3.p1.4.m4.1.1.3">SAM</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS3.p1.4.m4.1c">\textbf{m}^{\text{SAM}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS3.p1.4.m4.1d">m start_POSTSUPERSCRIPT SAM end_POSTSUPERSCRIPT</annotation></semantics></math> for the novel object in the area:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\textbf{m}^{\text{SAM}}=\text{SAM}(\textbf{x}^{\text{edit}};\text{padding}(%
\textbf{b}^{\text{id}},e))," class="ltx_Math" display="block" id="S3.E2.m1.2"><semantics id="S3.E2.m1.2a"><mrow id="S3.E2.m1.2.2.1" xref="S3.E2.m1.2.2.1.1.cmml"><mrow id="S3.E2.m1.2.2.1.1" xref="S3.E2.m1.2.2.1.1.cmml"><msup id="S3.E2.m1.2.2.1.1.4" xref="S3.E2.m1.2.2.1.1.4.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E2.m1.2.2.1.1.4.2" xref="S3.E2.m1.2.2.1.1.4.2a.cmml">m</mtext><mtext id="S3.E2.m1.2.2.1.1.4.3" xref="S3.E2.m1.2.2.1.1.4.3a.cmml">SAM</mtext></msup><mo id="S3.E2.m1.2.2.1.1.3" xref="S3.E2.m1.2.2.1.1.3.cmml">=</mo><mrow id="S3.E2.m1.2.2.1.1.2" xref="S3.E2.m1.2.2.1.1.2.cmml"><mtext id="S3.E2.m1.2.2.1.1.2.4" xref="S3.E2.m1.2.2.1.1.2.4a.cmml">SAM</mtext><mo id="S3.E2.m1.2.2.1.1.2.3" xref="S3.E2.m1.2.2.1.1.2.3.cmml">⁢</mo><mrow id="S3.E2.m1.2.2.1.1.2.2.2" xref="S3.E2.m1.2.2.1.1.2.2.3.cmml"><mo id="S3.E2.m1.2.2.1.1.2.2.2.3" stretchy="false" xref="S3.E2.m1.2.2.1.1.2.2.3.cmml">(</mo><msup id="S3.E2.m1.2.2.1.1.1.1.1.1" xref="S3.E2.m1.2.2.1.1.1.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E2.m1.2.2.1.1.1.1.1.1.2" xref="S3.E2.m1.2.2.1.1.1.1.1.1.2a.cmml">x</mtext><mtext id="S3.E2.m1.2.2.1.1.1.1.1.1.3" xref="S3.E2.m1.2.2.1.1.1.1.1.1.3a.cmml">edit</mtext></msup><mo id="S3.E2.m1.2.2.1.1.2.2.2.4" xref="S3.E2.m1.2.2.1.1.2.2.3.cmml">;</mo><mrow id="S3.E2.m1.2.2.1.1.2.2.2.2" xref="S3.E2.m1.2.2.1.1.2.2.2.2.cmml"><mtext id="S3.E2.m1.2.2.1.1.2.2.2.2.3" xref="S3.E2.m1.2.2.1.1.2.2.2.2.3a.cmml">padding</mtext><mo id="S3.E2.m1.2.2.1.1.2.2.2.2.2" xref="S3.E2.m1.2.2.1.1.2.2.2.2.2.cmml">⁢</mo><mrow id="S3.E2.m1.2.2.1.1.2.2.2.2.1.1" xref="S3.E2.m1.2.2.1.1.2.2.2.2.1.2.cmml"><mo id="S3.E2.m1.2.2.1.1.2.2.2.2.1.1.2" stretchy="false" xref="S3.E2.m1.2.2.1.1.2.2.2.2.1.2.cmml">(</mo><msup id="S3.E2.m1.2.2.1.1.2.2.2.2.1.1.1" xref="S3.E2.m1.2.2.1.1.2.2.2.2.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E2.m1.2.2.1.1.2.2.2.2.1.1.1.2" xref="S3.E2.m1.2.2.1.1.2.2.2.2.1.1.1.2a.cmml">b</mtext><mtext id="S3.E2.m1.2.2.1.1.2.2.2.2.1.1.1.3" xref="S3.E2.m1.2.2.1.1.2.2.2.2.1.1.1.3a.cmml">id</mtext></msup><mo id="S3.E2.m1.2.2.1.1.2.2.2.2.1.1.3" xref="S3.E2.m1.2.2.1.1.2.2.2.2.1.2.cmml">,</mo><mi id="S3.E2.m1.1.1" xref="S3.E2.m1.1.1.cmml">e</mi><mo id="S3.E2.m1.2.2.1.1.2.2.2.2.1.1.4" stretchy="false" xref="S3.E2.m1.2.2.1.1.2.2.2.2.1.2.cmml">)</mo></mrow></mrow><mo id="S3.E2.m1.2.2.1.1.2.2.2.5" stretchy="false" xref="S3.E2.m1.2.2.1.1.2.2.3.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E2.m1.2.2.1.2" xref="S3.E2.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.2b"><apply id="S3.E2.m1.2.2.1.1.cmml" xref="S3.E2.m1.2.2.1"><eq id="S3.E2.m1.2.2.1.1.3.cmml" xref="S3.E2.m1.2.2.1.1.3"></eq><apply id="S3.E2.m1.2.2.1.1.4.cmml" xref="S3.E2.m1.2.2.1.1.4"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.4.1.cmml" xref="S3.E2.m1.2.2.1.1.4">superscript</csymbol><ci id="S3.E2.m1.2.2.1.1.4.2a.cmml" xref="S3.E2.m1.2.2.1.1.4.2"><mtext class="ltx_mathvariant_bold" id="S3.E2.m1.2.2.1.1.4.2.cmml" xref="S3.E2.m1.2.2.1.1.4.2">m</mtext></ci><ci id="S3.E2.m1.2.2.1.1.4.3a.cmml" xref="S3.E2.m1.2.2.1.1.4.3"><mtext id="S3.E2.m1.2.2.1.1.4.3.cmml" mathsize="70%" xref="S3.E2.m1.2.2.1.1.4.3">SAM</mtext></ci></apply><apply id="S3.E2.m1.2.2.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.2"><times id="S3.E2.m1.2.2.1.1.2.3.cmml" xref="S3.E2.m1.2.2.1.1.2.3"></times><ci id="S3.E2.m1.2.2.1.1.2.4a.cmml" xref="S3.E2.m1.2.2.1.1.2.4"><mtext id="S3.E2.m1.2.2.1.1.2.4.cmml" xref="S3.E2.m1.2.2.1.1.2.4">SAM</mtext></ci><list id="S3.E2.m1.2.2.1.1.2.2.3.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2"><apply id="S3.E2.m1.2.2.1.1.1.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1">superscript</csymbol><ci id="S3.E2.m1.2.2.1.1.1.1.1.1.2a.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.E2.m1.2.2.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.2">x</mtext></ci><ci id="S3.E2.m1.2.2.1.1.1.1.1.1.3a.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.3"><mtext id="S3.E2.m1.2.2.1.1.1.1.1.1.3.cmml" mathsize="70%" xref="S3.E2.m1.2.2.1.1.1.1.1.1.3">edit</mtext></ci></apply><apply id="S3.E2.m1.2.2.1.1.2.2.2.2.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.2"><times id="S3.E2.m1.2.2.1.1.2.2.2.2.2.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.2.2"></times><ci id="S3.E2.m1.2.2.1.1.2.2.2.2.3a.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.2.3"><mtext id="S3.E2.m1.2.2.1.1.2.2.2.2.3.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.2.3">padding</mtext></ci><interval closure="open" id="S3.E2.m1.2.2.1.1.2.2.2.2.1.2.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.2.1.1"><apply id="S3.E2.m1.2.2.1.1.2.2.2.2.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.2.2.2.2.1.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.2.1.1.1">superscript</csymbol><ci id="S3.E2.m1.2.2.1.1.2.2.2.2.1.1.1.2a.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.2.1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.E2.m1.2.2.1.1.2.2.2.2.1.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.2.1.1.1.2">b</mtext></ci><ci id="S3.E2.m1.2.2.1.1.2.2.2.2.1.1.1.3a.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.2.1.1.1.3"><mtext id="S3.E2.m1.2.2.1.1.2.2.2.2.1.1.1.3.cmml" mathsize="70%" xref="S3.E2.m1.2.2.1.1.2.2.2.2.1.1.1.3">id</mtext></ci></apply><ci id="S3.E2.m1.1.1.cmml" xref="S3.E2.m1.1.1">𝑒</ci></interval></apply></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.2c">\textbf{m}^{\text{SAM}}=\text{SAM}(\textbf{x}^{\text{edit}};\text{padding}(%
\textbf{b}^{\text{id}},e)),</annotation><annotation encoding="application/x-llamapun" id="S3.E2.m1.2d">m start_POSTSUPERSCRIPT SAM end_POSTSUPERSCRIPT = SAM ( x start_POSTSUPERSCRIPT edit end_POSTSUPERSCRIPT ; padding ( b start_POSTSUPERSCRIPT id end_POSTSUPERSCRIPT , italic_e ) ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS1.SSS3.p1.9">where <math alttext="e" class="ltx_Math" display="inline" id="S3.SS1.SSS3.p1.5.m1.1"><semantics id="S3.SS1.SSS3.p1.5.m1.1a"><mi id="S3.SS1.SSS3.p1.5.m1.1.1" xref="S3.SS1.SSS3.p1.5.m1.1.1.cmml">e</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS3.p1.5.m1.1b"><ci id="S3.SS1.SSS3.p1.5.m1.1.1.cmml" xref="S3.SS1.SSS3.p1.5.m1.1.1">𝑒</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS3.p1.5.m1.1c">e</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS3.p1.5.m1.1d">italic_e</annotation></semantics></math> represents the range of padding. Then, we convert obtained masks <math alttext="\textbf{m}^{\text{SAM}}" class="ltx_Math" display="inline" id="S3.SS1.SSS3.p1.6.m2.1"><semantics id="S3.SS1.SSS3.p1.6.m2.1a"><msup id="S3.SS1.SSS3.p1.6.m2.1.1" xref="S3.SS1.SSS3.p1.6.m2.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS1.SSS3.p1.6.m2.1.1.2" xref="S3.SS1.SSS3.p1.6.m2.1.1.2a.cmml">m</mtext><mtext id="S3.SS1.SSS3.p1.6.m2.1.1.3" xref="S3.SS1.SSS3.p1.6.m2.1.1.3a.cmml">SAM</mtext></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS3.p1.6.m2.1b"><apply id="S3.SS1.SSS3.p1.6.m2.1.1.cmml" xref="S3.SS1.SSS3.p1.6.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS3.p1.6.m2.1.1.1.cmml" xref="S3.SS1.SSS3.p1.6.m2.1.1">superscript</csymbol><ci id="S3.SS1.SSS3.p1.6.m2.1.1.2a.cmml" xref="S3.SS1.SSS3.p1.6.m2.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.SS1.SSS3.p1.6.m2.1.1.2.cmml" xref="S3.SS1.SSS3.p1.6.m2.1.1.2">m</mtext></ci><ci id="S3.SS1.SSS3.p1.6.m2.1.1.3a.cmml" xref="S3.SS1.SSS3.p1.6.m2.1.1.3"><mtext id="S3.SS1.SSS3.p1.6.m2.1.1.3.cmml" mathsize="70%" xref="S3.SS1.SSS3.p1.6.m2.1.1.3">SAM</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS3.p1.6.m2.1c">\textbf{m}^{\text{SAM}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS3.p1.6.m2.1d">m start_POSTSUPERSCRIPT SAM end_POSTSUPERSCRIPT</annotation></semantics></math> to boxes <math alttext="\textbf{b}^{\text{SAM}}" class="ltx_Math" display="inline" id="S3.SS1.SSS3.p1.7.m3.1"><semantics id="S3.SS1.SSS3.p1.7.m3.1a"><msup id="S3.SS1.SSS3.p1.7.m3.1.1" xref="S3.SS1.SSS3.p1.7.m3.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS1.SSS3.p1.7.m3.1.1.2" xref="S3.SS1.SSS3.p1.7.m3.1.1.2a.cmml">b</mtext><mtext id="S3.SS1.SSS3.p1.7.m3.1.1.3" xref="S3.SS1.SSS3.p1.7.m3.1.1.3a.cmml">SAM</mtext></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS3.p1.7.m3.1b"><apply id="S3.SS1.SSS3.p1.7.m3.1.1.cmml" xref="S3.SS1.SSS3.p1.7.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS3.p1.7.m3.1.1.1.cmml" xref="S3.SS1.SSS3.p1.7.m3.1.1">superscript</csymbol><ci id="S3.SS1.SSS3.p1.7.m3.1.1.2a.cmml" xref="S3.SS1.SSS3.p1.7.m3.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.SS1.SSS3.p1.7.m3.1.1.2.cmml" xref="S3.SS1.SSS3.p1.7.m3.1.1.2">b</mtext></ci><ci id="S3.SS1.SSS3.p1.7.m3.1.1.3a.cmml" xref="S3.SS1.SSS3.p1.7.m3.1.1.3"><mtext id="S3.SS1.SSS3.p1.7.m3.1.1.3.cmml" mathsize="70%" xref="S3.SS1.SSS3.p1.7.m3.1.1.3">SAM</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS3.p1.7.m3.1c">\textbf{b}^{\text{SAM}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS3.p1.7.m3.1d">b start_POSTSUPERSCRIPT SAM end_POSTSUPERSCRIPT</annotation></semantics></math>, and calculate IoU between <math alttext="\textbf{b}^{\text{SAM}}" class="ltx_Math" display="inline" id="S3.SS1.SSS3.p1.8.m4.1"><semantics id="S3.SS1.SSS3.p1.8.m4.1a"><msup id="S3.SS1.SSS3.p1.8.m4.1.1" xref="S3.SS1.SSS3.p1.8.m4.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS1.SSS3.p1.8.m4.1.1.2" xref="S3.SS1.SSS3.p1.8.m4.1.1.2a.cmml">b</mtext><mtext id="S3.SS1.SSS3.p1.8.m4.1.1.3" xref="S3.SS1.SSS3.p1.8.m4.1.1.3a.cmml">SAM</mtext></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS3.p1.8.m4.1b"><apply id="S3.SS1.SSS3.p1.8.m4.1.1.cmml" xref="S3.SS1.SSS3.p1.8.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS3.p1.8.m4.1.1.1.cmml" xref="S3.SS1.SSS3.p1.8.m4.1.1">superscript</csymbol><ci id="S3.SS1.SSS3.p1.8.m4.1.1.2a.cmml" xref="S3.SS1.SSS3.p1.8.m4.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.SS1.SSS3.p1.8.m4.1.1.2.cmml" xref="S3.SS1.SSS3.p1.8.m4.1.1.2">b</mtext></ci><ci id="S3.SS1.SSS3.p1.8.m4.1.1.3a.cmml" xref="S3.SS1.SSS3.p1.8.m4.1.1.3"><mtext id="S3.SS1.SSS3.p1.8.m4.1.1.3.cmml" mathsize="70%" xref="S3.SS1.SSS3.p1.8.m4.1.1.3">SAM</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS3.p1.8.m4.1c">\textbf{b}^{\text{SAM}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS3.p1.8.m4.1d">b start_POSTSUPERSCRIPT SAM end_POSTSUPERSCRIPT</annotation></semantics></math> and the corresponding <math alttext="\textbf{b}^{\text{id}}" class="ltx_Math" display="inline" id="S3.SS1.SSS3.p1.9.m5.1"><semantics id="S3.SS1.SSS3.p1.9.m5.1a"><msup id="S3.SS1.SSS3.p1.9.m5.1.1" xref="S3.SS1.SSS3.p1.9.m5.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS1.SSS3.p1.9.m5.1.1.2" xref="S3.SS1.SSS3.p1.9.m5.1.1.2a.cmml">b</mtext><mtext id="S3.SS1.SSS3.p1.9.m5.1.1.3" xref="S3.SS1.SSS3.p1.9.m5.1.1.3a.cmml">id</mtext></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS3.p1.9.m5.1b"><apply id="S3.SS1.SSS3.p1.9.m5.1.1.cmml" xref="S3.SS1.SSS3.p1.9.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS3.p1.9.m5.1.1.1.cmml" xref="S3.SS1.SSS3.p1.9.m5.1.1">superscript</csymbol><ci id="S3.SS1.SSS3.p1.9.m5.1.1.2a.cmml" xref="S3.SS1.SSS3.p1.9.m5.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.SS1.SSS3.p1.9.m5.1.1.2.cmml" xref="S3.SS1.SSS3.p1.9.m5.1.1.2">b</mtext></ci><ci id="S3.SS1.SSS3.p1.9.m5.1.1.3a.cmml" xref="S3.SS1.SSS3.p1.9.m5.1.1.3"><mtext id="S3.SS1.SSS3.p1.9.m5.1.1.3.cmml" mathsize="70%" xref="S3.SS1.SSS3.p1.9.m5.1.1.3">id</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS3.p1.9.m5.1c">\textbf{b}^{\text{id}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS3.p1.9.m5.1d">b start_POSTSUPERSCRIPT id end_POSTSUPERSCRIPT</annotation></semantics></math> to filter out novel objects that vary highly in scale:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\left\{\textbf{b}^{\text{edit}}\right\}=\left\{\left.\textbf{b}^{\text{SAM}}%
\middle|\right.\text{IoU}(\textbf{b}^{\text{SAM}},\textbf{b}^{\text{id}})&gt;%
\gamma\right\}," class="ltx_Math" display="block" id="S3.E3.m1.1"><semantics id="S3.E3.m1.1a"><mrow id="S3.E3.m1.1.1.1" xref="S3.E3.m1.1.1.1.1.cmml"><mrow id="S3.E3.m1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.cmml"><mrow id="S3.E3.m1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.2.cmml"><mo id="S3.E3.m1.1.1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.1.2.cmml">{</mo><msup id="S3.E3.m1.1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E3.m1.1.1.1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.1.1.1.2a.cmml">b</mtext><mtext id="S3.E3.m1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.1.1.3a.cmml">edit</mtext></msup><mo id="S3.E3.m1.1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.2.cmml">}</mo></mrow><mo id="S3.E3.m1.1.1.1.1.4" xref="S3.E3.m1.1.1.1.1.4.cmml">=</mo><mrow id="S3.E3.m1.1.1.1.1.3.2" xref="S3.E3.m1.1.1.1.1.3.3.cmml"><mo id="S3.E3.m1.1.1.1.1.3.2.3" xref="S3.E3.m1.1.1.1.1.3.3.1.cmml">{</mo><msup id="S3.E3.m1.1.1.1.1.2.1.1" xref="S3.E3.m1.1.1.1.1.2.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E3.m1.1.1.1.1.2.1.1.2" xref="S3.E3.m1.1.1.1.1.2.1.1.2a.cmml">b</mtext><mtext id="S3.E3.m1.1.1.1.1.2.1.1.3" xref="S3.E3.m1.1.1.1.1.2.1.1.3a.cmml">SAM</mtext></msup><mo id="S3.E3.m1.1.1.1.1.3.2.4" lspace="0em" rspace="0em" stretchy="true" xref="S3.E3.m1.1.1.1.1.3.3.1.cmml">|</mo><mrow id="S3.E3.m1.1.1.1.1.3.2.2" xref="S3.E3.m1.1.1.1.1.3.2.2.cmml"><mrow id="S3.E3.m1.1.1.1.1.3.2.2.2" xref="S3.E3.m1.1.1.1.1.3.2.2.2.cmml"><mtext id="S3.E3.m1.1.1.1.1.3.2.2.2.4" xref="S3.E3.m1.1.1.1.1.3.2.2.2.4a.cmml">IoU</mtext><mo id="S3.E3.m1.1.1.1.1.3.2.2.2.3" xref="S3.E3.m1.1.1.1.1.3.2.2.2.3.cmml">⁢</mo><mrow id="S3.E3.m1.1.1.1.1.3.2.2.2.2.2" xref="S3.E3.m1.1.1.1.1.3.2.2.2.2.3.cmml"><mo id="S3.E3.m1.1.1.1.1.3.2.2.2.2.2.3" stretchy="false" xref="S3.E3.m1.1.1.1.1.3.2.2.2.2.3.cmml">(</mo><msup id="S3.E3.m1.1.1.1.1.3.2.2.1.1.1.1" xref="S3.E3.m1.1.1.1.1.3.2.2.1.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E3.m1.1.1.1.1.3.2.2.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.3.2.2.1.1.1.1.2a.cmml">b</mtext><mtext id="S3.E3.m1.1.1.1.1.3.2.2.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.3.2.2.1.1.1.1.3a.cmml">SAM</mtext></msup><mo id="S3.E3.m1.1.1.1.1.3.2.2.2.2.2.4" xref="S3.E3.m1.1.1.1.1.3.2.2.2.2.3.cmml">,</mo><msup id="S3.E3.m1.1.1.1.1.3.2.2.2.2.2.2" xref="S3.E3.m1.1.1.1.1.3.2.2.2.2.2.2.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E3.m1.1.1.1.1.3.2.2.2.2.2.2.2" xref="S3.E3.m1.1.1.1.1.3.2.2.2.2.2.2.2a.cmml">b</mtext><mtext id="S3.E3.m1.1.1.1.1.3.2.2.2.2.2.2.3" xref="S3.E3.m1.1.1.1.1.3.2.2.2.2.2.2.3a.cmml">id</mtext></msup><mo id="S3.E3.m1.1.1.1.1.3.2.2.2.2.2.5" stretchy="false" xref="S3.E3.m1.1.1.1.1.3.2.2.2.2.3.cmml">)</mo></mrow></mrow><mo id="S3.E3.m1.1.1.1.1.3.2.2.3" xref="S3.E3.m1.1.1.1.1.3.2.2.3.cmml">&gt;</mo><mi id="S3.E3.m1.1.1.1.1.3.2.2.4" xref="S3.E3.m1.1.1.1.1.3.2.2.4.cmml">γ</mi></mrow><mo id="S3.E3.m1.1.1.1.1.3.2.5" xref="S3.E3.m1.1.1.1.1.3.3.1.cmml">}</mo></mrow></mrow><mo id="S3.E3.m1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.1b"><apply id="S3.E3.m1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1"><eq id="S3.E3.m1.1.1.1.1.4.cmml" xref="S3.E3.m1.1.1.1.1.4"></eq><set id="S3.E3.m1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1"><apply id="S3.E3.m1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1">superscript</csymbol><ci id="S3.E3.m1.1.1.1.1.1.1.1.2a.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.E3.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.2">b</mtext></ci><ci id="S3.E3.m1.1.1.1.1.1.1.1.3a.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.3"><mtext id="S3.E3.m1.1.1.1.1.1.1.1.3.cmml" mathsize="70%" xref="S3.E3.m1.1.1.1.1.1.1.1.3">edit</mtext></ci></apply></set><apply id="S3.E3.m1.1.1.1.1.3.3.cmml" xref="S3.E3.m1.1.1.1.1.3.2"><csymbol cd="latexml" id="S3.E3.m1.1.1.1.1.3.3.1.cmml" xref="S3.E3.m1.1.1.1.1.3.2.3">conditional-set</csymbol><apply id="S3.E3.m1.1.1.1.1.2.1.1.cmml" xref="S3.E3.m1.1.1.1.1.2.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.2.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.2.1.1">superscript</csymbol><ci id="S3.E3.m1.1.1.1.1.2.1.1.2a.cmml" xref="S3.E3.m1.1.1.1.1.2.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.E3.m1.1.1.1.1.2.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.2.1.1.2">b</mtext></ci><ci id="S3.E3.m1.1.1.1.1.2.1.1.3a.cmml" xref="S3.E3.m1.1.1.1.1.2.1.1.3"><mtext id="S3.E3.m1.1.1.1.1.2.1.1.3.cmml" mathsize="70%" xref="S3.E3.m1.1.1.1.1.2.1.1.3">SAM</mtext></ci></apply><apply id="S3.E3.m1.1.1.1.1.3.2.2.cmml" xref="S3.E3.m1.1.1.1.1.3.2.2"><gt id="S3.E3.m1.1.1.1.1.3.2.2.3.cmml" xref="S3.E3.m1.1.1.1.1.3.2.2.3"></gt><apply id="S3.E3.m1.1.1.1.1.3.2.2.2.cmml" xref="S3.E3.m1.1.1.1.1.3.2.2.2"><times id="S3.E3.m1.1.1.1.1.3.2.2.2.3.cmml" xref="S3.E3.m1.1.1.1.1.3.2.2.2.3"></times><ci id="S3.E3.m1.1.1.1.1.3.2.2.2.4a.cmml" xref="S3.E3.m1.1.1.1.1.3.2.2.2.4"><mtext id="S3.E3.m1.1.1.1.1.3.2.2.2.4.cmml" xref="S3.E3.m1.1.1.1.1.3.2.2.2.4">IoU</mtext></ci><interval closure="open" id="S3.E3.m1.1.1.1.1.3.2.2.2.2.3.cmml" xref="S3.E3.m1.1.1.1.1.3.2.2.2.2.2"><apply id="S3.E3.m1.1.1.1.1.3.2.2.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.3.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.3.2.2.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.3.2.2.1.1.1.1">superscript</csymbol><ci id="S3.E3.m1.1.1.1.1.3.2.2.1.1.1.1.2a.cmml" xref="S3.E3.m1.1.1.1.1.3.2.2.1.1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.E3.m1.1.1.1.1.3.2.2.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.3.2.2.1.1.1.1.2">b</mtext></ci><ci id="S3.E3.m1.1.1.1.1.3.2.2.1.1.1.1.3a.cmml" xref="S3.E3.m1.1.1.1.1.3.2.2.1.1.1.1.3"><mtext id="S3.E3.m1.1.1.1.1.3.2.2.1.1.1.1.3.cmml" mathsize="70%" xref="S3.E3.m1.1.1.1.1.3.2.2.1.1.1.1.3">SAM</mtext></ci></apply><apply id="S3.E3.m1.1.1.1.1.3.2.2.2.2.2.2.cmml" xref="S3.E3.m1.1.1.1.1.3.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.3.2.2.2.2.2.2.1.cmml" xref="S3.E3.m1.1.1.1.1.3.2.2.2.2.2.2">superscript</csymbol><ci id="S3.E3.m1.1.1.1.1.3.2.2.2.2.2.2.2a.cmml" xref="S3.E3.m1.1.1.1.1.3.2.2.2.2.2.2.2"><mtext class="ltx_mathvariant_bold" id="S3.E3.m1.1.1.1.1.3.2.2.2.2.2.2.2.cmml" xref="S3.E3.m1.1.1.1.1.3.2.2.2.2.2.2.2">b</mtext></ci><ci id="S3.E3.m1.1.1.1.1.3.2.2.2.2.2.2.3a.cmml" xref="S3.E3.m1.1.1.1.1.3.2.2.2.2.2.2.3"><mtext id="S3.E3.m1.1.1.1.1.3.2.2.2.2.2.2.3.cmml" mathsize="70%" xref="S3.E3.m1.1.1.1.1.3.2.2.2.2.2.2.3">id</mtext></ci></apply></interval></apply><ci id="S3.E3.m1.1.1.1.1.3.2.2.4.cmml" xref="S3.E3.m1.1.1.1.1.3.2.2.4">𝛾</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.1c">\left\{\textbf{b}^{\text{edit}}\right\}=\left\{\left.\textbf{b}^{\text{SAM}}%
\middle|\right.\text{IoU}(\textbf{b}^{\text{SAM}},\textbf{b}^{\text{id}})&gt;%
\gamma\right\},</annotation><annotation encoding="application/x-llamapun" id="S3.E3.m1.1d">{ b start_POSTSUPERSCRIPT edit end_POSTSUPERSCRIPT } = { b start_POSTSUPERSCRIPT SAM end_POSTSUPERSCRIPT | IoU ( b start_POSTSUPERSCRIPT SAM end_POSTSUPERSCRIPT , b start_POSTSUPERSCRIPT id end_POSTSUPERSCRIPT ) &gt; italic_γ } ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS1.SSS3.p1.11">where <math alttext="\gamma" class="ltx_Math" display="inline" id="S3.SS1.SSS3.p1.10.m1.1"><semantics id="S3.SS1.SSS3.p1.10.m1.1a"><mi id="S3.SS1.SSS3.p1.10.m1.1.1" xref="S3.SS1.SSS3.p1.10.m1.1.1.cmml">γ</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS3.p1.10.m1.1b"><ci id="S3.SS1.SSS3.p1.10.m1.1.1.cmml" xref="S3.SS1.SSS3.p1.10.m1.1.1">𝛾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS3.p1.10.m1.1c">\gamma</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS3.p1.10.m1.1d">italic_γ</annotation></semantics></math> denotes a threshold value on IoU. It ensures a high enough recall rate to rule out the instability of Stable Diffusion and SAM and uncontrollable localization of the edited objects. Thus we obtain the synthetic outlier data <math alttext="\mathcal{D}_{\text{edit}}" class="ltx_Math" display="inline" id="S3.SS1.SSS3.p1.11.m2.1"><semantics id="S3.SS1.SSS3.p1.11.m2.1a"><msub id="S3.SS1.SSS3.p1.11.m2.1.1" xref="S3.SS1.SSS3.p1.11.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.SSS3.p1.11.m2.1.1.2" xref="S3.SS1.SSS3.p1.11.m2.1.1.2.cmml">𝒟</mi><mtext id="S3.SS1.SSS3.p1.11.m2.1.1.3" xref="S3.SS1.SSS3.p1.11.m2.1.1.3a.cmml">edit</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS3.p1.11.m2.1b"><apply id="S3.SS1.SSS3.p1.11.m2.1.1.cmml" xref="S3.SS1.SSS3.p1.11.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS3.p1.11.m2.1.1.1.cmml" xref="S3.SS1.SSS3.p1.11.m2.1.1">subscript</csymbol><ci id="S3.SS1.SSS3.p1.11.m2.1.1.2.cmml" xref="S3.SS1.SSS3.p1.11.m2.1.1.2">𝒟</ci><ci id="S3.SS1.SSS3.p1.11.m2.1.1.3a.cmml" xref="S3.SS1.SSS3.p1.11.m2.1.1.3"><mtext id="S3.SS1.SSS3.p1.11.m2.1.1.3.cmml" mathsize="70%" xref="S3.SS1.SSS3.p1.11.m2.1.1.3">edit</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS3.p1.11.m2.1c">\mathcal{D}_{\text{edit}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS3.p1.11.m2.1d">caligraphic_D start_POSTSUBSCRIPT edit end_POSTSUBSCRIPT</annotation></semantics></math> as illustrated in <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S1.F1" title="In 1 Introduction ‣ Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Mining Hard OOD Samples and Model Training</h3>
<section class="ltx_subsubsection" id="S3.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.1 </span>Mining Hard OOD Objects with High Visual Similarities for Training</h4>
<div class="ltx_para" id="S3.SS2.SSS1.p1">
<p class="ltx_p" id="S3.SS2.SSS1.p1.6">We consider the novel objects that are most likely to be confused with the corresponding ID objects by the object detector as the most effective ones. We thus aim to find synthetic OOD samples that are most easily confused as ID to participate in training based on pairwise similarity in the latent space of the pre-trained object detector. For each novel object with bounding box <math alttext="\textbf{b}^{\text{edit}}" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p1.1.m1.1"><semantics id="S3.SS2.SSS1.p1.1.m1.1a"><msup id="S3.SS2.SSS1.p1.1.m1.1.1" xref="S3.SS2.SSS1.p1.1.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS2.SSS1.p1.1.m1.1.1.2" xref="S3.SS2.SSS1.p1.1.m1.1.1.2a.cmml">b</mtext><mtext id="S3.SS2.SSS1.p1.1.m1.1.1.3" xref="S3.SS2.SSS1.p1.1.m1.1.1.3a.cmml">edit</mtext></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p1.1.m1.1b"><apply id="S3.SS2.SSS1.p1.1.m1.1.1.cmml" xref="S3.SS2.SSS1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p1.1.m1.1.1.1.cmml" xref="S3.SS2.SSS1.p1.1.m1.1.1">superscript</csymbol><ci id="S3.SS2.SSS1.p1.1.m1.1.1.2a.cmml" xref="S3.SS2.SSS1.p1.1.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.SS2.SSS1.p1.1.m1.1.1.2.cmml" xref="S3.SS2.SSS1.p1.1.m1.1.1.2">b</mtext></ci><ci id="S3.SS2.SSS1.p1.1.m1.1.1.3a.cmml" xref="S3.SS2.SSS1.p1.1.m1.1.1.3"><mtext id="S3.SS2.SSS1.p1.1.m1.1.1.3.cmml" mathsize="70%" xref="S3.SS2.SSS1.p1.1.m1.1.1.3">edit</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p1.1.m1.1c">\textbf{b}^{\text{edit}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p1.1.m1.1d">b start_POSTSUPERSCRIPT edit end_POSTSUPERSCRIPT</annotation></semantics></math> in the synthetic data <math alttext="\mathcal{D}_{\text{edit}}" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p1.2.m2.1"><semantics id="S3.SS2.SSS1.p1.2.m2.1a"><msub id="S3.SS2.SSS1.p1.2.m2.1.1" xref="S3.SS2.SSS1.p1.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.SSS1.p1.2.m2.1.1.2" xref="S3.SS2.SSS1.p1.2.m2.1.1.2.cmml">𝒟</mi><mtext id="S3.SS2.SSS1.p1.2.m2.1.1.3" xref="S3.SS2.SSS1.p1.2.m2.1.1.3a.cmml">edit</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p1.2.m2.1b"><apply id="S3.SS2.SSS1.p1.2.m2.1.1.cmml" xref="S3.SS2.SSS1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p1.2.m2.1.1.1.cmml" xref="S3.SS2.SSS1.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.SSS1.p1.2.m2.1.1.2.cmml" xref="S3.SS2.SSS1.p1.2.m2.1.1.2">𝒟</ci><ci id="S3.SS2.SSS1.p1.2.m2.1.1.3a.cmml" xref="S3.SS2.SSS1.p1.2.m2.1.1.3"><mtext id="S3.SS2.SSS1.p1.2.m2.1.1.3.cmml" mathsize="70%" xref="S3.SS2.SSS1.p1.2.m2.1.1.3">edit</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p1.2.m2.1c">\mathcal{D}_{\text{edit}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p1.2.m2.1d">caligraphic_D start_POSTSUBSCRIPT edit end_POSTSUBSCRIPT</annotation></semantics></math>, we construct it with the corresponding original ID object with its bounding box as a pair: <math alttext="\left\{(\textbf{b}^{\text{edit}},\textbf{x}^{\text{edit}}),(\textbf{b}^{\text{%
id}},\textbf{x}^{\text{id}})\right\}" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p1.3.m3.2"><semantics id="S3.SS2.SSS1.p1.3.m3.2a"><mrow id="S3.SS2.SSS1.p1.3.m3.2.2.2" xref="S3.SS2.SSS1.p1.3.m3.2.2.3.cmml"><mo id="S3.SS2.SSS1.p1.3.m3.2.2.2.3" xref="S3.SS2.SSS1.p1.3.m3.2.2.3.cmml">{</mo><mrow id="S3.SS2.SSS1.p1.3.m3.1.1.1.1.2" xref="S3.SS2.SSS1.p1.3.m3.1.1.1.1.3.cmml"><mo id="S3.SS2.SSS1.p1.3.m3.1.1.1.1.2.3" stretchy="false" xref="S3.SS2.SSS1.p1.3.m3.1.1.1.1.3.cmml">(</mo><msup id="S3.SS2.SSS1.p1.3.m3.1.1.1.1.1.1" xref="S3.SS2.SSS1.p1.3.m3.1.1.1.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS2.SSS1.p1.3.m3.1.1.1.1.1.1.2" xref="S3.SS2.SSS1.p1.3.m3.1.1.1.1.1.1.2a.cmml">b</mtext><mtext id="S3.SS2.SSS1.p1.3.m3.1.1.1.1.1.1.3" xref="S3.SS2.SSS1.p1.3.m3.1.1.1.1.1.1.3a.cmml">edit</mtext></msup><mo id="S3.SS2.SSS1.p1.3.m3.1.1.1.1.2.4" xref="S3.SS2.SSS1.p1.3.m3.1.1.1.1.3.cmml">,</mo><msup id="S3.SS2.SSS1.p1.3.m3.1.1.1.1.2.2" xref="S3.SS2.SSS1.p1.3.m3.1.1.1.1.2.2.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS2.SSS1.p1.3.m3.1.1.1.1.2.2.2" xref="S3.SS2.SSS1.p1.3.m3.1.1.1.1.2.2.2a.cmml">x</mtext><mtext id="S3.SS2.SSS1.p1.3.m3.1.1.1.1.2.2.3" xref="S3.SS2.SSS1.p1.3.m3.1.1.1.1.2.2.3a.cmml">edit</mtext></msup><mo id="S3.SS2.SSS1.p1.3.m3.1.1.1.1.2.5" stretchy="false" xref="S3.SS2.SSS1.p1.3.m3.1.1.1.1.3.cmml">)</mo></mrow><mo id="S3.SS2.SSS1.p1.3.m3.2.2.2.4" xref="S3.SS2.SSS1.p1.3.m3.2.2.3.cmml">,</mo><mrow id="S3.SS2.SSS1.p1.3.m3.2.2.2.2.2" xref="S3.SS2.SSS1.p1.3.m3.2.2.2.2.3.cmml"><mo id="S3.SS2.SSS1.p1.3.m3.2.2.2.2.2.3" stretchy="false" xref="S3.SS2.SSS1.p1.3.m3.2.2.2.2.3.cmml">(</mo><msup id="S3.SS2.SSS1.p1.3.m3.2.2.2.2.1.1" xref="S3.SS2.SSS1.p1.3.m3.2.2.2.2.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS2.SSS1.p1.3.m3.2.2.2.2.1.1.2" xref="S3.SS2.SSS1.p1.3.m3.2.2.2.2.1.1.2a.cmml">b</mtext><mtext id="S3.SS2.SSS1.p1.3.m3.2.2.2.2.1.1.3" xref="S3.SS2.SSS1.p1.3.m3.2.2.2.2.1.1.3a.cmml">id</mtext></msup><mo id="S3.SS2.SSS1.p1.3.m3.2.2.2.2.2.4" xref="S3.SS2.SSS1.p1.3.m3.2.2.2.2.3.cmml">,</mo><msup id="S3.SS2.SSS1.p1.3.m3.2.2.2.2.2.2" xref="S3.SS2.SSS1.p1.3.m3.2.2.2.2.2.2.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS2.SSS1.p1.3.m3.2.2.2.2.2.2.2" xref="S3.SS2.SSS1.p1.3.m3.2.2.2.2.2.2.2a.cmml">x</mtext><mtext id="S3.SS2.SSS1.p1.3.m3.2.2.2.2.2.2.3" xref="S3.SS2.SSS1.p1.3.m3.2.2.2.2.2.2.3a.cmml">id</mtext></msup><mo id="S3.SS2.SSS1.p1.3.m3.2.2.2.2.2.5" stretchy="false" xref="S3.SS2.SSS1.p1.3.m3.2.2.2.2.3.cmml">)</mo></mrow><mo id="S3.SS2.SSS1.p1.3.m3.2.2.2.5" xref="S3.SS2.SSS1.p1.3.m3.2.2.3.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p1.3.m3.2b"><set id="S3.SS2.SSS1.p1.3.m3.2.2.3.cmml" xref="S3.SS2.SSS1.p1.3.m3.2.2.2"><interval closure="open" id="S3.SS2.SSS1.p1.3.m3.1.1.1.1.3.cmml" xref="S3.SS2.SSS1.p1.3.m3.1.1.1.1.2"><apply id="S3.SS2.SSS1.p1.3.m3.1.1.1.1.1.1.cmml" xref="S3.SS2.SSS1.p1.3.m3.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p1.3.m3.1.1.1.1.1.1.1.cmml" xref="S3.SS2.SSS1.p1.3.m3.1.1.1.1.1.1">superscript</csymbol><ci id="S3.SS2.SSS1.p1.3.m3.1.1.1.1.1.1.2a.cmml" xref="S3.SS2.SSS1.p1.3.m3.1.1.1.1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.SS2.SSS1.p1.3.m3.1.1.1.1.1.1.2.cmml" xref="S3.SS2.SSS1.p1.3.m3.1.1.1.1.1.1.2">b</mtext></ci><ci id="S3.SS2.SSS1.p1.3.m3.1.1.1.1.1.1.3a.cmml" xref="S3.SS2.SSS1.p1.3.m3.1.1.1.1.1.1.3"><mtext id="S3.SS2.SSS1.p1.3.m3.1.1.1.1.1.1.3.cmml" mathsize="70%" xref="S3.SS2.SSS1.p1.3.m3.1.1.1.1.1.1.3">edit</mtext></ci></apply><apply id="S3.SS2.SSS1.p1.3.m3.1.1.1.1.2.2.cmml" xref="S3.SS2.SSS1.p1.3.m3.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p1.3.m3.1.1.1.1.2.2.1.cmml" xref="S3.SS2.SSS1.p1.3.m3.1.1.1.1.2.2">superscript</csymbol><ci id="S3.SS2.SSS1.p1.3.m3.1.1.1.1.2.2.2a.cmml" xref="S3.SS2.SSS1.p1.3.m3.1.1.1.1.2.2.2"><mtext class="ltx_mathvariant_bold" id="S3.SS2.SSS1.p1.3.m3.1.1.1.1.2.2.2.cmml" xref="S3.SS2.SSS1.p1.3.m3.1.1.1.1.2.2.2">x</mtext></ci><ci id="S3.SS2.SSS1.p1.3.m3.1.1.1.1.2.2.3a.cmml" xref="S3.SS2.SSS1.p1.3.m3.1.1.1.1.2.2.3"><mtext id="S3.SS2.SSS1.p1.3.m3.1.1.1.1.2.2.3.cmml" mathsize="70%" xref="S3.SS2.SSS1.p1.3.m3.1.1.1.1.2.2.3">edit</mtext></ci></apply></interval><interval closure="open" id="S3.SS2.SSS1.p1.3.m3.2.2.2.2.3.cmml" xref="S3.SS2.SSS1.p1.3.m3.2.2.2.2.2"><apply id="S3.SS2.SSS1.p1.3.m3.2.2.2.2.1.1.cmml" xref="S3.SS2.SSS1.p1.3.m3.2.2.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p1.3.m3.2.2.2.2.1.1.1.cmml" xref="S3.SS2.SSS1.p1.3.m3.2.2.2.2.1.1">superscript</csymbol><ci id="S3.SS2.SSS1.p1.3.m3.2.2.2.2.1.1.2a.cmml" xref="S3.SS2.SSS1.p1.3.m3.2.2.2.2.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.SS2.SSS1.p1.3.m3.2.2.2.2.1.1.2.cmml" xref="S3.SS2.SSS1.p1.3.m3.2.2.2.2.1.1.2">b</mtext></ci><ci id="S3.SS2.SSS1.p1.3.m3.2.2.2.2.1.1.3a.cmml" xref="S3.SS2.SSS1.p1.3.m3.2.2.2.2.1.1.3"><mtext id="S3.SS2.SSS1.p1.3.m3.2.2.2.2.1.1.3.cmml" mathsize="70%" xref="S3.SS2.SSS1.p1.3.m3.2.2.2.2.1.1.3">id</mtext></ci></apply><apply id="S3.SS2.SSS1.p1.3.m3.2.2.2.2.2.2.cmml" xref="S3.SS2.SSS1.p1.3.m3.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p1.3.m3.2.2.2.2.2.2.1.cmml" xref="S3.SS2.SSS1.p1.3.m3.2.2.2.2.2.2">superscript</csymbol><ci id="S3.SS2.SSS1.p1.3.m3.2.2.2.2.2.2.2a.cmml" xref="S3.SS2.SSS1.p1.3.m3.2.2.2.2.2.2.2"><mtext class="ltx_mathvariant_bold" id="S3.SS2.SSS1.p1.3.m3.2.2.2.2.2.2.2.cmml" xref="S3.SS2.SSS1.p1.3.m3.2.2.2.2.2.2.2">x</mtext></ci><ci id="S3.SS2.SSS1.p1.3.m3.2.2.2.2.2.2.3a.cmml" xref="S3.SS2.SSS1.p1.3.m3.2.2.2.2.2.2.3"><mtext id="S3.SS2.SSS1.p1.3.m3.2.2.2.2.2.2.3.cmml" mathsize="70%" xref="S3.SS2.SSS1.p1.3.m3.2.2.2.2.2.2.3">id</mtext></ci></apply></interval></set></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p1.3.m3.2c">\left\{(\textbf{b}^{\text{edit}},\textbf{x}^{\text{edit}}),(\textbf{b}^{\text{%
id}},\textbf{x}^{\text{id}})\right\}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p1.3.m3.2d">{ ( b start_POSTSUPERSCRIPT edit end_POSTSUPERSCRIPT , x start_POSTSUPERSCRIPT edit end_POSTSUPERSCRIPT ) , ( b start_POSTSUPERSCRIPT id end_POSTSUPERSCRIPT , x start_POSTSUPERSCRIPT id end_POSTSUPERSCRIPT ) }</annotation></semantics></math>. For an off-the-shelf object detector, denoted by <math alttext="\mathcal{F}_{\text{det}}" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p1.4.m4.1"><semantics id="S3.SS2.SSS1.p1.4.m4.1a"><msub id="S3.SS2.SSS1.p1.4.m4.1.1" xref="S3.SS2.SSS1.p1.4.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.SSS1.p1.4.m4.1.1.2" xref="S3.SS2.SSS1.p1.4.m4.1.1.2.cmml">ℱ</mi><mtext id="S3.SS2.SSS1.p1.4.m4.1.1.3" xref="S3.SS2.SSS1.p1.4.m4.1.1.3a.cmml">det</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p1.4.m4.1b"><apply id="S3.SS2.SSS1.p1.4.m4.1.1.cmml" xref="S3.SS2.SSS1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p1.4.m4.1.1.1.cmml" xref="S3.SS2.SSS1.p1.4.m4.1.1">subscript</csymbol><ci id="S3.SS2.SSS1.p1.4.m4.1.1.2.cmml" xref="S3.SS2.SSS1.p1.4.m4.1.1.2">ℱ</ci><ci id="S3.SS2.SSS1.p1.4.m4.1.1.3a.cmml" xref="S3.SS2.SSS1.p1.4.m4.1.1.3"><mtext id="S3.SS2.SSS1.p1.4.m4.1.1.3.cmml" mathsize="70%" xref="S3.SS2.SSS1.p1.4.m4.1.1.3">det</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p1.4.m4.1c">\mathcal{F}_{\text{det}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p1.4.m4.1d">caligraphic_F start_POSTSUBSCRIPT det end_POSTSUBSCRIPT</annotation></semantics></math>, we extract latent features, <math alttext="\textbf{z}^{\text{edit}}" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p1.5.m5.1"><semantics id="S3.SS2.SSS1.p1.5.m5.1a"><msup id="S3.SS2.SSS1.p1.5.m5.1.1" xref="S3.SS2.SSS1.p1.5.m5.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS2.SSS1.p1.5.m5.1.1.2" xref="S3.SS2.SSS1.p1.5.m5.1.1.2a.cmml">z</mtext><mtext id="S3.SS2.SSS1.p1.5.m5.1.1.3" xref="S3.SS2.SSS1.p1.5.m5.1.1.3a.cmml">edit</mtext></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p1.5.m5.1b"><apply id="S3.SS2.SSS1.p1.5.m5.1.1.cmml" xref="S3.SS2.SSS1.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p1.5.m5.1.1.1.cmml" xref="S3.SS2.SSS1.p1.5.m5.1.1">superscript</csymbol><ci id="S3.SS2.SSS1.p1.5.m5.1.1.2a.cmml" xref="S3.SS2.SSS1.p1.5.m5.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.SS2.SSS1.p1.5.m5.1.1.2.cmml" xref="S3.SS2.SSS1.p1.5.m5.1.1.2">z</mtext></ci><ci id="S3.SS2.SSS1.p1.5.m5.1.1.3a.cmml" xref="S3.SS2.SSS1.p1.5.m5.1.1.3"><mtext id="S3.SS2.SSS1.p1.5.m5.1.1.3.cmml" mathsize="70%" xref="S3.SS2.SSS1.p1.5.m5.1.1.3">edit</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p1.5.m5.1c">\textbf{z}^{\text{edit}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p1.5.m5.1d">z start_POSTSUPERSCRIPT edit end_POSTSUPERSCRIPT</annotation></semantics></math> and <math alttext="\textbf{z}^{\text{id}}" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p1.6.m6.1"><semantics id="S3.SS2.SSS1.p1.6.m6.1a"><msup id="S3.SS2.SSS1.p1.6.m6.1.1" xref="S3.SS2.SSS1.p1.6.m6.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS2.SSS1.p1.6.m6.1.1.2" xref="S3.SS2.SSS1.p1.6.m6.1.1.2a.cmml">z</mtext><mtext id="S3.SS2.SSS1.p1.6.m6.1.1.3" xref="S3.SS2.SSS1.p1.6.m6.1.1.3a.cmml">id</mtext></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p1.6.m6.1b"><apply id="S3.SS2.SSS1.p1.6.m6.1.1.cmml" xref="S3.SS2.SSS1.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p1.6.m6.1.1.1.cmml" xref="S3.SS2.SSS1.p1.6.m6.1.1">superscript</csymbol><ci id="S3.SS2.SSS1.p1.6.m6.1.1.2a.cmml" xref="S3.SS2.SSS1.p1.6.m6.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.SS2.SSS1.p1.6.m6.1.1.2.cmml" xref="S3.SS2.SSS1.p1.6.m6.1.1.2">z</mtext></ci><ci id="S3.SS2.SSS1.p1.6.m6.1.1.3a.cmml" xref="S3.SS2.SSS1.p1.6.m6.1.1.3"><mtext id="S3.SS2.SSS1.p1.6.m6.1.1.3.cmml" mathsize="70%" xref="S3.SS2.SSS1.p1.6.m6.1.1.3">id</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p1.6.m6.1c">\textbf{z}^{\text{id}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p1.6.m6.1d">z start_POSTSUPERSCRIPT id end_POSTSUPERSCRIPT</annotation></semantics></math>, for each pair:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E4">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\textbf{z}^{\text{edit}},\textbf{z}^{\text{id}}=\mathcal{F}_{\text{det}}(%
\textbf{b}^{\text{edit}};\textbf{x}^{\text{edit}}),\mathcal{F}_{\text{det}}(%
\textbf{b}^{\text{id}};\textbf{x}^{\text{id}})." class="ltx_Math" display="block" id="S3.E4.m1.1"><semantics id="S3.E4.m1.1a"><mrow id="S3.E4.m1.1.1.1"><mrow id="S3.E4.m1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.3.cmml"><mrow id="S3.E4.m1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.cmml"><mrow id="S3.E4.m1.1.1.1.1.1.1.2.2" xref="S3.E4.m1.1.1.1.1.1.1.2.3.cmml"><msup id="S3.E4.m1.1.1.1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E4.m1.1.1.1.1.1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.2a.cmml">z</mtext><mtext id="S3.E4.m1.1.1.1.1.1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.3a.cmml">edit</mtext></msup><mo id="S3.E4.m1.1.1.1.1.1.1.2.2.3" xref="S3.E4.m1.1.1.1.1.1.1.2.3.cmml">,</mo><msup id="S3.E4.m1.1.1.1.1.1.1.2.2.2" xref="S3.E4.m1.1.1.1.1.1.1.2.2.2.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E4.m1.1.1.1.1.1.1.2.2.2.2" xref="S3.E4.m1.1.1.1.1.1.1.2.2.2.2a.cmml">z</mtext><mtext id="S3.E4.m1.1.1.1.1.1.1.2.2.2.3" xref="S3.E4.m1.1.1.1.1.1.1.2.2.2.3a.cmml">id</mtext></msup></mrow><mo id="S3.E4.m1.1.1.1.1.1.1.5" xref="S3.E4.m1.1.1.1.1.1.1.5.cmml">=</mo><mrow id="S3.E4.m1.1.1.1.1.1.1.4" xref="S3.E4.m1.1.1.1.1.1.1.4.cmml"><msub id="S3.E4.m1.1.1.1.1.1.1.4.4" xref="S3.E4.m1.1.1.1.1.1.1.4.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E4.m1.1.1.1.1.1.1.4.4.2" xref="S3.E4.m1.1.1.1.1.1.1.4.4.2.cmml">ℱ</mi><mtext id="S3.E4.m1.1.1.1.1.1.1.4.4.3" xref="S3.E4.m1.1.1.1.1.1.1.4.4.3a.cmml">det</mtext></msub><mo id="S3.E4.m1.1.1.1.1.1.1.4.3" xref="S3.E4.m1.1.1.1.1.1.1.4.3.cmml">⁢</mo><mrow id="S3.E4.m1.1.1.1.1.1.1.4.2.2" xref="S3.E4.m1.1.1.1.1.1.1.4.2.3.cmml"><mo id="S3.E4.m1.1.1.1.1.1.1.4.2.2.3" stretchy="false" xref="S3.E4.m1.1.1.1.1.1.1.4.2.3.cmml">(</mo><msup id="S3.E4.m1.1.1.1.1.1.1.3.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.3.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E4.m1.1.1.1.1.1.1.3.1.1.1.2" xref="S3.E4.m1.1.1.1.1.1.1.3.1.1.1.2a.cmml">b</mtext><mtext id="S3.E4.m1.1.1.1.1.1.1.3.1.1.1.3" xref="S3.E4.m1.1.1.1.1.1.1.3.1.1.1.3a.cmml">edit</mtext></msup><mo id="S3.E4.m1.1.1.1.1.1.1.4.2.2.4" xref="S3.E4.m1.1.1.1.1.1.1.4.2.3.cmml">;</mo><msup id="S3.E4.m1.1.1.1.1.1.1.4.2.2.2" xref="S3.E4.m1.1.1.1.1.1.1.4.2.2.2.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E4.m1.1.1.1.1.1.1.4.2.2.2.2" xref="S3.E4.m1.1.1.1.1.1.1.4.2.2.2.2a.cmml">x</mtext><mtext id="S3.E4.m1.1.1.1.1.1.1.4.2.2.2.3" xref="S3.E4.m1.1.1.1.1.1.1.4.2.2.2.3a.cmml">edit</mtext></msup><mo id="S3.E4.m1.1.1.1.1.1.1.4.2.2.5" stretchy="false" xref="S3.E4.m1.1.1.1.1.1.1.4.2.3.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E4.m1.1.1.1.1.2.3" xref="S3.E4.m1.1.1.1.1.3a.cmml">,</mo><mrow id="S3.E4.m1.1.1.1.1.2.2" xref="S3.E4.m1.1.1.1.1.2.2.cmml"><msub id="S3.E4.m1.1.1.1.1.2.2.4" xref="S3.E4.m1.1.1.1.1.2.2.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E4.m1.1.1.1.1.2.2.4.2" xref="S3.E4.m1.1.1.1.1.2.2.4.2.cmml">ℱ</mi><mtext id="S3.E4.m1.1.1.1.1.2.2.4.3" xref="S3.E4.m1.1.1.1.1.2.2.4.3a.cmml">det</mtext></msub><mo id="S3.E4.m1.1.1.1.1.2.2.3" xref="S3.E4.m1.1.1.1.1.2.2.3.cmml">⁢</mo><mrow id="S3.E4.m1.1.1.1.1.2.2.2.2" xref="S3.E4.m1.1.1.1.1.2.2.2.3.cmml"><mo id="S3.E4.m1.1.1.1.1.2.2.2.2.3" stretchy="false" xref="S3.E4.m1.1.1.1.1.2.2.2.3.cmml">(</mo><msup id="S3.E4.m1.1.1.1.1.2.2.1.1.1" xref="S3.E4.m1.1.1.1.1.2.2.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E4.m1.1.1.1.1.2.2.1.1.1.2" xref="S3.E4.m1.1.1.1.1.2.2.1.1.1.2a.cmml">b</mtext><mtext id="S3.E4.m1.1.1.1.1.2.2.1.1.1.3" xref="S3.E4.m1.1.1.1.1.2.2.1.1.1.3a.cmml">id</mtext></msup><mo id="S3.E4.m1.1.1.1.1.2.2.2.2.4" xref="S3.E4.m1.1.1.1.1.2.2.2.3.cmml">;</mo><msup id="S3.E4.m1.1.1.1.1.2.2.2.2.2" xref="S3.E4.m1.1.1.1.1.2.2.2.2.2.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E4.m1.1.1.1.1.2.2.2.2.2.2" xref="S3.E4.m1.1.1.1.1.2.2.2.2.2.2a.cmml">x</mtext><mtext id="S3.E4.m1.1.1.1.1.2.2.2.2.2.3" xref="S3.E4.m1.1.1.1.1.2.2.2.2.2.3a.cmml">id</mtext></msup><mo id="S3.E4.m1.1.1.1.1.2.2.2.2.5" stretchy="false" xref="S3.E4.m1.1.1.1.1.2.2.2.3.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E4.m1.1.1.1.2" lspace="0em">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.1b"><apply id="S3.E4.m1.1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.3a.cmml" xref="S3.E4.m1.1.1.1.1.2.3">formulae-sequence</csymbol><apply id="S3.E4.m1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1"><eq id="S3.E4.m1.1.1.1.1.1.1.5.cmml" xref="S3.E4.m1.1.1.1.1.1.1.5"></eq><list id="S3.E4.m1.1.1.1.1.1.1.2.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.2.2"><apply id="S3.E4.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1">superscript</csymbol><ci id="S3.E4.m1.1.1.1.1.1.1.1.1.1.2a.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.E4.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.2">z</mtext></ci><ci id="S3.E4.m1.1.1.1.1.1.1.1.1.1.3a.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.3"><mtext id="S3.E4.m1.1.1.1.1.1.1.1.1.1.3.cmml" mathsize="70%" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.3">edit</mtext></ci></apply><apply id="S3.E4.m1.1.1.1.1.1.1.2.2.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.1.1.2.2.2.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.2.2.2">superscript</csymbol><ci id="S3.E4.m1.1.1.1.1.1.1.2.2.2.2a.cmml" xref="S3.E4.m1.1.1.1.1.1.1.2.2.2.2"><mtext class="ltx_mathvariant_bold" id="S3.E4.m1.1.1.1.1.1.1.2.2.2.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.2.2.2.2">z</mtext></ci><ci id="S3.E4.m1.1.1.1.1.1.1.2.2.2.3a.cmml" xref="S3.E4.m1.1.1.1.1.1.1.2.2.2.3"><mtext id="S3.E4.m1.1.1.1.1.1.1.2.2.2.3.cmml" mathsize="70%" xref="S3.E4.m1.1.1.1.1.1.1.2.2.2.3">id</mtext></ci></apply></list><apply id="S3.E4.m1.1.1.1.1.1.1.4.cmml" xref="S3.E4.m1.1.1.1.1.1.1.4"><times id="S3.E4.m1.1.1.1.1.1.1.4.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.4.3"></times><apply id="S3.E4.m1.1.1.1.1.1.1.4.4.cmml" xref="S3.E4.m1.1.1.1.1.1.1.4.4"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.1.1.4.4.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.4.4">subscript</csymbol><ci id="S3.E4.m1.1.1.1.1.1.1.4.4.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.4.4.2">ℱ</ci><ci id="S3.E4.m1.1.1.1.1.1.1.4.4.3a.cmml" xref="S3.E4.m1.1.1.1.1.1.1.4.4.3"><mtext id="S3.E4.m1.1.1.1.1.1.1.4.4.3.cmml" mathsize="70%" xref="S3.E4.m1.1.1.1.1.1.1.4.4.3">det</mtext></ci></apply><list id="S3.E4.m1.1.1.1.1.1.1.4.2.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.4.2.2"><apply id="S3.E4.m1.1.1.1.1.1.1.3.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.3.1.1.1"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.1.1.3.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.3.1.1.1">superscript</csymbol><ci id="S3.E4.m1.1.1.1.1.1.1.3.1.1.1.2a.cmml" xref="S3.E4.m1.1.1.1.1.1.1.3.1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.E4.m1.1.1.1.1.1.1.3.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.3.1.1.1.2">b</mtext></ci><ci id="S3.E4.m1.1.1.1.1.1.1.3.1.1.1.3a.cmml" xref="S3.E4.m1.1.1.1.1.1.1.3.1.1.1.3"><mtext id="S3.E4.m1.1.1.1.1.1.1.3.1.1.1.3.cmml" mathsize="70%" xref="S3.E4.m1.1.1.1.1.1.1.3.1.1.1.3">edit</mtext></ci></apply><apply id="S3.E4.m1.1.1.1.1.1.1.4.2.2.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.4.2.2.2"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.1.1.4.2.2.2.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.4.2.2.2">superscript</csymbol><ci id="S3.E4.m1.1.1.1.1.1.1.4.2.2.2.2a.cmml" xref="S3.E4.m1.1.1.1.1.1.1.4.2.2.2.2"><mtext class="ltx_mathvariant_bold" id="S3.E4.m1.1.1.1.1.1.1.4.2.2.2.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.4.2.2.2.2">x</mtext></ci><ci id="S3.E4.m1.1.1.1.1.1.1.4.2.2.2.3a.cmml" xref="S3.E4.m1.1.1.1.1.1.1.4.2.2.2.3"><mtext id="S3.E4.m1.1.1.1.1.1.1.4.2.2.2.3.cmml" mathsize="70%" xref="S3.E4.m1.1.1.1.1.1.1.4.2.2.2.3">edit</mtext></ci></apply></list></apply></apply><apply id="S3.E4.m1.1.1.1.1.2.2.cmml" xref="S3.E4.m1.1.1.1.1.2.2"><times id="S3.E4.m1.1.1.1.1.2.2.3.cmml" xref="S3.E4.m1.1.1.1.1.2.2.3"></times><apply id="S3.E4.m1.1.1.1.1.2.2.4.cmml" xref="S3.E4.m1.1.1.1.1.2.2.4"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.2.2.4.1.cmml" xref="S3.E4.m1.1.1.1.1.2.2.4">subscript</csymbol><ci id="S3.E4.m1.1.1.1.1.2.2.4.2.cmml" xref="S3.E4.m1.1.1.1.1.2.2.4.2">ℱ</ci><ci id="S3.E4.m1.1.1.1.1.2.2.4.3a.cmml" xref="S3.E4.m1.1.1.1.1.2.2.4.3"><mtext id="S3.E4.m1.1.1.1.1.2.2.4.3.cmml" mathsize="70%" xref="S3.E4.m1.1.1.1.1.2.2.4.3">det</mtext></ci></apply><list id="S3.E4.m1.1.1.1.1.2.2.2.3.cmml" xref="S3.E4.m1.1.1.1.1.2.2.2.2"><apply id="S3.E4.m1.1.1.1.1.2.2.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.2.2.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.2.2.1.1.1">superscript</csymbol><ci id="S3.E4.m1.1.1.1.1.2.2.1.1.1.2a.cmml" xref="S3.E4.m1.1.1.1.1.2.2.1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.E4.m1.1.1.1.1.2.2.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.2.2.1.1.1.2">b</mtext></ci><ci id="S3.E4.m1.1.1.1.1.2.2.1.1.1.3a.cmml" xref="S3.E4.m1.1.1.1.1.2.2.1.1.1.3"><mtext id="S3.E4.m1.1.1.1.1.2.2.1.1.1.3.cmml" mathsize="70%" xref="S3.E4.m1.1.1.1.1.2.2.1.1.1.3">id</mtext></ci></apply><apply id="S3.E4.m1.1.1.1.1.2.2.2.2.2.cmml" xref="S3.E4.m1.1.1.1.1.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.2.2.2.2.2.1.cmml" xref="S3.E4.m1.1.1.1.1.2.2.2.2.2">superscript</csymbol><ci id="S3.E4.m1.1.1.1.1.2.2.2.2.2.2a.cmml" xref="S3.E4.m1.1.1.1.1.2.2.2.2.2.2"><mtext class="ltx_mathvariant_bold" id="S3.E4.m1.1.1.1.1.2.2.2.2.2.2.cmml" xref="S3.E4.m1.1.1.1.1.2.2.2.2.2.2">x</mtext></ci><ci id="S3.E4.m1.1.1.1.1.2.2.2.2.2.3a.cmml" xref="S3.E4.m1.1.1.1.1.2.2.2.2.2.3"><mtext id="S3.E4.m1.1.1.1.1.2.2.2.2.2.3.cmml" mathsize="70%" xref="S3.E4.m1.1.1.1.1.2.2.2.2.2.3">id</mtext></ci></apply></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.1c">\textbf{z}^{\text{edit}},\textbf{z}^{\text{id}}=\mathcal{F}_{\text{det}}(%
\textbf{b}^{\text{edit}};\textbf{x}^{\text{edit}}),\mathcal{F}_{\text{det}}(%
\textbf{b}^{\text{id}};\textbf{x}^{\text{id}}).</annotation><annotation encoding="application/x-llamapun" id="S3.E4.m1.1d">z start_POSTSUPERSCRIPT edit end_POSTSUPERSCRIPT , z start_POSTSUPERSCRIPT id end_POSTSUPERSCRIPT = caligraphic_F start_POSTSUBSCRIPT det end_POSTSUBSCRIPT ( b start_POSTSUPERSCRIPT edit end_POSTSUPERSCRIPT ; x start_POSTSUPERSCRIPT edit end_POSTSUPERSCRIPT ) , caligraphic_F start_POSTSUBSCRIPT det end_POSTSUBSCRIPT ( b start_POSTSUPERSCRIPT id end_POSTSUPERSCRIPT ; x start_POSTSUPERSCRIPT id end_POSTSUPERSCRIPT ) .</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS2.SSS1.p1.9">The most effective novel objects are those with visual patterns that can be easily mistaken for their corresponding ID objects by an object detector. Therefore, we filter these novel objects based on their similarity to provide pseudo-OOD supervision:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E5">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\left\{\textbf{z}^{\text{ood}}\right\}=\left\{\left.\textbf{z}^{\text{edit}}%
\middle|\right.\epsilon_{\textit{low}}&lt;\text{sim}(\textbf{z}^{\text{edit}},%
\textbf{z}^{\text{id}})&lt;\epsilon_{\textit{up}}\right\}," class="ltx_Math" display="block" id="S3.E5.m1.1"><semantics id="S3.E5.m1.1a"><mrow id="S3.E5.m1.1.1.1" xref="S3.E5.m1.1.1.1.1.cmml"><mrow id="S3.E5.m1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.cmml"><mrow id="S3.E5.m1.1.1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.1.2.cmml"><mo id="S3.E5.m1.1.1.1.1.1.1.2" xref="S3.E5.m1.1.1.1.1.1.2.cmml">{</mo><msup id="S3.E5.m1.1.1.1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E5.m1.1.1.1.1.1.1.1.2" xref="S3.E5.m1.1.1.1.1.1.1.1.2a.cmml">z</mtext><mtext id="S3.E5.m1.1.1.1.1.1.1.1.3" xref="S3.E5.m1.1.1.1.1.1.1.1.3a.cmml">ood</mtext></msup><mo id="S3.E5.m1.1.1.1.1.1.1.3" xref="S3.E5.m1.1.1.1.1.1.2.cmml">}</mo></mrow><mo id="S3.E5.m1.1.1.1.1.4" xref="S3.E5.m1.1.1.1.1.4.cmml">=</mo><mrow id="S3.E5.m1.1.1.1.1.3.2" xref="S3.E5.m1.1.1.1.1.3.3.cmml"><mo id="S3.E5.m1.1.1.1.1.3.2.3" xref="S3.E5.m1.1.1.1.1.3.3.1.cmml">{</mo><msup id="S3.E5.m1.1.1.1.1.2.1.1" xref="S3.E5.m1.1.1.1.1.2.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E5.m1.1.1.1.1.2.1.1.2" xref="S3.E5.m1.1.1.1.1.2.1.1.2a.cmml">z</mtext><mtext id="S3.E5.m1.1.1.1.1.2.1.1.3" xref="S3.E5.m1.1.1.1.1.2.1.1.3a.cmml">edit</mtext></msup><mo id="S3.E5.m1.1.1.1.1.3.2.4" lspace="0em" rspace="0em" stretchy="true" xref="S3.E5.m1.1.1.1.1.3.3.1.cmml">|</mo><mrow id="S3.E5.m1.1.1.1.1.3.2.2" xref="S3.E5.m1.1.1.1.1.3.2.2.cmml"><msub id="S3.E5.m1.1.1.1.1.3.2.2.4" xref="S3.E5.m1.1.1.1.1.3.2.2.4.cmml"><mi id="S3.E5.m1.1.1.1.1.3.2.2.4.2" xref="S3.E5.m1.1.1.1.1.3.2.2.4.2.cmml">ϵ</mi><mtext class="ltx_mathvariant_italic" id="S3.E5.m1.1.1.1.1.3.2.2.4.3" xref="S3.E5.m1.1.1.1.1.3.2.2.4.3a.cmml">low</mtext></msub><mo id="S3.E5.m1.1.1.1.1.3.2.2.5" xref="S3.E5.m1.1.1.1.1.3.2.2.5.cmml">&lt;</mo><mrow id="S3.E5.m1.1.1.1.1.3.2.2.2" xref="S3.E5.m1.1.1.1.1.3.2.2.2.cmml"><mtext id="S3.E5.m1.1.1.1.1.3.2.2.2.4" xref="S3.E5.m1.1.1.1.1.3.2.2.2.4a.cmml">sim</mtext><mo id="S3.E5.m1.1.1.1.1.3.2.2.2.3" xref="S3.E5.m1.1.1.1.1.3.2.2.2.3.cmml">⁢</mo><mrow id="S3.E5.m1.1.1.1.1.3.2.2.2.2.2" xref="S3.E5.m1.1.1.1.1.3.2.2.2.2.3.cmml"><mo id="S3.E5.m1.1.1.1.1.3.2.2.2.2.2.3" stretchy="false" xref="S3.E5.m1.1.1.1.1.3.2.2.2.2.3.cmml">(</mo><msup id="S3.E5.m1.1.1.1.1.3.2.2.1.1.1.1" xref="S3.E5.m1.1.1.1.1.3.2.2.1.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E5.m1.1.1.1.1.3.2.2.1.1.1.1.2" xref="S3.E5.m1.1.1.1.1.3.2.2.1.1.1.1.2a.cmml">z</mtext><mtext id="S3.E5.m1.1.1.1.1.3.2.2.1.1.1.1.3" xref="S3.E5.m1.1.1.1.1.3.2.2.1.1.1.1.3a.cmml">edit</mtext></msup><mo id="S3.E5.m1.1.1.1.1.3.2.2.2.2.2.4" xref="S3.E5.m1.1.1.1.1.3.2.2.2.2.3.cmml">,</mo><msup id="S3.E5.m1.1.1.1.1.3.2.2.2.2.2.2" xref="S3.E5.m1.1.1.1.1.3.2.2.2.2.2.2.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E5.m1.1.1.1.1.3.2.2.2.2.2.2.2" xref="S3.E5.m1.1.1.1.1.3.2.2.2.2.2.2.2a.cmml">z</mtext><mtext id="S3.E5.m1.1.1.1.1.3.2.2.2.2.2.2.3" xref="S3.E5.m1.1.1.1.1.3.2.2.2.2.2.2.3a.cmml">id</mtext></msup><mo id="S3.E5.m1.1.1.1.1.3.2.2.2.2.2.5" stretchy="false" xref="S3.E5.m1.1.1.1.1.3.2.2.2.2.3.cmml">)</mo></mrow></mrow><mo id="S3.E5.m1.1.1.1.1.3.2.2.6" xref="S3.E5.m1.1.1.1.1.3.2.2.6.cmml">&lt;</mo><msub id="S3.E5.m1.1.1.1.1.3.2.2.7" xref="S3.E5.m1.1.1.1.1.3.2.2.7.cmml"><mi id="S3.E5.m1.1.1.1.1.3.2.2.7.2" xref="S3.E5.m1.1.1.1.1.3.2.2.7.2.cmml">ϵ</mi><mtext class="ltx_mathvariant_italic" id="S3.E5.m1.1.1.1.1.3.2.2.7.3" xref="S3.E5.m1.1.1.1.1.3.2.2.7.3a.cmml">up</mtext></msub></mrow><mo id="S3.E5.m1.1.1.1.1.3.2.5" xref="S3.E5.m1.1.1.1.1.3.3.1.cmml">}</mo></mrow></mrow><mo id="S3.E5.m1.1.1.1.2" xref="S3.E5.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E5.m1.1b"><apply id="S3.E5.m1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1"><eq id="S3.E5.m1.1.1.1.1.4.cmml" xref="S3.E5.m1.1.1.1.1.4"></eq><set id="S3.E5.m1.1.1.1.1.1.2.cmml" xref="S3.E5.m1.1.1.1.1.1.1"><apply id="S3.E5.m1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1">superscript</csymbol><ci id="S3.E5.m1.1.1.1.1.1.1.1.2a.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.E5.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.2">z</mtext></ci><ci id="S3.E5.m1.1.1.1.1.1.1.1.3a.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.3"><mtext id="S3.E5.m1.1.1.1.1.1.1.1.3.cmml" mathsize="70%" xref="S3.E5.m1.1.1.1.1.1.1.1.3">ood</mtext></ci></apply></set><apply id="S3.E5.m1.1.1.1.1.3.3.cmml" xref="S3.E5.m1.1.1.1.1.3.2"><csymbol cd="latexml" id="S3.E5.m1.1.1.1.1.3.3.1.cmml" xref="S3.E5.m1.1.1.1.1.3.2.3">conditional-set</csymbol><apply id="S3.E5.m1.1.1.1.1.2.1.1.cmml" xref="S3.E5.m1.1.1.1.1.2.1.1"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.2.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1.2.1.1">superscript</csymbol><ci id="S3.E5.m1.1.1.1.1.2.1.1.2a.cmml" xref="S3.E5.m1.1.1.1.1.2.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.E5.m1.1.1.1.1.2.1.1.2.cmml" xref="S3.E5.m1.1.1.1.1.2.1.1.2">z</mtext></ci><ci id="S3.E5.m1.1.1.1.1.2.1.1.3a.cmml" xref="S3.E5.m1.1.1.1.1.2.1.1.3"><mtext id="S3.E5.m1.1.1.1.1.2.1.1.3.cmml" mathsize="70%" xref="S3.E5.m1.1.1.1.1.2.1.1.3">edit</mtext></ci></apply><apply id="S3.E5.m1.1.1.1.1.3.2.2.cmml" xref="S3.E5.m1.1.1.1.1.3.2.2"><and id="S3.E5.m1.1.1.1.1.3.2.2a.cmml" xref="S3.E5.m1.1.1.1.1.3.2.2"></and><apply id="S3.E5.m1.1.1.1.1.3.2.2b.cmml" xref="S3.E5.m1.1.1.1.1.3.2.2"><lt id="S3.E5.m1.1.1.1.1.3.2.2.5.cmml" xref="S3.E5.m1.1.1.1.1.3.2.2.5"></lt><apply id="S3.E5.m1.1.1.1.1.3.2.2.4.cmml" xref="S3.E5.m1.1.1.1.1.3.2.2.4"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.3.2.2.4.1.cmml" xref="S3.E5.m1.1.1.1.1.3.2.2.4">subscript</csymbol><ci id="S3.E5.m1.1.1.1.1.3.2.2.4.2.cmml" xref="S3.E5.m1.1.1.1.1.3.2.2.4.2">italic-ϵ</ci><ci id="S3.E5.m1.1.1.1.1.3.2.2.4.3a.cmml" xref="S3.E5.m1.1.1.1.1.3.2.2.4.3"><mtext class="ltx_mathvariant_italic" id="S3.E5.m1.1.1.1.1.3.2.2.4.3.cmml" mathsize="70%" xref="S3.E5.m1.1.1.1.1.3.2.2.4.3">low</mtext></ci></apply><apply id="S3.E5.m1.1.1.1.1.3.2.2.2.cmml" xref="S3.E5.m1.1.1.1.1.3.2.2.2"><times id="S3.E5.m1.1.1.1.1.3.2.2.2.3.cmml" xref="S3.E5.m1.1.1.1.1.3.2.2.2.3"></times><ci id="S3.E5.m1.1.1.1.1.3.2.2.2.4a.cmml" xref="S3.E5.m1.1.1.1.1.3.2.2.2.4"><mtext id="S3.E5.m1.1.1.1.1.3.2.2.2.4.cmml" xref="S3.E5.m1.1.1.1.1.3.2.2.2.4">sim</mtext></ci><interval closure="open" id="S3.E5.m1.1.1.1.1.3.2.2.2.2.3.cmml" xref="S3.E5.m1.1.1.1.1.3.2.2.2.2.2"><apply id="S3.E5.m1.1.1.1.1.3.2.2.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1.3.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.3.2.2.1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1.3.2.2.1.1.1.1">superscript</csymbol><ci id="S3.E5.m1.1.1.1.1.3.2.2.1.1.1.1.2a.cmml" xref="S3.E5.m1.1.1.1.1.3.2.2.1.1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.E5.m1.1.1.1.1.3.2.2.1.1.1.1.2.cmml" xref="S3.E5.m1.1.1.1.1.3.2.2.1.1.1.1.2">z</mtext></ci><ci id="S3.E5.m1.1.1.1.1.3.2.2.1.1.1.1.3a.cmml" xref="S3.E5.m1.1.1.1.1.3.2.2.1.1.1.1.3"><mtext id="S3.E5.m1.1.1.1.1.3.2.2.1.1.1.1.3.cmml" mathsize="70%" xref="S3.E5.m1.1.1.1.1.3.2.2.1.1.1.1.3">edit</mtext></ci></apply><apply id="S3.E5.m1.1.1.1.1.3.2.2.2.2.2.2.cmml" xref="S3.E5.m1.1.1.1.1.3.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.3.2.2.2.2.2.2.1.cmml" xref="S3.E5.m1.1.1.1.1.3.2.2.2.2.2.2">superscript</csymbol><ci id="S3.E5.m1.1.1.1.1.3.2.2.2.2.2.2.2a.cmml" xref="S3.E5.m1.1.1.1.1.3.2.2.2.2.2.2.2"><mtext class="ltx_mathvariant_bold" id="S3.E5.m1.1.1.1.1.3.2.2.2.2.2.2.2.cmml" xref="S3.E5.m1.1.1.1.1.3.2.2.2.2.2.2.2">z</mtext></ci><ci id="S3.E5.m1.1.1.1.1.3.2.2.2.2.2.2.3a.cmml" xref="S3.E5.m1.1.1.1.1.3.2.2.2.2.2.2.3"><mtext id="S3.E5.m1.1.1.1.1.3.2.2.2.2.2.2.3.cmml" mathsize="70%" xref="S3.E5.m1.1.1.1.1.3.2.2.2.2.2.2.3">id</mtext></ci></apply></interval></apply></apply><apply id="S3.E5.m1.1.1.1.1.3.2.2c.cmml" xref="S3.E5.m1.1.1.1.1.3.2.2"><lt id="S3.E5.m1.1.1.1.1.3.2.2.6.cmml" xref="S3.E5.m1.1.1.1.1.3.2.2.6"></lt><share href="https://arxiv.org/html/2409.05162v1#S3.E5.m1.1.1.1.1.3.2.2.2.cmml" id="S3.E5.m1.1.1.1.1.3.2.2d.cmml" xref="S3.E5.m1.1.1.1.1.3.2.2"></share><apply id="S3.E5.m1.1.1.1.1.3.2.2.7.cmml" xref="S3.E5.m1.1.1.1.1.3.2.2.7"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.3.2.2.7.1.cmml" xref="S3.E5.m1.1.1.1.1.3.2.2.7">subscript</csymbol><ci id="S3.E5.m1.1.1.1.1.3.2.2.7.2.cmml" xref="S3.E5.m1.1.1.1.1.3.2.2.7.2">italic-ϵ</ci><ci id="S3.E5.m1.1.1.1.1.3.2.2.7.3a.cmml" xref="S3.E5.m1.1.1.1.1.3.2.2.7.3"><mtext class="ltx_mathvariant_italic" id="S3.E5.m1.1.1.1.1.3.2.2.7.3.cmml" mathsize="70%" xref="S3.E5.m1.1.1.1.1.3.2.2.7.3">up</mtext></ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E5.m1.1c">\left\{\textbf{z}^{\text{ood}}\right\}=\left\{\left.\textbf{z}^{\text{edit}}%
\middle|\right.\epsilon_{\textit{low}}&lt;\text{sim}(\textbf{z}^{\text{edit}},%
\textbf{z}^{\text{id}})&lt;\epsilon_{\textit{up}}\right\},</annotation><annotation encoding="application/x-llamapun" id="S3.E5.m1.1d">{ z start_POSTSUPERSCRIPT ood end_POSTSUPERSCRIPT } = { z start_POSTSUPERSCRIPT edit end_POSTSUPERSCRIPT | italic_ϵ start_POSTSUBSCRIPT low end_POSTSUBSCRIPT &lt; sim ( z start_POSTSUPERSCRIPT edit end_POSTSUPERSCRIPT , z start_POSTSUPERSCRIPT id end_POSTSUPERSCRIPT ) &lt; italic_ϵ start_POSTSUBSCRIPT up end_POSTSUBSCRIPT } ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS2.SSS1.p1.8">where the similarities are computed between latent object features of edit-ID pairs. Here <math alttext="\text{sim}(\cdot)" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p1.7.m1.1"><semantics id="S3.SS2.SSS1.p1.7.m1.1a"><mrow id="S3.SS2.SSS1.p1.7.m1.1.2" xref="S3.SS2.SSS1.p1.7.m1.1.2.cmml"><mtext id="S3.SS2.SSS1.p1.7.m1.1.2.2" xref="S3.SS2.SSS1.p1.7.m1.1.2.2a.cmml">sim</mtext><mo id="S3.SS2.SSS1.p1.7.m1.1.2.1" xref="S3.SS2.SSS1.p1.7.m1.1.2.1.cmml">⁢</mo><mrow id="S3.SS2.SSS1.p1.7.m1.1.2.3.2" xref="S3.SS2.SSS1.p1.7.m1.1.2.cmml"><mo id="S3.SS2.SSS1.p1.7.m1.1.2.3.2.1" stretchy="false" xref="S3.SS2.SSS1.p1.7.m1.1.2.cmml">(</mo><mo id="S3.SS2.SSS1.p1.7.m1.1.1" lspace="0em" rspace="0em" xref="S3.SS2.SSS1.p1.7.m1.1.1.cmml">⋅</mo><mo id="S3.SS2.SSS1.p1.7.m1.1.2.3.2.2" stretchy="false" xref="S3.SS2.SSS1.p1.7.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p1.7.m1.1b"><apply id="S3.SS2.SSS1.p1.7.m1.1.2.cmml" xref="S3.SS2.SSS1.p1.7.m1.1.2"><times id="S3.SS2.SSS1.p1.7.m1.1.2.1.cmml" xref="S3.SS2.SSS1.p1.7.m1.1.2.1"></times><ci id="S3.SS2.SSS1.p1.7.m1.1.2.2a.cmml" xref="S3.SS2.SSS1.p1.7.m1.1.2.2"><mtext id="S3.SS2.SSS1.p1.7.m1.1.2.2.cmml" xref="S3.SS2.SSS1.p1.7.m1.1.2.2">sim</mtext></ci><ci id="S3.SS2.SSS1.p1.7.m1.1.1.cmml" xref="S3.SS2.SSS1.p1.7.m1.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p1.7.m1.1c">\text{sim}(\cdot)</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p1.7.m1.1d">sim ( ⋅ )</annotation></semantics></math> denotes cosine similarity calculating and <math alttext="\epsilon_{\textit{low}},\epsilon_{\textit{up}}" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p1.8.m2.2"><semantics id="S3.SS2.SSS1.p1.8.m2.2a"><mrow id="S3.SS2.SSS1.p1.8.m2.2.2.2" xref="S3.SS2.SSS1.p1.8.m2.2.2.3.cmml"><msub id="S3.SS2.SSS1.p1.8.m2.1.1.1.1" xref="S3.SS2.SSS1.p1.8.m2.1.1.1.1.cmml"><mi id="S3.SS2.SSS1.p1.8.m2.1.1.1.1.2" xref="S3.SS2.SSS1.p1.8.m2.1.1.1.1.2.cmml">ϵ</mi><mtext class="ltx_mathvariant_italic" id="S3.SS2.SSS1.p1.8.m2.1.1.1.1.3" xref="S3.SS2.SSS1.p1.8.m2.1.1.1.1.3a.cmml">low</mtext></msub><mo id="S3.SS2.SSS1.p1.8.m2.2.2.2.3" xref="S3.SS2.SSS1.p1.8.m2.2.2.3.cmml">,</mo><msub id="S3.SS2.SSS1.p1.8.m2.2.2.2.2" xref="S3.SS2.SSS1.p1.8.m2.2.2.2.2.cmml"><mi id="S3.SS2.SSS1.p1.8.m2.2.2.2.2.2" xref="S3.SS2.SSS1.p1.8.m2.2.2.2.2.2.cmml">ϵ</mi><mtext class="ltx_mathvariant_italic" id="S3.SS2.SSS1.p1.8.m2.2.2.2.2.3" xref="S3.SS2.SSS1.p1.8.m2.2.2.2.2.3a.cmml">up</mtext></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p1.8.m2.2b"><list id="S3.SS2.SSS1.p1.8.m2.2.2.3.cmml" xref="S3.SS2.SSS1.p1.8.m2.2.2.2"><apply id="S3.SS2.SSS1.p1.8.m2.1.1.1.1.cmml" xref="S3.SS2.SSS1.p1.8.m2.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p1.8.m2.1.1.1.1.1.cmml" xref="S3.SS2.SSS1.p1.8.m2.1.1.1.1">subscript</csymbol><ci id="S3.SS2.SSS1.p1.8.m2.1.1.1.1.2.cmml" xref="S3.SS2.SSS1.p1.8.m2.1.1.1.1.2">italic-ϵ</ci><ci id="S3.SS2.SSS1.p1.8.m2.1.1.1.1.3a.cmml" xref="S3.SS2.SSS1.p1.8.m2.1.1.1.1.3"><mtext class="ltx_mathvariant_italic" id="S3.SS2.SSS1.p1.8.m2.1.1.1.1.3.cmml" mathsize="70%" xref="S3.SS2.SSS1.p1.8.m2.1.1.1.1.3">low</mtext></ci></apply><apply id="S3.SS2.SSS1.p1.8.m2.2.2.2.2.cmml" xref="S3.SS2.SSS1.p1.8.m2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p1.8.m2.2.2.2.2.1.cmml" xref="S3.SS2.SSS1.p1.8.m2.2.2.2.2">subscript</csymbol><ci id="S3.SS2.SSS1.p1.8.m2.2.2.2.2.2.cmml" xref="S3.SS2.SSS1.p1.8.m2.2.2.2.2.2">italic-ϵ</ci><ci id="S3.SS2.SSS1.p1.8.m2.2.2.2.2.3a.cmml" xref="S3.SS2.SSS1.p1.8.m2.2.2.2.2.3"><mtext class="ltx_mathvariant_italic" id="S3.SS2.SSS1.p1.8.m2.2.2.2.2.3.cmml" mathsize="70%" xref="S3.SS2.SSS1.p1.8.m2.2.2.2.2.3">up</mtext></ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p1.8.m2.2c">\epsilon_{\textit{low}},\epsilon_{\textit{up}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p1.8.m2.2d">italic_ϵ start_POSTSUBSCRIPT low end_POSTSUBSCRIPT , italic_ϵ start_POSTSUBSCRIPT up end_POSTSUBSCRIPT</annotation></semantics></math> stand for the lower/upper similarity thresholds.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS2.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.2 </span>Optimizing ID/OOD Decision Boundary with Synthetic Samples</h4>
<div class="ltx_para" id="S3.SS2.SSS2.p1">
<p class="ltx_p" id="S3.SS2.SSS2.p1.1">Once we have obtained the ID and synthetic OOD objects, we employ a lightweight MLP, denoted as <math alttext="\mathcal{F}_{\text{ood}}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p1.1.m1.1"><semantics id="S3.SS2.SSS2.p1.1.m1.1a"><msub id="S3.SS2.SSS2.p1.1.m1.1.1" xref="S3.SS2.SSS2.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.SSS2.p1.1.m1.1.1.2" xref="S3.SS2.SSS2.p1.1.m1.1.1.2.cmml">ℱ</mi><mtext id="S3.SS2.SSS2.p1.1.m1.1.1.3" xref="S3.SS2.SSS2.p1.1.m1.1.1.3a.cmml">ood</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p1.1.m1.1b"><apply id="S3.SS2.SSS2.p1.1.m1.1.1.cmml" xref="S3.SS2.SSS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p1.1.m1.1.1.1.cmml" xref="S3.SS2.SSS2.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.SSS2.p1.1.m1.1.1.2.cmml" xref="S3.SS2.SSS2.p1.1.m1.1.1.2">ℱ</ci><ci id="S3.SS2.SSS2.p1.1.m1.1.1.3a.cmml" xref="S3.SS2.SSS2.p1.1.m1.1.1.3"><mtext id="S3.SS2.SSS2.p1.1.m1.1.1.3.cmml" mathsize="70%" xref="S3.SS2.SSS2.p1.1.m1.1.1.3">ood</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p1.1.m1.1c">\mathcal{F}_{\text{ood}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p1.1.m1.1d">caligraphic_F start_POSTSUBSCRIPT ood end_POSTSUBSCRIPT</annotation></semantics></math>, as the OOD detector optimized with a bi-classify loss:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E6">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{L}_{\text{ood}}=\mathbb{E}_{\textbf{z}\sim\textbf{z}^{\text{id}}}%
\left[-\log\frac{1}{1+\exp^{-\mathcal{F}_{\text{ood}}(\textbf{z})}}\right]+%
\mathbb{E}_{\textbf{z}\sim\textbf{z}^{\text{ood}}}\left[-\log\frac{\exp^{-%
\mathcal{F}_{\text{ood}}(\textbf{z})}}{1+\exp^{-\mathcal{F}_{\text{ood}}(%
\textbf{z})}}\right]." class="ltx_Math" display="block" id="S3.E6.m1.4"><semantics id="S3.E6.m1.4a"><mrow id="S3.E6.m1.4.4.1" xref="S3.E6.m1.4.4.1.1.cmml"><mrow id="S3.E6.m1.4.4.1.1" xref="S3.E6.m1.4.4.1.1.cmml"><msub id="S3.E6.m1.4.4.1.1.4" xref="S3.E6.m1.4.4.1.1.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E6.m1.4.4.1.1.4.2" xref="S3.E6.m1.4.4.1.1.4.2.cmml">ℒ</mi><mtext id="S3.E6.m1.4.4.1.1.4.3" xref="S3.E6.m1.4.4.1.1.4.3a.cmml">ood</mtext></msub><mo id="S3.E6.m1.4.4.1.1.3" xref="S3.E6.m1.4.4.1.1.3.cmml">=</mo><mrow id="S3.E6.m1.4.4.1.1.2" xref="S3.E6.m1.4.4.1.1.2.cmml"><mrow id="S3.E6.m1.4.4.1.1.1.1" xref="S3.E6.m1.4.4.1.1.1.1.cmml"><msub id="S3.E6.m1.4.4.1.1.1.1.3" xref="S3.E6.m1.4.4.1.1.1.1.3.cmml"><mi id="S3.E6.m1.4.4.1.1.1.1.3.2" xref="S3.E6.m1.4.4.1.1.1.1.3.2.cmml">𝔼</mi><mrow id="S3.E6.m1.4.4.1.1.1.1.3.3" xref="S3.E6.m1.4.4.1.1.1.1.3.3.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E6.m1.4.4.1.1.1.1.3.3.2" xref="S3.E6.m1.4.4.1.1.1.1.3.3.2a.cmml">z</mtext><mo id="S3.E6.m1.4.4.1.1.1.1.3.3.1" xref="S3.E6.m1.4.4.1.1.1.1.3.3.1.cmml">∼</mo><msup id="S3.E6.m1.4.4.1.1.1.1.3.3.3" xref="S3.E6.m1.4.4.1.1.1.1.3.3.3.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E6.m1.4.4.1.1.1.1.3.3.3.2" xref="S3.E6.m1.4.4.1.1.1.1.3.3.3.2a.cmml">z</mtext><mtext id="S3.E6.m1.4.4.1.1.1.1.3.3.3.3" xref="S3.E6.m1.4.4.1.1.1.1.3.3.3.3a.cmml">id</mtext></msup></mrow></msub><mo id="S3.E6.m1.4.4.1.1.1.1.2" xref="S3.E6.m1.4.4.1.1.1.1.2.cmml">⁢</mo><mrow id="S3.E6.m1.4.4.1.1.1.1.1.1" xref="S3.E6.m1.4.4.1.1.1.1.1.2.cmml"><mo id="S3.E6.m1.4.4.1.1.1.1.1.1.2" xref="S3.E6.m1.4.4.1.1.1.1.1.2.1.cmml">[</mo><mrow id="S3.E6.m1.4.4.1.1.1.1.1.1.1" xref="S3.E6.m1.4.4.1.1.1.1.1.1.1.cmml"><mo id="S3.E6.m1.4.4.1.1.1.1.1.1.1a" rspace="0.167em" xref="S3.E6.m1.4.4.1.1.1.1.1.1.1.cmml">−</mo><mrow id="S3.E6.m1.4.4.1.1.1.1.1.1.1.2" xref="S3.E6.m1.4.4.1.1.1.1.1.1.1.2.cmml"><mi id="S3.E6.m1.4.4.1.1.1.1.1.1.1.2.1" xref="S3.E6.m1.4.4.1.1.1.1.1.1.1.2.1.cmml">log</mi><mo id="S3.E6.m1.4.4.1.1.1.1.1.1.1.2a" lspace="0.167em" xref="S3.E6.m1.4.4.1.1.1.1.1.1.1.2.cmml">⁡</mo><mfrac id="S3.E6.m1.1.1" xref="S3.E6.m1.1.1.cmml"><mn id="S3.E6.m1.1.1.3" xref="S3.E6.m1.1.1.3.cmml">1</mn><mrow id="S3.E6.m1.1.1.1" xref="S3.E6.m1.1.1.1.cmml"><mn id="S3.E6.m1.1.1.1.3" xref="S3.E6.m1.1.1.1.3.cmml">1</mn><mo id="S3.E6.m1.1.1.1.2" xref="S3.E6.m1.1.1.1.2.cmml">+</mo><msup id="S3.E6.m1.1.1.1.4" xref="S3.E6.m1.1.1.1.4.cmml"><mi id="S3.E6.m1.1.1.1.4.2" xref="S3.E6.m1.1.1.1.4.2.cmml">exp</mi><mrow id="S3.E6.m1.1.1.1.1.1" xref="S3.E6.m1.1.1.1.1.1.cmml"><mo id="S3.E6.m1.1.1.1.1.1a" xref="S3.E6.m1.1.1.1.1.1.cmml">−</mo><mrow id="S3.E6.m1.1.1.1.1.1.3" xref="S3.E6.m1.1.1.1.1.1.3.cmml"><msub id="S3.E6.m1.1.1.1.1.1.3.2" xref="S3.E6.m1.1.1.1.1.1.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E6.m1.1.1.1.1.1.3.2.2" xref="S3.E6.m1.1.1.1.1.1.3.2.2.cmml">ℱ</mi><mtext id="S3.E6.m1.1.1.1.1.1.3.2.3" xref="S3.E6.m1.1.1.1.1.1.3.2.3a.cmml">ood</mtext></msub><mo id="S3.E6.m1.1.1.1.1.1.3.1" xref="S3.E6.m1.1.1.1.1.1.3.1.cmml">⁢</mo><mrow id="S3.E6.m1.1.1.1.1.1.3.3.2" xref="S3.E6.m1.1.1.1.1.1.1a.cmml"><mo id="S3.E6.m1.1.1.1.1.1.3.3.2.1" stretchy="false" xref="S3.E6.m1.1.1.1.1.1.1a.cmml">(</mo><mtext class="ltx_mathvariant_bold" id="S3.E6.m1.1.1.1.1.1.1" xref="S3.E6.m1.1.1.1.1.1.1.cmml">z</mtext><mo id="S3.E6.m1.1.1.1.1.1.3.3.2.2" stretchy="false" xref="S3.E6.m1.1.1.1.1.1.1a.cmml">)</mo></mrow></mrow></mrow></msup></mrow></mfrac></mrow></mrow><mo id="S3.E6.m1.4.4.1.1.1.1.1.1.3" xref="S3.E6.m1.4.4.1.1.1.1.1.2.1.cmml">]</mo></mrow></mrow><mo id="S3.E6.m1.4.4.1.1.2.3" xref="S3.E6.m1.4.4.1.1.2.3.cmml">+</mo><mrow id="S3.E6.m1.4.4.1.1.2.2" xref="S3.E6.m1.4.4.1.1.2.2.cmml"><msub id="S3.E6.m1.4.4.1.1.2.2.3" xref="S3.E6.m1.4.4.1.1.2.2.3.cmml"><mi id="S3.E6.m1.4.4.1.1.2.2.3.2" xref="S3.E6.m1.4.4.1.1.2.2.3.2.cmml">𝔼</mi><mrow id="S3.E6.m1.4.4.1.1.2.2.3.3" xref="S3.E6.m1.4.4.1.1.2.2.3.3.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E6.m1.4.4.1.1.2.2.3.3.2" xref="S3.E6.m1.4.4.1.1.2.2.3.3.2a.cmml">z</mtext><mo id="S3.E6.m1.4.4.1.1.2.2.3.3.1" xref="S3.E6.m1.4.4.1.1.2.2.3.3.1.cmml">∼</mo><msup id="S3.E6.m1.4.4.1.1.2.2.3.3.3" xref="S3.E6.m1.4.4.1.1.2.2.3.3.3.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E6.m1.4.4.1.1.2.2.3.3.3.2" xref="S3.E6.m1.4.4.1.1.2.2.3.3.3.2a.cmml">z</mtext><mtext id="S3.E6.m1.4.4.1.1.2.2.3.3.3.3" xref="S3.E6.m1.4.4.1.1.2.2.3.3.3.3a.cmml">ood</mtext></msup></mrow></msub><mo id="S3.E6.m1.4.4.1.1.2.2.2" xref="S3.E6.m1.4.4.1.1.2.2.2.cmml">⁢</mo><mrow id="S3.E6.m1.4.4.1.1.2.2.1.1" xref="S3.E6.m1.4.4.1.1.2.2.1.2.cmml"><mo id="S3.E6.m1.4.4.1.1.2.2.1.1.2" xref="S3.E6.m1.4.4.1.1.2.2.1.2.1.cmml">[</mo><mrow id="S3.E6.m1.4.4.1.1.2.2.1.1.1" xref="S3.E6.m1.4.4.1.1.2.2.1.1.1.cmml"><mo id="S3.E6.m1.4.4.1.1.2.2.1.1.1a" rspace="0.167em" xref="S3.E6.m1.4.4.1.1.2.2.1.1.1.cmml">−</mo><mrow id="S3.E6.m1.4.4.1.1.2.2.1.1.1.2" xref="S3.E6.m1.4.4.1.1.2.2.1.1.1.2.cmml"><mi id="S3.E6.m1.4.4.1.1.2.2.1.1.1.2.1" xref="S3.E6.m1.4.4.1.1.2.2.1.1.1.2.1.cmml">log</mi><mo id="S3.E6.m1.4.4.1.1.2.2.1.1.1.2a" lspace="0.167em" xref="S3.E6.m1.4.4.1.1.2.2.1.1.1.2.cmml">⁡</mo><mfrac id="S3.E6.m1.3.3" xref="S3.E6.m1.3.3.cmml"><msup id="S3.E6.m1.2.2.1" xref="S3.E6.m1.2.2.1.cmml"><mi id="S3.E6.m1.2.2.1.3" xref="S3.E6.m1.2.2.1.3.cmml">exp</mi><mrow id="S3.E6.m1.2.2.1.1.1" xref="S3.E6.m1.2.2.1.1.1.cmml"><mo id="S3.E6.m1.2.2.1.1.1a" xref="S3.E6.m1.2.2.1.1.1.cmml">−</mo><mrow id="S3.E6.m1.2.2.1.1.1.3" xref="S3.E6.m1.2.2.1.1.1.3.cmml"><msub id="S3.E6.m1.2.2.1.1.1.3.2" xref="S3.E6.m1.2.2.1.1.1.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E6.m1.2.2.1.1.1.3.2.2" xref="S3.E6.m1.2.2.1.1.1.3.2.2.cmml">ℱ</mi><mtext id="S3.E6.m1.2.2.1.1.1.3.2.3" xref="S3.E6.m1.2.2.1.1.1.3.2.3a.cmml">ood</mtext></msub><mo id="S3.E6.m1.2.2.1.1.1.3.1" xref="S3.E6.m1.2.2.1.1.1.3.1.cmml">⁢</mo><mrow id="S3.E6.m1.2.2.1.1.1.3.3.2" xref="S3.E6.m1.2.2.1.1.1.1a.cmml"><mo id="S3.E6.m1.2.2.1.1.1.3.3.2.1" stretchy="false" xref="S3.E6.m1.2.2.1.1.1.1a.cmml">(</mo><mtext class="ltx_mathvariant_bold" id="S3.E6.m1.2.2.1.1.1.1" xref="S3.E6.m1.2.2.1.1.1.1.cmml">z</mtext><mo id="S3.E6.m1.2.2.1.1.1.3.3.2.2" stretchy="false" xref="S3.E6.m1.2.2.1.1.1.1a.cmml">)</mo></mrow></mrow></mrow></msup><mrow id="S3.E6.m1.3.3.2" xref="S3.E6.m1.3.3.2.cmml"><mn id="S3.E6.m1.3.3.2.3" xref="S3.E6.m1.3.3.2.3.cmml">1</mn><mo id="S3.E6.m1.3.3.2.2" xref="S3.E6.m1.3.3.2.2.cmml">+</mo><msup id="S3.E6.m1.3.3.2.4" xref="S3.E6.m1.3.3.2.4.cmml"><mi id="S3.E6.m1.3.3.2.4.2" xref="S3.E6.m1.3.3.2.4.2.cmml">exp</mi><mrow id="S3.E6.m1.3.3.2.1.1" xref="S3.E6.m1.3.3.2.1.1.cmml"><mo id="S3.E6.m1.3.3.2.1.1a" xref="S3.E6.m1.3.3.2.1.1.cmml">−</mo><mrow id="S3.E6.m1.3.3.2.1.1.3" xref="S3.E6.m1.3.3.2.1.1.3.cmml"><msub id="S3.E6.m1.3.3.2.1.1.3.2" xref="S3.E6.m1.3.3.2.1.1.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E6.m1.3.3.2.1.1.3.2.2" xref="S3.E6.m1.3.3.2.1.1.3.2.2.cmml">ℱ</mi><mtext id="S3.E6.m1.3.3.2.1.1.3.2.3" xref="S3.E6.m1.3.3.2.1.1.3.2.3a.cmml">ood</mtext></msub><mo id="S3.E6.m1.3.3.2.1.1.3.1" xref="S3.E6.m1.3.3.2.1.1.3.1.cmml">⁢</mo><mrow id="S3.E6.m1.3.3.2.1.1.3.3.2" xref="S3.E6.m1.3.3.2.1.1.1a.cmml"><mo id="S3.E6.m1.3.3.2.1.1.3.3.2.1" stretchy="false" xref="S3.E6.m1.3.3.2.1.1.1a.cmml">(</mo><mtext class="ltx_mathvariant_bold" id="S3.E6.m1.3.3.2.1.1.1" xref="S3.E6.m1.3.3.2.1.1.1.cmml">z</mtext><mo id="S3.E6.m1.3.3.2.1.1.3.3.2.2" stretchy="false" xref="S3.E6.m1.3.3.2.1.1.1a.cmml">)</mo></mrow></mrow></mrow></msup></mrow></mfrac></mrow></mrow><mo id="S3.E6.m1.4.4.1.1.2.2.1.1.3" xref="S3.E6.m1.4.4.1.1.2.2.1.2.1.cmml">]</mo></mrow></mrow></mrow></mrow><mo id="S3.E6.m1.4.4.1.2" lspace="0em" xref="S3.E6.m1.4.4.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E6.m1.4b"><apply id="S3.E6.m1.4.4.1.1.cmml" xref="S3.E6.m1.4.4.1"><eq id="S3.E6.m1.4.4.1.1.3.cmml" xref="S3.E6.m1.4.4.1.1.3"></eq><apply id="S3.E6.m1.4.4.1.1.4.cmml" xref="S3.E6.m1.4.4.1.1.4"><csymbol cd="ambiguous" id="S3.E6.m1.4.4.1.1.4.1.cmml" xref="S3.E6.m1.4.4.1.1.4">subscript</csymbol><ci id="S3.E6.m1.4.4.1.1.4.2.cmml" xref="S3.E6.m1.4.4.1.1.4.2">ℒ</ci><ci id="S3.E6.m1.4.4.1.1.4.3a.cmml" xref="S3.E6.m1.4.4.1.1.4.3"><mtext id="S3.E6.m1.4.4.1.1.4.3.cmml" mathsize="70%" xref="S3.E6.m1.4.4.1.1.4.3">ood</mtext></ci></apply><apply id="S3.E6.m1.4.4.1.1.2.cmml" xref="S3.E6.m1.4.4.1.1.2"><plus id="S3.E6.m1.4.4.1.1.2.3.cmml" xref="S3.E6.m1.4.4.1.1.2.3"></plus><apply id="S3.E6.m1.4.4.1.1.1.1.cmml" xref="S3.E6.m1.4.4.1.1.1.1"><times id="S3.E6.m1.4.4.1.1.1.1.2.cmml" xref="S3.E6.m1.4.4.1.1.1.1.2"></times><apply id="S3.E6.m1.4.4.1.1.1.1.3.cmml" xref="S3.E6.m1.4.4.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E6.m1.4.4.1.1.1.1.3.1.cmml" xref="S3.E6.m1.4.4.1.1.1.1.3">subscript</csymbol><ci id="S3.E6.m1.4.4.1.1.1.1.3.2.cmml" xref="S3.E6.m1.4.4.1.1.1.1.3.2">𝔼</ci><apply id="S3.E6.m1.4.4.1.1.1.1.3.3.cmml" xref="S3.E6.m1.4.4.1.1.1.1.3.3"><csymbol cd="latexml" id="S3.E6.m1.4.4.1.1.1.1.3.3.1.cmml" xref="S3.E6.m1.4.4.1.1.1.1.3.3.1">similar-to</csymbol><ci id="S3.E6.m1.4.4.1.1.1.1.3.3.2a.cmml" xref="S3.E6.m1.4.4.1.1.1.1.3.3.2"><mtext class="ltx_mathvariant_bold" id="S3.E6.m1.4.4.1.1.1.1.3.3.2.cmml" mathsize="70%" xref="S3.E6.m1.4.4.1.1.1.1.3.3.2">z</mtext></ci><apply id="S3.E6.m1.4.4.1.1.1.1.3.3.3.cmml" xref="S3.E6.m1.4.4.1.1.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.E6.m1.4.4.1.1.1.1.3.3.3.1.cmml" xref="S3.E6.m1.4.4.1.1.1.1.3.3.3">superscript</csymbol><ci id="S3.E6.m1.4.4.1.1.1.1.3.3.3.2a.cmml" xref="S3.E6.m1.4.4.1.1.1.1.3.3.3.2"><mtext class="ltx_mathvariant_bold" id="S3.E6.m1.4.4.1.1.1.1.3.3.3.2.cmml" mathsize="70%" xref="S3.E6.m1.4.4.1.1.1.1.3.3.3.2">z</mtext></ci><ci id="S3.E6.m1.4.4.1.1.1.1.3.3.3.3a.cmml" xref="S3.E6.m1.4.4.1.1.1.1.3.3.3.3"><mtext id="S3.E6.m1.4.4.1.1.1.1.3.3.3.3.cmml" mathsize="50%" xref="S3.E6.m1.4.4.1.1.1.1.3.3.3.3">id</mtext></ci></apply></apply></apply><apply id="S3.E6.m1.4.4.1.1.1.1.1.2.cmml" xref="S3.E6.m1.4.4.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E6.m1.4.4.1.1.1.1.1.2.1.cmml" xref="S3.E6.m1.4.4.1.1.1.1.1.1.2">delimited-[]</csymbol><apply id="S3.E6.m1.4.4.1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.4.4.1.1.1.1.1.1.1"><minus id="S3.E6.m1.4.4.1.1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.4.4.1.1.1.1.1.1.1"></minus><apply id="S3.E6.m1.4.4.1.1.1.1.1.1.1.2.cmml" xref="S3.E6.m1.4.4.1.1.1.1.1.1.1.2"><log id="S3.E6.m1.4.4.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E6.m1.4.4.1.1.1.1.1.1.1.2.1"></log><apply id="S3.E6.m1.1.1.cmml" xref="S3.E6.m1.1.1"><divide id="S3.E6.m1.1.1.2.cmml" xref="S3.E6.m1.1.1"></divide><cn id="S3.E6.m1.1.1.3.cmml" type="integer" xref="S3.E6.m1.1.1.3">1</cn><apply id="S3.E6.m1.1.1.1.cmml" xref="S3.E6.m1.1.1.1"><plus id="S3.E6.m1.1.1.1.2.cmml" xref="S3.E6.m1.1.1.1.2"></plus><cn id="S3.E6.m1.1.1.1.3.cmml" type="integer" xref="S3.E6.m1.1.1.1.3">1</cn><apply id="S3.E6.m1.1.1.1.4.cmml" xref="S3.E6.m1.1.1.1.4"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.4.1.cmml" xref="S3.E6.m1.1.1.1.4">superscript</csymbol><exp id="S3.E6.m1.1.1.1.4.2.cmml" xref="S3.E6.m1.1.1.1.4.2"></exp><apply id="S3.E6.m1.1.1.1.1.1.cmml" xref="S3.E6.m1.1.1.1.1.1"><minus id="S3.E6.m1.1.1.1.1.1.2.cmml" xref="S3.E6.m1.1.1.1.1.1"></minus><apply id="S3.E6.m1.1.1.1.1.1.3.cmml" xref="S3.E6.m1.1.1.1.1.1.3"><times id="S3.E6.m1.1.1.1.1.1.3.1.cmml" xref="S3.E6.m1.1.1.1.1.1.3.1"></times><apply id="S3.E6.m1.1.1.1.1.1.3.2.cmml" xref="S3.E6.m1.1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.1.3.2.1.cmml" xref="S3.E6.m1.1.1.1.1.1.3.2">subscript</csymbol><ci id="S3.E6.m1.1.1.1.1.1.3.2.2.cmml" xref="S3.E6.m1.1.1.1.1.1.3.2.2">ℱ</ci><ci id="S3.E6.m1.1.1.1.1.1.3.2.3a.cmml" xref="S3.E6.m1.1.1.1.1.1.3.2.3"><mtext id="S3.E6.m1.1.1.1.1.1.3.2.3.cmml" mathsize="50%" xref="S3.E6.m1.1.1.1.1.1.3.2.3">ood</mtext></ci></apply><ci id="S3.E6.m1.1.1.1.1.1.1a.cmml" xref="S3.E6.m1.1.1.1.1.1.3.3.2"><mtext class="ltx_mathvariant_bold" id="S3.E6.m1.1.1.1.1.1.1.cmml" mathsize="70%" xref="S3.E6.m1.1.1.1.1.1.1">z</mtext></ci></apply></apply></apply></apply></apply></apply></apply></apply></apply><apply id="S3.E6.m1.4.4.1.1.2.2.cmml" xref="S3.E6.m1.4.4.1.1.2.2"><times id="S3.E6.m1.4.4.1.1.2.2.2.cmml" xref="S3.E6.m1.4.4.1.1.2.2.2"></times><apply id="S3.E6.m1.4.4.1.1.2.2.3.cmml" xref="S3.E6.m1.4.4.1.1.2.2.3"><csymbol cd="ambiguous" id="S3.E6.m1.4.4.1.1.2.2.3.1.cmml" xref="S3.E6.m1.4.4.1.1.2.2.3">subscript</csymbol><ci id="S3.E6.m1.4.4.1.1.2.2.3.2.cmml" xref="S3.E6.m1.4.4.1.1.2.2.3.2">𝔼</ci><apply id="S3.E6.m1.4.4.1.1.2.2.3.3.cmml" xref="S3.E6.m1.4.4.1.1.2.2.3.3"><csymbol cd="latexml" id="S3.E6.m1.4.4.1.1.2.2.3.3.1.cmml" xref="S3.E6.m1.4.4.1.1.2.2.3.3.1">similar-to</csymbol><ci id="S3.E6.m1.4.4.1.1.2.2.3.3.2a.cmml" xref="S3.E6.m1.4.4.1.1.2.2.3.3.2"><mtext class="ltx_mathvariant_bold" id="S3.E6.m1.4.4.1.1.2.2.3.3.2.cmml" mathsize="70%" xref="S3.E6.m1.4.4.1.1.2.2.3.3.2">z</mtext></ci><apply id="S3.E6.m1.4.4.1.1.2.2.3.3.3.cmml" xref="S3.E6.m1.4.4.1.1.2.2.3.3.3"><csymbol cd="ambiguous" id="S3.E6.m1.4.4.1.1.2.2.3.3.3.1.cmml" xref="S3.E6.m1.4.4.1.1.2.2.3.3.3">superscript</csymbol><ci id="S3.E6.m1.4.4.1.1.2.2.3.3.3.2a.cmml" xref="S3.E6.m1.4.4.1.1.2.2.3.3.3.2"><mtext class="ltx_mathvariant_bold" id="S3.E6.m1.4.4.1.1.2.2.3.3.3.2.cmml" mathsize="70%" xref="S3.E6.m1.4.4.1.1.2.2.3.3.3.2">z</mtext></ci><ci id="S3.E6.m1.4.4.1.1.2.2.3.3.3.3a.cmml" xref="S3.E6.m1.4.4.1.1.2.2.3.3.3.3"><mtext id="S3.E6.m1.4.4.1.1.2.2.3.3.3.3.cmml" mathsize="50%" xref="S3.E6.m1.4.4.1.1.2.2.3.3.3.3">ood</mtext></ci></apply></apply></apply><apply id="S3.E6.m1.4.4.1.1.2.2.1.2.cmml" xref="S3.E6.m1.4.4.1.1.2.2.1.1"><csymbol cd="latexml" id="S3.E6.m1.4.4.1.1.2.2.1.2.1.cmml" xref="S3.E6.m1.4.4.1.1.2.2.1.1.2">delimited-[]</csymbol><apply id="S3.E6.m1.4.4.1.1.2.2.1.1.1.cmml" xref="S3.E6.m1.4.4.1.1.2.2.1.1.1"><minus id="S3.E6.m1.4.4.1.1.2.2.1.1.1.1.cmml" xref="S3.E6.m1.4.4.1.1.2.2.1.1.1"></minus><apply id="S3.E6.m1.4.4.1.1.2.2.1.1.1.2.cmml" xref="S3.E6.m1.4.4.1.1.2.2.1.1.1.2"><log id="S3.E6.m1.4.4.1.1.2.2.1.1.1.2.1.cmml" xref="S3.E6.m1.4.4.1.1.2.2.1.1.1.2.1"></log><apply id="S3.E6.m1.3.3.cmml" xref="S3.E6.m1.3.3"><divide id="S3.E6.m1.3.3.3.cmml" xref="S3.E6.m1.3.3"></divide><apply id="S3.E6.m1.2.2.1.cmml" xref="S3.E6.m1.2.2.1"><csymbol cd="ambiguous" id="S3.E6.m1.2.2.1.2.cmml" xref="S3.E6.m1.2.2.1">superscript</csymbol><exp id="S3.E6.m1.2.2.1.3.cmml" xref="S3.E6.m1.2.2.1.3"></exp><apply id="S3.E6.m1.2.2.1.1.1.cmml" xref="S3.E6.m1.2.2.1.1.1"><minus id="S3.E6.m1.2.2.1.1.1.2.cmml" xref="S3.E6.m1.2.2.1.1.1"></minus><apply id="S3.E6.m1.2.2.1.1.1.3.cmml" xref="S3.E6.m1.2.2.1.1.1.3"><times id="S3.E6.m1.2.2.1.1.1.3.1.cmml" xref="S3.E6.m1.2.2.1.1.1.3.1"></times><apply id="S3.E6.m1.2.2.1.1.1.3.2.cmml" xref="S3.E6.m1.2.2.1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E6.m1.2.2.1.1.1.3.2.1.cmml" xref="S3.E6.m1.2.2.1.1.1.3.2">subscript</csymbol><ci id="S3.E6.m1.2.2.1.1.1.3.2.2.cmml" xref="S3.E6.m1.2.2.1.1.1.3.2.2">ℱ</ci><ci id="S3.E6.m1.2.2.1.1.1.3.2.3a.cmml" xref="S3.E6.m1.2.2.1.1.1.3.2.3"><mtext id="S3.E6.m1.2.2.1.1.1.3.2.3.cmml" mathsize="50%" xref="S3.E6.m1.2.2.1.1.1.3.2.3">ood</mtext></ci></apply><ci id="S3.E6.m1.2.2.1.1.1.1a.cmml" xref="S3.E6.m1.2.2.1.1.1.3.3.2"><mtext class="ltx_mathvariant_bold" id="S3.E6.m1.2.2.1.1.1.1.cmml" mathsize="70%" xref="S3.E6.m1.2.2.1.1.1.1">z</mtext></ci></apply></apply></apply><apply id="S3.E6.m1.3.3.2.cmml" xref="S3.E6.m1.3.3.2"><plus id="S3.E6.m1.3.3.2.2.cmml" xref="S3.E6.m1.3.3.2.2"></plus><cn id="S3.E6.m1.3.3.2.3.cmml" type="integer" xref="S3.E6.m1.3.3.2.3">1</cn><apply id="S3.E6.m1.3.3.2.4.cmml" xref="S3.E6.m1.3.3.2.4"><csymbol cd="ambiguous" id="S3.E6.m1.3.3.2.4.1.cmml" xref="S3.E6.m1.3.3.2.4">superscript</csymbol><exp id="S3.E6.m1.3.3.2.4.2.cmml" xref="S3.E6.m1.3.3.2.4.2"></exp><apply id="S3.E6.m1.3.3.2.1.1.cmml" xref="S3.E6.m1.3.3.2.1.1"><minus id="S3.E6.m1.3.3.2.1.1.2.cmml" xref="S3.E6.m1.3.3.2.1.1"></minus><apply id="S3.E6.m1.3.3.2.1.1.3.cmml" xref="S3.E6.m1.3.3.2.1.1.3"><times id="S3.E6.m1.3.3.2.1.1.3.1.cmml" xref="S3.E6.m1.3.3.2.1.1.3.1"></times><apply id="S3.E6.m1.3.3.2.1.1.3.2.cmml" xref="S3.E6.m1.3.3.2.1.1.3.2"><csymbol cd="ambiguous" id="S3.E6.m1.3.3.2.1.1.3.2.1.cmml" xref="S3.E6.m1.3.3.2.1.1.3.2">subscript</csymbol><ci id="S3.E6.m1.3.3.2.1.1.3.2.2.cmml" xref="S3.E6.m1.3.3.2.1.1.3.2.2">ℱ</ci><ci id="S3.E6.m1.3.3.2.1.1.3.2.3a.cmml" xref="S3.E6.m1.3.3.2.1.1.3.2.3"><mtext id="S3.E6.m1.3.3.2.1.1.3.2.3.cmml" mathsize="50%" xref="S3.E6.m1.3.3.2.1.1.3.2.3">ood</mtext></ci></apply><ci id="S3.E6.m1.3.3.2.1.1.1a.cmml" xref="S3.E6.m1.3.3.2.1.1.3.3.2"><mtext class="ltx_mathvariant_bold" id="S3.E6.m1.3.3.2.1.1.1.cmml" mathsize="70%" xref="S3.E6.m1.3.3.2.1.1.1">z</mtext></ci></apply></apply></apply></apply></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E6.m1.4c">\mathcal{L}_{\text{ood}}=\mathbb{E}_{\textbf{z}\sim\textbf{z}^{\text{id}}}%
\left[-\log\frac{1}{1+\exp^{-\mathcal{F}_{\text{ood}}(\textbf{z})}}\right]+%
\mathbb{E}_{\textbf{z}\sim\textbf{z}^{\text{ood}}}\left[-\log\frac{\exp^{-%
\mathcal{F}_{\text{ood}}(\textbf{z})}}{1+\exp^{-\mathcal{F}_{\text{ood}}(%
\textbf{z})}}\right].</annotation><annotation encoding="application/x-llamapun" id="S3.E6.m1.4d">caligraphic_L start_POSTSUBSCRIPT ood end_POSTSUBSCRIPT = blackboard_E start_POSTSUBSCRIPT z ∼ z start_POSTSUPERSCRIPT id end_POSTSUPERSCRIPT end_POSTSUBSCRIPT [ - roman_log divide start_ARG 1 end_ARG start_ARG 1 + roman_exp start_POSTSUPERSCRIPT - caligraphic_F start_POSTSUBSCRIPT ood end_POSTSUBSCRIPT ( z ) end_POSTSUPERSCRIPT end_ARG ] + blackboard_E start_POSTSUBSCRIPT z ∼ z start_POSTSUPERSCRIPT ood end_POSTSUPERSCRIPT end_POSTSUBSCRIPT [ - roman_log divide start_ARG roman_exp start_POSTSUPERSCRIPT - caligraphic_F start_POSTSUBSCRIPT ood end_POSTSUBSCRIPT ( z ) end_POSTSUPERSCRIPT end_ARG start_ARG 1 + roman_exp start_POSTSUPERSCRIPT - caligraphic_F start_POSTSUBSCRIPT ood end_POSTSUBSCRIPT ( z ) end_POSTSUPERSCRIPT end_ARG ] .</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS2.SSS2.p1.2">The aforementioned design ensures both <em class="ltx_emph ltx_font_italic" id="S3.SS2.SSS2.p1.2.1">semantic separability</em> and <em class="ltx_emph ltx_font_italic" id="S3.SS2.SSS2.p1.2.2">pattern similarity</em> for the chosen synthetic samples. As a result, our proposed method elegantly optimizes the decision boundary using only a limited number of samples. It is further demonstrated and validated in the following experiments.</p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>
<section class="ltx_subsubsection" id="S4.SS0.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.0.1 </span>Datasets</h4>
<div class="ltx_para" id="S4.SS0.SSS1.p1">
<p class="ltx_p" id="S4.SS0.SSS1.p1.1">Following OOD object detection setting <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib15" title="">15</a>]</cite>, we use the <span class="ltx_text ltx_font_bold" id="S4.SS0.SSS1.p1.1.1">PASCAL-VOC</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib16" title="">16</a>]</cite> and <span class="ltx_text ltx_font_bold" id="S4.SS0.SSS1.p1.1.2">Berkeley DeepDrive (BDD-100K)</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib65" title="">65</a>]</cite> as the ID training datasets, which consist of 20 and 10 ID categories, respectively.
Meanwhile, we evaluate the performance of our approach on two OOD datasets: <span class="ltx_text ltx_font_bold" id="S4.SS0.SSS1.p1.1.3">MS-COCO</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib36" title="">36</a>]</cite> and <span class="ltx_text ltx_font_bold" id="S4.SS0.SSS1.p1.1.4">OpenImages</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib32" title="">32</a>]</cite> respectively.
Categories from the OOD datasets that overlapped with the ID datasets are removed to guarantee the absence of ID categories. We report ID categories, OOD categories, and texts used in driving image synthesis in the supplementary material.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS0.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.0.2 </span>Metrics</h4>
<div class="ltx_para" id="S4.SS0.SSS2.p1">
<p class="ltx_p" id="S4.SS0.SSS2.p1.1">We primarily focus on reporting the <span class="ltx_text ltx_font_bold" id="S4.SS0.SSS2.p1.1.1">FPR95</span> which represents the false positive rate of OOD samples when the true positive rate of ID samples is at 95% and lower is better. FPR95 is widely used to assess the OOD object detection performance <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib15" title="">15</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib12" title="">12</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib61" title="">61</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib60" title="">60</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib59" title="">59</a>]</cite>. Additionally, we present the Area Under the Receiver Operating Characteristic Curve (<span class="ltx_text ltx_font_bold" id="S4.SS0.SSS2.p1.1.2">AUROC</span>, higher is better) that is widely utilized to evaluate binary classification problems. Since we only train a plugin MLP on top of existing object detectors for OOD detection, ID performance, <em class="ltx_emph ltx_font_italic" id="S4.SS0.SSS2.p1.1.3">e.g</em>.<span class="ltx_text" id="S4.SS0.SSS2.p1.1.4"></span>, mean Average Precision (mAP) is unchanged and thus omitted.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS0.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.0.3 </span>Implementation Details</h4>
<div class="ltx_para" id="S4.SS0.SSS3.p1">
<p class="ltx_p" id="S4.SS0.SSS3.p1.1">For our synthetic data, in order to maintain the experimental setting of OOD object detection and avoid leaking prior knowledge of foundation models, we <span class="ltx_text ltx_font_bold" id="S4.SS0.SSS3.p1.1.1">remove</span> all imagined novel objects that have the same or similar meaning as the ground truth OOD data categories. For model training, we follow the architectures of the baseline method <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib15" title="">15</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib59" title="">59</a>]</cite> to use a Faster R-CNN <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib48" title="">48</a>]</cite> as the base object detector with ResNet-50 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib20" title="">20</a>]</cite> firstly. Then we trained a simple and lightweight 3-layer MLP. We follow <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib59" title="">59</a>]</cite> to extract multi-level features as training samples. ID samples are extracted from ID images and OOD samples are extracted from selected synthesized images with OOD bounding boxes. For training on the PASCAL-VOC dataset, we employ a learning rate of 1e-4, while for the BDD-100K dataset, we use a learning rate of 5e-5. Both training processes utilize a momentum of 0.9, a dropout rate of 0.5, and a batch size of 32. All training is conducted on GeForce RTX 3090 GPUs.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Main Results on OOD Object Detection</h3>
<figure class="ltx_table" id="S4.T1">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T1.19.3.1" style="font-size:90%;">Table 1</span>: </span><span class="ltx_text" id="S4.T1.4.2" style="font-size:90%;">Comparing on varied ID (PASCAL VOC <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib16" title="">16</a>]</cite>, BDD-100K <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib65" title="">65</a>]</cite>) and OOD (MS-COCO <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib36" title="">36</a>]</cite>, OpenImages <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib32" title="">32</a>]</cite>) datasets, our method significantly outperforms other methods on different metrics and achieves SOTA performance on OOD object detection. Our method is validated on two different existing object detectors, Faster R-CNN <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib48" title="">48</a>]</cite> and VOS <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib15" title="">15</a>]</cite> (denoted as <em class="ltx_emph ltx_font_italic" id="S4.T1.4.2.1">Ours</em><math alttext="{}_{\text{+Faster-R-CNN}}" class="ltx_Math" display="inline" id="S4.T1.3.1.m1.1"><semantics id="S4.T1.3.1.m1.1b"><msub id="S4.T1.3.1.m1.1.1" xref="S4.T1.3.1.m1.1.1.cmml"><mi id="S4.T1.3.1.m1.1.1b" xref="S4.T1.3.1.m1.1.1.cmml"></mi><mtext id="S4.T1.3.1.m1.1.1.1" xref="S4.T1.3.1.m1.1.1.1a.cmml">+Faster-R-CNN</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.T1.3.1.m1.1c"><apply id="S4.T1.3.1.m1.1.1.cmml" xref="S4.T1.3.1.m1.1.1"><ci id="S4.T1.3.1.m1.1.1.1a.cmml" xref="S4.T1.3.1.m1.1.1.1"><mtext id="S4.T1.3.1.m1.1.1.1.cmml" mathsize="70%" xref="S4.T1.3.1.m1.1.1.1">+Faster-R-CNN</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.3.1.m1.1d">{}_{\text{+Faster-R-CNN}}</annotation><annotation encoding="application/x-llamapun" id="S4.T1.3.1.m1.1e">start_FLOATSUBSCRIPT +Faster-R-CNN end_FLOATSUBSCRIPT</annotation></semantics></math> and <em class="ltx_emph ltx_font_italic" id="S4.T1.4.2.2">Ours</em><math alttext="{}_{\text{+VOS}}" class="ltx_Math" display="inline" id="S4.T1.4.2.m2.1"><semantics id="S4.T1.4.2.m2.1b"><msub id="S4.T1.4.2.m2.1.1" xref="S4.T1.4.2.m2.1.1.cmml"><mi id="S4.T1.4.2.m2.1.1b" xref="S4.T1.4.2.m2.1.1.cmml"></mi><mtext id="S4.T1.4.2.m2.1.1.1" xref="S4.T1.4.2.m2.1.1.1a.cmml">+VOS</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.T1.4.2.m2.1c"><apply id="S4.T1.4.2.m2.1.1.cmml" xref="S4.T1.4.2.m2.1.1"><ci id="S4.T1.4.2.m2.1.1.1a.cmml" xref="S4.T1.4.2.m2.1.1.1"><mtext id="S4.T1.4.2.m2.1.1.1.cmml" mathsize="70%" xref="S4.T1.4.2.m2.1.1.1">+VOS</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.4.2.m2.1d">{}_{\text{+VOS}}</annotation><annotation encoding="application/x-llamapun" id="S4.T1.4.2.m2.1e">start_FLOATSUBSCRIPT +VOS end_FLOATSUBSCRIPT</annotation></semantics></math> respectively).
(Top results are shown in <span class="ltx_text ltx_font_bold" id="S4.T1.4.2.3">bold</span>.)</span></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T1.14" style="width:433.6pt;height:229.4pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-89.4pt,47.3pt) scale(0.707969848926744,0.707969848926744) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T1.14.10">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T1.14.10.11.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S4.T1.14.10.11.1.1" rowspan="3" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.14.10.11.1.1.1">Method</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="4" id="S4.T1.14.10.11.1.2" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.14.10.11.1.2.1">ID:PASCAL-VOC</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="4" id="S4.T1.14.10.11.1.3" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.14.10.11.1.3.1">ID:BDD-100K</span></th>
</tr>
<tr class="ltx_tr" id="S4.T1.14.10.12.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" colspan="2" id="S4.T1.14.10.12.2.1" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.14.10.12.2.1.1">MS-COCO</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" colspan="2" id="S4.T1.14.10.12.2.2" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.14.10.12.2.2.1">OpenImages</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" colspan="2" id="S4.T1.14.10.12.2.3" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.14.10.12.2.3.1">MS-COCO</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" colspan="2" id="S4.T1.14.10.12.2.4" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.14.10.12.2.4.1">OpenImages</span></th>
</tr>
<tr class="ltx_tr" id="S4.T1.12.8.8">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.5.1.1.1" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.5.1.1.1.1">FPR95<math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T1.5.1.1.1.1.m1.1"><semantics id="S4.T1.5.1.1.1.1.m1.1a"><mo id="S4.T1.5.1.1.1.1.m1.1.1" stretchy="false" xref="S4.T1.5.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T1.5.1.1.1.1.m1.1b"><ci id="S4.T1.5.1.1.1.1.m1.1.1.cmml" xref="S4.T1.5.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.5.1.1.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T1.5.1.1.1.1.m1.1d">↓</annotation></semantics></math></span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.6.2.2.2" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.6.2.2.2.1">AUROC<math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T1.6.2.2.2.1.m1.1"><semantics id="S4.T1.6.2.2.2.1.m1.1a"><mo id="S4.T1.6.2.2.2.1.m1.1.1" stretchy="false" xref="S4.T1.6.2.2.2.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T1.6.2.2.2.1.m1.1b"><ci id="S4.T1.6.2.2.2.1.m1.1.1.cmml" xref="S4.T1.6.2.2.2.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.6.2.2.2.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T1.6.2.2.2.1.m1.1d">↑</annotation></semantics></math></span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.7.3.3.3" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.7.3.3.3.1">FPR95<math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T1.7.3.3.3.1.m1.1"><semantics id="S4.T1.7.3.3.3.1.m1.1a"><mo id="S4.T1.7.3.3.3.1.m1.1.1" stretchy="false" xref="S4.T1.7.3.3.3.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T1.7.3.3.3.1.m1.1b"><ci id="S4.T1.7.3.3.3.1.m1.1.1.cmml" xref="S4.T1.7.3.3.3.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.7.3.3.3.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T1.7.3.3.3.1.m1.1d">↓</annotation></semantics></math></span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.8.4.4.4" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.8.4.4.4.1">AUROC<math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T1.8.4.4.4.1.m1.1"><semantics id="S4.T1.8.4.4.4.1.m1.1a"><mo id="S4.T1.8.4.4.4.1.m1.1.1" stretchy="false" xref="S4.T1.8.4.4.4.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T1.8.4.4.4.1.m1.1b"><ci id="S4.T1.8.4.4.4.1.m1.1.1.cmml" xref="S4.T1.8.4.4.4.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.8.4.4.4.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T1.8.4.4.4.1.m1.1d">↑</annotation></semantics></math></span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.9.5.5.5" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.9.5.5.5.1">FPR95<math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T1.9.5.5.5.1.m1.1"><semantics id="S4.T1.9.5.5.5.1.m1.1a"><mo id="S4.T1.9.5.5.5.1.m1.1.1" stretchy="false" xref="S4.T1.9.5.5.5.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T1.9.5.5.5.1.m1.1b"><ci id="S4.T1.9.5.5.5.1.m1.1.1.cmml" xref="S4.T1.9.5.5.5.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.9.5.5.5.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T1.9.5.5.5.1.m1.1d">↓</annotation></semantics></math></span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.10.6.6.6" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.10.6.6.6.1">AUROC<math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T1.10.6.6.6.1.m1.1"><semantics id="S4.T1.10.6.6.6.1.m1.1a"><mo id="S4.T1.10.6.6.6.1.m1.1.1" stretchy="false" xref="S4.T1.10.6.6.6.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T1.10.6.6.6.1.m1.1b"><ci id="S4.T1.10.6.6.6.1.m1.1.1.cmml" xref="S4.T1.10.6.6.6.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.10.6.6.6.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T1.10.6.6.6.1.m1.1d">↑</annotation></semantics></math></span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.11.7.7.7" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.11.7.7.7.1">FPR95<math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T1.11.7.7.7.1.m1.1"><semantics id="S4.T1.11.7.7.7.1.m1.1a"><mo id="S4.T1.11.7.7.7.1.m1.1.1" stretchy="false" xref="S4.T1.11.7.7.7.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T1.11.7.7.7.1.m1.1b"><ci id="S4.T1.11.7.7.7.1.m1.1.1.cmml" xref="S4.T1.11.7.7.7.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.11.7.7.7.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T1.11.7.7.7.1.m1.1d">↓</annotation></semantics></math></span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.12.8.8.8" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.12.8.8.8.1">AUROC<math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T1.12.8.8.8.1.m1.1"><semantics id="S4.T1.12.8.8.8.1.m1.1a"><mo id="S4.T1.12.8.8.8.1.m1.1.1" stretchy="false" xref="S4.T1.12.8.8.8.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T1.12.8.8.8.1.m1.1b"><ci id="S4.T1.12.8.8.8.1.m1.1.1.cmml" xref="S4.T1.12.8.8.8.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.12.8.8.8.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T1.12.8.8.8.1.m1.1d">↑</annotation></semantics></math></span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T1.14.10.13.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T1.14.10.13.1.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">MSP <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib22" title="">22</a>]</cite>
</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.14.10.13.1.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">70.99</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.14.10.13.1.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">83.45</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.14.10.13.1.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">73.13</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.14.10.13.1.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">81.91</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.14.10.13.1.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">80.94</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.14.10.13.1.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">75.87</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.14.10.13.1.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">79.04</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.14.10.13.1.9" style="padding-top:0.5pt;padding-bottom:0.5pt;">77.38</td>
</tr>
<tr class="ltx_tr" id="S4.T1.14.10.14.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.14.10.14.2.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">ODIN <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib35" title="">35</a>]</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.14.2.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">59.82</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.14.2.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">82.20</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.14.2.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">63.14</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.14.2.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">82.59</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.14.2.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">62.85</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.14.2.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">74.44</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.14.2.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">58.92</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.14.2.9" style="padding-top:0.5pt;padding-bottom:0.5pt;">76.61</td>
</tr>
<tr class="ltx_tr" id="S4.T1.14.10.15.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.14.10.15.3.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">Mahalanobis <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib34" title="">34</a>]</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.15.3.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">96.46</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.15.3.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">59.25</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.15.3.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">96.27</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.15.3.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">57.42</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.15.3.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">57.66</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.15.3.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">84.92</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.15.3.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">60.16</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.15.3.9" style="padding-top:0.5pt;padding-bottom:0.5pt;">86.88</td>
</tr>
<tr class="ltx_tr" id="S4.T1.14.10.16.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.14.10.16.4.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">Energy score <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib38" title="">38</a>]</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.16.4.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">56.89</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.16.4.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">83.69</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.16.4.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">58.69</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.16.4.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">82.98</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.16.4.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">60.06</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.16.4.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">77.48</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.16.4.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">54.79</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.16.4.9" style="padding-top:0.5pt;padding-bottom:0.5pt;">79.60</td>
</tr>
<tr class="ltx_tr" id="S4.T1.14.10.17.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.14.10.17.5.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">Gram matrices <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib50" title="">50</a>]</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.17.5.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">62.75</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.17.5.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">79.88</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.17.5.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">67.42</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.17.5.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">77.62</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.17.5.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">60.93</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.17.5.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">74.93</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.17.5.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">77.55</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.17.5.9" style="padding-top:0.5pt;padding-bottom:0.5pt;">59.38</td>
</tr>
<tr class="ltx_tr" id="S4.T1.14.10.18.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.14.10.18.6.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">Generalized ODIN <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib25" title="">25</a>]</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.18.6.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">58.57</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.18.6.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">83.12</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.18.6.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">70.28</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.18.6.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">79.23</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.18.6.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">57.27</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.18.6.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">85.22</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.18.6.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">50.17</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.18.6.9" style="padding-top:0.5pt;padding-bottom:0.5pt;">87.18</td>
</tr>
<tr class="ltx_tr" id="S4.T1.14.10.19.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.14.10.19.7.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">CSI <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib52" title="">52</a>]</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.19.7.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">59.91</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.19.7.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">81.83</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.19.7.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">57.41</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.19.7.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">82.95</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.19.7.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">47.10</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.19.7.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">84.09</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.19.7.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">37.06</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.19.7.9" style="padding-top:0.5pt;padding-bottom:0.5pt;">87.99</td>
</tr>
<tr class="ltx_tr" id="S4.T1.14.10.20.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.14.10.20.8.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">GAN-synthesis <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib33" title="">33</a>]</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.20.8.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">60.93</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.20.8.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">83.67</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.20.8.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">59.97</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.20.8.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">82.67</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.20.8.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">57.03</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.20.8.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">78.82</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.20.8.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">50.61</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.20.8.9" style="padding-top:0.5pt;padding-bottom:0.5pt;">81.25</td>
</tr>
<tr class="ltx_tr" id="S4.T1.14.10.21.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.14.10.21.9.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">SIREN-KNN <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib12" title="">12</a>]</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.21.9.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">47.45</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.21.9.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">89.67</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.21.9.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">50.38</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.21.9.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">88.80</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.21.9.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">-</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.21.9.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">-</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.21.9.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">-</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.21.9.9" style="padding-top:0.5pt;padding-bottom:0.5pt;">-</td>
</tr>
<tr class="ltx_tr" id="S4.T1.14.10.22.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.14.10.22.10.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">VOS <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib15" title="">15</a>]</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.22.10.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">47.53</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.22.10.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">88.70</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.22.10.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">51.33</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.22.10.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">85.23</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.22.10.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">44.27</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.22.10.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">86.87</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.22.10.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">35.54</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.22.10.9" style="padding-top:0.5pt;padding-bottom:0.5pt;">88.52</td>
</tr>
<tr class="ltx_tr" id="S4.T1.14.10.23.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.14.10.23.11.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">SR-VAE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib61" title="">61</a>]</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.23.11.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">42.17</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.23.11.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">90.28</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.23.11.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">46.26</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.23.11.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">87.89</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.23.11.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">32.23</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.23.11.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">90.69</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.23.11.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">21.81</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.23.11.9" style="padding-top:0.5pt;padding-bottom:0.5pt;">93.55</td>
</tr>
<tr class="ltx_tr" id="S4.T1.14.10.24.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.14.10.24.12.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">DFDD <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib60" title="">60</a>]</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.24.12.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">41.34</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.24.12.3" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.14.10.24.12.3.1">90.79</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.24.12.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">44.52</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.24.12.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">88.65</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.24.12.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">30.71</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.24.12.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">90.74</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.24.12.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">22.67</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.24.12.9" style="padding-top:0.5pt;padding-bottom:0.5pt;">92.48</td>
</tr>
<tr class="ltx_tr" id="S4.T1.14.10.25.13">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.14.10.25.13.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">SAFE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib59" title="">59</a>]</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.25.13.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">47.40</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.25.13.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">80.30</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.25.13.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">20.06</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.25.13.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">92.28</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.25.13.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">32.56</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.25.13.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">88.96</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.25.13.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">16.04</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.10.25.13.9" style="padding-top:0.5pt;padding-bottom:0.5pt;">94.64</td>
</tr>
<tr class="ltx_tr" id="S4.T1.13.9.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.13.9.9.1" style="background-color:#E6E6E6;padding-top:0.5pt;padding-bottom:0.5pt;">
<em class="ltx_emph ltx_font_italic" id="S4.T1.13.9.9.1.1" style="background-color:#E6E6E6;">Ours</em><math alttext="{}_{\text{+Faster-R-CNN}}" class="ltx_Math" display="inline" id="S4.T1.13.9.9.1.m1.1" style="background-color:#E6E6E6;"><semantics id="S4.T1.13.9.9.1.m1.1a"><msub id="S4.T1.13.9.9.1.m1.1.1" xref="S4.T1.13.9.9.1.m1.1.1.cmml"><mi id="S4.T1.13.9.9.1.m1.1.1a" xref="S4.T1.13.9.9.1.m1.1.1.cmml"></mi><mtext id="S4.T1.13.9.9.1.m1.1.1.1" mathbackground="#E6E6E6" xref="S4.T1.13.9.9.1.m1.1.1.1a.cmml">+Faster-R-CNN</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.T1.13.9.9.1.m1.1b"><apply id="S4.T1.13.9.9.1.m1.1.1.cmml" xref="S4.T1.13.9.9.1.m1.1.1"><ci id="S4.T1.13.9.9.1.m1.1.1.1a.cmml" xref="S4.T1.13.9.9.1.m1.1.1.1"><mtext id="S4.T1.13.9.9.1.m1.1.1.1.cmml" mathbackground="#E6E6E6" mathsize="70%" xref="S4.T1.13.9.9.1.m1.1.1.1">+Faster-R-CNN</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.13.9.9.1.m1.1c">{}_{\text{+Faster-R-CNN}}</annotation><annotation encoding="application/x-llamapun" id="S4.T1.13.9.9.1.m1.1d">start_FLOATSUBSCRIPT +Faster-R-CNN end_FLOATSUBSCRIPT</annotation></semantics></math>
</th>
<td class="ltx_td ltx_align_center" id="S4.T1.13.9.9.2" style="background-color:#E6E6E6;padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.13.9.9.2.1" style="background-color:#E6E6E6;">36.44</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.13.9.9.3" style="background-color:#E6E6E6;padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="S4.T1.13.9.9.3.1" style="background-color:#E6E6E6;">86.52</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.13.9.9.4" style="background-color:#E6E6E6;padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.13.9.9.4.1" style="background-color:#E6E6E6;">13.34</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.13.9.9.5" style="background-color:#E6E6E6;padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.13.9.9.5.1" style="background-color:#E6E6E6;">95.37</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.13.9.9.6" style="background-color:#E6E6E6;padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.13.9.9.6.1" style="background-color:#E6E6E6;">22.67</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.13.9.9.7" style="background-color:#E6E6E6;padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.13.9.9.7.1" style="background-color:#E6E6E6;">95.44</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.13.9.9.8" style="background-color:#E6E6E6;padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.13.9.9.8.1" style="background-color:#E6E6E6;">12.96</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.13.9.9.9" style="background-color:#E6E6E6;padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.13.9.9.9.1" style="background-color:#E6E6E6;">96.26</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.14.10.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S4.T1.14.10.10.1" style="background-color:#E6E6E6;padding-top:0.5pt;padding-bottom:0.5pt;">
<em class="ltx_emph ltx_font_italic" id="S4.T1.14.10.10.1.1" style="background-color:#E6E6E6;">Ours</em><math alttext="{}_{\text{+VOS}}" class="ltx_Math" display="inline" id="S4.T1.14.10.10.1.m1.1" style="background-color:#E6E6E6;"><semantics id="S4.T1.14.10.10.1.m1.1a"><msub id="S4.T1.14.10.10.1.m1.1.1" xref="S4.T1.14.10.10.1.m1.1.1.cmml"><mi id="S4.T1.14.10.10.1.m1.1.1a" xref="S4.T1.14.10.10.1.m1.1.1.cmml"></mi><mtext id="S4.T1.14.10.10.1.m1.1.1.1" mathbackground="#E6E6E6" xref="S4.T1.14.10.10.1.m1.1.1.1a.cmml">+VOS</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.T1.14.10.10.1.m1.1b"><apply id="S4.T1.14.10.10.1.m1.1.1.cmml" xref="S4.T1.14.10.10.1.m1.1.1"><ci id="S4.T1.14.10.10.1.m1.1.1.1a.cmml" xref="S4.T1.14.10.10.1.m1.1.1.1"><mtext id="S4.T1.14.10.10.1.m1.1.1.1.cmml" mathbackground="#E6E6E6" mathsize="70%" xref="S4.T1.14.10.10.1.m1.1.1.1">+VOS</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.14.10.10.1.m1.1c">{}_{\text{+VOS}}</annotation><annotation encoding="application/x-llamapun" id="S4.T1.14.10.10.1.m1.1d">start_FLOATSUBSCRIPT +VOS end_FLOATSUBSCRIPT</annotation></semantics></math>
</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.14.10.10.2" style="background-color:#E6E6E6;padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.14.10.10.2.1" style="background-color:#E6E6E6;">34.97</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.14.10.10.3" style="background-color:#E6E6E6;padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="S4.T1.14.10.10.3.1" style="background-color:#E6E6E6;">87.90</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.14.10.10.4" style="background-color:#E6E6E6;padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.14.10.10.4.1" style="background-color:#E6E6E6;">11.25</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.14.10.10.5" style="background-color:#E6E6E6;padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.14.10.10.5.1" style="background-color:#E6E6E6;">96.96</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.14.10.10.6" style="background-color:#E6E6E6;padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.14.10.10.6.1" style="background-color:#E6E6E6;">23.09</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.14.10.10.7" style="background-color:#E6E6E6;padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.14.10.10.7.1" style="background-color:#E6E6E6;">94.32</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.14.10.10.8" style="background-color:#E6E6E6;padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.14.10.10.8.1" style="background-color:#E6E6E6;">14.12</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.14.10.10.9" style="background-color:#E6E6E6;padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.14.10.10.9.1" style="background-color:#E6E6E6;">96.41</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">We evaluate the performance of the proposed method on different challenging benchmarks and obtain notable results (see <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S4.T1" title="In 4.1 Main Results on OOD Object Detection ‣ 4 Experiments ‣ Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">1</span></a>). As the first work to introduce synthetic scene-level natural images as OOD samples, we incorporate our data-centric method to two off-the-shelf object detectors <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib48" title="">48</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib15" title="">15</a>]</cite>, achieving new state-of-the-art performance in OOD object detection.</p>
</div>
<div class="ltx_para" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1">Compared with previous methods, we present comprehensive and substantial performance improvements on FPR95. The encouraging outcomes clearly show that our synthetic data offers superior OOD supervision and are well-suited for forming a precise decision boundary between ID and OOD samples as illustrated in <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S1.F1" title="In 1 Introduction ‣ Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">1</span></a>, which significantly reduces the interference caused by contextual information when optimizing the decision boundary.</p>
</div>
<div class="ltx_para" id="S4.SS1.p3">
<p class="ltx_p" id="S4.SS1.p3.1">Bridged by our synthetic data, foundation models’ extensive knowledge and powerful logic about novel concepts are effectively injected into our model through novel concept imagining and region-level editing.
Furthermore, powered by the similarity-based filter, our synthetic data proves to be highly effective. Compared with SAFE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib59" title="">59</a>]</cite> which uses a similar framework, we only use around 25% (on PASCAL-VOC) and 20% (on BDD-100K) of auxiliary data to achieve a significant performance improvement. Further analysis is presented in <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S4.SS2" title="4.2 Ablation Study ‣ 4 Experiments ‣ Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_tag">Sec.</span> <span class="ltx_text ltx_ref_tag">4.2</span></a>.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Ablation Study</h3>
<figure class="ltx_table" id="S4.T2">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T2.4.1.1" style="font-size:90%;">Table 2</span>: </span><span class="ltx_text" id="S4.T2.5.2" style="font-size:90%;">Ablation on the number of our synthetic data in training. Taking PASCAL-VOC as the ID dataset, we perform seven groups of random sampling with different numbers in the synthetic dataset to extract features as OOD samples, evaluate and report the performance on the MS-COCO/OpenImages datasets.</span></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T2.2" style="width:433.6pt;height:57.4pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(13.0pt,-1.7pt) scale(1.06376912935377,1.06376912935377) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T2.2.2">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T2.2.2.3.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S4.T2.2.2.3.1.1" style="padding:0.25pt 3.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.2.2.3.1.1.1" style="font-size:90%;">#Sample</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T2.2.2.3.1.2" style="padding:0.25pt 3.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.2.2.3.1.2.1" style="font-size:90%;">14k</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T2.2.2.3.1.3" style="padding:0.25pt 3.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.2.2.3.1.3.1" style="font-size:90%;">12k</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T2.2.2.3.1.4" style="padding:0.25pt 3.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.2.2.3.1.4.1" style="font-size:90%;">10k</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T2.2.2.3.1.5" style="padding:0.25pt 3.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.2.2.3.1.5.1" style="font-size:90%;">8k</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T2.2.2.3.1.6" style="padding:0.25pt 3.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.2.2.3.1.6.1" style="font-size:90%;">6k</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T2.2.2.3.1.7" style="background-color:#E6E6E6;padding:0.25pt 3.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.2.2.3.1.7.1" style="font-size:90%;background-color:#E6E6E6;">4k</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T2.2.2.3.1.8" style="padding:0.25pt 3.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.2.2.3.1.8.1" style="font-size:90%;">2k</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T2.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T2.1.1.1.1" style="padding:0.25pt 3.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.1.1" style="font-size:90%;">FPR95<math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T2.1.1.1.1.1.m1.1"><semantics id="S4.T2.1.1.1.1.1.m1.1a"><mo id="S4.T2.1.1.1.1.1.m1.1.1" stretchy="false" xref="S4.T2.1.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T2.1.1.1.1.1.m1.1b"><ci id="S4.T2.1.1.1.1.1.m1.1.1.cmml" xref="S4.T2.1.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.1.1.1.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T2.1.1.1.1.1.m1.1d">↓</annotation></semantics></math></span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.1.2" style="padding:0.25pt 3.0pt;"><span class="ltx_text" id="S4.T2.1.1.1.2.1" style="font-size:90%;">36.70/12.96</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.1.3" style="padding:0.25pt 3.0pt;"><span class="ltx_text" id="S4.T2.1.1.1.3.1" style="font-size:90%;">36.27/13.01</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.1.4" style="padding:0.25pt 3.0pt;"><span class="ltx_text" id="S4.T2.1.1.1.4.1" style="font-size:90%;">37.31/13.25</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.1.5" style="padding:0.25pt 3.0pt;"><span class="ltx_text" id="S4.T2.1.1.1.5.1" style="font-size:90%;">36.53/13.30</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.1.6" style="padding:0.25pt 3.0pt;"><span class="ltx_text" id="S4.T2.1.1.1.6.1" style="font-size:90%;">36.70/12.96</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.1.7" style="background-color:#E6E6E6;padding:0.25pt 3.0pt;"><span class="ltx_text" id="S4.T2.1.1.1.7.1" style="font-size:90%;background-color:#E6E6E6;">36.44/13.34</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.1.8" style="padding:0.25pt 3.0pt;"><span class="ltx_text" id="S4.T2.1.1.1.8.1" style="font-size:90%;">37.82/13.87</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.2.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S4.T2.2.2.2.1" style="padding:0.25pt 3.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.2.2.2.1.1" style="font-size:90%;">AUROC<math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T2.2.2.2.1.1.m1.1"><semantics id="S4.T2.2.2.2.1.1.m1.1a"><mo id="S4.T2.2.2.2.1.1.m1.1.1" stretchy="false" xref="S4.T2.2.2.2.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T2.2.2.2.1.1.m1.1b"><ci id="S4.T2.2.2.2.1.1.m1.1.1.cmml" xref="S4.T2.2.2.2.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.2.2.2.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T2.2.2.2.1.1.m1.1d">↑</annotation></semantics></math></span></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.2.2.2.2" style="padding:0.25pt 3.0pt;"><span class="ltx_text" id="S4.T2.2.2.2.2.1" style="font-size:90%;">86.65/95.54</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.2.2.2.3" style="padding:0.25pt 3.0pt;"><span class="ltx_text" id="S4.T2.2.2.2.3.1" style="font-size:90%;">86.68/95.55</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.2.2.2.4" style="padding:0.25pt 3.0pt;"><span class="ltx_text" id="S4.T2.2.2.2.4.1" style="font-size:90%;">86.64/95.51</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.2.2.2.5" style="padding:0.25pt 3.0pt;"><span class="ltx_text" id="S4.T2.2.2.2.5.1" style="font-size:90%;">86.69/95.52</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.2.2.2.6" style="padding:0.25pt 3.0pt;"><span class="ltx_text" id="S4.T2.2.2.2.6.1" style="font-size:90%;">86.75/95.56</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.2.2.2.7" style="background-color:#E6E6E6;padding:0.25pt 3.0pt;"><span class="ltx_text" id="S4.T2.2.2.2.7.1" style="font-size:90%;background-color:#E6E6E6;">86.52/95.44</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.2.2.2.8" style="padding:0.25pt 3.0pt;"><span class="ltx_text" id="S4.T2.2.2.2.8.1" style="font-size:90%;">86.03/95.18</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<section class="ltx_subsubsection" id="S4.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.1 </span>Number of Training Samples</h4>
<div class="ltx_para" id="S4.SS2.SSS1.p1">
<p class="ltx_p" id="S4.SS2.SSS1.p1.1">We conduct an extensive ablation study on the quantity of synthetic data utilized, as illustrated in <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S4.T2" title="In 4.2 Ablation Study ‣ 4 Experiments ‣ Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">2</span></a>. We employ seven sets of synthetic data with varying quantities as OOD samples, using PASCAL-VOC as the ID dataset. Features are extracted and the OOD detector is trained based on the same Faster R-CNN checkpoint for each set. It is noteworthy that as the number of samples decreases from 14k to 2k, the performance does not deteriorate but rather maintains stable and superior results. This highlights our method’s data efficiency (SAFE used 16k samples). Combined with our feature similarity-based filtering strategy as in <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S3.SS2" title="3.2 Mining Hard OOD Samples and Model Training ‣ 3 Method ‣ Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_tag">Sec.</span> <span class="ltx_text ltx_ref_tag">3.2</span></a>, a small number of high-quality OOD samples with <em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS1.p1.1.1">visual similarity</em> directly promotes the optimization of precise decision boundaries to achieve stable improvements.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS1.p2">
<p class="ltx_p" id="S4.SS2.SSS1.p2.1">Meanwhile, we use the same detector checkpoint to assess the parallel baseline, SAFE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib59" title="">59</a>]</cite>, and get the performance of <span class="ltx_text ltx_font_bold" id="S4.SS2.SSS1.p2.1.1">50.86/23.60</span> on <span class="ltx_text ltx_font_bold" id="S4.SS2.SSS1.p2.1.2">FPR95</span> and <span class="ltx_text ltx_font_bold" id="S4.SS2.SSS1.p2.1.3">78.15/91.42</span> on <span class="ltx_text ltx_font_bold" id="S4.SS2.SSS1.p2.1.4">AUROC</span>. SAFE augments about 16k images and extracts more than 100k instance-level features as OOD samples. In contrast, our approach utilizes fewer synthetic images and extracts only one instance-level feature from the edited novel object in each synthetic image as an OOD sample, resulting in significantly superior performance compared to SAFE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib59" title="">59</a>]</cite>.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS2.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.2 </span>Number of Concepts to Imagine</h4>
<div class="ltx_para" id="S4.SS2.SSS2.p1">
<p class="ltx_p" id="S4.SS2.SSS2.p1.1">We employ in-context learning to guide LLM in associating new objects for driving image editing.
For each ID obejct, the LLM connects a steady stream of novel objects. We further explore the impact of the number of corresponding novel objects for each ID object on data performance. We randomly sample different numbers of novel objects from LLM’s responses for each ID object.
As shown in <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S4.T3" title="In 4.2.2 Number of Concepts to Imagine ‣ 4.2 Ablation Study ‣ 4 Experiments ‣ Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">3</span></a>, the performance remains stable despite changes in the number of concepts, further highlighting the stability and robustness of our synthetic data.</p>
</div>
<figure class="ltx_table" id="S4.T3">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T3.4.1.1" style="font-size:90%;">Table 3</span>: </span><span class="ltx_text" id="S4.T3.5.2" style="font-size:90%;">We study the impact of associating varying numbers of imagined novel objects with each ID object. Taking PASCAL-VOC as the ID dataset, we report the performance on MS-COCO/OpenImages datasets.</span></figcaption>
<div class="ltx_inline-block ltx_transformed_outer" id="S4.T3.2" style="width:433.6pt;height:65.1pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(37.1pt,-5.6pt) scale(1.20631203963745,1.20631203963745) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T3.2.2">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T3.2.2.3.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S4.T3.2.2.3.1.1" style="padding:0.25pt 3.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.2.2.3.1.1.1" style="font-size:90%;">#Sample</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T3.2.2.3.1.2" style="padding:0.25pt 3.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.2.2.3.1.2.1" style="font-size:90%;">3</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T3.2.2.3.1.3" style="padding:0.25pt 3.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.2.2.3.1.3.1" style="font-size:90%;">4</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T3.2.2.3.1.4" style="background-color:#E6E6E6;padding:0.25pt 3.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.2.2.3.1.4.1" style="font-size:90%;background-color:#E6E6E6;">5</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T3.2.2.3.1.5" style="padding:0.25pt 3.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.2.2.3.1.5.1" style="font-size:90%;">6</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T3.2.2.3.1.6" style="padding:0.25pt 3.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.2.2.3.1.6.1" style="font-size:90%;">7</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T3.2.2.3.1.7" style="padding:0.25pt 3.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.2.2.3.1.7.1" style="font-size:90%;">8</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T3.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T3.1.1.1.1" style="padding:0.25pt 3.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.1.1.1" style="font-size:90%;">FPR95<math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T3.1.1.1.1.1.m1.1"><semantics id="S4.T3.1.1.1.1.1.m1.1a"><mo id="S4.T3.1.1.1.1.1.m1.1.1" stretchy="false" xref="S4.T3.1.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T3.1.1.1.1.1.m1.1b"><ci id="S4.T3.1.1.1.1.1.m1.1.1.cmml" xref="S4.T3.1.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.1.1.1.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T3.1.1.1.1.1.m1.1d">↓</annotation></semantics></math></span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.1.2" style="padding:0.25pt 3.0pt;"><span class="ltx_text" id="S4.T3.1.1.1.2.1" style="font-size:90%;">36.96/13.58</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.1.3" style="padding:0.25pt 3.0pt;"><span class="ltx_text" id="S4.T3.1.1.1.3.1" style="font-size:90%;">37.13/13.15</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.1.4" style="background-color:#E6E6E6;padding:0.25pt 3.0pt;"><span class="ltx_text" id="S4.T3.1.1.1.4.1" style="font-size:90%;background-color:#E6E6E6;">37.31/12.82</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.1.5" style="padding:0.25pt 3.0pt;"><span class="ltx_text" id="S4.T3.1.1.1.5.1" style="font-size:90%;">36.87/13.25</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.1.6" style="padding:0.25pt 3.0pt;"><span class="ltx_text" id="S4.T3.1.1.1.6.1" style="font-size:90%;">37.91/13.53</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.1.7" style="padding:0.25pt 3.0pt;"><span class="ltx_text" id="S4.T3.1.1.1.7.1" style="font-size:90%;">37.13/13.15</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S4.T3.2.2.2.1" style="padding:0.25pt 3.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.2.2.2.1.1" style="font-size:90%;">AUROC<math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T3.2.2.2.1.1.m1.1"><semantics id="S4.T3.2.2.2.1.1.m1.1a"><mo id="S4.T3.2.2.2.1.1.m1.1.1" stretchy="false" xref="S4.T3.2.2.2.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T3.2.2.2.1.1.m1.1b"><ci id="S4.T3.2.2.2.1.1.m1.1.1.cmml" xref="S4.T3.2.2.2.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.2.2.2.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T3.2.2.2.1.1.m1.1d">↑</annotation></semantics></math></span></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.2.2.2.2" style="padding:0.25pt 3.0pt;"><span class="ltx_text" id="S4.T3.2.2.2.2.1" style="font-size:90%;">86.56/95.54</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.2.2.2.3" style="padding:0.25pt 3.0pt;"><span class="ltx_text" id="S4.T3.2.2.2.3.1" style="font-size:90%;">86.63/95.51</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.2.2.2.4" style="background-color:#E6E6E6;padding:0.25pt 3.0pt;"><span class="ltx_text" id="S4.T3.2.2.2.4.1" style="font-size:90%;background-color:#E6E6E6;">86.46/95.47</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.2.2.2.5" style="padding:0.25pt 3.0pt;"><span class="ltx_text" id="S4.T3.2.2.2.5.1" style="font-size:90%;">86.51/95.37</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.2.2.2.6" style="padding:0.25pt 3.0pt;"><span class="ltx_text" id="S4.T3.2.2.2.6.1" style="font-size:90%;">86.43/95.35</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.2.2.2.7" style="padding:0.25pt 3.0pt;"><span class="ltx_text" id="S4.T3.2.2.2.7.1" style="font-size:90%;">86.44/95.56</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<figure class="ltx_table" id="S4.T4">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T4.10.1.1" style="font-size:90%;">Table 4</span>: </span><span class="ltx_text" id="S4.T4.11.2" style="font-size:90%;">We randomly sample the same numbers of OOD features as the main experiment instead of using the feature filter (denoted as w/o filter), and evaluate on multiple datasets. The obtained results demonstrate the effectiveness of the proposed data filter.</span></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T4.8" style="width:433.6pt;height:83.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-15.7pt,3.0pt) scale(0.932570314535393,0.932570314535393) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T4.8.8">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T4.8.8.9.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="S4.T4.8.8.9.1.1" rowspan="3" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T4.8.8.9.1.1.1">Method</span></th>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="4" id="S4.T4.8.8.9.1.2" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T4.8.8.9.1.2.1">ID:PASCAL-VOC</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="4" id="S4.T4.8.8.9.1.3" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T4.8.8.9.1.3.1">ID:BDD-100K</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.8.8.10.2">
<td class="ltx_td ltx_align_center" colspan="2" id="S4.T4.8.8.10.2.1" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T4.8.8.10.2.1.1">MS-COCO</span></td>
<td class="ltx_td ltx_align_center" colspan="2" id="S4.T4.8.8.10.2.2" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T4.8.8.10.2.2.1">OpenImages</span></td>
<td class="ltx_td ltx_align_center" colspan="2" id="S4.T4.8.8.10.2.3" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T4.8.8.10.2.3.1">MS-COCO</span></td>
<td class="ltx_td ltx_align_center" colspan="2" id="S4.T4.8.8.10.2.4" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T4.8.8.10.2.4.1">OpenImages</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.8.8.8">
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.1.1.1.1" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T4.1.1.1.1.1">FPR95<math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T4.1.1.1.1.1.m1.1"><semantics id="S4.T4.1.1.1.1.1.m1.1a"><mo id="S4.T4.1.1.1.1.1.m1.1.1" stretchy="false" xref="S4.T4.1.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T4.1.1.1.1.1.m1.1b"><ci id="S4.T4.1.1.1.1.1.m1.1.1.cmml" xref="S4.T4.1.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.1.1.1.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T4.1.1.1.1.1.m1.1d">↓</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.2.2.2.2" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T4.2.2.2.2.1">AUROC<math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T4.2.2.2.2.1.m1.1"><semantics id="S4.T4.2.2.2.2.1.m1.1a"><mo id="S4.T4.2.2.2.2.1.m1.1.1" stretchy="false" xref="S4.T4.2.2.2.2.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T4.2.2.2.2.1.m1.1b"><ci id="S4.T4.2.2.2.2.1.m1.1.1.cmml" xref="S4.T4.2.2.2.2.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.2.2.2.2.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T4.2.2.2.2.1.m1.1d">↑</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.3.3.3" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T4.3.3.3.3.1">FPR95<math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T4.3.3.3.3.1.m1.1"><semantics id="S4.T4.3.3.3.3.1.m1.1a"><mo id="S4.T4.3.3.3.3.1.m1.1.1" stretchy="false" xref="S4.T4.3.3.3.3.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T4.3.3.3.3.1.m1.1b"><ci id="S4.T4.3.3.3.3.1.m1.1.1.cmml" xref="S4.T4.3.3.3.3.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.3.3.3.3.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T4.3.3.3.3.1.m1.1d">↓</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.4.4.4.4" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T4.4.4.4.4.1">AUROC<math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T4.4.4.4.4.1.m1.1"><semantics id="S4.T4.4.4.4.4.1.m1.1a"><mo id="S4.T4.4.4.4.4.1.m1.1.1" stretchy="false" xref="S4.T4.4.4.4.4.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T4.4.4.4.4.1.m1.1b"><ci id="S4.T4.4.4.4.4.1.m1.1.1.cmml" xref="S4.T4.4.4.4.4.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.4.4.4.4.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T4.4.4.4.4.1.m1.1d">↑</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.5.5.5.5" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T4.5.5.5.5.1">FPR95<math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T4.5.5.5.5.1.m1.1"><semantics id="S4.T4.5.5.5.5.1.m1.1a"><mo id="S4.T4.5.5.5.5.1.m1.1.1" stretchy="false" xref="S4.T4.5.5.5.5.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T4.5.5.5.5.1.m1.1b"><ci id="S4.T4.5.5.5.5.1.m1.1.1.cmml" xref="S4.T4.5.5.5.5.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.5.5.5.5.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T4.5.5.5.5.1.m1.1d">↓</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.6.6.6.6" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T4.6.6.6.6.1">AUROC<math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T4.6.6.6.6.1.m1.1"><semantics id="S4.T4.6.6.6.6.1.m1.1a"><mo id="S4.T4.6.6.6.6.1.m1.1.1" stretchy="false" xref="S4.T4.6.6.6.6.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T4.6.6.6.6.1.m1.1b"><ci id="S4.T4.6.6.6.6.1.m1.1.1.cmml" xref="S4.T4.6.6.6.6.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.6.6.6.6.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T4.6.6.6.6.1.m1.1d">↑</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.7.7.7.7" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T4.7.7.7.7.1">FPR95<math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T4.7.7.7.7.1.m1.1"><semantics id="S4.T4.7.7.7.7.1.m1.1a"><mo id="S4.T4.7.7.7.7.1.m1.1.1" stretchy="false" xref="S4.T4.7.7.7.7.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T4.7.7.7.7.1.m1.1b"><ci id="S4.T4.7.7.7.7.1.m1.1.1.cmml" xref="S4.T4.7.7.7.7.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.7.7.7.7.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T4.7.7.7.7.1.m1.1d">↓</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.8.8.8.8" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T4.8.8.8.8.1">AUROC<math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T4.8.8.8.8.1.m1.1"><semantics id="S4.T4.8.8.8.8.1.m1.1a"><mo id="S4.T4.8.8.8.8.1.m1.1.1" stretchy="false" xref="S4.T4.8.8.8.8.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T4.8.8.8.8.1.m1.1b"><ci id="S4.T4.8.8.8.8.1.m1.1.1.cmml" xref="S4.T4.8.8.8.8.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.8.8.8.8.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T4.8.8.8.8.1.m1.1d">↑</annotation></semantics></math></span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.8.8.11.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T4.8.8.11.3.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">w/o filter</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.8.8.11.3.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">39.29</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.8.8.11.3.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">85.46</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.8.8.11.3.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">13.68</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.8.8.11.3.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">95.22</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.8.8.11.3.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">25.45</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.8.8.11.3.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">93.17</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.8.8.11.3.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">15.32</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.8.8.11.3.9" style="padding-top:0.5pt;padding-bottom:0.5pt;">95.83</td>
</tr>
<tr class="ltx_tr" id="S4.T4.8.8.12.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S4.T4.8.8.12.4.1" style="background-color:#E6E6E6;padding-top:0.5pt;padding-bottom:0.5pt;"><em class="ltx_emph ltx_font_italic" id="S4.T4.8.8.12.4.1.1" style="background-color:#E6E6E6;">Ours</em></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T4.8.8.12.4.2" style="background-color:#E6E6E6;padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T4.8.8.12.4.2.1" style="background-color:#E6E6E6;">36.44</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T4.8.8.12.4.3" style="background-color:#E6E6E6;padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T4.8.8.12.4.3.1" style="background-color:#E6E6E6;">86.52</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T4.8.8.12.4.4" style="background-color:#E6E6E6;padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T4.8.8.12.4.4.1" style="background-color:#E6E6E6;">13.34</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T4.8.8.12.4.5" style="background-color:#E6E6E6;padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T4.8.8.12.4.5.1" style="background-color:#E6E6E6;">95.37</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T4.8.8.12.4.6" style="background-color:#E6E6E6;padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T4.8.8.12.4.6.1" style="background-color:#E6E6E6;">22.67</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T4.8.8.12.4.7" style="background-color:#E6E6E6;padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T4.8.8.12.4.7.1" style="background-color:#E6E6E6;">95.44</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T4.8.8.12.4.8" style="background-color:#E6E6E6;padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T4.8.8.12.4.8.1" style="background-color:#E6E6E6;">12.96</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T4.8.8.12.4.9" style="background-color:#E6E6E6;padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T4.8.8.12.4.9.1" style="background-color:#E6E6E6;">96.26</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section class="ltx_subsubsection" id="S4.SS2.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.3 </span>SAM-based Refiner</h4>
<div class="ltx_para" id="S4.SS2.SSS3.p1">
<p class="ltx_p" id="S4.SS2.SSS3.p1.1">As mentioned in <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S3.SS1" title="3.1 Synthesizing Semantic-novel Objects in Scene Images ‣ 3 Method ‣ Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_tag">Sec.</span> <span class="ltx_text ltx_ref_tag">3.1</span></a>, we propose to utilize SAM-based refiner to correct the bounding boxes of novel objects to obtain higher-quality instance-level OOD features. Therefore, we comparatively remove the proposed refiner and directly used the corresponding editing masks as bounding boxes to extract OOD features for training. Taking PASCAL-VOC as the ID dataset, after removing the refiner, we obtain <span class="ltx_text ltx_font_bold" id="S4.SS2.SSS3.p1.1.1">39.55/13.72</span> of <span class="ltx_text ltx_font_bold" id="S4.SS2.SSS3.p1.1.2">FPR95</span> and <span class="ltx_text ltx_font_bold" id="S4.SS2.SSS3.p1.1.3">85.94/95.37</span> of <span class="ltx_text ltx_font_bold" id="S4.SS2.SSS3.p1.1.4">AUROC</span> on MS-COCO/OpenImages datasets, which is better than previous methods but worse than the results (Faster R-CNN + <em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS3.p1.1.5">Ours</em> in <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S4.T1" title="In 4.1 Main Results on OOD Object Detection ‣ 4 Experiments ‣ Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">1</span></a>) when using the refiner. This proves that OOD supervision signals contained in the synthetic data are already extracted and achieve good results under the localization of the fuzzy boxes, but more precise boxes mean higher quality features. More demos and analyses of the SAM-based refiner are shown in the supplementary material.</p>
</div>
<figure class="ltx_figure" id="S4.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="572" id="S4.F3.g1" src="x3.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F3.5.2.1" style="font-size:90%;">Figure 3</span>: </span><span class="ltx_text" id="S4.F3.2.1" style="font-size:90%;">We show cases on six intervals of feature similarity (consistent with <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S3.E5" title="In 3.2.1 Mining Hard OOD Objects with High Visual Similarities for Training ‣ 3.2 Mining Hard OOD Samples and Model Training ‣ 3 Method ‣ Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_tag">Eq.</span> <span class="ltx_text ltx_ref_tag">5</span></a>, indicated at the bottom of the figure). The first line contains the corresponding initial images, the second line contains the synthetic images with the corresponding boxes of the novel objects (yellow boxes), and the third line contains the difference heat maps of the latent feature maps extracted from the above image pairs (superimposed on the corresponding synthetic images, denoted as <span class="ltx_text ltx_markedasmath" id="S4.F3.2.1.1">Diff-map</span>).</span></figcaption>
</figure>
</section>
<section class="ltx_subsubsection" id="S4.SS2.SSS4">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.4 </span>Similarity-based Filter</h4>
<div class="ltx_para" id="S4.SS2.SSS4.p1">
<p class="ltx_p" id="S4.SS2.SSS4.p1.1">The filter is designed to incorporate the most useful data into training, and avoid unnecessary noise. The design is reflected in two aspects: on one hand, the outlier object should process similar visual patterns to the original object, thus being confusing and can facilitate learning; on the other hand, over-high similarity may indicate failures of the editing process (<em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS4.p1.1.1">e.g</em>.<span class="ltx_text" id="S4.SS2.SSS4.p1.1.2"></span>, when the concept is not an object).
These considerations are applied as thresholding on pairwise cosine similarity between object features, as in <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S3.E5" title="In 3.2.1 Mining Hard OOD Objects with High Visual Similarities for Training ‣ 3.2 Mining Hard OOD Samples and Model Training ‣ 3 Method ‣ Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_tag">Eq.</span> <span class="ltx_text ltx_ref_tag">5</span></a>.
As shown in <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S4.T4" title="In 4.2.2 Number of Concepts to Imagine ‣ 4.2 Ablation Study ‣ 4 Experiments ‣ Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">4</span></a>, this filter brings a notable improvement across benchmarks.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS4.p2">
<p class="ltx_p" id="S4.SS2.SSS4.p2.1">To provide more insights on the choices of filtering thresholds, we display some cases in different intervals of feature similarity in <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S4.F3" title="In 4.2.3 SAM-based Refiner ‣ 4.2 Ablation Study ‣ 4 Experiments ‣ Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">3</span></a>. We show the synthetic images, the corresponding initial images, and the difference between feature maps (denoted as Diff-map), respectively. The Diff-maps prove that the edited area is sensitively attended to by the model.
But for images with extremely high similarity (<math alttext="&gt;0.9" class="ltx_Math" display="inline" id="S4.SS2.SSS4.p2.1.m1.1"><semantics id="S4.SS2.SSS4.p2.1.m1.1a"><mrow id="S4.SS2.SSS4.p2.1.m1.1.1" xref="S4.SS2.SSS4.p2.1.m1.1.1.cmml"><mi id="S4.SS2.SSS4.p2.1.m1.1.1.2" xref="S4.SS2.SSS4.p2.1.m1.1.1.2.cmml"></mi><mo id="S4.SS2.SSS4.p2.1.m1.1.1.1" xref="S4.SS2.SSS4.p2.1.m1.1.1.1.cmml">&gt;</mo><mn id="S4.SS2.SSS4.p2.1.m1.1.1.3" xref="S4.SS2.SSS4.p2.1.m1.1.1.3.cmml">0.9</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS4.p2.1.m1.1b"><apply id="S4.SS2.SSS4.p2.1.m1.1.1.cmml" xref="S4.SS2.SSS4.p2.1.m1.1.1"><gt id="S4.SS2.SSS4.p2.1.m1.1.1.1.cmml" xref="S4.SS2.SSS4.p2.1.m1.1.1.1"></gt><csymbol cd="latexml" id="S4.SS2.SSS4.p2.1.m1.1.1.2.cmml" xref="S4.SS2.SSS4.p2.1.m1.1.1.2">absent</csymbol><cn id="S4.SS2.SSS4.p2.1.m1.1.1.3.cmml" type="float" xref="S4.SS2.SSS4.p2.1.m1.1.1.3">0.9</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS4.p2.1.m1.1c">&gt;0.9</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS4.p2.1.m1.1d">&gt; 0.9</annotation></semantics></math>), they always contain some editing failures and blurs. As illustrated on the top of the first column in <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S4.F3" title="In 4.2.3 SAM-based Refiner ‣ 4.2 Ablation Study ‣ 4 Experiments ‣ Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">3</span></a>, it is not intuitively evident what the <span class="ltx_text ltx_font_italic" id="S4.SS2.SSS4.p2.1.1">ship</span> has been edited into (the target object is a <span class="ltx_text ltx_font_italic" id="S4.SS2.SSS4.p2.1.2">raft</span>).
Besides, as the similarity upperbound decreases, we progressively obtain more realistic and reasonable images. But note that when the similarity is excessively low, as seen in the last column of <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S4.F3" title="In 4.2.3 SAM-based Refiner ‣ 4.2 Ablation Study ‣ 4 Experiments ‣ Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">3</span></a>, the objects are edited into the corresponding text or an unnatural object, leading to image distortion. This strongly supports the idea that the quality and usability of edited images are closely connected to visual similarity. More cases and analyses are presented in the supplementary material.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Discussions on Outlier Synthesis</h3>
<figure class="ltx_table" id="S4.T5">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T5.7.1.1" style="font-size:90%;">Table 5</span>: </span><span class="ltx_text" id="S4.T5.8.2" style="font-size:90%;">Comparing varied images as OOD samples for training, we first show some synthetic object-centric images generated by Stable Diffusion (left side). Then with PASCAL-VOC as ID dataset, we report the results obtained by using synthetic object-centric images (denoted as object-centric images) and scene-level images with novel objects but without bounding boxes (denoted as scene-level w/o boxes) as OOD samples to participate in training.</span></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T5.5" style="width:433.6pt;height:84.4pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-14.3pt,2.8pt) scale(0.938165415926685,0.938165415926685) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T5.5.5">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T5.5.5.6.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S4.T5.5.5.6.1.1" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T5.5.5.6.1.1.1">Object-centric Images</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S4.T5.5.5.6.1.2" rowspan="2" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T5.5.5.6.1.2.1">Data</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2" id="S4.T5.5.5.6.1.3" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T5.5.5.6.1.3.1">MS-COCO</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2" id="S4.T5.5.5.6.1.4" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T5.5.5.6.1.4.1">OpenImages</span></th>
</tr>
<tr class="ltx_tr" id="S4.T5.5.5.5">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_bb" id="S4.T5.1.1.1.1" rowspan="4" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="S4.T5.1.1.1.1.1"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="98" id="S4.T5.1.1.1.1.1.g1" src="x4.png" width="256"/></span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T5.2.2.2.2" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T5.2.2.2.2.1">FPR95<math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T5.2.2.2.2.1.m1.1"><semantics id="S4.T5.2.2.2.2.1.m1.1a"><mo id="S4.T5.2.2.2.2.1.m1.1.1" stretchy="false" xref="S4.T5.2.2.2.2.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T5.2.2.2.2.1.m1.1b"><ci id="S4.T5.2.2.2.2.1.m1.1.1.cmml" xref="S4.T5.2.2.2.2.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.2.2.2.2.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T5.2.2.2.2.1.m1.1d">↓</annotation></semantics></math></span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T5.3.3.3.3" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T5.3.3.3.3.1">AUROC<math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T5.3.3.3.3.1.m1.1"><semantics id="S4.T5.3.3.3.3.1.m1.1a"><mo id="S4.T5.3.3.3.3.1.m1.1.1" stretchy="false" xref="S4.T5.3.3.3.3.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T5.3.3.3.3.1.m1.1b"><ci id="S4.T5.3.3.3.3.1.m1.1.1.cmml" xref="S4.T5.3.3.3.3.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.3.3.3.3.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T5.3.3.3.3.1.m1.1d">↑</annotation></semantics></math></span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T5.4.4.4.4" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T5.4.4.4.4.1">FPR95<math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T5.4.4.4.4.1.m1.1"><semantics id="S4.T5.4.4.4.4.1.m1.1a"><mo id="S4.T5.4.4.4.4.1.m1.1.1" stretchy="false" xref="S4.T5.4.4.4.4.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T5.4.4.4.4.1.m1.1b"><ci id="S4.T5.4.4.4.4.1.m1.1.1.cmml" xref="S4.T5.4.4.4.4.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.4.4.4.4.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T5.4.4.4.4.1.m1.1d">↓</annotation></semantics></math></span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T5.5.5.5.5" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T5.5.5.5.5.1">AUROC<math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T5.5.5.5.5.1.m1.1"><semantics id="S4.T5.5.5.5.5.1.m1.1a"><mo id="S4.T5.5.5.5.5.1.m1.1.1" stretchy="false" xref="S4.T5.5.5.5.5.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T5.5.5.5.5.1.m1.1b"><ci id="S4.T5.5.5.5.5.1.m1.1.1.cmml" xref="S4.T5.5.5.5.5.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.5.5.5.5.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T5.5.5.5.5.1.m1.1d">↑</annotation></semantics></math></span></th>
</tr>
<tr class="ltx_tr" id="S4.T5.5.5.7.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S4.T5.5.5.7.2.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">object-centric images</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.5.5.7.2.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">51.99</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.5.5.7.2.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">81.48</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.5.5.7.2.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">20.70</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.5.5.7.2.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">93.85</td>
</tr>
<tr class="ltx_tr" id="S4.T5.5.5.8.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T5.5.5.8.3.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">scene-level w/o boxes</th>
<td class="ltx_td ltx_align_center" id="S4.T5.5.5.8.3.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">48.01</td>
<td class="ltx_td ltx_align_center" id="S4.T5.5.5.8.3.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">82.38</td>
<td class="ltx_td ltx_align_center" id="S4.T5.5.5.8.3.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">18.61</td>
<td class="ltx_td ltx_align_center" id="S4.T5.5.5.8.3.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">93.44</td>
</tr>
<tr class="ltx_tr" id="S4.T5.5.5.9.4">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb" id="S4.T5.5.5.9.4.1" style="background-color:#E6E6E6;padding-top:0.5pt;padding-bottom:0.5pt;"><em class="ltx_emph ltx_font_italic" id="S4.T5.5.5.9.4.1.1" style="background-color:#E6E6E6;">Ours</em></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T5.5.5.9.4.2" style="background-color:#E6E6E6;padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T5.5.5.9.4.2.1" style="background-color:#E6E6E6;">36.44</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T5.5.5.9.4.3" style="background-color:#E6E6E6;padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T5.5.5.9.4.3.1" style="background-color:#E6E6E6;">86.52</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T5.5.5.9.4.4" style="background-color:#E6E6E6;padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T5.5.5.9.4.4.1" style="background-color:#E6E6E6;">13.34</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T5.5.5.9.4.5" style="background-color:#E6E6E6;padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T5.5.5.9.4.5.1" style="background-color:#E6E6E6;">95.37</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<section class="ltx_subsubsection" id="S4.SS3.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.1 </span>Scene-level Editing Matters</h4>
<div class="ltx_para" id="S4.SS3.SSS1.p1">
<p class="ltx_p" id="S4.SS3.SSS1.p1.1">Through regional-level editing, we replace the ID object with a novel object with a bounding box and ensure consistent context information. However, some simpler methods based on foundation models also achieve the acquisition and use of OOD data. For example, Dream-OOD <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib13" title="">13</a>]</cite> uses well-trained text-conditional space and diffusion model to synthesize realistic object-centric data for promoting OOD image classification. Similarly, keeping other settings unchanged, we use our novel concepts to drive Stable-Diffusion instead of Stable-Diffusion-Inpainting <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib49" title="">49</a>]</cite> to synthesize novel images, which are also processed and filtered by our proposed refiner and filter (some synthesized images are shown in <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S4.T5" title="In 4.3 Discussions on Outlier Synthesis ‣ 4 Experiments ‣ Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">5</span></a>), thereby participating in the training as OOD supervision. However, as shown in <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S4.T5" title="In 4.3 Discussions on Outlier Synthesis ‣ 4 Experiments ‣ Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">5</span></a> (object-centric images), the synthetic novel object-centric images do not aid in training and result in poor performance, even though they possess high visual quality. This clearly validates our decision to edit scene-level images rather than composing new ones, and highlights the significance of maintaining contextual consistency.</p>
</div>
<div class="ltx_para" id="S4.SS3.SSS1.p2">
<p class="ltx_p" id="S4.SS3.SSS1.p2.1">Additionally, we examine the possibility of using the edited scene-level image as a whole (ignoring the boxes) as OOD samples in the training process.
The results, as depicted in <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S4.T5" title="In 4.3 Discussions on Outlier Synthesis ‣ 4 Experiments ‣ Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">5</span></a> (scene-level w/o boxes), are significantly inferior compared to our method’s performance. This demonstrates that controllable bounding boxes are indispensable in this task.</p>
</div>
<figure class="ltx_figure" id="S4.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="286" id="S4.F4.g1" src="x5.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F4.2.1.1" style="font-size:90%;">Figure 4</span>: </span><span class="ltx_text" id="S4.F4.3.2" style="font-size:90%;">We edit the context of the synthetic data (in blue box) so that the images contain novel objects and novel context (in orange box). Then we calculate the similarity between the instance-level feature of the corresponding objects from all synthetic images and the instance-level feature in the initial image (left, the bird). The similarities and the corresponding difference maps are shown in the figure.</span></figcaption>
</figure>
</section>
<section class="ltx_subsubsection" id="S4.SS3.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.2 </span>Context Consistency Matters</h4>
<div class="ltx_para" id="S4.SS3.SSS2.p1">
<p class="ltx_p" id="S4.SS3.SSS2.p1.1">Given the importance of scene-level synthesis as discussed in the previous paragraph, we study the factors that make scene-level editing indispensable, and find context consistency to be a crucial one.
Besides calculating the similarity between ID/OOD object pairs before/after box-conditioned editing, we also try further editing parts of the background of the already edited images, and also calculate its object similarity with the initial object.
As shown in <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S4.F4" title="In 4.3.1 Scene-level Editing Matters ‣ 4.3 Discussions on Outlier Synthesis ‣ 4 Experiments ‣ Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">4</span></a>, even small editing on parts of the background (out of the object boxes) can make foreground objects ‘look’ notably different as perceived by the detector.
This highlights the importance of keeping the context unchanged when synthesizing outlier samples, in that if the context is changed, the model easily identifies the object as OOD and cannot break the context bias.</p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Discussion</h2>
<section class="ltx_subsubsection" id="S5.SS0.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.0.1 </span>What Type of OOD Data Matters?</h4>
<div class="ltx_para" id="S5.SS0.SSS1.p1">
<p class="ltx_p" id="S5.SS0.SSS1.p1.1">We are the first to explore how to edit scene-level images to include novel categories, which contain annotation boxes and ensure context consistency, facilitating OOD object detection.
The achieved state-of-the-art performance (<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S4.T1" title="In 4.1 Main Results on OOD Object Detection ‣ 4 Experiments ‣ Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">1</span></a>) benefits from the optimization of decision boundaries driven by high-quality OOD features.
Our exploration demonstrates that <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS1.p1.1.1">annotation boxes</span> and <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS1.p1.1.2">context consistency</span> are particularly important for synthesizing high-quality OOD instances.
On the one hand, high-quality annotation boxes provide the possibility to extract high-quality instance-level features from scene-level images, while unrefined boxes (<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S4.SS2.SSS3" title="4.2.3 SAM-based Refiner ‣ 4.2 Ablation Study ‣ 4 Experiments ‣ Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_tag">Sec.</span> <span class="ltx_text ltx_ref_tag">4.2.3</span></a>) or discarded boxes (<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S4.T5" title="In 4.3 Discussions on Outlier Synthesis ‣ 4 Experiments ‣ Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">5</span></a>) will have a negative impact on performance.
On the other hand, context consistency ensures the most effective OOD features are not interfered by different contexts and selected for utilizing (<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S4.F4" title="In 4.3.1 Scene-level Editing Matters ‣ 4.3 Discussions on Outlier Synthesis ‣ 4 Experiments ‣ Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">4</span></a>).</p>
</div>
</section>
<section class="ltx_subsubsection" id="S5.SS0.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.0.2 </span>How to Synthesize Suitable OOD Data?</h4>
<div class="ltx_para" id="S5.SS0.SSS2.p1">
<p class="ltx_p" id="S5.SS0.SSS2.p1.1">We are the first to build <em class="ltx_emph ltx_font_italic" id="S5.SS0.SSS2.p1.1.1">an automatic, transparent, and low-cost pipeline</em> (<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S3.SS1" title="3.1 Synthesizing Semantic-novel Objects in Scene Images ‣ 3 Method ‣ Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_tag">Sec.</span> <span class="ltx_text ltx_ref_tag">3.1</span></a>) for synthesizing scene-level images containing novel objects with annotation boxes and context consistency.
It benefits object detectors’ robustness and reliability to unseen data and sets up clear state-of-the-art on multiple OOD object detection benchmarks.
Specifically, we organically combine and cleverly use different foundation models <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib1" title="">1</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib49" title="">49</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib30" title="">30</a>]</cite> (<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S3.SS1" title="3.1 Synthesizing Semantic-novel Objects in Scene Images ‣ 3 Method ‣ Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_tag">Sec.</span> <span class="ltx_text ltx_ref_tag">3.1</span></a>) to distill open-world knowledge and inpaint the existing scenes for simulating real OOD scenarios.
In addition, our design <em class="ltx_emph ltx_font_italic" id="S5.SS0.SSS2.p1.1.2">takes into account the instability of the current foundation models</em> and can release better potential performance in the future development of foundation models.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S5.SS0.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.0.3 </span>How to Select Suitable OOD Data?</h4>
<div class="ltx_para" id="S5.SS0.SSS3.p1">
<p class="ltx_p" id="S5.SS0.SSS3.p1.1">We are the first to <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS3.p1.1.1">explicitly decouple OOD data synthesis and selection</span>. On the one hand, we ensure the separability of the synthetic objects in semantic concepts through open-world knowledge provided by LLMs (<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S3.SS1" title="3.1 Synthesizing Semantic-novel Objects in Scene Images ‣ 3 Method ‣ Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_tag">Sec.</span> <span class="ltx_text ltx_ref_tag">3.1</span></a>). On the other hand, we ensure the similarity of ID and OOD objects in visual patterns (<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#S3.SS1" title="3.1 Synthesizing Semantic-novel Objects in Scene Images ‣ 3 Method ‣ Can OOD Object Detectors Learn from Foundation Models?"><span class="ltx_text ltx_ref_tag">Sec.</span> <span class="ltx_text ltx_ref_tag">3.1</span></a>), thereby optimizing the precise decision boundary.
This line of thinking has the potential to facilitate more open-world solutions.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S5.SS0.SSS4">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.0.4 </span>Broader Impacts</h4>
<div class="ltx_para" id="S5.SS0.SSS4.p1">
<p class="ltx_p" id="S5.SS0.SSS4.p1.1">Beyond showcasing engineering success via effectively combining specific foundation models, our work uncovers the untapped potential of the text-to-image generative models and visual foundation models in pushing forward the OOD object detection task to effectively leverage the off-the-shelf open-world data knowledge <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib31" title="">31</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib66" title="">66</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib5" title="">5</a>]</cite>.
More importantly, our work establishes a bridge between OOD object detection and the latest advancements in deep learning, enabling it to benefit from ongoing developments, go beyond isolated academic practice, and resolve practical challenges in open-world applications.
Meanwhile, automating novel data generation and curation will inspire more tasks in more modalities, such as in visual-language <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib44" title="">44</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib58" title="">58</a>]</cite> and 3D vision <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib37" title="">37</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib64" title="">64</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05162v1#bib.bib8" title="">8</a>]</cite>.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">In this paper, we investigate improving OOD object detection by distilling open-world data knowledge from text-to-image generative models. We develop an automatic and cost-effective data curation pipeline, SyncOOD, that leverages foundation models as tools to obtain meaningful open-set data from generative models. Through extensive studies, we discover that object boxes and context consistency of the generated data contribute to the improvement of OOD object detection performance.
Our comprehensive experiments demonstrate that SyncOOD not only advances the state-of-the-art in OOD object detection but also emphasizes the untapped potential of utilizing large-scale generative models for enhancing the robustness of machine learning systems in open-world settings. As an initial exploration in leveraging foundation models for OOD object detection, we hope our promising results encourage further research in advancing this area in the future.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_title_section">Acknowledgments</h2>
<div class="ltx_para" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1">This work has been supported by Hong Kong Research Grant Council - Early Career Scheme (Grant No. 27209621), General Research Fund Scheme (Grant No. 17202422), Theme-based Research (Grant No. T45-701/22-R) and RGC Matching Fund Scheme (RMGS). Part of the described research work is conducted in the JC STEM Lab of Robotics for Soft Materials funded by The Hong Kong Jockey Club Charities Trust. We would like to thank Chirui Chang, Xiaoyang Lyu, Haoru Tan, and Xiuzhe Wu for their insightful discussions.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Achiam, J., Adler, S., Agarwal, S., Ahmad, L., Akkaya, I., Aleman, F.L., Almeida, D., Altenschmidt, J., Altman, S., Anadkat, S., et al.: GPT-4 technical report. arXiv preprint arXiv:2303.08774 (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Bendale, A., Boult, T.E.: Towards open set deep networks. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 1563–1572 (2016)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Bishop, C.M.: Novelty detection and neural network validation. IEE Proceedings-Vision, Image and Signal processing <span class="ltx_text ltx_font_bold" id="bib.bib3.1.1">141</span>(4), 217–222 (1994)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J.D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et al.: Language models are few-shot learners. Advances in Neural Information Processing Systems <span class="ltx_text ltx_font_bold" id="bib.bib4.1.1">33</span>, 1877–1901 (2020)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Chang, C., Liu, Z., Lyu, X., Qi, X.: What matters in detecting ai-generated videos like sora? arXiv preprint arXiv:2406.19568 (2024)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Chowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra, G., Roberts, A., Barham, P., Chung, H.W., Sutton, C., Gehrmann, S., et al.: Palm: Scaling language modeling with pathways. Journal of Machine Learning Research <span class="ltx_text ltx_font_bold" id="bib.bib6.1.1">24</span>(240), 1–113 (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Deepshikha, K., Yelleni, S.H., Srijith, P., Mohan, C.K.: Monte Carlo dropblock for modelling uncertainty in object detection. arXiv preprint arXiv:2108.03614 (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Deng, W., Ding, R., Yang, J., Liu, J., Li, Y., Qi, X., Ngai, E.: Can 3d vision-language models truly understand natural language? arXiv preprint arXiv:2403.14760 (2024)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Devlin, J., Chang, M.W., Lee, K., Toutanova, K.: Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805 (2018)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Dhamija, A., Gunther, M., Ventura, J., Boult, T.: The overlooked elephant of object detection: Open set. In: Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision. pp. 1021–1030 (2020)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Du, X., Fang, Z., Diakonikolas, I., Li, Y.: How does unlabeled data provably help out-of-distribution detection? arXiv preprint arXiv:2402.03502 (2024)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Du, X., Gozum, G., Ming, Y., Li, Y.: SIREN: Shaping representations for detecting out-of-distribution objects. Advances in Neural Information Processing Systems <span class="ltx_text ltx_font_bold" id="bib.bib12.1.1">35</span>, 20434–20449 (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Du, X., Sun, Y., Zhu, J., Li, Y.: Dream the impossible: Outlier imagination with diffusion models. Advances in Neural Information Processing Systems <span class="ltx_text ltx_font_bold" id="bib.bib13.1.1">36</span> (2024)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Du, X., Wang, X., Gozum, G., Li, Y.: Unknown-aware object detection: Learning what you don’t know from videos in the wild. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 13678–13688 (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Du, X., Wang, Z., Cai, M., Li, Y.: VOS: Learning what you don’t know by virtual outlier synthesis. arXiv preprint arXiv:2202.01197 (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Everingham, M., Van Gool, L., Williams, C.K., Winn, J., Zisserman, A.: The Pascal visual object classes (VOC) challenge. International journal of computer vision <span class="ltx_text ltx_font_bold" id="bib.bib16.1.1">88</span>, 303–338 (2010)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Gu, X., Lin, T.Y., Kuo, W., Cui, Y.: Open-vocabulary object detection via vision and language knowledge distillation. In: International Conference on Learning Representations (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Gupta, A., Narayan, S., Joseph, K., Khan, S., Khan, F.S., Shah, M.: Ow-detr: Open-world detection transformer. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 9235–9244 (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Hall, D., Dayoub, F., Skinner, J., Zhang, H., Miller, D., Corke, P., Carneiro, G., Angelova, A., Sünderhauf, N.: Probabilistic object detection: Definition and evaluation. In: Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision. pp. 1031–1040 (2020)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 770–778 (2016)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
He, R., Sun, S., Yu, X., Xue, C., Zhang, W., Torr, P., Bai, S., Qi, X.: Is synthetic data from generative models ready for image recognition? arXiv preprint arXiv:2210.07574 (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Hendrycks, D., Gimpel, K.: A baseline for detecting misclassified and out-of-distribution examples in neural networks. In: International Conference on Learning Representations (2017)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Hendrycks, D., Mazeika, M., Dietterich, T.: Deep anomaly detection with outlier exposure. arXiv preprint arXiv:1812.04606 (2018)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
Ho, J., Jain, A., Abbeel, P.: Denoising diffusion probabilistic models. Advances in neural information processing systems <span class="ltx_text ltx_font_bold" id="bib.bib24.1.1">33</span>, 6840–6851 (2020)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
Hsu, Y.C., Shen, Y., Jin, H., Kira, Z.: Generalized ODIN: Detecting out-of-distribution image without learning from out-of-distribution data. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 10951–10960 (2020)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
Huang, R., Geng, A., Li, Y.: On the importance of gradients for detecting distributional shifts in the wild. Advances in Neural Information Processing Systems <span class="ltx_text ltx_font_bold" id="bib.bib26.1.1">34</span>, 677–689 (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
Joseph, K., Khan, S., Khan, F.S., Balasubramanian, V.N.: Towards open world object detection. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 5830–5840 (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
Joseph, K., Khan, S., Khan, F.S., Balasubramanian, V.N.: Towards open world object detection. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. pp. 5830–5840 (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
Katz-Samuels, J., Nakhleh, J.B., Nowak, R., Li, Y.: Training ood detectors in their natural habitats. In: International Conference on Machine Learning. pp. 10848–10865. PMLR (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
Kirillov, A., Mintun, E., Ravi, N., Mao, H., Rolland, C., Gustafson, L., Xiao, T., Whitehead, S., Berg, A.C., Lo, W.Y., et al.: Segment anything. arXiv preprint arXiv:2304.02643 (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
Kong, S., Ramanan, D.: Opengan: Open-set recognition via open data generation. In: Proceedings of the IEEE/CVF International Conference on Computer Vision. pp. 813–822 (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
Kuznetsova, A., Rom, H., Alldrin, N., Uijlings, J., Krasin, I., Pont-Tuset, J., Kamali, S., Popov, S., Malloci, M., Kolesnikov, A., et al.: The open images dataset v4: Unified image classification, object detection, and visual relationship detection at scale. International Journal of Computer Vision <span class="ltx_text ltx_font_bold" id="bib.bib32.1.1">128</span>(7), 1956–1981 (2020)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
Lee, K., Lee, H., Lee, K., Shin, J.: Training confidence-calibrated classifiers for detecting out-of-distribution samples. In: International Conference on Learning Representations (2018)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
Lee, K., Lee, K., Lee, H., Shin, J.: A simple unified framework for detecting out-of-distribution samples and adversarial attacks. Advances in Neural Information Processing Systems <span class="ltx_text ltx_font_bold" id="bib.bib34.1.1">31</span> (2018)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
Liang, S., Li, Y., Srikant, R.: Enhancing the reliability of out-of-distribution image detection in neural networks. In: International Conference on Learning Representations, ICLR 2018 (2018)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
Lin, T.Y., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan, D., Dollár, P., Zitnick, C.L.: Microsoft COCO: Common objects in context. In: Computer Vision–ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part V 13. pp. 740–755. Springer (2014)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
Liu, J., Chang, C., Liu, J., Wu, X., Ma, L., Qi, X.: Mars3d: A plug-and-play motion-aware model for semantic segmentation on multi-scan 3d point clouds. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 9372–9381 (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
Liu, W., Wang, X., Owens, J., Li, Y.: Energy-based out-of-distribution detection. Advances in Neural Information Processing Systems <span class="ltx_text ltx_font_bold" id="bib.bib38.1.1">33</span>, 21464–21475 (2020)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
Liu, X., Yang, H., Ravichandran, A., Bhotika, R., Soatto, S.: Continual universal object detection. arXiv preprint arXiv:2002.05347 (2020)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
Miller, D., Dayoub, F., Milford, M., Sünderhauf, N.: Evaluating merging strategies for sampling-based uncertainty techniques in object detection. In: International Conference on Robotics and Automation (ICRA). pp. 2348–2354 (2019)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
Miller, D., Nicholson, L., Dayoub, F., Sünderhauf, N.: Dropout sampling for robust object detection in open-set conditions. In: IEEE International Conference on Robotics and Automation (ICRA). pp. 3243–3249 (2018)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
Nguyen, A., Yosinski, J., Clune, J.: Deep neural networks are easily fooled: High confidence predictions for unrecognizable images. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 427–436 (2015)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
Perez-Rua, J.M., Zhu, X., Hospedales, T.M., Xiang, T.: Incremental few-shot object detection. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 13846–13855 (2020)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
Radford, A., Kim, J.W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., Sastry, G., Askell, A., Mishkin, P., Clark, J., et al.: Learning transferable visual models from natural language supervision. In: International conference on machine learning. pp. 8748–8763. PMLR (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., Sutskever, I., et al.: Language models are unsupervised multitask learners. OpenAI blog <span class="ltx_text ltx_font_bold" id="bib.bib45.1.1">1</span>(8),  9 (2019)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
Rahman, S., Khan, S.H., Porikli, F.: Zero-shot object detection: Joint recognition and localization of novel concepts. International Journal of Computer Vision <span class="ltx_text ltx_font_bold" id="bib.bib46.1.1">128</span>, 2979–2999 (2020)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
Ren, J., Fort, S., Liu, J., Roy, A.G., Padhy, S., Lakshminarayanan, B.: A simple fix to Mahalanobis distance for improving near-ood detection. arXiv preprint arXiv:2106.09022 (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
Ren, S., He, K., Girshick, R., Sun, J.: Faster R-CNN: Towards real-time object detection with region proposal networks. Advances in Neural Information Processing Systems <span class="ltx_text ltx_font_bold" id="bib.bib48.1.1">28</span> (2015)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
Rombach, R., Blattmann, A., Lorenz, D., Esser, P., Ommer, B.: High-resolution image synthesis with latent diffusion models. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. pp. 10684–10695 (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
Sastry, C.S., Oore, S.: Detecting out-of-distribution examples with gram matrices. In: International Conference on Machine Learning. pp. 8491–8501. PMLR (2020)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock">
Sun, Y., Ming, Y., Zhu, X., Li, Y.: Out-of-distribution detection with deep nearest neighbors. In: International Conference on Machine Learning. pp. 20827–20840. PMLR (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock">
Tack, J., Mo, S., Jeong, J., Shin, J.: CSI: Novelty detection via contrastive learning on distributionally shifted instances. Advances in Neural Information Processing Systems <span class="ltx_text ltx_font_bold" id="bib.bib52.1.1">33</span>, 11839–11852 (2020)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock">
Tan, H., Wu, S., Du, F., Chen, Y., Wang, Z., Wang, F., Qi, X.: Data pruning via moving-one-sample-out. Advances in Neural Information Processing Systems (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock">
Tao, L., Du, X., Zhu, X., Li, Y.: Non-parametric outlier synthesis. arXiv preprint arXiv:2303.02966 (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock">
Tian, Y., Fan, L., Chen, K., Katabi, D., Krishnan, D., Isola, P.: Learning vision from models rivals learning vision from data. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 15887–15898 (2024)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock">
Wang, H., Liu, W., Bocchieri, A., Li, Y.: Can multi-label classification networks know what they don’t know? Advances in Neural Information Processing Systems <span class="ltx_text ltx_font_bold" id="bib.bib56.1.1">34</span>, 29074–29087 (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock">
Wang, X., Huang, T.E., Liu, B., Yu, F., Wang, X., Gonzalez, J.E., Darrell, T.: Robust object detection via instance-level temporal cycle confusion. In: Proceedings of the IEEE/CVF International Conference on Computer Vision. pp. 9143–9152 (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock">
Wen, X., Zhao, B., Chen, Y., Pang, J., Qi, X.: Generalization beyond data imbalance: A controlled study on clip for transferable insights. arXiv preprint arXiv:2405.21070 (2024)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib59">
<span class="ltx_tag ltx_tag_bibitem">[59]</span>
<span class="ltx_bibblock">
Wilson, S., Fischer, T., Dayoub, F., Miller, D., Sünderhauf, N.: SAFE: Sensitivity-aware features for out-of-distribution object detection. In: Proceedings of the IEEE/CVF International Conference on Computer Vision. pp. 23565–23576 (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib60">
<span class="ltx_tag ltx_tag_bibitem">[60]</span>
<span class="ltx_bibblock">
Wu, A., Chen, D., Deng, C.: Deep feature deblurring diffusion for detecting out-of-distribution objects. In: Proceedings of the IEEE/CVF International Conference on Computer Vision. pp. 13381–13391 (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib61">
<span class="ltx_tag ltx_tag_bibitem">[61]</span>
<span class="ltx_bibblock">
Wu, A., Deng, C.: Discriminating known from unknown objects via structure-enhanced recurrent variational autoencoder. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 23956–23965 (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib62">
<span class="ltx_tag ltx_tag_bibitem">[62]</span>
<span class="ltx_bibblock">
Wu, Q., Chen, Y., Yang, C., Yan, J.: Energy-based out-of-distribution detection for graph neural networks. arXiv preprint arXiv:2302.02914 (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib63">
<span class="ltx_tag ltx_tag_bibitem">[63]</span>
<span class="ltx_bibblock">
Wu, S., Tan, H., Tian, Z., Chen, Y., Qi, X., Jia, J.: Saco loss: Sample-wise affinity consistency for vision-language pre-training. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 27358–27369 (2024)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib64">
<span class="ltx_tag ltx_tag_bibitem">[64]</span>
<span class="ltx_bibblock">
Wu, X., Dai, P., Deng, W., Chen, H., Wu, Y., Cao, Y.P., Shan, Y., Qi, X.: Cl-nerf: continual learning of neural radiance fields for evolving scene representation. Advances in Neural Information Processing Systems <span class="ltx_text ltx_font_bold" id="bib.bib64.1.1">36</span> (2024)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib65">
<span class="ltx_tag ltx_tag_bibitem">[65]</span>
<span class="ltx_bibblock">
Yu, F., Chen, H., Wang, X., Xian, W., Chen, Y., Liu, F., Madhavan, V., Darrell, T.: BDD100K: A diverse driving dataset for heterogeneous multitask learning. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 2636–2645 (2020)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib66">
<span class="ltx_tag ltx_tag_bibitem">[66]</span>
<span class="ltx_bibblock">
Zheng, H., Wang, Q., Fang, Z., Xia, X., Liu, F., Liu, T., Han, B.: Out-of-distribution detection learning with unreliable out-of-distribution sources. Advances in Neural Information Processing Systems <span class="ltx_text ltx_font_bold" id="bib.bib66.1.1">36</span>, 72110–72123 (2023)

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Sun Sep  8 17:24:29 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
