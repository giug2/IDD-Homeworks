<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2302.01677] Revisiting Personalized Federated Learning: Robustness Against Backdoor Attacks</title><meta property="og:description" content="In this work, besides improving prediction accuracy, we study whether personalization could bring robustness benefits to backdoor attacks. We conduct the first study of backdoor attacks in the pFL framework, testing 4 â€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Revisiting Personalized Federated Learning: Robustness Against Backdoor Attacks">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Revisiting Personalized Federated Learning: Robustness Against Backdoor Attacks">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2302.01677">

<!--Generated on Thu Feb 29 22:23:01 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="backdoor attacks,  personalized federated learning,  robustness evaluation">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">Revisiting Personalized Federated Learning: Robustness Against Backdoor Attacks</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Zeyu Qin<sup id="id1.1.id1" class="ltx_sup">*</sup>
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id2.2.id1" class="ltx_text ltx_affiliation_institution">Hong Kong University of Science and Technology
</span><span id="id3.3.id2" class="ltx_text ltx_affiliation_country"></span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:zeyu.qin@connect.ust.hk">zeyu.qin@connect.ust.hk</a>
</span></span></span>
<span class="ltx_author_before">,Â </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Liuyi Yao
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id4.1.id1" class="ltx_text ltx_affiliation_institution">Alibaba Group</span><span id="id5.2.id2" class="ltx_text ltx_affiliation_country"></span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:yly287738@alibaba-inc.com">yly287738@alibaba-inc.com</a>
</span></span></span>
<span class="ltx_author_before">,Â </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Daoyuan Chen
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id6.1.id1" class="ltx_text ltx_affiliation_institution">Alibaba Group</span><span id="id7.2.id2" class="ltx_text ltx_affiliation_country"></span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:daoyuanchen.cdy@alibaba-inc.com">daoyuanchen.cdy@alibaba-inc.com</a>
</span></span></span>
<span class="ltx_author_before">,Â </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yaliang Li
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id8.1.id1" class="ltx_text ltx_affiliation_institution">Alibaba Group</span><span id="id9.2.id2" class="ltx_text ltx_affiliation_country"></span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:yaliang.li@alibaba-inc.com">yaliang.li@alibaba-inc.com</a>
</span></span></span>
<span class="ltx_author_before">,Â </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Bolin Ding
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id10.1.id1" class="ltx_text ltx_affiliation_institution">Alibaba Group</span><span id="id11.2.id2" class="ltx_text ltx_affiliation_country"></span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:bolin.ding@alibaba-inc.com">bolin.ding@alibaba-inc.com</a>
</span></span></span>
<span class="ltx_author_before">Â andÂ </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Minhao Cheng
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id12.1.id1" class="ltx_text ltx_affiliation_institution">Hong Kong University of Science and Technology
</span><span id="id13.2.id2" class="ltx_text ltx_affiliation_country"></span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:minhaocheng@ust.hk">minhaocheng@ust.hk</a>
</span></span></span>
</div>
<div class="ltx_dates">(2023)</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p id="id14.id1" class="ltx_p">In this work, besides improving prediction accuracy, we study whether personalization could bring robustness benefits to backdoor attacks. We conduct the first study of backdoor attacks in the pFL framework, testing 4 widely used backdoor attacks against 6 pFL methods on benchmark datasets FEMNIST and CIFAR-10, a total of 600 experiments. The study shows that pFL methods with partial model-sharing can significantly boost robustness against backdoor attacks. In contrast, pFL methods with full model-sharing do not show robustness. To analyze the reasons for varying robustness performances, we provide comprehensive ablation studies on different pFL methods. Based on our findings, we further propose a lightweight defense method, Simple-Tuning, which empirically improves defense performance against backdoor attacks. We believe that our work could provide both guidance for pFL application in terms of its robustness and offer valuable insights to design more robust FL methods in the future. We open-source our code to establish the first benchmark for black-box backdoor attacks in pFL: <a target="_blank" href="https://github.com/alibaba/FederatedScope/tree/backdoor-bench" title="" class="ltx_ref ltx_url ltx_font_typewriter ltx_font_italic">https://github.com/alibaba/FederatedScope/tree/backdoor-bench</a>.</p>
</div>
<div class="ltx_keywords">backdoor attacks, personalized federated learning, robustness evaluation
</div>
<span id="id1" class="ltx_note ltx_note_frontmatter ltx_role_journalyear"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">journalyear: </span>2023</span></span></span><span id="id2" class="ltx_note ltx_note_frontmatter ltx_role_copyright"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">copyright: </span>acmlicensed</span></span></span><span id="id3" class="ltx_note ltx_note_frontmatter ltx_role_conference"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">conference: </span>Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining; August 6â€“10, 2023; Long Beach, CA, USA</span></span></span><span id="id4" class="ltx_note ltx_note_frontmatter ltx_role_booktitle"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">booktitle: </span>Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD â€™23), August 6â€“10, 2023, Long Beach, CA, USA</span></span></span><span id="id5" class="ltx_note ltx_note_frontmatter ltx_role_price"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">price: </span>15.00</span></span></span><span id="id6" class="ltx_note ltx_note_frontmatter ltx_role_doi"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">doi: </span>10.1145/3580305.3599898</span></span></span><span id="id7" class="ltx_note ltx_note_frontmatter ltx_role_isbn"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">isbn: </span>979-8-4007-0103-0/23/08</span></span></span><span id="id8" class="ltx_note ltx_note_frontmatter ltx_role_ccs"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">ccs: </span>Information systemsÂ Data mining</span></span></span><span id="id9" class="ltx_note ltx_note_frontmatter ltx_role_ccs"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">ccs: </span>Security and privacyÂ Information accountability and usage control</span></span></span><span id="footnotex1" class="ltx_note ltx_role_footnotetext"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">footnotetext: </span>Work was done when the first author Zeyu Qin was an intern at Alibaba Group.</span></span></span>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Along with increasing concerns and stricter regulationsÂ <cite class="ltx_cite ltx_citemacro_citep">(European Commission, <a href="#bib.bib16" title="" class="ltx_ref">2016</a>)</cite> regarding data privacy, Federated Learning (FL)Â <cite class="ltx_cite ltx_citemacro_citep">(McMahan etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib41" title="" class="ltx_ref">2017</a>)</cite> has attracted widespread attention from both industry and academia.
As a paradigm for collaboratively training machine learning models without access to dispersed and private data, FL has been successfully used in many real-world applications including keyboard predictionÂ <cite class="ltx_cite ltx_citemacro_citep">(Hard etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib22" title="" class="ltx_ref">2018</a>)</cite>, Internet of ThingsÂ <cite class="ltx_cite ltx_citemacro_citep">(Khan etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib28" title="" class="ltx_ref">2021</a>)</cite>, and medical image analysisÂ <cite class="ltx_cite ltx_citemacro_citep">(Li etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2020</a>)</cite>. However, with the popularity of FL, we also face severe security threats from potential adversaries in real-world scenarios. Focusing on breaching the availability of FL models, poisoning attacksÂ <cite class="ltx_cite ltx_citemacro_citep">(Baruch etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib6" title="" class="ltx_ref">2019</a>; Tolpegin etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib52" title="" class="ltx_ref">2020</a>; Shejwalkar and Houmansadr, <a href="#bib.bib46" title="" class="ltx_ref">2021</a>)</cite> could completely corrupt the FL models. Focusing on breaching the confidentiality of FL models, inference attacksÂ <cite class="ltx_cite ltx_citemacro_citep">(Melis etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib42" title="" class="ltx_ref">2019</a>; Nasr etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib43" title="" class="ltx_ref">2019</a>)</cite> and reconstruction attacksÂ <cite class="ltx_cite ltx_citemacro_citep">(Zhu etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib64" title="" class="ltx_ref">2019</a>)</cite> could significantly increase the privacy risk of FL models. To eliminate the above threats, many defense methodsÂ <cite class="ltx_cite ltx_citemacro_citep">(Blanchard etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib8" title="" class="ltx_ref">2017</a>; Shejwalkar etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib47" title="" class="ltx_ref">2022</a>; Huang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib26" title="" class="ltx_ref">2021</a>)</cite> have been proposed and achieved outstanding defense performance against these attacks.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Meanwhile, due to the distributed nature of FL system, the backdoor attack is emerging and becoming one of the most serious security threats to FL systemÂ <cite class="ltx_cite ltx_citemacro_citep">(Bagdasaryan etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib4" title="" class="ltx_ref">2020</a>; Sun etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib49" title="" class="ltx_ref">2019</a>; Wang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib54" title="" class="ltx_ref">2020</a>; Goldblum etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2022</a>; Kairouz etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib27" title="" class="ltx_ref">2021</a>)</cite>.
Backdoor attacks aim only to mislead backdoored models to exhibit abnormal behavior on samples with backdoor triggers. Similar to poisoning attacks, the adversary manipulates some training samples, such as adding a small patch in samples or adding extra specific samples, to insert a backdoor trigger into the model. Compared with poisoning attacks that aim to corrupt FL modelsâ€™ prediction performance or make FL training divergeÂ <cite class="ltx_cite ltx_citemacro_citep">(Fang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib18" title="" class="ltx_ref">2020</a>; Blanchard etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib8" title="" class="ltx_ref">2017</a>; Baruch etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib6" title="" class="ltx_ref">2019</a>; Tolpegin etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib52" title="" class="ltx_ref">2020</a>)</cite>, backdoor attacks could only be activated by data with triggers so that they are more stealthy and much harder to be detected and defended against. How to effectively defend against backdoor attacks to FL methods is still an open problemÂ <cite class="ltx_cite ltx_citemacro_citep">(Bagdasaryan etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib4" title="" class="ltx_ref">2020</a>; Sun etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib49" title="" class="ltx_ref">2019</a>; Wang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib54" title="" class="ltx_ref">2020</a>; Goldblum etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2022</a>)</cite>. Existing defense methods that perform well against poisoning attacks like KrumÂ <cite class="ltx_cite ltx_citemacro_citep">(Blanchard etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib8" title="" class="ltx_ref">2017</a>)</cite>, norm clippingÂ <cite class="ltx_cite ltx_citemacro_citep">(Shejwalkar etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib47" title="" class="ltx_ref">2022</a>)</cite>, and adding noiseÂ <cite class="ltx_cite ltx_citemacro_citep">(Du etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib15" title="" class="ltx_ref">2020</a>; Wang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib54" title="" class="ltx_ref">2020</a>)</cite> do not achieve expected results against backdoor attacksÂ <cite class="ltx_cite ltx_citemacro_citep">(Wang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib54" title="" class="ltx_ref">2020</a>)</cite> (also seeing results in SectionÂ <a href="#S4.SS2" title="4.2. The Overall Robustness Evaluation â€£ 4. Robustness of pFL methods against Backdoor Attacks â€£ Revisiting Personalized Federated Learning: Robustness Against Backdoor Attacks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>). Backdoor attacks in FL framework could be separated into two categories: white-box and black-box attacksÂ <cite class="ltx_cite ltx_citemacro_citep">(Goldblum etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2022</a>; Lyu etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib38" title="" class="ltx_ref">2020</a>)</cite>. Compared with white-box attacks which allow adversarial clients to control the local training process, adversarial clients are only allowed to manipulate local training datasets under the black-box setting. Therefore, black-box attacks with few knowledge requirements are more practical for real-world scenariosÂ <cite class="ltx_cite ltx_citemacro_citep">(Shejwalkar etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib47" title="" class="ltx_ref">2022</a>)</cite> and also lead to non-negligible risks to FL systemsÂ <cite class="ltx_cite ltx_citemacro_citep">(Wang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib54" title="" class="ltx_ref">2020</a>; Shejwalkar etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib47" title="" class="ltx_ref">2022</a>)</cite> (seeing results in SectionÂ <a href="#S4.SS2" title="4.2. The Overall Robustness Evaluation â€£ 4. Robustness of pFL methods against Backdoor Attacks â€£ Revisiting Personalized Federated Learning: Robustness Against Backdoor Attacks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>).</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">A recent trend in FL deployment is to utilize personalized FL (pFL) methodsÂ <cite class="ltx_cite ltx_citemacro_citep">(Tan etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib51" title="" class="ltx_ref">2022</a>; Kairouz etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib27" title="" class="ltx_ref">2021</a>; Chen etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2022</a>, <a href="#bib.bib11" title="" class="ltx_ref">2023</a>)</cite> to mitigate the data heterogeneity issue across clients, a universal characteristic inherent in all real-world datasets. Being different from general FL methods only having a global model, pFL methods allow each client to have their own local personalized models, by finetuningÂ <cite class="ltx_cite ltx_citemacro_citep">(Liang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib36" title="" class="ltx_ref">2020</a>; Zhang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib61" title="" class="ltx_ref">2022b</a>)</cite>, interpolatingÂ <cite class="ltx_cite ltx_citemacro_citep">(Li etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib32" title="" class="ltx_ref">2021a</a>; Fallah etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib17" title="" class="ltx_ref">2020</a>)</cite>, or partially sharing the global modelÂ <cite class="ltx_cite ltx_citemacro_citep">(Li etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib34" title="" class="ltx_ref">2021b</a>; Collins etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2021</a>)</cite>. This brings better adaptability on local private datasets and helps pFL methods surpass general FL methods by a large margin on prediction accuracy under practical Non-IID scenariosÂ <cite class="ltx_cite ltx_citemacro_citep">(Chen etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2022</a>; Wu etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib57" title="" class="ltx_ref">2022b</a>)</cite>.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">The unique aspect of pFL, where clients have their own personalized local models, is a major contributor to its success. This distinction prompts us to consider whether the difference between clientsâ€™ local models could prevent the injection and spread of backdoor features. Specifically, in this study, we aim to determine whether pFL methods can also provide robustness against difficulty-eradicated backdoor attacks. We ask the below questions:</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p"><span id="S1.p5.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Do pFL methods bring robustness again backdoor attacks? And if the answer is yes, what leads to robustness, and how to utilize it?</span></p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.2" class="ltx_p">To answer the above questions, we study the robustness of mainstreamed pFL methods against backdoor attacks in this paper. Our work focuses on black-box backdoor attacks as they efficiently exploit security risks in more practical settings. We test <math id="S1.p6.1.m1.1" class="ltx_Math" alttext="4" display="inline"><semantics id="S1.p6.1.m1.1a"><mn id="S1.p6.1.m1.1.1" xref="S1.p6.1.m1.1.1.cmml">4</mn><annotation-xml encoding="MathML-Content" id="S1.p6.1.m1.1b"><cn type="integer" id="S1.p6.1.m1.1.1.cmml" xref="S1.p6.1.m1.1.1">4</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.p6.1.m1.1c">4</annotation></semantics></math> widely used backdoor attacks against <math id="S1.p6.2.m2.1" class="ltx_Math" alttext="6" display="inline"><semantics id="S1.p6.2.m2.1a"><mn id="S1.p6.2.m2.1.1" xref="S1.p6.2.m2.1.1.cmml">6</mn><annotation-xml encoding="MathML-Content" id="S1.p6.2.m2.1b"><cn type="integer" id="S1.p6.2.m2.1.1.cmml" xref="S1.p6.2.m2.1.1">6</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.p6.2.m2.1c">6</annotation></semantics></math> pFL methods on benchmark datasets FEMNIST and CIFAR-10, a total of 600 experiments.</p>
</div>
<div id="S1.p7" class="ltx_para">
<p id="S1.p7.1" class="ltx_p">For the first question, we find that various pFL methods show different robustness against backdoor attacks. <span id="S1.p7.1.1" class="ltx_text ltx_font_bold">Some pFL methods (partial model-sharing) could achieve outstanding defense performance</span>, especially FedRepÂ <cite class="ltx_cite ltx_citemacro_citep">(Collins etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2021</a>)</cite> could reduce backdoor attack success rate below <math id="S1.p7.1.m1.1" class="ltx_Math" alttext="10\%" display="inline"><semantics id="S1.p7.1.m1.1a"><mrow id="S1.p7.1.m1.1.1" xref="S1.p7.1.m1.1.1.cmml"><mn id="S1.p7.1.m1.1.1.2" xref="S1.p7.1.m1.1.1.2.cmml">10</mn><mo id="S1.p7.1.m1.1.1.1" xref="S1.p7.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S1.p7.1.m1.1b"><apply id="S1.p7.1.m1.1.1.cmml" xref="S1.p7.1.m1.1.1"><csymbol cd="latexml" id="S1.p7.1.m1.1.1.1.cmml" xref="S1.p7.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S1.p7.1.m1.1.1.2.cmml" xref="S1.p7.1.m1.1.1.2">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p7.1.m1.1c">10\%</annotation></semantics></math>. Even compared with some widely used defense methods, they are able to achieve similar and better robustness while still keeping excellent prediction accuracy.</p>
</div>
<div id="S1.p8" class="ltx_para">
<p id="S1.p8.1" class="ltx_p">Through a series of experiments to dig out the source of robustness from pFL methods, we find that <span id="S1.p8.1.1" class="ltx_text ltx_font_bold">the degree of personalization is a key factor to robustness benefits</span>. We observe that pFL methods with full model-sharing do not improve robustness against backdoor attacks. In contrast, pFL methods with partial model-sharing, FedBNÂ <cite class="ltx_cite ltx_citemacro_citep">(Li etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib34" title="" class="ltx_ref">2021b</a>)</cite>, and FedRepÂ <cite class="ltx_cite ltx_citemacro_citep">(Collins etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2021</a>)</cite>, significantly improve defense performance. These observations suggest a strong positive correlation between robustness against backdoor attacks and the larger personalization degree of pFL methods. Then, to further analyze the reasons behind different robustness from pFL methods, we conduct ablation studies on pFL methods. For full model-sharing methods, we find that if training of local models is more dependent on the global model, they are more vulnerable to backdoor attacks. For partial model-sharing methods like FedBN or FedRep which allow each client to own their locally preserved BN layers or linear classifiers, we find that they successfully block the propagation of backdoor features between personalized local models.</p>
</div>
<div id="S1.p9" class="ltx_para">
<p id="S1.p9.1" class="ltx_p">Finally, inspired by our findings, <span id="S1.p9.1.1" class="ltx_text ltx_font_bold">we further propose a defense method, <span id="S1.p9.1.1.1" class="ltx_text ltx_font_italic">Simple-Tuning</span></span>, that allows training FL models while efficiently reducing vulnerability to backdoor attacks. Simple-Tuning first reinitializes the linear classifier of trained models of each client and then trains it on local training datasets. As only tuning the linear classifier, Simple-Tuning is easier to be combined with existing FL methods with significantly reduced computation costs. We test defense performance of Simple-Tuning, and the results show that it significantly boosts robustness against backdoor attacks.</p>
</div>
<section id="S1.SS0.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_font_bold ltx_title_paragraph">Contributions.</h5>

<div id="S1.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S1.SS0.SSS0.Px1.p1.1" class="ltx_p">We summarize our contributions as follows:</p>
</div>
<div id="S1.SS0.SSS0.Px1.p2" class="ltx_para ltx_noindent">
<p id="S1.SS0.SSS0.Px1.p2.1" class="ltx_p"><span id="S1.SS0.SSS0.Px1.p2.1.1" class="ltx_text ltx_font_bold">(1)</span> We present the first detailed and thorough study that tests the robustness of 6 popular pFL methods against <math id="S1.SS0.SSS0.Px1.p2.1.m1.1" class="ltx_Math" alttext="4" display="inline"><semantics id="S1.SS0.SSS0.Px1.p2.1.m1.1a"><mn id="S1.SS0.SSS0.Px1.p2.1.m1.1.1" xref="S1.SS0.SSS0.Px1.p2.1.m1.1.1.cmml">4</mn><annotation-xml encoding="MathML-Content" id="S1.SS0.SSS0.Px1.p2.1.m1.1b"><cn type="integer" id="S1.SS0.SSS0.Px1.p2.1.m1.1.1.cmml" xref="S1.SS0.SSS0.Px1.p2.1.m1.1.1">4</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.SS0.SSS0.Px1.p2.1.m1.1c">4</annotation></semantics></math> widely used backdoor attacks. We find that some pFL methods (partial model-sharing) could achieve outstanding defense performance against backdoor attacks.</p>
</div>
<div id="S1.SS0.SSS0.Px1.p3" class="ltx_para ltx_noindent">
<p id="S1.SS0.SSS0.Px1.p3.1" class="ltx_p"><span id="S1.SS0.SSS0.Px1.p3.1.1" class="ltx_text ltx_font_bold">(2)</span> We find that the degree of model-sharing is a key factor to robustness benefits from pFL methods. pFL methods with full model-sharing do not show robustness against backdoor attacks. In contrast, pFL methods with partial model-sharing, FedBNÂ <cite class="ltx_cite ltx_citemacro_citep">(Li etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib34" title="" class="ltx_ref">2021b</a>)</cite>, and FedRepÂ <cite class="ltx_cite ltx_citemacro_citep">(Collins etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2021</a>)</cite>, significantly improve defense performance against backdoor attacks.</p>
</div>
<div id="S1.SS0.SSS0.Px1.p4" class="ltx_para ltx_noindent">
<p id="S1.SS0.SSS0.Px1.p4.1" class="ltx_p"><span id="S1.SS0.SSS0.Px1.p4.1.1" class="ltx_text ltx_font_bold">(3)</span> We also compare pFL methods with some widely used defense methods in FL against backdoor attacks. pFL methods are able to achieve similar and even better robustness while still keeping excellent prediction accuracy.</p>
</div>
<div id="S1.SS0.SSS0.Px1.p5" class="ltx_para ltx_noindent">
<p id="S1.SS0.SSS0.Px1.p5.1" class="ltx_p"><span id="S1.SS0.SSS0.Px1.p5.1.1" class="ltx_text ltx_font_bold">(4)</span> We conduct ablation studies on pFL methods to further analyze the reasons behind various robustness performances of pFL methods.</p>
</div>
<div id="S1.SS0.SSS0.Px1.p6" class="ltx_para ltx_noindent">
<p id="S1.SS0.SSS0.Px1.p6.1" class="ltx_p"><span id="S1.SS0.SSS0.Px1.p6.1.1" class="ltx_text ltx_font_bold">(5)</span> Based on our findings, we propose a lightweight and plug-and-play defense method, Simple-Tuning. The experiments show its effectiveness in boosting FL modelsâ€™ robustness against backdoor attacks.</p>
</div>
</section>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Background</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1. </span>Personalized Federated Learning</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.4" class="ltx_p">Before conducting our studies, we first introduce Federated Learning (FL) and personalized Federated Learning (pFL). Under FL scenario, each client <math id="S2.SS1.p1.1.m1.1" class="ltx_Math" alttext="i\in\mathcal{C}" display="inline"><semantics id="S2.SS1.p1.1.m1.1a"><mrow id="S2.SS1.p1.1.m1.1.1" xref="S2.SS1.p1.1.m1.1.1.cmml"><mi id="S2.SS1.p1.1.m1.1.1.2" xref="S2.SS1.p1.1.m1.1.1.2.cmml">i</mi><mo id="S2.SS1.p1.1.m1.1.1.1" xref="S2.SS1.p1.1.m1.1.1.1.cmml">âˆˆ</mo><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p1.1.m1.1.1.3" xref="S2.SS1.p1.1.m1.1.1.3.cmml">ğ’</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.1.m1.1b"><apply id="S2.SS1.p1.1.m1.1.1.cmml" xref="S2.SS1.p1.1.m1.1.1"><in id="S2.SS1.p1.1.m1.1.1.1.cmml" xref="S2.SS1.p1.1.m1.1.1.1"></in><ci id="S2.SS1.p1.1.m1.1.1.2.cmml" xref="S2.SS1.p1.1.m1.1.1.2">ğ‘–</ci><ci id="S2.SS1.p1.1.m1.1.1.3.cmml" xref="S2.SS1.p1.1.m1.1.1.3">ğ’</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.1.m1.1c">i\in\mathcal{C}</annotation></semantics></math> has his own private dataset <math id="S2.SS1.p1.2.m2.1" class="ltx_Math" alttext="\mathcal{S}_{i}" display="inline"><semantics id="S2.SS1.p1.2.m2.1a"><msub id="S2.SS1.p1.2.m2.1.1" xref="S2.SS1.p1.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p1.2.m2.1.1.2" xref="S2.SS1.p1.2.m2.1.1.2.cmml">ğ’®</mi><mi id="S2.SS1.p1.2.m2.1.1.3" xref="S2.SS1.p1.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.2.m2.1b"><apply id="S2.SS1.p1.2.m2.1.1.cmml" xref="S2.SS1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.2.m2.1.1.1.cmml" xref="S2.SS1.p1.2.m2.1.1">subscript</csymbol><ci id="S2.SS1.p1.2.m2.1.1.2.cmml" xref="S2.SS1.p1.2.m2.1.1.2">ğ’®</ci><ci id="S2.SS1.p1.2.m2.1.1.3.cmml" xref="S2.SS1.p1.2.m2.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.2.m2.1c">\mathcal{S}_{i}</annotation></semantics></math> drawn from its own local data distribution <math id="S2.SS1.p1.3.m3.1" class="ltx_Math" alttext="\mathcal{D}_{i}" display="inline"><semantics id="S2.SS1.p1.3.m3.1a"><msub id="S2.SS1.p1.3.m3.1.1" xref="S2.SS1.p1.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p1.3.m3.1.1.2" xref="S2.SS1.p1.3.m3.1.1.2.cmml">ğ’Ÿ</mi><mi id="S2.SS1.p1.3.m3.1.1.3" xref="S2.SS1.p1.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.3.m3.1b"><apply id="S2.SS1.p1.3.m3.1.1.cmml" xref="S2.SS1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.3.m3.1.1.1.cmml" xref="S2.SS1.p1.3.m3.1.1">subscript</csymbol><ci id="S2.SS1.p1.3.m3.1.1.2.cmml" xref="S2.SS1.p1.3.m3.1.1.2">ğ’Ÿ</ci><ci id="S2.SS1.p1.3.m3.1.1.3.cmml" xref="S2.SS1.p1.3.m3.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.3.m3.1c">\mathcal{D}_{i}</annotation></semantics></math> over <math id="S2.SS1.p1.4.m4.1" class="ltx_Math" alttext="\mathcal{X}\times\mathcal{Y}" display="inline"><semantics id="S2.SS1.p1.4.m4.1a"><mrow id="S2.SS1.p1.4.m4.1.1" xref="S2.SS1.p1.4.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p1.4.m4.1.1.2" xref="S2.SS1.p1.4.m4.1.1.2.cmml">ğ’³</mi><mo lspace="0.222em" rspace="0.222em" id="S2.SS1.p1.4.m4.1.1.1" xref="S2.SS1.p1.4.m4.1.1.1.cmml">Ã—</mo><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p1.4.m4.1.1.3" xref="S2.SS1.p1.4.m4.1.1.3.cmml">ğ’´</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.4.m4.1b"><apply id="S2.SS1.p1.4.m4.1.1.cmml" xref="S2.SS1.p1.4.m4.1.1"><times id="S2.SS1.p1.4.m4.1.1.1.cmml" xref="S2.SS1.p1.4.m4.1.1.1"></times><ci id="S2.SS1.p1.4.m4.1.1.2.cmml" xref="S2.SS1.p1.4.m4.1.1.2">ğ’³</ci><ci id="S2.SS1.p1.4.m4.1.1.3.cmml" xref="S2.SS1.p1.4.m4.1.1.3">ğ’´</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.4.m4.1c">\mathcal{X}\times\mathcal{Y}</annotation></semantics></math>. The goal of FL is to train a single (global) model collaboratively without sharing clientsâ€™ local data. The objective of FL is</p>
<table id="S2.E1" class="ltx_equationgroup ltx_eqn_table">
<tbody>
<tr id="S2.E1X" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equationgroup ltx_align_left">(1)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S2.E1X.2.1.1.m1.1" class="ltx_Math" alttext="\displaystyle\min_{\bm{\theta}_{g}}" display="inline"><semantics id="S2.E1X.2.1.1.m1.1a"><munder id="S2.E1X.2.1.1.m1.1.1" xref="S2.E1X.2.1.1.m1.1.1.cmml"><mi id="S2.E1X.2.1.1.m1.1.1.2" xref="S2.E1X.2.1.1.m1.1.1.2.cmml">min</mi><msub id="S2.E1X.2.1.1.m1.1.1.3" xref="S2.E1X.2.1.1.m1.1.1.3.cmml"><mi id="S2.E1X.2.1.1.m1.1.1.3.2" xref="S2.E1X.2.1.1.m1.1.1.3.2.cmml">ğœ½</mi><mi id="S2.E1X.2.1.1.m1.1.1.3.3" xref="S2.E1X.2.1.1.m1.1.1.3.3.cmml">g</mi></msub></munder><annotation-xml encoding="MathML-Content" id="S2.E1X.2.1.1.m1.1b"><apply id="S2.E1X.2.1.1.m1.1.1.cmml" xref="S2.E1X.2.1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.E1X.2.1.1.m1.1.1.1.cmml" xref="S2.E1X.2.1.1.m1.1.1">subscript</csymbol><min id="S2.E1X.2.1.1.m1.1.1.2.cmml" xref="S2.E1X.2.1.1.m1.1.1.2"></min><apply id="S2.E1X.2.1.1.m1.1.1.3.cmml" xref="S2.E1X.2.1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S2.E1X.2.1.1.m1.1.1.3.1.cmml" xref="S2.E1X.2.1.1.m1.1.1.3">subscript</csymbol><ci id="S2.E1X.2.1.1.m1.1.1.3.2.cmml" xref="S2.E1X.2.1.1.m1.1.1.3.2">ğœ½</ci><ci id="S2.E1X.2.1.1.m1.1.1.3.3.cmml" xref="S2.E1X.2.1.1.m1.1.1.3.3">ğ‘”</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1X.2.1.1.m1.1c">\displaystyle\min_{\bm{\theta}_{g}}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S2.E1X.3.2.2.m1.7" class="ltx_Math" alttext="\displaystyle\ \mathbb{E}_{(\bm{x},\bm{y})\sim\mathcal{D}_{i},i\in\mathcal{C}}\left[\mathcal{L}(f(\bm{\theta}_{g};\bm{x}),\bm{y})\right]" display="inline"><semantics id="S2.E1X.3.2.2.m1.7a"><mrow id="S2.E1X.3.2.2.m1.7.7" xref="S2.E1X.3.2.2.m1.7.7.cmml"><msub id="S2.E1X.3.2.2.m1.7.7.3" xref="S2.E1X.3.2.2.m1.7.7.3.cmml"><mi id="S2.E1X.3.2.2.m1.7.7.3.2" xref="S2.E1X.3.2.2.m1.7.7.3.2.cmml">ğ”¼</mi><mrow id="S2.E1X.3.2.2.m1.4.4.4.4" xref="S2.E1X.3.2.2.m1.4.4.4.5.cmml"><mrow id="S2.E1X.3.2.2.m1.3.3.3.3.1" xref="S2.E1X.3.2.2.m1.3.3.3.3.1.cmml"><mrow id="S2.E1X.3.2.2.m1.3.3.3.3.1.2.2" xref="S2.E1X.3.2.2.m1.3.3.3.3.1.2.1.cmml"><mo stretchy="false" id="S2.E1X.3.2.2.m1.3.3.3.3.1.2.2.1" xref="S2.E1X.3.2.2.m1.3.3.3.3.1.2.1.cmml">(</mo><mi id="S2.E1X.3.2.2.m1.1.1.1.1" xref="S2.E1X.3.2.2.m1.1.1.1.1.cmml">ğ’™</mi><mo id="S2.E1X.3.2.2.m1.3.3.3.3.1.2.2.2" xref="S2.E1X.3.2.2.m1.3.3.3.3.1.2.1.cmml">,</mo><mi id="S2.E1X.3.2.2.m1.2.2.2.2" xref="S2.E1X.3.2.2.m1.2.2.2.2.cmml">ğ’š</mi><mo stretchy="false" id="S2.E1X.3.2.2.m1.3.3.3.3.1.2.2.3" xref="S2.E1X.3.2.2.m1.3.3.3.3.1.2.1.cmml">)</mo></mrow><mo id="S2.E1X.3.2.2.m1.3.3.3.3.1.1" xref="S2.E1X.3.2.2.m1.3.3.3.3.1.1.cmml">âˆ¼</mo><msub id="S2.E1X.3.2.2.m1.3.3.3.3.1.3" xref="S2.E1X.3.2.2.m1.3.3.3.3.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E1X.3.2.2.m1.3.3.3.3.1.3.2" xref="S2.E1X.3.2.2.m1.3.3.3.3.1.3.2.cmml">ğ’Ÿ</mi><mi id="S2.E1X.3.2.2.m1.3.3.3.3.1.3.3" xref="S2.E1X.3.2.2.m1.3.3.3.3.1.3.3.cmml">i</mi></msub></mrow><mo id="S2.E1X.3.2.2.m1.4.4.4.4.3" xref="S2.E1X.3.2.2.m1.4.4.4.5a.cmml">,</mo><mrow id="S2.E1X.3.2.2.m1.4.4.4.4.2" xref="S2.E1X.3.2.2.m1.4.4.4.4.2.cmml"><mi id="S2.E1X.3.2.2.m1.4.4.4.4.2.2" xref="S2.E1X.3.2.2.m1.4.4.4.4.2.2.cmml">i</mi><mo id="S2.E1X.3.2.2.m1.4.4.4.4.2.1" xref="S2.E1X.3.2.2.m1.4.4.4.4.2.1.cmml">âˆˆ</mo><mi class="ltx_font_mathcaligraphic" id="S2.E1X.3.2.2.m1.4.4.4.4.2.3" xref="S2.E1X.3.2.2.m1.4.4.4.4.2.3.cmml">ğ’</mi></mrow></mrow></msub><mo lspace="0em" rspace="0em" id="S2.E1X.3.2.2.m1.7.7.2" xref="S2.E1X.3.2.2.m1.7.7.2.cmml">â€‹</mo><mrow id="S2.E1X.3.2.2.m1.7.7.1.1" xref="S2.E1X.3.2.2.m1.7.7.1.2.cmml"><mo id="S2.E1X.3.2.2.m1.7.7.1.1.2" xref="S2.E1X.3.2.2.m1.7.7.1.2.1.cmml">[</mo><mrow id="S2.E1X.3.2.2.m1.7.7.1.1.1" xref="S2.E1X.3.2.2.m1.7.7.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E1X.3.2.2.m1.7.7.1.1.1.3" xref="S2.E1X.3.2.2.m1.7.7.1.1.1.3.cmml">â„’</mi><mo lspace="0em" rspace="0em" id="S2.E1X.3.2.2.m1.7.7.1.1.1.2" xref="S2.E1X.3.2.2.m1.7.7.1.1.1.2.cmml">â€‹</mo><mrow id="S2.E1X.3.2.2.m1.7.7.1.1.1.1.1" xref="S2.E1X.3.2.2.m1.7.7.1.1.1.1.2.cmml"><mo stretchy="false" id="S2.E1X.3.2.2.m1.7.7.1.1.1.1.1.2" xref="S2.E1X.3.2.2.m1.7.7.1.1.1.1.2.cmml">(</mo><mrow id="S2.E1X.3.2.2.m1.7.7.1.1.1.1.1.1" xref="S2.E1X.3.2.2.m1.7.7.1.1.1.1.1.1.cmml"><mi id="S2.E1X.3.2.2.m1.7.7.1.1.1.1.1.1.3" xref="S2.E1X.3.2.2.m1.7.7.1.1.1.1.1.1.3.cmml">f</mi><mo lspace="0em" rspace="0em" id="S2.E1X.3.2.2.m1.7.7.1.1.1.1.1.1.2" xref="S2.E1X.3.2.2.m1.7.7.1.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S2.E1X.3.2.2.m1.7.7.1.1.1.1.1.1.1.1" xref="S2.E1X.3.2.2.m1.7.7.1.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S2.E1X.3.2.2.m1.7.7.1.1.1.1.1.1.1.1.2" xref="S2.E1X.3.2.2.m1.7.7.1.1.1.1.1.1.1.2.cmml">(</mo><msub id="S2.E1X.3.2.2.m1.7.7.1.1.1.1.1.1.1.1.1" xref="S2.E1X.3.2.2.m1.7.7.1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.E1X.3.2.2.m1.7.7.1.1.1.1.1.1.1.1.1.2" xref="S2.E1X.3.2.2.m1.7.7.1.1.1.1.1.1.1.1.1.2.cmml">ğœ½</mi><mi id="S2.E1X.3.2.2.m1.7.7.1.1.1.1.1.1.1.1.1.3" xref="S2.E1X.3.2.2.m1.7.7.1.1.1.1.1.1.1.1.1.3.cmml">g</mi></msub><mo id="S2.E1X.3.2.2.m1.7.7.1.1.1.1.1.1.1.1.3" xref="S2.E1X.3.2.2.m1.7.7.1.1.1.1.1.1.1.2.cmml">;</mo><mi id="S2.E1X.3.2.2.m1.5.5" xref="S2.E1X.3.2.2.m1.5.5.cmml">ğ’™</mi><mo stretchy="false" id="S2.E1X.3.2.2.m1.7.7.1.1.1.1.1.1.1.1.4" xref="S2.E1X.3.2.2.m1.7.7.1.1.1.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S2.E1X.3.2.2.m1.7.7.1.1.1.1.1.3" xref="S2.E1X.3.2.2.m1.7.7.1.1.1.1.2.cmml">,</mo><mi id="S2.E1X.3.2.2.m1.6.6" xref="S2.E1X.3.2.2.m1.6.6.cmml">ğ’š</mi><mo stretchy="false" id="S2.E1X.3.2.2.m1.7.7.1.1.1.1.1.4" xref="S2.E1X.3.2.2.m1.7.7.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S2.E1X.3.2.2.m1.7.7.1.1.3" xref="S2.E1X.3.2.2.m1.7.7.1.2.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E1X.3.2.2.m1.7b"><apply id="S2.E1X.3.2.2.m1.7.7.cmml" xref="S2.E1X.3.2.2.m1.7.7"><times id="S2.E1X.3.2.2.m1.7.7.2.cmml" xref="S2.E1X.3.2.2.m1.7.7.2"></times><apply id="S2.E1X.3.2.2.m1.7.7.3.cmml" xref="S2.E1X.3.2.2.m1.7.7.3"><csymbol cd="ambiguous" id="S2.E1X.3.2.2.m1.7.7.3.1.cmml" xref="S2.E1X.3.2.2.m1.7.7.3">subscript</csymbol><ci id="S2.E1X.3.2.2.m1.7.7.3.2.cmml" xref="S2.E1X.3.2.2.m1.7.7.3.2">ğ”¼</ci><apply id="S2.E1X.3.2.2.m1.4.4.4.5.cmml" xref="S2.E1X.3.2.2.m1.4.4.4.4"><csymbol cd="ambiguous" id="S2.E1X.3.2.2.m1.4.4.4.5a.cmml" xref="S2.E1X.3.2.2.m1.4.4.4.4.3">formulae-sequence</csymbol><apply id="S2.E1X.3.2.2.m1.3.3.3.3.1.cmml" xref="S2.E1X.3.2.2.m1.3.3.3.3.1"><csymbol cd="latexml" id="S2.E1X.3.2.2.m1.3.3.3.3.1.1.cmml" xref="S2.E1X.3.2.2.m1.3.3.3.3.1.1">similar-to</csymbol><interval closure="open" id="S2.E1X.3.2.2.m1.3.3.3.3.1.2.1.cmml" xref="S2.E1X.3.2.2.m1.3.3.3.3.1.2.2"><ci id="S2.E1X.3.2.2.m1.1.1.1.1.cmml" xref="S2.E1X.3.2.2.m1.1.1.1.1">ğ’™</ci><ci id="S2.E1X.3.2.2.m1.2.2.2.2.cmml" xref="S2.E1X.3.2.2.m1.2.2.2.2">ğ’š</ci></interval><apply id="S2.E1X.3.2.2.m1.3.3.3.3.1.3.cmml" xref="S2.E1X.3.2.2.m1.3.3.3.3.1.3"><csymbol cd="ambiguous" id="S2.E1X.3.2.2.m1.3.3.3.3.1.3.1.cmml" xref="S2.E1X.3.2.2.m1.3.3.3.3.1.3">subscript</csymbol><ci id="S2.E1X.3.2.2.m1.3.3.3.3.1.3.2.cmml" xref="S2.E1X.3.2.2.m1.3.3.3.3.1.3.2">ğ’Ÿ</ci><ci id="S2.E1X.3.2.2.m1.3.3.3.3.1.3.3.cmml" xref="S2.E1X.3.2.2.m1.3.3.3.3.1.3.3">ğ‘–</ci></apply></apply><apply id="S2.E1X.3.2.2.m1.4.4.4.4.2.cmml" xref="S2.E1X.3.2.2.m1.4.4.4.4.2"><in id="S2.E1X.3.2.2.m1.4.4.4.4.2.1.cmml" xref="S2.E1X.3.2.2.m1.4.4.4.4.2.1"></in><ci id="S2.E1X.3.2.2.m1.4.4.4.4.2.2.cmml" xref="S2.E1X.3.2.2.m1.4.4.4.4.2.2">ğ‘–</ci><ci id="S2.E1X.3.2.2.m1.4.4.4.4.2.3.cmml" xref="S2.E1X.3.2.2.m1.4.4.4.4.2.3">ğ’</ci></apply></apply></apply><apply id="S2.E1X.3.2.2.m1.7.7.1.2.cmml" xref="S2.E1X.3.2.2.m1.7.7.1.1"><csymbol cd="latexml" id="S2.E1X.3.2.2.m1.7.7.1.2.1.cmml" xref="S2.E1X.3.2.2.m1.7.7.1.1.2">delimited-[]</csymbol><apply id="S2.E1X.3.2.2.m1.7.7.1.1.1.cmml" xref="S2.E1X.3.2.2.m1.7.7.1.1.1"><times id="S2.E1X.3.2.2.m1.7.7.1.1.1.2.cmml" xref="S2.E1X.3.2.2.m1.7.7.1.1.1.2"></times><ci id="S2.E1X.3.2.2.m1.7.7.1.1.1.3.cmml" xref="S2.E1X.3.2.2.m1.7.7.1.1.1.3">â„’</ci><interval closure="open" id="S2.E1X.3.2.2.m1.7.7.1.1.1.1.2.cmml" xref="S2.E1X.3.2.2.m1.7.7.1.1.1.1.1"><apply id="S2.E1X.3.2.2.m1.7.7.1.1.1.1.1.1.cmml" xref="S2.E1X.3.2.2.m1.7.7.1.1.1.1.1.1"><times id="S2.E1X.3.2.2.m1.7.7.1.1.1.1.1.1.2.cmml" xref="S2.E1X.3.2.2.m1.7.7.1.1.1.1.1.1.2"></times><ci id="S2.E1X.3.2.2.m1.7.7.1.1.1.1.1.1.3.cmml" xref="S2.E1X.3.2.2.m1.7.7.1.1.1.1.1.1.3">ğ‘“</ci><list id="S2.E1X.3.2.2.m1.7.7.1.1.1.1.1.1.1.2.cmml" xref="S2.E1X.3.2.2.m1.7.7.1.1.1.1.1.1.1.1"><apply id="S2.E1X.3.2.2.m1.7.7.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E1X.3.2.2.m1.7.7.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E1X.3.2.2.m1.7.7.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E1X.3.2.2.m1.7.7.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.E1X.3.2.2.m1.7.7.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E1X.3.2.2.m1.7.7.1.1.1.1.1.1.1.1.1.2">ğœ½</ci><ci id="S2.E1X.3.2.2.m1.7.7.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E1X.3.2.2.m1.7.7.1.1.1.1.1.1.1.1.1.3">ğ‘”</ci></apply><ci id="S2.E1X.3.2.2.m1.5.5.cmml" xref="S2.E1X.3.2.2.m1.5.5">ğ’™</ci></list></apply><ci id="S2.E1X.3.2.2.m1.6.6.cmml" xref="S2.E1X.3.2.2.m1.6.6">ğ’š</ci></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1X.3.2.2.m1.7c">\displaystyle\ \mathbb{E}_{(\bm{x},\bm{y})\sim\mathcal{D}_{i},i\in\mathcal{C}}\left[\mathcal{L}(f(\bm{\theta}_{g};\bm{x}),\bm{y})\right]</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
</tbody>
</table>
<p id="S2.SS1.p1.9" class="ltx_p">where <math id="S2.SS1.p1.5.m1.1" class="ltx_Math" alttext="\bm{\theta}_{g}" display="inline"><semantics id="S2.SS1.p1.5.m1.1a"><msub id="S2.SS1.p1.5.m1.1.1" xref="S2.SS1.p1.5.m1.1.1.cmml"><mi id="S2.SS1.p1.5.m1.1.1.2" xref="S2.SS1.p1.5.m1.1.1.2.cmml">ğœ½</mi><mi id="S2.SS1.p1.5.m1.1.1.3" xref="S2.SS1.p1.5.m1.1.1.3.cmml">g</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.5.m1.1b"><apply id="S2.SS1.p1.5.m1.1.1.cmml" xref="S2.SS1.p1.5.m1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.5.m1.1.1.1.cmml" xref="S2.SS1.p1.5.m1.1.1">subscript</csymbol><ci id="S2.SS1.p1.5.m1.1.1.2.cmml" xref="S2.SS1.p1.5.m1.1.1.2">ğœ½</ci><ci id="S2.SS1.p1.5.m1.1.1.3.cmml" xref="S2.SS1.p1.5.m1.1.1.3">ğ‘”</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.5.m1.1c">\bm{\theta}_{g}</annotation></semantics></math> is the global model shared with all clients. <math id="S2.SS1.p1.6.m2.1" class="ltx_Math" alttext="\mathcal{L}" display="inline"><semantics id="S2.SS1.p1.6.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p1.6.m2.1.1" xref="S2.SS1.p1.6.m2.1.1.cmml">â„’</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.6.m2.1b"><ci id="S2.SS1.p1.6.m2.1.1.cmml" xref="S2.SS1.p1.6.m2.1.1">â„’</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.6.m2.1c">\mathcal{L}</annotation></semantics></math> is the loss function, such as cross-entropy of the classification task. FedAvgÂ <cite class="ltx_cite ltx_citemacro_citep">(McMahan etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib41" title="" class="ltx_ref">2017</a>)</cite> is the most widely used method to solve Eq.<a href="#S2.E1" title="In 2.1. Personalized Federated Learning â€£ 2. Background â€£ Revisiting Personalized Federated Learning: Robustness Against Backdoor Attacks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. For each round of FL training, several clients are selected by the server to participate in the training. The server first broadcasts <math id="S2.SS1.p1.7.m3.1" class="ltx_Math" alttext="\bm{\theta}_{g}" display="inline"><semantics id="S2.SS1.p1.7.m3.1a"><msub id="S2.SS1.p1.7.m3.1.1" xref="S2.SS1.p1.7.m3.1.1.cmml"><mi id="S2.SS1.p1.7.m3.1.1.2" xref="S2.SS1.p1.7.m3.1.1.2.cmml">ğœ½</mi><mi id="S2.SS1.p1.7.m3.1.1.3" xref="S2.SS1.p1.7.m3.1.1.3.cmml">g</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.7.m3.1b"><apply id="S2.SS1.p1.7.m3.1.1.cmml" xref="S2.SS1.p1.7.m3.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.7.m3.1.1.1.cmml" xref="S2.SS1.p1.7.m3.1.1">subscript</csymbol><ci id="S2.SS1.p1.7.m3.1.1.2.cmml" xref="S2.SS1.p1.7.m3.1.1.2">ğœ½</ci><ci id="S2.SS1.p1.7.m3.1.1.3.cmml" xref="S2.SS1.p1.7.m3.1.1.3">ğ‘”</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.7.m3.1c">\bm{\theta}_{g}</annotation></semantics></math> to selected clients. All clients then locally train <math id="S2.SS1.p1.8.m4.2" class="ltx_Math" alttext="f(\bm{\theta}_{g};\cdot)" display="inline"><semantics id="S2.SS1.p1.8.m4.2a"><mrow id="S2.SS1.p1.8.m4.2.2" xref="S2.SS1.p1.8.m4.2.2.cmml"><mi id="S2.SS1.p1.8.m4.2.2.3" xref="S2.SS1.p1.8.m4.2.2.3.cmml">f</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p1.8.m4.2.2.2" xref="S2.SS1.p1.8.m4.2.2.2.cmml">â€‹</mo><mrow id="S2.SS1.p1.8.m4.2.2.1.1" xref="S2.SS1.p1.8.m4.2.2.1.2.cmml"><mo stretchy="false" id="S2.SS1.p1.8.m4.2.2.1.1.2" xref="S2.SS1.p1.8.m4.2.2.1.2.cmml">(</mo><msub id="S2.SS1.p1.8.m4.2.2.1.1.1" xref="S2.SS1.p1.8.m4.2.2.1.1.1.cmml"><mi id="S2.SS1.p1.8.m4.2.2.1.1.1.2" xref="S2.SS1.p1.8.m4.2.2.1.1.1.2.cmml">ğœ½</mi><mi id="S2.SS1.p1.8.m4.2.2.1.1.1.3" xref="S2.SS1.p1.8.m4.2.2.1.1.1.3.cmml">g</mi></msub><mo rspace="0em" id="S2.SS1.p1.8.m4.2.2.1.1.3" xref="S2.SS1.p1.8.m4.2.2.1.2.cmml">;</mo><mo lspace="0em" rspace="0em" id="S2.SS1.p1.8.m4.1.1" xref="S2.SS1.p1.8.m4.1.1.cmml">â‹…</mo><mo stretchy="false" id="S2.SS1.p1.8.m4.2.2.1.1.4" xref="S2.SS1.p1.8.m4.2.2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.8.m4.2b"><apply id="S2.SS1.p1.8.m4.2.2.cmml" xref="S2.SS1.p1.8.m4.2.2"><times id="S2.SS1.p1.8.m4.2.2.2.cmml" xref="S2.SS1.p1.8.m4.2.2.2"></times><ci id="S2.SS1.p1.8.m4.2.2.3.cmml" xref="S2.SS1.p1.8.m4.2.2.3">ğ‘“</ci><list id="S2.SS1.p1.8.m4.2.2.1.2.cmml" xref="S2.SS1.p1.8.m4.2.2.1.1"><apply id="S2.SS1.p1.8.m4.2.2.1.1.1.cmml" xref="S2.SS1.p1.8.m4.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.8.m4.2.2.1.1.1.1.cmml" xref="S2.SS1.p1.8.m4.2.2.1.1.1">subscript</csymbol><ci id="S2.SS1.p1.8.m4.2.2.1.1.1.2.cmml" xref="S2.SS1.p1.8.m4.2.2.1.1.1.2">ğœ½</ci><ci id="S2.SS1.p1.8.m4.2.2.1.1.1.3.cmml" xref="S2.SS1.p1.8.m4.2.2.1.1.1.3">ğ‘”</ci></apply><ci id="S2.SS1.p1.8.m4.1.1.cmml" xref="S2.SS1.p1.8.m4.1.1">â‹…</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.8.m4.2c">f(\bm{\theta}_{g};\cdot)</annotation></semantics></math> on their private dataset by using SGD for several epochs and upload the update of <math id="S2.SS1.p1.9.m5.1" class="ltx_Math" alttext="\bm{\theta}_{g}" display="inline"><semantics id="S2.SS1.p1.9.m5.1a"><msub id="S2.SS1.p1.9.m5.1.1" xref="S2.SS1.p1.9.m5.1.1.cmml"><mi id="S2.SS1.p1.9.m5.1.1.2" xref="S2.SS1.p1.9.m5.1.1.2.cmml">ğœ½</mi><mi id="S2.SS1.p1.9.m5.1.1.3" xref="S2.SS1.p1.9.m5.1.1.3.cmml">g</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.9.m5.1b"><apply id="S2.SS1.p1.9.m5.1.1.cmml" xref="S2.SS1.p1.9.m5.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.9.m5.1.1.1.cmml" xref="S2.SS1.p1.9.m5.1.1">subscript</csymbol><ci id="S2.SS1.p1.9.m5.1.1.2.cmml" xref="S2.SS1.p1.9.m5.1.1.2">ğœ½</ci><ci id="S2.SS1.p1.9.m5.1.1.3.cmml" xref="S2.SS1.p1.9.m5.1.1.3">ğ‘”</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.9.m5.1c">\bm{\theta}_{g}</annotation></semantics></math> to the server. After receiving all clientsâ€™ update, the server conducts the weighted average of updates by</p>
<table id="A3.EGx1" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S2.E2"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(2)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S2.E2.m1.4" class="ltx_Math" alttext="\displaystyle\overline{\nabla\bm{\theta}_{g}}=\sum_{j=1}^{M}\frac{|\mathcal{S}_{j}|}{|\mathcal{S}|}\nabla\bm{\theta}_{g}^{j},\ \ |\mathcal{S}|=\sum_{j=1}^{M}|\mathcal{S}_{j}|." display="inline"><semantics id="S2.E2.m1.4a"><mrow id="S2.E2.m1.4.4.1"><mrow id="S2.E2.m1.4.4.1.1.2" xref="S2.E2.m1.4.4.1.1.3.cmml"><mrow id="S2.E2.m1.4.4.1.1.1.1" xref="S2.E2.m1.4.4.1.1.1.1.cmml"><mover accent="true" id="S2.E2.m1.4.4.1.1.1.1.2" xref="S2.E2.m1.4.4.1.1.1.1.2.cmml"><mrow id="S2.E2.m1.4.4.1.1.1.1.2.2" xref="S2.E2.m1.4.4.1.1.1.1.2.2.cmml"><mo rspace="0.167em" id="S2.E2.m1.4.4.1.1.1.1.2.2.1" xref="S2.E2.m1.4.4.1.1.1.1.2.2.1.cmml">âˆ‡</mo><msub id="S2.E2.m1.4.4.1.1.1.1.2.2.2" xref="S2.E2.m1.4.4.1.1.1.1.2.2.2.cmml"><mi id="S2.E2.m1.4.4.1.1.1.1.2.2.2.2" xref="S2.E2.m1.4.4.1.1.1.1.2.2.2.2.cmml">ğœ½</mi><mi id="S2.E2.m1.4.4.1.1.1.1.2.2.2.3" xref="S2.E2.m1.4.4.1.1.1.1.2.2.2.3.cmml">g</mi></msub></mrow><mo id="S2.E2.m1.4.4.1.1.1.1.2.1" xref="S2.E2.m1.4.4.1.1.1.1.2.1.cmml">Â¯</mo></mover><mo id="S2.E2.m1.4.4.1.1.1.1.1" xref="S2.E2.m1.4.4.1.1.1.1.1.cmml">=</mo><mrow id="S2.E2.m1.4.4.1.1.1.1.3" xref="S2.E2.m1.4.4.1.1.1.1.3.cmml"><mstyle displaystyle="true" id="S2.E2.m1.4.4.1.1.1.1.3.1" xref="S2.E2.m1.4.4.1.1.1.1.3.1.cmml"><munderover id="S2.E2.m1.4.4.1.1.1.1.3.1a" xref="S2.E2.m1.4.4.1.1.1.1.3.1.cmml"><mo movablelimits="false" id="S2.E2.m1.4.4.1.1.1.1.3.1.2.2" xref="S2.E2.m1.4.4.1.1.1.1.3.1.2.2.cmml">âˆ‘</mo><mrow id="S2.E2.m1.4.4.1.1.1.1.3.1.2.3" xref="S2.E2.m1.4.4.1.1.1.1.3.1.2.3.cmml"><mi id="S2.E2.m1.4.4.1.1.1.1.3.1.2.3.2" xref="S2.E2.m1.4.4.1.1.1.1.3.1.2.3.2.cmml">j</mi><mo id="S2.E2.m1.4.4.1.1.1.1.3.1.2.3.1" xref="S2.E2.m1.4.4.1.1.1.1.3.1.2.3.1.cmml">=</mo><mn id="S2.E2.m1.4.4.1.1.1.1.3.1.2.3.3" xref="S2.E2.m1.4.4.1.1.1.1.3.1.2.3.3.cmml">1</mn></mrow><mi id="S2.E2.m1.4.4.1.1.1.1.3.1.3" xref="S2.E2.m1.4.4.1.1.1.1.3.1.3.cmml">M</mi></munderover></mstyle><mrow id="S2.E2.m1.4.4.1.1.1.1.3.2" xref="S2.E2.m1.4.4.1.1.1.1.3.2.cmml"><mstyle displaystyle="true" id="S2.E2.m1.2.2" xref="S2.E2.m1.2.2.cmml"><mfrac id="S2.E2.m1.2.2a" xref="S2.E2.m1.2.2.cmml"><mrow id="S2.E2.m1.1.1.1.1" xref="S2.E2.m1.1.1.1.2.cmml"><mo stretchy="false" id="S2.E2.m1.1.1.1.1.2" xref="S2.E2.m1.1.1.1.2.1.cmml">|</mo><msub id="S2.E2.m1.1.1.1.1.1" xref="S2.E2.m1.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E2.m1.1.1.1.1.1.2" xref="S2.E2.m1.1.1.1.1.1.2.cmml">ğ’®</mi><mi id="S2.E2.m1.1.1.1.1.1.3" xref="S2.E2.m1.1.1.1.1.1.3.cmml">j</mi></msub><mo stretchy="false" id="S2.E2.m1.1.1.1.1.3" xref="S2.E2.m1.1.1.1.2.1.cmml">|</mo></mrow><mrow id="S2.E2.m1.2.2.2.3" xref="S2.E2.m1.2.2.2.2.cmml"><mo stretchy="false" id="S2.E2.m1.2.2.2.3.1" xref="S2.E2.m1.2.2.2.2.1.cmml">|</mo><mi class="ltx_font_mathcaligraphic" id="S2.E2.m1.2.2.2.1" xref="S2.E2.m1.2.2.2.1.cmml">ğ’®</mi><mo stretchy="false" id="S2.E2.m1.2.2.2.3.2" xref="S2.E2.m1.2.2.2.2.1.cmml">|</mo></mrow></mfrac></mstyle><mo lspace="0.167em" rspace="0em" id="S2.E2.m1.4.4.1.1.1.1.3.2.1" xref="S2.E2.m1.4.4.1.1.1.1.3.2.1.cmml">â€‹</mo><mrow id="S2.E2.m1.4.4.1.1.1.1.3.2.2" xref="S2.E2.m1.4.4.1.1.1.1.3.2.2.cmml"><mo rspace="0.167em" id="S2.E2.m1.4.4.1.1.1.1.3.2.2.1" xref="S2.E2.m1.4.4.1.1.1.1.3.2.2.1.cmml">âˆ‡</mo><msubsup id="S2.E2.m1.4.4.1.1.1.1.3.2.2.2" xref="S2.E2.m1.4.4.1.1.1.1.3.2.2.2.cmml"><mi id="S2.E2.m1.4.4.1.1.1.1.3.2.2.2.2.2" xref="S2.E2.m1.4.4.1.1.1.1.3.2.2.2.2.2.cmml">ğœ½</mi><mi id="S2.E2.m1.4.4.1.1.1.1.3.2.2.2.2.3" xref="S2.E2.m1.4.4.1.1.1.1.3.2.2.2.2.3.cmml">g</mi><mi id="S2.E2.m1.4.4.1.1.1.1.3.2.2.2.3" xref="S2.E2.m1.4.4.1.1.1.1.3.2.2.2.3.cmml">j</mi></msubsup></mrow></mrow></mrow></mrow><mo rspace="1.167em" id="S2.E2.m1.4.4.1.1.2.3" xref="S2.E2.m1.4.4.1.1.3a.cmml">,</mo><mrow id="S2.E2.m1.4.4.1.1.2.2" xref="S2.E2.m1.4.4.1.1.2.2.cmml"><mrow id="S2.E2.m1.4.4.1.1.2.2.3.2" xref="S2.E2.m1.4.4.1.1.2.2.3.1.cmml"><mo stretchy="false" id="S2.E2.m1.4.4.1.1.2.2.3.2.1" xref="S2.E2.m1.4.4.1.1.2.2.3.1.1.cmml">|</mo><mi class="ltx_font_mathcaligraphic" id="S2.E2.m1.3.3" xref="S2.E2.m1.3.3.cmml">ğ’®</mi><mo stretchy="false" id="S2.E2.m1.4.4.1.1.2.2.3.2.2" xref="S2.E2.m1.4.4.1.1.2.2.3.1.1.cmml">|</mo></mrow><mo id="S2.E2.m1.4.4.1.1.2.2.2" xref="S2.E2.m1.4.4.1.1.2.2.2.cmml">=</mo><mrow id="S2.E2.m1.4.4.1.1.2.2.1" xref="S2.E2.m1.4.4.1.1.2.2.1.cmml"><mstyle displaystyle="true" id="S2.E2.m1.4.4.1.1.2.2.1.2" xref="S2.E2.m1.4.4.1.1.2.2.1.2.cmml"><munderover id="S2.E2.m1.4.4.1.1.2.2.1.2a" xref="S2.E2.m1.4.4.1.1.2.2.1.2.cmml"><mo movablelimits="false" id="S2.E2.m1.4.4.1.1.2.2.1.2.2.2" xref="S2.E2.m1.4.4.1.1.2.2.1.2.2.2.cmml">âˆ‘</mo><mrow id="S2.E2.m1.4.4.1.1.2.2.1.2.2.3" xref="S2.E2.m1.4.4.1.1.2.2.1.2.2.3.cmml"><mi id="S2.E2.m1.4.4.1.1.2.2.1.2.2.3.2" xref="S2.E2.m1.4.4.1.1.2.2.1.2.2.3.2.cmml">j</mi><mo id="S2.E2.m1.4.4.1.1.2.2.1.2.2.3.1" xref="S2.E2.m1.4.4.1.1.2.2.1.2.2.3.1.cmml">=</mo><mn id="S2.E2.m1.4.4.1.1.2.2.1.2.2.3.3" xref="S2.E2.m1.4.4.1.1.2.2.1.2.2.3.3.cmml">1</mn></mrow><mi id="S2.E2.m1.4.4.1.1.2.2.1.2.3" xref="S2.E2.m1.4.4.1.1.2.2.1.2.3.cmml">M</mi></munderover></mstyle><mrow id="S2.E2.m1.4.4.1.1.2.2.1.1.1" xref="S2.E2.m1.4.4.1.1.2.2.1.1.2.cmml"><mo stretchy="false" id="S2.E2.m1.4.4.1.1.2.2.1.1.1.2" xref="S2.E2.m1.4.4.1.1.2.2.1.1.2.1.cmml">|</mo><msub id="S2.E2.m1.4.4.1.1.2.2.1.1.1.1" xref="S2.E2.m1.4.4.1.1.2.2.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E2.m1.4.4.1.1.2.2.1.1.1.1.2" xref="S2.E2.m1.4.4.1.1.2.2.1.1.1.1.2.cmml">ğ’®</mi><mi id="S2.E2.m1.4.4.1.1.2.2.1.1.1.1.3" xref="S2.E2.m1.4.4.1.1.2.2.1.1.1.1.3.cmml">j</mi></msub><mo stretchy="false" id="S2.E2.m1.4.4.1.1.2.2.1.1.1.3" xref="S2.E2.m1.4.4.1.1.2.2.1.1.2.1.cmml">|</mo></mrow></mrow></mrow></mrow><mo lspace="0em" id="S2.E2.m1.4.4.1.2">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E2.m1.4b"><apply id="S2.E2.m1.4.4.1.1.3.cmml" xref="S2.E2.m1.4.4.1.1.2"><csymbol cd="ambiguous" id="S2.E2.m1.4.4.1.1.3a.cmml" xref="S2.E2.m1.4.4.1.1.2.3">formulae-sequence</csymbol><apply id="S2.E2.m1.4.4.1.1.1.1.cmml" xref="S2.E2.m1.4.4.1.1.1.1"><eq id="S2.E2.m1.4.4.1.1.1.1.1.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1"></eq><apply id="S2.E2.m1.4.4.1.1.1.1.2.cmml" xref="S2.E2.m1.4.4.1.1.1.1.2"><ci id="S2.E2.m1.4.4.1.1.1.1.2.1.cmml" xref="S2.E2.m1.4.4.1.1.1.1.2.1">Â¯</ci><apply id="S2.E2.m1.4.4.1.1.1.1.2.2.cmml" xref="S2.E2.m1.4.4.1.1.1.1.2.2"><ci id="S2.E2.m1.4.4.1.1.1.1.2.2.1.cmml" xref="S2.E2.m1.4.4.1.1.1.1.2.2.1">âˆ‡</ci><apply id="S2.E2.m1.4.4.1.1.1.1.2.2.2.cmml" xref="S2.E2.m1.4.4.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S2.E2.m1.4.4.1.1.1.1.2.2.2.1.cmml" xref="S2.E2.m1.4.4.1.1.1.1.2.2.2">subscript</csymbol><ci id="S2.E2.m1.4.4.1.1.1.1.2.2.2.2.cmml" xref="S2.E2.m1.4.4.1.1.1.1.2.2.2.2">ğœ½</ci><ci id="S2.E2.m1.4.4.1.1.1.1.2.2.2.3.cmml" xref="S2.E2.m1.4.4.1.1.1.1.2.2.2.3">ğ‘”</ci></apply></apply></apply><apply id="S2.E2.m1.4.4.1.1.1.1.3.cmml" xref="S2.E2.m1.4.4.1.1.1.1.3"><apply id="S2.E2.m1.4.4.1.1.1.1.3.1.cmml" xref="S2.E2.m1.4.4.1.1.1.1.3.1"><csymbol cd="ambiguous" id="S2.E2.m1.4.4.1.1.1.1.3.1.1.cmml" xref="S2.E2.m1.4.4.1.1.1.1.3.1">superscript</csymbol><apply id="S2.E2.m1.4.4.1.1.1.1.3.1.2.cmml" xref="S2.E2.m1.4.4.1.1.1.1.3.1"><csymbol cd="ambiguous" id="S2.E2.m1.4.4.1.1.1.1.3.1.2.1.cmml" xref="S2.E2.m1.4.4.1.1.1.1.3.1">subscript</csymbol><sum id="S2.E2.m1.4.4.1.1.1.1.3.1.2.2.cmml" xref="S2.E2.m1.4.4.1.1.1.1.3.1.2.2"></sum><apply id="S2.E2.m1.4.4.1.1.1.1.3.1.2.3.cmml" xref="S2.E2.m1.4.4.1.1.1.1.3.1.2.3"><eq id="S2.E2.m1.4.4.1.1.1.1.3.1.2.3.1.cmml" xref="S2.E2.m1.4.4.1.1.1.1.3.1.2.3.1"></eq><ci id="S2.E2.m1.4.4.1.1.1.1.3.1.2.3.2.cmml" xref="S2.E2.m1.4.4.1.1.1.1.3.1.2.3.2">ğ‘—</ci><cn type="integer" id="S2.E2.m1.4.4.1.1.1.1.3.1.2.3.3.cmml" xref="S2.E2.m1.4.4.1.1.1.1.3.1.2.3.3">1</cn></apply></apply><ci id="S2.E2.m1.4.4.1.1.1.1.3.1.3.cmml" xref="S2.E2.m1.4.4.1.1.1.1.3.1.3">ğ‘€</ci></apply><apply id="S2.E2.m1.4.4.1.1.1.1.3.2.cmml" xref="S2.E2.m1.4.4.1.1.1.1.3.2"><times id="S2.E2.m1.4.4.1.1.1.1.3.2.1.cmml" xref="S2.E2.m1.4.4.1.1.1.1.3.2.1"></times><apply id="S2.E2.m1.2.2.cmml" xref="S2.E2.m1.2.2"><divide id="S2.E2.m1.2.2.3.cmml" xref="S2.E2.m1.2.2"></divide><apply id="S2.E2.m1.1.1.1.2.cmml" xref="S2.E2.m1.1.1.1.1"><abs id="S2.E2.m1.1.1.1.2.1.cmml" xref="S2.E2.m1.1.1.1.1.2"></abs><apply id="S2.E2.m1.1.1.1.1.1.cmml" xref="S2.E2.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.1.1.1.1.cmml" xref="S2.E2.m1.1.1.1.1.1">subscript</csymbol><ci id="S2.E2.m1.1.1.1.1.1.2.cmml" xref="S2.E2.m1.1.1.1.1.1.2">ğ’®</ci><ci id="S2.E2.m1.1.1.1.1.1.3.cmml" xref="S2.E2.m1.1.1.1.1.1.3">ğ‘—</ci></apply></apply><apply id="S2.E2.m1.2.2.2.2.cmml" xref="S2.E2.m1.2.2.2.3"><abs id="S2.E2.m1.2.2.2.2.1.cmml" xref="S2.E2.m1.2.2.2.3.1"></abs><ci id="S2.E2.m1.2.2.2.1.cmml" xref="S2.E2.m1.2.2.2.1">ğ’®</ci></apply></apply><apply id="S2.E2.m1.4.4.1.1.1.1.3.2.2.cmml" xref="S2.E2.m1.4.4.1.1.1.1.3.2.2"><ci id="S2.E2.m1.4.4.1.1.1.1.3.2.2.1.cmml" xref="S2.E2.m1.4.4.1.1.1.1.3.2.2.1">âˆ‡</ci><apply id="S2.E2.m1.4.4.1.1.1.1.3.2.2.2.cmml" xref="S2.E2.m1.4.4.1.1.1.1.3.2.2.2"><csymbol cd="ambiguous" id="S2.E2.m1.4.4.1.1.1.1.3.2.2.2.1.cmml" xref="S2.E2.m1.4.4.1.1.1.1.3.2.2.2">superscript</csymbol><apply id="S2.E2.m1.4.4.1.1.1.1.3.2.2.2.2.cmml" xref="S2.E2.m1.4.4.1.1.1.1.3.2.2.2"><csymbol cd="ambiguous" id="S2.E2.m1.4.4.1.1.1.1.3.2.2.2.2.1.cmml" xref="S2.E2.m1.4.4.1.1.1.1.3.2.2.2">subscript</csymbol><ci id="S2.E2.m1.4.4.1.1.1.1.3.2.2.2.2.2.cmml" xref="S2.E2.m1.4.4.1.1.1.1.3.2.2.2.2.2">ğœ½</ci><ci id="S2.E2.m1.4.4.1.1.1.1.3.2.2.2.2.3.cmml" xref="S2.E2.m1.4.4.1.1.1.1.3.2.2.2.2.3">ğ‘”</ci></apply><ci id="S2.E2.m1.4.4.1.1.1.1.3.2.2.2.3.cmml" xref="S2.E2.m1.4.4.1.1.1.1.3.2.2.2.3">ğ‘—</ci></apply></apply></apply></apply></apply><apply id="S2.E2.m1.4.4.1.1.2.2.cmml" xref="S2.E2.m1.4.4.1.1.2.2"><eq id="S2.E2.m1.4.4.1.1.2.2.2.cmml" xref="S2.E2.m1.4.4.1.1.2.2.2"></eq><apply id="S2.E2.m1.4.4.1.1.2.2.3.1.cmml" xref="S2.E2.m1.4.4.1.1.2.2.3.2"><abs id="S2.E2.m1.4.4.1.1.2.2.3.1.1.cmml" xref="S2.E2.m1.4.4.1.1.2.2.3.2.1"></abs><ci id="S2.E2.m1.3.3.cmml" xref="S2.E2.m1.3.3">ğ’®</ci></apply><apply id="S2.E2.m1.4.4.1.1.2.2.1.cmml" xref="S2.E2.m1.4.4.1.1.2.2.1"><apply id="S2.E2.m1.4.4.1.1.2.2.1.2.cmml" xref="S2.E2.m1.4.4.1.1.2.2.1.2"><csymbol cd="ambiguous" id="S2.E2.m1.4.4.1.1.2.2.1.2.1.cmml" xref="S2.E2.m1.4.4.1.1.2.2.1.2">superscript</csymbol><apply id="S2.E2.m1.4.4.1.1.2.2.1.2.2.cmml" xref="S2.E2.m1.4.4.1.1.2.2.1.2"><csymbol cd="ambiguous" id="S2.E2.m1.4.4.1.1.2.2.1.2.2.1.cmml" xref="S2.E2.m1.4.4.1.1.2.2.1.2">subscript</csymbol><sum id="S2.E2.m1.4.4.1.1.2.2.1.2.2.2.cmml" xref="S2.E2.m1.4.4.1.1.2.2.1.2.2.2"></sum><apply id="S2.E2.m1.4.4.1.1.2.2.1.2.2.3.cmml" xref="S2.E2.m1.4.4.1.1.2.2.1.2.2.3"><eq id="S2.E2.m1.4.4.1.1.2.2.1.2.2.3.1.cmml" xref="S2.E2.m1.4.4.1.1.2.2.1.2.2.3.1"></eq><ci id="S2.E2.m1.4.4.1.1.2.2.1.2.2.3.2.cmml" xref="S2.E2.m1.4.4.1.1.2.2.1.2.2.3.2">ğ‘—</ci><cn type="integer" id="S2.E2.m1.4.4.1.1.2.2.1.2.2.3.3.cmml" xref="S2.E2.m1.4.4.1.1.2.2.1.2.2.3.3">1</cn></apply></apply><ci id="S2.E2.m1.4.4.1.1.2.2.1.2.3.cmml" xref="S2.E2.m1.4.4.1.1.2.2.1.2.3">ğ‘€</ci></apply><apply id="S2.E2.m1.4.4.1.1.2.2.1.1.2.cmml" xref="S2.E2.m1.4.4.1.1.2.2.1.1.1"><abs id="S2.E2.m1.4.4.1.1.2.2.1.1.2.1.cmml" xref="S2.E2.m1.4.4.1.1.2.2.1.1.1.2"></abs><apply id="S2.E2.m1.4.4.1.1.2.2.1.1.1.1.cmml" xref="S2.E2.m1.4.4.1.1.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S2.E2.m1.4.4.1.1.2.2.1.1.1.1.1.cmml" xref="S2.E2.m1.4.4.1.1.2.2.1.1.1.1">subscript</csymbol><ci id="S2.E2.m1.4.4.1.1.2.2.1.1.1.1.2.cmml" xref="S2.E2.m1.4.4.1.1.2.2.1.1.1.1.2">ğ’®</ci><ci id="S2.E2.m1.4.4.1.1.2.2.1.1.1.1.3.cmml" xref="S2.E2.m1.4.4.1.1.2.2.1.1.1.1.3">ğ‘—</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E2.m1.4c">\displaystyle\overline{\nabla\bm{\theta}_{g}}=\sum_{j=1}^{M}\frac{|\mathcal{S}_{j}|}{|\mathcal{S}|}\nabla\bm{\theta}_{g}^{j},\ \ |\mathcal{S}|=\sum_{j=1}^{M}|\mathcal{S}_{j}|.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S2.SS1.p1.13" class="ltx_p">Here, <math id="S2.SS1.p1.10.m1.1" class="ltx_Math" alttext="|\mathcal{S}_{j}|" display="inline"><semantics id="S2.SS1.p1.10.m1.1a"><mrow id="S2.SS1.p1.10.m1.1.1.1" xref="S2.SS1.p1.10.m1.1.1.2.cmml"><mo stretchy="false" id="S2.SS1.p1.10.m1.1.1.1.2" xref="S2.SS1.p1.10.m1.1.1.2.1.cmml">|</mo><msub id="S2.SS1.p1.10.m1.1.1.1.1" xref="S2.SS1.p1.10.m1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p1.10.m1.1.1.1.1.2" xref="S2.SS1.p1.10.m1.1.1.1.1.2.cmml">ğ’®</mi><mi id="S2.SS1.p1.10.m1.1.1.1.1.3" xref="S2.SS1.p1.10.m1.1.1.1.1.3.cmml">j</mi></msub><mo stretchy="false" id="S2.SS1.p1.10.m1.1.1.1.3" xref="S2.SS1.p1.10.m1.1.1.2.1.cmml">|</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.10.m1.1b"><apply id="S2.SS1.p1.10.m1.1.1.2.cmml" xref="S2.SS1.p1.10.m1.1.1.1"><abs id="S2.SS1.p1.10.m1.1.1.2.1.cmml" xref="S2.SS1.p1.10.m1.1.1.1.2"></abs><apply id="S2.SS1.p1.10.m1.1.1.1.1.cmml" xref="S2.SS1.p1.10.m1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.10.m1.1.1.1.1.1.cmml" xref="S2.SS1.p1.10.m1.1.1.1.1">subscript</csymbol><ci id="S2.SS1.p1.10.m1.1.1.1.1.2.cmml" xref="S2.SS1.p1.10.m1.1.1.1.1.2">ğ’®</ci><ci id="S2.SS1.p1.10.m1.1.1.1.1.3.cmml" xref="S2.SS1.p1.10.m1.1.1.1.1.3">ğ‘—</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.10.m1.1c">|\mathcal{S}_{j}|</annotation></semantics></math> is the size of dataset owned by the selected client <math id="S2.SS1.p1.11.m2.1" class="ltx_Math" alttext="j" display="inline"><semantics id="S2.SS1.p1.11.m2.1a"><mi id="S2.SS1.p1.11.m2.1.1" xref="S2.SS1.p1.11.m2.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.11.m2.1b"><ci id="S2.SS1.p1.11.m2.1.1.cmml" xref="S2.SS1.p1.11.m2.1.1">ğ‘—</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.11.m2.1c">j</annotation></semantics></math>. The server applies the <math id="S2.SS1.p1.12.m3.1" class="ltx_Math" alttext="\overline{\nabla\bm{\theta}_{g}}" display="inline"><semantics id="S2.SS1.p1.12.m3.1a"><mover accent="true" id="S2.SS1.p1.12.m3.1.1" xref="S2.SS1.p1.12.m3.1.1.cmml"><mrow id="S2.SS1.p1.12.m3.1.1.2" xref="S2.SS1.p1.12.m3.1.1.2.cmml"><mo rspace="0.167em" id="S2.SS1.p1.12.m3.1.1.2.1" xref="S2.SS1.p1.12.m3.1.1.2.1.cmml">âˆ‡</mo><msub id="S2.SS1.p1.12.m3.1.1.2.2" xref="S2.SS1.p1.12.m3.1.1.2.2.cmml"><mi id="S2.SS1.p1.12.m3.1.1.2.2.2" xref="S2.SS1.p1.12.m3.1.1.2.2.2.cmml">ğœ½</mi><mi id="S2.SS1.p1.12.m3.1.1.2.2.3" xref="S2.SS1.p1.12.m3.1.1.2.2.3.cmml">g</mi></msub></mrow><mo id="S2.SS1.p1.12.m3.1.1.1" xref="S2.SS1.p1.12.m3.1.1.1.cmml">Â¯</mo></mover><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.12.m3.1b"><apply id="S2.SS1.p1.12.m3.1.1.cmml" xref="S2.SS1.p1.12.m3.1.1"><ci id="S2.SS1.p1.12.m3.1.1.1.cmml" xref="S2.SS1.p1.12.m3.1.1.1">Â¯</ci><apply id="S2.SS1.p1.12.m3.1.1.2.cmml" xref="S2.SS1.p1.12.m3.1.1.2"><ci id="S2.SS1.p1.12.m3.1.1.2.1.cmml" xref="S2.SS1.p1.12.m3.1.1.2.1">âˆ‡</ci><apply id="S2.SS1.p1.12.m3.1.1.2.2.cmml" xref="S2.SS1.p1.12.m3.1.1.2.2"><csymbol cd="ambiguous" id="S2.SS1.p1.12.m3.1.1.2.2.1.cmml" xref="S2.SS1.p1.12.m3.1.1.2.2">subscript</csymbol><ci id="S2.SS1.p1.12.m3.1.1.2.2.2.cmml" xref="S2.SS1.p1.12.m3.1.1.2.2.2">ğœ½</ci><ci id="S2.SS1.p1.12.m3.1.1.2.2.3.cmml" xref="S2.SS1.p1.12.m3.1.1.2.2.3">ğ‘”</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.12.m3.1c">\overline{\nabla\bm{\theta}_{g}}</annotation></semantics></math> into <math id="S2.SS1.p1.13.m4.1" class="ltx_Math" alttext="\bm{\theta}_{g}" display="inline"><semantics id="S2.SS1.p1.13.m4.1a"><msub id="S2.SS1.p1.13.m4.1.1" xref="S2.SS1.p1.13.m4.1.1.cmml"><mi id="S2.SS1.p1.13.m4.1.1.2" xref="S2.SS1.p1.13.m4.1.1.2.cmml">ğœ½</mi><mi id="S2.SS1.p1.13.m4.1.1.3" xref="S2.SS1.p1.13.m4.1.1.3.cmml">g</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.13.m4.1b"><apply id="S2.SS1.p1.13.m4.1.1.cmml" xref="S2.SS1.p1.13.m4.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.13.m4.1.1.1.cmml" xref="S2.SS1.p1.13.m4.1.1">subscript</csymbol><ci id="S2.SS1.p1.13.m4.1.1.2.cmml" xref="S2.SS1.p1.13.m4.1.1.2">ğœ½</ci><ci id="S2.SS1.p1.13.m4.1.1.3.cmml" xref="S2.SS1.p1.13.m4.1.1.3">ğ‘”</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.13.m4.1c">\bm{\theta}_{g}</annotation></semantics></math> for the next round of FL training, and the process repeats until convergence.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">Being different from FL, pFL methods not only tend to learn a global model but also aim to learn a local personalized model for each client. The local personalized model is better adaptive to each clientâ€™s local dataset and helps pFL methods surpass general FL methods by a large margin on prediction accuracy under practical Non-IID scenariosÂ <cite class="ltx_cite ltx_citemacro_citep">(Tan etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib51" title="" class="ltx_ref">2022</a>; Hanzely etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib21" title="" class="ltx_ref">2021</a>; Pillutla etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib45" title="" class="ltx_ref">2022</a>; Collins etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2021</a>; Liang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib36" title="" class="ltx_ref">2020</a>; Smith etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib48" title="" class="ltx_ref">2017</a>; Zhang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib61" title="" class="ltx_ref">2022b</a>)</cite>. Here, <span id="S2.SS1.p2.1.1" class="ltx_text ltx_font_bold">we use below formulations to illustrate various pFL methods based on different personalization degrees</span>.</p>
</div>
<section id="S2.SS1.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">
<span id="S2.SS1.SSS0.Px1.1.1" class="ltx_text ltx_font_bold">(i)</span> Full model-sharingÂ <cite class="ltx_cite ltx_citemacro_citep">(Li etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib32" title="" class="ltx_ref">2021a</a>; Liang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib36" title="" class="ltx_ref">2020</a>; TÂ Dinh etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib50" title="" class="ltx_ref">2020</a>; Marfoq etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib39" title="" class="ltx_ref">2021</a>; Fallah etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib17" title="" class="ltx_ref">2020</a>)</cite>:</h5>

<div id="S2.SS1.SSS0.Px1.p1" class="ltx_para">
<table id="S2.E3" class="ltx_equationgroup ltx_eqn_table">
<tbody>
<tr id="S2.E3X" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equationgroup ltx_align_left">(3)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S2.E3X.2.1.1.m1.2" class="ltx_Math" alttext="\displaystyle\min_{\bm{\theta}_{g},\{\bm{\theta}_{i}\}_{i\in C}}" display="inline"><semantics id="S2.E3X.2.1.1.m1.2a"><munder id="S2.E3X.2.1.1.m1.2.3" xref="S2.E3X.2.1.1.m1.2.3.cmml"><mi id="S2.E3X.2.1.1.m1.2.3.2" xref="S2.E3X.2.1.1.m1.2.3.2.cmml">min</mi><mrow id="S2.E3X.2.1.1.m1.2.2.2.2" xref="S2.E3X.2.1.1.m1.2.2.2.3.cmml"><msub id="S2.E3X.2.1.1.m1.1.1.1.1.1" xref="S2.E3X.2.1.1.m1.1.1.1.1.1.cmml"><mi id="S2.E3X.2.1.1.m1.1.1.1.1.1.2" xref="S2.E3X.2.1.1.m1.1.1.1.1.1.2.cmml">ğœ½</mi><mi id="S2.E3X.2.1.1.m1.1.1.1.1.1.3" xref="S2.E3X.2.1.1.m1.1.1.1.1.1.3.cmml">g</mi></msub><mo id="S2.E3X.2.1.1.m1.2.2.2.2.3" xref="S2.E3X.2.1.1.m1.2.2.2.3.cmml">,</mo><msub id="S2.E3X.2.1.1.m1.2.2.2.2.2" xref="S2.E3X.2.1.1.m1.2.2.2.2.2.cmml"><mrow id="S2.E3X.2.1.1.m1.2.2.2.2.2.1.1" xref="S2.E3X.2.1.1.m1.2.2.2.2.2.1.2.cmml"><mo stretchy="false" id="S2.E3X.2.1.1.m1.2.2.2.2.2.1.1.2" xref="S2.E3X.2.1.1.m1.2.2.2.2.2.1.2.cmml">{</mo><msub id="S2.E3X.2.1.1.m1.2.2.2.2.2.1.1.1" xref="S2.E3X.2.1.1.m1.2.2.2.2.2.1.1.1.cmml"><mi id="S2.E3X.2.1.1.m1.2.2.2.2.2.1.1.1.2" xref="S2.E3X.2.1.1.m1.2.2.2.2.2.1.1.1.2.cmml">ğœ½</mi><mi id="S2.E3X.2.1.1.m1.2.2.2.2.2.1.1.1.3" xref="S2.E3X.2.1.1.m1.2.2.2.2.2.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S2.E3X.2.1.1.m1.2.2.2.2.2.1.1.3" xref="S2.E3X.2.1.1.m1.2.2.2.2.2.1.2.cmml">}</mo></mrow><mrow id="S2.E3X.2.1.1.m1.2.2.2.2.2.3" xref="S2.E3X.2.1.1.m1.2.2.2.2.2.3.cmml"><mi id="S2.E3X.2.1.1.m1.2.2.2.2.2.3.2" xref="S2.E3X.2.1.1.m1.2.2.2.2.2.3.2.cmml">i</mi><mo id="S2.E3X.2.1.1.m1.2.2.2.2.2.3.1" xref="S2.E3X.2.1.1.m1.2.2.2.2.2.3.1.cmml">âˆˆ</mo><mi id="S2.E3X.2.1.1.m1.2.2.2.2.2.3.3" xref="S2.E3X.2.1.1.m1.2.2.2.2.2.3.3.cmml">C</mi></mrow></msub></mrow></munder><annotation-xml encoding="MathML-Content" id="S2.E3X.2.1.1.m1.2b"><apply id="S2.E3X.2.1.1.m1.2.3.cmml" xref="S2.E3X.2.1.1.m1.2.3"><csymbol cd="ambiguous" id="S2.E3X.2.1.1.m1.2.3.1.cmml" xref="S2.E3X.2.1.1.m1.2.3">subscript</csymbol><min id="S2.E3X.2.1.1.m1.2.3.2.cmml" xref="S2.E3X.2.1.1.m1.2.3.2"></min><list id="S2.E3X.2.1.1.m1.2.2.2.3.cmml" xref="S2.E3X.2.1.1.m1.2.2.2.2"><apply id="S2.E3X.2.1.1.m1.1.1.1.1.1.cmml" xref="S2.E3X.2.1.1.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E3X.2.1.1.m1.1.1.1.1.1.1.cmml" xref="S2.E3X.2.1.1.m1.1.1.1.1.1">subscript</csymbol><ci id="S2.E3X.2.1.1.m1.1.1.1.1.1.2.cmml" xref="S2.E3X.2.1.1.m1.1.1.1.1.1.2">ğœ½</ci><ci id="S2.E3X.2.1.1.m1.1.1.1.1.1.3.cmml" xref="S2.E3X.2.1.1.m1.1.1.1.1.1.3">ğ‘”</ci></apply><apply id="S2.E3X.2.1.1.m1.2.2.2.2.2.cmml" xref="S2.E3X.2.1.1.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="S2.E3X.2.1.1.m1.2.2.2.2.2.2.cmml" xref="S2.E3X.2.1.1.m1.2.2.2.2.2">subscript</csymbol><set id="S2.E3X.2.1.1.m1.2.2.2.2.2.1.2.cmml" xref="S2.E3X.2.1.1.m1.2.2.2.2.2.1.1"><apply id="S2.E3X.2.1.1.m1.2.2.2.2.2.1.1.1.cmml" xref="S2.E3X.2.1.1.m1.2.2.2.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.E3X.2.1.1.m1.2.2.2.2.2.1.1.1.1.cmml" xref="S2.E3X.2.1.1.m1.2.2.2.2.2.1.1.1">subscript</csymbol><ci id="S2.E3X.2.1.1.m1.2.2.2.2.2.1.1.1.2.cmml" xref="S2.E3X.2.1.1.m1.2.2.2.2.2.1.1.1.2">ğœ½</ci><ci id="S2.E3X.2.1.1.m1.2.2.2.2.2.1.1.1.3.cmml" xref="S2.E3X.2.1.1.m1.2.2.2.2.2.1.1.1.3">ğ‘–</ci></apply></set><apply id="S2.E3X.2.1.1.m1.2.2.2.2.2.3.cmml" xref="S2.E3X.2.1.1.m1.2.2.2.2.2.3"><in id="S2.E3X.2.1.1.m1.2.2.2.2.2.3.1.cmml" xref="S2.E3X.2.1.1.m1.2.2.2.2.2.3.1"></in><ci id="S2.E3X.2.1.1.m1.2.2.2.2.2.3.2.cmml" xref="S2.E3X.2.1.1.m1.2.2.2.2.2.3.2">ğ‘–</ci><ci id="S2.E3X.2.1.1.m1.2.2.2.2.2.3.3.cmml" xref="S2.E3X.2.1.1.m1.2.2.2.2.2.3.3">ğ¶</ci></apply></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E3X.2.1.1.m1.2c">\displaystyle\min_{\bm{\theta}_{g},\{\bm{\theta}_{i}\}_{i\in C}}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S2.E3X.3.2.2.m1.7" class="ltx_Math" alttext="\displaystyle\mathbb{E}_{(\bm{x},\bm{y})\sim\mathcal{D}_{i},i\in\mathcal{C}}\left[\mathcal{L}(f(\bm{\theta_{i}};\bm{x}),\bm{y})\right]+\lambda\mathcal{H}(\bm{\theta}_{g},\bm{\theta}_{i})," display="inline"><semantics id="S2.E3X.3.2.2.m1.7a"><mrow id="S2.E3X.3.2.2.m1.7.7.1" xref="S2.E3X.3.2.2.m1.7.7.1.1.cmml"><mrow id="S2.E3X.3.2.2.m1.7.7.1.1" xref="S2.E3X.3.2.2.m1.7.7.1.1.cmml"><mrow id="S2.E3X.3.2.2.m1.7.7.1.1.1" xref="S2.E3X.3.2.2.m1.7.7.1.1.1.cmml"><msub id="S2.E3X.3.2.2.m1.7.7.1.1.1.3" xref="S2.E3X.3.2.2.m1.7.7.1.1.1.3.cmml"><mi id="S2.E3X.3.2.2.m1.7.7.1.1.1.3.2" xref="S2.E3X.3.2.2.m1.7.7.1.1.1.3.2.cmml">ğ”¼</mi><mrow id="S2.E3X.3.2.2.m1.4.4.4.4" xref="S2.E3X.3.2.2.m1.4.4.4.5.cmml"><mrow id="S2.E3X.3.2.2.m1.3.3.3.3.1" xref="S2.E3X.3.2.2.m1.3.3.3.3.1.cmml"><mrow id="S2.E3X.3.2.2.m1.3.3.3.3.1.2.2" xref="S2.E3X.3.2.2.m1.3.3.3.3.1.2.1.cmml"><mo stretchy="false" id="S2.E3X.3.2.2.m1.3.3.3.3.1.2.2.1" xref="S2.E3X.3.2.2.m1.3.3.3.3.1.2.1.cmml">(</mo><mi id="S2.E3X.3.2.2.m1.1.1.1.1" xref="S2.E3X.3.2.2.m1.1.1.1.1.cmml">ğ’™</mi><mo id="S2.E3X.3.2.2.m1.3.3.3.3.1.2.2.2" xref="S2.E3X.3.2.2.m1.3.3.3.3.1.2.1.cmml">,</mo><mi id="S2.E3X.3.2.2.m1.2.2.2.2" xref="S2.E3X.3.2.2.m1.2.2.2.2.cmml">ğ’š</mi><mo stretchy="false" id="S2.E3X.3.2.2.m1.3.3.3.3.1.2.2.3" xref="S2.E3X.3.2.2.m1.3.3.3.3.1.2.1.cmml">)</mo></mrow><mo id="S2.E3X.3.2.2.m1.3.3.3.3.1.1" xref="S2.E3X.3.2.2.m1.3.3.3.3.1.1.cmml">âˆ¼</mo><msub id="S2.E3X.3.2.2.m1.3.3.3.3.1.3" xref="S2.E3X.3.2.2.m1.3.3.3.3.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E3X.3.2.2.m1.3.3.3.3.1.3.2" xref="S2.E3X.3.2.2.m1.3.3.3.3.1.3.2.cmml">ğ’Ÿ</mi><mi id="S2.E3X.3.2.2.m1.3.3.3.3.1.3.3" xref="S2.E3X.3.2.2.m1.3.3.3.3.1.3.3.cmml">i</mi></msub></mrow><mo id="S2.E3X.3.2.2.m1.4.4.4.4.3" xref="S2.E3X.3.2.2.m1.4.4.4.5a.cmml">,</mo><mrow id="S2.E3X.3.2.2.m1.4.4.4.4.2" xref="S2.E3X.3.2.2.m1.4.4.4.4.2.cmml"><mi id="S2.E3X.3.2.2.m1.4.4.4.4.2.2" xref="S2.E3X.3.2.2.m1.4.4.4.4.2.2.cmml">i</mi><mo id="S2.E3X.3.2.2.m1.4.4.4.4.2.1" xref="S2.E3X.3.2.2.m1.4.4.4.4.2.1.cmml">âˆˆ</mo><mi class="ltx_font_mathcaligraphic" id="S2.E3X.3.2.2.m1.4.4.4.4.2.3" xref="S2.E3X.3.2.2.m1.4.4.4.4.2.3.cmml">ğ’</mi></mrow></mrow></msub><mo lspace="0em" rspace="0em" id="S2.E3X.3.2.2.m1.7.7.1.1.1.2" xref="S2.E3X.3.2.2.m1.7.7.1.1.1.2.cmml">â€‹</mo><mrow id="S2.E3X.3.2.2.m1.7.7.1.1.1.1.1" xref="S2.E3X.3.2.2.m1.7.7.1.1.1.1.2.cmml"><mo id="S2.E3X.3.2.2.m1.7.7.1.1.1.1.1.2" xref="S2.E3X.3.2.2.m1.7.7.1.1.1.1.2.1.cmml">[</mo><mrow id="S2.E3X.3.2.2.m1.7.7.1.1.1.1.1.1" xref="S2.E3X.3.2.2.m1.7.7.1.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E3X.3.2.2.m1.7.7.1.1.1.1.1.1.3" xref="S2.E3X.3.2.2.m1.7.7.1.1.1.1.1.1.3.cmml">â„’</mi><mo lspace="0em" rspace="0em" id="S2.E3X.3.2.2.m1.7.7.1.1.1.1.1.1.2" xref="S2.E3X.3.2.2.m1.7.7.1.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S2.E3X.3.2.2.m1.7.7.1.1.1.1.1.1.1.1" xref="S2.E3X.3.2.2.m1.7.7.1.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S2.E3X.3.2.2.m1.7.7.1.1.1.1.1.1.1.1.2" xref="S2.E3X.3.2.2.m1.7.7.1.1.1.1.1.1.1.2.cmml">(</mo><mrow id="S2.E3X.3.2.2.m1.7.7.1.1.1.1.1.1.1.1.1" xref="S2.E3X.3.2.2.m1.7.7.1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.E3X.3.2.2.m1.7.7.1.1.1.1.1.1.1.1.1.3" xref="S2.E3X.3.2.2.m1.7.7.1.1.1.1.1.1.1.1.1.3.cmml">f</mi><mo lspace="0em" rspace="0em" id="S2.E3X.3.2.2.m1.7.7.1.1.1.1.1.1.1.1.1.2" xref="S2.E3X.3.2.2.m1.7.7.1.1.1.1.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S2.E3X.3.2.2.m1.7.7.1.1.1.1.1.1.1.1.1.1.1" xref="S2.E3X.3.2.2.m1.7.7.1.1.1.1.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S2.E3X.3.2.2.m1.7.7.1.1.1.1.1.1.1.1.1.1.1.2" xref="S2.E3X.3.2.2.m1.7.7.1.1.1.1.1.1.1.1.1.1.2.cmml">(</mo><msub id="S2.E3X.3.2.2.m1.7.7.1.1.1.1.1.1.1.1.1.1.1.1" xref="S2.E3X.3.2.2.m1.7.7.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.E3X.3.2.2.m1.7.7.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S2.E3X.3.2.2.m1.7.7.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">ğœ½</mi><mi id="S2.E3X.3.2.2.m1.7.7.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S2.E3X.3.2.2.m1.7.7.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">ğ’Š</mi></msub><mo id="S2.E3X.3.2.2.m1.7.7.1.1.1.1.1.1.1.1.1.1.1.3" xref="S2.E3X.3.2.2.m1.7.7.1.1.1.1.1.1.1.1.1.1.2.cmml">;</mo><mi id="S2.E3X.3.2.2.m1.5.5" xref="S2.E3X.3.2.2.m1.5.5.cmml">ğ’™</mi><mo stretchy="false" id="S2.E3X.3.2.2.m1.7.7.1.1.1.1.1.1.1.1.1.1.1.4" xref="S2.E3X.3.2.2.m1.7.7.1.1.1.1.1.1.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S2.E3X.3.2.2.m1.7.7.1.1.1.1.1.1.1.1.3" xref="S2.E3X.3.2.2.m1.7.7.1.1.1.1.1.1.1.2.cmml">,</mo><mi id="S2.E3X.3.2.2.m1.6.6" xref="S2.E3X.3.2.2.m1.6.6.cmml">ğ’š</mi><mo stretchy="false" id="S2.E3X.3.2.2.m1.7.7.1.1.1.1.1.1.1.1.4" xref="S2.E3X.3.2.2.m1.7.7.1.1.1.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S2.E3X.3.2.2.m1.7.7.1.1.1.1.1.3" xref="S2.E3X.3.2.2.m1.7.7.1.1.1.1.2.1.cmml">]</mo></mrow></mrow><mo id="S2.E3X.3.2.2.m1.7.7.1.1.4" xref="S2.E3X.3.2.2.m1.7.7.1.1.4.cmml">+</mo><mrow id="S2.E3X.3.2.2.m1.7.7.1.1.3" xref="S2.E3X.3.2.2.m1.7.7.1.1.3.cmml"><mi id="S2.E3X.3.2.2.m1.7.7.1.1.3.4" xref="S2.E3X.3.2.2.m1.7.7.1.1.3.4.cmml">Î»</mi><mo lspace="0em" rspace="0em" id="S2.E3X.3.2.2.m1.7.7.1.1.3.3" xref="S2.E3X.3.2.2.m1.7.7.1.1.3.3.cmml">â€‹</mo><mi class="ltx_font_mathcaligraphic" id="S2.E3X.3.2.2.m1.7.7.1.1.3.5" xref="S2.E3X.3.2.2.m1.7.7.1.1.3.5.cmml">â„‹</mi><mo lspace="0em" rspace="0em" id="S2.E3X.3.2.2.m1.7.7.1.1.3.3a" xref="S2.E3X.3.2.2.m1.7.7.1.1.3.3.cmml">â€‹</mo><mrow id="S2.E3X.3.2.2.m1.7.7.1.1.3.2.2" xref="S2.E3X.3.2.2.m1.7.7.1.1.3.2.3.cmml"><mo stretchy="false" id="S2.E3X.3.2.2.m1.7.7.1.1.3.2.2.3" xref="S2.E3X.3.2.2.m1.7.7.1.1.3.2.3.cmml">(</mo><msub id="S2.E3X.3.2.2.m1.7.7.1.1.2.1.1.1" xref="S2.E3X.3.2.2.m1.7.7.1.1.2.1.1.1.cmml"><mi id="S2.E3X.3.2.2.m1.7.7.1.1.2.1.1.1.2" xref="S2.E3X.3.2.2.m1.7.7.1.1.2.1.1.1.2.cmml">ğœ½</mi><mi id="S2.E3X.3.2.2.m1.7.7.1.1.2.1.1.1.3" xref="S2.E3X.3.2.2.m1.7.7.1.1.2.1.1.1.3.cmml">g</mi></msub><mo id="S2.E3X.3.2.2.m1.7.7.1.1.3.2.2.4" xref="S2.E3X.3.2.2.m1.7.7.1.1.3.2.3.cmml">,</mo><msub id="S2.E3X.3.2.2.m1.7.7.1.1.3.2.2.2" xref="S2.E3X.3.2.2.m1.7.7.1.1.3.2.2.2.cmml"><mi id="S2.E3X.3.2.2.m1.7.7.1.1.3.2.2.2.2" xref="S2.E3X.3.2.2.m1.7.7.1.1.3.2.2.2.2.cmml">ğœ½</mi><mi id="S2.E3X.3.2.2.m1.7.7.1.1.3.2.2.2.3" xref="S2.E3X.3.2.2.m1.7.7.1.1.3.2.2.2.3.cmml">i</mi></msub><mo stretchy="false" id="S2.E3X.3.2.2.m1.7.7.1.1.3.2.2.5" xref="S2.E3X.3.2.2.m1.7.7.1.1.3.2.3.cmml">)</mo></mrow></mrow></mrow><mo id="S2.E3X.3.2.2.m1.7.7.1.2" xref="S2.E3X.3.2.2.m1.7.7.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E3X.3.2.2.m1.7b"><apply id="S2.E3X.3.2.2.m1.7.7.1.1.cmml" xref="S2.E3X.3.2.2.m1.7.7.1"><plus id="S2.E3X.3.2.2.m1.7.7.1.1.4.cmml" xref="S2.E3X.3.2.2.m1.7.7.1.1.4"></plus><apply id="S2.E3X.3.2.2.m1.7.7.1.1.1.cmml" xref="S2.E3X.3.2.2.m1.7.7.1.1.1"><times id="S2.E3X.3.2.2.m1.7.7.1.1.1.2.cmml" xref="S2.E3X.3.2.2.m1.7.7.1.1.1.2"></times><apply id="S2.E3X.3.2.2.m1.7.7.1.1.1.3.cmml" xref="S2.E3X.3.2.2.m1.7.7.1.1.1.3"><csymbol cd="ambiguous" id="S2.E3X.3.2.2.m1.7.7.1.1.1.3.1.cmml" xref="S2.E3X.3.2.2.m1.7.7.1.1.1.3">subscript</csymbol><ci id="S2.E3X.3.2.2.m1.7.7.1.1.1.3.2.cmml" xref="S2.E3X.3.2.2.m1.7.7.1.1.1.3.2">ğ”¼</ci><apply id="S2.E3X.3.2.2.m1.4.4.4.5.cmml" xref="S2.E3X.3.2.2.m1.4.4.4.4"><csymbol cd="ambiguous" id="S2.E3X.3.2.2.m1.4.4.4.5a.cmml" xref="S2.E3X.3.2.2.m1.4.4.4.4.3">formulae-sequence</csymbol><apply id="S2.E3X.3.2.2.m1.3.3.3.3.1.cmml" xref="S2.E3X.3.2.2.m1.3.3.3.3.1"><csymbol cd="latexml" id="S2.E3X.3.2.2.m1.3.3.3.3.1.1.cmml" xref="S2.E3X.3.2.2.m1.3.3.3.3.1.1">similar-to</csymbol><interval closure="open" id="S2.E3X.3.2.2.m1.3.3.3.3.1.2.1.cmml" xref="S2.E3X.3.2.2.m1.3.3.3.3.1.2.2"><ci id="S2.E3X.3.2.2.m1.1.1.1.1.cmml" xref="S2.E3X.3.2.2.m1.1.1.1.1">ğ’™</ci><ci id="S2.E3X.3.2.2.m1.2.2.2.2.cmml" xref="S2.E3X.3.2.2.m1.2.2.2.2">ğ’š</ci></interval><apply id="S2.E3X.3.2.2.m1.3.3.3.3.1.3.cmml" xref="S2.E3X.3.2.2.m1.3.3.3.3.1.3"><csymbol cd="ambiguous" id="S2.E3X.3.2.2.m1.3.3.3.3.1.3.1.cmml" xref="S2.E3X.3.2.2.m1.3.3.3.3.1.3">subscript</csymbol><ci id="S2.E3X.3.2.2.m1.3.3.3.3.1.3.2.cmml" xref="S2.E3X.3.2.2.m1.3.3.3.3.1.3.2">ğ’Ÿ</ci><ci id="S2.E3X.3.2.2.m1.3.3.3.3.1.3.3.cmml" xref="S2.E3X.3.2.2.m1.3.3.3.3.1.3.3">ğ‘–</ci></apply></apply><apply id="S2.E3X.3.2.2.m1.4.4.4.4.2.cmml" xref="S2.E3X.3.2.2.m1.4.4.4.4.2"><in id="S2.E3X.3.2.2.m1.4.4.4.4.2.1.cmml" xref="S2.E3X.3.2.2.m1.4.4.4.4.2.1"></in><ci id="S2.E3X.3.2.2.m1.4.4.4.4.2.2.cmml" xref="S2.E3X.3.2.2.m1.4.4.4.4.2.2">ğ‘–</ci><ci id="S2.E3X.3.2.2.m1.4.4.4.4.2.3.cmml" xref="S2.E3X.3.2.2.m1.4.4.4.4.2.3">ğ’</ci></apply></apply></apply><apply id="S2.E3X.3.2.2.m1.7.7.1.1.1.1.2.cmml" xref="S2.E3X.3.2.2.m1.7.7.1.1.1.1.1"><csymbol cd="latexml" id="S2.E3X.3.2.2.m1.7.7.1.1.1.1.2.1.cmml" xref="S2.E3X.3.2.2.m1.7.7.1.1.1.1.1.2">delimited-[]</csymbol><apply id="S2.E3X.3.2.2.m1.7.7.1.1.1.1.1.1.cmml" xref="S2.E3X.3.2.2.m1.7.7.1.1.1.1.1.1"><times id="S2.E3X.3.2.2.m1.7.7.1.1.1.1.1.1.2.cmml" xref="S2.E3X.3.2.2.m1.7.7.1.1.1.1.1.1.2"></times><ci id="S2.E3X.3.2.2.m1.7.7.1.1.1.1.1.1.3.cmml" xref="S2.E3X.3.2.2.m1.7.7.1.1.1.1.1.1.3">â„’</ci><interval closure="open" id="S2.E3X.3.2.2.m1.7.7.1.1.1.1.1.1.1.2.cmml" xref="S2.E3X.3.2.2.m1.7.7.1.1.1.1.1.1.1.1"><apply id="S2.E3X.3.2.2.m1.7.7.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E3X.3.2.2.m1.7.7.1.1.1.1.1.1.1.1.1"><times id="S2.E3X.3.2.2.m1.7.7.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E3X.3.2.2.m1.7.7.1.1.1.1.1.1.1.1.1.2"></times><ci id="S2.E3X.3.2.2.m1.7.7.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E3X.3.2.2.m1.7.7.1.1.1.1.1.1.1.1.1.3">ğ‘“</ci><list id="S2.E3X.3.2.2.m1.7.7.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E3X.3.2.2.m1.7.7.1.1.1.1.1.1.1.1.1.1.1"><apply id="S2.E3X.3.2.2.m1.7.7.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E3X.3.2.2.m1.7.7.1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E3X.3.2.2.m1.7.7.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E3X.3.2.2.m1.7.7.1.1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.E3X.3.2.2.m1.7.7.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E3X.3.2.2.m1.7.7.1.1.1.1.1.1.1.1.1.1.1.1.2">ğœ½</ci><ci id="S2.E3X.3.2.2.m1.7.7.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E3X.3.2.2.m1.7.7.1.1.1.1.1.1.1.1.1.1.1.1.3">ğ’Š</ci></apply><ci id="S2.E3X.3.2.2.m1.5.5.cmml" xref="S2.E3X.3.2.2.m1.5.5">ğ’™</ci></list></apply><ci id="S2.E3X.3.2.2.m1.6.6.cmml" xref="S2.E3X.3.2.2.m1.6.6">ğ’š</ci></interval></apply></apply></apply><apply id="S2.E3X.3.2.2.m1.7.7.1.1.3.cmml" xref="S2.E3X.3.2.2.m1.7.7.1.1.3"><times id="S2.E3X.3.2.2.m1.7.7.1.1.3.3.cmml" xref="S2.E3X.3.2.2.m1.7.7.1.1.3.3"></times><ci id="S2.E3X.3.2.2.m1.7.7.1.1.3.4.cmml" xref="S2.E3X.3.2.2.m1.7.7.1.1.3.4">ğœ†</ci><ci id="S2.E3X.3.2.2.m1.7.7.1.1.3.5.cmml" xref="S2.E3X.3.2.2.m1.7.7.1.1.3.5">â„‹</ci><interval closure="open" id="S2.E3X.3.2.2.m1.7.7.1.1.3.2.3.cmml" xref="S2.E3X.3.2.2.m1.7.7.1.1.3.2.2"><apply id="S2.E3X.3.2.2.m1.7.7.1.1.2.1.1.1.cmml" xref="S2.E3X.3.2.2.m1.7.7.1.1.2.1.1.1"><csymbol cd="ambiguous" id="S2.E3X.3.2.2.m1.7.7.1.1.2.1.1.1.1.cmml" xref="S2.E3X.3.2.2.m1.7.7.1.1.2.1.1.1">subscript</csymbol><ci id="S2.E3X.3.2.2.m1.7.7.1.1.2.1.1.1.2.cmml" xref="S2.E3X.3.2.2.m1.7.7.1.1.2.1.1.1.2">ğœ½</ci><ci id="S2.E3X.3.2.2.m1.7.7.1.1.2.1.1.1.3.cmml" xref="S2.E3X.3.2.2.m1.7.7.1.1.2.1.1.1.3">ğ‘”</ci></apply><apply id="S2.E3X.3.2.2.m1.7.7.1.1.3.2.2.2.cmml" xref="S2.E3X.3.2.2.m1.7.7.1.1.3.2.2.2"><csymbol cd="ambiguous" id="S2.E3X.3.2.2.m1.7.7.1.1.3.2.2.2.1.cmml" xref="S2.E3X.3.2.2.m1.7.7.1.1.3.2.2.2">subscript</csymbol><ci id="S2.E3X.3.2.2.m1.7.7.1.1.3.2.2.2.2.cmml" xref="S2.E3X.3.2.2.m1.7.7.1.1.3.2.2.2.2">ğœ½</ci><ci id="S2.E3X.3.2.2.m1.7.7.1.1.3.2.2.2.3.cmml" xref="S2.E3X.3.2.2.m1.7.7.1.1.3.2.2.2.3">ğ‘–</ci></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E3X.3.2.2.m1.7c">\displaystyle\mathbb{E}_{(\bm{x},\bm{y})\sim\mathcal{D}_{i},i\in\mathcal{C}}\left[\mathcal{L}(f(\bm{\theta_{i}};\bm{x}),\bm{y})\right]+\lambda\mathcal{H}(\bm{\theta}_{g},\bm{\theta}_{i}),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
</tbody>
</table>
<p id="S2.SS1.SSS0.Px1.p1.11" class="ltx_p">where <math id="S2.SS1.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="\bm{\theta}_{i}" display="inline"><semantics id="S2.SS1.SSS0.Px1.p1.1.m1.1a"><msub id="S2.SS1.SSS0.Px1.p1.1.m1.1.1" xref="S2.SS1.SSS0.Px1.p1.1.m1.1.1.cmml"><mi id="S2.SS1.SSS0.Px1.p1.1.m1.1.1.2" xref="S2.SS1.SSS0.Px1.p1.1.m1.1.1.2.cmml">ğœ½</mi><mi id="S2.SS1.SSS0.Px1.p1.1.m1.1.1.3" xref="S2.SS1.SSS0.Px1.p1.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px1.p1.1.m1.1b"><apply id="S2.SS1.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px1.p1.1.m1.1.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.1.m1.1.1">subscript</csymbol><ci id="S2.SS1.SSS0.Px1.p1.1.m1.1.1.2.cmml" xref="S2.SS1.SSS0.Px1.p1.1.m1.1.1.2">ğœ½</ci><ci id="S2.SS1.SSS0.Px1.p1.1.m1.1.1.3.cmml" xref="S2.SS1.SSS0.Px1.p1.1.m1.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px1.p1.1.m1.1c">\bm{\theta}_{i}</annotation></semantics></math> represents local personalized model owned by each client and <math id="S2.SS1.SSS0.Px1.p1.2.m2.1" class="ltx_Math" alttext="\bm{\theta}_{g}" display="inline"><semantics id="S2.SS1.SSS0.Px1.p1.2.m2.1a"><msub id="S2.SS1.SSS0.Px1.p1.2.m2.1.1" xref="S2.SS1.SSS0.Px1.p1.2.m2.1.1.cmml"><mi id="S2.SS1.SSS0.Px1.p1.2.m2.1.1.2" xref="S2.SS1.SSS0.Px1.p1.2.m2.1.1.2.cmml">ğœ½</mi><mi id="S2.SS1.SSS0.Px1.p1.2.m2.1.1.3" xref="S2.SS1.SSS0.Px1.p1.2.m2.1.1.3.cmml">g</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px1.p1.2.m2.1b"><apply id="S2.SS1.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px1.p1.2.m2.1.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.2.m2.1.1">subscript</csymbol><ci id="S2.SS1.SSS0.Px1.p1.2.m2.1.1.2.cmml" xref="S2.SS1.SSS0.Px1.p1.2.m2.1.1.2">ğœ½</ci><ci id="S2.SS1.SSS0.Px1.p1.2.m2.1.1.3.cmml" xref="S2.SS1.SSS0.Px1.p1.2.m2.1.1.3">ğ‘”</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px1.p1.2.m2.1c">\bm{\theta}_{g}</annotation></semantics></math> means the global reference model shared among all clients. We can observe that the whole global model <math id="S2.SS1.SSS0.Px1.p1.3.m3.1" class="ltx_Math" alttext="\bm{\theta}_{g}" display="inline"><semantics id="S2.SS1.SSS0.Px1.p1.3.m3.1a"><msub id="S2.SS1.SSS0.Px1.p1.3.m3.1.1" xref="S2.SS1.SSS0.Px1.p1.3.m3.1.1.cmml"><mi id="S2.SS1.SSS0.Px1.p1.3.m3.1.1.2" xref="S2.SS1.SSS0.Px1.p1.3.m3.1.1.2.cmml">ğœ½</mi><mi id="S2.SS1.SSS0.Px1.p1.3.m3.1.1.3" xref="S2.SS1.SSS0.Px1.p1.3.m3.1.1.3.cmml">g</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px1.p1.3.m3.1b"><apply id="S2.SS1.SSS0.Px1.p1.3.m3.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px1.p1.3.m3.1.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.3.m3.1.1">subscript</csymbol><ci id="S2.SS1.SSS0.Px1.p1.3.m3.1.1.2.cmml" xref="S2.SS1.SSS0.Px1.p1.3.m3.1.1.2">ğœ½</ci><ci id="S2.SS1.SSS0.Px1.p1.3.m3.1.1.3.cmml" xref="S2.SS1.SSS0.Px1.p1.3.m3.1.1.3">ğ‘”</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px1.p1.3.m3.1c">\bm{\theta}_{g}</annotation></semantics></math> is shared across all clients.
The new added <math id="S2.SS1.SSS0.Px1.p1.4.m4.1" class="ltx_Math" alttext="\mathcal{H}" display="inline"><semantics id="S2.SS1.SSS0.Px1.p1.4.m4.1a"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.SSS0.Px1.p1.4.m4.1.1" xref="S2.SS1.SSS0.Px1.p1.4.m4.1.1.cmml">â„‹</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px1.p1.4.m4.1b"><ci id="S2.SS1.SSS0.Px1.p1.4.m4.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.4.m4.1.1">â„‹</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px1.p1.4.m4.1c">\mathcal{H}</annotation></semantics></math> is the regularizer of similarity between <math id="S2.SS1.SSS0.Px1.p1.5.m5.1" class="ltx_Math" alttext="\bm{\theta}_{g}" display="inline"><semantics id="S2.SS1.SSS0.Px1.p1.5.m5.1a"><msub id="S2.SS1.SSS0.Px1.p1.5.m5.1.1" xref="S2.SS1.SSS0.Px1.p1.5.m5.1.1.cmml"><mi id="S2.SS1.SSS0.Px1.p1.5.m5.1.1.2" xref="S2.SS1.SSS0.Px1.p1.5.m5.1.1.2.cmml">ğœ½</mi><mi id="S2.SS1.SSS0.Px1.p1.5.m5.1.1.3" xref="S2.SS1.SSS0.Px1.p1.5.m5.1.1.3.cmml">g</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px1.p1.5.m5.1b"><apply id="S2.SS1.SSS0.Px1.p1.5.m5.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px1.p1.5.m5.1.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.5.m5.1.1">subscript</csymbol><ci id="S2.SS1.SSS0.Px1.p1.5.m5.1.1.2.cmml" xref="S2.SS1.SSS0.Px1.p1.5.m5.1.1.2">ğœ½</ci><ci id="S2.SS1.SSS0.Px1.p1.5.m5.1.1.3.cmml" xref="S2.SS1.SSS0.Px1.p1.5.m5.1.1.3">ğ‘”</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px1.p1.5.m5.1c">\bm{\theta}_{g}</annotation></semantics></math> and <math id="S2.SS1.SSS0.Px1.p1.6.m6.1" class="ltx_Math" alttext="\bm{\theta}_{i}" display="inline"><semantics id="S2.SS1.SSS0.Px1.p1.6.m6.1a"><msub id="S2.SS1.SSS0.Px1.p1.6.m6.1.1" xref="S2.SS1.SSS0.Px1.p1.6.m6.1.1.cmml"><mi id="S2.SS1.SSS0.Px1.p1.6.m6.1.1.2" xref="S2.SS1.SSS0.Px1.p1.6.m6.1.1.2.cmml">ğœ½</mi><mi id="S2.SS1.SSS0.Px1.p1.6.m6.1.1.3" xref="S2.SS1.SSS0.Px1.p1.6.m6.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px1.p1.6.m6.1b"><apply id="S2.SS1.SSS0.Px1.p1.6.m6.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px1.p1.6.m6.1.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.6.m6.1.1">subscript</csymbol><ci id="S2.SS1.SSS0.Px1.p1.6.m6.1.1.2.cmml" xref="S2.SS1.SSS0.Px1.p1.6.m6.1.1.2">ğœ½</ci><ci id="S2.SS1.SSS0.Px1.p1.6.m6.1.1.3.cmml" xref="S2.SS1.SSS0.Px1.p1.6.m6.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px1.p1.6.m6.1c">\bm{\theta}_{i}</annotation></semantics></math> and <math id="S2.SS1.SSS0.Px1.p1.7.m7.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S2.SS1.SSS0.Px1.p1.7.m7.1a"><mi id="S2.SS1.SSS0.Px1.p1.7.m7.1.1" xref="S2.SS1.SSS0.Px1.p1.7.m7.1.1.cmml">Î»</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px1.p1.7.m7.1b"><ci id="S2.SS1.SSS0.Px1.p1.7.m7.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.7.m7.1.1">ğœ†</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px1.p1.7.m7.1c">\lambda</annotation></semantics></math> is the coefficient for each client. In each round, selected clients receive <math id="S2.SS1.SSS0.Px1.p1.8.m8.1" class="ltx_Math" alttext="\bm{\theta}_{g}" display="inline"><semantics id="S2.SS1.SSS0.Px1.p1.8.m8.1a"><msub id="S2.SS1.SSS0.Px1.p1.8.m8.1.1" xref="S2.SS1.SSS0.Px1.p1.8.m8.1.1.cmml"><mi id="S2.SS1.SSS0.Px1.p1.8.m8.1.1.2" xref="S2.SS1.SSS0.Px1.p1.8.m8.1.1.2.cmml">ğœ½</mi><mi id="S2.SS1.SSS0.Px1.p1.8.m8.1.1.3" xref="S2.SS1.SSS0.Px1.p1.8.m8.1.1.3.cmml">g</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px1.p1.8.m8.1b"><apply id="S2.SS1.SSS0.Px1.p1.8.m8.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.8.m8.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px1.p1.8.m8.1.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.8.m8.1.1">subscript</csymbol><ci id="S2.SS1.SSS0.Px1.p1.8.m8.1.1.2.cmml" xref="S2.SS1.SSS0.Px1.p1.8.m8.1.1.2">ğœ½</ci><ci id="S2.SS1.SSS0.Px1.p1.8.m8.1.1.3.cmml" xref="S2.SS1.SSS0.Px1.p1.8.m8.1.1.3">ğ‘”</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px1.p1.8.m8.1c">\bm{\theta}_{g}</annotation></semantics></math> and use it as the reference to training <math id="S2.SS1.SSS0.Px1.p1.9.m9.1" class="ltx_Math" alttext="\bm{\theta}_{i}" display="inline"><semantics id="S2.SS1.SSS0.Px1.p1.9.m9.1a"><msub id="S2.SS1.SSS0.Px1.p1.9.m9.1.1" xref="S2.SS1.SSS0.Px1.p1.9.m9.1.1.cmml"><mi id="S2.SS1.SSS0.Px1.p1.9.m9.1.1.2" xref="S2.SS1.SSS0.Px1.p1.9.m9.1.1.2.cmml">ğœ½</mi><mi id="S2.SS1.SSS0.Px1.p1.9.m9.1.1.3" xref="S2.SS1.SSS0.Px1.p1.9.m9.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px1.p1.9.m9.1b"><apply id="S2.SS1.SSS0.Px1.p1.9.m9.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.9.m9.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px1.p1.9.m9.1.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.9.m9.1.1">subscript</csymbol><ci id="S2.SS1.SSS0.Px1.p1.9.m9.1.1.2.cmml" xref="S2.SS1.SSS0.Px1.p1.9.m9.1.1.2">ğœ½</ci><ci id="S2.SS1.SSS0.Px1.p1.9.m9.1.1.3.cmml" xref="S2.SS1.SSS0.Px1.p1.9.m9.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px1.p1.9.m9.1c">\bm{\theta}_{i}</annotation></semantics></math>. <math id="S2.SS1.SSS0.Px1.p1.10.m10.1" class="ltx_Math" alttext="\bm{\theta}_{g}" display="inline"><semantics id="S2.SS1.SSS0.Px1.p1.10.m10.1a"><msub id="S2.SS1.SSS0.Px1.p1.10.m10.1.1" xref="S2.SS1.SSS0.Px1.p1.10.m10.1.1.cmml"><mi id="S2.SS1.SSS0.Px1.p1.10.m10.1.1.2" xref="S2.SS1.SSS0.Px1.p1.10.m10.1.1.2.cmml">ğœ½</mi><mi id="S2.SS1.SSS0.Px1.p1.10.m10.1.1.3" xref="S2.SS1.SSS0.Px1.p1.10.m10.1.1.3.cmml">g</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px1.p1.10.m10.1b"><apply id="S2.SS1.SSS0.Px1.p1.10.m10.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.10.m10.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px1.p1.10.m10.1.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.10.m10.1.1">subscript</csymbol><ci id="S2.SS1.SSS0.Px1.p1.10.m10.1.1.2.cmml" xref="S2.SS1.SSS0.Px1.p1.10.m10.1.1.2">ğœ½</ci><ci id="S2.SS1.SSS0.Px1.p1.10.m10.1.1.3.cmml" xref="S2.SS1.SSS0.Px1.p1.10.m10.1.1.3">ğ‘”</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px1.p1.10.m10.1c">\bm{\theta}_{g}</annotation></semantics></math> is also updated on local datasets and then uploaded to the server to participate in the aggregation process. Therefore, full model-sharing also indicates knowledge from every clientâ€™s local dataset could be transferred to local models of other clients by sharing <math id="S2.SS1.SSS0.Px1.p1.11.m11.1" class="ltx_Math" alttext="\bm{\theta}_{g}" display="inline"><semantics id="S2.SS1.SSS0.Px1.p1.11.m11.1a"><msub id="S2.SS1.SSS0.Px1.p1.11.m11.1.1" xref="S2.SS1.SSS0.Px1.p1.11.m11.1.1.cmml"><mi id="S2.SS1.SSS0.Px1.p1.11.m11.1.1.2" xref="S2.SS1.SSS0.Px1.p1.11.m11.1.1.2.cmml">ğœ½</mi><mi id="S2.SS1.SSS0.Px1.p1.11.m11.1.1.3" xref="S2.SS1.SSS0.Px1.p1.11.m11.1.1.3.cmml">g</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px1.p1.11.m11.1b"><apply id="S2.SS1.SSS0.Px1.p1.11.m11.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.11.m11.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px1.p1.11.m11.1.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.11.m11.1.1">subscript</csymbol><ci id="S2.SS1.SSS0.Px1.p1.11.m11.1.1.2.cmml" xref="S2.SS1.SSS0.Px1.p1.11.m11.1.1.2">ğœ½</ci><ci id="S2.SS1.SSS0.Px1.p1.11.m11.1.1.3.cmml" xref="S2.SS1.SSS0.Px1.p1.11.m11.1.1.3">ğ‘”</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px1.p1.11.m11.1c">\bm{\theta}_{g}</annotation></semantics></math>.</p>
</div>
<div id="S2.SS1.SSS0.Px1.p2" class="ltx_para">
<p id="S2.SS1.SSS0.Px1.p2.20" class="ltx_p">Here, we introduce several pFL methods with full model-sharing used in our experiments. <span id="S2.SS1.SSS0.Px1.p2.20.1" class="ltx_text ltx_font_bold">(1)</span> <span id="S2.SS1.SSS0.Px1.p2.20.2" class="ltx_text ltx_font_italic">Ditto</span>Â <cite class="ltx_cite ltx_citemacro_citep">(Li etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib32" title="" class="ltx_ref">2021a</a>)</cite>: each client has two models, global model <math id="S2.SS1.SSS0.Px1.p2.1.m1.1" class="ltx_Math" alttext="\bm{\theta}_{g}" display="inline"><semantics id="S2.SS1.SSS0.Px1.p2.1.m1.1a"><msub id="S2.SS1.SSS0.Px1.p2.1.m1.1.1" xref="S2.SS1.SSS0.Px1.p2.1.m1.1.1.cmml"><mi id="S2.SS1.SSS0.Px1.p2.1.m1.1.1.2" xref="S2.SS1.SSS0.Px1.p2.1.m1.1.1.2.cmml">ğœ½</mi><mi id="S2.SS1.SSS0.Px1.p2.1.m1.1.1.3" xref="S2.SS1.SSS0.Px1.p2.1.m1.1.1.3.cmml">g</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px1.p2.1.m1.1b"><apply id="S2.SS1.SSS0.Px1.p2.1.m1.1.1.cmml" xref="S2.SS1.SSS0.Px1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px1.p2.1.m1.1.1.1.cmml" xref="S2.SS1.SSS0.Px1.p2.1.m1.1.1">subscript</csymbol><ci id="S2.SS1.SSS0.Px1.p2.1.m1.1.1.2.cmml" xref="S2.SS1.SSS0.Px1.p2.1.m1.1.1.2">ğœ½</ci><ci id="S2.SS1.SSS0.Px1.p2.1.m1.1.1.3.cmml" xref="S2.SS1.SSS0.Px1.p2.1.m1.1.1.3">ğ‘”</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px1.p2.1.m1.1c">\bm{\theta}_{g}</annotation></semantics></math> and local model <math id="S2.SS1.SSS0.Px1.p2.2.m2.1" class="ltx_Math" alttext="\bm{\theta}_{i}" display="inline"><semantics id="S2.SS1.SSS0.Px1.p2.2.m2.1a"><msub id="S2.SS1.SSS0.Px1.p2.2.m2.1.1" xref="S2.SS1.SSS0.Px1.p2.2.m2.1.1.cmml"><mi id="S2.SS1.SSS0.Px1.p2.2.m2.1.1.2" xref="S2.SS1.SSS0.Px1.p2.2.m2.1.1.2.cmml">ğœ½</mi><mi id="S2.SS1.SSS0.Px1.p2.2.m2.1.1.3" xref="S2.SS1.SSS0.Px1.p2.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px1.p2.2.m2.1b"><apply id="S2.SS1.SSS0.Px1.p2.2.m2.1.1.cmml" xref="S2.SS1.SSS0.Px1.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px1.p2.2.m2.1.1.1.cmml" xref="S2.SS1.SSS0.Px1.p2.2.m2.1.1">subscript</csymbol><ci id="S2.SS1.SSS0.Px1.p2.2.m2.1.1.2.cmml" xref="S2.SS1.SSS0.Px1.p2.2.m2.1.1.2">ğœ½</ci><ci id="S2.SS1.SSS0.Px1.p2.2.m2.1.1.3.cmml" xref="S2.SS1.SSS0.Px1.p2.2.m2.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px1.p2.2.m2.1c">\bm{\theta}_{i}</annotation></semantics></math>. During local training, after receiving <math id="S2.SS1.SSS0.Px1.p2.3.m3.1" class="ltx_Math" alttext="\bm{\theta}_{g}" display="inline"><semantics id="S2.SS1.SSS0.Px1.p2.3.m3.1a"><msub id="S2.SS1.SSS0.Px1.p2.3.m3.1.1" xref="S2.SS1.SSS0.Px1.p2.3.m3.1.1.cmml"><mi id="S2.SS1.SSS0.Px1.p2.3.m3.1.1.2" xref="S2.SS1.SSS0.Px1.p2.3.m3.1.1.2.cmml">ğœ½</mi><mi id="S2.SS1.SSS0.Px1.p2.3.m3.1.1.3" xref="S2.SS1.SSS0.Px1.p2.3.m3.1.1.3.cmml">g</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px1.p2.3.m3.1b"><apply id="S2.SS1.SSS0.Px1.p2.3.m3.1.1.cmml" xref="S2.SS1.SSS0.Px1.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px1.p2.3.m3.1.1.1.cmml" xref="S2.SS1.SSS0.Px1.p2.3.m3.1.1">subscript</csymbol><ci id="S2.SS1.SSS0.Px1.p2.3.m3.1.1.2.cmml" xref="S2.SS1.SSS0.Px1.p2.3.m3.1.1.2">ğœ½</ci><ci id="S2.SS1.SSS0.Px1.p2.3.m3.1.1.3.cmml" xref="S2.SS1.SSS0.Px1.p2.3.m3.1.1.3">ğ‘”</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px1.p2.3.m3.1c">\bm{\theta}_{g}</annotation></semantics></math>, clients first train <math id="S2.SS1.SSS0.Px1.p2.4.m4.2" class="ltx_Math" alttext="f(\bm{\theta}_{g};\cdot)" display="inline"><semantics id="S2.SS1.SSS0.Px1.p2.4.m4.2a"><mrow id="S2.SS1.SSS0.Px1.p2.4.m4.2.2" xref="S2.SS1.SSS0.Px1.p2.4.m4.2.2.cmml"><mi id="S2.SS1.SSS0.Px1.p2.4.m4.2.2.3" xref="S2.SS1.SSS0.Px1.p2.4.m4.2.2.3.cmml">f</mi><mo lspace="0em" rspace="0em" id="S2.SS1.SSS0.Px1.p2.4.m4.2.2.2" xref="S2.SS1.SSS0.Px1.p2.4.m4.2.2.2.cmml">â€‹</mo><mrow id="S2.SS1.SSS0.Px1.p2.4.m4.2.2.1.1" xref="S2.SS1.SSS0.Px1.p2.4.m4.2.2.1.2.cmml"><mo stretchy="false" id="S2.SS1.SSS0.Px1.p2.4.m4.2.2.1.1.2" xref="S2.SS1.SSS0.Px1.p2.4.m4.2.2.1.2.cmml">(</mo><msub id="S2.SS1.SSS0.Px1.p2.4.m4.2.2.1.1.1" xref="S2.SS1.SSS0.Px1.p2.4.m4.2.2.1.1.1.cmml"><mi id="S2.SS1.SSS0.Px1.p2.4.m4.2.2.1.1.1.2" xref="S2.SS1.SSS0.Px1.p2.4.m4.2.2.1.1.1.2.cmml">ğœ½</mi><mi id="S2.SS1.SSS0.Px1.p2.4.m4.2.2.1.1.1.3" xref="S2.SS1.SSS0.Px1.p2.4.m4.2.2.1.1.1.3.cmml">g</mi></msub><mo rspace="0em" id="S2.SS1.SSS0.Px1.p2.4.m4.2.2.1.1.3" xref="S2.SS1.SSS0.Px1.p2.4.m4.2.2.1.2.cmml">;</mo><mo lspace="0em" rspace="0em" id="S2.SS1.SSS0.Px1.p2.4.m4.1.1" xref="S2.SS1.SSS0.Px1.p2.4.m4.1.1.cmml">â‹…</mo><mo stretchy="false" id="S2.SS1.SSS0.Px1.p2.4.m4.2.2.1.1.4" xref="S2.SS1.SSS0.Px1.p2.4.m4.2.2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px1.p2.4.m4.2b"><apply id="S2.SS1.SSS0.Px1.p2.4.m4.2.2.cmml" xref="S2.SS1.SSS0.Px1.p2.4.m4.2.2"><times id="S2.SS1.SSS0.Px1.p2.4.m4.2.2.2.cmml" xref="S2.SS1.SSS0.Px1.p2.4.m4.2.2.2"></times><ci id="S2.SS1.SSS0.Px1.p2.4.m4.2.2.3.cmml" xref="S2.SS1.SSS0.Px1.p2.4.m4.2.2.3">ğ‘“</ci><list id="S2.SS1.SSS0.Px1.p2.4.m4.2.2.1.2.cmml" xref="S2.SS1.SSS0.Px1.p2.4.m4.2.2.1.1"><apply id="S2.SS1.SSS0.Px1.p2.4.m4.2.2.1.1.1.cmml" xref="S2.SS1.SSS0.Px1.p2.4.m4.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px1.p2.4.m4.2.2.1.1.1.1.cmml" xref="S2.SS1.SSS0.Px1.p2.4.m4.2.2.1.1.1">subscript</csymbol><ci id="S2.SS1.SSS0.Px1.p2.4.m4.2.2.1.1.1.2.cmml" xref="S2.SS1.SSS0.Px1.p2.4.m4.2.2.1.1.1.2">ğœ½</ci><ci id="S2.SS1.SSS0.Px1.p2.4.m4.2.2.1.1.1.3.cmml" xref="S2.SS1.SSS0.Px1.p2.4.m4.2.2.1.1.1.3">ğ‘”</ci></apply><ci id="S2.SS1.SSS0.Px1.p2.4.m4.1.1.cmml" xref="S2.SS1.SSS0.Px1.p2.4.m4.1.1">â‹…</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px1.p2.4.m4.2c">f(\bm{\theta}_{g};\cdot)</annotation></semantics></math> on their local datasets to update <math id="S2.SS1.SSS0.Px1.p2.5.m5.1" class="ltx_Math" alttext="\bm{\theta}_{g}" display="inline"><semantics id="S2.SS1.SSS0.Px1.p2.5.m5.1a"><msub id="S2.SS1.SSS0.Px1.p2.5.m5.1.1" xref="S2.SS1.SSS0.Px1.p2.5.m5.1.1.cmml"><mi id="S2.SS1.SSS0.Px1.p2.5.m5.1.1.2" xref="S2.SS1.SSS0.Px1.p2.5.m5.1.1.2.cmml">ğœ½</mi><mi id="S2.SS1.SSS0.Px1.p2.5.m5.1.1.3" xref="S2.SS1.SSS0.Px1.p2.5.m5.1.1.3.cmml">g</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px1.p2.5.m5.1b"><apply id="S2.SS1.SSS0.Px1.p2.5.m5.1.1.cmml" xref="S2.SS1.SSS0.Px1.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px1.p2.5.m5.1.1.1.cmml" xref="S2.SS1.SSS0.Px1.p2.5.m5.1.1">subscript</csymbol><ci id="S2.SS1.SSS0.Px1.p2.5.m5.1.1.2.cmml" xref="S2.SS1.SSS0.Px1.p2.5.m5.1.1.2">ğœ½</ci><ci id="S2.SS1.SSS0.Px1.p2.5.m5.1.1.3.cmml" xref="S2.SS1.SSS0.Px1.p2.5.m5.1.1.3">ğ‘”</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px1.p2.5.m5.1c">\bm{\theta}_{g}</annotation></semantics></math>. Then they train local model <math id="S2.SS1.SSS0.Px1.p2.6.m6.1" class="ltx_Math" alttext="\bm{\theta}_{i}" display="inline"><semantics id="S2.SS1.SSS0.Px1.p2.6.m6.1a"><msub id="S2.SS1.SSS0.Px1.p2.6.m6.1.1" xref="S2.SS1.SSS0.Px1.p2.6.m6.1.1.cmml"><mi id="S2.SS1.SSS0.Px1.p2.6.m6.1.1.2" xref="S2.SS1.SSS0.Px1.p2.6.m6.1.1.2.cmml">ğœ½</mi><mi id="S2.SS1.SSS0.Px1.p2.6.m6.1.1.3" xref="S2.SS1.SSS0.Px1.p2.6.m6.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px1.p2.6.m6.1b"><apply id="S2.SS1.SSS0.Px1.p2.6.m6.1.1.cmml" xref="S2.SS1.SSS0.Px1.p2.6.m6.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px1.p2.6.m6.1.1.1.cmml" xref="S2.SS1.SSS0.Px1.p2.6.m6.1.1">subscript</csymbol><ci id="S2.SS1.SSS0.Px1.p2.6.m6.1.1.2.cmml" xref="S2.SS1.SSS0.Px1.p2.6.m6.1.1.2">ğœ½</ci><ci id="S2.SS1.SSS0.Px1.p2.6.m6.1.1.3.cmml" xref="S2.SS1.SSS0.Px1.p2.6.m6.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px1.p2.6.m6.1c">\bm{\theta}_{i}</annotation></semantics></math> using <math id="S2.SS1.SSS0.Px1.p2.7.m7.1" class="ltx_Math" alttext="\bm{\theta}_{g}" display="inline"><semantics id="S2.SS1.SSS0.Px1.p2.7.m7.1a"><msub id="S2.SS1.SSS0.Px1.p2.7.m7.1.1" xref="S2.SS1.SSS0.Px1.p2.7.m7.1.1.cmml"><mi id="S2.SS1.SSS0.Px1.p2.7.m7.1.1.2" xref="S2.SS1.SSS0.Px1.p2.7.m7.1.1.2.cmml">ğœ½</mi><mi id="S2.SS1.SSS0.Px1.p2.7.m7.1.1.3" xref="S2.SS1.SSS0.Px1.p2.7.m7.1.1.3.cmml">g</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px1.p2.7.m7.1b"><apply id="S2.SS1.SSS0.Px1.p2.7.m7.1.1.cmml" xref="S2.SS1.SSS0.Px1.p2.7.m7.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px1.p2.7.m7.1.1.1.cmml" xref="S2.SS1.SSS0.Px1.p2.7.m7.1.1">subscript</csymbol><ci id="S2.SS1.SSS0.Px1.p2.7.m7.1.1.2.cmml" xref="S2.SS1.SSS0.Px1.p2.7.m7.1.1.2">ğœ½</ci><ci id="S2.SS1.SSS0.Px1.p2.7.m7.1.1.3.cmml" xref="S2.SS1.SSS0.Px1.p2.7.m7.1.1.3">ğ‘”</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px1.p2.7.m7.1c">\bm{\theta}_{g}</annotation></semantics></math> as the reference with a added regularizer <math id="S2.SS1.SSS0.Px1.p2.8.m8.1" class="ltx_Math" alttext="\lambda\|\bm{\theta}_{i}-\bm{\theta}_{g}\|_{2}" display="inline"><semantics id="S2.SS1.SSS0.Px1.p2.8.m8.1a"><mrow id="S2.SS1.SSS0.Px1.p2.8.m8.1.1" xref="S2.SS1.SSS0.Px1.p2.8.m8.1.1.cmml"><mi id="S2.SS1.SSS0.Px1.p2.8.m8.1.1.3" xref="S2.SS1.SSS0.Px1.p2.8.m8.1.1.3.cmml">Î»</mi><mo lspace="0em" rspace="0em" id="S2.SS1.SSS0.Px1.p2.8.m8.1.1.2" xref="S2.SS1.SSS0.Px1.p2.8.m8.1.1.2.cmml">â€‹</mo><msub id="S2.SS1.SSS0.Px1.p2.8.m8.1.1.1" xref="S2.SS1.SSS0.Px1.p2.8.m8.1.1.1.cmml"><mrow id="S2.SS1.SSS0.Px1.p2.8.m8.1.1.1.1.1" xref="S2.SS1.SSS0.Px1.p2.8.m8.1.1.1.1.2.cmml"><mo stretchy="false" id="S2.SS1.SSS0.Px1.p2.8.m8.1.1.1.1.1.2" xref="S2.SS1.SSS0.Px1.p2.8.m8.1.1.1.1.2.1.cmml">â€–</mo><mrow id="S2.SS1.SSS0.Px1.p2.8.m8.1.1.1.1.1.1" xref="S2.SS1.SSS0.Px1.p2.8.m8.1.1.1.1.1.1.cmml"><msub id="S2.SS1.SSS0.Px1.p2.8.m8.1.1.1.1.1.1.2" xref="S2.SS1.SSS0.Px1.p2.8.m8.1.1.1.1.1.1.2.cmml"><mi id="S2.SS1.SSS0.Px1.p2.8.m8.1.1.1.1.1.1.2.2" xref="S2.SS1.SSS0.Px1.p2.8.m8.1.1.1.1.1.1.2.2.cmml">ğœ½</mi><mi id="S2.SS1.SSS0.Px1.p2.8.m8.1.1.1.1.1.1.2.3" xref="S2.SS1.SSS0.Px1.p2.8.m8.1.1.1.1.1.1.2.3.cmml">i</mi></msub><mo id="S2.SS1.SSS0.Px1.p2.8.m8.1.1.1.1.1.1.1" xref="S2.SS1.SSS0.Px1.p2.8.m8.1.1.1.1.1.1.1.cmml">âˆ’</mo><msub id="S2.SS1.SSS0.Px1.p2.8.m8.1.1.1.1.1.1.3" xref="S2.SS1.SSS0.Px1.p2.8.m8.1.1.1.1.1.1.3.cmml"><mi id="S2.SS1.SSS0.Px1.p2.8.m8.1.1.1.1.1.1.3.2" xref="S2.SS1.SSS0.Px1.p2.8.m8.1.1.1.1.1.1.3.2.cmml">ğœ½</mi><mi id="S2.SS1.SSS0.Px1.p2.8.m8.1.1.1.1.1.1.3.3" xref="S2.SS1.SSS0.Px1.p2.8.m8.1.1.1.1.1.1.3.3.cmml">g</mi></msub></mrow><mo stretchy="false" id="S2.SS1.SSS0.Px1.p2.8.m8.1.1.1.1.1.3" xref="S2.SS1.SSS0.Px1.p2.8.m8.1.1.1.1.2.1.cmml">â€–</mo></mrow><mn id="S2.SS1.SSS0.Px1.p2.8.m8.1.1.1.3" xref="S2.SS1.SSS0.Px1.p2.8.m8.1.1.1.3.cmml">2</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px1.p2.8.m8.1b"><apply id="S2.SS1.SSS0.Px1.p2.8.m8.1.1.cmml" xref="S2.SS1.SSS0.Px1.p2.8.m8.1.1"><times id="S2.SS1.SSS0.Px1.p2.8.m8.1.1.2.cmml" xref="S2.SS1.SSS0.Px1.p2.8.m8.1.1.2"></times><ci id="S2.SS1.SSS0.Px1.p2.8.m8.1.1.3.cmml" xref="S2.SS1.SSS0.Px1.p2.8.m8.1.1.3">ğœ†</ci><apply id="S2.SS1.SSS0.Px1.p2.8.m8.1.1.1.cmml" xref="S2.SS1.SSS0.Px1.p2.8.m8.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px1.p2.8.m8.1.1.1.2.cmml" xref="S2.SS1.SSS0.Px1.p2.8.m8.1.1.1">subscript</csymbol><apply id="S2.SS1.SSS0.Px1.p2.8.m8.1.1.1.1.2.cmml" xref="S2.SS1.SSS0.Px1.p2.8.m8.1.1.1.1.1"><csymbol cd="latexml" id="S2.SS1.SSS0.Px1.p2.8.m8.1.1.1.1.2.1.cmml" xref="S2.SS1.SSS0.Px1.p2.8.m8.1.1.1.1.1.2">norm</csymbol><apply id="S2.SS1.SSS0.Px1.p2.8.m8.1.1.1.1.1.1.cmml" xref="S2.SS1.SSS0.Px1.p2.8.m8.1.1.1.1.1.1"><minus id="S2.SS1.SSS0.Px1.p2.8.m8.1.1.1.1.1.1.1.cmml" xref="S2.SS1.SSS0.Px1.p2.8.m8.1.1.1.1.1.1.1"></minus><apply id="S2.SS1.SSS0.Px1.p2.8.m8.1.1.1.1.1.1.2.cmml" xref="S2.SS1.SSS0.Px1.p2.8.m8.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px1.p2.8.m8.1.1.1.1.1.1.2.1.cmml" xref="S2.SS1.SSS0.Px1.p2.8.m8.1.1.1.1.1.1.2">subscript</csymbol><ci id="S2.SS1.SSS0.Px1.p2.8.m8.1.1.1.1.1.1.2.2.cmml" xref="S2.SS1.SSS0.Px1.p2.8.m8.1.1.1.1.1.1.2.2">ğœ½</ci><ci id="S2.SS1.SSS0.Px1.p2.8.m8.1.1.1.1.1.1.2.3.cmml" xref="S2.SS1.SSS0.Px1.p2.8.m8.1.1.1.1.1.1.2.3">ğ‘–</ci></apply><apply id="S2.SS1.SSS0.Px1.p2.8.m8.1.1.1.1.1.1.3.cmml" xref="S2.SS1.SSS0.Px1.p2.8.m8.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px1.p2.8.m8.1.1.1.1.1.1.3.1.cmml" xref="S2.SS1.SSS0.Px1.p2.8.m8.1.1.1.1.1.1.3">subscript</csymbol><ci id="S2.SS1.SSS0.Px1.p2.8.m8.1.1.1.1.1.1.3.2.cmml" xref="S2.SS1.SSS0.Px1.p2.8.m8.1.1.1.1.1.1.3.2">ğœ½</ci><ci id="S2.SS1.SSS0.Px1.p2.8.m8.1.1.1.1.1.1.3.3.cmml" xref="S2.SS1.SSS0.Px1.p2.8.m8.1.1.1.1.1.1.3.3">ğ‘”</ci></apply></apply></apply><cn type="integer" id="S2.SS1.SSS0.Px1.p2.8.m8.1.1.1.3.cmml" xref="S2.SS1.SSS0.Px1.p2.8.m8.1.1.1.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px1.p2.8.m8.1c">\lambda\|\bm{\theta}_{i}-\bm{\theta}_{g}\|_{2}</annotation></semantics></math>. Here, <math id="S2.SS1.SSS0.Px1.p2.9.m9.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S2.SS1.SSS0.Px1.p2.9.m9.1a"><mi id="S2.SS1.SSS0.Px1.p2.9.m9.1.1" xref="S2.SS1.SSS0.Px1.p2.9.m9.1.1.cmml">Î»</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px1.p2.9.m9.1b"><ci id="S2.SS1.SSS0.Px1.p2.9.m9.1.1.cmml" xref="S2.SS1.SSS0.Px1.p2.9.m9.1.1">ğœ†</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px1.p2.9.m9.1c">\lambda</annotation></semantics></math> controls the consistence between <math id="S2.SS1.SSS0.Px1.p2.10.m10.1" class="ltx_Math" alttext="\bm{\theta}_{g}" display="inline"><semantics id="S2.SS1.SSS0.Px1.p2.10.m10.1a"><msub id="S2.SS1.SSS0.Px1.p2.10.m10.1.1" xref="S2.SS1.SSS0.Px1.p2.10.m10.1.1.cmml"><mi id="S2.SS1.SSS0.Px1.p2.10.m10.1.1.2" xref="S2.SS1.SSS0.Px1.p2.10.m10.1.1.2.cmml">ğœ½</mi><mi id="S2.SS1.SSS0.Px1.p2.10.m10.1.1.3" xref="S2.SS1.SSS0.Px1.p2.10.m10.1.1.3.cmml">g</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px1.p2.10.m10.1b"><apply id="S2.SS1.SSS0.Px1.p2.10.m10.1.1.cmml" xref="S2.SS1.SSS0.Px1.p2.10.m10.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px1.p2.10.m10.1.1.1.cmml" xref="S2.SS1.SSS0.Px1.p2.10.m10.1.1">subscript</csymbol><ci id="S2.SS1.SSS0.Px1.p2.10.m10.1.1.2.cmml" xref="S2.SS1.SSS0.Px1.p2.10.m10.1.1.2">ğœ½</ci><ci id="S2.SS1.SSS0.Px1.p2.10.m10.1.1.3.cmml" xref="S2.SS1.SSS0.Px1.p2.10.m10.1.1.3">ğ‘”</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px1.p2.10.m10.1c">\bm{\theta}_{g}</annotation></semantics></math> and <math id="S2.SS1.SSS0.Px1.p2.11.m11.1" class="ltx_Math" alttext="\bm{\theta}_{i}" display="inline"><semantics id="S2.SS1.SSS0.Px1.p2.11.m11.1a"><msub id="S2.SS1.SSS0.Px1.p2.11.m11.1.1" xref="S2.SS1.SSS0.Px1.p2.11.m11.1.1.cmml"><mi id="S2.SS1.SSS0.Px1.p2.11.m11.1.1.2" xref="S2.SS1.SSS0.Px1.p2.11.m11.1.1.2.cmml">ğœ½</mi><mi id="S2.SS1.SSS0.Px1.p2.11.m11.1.1.3" xref="S2.SS1.SSS0.Px1.p2.11.m11.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px1.p2.11.m11.1b"><apply id="S2.SS1.SSS0.Px1.p2.11.m11.1.1.cmml" xref="S2.SS1.SSS0.Px1.p2.11.m11.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px1.p2.11.m11.1.1.1.cmml" xref="S2.SS1.SSS0.Px1.p2.11.m11.1.1">subscript</csymbol><ci id="S2.SS1.SSS0.Px1.p2.11.m11.1.1.2.cmml" xref="S2.SS1.SSS0.Px1.p2.11.m11.1.1.2">ğœ½</ci><ci id="S2.SS1.SSS0.Px1.p2.11.m11.1.1.3.cmml" xref="S2.SS1.SSS0.Px1.p2.11.m11.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px1.p2.11.m11.1c">\bm{\theta}_{i}</annotation></semantics></math>, the personalization degree of each client. <span id="S2.SS1.SSS0.Px1.p2.20.3" class="ltx_text ltx_font_bold">(2)</span> <span id="S2.SS1.SSS0.Px1.p2.20.4" class="ltx_text ltx_font_italic">pFedMe</span>Â <cite class="ltx_cite ltx_citemacro_citep">(TÂ Dinh etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib50" title="" class="ltx_ref">2020</a>)</cite>: By first setting <math id="S2.SS1.SSS0.Px1.p2.12.m12.1" class="ltx_Math" alttext="\bm{\theta}_{g}" display="inline"><semantics id="S2.SS1.SSS0.Px1.p2.12.m12.1a"><msub id="S2.SS1.SSS0.Px1.p2.12.m12.1.1" xref="S2.SS1.SSS0.Px1.p2.12.m12.1.1.cmml"><mi id="S2.SS1.SSS0.Px1.p2.12.m12.1.1.2" xref="S2.SS1.SSS0.Px1.p2.12.m12.1.1.2.cmml">ğœ½</mi><mi id="S2.SS1.SSS0.Px1.p2.12.m12.1.1.3" xref="S2.SS1.SSS0.Px1.p2.12.m12.1.1.3.cmml">g</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px1.p2.12.m12.1b"><apply id="S2.SS1.SSS0.Px1.p2.12.m12.1.1.cmml" xref="S2.SS1.SSS0.Px1.p2.12.m12.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px1.p2.12.m12.1.1.1.cmml" xref="S2.SS1.SSS0.Px1.p2.12.m12.1.1">subscript</csymbol><ci id="S2.SS1.SSS0.Px1.p2.12.m12.1.1.2.cmml" xref="S2.SS1.SSS0.Px1.p2.12.m12.1.1.2">ğœ½</ci><ci id="S2.SS1.SSS0.Px1.p2.12.m12.1.1.3.cmml" xref="S2.SS1.SSS0.Px1.p2.12.m12.1.1.3">ğ‘”</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px1.p2.12.m12.1c">\bm{\theta}_{g}</annotation></semantics></math> as the reference, clients utilize the Moreau envelop similar to <span id="S2.SS1.SSS0.Px1.p2.20.5" class="ltx_text ltx_font_italic">Ditto</span> regularizer to update <math id="S2.SS1.SSS0.Px1.p2.13.m13.1" class="ltx_Math" alttext="\bm{\theta}_{i}" display="inline"><semantics id="S2.SS1.SSS0.Px1.p2.13.m13.1a"><msub id="S2.SS1.SSS0.Px1.p2.13.m13.1.1" xref="S2.SS1.SSS0.Px1.p2.13.m13.1.1.cmml"><mi id="S2.SS1.SSS0.Px1.p2.13.m13.1.1.2" xref="S2.SS1.SSS0.Px1.p2.13.m13.1.1.2.cmml">ğœ½</mi><mi id="S2.SS1.SSS0.Px1.p2.13.m13.1.1.3" xref="S2.SS1.SSS0.Px1.p2.13.m13.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px1.p2.13.m13.1b"><apply id="S2.SS1.SSS0.Px1.p2.13.m13.1.1.cmml" xref="S2.SS1.SSS0.Px1.p2.13.m13.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px1.p2.13.m13.1.1.1.cmml" xref="S2.SS1.SSS0.Px1.p2.13.m13.1.1">subscript</csymbol><ci id="S2.SS1.SSS0.Px1.p2.13.m13.1.1.2.cmml" xref="S2.SS1.SSS0.Px1.p2.13.m13.1.1.2">ğœ½</ci><ci id="S2.SS1.SSS0.Px1.p2.13.m13.1.1.3.cmml" xref="S2.SS1.SSS0.Px1.p2.13.m13.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px1.p2.13.m13.1c">\bm{\theta}_{i}</annotation></semantics></math>. Then they update <math id="S2.SS1.SSS0.Px1.p2.14.m14.1" class="ltx_Math" alttext="\bm{\theta}_{g}" display="inline"><semantics id="S2.SS1.SSS0.Px1.p2.14.m14.1a"><msub id="S2.SS1.SSS0.Px1.p2.14.m14.1.1" xref="S2.SS1.SSS0.Px1.p2.14.m14.1.1.cmml"><mi id="S2.SS1.SSS0.Px1.p2.14.m14.1.1.2" xref="S2.SS1.SSS0.Px1.p2.14.m14.1.1.2.cmml">ğœ½</mi><mi id="S2.SS1.SSS0.Px1.p2.14.m14.1.1.3" xref="S2.SS1.SSS0.Px1.p2.14.m14.1.1.3.cmml">g</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px1.p2.14.m14.1b"><apply id="S2.SS1.SSS0.Px1.p2.14.m14.1.1.cmml" xref="S2.SS1.SSS0.Px1.p2.14.m14.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px1.p2.14.m14.1.1.1.cmml" xref="S2.SS1.SSS0.Px1.p2.14.m14.1.1">subscript</csymbol><ci id="S2.SS1.SSS0.Px1.p2.14.m14.1.1.2.cmml" xref="S2.SS1.SSS0.Px1.p2.14.m14.1.1.2">ğœ½</ci><ci id="S2.SS1.SSS0.Px1.p2.14.m14.1.1.3.cmml" xref="S2.SS1.SSS0.Px1.p2.14.m14.1.1.3">ğ‘”</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px1.p2.14.m14.1c">\bm{\theta}_{g}</annotation></semantics></math> by using aggregation of the updates of <math id="S2.SS1.SSS0.Px1.p2.15.m15.1" class="ltx_Math" alttext="\bm{\theta}_{i}" display="inline"><semantics id="S2.SS1.SSS0.Px1.p2.15.m15.1a"><msub id="S2.SS1.SSS0.Px1.p2.15.m15.1.1" xref="S2.SS1.SSS0.Px1.p2.15.m15.1.1.cmml"><mi id="S2.SS1.SSS0.Px1.p2.15.m15.1.1.2" xref="S2.SS1.SSS0.Px1.p2.15.m15.1.1.2.cmml">ğœ½</mi><mi id="S2.SS1.SSS0.Px1.p2.15.m15.1.1.3" xref="S2.SS1.SSS0.Px1.p2.15.m15.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px1.p2.15.m15.1b"><apply id="S2.SS1.SSS0.Px1.p2.15.m15.1.1.cmml" xref="S2.SS1.SSS0.Px1.p2.15.m15.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px1.p2.15.m15.1.1.1.cmml" xref="S2.SS1.SSS0.Px1.p2.15.m15.1.1">subscript</csymbol><ci id="S2.SS1.SSS0.Px1.p2.15.m15.1.1.2.cmml" xref="S2.SS1.SSS0.Px1.p2.15.m15.1.1.2">ğœ½</ci><ci id="S2.SS1.SSS0.Px1.p2.15.m15.1.1.3.cmml" xref="S2.SS1.SSS0.Px1.p2.15.m15.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px1.p2.15.m15.1c">\bm{\theta}_{i}</annotation></semantics></math> at the end of each local epoch. <span id="S2.SS1.SSS0.Px1.p2.20.6" class="ltx_text ltx_font_bold">(3)</span> <span id="S2.SS1.SSS0.Px1.p2.20.7" class="ltx_text ltx_font_italic">FedEM</span>Â <cite class="ltx_cite ltx_citemacro_citep">(Marfoq etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib39" title="" class="ltx_ref">2021</a>)</cite>: this method assumes the data distribution of each client is the mixture of unknown underlying data distributions with different coefficients. Therefore, they propose to learn a mixture of multiple base models (<math id="S2.SS1.SSS0.Px1.p2.16.m16.2" class="ltx_Math" alttext="a_{i}^{1}\bm{\theta}^{1}+\dots+a_{i}^{k}\bm{\theta}^{k},~{}i\in C" display="inline"><semantics id="S2.SS1.SSS0.Px1.p2.16.m16.2a"><mrow id="S2.SS1.SSS0.Px1.p2.16.m16.2.2" xref="S2.SS1.SSS0.Px1.p2.16.m16.2.2.cmml"><mrow id="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1" xref="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.2.cmml"><mrow id="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1" xref="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.cmml"><mrow id="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.2" xref="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.2.cmml"><msubsup id="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.2.2" xref="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.2.2.cmml"><mi id="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.2.2.2.2" xref="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.2.2.2.2.cmml">a</mi><mi id="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.2.2.2.3" xref="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.2.2.2.3.cmml">i</mi><mn id="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.2.2.3" xref="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.2.2.3.cmml">1</mn></msubsup><mo lspace="0em" rspace="0em" id="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.2.1" xref="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.2.1.cmml">â€‹</mo><msup id="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.2.3" xref="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.2.3.cmml"><mi id="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.2.3.2" xref="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.2.3.2.cmml">ğœ½</mi><mn id="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.2.3.3" xref="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.2.3.3.cmml">1</mn></msup></mrow><mo id="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.1" xref="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.1.cmml">+</mo><mi mathvariant="normal" id="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.3" xref="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.3.cmml">â‹¯</mi><mo id="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.1a" xref="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.1.cmml">+</mo><mrow id="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.4" xref="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.4.cmml"><msubsup id="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.4.2" xref="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.4.2.cmml"><mi id="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.4.2.2.2" xref="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.4.2.2.2.cmml">a</mi><mi id="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.4.2.2.3" xref="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.4.2.2.3.cmml">i</mi><mi id="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.4.2.3" xref="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.4.2.3.cmml">k</mi></msubsup><mo lspace="0em" rspace="0em" id="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.4.1" xref="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.4.1.cmml">â€‹</mo><msup id="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.4.3" xref="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.4.3.cmml"><mi id="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.4.3.2" xref="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.4.3.2.cmml">ğœ½</mi><mi id="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.4.3.3" xref="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.4.3.3.cmml">k</mi></msup></mrow></mrow><mo rspace="0.497em" id="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.2" xref="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.2.cmml">,</mo><mi id="S2.SS1.SSS0.Px1.p2.16.m16.1.1" xref="S2.SS1.SSS0.Px1.p2.16.m16.1.1.cmml">i</mi></mrow><mo id="S2.SS1.SSS0.Px1.p2.16.m16.2.2.2" xref="S2.SS1.SSS0.Px1.p2.16.m16.2.2.2.cmml">âˆˆ</mo><mi id="S2.SS1.SSS0.Px1.p2.16.m16.2.2.3" xref="S2.SS1.SSS0.Px1.p2.16.m16.2.2.3.cmml">C</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px1.p2.16.m16.2b"><apply id="S2.SS1.SSS0.Px1.p2.16.m16.2.2.cmml" xref="S2.SS1.SSS0.Px1.p2.16.m16.2.2"><in id="S2.SS1.SSS0.Px1.p2.16.m16.2.2.2.cmml" xref="S2.SS1.SSS0.Px1.p2.16.m16.2.2.2"></in><list id="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.2.cmml" xref="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1"><apply id="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.cmml" xref="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1"><plus id="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.1.cmml" xref="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.1"></plus><apply id="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.2.cmml" xref="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.2"><times id="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.2.1.cmml" xref="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.2.1"></times><apply id="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.2.2.cmml" xref="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.2.2"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.2.2.1.cmml" xref="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.2.2">superscript</csymbol><apply id="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.2.2.2.cmml" xref="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.2.2"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.2.2.2.1.cmml" xref="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.2.2">subscript</csymbol><ci id="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.2.2.2.2.cmml" xref="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.2.2.2.2">ğ‘</ci><ci id="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.2.2.2.3.cmml" xref="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.2.2.2.3">ğ‘–</ci></apply><cn type="integer" id="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.2.2.3.cmml" xref="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.2.2.3">1</cn></apply><apply id="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.2.3.cmml" xref="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.2.3"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.2.3.1.cmml" xref="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.2.3">superscript</csymbol><ci id="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.2.3.2.cmml" xref="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.2.3.2">ğœ½</ci><cn type="integer" id="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.2.3.3.cmml" xref="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.2.3.3">1</cn></apply></apply><ci id="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.3.cmml" xref="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.3">â‹¯</ci><apply id="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.4.cmml" xref="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.4"><times id="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.4.1.cmml" xref="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.4.1"></times><apply id="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.4.2.cmml" xref="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.4.2"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.4.2.1.cmml" xref="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.4.2">superscript</csymbol><apply id="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.4.2.2.cmml" xref="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.4.2"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.4.2.2.1.cmml" xref="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.4.2">subscript</csymbol><ci id="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.4.2.2.2.cmml" xref="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.4.2.2.2">ğ‘</ci><ci id="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.4.2.2.3.cmml" xref="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.4.2.2.3">ğ‘–</ci></apply><ci id="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.4.2.3.cmml" xref="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.4.2.3">ğ‘˜</ci></apply><apply id="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.4.3.cmml" xref="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.4.3"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.4.3.1.cmml" xref="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.4.3">superscript</csymbol><ci id="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.4.3.2.cmml" xref="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.4.3.2">ğœ½</ci><ci id="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.4.3.3.cmml" xref="S2.SS1.SSS0.Px1.p2.16.m16.2.2.1.1.1.4.3.3">ğ‘˜</ci></apply></apply></apply><ci id="S2.SS1.SSS0.Px1.p2.16.m16.1.1.cmml" xref="S2.SS1.SSS0.Px1.p2.16.m16.1.1">ğ‘–</ci></list><ci id="S2.SS1.SSS0.Px1.p2.16.m16.2.2.3.cmml" xref="S2.SS1.SSS0.Px1.p2.16.m16.2.2.3">ğ¶</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px1.p2.16.m16.2c">a_{i}^{1}\bm{\theta}^{1}+\dots+a_{i}^{k}\bm{\theta}^{k},~{}i\in C</annotation></semantics></math>) for each client with different mixture coefficients. All clients share these based models <math id="S2.SS1.SSS0.Px1.p2.17.m17.3" class="ltx_Math" alttext="\bm{\theta}^{1},\dots,\bm{\theta}^{k}" display="inline"><semantics id="S2.SS1.SSS0.Px1.p2.17.m17.3a"><mrow id="S2.SS1.SSS0.Px1.p2.17.m17.3.3.2" xref="S2.SS1.SSS0.Px1.p2.17.m17.3.3.3.cmml"><msup id="S2.SS1.SSS0.Px1.p2.17.m17.2.2.1.1" xref="S2.SS1.SSS0.Px1.p2.17.m17.2.2.1.1.cmml"><mi id="S2.SS1.SSS0.Px1.p2.17.m17.2.2.1.1.2" xref="S2.SS1.SSS0.Px1.p2.17.m17.2.2.1.1.2.cmml">ğœ½</mi><mn id="S2.SS1.SSS0.Px1.p2.17.m17.2.2.1.1.3" xref="S2.SS1.SSS0.Px1.p2.17.m17.2.2.1.1.3.cmml">1</mn></msup><mo id="S2.SS1.SSS0.Px1.p2.17.m17.3.3.2.3" xref="S2.SS1.SSS0.Px1.p2.17.m17.3.3.3.cmml">,</mo><mi mathvariant="normal" id="S2.SS1.SSS0.Px1.p2.17.m17.1.1" xref="S2.SS1.SSS0.Px1.p2.17.m17.1.1.cmml">â€¦</mi><mo id="S2.SS1.SSS0.Px1.p2.17.m17.3.3.2.4" xref="S2.SS1.SSS0.Px1.p2.17.m17.3.3.3.cmml">,</mo><msup id="S2.SS1.SSS0.Px1.p2.17.m17.3.3.2.2" xref="S2.SS1.SSS0.Px1.p2.17.m17.3.3.2.2.cmml"><mi id="S2.SS1.SSS0.Px1.p2.17.m17.3.3.2.2.2" xref="S2.SS1.SSS0.Px1.p2.17.m17.3.3.2.2.2.cmml">ğœ½</mi><mi id="S2.SS1.SSS0.Px1.p2.17.m17.3.3.2.2.3" xref="S2.SS1.SSS0.Px1.p2.17.m17.3.3.2.2.3.cmml">k</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px1.p2.17.m17.3b"><list id="S2.SS1.SSS0.Px1.p2.17.m17.3.3.3.cmml" xref="S2.SS1.SSS0.Px1.p2.17.m17.3.3.2"><apply id="S2.SS1.SSS0.Px1.p2.17.m17.2.2.1.1.cmml" xref="S2.SS1.SSS0.Px1.p2.17.m17.2.2.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px1.p2.17.m17.2.2.1.1.1.cmml" xref="S2.SS1.SSS0.Px1.p2.17.m17.2.2.1.1">superscript</csymbol><ci id="S2.SS1.SSS0.Px1.p2.17.m17.2.2.1.1.2.cmml" xref="S2.SS1.SSS0.Px1.p2.17.m17.2.2.1.1.2">ğœ½</ci><cn type="integer" id="S2.SS1.SSS0.Px1.p2.17.m17.2.2.1.1.3.cmml" xref="S2.SS1.SSS0.Px1.p2.17.m17.2.2.1.1.3">1</cn></apply><ci id="S2.SS1.SSS0.Px1.p2.17.m17.1.1.cmml" xref="S2.SS1.SSS0.Px1.p2.17.m17.1.1">â€¦</ci><apply id="S2.SS1.SSS0.Px1.p2.17.m17.3.3.2.2.cmml" xref="S2.SS1.SSS0.Px1.p2.17.m17.3.3.2.2"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px1.p2.17.m17.3.3.2.2.1.cmml" xref="S2.SS1.SSS0.Px1.p2.17.m17.3.3.2.2">superscript</csymbol><ci id="S2.SS1.SSS0.Px1.p2.17.m17.3.3.2.2.2.cmml" xref="S2.SS1.SSS0.Px1.p2.17.m17.3.3.2.2.2">ğœ½</ci><ci id="S2.SS1.SSS0.Px1.p2.17.m17.3.3.2.2.3.cmml" xref="S2.SS1.SSS0.Px1.p2.17.m17.3.3.2.2.3">ğ‘˜</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px1.p2.17.m17.3c">\bm{\theta}^{1},\dots,\bm{\theta}^{k}</annotation></semantics></math> but they have their own personalized mixture coefficients, <math id="S2.SS1.SSS0.Px1.p2.18.m18.3" class="ltx_Math" alttext="a_{i}^{1},\dots,a_{i}^{k}" display="inline"><semantics id="S2.SS1.SSS0.Px1.p2.18.m18.3a"><mrow id="S2.SS1.SSS0.Px1.p2.18.m18.3.3.2" xref="S2.SS1.SSS0.Px1.p2.18.m18.3.3.3.cmml"><msubsup id="S2.SS1.SSS0.Px1.p2.18.m18.2.2.1.1" xref="S2.SS1.SSS0.Px1.p2.18.m18.2.2.1.1.cmml"><mi id="S2.SS1.SSS0.Px1.p2.18.m18.2.2.1.1.2.2" xref="S2.SS1.SSS0.Px1.p2.18.m18.2.2.1.1.2.2.cmml">a</mi><mi id="S2.SS1.SSS0.Px1.p2.18.m18.2.2.1.1.2.3" xref="S2.SS1.SSS0.Px1.p2.18.m18.2.2.1.1.2.3.cmml">i</mi><mn id="S2.SS1.SSS0.Px1.p2.18.m18.2.2.1.1.3" xref="S2.SS1.SSS0.Px1.p2.18.m18.2.2.1.1.3.cmml">1</mn></msubsup><mo id="S2.SS1.SSS0.Px1.p2.18.m18.3.3.2.3" xref="S2.SS1.SSS0.Px1.p2.18.m18.3.3.3.cmml">,</mo><mi mathvariant="normal" id="S2.SS1.SSS0.Px1.p2.18.m18.1.1" xref="S2.SS1.SSS0.Px1.p2.18.m18.1.1.cmml">â€¦</mi><mo id="S2.SS1.SSS0.Px1.p2.18.m18.3.3.2.4" xref="S2.SS1.SSS0.Px1.p2.18.m18.3.3.3.cmml">,</mo><msubsup id="S2.SS1.SSS0.Px1.p2.18.m18.3.3.2.2" xref="S2.SS1.SSS0.Px1.p2.18.m18.3.3.2.2.cmml"><mi id="S2.SS1.SSS0.Px1.p2.18.m18.3.3.2.2.2.2" xref="S2.SS1.SSS0.Px1.p2.18.m18.3.3.2.2.2.2.cmml">a</mi><mi id="S2.SS1.SSS0.Px1.p2.18.m18.3.3.2.2.2.3" xref="S2.SS1.SSS0.Px1.p2.18.m18.3.3.2.2.2.3.cmml">i</mi><mi id="S2.SS1.SSS0.Px1.p2.18.m18.3.3.2.2.3" xref="S2.SS1.SSS0.Px1.p2.18.m18.3.3.2.2.3.cmml">k</mi></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px1.p2.18.m18.3b"><list id="S2.SS1.SSS0.Px1.p2.18.m18.3.3.3.cmml" xref="S2.SS1.SSS0.Px1.p2.18.m18.3.3.2"><apply id="S2.SS1.SSS0.Px1.p2.18.m18.2.2.1.1.cmml" xref="S2.SS1.SSS0.Px1.p2.18.m18.2.2.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px1.p2.18.m18.2.2.1.1.1.cmml" xref="S2.SS1.SSS0.Px1.p2.18.m18.2.2.1.1">superscript</csymbol><apply id="S2.SS1.SSS0.Px1.p2.18.m18.2.2.1.1.2.cmml" xref="S2.SS1.SSS0.Px1.p2.18.m18.2.2.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px1.p2.18.m18.2.2.1.1.2.1.cmml" xref="S2.SS1.SSS0.Px1.p2.18.m18.2.2.1.1">subscript</csymbol><ci id="S2.SS1.SSS0.Px1.p2.18.m18.2.2.1.1.2.2.cmml" xref="S2.SS1.SSS0.Px1.p2.18.m18.2.2.1.1.2.2">ğ‘</ci><ci id="S2.SS1.SSS0.Px1.p2.18.m18.2.2.1.1.2.3.cmml" xref="S2.SS1.SSS0.Px1.p2.18.m18.2.2.1.1.2.3">ğ‘–</ci></apply><cn type="integer" id="S2.SS1.SSS0.Px1.p2.18.m18.2.2.1.1.3.cmml" xref="S2.SS1.SSS0.Px1.p2.18.m18.2.2.1.1.3">1</cn></apply><ci id="S2.SS1.SSS0.Px1.p2.18.m18.1.1.cmml" xref="S2.SS1.SSS0.Px1.p2.18.m18.1.1">â€¦</ci><apply id="S2.SS1.SSS0.Px1.p2.18.m18.3.3.2.2.cmml" xref="S2.SS1.SSS0.Px1.p2.18.m18.3.3.2.2"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px1.p2.18.m18.3.3.2.2.1.cmml" xref="S2.SS1.SSS0.Px1.p2.18.m18.3.3.2.2">superscript</csymbol><apply id="S2.SS1.SSS0.Px1.p2.18.m18.3.3.2.2.2.cmml" xref="S2.SS1.SSS0.Px1.p2.18.m18.3.3.2.2"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px1.p2.18.m18.3.3.2.2.2.1.cmml" xref="S2.SS1.SSS0.Px1.p2.18.m18.3.3.2.2">subscript</csymbol><ci id="S2.SS1.SSS0.Px1.p2.18.m18.3.3.2.2.2.2.cmml" xref="S2.SS1.SSS0.Px1.p2.18.m18.3.3.2.2.2.2">ğ‘</ci><ci id="S2.SS1.SSS0.Px1.p2.18.m18.3.3.2.2.2.3.cmml" xref="S2.SS1.SSS0.Px1.p2.18.m18.3.3.2.2.2.3">ğ‘–</ci></apply><ci id="S2.SS1.SSS0.Px1.p2.18.m18.3.3.2.2.3.cmml" xref="S2.SS1.SSS0.Px1.p2.18.m18.3.3.2.2.3">ğ‘˜</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px1.p2.18.m18.3c">a_{i}^{1},\dots,a_{i}^{k}</annotation></semantics></math>. <span id="S2.SS1.SSS0.Px1.p2.20.8" class="ltx_text ltx_font_bold">(4)</span> <span id="S2.SS1.SSS0.Px1.p2.20.9" class="ltx_text ltx_font_italic">Fine-tuning</span>: It is a widely used method to obtain a personalized model for each client and sometimes shows a better performance than other pFL methodsÂ <cite class="ltx_cite ltx_citemacro_citep">(Chen etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2022</a>; Matsuda etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib40" title="" class="ltx_ref">2022</a>)</cite>, in which each client obtains <math id="S2.SS1.SSS0.Px1.p2.19.m19.1" class="ltx_Math" alttext="\bm{\theta}_{i}" display="inline"><semantics id="S2.SS1.SSS0.Px1.p2.19.m19.1a"><msub id="S2.SS1.SSS0.Px1.p2.19.m19.1.1" xref="S2.SS1.SSS0.Px1.p2.19.m19.1.1.cmml"><mi id="S2.SS1.SSS0.Px1.p2.19.m19.1.1.2" xref="S2.SS1.SSS0.Px1.p2.19.m19.1.1.2.cmml">ğœ½</mi><mi id="S2.SS1.SSS0.Px1.p2.19.m19.1.1.3" xref="S2.SS1.SSS0.Px1.p2.19.m19.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px1.p2.19.m19.1b"><apply id="S2.SS1.SSS0.Px1.p2.19.m19.1.1.cmml" xref="S2.SS1.SSS0.Px1.p2.19.m19.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px1.p2.19.m19.1.1.1.cmml" xref="S2.SS1.SSS0.Px1.p2.19.m19.1.1">subscript</csymbol><ci id="S2.SS1.SSS0.Px1.p2.19.m19.1.1.2.cmml" xref="S2.SS1.SSS0.Px1.p2.19.m19.1.1.2">ğœ½</ci><ci id="S2.SS1.SSS0.Px1.p2.19.m19.1.1.3.cmml" xref="S2.SS1.SSS0.Px1.p2.19.m19.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px1.p2.19.m19.1c">\bm{\theta}_{i}</annotation></semantics></math> by Fine-tuning <math id="S2.SS1.SSS0.Px1.p2.20.m20.1" class="ltx_Math" alttext="\bm{\theta}_{g}" display="inline"><semantics id="S2.SS1.SSS0.Px1.p2.20.m20.1a"><msub id="S2.SS1.SSS0.Px1.p2.20.m20.1.1" xref="S2.SS1.SSS0.Px1.p2.20.m20.1.1.cmml"><mi id="S2.SS1.SSS0.Px1.p2.20.m20.1.1.2" xref="S2.SS1.SSS0.Px1.p2.20.m20.1.1.2.cmml">ğœ½</mi><mi id="S2.SS1.SSS0.Px1.p2.20.m20.1.1.3" xref="S2.SS1.SSS0.Px1.p2.20.m20.1.1.3.cmml">g</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px1.p2.20.m20.1b"><apply id="S2.SS1.SSS0.Px1.p2.20.m20.1.1.cmml" xref="S2.SS1.SSS0.Px1.p2.20.m20.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px1.p2.20.m20.1.1.1.cmml" xref="S2.SS1.SSS0.Px1.p2.20.m20.1.1">subscript</csymbol><ci id="S2.SS1.SSS0.Px1.p2.20.m20.1.1.2.cmml" xref="S2.SS1.SSS0.Px1.p2.20.m20.1.1.2">ğœ½</ci><ci id="S2.SS1.SSS0.Px1.p2.20.m20.1.1.3.cmml" xref="S2.SS1.SSS0.Px1.p2.20.m20.1.1.3">ğ‘”</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px1.p2.20.m20.1c">\bm{\theta}_{g}</annotation></semantics></math> on their local datasets after FL training finishes.</p>
</div>
</section>
<section id="S2.SS1.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">
<span id="S2.SS1.SSS0.Px2.1.1" class="ltx_text ltx_font_bold">(ii)</span> Partial model-sharingÂ <cite class="ltx_cite ltx_citemacro_citep">(Pillutla etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib45" title="" class="ltx_ref">2022</a>; Collins etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2021</a>; Li etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib34" title="" class="ltx_ref">2021b</a>; Arivazhagan etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib3" title="" class="ltx_ref">2019</a>)</cite>:</h5>

<div id="S2.SS1.SSS0.Px2.p1" class="ltx_para">
<table id="S2.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(4)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E4.m1.9" class="ltx_Math" alttext="\min_{\bm{\theta}^{s},\left\{\bm{\theta}_{i}^{p}\right\}_{i\in C}}\mathbb{E}_{(\bm{x},\bm{y})\sim\mathcal{D}_{i},i\in\mathcal{C}}\left[\mathcal{L}(f(\bm{\theta}^{s},\bm{\theta}_{i}^{p};\bm{x}),\bm{y})\right]," display="block"><semantics id="S2.E4.m1.9a"><mrow id="S2.E4.m1.9.9.1" xref="S2.E4.m1.9.9.1.1.cmml"><mrow id="S2.E4.m1.9.9.1.1" xref="S2.E4.m1.9.9.1.1.cmml"><mrow id="S2.E4.m1.9.9.1.1.3" xref="S2.E4.m1.9.9.1.1.3.cmml"><munder id="S2.E4.m1.9.9.1.1.3.1" xref="S2.E4.m1.9.9.1.1.3.1.cmml"><mi id="S2.E4.m1.9.9.1.1.3.1.2" xref="S2.E4.m1.9.9.1.1.3.1.2.cmml">min</mi><mrow id="S2.E4.m1.2.2.2.2" xref="S2.E4.m1.2.2.2.3.cmml"><msup id="S2.E4.m1.1.1.1.1.1" xref="S2.E4.m1.1.1.1.1.1.cmml"><mi id="S2.E4.m1.1.1.1.1.1.2" xref="S2.E4.m1.1.1.1.1.1.2.cmml">ğœ½</mi><mi id="S2.E4.m1.1.1.1.1.1.3" xref="S2.E4.m1.1.1.1.1.1.3.cmml">s</mi></msup><mo id="S2.E4.m1.2.2.2.2.3" xref="S2.E4.m1.2.2.2.3.cmml">,</mo><msub id="S2.E4.m1.2.2.2.2.2" xref="S2.E4.m1.2.2.2.2.2.cmml"><mrow id="S2.E4.m1.2.2.2.2.2.1.1" xref="S2.E4.m1.2.2.2.2.2.1.2.cmml"><mo id="S2.E4.m1.2.2.2.2.2.1.1.2" xref="S2.E4.m1.2.2.2.2.2.1.2.cmml">{</mo><msubsup id="S2.E4.m1.2.2.2.2.2.1.1.1" xref="S2.E4.m1.2.2.2.2.2.1.1.1.cmml"><mi id="S2.E4.m1.2.2.2.2.2.1.1.1.2.2" xref="S2.E4.m1.2.2.2.2.2.1.1.1.2.2.cmml">ğœ½</mi><mi id="S2.E4.m1.2.2.2.2.2.1.1.1.2.3" xref="S2.E4.m1.2.2.2.2.2.1.1.1.2.3.cmml">i</mi><mi id="S2.E4.m1.2.2.2.2.2.1.1.1.3" xref="S2.E4.m1.2.2.2.2.2.1.1.1.3.cmml">p</mi></msubsup><mo id="S2.E4.m1.2.2.2.2.2.1.1.3" xref="S2.E4.m1.2.2.2.2.2.1.2.cmml">}</mo></mrow><mrow id="S2.E4.m1.2.2.2.2.2.3" xref="S2.E4.m1.2.2.2.2.2.3.cmml"><mi id="S2.E4.m1.2.2.2.2.2.3.2" xref="S2.E4.m1.2.2.2.2.2.3.2.cmml">i</mi><mo id="S2.E4.m1.2.2.2.2.2.3.1" xref="S2.E4.m1.2.2.2.2.2.3.1.cmml">âˆˆ</mo><mi id="S2.E4.m1.2.2.2.2.2.3.3" xref="S2.E4.m1.2.2.2.2.2.3.3.cmml">C</mi></mrow></msub></mrow></munder><mo lspace="0.167em" id="S2.E4.m1.9.9.1.1.3a" xref="S2.E4.m1.9.9.1.1.3.cmml">â¡</mo><msub id="S2.E4.m1.9.9.1.1.3.2" xref="S2.E4.m1.9.9.1.1.3.2.cmml"><mi id="S2.E4.m1.9.9.1.1.3.2.2" xref="S2.E4.m1.9.9.1.1.3.2.2.cmml">ğ”¼</mi><mrow id="S2.E4.m1.6.6.4.4" xref="S2.E4.m1.6.6.4.5.cmml"><mrow id="S2.E4.m1.5.5.3.3.1" xref="S2.E4.m1.5.5.3.3.1.cmml"><mrow id="S2.E4.m1.5.5.3.3.1.2.2" xref="S2.E4.m1.5.5.3.3.1.2.1.cmml"><mo stretchy="false" id="S2.E4.m1.5.5.3.3.1.2.2.1" xref="S2.E4.m1.5.5.3.3.1.2.1.cmml">(</mo><mi id="S2.E4.m1.3.3.1.1" xref="S2.E4.m1.3.3.1.1.cmml">ğ’™</mi><mo id="S2.E4.m1.5.5.3.3.1.2.2.2" xref="S2.E4.m1.5.5.3.3.1.2.1.cmml">,</mo><mi id="S2.E4.m1.4.4.2.2" xref="S2.E4.m1.4.4.2.2.cmml">ğ’š</mi><mo stretchy="false" id="S2.E4.m1.5.5.3.3.1.2.2.3" xref="S2.E4.m1.5.5.3.3.1.2.1.cmml">)</mo></mrow><mo id="S2.E4.m1.5.5.3.3.1.1" xref="S2.E4.m1.5.5.3.3.1.1.cmml">âˆ¼</mo><msub id="S2.E4.m1.5.5.3.3.1.3" xref="S2.E4.m1.5.5.3.3.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E4.m1.5.5.3.3.1.3.2" xref="S2.E4.m1.5.5.3.3.1.3.2.cmml">ğ’Ÿ</mi><mi id="S2.E4.m1.5.5.3.3.1.3.3" xref="S2.E4.m1.5.5.3.3.1.3.3.cmml">i</mi></msub></mrow><mo id="S2.E4.m1.6.6.4.4.3" xref="S2.E4.m1.6.6.4.5a.cmml">,</mo><mrow id="S2.E4.m1.6.6.4.4.2" xref="S2.E4.m1.6.6.4.4.2.cmml"><mi id="S2.E4.m1.6.6.4.4.2.2" xref="S2.E4.m1.6.6.4.4.2.2.cmml">i</mi><mo id="S2.E4.m1.6.6.4.4.2.1" xref="S2.E4.m1.6.6.4.4.2.1.cmml">âˆˆ</mo><mi class="ltx_font_mathcaligraphic" id="S2.E4.m1.6.6.4.4.2.3" xref="S2.E4.m1.6.6.4.4.2.3.cmml">ğ’</mi></mrow></mrow></msub></mrow><mo lspace="0em" rspace="0em" id="S2.E4.m1.9.9.1.1.2" xref="S2.E4.m1.9.9.1.1.2.cmml">â€‹</mo><mrow id="S2.E4.m1.9.9.1.1.1.1" xref="S2.E4.m1.9.9.1.1.1.2.cmml"><mo id="S2.E4.m1.9.9.1.1.1.1.2" xref="S2.E4.m1.9.9.1.1.1.2.1.cmml">[</mo><mrow id="S2.E4.m1.9.9.1.1.1.1.1" xref="S2.E4.m1.9.9.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E4.m1.9.9.1.1.1.1.1.3" xref="S2.E4.m1.9.9.1.1.1.1.1.3.cmml">â„’</mi><mo lspace="0em" rspace="0em" id="S2.E4.m1.9.9.1.1.1.1.1.2" xref="S2.E4.m1.9.9.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S2.E4.m1.9.9.1.1.1.1.1.1.1" xref="S2.E4.m1.9.9.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S2.E4.m1.9.9.1.1.1.1.1.1.1.2" xref="S2.E4.m1.9.9.1.1.1.1.1.1.2.cmml">(</mo><mrow id="S2.E4.m1.9.9.1.1.1.1.1.1.1.1" xref="S2.E4.m1.9.9.1.1.1.1.1.1.1.1.cmml"><mi id="S2.E4.m1.9.9.1.1.1.1.1.1.1.1.4" xref="S2.E4.m1.9.9.1.1.1.1.1.1.1.1.4.cmml">f</mi><mo lspace="0em" rspace="0em" id="S2.E4.m1.9.9.1.1.1.1.1.1.1.1.3" xref="S2.E4.m1.9.9.1.1.1.1.1.1.1.1.3.cmml">â€‹</mo><mrow id="S2.E4.m1.9.9.1.1.1.1.1.1.1.1.2.2" xref="S2.E4.m1.9.9.1.1.1.1.1.1.1.1.2.3.cmml"><mo stretchy="false" id="S2.E4.m1.9.9.1.1.1.1.1.1.1.1.2.2.3" xref="S2.E4.m1.9.9.1.1.1.1.1.1.1.1.2.3.cmml">(</mo><msup id="S2.E4.m1.9.9.1.1.1.1.1.1.1.1.1.1.1" xref="S2.E4.m1.9.9.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.E4.m1.9.9.1.1.1.1.1.1.1.1.1.1.1.2" xref="S2.E4.m1.9.9.1.1.1.1.1.1.1.1.1.1.1.2.cmml">ğœ½</mi><mi id="S2.E4.m1.9.9.1.1.1.1.1.1.1.1.1.1.1.3" xref="S2.E4.m1.9.9.1.1.1.1.1.1.1.1.1.1.1.3.cmml">s</mi></msup><mo id="S2.E4.m1.9.9.1.1.1.1.1.1.1.1.2.2.4" xref="S2.E4.m1.9.9.1.1.1.1.1.1.1.1.2.3.cmml">,</mo><msubsup id="S2.E4.m1.9.9.1.1.1.1.1.1.1.1.2.2.2" xref="S2.E4.m1.9.9.1.1.1.1.1.1.1.1.2.2.2.cmml"><mi id="S2.E4.m1.9.9.1.1.1.1.1.1.1.1.2.2.2.2.2" xref="S2.E4.m1.9.9.1.1.1.1.1.1.1.1.2.2.2.2.2.cmml">ğœ½</mi><mi id="S2.E4.m1.9.9.1.1.1.1.1.1.1.1.2.2.2.2.3" xref="S2.E4.m1.9.9.1.1.1.1.1.1.1.1.2.2.2.2.3.cmml">i</mi><mi id="S2.E4.m1.9.9.1.1.1.1.1.1.1.1.2.2.2.3" xref="S2.E4.m1.9.9.1.1.1.1.1.1.1.1.2.2.2.3.cmml">p</mi></msubsup><mo id="S2.E4.m1.9.9.1.1.1.1.1.1.1.1.2.2.5" xref="S2.E4.m1.9.9.1.1.1.1.1.1.1.1.2.3.cmml">;</mo><mi id="S2.E4.m1.7.7" xref="S2.E4.m1.7.7.cmml">ğ’™</mi><mo stretchy="false" id="S2.E4.m1.9.9.1.1.1.1.1.1.1.1.2.2.6" xref="S2.E4.m1.9.9.1.1.1.1.1.1.1.1.2.3.cmml">)</mo></mrow></mrow><mo id="S2.E4.m1.9.9.1.1.1.1.1.1.1.3" xref="S2.E4.m1.9.9.1.1.1.1.1.1.2.cmml">,</mo><mi id="S2.E4.m1.8.8" xref="S2.E4.m1.8.8.cmml">ğ’š</mi><mo stretchy="false" id="S2.E4.m1.9.9.1.1.1.1.1.1.1.4" xref="S2.E4.m1.9.9.1.1.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S2.E4.m1.9.9.1.1.1.1.3" xref="S2.E4.m1.9.9.1.1.1.2.1.cmml">]</mo></mrow></mrow><mo id="S2.E4.m1.9.9.1.2" xref="S2.E4.m1.9.9.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E4.m1.9b"><apply id="S2.E4.m1.9.9.1.1.cmml" xref="S2.E4.m1.9.9.1"><times id="S2.E4.m1.9.9.1.1.2.cmml" xref="S2.E4.m1.9.9.1.1.2"></times><apply id="S2.E4.m1.9.9.1.1.3.cmml" xref="S2.E4.m1.9.9.1.1.3"><apply id="S2.E4.m1.9.9.1.1.3.1.cmml" xref="S2.E4.m1.9.9.1.1.3.1"><csymbol cd="ambiguous" id="S2.E4.m1.9.9.1.1.3.1.1.cmml" xref="S2.E4.m1.9.9.1.1.3.1">subscript</csymbol><min id="S2.E4.m1.9.9.1.1.3.1.2.cmml" xref="S2.E4.m1.9.9.1.1.3.1.2"></min><list id="S2.E4.m1.2.2.2.3.cmml" xref="S2.E4.m1.2.2.2.2"><apply id="S2.E4.m1.1.1.1.1.1.cmml" xref="S2.E4.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E4.m1.1.1.1.1.1.1.cmml" xref="S2.E4.m1.1.1.1.1.1">superscript</csymbol><ci id="S2.E4.m1.1.1.1.1.1.2.cmml" xref="S2.E4.m1.1.1.1.1.1.2">ğœ½</ci><ci id="S2.E4.m1.1.1.1.1.1.3.cmml" xref="S2.E4.m1.1.1.1.1.1.3">ğ‘ </ci></apply><apply id="S2.E4.m1.2.2.2.2.2.cmml" xref="S2.E4.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="S2.E4.m1.2.2.2.2.2.2.cmml" xref="S2.E4.m1.2.2.2.2.2">subscript</csymbol><set id="S2.E4.m1.2.2.2.2.2.1.2.cmml" xref="S2.E4.m1.2.2.2.2.2.1.1"><apply id="S2.E4.m1.2.2.2.2.2.1.1.1.cmml" xref="S2.E4.m1.2.2.2.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.E4.m1.2.2.2.2.2.1.1.1.1.cmml" xref="S2.E4.m1.2.2.2.2.2.1.1.1">superscript</csymbol><apply id="S2.E4.m1.2.2.2.2.2.1.1.1.2.cmml" xref="S2.E4.m1.2.2.2.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.E4.m1.2.2.2.2.2.1.1.1.2.1.cmml" xref="S2.E4.m1.2.2.2.2.2.1.1.1">subscript</csymbol><ci id="S2.E4.m1.2.2.2.2.2.1.1.1.2.2.cmml" xref="S2.E4.m1.2.2.2.2.2.1.1.1.2.2">ğœ½</ci><ci id="S2.E4.m1.2.2.2.2.2.1.1.1.2.3.cmml" xref="S2.E4.m1.2.2.2.2.2.1.1.1.2.3">ğ‘–</ci></apply><ci id="S2.E4.m1.2.2.2.2.2.1.1.1.3.cmml" xref="S2.E4.m1.2.2.2.2.2.1.1.1.3">ğ‘</ci></apply></set><apply id="S2.E4.m1.2.2.2.2.2.3.cmml" xref="S2.E4.m1.2.2.2.2.2.3"><in id="S2.E4.m1.2.2.2.2.2.3.1.cmml" xref="S2.E4.m1.2.2.2.2.2.3.1"></in><ci id="S2.E4.m1.2.2.2.2.2.3.2.cmml" xref="S2.E4.m1.2.2.2.2.2.3.2">ğ‘–</ci><ci id="S2.E4.m1.2.2.2.2.2.3.3.cmml" xref="S2.E4.m1.2.2.2.2.2.3.3">ğ¶</ci></apply></apply></list></apply><apply id="S2.E4.m1.9.9.1.1.3.2.cmml" xref="S2.E4.m1.9.9.1.1.3.2"><csymbol cd="ambiguous" id="S2.E4.m1.9.9.1.1.3.2.1.cmml" xref="S2.E4.m1.9.9.1.1.3.2">subscript</csymbol><ci id="S2.E4.m1.9.9.1.1.3.2.2.cmml" xref="S2.E4.m1.9.9.1.1.3.2.2">ğ”¼</ci><apply id="S2.E4.m1.6.6.4.5.cmml" xref="S2.E4.m1.6.6.4.4"><csymbol cd="ambiguous" id="S2.E4.m1.6.6.4.5a.cmml" xref="S2.E4.m1.6.6.4.4.3">formulae-sequence</csymbol><apply id="S2.E4.m1.5.5.3.3.1.cmml" xref="S2.E4.m1.5.5.3.3.1"><csymbol cd="latexml" id="S2.E4.m1.5.5.3.3.1.1.cmml" xref="S2.E4.m1.5.5.3.3.1.1">similar-to</csymbol><interval closure="open" id="S2.E4.m1.5.5.3.3.1.2.1.cmml" xref="S2.E4.m1.5.5.3.3.1.2.2"><ci id="S2.E4.m1.3.3.1.1.cmml" xref="S2.E4.m1.3.3.1.1">ğ’™</ci><ci id="S2.E4.m1.4.4.2.2.cmml" xref="S2.E4.m1.4.4.2.2">ğ’š</ci></interval><apply id="S2.E4.m1.5.5.3.3.1.3.cmml" xref="S2.E4.m1.5.5.3.3.1.3"><csymbol cd="ambiguous" id="S2.E4.m1.5.5.3.3.1.3.1.cmml" xref="S2.E4.m1.5.5.3.3.1.3">subscript</csymbol><ci id="S2.E4.m1.5.5.3.3.1.3.2.cmml" xref="S2.E4.m1.5.5.3.3.1.3.2">ğ’Ÿ</ci><ci id="S2.E4.m1.5.5.3.3.1.3.3.cmml" xref="S2.E4.m1.5.5.3.3.1.3.3">ğ‘–</ci></apply></apply><apply id="S2.E4.m1.6.6.4.4.2.cmml" xref="S2.E4.m1.6.6.4.4.2"><in id="S2.E4.m1.6.6.4.4.2.1.cmml" xref="S2.E4.m1.6.6.4.4.2.1"></in><ci id="S2.E4.m1.6.6.4.4.2.2.cmml" xref="S2.E4.m1.6.6.4.4.2.2">ğ‘–</ci><ci id="S2.E4.m1.6.6.4.4.2.3.cmml" xref="S2.E4.m1.6.6.4.4.2.3">ğ’</ci></apply></apply></apply></apply><apply id="S2.E4.m1.9.9.1.1.1.2.cmml" xref="S2.E4.m1.9.9.1.1.1.1"><csymbol cd="latexml" id="S2.E4.m1.9.9.1.1.1.2.1.cmml" xref="S2.E4.m1.9.9.1.1.1.1.2">delimited-[]</csymbol><apply id="S2.E4.m1.9.9.1.1.1.1.1.cmml" xref="S2.E4.m1.9.9.1.1.1.1.1"><times id="S2.E4.m1.9.9.1.1.1.1.1.2.cmml" xref="S2.E4.m1.9.9.1.1.1.1.1.2"></times><ci id="S2.E4.m1.9.9.1.1.1.1.1.3.cmml" xref="S2.E4.m1.9.9.1.1.1.1.1.3">â„’</ci><interval closure="open" id="S2.E4.m1.9.9.1.1.1.1.1.1.2.cmml" xref="S2.E4.m1.9.9.1.1.1.1.1.1.1"><apply id="S2.E4.m1.9.9.1.1.1.1.1.1.1.1.cmml" xref="S2.E4.m1.9.9.1.1.1.1.1.1.1.1"><times id="S2.E4.m1.9.9.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E4.m1.9.9.1.1.1.1.1.1.1.1.3"></times><ci id="S2.E4.m1.9.9.1.1.1.1.1.1.1.1.4.cmml" xref="S2.E4.m1.9.9.1.1.1.1.1.1.1.1.4">ğ‘“</ci><vector id="S2.E4.m1.9.9.1.1.1.1.1.1.1.1.2.3.cmml" xref="S2.E4.m1.9.9.1.1.1.1.1.1.1.1.2.2"><apply id="S2.E4.m1.9.9.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E4.m1.9.9.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E4.m1.9.9.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E4.m1.9.9.1.1.1.1.1.1.1.1.1.1.1">superscript</csymbol><ci id="S2.E4.m1.9.9.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E4.m1.9.9.1.1.1.1.1.1.1.1.1.1.1.2">ğœ½</ci><ci id="S2.E4.m1.9.9.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E4.m1.9.9.1.1.1.1.1.1.1.1.1.1.1.3">ğ‘ </ci></apply><apply id="S2.E4.m1.9.9.1.1.1.1.1.1.1.1.2.2.2.cmml" xref="S2.E4.m1.9.9.1.1.1.1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S2.E4.m1.9.9.1.1.1.1.1.1.1.1.2.2.2.1.cmml" xref="S2.E4.m1.9.9.1.1.1.1.1.1.1.1.2.2.2">superscript</csymbol><apply id="S2.E4.m1.9.9.1.1.1.1.1.1.1.1.2.2.2.2.cmml" xref="S2.E4.m1.9.9.1.1.1.1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S2.E4.m1.9.9.1.1.1.1.1.1.1.1.2.2.2.2.1.cmml" xref="S2.E4.m1.9.9.1.1.1.1.1.1.1.1.2.2.2">subscript</csymbol><ci id="S2.E4.m1.9.9.1.1.1.1.1.1.1.1.2.2.2.2.2.cmml" xref="S2.E4.m1.9.9.1.1.1.1.1.1.1.1.2.2.2.2.2">ğœ½</ci><ci id="S2.E4.m1.9.9.1.1.1.1.1.1.1.1.2.2.2.2.3.cmml" xref="S2.E4.m1.9.9.1.1.1.1.1.1.1.1.2.2.2.2.3">ğ‘–</ci></apply><ci id="S2.E4.m1.9.9.1.1.1.1.1.1.1.1.2.2.2.3.cmml" xref="S2.E4.m1.9.9.1.1.1.1.1.1.1.1.2.2.2.3">ğ‘</ci></apply><ci id="S2.E4.m1.7.7.cmml" xref="S2.E4.m1.7.7">ğ’™</ci></vector></apply><ci id="S2.E4.m1.8.8.cmml" xref="S2.E4.m1.8.8">ğ’š</ci></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E4.m1.9c">\min_{\bm{\theta}^{s},\left\{\bm{\theta}_{i}^{p}\right\}_{i\in C}}\mathbb{E}_{(\bm{x},\bm{y})\sim\mathcal{D}_{i},i\in\mathcal{C}}\left[\mathcal{L}(f(\bm{\theta}^{s},\bm{\theta}_{i}^{p};\bm{x}),\bm{y})\right],</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S2.SS1.SSS0.Px2.p1.15" class="ltx_p">where the local personalized model <math id="S2.SS1.SSS0.Px2.p1.1.m1.1" class="ltx_Math" alttext="\bm{\theta}_{i}" display="inline"><semantics id="S2.SS1.SSS0.Px2.p1.1.m1.1a"><msub id="S2.SS1.SSS0.Px2.p1.1.m1.1.1" xref="S2.SS1.SSS0.Px2.p1.1.m1.1.1.cmml"><mi id="S2.SS1.SSS0.Px2.p1.1.m1.1.1.2" xref="S2.SS1.SSS0.Px2.p1.1.m1.1.1.2.cmml">ğœ½</mi><mi id="S2.SS1.SSS0.Px2.p1.1.m1.1.1.3" xref="S2.SS1.SSS0.Px2.p1.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px2.p1.1.m1.1b"><apply id="S2.SS1.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S2.SS1.SSS0.Px2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px2.p1.1.m1.1.1.1.cmml" xref="S2.SS1.SSS0.Px2.p1.1.m1.1.1">subscript</csymbol><ci id="S2.SS1.SSS0.Px2.p1.1.m1.1.1.2.cmml" xref="S2.SS1.SSS0.Px2.p1.1.m1.1.1.2">ğœ½</ci><ci id="S2.SS1.SSS0.Px2.p1.1.m1.1.1.3.cmml" xref="S2.SS1.SSS0.Px2.p1.1.m1.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px2.p1.1.m1.1c">\bm{\theta}_{i}</annotation></semantics></math> is further separated into two group parameters, <math id="S2.SS1.SSS0.Px2.p1.2.m2.1" class="ltx_Math" alttext="\bm{\theta}^{s}" display="inline"><semantics id="S2.SS1.SSS0.Px2.p1.2.m2.1a"><msup id="S2.SS1.SSS0.Px2.p1.2.m2.1.1" xref="S2.SS1.SSS0.Px2.p1.2.m2.1.1.cmml"><mi id="S2.SS1.SSS0.Px2.p1.2.m2.1.1.2" xref="S2.SS1.SSS0.Px2.p1.2.m2.1.1.2.cmml">ğœ½</mi><mi id="S2.SS1.SSS0.Px2.p1.2.m2.1.1.3" xref="S2.SS1.SSS0.Px2.p1.2.m2.1.1.3.cmml">s</mi></msup><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px2.p1.2.m2.1b"><apply id="S2.SS1.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S2.SS1.SSS0.Px2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px2.p1.2.m2.1.1.1.cmml" xref="S2.SS1.SSS0.Px2.p1.2.m2.1.1">superscript</csymbol><ci id="S2.SS1.SSS0.Px2.p1.2.m2.1.1.2.cmml" xref="S2.SS1.SSS0.Px2.p1.2.m2.1.1.2">ğœ½</ci><ci id="S2.SS1.SSS0.Px2.p1.2.m2.1.1.3.cmml" xref="S2.SS1.SSS0.Px2.p1.2.m2.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px2.p1.2.m2.1c">\bm{\theta}^{s}</annotation></semantics></math> and <math id="S2.SS1.SSS0.Px2.p1.3.m3.1" class="ltx_Math" alttext="\bm{\theta}^{p}_{i}" display="inline"><semantics id="S2.SS1.SSS0.Px2.p1.3.m3.1a"><msubsup id="S2.SS1.SSS0.Px2.p1.3.m3.1.1" xref="S2.SS1.SSS0.Px2.p1.3.m3.1.1.cmml"><mi id="S2.SS1.SSS0.Px2.p1.3.m3.1.1.2.2" xref="S2.SS1.SSS0.Px2.p1.3.m3.1.1.2.2.cmml">ğœ½</mi><mi id="S2.SS1.SSS0.Px2.p1.3.m3.1.1.3" xref="S2.SS1.SSS0.Px2.p1.3.m3.1.1.3.cmml">i</mi><mi id="S2.SS1.SSS0.Px2.p1.3.m3.1.1.2.3" xref="S2.SS1.SSS0.Px2.p1.3.m3.1.1.2.3.cmml">p</mi></msubsup><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px2.p1.3.m3.1b"><apply id="S2.SS1.SSS0.Px2.p1.3.m3.1.1.cmml" xref="S2.SS1.SSS0.Px2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px2.p1.3.m3.1.1.1.cmml" xref="S2.SS1.SSS0.Px2.p1.3.m3.1.1">subscript</csymbol><apply id="S2.SS1.SSS0.Px2.p1.3.m3.1.1.2.cmml" xref="S2.SS1.SSS0.Px2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px2.p1.3.m3.1.1.2.1.cmml" xref="S2.SS1.SSS0.Px2.p1.3.m3.1.1">superscript</csymbol><ci id="S2.SS1.SSS0.Px2.p1.3.m3.1.1.2.2.cmml" xref="S2.SS1.SSS0.Px2.p1.3.m3.1.1.2.2">ğœ½</ci><ci id="S2.SS1.SSS0.Px2.p1.3.m3.1.1.2.3.cmml" xref="S2.SS1.SSS0.Px2.p1.3.m3.1.1.2.3">ğ‘</ci></apply><ci id="S2.SS1.SSS0.Px2.p1.3.m3.1.1.3.cmml" xref="S2.SS1.SSS0.Px2.p1.3.m3.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px2.p1.3.m3.1c">\bm{\theta}^{p}_{i}</annotation></semantics></math>. There is no more global model and only partial parameters <math id="S2.SS1.SSS0.Px2.p1.4.m4.1" class="ltx_Math" alttext="\bm{\theta}^{s}" display="inline"><semantics id="S2.SS1.SSS0.Px2.p1.4.m4.1a"><msup id="S2.SS1.SSS0.Px2.p1.4.m4.1.1" xref="S2.SS1.SSS0.Px2.p1.4.m4.1.1.cmml"><mi id="S2.SS1.SSS0.Px2.p1.4.m4.1.1.2" xref="S2.SS1.SSS0.Px2.p1.4.m4.1.1.2.cmml">ğœ½</mi><mi id="S2.SS1.SSS0.Px2.p1.4.m4.1.1.3" xref="S2.SS1.SSS0.Px2.p1.4.m4.1.1.3.cmml">s</mi></msup><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px2.p1.4.m4.1b"><apply id="S2.SS1.SSS0.Px2.p1.4.m4.1.1.cmml" xref="S2.SS1.SSS0.Px2.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px2.p1.4.m4.1.1.1.cmml" xref="S2.SS1.SSS0.Px2.p1.4.m4.1.1">superscript</csymbol><ci id="S2.SS1.SSS0.Px2.p1.4.m4.1.1.2.cmml" xref="S2.SS1.SSS0.Px2.p1.4.m4.1.1.2">ğœ½</ci><ci id="S2.SS1.SSS0.Px2.p1.4.m4.1.1.3.cmml" xref="S2.SS1.SSS0.Px2.p1.4.m4.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px2.p1.4.m4.1c">\bm{\theta}^{s}</annotation></semantics></math> of <math id="S2.SS1.SSS0.Px2.p1.5.m5.1" class="ltx_Math" alttext="\bm{\theta}_{i}" display="inline"><semantics id="S2.SS1.SSS0.Px2.p1.5.m5.1a"><msub id="S2.SS1.SSS0.Px2.p1.5.m5.1.1" xref="S2.SS1.SSS0.Px2.p1.5.m5.1.1.cmml"><mi id="S2.SS1.SSS0.Px2.p1.5.m5.1.1.2" xref="S2.SS1.SSS0.Px2.p1.5.m5.1.1.2.cmml">ğœ½</mi><mi id="S2.SS1.SSS0.Px2.p1.5.m5.1.1.3" xref="S2.SS1.SSS0.Px2.p1.5.m5.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px2.p1.5.m5.1b"><apply id="S2.SS1.SSS0.Px2.p1.5.m5.1.1.cmml" xref="S2.SS1.SSS0.Px2.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px2.p1.5.m5.1.1.1.cmml" xref="S2.SS1.SSS0.Px2.p1.5.m5.1.1">subscript</csymbol><ci id="S2.SS1.SSS0.Px2.p1.5.m5.1.1.2.cmml" xref="S2.SS1.SSS0.Px2.p1.5.m5.1.1.2">ğœ½</ci><ci id="S2.SS1.SSS0.Px2.p1.5.m5.1.1.3.cmml" xref="S2.SS1.SSS0.Px2.p1.5.m5.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px2.p1.5.m5.1c">\bm{\theta}_{i}</annotation></semantics></math> are shared across clients. After finishing local training, global shared parameters <math id="S2.SS1.SSS0.Px2.p1.6.m6.1" class="ltx_Math" alttext="\bm{\theta}^{s}" display="inline"><semantics id="S2.SS1.SSS0.Px2.p1.6.m6.1a"><msup id="S2.SS1.SSS0.Px2.p1.6.m6.1.1" xref="S2.SS1.SSS0.Px2.p1.6.m6.1.1.cmml"><mi id="S2.SS1.SSS0.Px2.p1.6.m6.1.1.2" xref="S2.SS1.SSS0.Px2.p1.6.m6.1.1.2.cmml">ğœ½</mi><mi id="S2.SS1.SSS0.Px2.p1.6.m6.1.1.3" xref="S2.SS1.SSS0.Px2.p1.6.m6.1.1.3.cmml">s</mi></msup><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px2.p1.6.m6.1b"><apply id="S2.SS1.SSS0.Px2.p1.6.m6.1.1.cmml" xref="S2.SS1.SSS0.Px2.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px2.p1.6.m6.1.1.1.cmml" xref="S2.SS1.SSS0.Px2.p1.6.m6.1.1">superscript</csymbol><ci id="S2.SS1.SSS0.Px2.p1.6.m6.1.1.2.cmml" xref="S2.SS1.SSS0.Px2.p1.6.m6.1.1.2">ğœ½</ci><ci id="S2.SS1.SSS0.Px2.p1.6.m6.1.1.3.cmml" xref="S2.SS1.SSS0.Px2.p1.6.m6.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px2.p1.6.m6.1c">\bm{\theta}^{s}</annotation></semantics></math> are uploaded to the server for aggregation. Locally parameters <math id="S2.SS1.SSS0.Px2.p1.7.m7.1" class="ltx_Math" alttext="\bm{\theta}^{p}_{i}" display="inline"><semantics id="S2.SS1.SSS0.Px2.p1.7.m7.1a"><msubsup id="S2.SS1.SSS0.Px2.p1.7.m7.1.1" xref="S2.SS1.SSS0.Px2.p1.7.m7.1.1.cmml"><mi id="S2.SS1.SSS0.Px2.p1.7.m7.1.1.2.2" xref="S2.SS1.SSS0.Px2.p1.7.m7.1.1.2.2.cmml">ğœ½</mi><mi id="S2.SS1.SSS0.Px2.p1.7.m7.1.1.3" xref="S2.SS1.SSS0.Px2.p1.7.m7.1.1.3.cmml">i</mi><mi id="S2.SS1.SSS0.Px2.p1.7.m7.1.1.2.3" xref="S2.SS1.SSS0.Px2.p1.7.m7.1.1.2.3.cmml">p</mi></msubsup><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px2.p1.7.m7.1b"><apply id="S2.SS1.SSS0.Px2.p1.7.m7.1.1.cmml" xref="S2.SS1.SSS0.Px2.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px2.p1.7.m7.1.1.1.cmml" xref="S2.SS1.SSS0.Px2.p1.7.m7.1.1">subscript</csymbol><apply id="S2.SS1.SSS0.Px2.p1.7.m7.1.1.2.cmml" xref="S2.SS1.SSS0.Px2.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px2.p1.7.m7.1.1.2.1.cmml" xref="S2.SS1.SSS0.Px2.p1.7.m7.1.1">superscript</csymbol><ci id="S2.SS1.SSS0.Px2.p1.7.m7.1.1.2.2.cmml" xref="S2.SS1.SSS0.Px2.p1.7.m7.1.1.2.2">ğœ½</ci><ci id="S2.SS1.SSS0.Px2.p1.7.m7.1.1.2.3.cmml" xref="S2.SS1.SSS0.Px2.p1.7.m7.1.1.2.3">ğ‘</ci></apply><ci id="S2.SS1.SSS0.Px2.p1.7.m7.1.1.3.cmml" xref="S2.SS1.SSS0.Px2.p1.7.m7.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px2.p1.7.m7.1c">\bm{\theta}^{p}_{i}</annotation></semantics></math> are never shared with other clients. Partial model-sharing indicates each client could only utilize knowledge of partial model parameters trained on the other clientsâ€™ local datasets so that each client could gain larger personalization degrees. For example,
<span id="S2.SS1.SSS0.Px2.p1.15.1" class="ltx_text ltx_font_bold">(5)</span> <span id="S2.SS1.SSS0.Px2.p1.15.2" class="ltx_text ltx_font_italic">FedBN</span>Â <cite class="ltx_cite ltx_citemacro_citep">(Li etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib34" title="" class="ltx_ref">2021b</a>)</cite> decouples the whole model <math id="S2.SS1.SSS0.Px2.p1.8.m8.1" class="ltx_Math" alttext="\bm{\theta}_{i}" display="inline"><semantics id="S2.SS1.SSS0.Px2.p1.8.m8.1a"><msub id="S2.SS1.SSS0.Px2.p1.8.m8.1.1" xref="S2.SS1.SSS0.Px2.p1.8.m8.1.1.cmml"><mi id="S2.SS1.SSS0.Px2.p1.8.m8.1.1.2" xref="S2.SS1.SSS0.Px2.p1.8.m8.1.1.2.cmml">ğœ½</mi><mi id="S2.SS1.SSS0.Px2.p1.8.m8.1.1.3" xref="S2.SS1.SSS0.Px2.p1.8.m8.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px2.p1.8.m8.1b"><apply id="S2.SS1.SSS0.Px2.p1.8.m8.1.1.cmml" xref="S2.SS1.SSS0.Px2.p1.8.m8.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px2.p1.8.m8.1.1.1.cmml" xref="S2.SS1.SSS0.Px2.p1.8.m8.1.1">subscript</csymbol><ci id="S2.SS1.SSS0.Px2.p1.8.m8.1.1.2.cmml" xref="S2.SS1.SSS0.Px2.p1.8.m8.1.1.2">ğœ½</ci><ci id="S2.SS1.SSS0.Px2.p1.8.m8.1.1.3.cmml" xref="S2.SS1.SSS0.Px2.p1.8.m8.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px2.p1.8.m8.1c">\bm{\theta}_{i}</annotation></semantics></math> into locally preserved BN layers <math id="S2.SS1.SSS0.Px2.p1.9.m9.1" class="ltx_Math" alttext="\bm{\theta}^{p}_{i}" display="inline"><semantics id="S2.SS1.SSS0.Px2.p1.9.m9.1a"><msubsup id="S2.SS1.SSS0.Px2.p1.9.m9.1.1" xref="S2.SS1.SSS0.Px2.p1.9.m9.1.1.cmml"><mi id="S2.SS1.SSS0.Px2.p1.9.m9.1.1.2.2" xref="S2.SS1.SSS0.Px2.p1.9.m9.1.1.2.2.cmml">ğœ½</mi><mi id="S2.SS1.SSS0.Px2.p1.9.m9.1.1.3" xref="S2.SS1.SSS0.Px2.p1.9.m9.1.1.3.cmml">i</mi><mi id="S2.SS1.SSS0.Px2.p1.9.m9.1.1.2.3" xref="S2.SS1.SSS0.Px2.p1.9.m9.1.1.2.3.cmml">p</mi></msubsup><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px2.p1.9.m9.1b"><apply id="S2.SS1.SSS0.Px2.p1.9.m9.1.1.cmml" xref="S2.SS1.SSS0.Px2.p1.9.m9.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px2.p1.9.m9.1.1.1.cmml" xref="S2.SS1.SSS0.Px2.p1.9.m9.1.1">subscript</csymbol><apply id="S2.SS1.SSS0.Px2.p1.9.m9.1.1.2.cmml" xref="S2.SS1.SSS0.Px2.p1.9.m9.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px2.p1.9.m9.1.1.2.1.cmml" xref="S2.SS1.SSS0.Px2.p1.9.m9.1.1">superscript</csymbol><ci id="S2.SS1.SSS0.Px2.p1.9.m9.1.1.2.2.cmml" xref="S2.SS1.SSS0.Px2.p1.9.m9.1.1.2.2">ğœ½</ci><ci id="S2.SS1.SSS0.Px2.p1.9.m9.1.1.2.3.cmml" xref="S2.SS1.SSS0.Px2.p1.9.m9.1.1.2.3">ğ‘</ci></apply><ci id="S2.SS1.SSS0.Px2.p1.9.m9.1.1.3.cmml" xref="S2.SS1.SSS0.Px2.p1.9.m9.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px2.p1.9.m9.1c">\bm{\theta}^{p}_{i}</annotation></semantics></math> and shared parameters <math id="S2.SS1.SSS0.Px2.p1.10.m10.1" class="ltx_Math" alttext="\bm{\theta}^{s}" display="inline"><semantics id="S2.SS1.SSS0.Px2.p1.10.m10.1a"><msup id="S2.SS1.SSS0.Px2.p1.10.m10.1.1" xref="S2.SS1.SSS0.Px2.p1.10.m10.1.1.cmml"><mi id="S2.SS1.SSS0.Px2.p1.10.m10.1.1.2" xref="S2.SS1.SSS0.Px2.p1.10.m10.1.1.2.cmml">ğœ½</mi><mi id="S2.SS1.SSS0.Px2.p1.10.m10.1.1.3" xref="S2.SS1.SSS0.Px2.p1.10.m10.1.1.3.cmml">s</mi></msup><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px2.p1.10.m10.1b"><apply id="S2.SS1.SSS0.Px2.p1.10.m10.1.1.cmml" xref="S2.SS1.SSS0.Px2.p1.10.m10.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px2.p1.10.m10.1.1.1.cmml" xref="S2.SS1.SSS0.Px2.p1.10.m10.1.1">superscript</csymbol><ci id="S2.SS1.SSS0.Px2.p1.10.m10.1.1.2.cmml" xref="S2.SS1.SSS0.Px2.p1.10.m10.1.1.2">ğœ½</ci><ci id="S2.SS1.SSS0.Px2.p1.10.m10.1.1.3.cmml" xref="S2.SS1.SSS0.Px2.p1.10.m10.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px2.p1.10.m10.1c">\bm{\theta}^{s}</annotation></semantics></math>. After the local training process finishes, clients only upload <math id="S2.SS1.SSS0.Px2.p1.11.m11.1" class="ltx_Math" alttext="\bm{\theta}^{s}" display="inline"><semantics id="S2.SS1.SSS0.Px2.p1.11.m11.1a"><msup id="S2.SS1.SSS0.Px2.p1.11.m11.1.1" xref="S2.SS1.SSS0.Px2.p1.11.m11.1.1.cmml"><mi id="S2.SS1.SSS0.Px2.p1.11.m11.1.1.2" xref="S2.SS1.SSS0.Px2.p1.11.m11.1.1.2.cmml">ğœ½</mi><mi id="S2.SS1.SSS0.Px2.p1.11.m11.1.1.3" xref="S2.SS1.SSS0.Px2.p1.11.m11.1.1.3.cmml">s</mi></msup><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px2.p1.11.m11.1b"><apply id="S2.SS1.SSS0.Px2.p1.11.m11.1.1.cmml" xref="S2.SS1.SSS0.Px2.p1.11.m11.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px2.p1.11.m11.1.1.1.cmml" xref="S2.SS1.SSS0.Px2.p1.11.m11.1.1">superscript</csymbol><ci id="S2.SS1.SSS0.Px2.p1.11.m11.1.1.2.cmml" xref="S2.SS1.SSS0.Px2.p1.11.m11.1.1.2">ğœ½</ci><ci id="S2.SS1.SSS0.Px2.p1.11.m11.1.1.3.cmml" xref="S2.SS1.SSS0.Px2.p1.11.m11.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px2.p1.11.m11.1c">\bm{\theta}^{s}</annotation></semantics></math> to participate in aggregation. <span id="S2.SS1.SSS0.Px2.p1.15.3" class="ltx_text ltx_font_bold">(6)</span> <span id="S2.SS1.SSS0.Px2.p1.15.4" class="ltx_text ltx_font_italic">FedRep</span>Â <cite class="ltx_cite ltx_citemacro_citep">(Collins etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2021</a>; Pillutla etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib45" title="" class="ltx_ref">2022</a>)</cite> decouples models into global feature extractor (<math id="S2.SS1.SSS0.Px2.p1.12.m12.1" class="ltx_Math" alttext="\bm{\theta}^{s}" display="inline"><semantics id="S2.SS1.SSS0.Px2.p1.12.m12.1a"><msup id="S2.SS1.SSS0.Px2.p1.12.m12.1.1" xref="S2.SS1.SSS0.Px2.p1.12.m12.1.1.cmml"><mi id="S2.SS1.SSS0.Px2.p1.12.m12.1.1.2" xref="S2.SS1.SSS0.Px2.p1.12.m12.1.1.2.cmml">ğœ½</mi><mi id="S2.SS1.SSS0.Px2.p1.12.m12.1.1.3" xref="S2.SS1.SSS0.Px2.p1.12.m12.1.1.3.cmml">s</mi></msup><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px2.p1.12.m12.1b"><apply id="S2.SS1.SSS0.Px2.p1.12.m12.1.1.cmml" xref="S2.SS1.SSS0.Px2.p1.12.m12.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px2.p1.12.m12.1.1.1.cmml" xref="S2.SS1.SSS0.Px2.p1.12.m12.1.1">superscript</csymbol><ci id="S2.SS1.SSS0.Px2.p1.12.m12.1.1.2.cmml" xref="S2.SS1.SSS0.Px2.p1.12.m12.1.1.2">ğœ½</ci><ci id="S2.SS1.SSS0.Px2.p1.12.m12.1.1.3.cmml" xref="S2.SS1.SSS0.Px2.p1.12.m12.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px2.p1.12.m12.1c">\bm{\theta}^{s}</annotation></semantics></math>) and local linear classifier (<math id="S2.SS1.SSS0.Px2.p1.13.m13.1" class="ltx_Math" alttext="\bm{\theta}_{i}^{p}" display="inline"><semantics id="S2.SS1.SSS0.Px2.p1.13.m13.1a"><msubsup id="S2.SS1.SSS0.Px2.p1.13.m13.1.1" xref="S2.SS1.SSS0.Px2.p1.13.m13.1.1.cmml"><mi id="S2.SS1.SSS0.Px2.p1.13.m13.1.1.2.2" xref="S2.SS1.SSS0.Px2.p1.13.m13.1.1.2.2.cmml">ğœ½</mi><mi id="S2.SS1.SSS0.Px2.p1.13.m13.1.1.2.3" xref="S2.SS1.SSS0.Px2.p1.13.m13.1.1.2.3.cmml">i</mi><mi id="S2.SS1.SSS0.Px2.p1.13.m13.1.1.3" xref="S2.SS1.SSS0.Px2.p1.13.m13.1.1.3.cmml">p</mi></msubsup><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px2.p1.13.m13.1b"><apply id="S2.SS1.SSS0.Px2.p1.13.m13.1.1.cmml" xref="S2.SS1.SSS0.Px2.p1.13.m13.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px2.p1.13.m13.1.1.1.cmml" xref="S2.SS1.SSS0.Px2.p1.13.m13.1.1">superscript</csymbol><apply id="S2.SS1.SSS0.Px2.p1.13.m13.1.1.2.cmml" xref="S2.SS1.SSS0.Px2.p1.13.m13.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px2.p1.13.m13.1.1.2.1.cmml" xref="S2.SS1.SSS0.Px2.p1.13.m13.1.1">subscript</csymbol><ci id="S2.SS1.SSS0.Px2.p1.13.m13.1.1.2.2.cmml" xref="S2.SS1.SSS0.Px2.p1.13.m13.1.1.2.2">ğœ½</ci><ci id="S2.SS1.SSS0.Px2.p1.13.m13.1.1.2.3.cmml" xref="S2.SS1.SSS0.Px2.p1.13.m13.1.1.2.3">ğ‘–</ci></apply><ci id="S2.SS1.SSS0.Px2.p1.13.m13.1.1.3.cmml" xref="S2.SS1.SSS0.Px2.p1.13.m13.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px2.p1.13.m13.1c">\bm{\theta}_{i}^{p}</annotation></semantics></math>). In each iteration of local training, clients first freeze the feature extractor and update <math id="S2.SS1.SSS0.Px2.p1.14.m14.1" class="ltx_Math" alttext="\bm{\theta}_{i}^{p}" display="inline"><semantics id="S2.SS1.SSS0.Px2.p1.14.m14.1a"><msubsup id="S2.SS1.SSS0.Px2.p1.14.m14.1.1" xref="S2.SS1.SSS0.Px2.p1.14.m14.1.1.cmml"><mi id="S2.SS1.SSS0.Px2.p1.14.m14.1.1.2.2" xref="S2.SS1.SSS0.Px2.p1.14.m14.1.1.2.2.cmml">ğœ½</mi><mi id="S2.SS1.SSS0.Px2.p1.14.m14.1.1.2.3" xref="S2.SS1.SSS0.Px2.p1.14.m14.1.1.2.3.cmml">i</mi><mi id="S2.SS1.SSS0.Px2.p1.14.m14.1.1.3" xref="S2.SS1.SSS0.Px2.p1.14.m14.1.1.3.cmml">p</mi></msubsup><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px2.p1.14.m14.1b"><apply id="S2.SS1.SSS0.Px2.p1.14.m14.1.1.cmml" xref="S2.SS1.SSS0.Px2.p1.14.m14.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px2.p1.14.m14.1.1.1.cmml" xref="S2.SS1.SSS0.Px2.p1.14.m14.1.1">superscript</csymbol><apply id="S2.SS1.SSS0.Px2.p1.14.m14.1.1.2.cmml" xref="S2.SS1.SSS0.Px2.p1.14.m14.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px2.p1.14.m14.1.1.2.1.cmml" xref="S2.SS1.SSS0.Px2.p1.14.m14.1.1">subscript</csymbol><ci id="S2.SS1.SSS0.Px2.p1.14.m14.1.1.2.2.cmml" xref="S2.SS1.SSS0.Px2.p1.14.m14.1.1.2.2">ğœ½</ci><ci id="S2.SS1.SSS0.Px2.p1.14.m14.1.1.2.3.cmml" xref="S2.SS1.SSS0.Px2.p1.14.m14.1.1.2.3">ğ‘–</ci></apply><ci id="S2.SS1.SSS0.Px2.p1.14.m14.1.1.3.cmml" xref="S2.SS1.SSS0.Px2.p1.14.m14.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px2.p1.14.m14.1c">\bm{\theta}_{i}^{p}</annotation></semantics></math> on their private datasets. And then, they freeze the local linear classifier and update global feature extractor <math id="S2.SS1.SSS0.Px2.p1.15.m15.1" class="ltx_Math" alttext="\bm{\theta}^{s}" display="inline"><semantics id="S2.SS1.SSS0.Px2.p1.15.m15.1a"><msup id="S2.SS1.SSS0.Px2.p1.15.m15.1.1" xref="S2.SS1.SSS0.Px2.p1.15.m15.1.1.cmml"><mi id="S2.SS1.SSS0.Px2.p1.15.m15.1.1.2" xref="S2.SS1.SSS0.Px2.p1.15.m15.1.1.2.cmml">ğœ½</mi><mi id="S2.SS1.SSS0.Px2.p1.15.m15.1.1.3" xref="S2.SS1.SSS0.Px2.p1.15.m15.1.1.3.cmml">s</mi></msup><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px2.p1.15.m15.1b"><apply id="S2.SS1.SSS0.Px2.p1.15.m15.1.1.cmml" xref="S2.SS1.SSS0.Px2.p1.15.m15.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px2.p1.15.m15.1.1.1.cmml" xref="S2.SS1.SSS0.Px2.p1.15.m15.1.1">superscript</csymbol><ci id="S2.SS1.SSS0.Px2.p1.15.m15.1.1.2.cmml" xref="S2.SS1.SSS0.Px2.p1.15.m15.1.1.2">ğœ½</ci><ci id="S2.SS1.SSS0.Px2.p1.15.m15.1.1.3.cmml" xref="S2.SS1.SSS0.Px2.p1.15.m15.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px2.p1.15.m15.1c">\bm{\theta}^{s}</annotation></semantics></math>. Only the global feature extractor is uploaded to the server and participates in aggregation.</p>
</div>
</section>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2. </span>Backdoor Attacks in FL</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.6" class="ltx_p">Backdoor attacks aim to mislead the backdoored model to exhibit abnormal behavior on samples stamped with the backdoor trigger but behave normally on all benign samples. As shown in FigureÂ <a href="#S2.F1" title="Figure 1 â€£ 2.2. Backdoor Attacks in FL â€£ 2. Background â€£ Revisiting Personalized Federated Learning: Robustness Against Backdoor Attacks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, the backdoor attacker inserts a backdoor trigger into the model by manipulating some training data samples, like adding a small patch in clean images or just choosing special samples as triggers. Backdoored samplesâ€™ labels would also be changed to attacker designated target label <math id="S2.SS2.p1.1.m1.1" class="ltx_Math" alttext="\bm{y}_{t}" display="inline"><semantics id="S2.SS2.p1.1.m1.1a"><msub id="S2.SS2.p1.1.m1.1.1" xref="S2.SS2.p1.1.m1.1.1.cmml"><mi id="S2.SS2.p1.1.m1.1.1.2" xref="S2.SS2.p1.1.m1.1.1.2.cmml">ğ’š</mi><mi id="S2.SS2.p1.1.m1.1.1.3" xref="S2.SS2.p1.1.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.1.m1.1b"><apply id="S2.SS2.p1.1.m1.1.1.cmml" xref="S2.SS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.1.m1.1.1.1.cmml" xref="S2.SS2.p1.1.m1.1.1">subscript</csymbol><ci id="S2.SS2.p1.1.m1.1.1.2.cmml" xref="S2.SS2.p1.1.m1.1.1.2">ğ’š</ci><ci id="S2.SS2.p1.1.m1.1.1.3.cmml" xref="S2.SS2.p1.1.m1.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.1.m1.1c">\bm{y}_{t}</annotation></semantics></math>. In the training phase, the model <math id="S2.SS2.p1.2.m2.2" class="ltx_Math" alttext="f(\bm{\theta}^{\prime};\cdot)" display="inline"><semantics id="S2.SS2.p1.2.m2.2a"><mrow id="S2.SS2.p1.2.m2.2.2" xref="S2.SS2.p1.2.m2.2.2.cmml"><mi id="S2.SS2.p1.2.m2.2.2.3" xref="S2.SS2.p1.2.m2.2.2.3.cmml">f</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p1.2.m2.2.2.2" xref="S2.SS2.p1.2.m2.2.2.2.cmml">â€‹</mo><mrow id="S2.SS2.p1.2.m2.2.2.1.1" xref="S2.SS2.p1.2.m2.2.2.1.2.cmml"><mo stretchy="false" id="S2.SS2.p1.2.m2.2.2.1.1.2" xref="S2.SS2.p1.2.m2.2.2.1.2.cmml">(</mo><msup id="S2.SS2.p1.2.m2.2.2.1.1.1" xref="S2.SS2.p1.2.m2.2.2.1.1.1.cmml"><mi id="S2.SS2.p1.2.m2.2.2.1.1.1.2" xref="S2.SS2.p1.2.m2.2.2.1.1.1.2.cmml">ğœ½</mi><mo id="S2.SS2.p1.2.m2.2.2.1.1.1.3" xref="S2.SS2.p1.2.m2.2.2.1.1.1.3.cmml">â€²</mo></msup><mo rspace="0em" id="S2.SS2.p1.2.m2.2.2.1.1.3" xref="S2.SS2.p1.2.m2.2.2.1.2.cmml">;</mo><mo lspace="0em" rspace="0em" id="S2.SS2.p1.2.m2.1.1" xref="S2.SS2.p1.2.m2.1.1.cmml">â‹…</mo><mo stretchy="false" id="S2.SS2.p1.2.m2.2.2.1.1.4" xref="S2.SS2.p1.2.m2.2.2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.2.m2.2b"><apply id="S2.SS2.p1.2.m2.2.2.cmml" xref="S2.SS2.p1.2.m2.2.2"><times id="S2.SS2.p1.2.m2.2.2.2.cmml" xref="S2.SS2.p1.2.m2.2.2.2"></times><ci id="S2.SS2.p1.2.m2.2.2.3.cmml" xref="S2.SS2.p1.2.m2.2.2.3">ğ‘“</ci><list id="S2.SS2.p1.2.m2.2.2.1.2.cmml" xref="S2.SS2.p1.2.m2.2.2.1.1"><apply id="S2.SS2.p1.2.m2.2.2.1.1.1.cmml" xref="S2.SS2.p1.2.m2.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.2.m2.2.2.1.1.1.1.cmml" xref="S2.SS2.p1.2.m2.2.2.1.1.1">superscript</csymbol><ci id="S2.SS2.p1.2.m2.2.2.1.1.1.2.cmml" xref="S2.SS2.p1.2.m2.2.2.1.1.1.2">ğœ½</ci><ci id="S2.SS2.p1.2.m2.2.2.1.1.1.3.cmml" xref="S2.SS2.p1.2.m2.2.2.1.1.1.3">â€²</ci></apply><ci id="S2.SS2.p1.2.m2.1.1.cmml" xref="S2.SS2.p1.2.m2.1.1">â‹…</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.2.m2.2c">f(\bm{\theta}^{\prime};\cdot)</annotation></semantics></math> is trained on clean data samples <math id="S2.SS2.p1.3.m3.2" class="ltx_Math" alttext="(\bm{x},\bm{y})" display="inline"><semantics id="S2.SS2.p1.3.m3.2a"><mrow id="S2.SS2.p1.3.m3.2.3.2" xref="S2.SS2.p1.3.m3.2.3.1.cmml"><mo stretchy="false" id="S2.SS2.p1.3.m3.2.3.2.1" xref="S2.SS2.p1.3.m3.2.3.1.cmml">(</mo><mi id="S2.SS2.p1.3.m3.1.1" xref="S2.SS2.p1.3.m3.1.1.cmml">ğ’™</mi><mo id="S2.SS2.p1.3.m3.2.3.2.2" xref="S2.SS2.p1.3.m3.2.3.1.cmml">,</mo><mi id="S2.SS2.p1.3.m3.2.2" xref="S2.SS2.p1.3.m3.2.2.cmml">ğ’š</mi><mo stretchy="false" id="S2.SS2.p1.3.m3.2.3.2.3" xref="S2.SS2.p1.3.m3.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.3.m3.2b"><interval closure="open" id="S2.SS2.p1.3.m3.2.3.1.cmml" xref="S2.SS2.p1.3.m3.2.3.2"><ci id="S2.SS2.p1.3.m3.1.1.cmml" xref="S2.SS2.p1.3.m3.1.1">ğ’™</ci><ci id="S2.SS2.p1.3.m3.2.2.cmml" xref="S2.SS2.p1.3.m3.2.2">ğ’š</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.3.m3.2c">(\bm{x},\bm{y})</annotation></semantics></math> together with backdoored samples <math id="S2.SS2.p1.4.m4.2" class="ltx_Math" alttext="(\bm{x}^{\prime},\bm{y}_{t})" display="inline"><semantics id="S2.SS2.p1.4.m4.2a"><mrow id="S2.SS2.p1.4.m4.2.2.2" xref="S2.SS2.p1.4.m4.2.2.3.cmml"><mo stretchy="false" id="S2.SS2.p1.4.m4.2.2.2.3" xref="S2.SS2.p1.4.m4.2.2.3.cmml">(</mo><msup id="S2.SS2.p1.4.m4.1.1.1.1" xref="S2.SS2.p1.4.m4.1.1.1.1.cmml"><mi id="S2.SS2.p1.4.m4.1.1.1.1.2" xref="S2.SS2.p1.4.m4.1.1.1.1.2.cmml">ğ’™</mi><mo id="S2.SS2.p1.4.m4.1.1.1.1.3" xref="S2.SS2.p1.4.m4.1.1.1.1.3.cmml">â€²</mo></msup><mo id="S2.SS2.p1.4.m4.2.2.2.4" xref="S2.SS2.p1.4.m4.2.2.3.cmml">,</mo><msub id="S2.SS2.p1.4.m4.2.2.2.2" xref="S2.SS2.p1.4.m4.2.2.2.2.cmml"><mi id="S2.SS2.p1.4.m4.2.2.2.2.2" xref="S2.SS2.p1.4.m4.2.2.2.2.2.cmml">ğ’š</mi><mi id="S2.SS2.p1.4.m4.2.2.2.2.3" xref="S2.SS2.p1.4.m4.2.2.2.2.3.cmml">t</mi></msub><mo stretchy="false" id="S2.SS2.p1.4.m4.2.2.2.5" xref="S2.SS2.p1.4.m4.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.4.m4.2b"><interval closure="open" id="S2.SS2.p1.4.m4.2.2.3.cmml" xref="S2.SS2.p1.4.m4.2.2.2"><apply id="S2.SS2.p1.4.m4.1.1.1.1.cmml" xref="S2.SS2.p1.4.m4.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.4.m4.1.1.1.1.1.cmml" xref="S2.SS2.p1.4.m4.1.1.1.1">superscript</csymbol><ci id="S2.SS2.p1.4.m4.1.1.1.1.2.cmml" xref="S2.SS2.p1.4.m4.1.1.1.1.2">ğ’™</ci><ci id="S2.SS2.p1.4.m4.1.1.1.1.3.cmml" xref="S2.SS2.p1.4.m4.1.1.1.1.3">â€²</ci></apply><apply id="S2.SS2.p1.4.m4.2.2.2.2.cmml" xref="S2.SS2.p1.4.m4.2.2.2.2"><csymbol cd="ambiguous" id="S2.SS2.p1.4.m4.2.2.2.2.1.cmml" xref="S2.SS2.p1.4.m4.2.2.2.2">subscript</csymbol><ci id="S2.SS2.p1.4.m4.2.2.2.2.2.cmml" xref="S2.SS2.p1.4.m4.2.2.2.2.2">ğ’š</ci><ci id="S2.SS2.p1.4.m4.2.2.2.2.3.cmml" xref="S2.SS2.p1.4.m4.2.2.2.2.3">ğ‘¡</ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.4.m4.2c">(\bm{x}^{\prime},\bm{y}_{t})</annotation></semantics></math>. During the inference phase, the presence of a backdoor trigger in input samples will mislead backdoored model <math id="S2.SS2.p1.5.m5.2" class="ltx_Math" alttext="f(\bm{\theta}^{\prime};\cdot)" display="inline"><semantics id="S2.SS2.p1.5.m5.2a"><mrow id="S2.SS2.p1.5.m5.2.2" xref="S2.SS2.p1.5.m5.2.2.cmml"><mi id="S2.SS2.p1.5.m5.2.2.3" xref="S2.SS2.p1.5.m5.2.2.3.cmml">f</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p1.5.m5.2.2.2" xref="S2.SS2.p1.5.m5.2.2.2.cmml">â€‹</mo><mrow id="S2.SS2.p1.5.m5.2.2.1.1" xref="S2.SS2.p1.5.m5.2.2.1.2.cmml"><mo stretchy="false" id="S2.SS2.p1.5.m5.2.2.1.1.2" xref="S2.SS2.p1.5.m5.2.2.1.2.cmml">(</mo><msup id="S2.SS2.p1.5.m5.2.2.1.1.1" xref="S2.SS2.p1.5.m5.2.2.1.1.1.cmml"><mi id="S2.SS2.p1.5.m5.2.2.1.1.1.2" xref="S2.SS2.p1.5.m5.2.2.1.1.1.2.cmml">ğœ½</mi><mo id="S2.SS2.p1.5.m5.2.2.1.1.1.3" xref="S2.SS2.p1.5.m5.2.2.1.1.1.3.cmml">â€²</mo></msup><mo rspace="0em" id="S2.SS2.p1.5.m5.2.2.1.1.3" xref="S2.SS2.p1.5.m5.2.2.1.2.cmml">;</mo><mo lspace="0em" rspace="0em" id="S2.SS2.p1.5.m5.1.1" xref="S2.SS2.p1.5.m5.1.1.cmml">â‹…</mo><mo stretchy="false" id="S2.SS2.p1.5.m5.2.2.1.1.4" xref="S2.SS2.p1.5.m5.2.2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.5.m5.2b"><apply id="S2.SS2.p1.5.m5.2.2.cmml" xref="S2.SS2.p1.5.m5.2.2"><times id="S2.SS2.p1.5.m5.2.2.2.cmml" xref="S2.SS2.p1.5.m5.2.2.2"></times><ci id="S2.SS2.p1.5.m5.2.2.3.cmml" xref="S2.SS2.p1.5.m5.2.2.3">ğ‘“</ci><list id="S2.SS2.p1.5.m5.2.2.1.2.cmml" xref="S2.SS2.p1.5.m5.2.2.1.1"><apply id="S2.SS2.p1.5.m5.2.2.1.1.1.cmml" xref="S2.SS2.p1.5.m5.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.5.m5.2.2.1.1.1.1.cmml" xref="S2.SS2.p1.5.m5.2.2.1.1.1">superscript</csymbol><ci id="S2.SS2.p1.5.m5.2.2.1.1.1.2.cmml" xref="S2.SS2.p1.5.m5.2.2.1.1.1.2">ğœ½</ci><ci id="S2.SS2.p1.5.m5.2.2.1.1.1.3.cmml" xref="S2.SS2.p1.5.m5.2.2.1.1.1.3">â€²</ci></apply><ci id="S2.SS2.p1.5.m5.1.1.cmml" xref="S2.SS2.p1.5.m5.1.1">â‹…</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.5.m5.2c">f(\bm{\theta}^{\prime};\cdot)</annotation></semantics></math> to predict the target label <math id="S2.SS2.p1.6.m6.1" class="ltx_Math" alttext="\bm{y}_{t}" display="inline"><semantics id="S2.SS2.p1.6.m6.1a"><msub id="S2.SS2.p1.6.m6.1.1" xref="S2.SS2.p1.6.m6.1.1.cmml"><mi id="S2.SS2.p1.6.m6.1.1.2" xref="S2.SS2.p1.6.m6.1.1.2.cmml">ğ’š</mi><mi id="S2.SS2.p1.6.m6.1.1.3" xref="S2.SS2.p1.6.m6.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.6.m6.1b"><apply id="S2.SS2.p1.6.m6.1.1.cmml" xref="S2.SS2.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.6.m6.1.1.1.cmml" xref="S2.SS2.p1.6.m6.1.1">subscript</csymbol><ci id="S2.SS2.p1.6.m6.1.1.2.cmml" xref="S2.SS2.p1.6.m6.1.1.2">ğ’š</ci><ci id="S2.SS2.p1.6.m6.1.1.3.cmml" xref="S2.SS2.p1.6.m6.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.6.m6.1c">\bm{y}_{t}</annotation></semantics></math> while keeping the same performance on samples without the trigger. Therefore, compared with poisoning attacks which corrupt FL modelsâ€™ prediction performance or make FL training divergeÂ <cite class="ltx_cite ltx_citemacro_citep">(Fang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib18" title="" class="ltx_ref">2020</a>; Blanchard etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib8" title="" class="ltx_ref">2017</a>; Baruch etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib6" title="" class="ltx_ref">2019</a>; Tolpegin etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib52" title="" class="ltx_ref">2020</a>)</cite>, backdoor attacks are more stealthy and hard to detect since the backdoored model behaves normally in the absence of triggersÂ <cite class="ltx_cite ltx_citemacro_citep">(Goldblum etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p">Backdoor Attacks in FL could be separated into 2 categories: <span id="S2.SS2.p2.1.1" class="ltx_text ltx_font_bold">(1)</span> white-box setting where the adversarial client can control the whole local training process and local updates to the server; <span id="S2.SS2.p2.1.2" class="ltx_text ltx_font_bold">(2)</span> black-box setting where the adversarial client is only allowed to manipulate his own local dataset. In the black-box setting, the adversary does not require computing resources and any access to the internal configurations (e.g., FL binaries, memory) of compromised devices. Therefore, backdoor attacks in black-box setting is much more practical in real-world scenariosÂ <cite class="ltx_cite ltx_citemacro_citep">(Shejwalkar etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib47" title="" class="ltx_ref">2022</a>; Lyu etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib38" title="" class="ltx_ref">2020</a>; Kairouz etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib27" title="" class="ltx_ref">2021</a>)</cite> and also more widely used in previous works of backdoor learningÂ <cite class="ltx_cite ltx_citemacro_citep">(Wang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib54" title="" class="ltx_ref">2020</a>; Shejwalkar etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib47" title="" class="ltx_ref">2022</a>; Wu etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib55" title="" class="ltx_ref">2022a</a>)</cite>.</p>
</div>
<div id="S2.SS2.p3" class="ltx_para">
<p id="S2.SS2.p3.1" class="ltx_p">Bagdasaryan et alÂ <cite class="ltx_cite ltx_citemacro_citep">(Bagdasaryan etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib4" title="" class="ltx_ref">2020</a>)</cite> propose the ï¬rst backdoor attack in FL. One or multiple adversarial clients use several special training samples as semantic triggers which are inconsistent with other images in the same class. The authors also assume that attackers always conduct attacks near the convergent phase of FL training.
Wang et alÂ <cite class="ltx_cite ltx_citemacro_citep">(Wang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib54" title="" class="ltx_ref">2020</a>)</cite> propose edge-case backdoor triggers by choosing samples from other data distributions as backdoor triggers. They think these samples are located in the tail of the original data distribution. Therefore, the model updates from those samples are unlikely to conflict with model updates from other benign clients. Their experiments also show that edge-case triggers are more effective and persistent than semantic triggers. Besides, the authors also use a more practical attack setting, where the attacker could only periodically participates in several FL rounds, for example, in every fixed <math id="S2.SS2.p3.1.m1.1" class="ltx_Math" alttext="Q" display="inline"><semantics id="S2.SS2.p3.1.m1.1a"><mi id="S2.SS2.p3.1.m1.1.1" xref="S2.SS2.p3.1.m1.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.1.m1.1b"><ci id="S2.SS2.p3.1.m1.1.1.cmml" xref="S2.SS2.p3.1.m1.1.1">ğ‘„</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.1.m1.1c">Q</annotation></semantics></math> round.</p>
</div>
<div id="S2.SS2.p4" class="ltx_para">
<p id="S2.SS2.p4.1" class="ltx_p">In DBA attackÂ <cite class="ltx_cite ltx_citemacro_citep">(Xie etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib58" title="" class="ltx_ref">2020</a>)</cite>, the authors propose to use the BadNetÂ <cite class="ltx_cite ltx_citemacro_citep">(Gu etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib20" title="" class="ltx_ref">2019</a>)</cite> trigger which is the most widely used attack in centralized training. Besides, DBA attack also assumes the attacker can control multiple adversarial clients. Each adversary injects a different local trigger into his own dataset, trains the model on this backdoored dataset, and uploads its model updates to the server. During the inference process, the attacker uses the combination of these local triggers as a new trigger to conduct the attack.</p>
</div>
<div id="S2.SS2.p5" class="ltx_para">
<p id="S2.SS2.p5.1" class="ltx_p">Besides, other works also propose white-box backdoor attacksÂ <cite class="ltx_cite ltx_citemacro_citep">(Bagdasaryan etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib4" title="" class="ltx_ref">2020</a>; Bhagoji etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib7" title="" class="ltx_ref">2019</a>; Zhang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib62" title="" class="ltx_ref">2022a</a>; Xie etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib58" title="" class="ltx_ref">2020</a>)</cite>, which allow attackers to control the local training process, such as model replacement attack to magnify poisoning updateÂ <cite class="ltx_cite ltx_citemacro_citep">(Bagdasaryan etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib4" title="" class="ltx_ref">2020</a>)</cite>. We leave evaluations about them in future work.</p>
</div>
<figure id="S2.F1" class="ltx_figure"><img src="/html/2302.01677/assets/x1.png" id="S2.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="207" height="102" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F1.2.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>. </span><span id="S2.F1.3.2" class="ltx_text" style="font-size:90%;">We show used backdoor triggers: edge-case, BadNet, Blended, SIG triggers. The first and second row are visualizations on CIFAR-10 and FEMNIST, respectively.</span></figcaption>
</figure>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>Threat Model</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">In this work, we focus on <span id="S3.p1.1.1" class="ltx_text ltx_font_bold">black-box backdoor attacks</span> that do not require control and knowledge about training procedures like model architecture, parameters, or training methods. They also do not require any computing resources which makes them essential threat in real-world scenarios. For simplicity, we consider the task of image classification that has been used in most research on backdoor attacks.</p>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.2" class="ltx_p">In our studies, we choose the stricter assumption that there is only one adversarial client. FollowingÂ <cite class="ltx_cite ltx_citemacro_citep">(Wang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib54" title="" class="ltx_ref">2020</a>; Sun etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib49" title="" class="ltx_ref">2019</a>)</cite>, we adopt the fix-frequency attack setting in which the adversarial client is selected to join in the training process for every fixed <math id="S3.p2.1.m1.1" class="ltx_Math" alttext="Q" display="inline"><semantics id="S3.p2.1.m1.1a"><mi id="S3.p2.1.m1.1.1" xref="S3.p2.1.m1.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S3.p2.1.m1.1b"><ci id="S3.p2.1.m1.1.1.cmml" xref="S3.p2.1.m1.1.1">ğ‘„</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.1.m1.1c">Q</annotation></semantics></math> round, where we set <math id="S3.p2.2.m2.1" class="ltx_Math" alttext="Q=10" display="inline"><semantics id="S3.p2.2.m2.1a"><mrow id="S3.p2.2.m2.1.1" xref="S3.p2.2.m2.1.1.cmml"><mi id="S3.p2.2.m2.1.1.2" xref="S3.p2.2.m2.1.1.2.cmml">Q</mi><mo id="S3.p2.2.m2.1.1.1" xref="S3.p2.2.m2.1.1.1.cmml">=</mo><mn id="S3.p2.2.m2.1.1.3" xref="S3.p2.2.m2.1.1.3.cmml">10</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.p2.2.m2.1b"><apply id="S3.p2.2.m2.1.1.cmml" xref="S3.p2.2.m2.1.1"><eq id="S3.p2.2.m2.1.1.1.cmml" xref="S3.p2.2.m2.1.1.1"></eq><ci id="S3.p2.2.m2.1.1.2.cmml" xref="S3.p2.2.m2.1.1.2">ğ‘„</ci><cn type="integer" id="S3.p2.2.m2.1.1.3.cmml" xref="S3.p2.2.m2.1.1.3">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.2.m2.1c">Q=10</annotation></semantics></math> through all experiments.</p>
</div>
<div id="S3.p3" class="ltx_para">
<p id="S3.p3.1" class="ltx_p">We adopt commonly used <span id="S3.p3.1.1" class="ltx_text ltx_font_bold">edge-case</span> and <span id="S3.p3.1.2" class="ltx_text ltx_font_bold">BadNet</span> triggers in our evaluations and also explore various trigger types, including <span id="S3.p3.1.3" class="ltx_text ltx_font_bold">Blended</span>Â <cite class="ltx_cite ltx_citemacro_citep">(Chen etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib12" title="" class="ltx_ref">2017</a>)</cite> and <span id="S3.p3.1.4" class="ltx_text ltx_font_bold">SIG</span>Â <cite class="ltx_cite ltx_citemacro_citep">(Barni etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib5" title="" class="ltx_ref">2019</a>)</cite> triggers, which are widely used in centralized training but not yet studied in FL. Blended trigger extends BadNet by encouraging the invisibility of triggers through blending clean images and triggers. We choose the hello-kitty (hk) pattern as our trigger since it achieves the best attack performance in related backdoor defense worksÂ <cite class="ltx_cite ltx_citemacro_citep">(Huang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib25" title="" class="ltx_ref">2022</a>; Wu and Wang, <a href="#bib.bib56" title="" class="ltx_ref">2021</a>; Wu etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib55" title="" class="ltx_ref">2022a</a>; Zheng etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib63" title="" class="ltx_ref">2022</a>)</cite>. Without changing image pixels, SIG adopts a sinusoidal signal as the trigger to perturb clean images. Examples of backdoor triggers are listed in FigureÂ <a href="#S2.F1" title="Figure 1 â€£ 2.2. Backdoor Attacks in FL â€£ 2. Background â€£ Revisiting Personalized Federated Learning: Robustness Against Backdoor Attacks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>Robustness of pFL methods against Backdoor Attacks</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">In this work, we want to learn that apart from better prediction accuracy, do pFL methods bring robustness again backdoor attacks? If the answer is true, what factors of pFL methods lead to robustness? And based on our studies, could we exploit this robustness benefit to help improve the robustness of FL models against backdoor attacks? We first try to answer the first question by conducting the evaluations of backdoor attacks on pFL methods mentioned before. We outline our experimental setup in Section <a href="#S4.SS1" title="4.1. Experimental Settings â€£ 4. Robustness of pFL methods against Backdoor Attacks â€£ Revisiting Personalized Federated Learning: Robustness Against Backdoor Attacks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a> and show overall experimental results in Section <a href="#S4.SS2" title="4.2. The Overall Robustness Evaluation â€£ 4. Robustness of pFL methods against Backdoor Attacks â€£ Revisiting Personalized Federated Learning: Robustness Against Backdoor Attacks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a> followed by our interesting findings. We also compare some widely used defense methods in FL in Section <a href="#S4.SS2" title="4.2. The Overall Robustness Evaluation â€£ 4. Robustness of pFL methods against Backdoor Attacks â€£ Revisiting Personalized Federated Learning: Robustness Against Backdoor Attacks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.1" class="ltx_p">To further analyze the reasons behind various robustness
from pFL methods, we conduct ablation studies on pFL methods with partial model-sharing in Section <a href="#S5.SS1" title="5.1. pFL Methods with Partial model-sharing â€£ 5. Analysis of Various Robustness from pFL Against Backdoor Attacks â€£ Revisiting Personalized Federated Learning: Robustness Against Backdoor Attacks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.1</span></a> and methods with full model-sharing in Section <a href="#S5.SS2" title="5.2. pFL Methods with Full model-sharing â€£ 5. Analysis of Various Robustness from pFL Against Backdoor Attacks â€£ Revisiting Personalized Federated Learning: Robustness Against Backdoor Attacks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.2</span></a>, respectively. In Section <a href="#S6" title="6. Improving Backdoor Robustness with Simple-Tuning â€£ Revisiting Personalized Federated Learning: Robustness Against Backdoor Attacks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>, based on previous findings, we propose a simple defense method, <span id="S4.p2.1.1" class="ltx_text ltx_font_italic">Simple-Tuning</span> and further verify its effectiveness of defending against backdoor attacks by taking experiments on FL methods.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1. </span>Experimental Settings</h3>

<section id="S4.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.1. </span>Datasets and Models</h4>

<div id="S4.SS1.SSS1.p1" class="ltx_para">
<p id="S4.SS1.SSS1.p1.1" class="ltx_p">We conduct evaluations on two widely used image classification datasets, <span id="S4.SS1.SSS1.p1.1.1" class="ltx_text ltx_font_bold">FEMNIST</span>Â <cite class="ltx_cite ltx_citemacro_citep">(Caldas etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib9" title="" class="ltx_ref">2018</a>)</cite> and <span id="S4.SS1.SSS1.p1.1.2" class="ltx_text ltx_font_bold">CIFAR-10</span>Â <cite class="ltx_cite ltx_citemacro_citep">(Krizhevsky etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib29" title="" class="ltx_ref">2009</a>)</cite> in FL literature.
FEMNIST is a handwritten character recognition dataset containing 62 classes and each client corresponds to a character writer from EMNIST<cite class="ltx_cite ltx_citemacro_citep">(Cohen etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib13" title="" class="ltx_ref">2017</a>)</cite>.
Following pFL-bench<cite class="ltx_cite ltx_citemacro_citep">(Chen etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2022</a>)</cite>, we adopt the sub-sampled version of FEMNIST in our experiment, and it contains 200 clients. And the dataset is randomly split into train/valid/test sets with a ratio 3:1:1. For CIFAR-10, following previous worksÂ <cite class="ltx_cite ltx_citemacro_citep">(Chen etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2022</a>; Caldas etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib9" title="" class="ltx_ref">2018</a>; Wang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib54" title="" class="ltx_ref">2020</a>; Zawad etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib60" title="" class="ltx_ref">2021</a>)</cite>, we use Dirichlet allocation to split
it into 100 clients with Dirichlet factor <math id="S4.SS1.SSS1.p1.1.m1.1" class="ltx_Math" alttext="\alpha=0.5" display="inline"><semantics id="S4.SS1.SSS1.p1.1.m1.1a"><mrow id="S4.SS1.SSS1.p1.1.m1.1.1" xref="S4.SS1.SSS1.p1.1.m1.1.1.cmml"><mi id="S4.SS1.SSS1.p1.1.m1.1.1.2" xref="S4.SS1.SSS1.p1.1.m1.1.1.2.cmml">Î±</mi><mo id="S4.SS1.SSS1.p1.1.m1.1.1.1" xref="S4.SS1.SSS1.p1.1.m1.1.1.1.cmml">=</mo><mn id="S4.SS1.SSS1.p1.1.m1.1.1.3" xref="S4.SS1.SSS1.p1.1.m1.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.p1.1.m1.1b"><apply id="S4.SS1.SSS1.p1.1.m1.1.1.cmml" xref="S4.SS1.SSS1.p1.1.m1.1.1"><eq id="S4.SS1.SSS1.p1.1.m1.1.1.1.cmml" xref="S4.SS1.SSS1.p1.1.m1.1.1.1"></eq><ci id="S4.SS1.SSS1.p1.1.m1.1.1.2.cmml" xref="S4.SS1.SSS1.p1.1.m1.1.1.2">ğ›¼</ci><cn type="float" id="S4.SS1.SSS1.p1.1.m1.1.1.3.cmml" xref="S4.SS1.SSS1.p1.1.m1.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.p1.1.m1.1c">\alpha=0.5</annotation></semantics></math>.
These two datasets represent two different settings in Non-IID setting: feature-skew and label skewÂ <cite class="ltx_cite ltx_citemacro_citep">(Chen etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2022</a>; Lyu etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib38" title="" class="ltx_ref">2020</a>; Zawad etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib60" title="" class="ltx_ref">2021</a>)</cite>.
Besides, for CIFAR-10, we also consider the IID setting in which we uniformly and randomly sample images from each class for each client. The splitting details about datasets are shown in Section <a href="#A1" title="Appendix A1 Datasets and Models â€£ Revisiting Personalized Federated Learning: Robustness Against Backdoor Attacks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A1</span></a> in <span id="S4.SS1.SSS1.p1.1.3" class="ltx_text ltx_font_italic">Appendix</span>.</p>
</div>
<div id="S4.SS1.SSS1.p2" class="ltx_para">
<p id="S4.SS1.SSS1.p2.1" class="ltx_p">Following pFL worksÂ <cite class="ltx_cite ltx_citemacro_citep">(Chen etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2022</a>; Liang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib36" title="" class="ltx_ref">2020</a>; TÂ Dinh etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib50" title="" class="ltx_ref">2020</a>)</cite>, we use a simple ConvNet model on these two datasets. The details are shown in Section <a href="#A1" title="Appendix A1 Datasets and Models â€£ Revisiting Personalized Federated Learning: Robustness Against Backdoor Attacks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A1</span></a> in <span id="S4.SS1.SSS1.p2.1.1" class="ltx_text ltx_font_italic">Appendix</span>. Besides, to align with previous backdoor attacks worksÂ <cite class="ltx_cite ltx_citemacro_citep">(Wang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib54" title="" class="ltx_ref">2020</a>; Zhang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib62" title="" class="ltx_ref">2022a</a>)</cite>, we also use a larger network, ResNet-18Â <cite class="ltx_cite ltx_citemacro_citep">(He etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib24" title="" class="ltx_ref">2016</a>)</cite>, for CIFAR-10 dataset.</p>
</div>
</section>
<section id="S4.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.2. </span>Personalized FL Methods.</h4>

<div id="S4.SS1.SSS2.p1" class="ltx_para">
<p id="S4.SS1.SSS2.p1.1" class="ltx_p">We first consider the baseline FL method, <span id="S4.SS1.SSS2.p1.1.1" class="ltx_text ltx_font_italic">FedAvg</span>Â <cite class="ltx_cite ltx_citemacro_citep">(McMahan etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib41" title="" class="ltx_ref">2017</a>)</cite>. We adopt mainstreamed pFL methods mentioned in Section <a href="#S2.SS1" title="2.1. Personalized Federated Learning â€£ 2. Background â€£ Revisiting Personalized Federated Learning: Robustness Against Backdoor Attacks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.1</span></a>, <span id="S4.SS1.SSS2.p1.1.2" class="ltx_text ltx_font_italic">Fine-tuning</span>Â <cite class="ltx_cite ltx_citemacro_citep">(Liang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib36" title="" class="ltx_ref">2020</a>)</cite>, <span id="S4.SS1.SSS2.p1.1.3" class="ltx_text ltx_font_italic">FedBN</span>Â <cite class="ltx_cite ltx_citemacro_citep">(Li etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib34" title="" class="ltx_ref">2021b</a>)</cite>, <span id="S4.SS1.SSS2.p1.1.4" class="ltx_text ltx_font_italic">FedRep</span>Â <cite class="ltx_cite ltx_citemacro_citep">(Collins etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2021</a>; Pillutla etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib45" title="" class="ltx_ref">2022</a>)</cite>, <span id="S4.SS1.SSS2.p1.1.5" class="ltx_text ltx_font_italic">Ditto</span>Â <cite class="ltx_cite ltx_citemacro_citep">(Li etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib32" title="" class="ltx_ref">2021a</a>)</cite>, <span id="S4.SS1.SSS2.p1.1.6" class="ltx_text ltx_font_italic">pFedMe</span>Â <cite class="ltx_cite ltx_citemacro_citep">(TÂ Dinh etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib50" title="" class="ltx_ref">2020</a>)</cite>, <span id="S4.SS1.SSS2.p1.1.7" class="ltx_text ltx_font_italic">FedEM</span>Â <cite class="ltx_cite ltx_citemacro_citep">(Marfoq etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib39" title="" class="ltx_ref">2021</a>)</cite>. They are also used in recent benchmarkÂ <cite class="ltx_cite ltx_citemacro_citep">(Chen etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2022</a>; Matsuda etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib40" title="" class="ltx_ref">2022</a>)</cite>. We implement these methods following pFL-bench <span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a target="_blank" href="https://github.com/alibaba/FederatedScope/tree/master/benchmark/pFL-Bench" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/alibaba/FederatedScope/tree/master/benchmark/pFL-Bench</a></span></span></span>Â <cite class="ltx_cite ltx_citemacro_citep">(Chen etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2022</a>)</cite> and defer the choice of hyperparameters in Section <a href="#A2" title="Appendix A2 Implementation Details â€£ Revisiting Personalized Federated Learning: Robustness Against Backdoor Attacks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A2</span></a> in <span id="S4.SS1.SSS2.p1.1.8" class="ltx_text ltx_font_italic">Appendix</span>.</p>
</div>
</section>
<section id="S4.SS1.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.3. </span>Training Details.</h4>

<div id="S4.SS1.SSS3.p1" class="ltx_para">
<p id="S4.SS1.SSS3.p1.5" class="ltx_p">The total training round <math id="S4.SS1.SSS3.p1.1.m1.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S4.SS1.SSS3.p1.1.m1.1a"><mi id="S4.SS1.SSS3.p1.1.m1.1.1" xref="S4.SS1.SSS3.p1.1.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS3.p1.1.m1.1b"><ci id="S4.SS1.SSS3.p1.1.m1.1.1.cmml" xref="S4.SS1.SSS3.p1.1.m1.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS3.p1.1.m1.1c">T</annotation></semantics></math> is set to be <math id="S4.SS1.SSS3.p1.2.m2.2" class="ltx_Math" alttext="1,000" display="inline"><semantics id="S4.SS1.SSS3.p1.2.m2.2a"><mrow id="S4.SS1.SSS3.p1.2.m2.2.3.2" xref="S4.SS1.SSS3.p1.2.m2.2.3.1.cmml"><mn id="S4.SS1.SSS3.p1.2.m2.1.1" xref="S4.SS1.SSS3.p1.2.m2.1.1.cmml">1</mn><mo id="S4.SS1.SSS3.p1.2.m2.2.3.2.1" xref="S4.SS1.SSS3.p1.2.m2.2.3.1.cmml">,</mo><mn id="S4.SS1.SSS3.p1.2.m2.2.2" xref="S4.SS1.SSS3.p1.2.m2.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS3.p1.2.m2.2b"><list id="S4.SS1.SSS3.p1.2.m2.2.3.1.cmml" xref="S4.SS1.SSS3.p1.2.m2.2.3.2"><cn type="integer" id="S4.SS1.SSS3.p1.2.m2.1.1.cmml" xref="S4.SS1.SSS3.p1.2.m2.1.1">1</cn><cn type="integer" id="S4.SS1.SSS3.p1.2.m2.2.2.cmml" xref="S4.SS1.SSS3.p1.2.m2.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS3.p1.2.m2.2c">1,000</annotation></semantics></math>. For each training round, the server randomly samples <math id="S4.SS1.SSS3.p1.3.m3.1" class="ltx_Math" alttext="10\%" display="inline"><semantics id="S4.SS1.SSS3.p1.3.m3.1a"><mrow id="S4.SS1.SSS3.p1.3.m3.1.1" xref="S4.SS1.SSS3.p1.3.m3.1.1.cmml"><mn id="S4.SS1.SSS3.p1.3.m3.1.1.2" xref="S4.SS1.SSS3.p1.3.m3.1.1.2.cmml">10</mn><mo id="S4.SS1.SSS3.p1.3.m3.1.1.1" xref="S4.SS1.SSS3.p1.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS3.p1.3.m3.1b"><apply id="S4.SS1.SSS3.p1.3.m3.1.1.cmml" xref="S4.SS1.SSS3.p1.3.m3.1.1"><csymbol cd="latexml" id="S4.SS1.SSS3.p1.3.m3.1.1.1.cmml" xref="S4.SS1.SSS3.p1.3.m3.1.1.1">percent</csymbol><cn type="integer" id="S4.SS1.SSS3.p1.3.m3.1.1.2.cmml" xref="S4.SS1.SSS3.p1.3.m3.1.1.2">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS3.p1.3.m3.1c">10\%</annotation></semantics></math> clients from all clients to participate in the training process. That is to say, in each round, <math id="S4.SS1.SSS3.p1.4.m4.1" class="ltx_Math" alttext="20" display="inline"><semantics id="S4.SS1.SSS3.p1.4.m4.1a"><mn id="S4.SS1.SSS3.p1.4.m4.1.1" xref="S4.SS1.SSS3.p1.4.m4.1.1.cmml">20</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS3.p1.4.m4.1b"><cn type="integer" id="S4.SS1.SSS3.p1.4.m4.1.1.cmml" xref="S4.SS1.SSS3.p1.4.m4.1.1">20</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS3.p1.4.m4.1c">20</annotation></semantics></math> and <math id="S4.SS1.SSS3.p1.5.m5.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S4.SS1.SSS3.p1.5.m5.1a"><mn id="S4.SS1.SSS3.p1.5.m5.1.1" xref="S4.SS1.SSS3.p1.5.m5.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS3.p1.5.m5.1b"><cn type="integer" id="S4.SS1.SSS3.p1.5.m5.1.1.cmml" xref="S4.SS1.SSS3.p1.5.m5.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS3.p1.5.m5.1c">10</annotation></semantics></math> clients are randomly selected for FEMNIST and CIFAR-10 dataset.</p>
</div>
</section>
<section id="S4.SS1.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.4. </span>Attack Settings.</h4>

<div id="S4.SS1.SSS4.p1" class="ltx_para">
<p id="S4.SS1.SSS4.p1.9" class="ltx_p">Through our evaluations, for simplicity, we choose the client-<math id="S4.SS1.SSS4.p1.1.m1.1" class="ltx_Math" alttext="1" display="inline"><semantics id="S4.SS1.SSS4.p1.1.m1.1a"><mn id="S4.SS1.SSS4.p1.1.m1.1.1" xref="S4.SS1.SSS4.p1.1.m1.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS4.p1.1.m1.1b"><cn type="integer" id="S4.SS1.SSS4.p1.1.m1.1.1.cmml" xref="S4.SS1.SSS4.p1.1.m1.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS4.p1.1.m1.1c">1</annotation></semantics></math> and client-<math id="S4.SS1.SSS4.p1.2.m2.1" class="ltx_Math" alttext="15" display="inline"><semantics id="S4.SS1.SSS4.p1.2.m2.1a"><mn id="S4.SS1.SSS4.p1.2.m2.1.1" xref="S4.SS1.SSS4.p1.2.m2.1.1.cmml">15</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS4.p1.2.m2.1b"><cn type="integer" id="S4.SS1.SSS4.p1.2.m2.1.1.cmml" xref="S4.SS1.SSS4.p1.2.m2.1.1">15</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS4.p1.2.m2.1c">15</annotation></semantics></math> as the adversarial client on FEMNIST and CIFAR-10, respectively. We set the target label <math id="S4.SS1.SSS4.p1.3.m3.1" class="ltx_Math" alttext="\bm{y_{t}}=1" display="inline"><semantics id="S4.SS1.SSS4.p1.3.m3.1a"><mrow id="S4.SS1.SSS4.p1.3.m3.1.1" xref="S4.SS1.SSS4.p1.3.m3.1.1.cmml"><msub id="S4.SS1.SSS4.p1.3.m3.1.1.2" xref="S4.SS1.SSS4.p1.3.m3.1.1.2.cmml"><mi id="S4.SS1.SSS4.p1.3.m3.1.1.2.2" xref="S4.SS1.SSS4.p1.3.m3.1.1.2.2.cmml">ğ’š</mi><mi id="S4.SS1.SSS4.p1.3.m3.1.1.2.3" xref="S4.SS1.SSS4.p1.3.m3.1.1.2.3.cmml">ğ’•</mi></msub><mo id="S4.SS1.SSS4.p1.3.m3.1.1.1" xref="S4.SS1.SSS4.p1.3.m3.1.1.1.cmml">=</mo><mn id="S4.SS1.SSS4.p1.3.m3.1.1.3" xref="S4.SS1.SSS4.p1.3.m3.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS4.p1.3.m3.1b"><apply id="S4.SS1.SSS4.p1.3.m3.1.1.cmml" xref="S4.SS1.SSS4.p1.3.m3.1.1"><eq id="S4.SS1.SSS4.p1.3.m3.1.1.1.cmml" xref="S4.SS1.SSS4.p1.3.m3.1.1.1"></eq><apply id="S4.SS1.SSS4.p1.3.m3.1.1.2.cmml" xref="S4.SS1.SSS4.p1.3.m3.1.1.2"><csymbol cd="ambiguous" id="S4.SS1.SSS4.p1.3.m3.1.1.2.1.cmml" xref="S4.SS1.SSS4.p1.3.m3.1.1.2">subscript</csymbol><ci id="S4.SS1.SSS4.p1.3.m3.1.1.2.2.cmml" xref="S4.SS1.SSS4.p1.3.m3.1.1.2.2">ğ’š</ci><ci id="S4.SS1.SSS4.p1.3.m3.1.1.2.3.cmml" xref="S4.SS1.SSS4.p1.3.m3.1.1.2.3">ğ’•</ci></apply><cn type="integer" id="S4.SS1.SSS4.p1.3.m3.1.1.3.cmml" xref="S4.SS1.SSS4.p1.3.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS4.p1.3.m3.1c">\bm{y_{t}}=1</annotation></semantics></math> on FEMNIST and <math id="S4.SS1.SSS4.p1.4.m4.1" class="ltx_Math" alttext="\bm{y_{t}}=9" display="inline"><semantics id="S4.SS1.SSS4.p1.4.m4.1a"><mrow id="S4.SS1.SSS4.p1.4.m4.1.1" xref="S4.SS1.SSS4.p1.4.m4.1.1.cmml"><msub id="S4.SS1.SSS4.p1.4.m4.1.1.2" xref="S4.SS1.SSS4.p1.4.m4.1.1.2.cmml"><mi id="S4.SS1.SSS4.p1.4.m4.1.1.2.2" xref="S4.SS1.SSS4.p1.4.m4.1.1.2.2.cmml">ğ’š</mi><mi id="S4.SS1.SSS4.p1.4.m4.1.1.2.3" xref="S4.SS1.SSS4.p1.4.m4.1.1.2.3.cmml">ğ’•</mi></msub><mo id="S4.SS1.SSS4.p1.4.m4.1.1.1" xref="S4.SS1.SSS4.p1.4.m4.1.1.1.cmml">=</mo><mn id="S4.SS1.SSS4.p1.4.m4.1.1.3" xref="S4.SS1.SSS4.p1.4.m4.1.1.3.cmml">9</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS4.p1.4.m4.1b"><apply id="S4.SS1.SSS4.p1.4.m4.1.1.cmml" xref="S4.SS1.SSS4.p1.4.m4.1.1"><eq id="S4.SS1.SSS4.p1.4.m4.1.1.1.cmml" xref="S4.SS1.SSS4.p1.4.m4.1.1.1"></eq><apply id="S4.SS1.SSS4.p1.4.m4.1.1.2.cmml" xref="S4.SS1.SSS4.p1.4.m4.1.1.2"><csymbol cd="ambiguous" id="S4.SS1.SSS4.p1.4.m4.1.1.2.1.cmml" xref="S4.SS1.SSS4.p1.4.m4.1.1.2">subscript</csymbol><ci id="S4.SS1.SSS4.p1.4.m4.1.1.2.2.cmml" xref="S4.SS1.SSS4.p1.4.m4.1.1.2.2">ğ’š</ci><ci id="S4.SS1.SSS4.p1.4.m4.1.1.2.3.cmml" xref="S4.SS1.SSS4.p1.4.m4.1.1.2.3">ğ’•</ci></apply><cn type="integer" id="S4.SS1.SSS4.p1.4.m4.1.1.3.cmml" xref="S4.SS1.SSS4.p1.4.m4.1.1.3">9</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS4.p1.4.m4.1c">\bm{y_{t}}=9</annotation></semantics></math> on CIFAR-10 followingÂ <cite class="ltx_cite ltx_citemacro_citep">(Wang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib54" title="" class="ltx_ref">2020</a>)</cite>. For FEMNIST dataset, we use 100 images of â€œ7â€s from ArdisÂ <cite class="ltx_cite ltx_citemacro_citep">(Kusetogullari etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib30" title="" class="ltx_ref">2020</a>)</cite> as edge-case triggers. For CIFAR-10 dataset, we use 500 images of Southwest Airlineâ€™s planes provided inÂ <cite class="ltx_cite ltx_citemacro_citep">(Wang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib54" title="" class="ltx_ref">2020</a>)</cite> as edge-case triggers. For each of BadNet, Blended, and SIG, we put it on <math id="S4.SS1.SSS4.p1.5.m5.1" class="ltx_Math" alttext="50\%" display="inline"><semantics id="S4.SS1.SSS4.p1.5.m5.1a"><mrow id="S4.SS1.SSS4.p1.5.m5.1.1" xref="S4.SS1.SSS4.p1.5.m5.1.1.cmml"><mn id="S4.SS1.SSS4.p1.5.m5.1.1.2" xref="S4.SS1.SSS4.p1.5.m5.1.1.2.cmml">50</mn><mo id="S4.SS1.SSS4.p1.5.m5.1.1.1" xref="S4.SS1.SSS4.p1.5.m5.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS4.p1.5.m5.1b"><apply id="S4.SS1.SSS4.p1.5.m5.1.1.cmml" xref="S4.SS1.SSS4.p1.5.m5.1.1"><csymbol cd="latexml" id="S4.SS1.SSS4.p1.5.m5.1.1.1.cmml" xref="S4.SS1.SSS4.p1.5.m5.1.1.1">percent</csymbol><cn type="integer" id="S4.SS1.SSS4.p1.5.m5.1.1.2.cmml" xref="S4.SS1.SSS4.p1.5.m5.1.1.2">50</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS4.p1.5.m5.1c">50\%</annotation></semantics></math> of training samples of the adversarial client. Following attack hyparameters provided inÂ <cite class="ltx_cite ltx_citemacro_citep">(Wu etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib55" title="" class="ltx_ref">2022a</a>)</cite>, for BadNet attack, we choose the <math id="S4.SS1.SSS4.p1.6.m6.1" class="ltx_Math" alttext="3\times 3" display="inline"><semantics id="S4.SS1.SSS4.p1.6.m6.1a"><mrow id="S4.SS1.SSS4.p1.6.m6.1.1" xref="S4.SS1.SSS4.p1.6.m6.1.1.cmml"><mn id="S4.SS1.SSS4.p1.6.m6.1.1.2" xref="S4.SS1.SSS4.p1.6.m6.1.1.2.cmml">3</mn><mo lspace="0.222em" rspace="0.222em" id="S4.SS1.SSS4.p1.6.m6.1.1.1" xref="S4.SS1.SSS4.p1.6.m6.1.1.1.cmml">Ã—</mo><mn id="S4.SS1.SSS4.p1.6.m6.1.1.3" xref="S4.SS1.SSS4.p1.6.m6.1.1.3.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS4.p1.6.m6.1b"><apply id="S4.SS1.SSS4.p1.6.m6.1.1.cmml" xref="S4.SS1.SSS4.p1.6.m6.1.1"><times id="S4.SS1.SSS4.p1.6.m6.1.1.1.cmml" xref="S4.SS1.SSS4.p1.6.m6.1.1.1"></times><cn type="integer" id="S4.SS1.SSS4.p1.6.m6.1.1.2.cmml" xref="S4.SS1.SSS4.p1.6.m6.1.1.2">3</cn><cn type="integer" id="S4.SS1.SSS4.p1.6.m6.1.1.3.cmml" xref="S4.SS1.SSS4.p1.6.m6.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS4.p1.6.m6.1c">3\times 3</annotation></semantics></math> grid pattern and put it at the downright corner of poisoned samples. For Blended attack, we choose the hello-kitty pattern and set the blending ratio <math id="S4.SS1.SSS4.p1.7.m7.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S4.SS1.SSS4.p1.7.m7.1a"><mi id="S4.SS1.SSS4.p1.7.m7.1.1" xref="S4.SS1.SSS4.p1.7.m7.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS4.p1.7.m7.1b"><ci id="S4.SS1.SSS4.p1.7.m7.1.1.cmml" xref="S4.SS1.SSS4.p1.7.m7.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS4.p1.7.m7.1c">\alpha</annotation></semantics></math> as <math id="S4.SS1.SSS4.p1.8.m8.1" class="ltx_Math" alttext="0.2" display="inline"><semantics id="S4.SS1.SSS4.p1.8.m8.1a"><mn id="S4.SS1.SSS4.p1.8.m8.1.1" xref="S4.SS1.SSS4.p1.8.m8.1.1.cmml">0.2</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS4.p1.8.m8.1b"><cn type="float" id="S4.SS1.SSS4.p1.8.m8.1.1.cmml" xref="S4.SS1.SSS4.p1.8.m8.1.1">0.2</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS4.p1.8.m8.1c">0.2</annotation></semantics></math>. For SIG attack, we set the amplitude of sinusoidal signal as 20 (<math id="S4.SS1.SSS4.p1.9.m9.2" class="ltx_Math" alttext="[0,255]" display="inline"><semantics id="S4.SS1.SSS4.p1.9.m9.2a"><mrow id="S4.SS1.SSS4.p1.9.m9.2.3.2" xref="S4.SS1.SSS4.p1.9.m9.2.3.1.cmml"><mo stretchy="false" id="S4.SS1.SSS4.p1.9.m9.2.3.2.1" xref="S4.SS1.SSS4.p1.9.m9.2.3.1.cmml">[</mo><mn id="S4.SS1.SSS4.p1.9.m9.1.1" xref="S4.SS1.SSS4.p1.9.m9.1.1.cmml">0</mn><mo id="S4.SS1.SSS4.p1.9.m9.2.3.2.2" xref="S4.SS1.SSS4.p1.9.m9.2.3.1.cmml">,</mo><mn id="S4.SS1.SSS4.p1.9.m9.2.2" xref="S4.SS1.SSS4.p1.9.m9.2.2.cmml">255</mn><mo stretchy="false" id="S4.SS1.SSS4.p1.9.m9.2.3.2.3" xref="S4.SS1.SSS4.p1.9.m9.2.3.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS4.p1.9.m9.2b"><interval closure="closed" id="S4.SS1.SSS4.p1.9.m9.2.3.1.cmml" xref="S4.SS1.SSS4.p1.9.m9.2.3.2"><cn type="integer" id="S4.SS1.SSS4.p1.9.m9.1.1.cmml" xref="S4.SS1.SSS4.p1.9.m9.1.1">0</cn><cn type="integer" id="S4.SS1.SSS4.p1.9.m9.2.2.cmml" xref="S4.SS1.SSS4.p1.9.m9.2.2">255</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS4.p1.9.m9.2c">[0,255]</annotation></semantics></math>). We also show these used triggers in Figure <a href="#S2.F1" title="Figure 1 â€£ 2.2. Backdoor Attacks in FL â€£ 2. Background â€£ Revisiting Personalized Federated Learning: Robustness Against Backdoor Attacks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
</section>
<section id="S4.SS1.SSS5" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.5. </span>Baseline Defense Methods.</h4>

<div id="S4.SS1.SSS5.p1" class="ltx_para">
<p id="S4.SS1.SSS5.p1.9" class="ltx_p">We adopt four baseline defense methods in FL: norm-clippingÂ <cite class="ltx_cite ltx_citemacro_citep">(Wang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib54" title="" class="ltx_ref">2020</a>; Shejwalkar etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib47" title="" class="ltx_ref">2022</a>; Sun etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib49" title="" class="ltx_ref">2019</a>)</cite>, adding noiseÂ <cite class="ltx_cite ltx_citemacro_citep">(Wang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib54" title="" class="ltx_ref">2020</a>; Sun etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib49" title="" class="ltx_ref">2019</a>; Du etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib15" title="" class="ltx_ref">2020</a>)</cite>, KrumÂ <cite class="ltx_cite ltx_citemacro_citep">(Blanchard etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib8" title="" class="ltx_ref">2017</a>)</cite>, and Multi-KrumÂ <cite class="ltx_cite ltx_citemacro_citep">(Blanchard etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib8" title="" class="ltx_ref">2017</a>)</cite> which are widely used in previous worksÂ <cite class="ltx_cite ltx_citemacro_citep">(Bagdasaryan etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib4" title="" class="ltx_ref">2020</a>; Sun etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib49" title="" class="ltx_ref">2019</a>; Wang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib54" title="" class="ltx_ref">2020</a>; Zhang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib62" title="" class="ltx_ref">2022a</a>; Shejwalkar etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib47" title="" class="ltx_ref">2022</a>; Du etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib15" title="" class="ltx_ref">2020</a>; Bagdasaryan etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib4" title="" class="ltx_ref">2020</a>; Xie etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib58" title="" class="ltx_ref">2020</a>)</cite>. <span id="S4.SS1.SSS5.p1.9.1" class="ltx_text ltx_font_bold">(1)</span> Krum only selects one uploaded model update which is similar to other updates by computing parameter similarity (<math id="S4.SS1.SSS5.p1.1.m1.1" class="ltx_Math" alttext="\ell_{2}" display="inline"><semantics id="S4.SS1.SSS5.p1.1.m1.1a"><msub id="S4.SS1.SSS5.p1.1.m1.1.1" xref="S4.SS1.SSS5.p1.1.m1.1.1.cmml"><mi mathvariant="normal" id="S4.SS1.SSS5.p1.1.m1.1.1.2" xref="S4.SS1.SSS5.p1.1.m1.1.1.2.cmml">â„“</mi><mn id="S4.SS1.SSS5.p1.1.m1.1.1.3" xref="S4.SS1.SSS5.p1.1.m1.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS5.p1.1.m1.1b"><apply id="S4.SS1.SSS5.p1.1.m1.1.1.cmml" xref="S4.SS1.SSS5.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS5.p1.1.m1.1.1.1.cmml" xref="S4.SS1.SSS5.p1.1.m1.1.1">subscript</csymbol><ci id="S4.SS1.SSS5.p1.1.m1.1.1.2.cmml" xref="S4.SS1.SSS5.p1.1.m1.1.1.2">â„“</ci><cn type="integer" id="S4.SS1.SSS5.p1.1.m1.1.1.3.cmml" xref="S4.SS1.SSS5.p1.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS5.p1.1.m1.1c">\ell_{2}</annotation></semantics></math> norm) between them as the aggregation result. Rather than only selecting one update, Multi-Krum selects top-k updates based on ranking of computed similarity and then takes an average as the aggregation result. <span id="S4.SS1.SSS5.p1.9.2" class="ltx_text ltx_font_bold">(2)</span> Norm-clipping: Norm-clipping clips the model update so as not to exceed the given threshold <math id="S4.SS1.SSS5.p1.2.m2.1" class="ltx_Math" alttext="c" display="inline"><semantics id="S4.SS1.SSS5.p1.2.m2.1a"><mi id="S4.SS1.SSS5.p1.2.m2.1.1" xref="S4.SS1.SSS5.p1.2.m2.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS5.p1.2.m2.1b"><ci id="S4.SS1.SSS5.p1.2.m2.1.1.cmml" xref="S4.SS1.SSS5.p1.2.m2.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS5.p1.2.m2.1c">c</annotation></semantics></math> before aggregation. We set <math id="S4.SS1.SSS5.p1.3.m3.1" class="ltx_Math" alttext="c=1" display="inline"><semantics id="S4.SS1.SSS5.p1.3.m3.1a"><mrow id="S4.SS1.SSS5.p1.3.m3.1.1" xref="S4.SS1.SSS5.p1.3.m3.1.1.cmml"><mi id="S4.SS1.SSS5.p1.3.m3.1.1.2" xref="S4.SS1.SSS5.p1.3.m3.1.1.2.cmml">c</mi><mo id="S4.SS1.SSS5.p1.3.m3.1.1.1" xref="S4.SS1.SSS5.p1.3.m3.1.1.1.cmml">=</mo><mn id="S4.SS1.SSS5.p1.3.m3.1.1.3" xref="S4.SS1.SSS5.p1.3.m3.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS5.p1.3.m3.1b"><apply id="S4.SS1.SSS5.p1.3.m3.1.1.cmml" xref="S4.SS1.SSS5.p1.3.m3.1.1"><eq id="S4.SS1.SSS5.p1.3.m3.1.1.1.cmml" xref="S4.SS1.SSS5.p1.3.m3.1.1.1"></eq><ci id="S4.SS1.SSS5.p1.3.m3.1.1.2.cmml" xref="S4.SS1.SSS5.p1.3.m3.1.1.2">ğ‘</ci><cn type="integer" id="S4.SS1.SSS5.p1.3.m3.1.1.3.cmml" xref="S4.SS1.SSS5.p1.3.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS5.p1.3.m3.1c">c=1</annotation></semantics></math> and <math id="S4.SS1.SSS5.p1.4.m4.1" class="ltx_Math" alttext="c=0.5" display="inline"><semantics id="S4.SS1.SSS5.p1.4.m4.1a"><mrow id="S4.SS1.SSS5.p1.4.m4.1.1" xref="S4.SS1.SSS5.p1.4.m4.1.1.cmml"><mi id="S4.SS1.SSS5.p1.4.m4.1.1.2" xref="S4.SS1.SSS5.p1.4.m4.1.1.2.cmml">c</mi><mo id="S4.SS1.SSS5.p1.4.m4.1.1.1" xref="S4.SS1.SSS5.p1.4.m4.1.1.1.cmml">=</mo><mn id="S4.SS1.SSS5.p1.4.m4.1.1.3" xref="S4.SS1.SSS5.p1.4.m4.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS5.p1.4.m4.1b"><apply id="S4.SS1.SSS5.p1.4.m4.1.1.cmml" xref="S4.SS1.SSS5.p1.4.m4.1.1"><eq id="S4.SS1.SSS5.p1.4.m4.1.1.1.cmml" xref="S4.SS1.SSS5.p1.4.m4.1.1.1"></eq><ci id="S4.SS1.SSS5.p1.4.m4.1.1.2.cmml" xref="S4.SS1.SSS5.p1.4.m4.1.1.2">ğ‘</ci><cn type="float" id="S4.SS1.SSS5.p1.4.m4.1.1.3.cmml" xref="S4.SS1.SSS5.p1.4.m4.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS5.p1.4.m4.1c">c=0.5</annotation></semantics></math> followingÂ <cite class="ltx_cite ltx_citemacro_citep">(Zhang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib62" title="" class="ltx_ref">2022a</a>)</cite>, where a smaller <math id="S4.SS1.SSS5.p1.5.m5.1" class="ltx_Math" alttext="c" display="inline"><semantics id="S4.SS1.SSS5.p1.5.m5.1a"><mi id="S4.SS1.SSS5.p1.5.m5.1.1" xref="S4.SS1.SSS5.p1.5.m5.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS5.p1.5.m5.1b"><ci id="S4.SS1.SSS5.p1.5.m5.1.1.cmml" xref="S4.SS1.SSS5.p1.5.m5.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS5.p1.5.m5.1c">c</annotation></semantics></math> means the smaller contribution to model aggregation from local model update. <span id="S4.SS1.SSS5.p1.9.3" class="ltx_text ltx_font_bold">(3)</span> Adding noise method adds Gaussian noises <math id="S4.SS1.SSS5.p1.6.m6.1" class="ltx_Math" alttext="\lambda*\bm{v}" display="inline"><semantics id="S4.SS1.SSS5.p1.6.m6.1a"><mrow id="S4.SS1.SSS5.p1.6.m6.1.1" xref="S4.SS1.SSS5.p1.6.m6.1.1.cmml"><mi id="S4.SS1.SSS5.p1.6.m6.1.1.2" xref="S4.SS1.SSS5.p1.6.m6.1.1.2.cmml">Î»</mi><mo lspace="0.222em" rspace="0.222em" id="S4.SS1.SSS5.p1.6.m6.1.1.1" xref="S4.SS1.SSS5.p1.6.m6.1.1.1.cmml">âˆ—</mo><mi id="S4.SS1.SSS5.p1.6.m6.1.1.3" xref="S4.SS1.SSS5.p1.6.m6.1.1.3.cmml">ğ’—</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS5.p1.6.m6.1b"><apply id="S4.SS1.SSS5.p1.6.m6.1.1.cmml" xref="S4.SS1.SSS5.p1.6.m6.1.1"><times id="S4.SS1.SSS5.p1.6.m6.1.1.1.cmml" xref="S4.SS1.SSS5.p1.6.m6.1.1.1"></times><ci id="S4.SS1.SSS5.p1.6.m6.1.1.2.cmml" xref="S4.SS1.SSS5.p1.6.m6.1.1.2">ğœ†</ci><ci id="S4.SS1.SSS5.p1.6.m6.1.1.3.cmml" xref="S4.SS1.SSS5.p1.6.m6.1.1.3">ğ’—</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS5.p1.6.m6.1c">\lambda*\bm{v}</annotation></semantics></math> to model updates from clients. <math id="S4.SS1.SSS5.p1.7.m7.1" class="ltx_Math" alttext="\bm{v}" display="inline"><semantics id="S4.SS1.SSS5.p1.7.m7.1a"><mi id="S4.SS1.SSS5.p1.7.m7.1.1" xref="S4.SS1.SSS5.p1.7.m7.1.1.cmml">ğ’—</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS5.p1.7.m7.1b"><ci id="S4.SS1.SSS5.p1.7.m7.1.1.cmml" xref="S4.SS1.SSS5.p1.7.m7.1.1">ğ’—</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS5.p1.7.m7.1c">\bm{v}</annotation></semantics></math> is sampled from normal distribution. We try a series of noise scales <math id="S4.SS1.SSS5.p1.8.m8.2" class="ltx_Math" alttext="\sigma=10^{-3},5*10^{-4}" display="inline"><semantics id="S4.SS1.SSS5.p1.8.m8.2a"><mrow id="S4.SS1.SSS5.p1.8.m8.2.2" xref="S4.SS1.SSS5.p1.8.m8.2.2.cmml"><mi id="S4.SS1.SSS5.p1.8.m8.2.2.4" xref="S4.SS1.SSS5.p1.8.m8.2.2.4.cmml">Ïƒ</mi><mo id="S4.SS1.SSS5.p1.8.m8.2.2.3" xref="S4.SS1.SSS5.p1.8.m8.2.2.3.cmml">=</mo><mrow id="S4.SS1.SSS5.p1.8.m8.2.2.2.2" xref="S4.SS1.SSS5.p1.8.m8.2.2.2.3.cmml"><msup id="S4.SS1.SSS5.p1.8.m8.1.1.1.1.1" xref="S4.SS1.SSS5.p1.8.m8.1.1.1.1.1.cmml"><mn id="S4.SS1.SSS5.p1.8.m8.1.1.1.1.1.2" xref="S4.SS1.SSS5.p1.8.m8.1.1.1.1.1.2.cmml">10</mn><mrow id="S4.SS1.SSS5.p1.8.m8.1.1.1.1.1.3" xref="S4.SS1.SSS5.p1.8.m8.1.1.1.1.1.3.cmml"><mo id="S4.SS1.SSS5.p1.8.m8.1.1.1.1.1.3a" xref="S4.SS1.SSS5.p1.8.m8.1.1.1.1.1.3.cmml">âˆ’</mo><mn id="S4.SS1.SSS5.p1.8.m8.1.1.1.1.1.3.2" xref="S4.SS1.SSS5.p1.8.m8.1.1.1.1.1.3.2.cmml">3</mn></mrow></msup><mo id="S4.SS1.SSS5.p1.8.m8.2.2.2.2.3" xref="S4.SS1.SSS5.p1.8.m8.2.2.2.3.cmml">,</mo><mrow id="S4.SS1.SSS5.p1.8.m8.2.2.2.2.2" xref="S4.SS1.SSS5.p1.8.m8.2.2.2.2.2.cmml"><mn id="S4.SS1.SSS5.p1.8.m8.2.2.2.2.2.2" xref="S4.SS1.SSS5.p1.8.m8.2.2.2.2.2.2.cmml">5</mn><mo lspace="0.222em" rspace="0.222em" id="S4.SS1.SSS5.p1.8.m8.2.2.2.2.2.1" xref="S4.SS1.SSS5.p1.8.m8.2.2.2.2.2.1.cmml">âˆ—</mo><msup id="S4.SS1.SSS5.p1.8.m8.2.2.2.2.2.3" xref="S4.SS1.SSS5.p1.8.m8.2.2.2.2.2.3.cmml"><mn id="S4.SS1.SSS5.p1.8.m8.2.2.2.2.2.3.2" xref="S4.SS1.SSS5.p1.8.m8.2.2.2.2.2.3.2.cmml">10</mn><mrow id="S4.SS1.SSS5.p1.8.m8.2.2.2.2.2.3.3" xref="S4.SS1.SSS5.p1.8.m8.2.2.2.2.2.3.3.cmml"><mo id="S4.SS1.SSS5.p1.8.m8.2.2.2.2.2.3.3a" xref="S4.SS1.SSS5.p1.8.m8.2.2.2.2.2.3.3.cmml">âˆ’</mo><mn id="S4.SS1.SSS5.p1.8.m8.2.2.2.2.2.3.3.2" xref="S4.SS1.SSS5.p1.8.m8.2.2.2.2.2.3.3.2.cmml">4</mn></mrow></msup></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS5.p1.8.m8.2b"><apply id="S4.SS1.SSS5.p1.8.m8.2.2.cmml" xref="S4.SS1.SSS5.p1.8.m8.2.2"><eq id="S4.SS1.SSS5.p1.8.m8.2.2.3.cmml" xref="S4.SS1.SSS5.p1.8.m8.2.2.3"></eq><ci id="S4.SS1.SSS5.p1.8.m8.2.2.4.cmml" xref="S4.SS1.SSS5.p1.8.m8.2.2.4">ğœ</ci><list id="S4.SS1.SSS5.p1.8.m8.2.2.2.3.cmml" xref="S4.SS1.SSS5.p1.8.m8.2.2.2.2"><apply id="S4.SS1.SSS5.p1.8.m8.1.1.1.1.1.cmml" xref="S4.SS1.SSS5.p1.8.m8.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS5.p1.8.m8.1.1.1.1.1.1.cmml" xref="S4.SS1.SSS5.p1.8.m8.1.1.1.1.1">superscript</csymbol><cn type="integer" id="S4.SS1.SSS5.p1.8.m8.1.1.1.1.1.2.cmml" xref="S4.SS1.SSS5.p1.8.m8.1.1.1.1.1.2">10</cn><apply id="S4.SS1.SSS5.p1.8.m8.1.1.1.1.1.3.cmml" xref="S4.SS1.SSS5.p1.8.m8.1.1.1.1.1.3"><minus id="S4.SS1.SSS5.p1.8.m8.1.1.1.1.1.3.1.cmml" xref="S4.SS1.SSS5.p1.8.m8.1.1.1.1.1.3"></minus><cn type="integer" id="S4.SS1.SSS5.p1.8.m8.1.1.1.1.1.3.2.cmml" xref="S4.SS1.SSS5.p1.8.m8.1.1.1.1.1.3.2">3</cn></apply></apply><apply id="S4.SS1.SSS5.p1.8.m8.2.2.2.2.2.cmml" xref="S4.SS1.SSS5.p1.8.m8.2.2.2.2.2"><times id="S4.SS1.SSS5.p1.8.m8.2.2.2.2.2.1.cmml" xref="S4.SS1.SSS5.p1.8.m8.2.2.2.2.2.1"></times><cn type="integer" id="S4.SS1.SSS5.p1.8.m8.2.2.2.2.2.2.cmml" xref="S4.SS1.SSS5.p1.8.m8.2.2.2.2.2.2">5</cn><apply id="S4.SS1.SSS5.p1.8.m8.2.2.2.2.2.3.cmml" xref="S4.SS1.SSS5.p1.8.m8.2.2.2.2.2.3"><csymbol cd="ambiguous" id="S4.SS1.SSS5.p1.8.m8.2.2.2.2.2.3.1.cmml" xref="S4.SS1.SSS5.p1.8.m8.2.2.2.2.2.3">superscript</csymbol><cn type="integer" id="S4.SS1.SSS5.p1.8.m8.2.2.2.2.2.3.2.cmml" xref="S4.SS1.SSS5.p1.8.m8.2.2.2.2.2.3.2">10</cn><apply id="S4.SS1.SSS5.p1.8.m8.2.2.2.2.2.3.3.cmml" xref="S4.SS1.SSS5.p1.8.m8.2.2.2.2.2.3.3"><minus id="S4.SS1.SSS5.p1.8.m8.2.2.2.2.2.3.3.1.cmml" xref="S4.SS1.SSS5.p1.8.m8.2.2.2.2.2.3.3"></minus><cn type="integer" id="S4.SS1.SSS5.p1.8.m8.2.2.2.2.2.3.3.2.cmml" xref="S4.SS1.SSS5.p1.8.m8.2.2.2.2.2.3.3.2">4</cn></apply></apply></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS5.p1.8.m8.2c">\sigma=10^{-3},5*10^{-4}</annotation></semantics></math>, and <math id="S4.SS1.SSS5.p1.9.m9.1" class="ltx_Math" alttext="10^{-4}" display="inline"><semantics id="S4.SS1.SSS5.p1.9.m9.1a"><msup id="S4.SS1.SSS5.p1.9.m9.1.1" xref="S4.SS1.SSS5.p1.9.m9.1.1.cmml"><mn id="S4.SS1.SSS5.p1.9.m9.1.1.2" xref="S4.SS1.SSS5.p1.9.m9.1.1.2.cmml">10</mn><mrow id="S4.SS1.SSS5.p1.9.m9.1.1.3" xref="S4.SS1.SSS5.p1.9.m9.1.1.3.cmml"><mo id="S4.SS1.SSS5.p1.9.m9.1.1.3a" xref="S4.SS1.SSS5.p1.9.m9.1.1.3.cmml">âˆ’</mo><mn id="S4.SS1.SSS5.p1.9.m9.1.1.3.2" xref="S4.SS1.SSS5.p1.9.m9.1.1.3.2.cmml">4</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS5.p1.9.m9.1b"><apply id="S4.SS1.SSS5.p1.9.m9.1.1.cmml" xref="S4.SS1.SSS5.p1.9.m9.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS5.p1.9.m9.1.1.1.cmml" xref="S4.SS1.SSS5.p1.9.m9.1.1">superscript</csymbol><cn type="integer" id="S4.SS1.SSS5.p1.9.m9.1.1.2.cmml" xref="S4.SS1.SSS5.p1.9.m9.1.1.2">10</cn><apply id="S4.SS1.SSS5.p1.9.m9.1.1.3.cmml" xref="S4.SS1.SSS5.p1.9.m9.1.1.3"><minus id="S4.SS1.SSS5.p1.9.m9.1.1.3.1.cmml" xref="S4.SS1.SSS5.p1.9.m9.1.1.3"></minus><cn type="integer" id="S4.SS1.SSS5.p1.9.m9.1.1.3.2.cmml" xref="S4.SS1.SSS5.p1.9.m9.1.1.3.2">4</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS5.p1.9.m9.1c">10^{-4}</annotation></semantics></math>. We implement them based on source code <span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a target="_blank" href="https://github.com/ksreenivasan/OOD_Federated_Learning" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/ksreenivasan/OOD_Federated_Learning</a></span></span></span> ofÂ <cite class="ltx_cite ltx_citemacro_citep">(Wang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib54" title="" class="ltx_ref">2020</a>)</cite>.</p>
</div>
</section>
<section id="S4.SS1.SSS6" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.6. </span>Evaluation Details.</h4>

<div id="S4.SS1.SSS6.p1" class="ltx_para">
<p id="S4.SS1.SSS6.p1.3" class="ltx_p">We take two evaluation metrics, including <span id="S4.SS1.SSS6.p1.3.1" class="ltx_text ltx_font_italic">Clean Accuracy (C-Acc)</span> (i.e., the prediction accuracy of clean samples) and <span id="S4.SS1.SSS6.p1.3.2" class="ltx_text ltx_font_italic">Attack Success Rate (ASR)</span> (i.e., the prediction accuracy of poisoned samples to the target class). We test C-Accs on all clientsâ€™ testing dataset using their own pFL models. For edge-case attack, we followÂ <cite class="ltx_cite ltx_citemacro_citep">(Wang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib54" title="" class="ltx_ref">2020</a>)</cite> to test ASR on <math id="S4.SS1.SSS6.p1.1.m1.1" class="ltx_Math" alttext="100" display="inline"><semantics id="S4.SS1.SSS6.p1.1.m1.1a"><mn id="S4.SS1.SSS6.p1.1.m1.1.1" xref="S4.SS1.SSS6.p1.1.m1.1.1.cmml">100</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS6.p1.1.m1.1b"><cn type="integer" id="S4.SS1.SSS6.p1.1.m1.1.1.cmml" xref="S4.SS1.SSS6.p1.1.m1.1.1">100</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS6.p1.1.m1.1c">100</annotation></semantics></math> edge-case images on FEMNIST and <math id="S4.SS1.SSS6.p1.2.m2.1" class="ltx_Math" alttext="196" display="inline"><semantics id="S4.SS1.SSS6.p1.2.m2.1a"><mn id="S4.SS1.SSS6.p1.2.m2.1.1" xref="S4.SS1.SSS6.p1.2.m2.1.1.cmml">196</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS6.p1.2.m2.1b"><cn type="integer" id="S4.SS1.SSS6.p1.2.m2.1.1.cmml" xref="S4.SS1.SSS6.p1.2.m2.1.1">196</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS6.p1.2.m2.1c">196</annotation></semantics></math> edge-case images on CIFAR-10, respectively. For BadNet, Blended, and SIG attacks, we test ASR on testing sets of all clients except the selected adversarial client. All experiments are conducted with <math id="S4.SS1.SSS6.p1.3.m3.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S4.SS1.SSS6.p1.3.m3.1a"><mn id="S4.SS1.SSS6.p1.3.m3.1.1" xref="S4.SS1.SSS6.p1.3.m3.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS6.p1.3.m3.1b"><cn type="integer" id="S4.SS1.SSS6.p1.3.m3.1.1.cmml" xref="S4.SS1.SSS6.p1.3.m3.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS6.p1.3.m3.1c">3</annotation></semantics></math> times over different random seeds, and we report the average through experiments.</p>
</div>
</section>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2. </span>The Overall Robustness Evaluation </h3>

<figure id="S4.F2" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F2.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2302.01677/assets/x2.png" id="S4.F2.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="123" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F2.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S4.F2.sf1.3.2" class="ltx_text" style="font-size:90%;">ResNet-18@CIFAR-10</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F2.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2302.01677/assets/x3.png" id="S4.F2.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="125" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F2.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S4.F2.sf2.3.2" class="ltx_text" style="font-size:90%;">ConvNet@CIFAR-10</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F2.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2302.01677/assets/x4.png" id="S4.F2.sf3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="122" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F2.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="S4.F2.sf3.3.2" class="ltx_text" style="font-size:90%;">ConvNet@FEMNIST</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F2.2.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>. </span><span id="S4.F2.3.2" class="ltx_text" style="font-size:90%;">Comparison of backdoor attacks on different pFL methods. (a): Results on ResNet-18 and CIFAR-10; (b) Results on ConvNet and CIFAR-10; (c) Results on ConvNet and FEMNIST. In each figure, the value of horizontal or vertical axis is the number of training rounds or attack success rate, respectively. The solid line means ASR, and the dashed line means the C-Acc.</span></figcaption>
</figure>
<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">In FigureÂ <a href="#S4.F2" title="Figure 2 â€£ 4.2. The Overall Robustness Evaluation â€£ 4. Robustness of pFL methods against Backdoor Attacks â€£ Revisiting Personalized Federated Learning: Robustness Against Backdoor Attacks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, we show performance curves of backdoor attacks on pFL methods under Non-IID data distribution. Due to the space limitation, the results of IID setting are deferred in Section <a href="#A3" title="Appendix A3 Detailed Experimental Results â€£ Revisiting Personalized Federated Learning: Robustness Against Backdoor Attacks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A3</span></a> of <span id="S4.SS2.p1.1.1" class="ltx_text ltx_markedasmath ltx_font_italic">Appendix</span>. There are three subfigures: results on ResNet-18 and CIFAR-10, results on ConvNet and CIFAR-10, and results on ConvNet and FEMNIST. In each subfigure, we first demonstrate the backdoor attack success rate (ASR) and then the original taskâ€™s clean accuracy (C-Acc). Each column represents different FL and pFL methods. The solid line represents ASR, and the dashed line represents the C-Acc.</p>
</div>
<section id="S4.SS2.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_font_bold ltx_title_paragraph">Black-box backdoor attacks achieve good attack performance.</h5>

<div id="S4.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS2.SSS0.Px1.p1.1" class="ltx_p">We first look at how black-box backdoor attacks perform on pFL methods. From FigureÂ <a href="#S4.F2" title="Figure 2 â€£ 4.2. The Overall Robustness Evaluation â€£ 4. Robustness of pFL methods against Backdoor Attacks â€£ Revisiting Personalized Federated Learning: Robustness Against Backdoor Attacks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, we first observe that even without requiring access to the FL training process, simple black-box backdoor attacks especially BadNet and Blended attacks achieve outstanding performance. This shows that practical black-box backdoor attacks are non-negligible threats. And, for all pFL methods, backdoor attacks do not affect C-Acc. As shown in each subfigure, different color dash lines almost overlap with the grey dash line (clean accuracy without attacks). It also reflects the stealthiness of black-box backdoor attacks that behave normally on samples without triggers. Then, among these four attack methods, Blended attack (the solid red line) achieves the best attack performance on CIFAR-10 dataset with over <math id="S4.SS2.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="90\%" display="inline"><semantics id="S4.SS2.SSS0.Px1.p1.1.m1.1a"><mrow id="S4.SS2.SSS0.Px1.p1.1.m1.1.1" xref="S4.SS2.SSS0.Px1.p1.1.m1.1.1.cmml"><mn id="S4.SS2.SSS0.Px1.p1.1.m1.1.1.2" xref="S4.SS2.SSS0.Px1.p1.1.m1.1.1.2.cmml">90</mn><mo id="S4.SS2.SSS0.Px1.p1.1.m1.1.1.1" xref="S4.SS2.SSS0.Px1.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px1.p1.1.m1.1b"><apply id="S4.SS2.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S4.SS2.SSS0.Px1.p1.1.m1.1.1"><csymbol cd="latexml" id="S4.SS2.SSS0.Px1.p1.1.m1.1.1.1.cmml" xref="S4.SS2.SSS0.Px1.p1.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S4.SS2.SSS0.Px1.p1.1.m1.1.1.2.cmml" xref="S4.SS2.SSS0.Px1.p1.1.m1.1.1.2">90</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px1.p1.1.m1.1c">90\%</annotation></semantics></math> ASR on two models.
On FEMNIST, BadNet attack achieves the best attack performance, followed by Blended attack.</p>
</div>
</section>
<section id="S4.SS2.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_font_bold ltx_title_paragraph">pFL methods with partial model-sharing effectively alleviate backdoor attacks</h5>

<div id="S4.SS2.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS2.SSS0.Px2.p1.3" class="ltx_p">Next, we can clearly observe that pFL methods with partial model-sharing (last two columns), FedRep and FedBN, show outstanding robustness against backdoor attacks. FedRep shows the best defense performance against attacks and can limit the success rate of Blended attack and other attacks below <math id="S4.SS2.SSS0.Px2.p1.1.m1.1" class="ltx_Math" alttext="20\%" display="inline"><semantics id="S4.SS2.SSS0.Px2.p1.1.m1.1a"><mrow id="S4.SS2.SSS0.Px2.p1.1.m1.1.1" xref="S4.SS2.SSS0.Px2.p1.1.m1.1.1.cmml"><mn id="S4.SS2.SSS0.Px2.p1.1.m1.1.1.2" xref="S4.SS2.SSS0.Px2.p1.1.m1.1.1.2.cmml">20</mn><mo id="S4.SS2.SSS0.Px2.p1.1.m1.1.1.1" xref="S4.SS2.SSS0.Px2.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px2.p1.1.m1.1b"><apply id="S4.SS2.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S4.SS2.SSS0.Px2.p1.1.m1.1.1"><csymbol cd="latexml" id="S4.SS2.SSS0.Px2.p1.1.m1.1.1.1.cmml" xref="S4.SS2.SSS0.Px2.p1.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S4.SS2.SSS0.Px2.p1.1.m1.1.1.2.cmml" xref="S4.SS2.SSS0.Px2.p1.1.m1.1.1.2">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px2.p1.1.m1.1c">20\%</annotation></semantics></math> and <math id="S4.SS2.SSS0.Px2.p1.2.m2.1" class="ltx_Math" alttext="10\%" display="inline"><semantics id="S4.SS2.SSS0.Px2.p1.2.m2.1a"><mrow id="S4.SS2.SSS0.Px2.p1.2.m2.1.1" xref="S4.SS2.SSS0.Px2.p1.2.m2.1.1.cmml"><mn id="S4.SS2.SSS0.Px2.p1.2.m2.1.1.2" xref="S4.SS2.SSS0.Px2.p1.2.m2.1.1.2.cmml">10</mn><mo id="S4.SS2.SSS0.Px2.p1.2.m2.1.1.1" xref="S4.SS2.SSS0.Px2.p1.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px2.p1.2.m2.1b"><apply id="S4.SS2.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S4.SS2.SSS0.Px2.p1.2.m2.1.1"><csymbol cd="latexml" id="S4.SS2.SSS0.Px2.p1.2.m2.1.1.1.cmml" xref="S4.SS2.SSS0.Px2.p1.2.m2.1.1.1">percent</csymbol><cn type="integer" id="S4.SS2.SSS0.Px2.p1.2.m2.1.1.2.cmml" xref="S4.SS2.SSS0.Px2.p1.2.m2.1.1.2">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px2.p1.2.m2.1c">10\%</annotation></semantics></math>. FedBN achieves the second-best defense performance on CIFAR-10 dataset and reduces ASR of four attacks below <math id="S4.SS2.SSS0.Px2.p1.3.m3.1" class="ltx_Math" alttext="20\%" display="inline"><semantics id="S4.SS2.SSS0.Px2.p1.3.m3.1a"><mrow id="S4.SS2.SSS0.Px2.p1.3.m3.1.1" xref="S4.SS2.SSS0.Px2.p1.3.m3.1.1.cmml"><mn id="S4.SS2.SSS0.Px2.p1.3.m3.1.1.2" xref="S4.SS2.SSS0.Px2.p1.3.m3.1.1.2.cmml">20</mn><mo id="S4.SS2.SSS0.Px2.p1.3.m3.1.1.1" xref="S4.SS2.SSS0.Px2.p1.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px2.p1.3.m3.1b"><apply id="S4.SS2.SSS0.Px2.p1.3.m3.1.1.cmml" xref="S4.SS2.SSS0.Px2.p1.3.m3.1.1"><csymbol cd="latexml" id="S4.SS2.SSS0.Px2.p1.3.m3.1.1.1.cmml" xref="S4.SS2.SSS0.Px2.p1.3.m3.1.1.1">percent</csymbol><cn type="integer" id="S4.SS2.SSS0.Px2.p1.3.m3.1.1.2.cmml" xref="S4.SS2.SSS0.Px2.p1.3.m3.1.1.2">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px2.p1.3.m3.1c">20\%</annotation></semantics></math> on the larger model, ResNet-18. These positive results demonstrate that <span id="S4.SS2.SSS0.Px2.p1.3.1" class="ltx_text ltx_font_bold">apart from improving prediction accuracy, some pFL methods (partial model-sharing) also bring better robustness against backdoor attacks.</span></p>
</div>
</section>
<section id="S4.SS2.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_font_bold ltx_title_paragraph">The degree of personalization is a key factor to robustness
benefits.</h5>

<div id="S4.SS2.SSS0.Px3.p1" class="ltx_para">
<p id="S4.SS2.SSS0.Px3.p1.1" class="ltx_p">Across columns, we observe that pFL methods with partial model-sharing significantly improve defense performance, but all pFL methods with full model-sharing (from the 2nd to 5th column) do not show improvement in the robustness against backdoor attacks except for pFedMe method. These observations suggest a strong positive correlation between robustness against backdoor attacks and the larger personalization degree of pFL methods. In SectionÂ <a href="#S5" title="5. Analysis of Various Robustness from pFL Against Backdoor Attacks â€£ Revisiting Personalized Federated Learning: Robustness Against Backdoor Attacks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, we will deeply investigate why different model-sharing degrees lead to various defensive effects and show that pfedMe is also vulnerable to backdoor attacks like other full model-sharing methods.</p>
</div>
<div id="S4.SS2.SSS0.Px3.p2" class="ltx_para">
<p id="S4.SS2.SSS0.Px3.p2.1" class="ltx_p">Besides, comparing results of two different models on CIFAR-10 dataset, we could observe that backdoor attacks achieve better attack performance on high-capacity model (ResNet-18) than on the low-capacity model (ConvNet), which indicates that larger models may be more vulnerable to be injected with backdoor triggers in FL. The similar trend is also observed inÂ <cite class="ltx_cite ltx_citemacro_citep">(Wang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib54" title="" class="ltx_ref">2020</a>; Wu etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib55" title="" class="ltx_ref">2022a</a>)</cite>.</p>
</div>
</section>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3. </span>The Robustness Evaluation of Baseline Defense Methods</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">To further compare the robustness brought by pFL methods, we also conduct experiments to evaluate defense performance of some widely used defense strategies in FL. We adopt four defense methods: norm-clipping, adding noise, Krum, and Multi-Krum. The hyperparameters have been outlined in Section <a href="#S4.SS1" title="4.1. Experimental Settings â€£ 4. Robustness of pFL methods against Backdoor Attacks â€£ Revisiting Personalized Federated Learning: Robustness Against Backdoor Attacks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>. InÂ <cite class="ltx_cite ltx_citemacro_citep">(Wang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib54" title="" class="ltx_ref">2020</a>)</cite>, these four defense methods, especially Krum and Multi-Krum, show robustness against edge-case attack. Here, we implement these defense methods followingÂ <cite class="ltx_cite ltx_citemacro_citep">(Wang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib54" title="" class="ltx_ref">2020</a>)</cite> and test them on the Blended attack which behaves better performance in the above studies. We still adopt the Non-IID setting and choose the FedAvg training method. The final epochâ€™s ASR and C-Acc are shown in FigureÂ <a href="#S4.F3" title="Figure 3 â€£ 4.3. The Robustness Evaluation of Baseline Defense Methods â€£ 4. Robustness of pFL methods against Backdoor Attacks â€£ Revisiting Personalized Federated Learning: Robustness Against Backdoor Attacks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.5" class="ltx_p">We first observe the defense performance of the simple norm clipping (NC) method. NC with <math id="S4.SS3.p2.1.m1.1" class="ltx_Math" alttext="c=1" display="inline"><semantics id="S4.SS3.p2.1.m1.1a"><mrow id="S4.SS3.p2.1.m1.1.1" xref="S4.SS3.p2.1.m1.1.1.cmml"><mi id="S4.SS3.p2.1.m1.1.1.2" xref="S4.SS3.p2.1.m1.1.1.2.cmml">c</mi><mo id="S4.SS3.p2.1.m1.1.1.1" xref="S4.SS3.p2.1.m1.1.1.1.cmml">=</mo><mn id="S4.SS3.p2.1.m1.1.1.3" xref="S4.SS3.p2.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.1.m1.1b"><apply id="S4.SS3.p2.1.m1.1.1.cmml" xref="S4.SS3.p2.1.m1.1.1"><eq id="S4.SS3.p2.1.m1.1.1.1.cmml" xref="S4.SS3.p2.1.m1.1.1.1"></eq><ci id="S4.SS3.p2.1.m1.1.1.2.cmml" xref="S4.SS3.p2.1.m1.1.1.2">ğ‘</ci><cn type="integer" id="S4.SS3.p2.1.m1.1.1.3.cmml" xref="S4.SS3.p2.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.1.m1.1c">c=1</annotation></semantics></math> used inÂ <cite class="ltx_cite ltx_citemacro_citep">(Wang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib54" title="" class="ltx_ref">2020</a>)</cite> couldnâ€™t bring any robustness improvement against the Blended attack. We further reduce the norm constrain of NC on local update to <math id="S4.SS3.p2.2.m2.1" class="ltx_Math" alttext="0.5" display="inline"><semantics id="S4.SS3.p2.2.m2.1a"><mn id="S4.SS3.p2.2.m2.1.1" xref="S4.SS3.p2.2.m2.1.1.cmml">0.5</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.2.m2.1b"><cn type="float" id="S4.SS3.p2.2.m2.1.1.cmml" xref="S4.SS3.p2.2.m2.1.1">0.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.2.m2.1c">0.5</annotation></semantics></math>. While reducing ASR of Blended attack, it also causes a significant drop on C-Acc. Like norm clipping, with increased strength of added noise <math id="S4.SS3.p2.3.m3.1" class="ltx_Math" alttext="\sigma" display="inline"><semantics id="S4.SS3.p2.3.m3.1a"><mi id="S4.SS3.p2.3.m3.1.1" xref="S4.SS3.p2.3.m3.1.1.cmml">Ïƒ</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.3.m3.1b"><ci id="S4.SS3.p2.3.m3.1.1.cmml" xref="S4.SS3.p2.3.m3.1.1">ğœ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.3.m3.1c">\sigma</annotation></semantics></math>, AD significantly reduces the ASR of Blended attack. However, it also leads to a significant drop of C-Acc. Similar to performance on the edge-case attack, Krum also improves the robustness against Blended attack. However, since only one model would be selected in every aggregation, the C-Acc also experiences a significant drop. Rather than only selecting one model update as the result of aggregation, Multi-Krum selects top-<math id="S4.SS3.p2.4.m4.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S4.SS3.p2.4.m4.1a"><mi id="S4.SS3.p2.4.m4.1.1" xref="S4.SS3.p2.4.m4.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.4.m4.1b"><ci id="S4.SS3.p2.4.m4.1.1.cmml" xref="S4.SS3.p2.4.m4.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.4.m4.1c">k</annotation></semantics></math> (<math id="S4.SS3.p2.5.m5.1" class="ltx_Math" alttext="k=7" display="inline"><semantics id="S4.SS3.p2.5.m5.1a"><mrow id="S4.SS3.p2.5.m5.1.1" xref="S4.SS3.p2.5.m5.1.1.cmml"><mi id="S4.SS3.p2.5.m5.1.1.2" xref="S4.SS3.p2.5.m5.1.1.2.cmml">k</mi><mo id="S4.SS3.p2.5.m5.1.1.1" xref="S4.SS3.p2.5.m5.1.1.1.cmml">=</mo><mn id="S4.SS3.p2.5.m5.1.1.3" xref="S4.SS3.p2.5.m5.1.1.3.cmml">7</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.5.m5.1b"><apply id="S4.SS3.p2.5.m5.1.1.cmml" xref="S4.SS3.p2.5.m5.1.1"><eq id="S4.SS3.p2.5.m5.1.1.1.cmml" xref="S4.SS3.p2.5.m5.1.1.1"></eq><ci id="S4.SS3.p2.5.m5.1.1.2.cmml" xref="S4.SS3.p2.5.m5.1.1.2">ğ‘˜</ci><cn type="integer" id="S4.SS3.p2.5.m5.1.1.3.cmml" xref="S4.SS3.p2.5.m5.1.1.3">7</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.5.m5.1c">k=7</annotation></semantics></math>) model updates and then averages updates in the aggregation. Although Multi-Krum achieves better C-Acc, it fails to defend against Blended attack. Although NC, AD, and, Krum show different robustness improvements against Blended attack, <span id="S4.SS3.p2.5.1" class="ltx_text ltx_font_bold">they all face a serious trade-off between robustness and clean accuracy</span>.</p>
</div>
<figure id="S4.F3" class="ltx_figure"><img src="/html/2302.01677/assets/x5.png" id="S4.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="216" height="82" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F3.2.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>. </span><span id="S4.F3.3.2" class="ltx_text" style="font-size:90%;">The evaluation of FedAvg with baseline defense methods against Blended attack on ResNet-18. Left: The ASR of Blended attack; Right: The C-Acc of FedAvg with defense strategies.</span></figcaption>
</figure>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5. </span>Analysis of Various Robustness from pFL Against Backdoor Attacks</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In SectionÂ <a href="#S4.SS2" title="4.2. The Overall Robustness Evaluation â€£ 4. Robustness of pFL methods against Backdoor Attacks â€£ Revisiting Personalized Federated Learning: Robustness Against Backdoor Attacks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>, we observe that pFL methods with partial model-sharing, FedRep, and FedBN, gain much better robustness against backdoor attacks than full model-sharing methods. In following sections, we take detailed studies of pFL methods to analyze the reasons behind various robustness from them. We first look at FedBN and FedRep in Section <a href="#S5.SS1" title="5.1. pFL Methods with Partial model-sharing â€£ 5. Analysis of Various Robustness from pFL Against Backdoor Attacks â€£ Revisiting Personalized Federated Learning: Robustness Against Backdoor Attacks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.1</span></a> and then analyze full model-sharing methods in Section
<a href="#S5.SS2" title="5.2. pFL Methods with Full model-sharing â€£ 5. Analysis of Various Robustness from pFL Against Backdoor Attacks â€£ Revisiting Personalized Federated Learning: Robustness Against Backdoor Attacks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.2</span></a>.</p>
</div>
<figure id="S5.F4" class="ltx_figure"><img src="/html/2302.01677/assets/x6.png" id="S5.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="161" height="103" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F4.2.1.1" class="ltx_text" style="font-size:90%;">Figure 4</span>. </span><span id="S5.F4.3.2" class="ltx_text" style="font-size:90%;">The results of Blended attack on FedBN on CIFAR-10 dataset under Non-IID and IID setting. Left: On ResNet-18; Right: On ConvNet.</span></figcaption>
</figure>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1. </span>pFL Methods with Partial model-sharing</h3>

<section id="S5.SS1.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">FedBN</h5>

<div id="S5.SS1.SSS0.Px1.p1" class="ltx_para">
<p id="S5.SS1.SSS0.Px1.p1.10" class="ltx_p">In FedBN, as every client shares all parameters except local BN layers, data heterogeneity among clients leads to differences in local BN layersâ€™ parameters. We think differences in local BN layers across clients block backdoor feature propagation in local models.
For simplicity, each local model could be denoted as a neural network <math id="S5.SS1.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="F_{i}^{(l)}" display="inline"><semantics id="S5.SS1.SSS0.Px1.p1.1.m1.1a"><msubsup id="S5.SS1.SSS0.Px1.p1.1.m1.1.2" xref="S5.SS1.SSS0.Px1.p1.1.m1.1.2.cmml"><mi id="S5.SS1.SSS0.Px1.p1.1.m1.1.2.2.2" xref="S5.SS1.SSS0.Px1.p1.1.m1.1.2.2.2.cmml">F</mi><mi id="S5.SS1.SSS0.Px1.p1.1.m1.1.2.2.3" xref="S5.SS1.SSS0.Px1.p1.1.m1.1.2.2.3.cmml">i</mi><mrow id="S5.SS1.SSS0.Px1.p1.1.m1.1.1.1.3" xref="S5.SS1.SSS0.Px1.p1.1.m1.1.2.cmml"><mo stretchy="false" id="S5.SS1.SSS0.Px1.p1.1.m1.1.1.1.3.1" xref="S5.SS1.SSS0.Px1.p1.1.m1.1.2.cmml">(</mo><mi id="S5.SS1.SSS0.Px1.p1.1.m1.1.1.1.1" xref="S5.SS1.SSS0.Px1.p1.1.m1.1.1.1.1.cmml">l</mi><mo stretchy="false" id="S5.SS1.SSS0.Px1.p1.1.m1.1.1.1.3.2" xref="S5.SS1.SSS0.Px1.p1.1.m1.1.2.cmml">)</mo></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px1.p1.1.m1.1b"><apply id="S5.SS1.SSS0.Px1.p1.1.m1.1.2.cmml" xref="S5.SS1.SSS0.Px1.p1.1.m1.1.2"><csymbol cd="ambiguous" id="S5.SS1.SSS0.Px1.p1.1.m1.1.2.1.cmml" xref="S5.SS1.SSS0.Px1.p1.1.m1.1.2">superscript</csymbol><apply id="S5.SS1.SSS0.Px1.p1.1.m1.1.2.2.cmml" xref="S5.SS1.SSS0.Px1.p1.1.m1.1.2"><csymbol cd="ambiguous" id="S5.SS1.SSS0.Px1.p1.1.m1.1.2.2.1.cmml" xref="S5.SS1.SSS0.Px1.p1.1.m1.1.2">subscript</csymbol><ci id="S5.SS1.SSS0.Px1.p1.1.m1.1.2.2.2.cmml" xref="S5.SS1.SSS0.Px1.p1.1.m1.1.2.2.2">ğ¹</ci><ci id="S5.SS1.SSS0.Px1.p1.1.m1.1.2.2.3.cmml" xref="S5.SS1.SSS0.Px1.p1.1.m1.1.2.2.3">ğ‘–</ci></apply><ci id="S5.SS1.SSS0.Px1.p1.1.m1.1.1.1.1.cmml" xref="S5.SS1.SSS0.Px1.p1.1.m1.1.1.1.1">ğ‘™</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px1.p1.1.m1.1c">F_{i}^{(l)}</annotation></semantics></math> with <math id="S5.SS1.SSS0.Px1.p1.2.m2.1" class="ltx_Math" alttext="l" display="inline"><semantics id="S5.SS1.SSS0.Px1.p1.2.m2.1a"><mi id="S5.SS1.SSS0.Px1.p1.2.m2.1.1" xref="S5.SS1.SSS0.Px1.p1.2.m2.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px1.p1.2.m2.1b"><ci id="S5.SS1.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S5.SS1.SSS0.Px1.p1.2.m2.1.1">ğ‘™</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px1.p1.2.m2.1c">l</annotation></semantics></math> layers,
<math id="S5.SS1.SSS0.Px1.p1.3.m3.4" class="ltx_Math" alttext="F_{i}^{(l)}=f^{(l)}\circ\phi_{i}\circ f^{(l-1)}\circ\phi_{i}\circ\cdots\circ f^{(1)}" display="inline"><semantics id="S5.SS1.SSS0.Px1.p1.3.m3.4a"><mrow id="S5.SS1.SSS0.Px1.p1.3.m3.4.5" xref="S5.SS1.SSS0.Px1.p1.3.m3.4.5.cmml"><msubsup id="S5.SS1.SSS0.Px1.p1.3.m3.4.5.2" xref="S5.SS1.SSS0.Px1.p1.3.m3.4.5.2.cmml"><mi id="S5.SS1.SSS0.Px1.p1.3.m3.4.5.2.2.2" xref="S5.SS1.SSS0.Px1.p1.3.m3.4.5.2.2.2.cmml">F</mi><mi id="S5.SS1.SSS0.Px1.p1.3.m3.4.5.2.2.3" xref="S5.SS1.SSS0.Px1.p1.3.m3.4.5.2.2.3.cmml">i</mi><mrow id="S5.SS1.SSS0.Px1.p1.3.m3.1.1.1.3" xref="S5.SS1.SSS0.Px1.p1.3.m3.4.5.2.cmml"><mo stretchy="false" id="S5.SS1.SSS0.Px1.p1.3.m3.1.1.1.3.1" xref="S5.SS1.SSS0.Px1.p1.3.m3.4.5.2.cmml">(</mo><mi id="S5.SS1.SSS0.Px1.p1.3.m3.1.1.1.1" xref="S5.SS1.SSS0.Px1.p1.3.m3.1.1.1.1.cmml">l</mi><mo stretchy="false" id="S5.SS1.SSS0.Px1.p1.3.m3.1.1.1.3.2" xref="S5.SS1.SSS0.Px1.p1.3.m3.4.5.2.cmml">)</mo></mrow></msubsup><mo id="S5.SS1.SSS0.Px1.p1.3.m3.4.5.1" xref="S5.SS1.SSS0.Px1.p1.3.m3.4.5.1.cmml">=</mo><mrow id="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3" xref="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.cmml"><msup id="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.2" xref="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.2.cmml"><mi id="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.2.2" xref="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.2.2.cmml">f</mi><mrow id="S5.SS1.SSS0.Px1.p1.3.m3.2.2.1.3" xref="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.2.cmml"><mo stretchy="false" id="S5.SS1.SSS0.Px1.p1.3.m3.2.2.1.3.1" xref="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.2.cmml">(</mo><mi id="S5.SS1.SSS0.Px1.p1.3.m3.2.2.1.1" xref="S5.SS1.SSS0.Px1.p1.3.m3.2.2.1.1.cmml">l</mi><mo stretchy="false" id="S5.SS1.SSS0.Px1.p1.3.m3.2.2.1.3.2" xref="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.2.cmml">)</mo></mrow></msup><mo lspace="0.222em" rspace="0.222em" id="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.1" xref="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.1.cmml">âˆ˜</mo><msub id="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.3" xref="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.3.cmml"><mi id="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.3.2" xref="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.3.2.cmml">Ï•</mi><mi id="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.3.3" xref="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.3.3.cmml">i</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.1a" xref="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.1.cmml">âˆ˜</mo><msup id="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.4" xref="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.4.cmml"><mi id="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.4.2" xref="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.4.2.cmml">f</mi><mrow id="S5.SS1.SSS0.Px1.p1.3.m3.3.3.1.1" xref="S5.SS1.SSS0.Px1.p1.3.m3.3.3.1.1.1.cmml"><mo stretchy="false" id="S5.SS1.SSS0.Px1.p1.3.m3.3.3.1.1.2" xref="S5.SS1.SSS0.Px1.p1.3.m3.3.3.1.1.1.cmml">(</mo><mrow id="S5.SS1.SSS0.Px1.p1.3.m3.3.3.1.1.1" xref="S5.SS1.SSS0.Px1.p1.3.m3.3.3.1.1.1.cmml"><mi id="S5.SS1.SSS0.Px1.p1.3.m3.3.3.1.1.1.2" xref="S5.SS1.SSS0.Px1.p1.3.m3.3.3.1.1.1.2.cmml">l</mi><mo id="S5.SS1.SSS0.Px1.p1.3.m3.3.3.1.1.1.1" xref="S5.SS1.SSS0.Px1.p1.3.m3.3.3.1.1.1.1.cmml">âˆ’</mo><mn id="S5.SS1.SSS0.Px1.p1.3.m3.3.3.1.1.1.3" xref="S5.SS1.SSS0.Px1.p1.3.m3.3.3.1.1.1.3.cmml">1</mn></mrow><mo stretchy="false" id="S5.SS1.SSS0.Px1.p1.3.m3.3.3.1.1.3" xref="S5.SS1.SSS0.Px1.p1.3.m3.3.3.1.1.1.cmml">)</mo></mrow></msup><mo lspace="0.222em" rspace="0.222em" id="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.1b" xref="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.1.cmml">âˆ˜</mo><msub id="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.5" xref="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.5.cmml"><mi id="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.5.2" xref="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.5.2.cmml">Ï•</mi><mi id="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.5.3" xref="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.5.3.cmml">i</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.1c" xref="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.1.cmml">âˆ˜</mo><mi mathvariant="normal" id="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.6" xref="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.6.cmml">â‹¯</mi><mo lspace="0.222em" rspace="0.222em" id="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.1d" xref="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.1.cmml">âˆ˜</mo><msup id="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.7" xref="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.7.cmml"><mi id="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.7.2" xref="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.7.2.cmml">f</mi><mrow id="S5.SS1.SSS0.Px1.p1.3.m3.4.4.1.3" xref="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.7.cmml"><mo stretchy="false" id="S5.SS1.SSS0.Px1.p1.3.m3.4.4.1.3.1" xref="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.7.cmml">(</mo><mn id="S5.SS1.SSS0.Px1.p1.3.m3.4.4.1.1" xref="S5.SS1.SSS0.Px1.p1.3.m3.4.4.1.1.cmml">1</mn><mo stretchy="false" id="S5.SS1.SSS0.Px1.p1.3.m3.4.4.1.3.2" xref="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.7.cmml">)</mo></mrow></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px1.p1.3.m3.4b"><apply id="S5.SS1.SSS0.Px1.p1.3.m3.4.5.cmml" xref="S5.SS1.SSS0.Px1.p1.3.m3.4.5"><eq id="S5.SS1.SSS0.Px1.p1.3.m3.4.5.1.cmml" xref="S5.SS1.SSS0.Px1.p1.3.m3.4.5.1"></eq><apply id="S5.SS1.SSS0.Px1.p1.3.m3.4.5.2.cmml" xref="S5.SS1.SSS0.Px1.p1.3.m3.4.5.2"><csymbol cd="ambiguous" id="S5.SS1.SSS0.Px1.p1.3.m3.4.5.2.1.cmml" xref="S5.SS1.SSS0.Px1.p1.3.m3.4.5.2">superscript</csymbol><apply id="S5.SS1.SSS0.Px1.p1.3.m3.4.5.2.2.cmml" xref="S5.SS1.SSS0.Px1.p1.3.m3.4.5.2"><csymbol cd="ambiguous" id="S5.SS1.SSS0.Px1.p1.3.m3.4.5.2.2.1.cmml" xref="S5.SS1.SSS0.Px1.p1.3.m3.4.5.2">subscript</csymbol><ci id="S5.SS1.SSS0.Px1.p1.3.m3.4.5.2.2.2.cmml" xref="S5.SS1.SSS0.Px1.p1.3.m3.4.5.2.2.2">ğ¹</ci><ci id="S5.SS1.SSS0.Px1.p1.3.m3.4.5.2.2.3.cmml" xref="S5.SS1.SSS0.Px1.p1.3.m3.4.5.2.2.3">ğ‘–</ci></apply><ci id="S5.SS1.SSS0.Px1.p1.3.m3.1.1.1.1.cmml" xref="S5.SS1.SSS0.Px1.p1.3.m3.1.1.1.1">ğ‘™</ci></apply><apply id="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.cmml" xref="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3"><compose id="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.1.cmml" xref="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.1"></compose><apply id="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.2.cmml" xref="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.2"><csymbol cd="ambiguous" id="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.2.1.cmml" xref="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.2">superscript</csymbol><ci id="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.2.2.cmml" xref="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.2.2">ğ‘“</ci><ci id="S5.SS1.SSS0.Px1.p1.3.m3.2.2.1.1.cmml" xref="S5.SS1.SSS0.Px1.p1.3.m3.2.2.1.1">ğ‘™</ci></apply><apply id="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.3.cmml" xref="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.3"><csymbol cd="ambiguous" id="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.3.1.cmml" xref="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.3">subscript</csymbol><ci id="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.3.2.cmml" xref="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.3.2">italic-Ï•</ci><ci id="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.3.3.cmml" xref="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.3.3">ğ‘–</ci></apply><apply id="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.4.cmml" xref="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.4"><csymbol cd="ambiguous" id="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.4.1.cmml" xref="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.4">superscript</csymbol><ci id="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.4.2.cmml" xref="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.4.2">ğ‘“</ci><apply id="S5.SS1.SSS0.Px1.p1.3.m3.3.3.1.1.1.cmml" xref="S5.SS1.SSS0.Px1.p1.3.m3.3.3.1.1"><minus id="S5.SS1.SSS0.Px1.p1.3.m3.3.3.1.1.1.1.cmml" xref="S5.SS1.SSS0.Px1.p1.3.m3.3.3.1.1.1.1"></minus><ci id="S5.SS1.SSS0.Px1.p1.3.m3.3.3.1.1.1.2.cmml" xref="S5.SS1.SSS0.Px1.p1.3.m3.3.3.1.1.1.2">ğ‘™</ci><cn type="integer" id="S5.SS1.SSS0.Px1.p1.3.m3.3.3.1.1.1.3.cmml" xref="S5.SS1.SSS0.Px1.p1.3.m3.3.3.1.1.1.3">1</cn></apply></apply><apply id="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.5.cmml" xref="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.5"><csymbol cd="ambiguous" id="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.5.1.cmml" xref="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.5">subscript</csymbol><ci id="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.5.2.cmml" xref="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.5.2">italic-Ï•</ci><ci id="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.5.3.cmml" xref="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.5.3">ğ‘–</ci></apply><ci id="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.6.cmml" xref="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.6">â‹¯</ci><apply id="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.7.cmml" xref="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.7"><csymbol cd="ambiguous" id="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.7.1.cmml" xref="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.7">superscript</csymbol><ci id="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.7.2.cmml" xref="S5.SS1.SSS0.Px1.p1.3.m3.4.5.3.7.2">ğ‘“</ci><cn type="integer" id="S5.SS1.SSS0.Px1.p1.3.m3.4.4.1.1.cmml" xref="S5.SS1.SSS0.Px1.p1.3.m3.4.4.1.1">1</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px1.p1.3.m3.4c">F_{i}^{(l)}=f^{(l)}\circ\phi_{i}\circ f^{(l-1)}\circ\phi_{i}\circ\cdots\circ f^{(1)}</annotation></semantics></math>,
where <math id="S5.SS1.SSS0.Px1.p1.4.m4.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S5.SS1.SSS0.Px1.p1.4.m4.1a"><mi id="S5.SS1.SSS0.Px1.p1.4.m4.1.1" xref="S5.SS1.SSS0.Px1.p1.4.m4.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px1.p1.4.m4.1b"><ci id="S5.SS1.SSS0.Px1.p1.4.m4.1.1.cmml" xref="S5.SS1.SSS0.Px1.p1.4.m4.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px1.p1.4.m4.1c">i</annotation></semantics></math> is the client index and <math id="S5.SS1.SSS0.Px1.p1.5.m5.1" class="ltx_Math" alttext="l" display="inline"><semantics id="S5.SS1.SSS0.Px1.p1.5.m5.1a"><mi id="S5.SS1.SSS0.Px1.p1.5.m5.1.1" xref="S5.SS1.SSS0.Px1.p1.5.m5.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px1.p1.5.m5.1b"><ci id="S5.SS1.SSS0.Px1.p1.5.m5.1.1.cmml" xref="S5.SS1.SSS0.Px1.p1.5.m5.1.1">ğ‘™</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px1.p1.5.m5.1c">l</annotation></semantics></math> is total number of layers. <math id="S5.SS1.SSS0.Px1.p1.6.m6.1" class="ltx_Math" alttext="\phi_{i}" display="inline"><semantics id="S5.SS1.SSS0.Px1.p1.6.m6.1a"><msub id="S5.SS1.SSS0.Px1.p1.6.m6.1.1" xref="S5.SS1.SSS0.Px1.p1.6.m6.1.1.cmml"><mi id="S5.SS1.SSS0.Px1.p1.6.m6.1.1.2" xref="S5.SS1.SSS0.Px1.p1.6.m6.1.1.2.cmml">Ï•</mi><mi id="S5.SS1.SSS0.Px1.p1.6.m6.1.1.3" xref="S5.SS1.SSS0.Px1.p1.6.m6.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px1.p1.6.m6.1b"><apply id="S5.SS1.SSS0.Px1.p1.6.m6.1.1.cmml" xref="S5.SS1.SSS0.Px1.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S5.SS1.SSS0.Px1.p1.6.m6.1.1.1.cmml" xref="S5.SS1.SSS0.Px1.p1.6.m6.1.1">subscript</csymbol><ci id="S5.SS1.SSS0.Px1.p1.6.m6.1.1.2.cmml" xref="S5.SS1.SSS0.Px1.p1.6.m6.1.1.2">italic-Ï•</ci><ci id="S5.SS1.SSS0.Px1.p1.6.m6.1.1.3.cmml" xref="S5.SS1.SSS0.Px1.p1.6.m6.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px1.p1.6.m6.1c">\phi_{i}</annotation></semantics></math> are local BN layers and the remaining <math id="S5.SS1.SSS0.Px1.p1.7.m7.1" class="ltx_Math" alttext="f" display="inline"><semantics id="S5.SS1.SSS0.Px1.p1.7.m7.1a"><mi id="S5.SS1.SSS0.Px1.p1.7.m7.1.1" xref="S5.SS1.SSS0.Px1.p1.7.m7.1.1.cmml">f</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px1.p1.7.m7.1b"><ci id="S5.SS1.SSS0.Px1.p1.7.m7.1.1.cmml" xref="S5.SS1.SSS0.Px1.p1.7.m7.1.1">ğ‘“</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px1.p1.7.m7.1c">f</annotation></semantics></math> are shared parameters <math id="S5.SS1.SSS0.Px1.p1.8.m8.1" class="ltx_Math" alttext="\bm{\theta}^{s}" display="inline"><semantics id="S5.SS1.SSS0.Px1.p1.8.m8.1a"><msup id="S5.SS1.SSS0.Px1.p1.8.m8.1.1" xref="S5.SS1.SSS0.Px1.p1.8.m8.1.1.cmml"><mi id="S5.SS1.SSS0.Px1.p1.8.m8.1.1.2" xref="S5.SS1.SSS0.Px1.p1.8.m8.1.1.2.cmml">ğœ½</mi><mi id="S5.SS1.SSS0.Px1.p1.8.m8.1.1.3" xref="S5.SS1.SSS0.Px1.p1.8.m8.1.1.3.cmml">s</mi></msup><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px1.p1.8.m8.1b"><apply id="S5.SS1.SSS0.Px1.p1.8.m8.1.1.cmml" xref="S5.SS1.SSS0.Px1.p1.8.m8.1.1"><csymbol cd="ambiguous" id="S5.SS1.SSS0.Px1.p1.8.m8.1.1.1.cmml" xref="S5.SS1.SSS0.Px1.p1.8.m8.1.1">superscript</csymbol><ci id="S5.SS1.SSS0.Px1.p1.8.m8.1.1.2.cmml" xref="S5.SS1.SSS0.Px1.p1.8.m8.1.1.2">ğœ½</ci><ci id="S5.SS1.SSS0.Px1.p1.8.m8.1.1.3.cmml" xref="S5.SS1.SSS0.Px1.p1.8.m8.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px1.p1.8.m8.1c">\bm{\theta}^{s}</annotation></semantics></math>. Even if backdoor features have been learned by <math id="S5.SS1.SSS0.Px1.p1.9.m9.1" class="ltx_Math" alttext="\bm{\theta}^{s}" display="inline"><semantics id="S5.SS1.SSS0.Px1.p1.9.m9.1a"><msup id="S5.SS1.SSS0.Px1.p1.9.m9.1.1" xref="S5.SS1.SSS0.Px1.p1.9.m9.1.1.cmml"><mi id="S5.SS1.SSS0.Px1.p1.9.m9.1.1.2" xref="S5.SS1.SSS0.Px1.p1.9.m9.1.1.2.cmml">ğœ½</mi><mi id="S5.SS1.SSS0.Px1.p1.9.m9.1.1.3" xref="S5.SS1.SSS0.Px1.p1.9.m9.1.1.3.cmml">s</mi></msup><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px1.p1.9.m9.1b"><apply id="S5.SS1.SSS0.Px1.p1.9.m9.1.1.cmml" xref="S5.SS1.SSS0.Px1.p1.9.m9.1.1"><csymbol cd="ambiguous" id="S5.SS1.SSS0.Px1.p1.9.m9.1.1.1.cmml" xref="S5.SS1.SSS0.Px1.p1.9.m9.1.1">superscript</csymbol><ci id="S5.SS1.SSS0.Px1.p1.9.m9.1.1.2.cmml" xref="S5.SS1.SSS0.Px1.p1.9.m9.1.1.2">ğœ½</ci><ci id="S5.SS1.SSS0.Px1.p1.9.m9.1.1.3.cmml" xref="S5.SS1.SSS0.Px1.p1.9.m9.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px1.p1.9.m9.1c">\bm{\theta}^{s}</annotation></semantics></math>, due to different <math id="S5.SS1.SSS0.Px1.p1.10.m10.1" class="ltx_Math" alttext="\phi_{i}" display="inline"><semantics id="S5.SS1.SSS0.Px1.p1.10.m10.1a"><msub id="S5.SS1.SSS0.Px1.p1.10.m10.1.1" xref="S5.SS1.SSS0.Px1.p1.10.m10.1.1.cmml"><mi id="S5.SS1.SSS0.Px1.p1.10.m10.1.1.2" xref="S5.SS1.SSS0.Px1.p1.10.m10.1.1.2.cmml">Ï•</mi><mi id="S5.SS1.SSS0.Px1.p1.10.m10.1.1.3" xref="S5.SS1.SSS0.Px1.p1.10.m10.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px1.p1.10.m10.1b"><apply id="S5.SS1.SSS0.Px1.p1.10.m10.1.1.cmml" xref="S5.SS1.SSS0.Px1.p1.10.m10.1.1"><csymbol cd="ambiguous" id="S5.SS1.SSS0.Px1.p1.10.m10.1.1.1.cmml" xref="S5.SS1.SSS0.Px1.p1.10.m10.1.1">subscript</csymbol><ci id="S5.SS1.SSS0.Px1.p1.10.m10.1.1.2.cmml" xref="S5.SS1.SSS0.Px1.p1.10.m10.1.1.2">italic-Ï•</ci><ci id="S5.SS1.SSS0.Px1.p1.10.m10.1.1.3.cmml" xref="S5.SS1.SSS0.Px1.p1.10.m10.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px1.p1.10.m10.1c">\phi_{i}</annotation></semantics></math> from FedBN, neurons corresponding to backdoor features after the BN layers of other local models wonâ€™t be activated by triggers. Therefore, FedBN could perform better robustness against backdoor attacks. To verify this, we conduct evaluations of Blended attack on FedBN under Non-IID and IID settings on CIFIAR-10.
According to our previous analysis, under IID setting, without data heterogeneity, local BN layers of clients become more consistent with each other, which should lead to better attack results under this setting. As shown in Figure <a href="#S5.F4" title="Figure 4 â€£ 5. Analysis of Various Robustness from pFL Against Backdoor Attacks â€£ Revisiting Personalized Federated Learning: Robustness Against Backdoor Attacks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, ASR of IID is higher than that of Non-IID. Especially on ResNet-18, FedBN does not show a defensive effect, which is consistent with our previous analysis.</p>
</div>
<div id="S5.SS1.SSS0.Px1.p2" class="ltx_para">
<p id="S5.SS1.SSS0.Px1.p2.5" class="ltx_p">To further analyze defense performance of local BN layers, we take attack evaluations on each part of BN layers, i.e., running statistics <math id="S5.SS1.SSS0.Px1.p2.1.m1.1" class="ltx_Math" alttext="\mu" display="inline"><semantics id="S5.SS1.SSS0.Px1.p2.1.m1.1a"><mi id="S5.SS1.SSS0.Px1.p2.1.m1.1.1" xref="S5.SS1.SSS0.Px1.p2.1.m1.1.1.cmml">Î¼</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px1.p2.1.m1.1b"><ci id="S5.SS1.SSS0.Px1.p2.1.m1.1.1.cmml" xref="S5.SS1.SSS0.Px1.p2.1.m1.1.1">ğœ‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px1.p2.1.m1.1c">\mu</annotation></semantics></math>, <math id="S5.SS1.SSS0.Px1.p2.2.m2.1" class="ltx_Math" alttext="\sigma^{2}" display="inline"><semantics id="S5.SS1.SSS0.Px1.p2.2.m2.1a"><msup id="S5.SS1.SSS0.Px1.p2.2.m2.1.1" xref="S5.SS1.SSS0.Px1.p2.2.m2.1.1.cmml"><mi id="S5.SS1.SSS0.Px1.p2.2.m2.1.1.2" xref="S5.SS1.SSS0.Px1.p2.2.m2.1.1.2.cmml">Ïƒ</mi><mn id="S5.SS1.SSS0.Px1.p2.2.m2.1.1.3" xref="S5.SS1.SSS0.Px1.p2.2.m2.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px1.p2.2.m2.1b"><apply id="S5.SS1.SSS0.Px1.p2.2.m2.1.1.cmml" xref="S5.SS1.SSS0.Px1.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS1.SSS0.Px1.p2.2.m2.1.1.1.cmml" xref="S5.SS1.SSS0.Px1.p2.2.m2.1.1">superscript</csymbol><ci id="S5.SS1.SSS0.Px1.p2.2.m2.1.1.2.cmml" xref="S5.SS1.SSS0.Px1.p2.2.m2.1.1.2">ğœ</ci><cn type="integer" id="S5.SS1.SSS0.Px1.p2.2.m2.1.1.3.cmml" xref="S5.SS1.SSS0.Px1.p2.2.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px1.p2.2.m2.1c">\sigma^{2}</annotation></semantics></math> and learnable parameters <math id="S5.SS1.SSS0.Px1.p2.3.m3.1" class="ltx_Math" alttext="\gamma" display="inline"><semantics id="S5.SS1.SSS0.Px1.p2.3.m3.1a"><mi id="S5.SS1.SSS0.Px1.p2.3.m3.1.1" xref="S5.SS1.SSS0.Px1.p2.3.m3.1.1.cmml">Î³</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px1.p2.3.m3.1b"><ci id="S5.SS1.SSS0.Px1.p2.3.m3.1.1.cmml" xref="S5.SS1.SSS0.Px1.p2.3.m3.1.1">ğ›¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px1.p2.3.m3.1c">\gamma</annotation></semantics></math>, <math id="S5.SS1.SSS0.Px1.p2.4.m4.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="S5.SS1.SSS0.Px1.p2.4.m4.1a"><mi id="S5.SS1.SSS0.Px1.p2.4.m4.1.1" xref="S5.SS1.SSS0.Px1.p2.4.m4.1.1.cmml">Î²</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px1.p2.4.m4.1b"><ci id="S5.SS1.SSS0.Px1.p2.4.m4.1.1.cmml" xref="S5.SS1.SSS0.Px1.p2.4.m4.1.1">ğ›½</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px1.p2.4.m4.1c">\beta</annotation></semantics></math>.
Unlike FedBN, we only choose not to share running statistics or learnable parameters. We denote them as <span id="S5.SS1.SSS0.Px1.p2.5.1" class="ltx_text ltx_font_italic">Fed-sta</span> or <span id="S5.SS1.SSS0.Px1.p2.5.2" class="ltx_text ltx_font_italic">Fed-para</span>. The comparison between Fed-sta, Fed-para, and the original FedBN on the Blended attack and CIFAR-10 dataset is shown inÂ Fig <a href="#S5.F5" title="Figure 5 â€£ FedBN â€£ 5.1. pFL Methods with Partial model-sharing â€£ 5. Analysis of Various Robustness from pFL Against Backdoor Attacks â€£ Revisiting Personalized Federated Learning: Robustness Against Backdoor Attacks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>. We can observe that in terms of C-Acc, Fed-sta and Fed-para experience a drop on ResNet-18 but the latter drops less. In ConvNet, Fed-para keeps the same C-Acc as FedBN. Surprisingly, we find that Fed-para achieves even better robustness than FedBN. In contrast, Fed-sta performs the worst defensive effect against Blended attack, and ASR even increases to <math id="S5.SS1.SSS0.Px1.p2.5.m5.1" class="ltx_Math" alttext="90\%" display="inline"><semantics id="S5.SS1.SSS0.Px1.p2.5.m5.1a"><mrow id="S5.SS1.SSS0.Px1.p2.5.m5.1.1" xref="S5.SS1.SSS0.Px1.p2.5.m5.1.1.cmml"><mn id="S5.SS1.SSS0.Px1.p2.5.m5.1.1.2" xref="S5.SS1.SSS0.Px1.p2.5.m5.1.1.2.cmml">90</mn><mo id="S5.SS1.SSS0.Px1.p2.5.m5.1.1.1" xref="S5.SS1.SSS0.Px1.p2.5.m5.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px1.p2.5.m5.1b"><apply id="S5.SS1.SSS0.Px1.p2.5.m5.1.1.cmml" xref="S5.SS1.SSS0.Px1.p2.5.m5.1.1"><csymbol cd="latexml" id="S5.SS1.SSS0.Px1.p2.5.m5.1.1.1.cmml" xref="S5.SS1.SSS0.Px1.p2.5.m5.1.1.1">percent</csymbol><cn type="integer" id="S5.SS1.SSS0.Px1.p2.5.m5.1.1.2.cmml" xref="S5.SS1.SSS0.Px1.p2.5.m5.1.1.2">90</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px1.p2.5.m5.1c">90\%</annotation></semantics></math> on ResNet-18. Those results demonstrate the differences in learnable parameters may be more important in preventing the propagation of backdoor features than the differences in running statistics of BN layers.</p>
</div>
<figure id="S5.F5" class="ltx_figure"><img src="/html/2302.01677/assets/x7.png" id="S5.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="207" height="111" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F5.2.1.1" class="ltx_text" style="font-size:90%;">Figure 5</span>. </span><span id="S5.F5.3.2" class="ltx_text" style="font-size:90%;">The evaluation of each part of BN layers. Left: On ResNet-18; Right: On ConvNet.</span></figcaption>
</figure>
<figure id="S5.F6" class="ltx_figure"><img src="/html/2302.01677/assets/figs/exp/fedrep_tsne.png" id="S5.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="264" height="121" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F6.2.1.1" class="ltx_text" style="font-size:90%;">Figure 6</span>. </span><span id="S5.F6.3.2" class="ltx_text" style="font-size:90%;">The T-SNE visualization on feature space of global feature extractor of FedRep. Each color denotes each class, and the black points represent backdoored samples.</span></figcaption>
</figure>
</section>
<section id="S5.SS1.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">FedRep</h5>

<div id="S5.SS1.SSS0.Px2.p1" class="ltx_para">
<p id="S5.SS1.SSS0.Px2.p1.6" class="ltx_p">FedRep decouples the local model into global feature extractor <math id="S5.SS1.SSS0.Px2.p1.1.m1.1" class="ltx_Math" alttext="\bm{\theta}^{s}" display="inline"><semantics id="S5.SS1.SSS0.Px2.p1.1.m1.1a"><msup id="S5.SS1.SSS0.Px2.p1.1.m1.1.1" xref="S5.SS1.SSS0.Px2.p1.1.m1.1.1.cmml"><mi id="S5.SS1.SSS0.Px2.p1.1.m1.1.1.2" xref="S5.SS1.SSS0.Px2.p1.1.m1.1.1.2.cmml">ğœ½</mi><mi id="S5.SS1.SSS0.Px2.p1.1.m1.1.1.3" xref="S5.SS1.SSS0.Px2.p1.1.m1.1.1.3.cmml">s</mi></msup><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px2.p1.1.m1.1b"><apply id="S5.SS1.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S5.SS1.SSS0.Px2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS1.SSS0.Px2.p1.1.m1.1.1.1.cmml" xref="S5.SS1.SSS0.Px2.p1.1.m1.1.1">superscript</csymbol><ci id="S5.SS1.SSS0.Px2.p1.1.m1.1.1.2.cmml" xref="S5.SS1.SSS0.Px2.p1.1.m1.1.1.2">ğœ½</ci><ci id="S5.SS1.SSS0.Px2.p1.1.m1.1.1.3.cmml" xref="S5.SS1.SSS0.Px2.p1.1.m1.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px2.p1.1.m1.1c">\bm{\theta}^{s}</annotation></semantics></math> and local linear classifier <math id="S5.SS1.SSS0.Px2.p1.2.m2.1" class="ltx_Math" alttext="\bm{\theta}^{p}_{i}" display="inline"><semantics id="S5.SS1.SSS0.Px2.p1.2.m2.1a"><msubsup id="S5.SS1.SSS0.Px2.p1.2.m2.1.1" xref="S5.SS1.SSS0.Px2.p1.2.m2.1.1.cmml"><mi id="S5.SS1.SSS0.Px2.p1.2.m2.1.1.2.2" xref="S5.SS1.SSS0.Px2.p1.2.m2.1.1.2.2.cmml">ğœ½</mi><mi id="S5.SS1.SSS0.Px2.p1.2.m2.1.1.3" xref="S5.SS1.SSS0.Px2.p1.2.m2.1.1.3.cmml">i</mi><mi id="S5.SS1.SSS0.Px2.p1.2.m2.1.1.2.3" xref="S5.SS1.SSS0.Px2.p1.2.m2.1.1.2.3.cmml">p</mi></msubsup><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px2.p1.2.m2.1b"><apply id="S5.SS1.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S5.SS1.SSS0.Px2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS1.SSS0.Px2.p1.2.m2.1.1.1.cmml" xref="S5.SS1.SSS0.Px2.p1.2.m2.1.1">subscript</csymbol><apply id="S5.SS1.SSS0.Px2.p1.2.m2.1.1.2.cmml" xref="S5.SS1.SSS0.Px2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS1.SSS0.Px2.p1.2.m2.1.1.2.1.cmml" xref="S5.SS1.SSS0.Px2.p1.2.m2.1.1">superscript</csymbol><ci id="S5.SS1.SSS0.Px2.p1.2.m2.1.1.2.2.cmml" xref="S5.SS1.SSS0.Px2.p1.2.m2.1.1.2.2">ğœ½</ci><ci id="S5.SS1.SSS0.Px2.p1.2.m2.1.1.2.3.cmml" xref="S5.SS1.SSS0.Px2.p1.2.m2.1.1.2.3">ğ‘</ci></apply><ci id="S5.SS1.SSS0.Px2.p1.2.m2.1.1.3.cmml" xref="S5.SS1.SSS0.Px2.p1.2.m2.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px2.p1.2.m2.1c">\bm{\theta}^{p}_{i}</annotation></semantics></math> and alternatively trains them on local datasets. And only feature extractor <math id="S5.SS1.SSS0.Px2.p1.3.m3.1" class="ltx_Math" alttext="\bm{\theta}^{s}" display="inline"><semantics id="S5.SS1.SSS0.Px2.p1.3.m3.1a"><msup id="S5.SS1.SSS0.Px2.p1.3.m3.1.1" xref="S5.SS1.SSS0.Px2.p1.3.m3.1.1.cmml"><mi id="S5.SS1.SSS0.Px2.p1.3.m3.1.1.2" xref="S5.SS1.SSS0.Px2.p1.3.m3.1.1.2.cmml">ğœ½</mi><mi id="S5.SS1.SSS0.Px2.p1.3.m3.1.1.3" xref="S5.SS1.SSS0.Px2.p1.3.m3.1.1.3.cmml">s</mi></msup><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px2.p1.3.m3.1b"><apply id="S5.SS1.SSS0.Px2.p1.3.m3.1.1.cmml" xref="S5.SS1.SSS0.Px2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S5.SS1.SSS0.Px2.p1.3.m3.1.1.1.cmml" xref="S5.SS1.SSS0.Px2.p1.3.m3.1.1">superscript</csymbol><ci id="S5.SS1.SSS0.Px2.p1.3.m3.1.1.2.cmml" xref="S5.SS1.SSS0.Px2.p1.3.m3.1.1.2">ğœ½</ci><ci id="S5.SS1.SSS0.Px2.p1.3.m3.1.1.3.cmml" xref="S5.SS1.SSS0.Px2.p1.3.m3.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px2.p1.3.m3.1c">\bm{\theta}^{s}</annotation></semantics></math> is updated and shared across clients. We would like to know which part of FedRep leads to or contributes most to improving robustness against backdoor attacks. We first study the global feature extractor <math id="S5.SS1.SSS0.Px2.p1.4.m4.1" class="ltx_Math" alttext="\bm{\theta}^{s}" display="inline"><semantics id="S5.SS1.SSS0.Px2.p1.4.m4.1a"><msup id="S5.SS1.SSS0.Px2.p1.4.m4.1.1" xref="S5.SS1.SSS0.Px2.p1.4.m4.1.1.cmml"><mi id="S5.SS1.SSS0.Px2.p1.4.m4.1.1.2" xref="S5.SS1.SSS0.Px2.p1.4.m4.1.1.2.cmml">ğœ½</mi><mi id="S5.SS1.SSS0.Px2.p1.4.m4.1.1.3" xref="S5.SS1.SSS0.Px2.p1.4.m4.1.1.3.cmml">s</mi></msup><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px2.p1.4.m4.1b"><apply id="S5.SS1.SSS0.Px2.p1.4.m4.1.1.cmml" xref="S5.SS1.SSS0.Px2.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S5.SS1.SSS0.Px2.p1.4.m4.1.1.1.cmml" xref="S5.SS1.SSS0.Px2.p1.4.m4.1.1">superscript</csymbol><ci id="S5.SS1.SSS0.Px2.p1.4.m4.1.1.2.cmml" xref="S5.SS1.SSS0.Px2.p1.4.m4.1.1.2">ğœ½</ci><ci id="S5.SS1.SSS0.Px2.p1.4.m4.1.1.3.cmml" xref="S5.SS1.SSS0.Px2.p1.4.m4.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px2.p1.4.m4.1c">\bm{\theta}^{s}</annotation></semantics></math> to figure out whether it has learned backdoor triggers even under an alternative training procedure. We conduct feature visualization on feature space of <math id="S5.SS1.SSS0.Px2.p1.5.m5.1" class="ltx_Math" alttext="\bm{\theta}^{s}" display="inline"><semantics id="S5.SS1.SSS0.Px2.p1.5.m5.1a"><msup id="S5.SS1.SSS0.Px2.p1.5.m5.1.1" xref="S5.SS1.SSS0.Px2.p1.5.m5.1.1.cmml"><mi id="S5.SS1.SSS0.Px2.p1.5.m5.1.1.2" xref="S5.SS1.SSS0.Px2.p1.5.m5.1.1.2.cmml">ğœ½</mi><mi id="S5.SS1.SSS0.Px2.p1.5.m5.1.1.3" xref="S5.SS1.SSS0.Px2.p1.5.m5.1.1.3.cmml">s</mi></msup><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px2.p1.5.m5.1b"><apply id="S5.SS1.SSS0.Px2.p1.5.m5.1.1.cmml" xref="S5.SS1.SSS0.Px2.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S5.SS1.SSS0.Px2.p1.5.m5.1.1.1.cmml" xref="S5.SS1.SSS0.Px2.p1.5.m5.1.1">superscript</csymbol><ci id="S5.SS1.SSS0.Px2.p1.5.m5.1.1.2.cmml" xref="S5.SS1.SSS0.Px2.p1.5.m5.1.1.2">ğœ½</ci><ci id="S5.SS1.SSS0.Px2.p1.5.m5.1.1.3.cmml" xref="S5.SS1.SSS0.Px2.p1.5.m5.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px2.p1.5.m5.1c">\bm{\theta}^{s}</annotation></semantics></math> by using T-SNEÂ <cite class="ltx_cite ltx_citemacro_citep">(VanÂ der Maaten and Hinton, <a href="#bib.bib53" title="" class="ltx_ref">2008</a>)</cite>. Specifically, we randomly choose <math id="S5.SS1.SSS0.Px2.p1.6.m6.1" class="ltx_Math" alttext="4" display="inline"><semantics id="S5.SS1.SSS0.Px2.p1.6.m6.1a"><mn id="S5.SS1.SSS0.Px2.p1.6.m6.1.1" xref="S5.SS1.SSS0.Px2.p1.6.m6.1.1.cmml">4</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px2.p1.6.m6.1b"><cn type="integer" id="S5.SS1.SSS0.Px2.p1.6.m6.1.1.cmml" xref="S5.SS1.SSS0.Px2.p1.6.m6.1.1">4</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px2.p1.6.m6.1c">4</annotation></semantics></math> benign clients with the adversarial client and visualize their training samples in feature space for both BadNet and Blended attacks. We take experiments on ResNet-18 and CIFAR-10. The results are shown in Figure <a href="#S5.F6" title="Figure 6 â€£ FedBN â€£ 5.1. pFL Methods with Partial model-sharing â€£ 5. Analysis of Various Robustness from pFL Against Backdoor Attacks â€£ Revisiting Personalized Federated Learning: Robustness Against Backdoor Attacks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>, where black points are backdoored samples. We could observe that most backdoored samples gather together in a single cluster, which indicates that the global feature extractor has already learned backdoor features.</p>
</div>
<div id="S5.SS1.SSS0.Px2.p2" class="ltx_para">
<p id="S5.SS1.SSS0.Px2.p2.4" class="ltx_p">Therefore, FedRepâ€™s outstanding robustness against backdoor attacks comes from the local linear classifier <math id="S5.SS1.SSS0.Px2.p2.1.m1.1" class="ltx_Math" alttext="\bm{\theta}^{p}_{i}" display="inline"><semantics id="S5.SS1.SSS0.Px2.p2.1.m1.1a"><msubsup id="S5.SS1.SSS0.Px2.p2.1.m1.1.1" xref="S5.SS1.SSS0.Px2.p2.1.m1.1.1.cmml"><mi id="S5.SS1.SSS0.Px2.p2.1.m1.1.1.2.2" xref="S5.SS1.SSS0.Px2.p2.1.m1.1.1.2.2.cmml">ğœ½</mi><mi id="S5.SS1.SSS0.Px2.p2.1.m1.1.1.3" xref="S5.SS1.SSS0.Px2.p2.1.m1.1.1.3.cmml">i</mi><mi id="S5.SS1.SSS0.Px2.p2.1.m1.1.1.2.3" xref="S5.SS1.SSS0.Px2.p2.1.m1.1.1.2.3.cmml">p</mi></msubsup><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px2.p2.1.m1.1b"><apply id="S5.SS1.SSS0.Px2.p2.1.m1.1.1.cmml" xref="S5.SS1.SSS0.Px2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS1.SSS0.Px2.p2.1.m1.1.1.1.cmml" xref="S5.SS1.SSS0.Px2.p2.1.m1.1.1">subscript</csymbol><apply id="S5.SS1.SSS0.Px2.p2.1.m1.1.1.2.cmml" xref="S5.SS1.SSS0.Px2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS1.SSS0.Px2.p2.1.m1.1.1.2.1.cmml" xref="S5.SS1.SSS0.Px2.p2.1.m1.1.1">superscript</csymbol><ci id="S5.SS1.SSS0.Px2.p2.1.m1.1.1.2.2.cmml" xref="S5.SS1.SSS0.Px2.p2.1.m1.1.1.2.2">ğœ½</ci><ci id="S5.SS1.SSS0.Px2.p2.1.m1.1.1.2.3.cmml" xref="S5.SS1.SSS0.Px2.p2.1.m1.1.1.2.3">ğ‘</ci></apply><ci id="S5.SS1.SSS0.Px2.p2.1.m1.1.1.3.cmml" xref="S5.SS1.SSS0.Px2.p2.1.m1.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px2.p2.1.m1.1c">\bm{\theta}^{p}_{i}</annotation></semantics></math> of each client. <math id="S5.SS1.SSS0.Px2.p2.2.m2.1" class="ltx_Math" alttext="\bm{\theta}^{p}_{i}" display="inline"><semantics id="S5.SS1.SSS0.Px2.p2.2.m2.1a"><msubsup id="S5.SS1.SSS0.Px2.p2.2.m2.1.1" xref="S5.SS1.SSS0.Px2.p2.2.m2.1.1.cmml"><mi id="S5.SS1.SSS0.Px2.p2.2.m2.1.1.2.2" xref="S5.SS1.SSS0.Px2.p2.2.m2.1.1.2.2.cmml">ğœ½</mi><mi id="S5.SS1.SSS0.Px2.p2.2.m2.1.1.3" xref="S5.SS1.SSS0.Px2.p2.2.m2.1.1.3.cmml">i</mi><mi id="S5.SS1.SSS0.Px2.p2.2.m2.1.1.2.3" xref="S5.SS1.SSS0.Px2.p2.2.m2.1.1.2.3.cmml">p</mi></msubsup><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px2.p2.2.m2.1b"><apply id="S5.SS1.SSS0.Px2.p2.2.m2.1.1.cmml" xref="S5.SS1.SSS0.Px2.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS1.SSS0.Px2.p2.2.m2.1.1.1.cmml" xref="S5.SS1.SSS0.Px2.p2.2.m2.1.1">subscript</csymbol><apply id="S5.SS1.SSS0.Px2.p2.2.m2.1.1.2.cmml" xref="S5.SS1.SSS0.Px2.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS1.SSS0.Px2.p2.2.m2.1.1.2.1.cmml" xref="S5.SS1.SSS0.Px2.p2.2.m2.1.1">superscript</csymbol><ci id="S5.SS1.SSS0.Px2.p2.2.m2.1.1.2.2.cmml" xref="S5.SS1.SSS0.Px2.p2.2.m2.1.1.2.2">ğœ½</ci><ci id="S5.SS1.SSS0.Px2.p2.2.m2.1.1.2.3.cmml" xref="S5.SS1.SSS0.Px2.p2.2.m2.1.1.2.3">ğ‘</ci></apply><ci id="S5.SS1.SSS0.Px2.p2.2.m2.1.1.3.cmml" xref="S5.SS1.SSS0.Px2.p2.2.m2.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px2.p2.2.m2.1c">\bm{\theta}^{p}_{i}</annotation></semantics></math> of benign clients are updated only based on their own clean dataset and never shared with other clients. Therefore, benign clientâ€™s linear classifiers <math id="S5.SS1.SSS0.Px2.p2.3.m3.1" class="ltx_Math" alttext="\bm{\theta}^{p}_{i}" display="inline"><semantics id="S5.SS1.SSS0.Px2.p2.3.m3.1a"><msubsup id="S5.SS1.SSS0.Px2.p2.3.m3.1.1" xref="S5.SS1.SSS0.Px2.p2.3.m3.1.1.cmml"><mi id="S5.SS1.SSS0.Px2.p2.3.m3.1.1.2.2" xref="S5.SS1.SSS0.Px2.p2.3.m3.1.1.2.2.cmml">ğœ½</mi><mi id="S5.SS1.SSS0.Px2.p2.3.m3.1.1.3" xref="S5.SS1.SSS0.Px2.p2.3.m3.1.1.3.cmml">i</mi><mi id="S5.SS1.SSS0.Px2.p2.3.m3.1.1.2.3" xref="S5.SS1.SSS0.Px2.p2.3.m3.1.1.2.3.cmml">p</mi></msubsup><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px2.p2.3.m3.1b"><apply id="S5.SS1.SSS0.Px2.p2.3.m3.1.1.cmml" xref="S5.SS1.SSS0.Px2.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S5.SS1.SSS0.Px2.p2.3.m3.1.1.1.cmml" xref="S5.SS1.SSS0.Px2.p2.3.m3.1.1">subscript</csymbol><apply id="S5.SS1.SSS0.Px2.p2.3.m3.1.1.2.cmml" xref="S5.SS1.SSS0.Px2.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S5.SS1.SSS0.Px2.p2.3.m3.1.1.2.1.cmml" xref="S5.SS1.SSS0.Px2.p2.3.m3.1.1">superscript</csymbol><ci id="S5.SS1.SSS0.Px2.p2.3.m3.1.1.2.2.cmml" xref="S5.SS1.SSS0.Px2.p2.3.m3.1.1.2.2">ğœ½</ci><ci id="S5.SS1.SSS0.Px2.p2.3.m3.1.1.2.3.cmml" xref="S5.SS1.SSS0.Px2.p2.3.m3.1.1.2.3">ğ‘</ci></apply><ci id="S5.SS1.SSS0.Px2.p2.3.m3.1.1.3.cmml" xref="S5.SS1.SSS0.Px2.p2.3.m3.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px2.p2.3.m3.1c">\bm{\theta}^{p}_{i}</annotation></semantics></math> do not learn the mapping from backdoor features to target label <math id="S5.SS1.SSS0.Px2.p2.4.m4.1" class="ltx_Math" alttext="\bm{y}_{t}" display="inline"><semantics id="S5.SS1.SSS0.Px2.p2.4.m4.1a"><msub id="S5.SS1.SSS0.Px2.p2.4.m4.1.1" xref="S5.SS1.SSS0.Px2.p2.4.m4.1.1.cmml"><mi id="S5.SS1.SSS0.Px2.p2.4.m4.1.1.2" xref="S5.SS1.SSS0.Px2.p2.4.m4.1.1.2.cmml">ğ’š</mi><mi id="S5.SS1.SSS0.Px2.p2.4.m4.1.1.3" xref="S5.SS1.SSS0.Px2.p2.4.m4.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px2.p2.4.m4.1b"><apply id="S5.SS1.SSS0.Px2.p2.4.m4.1.1.cmml" xref="S5.SS1.SSS0.Px2.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S5.SS1.SSS0.Px2.p2.4.m4.1.1.1.cmml" xref="S5.SS1.SSS0.Px2.p2.4.m4.1.1">subscript</csymbol><ci id="S5.SS1.SSS0.Px2.p2.4.m4.1.1.2.cmml" xref="S5.SS1.SSS0.Px2.p2.4.m4.1.1.2">ğ’š</ci><ci id="S5.SS1.SSS0.Px2.p2.4.m4.1.1.3.cmml" xref="S5.SS1.SSS0.Px2.p2.4.m4.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px2.p2.4.m4.1c">\bm{y}_{t}</annotation></semantics></math>. Inspired by this exciting finding, we further propose a simple defense method and will discuss it in Section <a href="#S6" title="6. Improving Backdoor Robustness with Simple-Tuning â€£ Revisiting Personalized Federated Learning: Robustness Against Backdoor Attacks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>.</p>
</div>
</section>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2. </span>pFL Methods with Full model-sharing</h3>

<section id="S5.SS2.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Ditto.</h5>

<figure id="S5.F7" class="ltx_figure"><img src="/html/2302.01677/assets/x8.png" id="S5.F7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="150" height="96" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F7.4.2.1" class="ltx_text" style="font-size:90%;">Figure 7</span>. </span><span id="S5.F7.2.1" class="ltx_text" style="font-size:90%;">The results of Blended attack on Ditto with different <math id="S5.F7.2.1.m1.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S5.F7.2.1.m1.1b"><mi id="S5.F7.2.1.m1.1.1" xref="S5.F7.2.1.m1.1.1.cmml">Î»</mi><annotation-xml encoding="MathML-Content" id="S5.F7.2.1.m1.1c"><ci id="S5.F7.2.1.m1.1.1.cmml" xref="S5.F7.2.1.m1.1.1">ğœ†</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.F7.2.1.m1.1d">\lambda</annotation></semantics></math> on CIFAR-10 dataset. Left: ResNet-18; Right: ConvNet.</span></figcaption>
</figure>
<div id="S5.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="S5.SS2.SSS0.Px1.p1.16" class="ltx_p">Backdoor features could be inserted into <math id="S5.SS2.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="\bm{\theta}_{g}" display="inline"><semantics id="S5.SS2.SSS0.Px1.p1.1.m1.1a"><msub id="S5.SS2.SSS0.Px1.p1.1.m1.1.1" xref="S5.SS2.SSS0.Px1.p1.1.m1.1.1.cmml"><mi id="S5.SS2.SSS0.Px1.p1.1.m1.1.1.2" xref="S5.SS2.SSS0.Px1.p1.1.m1.1.1.2.cmml">ğœ½</mi><mi id="S5.SS2.SSS0.Px1.p1.1.m1.1.1.3" xref="S5.SS2.SSS0.Px1.p1.1.m1.1.1.3.cmml">g</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px1.p1.1.m1.1b"><apply id="S5.SS2.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S5.SS2.SSS0.Px1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS0.Px1.p1.1.m1.1.1.1.cmml" xref="S5.SS2.SSS0.Px1.p1.1.m1.1.1">subscript</csymbol><ci id="S5.SS2.SSS0.Px1.p1.1.m1.1.1.2.cmml" xref="S5.SS2.SSS0.Px1.p1.1.m1.1.1.2">ğœ½</ci><ci id="S5.SS2.SSS0.Px1.p1.1.m1.1.1.3.cmml" xref="S5.SS2.SSS0.Px1.p1.1.m1.1.1.3">ğ‘”</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px1.p1.1.m1.1c">\bm{\theta}_{g}</annotation></semantics></math> during local training on the adversary client and then propagated to other clients by full model-sharing. In DittoÂ <cite class="ltx_cite ltx_citemacro_citep">(Li etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib32" title="" class="ltx_ref">2021a</a>)</cite>, clients use the global model <math id="S5.SS2.SSS0.Px1.p1.2.m2.1" class="ltx_Math" alttext="\bm{\theta}_{g}" display="inline"><semantics id="S5.SS2.SSS0.Px1.p1.2.m2.1a"><msub id="S5.SS2.SSS0.Px1.p1.2.m2.1.1" xref="S5.SS2.SSS0.Px1.p1.2.m2.1.1.cmml"><mi id="S5.SS2.SSS0.Px1.p1.2.m2.1.1.2" xref="S5.SS2.SSS0.Px1.p1.2.m2.1.1.2.cmml">ğœ½</mi><mi id="S5.SS2.SSS0.Px1.p1.2.m2.1.1.3" xref="S5.SS2.SSS0.Px1.p1.2.m2.1.1.3.cmml">g</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px1.p1.2.m2.1b"><apply id="S5.SS2.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S5.SS2.SSS0.Px1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS0.Px1.p1.2.m2.1.1.1.cmml" xref="S5.SS2.SSS0.Px1.p1.2.m2.1.1">subscript</csymbol><ci id="S5.SS2.SSS0.Px1.p1.2.m2.1.1.2.cmml" xref="S5.SS2.SSS0.Px1.p1.2.m2.1.1.2">ğœ½</ci><ci id="S5.SS2.SSS0.Px1.p1.2.m2.1.1.3.cmml" xref="S5.SS2.SSS0.Px1.p1.2.m2.1.1.3">ğ‘”</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px1.p1.2.m2.1c">\bm{\theta}_{g}</annotation></semantics></math> as the reference to guide training of local model <math id="S5.SS2.SSS0.Px1.p1.3.m3.1" class="ltx_Math" alttext="\bm{\theta}_{i}" display="inline"><semantics id="S5.SS2.SSS0.Px1.p1.3.m3.1a"><msub id="S5.SS2.SSS0.Px1.p1.3.m3.1.1" xref="S5.SS2.SSS0.Px1.p1.3.m3.1.1.cmml"><mi id="S5.SS2.SSS0.Px1.p1.3.m3.1.1.2" xref="S5.SS2.SSS0.Px1.p1.3.m3.1.1.2.cmml">ğœ½</mi><mi id="S5.SS2.SSS0.Px1.p1.3.m3.1.1.3" xref="S5.SS2.SSS0.Px1.p1.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px1.p1.3.m3.1b"><apply id="S5.SS2.SSS0.Px1.p1.3.m3.1.1.cmml" xref="S5.SS2.SSS0.Px1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS0.Px1.p1.3.m3.1.1.1.cmml" xref="S5.SS2.SSS0.Px1.p1.3.m3.1.1">subscript</csymbol><ci id="S5.SS2.SSS0.Px1.p1.3.m3.1.1.2.cmml" xref="S5.SS2.SSS0.Px1.p1.3.m3.1.1.2">ğœ½</ci><ci id="S5.SS2.SSS0.Px1.p1.3.m3.1.1.3.cmml" xref="S5.SS2.SSS0.Px1.p1.3.m3.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px1.p1.3.m3.1c">\bm{\theta}_{i}</annotation></semantics></math> based on <math id="S5.SS2.SSS0.Px1.p1.4.m4.2" class="ltx_Math" alttext="\lambda\mathcal{H}(\bm{\theta}_{g},\bm{\theta}_{i})" display="inline"><semantics id="S5.SS2.SSS0.Px1.p1.4.m4.2a"><mrow id="S5.SS2.SSS0.Px1.p1.4.m4.2.2" xref="S5.SS2.SSS0.Px1.p1.4.m4.2.2.cmml"><mi id="S5.SS2.SSS0.Px1.p1.4.m4.2.2.4" xref="S5.SS2.SSS0.Px1.p1.4.m4.2.2.4.cmml">Î»</mi><mo lspace="0em" rspace="0em" id="S5.SS2.SSS0.Px1.p1.4.m4.2.2.3" xref="S5.SS2.SSS0.Px1.p1.4.m4.2.2.3.cmml">â€‹</mo><mi class="ltx_font_mathcaligraphic" id="S5.SS2.SSS0.Px1.p1.4.m4.2.2.5" xref="S5.SS2.SSS0.Px1.p1.4.m4.2.2.5.cmml">â„‹</mi><mo lspace="0em" rspace="0em" id="S5.SS2.SSS0.Px1.p1.4.m4.2.2.3a" xref="S5.SS2.SSS0.Px1.p1.4.m4.2.2.3.cmml">â€‹</mo><mrow id="S5.SS2.SSS0.Px1.p1.4.m4.2.2.2.2" xref="S5.SS2.SSS0.Px1.p1.4.m4.2.2.2.3.cmml"><mo stretchy="false" id="S5.SS2.SSS0.Px1.p1.4.m4.2.2.2.2.3" xref="S5.SS2.SSS0.Px1.p1.4.m4.2.2.2.3.cmml">(</mo><msub id="S5.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1" xref="S5.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.cmml"><mi id="S5.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.2" xref="S5.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.2.cmml">ğœ½</mi><mi id="S5.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.3" xref="S5.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.3.cmml">g</mi></msub><mo id="S5.SS2.SSS0.Px1.p1.4.m4.2.2.2.2.4" xref="S5.SS2.SSS0.Px1.p1.4.m4.2.2.2.3.cmml">,</mo><msub id="S5.SS2.SSS0.Px1.p1.4.m4.2.2.2.2.2" xref="S5.SS2.SSS0.Px1.p1.4.m4.2.2.2.2.2.cmml"><mi id="S5.SS2.SSS0.Px1.p1.4.m4.2.2.2.2.2.2" xref="S5.SS2.SSS0.Px1.p1.4.m4.2.2.2.2.2.2.cmml">ğœ½</mi><mi id="S5.SS2.SSS0.Px1.p1.4.m4.2.2.2.2.2.3" xref="S5.SS2.SSS0.Px1.p1.4.m4.2.2.2.2.2.3.cmml">i</mi></msub><mo stretchy="false" id="S5.SS2.SSS0.Px1.p1.4.m4.2.2.2.2.5" xref="S5.SS2.SSS0.Px1.p1.4.m4.2.2.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px1.p1.4.m4.2b"><apply id="S5.SS2.SSS0.Px1.p1.4.m4.2.2.cmml" xref="S5.SS2.SSS0.Px1.p1.4.m4.2.2"><times id="S5.SS2.SSS0.Px1.p1.4.m4.2.2.3.cmml" xref="S5.SS2.SSS0.Px1.p1.4.m4.2.2.3"></times><ci id="S5.SS2.SSS0.Px1.p1.4.m4.2.2.4.cmml" xref="S5.SS2.SSS0.Px1.p1.4.m4.2.2.4">ğœ†</ci><ci id="S5.SS2.SSS0.Px1.p1.4.m4.2.2.5.cmml" xref="S5.SS2.SSS0.Px1.p1.4.m4.2.2.5">â„‹</ci><interval closure="open" id="S5.SS2.SSS0.Px1.p1.4.m4.2.2.2.3.cmml" xref="S5.SS2.SSS0.Px1.p1.4.m4.2.2.2.2"><apply id="S5.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.cmml" xref="S5.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.cmml" xref="S5.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1">subscript</csymbol><ci id="S5.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.2.cmml" xref="S5.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.2">ğœ½</ci><ci id="S5.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.3.cmml" xref="S5.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.3">ğ‘”</ci></apply><apply id="S5.SS2.SSS0.Px1.p1.4.m4.2.2.2.2.2.cmml" xref="S5.SS2.SSS0.Px1.p1.4.m4.2.2.2.2.2"><csymbol cd="ambiguous" id="S5.SS2.SSS0.Px1.p1.4.m4.2.2.2.2.2.1.cmml" xref="S5.SS2.SSS0.Px1.p1.4.m4.2.2.2.2.2">subscript</csymbol><ci id="S5.SS2.SSS0.Px1.p1.4.m4.2.2.2.2.2.2.cmml" xref="S5.SS2.SSS0.Px1.p1.4.m4.2.2.2.2.2.2">ğœ½</ci><ci id="S5.SS2.SSS0.Px1.p1.4.m4.2.2.2.2.2.3.cmml" xref="S5.SS2.SSS0.Px1.p1.4.m4.2.2.2.2.2.3">ğ‘–</ci></apply></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px1.p1.4.m4.2c">\lambda\mathcal{H}(\bm{\theta}_{g},\bm{\theta}_{i})</annotation></semantics></math>. <math id="S5.SS2.SSS0.Px1.p1.5.m5.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S5.SS2.SSS0.Px1.p1.5.m5.1a"><mi id="S5.SS2.SSS0.Px1.p1.5.m5.1.1" xref="S5.SS2.SSS0.Px1.p1.5.m5.1.1.cmml">Î»</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px1.p1.5.m5.1b"><ci id="S5.SS2.SSS0.Px1.p1.5.m5.1.1.cmml" xref="S5.SS2.SSS0.Px1.p1.5.m5.1.1">ğœ†</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px1.p1.5.m5.1c">\lambda</annotation></semantics></math> controls the similarity with <math id="S5.SS2.SSS0.Px1.p1.6.m6.1" class="ltx_Math" alttext="\bm{\theta}_{g}" display="inline"><semantics id="S5.SS2.SSS0.Px1.p1.6.m6.1a"><msub id="S5.SS2.SSS0.Px1.p1.6.m6.1.1" xref="S5.SS2.SSS0.Px1.p1.6.m6.1.1.cmml"><mi id="S5.SS2.SSS0.Px1.p1.6.m6.1.1.2" xref="S5.SS2.SSS0.Px1.p1.6.m6.1.1.2.cmml">ğœ½</mi><mi id="S5.SS2.SSS0.Px1.p1.6.m6.1.1.3" xref="S5.SS2.SSS0.Px1.p1.6.m6.1.1.3.cmml">g</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px1.p1.6.m6.1b"><apply id="S5.SS2.SSS0.Px1.p1.6.m6.1.1.cmml" xref="S5.SS2.SSS0.Px1.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS0.Px1.p1.6.m6.1.1.1.cmml" xref="S5.SS2.SSS0.Px1.p1.6.m6.1.1">subscript</csymbol><ci id="S5.SS2.SSS0.Px1.p1.6.m6.1.1.2.cmml" xref="S5.SS2.SSS0.Px1.p1.6.m6.1.1.2">ğœ½</ci><ci id="S5.SS2.SSS0.Px1.p1.6.m6.1.1.3.cmml" xref="S5.SS2.SSS0.Px1.p1.6.m6.1.1.3">ğ‘”</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px1.p1.6.m6.1c">\bm{\theta}_{g}</annotation></semantics></math> and also the personalization degree of <math id="S5.SS2.SSS0.Px1.p1.7.m7.1" class="ltx_Math" alttext="\bm{\theta}_{i}" display="inline"><semantics id="S5.SS2.SSS0.Px1.p1.7.m7.1a"><msub id="S5.SS2.SSS0.Px1.p1.7.m7.1.1" xref="S5.SS2.SSS0.Px1.p1.7.m7.1.1.cmml"><mi id="S5.SS2.SSS0.Px1.p1.7.m7.1.1.2" xref="S5.SS2.SSS0.Px1.p1.7.m7.1.1.2.cmml">ğœ½</mi><mi id="S5.SS2.SSS0.Px1.p1.7.m7.1.1.3" xref="S5.SS2.SSS0.Px1.p1.7.m7.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px1.p1.7.m7.1b"><apply id="S5.SS2.SSS0.Px1.p1.7.m7.1.1.cmml" xref="S5.SS2.SSS0.Px1.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS0.Px1.p1.7.m7.1.1.1.cmml" xref="S5.SS2.SSS0.Px1.p1.7.m7.1.1">subscript</csymbol><ci id="S5.SS2.SSS0.Px1.p1.7.m7.1.1.2.cmml" xref="S5.SS2.SSS0.Px1.p1.7.m7.1.1.2">ğœ½</ci><ci id="S5.SS2.SSS0.Px1.p1.7.m7.1.1.3.cmml" xref="S5.SS2.SSS0.Px1.p1.7.m7.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px1.p1.7.m7.1c">\bm{\theta}_{i}</annotation></semantics></math>. The smaller <math id="S5.SS2.SSS0.Px1.p1.8.m8.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S5.SS2.SSS0.Px1.p1.8.m8.1a"><mi id="S5.SS2.SSS0.Px1.p1.8.m8.1.1" xref="S5.SS2.SSS0.Px1.p1.8.m8.1.1.cmml">Î»</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px1.p1.8.m8.1b"><ci id="S5.SS2.SSS0.Px1.p1.8.m8.1.1.cmml" xref="S5.SS2.SSS0.Px1.p1.8.m8.1.1">ğœ†</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px1.p1.8.m8.1c">\lambda</annotation></semantics></math> means the <math id="S5.SS2.SSS0.Px1.p1.9.m9.1" class="ltx_Math" alttext="\bm{\theta}_{i}" display="inline"><semantics id="S5.SS2.SSS0.Px1.p1.9.m9.1a"><msub id="S5.SS2.SSS0.Px1.p1.9.m9.1.1" xref="S5.SS2.SSS0.Px1.p1.9.m9.1.1.cmml"><mi id="S5.SS2.SSS0.Px1.p1.9.m9.1.1.2" xref="S5.SS2.SSS0.Px1.p1.9.m9.1.1.2.cmml">ğœ½</mi><mi id="S5.SS2.SSS0.Px1.p1.9.m9.1.1.3" xref="S5.SS2.SSS0.Px1.p1.9.m9.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px1.p1.9.m9.1b"><apply id="S5.SS2.SSS0.Px1.p1.9.m9.1.1.cmml" xref="S5.SS2.SSS0.Px1.p1.9.m9.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS0.Px1.p1.9.m9.1.1.1.cmml" xref="S5.SS2.SSS0.Px1.p1.9.m9.1.1">subscript</csymbol><ci id="S5.SS2.SSS0.Px1.p1.9.m9.1.1.2.cmml" xref="S5.SS2.SSS0.Px1.p1.9.m9.1.1.2">ğœ½</ci><ci id="S5.SS2.SSS0.Px1.p1.9.m9.1.1.3.cmml" xref="S5.SS2.SSS0.Px1.p1.9.m9.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px1.p1.9.m9.1c">\bm{\theta}_{i}</annotation></semantics></math>â€™s update is less dependent on <math id="S5.SS2.SSS0.Px1.p1.10.m10.1" class="ltx_Math" alttext="\bm{\theta}_{g}" display="inline"><semantics id="S5.SS2.SSS0.Px1.p1.10.m10.1a"><msub id="S5.SS2.SSS0.Px1.p1.10.m10.1.1" xref="S5.SS2.SSS0.Px1.p1.10.m10.1.1.cmml"><mi id="S5.SS2.SSS0.Px1.p1.10.m10.1.1.2" xref="S5.SS2.SSS0.Px1.p1.10.m10.1.1.2.cmml">ğœ½</mi><mi id="S5.SS2.SSS0.Px1.p1.10.m10.1.1.3" xref="S5.SS2.SSS0.Px1.p1.10.m10.1.1.3.cmml">g</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px1.p1.10.m10.1b"><apply id="S5.SS2.SSS0.Px1.p1.10.m10.1.1.cmml" xref="S5.SS2.SSS0.Px1.p1.10.m10.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS0.Px1.p1.10.m10.1.1.1.cmml" xref="S5.SS2.SSS0.Px1.p1.10.m10.1.1">subscript</csymbol><ci id="S5.SS2.SSS0.Px1.p1.10.m10.1.1.2.cmml" xref="S5.SS2.SSS0.Px1.p1.10.m10.1.1.2">ğœ½</ci><ci id="S5.SS2.SSS0.Px1.p1.10.m10.1.1.3.cmml" xref="S5.SS2.SSS0.Px1.p1.10.m10.1.1.3">ğ‘”</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px1.p1.10.m10.1c">\bm{\theta}_{g}</annotation></semantics></math>. Since previous results indicate a strong positive correlation
between robustness against backdoor attacks and the larger personalization degree, we investigate if the smaller <math id="S5.SS2.SSS0.Px1.p1.11.m11.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S5.SS2.SSS0.Px1.p1.11.m11.1a"><mi id="S5.SS2.SSS0.Px1.p1.11.m11.1.1" xref="S5.SS2.SSS0.Px1.p1.11.m11.1.1.cmml">Î»</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px1.p1.11.m11.1b"><ci id="S5.SS2.SSS0.Px1.p1.11.m11.1.1.cmml" xref="S5.SS2.SSS0.Px1.p1.11.m11.1.1">ğœ†</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px1.p1.11.m11.1c">\lambda</annotation></semantics></math> (larger personalization degree) can block the transfer of backdoor features from <math id="S5.SS2.SSS0.Px1.p1.12.m12.1" class="ltx_Math" alttext="\bm{\theta}_{g}" display="inline"><semantics id="S5.SS2.SSS0.Px1.p1.12.m12.1a"><msub id="S5.SS2.SSS0.Px1.p1.12.m12.1.1" xref="S5.SS2.SSS0.Px1.p1.12.m12.1.1.cmml"><mi id="S5.SS2.SSS0.Px1.p1.12.m12.1.1.2" xref="S5.SS2.SSS0.Px1.p1.12.m12.1.1.2.cmml">ğœ½</mi><mi id="S5.SS2.SSS0.Px1.p1.12.m12.1.1.3" xref="S5.SS2.SSS0.Px1.p1.12.m12.1.1.3.cmml">g</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px1.p1.12.m12.1b"><apply id="S5.SS2.SSS0.Px1.p1.12.m12.1.1.cmml" xref="S5.SS2.SSS0.Px1.p1.12.m12.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS0.Px1.p1.12.m12.1.1.1.cmml" xref="S5.SS2.SSS0.Px1.p1.12.m12.1.1">subscript</csymbol><ci id="S5.SS2.SSS0.Px1.p1.12.m12.1.1.2.cmml" xref="S5.SS2.SSS0.Px1.p1.12.m12.1.1.2">ğœ½</ci><ci id="S5.SS2.SSS0.Px1.p1.12.m12.1.1.3.cmml" xref="S5.SS2.SSS0.Px1.p1.12.m12.1.1.3">ğ‘”</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px1.p1.12.m12.1c">\bm{\theta}_{g}</annotation></semantics></math> to <math id="S5.SS2.SSS0.Px1.p1.13.m13.1" class="ltx_Math" alttext="\bm{\theta}_{i}" display="inline"><semantics id="S5.SS2.SSS0.Px1.p1.13.m13.1a"><msub id="S5.SS2.SSS0.Px1.p1.13.m13.1.1" xref="S5.SS2.SSS0.Px1.p1.13.m13.1.1.cmml"><mi id="S5.SS2.SSS0.Px1.p1.13.m13.1.1.2" xref="S5.SS2.SSS0.Px1.p1.13.m13.1.1.2.cmml">ğœ½</mi><mi id="S5.SS2.SSS0.Px1.p1.13.m13.1.1.3" xref="S5.SS2.SSS0.Px1.p1.13.m13.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px1.p1.13.m13.1b"><apply id="S5.SS2.SSS0.Px1.p1.13.m13.1.1.cmml" xref="S5.SS2.SSS0.Px1.p1.13.m13.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS0.Px1.p1.13.m13.1.1.1.cmml" xref="S5.SS2.SSS0.Px1.p1.13.m13.1.1">subscript</csymbol><ci id="S5.SS2.SSS0.Px1.p1.13.m13.1.1.2.cmml" xref="S5.SS2.SSS0.Px1.p1.13.m13.1.1.2">ğœ½</ci><ci id="S5.SS2.SSS0.Px1.p1.13.m13.1.1.3.cmml" xref="S5.SS2.SSS0.Px1.p1.13.m13.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px1.p1.13.m13.1c">\bm{\theta}_{i}</annotation></semantics></math>. We conduct experiments of Blended attack on CIFAR-10 dataset with <math id="S5.SS2.SSS0.Px1.p1.14.m14.1" class="ltx_Math" alttext="\lambda=0.1" display="inline"><semantics id="S5.SS2.SSS0.Px1.p1.14.m14.1a"><mrow id="S5.SS2.SSS0.Px1.p1.14.m14.1.1" xref="S5.SS2.SSS0.Px1.p1.14.m14.1.1.cmml"><mi id="S5.SS2.SSS0.Px1.p1.14.m14.1.1.2" xref="S5.SS2.SSS0.Px1.p1.14.m14.1.1.2.cmml">Î»</mi><mo id="S5.SS2.SSS0.Px1.p1.14.m14.1.1.1" xref="S5.SS2.SSS0.Px1.p1.14.m14.1.1.1.cmml">=</mo><mn id="S5.SS2.SSS0.Px1.p1.14.m14.1.1.3" xref="S5.SS2.SSS0.Px1.p1.14.m14.1.1.3.cmml">0.1</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px1.p1.14.m14.1b"><apply id="S5.SS2.SSS0.Px1.p1.14.m14.1.1.cmml" xref="S5.SS2.SSS0.Px1.p1.14.m14.1.1"><eq id="S5.SS2.SSS0.Px1.p1.14.m14.1.1.1.cmml" xref="S5.SS2.SSS0.Px1.p1.14.m14.1.1.1"></eq><ci id="S5.SS2.SSS0.Px1.p1.14.m14.1.1.2.cmml" xref="S5.SS2.SSS0.Px1.p1.14.m14.1.1.2">ğœ†</ci><cn type="float" id="S5.SS2.SSS0.Px1.p1.14.m14.1.1.3.cmml" xref="S5.SS2.SSS0.Px1.p1.14.m14.1.1.3">0.1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px1.p1.14.m14.1c">\lambda=0.1</annotation></semantics></math> and <math id="S5.SS2.SSS0.Px1.p1.15.m15.1" class="ltx_Math" alttext="\lambda=0.01" display="inline"><semantics id="S5.SS2.SSS0.Px1.p1.15.m15.1a"><mrow id="S5.SS2.SSS0.Px1.p1.15.m15.1.1" xref="S5.SS2.SSS0.Px1.p1.15.m15.1.1.cmml"><mi id="S5.SS2.SSS0.Px1.p1.15.m15.1.1.2" xref="S5.SS2.SSS0.Px1.p1.15.m15.1.1.2.cmml">Î»</mi><mo id="S5.SS2.SSS0.Px1.p1.15.m15.1.1.1" xref="S5.SS2.SSS0.Px1.p1.15.m15.1.1.1.cmml">=</mo><mn id="S5.SS2.SSS0.Px1.p1.15.m15.1.1.3" xref="S5.SS2.SSS0.Px1.p1.15.m15.1.1.3.cmml">0.01</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px1.p1.15.m15.1b"><apply id="S5.SS2.SSS0.Px1.p1.15.m15.1.1.cmml" xref="S5.SS2.SSS0.Px1.p1.15.m15.1.1"><eq id="S5.SS2.SSS0.Px1.p1.15.m15.1.1.1.cmml" xref="S5.SS2.SSS0.Px1.p1.15.m15.1.1.1"></eq><ci id="S5.SS2.SSS0.Px1.p1.15.m15.1.1.2.cmml" xref="S5.SS2.SSS0.Px1.p1.15.m15.1.1.2">ğœ†</ci><cn type="float" id="S5.SS2.SSS0.Px1.p1.15.m15.1.1.3.cmml" xref="S5.SS2.SSS0.Px1.p1.15.m15.1.1.3">0.01</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px1.p1.15.m15.1c">\lambda=0.01</annotation></semantics></math> in FigureÂ <a href="#S5.F7" title="Figure 7 â€£ Ditto. â€£ 5.2. pFL Methods with Full model-sharing â€£ 5. Analysis of Various Robustness from pFL Against Backdoor Attacks â€£ Revisiting Personalized Federated Learning: Robustness Against Backdoor Attacks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>. We could observe that with smaller <math id="S5.SS2.SSS0.Px1.p1.16.m16.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S5.SS2.SSS0.Px1.p1.16.m16.1a"><mi id="S5.SS2.SSS0.Px1.p1.16.m16.1.1" xref="S5.SS2.SSS0.Px1.p1.16.m16.1.1.cmml">Î»</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px1.p1.16.m16.1b"><ci id="S5.SS2.SSS0.Px1.p1.16.m16.1.1.cmml" xref="S5.SS2.SSS0.Px1.p1.16.m16.1.1">ğœ†</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px1.p1.16.m16.1c">\lambda</annotation></semantics></math>, ASR drops slightly on ResNet-18 and ConvNet. This verifies our thought. However, in terms of clean accuracy, the convergence of Ditto also significantly slows down. Therefore, Ditto also faces a trade-off between backdoor robustness and clean accuracy of the main task like mentioned defense methods.</p>
</div>
</section>
<section id="S5.SS2.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">pFedMe</h5>

<div id="S5.SS2.SSS0.Px2.p1" class="ltx_para">
<p id="S5.SS2.SSS0.Px2.p1.6" class="ltx_p">Similar to Ditto, pFedMeÂ <cite class="ltx_cite ltx_citemacro_citep">(TÂ Dinh etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib50" title="" class="ltx_ref">2020</a>)</cite> also trains local personalized model of each client with a penalty term <math id="S5.SS2.SSS0.Px2.p1.1.m1.2" class="ltx_Math" alttext="\lambda\mathcal{H}(\bm{\theta}_{g},\bm{\theta}_{i})" display="inline"><semantics id="S5.SS2.SSS0.Px2.p1.1.m1.2a"><mrow id="S5.SS2.SSS0.Px2.p1.1.m1.2.2" xref="S5.SS2.SSS0.Px2.p1.1.m1.2.2.cmml"><mi id="S5.SS2.SSS0.Px2.p1.1.m1.2.2.4" xref="S5.SS2.SSS0.Px2.p1.1.m1.2.2.4.cmml">Î»</mi><mo lspace="0em" rspace="0em" id="S5.SS2.SSS0.Px2.p1.1.m1.2.2.3" xref="S5.SS2.SSS0.Px2.p1.1.m1.2.2.3.cmml">â€‹</mo><mi class="ltx_font_mathcaligraphic" id="S5.SS2.SSS0.Px2.p1.1.m1.2.2.5" xref="S5.SS2.SSS0.Px2.p1.1.m1.2.2.5.cmml">â„‹</mi><mo lspace="0em" rspace="0em" id="S5.SS2.SSS0.Px2.p1.1.m1.2.2.3a" xref="S5.SS2.SSS0.Px2.p1.1.m1.2.2.3.cmml">â€‹</mo><mrow id="S5.SS2.SSS0.Px2.p1.1.m1.2.2.2.2" xref="S5.SS2.SSS0.Px2.p1.1.m1.2.2.2.3.cmml"><mo stretchy="false" id="S5.SS2.SSS0.Px2.p1.1.m1.2.2.2.2.3" xref="S5.SS2.SSS0.Px2.p1.1.m1.2.2.2.3.cmml">(</mo><msub id="S5.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.1" xref="S5.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.1.cmml"><mi id="S5.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.1.2" xref="S5.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.1.2.cmml">ğœ½</mi><mi id="S5.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.1.3" xref="S5.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.1.3.cmml">g</mi></msub><mo id="S5.SS2.SSS0.Px2.p1.1.m1.2.2.2.2.4" xref="S5.SS2.SSS0.Px2.p1.1.m1.2.2.2.3.cmml">,</mo><msub id="S5.SS2.SSS0.Px2.p1.1.m1.2.2.2.2.2" xref="S5.SS2.SSS0.Px2.p1.1.m1.2.2.2.2.2.cmml"><mi id="S5.SS2.SSS0.Px2.p1.1.m1.2.2.2.2.2.2" xref="S5.SS2.SSS0.Px2.p1.1.m1.2.2.2.2.2.2.cmml">ğœ½</mi><mi id="S5.SS2.SSS0.Px2.p1.1.m1.2.2.2.2.2.3" xref="S5.SS2.SSS0.Px2.p1.1.m1.2.2.2.2.2.3.cmml">i</mi></msub><mo stretchy="false" id="S5.SS2.SSS0.Px2.p1.1.m1.2.2.2.2.5" xref="S5.SS2.SSS0.Px2.p1.1.m1.2.2.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px2.p1.1.m1.2b"><apply id="S5.SS2.SSS0.Px2.p1.1.m1.2.2.cmml" xref="S5.SS2.SSS0.Px2.p1.1.m1.2.2"><times id="S5.SS2.SSS0.Px2.p1.1.m1.2.2.3.cmml" xref="S5.SS2.SSS0.Px2.p1.1.m1.2.2.3"></times><ci id="S5.SS2.SSS0.Px2.p1.1.m1.2.2.4.cmml" xref="S5.SS2.SSS0.Px2.p1.1.m1.2.2.4">ğœ†</ci><ci id="S5.SS2.SSS0.Px2.p1.1.m1.2.2.5.cmml" xref="S5.SS2.SSS0.Px2.p1.1.m1.2.2.5">â„‹</ci><interval closure="open" id="S5.SS2.SSS0.Px2.p1.1.m1.2.2.2.3.cmml" xref="S5.SS2.SSS0.Px2.p1.1.m1.2.2.2.2"><apply id="S5.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.1.cmml" xref="S5.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.1.1.cmml" xref="S5.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.1">subscript</csymbol><ci id="S5.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.1.2.cmml" xref="S5.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.1.2">ğœ½</ci><ci id="S5.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.1.3.cmml" xref="S5.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.1.3">ğ‘”</ci></apply><apply id="S5.SS2.SSS0.Px2.p1.1.m1.2.2.2.2.2.cmml" xref="S5.SS2.SSS0.Px2.p1.1.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="S5.SS2.SSS0.Px2.p1.1.m1.2.2.2.2.2.1.cmml" xref="S5.SS2.SSS0.Px2.p1.1.m1.2.2.2.2.2">subscript</csymbol><ci id="S5.SS2.SSS0.Px2.p1.1.m1.2.2.2.2.2.2.cmml" xref="S5.SS2.SSS0.Px2.p1.1.m1.2.2.2.2.2.2">ğœ½</ci><ci id="S5.SS2.SSS0.Px2.p1.1.m1.2.2.2.2.2.3.cmml" xref="S5.SS2.SSS0.Px2.p1.1.m1.2.2.2.2.2.3">ğ‘–</ci></apply></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px2.p1.1.m1.2c">\lambda\mathcal{H}(\bm{\theta}_{g},\bm{\theta}_{i})</annotation></semantics></math> but performs a better defense performance against backdoor attacks. The reason is that pFedMe only updates the global model at the end of each epoch of local training based on local model updates, which leads to fewer chances for backdoor triggers to insert into the global model by using pFedMe method. Compared with Ditto which updates <math id="S5.SS2.SSS0.Px2.p1.2.m2.1" class="ltx_Math" alttext="\bm{\theta}_{g}" display="inline"><semantics id="S5.SS2.SSS0.Px2.p1.2.m2.1a"><msub id="S5.SS2.SSS0.Px2.p1.2.m2.1.1" xref="S5.SS2.SSS0.Px2.p1.2.m2.1.1.cmml"><mi id="S5.SS2.SSS0.Px2.p1.2.m2.1.1.2" xref="S5.SS2.SSS0.Px2.p1.2.m2.1.1.2.cmml">ğœ½</mi><mi id="S5.SS2.SSS0.Px2.p1.2.m2.1.1.3" xref="S5.SS2.SSS0.Px2.p1.2.m2.1.1.3.cmml">g</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px2.p1.2.m2.1b"><apply id="S5.SS2.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S5.SS2.SSS0.Px2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS0.Px2.p1.2.m2.1.1.1.cmml" xref="S5.SS2.SSS0.Px2.p1.2.m2.1.1">subscript</csymbol><ci id="S5.SS2.SSS0.Px2.p1.2.m2.1.1.2.cmml" xref="S5.SS2.SSS0.Px2.p1.2.m2.1.1.2">ğœ½</ci><ci id="S5.SS2.SSS0.Px2.p1.2.m2.1.1.3.cmml" xref="S5.SS2.SSS0.Px2.p1.2.m2.1.1.3">ğ‘”</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px2.p1.2.m2.1c">\bm{\theta}_{g}</annotation></semantics></math> at each batch in local training, few updates of <math id="S5.SS2.SSS0.Px2.p1.3.m3.1" class="ltx_Math" alttext="\bm{\theta}_{g}" display="inline"><semantics id="S5.SS2.SSS0.Px2.p1.3.m3.1a"><msub id="S5.SS2.SSS0.Px2.p1.3.m3.1.1" xref="S5.SS2.SSS0.Px2.p1.3.m3.1.1.cmml"><mi id="S5.SS2.SSS0.Px2.p1.3.m3.1.1.2" xref="S5.SS2.SSS0.Px2.p1.3.m3.1.1.2.cmml">ğœ½</mi><mi id="S5.SS2.SSS0.Px2.p1.3.m3.1.1.3" xref="S5.SS2.SSS0.Px2.p1.3.m3.1.1.3.cmml">g</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px2.p1.3.m3.1b"><apply id="S5.SS2.SSS0.Px2.p1.3.m3.1.1.cmml" xref="S5.SS2.SSS0.Px2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS0.Px2.p1.3.m3.1.1.1.cmml" xref="S5.SS2.SSS0.Px2.p1.3.m3.1.1">subscript</csymbol><ci id="S5.SS2.SSS0.Px2.p1.3.m3.1.1.2.cmml" xref="S5.SS2.SSS0.Px2.p1.3.m3.1.1.2">ğœ½</ci><ci id="S5.SS2.SSS0.Px2.p1.3.m3.1.1.3.cmml" xref="S5.SS2.SSS0.Px2.p1.3.m3.1.1.3">ğ‘”</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px2.p1.3.m3.1c">\bm{\theta}_{g}</annotation></semantics></math> on the adversarial client hinder the injection of backdoor signatures. Therefore, we test Blended attack performance on ResNet-18 and ConvNet on CIFAR-10 while increasing the number of local epochs from the original <math id="S5.SS2.SSS0.Px2.p1.4.m4.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S5.SS2.SSS0.Px2.p1.4.m4.1a"><mn id="S5.SS2.SSS0.Px2.p1.4.m4.1.1" xref="S5.SS2.SSS0.Px2.p1.4.m4.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px2.p1.4.m4.1b"><cn type="integer" id="S5.SS2.SSS0.Px2.p1.4.m4.1.1.cmml" xref="S5.SS2.SSS0.Px2.p1.4.m4.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px2.p1.4.m4.1c">3</annotation></semantics></math> to <math id="S5.SS2.SSS0.Px2.p1.5.m5.1" class="ltx_Math" alttext="6" display="inline"><semantics id="S5.SS2.SSS0.Px2.p1.5.m5.1a"><mn id="S5.SS2.SSS0.Px2.p1.5.m5.1.1" xref="S5.SS2.SSS0.Px2.p1.5.m5.1.1.cmml">6</mn><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px2.p1.5.m5.1b"><cn type="integer" id="S5.SS2.SSS0.Px2.p1.5.m5.1.1.cmml" xref="S5.SS2.SSS0.Px2.p1.5.m5.1.1">6</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px2.p1.5.m5.1c">6</annotation></semantics></math>. The results are shown in FigureÂ <a href="#S5.F8" title="Figure 8 â€£ pFedMe â€£ 5.2. pFL Methods with Full model-sharing â€£ 5. Analysis of Various Robustness from pFL Against Backdoor Attacks â€£ Revisiting Personalized Federated Learning: Robustness Against Backdoor Attacks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>. We can observe that ASR increases by <math id="S5.SS2.SSS0.Px2.p1.6.m6.1" class="ltx_Math" alttext="15\%" display="inline"><semantics id="S5.SS2.SSS0.Px2.p1.6.m6.1a"><mrow id="S5.SS2.SSS0.Px2.p1.6.m6.1.1" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.cmml"><mn id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.2" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.2.cmml">15</mn><mo id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px2.p1.6.m6.1b"><apply id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.cmml" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1"><csymbol cd="latexml" id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.cmml" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1">percent</csymbol><cn type="integer" id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.2.cmml" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.2">15</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px2.p1.6.m6.1c">15\%</annotation></semantics></math> along with increasing local epoch number. This demonstrates that pFedMe is also vulnerable to backdoor attacks like Ditto.</p>
</div>
<figure id="S5.F8" class="ltx_figure"><img src="/html/2302.01677/assets/x9.png" id="S5.F8.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="147" height="97" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F8.2.1.1" class="ltx_text" style="font-size:90%;">Figure 8</span>. </span><span id="S5.F8.3.2" class="ltx_text" style="font-size:90%;">The results of Blended attack on pFedMe with the different number of local training epoches on CIFAR-10. Left: on ResNet-18; Right: on ConvNet.</span></figcaption>
</figure>
<figure id="S5.F9" class="ltx_figure"><img src="/html/2302.01677/assets/x10.png" id="S5.F9.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="210" height="91" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F9.2.1.1" class="ltx_text" style="font-size:90%;">Figure 9</span>. </span><span id="S5.F9.3.2" class="ltx_text" style="font-size:90%;">The results of Blended attack for FT with various epoch numbers on ConvNet and CIFAR-10.</span></figcaption>
</figure>
</section>
<section id="S5.SS2.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">FedEM</h5>

<div id="S5.SS2.SSS0.Px3.p1" class="ltx_para">
<p id="S5.SS2.SSS0.Px3.p1.1" class="ltx_p">In FedEMÂ <cite class="ltx_cite ltx_citemacro_citep">(Marfoq etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib39" title="" class="ltx_ref">2021</a>)</cite>, each client trains multiple base models on local datasets, and all base models are later uploaded to aggregate in the server. Therefore, backdoor features could be learned by the base models from adversarial clients and are later propagated to other clients by full model-sharing.</p>
</div>
</section>
<section id="S5.SS2.SSS0.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Fine-tuning.</h5>

<div id="S5.SS2.SSS0.Px4.p1" class="ltx_para">
<p id="S5.SS2.SSS0.Px4.p1.6" class="ltx_p">Fine-tuning (FT) is also a widely used backdoor defense method in centralized settingÂ <cite class="ltx_cite ltx_citemacro_citep">(Liu etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib37" title="" class="ltx_ref">2018</a>; Wu etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib55" title="" class="ltx_ref">2022a</a>; Huang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib25" title="" class="ltx_ref">2022</a>; Li etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib35" title="" class="ltx_ref">2021c</a>)</cite> which further updates trained model to forget backdoor triggers. However, we find it couldnâ€™t improve the robustness under FL setting. Specifically, we set the epoch number of FT as <math id="S5.SS2.SSS0.Px4.p1.1.m1.1" class="ltx_Math" alttext="5" display="inline"><semantics id="S5.SS2.SSS0.Px4.p1.1.m1.1a"><mn id="S5.SS2.SSS0.Px4.p1.1.m1.1.1" xref="S5.SS2.SSS0.Px4.p1.1.m1.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px4.p1.1.m1.1b"><cn type="integer" id="S5.SS2.SSS0.Px4.p1.1.m1.1.1.cmml" xref="S5.SS2.SSS0.Px4.p1.1.m1.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px4.p1.1.m1.1c">5</annotation></semantics></math>, <math id="S5.SS2.SSS0.Px4.p1.2.m2.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S5.SS2.SSS0.Px4.p1.2.m2.1a"><mn id="S5.SS2.SSS0.Px4.p1.2.m2.1.1" xref="S5.SS2.SSS0.Px4.p1.2.m2.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px4.p1.2.m2.1b"><cn type="integer" id="S5.SS2.SSS0.Px4.p1.2.m2.1.1.cmml" xref="S5.SS2.SSS0.Px4.p1.2.m2.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px4.p1.2.m2.1c">10</annotation></semantics></math>, <math id="S5.SS2.SSS0.Px4.p1.3.m3.1" class="ltx_Math" alttext="20" display="inline"><semantics id="S5.SS2.SSS0.Px4.p1.3.m3.1a"><mn id="S5.SS2.SSS0.Px4.p1.3.m3.1.1" xref="S5.SS2.SSS0.Px4.p1.3.m3.1.1.cmml">20</mn><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px4.p1.3.m3.1b"><cn type="integer" id="S5.SS2.SSS0.Px4.p1.3.m3.1.1.cmml" xref="S5.SS2.SSS0.Px4.p1.3.m3.1.1">20</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px4.p1.3.m3.1c">20</annotation></semantics></math>, and <math id="S5.SS2.SSS0.Px4.p1.4.m4.1" class="ltx_Math" alttext="50" display="inline"><semantics id="S5.SS2.SSS0.Px4.p1.4.m4.1a"><mn id="S5.SS2.SSS0.Px4.p1.4.m4.1.1" xref="S5.SS2.SSS0.Px4.p1.4.m4.1.1.cmml">50</mn><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px4.p1.4.m4.1b"><cn type="integer" id="S5.SS2.SSS0.Px4.p1.4.m4.1.1.cmml" xref="S5.SS2.SSS0.Px4.p1.4.m4.1.1">50</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px4.p1.4.m4.1c">50</annotation></semantics></math> to observe if the robustness will increase with the increase of FT epochs. The results on ConvNet and CIFAR-10 are shown in Figure <a href="#S5.F9" title="Figure 9 â€£ pFedMe â€£ 5.2. pFL Methods with Full model-sharing â€£ 5. Analysis of Various Robustness from pFL Against Backdoor Attacks â€£ Revisiting Personalized Federated Learning: Robustness Against Backdoor Attacks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>. Even if we use 50 epochs to conduct local Fine-tuning, ASR remains unchanged. The first potential reason is that there are no sufficient clean training examples for Fine-tuning to purify the backdoored global model. Training samples owned by each client are much less than training samples under centralized setting, which restricts the effect of Fine-tuning. Besides, it is also observed that FT couldnâ€™t effectively reduce ASR of backdoor attacks with low poisoning rateÂ <cite class="ltx_cite ltx_citemacro_citep">(Wu etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib55" title="" class="ltx_ref">2022a</a>)</cite>. Since there is only one adversarial client and <math id="S5.SS2.SSS0.Px4.p1.5.m5.1" class="ltx_Math" alttext="50\%" display="inline"><semantics id="S5.SS2.SSS0.Px4.p1.5.m5.1a"><mrow id="S5.SS2.SSS0.Px4.p1.5.m5.1.1" xref="S5.SS2.SSS0.Px4.p1.5.m5.1.1.cmml"><mn id="S5.SS2.SSS0.Px4.p1.5.m5.1.1.2" xref="S5.SS2.SSS0.Px4.p1.5.m5.1.1.2.cmml">50</mn><mo id="S5.SS2.SSS0.Px4.p1.5.m5.1.1.1" xref="S5.SS2.SSS0.Px4.p1.5.m5.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px4.p1.5.m5.1b"><apply id="S5.SS2.SSS0.Px4.p1.5.m5.1.1.cmml" xref="S5.SS2.SSS0.Px4.p1.5.m5.1.1"><csymbol cd="latexml" id="S5.SS2.SSS0.Px4.p1.5.m5.1.1.1.cmml" xref="S5.SS2.SSS0.Px4.p1.5.m5.1.1.1">percent</csymbol><cn type="integer" id="S5.SS2.SSS0.Px4.p1.5.m5.1.1.2.cmml" xref="S5.SS2.SSS0.Px4.p1.5.m5.1.1.2">50</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px4.p1.5.m5.1c">50\%</annotation></semantics></math> of training samples of the adversarial client are backdoor samples in our evaluations, the proportion of poisoned samples in all training samples is still very low with only <math id="S5.SS2.SSS0.Px4.p1.6.m6.1" class="ltx_Math" alttext="0.55\%" display="inline"><semantics id="S5.SS2.SSS0.Px4.p1.6.m6.1a"><mrow id="S5.SS2.SSS0.Px4.p1.6.m6.1.1" xref="S5.SS2.SSS0.Px4.p1.6.m6.1.1.cmml"><mn id="S5.SS2.SSS0.Px4.p1.6.m6.1.1.2" xref="S5.SS2.SSS0.Px4.p1.6.m6.1.1.2.cmml">0.55</mn><mo id="S5.SS2.SSS0.Px4.p1.6.m6.1.1.1" xref="S5.SS2.SSS0.Px4.p1.6.m6.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px4.p1.6.m6.1b"><apply id="S5.SS2.SSS0.Px4.p1.6.m6.1.1.cmml" xref="S5.SS2.SSS0.Px4.p1.6.m6.1.1"><csymbol cd="latexml" id="S5.SS2.SSS0.Px4.p1.6.m6.1.1.1.cmml" xref="S5.SS2.SSS0.Px4.p1.6.m6.1.1.1">percent</csymbol><cn type="float" id="S5.SS2.SSS0.Px4.p1.6.m6.1.1.2.cmml" xref="S5.SS2.SSS0.Px4.p1.6.m6.1.1.2">0.55</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px4.p1.6.m6.1c">0.55\%</annotation></semantics></math> (275/50000).</p>
</div>
<figure id="S5.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S5.T1.9.1.1" class="ltx_text" style="font-size:90%;">Table 1</span>. </span><span id="S5.T1.10.2" class="ltx_text" style="font-size:90%;">The results on ResNet-18 and ConvNet models on CIFAR-10 dataset. We adopt trained models from FedAvg and Ditto methods. A lower ASR means better robustness. A higher ACC means better C-Acc. The best results are highlighted in <span id="S5.T1.10.2.1" class="ltx_text ltx_font_bold">bold</span>.</span></figcaption>
<div id="S5.T1.6" class="ltx_inline-block ltx_transformed_outer" style="width:305.0pt;height:136.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-48.2pt,21.6pt) scale(0.76,0.76) ;">
<table id="S5.T1.6.6" class="ltx_tabular ltx_align_middle">
<tr id="S5.T1.6.6.7" class="ltx_tr">
<td id="S5.T1.6.6.7.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="2"><span id="S5.T1.6.6.7.1.1" class="ltx_text">Models</span></td>
<td id="S5.T1.6.6.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Methods</td>
<td id="S5.T1.6.6.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2">original</td>
<td id="S5.T1.6.6.7.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2">+ FT-linear</td>
<td id="S5.T1.6.6.7.5" class="ltx_td ltx_align_center ltx_border_t" colspan="2">+ ST</td>
</tr>
<tr id="S5.T1.6.6.6" class="ltx_tr">
<td id="S5.T1.6.6.6.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Attacks</td>
<td id="S5.T1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_t">ASR(<math id="S5.T1.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T1.1.1.1.1.m1.1a"><mo stretchy="false" id="S5.T1.1.1.1.1.m1.1.1" xref="S5.T1.1.1.1.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S5.T1.1.1.1.1.m1.1b"><ci id="S5.T1.1.1.1.1.m1.1.1.cmml" xref="S5.T1.1.1.1.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math>)</td>
<td id="S5.T1.2.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Acc(<math id="S5.T1.2.2.2.2.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S5.T1.2.2.2.2.m1.1a"><mo stretchy="false" id="S5.T1.2.2.2.2.m1.1.1" xref="S5.T1.2.2.2.2.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S5.T1.2.2.2.2.m1.1b"><ci id="S5.T1.2.2.2.2.m1.1.1.cmml" xref="S5.T1.2.2.2.2.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.2.2.2.2.m1.1c">\uparrow</annotation></semantics></math>)</td>
<td id="S5.T1.3.3.3.3" class="ltx_td ltx_align_center ltx_border_t">ASR(<math id="S5.T1.3.3.3.3.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T1.3.3.3.3.m1.1a"><mo stretchy="false" id="S5.T1.3.3.3.3.m1.1.1" xref="S5.T1.3.3.3.3.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S5.T1.3.3.3.3.m1.1b"><ci id="S5.T1.3.3.3.3.m1.1.1.cmml" xref="S5.T1.3.3.3.3.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.3.3.3.3.m1.1c">\downarrow</annotation></semantics></math>)</td>
<td id="S5.T1.4.4.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Acc(<math id="S5.T1.4.4.4.4.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S5.T1.4.4.4.4.m1.1a"><mo stretchy="false" id="S5.T1.4.4.4.4.m1.1.1" xref="S5.T1.4.4.4.4.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S5.T1.4.4.4.4.m1.1b"><ci id="S5.T1.4.4.4.4.m1.1.1.cmml" xref="S5.T1.4.4.4.4.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.4.4.4.4.m1.1c">\uparrow</annotation></semantics></math>)</td>
<td id="S5.T1.5.5.5.5" class="ltx_td ltx_align_center ltx_border_t">ASR(<math id="S5.T1.5.5.5.5.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T1.5.5.5.5.m1.1a"><mo stretchy="false" id="S5.T1.5.5.5.5.m1.1.1" xref="S5.T1.5.5.5.5.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S5.T1.5.5.5.5.m1.1b"><ci id="S5.T1.5.5.5.5.m1.1.1.cmml" xref="S5.T1.5.5.5.5.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.5.5.5.5.m1.1c">\downarrow</annotation></semantics></math>)</td>
<td id="S5.T1.6.6.6.6" class="ltx_td ltx_align_center ltx_border_t">Acc(<math id="S5.T1.6.6.6.6.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S5.T1.6.6.6.6.m1.1a"><mo stretchy="false" id="S5.T1.6.6.6.6.m1.1.1" xref="S5.T1.6.6.6.6.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S5.T1.6.6.6.6.m1.1b"><ci id="S5.T1.6.6.6.6.m1.1.1.cmml" xref="S5.T1.6.6.6.6.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.6.6.6.6.m1.1c">\uparrow</annotation></semantics></math>)</td>
</tr>
<tr id="S5.T1.6.6.8" class="ltx_tr">
<td id="S5.T1.6.6.8.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="2"><span id="S5.T1.6.6.8.1.1" class="ltx_text">Res18@FedAvg</span></td>
<td id="S5.T1.6.6.8.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">BadNet</td>
<td id="S5.T1.6.6.8.3" class="ltx_td ltx_align_center ltx_border_t">89.2</td>
<td id="S5.T1.6.6.8.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">78.1</td>
<td id="S5.T1.6.6.8.5" class="ltx_td ltx_align_center ltx_border_t">90.1</td>
<td id="S5.T1.6.6.8.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">76.8</td>
<td id="S5.T1.6.6.8.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T1.6.6.8.7.1" class="ltx_text ltx_font_bold">39.3</span></td>
<td id="S5.T1.6.6.8.8" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T1.6.6.8.8.1" class="ltx_text ltx_font_bold">80.9</span></td>
</tr>
<tr id="S5.T1.6.6.9" class="ltx_tr">
<td id="S5.T1.6.6.9.1" class="ltx_td ltx_align_center ltx_border_r">Blended</td>
<td id="S5.T1.6.6.9.2" class="ltx_td ltx_align_center">97.5</td>
<td id="S5.T1.6.6.9.3" class="ltx_td ltx_align_center ltx_border_r">78.1</td>
<td id="S5.T1.6.6.9.4" class="ltx_td ltx_align_center">97.4</td>
<td id="S5.T1.6.6.9.5" class="ltx_td ltx_align_center ltx_border_r">76.7</td>
<td id="S5.T1.6.6.9.6" class="ltx_td ltx_align_center"><span id="S5.T1.6.6.9.6.1" class="ltx_text ltx_font_bold">47.2</span></td>
<td id="S5.T1.6.6.9.7" class="ltx_td ltx_align_center"><span id="S5.T1.6.6.9.7.1" class="ltx_text ltx_font_bold">81.1</span></td>
</tr>
<tr id="S5.T1.6.6.10" class="ltx_tr">
<td id="S5.T1.6.6.10.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="2"><span id="S5.T1.6.6.10.1.1" class="ltx_text">Conv@FedAvg</span></td>
<td id="S5.T1.6.6.10.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">BadNet</td>
<td id="S5.T1.6.6.10.3" class="ltx_td ltx_align_center ltx_border_t">76.5</td>
<td id="S5.T1.6.6.10.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">74.4</td>
<td id="S5.T1.6.6.10.5" class="ltx_td ltx_align_center ltx_border_t">71.0</td>
<td id="S5.T1.6.6.10.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">74.8</td>
<td id="S5.T1.6.6.10.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T1.6.6.10.7.1" class="ltx_text ltx_font_bold">6.4</span></td>
<td id="S5.T1.6.6.10.8" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T1.6.6.10.8.1" class="ltx_text ltx_font_bold">76.0</span></td>
</tr>
<tr id="S5.T1.6.6.11" class="ltx_tr">
<td id="S5.T1.6.6.11.1" class="ltx_td ltx_align_center ltx_border_r">Blended</td>
<td id="S5.T1.6.6.11.2" class="ltx_td ltx_align_center">76.7</td>
<td id="S5.T1.6.6.11.3" class="ltx_td ltx_align_center ltx_border_r">74.5</td>
<td id="S5.T1.6.6.11.4" class="ltx_td ltx_align_center">77.1</td>
<td id="S5.T1.6.6.11.5" class="ltx_td ltx_align_center ltx_border_r">74.7</td>
<td id="S5.T1.6.6.11.6" class="ltx_td ltx_align_center"><span id="S5.T1.6.6.11.6.1" class="ltx_text ltx_font_bold">13.8</span></td>
<td id="S5.T1.6.6.11.7" class="ltx_td ltx_align_center"><span id="S5.T1.6.6.11.7.1" class="ltx_text ltx_font_bold">76.1</span></td>
</tr>
<tr id="S5.T1.6.6.12" class="ltx_tr">
<td id="S5.T1.6.6.12.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="2"><span id="S5.T1.6.6.12.1.1" class="ltx_text">Res18@Ditto</span></td>
<td id="S5.T1.6.6.12.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">BadNet</td>
<td id="S5.T1.6.6.12.3" class="ltx_td ltx_align_center ltx_border_t">85.1</td>
<td id="S5.T1.6.6.12.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">76.5</td>
<td id="S5.T1.6.6.12.5" class="ltx_td ltx_align_center ltx_border_t">86.2</td>
<td id="S5.T1.6.6.12.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">74.5</td>
<td id="S5.T1.6.6.12.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T1.6.6.12.7.1" class="ltx_text ltx_font_bold">38.9</span></td>
<td id="S5.T1.6.6.12.8" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T1.6.6.12.8.1" class="ltx_text ltx_font_bold">80.8</span></td>
</tr>
<tr id="S5.T1.6.6.13" class="ltx_tr">
<td id="S5.T1.6.6.13.1" class="ltx_td ltx_align_center ltx_border_r">Blended</td>
<td id="S5.T1.6.6.13.2" class="ltx_td ltx_align_center">95.6</td>
<td id="S5.T1.6.6.13.3" class="ltx_td ltx_align_center ltx_border_r">76.6</td>
<td id="S5.T1.6.6.13.4" class="ltx_td ltx_align_center">95.7</td>
<td id="S5.T1.6.6.13.5" class="ltx_td ltx_align_center ltx_border_r">74.4</td>
<td id="S5.T1.6.6.13.6" class="ltx_td ltx_align_center"><span id="S5.T1.6.6.13.6.1" class="ltx_text ltx_font_bold">47.1</span></td>
<td id="S5.T1.6.6.13.7" class="ltx_td ltx_align_center"><span id="S5.T1.6.6.13.7.1" class="ltx_text ltx_font_bold">81.2</span></td>
</tr>
<tr id="S5.T1.6.6.14" class="ltx_tr">
<td id="S5.T1.6.6.14.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" rowspan="2"><span id="S5.T1.6.6.14.1.1" class="ltx_text">Conv@Ditto</span></td>
<td id="S5.T1.6.6.14.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">BadNet</td>
<td id="S5.T1.6.6.14.3" class="ltx_td ltx_align_center ltx_border_t">71.2</td>
<td id="S5.T1.6.6.14.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T1.6.6.14.4.1" class="ltx_text ltx_font_bold">77.9</span></td>
<td id="S5.T1.6.6.14.5" class="ltx_td ltx_align_center ltx_border_t">72.6</td>
<td id="S5.T1.6.6.14.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">76.5</td>
<td id="S5.T1.6.6.14.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T1.6.6.14.7.1" class="ltx_text ltx_font_bold">5.6</span></td>
<td id="S5.T1.6.6.14.8" class="ltx_td ltx_align_center ltx_border_t">76.7</td>
</tr>
<tr id="S5.T1.6.6.15" class="ltx_tr">
<td id="S5.T1.6.6.15.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">Blended</td>
<td id="S5.T1.6.6.15.2" class="ltx_td ltx_align_center ltx_border_b">76.8</td>
<td id="S5.T1.6.6.15.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S5.T1.6.6.15.3.1" class="ltx_text ltx_font_bold">77.8</span></td>
<td id="S5.T1.6.6.15.4" class="ltx_td ltx_align_center ltx_border_b">77.1</td>
<td id="S5.T1.6.6.15.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">76.6</td>
<td id="S5.T1.6.6.15.6" class="ltx_td ltx_align_center ltx_border_b"><span id="S5.T1.6.6.15.6.1" class="ltx_text ltx_font_bold">17.4</span></td>
<td id="S5.T1.6.6.15.7" class="ltx_td ltx_align_center ltx_border_b">76.8</td>
</tr>
</table>
</span></div>
</figure>
</section>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6. </span>Improving Backdoor Robustness with Simple-Tuning</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">In previous sections, we observed that pFL methods with partial model-sharing could achieve better robustness against backdoor attacks. By conducting detailed studies on them in SectionÂ <a href="#S5.SS1" title="5.1. pFL Methods with Partial model-sharing â€£ 5. Analysis of Various Robustness from pFL Against Backdoor Attacks â€£ Revisiting Personalized Federated Learning: Robustness Against Backdoor Attacks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.1</span></a>, we found that locally trained BN layers in FedBN or locally trained linear classifiers in FedRep plays the key roles in improving robustness. Therefore, it is natural to consider, whether can we provide some insight for designing better robust FL methods to further boost robustness based on our findings and analyses? In this section, we take an initial step by providing a simple but effective defense method.</p>
</div>
<div id="S6.p2" class="ltx_para">
<p id="S6.p2.1" class="ltx_p">Based on the idea of locally training a linear classifier of FedRep, we propose <span id="S6.p2.1.1" class="ltx_text ltx_font_italic">Simple-Tuning</span> which only tunes the linear classifier of FL models of each client after the training process. Specifically, we first <span id="S6.p2.1.2" class="ltx_text ltx_font_bold">reinitialize</span> the linear classifier and <span id="S6.p2.1.3" class="ltx_text ltx_font_bold">retrain</span> it with the local training dataset of each client, while freezing the remaining parameters of each model. Compared with vanilla Fine-tuning, Simple-Tuning (ST) has made two improvements: <span id="S6.p2.1.4" class="ltx_text ltx_font_bold">(1)</span> Compared with tuning the whole model in FT, we only tune the linear classifier after finishing the training process, which could efficiently reduce computation costs; <span id="S6.p2.1.5" class="ltx_text ltx_font_bold">(2)</span> Rather than inheriting parameters of original models like FT, we choose to reinitialize and retrain local linear classifier on local datasets.</p>
</div>
<div id="S6.p3" class="ltx_para">
<p id="S6.p3.5" class="ltx_p">We test our method on trained models from FedAvg and Ditto and show defense performances against BadNet and Blended attacks. For Simple-Tuning, we adopt default Kaiming Uniform normalizationÂ <cite class="ltx_cite ltx_citemacro_citep">(He etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib23" title="" class="ltx_ref">2015</a>)</cite> and use the constant learning rate as <math id="S6.p3.1.m1.1" class="ltx_Math" alttext="0.005" display="inline"><semantics id="S6.p3.1.m1.1a"><mn id="S6.p3.1.m1.1.1" xref="S6.p3.1.m1.1.1.cmml">0.005</mn><annotation-xml encoding="MathML-Content" id="S6.p3.1.m1.1b"><cn type="float" id="S6.p3.1.m1.1.1.cmml" xref="S6.p3.1.m1.1.1">0.005</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p3.1.m1.1c">0.005</annotation></semantics></math>. We only tune the linear classifier for <math id="S6.p3.2.m2.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S6.p3.2.m2.1a"><mn id="S6.p3.2.m2.1.1" xref="S6.p3.2.m2.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S6.p3.2.m2.1b"><cn type="integer" id="S6.p3.2.m2.1.1.cmml" xref="S6.p3.2.m2.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p3.2.m2.1c">10</annotation></semantics></math> epochs. The results containing ASR and C-Acc on ResNet-18 and ConvNet models are shown in TableÂ <a href="#S5.T1" title="Table 1 â€£ Fine-tuning. â€£ 5.2. pFL Methods with Full model-sharing â€£ 5. Analysis of Various Robustness from pFL Against Backdoor Attacks â€£ Revisiting Personalized Federated Learning: Robustness Against Backdoor Attacks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. We compare the results of our method with the results of original FedAvg and Ditto models and models from only fine-tuning local linear classifiers without reinitialization. We denote the latter as FT-linear. As shown in TableÂ <a href="#S5.T1" title="Table 1 â€£ Fine-tuning. â€£ 5.2. pFL Methods with Full model-sharing â€£ 5. Analysis of Various Robustness from pFL Against Backdoor Attacks â€£ Revisiting Personalized Federated Learning: Robustness Against Backdoor Attacks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, our method, Simple-Tuning, significantly improves robustness against backdoor attacks. Compared with original models, it efficiently reduces the ASR of two backdoor attacks by <math id="S6.p3.3.m3.1" class="ltx_Math" alttext="56.6\%" display="inline"><semantics id="S6.p3.3.m3.1a"><mrow id="S6.p3.3.m3.1.1" xref="S6.p3.3.m3.1.1.cmml"><mn id="S6.p3.3.m3.1.1.2" xref="S6.p3.3.m3.1.1.2.cmml">56.6</mn><mo id="S6.p3.3.m3.1.1.1" xref="S6.p3.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.p3.3.m3.1b"><apply id="S6.p3.3.m3.1.1.cmml" xref="S6.p3.3.m3.1.1"><csymbol cd="latexml" id="S6.p3.3.m3.1.1.1.cmml" xref="S6.p3.3.m3.1.1.1">percent</csymbol><cn type="float" id="S6.p3.3.m3.1.1.2.cmml" xref="S6.p3.3.m3.1.1.2">56.6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.p3.3.m3.1c">56.6\%</annotation></semantics></math> on average. It achieves better robustness on smaller model ConvNet, reducing ASR below <math id="S6.p3.4.m4.1" class="ltx_Math" alttext="20\%" display="inline"><semantics id="S6.p3.4.m4.1a"><mrow id="S6.p3.4.m4.1.1" xref="S6.p3.4.m4.1.1.cmml"><mn id="S6.p3.4.m4.1.1.2" xref="S6.p3.4.m4.1.1.2.cmml">20</mn><mo id="S6.p3.4.m4.1.1.1" xref="S6.p3.4.m4.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.p3.4.m4.1b"><apply id="S6.p3.4.m4.1.1.cmml" xref="S6.p3.4.m4.1.1"><csymbol cd="latexml" id="S6.p3.4.m4.1.1.1.cmml" xref="S6.p3.4.m4.1.1.1">percent</csymbol><cn type="integer" id="S6.p3.4.m4.1.1.2.cmml" xref="S6.p3.4.m4.1.1.2">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.p3.4.m4.1c">20\%</annotation></semantics></math>. Surprisingly, Simple-Tuning even improves the C-Acc of FL methods except for Ditto on ConvNet. These results demonstrate the great potential of Simple-Tuning. It is worth noting that FT-linear does not show any robustness like vanilla FT. It also verifies the importance of reinitialization in our method to backdoor robustness. This suggests that directly fine-tuning FL backdoor models may not efficiently remove backdoor triggers. It also contrasts with findings of <cite class="ltx_cite ltx_citemacro_citep">(Adi etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib2" title="" class="ltx_ref">2018</a>)</cite> which utilizes FT methods to purify watermark, specific backdoor trigger, in DNN models. However, they demonstrated that all three methods - vanilla FT, FT-linear, and FT-linear with randomized linear classifier - can effectively purify watermark triggers. We believe this is mainly because triggers of the watermark are set differently from the general backdoor triggers. In <cite class="ltx_cite ltx_citemacro_citep">(Adi etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib2" title="" class="ltx_ref">2018</a>)</cite>, the authors set <math id="S6.p3.5.m5.1" class="ltx_Math" alttext="\bm{y}_{t}" display="inline"><semantics id="S6.p3.5.m5.1a"><msub id="S6.p3.5.m5.1.1" xref="S6.p3.5.m5.1.1.cmml"><mi id="S6.p3.5.m5.1.1.2" xref="S6.p3.5.m5.1.1.2.cmml">ğ’š</mi><mi id="S6.p3.5.m5.1.1.3" xref="S6.p3.5.m5.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S6.p3.5.m5.1b"><apply id="S6.p3.5.m5.1.1.cmml" xref="S6.p3.5.m5.1.1"><csymbol cd="ambiguous" id="S6.p3.5.m5.1.1.1.cmml" xref="S6.p3.5.m5.1.1">subscript</csymbol><ci id="S6.p3.5.m5.1.1.2.cmml" xref="S6.p3.5.m5.1.1.2">ğ’š</ci><ci id="S6.p3.5.m5.1.1.3.cmml" xref="S6.p3.5.m5.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.p3.5.m5.1c">\bm{y}_{t}</annotation></semantics></math> of each watermarked sample to a randomly chosen label, rather than a fixed target label as in backdoor attacks.</p>
</div>
<div id="S6.p4" class="ltx_para">
<p id="S6.p4.1" class="ltx_p">By only tuning the linear classifier, Simple-Tuning is easier to be combined with existing FL methods. It is also more convenient to deploy in real-world scenarios with significantly reduced computation costs. However, Simple-Tuning still couldnâ€™t completely eliminate security risks from backdoor attacks. We hope it could inspire future work to propose better defense mechanisms, such as using more advanced optimizers and designing better FT methods.</p>
</div>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7. </span>Conclusion</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">This paper studies the robustness of popular personalized FL methods against backdoor attacks in FL. We conduct the first study of backdoor attacks in the pFL framework, testing 4 widely used backdoor attacks against 6 pFL methods on benchmark datasets FEMNIST and CIFAR-10, a total of 600 experiments. We show that pFL methods with partial model-sharing achieve outstanding robustness against backdoor attacks. Based on our in-depth ablation studies on various pFL methods, we find there is a strong positive correlation between robustness and a larger personalization degree. Inspired by our findings, we further propose a simple defense method that could effectively alleviate backdoor attacks with much fewer computational costs. We make two
categories of conclusions:</p>
</div>
<section id="S7.SS0.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Next steps for researchers</h5>

<div id="S7.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S7.SS0.SSS0.Px1.p1.1" class="ltx_p">We have shown that FedRep and our Simple-Tuning achieve good defense performance. It is an interesting question if there is a new way to design stronger backdoor attacks that reduce the effectiveness of FedRep and bypass our Simple-Tuning. It could help us better foresee potential security risks.
Another direction is to design a better defense method suitable for FL settings. We should consider both defense performance and requirements of real-world scenarios like limited computational resources.</p>
</div>
</section>
<section id="S7.SS0.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Next steps for practitioners</h5>

<div id="S7.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S7.SS0.SSS0.Px2.p1.1" class="ltx_p">The security threat, black-box backdoor attacks, we expose is immediately practical and lead to non-negligible risks. Therefore, this vulnerability will need to be considered during the deployment of FL models. Both improving prediction accuracy under Non-IID setting and boosting backdoor robustness, pFL methods with partial model-sharing may be better choices in real-world applications.</p>
</div>
</section>
</section>
<section id="S8" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8. </span>Acknowledgements</h2>

<div id="S8.p1" class="ltx_para">
<p id="S8.p1.1" class="ltx_p">Zeyu Qin was supported by Alibaba Group through Alibaba Research Intern Program.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">        




</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Adi etÂ al<span id="bib.bib2.6.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Yossi Adi, Carsten Baum,
Moustapha Cisse, Benny Pinkas, and
Joseph Keshet. 2018.

</span>
<span class="ltx_bibblock">Turning your weakness into a strength: Watermarking
deep neural networks by backdooring. In <em id="bib.bib2.4.4" class="ltx_emph ltx_font_italic">27th
<math id="bib.bib2.1.1.m1.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib2.1.1.m1.1a"><mo stretchy="false" id="bib.bib2.1.1.m1.1.1" xref="bib.bib2.1.1.m1.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib2.1.1.m1.1b"><ci id="bib.bib2.1.1.m1.1.1.cmml" xref="bib.bib2.1.1.m1.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib2.1.1.m1.1c">\{</annotation></semantics></math>USENIX<math id="bib.bib2.2.2.m2.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib2.2.2.m2.1a"><mo stretchy="false" id="bib.bib2.2.2.m2.1.1" xref="bib.bib2.2.2.m2.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib2.2.2.m2.1b"><ci id="bib.bib2.2.2.m2.1.1.cmml" xref="bib.bib2.2.2.m2.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib2.2.2.m2.1c">\}</annotation></semantics></math> Security Symposium (<math id="bib.bib2.3.3.m3.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib2.3.3.m3.1a"><mo stretchy="false" id="bib.bib2.3.3.m3.1.1" xref="bib.bib2.3.3.m3.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib2.3.3.m3.1b"><ci id="bib.bib2.3.3.m3.1.1.cmml" xref="bib.bib2.3.3.m3.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib2.3.3.m3.1c">\{</annotation></semantics></math>USENIX<math id="bib.bib2.4.4.m4.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib2.4.4.m4.1a"><mo stretchy="false" id="bib.bib2.4.4.m4.1.1" xref="bib.bib2.4.4.m4.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib2.4.4.m4.1b"><ci id="bib.bib2.4.4.m4.1.1.cmml" xref="bib.bib2.4.4.m4.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib2.4.4.m4.1c">\}</annotation></semantics></math> Security 18)</em>.
1615â€“1631.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Arivazhagan etÂ al<span id="bib.bib3.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
ManojÂ Ghuhan Arivazhagan,
Vinay Aggarwal, AadityaÂ Kumar Singh,
and Sunav Choudhary. 2019.

</span>
<span class="ltx_bibblock">Federated learning with personalization layers.

</span>
<span class="ltx_bibblock"><em id="bib.bib3.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1912.00818</em>
(2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bagdasaryan etÂ al<span id="bib.bib4.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Eugene Bagdasaryan,
Andreas Veit, Yiqing Hua,
Deborah Estrin, and Vitaly Shmatikov.
2020.

</span>
<span class="ltx_bibblock">How to backdoor federated learning. In
<em id="bib.bib4.3.1" class="ltx_emph ltx_font_italic">International Conference on Artificial Intelligence
and Statistics</em>. PMLR, 2938â€“2948.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Barni etÂ al<span id="bib.bib5.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Mauro Barni, Kassem
Kallas, and Benedetta Tondi.
2019.

</span>
<span class="ltx_bibblock">A new backdoor attack in cnns by training set
corruption without label poisoning. In <em id="bib.bib5.3.1" class="ltx_emph ltx_font_italic">2019 IEEE
International Conference on Image Processing (ICIP)</em>. IEEE,
101â€“105.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Baruch etÂ al<span id="bib.bib6.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Gilad Baruch, Moran
Baruch, and Yoav Goldberg.
2019.

</span>
<span class="ltx_bibblock">A little is enough: Circumventing defenses for
distributed learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib6.3.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing
Systems</em> 32 (2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bhagoji etÂ al<span id="bib.bib7.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
ArjunÂ Nitin Bhagoji,
Supriyo Chakraborty, Prateek Mittal,
and Seraphin Calo. 2019.

</span>
<span class="ltx_bibblock">Analyzing federated learning through an adversarial
lens. In <em id="bib.bib7.3.1" class="ltx_emph ltx_font_italic">International Conference on Machine
Learning</em>. PMLR, 634â€“643.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Blanchard etÂ al<span id="bib.bib8.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Peva Blanchard, ElÂ Mahdi
ElÂ Mhamdi, Rachid Guerraoui, and Julien
Stainer. 2017.

</span>
<span class="ltx_bibblock">Machine learning with adversaries: Byzantine
tolerant gradient descent.

</span>
<span class="ltx_bibblock"><em id="bib.bib8.3.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing
Systems</em> 30 (2017).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Caldas etÂ al<span id="bib.bib9.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Sebastian Caldas, Sai
MeherÂ Karthik Duddu, Peter Wu, Tian Li,
Jakub KoneÄná»³, HÂ Brendan
McMahan, Virginia Smith, and Ameet
Talwalkar. 2018.

</span>
<span class="ltx_bibblock">Leaf: A benchmark for federated settings.

</span>
<span class="ltx_bibblock"><em id="bib.bib9.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1812.01097</em>
(2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen etÂ al<span id="bib.bib10.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Daoyuan Chen, Dawei Gao,
Weirui Kuang, Yaliang Li, and
Bolin Ding. 2022.

</span>
<span class="ltx_bibblock">pFL-Bench: A Comprehensive Benchmark for
Personalized Federated Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib10.3.1" class="ltx_emph ltx_font_italic">Neural Information Processing Systems
(NeurIPS) Track on Datasets and Benchmarks</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen etÂ al<span id="bib.bib11.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Daoyuan Chen, Liuyi Yao,
Dawei Gao, Bolin Ding, and
Yaliang Li. 2023.

</span>
<span class="ltx_bibblock">Efficient Personalized Federated Learning via
Sparse Model-Adaptation. In <em id="bib.bib11.3.1" class="ltx_emph ltx_font_italic">International
Conference on Machine Learning</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen etÂ al<span id="bib.bib12.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Xinyun Chen, Chang Liu,
Bo Li, Kimberly Lu, and
Dawn Song. 2017.

</span>
<span class="ltx_bibblock">Targeted backdoor attacks on deep learning systems
using data poisoning.

</span>
<span class="ltx_bibblock"><em id="bib.bib12.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1712.05526</em>
(2017).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cohen etÂ al<span id="bib.bib13.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Gregory Cohen, Saeed
Afshar, Jonathan Tapson, and Andre
VanÂ Schaik. 2017.

</span>
<span class="ltx_bibblock">EMNIST: Extending MNIST to handwritten letters. In
<em id="bib.bib13.3.1" class="ltx_emph ltx_font_italic">2017 international joint conference on neural
networks (IJCNN)</em>. IEEE, 2921â€“2926.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Collins etÂ al<span id="bib.bib14.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Liam Collins, Hamed
Hassani, Aryan Mokhtari, and Sanjay
Shakkottai. 2021.

</span>
<span class="ltx_bibblock">Exploiting shared representations for personalized
federated learning. In <em id="bib.bib14.3.1" class="ltx_emph ltx_font_italic">International Conference on
Machine Learning</em>. PMLR, 2089â€“2099.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Du etÂ al<span id="bib.bib15.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Min Du, Ruoxi Jia, and
Dawn Song. 2020.

</span>
<span class="ltx_bibblock">Robust anomaly detection and backdoor attack
detection via differential privacy. In
<em id="bib.bib15.3.1" class="ltx_emph ltx_font_italic">International Conference on Learning
Representations</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">European Commission (2016)</span>
<span class="ltx_bibblock">
European Commission.
2016.

</span>
<span class="ltx_bibblock">Regulation (EU) 2016/679 of the European
Parliament and of the Council of 27 April 2016 on the protection of
natural persons with regard to the processing of personal data and on the
free movement of such data, and repealing Directive 95/46/EC (General
Data Protection Regulation) (Text with EEA relevance).

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://eur-lex.europa.eu/eli/reg/2016/679/oj" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://eur-lex.europa.eu/eli/reg/2016/679/oj</a>

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fallah etÂ al<span id="bib.bib17.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Alireza Fallah, Aryan
Mokhtari, and Asuman Ozdaglar.
2020.

</span>
<span class="ltx_bibblock">Personalized federated learning: A meta-learning
approach.

</span>
<span class="ltx_bibblock"><em id="bib.bib17.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2002.07948</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fang etÂ al<span id="bib.bib18.4.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Minghong Fang, Xiaoyu
Cao, Jinyuan Jia, and Neil Gong.
2020.

</span>
<span class="ltx_bibblock">Local model poisoning attacks to
<math id="bib.bib18.1.m1.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib18.1.m1.1a"><mo stretchy="false" id="bib.bib18.1.m1.1.1" xref="bib.bib18.1.m1.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib18.1.m1.1b"><ci id="bib.bib18.1.m1.1.1.cmml" xref="bib.bib18.1.m1.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib18.1.m1.1c">\{</annotation></semantics></math>Byzantine-Robust<math id="bib.bib18.2.m2.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib18.2.m2.1a"><mo stretchy="false" id="bib.bib18.2.m2.1.1" xref="bib.bib18.2.m2.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib18.2.m2.1b"><ci id="bib.bib18.2.m2.1.1.cmml" xref="bib.bib18.2.m2.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib18.2.m2.1c">\}</annotation></semantics></math> federated learning. In
<em id="bib.bib18.5.1" class="ltx_emph ltx_font_italic">29th USENIX Security Symposium (USENIX Security
20)</em>. 1605â€“1622.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Goldblum etÂ al<span id="bib.bib19.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Micah Goldblum, Dimitris
Tsipras, Chulin Xie, Xinyun Chen,
Avi Schwarzschild, Dawn Song,
Aleksander Madry, Bo Li, and
Tom Goldstein. 2022.

</span>
<span class="ltx_bibblock">Dataset security for machine learning: Data
poisoning, backdoor attacks, and defenses.

</span>
<span class="ltx_bibblock"><em id="bib.bib19.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Pattern Analysis and
Machine Intelligence</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gu etÂ al<span id="bib.bib20.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Tianyu Gu, Kang Liu,
Brendan Dolan-Gavitt, and Siddharth
Garg. 2019.

</span>
<span class="ltx_bibblock">Badnets: Evaluating backdooring attacks on deep
neural networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib20.3.1" class="ltx_emph ltx_font_italic">IEEE Access</em> 7
(2019), 47230â€“47244.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hanzely etÂ al<span id="bib.bib21.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Filip Hanzely, Boxin
Zhao, and Mladen Kolar.
2021.

</span>
<span class="ltx_bibblock">Personalized federated learning: A unified
framework and universal optimization techniques.

</span>
<span class="ltx_bibblock"><em id="bib.bib21.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2102.09743</em>
(2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hard etÂ al<span id="bib.bib22.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Andrew Hard, Kanishka
Rao, Rajiv Mathews, Swaroop Ramaswamy,
FranÃ§oise Beaufays, Sean
Augenstein, Hubert Eichner, ChloÃ©
Kiddon, and Daniel Ramage.
2018.

</span>
<span class="ltx_bibblock">Federated learning for mobile keyboard prediction.

</span>
<span class="ltx_bibblock"><em id="bib.bib22.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1811.03604</em>
(2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He etÂ al<span id="bib.bib23.2.2.1" class="ltx_text">.</span> (2015)</span>
<span class="ltx_bibblock">
Kaiming He, Xiangyu
Zhang, Shaoqing Ren, and Jian Sun.
2015.

</span>
<span class="ltx_bibblock">Delving deep into rectifiers: Surpassing
human-level performance on imagenet classification. In
<em id="bib.bib23.3.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE international conference on
computer vision</em>. 1026â€“1034.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He etÂ al<span id="bib.bib24.2.2.1" class="ltx_text">.</span> (2016)</span>
<span class="ltx_bibblock">
Kaiming He, Xiangyu
Zhang, Shaoqing Ren, and Jian Sun.
2016.

</span>
<span class="ltx_bibblock">Deep residual learning for image recognition. In
<em id="bib.bib24.3.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE conference on computer
vision and pattern recognition</em>. 770â€“778.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang etÂ al<span id="bib.bib25.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Kunzhe Huang, Yiming Li,
Baoyuan Wu, Zhan Qin, and
Kui Ren. 2022.

</span>
<span class="ltx_bibblock">Backdoor Defense via Decoupling the Training
Process. In <em id="bib.bib25.3.1" class="ltx_emph ltx_font_italic">International Conference on Learning
Representations</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang etÂ al<span id="bib.bib26.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Yangsibo Huang, Samyak
Gupta, Zhao Song, Kai Li, and
Sanjeev Arora. 2021.

</span>
<span class="ltx_bibblock">Evaluating gradient inversion attacks and defenses
in federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib26.3.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing
Systems</em> 34 (2021),
7232â€“7241.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kairouz etÂ al<span id="bib.bib27.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Peter Kairouz, HÂ Brendan
McMahan, Brendan Avent, AurÃ©lien
Bellet, Mehdi Bennis, ArjunÂ Nitin
Bhagoji, Kallista Bonawitz, Zachary
Charles, Graham Cormode, Rachel
Cummings, etÂ al<span id="bib.bib27.3.1" class="ltx_text">.</span> 2021.

</span>
<span class="ltx_bibblock">Advances and open problems in federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib27.4.1" class="ltx_emph ltx_font_italic">Foundations and TrendsÂ® in
Machine Learning</em> 14, 1â€“2
(2021), 1â€“210.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Khan etÂ al<span id="bib.bib28.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
LatifÂ U Khan, Walid Saad,
Zhu Han, Ekram Hossain, and
ChoongÂ Seon Hong. 2021.

</span>
<span class="ltx_bibblock">Federated learning for internet of things: Recent
advances, taxonomy, and open challenges.

</span>
<span class="ltx_bibblock"><em id="bib.bib28.3.1" class="ltx_emph ltx_font_italic">IEEE Communications Surveys &amp; Tutorials</em>
23, 3 (2021),
1759â€“1799.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Krizhevsky etÂ al<span id="bib.bib29.2.2.1" class="ltx_text">.</span> (2009)</span>
<span class="ltx_bibblock">
Alex Krizhevsky etÂ al<span id="bib.bib29.3.1" class="ltx_text">.</span>
2009.

</span>
<span class="ltx_bibblock">Learning multiple layers of features from tiny
images.

</span>
<span class="ltx_bibblock">(2009).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kusetogullari etÂ al<span id="bib.bib30.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Huseyin Kusetogullari,
Amir Yavariabdi, Abbas Cheddad,
HÃ¥kan Grahn, and Johan Hall.
2020.

</span>
<span class="ltx_bibblock">ARDIS: a Swedish historical handwritten digit
dataset.

</span>
<span class="ltx_bibblock"><em id="bib.bib30.3.1" class="ltx_emph ltx_font_italic">Neural Computing and Applications</em>
32, 21 (2020),
16505â€“16518.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li etÂ al<span id="bib.bib31.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Lisha Li, Kevin Jamieson,
Giulia DeSalvo, Afshin Rostamizadeh,
and Ameet Talwalkar. 2017.

</span>
<span class="ltx_bibblock">Hyperband: Bandit-Based Configuration Evaluation
for Hyperparameter Optimization. In <em id="bib.bib31.3.1" class="ltx_emph ltx_font_italic">International
Conference on Learning Representations</em>.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://openreview.net/forum?id=ry18Ww5ee" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://openreview.net/forum?id=ry18Ww5ee</a>

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li etÂ al<span id="bib.bib32.2.2.1" class="ltx_text">.</span> (2021a)</span>
<span class="ltx_bibblock">
Tian Li, Shengyuan Hu,
Ahmad Beirami, and Virginia Smith.
2021a.

</span>
<span class="ltx_bibblock">Ditto: Fair and robust federated learning through
personalization. In <em id="bib.bib32.3.1" class="ltx_emph ltx_font_italic">International Conference on
Machine Learning</em>. PMLR, 6357â€“6368.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li etÂ al<span id="bib.bib33.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Xiaoxiao Li, Yufeng Gu,
Nicha Dvornek, LawrenceÂ H Staib,
Pamela Ventola, and JamesÂ S Duncan.
2020.

</span>
<span class="ltx_bibblock">Multi-site fMRI analysis using privacy-preserving
federated learning and domain adaptation: ABIDE results.

</span>
<span class="ltx_bibblock"><em id="bib.bib33.3.1" class="ltx_emph ltx_font_italic">Medical Image Analysis</em>
65 (2020), 101765.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li etÂ al<span id="bib.bib34.2.2.1" class="ltx_text">.</span> (2021b)</span>
<span class="ltx_bibblock">
Xiaoxiao Li, Meirui
JIANG, Xiaofei Zhang, Michael Kamp,
and Qi Dou. 2021b.

</span>
<span class="ltx_bibblock">FedBN: Federated Learning on Non-IID Features
via Local Batch Normalization. In <em id="bib.bib34.3.1" class="ltx_emph ltx_font_italic">International
Conference on Learning Representations</em>.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://openreview.net/forum?id=6YEQUn0QICG" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://openreview.net/forum?id=6YEQUn0QICG</a>

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li etÂ al<span id="bib.bib35.2.2.1" class="ltx_text">.</span> (2021c)</span>
<span class="ltx_bibblock">
Yige Li, Xixiang Lyu,
Nodens Koren, Lingjuan Lyu,
Bo Li, and Xingjun Ma.
2021c.

</span>
<span class="ltx_bibblock">Neural Attention Distillation: Erasing Backdoor
Triggers from Deep Neural Networks. In
<em id="bib.bib35.3.1" class="ltx_emph ltx_font_italic">International Conference on Learning
Representations</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liang etÂ al<span id="bib.bib36.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
PaulÂ Pu Liang, Terrance
Liu, Liu Ziyin, NicholasÂ B Allen,
RandyÂ P Auerbach, David Brent,
Ruslan Salakhutdinov, and Louis-Philippe
Morency. 2020.

</span>
<span class="ltx_bibblock">Think locally, act globally: Federated learning
with local and global representations.

</span>
<span class="ltx_bibblock"><em id="bib.bib36.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2001.01523</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu etÂ al<span id="bib.bib37.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Kang Liu, Brendan
Dolan-Gavitt, and Siddharth Garg.
2018.

</span>
<span class="ltx_bibblock">Fine-pruning: Defending against backdooring attacks
on deep neural networks. In <em id="bib.bib37.3.1" class="ltx_emph ltx_font_italic">International
Symposium on Research in Attacks, Intrusions, and Defenses</em>. Springer,
273â€“294.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lyu etÂ al<span id="bib.bib38.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Lingjuan Lyu, Han Yu,
Xingjun Ma, Lichao Sun,
Jun Zhao, Qiang Yang, and
PhilipÂ S Yu. 2020.

</span>
<span class="ltx_bibblock">Privacy and robustness in federated learning:
Attacks and defenses.

</span>
<span class="ltx_bibblock"><em id="bib.bib38.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2012.06337</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Marfoq etÂ al<span id="bib.bib39.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Othmane Marfoq, Giovanni
Neglia, AurÃ©lien Bellet, Laetitia
Kameni, and Richard Vidal.
2021.

</span>
<span class="ltx_bibblock">Federated multi-task learning under a mixture of
distributions.

</span>
<span class="ltx_bibblock"><em id="bib.bib39.3.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing
Systems</em> 34 (2021),
15434â€“15447.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Matsuda etÂ al<span id="bib.bib40.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Koji Matsuda, Yuya
Sasaki, Chuan Xiao, and Makoto
Onizuka. 2022.

</span>
<span class="ltx_bibblock">An Empirical Study of Personalized Federated
Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib40.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2206.13190</em>
(2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McMahan etÂ al<span id="bib.bib41.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Brendan McMahan, Eider
Moore, Daniel Ramage, Seth Hampson,
and BlaiseÂ Aguera y Arcas.
2017.

</span>
<span class="ltx_bibblock">Communication-efficient learning of deep networks
from decentralized data. In <em id="bib.bib41.3.1" class="ltx_emph ltx_font_italic">Artificial
intelligence and statistics</em>. PMLR, 1273â€“1282.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Melis etÂ al<span id="bib.bib42.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Luca Melis, Congzheng
Song, Emiliano DeÂ Cristofaro, and
Vitaly Shmatikov. 2019.

</span>
<span class="ltx_bibblock">Exploiting unintended feature leakage in
collaborative learning. In <em id="bib.bib42.3.1" class="ltx_emph ltx_font_italic">2019 IEEE symposium on
security and privacy (SP)</em>. IEEE, 691â€“706.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nasr etÂ al<span id="bib.bib43.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Milad Nasr, Reza Shokri,
and Amir Houmansadr. 2019.

</span>
<span class="ltx_bibblock">Comprehensive privacy analysis of deep learning:
Passive and active white-box inference attacks against centralized and
federated learning. In <em id="bib.bib43.3.1" class="ltx_emph ltx_font_italic">2019 IEEE symposium on
security and privacy (SP)</em>. IEEE, 739â€“753.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Paszke etÂ al<span id="bib.bib44.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Adam Paszke, Sam Gross,
Soumith Chintala, Gregory Chanan,
Edward Yang, Zachary DeVito,
Zeming Lin, Alban Desmaison,
Luca Antiga, and Adam Lerer.
2017.

</span>
<span class="ltx_bibblock">Automatic differentiation in pytorch.

</span>
<span class="ltx_bibblock">(2017).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pillutla etÂ al<span id="bib.bib45.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Krishna Pillutla, Kshitiz
Malik, Abdel-Rahman Mohamed, Mike
Rabbat, Maziar Sanjabi, and Lin Xiao.
2022.

</span>
<span class="ltx_bibblock">Federated Learning with Partial Model
Personalization. In <em id="bib.bib45.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 39th
International Conference on Machine Learning</em>
<em id="bib.bib45.4.2" class="ltx_emph ltx_font_italic">(Proceedings of Machine Learning Research,
Vol.Â 162)</em>, Kamalika
Chaudhuri, Stefanie Jegelka, LeÂ Song,
Csaba Szepesvari, Gang Niu, and
Sivan Sabato (Eds.). PMLR,
17716â€“17758.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shejwalkar and Houmansadr (2021)</span>
<span class="ltx_bibblock">
Virat Shejwalkar and
Amir Houmansadr. 2021.

</span>
<span class="ltx_bibblock">Manipulating the byzantine: Optimizing model
poisoning attacks and defenses for federated learning. In
<em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">NDSS</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shejwalkar etÂ al<span id="bib.bib47.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Virat Shejwalkar, Amir
Houmansadr, Peter Kairouz, and Daniel
Ramage. 2022.

</span>
<span class="ltx_bibblock">Back to the drawing board: A critical evaluation of
poisoning attacks on production federated learning. In
<em id="bib.bib47.3.1" class="ltx_emph ltx_font_italic">2022 IEEE Symposium on Security and Privacy (SP)</em>.
IEEE, 1354â€“1371.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Smith etÂ al<span id="bib.bib48.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Virginia Smith, Chao-Kai
Chiang, Maziar Sanjabi, and AmeetÂ S
Talwalkar. 2017.

</span>
<span class="ltx_bibblock">Federated multi-task learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib48.3.1" class="ltx_emph ltx_font_italic">Advances in neural information processing
systems</em> 30 (2017).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun etÂ al<span id="bib.bib49.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Ziteng Sun, Peter
Kairouz, AnandaÂ Theertha Suresh, and
HÂ Brendan McMahan. 2019.

</span>
<span class="ltx_bibblock">Can you really backdoor federated learning?

</span>
<span class="ltx_bibblock"><em id="bib.bib49.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1911.07963</em>
(2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">TÂ Dinh etÂ al<span id="bib.bib50.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Canh TÂ Dinh, Nguyen Tran,
and Josh Nguyen. 2020.

</span>
<span class="ltx_bibblock">Personalized federated learning with moreau
envelopes.

</span>
<span class="ltx_bibblock"><em id="bib.bib50.3.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing
Systems</em> 33 (2020),
21394â€“21405.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tan etÂ al<span id="bib.bib51.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
AlysaÂ Ziying Tan, Han Yu,
Lizhen Cui, and Qiang Yang.
2022.

</span>
<span class="ltx_bibblock">Towards personalized federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib51.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Neural Networks and
Learning Systems</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tolpegin etÂ al<span id="bib.bib52.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Vale Tolpegin, Stacey
Truex, MehmetÂ Emre Gursoy, and Ling
Liu. 2020.

</span>
<span class="ltx_bibblock">Data poisoning attacks against federated learning
systems. In <em id="bib.bib52.3.1" class="ltx_emph ltx_font_italic">Computer Securityâ€“ESORICS 2020: 25th
European Symposium on Research in Computer Security, ESORICS 2020, Guildford,
UK, September 14â€“18, 2020, Proceedings, Part I 25</em>. Springer,
480â€“501.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">VanÂ der Maaten and Hinton (2008)</span>
<span class="ltx_bibblock">
Laurens VanÂ der Maaten and
Geoffrey Hinton. 2008.

</span>
<span class="ltx_bibblock">Visualizing data using t-SNE.

</span>
<span class="ltx_bibblock"><em id="bib.bib53.1.1" class="ltx_emph ltx_font_italic">Journal of machine learning research</em>
9, 11 (2008).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang etÂ al<span id="bib.bib54.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Hongyi Wang, Kartik
Sreenivasan, Shashank Rajput, Harit
Vishwakarma, Saurabh Agarwal, Jy-yong
Sohn, Kangwook Lee, and Dimitris
Papailiopoulos. 2020.

</span>
<span class="ltx_bibblock">Attack of the tails: Yes, you really can backdoor
federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib54.3.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing
Systems</em> 33 (2020),
16070â€“16084.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu etÂ al<span id="bib.bib55.2.2.1" class="ltx_text">.</span> (2022a)</span>
<span class="ltx_bibblock">
Baoyuan Wu, Hongrui Chen,
Mingda Zhang, Zihao Zhu,
Shaokui Wei, Danni Yuan,
Chao Shen, and Hongyuan Zha.
2022a.

</span>
<span class="ltx_bibblock">Backdoorbench: A comprehensive benchmark of
backdoor learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib55.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2206.12654</em>
(2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu and Wang (2021)</span>
<span class="ltx_bibblock">
Dongxian Wu and Yisen
Wang. 2021.

</span>
<span class="ltx_bibblock">Adversarial neuron pruning purifies backdoored deep
models.

</span>
<span class="ltx_bibblock"><em id="bib.bib56.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing
Systems</em> 34 (2021),
16913â€“16925.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu etÂ al<span id="bib.bib57.2.2.1" class="ltx_text">.</span> (2022b)</span>
<span class="ltx_bibblock">
Shanshan Wu, Tian Li,
Zachary Charles, Yu Xiao,
Ziyu Liu, Zheng Xu, and
Virginia Smith. 2022b.

</span>
<span class="ltx_bibblock">Motley: Benchmarking heterogeneity and
personalization in federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib57.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2206.09262</em>
(2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xie etÂ al<span id="bib.bib58.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Chulin Xie, Keli Huang,
Pin-Yu Chen, and Bo Li.
2020.

</span>
<span class="ltx_bibblock">DBA: Distributed Backdoor Attacks against Federated
Learning. In <em id="bib.bib58.3.1" class="ltx_emph ltx_font_italic">International Conference on Learning
Representations</em>.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://openreview.net/forum?id=rkgyS0VFvr" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://openreview.net/forum?id=rkgyS0VFvr</a>

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xie etÂ al<span id="bib.bib59.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Yuexiang Xie, Zhen Wang,
Dawei Gao, Daoyuan Chen,
Liuyi Yao, Weirui Kuang,
Yaliang Li, Bolin Ding, and
Jingren Zhou. 2023.

</span>
<span class="ltx_bibblock">FederatedScope: A Flexible Federated Learning
Platform for Heterogeneity.

</span>
<span class="ltx_bibblock"><em id="bib.bib59.3.1" class="ltx_emph ltx_font_italic">Proc. VLDB Endow.</em> 16,
5 (2023), 1059â€“1072.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zawad etÂ al<span id="bib.bib60.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Syed Zawad, Ahsan Ali,
Pin-Yu Chen, Ali Anwar,
Yi Zhou, Nathalie Baracaldo,
Yuan Tian, and Feng Yan.
2021.

</span>
<span class="ltx_bibblock">Curse or redemption? how data heterogeneity affects
the robustness of federated learning. In
<em id="bib.bib60.3.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI Conference on Artificial
Intelligence</em>, Vol.Â 35. 10807â€“10814.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang etÂ al<span id="bib.bib61.2.2.1" class="ltx_text">.</span> (2022b)</span>
<span class="ltx_bibblock">
Lin Zhang, Li Shen,
Liang Ding, Dacheng Tao, and
Ling-Yu Duan. 2022b.

</span>
<span class="ltx_bibblock">Fine-tuning global model via data-free knowledge
distillation for non-iid federated learning. In
<em id="bib.bib61.3.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer
Vision and Pattern Recognition</em>. 10174â€“10183.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang etÂ al<span id="bib.bib62.2.2.1" class="ltx_text">.</span> (2022a)</span>
<span class="ltx_bibblock">
Zhengming Zhang, Ashwinee
Panda, Linyue Song, Yaoqing Yang,
Michael Mahoney, Prateek Mittal,
Ramchandran Kannan, and Joseph
Gonzalez. 2022a.

</span>
<span class="ltx_bibblock">Neurotoxin: durable backdoors in federated
learning. In <em id="bib.bib62.3.1" class="ltx_emph ltx_font_italic">International Conference on Machine
Learning</em>. PMLR, 26429â€“26446.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zheng etÂ al<span id="bib.bib63.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Runkai Zheng, Rongjun
Tang, Jianze Li, and Li Liu.
2022.

</span>
<span class="ltx_bibblock">Data-free backdoor removal based on channel
lipschitzness. In <em id="bib.bib63.3.1" class="ltx_emph ltx_font_italic">European Conference on Computer
Vision</em>. Springer, 175â€“191.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu etÂ al<span id="bib.bib64.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Ligeng Zhu, Zhijian Liu,
and Song Han. 2019.

</span>
<span class="ltx_bibblock">Deep leakage from gradients.

</span>
<span class="ltx_bibblock"><em id="bib.bib64.3.1" class="ltx_emph ltx_font_italic">Advances in neural information processing
systems</em> 32 (2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A1 </span>Datasets and Models</h2>

<section id="A1.SS0.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Datasets.</h5>

<div id="A1.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="A1.SS0.SSS0.Px1.p1.1" class="ltx_p">We conduct experiments on two widely used dataset, FEMNIST and CIFAR-10 in FL literatureÂ <cite class="ltx_cite ltx_citemacro_citep">(McMahan etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib41" title="" class="ltx_ref">2017</a>; Caldas etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib9" title="" class="ltx_ref">2018</a>; Chen etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2022</a>; Matsuda etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib40" title="" class="ltx_ref">2022</a>; Wu etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib57" title="" class="ltx_ref">2022b</a>; Wang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib54" title="" class="ltx_ref">2020</a>)</cite>. These two datasets represent two different settings of Non-IID respectively, feature-skew and label skewÂ <cite class="ltx_cite ltx_citemacro_citep">(Chen etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2022</a>; Lyu etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib38" title="" class="ltx_ref">2020</a>; Zawad etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib60" title="" class="ltx_ref">2021</a>)</cite>.</p>
</div>
<div id="A1.SS0.SSS0.Px1.p2" class="ltx_para">
<ul id="A1.I1" class="ltx_itemize">
<li id="A1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="A1.I1.i1.p1" class="ltx_para">
<p id="A1.I1.i1.p1.2" class="ltx_p">FEMNIST: The Federated Extended MNIST (FEMNIST) is a widely used FL dataset for 62-class handwritten character recognitionÂ <cite class="ltx_cite ltx_citemacro_citep">(Caldas etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib9" title="" class="ltx_ref">2018</a>)</cite>. The original FEMNIST dataset contains 3,550 clients and each client corresponds to a character writer from EMNIST<cite class="ltx_cite ltx_citemacro_citep">(Cohen etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib13" title="" class="ltx_ref">2017</a>)</cite>. We adopt the sub-sampled version in our evaluations, which contains 200 clients and totally <math id="A1.I1.i1.p1.1.m1.2" class="ltx_Math" alttext="43,400" display="inline"><semantics id="A1.I1.i1.p1.1.m1.2a"><mrow id="A1.I1.i1.p1.1.m1.2.3.2" xref="A1.I1.i1.p1.1.m1.2.3.1.cmml"><mn id="A1.I1.i1.p1.1.m1.1.1" xref="A1.I1.i1.p1.1.m1.1.1.cmml">43</mn><mo id="A1.I1.i1.p1.1.m1.2.3.2.1" xref="A1.I1.i1.p1.1.m1.2.3.1.cmml">,</mo><mn id="A1.I1.i1.p1.1.m1.2.2" xref="A1.I1.i1.p1.1.m1.2.2.cmml">400</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.I1.i1.p1.1.m1.2b"><list id="A1.I1.i1.p1.1.m1.2.3.1.cmml" xref="A1.I1.i1.p1.1.m1.2.3.2"><cn type="integer" id="A1.I1.i1.p1.1.m1.1.1.cmml" xref="A1.I1.i1.p1.1.m1.1.1">43</cn><cn type="integer" id="A1.I1.i1.p1.1.m1.2.2.cmml" xref="A1.I1.i1.p1.1.m1.2.2">400</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.I1.i1.p1.1.m1.2c">43,400</annotation></semantics></math> images with resolution of <math id="A1.I1.i1.p1.2.m2.1" class="ltx_Math" alttext="28\times 28" display="inline"><semantics id="A1.I1.i1.p1.2.m2.1a"><mrow id="A1.I1.i1.p1.2.m2.1.1" xref="A1.I1.i1.p1.2.m2.1.1.cmml"><mn id="A1.I1.i1.p1.2.m2.1.1.2" xref="A1.I1.i1.p1.2.m2.1.1.2.cmml">28</mn><mo lspace="0.222em" rspace="0.222em" id="A1.I1.i1.p1.2.m2.1.1.1" xref="A1.I1.i1.p1.2.m2.1.1.1.cmml">Ã—</mo><mn id="A1.I1.i1.p1.2.m2.1.1.3" xref="A1.I1.i1.p1.2.m2.1.1.3.cmml">28</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.I1.i1.p1.2.m2.1b"><apply id="A1.I1.i1.p1.2.m2.1.1.cmml" xref="A1.I1.i1.p1.2.m2.1.1"><times id="A1.I1.i1.p1.2.m2.1.1.1.cmml" xref="A1.I1.i1.p1.2.m2.1.1.1"></times><cn type="integer" id="A1.I1.i1.p1.2.m2.1.1.2.cmml" xref="A1.I1.i1.p1.2.m2.1.1.2">28</cn><cn type="integer" id="A1.I1.i1.p1.2.m2.1.1.3.cmml" xref="A1.I1.i1.p1.2.m2.1.1.3">28</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.I1.i1.p1.2.m2.1c">28\times 28</annotation></semantics></math> pixels. The distribution of samples number per client is shown in Figure <a href="#A2.F10" title="Figure A10 â€£ A2.1. More Details of Attacks Hyper-parameters â€£ Appendix A2 Implementation Details â€£ Revisiting Personalized Federated Learning: Robustness Against Backdoor Attacks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A10</span></a>.</p>
</div>
</li>
<li id="A1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="A1.I1.i2.p1" class="ltx_para">
<p id="A1.I1.i2.p1.1" class="ltx_p">CIFAR-10 is a 10-class image classiï¬cation dataset containing 60,000 colored images with resolution of 32x32 pixels. We use Dirichlet allocation to split this dataset into 100 clients with <math id="A1.I1.i2.p1.1.m1.1" class="ltx_Math" alttext="\alpha=0.5" display="inline"><semantics id="A1.I1.i2.p1.1.m1.1a"><mrow id="A1.I1.i2.p1.1.m1.1.1" xref="A1.I1.i2.p1.1.m1.1.1.cmml"><mi id="A1.I1.i2.p1.1.m1.1.1.2" xref="A1.I1.i2.p1.1.m1.1.1.2.cmml">Î±</mi><mo id="A1.I1.i2.p1.1.m1.1.1.1" xref="A1.I1.i2.p1.1.m1.1.1.1.cmml">=</mo><mn id="A1.I1.i2.p1.1.m1.1.1.3" xref="A1.I1.i2.p1.1.m1.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.I1.i2.p1.1.m1.1b"><apply id="A1.I1.i2.p1.1.m1.1.1.cmml" xref="A1.I1.i2.p1.1.m1.1.1"><eq id="A1.I1.i2.p1.1.m1.1.1.1.cmml" xref="A1.I1.i2.p1.1.m1.1.1.1"></eq><ci id="A1.I1.i2.p1.1.m1.1.1.2.cmml" xref="A1.I1.i2.p1.1.m1.1.1.2">ğ›¼</ci><cn type="float" id="A1.I1.i2.p1.1.m1.1.1.3.cmml" xref="A1.I1.i2.p1.1.m1.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.I1.i2.p1.1.m1.1c">\alpha=0.5</annotation></semantics></math>. The distribution of samples number per client is shown in Figure <a href="#A2.F10" title="Figure A10 â€£ A2.1. More Details of Attacks Hyper-parameters â€£ Appendix A2 Implementation Details â€£ Revisiting Personalized Federated Learning: Robustness Against Backdoor Attacks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A10</span></a>.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="A1.SS0.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Models.</h5>

<div id="A1.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="A1.SS0.SSS0.Px2.p1.3" class="ltx_p">Following the previous pFL worksÂ <cite class="ltx_cite ltx_citemacro_citep">(TÂ Dinh etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib50" title="" class="ltx_ref">2020</a>; Liang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib36" title="" class="ltx_ref">2020</a>; Chen etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2022</a>; Marfoq etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib39" title="" class="ltx_ref">2021</a>)</cite>, we utilize a simple ConvNet on FEMNIST and CIFAR10. This ConvNet model consists of two convolutional layers with the <math id="A1.SS0.SSS0.Px2.p1.1.m1.1" class="ltx_Math" alttext="5\times 5" display="inline"><semantics id="A1.SS0.SSS0.Px2.p1.1.m1.1a"><mrow id="A1.SS0.SSS0.Px2.p1.1.m1.1.1" xref="A1.SS0.SSS0.Px2.p1.1.m1.1.1.cmml"><mn id="A1.SS0.SSS0.Px2.p1.1.m1.1.1.2" xref="A1.SS0.SSS0.Px2.p1.1.m1.1.1.2.cmml">5</mn><mo lspace="0.222em" rspace="0.222em" id="A1.SS0.SSS0.Px2.p1.1.m1.1.1.1" xref="A1.SS0.SSS0.Px2.p1.1.m1.1.1.1.cmml">Ã—</mo><mn id="A1.SS0.SSS0.Px2.p1.1.m1.1.1.3" xref="A1.SS0.SSS0.Px2.p1.1.m1.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS0.SSS0.Px2.p1.1.m1.1b"><apply id="A1.SS0.SSS0.Px2.p1.1.m1.1.1.cmml" xref="A1.SS0.SSS0.Px2.p1.1.m1.1.1"><times id="A1.SS0.SSS0.Px2.p1.1.m1.1.1.1.cmml" xref="A1.SS0.SSS0.Px2.p1.1.m1.1.1.1"></times><cn type="integer" id="A1.SS0.SSS0.Px2.p1.1.m1.1.1.2.cmml" xref="A1.SS0.SSS0.Px2.p1.1.m1.1.1.2">5</cn><cn type="integer" id="A1.SS0.SSS0.Px2.p1.1.m1.1.1.3.cmml" xref="A1.SS0.SSS0.Px2.p1.1.m1.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS0.SSS0.Px2.p1.1.m1.1c">5\times 5</annotation></semantics></math> kernel, max pooling, batch normalization, ReLU activation, and two dense linear layers. The hidden size of linear layer is <math id="A1.SS0.SSS0.Px2.p1.2.m2.2" class="ltx_Math" alttext="2,048" display="inline"><semantics id="A1.SS0.SSS0.Px2.p1.2.m2.2a"><mrow id="A1.SS0.SSS0.Px2.p1.2.m2.2.3.2" xref="A1.SS0.SSS0.Px2.p1.2.m2.2.3.1.cmml"><mn id="A1.SS0.SSS0.Px2.p1.2.m2.1.1" xref="A1.SS0.SSS0.Px2.p1.2.m2.1.1.cmml">2</mn><mo id="A1.SS0.SSS0.Px2.p1.2.m2.2.3.2.1" xref="A1.SS0.SSS0.Px2.p1.2.m2.2.3.1.cmml">,</mo><mn id="A1.SS0.SSS0.Px2.p1.2.m2.2.2" xref="A1.SS0.SSS0.Px2.p1.2.m2.2.2.cmml">048</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS0.SSS0.Px2.p1.2.m2.2b"><list id="A1.SS0.SSS0.Px2.p1.2.m2.2.3.1.cmml" xref="A1.SS0.SSS0.Px2.p1.2.m2.2.3.2"><cn type="integer" id="A1.SS0.SSS0.Px2.p1.2.m2.1.1.cmml" xref="A1.SS0.SSS0.Px2.p1.2.m2.1.1">2</cn><cn type="integer" id="A1.SS0.SSS0.Px2.p1.2.m2.2.2.cmml" xref="A1.SS0.SSS0.Px2.p1.2.m2.2.2">048</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.SS0.SSS0.Px2.p1.2.m2.2c">2,048</annotation></semantics></math> and <math id="A1.SS0.SSS0.Px2.p1.3.m3.1" class="ltx_Math" alttext="512" display="inline"><semantics id="A1.SS0.SSS0.Px2.p1.3.m3.1a"><mn id="A1.SS0.SSS0.Px2.p1.3.m3.1.1" xref="A1.SS0.SSS0.Px2.p1.3.m3.1.1.cmml">512</mn><annotation-xml encoding="MathML-Content" id="A1.SS0.SSS0.Px2.p1.3.m3.1b"><cn type="integer" id="A1.SS0.SSS0.Px2.p1.3.m3.1.1.cmml" xref="A1.SS0.SSS0.Px2.p1.3.m3.1.1">512</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS0.SSS0.Px2.p1.3.m3.1c">512</annotation></semantics></math> on FEMNIST and CIFAR10 respectively. To align with backdoor attacks worksÂ <cite class="ltx_cite ltx_citemacro_citep">(Wang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib54" title="" class="ltx_ref">2020</a>; Wu etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib55" title="" class="ltx_ref">2022a</a>; Sun etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib49" title="" class="ltx_ref">2019</a>; Zhang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib62" title="" class="ltx_ref">2022a</a>)</cite>, we also adopt the larger model, ResNet-18 on CIFAR-10 dataset.</p>
</div>
</section>
</section>
<section id="A2" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A2 </span>Implementation Details</h2>

<section id="A2.SS0.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Environment.</h5>

<div id="A2.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="A2.SS0.SSS0.Px1.p1.1" class="ltx_p">We implement our evaluations <span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a target="_blank" href="https://github.com/alibaba/FederatedScope/tree/backdoor-bench" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/alibaba/FederatedScope/tree/backdoor-bench</a></span></span></span> based on PytorchÂ <cite class="ltx_cite ltx_citemacro_citep">(Paszke etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib44" title="" class="ltx_ref">2017</a>)</cite> and FederetadScope frameworkÂ <cite class="ltx_cite ltx_citemacro_citep">(Xie etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib59" title="" class="ltx_ref">2023</a>)</cite>. And all experiments are conducted on a cluster of 8 NVIDIA GeForce GTX 2080 Ti GPUs.</p>
</div>
</section>
<section id="A2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A2.1. </span>More Details of Attacks Hyper-parameters</h3>

<div id="A2.SS1.p1" class="ltx_para">
<p id="A2.SS1.p1.4" class="ltx_p">Following attack hyparameters provided inÂ <cite class="ltx_cite ltx_citemacro_citep">(Wu etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib55" title="" class="ltx_ref">2022a</a>)</cite>, for BadNet attack, we choose the <math id="A2.SS1.p1.1.m1.1" class="ltx_Math" alttext="3\times 3" display="inline"><semantics id="A2.SS1.p1.1.m1.1a"><mrow id="A2.SS1.p1.1.m1.1.1" xref="A2.SS1.p1.1.m1.1.1.cmml"><mn id="A2.SS1.p1.1.m1.1.1.2" xref="A2.SS1.p1.1.m1.1.1.2.cmml">3</mn><mo lspace="0.222em" rspace="0.222em" id="A2.SS1.p1.1.m1.1.1.1" xref="A2.SS1.p1.1.m1.1.1.1.cmml">Ã—</mo><mn id="A2.SS1.p1.1.m1.1.1.3" xref="A2.SS1.p1.1.m1.1.1.3.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="A2.SS1.p1.1.m1.1b"><apply id="A2.SS1.p1.1.m1.1.1.cmml" xref="A2.SS1.p1.1.m1.1.1"><times id="A2.SS1.p1.1.m1.1.1.1.cmml" xref="A2.SS1.p1.1.m1.1.1.1"></times><cn type="integer" id="A2.SS1.p1.1.m1.1.1.2.cmml" xref="A2.SS1.p1.1.m1.1.1.2">3</cn><cn type="integer" id="A2.SS1.p1.1.m1.1.1.3.cmml" xref="A2.SS1.p1.1.m1.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS1.p1.1.m1.1c">3\times 3</annotation></semantics></math> grid pattern and put it at downright corner of poisoned samples. For Blended attack, we choose the hello-kitty pattern and set the blending ratio <math id="A2.SS1.p1.2.m2.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="A2.SS1.p1.2.m2.1a"><mi id="A2.SS1.p1.2.m2.1.1" xref="A2.SS1.p1.2.m2.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="A2.SS1.p1.2.m2.1b"><ci id="A2.SS1.p1.2.m2.1.1.cmml" xref="A2.SS1.p1.2.m2.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.SS1.p1.2.m2.1c">\alpha</annotation></semantics></math> as <math id="A2.SS1.p1.3.m3.1" class="ltx_Math" alttext="0.2" display="inline"><semantics id="A2.SS1.p1.3.m3.1a"><mn id="A2.SS1.p1.3.m3.1.1" xref="A2.SS1.p1.3.m3.1.1.cmml">0.2</mn><annotation-xml encoding="MathML-Content" id="A2.SS1.p1.3.m3.1b"><cn type="float" id="A2.SS1.p1.3.m3.1.1.cmml" xref="A2.SS1.p1.3.m3.1.1">0.2</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.SS1.p1.3.m3.1c">0.2</annotation></semantics></math>. For SIG attack, we set the amplitude of sinusoidal signal as 20 (<math id="A2.SS1.p1.4.m4.2" class="ltx_Math" alttext="[0,255]" display="inline"><semantics id="A2.SS1.p1.4.m4.2a"><mrow id="A2.SS1.p1.4.m4.2.3.2" xref="A2.SS1.p1.4.m4.2.3.1.cmml"><mo stretchy="false" id="A2.SS1.p1.4.m4.2.3.2.1" xref="A2.SS1.p1.4.m4.2.3.1.cmml">[</mo><mn id="A2.SS1.p1.4.m4.1.1" xref="A2.SS1.p1.4.m4.1.1.cmml">0</mn><mo id="A2.SS1.p1.4.m4.2.3.2.2" xref="A2.SS1.p1.4.m4.2.3.1.cmml">,</mo><mn id="A2.SS1.p1.4.m4.2.2" xref="A2.SS1.p1.4.m4.2.2.cmml">255</mn><mo stretchy="false" id="A2.SS1.p1.4.m4.2.3.2.3" xref="A2.SS1.p1.4.m4.2.3.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A2.SS1.p1.4.m4.2b"><interval closure="closed" id="A2.SS1.p1.4.m4.2.3.1.cmml" xref="A2.SS1.p1.4.m4.2.3.2"><cn type="integer" id="A2.SS1.p1.4.m4.1.1.cmml" xref="A2.SS1.p1.4.m4.1.1">0</cn><cn type="integer" id="A2.SS1.p1.4.m4.2.2.cmml" xref="A2.SS1.p1.4.m4.2.2">255</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="A2.SS1.p1.4.m4.2c">[0,255]</annotation></semantics></math>).</p>
</div>
<figure id="A2.F10" class="ltx_figure"><img src="/html/2302.01677/assets/x11.png" id="A2.F10.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="216" height="77" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A2.F10.2.1.1" class="ltx_text" style="font-size:90%;">Figure A10</span>. </span><span id="A2.F10.3.2" class="ltx_text" style="font-size:90%;">The violin plot of number of samples per client for CIFAR-10 and FEMNIST datasets.</span></figcaption>
</figure>
<figure id="A2.F11" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A2.F11.sf1" class="ltx_figure ltx_figure_panel"><img src="/html/2302.01677/assets/x12.png" id="A2.F11.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="120" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A2.F11.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="A2.F11.sf1.3.2" class="ltx_text" style="font-size:90%;">IID: ResNet-18@CIFAR-10</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A2.F11.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2302.01677/assets/x13.png" id="A2.F11.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="119" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A2.F11.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="A2.F11.sf2.3.2" class="ltx_text" style="font-size:90%;">IID: Convnet2@CIFAR-10</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A2.F11.2.1.1" class="ltx_text" style="font-size:90%;">Figure A11</span>. </span><span id="A2.F11.3.2" class="ltx_text" style="font-size:90%;">Comparison of backdoor attacks on different pFL methods. (a): Results on ResNet-18 and CIFAR-10; (b) Results on ConvNet and CIFAR-10. In the figures, the solid line means ASR, and the dashed line means the C-Acc.</span></figcaption>
</figure>
</section>
<section id="A2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A2.2. </span>Implementation Details of pFL methods</h3>

<div id="A2.SS2.p1" class="ltx_para">
<p id="A2.SS2.p1.1" class="ltx_p">Following pFL-bench <span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><a target="_blank" href="https://github.com/alibaba/FederatedScope/tree/master/benchmark/pFL-Bench" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/alibaba/FederatedScope/tree/master/benchmark/pFL-Bench</a></span></span></span>Â <cite class="ltx_cite ltx_citemacro_citep">(Chen etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2022</a>)</cite>, we also use hyper-parameter searching (HPO) algorithm, HyperBandÂ <cite class="ltx_cite ltx_citemacro_citep">(Li etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib31" title="" class="ltx_ref">2017</a>)</cite>, to ï¬nd the best hyper-parameters for all the baselines on all datasets. We use the vanilla SGD optimizer and set the batch size of local datsets as <math id="A2.SS2.p1.1.m1.1" class="ltx_Math" alttext="32" display="inline"><semantics id="A2.SS2.p1.1.m1.1a"><mn id="A2.SS2.p1.1.m1.1.1" xref="A2.SS2.p1.1.m1.1.1.cmml">32</mn><annotation-xml encoding="MathML-Content" id="A2.SS2.p1.1.m1.1b"><cn type="integer" id="A2.SS2.p1.1.m1.1.1.cmml" xref="A2.SS2.p1.1.m1.1.1">32</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.SS2.p1.1.m1.1c">32</annotation></semantics></math> for all methods. Here, we provide adopted hyper-parameters for all baseline methods:</p>
<ul id="A2.I1" class="ltx_itemize">
<li id="A2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="A2.I1.i1.p1" class="ltx_para">
<p id="A2.I1.i1.p1.2" class="ltx_p">FedAvg: we set learning rate as <math id="A2.I1.i1.p1.1.m1.1" class="ltx_Math" alttext="0.1" display="inline"><semantics id="A2.I1.i1.p1.1.m1.1a"><mn id="A2.I1.i1.p1.1.m1.1.1" xref="A2.I1.i1.p1.1.m1.1.1.cmml">0.1</mn><annotation-xml encoding="MathML-Content" id="A2.I1.i1.p1.1.m1.1b"><cn type="float" id="A2.I1.i1.p1.1.m1.1.1.cmml" xref="A2.I1.i1.p1.1.m1.1.1">0.1</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i1.p1.1.m1.1c">0.1</annotation></semantics></math> and epoch number as <math id="A2.I1.i1.p1.2.m2.1" class="ltx_Math" alttext="2" display="inline"><semantics id="A2.I1.i1.p1.2.m2.1a"><mn id="A2.I1.i1.p1.2.m2.1.1" xref="A2.I1.i1.p1.2.m2.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="A2.I1.i1.p1.2.m2.1b"><cn type="integer" id="A2.I1.i1.p1.2.m2.1.1.cmml" xref="A2.I1.i1.p1.2.m2.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i1.p1.2.m2.1c">2</annotation></semantics></math> for each client on two datasets.</p>
</div>
</li>
<li id="A2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="A2.I1.i2.p1" class="ltx_para">
<p id="A2.I1.i2.p1.5" class="ltx_p">Ditto: we set learning rate as <math id="A2.I1.i2.p1.1.m1.1" class="ltx_Math" alttext="0.1" display="inline"><semantics id="A2.I1.i2.p1.1.m1.1a"><mn id="A2.I1.i2.p1.1.m1.1.1" xref="A2.I1.i2.p1.1.m1.1.1.cmml">0.1</mn><annotation-xml encoding="MathML-Content" id="A2.I1.i2.p1.1.m1.1b"><cn type="float" id="A2.I1.i2.p1.1.m1.1.1.cmml" xref="A2.I1.i2.p1.1.m1.1.1">0.1</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i2.p1.1.m1.1c">0.1</annotation></semantics></math> and <math id="A2.I1.i2.p1.2.m2.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="A2.I1.i2.p1.2.m2.1a"><mi id="A2.I1.i2.p1.2.m2.1.1" xref="A2.I1.i2.p1.2.m2.1.1.cmml">Î»</mi><annotation-xml encoding="MathML-Content" id="A2.I1.i2.p1.2.m2.1b"><ci id="A2.I1.i2.p1.2.m2.1.1.cmml" xref="A2.I1.i2.p1.2.m2.1.1">ğœ†</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i2.p1.2.m2.1c">\lambda</annotation></semantics></math> as <math id="A2.I1.i2.p1.3.m3.1" class="ltx_Math" alttext="0.1" display="inline"><semantics id="A2.I1.i2.p1.3.m3.1a"><mn id="A2.I1.i2.p1.3.m3.1.1" xref="A2.I1.i2.p1.3.m3.1.1.cmml">0.1</mn><annotation-xml encoding="MathML-Content" id="A2.I1.i2.p1.3.m3.1b"><cn type="float" id="A2.I1.i2.p1.3.m3.1.1.cmml" xref="A2.I1.i2.p1.3.m3.1.1">0.1</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i2.p1.3.m3.1c">0.1</annotation></semantics></math> for each client. The epoch number is <math id="A2.I1.i2.p1.4.m4.1" class="ltx_Math" alttext="2" display="inline"><semantics id="A2.I1.i2.p1.4.m4.1a"><mn id="A2.I1.i2.p1.4.m4.1.1" xref="A2.I1.i2.p1.4.m4.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="A2.I1.i2.p1.4.m4.1b"><cn type="integer" id="A2.I1.i2.p1.4.m4.1.1.cmml" xref="A2.I1.i2.p1.4.m4.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i2.p1.4.m4.1c">2</annotation></semantics></math> or <math id="A2.I1.i2.p1.5.m5.1" class="ltx_Math" alttext="3" display="inline"><semantics id="A2.I1.i2.p1.5.m5.1a"><mn id="A2.I1.i2.p1.5.m5.1.1" xref="A2.I1.i2.p1.5.m5.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="A2.I1.i2.p1.5.m5.1b"><cn type="integer" id="A2.I1.i2.p1.5.m5.1.1.cmml" xref="A2.I1.i2.p1.5.m5.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i2.p1.5.m5.1c">3</annotation></semantics></math> on CIFAR-10 or FEMNIST.</p>
</div>
</li>
<li id="A2.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="A2.I1.i3.p1" class="ltx_para">
<p id="A2.I1.i3.p1.5" class="ltx_p">FedEM: ResNet-18 and CIFAR-10: we set learning rate as <math id="A2.I1.i3.p1.1.m1.1" class="ltx_Math" alttext="0.5" display="inline"><semantics id="A2.I1.i3.p1.1.m1.1a"><mn id="A2.I1.i3.p1.1.m1.1.1" xref="A2.I1.i3.p1.1.m1.1.1.cmml">0.5</mn><annotation-xml encoding="MathML-Content" id="A2.I1.i3.p1.1.m1.1b"><cn type="float" id="A2.I1.i3.p1.1.m1.1.1.cmml" xref="A2.I1.i3.p1.1.m1.1.1">0.5</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i3.p1.1.m1.1c">0.5</annotation></semantics></math> and epoch number as <math id="A2.I1.i3.p1.2.m2.1" class="ltx_Math" alttext="1" display="inline"><semantics id="A2.I1.i3.p1.2.m2.1a"><mn id="A2.I1.i3.p1.2.m2.1.1" xref="A2.I1.i3.p1.2.m2.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="A2.I1.i3.p1.2.m2.1b"><cn type="integer" id="A2.I1.i3.p1.2.m2.1.1.cmml" xref="A2.I1.i3.p1.2.m2.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i3.p1.2.m2.1c">1</annotation></semantics></math>. ConvNet and CIFAR-10 or FEMNIST: we set learning rate as <math id="A2.I1.i3.p1.3.m3.1" class="ltx_Math" alttext="0.05" display="inline"><semantics id="A2.I1.i3.p1.3.m3.1a"><mn id="A2.I1.i3.p1.3.m3.1.1" xref="A2.I1.i3.p1.3.m3.1.1.cmml">0.05</mn><annotation-xml encoding="MathML-Content" id="A2.I1.i3.p1.3.m3.1b"><cn type="float" id="A2.I1.i3.p1.3.m3.1.1.cmml" xref="A2.I1.i3.p1.3.m3.1.1">0.05</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i3.p1.3.m3.1c">0.05</annotation></semantics></math> and epoch number as <math id="A2.I1.i3.p1.4.m4.1" class="ltx_Math" alttext="2" display="inline"><semantics id="A2.I1.i3.p1.4.m4.1a"><mn id="A2.I1.i3.p1.4.m4.1.1" xref="A2.I1.i3.p1.4.m4.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="A2.I1.i3.p1.4.m4.1b"><cn type="integer" id="A2.I1.i3.p1.4.m4.1.1.cmml" xref="A2.I1.i3.p1.4.m4.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i3.p1.4.m4.1c">2</annotation></semantics></math>. The number of base model for two datasets is <math id="A2.I1.i3.p1.5.m5.1" class="ltx_Math" alttext="3" display="inline"><semantics id="A2.I1.i3.p1.5.m5.1a"><mn id="A2.I1.i3.p1.5.m5.1.1" xref="A2.I1.i3.p1.5.m5.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="A2.I1.i3.p1.5.m5.1b"><cn type="integer" id="A2.I1.i3.p1.5.m5.1.1.cmml" xref="A2.I1.i3.p1.5.m5.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i3.p1.5.m5.1c">3</annotation></semantics></math>.</p>
</div>
</li>
<li id="A2.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="A2.I1.i4.p1" class="ltx_para">
<p id="A2.I1.i4.p1.4" class="ltx_p">Fine-tuning: On CIFAR-10: we set learning rate of FT as <math id="A2.I1.i4.p1.1.m1.1" class="ltx_Math" alttext="0.01" display="inline"><semantics id="A2.I1.i4.p1.1.m1.1a"><mn id="A2.I1.i4.p1.1.m1.1.1" xref="A2.I1.i4.p1.1.m1.1.1.cmml">0.01</mn><annotation-xml encoding="MathML-Content" id="A2.I1.i4.p1.1.m1.1b"><cn type="float" id="A2.I1.i4.p1.1.m1.1.1.cmml" xref="A2.I1.i4.p1.1.m1.1.1">0.01</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i4.p1.1.m1.1c">0.01</annotation></semantics></math> and epoch number of FT as <math id="A2.I1.i4.p1.2.m2.1" class="ltx_Math" alttext="2" display="inline"><semantics id="A2.I1.i4.p1.2.m2.1a"><mn id="A2.I1.i4.p1.2.m2.1.1" xref="A2.I1.i4.p1.2.m2.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="A2.I1.i4.p1.2.m2.1b"><cn type="integer" id="A2.I1.i4.p1.2.m2.1.1.cmml" xref="A2.I1.i4.p1.2.m2.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i4.p1.2.m2.1c">2</annotation></semantics></math>. On FEMNIST: we set learning rate of FT as <math id="A2.I1.i4.p1.3.m3.1" class="ltx_Math" alttext="0.01" display="inline"><semantics id="A2.I1.i4.p1.3.m3.1a"><mn id="A2.I1.i4.p1.3.m3.1.1" xref="A2.I1.i4.p1.3.m3.1.1.cmml">0.01</mn><annotation-xml encoding="MathML-Content" id="A2.I1.i4.p1.3.m3.1b"><cn type="float" id="A2.I1.i4.p1.3.m3.1.1.cmml" xref="A2.I1.i4.p1.3.m3.1.1">0.01</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i4.p1.3.m3.1c">0.01</annotation></semantics></math> and epoch number of FT as <math id="A2.I1.i4.p1.4.m4.1" class="ltx_Math" alttext="3" display="inline"><semantics id="A2.I1.i4.p1.4.m4.1a"><mn id="A2.I1.i4.p1.4.m4.1.1" xref="A2.I1.i4.p1.4.m4.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="A2.I1.i4.p1.4.m4.1b"><cn type="integer" id="A2.I1.i4.p1.4.m4.1.1.cmml" xref="A2.I1.i4.p1.4.m4.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i4.p1.4.m4.1c">3</annotation></semantics></math>.</p>
</div>
</li>
<li id="A2.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="A2.I1.i5.p1" class="ltx_para">
<p id="A2.I1.i5.p1.24" class="ltx_p">pFedMe: On ResNet-18 and CIFAR-10: we set learning rate as <math id="A2.I1.i5.p1.1.m1.1" class="ltx_Math" alttext="0.5" display="inline"><semantics id="A2.I1.i5.p1.1.m1.1a"><mn id="A2.I1.i5.p1.1.m1.1.1" xref="A2.I1.i5.p1.1.m1.1.1.cmml">0.5</mn><annotation-xml encoding="MathML-Content" id="A2.I1.i5.p1.1.m1.1b"><cn type="float" id="A2.I1.i5.p1.1.m1.1.1.cmml" xref="A2.I1.i5.p1.1.m1.1.1">0.5</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i5.p1.1.m1.1c">0.5</annotation></semantics></math> and epoch number as <math id="A2.I1.i5.p1.2.m2.1" class="ltx_Math" alttext="3" display="inline"><semantics id="A2.I1.i5.p1.2.m2.1a"><mn id="A2.I1.i5.p1.2.m2.1.1" xref="A2.I1.i5.p1.2.m2.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="A2.I1.i5.p1.2.m2.1b"><cn type="integer" id="A2.I1.i5.p1.2.m2.1.1.cmml" xref="A2.I1.i5.p1.2.m2.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i5.p1.2.m2.1c">3</annotation></semantics></math>. We set local approximation steps <math id="A2.I1.i5.p1.3.m3.1" class="ltx_Math" alttext="K" display="inline"><semantics id="A2.I1.i5.p1.3.m3.1a"><mi id="A2.I1.i5.p1.3.m3.1.1" xref="A2.I1.i5.p1.3.m3.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="A2.I1.i5.p1.3.m3.1b"><ci id="A2.I1.i5.p1.3.m3.1.1.cmml" xref="A2.I1.i5.p1.3.m3.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i5.p1.3.m3.1c">K</annotation></semantics></math> as <math id="A2.I1.i5.p1.4.m4.1" class="ltx_Math" alttext="1" display="inline"><semantics id="A2.I1.i5.p1.4.m4.1a"><mn id="A2.I1.i5.p1.4.m4.1.1" xref="A2.I1.i5.p1.4.m4.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="A2.I1.i5.p1.4.m4.1b"><cn type="integer" id="A2.I1.i5.p1.4.m4.1.1.cmml" xref="A2.I1.i5.p1.4.m4.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i5.p1.4.m4.1c">1</annotation></semantics></math>, average moving parameter <math id="A2.I1.i5.p1.5.m5.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="A2.I1.i5.p1.5.m5.1a"><mi id="A2.I1.i5.p1.5.m5.1.1" xref="A2.I1.i5.p1.5.m5.1.1.cmml">Î²</mi><annotation-xml encoding="MathML-Content" id="A2.I1.i5.p1.5.m5.1b"><ci id="A2.I1.i5.p1.5.m5.1.1.cmml" xref="A2.I1.i5.p1.5.m5.1.1">ğ›½</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i5.p1.5.m5.1c">\beta</annotation></semantics></math> as <math id="A2.I1.i5.p1.6.m6.1" class="ltx_Math" alttext="1" display="inline"><semantics id="A2.I1.i5.p1.6.m6.1a"><mn id="A2.I1.i5.p1.6.m6.1.1" xref="A2.I1.i5.p1.6.m6.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="A2.I1.i5.p1.6.m6.1b"><cn type="integer" id="A2.I1.i5.p1.6.m6.1.1.cmml" xref="A2.I1.i5.p1.6.m6.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i5.p1.6.m6.1c">1</annotation></semantics></math> and <math id="A2.I1.i5.p1.7.m7.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="A2.I1.i5.p1.7.m7.1a"><mi id="A2.I1.i5.p1.7.m7.1.1" xref="A2.I1.i5.p1.7.m7.1.1.cmml">Î»</mi><annotation-xml encoding="MathML-Content" id="A2.I1.i5.p1.7.m7.1b"><ci id="A2.I1.i5.p1.7.m7.1.1.cmml" xref="A2.I1.i5.p1.7.m7.1.1">ğœ†</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i5.p1.7.m7.1c">\lambda</annotation></semantics></math> as <math id="A2.I1.i5.p1.8.m8.1" class="ltx_Math" alttext="0.5" display="inline"><semantics id="A2.I1.i5.p1.8.m8.1a"><mn id="A2.I1.i5.p1.8.m8.1.1" xref="A2.I1.i5.p1.8.m8.1.1.cmml">0.5</mn><annotation-xml encoding="MathML-Content" id="A2.I1.i5.p1.8.m8.1b"><cn type="float" id="A2.I1.i5.p1.8.m8.1.1.cmml" xref="A2.I1.i5.p1.8.m8.1.1">0.5</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i5.p1.8.m8.1c">0.5</annotation></semantics></math>; On ConvNet and CIFAR-10: we set learning rate as <math id="A2.I1.i5.p1.9.m9.1" class="ltx_Math" alttext="0.1" display="inline"><semantics id="A2.I1.i5.p1.9.m9.1a"><mn id="A2.I1.i5.p1.9.m9.1.1" xref="A2.I1.i5.p1.9.m9.1.1.cmml">0.1</mn><annotation-xml encoding="MathML-Content" id="A2.I1.i5.p1.9.m9.1b"><cn type="float" id="A2.I1.i5.p1.9.m9.1.1.cmml" xref="A2.I1.i5.p1.9.m9.1.1">0.1</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i5.p1.9.m9.1c">0.1</annotation></semantics></math> and epoch number as <math id="A2.I1.i5.p1.10.m10.1" class="ltx_Math" alttext="3" display="inline"><semantics id="A2.I1.i5.p1.10.m10.1a"><mn id="A2.I1.i5.p1.10.m10.1.1" xref="A2.I1.i5.p1.10.m10.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="A2.I1.i5.p1.10.m10.1b"><cn type="integer" id="A2.I1.i5.p1.10.m10.1.1.cmml" xref="A2.I1.i5.p1.10.m10.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i5.p1.10.m10.1c">3</annotation></semantics></math>. We set local approximation steps <math id="A2.I1.i5.p1.11.m11.1" class="ltx_Math" alttext="K" display="inline"><semantics id="A2.I1.i5.p1.11.m11.1a"><mi id="A2.I1.i5.p1.11.m11.1.1" xref="A2.I1.i5.p1.11.m11.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="A2.I1.i5.p1.11.m11.1b"><ci id="A2.I1.i5.p1.11.m11.1.1.cmml" xref="A2.I1.i5.p1.11.m11.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i5.p1.11.m11.1c">K</annotation></semantics></math> as <math id="A2.I1.i5.p1.12.m12.1" class="ltx_Math" alttext="2" display="inline"><semantics id="A2.I1.i5.p1.12.m12.1a"><mn id="A2.I1.i5.p1.12.m12.1.1" xref="A2.I1.i5.p1.12.m12.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="A2.I1.i5.p1.12.m12.1b"><cn type="integer" id="A2.I1.i5.p1.12.m12.1.1.cmml" xref="A2.I1.i5.p1.12.m12.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i5.p1.12.m12.1c">2</annotation></semantics></math>, average moving parameter <math id="A2.I1.i5.p1.13.m13.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="A2.I1.i5.p1.13.m13.1a"><mi id="A2.I1.i5.p1.13.m13.1.1" xref="A2.I1.i5.p1.13.m13.1.1.cmml">Î²</mi><annotation-xml encoding="MathML-Content" id="A2.I1.i5.p1.13.m13.1b"><ci id="A2.I1.i5.p1.13.m13.1.1.cmml" xref="A2.I1.i5.p1.13.m13.1.1">ğ›½</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i5.p1.13.m13.1c">\beta</annotation></semantics></math> as <math id="A2.I1.i5.p1.14.m14.1" class="ltx_Math" alttext="1" display="inline"><semantics id="A2.I1.i5.p1.14.m14.1a"><mn id="A2.I1.i5.p1.14.m14.1.1" xref="A2.I1.i5.p1.14.m14.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="A2.I1.i5.p1.14.m14.1b"><cn type="integer" id="A2.I1.i5.p1.14.m14.1.1.cmml" xref="A2.I1.i5.p1.14.m14.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i5.p1.14.m14.1c">1</annotation></semantics></math>, and <math id="A2.I1.i5.p1.15.m15.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="A2.I1.i5.p1.15.m15.1a"><mi id="A2.I1.i5.p1.15.m15.1.1" xref="A2.I1.i5.p1.15.m15.1.1.cmml">Î»</mi><annotation-xml encoding="MathML-Content" id="A2.I1.i5.p1.15.m15.1b"><ci id="A2.I1.i5.p1.15.m15.1.1.cmml" xref="A2.I1.i5.p1.15.m15.1.1">ğœ†</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i5.p1.15.m15.1c">\lambda</annotation></semantics></math> as <math id="A2.I1.i5.p1.16.m16.1" class="ltx_Math" alttext="0.5" display="inline"><semantics id="A2.I1.i5.p1.16.m16.1a"><mn id="A2.I1.i5.p1.16.m16.1.1" xref="A2.I1.i5.p1.16.m16.1.1.cmml">0.5</mn><annotation-xml encoding="MathML-Content" id="A2.I1.i5.p1.16.m16.1b"><cn type="float" id="A2.I1.i5.p1.16.m16.1.1.cmml" xref="A2.I1.i5.p1.16.m16.1.1">0.5</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i5.p1.16.m16.1c">0.5</annotation></semantics></math>; On ConvNet and FEMNIST: learning rate is <math id="A2.I1.i5.p1.17.m17.1" class="ltx_Math" alttext="0.1" display="inline"><semantics id="A2.I1.i5.p1.17.m17.1a"><mn id="A2.I1.i5.p1.17.m17.1.1" xref="A2.I1.i5.p1.17.m17.1.1.cmml">0.1</mn><annotation-xml encoding="MathML-Content" id="A2.I1.i5.p1.17.m17.1b"><cn type="float" id="A2.I1.i5.p1.17.m17.1.1.cmml" xref="A2.I1.i5.p1.17.m17.1.1">0.1</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i5.p1.17.m17.1c">0.1</annotation></semantics></math>, epoch number is <math id="A2.I1.i5.p1.18.m18.1" class="ltx_Math" alttext="2" display="inline"><semantics id="A2.I1.i5.p1.18.m18.1a"><mn id="A2.I1.i5.p1.18.m18.1.1" xref="A2.I1.i5.p1.18.m18.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="A2.I1.i5.p1.18.m18.1b"><cn type="integer" id="A2.I1.i5.p1.18.m18.1.1.cmml" xref="A2.I1.i5.p1.18.m18.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i5.p1.18.m18.1c">2</annotation></semantics></math>, local approximation steps <math id="A2.I1.i5.p1.19.m19.1" class="ltx_Math" alttext="K" display="inline"><semantics id="A2.I1.i5.p1.19.m19.1a"><mi id="A2.I1.i5.p1.19.m19.1.1" xref="A2.I1.i5.p1.19.m19.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="A2.I1.i5.p1.19.m19.1b"><ci id="A2.I1.i5.p1.19.m19.1.1.cmml" xref="A2.I1.i5.p1.19.m19.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i5.p1.19.m19.1c">K</annotation></semantics></math> is <math id="A2.I1.i5.p1.20.m20.1" class="ltx_Math" alttext="3" display="inline"><semantics id="A2.I1.i5.p1.20.m20.1a"><mn id="A2.I1.i5.p1.20.m20.1.1" xref="A2.I1.i5.p1.20.m20.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="A2.I1.i5.p1.20.m20.1b"><cn type="integer" id="A2.I1.i5.p1.20.m20.1.1.cmml" xref="A2.I1.i5.p1.20.m20.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i5.p1.20.m20.1c">3</annotation></semantics></math>, average moving parameter <math id="A2.I1.i5.p1.21.m21.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="A2.I1.i5.p1.21.m21.1a"><mi id="A2.I1.i5.p1.21.m21.1.1" xref="A2.I1.i5.p1.21.m21.1.1.cmml">Î²</mi><annotation-xml encoding="MathML-Content" id="A2.I1.i5.p1.21.m21.1b"><ci id="A2.I1.i5.p1.21.m21.1.1.cmml" xref="A2.I1.i5.p1.21.m21.1.1">ğ›½</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i5.p1.21.m21.1c">\beta</annotation></semantics></math> is <math id="A2.I1.i5.p1.22.m22.1" class="ltx_Math" alttext="1" display="inline"><semantics id="A2.I1.i5.p1.22.m22.1a"><mn id="A2.I1.i5.p1.22.m22.1.1" xref="A2.I1.i5.p1.22.m22.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="A2.I1.i5.p1.22.m22.1b"><cn type="integer" id="A2.I1.i5.p1.22.m22.1.1.cmml" xref="A2.I1.i5.p1.22.m22.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i5.p1.22.m22.1c">1</annotation></semantics></math>, <math id="A2.I1.i5.p1.23.m23.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="A2.I1.i5.p1.23.m23.1a"><mi id="A2.I1.i5.p1.23.m23.1.1" xref="A2.I1.i5.p1.23.m23.1.1.cmml">Î»</mi><annotation-xml encoding="MathML-Content" id="A2.I1.i5.p1.23.m23.1b"><ci id="A2.I1.i5.p1.23.m23.1.1.cmml" xref="A2.I1.i5.p1.23.m23.1.1">ğœ†</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i5.p1.23.m23.1c">\lambda</annotation></semantics></math> is <math id="A2.I1.i5.p1.24.m24.1" class="ltx_Math" alttext="0.8" display="inline"><semantics id="A2.I1.i5.p1.24.m24.1a"><mn id="A2.I1.i5.p1.24.m24.1.1" xref="A2.I1.i5.p1.24.m24.1.1.cmml">0.8</mn><annotation-xml encoding="MathML-Content" id="A2.I1.i5.p1.24.m24.1b"><cn type="float" id="A2.I1.i5.p1.24.m24.1.1.cmml" xref="A2.I1.i5.p1.24.m24.1.1">0.8</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i5.p1.24.m24.1c">0.8</annotation></semantics></math>.</p>
</div>
</li>
<li id="A2.I1.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="A2.I1.i6.p1" class="ltx_para">
<p id="A2.I1.i6.p1.6" class="ltx_p">FedBN: On ResNet-18 and CIFAR-10: we set learning rate as <math id="A2.I1.i6.p1.1.m1.1" class="ltx_Math" alttext="0.5" display="inline"><semantics id="A2.I1.i6.p1.1.m1.1a"><mn id="A2.I1.i6.p1.1.m1.1.1" xref="A2.I1.i6.p1.1.m1.1.1.cmml">0.5</mn><annotation-xml encoding="MathML-Content" id="A2.I1.i6.p1.1.m1.1b"><cn type="float" id="A2.I1.i6.p1.1.m1.1.1.cmml" xref="A2.I1.i6.p1.1.m1.1.1">0.5</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i6.p1.1.m1.1c">0.5</annotation></semantics></math> and epoch number as <math id="A2.I1.i6.p1.2.m2.1" class="ltx_Math" alttext="2" display="inline"><semantics id="A2.I1.i6.p1.2.m2.1a"><mn id="A2.I1.i6.p1.2.m2.1.1" xref="A2.I1.i6.p1.2.m2.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="A2.I1.i6.p1.2.m2.1b"><cn type="integer" id="A2.I1.i6.p1.2.m2.1.1.cmml" xref="A2.I1.i6.p1.2.m2.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i6.p1.2.m2.1c">2</annotation></semantics></math>; On ConvNet and CIFAR-10: we learning rate as <math id="A2.I1.i6.p1.3.m3.1" class="ltx_Math" alttext="0.1" display="inline"><semantics id="A2.I1.i6.p1.3.m3.1a"><mn id="A2.I1.i6.p1.3.m3.1.1" xref="A2.I1.i6.p1.3.m3.1.1.cmml">0.1</mn><annotation-xml encoding="MathML-Content" id="A2.I1.i6.p1.3.m3.1b"><cn type="float" id="A2.I1.i6.p1.3.m3.1.1.cmml" xref="A2.I1.i6.p1.3.m3.1.1">0.1</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i6.p1.3.m3.1c">0.1</annotation></semantics></math> and epoch number as <math id="A2.I1.i6.p1.4.m4.1" class="ltx_Math" alttext="2" display="inline"><semantics id="A2.I1.i6.p1.4.m4.1a"><mn id="A2.I1.i6.p1.4.m4.1.1" xref="A2.I1.i6.p1.4.m4.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="A2.I1.i6.p1.4.m4.1b"><cn type="integer" id="A2.I1.i6.p1.4.m4.1.1.cmml" xref="A2.I1.i6.p1.4.m4.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i6.p1.4.m4.1c">2</annotation></semantics></math>; On ConvNet and FEMNIST: we set learning rate as <math id="A2.I1.i6.p1.5.m5.1" class="ltx_Math" alttext="0.01" display="inline"><semantics id="A2.I1.i6.p1.5.m5.1a"><mn id="A2.I1.i6.p1.5.m5.1.1" xref="A2.I1.i6.p1.5.m5.1.1.cmml">0.01</mn><annotation-xml encoding="MathML-Content" id="A2.I1.i6.p1.5.m5.1b"><cn type="float" id="A2.I1.i6.p1.5.m5.1.1.cmml" xref="A2.I1.i6.p1.5.m5.1.1">0.01</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i6.p1.5.m5.1c">0.01</annotation></semantics></math> and epoch number as <math id="A2.I1.i6.p1.6.m6.1" class="ltx_Math" alttext="2" display="inline"><semantics id="A2.I1.i6.p1.6.m6.1a"><mn id="A2.I1.i6.p1.6.m6.1.1" xref="A2.I1.i6.p1.6.m6.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="A2.I1.i6.p1.6.m6.1b"><cn type="integer" id="A2.I1.i6.p1.6.m6.1.1.cmml" xref="A2.I1.i6.p1.6.m6.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i6.p1.6.m6.1c">2</annotation></semantics></math>.</p>
</div>
</li>
<li id="A2.I1.i7" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="A2.I1.i7.p1" class="ltx_para">
<p id="A2.I1.i7.p1.16" class="ltx_p">FedRep: On CIFAR-10: we set learning rate of <math id="A2.I1.i7.p1.1.m1.1" class="ltx_Math" alttext="\bm{\theta}^{s}" display="inline"><semantics id="A2.I1.i7.p1.1.m1.1a"><msup id="A2.I1.i7.p1.1.m1.1.1" xref="A2.I1.i7.p1.1.m1.1.1.cmml"><mi id="A2.I1.i7.p1.1.m1.1.1.2" xref="A2.I1.i7.p1.1.m1.1.1.2.cmml">ğœ½</mi><mi id="A2.I1.i7.p1.1.m1.1.1.3" xref="A2.I1.i7.p1.1.m1.1.1.3.cmml">s</mi></msup><annotation-xml encoding="MathML-Content" id="A2.I1.i7.p1.1.m1.1b"><apply id="A2.I1.i7.p1.1.m1.1.1.cmml" xref="A2.I1.i7.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A2.I1.i7.p1.1.m1.1.1.1.cmml" xref="A2.I1.i7.p1.1.m1.1.1">superscript</csymbol><ci id="A2.I1.i7.p1.1.m1.1.1.2.cmml" xref="A2.I1.i7.p1.1.m1.1.1.2">ğœ½</ci><ci id="A2.I1.i7.p1.1.m1.1.1.3.cmml" xref="A2.I1.i7.p1.1.m1.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i7.p1.1.m1.1c">\bm{\theta}^{s}</annotation></semantics></math> as <math id="A2.I1.i7.p1.2.m2.1" class="ltx_Math" alttext="0.1" display="inline"><semantics id="A2.I1.i7.p1.2.m2.1a"><mn id="A2.I1.i7.p1.2.m2.1.1" xref="A2.I1.i7.p1.2.m2.1.1.cmml">0.1</mn><annotation-xml encoding="MathML-Content" id="A2.I1.i7.p1.2.m2.1b"><cn type="float" id="A2.I1.i7.p1.2.m2.1.1.cmml" xref="A2.I1.i7.p1.2.m2.1.1">0.1</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i7.p1.2.m2.1c">0.1</annotation></semantics></math>, epoch number of <math id="A2.I1.i7.p1.3.m3.1" class="ltx_Math" alttext="\bm{\theta}^{s}" display="inline"><semantics id="A2.I1.i7.p1.3.m3.1a"><msup id="A2.I1.i7.p1.3.m3.1.1" xref="A2.I1.i7.p1.3.m3.1.1.cmml"><mi id="A2.I1.i7.p1.3.m3.1.1.2" xref="A2.I1.i7.p1.3.m3.1.1.2.cmml">ğœ½</mi><mi id="A2.I1.i7.p1.3.m3.1.1.3" xref="A2.I1.i7.p1.3.m3.1.1.3.cmml">s</mi></msup><annotation-xml encoding="MathML-Content" id="A2.I1.i7.p1.3.m3.1b"><apply id="A2.I1.i7.p1.3.m3.1.1.cmml" xref="A2.I1.i7.p1.3.m3.1.1"><csymbol cd="ambiguous" id="A2.I1.i7.p1.3.m3.1.1.1.cmml" xref="A2.I1.i7.p1.3.m3.1.1">superscript</csymbol><ci id="A2.I1.i7.p1.3.m3.1.1.2.cmml" xref="A2.I1.i7.p1.3.m3.1.1.2">ğœ½</ci><ci id="A2.I1.i7.p1.3.m3.1.1.3.cmml" xref="A2.I1.i7.p1.3.m3.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i7.p1.3.m3.1c">\bm{\theta}^{s}</annotation></semantics></math> as <math id="A2.I1.i7.p1.4.m4.1" class="ltx_Math" alttext="1" display="inline"><semantics id="A2.I1.i7.p1.4.m4.1a"><mn id="A2.I1.i7.p1.4.m4.1.1" xref="A2.I1.i7.p1.4.m4.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="A2.I1.i7.p1.4.m4.1b"><cn type="integer" id="A2.I1.i7.p1.4.m4.1.1.cmml" xref="A2.I1.i7.p1.4.m4.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i7.p1.4.m4.1c">1</annotation></semantics></math>, learning rate of <math id="A2.I1.i7.p1.5.m5.1" class="ltx_Math" alttext="\bm{\theta}^{p}" display="inline"><semantics id="A2.I1.i7.p1.5.m5.1a"><msup id="A2.I1.i7.p1.5.m5.1.1" xref="A2.I1.i7.p1.5.m5.1.1.cmml"><mi id="A2.I1.i7.p1.5.m5.1.1.2" xref="A2.I1.i7.p1.5.m5.1.1.2.cmml">ğœ½</mi><mi id="A2.I1.i7.p1.5.m5.1.1.3" xref="A2.I1.i7.p1.5.m5.1.1.3.cmml">p</mi></msup><annotation-xml encoding="MathML-Content" id="A2.I1.i7.p1.5.m5.1b"><apply id="A2.I1.i7.p1.5.m5.1.1.cmml" xref="A2.I1.i7.p1.5.m5.1.1"><csymbol cd="ambiguous" id="A2.I1.i7.p1.5.m5.1.1.1.cmml" xref="A2.I1.i7.p1.5.m5.1.1">superscript</csymbol><ci id="A2.I1.i7.p1.5.m5.1.1.2.cmml" xref="A2.I1.i7.p1.5.m5.1.1.2">ğœ½</ci><ci id="A2.I1.i7.p1.5.m5.1.1.3.cmml" xref="A2.I1.i7.p1.5.m5.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i7.p1.5.m5.1c">\bm{\theta}^{p}</annotation></semantics></math>as <math id="A2.I1.i7.p1.6.m6.1" class="ltx_Math" alttext="0.005" display="inline"><semantics id="A2.I1.i7.p1.6.m6.1a"><mn id="A2.I1.i7.p1.6.m6.1.1" xref="A2.I1.i7.p1.6.m6.1.1.cmml">0.005</mn><annotation-xml encoding="MathML-Content" id="A2.I1.i7.p1.6.m6.1b"><cn type="float" id="A2.I1.i7.p1.6.m6.1.1.cmml" xref="A2.I1.i7.p1.6.m6.1.1">0.005</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i7.p1.6.m6.1c">0.005</annotation></semantics></math>, and epoch number of <math id="A2.I1.i7.p1.7.m7.1" class="ltx_Math" alttext="\bm{\theta}^{p}" display="inline"><semantics id="A2.I1.i7.p1.7.m7.1a"><msup id="A2.I1.i7.p1.7.m7.1.1" xref="A2.I1.i7.p1.7.m7.1.1.cmml"><mi id="A2.I1.i7.p1.7.m7.1.1.2" xref="A2.I1.i7.p1.7.m7.1.1.2.cmml">ğœ½</mi><mi id="A2.I1.i7.p1.7.m7.1.1.3" xref="A2.I1.i7.p1.7.m7.1.1.3.cmml">p</mi></msup><annotation-xml encoding="MathML-Content" id="A2.I1.i7.p1.7.m7.1b"><apply id="A2.I1.i7.p1.7.m7.1.1.cmml" xref="A2.I1.i7.p1.7.m7.1.1"><csymbol cd="ambiguous" id="A2.I1.i7.p1.7.m7.1.1.1.cmml" xref="A2.I1.i7.p1.7.m7.1.1">superscript</csymbol><ci id="A2.I1.i7.p1.7.m7.1.1.2.cmml" xref="A2.I1.i7.p1.7.m7.1.1.2">ğœ½</ci><ci id="A2.I1.i7.p1.7.m7.1.1.3.cmml" xref="A2.I1.i7.p1.7.m7.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i7.p1.7.m7.1c">\bm{\theta}^{p}</annotation></semantics></math> as <math id="A2.I1.i7.p1.8.m8.1" class="ltx_Math" alttext="1" display="inline"><semantics id="A2.I1.i7.p1.8.m8.1a"><mn id="A2.I1.i7.p1.8.m8.1.1" xref="A2.I1.i7.p1.8.m8.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="A2.I1.i7.p1.8.m8.1b"><cn type="integer" id="A2.I1.i7.p1.8.m8.1.1.cmml" xref="A2.I1.i7.p1.8.m8.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i7.p1.8.m8.1c">1</annotation></semantics></math>; On FENNIST: we set learning rate of <math id="A2.I1.i7.p1.9.m9.1" class="ltx_Math" alttext="\bm{\theta}^{s}" display="inline"><semantics id="A2.I1.i7.p1.9.m9.1a"><msup id="A2.I1.i7.p1.9.m9.1.1" xref="A2.I1.i7.p1.9.m9.1.1.cmml"><mi id="A2.I1.i7.p1.9.m9.1.1.2" xref="A2.I1.i7.p1.9.m9.1.1.2.cmml">ğœ½</mi><mi id="A2.I1.i7.p1.9.m9.1.1.3" xref="A2.I1.i7.p1.9.m9.1.1.3.cmml">s</mi></msup><annotation-xml encoding="MathML-Content" id="A2.I1.i7.p1.9.m9.1b"><apply id="A2.I1.i7.p1.9.m9.1.1.cmml" xref="A2.I1.i7.p1.9.m9.1.1"><csymbol cd="ambiguous" id="A2.I1.i7.p1.9.m9.1.1.1.cmml" xref="A2.I1.i7.p1.9.m9.1.1">superscript</csymbol><ci id="A2.I1.i7.p1.9.m9.1.1.2.cmml" xref="A2.I1.i7.p1.9.m9.1.1.2">ğœ½</ci><ci id="A2.I1.i7.p1.9.m9.1.1.3.cmml" xref="A2.I1.i7.p1.9.m9.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i7.p1.9.m9.1c">\bm{\theta}^{s}</annotation></semantics></math> as <math id="A2.I1.i7.p1.10.m10.1" class="ltx_Math" alttext="0.1" display="inline"><semantics id="A2.I1.i7.p1.10.m10.1a"><mn id="A2.I1.i7.p1.10.m10.1.1" xref="A2.I1.i7.p1.10.m10.1.1.cmml">0.1</mn><annotation-xml encoding="MathML-Content" id="A2.I1.i7.p1.10.m10.1b"><cn type="float" id="A2.I1.i7.p1.10.m10.1.1.cmml" xref="A2.I1.i7.p1.10.m10.1.1">0.1</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i7.p1.10.m10.1c">0.1</annotation></semantics></math>, epoch number of <math id="A2.I1.i7.p1.11.m11.1" class="ltx_Math" alttext="\bm{\theta}^{s}" display="inline"><semantics id="A2.I1.i7.p1.11.m11.1a"><msup id="A2.I1.i7.p1.11.m11.1.1" xref="A2.I1.i7.p1.11.m11.1.1.cmml"><mi id="A2.I1.i7.p1.11.m11.1.1.2" xref="A2.I1.i7.p1.11.m11.1.1.2.cmml">ğœ½</mi><mi id="A2.I1.i7.p1.11.m11.1.1.3" xref="A2.I1.i7.p1.11.m11.1.1.3.cmml">s</mi></msup><annotation-xml encoding="MathML-Content" id="A2.I1.i7.p1.11.m11.1b"><apply id="A2.I1.i7.p1.11.m11.1.1.cmml" xref="A2.I1.i7.p1.11.m11.1.1"><csymbol cd="ambiguous" id="A2.I1.i7.p1.11.m11.1.1.1.cmml" xref="A2.I1.i7.p1.11.m11.1.1">superscript</csymbol><ci id="A2.I1.i7.p1.11.m11.1.1.2.cmml" xref="A2.I1.i7.p1.11.m11.1.1.2">ğœ½</ci><ci id="A2.I1.i7.p1.11.m11.1.1.3.cmml" xref="A2.I1.i7.p1.11.m11.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i7.p1.11.m11.1c">\bm{\theta}^{s}</annotation></semantics></math> as <math id="A2.I1.i7.p1.12.m12.1" class="ltx_Math" alttext="2" display="inline"><semantics id="A2.I1.i7.p1.12.m12.1a"><mn id="A2.I1.i7.p1.12.m12.1.1" xref="A2.I1.i7.p1.12.m12.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="A2.I1.i7.p1.12.m12.1b"><cn type="integer" id="A2.I1.i7.p1.12.m12.1.1.cmml" xref="A2.I1.i7.p1.12.m12.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i7.p1.12.m12.1c">2</annotation></semantics></math>, learning rate of <math id="A2.I1.i7.p1.13.m13.1" class="ltx_Math" alttext="\bm{\theta}^{p}" display="inline"><semantics id="A2.I1.i7.p1.13.m13.1a"><msup id="A2.I1.i7.p1.13.m13.1.1" xref="A2.I1.i7.p1.13.m13.1.1.cmml"><mi id="A2.I1.i7.p1.13.m13.1.1.2" xref="A2.I1.i7.p1.13.m13.1.1.2.cmml">ğœ½</mi><mi id="A2.I1.i7.p1.13.m13.1.1.3" xref="A2.I1.i7.p1.13.m13.1.1.3.cmml">p</mi></msup><annotation-xml encoding="MathML-Content" id="A2.I1.i7.p1.13.m13.1b"><apply id="A2.I1.i7.p1.13.m13.1.1.cmml" xref="A2.I1.i7.p1.13.m13.1.1"><csymbol cd="ambiguous" id="A2.I1.i7.p1.13.m13.1.1.1.cmml" xref="A2.I1.i7.p1.13.m13.1.1">superscript</csymbol><ci id="A2.I1.i7.p1.13.m13.1.1.2.cmml" xref="A2.I1.i7.p1.13.m13.1.1.2">ğœ½</ci><ci id="A2.I1.i7.p1.13.m13.1.1.3.cmml" xref="A2.I1.i7.p1.13.m13.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i7.p1.13.m13.1c">\bm{\theta}^{p}</annotation></semantics></math> as <math id="A2.I1.i7.p1.14.m14.1" class="ltx_Math" alttext="0.1" display="inline"><semantics id="A2.I1.i7.p1.14.m14.1a"><mn id="A2.I1.i7.p1.14.m14.1.1" xref="A2.I1.i7.p1.14.m14.1.1.cmml">0.1</mn><annotation-xml encoding="MathML-Content" id="A2.I1.i7.p1.14.m14.1b"><cn type="float" id="A2.I1.i7.p1.14.m14.1.1.cmml" xref="A2.I1.i7.p1.14.m14.1.1">0.1</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i7.p1.14.m14.1c">0.1</annotation></semantics></math>, and epoch number of <math id="A2.I1.i7.p1.15.m15.1" class="ltx_Math" alttext="\bm{\theta}^{p}" display="inline"><semantics id="A2.I1.i7.p1.15.m15.1a"><msup id="A2.I1.i7.p1.15.m15.1.1" xref="A2.I1.i7.p1.15.m15.1.1.cmml"><mi id="A2.I1.i7.p1.15.m15.1.1.2" xref="A2.I1.i7.p1.15.m15.1.1.2.cmml">ğœ½</mi><mi id="A2.I1.i7.p1.15.m15.1.1.3" xref="A2.I1.i7.p1.15.m15.1.1.3.cmml">p</mi></msup><annotation-xml encoding="MathML-Content" id="A2.I1.i7.p1.15.m15.1b"><apply id="A2.I1.i7.p1.15.m15.1.1.cmml" xref="A2.I1.i7.p1.15.m15.1.1"><csymbol cd="ambiguous" id="A2.I1.i7.p1.15.m15.1.1.1.cmml" xref="A2.I1.i7.p1.15.m15.1.1">superscript</csymbol><ci id="A2.I1.i7.p1.15.m15.1.1.2.cmml" xref="A2.I1.i7.p1.15.m15.1.1.2">ğœ½</ci><ci id="A2.I1.i7.p1.15.m15.1.1.3.cmml" xref="A2.I1.i7.p1.15.m15.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i7.p1.15.m15.1c">\bm{\theta}^{p}</annotation></semantics></math> as <math id="A2.I1.i7.p1.16.m16.1" class="ltx_Math" alttext="1" display="inline"><semantics id="A2.I1.i7.p1.16.m16.1a"><mn id="A2.I1.i7.p1.16.m16.1.1" xref="A2.I1.i7.p1.16.m16.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="A2.I1.i7.p1.16.m16.1b"><cn type="integer" id="A2.I1.i7.p1.16.m16.1.1.cmml" xref="A2.I1.i7.p1.16.m16.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i7.p1.16.m16.1c">1</annotation></semantics></math>.</p>
</div>
</li>
</ul>
</div>
</section>
</section>
<section id="A3" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A3 </span>Detailed Experimental Results</h2>

<section id="A3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A3.1. </span>Experimental Results about IID Setting</h3>

<div id="A3.SS1.p1" class="ltx_para">
<p id="A3.SS1.p1.1" class="ltx_p">In this section, we demonstrate attack results on pFL methods under IID setting in which we uniformly and randomly sample images from each class of CIFAR-10 for each client. The results are shown in FigureÂ <a href="#A2.F11" title="Figure A11 â€£ A2.1. More Details of Attacks Hyper-parameters â€£ Appendix A2 Implementation Details â€£ Revisiting Personalized Federated Learning: Robustness Against Backdoor Attacks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A11</span></a>. We have similar observations as in the Non-IID scenario: â¶ Under IID setting, for all pFL methods, backdoor attacks do still not affect C-Acc. â· Under IID setting, Blended attack (the solid red line) also achieves the best ASR on all pFL methods and CIFAR-10 dataset. â¸ pFL methods with partial model-sharing also achieve better defense performance against backdoor attacks. Compared with attack results under Non-IID setting, attack results on FedBN under IID setting are higher. We have analysed reasons in SectionÂ <a href="#S5.SS1" title="5.1. pFL Methods with Partial model-sharing â€£ 5. Analysis of Various Robustness from pFL Against Backdoor Attacks â€£ Revisiting Personalized Federated Learning: Robustness Against Backdoor Attacks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.1</span></a>. â¹ Under IID scenario, we still observe that backdoor attacks achieves better attack performance on high-capacity model (ResNet-18) than on low-capacity model (ConvNet).</p>
</div>
</section>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2302.01675" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2302.01677" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2302.01677">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2302.01677" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2302.01678" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Feb 29 22:23:01 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
