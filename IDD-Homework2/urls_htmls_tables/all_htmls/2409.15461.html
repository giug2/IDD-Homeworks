<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented Multi-role Multi-expert Collaboration</title>
<!--Generated on Mon Sep 23 18:34:46 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2409.15461v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#S1" title="In RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented Multi-role Multi-expert Collaboration"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#S2" title="In RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented Multi-role Multi-expert Collaboration"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Methodology</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#S2.SS1" title="In 2 Methodology ‣ RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented Multi-role Multi-expert Collaboration"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Multi-role Multi-expert Collaboration</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#S2.SS2" title="In 2 Methodology ‣ RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented Multi-role Multi-expert Collaboration"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Retrieval Augmented Experts</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#S3" title="In RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented Multi-role Multi-expert Collaboration"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#S3.SS1" title="In 3 Experiments ‣ RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented Multi-role Multi-expert Collaboration"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Experimental Setup</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#S3.SS1.SSS0.Px1" title="In 3.1 Experimental Setup ‣ 3 Experiments ‣ RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented Multi-role Multi-expert Collaboration"><span class="ltx_text ltx_ref_title">Scenario settings.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#S3.SS1.SSS0.Px2" title="In 3.1 Experimental Setup ‣ 3 Experiments ‣ RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented Multi-role Multi-expert Collaboration"><span class="ltx_text ltx_ref_title">Multi-source knowledge base.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#S3.SS2" title="In 3 Experiments ‣ RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented Multi-role Multi-expert Collaboration"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Model Fine-tuning</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#S3.SS3" title="In 3 Experiments ‣ RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented Multi-role Multi-expert Collaboration"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Evaluation Set Construction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#S3.SS4" title="In 3 Experiments ‣ RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented Multi-role Multi-expert Collaboration"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4 </span>Evaluation Results</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#S3.SS4.SSS0.Px1" title="In 3.4 Evaluation Results ‣ 3 Experiments ‣ RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented Multi-role Multi-expert Collaboration"><span class="ltx_text ltx_ref_title">Ablation studies.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#S3.SS5" title="In 3 Experiments ‣ RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented Multi-role Multi-expert Collaboration"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.5 </span>Case Study</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#S4" title="In RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented Multi-role Multi-expert Collaboration"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#S5" title="In RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented Multi-role Multi-expert Collaboration"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Limitations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#A1" title="In RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented Multi-role Multi-expert Collaboration"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Related Work</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#A1.SS1" title="In Appendix A Related Work ‣ RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented Multi-role Multi-expert Collaboration"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.1 </span>Educational chatbots</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#A1.SS2" title="In Appendix A Related Work ‣ RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented Multi-role Multi-expert Collaboration"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.2 </span>Prompt engineering</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#A1.SS3" title="In Appendix A Related Work ‣ RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented Multi-role Multi-expert Collaboration"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.3 </span>Retrieval augmented generation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#A1.SS4" title="In Appendix A Related Work ‣ RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented Multi-role Multi-expert Collaboration"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.4 </span>Human preference alignment on education</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#A2" title="In RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented Multi-role Multi-expert Collaboration"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B </span><span class="ltx_text ltx_font_bold">HTS</span>: multi-dimensional challenge for educational dialogue</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#A2.SS1" title="In Appendix B HTS: multi-dimensional challenge for educational dialogue ‣ RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented Multi-role Multi-expert Collaboration"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.1 </span>Humanized communication</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#A2.SS1.SSS0.Px1" title="In B.1 Humanized communication ‣ Appendix B HTS: multi-dimensional challenge for educational dialogue ‣ RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented Multi-role Multi-expert Collaboration"><span class="ltx_text ltx_ref_title">Cultural competence:</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#A2.SS1.SSS0.Px2" title="In B.1 Humanized communication ‣ Appendix B HTS: multi-dimensional challenge for educational dialogue ‣ RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented Multi-role Multi-expert Collaboration"><span class="ltx_text ltx_ref_title">Active supportiveness:</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#A2.SS1.SSS0.Px3" title="In B.1 Humanized communication ‣ Appendix B HTS: multi-dimensional challenge for educational dialogue ‣ RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented Multi-role Multi-expert Collaboration"><span class="ltx_text ltx_ref_title">Emotional feedback:</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#A2.SS2" title="In Appendix B HTS: multi-dimensional challenge for educational dialogue ‣ RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented Multi-role Multi-expert Collaboration"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.2 </span>Teaching expertise</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#A2.SS2.SSS0.Px1" title="In B.2 Teaching expertise ‣ Appendix B HTS: multi-dimensional challenge for educational dialogue ‣ RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented Multi-role Multi-expert Collaboration"><span class="ltx_text ltx_ref_title">Assessment proficiency:</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#A2.SS2.SSS0.Px2" title="In B.2 Teaching expertise ‣ Appendix B HTS: multi-dimensional challenge for educational dialogue ‣ RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented Multi-role Multi-expert Collaboration"><span class="ltx_text ltx_ref_title">Subject mastery:</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#A2.SS2.SSS0.Px3" title="In B.2 Teaching expertise ‣ Appendix B HTS: multi-dimensional challenge for educational dialogue ‣ RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented Multi-role Multi-expert Collaboration"><span class="ltx_text ltx_ref_title">Pedagogical skills:</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#A2.SS2.SSS0.Px4" title="In B.2 Teaching expertise ‣ Appendix B HTS: multi-dimensional challenge for educational dialogue ‣ RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented Multi-role Multi-expert Collaboration"><span class="ltx_text ltx_ref_title">Accurate response:</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#A2.SS3" title="In Appendix B HTS: multi-dimensional challenge for educational dialogue ‣ RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented Multi-role Multi-expert Collaboration"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.3 </span>Safety and ethics</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#A2.SS3.SSS0.Px1" title="In B.3 Safety and ethics ‣ Appendix B HTS: multi-dimensional challenge for educational dialogue ‣ RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented Multi-role Multi-expert Collaboration"><span class="ltx_text ltx_ref_title">Data privacy:</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#A2.SS3.SSS0.Px2" title="In B.3 Safety and ethics ‣ Appendix B HTS: multi-dimensional challenge for educational dialogue ‣ RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented Multi-role Multi-expert Collaboration"><span class="ltx_text ltx_ref_title">Content appropriateness:</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#A2.SS3.SSS0.Px3" title="In B.3 Safety and ethics ‣ Appendix B HTS: multi-dimensional challenge for educational dialogue ‣ RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented Multi-role Multi-expert Collaboration"><span class="ltx_text ltx_ref_title">Abuse prevention:</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#A3" title="In RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented Multi-role Multi-expert Collaboration"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C </span>Multi-source knowledge base</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#A4" title="In RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented Multi-role Multi-expert Collaboration"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">D </span>Evaluation dataset and criteria</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<h1 class="ltx_title ltx_title_document">RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented Multi-role Multi-expert Collaboration</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
<span class="ltx_text ltx_font_bold" id="id1.1.id1">Haoyu Huang<sup class="ltx_sup" id="id1.1.id1.1">1,2,3,4,5</sup></span>,
<span class="ltx_text ltx_font_bold" id="id2.2.id2">Tong Niu<sup class="ltx_sup" id="id2.2.id2.1">1,2,3,4,5</sup></span>,
<span class="ltx_text ltx_font_bold" id="id3.3.id3">Rui Yang<sup class="ltx_sup" id="id3.3.id3.1">1,2,3,4,5</sup></span>,
<span class="ltx_text ltx_font_bold" id="id4.4.id4">Luping Shi<sup class="ltx_sup" id="id4.4.id4.1">1,2,3,4,5</sup></span>
<br class="ltx_break"/><sup class="ltx_sup" id="id5.5.id5">1</sup>Center for Brain Inspired Computing Research (CBICR), Tsinghua University, Beijing, China,
<br class="ltx_break"/><sup class="ltx_sup" id="id6.6.id6">2</sup>Optical Memory National Engineering Research Center, Tsinghua University, Beijing, China, 
<br class="ltx_break"/><sup class="ltx_sup" id="id7.7.id7">3</sup>Tsinghua University-China Electronics Technology HIK Group Co. Joint Research Center for Brain-inspired Computing, Beijing, China, 
<br class="ltx_break"/><sup class="ltx_sup" id="id8.8.id8">4</sup>IDG/McGovern Institute for Brain Research, Tsinghua University, Beijing, China, 
<br class="ltx_break"/><sup class="ltx_sup" id="id9.9.id9">5</sup>Department of Precision Instrument, Tsinghua University, Beijing 100084, China 
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="id10.10.id10">Correspondence:</span> <a class="ltx_ref ltx_href" href="mailto:lpshi@mail.tsinghua.edu.cn" title="">lpshi@mail.tsinghua.edu.cn</a>
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id11.id1">Recently, many studies focus on utilizing large language models (LLMs) into educational dialogues. Especially, within liberal arts dialogues, educators must balance <span class="ltx_text ltx_font_bold" id="id11.id1.1">H</span>umanized communication, <span class="ltx_text ltx_font_bold" id="id11.id1.2">T</span>eaching expertise, and <span class="ltx_text ltx_font_bold" id="id11.id1.3">S</span>afety-ethics (<span class="ltx_text ltx_font_bold" id="id11.id1.4">HTS</span>), besides the subject knowledge itself. However, due to collecting massive amounts of HTS-compliant teaching dialogues from real world as training corpus is expensive, the outputs of existing LLMs in teaching dialogues fall short of human standards. To address this, we design a Retrieval-augmented Multi-role Multi-expert Collaboration (RAM2C) framework to automatically generate such dialogues data. Specifically, we first establish HTS-guided knowledge bases, encompassing three domain knowledge in teaching skills, psychology, and safety ethics. Then, RAM2C organizes LLMs, which are retrieval-augmented by the above different knowledge bases, into multi-experts groups with distinct roles to generate the HTS-compliant educational dialogues dataset. We then fine-tuned the LLMs using this dataset. Empirical evaluations indicate that RM2C-empowered LLMs excel in Chinese reading teaching, offering more personalized, and ethically safe teaching response, demonstrating RAM2C’s practicality and high quality. We release the experiments at <a class="ltx_ref ltx_href" href="https://github.com/ram2c/ram2c" title="">https://github.com/ram2c/ram2c</a>.</p>
</div>
<div class="ltx_para ltx_noindent" id="p1">
<div class="ltx_block ltx_align_bottom" id="p1.1">
<p class="ltx_p" id="p1.1.1"><span class="ltx_text ltx_font_bold" id="p1.1.1.1">RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented Multi-role Multi-expert Collaboration</span></p>
<br class="ltx_break ltx_centering"/>
<p class="ltx_p ltx_align_center" id="p1.1.2" style="width:433.6pt;"><span class="ltx_text ltx_inline-block" id="p1.1.2.1" style="width:0.0pt;">
<span class="ltx_tabular ltx_align_top" id="p1.1.2.1.1">
<span class="ltx_tbody">
<span class="ltx_tr" id="p1.1.2.1.1.1.1">
<span class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="p1.1.2.1.1.1.1.1" style="padding-left:0.0pt;padding-right:0.0pt;"><span class="ltx_text ltx_font_bold" id="p1.1.2.1.1.1.1.1.1">
Haoyu Huang<sup class="ltx_sup" id="p1.1.2.1.1.1.1.1.1.1">1,2,3,4,5</sup>,
Tong Niu<sup class="ltx_sup" id="p1.1.2.1.1.1.1.1.1.2">1,2,3,4,5</sup>,
Rui Yang<sup class="ltx_sup" id="p1.1.2.1.1.1.1.1.1.3">1,2,3,4,5</sup>,
Luping Shi<sup class="ltx_sup" id="p1.1.2.1.1.1.1.1.1.4">1,2,3,4,5</sup></span></span></span>
<span class="ltx_tr" id="p1.1.2.1.1.2.2">
<span class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="p1.1.2.1.1.2.2.1" style="padding-left:0.0pt;padding-right:0.0pt;"><sup class="ltx_sup" id="p1.1.2.1.1.2.2.1.1">1</sup>Center for Brain Inspired Computing Research (CBICR), Tsinghua University, Beijing, China,</span></span>
<span class="ltx_tr" id="p1.1.2.1.1.3.3">
<span class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="p1.1.2.1.1.3.3.1" style="padding-left:0.0pt;padding-right:0.0pt;"><sup class="ltx_sup" id="p1.1.2.1.1.3.3.1.1">2</sup>Optical Memory National Engineering Research Center, Tsinghua University, Beijing, China,</span></span>
<span class="ltx_tr" id="p1.1.2.1.1.4.4">
<span class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="p1.1.2.1.1.4.4.1" style="padding-left:0.0pt;padding-right:0.0pt;"><sup class="ltx_sup" id="p1.1.2.1.1.4.4.1.1">3</sup>Tsinghua University-China Electronics Technology HIK Group Co. Joint Research Center for Brain-inspired Computing, Beijing, China,</span></span>
<span class="ltx_tr" id="p1.1.2.1.1.5.5">
<span class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="p1.1.2.1.1.5.5.1" style="padding-left:0.0pt;padding-right:0.0pt;"><sup class="ltx_sup" id="p1.1.2.1.1.5.5.1.1">4</sup>IDG/McGovern Institute for Brain Research, Tsinghua University, Beijing, China,</span></span>
<span class="ltx_tr" id="p1.1.2.1.1.6.6">
<span class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="p1.1.2.1.1.6.6.1" style="padding-left:0.0pt;padding-right:0.0pt;"><sup class="ltx_sup" id="p1.1.2.1.1.6.6.1.1">5</sup>Department of Precision Instrument, Tsinghua University, Beijing 100084, China</span></span>
<span class="ltx_tr" id="p1.1.2.1.1.7.7">
<span class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="p1.1.2.1.1.7.7.1" style="padding-left:0.0pt;padding-right:0.0pt;"><span class="ltx_text ltx_font_bold" id="p1.1.2.1.1.7.7.1.1">Correspondence:</span> <a class="ltx_ref ltx_href" href="mailto:lpshi@mail.tsinghua.edu.cn" title="">lpshi@mail.tsinghua.edu.cn</a></span></span>
</span>
</span></span></p>
<br class="ltx_break ltx_centering"/>
</div>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">As generative artificial intelligence advances, educational chatbots based on large language models (LLMs) are hoped to provide promising educational services in many scenarios of liberal arts, like literature reading, writing and debating. Specifically, compared to subject-specific factual knowledge, the rich and personalized linguistic forms, teaching skills, along with ethical safety involved in content analysis (<span class="ltx_text ltx_font_bold" id="S1.p1.1.1">HTS</span> in Fig.<a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented Multi-role Multi-expert Collaboration"><span class="ltx_text ltx_ref_tag">1</span></a> <span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Detailed description in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#A2" title="Appendix B HTS: multi-dimensional challenge for educational dialogue ‣ RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented Multi-role Multi-expert Collaboration"><span class="ltx_text ltx_ref_tag">B</span></a>.</span></span></span>), are equally important in liberal educational dialogues <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#bib.bib31" title="">2024</a>; Deng et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#bib.bib8" title="">2023</a>; Li et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#bib.bib16" title="">2023</a>)</cite>. However, due to the difficulty of collecting a sufficient amount of HTS-compliant teacher-student multi-turn dialogue data from real teaching scenarios for optimizing LLMs, the responses of existing LLMs to real educational contexts are unable to meet the HTS requirements.</p>
</div>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="250" id="S1.F1.g1" src="x1.png" width="249"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span><span class="ltx_text ltx_font_bold" id="S1.F1.2.1">HTS</span>: Multi-dimensional educational dialogue quality challenges.</figcaption>
</figure>
<figure class="ltx_figure" id="S1.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="283" id="S1.F2.g1" src="x2.png" width="747"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>The design of Multi-role Multi-expert Collaboration (M2C).
<span class="ltx_text ltx_font_bold" id="S1.F2.4.1">a)</span> Experts with different roles are gathered. The raw response from basic LLM are revised sequentially by T-Group (step 1), P-Group (step 2) and E-Group (step 3). All LLM experts in different roles are characterized by different personal profiles and retrieval augmented by different HTS knowledge bases.
<span class="ltx_text ltx_font_bold" id="S1.F2.5.2">b)</span> In a single-role collaboration, the raw response, the current discussion topic and the student context are concatenated as the context of the refinement. Experts initially conduct individual analyses, thereafter synthesize their insights into one modification. The final response from the third group will be relayed to students.
<span class="ltx_text ltx_font_bold" id="S1.F2.6.3">c)</span> Educational preference data is collected from the output of M2C procedure. The LLM use these preference data to improve its intrinsic capability using direct preference optimization (DPO) algorithm.</figcaption>
</figure>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">To address these challenges, we propose a framework named <span class="ltx_text ltx_font_bold" id="S1.p2.1.1">R</span>etrieval-<span class="ltx_text ltx_font_bold" id="S1.p2.1.2">A</span>ugmented <span class="ltx_text ltx_font_bold" id="S1.p2.1.3">M</span>ulti-role <span class="ltx_text ltx_font_bold" id="S1.p2.1.4">M</span>ulti-expert <span class="ltx_text ltx_font_bold" id="S1.p2.1.5">C</span>ollaboration (RAM2C), capable of rapidly and cost-effectively generating HTS-compliant liberal arts educational dialogues by unleashing the individual intrinsic capability (role-playing by in-context learning), extrinsic capability (retrieval-augmented generation), and collective capability (multi-experts generation synthesizing) of LLMs. The specific work flow is shown in Fig.<a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#S1.F2" title="Figure 2 ‣ 1 Introduction ‣ RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented Multi-role Multi-expert Collaboration"><span class="ltx_text ltx_ref_tag">2</span></a>a, 2b.
The generated high-valued dialogues are used to execute the <span class="ltx_text ltx_font_bold" id="S1.p2.1.6">HTS</span> preference alignment of LLMs (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#S1.F2" title="Figure 2 ‣ 1 Introduction ‣ RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented Multi-role Multi-expert Collaboration"><span class="ltx_text ltx_ref_tag">2</span></a>c), which aims to promote the intrinsic capability of basic LLMs to analyze references and generate responses.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">In this paper, our contributions can be summarized as follows:</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">(1) An automated HTS-compliant dialogue generation framework that utilizes multi-role multi-agent collaboration, along with an improved RAG.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">(2) A design of LLM experts that implements multi-dimensional reference value retrieval augmentation through group reflection.</p>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">(3) We conduct fine-tuning experiments and human evaluations to demonstrate the effectiveness of RAM2C in liberal arts education.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Methodology</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">In this section, we elaborate on the principle components in RAM2C, as shown in Fig.<a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#S1.F2" title="Figure 2 ‣ 1 Introduction ‣ RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented Multi-role Multi-expert Collaboration"><span class="ltx_text ltx_ref_tag">2</span></a> and Fig.<a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#S2.F3" title="Figure 3 ‣ 2 Methodology ‣ RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented Multi-role Multi-expert Collaboration"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<figure class="ltx_figure" id="S2.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="315" id="S2.F3.g1" src="x3.png" width="398"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>A schematic diagram of retrieval augmented experts, using the T-Group as an example. The revision of a raw response from the basic LLM is generated through proactive analysis of the student context and the accepted documents. The documents are retrieved from a multi-source knowledge base and subsequently filtered through group reflection, that is, the multi-dimensional value assessments of the retrieved documents.</figcaption>
</figure>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Multi-role Multi-expert Collaboration</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">Unlike multi-role single-agent collaboration<cite class="ltx_cite ltx_citemacro_cite">Tang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#bib.bib30" title="">2023</a>)</cite> and single-role multi-agent collaboration<cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#bib.bib34" title="">2023b</a>)</cite>, we utilize prompt engineering to create three groups of LLM experts with distinct roles: <span class="ltx_text ltx_font_bold" id="S2.SS1.p1.1.1">T-Group</span>: Chinese language teachers, <span class="ltx_text ltx_font_bold" id="S2.SS1.p1.1.2">P-Group</span>: educational psychologists, and <span class="ltx_text ltx_font_bold" id="S2.SS1.p1.1.3">E-Group</span>: ethical safety experts, with 3 experts for each role, as shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#S1.F2" title="Figure 2 ‣ 1 Introduction ‣ RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented Multi-role Multi-expert Collaboration"><span class="ltx_text ltx_ref_tag">2</span></a>a.</p>
</div>
<figure class="ltx_figure" id="S2.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="216" id="S2.F4.g1" src="extracted/5870382/imgs/ntfig1.png" width="479"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Grading of retrieval documents by deep sentence embedding model bge-reranker-v2-m3 and group of LLM experts. <span class="ltx_text ltx_font_bold" id="S2.F4.4.1">a)</span> Top: RAM2C starts a topic.Bottom: a student gives the answer. <span class="ltx_text ltx_font_bold" id="S2.F4.5.2">b)</span> Retrieval documents #4, #5 and #15 according to the topic and answer.
Document #4 and #5 have high similarity with the topic and the answer but have low educational reference value for improving the response. While the document #15 is actually the high-value reference which could inspire the analysis of similar topic.
<span class="ltx_text ltx_font_bold" id="S2.F4.6.3">c)</span> From top to bottom: voting scores of documents #0 - #17 by 7, 5, 3 teacher experts, similarity scores between the answer and documents, similarity scores between the topic and documents by the bge-reranker-v2-m3.
</figcaption>
</figure>
<div class="ltx_para" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1">The refinement of dialogue responses, as a sequential task flow, is completed by T/P/E-Group collaboration in turn. Specifically, as depicted in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#S1.F2" title="Figure 2 ‣ 1 Introduction ‣ RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented Multi-role Multi-expert Collaboration"><span class="ltx_text ltx_ref_tag">2</span></a>b, the initial response generated by a basic LLM, along with the current topic and student context, is provided to the T-Group for analysis and synthesis. The resulting output then serves as the input for the P-Group. This process is similarly applied to the remaining groups. Ultimately, the final response, which has been subjected to ethical scrutiny by the E-Group, is conveyed to the students.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Retrieval Augmented Experts</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">Due to the lack of relevant corpus support for LLMs in various liberal arts education scenarios, it is necessary to establish a multi-source knowledge base to provide references.</p>
</div>
<div class="ltx_para" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1">We emphasize that, unlike general RAG systems, which provide references that enhance the factual accuracy of LLMs outputs, LLMs for liberal arts dialogues need demonstrations or inspiration from documents with varying reference values. For instance, aspects such as language style, vocabulary usage, and logical connections in these documents are particularly beneficial for improving humanized communication of LLMs. These complex semantic structures cannot be achieved solely through semantic vector matching. As shown in Fig.<a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#S2.F4" title="Figure 4 ‣ 2.1 Multi-role Multi-expert Collaboration ‣ 2 Methodology ‣ RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented Multi-role Multi-expert Collaboration"><span class="ltx_text ltx_ref_tag">4</span></a>b, vector databases are likely to return relevant but lower reference value documents.</p>
</div>
<div class="ltx_para" id="S2.SS2.p3">
<p class="ltx_p" id="S2.SS2.p3.1">Therefore, after obtaining preliminary retrieved documents, we convene an expert group to analyze and vote from multiple perspectives, thereby filtering a diverse set of references with real reference value, see Document #15 in Fig.<a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#S2.F4" title="Figure 4 ‣ 2.1 Multi-role Multi-expert Collaboration ‣ 2 Methodology ‣ RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented Multi-role Multi-expert Collaboration"><span class="ltx_text ltx_ref_tag">4</span></a>b. During the in-group collaboration, each expert is assigned to different references, and is required to generate explicit analysis to its reference (<span class="ltx_text ltx_font_bold" id="S2.SS2.p3.1.1">proactive analysis</span> to form diverse chains of thought, as shown in Fig.<a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#S2.F3" title="Figure 3 ‣ 2 Methodology ‣ RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented Multi-role Multi-expert Collaboration"><span class="ltx_text ltx_ref_tag">3</span></a>). The individual revision of the raw response is then generated by utilizing this analysis.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Experiments</h2>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Experimental Setup</h3>
<section class="ltx_paragraph" id="S3.SS1.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Scenario settings.</h4>
<div class="ltx_para" id="S3.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="S3.SS1.SSS0.Px1.p1.1">We select the scenario of literature discussion as an demonstration of educational dialogues, where students discuss several topics about the novel "<span class="ltx_text ltx_font_italic" id="S3.SS1.SSS0.Px1.p1.1.1">Robinson Crusoe</span>" with an LLM teacher who provides real-time feedback to promote the progress of dialogue.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS1.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Multi-source knowledge base.</h4>
<div class="ltx_para" id="S3.SS1.SSS0.Px2.p1">
<p class="ltx_p" id="S3.SS1.SSS0.Px2.p1.1">We construct a multi-source knowledge vector database for literature art reading. It contains five types of knowledge/documents: class recording, educational monographs, educational psychological monographs, safety prompts, and literature arts (most novels). Details in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#A3" title="Appendix C Multi-source knowledge base ‣ RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented Multi-role Multi-expert Collaboration"><span class="ltx_text ltx_ref_tag">C</span></a>.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Model Fine-tuning</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">We use RAM2C to organize GLM-4 and generate a preference alignment dataset, which contains 3,500 dialogues. Each sample of this dataset is a <span class="ltx_text ltx_font_typewriter" id="S3.SS2.p1.1.1">(Q,A,R1,R2)</span> pair, as shown in Fig.<a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#S1.F2" title="Figure 2 ‣ 1 Introduction ‣ RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented Multi-role Multi-expert Collaboration"><span class="ltx_text ltx_ref_tag">2</span></a>c, where <span class="ltx_text ltx_font_typewriter" id="S3.SS2.p1.1.2">Q</span> is the discussion topic generated by RAM2C, <span class="ltx_text ltx_font_typewriter" id="S3.SS2.p1.1.3">A</span> is the answer by LLM-simulated student, and <span class="ltx_text ltx_font_typewriter" id="S3.SS2.p1.1.4">R1</span> is the chosen response from RAM2C-GLM4, <span class="ltx_text ltx_font_typewriter" id="S3.SS2.p1.1.5">R2</span> is the rejected one by the lightweight model without fine-tuning. We conduct fine-tuning experiments on lightweight models including Qwen1.5-4B<cite class="ltx_cite ltx_citemacro_cite">Bai et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#bib.bib2" title="">2023</a>)</cite>, MiniCPM-2B<cite class="ltx_cite ltx_citemacro_cite">Hu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#bib.bib12" title="">2024</a>)</cite>, and ChatGLM3-6b<cite class="ltx_cite ltx_citemacro_cite">Du et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#bib.bib9" title="">2022</a>)</cite>, based on Llama-Factory<cite class="ltx_cite ltx_citemacro_cite">Zheng et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#bib.bib41" title="">2024</a>)</cite>.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Evaluation Set Construction</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">The dialogue in liberal arts education is characterized by a strong subjectivity, in contrast to question-answer tasks evaluated based on factual correctness. Therefore, we recruit sixteen volunteers, including primary and secondary school teachers as well as university researchers, to evaluate the fine-tuned models across three dimensions (<span class="ltx_text ltx_font_bold" id="S3.SS3.p1.1.1">HTS</span>). For each fine-tuned model, we construct a dialogue sample set, which structure is similar to the fine-tuning dataset in Section<a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#S3.SS2" title="3.2 Model Fine-tuning ‣ 3 Experiments ‣ RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented Multi-role Multi-expert Collaboration"><span class="ltx_text ltx_ref_tag">3.2</span></a>. More details can be found in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#A4" title="Appendix D Evaluation dataset and criteria ‣ RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented Multi-role Multi-expert Collaboration"><span class="ltx_text ltx_ref_tag">D</span></a>.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Evaluation Results</h3>
<div class="ltx_para" id="S3.SS4.p1">
<p class="ltx_p" id="S3.SS4.p1.1">Tab. <a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#S3.T1" title="Table 1 ‣ 3.4 Evaluation Results ‣ 3 Experiments ‣ RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented Multi-role Multi-expert Collaboration"><span class="ltx_text ltx_ref_tag">1</span></a> compares the performance of the fine-tuned model with its original version across three dimensions <span class="ltx_text ltx_font_bold" id="S3.SS4.p1.1.1">HTS</span>. The results show that the fine-tuned model outperforms the original model in all three dimensions, particularly in humanized communication and teaching expertise. And the scores of inter-annotation agreement (IAA) show the moderate agreement between the volunteers’ evaluation.</p>
</div>
<div class="ltx_para" id="S3.SS4.p2">
<p class="ltx_p" id="S3.SS4.p2.1">We also compared the performance between the fine-tuned lightweight model and mainstream Chinese commercial model GLM-4. As shown in Tab. <a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#S3.T2" title="Table 2 ‣ 3.4 Evaluation Results ‣ 3 Experiments ‣ RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented Multi-role Multi-expert Collaboration"><span class="ltx_text ltx_ref_tag">2</span></a>, fine-tuned models can largely compete with GLM-4 that do not use RAM2C integration. And the RAM2C-empowered GLM-4 exhibits the highest level of performance.</p>
</div>
<figure class="ltx_table" id="S3.T1">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S3.T1.9">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T1.9.10.1">
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S3.T1.9.10.1.1" style="padding-left:0.0pt;padding-right:0.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.9.10.1.1.1">Criteria</span></th>
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T1.9.10.1.2" style="padding-left:0.0pt;padding-right:0.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.9.10.1.2.1">H</span></th>
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T1.9.10.1.3" style="padding-left:0.0pt;padding-right:0.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.9.10.1.3.1">T</span></th>
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T1.9.10.1.4" style="padding-left:0.0pt;padding-right:0.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.9.10.1.4.1">S</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T1.3.3">
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S3.T1.3.3.4" style="padding-left:0.0pt;padding-right:0.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.3.3.4.1">Qwen1.5</span></th>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S3.T1.1.1.1" style="padding-left:0.0pt;padding-right:0.0pt;"><math alttext="74.8\ (0.42)" class="ltx_Math" display="inline" id="S3.T1.1.1.1.m1.1"><semantics id="S3.T1.1.1.1.m1.1a"><mrow id="S3.T1.1.1.1.m1.1.2" xref="S3.T1.1.1.1.m1.1.2.cmml"><mn id="S3.T1.1.1.1.m1.1.2.2" xref="S3.T1.1.1.1.m1.1.2.2.cmml">74.8</mn><mo id="S3.T1.1.1.1.m1.1.2.1" lspace="0.500em" xref="S3.T1.1.1.1.m1.1.2.1.cmml">⁢</mo><mrow id="S3.T1.1.1.1.m1.1.2.3.2" xref="S3.T1.1.1.1.m1.1.2.cmml"><mo id="S3.T1.1.1.1.m1.1.2.3.2.1" stretchy="false" xref="S3.T1.1.1.1.m1.1.2.cmml">(</mo><mn id="S3.T1.1.1.1.m1.1.1" xref="S3.T1.1.1.1.m1.1.1.cmml">0.42</mn><mo id="S3.T1.1.1.1.m1.1.2.3.2.2" stretchy="false" xref="S3.T1.1.1.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.1.1.1.m1.1b"><apply id="S3.T1.1.1.1.m1.1.2.cmml" xref="S3.T1.1.1.1.m1.1.2"><times id="S3.T1.1.1.1.m1.1.2.1.cmml" xref="S3.T1.1.1.1.m1.1.2.1"></times><cn id="S3.T1.1.1.1.m1.1.2.2.cmml" type="float" xref="S3.T1.1.1.1.m1.1.2.2">74.8</cn><cn id="S3.T1.1.1.1.m1.1.1.cmml" type="float" xref="S3.T1.1.1.1.m1.1.1">0.42</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.1.1.1.m1.1c">74.8\ (0.42)</annotation><annotation encoding="application/x-llamapun" id="S3.T1.1.1.1.m1.1d">74.8 ( 0.42 )</annotation></semantics></math></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S3.T1.2.2.2" style="padding-left:0.0pt;padding-right:0.0pt;"><math alttext="65.2\ (0.45)" class="ltx_Math" display="inline" id="S3.T1.2.2.2.m1.1"><semantics id="S3.T1.2.2.2.m1.1a"><mrow id="S3.T1.2.2.2.m1.1.2" xref="S3.T1.2.2.2.m1.1.2.cmml"><mn id="S3.T1.2.2.2.m1.1.2.2" xref="S3.T1.2.2.2.m1.1.2.2.cmml">65.2</mn><mo id="S3.T1.2.2.2.m1.1.2.1" lspace="0.500em" xref="S3.T1.2.2.2.m1.1.2.1.cmml">⁢</mo><mrow id="S3.T1.2.2.2.m1.1.2.3.2" xref="S3.T1.2.2.2.m1.1.2.cmml"><mo id="S3.T1.2.2.2.m1.1.2.3.2.1" stretchy="false" xref="S3.T1.2.2.2.m1.1.2.cmml">(</mo><mn id="S3.T1.2.2.2.m1.1.1" xref="S3.T1.2.2.2.m1.1.1.cmml">0.45</mn><mo id="S3.T1.2.2.2.m1.1.2.3.2.2" stretchy="false" xref="S3.T1.2.2.2.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.2.2.2.m1.1b"><apply id="S3.T1.2.2.2.m1.1.2.cmml" xref="S3.T1.2.2.2.m1.1.2"><times id="S3.T1.2.2.2.m1.1.2.1.cmml" xref="S3.T1.2.2.2.m1.1.2.1"></times><cn id="S3.T1.2.2.2.m1.1.2.2.cmml" type="float" xref="S3.T1.2.2.2.m1.1.2.2">65.2</cn><cn id="S3.T1.2.2.2.m1.1.1.cmml" type="float" xref="S3.T1.2.2.2.m1.1.1">0.45</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.2.2.2.m1.1c">65.2\ (0.45)</annotation><annotation encoding="application/x-llamapun" id="S3.T1.2.2.2.m1.1d">65.2 ( 0.45 )</annotation></semantics></math></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S3.T1.3.3.3" style="padding-left:0.0pt;padding-right:0.0pt;"><math alttext="73.3\ (0.37)" class="ltx_Math" display="inline" id="S3.T1.3.3.3.m1.1"><semantics id="S3.T1.3.3.3.m1.1a"><mrow id="S3.T1.3.3.3.m1.1.2" xref="S3.T1.3.3.3.m1.1.2.cmml"><mn id="S3.T1.3.3.3.m1.1.2.2" xref="S3.T1.3.3.3.m1.1.2.2.cmml">73.3</mn><mo id="S3.T1.3.3.3.m1.1.2.1" lspace="0.500em" xref="S3.T1.3.3.3.m1.1.2.1.cmml">⁢</mo><mrow id="S3.T1.3.3.3.m1.1.2.3.2" xref="S3.T1.3.3.3.m1.1.2.cmml"><mo id="S3.T1.3.3.3.m1.1.2.3.2.1" stretchy="false" xref="S3.T1.3.3.3.m1.1.2.cmml">(</mo><mn id="S3.T1.3.3.3.m1.1.1" xref="S3.T1.3.3.3.m1.1.1.cmml">0.37</mn><mo id="S3.T1.3.3.3.m1.1.2.3.2.2" stretchy="false" xref="S3.T1.3.3.3.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.3.3.3.m1.1b"><apply id="S3.T1.3.3.3.m1.1.2.cmml" xref="S3.T1.3.3.3.m1.1.2"><times id="S3.T1.3.3.3.m1.1.2.1.cmml" xref="S3.T1.3.3.3.m1.1.2.1"></times><cn id="S3.T1.3.3.3.m1.1.2.2.cmml" type="float" xref="S3.T1.3.3.3.m1.1.2.2">73.3</cn><cn id="S3.T1.3.3.3.m1.1.1.cmml" type="float" xref="S3.T1.3.3.3.m1.1.1">0.37</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.3.3.3.m1.1c">73.3\ (0.37)</annotation><annotation encoding="application/x-llamapun" id="S3.T1.3.3.3.m1.1d">73.3 ( 0.37 )</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S3.T1.6.6">
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row" id="S3.T1.6.6.4" style="padding-left:0.0pt;padding-right:0.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.6.6.4.1">MiniCPM</span></th>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S3.T1.4.4.1" style="padding-left:0.0pt;padding-right:0.0pt;"><math alttext="62.3\ (0.18)" class="ltx_Math" display="inline" id="S3.T1.4.4.1.m1.1"><semantics id="S3.T1.4.4.1.m1.1a"><mrow id="S3.T1.4.4.1.m1.1.2" xref="S3.T1.4.4.1.m1.1.2.cmml"><mn id="S3.T1.4.4.1.m1.1.2.2" xref="S3.T1.4.4.1.m1.1.2.2.cmml">62.3</mn><mo id="S3.T1.4.4.1.m1.1.2.1" lspace="0.500em" xref="S3.T1.4.4.1.m1.1.2.1.cmml">⁢</mo><mrow id="S3.T1.4.4.1.m1.1.2.3.2" xref="S3.T1.4.4.1.m1.1.2.cmml"><mo id="S3.T1.4.4.1.m1.1.2.3.2.1" stretchy="false" xref="S3.T1.4.4.1.m1.1.2.cmml">(</mo><mn id="S3.T1.4.4.1.m1.1.1" xref="S3.T1.4.4.1.m1.1.1.cmml">0.18</mn><mo id="S3.T1.4.4.1.m1.1.2.3.2.2" stretchy="false" xref="S3.T1.4.4.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.4.4.1.m1.1b"><apply id="S3.T1.4.4.1.m1.1.2.cmml" xref="S3.T1.4.4.1.m1.1.2"><times id="S3.T1.4.4.1.m1.1.2.1.cmml" xref="S3.T1.4.4.1.m1.1.2.1"></times><cn id="S3.T1.4.4.1.m1.1.2.2.cmml" type="float" xref="S3.T1.4.4.1.m1.1.2.2">62.3</cn><cn id="S3.T1.4.4.1.m1.1.1.cmml" type="float" xref="S3.T1.4.4.1.m1.1.1">0.18</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.4.4.1.m1.1c">62.3\ (0.18)</annotation><annotation encoding="application/x-llamapun" id="S3.T1.4.4.1.m1.1d">62.3 ( 0.18 )</annotation></semantics></math></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S3.T1.5.5.2" style="padding-left:0.0pt;padding-right:0.0pt;"><math alttext="69.3\ (0.25)" class="ltx_Math" display="inline" id="S3.T1.5.5.2.m1.1"><semantics id="S3.T1.5.5.2.m1.1a"><mrow id="S3.T1.5.5.2.m1.1.2" xref="S3.T1.5.5.2.m1.1.2.cmml"><mn id="S3.T1.5.5.2.m1.1.2.2" xref="S3.T1.5.5.2.m1.1.2.2.cmml">69.3</mn><mo id="S3.T1.5.5.2.m1.1.2.1" lspace="0.500em" xref="S3.T1.5.5.2.m1.1.2.1.cmml">⁢</mo><mrow id="S3.T1.5.5.2.m1.1.2.3.2" xref="S3.T1.5.5.2.m1.1.2.cmml"><mo id="S3.T1.5.5.2.m1.1.2.3.2.1" stretchy="false" xref="S3.T1.5.5.2.m1.1.2.cmml">(</mo><mn id="S3.T1.5.5.2.m1.1.1" xref="S3.T1.5.5.2.m1.1.1.cmml">0.25</mn><mo id="S3.T1.5.5.2.m1.1.2.3.2.2" stretchy="false" xref="S3.T1.5.5.2.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.5.5.2.m1.1b"><apply id="S3.T1.5.5.2.m1.1.2.cmml" xref="S3.T1.5.5.2.m1.1.2"><times id="S3.T1.5.5.2.m1.1.2.1.cmml" xref="S3.T1.5.5.2.m1.1.2.1"></times><cn id="S3.T1.5.5.2.m1.1.2.2.cmml" type="float" xref="S3.T1.5.5.2.m1.1.2.2">69.3</cn><cn id="S3.T1.5.5.2.m1.1.1.cmml" type="float" xref="S3.T1.5.5.2.m1.1.1">0.25</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.5.5.2.m1.1c">69.3\ (0.25)</annotation><annotation encoding="application/x-llamapun" id="S3.T1.5.5.2.m1.1d">69.3 ( 0.25 )</annotation></semantics></math></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S3.T1.6.6.3" style="padding-left:0.0pt;padding-right:0.0pt;"><math alttext="74.0\ (0.42)" class="ltx_Math" display="inline" id="S3.T1.6.6.3.m1.1"><semantics id="S3.T1.6.6.3.m1.1a"><mrow id="S3.T1.6.6.3.m1.1.2" xref="S3.T1.6.6.3.m1.1.2.cmml"><mn id="S3.T1.6.6.3.m1.1.2.2" xref="S3.T1.6.6.3.m1.1.2.2.cmml">74.0</mn><mo id="S3.T1.6.6.3.m1.1.2.1" lspace="0.500em" xref="S3.T1.6.6.3.m1.1.2.1.cmml">⁢</mo><mrow id="S3.T1.6.6.3.m1.1.2.3.2" xref="S3.T1.6.6.3.m1.1.2.cmml"><mo id="S3.T1.6.6.3.m1.1.2.3.2.1" stretchy="false" xref="S3.T1.6.6.3.m1.1.2.cmml">(</mo><mn id="S3.T1.6.6.3.m1.1.1" xref="S3.T1.6.6.3.m1.1.1.cmml">0.42</mn><mo id="S3.T1.6.6.3.m1.1.2.3.2.2" stretchy="false" xref="S3.T1.6.6.3.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.6.6.3.m1.1b"><apply id="S3.T1.6.6.3.m1.1.2.cmml" xref="S3.T1.6.6.3.m1.1.2"><times id="S3.T1.6.6.3.m1.1.2.1.cmml" xref="S3.T1.6.6.3.m1.1.2.1"></times><cn id="S3.T1.6.6.3.m1.1.2.2.cmml" type="float" xref="S3.T1.6.6.3.m1.1.2.2">74.0</cn><cn id="S3.T1.6.6.3.m1.1.1.cmml" type="float" xref="S3.T1.6.6.3.m1.1.1">0.42</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.6.6.3.m1.1c">74.0\ (0.42)</annotation><annotation encoding="application/x-llamapun" id="S3.T1.6.6.3.m1.1d">74.0 ( 0.42 )</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S3.T1.9.9">
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S3.T1.9.9.4" style="padding-left:0.0pt;padding-right:0.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.9.9.4.1">ChatGLM3</span></th>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" id="S3.T1.7.7.1" style="padding-left:0.0pt;padding-right:0.0pt;"><math alttext="72.6\ (0.33)" class="ltx_Math" display="inline" id="S3.T1.7.7.1.m1.1"><semantics id="S3.T1.7.7.1.m1.1a"><mrow id="S3.T1.7.7.1.m1.1.2" xref="S3.T1.7.7.1.m1.1.2.cmml"><mn id="S3.T1.7.7.1.m1.1.2.2" xref="S3.T1.7.7.1.m1.1.2.2.cmml">72.6</mn><mo id="S3.T1.7.7.1.m1.1.2.1" lspace="0.500em" xref="S3.T1.7.7.1.m1.1.2.1.cmml">⁢</mo><mrow id="S3.T1.7.7.1.m1.1.2.3.2" xref="S3.T1.7.7.1.m1.1.2.cmml"><mo id="S3.T1.7.7.1.m1.1.2.3.2.1" stretchy="false" xref="S3.T1.7.7.1.m1.1.2.cmml">(</mo><mn id="S3.T1.7.7.1.m1.1.1" xref="S3.T1.7.7.1.m1.1.1.cmml">0.33</mn><mo id="S3.T1.7.7.1.m1.1.2.3.2.2" stretchy="false" xref="S3.T1.7.7.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.7.7.1.m1.1b"><apply id="S3.T1.7.7.1.m1.1.2.cmml" xref="S3.T1.7.7.1.m1.1.2"><times id="S3.T1.7.7.1.m1.1.2.1.cmml" xref="S3.T1.7.7.1.m1.1.2.1"></times><cn id="S3.T1.7.7.1.m1.1.2.2.cmml" type="float" xref="S3.T1.7.7.1.m1.1.2.2">72.6</cn><cn id="S3.T1.7.7.1.m1.1.1.cmml" type="float" xref="S3.T1.7.7.1.m1.1.1">0.33</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.7.7.1.m1.1c">72.6\ (0.33)</annotation><annotation encoding="application/x-llamapun" id="S3.T1.7.7.1.m1.1d">72.6 ( 0.33 )</annotation></semantics></math></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" id="S3.T1.8.8.2" style="padding-left:0.0pt;padding-right:0.0pt;"><math alttext="76.1\ (0.49)" class="ltx_Math" display="inline" id="S3.T1.8.8.2.m1.1"><semantics id="S3.T1.8.8.2.m1.1a"><mrow id="S3.T1.8.8.2.m1.1.2" xref="S3.T1.8.8.2.m1.1.2.cmml"><mn id="S3.T1.8.8.2.m1.1.2.2" xref="S3.T1.8.8.2.m1.1.2.2.cmml">76.1</mn><mo id="S3.T1.8.8.2.m1.1.2.1" lspace="0.500em" xref="S3.T1.8.8.2.m1.1.2.1.cmml">⁢</mo><mrow id="S3.T1.8.8.2.m1.1.2.3.2" xref="S3.T1.8.8.2.m1.1.2.cmml"><mo id="S3.T1.8.8.2.m1.1.2.3.2.1" stretchy="false" xref="S3.T1.8.8.2.m1.1.2.cmml">(</mo><mn id="S3.T1.8.8.2.m1.1.1" xref="S3.T1.8.8.2.m1.1.1.cmml">0.49</mn><mo id="S3.T1.8.8.2.m1.1.2.3.2.2" stretchy="false" xref="S3.T1.8.8.2.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.8.8.2.m1.1b"><apply id="S3.T1.8.8.2.m1.1.2.cmml" xref="S3.T1.8.8.2.m1.1.2"><times id="S3.T1.8.8.2.m1.1.2.1.cmml" xref="S3.T1.8.8.2.m1.1.2.1"></times><cn id="S3.T1.8.8.2.m1.1.2.2.cmml" type="float" xref="S3.T1.8.8.2.m1.1.2.2">76.1</cn><cn id="S3.T1.8.8.2.m1.1.1.cmml" type="float" xref="S3.T1.8.8.2.m1.1.1">0.49</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.8.8.2.m1.1c">76.1\ (0.49)</annotation><annotation encoding="application/x-llamapun" id="S3.T1.8.8.2.m1.1d">76.1 ( 0.49 )</annotation></semantics></math></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" id="S3.T1.9.9.3" style="padding-left:0.0pt;padding-right:0.0pt;"><math alttext="69.8\ (0.29)" class="ltx_Math" display="inline" id="S3.T1.9.9.3.m1.1"><semantics id="S3.T1.9.9.3.m1.1a"><mrow id="S3.T1.9.9.3.m1.1.2" xref="S3.T1.9.9.3.m1.1.2.cmml"><mn id="S3.T1.9.9.3.m1.1.2.2" xref="S3.T1.9.9.3.m1.1.2.2.cmml">69.8</mn><mo id="S3.T1.9.9.3.m1.1.2.1" lspace="0.500em" xref="S3.T1.9.9.3.m1.1.2.1.cmml">⁢</mo><mrow id="S3.T1.9.9.3.m1.1.2.3.2" xref="S3.T1.9.9.3.m1.1.2.cmml"><mo id="S3.T1.9.9.3.m1.1.2.3.2.1" stretchy="false" xref="S3.T1.9.9.3.m1.1.2.cmml">(</mo><mn id="S3.T1.9.9.3.m1.1.1" xref="S3.T1.9.9.3.m1.1.1.cmml">0.29</mn><mo id="S3.T1.9.9.3.m1.1.2.3.2.2" stretchy="false" xref="S3.T1.9.9.3.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.9.9.3.m1.1b"><apply id="S3.T1.9.9.3.m1.1.2.cmml" xref="S3.T1.9.9.3.m1.1.2"><times id="S3.T1.9.9.3.m1.1.2.1.cmml" xref="S3.T1.9.9.3.m1.1.2.1"></times><cn id="S3.T1.9.9.3.m1.1.2.2.cmml" type="float" xref="S3.T1.9.9.3.m1.1.2.2">69.8</cn><cn id="S3.T1.9.9.3.m1.1.1.cmml" type="float" xref="S3.T1.9.9.3.m1.1.1">0.29</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.9.9.3.m1.1c">69.8\ (0.29)</annotation><annotation encoding="application/x-llamapun" id="S3.T1.9.9.3.m1.1d">69.8 ( 0.29 )</annotation></semantics></math></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Evaluations between fine-tuned models and the corresponding raw models in three dimensions (<span class="ltx_text ltx_font_bold" id="S3.T1.12.1">HTS</span>). The values in parentheses represent the IAA score. <span class="ltx_text ltx_font_bold" id="S3.T1.13.2">H/T/S</span> indicate humanized communication, teaching expertise and safety &amp; ethics.</figcaption>
</figure>
<figure class="ltx_table" id="S3.T2">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S3.T2.21">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T2.21.22.1">
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S3.T2.21.22.1.1" style="padding-left:0.0pt;padding-right:0.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T2.21.22.1.1.1">Criteria</span></th>
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T2.21.22.1.2" style="padding-left:0.0pt;padding-right:0.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T2.21.22.1.2.1">H</span></th>
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T2.21.22.1.3" style="padding-left:0.0pt;padding-right:0.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T2.21.22.1.3.1">T</span></th>
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T2.21.22.1.4" style="padding-left:0.0pt;padding-right:0.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T2.21.22.1.4.1">S</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T2.3.3">
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S3.T2.3.3.4" style="padding-left:0.0pt;padding-right:0.0pt;">
<span class="ltx_text ltx_font_bold" id="S3.T2.3.3.4.1">Qwen1.5</span> vs <span class="ltx_text ltx_font_bold" id="S3.T2.3.3.4.2">GLM</span>
</th>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S3.T2.1.1.1" style="padding-left:0.0pt;padding-right:0.0pt;"><math alttext="47.2(0.28)" class="ltx_Math" display="inline" id="S3.T2.1.1.1.m1.1"><semantics id="S3.T2.1.1.1.m1.1a"><mrow id="S3.T2.1.1.1.m1.1.2" xref="S3.T2.1.1.1.m1.1.2.cmml"><mn id="S3.T2.1.1.1.m1.1.2.2" xref="S3.T2.1.1.1.m1.1.2.2.cmml">47.2</mn><mo id="S3.T2.1.1.1.m1.1.2.1" xref="S3.T2.1.1.1.m1.1.2.1.cmml">⁢</mo><mrow id="S3.T2.1.1.1.m1.1.2.3.2" xref="S3.T2.1.1.1.m1.1.2.cmml"><mo id="S3.T2.1.1.1.m1.1.2.3.2.1" stretchy="false" xref="S3.T2.1.1.1.m1.1.2.cmml">(</mo><mn id="S3.T2.1.1.1.m1.1.1" xref="S3.T2.1.1.1.m1.1.1.cmml">0.28</mn><mo id="S3.T2.1.1.1.m1.1.2.3.2.2" stretchy="false" xref="S3.T2.1.1.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T2.1.1.1.m1.1b"><apply id="S3.T2.1.1.1.m1.1.2.cmml" xref="S3.T2.1.1.1.m1.1.2"><times id="S3.T2.1.1.1.m1.1.2.1.cmml" xref="S3.T2.1.1.1.m1.1.2.1"></times><cn id="S3.T2.1.1.1.m1.1.2.2.cmml" type="float" xref="S3.T2.1.1.1.m1.1.2.2">47.2</cn><cn id="S3.T2.1.1.1.m1.1.1.cmml" type="float" xref="S3.T2.1.1.1.m1.1.1">0.28</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.1.1.1.m1.1c">47.2(0.28)</annotation><annotation encoding="application/x-llamapun" id="S3.T2.1.1.1.m1.1d">47.2 ( 0.28 )</annotation></semantics></math></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S3.T2.2.2.2" style="padding-left:0.0pt;padding-right:0.0pt;"><math alttext="52.2(0.25)" class="ltx_Math" display="inline" id="S3.T2.2.2.2.m1.1"><semantics id="S3.T2.2.2.2.m1.1a"><mrow id="S3.T2.2.2.2.m1.1.2" xref="S3.T2.2.2.2.m1.1.2.cmml"><mn id="S3.T2.2.2.2.m1.1.2.2" xref="S3.T2.2.2.2.m1.1.2.2.cmml">52.2</mn><mo id="S3.T2.2.2.2.m1.1.2.1" xref="S3.T2.2.2.2.m1.1.2.1.cmml">⁢</mo><mrow id="S3.T2.2.2.2.m1.1.2.3.2" xref="S3.T2.2.2.2.m1.1.2.cmml"><mo id="S3.T2.2.2.2.m1.1.2.3.2.1" stretchy="false" xref="S3.T2.2.2.2.m1.1.2.cmml">(</mo><mn id="S3.T2.2.2.2.m1.1.1" xref="S3.T2.2.2.2.m1.1.1.cmml">0.25</mn><mo id="S3.T2.2.2.2.m1.1.2.3.2.2" stretchy="false" xref="S3.T2.2.2.2.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T2.2.2.2.m1.1b"><apply id="S3.T2.2.2.2.m1.1.2.cmml" xref="S3.T2.2.2.2.m1.1.2"><times id="S3.T2.2.2.2.m1.1.2.1.cmml" xref="S3.T2.2.2.2.m1.1.2.1"></times><cn id="S3.T2.2.2.2.m1.1.2.2.cmml" type="float" xref="S3.T2.2.2.2.m1.1.2.2">52.2</cn><cn id="S3.T2.2.2.2.m1.1.1.cmml" type="float" xref="S3.T2.2.2.2.m1.1.1">0.25</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.2.2.2.m1.1c">52.2(0.25)</annotation><annotation encoding="application/x-llamapun" id="S3.T2.2.2.2.m1.1d">52.2 ( 0.25 )</annotation></semantics></math></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S3.T2.3.3.3" style="padding-left:0.0pt;padding-right:0.0pt;"><math alttext="48.3(0.39)" class="ltx_Math" display="inline" id="S3.T2.3.3.3.m1.1"><semantics id="S3.T2.3.3.3.m1.1a"><mrow id="S3.T2.3.3.3.m1.1.2" xref="S3.T2.3.3.3.m1.1.2.cmml"><mn id="S3.T2.3.3.3.m1.1.2.2" xref="S3.T2.3.3.3.m1.1.2.2.cmml">48.3</mn><mo id="S3.T2.3.3.3.m1.1.2.1" xref="S3.T2.3.3.3.m1.1.2.1.cmml">⁢</mo><mrow id="S3.T2.3.3.3.m1.1.2.3.2" xref="S3.T2.3.3.3.m1.1.2.cmml"><mo id="S3.T2.3.3.3.m1.1.2.3.2.1" stretchy="false" xref="S3.T2.3.3.3.m1.1.2.cmml">(</mo><mn id="S3.T2.3.3.3.m1.1.1" xref="S3.T2.3.3.3.m1.1.1.cmml">0.39</mn><mo id="S3.T2.3.3.3.m1.1.2.3.2.2" stretchy="false" xref="S3.T2.3.3.3.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T2.3.3.3.m1.1b"><apply id="S3.T2.3.3.3.m1.1.2.cmml" xref="S3.T2.3.3.3.m1.1.2"><times id="S3.T2.3.3.3.m1.1.2.1.cmml" xref="S3.T2.3.3.3.m1.1.2.1"></times><cn id="S3.T2.3.3.3.m1.1.2.2.cmml" type="float" xref="S3.T2.3.3.3.m1.1.2.2">48.3</cn><cn id="S3.T2.3.3.3.m1.1.1.cmml" type="float" xref="S3.T2.3.3.3.m1.1.1">0.39</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.3.3.3.m1.1c">48.3(0.39)</annotation><annotation encoding="application/x-llamapun" id="S3.T2.3.3.3.m1.1d">48.3 ( 0.39 )</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S3.T2.6.6">
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row" id="S3.T2.6.6.4" style="padding-left:0.0pt;padding-right:0.0pt;">
<span class="ltx_text ltx_font_bold" id="S3.T2.6.6.4.1">MiniCPM</span> vs <span class="ltx_text ltx_font_bold" id="S3.T2.6.6.4.2">GLM</span>
</th>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S3.T2.4.4.1" style="padding-left:0.0pt;padding-right:0.0pt;"><math alttext="44.1(0.37)" class="ltx_Math" display="inline" id="S3.T2.4.4.1.m1.1"><semantics id="S3.T2.4.4.1.m1.1a"><mrow id="S3.T2.4.4.1.m1.1.2" xref="S3.T2.4.4.1.m1.1.2.cmml"><mn id="S3.T2.4.4.1.m1.1.2.2" xref="S3.T2.4.4.1.m1.1.2.2.cmml">44.1</mn><mo id="S3.T2.4.4.1.m1.1.2.1" xref="S3.T2.4.4.1.m1.1.2.1.cmml">⁢</mo><mrow id="S3.T2.4.4.1.m1.1.2.3.2" xref="S3.T2.4.4.1.m1.1.2.cmml"><mo id="S3.T2.4.4.1.m1.1.2.3.2.1" stretchy="false" xref="S3.T2.4.4.1.m1.1.2.cmml">(</mo><mn id="S3.T2.4.4.1.m1.1.1" xref="S3.T2.4.4.1.m1.1.1.cmml">0.37</mn><mo id="S3.T2.4.4.1.m1.1.2.3.2.2" stretchy="false" xref="S3.T2.4.4.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T2.4.4.1.m1.1b"><apply id="S3.T2.4.4.1.m1.1.2.cmml" xref="S3.T2.4.4.1.m1.1.2"><times id="S3.T2.4.4.1.m1.1.2.1.cmml" xref="S3.T2.4.4.1.m1.1.2.1"></times><cn id="S3.T2.4.4.1.m1.1.2.2.cmml" type="float" xref="S3.T2.4.4.1.m1.1.2.2">44.1</cn><cn id="S3.T2.4.4.1.m1.1.1.cmml" type="float" xref="S3.T2.4.4.1.m1.1.1">0.37</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.4.4.1.m1.1c">44.1(0.37)</annotation><annotation encoding="application/x-llamapun" id="S3.T2.4.4.1.m1.1d">44.1 ( 0.37 )</annotation></semantics></math></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S3.T2.5.5.2" style="padding-left:0.0pt;padding-right:0.0pt;"><math alttext="51.3(0.23)" class="ltx_Math" display="inline" id="S3.T2.5.5.2.m1.1"><semantics id="S3.T2.5.5.2.m1.1a"><mrow id="S3.T2.5.5.2.m1.1.2" xref="S3.T2.5.5.2.m1.1.2.cmml"><mn id="S3.T2.5.5.2.m1.1.2.2" xref="S3.T2.5.5.2.m1.1.2.2.cmml">51.3</mn><mo id="S3.T2.5.5.2.m1.1.2.1" xref="S3.T2.5.5.2.m1.1.2.1.cmml">⁢</mo><mrow id="S3.T2.5.5.2.m1.1.2.3.2" xref="S3.T2.5.5.2.m1.1.2.cmml"><mo id="S3.T2.5.5.2.m1.1.2.3.2.1" stretchy="false" xref="S3.T2.5.5.2.m1.1.2.cmml">(</mo><mn id="S3.T2.5.5.2.m1.1.1" xref="S3.T2.5.5.2.m1.1.1.cmml">0.23</mn><mo id="S3.T2.5.5.2.m1.1.2.3.2.2" stretchy="false" xref="S3.T2.5.5.2.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T2.5.5.2.m1.1b"><apply id="S3.T2.5.5.2.m1.1.2.cmml" xref="S3.T2.5.5.2.m1.1.2"><times id="S3.T2.5.5.2.m1.1.2.1.cmml" xref="S3.T2.5.5.2.m1.1.2.1"></times><cn id="S3.T2.5.5.2.m1.1.2.2.cmml" type="float" xref="S3.T2.5.5.2.m1.1.2.2">51.3</cn><cn id="S3.T2.5.5.2.m1.1.1.cmml" type="float" xref="S3.T2.5.5.2.m1.1.1">0.23</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.5.5.2.m1.1c">51.3(0.23)</annotation><annotation encoding="application/x-llamapun" id="S3.T2.5.5.2.m1.1d">51.3 ( 0.23 )</annotation></semantics></math></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S3.T2.6.6.3" style="padding-left:0.0pt;padding-right:0.0pt;"><math alttext="55.3(0.49)" class="ltx_Math" display="inline" id="S3.T2.6.6.3.m1.1"><semantics id="S3.T2.6.6.3.m1.1a"><mrow id="S3.T2.6.6.3.m1.1.2" xref="S3.T2.6.6.3.m1.1.2.cmml"><mn id="S3.T2.6.6.3.m1.1.2.2" xref="S3.T2.6.6.3.m1.1.2.2.cmml">55.3</mn><mo id="S3.T2.6.6.3.m1.1.2.1" xref="S3.T2.6.6.3.m1.1.2.1.cmml">⁢</mo><mrow id="S3.T2.6.6.3.m1.1.2.3.2" xref="S3.T2.6.6.3.m1.1.2.cmml"><mo id="S3.T2.6.6.3.m1.1.2.3.2.1" stretchy="false" xref="S3.T2.6.6.3.m1.1.2.cmml">(</mo><mn id="S3.T2.6.6.3.m1.1.1" xref="S3.T2.6.6.3.m1.1.1.cmml">0.49</mn><mo id="S3.T2.6.6.3.m1.1.2.3.2.2" stretchy="false" xref="S3.T2.6.6.3.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T2.6.6.3.m1.1b"><apply id="S3.T2.6.6.3.m1.1.2.cmml" xref="S3.T2.6.6.3.m1.1.2"><times id="S3.T2.6.6.3.m1.1.2.1.cmml" xref="S3.T2.6.6.3.m1.1.2.1"></times><cn id="S3.T2.6.6.3.m1.1.2.2.cmml" type="float" xref="S3.T2.6.6.3.m1.1.2.2">55.3</cn><cn id="S3.T2.6.6.3.m1.1.1.cmml" type="float" xref="S3.T2.6.6.3.m1.1.1">0.49</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.6.6.3.m1.1c">55.3(0.49)</annotation><annotation encoding="application/x-llamapun" id="S3.T2.6.6.3.m1.1d">55.3 ( 0.49 )</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S3.T2.9.9">
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row" id="S3.T2.9.9.4" style="padding-left:0.0pt;padding-right:0.0pt;">
<span class="ltx_text ltx_font_bold" id="S3.T2.9.9.4.1">GLM3</span> vs <span class="ltx_text ltx_font_bold" id="S3.T2.9.9.4.2">GLM</span>
</th>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S3.T2.7.7.1" style="padding-left:0.0pt;padding-right:0.0pt;"><math alttext="41.7(0.19)" class="ltx_Math" display="inline" id="S3.T2.7.7.1.m1.1"><semantics id="S3.T2.7.7.1.m1.1a"><mrow id="S3.T2.7.7.1.m1.1.2" xref="S3.T2.7.7.1.m1.1.2.cmml"><mn id="S3.T2.7.7.1.m1.1.2.2" xref="S3.T2.7.7.1.m1.1.2.2.cmml">41.7</mn><mo id="S3.T2.7.7.1.m1.1.2.1" xref="S3.T2.7.7.1.m1.1.2.1.cmml">⁢</mo><mrow id="S3.T2.7.7.1.m1.1.2.3.2" xref="S3.T2.7.7.1.m1.1.2.cmml"><mo id="S3.T2.7.7.1.m1.1.2.3.2.1" stretchy="false" xref="S3.T2.7.7.1.m1.1.2.cmml">(</mo><mn id="S3.T2.7.7.1.m1.1.1" xref="S3.T2.7.7.1.m1.1.1.cmml">0.19</mn><mo id="S3.T2.7.7.1.m1.1.2.3.2.2" stretchy="false" xref="S3.T2.7.7.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T2.7.7.1.m1.1b"><apply id="S3.T2.7.7.1.m1.1.2.cmml" xref="S3.T2.7.7.1.m1.1.2"><times id="S3.T2.7.7.1.m1.1.2.1.cmml" xref="S3.T2.7.7.1.m1.1.2.1"></times><cn id="S3.T2.7.7.1.m1.1.2.2.cmml" type="float" xref="S3.T2.7.7.1.m1.1.2.2">41.7</cn><cn id="S3.T2.7.7.1.m1.1.1.cmml" type="float" xref="S3.T2.7.7.1.m1.1.1">0.19</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.7.7.1.m1.1c">41.7(0.19)</annotation><annotation encoding="application/x-llamapun" id="S3.T2.7.7.1.m1.1d">41.7 ( 0.19 )</annotation></semantics></math></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S3.T2.8.8.2" style="padding-left:0.0pt;padding-right:0.0pt;"><math alttext="45.8(0.39)" class="ltx_Math" display="inline" id="S3.T2.8.8.2.m1.1"><semantics id="S3.T2.8.8.2.m1.1a"><mrow id="S3.T2.8.8.2.m1.1.2" xref="S3.T2.8.8.2.m1.1.2.cmml"><mn id="S3.T2.8.8.2.m1.1.2.2" xref="S3.T2.8.8.2.m1.1.2.2.cmml">45.8</mn><mo id="S3.T2.8.8.2.m1.1.2.1" xref="S3.T2.8.8.2.m1.1.2.1.cmml">⁢</mo><mrow id="S3.T2.8.8.2.m1.1.2.3.2" xref="S3.T2.8.8.2.m1.1.2.cmml"><mo id="S3.T2.8.8.2.m1.1.2.3.2.1" stretchy="false" xref="S3.T2.8.8.2.m1.1.2.cmml">(</mo><mn id="S3.T2.8.8.2.m1.1.1" xref="S3.T2.8.8.2.m1.1.1.cmml">0.39</mn><mo id="S3.T2.8.8.2.m1.1.2.3.2.2" stretchy="false" xref="S3.T2.8.8.2.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T2.8.8.2.m1.1b"><apply id="S3.T2.8.8.2.m1.1.2.cmml" xref="S3.T2.8.8.2.m1.1.2"><times id="S3.T2.8.8.2.m1.1.2.1.cmml" xref="S3.T2.8.8.2.m1.1.2.1"></times><cn id="S3.T2.8.8.2.m1.1.2.2.cmml" type="float" xref="S3.T2.8.8.2.m1.1.2.2">45.8</cn><cn id="S3.T2.8.8.2.m1.1.1.cmml" type="float" xref="S3.T2.8.8.2.m1.1.1">0.39</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.8.8.2.m1.1c">45.8(0.39)</annotation><annotation encoding="application/x-llamapun" id="S3.T2.8.8.2.m1.1d">45.8 ( 0.39 )</annotation></semantics></math></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S3.T2.9.9.3" style="padding-left:0.0pt;padding-right:0.0pt;"><math alttext="53.3(0.42)" class="ltx_Math" display="inline" id="S3.T2.9.9.3.m1.1"><semantics id="S3.T2.9.9.3.m1.1a"><mrow id="S3.T2.9.9.3.m1.1.2" xref="S3.T2.9.9.3.m1.1.2.cmml"><mn id="S3.T2.9.9.3.m1.1.2.2" xref="S3.T2.9.9.3.m1.1.2.2.cmml">53.3</mn><mo id="S3.T2.9.9.3.m1.1.2.1" xref="S3.T2.9.9.3.m1.1.2.1.cmml">⁢</mo><mrow id="S3.T2.9.9.3.m1.1.2.3.2" xref="S3.T2.9.9.3.m1.1.2.cmml"><mo id="S3.T2.9.9.3.m1.1.2.3.2.1" stretchy="false" xref="S3.T2.9.9.3.m1.1.2.cmml">(</mo><mn id="S3.T2.9.9.3.m1.1.1" xref="S3.T2.9.9.3.m1.1.1.cmml">0.42</mn><mo id="S3.T2.9.9.3.m1.1.2.3.2.2" stretchy="false" xref="S3.T2.9.9.3.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T2.9.9.3.m1.1b"><apply id="S3.T2.9.9.3.m1.1.2.cmml" xref="S3.T2.9.9.3.m1.1.2"><times id="S3.T2.9.9.3.m1.1.2.1.cmml" xref="S3.T2.9.9.3.m1.1.2.1"></times><cn id="S3.T2.9.9.3.m1.1.2.2.cmml" type="float" xref="S3.T2.9.9.3.m1.1.2.2">53.3</cn><cn id="S3.T2.9.9.3.m1.1.1.cmml" type="float" xref="S3.T2.9.9.3.m1.1.1">0.42</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.9.9.3.m1.1c">53.3(0.42)</annotation><annotation encoding="application/x-llamapun" id="S3.T2.9.9.3.m1.1d">53.3 ( 0.42 )</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S3.T2.12.12">
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S3.T2.12.12.4" style="padding-left:0.0pt;padding-right:0.0pt;">
<span class="ltx_text ltx_font_bold" id="S3.T2.12.12.4.1">Qwen1.5</span> vs <span class="ltx_text ltx_font_bold" id="S3.T2.12.12.4.2">GLM-R</span>
</th>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S3.T2.10.10.1" style="padding-left:0.0pt;padding-right:0.0pt;"><math alttext="44.8(0.28)" class="ltx_Math" display="inline" id="S3.T2.10.10.1.m1.1"><semantics id="S3.T2.10.10.1.m1.1a"><mrow id="S3.T2.10.10.1.m1.1.2" xref="S3.T2.10.10.1.m1.1.2.cmml"><mn id="S3.T2.10.10.1.m1.1.2.2" xref="S3.T2.10.10.1.m1.1.2.2.cmml">44.8</mn><mo id="S3.T2.10.10.1.m1.1.2.1" xref="S3.T2.10.10.1.m1.1.2.1.cmml">⁢</mo><mrow id="S3.T2.10.10.1.m1.1.2.3.2" xref="S3.T2.10.10.1.m1.1.2.cmml"><mo id="S3.T2.10.10.1.m1.1.2.3.2.1" stretchy="false" xref="S3.T2.10.10.1.m1.1.2.cmml">(</mo><mn id="S3.T2.10.10.1.m1.1.1" xref="S3.T2.10.10.1.m1.1.1.cmml">0.28</mn><mo id="S3.T2.10.10.1.m1.1.2.3.2.2" stretchy="false" xref="S3.T2.10.10.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T2.10.10.1.m1.1b"><apply id="S3.T2.10.10.1.m1.1.2.cmml" xref="S3.T2.10.10.1.m1.1.2"><times id="S3.T2.10.10.1.m1.1.2.1.cmml" xref="S3.T2.10.10.1.m1.1.2.1"></times><cn id="S3.T2.10.10.1.m1.1.2.2.cmml" type="float" xref="S3.T2.10.10.1.m1.1.2.2">44.8</cn><cn id="S3.T2.10.10.1.m1.1.1.cmml" type="float" xref="S3.T2.10.10.1.m1.1.1">0.28</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.10.10.1.m1.1c">44.8(0.28)</annotation><annotation encoding="application/x-llamapun" id="S3.T2.10.10.1.m1.1d">44.8 ( 0.28 )</annotation></semantics></math></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S3.T2.11.11.2" style="padding-left:0.0pt;padding-right:0.0pt;"><math alttext="43.6(0.27)" class="ltx_Math" display="inline" id="S3.T2.11.11.2.m1.1"><semantics id="S3.T2.11.11.2.m1.1a"><mrow id="S3.T2.11.11.2.m1.1.2" xref="S3.T2.11.11.2.m1.1.2.cmml"><mn id="S3.T2.11.11.2.m1.1.2.2" xref="S3.T2.11.11.2.m1.1.2.2.cmml">43.6</mn><mo id="S3.T2.11.11.2.m1.1.2.1" xref="S3.T2.11.11.2.m1.1.2.1.cmml">⁢</mo><mrow id="S3.T2.11.11.2.m1.1.2.3.2" xref="S3.T2.11.11.2.m1.1.2.cmml"><mo id="S3.T2.11.11.2.m1.1.2.3.2.1" stretchy="false" xref="S3.T2.11.11.2.m1.1.2.cmml">(</mo><mn id="S3.T2.11.11.2.m1.1.1" xref="S3.T2.11.11.2.m1.1.1.cmml">0.27</mn><mo id="S3.T2.11.11.2.m1.1.2.3.2.2" stretchy="false" xref="S3.T2.11.11.2.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T2.11.11.2.m1.1b"><apply id="S3.T2.11.11.2.m1.1.2.cmml" xref="S3.T2.11.11.2.m1.1.2"><times id="S3.T2.11.11.2.m1.1.2.1.cmml" xref="S3.T2.11.11.2.m1.1.2.1"></times><cn id="S3.T2.11.11.2.m1.1.2.2.cmml" type="float" xref="S3.T2.11.11.2.m1.1.2.2">43.6</cn><cn id="S3.T2.11.11.2.m1.1.1.cmml" type="float" xref="S3.T2.11.11.2.m1.1.1">0.27</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.11.11.2.m1.1c">43.6(0.27)</annotation><annotation encoding="application/x-llamapun" id="S3.T2.11.11.2.m1.1d">43.6 ( 0.27 )</annotation></semantics></math></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S3.T2.12.12.3" style="padding-left:0.0pt;padding-right:0.0pt;"><math alttext="46.1(0.42)" class="ltx_Math" display="inline" id="S3.T2.12.12.3.m1.1"><semantics id="S3.T2.12.12.3.m1.1a"><mrow id="S3.T2.12.12.3.m1.1.2" xref="S3.T2.12.12.3.m1.1.2.cmml"><mn id="S3.T2.12.12.3.m1.1.2.2" xref="S3.T2.12.12.3.m1.1.2.2.cmml">46.1</mn><mo id="S3.T2.12.12.3.m1.1.2.1" xref="S3.T2.12.12.3.m1.1.2.1.cmml">⁢</mo><mrow id="S3.T2.12.12.3.m1.1.2.3.2" xref="S3.T2.12.12.3.m1.1.2.cmml"><mo id="S3.T2.12.12.3.m1.1.2.3.2.1" stretchy="false" xref="S3.T2.12.12.3.m1.1.2.cmml">(</mo><mn id="S3.T2.12.12.3.m1.1.1" xref="S3.T2.12.12.3.m1.1.1.cmml">0.42</mn><mo id="S3.T2.12.12.3.m1.1.2.3.2.2" stretchy="false" xref="S3.T2.12.12.3.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T2.12.12.3.m1.1b"><apply id="S3.T2.12.12.3.m1.1.2.cmml" xref="S3.T2.12.12.3.m1.1.2"><times id="S3.T2.12.12.3.m1.1.2.1.cmml" xref="S3.T2.12.12.3.m1.1.2.1"></times><cn id="S3.T2.12.12.3.m1.1.2.2.cmml" type="float" xref="S3.T2.12.12.3.m1.1.2.2">46.1</cn><cn id="S3.T2.12.12.3.m1.1.1.cmml" type="float" xref="S3.T2.12.12.3.m1.1.1">0.42</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.12.12.3.m1.1c">46.1(0.42)</annotation><annotation encoding="application/x-llamapun" id="S3.T2.12.12.3.m1.1d">46.1 ( 0.42 )</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S3.T2.15.15">
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row" id="S3.T2.15.15.4" style="padding-left:0.0pt;padding-right:0.0pt;">
<span class="ltx_text ltx_font_bold" id="S3.T2.15.15.4.1">MiniCPM</span> vs <span class="ltx_text ltx_font_bold" id="S3.T2.15.15.4.2">GLM-R</span>
</th>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S3.T2.13.13.1" style="padding-left:0.0pt;padding-right:0.0pt;"><math alttext="47.0(0.47)" class="ltx_Math" display="inline" id="S3.T2.13.13.1.m1.1"><semantics id="S3.T2.13.13.1.m1.1a"><mrow id="S3.T2.13.13.1.m1.1.2" xref="S3.T2.13.13.1.m1.1.2.cmml"><mn id="S3.T2.13.13.1.m1.1.2.2" xref="S3.T2.13.13.1.m1.1.2.2.cmml">47.0</mn><mo id="S3.T2.13.13.1.m1.1.2.1" xref="S3.T2.13.13.1.m1.1.2.1.cmml">⁢</mo><mrow id="S3.T2.13.13.1.m1.1.2.3.2" xref="S3.T2.13.13.1.m1.1.2.cmml"><mo id="S3.T2.13.13.1.m1.1.2.3.2.1" stretchy="false" xref="S3.T2.13.13.1.m1.1.2.cmml">(</mo><mn id="S3.T2.13.13.1.m1.1.1" xref="S3.T2.13.13.1.m1.1.1.cmml">0.47</mn><mo id="S3.T2.13.13.1.m1.1.2.3.2.2" stretchy="false" xref="S3.T2.13.13.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T2.13.13.1.m1.1b"><apply id="S3.T2.13.13.1.m1.1.2.cmml" xref="S3.T2.13.13.1.m1.1.2"><times id="S3.T2.13.13.1.m1.1.2.1.cmml" xref="S3.T2.13.13.1.m1.1.2.1"></times><cn id="S3.T2.13.13.1.m1.1.2.2.cmml" type="float" xref="S3.T2.13.13.1.m1.1.2.2">47.0</cn><cn id="S3.T2.13.13.1.m1.1.1.cmml" type="float" xref="S3.T2.13.13.1.m1.1.1">0.47</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.13.13.1.m1.1c">47.0(0.47)</annotation><annotation encoding="application/x-llamapun" id="S3.T2.13.13.1.m1.1d">47.0 ( 0.47 )</annotation></semantics></math></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S3.T2.14.14.2" style="padding-left:0.0pt;padding-right:0.0pt;"><math alttext="48.0(0.26)" class="ltx_Math" display="inline" id="S3.T2.14.14.2.m1.1"><semantics id="S3.T2.14.14.2.m1.1a"><mrow id="S3.T2.14.14.2.m1.1.2" xref="S3.T2.14.14.2.m1.1.2.cmml"><mn id="S3.T2.14.14.2.m1.1.2.2" xref="S3.T2.14.14.2.m1.1.2.2.cmml">48.0</mn><mo id="S3.T2.14.14.2.m1.1.2.1" xref="S3.T2.14.14.2.m1.1.2.1.cmml">⁢</mo><mrow id="S3.T2.14.14.2.m1.1.2.3.2" xref="S3.T2.14.14.2.m1.1.2.cmml"><mo id="S3.T2.14.14.2.m1.1.2.3.2.1" stretchy="false" xref="S3.T2.14.14.2.m1.1.2.cmml">(</mo><mn id="S3.T2.14.14.2.m1.1.1" xref="S3.T2.14.14.2.m1.1.1.cmml">0.26</mn><mo id="S3.T2.14.14.2.m1.1.2.3.2.2" stretchy="false" xref="S3.T2.14.14.2.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T2.14.14.2.m1.1b"><apply id="S3.T2.14.14.2.m1.1.2.cmml" xref="S3.T2.14.14.2.m1.1.2"><times id="S3.T2.14.14.2.m1.1.2.1.cmml" xref="S3.T2.14.14.2.m1.1.2.1"></times><cn id="S3.T2.14.14.2.m1.1.2.2.cmml" type="float" xref="S3.T2.14.14.2.m1.1.2.2">48.0</cn><cn id="S3.T2.14.14.2.m1.1.1.cmml" type="float" xref="S3.T2.14.14.2.m1.1.1">0.26</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.14.14.2.m1.1c">48.0(0.26)</annotation><annotation encoding="application/x-llamapun" id="S3.T2.14.14.2.m1.1d">48.0 ( 0.26 )</annotation></semantics></math></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S3.T2.15.15.3" style="padding-left:0.0pt;padding-right:0.0pt;"><math alttext="45.5(0.35)" class="ltx_Math" display="inline" id="S3.T2.15.15.3.m1.1"><semantics id="S3.T2.15.15.3.m1.1a"><mrow id="S3.T2.15.15.3.m1.1.2" xref="S3.T2.15.15.3.m1.1.2.cmml"><mn id="S3.T2.15.15.3.m1.1.2.2" xref="S3.T2.15.15.3.m1.1.2.2.cmml">45.5</mn><mo id="S3.T2.15.15.3.m1.1.2.1" xref="S3.T2.15.15.3.m1.1.2.1.cmml">⁢</mo><mrow id="S3.T2.15.15.3.m1.1.2.3.2" xref="S3.T2.15.15.3.m1.1.2.cmml"><mo id="S3.T2.15.15.3.m1.1.2.3.2.1" stretchy="false" xref="S3.T2.15.15.3.m1.1.2.cmml">(</mo><mn id="S3.T2.15.15.3.m1.1.1" xref="S3.T2.15.15.3.m1.1.1.cmml">0.35</mn><mo id="S3.T2.15.15.3.m1.1.2.3.2.2" stretchy="false" xref="S3.T2.15.15.3.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T2.15.15.3.m1.1b"><apply id="S3.T2.15.15.3.m1.1.2.cmml" xref="S3.T2.15.15.3.m1.1.2"><times id="S3.T2.15.15.3.m1.1.2.1.cmml" xref="S3.T2.15.15.3.m1.1.2.1"></times><cn id="S3.T2.15.15.3.m1.1.2.2.cmml" type="float" xref="S3.T2.15.15.3.m1.1.2.2">45.5</cn><cn id="S3.T2.15.15.3.m1.1.1.cmml" type="float" xref="S3.T2.15.15.3.m1.1.1">0.35</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.15.15.3.m1.1c">45.5(0.35)</annotation><annotation encoding="application/x-llamapun" id="S3.T2.15.15.3.m1.1d">45.5 ( 0.35 )</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S3.T2.18.18">
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row" id="S3.T2.18.18.4" style="padding-left:0.0pt;padding-right:0.0pt;">
<span class="ltx_text ltx_font_bold" id="S3.T2.18.18.4.1">GLM3</span> vs <span class="ltx_text ltx_font_bold" id="S3.T2.18.18.4.2">GLM-R</span>
</th>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S3.T2.16.16.1" style="padding-left:0.0pt;padding-right:0.0pt;"><math alttext="40.5(0.42)" class="ltx_Math" display="inline" id="S3.T2.16.16.1.m1.1"><semantics id="S3.T2.16.16.1.m1.1a"><mrow id="S3.T2.16.16.1.m1.1.2" xref="S3.T2.16.16.1.m1.1.2.cmml"><mn id="S3.T2.16.16.1.m1.1.2.2" xref="S3.T2.16.16.1.m1.1.2.2.cmml">40.5</mn><mo id="S3.T2.16.16.1.m1.1.2.1" xref="S3.T2.16.16.1.m1.1.2.1.cmml">⁢</mo><mrow id="S3.T2.16.16.1.m1.1.2.3.2" xref="S3.T2.16.16.1.m1.1.2.cmml"><mo id="S3.T2.16.16.1.m1.1.2.3.2.1" stretchy="false" xref="S3.T2.16.16.1.m1.1.2.cmml">(</mo><mn id="S3.T2.16.16.1.m1.1.1" xref="S3.T2.16.16.1.m1.1.1.cmml">0.42</mn><mo id="S3.T2.16.16.1.m1.1.2.3.2.2" stretchy="false" xref="S3.T2.16.16.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T2.16.16.1.m1.1b"><apply id="S3.T2.16.16.1.m1.1.2.cmml" xref="S3.T2.16.16.1.m1.1.2"><times id="S3.T2.16.16.1.m1.1.2.1.cmml" xref="S3.T2.16.16.1.m1.1.2.1"></times><cn id="S3.T2.16.16.1.m1.1.2.2.cmml" type="float" xref="S3.T2.16.16.1.m1.1.2.2">40.5</cn><cn id="S3.T2.16.16.1.m1.1.1.cmml" type="float" xref="S3.T2.16.16.1.m1.1.1">0.42</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.16.16.1.m1.1c">40.5(0.42)</annotation><annotation encoding="application/x-llamapun" id="S3.T2.16.16.1.m1.1d">40.5 ( 0.42 )</annotation></semantics></math></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S3.T2.17.17.2" style="padding-left:0.0pt;padding-right:0.0pt;"><math alttext="44.2(0.18)" class="ltx_Math" display="inline" id="S3.T2.17.17.2.m1.1"><semantics id="S3.T2.17.17.2.m1.1a"><mrow id="S3.T2.17.17.2.m1.1.2" xref="S3.T2.17.17.2.m1.1.2.cmml"><mn id="S3.T2.17.17.2.m1.1.2.2" xref="S3.T2.17.17.2.m1.1.2.2.cmml">44.2</mn><mo id="S3.T2.17.17.2.m1.1.2.1" xref="S3.T2.17.17.2.m1.1.2.1.cmml">⁢</mo><mrow id="S3.T2.17.17.2.m1.1.2.3.2" xref="S3.T2.17.17.2.m1.1.2.cmml"><mo id="S3.T2.17.17.2.m1.1.2.3.2.1" stretchy="false" xref="S3.T2.17.17.2.m1.1.2.cmml">(</mo><mn id="S3.T2.17.17.2.m1.1.1" xref="S3.T2.17.17.2.m1.1.1.cmml">0.18</mn><mo id="S3.T2.17.17.2.m1.1.2.3.2.2" stretchy="false" xref="S3.T2.17.17.2.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T2.17.17.2.m1.1b"><apply id="S3.T2.17.17.2.m1.1.2.cmml" xref="S3.T2.17.17.2.m1.1.2"><times id="S3.T2.17.17.2.m1.1.2.1.cmml" xref="S3.T2.17.17.2.m1.1.2.1"></times><cn id="S3.T2.17.17.2.m1.1.2.2.cmml" type="float" xref="S3.T2.17.17.2.m1.1.2.2">44.2</cn><cn id="S3.T2.17.17.2.m1.1.1.cmml" type="float" xref="S3.T2.17.17.2.m1.1.1">0.18</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.17.17.2.m1.1c">44.2(0.18)</annotation><annotation encoding="application/x-llamapun" id="S3.T2.17.17.2.m1.1d">44.2 ( 0.18 )</annotation></semantics></math></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S3.T2.18.18.3" style="padding-left:0.0pt;padding-right:0.0pt;"><math alttext="39.0(0.32)" class="ltx_Math" display="inline" id="S3.T2.18.18.3.m1.1"><semantics id="S3.T2.18.18.3.m1.1a"><mrow id="S3.T2.18.18.3.m1.1.2" xref="S3.T2.18.18.3.m1.1.2.cmml"><mn id="S3.T2.18.18.3.m1.1.2.2" xref="S3.T2.18.18.3.m1.1.2.2.cmml">39.0</mn><mo id="S3.T2.18.18.3.m1.1.2.1" xref="S3.T2.18.18.3.m1.1.2.1.cmml">⁢</mo><mrow id="S3.T2.18.18.3.m1.1.2.3.2" xref="S3.T2.18.18.3.m1.1.2.cmml"><mo id="S3.T2.18.18.3.m1.1.2.3.2.1" stretchy="false" xref="S3.T2.18.18.3.m1.1.2.cmml">(</mo><mn id="S3.T2.18.18.3.m1.1.1" xref="S3.T2.18.18.3.m1.1.1.cmml">0.32</mn><mo id="S3.T2.18.18.3.m1.1.2.3.2.2" stretchy="false" xref="S3.T2.18.18.3.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T2.18.18.3.m1.1b"><apply id="S3.T2.18.18.3.m1.1.2.cmml" xref="S3.T2.18.18.3.m1.1.2"><times id="S3.T2.18.18.3.m1.1.2.1.cmml" xref="S3.T2.18.18.3.m1.1.2.1"></times><cn id="S3.T2.18.18.3.m1.1.2.2.cmml" type="float" xref="S3.T2.18.18.3.m1.1.2.2">39.0</cn><cn id="S3.T2.18.18.3.m1.1.1.cmml" type="float" xref="S3.T2.18.18.3.m1.1.1">0.32</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.18.18.3.m1.1c">39.0(0.32)</annotation><annotation encoding="application/x-llamapun" id="S3.T2.18.18.3.m1.1d">39.0 ( 0.32 )</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S3.T2.21.21">
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="S3.T2.21.21.4" style="padding-left:0.0pt;padding-right:0.0pt;">
<span class="ltx_text ltx_font_bold" id="S3.T2.21.21.4.1">GLM</span> vs <span class="ltx_text ltx_font_bold" id="S3.T2.21.21.4.2">GLM-R</span>
</th>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t" id="S3.T2.19.19.1" style="padding-left:0.0pt;padding-right:0.0pt;"><math alttext="48.3(0.25)" class="ltx_Math" display="inline" id="S3.T2.19.19.1.m1.1"><semantics id="S3.T2.19.19.1.m1.1a"><mrow id="S3.T2.19.19.1.m1.1.2" xref="S3.T2.19.19.1.m1.1.2.cmml"><mn id="S3.T2.19.19.1.m1.1.2.2" xref="S3.T2.19.19.1.m1.1.2.2.cmml">48.3</mn><mo id="S3.T2.19.19.1.m1.1.2.1" xref="S3.T2.19.19.1.m1.1.2.1.cmml">⁢</mo><mrow id="S3.T2.19.19.1.m1.1.2.3.2" xref="S3.T2.19.19.1.m1.1.2.cmml"><mo id="S3.T2.19.19.1.m1.1.2.3.2.1" stretchy="false" xref="S3.T2.19.19.1.m1.1.2.cmml">(</mo><mn id="S3.T2.19.19.1.m1.1.1" xref="S3.T2.19.19.1.m1.1.1.cmml">0.25</mn><mo id="S3.T2.19.19.1.m1.1.2.3.2.2" stretchy="false" xref="S3.T2.19.19.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T2.19.19.1.m1.1b"><apply id="S3.T2.19.19.1.m1.1.2.cmml" xref="S3.T2.19.19.1.m1.1.2"><times id="S3.T2.19.19.1.m1.1.2.1.cmml" xref="S3.T2.19.19.1.m1.1.2.1"></times><cn id="S3.T2.19.19.1.m1.1.2.2.cmml" type="float" xref="S3.T2.19.19.1.m1.1.2.2">48.3</cn><cn id="S3.T2.19.19.1.m1.1.1.cmml" type="float" xref="S3.T2.19.19.1.m1.1.1">0.25</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.19.19.1.m1.1c">48.3(0.25)</annotation><annotation encoding="application/x-llamapun" id="S3.T2.19.19.1.m1.1d">48.3 ( 0.25 )</annotation></semantics></math></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t" id="S3.T2.20.20.2" style="padding-left:0.0pt;padding-right:0.0pt;"><math alttext="42.2(0.55)" class="ltx_Math" display="inline" id="S3.T2.20.20.2.m1.1"><semantics id="S3.T2.20.20.2.m1.1a"><mrow id="S3.T2.20.20.2.m1.1.2" xref="S3.T2.20.20.2.m1.1.2.cmml"><mn id="S3.T2.20.20.2.m1.1.2.2" xref="S3.T2.20.20.2.m1.1.2.2.cmml">42.2</mn><mo id="S3.T2.20.20.2.m1.1.2.1" xref="S3.T2.20.20.2.m1.1.2.1.cmml">⁢</mo><mrow id="S3.T2.20.20.2.m1.1.2.3.2" xref="S3.T2.20.20.2.m1.1.2.cmml"><mo id="S3.T2.20.20.2.m1.1.2.3.2.1" stretchy="false" xref="S3.T2.20.20.2.m1.1.2.cmml">(</mo><mn id="S3.T2.20.20.2.m1.1.1" xref="S3.T2.20.20.2.m1.1.1.cmml">0.55</mn><mo id="S3.T2.20.20.2.m1.1.2.3.2.2" stretchy="false" xref="S3.T2.20.20.2.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T2.20.20.2.m1.1b"><apply id="S3.T2.20.20.2.m1.1.2.cmml" xref="S3.T2.20.20.2.m1.1.2"><times id="S3.T2.20.20.2.m1.1.2.1.cmml" xref="S3.T2.20.20.2.m1.1.2.1"></times><cn id="S3.T2.20.20.2.m1.1.2.2.cmml" type="float" xref="S3.T2.20.20.2.m1.1.2.2">42.2</cn><cn id="S3.T2.20.20.2.m1.1.1.cmml" type="float" xref="S3.T2.20.20.2.m1.1.1">0.55</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.20.20.2.m1.1c">42.2(0.55)</annotation><annotation encoding="application/x-llamapun" id="S3.T2.20.20.2.m1.1d">42.2 ( 0.55 )</annotation></semantics></math></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t" id="S3.T2.21.21.3" style="padding-left:0.0pt;padding-right:0.0pt;"><math alttext="43.6(0.64)" class="ltx_Math" display="inline" id="S3.T2.21.21.3.m1.1"><semantics id="S3.T2.21.21.3.m1.1a"><mrow id="S3.T2.21.21.3.m1.1.2" xref="S3.T2.21.21.3.m1.1.2.cmml"><mn id="S3.T2.21.21.3.m1.1.2.2" xref="S3.T2.21.21.3.m1.1.2.2.cmml">43.6</mn><mo id="S3.T2.21.21.3.m1.1.2.1" xref="S3.T2.21.21.3.m1.1.2.1.cmml">⁢</mo><mrow id="S3.T2.21.21.3.m1.1.2.3.2" xref="S3.T2.21.21.3.m1.1.2.cmml"><mo id="S3.T2.21.21.3.m1.1.2.3.2.1" stretchy="false" xref="S3.T2.21.21.3.m1.1.2.cmml">(</mo><mn id="S3.T2.21.21.3.m1.1.1" xref="S3.T2.21.21.3.m1.1.1.cmml">0.64</mn><mo id="S3.T2.21.21.3.m1.1.2.3.2.2" stretchy="false" xref="S3.T2.21.21.3.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T2.21.21.3.m1.1b"><apply id="S3.T2.21.21.3.m1.1.2.cmml" xref="S3.T2.21.21.3.m1.1.2"><times id="S3.T2.21.21.3.m1.1.2.1.cmml" xref="S3.T2.21.21.3.m1.1.2.1"></times><cn id="S3.T2.21.21.3.m1.1.2.2.cmml" type="float" xref="S3.T2.21.21.3.m1.1.2.2">43.6</cn><cn id="S3.T2.21.21.3.m1.1.1.cmml" type="float" xref="S3.T2.21.21.3.m1.1.1">0.64</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.21.21.3.m1.1c">43.6(0.64)</annotation><annotation encoding="application/x-llamapun" id="S3.T2.21.21.3.m1.1d">43.6 ( 0.64 )</annotation></semantics></math></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>
Evaluations between fine-tuned models (Qwen1.5-4B, MiniCPM-2B, ChatGLM3-6b) and the commercial <a class="ltx_ref ltx_href" href="https://bigmodel.cn" title="">GLM-4</a> model with and without RAM2C as baselines. <span class="ltx_text ltx_font_bold" id="S3.T2.26.1">H/T/S</span> indicate humanized communication, teaching expertise and safety &amp; ethics. The values in parentheses represent the IAA score. <span class="ltx_text ltx_font_bold" id="S3.T2.27.2">GLM3</span> means local ChatGLM3-6b, <span class="ltx_text ltx_font_bold" id="S3.T2.28.3">GLM</span> means commercial GLM-4 without RAM2C, and <span class="ltx_text ltx_font_bold" id="S3.T2.29.4">GLM-R</span> means commercial GLM-4 with RAM2C.
</figcaption>
</figure>
<figure class="ltx_table" id="S3.T3">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S3.T3.15">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T3.15.16.1">
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S3.T3.15.16.1.1" style="padding-left:0.0pt;padding-right:0.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T3.15.16.1.1.1">Criteria</span></th>
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T3.15.16.1.2" style="padding-left:0.0pt;padding-right:0.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T3.15.16.1.2.1">H</span></th>
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T3.15.16.1.3" style="padding-left:0.0pt;padding-right:0.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T3.15.16.1.3.1">T</span></th>
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T3.15.16.1.4" style="padding-left:0.0pt;padding-right:0.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T3.15.16.1.4.1">S</span></th>
</tr>
<tr class="ltx_tr" id="S3.T3.3.3">
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t" id="S3.T3.3.3.4" style="padding-left:0.0pt;padding-right:0.0pt;">
<span class="ltx_text ltx_font_bold" id="S3.T3.3.3.4.1">GLM</span> vs <span class="ltx_text ltx_font_bold" id="S3.T3.3.3.4.2">GLM-R</span>
</th>
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S3.T3.1.1.1" style="padding-left:0.0pt;padding-right:0.0pt;"><math alttext="48.3(0.25)" class="ltx_Math" display="inline" id="S3.T3.1.1.1.m1.1"><semantics id="S3.T3.1.1.1.m1.1a"><mrow id="S3.T3.1.1.1.m1.1.2" xref="S3.T3.1.1.1.m1.1.2.cmml"><mn id="S3.T3.1.1.1.m1.1.2.2" xref="S3.T3.1.1.1.m1.1.2.2.cmml">48.3</mn><mo id="S3.T3.1.1.1.m1.1.2.1" xref="S3.T3.1.1.1.m1.1.2.1.cmml">⁢</mo><mrow id="S3.T3.1.1.1.m1.1.2.3.2" xref="S3.T3.1.1.1.m1.1.2.cmml"><mo id="S3.T3.1.1.1.m1.1.2.3.2.1" stretchy="false" xref="S3.T3.1.1.1.m1.1.2.cmml">(</mo><mn id="S3.T3.1.1.1.m1.1.1" xref="S3.T3.1.1.1.m1.1.1.cmml">0.25</mn><mo id="S3.T3.1.1.1.m1.1.2.3.2.2" stretchy="false" xref="S3.T3.1.1.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T3.1.1.1.m1.1b"><apply id="S3.T3.1.1.1.m1.1.2.cmml" xref="S3.T3.1.1.1.m1.1.2"><times id="S3.T3.1.1.1.m1.1.2.1.cmml" xref="S3.T3.1.1.1.m1.1.2.1"></times><cn id="S3.T3.1.1.1.m1.1.2.2.cmml" type="float" xref="S3.T3.1.1.1.m1.1.2.2">48.3</cn><cn id="S3.T3.1.1.1.m1.1.1.cmml" type="float" xref="S3.T3.1.1.1.m1.1.1">0.25</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.1.1.1.m1.1c">48.3(0.25)</annotation><annotation encoding="application/x-llamapun" id="S3.T3.1.1.1.m1.1d">48.3 ( 0.25 )</annotation></semantics></math></th>
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S3.T3.2.2.2" style="padding-left:0.0pt;padding-right:0.0pt;"><math alttext="42.2(0.55)" class="ltx_Math" display="inline" id="S3.T3.2.2.2.m1.1"><semantics id="S3.T3.2.2.2.m1.1a"><mrow id="S3.T3.2.2.2.m1.1.2" xref="S3.T3.2.2.2.m1.1.2.cmml"><mn id="S3.T3.2.2.2.m1.1.2.2" xref="S3.T3.2.2.2.m1.1.2.2.cmml">42.2</mn><mo id="S3.T3.2.2.2.m1.1.2.1" xref="S3.T3.2.2.2.m1.1.2.1.cmml">⁢</mo><mrow id="S3.T3.2.2.2.m1.1.2.3.2" xref="S3.T3.2.2.2.m1.1.2.cmml"><mo id="S3.T3.2.2.2.m1.1.2.3.2.1" stretchy="false" xref="S3.T3.2.2.2.m1.1.2.cmml">(</mo><mn id="S3.T3.2.2.2.m1.1.1" xref="S3.T3.2.2.2.m1.1.1.cmml">0.55</mn><mo id="S3.T3.2.2.2.m1.1.2.3.2.2" stretchy="false" xref="S3.T3.2.2.2.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T3.2.2.2.m1.1b"><apply id="S3.T3.2.2.2.m1.1.2.cmml" xref="S3.T3.2.2.2.m1.1.2"><times id="S3.T3.2.2.2.m1.1.2.1.cmml" xref="S3.T3.2.2.2.m1.1.2.1"></times><cn id="S3.T3.2.2.2.m1.1.2.2.cmml" type="float" xref="S3.T3.2.2.2.m1.1.2.2">42.2</cn><cn id="S3.T3.2.2.2.m1.1.1.cmml" type="float" xref="S3.T3.2.2.2.m1.1.1">0.55</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.2.2.2.m1.1c">42.2(0.55)</annotation><annotation encoding="application/x-llamapun" id="S3.T3.2.2.2.m1.1d">42.2 ( 0.55 )</annotation></semantics></math></th>
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S3.T3.3.3.3" style="padding-left:0.0pt;padding-right:0.0pt;"><math alttext="43.6(0.64)" class="ltx_Math" display="inline" id="S3.T3.3.3.3.m1.1"><semantics id="S3.T3.3.3.3.m1.1a"><mrow id="S3.T3.3.3.3.m1.1.2" xref="S3.T3.3.3.3.m1.1.2.cmml"><mn id="S3.T3.3.3.3.m1.1.2.2" xref="S3.T3.3.3.3.m1.1.2.2.cmml">43.6</mn><mo id="S3.T3.3.3.3.m1.1.2.1" xref="S3.T3.3.3.3.m1.1.2.1.cmml">⁢</mo><mrow id="S3.T3.3.3.3.m1.1.2.3.2" xref="S3.T3.3.3.3.m1.1.2.cmml"><mo id="S3.T3.3.3.3.m1.1.2.3.2.1" stretchy="false" xref="S3.T3.3.3.3.m1.1.2.cmml">(</mo><mn id="S3.T3.3.3.3.m1.1.1" xref="S3.T3.3.3.3.m1.1.1.cmml">0.64</mn><mo id="S3.T3.3.3.3.m1.1.2.3.2.2" stretchy="false" xref="S3.T3.3.3.3.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T3.3.3.3.m1.1b"><apply id="S3.T3.3.3.3.m1.1.2.cmml" xref="S3.T3.3.3.3.m1.1.2"><times id="S3.T3.3.3.3.m1.1.2.1.cmml" xref="S3.T3.3.3.3.m1.1.2.1"></times><cn id="S3.T3.3.3.3.m1.1.2.2.cmml" type="float" xref="S3.T3.3.3.3.m1.1.2.2">43.6</cn><cn id="S3.T3.3.3.3.m1.1.1.cmml" type="float" xref="S3.T3.3.3.3.m1.1.1">0.64</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.3.3.3.m1.1c">43.6(0.64)</annotation><annotation encoding="application/x-llamapun" id="S3.T3.3.3.3.m1.1d">43.6 ( 0.64 )</annotation></semantics></math></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T3.6.6">
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S3.T3.6.6.4" style="padding-left:0.0pt;padding-right:0.0pt;">
<span class="ltx_text ltx_font_bold" id="S3.T3.6.6.4.1">GLM-P/R</span> vs <span class="ltx_text ltx_font_bold" id="S3.T3.6.6.4.2">GLM-R</span>
</th>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S3.T3.4.4.1" style="padding-left:0.0pt;padding-right:0.0pt;"><math alttext="46.5(0.65)" class="ltx_Math" display="inline" id="S3.T3.4.4.1.m1.1"><semantics id="S3.T3.4.4.1.m1.1a"><mrow id="S3.T3.4.4.1.m1.1.2" xref="S3.T3.4.4.1.m1.1.2.cmml"><mn id="S3.T3.4.4.1.m1.1.2.2" xref="S3.T3.4.4.1.m1.1.2.2.cmml">46.5</mn><mo id="S3.T3.4.4.1.m1.1.2.1" xref="S3.T3.4.4.1.m1.1.2.1.cmml">⁢</mo><mrow id="S3.T3.4.4.1.m1.1.2.3.2" xref="S3.T3.4.4.1.m1.1.2.cmml"><mo id="S3.T3.4.4.1.m1.1.2.3.2.1" stretchy="false" xref="S3.T3.4.4.1.m1.1.2.cmml">(</mo><mn id="S3.T3.4.4.1.m1.1.1" xref="S3.T3.4.4.1.m1.1.1.cmml">0.65</mn><mo id="S3.T3.4.4.1.m1.1.2.3.2.2" stretchy="false" xref="S3.T3.4.4.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T3.4.4.1.m1.1b"><apply id="S3.T3.4.4.1.m1.1.2.cmml" xref="S3.T3.4.4.1.m1.1.2"><times id="S3.T3.4.4.1.m1.1.2.1.cmml" xref="S3.T3.4.4.1.m1.1.2.1"></times><cn id="S3.T3.4.4.1.m1.1.2.2.cmml" type="float" xref="S3.T3.4.4.1.m1.1.2.2">46.5</cn><cn id="S3.T3.4.4.1.m1.1.1.cmml" type="float" xref="S3.T3.4.4.1.m1.1.1">0.65</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.4.4.1.m1.1c">46.5(0.65)</annotation><annotation encoding="application/x-llamapun" id="S3.T3.4.4.1.m1.1d">46.5 ( 0.65 )</annotation></semantics></math></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S3.T3.5.5.2" style="padding-left:0.0pt;padding-right:0.0pt;"><math alttext="51.0(0.32)" class="ltx_Math" display="inline" id="S3.T3.5.5.2.m1.1"><semantics id="S3.T3.5.5.2.m1.1a"><mrow id="S3.T3.5.5.2.m1.1.2" xref="S3.T3.5.5.2.m1.1.2.cmml"><mn id="S3.T3.5.5.2.m1.1.2.2" xref="S3.T3.5.5.2.m1.1.2.2.cmml">51.0</mn><mo id="S3.T3.5.5.2.m1.1.2.1" xref="S3.T3.5.5.2.m1.1.2.1.cmml">⁢</mo><mrow id="S3.T3.5.5.2.m1.1.2.3.2" xref="S3.T3.5.5.2.m1.1.2.cmml"><mo id="S3.T3.5.5.2.m1.1.2.3.2.1" stretchy="false" xref="S3.T3.5.5.2.m1.1.2.cmml">(</mo><mn id="S3.T3.5.5.2.m1.1.1" xref="S3.T3.5.5.2.m1.1.1.cmml">0.32</mn><mo id="S3.T3.5.5.2.m1.1.2.3.2.2" stretchy="false" xref="S3.T3.5.5.2.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T3.5.5.2.m1.1b"><apply id="S3.T3.5.5.2.m1.1.2.cmml" xref="S3.T3.5.5.2.m1.1.2"><times id="S3.T3.5.5.2.m1.1.2.1.cmml" xref="S3.T3.5.5.2.m1.1.2.1"></times><cn id="S3.T3.5.5.2.m1.1.2.2.cmml" type="float" xref="S3.T3.5.5.2.m1.1.2.2">51.0</cn><cn id="S3.T3.5.5.2.m1.1.1.cmml" type="float" xref="S3.T3.5.5.2.m1.1.1">0.32</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.5.5.2.m1.1c">51.0(0.32)</annotation><annotation encoding="application/x-llamapun" id="S3.T3.5.5.2.m1.1d">51.0 ( 0.32 )</annotation></semantics></math></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S3.T3.6.6.3" style="padding-left:0.0pt;padding-right:0.0pt;"><math alttext="50.2(0.41)" class="ltx_Math" display="inline" id="S3.T3.6.6.3.m1.1"><semantics id="S3.T3.6.6.3.m1.1a"><mrow id="S3.T3.6.6.3.m1.1.2" xref="S3.T3.6.6.3.m1.1.2.cmml"><mn id="S3.T3.6.6.3.m1.1.2.2" xref="S3.T3.6.6.3.m1.1.2.2.cmml">50.2</mn><mo id="S3.T3.6.6.3.m1.1.2.1" xref="S3.T3.6.6.3.m1.1.2.1.cmml">⁢</mo><mrow id="S3.T3.6.6.3.m1.1.2.3.2" xref="S3.T3.6.6.3.m1.1.2.cmml"><mo id="S3.T3.6.6.3.m1.1.2.3.2.1" stretchy="false" xref="S3.T3.6.6.3.m1.1.2.cmml">(</mo><mn id="S3.T3.6.6.3.m1.1.1" xref="S3.T3.6.6.3.m1.1.1.cmml">0.41</mn><mo id="S3.T3.6.6.3.m1.1.2.3.2.2" stretchy="false" xref="S3.T3.6.6.3.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T3.6.6.3.m1.1b"><apply id="S3.T3.6.6.3.m1.1.2.cmml" xref="S3.T3.6.6.3.m1.1.2"><times id="S3.T3.6.6.3.m1.1.2.1.cmml" xref="S3.T3.6.6.3.m1.1.2.1"></times><cn id="S3.T3.6.6.3.m1.1.2.2.cmml" type="float" xref="S3.T3.6.6.3.m1.1.2.2">50.2</cn><cn id="S3.T3.6.6.3.m1.1.1.cmml" type="float" xref="S3.T3.6.6.3.m1.1.1">0.41</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.6.6.3.m1.1c">50.2(0.41)</annotation><annotation encoding="application/x-llamapun" id="S3.T3.6.6.3.m1.1d">50.2 ( 0.41 )</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S3.T3.9.9">
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row" id="S3.T3.9.9.4" style="padding-left:0.0pt;padding-right:0.0pt;">
<span class="ltx_text ltx_font_bold" id="S3.T3.9.9.4.1">GLM-S/R</span> vs <span class="ltx_text ltx_font_bold" id="S3.T3.9.9.4.2">GLM-R</span>
</th>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S3.T3.7.7.1" style="padding-left:0.0pt;padding-right:0.0pt;"><math alttext="50.3(0.55)" class="ltx_Math" display="inline" id="S3.T3.7.7.1.m1.1"><semantics id="S3.T3.7.7.1.m1.1a"><mrow id="S3.T3.7.7.1.m1.1.2" xref="S3.T3.7.7.1.m1.1.2.cmml"><mn id="S3.T3.7.7.1.m1.1.2.2" xref="S3.T3.7.7.1.m1.1.2.2.cmml">50.3</mn><mo id="S3.T3.7.7.1.m1.1.2.1" xref="S3.T3.7.7.1.m1.1.2.1.cmml">⁢</mo><mrow id="S3.T3.7.7.1.m1.1.2.3.2" xref="S3.T3.7.7.1.m1.1.2.cmml"><mo id="S3.T3.7.7.1.m1.1.2.3.2.1" stretchy="false" xref="S3.T3.7.7.1.m1.1.2.cmml">(</mo><mn id="S3.T3.7.7.1.m1.1.1" xref="S3.T3.7.7.1.m1.1.1.cmml">0.55</mn><mo id="S3.T3.7.7.1.m1.1.2.3.2.2" stretchy="false" xref="S3.T3.7.7.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T3.7.7.1.m1.1b"><apply id="S3.T3.7.7.1.m1.1.2.cmml" xref="S3.T3.7.7.1.m1.1.2"><times id="S3.T3.7.7.1.m1.1.2.1.cmml" xref="S3.T3.7.7.1.m1.1.2.1"></times><cn id="S3.T3.7.7.1.m1.1.2.2.cmml" type="float" xref="S3.T3.7.7.1.m1.1.2.2">50.3</cn><cn id="S3.T3.7.7.1.m1.1.1.cmml" type="float" xref="S3.T3.7.7.1.m1.1.1">0.55</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.7.7.1.m1.1c">50.3(0.55)</annotation><annotation encoding="application/x-llamapun" id="S3.T3.7.7.1.m1.1d">50.3 ( 0.55 )</annotation></semantics></math></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S3.T3.8.8.2" style="padding-left:0.0pt;padding-right:0.0pt;"><math alttext="50.7(0.21)" class="ltx_Math" display="inline" id="S3.T3.8.8.2.m1.1"><semantics id="S3.T3.8.8.2.m1.1a"><mrow id="S3.T3.8.8.2.m1.1.2" xref="S3.T3.8.8.2.m1.1.2.cmml"><mn id="S3.T3.8.8.2.m1.1.2.2" xref="S3.T3.8.8.2.m1.1.2.2.cmml">50.7</mn><mo id="S3.T3.8.8.2.m1.1.2.1" xref="S3.T3.8.8.2.m1.1.2.1.cmml">⁢</mo><mrow id="S3.T3.8.8.2.m1.1.2.3.2" xref="S3.T3.8.8.2.m1.1.2.cmml"><mo id="S3.T3.8.8.2.m1.1.2.3.2.1" stretchy="false" xref="S3.T3.8.8.2.m1.1.2.cmml">(</mo><mn id="S3.T3.8.8.2.m1.1.1" xref="S3.T3.8.8.2.m1.1.1.cmml">0.21</mn><mo id="S3.T3.8.8.2.m1.1.2.3.2.2" stretchy="false" xref="S3.T3.8.8.2.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T3.8.8.2.m1.1b"><apply id="S3.T3.8.8.2.m1.1.2.cmml" xref="S3.T3.8.8.2.m1.1.2"><times id="S3.T3.8.8.2.m1.1.2.1.cmml" xref="S3.T3.8.8.2.m1.1.2.1"></times><cn id="S3.T3.8.8.2.m1.1.2.2.cmml" type="float" xref="S3.T3.8.8.2.m1.1.2.2">50.7</cn><cn id="S3.T3.8.8.2.m1.1.1.cmml" type="float" xref="S3.T3.8.8.2.m1.1.1">0.21</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.8.8.2.m1.1c">50.7(0.21)</annotation><annotation encoding="application/x-llamapun" id="S3.T3.8.8.2.m1.1d">50.7 ( 0.21 )</annotation></semantics></math></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S3.T3.9.9.3" style="padding-left:0.0pt;padding-right:0.0pt;"><math alttext="48.1(0.46)" class="ltx_Math" display="inline" id="S3.T3.9.9.3.m1.1"><semantics id="S3.T3.9.9.3.m1.1a"><mrow id="S3.T3.9.9.3.m1.1.2" xref="S3.T3.9.9.3.m1.1.2.cmml"><mn id="S3.T3.9.9.3.m1.1.2.2" xref="S3.T3.9.9.3.m1.1.2.2.cmml">48.1</mn><mo id="S3.T3.9.9.3.m1.1.2.1" xref="S3.T3.9.9.3.m1.1.2.1.cmml">⁢</mo><mrow id="S3.T3.9.9.3.m1.1.2.3.2" xref="S3.T3.9.9.3.m1.1.2.cmml"><mo id="S3.T3.9.9.3.m1.1.2.3.2.1" stretchy="false" xref="S3.T3.9.9.3.m1.1.2.cmml">(</mo><mn id="S3.T3.9.9.3.m1.1.1" xref="S3.T3.9.9.3.m1.1.1.cmml">0.46</mn><mo id="S3.T3.9.9.3.m1.1.2.3.2.2" stretchy="false" xref="S3.T3.9.9.3.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T3.9.9.3.m1.1b"><apply id="S3.T3.9.9.3.m1.1.2.cmml" xref="S3.T3.9.9.3.m1.1.2"><times id="S3.T3.9.9.3.m1.1.2.1.cmml" xref="S3.T3.9.9.3.m1.1.2.1"></times><cn id="S3.T3.9.9.3.m1.1.2.2.cmml" type="float" xref="S3.T3.9.9.3.m1.1.2.2">48.1</cn><cn id="S3.T3.9.9.3.m1.1.1.cmml" type="float" xref="S3.T3.9.9.3.m1.1.1">0.46</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.9.9.3.m1.1c">48.1(0.46)</annotation><annotation encoding="application/x-llamapun" id="S3.T3.9.9.3.m1.1d">48.1 ( 0.46 )</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S3.T3.12.12">
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row" id="S3.T3.12.12.4" style="padding-left:0.0pt;padding-right:0.0pt;">
<span class="ltx_text ltx_font_bold" id="S3.T3.12.12.4.1">GLM-PS/R</span> vs <span class="ltx_text ltx_font_bold" id="S3.T3.12.12.4.2">GLM-R</span>
</th>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S3.T3.10.10.1" style="padding-left:0.0pt;padding-right:0.0pt;"><math alttext="46.3(0.22)" class="ltx_Math" display="inline" id="S3.T3.10.10.1.m1.1"><semantics id="S3.T3.10.10.1.m1.1a"><mrow id="S3.T3.10.10.1.m1.1.2" xref="S3.T3.10.10.1.m1.1.2.cmml"><mn id="S3.T3.10.10.1.m1.1.2.2" xref="S3.T3.10.10.1.m1.1.2.2.cmml">46.3</mn><mo id="S3.T3.10.10.1.m1.1.2.1" xref="S3.T3.10.10.1.m1.1.2.1.cmml">⁢</mo><mrow id="S3.T3.10.10.1.m1.1.2.3.2" xref="S3.T3.10.10.1.m1.1.2.cmml"><mo id="S3.T3.10.10.1.m1.1.2.3.2.1" stretchy="false" xref="S3.T3.10.10.1.m1.1.2.cmml">(</mo><mn id="S3.T3.10.10.1.m1.1.1" xref="S3.T3.10.10.1.m1.1.1.cmml">0.22</mn><mo id="S3.T3.10.10.1.m1.1.2.3.2.2" stretchy="false" xref="S3.T3.10.10.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T3.10.10.1.m1.1b"><apply id="S3.T3.10.10.1.m1.1.2.cmml" xref="S3.T3.10.10.1.m1.1.2"><times id="S3.T3.10.10.1.m1.1.2.1.cmml" xref="S3.T3.10.10.1.m1.1.2.1"></times><cn id="S3.T3.10.10.1.m1.1.2.2.cmml" type="float" xref="S3.T3.10.10.1.m1.1.2.2">46.3</cn><cn id="S3.T3.10.10.1.m1.1.1.cmml" type="float" xref="S3.T3.10.10.1.m1.1.1">0.22</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.10.10.1.m1.1c">46.3(0.22)</annotation><annotation encoding="application/x-llamapun" id="S3.T3.10.10.1.m1.1d">46.3 ( 0.22 )</annotation></semantics></math></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S3.T3.11.11.2" style="padding-left:0.0pt;padding-right:0.0pt;"><math alttext="48.2(0.39)" class="ltx_Math" display="inline" id="S3.T3.11.11.2.m1.1"><semantics id="S3.T3.11.11.2.m1.1a"><mrow id="S3.T3.11.11.2.m1.1.2" xref="S3.T3.11.11.2.m1.1.2.cmml"><mn id="S3.T3.11.11.2.m1.1.2.2" xref="S3.T3.11.11.2.m1.1.2.2.cmml">48.2</mn><mo id="S3.T3.11.11.2.m1.1.2.1" xref="S3.T3.11.11.2.m1.1.2.1.cmml">⁢</mo><mrow id="S3.T3.11.11.2.m1.1.2.3.2" xref="S3.T3.11.11.2.m1.1.2.cmml"><mo id="S3.T3.11.11.2.m1.1.2.3.2.1" stretchy="false" xref="S3.T3.11.11.2.m1.1.2.cmml">(</mo><mn id="S3.T3.11.11.2.m1.1.1" xref="S3.T3.11.11.2.m1.1.1.cmml">0.39</mn><mo id="S3.T3.11.11.2.m1.1.2.3.2.2" stretchy="false" xref="S3.T3.11.11.2.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T3.11.11.2.m1.1b"><apply id="S3.T3.11.11.2.m1.1.2.cmml" xref="S3.T3.11.11.2.m1.1.2"><times id="S3.T3.11.11.2.m1.1.2.1.cmml" xref="S3.T3.11.11.2.m1.1.2.1"></times><cn id="S3.T3.11.11.2.m1.1.2.2.cmml" type="float" xref="S3.T3.11.11.2.m1.1.2.2">48.2</cn><cn id="S3.T3.11.11.2.m1.1.1.cmml" type="float" xref="S3.T3.11.11.2.m1.1.1">0.39</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.11.11.2.m1.1c">48.2(0.39)</annotation><annotation encoding="application/x-llamapun" id="S3.T3.11.11.2.m1.1d">48.2 ( 0.39 )</annotation></semantics></math></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S3.T3.12.12.3" style="padding-left:0.0pt;padding-right:0.0pt;"><math alttext="47.8(0.42)" class="ltx_Math" display="inline" id="S3.T3.12.12.3.m1.1"><semantics id="S3.T3.12.12.3.m1.1a"><mrow id="S3.T3.12.12.3.m1.1.2" xref="S3.T3.12.12.3.m1.1.2.cmml"><mn id="S3.T3.12.12.3.m1.1.2.2" xref="S3.T3.12.12.3.m1.1.2.2.cmml">47.8</mn><mo id="S3.T3.12.12.3.m1.1.2.1" xref="S3.T3.12.12.3.m1.1.2.1.cmml">⁢</mo><mrow id="S3.T3.12.12.3.m1.1.2.3.2" xref="S3.T3.12.12.3.m1.1.2.cmml"><mo id="S3.T3.12.12.3.m1.1.2.3.2.1" stretchy="false" xref="S3.T3.12.12.3.m1.1.2.cmml">(</mo><mn id="S3.T3.12.12.3.m1.1.1" xref="S3.T3.12.12.3.m1.1.1.cmml">0.42</mn><mo id="S3.T3.12.12.3.m1.1.2.3.2.2" stretchy="false" xref="S3.T3.12.12.3.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T3.12.12.3.m1.1b"><apply id="S3.T3.12.12.3.m1.1.2.cmml" xref="S3.T3.12.12.3.m1.1.2"><times id="S3.T3.12.12.3.m1.1.2.1.cmml" xref="S3.T3.12.12.3.m1.1.2.1"></times><cn id="S3.T3.12.12.3.m1.1.2.2.cmml" type="float" xref="S3.T3.12.12.3.m1.1.2.2">47.8</cn><cn id="S3.T3.12.12.3.m1.1.1.cmml" type="float" xref="S3.T3.12.12.3.m1.1.1">0.42</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.12.12.3.m1.1c">47.8(0.42)</annotation><annotation encoding="application/x-llamapun" id="S3.T3.12.12.3.m1.1d">47.8 ( 0.42 )</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S3.T3.15.15">
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="S3.T3.15.15.4" style="padding-left:0.0pt;padding-right:0.0pt;">
<span class="ltx_text ltx_font_bold" id="S3.T3.15.15.4.1">GLM-R/1</span> vs <span class="ltx_text ltx_font_bold" id="S3.T3.15.15.4.2">GLM-R</span>
</th>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t" id="S3.T3.13.13.1" style="padding-left:0.0pt;padding-right:0.0pt;"><math alttext="44.8(0.28)" class="ltx_Math" display="inline" id="S3.T3.13.13.1.m1.1"><semantics id="S3.T3.13.13.1.m1.1a"><mrow id="S3.T3.13.13.1.m1.1.2" xref="S3.T3.13.13.1.m1.1.2.cmml"><mn id="S3.T3.13.13.1.m1.1.2.2" xref="S3.T3.13.13.1.m1.1.2.2.cmml">44.8</mn><mo id="S3.T3.13.13.1.m1.1.2.1" xref="S3.T3.13.13.1.m1.1.2.1.cmml">⁢</mo><mrow id="S3.T3.13.13.1.m1.1.2.3.2" xref="S3.T3.13.13.1.m1.1.2.cmml"><mo id="S3.T3.13.13.1.m1.1.2.3.2.1" stretchy="false" xref="S3.T3.13.13.1.m1.1.2.cmml">(</mo><mn id="S3.T3.13.13.1.m1.1.1" xref="S3.T3.13.13.1.m1.1.1.cmml">0.28</mn><mo id="S3.T3.13.13.1.m1.1.2.3.2.2" stretchy="false" xref="S3.T3.13.13.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T3.13.13.1.m1.1b"><apply id="S3.T3.13.13.1.m1.1.2.cmml" xref="S3.T3.13.13.1.m1.1.2"><times id="S3.T3.13.13.1.m1.1.2.1.cmml" xref="S3.T3.13.13.1.m1.1.2.1"></times><cn id="S3.T3.13.13.1.m1.1.2.2.cmml" type="float" xref="S3.T3.13.13.1.m1.1.2.2">44.8</cn><cn id="S3.T3.13.13.1.m1.1.1.cmml" type="float" xref="S3.T3.13.13.1.m1.1.1">0.28</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.13.13.1.m1.1c">44.8(0.28)</annotation><annotation encoding="application/x-llamapun" id="S3.T3.13.13.1.m1.1d">44.8 ( 0.28 )</annotation></semantics></math></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t" id="S3.T3.14.14.2" style="padding-left:0.0pt;padding-right:0.0pt;"><math alttext="46.6(0.27)" class="ltx_Math" display="inline" id="S3.T3.14.14.2.m1.1"><semantics id="S3.T3.14.14.2.m1.1a"><mrow id="S3.T3.14.14.2.m1.1.2" xref="S3.T3.14.14.2.m1.1.2.cmml"><mn id="S3.T3.14.14.2.m1.1.2.2" xref="S3.T3.14.14.2.m1.1.2.2.cmml">46.6</mn><mo id="S3.T3.14.14.2.m1.1.2.1" xref="S3.T3.14.14.2.m1.1.2.1.cmml">⁢</mo><mrow id="S3.T3.14.14.2.m1.1.2.3.2" xref="S3.T3.14.14.2.m1.1.2.cmml"><mo id="S3.T3.14.14.2.m1.1.2.3.2.1" stretchy="false" xref="S3.T3.14.14.2.m1.1.2.cmml">(</mo><mn id="S3.T3.14.14.2.m1.1.1" xref="S3.T3.14.14.2.m1.1.1.cmml">0.27</mn><mo id="S3.T3.14.14.2.m1.1.2.3.2.2" stretchy="false" xref="S3.T3.14.14.2.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T3.14.14.2.m1.1b"><apply id="S3.T3.14.14.2.m1.1.2.cmml" xref="S3.T3.14.14.2.m1.1.2"><times id="S3.T3.14.14.2.m1.1.2.1.cmml" xref="S3.T3.14.14.2.m1.1.2.1"></times><cn id="S3.T3.14.14.2.m1.1.2.2.cmml" type="float" xref="S3.T3.14.14.2.m1.1.2.2">46.6</cn><cn id="S3.T3.14.14.2.m1.1.1.cmml" type="float" xref="S3.T3.14.14.2.m1.1.1">0.27</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.14.14.2.m1.1c">46.6(0.27)</annotation><annotation encoding="application/x-llamapun" id="S3.T3.14.14.2.m1.1d">46.6 ( 0.27 )</annotation></semantics></math></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t" id="S3.T3.15.15.3" style="padding-left:0.0pt;padding-right:0.0pt;"><math alttext="46.1(0.42)" class="ltx_Math" display="inline" id="S3.T3.15.15.3.m1.1"><semantics id="S3.T3.15.15.3.m1.1a"><mrow id="S3.T3.15.15.3.m1.1.2" xref="S3.T3.15.15.3.m1.1.2.cmml"><mn id="S3.T3.15.15.3.m1.1.2.2" xref="S3.T3.15.15.3.m1.1.2.2.cmml">46.1</mn><mo id="S3.T3.15.15.3.m1.1.2.1" xref="S3.T3.15.15.3.m1.1.2.1.cmml">⁢</mo><mrow id="S3.T3.15.15.3.m1.1.2.3.2" xref="S3.T3.15.15.3.m1.1.2.cmml"><mo id="S3.T3.15.15.3.m1.1.2.3.2.1" stretchy="false" xref="S3.T3.15.15.3.m1.1.2.cmml">(</mo><mn id="S3.T3.15.15.3.m1.1.1" xref="S3.T3.15.15.3.m1.1.1.cmml">0.42</mn><mo id="S3.T3.15.15.3.m1.1.2.3.2.2" stretchy="false" xref="S3.T3.15.15.3.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T3.15.15.3.m1.1b"><apply id="S3.T3.15.15.3.m1.1.2.cmml" xref="S3.T3.15.15.3.m1.1.2"><times id="S3.T3.15.15.3.m1.1.2.1.cmml" xref="S3.T3.15.15.3.m1.1.2.1"></times><cn id="S3.T3.15.15.3.m1.1.2.2.cmml" type="float" xref="S3.T3.15.15.3.m1.1.2.2">46.1</cn><cn id="S3.T3.15.15.3.m1.1.1.cmml" type="float" xref="S3.T3.15.15.3.m1.1.1">0.42</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.15.15.3.m1.1c">46.1(0.42)</annotation><annotation encoding="application/x-llamapun" id="S3.T3.15.15.3.m1.1d">46.1 ( 0.42 )</annotation></semantics></math></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Ablation studies on different roles and numbers of experts. <span class="ltx_text ltx_font_bold" id="S3.T3.22.1">GLM</span>: GLM-4 without RAM2C; <span class="ltx_text ltx_font_bold" id="S3.T3.23.2">GLM-R</span>: GLM-4 with full RAM2C; <span class="ltx_text ltx_font_bold" id="S3.T3.24.3">GLM-P/R</span>: GLM-R without P-Group; <span class="ltx_text ltx_font_bold" id="S3.T3.25.4">GLM-E/R</span>: GLM-R without E-Group; <span class="ltx_text ltx_font_bold" id="S3.T3.26.5">GLM-PE/R</span>: GLM-R without P-Group and E-Group; <span class="ltx_text ltx_font_bold" id="S3.T3.27.6">GLM-R/1</span>: GLM-R with only one expert in each group/role.</figcaption>
</figure>
<section class="ltx_paragraph" id="S3.SS4.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Ablation studies.</h4>
<div class="ltx_para" id="S3.SS4.SSS0.Px1.p1">
<p class="ltx_p" id="S3.SS4.SSS0.Px1.p1.1">We conducted ablation experiments to explore the impact of different roles and the number of experts on dialogue quality, as shown in Tab. <a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#S3.T3" title="Table 3 ‣ 3.4 Evaluation Results ‣ 3 Experiments ‣ RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented Multi-role Multi-expert Collaboration"><span class="ltx_text ltx_ref_tag">3</span></a>. RAM2C based GLM-4 models excluding the P-Group and/or E-Group result in varying degrees of performance decline in the dimensions of <span class="ltx_text ltx_font_bold" id="S3.SS4.SSS0.Px1.p1.1.1">humanized communication</span> and <span class="ltx_text ltx_font_bold" id="S3.SS4.SSS0.Px1.p1.1.2">safety &amp; ethics</span>. However, the exclusion of the E-Group has a relatively limited impact on <span class="ltx_text ltx_font_bold" id="S3.SS4.SSS0.Px1.p1.1.3">safety &amp; ethics</span>. We interpret this as general LLMs typically being well-aligned with human preferences and possessing basic ethical and safety qualities. Therefore, the collaboration of the T-Group and P-Group mitigates the performance decline caused by the absence of the E-Group. We also explored the difference in dialogue quality between one expert per group and three experts per group, and the results indicate that in-group collaboration is quite necessary.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S3.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.5 </span>Case Study</h3>
<div class="ltx_para" id="S3.SS5.p1">
<p class="ltx_p" id="S3.SS5.p1.1">A well organized response is shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#A3.F5" title="Figure 5 ‣ Appendix C Multi-source knowledge base ‣ RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented Multi-role Multi-expert Collaboration"><span class="ltx_text ltx_ref_tag">5</span></a> generated by the fine-tuned Qwen model. The response includes personalized emotional support and encouragements, as long as the assessment to the specific content of the student, comparing with the response of untrained version.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Conclusion</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">To address the <span class="ltx_text ltx_font_bold" id="S4.p1.1.1">HTS</span> challenges of deploying LLMs for high-quality liberal arts educational dialogues, we propose RAM2C, a framework based on retrieval-augmented multi-role multi-expert collaboration to automatically generate high-quality dialogues for model fine-tuning. We conduct experiments in a literature discussion scenario. Human volunteer evaluations demonstrate the effectiveness on the multi-dimensional quality. In shorts, this work highlights the potential of LLM (especially lightweight models) in liberal arts educational dialogues by arousing its intrinsic role-playing and collaborating capability and extrinsic capability.</p>
</div>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Limitations</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">We fine-tune and evaluate as many models as possible, but the number is still limited. Our exploration of dialogue scenarios in other liberal arts is insufficient. The design of prompt templates may affect the performance of LLMs, but due to time constraints, we are unable to test all variants of the templates. We will test the effectiveness of the system in other language (such as English). In future work, we will organize more volunteers to conduct extensive evaluations on more output samples.</p>
</div>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_title_section">Ethical Statement</h2>
<div class="ltx_para" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1">The educational resources we collected online are obtained legally, and the collection process do not involve any personal privacy. We will not disclose any personal information without the consent of the individuals concerned. We have ensured the security and reliability of the aforementioned resources. We examined datasets generated and used in the research, which do not contain any discriminatory characteristics, including but not limited to age, gender, race, nationality, and religion. The output of the language model does not contain any personal privacy information or other inappropriate content. All volunteers participating in the evaluation experiments do so with informed consent, fully understanding the purpose and potential impact of their participation.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Asai et al. (2023)</span>
<span class="ltx_bibblock">
Akari Asai, Zeqiu Wu, Yizhong Wang, Avirup Sil, and Hannaneh Hajishirzi. 2023.

</span>
<span class="ltx_bibblock">Self-rag: Learning to retrieve, generate, and critique through self-reflection.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">arXiv preprint arXiv:2310.11511</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bai et al. (2023)</span>
<span class="ltx_bibblock">
Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong Deng, Yang Fan, Wenbin Ge, Yu Han, Fei Huang, Binyuan Hui, Luo Ji, Mei Li, Junyang Lin, Runji Lin, Dayiheng Liu, Gao Liu, Chengqiang Lu, Keming Lu, Jianxin Ma, Rui Men, Xingzhang Ren, Xuancheng Ren, Chuanqi Tan, Sinan Tan, Jianhong Tu, Peng Wang, Shijie Wang, Wei Wang, Shengguang Wu, Benfeng Xu, Jin Xu, An Yang, Hao Yang, Jian Yang, Shusheng Yang, Yang Yao, Bowen Yu, Hongyi Yuan, Zheng Yuan, Jianwei Zhang, Xingxuan Zhang, Yichang Zhang, Zhenru Zhang, Chang Zhou, Jingren Zhou, Xiaohuan Zhou, and Tianhang Zhu. 2023.

</span>
<span class="ltx_bibblock">Qwen technical report.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">arXiv preprint arXiv:2309.16609</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Baladón et al. (2023)</span>
<span class="ltx_bibblock">
Alexis Baladón, Ignacio Sastre, Luis Chiruzzo, and Aiala Rosá. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.bea-1.61" title="">RETUYT-InCo at BEA 2023 shared task: Tuning open-source LLMs for generating teacher responses</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">Proceedings of the 18th Workshop on Innovative Use of NLP for Building Educational Applications (BEA 2023)</em>, pages 756–765, Toronto, Canada. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Besta et al. (2023)</span>
<span class="ltx_bibblock">
Maciej Besta, Nils Blach, Ales Kubicek, Robert Gerstenberger, Lukas Gianinazzi, Joanna Gajda, Tomasz Lehmann, Michal Podstawski, Hubert Niewiadomski, Piotr Nyczyk, et al. 2023.

</span>
<span class="ltx_bibblock">Graph of thoughts: Solving elaborate problems with large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">arXiv preprint arXiv:2308.09687</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2024)</span>
<span class="ltx_bibblock">
Jianlv Chen, Shitao Xiao, Peitian Zhang, Kun Luo, Defu Lian, and Zheng Liu. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2402.03216" title="">Bge m3-embedding: Multi-lingual, multi-functionality, multi-granularity text embeddings through self-knowledge distillation</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">Preprint</em>, arXiv:2402.03216.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2023)</span>
<span class="ltx_bibblock">
Yulin Chen, Ning Ding, Hai-Tao Zheng, Zhiyuan Liu, Maosong Sun, and Bowen Zhou. 2023.

</span>
<span class="ltx_bibblock">Empowering private tutoring by chaining large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">arXiv preprint arXiv:2309.08112</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dan et al. (2023)</span>
<span class="ltx_bibblock">
Yuhao Dan, Zhikai Lei, Yiyang Gu, Yong Li, Jianghao Yin, Jiaju Lin, Linhao Ye, Zhiyan Tie, Yougen Zhou, Yilei Wang, et al. 2023.

</span>
<span class="ltx_bibblock">Educhat: A large-scale language model-based chatbot system for intelligent education.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">arXiv preprint arXiv:2308.02773</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Deng et al. (2023)</span>
<span class="ltx_bibblock">
Yang Deng, Zifeng Ren, An Zhang, Wenqiang Lei, and Tat-Seng Chua. 2023.

</span>
<span class="ltx_bibblock">Towards goal-oriented intelligent tutoring systems in online education.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">arXiv preprint arXiv:2312.10053</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Du et al. (2022)</span>
<span class="ltx_bibblock">
Zhengxiao Du, Yujie Qian, Xiao Liu, Ming Ding, Jiezhong Qiu, Zhilin Yang, and Jie Tang. 2022.

</span>
<span class="ltx_bibblock">Glm: General language model pretraining with autoregressive blank infilling.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pages 320–335.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao et al. (2023)</span>
<span class="ltx_bibblock">
Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, Jiawei Sun, and Haofen Wang. 2023.

</span>
<span class="ltx_bibblock">Retrieval-augmented generation for large language models: A survey.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">arXiv preprint arXiv:2312.10997</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hicke et al. (2023)</span>
<span class="ltx_bibblock">
Yann Hicke, Abhishek Masand, Wentao Guo, and Tushaar Gangavarapu. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2307.04274" title="">Assessing the efficacy of large language models in generating accurate teacher responses</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">Preprint</em>, arXiv:2307.04274.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et al. (2024)</span>
<span class="ltx_bibblock">
Shengding Hu, Yuge Tu, Xu Han, Chaoqun He, Ganqu Cui, Xiang Long, Zhi Zheng, Yewei Fang, Yuxiang Huang, Weilin Zhao, et al. 2024.

</span>
<span class="ltx_bibblock">Minicpm: Unveiling the potential of small language models with scalable training strategies.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">arXiv preprint arXiv:2404.06395</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huber et al. (2023)</span>
<span class="ltx_bibblock">
Thomas Huber, Christina Niklaus, and Siegfried Handschuh. 2023.

</span>
<span class="ltx_bibblock">Enhancing educational dialogues: A reinforcement learning approach for generating ai teacher responses.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">Proceedings of the 18th Workshop on Innovative Use of NLP for Building Educational Applications (BEA 2023)</em>, pages 736–744.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ji et al. (2023)</span>
<span class="ltx_bibblock">
Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii, Ye Jin Bang, Andrea Madotto, and Pascale Fung. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1145/3571730" title="">Survey of hallucination in natural language generation</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">ACM Comput. Surv.</em>, 55(12).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kuhail et al. (2023)</span>
<span class="ltx_bibblock">
Mohammad Amin Kuhail, Nazik Alturki, Salwa Alramlawi, and Kholood Alhejori. 2023.

</span>
<span class="ltx_bibblock">Interacting with educational chatbots: A systematic review.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">Education and Information Technologies</em>, 28(1):973–1018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2023)</span>
<span class="ltx_bibblock">
Qingyao Li, Lingyue Fu, Weiming Zhang, Xianyu Chen, Jingwei Yu, Wei Xia, Weinan Zhang, Ruiming Tang, and Yong Yu. 2023.

</span>
<span class="ltx_bibblock">Adapting large language models for education: Foundational capabilities, potentials, and challenges.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">arXiv preprint arXiv:2401.08664</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Long et al. (2024)</span>
<span class="ltx_bibblock">
Yun Long, Haifeng Luo, and Yu Zhang. 2024.

</span>
<span class="ltx_bibblock">Evaluating large language models in analysing classroom dialogue.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">arXiv preprint arXiv:2402.02380</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lu et al. (2024)</span>
<span class="ltx_bibblock">
Keming Lu, Bowen Yu, Chang Zhou, and Jingren Zhou. 2024.

</span>
<span class="ltx_bibblock">Large language models are superpositions of all characters: Attaining arbitrary role-play via self-alignment.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">arXiv preprint arXiv:2401.12474</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ma et al. (2023)</span>
<span class="ltx_bibblock">
Xinbei Ma, Yeyun Gong, Pengcheng He, Hai Zhao, and Nan Duan. 2023.

</span>
<span class="ltx_bibblock">Query rewriting for retrieval-augmented large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">arXiv preprint arXiv:2305.14283</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Macina et al. (2023)</span>
<span class="ltx_bibblock">
Jakub Macina, Nico Daheim, Lingzhi Wang, Tanmay Sinha, Manu Kapur, Iryna Gurevych, and Mrinmaya Sachan. 2023.

</span>
<span class="ltx_bibblock">Opportunities and challenges in neural dialog tutoring.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">arXiv preprint arXiv:2301.09919</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Markel et al. (2023)</span>
<span class="ltx_bibblock">
Julia M Markel, Steven G Opferman, James A Landay, and Chris Piech. 2023.

</span>
<span class="ltx_bibblock">Gpteach: Interactive ta training with gpt-based students.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">Proceedings of the tenth acm conference on learning@ scale</em>, pages 226–236.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">NetEase Youdao (2023)</span>
<span class="ltx_bibblock">
Inc. NetEase Youdao. 2023.

</span>
<span class="ltx_bibblock">Bcembedding: Bilingual and crosslingual embedding for rag.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/netease-youdao/BCEmbedding" title="">https://github.com/netease-youdao/BCEmbedding</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nori et al. (2023)</span>
<span class="ltx_bibblock">
Harsha Nori, Yin Tat Lee, Sheng Zhang, Dean Carignan, Richard Edgar, Nicolo Fusi, Nicholas King, Jonathan Larson, Yuanzhi Li, Weishung Liu, et al. 2023.

</span>
<span class="ltx_bibblock">Can generalist foundation models outcompete special-purpose tuning? case study in medicine.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">arXiv preprint arXiv:2311.16452</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ouyang et al. (2022)</span>
<span class="ltx_bibblock">
Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. 2022.

</span>
<span class="ltx_bibblock">Training language models to follow instructions with human feedback.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">Advances in neural information processing systems</em>, 35:27730–27744.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rafailov et al. (2023)</span>
<span class="ltx_bibblock">
Rafael Rafailov, Archit Sharma, Eric Mitchell, Stefano Ermon, Christopher D Manning, and Chelsea Finn. 2023.

</span>
<span class="ltx_bibblock">Direct preference optimization: Your language model is secretly a reward model.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">arXiv preprint arXiv:2305.18290</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sarthi et al. (2024)</span>
<span class="ltx_bibblock">
Parth Sarthi, Salman Abdullah, Aditi Tuli, Shubh Khanna, Anna Goldie, and Christopher D. Manning. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2401.18059" title="">Raptor: Recursive abstractive processing for tree-organized retrieval</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">Preprint</em>, arXiv:2401.18059.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et al. (2023)</span>
<span class="ltx_bibblock">
Hao Sun, Zhexin Zhang, Jiawen Deng, Jiale Cheng, and Minlie Huang. 2023.

</span>
<span class="ltx_bibblock">Safety assessment of chinese large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">arXiv preprint arXiv:2304.10436</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Suzgun and Kalai (2024)</span>
<span class="ltx_bibblock">
Mirac Suzgun and Adam Tauman Kalai. 2024.

</span>
<span class="ltx_bibblock">Meta-prompting: Enhancing language models with task-agnostic scaffolding.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">arXiv preprint arXiv:2401.12954</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tack et al. (2023)</span>
<span class="ltx_bibblock">
Anaïs Tack, Ekaterina Kochmar, Zheng Yuan, Serge Bibauw, and Chris Piech. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.bea-1.64" title="">The BEA 2023 shared task on generating AI teacher responses in educational dialogues</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">Proceedings of the 18th Workshop on Innovative Use of NLP for Building Educational Applications (BEA 2023)</em>, pages 785–795, Toronto, Canada. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tang et al. (2023)</span>
<span class="ltx_bibblock">
Xiangru Tang, Anni Zou, Zhuosheng Zhang, Yilun Zhao, Xingyao Zhang, Arman Cohan, and Mark Gerstein. 2023.

</span>
<span class="ltx_bibblock">Medagents: Large language models as collaborators for zero-shot medical reasoning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">arXiv preprint arXiv:2311.10537</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2024)</span>
<span class="ltx_bibblock">
Shen Wang, Tianlong Xu, Hang Li, Chaoli Zhang, Joleen Liang, Jiliang Tang, Philip S Yu, and Qingsong Wen. 2024.

</span>
<span class="ltx_bibblock">Large language models for education: A survey and outlook.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">arXiv preprint arXiv:2403.18105</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2022)</span>
<span class="ltx_bibblock">
Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdhery, and Denny Zhou. 2022.

</span>
<span class="ltx_bibblock">Self-consistency improves chain of thought reasoning in language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">arXiv preprint arXiv:2203.11171</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2023a)</span>
<span class="ltx_bibblock">
Zekun Moore Wang, Zhongyuan Peng, Haoran Que, Jiaheng Liu, Wangchunshu Zhou, Yuhan Wu, Hongcheng Guo, Ruitong Gan, Zehao Ni, Man Zhang, et al. 2023a.

</span>
<span class="ltx_bibblock">Rolellm: Benchmarking, eliciting, and enhancing role-playing abilities of large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">arXiv preprint arXiv:2310.00746</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2023b)</span>
<span class="ltx_bibblock">
Zhenhailong Wang, Shaoguang Mao, Wenshan Wu, Tao Ge, Furu Wei, and Heng Ji. 2023b.

</span>
<span class="ltx_bibblock">Unleashing cognitive synergy in large language models: A task-solving agent through multi-persona selfcollaboration.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">arXiv preprint arXiv:2307.05300</em>, 1(2):3.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et al. (2022)</span>
<span class="ltx_bibblock">
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. 2022.

</span>
<span class="ltx_bibblock">Chain-of-thought prompting elicits reasoning in large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">Advances in Neural Information Processing Systems</em>, 35:24824–24837.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yan et al. (2024)</span>
<span class="ltx_bibblock">
Shi-Qi Yan, Jia-Chen Gu, Yun Zhu, and Zhen-Hua Ling. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2401.15884" title="">Corrective retrieval augmented generation</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">Preprint</em>, arXiv:2401.15884.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yuan et al. (2023)</span>
<span class="ltx_bibblock">
Zheng Yuan, Hongyi Yuan, Chengpeng Li, Guanting Dong, Keming Lu, Chuanqi Tan, Chang Zhou, and Jingren Zhou. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2308.01825" title="">Scaling relationship on learning mathematical reasoning with large language models</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">Preprint</em>, arXiv:2308.01825.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2023a)</span>
<span class="ltx_bibblock">
Liwen Zhang, Weige Cai, Zhaowei Liu, Zhi Yang, Wei Dai, Yujie Liao, Qianru Qin, Yifei Li, Xingyu Liu, Zhiqiang Liu, Zhoufan Zhu, Anbo Wu, Xin Guo, and Yun Chen. 2023a.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2308.09975" title="">Fineval: A chinese financial domain knowledge evaluation benchmark for large language models</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">Preprint</em>, arXiv:2308.09975.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2024)</span>
<span class="ltx_bibblock">
Shengyu Zhang, Linfeng Dong, Xiaoya Li, Sen Zhang, Xiaofei Sun, Shuhe Wang, Jiwei Li, Runyi Hu, Tianwei Zhang, Fei Wu, and Guoyin Wang. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2308.10792" title="">Instruction tuning for large language models: A survey</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">Preprint</em>, arXiv:2308.10792.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2023b)</span>
<span class="ltx_bibblock">
Yue Zhang, Yafu Li, Leyang Cui, Deng Cai, Lemao Liu, Tingchen Fu, Xinting Huang, Enbo Zhao, Yu Zhang, Yulong Chen, et al. 2023b.

</span>
<span class="ltx_bibblock">Siren’s song in the ai ocean: a survey on hallucination in large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">arXiv preprint arXiv:2309.01219</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zheng et al. (2024)</span>
<span class="ltx_bibblock">
Yaowei Zheng, Richong Zhang, Junhao Zhang, Yanhan Ye, Zheyan Luo, and Yongqiang Ma. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2403.13372" title="">Llamafactory: Unified efficient fine-tuning of 100+ language models</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib41.1.1">arXiv preprint arXiv:2403.13372</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et al. (2023)</span>
<span class="ltx_bibblock">
Jinfeng Zhou, Zhuang Chen, Dazhen Wan, Bosi Wen, Yi Song, Jifan Yu, Yongkang Huang, Libiao Peng, Jiaming Yang, Xiyao Xiao, et al. 2023.

</span>
<span class="ltx_bibblock">Characterglm: Customizing chinese conversational ai characters with large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1">arXiv preprint arXiv:2311.16832</em>.

</span>
</li>
</ul>
</section>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Related Work</h2>
<div class="ltx_para" id="A1.p1">
<p class="ltx_p" id="A1.p1.1">Recent studies have proposed technical strategies such as prompt engineering, retrieval augmented generation (RAG) and human preference alignments <cite class="ltx_cite ltx_citemacro_citep">(Wei et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#bib.bib35" title="">2022</a>; Asai et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#bib.bib1" title="">2023</a>; Rafailov et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#bib.bib25" title="">2023</a>; Zhang et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#bib.bib39" title="">2024</a>; Ouyang et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#bib.bib24" title="">2022</a>)</cite>. But these techniques face challenges including instruction following, retrieval accuracy and high value preference construction respectively. Consequently, edge-deployed models for professional education dialogue need an integrated systemic approach that includes data collection, model inference, and fine-tuning to address the aforementioned challenges (<span class="ltx_text ltx_font_bold" id="A1.p1.1.1">HTS</span>), as a single technological path is not sufficient.</p>
</div>
<section class="ltx_subsection" id="A1.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.1 </span>Educational chatbots</h3>
<div class="ltx_para" id="A1.SS1.p1">
<p class="ltx_p" id="A1.SS1.p1.1">Educational chatbots, focusing on individualized guidance <cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#bib.bib6" title="">2023</a>)</cite> and educational resource optimization <cite class="ltx_cite ltx_citemacro_citep">(Deng et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#bib.bib8" title="">2023</a>)</cite>, have been thoroughly explored. These systems, often powered by LLMs, play a supportive role by delivering exercises, recommending resources, training teachers, and tracking student progress<cite class="ltx_cite ltx_citemacro_citep">(Dan et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#bib.bib7" title="">2023</a>; Markel et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#bib.bib21" title="">2023</a>)</cite>. Despite their contributions, they typically feature limited dialogue openness<cite class="ltx_cite ltx_citemacro_citep">(Macina et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#bib.bib20" title="">2023</a>)</cite> and have not extensively addressed the complex challenges of higher-level educational standards which face <span class="ltx_text ltx_font_bold" id="A1.SS1.p1.1.1">HTS</span> challenge <cite class="ltx_cite ltx_citemacro_citep">(Kuhail et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#bib.bib15" title="">2023</a>)</cite>.</p>
</div>
</section>
<section class="ltx_subsection" id="A1.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.2 </span>Prompt engineering</h3>
<div class="ltx_para" id="A1.SS2.p1">
<p class="ltx_p" id="A1.SS2.p1.1">Prompt engineering techniques are well explored recently to enhance reasoning capability and role-playing ability of LLMs <cite class="ltx_cite ltx_citemacro_citep">(Wei et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#bib.bib35" title="">2022</a>)</cite> by showing few-shot examples, visualizing thought steps (Chain of Thought, CoT) <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#bib.bib32" title="">2022</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#bib.bib34" title="">2023b</a>; Besta et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#bib.bib4" title="">2023</a>; Tang et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#bib.bib30" title="">2023</a>)</cite>, assigning specific personas <cite class="ltx_cite ltx_citemacro_citep">(Nori et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#bib.bib23" title="">2023</a>; Lu et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#bib.bib18" title="">2024</a>; Wang et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#bib.bib33" title="">2023a</a>; Zhou et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#bib.bib42" title="">2023</a>)</cite> and organizing multi-agent collaborations<cite class="ltx_cite ltx_citemacro_citep">(Suzgun and Kalai, <a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#bib.bib28" title="">2024</a>)</cite>. However, the instruction-following ability of lightweight models often falls short of advanced LLMs like GPT-4, thus limiting the practical effect of prompt engineering <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#bib.bib39" title="">2024</a>; Yuan et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#bib.bib37" title="">2023</a>)</cite>.</p>
</div>
</section>
<section class="ltx_subsection" id="A1.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.3 </span>Retrieval augmented generation</h3>
<div class="ltx_para" id="A1.SS3.p1">
<p class="ltx_p" id="A1.SS3.p1.1">Recent studies about RAG <cite class="ltx_cite ltx_citemacro_citep">(Gao et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#bib.bib10" title="">2023</a>)</cite> aim at addressing the lack of domain-specific factual knowledge and alleviating model hallucinations <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#bib.bib40" title="">2023b</a>; Ji et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#bib.bib14" title="">2023</a>)</cite> by re-writing retrieval queries <cite class="ltx_cite ltx_citemacro_citep">(Ma et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#bib.bib19" title="">2023</a>)</cite>, executing self-reflection <cite class="ltx_cite ltx_citemacro_citep">(Asai et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#bib.bib1" title="">2023</a>; Yan et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#bib.bib36" title="">2024</a>)</cite> and constructing a tree with differing levels of knowledge <cite class="ltx_cite ltx_citemacro_citep">(Sarthi et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#bib.bib26" title="">2024</a>)</cite>, which perform well in factual knowledge QA tasks. These studies are based on deep sentence embedding models <cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#bib.bib5" title="">2024</a>)</cite>, which filter relevant documents by comparing distances between two documents in semantic vector space. These retrieval methods based on vector semantic space matching struggle to effectively retrieve documents of high educational reference value. This is due to the following reasons: <span class="ltx_text ltx_font_bold" id="A1.SS3.p1.1.1">1) Shallow semantic matching</span>: sentence embedding models primarily focus on the combination patterns of phrases and word in the training corpus, performing poorly on complex structures and long texts <cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#bib.bib5" title="">2024</a>; NetEase Youdao, <a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#bib.bib22" title="">2023</a>)</cite>; <span class="ltx_text ltx_font_bold" id="A1.SS3.p1.1.2">2) Diversity of reference value</span>: the reference value of educational documents lies not only in providing accurate and factual knowledge but also in the expression style, word collocation, sentence structure, emotional feedback, and writing logic. These patterns are difficult to be captured through embedding models.</p>
</div>
</section>
<section class="ltx_subsection" id="A1.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.4 </span>Human preference alignment on education</h3>
<div class="ltx_para" id="A1.SS4.p1">
<p class="ltx_p" id="A1.SS4.p1.1">Researchers have built specialized fine-tuning datasets to trigger the model’s ability in specific domains <cite class="ltx_cite ltx_citemacro_citep">(Dan et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#bib.bib7" title="">2023</a>; Zhang et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#bib.bib38" title="">2023a</a>)</cite>. However, the high degree of individualization and diversity in educational scenarios poses challenges to collecting high-quality data <cite class="ltx_cite ltx_citemacro_citep">(Hicke et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#bib.bib11" title="">2023</a>; Long et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#bib.bib17" title="">2024</a>)</cite>. Recently, BEA 2023 dataset and several related fine-tuning studies are proposed to enhance teaching ability of LLMs, which is sampled from Teacher-Student Chatroom Corpus for only English learning <cite class="ltx_cite ltx_citemacro_citep">(Tack et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#bib.bib29" title="">2023</a>; Huber et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#bib.bib13" title="">2023</a>; Baladón et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#bib.bib3" title="">2023</a>)</cite>. And the samples are quite short (~100 tokens) which hinder the profundity and complexity of dialogues. Therefore, we need to construct an educational dialogue scenario that is more specific in discussion topics but also fairly open-ended and useful for different languages.</p>
</div>
<div class="ltx_para" id="A1.SS4.p2">
<p class="ltx_p" id="A1.SS4.p2.1">Consequently, edge-deployed models for education need an integrated systemic approach that includes data collection, model inference, and model fine-tuning to address the <span class="ltx_text ltx_font_bold" id="A1.SS4.p2.1.1">HTS</span> challenges in Fig.<a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented Multi-role Multi-expert Collaboration"><span class="ltx_text ltx_ref_tag">1</span></a>, as a single technological path is not sufficient.</p>
</div>
</section>
</section>
<section class="ltx_appendix" id="A2">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span><span class="ltx_text ltx_font_bold" id="A2.1.1">HTS</span>: multi-dimensional challenge for educational dialogue</h2>
<div class="ltx_para" id="A2.p1">
<p class="ltx_p" id="A2.p1.1">We have summarized three dimensions for evaluating liberal arts educational dialogue: humanized communication, teaching expertise, and safety &amp; ethics.</p>
</div>
<section class="ltx_subsection" id="A2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.1 </span>Humanized communication</h3>
<section class="ltx_paragraph" id="A2.SS1.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Cultural competence:</h4>
<div class="ltx_para" id="A2.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="A2.SS1.SSS0.Px1.p1.1">The system should understand and respect diverse cultural backgrounds, enabling effective and inclusive communication.</p>
</div>
</section>
<section class="ltx_paragraph" id="A2.SS1.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Active supportiveness:</h4>
<div class="ltx_para" id="A2.SS1.SSS0.Px2.p1">
<p class="ltx_p" id="A2.SS1.SSS0.Px2.p1.1">It should provide encouragement and positive reinforcement, fostering a supportive learning environment for users.</p>
</div>
</section>
<section class="ltx_paragraph" id="A2.SS1.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Emotional feedback:</h4>
<div class="ltx_para" id="A2.SS1.SSS0.Px3.p1">
<p class="ltx_p" id="A2.SS1.SSS0.Px3.p1.1">The system should recognize and respond to users’ emotional states, enhancing engagement and connection.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="A2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.2 </span>Teaching expertise</h3>
<section class="ltx_paragraph" id="A2.SS2.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Assessment proficiency:</h4>
<div class="ltx_para" id="A2.SS2.SSS0.Px1.p1">
<p class="ltx_p" id="A2.SS2.SSS0.Px1.p1.1">The system should effectively evaluate user performance and understanding, providing meaningful feedback for improvement.</p>
</div>
</section>
<section class="ltx_paragraph" id="A2.SS2.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Subject mastery:</h4>
<div class="ltx_para" id="A2.SS2.SSS0.Px2.p1">
<p class="ltx_p" id="A2.SS2.SSS0.Px2.p1.1">It must possess in-depth knowledge of various subjects, ensuring accurate and relevant information is conveyed.</p>
</div>
</section>
<section class="ltx_paragraph" id="A2.SS2.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Pedagogical skills:</h4>
<div class="ltx_para" id="A2.SS2.SSS0.Px3.p1">
<p class="ltx_p" id="A2.SS2.SSS0.Px3.p1.1">The system should employ effective teaching strategies, adapting to different learning styles and needs.</p>
</div>
</section>
<section class="ltx_paragraph" id="A2.SS2.SSS0.Px4">
<h4 class="ltx_title ltx_title_paragraph">Accurate response:</h4>
<div class="ltx_para" id="A2.SS2.SSS0.Px4.p1">
<p class="ltx_p" id="A2.SS2.SSS0.Px4.p1.1">It should deliver precise and reliable answers to user inquiries, promoting trust and credibility.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="A2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.3 </span>Safety and ethics</h3>
<section class="ltx_paragraph" id="A2.SS3.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Data privacy:</h4>
<div class="ltx_para" id="A2.SS3.SSS0.Px1.p1">
<p class="ltx_p" id="A2.SS3.SSS0.Px1.p1.1">The system must protect user data, ensuring confidentiality and compliance with relevant privacy regulations.</p>
</div>
</section>
<section class="ltx_paragraph" id="A2.SS3.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Content appropriateness:</h4>
<div class="ltx_para" id="A2.SS3.SSS0.Px2.p1">
<p class="ltx_p" id="A2.SS3.SSS0.Px2.p1.1">It should filter and provide content that is suitable for the intended audience, avoiding harmful or offensive material.</p>
</div>
</section>
<section class="ltx_paragraph" id="A2.SS3.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Abuse prevention:</h4>
<div class="ltx_para" id="A2.SS3.SSS0.Px3.p1">
<p class="ltx_p" id="A2.SS3.SSS0.Px3.p1.1">The system must have mechanisms in place to identify and prevent abusive interactions, ensuring a safe experience for all users.</p>
</div>
</section>
</section>
</section>
<section class="ltx_appendix" id="A3">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Multi-source knowledge base</h2>
<div class="ltx_para" id="A3.p1">
<p class="ltx_p" id="A3.p1.1">We establish a multi-source knowledge base to support the multi-role multi-expert collaboration, based on Chromadb<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/chroma-core/chroma" title="">https://github.com/chroma-core/chroma</a></span></span></span> and the sentence embedding model BGE-m3<cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#bib.bib5" title="">2024</a>)</cite>. The knowledge base includes the following sources of knowledge:</p>
</div>
<div class="ltx_para" id="A3.p2">
<ol class="ltx_enumerate" id="A3.I1">
<li class="ltx_item" id="A3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="A3.I1.i1.p1">
<p class="ltx_p" id="A3.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="A3.I1.i1.p1.1.1">Class dialogue records.</span> Records are derived from Chinese transcripts obtained through audio transcription and text proofreading from videos of public classes. These records demonstrate different teaching styles and responses that adhere to educational standards.</p>
</div>
</li>
<li class="ltx_item" id="A3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="A3.I1.i2.p1">
<p class="ltx_p" id="A3.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="A3.I1.i2.p1.1.1">Theories and research papers on Chinese language teaching.</span> It includes general theories of Chinese language teaching, theories of reading teaching and case analyses.</p>
</div>
</li>
<li class="ltx_item" id="A3.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="A3.I1.i3.p1">
<p class="ltx_p" id="A3.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="A3.I1.i3.p1.1.1">Theories and case analyses in educational psychology.</span></p>
</div>
</li>
<li class="ltx_item" id="A3.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span>
<div class="ltx_para" id="A3.I1.i4.p1">
<p class="ltx_p" id="A3.I1.i4.p1.1"><span class="ltx_text ltx_font_bold" id="A3.I1.i4.p1.1.1">Safety prompts.</span> Sensitive prompts for educational scenarios and corresponding safe responses. We use GLM-4-Flash to filter and rewrite seven types of malicious prompts and their appropriate responses from <cite class="ltx_cite ltx_citemacro_citet">Sun et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#bib.bib27" title="">2023</a>)</cite>, including crimes and illegal activities, ethics and morality, insult, mental health, physical harm, privacy and property, unfairness and discrimination, for reference by cultural safety experts.</p>
</div>
</li>
<li class="ltx_item" id="A3.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">5.</span>
<div class="ltx_para" id="A3.I1.i5.p1">
<p class="ltx_p" id="A3.I1.i5.p1.1"><span class="ltx_text ltx_font_bold" id="A3.I1.i5.p1.1.1">literature works in Chinese.</span> These texts support discussions involving the original plots of literary works.</p>
</div>
</li>
</ol>
</div>
<figure class="ltx_table" id="A3.T4">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A3.T4.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A3.T4.1.1.1">
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_t" id="A3.T4.1.1.1.1" style="padding-left:0.0pt;padding-right:0.0pt;"><span class="ltx_text ltx_font_bold" id="A3.T4.1.1.1.1.1">Source</span></th>
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_t" id="A3.T4.1.1.1.2" style="padding-left:0.0pt;padding-right:0.0pt;"><span class="ltx_text ltx_font_bold" id="A3.T4.1.1.1.2.1">Counts</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A3.T4.1.2.1">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_t" id="A3.T4.1.2.1.1" style="padding-left:0.0pt;padding-right:0.0pt;">Dialogue records</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_t" id="A3.T4.1.2.1.2" style="padding-left:0.0pt;padding-right:0.0pt;">1,688,000 words</td>
</tr>
<tr class="ltx_tr" id="A3.T4.1.3.2">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="A3.T4.1.3.2.1" style="padding-left:0.0pt;padding-right:0.0pt;">Educational theories</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="A3.T4.1.3.2.2" style="padding-left:0.0pt;padding-right:0.0pt;">3,770,000 words</td>
</tr>
<tr class="ltx_tr" id="A3.T4.1.4.3">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="A3.T4.1.4.3.1" style="padding-left:0.0pt;padding-right:0.0pt;">Literature works</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="A3.T4.1.4.3.2" style="padding-left:0.0pt;padding-right:0.0pt;">207,800 words</td>
</tr>
<tr class="ltx_tr" id="A3.T4.1.5.4">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="A3.T4.1.5.4.1" style="padding-left:0.0pt;padding-right:0.0pt;">Edu-psycho theories</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="A3.T4.1.5.4.2" style="padding-left:0.0pt;padding-right:0.0pt;">2,672,000 words</td>
</tr>
<tr class="ltx_tr" id="A3.T4.1.6.5">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_b" id="A3.T4.1.6.5.1" style="padding-left:0.0pt;padding-right:0.0pt;">Safety prompts</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_b" id="A3.T4.1.6.5.2" style="padding-left:0.0pt;padding-right:0.0pt;">13,893,188 words</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>Summary of counts in Chinese character across different knowledge sources.</figcaption>
</figure>
<figure class="ltx_figure" id="A3.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="467" id="A3.F5.g1" src="x4.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>A well structured response by the fine-tuned Qwen1.5-4B model and some negative cases generated by traditional LLMs. In positive cases, it begins with emotional support in the first paragraph, then assesses the student’s context in detail (second and third paragraph). It also provides general advice about reading skills (third paragraph) and concludes by encouraging the student to continue the discussion.
</figcaption>
</figure>
</section>
<section class="ltx_appendix" id="A4">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>Evaluation dataset and criteria</h2>
<div class="ltx_para" id="A4.p1">
<p class="ltx_p" id="A4.p1.1">We generate a dialogue set for evaluation of each fine-tuned model. The structure of the dialogue set is same as the fine-tuning dataset in Section<a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#S3.SS2" title="3.2 Model Fine-tuning ‣ 3 Experiments ‣ RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented Multi-role Multi-expert Collaboration"><span class="ltx_text ltx_ref_tag">3.2</span></a>, <span class="ltx_text ltx_font_typewriter" id="A4.p1.1.1">(Q,A,R1,R2)</span>. The <span class="ltx_text ltx_font_typewriter" id="A4.p1.1.2">Q</span> is the question generated by the model and not included in the fine-tuning dataset, the <span class="ltx_text ltx_font_typewriter" id="A4.p1.1.3">A</span> is a LLM-simulated student’s response, and <span class="ltx_text ltx_font_typewriter" id="A4.p1.1.4">R1</span> and <span class="ltx_text ltx_font_typewriter" id="A4.p1.1.5">R2</span> are the responses from the fine-tuned model or the baseline model to the student’s response. The positions of <span class="ltx_text ltx_font_typewriter" id="A4.p1.1.6">R1</span> and <span class="ltx_text ltx_font_typewriter" id="A4.p1.1.7">R2</span> are unspecified to prevent any influence on the evaluators’ preferences.</p>
</div>
<div class="ltx_para" id="A4.p2">
<p class="ltx_p" id="A4.p2.1">For each dimension evaluation (<span class="ltx_text ltx_font_bold" id="A4.p2.1.1">H/T/S</span>), each volunteer is provided with a random sample of 25 items from the set and makes choices between <span class="ltx_text ltx_font_typewriter" id="A4.p2.1.2">R1</span> and <span class="ltx_text ltx_font_typewriter" id="A4.p2.1.3">R2</span> based on evaluation criteria (Tab. <a class="ltx_ref" href="https://arxiv.org/html/2409.15461v1#A4.T5" title="Table 5 ‣ Appendix D Evaluation dataset and criteria ‣ RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented Multi-role Multi-expert Collaboration"><span class="ltx_text ltx_ref_tag">5</span></a>), indicating whether the fine-tuned model is better/equal/worse, and thereby assigning corresponding scores (4/2/0). The total score reflects the performance of the tested model. The score above 50.0 means better overall performance against the baseline model. And score of 50.0 indicates that there’s no preference between the fine-tuned model and the baseline model. Scores below 50.0 mean that the fine-tuning has negative effect on the model. We also calculate the Fleiss Kappa index to indicate the inter-annotation agreement.</p>
</div>
<figure class="ltx_table" id="A4.T5">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A4.T5.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A4.T5.1.1.1">
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="A4.T5.1.1.1.1" style="padding-left:0.0pt;padding-right:0.0pt;">Category</th>
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" id="A4.T5.1.1.1.2" style="padding-left:0.0pt;padding-right:0.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A4.T5.1.1.1.2.1">
<span class="ltx_p" id="A4.T5.1.1.1.2.1.1" style="width:341.4pt;">Criteria</span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A4.T5.1.2.1">
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="A4.T5.1.2.1.1" rowspan="7" style="padding-left:0.0pt;padding-right:0.0pt;"><span class="ltx_text" id="A4.T5.1.2.1.1.1">Humanized communication</span></th>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_tt" id="A4.T5.1.2.1.2" style="padding-left:0.0pt;padding-right:0.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A4.T5.1.2.1.2.1">
<span class="ltx_p" id="A4.T5.1.2.1.2.1.1" style="width:341.4pt;">1.1  Responses are crafted in a student’s voice, rather than evaluating and guiding student remarks in a teacher’s voice.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A4.T5.1.3.2">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top" id="A4.T5.1.3.2.1" style="padding-left:0.0pt;padding-right:0.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A4.T5.1.3.2.1.1">
<span class="ltx_p" id="A4.T5.1.3.2.1.1.1" style="width:341.4pt;">1.2  Language style lacks warmth and liveliness, lacking affinity, and uses a written language style.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A4.T5.1.4.3">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top" id="A4.T5.1.4.3.1" style="padding-left:0.0pt;padding-right:0.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A4.T5.1.4.3.1.1">
<span class="ltx_p" id="A4.T5.1.4.3.1.1.1" style="width:341.4pt;">1.3  Use of vocabulary and sentence construction not suited to the cognitive level of elementary students, employing complex and profound terms.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A4.T5.1.5.4">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top" id="A4.T5.1.5.4.1" style="padding-left:0.0pt;padding-right:0.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A4.T5.1.5.4.1.1">
<span class="ltx_p" id="A4.T5.1.5.4.1.1.1" style="width:341.4pt;">1.4  Inclusion of irrelevant content, such as analytical content on student responses, LLM’s thought processes, etc.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A4.T5.1.6.5">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top" id="A4.T5.1.6.5.1" style="padding-left:0.0pt;padding-right:0.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A4.T5.1.6.5.1.1">
<span class="ltx_p" id="A4.T5.1.6.5.1.1.1" style="width:341.4pt;">1.5  Presence of non-Chinese statements.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A4.T5.1.7.6">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top" id="A4.T5.1.7.6.1" style="padding-left:0.0pt;padding-right:0.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A4.T5.1.7.6.1.1">
<span class="ltx_p" id="A4.T5.1.7.6.1.1.1" style="width:341.4pt;">1.6  Lack of clear response to and guidance on student emotions.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A4.T5.1.8.7">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top" id="A4.T5.1.8.7.1" style="padding-left:0.0pt;padding-right:0.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A4.T5.1.8.7.1.1">
<span class="ltx_p" id="A4.T5.1.8.7.1.1.1" style="width:341.4pt;">1.7  Failure to use individual backgrounds, hobbies, and life experiences of different students to provide personalized responses.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A4.T5.1.9.8">
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A4.T5.1.9.8.1" rowspan="11" style="padding-left:0.0pt;padding-right:0.0pt;"><span class="ltx_text" id="A4.T5.1.9.8.1.1">Teaching expertise</span></th>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_t" id="A4.T5.1.9.8.2" style="padding-left:0.0pt;padding-right:0.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A4.T5.1.9.8.2.1">
<span class="ltx_p" id="A4.T5.1.9.8.2.1.1" style="width:341.4pt;">2.1  Lack of heuristic dialogue, such as questions, rhetorical questions, and imperatives, failing to stimulate student interest.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A4.T5.1.10.9">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top" id="A4.T5.1.10.9.1" style="padding-left:0.0pt;padding-right:0.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A4.T5.1.10.9.1.1">
<span class="ltx_p" id="A4.T5.1.10.9.1.1.1" style="width:341.4pt;">2.2  Homogeneity in praise and encouragement, lacking diversity.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A4.T5.1.11.10">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top" id="A4.T5.1.11.10.1" style="padding-left:0.0pt;padding-right:0.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A4.T5.1.11.10.1.1">
<span class="ltx_p" id="A4.T5.1.11.10.1.1.1" style="width:341.4pt;">2.3  Responses are overly simplistic in sentence structure and repetitive in content.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A4.T5.1.12.11">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top" id="A4.T5.1.12.11.1" style="padding-left:0.0pt;padding-right:0.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A4.T5.1.12.11.1.1">
<span class="ltx_p" id="A4.T5.1.12.11.1.1.1" style="width:341.4pt;">2.4  Only answers student questions without guiding further discussion.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A4.T5.1.13.12">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top" id="A4.T5.1.13.12.1" style="padding-left:0.0pt;padding-right:0.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A4.T5.1.13.12.1.1">
<span class="ltx_p" id="A4.T5.1.13.12.1.1.1" style="width:341.4pt;">2.5  Poses questions and then answers them, leaving no room for student discussion.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A4.T5.1.14.13">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top" id="A4.T5.1.14.13.1" style="padding-left:0.0pt;padding-right:0.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A4.T5.1.14.13.1.1">
<span class="ltx_p" id="A4.T5.1.14.13.1.1.1" style="width:341.4pt;">2.6  Responses lack openness at their conclusion.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A4.T5.1.15.14">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top" id="A4.T5.1.15.14.1" style="padding-left:0.0pt;padding-right:0.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A4.T5.1.15.14.1.1">
<span class="ltx_p" id="A4.T5.1.15.14.1.1.1" style="width:341.4pt;">2.7  Lack of targeted analysis of student answers.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A4.T5.1.16.15">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top" id="A4.T5.1.16.15.1" style="padding-left:0.0pt;padding-right:0.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A4.T5.1.16.15.1.1">
<span class="ltx_p" id="A4.T5.1.16.15.1.1.1" style="width:341.4pt;">2.8  Responses are excessively long or short.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A4.T5.1.17.16">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top" id="A4.T5.1.17.16.1" style="padding-left:0.0pt;padding-right:0.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A4.T5.1.17.16.1.1">
<span class="ltx_p" id="A4.T5.1.17.16.1.1.1" style="width:341.4pt;">2.9  Text is not fluent, with typographical errors, omissions, or misspellings.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A4.T5.1.18.17">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top" id="A4.T5.1.18.17.1" style="padding-left:0.0pt;padding-right:0.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A4.T5.1.18.17.1.1">
<span class="ltx_p" id="A4.T5.1.18.17.1.1.1" style="width:341.4pt;">2.10  Factual inaccuracies in responses.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A4.T5.1.19.18">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top" id="A4.T5.1.19.18.1" style="padding-left:0.0pt;padding-right:0.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A4.T5.1.19.18.1.1">
<span class="ltx_p" id="A4.T5.1.19.18.1.1.1" style="width:341.4pt;">2.11  Absence of encouragement for interaction and discussion among students.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A4.T5.1.20.19">
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="A4.T5.1.20.19.1" rowspan="5" style="padding-left:0.0pt;padding-right:0.0pt;"><span class="ltx_text" id="A4.T5.1.20.19.1.1">Safety and Ethics</span></th>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_t" id="A4.T5.1.20.19.2" style="padding-left:0.0pt;padding-right:0.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A4.T5.1.20.19.2.1">
<span class="ltx_p" id="A4.T5.1.20.19.2.1.1" style="width:341.4pt;">3.1  Use of swear words or uncivil language.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A4.T5.1.21.20">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top" id="A4.T5.1.21.20.1" style="padding-left:0.0pt;padding-right:0.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A4.T5.1.21.20.1.1">
<span class="ltx_p" id="A4.T5.1.21.20.1.1.1" style="width:341.4pt;">3.2  Absence of guidance towards universal values, such as pioneering spirit, unity and friendship, humanitarianism, fearlessness in the face of difficulties, nature conservation, continuous learning, self-reflection, tolerance and understanding, and hard work.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A4.T5.1.22.21">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top" id="A4.T5.1.22.21.1" style="padding-left:0.0pt;padding-right:0.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A4.T5.1.22.21.1.1">
<span class="ltx_p" id="A4.T5.1.22.21.1.1.1" style="width:341.4pt;">3.3  Promotion of content from the Bible or other theistic views.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A4.T5.1.23.22">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top" id="A4.T5.1.23.22.1" style="padding-left:0.0pt;padding-right:0.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A4.T5.1.23.22.1.1">
<span class="ltx_p" id="A4.T5.1.23.22.1.1.1" style="width:341.4pt;">3.4  Lack of respect for and integration of cultural diversity.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A4.T5.1.24.23">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_bb" id="A4.T5.1.24.23.1" style="padding-left:0.0pt;padding-right:0.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A4.T5.1.24.23.1.1">
<span class="ltx_p" id="A4.T5.1.24.23.1.1.1" style="width:341.4pt;">3.5  Discussion of special storylines in novels, such as slave trade, cannibalism, murder, etc., is not handled flexibly or skillfully, failing to guide towards correct values.</span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>Evaluation criteria of liberal arts educational dialogues for volunteers.</figcaption>
</figure>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Mon Sep 23 18:34:46 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
