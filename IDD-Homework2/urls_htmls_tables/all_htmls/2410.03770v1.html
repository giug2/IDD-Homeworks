<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>A Two-Stage Proactive Dialogue Generator for Efficient Clinical Information Collection Using Large Language Model</title>
<!--Generated on Wed Oct  2 19:31:22 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2410.03770v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#S1" title="In A Two-Stage Proactive Dialogue Generator for Efficient Clinical Information Collection Using Large Language Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#S2" title="In A Two-Stage Proactive Dialogue Generator for Efficient Clinical Information Collection Using Large Language Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#S3" title="In A Two-Stage Proactive Dialogue Generator for Efficient Clinical Information Collection Using Large Language Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Methods</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#S3.SS1" title="In 3 Methods ‚Ä£ A Two-Stage Proactive Dialogue Generator for Efficient Clinical Information Collection Using Large Language Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Overall Description</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#S3.SS2" title="In 3 Methods ‚Ä£ A Two-Stage Proactive Dialogue Generator for Efficient Clinical Information Collection Using Large Language Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Proactive Dialogue Generator</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#S3.SS3" title="In 3 Methods ‚Ä£ A Two-Stage Proactive Dialogue Generator for Efficient Clinical Information Collection Using Large Language Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Dialogue Recommendation System</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#S3.SS4" title="In 3 Methods ‚Ä£ A Two-Stage Proactive Dialogue Generator for Efficient Clinical Information Collection Using Large Language Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4 </span>The Interactive Patient Agent</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#S4" title="In A Two-Stage Proactive Dialogue Generator for Efficient Clinical Information Collection Using Large Language Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Results</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#S4.SS1" title="In 4 Results ‚Ä£ A Two-Stage Proactive Dialogue Generator for Efficient Clinical Information Collection Using Large Language Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Experimental settings</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#S4.SS1.SSS1" title="In 4.1 Experimental settings ‚Ä£ 4 Results ‚Ä£ A Two-Stage Proactive Dialogue Generator for Efficient Clinical Information Collection Using Large Language Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1.1 </span>Experimental dataset</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#S4.SS1.SSS2" title="In 4.1 Experimental settings ‚Ä£ 4 Results ‚Ä£ A Two-Stage Proactive Dialogue Generator for Efficient Clinical Information Collection Using Large Language Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1.2 </span>Evaluation metrics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#S4.SS1.SSS3" title="In 4.1 Experimental settings ‚Ä£ 4 Results ‚Ä£ A Two-Stage Proactive Dialogue Generator for Efficient Clinical Information Collection Using Large Language Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1.3 </span>Implementation details</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#S4.SS2" title="In 4 Results ‚Ä£ A Two-Stage Proactive Dialogue Generator for Efficient Clinical Information Collection Using Large Language Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Language styles of LLMs</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#S4.SS3" title="In 4 Results ‚Ä£ A Two-Stage Proactive Dialogue Generator for Efficient Clinical Information Collection Using Large Language Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Retrieval of diagnostic information</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#S4.SS4" title="In 4 Results ‚Ä£ A Two-Stage Proactive Dialogue Generator for Efficient Clinical Information Collection Using Large Language Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4 </span>Ablation study on quality of responses</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#S4.SS5" title="In 4 Results ‚Ä£ A Two-Stage Proactive Dialogue Generator for Efficient Clinical Information Collection Using Large Language Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.5 </span>Demonstration of proactive query generation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#S5" title="In A Two-Stage Proactive Dialogue Generator for Efficient Clinical Information Collection Using Large Language Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Discussion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#S6" title="In A Two-Stage Proactive Dialogue Generator for Efficient Clinical Information Collection Using Large Language Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#S7" title="In A Two-Stage Proactive Dialogue Generator for Efficient Clinical Information Collection Using Large Language Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Acknowledgment</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<div class="ltx_para" id="p1">
<span class="ltx_ERROR undefined" id="p1.1">\sidecaptionvpos</span>
<p class="ltx_p" id="p1.2">figurec









































</p>
</div>
<h1 class="ltx_title ltx_title_document">A Two-Stage Proactive Dialogue Generator for Efficient Clinical Information Collection Using Large Language Model</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Xueshen Li
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Department of Biomedical Engineering, Stevens Institute of Technology
</span>
<span class="ltx_contact ltx_role_affiliation">
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Xinlong Hou
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Department of Biomedical Engineering, Stevens Institute of Technology
</span>
<span class="ltx_contact ltx_role_affiliation">
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Nirupama Ravi
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Nokia Bell Labs
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Ziyi Huang
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Nokia Bell Labs
</span>
<span class="ltx_contact ltx_role_affiliation">
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yu Gan
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Department of Biomedical Engineering, Stevens Institute of Technology
</span>
<span class="ltx_contact ltx_role_affiliation">
</span></span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id1.id1">Efficient patient-doctor interaction is among the key factors for a successful disease diagnosis. During the conversation, the doctor could query complementary diagnostic information, such as the patient‚Äôs symptoms, previous surgery, and other related information that goes beyond medical evidence data (test results) to enhance disease diagnosis. However, this procedure is usually time-consuming and less-efficient, which can be potentially optimized through computer-assisted systems. As such, we propose a diagnostic dialogue system to automate the patient information collection procedure. By exploiting medical history and conversation logic, our conversation agents, particularly the doctor agent, can pose multi-round clinical queries to effectively collect the most relevant disease diagnostic information. Moreover, benefiting from our two-stage recommendation structure, carefully designed ranking criteria, and interactive patient agent, our model is able to overcome the under-exploration and non-flexible challenges in dialogue generation. Our experimental results on a real-world medical conversation dataset show that our model can generate clinical queries that mimic the conversation style of real doctors, with efficient fluency, professionalism, and safety, while effectively collecting relevant disease diagnostic information.</p>
</div>
<span class="ltx_note ltx_role_footnotetext" id="footnotex1"><sup class="ltx_note_mark">‚Ä†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">‚Ä†</sup><span class="ltx_note_type">footnotetext: </span>Co-first authors<sup class="ltx_sup" id="footnotex1.1"><span class="ltx_text ltx_font_italic" id="footnotex1.1.1">‚Ä†</span></sup>. Corresponding authors<sup class="ltx_sup" id="footnotex1.2"><span class="ltx_text ltx_font_italic" id="footnotex1.2.1">‚àó</span></sup>: <a class="ltx_ref ltx_url ltx_font_typewriter" href="ziyi.huang@nokia-bell-labs.com" title="">ziyi.huang@nokia-bell-labs.com</a>, <a class="ltx_ref ltx_url ltx_font_typewriter" href="ygan5@stevens.edu" title="">ygan5@stevens.edu</a></span></span></span>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Clinical diagnosis is a complex decision-making process that combines evidence-based information collected from multiple resources, including patients‚Äô symptoms, previous surgery, medical testing evidence, and other related information such as habits <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib1" title="">1</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib2" title="">2</a>]</cite>. Existing studies mainly target computer-assisted disease analysis tasks, such as abnormal detection and disease prediction <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib3" title="">3</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib4" title="">4</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib5" title="">5</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib6" title="">6</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib7" title="">7</a>]</cite>, with few studies investigating diagnostic data collection. Currently, the diagnostic-critical information is usually collected manually through patient-doctor/nurse interviews or conventional queries, which is less efficient and time-consuming. Moreover, the extensive questioning required can lead to patient fatigue, increasing the likelihood of inaccuracies in their responses. Automating the medical query process could significantly streamline data collection, enhance the accuracy of information gathered, and improve overall patient experience by reducing the cognitive load on patients during medical interviews. A potential solution to accelerate this process is using questionnaires to guide self-report medical history collection<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib8" title="">8</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib9" title="">9</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib10" title="">10</a>]</cite>. However, previous studies show that self-administered questionnaires may not be able to provide the same information as clinical interviews, and thus are not recommended for certain diseases <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib11" title="">11</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib12" title="">12</a>]</cite>. As such, there is a need to develop an intelligent dialogue system to effectively query patient‚Äôs information to support the diagnostic procedure.</p>
</div>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="233" id="S1.F1.1.g1" src="extracted/5896984/figures/high_level.png" width="299"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>A comparison between existing a) Question-Answering (QA) System and b) Proactive Dialogue System. The traditional question-answering system answers the questions from patients in a passive way. Our proposed Proactive Dialogue System could proactively generate queries, leading to a dialogue that collects diagnostic information that supports Diagnosis and Treatment. </figcaption>
</figure>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Despite its practical importance in diagnosis, the development of computer-assisted diagnostic dialogue systems is in the early stages. Directly transferring the solution of question-answering (QA) tasks <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib13" title="">13</a>]</cite> to diagnostic query generation is challenging. In a typical QA interaction, the model responds to a given query by performing information retrials from its knowledge database. Similar to a search engine <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib14" title="">14</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib15" title="">15</a>]</cite>, it can only passively answer questions, with no query capability to pose questions. By contrast, the diagnostic dialogue system aims to pose questions to effectively collect disease-relevant information, such as symptoms, previous surgery, and other related information, from the patients to enhance the following diagnosis. This requires the model to have the professional knowledge to identify disease features, the logical capability to perform communication, and the incorporation capability to analyze multi-round conversations. Overall, the model should be equipped with reasoning capability to <span class="ltx_text ltx_font_italic" id="S1.p2.1.1">raise</span> diagnostic relevant questions, rather than simply <span class="ltx_text ltx_font_italic" id="S1.p2.1.2">answer</span> a given question. In Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#S1.F1" title="Figure 1 ‚Ä£ 1 Introduction ‚Ä£ A Two-Stage Proactive Dialogue Generator for Efficient Clinical Information Collection Using Large Language Model"><span class="ltx_text ltx_ref_tag">1</span></a>, we show a conceptual comparison between the proposed proactive dialogue system and a typical QA task. Our Proactive Dialogue System actively generates queries to engage patients in a dialogue that collects diagnostic information while traditional QA systems respond passively.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">Naively formulating the query generation problem as a single query prediction task is not an ideal solution, as it could reduce the flexibility of the query and further hinder the completeness of diagnostic information collection. In natural dialogue, it is possible to have multiple appropriate ‚Äôanswers‚Äô for a given response. This is different from standard classification tasks with one-to-one expected outputs where each input is assigned to a single clear label for prediction. However, limited by the training framework, we could only use one ground truth query in the model optimization. Hence, the flexibility of query generation will be limited due to the lack of exploration designs. Moreover, the prediction from an optimized foundation model is mostly based on its nearest contextual sentences to ensure the logic is coherent. As a result, key diagnostic factors, such as the completeness of disease feature checking and the rationale of disease diagnosis, might be insufficiently performed and considered during the conversation generation. Formulating a recommendation system solution could directly address the above challenges. The importance of key diagnostic factors can be directly enhanced through a carefully designed ranking strategy on query candidate selection. Benefiting from the explore-exploit tradeoff strategy, the model could fully explore the potential mechanism and relevant features for disease diagnosis from the real-world clinical dialogue to improve the completeness of the diagnostic checking.</p>
</div>
<figure class="ltx_figure" id="S1.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="335" id="S1.F2.1.g1" src="extracted/5896984/figures/flow_chart.png" width="598"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>The algorithm diagram of the proposed proactive dialogue system framework. <span class="ltx_text ltx_font_bold" id="S1.F2.4.1">(a):</span> Structure of the proposed proactive dialogue generator. <span class="ltx_text ltx_font_bold" id="S1.F2.5.2">(b):</span> Fine-tuning stage of doctor agent. The doctor agent has access to the patient‚Äôs query and medical history of the patient. The proactive dialogue generator produces responses from patients. In implementation, this dialogue generation process is optimized by the process of fine-tuning the doctor agent. </figcaption>
</figure>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">In this paper, we develop a diagnostic system, which consists of a unique two-stage recommendation structure, to proactively collect diagnostic information from patients with the following key features:</p>
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">We propose a proactive, diagnostic dialogue system with a critical doctor agent model to automatically collect diagnostic information, such as symptoms, previous surgery, medical testing evidence, etc., from patients. Different from classic QA tasks, our doctor agents could proactively pose disease-relevant queries, rather than passively answer questions, to lead an efficient and effective collection of clinical information.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">We develop a two-stage recommendation (ranking) structure, including query generation and candidate ranking, to address the issue of the under-exploration and non-flexible challenge in diagnostic query generation. In particular, we investigate medical history from a real-world diagnostic dialogue dataset and further use it to design a novel query ranking strategy to improve the model‚Äôs professional knowledge and reasoning capability on disease diagnosis.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">We conduct comprehensive experiments to validate our proposed dialogue system. Experiments in a real-world medical conversation dataset show that our proposed model generates medical dialogue that better mimics the conversation style of real doctors, with enhanced professionalism, effectiveness, and safety during the conversation in comparison with the state of the arts. Moreover, we demonstrate that our model is capable of collecting disease diagnostic information.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">Recent advances in large language models (LLMs), such as PaLM<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib16" title="">16</a>]</cite>, LLaMA<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib17" title="">17</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib18" title="">18</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib19" title="">19</a>]</cite>, GPT family<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib20" title="">20</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib21" title="">21</a>]</cite>, and ChatGLM<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib22" title="">22</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib23" title="">23</a>]</cite>, have pushed the boundaries of natural language processing (NLP) tasks, including text generation, text summarization, and QA. LLMs have demonstrated the potential for computer-assisted diagnosis.
Medical LLMs, such as Med-PaLM<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib24" title="">24</a>]</cite>, MEDITRON<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib25" title="">25</a>]</cite>, PMC-LLAMA<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib26" title="">26</a>]</cite>, and BioMedGPT<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib27" title="">27</a>]</cite>, have achieved satisfying scores in the United States Medical Licensing Examination. However, such contribution is limited in disease summarizing given clinical information.</p>
</div>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">Recent studies employing large language models (LLMs) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib28" title="">28</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib29" title="">29</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib30" title="">30</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib31" title="">31</a>]</cite> for the generation of automatic visual descriptions have shown considerable potential in computer-aided diagnostic applications. Notably, preliminary research has pioneered the use of a medical dialogue system that leverages a foundational model framework, such as ChatGPT<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib32" title="">32</a>]</cite>, to deliver medical advice across three distinct imaging domains <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib4" title="">4</a>]</cite>. Furthermore, Zhou et al. advanced this field by creating an interactive dermatology diagnostic system <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib5" title="">5</a>]</cite>. This system was developed by fine-tuning Mini-GPT with an extensive dataset of skin disease images, enabling the generation of detailed reports on various skin conditions. This integration of clinical concepts and physician annotations has significantly enhanced the utility and accuracy of automated diagnostic systems. Although image information is aligned in a pre-trained LLM, those dialogue models still lack the capability of proactive interaction.</p>
</div>
<div class="ltx_para" id="S2.p3">
<p class="ltx_p" id="S2.p3.1">HuatuoGPT<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib33" title="">33</a>]</cite>, Zhongjing<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib34" title="">34</a>]</cite> have been developed for medical Q&amp;A via conversation interaction. These medical large language models (LLMs) demonstrate strong performance in answering medical questions by leveraging training on medical databases and dialogues. However, they are not specifically optimized for proactively gathering diagnostic information. Moreover, these models employ deterministic generation methods, which lack the adaptability offered by a recommendation system.</p>
</div>
<figure class="ltx_figure" id="S2.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="328" id="S2.F3.1.g1" src="extracted/5896984/figures/prompt.png" width="562"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>The prompt used in this paper. (a): The prompts used to calculate the consistency between the generated dialogue and the medical history. (b): The prompt used to calculate the quality of the generated dialogue by the nursing agent. (c): The prompt for calculating high-level metrics, including Fluency, Professionalism, and Safety, of the generated dialogue. (d): The prompt to extract diagnostic information from the generated dialogue. We use the first data entry in the testing set for the example in the prompt. (e): The prompt for the patient agent. The patient agent has access to the medical history and generates responses which can be follow-up questions regarding their medical conditions or an answer to the doctor agent‚Äôs previous question.</figcaption>
</figure>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Methods</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">In this study, we present a proactive LLM-based medical conversation framework to effectively acquire diagnostic-associated information from the patients. Different from classic VQA or QA tasks, our dialogue agents could proactively post questions to effectively collect diagnostic information, rather than passively answering questions. Specifically, our proposed system can professionally retrieve patients‚Äô medical histories and collect their health conditions to support follow-up disease diagnosis. This design is motivated by the clinical dialogue between patient and doctor during regular clinical visits.</p>
</div>
<div class="ltx_para" id="S3.p2">
<p class="ltx_p" id="S3.p2.1">The overall structure of our proposed dialogue system is illustrated in Fig.<a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#S1.F2" title="Figure 2 ‚Ä£ 1 Introduction ‚Ä£ A Two-Stage Proactive Dialogue Generator for Efficient Clinical Information Collection Using Large Language Model"><span class="ltx_text ltx_ref_tag">2</span></a> (a). As shown, our proposed proactive dialogue generator consists of three major modules: a doctor agent, a dialogue recommendation system, and a patient agent. The proactive dialogue generator takes the patients‚Äô latest interactions as input and generates several disease-relevant queries/answers as response candidates. Based on a novel ranking strategy, the dialogue ranking system selects the most relevant response among the ranked candidates to continue interacting with the patients.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Overall Description</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">The development of medical dialogue systems requires a doctor agent with reasoning abilities on disease understanding, diagnosis logic performing, and communication concluding. However, existing LLMs <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib16" title="">16</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib17" title="">17</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib18" title="">18</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib19" title="">19</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib20" title="">20</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib21" title="">21</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib22" title="">22</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib23" title="">23</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib25" title="">25</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib24" title="">24</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib26" title="">26</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib27" title="">27</a>]</cite> are mainly trained on general text datasets, with limited clinical knowledge in disease diagnosis.
In this paper, we finetune an LLM based on a real-world clinical dialogue dataset <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib35" title="">35</a>]</cite> to confer domain expertise of our model, which is referred to as a doctor agent.
This allows the model to have a professional understanding of disease-relevant features, enhancing its reliability on downstream disease diagnostic tasks. In addition, we utilize the medical history generated from <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib35" title="">35</a>]</cite> in the model finetuning stage (detailed in <a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#S3.SS2" title="3.2 Proactive Dialogue Generator ‚Ä£ 3 Methods ‚Ä£ A Two-Stage Proactive Dialogue Generator for Efficient Clinical Information Collection Using Large Language Model"><span class="ltx_text ltx_ref_tag">3.2</span></a>) to further strengthen its reasoning and logic capability for query generation. In the ideal case, there should be a real patient who answers the questions from the doctor. However, the real-world dataset only provides fixed answers and follow-up queries from patients for each round of conversation. To reduce the potential inconsistency and logic flaws among multi-round conversations, we developed an interactive patient agent to answer questions and ask follow-up queries from the doctor agent, based on medical history data. In addition to the powerful doctor agent, with the involvement of a patient agent, we can generate a realistic clinical dialogue for LLM training or educational training.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Proactive Dialogue Generator</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.6">In the proactive dialogue generator module, we finetune a doctor agent to proactively generate disease-relevant query candidates. We propose to start from a pre-trained LLM on general textural information to fully utilize its reasoning and language abilities and further fine-tune it through the real-world medical dialogue dataset along with medical histories to expand its professional knowledge of disease understanding. In Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#S1.F2" title="Figure 2 ‚Ä£ 1 Introduction ‚Ä£ A Two-Stage Proactive Dialogue Generator for Efficient Clinical Information Collection Using Large Language Model"><span class="ltx_text ltx_ref_tag">2</span></a> (b), we present the finetuning diagram of the proposed doctor agent. We only fine-tune the doctor agent for query generation with a fixed patient agent, to ensure a quick and reliable model convergence. The patient agent is fixed to provide the same response as the patients‚Äô response in the dataset during finetuning. In particular, the queries generated from the doctor agent are conditioned on both inputs from patient agent and medical histories, as this combination could potentially enhance the model‚Äôs clinical understanding of the target disease and allow it to effectively and reliably post the most relevant queries. In each conversation round, the patient agent initials the conversation and refers to the training dialogues to answer the queries. Then, the doctor agent is fine-tuned based on the ground truth query from the training set via the following loss function.</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\begin{split}L_{doctor}(\theta;X_{t},X_{r})=-\sum^{L}_{i=1}logp_{\theta}(x_{i}%
,X_{t},X_{r,&lt;i}),\end{split}" class="ltx_Math" display="block" id="S3.E1.m1.34"><semantics id="S3.E1.m1.34a"><mtable displaystyle="true" id="S3.E1.m1.34.34.2"><mtr id="S3.E1.m1.34.34.2a"><mtd class="ltx_align_right" columnalign="right" id="S3.E1.m1.34.34.2b"><mrow id="S3.E1.m1.34.34.2.33.33.33.33"><mrow id="S3.E1.m1.34.34.2.33.33.33.33.1"><mrow id="S3.E1.m1.34.34.2.33.33.33.33.1.2"><msub id="S3.E1.m1.34.34.2.33.33.33.33.1.2.4"><mi id="S3.E1.m1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.cmml">L</mi><mrow id="S3.E1.m1.2.2.2.2.2.2.1" xref="S3.E1.m1.2.2.2.2.2.2.1.cmml"><mi id="S3.E1.m1.2.2.2.2.2.2.1.2" xref="S3.E1.m1.2.2.2.2.2.2.1.2.cmml">d</mi><mo id="S3.E1.m1.2.2.2.2.2.2.1.1" xref="S3.E1.m1.2.2.2.2.2.2.1.1.cmml">‚Å¢</mo><mi id="S3.E1.m1.2.2.2.2.2.2.1.3" xref="S3.E1.m1.2.2.2.2.2.2.1.3.cmml">o</mi><mo id="S3.E1.m1.2.2.2.2.2.2.1.1a" xref="S3.E1.m1.2.2.2.2.2.2.1.1.cmml">‚Å¢</mo><mi id="S3.E1.m1.2.2.2.2.2.2.1.4" xref="S3.E1.m1.2.2.2.2.2.2.1.4.cmml">c</mi><mo id="S3.E1.m1.2.2.2.2.2.2.1.1b" xref="S3.E1.m1.2.2.2.2.2.2.1.1.cmml">‚Å¢</mo><mi id="S3.E1.m1.2.2.2.2.2.2.1.5" xref="S3.E1.m1.2.2.2.2.2.2.1.5.cmml">t</mi><mo id="S3.E1.m1.2.2.2.2.2.2.1.1c" xref="S3.E1.m1.2.2.2.2.2.2.1.1.cmml">‚Å¢</mo><mi id="S3.E1.m1.2.2.2.2.2.2.1.6" xref="S3.E1.m1.2.2.2.2.2.2.1.6.cmml">o</mi><mo id="S3.E1.m1.2.2.2.2.2.2.1.1d" xref="S3.E1.m1.2.2.2.2.2.2.1.1.cmml">‚Å¢</mo><mi id="S3.E1.m1.2.2.2.2.2.2.1.7" xref="S3.E1.m1.2.2.2.2.2.2.1.7.cmml">r</mi></mrow></msub><mo id="S3.E1.m1.34.34.2.33.33.33.33.1.2.3" xref="S3.E1.m1.33.33.1.1.1.cmml">‚Å¢</mo><mrow id="S3.E1.m1.34.34.2.33.33.33.33.1.2.2.2"><mo id="S3.E1.m1.3.3.3.3.3.3" stretchy="false" xref="S3.E1.m1.33.33.1.1.1.cmml">(</mo><mi id="S3.E1.m1.4.4.4.4.4.4" xref="S3.E1.m1.4.4.4.4.4.4.cmml">Œ∏</mi><mo id="S3.E1.m1.5.5.5.5.5.5" xref="S3.E1.m1.33.33.1.1.1.cmml">;</mo><msub id="S3.E1.m1.34.34.2.33.33.33.33.1.1.1.1.1"><mi id="S3.E1.m1.6.6.6.6.6.6" xref="S3.E1.m1.6.6.6.6.6.6.cmml">X</mi><mi id="S3.E1.m1.7.7.7.7.7.7.1" xref="S3.E1.m1.7.7.7.7.7.7.1.cmml">t</mi></msub><mo id="S3.E1.m1.8.8.8.8.8.8" xref="S3.E1.m1.33.33.1.1.1.cmml">,</mo><msub id="S3.E1.m1.34.34.2.33.33.33.33.1.2.2.2.2"><mi id="S3.E1.m1.9.9.9.9.9.9" xref="S3.E1.m1.9.9.9.9.9.9.cmml">X</mi><mi id="S3.E1.m1.10.10.10.10.10.10.1" xref="S3.E1.m1.10.10.10.10.10.10.1.cmml">r</mi></msub><mo id="S3.E1.m1.11.11.11.11.11.11" stretchy="false" xref="S3.E1.m1.33.33.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.12.12.12.12.12.12" xref="S3.E1.m1.12.12.12.12.12.12.cmml">=</mo><mrow id="S3.E1.m1.34.34.2.33.33.33.33.1.5"><mo id="S3.E1.m1.34.34.2.33.33.33.33.1.5a" xref="S3.E1.m1.33.33.1.1.1.cmml">‚àí</mo><mrow id="S3.E1.m1.34.34.2.33.33.33.33.1.5.3"><munderover id="S3.E1.m1.34.34.2.33.33.33.33.1.5.3.4"><mo id="S3.E1.m1.14.14.14.14.14.14" movablelimits="false" xref="S3.E1.m1.14.14.14.14.14.14.cmml">‚àë</mo><mrow id="S3.E1.m1.16.16.16.16.16.16.1" xref="S3.E1.m1.16.16.16.16.16.16.1.cmml"><mi id="S3.E1.m1.16.16.16.16.16.16.1.2" xref="S3.E1.m1.16.16.16.16.16.16.1.2.cmml">i</mi><mo id="S3.E1.m1.16.16.16.16.16.16.1.1" xref="S3.E1.m1.16.16.16.16.16.16.1.1.cmml">=</mo><mn id="S3.E1.m1.16.16.16.16.16.16.1.3" xref="S3.E1.m1.16.16.16.16.16.16.1.3.cmml">1</mn></mrow><mi id="S3.E1.m1.15.15.15.15.15.15.1" xref="S3.E1.m1.15.15.15.15.15.15.1.cmml">L</mi></munderover><mrow id="S3.E1.m1.34.34.2.33.33.33.33.1.5.3.3"><mi id="S3.E1.m1.17.17.17.17.17.17" xref="S3.E1.m1.17.17.17.17.17.17.cmml">l</mi><mo id="S3.E1.m1.34.34.2.33.33.33.33.1.5.3.3.4" xref="S3.E1.m1.33.33.1.1.1.cmml">‚Å¢</mo><mi id="S3.E1.m1.18.18.18.18.18.18" xref="S3.E1.m1.18.18.18.18.18.18.cmml">o</mi><mo id="S3.E1.m1.34.34.2.33.33.33.33.1.5.3.3.4a" xref="S3.E1.m1.33.33.1.1.1.cmml">‚Å¢</mo><mi id="S3.E1.m1.19.19.19.19.19.19" xref="S3.E1.m1.19.19.19.19.19.19.cmml">g</mi><mo id="S3.E1.m1.34.34.2.33.33.33.33.1.5.3.3.4b" xref="S3.E1.m1.33.33.1.1.1.cmml">‚Å¢</mo><msub id="S3.E1.m1.34.34.2.33.33.33.33.1.5.3.3.5"><mi id="S3.E1.m1.20.20.20.20.20.20" xref="S3.E1.m1.20.20.20.20.20.20.cmml">p</mi><mi id="S3.E1.m1.21.21.21.21.21.21.1" xref="S3.E1.m1.21.21.21.21.21.21.1.cmml">Œ∏</mi></msub><mo id="S3.E1.m1.34.34.2.33.33.33.33.1.5.3.3.4c" xref="S3.E1.m1.33.33.1.1.1.cmml">‚Å¢</mo><mrow id="S3.E1.m1.34.34.2.33.33.33.33.1.5.3.3.3.3"><mo id="S3.E1.m1.22.22.22.22.22.22" stretchy="false" xref="S3.E1.m1.33.33.1.1.1.cmml">(</mo><msub id="S3.E1.m1.34.34.2.33.33.33.33.1.3.1.1.1.1.1"><mi id="S3.E1.m1.23.23.23.23.23.23" xref="S3.E1.m1.23.23.23.23.23.23.cmml">x</mi><mi id="S3.E1.m1.24.24.24.24.24.24.1" xref="S3.E1.m1.24.24.24.24.24.24.1.cmml">i</mi></msub><mo id="S3.E1.m1.25.25.25.25.25.25" xref="S3.E1.m1.33.33.1.1.1.cmml">,</mo><msub id="S3.E1.m1.34.34.2.33.33.33.33.1.4.2.2.2.2.2"><mi id="S3.E1.m1.26.26.26.26.26.26" xref="S3.E1.m1.26.26.26.26.26.26.cmml">X</mi><mi id="S3.E1.m1.27.27.27.27.27.27.1" xref="S3.E1.m1.27.27.27.27.27.27.1.cmml">t</mi></msub><mo id="S3.E1.m1.28.28.28.28.28.28" xref="S3.E1.m1.33.33.1.1.1.cmml">,</mo><msub id="S3.E1.m1.34.34.2.33.33.33.33.1.5.3.3.3.3.3"><mi id="S3.E1.m1.29.29.29.29.29.29" xref="S3.E1.m1.29.29.29.29.29.29.cmml">X</mi><mrow id="S3.E1.m1.30.30.30.30.30.30.1.2" xref="S3.E1.m1.30.30.30.30.30.30.1.3.cmml"><mi id="S3.E1.m1.30.30.30.30.30.30.1.1" xref="S3.E1.m1.30.30.30.30.30.30.1.1.cmml">r</mi><mo id="S3.E1.m1.30.30.30.30.30.30.1.2.2" xref="S3.E1.m1.30.30.30.30.30.30.1.3.cmml">,</mo><mrow id="S3.E1.m1.30.30.30.30.30.30.1.2.1" xref="S3.E1.m1.30.30.30.30.30.30.1.2.1.cmml"><mi id="S3.E1.m1.30.30.30.30.30.30.1.2.1.2" xref="S3.E1.m1.30.30.30.30.30.30.1.2.1.2.cmml"></mi><mo id="S3.E1.m1.30.30.30.30.30.30.1.2.1.1" xref="S3.E1.m1.30.30.30.30.30.30.1.2.1.1.cmml">&lt;</mo><mi id="S3.E1.m1.30.30.30.30.30.30.1.2.1.3" xref="S3.E1.m1.30.30.30.30.30.30.1.2.1.3.cmml">i</mi></mrow></mrow></msub><mo id="S3.E1.m1.31.31.31.31.31.31" stretchy="false" xref="S3.E1.m1.33.33.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><mo id="S3.E1.m1.32.32.32.32.32.32" xref="S3.E1.m1.33.33.1.1.1.cmml">,</mo></mrow></mtd></mtr></mtable><annotation-xml encoding="MathML-Content" id="S3.E1.m1.34b"><apply id="S3.E1.m1.33.33.1.1.1.cmml" xref="S3.E1.m1.34.34.2.33.33.33.33.1.2.3"><eq id="S3.E1.m1.12.12.12.12.12.12.cmml" xref="S3.E1.m1.12.12.12.12.12.12"></eq><apply id="S3.E1.m1.33.33.1.1.1.2.cmml" xref="S3.E1.m1.34.34.2.33.33.33.33.1.2.3"><times id="S3.E1.m1.33.33.1.1.1.2.3.cmml" xref="S3.E1.m1.34.34.2.33.33.33.33.1.2.3"></times><apply id="S3.E1.m1.33.33.1.1.1.2.4.cmml" xref="S3.E1.m1.34.34.2.33.33.33.33.1.2.3"><csymbol cd="ambiguous" id="S3.E1.m1.33.33.1.1.1.2.4.1.cmml" xref="S3.E1.m1.34.34.2.33.33.33.33.1.2.3">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1">ùêø</ci><apply id="S3.E1.m1.2.2.2.2.2.2.1.cmml" xref="S3.E1.m1.2.2.2.2.2.2.1"><times id="S3.E1.m1.2.2.2.2.2.2.1.1.cmml" xref="S3.E1.m1.2.2.2.2.2.2.1.1"></times><ci id="S3.E1.m1.2.2.2.2.2.2.1.2.cmml" xref="S3.E1.m1.2.2.2.2.2.2.1.2">ùëë</ci><ci id="S3.E1.m1.2.2.2.2.2.2.1.3.cmml" xref="S3.E1.m1.2.2.2.2.2.2.1.3">ùëú</ci><ci id="S3.E1.m1.2.2.2.2.2.2.1.4.cmml" xref="S3.E1.m1.2.2.2.2.2.2.1.4">ùëê</ci><ci id="S3.E1.m1.2.2.2.2.2.2.1.5.cmml" xref="S3.E1.m1.2.2.2.2.2.2.1.5">ùë°</ci><ci id="S3.E1.m1.2.2.2.2.2.2.1.6.cmml" xref="S3.E1.m1.2.2.2.2.2.2.1.6">ùëú</ci><ci id="S3.E1.m1.2.2.2.2.2.2.1.7.cmml" xref="S3.E1.m1.2.2.2.2.2.2.1.7">ùëü</ci></apply></apply><list id="S3.E1.m1.33.33.1.1.1.2.2.3.cmml" xref="S3.E1.m1.34.34.2.33.33.33.33.1.2.3"><ci id="S3.E1.m1.4.4.4.4.4.4.cmml" xref="S3.E1.m1.4.4.4.4.4.4">ùúÉ</ci><apply id="S3.E1.m1.33.33.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.34.34.2.33.33.33.33.1.2.3"><csymbol cd="ambiguous" id="S3.E1.m1.33.33.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.34.34.2.33.33.33.33.1.2.3">subscript</csymbol><ci id="S3.E1.m1.6.6.6.6.6.6.cmml" xref="S3.E1.m1.6.6.6.6.6.6">ùëã</ci><ci id="S3.E1.m1.7.7.7.7.7.7.1.cmml" xref="S3.E1.m1.7.7.7.7.7.7.1">ùë°</ci></apply><apply id="S3.E1.m1.33.33.1.1.1.2.2.2.2.cmml" xref="S3.E1.m1.34.34.2.33.33.33.33.1.2.3"><csymbol cd="ambiguous" id="S3.E1.m1.33.33.1.1.1.2.2.2.2.1.cmml" xref="S3.E1.m1.34.34.2.33.33.33.33.1.2.3">subscript</csymbol><ci id="S3.E1.m1.9.9.9.9.9.9.cmml" xref="S3.E1.m1.9.9.9.9.9.9">ùëã</ci><ci id="S3.E1.m1.10.10.10.10.10.10.1.cmml" xref="S3.E1.m1.10.10.10.10.10.10.1">ùëü</ci></apply></list></apply><apply id="S3.E1.m1.33.33.1.1.1.5.cmml" xref="S3.E1.m1.34.34.2.33.33.33.33.1.2.3"><minus id="S3.E1.m1.13.13.13.13.13.13.cmml" xref="S3.E1.m1.34.34.2.33.33.33.33.1.2.3"></minus><apply id="S3.E1.m1.33.33.1.1.1.5.3.cmml" xref="S3.E1.m1.34.34.2.33.33.33.33.1.2.3"><apply id="S3.E1.m1.33.33.1.1.1.5.3.4.cmml" xref="S3.E1.m1.34.34.2.33.33.33.33.1.2.3"><csymbol cd="ambiguous" id="S3.E1.m1.33.33.1.1.1.5.3.4.1.cmml" xref="S3.E1.m1.34.34.2.33.33.33.33.1.2.3">subscript</csymbol><apply id="S3.E1.m1.33.33.1.1.1.5.3.4.2.cmml" xref="S3.E1.m1.34.34.2.33.33.33.33.1.2.3"><csymbol cd="ambiguous" id="S3.E1.m1.33.33.1.1.1.5.3.4.2.1.cmml" xref="S3.E1.m1.34.34.2.33.33.33.33.1.2.3">superscript</csymbol><sum id="S3.E1.m1.14.14.14.14.14.14.cmml" xref="S3.E1.m1.14.14.14.14.14.14"></sum><ci id="S3.E1.m1.15.15.15.15.15.15.1.cmml" xref="S3.E1.m1.15.15.15.15.15.15.1">ùêø</ci></apply><apply id="S3.E1.m1.16.16.16.16.16.16.1.cmml" xref="S3.E1.m1.16.16.16.16.16.16.1"><eq id="S3.E1.m1.16.16.16.16.16.16.1.1.cmml" xref="S3.E1.m1.16.16.16.16.16.16.1.1"></eq><ci id="S3.E1.m1.16.16.16.16.16.16.1.2.cmml" xref="S3.E1.m1.16.16.16.16.16.16.1.2">ùëñ</ci><cn id="S3.E1.m1.16.16.16.16.16.16.1.3.cmml" type="integer" xref="S3.E1.m1.16.16.16.16.16.16.1.3">1</cn></apply></apply><apply id="S3.E1.m1.33.33.1.1.1.5.3.3.cmml" xref="S3.E1.m1.34.34.2.33.33.33.33.1.2.3"><times id="S3.E1.m1.33.33.1.1.1.5.3.3.4.cmml" xref="S3.E1.m1.34.34.2.33.33.33.33.1.2.3"></times><ci id="S3.E1.m1.17.17.17.17.17.17.cmml" xref="S3.E1.m1.17.17.17.17.17.17">ùëô</ci><ci id="S3.E1.m1.18.18.18.18.18.18.cmml" xref="S3.E1.m1.18.18.18.18.18.18">ùëú</ci><ci id="S3.E1.m1.19.19.19.19.19.19.cmml" xref="S3.E1.m1.19.19.19.19.19.19">ùëî</ci><apply id="S3.E1.m1.33.33.1.1.1.5.3.3.8.cmml" xref="S3.E1.m1.34.34.2.33.33.33.33.1.2.3"><csymbol cd="ambiguous" id="S3.E1.m1.33.33.1.1.1.5.3.3.8.1.cmml" xref="S3.E1.m1.34.34.2.33.33.33.33.1.2.3">subscript</csymbol><ci id="S3.E1.m1.20.20.20.20.20.20.cmml" xref="S3.E1.m1.20.20.20.20.20.20">ùëù</ci><ci id="S3.E1.m1.21.21.21.21.21.21.1.cmml" xref="S3.E1.m1.21.21.21.21.21.21.1">ùúÉ</ci></apply><vector id="S3.E1.m1.33.33.1.1.1.5.3.3.3.4.cmml" xref="S3.E1.m1.34.34.2.33.33.33.33.1.2.3"><apply id="S3.E1.m1.33.33.1.1.1.3.1.1.1.1.1.cmml" xref="S3.E1.m1.34.34.2.33.33.33.33.1.2.3"><csymbol cd="ambiguous" id="S3.E1.m1.33.33.1.1.1.3.1.1.1.1.1.1.cmml" xref="S3.E1.m1.34.34.2.33.33.33.33.1.2.3">subscript</csymbol><ci id="S3.E1.m1.23.23.23.23.23.23.cmml" xref="S3.E1.m1.23.23.23.23.23.23">ùë•</ci><ci id="S3.E1.m1.24.24.24.24.24.24.1.cmml" xref="S3.E1.m1.24.24.24.24.24.24.1">ùëñ</ci></apply><apply id="S3.E1.m1.33.33.1.1.1.4.2.2.2.2.2.cmml" xref="S3.E1.m1.34.34.2.33.33.33.33.1.2.3"><csymbol cd="ambiguous" id="S3.E1.m1.33.33.1.1.1.4.2.2.2.2.2.1.cmml" xref="S3.E1.m1.34.34.2.33.33.33.33.1.2.3">subscript</csymbol><ci id="S3.E1.m1.26.26.26.26.26.26.cmml" xref="S3.E1.m1.26.26.26.26.26.26">ùëã</ci><ci id="S3.E1.m1.27.27.27.27.27.27.1.cmml" xref="S3.E1.m1.27.27.27.27.27.27.1">ùë°</ci></apply><apply id="S3.E1.m1.33.33.1.1.1.5.3.3.3.3.3.cmml" xref="S3.E1.m1.34.34.2.33.33.33.33.1.2.3"><csymbol cd="ambiguous" id="S3.E1.m1.33.33.1.1.1.5.3.3.3.3.3.1.cmml" xref="S3.E1.m1.34.34.2.33.33.33.33.1.2.3">subscript</csymbol><ci id="S3.E1.m1.29.29.29.29.29.29.cmml" xref="S3.E1.m1.29.29.29.29.29.29">ùëã</ci><list id="S3.E1.m1.30.30.30.30.30.30.1.3.cmml" xref="S3.E1.m1.30.30.30.30.30.30.1.2"><ci id="S3.E1.m1.30.30.30.30.30.30.1.1.cmml" xref="S3.E1.m1.30.30.30.30.30.30.1.1">ùëü</ci><apply id="S3.E1.m1.30.30.30.30.30.30.1.2.1.cmml" xref="S3.E1.m1.30.30.30.30.30.30.1.2.1"><lt id="S3.E1.m1.30.30.30.30.30.30.1.2.1.1.cmml" xref="S3.E1.m1.30.30.30.30.30.30.1.2.1.1"></lt><csymbol cd="latexml" id="S3.E1.m1.30.30.30.30.30.30.1.2.1.2.cmml" xref="S3.E1.m1.30.30.30.30.30.30.1.2.1.2">absent</csymbol><ci id="S3.E1.m1.30.30.30.30.30.30.1.2.1.3.cmml" xref="S3.E1.m1.30.30.30.30.30.30.1.2.1.3">ùëñ</ci></apply></list></apply></vector></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.34c">\begin{split}L_{doctor}(\theta;X_{t},X_{r})=-\sum^{L}_{i=1}logp_{\theta}(x_{i}%
,X_{t},X_{r,&lt;i}),\end{split}</annotation><annotation encoding="application/x-llamapun" id="S3.E1.m1.34d">start_ROW start_CELL italic_L start_POSTSUBSCRIPT italic_d italic_o italic_c italic_t italic_o italic_r end_POSTSUBSCRIPT ( italic_Œ∏ ; italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_X start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ) = - ‚àë start_POSTSUPERSCRIPT italic_L end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT italic_l italic_o italic_g italic_p start_POSTSUBSCRIPT italic_Œ∏ end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_X start_POSTSUBSCRIPT italic_r , &lt; italic_i end_POSTSUBSCRIPT ) , end_CELL end_ROW</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS2.p1.5">where <math alttext="\theta" class="ltx_Math" display="inline" id="S3.SS2.p1.1.m1.1"><semantics id="S3.SS2.p1.1.m1.1a"><mi id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml">Œ∏</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><ci id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">ùúÉ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">\theta</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.1.m1.1d">italic_Œ∏</annotation></semantics></math> represents the trainable parameters in the doctor agent, <math alttext="L" class="ltx_Math" display="inline" id="S3.SS2.p1.2.m2.1"><semantics id="S3.SS2.p1.2.m2.1a"><mi id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><ci id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1">ùêø</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">L</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.2.m2.1d">italic_L</annotation></semantics></math> represents the length of the generated sentence, <math alttext="X_{r}" class="ltx_Math" display="inline" id="S3.SS2.p1.3.m3.1"><semantics id="S3.SS2.p1.3.m3.1a"><msub id="S3.SS2.p1.3.m3.1.1" xref="S3.SS2.p1.3.m3.1.1.cmml"><mi id="S3.SS2.p1.3.m3.1.1.2" xref="S3.SS2.p1.3.m3.1.1.2.cmml">X</mi><mi id="S3.SS2.p1.3.m3.1.1.3" xref="S3.SS2.p1.3.m3.1.1.3.cmml">r</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.3.m3.1b"><apply id="S3.SS2.p1.3.m3.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.3.m3.1.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1">subscript</csymbol><ci id="S3.SS2.p1.3.m3.1.1.2.cmml" xref="S3.SS2.p1.3.m3.1.1.2">ùëã</ci><ci id="S3.SS2.p1.3.m3.1.1.3.cmml" xref="S3.SS2.p1.3.m3.1.1.3">ùëü</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.3.m3.1c">X_{r}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.3.m3.1d">italic_X start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT</annotation></semantics></math> represents the current prediction token, <math alttext="X_{t}" class="ltx_Math" display="inline" id="S3.SS2.p1.4.m4.1"><semantics id="S3.SS2.p1.4.m4.1a"><msub id="S3.SS2.p1.4.m4.1.1" xref="S3.SS2.p1.4.m4.1.1.cmml"><mi id="S3.SS2.p1.4.m4.1.1.2" xref="S3.SS2.p1.4.m4.1.1.2.cmml">X</mi><mi id="S3.SS2.p1.4.m4.1.1.3" xref="S3.SS2.p1.4.m4.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.4.m4.1b"><apply id="S3.SS2.p1.4.m4.1.1.cmml" xref="S3.SS2.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.4.m4.1.1.1.cmml" xref="S3.SS2.p1.4.m4.1.1">subscript</csymbol><ci id="S3.SS2.p1.4.m4.1.1.2.cmml" xref="S3.SS2.p1.4.m4.1.1.2">ùëã</ci><ci id="S3.SS2.p1.4.m4.1.1.3.cmml" xref="S3.SS2.p1.4.m4.1.1.3">ùë°</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.4.m4.1c">X_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.4.m4.1d">italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> represents the medical history as textual inputs, and <math alttext="X_{r,&lt;i}" class="ltx_Math" display="inline" id="S3.SS2.p1.5.m5.2"><semantics id="S3.SS2.p1.5.m5.2a"><msub id="S3.SS2.p1.5.m5.2.3" xref="S3.SS2.p1.5.m5.2.3.cmml"><mi id="S3.SS2.p1.5.m5.2.3.2" xref="S3.SS2.p1.5.m5.2.3.2.cmml">X</mi><mrow id="S3.SS2.p1.5.m5.2.2.2.2" xref="S3.SS2.p1.5.m5.2.2.2.3.cmml"><mi id="S3.SS2.p1.5.m5.1.1.1.1" xref="S3.SS2.p1.5.m5.1.1.1.1.cmml">r</mi><mo id="S3.SS2.p1.5.m5.2.2.2.2.2" xref="S3.SS2.p1.5.m5.2.2.2.3.cmml">,</mo><mrow id="S3.SS2.p1.5.m5.2.2.2.2.1" xref="S3.SS2.p1.5.m5.2.2.2.2.1.cmml"><mi id="S3.SS2.p1.5.m5.2.2.2.2.1.2" xref="S3.SS2.p1.5.m5.2.2.2.2.1.2.cmml"></mi><mo id="S3.SS2.p1.5.m5.2.2.2.2.1.1" xref="S3.SS2.p1.5.m5.2.2.2.2.1.1.cmml">&lt;</mo><mi id="S3.SS2.p1.5.m5.2.2.2.2.1.3" xref="S3.SS2.p1.5.m5.2.2.2.2.1.3.cmml">i</mi></mrow></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.5.m5.2b"><apply id="S3.SS2.p1.5.m5.2.3.cmml" xref="S3.SS2.p1.5.m5.2.3"><csymbol cd="ambiguous" id="S3.SS2.p1.5.m5.2.3.1.cmml" xref="S3.SS2.p1.5.m5.2.3">subscript</csymbol><ci id="S3.SS2.p1.5.m5.2.3.2.cmml" xref="S3.SS2.p1.5.m5.2.3.2">ùëã</ci><list id="S3.SS2.p1.5.m5.2.2.2.3.cmml" xref="S3.SS2.p1.5.m5.2.2.2.2"><ci id="S3.SS2.p1.5.m5.1.1.1.1.cmml" xref="S3.SS2.p1.5.m5.1.1.1.1">ùëü</ci><apply id="S3.SS2.p1.5.m5.2.2.2.2.1.cmml" xref="S3.SS2.p1.5.m5.2.2.2.2.1"><lt id="S3.SS2.p1.5.m5.2.2.2.2.1.1.cmml" xref="S3.SS2.p1.5.m5.2.2.2.2.1.1"></lt><csymbol cd="latexml" id="S3.SS2.p1.5.m5.2.2.2.2.1.2.cmml" xref="S3.SS2.p1.5.m5.2.2.2.2.1.2">absent</csymbol><ci id="S3.SS2.p1.5.m5.2.2.2.2.1.3.cmml" xref="S3.SS2.p1.5.m5.2.2.2.2.1.3">ùëñ</ci></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.5.m5.2c">X_{r,&lt;i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.5.m5.2d">italic_X start_POSTSUBSCRIPT italic_r , &lt; italic_i end_POSTSUBSCRIPT</annotation></semantics></math> represents the token before the predicted token.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Dialogue Recommendation System</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">We propose to design a dialogue recommendation system to perform query generation and selection. Compared with a single end-to-end doctor agent, the proposed dialogue recommendation system can perform a more calibrated query selection and finalization. As shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#S1.F2" title="Figure 2 ‚Ä£ 1 Introduction ‚Ä£ A Two-Stage Proactive Dialogue Generator for Efficient Clinical Information Collection Using Large Language Model"><span class="ltx_text ltx_ref_tag">2</span></a> (a), our recommendation system consists of two stages: query candidate generation and candidate ranking. This design allows us to fully explore the candidate query space and select the most relevant queries as the current response. Our candidate ranking algorithm pseudo code is shown in Algorithm <a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#alg1" title="Algorithm 1 ‚Ä£ 3.3 Dialogue Recommendation System ‚Ä£ 3 Methods ‚Ä£ A Two-Stage Proactive Dialogue Generator for Efficient Clinical Information Collection Using Large Language Model"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<div class="ltx_para" id="S3.SS3.p2">
<p class="ltx_p" id="S3.SS3.p2.4"><span class="ltx_text ltx_font_bold" id="S3.SS3.p2.4.1">Query Candidate Generation.</span> We let the patient agent initial the start of the dialogue. Based on patients‚Äô input, we let the doctor agent generate <math alttext="N" class="ltx_Math" display="inline" id="S3.SS3.p2.1.m1.1"><semantics id="S3.SS3.p2.1.m1.1a"><mi id="S3.SS3.p2.1.m1.1.1" xref="S3.SS3.p2.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.1.m1.1b"><ci id="S3.SS3.p2.1.m1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1">ùëÅ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.1.m1.1c">N</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.1.m1.1d">italic_N</annotation></semantics></math> queries as candidates. Then the patient agent generates a response for each dialogue <math alttext="n_{i}" class="ltx_Math" display="inline" id="S3.SS3.p2.2.m2.1"><semantics id="S3.SS3.p2.2.m2.1a"><msub id="S3.SS3.p2.2.m2.1.1" xref="S3.SS3.p2.2.m2.1.1.cmml"><mi id="S3.SS3.p2.2.m2.1.1.2" xref="S3.SS3.p2.2.m2.1.1.2.cmml">n</mi><mi id="S3.SS3.p2.2.m2.1.1.3" xref="S3.SS3.p2.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.2.m2.1b"><apply id="S3.SS3.p2.2.m2.1.1.cmml" xref="S3.SS3.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.2.m2.1.1.1.cmml" xref="S3.SS3.p2.2.m2.1.1">subscript</csymbol><ci id="S3.SS3.p2.2.m2.1.1.2.cmml" xref="S3.SS3.p2.2.m2.1.1.2">ùëõ</ci><ci id="S3.SS3.p2.2.m2.1.1.3.cmml" xref="S3.SS3.p2.2.m2.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.2.m2.1c">n_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.2.m2.1d">italic_n start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> in the queue, where <math alttext="i" class="ltx_Math" display="inline" id="S3.SS3.p2.3.m3.1"><semantics id="S3.SS3.p2.3.m3.1a"><mi id="S3.SS3.p2.3.m3.1.1" xref="S3.SS3.p2.3.m3.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.3.m3.1b"><ci id="S3.SS3.p2.3.m3.1.1.cmml" xref="S3.SS3.p2.3.m3.1.1">ùëñ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.3.m3.1c">i</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.3.m3.1d">italic_i</annotation></semantics></math> stands for the index of the dialogue. After that, we generate another <math alttext="N" class="ltx_Math" display="inline" id="S3.SS3.p2.4.m4.1"><semantics id="S3.SS3.p2.4.m4.1a"><mi id="S3.SS3.p2.4.m4.1.1" xref="S3.SS3.p2.4.m4.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.4.m4.1b"><ci id="S3.SS3.p2.4.m4.1.1.cmml" xref="S3.SS3.p2.4.m4.1.1">ùëÅ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.4.m4.1c">N</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.4.m4.1d">italic_N</annotation></semantics></math> candidate and select the optimal candidate based on the ranking score (detailed below). These steps are repeated until the patient agent stops to generate text.</p>
</div>
<div class="ltx_para" id="S3.SS3.p3">
<p class="ltx_p" id="S3.SS3.p3.1"><span class="ltx_text ltx_font_bold" id="S3.SS3.p3.1.1">Candidates Ranking.</span>
To calculate the ranking score, we use a pre-trained LLM to evaluate the quality of the candidates. The LLM is prompted to provide ranking scores within a range of 1 to 10 for multiple aspects. In this paper, we consider the correctness of logic and relevance to medical history, as the two aspects to evaluate the quality of the response generated by the doctor agent. The combination of the two scores is considered to be the final ranking score, with 20 indicating the best quality and 0 indicating the worst quality. <span class="ltx_text" id="S3.SS3.p3.1.2" style="color:#000000;">Note that our proposed ranking strategy overcomes the black box challenge in general LLM. During the process of candidate ranking, the potential candidates are listed and selected based on explicitly defined criteria, making our proposed solution transparent and explainable.</span> The prompts for ranking the candidates are shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#S2.F3" title="Figure 3 ‚Ä£ 2 Related Work ‚Ä£ A Two-Stage Proactive Dialogue Generator for Efficient Clinical Information Collection Using Large Language Model"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<figure class="ltx_float ltx_float_algorithm ltx_framed ltx_framed_top" id="alg1">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel" id="alg1.9">P: initial query or statement from the patient;
<math alttext="\mathcal{G}(\mathit{d},\mathit{N})" class="ltx_Math" display="inline" id="alg1.1.m1.2"><semantics id="alg1.1.m1.2a"><mrow id="alg1.1.m1.2.3" xref="alg1.1.m1.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="alg1.1.m1.2.3.2" xref="alg1.1.m1.2.3.2.cmml">ùí¢</mi><mo id="alg1.1.m1.2.3.1" xref="alg1.1.m1.2.3.1.cmml">‚Å¢</mo><mrow id="alg1.1.m1.2.3.3.2" xref="alg1.1.m1.2.3.3.1.cmml"><mo id="alg1.1.m1.2.3.3.2.1" stretchy="false" xref="alg1.1.m1.2.3.3.1.cmml">(</mo><mi id="alg1.1.m1.1.1" xref="alg1.1.m1.1.1.cmml">d</mi><mo id="alg1.1.m1.2.3.3.2.2" xref="alg1.1.m1.2.3.3.1.cmml">,</mo><mi id="alg1.1.m1.2.2" xref="alg1.1.m1.2.2.cmml">N</mi><mo id="alg1.1.m1.2.3.3.2.3" stretchy="false" xref="alg1.1.m1.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.1.m1.2b"><apply id="alg1.1.m1.2.3.cmml" xref="alg1.1.m1.2.3"><times id="alg1.1.m1.2.3.1.cmml" xref="alg1.1.m1.2.3.1"></times><ci id="alg1.1.m1.2.3.2.cmml" xref="alg1.1.m1.2.3.2">ùí¢</ci><interval closure="open" id="alg1.1.m1.2.3.3.1.cmml" xref="alg1.1.m1.2.3.3.2"><ci id="alg1.1.m1.1.1.cmml" xref="alg1.1.m1.1.1">ùëë</ci><ci id="alg1.1.m1.2.2.cmml" xref="alg1.1.m1.2.2">ùëÅ</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.1.m1.2c">\mathcal{G}(\mathit{d},\mathit{N})</annotation><annotation encoding="application/x-llamapun" id="alg1.1.m1.2d">caligraphic_G ( italic_d , italic_N )</annotation></semantics></math>:
Dialogue generator;
<math alttext="\mathcal{S}_{i}" class="ltx_Math" display="inline" id="alg1.2.m2.1"><semantics id="alg1.2.m2.1a"><msub id="alg1.2.m2.1.1" xref="alg1.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="alg1.2.m2.1.1.2" xref="alg1.2.m2.1.1.2.cmml">ùíÆ</mi><mi id="alg1.2.m2.1.1.3" xref="alg1.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.2.m2.1b"><apply id="alg1.2.m2.1.1.cmml" xref="alg1.2.m2.1.1"><csymbol cd="ambiguous" id="alg1.2.m2.1.1.1.cmml" xref="alg1.2.m2.1.1">subscript</csymbol><ci id="alg1.2.m2.1.1.2.cmml" xref="alg1.2.m2.1.1.2">ùíÆ</ci><ci id="alg1.2.m2.1.1.3.cmml" xref="alg1.2.m2.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.2.m2.1c">\mathcal{S}_{i}</annotation><annotation encoding="application/x-llamapun" id="alg1.2.m2.1d">caligraphic_S start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>: dialogues sequences after <math alttext="i" class="ltx_Math" display="inline" id="alg1.3.m3.1"><semantics id="alg1.3.m3.1a"><mi id="alg1.3.m3.1.1" xref="alg1.3.m3.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="alg1.3.m3.1b"><ci id="alg1.3.m3.1.1.cmml" xref="alg1.3.m3.1.1">ùëñ</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.3.m3.1c">i</annotation><annotation encoding="application/x-llamapun" id="alg1.3.m3.1d">italic_i</annotation></semantics></math> rounds of selection; <math alttext="\mathit{N}" class="ltx_Math" display="inline" id="alg1.4.m4.1"><semantics id="alg1.4.m4.1a"><mi id="alg1.4.m4.1.1" xref="alg1.4.m4.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="alg1.4.m4.1b"><ci id="alg1.4.m4.1.1.cmml" xref="alg1.4.m4.1.1">ùëÅ</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.4.m4.1c">\mathit{N}</annotation><annotation encoding="application/x-llamapun" id="alg1.4.m4.1d">italic_N</annotation></semantics></math>: number of responses;
<math alttext="\mathit{I}" class="ltx_Math" display="inline" id="alg1.5.m5.1"><semantics id="alg1.5.m5.1a"><mi id="alg1.5.m5.1.1" xref="alg1.5.m5.1.1.cmml">I</mi><annotation-xml encoding="MathML-Content" id="alg1.5.m5.1b"><ci id="alg1.5.m5.1.1.cmml" xref="alg1.5.m5.1.1">ùêº</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.5.m5.1c">\mathit{I}</annotation><annotation encoding="application/x-llamapun" id="alg1.5.m5.1d">italic_I</annotation></semantics></math>: number of rounds; <math alttext="\mathcal{R}(\mathit{d})" class="ltx_Math" display="inline" id="alg1.6.m6.1"><semantics id="alg1.6.m6.1a"><mrow id="alg1.6.m6.1.2" xref="alg1.6.m6.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="alg1.6.m6.1.2.2" xref="alg1.6.m6.1.2.2.cmml">‚Ñõ</mi><mo id="alg1.6.m6.1.2.1" xref="alg1.6.m6.1.2.1.cmml">‚Å¢</mo><mrow id="alg1.6.m6.1.2.3.2" xref="alg1.6.m6.1.2.cmml"><mo id="alg1.6.m6.1.2.3.2.1" stretchy="false" xref="alg1.6.m6.1.2.cmml">(</mo><mi id="alg1.6.m6.1.1" xref="alg1.6.m6.1.1.cmml">d</mi><mo id="alg1.6.m6.1.2.3.2.2" stretchy="false" xref="alg1.6.m6.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.6.m6.1b"><apply id="alg1.6.m6.1.2.cmml" xref="alg1.6.m6.1.2"><times id="alg1.6.m6.1.2.1.cmml" xref="alg1.6.m6.1.2.1"></times><ci id="alg1.6.m6.1.2.2.cmml" xref="alg1.6.m6.1.2.2">‚Ñõ</ci><ci id="alg1.6.m6.1.1.cmml" xref="alg1.6.m6.1.1">ùëë</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.6.m6.1c">\mathcal{R}(\mathit{d})</annotation><annotation encoding="application/x-llamapun" id="alg1.6.m6.1d">caligraphic_R ( italic_d )</annotation></semantics></math>: LLM ranking model; <math alttext="\mathcal{V}_{\text{final}}" class="ltx_Math" display="inline" id="alg1.7.m7.1"><semantics id="alg1.7.m7.1a"><msub id="alg1.7.m7.1.1" xref="alg1.7.m7.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="alg1.7.m7.1.1.2" xref="alg1.7.m7.1.1.2.cmml">ùí±</mi><mtext id="alg1.7.m7.1.1.3" xref="alg1.7.m7.1.1.3a.cmml">final</mtext></msub><annotation-xml encoding="MathML-Content" id="alg1.7.m7.1b"><apply id="alg1.7.m7.1.1.cmml" xref="alg1.7.m7.1.1"><csymbol cd="ambiguous" id="alg1.7.m7.1.1.1.cmml" xref="alg1.7.m7.1.1">subscript</csymbol><ci id="alg1.7.m7.1.1.2.cmml" xref="alg1.7.m7.1.1.2">ùí±</ci><ci id="alg1.7.m7.1.1.3a.cmml" xref="alg1.7.m7.1.1.3"><mtext id="alg1.7.m7.1.1.3.cmml" mathsize="70%" xref="alg1.7.m7.1.1.3">final</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.7.m7.1c">\mathcal{V}_{\text{final}}</annotation><annotation encoding="application/x-llamapun" id="alg1.7.m7.1d">caligraphic_V start_POSTSUBSCRIPT final end_POSTSUBSCRIPT</annotation></semantics></math>:
scores assigned to all dialogues <math alttext="\mathcal{D}" class="ltx_Math" display="inline" id="alg1.8.m8.1"><semantics id="alg1.8.m8.1a"><mi class="ltx_font_mathcaligraphic" id="alg1.8.m8.1.1" xref="alg1.8.m8.1.1.cmml">ùíü</mi><annotation-xml encoding="MathML-Content" id="alg1.8.m8.1b"><ci id="alg1.8.m8.1.1.cmml" xref="alg1.8.m8.1.1">ùíü</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.8.m8.1c">\mathcal{D}</annotation><annotation encoding="application/x-llamapun" id="alg1.8.m8.1d">caligraphic_D</annotation></semantics></math>; <math alttext="\mathcal{D}_{\text{best}}" class="ltx_Math" display="inline" id="alg1.9.m9.1"><semantics id="alg1.9.m9.1a"><msub id="alg1.9.m9.1.1" xref="alg1.9.m9.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="alg1.9.m9.1.1.2" xref="alg1.9.m9.1.1.2.cmml">ùíü</mi><mtext id="alg1.9.m9.1.1.3" xref="alg1.9.m9.1.1.3a.cmml">best</mtext></msub><annotation-xml encoding="MathML-Content" id="alg1.9.m9.1b"><apply id="alg1.9.m9.1.1.cmml" xref="alg1.9.m9.1.1"><csymbol cd="ambiguous" id="alg1.9.m9.1.1.1.cmml" xref="alg1.9.m9.1.1">subscript</csymbol><ci id="alg1.9.m9.1.1.2.cmml" xref="alg1.9.m9.1.1.2">ùíü</ci><ci id="alg1.9.m9.1.1.3a.cmml" xref="alg1.9.m9.1.1.3"><mtext id="alg1.9.m9.1.1.3.cmml" mathsize="70%" xref="alg1.9.m9.1.1.3">best</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.9.m9.1c">\mathcal{D}_{\text{best}}</annotation><annotation encoding="application/x-llamapun" id="alg1.9.m9.1d">caligraphic_D start_POSTSUBSCRIPT best end_POSTSUBSCRIPT</annotation></semantics></math>: optimal dialogue selected</p>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span class="ltx_text ltx_font_bold" id="alg1.11.1.1">Algorithm 1</span> </span> The candidate ranking algorithm</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_listing ltx_figure_panel ltx_listing" id="alg1.12">
<div class="ltx_listingline" id="alg1.l1">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l1.2.1.1" style="font-size:80%;">1:</span></span><math alttext="\mathbf{D}\leftarrow[\mathbf{P}]" class="ltx_Math" display="inline" id="alg1.l1.m1.1"><semantics id="alg1.l1.m1.1a"><mrow id="alg1.l1.m1.1.2" xref="alg1.l1.m1.1.2.cmml"><mi id="alg1.l1.m1.1.2.2" xref="alg1.l1.m1.1.2.2.cmml">ùêÉ</mi><mo id="alg1.l1.m1.1.2.1" stretchy="false" xref="alg1.l1.m1.1.2.1.cmml">‚Üê</mo><mrow id="alg1.l1.m1.1.2.3.2" xref="alg1.l1.m1.1.2.3.1.cmml"><mo id="alg1.l1.m1.1.2.3.2.1" stretchy="false" xref="alg1.l1.m1.1.2.3.1.1.cmml">[</mo><mi id="alg1.l1.m1.1.1" xref="alg1.l1.m1.1.1.cmml">ùêè</mi><mo id="alg1.l1.m1.1.2.3.2.2" stretchy="false" xref="alg1.l1.m1.1.2.3.1.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l1.m1.1b"><apply id="alg1.l1.m1.1.2.cmml" xref="alg1.l1.m1.1.2"><ci id="alg1.l1.m1.1.2.1.cmml" xref="alg1.l1.m1.1.2.1">‚Üê</ci><ci id="alg1.l1.m1.1.2.2.cmml" xref="alg1.l1.m1.1.2.2">ùêÉ</ci><apply id="alg1.l1.m1.1.2.3.1.cmml" xref="alg1.l1.m1.1.2.3.2"><csymbol cd="latexml" id="alg1.l1.m1.1.2.3.1.1.cmml" xref="alg1.l1.m1.1.2.3.2.1">delimited-[]</csymbol><ci id="alg1.l1.m1.1.1.cmml" xref="alg1.l1.m1.1.1">ùêè</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m1.1c">\mathbf{D}\leftarrow[\mathbf{P}]</annotation><annotation encoding="application/x-llamapun" id="alg1.l1.m1.1d">bold_D ‚Üê [ bold_P ]</annotation></semantics></math> <span class="ltx_text" id="alg1.l1.1" style="float:right;"><math alttext="\triangleright" class="ltx_Math" display="inline" id="alg1.l1.1.m1.1"><semantics id="alg1.l1.1.m1.1a"><mo id="alg1.l1.1.m1.1.1" xref="alg1.l1.1.m1.1.1.cmml">‚ñ∑</mo><annotation-xml encoding="MathML-Content" id="alg1.l1.1.m1.1b"><ci id="alg1.l1.1.m1.1.1.cmml" xref="alg1.l1.1.m1.1.1">‚ñ∑</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.1.m1.1c">\triangleright</annotation><annotation encoding="application/x-llamapun" id="alg1.l1.1.m1.1d">‚ñ∑</annotation></semantics></math> Initialize the dialogue with the patient query
</span>
</div>
<div class="ltx_listingline" id="alg1.l2">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l2.1.1.1" style="font-size:80%;">2:</span></span>Generate initial <math alttext="\mathbf{N}" class="ltx_Math" display="inline" id="alg1.l2.m1.1"><semantics id="alg1.l2.m1.1a"><mi id="alg1.l2.m1.1.1" xref="alg1.l2.m1.1.1.cmml">ùêç</mi><annotation-xml encoding="MathML-Content" id="alg1.l2.m1.1b"><ci id="alg1.l2.m1.1.1.cmml" xref="alg1.l2.m1.1.1">ùêç</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l2.m1.1c">\mathbf{N}</annotation><annotation encoding="application/x-llamapun" id="alg1.l2.m1.1d">bold_N</annotation></semantics></math> responses: <math alttext="\mathbf{S}_{1}\leftarrow G(\mathbf{P},\mathbf{N})" class="ltx_Math" display="inline" id="alg1.l2.m2.2"><semantics id="alg1.l2.m2.2a"><mrow id="alg1.l2.m2.2.3" xref="alg1.l2.m2.2.3.cmml"><msub id="alg1.l2.m2.2.3.2" xref="alg1.l2.m2.2.3.2.cmml"><mi id="alg1.l2.m2.2.3.2.2" xref="alg1.l2.m2.2.3.2.2.cmml">ùêí</mi><mn id="alg1.l2.m2.2.3.2.3" xref="alg1.l2.m2.2.3.2.3.cmml">1</mn></msub><mo id="alg1.l2.m2.2.3.1" stretchy="false" xref="alg1.l2.m2.2.3.1.cmml">‚Üê</mo><mrow id="alg1.l2.m2.2.3.3" xref="alg1.l2.m2.2.3.3.cmml"><mi id="alg1.l2.m2.2.3.3.2" xref="alg1.l2.m2.2.3.3.2.cmml">G</mi><mo id="alg1.l2.m2.2.3.3.1" xref="alg1.l2.m2.2.3.3.1.cmml">‚Å¢</mo><mrow id="alg1.l2.m2.2.3.3.3.2" xref="alg1.l2.m2.2.3.3.3.1.cmml"><mo id="alg1.l2.m2.2.3.3.3.2.1" stretchy="false" xref="alg1.l2.m2.2.3.3.3.1.cmml">(</mo><mi id="alg1.l2.m2.1.1" xref="alg1.l2.m2.1.1.cmml">ùêè</mi><mo id="alg1.l2.m2.2.3.3.3.2.2" xref="alg1.l2.m2.2.3.3.3.1.cmml">,</mo><mi id="alg1.l2.m2.2.2" xref="alg1.l2.m2.2.2.cmml">ùêç</mi><mo id="alg1.l2.m2.2.3.3.3.2.3" stretchy="false" xref="alg1.l2.m2.2.3.3.3.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l2.m2.2b"><apply id="alg1.l2.m2.2.3.cmml" xref="alg1.l2.m2.2.3"><ci id="alg1.l2.m2.2.3.1.cmml" xref="alg1.l2.m2.2.3.1">‚Üê</ci><apply id="alg1.l2.m2.2.3.2.cmml" xref="alg1.l2.m2.2.3.2"><csymbol cd="ambiguous" id="alg1.l2.m2.2.3.2.1.cmml" xref="alg1.l2.m2.2.3.2">subscript</csymbol><ci id="alg1.l2.m2.2.3.2.2.cmml" xref="alg1.l2.m2.2.3.2.2">ùêí</ci><cn id="alg1.l2.m2.2.3.2.3.cmml" type="integer" xref="alg1.l2.m2.2.3.2.3">1</cn></apply><apply id="alg1.l2.m2.2.3.3.cmml" xref="alg1.l2.m2.2.3.3"><times id="alg1.l2.m2.2.3.3.1.cmml" xref="alg1.l2.m2.2.3.3.1"></times><ci id="alg1.l2.m2.2.3.3.2.cmml" xref="alg1.l2.m2.2.3.3.2">ùê∫</ci><interval closure="open" id="alg1.l2.m2.2.3.3.3.1.cmml" xref="alg1.l2.m2.2.3.3.3.2"><ci id="alg1.l2.m2.1.1.cmml" xref="alg1.l2.m2.1.1">ùêè</ci><ci id="alg1.l2.m2.2.2.cmml" xref="alg1.l2.m2.2.2">ùêç</ci></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l2.m2.2c">\mathbf{S}_{1}\leftarrow G(\mathbf{P},\mathbf{N})</annotation><annotation encoding="application/x-llamapun" id="alg1.l2.m2.2d">bold_S start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ‚Üê italic_G ( bold_P , bold_N )</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg1.l3">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l3.1.1.1" style="font-size:80%;">3:</span></span><span class="ltx_text ltx_font_bold" id="alg1.l3.2">for</span>¬†<math alttext="i=2,\ldots,\mathbf{I}" class="ltx_Math" display="inline" id="alg1.l3.m1.3"><semantics id="alg1.l3.m1.3a"><mrow id="alg1.l3.m1.3.4" xref="alg1.l3.m1.3.4.cmml"><mi id="alg1.l3.m1.3.4.2" xref="alg1.l3.m1.3.4.2.cmml">i</mi><mo id="alg1.l3.m1.3.4.1" xref="alg1.l3.m1.3.4.1.cmml">=</mo><mrow id="alg1.l3.m1.3.4.3.2" xref="alg1.l3.m1.3.4.3.1.cmml"><mn id="alg1.l3.m1.1.1" xref="alg1.l3.m1.1.1.cmml">2</mn><mo id="alg1.l3.m1.3.4.3.2.1" xref="alg1.l3.m1.3.4.3.1.cmml">,</mo><mi id="alg1.l3.m1.2.2" mathvariant="normal" xref="alg1.l3.m1.2.2.cmml">‚Ä¶</mi><mo id="alg1.l3.m1.3.4.3.2.2" xref="alg1.l3.m1.3.4.3.1.cmml">,</mo><mi id="alg1.l3.m1.3.3" xref="alg1.l3.m1.3.3.cmml">ùêà</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l3.m1.3b"><apply id="alg1.l3.m1.3.4.cmml" xref="alg1.l3.m1.3.4"><eq id="alg1.l3.m1.3.4.1.cmml" xref="alg1.l3.m1.3.4.1"></eq><ci id="alg1.l3.m1.3.4.2.cmml" xref="alg1.l3.m1.3.4.2">ùëñ</ci><list id="alg1.l3.m1.3.4.3.1.cmml" xref="alg1.l3.m1.3.4.3.2"><cn id="alg1.l3.m1.1.1.cmml" type="integer" xref="alg1.l3.m1.1.1">2</cn><ci id="alg1.l3.m1.2.2.cmml" xref="alg1.l3.m1.2.2">‚Ä¶</ci><ci id="alg1.l3.m1.3.3.cmml" xref="alg1.l3.m1.3.3">ùêà</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l3.m1.3c">i=2,\ldots,\mathbf{I}</annotation><annotation encoding="application/x-llamapun" id="alg1.l3.m1.3d">italic_i = 2 , ‚Ä¶ , bold_I</annotation></semantics></math>¬†<span class="ltx_text ltx_font_bold" id="alg1.l3.3">do</span>
</div>
<div class="ltx_listingline" id="alg1.l4">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l4.1.1.1" style="font-size:80%;">4:</span></span>¬†¬†¬†¬†¬†<math alttext="\mathbf{S}_{i}\leftarrow\{\}" class="ltx_Math" display="inline" id="alg1.l4.m1.1"><semantics id="alg1.l4.m1.1a"><mrow id="alg1.l4.m1.1.1" xref="alg1.l4.m1.1.1.cmml"><msub id="alg1.l4.m1.1.1.2" xref="alg1.l4.m1.1.1.2.cmml"><mi id="alg1.l4.m1.1.1.2.2" xref="alg1.l4.m1.1.1.2.2.cmml">ùêí</mi><mi id="alg1.l4.m1.1.1.2.3" xref="alg1.l4.m1.1.1.2.3.cmml">i</mi></msub><mo id="alg1.l4.m1.1.1.1" stretchy="false" xref="alg1.l4.m1.1.1.1.cmml">‚Üê</mo><mrow id="alg1.l4.m1.1.1.3.2" xref="alg1.l4.m1.1.1.cmml"><mo id="alg1.l4.m1.1.1.3.2.1" stretchy="false" xref="alg1.l4.m1.1.1.3.1.cmml">{</mo><mo id="alg1.l4.m1.1.1.3.2.2" stretchy="false" xref="alg1.l4.m1.1.1.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l4.m1.1b"><apply id="alg1.l4.m1.1.1.cmml" xref="alg1.l4.m1.1.1"><ci id="alg1.l4.m1.1.1.1.cmml" xref="alg1.l4.m1.1.1.1">‚Üê</ci><apply id="alg1.l4.m1.1.1.2.cmml" xref="alg1.l4.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.l4.m1.1.1.2.1.cmml" xref="alg1.l4.m1.1.1.2">subscript</csymbol><ci id="alg1.l4.m1.1.1.2.2.cmml" xref="alg1.l4.m1.1.1.2.2">ùêí</ci><ci id="alg1.l4.m1.1.1.2.3.cmml" xref="alg1.l4.m1.1.1.2.3">ùëñ</ci></apply><list id="alg1.l4.m1.1.1.3.1.cmml" xref="alg1.l4.m1.1.1.3.2.1"></list></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l4.m1.1c">\mathbf{S}_{i}\leftarrow\{\}</annotation><annotation encoding="application/x-llamapun" id="alg1.l4.m1.1d">bold_S start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ‚Üê { }</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg1.l5">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l5.1.1.1" style="font-size:80%;">5:</span></span>¬†¬†¬†¬†¬†<span class="ltx_text ltx_font_bold" id="alg1.l5.2">for</span>¬†<math alttext="t=1,\ldots,\mathbf{N}" class="ltx_Math" display="inline" id="alg1.l5.m1.3"><semantics id="alg1.l5.m1.3a"><mrow id="alg1.l5.m1.3.4" xref="alg1.l5.m1.3.4.cmml"><mi id="alg1.l5.m1.3.4.2" xref="alg1.l5.m1.3.4.2.cmml">t</mi><mo id="alg1.l5.m1.3.4.1" xref="alg1.l5.m1.3.4.1.cmml">=</mo><mrow id="alg1.l5.m1.3.4.3.2" xref="alg1.l5.m1.3.4.3.1.cmml"><mn id="alg1.l5.m1.1.1" xref="alg1.l5.m1.1.1.cmml">1</mn><mo id="alg1.l5.m1.3.4.3.2.1" xref="alg1.l5.m1.3.4.3.1.cmml">,</mo><mi id="alg1.l5.m1.2.2" mathvariant="normal" xref="alg1.l5.m1.2.2.cmml">‚Ä¶</mi><mo id="alg1.l5.m1.3.4.3.2.2" xref="alg1.l5.m1.3.4.3.1.cmml">,</mo><mi id="alg1.l5.m1.3.3" xref="alg1.l5.m1.3.3.cmml">ùêç</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l5.m1.3b"><apply id="alg1.l5.m1.3.4.cmml" xref="alg1.l5.m1.3.4"><eq id="alg1.l5.m1.3.4.1.cmml" xref="alg1.l5.m1.3.4.1"></eq><ci id="alg1.l5.m1.3.4.2.cmml" xref="alg1.l5.m1.3.4.2">ùë°</ci><list id="alg1.l5.m1.3.4.3.1.cmml" xref="alg1.l5.m1.3.4.3.2"><cn id="alg1.l5.m1.1.1.cmml" type="integer" xref="alg1.l5.m1.1.1">1</cn><ci id="alg1.l5.m1.2.2.cmml" xref="alg1.l5.m1.2.2">‚Ä¶</ci><ci id="alg1.l5.m1.3.3.cmml" xref="alg1.l5.m1.3.3">ùêç</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l5.m1.3c">t=1,\ldots,\mathbf{N}</annotation><annotation encoding="application/x-llamapun" id="alg1.l5.m1.3d">italic_t = 1 , ‚Ä¶ , bold_N</annotation></semantics></math>¬†<span class="ltx_text ltx_font_bold" id="alg1.l5.3">do</span>
</div>
<div class="ltx_listingline" id="alg1.l6">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l6.1.1.1" style="font-size:80%;">6:</span></span>¬†¬†¬†¬†¬†¬†¬†¬†¬†Generate <math alttext="\mathbf{N}" class="ltx_Math" display="inline" id="alg1.l6.m1.1"><semantics id="alg1.l6.m1.1a"><mi id="alg1.l6.m1.1.1" xref="alg1.l6.m1.1.1.cmml">ùêç</mi><annotation-xml encoding="MathML-Content" id="alg1.l6.m1.1b"><ci id="alg1.l6.m1.1.1.cmml" xref="alg1.l6.m1.1.1">ùêç</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l6.m1.1c">\mathbf{N}</annotation><annotation encoding="application/x-llamapun" id="alg1.l6.m1.1d">bold_N</annotation></semantics></math> responses for each candidate in <math alttext="\mathbf{S}_{i-1,t}" class="ltx_Math" display="inline" id="alg1.l6.m2.2"><semantics id="alg1.l6.m2.2a"><msub id="alg1.l6.m2.2.3" xref="alg1.l6.m2.2.3.cmml"><mi id="alg1.l6.m2.2.3.2" xref="alg1.l6.m2.2.3.2.cmml">ùêí</mi><mrow id="alg1.l6.m2.2.2.2.2" xref="alg1.l6.m2.2.2.2.3.cmml"><mrow id="alg1.l6.m2.2.2.2.2.1" xref="alg1.l6.m2.2.2.2.2.1.cmml"><mi id="alg1.l6.m2.2.2.2.2.1.2" xref="alg1.l6.m2.2.2.2.2.1.2.cmml">i</mi><mo id="alg1.l6.m2.2.2.2.2.1.1" xref="alg1.l6.m2.2.2.2.2.1.1.cmml">‚àí</mo><mn id="alg1.l6.m2.2.2.2.2.1.3" xref="alg1.l6.m2.2.2.2.2.1.3.cmml">1</mn></mrow><mo id="alg1.l6.m2.2.2.2.2.2" xref="alg1.l6.m2.2.2.2.3.cmml">,</mo><mi id="alg1.l6.m2.1.1.1.1" xref="alg1.l6.m2.1.1.1.1.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="alg1.l6.m2.2b"><apply id="alg1.l6.m2.2.3.cmml" xref="alg1.l6.m2.2.3"><csymbol cd="ambiguous" id="alg1.l6.m2.2.3.1.cmml" xref="alg1.l6.m2.2.3">subscript</csymbol><ci id="alg1.l6.m2.2.3.2.cmml" xref="alg1.l6.m2.2.3.2">ùêí</ci><list id="alg1.l6.m2.2.2.2.3.cmml" xref="alg1.l6.m2.2.2.2.2"><apply id="alg1.l6.m2.2.2.2.2.1.cmml" xref="alg1.l6.m2.2.2.2.2.1"><minus id="alg1.l6.m2.2.2.2.2.1.1.cmml" xref="alg1.l6.m2.2.2.2.2.1.1"></minus><ci id="alg1.l6.m2.2.2.2.2.1.2.cmml" xref="alg1.l6.m2.2.2.2.2.1.2">ùëñ</ci><cn id="alg1.l6.m2.2.2.2.2.1.3.cmml" type="integer" xref="alg1.l6.m2.2.2.2.2.1.3">1</cn></apply><ci id="alg1.l6.m2.1.1.1.1.cmml" xref="alg1.l6.m2.1.1.1.1">ùë°</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l6.m2.2c">\mathbf{S}_{i-1,t}</annotation><annotation encoding="application/x-llamapun" id="alg1.l6.m2.2d">bold_S start_POSTSUBSCRIPT italic_i - 1 , italic_t end_POSTSUBSCRIPT</annotation></semantics></math>:

</div>
<div class="ltx_listingline" id="alg1.l7">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l7.1.1.1" style="font-size:80%;">7:</span></span>¬†¬†¬†¬†¬†¬†¬†¬†¬†<math alttext="\mathbf{S}^{\prime}_{i,t}\leftarrow\{[\mathbf{d},\mathbf{z}]\mid\mathbf{d}\in%
\mathbf{S}_{i-1},\mathbf{z}\in G(\mathbf{d},1)\}" class="ltx_Math" display="inline" id="alg1.l7.m1.8"><semantics id="alg1.l7.m1.8a"><mrow id="alg1.l7.m1.8.8" xref="alg1.l7.m1.8.8.cmml"><msubsup id="alg1.l7.m1.8.8.4" xref="alg1.l7.m1.8.8.4.cmml"><mi id="alg1.l7.m1.8.8.4.2.2" xref="alg1.l7.m1.8.8.4.2.2.cmml">ùêí</mi><mrow id="alg1.l7.m1.2.2.2.4" xref="alg1.l7.m1.2.2.2.3.cmml"><mi id="alg1.l7.m1.1.1.1.1" xref="alg1.l7.m1.1.1.1.1.cmml">i</mi><mo id="alg1.l7.m1.2.2.2.4.1" xref="alg1.l7.m1.2.2.2.3.cmml">,</mo><mi id="alg1.l7.m1.2.2.2.2" xref="alg1.l7.m1.2.2.2.2.cmml">t</mi></mrow><mo id="alg1.l7.m1.8.8.4.2.3" xref="alg1.l7.m1.8.8.4.2.3.cmml">‚Ä≤</mo></msubsup><mo id="alg1.l7.m1.8.8.3" stretchy="false" xref="alg1.l7.m1.8.8.3.cmml">‚Üê</mo><mrow id="alg1.l7.m1.8.8.2.2" xref="alg1.l7.m1.8.8.2.3.cmml"><mo id="alg1.l7.m1.8.8.2.2.3" stretchy="false" xref="alg1.l7.m1.8.8.2.3.1.cmml">{</mo><mrow id="alg1.l7.m1.7.7.1.1.1.2" xref="alg1.l7.m1.7.7.1.1.1.1.cmml"><mo id="alg1.l7.m1.7.7.1.1.1.2.1" stretchy="false" xref="alg1.l7.m1.7.7.1.1.1.1.cmml">[</mo><mi id="alg1.l7.m1.3.3" xref="alg1.l7.m1.3.3.cmml">ùêù</mi><mo id="alg1.l7.m1.7.7.1.1.1.2.2" xref="alg1.l7.m1.7.7.1.1.1.1.cmml">,</mo><mi id="alg1.l7.m1.4.4" xref="alg1.l7.m1.4.4.cmml">ùê≥</mi><mo id="alg1.l7.m1.7.7.1.1.1.2.3" stretchy="false" xref="alg1.l7.m1.7.7.1.1.1.1.cmml">]</mo></mrow><mo fence="true" id="alg1.l7.m1.8.8.2.2.4" lspace="0em" rspace="0em" xref="alg1.l7.m1.8.8.2.3.1.cmml">‚à£</mo><mrow id="alg1.l7.m1.8.8.2.2.2.2" xref="alg1.l7.m1.8.8.2.2.2.3.cmml"><mrow id="alg1.l7.m1.8.8.2.2.2.1.1" xref="alg1.l7.m1.8.8.2.2.2.1.1.cmml"><mi id="alg1.l7.m1.8.8.2.2.2.1.1.2" xref="alg1.l7.m1.8.8.2.2.2.1.1.2.cmml">ùêù</mi><mo id="alg1.l7.m1.8.8.2.2.2.1.1.1" xref="alg1.l7.m1.8.8.2.2.2.1.1.1.cmml">‚àà</mo><msub id="alg1.l7.m1.8.8.2.2.2.1.1.3" xref="alg1.l7.m1.8.8.2.2.2.1.1.3.cmml"><mi id="alg1.l7.m1.8.8.2.2.2.1.1.3.2" xref="alg1.l7.m1.8.8.2.2.2.1.1.3.2.cmml">ùêí</mi><mrow id="alg1.l7.m1.8.8.2.2.2.1.1.3.3" xref="alg1.l7.m1.8.8.2.2.2.1.1.3.3.cmml"><mi id="alg1.l7.m1.8.8.2.2.2.1.1.3.3.2" xref="alg1.l7.m1.8.8.2.2.2.1.1.3.3.2.cmml">i</mi><mo id="alg1.l7.m1.8.8.2.2.2.1.1.3.3.1" xref="alg1.l7.m1.8.8.2.2.2.1.1.3.3.1.cmml">‚àí</mo><mn id="alg1.l7.m1.8.8.2.2.2.1.1.3.3.3" xref="alg1.l7.m1.8.8.2.2.2.1.1.3.3.3.cmml">1</mn></mrow></msub></mrow><mo id="alg1.l7.m1.8.8.2.2.2.2.3" xref="alg1.l7.m1.8.8.2.2.2.3a.cmml">,</mo><mrow id="alg1.l7.m1.8.8.2.2.2.2.2" xref="alg1.l7.m1.8.8.2.2.2.2.2.cmml"><mi id="alg1.l7.m1.8.8.2.2.2.2.2.2" xref="alg1.l7.m1.8.8.2.2.2.2.2.2.cmml">ùê≥</mi><mo id="alg1.l7.m1.8.8.2.2.2.2.2.1" xref="alg1.l7.m1.8.8.2.2.2.2.2.1.cmml">‚àà</mo><mrow id="alg1.l7.m1.8.8.2.2.2.2.2.3" xref="alg1.l7.m1.8.8.2.2.2.2.2.3.cmml"><mi id="alg1.l7.m1.8.8.2.2.2.2.2.3.2" xref="alg1.l7.m1.8.8.2.2.2.2.2.3.2.cmml">G</mi><mo id="alg1.l7.m1.8.8.2.2.2.2.2.3.1" xref="alg1.l7.m1.8.8.2.2.2.2.2.3.1.cmml">‚Å¢</mo><mrow id="alg1.l7.m1.8.8.2.2.2.2.2.3.3.2" xref="alg1.l7.m1.8.8.2.2.2.2.2.3.3.1.cmml"><mo id="alg1.l7.m1.8.8.2.2.2.2.2.3.3.2.1" stretchy="false" xref="alg1.l7.m1.8.8.2.2.2.2.2.3.3.1.cmml">(</mo><mi id="alg1.l7.m1.5.5" xref="alg1.l7.m1.5.5.cmml">ùêù</mi><mo id="alg1.l7.m1.8.8.2.2.2.2.2.3.3.2.2" xref="alg1.l7.m1.8.8.2.2.2.2.2.3.3.1.cmml">,</mo><mn id="alg1.l7.m1.6.6" xref="alg1.l7.m1.6.6.cmml">1</mn><mo id="alg1.l7.m1.8.8.2.2.2.2.2.3.3.2.3" stretchy="false" xref="alg1.l7.m1.8.8.2.2.2.2.2.3.3.1.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="alg1.l7.m1.8.8.2.2.5" stretchy="false" xref="alg1.l7.m1.8.8.2.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l7.m1.8b"><apply id="alg1.l7.m1.8.8.cmml" xref="alg1.l7.m1.8.8"><ci id="alg1.l7.m1.8.8.3.cmml" xref="alg1.l7.m1.8.8.3">‚Üê</ci><apply id="alg1.l7.m1.8.8.4.cmml" xref="alg1.l7.m1.8.8.4"><csymbol cd="ambiguous" id="alg1.l7.m1.8.8.4.1.cmml" xref="alg1.l7.m1.8.8.4">subscript</csymbol><apply id="alg1.l7.m1.8.8.4.2.cmml" xref="alg1.l7.m1.8.8.4"><csymbol cd="ambiguous" id="alg1.l7.m1.8.8.4.2.1.cmml" xref="alg1.l7.m1.8.8.4">superscript</csymbol><ci id="alg1.l7.m1.8.8.4.2.2.cmml" xref="alg1.l7.m1.8.8.4.2.2">ùêí</ci><ci id="alg1.l7.m1.8.8.4.2.3.cmml" xref="alg1.l7.m1.8.8.4.2.3">‚Ä≤</ci></apply><list id="alg1.l7.m1.2.2.2.3.cmml" xref="alg1.l7.m1.2.2.2.4"><ci id="alg1.l7.m1.1.1.1.1.cmml" xref="alg1.l7.m1.1.1.1.1">ùëñ</ci><ci id="alg1.l7.m1.2.2.2.2.cmml" xref="alg1.l7.m1.2.2.2.2">ùë°</ci></list></apply><apply id="alg1.l7.m1.8.8.2.3.cmml" xref="alg1.l7.m1.8.8.2.2"><csymbol cd="latexml" id="alg1.l7.m1.8.8.2.3.1.cmml" xref="alg1.l7.m1.8.8.2.2.3">conditional-set</csymbol><interval closure="closed" id="alg1.l7.m1.7.7.1.1.1.1.cmml" xref="alg1.l7.m1.7.7.1.1.1.2"><ci id="alg1.l7.m1.3.3.cmml" xref="alg1.l7.m1.3.3">ùêù</ci><ci id="alg1.l7.m1.4.4.cmml" xref="alg1.l7.m1.4.4">ùê≥</ci></interval><apply id="alg1.l7.m1.8.8.2.2.2.3.cmml" xref="alg1.l7.m1.8.8.2.2.2.2"><csymbol cd="ambiguous" id="alg1.l7.m1.8.8.2.2.2.3a.cmml" xref="alg1.l7.m1.8.8.2.2.2.2.3">formulae-sequence</csymbol><apply id="alg1.l7.m1.8.8.2.2.2.1.1.cmml" xref="alg1.l7.m1.8.8.2.2.2.1.1"><in id="alg1.l7.m1.8.8.2.2.2.1.1.1.cmml" xref="alg1.l7.m1.8.8.2.2.2.1.1.1"></in><ci id="alg1.l7.m1.8.8.2.2.2.1.1.2.cmml" xref="alg1.l7.m1.8.8.2.2.2.1.1.2">ùêù</ci><apply id="alg1.l7.m1.8.8.2.2.2.1.1.3.cmml" xref="alg1.l7.m1.8.8.2.2.2.1.1.3"><csymbol cd="ambiguous" id="alg1.l7.m1.8.8.2.2.2.1.1.3.1.cmml" xref="alg1.l7.m1.8.8.2.2.2.1.1.3">subscript</csymbol><ci id="alg1.l7.m1.8.8.2.2.2.1.1.3.2.cmml" xref="alg1.l7.m1.8.8.2.2.2.1.1.3.2">ùêí</ci><apply id="alg1.l7.m1.8.8.2.2.2.1.1.3.3.cmml" xref="alg1.l7.m1.8.8.2.2.2.1.1.3.3"><minus id="alg1.l7.m1.8.8.2.2.2.1.1.3.3.1.cmml" xref="alg1.l7.m1.8.8.2.2.2.1.1.3.3.1"></minus><ci id="alg1.l7.m1.8.8.2.2.2.1.1.3.3.2.cmml" xref="alg1.l7.m1.8.8.2.2.2.1.1.3.3.2">ùëñ</ci><cn id="alg1.l7.m1.8.8.2.2.2.1.1.3.3.3.cmml" type="integer" xref="alg1.l7.m1.8.8.2.2.2.1.1.3.3.3">1</cn></apply></apply></apply><apply id="alg1.l7.m1.8.8.2.2.2.2.2.cmml" xref="alg1.l7.m1.8.8.2.2.2.2.2"><in id="alg1.l7.m1.8.8.2.2.2.2.2.1.cmml" xref="alg1.l7.m1.8.8.2.2.2.2.2.1"></in><ci id="alg1.l7.m1.8.8.2.2.2.2.2.2.cmml" xref="alg1.l7.m1.8.8.2.2.2.2.2.2">ùê≥</ci><apply id="alg1.l7.m1.8.8.2.2.2.2.2.3.cmml" xref="alg1.l7.m1.8.8.2.2.2.2.2.3"><times id="alg1.l7.m1.8.8.2.2.2.2.2.3.1.cmml" xref="alg1.l7.m1.8.8.2.2.2.2.2.3.1"></times><ci id="alg1.l7.m1.8.8.2.2.2.2.2.3.2.cmml" xref="alg1.l7.m1.8.8.2.2.2.2.2.3.2">ùê∫</ci><interval closure="open" id="alg1.l7.m1.8.8.2.2.2.2.2.3.3.1.cmml" xref="alg1.l7.m1.8.8.2.2.2.2.2.3.3.2"><ci id="alg1.l7.m1.5.5.cmml" xref="alg1.l7.m1.5.5">ùêù</ci><cn id="alg1.l7.m1.6.6.cmml" type="integer" xref="alg1.l7.m1.6.6">1</cn></interval></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l7.m1.8c">\mathbf{S}^{\prime}_{i,t}\leftarrow\{[\mathbf{d},\mathbf{z}]\mid\mathbf{d}\in%
\mathbf{S}_{i-1},\mathbf{z}\in G(\mathbf{d},1)\}</annotation><annotation encoding="application/x-llamapun" id="alg1.l7.m1.8d">bold_S start_POSTSUPERSCRIPT ‚Ä≤ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i , italic_t end_POSTSUBSCRIPT ‚Üê { [ bold_d , bold_z ] ‚à£ bold_d ‚àà bold_S start_POSTSUBSCRIPT italic_i - 1 end_POSTSUBSCRIPT , bold_z ‚àà italic_G ( bold_d , 1 ) }</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg1.l8">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l8.1.1.1" style="font-size:80%;">8:</span></span>¬†¬†¬†¬†¬†¬†¬†¬†¬†Evaluate the generated responses:

</div>
<div class="ltx_listingline" id="alg1.l9">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l9.1.1.1" style="font-size:80%;">9:</span></span>¬†¬†¬†¬†¬†¬†¬†¬†¬†<math alttext="\mathbf{V}_{i,t}\leftarrow R(\mathbf{S}^{\prime}_{i,t})" class="ltx_Math" display="inline" id="alg1.l9.m1.5"><semantics id="alg1.l9.m1.5a"><mrow id="alg1.l9.m1.5.5" xref="alg1.l9.m1.5.5.cmml"><msub id="alg1.l9.m1.5.5.3" xref="alg1.l9.m1.5.5.3.cmml"><mi id="alg1.l9.m1.5.5.3.2" xref="alg1.l9.m1.5.5.3.2.cmml">ùêï</mi><mrow id="alg1.l9.m1.2.2.2.4" xref="alg1.l9.m1.2.2.2.3.cmml"><mi id="alg1.l9.m1.1.1.1.1" xref="alg1.l9.m1.1.1.1.1.cmml">i</mi><mo id="alg1.l9.m1.2.2.2.4.1" xref="alg1.l9.m1.2.2.2.3.cmml">,</mo><mi id="alg1.l9.m1.2.2.2.2" xref="alg1.l9.m1.2.2.2.2.cmml">t</mi></mrow></msub><mo id="alg1.l9.m1.5.5.2" stretchy="false" xref="alg1.l9.m1.5.5.2.cmml">‚Üê</mo><mrow id="alg1.l9.m1.5.5.1" xref="alg1.l9.m1.5.5.1.cmml"><mi id="alg1.l9.m1.5.5.1.3" xref="alg1.l9.m1.5.5.1.3.cmml">R</mi><mo id="alg1.l9.m1.5.5.1.2" xref="alg1.l9.m1.5.5.1.2.cmml">‚Å¢</mo><mrow id="alg1.l9.m1.5.5.1.1.1" xref="alg1.l9.m1.5.5.1.1.1.1.cmml"><mo id="alg1.l9.m1.5.5.1.1.1.2" stretchy="false" xref="alg1.l9.m1.5.5.1.1.1.1.cmml">(</mo><msubsup id="alg1.l9.m1.5.5.1.1.1.1" xref="alg1.l9.m1.5.5.1.1.1.1.cmml"><mi id="alg1.l9.m1.5.5.1.1.1.1.2.2" xref="alg1.l9.m1.5.5.1.1.1.1.2.2.cmml">ùêí</mi><mrow id="alg1.l9.m1.4.4.2.4" xref="alg1.l9.m1.4.4.2.3.cmml"><mi id="alg1.l9.m1.3.3.1.1" xref="alg1.l9.m1.3.3.1.1.cmml">i</mi><mo id="alg1.l9.m1.4.4.2.4.1" xref="alg1.l9.m1.4.4.2.3.cmml">,</mo><mi id="alg1.l9.m1.4.4.2.2" xref="alg1.l9.m1.4.4.2.2.cmml">t</mi></mrow><mo id="alg1.l9.m1.5.5.1.1.1.1.2.3" xref="alg1.l9.m1.5.5.1.1.1.1.2.3.cmml">‚Ä≤</mo></msubsup><mo id="alg1.l9.m1.5.5.1.1.1.3" stretchy="false" xref="alg1.l9.m1.5.5.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l9.m1.5b"><apply id="alg1.l9.m1.5.5.cmml" xref="alg1.l9.m1.5.5"><ci id="alg1.l9.m1.5.5.2.cmml" xref="alg1.l9.m1.5.5.2">‚Üê</ci><apply id="alg1.l9.m1.5.5.3.cmml" xref="alg1.l9.m1.5.5.3"><csymbol cd="ambiguous" id="alg1.l9.m1.5.5.3.1.cmml" xref="alg1.l9.m1.5.5.3">subscript</csymbol><ci id="alg1.l9.m1.5.5.3.2.cmml" xref="alg1.l9.m1.5.5.3.2">ùêï</ci><list id="alg1.l9.m1.2.2.2.3.cmml" xref="alg1.l9.m1.2.2.2.4"><ci id="alg1.l9.m1.1.1.1.1.cmml" xref="alg1.l9.m1.1.1.1.1">ùëñ</ci><ci id="alg1.l9.m1.2.2.2.2.cmml" xref="alg1.l9.m1.2.2.2.2">ùë°</ci></list></apply><apply id="alg1.l9.m1.5.5.1.cmml" xref="alg1.l9.m1.5.5.1"><times id="alg1.l9.m1.5.5.1.2.cmml" xref="alg1.l9.m1.5.5.1.2"></times><ci id="alg1.l9.m1.5.5.1.3.cmml" xref="alg1.l9.m1.5.5.1.3">ùëÖ</ci><apply id="alg1.l9.m1.5.5.1.1.1.1.cmml" xref="alg1.l9.m1.5.5.1.1.1"><csymbol cd="ambiguous" id="alg1.l9.m1.5.5.1.1.1.1.1.cmml" xref="alg1.l9.m1.5.5.1.1.1">subscript</csymbol><apply id="alg1.l9.m1.5.5.1.1.1.1.2.cmml" xref="alg1.l9.m1.5.5.1.1.1"><csymbol cd="ambiguous" id="alg1.l9.m1.5.5.1.1.1.1.2.1.cmml" xref="alg1.l9.m1.5.5.1.1.1">superscript</csymbol><ci id="alg1.l9.m1.5.5.1.1.1.1.2.2.cmml" xref="alg1.l9.m1.5.5.1.1.1.1.2.2">ùêí</ci><ci id="alg1.l9.m1.5.5.1.1.1.1.2.3.cmml" xref="alg1.l9.m1.5.5.1.1.1.1.2.3">‚Ä≤</ci></apply><list id="alg1.l9.m1.4.4.2.3.cmml" xref="alg1.l9.m1.4.4.2.4"><ci id="alg1.l9.m1.3.3.1.1.cmml" xref="alg1.l9.m1.3.3.1.1">ùëñ</ci><ci id="alg1.l9.m1.4.4.2.2.cmml" xref="alg1.l9.m1.4.4.2.2">ùë°</ci></list></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l9.m1.5c">\mathbf{V}_{i,t}\leftarrow R(\mathbf{S}^{\prime}_{i,t})</annotation><annotation encoding="application/x-llamapun" id="alg1.l9.m1.5d">bold_V start_POSTSUBSCRIPT italic_i , italic_t end_POSTSUBSCRIPT ‚Üê italic_R ( bold_S start_POSTSUPERSCRIPT ‚Ä≤ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i , italic_t end_POSTSUBSCRIPT )</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg1.l10">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l10.1.1.1" style="font-size:80%;">10:</span></span>¬†¬†¬†¬†¬†¬†¬†¬†¬†Select the best candidate:

</div>
<div class="ltx_listingline" id="alg1.l11">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l11.1.1.1" style="font-size:80%;">11:</span></span>¬†¬†¬†¬†¬†¬†¬†¬†¬†<math alttext="\mathbf{d}_{i,t}\leftarrow\arg\max_{[\mathbf{d},\mathbf{z}]\in\mathbf{S}^{%
\prime}_{i,t}}\mathbf{V}_{i,t}([\mathbf{d},\mathbf{z}])" class="ltx_Math" display="inline" id="alg1.l11.m1.11"><semantics id="alg1.l11.m1.11a"><mrow id="alg1.l11.m1.11.11" xref="alg1.l11.m1.11.11.cmml"><msub id="alg1.l11.m1.11.11.3" xref="alg1.l11.m1.11.11.3.cmml"><mi id="alg1.l11.m1.11.11.3.2" xref="alg1.l11.m1.11.11.3.2.cmml">ùêù</mi><mrow id="alg1.l11.m1.2.2.2.4" xref="alg1.l11.m1.2.2.2.3.cmml"><mi id="alg1.l11.m1.1.1.1.1" xref="alg1.l11.m1.1.1.1.1.cmml">i</mi><mo id="alg1.l11.m1.2.2.2.4.1" xref="alg1.l11.m1.2.2.2.3.cmml">,</mo><mi id="alg1.l11.m1.2.2.2.2" xref="alg1.l11.m1.2.2.2.2.cmml">t</mi></mrow></msub><mo id="alg1.l11.m1.11.11.2" stretchy="false" xref="alg1.l11.m1.11.11.2.cmml">‚Üê</mo><mrow id="alg1.l11.m1.11.11.1" xref="alg1.l11.m1.11.11.1.cmml"><mrow id="alg1.l11.m1.11.11.1.3" xref="alg1.l11.m1.11.11.1.3.cmml"><mi id="alg1.l11.m1.11.11.1.3.1" xref="alg1.l11.m1.11.11.1.3.1.cmml">arg</mi><mo id="alg1.l11.m1.11.11.1.3a" lspace="0.167em" xref="alg1.l11.m1.11.11.1.3.cmml">‚Å°</mo><mrow id="alg1.l11.m1.11.11.1.3.2" xref="alg1.l11.m1.11.11.1.3.2.cmml"><msub id="alg1.l11.m1.11.11.1.3.2.1" xref="alg1.l11.m1.11.11.1.3.2.1.cmml"><mi id="alg1.l11.m1.11.11.1.3.2.1.2" xref="alg1.l11.m1.11.11.1.3.2.1.2.cmml">max</mi><mrow id="alg1.l11.m1.6.6.4" xref="alg1.l11.m1.6.6.4.cmml"><mrow id="alg1.l11.m1.6.6.4.6.2" xref="alg1.l11.m1.6.6.4.6.1.cmml"><mo id="alg1.l11.m1.6.6.4.6.2.1" stretchy="false" xref="alg1.l11.m1.6.6.4.6.1.cmml">[</mo><mi id="alg1.l11.m1.5.5.3.3" xref="alg1.l11.m1.5.5.3.3.cmml">ùêù</mi><mo id="alg1.l11.m1.6.6.4.6.2.2" xref="alg1.l11.m1.6.6.4.6.1.cmml">,</mo><mi id="alg1.l11.m1.6.6.4.4" xref="alg1.l11.m1.6.6.4.4.cmml">ùê≥</mi><mo id="alg1.l11.m1.6.6.4.6.2.3" stretchy="false" xref="alg1.l11.m1.6.6.4.6.1.cmml">]</mo></mrow><mo id="alg1.l11.m1.6.6.4.5" xref="alg1.l11.m1.6.6.4.5.cmml">‚àà</mo><msubsup id="alg1.l11.m1.6.6.4.7" xref="alg1.l11.m1.6.6.4.7.cmml"><mi id="alg1.l11.m1.6.6.4.7.2.2" xref="alg1.l11.m1.6.6.4.7.2.2.cmml">ùêí</mi><mrow id="alg1.l11.m1.4.4.2.2.2.4" xref="alg1.l11.m1.4.4.2.2.2.3.cmml"><mi id="alg1.l11.m1.3.3.1.1.1.1" xref="alg1.l11.m1.3.3.1.1.1.1.cmml">i</mi><mo id="alg1.l11.m1.4.4.2.2.2.4.1" xref="alg1.l11.m1.4.4.2.2.2.3.cmml">,</mo><mi id="alg1.l11.m1.4.4.2.2.2.2" xref="alg1.l11.m1.4.4.2.2.2.2.cmml">t</mi></mrow><mo id="alg1.l11.m1.6.6.4.7.2.3" xref="alg1.l11.m1.6.6.4.7.2.3.cmml">‚Ä≤</mo></msubsup></mrow></msub><mo id="alg1.l11.m1.11.11.1.3.2a" lspace="0.167em" xref="alg1.l11.m1.11.11.1.3.2.cmml">‚Å°</mo><msub id="alg1.l11.m1.11.11.1.3.2.2" xref="alg1.l11.m1.11.11.1.3.2.2.cmml"><mi id="alg1.l11.m1.11.11.1.3.2.2.2" xref="alg1.l11.m1.11.11.1.3.2.2.2.cmml">ùêï</mi><mrow id="alg1.l11.m1.8.8.2.4" xref="alg1.l11.m1.8.8.2.3.cmml"><mi id="alg1.l11.m1.7.7.1.1" xref="alg1.l11.m1.7.7.1.1.cmml">i</mi><mo id="alg1.l11.m1.8.8.2.4.1" xref="alg1.l11.m1.8.8.2.3.cmml">,</mo><mi id="alg1.l11.m1.8.8.2.2" xref="alg1.l11.m1.8.8.2.2.cmml">t</mi></mrow></msub></mrow></mrow><mo id="alg1.l11.m1.11.11.1.2" xref="alg1.l11.m1.11.11.1.2.cmml">‚Å¢</mo><mrow id="alg1.l11.m1.11.11.1.1.1" xref="alg1.l11.m1.11.11.1.cmml"><mo id="alg1.l11.m1.11.11.1.1.1.2" stretchy="false" xref="alg1.l11.m1.11.11.1.cmml">(</mo><mrow id="alg1.l11.m1.11.11.1.1.1.1.2" xref="alg1.l11.m1.11.11.1.1.1.1.1.cmml"><mo id="alg1.l11.m1.11.11.1.1.1.1.2.1" stretchy="false" xref="alg1.l11.m1.11.11.1.1.1.1.1.cmml">[</mo><mi id="alg1.l11.m1.9.9" xref="alg1.l11.m1.9.9.cmml">ùêù</mi><mo id="alg1.l11.m1.11.11.1.1.1.1.2.2" xref="alg1.l11.m1.11.11.1.1.1.1.1.cmml">,</mo><mi id="alg1.l11.m1.10.10" xref="alg1.l11.m1.10.10.cmml">ùê≥</mi><mo id="alg1.l11.m1.11.11.1.1.1.1.2.3" stretchy="false" xref="alg1.l11.m1.11.11.1.1.1.1.1.cmml">]</mo></mrow><mo id="alg1.l11.m1.11.11.1.1.1.3" stretchy="false" xref="alg1.l11.m1.11.11.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l11.m1.11b"><apply id="alg1.l11.m1.11.11.cmml" xref="alg1.l11.m1.11.11"><ci id="alg1.l11.m1.11.11.2.cmml" xref="alg1.l11.m1.11.11.2">‚Üê</ci><apply id="alg1.l11.m1.11.11.3.cmml" xref="alg1.l11.m1.11.11.3"><csymbol cd="ambiguous" id="alg1.l11.m1.11.11.3.1.cmml" xref="alg1.l11.m1.11.11.3">subscript</csymbol><ci id="alg1.l11.m1.11.11.3.2.cmml" xref="alg1.l11.m1.11.11.3.2">ùêù</ci><list id="alg1.l11.m1.2.2.2.3.cmml" xref="alg1.l11.m1.2.2.2.4"><ci id="alg1.l11.m1.1.1.1.1.cmml" xref="alg1.l11.m1.1.1.1.1">ùëñ</ci><ci id="alg1.l11.m1.2.2.2.2.cmml" xref="alg1.l11.m1.2.2.2.2">ùë°</ci></list></apply><apply id="alg1.l11.m1.11.11.1.cmml" xref="alg1.l11.m1.11.11.1"><times id="alg1.l11.m1.11.11.1.2.cmml" xref="alg1.l11.m1.11.11.1.2"></times><apply id="alg1.l11.m1.11.11.1.3.cmml" xref="alg1.l11.m1.11.11.1.3"><arg id="alg1.l11.m1.11.11.1.3.1.cmml" xref="alg1.l11.m1.11.11.1.3.1"></arg><apply id="alg1.l11.m1.11.11.1.3.2.cmml" xref="alg1.l11.m1.11.11.1.3.2"><apply id="alg1.l11.m1.11.11.1.3.2.1.cmml" xref="alg1.l11.m1.11.11.1.3.2.1"><csymbol cd="ambiguous" id="alg1.l11.m1.11.11.1.3.2.1.1.cmml" xref="alg1.l11.m1.11.11.1.3.2.1">subscript</csymbol><max id="alg1.l11.m1.11.11.1.3.2.1.2.cmml" xref="alg1.l11.m1.11.11.1.3.2.1.2"></max><apply id="alg1.l11.m1.6.6.4.cmml" xref="alg1.l11.m1.6.6.4"><in id="alg1.l11.m1.6.6.4.5.cmml" xref="alg1.l11.m1.6.6.4.5"></in><interval closure="closed" id="alg1.l11.m1.6.6.4.6.1.cmml" xref="alg1.l11.m1.6.6.4.6.2"><ci id="alg1.l11.m1.5.5.3.3.cmml" xref="alg1.l11.m1.5.5.3.3">ùêù</ci><ci id="alg1.l11.m1.6.6.4.4.cmml" xref="alg1.l11.m1.6.6.4.4">ùê≥</ci></interval><apply id="alg1.l11.m1.6.6.4.7.cmml" xref="alg1.l11.m1.6.6.4.7"><csymbol cd="ambiguous" id="alg1.l11.m1.6.6.4.7.1.cmml" xref="alg1.l11.m1.6.6.4.7">subscript</csymbol><apply id="alg1.l11.m1.6.6.4.7.2.cmml" xref="alg1.l11.m1.6.6.4.7"><csymbol cd="ambiguous" id="alg1.l11.m1.6.6.4.7.2.1.cmml" xref="alg1.l11.m1.6.6.4.7">superscript</csymbol><ci id="alg1.l11.m1.6.6.4.7.2.2.cmml" xref="alg1.l11.m1.6.6.4.7.2.2">ùêí</ci><ci id="alg1.l11.m1.6.6.4.7.2.3.cmml" xref="alg1.l11.m1.6.6.4.7.2.3">‚Ä≤</ci></apply><list id="alg1.l11.m1.4.4.2.2.2.3.cmml" xref="alg1.l11.m1.4.4.2.2.2.4"><ci id="alg1.l11.m1.3.3.1.1.1.1.cmml" xref="alg1.l11.m1.3.3.1.1.1.1">ùëñ</ci><ci id="alg1.l11.m1.4.4.2.2.2.2.cmml" xref="alg1.l11.m1.4.4.2.2.2.2">ùë°</ci></list></apply></apply></apply><apply id="alg1.l11.m1.11.11.1.3.2.2.cmml" xref="alg1.l11.m1.11.11.1.3.2.2"><csymbol cd="ambiguous" id="alg1.l11.m1.11.11.1.3.2.2.1.cmml" xref="alg1.l11.m1.11.11.1.3.2.2">subscript</csymbol><ci id="alg1.l11.m1.11.11.1.3.2.2.2.cmml" xref="alg1.l11.m1.11.11.1.3.2.2.2">ùêï</ci><list id="alg1.l11.m1.8.8.2.3.cmml" xref="alg1.l11.m1.8.8.2.4"><ci id="alg1.l11.m1.7.7.1.1.cmml" xref="alg1.l11.m1.7.7.1.1">ùëñ</ci><ci id="alg1.l11.m1.8.8.2.2.cmml" xref="alg1.l11.m1.8.8.2.2">ùë°</ci></list></apply></apply></apply><interval closure="closed" id="alg1.l11.m1.11.11.1.1.1.1.1.cmml" xref="alg1.l11.m1.11.11.1.1.1.1.2"><ci id="alg1.l11.m1.9.9.cmml" xref="alg1.l11.m1.9.9">ùêù</ci><ci id="alg1.l11.m1.10.10.cmml" xref="alg1.l11.m1.10.10">ùê≥</ci></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l11.m1.11c">\mathbf{d}_{i,t}\leftarrow\arg\max_{[\mathbf{d},\mathbf{z}]\in\mathbf{S}^{%
\prime}_{i,t}}\mathbf{V}_{i,t}([\mathbf{d},\mathbf{z}])</annotation><annotation encoding="application/x-llamapun" id="alg1.l11.m1.11d">bold_d start_POSTSUBSCRIPT italic_i , italic_t end_POSTSUBSCRIPT ‚Üê roman_arg roman_max start_POSTSUBSCRIPT [ bold_d , bold_z ] ‚àà bold_S start_POSTSUPERSCRIPT ‚Ä≤ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i , italic_t end_POSTSUBSCRIPT end_POSTSUBSCRIPT bold_V start_POSTSUBSCRIPT italic_i , italic_t end_POSTSUBSCRIPT ( [ bold_d , bold_z ] )</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg1.l12">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l12.1.1.1" style="font-size:80%;">12:</span></span>¬†¬†¬†¬†¬†¬†¬†¬†¬†Add <math alttext="\mathbf{d}_{i,t}" class="ltx_Math" display="inline" id="alg1.l12.m1.2"><semantics id="alg1.l12.m1.2a"><msub id="alg1.l12.m1.2.3" xref="alg1.l12.m1.2.3.cmml"><mi id="alg1.l12.m1.2.3.2" xref="alg1.l12.m1.2.3.2.cmml">ùêù</mi><mrow id="alg1.l12.m1.2.2.2.4" xref="alg1.l12.m1.2.2.2.3.cmml"><mi id="alg1.l12.m1.1.1.1.1" xref="alg1.l12.m1.1.1.1.1.cmml">i</mi><mo id="alg1.l12.m1.2.2.2.4.1" xref="alg1.l12.m1.2.2.2.3.cmml">,</mo><mi id="alg1.l12.m1.2.2.2.2" xref="alg1.l12.m1.2.2.2.2.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="alg1.l12.m1.2b"><apply id="alg1.l12.m1.2.3.cmml" xref="alg1.l12.m1.2.3"><csymbol cd="ambiguous" id="alg1.l12.m1.2.3.1.cmml" xref="alg1.l12.m1.2.3">subscript</csymbol><ci id="alg1.l12.m1.2.3.2.cmml" xref="alg1.l12.m1.2.3.2">ùêù</ci><list id="alg1.l12.m1.2.2.2.3.cmml" xref="alg1.l12.m1.2.2.2.4"><ci id="alg1.l12.m1.1.1.1.1.cmml" xref="alg1.l12.m1.1.1.1.1">ùëñ</ci><ci id="alg1.l12.m1.2.2.2.2.cmml" xref="alg1.l12.m1.2.2.2.2">ùë°</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l12.m1.2c">\mathbf{d}_{i,t}</annotation><annotation encoding="application/x-llamapun" id="alg1.l12.m1.2d">bold_d start_POSTSUBSCRIPT italic_i , italic_t end_POSTSUBSCRIPT</annotation></semantics></math> to <math alttext="\mathbf{S}_{i,t}" class="ltx_Math" display="inline" id="alg1.l12.m2.2"><semantics id="alg1.l12.m2.2a"><msub id="alg1.l12.m2.2.3" xref="alg1.l12.m2.2.3.cmml"><mi id="alg1.l12.m2.2.3.2" xref="alg1.l12.m2.2.3.2.cmml">ùêí</mi><mrow id="alg1.l12.m2.2.2.2.4" xref="alg1.l12.m2.2.2.2.3.cmml"><mi id="alg1.l12.m2.1.1.1.1" xref="alg1.l12.m2.1.1.1.1.cmml">i</mi><mo id="alg1.l12.m2.2.2.2.4.1" xref="alg1.l12.m2.2.2.2.3.cmml">,</mo><mi id="alg1.l12.m2.2.2.2.2" xref="alg1.l12.m2.2.2.2.2.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="alg1.l12.m2.2b"><apply id="alg1.l12.m2.2.3.cmml" xref="alg1.l12.m2.2.3"><csymbol cd="ambiguous" id="alg1.l12.m2.2.3.1.cmml" xref="alg1.l12.m2.2.3">subscript</csymbol><ci id="alg1.l12.m2.2.3.2.cmml" xref="alg1.l12.m2.2.3.2">ùêí</ci><list id="alg1.l12.m2.2.2.2.3.cmml" xref="alg1.l12.m2.2.2.2.4"><ci id="alg1.l12.m2.1.1.1.1.cmml" xref="alg1.l12.m2.1.1.1.1">ùëñ</ci><ci id="alg1.l12.m2.2.2.2.2.cmml" xref="alg1.l12.m2.2.2.2.2">ùë°</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l12.m2.2c">\mathbf{S}_{i,t}</annotation><annotation encoding="application/x-llamapun" id="alg1.l12.m2.2d">bold_S start_POSTSUBSCRIPT italic_i , italic_t end_POSTSUBSCRIPT</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg1.l13">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l13.1.1.1" style="font-size:80%;">13:</span></span>¬†¬†¬†¬†¬†<span class="ltx_text ltx_font_bold" id="alg1.l13.2">end</span>¬†<span class="ltx_text ltx_font_bold" id="alg1.l13.3">for</span>
</div>
<div class="ltx_listingline" id="alg1.l14">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l14.1.1.1" style="font-size:80%;">14:</span></span><span class="ltx_text ltx_font_bold" id="alg1.l14.2">end</span>¬†<span class="ltx_text ltx_font_bold" id="alg1.l14.3">for</span>
</div>
<div class="ltx_listingline" id="alg1.l15">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l15.1.1.1" style="font-size:80%;">15:</span></span>Evaluate the dialogues: <math alttext="\mathbf{V}_{\text{final}}\leftarrow R(\mathbf{D})" class="ltx_Math" display="inline" id="alg1.l15.m1.1"><semantics id="alg1.l15.m1.1a"><mrow id="alg1.l15.m1.1.2" xref="alg1.l15.m1.1.2.cmml"><msub id="alg1.l15.m1.1.2.2" xref="alg1.l15.m1.1.2.2.cmml"><mi id="alg1.l15.m1.1.2.2.2" xref="alg1.l15.m1.1.2.2.2.cmml">ùêï</mi><mtext id="alg1.l15.m1.1.2.2.3" xref="alg1.l15.m1.1.2.2.3a.cmml">final</mtext></msub><mo id="alg1.l15.m1.1.2.1" stretchy="false" xref="alg1.l15.m1.1.2.1.cmml">‚Üê</mo><mrow id="alg1.l15.m1.1.2.3" xref="alg1.l15.m1.1.2.3.cmml"><mi id="alg1.l15.m1.1.2.3.2" xref="alg1.l15.m1.1.2.3.2.cmml">R</mi><mo id="alg1.l15.m1.1.2.3.1" xref="alg1.l15.m1.1.2.3.1.cmml">‚Å¢</mo><mrow id="alg1.l15.m1.1.2.3.3.2" xref="alg1.l15.m1.1.2.3.cmml"><mo id="alg1.l15.m1.1.2.3.3.2.1" stretchy="false" xref="alg1.l15.m1.1.2.3.cmml">(</mo><mi id="alg1.l15.m1.1.1" xref="alg1.l15.m1.1.1.cmml">ùêÉ</mi><mo id="alg1.l15.m1.1.2.3.3.2.2" stretchy="false" xref="alg1.l15.m1.1.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l15.m1.1b"><apply id="alg1.l15.m1.1.2.cmml" xref="alg1.l15.m1.1.2"><ci id="alg1.l15.m1.1.2.1.cmml" xref="alg1.l15.m1.1.2.1">‚Üê</ci><apply id="alg1.l15.m1.1.2.2.cmml" xref="alg1.l15.m1.1.2.2"><csymbol cd="ambiguous" id="alg1.l15.m1.1.2.2.1.cmml" xref="alg1.l15.m1.1.2.2">subscript</csymbol><ci id="alg1.l15.m1.1.2.2.2.cmml" xref="alg1.l15.m1.1.2.2.2">ùêï</ci><ci id="alg1.l15.m1.1.2.2.3a.cmml" xref="alg1.l15.m1.1.2.2.3"><mtext id="alg1.l15.m1.1.2.2.3.cmml" mathsize="70%" xref="alg1.l15.m1.1.2.2.3">final</mtext></ci></apply><apply id="alg1.l15.m1.1.2.3.cmml" xref="alg1.l15.m1.1.2.3"><times id="alg1.l15.m1.1.2.3.1.cmml" xref="alg1.l15.m1.1.2.3.1"></times><ci id="alg1.l15.m1.1.2.3.2.cmml" xref="alg1.l15.m1.1.2.3.2">ùëÖ</ci><ci id="alg1.l15.m1.1.1.cmml" xref="alg1.l15.m1.1.1">ùêÉ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l15.m1.1c">\mathbf{V}_{\text{final}}\leftarrow R(\mathbf{D})</annotation><annotation encoding="application/x-llamapun" id="alg1.l15.m1.1d">bold_V start_POSTSUBSCRIPT final end_POSTSUBSCRIPT ‚Üê italic_R ( bold_D )</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg1.l16">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l16.1.1.1" style="font-size:80%;">16:</span></span>Select the best dialogue: <math alttext="\mathbf{D}_{\text{best}}\leftarrow\arg\max_{\mathbf{d}\in\mathbf{D}}\mathbf{V}%
_{\text{final}}(\mathbf{d})" class="ltx_Math" display="inline" id="alg1.l16.m1.1"><semantics id="alg1.l16.m1.1a"><mrow id="alg1.l16.m1.1.2" xref="alg1.l16.m1.1.2.cmml"><msub id="alg1.l16.m1.1.2.2" xref="alg1.l16.m1.1.2.2.cmml"><mi id="alg1.l16.m1.1.2.2.2" xref="alg1.l16.m1.1.2.2.2.cmml">ùêÉ</mi><mtext id="alg1.l16.m1.1.2.2.3" xref="alg1.l16.m1.1.2.2.3a.cmml">best</mtext></msub><mo id="alg1.l16.m1.1.2.1" stretchy="false" xref="alg1.l16.m1.1.2.1.cmml">‚Üê</mo><mrow id="alg1.l16.m1.1.2.3" xref="alg1.l16.m1.1.2.3.cmml"><mrow id="alg1.l16.m1.1.2.3.2" xref="alg1.l16.m1.1.2.3.2.cmml"><mi id="alg1.l16.m1.1.2.3.2.1" xref="alg1.l16.m1.1.2.3.2.1.cmml">arg</mi><mo id="alg1.l16.m1.1.2.3.2a" lspace="0.167em" xref="alg1.l16.m1.1.2.3.2.cmml">‚Å°</mo><mrow id="alg1.l16.m1.1.2.3.2.2" xref="alg1.l16.m1.1.2.3.2.2.cmml"><msub id="alg1.l16.m1.1.2.3.2.2.1" xref="alg1.l16.m1.1.2.3.2.2.1.cmml"><mi id="alg1.l16.m1.1.2.3.2.2.1.2" xref="alg1.l16.m1.1.2.3.2.2.1.2.cmml">max</mi><mrow id="alg1.l16.m1.1.2.3.2.2.1.3" xref="alg1.l16.m1.1.2.3.2.2.1.3.cmml"><mi id="alg1.l16.m1.1.2.3.2.2.1.3.2" xref="alg1.l16.m1.1.2.3.2.2.1.3.2.cmml">ùêù</mi><mo id="alg1.l16.m1.1.2.3.2.2.1.3.1" xref="alg1.l16.m1.1.2.3.2.2.1.3.1.cmml">‚àà</mo><mi id="alg1.l16.m1.1.2.3.2.2.1.3.3" xref="alg1.l16.m1.1.2.3.2.2.1.3.3.cmml">ùêÉ</mi></mrow></msub><mo id="alg1.l16.m1.1.2.3.2.2a" lspace="0.167em" xref="alg1.l16.m1.1.2.3.2.2.cmml">‚Å°</mo><msub id="alg1.l16.m1.1.2.3.2.2.2" xref="alg1.l16.m1.1.2.3.2.2.2.cmml"><mi id="alg1.l16.m1.1.2.3.2.2.2.2" xref="alg1.l16.m1.1.2.3.2.2.2.2.cmml">ùêï</mi><mtext id="alg1.l16.m1.1.2.3.2.2.2.3" xref="alg1.l16.m1.1.2.3.2.2.2.3a.cmml">final</mtext></msub></mrow></mrow><mo id="alg1.l16.m1.1.2.3.1" xref="alg1.l16.m1.1.2.3.1.cmml">‚Å¢</mo><mrow id="alg1.l16.m1.1.2.3.3.2" xref="alg1.l16.m1.1.2.3.cmml"><mo id="alg1.l16.m1.1.2.3.3.2.1" stretchy="false" xref="alg1.l16.m1.1.2.3.cmml">(</mo><mi id="alg1.l16.m1.1.1" xref="alg1.l16.m1.1.1.cmml">ùêù</mi><mo id="alg1.l16.m1.1.2.3.3.2.2" stretchy="false" xref="alg1.l16.m1.1.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l16.m1.1b"><apply id="alg1.l16.m1.1.2.cmml" xref="alg1.l16.m1.1.2"><ci id="alg1.l16.m1.1.2.1.cmml" xref="alg1.l16.m1.1.2.1">‚Üê</ci><apply id="alg1.l16.m1.1.2.2.cmml" xref="alg1.l16.m1.1.2.2"><csymbol cd="ambiguous" id="alg1.l16.m1.1.2.2.1.cmml" xref="alg1.l16.m1.1.2.2">subscript</csymbol><ci id="alg1.l16.m1.1.2.2.2.cmml" xref="alg1.l16.m1.1.2.2.2">ùêÉ</ci><ci id="alg1.l16.m1.1.2.2.3a.cmml" xref="alg1.l16.m1.1.2.2.3"><mtext id="alg1.l16.m1.1.2.2.3.cmml" mathsize="70%" xref="alg1.l16.m1.1.2.2.3">best</mtext></ci></apply><apply id="alg1.l16.m1.1.2.3.cmml" xref="alg1.l16.m1.1.2.3"><times id="alg1.l16.m1.1.2.3.1.cmml" xref="alg1.l16.m1.1.2.3.1"></times><apply id="alg1.l16.m1.1.2.3.2.cmml" xref="alg1.l16.m1.1.2.3.2"><arg id="alg1.l16.m1.1.2.3.2.1.cmml" xref="alg1.l16.m1.1.2.3.2.1"></arg><apply id="alg1.l16.m1.1.2.3.2.2.cmml" xref="alg1.l16.m1.1.2.3.2.2"><apply id="alg1.l16.m1.1.2.3.2.2.1.cmml" xref="alg1.l16.m1.1.2.3.2.2.1"><csymbol cd="ambiguous" id="alg1.l16.m1.1.2.3.2.2.1.1.cmml" xref="alg1.l16.m1.1.2.3.2.2.1">subscript</csymbol><max id="alg1.l16.m1.1.2.3.2.2.1.2.cmml" xref="alg1.l16.m1.1.2.3.2.2.1.2"></max><apply id="alg1.l16.m1.1.2.3.2.2.1.3.cmml" xref="alg1.l16.m1.1.2.3.2.2.1.3"><in id="alg1.l16.m1.1.2.3.2.2.1.3.1.cmml" xref="alg1.l16.m1.1.2.3.2.2.1.3.1"></in><ci id="alg1.l16.m1.1.2.3.2.2.1.3.2.cmml" xref="alg1.l16.m1.1.2.3.2.2.1.3.2">ùêù</ci><ci id="alg1.l16.m1.1.2.3.2.2.1.3.3.cmml" xref="alg1.l16.m1.1.2.3.2.2.1.3.3">ùêÉ</ci></apply></apply><apply id="alg1.l16.m1.1.2.3.2.2.2.cmml" xref="alg1.l16.m1.1.2.3.2.2.2"><csymbol cd="ambiguous" id="alg1.l16.m1.1.2.3.2.2.2.1.cmml" xref="alg1.l16.m1.1.2.3.2.2.2">subscript</csymbol><ci id="alg1.l16.m1.1.2.3.2.2.2.2.cmml" xref="alg1.l16.m1.1.2.3.2.2.2.2">ùêï</ci><ci id="alg1.l16.m1.1.2.3.2.2.2.3a.cmml" xref="alg1.l16.m1.1.2.3.2.2.2.3"><mtext id="alg1.l16.m1.1.2.3.2.2.2.3.cmml" mathsize="70%" xref="alg1.l16.m1.1.2.3.2.2.2.3">final</mtext></ci></apply></apply></apply><ci id="alg1.l16.m1.1.1.cmml" xref="alg1.l16.m1.1.1">ùêù</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l16.m1.1c">\mathbf{D}_{\text{best}}\leftarrow\arg\max_{\mathbf{d}\in\mathbf{D}}\mathbf{V}%
_{\text{final}}(\mathbf{d})</annotation><annotation encoding="application/x-llamapun" id="alg1.l16.m1.1d">bold_D start_POSTSUBSCRIPT best end_POSTSUBSCRIPT ‚Üê roman_arg roman_max start_POSTSUBSCRIPT bold_d ‚àà bold_D end_POSTSUBSCRIPT bold_V start_POSTSUBSCRIPT final end_POSTSUBSCRIPT ( bold_d )</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg1.l17">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l17.1.1.1" style="font-size:80%;">17:</span></span><span class="ltx_text ltx_font_bold" id="alg1.l17.2">return</span> <math alttext="\mathbf{D}_{\text{best}}" class="ltx_Math" display="inline" id="alg1.l17.m1.1"><semantics id="alg1.l17.m1.1a"><msub id="alg1.l17.m1.1.1" xref="alg1.l17.m1.1.1.cmml"><mi id="alg1.l17.m1.1.1.2" xref="alg1.l17.m1.1.1.2.cmml">ùêÉ</mi><mtext id="alg1.l17.m1.1.1.3" xref="alg1.l17.m1.1.1.3a.cmml">best</mtext></msub><annotation-xml encoding="MathML-Content" id="alg1.l17.m1.1b"><apply id="alg1.l17.m1.1.1.cmml" xref="alg1.l17.m1.1.1"><csymbol cd="ambiguous" id="alg1.l17.m1.1.1.1.cmml" xref="alg1.l17.m1.1.1">subscript</csymbol><ci id="alg1.l17.m1.1.1.2.cmml" xref="alg1.l17.m1.1.1.2">ùêÉ</ci><ci id="alg1.l17.m1.1.1.3a.cmml" xref="alg1.l17.m1.1.1.3"><mtext id="alg1.l17.m1.1.1.3.cmml" mathsize="70%" xref="alg1.l17.m1.1.1.3">best</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l17.m1.1c">\mathbf{D}_{\text{best}}</annotation><annotation encoding="application/x-llamapun" id="alg1.l17.m1.1d">bold_D start_POSTSUBSCRIPT best end_POSTSUBSCRIPT</annotation></semantics></math>
</div>
</div>
</div>
</div>
</figure>
<figure class="ltx_table" id="S3.T1">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span><span class="ltx_text" id="S3.T1.4.1" style="color:#000000;">Results from A Comparative Study on The performance of dialogue generation Between the Proposed Method and Existing Methods.</span> The best scores are highlighted in <span class="ltx_text" id="S3.T1.5.2" style="color:#FF0000;">red</span> and the second best scores are highlighted in <span class="ltx_text ltx_ulem_uline" id="S3.T1.6.3" style="color:#0000FF;">blue</span>.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S3.T1.7" style="width:263.7pt;height:126.6pt;vertical-align:-122.4pt;"><span class="ltx_transformed_inner" style="transform:translate(-87.9pt,1.4pt) scale(0.6,0.6) ;"><span class="ltx_ERROR undefined" id="S3.T1.7.1">{tblr}</span>
<p class="ltx_p" id="S3.T1.7.2">row9 = c,
column1 = c,
cell11 = r=2,
cell12 = r=2c,
cell13 = r=2c,
cell14 = r=2,
cell15 = r=2,
cell16 = c=5c,
cell26 = c,
cell27 = c,
cell28 = c,
cell32 = c,
cell33 = c,
cell36 = c,
cell37 = c,
cell38 = c,
cell39 = c,
cell310 = c,
cell46 = c,
cell47 = c,
cell48 = c,
cell49 = c,
cell410 = c,
cell56 = c,
cell57 = c,
cell58 = c,
cell59 = c,
cell510 = c,
cell61 = r=4,
cell62 = c,
cell63 = c,
cell64 = c,
cell66 = c,
cell67 = c,
cell68 = c,
cell69 = c,
cell610 = c,
cell72 = c,
cell73 = c,
cell74 = c,
cell76 = c,
cell77 = c,
cell78 = c,
cell79 = c,
cell710 = c,
cell82 = c,
cell83 = c,
cell84 = c,
cell86 = c,fg=blue,
cell87 = c,fg=blue,
cell88 = c,fg=blue,
cell89 = c,fg=blue,
cell810 = c,fg=blue,
cell96 = fg=red,
cell97 = fg=red,
cell98 = fg=red,
cell99 = fg=red,
cell910 = fg=red,
hline1,3,10 = -,
hline2 = 6-10,

Dialogues &amp; Doctor agent¬†  Candidate ranking  Patient agent (not finetuned)  Patient agent (finetuned)  Metrics     
<br class="ltx_break"/>     BLEU1  BLEU2  BLEU3  BLEU4  ROUGE 
<br class="ltx_break"/>HuatuoGPT (Zhang et al 2023)      0.134  0.049  0.017  0.006  0.107 
<br class="ltx_break"/>Zhongjing (Yang et al 2023)      0.134  0.050  0.021  0.009  0.116 
<br class="ltx_break"/>Llama3 (Meta AI 2024)      0.165  0.067  0.028  0.009  0.116 
<br class="ltx_break"/>Proposed  ‚úì    0.210  0.093  0.050  0.030  0.120 
<br class="ltx_break"/> ‚úì ‚úì   0.228  0.098  0.047  0.026  0.127 
<br class="ltx_break"/> ‚úì ‚úì ‚úì  <span class="ltx_text ltx_ulem_uline" id="S3.T1.7.2.1">0.253</span> <span class="ltx_text ltx_ulem_uline" id="S3.T1.7.2.2">0.112</span> <span class="ltx_text ltx_ulem_uline" id="S3.T1.7.2.3">0.060</span> <span class="ltx_text ltx_ulem_uline" id="S3.T1.7.2.4">0.038</span> <span class="ltx_text ltx_ulem_uline" id="S3.T1.7.2.5">0.133</span>
<br class="ltx_break"/> ‚úì ‚úì ‚úì ‚úì <span class="ltx_text ltx_font_bold" id="S3.T1.7.2.6">0.273</span> <span class="ltx_text ltx_font_bold" id="S3.T1.7.2.7">0.134</span> <span class="ltx_text ltx_font_bold" id="S3.T1.7.2.8">0.077</span> <span class="ltx_text ltx_font_bold" id="S3.T1.7.2.9">0.049</span> <span class="ltx_text ltx_font_bold" id="S3.T1.7.2.10">0.140</span></p>
</span></div>
</figure>
</section>
<section class="ltx_subsection" id="S3.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>The Interactive Patient Agent</h3>
<div class="ltx_para" id="S3.SS4.p1">
<p class="ltx_p" id="S3.SS4.p1.1">Using the candidate ranking strategy, our doctor agent will search for the optimal answer/query based on previous conversation records. <span class="ltx_text" id="S3.SS4.p1.1.1" style="color:#000000;">We further design a patient agent to provide appropriate responses to the queries posed by the doctor agent. Empowered by LLMs, our patient agent uses the patient‚Äôs medical history to avoid inconsistency and logical errors between the current and future rounds of the conversation.</span> Based on the medical history, the interactive patient agent will answer the doctor agent‚Äôs questions or generate new queries that are related to the health conditions. <span class="ltx_text" id="S3.SS4.p1.1.2" style="color:#000000;">In real-world settings, patients may have diverse backgrounds. As such, we investigate two types of patient agents, one directly using a pre-trained LLM while another fine-tuned by the real-world dialogue dataset <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib35" title="">35</a>]</cite>. The latter is used to mimic the scenario where patients have basic clinical knowledge for their current visits.</span> The prompts used for the interactive patient agent are shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#S2.F3" title="Figure 3 ‚Ä£ 2 Related Work ‚Ä£ A Two-Stage Proactive Dialogue Generator for Efficient Clinical Information Collection Using Large Language Model"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<div class="ltx_para" id="S3.SS4.p2">
<p class="ltx_p" id="S3.SS4.p2.1">Thus, we set our proposed proactive dialogue generator as a combination of finetuning, candidate ranking, and interactive patient agent. Using finetuning, our framework is familiarized with the medical history and style of clinical conversation between a doctor and a patient. With the candidate ranking strategy, the doctor agent generates the optimal query/answer according to the statement from the patient agent. Using the interactive patient agent, we aim to mitigate the inconsistency and logic flaws among multi-round conversations.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Results</h2>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Experimental settings</h3>
<section class="ltx_subsubsection" id="S4.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.1 </span>Experimental dataset</h4>
<div class="ltx_para" id="S4.SS1.SSS1.p1">
<p class="ltx_p" id="S4.SS1.SSS1.p1.1">We conduct extensive experiments to validate our model in the real-world medical conversation dataset <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib35" title="">35</a>]</cite>. The real-world dataset contains multi-round 1,120
doctor-patient dialogues
from online consultation medical dialogues, with an official split of 800 for training, 160 for validation, and 160 for testing. We use the official training set to finetune the query generator and the test set to generate queries. For each dialogue, there is a set of labels that serves as diagnostic information. The diagnostic information is formulated by three sections, which are category, items, and status. For the category, there are four subclasses which are symptoms, surgery, test, and other information. The detailed descriptions of the contents in the category are provided in the item section. The status section contains the doctor‚Äôs diagnosis and patients‚Äô self-reporting labels, either positive or negative, for each item in the corresponding category. Based on the diagnostic information, we use ChatGPT-3.5 to generate medical history for each patient.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS1.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.2 </span>Evaluation metrics</h4>
<div class="ltx_para" id="S4.SS1.SSS2.p1">
<p class="ltx_p" id="S4.SS1.SSS2.p1.1">We use Bilingual Evaluation Understudy (BLEU) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib36" title="">36</a>]</cite> and Recall-Oriented Understudy for Gisting Evaluation (ROUGE) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib37" title="">37</a>]</cite> scores to evaluate the performance of dialogue generation using different models. Also, we evaluate high-level metrics of the generated dialogues from the perspectives of Fluency, Professionalism, and Safety. We follow the definitions of the three high-level metrics in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib34" title="">34</a>]</cite>. The high-level metrics are calculated using ChatGPT-3.5. Also, we evaluate the performance of our method in the downstream task of extracting diagnostic information. For the real-world and generated medical dialogues, we extract the diagnostic information using ChatGPT-3.5. We calculate the F1 scores of the extracted diagnostic information. The prompts for calculating high-level metrics and extracting diagnostic information are shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#S2.F3" title="Figure 3 ‚Ä£ 2 Related Work ‚Ä£ A Two-Stage Proactive Dialogue Generator for Efficient Clinical Information Collection Using Large Language Model"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS1.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.3 </span>Implementation details</h4>
<figure class="ltx_table" id="S4.T2">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Results from A Comparative Study on the Quality of Retrieved Diagnostic Information for Categories, Items, and Status Between the Proposed Method and Existing Methods. The best scores are highlighted in <span class="ltx_text" id="S4.T2.3.1" style="color:#FF0000;">red</span> and the second best scores are highlighted in <span class="ltx_text ltx_ulem_uline" id="S4.T2.4.2" style="color:#0000FF;">blue</span>.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T2.5" style="width:348.5pt;height:84.8pt;vertical-align:-79.2pt;"><span class="ltx_transformed_inner" style="transform:translate(-43.6pt,0.7pt) scale(0.8,0.8) ;"><span class="ltx_ERROR undefined" id="S4.T2.5.1">{tblr}</span>
<p class="ltx_p" id="S4.T2.5.2">rowodd = c,
row4 = c,
row6 = c,
row7 = ,
cell11 = r=2,
cell12 = c=3,
cell22 = c,
cell23 = c,
cell33 = fg=blue,
cell34 = fg=blue,
cell61 = c,
cell62 = fg=blue,
cell63 = c,
cell64 = fg=red,
cell72 = fg=red,
cell73 = fg=red,
cell74 = ,
hline1,3,8 = -,
hline2 = 2-4,

Dialogues &amp; F1 Score   
<br class="ltx_break"/> Category  Items  Status 
<br class="ltx_break"/>HuatuoGPT (Zhang et al 2023)  0.717  <span class="ltx_text ltx_ulem_uline" id="S4.T2.5.2.1">0.887</span> <span class="ltx_text ltx_ulem_uline" id="S4.T2.5.2.2">0.828</span>
<br class="ltx_break"/>Zhongjing (Yang et al 2023)  0.727  0.882  0.827 
<br class="ltx_break"/>Llama3 (Meta AI 2024)  0.705  0.839  0.740 
<br class="ltx_break"/>Proposed w patient agent  <span class="ltx_text ltx_ulem_uline" id="S4.T2.5.2.3">0.813</span>  0.886  <span class="ltx_text ltx_font_bold" id="S4.T2.5.2.4">0.832</span>
<br class="ltx_break"/>Proposed w/o patient agent  <span class="ltx_text ltx_font_bold" id="S4.T2.5.2.5">0.837</span> <span class="ltx_text ltx_font_bold" id="S4.T2.5.2.6">0.906</span>  0.810</p>
</span></div>
</figure>
<figure class="ltx_table" id="S4.T3">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span><span class="ltx_text" id="S4.T3.4.1" style="color:#000000;">Results from An ablation study on the Fluency, Professionalism, and Safety of generated dialogues.</span> The best scores are highlighted in <span class="ltx_text" id="S4.T3.5.2" style="color:#FF0000;">red</span> and the second best scores are highlighted in <span class="ltx_text ltx_ulem_uline" id="S4.T3.6.3" style="color:#0000FF;">blue</span>.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T3.7" style="width:306.9pt;height:88.9pt;vertical-align:-84.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-65.8pt,1.0pt) scale(0.7,0.7) ;"><span class="ltx_ERROR undefined" id="S4.T3.7.1">{tblr}</span>
<p class="ltx_p" id="S4.T3.7.2">row2 = c,
row6 = c,
column1 = c,
cell11 = r=2,
cell12 = r=2c,
cell13 = r=2c,
cell14 = r=2,
cell15 = r=2,
cell16 = c=3c,
cell31 = r=4,
cell32 = c,
cell36 = c,
cell37 = c,
cell42 = c,
cell43 = c,
cell44 = c,
cell46 = c,
cell47 = c,fg=blue,
cell48 = c,fg=blue,
cell52 = c,
cell53 = c,
cell54 = c,
cell56 = c,fg=blue,
cell57 = c,
cell58 = c,
cell66 = fg=red,
cell67 = fg=red,
cell68 = fg=red,
hline1,3,7 = -,
hline2 = 6-8,

Dialogues &amp; Doctor agent  Candidate ranking  Patient agent (not finetuned)  Patient agent (finetuned)  Metrics   
<br class="ltx_break"/>     Fluency  Professionalism  Safety 
<br class="ltx_break"/>Proposed  ‚úì    3.462  3.583  3.544 
<br class="ltx_break"/> ‚úì ‚úì   6.531  <span class="ltx_text ltx_ulem_uline" id="S4.T3.7.2.1">6.462</span> <span class="ltx_text ltx_ulem_uline" id="S4.T3.7.2.2">7.131</span>
<br class="ltx_break"/> ‚úì ‚úì ‚úì  <span class="ltx_text ltx_ulem_uline" id="S4.T3.7.2.3">6.788</span>  6.112  6.318 
<br class="ltx_break"/> ‚úì ‚úì ‚úì ‚úì <span class="ltx_text ltx_font_bold" id="S4.T3.7.2.4">7.719</span> <span class="ltx_text ltx_font_bold" id="S4.T3.7.2.5">7.775</span> <span class="ltx_text ltx_font_bold" id="S4.T3.7.2.6">8.238</span></p>
</span></div>
</figure>
<div class="ltx_para" id="S4.SS1.SSS3.p1">
<p class="ltx_p" id="S4.SS1.SSS3.p1.1">In this paper, we finetune a Llama-3-8B-Instruct <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib19" title="">19</a>]</cite> as the doctor agent, based on which we perform candidate ranking. We finetuned the doctor agent on the real-world dataset for 50 epochs. During the candidate ranking, we use Llama-3-8B-Instruct to generate ranking scores based on the correctness of logic and relevance to medical history. For the patient agent, we use another Llama-3-8B-Instruct to serve as the patient and generate responses according to the doctor agent‚Äôs query. The fine-tuning, candidate ranking, and patient agent are running on a single Nvidia A6000 GPU. We use official implementation and model weights for HuatuoGPT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib33" title="">33</a>]</cite> and Zhongjing <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib34" title="">34</a>]</cite>.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Language styles of LLMs</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1"><span class="ltx_text" id="S4.SS2.p1.1.1" style="color:#000000;">In Table <a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#S3.T1" title="Table 1 ‚Ä£ 3.3 Dialogue Recommendation System ‚Ä£ 3 Methods ‚Ä£ A Two-Stage Proactive Dialogue Generator for Efficient Clinical Information Collection Using Large Language Model"><span class="ltx_text ltx_ref_tag">1</span></a>, we evaluate the generated responses from the proactive dialogue generator with state-of-the-art dialogue generators HuatuoGPT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib33" title="">33</a>]</cite>, Zhongjing <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib34" title="">34</a>]</cite>, and Llama3 (Meta AI 2024) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib19" title="">19</a>]</cite>. Additionally, we report the ablation results with different experimental settings. As shown, our model outperforms baselines in all evaluation metrics.</span> We observe that existing medical Q&amp;A LLMs <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib33" title="">33</a>]</cite> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib34" title="">34</a>]</cite> suffer from low BLEU and ROUGE scores. A possible reason is that these models are mainly designed to generate a response, rather than proactively collecting diagnostic information through posing multi-round queries. These results indicate that our framework could effectively mimic the pattern of real-clinic interactions, where healthcare professionals proactively ask clinical questions to collect comprehensive diagnostic information from patients. <span class="ltx_text" id="S4.SS2.p1.1.2" style="color:#000000;">Moreover, in our ablation study, we observe an improved overall performance when conducting dialogues with the fine-tuned patient agent. The fine-tuning of the patient agent grants it clinical knowledge of the disease diagnosis, making it respond more professionally to disease-related queries. This aligns well with our intuition and knowledge. That is, the outcome of the diagnosis will likely be improved with effective patient-doctor interactions.</span></p>
</div>
<figure class="ltx_figure" id="S4.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="300" id="S4.F4.1.g1" src="extracted/5896984/figures/res_dialogue.png" width="598"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Representative examples of patient-doctors dialogues. For a query from a <span class="ltx_text" id="S4.F4.7.1" style="color:#0000FF;">patient</span>, two variations of our model (<span class="ltx_text" id="S4.F4.8.2" style="color:#008080;">finetuning+candidate ranking</span> and <span class="ltx_text" id="S4.F4.9.3" style="color:#FF8000;">finetuning</span>) generate responses. The <span class="ltx_text" id="S4.F4.10.4" style="color:#808080;">reference</span> response is shown in also demonstrated. The proactive questions are highlighted in <span class="ltx_text" id="S4.F4.11.5" style="color:#FF0000;">red</span> color. The demonstrations use the first round of dialogue from the real-world conversation dataset. In these cases, our methods (finetuning+candidate ranking) and (finetuning+candidate ranking+patient agent) generate the same response.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Retrieval of diagnostic information</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">We further evaluate the quality of retrieved diagnostic information. Following the definition in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib35" title="">35</a>]</cite>, we measure the F1 scores of the extracted diagnostic information from the aspects of category, items, and status. The diagnostic information is retrieved using ChatGPT-3.5. The prompts to retrieve diagnostic information from different dialogues are shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#S2.F3" title="Figure 3 ‚Ä£ 2 Related Work ‚Ä£ A Two-Stage Proactive Dialogue Generator for Efficient Clinical Information Collection Using Large Language Model"><span class="ltx_text ltx_ref_tag">3</span></a>. The results are reported in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#S4.T2" title="Table 2 ‚Ä£ 4.1.3 Implementation details ‚Ä£ 4.1 Experimental settings ‚Ä£ 4 Results ‚Ä£ A Two-Stage Proactive Dialogue Generator for Efficient Clinical Information Collection Using Large Language Model"><span class="ltx_text ltx_ref_tag">2</span></a>. Similar to experiments on language style, we compare with Llama-3
<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib19" title="">19</a>]</cite>, HuatuoGPT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib33" title="">33</a>]</cite> and Zhongjing <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib34" title="">34</a>]</cite>. Since the above baselines do not have a patient agent, we report the results of the proposed model with and without the patient agent to present a fair comparison. Benefiting from the improved dialogue quality, the proposed method achieves the best F1 score for categories and items.
In addition to the results reported in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#S4.T2" title="Table 2 ‚Ä£ 4.1.3 Implementation details ‚Ä£ 4.1 Experimental settings ‚Ä£ 4 Results ‚Ä£ A Two-Stage Proactive Dialogue Generator for Efficient Clinical Information Collection Using Large Language Model"><span class="ltx_text ltx_ref_tag">2</span></a>, our proposed method also demonstrates the potential to serve as an effective input for retrieving diagnostic information at a similar level compared to the real-world dataset, which has an F1 score of 0.836 in Status.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Ablation study on quality of responses</h3>
<div class="ltx_para" id="S4.SS4.p1">
<p class="ltx_p" id="S4.SS4.p1.1">Inspired by <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib34" title="">34</a>]</cite>, we use ChatGPT-3.5 to evaluate the language quality of the generate dialogue using the following evaluation metrics: Fluency, Professionalism, and Safety of the generated dialogues. To avoid the dilemma of using ChatGPT to evaluate ChatGPT-generated data (e.g., HuatuoGPT and Zhongjing), this section is limited to an ablation study on the efficiency of proposed components. The results are reported in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#S4.T3" title="Table 3 ‚Ä£ 4.1.3 Implementation details ‚Ä£ 4.1 Experimental settings ‚Ä£ 4 Results ‚Ä£ A Two-Stage Proactive Dialogue Generator for Efficient Clinical Information Collection Using Large Language Model"><span class="ltx_text ltx_ref_tag">3</span></a>. Benefiting from our proposed candidate ranking strategy, all evaluation metrics are increased by at least 80%. These results confirm that our candidate ranking strategy is efficient and could significantly improve the quality of the generated dialogues. Also, the results show that the interactive patient agent can improve the fluency of the generated dialogue, which reflects the purpose of designing the interactive mode to reduce the logical flaws among multi-round conversations. Besides, we argue that doctor agent strategy alone is not sufficient to generate the optimal candidate. As pointed out by <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#bib.bib38" title="">38</a>]</cite>, the autoregressive mechanism of LLM for generating text confines the candidate decisions by its token-level decision and left-to-right fashion. Thus, our results indicate the importance of the proposed candidate ranking strategy, which overcomes the limitation of the autoregressive mechanism by searching and ranking among a larger pool of candidates.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.5 </span>Demonstration of proactive query generation</h3>
<div class="ltx_para" id="S4.SS5.p1">
<p class="ltx_p" id="S4.SS5.p1.1">In Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.03770v1#S4.F4" title="Figure 4 ‚Ä£ 4.2 Language styles of LLMs ‚Ä£ 4 Results ‚Ä£ A Two-Stage Proactive Dialogue Generator for Efficient Clinical Information Collection Using Large Language Model"><span class="ltx_text ltx_ref_tag">4</span></a>, we demonstrate four representative cases of single-round dialogue between the patient agent and doctoral agents. Note that all the examples shown in the figure are in the first round of conversation, where two variations of our method (doctor agent+candidate ranking) and (doctor agent+candidate ranking+patient agent) generate the same response. In case (a), our doctor agent+candidate ranking model actively asks for the discomfort (symptoms) of the patient, which is in accord with the real-world dialogue. In case (b), the doctor agent+ranking model further asks for more details about the irregular heartbeat (symptoms) and previous medical testing records (medical evidence data). In case (c), the doctor agent+ranking model questions the symptoms of the patient. In case (d), the doctor agent+ranking model refers to the cardio ultrasound testing (medical testing records). In contrast, the doctor agent model turns to directly answering the query of the patient agent by explaining medical terminologies. The demonstrations indicate that the candidate ranking strategy further boosts the capability of LLMs to proactively ask for and collect diagnostic information as proactive dialogue generator.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Discussion</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">The experimental results confirm that the proposed doctor agent, candidate ranking strategy, and patient agent provide clinical dialogues that mimic the clinical conversation. <span class="ltx_text" id="S5.p1.1.1" style="color:#000000;">Moreover, our proposed model does not adopt any prior knowledge/assumption of any disease or language. As such, it is generic for different types of diseases and languages.</span>
Benefiting from the doctor agent and candidate ranking strategies, the proposed methods achieve higher BLEU and ROUGE scores, as well as high-level metrics such as Fluency, Professionalism, and Safety. Moreover, the interactive patient agent improves the high-level scores among multi-round conversations. Although these high-level metrics are not a part of the ranking criteria, the improved high-level scores demonstrate the effectiveness and robustness of the candidate ranking strategy. Also, we confirm that the generated dialogues by the proactive dialogue generator can provide comprehensive diagnostic information compared to the real-world dataset.
It is worth mentioning that in real clinical practice, there should be a patient who addresses the queries from the doctor‚Äôs agent. Limited by the availability of the dataset and patients‚Äô involvement, we developed the interactive patient agent to answer queries from the doctor agent and ask follow-up questions. As suggested by the experimental results, the interactive patient agent reduces the inconsistency and flaws in logic in the multi-round conversations.
<span class="ltx_text" id="S5.p1.1.2" style="color:#000000;">Also, We observe a further increase in fluency, professionalism, and safety scores, after the patient agent is finetuned. </span></p>
</div>
<div class="ltx_para" id="S5.p2">
<p class="ltx_p" id="S5.p2.1">The outcomes of our framework have multiple applications. For example, the generated dialogue can be employed to train natural language models for extracting symptoms and diagnosing diseases. The doctor agent can be used to generate query to patient and extracting diagnostic information in clinics. Additionally, it can be used for educational purposes, such as training avatars to interact with healthcare professional students in the role of standardized patients during clinical examinations. Also, the patient agent can be used for training purposes for clinical professionals to practice clinical interactions.</p>
</div>
<div class="ltx_para" id="S5.p3">
<p class="ltx_p" id="S5.p3.1">Beyond the proposed framework, we believe that more agents can be potentially incorporated into the framework. For example, nursing agents, if fine-tuned in different domains of medicine, can be added to our system to provide detailed suggestions which is tailored by the patients‚Äô needs. Also, a supervision agent, focusing on the correctness of the doctor agent‚Äôs output, can be added to the framework to further improve the quality of the generated dialogues. With incremental data, we can also train a model for specialist, such as cardiologist, neurologist, etc., in clinical diagnosis.</p>
</div>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">In this paper, we develop a diagnostic system to proactively collect diagnostic information via interactive conversations between doctor and patient agents. Using the proposed doctor agent, two-stage recommendation structure, and interactive patient agent, we perform comprehensive experiments on a real-world medical dialogue dataset. The BLEU and ROUGE scores show that the proposed method, after fine-tuning and candidate ranking, better mimics the conversation style in real-world dialogue. Moreover, the proposed framework achieves better performance in terms of high-level metrics including Fluency, Professionalism, and Safety. The generated dialogues are capable of providing diagnostic information.
<span class="ltx_text" id="S6.p1.1.1" style="color:#000000;">In the future, we will conduct a human evaluation to further evaluate our model in real-world settings. Specifically, we will invite patients and physicians to evaluate the performance of the proposed algorithms from multiple aspects, including friendliness, efficiency, and accuracy, over the conversation.</span></p>
</div>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Acknowledgment</h2>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p" id="S7.p1.1">Financial support for this publication partially results from Scialog grant #SA-AUT-2024-022b from Research Corporation for Science Advancement and Arnold and Mabel Beckman Foundation.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Trevena et¬†al. [2006]</span>
<span class="ltx_bibblock">
Lyndal¬†J Trevena, Heather M¬†Davey BPsych, Alexandra Barratt, et¬†al.

</span>
<span class="ltx_bibblock">A systematic review on communicating with patients about evidence.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">Journal of evaluation in clinical practice</em>, 12(1):13‚Äì23, 2006.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">G√∏tzsche [2008]</span>
<span class="ltx_bibblock">
Peter G√∏tzsche.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">Rational diagnosis and treatment: evidence-based clinical decision-making</em>.

</span>
<span class="ltx_bibblock">John Wiley &amp; Sons, 2008.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brunetti et¬†al. [2019]</span>
<span class="ltx_bibblock">
Antonio Brunetti, Leonarda Carnimeo, Gianpaolo¬†Francesco Trotta, et¬†al.

</span>
<span class="ltx_bibblock">Computer-assisted frameworks for classification of liver, breast and blood neoplasias via neural networks: A survey based on medical images.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">Neurocomputing</em>, 335:274‚Äì298, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et¬†al. [2023]</span>
<span class="ltx_bibblock">
Zihao Zhao, Sheng Wang, Jinchen Gu, et¬†al.

</span>
<span class="ltx_bibblock">ChatCAD+: Towards a universal and reliable interactive CAD using LLMs.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">arXiv preprint arXiv:2305.15964</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et¬†al. [2023]</span>
<span class="ltx_bibblock">
Juexiao Zhou, Xiaonan He, Liyuan Sun, et¬†al.

</span>
<span class="ltx_bibblock">SkinGPT-4: An interactive dermatology diagnostic system with visual large language model, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu et¬†al. [2023]</span>
<span class="ltx_bibblock">
Deyao Zhu, Jun Chen, Xiaoqian Shen, et¬†al.

</span>
<span class="ltx_bibblock">MiniGPT-4: Enhancing vision-language understanding with advanced large language models, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et¬†al. [2021]</span>
<span class="ltx_bibblock">
Zhihong Chen, Yaling Shen, Yan Song, and Xiang Wan.

</span>
<span class="ltx_bibblock">Cross-modal memory networks for radiology report generation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</em>, pages 5904‚Äì5914, Online, August 2021. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/2021.acl-long.459</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2021.acl-long.459" title="">https://aclanthology.org/2021.acl-long.459</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Paulhus et¬†al. [2007]</span>
<span class="ltx_bibblock">
Delroy¬†L Paulhus, Simine Vazire, et¬†al.

</span>
<span class="ltx_bibblock">The self-report method.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">Handbook of research methods in personality psychology</em>, 1(2007):224‚Äì239, 2007.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bruce and Fries [2003]</span>
<span class="ltx_bibblock">
Bonnie Bruce and James¬†F Fries.

</span>
<span class="ltx_bibblock">The stanford health assessment questionnaire: a review of its history, issues, progress, and documentation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">The Journal of rheumatology</em>, 30(1):167‚Äì178, 2003.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Stange et¬†al. [1998]</span>
<span class="ltx_bibblock">
Kurt¬†C Stange, Stephen¬†J Zyzanski, Tracy¬†Fedirko Smith, Robert Kelly, Doreen¬†M Langa, Susan¬†A Flocke, and Carlos¬†R Ja√©n.

</span>
<span class="ltx_bibblock">How valid are medical records and patient questionnaires for physician profiling and health services research?: A comparison with direct observation of patient visits.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">Medical care</em>, 36(6):851‚Äì867, 1998.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bergmann et¬†al. [2004]</span>
<span class="ltx_bibblock">
Manuela¬†M Bergmann, Eric¬†J Jacobs, Kurt Hoffmann, et¬†al.

</span>
<span class="ltx_bibblock">Agreement of self-reported medical history: comparison of an in-person interview with a self-administered questionnaire.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">European journal of epidemiology</em>, 19:411‚Äì416, 2004.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Stirratt et¬†al. [2015]</span>
<span class="ltx_bibblock">
Michael¬†J Stirratt, Jacqueline Dunbar-Jacob, Heidi¬†M Crane, Jane¬†M Simoni, Susan Czajkowski, Marisa¬†E Hilliard, James¬†E Aikens, Christine¬†M Hunter, Dawn¬†I Velligan, Kristen Huntley, et¬†al.

</span>
<span class="ltx_bibblock">Self-report measures of medication adherence behavior: recommendations on optimal use.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">Translational behavioral medicine</em>, 5(4):470‚Äì482, 2015.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jin et¬†al. [2022]</span>
<span class="ltx_bibblock">
Qiao Jin, Zheng Yuan, Guangzhi Xiong, et¬†al.

</span>
<span class="ltx_bibblock">Biomedical question answering: a survey of approaches and challenges.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">ACM Computing Surveys (CSUR)</em>, 55(2):1‚Äì36, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lewis et¬†al. [2020]</span>
<span class="ltx_bibblock">
Patrick Lewis, Ethan Perez, Aleksandra Piktus, et¬†al.

</span>
<span class="ltx_bibblock">Retrieval-augmented generation for knowledge-intensive nlp tasks.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">Proceedings of the 34th International Conference on Neural Information Processing Systems</em>, NIPS ‚Äô20, Red Hook, NY, USA, 2020. Curran Associates Inc.

</span>
<span class="ltx_bibblock">ISBN 9781713829546.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pinho et¬†al. [2017]</span>
<span class="ltx_bibblock">
Eduardo Pinho, Tiago Godinho, Frederico Valente, and Carlos Costa.

</span>
<span class="ltx_bibblock">A multimodal search engine for medical imaging studies.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">Journal of digital imaging</em>, 30:39‚Äì48, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chowdhery et¬†al. [2024]</span>
<span class="ltx_bibblock">
Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, et¬†al.

</span>
<span class="ltx_bibblock">Palm: scaling language modeling with pathways.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">J. Mach. Learn. Res.</em>, 24(1), mar 2024.

</span>
<span class="ltx_bibblock">ISSN 1532-4435.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et¬†al. [2023a]</span>
<span class="ltx_bibblock">
Hugo Touvron, Thibaut Lavril, Gautier Izacard, et¬†al.

</span>
<span class="ltx_bibblock">Llama: Open and efficient foundation language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">ArXiv</em>, abs/2302.13971, 2023a.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://api.semanticscholar.org/CorpusID:257219404" title="">https://api.semanticscholar.org/CorpusID:257219404</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et¬†al. [2023b]</span>
<span class="ltx_bibblock">
Hugo Touvron, Louis Martin, Kevin¬†R. Stone, et¬†al.

</span>
<span class="ltx_bibblock">Llama 2: Open foundation and fine-tuned chat models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">ArXiv</em>, abs/2307.09288, 2023b.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://api.semanticscholar.org/CorpusID:259950998" title="">https://api.semanticscholar.org/CorpusID:259950998</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">AI@Meta [2024]</span>
<span class="ltx_bibblock">
AI@Meta.

</span>
<span class="ltx_bibblock">Llama 3 model card.

</span>
<span class="ltx_bibblock">2024.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/meta-llama/llama3/blob/main/MODEL_CARD.md" title="">https://github.com/meta-llama/llama3/blob/main/MODEL_CARD.md</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown et¬†al. [2020]</span>
<span class="ltx_bibblock">
Tom¬†B. Brown, Benjamin Mann, Nick Ryder, et¬†al.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">Proceedings of the 34th International Conference on Neural Information Processing Systems</em>, NIPS ‚Äô20, Red Hook, NY, USA, 2020. Curran Associates Inc.

</span>
<span class="ltx_bibblock">ISBN 9781713829546.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI et¬†al. [2024]</span>
<span class="ltx_bibblock">
OpenAI, Josh Achiam, Steven Adler, et¬†al.

</span>
<span class="ltx_bibblock">Gpt-4 technical report, 2024.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2303.08774" title="">https://arxiv.org/abs/2303.08774</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Du et¬†al. [2022]</span>
<span class="ltx_bibblock">
Zhengxiao Du, Yujie Qian, Xiao Liu, et¬†al.

</span>
<span class="ltx_bibblock">GLM: General language model pretraining with autoregressive blank infilling.

</span>
<span class="ltx_bibblock">In Smaranda Muresan, Preslav Nakov, and Aline Villavicencio, editors, <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pages 320‚Äì335, Dublin, Ireland, May 2022. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/2022.acl-long.26</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2022.acl-long.26" title="">https://aclanthology.org/2022.acl-long.26</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zeng et¬†al. [2022]</span>
<span class="ltx_bibblock">
Aohan Zeng, Xiao Liu, Zhengxiao Du, et¬†al.

</span>
<span class="ltx_bibblock">Glm-130b: An open bilingual pre-trained model.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">ArXiv</em>, abs/2210.02414, 2022.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://api.semanticscholar.org/CorpusID:252715691" title="">https://api.semanticscholar.org/CorpusID:252715691</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Singhal et¬†al. [2023]</span>
<span class="ltx_bibblock">
Karan Singhal, Tao Tu, Juraj Gottweis, et¬†al.

</span>
<span class="ltx_bibblock">Towards expert-level medical question answering with large language models, 2023.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2305.09617" title="">https://arxiv.org/abs/2305.09617</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et¬†al. [2023]</span>
<span class="ltx_bibblock">
Zeming Chen, Alejandro¬†Hern√°ndez Cano, Angelika Romanou, et¬†al.

</span>
<span class="ltx_bibblock">Meditron-70b: Scaling medical pretraining for large language models, 2023.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2311.16079" title="">https://arxiv.org/abs/2311.16079</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et¬†al. [2023a]</span>
<span class="ltx_bibblock">
Chaoyi Wu, Weixiong Lin, Xiaoman Zhang, et¬†al.

</span>
<span class="ltx_bibblock">Pmc-llama: Towards building open-source language models for medicine, 2023a.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2304.14454" title="">https://arxiv.org/abs/2304.14454</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et¬†al. [2024]</span>
<span class="ltx_bibblock">
Kai Zhang, Jun Yu, Eashan Adhikarla, et¬†al.

</span>
<span class="ltx_bibblock">Biomedgpt: A unified and generalist biomedical generative pre-trained transformer for vision, language, and multimodal tasks, 2024.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2305.17100" title="">https://arxiv.org/abs/2305.17100</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI [2023]</span>
<span class="ltx_bibblock">
R¬†OpenAI.

</span>
<span class="ltx_bibblock">Gpt-4 technical report. arxiv 2303.08774.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">View in Article</em>, 2:13, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hoffmann et¬†al. [2022]</span>
<span class="ltx_bibblock">
Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, et¬†al.

</span>
<span class="ltx_bibblock">Training compute-optimal large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">arXiv preprint arXiv:2203.15556</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et¬†al. [2023c]</span>
<span class="ltx_bibblock">
Hugo Touvron, Louis Martin, Kevin Stone, et¬†al.

</span>
<span class="ltx_bibblock">Llama 2: Open foundation and fine-tuned chat models, 2023c.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chowdhery et¬†al. [2023]</span>
<span class="ltx_bibblock">
Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, et¬†al.

</span>
<span class="ltx_bibblock">Palm: Scaling language modeling with pathways.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">Journal of Machine Learning Research</em>, 24(240):1‚Äì113, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et¬†al. [2023b]</span>
<span class="ltx_bibblock">
Tianyu Wu, Shizhu He, Jingping Liu, et¬†al.

</span>
<span class="ltx_bibblock">A brief overview of chatgpt: The history, status quo and potential future development.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">IEEE/CAA Journal of Automatica Sinica</em>, 10(5):1122‚Äì1136, 2023b.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1109/JAS.2023.123618</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et¬†al. [2023]</span>
<span class="ltx_bibblock">
Hongbo Zhang, Junying Chen, Feng Jiang, et¬†al.

</span>
<span class="ltx_bibblock">HuatuoGPT, towards taming language model to be a doctor.

</span>
<span class="ltx_bibblock">In Houda Bouamor, Juan Pino, and Kalika Bali, editors, <em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">Findings of the Association for Computational Linguistics: EMNLP 2023</em>, pages 10859‚Äì10885, Singapore, December 2023. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/2023.findings-emnlp.725</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2023.findings-emnlp.725" title="">https://aclanthology.org/2023.findings-emnlp.725</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et¬†al. [2023]</span>
<span class="ltx_bibblock">
Songhua Yang, Hanjia Zhao, Senbin Zhu, et¬†al.

</span>
<span class="ltx_bibblock">Zhongjing: Enhancing chinese medical capabilities of large language models through expert feedback and real-world multi-turn dialogues.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">arXiv preprint arXiv:2308.03549</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et¬†al. [2020]</span>
<span class="ltx_bibblock">
Yuanzhe Zhang, Zhongtao Jiang, Tao Zhang, et¬†al.

</span>
<span class="ltx_bibblock">Mie: A medical information extractor towards medical dialogues.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">Annual Meeting of the Association for Computational Linguistics</em>, 2020.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://api.semanticscholar.org/CorpusID:220047186" title="">https://api.semanticscholar.org/CorpusID:220047186</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Papineni et¬†al. [2002]</span>
<span class="ltx_bibblock">
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.

</span>
<span class="ltx_bibblock">Bleu: a method for automatic evaluation of machine translation.

</span>
<span class="ltx_bibblock">In Pierre Isabelle, Eugene Charniak, and Dekang Lin, editors, <em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics</em>, pages 311‚Äì318, Philadelphia, Pennsylvania, USA, July 2002.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.3115/1073083.1073135</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/P02-1040" title="">https://aclanthology.org/P02-1040</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin [2004]</span>
<span class="ltx_bibblock">
Chin-Yew Lin.

</span>
<span class="ltx_bibblock">ROUGE: A package for automatic evaluation of summaries.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">Text Summarization Branches Out</em>, pages 74‚Äì81, Barcelona, Spain, July 2004. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/W04-1013" title="">https://aclanthology.org/W04-1013</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yao et¬†al. [2023]</span>
<span class="ltx_bibblock">
Shunyu Yao, Dian Yu, Jeffrey Zhao, et¬†al.

</span>
<span class="ltx_bibblock">Tree of thoughts: Deliberate problem solving with large language models.

</span>
<span class="ltx_bibblock">In A.¬†Oh, T.¬†Naumann, A.¬†Globerson, K.¬†Saenko, M.¬†Hardt, and S.¬†Levine, editors, <em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">Advances in Neural Information Processing Systems</em>, volume¬†36, pages 11809‚Äì11822. Curran Associates, Inc., 2023.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://proceedings.neurips.cc/paper_files/paper/2023/file/271db9922b8d1f4dd7aaef84ed5ac703-Paper-Conference.pdf" title="">https://proceedings.neurips.cc/paper_files/paper/2023/file/271db9922b8d1f4dd7aaef84ed5ac703-Paper-Conference.pdf</a>.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Wed Oct  2 19:31:22 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
