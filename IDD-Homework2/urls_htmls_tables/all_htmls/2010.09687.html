<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2010.09687] A Demonstration of Smart Doorbell Design Using Federated Deep Learning</title><meta property="og:description" content="Smart doorbells have been playing an important role in protecting our modern homes. Existing approaches of sending video streams to a centralized server (or Cloud) for video analytics have been facing many challenges s…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="A Demonstration of Smart Doorbell Design Using Federated Deep Learning">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="A Demonstration of Smart Doorbell Design Using Federated Deep Learning">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2010.09687">

<!--Generated on Sat Mar  2 09:09:24 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="Federated Learning,  Internet of Things,  Video Analytics,  Artificial Intelligence,  Deep Learning,  Machine Learning,  Privacy,  Security">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">A Demonstration of Smart Doorbell Design Using Federated Deep Learning</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Vatsal Patel, Sarth Kanani, Tapan Pathak
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:vatsal.pce18@sot.pdpu.ac.in">vatsal.pce18@sot.pdpu.ac.in</a>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:sarth.kce18@sot.pdpu.ac.in">sarth.kce18@sot.pdpu.ac.in</a>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:tapan.pce18@sot.pdpu.ac.in">tapan.pce18@sot.pdpu.ac.in</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span id="id1.1.id1" class="ltx_text ltx_affiliation_institution">Pandit Deendayal Petroleum University</span><span id="id2.2.id2" class="ltx_text ltx_affiliation_city">Gandhinagar</span><span id="id3.3.id3" class="ltx_text ltx_affiliation_country">India</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Pankesh Patel, Muhammad Intizar Ali
</span></span>
<span class="ltx_author_before"> and </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">John Breslin
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:pankesh.patel@insight-centre.org,">pankesh.patel@insight-centre.org,</a>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:ali.intizar@nuigalway.ie,%20john.breslin@nuigalway.ie">ali.intizar@nuigalway.ie, john.breslin@nuigalway.ie</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span id="id4.1.id1" class="ltx_text ltx_affiliation_institution">Confirm SFI Research Centre for Smart Manufacturing, Data Science Institute, NUI Galway, Ireland</span>
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p id="id5.id1" class="ltx_p">Smart doorbells have been playing an important role in protecting our modern homes. Existing approaches of sending video streams to a centralized server (or Cloud) for video analytics have been facing many challenges such as latency, bandwidth cost and more importantly users’ privacy concerns. To address these challenges, this paper showcases the ability of an intelligent smart doorbell based on Federated Deep Learning, which can deploy and manage video analytics applications such as a smart doorbell across Edge and Cloud resources. This platform can scale, work with multiple devices, seamlessly manage online orchestration of the application components. The proposed framework is implemented using state-of-the-art technology. We implement the Federated Server using the Flask framework, containerized using Nginx and Gunicorn, which is deployed on AWS EC2 and AWS Serverless architecture.</p>
</div>
<div class="ltx_keywords">Federated Learning, Internet of Things, Video Analytics, Artificial Intelligence, Deep Learning, Machine Learning, Privacy, Security
</div>
<span id="id1" class="ltx_note ltx_note_frontmatter ltx_role_copyright"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">copyright: </span>none</span></span></span>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">The smart doorbell has been playing an important role in protecting our modern homes since they were invented. The recent trend from big companies <cite class="ltx_cite ltx_citemacro_citep">(Delaney, <a href="#bib.bib6" title="" class="ltx_ref">2020</a>)</cite> is to offer a smart doorbell that integrates all possible services including face recognition at the door. A common approach, adopted by these offerings, is to send image streams over the network to a central server (or Cloud), where all the processing takes place and appropriate decisions are made. Although this approach reduces the maintenance cost by keeping the application logic in one central location, it may not be suitable for applications relying on video analytics. Some of the reasons are: <span id="S1.p1.1.1" class="ltx_text ltx_font_bold">First</span>, the central server approach for video analytics may not be suitable for latency-sensitive applications because of the delay caused by transferring data to a central server for analysis and back to the application. <span id="S1.p1.1.2" class="ltx_text ltx_font_bold">Second</span>, the use of the central sever for continuous data storage, object detection, and analysis is expensive because these applications generate high volume of image and video data. Furthermore, the processing and storage of multiple video streams make the subscription more costly. Secondly, this design requires a huge amount of reliable bandwidth, which may not always be had. <span id="S1.p1.1.3" class="ltx_text ltx_font_bold">Third</span>, even if we assume that we could address latency and bandwidth issue by empowering a sophisticated infrastructure, a large class of video-based applications may not be suitable because of regulations and security concerns of sharing data as there is an involvement of biometric data of residents. For instance, GDPR restricts the sharing of users’ private data across organizations.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">The recent advancements in Federated Learning <cite class="ltx_cite ltx_citemacro_citep">(Konecný et al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2016</a>; Yang
et al<span class="ltx_text">.</span>, <a href="#bib.bib23" title="" class="ltx_ref">2019</a>)</cite> have shown the potential to address the aforementioned challenges. Federated Learning works on <span id="S1.p2.1.1" class="ltx_text ltx_font_bold ltx_font_italic">model aggregation rather than data aggregation</span> principle <cite class="ltx_cite ltx_citemacro_citep">(Liu et al<span class="ltx_text">.</span>, <a href="#bib.bib16" title="" class="ltx_ref">2020</a>)</cite>. Building a model using Federated Learning fits the problem naturally for video analytics applications: <span id="S1.p2.1.2" class="ltx_text ltx_font_bold">First</span>, it trains the model(s) locally and then uploads the model parameters to a centralized server for aggregation. Thus, it prevents data leakage as sensitive data does not leave the smart doorbell device. <span id="S1.p2.1.3" class="ltx_text ltx_font_bold">Second</span>, it reduces communication cost <cite class="ltx_cite ltx_citemacro_citep">(Konecný et al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2016</a>; Elgamal et al<span class="ltx_text">.</span>, <a href="#bib.bib7" title="" class="ltx_ref">2020</a>; Liu
et al<span class="ltx_text">.</span>, <a href="#bib.bib15" title="" class="ltx_ref">2018</a>)</cite>, as devices upload the trained model parameters to the centralized server, instead of the images. Federated Learning is not much tested in practice so far, specifically for video analytics applications <cite class="ltx_cite ltx_citemacro_citep">(Liu et al<span class="ltx_text">.</span>, <a href="#bib.bib16" title="" class="ltx_ref">2020</a>)</cite>, thus some open questions related to implementation details for video analytics applications (such as a potential architecture when it is applied to computer vision applications and an implementation of this approach for resource constrained IoT devices) need to be addressed.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">In this paper, we showcase the ability of an intelligent framework <cite class="ltx_cite ltx_citemacro_citep">(Chauhan et al<span class="ltx_text">.</span>, <a href="#bib.bib3" title="" class="ltx_ref">2016a</a>, <a href="#bib.bib4" title="" class="ltx_ref">b</a>)</cite> based on Federated Learning (addressing the challenges as mentioned above), which can deploy and manage video analytics applications such as a smart doorbell across Edge and Cloud resources <cite class="ltx_cite ltx_citemacro_citep">(Patel
et al<span class="ltx_text">.</span>, <a href="#bib.bib20" title="" class="ltx_ref">2017</a>)</cite>. The proposed framework is implemented using state-of-the-art technology. We implement the Federated Server using the Flask framework, containerized using Nginx and Gunicorn deployed on AWS EC2 and AWS Serverless architecture. Second, we have built MobileNet object detection models <cite class="ltx_cite ltx_citemacro_citep">(Pathak et al<span class="ltx_text">.</span>, <a href="#bib.bib21" title="" class="ltx_ref">2020</a>; Joshi et al<span class="ltx_text">.</span>, <a href="#bib.bib13" title="" class="ltx_ref">2020</a>)</cite> for different scenarios (such as face detection, an unsafe content detection, a noteworthy vehicle detection) and deployed them on resource-constrained IoT devices using TensorFlow Lite to reduce the object detection latency. These models are developed using Federated Learning, as a novel distributed deep learning approach, on a popular datasets such as ImageNet, Common Objects in Context (COCO).</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2010.09687/assets/Federated-Client.jpg" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="216" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1. </span>Logical Flow of Federated Learning for Video Analytics at Federated Client.</figcaption>
</figure>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>System Design and Implementation</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">The proposed system consists of <span id="S2.p1.1.1" class="ltx_text ltx_font_bold">Federated Clients </span>and a <span id="S2.p1.1.2" class="ltx_text ltx_font_bold">Federated Server</span>. The data flow goes as follows: A real-time video stream is captured by a camera and pre-processed at the Federated Client. It implements the video analytics logic to identify objects and training module to train a local model to be sent to the Federated Server. The Federated Server receives local models from each smart doorbell device and generates a global aggregated model. It distributes the aggregated global model back to the Federated Clients. The Federated Client uses this aggregated model to detect objects. The video analytics results from the Federated Client are sent to the Cloud layer for storage. This lets users access the doorbell anywhere and anytime. In the following, we present the functionality of each component and its implementation in detail.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1. </span>Federated Client</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Each smart doorbell is interfaced with a camera module to capture a video stream and PIR sensor to detect the motion of an object. We prototype the smart doorbell using WiFi-enabled Raspberry Pi 3 Model B+. Each smart doorbell hosts the Federated Client. In the following section, we present the software components of the Federated Client.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para ltx_noindent">
<p id="S2.SS1.p2.1" class="ltx_p"><span id="S2.SS1.p2.1.1" class="ltx_text ltx_font_bold">Device Registration and Authentication.</span> Each Federated Client implements device registration and authentication, which allows users to interact with the device anywhere and anytime (Circled  <svg id="S2.SS1.p2.1.pic1" class="ltx_picture" height="15.74" overflow="visible" version="1.1" width="15.74"><g transform="translate(0,15.74) matrix(1 0 0 -1 0 0) translate(7.87,0) translate(0,7.87)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 7.59 0 C 7.59 4.19 4.19 7.59 0 7.59 C -4.19 7.59 -7.59 4.19 -7.59 0 C -7.59 -4.19 -4.19 -7.59 0 -7.59 C 4.19 -7.59 7.59 -4.19 7.59 0 Z M 0 0" style="fill:none"></path><g transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)" fill="#000000" stroke="#000000"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S2.SS1.p2.1.pic1.1.1.1.1.1" class="ltx_text">1</span></foreignObject></g></g></svg> in Figure <a href="#S1.F1" title="Figure 1 ‣ 1. Introduction ‣ A Demonstration of Smart Doorbell Design Using Federated Deep Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>) in a secure manner. We implement it using AWS IoT Core. The device registry keeps a record of all registered devices. Moreover, it supports X.509 certificate-based authentication so that data is never exchanged without proven identity <cite class="ltx_cite ltx_citemacro_citep">(Intizar et al<span class="ltx_text">.</span>, <a href="#bib.bib12" title="" class="ltx_ref">2017</a>)</cite>.</p>
</div>
<div id="S2.SS1.p3" class="ltx_para ltx_noindent">
<p id="S2.SS1.p3.1" class="ltx_p"><span id="S2.SS1.p3.1.1" class="ltx_text ltx_font_bold">Frame Sampling.</span>
It samples a frame off of a live video stream from the camera attached with the Federated Client (Circled  <svg id="S2.SS1.p3.1.pic1" class="ltx_picture" height="15.74" overflow="visible" version="1.1" width="15.74"><g transform="translate(0,15.74) matrix(1 0 0 -1 0 0) translate(7.87,0) translate(0,7.87)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 7.59 0 C 7.59 4.19 4.19 7.59 0 7.59 C -4.19 7.59 -7.59 4.19 -7.59 0 C -7.59 -4.19 -4.19 -7.59 0 -7.59 C 4.19 -7.59 7.59 -4.19 7.59 0 Z M 0 0" style="fill:none"></path><g transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)" fill="#000000" stroke="#000000"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S2.SS1.p3.1.pic1.1.1.1.1.1" class="ltx_text">2</span></foreignObject></g></g></svg> in Figure <a href="#S1.F1" title="Figure 1 ‣ 1. Introduction ‣ A Demonstration of Smart Doorbell Design Using Federated Deep Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>). It packages the captured frames and sends raw footage to the video pre-processing component for further pre-processing.</p>
</div>
<div id="S2.SS1.p4" class="ltx_para ltx_noindent">
<p id="S2.SS1.p4.1" class="ltx_p"><span id="S2.SS1.p4.1.1" class="ltx_text ltx_font_bold">Video Pre-processing.</span> A considerable part of a video stream contains data that is not useful. This consumes a huge chunk of a network’s bandwidth and adds to computation cost unnecessarily. We employ spatial and temporal redundancy <cite class="ltx_cite ltx_citemacro_citep">(Ben Sada et al<span class="ltx_text">.</span>, <a href="#bib.bib2" title="" class="ltx_ref">2019</a>)</cite> to remove redundant and uninteresting parts (Circled  <svg id="S2.SS1.p4.1.pic1" class="ltx_picture" height="15.74" overflow="visible" version="1.1" width="15.74"><g transform="translate(0,15.74) matrix(1 0 0 -1 0 0) translate(7.87,0) translate(0,7.87)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 7.59 0 C 7.59 4.19 4.19 7.59 0 7.59 C -4.19 7.59 -7.59 4.19 -7.59 0 C -7.59 -4.19 -4.19 -7.59 0 -7.59 C 4.19 -7.59 7.59 -4.19 7.59 0 Z M 0 0" style="fill:none"></path><g transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)" fill="#000000" stroke="#000000"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S2.SS1.p4.1.pic1.1.1.1.1.1" class="ltx_text">3</span></foreignObject></g></g></svg> in Figure <a href="#S1.F1" title="Figure 1 ‣ 1. Introduction ‣ A Demonstration of Smart Doorbell Design Using Federated Deep Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>):</p>
</div>
<div id="S2.SS1.p5" class="ltx_para ltx_noindent">
<p id="S2.SS1.p5.1" class="ltx_p"><span id="S2.SS1.p5.1.1" class="ltx_text ltx_font_bold">– <span id="S2.SS1.p5.1.1.1" class="ltx_text ltx_font_italic">Temporal redundancy</span>.</span> It reduces consecutive and similar video frames, using various filtering techniques such as motion detection. The motion sensor triggers the camera if there is any motion in front of the doorbell. The integration of a motion sensor allows the Federated Client to process data only when there is a motion.</p>
</div>
<div id="S2.SS1.p6" class="ltx_para ltx_noindent">
<p id="S2.SS1.p6.1" class="ltx_p"><span id="S2.SS1.p6.1.1" class="ltx_text ltx_font_bold">– <span id="S2.SS1.p6.1.1.1" class="ltx_text ltx_font_italic">Spatial redundancy</span>.</span> It is represented by removing the background of a video frame, which is not always necessary for object detection. We employ background subtraction technique <cite class="ltx_cite ltx_citemacro_citep">(Pajankar, <a href="#bib.bib19" title="" class="ltx_ref">2015</a>)</cite> to extract the Region of Interest (RoI). It separates out foreground objects from the background. This technique is quite relevant for our smart doorbell as the background of an image largely remains uniform due to static camera. The RoI is sent to the object detection module for further processing, as discussed in Section <a href="#S2.SS2" title="2.2. Federated Learning ‣ 2. System Design and Implementation ‣ A Demonstration of Smart Doorbell Design Using Federated Deep Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.2</span></a>.</p>
</div>
<figure id="S2.F2" class="ltx_figure"><img src="/html/2010.09687/assets/Federated-Server.jpg" id="S2.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="318" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2. </span>Logical Flow of Federated Server hosted on AWS EC2 (Upper part). AWS Serverless Architecture (Lower Part).</figcaption>
</figure>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2. </span>Federated Learning</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">This component runs the <span id="S2.SS2.p1.1.1" class="ltx_text ltx_font_italic">Federated Learning</span> modules to train the object detection model locally, which are sent to the Federated Server for aggregation, and the <span id="S2.SS2.p1.1.2" class="ltx_text ltx_font_italic">Object Detection</span> module that uses an aggregated model from the Federated Server to detect objects.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para ltx_noindent">
<p id="S2.SS2.p2.1" class="ltx_p"><span id="S2.SS2.p2.1.1" class="ltx_text ltx_font_bold">DL-based Object Detection.</span> It is dedicated to running various object detection models. It takes the image as input from the video pre-processing module and runs various models to detect objects (Circled  <svg id="S2.SS2.p2.1.pic1" class="ltx_picture" height="15.74" overflow="visible" version="1.1" width="15.74"><g transform="translate(0,15.74) matrix(1 0 0 -1 0 0) translate(7.87,0) translate(0,7.87)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 7.59 0 C 7.59 4.19 4.19 7.59 0 7.59 C -4.19 7.59 -7.59 4.19 -7.59 0 C -7.59 -4.19 -4.19 -7.59 0 -7.59 C 4.19 -7.59 7.59 -4.19 7.59 0 Z M 0 0" style="fill:none"></path><g transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)" fill="#000000" stroke="#000000"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S2.SS2.p2.1.pic1.1.1.1.1.1" class="ltx_text">4</span></foreignObject></g></g></svg> in Figure <a href="#S1.F1" title="Figure 1 ‣ 1. Introduction ‣ A Demonstration of Smart Doorbell Design Using Federated Deep Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>). The current version implements four models: face detection and recognition, animal detection, unsafe content detection (such as violence, gun etc.) and a noteworthy vehicle detection such as a fire truck and a courier service (e.g., FedEx, USPS) van. For object detection, we adopt On-Device DL-approach. This approach employs various model reduction techniques <cite class="ltx_cite ltx_citemacro_citep">(Chen and Ran, <a href="#bib.bib5" title="" class="ltx_ref">2019</a>)</cite> (e.g., model compression, parameter pruning, parameter quantization, model design) to enable its deployment on IoT devices, while maintaining a reasonably good object detection accuracy. The current implementation uses MobileNets  <cite class="ltx_cite ltx_citemacro_citep">(Howard et al<span class="ltx_text">.</span>, <a href="#bib.bib11" title="" class="ltx_ref">2017</a>)</cite>, which is a family of computer vision models for TensorFlow, designed for resource-constrained devices such as mobile phones and embedded devices.</p>
</div>
<div id="S2.SS2.p3" class="ltx_para">
<p id="S2.SS2.p3.2" class="ltx_p">Depending on the detection results, the object detection module decides whether data needs to be sent to the Cloud layer or it is to be kept in local memory of the doorbell. For instance, if an object is identified by this module, the video analysis meta-data is sent to Cloud (Circled  <svg id="S2.SS2.p3.1.pic1" class="ltx_picture" height="15.74" overflow="visible" version="1.1" width="15.74"><g transform="translate(0,15.74) matrix(1 0 0 -1 0 0) translate(7.87,0) translate(0,7.87)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 7.59 0 C 7.59 4.19 4.19 7.59 0 7.59 C -4.19 7.59 -7.59 4.19 -7.59 0 C -7.59 -4.19 -4.19 -7.59 0 -7.59 C 4.19 -7.59 7.59 -4.19 7.59 0 Z M 0 0" style="fill:none"></path><g transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)" fill="#000000" stroke="#000000"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S2.SS2.p3.1.pic1.1.1.1.1.1" class="ltx_text">5</span></foreignObject></g></g></svg> in Figure <a href="#S1.F1" title="Figure 1 ‣ 1. Introduction ‣ A Demonstration of Smart Doorbell Design Using Federated Deep Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>). The image is stored in local memory in case the object is identified as new or unknown. The stored images are processed further by the training module (Circled  <svg id="S2.SS2.p3.2.pic2" class="ltx_picture" height="15.74" overflow="visible" version="1.1" width="15.74"><g transform="translate(0,15.74) matrix(1 0 0 -1 0 0) translate(7.87,0) translate(0,7.87)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 7.59 0 C 7.59 4.19 4.19 7.59 0 7.59 C -4.19 7.59 -7.59 4.19 -7.59 0 C -7.59 -4.19 -4.19 -7.59 0 -7.59 C 4.19 -7.59 7.59 -4.19 7.59 0 Z M 0 0" style="fill:none"></path><g transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)" fill="#000000" stroke="#000000"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S2.SS2.p3.2.pic2.1.1.1.1.1" class="ltx_text">6</span></foreignObject></g></g></svg> in Figure <a href="#S1.F1" title="Figure 1 ‣ 1. Introduction ‣ A Demonstration of Smart Doorbell Design Using Federated Deep Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>), as discussed in the next section.</p>
</div>
<div id="S2.SS2.p4" class="ltx_para ltx_noindent">
<p id="S2.SS2.p4.2" class="ltx_p"><span id="S2.SS2.p4.2.1" class="ltx_text ltx_font_bold">Federated Learning.</span>
This component is responsible for two tasks: first, image annotations to label locally stored images; second, the Federated Learning module uses these annotated images to build local models, typically contains model parameters and corresponding weights (Circled  <svg id="S2.SS2.p4.1.pic1" class="ltx_picture" height="15.74" overflow="visible" version="1.1" width="15.74"><g transform="translate(0,15.74) matrix(1 0 0 -1 0 0) translate(7.87,0) translate(0,7.87)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 7.59 0 C 7.59 4.19 4.19 7.59 0 7.59 C -4.19 7.59 -7.59 4.19 -7.59 0 C -7.59 -4.19 -4.19 -7.59 0 -7.59 C 4.19 -7.59 7.59 -4.19 7.59 0 Z M 0 0" style="fill:none"></path><g transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)" fill="#000000" stroke="#000000"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S2.SS2.p4.1.pic1.1.1.1.1.1" class="ltx_text">9</span></foreignObject></g></g></svg> in Figure <a href="#S1.F1" title="Figure 1 ‣ 1. Introduction ‣ A Demonstration of Smart Doorbell Design Using Federated Deep Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>). The image annotation module (Circled  <svg id="S2.SS2.p4.2.pic2" class="ltx_picture" height="15.74" overflow="visible" version="1.1" width="15.74"><g transform="translate(0,15.74) matrix(1 0 0 -1 0 0) translate(7.87,0) translate(0,7.87)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 7.59 0 C 7.59 4.19 4.19 7.59 0 7.59 C -4.19 7.59 -7.59 4.19 -7.59 0 C -7.59 -4.19 -4.19 -7.59 0 -7.59 C 4.19 -7.59 7.59 -4.19 7.59 0 Z M 0 0" style="fill:none"></path><g transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)" fill="#000000" stroke="#000000"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S2.SS2.p4.2.pic2.1.1.1.1.1" class="ltx_text">7</span></foreignObject></g></g></svg> in Figure <a href="#S1.F1" title="Figure 1 ‣ 1. Introduction ‣ A Demonstration of Smart Doorbell Design Using Federated Deep Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>) provides an interface that lets the smart doorbell owners specify a bounding box and the corresponding label information, similar to the work <cite class="ltx_cite ltx_citemacro_citep">(Liu et al<span class="ltx_text">.</span>, <a href="#bib.bib16" title="" class="ltx_ref">2020</a>)</cite>. This image annotation process requires the smart doorbell user to be able to visually identify where the objects of interest are located in a given image file and draw the bounding box and assign it to a category. We integrate LabelImg tool <cite class="ltx_cite ltx_citemacro_citep">(Tzutalin, <a href="#bib.bib22" title="" class="ltx_ref">2020</a>)</cite> to implement this functionality. This tool generates annotations as an XML file, which is automatically mapped to an appropriate system directory for model training.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3. </span>Federated Server at Cloud</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">It receives model updates learned at Client. It performs model aggregation on them to produce a global aggregated model and distributes back it in the federation to be used for inference in object detection operations (Circled  <svg id="S2.SS3.p1.1.pic1" class="ltx_picture" height="20.79" overflow="visible" version="1.1" width="20.79"><g transform="translate(0,20.79) matrix(1 0 0 -1 0 0) translate(10.4,0) translate(0,10.4)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 10.12 0 C 10.12 5.59 5.59 10.12 0 10.12 C -5.59 10.12 -10.12 5.59 -10.12 0 C -10.12 -5.59 -5.59 -10.12 0 -10.12 C 5.59 -10.12 10.12 -5.59 10.12 0 Z M 0 0" style="fill:none"></path><g transform="matrix(1.0 0.0 0.0 1.0 -6.92 -4.46)" fill="#000000" stroke="#000000"><foreignObject width="13.84" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S2.SS3.p1.1.pic1.1.1.1.1.1" class="ltx_text">10</span></foreignObject></g></g></svg> in Figure <a href="#S1.F1" title="Figure 1 ‣ 1. Introduction ‣ A Demonstration of Smart Doorbell Design Using Federated Deep Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>).</p>
</div>
<div id="S2.SS3.p2" class="ltx_para">
<p id="S2.SS3.p2.1" class="ltx_p">The model aggregation algorithm leverages Horizontal Federated Learning (HFL) <cite class="ltx_cite ltx_citemacro_citep">(Yang
et al<span class="ltx_text">.</span>, <a href="#bib.bib23" title="" class="ltx_ref">2019</a>)</cite>. It can be applied in collaborative learning scenarios in which the device shares the same feature space but it is collected from different devices. HFL is suitable for our smart doorbell application scenario as it aims to help multiple devices with data from the same feature space (i.e., labelled image data) to train a global aggregated object detection model. The algorithm performs component-wise parameter averaging which are weighed based on the proportion of data points contributed by each participating doorbell device. The following is federated averaging equation <cite class="ltx_cite ltx_citemacro_citep">(McMahan
et al<span class="ltx_text">.</span>, <a href="#bib.bib17" title="" class="ltx_ref">2016</a>)</cite>:</p>
</div>
<div id="S2.SS3.p3" class="ltx_para">
<table id="S2.Ex1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.Ex1.m1.6" class="ltx_Math" alttext="f(w)=\sum\limits_{k=1}^{K}\frac{n_{k}}{n}F_{k}(w)\quad\textrm{where}\quad F_{k}(w)=\frac{1}{n_{k}}\sum\limits_{i\in P_{k}}f_{i}(w)." display="block"><semantics id="S2.Ex1.m1.6a"><mrow id="S2.Ex1.m1.6.6.1"><mrow id="S2.Ex1.m1.6.6.1.1.2" xref="S2.Ex1.m1.6.6.1.1.3.cmml"><mrow id="S2.Ex1.m1.6.6.1.1.1.1" xref="S2.Ex1.m1.6.6.1.1.1.1.cmml"><mrow id="S2.Ex1.m1.6.6.1.1.1.1.3" xref="S2.Ex1.m1.6.6.1.1.1.1.3.cmml"><mi id="S2.Ex1.m1.6.6.1.1.1.1.3.2" xref="S2.Ex1.m1.6.6.1.1.1.1.3.2.cmml">f</mi><mo lspace="0em" rspace="0em" id="S2.Ex1.m1.6.6.1.1.1.1.3.1" xref="S2.Ex1.m1.6.6.1.1.1.1.3.1.cmml">​</mo><mrow id="S2.Ex1.m1.6.6.1.1.1.1.3.3.2" xref="S2.Ex1.m1.6.6.1.1.1.1.3.cmml"><mo stretchy="false" id="S2.Ex1.m1.6.6.1.1.1.1.3.3.2.1" xref="S2.Ex1.m1.6.6.1.1.1.1.3.cmml">(</mo><mi id="S2.Ex1.m1.1.1" xref="S2.Ex1.m1.1.1.cmml">w</mi><mo stretchy="false" id="S2.Ex1.m1.6.6.1.1.1.1.3.3.2.2" xref="S2.Ex1.m1.6.6.1.1.1.1.3.cmml">)</mo></mrow></mrow><mo rspace="0.111em" id="S2.Ex1.m1.6.6.1.1.1.1.2" xref="S2.Ex1.m1.6.6.1.1.1.1.2.cmml">=</mo><mrow id="S2.Ex1.m1.6.6.1.1.1.1.1.1" xref="S2.Ex1.m1.6.6.1.1.1.1.1.2.cmml"><mrow id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.cmml"><munderover id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.cmml"><mo movablelimits="false" id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.2.2" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.2.2.cmml">∑</mo><mrow id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.2.3" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.2.3.cmml"><mi id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.2.3.2" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.2.3.2.cmml">k</mi><mo id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.2.3.1" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.2.3.1.cmml">=</mo><mn id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.2.3.3" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.2.3.3.cmml">1</mn></mrow><mi id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.3" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.3.cmml">K</mi></munderover><mrow id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.2" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.2.cmml"><mfrac id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.2.2" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.2.2.cmml"><msub id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.2.2.2" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.2.2.2.cmml"><mi id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.2.2.2.2" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.2.2.2.2.cmml">n</mi><mi id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.2.2.2.3" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.2.2.2.3.cmml">k</mi></msub><mi id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.2.2.3" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.2.2.3.cmml">n</mi></mfrac><mo lspace="0em" rspace="0em" id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.2.1" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.2.1.cmml">​</mo><msub id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.2.3" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.2.3.cmml"><mi id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.2.3.2" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.2.3.2.cmml">F</mi><mi id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.2.3.3" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.2.3.3.cmml">k</mi></msub><mo lspace="0em" rspace="0em" id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.2.1a" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.2.1.cmml">​</mo><mrow id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.2.4.2" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.2.4.2.1" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.2.cmml">(</mo><mi id="S2.Ex1.m1.2.2" xref="S2.Ex1.m1.2.2.cmml">w</mi><mo stretchy="false" id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.2.4.2.2" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.2.cmml">)</mo></mrow></mrow></mrow><mspace width="1em" id="S2.Ex1.m1.6.6.1.1.1.1.1.1.2" xref="S2.Ex1.m1.6.6.1.1.1.1.1.2.cmml"></mspace><mtext id="S2.Ex1.m1.5.5" xref="S2.Ex1.m1.5.5a.cmml">where</mtext></mrow></mrow><mspace width="1em" id="S2.Ex1.m1.6.6.1.1.2.3" xref="S2.Ex1.m1.6.6.1.1.3a.cmml"></mspace><mrow id="S2.Ex1.m1.6.6.1.1.2.2" xref="S2.Ex1.m1.6.6.1.1.2.2.cmml"><mrow id="S2.Ex1.m1.6.6.1.1.2.2.2" xref="S2.Ex1.m1.6.6.1.1.2.2.2.cmml"><msub id="S2.Ex1.m1.6.6.1.1.2.2.2.2" xref="S2.Ex1.m1.6.6.1.1.2.2.2.2.cmml"><mi id="S2.Ex1.m1.6.6.1.1.2.2.2.2.2" xref="S2.Ex1.m1.6.6.1.1.2.2.2.2.2.cmml">F</mi><mi id="S2.Ex1.m1.6.6.1.1.2.2.2.2.3" xref="S2.Ex1.m1.6.6.1.1.2.2.2.2.3.cmml">k</mi></msub><mo lspace="0em" rspace="0em" id="S2.Ex1.m1.6.6.1.1.2.2.2.1" xref="S2.Ex1.m1.6.6.1.1.2.2.2.1.cmml">​</mo><mrow id="S2.Ex1.m1.6.6.1.1.2.2.2.3.2" xref="S2.Ex1.m1.6.6.1.1.2.2.2.cmml"><mo stretchy="false" id="S2.Ex1.m1.6.6.1.1.2.2.2.3.2.1" xref="S2.Ex1.m1.6.6.1.1.2.2.2.cmml">(</mo><mi id="S2.Ex1.m1.3.3" xref="S2.Ex1.m1.3.3.cmml">w</mi><mo stretchy="false" id="S2.Ex1.m1.6.6.1.1.2.2.2.3.2.2" xref="S2.Ex1.m1.6.6.1.1.2.2.2.cmml">)</mo></mrow></mrow><mo id="S2.Ex1.m1.6.6.1.1.2.2.1" xref="S2.Ex1.m1.6.6.1.1.2.2.1.cmml">=</mo><mrow id="S2.Ex1.m1.6.6.1.1.2.2.3" xref="S2.Ex1.m1.6.6.1.1.2.2.3.cmml"><mfrac id="S2.Ex1.m1.6.6.1.1.2.2.3.2" xref="S2.Ex1.m1.6.6.1.1.2.2.3.2.cmml"><mn id="S2.Ex1.m1.6.6.1.1.2.2.3.2.2" xref="S2.Ex1.m1.6.6.1.1.2.2.3.2.2.cmml">1</mn><msub id="S2.Ex1.m1.6.6.1.1.2.2.3.2.3" xref="S2.Ex1.m1.6.6.1.1.2.2.3.2.3.cmml"><mi id="S2.Ex1.m1.6.6.1.1.2.2.3.2.3.2" xref="S2.Ex1.m1.6.6.1.1.2.2.3.2.3.2.cmml">n</mi><mi id="S2.Ex1.m1.6.6.1.1.2.2.3.2.3.3" xref="S2.Ex1.m1.6.6.1.1.2.2.3.2.3.3.cmml">k</mi></msub></mfrac><mo lspace="0em" rspace="0em" id="S2.Ex1.m1.6.6.1.1.2.2.3.1" xref="S2.Ex1.m1.6.6.1.1.2.2.3.1.cmml">​</mo><mrow id="S2.Ex1.m1.6.6.1.1.2.2.3.3" xref="S2.Ex1.m1.6.6.1.1.2.2.3.3.cmml"><munder id="S2.Ex1.m1.6.6.1.1.2.2.3.3.1" xref="S2.Ex1.m1.6.6.1.1.2.2.3.3.1.cmml"><mo movablelimits="false" id="S2.Ex1.m1.6.6.1.1.2.2.3.3.1.2" xref="S2.Ex1.m1.6.6.1.1.2.2.3.3.1.2.cmml">∑</mo><mrow id="S2.Ex1.m1.6.6.1.1.2.2.3.3.1.3" xref="S2.Ex1.m1.6.6.1.1.2.2.3.3.1.3.cmml"><mi id="S2.Ex1.m1.6.6.1.1.2.2.3.3.1.3.2" xref="S2.Ex1.m1.6.6.1.1.2.2.3.3.1.3.2.cmml">i</mi><mo id="S2.Ex1.m1.6.6.1.1.2.2.3.3.1.3.1" xref="S2.Ex1.m1.6.6.1.1.2.2.3.3.1.3.1.cmml">∈</mo><msub id="S2.Ex1.m1.6.6.1.1.2.2.3.3.1.3.3" xref="S2.Ex1.m1.6.6.1.1.2.2.3.3.1.3.3.cmml"><mi id="S2.Ex1.m1.6.6.1.1.2.2.3.3.1.3.3.2" xref="S2.Ex1.m1.6.6.1.1.2.2.3.3.1.3.3.2.cmml">P</mi><mi id="S2.Ex1.m1.6.6.1.1.2.2.3.3.1.3.3.3" xref="S2.Ex1.m1.6.6.1.1.2.2.3.3.1.3.3.3.cmml">k</mi></msub></mrow></munder><mrow id="S2.Ex1.m1.6.6.1.1.2.2.3.3.2" xref="S2.Ex1.m1.6.6.1.1.2.2.3.3.2.cmml"><msub id="S2.Ex1.m1.6.6.1.1.2.2.3.3.2.2" xref="S2.Ex1.m1.6.6.1.1.2.2.3.3.2.2.cmml"><mi id="S2.Ex1.m1.6.6.1.1.2.2.3.3.2.2.2" xref="S2.Ex1.m1.6.6.1.1.2.2.3.3.2.2.2.cmml">f</mi><mi id="S2.Ex1.m1.6.6.1.1.2.2.3.3.2.2.3" xref="S2.Ex1.m1.6.6.1.1.2.2.3.3.2.2.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S2.Ex1.m1.6.6.1.1.2.2.3.3.2.1" xref="S2.Ex1.m1.6.6.1.1.2.2.3.3.2.1.cmml">​</mo><mrow id="S2.Ex1.m1.6.6.1.1.2.2.3.3.2.3.2" xref="S2.Ex1.m1.6.6.1.1.2.2.3.3.2.cmml"><mo stretchy="false" id="S2.Ex1.m1.6.6.1.1.2.2.3.3.2.3.2.1" xref="S2.Ex1.m1.6.6.1.1.2.2.3.3.2.cmml">(</mo><mi id="S2.Ex1.m1.4.4" xref="S2.Ex1.m1.4.4.cmml">w</mi><mo stretchy="false" id="S2.Ex1.m1.6.6.1.1.2.2.3.3.2.3.2.2" xref="S2.Ex1.m1.6.6.1.1.2.2.3.3.2.cmml">)</mo></mrow></mrow></mrow></mrow></mrow></mrow><mo lspace="0em" id="S2.Ex1.m1.6.6.1.2">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.Ex1.m1.6b"><apply id="S2.Ex1.m1.6.6.1.1.3.cmml" xref="S2.Ex1.m1.6.6.1.1.2"><csymbol cd="ambiguous" id="S2.Ex1.m1.6.6.1.1.3a.cmml" xref="S2.Ex1.m1.6.6.1.1.2.3">formulae-sequence</csymbol><apply id="S2.Ex1.m1.6.6.1.1.1.1.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1"><eq id="S2.Ex1.m1.6.6.1.1.1.1.2.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.2"></eq><apply id="S2.Ex1.m1.6.6.1.1.1.1.3.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.3"><times id="S2.Ex1.m1.6.6.1.1.1.1.3.1.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.3.1"></times><ci id="S2.Ex1.m1.6.6.1.1.1.1.3.2.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.3.2">𝑓</ci><ci id="S2.Ex1.m1.1.1.cmml" xref="S2.Ex1.m1.1.1">𝑤</ci></apply><list id="S2.Ex1.m1.6.6.1.1.1.1.1.2.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1"><apply id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1"><apply id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1">superscript</csymbol><apply id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.2.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.2.1.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1">subscript</csymbol><sum id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.2.2.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.2.2"></sum><apply id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.2.3.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.2.3"><eq id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.2.3.1.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.2.3.1"></eq><ci id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.2.3.2.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.2.3.2">𝑘</ci><cn type="integer" id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.2.3.3.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.2.3.3">1</cn></apply></apply><ci id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.3.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.3">𝐾</ci></apply><apply id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.2.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.2"><times id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.2.1.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.2.1"></times><apply id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.2.2.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.2.2"><divide id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.2.2.1.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.2.2"></divide><apply id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.2.2.2.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.2.2.2.1.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.2.2.2">subscript</csymbol><ci id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.2.2.2.2.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.2.2.2.2">𝑛</ci><ci id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.2.2.2.3.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.2.2.2.3">𝑘</ci></apply><ci id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.2.2.3.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.2.2.3">𝑛</ci></apply><apply id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.2.3.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.2.3"><csymbol cd="ambiguous" id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.2.3.1.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.2.3">subscript</csymbol><ci id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.2.3.2.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.2.3.2">𝐹</ci><ci id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.2.3.3.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.2.3.3">𝑘</ci></apply><ci id="S2.Ex1.m1.2.2.cmml" xref="S2.Ex1.m1.2.2">𝑤</ci></apply></apply><ci id="S2.Ex1.m1.5.5a.cmml" xref="S2.Ex1.m1.5.5"><mtext id="S2.Ex1.m1.5.5.cmml" xref="S2.Ex1.m1.5.5">where</mtext></ci></list></apply><apply id="S2.Ex1.m1.6.6.1.1.2.2.cmml" xref="S2.Ex1.m1.6.6.1.1.2.2"><eq id="S2.Ex1.m1.6.6.1.1.2.2.1.cmml" xref="S2.Ex1.m1.6.6.1.1.2.2.1"></eq><apply id="S2.Ex1.m1.6.6.1.1.2.2.2.cmml" xref="S2.Ex1.m1.6.6.1.1.2.2.2"><times id="S2.Ex1.m1.6.6.1.1.2.2.2.1.cmml" xref="S2.Ex1.m1.6.6.1.1.2.2.2.1"></times><apply id="S2.Ex1.m1.6.6.1.1.2.2.2.2.cmml" xref="S2.Ex1.m1.6.6.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S2.Ex1.m1.6.6.1.1.2.2.2.2.1.cmml" xref="S2.Ex1.m1.6.6.1.1.2.2.2.2">subscript</csymbol><ci id="S2.Ex1.m1.6.6.1.1.2.2.2.2.2.cmml" xref="S2.Ex1.m1.6.6.1.1.2.2.2.2.2">𝐹</ci><ci id="S2.Ex1.m1.6.6.1.1.2.2.2.2.3.cmml" xref="S2.Ex1.m1.6.6.1.1.2.2.2.2.3">𝑘</ci></apply><ci id="S2.Ex1.m1.3.3.cmml" xref="S2.Ex1.m1.3.3">𝑤</ci></apply><apply id="S2.Ex1.m1.6.6.1.1.2.2.3.cmml" xref="S2.Ex1.m1.6.6.1.1.2.2.3"><times id="S2.Ex1.m1.6.6.1.1.2.2.3.1.cmml" xref="S2.Ex1.m1.6.6.1.1.2.2.3.1"></times><apply id="S2.Ex1.m1.6.6.1.1.2.2.3.2.cmml" xref="S2.Ex1.m1.6.6.1.1.2.2.3.2"><divide id="S2.Ex1.m1.6.6.1.1.2.2.3.2.1.cmml" xref="S2.Ex1.m1.6.6.1.1.2.2.3.2"></divide><cn type="integer" id="S2.Ex1.m1.6.6.1.1.2.2.3.2.2.cmml" xref="S2.Ex1.m1.6.6.1.1.2.2.3.2.2">1</cn><apply id="S2.Ex1.m1.6.6.1.1.2.2.3.2.3.cmml" xref="S2.Ex1.m1.6.6.1.1.2.2.3.2.3"><csymbol cd="ambiguous" id="S2.Ex1.m1.6.6.1.1.2.2.3.2.3.1.cmml" xref="S2.Ex1.m1.6.6.1.1.2.2.3.2.3">subscript</csymbol><ci id="S2.Ex1.m1.6.6.1.1.2.2.3.2.3.2.cmml" xref="S2.Ex1.m1.6.6.1.1.2.2.3.2.3.2">𝑛</ci><ci id="S2.Ex1.m1.6.6.1.1.2.2.3.2.3.3.cmml" xref="S2.Ex1.m1.6.6.1.1.2.2.3.2.3.3">𝑘</ci></apply></apply><apply id="S2.Ex1.m1.6.6.1.1.2.2.3.3.cmml" xref="S2.Ex1.m1.6.6.1.1.2.2.3.3"><apply id="S2.Ex1.m1.6.6.1.1.2.2.3.3.1.cmml" xref="S2.Ex1.m1.6.6.1.1.2.2.3.3.1"><csymbol cd="ambiguous" id="S2.Ex1.m1.6.6.1.1.2.2.3.3.1.1.cmml" xref="S2.Ex1.m1.6.6.1.1.2.2.3.3.1">subscript</csymbol><sum id="S2.Ex1.m1.6.6.1.1.2.2.3.3.1.2.cmml" xref="S2.Ex1.m1.6.6.1.1.2.2.3.3.1.2"></sum><apply id="S2.Ex1.m1.6.6.1.1.2.2.3.3.1.3.cmml" xref="S2.Ex1.m1.6.6.1.1.2.2.3.3.1.3"><in id="S2.Ex1.m1.6.6.1.1.2.2.3.3.1.3.1.cmml" xref="S2.Ex1.m1.6.6.1.1.2.2.3.3.1.3.1"></in><ci id="S2.Ex1.m1.6.6.1.1.2.2.3.3.1.3.2.cmml" xref="S2.Ex1.m1.6.6.1.1.2.2.3.3.1.3.2">𝑖</ci><apply id="S2.Ex1.m1.6.6.1.1.2.2.3.3.1.3.3.cmml" xref="S2.Ex1.m1.6.6.1.1.2.2.3.3.1.3.3"><csymbol cd="ambiguous" id="S2.Ex1.m1.6.6.1.1.2.2.3.3.1.3.3.1.cmml" xref="S2.Ex1.m1.6.6.1.1.2.2.3.3.1.3.3">subscript</csymbol><ci id="S2.Ex1.m1.6.6.1.1.2.2.3.3.1.3.3.2.cmml" xref="S2.Ex1.m1.6.6.1.1.2.2.3.3.1.3.3.2">𝑃</ci><ci id="S2.Ex1.m1.6.6.1.1.2.2.3.3.1.3.3.3.cmml" xref="S2.Ex1.m1.6.6.1.1.2.2.3.3.1.3.3.3">𝑘</ci></apply></apply></apply><apply id="S2.Ex1.m1.6.6.1.1.2.2.3.3.2.cmml" xref="S2.Ex1.m1.6.6.1.1.2.2.3.3.2"><times id="S2.Ex1.m1.6.6.1.1.2.2.3.3.2.1.cmml" xref="S2.Ex1.m1.6.6.1.1.2.2.3.3.2.1"></times><apply id="S2.Ex1.m1.6.6.1.1.2.2.3.3.2.2.cmml" xref="S2.Ex1.m1.6.6.1.1.2.2.3.3.2.2"><csymbol cd="ambiguous" id="S2.Ex1.m1.6.6.1.1.2.2.3.3.2.2.1.cmml" xref="S2.Ex1.m1.6.6.1.1.2.2.3.3.2.2">subscript</csymbol><ci id="S2.Ex1.m1.6.6.1.1.2.2.3.3.2.2.2.cmml" xref="S2.Ex1.m1.6.6.1.1.2.2.3.3.2.2.2">𝑓</ci><ci id="S2.Ex1.m1.6.6.1.1.2.2.3.3.2.2.3.cmml" xref="S2.Ex1.m1.6.6.1.1.2.2.3.3.2.2.3">𝑖</ci></apply><ci id="S2.Ex1.m1.4.4.cmml" xref="S2.Ex1.m1.4.4">𝑤</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex1.m1.6c">f(w)=\sum\limits_{k=1}^{K}\frac{n_{k}}{n}F_{k}(w)\quad\textrm{where}\quad F_{k}(w)=\frac{1}{n_{k}}\sum\limits_{i\in P_{k}}f_{i}(w).</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div id="S2.SS3.p4" class="ltx_para">
<p id="S2.SS3.p4.1" class="ltx_p">The right-hand side of the above equation estimates the weight parameters for each smart doorbell device based on the loss values recorded across every data point (i.e., images) they trained with. The left side of the above equation scales each of those parameters and sums them all component-wise.</p>
</div>
<div id="S2.SS3.p5" class="ltx_para">
<p id="S2.SS3.p5.1" class="ltx_p">We have implemented the Federated Server using the Flask framework <cite class="ltx_cite ltx_citemacro_citep">(Flask, <a href="#bib.bib8" title="" class="ltx_ref">2020</a>)</cite> and hosted it on Amazon EC2. The Flask framework comes with an inbuilt web server. However, it is a single-threaded server, which is not ideal for our scenarios as the Federated Server has to handle multiple requests from Federated Clients. Therefore, we containerize the FlaskApp with Nginx <cite class="ltx_cite ltx_citemacro_citep">(Nginx, <a href="#bib.bib18" title="" class="ltx_ref">2020</a>)</cite> and Gunicorn <cite class="ltx_cite ltx_citemacro_citep">(Gunicorn, <a href="#bib.bib9" title="" class="ltx_ref">2020</a>)</cite>. The Gunicorn can handle multiple requests simultaneously. As a developer, you can configure Gunicorn with a number of workers and a number of threads it can run. These two parameters determine how much transactions you can handle at one point of time. The objective of using Nginx is to isolate the Federated Server logic from the Federated Clients. Second, it can act as a load balancer. Moreover, it can buffer multiple requests from clients and pass them to Gunicorn for further processing. This web application receives local model parameters from each client using HTTP POST request and distributes the global aggregated model back to each client.</p>
</div>
</section>
<section id="S2.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.4. </span>Serverless Architecture</h3>

<div id="S2.SS4.p1" class="ltx_para">
<p id="S2.SS4.p1.1" class="ltx_p">One of our design goals is to minimize video data transmissions to the Cloud to reduce cost. However, we still need to store important video data to access data remotely. Therefore, we use the cloud to store detection results. For the sake of completeness, we briefly present the functionality of a doorbell hosted on the serverless infrastructure of Cloud. For the detailed description, we recommend the readers to refer our work:</p>
</div>
<div id="S2.SS4.p2" class="ltx_para ltx_noindent">
<p id="S2.SS4.p2.2" class="ltx_p"><span id="S2.SS4.p2.2.1" class="ltx_text ltx_font_bold">Real-time Push Notification.</span> It sends a real-time alert notification to the user when a motion is detected in the proximity of the doorbell. We implement AWS Lambda functions that process the metadata in response to data ingestion <cite class="ltx_cite ltx_citemacro_citep">(Gyrard
et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2017</a>)</cite> from Kinesis and triggers the push notification (Circled  <svg id="S2.SS4.p2.1.pic1" class="ltx_picture" height="15.74" overflow="visible" version="1.1" width="15.74"><g transform="translate(0,15.74) matrix(1 0 0 -1 0 0) translate(7.87,0) translate(0,7.87)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 7.59 0 C 7.59 4.19 4.19 7.59 0 7.59 C -4.19 7.59 -7.59 4.19 -7.59 0 C -7.59 -4.19 -4.19 -7.59 0 -7.59 C 4.19 -7.59 7.59 -4.19 7.59 0 Z M 0 0" style="fill:none"></path><g transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)" fill="#000000" stroke="#000000"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S2.SS4.p2.1.pic1.1.1.1.1.1" class="ltx_text">1</span></foreignObject></g></g></svg>– <svg id="S2.SS4.p2.2.pic2" class="ltx_picture" height="15.74" overflow="visible" version="1.1" width="15.74"><g transform="translate(0,15.74) matrix(1 0 0 -1 0 0) translate(7.87,0) translate(0,7.87)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 7.59 0 C 7.59 4.19 4.19 7.59 0 7.59 C -4.19 7.59 -7.59 4.19 -7.59 0 C -7.59 -4.19 -4.19 -7.59 0 -7.59 C 4.19 -7.59 7.59 -4.19 7.59 0 Z M 0 0" style="fill:none"></path><g transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)" fill="#000000" stroke="#000000"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S2.SS4.p2.2.pic2.1.1.1.1.1" class="ltx_text">3</span></foreignObject></g></g></svg> in Figure <a href="#S2.F2" title="Figure 2 ‣ 2.1. Federated Client ‣ 2. System Design and Implementation ‣ A Demonstration of Smart Doorbell Design Using Federated Deep Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>), which is implemented using Amazon Simple Notification Service.</p>
</div>
<div id="S2.SS4.p3" class="ltx_para ltx_noindent">
<p id="S2.SS4.p3.2" class="ltx_p"><span id="S2.SS4.p3.2.1" class="ltx_text ltx_font_bold">Persistent Data Storage and Access.</span> It receives video analytics metadata from a doorbell and provides a scalable storage to access data anywhere and anytime. We implement the storage services using Amazon DynamoDB and Amazon S3 (Circled  <svg id="S2.SS4.p3.1.pic1" class="ltx_picture" height="15.74" overflow="visible" version="1.1" width="15.74"><g transform="translate(0,15.74) matrix(1 0 0 -1 0 0) translate(7.87,0) translate(0,7.87)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 7.59 0 C 7.59 4.19 4.19 7.59 0 7.59 C -4.19 7.59 -7.59 4.19 -7.59 0 C -7.59 -4.19 -4.19 -7.59 0 -7.59 C 4.19 -7.59 7.59 -4.19 7.59 0 Z M 0 0" style="fill:none"></path><g transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)" fill="#000000" stroke="#000000"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S2.SS4.p3.1.pic1.1.1.1.1.1" class="ltx_text">4</span></foreignObject></g></g></svg> in Figure <a href="#S2.F2" title="Figure 2 ‣ 2.1. Federated Client ‣ 2. System Design and Implementation ‣ A Demonstration of Smart Doorbell Design Using Federated Deep Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>), which are exposed by Amazon API Gateway (Circled  <svg id="S2.SS4.p3.2.pic2" class="ltx_picture" height="15.74" overflow="visible" version="1.1" width="15.74"><g transform="translate(0,15.74) matrix(1 0 0 -1 0 0) translate(7.87,0) translate(0,7.87)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 7.59 0 C 7.59 4.19 4.19 7.59 0 7.59 C -4.19 7.59 -7.59 4.19 -7.59 0 C -7.59 -4.19 -4.19 -7.59 0 -7.59 C 4.19 -7.59 7.59 -4.19 7.59 0 Z M 0 0" style="fill:none"></path><g transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)" fill="#000000" stroke="#000000"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S2.SS4.p3.2.pic2.1.1.1.1.1" class="ltx_text">5</span></foreignObject></g></g></svg> in Figure <a href="#S2.F2" title="Figure 2 ‣ 2.1. Federated Client ‣ 2. System Design and Implementation ‣ A Demonstration of Smart Doorbell Design Using Federated Deep Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>), which accommodates the requests from MobileApp.</p>
</div>
<div id="S2.SS4.p4" class="ltx_para ltx_noindent">
<p id="S2.SS4.p4.1" class="ltx_p"><span id="S2.SS4.p4.1.1" class="ltx_text ltx_font_bold">Conversational User Interface.</span> The voice assistant system leverages the logged video analytics results to provide a meaningful response. We implement an Alexa skill that can be triggered using the various voice commands (such as “<span id="S2.SS4.p4.1.2" class="ltx_text ltx_font_italic">Alexa, tell me what is happening at the door?</span>”, “<span id="S2.SS4.p4.1.3" class="ltx_text ltx_font_italic">Alexa, send me a snapshot of all activities at my door today</span>”). Our custom Alexa skill triggers a set of lambda functions, which queries the video analytics metadata stored in DynamoDB (Circled  <svg id="S2.SS4.p4.1.pic1" class="ltx_picture" height="15.74" overflow="visible" version="1.1" width="15.74"><g transform="translate(0,15.74) matrix(1 0 0 -1 0 0) translate(7.87,0) translate(0,7.87)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 7.59 0 C 7.59 4.19 4.19 7.59 0 7.59 C -4.19 7.59 -7.59 4.19 -7.59 0 C -7.59 -4.19 -4.19 -7.59 0 -7.59 C 4.19 -7.59 7.59 -4.19 7.59 0 Z M 0 0" style="fill:none"></path><g transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)" fill="#000000" stroke="#000000"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S2.SS4.p4.1.pic1.1.1.1.1.1" class="ltx_text">6</span></foreignObject></g></g></svg> in Figure <a href="#S2.F2" title="Figure 2 ‣ 2.1. Federated Client ‣ 2. System Design and Implementation ‣ A Demonstration of Smart Doorbell Design Using Federated Deep Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>). Once the query result is computed, the results are sent back through Alexa Voice.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>Demonstration</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">At the conference, we plan to demonstrate the following use cases:</p>
</div>
<div id="S3.p2" class="ltx_para ltx_noindent">
<p id="S3.p2.1" class="ltx_p"><span id="S3.p2.1.1" class="ltx_text ltx_font_bold">Use case 1: End-to-End Federated Learning Process for Video Analytics.</span>
It demonstrates an end-to-end Federated Learning process, implemented for the smart doorbell case study. It consists of transmitting the model parameters from each smart doorbell device after local model training. The updated model parameters are stored at the Federated Server as files. The federated Server combines these local model parameters and generates a global aggregated model, which is eventually distributed to each smart doorbell in the federation to be used for inference in object detection.</p>
</div>
<div id="S3.p3" class="ltx_para ltx_noindent">
<p id="S3.p3.1" class="ltx_p"><span id="S3.p3.1.1" class="ltx_text ltx_font_bold">Use case 2: Object Detection using Global Federated Model.</span> It demonstrates the live object detections by the doorbell. The system is initially at rest. An object entering the proximity of the doorbell enables the smart doorbell to start. This activity automatically triggers the object detection and recognition. The lower part of Figure <a href="#S3.F3" title="Figure 3 ‣ 3. Demonstration ‣ A Demonstration of Smart Doorbell Design Using Federated Deep Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>–(a) shows the MobileApp dashboard that provides the detailed activities at the doorbell. The notification messages include face recognition (including known and unknown persons) and object detection (e.g., noteworthy car, animal, etc.).</p>
</div>
<div id="S3.p4" class="ltx_para ltx_noindent">
<p id="S3.p4.1" class="ltx_p"><span id="S3.p4.1.1" class="ltx_text ltx_font_bold">Use case 3: Real-time Notifications using Global Federated Model.</span> It demonstrates the ability of sending real-time alerts to the user when a motion is detected in the proximity of the doorbell. Figure <a href="#S3.F3" title="Figure 3 ‣ 3. Demonstration ‣ A Demonstration of Smart Doorbell Design Using Federated Deep Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>–(b) shows an interface for real-time push notification. The user receives alerts on his mobile application when a visitor is detected at the door. The user can respond to the notification or just ”ignore” it. Figure <a href="#S3.F3" title="Figure 3 ‣ 3. Demonstration ‣ A Demonstration of Smart Doorbell Design Using Federated Deep Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>–(c) shows the video library. This interface of the MobileApp lets the users review activities and events at the door at a later time in case the user misses the real-time alert.</p>
</div>
<div id="S3.p5" class="ltx_para ltx_noindent">
<p id="S3.p5.1" class="ltx_p"><span id="S3.p5.1.1" class="ltx_text ltx_font_bold">Attendee Interactions.</span> To demonstrate the Federated Learning based Smart doorbell design, we will carry three smart doorbell devices with us. The smart doorbell devices will be used to demonstrate the functionality of Federated Clients. Moreover, they will be used to present the smart doorbell hardware and software design and to explain how different components of the system interact with each other. Moreover, we will demo our work to explain the overall functionality of the doorbell. We will invite conference participants who are willing to try our MobileApp that lets them interact with the intelligent doorbell. We will keep a QR code at the booth to help install our MobileApp. To create an efficient flow of people at the time of demonstration, we will have a video played in loop on a laptop that we will bring along with us.</p>
</div>
<div id="S3.p6" class="ltx_para ltx_noindent">
<p id="S3.p6.1" class="ltx_p"><span id="S3.p6.1.1" class="ltx_text ltx_font_bold">Technical Requirements.</span> For demonstration at the conference, we will carry the required set of Raspberry Pi kit with sensors to demonstrate the FL-based smart doorbell functionality, an iPhone to interact with the smart doorbell, and a laptop to demo a web smart doorbell interface. From the conference organizers, we would only require a reliable WiFi/Ethernet internet to connect the smart doorbell to the software components running on AWS.</p>
</div>
<figure id="S3.F3" class="ltx_figure"><img src="/html/2010.09687/assets/mobileapp.png" id="S3.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="314" height="197" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3. </span>Smart Doorbell Mobile App.</figcaption>
</figure>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>Conclusion and Future Work</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">Through this paper, we demonstrate an intelligent smart doorbell design using Federated Learning across edge and cloud resources. The proposed smart doorbell design reduces communication cost, as smart doorbell uploads a trained model parameters to the centralized server, instead of images. Second, the smart doorbell deploys On-Device Federated model (aggregated by the Federated Server) to reduce the object detection latency. Finally, it exchanges model instead of exchanging images, which provide with a sense of preserving privacy.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.1" class="ltx_p">We understand that “model aggregation rather than data aggregation” is not enough to address the user’s privacy concerns fully. As a part of our future, we plan to extend the existing prototype on <span id="S4.p2.1.1" class="ltx_text ltx_font_italic">homomorphic encryption</span> where computing is done on encrypted image data, <span id="S4.p2.1.2" class="ltx_text ltx_font_italic">Secure Multiparty Computation (SMC)</span> that enables multiple parties (i.e., smart doorbell devices deployed across a large building) to collaboratively compute an agreed-upon computation without leaking information from participants.</p>
</div>
<div class="ltx_acknowledgements">
<h6 class="ltx_title ltx_title_acknowledgements">Acknowledgements.</h6>
This publication has emanated from research supported by grants from the European Union’s Horizon 2020 research and innovation programme under grant agreement number 847577 (SMART 4.0 Marie Sklodowska-Curie actions COFUND) and from Science Foundation Ireland (SFI) under grant number SFI/16/RC/3918 (Confirm) cofunded by the European Regional Development Fund.

</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">        




</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ben Sada et al<span id="bib.bib2.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
A. Ben Sada, M. A.
Bouras, J. Ma, H. Runhe, and
H. Ning. 2019.

</span>
<span class="ltx_bibblock">A Distributed Video Analytics Architecture Based on
Edge-Computing and Federated Learning. In <em id="bib.bib2.3.1" class="ltx_emph ltx_font_italic">2019
IEEE Intl Conf on Dependable, Autonomic and Secure Computing, Intl Conf on
Pervasive Intelligence and Computing, Intl Conf on Cloud and Big Data
Computing, Intl Conf on Cyber Science and Technology Congress
(DASC/PiCom/CBDCom/CyberSciTech)</em>. 215–220.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chauhan et al<span id="bib.bib3.2.2.1" class="ltx_text">.</span> (2016a)</span>
<span class="ltx_bibblock">
S. Chauhan, P. Patel,
F. C. Delicato, and S. Chaudhary.
2016a.

</span>
<span class="ltx_bibblock">A Development Framework for Programming
Cyber-Physical Systems. In <em id="bib.bib3.3.1" class="ltx_emph ltx_font_italic">2016 IEEE/ACM 2nd
International Workshop on Software Engineering for Smart Cyber-Physical
Systems (SEsCPS)</em>. 47–53.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chauhan et al<span id="bib.bib4.2.2.1" class="ltx_text">.</span> (2016b)</span>
<span class="ltx_bibblock">
S. Chauhan, P. Patel,
A. Sureka, F. C. Delicato, and
S. Chaudhary. 2016b.

</span>
<span class="ltx_bibblock">Demonstration Abstract: IoTSuite - A Framework to
Design, Implement, and Deploy IoT Applications. In
<em id="bib.bib4.3.1" class="ltx_emph ltx_font_italic">2016 15th ACM/IEEE International Conference on
Information Processing in Sensor Networks (IPSN)</em>. 1–2.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen and Ran (2019)</span>
<span class="ltx_bibblock">
J. Chen and X.
Ran. 2019.

</span>
<span class="ltx_bibblock">Deep Learning With Edge Computing: A Review.

</span>
<span class="ltx_bibblock"><em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Proc. IEEE</em> 107,
8 (2019), 1655–1674.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Delaney (2020)</span>
<span class="ltx_bibblock">
John R. Delaney.
2020.

</span>
<span class="ltx_bibblock">The Best Video Doorbells for 2020.

</span>
<span class="ltx_bibblock">PC Magazine Article,
https://in.pcmag.com/home-security/118816/the-best-video-doorbells-for-2020.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Elgamal et al<span id="bib.bib7.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Tarek Elgamal, Shu Shi,
Varun Gupta, Rittwik Jana, and
Klara Nahrstedt. 2020.

</span>
<span class="ltx_bibblock">SiEVE: Semantically Encoded Video Analytics on Edge
and Cloud.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2006.01318 [cs.DC]

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Flask (2020)</span>
<span class="ltx_bibblock">
Flask. 2020.

</span>
<span class="ltx_bibblock">Flask – Web Develoment one drop at a time.

</span>
<span class="ltx_bibblock">Flask url
https://flask.palletsprojects.com/en/1.1.x/.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gunicorn (2020)</span>
<span class="ltx_bibblock">
Gunicorn. 2020.

</span>
<span class="ltx_bibblock">Gunicorn - Python WSGI HTTP Server for UNIX.

</span>
<span class="ltx_bibblock">Nginx url https://gunicorn.org/.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gyrard
et al<span id="bib.bib10.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Amelie Gyrard, Martin
Serrano, and Pankesh Patel.
2017.

</span>
<span class="ltx_bibblock">Chapter 11 - Building Interoperable and
Cross-Domain Semantic Web of Things Applications.

</span>
<span class="ltx_bibblock">In <em id="bib.bib10.3.1" class="ltx_emph ltx_font_italic">Managing the Web of Things</em>,
Quan Z. Sheng, Yongrui
Qin, Lina Yao, and Boualem Benatallah
(Eds.). Morgan Kaufmann, Boston,
305 – 324.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1016/B978-0-12-809764-9.00014-7" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1016/B978-0-12-809764-9.00014-7</a>

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Howard et al<span id="bib.bib11.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Andrew G. Howard, Menglong
Zhu, Bo Chen, Dmitry Kalenichenko,
Weijun Wang, Tobias Weyand,
Marco Andreetto, and Hartwig Adam.
2017.

</span>
<span class="ltx_bibblock">MobileNets: Efficient Convolutional Neural Networks
for Mobile Vision Applications.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:1704.04861 [cs.CV]

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Intizar et al<span id="bib.bib12.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Muhammad Intizar, Pankesh
Patel, Soumiya Kanti Datta, and Amelie
Gyrard. 2017.

</span>
<span class="ltx_bibblock">Multi-Layer Cross Domain Reasoning over
Distributed Autonomous IoT Applications.

</span>
<span class="ltx_bibblock"><em id="bib.bib12.3.1" class="ltx_emph ltx_font_italic">Open Journal of Internet of Things</em>
3 (2017).

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://hal-emse.ccsd.cnrs.fr/emse-01644333" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://hal-emse.ccsd.cnrs.fr/emse-01644333</a>

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Joshi et al<span id="bib.bib13.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Bhavin Joshi, Tapan
Pathak, Vatsal Patel, Sarth Kanani,
Pankesh Patel, and Muhammad Intizar
Ali. 2020.

</span>
<span class="ltx_bibblock">A Cloud-Based Smart Doorbell Using Low-Cost COTS
Devices. In <em id="bib.bib13.3.1" class="ltx_emph ltx_font_italic">10th International Conference on the
Internet of Things Companion</em> (Malmö, Sweden)
<em id="bib.bib13.4.2" class="ltx_emph ltx_font_italic">(IoT ’20 Companion)</em>. Association
for Computing Machinery, New York, NY, USA, Article
17, 4 pages.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3423423.3423465" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3423423.3423465</a>

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Konecný et al<span id="bib.bib14.2.2.1" class="ltx_text">.</span> (2016)</span>
<span class="ltx_bibblock">
Jakub Konecný,
H. Brendan McMahan, Felix X. Yu,
Peter Richtárik, Ananda Theertha
Suresh, and Dave Bacon.
2016.

</span>
<span class="ltx_bibblock">Federated Learning: Strategies for Improving
Communication Efficiency.

</span>
<span class="ltx_bibblock"><em id="bib.bib14.3.1" class="ltx_emph ltx_font_italic">CoRR</em> abs/1610.05492
(2016).

</span>
<span class="ltx_bibblock">arXiv:1610.05492

<a target="_blank" href="http://arxiv.org/abs/1610.05492" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/1610.05492</a>

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu
et al<span id="bib.bib15.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Peng Liu, Bozhao Qi,
and Suman Banerjee. 2018.

</span>
<span class="ltx_bibblock">EdgeEye: An Edge Service Framework for Real-Time
Intelligent Video Analytics. In <em id="bib.bib15.3.1" class="ltx_emph ltx_font_italic">Proceedings of the
1st International Workshop on Edge Systems, Analytics and Networking</em>
(Munich, Germany) <em id="bib.bib15.4.2" class="ltx_emph ltx_font_italic">(EdgeSys’18)</em>.
Association for Computing Machinery,
New York, NY, USA, 1–6.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3213344.3213345" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3213344.3213345</a>

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al<span id="bib.bib16.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Yang Liu, Anbu Huang,
Yun Luo, He Huang,
Youzhi Liu, Yuanyuan Chen,
Lican Feng, Tianjian Chen,
Han Yu, and Qiang Yang.
2020.

</span>
<span class="ltx_bibblock">FedVision: An Online Visual Object Detection Platform
Powered by Federated Learning.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2001.06202 [cs.LG]

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McMahan
et al<span id="bib.bib17.2.2.1" class="ltx_text">.</span> (2016)</span>
<span class="ltx_bibblock">
H. Brendan McMahan, Eider
Moore, Daniel Ramage, and
Blaise Agüera y Arcas.
2016.

</span>
<span class="ltx_bibblock">Federated Learning of Deep Networks using Model
Averaging.

</span>
<span class="ltx_bibblock"><em id="bib.bib17.3.1" class="ltx_emph ltx_font_italic">CoRR</em> abs/1602.05629
(2016).

</span>
<span class="ltx_bibblock">arXiv:1602.05629

<a target="_blank" href="http://arxiv.org/abs/1602.05629" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/1602.05629</a>

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nginx (2020)</span>
<span class="ltx_bibblock">
Nginx. 2020.

</span>
<span class="ltx_bibblock">Nginx – Part of F5.

</span>
<span class="ltx_bibblock">Nginx url https://www.nginx.com/.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pajankar (2015)</span>
<span class="ltx_bibblock">
Ashwin Pajankar.
2015.

</span>
<span class="ltx_bibblock"><em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">Raspberry Pi Computer Vision Programming</em>.

</span>
<span class="ltx_bibblock">Packt Publishing.

</span>
<span class="ltx_bibblock">

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Patel
et al<span id="bib.bib20.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Pankesh Patel, Amelie
Gyrard, Soumya Kanti Datta, and
Muhammad Intizar Ali. 2017.

</span>
<span class="ltx_bibblock">SWoTSuite: A Toolkit for Prototyping End-to-End
Semantic Web of Things Applications. In
<em id="bib.bib20.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 26th International Conference on
World Wide Web Companion</em> (Perth, Australia) <em id="bib.bib20.4.2" class="ltx_emph ltx_font_italic">(WWW ’17
Companion)</em>. International World Wide Web Conferences
Steering Committee, Republic and Canton of Geneva, CHE,
263–267.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3041021.3054736" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3041021.3054736</a>

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pathak et al<span id="bib.bib21.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Tapan Pathak, Vatsal
Patel, Sarth Kanani, Shailesh Arya,
Pankesh Patel, and Muhammad Intizar
Ali. 2020.

</span>
<span class="ltx_bibblock">A Distributed Framework to Orchestrate Video
Analytics across Edge and Cloud: A Use Case of Smart Doorbell. In
<em id="bib.bib21.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 10th International Conference on
the Internet of Things</em> (Malmö, Sweden) <em id="bib.bib21.4.2" class="ltx_emph ltx_font_italic">(IoT
’20)</em>. Association for Computing Machinery,
New York, NY, USA, Article 23,
8 pages.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3410992.3411013" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3410992.3411013</a>

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tzutalin (2020)</span>
<span class="ltx_bibblock">
Darrenl Tzutalin.
2020.

</span>
<span class="ltx_bibblock">LabelImg – LabelImg is a graphical image annotation
tool.

</span>
<span class="ltx_bibblock">Github Repository,
https://github.com/tzutalin/labelImg.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang
et al<span id="bib.bib23.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Qiang Yang, Yang Liu,
Tianjian Chen, and Yongxin Tong.
2019.

</span>
<span class="ltx_bibblock">Federated Machine Learning: Concept and
Applications.

</span>
<span class="ltx_bibblock"><em id="bib.bib23.3.1" class="ltx_emph ltx_font_italic">CoRR</em> abs/1902.04885
(2019).

</span>
<span class="ltx_bibblock">arXiv:1902.04885

<a target="_blank" href="http://arxiv.org/abs/1902.04885" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/1902.04885</a>

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2010.09686" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2010.09687" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2010.09687">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2010.09687" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2010.09688" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sat Mar  2 09:09:24 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
