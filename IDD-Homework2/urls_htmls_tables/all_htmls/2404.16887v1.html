<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Anomaly Detection for Incident Response at Scale</title>
<!--Generated on Tue Apr 30 18:33:23 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="Anomaly Detection,  AIOps,  Fault Management System" lang="en" name="keywords"/>
<base href="/html/2404.16887v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2404.16887v1#S1" title="In Anomaly Detection for Incident Response at Scale"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2404.16887v1#S2" title="In Anomaly Detection for Incident Response at Scale"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>System Engineering</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.16887v1#S2.SS1" title="In 2. System Engineering ‣ Anomaly Detection for Incident Response at Scale"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Architecture Overview</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.16887v1#S2.SS2" title="In 2. System Engineering ‣ Anomaly Detection for Incident Response at Scale"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Signal &amp; Model Orchestrator</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2404.16887v1#S2.SS3" title="In 2. System Engineering ‣ Anomaly Detection for Incident Response at Scale"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>MLO Components</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.16887v1#S2.SS3.SSS1" title="In 2.3. MLO Components ‣ 2. System Engineering ‣ Anomaly Detection for Incident Response at Scale"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3.1 </span>Model Hosting Service</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.16887v1#S2.SS3.SSS2" title="In 2.3. MLO Components ‣ 2. System Engineering ‣ Anomaly Detection for Incident Response at Scale"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3.2 </span>Model Management Service</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.16887v1#S2.SS3.SSS3" title="In 2.3. MLO Components ‣ 2. System Engineering ‣ Anomaly Detection for Incident Response at Scale"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3.3 </span>Model Training Service</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.16887v1#S2.SS4" title="In 2. System Engineering ‣ Anomaly Detection for Incident Response at Scale"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.4 </span>Model Monitoring and Self-Healing</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2404.16887v1#S3" title="In Anomaly Detection for Incident Response at Scale"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Methodology</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2404.16887v1#S3.SS1" title="In 3. Methodology ‣ Anomaly Detection for Incident Response at Scale"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Independent Algorithms</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.16887v1#S3.SS1.SSS1" title="In 3.1. Independent Algorithms ‣ 3. Methodology ‣ Anomaly Detection for Incident Response at Scale"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.1 </span>Core Predictive Algorithms:</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.16887v1#S3.SS1.SSS2" title="In 3.1. Independent Algorithms ‣ 3. Methodology ‣ Anomaly Detection for Incident Response at Scale"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.2 </span>Model Enhancement Techniques:</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.16887v1#S3.SS2" title="In 3. Methodology ‣ Anomaly Detection for Incident Response at Scale"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Model Onboarding Life-cycle</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.16887v1#S3.SS3" title="In 3. Methodology ‣ Anomaly Detection for Incident Response at Scale"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Experimental Results</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2404.16887v1#S4" title="In Anomaly Detection for Incident Response at Scale"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>System Validation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2404.16887v1#S5" title="In Anomaly Detection for Incident Response at Scale"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Conclusion</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">Anomaly Detection for Incident Response at Scale</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Hanzhang Wang
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id2.1.id1">Walmart Global Tech</span><span class="ltx_text ltx_affiliation_streetaddress" id="id3.2.id2">860 W California Ave</span><span class="ltx_text ltx_affiliation_city" id="id4.3.id3">Sunnyvale</span><span class="ltx_text ltx_affiliation_state" id="id5.4.id4">California</span><span class="ltx_text ltx_affiliation_country" id="id6.5.id5">USA</span><span class="ltx_text ltx_affiliation_postcode" id="id7.6.id6">94086</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:hanzhang.wang@walmart.com">hanzhang.wang@walmart.com</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Gowtham Kumar Tangirala
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id8.1.id1">Walmart Global Tech</span><span class="ltx_text ltx_affiliation_streetaddress" id="id9.2.id2">221 River Street</span><span class="ltx_text ltx_affiliation_city" id="id10.3.id3">Hoboken</span><span class="ltx_text ltx_affiliation_state" id="id11.4.id4">New Jersey</span><span class="ltx_text ltx_affiliation_country" id="id12.5.id5">USA</span><span class="ltx_text ltx_affiliation_postcode" id="id13.6.id6">07030</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:Gowthamkumar.Tangira@walmart.com">Gowthamkumar.Tangira@walmart.com</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Gilkara Pranav Naidu
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id14.1.id1">Walmart Global Tech</span><span class="ltx_text ltx_affiliation_streetaddress" id="id15.2.id2">15 John Street</span><span class="ltx_text ltx_affiliation_city" id="id16.3.id3">Toronto</span><span class="ltx_text ltx_affiliation_state" id="id17.4.id4">Ontario</span><span class="ltx_text ltx_affiliation_country" id="id18.5.id5">Canada</span><span class="ltx_text ltx_affiliation_postcode" id="id19.6.id6">M5V 3G6</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:Gilkarapranav.Naidu@walmart.com">Gilkarapranav.Naidu@walmart.com</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Charles Mayville
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id20.1.id1">Walmart Global Tech</span><span class="ltx_text ltx_affiliation_streetaddress" id="id21.2.id2">860 W California Ave</span><span class="ltx_text ltx_affiliation_city" id="id22.3.id3">Sunnyvale</span><span class="ltx_text ltx_affiliation_state" id="id23.4.id4">California</span><span class="ltx_text ltx_affiliation_country" id="id24.5.id5">USA</span><span class="ltx_text ltx_affiliation_postcode" id="id25.6.id6">94086</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:Charles.Mayville@walmart.com">Charles.Mayville@walmart.com</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Arighna Roy
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id26.1.id1">Walmart Global Tech</span><span class="ltx_text ltx_affiliation_streetaddress" id="id27.2.id2">221 River Street</span><span class="ltx_text ltx_affiliation_city" id="id28.3.id3">Hoboken</span><span class="ltx_text ltx_affiliation_state" id="id29.4.id4">New Jersey</span><span class="ltx_text ltx_affiliation_country" id="id30.5.id5">USA</span><span class="ltx_text ltx_affiliation_postcode" id="id31.6.id6">07030</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:Arighna.Roy@walmart.com">Arighna.Roy@walmart.com</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Joanne Sun
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id32.1.id1">Walmart Global Tech</span><span class="ltx_text ltx_affiliation_streetaddress" id="id33.2.id2">860 W California Ave</span><span class="ltx_text ltx_affiliation_city" id="id34.3.id3">Sunnyvale</span><span class="ltx_text ltx_affiliation_state" id="id35.4.id4">California</span><span class="ltx_text ltx_affiliation_country" id="id36.5.id5">USA</span><span class="ltx_text ltx_affiliation_postcode" id="id37.6.id6">94086</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:Joanne.Sun@walmart.com">Joanne.Sun@walmart.com</a>
</span></span></span>
<span class="ltx_author_before"> and </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Ramesh Babu Mandava
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id38.1.id1">Walmart Global Tech</span><span class="ltx_text ltx_affiliation_streetaddress" id="id39.2.id2">860 W California Ave</span><span class="ltx_text ltx_affiliation_city" id="id40.3.id3">Sunnyvale</span><span class="ltx_text ltx_affiliation_state" id="id41.4.id4">California</span><span class="ltx_text ltx_affiliation_country" id="id42.5.id5">USA</span><span class="ltx_text ltx_affiliation_postcode" id="id43.6.id6">94086</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:Rameshbabu.Mandava@walmart.com">Rameshbabu.Mandava@walmart.com</a>
</span></span></span>
</div>
<div class="ltx_dates">(2018)</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p class="ltx_p" id="id44.id1">We present a machine learning-based anomaly detection product, AI Detect and Respond (AIDR), that monitors Walmart’s business and system health in real-time. During the validation over 3 months, the product served predictions from over 3000 models to more than 25 application, platform, and operation teams, covering 63% of major incidents and reducing the mean-time-to-detect (MTTD) by more than 7 minutes. Unlike previous anomaly detection methods, our solution leverages statistical, ML and deep learning models while continuing to incorporate rule-based static thresholds to incorporate domain-specific knowledge.</p>
<p class="ltx_p" id="id45.id2">Both univariate and multivariate ML models are deployed and maintained through distributed services for scalability and high availability. AIDR has a feedback loop that assesses model quality with a combination of drift detection algorithms and customer feedback. It also offers self-onboarding capabilities and customizability.</p>
<p class="ltx_p" id="id46.id3">AIDR has achieved success with various internal teams with lower time to detection and fewer false positives than previous methods. As we move forward, we aim to expand incident coverage and prevention, reduce noise, and integrate further with root cause recommendation (RCR) to enable an end-to-end AIDR experience.</p>
</div>
<div class="ltx_keywords">Anomaly Detection, AIOps, Fault Management System
</div>
<span class="ltx_note ltx_note_frontmatter ltx_role_copyright" id="id1"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">copyright: </span>acmlicensed</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_journalyear" id="id2"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">journalyear: </span>2018</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_doi" id="id3"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">doi: </span>XXXXXXX.XXXXXXX</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_conference" id="id1a"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">conference: </span><math alttext="5^{th}" class="ltx_Math" display="inline" id="id1.m1.1"><semantics id="id1.m1.1b"><msup id="id1.m1.1.1" xref="id1.m1.1.1.cmml"><mn id="id1.m1.1.1.2" xref="id1.m1.1.1.2.cmml">5</mn><mrow id="id1.m1.1.1.3" xref="id1.m1.1.1.3.cmml"><mi id="id1.m1.1.1.3.2" xref="id1.m1.1.1.3.2.cmml">t</mi><mo id="id1.m1.1.1.3.1" xref="id1.m1.1.1.3.1.cmml">⁢</mo><mi id="id1.m1.1.1.3.3" xref="id1.m1.1.1.3.3.cmml">h</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="id1.m1.1c"><apply id="id1.m1.1.1.cmml" xref="id1.m1.1.1"><csymbol cd="ambiguous" id="id1.m1.1.1.1.cmml" xref="id1.m1.1.1">superscript</csymbol><cn id="id1.m1.1.1.2.cmml" type="integer" xref="id1.m1.1.1.2">5</cn><apply id="id1.m1.1.1.3.cmml" xref="id1.m1.1.1.3"><times id="id1.m1.1.1.3.1.cmml" xref="id1.m1.1.1.3.1"></times><ci id="id1.m1.1.1.3.2.cmml" xref="id1.m1.1.1.3.2">𝑡</ci><ci id="id1.m1.1.1.3.3.cmml" xref="id1.m1.1.1.3.3">ℎ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="id1.m1.1d">5^{th}</annotation><annotation encoding="application/x-llamapun" id="id1.m1.1e">5 start_POSTSUPERSCRIPT italic_t italic_h end_POSTSUPERSCRIPT</annotation></semantics></math> International Workshop on Cloud Intelligence/AIOps ; April 27th, 2024; San Diego, CA</span></span></span>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">In this paper, we present our work in developing a real-time anomaly detection product for Walmart. In such a complex organization, there are multiple dedicated teams focused on tracking crucial system health metrics in real-time to ensure smooth day-to-day operations. Any single failure can potentially trigger a domino effect and impact multiple dependent systems, cascading into a major incident that directly affects Walmart’s revenue stream. Therefore, it is imperative to detect and mitigate any such issue as soon as possible. Thus, anomaly detection (AD) in real-time holds great significance within Walmart’s operational landscape as it plays an important role in maintaining a seamless customer experience.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Traditional real-time anomaly detection efforts were driven primarily through rule-based alerting and eyeball monitoring. These approaches are time consuming, incomplete in their coverage, and agnostic to interdependent data patterns. In order to achieve high recall, rule-based alerting systems often increase alert volume in order to increase coverage, resulting in very low precision. This causes alert fatigue and reduces the efficacy. In contrast, ML-based solutions, when configured and trained carefully, offer improved accuracy and reduced noise. However, models are time consuming to maintain and hard to scale. Additionally, high knowledge barriers often limit the practicality of ML-based solutions to domain engineers with little ML know-how, risking wasted time and reduced accuracy.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">To address these issues, our anomaly detection solution, AIDR, is designed with the following key offerings:</p>
</div>
<div class="ltx_para" id="S1.p4">
<ol class="ltx_enumerate" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(1)</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S1.I1.i1.p1.1.1">Easy-to-customize and Adaptive Solution Flow</span>: AIDR interfaces are built with an emphasis on user-friendly design that offers a high degree of customizability for building AD models while minimizing required ML knowledge. It also allows customers to integrate their domain-specific knowledge and constraints when configuring alerts.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(2)</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S1.I1.i2.p1.1.1">API-Driven Design</span>: AIDR operates on a cloud infrastructure, enabling us to deliver a practical, scalable, self-service machine learning-based alert system that is capable of delivering accurate, smart, and adaptable alerts to any team that requires them. As a self-contained, API-driven, cloud-native end-to-end MLOps implementation, it scales efficiently and eliminates the necessity for any ad-hoc scripting.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(3)</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S1.I1.i3.p1.1.1">Self-Healing Model Life-cycle with Stability</span>: AIDR includes a self-healing model monitoring module with automatic drift detection and feedback monitoring features. This significantly reduces the need for manual intervention to maintain the model life-cycle, thereby rendering the system fully automatic, resulting in a reliable model life-cycle management.</p>
</div>
</li>
</ol>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">In this paper, we explore various aspects of AIDR in depth. In Section <a class="ltx_ref" href="https://arxiv.org/html/2404.16887v1#S2" title="2. System Engineering ‣ Anomaly Detection for Incident Response at Scale"><span class="ltx_text ltx_ref_tag">2</span></a>, we provide a high-level engineering architecture overview of AIDR. Section <a class="ltx_ref" href="https://arxiv.org/html/2404.16887v1#S3" title="3. Methodology ‣ Anomaly Detection for Incident Response at Scale"><span class="ltx_text ltx_ref_tag">3</span></a> focuses on the ML algorithms that underpin the solution. In Section <a class="ltx_ref" href="https://arxiv.org/html/2404.16887v1#S4" title="4. System Validation ‣ Anomaly Detection for Incident Response at Scale"><span class="ltx_text ltx_ref_tag">4</span></a>, we discuss its adoption within our organization and outline its impact on various internal teams. We provide a conclusion in Section <a class="ltx_ref" href="https://arxiv.org/html/2404.16887v1#S5" title="5. Conclusion ‣ Anomaly Detection for Incident Response at Scale"><span class="ltx_text ltx_ref_tag">5</span></a> and lay out plans for future development.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>System Engineering</h2>
<figure class="ltx_figure" id="S2.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="289" id="S2.F1.g1" src="extracted/2404.16887v1/figures/Final_Architecture.drawio.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1. </span>Anomaly Detection Platform Architecture</figcaption>
</figure>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1. </span>Architecture Overview</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">As shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2404.16887v1#S2.F1" title="Figure 1 ‣ 2. System Engineering ‣ Anomaly Detection for Incident Response at Scale"><span class="ltx_text ltx_ref_tag">1</span></a>, the high-level architecture of this system is comprised of four main subsystems: Signal &amp; Model Orchestrator (SMO), Machine Learning Orchestrator (MLO), Data Store, and the Model Monitoring / Self-Healing Component. The SMO provides APIs to the onboarding UI which allows customers and data scientists to register signals and train, register, and deploy models. SMO dispatches model training, model preview and model management requests to the relevant MLO components. At every minute, SMO scans the model registry and fetches real-time metrics from the Prometheus-based Managed Metric Database (MMD) for each model’s signals. Then, it calls Model Hosting Service to trigger predictions. The prediction scores and anomaly metrics are published back to MMD where they can be read by our own interfaces and customer tools. SMO also sends anomaly alerts as interactive Slack messages, allowing customers to mark those individual alerts as true or false positives, and stores that feedback data for future retraining.</p>
</div>
<div class="ltx_para" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1">The Model Monitoring and Self-Healing Components empower our ML life-cycle. They detect potential data drift by taking into account several statistical measures (discussed in Section <a class="ltx_ref" href="https://arxiv.org/html/2404.16887v1#S2.SS4" title="2.4. Model Monitoring and Self-Healing ‣ 2. System Engineering ‣ Anomaly Detection for Incident Response at Scale"><span class="ltx_text ltx_ref_tag">2.4</span></a>) via daily job. Once they identify the culprit models, they generate slack notifications to relevant stakeholders with a preview of suggested improvements to the model. If the user consents to the change, it seamlessly updates the model, which is utilized for real-time predictions immediately. This system allows us to preserve prediction quality and minimize manual intervention by both customers and data scientist during the models’ life-cycles.</p>
</div>
<div class="ltx_para" id="S2.SS1.p3">
<p class="ltx_p" id="S2.SS1.p3.1">The Data Store Component is responsible for storing all the ML artifacts such as signal data, serialized models, model registry, alert data and feedback data in a secure and organized manner.</p>
</div>
<div class="ltx_para" id="S2.SS1.p4">
<p class="ltx_p" id="S2.SS1.p4.1">Overall, the SMO, MLO, Model Monitoring and Self-Healing Components, and Data and Artifact Store work in tandem to ensure that the system is always learning and improving. With this architecture in place, AIDR can provide accurate and up-to-date predictions, making it an indispensable tool for site and platform reliability operations.</p>
</div>
<div class="ltx_para" id="S2.SS1.p5">
<p class="ltx_p" id="S2.SS1.p5.1">We have two routes to onboard customers to AIDR that takes advantage of the above-mentioned components. First, we provide a bespoke bulk onboarding strategy. Our data scientists collaborate with customers to determine the best selection of signals for their specific use case. They then build proof-of-concept (PoC) models for an initial validation before concurrently training and deploying hundreds of models. Each of these steps is executed by leveraging the API interface offered by SMO. This process typically takes about one month end-to-end for each customer.</p>
</div>
<div class="ltx_para" id="S2.SS1.p6">
<p class="ltx_p" id="S2.SS1.p6.1">Additionally, we also offer a user-friendly self-onboarding UI portal where users with little to no ML knowledge can visualize signals and train, preview, adjust, and deploy anomaly detection models in minutes with a few clicks of a button. They can independently maintain and manage these models and adjust parameters such as spike and drop thresholds in the univariate (UV) flow as in Figure <a class="ltx_ref" href="https://arxiv.org/html/2404.16887v1#S2.F2" title="Figure 2 ‣ 2.1. Architecture Overview ‣ 2. System Engineering ‣ Anomaly Detection for Incident Response at Scale"><span class="ltx_text ltx_ref_tag">2</span></a>, or model sensitivity and hold variables in the multivariate (MV) flow.</p>
</div>
<figure class="ltx_figure" id="S2.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="309" id="S2.F2.g1" src="extracted/2404.16887v1/figures/Self-service_UI.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2. </span>Anomaly Detection UI Univariate Model Onboarding</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2. </span>Signal &amp; Model Orchestrator</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">The SMO includes a variety of services including the Signal Service, Model Orchestrator Service, Inference Orchestrator, Signal Job, and Alert Service. These are designed to facilitate the onboarding UI for effective signal and model management. The SMO services are also instrumental in generating predictions and alerts, which are subsequently exposed to the MMD in the form of Prometheus metrics.</p>
</div>
<div class="ltx_para" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1">The first step of model onboarding involves signal registration, achieved through a Create Retrieve Update and Delete (CRUD) API interface. During signal registration, the specific signal name and the associated PromQL query are recorded. Once a signal is registered, 21 days’ worth of time series data is collected from the MMD (the maximum held by MMD) and saved as a signal dataset in the Data Store. The daily Signal Job ensures this data remains current with every new run. Subsequent steps usually entail model training and registration, utilizing the underlying MLO interface for model training. Following this, the model is associated with the appropriate communication channel for publishing alert events. These requirements are met using the API contracts offered by the Model Orchestrator Service.</p>
</div>
<div class="ltx_para" id="S2.SS2.p3">
<p class="ltx_p" id="S2.SS2.p3.1">The Inference Orchestrator performs inference for all registered models on a minute-by-minute basis through the MLO components. It subsequently pushes alert events through the Alert Service upon the detection of an anomaly. It also exposes the corresponding anomaly metric and the predicted signal values into the MMD. The integration of these metrics into MMD allows for effective visualization of the original and predicted signals and associated anomalies on the user dashboard we provide.</p>
</div>
<div class="ltx_para" id="S2.SS2.p4">
<p class="ltx_p" id="S2.SS2.p4.1">To accommodate the increasing number of models and signals, the Inference Orchestrator implements a distributed load sharing approach which is horizontally scalable. This is achieved by utilizing a host discovery tool and Raft consensus protocol to select a leader host that orchestrates the load sharing process. Upon the creation of a new pod, the discovery service propagates the creation event to all inference service pods, thereby rendering the new pod discoverable. Leveraging the Raft consensus algorithm <cite class="ltx_cite ltx_citemacro_citep">(Ongaro and Ousterhout, <a class="ltx_ref" href="https://arxiv.org/html/2404.16887v1#bib.bib12" title="">2014</a>)</cite>, a leader pod is subsequently elected within a few seconds to dispatch inference responsibilities to other stateless workers, thereby ensuring fault tolerance. The leader pod distributes the load to all non-leader pods using low latency gRPC. The non-leader pods perform prediction requests through MLO components, assigning prediction duties to them to prevent the occurrence of CPU spikes on the leader. Since the leader only distributes responsibilities, it never itself becomes a bottleneck.</p>
</div>
<div class="ltx_para" id="S2.SS2.p5">
<p class="ltx_p" id="S2.SS2.p5.1">Lastly, we make use of the Alert Service which provides a CRUD interface to publish alerts through Slack notifications. This allows the users to accomplish activities such as deleting or snoozing alerts seamlessly through buttons provided on the Slack notification. The alert data is also used to re-calibrate models using the Model Monitoring and Self-Healing components.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3. </span>MLO Components</h3>
<div class="ltx_para" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.1">The MLO components serve as building blocks to provide an interface for typical ML system requirements such as training, online inference and model configuration. All interactions with these components take place through the use of a versatile API-driven interface which ensures that a wide range of ML requirements can be fulfilled. Additionally, these fundamental services are designed to be stateless in nature, allowing the system to scale horizontally.</p>
</div>
<section class="ltx_subsubsection" id="S2.SS3.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.3.1. </span>Model Hosting Service</h4>
<div class="ltx_para" id="S2.SS3.SSS1.p1">
<p class="ltx_p" id="S2.SS3.SSS1.p1.1">The Hosting service surfaces prediction APIs that provide the system online inference capabilities. It lets us support more than 4000 model inferences per minute while accommodating various model types that may use entirely different ML stacks.</p>
</div>
<div class="ltx_para" id="S2.SS3.SSS1.p2">
<p class="ltx_p" id="S2.SS3.SSS1.p2.1">The primary challenges lie in optimizing the model inference speed and scalability. The inference speed of the worker is inversely correlated to the scaling cost of the entire system. Higher inference time per worker implies more concurrent workers are required to perform prediction within a one-minute time period. This directly translates into higher scaling costs as we onboard additional models into our system. In order to optimize latency and scaling cost we make use of a distributed hosting cache and employ a multi-tiered load-balancing approach.</p>
</div>
<div class="ltx_para" id="S2.SS3.SSS1.p3">
<p class="ltx_p" id="S2.SS3.SSS1.p3.1">The distributed model cache stores serialized models in memory for swift retrieval prior to prediction. In case the model is not already present in cache, it is fetched from the Model Store and inserted into the cache for future use. This approach significantly improves prediction speed and ensures limitless scalability by decoupling model store from prediction, making the service stateless.</p>
</div>
<div class="ltx_para" id="S2.SS3.SSS1.p4">
<p class="ltx_p" id="S2.SS3.SSS1.p4.1">Additionally, each hosting pod consists of several light-weight asynchronous workers. Leveraging the power of Kubernetes, we provide load-balancing at the worker, pod, and region levels, enhancing the resilience and fault tolerance of our system, resulting in a highly optimized inference service. In order to ensure this resiliency is maintained throughout the life of the system, releases undergo a thorough series of chaos testing.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S2.SS3.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.3.2. </span>Model Management Service</h4>
<div class="ltx_para" id="S2.SS3.SSS2.p1">
<p class="ltx_p" id="S2.SS3.SSS2.p1.1">The Model Management Service (MMS) provides a CRUD API interface to interact with the Model Registry and Model Configuration. The Model Registry serves as a record of all onboarded models, their current versions, and metadata such as model type, training parameters (including holding and smoothing windows), and static thresholds. The SMO utilizes the model registry to identify all models for which it needs to periodically deliver and publish inferences. The Model Configuration—stored alongside each model in the Model Store—serves as a record of configurations specific to the model type, including parameters like minimum training length, minimum prediction step, and other model-specific parameters. These configurations are used by the SMO to prepare the appropriate payload for real-time inferences. They are also used by the Model Training Service to set the default values of optional training parameters.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S2.SS3.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.3.3. </span>Model Training Service</h4>
<div class="ltx_para" id="S2.SS3.SSS3.p1">
<p class="ltx_p" id="S2.SS3.SSS3.p1.1">Model Training Service provides APIs that initiate training, a process that creates versioned model artifacts that are able to be used in inference. The API provides the capability to execute both model preview and training. While generating the model preview, we make use of a smaller subset of the dataset to fast-train a temporary model which is intended to provide the user a sense of the effectiveness of the model in detecting anomalies. If the user is satisfied with the preview, they can proceed with model training. The model training module utilizes 21 days of historical data to train the model and create a model artifact that is stored in the Model Store.</p>
</div>
<div class="ltx_para" id="S2.SS3.SSS3.p2">
<p class="ltx_p" id="S2.SS3.SSS3.p2.1">The training process starts with fetching the historical data from the Data Store and conducting data pre-processing. This is followed by Model Selection, in which the appropriate model training routine is identified and executed based on the model type specified in the API request. Once the model is trained, it goes through the Model Enrichment module for further refinement, to account for any smoothing or holding specified in the API request. We discuss this in detail in Section <a class="ltx_ref" href="https://arxiv.org/html/2404.16887v1#S3.SS1" title="3.1. Independent Algorithms ‣ 3. Methodology ‣ Anomaly Detection for Incident Response at Scale"><span class="ltx_text ltx_ref_tag">3.1</span></a>. In the final step, multivariate models go through the Model Explainability module, which generates the Model Explainability object. This object provides insight into the underlying cause of the detected anomaly for root cause analysis. The final model object is packaged, serialized and stored in the Model Store. If a model is to be registered into production (specified in the API request), the model metadata is passed on to the Model Management Service which updates the model registry.</p>
</div>
<div class="ltx_para" id="S2.SS3.SSS3.p3">
<p class="ltx_p" id="S2.SS3.SSS3.p3.1">Model training is a complex and time-consuming process that requires significant computational resources. Maintaining stability and scalability while being cost-efficient becomes the top priority in our design. We make use of Kubernetes-friendly serverless framework tailored to the specific requirements of model training, considering its infrequent usage and significant resource consumption. This serverless framework can automatically scale down to and up from zero, ensuring that we only utilize resources when there is a training request coming in.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S2.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.4. </span>Model Monitoring and Self-Healing</h3>
<div class="ltx_para" id="S2.SS4.p1">
<p class="ltx_p" id="S2.SS4.p1.1">We implemented a daily multiprocessing cron job designed to identify data and concept drift within each model. This was based on the deviation of the statistical distribution of signal data compared to the training data, along with the number of daily anomalies triggered. When a model is found to be faulty, a preview graph, visualizing models from both pre and post re-training, is dispatched to customers via Slack notifications. Model re-training automatically commences following customer approval or a timeout. The drift detection process, along with customer feedback, is used to refine the model parameters during the re-training of models. At present, data drift detection is grounded in five statistical methods: Kolmogorov-Smirnov test statistic, Population Stability Index (PSI), Kullback-Leibler divergence, Jensen-Shannon divergence, and Wasserstein distance.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>Methodology</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">Curating ML solutions for users with unique challenges requires a wide variety of models and model-enriching techniques. It also involves numerous iterations of model building. In this section, we lay out the end-to-end process of model onboarding in the context of these requirements.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1. </span>Independent Algorithms</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">AIDR is an amalgamation of ML predictive models, statistical estimators, explainable AI algorithms, and rule-based filtering. Our core ML model inventory accommodates a diverse set of algorithms that range from regression-based statistical models to advanced deep learning models. While deep learning models demonstrate superior predictive performance, they often suffer from performance bottlenecks in production and require additional attention <cite class="ltx_cite ltx_citemacro_citep">(Thompson et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2404.16887v1#bib.bib14" title="">2020</a>)</cite>. Further, less complicated solutions are often good fits for fast user adoption.</p>
</div>
<section class="ltx_subsubsection" id="S3.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.1. </span>Core Predictive Algorithms:</h4>
<div class="ltx_para" id="S3.SS1.SSS1.p1">
<p class="ltx_p" id="S3.SS1.SSS1.p1.1">At the core of the anomaly detection engine, we have ARIMA (Auto-Regressive Integrated Moving Average) <cite class="ltx_cite ltx_citemacro_citep">(Shumway and Stoffer, <a class="ltx_ref" href="https://arxiv.org/html/2404.16887v1#bib.bib13" title="">2017</a>)</cite>, XGBoost <cite class="ltx_cite ltx_citemacro_citep">(Chen and Guestrin, <a class="ltx_ref" href="https://arxiv.org/html/2404.16887v1#bib.bib4" title="">2016</a>)</cite>, Isolation Forest (IF) <cite class="ltx_cite ltx_citemacro_citep">(Liu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2404.16887v1#bib.bib10" title="">2008</a>)</cite>, and Variational Autoencoder <cite class="ltx_cite ltx_citemacro_citep">(Kingma and Welling, <a class="ltx_ref" href="https://arxiv.org/html/2404.16887v1#bib.bib7" title="">2013</a>)</cite> models, in conjunction with Inter-Quartile Range and Empirical Quantiles to estimate the respective decision boundaries for anomaly classification.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS1.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.2. </span>Model Enhancement Techniques:</h4>
<div class="ltx_para" id="S3.SS1.SSS2.p1">
<p class="ltx_p" id="S3.SS1.SSS2.p1.1">These add-ons are designed to assist the core algorithms to handle certain challenges:</p>
<ol class="ltx_enumerate" id="S3.I1">
<li class="ltx_item" id="S3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(1)</span>
<div class="ltx_para" id="S3.I1.i1.p1">
<p class="ltx_p" id="S3.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i1.p1.1.1">Noise injection:</span> Due to the data availability constraints in our Data Store, our ML models encounter sampling bias on the training data, especially during the onboarding phase. We employ a noise injection strategy in the training data to prevent overfitting of the trained model and make it immune to the benign spikes/ drops during inference <cite class="ltx_cite ltx_citemacro_citep">(Liu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2404.16887v1#bib.bib9" title="">2020</a>)</cite>.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(2)</span>
<div class="ltx_para" id="S3.I1.i2.p1">
<p class="ltx_p" id="S3.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i2.p1.1.1">Hold / Smoothing:</span> We further complement the predictive models with exponential smoothing <cite class="ltx_cite ltx_citemacro_citep">(Gardner Jr, <a class="ltx_ref" href="https://arxiv.org/html/2404.16887v1#bib.bib6" title="">1985</a>)</cite> and hold logic on the anomaly scores to make the alerts resistant to temporary spikes/drops. Unlike intrusion detection, AIOps for failure management has a higher tolerance for data behavior change <cite class="ltx_cite ltx_citemacro_citep">(Notaro et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2404.16887v1#bib.bib11" title="">2021</a>)</cite> <cite class="ltx_cite ltx_citemacro_citep">(Zhou et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2404.16887v1#bib.bib15" title="">2015</a>)</cite>. A detection alert is held back till the number of anomalous time points encountered within a given lookback window exceeds a certain limit.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(3)</span>
<div class="ltx_para" id="S3.I1.i3.p1">
<p class="ltx_p" id="S3.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i3.p1.1.1">Rule-Based filter:</span> To further reduce the false positive rate, we implemented a rule-based filter which acts as a safety net for extreme cases through several static thresholds <cite class="ltx_cite ltx_citemacro_citep">(Almalawi et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2404.16887v1#bib.bib2" title="">2020</a>)</cite> <cite class="ltx_cite ltx_citemacro_citep">(Duffield et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2404.16887v1#bib.bib5" title="">2009</a>)</cite>. These thresholds can act as a cheap way to incorporate domain knowledge in the model. These are often set to be the Service-Level Objectives (SLO) of customers.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(4)</span>
<div class="ltx_para" id="S3.I1.i4.p1">
<p class="ltx_p" id="S3.I1.i4.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i4.p1.1.1">Explainable AI:</span> Beyond the predictive accuracy, we extend the responsibility of our AIML solution through model explainability. We employ a set of SHAP (SHapley Additive exPlanations) based explainers that act as surrogate models on top of the core predictive models. When an anomaly is detected, they help identify the major contributing signals.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(5)</span>
<div class="ltx_para" id="S3.I1.i5.p1">
<p class="ltx_p" id="S3.I1.i5.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i5.p1.1.1">Seasonality:</span> If seasonality is observed in the input streaming signals, we use MEDIFF <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2404.16887v1#bib.bib8" title="">2020</a>)</cite> to extract the seasonality component. MEDIFF is a moving median smoothing-based seasonality extraction algorithm.</p>
</div>
</li>
</ol>
</div>
<div class="ltx_para" id="S3.SS1.SSS2.p2">
<p class="ltx_p" id="S3.SS1.SSS2.p2.1">Algorithm <a class="ltx_ref" href="https://arxiv.org/html/2404.16887v1#algorithm1" title="In 3.1.2. Model Enhancement Techniques: ‣ 3.1. Independent Algorithms ‣ 3. Methodology ‣ Anomaly Detection for Incident Response at Scale"><span class="ltx_text ltx_ref_tag">1</span></a> shows a schematic to demonstrate the workflow of the system that describes how an incoming request is processed through the pipeline.</p>
</div>
<figure class="ltx_float ltx_algorithm" id="algorithm1">
<div class="ltx_listing ltx_lst_numbers_left ltx_listing" id="algorithm1.8">
<div class="ltx_listingline" id="algorithm1.1.1">
<span class="ltx_text" id="algorithm1.1.1.1"><span class="ltx_text ltx_font_bold" id="algorithm1.1.1.1.1">Data:</span> </span> A rolling window of length <math alttext="n" class="ltx_Math" display="inline" id="algorithm1.1.1.m1.1"><semantics id="algorithm1.1.1.m1.1a"><mi id="algorithm1.1.1.m1.1.1" xref="algorithm1.1.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="algorithm1.1.1.m1.1b"><ci id="algorithm1.1.1.m1.1.1.cmml" xref="algorithm1.1.1.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.1.1.m1.1c">n</annotation><annotation encoding="application/x-llamapun" id="algorithm1.1.1.m1.1d">italic_n</annotation></semantics></math> sliced from the input streaming data
</div>
<div class="ltx_listingline" id="algorithm1.8.9">
<span class="ltx_text" id="algorithm1.8.9.1"><span class="ltx_text ltx_font_bold" id="algorithm1.8.9.1.1">Result:</span> </span> is_anomaly = True — False
</div>
<div class="ltx_listingline" id="algorithm1.2.2">
<span class="ltx_text ltx_font_bold" id="algorithm1.2.2.2">if</span> <em class="ltx_emph ltx_font_italic" id="algorithm1.2.2.1"># of time points breaching static thresholds <math alttext="\leq" class="ltx_Math" display="inline" id="algorithm1.2.2.1.m1.1"><semantics id="algorithm1.2.2.1.m1.1a"><mo id="algorithm1.2.2.1.m1.1.1" xref="algorithm1.2.2.1.m1.1.1.cmml">≤</mo><annotation-xml encoding="MathML-Content" id="algorithm1.2.2.1.m1.1b"><leq id="algorithm1.2.2.1.m1.1.1.cmml" xref="algorithm1.2.2.1.m1.1.1"></leq></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.2.2.1.m1.1c">\leq</annotation><annotation encoding="application/x-llamapun" id="algorithm1.2.2.1.m1.1d">≤</annotation></semantics></math> hold tolerance </em> <span class="ltx_text ltx_font_bold" id="algorithm1.2.2.3">then</span>
</div>
<div class="ltx_listingline" id="algorithm1.3.3">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
is_anomaly <math alttext="\leftarrow" class="ltx_Math" display="inline" id="algorithm1.3.3.m1.1"><semantics id="algorithm1.3.3.m1.1a"><mo id="algorithm1.3.3.m1.1.1" stretchy="false" xref="algorithm1.3.3.m1.1.1.cmml">←</mo><annotation-xml encoding="MathML-Content" id="algorithm1.3.3.m1.1b"><ci id="algorithm1.3.3.m1.1.1.cmml" xref="algorithm1.3.3.m1.1.1">←</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.3.3.m1.1c">\leftarrow</annotation><annotation encoding="application/x-llamapun" id="algorithm1.3.3.m1.1d">←</annotation></semantics></math> rule based decision;
</div>
<div class="ltx_listingline" id="algorithm1.8.10">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   

</div>
<div class="ltx_listingline" id="algorithm1.8.11">
<span class="ltx_text ltx_font_bold" id="algorithm1.8.11.1">else</span>
</div>
<div class="ltx_listingline" id="algorithm1.8.12">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
<span class="ltx_text ltx_font_typewriter" id="algorithm1.8.12.1">/* </span><span class="ltx_text ltx_font_typewriter" id="algorithm1.8.12.2">if applicable  */</span>
</div>
<div class="ltx_listingline" id="algorithm1.4.4">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
seasonal_component <math alttext="\leftarrow" class="ltx_Math" display="inline" id="algorithm1.4.4.m1.1"><semantics id="algorithm1.4.4.m1.1a"><mo id="algorithm1.4.4.m1.1.1" stretchy="false" xref="algorithm1.4.4.m1.1.1.cmml">←</mo><annotation-xml encoding="MathML-Content" id="algorithm1.4.4.m1.1b"><ci id="algorithm1.4.4.m1.1.1.cmml" xref="algorithm1.4.4.m1.1.1">←</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.4.4.m1.1c">\leftarrow</annotation><annotation encoding="application/x-llamapun" id="algorithm1.4.4.m1.1d">←</annotation></semantics></math> MEDIFF(Data);
</div>
<div class="ltx_listingline" id="algorithm1.8.13">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   

</div>
<div class="ltx_listingline" id="algorithm1.5.5">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   anomaly_scores <math alttext="\leftarrow" class="ltx_Math" display="inline" id="algorithm1.5.5.m1.1"><semantics id="algorithm1.5.5.m1.1a"><mo id="algorithm1.5.5.m1.1.1" stretchy="false" xref="algorithm1.5.5.m1.1.1.cmml">←</mo><annotation-xml encoding="MathML-Content" id="algorithm1.5.5.m1.1b"><ci id="algorithm1.5.5.m1.1.1.cmml" xref="algorithm1.5.5.m1.1.1">←</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.5.5.m1.1c">\leftarrow</annotation><annotation encoding="application/x-llamapun" id="algorithm1.5.5.m1.1d">←</annotation></semantics></math> core model prediction score(Data, seasonal_component);
</div>
<div class="ltx_listingline" id="algorithm1.8.14">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   

</div>
<div class="ltx_listingline" id="algorithm1.7.7">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   anomaly_counts <math alttext="\leftarrow" class="ltx_Math" display="inline" id="algorithm1.6.6.m1.1"><semantics id="algorithm1.6.6.m1.1a"><mo id="algorithm1.6.6.m1.1.1" stretchy="false" xref="algorithm1.6.6.m1.1.1.cmml">←</mo><annotation-xml encoding="MathML-Content" id="algorithm1.6.6.m1.1b"><ci id="algorithm1.6.6.m1.1.1.cmml" xref="algorithm1.6.6.m1.1.1">←</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.6.6.m1.1c">\leftarrow</annotation><annotation encoding="application/x-llamapun" id="algorithm1.6.6.m1.1d">←</annotation></semantics></math> exponential_smoothing(<math alttext="anomaly\_scores" class="ltx_Math" display="inline" id="algorithm1.7.7.m2.1"><semantics id="algorithm1.7.7.m2.1a"><mrow id="algorithm1.7.7.m2.1.1" xref="algorithm1.7.7.m2.1.1.cmml"><mi id="algorithm1.7.7.m2.1.1.2" xref="algorithm1.7.7.m2.1.1.2.cmml">a</mi><mo id="algorithm1.7.7.m2.1.1.1" xref="algorithm1.7.7.m2.1.1.1.cmml">⁢</mo><mi id="algorithm1.7.7.m2.1.1.3" xref="algorithm1.7.7.m2.1.1.3.cmml">n</mi><mo id="algorithm1.7.7.m2.1.1.1a" xref="algorithm1.7.7.m2.1.1.1.cmml">⁢</mo><mi id="algorithm1.7.7.m2.1.1.4" xref="algorithm1.7.7.m2.1.1.4.cmml">o</mi><mo id="algorithm1.7.7.m2.1.1.1b" xref="algorithm1.7.7.m2.1.1.1.cmml">⁢</mo><mi id="algorithm1.7.7.m2.1.1.5" xref="algorithm1.7.7.m2.1.1.5.cmml">m</mi><mo id="algorithm1.7.7.m2.1.1.1c" xref="algorithm1.7.7.m2.1.1.1.cmml">⁢</mo><mi id="algorithm1.7.7.m2.1.1.6" xref="algorithm1.7.7.m2.1.1.6.cmml">a</mi><mo id="algorithm1.7.7.m2.1.1.1d" xref="algorithm1.7.7.m2.1.1.1.cmml">⁢</mo><mi id="algorithm1.7.7.m2.1.1.7" xref="algorithm1.7.7.m2.1.1.7.cmml">l</mi><mo id="algorithm1.7.7.m2.1.1.1e" xref="algorithm1.7.7.m2.1.1.1.cmml">⁢</mo><mi id="algorithm1.7.7.m2.1.1.8" xref="algorithm1.7.7.m2.1.1.8.cmml">y</mi><mo id="algorithm1.7.7.m2.1.1.1f" xref="algorithm1.7.7.m2.1.1.1.cmml">⁢</mo><mi id="algorithm1.7.7.m2.1.1.9" mathvariant="normal" xref="algorithm1.7.7.m2.1.1.9.cmml">_</mi><mo id="algorithm1.7.7.m2.1.1.1g" xref="algorithm1.7.7.m2.1.1.1.cmml">⁢</mo><mi id="algorithm1.7.7.m2.1.1.10" xref="algorithm1.7.7.m2.1.1.10.cmml">s</mi><mo id="algorithm1.7.7.m2.1.1.1h" xref="algorithm1.7.7.m2.1.1.1.cmml">⁢</mo><mi id="algorithm1.7.7.m2.1.1.11" xref="algorithm1.7.7.m2.1.1.11.cmml">c</mi><mo id="algorithm1.7.7.m2.1.1.1i" xref="algorithm1.7.7.m2.1.1.1.cmml">⁢</mo><mi id="algorithm1.7.7.m2.1.1.12" xref="algorithm1.7.7.m2.1.1.12.cmml">o</mi><mo id="algorithm1.7.7.m2.1.1.1j" xref="algorithm1.7.7.m2.1.1.1.cmml">⁢</mo><mi id="algorithm1.7.7.m2.1.1.13" xref="algorithm1.7.7.m2.1.1.13.cmml">r</mi><mo id="algorithm1.7.7.m2.1.1.1k" xref="algorithm1.7.7.m2.1.1.1.cmml">⁢</mo><mi id="algorithm1.7.7.m2.1.1.14" xref="algorithm1.7.7.m2.1.1.14.cmml">e</mi><mo id="algorithm1.7.7.m2.1.1.1l" xref="algorithm1.7.7.m2.1.1.1.cmml">⁢</mo><mi id="algorithm1.7.7.m2.1.1.15" xref="algorithm1.7.7.m2.1.1.15.cmml">s</mi></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.7.7.m2.1b"><apply id="algorithm1.7.7.m2.1.1.cmml" xref="algorithm1.7.7.m2.1.1"><times id="algorithm1.7.7.m2.1.1.1.cmml" xref="algorithm1.7.7.m2.1.1.1"></times><ci id="algorithm1.7.7.m2.1.1.2.cmml" xref="algorithm1.7.7.m2.1.1.2">𝑎</ci><ci id="algorithm1.7.7.m2.1.1.3.cmml" xref="algorithm1.7.7.m2.1.1.3">𝑛</ci><ci id="algorithm1.7.7.m2.1.1.4.cmml" xref="algorithm1.7.7.m2.1.1.4">𝑜</ci><ci id="algorithm1.7.7.m2.1.1.5.cmml" xref="algorithm1.7.7.m2.1.1.5">𝑚</ci><ci id="algorithm1.7.7.m2.1.1.6.cmml" xref="algorithm1.7.7.m2.1.1.6">𝑎</ci><ci id="algorithm1.7.7.m2.1.1.7.cmml" xref="algorithm1.7.7.m2.1.1.7">𝑙</ci><ci id="algorithm1.7.7.m2.1.1.8.cmml" xref="algorithm1.7.7.m2.1.1.8">𝑦</ci><ci id="algorithm1.7.7.m2.1.1.9.cmml" xref="algorithm1.7.7.m2.1.1.9">_</ci><ci id="algorithm1.7.7.m2.1.1.10.cmml" xref="algorithm1.7.7.m2.1.1.10">𝑠</ci><ci id="algorithm1.7.7.m2.1.1.11.cmml" xref="algorithm1.7.7.m2.1.1.11">𝑐</ci><ci id="algorithm1.7.7.m2.1.1.12.cmml" xref="algorithm1.7.7.m2.1.1.12">𝑜</ci><ci id="algorithm1.7.7.m2.1.1.13.cmml" xref="algorithm1.7.7.m2.1.1.13">𝑟</ci><ci id="algorithm1.7.7.m2.1.1.14.cmml" xref="algorithm1.7.7.m2.1.1.14">𝑒</ci><ci id="algorithm1.7.7.m2.1.1.15.cmml" xref="algorithm1.7.7.m2.1.1.15">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.7.7.m2.1c">anomaly\_scores</annotation><annotation encoding="application/x-llamapun" id="algorithm1.7.7.m2.1d">italic_a italic_n italic_o italic_m italic_a italic_l italic_y _ italic_s italic_c italic_o italic_r italic_e italic_s</annotation></semantics></math>);
</div>
<div class="ltx_listingline" id="algorithm1.8.15">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   

</div>
<div class="ltx_listingline" id="algorithm1.8.8">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   is_anomaly <math alttext="\leftarrow" class="ltx_Math" display="inline" id="algorithm1.8.8.m1.1"><semantics id="algorithm1.8.8.m1.1a"><mo id="algorithm1.8.8.m1.1.1" stretchy="false" xref="algorithm1.8.8.m1.1.1.cmml">←</mo><annotation-xml encoding="MathML-Content" id="algorithm1.8.8.m1.1b"><ci id="algorithm1.8.8.m1.1.1.cmml" xref="algorithm1.8.8.m1.1.1">←</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.8.8.m1.1c">\leftarrow</annotation><annotation encoding="application/x-llamapun" id="algorithm1.8.8.m1.1d">←</annotation></semantics></math> apply_hold_tolerance(anomaly_counts)

</div>
<div class="ltx_listingline" id="algorithm1.8.16"> end if
</div>
<div class="ltx_listingline" id="algorithm1.8.17">
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span class="ltx_text ltx_font_bold" id="algorithm1.10.1.1">Algorithm 1</span> </span>Prediction flow of anomaly detection on streaming data</figcaption>
</figure>
</section>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2. </span>Model Onboarding Life-cycle</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">A quick model onboarding process comes with the potential cost of surgical changes during future iterations. To handle that, we wrap each algorithm into self-contained capsules that can easily be plugged into ensemble solutions. It makes our initial drafts adaptive to the iterative requirement changes of the customers.</p>
</div>
<figure class="ltx_table" id="S3.T1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1. </span>Comparative Analysis of Univariate Models for a Labeled Dataset</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S3.T1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T1.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.1.1.1.1">Models</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S3.T1.1.1.1.2">Precision</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S3.T1.1.1.1.3">Recall</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S3.T1.1.1.1.4">Balanced Accuracy</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T1.1.2.1">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.1.2.1.1">ARIMA</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.2.1.2">0.98</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.2.1.3">0.53</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.2.1.4">0.76</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.3.2">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.1.3.2.1">ARIMA+MEDIFF</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.3.2.2">0.97</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.3.2.3">0.70</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.3.2.4">0.85</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.4.3">
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.1.4.3.1">XGBoost</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T1.1.4.3.2">0.10</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T1.1.4.3.3">0.96</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T1.1.4.3.4">0.86</td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1">As described in Figure <a class="ltx_ref" href="https://arxiv.org/html/2404.16887v1#S3.T1" title="Table 1 ‣ 3.2. Model Onboarding Life-cycle ‣ 3. Methodology ‣ Anomaly Detection for Incident Response at Scale"><span class="ltx_text ltx_ref_tag">1</span></a>, we provide a self-onboarding process of models through an in-house UI supported by the SMO APIs. The plug-and-play model building interface, complemented with default configurations, provides an AutoML solution to customers with minimal ML know-how. Tier-1 customers require bulk onboarding and are supported by data scientists. Some of the models onboarded in bulk suffer from concept drift and turn into quiet and noisy models. A self-healing solution is designed to perform drift detection and autonomous re-training, as discussed in Section <a class="ltx_ref" href="https://arxiv.org/html/2404.16887v1#S2.SS4" title="2.4. Model Monitoring and Self-Healing ‣ 2. System Engineering ‣ Anomaly Detection for Incident Response at Scale"><span class="ltx_text ltx_ref_tag">2.4</span></a>.</p>
</div>
<div class="ltx_para" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.1">Our autonomous model maintenance system helps data scientists focus on new interesting use cases with unique problem statements. Our configuration-driven model-building pipeline makes it easy for data scientists to quickly iterate through the potential solutions during the ideation phase. Our centralized Artifact Store reduces the experimentation time to find a problem-solution fit while building PoC models. The non-intrusive nature of the algorithm plug-ins makes quick prototyping possible without risking the possibility of incremental efforts in the future.
</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3. </span>Experimental Results</h3>
<figure class="ltx_table" id="S3.T2">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2. </span>Comparative Analysis of Balanced Accuracy for Multivariate Models</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S3.T2.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T2.1.1.1">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.1.1.1.1">Dataset</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.1.2">IF</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.1.3">IF</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.1.4">IF</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.1.5">Autoencoder</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.2.2">
<td class="ltx_td ltx_border_l ltx_border_r" id="S3.T2.1.2.2.1"></td>
<td class="ltx_td ltx_border_r" id="S3.T2.1.2.2.2"></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.2.2.3">(hold)</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.2.2.4">(hold &amp; smoothing)</td>
<td class="ltx_td ltx_border_r" id="S3.T2.1.2.2.5"></td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.3.3">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.1.3.3.1">DS 1</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.3.3.2">0.70</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.3.3.3">0.74</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.3.3.4">0.75</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.3.3.5">0.81</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.4.4">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.1.4.4.1">DS 2</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.4.4.2">0.59</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.4.4.3">0.66</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.4.4.4">0.67</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.4.4.5">0.75</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.5.5">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.1.5.5.1">DS 3</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.5.5.2">0.64</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.5.5.3">0.70</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.5.5.4">0.71</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.5.5.5">0.72</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.6.6">
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.1.6.6.1">DS 4</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T2.1.6.6.2">0.65</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T2.1.6.6.3">0.70</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T2.1.6.6.4">0.71</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T2.1.6.6.5">0.81</td>
</tr>
</tbody>
</table>
</figure>
<figure class="ltx_table" id="S3.T3">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3. </span>AIDR Noise Reduction and Success</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S3.T3.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T3.1.1.1">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S3.T3.1.1.1.1">Customer</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.1.1.2">Noise</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.1.1.3">Incidents</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.1.1.4">Incidents</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.2.2">
<td class="ltx_td ltx_border_l ltx_border_r" id="S3.T3.1.2.2.1"></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T3.1.2.2.2">Reduction</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T3.1.2.2.3">Detected</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T3.1.2.2.4">Prevented</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.3.3">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S3.T3.1.3.3.1">Pricing &amp; Delivery</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.3.3.2">94%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.3.3.3">100% (4/4)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.3.3.4">2</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.4.4">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S3.T3.1.4.4.1">Payments</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.4.4.2">90%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.4.4.3">100% (3/3)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.4.4.4">2</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.5.5">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S3.T3.1.5.5.1">Networks</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.5.5.2">99%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.5.5.3">100% (3/3)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.5.5.4">2</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.6.6">
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="S3.T3.1.6.6.1">Operations</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T3.1.6.6.2">91%</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T3.1.6.6.3">56% (27/48)</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T3.1.6.6.4">1</td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2404.16887v1#S3.T1" title="Table 1 ‣ 3.2. Model Onboarding Life-cycle ‣ 3. Methodology ‣ Anomaly Detection for Incident Response at Scale"><span class="ltx_text ltx_ref_tag">1</span></a> shows the effectiveness of various supported model types for the UV flow through three evaluation metrics—precision, recall and balanced accuracy. These models were built for one of our point-of-sale traffic metrics and were validated over a period of 90 days. The models reported in Table <a class="ltx_ref" href="https://arxiv.org/html/2404.16887v1#S3.T1" title="Table 1 ‣ 3.2. Model Onboarding Life-cycle ‣ 3. Methodology ‣ Anomaly Detection for Incident Response at Scale"><span class="ltx_text ltx_ref_tag">1</span></a> were arrived at by maximizing the balanced accuracy score. We chose to consider the balanced accuracy as our key performance metric due to the extreme imbalance observed in our datasets. This metric, unlike traditional accuracy, gives equal weight to both false positives and false negatives, making it particularly effective for evaluating model performance on imbalanced data <cite class="ltx_cite ltx_citemacro_citep">(Brodersen et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2404.16887v1#bib.bib3" title="">2010</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S3.SS3.p2">
<p class="ltx_p" id="S3.SS3.p2.1">While an XGBoost classifier yields a superior recall of 96%, it severely suffers from a low precision of 10%. In contrast, a regression-based next-time-point-prediction model ARIMA yields an impressive precision of 98% while it suffers from a low recall of 53%. In practice, none of these extreme trade-offs are welcome for most of the user stories even though they yield a reasonable balanced accuracy. After combining MEDIFF with ARIMA, we see a significant improvement of recall (70% from 53%) for a negligible loss in precision and a higher balanced accuracy.</p>
</div>
<div class="ltx_para" id="S3.SS3.p3">
<p class="ltx_p" id="S3.SS3.p3.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2404.16887v1#S3.T2" title="Table 2 ‣ 3.3. Experimental Results ‣ 3. Methodology ‣ Anomaly Detection for Incident Response at Scale"><span class="ltx_text ltx_ref_tag">2</span></a> extends the comparative analysis for the MV flow to 4 datasets—DS1, DS2, DS3 and DS4—reporting the maximum balanced accuracy for each model type. DS1 corresponds to one of our E-commerce applications, DS2 to an internal database, DS3 to a critical application team, and DS4 to a critical group of operational infrastructure metrics. These models were validated over a period of 59 days.</p>
</div>
<div class="ltx_para" id="S3.SS3.p4">
<p class="ltx_p" id="S3.SS3.p4.1">For MV use cases, our first choice is Isolation Forest. It has a low memory requirement and linear time complexity. The accuracy of a vanilla IF can be improved with the add-on decision-enriching techniques for all four datasets. An Autoencoder outperforms Isolation Forest for every dataset at the cost of computational cost.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>System Validation</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">In this section, we present a few validation metrics and KPIs collected over the course of one business quarter that demonstrate the effectiveness of AIDR.</p>
</div>
<div class="ltx_para" id="S4.p2">
<p class="ltx_p" id="S4.p2.1">During the validation for over 90 days, the anomaly detection platform served out predictions from over 3000 models, providing real-time anomaly detection to around 30 application, internal platforms, operations teams. AIDR is the default go-to solution for anomaly detection within the platform site reliability team. These models alerted early for 37 major incidents and triggered at least 12 code changes, backouts, and other interventions that prevented potential incidents. Table <a class="ltx_ref" href="https://arxiv.org/html/2404.16887v1#S3.T3" title="Table 3 ‣ 3.3. Experimental Results ‣ 3. Methodology ‣ Anomaly Detection for Incident Response at Scale"><span class="ltx_text ltx_ref_tag">3</span></a> summarizes our high-level success around alert efficacy and noise reduction for 4 case study customers.</p>
</div>
<div class="ltx_para" id="S4.p3">
<p class="ltx_p" id="S4.p3.1">Our AD models designed for pricing and delivery applications have a 100% incident coverage rate and helped reduce MTTD by 7 minutes, with a 91% noise reduction compared to non-AIDR alerts. In two cases, our models were the only source of alerts for upcoming issues on unhealthy applications and directly led to code changes. For AD models built to track payment transactions, our models have a 100% incident coverage rate with an MTTD reduction of 14 minutes. Models here also worked to reduce mean-time-to-triage (MTTT). They were able to trace issues to specific payment authorizers and tender types in contrast to existing alerts, with an average of 16 minutes reduction in MTTT.</p>
</div>
<div class="ltx_para" id="S4.p4">
<p class="ltx_p" id="S4.p4.1">For our internal network platform, we built models that monitor network connections to detect distributed-denial-of-service (DDoS) attacks. These models helped prevent 4 attacks from becoming incidents and detected another 4 earlier than alternative alerting. These models have a 100% success rate in detecting DDoS attacks, with a 99% noise reduction compared to non-AIDR alerts. For one of our database platforms, we built models to identify servers with bad, overloaded queries. 70% of these alerts were found to be actionable.</p>
</div>
<div class="ltx_para" id="S4.p5">
<p class="ltx_p" id="S4.p5.1">For the Operations team, we built AD models to cover key business signals (including E-commerce traffic and metrics tracking online user journey) and critical application and network health metrics. Within our organization, the Operations team serves as the first responder to any major incidents, with its scope spanning multiple global markets. Consequently, our model coverage for this team is relatively lower, leading to lower incident coverage numbers. We were able to cover 56% of major incidents with a MTTD reduction of 7.2 minutes and prevent 1 incident, with a noise reduction of 91% compared to non-AIDR alerts. While the noise reduction in this case is highly desirable, there is significant room for improvement in terms of incident coverage.</p>
</div>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5. </span>Conclusion</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">In conclusion, our paper has presented a comprehensive, innovative, and scalable anomaly detection solution that harnesses statistical and machine learning models to deliver accurate, real-time alerts to production systems. The tech novelty of our solution lies in its ease of use for users with little to no ML know-how, its API-driven, scalable cloud-native design, its utilization of advanced algorithms bolstered by non-intrusive and algorithm plug-ins, and its implementation of a self-healing module for automated model life-cycle management. Its adoption and impact within our organization has been significant, providing our customers with an alternative to traditional means of alerting. We have identified some areas where significant improvement can be made, particularly with the Operations team. Going forward, we would like to incorporate our solution with a Root Cause Recommendation (RCR) system and generative AI empowered ChatOps to provide an end-to-end incident detection and triaging experience for our customers.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Almalawi et al<span class="ltx_text" id="bib.bib2.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Abdulmohsen Almalawi, Adil Fahad, Zahir Tari, Asif Irshad Khan, Nouf Alzahrani, Sheikh Tahir Bakhsh, Madini O. Alassafi, Abdulrahman Alshdadi, and Sana Qaiyum. 2020.

</span>
<span class="ltx_bibblock">Add-On Anomaly Threshold Technique for Improving Unsupervised Intrusion Detection on SCADA Data.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib2.3.1">Electronics</em> 9, 6 (2020).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.3390/electronics9061017" title="">https://doi.org/10.3390/electronics9061017</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brodersen et al<span class="ltx_text" id="bib.bib3.2.2.1">.</span> (2010)</span>
<span class="ltx_bibblock">
Kay H Brodersen, Cheng S Ong, Klaas E Stephan, and Joachim M Buhmann. 2010.

</span>
<span class="ltx_bibblock">The balanced accuracy and its posterior distribution. In <em class="ltx_emph ltx_font_italic" id="bib.bib3.3.1">2010 20th International Conference on Pattern Recognition</em>. IEEE, 3121–3124.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen and Guestrin (2016)</span>
<span class="ltx_bibblock">
Tianqi Chen and Carlos Guestrin. 2016.

</span>
<span class="ltx_bibblock">Xgboost: A scalable tree boosting system. In <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining</em>. 785–794.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Duffield et al<span class="ltx_text" id="bib.bib5.2.2.1">.</span> (2009)</span>
<span class="ltx_bibblock">
N. Duffield, P. Haffner, B. Krishnamurthy, and H. Ringberg. 2009.

</span>
<span class="ltx_bibblock">Rule-Based Anomaly Detection on IP Flows. In <em class="ltx_emph ltx_font_italic" id="bib.bib5.3.1">IEEE INFOCOM 2009</em>. 424–432.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/INFCOM.2009.5061947" title="">https://doi.org/10.1109/INFCOM.2009.5061947</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gardner Jr (1985)</span>
<span class="ltx_bibblock">
Everette S Gardner Jr. 1985.

</span>
<span class="ltx_bibblock">Exponential smoothing: The state of the art.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">Journal of forecasting</em> 4, 1 (1985), 1–28.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kingma and Welling (2013)</span>
<span class="ltx_bibblock">
Diederik P Kingma and Max Welling. 2013.

</span>
<span class="ltx_bibblock">Auto-Encoding Variational Bayes.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">arXiv preprint arXiv:1312.6114</em> (2013).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span class="ltx_text" id="bib.bib8.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Tianwei Li, Yitong Geng, and Huai Jiang. 2020.

</span>
<span class="ltx_bibblock">Anomaly detection on seasonal metrics via robust time series decomposition.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.3.1">arXiv preprint arXiv:2008.09245</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al<span class="ltx_text" id="bib.bib9.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Bo Liu, Zhenguo Zhang, and Rongyi Cui. 2020.

</span>
<span class="ltx_bibblock">Efficient Time Series Augmentation Methods. In <em class="ltx_emph ltx_font_italic" id="bib.bib9.3.1">2020 13th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI)</em>. 1004–1009.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/CISP-BMEI51763.2020.9263602" title="">https://doi.org/10.1109/CISP-BMEI51763.2020.9263602</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al<span class="ltx_text" id="bib.bib10.2.2.1">.</span> (2008)</span>
<span class="ltx_bibblock">
Fei Tony Liu, Kai Ming Ting, and Zhi-Hua Zhou. 2008.

</span>
<span class="ltx_bibblock">Isolation forest. In <em class="ltx_emph ltx_font_italic" id="bib.bib10.3.1">2008 eighth ieee international conference on data mining</em>. IEEE, 413–422.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Notaro et al<span class="ltx_text" id="bib.bib11.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Paolo Notaro, Jorge Cardoso, and Michael Gerndt. 2021.

</span>
<span class="ltx_bibblock">A Survey of AIOps Methods for Failure Management.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.3.1">ACM Trans. Intell. Syst. Technol.</em> 12, 6, Article 81 (nov 2021), 45 pages.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3483424" title="">https://doi.org/10.1145/3483424</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ongaro and Ousterhout (2014)</span>
<span class="ltx_bibblock">
Diego Ongaro and John Ousterhout. 2014.

</span>
<span class="ltx_bibblock">In search of an understandable consensus algorithm. In <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">2014 USENIX annual technical conference (USENIX ATC 14)</em>. 305–319.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shumway and Stoffer (2017)</span>
<span class="ltx_bibblock">
Robert H. Shumway and David S. Stoffer. 2017.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">ARIMA Models</em>.

</span>
<span class="ltx_bibblock">Springer International Publishing, Cham, 75–163.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1007/978-3-319-52452-8_3" title="">https://doi.org/10.1007/978-3-319-52452-8_3</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Thompson et al<span class="ltx_text" id="bib.bib14.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Neil C Thompson, Kristjan Greenewald, Keeheon Lee, and Gabriel F Manso. 2020.

</span>
<span class="ltx_bibblock">The computational limits of deep learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib14.3.1">arXiv preprint arXiv:2007.05558</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et al<span class="ltx_text" id="bib.bib15.2.2.1">.</span> (2015)</span>
<span class="ltx_bibblock">
Chunjie Zhou, Shuang Huang, Naixue Xiong, Shuang-Hua Yang, Huiyun Li, Yuanqing Qin, and Xuan Li. 2015.

</span>
<span class="ltx_bibblock">Design and Analysis of Multimodel-Based Anomaly Intrusion Detection Systems in Industrial Process Automation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib15.3.1">IEEE Transactions on Systems, Man, and Cybernetics: Systems</em> 45, 10 (2015), 1345–1360.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/TSMC.2015.2415763" title="">https://doi.org/10.1109/TSMC.2015.2415763</a>
</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Tue Apr 30 18:33:23 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
