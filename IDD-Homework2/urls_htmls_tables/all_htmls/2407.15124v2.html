<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Chemical Reaction Extraction from Long Patent Documents</title>
<!--Generated on Tue Jul 23 07:11:05 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2407.15124v2/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.15124v2#S1" title="In Chemical Reaction Extraction from Long Patent Documents"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.15124v2#S2" title="In Chemical Reaction Extraction from Long Patent Documents"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Literature Review</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.15124v2#S3" title="In Chemical Reaction Extraction from Long Patent Documents"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Dataset</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.15124v2#S4" title="In Chemical Reaction Extraction from Long Patent Documents"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Task Formulation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.15124v2#S5" title="In Chemical Reaction Extraction from Long Patent Documents"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Baseline Models</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2407.15124v2#S6" title="In Chemical Reaction Extraction from Long Patent Documents"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Our Approach</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.15124v2#S6.SS1" title="In 6 Our Approach â€£ Chemical Reaction Extraction from Long Patent Documents"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.1 </span>BERT Embeddings</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.15124v2#S6.SS2" title="In 6 Our Approach â€£ Chemical Reaction Extraction from Long Patent Documents"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.2 </span>ChemBERT</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.15124v2#S6.SS3" title="In 6 Our Approach â€£ Chemical Reaction Extraction from Long Patent Documents"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.3 </span>Sentence-level Sequence Tagging</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.15124v2#S6.SS4" title="In 6 Our Approach â€£ Chemical Reaction Extraction from Long Patent Documents"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.4 </span>[CHEM] tokens</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.15124v2#S7" title="In Chemical Reaction Extraction from Long Patent Documents"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Evaluation Metrics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2407.15124v2#S8" title="In Chemical Reaction Extraction from Long Patent Documents"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8 </span>Results and Error Analysis</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2407.15124v2#S8.SS1" title="In 8 Results and Error Analysis â€£ Chemical Reaction Extraction from Long Patent Documents"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8.1 </span>Performance on In-Domain Test Set</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.15124v2#S8.SS1.SSS1" title="In 8.1 Performance on In-Domain Test Set â€£ 8 Results and Error Analysis â€£ Chemical Reaction Extraction from Long Patent Documents"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8.1.1 </span>Trigram vs BiLSTM CRF decoder for base BERT models</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.15124v2#S8.SS1.SSS2" title="In 8.1 Performance on In-Domain Test Set â€£ 8 Results and Error Analysis â€£ Chemical Reaction Extraction from Long Patent Documents"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8.1.2 </span>Base BERT vs ChemBERT models</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.15124v2#S8.SS1.SSS3" title="In 8.1 Performance on In-Domain Test Set â€£ 8 Results and Error Analysis â€£ Chemical Reaction Extraction from Long Patent Documents"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8.1.3 </span>Effect of Introducing [CHEM] tokens</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.15124v2#S8.SS2" title="In 8 Results and Error Analysis â€£ Chemical Reaction Extraction from Long Patent Documents"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8.2 </span>Generalization Performance Analysis</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.15124v2#S9" title="In Chemical Reaction Extraction from Long Patent Documents"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">9 </span>Discussion and Future Direction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.15124v2#S10" title="In Chemical Reaction Extraction from Long Patent Documents"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">10 </span>Conclusion</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Chemical Reaction Extraction from Long Patent Documents
<br class="ltx_break"/> </h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Aishwarya Jadhav
<br class="ltx_break"/>Language Technologies Institute 
<br class="ltx_break"/>Carnegie Mellon University 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id1.1.id1">anjadhav@cs.cmu.edu</span>
<br class="ltx_break"/>&amp;Ritam Dutt 
<br class="ltx_break"/>Language Technologies Institute 
<br class="ltx_break"/>Carnegie Mellon University 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id2.2.id2">rdutt@cs.cmu.edu</span>
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id3.id1">The task of searching through patent documents is crucial for chemical patent recommendation and retrieval. This can be enhanced by creating a patent knowledge base (ChemPatKB) to aid in prior art searches and to provide a platform for domain experts to explore new innovations in chemical compound synthesis and use-cases. An essential foundational component of this KB is the extraction of important reaction snippets from long patents documents which facilitates multiple downstream tasks such as reaction co-reference resolution and chemical entity role identification. In this work, we explore the problem of extracting reactions spans from chemical patents in order to create a reactions resource database. We formulate this task as a paragraph-level sequence tagging problem, where the system is required to return a sequence of paragraphs that contain a description of a reaction. We propose several approaches and modifications of the baseline models and study how different methods generalize across different domains of chemical patents.</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">The exponential publication rate in recent years and the fact that new innovations for chemical compound synthesis and use-cases are primarily mentioned first in patents before they appear in scientific articles makes the task of patent recommendation and retrieval crucial. However, publicly available patent recommendation systems are scarce; patents are mostly searched using Google Patents or USPTO, where recommendations are carried out through citation networks and topics. We intend to leverage key information about chemical processes from patents as well as publicly available external domain knowledge in order to improve retrieval and recommendation. To that end, we explore the idea of creating a patent knowledge base (ChemPatKB) to facilitate prior art search as well provide a means for domain experts to explore the KB in natural language queries.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Some of the major components of the proposed ChemPatKB include patents, authors, assignees, reactions, chemical compounds and roles and properties of chemicals. In this project, we deal mainly with the major recipes or reactions involved in the patent since reactions are an essential component of the Chemical KB and help focus on the more important spans within the long patent documents. The essence of the reaction extraction task involves document-level information extraction to detect the textual spans that describe or refer to chemical reactions.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">While most previous research in text mining of chemical reactions has focussed on chemical NER, there has been limited research on automatically extracting chemical reactions from patents. A chemical reaction is a process where a set of chemical compounds is transformed into another set of chemical compounds. A reaction description may include the source chemical compounds, solvents and reagents involved in the reaction, reaction conditions, and materials obtained as a result of the reaction. Once a reaction has been identified, it can be used as the input to (more complex) downstream tasks. For example, consider an event extraction system that extracts every step of a reaction as an individual event. Such downstream tasks require as input a paragraph sequence corresponding to a reaction, in a representation that preserves the order of the reaction substeps. Our end goal is to create such a database of reaction sequences, much larger and encompassing more domains than the ones available presently.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">We build on top of the baseline model <cite class="ltx_cite ltx_citemacro_cite">Yoshikawa etÂ al. [<a class="ltx_ref" href="https://arxiv.org/html/2407.15124v2#bib.bib14" title="">2019</a>]</cite> proposed by Yoshikawa et al. by introducing a BERT-based embedding module, exploring sentence vs paragraph level predictions, and replacing chemical entities with special chemical tokens for better generalization. We train the models over a manually annotated dataset made available by Chemu <cite class="ltx_cite ltx_citemacro_cite">He etÂ al. [<a class="ltx_ref" href="https://arxiv.org/html/2407.15124v2#bib.bib3" title="">2021</a>]</cite> and test generalization over a test collection consisting of patents from Organice, Inorganic, Petrochemical, and Alcohol domains.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">Code for this project can be found on GitHub <span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/aishwaryajadhav/Chemical-Patent-Reaction-Extraction" title="">https://github.com/aishwaryajadhav/Chemical-Patent-Reaction-Extraction</a></span></span></span>.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Literature Review</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">Although there has been limited work on this topic, this research direction is quite dated. Patents are regarded as an important resource for chemical information, and a large volume of NLP research has focused on them (<cite class="ltx_cite ltx_citemacro_cite">Tseng etÂ al. [<a class="ltx_ref" href="https://arxiv.org/html/2407.15124v2#bib.bib12" title="">2007</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">Fujii etÂ al. [<a class="ltx_ref" href="https://arxiv.org/html/2407.15124v2#bib.bib1" title="">2007</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">Gurulingappa etÂ al. [<a class="ltx_ref" href="https://arxiv.org/html/2407.15124v2#bib.bib2" title="">2013</a>]</cite>). Some previous work has attempted to extract not only chemical names but also reaction procedures from the literature (<cite class="ltx_cite ltx_citemacro_cite">Lawson etÂ al. [<a class="ltx_ref" href="https://arxiv.org/html/2407.15124v2#bib.bib6" title="">2011</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">Wei etÂ al. [<a class="ltx_ref" href="https://arxiv.org/html/2407.15124v2#bib.bib13" title="">2015</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">Sang and Veenstra [<a class="ltx_ref" href="https://arxiv.org/html/2407.15124v2#bib.bib11" title="">1999</a>]</cite>). Among them, <cite class="ltx_cite ltx_citemacro_cite">Lowe [<a class="ltx_ref" href="https://arxiv.org/html/2407.15124v2#bib.bib8" title="">2012</a>]</cite> presents an integrated system that detects reaction text from chemical patents, and extracts chemicals and their roles in the corresponding reaction. The system is heavily rule-based and incorporates existing NLP libraries. More recent efforts for the specific task of reaction extraction has been described in Yoshikawa et al., 2019 <cite class="ltx_cite ltx_citemacro_cite">Yoshikawa etÂ al. [<a class="ltx_ref" href="https://arxiv.org/html/2407.15124v2#bib.bib14" title="">2019</a>]</cite>, where a number of baseline and neural architectures have been proposed for this task. They achieve quite good results for the extraction task. However, their models were trained on a very limited set of silver standard data containing patents from organic chemistry. They do not report on how their models generalize to different topics or domains of chemical patents.</p>
</div>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">Another aspect of this problem is the availability of a standard benchmark gold dataset containing reactions extracted from chemical patents covering a variety of topics and domains. The dataset used by Yoshikawa et al. <cite class="ltx_cite ltx_citemacro_cite">Yoshikawa etÂ al. [<a class="ltx_ref" href="https://arxiv.org/html/2407.15124v2#bib.bib14" title="">2019</a>]</cite> is silver standard dataset derived from the ReaxysÂ® database. Recently Chemu <cite class="ltx_cite ltx_citemacro_cite">He etÂ al. [<a class="ltx_ref" href="https://arxiv.org/html/2407.15124v2#bib.bib3" title="">2021</a>]</cite> released a gold standard annotated dataset for the Chemu challenge of reaction coreference resolution resolution containing reaction span annotation for 150 patents.</p>
</div>
<div class="ltx_para" id="S2.p3">
<p class="ltx_p" id="S2.p3.1">In this work we try to improvise on models for reaction extraction and work towards generating a large scale patent-reactions resource for research in this area.</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Dataset</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">We use the Chemu dataset <cite class="ltx_cite ltx_citemacro_cite">He etÂ al. [<a class="ltx_ref" href="https://arxiv.org/html/2407.15124v2#bib.bib3" title="">2021</a>]</cite> for training and evaluation of our models. It consist mainly of organic chemistry patents from the European Patent Office and the United States Patent and Trademark Office (USPTO). It is a gold standard dataset manually annotated for the Chemu 2021 challenge <cite class="ltx_cite ltx_citemacro_cite">He etÂ al. [<a class="ltx_ref" href="https://arxiv.org/html/2407.15124v2#bib.bib3" title="">2021</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S3.p2">
<p class="ltx_p" id="S3.p2.1">The dataset contains 120 annotated patent documents in the BRAT file format in the train set and 30 patents in the development set. The annotations are available in the form of character-level spans denoting the reactions. Additional annotations include relations between parent-child reactions and relation identification cues which are ignored for our task. Table <a class="ltx_ref" href="https://arxiv.org/html/2407.15124v2#S3.T1" title="Table 1 â€£ 3 Dataset â€£ Chemical Reaction Extraction from Long Patent Documents"><span class="ltx_text ltx_ref_tag">1</span></a> contains some stats about the patent documents and reaction annotations. We use the 30 dev set documents as a blind test set and use 20% of the 120 train set documents as the validation set. The rest is used for training.</p>
</div>
<figure class="ltx_table" id="S3.T1">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S3.T1.2" style="width:173.4pt;height:86.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-40.0pt,19.9pt) scale(0.684201506964167,0.684201506964167) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S3.T1.2.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T1.2.1.1.1">
<th class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.2.1.1.1.1"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S3.T1.2.1.1.1.2">Train Set</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S3.T1.2.1.1.1.3">Dev Set</th>
</tr>
<tr class="ltx_tr" id="S3.T1.2.1.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.2.1.2.2.1">No of Files</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S3.T1.2.1.2.2.2">120</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S3.T1.2.1.2.2.3">30</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T1.2.1.3.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" id="S3.T1.2.1.3.1.1">No of Words</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T1.2.1.3.1.2">1186K</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T1.2.1.3.1.3">295K</td>
</tr>
<tr class="ltx_tr" id="S3.T1.2.1.4.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" id="S3.T1.2.1.4.2.1">No of Paras</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T1.2.1.4.2.2">53.5K</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T1.2.1.4.2.3">12.5K</td>
</tr>
<tr class="ltx_tr" id="S3.T1.2.1.5.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" id="S3.T1.2.1.5.3.1">Avg No of tokens per para</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T1.2.1.5.3.2">22.15</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T1.2.1.5.3.3">22.9</td>
</tr>
<tr class="ltx_tr" id="S3.T1.2.1.6.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" id="S3.T1.2.1.6.4.1">Avg No of paras per document</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T1.2.1.6.4.2">446.4</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T1.2.1.6.4.3">429</td>
</tr>
<tr class="ltx_tr" id="S3.T1.2.1.7.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r" id="S3.T1.2.1.7.5.1">Total reactions annotated</th>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S3.T1.2.1.7.5.2">6378</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S3.T1.2.1.7.5.3">1244</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S3.T1.3.1.1" style="font-size:90%;">Table 1</span>: </span><span class="ltx_text" id="S3.T1.4.2" style="font-size:90%;">Gold Dataset Statistics</span></figcaption>
</figure>
<div class="ltx_para" id="S3.p3">
<p class="ltx_p" id="S3.p3.1">We also test the generalization performance of our models on out-of-domain patents. For this, we have hand-picked a collection of 4 organic chemistry patents belonging to various CPC codes and a set of 3 patents from inorganic chemistry, petrochemical and alcohol domains. All of these contain varying citations, are from industry or academia and small and large corporations to add variability to the style to evaluate the robustness of our models. This formed our generalization set.</p>
</div>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Task Formulation</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">Multiple contiguous paragraphs often describe a single reaction. Since a reaction consists of a series of sub-steps executed over time, it is crucial to accurately detect the beginning and end of each reaction text. Therefore, we define the task as a span detection problem rather than the simpler task of binary classification (i.e., classifying each paragraph as describing (part of) a reaction or not) to capture reaction substructure. A patent document is given as a sequence of paragraphs. The task is to detect a span of contiguous paragraphs that describe a single chemical reaction. In our corpus, we provide paragraph-level label sequences over paragraphs in patent documents, following the IOB2 tagging scheme <cite class="ltx_cite ltx_citemacro_cite">Krallinger etÂ al. [<a class="ltx_ref" href="https://arxiv.org/html/2407.15124v2#bib.bib5" title="">2017</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S4.p2">
<p class="ltx_p" id="S4.p2.1">We transform the character span annotations to IOB tags using a simple mapping that assigns a â€˜Bâ€™ tag to the paragraphs containing the first character of the reaction span and â€˜Iâ€™ tag to all the subsequent paragraphs uptil the one containing the last reaction span character. All other paragraphs that do not contain any reaction characters are tagged â€˜Oâ€™.</p>
</div>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Baseline Models</h2>
<figure class="ltx_figure" id="S5.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="112" id="S5.F1.1.g1" src="extracted/5749209/images/baseline.png" width="510"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F1.3.1.1" style="font-size:90%;">Figure 1</span>: </span><span class="ltx_text" id="S5.F1.4.2" style="font-size:90%;">Baseline Architecture. The left figure illustrates the general architecture of the whole model, while the
right figure details the 3 decoder components. </span></figcaption>
</figure>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">Our backbone architecture is based on the baseline models described in Yoshikawa et al. <cite class="ltx_cite ltx_citemacro_cite">Yoshikawa etÂ al. [<a class="ltx_ref" href="https://arxiv.org/html/2407.15124v2#bib.bib14" title="">2019</a>]</cite>. Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.15124v2#S5.F1" title="Figure 1 â€£ 5 Baseline Models â€£ Chemical Reaction Extraction from Long Patent Documents"><span class="ltx_text ltx_ref_tag">1</span></a> from the paper describes these architectures. All 3 baseline models have the same paragraph encoders but use different decoders for generating the IOB tags of a sequence of patent paragraphs.</p>
</div>
<div class="ltx_para" id="S5.p2">
<p class="ltx_p" id="S5.p2.6">On a high level, each paragraph is tokenized into words using the OSCAR4 tokenizer <cite class="ltx_cite ltx_citemacro_cite">Jessop etÂ al. [<a class="ltx_ref" href="https://arxiv.org/html/2407.15124v2#bib.bib4" title="">2011</a>]</cite>, which is specifically customized for chemical text mining. The embedding for each token is then generated by concatenating the pre-trained word embedding of each token or word <math alttext="wi" class="ltx_Math" display="inline" id="S5.p2.1.m1.1"><semantics id="S5.p2.1.m1.1a"><mrow id="S5.p2.1.m1.1.1" xref="S5.p2.1.m1.1.1.cmml"><mi id="S5.p2.1.m1.1.1.2" xref="S5.p2.1.m1.1.1.2.cmml">w</mi><mo id="S5.p2.1.m1.1.1.1" xref="S5.p2.1.m1.1.1.1.cmml">â¢</mo><mi id="S5.p2.1.m1.1.1.3" xref="S5.p2.1.m1.1.1.3.cmml">i</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.p2.1.m1.1b"><apply id="S5.p2.1.m1.1.1.cmml" xref="S5.p2.1.m1.1.1"><times id="S5.p2.1.m1.1.1.1.cmml" xref="S5.p2.1.m1.1.1.1"></times><ci id="S5.p2.1.m1.1.1.2.cmml" xref="S5.p2.1.m1.1.1.2">ğ‘¤</ci><ci id="S5.p2.1.m1.1.1.3.cmml" xref="S5.p2.1.m1.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.1.m1.1c">wi</annotation><annotation encoding="application/x-llamapun" id="S5.p2.1.m1.1d">italic_w italic_i</annotation></semantics></math>: <math alttext="e^{WE}_{w_{i}}" class="ltx_Math" display="inline" id="S5.p2.2.m2.1"><semantics id="S5.p2.2.m2.1a"><msubsup id="S5.p2.2.m2.1.1" xref="S5.p2.2.m2.1.1.cmml"><mi id="S5.p2.2.m2.1.1.2.2" xref="S5.p2.2.m2.1.1.2.2.cmml">e</mi><msub id="S5.p2.2.m2.1.1.3" xref="S5.p2.2.m2.1.1.3.cmml"><mi id="S5.p2.2.m2.1.1.3.2" xref="S5.p2.2.m2.1.1.3.2.cmml">w</mi><mi id="S5.p2.2.m2.1.1.3.3" xref="S5.p2.2.m2.1.1.3.3.cmml">i</mi></msub><mrow id="S5.p2.2.m2.1.1.2.3" xref="S5.p2.2.m2.1.1.2.3.cmml"><mi id="S5.p2.2.m2.1.1.2.3.2" xref="S5.p2.2.m2.1.1.2.3.2.cmml">W</mi><mo id="S5.p2.2.m2.1.1.2.3.1" xref="S5.p2.2.m2.1.1.2.3.1.cmml">â¢</mo><mi id="S5.p2.2.m2.1.1.2.3.3" xref="S5.p2.2.m2.1.1.2.3.3.cmml">E</mi></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S5.p2.2.m2.1b"><apply id="S5.p2.2.m2.1.1.cmml" xref="S5.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S5.p2.2.m2.1.1.1.cmml" xref="S5.p2.2.m2.1.1">subscript</csymbol><apply id="S5.p2.2.m2.1.1.2.cmml" xref="S5.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S5.p2.2.m2.1.1.2.1.cmml" xref="S5.p2.2.m2.1.1">superscript</csymbol><ci id="S5.p2.2.m2.1.1.2.2.cmml" xref="S5.p2.2.m2.1.1.2.2">ğ‘’</ci><apply id="S5.p2.2.m2.1.1.2.3.cmml" xref="S5.p2.2.m2.1.1.2.3"><times id="S5.p2.2.m2.1.1.2.3.1.cmml" xref="S5.p2.2.m2.1.1.2.3.1"></times><ci id="S5.p2.2.m2.1.1.2.3.2.cmml" xref="S5.p2.2.m2.1.1.2.3.2">ğ‘Š</ci><ci id="S5.p2.2.m2.1.1.2.3.3.cmml" xref="S5.p2.2.m2.1.1.2.3.3">ğ¸</ci></apply></apply><apply id="S5.p2.2.m2.1.1.3.cmml" xref="S5.p2.2.m2.1.1.3"><csymbol cd="ambiguous" id="S5.p2.2.m2.1.1.3.1.cmml" xref="S5.p2.2.m2.1.1.3">subscript</csymbol><ci id="S5.p2.2.m2.1.1.3.2.cmml" xref="S5.p2.2.m2.1.1.3.2">ğ‘¤</ci><ci id="S5.p2.2.m2.1.1.3.3.cmml" xref="S5.p2.2.m2.1.1.3.3">ğ‘–</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.2.m2.1c">e^{WE}_{w_{i}}</annotation><annotation encoding="application/x-llamapun" id="S5.p2.2.m2.1d">italic_e start_POSTSUPERSCRIPT italic_W italic_E end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT</annotation></semantics></math>, its contextualized embedding <math alttext="e^{CW}_{w_{i}|p}" class="ltx_Math" display="inline" id="S5.p2.3.m3.1"><semantics id="S5.p2.3.m3.1a"><msubsup id="S5.p2.3.m3.1.1" xref="S5.p2.3.m3.1.1.cmml"><mi id="S5.p2.3.m3.1.1.2.2" xref="S5.p2.3.m3.1.1.2.2.cmml">e</mi><mrow id="S5.p2.3.m3.1.1.3" xref="S5.p2.3.m3.1.1.3.cmml"><msub id="S5.p2.3.m3.1.1.3.2" xref="S5.p2.3.m3.1.1.3.2.cmml"><mi id="S5.p2.3.m3.1.1.3.2.2" xref="S5.p2.3.m3.1.1.3.2.2.cmml">w</mi><mi id="S5.p2.3.m3.1.1.3.2.3" xref="S5.p2.3.m3.1.1.3.2.3.cmml">i</mi></msub><mo fence="false" id="S5.p2.3.m3.1.1.3.1" xref="S5.p2.3.m3.1.1.3.1.cmml">|</mo><mi id="S5.p2.3.m3.1.1.3.3" xref="S5.p2.3.m3.1.1.3.3.cmml">p</mi></mrow><mrow id="S5.p2.3.m3.1.1.2.3" xref="S5.p2.3.m3.1.1.2.3.cmml"><mi id="S5.p2.3.m3.1.1.2.3.2" xref="S5.p2.3.m3.1.1.2.3.2.cmml">C</mi><mo id="S5.p2.3.m3.1.1.2.3.1" xref="S5.p2.3.m3.1.1.2.3.1.cmml">â¢</mo><mi id="S5.p2.3.m3.1.1.2.3.3" xref="S5.p2.3.m3.1.1.2.3.3.cmml">W</mi></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S5.p2.3.m3.1b"><apply id="S5.p2.3.m3.1.1.cmml" xref="S5.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S5.p2.3.m3.1.1.1.cmml" xref="S5.p2.3.m3.1.1">subscript</csymbol><apply id="S5.p2.3.m3.1.1.2.cmml" xref="S5.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S5.p2.3.m3.1.1.2.1.cmml" xref="S5.p2.3.m3.1.1">superscript</csymbol><ci id="S5.p2.3.m3.1.1.2.2.cmml" xref="S5.p2.3.m3.1.1.2.2">ğ‘’</ci><apply id="S5.p2.3.m3.1.1.2.3.cmml" xref="S5.p2.3.m3.1.1.2.3"><times id="S5.p2.3.m3.1.1.2.3.1.cmml" xref="S5.p2.3.m3.1.1.2.3.1"></times><ci id="S5.p2.3.m3.1.1.2.3.2.cmml" xref="S5.p2.3.m3.1.1.2.3.2">ğ¶</ci><ci id="S5.p2.3.m3.1.1.2.3.3.cmml" xref="S5.p2.3.m3.1.1.2.3.3">ğ‘Š</ci></apply></apply><apply id="S5.p2.3.m3.1.1.3.cmml" xref="S5.p2.3.m3.1.1.3"><csymbol cd="latexml" id="S5.p2.3.m3.1.1.3.1.cmml" xref="S5.p2.3.m3.1.1.3.1">conditional</csymbol><apply id="S5.p2.3.m3.1.1.3.2.cmml" xref="S5.p2.3.m3.1.1.3.2"><csymbol cd="ambiguous" id="S5.p2.3.m3.1.1.3.2.1.cmml" xref="S5.p2.3.m3.1.1.3.2">subscript</csymbol><ci id="S5.p2.3.m3.1.1.3.2.2.cmml" xref="S5.p2.3.m3.1.1.3.2.2">ğ‘¤</ci><ci id="S5.p2.3.m3.1.1.3.2.3.cmml" xref="S5.p2.3.m3.1.1.3.2.3">ğ‘–</ci></apply><ci id="S5.p2.3.m3.1.1.3.3.cmml" xref="S5.p2.3.m3.1.1.3.3">ğ‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.3.m3.1c">e^{CW}_{w_{i}|p}</annotation><annotation encoding="application/x-llamapun" id="S5.p2.3.m3.1d">italic_e start_POSTSUPERSCRIPT italic_C italic_W end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | italic_p end_POSTSUBSCRIPT</annotation></semantics></math>, and an optional embedding <math alttext="e^{FT}_{fi}" class="ltx_Math" display="inline" id="S5.p2.4.m4.1"><semantics id="S5.p2.4.m4.1a"><msubsup id="S5.p2.4.m4.1.1" xref="S5.p2.4.m4.1.1.cmml"><mi id="S5.p2.4.m4.1.1.2.2" xref="S5.p2.4.m4.1.1.2.2.cmml">e</mi><mrow id="S5.p2.4.m4.1.1.3" xref="S5.p2.4.m4.1.1.3.cmml"><mi id="S5.p2.4.m4.1.1.3.2" xref="S5.p2.4.m4.1.1.3.2.cmml">f</mi><mo id="S5.p2.4.m4.1.1.3.1" xref="S5.p2.4.m4.1.1.3.1.cmml">â¢</mo><mi id="S5.p2.4.m4.1.1.3.3" xref="S5.p2.4.m4.1.1.3.3.cmml">i</mi></mrow><mrow id="S5.p2.4.m4.1.1.2.3" xref="S5.p2.4.m4.1.1.2.3.cmml"><mi id="S5.p2.4.m4.1.1.2.3.2" xref="S5.p2.4.m4.1.1.2.3.2.cmml">F</mi><mo id="S5.p2.4.m4.1.1.2.3.1" xref="S5.p2.4.m4.1.1.2.3.1.cmml">â¢</mo><mi id="S5.p2.4.m4.1.1.2.3.3" xref="S5.p2.4.m4.1.1.2.3.3.cmml">T</mi></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S5.p2.4.m4.1b"><apply id="S5.p2.4.m4.1.1.cmml" xref="S5.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S5.p2.4.m4.1.1.1.cmml" xref="S5.p2.4.m4.1.1">subscript</csymbol><apply id="S5.p2.4.m4.1.1.2.cmml" xref="S5.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S5.p2.4.m4.1.1.2.1.cmml" xref="S5.p2.4.m4.1.1">superscript</csymbol><ci id="S5.p2.4.m4.1.1.2.2.cmml" xref="S5.p2.4.m4.1.1.2.2">ğ‘’</ci><apply id="S5.p2.4.m4.1.1.2.3.cmml" xref="S5.p2.4.m4.1.1.2.3"><times id="S5.p2.4.m4.1.1.2.3.1.cmml" xref="S5.p2.4.m4.1.1.2.3.1"></times><ci id="S5.p2.4.m4.1.1.2.3.2.cmml" xref="S5.p2.4.m4.1.1.2.3.2">ğ¹</ci><ci id="S5.p2.4.m4.1.1.2.3.3.cmml" xref="S5.p2.4.m4.1.1.2.3.3">ğ‘‡</ci></apply></apply><apply id="S5.p2.4.m4.1.1.3.cmml" xref="S5.p2.4.m4.1.1.3"><times id="S5.p2.4.m4.1.1.3.1.cmml" xref="S5.p2.4.m4.1.1.3.1"></times><ci id="S5.p2.4.m4.1.1.3.2.cmml" xref="S5.p2.4.m4.1.1.3.2">ğ‘“</ci><ci id="S5.p2.4.m4.1.1.3.3.cmml" xref="S5.p2.4.m4.1.1.3.3">ğ‘–</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.4.m4.1c">e^{FT}_{fi}</annotation><annotation encoding="application/x-llamapun" id="S5.p2.4.m4.1d">italic_e start_POSTSUPERSCRIPT italic_F italic_T end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_f italic_i end_POSTSUBSCRIPT</annotation></semantics></math> representing additional features <math alttext="f_{i}" class="ltx_Math" display="inline" id="S5.p2.5.m5.1"><semantics id="S5.p2.5.m5.1a"><msub id="S5.p2.5.m5.1.1" xref="S5.p2.5.m5.1.1.cmml"><mi id="S5.p2.5.m5.1.1.2" xref="S5.p2.5.m5.1.1.2.cmml">f</mi><mi id="S5.p2.5.m5.1.1.3" xref="S5.p2.5.m5.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S5.p2.5.m5.1b"><apply id="S5.p2.5.m5.1.1.cmml" xref="S5.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S5.p2.5.m5.1.1.1.cmml" xref="S5.p2.5.m5.1.1">subscript</csymbol><ci id="S5.p2.5.m5.1.1.2.cmml" xref="S5.p2.5.m5.1.1.2">ğ‘“</ci><ci id="S5.p2.5.m5.1.1.3.cmml" xref="S5.p2.5.m5.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.5.m5.1c">f_{i}</annotation><annotation encoding="application/x-llamapun" id="S5.p2.5.m5.1d">italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> associated with <math alttext="w_{i}" class="ltx_Math" display="inline" id="S5.p2.6.m6.1"><semantics id="S5.p2.6.m6.1a"><msub id="S5.p2.6.m6.1.1" xref="S5.p2.6.m6.1.1.cmml"><mi id="S5.p2.6.m6.1.1.2" xref="S5.p2.6.m6.1.1.2.cmml">w</mi><mi id="S5.p2.6.m6.1.1.3" xref="S5.p2.6.m6.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S5.p2.6.m6.1b"><apply id="S5.p2.6.m6.1.1.cmml" xref="S5.p2.6.m6.1.1"><csymbol cd="ambiguous" id="S5.p2.6.m6.1.1.1.cmml" xref="S5.p2.6.m6.1.1">subscript</csymbol><ci id="S5.p2.6.m6.1.1.2.cmml" xref="S5.p2.6.m6.1.1.2">ğ‘¤</ci><ci id="S5.p2.6.m6.1.1.3.cmml" xref="S5.p2.6.m6.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.6.m6.1c">w_{i}</annotation><annotation encoding="application/x-llamapun" id="S5.p2.6.m6.1d">italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>:</p>
<table class="ltx_equation ltx_eqn_table" id="S5.Ex1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="e_{i}=e^{WE}_{w_{i}}+e^{CW}_{w_{i}|p}+e^{FT}_{fi}" class="ltx_Math" display="block" id="S5.Ex1.m1.1"><semantics id="S5.Ex1.m1.1a"><mrow id="S5.Ex1.m1.1.1" xref="S5.Ex1.m1.1.1.cmml"><msub id="S5.Ex1.m1.1.1.2" xref="S5.Ex1.m1.1.1.2.cmml"><mi id="S5.Ex1.m1.1.1.2.2" xref="S5.Ex1.m1.1.1.2.2.cmml">e</mi><mi id="S5.Ex1.m1.1.1.2.3" xref="S5.Ex1.m1.1.1.2.3.cmml">i</mi></msub><mo id="S5.Ex1.m1.1.1.1" xref="S5.Ex1.m1.1.1.1.cmml">=</mo><mrow id="S5.Ex1.m1.1.1.3" xref="S5.Ex1.m1.1.1.3.cmml"><msubsup id="S5.Ex1.m1.1.1.3.2" xref="S5.Ex1.m1.1.1.3.2.cmml"><mi id="S5.Ex1.m1.1.1.3.2.2.2" xref="S5.Ex1.m1.1.1.3.2.2.2.cmml">e</mi><msub id="S5.Ex1.m1.1.1.3.2.3" xref="S5.Ex1.m1.1.1.3.2.3.cmml"><mi id="S5.Ex1.m1.1.1.3.2.3.2" xref="S5.Ex1.m1.1.1.3.2.3.2.cmml">w</mi><mi id="S5.Ex1.m1.1.1.3.2.3.3" xref="S5.Ex1.m1.1.1.3.2.3.3.cmml">i</mi></msub><mrow id="S5.Ex1.m1.1.1.3.2.2.3" xref="S5.Ex1.m1.1.1.3.2.2.3.cmml"><mi id="S5.Ex1.m1.1.1.3.2.2.3.2" xref="S5.Ex1.m1.1.1.3.2.2.3.2.cmml">W</mi><mo id="S5.Ex1.m1.1.1.3.2.2.3.1" xref="S5.Ex1.m1.1.1.3.2.2.3.1.cmml">â¢</mo><mi id="S5.Ex1.m1.1.1.3.2.2.3.3" xref="S5.Ex1.m1.1.1.3.2.2.3.3.cmml">E</mi></mrow></msubsup><mo id="S5.Ex1.m1.1.1.3.1" xref="S5.Ex1.m1.1.1.3.1.cmml">+</mo><msubsup id="S5.Ex1.m1.1.1.3.3" xref="S5.Ex1.m1.1.1.3.3.cmml"><mi id="S5.Ex1.m1.1.1.3.3.2.2" xref="S5.Ex1.m1.1.1.3.3.2.2.cmml">e</mi><mrow id="S5.Ex1.m1.1.1.3.3.3" xref="S5.Ex1.m1.1.1.3.3.3.cmml"><msub id="S5.Ex1.m1.1.1.3.3.3.2" xref="S5.Ex1.m1.1.1.3.3.3.2.cmml"><mi id="S5.Ex1.m1.1.1.3.3.3.2.2" xref="S5.Ex1.m1.1.1.3.3.3.2.2.cmml">w</mi><mi id="S5.Ex1.m1.1.1.3.3.3.2.3" xref="S5.Ex1.m1.1.1.3.3.3.2.3.cmml">i</mi></msub><mo fence="false" id="S5.Ex1.m1.1.1.3.3.3.1" xref="S5.Ex1.m1.1.1.3.3.3.1.cmml">|</mo><mi id="S5.Ex1.m1.1.1.3.3.3.3" xref="S5.Ex1.m1.1.1.3.3.3.3.cmml">p</mi></mrow><mrow id="S5.Ex1.m1.1.1.3.3.2.3" xref="S5.Ex1.m1.1.1.3.3.2.3.cmml"><mi id="S5.Ex1.m1.1.1.3.3.2.3.2" xref="S5.Ex1.m1.1.1.3.3.2.3.2.cmml">C</mi><mo id="S5.Ex1.m1.1.1.3.3.2.3.1" xref="S5.Ex1.m1.1.1.3.3.2.3.1.cmml">â¢</mo><mi id="S5.Ex1.m1.1.1.3.3.2.3.3" xref="S5.Ex1.m1.1.1.3.3.2.3.3.cmml">W</mi></mrow></msubsup><mo id="S5.Ex1.m1.1.1.3.1a" xref="S5.Ex1.m1.1.1.3.1.cmml">+</mo><msubsup id="S5.Ex1.m1.1.1.3.4" xref="S5.Ex1.m1.1.1.3.4.cmml"><mi id="S5.Ex1.m1.1.1.3.4.2.2" xref="S5.Ex1.m1.1.1.3.4.2.2.cmml">e</mi><mrow id="S5.Ex1.m1.1.1.3.4.3" xref="S5.Ex1.m1.1.1.3.4.3.cmml"><mi id="S5.Ex1.m1.1.1.3.4.3.2" xref="S5.Ex1.m1.1.1.3.4.3.2.cmml">f</mi><mo id="S5.Ex1.m1.1.1.3.4.3.1" xref="S5.Ex1.m1.1.1.3.4.3.1.cmml">â¢</mo><mi id="S5.Ex1.m1.1.1.3.4.3.3" xref="S5.Ex1.m1.1.1.3.4.3.3.cmml">i</mi></mrow><mrow id="S5.Ex1.m1.1.1.3.4.2.3" xref="S5.Ex1.m1.1.1.3.4.2.3.cmml"><mi id="S5.Ex1.m1.1.1.3.4.2.3.2" xref="S5.Ex1.m1.1.1.3.4.2.3.2.cmml">F</mi><mo id="S5.Ex1.m1.1.1.3.4.2.3.1" xref="S5.Ex1.m1.1.1.3.4.2.3.1.cmml">â¢</mo><mi id="S5.Ex1.m1.1.1.3.4.2.3.3" xref="S5.Ex1.m1.1.1.3.4.2.3.3.cmml">T</mi></mrow></msubsup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.Ex1.m1.1b"><apply id="S5.Ex1.m1.1.1.cmml" xref="S5.Ex1.m1.1.1"><eq id="S5.Ex1.m1.1.1.1.cmml" xref="S5.Ex1.m1.1.1.1"></eq><apply id="S5.Ex1.m1.1.1.2.cmml" xref="S5.Ex1.m1.1.1.2"><csymbol cd="ambiguous" id="S5.Ex1.m1.1.1.2.1.cmml" xref="S5.Ex1.m1.1.1.2">subscript</csymbol><ci id="S5.Ex1.m1.1.1.2.2.cmml" xref="S5.Ex1.m1.1.1.2.2">ğ‘’</ci><ci id="S5.Ex1.m1.1.1.2.3.cmml" xref="S5.Ex1.m1.1.1.2.3">ğ‘–</ci></apply><apply id="S5.Ex1.m1.1.1.3.cmml" xref="S5.Ex1.m1.1.1.3"><plus id="S5.Ex1.m1.1.1.3.1.cmml" xref="S5.Ex1.m1.1.1.3.1"></plus><apply id="S5.Ex1.m1.1.1.3.2.cmml" xref="S5.Ex1.m1.1.1.3.2"><csymbol cd="ambiguous" id="S5.Ex1.m1.1.1.3.2.1.cmml" xref="S5.Ex1.m1.1.1.3.2">subscript</csymbol><apply id="S5.Ex1.m1.1.1.3.2.2.cmml" xref="S5.Ex1.m1.1.1.3.2"><csymbol cd="ambiguous" id="S5.Ex1.m1.1.1.3.2.2.1.cmml" xref="S5.Ex1.m1.1.1.3.2">superscript</csymbol><ci id="S5.Ex1.m1.1.1.3.2.2.2.cmml" xref="S5.Ex1.m1.1.1.3.2.2.2">ğ‘’</ci><apply id="S5.Ex1.m1.1.1.3.2.2.3.cmml" xref="S5.Ex1.m1.1.1.3.2.2.3"><times id="S5.Ex1.m1.1.1.3.2.2.3.1.cmml" xref="S5.Ex1.m1.1.1.3.2.2.3.1"></times><ci id="S5.Ex1.m1.1.1.3.2.2.3.2.cmml" xref="S5.Ex1.m1.1.1.3.2.2.3.2">ğ‘Š</ci><ci id="S5.Ex1.m1.1.1.3.2.2.3.3.cmml" xref="S5.Ex1.m1.1.1.3.2.2.3.3">ğ¸</ci></apply></apply><apply id="S5.Ex1.m1.1.1.3.2.3.cmml" xref="S5.Ex1.m1.1.1.3.2.3"><csymbol cd="ambiguous" id="S5.Ex1.m1.1.1.3.2.3.1.cmml" xref="S5.Ex1.m1.1.1.3.2.3">subscript</csymbol><ci id="S5.Ex1.m1.1.1.3.2.3.2.cmml" xref="S5.Ex1.m1.1.1.3.2.3.2">ğ‘¤</ci><ci id="S5.Ex1.m1.1.1.3.2.3.3.cmml" xref="S5.Ex1.m1.1.1.3.2.3.3">ğ‘–</ci></apply></apply><apply id="S5.Ex1.m1.1.1.3.3.cmml" xref="S5.Ex1.m1.1.1.3.3"><csymbol cd="ambiguous" id="S5.Ex1.m1.1.1.3.3.1.cmml" xref="S5.Ex1.m1.1.1.3.3">subscript</csymbol><apply id="S5.Ex1.m1.1.1.3.3.2.cmml" xref="S5.Ex1.m1.1.1.3.3"><csymbol cd="ambiguous" id="S5.Ex1.m1.1.1.3.3.2.1.cmml" xref="S5.Ex1.m1.1.1.3.3">superscript</csymbol><ci id="S5.Ex1.m1.1.1.3.3.2.2.cmml" xref="S5.Ex1.m1.1.1.3.3.2.2">ğ‘’</ci><apply id="S5.Ex1.m1.1.1.3.3.2.3.cmml" xref="S5.Ex1.m1.1.1.3.3.2.3"><times id="S5.Ex1.m1.1.1.3.3.2.3.1.cmml" xref="S5.Ex1.m1.1.1.3.3.2.3.1"></times><ci id="S5.Ex1.m1.1.1.3.3.2.3.2.cmml" xref="S5.Ex1.m1.1.1.3.3.2.3.2">ğ¶</ci><ci id="S5.Ex1.m1.1.1.3.3.2.3.3.cmml" xref="S5.Ex1.m1.1.1.3.3.2.3.3">ğ‘Š</ci></apply></apply><apply id="S5.Ex1.m1.1.1.3.3.3.cmml" xref="S5.Ex1.m1.1.1.3.3.3"><csymbol cd="latexml" id="S5.Ex1.m1.1.1.3.3.3.1.cmml" xref="S5.Ex1.m1.1.1.3.3.3.1">conditional</csymbol><apply id="S5.Ex1.m1.1.1.3.3.3.2.cmml" xref="S5.Ex1.m1.1.1.3.3.3.2"><csymbol cd="ambiguous" id="S5.Ex1.m1.1.1.3.3.3.2.1.cmml" xref="S5.Ex1.m1.1.1.3.3.3.2">subscript</csymbol><ci id="S5.Ex1.m1.1.1.3.3.3.2.2.cmml" xref="S5.Ex1.m1.1.1.3.3.3.2.2">ğ‘¤</ci><ci id="S5.Ex1.m1.1.1.3.3.3.2.3.cmml" xref="S5.Ex1.m1.1.1.3.3.3.2.3">ğ‘–</ci></apply><ci id="S5.Ex1.m1.1.1.3.3.3.3.cmml" xref="S5.Ex1.m1.1.1.3.3.3.3">ğ‘</ci></apply></apply><apply id="S5.Ex1.m1.1.1.3.4.cmml" xref="S5.Ex1.m1.1.1.3.4"><csymbol cd="ambiguous" id="S5.Ex1.m1.1.1.3.4.1.cmml" xref="S5.Ex1.m1.1.1.3.4">subscript</csymbol><apply id="S5.Ex1.m1.1.1.3.4.2.cmml" xref="S5.Ex1.m1.1.1.3.4"><csymbol cd="ambiguous" id="S5.Ex1.m1.1.1.3.4.2.1.cmml" xref="S5.Ex1.m1.1.1.3.4">superscript</csymbol><ci id="S5.Ex1.m1.1.1.3.4.2.2.cmml" xref="S5.Ex1.m1.1.1.3.4.2.2">ğ‘’</ci><apply id="S5.Ex1.m1.1.1.3.4.2.3.cmml" xref="S5.Ex1.m1.1.1.3.4.2.3"><times id="S5.Ex1.m1.1.1.3.4.2.3.1.cmml" xref="S5.Ex1.m1.1.1.3.4.2.3.1"></times><ci id="S5.Ex1.m1.1.1.3.4.2.3.2.cmml" xref="S5.Ex1.m1.1.1.3.4.2.3.2">ğ¹</ci><ci id="S5.Ex1.m1.1.1.3.4.2.3.3.cmml" xref="S5.Ex1.m1.1.1.3.4.2.3.3">ğ‘‡</ci></apply></apply><apply id="S5.Ex1.m1.1.1.3.4.3.cmml" xref="S5.Ex1.m1.1.1.3.4.3"><times id="S5.Ex1.m1.1.1.3.4.3.1.cmml" xref="S5.Ex1.m1.1.1.3.4.3.1"></times><ci id="S5.Ex1.m1.1.1.3.4.3.2.cmml" xref="S5.Ex1.m1.1.1.3.4.3.2">ğ‘“</ci><ci id="S5.Ex1.m1.1.1.3.4.3.3.cmml" xref="S5.Ex1.m1.1.1.3.4.3.3">ğ‘–</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.Ex1.m1.1c">e_{i}=e^{WE}_{w_{i}}+e^{CW}_{w_{i}|p}+e^{FT}_{fi}</annotation><annotation encoding="application/x-llamapun" id="S5.Ex1.m1.1d">italic_e start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = italic_e start_POSTSUPERSCRIPT italic_W italic_E end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT + italic_e start_POSTSUPERSCRIPT italic_C italic_W end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | italic_p end_POSTSUBSCRIPT + italic_e start_POSTSUPERSCRIPT italic_F italic_T end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_f italic_i end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S5.p2.9">For the word embeddings, <math alttext="e^{WE}_{w_{i}}" class="ltx_Math" display="inline" id="S5.p2.7.m1.1"><semantics id="S5.p2.7.m1.1a"><msubsup id="S5.p2.7.m1.1.1" xref="S5.p2.7.m1.1.1.cmml"><mi id="S5.p2.7.m1.1.1.2.2" xref="S5.p2.7.m1.1.1.2.2.cmml">e</mi><msub id="S5.p2.7.m1.1.1.3" xref="S5.p2.7.m1.1.1.3.cmml"><mi id="S5.p2.7.m1.1.1.3.2" xref="S5.p2.7.m1.1.1.3.2.cmml">w</mi><mi id="S5.p2.7.m1.1.1.3.3" xref="S5.p2.7.m1.1.1.3.3.cmml">i</mi></msub><mrow id="S5.p2.7.m1.1.1.2.3" xref="S5.p2.7.m1.1.1.2.3.cmml"><mi id="S5.p2.7.m1.1.1.2.3.2" xref="S5.p2.7.m1.1.1.2.3.2.cmml">W</mi><mo id="S5.p2.7.m1.1.1.2.3.1" xref="S5.p2.7.m1.1.1.2.3.1.cmml">â¢</mo><mi id="S5.p2.7.m1.1.1.2.3.3" xref="S5.p2.7.m1.1.1.2.3.3.cmml">E</mi></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S5.p2.7.m1.1b"><apply id="S5.p2.7.m1.1.1.cmml" xref="S5.p2.7.m1.1.1"><csymbol cd="ambiguous" id="S5.p2.7.m1.1.1.1.cmml" xref="S5.p2.7.m1.1.1">subscript</csymbol><apply id="S5.p2.7.m1.1.1.2.cmml" xref="S5.p2.7.m1.1.1"><csymbol cd="ambiguous" id="S5.p2.7.m1.1.1.2.1.cmml" xref="S5.p2.7.m1.1.1">superscript</csymbol><ci id="S5.p2.7.m1.1.1.2.2.cmml" xref="S5.p2.7.m1.1.1.2.2">ğ‘’</ci><apply id="S5.p2.7.m1.1.1.2.3.cmml" xref="S5.p2.7.m1.1.1.2.3"><times id="S5.p2.7.m1.1.1.2.3.1.cmml" xref="S5.p2.7.m1.1.1.2.3.1"></times><ci id="S5.p2.7.m1.1.1.2.3.2.cmml" xref="S5.p2.7.m1.1.1.2.3.2">ğ‘Š</ci><ci id="S5.p2.7.m1.1.1.2.3.3.cmml" xref="S5.p2.7.m1.1.1.2.3.3">ğ¸</ci></apply></apply><apply id="S5.p2.7.m1.1.1.3.cmml" xref="S5.p2.7.m1.1.1.3"><csymbol cd="ambiguous" id="S5.p2.7.m1.1.1.3.1.cmml" xref="S5.p2.7.m1.1.1.3">subscript</csymbol><ci id="S5.p2.7.m1.1.1.3.2.cmml" xref="S5.p2.7.m1.1.1.3.2">ğ‘¤</ci><ci id="S5.p2.7.m1.1.1.3.3.cmml" xref="S5.p2.7.m1.1.1.3.3">ğ‘–</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.7.m1.1c">e^{WE}_{w_{i}}</annotation><annotation encoding="application/x-llamapun" id="S5.p2.7.m1.1d">italic_e start_POSTSUPERSCRIPT italic_W italic_E end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT</annotation></semantics></math> and contextualized embeddings <math alttext="e^{CW}_{w_{i}|p}" class="ltx_Math" display="inline" id="S5.p2.8.m2.1"><semantics id="S5.p2.8.m2.1a"><msubsup id="S5.p2.8.m2.1.1" xref="S5.p2.8.m2.1.1.cmml"><mi id="S5.p2.8.m2.1.1.2.2" xref="S5.p2.8.m2.1.1.2.2.cmml">e</mi><mrow id="S5.p2.8.m2.1.1.3" xref="S5.p2.8.m2.1.1.3.cmml"><msub id="S5.p2.8.m2.1.1.3.2" xref="S5.p2.8.m2.1.1.3.2.cmml"><mi id="S5.p2.8.m2.1.1.3.2.2" xref="S5.p2.8.m2.1.1.3.2.2.cmml">w</mi><mi id="S5.p2.8.m2.1.1.3.2.3" xref="S5.p2.8.m2.1.1.3.2.3.cmml">i</mi></msub><mo fence="false" id="S5.p2.8.m2.1.1.3.1" xref="S5.p2.8.m2.1.1.3.1.cmml">|</mo><mi id="S5.p2.8.m2.1.1.3.3" xref="S5.p2.8.m2.1.1.3.3.cmml">p</mi></mrow><mrow id="S5.p2.8.m2.1.1.2.3" xref="S5.p2.8.m2.1.1.2.3.cmml"><mi id="S5.p2.8.m2.1.1.2.3.2" xref="S5.p2.8.m2.1.1.2.3.2.cmml">C</mi><mo id="S5.p2.8.m2.1.1.2.3.1" xref="S5.p2.8.m2.1.1.2.3.1.cmml">â¢</mo><mi id="S5.p2.8.m2.1.1.2.3.3" xref="S5.p2.8.m2.1.1.2.3.3.cmml">W</mi></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S5.p2.8.m2.1b"><apply id="S5.p2.8.m2.1.1.cmml" xref="S5.p2.8.m2.1.1"><csymbol cd="ambiguous" id="S5.p2.8.m2.1.1.1.cmml" xref="S5.p2.8.m2.1.1">subscript</csymbol><apply id="S5.p2.8.m2.1.1.2.cmml" xref="S5.p2.8.m2.1.1"><csymbol cd="ambiguous" id="S5.p2.8.m2.1.1.2.1.cmml" xref="S5.p2.8.m2.1.1">superscript</csymbol><ci id="S5.p2.8.m2.1.1.2.2.cmml" xref="S5.p2.8.m2.1.1.2.2">ğ‘’</ci><apply id="S5.p2.8.m2.1.1.2.3.cmml" xref="S5.p2.8.m2.1.1.2.3"><times id="S5.p2.8.m2.1.1.2.3.1.cmml" xref="S5.p2.8.m2.1.1.2.3.1"></times><ci id="S5.p2.8.m2.1.1.2.3.2.cmml" xref="S5.p2.8.m2.1.1.2.3.2">ğ¶</ci><ci id="S5.p2.8.m2.1.1.2.3.3.cmml" xref="S5.p2.8.m2.1.1.2.3.3">ğ‘Š</ci></apply></apply><apply id="S5.p2.8.m2.1.1.3.cmml" xref="S5.p2.8.m2.1.1.3"><csymbol cd="latexml" id="S5.p2.8.m2.1.1.3.1.cmml" xref="S5.p2.8.m2.1.1.3.1">conditional</csymbol><apply id="S5.p2.8.m2.1.1.3.2.cmml" xref="S5.p2.8.m2.1.1.3.2"><csymbol cd="ambiguous" id="S5.p2.8.m2.1.1.3.2.1.cmml" xref="S5.p2.8.m2.1.1.3.2">subscript</csymbol><ci id="S5.p2.8.m2.1.1.3.2.2.cmml" xref="S5.p2.8.m2.1.1.3.2.2">ğ‘¤</ci><ci id="S5.p2.8.m2.1.1.3.2.3.cmml" xref="S5.p2.8.m2.1.1.3.2.3">ğ‘–</ci></apply><ci id="S5.p2.8.m2.1.1.3.3.cmml" xref="S5.p2.8.m2.1.1.3.3">ğ‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.8.m2.1c">e^{CW}_{w_{i}|p}</annotation><annotation encoding="application/x-llamapun" id="S5.p2.8.m2.1d">italic_e start_POSTSUPERSCRIPT italic_C italic_W end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | italic_p end_POSTSUBSCRIPT</annotation></semantics></math>, Word2Vec <cite class="ltx_cite ltx_citemacro_cite">Mikolov etÂ al. [<a class="ltx_ref" href="https://arxiv.org/html/2407.15124v2#bib.bib9" title="">2013</a>]</cite> and ELMo <cite class="ltx_cite ltx_citemacro_cite">Peters etÂ al. [<a class="ltx_ref" href="https://arxiv.org/html/2407.15124v2#bib.bib10" title="">2018</a>]</cite>, respectively, are employed. Both are pre-trained on chemical patent documents from <cite class="ltx_cite ltx_citemacro_cite">Zhai etÂ al. [<a class="ltx_ref" href="https://arxiv.org/html/2407.15124v2#bib.bib15" title="">2019</a>]</cite>. These embeddings are fixed during training. The additional learnable feature embeddings <math alttext="e^{FT}_{fi}" class="ltx_Math" display="inline" id="S5.p2.9.m3.1"><semantics id="S5.p2.9.m3.1a"><msubsup id="S5.p2.9.m3.1.1" xref="S5.p2.9.m3.1.1.cmml"><mi id="S5.p2.9.m3.1.1.2.2" xref="S5.p2.9.m3.1.1.2.2.cmml">e</mi><mrow id="S5.p2.9.m3.1.1.3" xref="S5.p2.9.m3.1.1.3.cmml"><mi id="S5.p2.9.m3.1.1.3.2" xref="S5.p2.9.m3.1.1.3.2.cmml">f</mi><mo id="S5.p2.9.m3.1.1.3.1" xref="S5.p2.9.m3.1.1.3.1.cmml">â¢</mo><mi id="S5.p2.9.m3.1.1.3.3" xref="S5.p2.9.m3.1.1.3.3.cmml">i</mi></mrow><mrow id="S5.p2.9.m3.1.1.2.3" xref="S5.p2.9.m3.1.1.2.3.cmml"><mi id="S5.p2.9.m3.1.1.2.3.2" xref="S5.p2.9.m3.1.1.2.3.2.cmml">F</mi><mo id="S5.p2.9.m3.1.1.2.3.1" xref="S5.p2.9.m3.1.1.2.3.1.cmml">â¢</mo><mi id="S5.p2.9.m3.1.1.2.3.3" xref="S5.p2.9.m3.1.1.2.3.3.cmml">T</mi></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S5.p2.9.m3.1b"><apply id="S5.p2.9.m3.1.1.cmml" xref="S5.p2.9.m3.1.1"><csymbol cd="ambiguous" id="S5.p2.9.m3.1.1.1.cmml" xref="S5.p2.9.m3.1.1">subscript</csymbol><apply id="S5.p2.9.m3.1.1.2.cmml" xref="S5.p2.9.m3.1.1"><csymbol cd="ambiguous" id="S5.p2.9.m3.1.1.2.1.cmml" xref="S5.p2.9.m3.1.1">superscript</csymbol><ci id="S5.p2.9.m3.1.1.2.2.cmml" xref="S5.p2.9.m3.1.1.2.2">ğ‘’</ci><apply id="S5.p2.9.m3.1.1.2.3.cmml" xref="S5.p2.9.m3.1.1.2.3"><times id="S5.p2.9.m3.1.1.2.3.1.cmml" xref="S5.p2.9.m3.1.1.2.3.1"></times><ci id="S5.p2.9.m3.1.1.2.3.2.cmml" xref="S5.p2.9.m3.1.1.2.3.2">ğ¹</ci><ci id="S5.p2.9.m3.1.1.2.3.3.cmml" xref="S5.p2.9.m3.1.1.2.3.3">ğ‘‡</ci></apply></apply><apply id="S5.p2.9.m3.1.1.3.cmml" xref="S5.p2.9.m3.1.1.3"><times id="S5.p2.9.m3.1.1.3.1.cmml" xref="S5.p2.9.m3.1.1.3.1"></times><ci id="S5.p2.9.m3.1.1.3.2.cmml" xref="S5.p2.9.m3.1.1.3.2">ğ‘“</ci><ci id="S5.p2.9.m3.1.1.3.3.cmml" xref="S5.p2.9.m3.1.1.3.3">ğ‘–</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.9.m3.1c">e^{FT}_{fi}</annotation><annotation encoding="application/x-llamapun" id="S5.p2.9.m3.1d">italic_e start_POSTSUPERSCRIPT italic_F italic_T end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_f italic_i end_POSTSUBSCRIPT</annotation></semantics></math> (in Equation 1) are based on the output of a chemical named entity recognizer <cite class="ltx_cite ltx_citemacro_cite">Zhai etÂ al. [<a class="ltx_ref" href="https://arxiv.org/html/2407.15124v2#bib.bib15" title="">2019</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S5.p3">
<p class="ltx_p" id="S5.p3.1">The paragraph encoder then generates a single embedding vector for the entire paragraph using a BiLSTM over the concatenated token embeddings. The paragraph decoders take in the para embeddings to output a B/I/O tag for each paragraph. The following 3 decoder models are used for the 3 baselines as shown in figure <a class="ltx_ref" href="https://arxiv.org/html/2407.15124v2#S5.F1" title="Figure 1 â€£ 5 Baseline Models â€£ Chemical Reaction Extraction from Long Patent Documents"><span class="ltx_text ltx_ref_tag">1</span></a>. The linear softmax decoder considers just the current paragraph while predicting the B/I/O tags. The Trigram-based decoder considers one paragraph before and one after the paragraph being decoded and tagged. The BiLSTM-CRF based decoders helps capture long range dependencies between the paragraphs.</p>
</div>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Our Approach</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">We utilize the paragraph encoders described in [1]. For the decoder, we experiment with both the trigram and BiLSTM CRF-based architectures. We did run 1 experiment with the linear-softmax based decoder using our approach described below but choose not to use it in other experiments due to its sub-optimal results.</p>
</div>
<section class="ltx_subsection" id="S6.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1 </span>BERT Embeddings</h3>
<div class="ltx_para" id="S6.SS1.p1">
<p class="ltx_p" id="S6.SS1.p1.1">For the 2 baseline models described above, we replace the first embedding layer that feeds into the paragraph encoder by BERT-based embeddings. BERT is a SOTA model used for a wide range of NLP and IR tasks and we wanted to assess the performance of the baseline architecture with BERT embeddings. We conducted experiments using raw token embeddings generated without finetuning the base BERT (bert-base-uncased), with embeddings generated by finetuning base BERT (bert-base-uncased).</p>
</div>
</section>
<section class="ltx_subsection" id="S6.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2 </span>ChemBERT</h3>
<div class="ltx_para" id="S6.SS2.p1">
<p class="ltx_p" id="S6.SS2.p1.1">We also experimented with 2 different pretrained BERT models:</p>
</div>
<div class="ltx_para" id="S6.SS2.p2">
<ul class="ltx_itemize" id="S6.I1">
<li class="ltx_item" id="S6.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S6.I1.i1.p1">
<p class="ltx_p" id="S6.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S6.I1.i1.p1.1.1">recobo/chemical-bert-uncased-pharmaceutical-chemical-classifier</span>: Chemical domain BERT model finetuned on 13K Chemical, and 14K Pharma Wikipedia articles broken into paragraphs.</p>
</div>
</li>
<li class="ltx_item" id="S6.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S6.I1.i2.p1">
<p class="ltx_p" id="S6.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S6.I1.i2.p1.1.1">recobo/chemical-bert-uncased</span>:
BERT-based model further pre-trained from the checkpoint of SciBERT using a corpus of over 40,000+ technical documents from the Chemical Industrial domain and combined it with 13,000 Wikipedia Chemistry articles, ranging from Safety Data Sheets and Products Information Documents.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_subsection" id="S6.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.3 </span>Sentence-level Sequence Tagging</h3>
<div class="ltx_para" id="S6.SS3.p1">
<p class="ltx_p" id="S6.SS3.p1.1">During our experiments, we observed that most of the errors were witnessed at the end boundary of the reaction, especially where properties of the newly synthesized compound were being listed. Some patents contained these properties in the same paragraph as the reaction paragraphs while others mentioned them in a separate paragraph. So the models always made errors while determining the correct end boundary for the reaction span. This was actually an artifact of our ground truth tagging scheme. Because we formulated the problem as a paragraph-level sequence tagging task, we consider the entire paragraph as a reaction even though a part of it is outside the actual annotated character-level reaction span. About 8% of the reaction paragraphs in the train set contained more 40% non-reaction characters.</p>
</div>
<div class="ltx_para" id="S6.SS3.p2">
<p class="ltx_p" id="S6.SS3.p2.1">Hence, we experimented with sentence-level encoding and tagging. The architectures here are the same as that of the paragraph-level tagging task. Instead, the training and validation data contain tags at the sentence level.</p>
</div>
</section>
<section class="ltx_subsection" id="S6.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.4 </span>[CHEM] tokens</h3>
<div class="ltx_para" id="S6.SS4.p1">
<p class="ltx_p" id="S6.SS4.p1.1">When we checked the generalization performance of the models outlined above on the out-of-domain generalization set, we observed that most of the mistakes occurred where the reaction paragraph described a reaction without any chemical names. This could be paragraphs describing general reaction recipes or that the domain addresses its materials by common language names instead of their chemical nomenclature. In order to combat the model overfitting to chemical compound names, we replace all chemical names in the train, validation, test and generalization set with a new token [CHEM]. This was added to the BERT layer as a special token. We then finetuned the bert-base-uncased and chemical-bert-uncased-pharmaceutical-chemical-classifier with this new token.</p>
</div>
<div class="ltx_para" id="S6.SS4.p2">
<p class="ltx_p" id="S6.SS4.p2.1">In order to tag the chemical tokens in the patents to replace with [CHEM], we used tmChem <cite class="ltx_cite ltx_citemacro_cite">Leaman etÂ al. [<a class="ltx_ref" href="https://arxiv.org/html/2407.15124v2#bib.bib7" title="">2015</a>]</cite> an open-source software tool for identifying chemical names in biomedical literature, including chemical identifiers, drug brand and trade names. This tagger service was accessed over a RESTful api made available by the authors that parses the entire patent document or chucks thereof in a single request returning all the chemical name tokens in the submitted text.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Evaluation Metrics</h2>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p" id="S7.p1.1">For model selection we use the span-based scores based on a strict match strategy, where an output span is regarded as correct if the beginning and ending paragraphs strictly match those of the gold span. In some practical applications, it also makes sense to understand if the model can identify the approximate region where a reaction is described. Thus, for evaluation, we also compute the scores based on a fuzzy match strategy, where we calculate the number of matches by counting the number of gold spans that have at least one corresponding predicted output span whose beginning and ending paragraph indices are at most 1 paragraph away from the gold ones.</p>
</div>
<div class="ltx_para" id="S7.p2">
<p class="ltx_p" id="S7.p2.1">We report the Accuracy, Precision, Recall and F1 score for each model on the test and generalization datasets according to the strict and fuzzy match criteria defined above.</p>
</div>
</section>
<section class="ltx_section" id="S8">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8 </span>Results and Error Analysis</h2>
<div class="ltx_para" id="S8.p1">
<p class="ltx_p" id="S8.p1.1">We first evaluate the performance of the various approaches over the in-domain test set. Note that we do not show the results of the sentence based models since these results on the test and generalization are extremely bad. Sentence based tagging needs the model to capture very long range dependencies because a single reactions paragraph can contain tens of sentences. Hence, capturing multi-para reactions necessitates attending to a long sequence of reaction sentences which does not work well at all.</p>
</div>
<section class="ltx_subsection" id="S8.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">8.1 </span>Performance on In-Domain Test Set</h3>
<section class="ltx_subsubsection" id="S8.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">8.1.1 </span>Trigram vs BiLSTM CRF decoder for base BERT models</h4>
<figure class="ltx_table" id="S8.T2">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S8.T2.2" style="width:429.3pt;height:106.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-2.9pt,0.7pt) scale(0.98673719641784,0.98673719641784) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S8.T2.2.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S8.T2.2.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S8.T2.2.1.1.1.1" rowspan="2"><span class="ltx_text" id="S8.T2.2.1.1.1.1.1">Model</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="3" id="S8.T2.2.1.1.1.2">Strict Match</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="3" id="S8.T2.2.1.1.1.3">Fuzzy Match</th>
</tr>
<tr class="ltx_tr" id="S8.T2.2.1.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r" id="S8.T2.2.1.2.2.1">F1</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r" id="S8.T2.2.1.2.2.2">Precision</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r" id="S8.T2.2.1.2.2.3">Recall</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r" id="S8.T2.2.1.2.2.4">F1</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r" id="S8.T2.2.1.2.2.5">Precision</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r" id="S8.T2.2.1.2.2.6">Recall</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S8.T2.2.1.3.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S8.T2.2.1.3.1.1">Trigram Base BERT</th>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S8.T2.2.1.3.1.2">0.727</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S8.T2.2.1.3.1.3">0.749</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S8.T2.2.1.3.1.4">0.706</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S8.T2.2.1.3.1.5">0.813</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S8.T2.2.1.3.1.6">0.799</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S8.T2.2.1.3.1.7">0.827</td>
</tr>
<tr class="ltx_tr" id="S8.T2.2.1.4.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" id="S8.T2.2.1.4.2.1">Trigram Base BERT Finetuned</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="S8.T2.2.1.4.2.2">0.714</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S8.T2.2.1.4.2.3">0.769</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S8.T2.2.1.4.2.4">0.667</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S8.T2.2.1.4.2.5">0.836</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S8.T2.2.1.4.2.6">0.836</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S8.T2.2.1.4.2.7">0.836</td>
</tr>
<tr class="ltx_tr" id="S8.T2.2.1.5.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" id="S8.T2.2.1.5.3.1">BiLSTM CRF Base BERT</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="S8.T2.2.1.5.3.2">0.678</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S8.T2.2.1.5.3.3">0.713</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S8.T2.2.1.5.3.4">0.646</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S8.T2.2.1.5.3.5">0.825</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S8.T2.2.1.5.3.6">0.841</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S8.T2.2.1.5.3.7">0.81</td>
</tr>
<tr class="ltx_tr" id="S8.T2.2.1.6.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r" id="S8.T2.2.1.6.4.1">BiLSTM CRF Base BERT Finetuned</th>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S8.T2.2.1.6.4.2">0.745</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S8.T2.2.1.6.4.3">0.8135</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S8.T2.2.1.6.4.4">0.6875</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S8.T2.2.1.6.4.5">0.853</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S8.T2.2.1.6.4.6">0.8975</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S8.T2.2.1.6.4.7">0.814</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S8.T2.3.1.1" style="font-size:90%;">Table 2</span>: </span><span class="ltx_text" id="S8.T2.4.2" style="font-size:90%;">Trigram vs BiLSTM CRF decoder for base BERT models</span></figcaption>
</figure>
<div class="ltx_para" id="S8.SS1.SSS1.p1">
<p class="ltx_p" id="S8.SS1.SSS1.p1.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2407.15124v2#S8.T2" title="Table 2 â€£ 8.1.1 Trigram vs BiLSTM CRF decoder for base BERT models â€£ 8.1 Performance on In-Domain Test Set â€£ 8 Results and Error Analysis â€£ Chemical Reaction Extraction from Long Patent Documents"><span class="ltx_text ltx_ref_tag">2</span></a> depicts the comparison between the Trigram-based decoder vs the BiLSTM CRF-based decoder for the bert-base-uncased BERT embeddings. We compare the performances of the models with and without BERT finetuning. The fuzzy f1 score for the CRF-based models are higher in both the scenarios. We use 16 paragraph sequences for the BiLSTM encoding-decoding and CRF decoding. Naturally, the CRF model is better able to capture the long range dependencies as compared to the trigram decoder model that just considers 1 paragraph before and after the current paragraph. Hence, for the future studies, we only train and evaluate the BiLSTM-CRF based architecture.</p>
</div>
<div class="ltx_para" id="S8.SS1.SSS1.p2">
<p class="ltx_p" id="S8.SS1.SSS1.p2.1">We also observe that fine-tuning the BERT model provides significant gains in both scenarios.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S8.SS1.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">8.1.2 </span>Base BERT vs ChemBERT models</h4>
<figure class="ltx_table" id="S8.T3">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S8.T3.2" style="width:429.3pt;height:93.1pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(7.1pt,-1.5pt) scale(1.03407667289996,1.03407667289996) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S8.T3.2.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S8.T3.2.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S8.T3.2.1.1.1.1" rowspan="2"><span class="ltx_text" id="S8.T3.2.1.1.1.1.1">Model</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="3" id="S8.T3.2.1.1.1.2">Strict Match</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="3" id="S8.T3.2.1.1.1.3">Fuzzy Match</th>
</tr>
<tr class="ltx_tr" id="S8.T3.2.1.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r" id="S8.T3.2.1.2.2.1">F1</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r" id="S8.T3.2.1.2.2.2">Precision</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r" id="S8.T3.2.1.2.2.3">Recall</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r" id="S8.T3.2.1.2.2.4">F1</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r" id="S8.T3.2.1.2.2.5">Precision</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r" id="S8.T3.2.1.2.2.6">Recall</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S8.T3.2.1.3.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S8.T3.2.1.3.1.1">Base BERT Finetuned</th>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S8.T3.2.1.3.1.2">0.745</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S8.T3.2.1.3.1.3">0.8135</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S8.T3.2.1.3.1.4">0.6875</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S8.T3.2.1.3.1.5">0.853</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S8.T3.2.1.3.1.6">0.8975</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S8.T3.2.1.3.1.7">0.814</td>
</tr>
<tr class="ltx_tr" id="S8.T3.2.1.4.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" id="S8.T3.2.1.4.2.1">ChemBERT No Finetuning</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="S8.T3.2.1.4.2.2">0.712</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S8.T3.2.1.4.2.3">0.706</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S8.T3.2.1.4.2.4">0.717179903</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S8.T3.2.1.4.2.5">0.819</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S8.T3.2.1.4.2.6">0.792</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S8.T3.2.1.4.2.7">0.848</td>
</tr>
<tr class="ltx_tr" id="S8.T3.2.1.5.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r" id="S8.T3.2.1.5.3.1">ChemBERT Finetuned</th>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S8.T3.2.1.5.3.2">0.727</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S8.T3.2.1.5.3.3">0.758</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S8.T3.2.1.5.3.4">0.699</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S8.T3.2.1.5.3.5">0.854</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S8.T3.2.1.5.3.6">0.855</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S8.T3.2.1.5.3.7">0.853</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S8.T3.3.1.1" style="font-size:90%;">Table 3</span>: </span><span class="ltx_text" id="S8.T3.4.2" style="font-size:90%;">BiLSTM CRF models with Base BERT vs ChemBERT embeddings</span></figcaption>
</figure>
<div class="ltx_para" id="S8.SS1.SSS2.p1">
<p class="ltx_p" id="S8.SS1.SSS2.p1.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2407.15124v2#S8.T3" title="Table 3 â€£ 8.1.2 Base BERT vs ChemBERT models â€£ 8.1 Performance on In-Domain Test Set â€£ 8 Results and Error Analysis â€£ Chemical Reaction Extraction from Long Patent Documents"><span class="ltx_text ltx_ref_tag">3</span></a> summarizes the performances obtained by using the BERT pretrained on the chemical domain dataset for generating the token embeddings against the Base BERT performance. We note that the ChemBert used here is the recobo/chemical-bert-uncased-pharmaceutical-chemical-classifier pretrained BERT since this gave superior results as compared to the other pretrained BERT model. Hence, we only report results and perform comparative analysis for this version of chemical pretrained BERT.
Here again we see that finetuning benefits the performance considerably. We observe minor gains in the performance of the model based on ChemBert embeddings. This improvement is not significant. Although we would have expected a good improvement upon using the ChemBERT embeddings, model finetuning closes this gap.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S8.SS1.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">8.1.3 </span>Effect of Introducing [CHEM] tokens</h4>
<figure class="ltx_table" id="S8.T4">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S8.T4.2" style="width:429.3pt;height:106.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-3.6pt,0.9pt) scale(0.983409376458491,0.983409376458491) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S8.T4.2.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S8.T4.2.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S8.T4.2.1.1.1.1" rowspan="2"><span class="ltx_text" id="S8.T4.2.1.1.1.1.1">Model</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="3" id="S8.T4.2.1.1.1.2">Strict Match</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="3" id="S8.T4.2.1.1.1.3">Fuzzy Match</th>
</tr>
<tr class="ltx_tr" id="S8.T4.2.1.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r" id="S8.T4.2.1.2.2.1">F1</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r" id="S8.T4.2.1.2.2.2">Precision</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r" id="S8.T4.2.1.2.2.3">Recall</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r" id="S8.T4.2.1.2.2.4">F1</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r" id="S8.T4.2.1.2.2.5">Precision</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r" id="S8.T4.2.1.2.2.6">Recall</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S8.T4.2.1.3.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S8.T4.2.1.3.1.1">Base BERT No Finetuning ([CHEM])</th>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S8.T4.2.1.3.1.2">0.729</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S8.T4.2.1.3.1.3">0.739</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S8.T4.2.1.3.1.4">0.72</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S8.T4.2.1.3.1.5">0.839</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S8.T4.2.1.3.1.6">0.83</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S8.T4.2.1.3.1.7">0.848</td>
</tr>
<tr class="ltx_tr" id="S8.T4.2.1.4.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" id="S8.T4.2.1.4.2.1">Base BERT Finetuned ([CHEM])</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="S8.T4.2.1.4.2.2">0.72</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S8.T4.2.1.4.2.3">0.799</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S8.T4.2.1.4.2.4">0.655</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S8.T4.2.1.4.2.5">0.844</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S8.T4.2.1.4.2.6">0.887</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S8.T4.2.1.4.2.7">0.806</td>
</tr>
<tr class="ltx_tr" id="S8.T4.2.1.5.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" id="S8.T4.2.1.5.3.1">ChemBERT No Finetuning ([CHEM])</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="S8.T4.2.1.5.3.2">0.643</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S8.T4.2.1.5.3.3">0.685</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S8.T4.2.1.5.3.4">0.607</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S8.T4.2.1.5.3.5">0.819</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S8.T4.2.1.5.3.6">0.846</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S8.T4.2.1.5.3.7">0.793</td>
</tr>
<tr class="ltx_tr" id="S8.T4.2.1.6.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r" id="S8.T4.2.1.6.4.1">ChemBERT Finetuned ([CHEM])</th>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S8.T4.2.1.6.4.2">0.742</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S8.T4.2.1.6.4.3">0.777</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S8.T4.2.1.6.4.4">0.709</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S8.T4.2.1.6.4.5">0.833</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S8.T4.2.1.6.4.6">0.848</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S8.T4.2.1.6.4.7">0.819</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S8.T4.3.1.1" style="font-size:90%;">Table 4</span>: </span><span class="ltx_text" id="S8.T4.4.2" style="font-size:90%;">BiLSTM CRF models with [CHEM] tokens</span></figcaption>
</figure>
<div class="ltx_para" id="S8.SS1.SSS3.p1">
<p class="ltx_p" id="S8.SS1.SSS3.p1.1">The main observation in this scenario is that unlike the previous case, here, the base BERT model outperforms the ChemBERT-based model. However, this is not surprising because ChemBERT has been trained to recognize and embed chemical names and tokens which are masked in this scenario. Hence, using ChemBERT in the absence of any chemical entity tokens hurts the model. We also observe that the [CHEM] masked model with base bert performs similarly to the non-CHEM masked model from table <a class="ltx_ref" href="https://arxiv.org/html/2407.15124v2#S8.T4" title="Table 4 â€£ 8.1.3 Effect of Introducing [CHEM] tokens â€£ 8.1 Performance on In-Domain Test Set â€£ 8 Results and Error Analysis â€£ Chemical Reaction Extraction from Long Patent Documents"><span class="ltx_text ltx_ref_tag">4</span></a>. This hints toward the fact that the model actually learns the structure of the reaction paragraphs rather than basing the reaction or no-reaction decision on the presence or absence of certain chemical entities which might be different across different domains.</p>
</div>
<div class="ltx_para" id="S8.SS1.SSS3.p2">
<p class="ltx_p" id="S8.SS1.SSS3.p2.1">We now look at the generationalization performances of some models selected from the analysis above.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S8.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">8.2 </span>Generalization Performance Analysis</h3>
<figure class="ltx_table" id="S8.T5">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S8.T5.2" style="width:429.3pt;height:111.1pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(6.0pt,-1.5pt) scale(1.0285709919393,1.0285709919393) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S8.T5.2.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S8.T5.2.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S8.T5.2.1.1.1.1" rowspan="2"><span class="ltx_text" id="S8.T5.2.1.1.1.1.1">Model</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="3" id="S8.T5.2.1.1.1.2">Strict Match</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="3" id="S8.T5.2.1.1.1.3">Fuzzy Match</th>
</tr>
<tr class="ltx_tr" id="S8.T5.2.1.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r" id="S8.T5.2.1.2.2.1">F1</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r" id="S8.T5.2.1.2.2.2">Precision</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r" id="S8.T5.2.1.2.2.3">Recall</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r" id="S8.T5.2.1.2.2.4">F1</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r" id="S8.T5.2.1.2.2.5">Precision</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r" id="S8.T5.2.1.2.2.6">Recall</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S8.T5.2.1.3.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S8.T5.2.1.3.1.1">Base BERT Finetuned</th>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S8.T5.2.1.3.1.2">0.707</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S8.T5.2.1.3.1.3">0.854</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S8.T5.2.1.3.1.4">0.603</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S8.T5.2.1.3.1.5">0.776</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S8.T5.2.1.3.1.6">0.951</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S8.T5.2.1.3.1.7">0.655</td>
</tr>
<tr class="ltx_tr" id="S8.T5.2.1.4.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" id="S8.T5.2.1.4.2.1">Base BERT Finetuned ([CHEM])</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="S8.T5.2.1.4.2.2">0.638</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S8.T5.2.1.4.2.3">0.833</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S8.T5.2.1.4.2.4">0.517</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S8.T5.2.1.4.2.5">0.775</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S8.T5.2.1.4.2.6">0.949</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S8.T5.2.1.4.2.7">0.655</td>
</tr>
<tr class="ltx_tr" id="S8.T5.2.1.5.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" id="S8.T5.2.1.5.3.1">ChemBERT Finetuned</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="S8.T5.2.1.5.3.2">0.708</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S8.T5.2.1.5.3.3">0.769</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S8.T5.2.1.5.3.4">0.656</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S8.T5.2.1.5.3.5">0.801</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S8.T5.2.1.5.3.6">0.855</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S8.T5.2.1.5.3.7">0.754</td>
</tr>
<tr class="ltx_tr" id="S8.T5.2.1.6.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r" id="S8.T5.2.1.6.4.1">ChemBERT Finetuned ([CHEM])</th>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S8.T5.2.1.6.4.2">0.705</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S8.T5.2.1.6.4.3">0.787</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S8.T5.2.1.6.4.4">0.638</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S8.T5.2.1.6.4.5">0.850</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S8.T5.2.1.6.4.6">0.94</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S8.T5.2.1.6.4.7">0.776</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S8.T5.3.1.1" style="font-size:90%;">Table 5</span>: </span><span class="ltx_text" id="S8.T5.4.2" style="font-size:90%;">Generalization Performances of BiLSTM CRF Models</span></figcaption>
</figure>
<div class="ltx_para" id="S8.SS2.p1">
<p class="ltx_p" id="S8.SS2.p1.1">While the strict match performance of all the models here is the same, we see that the results for the fuzzy match are quite the opposite of those seen for the test set. The ChemBERT-based models significantly outperform the base BERT models. Even for the approach consisting of [CHEM] tokens, the ChemBERT based embeddings provide much better results. One plausible explanation for this might be the fact that this chemical domain pretrained model is actually learning the structural components of reaction paragraphs which are similar across domains. Just the entities in the reactions are different for the different domains and thus, replacing those with [CHEM] tags reduces the noise and enables the model to focus on the structure of the paragraph to determine whether it is a reaction paragraph or not.</p>
</div>
<div class="ltx_para" id="S8.SS2.p2">
<p class="ltx_p" id="S8.SS2.p2.1">A main problem observed across the different models for the generalization set is the poor recall of these models. Both the ChemBERT models have also performed significantly better in terms of extracting more reaction spans present in the patents, demonstrating generalizability across different domain chemical patents.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S9">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">9 </span>Discussion and Future Direction</h2>
<div class="ltx_para" id="S9.p1">
<p class="ltx_p" id="S9.p1.1">In this project, we primarily explored various methods to extract reaction spans from patents and evaluated their performance in both in-domain and out-of-domain chemical patent documents. Our findings highlight several areas where current models struggle. Firstly, the models often perform poorly for reaction spans exceeding three paragraphs. Secondly, they encounter difficulties in accurately demarcating boundaries between consecutive reactions, especially when multiple reactions follow one another without clear headings. Additionally, the models are not well-equipped to handle reaction snippets embedded within tables.</p>
</div>
<div class="ltx_para" id="S9.p2">
<p class="ltx_p" id="S9.p2.1">Moving forward, our research will focus on two main directions. Firstly, we plan to explore the impact of multi-task learning on reaction extraction. Specifically, we aim to evaluate the performance of a BERT-based model trained jointly for Chemical Named Entity Recognition (NER) and reaction extraction. This approach will help us determine whether learning structural components of the text through joint training for these two tasks enhances the modelâ€™s ability to generalize across domains. Secondly, we intend to create a comprehensive database of reactions extracted from chemical patents for use in downstream tasks.</p>
</div>
<div class="ltx_para" id="S9.p3">
<p class="ltx_p" id="S9.p3.1">Moreover, there is a pressing need for a standardized benchmark dataset for the Reaction Extraction task. Although our results demonstrate superior performance compared to previous work by Yoshikawa et al., we emphasize the importance of a gold standard dataset with annotations for a broader set of patents. Such a benchmark is crucial for fair comparisons across different methodologies in this area.</p>
</div>
</section>
<section class="ltx_section" id="S10">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">10 </span>Conclusion </h2>
<div class="ltx_para" id="S10.p1">
<p class="ltx_p" id="S10.p1.1">We have explored different approaches to extracting reaction spans from chemical patent documents and evaluated the generalization of these models across various chemical domains. We seek to continue to improve this task in order to create a valuable resource of reactions for the research community.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fujii etÂ al. [2007]</span>
<span class="ltx_bibblock">
Atsushi Fujii, Makoto Iwayama, and Noriko Kando.

</span>
<span class="ltx_bibblock">Introduction to the special issue on patent processing.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">Information Processing &amp; Management</em>, 43(5):1149â€“1153, 2007.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gurulingappa etÂ al. [2013]</span>
<span class="ltx_bibblock">
Harsha Gurulingappa, Anirban Mudi, Luca Toldo, Martin Hofmann-Apitius, and
Jignesh Bhate.

</span>
<span class="ltx_bibblock">Challenges in mining the literature for chemical information.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">RSC Advances</em>, 3(37):16194â€“16211, 2013.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He etÂ al. [2021]</span>
<span class="ltx_bibblock">
Jiayuan He, Biaoyan Fang, Hiyori Yoshikawa, Yuan Li, Saber Akhondi, Christian
Druckenbrodt, Camilo Thorne, Zubair Afzal, Zenan Zhai, Lawrence Cavedon,
Trevor Cohn, Timothy Baldwin, and Karin Verspoor.

</span>
<span class="ltx_bibblock">Chemu 2021: Reaction reference resolution and anaphora resolution in
chemical patents.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">Advances in Information Retrieval. ECIR</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jessop etÂ al. [2011]</span>
<span class="ltx_bibblock">
DavidÂ M. Jessop, SamÂ E. Adams, EgonÂ L. Willighagen, Lezan Hawizy, and Peter
Murray-Rust.

</span>
<span class="ltx_bibblock">Oscar4: A flexible architecture for chemical textmining.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">Journal of Cheminformatics</em>, 2011.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Krallinger etÂ al. [2017]</span>
<span class="ltx_bibblock">
Martin Krallinger, Obdulia Rabal, and SaberÂ A. Akhondi.

</span>
<span class="ltx_bibblock">Overview of the biocreative vi chemical-protein interaction track.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">Proceedings of the Sixth BioCreative Challenge Evaluation
Workshop</em>, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lawson etÂ al. [2011]</span>
<span class="ltx_bibblock">
AlexanderÂ Johnston Lawson, Stefan Roller, Helmut Grotz, JanuszÂ L. Wisniewski,
and Libuse Goebels.

</span>
<span class="ltx_bibblock">Method and software for extracting chemical data, 2011.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Leaman etÂ al. [2015]</span>
<span class="ltx_bibblock">
R.Â Leaman, C.H. Wei, and Z.Â Lu.

</span>
<span class="ltx_bibblock">mchem: A high performance approach for chemical named entity
recognition and normalization.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">Cheminform</em>, 2015.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lowe [2012]</span>
<span class="ltx_bibblock">
DanielÂ M. Lowe.

</span>
<span class="ltx_bibblock">Extraction of chemical structures and reactions from the literature.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">Digital Discovery</em>, 2012.

</span>
<span class="ltx_bibblock">Ph.D. thesis, University of Cambridge.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mikolov etÂ al. [2013]</span>
<span class="ltx_bibblock">
Tomas Mikolov, Ilya Sutskever, Kai Chen, GregÂ S. Corrado, and Jeff Dean.

</span>
<span class="ltx_bibblock">Distributed representations of words and phrases and their
compositionality.

</span>
<span class="ltx_bibblock">In C.J.C. Burges, L.Â Bottou, M.Â Welling, Z.Â Ghahramani, and K.Q.
Weinberger, editors, <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">Advances in Neural Information Processing
Systems</em>, volumeÂ 26, pages 3111â€“3119. Curran Associates, Inc., 2013.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Peters etÂ al. [2018]</span>
<span class="ltx_bibblock">
Matthew Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark,
Kenton Lee, and Luke Zettlemoyer.

</span>
<span class="ltx_bibblock">Deep contextualized word representations.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">Proceedings of the Conference of the North American Chapter
of the Association for Computational Linguistics: Human Language
Technologies</em>, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sang and Veenstra [1999]</span>
<span class="ltx_bibblock">
Erik F. TjongÂ Kim Sang and Jorn Veenstra.

</span>
<span class="ltx_bibblock">Representing text chunks.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">Proceedings of the Ninth Conference on European Chapter of
the Association for Computational Linguistics</em>, pages 173â€“179, Bergen,
Norway, 1999. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tseng etÂ al. [2007]</span>
<span class="ltx_bibblock">
Yuen-Hsien Tseng, Chi-Jen Lin, and Yu-I Lin.

</span>
<span class="ltx_bibblock">Text mining techniques for patent analysis.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">Information Processing &amp; Management</em>, 43(5):1216â€“1247, 2007.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei etÂ al. [2015]</span>
<span class="ltx_bibblock">
Chih-Hsuan Wei, Yifan Peng, Robert Leaman, AllanÂ Peter Davis, CarolynÂ J.
Mattingly, Jiao Li, ThomasÂ C. Wiegers, and Zhiyong Lu.

</span>
<span class="ltx_bibblock">Overview of the biocreative v chemical disease relation (cdr) task.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">Proceedings of the Fifth BioCreative Challenge Evaluation
Workshop</em>, 2015.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yoshikawa etÂ al. [2019]</span>
<span class="ltx_bibblock">
Hiyori Yoshikawa, DatÂ Quoc Nguyen, Zenan Zhai, Christian Druckenbrodt, Camilo
Thorne, SaberÂ A. Akhondi, Timothy Baldwin, and Karin Verspoor.

</span>
<span class="ltx_bibblock">Detecting chemical reactions in patents.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">Proceedings of the ALTA 2019 Conference</em>, pages 100â€“110,
2019.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclweb.org/anthology/papers/U/U19/U19-1014/" title="">https://aclweb.org/anthology/papers/U/U19/U19-1014/</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhai etÂ al. [2019]</span>
<span class="ltx_bibblock">
Zenan Zhai, DatÂ Quoc Nguyen, Saber Akhondi, Camilo Thorne, Christian
Druckenbrodt, Trevor Cohn, Michelle Gregory, and Karin Verspoor.

</span>
<span class="ltx_bibblock">Improving chemical named entity recognition in patents with
contextualized word embeddings.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">Proceedings of the 18th BioNLP Workshop and Shared Task</em>,
2019.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Tue Jul 23 07:11:05 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
