<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>MMREC: LLM Based Multi-Modal Recommender System</title>
<!--Generated on Thu Aug  8 04:30:22 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="Multi-Modality,  Large Language Models,  Recommender System,  Deep Learning Recommendation Model,  Personalization,  Imbalanced Dataset Modeling" lang="en" name="keywords"/>
<base href="/html/2408.04211v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#S1" title="In MMREC: LLM Based Multi-Modal Recommender System"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#S2" title="In MMREC: LLM Based Multi-Modal Recommender System"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#S2.SS1" title="In 2. Related Work ‣ MMREC: LLM Based Multi-Modal Recommender System"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Recommender System</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#S2.SS2" title="In 2. Related Work ‣ MMREC: LLM Based Multi-Modal Recommender System"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Large Language Models Reasoning</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#S2.SS3" title="In 2. Related Work ‣ MMREC: LLM Based Multi-Modal Recommender System"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>LLM for Recommender Systems</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#S3" title="In MMREC: LLM Based Multi-Modal Recommender System"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Data</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#S3.SS1" title="In 3. Data ‣ MMREC: LLM Based Multi-Modal Recommender System"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Source</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#S3.SS2" title="In 3. Data ‣ MMREC: LLM Based Multi-Modal Recommender System"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Splitting</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#S4" title="In MMREC: LLM Based Multi-Modal Recommender System"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Methodology</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#S4.SS1" title="In 4. Methodology ‣ MMREC: LLM Based Multi-Modal Recommender System"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>DLRM and the base model</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#S4.SS2" title="In 4. Methodology ‣ MMREC: LLM Based Multi-Modal Recommender System"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>LLM summarization</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#S4.SS3" title="In 4. Methodology ‣ MMREC: LLM Based Multi-Modal Recommender System"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Dimension reduction</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#S5" title="In MMREC: LLM Based Multi-Modal Recommender System"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Experiement</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#S5.SS1" title="In 5. Experiement ‣ MMREC: LLM Based Multi-Modal Recommender System"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Parameter and Configuration</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#S5.SS2" title="In 5. Experiement ‣ MMREC: LLM Based Multi-Modal Recommender System"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Data Pre-processing</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#S5.SS3" title="In 5. Experiement ‣ MMREC: LLM Based Multi-Modal Recommender System"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3 </span>Result</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#S5.SS4" title="In 5. Experiement ‣ MMREC: LLM Based Multi-Modal Recommender System"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.4 </span>Analysis</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#S6" title="In MMREC: LLM Based Multi-Modal Recommender System"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Conclusion</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">MMREC: LLM Based Multi-Modal Recommender System</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Jiahao Tian
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:jtian83@gatech.edu">jtian83@gatech.edu</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id1.1.id1">Georgia Institute of Technology</span><span class="ltx_text ltx_affiliation_city" id="id2.2.id2">Atlanta</span><span class="ltx_text ltx_affiliation_state" id="id3.3.id3">Georgia</span><span class="ltx_text ltx_affiliation_country" id="id4.4.id4">USA</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Jinman Zhao
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:jinman.zhao@mail.utoronto.ca">jinman.zhao@mail.utoronto.ca</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id5.1.id1">Univeristy of Toronto</span><span class="ltx_text ltx_affiliation_city" id="id6.2.id2">Toronto</span><span class="ltx_text ltx_affiliation_state" id="id7.3.id3">Ontario</span><span class="ltx_text ltx_affiliation_country" id="id8.4.id4">Canada</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Zhenkai Wang
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:kay.zhenkai.wang@utexas.edu">kay.zhenkai.wang@utexas.edu</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id9.1.id1">The University of Texas at Austin</span><span class="ltx_text ltx_affiliation_city" id="id10.2.id2">Austin</span><span class="ltx_text ltx_affiliation_state" id="id11.3.id3">Texas</span><span class="ltx_text ltx_affiliation_country" id="id12.4.id4">USA</span>
</span></span></span>
<span class="ltx_author_before"> and </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Zhicheng Ding
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:zhicheng.ding@columbia.edu">zhicheng.ding@columbia.edu</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id13.1.id1">Columbia University</span><span class="ltx_text ltx_affiliation_city" id="id14.2.id2">New York</span><span class="ltx_text ltx_affiliation_state" id="id15.3.id3">NY</span><span class="ltx_text ltx_affiliation_country" id="id16.4.id4">USA</span>
</span></span></span>
</div>
<div class="ltx_dates">(2018)</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p class="ltx_p" id="id17.id1">The importance of recommender systems is growing rapidly due to the exponential increase in the volume of content generated daily. This surge in content presents unique challenges for designing effective recommender systems. Key among these challenges is the need to effectively leverage the vast amounts of natural language data and images that represent user preferences.
This paper presents a novel approach to enhancing recommender systems by leveraging Large Language Models (LLMs) and deep learning techniques. The proposed framework aims to improve the accuracy and relevance of recommendations by incorporating multi-modal information processing and by the use of unified latent space representation. The study explores the potential of LLMs to better understand and utilize natural language data in recommendation contexts, addressing the limitations of previous methods. The framework efficiently extracts and integrates text and image information through LLMs, unifying diverse modalities in a latent space to simplify the learning process for the ranking model. Experimental results demonstrate the enhanced discriminative power of the model when utilizing multi-modal information. This research contributes to the evolving field of recommender systems by showcasing the potential of LLMs and multi-modal data integration to create more personalized and contextually relevant recommendations.</p>
</div>
<div class="ltx_keywords">Multi-Modality, Large Language Models, Recommender System, Deep Learning Recommendation Model, Personalization, Imbalanced Dataset Modeling
</div>
<span class="ltx_note ltx_note_frontmatter ltx_role_copyright" id="id1"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">copyright: </span>acmlicensed</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_journalyear" id="id2"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">journalyear: </span>2018</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_doi" id="id3"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">doi: </span>XXXXXXX.XXXXXXX</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_conference" id="id4"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">conference: </span>Make sure to enter the correct
conference title from your rights confirmation emai; June 03–05,
2018; Woodstock, NY</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_isbn" id="id5"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">isbn: </span>978-1-4503-XXXX-X/18/06</span></span></span>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Recommender Systems have become an integral component of modern digital ecosystems, playing a pivotal role in personalizing user experiences across various domains such as e-commerce, streaming services, social media, and more <cite class="ltx_cite ltx_citemacro_citep">(Guo et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#bib.bib17" title="">2017</a>; Zhou et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#bib.bib65" title="">2018</a>; Pi et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#bib.bib36" title="">2020</a>; Pancha et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#bib.bib35" title="">2022</a>; Yin et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#bib.bib58" title="">2023</a>)</cite>. These systems aim to predict the preferences of users and suggest items that align with their tastes, thereby enhancing user engagement and satisfaction. The foundations of the Recommender System can be traced back to collaborative filtering techniques, which leverage user-item interaction data to identify patterns and make recommendations. Over time, these systems have evolved to incorporate more sophisticated approaches, including content-based filtering, hybrid methods, and context-aware recommendations, to address user data’s growing complexity and scale.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">The development of machine learning and deep learning has revolutionized nearly every field <cite class="ltx_cite ltx_citemacro_citep">(He et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#bib.bib20" title="">2016</a>; Zhang and Yang, <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#bib.bib60" title="">2021</a>; Tian and Porter, <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#bib.bib43" title="">2022</a>, <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#bib.bib44" title="">2024</a>; Koroteev, <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#bib.bib27" title="">2021</a>; Achiam et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#bib.bib2" title="">2023</a>; Koch et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#bib.bib25" title="">2020</a>)</cite>, including recommender systems. These systems now benefit from large-scale models that can leverage vast amounts of data to extract complex relationships. Deep learning techniques, such as neural collaborative filtering (NCF), convolutional neural networks (CNNs), and recurrent neural networks (RNNs), have been employed to enhance the accuracy and robustness of Recommender System <cite class="ltx_cite ltx_citemacro_citep">(Covington et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#bib.bib10" title="">2016</a>; Cheng et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#bib.bib7" title="">2016</a>; He et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#bib.bib22" title="">2017</a>; Zhou et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#bib.bib66" title="">2020</a>; Xu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#bib.bib57" title="">2019</a>)</cite>. These models benefit from their ability to automatically learn feature representations from raw data, eliminating the need for manual feature engineering and improving predictive performance. Moreover, the use of attention mechanisms and transformer architectures has further advanced the capabilities of deep learning-based recommenders by allowing them to capture sequential and contextual information better <cite class="ltx_cite ltx_citemacro_citep">(Zhou et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#bib.bib65" title="">2018</a>; Pi et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#bib.bib36" title="">2020</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">Recently, Large Language Models (LLMs) like GPT-4 have shown immense potential in understanding and generating human-like text. In recommender systems, vast amounts of natural language data, such as user reviews and product information, are rich in valuable insights <cite class="ltx_cite ltx_citemacro_citep">(Zheng et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#bib.bib64" title="">2017</a>; Li and Karahanna, <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#bib.bib32" title="">2015</a>)</cite>. Before the era of LLMs, Pretrained Language Model such as BERT <cite class="ltx_cite ltx_citemacro_citep">(Devlin et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#bib.bib12" title="">2019</a>)</cite> was heavily used for processing text information . However, LLMs have demonstrated the potential to outperform BERT in terms of reasoning and understanding human language. By leveraging the processed information provided by LLMs, recommender systems can achieve a deeper understanding of user intents and preferences, leading to more personalized and contextually relevant recommendations.
In this paper, we propose a novel LLM-enhanced deep learning framework with the following contributions:</p>
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">We developed a framework that efficiently extracts multi-modal information, such as text and images, from LLMs</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">Information from different modalities is unified in a latent space, simplifying the learning process for the ranking model.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">We demonstrated how the use of multi-modal information can further enhance the discriminative power of the model, especially for improving false positive rate in the case of the imbalanced dataset.</p>
</div>
</li>
</ul>
<p class="ltx_p" id="S1.p3.2">The structure of the paper is as follows: Section <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#S2" title="2. Related Work ‣ MMREC: LLM Based Multi-Modal Recommender System"><span class="ltx_text ltx_ref_tag">2</span></a> introduces the latest developments in recommender systems and LLMs. Section <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#S3" title="3. Data ‣ MMREC: LLM Based Multi-Modal Recommender System"><span class="ltx_text ltx_ref_tag">3</span></a> briefly discusses the data used. Section <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#S4" title="4. Methodology ‣ MMREC: LLM Based Multi-Modal Recommender System"><span class="ltx_text ltx_ref_tag">4</span></a> presents our proposed framework and its key components. Section <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#S5" title="5. Experiement ‣ MMREC: LLM Based Multi-Modal Recommender System"><span class="ltx_text ltx_ref_tag">5</span></a> details the experimental setup and analysis. Finally, Section <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#S6" title="6. Conclusion ‣ MMREC: LLM Based Multi-Modal Recommender System"><span class="ltx_text ltx_ref_tag">6</span></a> provides concluding remarks.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Related Work</h2>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1. </span>Recommender System</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">Earlier work on Recommender Systems(RS) did not involve the extensive use of deep learning as seen in current approaches. For specifics, one can refer to <cite class="ltx_cite ltx_citemacro_citep">(Haruna et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#bib.bib19" title="">2017</a>)</cite>, which includes over 100 techniques from before 2017.</p>
</div>
<div class="ltx_para" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1">RS can be broadly categorized into personalized <cite class="ltx_cite ltx_citemacro_citep">(Wu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#bib.bib54" title="">2022</a>; Zheng et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#bib.bib63" title="">2022</a>; Zhao et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#bib.bib62" title="">2022</a>)</cite> and group-based <cite class="ltx_cite ltx_citemacro_citep">(Stratigi et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#bib.bib39" title="">2022</a>; Kumar et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#bib.bib28" title="">2022</a>; Zan et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#bib.bib59" title="">2021</a>; Sato, <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#bib.bib37" title="">2022</a>; Zhang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#bib.bib61" title="">2022</a>)</cite> systems. Collaborative Filtering (CF) stands out as a prevalent technique. CF predicts a user’s preferences or opinions by leveraging the collective insights from a large user base. Notable implementations include memory-based CF approaches such as those presented in  <cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#bib.bib6" title="">2019</a>)</cite> and  <cite class="ltx_cite ltx_citemacro_citep">(Barkan et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#bib.bib4" title="">2021</a>)</cite>, which utilize vector representations. Another prominent category is Model-based CF, which forecasts user preferences by analyzing the relationships between users and items. In recent years, the integration of graph neural networks like CNN <cite class="ltx_cite ltx_citemacro_citep">(An and Moon, <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#bib.bib3" title="">2022</a>)</cite>, GCN <cite class="ltx_cite ltx_citemacro_citep">(Kipf and Welling, <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#bib.bib24" title="">2016</a>)</cite>, GraphSAGE <cite class="ltx_cite ltx_citemacro_citep">(Hamilton et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#bib.bib18" title="">2017</a>)</cite>, and others have significantly enhanced model-based CF methods. These models have been extensively applied across various domains, with notable success in music, Point of Interest (POI), and book recommendations. For instance, the JODIE <cite class="ltx_cite ltx_citemacro_citep">(Kumar et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#bib.bib29" title="">2019</a>)</cite> model has been influential in music recommendation, while Multi-GCCF <cite class="ltx_cite ltx_citemacro_citep">(Sun et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#bib.bib40" title="">2019</a>)</cite>, and LightGCN <cite class="ltx_cite ltx_citemacro_citep">(He et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#bib.bib21" title="">2020</a>)</cite> have shown promising results in POI and book recommendation scenarios. Among these, LightGCN has emerged as a classic model in the RS field. The effectiveness of review text in RS has been a subject of debate. For example,  <cite class="ltx_cite ltx_citemacro_citep">(Chin et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#bib.bib8" title="">2018</a>)</cite> argued that not all parts of reviews hold equal importance, leading them to propose an Aspect-based Neural Recommender (ANR) that focuses on more granular feature representations of items. Similarly,  <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#bib.bib30" title="">2019</a>)</cite> employed capsule neural networks to extract specific viewpoints and aspects from user and item reviews. Furthermore,  <cite class="ltx_cite ltx_citemacro_citep">(Wu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#bib.bib55" title="">2019</a>)</cite> developed a dual-encoder system using CNNs, one for encoding news and the other for learning user profiles based on their interaction with clicked news.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2. </span>Large Language Models Reasoning</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">LLMs have demonstrated remarkable reasoning capabilities, particularly in benchmarks such as arithmetic <cite class="ltx_cite ltx_citemacro_citep">(Cobbe et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#bib.bib9" title="">2021</a>; Ling et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#bib.bib33" title="">2017</a>)</cite> and commonsense <cite class="ltx_cite ltx_citemacro_citep">(Talmor et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#bib.bib42" title="">2019</a>)</cite>. These models have showcased an ability to understand and perform complex calculations, as well as to apply general knowledge about the world in a way that mimics human-like understanding. Many works show the power of prompting during reasoning with LLMs such as few-shot learning <cite class="ltx_cite ltx_citemacro_citep">(Brown et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#bib.bib5" title="">2020</a>)</cite>, emotional prompt  <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#bib.bib31" title="">2023</a>)</cite> and Chain-of-Thought <cite class="ltx_cite ltx_citemacro_citep">(Wei et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#bib.bib53" title="">2022</a>; Kojima et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#bib.bib26" title="">2022</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1">Recently, there has been a trend towards using LLMs for traditional tasks. For instance,  <cite class="ltx_cite ltx_citemacro_citep">(Wan et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#bib.bib45" title="">2023</a>)</cite> employs in-context learning on GPT-3 for Relation Extraction(RE), achieving state-of-the-art (SOTA) performance on multiple test sets. <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#bib.bib48" title="">2023b</a>)</cite> adapts LLMs to the Named Entity Recognition (NER) task, aiming to bridge the gap between sequence labeling and text generation. This adaptation demonstrates how LLMs can be fine-tuned or prompted in innovative ways to handle tasks traditionally outside their direct training objectives.  <cite class="ltx_cite ltx_citemacro_citep">(Xie et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#bib.bib56" title="">2023</a>)</cite> investigate the capabilities of LLMs in zero-shot information extraction scenarios, specifically examining the performance of ChatGPT in the NER task. By focusing on zero-shot learning, the study investigates ChatGPT’s ability to identify and classify named entities within text and without any task-specific training data or fine-tuning.  <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#bib.bib52" title="">[n. d.]</a>)</cite> conducted the ability of LLMs to generate new financial signals. LLMs have also been employed for other tasks such as text summarization <cite class="ltx_cite ltx_citemacro_citep">(Goyal et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#bib.bib15" title="">2023</a>)</cite> and sentiment analysis <cite class="ltx_cite ltx_citemacro_citep">(Sun et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#bib.bib41" title="">2023</a>)</cite>.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3. </span>LLM for Recommender Systems</h3>
<div class="ltx_para" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.1">Recent efforts in the domain of recommender systems have increasingly focused on the utilization of Language Models <cite class="ltx_cite ltx_citemacro_citep">(Geng et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#bib.bib14" title="">2022</a>; Hou et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#bib.bib23" title="">2022</a>; Wang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#bib.bib51" title="">2022</a>)</cite>.  <cite class="ltx_cite ltx_citemacro_citep">(Gao et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#bib.bib13" title="">2023</a>)</cite> utilizes LLMs as the interface for recommender systems, facilitating multi-round recommendations. This enhances both the interactivity and the explainability of the system.  <cite class="ltx_cite ltx_citemacro_citep">(Wang and Lim, <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#bib.bib47" title="">2023</a>)</cite> proposed a three-step prompting strategy that substantially surpasses traditional simple prompting techniques in zero-shot settings.  <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#bib.bib49" title="">2023a</a>)</cite> preprocess users’ instructions and traditional feedback, such as clicks, using an instructor module to generate tailored guidance.  <cite class="ltx_cite ltx_citemacro_citep">(Dai et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#bib.bib11" title="">2023</a>)</cite> conduct an evaluation to assess off-the-shelf LLMs for RS, analyzing them from point-wise, pair-wise, and list-wise perspectives.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>Data</h2>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1. </span>Source</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">In this study, we utilized a comprehensive dataset tailored for restaurant reviews analysis. This data is published in Kaggle<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.kaggle.com/" title="">https://www.kaggle.com/</a></span></span></span> and it is collected from Google reviews <cite class="ltx_cite ltx_citemacro_citep">(Wang, <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#bib.bib46" title="">2023</a>)</cite>. This dataset comprises user-generated reviews for various restaurants. Each entry includes:</p>
<ul class="ltx_itemize" id="S3.I1">
<li class="ltx_item" id="S3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I1.i1.p1">
<p class="ltx_p" id="S3.I1.i1.p1.1">a unique user ID</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I1.i2.p1">
<p class="ltx_p" id="S3.I1.i2.p1.1">the business ID of the restaurant being reviewed</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I1.i3.p1">
<p class="ltx_p" id="S3.I1.i3.p1.1">the review rating (ranging from 1 to 5, we consider a rating below greater or equal to 4 as a positive rating)</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I1.i4.p1">
<p class="ltx_p" id="S3.I1.i4.p1.1">the actual text of the review</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I1.i5.p1">
<p class="ltx_p" id="S3.I1.i5.p1.1">images uploaded by the user that are associated with the review.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2. </span>Splitting</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">Our primary objective in this study is to analyze the impact of LLM summarization capabilities on feature engineering, rather than addressing the cold start problem. Therefore, during data pre-processing, we exclude any business ID or user ID that has only one associated review. This ensures that after splitting the dataset into training and test sets, no user or business in the test set will face the cold start issue, allowing us to directly apply features derived from the training set to the test set reviews. After eliminating these data points, we set the train-test split ratio to 3:1. We then perform random sampling with the condition that every user and business ID in the test set must also exist in the training set. Eventually, the train set contains 50468 positive reviews and 6537 negative reviews, test set contains 15370 positive reviews and 2032 negative reviews.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>Methodology</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">Our proposed model leverages deep learning techniques and the advanced reasoning capabilities provided by large language models (LLMs) to enhance the performance of the ranking model. We hypothesize that the summarization power of LLMs can significantly improve the discriminative capabilities of the ranking model, leading to more accurate and relevant recommendations.</p>
</div>
<div class="ltx_para" id="S4.p2">
<p class="ltx_p" id="S4.p2.1">In this section, we introduce the various components of our proposed LLM-enhanced Deep Learning Recommendation Model (DLRM). We detail the architecture, data preprocessing steps, feature engineering techniques, and the training process. Additionally, we discuss the integration of LLMs into the DLRM framework, highlighting how their contextual understanding and summarization abilities contribute to improved model performance.</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1. </span>DLRM and the base model</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">DLRM is a robust framework that leverages deep learning techniques for recommendation tasks <cite class="ltx_cite ltx_citemacro_citep">(Naumov et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#bib.bib34" title="">2019</a>)</cite>. DLRM has proven to be highly effective in personalization and recommendation scenarios, such as click-through rate (CTR) prediction <cite class="ltx_cite ltx_citemacro_citep">(Song et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#bib.bib38" title="">2020</a>; Guo et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#bib.bib16" title="">2021</a>)</cite>.
At its core, DLRM comprises three main components: the Bottom Multi-Layer Perceptron (MLP), the Feature Interaction module, and the Top MLP. The Bottom MLP is designed to process and extract signals from dense or continuous features, learning essential patterns and representations. The Feature Interaction module then takes the embeddings of sparse or categorical features, along with the output of the Bottom MLP, to capture and model the interactions between all features comprehensively. Specifically, the output from the Bottom MLP and sparse embeddings are concatenated, and the inner product is calculated across all pairwise dimensions.
Finally, the Top MLP combines the outputs from the Feature Interaction module and the Bottom MLP to make the final prediction, such as the click-through probability in our case.</p>
</div>
<figure class="ltx_figure" id="S4.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="340" id="S4.F1.g1" src="extracted/5780532/figures/baseline_model_fig.jpg" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1. </span>Base model for the restaurant recommendation task</figcaption>
</figure>
<div class="ltx_para" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1">As shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#S4.F1" title="Figure 1 ‣ 4.1. DLRM and the base model ‣ 4. Methodology ‣ MMREC: LLM Based Multi-Modal Recommender System"><span class="ltx_text ltx_ref_tag">1</span></a>, we process the textual information contained in user reviews by converting each text review into an embedding using the sentence transformer. Specifically, we use MiniLM-L6-v2 model for all our experiments <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#bib.bib50" title="">2020</a>)</cite>. We then take the element-wise average across all dimensions to create user or business features. Similarly, each image contained in the user reviews or associated with a particular business is transformed into continuous data using ResNet50. Specifically, we extract the second-to-last layer to represent the images, capturing rich feature representations.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2. </span>LLM summarization</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">To leverage the summarizing power of large language models (LLMs), we propose various methods to enhance the features fed into our model. In this section, we explain how the LLM-enhanced DLRM differs from the base model presented above.</p>
<ul class="ltx_itemize" id="S4.I1">
<li class="ltx_item" id="S4.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i1.p1">
<p class="ltx_p" id="S4.I1.i1.p1.1">Dense Features: In addition to the continuous features used in the base model (e.g., the number of reviews a restaurant received, average rating), we utilize the LLM’s reasoning ability to extract pricing information from user reviews. This enriched feature set provides a more comprehensive understanding of the restaurant being scored.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i2.p1">
<p class="ltx_p" id="S4.I1.i2.p1.1">Sparse Features: Instead of applying an element-wise average across embeddings from all textual reviews or images, we use the LLM to process and summarize the most important information from all reviews, obtaining an embedding for this summary alone. For images, we leverage the LLM’s multimodal capabilities to interpret and summarize the information contained in the images, converting them into textual descriptions. This textual information is then processed in a similar manner to the reviews.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1">This approach offers several advantages:</p>
<ul class="ltx_itemize" id="S4.I2">
<li class="ltx_item" id="S4.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I2.i1.p1">
<p class="ltx_p" id="S4.I2.i1.p1.1">Reduction of Noise: By summarizing the most important information, we ensure that only relevant data is fed into the model, preventing irrelevant or noisy information from diluting important signals.</p>
</div>
</li>
<li class="ltx_item" id="S4.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I2.i2.p1">
<p class="ltx_p" id="S4.I2.i2.p1.1">Unified Embedding Technique: Since images are converted into textual descriptions, both reviews and images use the same embedding technique to transform them into continuous data. This ensures that features from different modalities are projected into the same latent space, enhancing the model’s ability to understand and utilize the combined information effectively.</p>
</div>
</li>
</ul>
</div>
<figure class="ltx_figure" id="S4.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="389" id="S4.F2.g1" src="extracted/5780532/figures/proposed_model_architecture.jpg" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2. </span>LLM enhanced DLRM for the restaurant recommendation task</figcaption>
</figure>
<figure class="ltx_figure" id="S4.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="715" id="S4.F3.g1" src="x1.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3. </span>LLM user summary example.</figcaption>
</figure>
<div class="ltx_para" id="S4.SS2.p3">
<p class="ltx_p" id="S4.SS2.p3.1">Besides the differences mentioned above, as shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#S4.F2" title="Figure 2 ‣ 4.2. LLM summarization ‣ 4. Methodology ‣ MMREC: LLM Based Multi-Modal Recommender System"><span class="ltx_text ltx_ref_tag">2</span></a>, we also introduce an additional sparse feature into the model. Using the LLM, we categorize each restaurant into one of 11 categories. This categorical feature is then fed into the feature interaction module after the embedding layer.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3. </span>Dimension reduction</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">To mitigate the risk of overfitting caused by the high-dimensional outputs of both the sentence transformer (384 dimensions) and ResNet50 (2048 dimensions), we propose an upstream model for dimensionality reduction. This approach preserves meaningful information while addressing the potential increase in model parameters.
Our method involves the following steps:</p>
<ul class="ltx_itemize" id="S4.I3">
<li class="ltx_item" id="S4.I3.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I3.i1.p1">
<p class="ltx_p" id="S4.I3.i1.p1.1">Concatenate embeddings from both the text encoder and image encoder into a single tensor.</p>
</div>
</li>
<li class="ltx_item" id="S4.I3.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I3.i2.p1">
<p class="ltx_p" id="S4.I3.i2.p1.1">Feed this combined tensor through a Multi-Layer Perceptron (MLP).</p>
</div>
</li>
<li class="ltx_item" id="S4.I3.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I3.i3.p1">
<p class="ltx_p" id="S4.I3.i3.p1.1">The MLP outputs the probability of the outcome of interest (e.g., a positive review).</p>
</div>
</li>
</ul>
<p class="ltx_p" id="S4.SS3.p1.2">Importantly, we apply the same MLP used in training to the embeddings during the testing phase. This approach ensures effective dimensionality reduction while retaining the most crucial information for prediction. By implementing this technique, we balance model complexity and predictive power, enhancing the overall performance of our recommender system.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5. </span>Experiement</h2>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1. </span>Parameter and Configuration</h3>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">To evaluate the model’s performance under different conditions, we experiment with various dropout rates, different weighted loss function and baseline vs proposed model.</p>
<ul class="ltx_itemize" id="S5.I1">
<li class="ltx_item" id="S5.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I1.i1.p1">
<p class="ltx_p" id="S5.I1.i1.p1.1">Dropout: is a regularization technique that helps prevent overfitting by randomly setting a fraction of input units to zero during training, specifically [0.1, 0.3, 0.5]</p>
</div>
</li>
<li class="ltx_item" id="S5.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I1.i2.p1">
<p class="ltx_p" id="S5.I1.i2.p1.1">weighted loss: This dataset is highly imbalanced with 1/8 of the datapoint is associated with false labels and rest are postive samples. In order to balance the impact of each class on the loss function, we also experiment with different weighted loss functions. Weights are normalized after calculated by following formulas:</p>
<ul class="ltx_itemize" id="S5.I1.i2.I1">
<li class="ltx_item" id="S5.I1.i2.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="S5.I1.i2.I1.i1.1.1.1">–</span></span>
<div class="ltx_para" id="S5.I1.i2.I1.i1.p1">
<p class="ltx_p" id="S5.I1.i2.I1.i1.p1.1">Basic:</p>
<table class="ltx_equation ltx_eqn_table" id="S5.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_left">(1)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="W^{label}=1-\frac{Num^{label}}{Num^{total}}" class="ltx_Math" display="block" id="S5.E1.m1.1"><semantics id="S5.E1.m1.1a"><mrow id="S5.E1.m1.1.1" xref="S5.E1.m1.1.1.cmml"><msup id="S5.E1.m1.1.1.2" xref="S5.E1.m1.1.1.2.cmml"><mi id="S5.E1.m1.1.1.2.2" xref="S5.E1.m1.1.1.2.2.cmml">W</mi><mrow id="S5.E1.m1.1.1.2.3" xref="S5.E1.m1.1.1.2.3.cmml"><mi id="S5.E1.m1.1.1.2.3.2" xref="S5.E1.m1.1.1.2.3.2.cmml">l</mi><mo id="S5.E1.m1.1.1.2.3.1" xref="S5.E1.m1.1.1.2.3.1.cmml">⁢</mo><mi id="S5.E1.m1.1.1.2.3.3" xref="S5.E1.m1.1.1.2.3.3.cmml">a</mi><mo id="S5.E1.m1.1.1.2.3.1a" xref="S5.E1.m1.1.1.2.3.1.cmml">⁢</mo><mi id="S5.E1.m1.1.1.2.3.4" xref="S5.E1.m1.1.1.2.3.4.cmml">b</mi><mo id="S5.E1.m1.1.1.2.3.1b" xref="S5.E1.m1.1.1.2.3.1.cmml">⁢</mo><mi id="S5.E1.m1.1.1.2.3.5" xref="S5.E1.m1.1.1.2.3.5.cmml">e</mi><mo id="S5.E1.m1.1.1.2.3.1c" xref="S5.E1.m1.1.1.2.3.1.cmml">⁢</mo><mi id="S5.E1.m1.1.1.2.3.6" xref="S5.E1.m1.1.1.2.3.6.cmml">l</mi></mrow></msup><mo id="S5.E1.m1.1.1.1" xref="S5.E1.m1.1.1.1.cmml">=</mo><mrow id="S5.E1.m1.1.1.3" xref="S5.E1.m1.1.1.3.cmml"><mn id="S5.E1.m1.1.1.3.2" xref="S5.E1.m1.1.1.3.2.cmml">1</mn><mo id="S5.E1.m1.1.1.3.1" xref="S5.E1.m1.1.1.3.1.cmml">−</mo><mfrac id="S5.E1.m1.1.1.3.3" xref="S5.E1.m1.1.1.3.3.cmml"><mrow id="S5.E1.m1.1.1.3.3.2" xref="S5.E1.m1.1.1.3.3.2.cmml"><mi id="S5.E1.m1.1.1.3.3.2.2" xref="S5.E1.m1.1.1.3.3.2.2.cmml">N</mi><mo id="S5.E1.m1.1.1.3.3.2.1" xref="S5.E1.m1.1.1.3.3.2.1.cmml">⁢</mo><mi id="S5.E1.m1.1.1.3.3.2.3" xref="S5.E1.m1.1.1.3.3.2.3.cmml">u</mi><mo id="S5.E1.m1.1.1.3.3.2.1a" xref="S5.E1.m1.1.1.3.3.2.1.cmml">⁢</mo><msup id="S5.E1.m1.1.1.3.3.2.4" xref="S5.E1.m1.1.1.3.3.2.4.cmml"><mi id="S5.E1.m1.1.1.3.3.2.4.2" xref="S5.E1.m1.1.1.3.3.2.4.2.cmml">m</mi><mrow id="S5.E1.m1.1.1.3.3.2.4.3" xref="S5.E1.m1.1.1.3.3.2.4.3.cmml"><mi id="S5.E1.m1.1.1.3.3.2.4.3.2" xref="S5.E1.m1.1.1.3.3.2.4.3.2.cmml">l</mi><mo id="S5.E1.m1.1.1.3.3.2.4.3.1" xref="S5.E1.m1.1.1.3.3.2.4.3.1.cmml">⁢</mo><mi id="S5.E1.m1.1.1.3.3.2.4.3.3" xref="S5.E1.m1.1.1.3.3.2.4.3.3.cmml">a</mi><mo id="S5.E1.m1.1.1.3.3.2.4.3.1a" xref="S5.E1.m1.1.1.3.3.2.4.3.1.cmml">⁢</mo><mi id="S5.E1.m1.1.1.3.3.2.4.3.4" xref="S5.E1.m1.1.1.3.3.2.4.3.4.cmml">b</mi><mo id="S5.E1.m1.1.1.3.3.2.4.3.1b" xref="S5.E1.m1.1.1.3.3.2.4.3.1.cmml">⁢</mo><mi id="S5.E1.m1.1.1.3.3.2.4.3.5" xref="S5.E1.m1.1.1.3.3.2.4.3.5.cmml">e</mi><mo id="S5.E1.m1.1.1.3.3.2.4.3.1c" xref="S5.E1.m1.1.1.3.3.2.4.3.1.cmml">⁢</mo><mi id="S5.E1.m1.1.1.3.3.2.4.3.6" xref="S5.E1.m1.1.1.3.3.2.4.3.6.cmml">l</mi></mrow></msup></mrow><mrow id="S5.E1.m1.1.1.3.3.3" xref="S5.E1.m1.1.1.3.3.3.cmml"><mi id="S5.E1.m1.1.1.3.3.3.2" xref="S5.E1.m1.1.1.3.3.3.2.cmml">N</mi><mo id="S5.E1.m1.1.1.3.3.3.1" xref="S5.E1.m1.1.1.3.3.3.1.cmml">⁢</mo><mi id="S5.E1.m1.1.1.3.3.3.3" xref="S5.E1.m1.1.1.3.3.3.3.cmml">u</mi><mo id="S5.E1.m1.1.1.3.3.3.1a" xref="S5.E1.m1.1.1.3.3.3.1.cmml">⁢</mo><msup id="S5.E1.m1.1.1.3.3.3.4" xref="S5.E1.m1.1.1.3.3.3.4.cmml"><mi id="S5.E1.m1.1.1.3.3.3.4.2" xref="S5.E1.m1.1.1.3.3.3.4.2.cmml">m</mi><mrow id="S5.E1.m1.1.1.3.3.3.4.3" xref="S5.E1.m1.1.1.3.3.3.4.3.cmml"><mi id="S5.E1.m1.1.1.3.3.3.4.3.2" xref="S5.E1.m1.1.1.3.3.3.4.3.2.cmml">t</mi><mo id="S5.E1.m1.1.1.3.3.3.4.3.1" xref="S5.E1.m1.1.1.3.3.3.4.3.1.cmml">⁢</mo><mi id="S5.E1.m1.1.1.3.3.3.4.3.3" xref="S5.E1.m1.1.1.3.3.3.4.3.3.cmml">o</mi><mo id="S5.E1.m1.1.1.3.3.3.4.3.1a" xref="S5.E1.m1.1.1.3.3.3.4.3.1.cmml">⁢</mo><mi id="S5.E1.m1.1.1.3.3.3.4.3.4" xref="S5.E1.m1.1.1.3.3.3.4.3.4.cmml">t</mi><mo id="S5.E1.m1.1.1.3.3.3.4.3.1b" xref="S5.E1.m1.1.1.3.3.3.4.3.1.cmml">⁢</mo><mi id="S5.E1.m1.1.1.3.3.3.4.3.5" xref="S5.E1.m1.1.1.3.3.3.4.3.5.cmml">a</mi><mo id="S5.E1.m1.1.1.3.3.3.4.3.1c" xref="S5.E1.m1.1.1.3.3.3.4.3.1.cmml">⁢</mo><mi id="S5.E1.m1.1.1.3.3.3.4.3.6" xref="S5.E1.m1.1.1.3.3.3.4.3.6.cmml">l</mi></mrow></msup></mrow></mfrac></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.E1.m1.1b"><apply id="S5.E1.m1.1.1.cmml" xref="S5.E1.m1.1.1"><eq id="S5.E1.m1.1.1.1.cmml" xref="S5.E1.m1.1.1.1"></eq><apply id="S5.E1.m1.1.1.2.cmml" xref="S5.E1.m1.1.1.2"><csymbol cd="ambiguous" id="S5.E1.m1.1.1.2.1.cmml" xref="S5.E1.m1.1.1.2">superscript</csymbol><ci id="S5.E1.m1.1.1.2.2.cmml" xref="S5.E1.m1.1.1.2.2">𝑊</ci><apply id="S5.E1.m1.1.1.2.3.cmml" xref="S5.E1.m1.1.1.2.3"><times id="S5.E1.m1.1.1.2.3.1.cmml" xref="S5.E1.m1.1.1.2.3.1"></times><ci id="S5.E1.m1.1.1.2.3.2.cmml" xref="S5.E1.m1.1.1.2.3.2">𝑙</ci><ci id="S5.E1.m1.1.1.2.3.3.cmml" xref="S5.E1.m1.1.1.2.3.3">𝑎</ci><ci id="S5.E1.m1.1.1.2.3.4.cmml" xref="S5.E1.m1.1.1.2.3.4">𝑏</ci><ci id="S5.E1.m1.1.1.2.3.5.cmml" xref="S5.E1.m1.1.1.2.3.5">𝑒</ci><ci id="S5.E1.m1.1.1.2.3.6.cmml" xref="S5.E1.m1.1.1.2.3.6">𝑙</ci></apply></apply><apply id="S5.E1.m1.1.1.3.cmml" xref="S5.E1.m1.1.1.3"><minus id="S5.E1.m1.1.1.3.1.cmml" xref="S5.E1.m1.1.1.3.1"></minus><cn id="S5.E1.m1.1.1.3.2.cmml" type="integer" xref="S5.E1.m1.1.1.3.2">1</cn><apply id="S5.E1.m1.1.1.3.3.cmml" xref="S5.E1.m1.1.1.3.3"><divide id="S5.E1.m1.1.1.3.3.1.cmml" xref="S5.E1.m1.1.1.3.3"></divide><apply id="S5.E1.m1.1.1.3.3.2.cmml" xref="S5.E1.m1.1.1.3.3.2"><times id="S5.E1.m1.1.1.3.3.2.1.cmml" xref="S5.E1.m1.1.1.3.3.2.1"></times><ci id="S5.E1.m1.1.1.3.3.2.2.cmml" xref="S5.E1.m1.1.1.3.3.2.2">𝑁</ci><ci id="S5.E1.m1.1.1.3.3.2.3.cmml" xref="S5.E1.m1.1.1.3.3.2.3">𝑢</ci><apply id="S5.E1.m1.1.1.3.3.2.4.cmml" xref="S5.E1.m1.1.1.3.3.2.4"><csymbol cd="ambiguous" id="S5.E1.m1.1.1.3.3.2.4.1.cmml" xref="S5.E1.m1.1.1.3.3.2.4">superscript</csymbol><ci id="S5.E1.m1.1.1.3.3.2.4.2.cmml" xref="S5.E1.m1.1.1.3.3.2.4.2">𝑚</ci><apply id="S5.E1.m1.1.1.3.3.2.4.3.cmml" xref="S5.E1.m1.1.1.3.3.2.4.3"><times id="S5.E1.m1.1.1.3.3.2.4.3.1.cmml" xref="S5.E1.m1.1.1.3.3.2.4.3.1"></times><ci id="S5.E1.m1.1.1.3.3.2.4.3.2.cmml" xref="S5.E1.m1.1.1.3.3.2.4.3.2">𝑙</ci><ci id="S5.E1.m1.1.1.3.3.2.4.3.3.cmml" xref="S5.E1.m1.1.1.3.3.2.4.3.3">𝑎</ci><ci id="S5.E1.m1.1.1.3.3.2.4.3.4.cmml" xref="S5.E1.m1.1.1.3.3.2.4.3.4">𝑏</ci><ci id="S5.E1.m1.1.1.3.3.2.4.3.5.cmml" xref="S5.E1.m1.1.1.3.3.2.4.3.5">𝑒</ci><ci id="S5.E1.m1.1.1.3.3.2.4.3.6.cmml" xref="S5.E1.m1.1.1.3.3.2.4.3.6">𝑙</ci></apply></apply></apply><apply id="S5.E1.m1.1.1.3.3.3.cmml" xref="S5.E1.m1.1.1.3.3.3"><times id="S5.E1.m1.1.1.3.3.3.1.cmml" xref="S5.E1.m1.1.1.3.3.3.1"></times><ci id="S5.E1.m1.1.1.3.3.3.2.cmml" xref="S5.E1.m1.1.1.3.3.3.2">𝑁</ci><ci id="S5.E1.m1.1.1.3.3.3.3.cmml" xref="S5.E1.m1.1.1.3.3.3.3">𝑢</ci><apply id="S5.E1.m1.1.1.3.3.3.4.cmml" xref="S5.E1.m1.1.1.3.3.3.4"><csymbol cd="ambiguous" id="S5.E1.m1.1.1.3.3.3.4.1.cmml" xref="S5.E1.m1.1.1.3.3.3.4">superscript</csymbol><ci id="S5.E1.m1.1.1.3.3.3.4.2.cmml" xref="S5.E1.m1.1.1.3.3.3.4.2">𝑚</ci><apply id="S5.E1.m1.1.1.3.3.3.4.3.cmml" xref="S5.E1.m1.1.1.3.3.3.4.3"><times id="S5.E1.m1.1.1.3.3.3.4.3.1.cmml" xref="S5.E1.m1.1.1.3.3.3.4.3.1"></times><ci id="S5.E1.m1.1.1.3.3.3.4.3.2.cmml" xref="S5.E1.m1.1.1.3.3.3.4.3.2">𝑡</ci><ci id="S5.E1.m1.1.1.3.3.3.4.3.3.cmml" xref="S5.E1.m1.1.1.3.3.3.4.3.3">𝑜</ci><ci id="S5.E1.m1.1.1.3.3.3.4.3.4.cmml" xref="S5.E1.m1.1.1.3.3.3.4.3.4">𝑡</ci><ci id="S5.E1.m1.1.1.3.3.3.4.3.5.cmml" xref="S5.E1.m1.1.1.3.3.3.4.3.5">𝑎</ci><ci id="S5.E1.m1.1.1.3.3.3.4.3.6.cmml" xref="S5.E1.m1.1.1.3.3.3.4.3.6">𝑙</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.E1.m1.1c">W^{label}=1-\frac{Num^{label}}{Num^{total}}</annotation><annotation encoding="application/x-llamapun" id="S5.E1.m1.1d">italic_W start_POSTSUPERSCRIPT italic_l italic_a italic_b italic_e italic_l end_POSTSUPERSCRIPT = 1 - divide start_ARG italic_N italic_u italic_m start_POSTSUPERSCRIPT italic_l italic_a italic_b italic_e italic_l end_POSTSUPERSCRIPT end_ARG start_ARG italic_N italic_u italic_m start_POSTSUPERSCRIPT italic_t italic_o italic_t italic_a italic_l end_POSTSUPERSCRIPT end_ARG</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
</li>
<li class="ltx_item" id="S5.I1.i2.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="S5.I1.i2.I1.i2.1.1.1">–</span></span>
<div class="ltx_para" id="S5.I1.i2.I1.i2.p1">
<p class="ltx_p" id="S5.I1.i2.I1.i2.p1.1">Square root:</p>
<table class="ltx_equation ltx_eqn_table" id="S5.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_left">(2)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="W^{label}=\sqrt{1-\frac{Num^{label}}{Num^{total}}}" class="ltx_Math" display="block" id="S5.E2.m1.1"><semantics id="S5.E2.m1.1a"><mrow id="S5.E2.m1.1.1" xref="S5.E2.m1.1.1.cmml"><msup id="S5.E2.m1.1.1.2" xref="S5.E2.m1.1.1.2.cmml"><mi id="S5.E2.m1.1.1.2.2" xref="S5.E2.m1.1.1.2.2.cmml">W</mi><mrow id="S5.E2.m1.1.1.2.3" xref="S5.E2.m1.1.1.2.3.cmml"><mi id="S5.E2.m1.1.1.2.3.2" xref="S5.E2.m1.1.1.2.3.2.cmml">l</mi><mo id="S5.E2.m1.1.1.2.3.1" xref="S5.E2.m1.1.1.2.3.1.cmml">⁢</mo><mi id="S5.E2.m1.1.1.2.3.3" xref="S5.E2.m1.1.1.2.3.3.cmml">a</mi><mo id="S5.E2.m1.1.1.2.3.1a" xref="S5.E2.m1.1.1.2.3.1.cmml">⁢</mo><mi id="S5.E2.m1.1.1.2.3.4" xref="S5.E2.m1.1.1.2.3.4.cmml">b</mi><mo id="S5.E2.m1.1.1.2.3.1b" xref="S5.E2.m1.1.1.2.3.1.cmml">⁢</mo><mi id="S5.E2.m1.1.1.2.3.5" xref="S5.E2.m1.1.1.2.3.5.cmml">e</mi><mo id="S5.E2.m1.1.1.2.3.1c" xref="S5.E2.m1.1.1.2.3.1.cmml">⁢</mo><mi id="S5.E2.m1.1.1.2.3.6" xref="S5.E2.m1.1.1.2.3.6.cmml">l</mi></mrow></msup><mo id="S5.E2.m1.1.1.1" xref="S5.E2.m1.1.1.1.cmml">=</mo><msqrt id="S5.E2.m1.1.1.3" xref="S5.E2.m1.1.1.3.cmml"><mrow id="S5.E2.m1.1.1.3.2" xref="S5.E2.m1.1.1.3.2.cmml"><mn id="S5.E2.m1.1.1.3.2.2" xref="S5.E2.m1.1.1.3.2.2.cmml">1</mn><mo id="S5.E2.m1.1.1.3.2.1" xref="S5.E2.m1.1.1.3.2.1.cmml">−</mo><mfrac id="S5.E2.m1.1.1.3.2.3" xref="S5.E2.m1.1.1.3.2.3.cmml"><mrow id="S5.E2.m1.1.1.3.2.3.2" xref="S5.E2.m1.1.1.3.2.3.2.cmml"><mi id="S5.E2.m1.1.1.3.2.3.2.2" xref="S5.E2.m1.1.1.3.2.3.2.2.cmml">N</mi><mo id="S5.E2.m1.1.1.3.2.3.2.1" xref="S5.E2.m1.1.1.3.2.3.2.1.cmml">⁢</mo><mi id="S5.E2.m1.1.1.3.2.3.2.3" xref="S5.E2.m1.1.1.3.2.3.2.3.cmml">u</mi><mo id="S5.E2.m1.1.1.3.2.3.2.1a" xref="S5.E2.m1.1.1.3.2.3.2.1.cmml">⁢</mo><msup id="S5.E2.m1.1.1.3.2.3.2.4" xref="S5.E2.m1.1.1.3.2.3.2.4.cmml"><mi id="S5.E2.m1.1.1.3.2.3.2.4.2" xref="S5.E2.m1.1.1.3.2.3.2.4.2.cmml">m</mi><mrow id="S5.E2.m1.1.1.3.2.3.2.4.3" xref="S5.E2.m1.1.1.3.2.3.2.4.3.cmml"><mi id="S5.E2.m1.1.1.3.2.3.2.4.3.2" xref="S5.E2.m1.1.1.3.2.3.2.4.3.2.cmml">l</mi><mo id="S5.E2.m1.1.1.3.2.3.2.4.3.1" xref="S5.E2.m1.1.1.3.2.3.2.4.3.1.cmml">⁢</mo><mi id="S5.E2.m1.1.1.3.2.3.2.4.3.3" xref="S5.E2.m1.1.1.3.2.3.2.4.3.3.cmml">a</mi><mo id="S5.E2.m1.1.1.3.2.3.2.4.3.1a" xref="S5.E2.m1.1.1.3.2.3.2.4.3.1.cmml">⁢</mo><mi id="S5.E2.m1.1.1.3.2.3.2.4.3.4" xref="S5.E2.m1.1.1.3.2.3.2.4.3.4.cmml">b</mi><mo id="S5.E2.m1.1.1.3.2.3.2.4.3.1b" xref="S5.E2.m1.1.1.3.2.3.2.4.3.1.cmml">⁢</mo><mi id="S5.E2.m1.1.1.3.2.3.2.4.3.5" xref="S5.E2.m1.1.1.3.2.3.2.4.3.5.cmml">e</mi><mo id="S5.E2.m1.1.1.3.2.3.2.4.3.1c" xref="S5.E2.m1.1.1.3.2.3.2.4.3.1.cmml">⁢</mo><mi id="S5.E2.m1.1.1.3.2.3.2.4.3.6" xref="S5.E2.m1.1.1.3.2.3.2.4.3.6.cmml">l</mi></mrow></msup></mrow><mrow id="S5.E2.m1.1.1.3.2.3.3" xref="S5.E2.m1.1.1.3.2.3.3.cmml"><mi id="S5.E2.m1.1.1.3.2.3.3.2" xref="S5.E2.m1.1.1.3.2.3.3.2.cmml">N</mi><mo id="S5.E2.m1.1.1.3.2.3.3.1" xref="S5.E2.m1.1.1.3.2.3.3.1.cmml">⁢</mo><mi id="S5.E2.m1.1.1.3.2.3.3.3" xref="S5.E2.m1.1.1.3.2.3.3.3.cmml">u</mi><mo id="S5.E2.m1.1.1.3.2.3.3.1a" xref="S5.E2.m1.1.1.3.2.3.3.1.cmml">⁢</mo><msup id="S5.E2.m1.1.1.3.2.3.3.4" xref="S5.E2.m1.1.1.3.2.3.3.4.cmml"><mi id="S5.E2.m1.1.1.3.2.3.3.4.2" xref="S5.E2.m1.1.1.3.2.3.3.4.2.cmml">m</mi><mrow id="S5.E2.m1.1.1.3.2.3.3.4.3" xref="S5.E2.m1.1.1.3.2.3.3.4.3.cmml"><mi id="S5.E2.m1.1.1.3.2.3.3.4.3.2" xref="S5.E2.m1.1.1.3.2.3.3.4.3.2.cmml">t</mi><mo id="S5.E2.m1.1.1.3.2.3.3.4.3.1" xref="S5.E2.m1.1.1.3.2.3.3.4.3.1.cmml">⁢</mo><mi id="S5.E2.m1.1.1.3.2.3.3.4.3.3" xref="S5.E2.m1.1.1.3.2.3.3.4.3.3.cmml">o</mi><mo id="S5.E2.m1.1.1.3.2.3.3.4.3.1a" xref="S5.E2.m1.1.1.3.2.3.3.4.3.1.cmml">⁢</mo><mi id="S5.E2.m1.1.1.3.2.3.3.4.3.4" xref="S5.E2.m1.1.1.3.2.3.3.4.3.4.cmml">t</mi><mo id="S5.E2.m1.1.1.3.2.3.3.4.3.1b" xref="S5.E2.m1.1.1.3.2.3.3.4.3.1.cmml">⁢</mo><mi id="S5.E2.m1.1.1.3.2.3.3.4.3.5" xref="S5.E2.m1.1.1.3.2.3.3.4.3.5.cmml">a</mi><mo id="S5.E2.m1.1.1.3.2.3.3.4.3.1c" xref="S5.E2.m1.1.1.3.2.3.3.4.3.1.cmml">⁢</mo><mi id="S5.E2.m1.1.1.3.2.3.3.4.3.6" xref="S5.E2.m1.1.1.3.2.3.3.4.3.6.cmml">l</mi></mrow></msup></mrow></mfrac></mrow></msqrt></mrow><annotation-xml encoding="MathML-Content" id="S5.E2.m1.1b"><apply id="S5.E2.m1.1.1.cmml" xref="S5.E2.m1.1.1"><eq id="S5.E2.m1.1.1.1.cmml" xref="S5.E2.m1.1.1.1"></eq><apply id="S5.E2.m1.1.1.2.cmml" xref="S5.E2.m1.1.1.2"><csymbol cd="ambiguous" id="S5.E2.m1.1.1.2.1.cmml" xref="S5.E2.m1.1.1.2">superscript</csymbol><ci id="S5.E2.m1.1.1.2.2.cmml" xref="S5.E2.m1.1.1.2.2">𝑊</ci><apply id="S5.E2.m1.1.1.2.3.cmml" xref="S5.E2.m1.1.1.2.3"><times id="S5.E2.m1.1.1.2.3.1.cmml" xref="S5.E2.m1.1.1.2.3.1"></times><ci id="S5.E2.m1.1.1.2.3.2.cmml" xref="S5.E2.m1.1.1.2.3.2">𝑙</ci><ci id="S5.E2.m1.1.1.2.3.3.cmml" xref="S5.E2.m1.1.1.2.3.3">𝑎</ci><ci id="S5.E2.m1.1.1.2.3.4.cmml" xref="S5.E2.m1.1.1.2.3.4">𝑏</ci><ci id="S5.E2.m1.1.1.2.3.5.cmml" xref="S5.E2.m1.1.1.2.3.5">𝑒</ci><ci id="S5.E2.m1.1.1.2.3.6.cmml" xref="S5.E2.m1.1.1.2.3.6">𝑙</ci></apply></apply><apply id="S5.E2.m1.1.1.3.cmml" xref="S5.E2.m1.1.1.3"><root id="S5.E2.m1.1.1.3a.cmml" xref="S5.E2.m1.1.1.3"></root><apply id="S5.E2.m1.1.1.3.2.cmml" xref="S5.E2.m1.1.1.3.2"><minus id="S5.E2.m1.1.1.3.2.1.cmml" xref="S5.E2.m1.1.1.3.2.1"></minus><cn id="S5.E2.m1.1.1.3.2.2.cmml" type="integer" xref="S5.E2.m1.1.1.3.2.2">1</cn><apply id="S5.E2.m1.1.1.3.2.3.cmml" xref="S5.E2.m1.1.1.3.2.3"><divide id="S5.E2.m1.1.1.3.2.3.1.cmml" xref="S5.E2.m1.1.1.3.2.3"></divide><apply id="S5.E2.m1.1.1.3.2.3.2.cmml" xref="S5.E2.m1.1.1.3.2.3.2"><times id="S5.E2.m1.1.1.3.2.3.2.1.cmml" xref="S5.E2.m1.1.1.3.2.3.2.1"></times><ci id="S5.E2.m1.1.1.3.2.3.2.2.cmml" xref="S5.E2.m1.1.1.3.2.3.2.2">𝑁</ci><ci id="S5.E2.m1.1.1.3.2.3.2.3.cmml" xref="S5.E2.m1.1.1.3.2.3.2.3">𝑢</ci><apply id="S5.E2.m1.1.1.3.2.3.2.4.cmml" xref="S5.E2.m1.1.1.3.2.3.2.4"><csymbol cd="ambiguous" id="S5.E2.m1.1.1.3.2.3.2.4.1.cmml" xref="S5.E2.m1.1.1.3.2.3.2.4">superscript</csymbol><ci id="S5.E2.m1.1.1.3.2.3.2.4.2.cmml" xref="S5.E2.m1.1.1.3.2.3.2.4.2">𝑚</ci><apply id="S5.E2.m1.1.1.3.2.3.2.4.3.cmml" xref="S5.E2.m1.1.1.3.2.3.2.4.3"><times id="S5.E2.m1.1.1.3.2.3.2.4.3.1.cmml" xref="S5.E2.m1.1.1.3.2.3.2.4.3.1"></times><ci id="S5.E2.m1.1.1.3.2.3.2.4.3.2.cmml" xref="S5.E2.m1.1.1.3.2.3.2.4.3.2">𝑙</ci><ci id="S5.E2.m1.1.1.3.2.3.2.4.3.3.cmml" xref="S5.E2.m1.1.1.3.2.3.2.4.3.3">𝑎</ci><ci id="S5.E2.m1.1.1.3.2.3.2.4.3.4.cmml" xref="S5.E2.m1.1.1.3.2.3.2.4.3.4">𝑏</ci><ci id="S5.E2.m1.1.1.3.2.3.2.4.3.5.cmml" xref="S5.E2.m1.1.1.3.2.3.2.4.3.5">𝑒</ci><ci id="S5.E2.m1.1.1.3.2.3.2.4.3.6.cmml" xref="S5.E2.m1.1.1.3.2.3.2.4.3.6">𝑙</ci></apply></apply></apply><apply id="S5.E2.m1.1.1.3.2.3.3.cmml" xref="S5.E2.m1.1.1.3.2.3.3"><times id="S5.E2.m1.1.1.3.2.3.3.1.cmml" xref="S5.E2.m1.1.1.3.2.3.3.1"></times><ci id="S5.E2.m1.1.1.3.2.3.3.2.cmml" xref="S5.E2.m1.1.1.3.2.3.3.2">𝑁</ci><ci id="S5.E2.m1.1.1.3.2.3.3.3.cmml" xref="S5.E2.m1.1.1.3.2.3.3.3">𝑢</ci><apply id="S5.E2.m1.1.1.3.2.3.3.4.cmml" xref="S5.E2.m1.1.1.3.2.3.3.4"><csymbol cd="ambiguous" id="S5.E2.m1.1.1.3.2.3.3.4.1.cmml" xref="S5.E2.m1.1.1.3.2.3.3.4">superscript</csymbol><ci id="S5.E2.m1.1.1.3.2.3.3.4.2.cmml" xref="S5.E2.m1.1.1.3.2.3.3.4.2">𝑚</ci><apply id="S5.E2.m1.1.1.3.2.3.3.4.3.cmml" xref="S5.E2.m1.1.1.3.2.3.3.4.3"><times id="S5.E2.m1.1.1.3.2.3.3.4.3.1.cmml" xref="S5.E2.m1.1.1.3.2.3.3.4.3.1"></times><ci id="S5.E2.m1.1.1.3.2.3.3.4.3.2.cmml" xref="S5.E2.m1.1.1.3.2.3.3.4.3.2">𝑡</ci><ci id="S5.E2.m1.1.1.3.2.3.3.4.3.3.cmml" xref="S5.E2.m1.1.1.3.2.3.3.4.3.3">𝑜</ci><ci id="S5.E2.m1.1.1.3.2.3.3.4.3.4.cmml" xref="S5.E2.m1.1.1.3.2.3.3.4.3.4">𝑡</ci><ci id="S5.E2.m1.1.1.3.2.3.3.4.3.5.cmml" xref="S5.E2.m1.1.1.3.2.3.3.4.3.5">𝑎</ci><ci id="S5.E2.m1.1.1.3.2.3.3.4.3.6.cmml" xref="S5.E2.m1.1.1.3.2.3.3.4.3.6">𝑙</ci></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.E2.m1.1c">W^{label}=\sqrt{1-\frac{Num^{label}}{Num^{total}}}</annotation><annotation encoding="application/x-llamapun" id="S5.E2.m1.1d">italic_W start_POSTSUPERSCRIPT italic_l italic_a italic_b italic_e italic_l end_POSTSUPERSCRIPT = square-root start_ARG 1 - divide start_ARG italic_N italic_u italic_m start_POSTSUPERSCRIPT italic_l italic_a italic_b italic_e italic_l end_POSTSUPERSCRIPT end_ARG start_ARG italic_N italic_u italic_m start_POSTSUPERSCRIPT italic_t italic_o italic_t italic_a italic_l end_POSTSUPERSCRIPT end_ARG end_ARG</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S5.SS1.p2">
<p class="ltx_p" id="S5.SS1.p2.1">Each training starts with learning rate as 0.01, utilizing Adaptive Moment Estimation for adaptive learning rate adjustment. In each epoch, we evaluate the model performance against the training set and test set and update the best model if the model has a better false positive rate against the test set. We start applying early stops after finishing the first 300 epochs. Training stops when there is no continuous improvement of the false positive rate in the last 50 epochs. We repeated each parameter set evaluation five times.</p>
</div>
<figure class="ltx_table" id="S5.T1">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1. </span>Performance of best model against training set (wgted loss is the way of calculating weighted loss, fp rate means false positive rate</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S5.T1.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T1.1.1.1">
<td class="ltx_td ltx_border_tt" id="S5.T1.1.1.1.1"></td>
<th class="ltx_td ltx_th ltx_th_column ltx_border_tt" id="S5.T1.1.1.1.2"></th>
<th class="ltx_td ltx_th ltx_th_column ltx_border_tt" id="S5.T1.1.1.1.3"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S5.T1.1.1.1.4">accuracy</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S5.T1.1.1.1.5">fp rate</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S5.T1.1.1.1.6">loss</th>
</tr>
<tr class="ltx_tr" id="S5.T1.1.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column" id="S5.T1.1.2.2.1">model</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column" id="S5.T1.1.2.2.2">wgted loss</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column" id="S5.T1.1.2.2.3">dropout</th>
<th class="ltx_td ltx_th ltx_th_column" id="S5.T1.1.2.2.4"></th>
<th class="ltx_td ltx_th ltx_th_column" id="S5.T1.1.2.2.5"></th>
<td class="ltx_td" id="S5.T1.1.2.2.6"></td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.3.3">
<td class="ltx_td ltx_align_left ltx_align_top ltx_border_t" id="S5.T1.1.3.3.1" rowspan="6"><span class="ltx_text" id="S5.T1.1.3.3.1.1">proposed</span></td>
<td class="ltx_td ltx_align_left ltx_align_top ltx_border_t" id="S5.T1.1.3.3.2" rowspan="3"><span class="ltx_text" id="S5.T1.1.3.3.2.1">basic</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T1.1.3.3.3"><span class="ltx_text ltx_font_bold" id="S5.T1.1.3.3.3.1">0.10</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T1.1.3.3.4"><span class="ltx_text ltx_font_bold" id="S5.T1.1.3.3.4.1">91.62%</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T1.1.3.3.5"><span class="ltx_text ltx_font_bold" id="S5.T1.1.3.3.5.1">2.02%</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T1.1.3.3.6">2.7</td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.4.4">
<td class="ltx_td ltx_align_left" id="S5.T1.1.4.4.1">0.30</td>
<td class="ltx_td ltx_align_left" id="S5.T1.1.4.4.2">88.11%</td>
<td class="ltx_td ltx_align_left" id="S5.T1.1.4.4.3">4.14%</td>
<td class="ltx_td ltx_align_left" id="S5.T1.1.4.4.4">4.08</td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.5.5">
<td class="ltx_td ltx_align_left" id="S5.T1.1.5.5.1">0.50</td>
<td class="ltx_td ltx_align_left" id="S5.T1.1.5.5.2">86.06%</td>
<td class="ltx_td ltx_align_left" id="S5.T1.1.5.5.3">7.06%</td>
<td class="ltx_td ltx_align_left" id="S5.T1.1.5.5.4">5.28</td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.6.6">
<td class="ltx_td ltx_align_left ltx_align_top ltx_border_t" id="S5.T1.1.6.6.1" rowspan="3"><span class="ltx_text" id="S5.T1.1.6.6.1.1">sqrt root</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T1.1.6.6.2">0.10</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T1.1.6.6.3">95.95%</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T1.1.6.6.4">4.36%</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T1.1.6.6.5">4.36</td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.7.7">
<td class="ltx_td ltx_align_left" id="S5.T1.1.7.7.1">0.30</td>
<td class="ltx_td ltx_align_left" id="S5.T1.1.7.7.2">94.14%</td>
<td class="ltx_td ltx_align_left" id="S5.T1.1.7.7.3">13.69%</td>
<td class="ltx_td ltx_align_left" id="S5.T1.1.7.7.4">6.35</td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.8.8">
<td class="ltx_td ltx_align_left" id="S5.T1.1.8.8.1">0.50</td>
<td class="ltx_td ltx_align_left" id="S5.T1.1.8.8.2">91.95%</td>
<td class="ltx_td ltx_align_left" id="S5.T1.1.8.8.3">18.87%</td>
<td class="ltx_td ltx_align_left" id="S5.T1.1.8.8.4">9.19</td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.9.9">
<td class="ltx_td ltx_align_left ltx_align_top ltx_border_bb ltx_border_t" id="S5.T1.1.9.9.1" rowspan="6"><span class="ltx_text" id="S5.T1.1.9.9.1.1">baseline</span></td>
<td class="ltx_td ltx_align_left ltx_align_top ltx_border_t" id="S5.T1.1.9.9.2" rowspan="3"><span class="ltx_text" id="S5.T1.1.9.9.2.1">basic</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T1.1.9.9.3">0.10</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T1.1.9.9.4">92.51%</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T1.1.9.9.5">26.58%</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T1.1.9.9.6">6.35</td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.10.10">
<td class="ltx_td ltx_align_left" id="S5.T1.1.10.10.1">0.30</td>
<td class="ltx_td ltx_align_left" id="S5.T1.1.10.10.2">92.39%</td>
<td class="ltx_td ltx_align_left" id="S5.T1.1.10.10.3">27.82%</td>
<td class="ltx_td ltx_align_left" id="S5.T1.1.10.10.4">6.82</td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.11.11">
<td class="ltx_td ltx_align_left" id="S5.T1.1.11.11.1">0.50</td>
<td class="ltx_td ltx_align_left" id="S5.T1.1.11.11.2">92.23%</td>
<td class="ltx_td ltx_align_left" id="S5.T1.1.11.11.3">28.27%</td>
<td class="ltx_td ltx_align_left" id="S5.T1.1.11.11.4">6.97</td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.12.12">
<td class="ltx_td ltx_align_left ltx_align_top ltx_border_bb ltx_border_t" id="S5.T1.1.12.12.1" rowspan="3"><span class="ltx_text" id="S5.T1.1.12.12.1.1">sqrt root</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T1.1.12.12.2">0.10</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T1.1.12.12.3">94.12%</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T1.1.12.12.4">29.01%</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T1.1.12.12.5">10.46</td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.13.13">
<td class="ltx_td ltx_align_left" id="S5.T1.1.13.13.1">0.30</td>
<td class="ltx_td ltx_align_left" id="S5.T1.1.13.13.2">93.97%</td>
<td class="ltx_td ltx_align_left" id="S5.T1.1.13.13.3">31.02%</td>
<td class="ltx_td ltx_align_left" id="S5.T1.1.13.13.4">11.07</td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.14.14">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S5.T1.1.14.14.1">0.50</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S5.T1.1.14.14.2">94.06%</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S5.T1.1.14.14.3">33.49%</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S5.T1.1.14.14.4">11.54</td>
</tr>
</tbody>
</table>
</figure>
<figure class="ltx_table" id="S5.T2">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2. </span>Performance of best model against testing set</figcaption>
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S5.T2.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T2.1.1.1">
<td class="ltx_td ltx_border_tt" id="S5.T2.1.1.1.1"></td>
<th class="ltx_td ltx_th ltx_th_column ltx_border_tt" id="S5.T2.1.1.1.2"></th>
<th class="ltx_td ltx_th ltx_th_column ltx_border_tt" id="S5.T2.1.1.1.3"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S5.T2.1.1.1.4">accuracy</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S5.T2.1.1.1.5">fp rate</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S5.T2.1.1.1.6">loss</th>
</tr>
<tr class="ltx_tr" id="S5.T2.1.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column" id="S5.T2.1.2.2.1">model</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column" id="S5.T2.1.2.2.2">wgted loss</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column" id="S5.T2.1.2.2.3">dropout</th>
<th class="ltx_td ltx_th ltx_th_column" id="S5.T2.1.2.2.4"></th>
<th class="ltx_td ltx_th ltx_th_column" id="S5.T2.1.2.2.5"></th>
<td class="ltx_td" id="S5.T2.1.2.2.6"></td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.3.3">
<td class="ltx_td ltx_align_left ltx_align_top ltx_border_t" id="S5.T2.1.3.3.1" rowspan="6"><span class="ltx_text" id="S5.T2.1.3.3.1.1">proposed</span></td>
<td class="ltx_td ltx_align_left ltx_align_top ltx_border_t" id="S5.T2.1.3.3.2" rowspan="3"><span class="ltx_text" id="S5.T2.1.3.3.2.1">basic</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T2.1.3.3.3">0.10</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T2.1.3.3.4">85.27%</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T2.1.3.3.5">27.22%</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T2.1.3.3.6">50.18</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.4.4">
<td class="ltx_td ltx_align_left" id="S5.T2.1.4.4.1">0.30</td>
<td class="ltx_td ltx_align_left" id="S5.T2.1.4.4.2">84.02%</td>
<td class="ltx_td ltx_align_left" id="S5.T2.1.4.4.3">20.84%</td>
<td class="ltx_td ltx_align_left" id="S5.T2.1.4.4.4">30.66</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.5.5">
<td class="ltx_td ltx_align_left" id="S5.T2.1.5.5.1"><span class="ltx_text ltx_font_bold" id="S5.T2.1.5.5.1.1">0.50</span></td>
<td class="ltx_td ltx_align_left" id="S5.T2.1.5.5.2"><span class="ltx_text ltx_font_bold" id="S5.T2.1.5.5.2.1">83.48%</span></td>
<td class="ltx_td ltx_align_left" id="S5.T2.1.5.5.3"><span class="ltx_text ltx_font_bold" id="S5.T2.1.5.5.3.1">18.16%</span></td>
<td class="ltx_td ltx_align_left" id="S5.T2.1.5.5.4">15.96</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.6.6">
<td class="ltx_td ltx_align_left ltx_align_top ltx_border_t" id="S5.T2.1.6.6.1" rowspan="3"><span class="ltx_text" id="S5.T2.1.6.6.1.1">sqrt root</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T2.1.6.6.2">0.10</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T2.1.6.6.3">88.05%</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T2.1.6.6.4">38.68%</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T2.1.6.6.5">66.51</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.7.7">
<td class="ltx_td ltx_align_left" id="S5.T2.1.7.7.1">0.30</td>
<td class="ltx_td ltx_align_left" id="S5.T2.1.7.7.2">89.15%</td>
<td class="ltx_td ltx_align_left" id="S5.T2.1.7.7.3">36.42%</td>
<td class="ltx_td ltx_align_left" id="S5.T2.1.7.7.4">49.68</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.8.8">
<td class="ltx_td ltx_align_left" id="S5.T2.1.8.8.1">0.50</td>
<td class="ltx_td ltx_align_left" id="S5.T2.1.8.8.2">89.02%</td>
<td class="ltx_td ltx_align_left" id="S5.T2.1.8.8.3">31.82%</td>
<td class="ltx_td ltx_align_left" id="S5.T2.1.8.8.4">23.76</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.9.9">
<td class="ltx_td ltx_align_left ltx_align_top ltx_border_bb ltx_border_t" id="S5.T2.1.9.9.1" rowspan="6"><span class="ltx_text" id="S5.T2.1.9.9.1.1">baseline</span></td>
<td class="ltx_td ltx_align_left ltx_align_top ltx_border_t" id="S5.T2.1.9.9.2" rowspan="3"><span class="ltx_text" id="S5.T2.1.9.9.2.1">basic</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T2.1.9.9.3">0.10</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T2.1.9.9.4">91.36%</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T2.1.9.9.5">31.80%</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T2.1.9.9.6">9.32</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.10.10">
<td class="ltx_td ltx_align_left" id="S5.T2.1.10.10.1">0.30</td>
<td class="ltx_td ltx_align_left" id="S5.T2.1.10.10.2">91.89%</td>
<td class="ltx_td ltx_align_left" id="S5.T2.1.10.10.3">31.74%</td>
<td class="ltx_td ltx_align_left" id="S5.T2.1.10.10.4">7.66</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.11.11">
<td class="ltx_td ltx_align_left" id="S5.T2.1.11.11.1">0.50</td>
<td class="ltx_td ltx_align_left" id="S5.T2.1.11.11.2">91.83%</td>
<td class="ltx_td ltx_align_left" id="S5.T2.1.11.11.3">31.79%</td>
<td class="ltx_td ltx_align_left" id="S5.T2.1.11.11.4">7.64</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.12.12">
<td class="ltx_td ltx_align_left ltx_align_top ltx_border_bb ltx_border_t" id="S5.T2.1.12.12.1" rowspan="3"><span class="ltx_text" id="S5.T2.1.12.12.1.1">sqrt root</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T2.1.12.12.2">0.10</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T2.1.12.12.3">92.96%</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T2.1.12.12.4">35.26%</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T2.1.12.12.5">14.57</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.13.13">
<td class="ltx_td ltx_align_left" id="S5.T2.1.13.13.1">0.30</td>
<td class="ltx_td ltx_align_left" id="S5.T2.1.13.13.2">93.26%</td>
<td class="ltx_td ltx_align_left" id="S5.T2.1.13.13.3">35.66%</td>
<td class="ltx_td ltx_align_left" id="S5.T2.1.13.13.4">12.62</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.14.14">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S5.T2.1.14.14.1"><span class="ltx_text ltx_font_bold" id="S5.T2.1.14.14.1.1">0.50</span></td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S5.T2.1.14.14.2"><span class="ltx_text ltx_font_bold" id="S5.T2.1.14.14.2.1">93.47%</span></td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S5.T2.1.14.14.3"><span class="ltx_text ltx_font_bold" id="S5.T2.1.14.14.3.1">37.58%</span></td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S5.T2.1.14.14.4">12.59</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2. </span>Data Pre-processing</h3>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">Our baseline model utilizes dense features and embedding features to predict the review rating.In constructing the following features, we exclude the current review to avoid bias. During training, for each data point (business_id, user_id, current review), we generate business features based on reviews from other users. This ensures that the current user’s review does not influence the feature construction. Similarly, we generate user features based on reviews users provided to other businesses. During testing, we use the entire training dataset to construct features for the testing data points.</p>
<ul class="ltx_itemize" id="S5.I2">
<li class="ltx_item" id="S5.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I2.i1.p1">
<p class="ltx_p" id="S5.I2.i1.p1.1">Dense Features:</p>
<ul class="ltx_itemize" id="S5.I2.i1.I1">
<li class="ltx_item" id="S5.I2.i1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="S5.I2.i1.I1.i1.1.1.1">–</span></span>
<div class="ltx_para" id="S5.I2.i1.I1.i1.p1">
<p class="ltx_p" id="S5.I2.i1.I1.i1.p1.1">Number of Reviews for the Business: The total number of reviews received by current business.</p>
</div>
</li>
<li class="ltx_item" id="S5.I2.i1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="S5.I2.i1.I1.i2.1.1.1">–</span></span>
<div class="ltx_para" id="S5.I2.i1.I1.i2.p1">
<p class="ltx_p" id="S5.I2.i1.I1.i2.p1.1">Average Rating from the User: The average rating given by the user across all their reviews.</p>
</div>
</li>
<li class="ltx_item" id="S5.I2.i1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="S5.I2.i1.I1.i3.1.1.1">–</span></span>
<div class="ltx_para" id="S5.I2.i1.I1.i3.p1">
<p class="ltx_p" id="S5.I2.i1.I1.i3.p1.1">Average Rating for the Business: The average rating received by the business across all reviews.</p>
</div>
</li>
</ul>
</div>
</li>
<li class="ltx_item" id="S5.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I2.i2.p1">
<p class="ltx_p" id="S5.I2.i2.p1.1">Embedding Features:</p>
<ul class="ltx_itemize" id="S5.I2.i2.I1">
<li class="ltx_item" id="S5.I2.i2.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="S5.I2.i2.I1.i1.1.1.1">–</span></span>
<div class="ltx_para" id="S5.I2.i2.I1.i1.p1">
<p class="ltx_p" id="S5.I2.i2.I1.i1.p1.1">User Review Text Feature: All reviews written by the user are collected and converted into 384-dimensional embedding vectors using the sentence transformer. An average pooling operation is then applied to these vectors to produce a single 1x384 vector representing the user’s review text feature.</p>
</div>
</li>
<li class="ltx_item" id="S5.I2.i2.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="S5.I2.i2.I1.i2.1.1.1">–</span></span>
<div class="ltx_para" id="S5.I2.i2.I1.i2.p1">
<p class="ltx_p" id="S5.I2.i2.I1.i2.p1.1">Business Review Text Feature: Similarly, all reviews received by the business are collected and converted into multiple 384-dimensional embedding vectors, then average pooling is used to generate a single 384-dimensional embedding vector.</p>
</div>
</li>
<li class="ltx_item" id="S5.I2.i2.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="S5.I2.i2.I1.i3.1.1.1">–</span></span>
<div class="ltx_para" id="S5.I2.i2.I1.i3.p1">
<p class="ltx_p" id="S5.I2.i2.I1.i3.p1.1">Review Image Feature: Firstly, we use each image as input for a pre-trained reset-50 model, then extract features from the second-to-last layer. Each image generates a 1x2048-dimensional embedding vector.All image embedding vectors for a business are collected, and average pooling is applied to obtain a single embedding vector.
Finally, we concatenate the business review text feature, user review text feature, and review image feature into a single big vector. This vector is then passed through a upstream model to reduce its dimension to 32.</p>
</div>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S5.SS2.p2">
<p class="ltx_p" id="S5.SS2.p2.1">Compared to the baseline model, we add new dense feature: Price Tag, and a sparse Feature: Restaurant Category, into the proposed model. In addition, we replace all embedding features with new ones generated with the help of LLM and multi-modal model.</p>
</div>
<div class="ltx_para" id="S5.SS2.p3">
<ul class="ltx_itemize" id="S5.I3">
<li class="ltx_item" id="S5.I3.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I3.i1.p1">
<p class="ltx_p" id="S5.I3.i1.p1.1">All following prompt engineering are using the GPT 3.5-turbo-1106 model.</p>
</div>
</li>
<li class="ltx_item" id="S5.I3.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I3.i2.p1">
<p class="ltx_p" id="S5.I3.i2.p1.1">Dense Features:</p>
<ul class="ltx_itemize" id="S5.I3.i2.I1">
<li class="ltx_item" id="S5.I3.i2.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="S5.I3.i2.I1.i1.1.1.1">–</span></span>
<div class="ltx_para" id="S5.I3.i2.I1.i1.p1">
<p class="ltx_p" id="S5.I3.i2.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S5.I3.i2.I1.i1.p1.1.1">Price Tag Feature</span>: Use LLMs to analyze reviews for a business. We use the prompt: “Can you tell me if the price is over-rice, fair price, low price from reviews for this restaurant. Give me just the category ”. There can be a case that there is no clear indication of the price level in review. Therefore after some data post-processing, we generate a price tag categorized as fair price, overpriced, cheap price, or none for each restaurant</p>
</div>
</li>
</ul>
</div>
</li>
<li class="ltx_item" id="S5.I3.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I3.i3.p1">
<p class="ltx_p" id="S5.I3.i3.p1.1">Sparse Features:</p>
<ul class="ltx_itemize" id="S5.I3.i3.I1">
<li class="ltx_item" id="S5.I3.i3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="S5.I3.i3.I1.i1.1.1.1">–</span></span>
<div class="ltx_para" id="S5.I3.i3.I1.i1.p1">
<p class="ltx_p" id="S5.I3.i3.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S5.I3.i3.I1.i1.p1.1.1">Restaurant Category Feature</span>: Similar to the price tag feature, we use prompt <span class="ltx_text ltx_font_italic" id="S5.I3.i3.I1.i1.p1.1.2">“can you tell me what kind of restaurant this is from these reviews for the restaurant. Return me in this format:’type’”</span>. This prompt helps generate the best description of the restaurant category based on reviews. Given the limitation of the current LLM model, the result is not always a single restaurant type, usually a brief summary of the food style presented in reviews. Therefore, we generate each restaurant a list of subtypes. There are 179 distinct types and the maximum number of subtypes for a restaurant is 11. In the pre-processing step, all subtype tensors were padded to the length of 11, and the padding value is set to 179 (i.e. embedding table contains 180 distinct values and the last one is padding idx).</p>
</div>
</li>
</ul>
</div>
</li>
<li class="ltx_item" id="S5.I3.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I3.i4.p1">
<p class="ltx_p" id="S5.I3.i4.p1.1">Embedding Features with LLM:</p>
<ul class="ltx_itemize" id="S5.I3.i4.I1">
<li class="ltx_item" id="S5.I3.i4.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="S5.I3.i4.I1.i1.1.1.1">–</span></span>
<div class="ltx_para" id="S5.I3.i4.I1.i1.p1">
<p class="ltx_p" id="S5.I3.i4.I1.i1.p1.1">With the help of LLM, we are able to get a summary of review with prompts shown in Fig <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#S4.F3" title="Figure 3 ‣ 4.2. LLM summarization ‣ 4. Methodology ‣ MMREC: LLM Based Multi-Modal Recommender System"><span class="ltx_text ltx_ref_tag">3</span></a> to summarize all reviews written by the same user, then convert the summary into an embedding vector representing the user. Similarly, we can get the embedding vector for a single business. We concatenate the business review summary features and user review summary features into one big vector. This vector is then passed through an upstream model to reduce its dimensionality of vector to 32.</p>
</div>
</li>
<li class="ltx_item" id="S5.I3.i4.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="S5.I3.i4.I1.i2.1.1.1">–</span></span>
<div class="ltx_para" id="S5.I3.i4.I1.i2.p1">
<p class="ltx_p" id="S5.I3.i4.I1.i2.p1.1">In addition, we rely on a multi-modal model (BLIP 2) to produce textual information from images through unconditional image captioning, producing objective descriptions for the images as shown in Fig <a class="ltx_ref" href="https://arxiv.org/html/2408.04211v1#S5.F4" title="Figure 4 ‣ 4th item ‣ 5.2. Data Pre-processing ‣ 5. Experiement ‣ MMREC: LLM Based Multi-Modal Recommender System"><span class="ltx_text ltx_ref_tag">4</span></a>. Each image is converted to one description sentence and then is transformed into anembedding vector. Average pooling is used to combine these vectors to create a comprehensive image feature representation for the restaurant. The averaged vector is then passed through an upstream model to reduce its dimensionality to 32.</p>
</div>
</li>
<li class="ltx_item" id="S5.I3.i4.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="S5.I3.i4.I1.i3.1.1.1">–</span></span>
<div class="ltx_para" id="S5.I3.i4.I1.i3.p1">
<p class="ltx_p" id="S5.I3.i4.I1.i3.p1.1">By concatenating the text vector and image vector together, we form the embedding features for the proposed model.</p>
</div>
</li>
</ul>
</div>
<figure class="ltx_figure" id="S5.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="385" id="S5.F4.g1" src="extracted/5780532/figures/blip2_example.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4. </span>Using BLIP-2 to perform unconditional image captioning on restaurant review image</figcaption>
</figure>
</li>
</ul>
</div>
</section>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3. </span>Result</h3>
<div class="ltx_para" id="S5.SS3.p1">
<ul class="ltx_itemize" id="S5.I4">
<li class="ltx_item" id="S5.I4.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I4.i1.p1">
<p class="ltx_p" id="S5.I4.i1.p1.1">Compared to the baseline model, the proposed model achieves a much better false positive rate in both the train set and the test set. According to Table 1, The best model against the train set is the proposed model with basic weighted loss and 0.1 dropout rate, the false positive rate is around 2%.</p>
</div>
</li>
<li class="ltx_item" id="S5.I4.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I4.i2.p1">
<p class="ltx_p" id="S5.I4.i2.p1.1">The model with the highest accuracy is the baseline model with a 0.5 dropout rate and square root weight. It achieves 93.47% accuracy with a 37.58% false positive rate against the test set as shown in Table 2.</p>
</div>
</li>
<li class="ltx_item" id="S5.I4.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I4.i3.p1">
<p class="ltx_p" id="S5.I4.i3.p1.1">Regarding the performance of the false positive rate against the test set, see Table 2, the best model turns out to be the proposed model with basic weighted loss and 0.5 dropout rate. It achieves a 18.16% false positive rate while accuracy on the test set still reaches 83.48% <span class="ltx_text ltx_font_bold" id="S5.I4.i3.p1.1.1">we obtain a 19.4% improvement in the false positive rate at the expense of 10% decrease in accuracy</span></p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_subsection" id="S5.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4. </span>Analysis</h3>
<div class="ltx_para" id="S5.SS4.p1">
<p class="ltx_p" id="S5.SS4.p1.1">We observed that when square root weighting is applied, there is a tendency for the false positive rate to increase. This is likely due to the model’s focus on minimizing the overall error, potentially at the expense of higher precision.</p>
</div>
<div class="ltx_para" id="S5.SS4.p2">
<p class="ltx_p" id="S5.SS4.p2.1">In the proposed model, we observe a clear over-fitting with a lower dropout rate, which, paradoxically, results in increased accuracy and a reduced false positive rate. Although the model exhibits over-fitting, the aim of this paper is not to fine-tune the model to achieve optimal performance but to leverage the Large Language Model (LLM) summarization capabilities.</p>
</div>
<div class="ltx_para" id="S5.SS4.p3">
<p class="ltx_p" id="S5.SS4.p3.1">In the context of ranking and recommendation, it is crucial to avoid recommending items that do not match customers’ preferences, which means a high false positive rate is unacceptable. In most practical applications, RS shows users a list of top N items. A lower false positive rate ensures that the recommendations are more aligned with the users’ tastes and top 1 accuracy becomes less important. Usually, top N accuracy is high enough. In our experiment, the baseline model tends to label data as positive which results in higher accuracy due to the imbalanced dataset, and performs worse in identifying false samples. Therefore, instead of focusing on accuracy, we consider the proposed model to be better than the baseline model given its superior performance on a low false positive rate.</p>
</div>
<div class="ltx_para" id="S5.SS4.p4">
<p class="ltx_p" id="S5.SS4.p4.1">The significant reduction in the false positive rate observed in the proposed model can be attributed to the powerful ability of Large Language Models (LLMs) in summarizing reviews. LLMs, trained on vast and diverse corpora, possess extensive knowledge and nuanced understanding of language, enabling them to distill complex information effectively. When tasked with generating features like price levels or restaurant types from multiple reviews, LLMs can synthesize and summarize data, extracting relevant details and insights that might be challenging to identify through traditional methods. This process not only enhances the original information by integrating the contextual and experiential knowledge embedded in the reviews but also enriches the dataset with features that are informed by the broader understanding LLMs have acquired during their own training.</p>
</div>
<div class="ltx_para" id="S5.SS4.p5">
<p class="ltx_p" id="S5.SS4.p5.1">In addition, LLMs are good at extracting and emphasizing critical and repeated information in various reviews. By using prompts to summarize reviews, LLM helps provide a more accurate and representative summary of the sentiments and opinions expressed by users. This summarization power ensures that the model captures the essential features that distinguish different users and restaurants, leading to more precise recommendations. In contrast, the baseline model employs a simpler approach by averaging the embedding vectors of all reviews. This method tends to dilute the information because it treats all reviews equally, regardless of their quality or relevance. Consequently, the baseline model is prone to incorporating a lot of noise into the embeddings, which can obscure the critical information needed to make accurate predictions. This noise makes it difficult for the model to effectively differentiate between user preferences and restaurant characteristics, resulting in a higher false positive rate.</p>
</div>
<div class="ltx_para" id="S5.SS4.p6">
<p class="ltx_p" id="S5.SS4.p6.1">In addition, the proposed model leverages the multimodal model (BLIP2) and its description ability to identify multiple food items listed in review images, helping the model to discriminate between various users and restaurants. By contrast, the baseline model relies on the image classification model(resnet), which has limitations in identifying multiple objects within the image, especially when dealing with multiple types. Image classification models alone fail to capture the semantic meaning within images, making the extracted signals less powerful when fed to the recommender.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6. </span>Conclusion</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">In this paper, we have proposed an innovative framework that harnesses the reasoning and summarization capabilities of LLMs to process multi-modal information effectively. Our research demonstrates the significant potential of integrating multi-modal data to enhance the performance of deep learning-based recommender systems, particularly in scenarios involving imbalanced datasets.</p>
</div>
<div class="ltx_para" id="S6.p2">
<p class="ltx_p" id="S6.p2.1">The utilization of LLMs enables the projection of features from diverse modalities into a unified latent space, facilitating more efficient model learning and convergence. Specifically, our approach leverages LLMs to:</p>
<ul class="ltx_itemize" id="S6.I1">
<li class="ltx_item" id="S6.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S6.I1.i1.p1">
<p class="ltx_p" id="S6.I1.i1.p1.1">Summarize user review texts, capturing nuanced user behaviors and preferences.</p>
</div>
</li>
<li class="ltx_item" id="S6.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S6.I1.i2.p1">
<p class="ltx_p" id="S6.I1.i2.p1.1">Generate descriptive text for images, extracting implicit knowledge about businesses and products.</p>
</div>
</li>
</ul>
<p class="ltx_p" id="S6.p2.2">This novel method allows for the transformation of image-based information into textual data, which can then be processed using the same text encoder employed for user reviews. Consequently, both image-derived and text-based features are represented in the same latent space when fed into the model, ensuring a more cohesive and comprehensive input.</p>
</div>
<div class="ltx_para" id="S6.p3">
<p class="ltx_p" id="S6.p3.1">Our findings indicate that the incorporation of these LLM-generated signals leads to substantial improvements in model performance. We hypothesize that this enhancement is particularly pronounced due to two factors:</p>
<ul class="ltx_itemize" id="S6.I2">
<li class="ltx_item" id="S6.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S6.I2.i1.p1">
<p class="ltx_p" id="S6.I2.i1.p1.1">The ability to extract valuable insights from negative reviews, which often contain critical information for recommendation systems.</p>
</div>
</li>
<li class="ltx_item" id="S6.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S6.I2.i2.p1">
<p class="ltx_p" id="S6.I2.i2.p1.1">The summarization capabilities of LLMs, which ensure that essential information is distilled and preserved, rather than diluted during the averaging process typically employed in traditional approaches.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Achiam et al<span class="ltx_text" id="bib.bib2.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al<span class="ltx_text" id="bib.bib2.3.1">.</span> 2023.

</span>
<span class="ltx_bibblock">Gpt-4 technical report.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib2.4.1">arXiv preprint arXiv:2303.08774</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">An and Moon (2022)</span>
<span class="ltx_bibblock">
Hyeon-woo An and Nammee Moon. 2022.

</span>
<span class="ltx_bibblock">Design of recommendation system for tourist spot using sentiment analysis based on CNN-LSTM.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">Journal of Ambient Intelligence and Humanized Computing</em> 13, 3 (2022), 1653–1663.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Barkan et al<span class="ltx_text" id="bib.bib4.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Oren Barkan, Roy Hirsch, Ori Katz, Avi Caciularu, and Noam Koenigstein. 2021.

</span>
<span class="ltx_bibblock">Anchor-based collaborative filtering. In <em class="ltx_emph ltx_font_italic" id="bib.bib4.3.1">Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management</em>. 2877–2881.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown et al<span class="ltx_text" id="bib.bib5.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and
Dario Amodei. 2020.

</span>
<span class="ltx_bibblock">Language Models are Few-Shot Learners. In <em class="ltx_emph ltx_font_italic" id="bib.bib5.3.1">Advances in Neural Information Processing Systems</em>, H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, and H. Lin (Eds.), Vol. 33. Curran Associates, Inc., 1877–1901.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf" title="">https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al<span class="ltx_text" id="bib.bib6.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Chih-Ming Chen, Chuan-Ju Wang, Ming-Feng Tsai, and Yi-Hsuan Yang. 2019.

</span>
<span class="ltx_bibblock">Collaborative similarity embedding for recommender systems. In <em class="ltx_emph ltx_font_italic" id="bib.bib6.3.1">The World Wide Web Conference</em>. 2637–2643.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cheng et al<span class="ltx_text" id="bib.bib7.2.2.1">.</span> (2016)</span>
<span class="ltx_bibblock">
Heng-Tze Cheng, Levent Koc, Jeremiah Harmsen, Tal Shaked, Tushar Chandra, Hrishi Aradhye, Glen Anderson, Greg Corrado, Wei Chai, Mustafa Ispir, et al<span class="ltx_text" id="bib.bib7.3.1">.</span> 2016.

</span>
<span class="ltx_bibblock">Wide &amp; deep learning for recommender systems. In <em class="ltx_emph ltx_font_italic" id="bib.bib7.4.1">Proceedings of the 1st workshop on deep learning for recommender systems</em>. 7–10.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chin et al<span class="ltx_text" id="bib.bib8.2.2.1">.</span> (2018)</span>
<span class="ltx_bibblock">
Jin Yao Chin, Kaiqi Zhao, Shafiq Joty, and Gao Cong. 2018.

</span>
<span class="ltx_bibblock">ANR: Aspect-based neural recommender. In <em class="ltx_emph ltx_font_italic" id="bib.bib8.3.1">Proceedings of the 27th ACM International conference on information and knowledge management</em>. 147–156.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cobbe et al<span class="ltx_text" id="bib.bib9.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, and John Schulman. 2021.

</span>
<span class="ltx_bibblock">Training Verifiers to Solve Math Word Problems.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2110.14168 [cs.LG]

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Covington et al<span class="ltx_text" id="bib.bib10.2.2.1">.</span> (2016)</span>
<span class="ltx_bibblock">
Paul Covington, Jay Adams, and Emre Sargin. 2016.

</span>
<span class="ltx_bibblock">Deep neural networks for youtube recommendations. In <em class="ltx_emph ltx_font_italic" id="bib.bib10.3.1">Proceedings of the 10th ACM conference on recommender systems</em>. 191–198.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dai et al<span class="ltx_text" id="bib.bib11.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Sunhao Dai, Ninglu Shao, Haiyuan Zhao, Weijie Yu, Zihua Si, Chen Xu, Zhongxiang Sun, Xiao Zhang, and Jun Xu. 2023.

</span>
<span class="ltx_bibblock">Uncovering chatgpt’s capabilities in recommender systems. In <em class="ltx_emph ltx_font_italic" id="bib.bib11.3.1">Proceedings of the 17th ACM Conference on Recommender Systems</em>. 1126–1132.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Devlin et al<span class="ltx_text" id="bib.bib12.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019.

</span>
<span class="ltx_bibblock">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In <em class="ltx_emph ltx_font_italic" id="bib.bib12.3.1">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</em>, Jill Burstein, Christy Doran, and Thamar Solorio (Eds.). Association for Computational Linguistics, Minneapolis, Minnesota, 4171–4186.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/v1/N19-1423" title="">https://doi.org/10.18653/v1/N19-1423</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao et al<span class="ltx_text" id="bib.bib13.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Yunfan Gao, Tao Sheng, Youlin Xiang, Yun Xiong, Haofen Wang, and Jiawei Zhang. 2023.

</span>
<span class="ltx_bibblock">Chat-rec: Towards interactive and explainable llms-augmented recommender system.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib13.3.1">arXiv preprint arXiv:2303.14524</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Geng et al<span class="ltx_text" id="bib.bib14.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Shijie Geng, Shuchang Liu, Zuohui Fu, Yingqiang Ge, and Yongfeng Zhang. 2022.

</span>
<span class="ltx_bibblock">Recommendation as language processing (rlp): A unified pretrain, personalized prompt &amp; predict paradigm (p5). In <em class="ltx_emph ltx_font_italic" id="bib.bib14.3.1">Proceedings of the 16th ACM Conference on Recommender Systems</em>. 299–315.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Goyal et al<span class="ltx_text" id="bib.bib15.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Tanya Goyal, Junyi Jessy Li, and Greg Durrett. 2023.

</span>
<span class="ltx_bibblock">News Summarization and Evaluation in the Era of GPT-3.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2209.12356 [cs.CL]

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guo et al<span class="ltx_text" id="bib.bib16.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Huifeng Guo, Bo Chen, Ruiming Tang, Weinan Zhang, Zhenguo Li, and Xiuqiang He. 2021.

</span>
<span class="ltx_bibblock">An embedding learning framework for numerical features in ctr prediction. In <em class="ltx_emph ltx_font_italic" id="bib.bib16.3.1">Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining</em>. 2910–2918.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guo et al<span class="ltx_text" id="bib.bib17.2.2.1">.</span> (2017)</span>
<span class="ltx_bibblock">
Huifeng Guo, Ruiming Tang, Yunming Ye, Zhenguo Li, and Xiuqiang He. 2017.

</span>
<span class="ltx_bibblock">DeepFM: a factorization-machine based neural network for CTR prediction.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib17.3.1">arXiv preprint arXiv:1703.04247</em> (2017).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hamilton et al<span class="ltx_text" id="bib.bib18.2.2.1">.</span> (2017)</span>
<span class="ltx_bibblock">
Will Hamilton, Zhitao Ying, and Jure Leskovec. 2017.

</span>
<span class="ltx_bibblock">Inductive representation learning on large graphs.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib18.3.1">Advances in neural information processing systems</em> 30 (2017).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Haruna et al<span class="ltx_text" id="bib.bib19.2.2.1">.</span> (2017)</span>
<span class="ltx_bibblock">
Khalid Haruna, Maizatul Akmar Ismail, Suhendroyono Suhendroyono, Damiasih Damiasih, Adi Cilik Pierewan, Haruna Chiroma, and Tutut Herawan. 2017.

</span>
<span class="ltx_bibblock">Context-Aware Recommender System: A Review of Recent Developmental Process and Future Research Direction.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.3.1">Applied Sciences</em> 7, 12 (2017).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.3390/app7121211" title="">https://doi.org/10.3390/app7121211</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et al<span class="ltx_text" id="bib.bib20.2.2.1">.</span> (2016)</span>
<span class="ltx_bibblock">
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016.

</span>
<span class="ltx_bibblock">Identity mappings in deep residual networks. In <em class="ltx_emph ltx_font_italic" id="bib.bib20.3.1">Computer Vision–ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11–14, 2016, Proceedings, Part IV 14</em>. Springer, 630–645.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et al<span class="ltx_text" id="bib.bib21.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Xiangnan He, Kuan Deng, Xiang Wang, Yan Li, Yongdong Zhang, and Meng Wang. 2020.

</span>
<span class="ltx_bibblock">Lightgcn: Simplifying and powering graph convolution network for recommendation. In <em class="ltx_emph ltx_font_italic" id="bib.bib21.3.1">Proceedings of the 43rd International ACM SIGIR conference on research and development in Information Retrieval</em>. 639–648.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et al<span class="ltx_text" id="bib.bib22.2.2.1">.</span> (2017)</span>
<span class="ltx_bibblock">
Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Seng Chua. 2017.

</span>
<span class="ltx_bibblock">Neural collaborative filtering. In <em class="ltx_emph ltx_font_italic" id="bib.bib22.3.1">Proceedings of the 26th international conference on world wide web</em>. 173–182.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hou et al<span class="ltx_text" id="bib.bib23.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Yupeng Hou, Shanlei Mu, Wayne Xin Zhao, Yaliang Li, Bolin Ding, and Ji-Rong Wen. 2022.

</span>
<span class="ltx_bibblock">Towards universal sequence representation learning for recommender systems. In <em class="ltx_emph ltx_font_italic" id="bib.bib23.3.1">Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</em>. 585–593.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kipf and Welling (2016)</span>
<span class="ltx_bibblock">
Thomas N Kipf and Max Welling. 2016.

</span>
<span class="ltx_bibblock">Semi-supervised classification with graph convolutional networks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">arXiv preprint arXiv:1609.02907</em> (2016).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Koch et al<span class="ltx_text" id="bib.bib25.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Andrew Koch, Jiahao Tian, and Michael D Porter. 2020.

</span>
<span class="ltx_bibblock">Criminal Consistency and Distinctiveness. In <em class="ltx_emph ltx_font_italic" id="bib.bib25.3.1">2020 Systems and Information Engineering Design Symposium (SIEDS)</em>. IEEE, 1–3.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kojima et al<span class="ltx_text" id="bib.bib26.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Takeshi Kojima, Shixiang (Shane) Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. 2022.

</span>
<span class="ltx_bibblock">Large Language Models are Zero-Shot Reasoners. In <em class="ltx_emph ltx_font_italic" id="bib.bib26.3.1">Advances in Neural Information Processing Systems</em>, S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh (Eds.), Vol. 35. Curran Associates, Inc., 22199–22213.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://proceedings.neurips.cc/paper_files/paper/2022/file/8bb0d291acd4acf06ef112099c16f326-Paper-Conference.pdf" title="">https://proceedings.neurips.cc/paper_files/paper/2022/file/8bb0d291acd4acf06ef112099c16f326-Paper-Conference.pdf</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Koroteev (2021)</span>
<span class="ltx_bibblock">
Mikhail V Koroteev. 2021.

</span>
<span class="ltx_bibblock">BERT: a review of applications in natural language processing and understanding.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">arXiv preprint arXiv:2103.11943</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kumar et al<span class="ltx_text" id="bib.bib28.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Chintoo Kumar, C Ravindranath Chowdary, and Deepika Shukla. 2022.

</span>
<span class="ltx_bibblock">Automatically detecting groups using locality-sensitive hashing in group recommendations.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib28.3.1">Information Sciences</em> 601 (2022), 207–223.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kumar et al<span class="ltx_text" id="bib.bib29.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Srijan Kumar, Xikun Zhang, and Jure Leskovec. 2019.

</span>
<span class="ltx_bibblock">Predicting dynamic embedding trajectory in temporal interaction networks. In <em class="ltx_emph ltx_font_italic" id="bib.bib29.3.1">Proceedings of the 25th ACM SIGKDD international conference on knowledge discovery &amp; data mining</em>. 1269–1278.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span class="ltx_text" id="bib.bib30.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Chenliang Li, Cong Quan, Li Peng, Yunwei Qi, Yuming Deng, and Libing Wu. 2019.

</span>
<span class="ltx_bibblock">A capsule network for recommendation and explaining what you like and dislike. In <em class="ltx_emph ltx_font_italic" id="bib.bib30.3.1">Proceedings of the 42nd international ACM SIGIR conference on research and development in information retrieval</em>. 275–284.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span class="ltx_text" id="bib.bib31.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Cheng Li, Jindong Wang, Yixuan Zhang, Kaijie Zhu, Wenxin Hou, Jianxun Lian, Fang Luo, Qiang Yang, and Xing Xie. 2023.

</span>
<span class="ltx_bibblock">Large Language Models Understand and Can be Enhanced by Emotional Stimuli.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2307.11760 [cs.CL]

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li and Karahanna (2015)</span>
<span class="ltx_bibblock">
Seth Siyuan Li and Elena Karahanna. 2015.

</span>
<span class="ltx_bibblock">Online recommendation systems in a B2C E-commerce context: a review and future directions.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">Journal of the association for information systems</em> 16, 2 (2015), 2.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ling et al<span class="ltx_text" id="bib.bib33.2.2.1">.</span> (2017)</span>
<span class="ltx_bibblock">
Wang Ling, Dani Yogatama, Chris Dyer, and Phil Blunsom. 2017.

</span>
<span class="ltx_bibblock">Program Induction by Rationale Generation: Learning to Solve and Explain Algebraic Word Problems. In <em class="ltx_emph ltx_font_italic" id="bib.bib33.3.1">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, Regina Barzilay and Min-Yen Kan (Eds.). Association for Computational Linguistics, Vancouver, Canada, 158–167.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/v1/P17-1015" title="">https://doi.org/10.18653/v1/P17-1015</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Naumov et al<span class="ltx_text" id="bib.bib34.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Maxim Naumov, Dheevatsa Mudigere, Hao-Jun Michael Shi, Jianyu Huang, Narayanan Sundaraman, Jongsoo Park, Xiaodong Wang, Udit Gupta, Carole-Jean Wu, Alisson G Azzolini, et al<span class="ltx_text" id="bib.bib34.3.1">.</span> 2019.

</span>
<span class="ltx_bibblock">Deep learning recommendation model for personalization and recommendation systems.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib34.4.1">arXiv preprint arXiv:1906.00091</em> (2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pancha et al<span class="ltx_text" id="bib.bib35.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Nikil Pancha, Andrew Zhai, Jure Leskovec, and Charles Rosenberg. 2022.

</span>
<span class="ltx_bibblock">Pinnerformer: Sequence modeling for user representation at pinterest. In <em class="ltx_emph ltx_font_italic" id="bib.bib35.3.1">Proceedings of the 28th ACM SIGKDD conference on knowledge discovery and data mining</em>. 3702–3712.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pi et al<span class="ltx_text" id="bib.bib36.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Qi Pi, Guorui Zhou, Yujing Zhang, Zhe Wang, Lejian Ren, Ying Fan, Xiaoqiang Zhu, and Kun Gai. 2020.

</span>
<span class="ltx_bibblock">Search-based user interest modeling with lifelong sequential behavior data for click-through rate prediction. In <em class="ltx_emph ltx_font_italic" id="bib.bib36.3.1">Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management</em>. 2685–2692.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sato (2022)</span>
<span class="ltx_bibblock">
Ryoma Sato. 2022.

</span>
<span class="ltx_bibblock">Enumerating fair packages for group recommendations. In <em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining</em>. 870–878.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Song et al<span class="ltx_text" id="bib.bib38.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Qingquan Song, Dehua Cheng, Hanning Zhou, Jiyan Yang, Yuandong Tian, and Xia Hu. 2020.

</span>
<span class="ltx_bibblock">Towards automated neural interaction discovery for click-through rate prediction. In <em class="ltx_emph ltx_font_italic" id="bib.bib38.3.1">Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</em>. 945–955.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Stratigi et al<span class="ltx_text" id="bib.bib39.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Maria Stratigi, Evaggelia Pitoura, Jyrki Nummenmaa, and Kostas Stefanidis. 2022.

</span>
<span class="ltx_bibblock">Sequential group recommendations based on satisfaction and disagreement scores.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib39.3.1">Journal of Intelligent Information Systems</em> (2022), 1–28.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et al<span class="ltx_text" id="bib.bib40.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Jianing Sun, Yingxue Zhang, Chen Ma, Mark Coates, Huifeng Guo, Ruiming Tang, and Xiuqiang He. 2019.

</span>
<span class="ltx_bibblock">Multi-graph convolution collaborative filtering. In <em class="ltx_emph ltx_font_italic" id="bib.bib40.3.1">2019 IEEE International Conference on Data Mining (ICDM)</em>. IEEE, 1306–1311.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et al<span class="ltx_text" id="bib.bib41.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Xiaofei Sun, Xiaoya Li, Shengyu Zhang, Shuhe Wang, Fei Wu, Jiwei Li, Tianwei Zhang, and Guoyin Wang. 2023.

</span>
<span class="ltx_bibblock">Sentiment Analysis through LLM Negotiations.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2311.01876 [cs.CL]

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Talmor et al<span class="ltx_text" id="bib.bib42.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Alon Talmor, Jonathan Herzig, Nicholas Lourie, and Jonathan Berant. 2019.

</span>
<span class="ltx_bibblock">CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge. In <em class="ltx_emph ltx_font_italic" id="bib.bib42.3.1">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</em>, Jill Burstein, Christy Doran, and Thamar Solorio (Eds.). Association for Computational Linguistics, Minneapolis, Minnesota, 4149–4158.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/v1/N19-1421" title="">https://doi.org/10.18653/v1/N19-1421</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tian and Porter (2022)</span>
<span class="ltx_bibblock">
Jiahao Tian and Michael D Porter. 2022.

</span>
<span class="ltx_bibblock">Changing presidential approval: Detecting and understanding change points in interval censored polling data.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">Stat</em> 11, 1 (2022), e463.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tian and Porter (2024)</span>
<span class="ltx_bibblock">
Jiahao Tian and Michael D Porter. 2024.

</span>
<span class="ltx_bibblock">Time of week intensity estimation from partly interval censored data with applications to police patrol planning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib44.1.1">Journal of Applied Statistics</em> (2024), 1–19.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wan et al<span class="ltx_text" id="bib.bib45.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Zhen Wan, Fei Cheng, Zhuoyuan Mao, Qianying Liu, Haiyue Song, Jiwei Li, and Sadao Kurohashi. 2023.

</span>
<span class="ltx_bibblock">GPT-RE: In-context Learning for Relation Extraction using Large Language Models. In <em class="ltx_emph ltx_font_italic" id="bib.bib45.3.1">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</em>, Houda Bouamor, Juan Pino, and Kalika Bali (Eds.). Association for Computational Linguistics, Singapore, 3534–3547.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/v1/2023.emnlp-main.214" title="">https://doi.org/10.18653/v1/2023.emnlp-main.214</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang (2023)</span>
<span class="ltx_bibblock">
Haowen Wang. 2023.

</span>
<span class="ltx_bibblock">Google Restaurants Rating [recommendation system].

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.kaggle.com/datasets/hwwang98/google-restaurants" title="">https://www.kaggle.com/datasets/hwwang98/google-restaurants</a>
</span>
<span class="ltx_bibblock">Accessed: 2024-05-20.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang and Lim (2023)</span>
<span class="ltx_bibblock">
Lei Wang and Ee-Peng Lim. 2023.

</span>
<span class="ltx_bibblock">Zero-shot next-item recommendation using large pretrained language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib47.1.1">arXiv preprint arXiv:2304.03153</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span class="ltx_text" id="bib.bib48.2.2.1">.</span> (2023b)</span>
<span class="ltx_bibblock">
Shuhe Wang, Xiaofei Sun, Xiaoya Li, Rongbin Ouyang, Fei Wu, Tianwei Zhang, Jiwei Li, and Guoyin Wang. 2023b.

</span>
<span class="ltx_bibblock">GPT-NER: Named Entity Recognition via Large Language Models.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2304.10428 [cs.CL]

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span class="ltx_text" id="bib.bib49.2.2.1">.</span> (2023a)</span>
<span class="ltx_bibblock">
Wenjie Wang, Xinyu Lin, Fuli Feng, Xiangnan He, and Tat-Seng Chua. 2023a.

</span>
<span class="ltx_bibblock">Generative recommendation: Towards next-generation recommender paradigm.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib49.3.1">arXiv preprint arXiv:2304.03516</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span class="ltx_text" id="bib.bib50.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Wenhui Wang, Furu Wei, Li Dong, Hangbo Bao, Nan Yang, and Ming Zhou. 2020.

</span>
<span class="ltx_bibblock">MiniLM: Deep Self-Attention Distillation for Task-Agnostic Compression of Pre-Trained Transformers. In <em class="ltx_emph ltx_font_italic" id="bib.bib50.3.1">Proceedings of the 34th International Conference on Neural Information Processing Systems</em>. 5776–5788.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span class="ltx_text" id="bib.bib51.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Xiaolei Wang, Kun Zhou, Ji-Rong Wen, and Wayne Xin Zhao. 2022.

</span>
<span class="ltx_bibblock">Towards unified conversational recommender systems via knowledge-enhanced prompt learning. In <em class="ltx_emph ltx_font_italic" id="bib.bib51.3.1">Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</em>. 1929–1937.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span class="ltx_text" id="bib.bib52.2.2.1">.</span> ([n. d.])</span>
<span class="ltx_bibblock">
Yining Wang, Jinman Zhao, and Yuri Lawryshyn. [n. d.].

</span>
<span class="ltx_bibblock">GPT-Signal: Generative AI for Semi-automated Feature Engineering in the Alpha Research Process.. In <em class="ltx_emph ltx_font_italic" id="bib.bib52.3.1">Proceedings of the Joint Workshop of the 8th Financial Technology and Natural Language Processing, and the 1st Workshop on Agent AI for Scenario Planning @ IJCAI 2024</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et al<span class="ltx_text" id="bib.bib53.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al<span class="ltx_text" id="bib.bib53.3.1">.</span> 2022.

</span>
<span class="ltx_bibblock">Chain-of-thought prompting elicits reasoning in large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib53.4.1">Advances in Neural Information Processing Systems</em> 35 (2022), 24824–24837.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al<span class="ltx_text" id="bib.bib54.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Chao Wu, Sannyuya Liu, Zeyu Zeng, Mao Chen, Adi Alhudhaif, Xiangyang Tang, Fayadh Alenezi, Norah Alnaim, and Xicheng Peng. 2022.

</span>
<span class="ltx_bibblock">Knowledge graph-based multi-context-aware recommendation algorithm.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib54.3.1">Information Sciences</em> 595 (2022), 179–194.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al<span class="ltx_text" id="bib.bib55.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Chuhan Wu, Fangzhao Wu, Mingxiao An, Jianqiang Huang, Yongfeng Huang, and Xing Xie. 2019.

</span>
<span class="ltx_bibblock">NPA: neural news recommendation with personalized attention. In <em class="ltx_emph ltx_font_italic" id="bib.bib55.3.1">Proceedings of the 25th ACM SIGKDD international conference on knowledge discovery &amp; data mining</em>. 2576–2584.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xie et al<span class="ltx_text" id="bib.bib56.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Tingyu Xie, Qi Li, Jian Zhang, Yan Zhang, Zuozhu Liu, and Hongwei Wang. 2023.

</span>
<span class="ltx_bibblock">Empirical Study of Zero-Shot NER with ChatGPT. In <em class="ltx_emph ltx_font_italic" id="bib.bib56.3.1">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</em>, Houda Bouamor, Juan Pino, and Kalika Bali (Eds.). Association for Computational Linguistics, Singapore, 7935–7956.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/v1/2023.emnlp-main.493" title="">https://doi.org/10.18653/v1/2023.emnlp-main.493</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al<span class="ltx_text" id="bib.bib57.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Chengfeng Xu, Pengpeng Zhao, Yanchi Liu, Jiajie Xu, Victor S Sheng S. Sheng, Zhiming Cui, Xiaofang Zhou, and Hui Xiong. 2019.

</span>
<span class="ltx_bibblock">Recurrent convolutional neural network for sequential recommendation. In <em class="ltx_emph ltx_font_italic" id="bib.bib57.3.1">The world wide web conference</em>. 3398–3404.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yin et al<span class="ltx_text" id="bib.bib58.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Bin Yin, Junjie Xie, Yu Qin, Zixiang Ding, Zhichao Feng, Xiang Li, and Wei Lin. 2023.

</span>
<span class="ltx_bibblock">Heterogeneous knowledge fusion: A novel approach for personalized recommendation via llm. In <em class="ltx_emph ltx_font_italic" id="bib.bib58.3.1">Proceedings of the 17th ACM Conference on Recommender Systems</em>. 599–601.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib59">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zan et al<span class="ltx_text" id="bib.bib59.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Shuxun Zan, Yujie Zhang, Xiangwu Meng, Pengtao Lv, and Yulu Du. 2021.

</span>
<span class="ltx_bibblock">UDA: A user-difference attention for group recommendation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib59.3.1">Information Sciences</em> 571 (2021), 401–417.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib60">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang and Yang (2021)</span>
<span class="ltx_bibblock">
Qinglong Zhang and Yu-Bin Yang. 2021.

</span>
<span class="ltx_bibblock">Rest: An efficient transformer for visual recognition.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib60.1.1">Advances in neural information processing systems</em> 34 (2021), 15475–15485.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib61">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span class="ltx_text" id="bib.bib61.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Song Zhang, Nan Zheng, and Danli Wang. 2022.

</span>
<span class="ltx_bibblock">GBERT: Pre-training user representations for ephemeral group recommendation. In <em class="ltx_emph ltx_font_italic" id="bib.bib61.3.1">Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management</em>. 2631–2639.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib62">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al<span class="ltx_text" id="bib.bib62.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Rongmei Zhao, Shenggen Ju, Jian Peng, Ning Yang, Fanli Yan, and Siyu Sun. 2022.

</span>
<span class="ltx_bibblock">Two-level graph path reasoning for conversational recommendation with user realistic preference. In <em class="ltx_emph ltx_font_italic" id="bib.bib62.3.1">proceedings of the 31st ACM international conference on information &amp; knowledge management</em>. 2701–2710.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib63">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zheng et al<span class="ltx_text" id="bib.bib63.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Jiayin Zheng, Juanyun Mai, and Yanlong Wen. 2022.

</span>
<span class="ltx_bibblock">Explainable session-based recommendation with meta-path guided instances and self-attention mechanism. In <em class="ltx_emph ltx_font_italic" id="bib.bib63.3.1">Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval</em>. 2555–2559.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib64">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zheng et al<span class="ltx_text" id="bib.bib64.2.2.1">.</span> (2017)</span>
<span class="ltx_bibblock">
Lei Zheng, Vahid Noroozi, and Philip S Yu. 2017.

</span>
<span class="ltx_bibblock">Joint deep modeling of users and items using reviews for recommendation. In <em class="ltx_emph ltx_font_italic" id="bib.bib64.3.1">Proceedings of the tenth ACM international conference on web search and data mining</em>. 425–434.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib65">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et al<span class="ltx_text" id="bib.bib65.2.2.1">.</span> (2018)</span>
<span class="ltx_bibblock">
Guorui Zhou, Xiaoqiang Zhu, Chenru Song, Ying Fan, Han Zhu, Xiao Ma, Yanghui Yan, Junqi Jin, Han Li, and Kun Gai. 2018.

</span>
<span class="ltx_bibblock">Deep interest network for click-through rate prediction. In <em class="ltx_emph ltx_font_italic" id="bib.bib65.3.1">Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery &amp; data mining</em>. 1059–1068.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib66">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et al<span class="ltx_text" id="bib.bib66.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Xiaokang Zhou, Yue Li, and Wei Liang. 2020.

</span>
<span class="ltx_bibblock">CNN-RNN based intelligent recommendation for online medical pre-diagnosis support.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib66.3.1">IEEE/ACM Transactions on Computational Biology and Bioinformatics</em> 18, 3 (2020), 912–921.

</span>
<span class="ltx_bibblock">
</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Thu Aug  8 04:30:22 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
