<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2308.04604] A Survey on Decentralized Federated Learning</title><meta property="og:description" content="In recent years, federated learning (FL) has become a very popular paradigm for training distributed, large-scale, and privacy-preserving machine learning (ML) systems.
In contrast to standard ML, where data must be co…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="A Survey on Decentralized Federated Learning">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="A Survey on Decentralized Federated Learning">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2308.04604">

<!--Generated on Wed Feb 28 13:16:43 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="Decentralized Federated Learning,  Peer-to-Peer Federated Learning,  Blockchain-based Federated Learning">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">A Survey on Decentralized Federated Learning</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Edoardo Gabrielli
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:gabrielli.1693726@studenti.uniroma1.it">gabrielli.1693726@studenti.uniroma1.it</a>
</span>
<span class="ltx_contact ltx_role_orcid"><a target="_blank" href="https://orcid.org/1234-5678-9012" title="ORCID identifier" class="ltx_ref">1234-5678-9012</a></span>
</span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Giovanni Pica
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:pica.1816394@studenti.uniroma1.it">pica.1816394@studenti.uniroma1.it</a>
</span>
<span class="ltx_contact ltx_role_orcid"><a target="_blank" href="https://orcid.org/1234-5678-9012" title="ORCID identifier" class="ltx_ref">1234-5678-9012</a></span>
</span></span>
<span class="ltx_author_before"> and </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Gabriele Tolomei
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:tolomei@di.uniroma1.it">tolomei@di.uniroma1.it</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span id="id1.1.id1" class="ltx_text ltx_affiliation_institution">Sapienza University of Rome</span><span id="id2.2.id2" class="ltx_text ltx_affiliation_streetaddress">Viale Regina Elena, 295</span><span id="id3.3.id3" class="ltx_text ltx_affiliation_city">Rome</span><span id="id4.4.id4" class="ltx_text ltx_affiliation_country">Italy</span><span id="id5.5.id5" class="ltx_text ltx_affiliation_postcode">00161</span>
</span></span></span>
</div>
<div class="ltx_dates">(2023)</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p id="id6.id1" class="ltx_p">In recent years, <span id="id6.id1.1" class="ltx_text ltx_font_italic">federated learning</span> (FL) has become a very popular paradigm for training distributed, large-scale, and privacy-preserving machine learning (ML) systems.
In contrast to standard ML, where data must be collected at the exact location where training is performed, FL takes advantage of the computational capabilities of millions of edge devices to collaboratively train a shared, global model without disclosing their local private data.
Specifically, in a typical FL system, the central server acts only as an orchestrator; it iteratively gathers and aggregates all the local models trained by each client on its private data until convergence.
Although FL undoubtedly has several benefits over traditional ML (e.g., it protects private data ownership by design), it suffers from several weaknesses.
One of the most critical challenges is to overcome the centralized orchestration of the classical FL client-server architecture, which is known to be vulnerable to single-point-of-failure risks and man-in-the-middle attacks, among others.
To mitigate such exposure, <span id="id6.id1.2" class="ltx_text ltx_font_italic">decentralized</span> FL solutions have emerged where all FL clients cooperate and communicate without a central server.
<br class="ltx_break">This survey comprehensively summarizes and reviews existing decentralized FL approaches proposed in the literature.
Furthermore, it identifies emerging challenges and suggests promising research directions in this under-explored domain.</p>
</div>
<div class="ltx_keywords">Decentralized Federated Learning, Peer-to-Peer Federated Learning, Blockchain-based Federated Learning
</div>
<span id="id1" class="ltx_note ltx_note_frontmatter ltx_role_copyright"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">copyright: </span>acmcopyright</span></span></span><span id="id2" class="ltx_note ltx_note_frontmatter ltx_role_journalyear"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">journalyear: </span>2023</span></span></span><span id="id3" class="ltx_note ltx_note_frontmatter ltx_role_doi"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">doi: </span>XXXXXXX.XXXXXXX</span></span></span><span id="id4" class="ltx_note ltx_note_frontmatter ltx_role_ccs"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Computing methodologies Machine learning</span></span></span><span id="id5" class="ltx_note ltx_note_frontmatter ltx_role_ccs"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Computing methodologies Learning paradigms</span></span></span><span id="id6" class="ltx_note ltx_note_frontmatter ltx_role_ccs"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Computing methodologies Distributed artificial intelligence</span></span></span><span id="id7" class="ltx_note ltx_note_frontmatter ltx_role_ccs"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Computing methodologies Distributed algorithms</span></span></span><span id="id8" class="ltx_note ltx_note_frontmatter ltx_role_ccs"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Computer systems organization Peer-to-peer architectures</span></span></span>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">The last decade has witnessed incredible advances in machine learning (ML) and artificial intelligence (AI), which in turn have led to the pervasive application of such techniques across several domains.
For example, ML/AI solutions are nowadays successfully used to solve complex tasks in natural language processing (NLP), computer vision, finance, and healthcare, to name a few.
One of the most remarkable successes of ML/AI is undoubtedly represented by the most recent generative large language models (LLMs), such as ChatGPT and GPT-4 <cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a href="#bib.bib64" title="" class="ltx_ref">2023</a>)</cite>, as well as text-to-image generators like DALL-E 2 <cite class="ltx_cite ltx_citemacro_citep">(Ramesh et al<span class="ltx_text">.</span>, <a href="#bib.bib78" title="" class="ltx_ref">2022</a>)</cite>, and Midjourney <cite class="ltx_cite ltx_citemacro_citep">(Oppenlaender, <a href="#bib.bib65" title="" class="ltx_ref">2022</a>)</cite>.
These tools have raised the bar of human-to-machine interaction to a <span id="S1.p1.1.1" class="ltx_text ltx_font_italic">new</span> level, unforeseeable only a few years ago.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">The increasing complexity of deep neural network architectures at the heart of such tools, having millions or even billions of learnable parameters, requires a massive volume of training data to avoid the risk of overfitting.
The standard approach for training such huge models is to collect large datasets in a single location, either physically centralized like a dedicated server or logically centralized like a cloud-based cluster of machines.
Very often, this necessitates moving data from their local origins to a remote destination, causing at least two problems.
First, the high-rate transmission of large bulk of data may exhaust network bandwidth consumption, ultimately affecting energy efficiency, especially for resource-constrained devices like mobile smartphones.
Second, and most importantly, data ownership is transferred to a third-party entity with possible implications for its privacy and security.
This paradigm poses significant challenges in some critical application domains where ML/AI systems are deployed due to existing regulatory restrictions. Indeed, several initiatives, such as GDPR <cite class="ltx_cite ltx_citemacro_citep">(Tikkinen-Piri et al<span class="ltx_text">.</span>, <a href="#bib.bib87" title="" class="ltx_ref">2018</a>)</cite> and HIPAA <cite class="ltx_cite ltx_citemacro_citep">(Nosowsky and Giordano, <a href="#bib.bib62" title="" class="ltx_ref">2006</a>)</cite>, have emerged to govern and protect sharing of sensitive data.
As it turns out, any company that (marginally) relies on ML/AI tools to run its business must satisfy data privacy and security requirements promulgated by current laws and regulations.
This is even more stringent for so-called “data-driven” companies, whose revenue heavily depends on the value they are able to extract from data.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Many solutions have been proposed in the literature to mitigate potential data privacy and security issues in the traditional ML setting, primarily leveraging <span id="S1.p3.1.1" class="ltx_text ltx_font_italic">differential privacy</span> (DP) <cite class="ltx_cite ltx_citemacro_citep">(Dwork and Roth, <a href="#bib.bib19" title="" class="ltx_ref">2014</a>)</cite>, <span id="S1.p3.1.2" class="ltx_text ltx_font_italic">homomorphic cryptography</span> (HC) <cite class="ltx_cite ltx_citemacro_citep">(Phong et al<span class="ltx_text">.</span>, <a href="#bib.bib70" title="" class="ltx_ref">2018</a>)</cite>, and <span id="S1.p3.1.3" class="ltx_text ltx_font_italic">secure multi-party computation</span> (SMPC) <cite class="ltx_cite ltx_citemacro_citep">(Goldreich, <a href="#bib.bib25" title="" class="ltx_ref">1999</a>)</cite> techniques.
However, deploying these solutions in practice may be problematic.
For instance, the amount of random noise injected by DP mechanisms must be carefully calibrated; adding more noise can guarantee higher data privacy protection but might also decrease the model accuracy significantly.
Similarly, using HC to compute encrypted learning data may be limited to simple linear models <cite class="ltx_cite ltx_citemacro_citep">(Nikolaenko et al<span class="ltx_text">.</span>, <a href="#bib.bib61" title="" class="ltx_ref">2013</a>)</cite> or a very small amount of entities involved <cite class="ltx_cite ltx_citemacro_citep">(Yuan and Yu, <a href="#bib.bib99" title="" class="ltx_ref">2014</a>)</cite>.
Finally, although SMPC can be used for large-scale ML, this technique is not immune to information leakage.
Thus, instead of “patching” the standard ML framework with privacy-preserving solutions <span id="S1.p3.1.4" class="ltx_text ltx_font_italic">ex post</span>, the focus of the research community has shifted to planning novel ML training procedures that protect data privacy and security <span id="S1.p3.1.5" class="ltx_text ltx_font_italic">by design</span>.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.3" class="ltx_p">As a result of such effort, <span id="S1.p4.3.1" class="ltx_text ltx_font_italic">federated learning</span> (FL) is a new ML paradigm first introduced by Google in 2017 <cite class="ltx_cite ltx_citemacro_citep">(McMahan and Ramage, <a href="#bib.bib55" title="" class="ltx_ref">2017</a>)</cite> that addresses the challenges above.
The authors advocate the need for a new <span id="S1.p4.3.2" class="ltx_text ltx_font_italic">distributed</span> training procedure with a well-known app for smartphones, i.e., the smart Google keyboard (Gboard). Indeed, at the core of Gboard, there is a neural language model that can predict, hence suggest, the next word to enter while the user is typing.
Of course, for such a model to be successful, it must be trained on vast text corpora collected from many user devices (e.g., smartphones).
In contrast to the standard ML approach, which would require <math id="S1.p4.1.m1.1" class="ltx_Math" alttext="(i)" display="inline"><semantics id="S1.p4.1.m1.1a"><mrow id="S1.p4.1.m1.1.2.2"><mo stretchy="false" id="S1.p4.1.m1.1.2.2.1">(</mo><mi id="S1.p4.1.m1.1.1" xref="S1.p4.1.m1.1.1.cmml">i</mi><mo stretchy="false" id="S1.p4.1.m1.1.2.2.2">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S1.p4.1.m1.1b"><ci id="S1.p4.1.m1.1.1.cmml" xref="S1.p4.1.m1.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.1.m1.1c">(i)</annotation></semantics></math> transferring these user-generated data from remote devices into Google’s infrastructure, <math id="S1.p4.2.m2.1" class="ltx_Math" alttext="(ii)" display="inline"><semantics id="S1.p4.2.m2.1a"><mrow id="S1.p4.2.m2.1.1.1" xref="S1.p4.2.m2.1.1.1.1.cmml"><mo stretchy="false" id="S1.p4.2.m2.1.1.1.2" xref="S1.p4.2.m2.1.1.1.1.cmml">(</mo><mrow id="S1.p4.2.m2.1.1.1.1" xref="S1.p4.2.m2.1.1.1.1.cmml"><mi id="S1.p4.2.m2.1.1.1.1.2" xref="S1.p4.2.m2.1.1.1.1.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S1.p4.2.m2.1.1.1.1.1" xref="S1.p4.2.m2.1.1.1.1.1.cmml">​</mo><mi id="S1.p4.2.m2.1.1.1.1.3" xref="S1.p4.2.m2.1.1.1.1.3.cmml">i</mi></mrow><mo stretchy="false" id="S1.p4.2.m2.1.1.1.3" xref="S1.p4.2.m2.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S1.p4.2.m2.1b"><apply id="S1.p4.2.m2.1.1.1.1.cmml" xref="S1.p4.2.m2.1.1.1"><times id="S1.p4.2.m2.1.1.1.1.1.cmml" xref="S1.p4.2.m2.1.1.1.1.1"></times><ci id="S1.p4.2.m2.1.1.1.1.2.cmml" xref="S1.p4.2.m2.1.1.1.1.2">𝑖</ci><ci id="S1.p4.2.m2.1.1.1.1.3.cmml" xref="S1.p4.2.m2.1.1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.2.m2.1c">(ii)</annotation></semantics></math> training a model on those data at a central location, and <math id="S1.p4.3.m3.1" class="ltx_Math" alttext="(iii)" display="inline"><semantics id="S1.p4.3.m3.1a"><mrow id="S1.p4.3.m3.1.1.1" xref="S1.p4.3.m3.1.1.1.1.cmml"><mo stretchy="false" id="S1.p4.3.m3.1.1.1.2" xref="S1.p4.3.m3.1.1.1.1.cmml">(</mo><mrow id="S1.p4.3.m3.1.1.1.1" xref="S1.p4.3.m3.1.1.1.1.cmml"><mi id="S1.p4.3.m3.1.1.1.1.2" xref="S1.p4.3.m3.1.1.1.1.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S1.p4.3.m3.1.1.1.1.1" xref="S1.p4.3.m3.1.1.1.1.1.cmml">​</mo><mi id="S1.p4.3.m3.1.1.1.1.3" xref="S1.p4.3.m3.1.1.1.1.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S1.p4.3.m3.1.1.1.1.1a" xref="S1.p4.3.m3.1.1.1.1.1.cmml">​</mo><mi id="S1.p4.3.m3.1.1.1.1.4" xref="S1.p4.3.m3.1.1.1.1.4.cmml">i</mi></mrow><mo stretchy="false" id="S1.p4.3.m3.1.1.1.3" xref="S1.p4.3.m3.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S1.p4.3.m3.1b"><apply id="S1.p4.3.m3.1.1.1.1.cmml" xref="S1.p4.3.m3.1.1.1"><times id="S1.p4.3.m3.1.1.1.1.1.cmml" xref="S1.p4.3.m3.1.1.1.1.1"></times><ci id="S1.p4.3.m3.1.1.1.1.2.cmml" xref="S1.p4.3.m3.1.1.1.1.2">𝑖</ci><ci id="S1.p4.3.m3.1.1.1.1.3.cmml" xref="S1.p4.3.m3.1.1.1.1.3">𝑖</ci><ci id="S1.p4.3.m3.1.1.1.1.4.cmml" xref="S1.p4.3.m3.1.1.1.1.4">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.3.m3.1c">(iii)</annotation></semantics></math> distributing the learned model back to user devices, Google proposed FL.
Generally speaking, FL trains a global model using distributed data, <span id="S1.p4.3.3" class="ltx_text ltx_font_italic">without</span> the need for the data to be shared nor transferred to any central facility.
In other words, FL takes advantage of a multitude of AI-enabled edge devices that cooperate with each other to <span id="S1.p4.3.4" class="ltx_text ltx_font_italic">jointly</span> learn a predictive model using their own local private data.
Specifically, an FL system consists of a central server and many edge clients; a typical FL round involves the following steps: <span id="S1.p4.3.5" class="ltx_text ltx_font_italic">(i)</span> the server randomly picks some clients and sends them the current, global model; <span id="S1.p4.3.6" class="ltx_text ltx_font_italic">(ii)</span> each selected client locally trains its model with its own private data; then, it sends the resulting local model to the server;<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Whenever we refer to global/local model, we mean global/local model <span id="footnote1.1" class="ltx_text ltx_font_italic">parameters</span>.</span></span></span> <span id="S1.p4.3.7" class="ltx_text ltx_font_italic">(iii)</span> the server updates the global model by computing an <em id="S1.p4.3.8" class="ltx_emph ltx_font_italic">aggregation function</em> on the local models received from clients (by default, the average, FedAvg <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib54" title="" class="ltx_ref">2017</a>)</cite>).
The process above continues until the global model converges.
Since this paradigm smoothly integrates with ubiquitous, distributed infrastructures, FL has been successfully applied to several domains, such as IoT <cite class="ltx_cite ltx_citemacro_citep">(Wu et al<span class="ltx_text">.</span>, <a href="#bib.bib92" title="" class="ltx_ref">2020a</a>)</cite>, Fog computing <cite class="ltx_cite ltx_citemacro_citep">(Zhou et al<span class="ltx_text">.</span>, <a href="#bib.bib105" title="" class="ltx_ref">2020</a>)</cite>, autonomous vehicles <cite class="ltx_cite ltx_citemacro_citep">(Pokhrel and Choi, <a href="#bib.bib71" title="" class="ltx_ref">2020</a>)</cite>, and wearable devices <cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib16" title="" class="ltx_ref">2020</a>)</cite>.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">Although FL has unquestionable advantages over standard ML, it also presents its own problems.
Broadly speaking, FL still faces the following critical challenges.</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p"><span id="S1.I1.i1.p1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Security and Privacy:</span> Keeping local data at each client’s end naturally preserves its privacy. Yet, FL can be vulnerable to data confidentiality, integrity, and availability threats <cite class="ltx_cite ltx_citemacro_citep">(Costa et al<span class="ltx_text">.</span>, <a href="#bib.bib18" title="" class="ltx_ref">2022</a>)</cite>.
We invite the reader to refer to <cite class="ltx_cite ltx_citemacro_citep">(Rodríguez-Barroso et al<span class="ltx_text">.</span>, <a href="#bib.bib79" title="" class="ltx_ref">2023</a>)</cite> for an exhaustive survey on these issues.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p"><span id="S1.I1.i2.p1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Communication Efficiency:</span> Avoiding large data transfers from their origins to a shared training facility improves communication efficiency. Nevertheless, FL requires several rounds of interactions, where updated model parameters are iteratively exchanged between edge clients and the central server until convergence.
This may slow down the distributed training of very complex models with millions or even billions of parameters and therefore needs adequate strategies to reduce communication overhead (e.g., model compression techniques <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a href="#bib.bib89" title="" class="ltx_ref">2018</a>; Seide et al<span class="ltx_text">.</span>, <a href="#bib.bib82" title="" class="ltx_ref">2014</a>; Zhang et al<span class="ltx_text">.</span>, <a href="#bib.bib100" title="" class="ltx_ref">2017</a>)</cite>).
Interested readers should consider <cite class="ltx_cite ltx_citemacro_citep">(Pouriyeh et al<span class="ltx_text">.</span>, <a href="#bib.bib72" title="" class="ltx_ref">2022</a>)</cite> for a survey on these aspects.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p"><span id="S1.I1.i3.p1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Data and System Heterogeneity:</span> One of the key characteristics of FL is that data generated by federated clients is usually non-independent and identically distributed (non-IID), which contrasts with the typical IID assumption of standard ML. In addition, the capabilities of FL clients may be very different from each other, e.g., in terms of network connectivity (WiFi, 5G, etc.) and hardware characteristics (memory, CPU, battery, etc.) Such differences also fluctuate due to the highly dynamic nature of FL systems, where new clients frequently join while others drop out.
A useful reference to learn more about this matter is <cite class="ltx_cite ltx_citemacro_citep">(Ma et al<span class="ltx_text">.</span>, <a href="#bib.bib52" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
</li>
<li id="S1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i4.p1" class="ltx_para">
<p id="S1.I1.i4.p1.1" class="ltx_p"><span id="S1.I1.i4.p1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Incentive Mechanisms:</span> The success of FL depends on the ability to attract edge devices with high-quality data and strong computational capabilities to join the federation. Currently, there are not enough incentives for those clients to participate and contribute.
Interesting attempts to engage “valuable” FL clients with the platform are discussed in <cite class="ltx_cite ltx_citemacro_citep">(Peng et al<span class="ltx_text">.</span>, <a href="#bib.bib69" title="" class="ltx_ref">2022</a>; Kang et al<span class="ltx_text">.</span>, <a href="#bib.bib35" title="" class="ltx_ref">2019</a>)</cite>.</p>
</div>
</li>
<li id="S1.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i5.p1" class="ltx_para">
<p id="S1.I1.i5.p1.1" class="ltx_p"><span id="S1.I1.i5.p1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Centralized Orchestration:</span> In “vanilla” FL, a single, central server is responsible for handling the entire federated training process. This scheme suffers from the same weaknesses as any other client-server architecture, e.g., single-point failure and man-in-the-middle attacks.
The present survey focuses exactly on this specific issue. In particular, we provide a comprehensive review of the most relevant works that attempt to overcome the limitations of centralized orchestration through <span id="S1.I1.i5.p1.1.2" class="ltx_text ltx_font_italic">decentralized</span> FL solutions. Moreover, we show how some of the methods designed to tackle this challenge may also be useful in solving some of the other problems listed above.</p>
</div>
</li>
</ul>
<p id="S1.p5.2" class="ltx_p">The remainder of this paper is organized as follows. In Section <a href="#S2" title="2. Background and Preliminaries ‣ A Survey on Decentralized Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, we recall some background and preliminary concepts.
Section <a href="#S3" title="3. Research Method ‣ A Survey on Decentralized Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> describes the methodology used to collect the set of most relevant works on decentralized FL proposed in the literature and considered in this survey. Specifically, we adopt the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) guidelines <cite class="ltx_cite ltx_citemacro_citep">(Page et al<span class="ltx_text">.</span>, <a href="#bib.bib66" title="" class="ltx_ref">2021</a>)</cite>.
We categorize and review these contributions in Section <a href="#S4" title="4. A Taxonomy of Decentralized FL Approaches ‣ A Survey on Decentralized Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.
Section <a href="#S5" title="5. Challenges of Decentralized FL ‣ A Survey on Decentralized Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> discusses the main challenges of decentralized FL.
We also sketch several interesting lines of future research on this subject in Section <a href="#S6" title="6. Future Directions ‣ A Survey on Decentralized Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>.
Finally, Section <a href="#S7" title="7. Conclusion ‣ A Survey on Decentralized Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> concludes our work.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Background and Preliminaries</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.3" class="ltx_p">In this section, we review some background and preliminary concepts utilized throughout this manuscript. Specifically, we cover three main topics: <math id="S2.p1.1.m1.1" class="ltx_Math" alttext="(i)" display="inline"><semantics id="S2.p1.1.m1.1a"><mrow id="S2.p1.1.m1.1.2.2"><mo stretchy="false" id="S2.p1.1.m1.1.2.2.1">(</mo><mi id="S2.p1.1.m1.1.1" xref="S2.p1.1.m1.1.1.cmml">i</mi><mo stretchy="false" id="S2.p1.1.m1.1.2.2.2">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.1.m1.1b"><ci id="S2.p1.1.m1.1.1.cmml" xref="S2.p1.1.m1.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.1.m1.1c">(i)</annotation></semantics></math> <span id="S2.p1.3.1" class="ltx_text ltx_font_italic">federated learning</span>, <math id="S2.p1.2.m2.1" class="ltx_Math" alttext="(ii)" display="inline"><semantics id="S2.p1.2.m2.1a"><mrow id="S2.p1.2.m2.1.1.1" xref="S2.p1.2.m2.1.1.1.1.cmml"><mo stretchy="false" id="S2.p1.2.m2.1.1.1.2" xref="S2.p1.2.m2.1.1.1.1.cmml">(</mo><mrow id="S2.p1.2.m2.1.1.1.1" xref="S2.p1.2.m2.1.1.1.1.cmml"><mi id="S2.p1.2.m2.1.1.1.1.2" xref="S2.p1.2.m2.1.1.1.1.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S2.p1.2.m2.1.1.1.1.1" xref="S2.p1.2.m2.1.1.1.1.1.cmml">​</mo><mi id="S2.p1.2.m2.1.1.1.1.3" xref="S2.p1.2.m2.1.1.1.1.3.cmml">i</mi></mrow><mo stretchy="false" id="S2.p1.2.m2.1.1.1.3" xref="S2.p1.2.m2.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.2.m2.1b"><apply id="S2.p1.2.m2.1.1.1.1.cmml" xref="S2.p1.2.m2.1.1.1"><times id="S2.p1.2.m2.1.1.1.1.1.cmml" xref="S2.p1.2.m2.1.1.1.1.1"></times><ci id="S2.p1.2.m2.1.1.1.1.2.cmml" xref="S2.p1.2.m2.1.1.1.1.2">𝑖</ci><ci id="S2.p1.2.m2.1.1.1.1.3.cmml" xref="S2.p1.2.m2.1.1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.2.m2.1c">(ii)</annotation></semantics></math> <span id="S2.p1.3.2" class="ltx_text ltx_font_italic">peer-to-peer systems</span> (P2P), and <math id="S2.p1.3.m3.1" class="ltx_Math" alttext="(iii)" display="inline"><semantics id="S2.p1.3.m3.1a"><mrow id="S2.p1.3.m3.1.1.1" xref="S2.p1.3.m3.1.1.1.1.cmml"><mo stretchy="false" id="S2.p1.3.m3.1.1.1.2" xref="S2.p1.3.m3.1.1.1.1.cmml">(</mo><mrow id="S2.p1.3.m3.1.1.1.1" xref="S2.p1.3.m3.1.1.1.1.cmml"><mi id="S2.p1.3.m3.1.1.1.1.2" xref="S2.p1.3.m3.1.1.1.1.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S2.p1.3.m3.1.1.1.1.1" xref="S2.p1.3.m3.1.1.1.1.1.cmml">​</mo><mi id="S2.p1.3.m3.1.1.1.1.3" xref="S2.p1.3.m3.1.1.1.1.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S2.p1.3.m3.1.1.1.1.1a" xref="S2.p1.3.m3.1.1.1.1.1.cmml">​</mo><mi id="S2.p1.3.m3.1.1.1.1.4" xref="S2.p1.3.m3.1.1.1.1.4.cmml">i</mi></mrow><mo stretchy="false" id="S2.p1.3.m3.1.1.1.3" xref="S2.p1.3.m3.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.3.m3.1b"><apply id="S2.p1.3.m3.1.1.1.1.cmml" xref="S2.p1.3.m3.1.1.1"><times id="S2.p1.3.m3.1.1.1.1.1.cmml" xref="S2.p1.3.m3.1.1.1.1.1"></times><ci id="S2.p1.3.m3.1.1.1.1.2.cmml" xref="S2.p1.3.m3.1.1.1.1.2">𝑖</ci><ci id="S2.p1.3.m3.1.1.1.1.3.cmml" xref="S2.p1.3.m3.1.1.1.1.3">𝑖</ci><ci id="S2.p1.3.m3.1.1.1.1.4.cmml" xref="S2.p1.3.m3.1.1.1.1.4">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.3.m3.1c">(iii)</annotation></semantics></math> <span id="S2.p1.3.3" class="ltx_text ltx_font_italic">Blockchain</span>.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1. </span>Federated Learning</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.7" class="ltx_p">The prototypical FL setting consists of a central server <math id="S2.SS1.p1.1.m1.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S2.SS1.p1.1.m1.1a"><mi id="S2.SS1.p1.1.m1.1.1" xref="S2.SS1.p1.1.m1.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.1.m1.1b"><ci id="S2.SS1.p1.1.m1.1.1.cmml" xref="S2.SS1.p1.1.m1.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.1.m1.1c">S</annotation></semantics></math> and a set of distributed clients <math id="S2.SS1.p1.2.m2.1" class="ltx_Math" alttext="\mathcal{C}" display="inline"><semantics id="S2.SS1.p1.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p1.2.m2.1.1" xref="S2.SS1.p1.2.m2.1.1.cmml">𝒞</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.2.m2.1b"><ci id="S2.SS1.p1.2.m2.1.1.cmml" xref="S2.SS1.p1.2.m2.1.1">𝒞</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.2.m2.1c">\mathcal{C}</annotation></semantics></math>, such that <math id="S2.SS1.p1.3.m3.1" class="ltx_Math" alttext="|\mathcal{C}|=K" display="inline"><semantics id="S2.SS1.p1.3.m3.1a"><mrow id="S2.SS1.p1.3.m3.1.2" xref="S2.SS1.p1.3.m3.1.2.cmml"><mrow id="S2.SS1.p1.3.m3.1.2.2.2" xref="S2.SS1.p1.3.m3.1.2.2.1.cmml"><mo stretchy="false" id="S2.SS1.p1.3.m3.1.2.2.2.1" xref="S2.SS1.p1.3.m3.1.2.2.1.1.cmml">|</mo><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p1.3.m3.1.1" xref="S2.SS1.p1.3.m3.1.1.cmml">𝒞</mi><mo stretchy="false" id="S2.SS1.p1.3.m3.1.2.2.2.2" xref="S2.SS1.p1.3.m3.1.2.2.1.1.cmml">|</mo></mrow><mo id="S2.SS1.p1.3.m3.1.2.1" xref="S2.SS1.p1.3.m3.1.2.1.cmml">=</mo><mi id="S2.SS1.p1.3.m3.1.2.3" xref="S2.SS1.p1.3.m3.1.2.3.cmml">K</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.3.m3.1b"><apply id="S2.SS1.p1.3.m3.1.2.cmml" xref="S2.SS1.p1.3.m3.1.2"><eq id="S2.SS1.p1.3.m3.1.2.1.cmml" xref="S2.SS1.p1.3.m3.1.2.1"></eq><apply id="S2.SS1.p1.3.m3.1.2.2.1.cmml" xref="S2.SS1.p1.3.m3.1.2.2.2"><abs id="S2.SS1.p1.3.m3.1.2.2.1.1.cmml" xref="S2.SS1.p1.3.m3.1.2.2.2.1"></abs><ci id="S2.SS1.p1.3.m3.1.1.cmml" xref="S2.SS1.p1.3.m3.1.1">𝒞</ci></apply><ci id="S2.SS1.p1.3.m3.1.2.3.cmml" xref="S2.SS1.p1.3.m3.1.2.3">𝐾</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.3.m3.1c">|\mathcal{C}|=K</annotation></semantics></math>, that jointly cooperate to solve a standard supervised learning task.<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>Notice that the FL paradigm can also be used to solve unsupervised learning tasks like K-means clustering <cite class="ltx_cite ltx_citemacro_citep">(Kumar et al<span class="ltx_text">.</span>, <a href="#bib.bib39" title="" class="ltx_ref">2020</a>)</cite>.</span></span></span>Each client <math id="S2.SS1.p1.4.m4.1" class="ltx_Math" alttext="c\in\mathcal{C}" display="inline"><semantics id="S2.SS1.p1.4.m4.1a"><mrow id="S2.SS1.p1.4.m4.1.1" xref="S2.SS1.p1.4.m4.1.1.cmml"><mi id="S2.SS1.p1.4.m4.1.1.2" xref="S2.SS1.p1.4.m4.1.1.2.cmml">c</mi><mo id="S2.SS1.p1.4.m4.1.1.1" xref="S2.SS1.p1.4.m4.1.1.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p1.4.m4.1.1.3" xref="S2.SS1.p1.4.m4.1.1.3.cmml">𝒞</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.4.m4.1b"><apply id="S2.SS1.p1.4.m4.1.1.cmml" xref="S2.SS1.p1.4.m4.1.1"><in id="S2.SS1.p1.4.m4.1.1.1.cmml" xref="S2.SS1.p1.4.m4.1.1.1"></in><ci id="S2.SS1.p1.4.m4.1.1.2.cmml" xref="S2.SS1.p1.4.m4.1.1.2">𝑐</ci><ci id="S2.SS1.p1.4.m4.1.1.3.cmml" xref="S2.SS1.p1.4.m4.1.1.3">𝒞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.4.m4.1c">c\in\mathcal{C}</annotation></semantics></math> has access to its own private training set <math id="S2.SS1.p1.5.m5.1" class="ltx_Math" alttext="\mathcal{D}_{c}" display="inline"><semantics id="S2.SS1.p1.5.m5.1a"><msub id="S2.SS1.p1.5.m5.1.1" xref="S2.SS1.p1.5.m5.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p1.5.m5.1.1.2" xref="S2.SS1.p1.5.m5.1.1.2.cmml">𝒟</mi><mi id="S2.SS1.p1.5.m5.1.1.3" xref="S2.SS1.p1.5.m5.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.5.m5.1b"><apply id="S2.SS1.p1.5.m5.1.1.cmml" xref="S2.SS1.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.5.m5.1.1.1.cmml" xref="S2.SS1.p1.5.m5.1.1">subscript</csymbol><ci id="S2.SS1.p1.5.m5.1.1.2.cmml" xref="S2.SS1.p1.5.m5.1.1.2">𝒟</ci><ci id="S2.SS1.p1.5.m5.1.1.3.cmml" xref="S2.SS1.p1.5.m5.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.5.m5.1c">\mathcal{D}_{c}</annotation></semantics></math>, namely the set of its <math id="S2.SS1.p1.6.m6.1" class="ltx_Math" alttext="n_{c}" display="inline"><semantics id="S2.SS1.p1.6.m6.1a"><msub id="S2.SS1.p1.6.m6.1.1" xref="S2.SS1.p1.6.m6.1.1.cmml"><mi id="S2.SS1.p1.6.m6.1.1.2" xref="S2.SS1.p1.6.m6.1.1.2.cmml">n</mi><mi id="S2.SS1.p1.6.m6.1.1.3" xref="S2.SS1.p1.6.m6.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.6.m6.1b"><apply id="S2.SS1.p1.6.m6.1.1.cmml" xref="S2.SS1.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.6.m6.1.1.1.cmml" xref="S2.SS1.p1.6.m6.1.1">subscript</csymbol><ci id="S2.SS1.p1.6.m6.1.1.2.cmml" xref="S2.SS1.p1.6.m6.1.1.2">𝑛</ci><ci id="S2.SS1.p1.6.m6.1.1.3.cmml" xref="S2.SS1.p1.6.m6.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.6.m6.1c">n_{c}</annotation></semantics></math> local labeled examples, i.e., <math id="S2.SS1.p1.7.m7.6" class="ltx_Math" alttext="\mathcal{D}_{c}=\{\bm{x}_{c,i},y_{c,i}\}_{i=1}^{n_{c}}" display="inline"><semantics id="S2.SS1.p1.7.m7.6a"><mrow id="S2.SS1.p1.7.m7.6.6" xref="S2.SS1.p1.7.m7.6.6.cmml"><msub id="S2.SS1.p1.7.m7.6.6.4" xref="S2.SS1.p1.7.m7.6.6.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p1.7.m7.6.6.4.2" xref="S2.SS1.p1.7.m7.6.6.4.2.cmml">𝒟</mi><mi id="S2.SS1.p1.7.m7.6.6.4.3" xref="S2.SS1.p1.7.m7.6.6.4.3.cmml">c</mi></msub><mo id="S2.SS1.p1.7.m7.6.6.3" xref="S2.SS1.p1.7.m7.6.6.3.cmml">=</mo><msubsup id="S2.SS1.p1.7.m7.6.6.2" xref="S2.SS1.p1.7.m7.6.6.2.cmml"><mrow id="S2.SS1.p1.7.m7.6.6.2.2.2.2" xref="S2.SS1.p1.7.m7.6.6.2.2.2.3.cmml"><mo stretchy="false" id="S2.SS1.p1.7.m7.6.6.2.2.2.2.3" xref="S2.SS1.p1.7.m7.6.6.2.2.2.3.cmml">{</mo><msub id="S2.SS1.p1.7.m7.5.5.1.1.1.1.1" xref="S2.SS1.p1.7.m7.5.5.1.1.1.1.1.cmml"><mi id="S2.SS1.p1.7.m7.5.5.1.1.1.1.1.2" xref="S2.SS1.p1.7.m7.5.5.1.1.1.1.1.2.cmml">𝒙</mi><mrow id="S2.SS1.p1.7.m7.2.2.2.4" xref="S2.SS1.p1.7.m7.2.2.2.3.cmml"><mi id="S2.SS1.p1.7.m7.1.1.1.1" xref="S2.SS1.p1.7.m7.1.1.1.1.cmml">c</mi><mo id="S2.SS1.p1.7.m7.2.2.2.4.1" xref="S2.SS1.p1.7.m7.2.2.2.3.cmml">,</mo><mi id="S2.SS1.p1.7.m7.2.2.2.2" xref="S2.SS1.p1.7.m7.2.2.2.2.cmml">i</mi></mrow></msub><mo id="S2.SS1.p1.7.m7.6.6.2.2.2.2.4" xref="S2.SS1.p1.7.m7.6.6.2.2.2.3.cmml">,</mo><msub id="S2.SS1.p1.7.m7.6.6.2.2.2.2.2" xref="S2.SS1.p1.7.m7.6.6.2.2.2.2.2.cmml"><mi id="S2.SS1.p1.7.m7.6.6.2.2.2.2.2.2" xref="S2.SS1.p1.7.m7.6.6.2.2.2.2.2.2.cmml">y</mi><mrow id="S2.SS1.p1.7.m7.4.4.2.4" xref="S2.SS1.p1.7.m7.4.4.2.3.cmml"><mi id="S2.SS1.p1.7.m7.3.3.1.1" xref="S2.SS1.p1.7.m7.3.3.1.1.cmml">c</mi><mo id="S2.SS1.p1.7.m7.4.4.2.4.1" xref="S2.SS1.p1.7.m7.4.4.2.3.cmml">,</mo><mi id="S2.SS1.p1.7.m7.4.4.2.2" xref="S2.SS1.p1.7.m7.4.4.2.2.cmml">i</mi></mrow></msub><mo stretchy="false" id="S2.SS1.p1.7.m7.6.6.2.2.2.2.5" xref="S2.SS1.p1.7.m7.6.6.2.2.2.3.cmml">}</mo></mrow><mrow id="S2.SS1.p1.7.m7.6.6.2.2.4" xref="S2.SS1.p1.7.m7.6.6.2.2.4.cmml"><mi id="S2.SS1.p1.7.m7.6.6.2.2.4.2" xref="S2.SS1.p1.7.m7.6.6.2.2.4.2.cmml">i</mi><mo id="S2.SS1.p1.7.m7.6.6.2.2.4.1" xref="S2.SS1.p1.7.m7.6.6.2.2.4.1.cmml">=</mo><mn id="S2.SS1.p1.7.m7.6.6.2.2.4.3" xref="S2.SS1.p1.7.m7.6.6.2.2.4.3.cmml">1</mn></mrow><msub id="S2.SS1.p1.7.m7.6.6.2.4" xref="S2.SS1.p1.7.m7.6.6.2.4.cmml"><mi id="S2.SS1.p1.7.m7.6.6.2.4.2" xref="S2.SS1.p1.7.m7.6.6.2.4.2.cmml">n</mi><mi id="S2.SS1.p1.7.m7.6.6.2.4.3" xref="S2.SS1.p1.7.m7.6.6.2.4.3.cmml">c</mi></msub></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.7.m7.6b"><apply id="S2.SS1.p1.7.m7.6.6.cmml" xref="S2.SS1.p1.7.m7.6.6"><eq id="S2.SS1.p1.7.m7.6.6.3.cmml" xref="S2.SS1.p1.7.m7.6.6.3"></eq><apply id="S2.SS1.p1.7.m7.6.6.4.cmml" xref="S2.SS1.p1.7.m7.6.6.4"><csymbol cd="ambiguous" id="S2.SS1.p1.7.m7.6.6.4.1.cmml" xref="S2.SS1.p1.7.m7.6.6.4">subscript</csymbol><ci id="S2.SS1.p1.7.m7.6.6.4.2.cmml" xref="S2.SS1.p1.7.m7.6.6.4.2">𝒟</ci><ci id="S2.SS1.p1.7.m7.6.6.4.3.cmml" xref="S2.SS1.p1.7.m7.6.6.4.3">𝑐</ci></apply><apply id="S2.SS1.p1.7.m7.6.6.2.cmml" xref="S2.SS1.p1.7.m7.6.6.2"><csymbol cd="ambiguous" id="S2.SS1.p1.7.m7.6.6.2.3.cmml" xref="S2.SS1.p1.7.m7.6.6.2">superscript</csymbol><apply id="S2.SS1.p1.7.m7.6.6.2.2.cmml" xref="S2.SS1.p1.7.m7.6.6.2"><csymbol cd="ambiguous" id="S2.SS1.p1.7.m7.6.6.2.2.3.cmml" xref="S2.SS1.p1.7.m7.6.6.2">subscript</csymbol><set id="S2.SS1.p1.7.m7.6.6.2.2.2.3.cmml" xref="S2.SS1.p1.7.m7.6.6.2.2.2.2"><apply id="S2.SS1.p1.7.m7.5.5.1.1.1.1.1.cmml" xref="S2.SS1.p1.7.m7.5.5.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.7.m7.5.5.1.1.1.1.1.1.cmml" xref="S2.SS1.p1.7.m7.5.5.1.1.1.1.1">subscript</csymbol><ci id="S2.SS1.p1.7.m7.5.5.1.1.1.1.1.2.cmml" xref="S2.SS1.p1.7.m7.5.5.1.1.1.1.1.2">𝒙</ci><list id="S2.SS1.p1.7.m7.2.2.2.3.cmml" xref="S2.SS1.p1.7.m7.2.2.2.4"><ci id="S2.SS1.p1.7.m7.1.1.1.1.cmml" xref="S2.SS1.p1.7.m7.1.1.1.1">𝑐</ci><ci id="S2.SS1.p1.7.m7.2.2.2.2.cmml" xref="S2.SS1.p1.7.m7.2.2.2.2">𝑖</ci></list></apply><apply id="S2.SS1.p1.7.m7.6.6.2.2.2.2.2.cmml" xref="S2.SS1.p1.7.m7.6.6.2.2.2.2.2"><csymbol cd="ambiguous" id="S2.SS1.p1.7.m7.6.6.2.2.2.2.2.1.cmml" xref="S2.SS1.p1.7.m7.6.6.2.2.2.2.2">subscript</csymbol><ci id="S2.SS1.p1.7.m7.6.6.2.2.2.2.2.2.cmml" xref="S2.SS1.p1.7.m7.6.6.2.2.2.2.2.2">𝑦</ci><list id="S2.SS1.p1.7.m7.4.4.2.3.cmml" xref="S2.SS1.p1.7.m7.4.4.2.4"><ci id="S2.SS1.p1.7.m7.3.3.1.1.cmml" xref="S2.SS1.p1.7.m7.3.3.1.1">𝑐</ci><ci id="S2.SS1.p1.7.m7.4.4.2.2.cmml" xref="S2.SS1.p1.7.m7.4.4.2.2">𝑖</ci></list></apply></set><apply id="S2.SS1.p1.7.m7.6.6.2.2.4.cmml" xref="S2.SS1.p1.7.m7.6.6.2.2.4"><eq id="S2.SS1.p1.7.m7.6.6.2.2.4.1.cmml" xref="S2.SS1.p1.7.m7.6.6.2.2.4.1"></eq><ci id="S2.SS1.p1.7.m7.6.6.2.2.4.2.cmml" xref="S2.SS1.p1.7.m7.6.6.2.2.4.2">𝑖</ci><cn type="integer" id="S2.SS1.p1.7.m7.6.6.2.2.4.3.cmml" xref="S2.SS1.p1.7.m7.6.6.2.2.4.3">1</cn></apply></apply><apply id="S2.SS1.p1.7.m7.6.6.2.4.cmml" xref="S2.SS1.p1.7.m7.6.6.2.4"><csymbol cd="ambiguous" id="S2.SS1.p1.7.m7.6.6.2.4.1.cmml" xref="S2.SS1.p1.7.m7.6.6.2.4">subscript</csymbol><ci id="S2.SS1.p1.7.m7.6.6.2.4.2.cmml" xref="S2.SS1.p1.7.m7.6.6.2.4.2">𝑛</ci><ci id="S2.SS1.p1.7.m7.6.6.2.4.3.cmml" xref="S2.SS1.p1.7.m7.6.6.2.4.3">𝑐</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.7.m7.6c">\mathcal{D}_{c}=\{\bm{x}_{c,i},y_{c,i}\}_{i=1}^{n_{c}}</annotation></semantics></math>.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">The goal of FL is to train a global predictive model whose architecture and parameters <math id="S2.SS1.p2.1.m1.1" class="ltx_Math" alttext="\bm{\theta}^{*}\in\mathbb{R}^{d}" display="inline"><semantics id="S2.SS1.p2.1.m1.1a"><mrow id="S2.SS1.p2.1.m1.1.1" xref="S2.SS1.p2.1.m1.1.1.cmml"><msup id="S2.SS1.p2.1.m1.1.1.2" xref="S2.SS1.p2.1.m1.1.1.2.cmml"><mi id="S2.SS1.p2.1.m1.1.1.2.2" xref="S2.SS1.p2.1.m1.1.1.2.2.cmml">𝜽</mi><mo id="S2.SS1.p2.1.m1.1.1.2.3" xref="S2.SS1.p2.1.m1.1.1.2.3.cmml">∗</mo></msup><mo id="S2.SS1.p2.1.m1.1.1.1" xref="S2.SS1.p2.1.m1.1.1.1.cmml">∈</mo><msup id="S2.SS1.p2.1.m1.1.1.3" xref="S2.SS1.p2.1.m1.1.1.3.cmml"><mi id="S2.SS1.p2.1.m1.1.1.3.2" xref="S2.SS1.p2.1.m1.1.1.3.2.cmml">ℝ</mi><mi id="S2.SS1.p2.1.m1.1.1.3.3" xref="S2.SS1.p2.1.m1.1.1.3.3.cmml">d</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.1.m1.1b"><apply id="S2.SS1.p2.1.m1.1.1.cmml" xref="S2.SS1.p2.1.m1.1.1"><in id="S2.SS1.p2.1.m1.1.1.1.cmml" xref="S2.SS1.p2.1.m1.1.1.1"></in><apply id="S2.SS1.p2.1.m1.1.1.2.cmml" xref="S2.SS1.p2.1.m1.1.1.2"><csymbol cd="ambiguous" id="S2.SS1.p2.1.m1.1.1.2.1.cmml" xref="S2.SS1.p2.1.m1.1.1.2">superscript</csymbol><ci id="S2.SS1.p2.1.m1.1.1.2.2.cmml" xref="S2.SS1.p2.1.m1.1.1.2.2">𝜽</ci><times id="S2.SS1.p2.1.m1.1.1.2.3.cmml" xref="S2.SS1.p2.1.m1.1.1.2.3"></times></apply><apply id="S2.SS1.p2.1.m1.1.1.3.cmml" xref="S2.SS1.p2.1.m1.1.1.3"><csymbol cd="ambiguous" id="S2.SS1.p2.1.m1.1.1.3.1.cmml" xref="S2.SS1.p2.1.m1.1.1.3">superscript</csymbol><ci id="S2.SS1.p2.1.m1.1.1.3.2.cmml" xref="S2.SS1.p2.1.m1.1.1.3.2">ℝ</ci><ci id="S2.SS1.p2.1.m1.1.1.3.3.cmml" xref="S2.SS1.p2.1.m1.1.1.3.3">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.1.m1.1c">\bm{\theta}^{*}\in\mathbb{R}^{d}</annotation></semantics></math> are shared amongst all the clients and found to solve the following objective:</p>
<table id="S2.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(1)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E1.m1.3" class="ltx_Math" alttext="\bm{\theta}^{*}=\text{argmin}_{\bm{\theta}}\mathcal{L}(\bm{\theta})=\text{argmin}_{\bm{\theta}}\sum_{c=1}^{K}p_{c}\mathcal{L}_{c}(\bm{\theta};\mathcal{D}_{c})," display="block"><semantics id="S2.E1.m1.3a"><mrow id="S2.E1.m1.3.3.1" xref="S2.E1.m1.3.3.1.1.cmml"><mrow id="S2.E1.m1.3.3.1.1" xref="S2.E1.m1.3.3.1.1.cmml"><msup id="S2.E1.m1.3.3.1.1.3" xref="S2.E1.m1.3.3.1.1.3.cmml"><mi id="S2.E1.m1.3.3.1.1.3.2" xref="S2.E1.m1.3.3.1.1.3.2.cmml">𝜽</mi><mo id="S2.E1.m1.3.3.1.1.3.3" xref="S2.E1.m1.3.3.1.1.3.3.cmml">∗</mo></msup><mo id="S2.E1.m1.3.3.1.1.4" xref="S2.E1.m1.3.3.1.1.4.cmml">=</mo><mrow id="S2.E1.m1.3.3.1.1.5" xref="S2.E1.m1.3.3.1.1.5.cmml"><msub id="S2.E1.m1.3.3.1.1.5.2" xref="S2.E1.m1.3.3.1.1.5.2.cmml"><mtext id="S2.E1.m1.3.3.1.1.5.2.2" xref="S2.E1.m1.3.3.1.1.5.2.2a.cmml">argmin</mtext><mi id="S2.E1.m1.3.3.1.1.5.2.3" xref="S2.E1.m1.3.3.1.1.5.2.3.cmml">𝜽</mi></msub><mo lspace="0em" rspace="0em" id="S2.E1.m1.3.3.1.1.5.1" xref="S2.E1.m1.3.3.1.1.5.1.cmml">​</mo><mi class="ltx_font_mathcaligraphic" id="S2.E1.m1.3.3.1.1.5.3" xref="S2.E1.m1.3.3.1.1.5.3.cmml">ℒ</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.3.3.1.1.5.1a" xref="S2.E1.m1.3.3.1.1.5.1.cmml">​</mo><mrow id="S2.E1.m1.3.3.1.1.5.4.2" xref="S2.E1.m1.3.3.1.1.5.cmml"><mo stretchy="false" id="S2.E1.m1.3.3.1.1.5.4.2.1" xref="S2.E1.m1.3.3.1.1.5.cmml">(</mo><mi id="S2.E1.m1.1.1" xref="S2.E1.m1.1.1.cmml">𝜽</mi><mo stretchy="false" id="S2.E1.m1.3.3.1.1.5.4.2.2" xref="S2.E1.m1.3.3.1.1.5.cmml">)</mo></mrow></mrow><mo id="S2.E1.m1.3.3.1.1.6" xref="S2.E1.m1.3.3.1.1.6.cmml">=</mo><mrow id="S2.E1.m1.3.3.1.1.1" xref="S2.E1.m1.3.3.1.1.1.cmml"><msub id="S2.E1.m1.3.3.1.1.1.3" xref="S2.E1.m1.3.3.1.1.1.3.cmml"><mtext id="S2.E1.m1.3.3.1.1.1.3.2" xref="S2.E1.m1.3.3.1.1.1.3.2a.cmml">argmin</mtext><mi id="S2.E1.m1.3.3.1.1.1.3.3" xref="S2.E1.m1.3.3.1.1.1.3.3.cmml">𝜽</mi></msub><mo lspace="0em" rspace="0em" id="S2.E1.m1.3.3.1.1.1.2" xref="S2.E1.m1.3.3.1.1.1.2.cmml">​</mo><mrow id="S2.E1.m1.3.3.1.1.1.1" xref="S2.E1.m1.3.3.1.1.1.1.cmml"><munderover id="S2.E1.m1.3.3.1.1.1.1.2" xref="S2.E1.m1.3.3.1.1.1.1.2.cmml"><mo movablelimits="false" id="S2.E1.m1.3.3.1.1.1.1.2.2.2" xref="S2.E1.m1.3.3.1.1.1.1.2.2.2.cmml">∑</mo><mrow id="S2.E1.m1.3.3.1.1.1.1.2.2.3" xref="S2.E1.m1.3.3.1.1.1.1.2.2.3.cmml"><mi id="S2.E1.m1.3.3.1.1.1.1.2.2.3.2" xref="S2.E1.m1.3.3.1.1.1.1.2.2.3.2.cmml">c</mi><mo id="S2.E1.m1.3.3.1.1.1.1.2.2.3.1" xref="S2.E1.m1.3.3.1.1.1.1.2.2.3.1.cmml">=</mo><mn id="S2.E1.m1.3.3.1.1.1.1.2.2.3.3" xref="S2.E1.m1.3.3.1.1.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S2.E1.m1.3.3.1.1.1.1.2.3" xref="S2.E1.m1.3.3.1.1.1.1.2.3.cmml">K</mi></munderover><mrow id="S2.E1.m1.3.3.1.1.1.1.1" xref="S2.E1.m1.3.3.1.1.1.1.1.cmml"><msub id="S2.E1.m1.3.3.1.1.1.1.1.3" xref="S2.E1.m1.3.3.1.1.1.1.1.3.cmml"><mi id="S2.E1.m1.3.3.1.1.1.1.1.3.2" xref="S2.E1.m1.3.3.1.1.1.1.1.3.2.cmml">p</mi><mi id="S2.E1.m1.3.3.1.1.1.1.1.3.3" xref="S2.E1.m1.3.3.1.1.1.1.1.3.3.cmml">c</mi></msub><mo lspace="0em" rspace="0em" id="S2.E1.m1.3.3.1.1.1.1.1.2" xref="S2.E1.m1.3.3.1.1.1.1.1.2.cmml">​</mo><msub id="S2.E1.m1.3.3.1.1.1.1.1.4" xref="S2.E1.m1.3.3.1.1.1.1.1.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E1.m1.3.3.1.1.1.1.1.4.2" xref="S2.E1.m1.3.3.1.1.1.1.1.4.2.cmml">ℒ</mi><mi id="S2.E1.m1.3.3.1.1.1.1.1.4.3" xref="S2.E1.m1.3.3.1.1.1.1.1.4.3.cmml">c</mi></msub><mo lspace="0em" rspace="0em" id="S2.E1.m1.3.3.1.1.1.1.1.2a" xref="S2.E1.m1.3.3.1.1.1.1.1.2.cmml">​</mo><mrow id="S2.E1.m1.3.3.1.1.1.1.1.1.1" xref="S2.E1.m1.3.3.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S2.E1.m1.3.3.1.1.1.1.1.1.1.2" xref="S2.E1.m1.3.3.1.1.1.1.1.1.2.cmml">(</mo><mi id="S2.E1.m1.2.2" xref="S2.E1.m1.2.2.cmml">𝜽</mi><mo id="S2.E1.m1.3.3.1.1.1.1.1.1.1.3" xref="S2.E1.m1.3.3.1.1.1.1.1.1.2.cmml">;</mo><msub id="S2.E1.m1.3.3.1.1.1.1.1.1.1.1" xref="S2.E1.m1.3.3.1.1.1.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E1.m1.3.3.1.1.1.1.1.1.1.1.2" xref="S2.E1.m1.3.3.1.1.1.1.1.1.1.1.2.cmml">𝒟</mi><mi id="S2.E1.m1.3.3.1.1.1.1.1.1.1.1.3" xref="S2.E1.m1.3.3.1.1.1.1.1.1.1.1.3.cmml">c</mi></msub><mo stretchy="false" id="S2.E1.m1.3.3.1.1.1.1.1.1.1.4" xref="S2.E1.m1.3.3.1.1.1.1.1.1.2.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><mo id="S2.E1.m1.3.3.1.2" xref="S2.E1.m1.3.3.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.3b"><apply id="S2.E1.m1.3.3.1.1.cmml" xref="S2.E1.m1.3.3.1"><and id="S2.E1.m1.3.3.1.1a.cmml" xref="S2.E1.m1.3.3.1"></and><apply id="S2.E1.m1.3.3.1.1b.cmml" xref="S2.E1.m1.3.3.1"><eq id="S2.E1.m1.3.3.1.1.4.cmml" xref="S2.E1.m1.3.3.1.1.4"></eq><apply id="S2.E1.m1.3.3.1.1.3.cmml" xref="S2.E1.m1.3.3.1.1.3"><csymbol cd="ambiguous" id="S2.E1.m1.3.3.1.1.3.1.cmml" xref="S2.E1.m1.3.3.1.1.3">superscript</csymbol><ci id="S2.E1.m1.3.3.1.1.3.2.cmml" xref="S2.E1.m1.3.3.1.1.3.2">𝜽</ci><times id="S2.E1.m1.3.3.1.1.3.3.cmml" xref="S2.E1.m1.3.3.1.1.3.3"></times></apply><apply id="S2.E1.m1.3.3.1.1.5.cmml" xref="S2.E1.m1.3.3.1.1.5"><times id="S2.E1.m1.3.3.1.1.5.1.cmml" xref="S2.E1.m1.3.3.1.1.5.1"></times><apply id="S2.E1.m1.3.3.1.1.5.2.cmml" xref="S2.E1.m1.3.3.1.1.5.2"><csymbol cd="ambiguous" id="S2.E1.m1.3.3.1.1.5.2.1.cmml" xref="S2.E1.m1.3.3.1.1.5.2">subscript</csymbol><ci id="S2.E1.m1.3.3.1.1.5.2.2a.cmml" xref="S2.E1.m1.3.3.1.1.5.2.2"><mtext id="S2.E1.m1.3.3.1.1.5.2.2.cmml" xref="S2.E1.m1.3.3.1.1.5.2.2">argmin</mtext></ci><ci id="S2.E1.m1.3.3.1.1.5.2.3.cmml" xref="S2.E1.m1.3.3.1.1.5.2.3">𝜽</ci></apply><ci id="S2.E1.m1.3.3.1.1.5.3.cmml" xref="S2.E1.m1.3.3.1.1.5.3">ℒ</ci><ci id="S2.E1.m1.1.1.cmml" xref="S2.E1.m1.1.1">𝜽</ci></apply></apply><apply id="S2.E1.m1.3.3.1.1c.cmml" xref="S2.E1.m1.3.3.1"><eq id="S2.E1.m1.3.3.1.1.6.cmml" xref="S2.E1.m1.3.3.1.1.6"></eq><share href="#S2.E1.m1.3.3.1.1.5.cmml" id="S2.E1.m1.3.3.1.1d.cmml" xref="S2.E1.m1.3.3.1"></share><apply id="S2.E1.m1.3.3.1.1.1.cmml" xref="S2.E1.m1.3.3.1.1.1"><times id="S2.E1.m1.3.3.1.1.1.2.cmml" xref="S2.E1.m1.3.3.1.1.1.2"></times><apply id="S2.E1.m1.3.3.1.1.1.3.cmml" xref="S2.E1.m1.3.3.1.1.1.3"><csymbol cd="ambiguous" id="S2.E1.m1.3.3.1.1.1.3.1.cmml" xref="S2.E1.m1.3.3.1.1.1.3">subscript</csymbol><ci id="S2.E1.m1.3.3.1.1.1.3.2a.cmml" xref="S2.E1.m1.3.3.1.1.1.3.2"><mtext id="S2.E1.m1.3.3.1.1.1.3.2.cmml" xref="S2.E1.m1.3.3.1.1.1.3.2">argmin</mtext></ci><ci id="S2.E1.m1.3.3.1.1.1.3.3.cmml" xref="S2.E1.m1.3.3.1.1.1.3.3">𝜽</ci></apply><apply id="S2.E1.m1.3.3.1.1.1.1.cmml" xref="S2.E1.m1.3.3.1.1.1.1"><apply id="S2.E1.m1.3.3.1.1.1.1.2.cmml" xref="S2.E1.m1.3.3.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.E1.m1.3.3.1.1.1.1.2.1.cmml" xref="S2.E1.m1.3.3.1.1.1.1.2">superscript</csymbol><apply id="S2.E1.m1.3.3.1.1.1.1.2.2.cmml" xref="S2.E1.m1.3.3.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.E1.m1.3.3.1.1.1.1.2.2.1.cmml" xref="S2.E1.m1.3.3.1.1.1.1.2">subscript</csymbol><sum id="S2.E1.m1.3.3.1.1.1.1.2.2.2.cmml" xref="S2.E1.m1.3.3.1.1.1.1.2.2.2"></sum><apply id="S2.E1.m1.3.3.1.1.1.1.2.2.3.cmml" xref="S2.E1.m1.3.3.1.1.1.1.2.2.3"><eq id="S2.E1.m1.3.3.1.1.1.1.2.2.3.1.cmml" xref="S2.E1.m1.3.3.1.1.1.1.2.2.3.1"></eq><ci id="S2.E1.m1.3.3.1.1.1.1.2.2.3.2.cmml" xref="S2.E1.m1.3.3.1.1.1.1.2.2.3.2">𝑐</ci><cn type="integer" id="S2.E1.m1.3.3.1.1.1.1.2.2.3.3.cmml" xref="S2.E1.m1.3.3.1.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="S2.E1.m1.3.3.1.1.1.1.2.3.cmml" xref="S2.E1.m1.3.3.1.1.1.1.2.3">𝐾</ci></apply><apply id="S2.E1.m1.3.3.1.1.1.1.1.cmml" xref="S2.E1.m1.3.3.1.1.1.1.1"><times id="S2.E1.m1.3.3.1.1.1.1.1.2.cmml" xref="S2.E1.m1.3.3.1.1.1.1.1.2"></times><apply id="S2.E1.m1.3.3.1.1.1.1.1.3.cmml" xref="S2.E1.m1.3.3.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E1.m1.3.3.1.1.1.1.1.3.1.cmml" xref="S2.E1.m1.3.3.1.1.1.1.1.3">subscript</csymbol><ci id="S2.E1.m1.3.3.1.1.1.1.1.3.2.cmml" xref="S2.E1.m1.3.3.1.1.1.1.1.3.2">𝑝</ci><ci id="S2.E1.m1.3.3.1.1.1.1.1.3.3.cmml" xref="S2.E1.m1.3.3.1.1.1.1.1.3.3">𝑐</ci></apply><apply id="S2.E1.m1.3.3.1.1.1.1.1.4.cmml" xref="S2.E1.m1.3.3.1.1.1.1.1.4"><csymbol cd="ambiguous" id="S2.E1.m1.3.3.1.1.1.1.1.4.1.cmml" xref="S2.E1.m1.3.3.1.1.1.1.1.4">subscript</csymbol><ci id="S2.E1.m1.3.3.1.1.1.1.1.4.2.cmml" xref="S2.E1.m1.3.3.1.1.1.1.1.4.2">ℒ</ci><ci id="S2.E1.m1.3.3.1.1.1.1.1.4.3.cmml" xref="S2.E1.m1.3.3.1.1.1.1.1.4.3">𝑐</ci></apply><list id="S2.E1.m1.3.3.1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.3.3.1.1.1.1.1.1.1"><ci id="S2.E1.m1.2.2.cmml" xref="S2.E1.m1.2.2">𝜽</ci><apply id="S2.E1.m1.3.3.1.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.3.3.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E1.m1.3.3.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.3.3.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.E1.m1.3.3.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.3.3.1.1.1.1.1.1.1.1.2">𝒟</ci><ci id="S2.E1.m1.3.3.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E1.m1.3.3.1.1.1.1.1.1.1.1.3">𝑐</ci></apply></list></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.3c">\bm{\theta}^{*}=\text{argmin}_{\bm{\theta}}\mathcal{L}(\bm{\theta})=\text{argmin}_{\bm{\theta}}\sum_{c=1}^{K}p_{c}\mathcal{L}_{c}(\bm{\theta};\mathcal{D}_{c}),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S2.SS1.p2.4" class="ltx_p">where <math id="S2.SS1.p2.2.m1.1" class="ltx_Math" alttext="\mathcal{L}_{c}" display="inline"><semantics id="S2.SS1.p2.2.m1.1a"><msub id="S2.SS1.p2.2.m1.1.1" xref="S2.SS1.p2.2.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p2.2.m1.1.1.2" xref="S2.SS1.p2.2.m1.1.1.2.cmml">ℒ</mi><mi id="S2.SS1.p2.2.m1.1.1.3" xref="S2.SS1.p2.2.m1.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.2.m1.1b"><apply id="S2.SS1.p2.2.m1.1.1.cmml" xref="S2.SS1.p2.2.m1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.2.m1.1.1.1.cmml" xref="S2.SS1.p2.2.m1.1.1">subscript</csymbol><ci id="S2.SS1.p2.2.m1.1.1.2.cmml" xref="S2.SS1.p2.2.m1.1.1.2">ℒ</ci><ci id="S2.SS1.p2.2.m1.1.1.3.cmml" xref="S2.SS1.p2.2.m1.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.2.m1.1c">\mathcal{L}_{c}</annotation></semantics></math> is the local objective function for client <math id="S2.SS1.p2.3.m2.1" class="ltx_Math" alttext="c" display="inline"><semantics id="S2.SS1.p2.3.m2.1a"><mi id="S2.SS1.p2.3.m2.1.1" xref="S2.SS1.p2.3.m2.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.3.m2.1b"><ci id="S2.SS1.p2.3.m2.1.1.cmml" xref="S2.SS1.p2.3.m2.1.1">𝑐</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.3.m2.1c">c</annotation></semantics></math>. Usually, this is defined as the empirical risk calculated over the training set <math id="S2.SS1.p2.4.m3.1" class="ltx_Math" alttext="\mathcal{D}_{c}" display="inline"><semantics id="S2.SS1.p2.4.m3.1a"><msub id="S2.SS1.p2.4.m3.1.1" xref="S2.SS1.p2.4.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p2.4.m3.1.1.2" xref="S2.SS1.p2.4.m3.1.1.2.cmml">𝒟</mi><mi id="S2.SS1.p2.4.m3.1.1.3" xref="S2.SS1.p2.4.m3.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.4.m3.1b"><apply id="S2.SS1.p2.4.m3.1.1.cmml" xref="S2.SS1.p2.4.m3.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.4.m3.1.1.1.cmml" xref="S2.SS1.p2.4.m3.1.1">subscript</csymbol><ci id="S2.SS1.p2.4.m3.1.1.2.cmml" xref="S2.SS1.p2.4.m3.1.1.2">𝒟</ci><ci id="S2.SS1.p2.4.m3.1.1.3.cmml" xref="S2.SS1.p2.4.m3.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.4.m3.1c">\mathcal{D}_{c}</annotation></semantics></math> sampled from the client’s local data distribution:</p>
<table id="S2.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(2)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E2.m1.7" class="ltx_Math" alttext="\mathcal{L}_{c}(\bm{\theta};\mathcal{D}_{c})=\frac{1}{n_{c}}\sum_{i=1}^{n_{c}}\ell(\bm{\theta};(\bm{x}_{c,i},y_{c,i}))," display="block"><semantics id="S2.E2.m1.7a"><mrow id="S2.E2.m1.7.7.1" xref="S2.E2.m1.7.7.1.1.cmml"><mrow id="S2.E2.m1.7.7.1.1" xref="S2.E2.m1.7.7.1.1.cmml"><mrow id="S2.E2.m1.7.7.1.1.1" xref="S2.E2.m1.7.7.1.1.1.cmml"><msub id="S2.E2.m1.7.7.1.1.1.3" xref="S2.E2.m1.7.7.1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E2.m1.7.7.1.1.1.3.2" xref="S2.E2.m1.7.7.1.1.1.3.2.cmml">ℒ</mi><mi id="S2.E2.m1.7.7.1.1.1.3.3" xref="S2.E2.m1.7.7.1.1.1.3.3.cmml">c</mi></msub><mo lspace="0em" rspace="0em" id="S2.E2.m1.7.7.1.1.1.2" xref="S2.E2.m1.7.7.1.1.1.2.cmml">​</mo><mrow id="S2.E2.m1.7.7.1.1.1.1.1" xref="S2.E2.m1.7.7.1.1.1.1.2.cmml"><mo stretchy="false" id="S2.E2.m1.7.7.1.1.1.1.1.2" xref="S2.E2.m1.7.7.1.1.1.1.2.cmml">(</mo><mi id="S2.E2.m1.5.5" xref="S2.E2.m1.5.5.cmml">𝜽</mi><mo id="S2.E2.m1.7.7.1.1.1.1.1.3" xref="S2.E2.m1.7.7.1.1.1.1.2.cmml">;</mo><msub id="S2.E2.m1.7.7.1.1.1.1.1.1" xref="S2.E2.m1.7.7.1.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E2.m1.7.7.1.1.1.1.1.1.2" xref="S2.E2.m1.7.7.1.1.1.1.1.1.2.cmml">𝒟</mi><mi id="S2.E2.m1.7.7.1.1.1.1.1.1.3" xref="S2.E2.m1.7.7.1.1.1.1.1.1.3.cmml">c</mi></msub><mo stretchy="false" id="S2.E2.m1.7.7.1.1.1.1.1.4" xref="S2.E2.m1.7.7.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S2.E2.m1.7.7.1.1.3" xref="S2.E2.m1.7.7.1.1.3.cmml">=</mo><mrow id="S2.E2.m1.7.7.1.1.2" xref="S2.E2.m1.7.7.1.1.2.cmml"><mfrac id="S2.E2.m1.7.7.1.1.2.3" xref="S2.E2.m1.7.7.1.1.2.3.cmml"><mn id="S2.E2.m1.7.7.1.1.2.3.2" xref="S2.E2.m1.7.7.1.1.2.3.2.cmml">1</mn><msub id="S2.E2.m1.7.7.1.1.2.3.3" xref="S2.E2.m1.7.7.1.1.2.3.3.cmml"><mi id="S2.E2.m1.7.7.1.1.2.3.3.2" xref="S2.E2.m1.7.7.1.1.2.3.3.2.cmml">n</mi><mi id="S2.E2.m1.7.7.1.1.2.3.3.3" xref="S2.E2.m1.7.7.1.1.2.3.3.3.cmml">c</mi></msub></mfrac><mo lspace="0em" rspace="0em" id="S2.E2.m1.7.7.1.1.2.2" xref="S2.E2.m1.7.7.1.1.2.2.cmml">​</mo><mrow id="S2.E2.m1.7.7.1.1.2.1" xref="S2.E2.m1.7.7.1.1.2.1.cmml"><munderover id="S2.E2.m1.7.7.1.1.2.1.2" xref="S2.E2.m1.7.7.1.1.2.1.2.cmml"><mo movablelimits="false" id="S2.E2.m1.7.7.1.1.2.1.2.2.2" xref="S2.E2.m1.7.7.1.1.2.1.2.2.2.cmml">∑</mo><mrow id="S2.E2.m1.7.7.1.1.2.1.2.2.3" xref="S2.E2.m1.7.7.1.1.2.1.2.2.3.cmml"><mi id="S2.E2.m1.7.7.1.1.2.1.2.2.3.2" xref="S2.E2.m1.7.7.1.1.2.1.2.2.3.2.cmml">i</mi><mo id="S2.E2.m1.7.7.1.1.2.1.2.2.3.1" xref="S2.E2.m1.7.7.1.1.2.1.2.2.3.1.cmml">=</mo><mn id="S2.E2.m1.7.7.1.1.2.1.2.2.3.3" xref="S2.E2.m1.7.7.1.1.2.1.2.2.3.3.cmml">1</mn></mrow><msub id="S2.E2.m1.7.7.1.1.2.1.2.3" xref="S2.E2.m1.7.7.1.1.2.1.2.3.cmml"><mi id="S2.E2.m1.7.7.1.1.2.1.2.3.2" xref="S2.E2.m1.7.7.1.1.2.1.2.3.2.cmml">n</mi><mi id="S2.E2.m1.7.7.1.1.2.1.2.3.3" xref="S2.E2.m1.7.7.1.1.2.1.2.3.3.cmml">c</mi></msub></munderover><mrow id="S2.E2.m1.7.7.1.1.2.1.1" xref="S2.E2.m1.7.7.1.1.2.1.1.cmml"><mi mathvariant="normal" id="S2.E2.m1.7.7.1.1.2.1.1.3" xref="S2.E2.m1.7.7.1.1.2.1.1.3.cmml">ℓ</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.7.7.1.1.2.1.1.2" xref="S2.E2.m1.7.7.1.1.2.1.1.2.cmml">​</mo><mrow id="S2.E2.m1.7.7.1.1.2.1.1.1.1" xref="S2.E2.m1.7.7.1.1.2.1.1.1.2.cmml"><mo stretchy="false" id="S2.E2.m1.7.7.1.1.2.1.1.1.1.2" xref="S2.E2.m1.7.7.1.1.2.1.1.1.2.cmml">(</mo><mi id="S2.E2.m1.6.6" xref="S2.E2.m1.6.6.cmml">𝜽</mi><mo id="S2.E2.m1.7.7.1.1.2.1.1.1.1.3" xref="S2.E2.m1.7.7.1.1.2.1.1.1.2.cmml">;</mo><mrow id="S2.E2.m1.7.7.1.1.2.1.1.1.1.1.2" xref="S2.E2.m1.7.7.1.1.2.1.1.1.1.1.3.cmml"><mo stretchy="false" id="S2.E2.m1.7.7.1.1.2.1.1.1.1.1.2.3" xref="S2.E2.m1.7.7.1.1.2.1.1.1.1.1.3.cmml">(</mo><msub id="S2.E2.m1.7.7.1.1.2.1.1.1.1.1.1.1" xref="S2.E2.m1.7.7.1.1.2.1.1.1.1.1.1.1.cmml"><mi id="S2.E2.m1.7.7.1.1.2.1.1.1.1.1.1.1.2" xref="S2.E2.m1.7.7.1.1.2.1.1.1.1.1.1.1.2.cmml">𝒙</mi><mrow id="S2.E2.m1.2.2.2.4" xref="S2.E2.m1.2.2.2.3.cmml"><mi id="S2.E2.m1.1.1.1.1" xref="S2.E2.m1.1.1.1.1.cmml">c</mi><mo id="S2.E2.m1.2.2.2.4.1" xref="S2.E2.m1.2.2.2.3.cmml">,</mo><mi id="S2.E2.m1.2.2.2.2" xref="S2.E2.m1.2.2.2.2.cmml">i</mi></mrow></msub><mo id="S2.E2.m1.7.7.1.1.2.1.1.1.1.1.2.4" xref="S2.E2.m1.7.7.1.1.2.1.1.1.1.1.3.cmml">,</mo><msub id="S2.E2.m1.7.7.1.1.2.1.1.1.1.1.2.2" xref="S2.E2.m1.7.7.1.1.2.1.1.1.1.1.2.2.cmml"><mi id="S2.E2.m1.7.7.1.1.2.1.1.1.1.1.2.2.2" xref="S2.E2.m1.7.7.1.1.2.1.1.1.1.1.2.2.2.cmml">y</mi><mrow id="S2.E2.m1.4.4.2.4" xref="S2.E2.m1.4.4.2.3.cmml"><mi id="S2.E2.m1.3.3.1.1" xref="S2.E2.m1.3.3.1.1.cmml">c</mi><mo id="S2.E2.m1.4.4.2.4.1" xref="S2.E2.m1.4.4.2.3.cmml">,</mo><mi id="S2.E2.m1.4.4.2.2" xref="S2.E2.m1.4.4.2.2.cmml">i</mi></mrow></msub><mo stretchy="false" id="S2.E2.m1.7.7.1.1.2.1.1.1.1.1.2.5" xref="S2.E2.m1.7.7.1.1.2.1.1.1.1.1.3.cmml">)</mo></mrow><mo stretchy="false" id="S2.E2.m1.7.7.1.1.2.1.1.1.1.4" xref="S2.E2.m1.7.7.1.1.2.1.1.1.2.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><mo id="S2.E2.m1.7.7.1.2" xref="S2.E2.m1.7.7.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E2.m1.7b"><apply id="S2.E2.m1.7.7.1.1.cmml" xref="S2.E2.m1.7.7.1"><eq id="S2.E2.m1.7.7.1.1.3.cmml" xref="S2.E2.m1.7.7.1.1.3"></eq><apply id="S2.E2.m1.7.7.1.1.1.cmml" xref="S2.E2.m1.7.7.1.1.1"><times id="S2.E2.m1.7.7.1.1.1.2.cmml" xref="S2.E2.m1.7.7.1.1.1.2"></times><apply id="S2.E2.m1.7.7.1.1.1.3.cmml" xref="S2.E2.m1.7.7.1.1.1.3"><csymbol cd="ambiguous" id="S2.E2.m1.7.7.1.1.1.3.1.cmml" xref="S2.E2.m1.7.7.1.1.1.3">subscript</csymbol><ci id="S2.E2.m1.7.7.1.1.1.3.2.cmml" xref="S2.E2.m1.7.7.1.1.1.3.2">ℒ</ci><ci id="S2.E2.m1.7.7.1.1.1.3.3.cmml" xref="S2.E2.m1.7.7.1.1.1.3.3">𝑐</ci></apply><list id="S2.E2.m1.7.7.1.1.1.1.2.cmml" xref="S2.E2.m1.7.7.1.1.1.1.1"><ci id="S2.E2.m1.5.5.cmml" xref="S2.E2.m1.5.5">𝜽</ci><apply id="S2.E2.m1.7.7.1.1.1.1.1.1.cmml" xref="S2.E2.m1.7.7.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E2.m1.7.7.1.1.1.1.1.1.1.cmml" xref="S2.E2.m1.7.7.1.1.1.1.1.1">subscript</csymbol><ci id="S2.E2.m1.7.7.1.1.1.1.1.1.2.cmml" xref="S2.E2.m1.7.7.1.1.1.1.1.1.2">𝒟</ci><ci id="S2.E2.m1.7.7.1.1.1.1.1.1.3.cmml" xref="S2.E2.m1.7.7.1.1.1.1.1.1.3">𝑐</ci></apply></list></apply><apply id="S2.E2.m1.7.7.1.1.2.cmml" xref="S2.E2.m1.7.7.1.1.2"><times id="S2.E2.m1.7.7.1.1.2.2.cmml" xref="S2.E2.m1.7.7.1.1.2.2"></times><apply id="S2.E2.m1.7.7.1.1.2.3.cmml" xref="S2.E2.m1.7.7.1.1.2.3"><divide id="S2.E2.m1.7.7.1.1.2.3.1.cmml" xref="S2.E2.m1.7.7.1.1.2.3"></divide><cn type="integer" id="S2.E2.m1.7.7.1.1.2.3.2.cmml" xref="S2.E2.m1.7.7.1.1.2.3.2">1</cn><apply id="S2.E2.m1.7.7.1.1.2.3.3.cmml" xref="S2.E2.m1.7.7.1.1.2.3.3"><csymbol cd="ambiguous" id="S2.E2.m1.7.7.1.1.2.3.3.1.cmml" xref="S2.E2.m1.7.7.1.1.2.3.3">subscript</csymbol><ci id="S2.E2.m1.7.7.1.1.2.3.3.2.cmml" xref="S2.E2.m1.7.7.1.1.2.3.3.2">𝑛</ci><ci id="S2.E2.m1.7.7.1.1.2.3.3.3.cmml" xref="S2.E2.m1.7.7.1.1.2.3.3.3">𝑐</ci></apply></apply><apply id="S2.E2.m1.7.7.1.1.2.1.cmml" xref="S2.E2.m1.7.7.1.1.2.1"><apply id="S2.E2.m1.7.7.1.1.2.1.2.cmml" xref="S2.E2.m1.7.7.1.1.2.1.2"><csymbol cd="ambiguous" id="S2.E2.m1.7.7.1.1.2.1.2.1.cmml" xref="S2.E2.m1.7.7.1.1.2.1.2">superscript</csymbol><apply id="S2.E2.m1.7.7.1.1.2.1.2.2.cmml" xref="S2.E2.m1.7.7.1.1.2.1.2"><csymbol cd="ambiguous" id="S2.E2.m1.7.7.1.1.2.1.2.2.1.cmml" xref="S2.E2.m1.7.7.1.1.2.1.2">subscript</csymbol><sum id="S2.E2.m1.7.7.1.1.2.1.2.2.2.cmml" xref="S2.E2.m1.7.7.1.1.2.1.2.2.2"></sum><apply id="S2.E2.m1.7.7.1.1.2.1.2.2.3.cmml" xref="S2.E2.m1.7.7.1.1.2.1.2.2.3"><eq id="S2.E2.m1.7.7.1.1.2.1.2.2.3.1.cmml" xref="S2.E2.m1.7.7.1.1.2.1.2.2.3.1"></eq><ci id="S2.E2.m1.7.7.1.1.2.1.2.2.3.2.cmml" xref="S2.E2.m1.7.7.1.1.2.1.2.2.3.2">𝑖</ci><cn type="integer" id="S2.E2.m1.7.7.1.1.2.1.2.2.3.3.cmml" xref="S2.E2.m1.7.7.1.1.2.1.2.2.3.3">1</cn></apply></apply><apply id="S2.E2.m1.7.7.1.1.2.1.2.3.cmml" xref="S2.E2.m1.7.7.1.1.2.1.2.3"><csymbol cd="ambiguous" id="S2.E2.m1.7.7.1.1.2.1.2.3.1.cmml" xref="S2.E2.m1.7.7.1.1.2.1.2.3">subscript</csymbol><ci id="S2.E2.m1.7.7.1.1.2.1.2.3.2.cmml" xref="S2.E2.m1.7.7.1.1.2.1.2.3.2">𝑛</ci><ci id="S2.E2.m1.7.7.1.1.2.1.2.3.3.cmml" xref="S2.E2.m1.7.7.1.1.2.1.2.3.3">𝑐</ci></apply></apply><apply id="S2.E2.m1.7.7.1.1.2.1.1.cmml" xref="S2.E2.m1.7.7.1.1.2.1.1"><times id="S2.E2.m1.7.7.1.1.2.1.1.2.cmml" xref="S2.E2.m1.7.7.1.1.2.1.1.2"></times><ci id="S2.E2.m1.7.7.1.1.2.1.1.3.cmml" xref="S2.E2.m1.7.7.1.1.2.1.1.3">ℓ</ci><list id="S2.E2.m1.7.7.1.1.2.1.1.1.2.cmml" xref="S2.E2.m1.7.7.1.1.2.1.1.1.1"><ci id="S2.E2.m1.6.6.cmml" xref="S2.E2.m1.6.6">𝜽</ci><interval closure="open" id="S2.E2.m1.7.7.1.1.2.1.1.1.1.1.3.cmml" xref="S2.E2.m1.7.7.1.1.2.1.1.1.1.1.2"><apply id="S2.E2.m1.7.7.1.1.2.1.1.1.1.1.1.1.cmml" xref="S2.E2.m1.7.7.1.1.2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E2.m1.7.7.1.1.2.1.1.1.1.1.1.1.1.cmml" xref="S2.E2.m1.7.7.1.1.2.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.E2.m1.7.7.1.1.2.1.1.1.1.1.1.1.2.cmml" xref="S2.E2.m1.7.7.1.1.2.1.1.1.1.1.1.1.2">𝒙</ci><list id="S2.E2.m1.2.2.2.3.cmml" xref="S2.E2.m1.2.2.2.4"><ci id="S2.E2.m1.1.1.1.1.cmml" xref="S2.E2.m1.1.1.1.1">𝑐</ci><ci id="S2.E2.m1.2.2.2.2.cmml" xref="S2.E2.m1.2.2.2.2">𝑖</ci></list></apply><apply id="S2.E2.m1.7.7.1.1.2.1.1.1.1.1.2.2.cmml" xref="S2.E2.m1.7.7.1.1.2.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S2.E2.m1.7.7.1.1.2.1.1.1.1.1.2.2.1.cmml" xref="S2.E2.m1.7.7.1.1.2.1.1.1.1.1.2.2">subscript</csymbol><ci id="S2.E2.m1.7.7.1.1.2.1.1.1.1.1.2.2.2.cmml" xref="S2.E2.m1.7.7.1.1.2.1.1.1.1.1.2.2.2">𝑦</ci><list id="S2.E2.m1.4.4.2.3.cmml" xref="S2.E2.m1.4.4.2.4"><ci id="S2.E2.m1.3.3.1.1.cmml" xref="S2.E2.m1.3.3.1.1">𝑐</ci><ci id="S2.E2.m1.4.4.2.2.cmml" xref="S2.E2.m1.4.4.2.2">𝑖</ci></list></apply></interval></list></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E2.m1.7c">\mathcal{L}_{c}(\bm{\theta};\mathcal{D}_{c})=\frac{1}{n_{c}}\sum_{i=1}^{n_{c}}\ell(\bm{\theta};(\bm{x}_{c,i},y_{c,i})),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S2.SS1.p2.10" class="ltx_p">where <math id="S2.SS1.p2.5.m1.1" class="ltx_Math" alttext="\ell" display="inline"><semantics id="S2.SS1.p2.5.m1.1a"><mi mathvariant="normal" id="S2.SS1.p2.5.m1.1.1" xref="S2.SS1.p2.5.m1.1.1.cmml">ℓ</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.5.m1.1b"><ci id="S2.SS1.p2.5.m1.1.1.cmml" xref="S2.SS1.p2.5.m1.1.1">ℓ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.5.m1.1c">\ell</annotation></semantics></math> is an instance-level loss (e.g., cross-entropy loss or squared error in the case of classification or regression tasks, respectively).
Furthermore, each <math id="S2.SS1.p2.6.m2.1" class="ltx_Math" alttext="p_{c}\geq 0" display="inline"><semantics id="S2.SS1.p2.6.m2.1a"><mrow id="S2.SS1.p2.6.m2.1.1" xref="S2.SS1.p2.6.m2.1.1.cmml"><msub id="S2.SS1.p2.6.m2.1.1.2" xref="S2.SS1.p2.6.m2.1.1.2.cmml"><mi id="S2.SS1.p2.6.m2.1.1.2.2" xref="S2.SS1.p2.6.m2.1.1.2.2.cmml">p</mi><mi id="S2.SS1.p2.6.m2.1.1.2.3" xref="S2.SS1.p2.6.m2.1.1.2.3.cmml">c</mi></msub><mo id="S2.SS1.p2.6.m2.1.1.1" xref="S2.SS1.p2.6.m2.1.1.1.cmml">≥</mo><mn id="S2.SS1.p2.6.m2.1.1.3" xref="S2.SS1.p2.6.m2.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.6.m2.1b"><apply id="S2.SS1.p2.6.m2.1.1.cmml" xref="S2.SS1.p2.6.m2.1.1"><geq id="S2.SS1.p2.6.m2.1.1.1.cmml" xref="S2.SS1.p2.6.m2.1.1.1"></geq><apply id="S2.SS1.p2.6.m2.1.1.2.cmml" xref="S2.SS1.p2.6.m2.1.1.2"><csymbol cd="ambiguous" id="S2.SS1.p2.6.m2.1.1.2.1.cmml" xref="S2.SS1.p2.6.m2.1.1.2">subscript</csymbol><ci id="S2.SS1.p2.6.m2.1.1.2.2.cmml" xref="S2.SS1.p2.6.m2.1.1.2.2">𝑝</ci><ci id="S2.SS1.p2.6.m2.1.1.2.3.cmml" xref="S2.SS1.p2.6.m2.1.1.2.3">𝑐</ci></apply><cn type="integer" id="S2.SS1.p2.6.m2.1.1.3.cmml" xref="S2.SS1.p2.6.m2.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.6.m2.1c">p_{c}\geq 0</annotation></semantics></math> specifies the relative contribution of each client.
Since it must hold that <math id="S2.SS1.p2.7.m3.1" class="ltx_Math" alttext="\sum_{c=1}^{K}p_{c}=1" display="inline"><semantics id="S2.SS1.p2.7.m3.1a"><mrow id="S2.SS1.p2.7.m3.1.1" xref="S2.SS1.p2.7.m3.1.1.cmml"><mrow id="S2.SS1.p2.7.m3.1.1.2" xref="S2.SS1.p2.7.m3.1.1.2.cmml"><msubsup id="S2.SS1.p2.7.m3.1.1.2.1" xref="S2.SS1.p2.7.m3.1.1.2.1.cmml"><mo id="S2.SS1.p2.7.m3.1.1.2.1.2.2" xref="S2.SS1.p2.7.m3.1.1.2.1.2.2.cmml">∑</mo><mrow id="S2.SS1.p2.7.m3.1.1.2.1.2.3" xref="S2.SS1.p2.7.m3.1.1.2.1.2.3.cmml"><mi id="S2.SS1.p2.7.m3.1.1.2.1.2.3.2" xref="S2.SS1.p2.7.m3.1.1.2.1.2.3.2.cmml">c</mi><mo id="S2.SS1.p2.7.m3.1.1.2.1.2.3.1" xref="S2.SS1.p2.7.m3.1.1.2.1.2.3.1.cmml">=</mo><mn id="S2.SS1.p2.7.m3.1.1.2.1.2.3.3" xref="S2.SS1.p2.7.m3.1.1.2.1.2.3.3.cmml">1</mn></mrow><mi id="S2.SS1.p2.7.m3.1.1.2.1.3" xref="S2.SS1.p2.7.m3.1.1.2.1.3.cmml">K</mi></msubsup><msub id="S2.SS1.p2.7.m3.1.1.2.2" xref="S2.SS1.p2.7.m3.1.1.2.2.cmml"><mi id="S2.SS1.p2.7.m3.1.1.2.2.2" xref="S2.SS1.p2.7.m3.1.1.2.2.2.cmml">p</mi><mi id="S2.SS1.p2.7.m3.1.1.2.2.3" xref="S2.SS1.p2.7.m3.1.1.2.2.3.cmml">c</mi></msub></mrow><mo id="S2.SS1.p2.7.m3.1.1.1" xref="S2.SS1.p2.7.m3.1.1.1.cmml">=</mo><mn id="S2.SS1.p2.7.m3.1.1.3" xref="S2.SS1.p2.7.m3.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.7.m3.1b"><apply id="S2.SS1.p2.7.m3.1.1.cmml" xref="S2.SS1.p2.7.m3.1.1"><eq id="S2.SS1.p2.7.m3.1.1.1.cmml" xref="S2.SS1.p2.7.m3.1.1.1"></eq><apply id="S2.SS1.p2.7.m3.1.1.2.cmml" xref="S2.SS1.p2.7.m3.1.1.2"><apply id="S2.SS1.p2.7.m3.1.1.2.1.cmml" xref="S2.SS1.p2.7.m3.1.1.2.1"><csymbol cd="ambiguous" id="S2.SS1.p2.7.m3.1.1.2.1.1.cmml" xref="S2.SS1.p2.7.m3.1.1.2.1">superscript</csymbol><apply id="S2.SS1.p2.7.m3.1.1.2.1.2.cmml" xref="S2.SS1.p2.7.m3.1.1.2.1"><csymbol cd="ambiguous" id="S2.SS1.p2.7.m3.1.1.2.1.2.1.cmml" xref="S2.SS1.p2.7.m3.1.1.2.1">subscript</csymbol><sum id="S2.SS1.p2.7.m3.1.1.2.1.2.2.cmml" xref="S2.SS1.p2.7.m3.1.1.2.1.2.2"></sum><apply id="S2.SS1.p2.7.m3.1.1.2.1.2.3.cmml" xref="S2.SS1.p2.7.m3.1.1.2.1.2.3"><eq id="S2.SS1.p2.7.m3.1.1.2.1.2.3.1.cmml" xref="S2.SS1.p2.7.m3.1.1.2.1.2.3.1"></eq><ci id="S2.SS1.p2.7.m3.1.1.2.1.2.3.2.cmml" xref="S2.SS1.p2.7.m3.1.1.2.1.2.3.2">𝑐</ci><cn type="integer" id="S2.SS1.p2.7.m3.1.1.2.1.2.3.3.cmml" xref="S2.SS1.p2.7.m3.1.1.2.1.2.3.3">1</cn></apply></apply><ci id="S2.SS1.p2.7.m3.1.1.2.1.3.cmml" xref="S2.SS1.p2.7.m3.1.1.2.1.3">𝐾</ci></apply><apply id="S2.SS1.p2.7.m3.1.1.2.2.cmml" xref="S2.SS1.p2.7.m3.1.1.2.2"><csymbol cd="ambiguous" id="S2.SS1.p2.7.m3.1.1.2.2.1.cmml" xref="S2.SS1.p2.7.m3.1.1.2.2">subscript</csymbol><ci id="S2.SS1.p2.7.m3.1.1.2.2.2.cmml" xref="S2.SS1.p2.7.m3.1.1.2.2.2">𝑝</ci><ci id="S2.SS1.p2.7.m3.1.1.2.2.3.cmml" xref="S2.SS1.p2.7.m3.1.1.2.2.3">𝑐</ci></apply></apply><cn type="integer" id="S2.SS1.p2.7.m3.1.1.3.cmml" xref="S2.SS1.p2.7.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.7.m3.1c">\sum_{c=1}^{K}p_{c}=1</annotation></semantics></math>, two possible settings for it are: <math id="S2.SS1.p2.8.m4.1" class="ltx_Math" alttext="p_{c}=1/K" display="inline"><semantics id="S2.SS1.p2.8.m4.1a"><mrow id="S2.SS1.p2.8.m4.1.1" xref="S2.SS1.p2.8.m4.1.1.cmml"><msub id="S2.SS1.p2.8.m4.1.1.2" xref="S2.SS1.p2.8.m4.1.1.2.cmml"><mi id="S2.SS1.p2.8.m4.1.1.2.2" xref="S2.SS1.p2.8.m4.1.1.2.2.cmml">p</mi><mi id="S2.SS1.p2.8.m4.1.1.2.3" xref="S2.SS1.p2.8.m4.1.1.2.3.cmml">c</mi></msub><mo id="S2.SS1.p2.8.m4.1.1.1" xref="S2.SS1.p2.8.m4.1.1.1.cmml">=</mo><mrow id="S2.SS1.p2.8.m4.1.1.3" xref="S2.SS1.p2.8.m4.1.1.3.cmml"><mn id="S2.SS1.p2.8.m4.1.1.3.2" xref="S2.SS1.p2.8.m4.1.1.3.2.cmml">1</mn><mo id="S2.SS1.p2.8.m4.1.1.3.1" xref="S2.SS1.p2.8.m4.1.1.3.1.cmml">/</mo><mi id="S2.SS1.p2.8.m4.1.1.3.3" xref="S2.SS1.p2.8.m4.1.1.3.3.cmml">K</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.8.m4.1b"><apply id="S2.SS1.p2.8.m4.1.1.cmml" xref="S2.SS1.p2.8.m4.1.1"><eq id="S2.SS1.p2.8.m4.1.1.1.cmml" xref="S2.SS1.p2.8.m4.1.1.1"></eq><apply id="S2.SS1.p2.8.m4.1.1.2.cmml" xref="S2.SS1.p2.8.m4.1.1.2"><csymbol cd="ambiguous" id="S2.SS1.p2.8.m4.1.1.2.1.cmml" xref="S2.SS1.p2.8.m4.1.1.2">subscript</csymbol><ci id="S2.SS1.p2.8.m4.1.1.2.2.cmml" xref="S2.SS1.p2.8.m4.1.1.2.2">𝑝</ci><ci id="S2.SS1.p2.8.m4.1.1.2.3.cmml" xref="S2.SS1.p2.8.m4.1.1.2.3">𝑐</ci></apply><apply id="S2.SS1.p2.8.m4.1.1.3.cmml" xref="S2.SS1.p2.8.m4.1.1.3"><divide id="S2.SS1.p2.8.m4.1.1.3.1.cmml" xref="S2.SS1.p2.8.m4.1.1.3.1"></divide><cn type="integer" id="S2.SS1.p2.8.m4.1.1.3.2.cmml" xref="S2.SS1.p2.8.m4.1.1.3.2">1</cn><ci id="S2.SS1.p2.8.m4.1.1.3.3.cmml" xref="S2.SS1.p2.8.m4.1.1.3.3">𝐾</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.8.m4.1c">p_{c}=1/K</annotation></semantics></math> or <math id="S2.SS1.p2.9.m5.1" class="ltx_Math" alttext="p_{c}=n_{c}/n" display="inline"><semantics id="S2.SS1.p2.9.m5.1a"><mrow id="S2.SS1.p2.9.m5.1.1" xref="S2.SS1.p2.9.m5.1.1.cmml"><msub id="S2.SS1.p2.9.m5.1.1.2" xref="S2.SS1.p2.9.m5.1.1.2.cmml"><mi id="S2.SS1.p2.9.m5.1.1.2.2" xref="S2.SS1.p2.9.m5.1.1.2.2.cmml">p</mi><mi id="S2.SS1.p2.9.m5.1.1.2.3" xref="S2.SS1.p2.9.m5.1.1.2.3.cmml">c</mi></msub><mo id="S2.SS1.p2.9.m5.1.1.1" xref="S2.SS1.p2.9.m5.1.1.1.cmml">=</mo><mrow id="S2.SS1.p2.9.m5.1.1.3" xref="S2.SS1.p2.9.m5.1.1.3.cmml"><msub id="S2.SS1.p2.9.m5.1.1.3.2" xref="S2.SS1.p2.9.m5.1.1.3.2.cmml"><mi id="S2.SS1.p2.9.m5.1.1.3.2.2" xref="S2.SS1.p2.9.m5.1.1.3.2.2.cmml">n</mi><mi id="S2.SS1.p2.9.m5.1.1.3.2.3" xref="S2.SS1.p2.9.m5.1.1.3.2.3.cmml">c</mi></msub><mo id="S2.SS1.p2.9.m5.1.1.3.1" xref="S2.SS1.p2.9.m5.1.1.3.1.cmml">/</mo><mi id="S2.SS1.p2.9.m5.1.1.3.3" xref="S2.SS1.p2.9.m5.1.1.3.3.cmml">n</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.9.m5.1b"><apply id="S2.SS1.p2.9.m5.1.1.cmml" xref="S2.SS1.p2.9.m5.1.1"><eq id="S2.SS1.p2.9.m5.1.1.1.cmml" xref="S2.SS1.p2.9.m5.1.1.1"></eq><apply id="S2.SS1.p2.9.m5.1.1.2.cmml" xref="S2.SS1.p2.9.m5.1.1.2"><csymbol cd="ambiguous" id="S2.SS1.p2.9.m5.1.1.2.1.cmml" xref="S2.SS1.p2.9.m5.1.1.2">subscript</csymbol><ci id="S2.SS1.p2.9.m5.1.1.2.2.cmml" xref="S2.SS1.p2.9.m5.1.1.2.2">𝑝</ci><ci id="S2.SS1.p2.9.m5.1.1.2.3.cmml" xref="S2.SS1.p2.9.m5.1.1.2.3">𝑐</ci></apply><apply id="S2.SS1.p2.9.m5.1.1.3.cmml" xref="S2.SS1.p2.9.m5.1.1.3"><divide id="S2.SS1.p2.9.m5.1.1.3.1.cmml" xref="S2.SS1.p2.9.m5.1.1.3.1"></divide><apply id="S2.SS1.p2.9.m5.1.1.3.2.cmml" xref="S2.SS1.p2.9.m5.1.1.3.2"><csymbol cd="ambiguous" id="S2.SS1.p2.9.m5.1.1.3.2.1.cmml" xref="S2.SS1.p2.9.m5.1.1.3.2">subscript</csymbol><ci id="S2.SS1.p2.9.m5.1.1.3.2.2.cmml" xref="S2.SS1.p2.9.m5.1.1.3.2.2">𝑛</ci><ci id="S2.SS1.p2.9.m5.1.1.3.2.3.cmml" xref="S2.SS1.p2.9.m5.1.1.3.2.3">𝑐</ci></apply><ci id="S2.SS1.p2.9.m5.1.1.3.3.cmml" xref="S2.SS1.p2.9.m5.1.1.3.3">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.9.m5.1c">p_{c}=n_{c}/n</annotation></semantics></math>, where <math id="S2.SS1.p2.10.m6.1" class="ltx_Math" alttext="n=\sum_{c=1}^{K}n_{c}" display="inline"><semantics id="S2.SS1.p2.10.m6.1a"><mrow id="S2.SS1.p2.10.m6.1.1" xref="S2.SS1.p2.10.m6.1.1.cmml"><mi id="S2.SS1.p2.10.m6.1.1.2" xref="S2.SS1.p2.10.m6.1.1.2.cmml">n</mi><mo rspace="0.111em" id="S2.SS1.p2.10.m6.1.1.1" xref="S2.SS1.p2.10.m6.1.1.1.cmml">=</mo><mrow id="S2.SS1.p2.10.m6.1.1.3" xref="S2.SS1.p2.10.m6.1.1.3.cmml"><msubsup id="S2.SS1.p2.10.m6.1.1.3.1" xref="S2.SS1.p2.10.m6.1.1.3.1.cmml"><mo id="S2.SS1.p2.10.m6.1.1.3.1.2.2" xref="S2.SS1.p2.10.m6.1.1.3.1.2.2.cmml">∑</mo><mrow id="S2.SS1.p2.10.m6.1.1.3.1.2.3" xref="S2.SS1.p2.10.m6.1.1.3.1.2.3.cmml"><mi id="S2.SS1.p2.10.m6.1.1.3.1.2.3.2" xref="S2.SS1.p2.10.m6.1.1.3.1.2.3.2.cmml">c</mi><mo id="S2.SS1.p2.10.m6.1.1.3.1.2.3.1" xref="S2.SS1.p2.10.m6.1.1.3.1.2.3.1.cmml">=</mo><mn id="S2.SS1.p2.10.m6.1.1.3.1.2.3.3" xref="S2.SS1.p2.10.m6.1.1.3.1.2.3.3.cmml">1</mn></mrow><mi id="S2.SS1.p2.10.m6.1.1.3.1.3" xref="S2.SS1.p2.10.m6.1.1.3.1.3.cmml">K</mi></msubsup><msub id="S2.SS1.p2.10.m6.1.1.3.2" xref="S2.SS1.p2.10.m6.1.1.3.2.cmml"><mi id="S2.SS1.p2.10.m6.1.1.3.2.2" xref="S2.SS1.p2.10.m6.1.1.3.2.2.cmml">n</mi><mi id="S2.SS1.p2.10.m6.1.1.3.2.3" xref="S2.SS1.p2.10.m6.1.1.3.2.3.cmml">c</mi></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.10.m6.1b"><apply id="S2.SS1.p2.10.m6.1.1.cmml" xref="S2.SS1.p2.10.m6.1.1"><eq id="S2.SS1.p2.10.m6.1.1.1.cmml" xref="S2.SS1.p2.10.m6.1.1.1"></eq><ci id="S2.SS1.p2.10.m6.1.1.2.cmml" xref="S2.SS1.p2.10.m6.1.1.2">𝑛</ci><apply id="S2.SS1.p2.10.m6.1.1.3.cmml" xref="S2.SS1.p2.10.m6.1.1.3"><apply id="S2.SS1.p2.10.m6.1.1.3.1.cmml" xref="S2.SS1.p2.10.m6.1.1.3.1"><csymbol cd="ambiguous" id="S2.SS1.p2.10.m6.1.1.3.1.1.cmml" xref="S2.SS1.p2.10.m6.1.1.3.1">superscript</csymbol><apply id="S2.SS1.p2.10.m6.1.1.3.1.2.cmml" xref="S2.SS1.p2.10.m6.1.1.3.1"><csymbol cd="ambiguous" id="S2.SS1.p2.10.m6.1.1.3.1.2.1.cmml" xref="S2.SS1.p2.10.m6.1.1.3.1">subscript</csymbol><sum id="S2.SS1.p2.10.m6.1.1.3.1.2.2.cmml" xref="S2.SS1.p2.10.m6.1.1.3.1.2.2"></sum><apply id="S2.SS1.p2.10.m6.1.1.3.1.2.3.cmml" xref="S2.SS1.p2.10.m6.1.1.3.1.2.3"><eq id="S2.SS1.p2.10.m6.1.1.3.1.2.3.1.cmml" xref="S2.SS1.p2.10.m6.1.1.3.1.2.3.1"></eq><ci id="S2.SS1.p2.10.m6.1.1.3.1.2.3.2.cmml" xref="S2.SS1.p2.10.m6.1.1.3.1.2.3.2">𝑐</ci><cn type="integer" id="S2.SS1.p2.10.m6.1.1.3.1.2.3.3.cmml" xref="S2.SS1.p2.10.m6.1.1.3.1.2.3.3">1</cn></apply></apply><ci id="S2.SS1.p2.10.m6.1.1.3.1.3.cmml" xref="S2.SS1.p2.10.m6.1.1.3.1.3">𝐾</ci></apply><apply id="S2.SS1.p2.10.m6.1.1.3.2.cmml" xref="S2.SS1.p2.10.m6.1.1.3.2"><csymbol cd="ambiguous" id="S2.SS1.p2.10.m6.1.1.3.2.1.cmml" xref="S2.SS1.p2.10.m6.1.1.3.2">subscript</csymbol><ci id="S2.SS1.p2.10.m6.1.1.3.2.2.cmml" xref="S2.SS1.p2.10.m6.1.1.3.2.2">𝑛</ci><ci id="S2.SS1.p2.10.m6.1.1.3.2.3.cmml" xref="S2.SS1.p2.10.m6.1.1.3.2.3">𝑐</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.10.m6.1c">n=\sum_{c=1}^{K}n_{c}</annotation></semantics></math>.</p>
</div>
<div id="S2.SS1.p3" class="ltx_para">
<p id="S2.SS1.p3.2" class="ltx_p">The generic federated round at each time <math id="S2.SS1.p3.1.m1.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S2.SS1.p3.1.m1.1a"><mi id="S2.SS1.p3.1.m1.1.1" xref="S2.SS1.p3.1.m1.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.1.m1.1b"><ci id="S2.SS1.p3.1.m1.1.1.cmml" xref="S2.SS1.p3.1.m1.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.1.m1.1c">t</annotation></semantics></math> is decomposed into the following steps and iteratively repeated until convergence, i.e., for each <math id="S2.SS1.p3.2.m2.4" class="ltx_Math" alttext="t=1,2,\ldots,T" display="inline"><semantics id="S2.SS1.p3.2.m2.4a"><mrow id="S2.SS1.p3.2.m2.4.5" xref="S2.SS1.p3.2.m2.4.5.cmml"><mi id="S2.SS1.p3.2.m2.4.5.2" xref="S2.SS1.p3.2.m2.4.5.2.cmml">t</mi><mo id="S2.SS1.p3.2.m2.4.5.1" xref="S2.SS1.p3.2.m2.4.5.1.cmml">=</mo><mrow id="S2.SS1.p3.2.m2.4.5.3.2" xref="S2.SS1.p3.2.m2.4.5.3.1.cmml"><mn id="S2.SS1.p3.2.m2.1.1" xref="S2.SS1.p3.2.m2.1.1.cmml">1</mn><mo id="S2.SS1.p3.2.m2.4.5.3.2.1" xref="S2.SS1.p3.2.m2.4.5.3.1.cmml">,</mo><mn id="S2.SS1.p3.2.m2.2.2" xref="S2.SS1.p3.2.m2.2.2.cmml">2</mn><mo id="S2.SS1.p3.2.m2.4.5.3.2.2" xref="S2.SS1.p3.2.m2.4.5.3.1.cmml">,</mo><mi mathvariant="normal" id="S2.SS1.p3.2.m2.3.3" xref="S2.SS1.p3.2.m2.3.3.cmml">…</mi><mo id="S2.SS1.p3.2.m2.4.5.3.2.3" xref="S2.SS1.p3.2.m2.4.5.3.1.cmml">,</mo><mi id="S2.SS1.p3.2.m2.4.4" xref="S2.SS1.p3.2.m2.4.4.cmml">T</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.2.m2.4b"><apply id="S2.SS1.p3.2.m2.4.5.cmml" xref="S2.SS1.p3.2.m2.4.5"><eq id="S2.SS1.p3.2.m2.4.5.1.cmml" xref="S2.SS1.p3.2.m2.4.5.1"></eq><ci id="S2.SS1.p3.2.m2.4.5.2.cmml" xref="S2.SS1.p3.2.m2.4.5.2">𝑡</ci><list id="S2.SS1.p3.2.m2.4.5.3.1.cmml" xref="S2.SS1.p3.2.m2.4.5.3.2"><cn type="integer" id="S2.SS1.p3.2.m2.1.1.cmml" xref="S2.SS1.p3.2.m2.1.1">1</cn><cn type="integer" id="S2.SS1.p3.2.m2.2.2.cmml" xref="S2.SS1.p3.2.m2.2.2">2</cn><ci id="S2.SS1.p3.2.m2.3.3.cmml" xref="S2.SS1.p3.2.m2.3.3">…</ci><ci id="S2.SS1.p3.2.m2.4.4.cmml" xref="S2.SS1.p3.2.m2.4.4">𝑇</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.2.m2.4c">t=1,2,\ldots,T</annotation></semantics></math>:</p>
<ol id="S2.I1" class="ltx_enumerate">
<li id="S2.I1.ix1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><math id="S2.I1.ix1.1.1.m1.1" class="ltx_Math" alttext="(i)" display="inline"><semantics id="S2.I1.ix1.1.1.m1.1b"><mrow id="S2.I1.ix1.1.1.m1.1.2.2"><mo stretchy="false" id="S2.I1.ix1.1.1.m1.1.2.2.1">(</mo><mi id="S2.I1.ix1.1.1.m1.1.1" xref="S2.I1.ix1.1.1.m1.1.1.cmml">i</mi><mo stretchy="false" id="S2.I1.ix1.1.1.m1.1.2.2.2">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.ix1.1.1.m1.1c"><ci id="S2.I1.ix1.1.1.m1.1.1.cmml" xref="S2.I1.ix1.1.1.m1.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.ix1.1.1.m1.1d">(i)</annotation></semantics></math></span> 
<div id="S2.I1.ix1.p1" class="ltx_para">
<p id="S2.I1.ix1.p1.5" class="ltx_p"><math id="S2.I1.ix1.p1.1.m1.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S2.I1.ix1.p1.1.m1.1a"><mi id="S2.I1.ix1.p1.1.m1.1.1" xref="S2.I1.ix1.p1.1.m1.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S2.I1.ix1.p1.1.m1.1b"><ci id="S2.I1.ix1.p1.1.m1.1.1.cmml" xref="S2.I1.ix1.p1.1.m1.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.ix1.p1.1.m1.1c">S</annotation></semantics></math> randomly selects a subset of clients <math id="S2.I1.ix1.p1.2.m2.1" class="ltx_Math" alttext="{\mathcal{C}}^{(t)}\subseteq\mathcal{C}" display="inline"><semantics id="S2.I1.ix1.p1.2.m2.1a"><mrow id="S2.I1.ix1.p1.2.m2.1.2" xref="S2.I1.ix1.p1.2.m2.1.2.cmml"><msup id="S2.I1.ix1.p1.2.m2.1.2.2" xref="S2.I1.ix1.p1.2.m2.1.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.I1.ix1.p1.2.m2.1.2.2.2" xref="S2.I1.ix1.p1.2.m2.1.2.2.2.cmml">𝒞</mi><mrow id="S2.I1.ix1.p1.2.m2.1.1.1.3" xref="S2.I1.ix1.p1.2.m2.1.2.2.cmml"><mo stretchy="false" id="S2.I1.ix1.p1.2.m2.1.1.1.3.1" xref="S2.I1.ix1.p1.2.m2.1.2.2.cmml">(</mo><mi id="S2.I1.ix1.p1.2.m2.1.1.1.1" xref="S2.I1.ix1.p1.2.m2.1.1.1.1.cmml">t</mi><mo stretchy="false" id="S2.I1.ix1.p1.2.m2.1.1.1.3.2" xref="S2.I1.ix1.p1.2.m2.1.2.2.cmml">)</mo></mrow></msup><mo id="S2.I1.ix1.p1.2.m2.1.2.1" xref="S2.I1.ix1.p1.2.m2.1.2.1.cmml">⊆</mo><mi class="ltx_font_mathcaligraphic" id="S2.I1.ix1.p1.2.m2.1.2.3" xref="S2.I1.ix1.p1.2.m2.1.2.3.cmml">𝒞</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.ix1.p1.2.m2.1b"><apply id="S2.I1.ix1.p1.2.m2.1.2.cmml" xref="S2.I1.ix1.p1.2.m2.1.2"><subset id="S2.I1.ix1.p1.2.m2.1.2.1.cmml" xref="S2.I1.ix1.p1.2.m2.1.2.1"></subset><apply id="S2.I1.ix1.p1.2.m2.1.2.2.cmml" xref="S2.I1.ix1.p1.2.m2.1.2.2"><csymbol cd="ambiguous" id="S2.I1.ix1.p1.2.m2.1.2.2.1.cmml" xref="S2.I1.ix1.p1.2.m2.1.2.2">superscript</csymbol><ci id="S2.I1.ix1.p1.2.m2.1.2.2.2.cmml" xref="S2.I1.ix1.p1.2.m2.1.2.2.2">𝒞</ci><ci id="S2.I1.ix1.p1.2.m2.1.1.1.1.cmml" xref="S2.I1.ix1.p1.2.m2.1.1.1.1">𝑡</ci></apply><ci id="S2.I1.ix1.p1.2.m2.1.2.3.cmml" xref="S2.I1.ix1.p1.2.m2.1.2.3">𝒞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.ix1.p1.2.m2.1c">{\mathcal{C}}^{(t)}\subseteq\mathcal{C}</annotation></semantics></math>, so that <math id="S2.I1.ix1.p1.3.m3.2" class="ltx_Math" alttext="1\leq|{\mathcal{C}}^{(t)}|\leq K" display="inline"><semantics id="S2.I1.ix1.p1.3.m3.2a"><mrow id="S2.I1.ix1.p1.3.m3.2.2" xref="S2.I1.ix1.p1.3.m3.2.2.cmml"><mn id="S2.I1.ix1.p1.3.m3.2.2.3" xref="S2.I1.ix1.p1.3.m3.2.2.3.cmml">1</mn><mo id="S2.I1.ix1.p1.3.m3.2.2.4" xref="S2.I1.ix1.p1.3.m3.2.2.4.cmml">≤</mo><mrow id="S2.I1.ix1.p1.3.m3.2.2.1.1" xref="S2.I1.ix1.p1.3.m3.2.2.1.2.cmml"><mo stretchy="false" id="S2.I1.ix1.p1.3.m3.2.2.1.1.2" xref="S2.I1.ix1.p1.3.m3.2.2.1.2.1.cmml">|</mo><msup id="S2.I1.ix1.p1.3.m3.2.2.1.1.1" xref="S2.I1.ix1.p1.3.m3.2.2.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.I1.ix1.p1.3.m3.2.2.1.1.1.2" xref="S2.I1.ix1.p1.3.m3.2.2.1.1.1.2.cmml">𝒞</mi><mrow id="S2.I1.ix1.p1.3.m3.1.1.1.3" xref="S2.I1.ix1.p1.3.m3.2.2.1.1.1.cmml"><mo stretchy="false" id="S2.I1.ix1.p1.3.m3.1.1.1.3.1" xref="S2.I1.ix1.p1.3.m3.2.2.1.1.1.cmml">(</mo><mi id="S2.I1.ix1.p1.3.m3.1.1.1.1" xref="S2.I1.ix1.p1.3.m3.1.1.1.1.cmml">t</mi><mo stretchy="false" id="S2.I1.ix1.p1.3.m3.1.1.1.3.2" xref="S2.I1.ix1.p1.3.m3.2.2.1.1.1.cmml">)</mo></mrow></msup><mo stretchy="false" id="S2.I1.ix1.p1.3.m3.2.2.1.1.3" xref="S2.I1.ix1.p1.3.m3.2.2.1.2.1.cmml">|</mo></mrow><mo id="S2.I1.ix1.p1.3.m3.2.2.5" xref="S2.I1.ix1.p1.3.m3.2.2.5.cmml">≤</mo><mi id="S2.I1.ix1.p1.3.m3.2.2.6" xref="S2.I1.ix1.p1.3.m3.2.2.6.cmml">K</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.ix1.p1.3.m3.2b"><apply id="S2.I1.ix1.p1.3.m3.2.2.cmml" xref="S2.I1.ix1.p1.3.m3.2.2"><and id="S2.I1.ix1.p1.3.m3.2.2a.cmml" xref="S2.I1.ix1.p1.3.m3.2.2"></and><apply id="S2.I1.ix1.p1.3.m3.2.2b.cmml" xref="S2.I1.ix1.p1.3.m3.2.2"><leq id="S2.I1.ix1.p1.3.m3.2.2.4.cmml" xref="S2.I1.ix1.p1.3.m3.2.2.4"></leq><cn type="integer" id="S2.I1.ix1.p1.3.m3.2.2.3.cmml" xref="S2.I1.ix1.p1.3.m3.2.2.3">1</cn><apply id="S2.I1.ix1.p1.3.m3.2.2.1.2.cmml" xref="S2.I1.ix1.p1.3.m3.2.2.1.1"><abs id="S2.I1.ix1.p1.3.m3.2.2.1.2.1.cmml" xref="S2.I1.ix1.p1.3.m3.2.2.1.1.2"></abs><apply id="S2.I1.ix1.p1.3.m3.2.2.1.1.1.cmml" xref="S2.I1.ix1.p1.3.m3.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.I1.ix1.p1.3.m3.2.2.1.1.1.1.cmml" xref="S2.I1.ix1.p1.3.m3.2.2.1.1.1">superscript</csymbol><ci id="S2.I1.ix1.p1.3.m3.2.2.1.1.1.2.cmml" xref="S2.I1.ix1.p1.3.m3.2.2.1.1.1.2">𝒞</ci><ci id="S2.I1.ix1.p1.3.m3.1.1.1.1.cmml" xref="S2.I1.ix1.p1.3.m3.1.1.1.1">𝑡</ci></apply></apply></apply><apply id="S2.I1.ix1.p1.3.m3.2.2c.cmml" xref="S2.I1.ix1.p1.3.m3.2.2"><leq id="S2.I1.ix1.p1.3.m3.2.2.5.cmml" xref="S2.I1.ix1.p1.3.m3.2.2.5"></leq><share href="#S2.I1.ix1.p1.3.m3.2.2.1.cmml" id="S2.I1.ix1.p1.3.m3.2.2d.cmml" xref="S2.I1.ix1.p1.3.m3.2.2"></share><ci id="S2.I1.ix1.p1.3.m3.2.2.6.cmml" xref="S2.I1.ix1.p1.3.m3.2.2.6">𝐾</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.ix1.p1.3.m3.2c">1\leq|{\mathcal{C}}^{(t)}|\leq K</annotation></semantics></math>, and sends them the current, global model <math id="S2.I1.ix1.p1.4.m4.1" class="ltx_Math" alttext="\bm{\theta}^{(t)}" display="inline"><semantics id="S2.I1.ix1.p1.4.m4.1a"><msup id="S2.I1.ix1.p1.4.m4.1.2" xref="S2.I1.ix1.p1.4.m4.1.2.cmml"><mi id="S2.I1.ix1.p1.4.m4.1.2.2" xref="S2.I1.ix1.p1.4.m4.1.2.2.cmml">𝜽</mi><mrow id="S2.I1.ix1.p1.4.m4.1.1.1.3" xref="S2.I1.ix1.p1.4.m4.1.2.cmml"><mo stretchy="false" id="S2.I1.ix1.p1.4.m4.1.1.1.3.1" xref="S2.I1.ix1.p1.4.m4.1.2.cmml">(</mo><mi id="S2.I1.ix1.p1.4.m4.1.1.1.1" xref="S2.I1.ix1.p1.4.m4.1.1.1.1.cmml">t</mi><mo stretchy="false" id="S2.I1.ix1.p1.4.m4.1.1.1.3.2" xref="S2.I1.ix1.p1.4.m4.1.2.cmml">)</mo></mrow></msup><annotation-xml encoding="MathML-Content" id="S2.I1.ix1.p1.4.m4.1b"><apply id="S2.I1.ix1.p1.4.m4.1.2.cmml" xref="S2.I1.ix1.p1.4.m4.1.2"><csymbol cd="ambiguous" id="S2.I1.ix1.p1.4.m4.1.2.1.cmml" xref="S2.I1.ix1.p1.4.m4.1.2">superscript</csymbol><ci id="S2.I1.ix1.p1.4.m4.1.2.2.cmml" xref="S2.I1.ix1.p1.4.m4.1.2.2">𝜽</ci><ci id="S2.I1.ix1.p1.4.m4.1.1.1.1.cmml" xref="S2.I1.ix1.p1.4.m4.1.1.1.1">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.ix1.p1.4.m4.1c">\bm{\theta}^{(t)}</annotation></semantics></math>.
To ease of presentation, without loss of generality, in the following, we assume that the number of clients picked at each round is constant and fixed, i.e., <math id="S2.I1.ix1.p1.5.m5.7" class="ltx_Math" alttext="|\mathcal{C}^{(t)}|=m,~{}\forall t\in\{1,2,\ldots,T\}" display="inline"><semantics id="S2.I1.ix1.p1.5.m5.7a"><mrow id="S2.I1.ix1.p1.5.m5.7.7.2" xref="S2.I1.ix1.p1.5.m5.7.7.3.cmml"><mrow id="S2.I1.ix1.p1.5.m5.6.6.1.1" xref="S2.I1.ix1.p1.5.m5.6.6.1.1.cmml"><mrow id="S2.I1.ix1.p1.5.m5.6.6.1.1.1.1" xref="S2.I1.ix1.p1.5.m5.6.6.1.1.1.2.cmml"><mo stretchy="false" id="S2.I1.ix1.p1.5.m5.6.6.1.1.1.1.2" xref="S2.I1.ix1.p1.5.m5.6.6.1.1.1.2.1.cmml">|</mo><msup id="S2.I1.ix1.p1.5.m5.6.6.1.1.1.1.1" xref="S2.I1.ix1.p1.5.m5.6.6.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.I1.ix1.p1.5.m5.6.6.1.1.1.1.1.2" xref="S2.I1.ix1.p1.5.m5.6.6.1.1.1.1.1.2.cmml">𝒞</mi><mrow id="S2.I1.ix1.p1.5.m5.1.1.1.3" xref="S2.I1.ix1.p1.5.m5.6.6.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.I1.ix1.p1.5.m5.1.1.1.3.1" xref="S2.I1.ix1.p1.5.m5.6.6.1.1.1.1.1.cmml">(</mo><mi id="S2.I1.ix1.p1.5.m5.1.1.1.1" xref="S2.I1.ix1.p1.5.m5.1.1.1.1.cmml">t</mi><mo stretchy="false" id="S2.I1.ix1.p1.5.m5.1.1.1.3.2" xref="S2.I1.ix1.p1.5.m5.6.6.1.1.1.1.1.cmml">)</mo></mrow></msup><mo stretchy="false" id="S2.I1.ix1.p1.5.m5.6.6.1.1.1.1.3" xref="S2.I1.ix1.p1.5.m5.6.6.1.1.1.2.1.cmml">|</mo></mrow><mo id="S2.I1.ix1.p1.5.m5.6.6.1.1.2" xref="S2.I1.ix1.p1.5.m5.6.6.1.1.2.cmml">=</mo><mi id="S2.I1.ix1.p1.5.m5.6.6.1.1.3" xref="S2.I1.ix1.p1.5.m5.6.6.1.1.3.cmml">m</mi></mrow><mo rspace="0.497em" id="S2.I1.ix1.p1.5.m5.7.7.2.3" xref="S2.I1.ix1.p1.5.m5.7.7.3a.cmml">,</mo><mrow id="S2.I1.ix1.p1.5.m5.7.7.2.2" xref="S2.I1.ix1.p1.5.m5.7.7.2.2.cmml"><mrow id="S2.I1.ix1.p1.5.m5.7.7.2.2.2" xref="S2.I1.ix1.p1.5.m5.7.7.2.2.2.cmml"><mo rspace="0.167em" id="S2.I1.ix1.p1.5.m5.7.7.2.2.2.1" xref="S2.I1.ix1.p1.5.m5.7.7.2.2.2.1.cmml">∀</mo><mi id="S2.I1.ix1.p1.5.m5.7.7.2.2.2.2" xref="S2.I1.ix1.p1.5.m5.7.7.2.2.2.2.cmml">t</mi></mrow><mo id="S2.I1.ix1.p1.5.m5.7.7.2.2.1" xref="S2.I1.ix1.p1.5.m5.7.7.2.2.1.cmml">∈</mo><mrow id="S2.I1.ix1.p1.5.m5.7.7.2.2.3.2" xref="S2.I1.ix1.p1.5.m5.7.7.2.2.3.1.cmml"><mo stretchy="false" id="S2.I1.ix1.p1.5.m5.7.7.2.2.3.2.1" xref="S2.I1.ix1.p1.5.m5.7.7.2.2.3.1.cmml">{</mo><mn id="S2.I1.ix1.p1.5.m5.2.2" xref="S2.I1.ix1.p1.5.m5.2.2.cmml">1</mn><mo id="S2.I1.ix1.p1.5.m5.7.7.2.2.3.2.2" xref="S2.I1.ix1.p1.5.m5.7.7.2.2.3.1.cmml">,</mo><mn id="S2.I1.ix1.p1.5.m5.3.3" xref="S2.I1.ix1.p1.5.m5.3.3.cmml">2</mn><mo id="S2.I1.ix1.p1.5.m5.7.7.2.2.3.2.3" xref="S2.I1.ix1.p1.5.m5.7.7.2.2.3.1.cmml">,</mo><mi mathvariant="normal" id="S2.I1.ix1.p1.5.m5.4.4" xref="S2.I1.ix1.p1.5.m5.4.4.cmml">…</mi><mo id="S2.I1.ix1.p1.5.m5.7.7.2.2.3.2.4" xref="S2.I1.ix1.p1.5.m5.7.7.2.2.3.1.cmml">,</mo><mi id="S2.I1.ix1.p1.5.m5.5.5" xref="S2.I1.ix1.p1.5.m5.5.5.cmml">T</mi><mo stretchy="false" id="S2.I1.ix1.p1.5.m5.7.7.2.2.3.2.5" xref="S2.I1.ix1.p1.5.m5.7.7.2.2.3.1.cmml">}</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.ix1.p1.5.m5.7b"><apply id="S2.I1.ix1.p1.5.m5.7.7.3.cmml" xref="S2.I1.ix1.p1.5.m5.7.7.2"><csymbol cd="ambiguous" id="S2.I1.ix1.p1.5.m5.7.7.3a.cmml" xref="S2.I1.ix1.p1.5.m5.7.7.2.3">formulae-sequence</csymbol><apply id="S2.I1.ix1.p1.5.m5.6.6.1.1.cmml" xref="S2.I1.ix1.p1.5.m5.6.6.1.1"><eq id="S2.I1.ix1.p1.5.m5.6.6.1.1.2.cmml" xref="S2.I1.ix1.p1.5.m5.6.6.1.1.2"></eq><apply id="S2.I1.ix1.p1.5.m5.6.6.1.1.1.2.cmml" xref="S2.I1.ix1.p1.5.m5.6.6.1.1.1.1"><abs id="S2.I1.ix1.p1.5.m5.6.6.1.1.1.2.1.cmml" xref="S2.I1.ix1.p1.5.m5.6.6.1.1.1.1.2"></abs><apply id="S2.I1.ix1.p1.5.m5.6.6.1.1.1.1.1.cmml" xref="S2.I1.ix1.p1.5.m5.6.6.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.I1.ix1.p1.5.m5.6.6.1.1.1.1.1.1.cmml" xref="S2.I1.ix1.p1.5.m5.6.6.1.1.1.1.1">superscript</csymbol><ci id="S2.I1.ix1.p1.5.m5.6.6.1.1.1.1.1.2.cmml" xref="S2.I1.ix1.p1.5.m5.6.6.1.1.1.1.1.2">𝒞</ci><ci id="S2.I1.ix1.p1.5.m5.1.1.1.1.cmml" xref="S2.I1.ix1.p1.5.m5.1.1.1.1">𝑡</ci></apply></apply><ci id="S2.I1.ix1.p1.5.m5.6.6.1.1.3.cmml" xref="S2.I1.ix1.p1.5.m5.6.6.1.1.3">𝑚</ci></apply><apply id="S2.I1.ix1.p1.5.m5.7.7.2.2.cmml" xref="S2.I1.ix1.p1.5.m5.7.7.2.2"><in id="S2.I1.ix1.p1.5.m5.7.7.2.2.1.cmml" xref="S2.I1.ix1.p1.5.m5.7.7.2.2.1"></in><apply id="S2.I1.ix1.p1.5.m5.7.7.2.2.2.cmml" xref="S2.I1.ix1.p1.5.m5.7.7.2.2.2"><csymbol cd="latexml" id="S2.I1.ix1.p1.5.m5.7.7.2.2.2.1.cmml" xref="S2.I1.ix1.p1.5.m5.7.7.2.2.2.1">for-all</csymbol><ci id="S2.I1.ix1.p1.5.m5.7.7.2.2.2.2.cmml" xref="S2.I1.ix1.p1.5.m5.7.7.2.2.2.2">𝑡</ci></apply><set id="S2.I1.ix1.p1.5.m5.7.7.2.2.3.1.cmml" xref="S2.I1.ix1.p1.5.m5.7.7.2.2.3.2"><cn type="integer" id="S2.I1.ix1.p1.5.m5.2.2.cmml" xref="S2.I1.ix1.p1.5.m5.2.2">1</cn><cn type="integer" id="S2.I1.ix1.p1.5.m5.3.3.cmml" xref="S2.I1.ix1.p1.5.m5.3.3">2</cn><ci id="S2.I1.ix1.p1.5.m5.4.4.cmml" xref="S2.I1.ix1.p1.5.m5.4.4">…</ci><ci id="S2.I1.ix1.p1.5.m5.5.5.cmml" xref="S2.I1.ix1.p1.5.m5.5.5">𝑇</ci></set></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.ix1.p1.5.m5.7c">|\mathcal{C}^{(t)}|=m,~{}\forall t\in\{1,2,\ldots,T\}</annotation></semantics></math>.</p>
</div>
</li>
<li id="S2.I1.ix2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><math id="S2.I1.ix2.1.1.m1.1" class="ltx_Math" alttext="(ii)" display="inline"><semantics id="S2.I1.ix2.1.1.m1.1b"><mrow id="S2.I1.ix2.1.1.m1.1.1.1" xref="S2.I1.ix2.1.1.m1.1.1.1.1.cmml"><mo stretchy="false" id="S2.I1.ix2.1.1.m1.1.1.1.2" xref="S2.I1.ix2.1.1.m1.1.1.1.1.cmml">(</mo><mrow id="S2.I1.ix2.1.1.m1.1.1.1.1" xref="S2.I1.ix2.1.1.m1.1.1.1.1.cmml"><mi id="S2.I1.ix2.1.1.m1.1.1.1.1.2" xref="S2.I1.ix2.1.1.m1.1.1.1.1.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S2.I1.ix2.1.1.m1.1.1.1.1.1" xref="S2.I1.ix2.1.1.m1.1.1.1.1.1.cmml">​</mo><mi id="S2.I1.ix2.1.1.m1.1.1.1.1.3" xref="S2.I1.ix2.1.1.m1.1.1.1.1.3.cmml">i</mi></mrow><mo stretchy="false" id="S2.I1.ix2.1.1.m1.1.1.1.3" xref="S2.I1.ix2.1.1.m1.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.ix2.1.1.m1.1c"><apply id="S2.I1.ix2.1.1.m1.1.1.1.1.cmml" xref="S2.I1.ix2.1.1.m1.1.1.1"><times id="S2.I1.ix2.1.1.m1.1.1.1.1.1.cmml" xref="S2.I1.ix2.1.1.m1.1.1.1.1.1"></times><ci id="S2.I1.ix2.1.1.m1.1.1.1.1.2.cmml" xref="S2.I1.ix2.1.1.m1.1.1.1.1.2">𝑖</ci><ci id="S2.I1.ix2.1.1.m1.1.1.1.1.3.cmml" xref="S2.I1.ix2.1.1.m1.1.1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.ix2.1.1.m1.1d">(ii)</annotation></semantics></math></span> 
<div id="S2.I1.ix2.p1" class="ltx_para">
<p id="S2.I1.ix2.p1.4" class="ltx_p">Each selected client <math id="S2.I1.ix2.p1.1.m1.1" class="ltx_Math" alttext="c\in{\mathcal{C}}^{(t)}" display="inline"><semantics id="S2.I1.ix2.p1.1.m1.1a"><mrow id="S2.I1.ix2.p1.1.m1.1.2" xref="S2.I1.ix2.p1.1.m1.1.2.cmml"><mi id="S2.I1.ix2.p1.1.m1.1.2.2" xref="S2.I1.ix2.p1.1.m1.1.2.2.cmml">c</mi><mo id="S2.I1.ix2.p1.1.m1.1.2.1" xref="S2.I1.ix2.p1.1.m1.1.2.1.cmml">∈</mo><msup id="S2.I1.ix2.p1.1.m1.1.2.3" xref="S2.I1.ix2.p1.1.m1.1.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.I1.ix2.p1.1.m1.1.2.3.2" xref="S2.I1.ix2.p1.1.m1.1.2.3.2.cmml">𝒞</mi><mrow id="S2.I1.ix2.p1.1.m1.1.1.1.3" xref="S2.I1.ix2.p1.1.m1.1.2.3.cmml"><mo stretchy="false" id="S2.I1.ix2.p1.1.m1.1.1.1.3.1" xref="S2.I1.ix2.p1.1.m1.1.2.3.cmml">(</mo><mi id="S2.I1.ix2.p1.1.m1.1.1.1.1" xref="S2.I1.ix2.p1.1.m1.1.1.1.1.cmml">t</mi><mo stretchy="false" id="S2.I1.ix2.p1.1.m1.1.1.1.3.2" xref="S2.I1.ix2.p1.1.m1.1.2.3.cmml">)</mo></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.ix2.p1.1.m1.1b"><apply id="S2.I1.ix2.p1.1.m1.1.2.cmml" xref="S2.I1.ix2.p1.1.m1.1.2"><in id="S2.I1.ix2.p1.1.m1.1.2.1.cmml" xref="S2.I1.ix2.p1.1.m1.1.2.1"></in><ci id="S2.I1.ix2.p1.1.m1.1.2.2.cmml" xref="S2.I1.ix2.p1.1.m1.1.2.2">𝑐</ci><apply id="S2.I1.ix2.p1.1.m1.1.2.3.cmml" xref="S2.I1.ix2.p1.1.m1.1.2.3"><csymbol cd="ambiguous" id="S2.I1.ix2.p1.1.m1.1.2.3.1.cmml" xref="S2.I1.ix2.p1.1.m1.1.2.3">superscript</csymbol><ci id="S2.I1.ix2.p1.1.m1.1.2.3.2.cmml" xref="S2.I1.ix2.p1.1.m1.1.2.3.2">𝒞</ci><ci id="S2.I1.ix2.p1.1.m1.1.1.1.1.cmml" xref="S2.I1.ix2.p1.1.m1.1.1.1.1">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.ix2.p1.1.m1.1c">c\in{\mathcal{C}}^{(t)}</annotation></semantics></math> trains its local model <math id="S2.I1.ix2.p1.2.m2.1" class="ltx_Math" alttext="\bm{\theta}_{c}^{(t)}" display="inline"><semantics id="S2.I1.ix2.p1.2.m2.1a"><msubsup id="S2.I1.ix2.p1.2.m2.1.2" xref="S2.I1.ix2.p1.2.m2.1.2.cmml"><mi id="S2.I1.ix2.p1.2.m2.1.2.2.2" xref="S2.I1.ix2.p1.2.m2.1.2.2.2.cmml">𝜽</mi><mi id="S2.I1.ix2.p1.2.m2.1.2.2.3" xref="S2.I1.ix2.p1.2.m2.1.2.2.3.cmml">c</mi><mrow id="S2.I1.ix2.p1.2.m2.1.1.1.3" xref="S2.I1.ix2.p1.2.m2.1.2.cmml"><mo stretchy="false" id="S2.I1.ix2.p1.2.m2.1.1.1.3.1" xref="S2.I1.ix2.p1.2.m2.1.2.cmml">(</mo><mi id="S2.I1.ix2.p1.2.m2.1.1.1.1" xref="S2.I1.ix2.p1.2.m2.1.1.1.1.cmml">t</mi><mo stretchy="false" id="S2.I1.ix2.p1.2.m2.1.1.1.3.2" xref="S2.I1.ix2.p1.2.m2.1.2.cmml">)</mo></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S2.I1.ix2.p1.2.m2.1b"><apply id="S2.I1.ix2.p1.2.m2.1.2.cmml" xref="S2.I1.ix2.p1.2.m2.1.2"><csymbol cd="ambiguous" id="S2.I1.ix2.p1.2.m2.1.2.1.cmml" xref="S2.I1.ix2.p1.2.m2.1.2">superscript</csymbol><apply id="S2.I1.ix2.p1.2.m2.1.2.2.cmml" xref="S2.I1.ix2.p1.2.m2.1.2"><csymbol cd="ambiguous" id="S2.I1.ix2.p1.2.m2.1.2.2.1.cmml" xref="S2.I1.ix2.p1.2.m2.1.2">subscript</csymbol><ci id="S2.I1.ix2.p1.2.m2.1.2.2.2.cmml" xref="S2.I1.ix2.p1.2.m2.1.2.2.2">𝜽</ci><ci id="S2.I1.ix2.p1.2.m2.1.2.2.3.cmml" xref="S2.I1.ix2.p1.2.m2.1.2.2.3">𝑐</ci></apply><ci id="S2.I1.ix2.p1.2.m2.1.1.1.1.cmml" xref="S2.I1.ix2.p1.2.m2.1.1.1.1">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.ix2.p1.2.m2.1c">\bm{\theta}_{c}^{(t)}</annotation></semantics></math> on its own private data <math id="S2.I1.ix2.p1.3.m3.1" class="ltx_Math" alttext="\mathcal{D}_{c}" display="inline"><semantics id="S2.I1.ix2.p1.3.m3.1a"><msub id="S2.I1.ix2.p1.3.m3.1.1" xref="S2.I1.ix2.p1.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.I1.ix2.p1.3.m3.1.1.2" xref="S2.I1.ix2.p1.3.m3.1.1.2.cmml">𝒟</mi><mi id="S2.I1.ix2.p1.3.m3.1.1.3" xref="S2.I1.ix2.p1.3.m3.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S2.I1.ix2.p1.3.m3.1b"><apply id="S2.I1.ix2.p1.3.m3.1.1.cmml" xref="S2.I1.ix2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S2.I1.ix2.p1.3.m3.1.1.1.cmml" xref="S2.I1.ix2.p1.3.m3.1.1">subscript</csymbol><ci id="S2.I1.ix2.p1.3.m3.1.1.2.cmml" xref="S2.I1.ix2.p1.3.m3.1.1.2">𝒟</ci><ci id="S2.I1.ix2.p1.3.m3.1.1.3.cmml" xref="S2.I1.ix2.p1.3.m3.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.ix2.p1.3.m3.1c">\mathcal{D}_{c}</annotation></semantics></math> by optimizing the following objective, starting from <math id="S2.I1.ix2.p1.4.m4.1" class="ltx_Math" alttext="\bm{\theta}^{(t)}" display="inline"><semantics id="S2.I1.ix2.p1.4.m4.1a"><msup id="S2.I1.ix2.p1.4.m4.1.2" xref="S2.I1.ix2.p1.4.m4.1.2.cmml"><mi id="S2.I1.ix2.p1.4.m4.1.2.2" xref="S2.I1.ix2.p1.4.m4.1.2.2.cmml">𝜽</mi><mrow id="S2.I1.ix2.p1.4.m4.1.1.1.3" xref="S2.I1.ix2.p1.4.m4.1.2.cmml"><mo stretchy="false" id="S2.I1.ix2.p1.4.m4.1.1.1.3.1" xref="S2.I1.ix2.p1.4.m4.1.2.cmml">(</mo><mi id="S2.I1.ix2.p1.4.m4.1.1.1.1" xref="S2.I1.ix2.p1.4.m4.1.1.1.1.cmml">t</mi><mo stretchy="false" id="S2.I1.ix2.p1.4.m4.1.1.1.3.2" xref="S2.I1.ix2.p1.4.m4.1.2.cmml">)</mo></mrow></msup><annotation-xml encoding="MathML-Content" id="S2.I1.ix2.p1.4.m4.1b"><apply id="S2.I1.ix2.p1.4.m4.1.2.cmml" xref="S2.I1.ix2.p1.4.m4.1.2"><csymbol cd="ambiguous" id="S2.I1.ix2.p1.4.m4.1.2.1.cmml" xref="S2.I1.ix2.p1.4.m4.1.2">superscript</csymbol><ci id="S2.I1.ix2.p1.4.m4.1.2.2.cmml" xref="S2.I1.ix2.p1.4.m4.1.2.2">𝜽</ci><ci id="S2.I1.ix2.p1.4.m4.1.1.1.1.cmml" xref="S2.I1.ix2.p1.4.m4.1.1.1.1">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.ix2.p1.4.m4.1c">\bm{\theta}^{(t)}</annotation></semantics></math>:</p>
<table id="S2.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(3)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E3.m1.4" class="ltx_Math" alttext="\bm{\theta}_{c}^{(t)}=\text{argmin}_{\bm{\theta}^{(t)}}\mathcal{L}_{c}(\bm{\theta}^{(t)};\mathcal{D}_{c})." display="block"><semantics id="S2.E3.m1.4a"><mrow id="S2.E3.m1.4.4.1" xref="S2.E3.m1.4.4.1.1.cmml"><mrow id="S2.E3.m1.4.4.1.1" xref="S2.E3.m1.4.4.1.1.cmml"><msubsup id="S2.E3.m1.4.4.1.1.4" xref="S2.E3.m1.4.4.1.1.4.cmml"><mi id="S2.E3.m1.4.4.1.1.4.2.2" xref="S2.E3.m1.4.4.1.1.4.2.2.cmml">𝜽</mi><mi id="S2.E3.m1.4.4.1.1.4.2.3" xref="S2.E3.m1.4.4.1.1.4.2.3.cmml">c</mi><mrow id="S2.E3.m1.1.1.1.3" xref="S2.E3.m1.4.4.1.1.4.cmml"><mo stretchy="false" id="S2.E3.m1.1.1.1.3.1" xref="S2.E3.m1.4.4.1.1.4.cmml">(</mo><mi id="S2.E3.m1.1.1.1.1" xref="S2.E3.m1.1.1.1.1.cmml">t</mi><mo stretchy="false" id="S2.E3.m1.1.1.1.3.2" xref="S2.E3.m1.4.4.1.1.4.cmml">)</mo></mrow></msubsup><mo id="S2.E3.m1.4.4.1.1.3" xref="S2.E3.m1.4.4.1.1.3.cmml">=</mo><mrow id="S2.E3.m1.4.4.1.1.2" xref="S2.E3.m1.4.4.1.1.2.cmml"><msub id="S2.E3.m1.4.4.1.1.2.4" xref="S2.E3.m1.4.4.1.1.2.4.cmml"><mtext id="S2.E3.m1.4.4.1.1.2.4.2" xref="S2.E3.m1.4.4.1.1.2.4.2a.cmml">argmin</mtext><msup id="S2.E3.m1.2.2.1" xref="S2.E3.m1.2.2.1.cmml"><mi id="S2.E3.m1.2.2.1.3" xref="S2.E3.m1.2.2.1.3.cmml">𝜽</mi><mrow id="S2.E3.m1.2.2.1.1.1.3" xref="S2.E3.m1.2.2.1.cmml"><mo stretchy="false" id="S2.E3.m1.2.2.1.1.1.3.1" xref="S2.E3.m1.2.2.1.cmml">(</mo><mi id="S2.E3.m1.2.2.1.1.1.1" xref="S2.E3.m1.2.2.1.1.1.1.cmml">t</mi><mo stretchy="false" id="S2.E3.m1.2.2.1.1.1.3.2" xref="S2.E3.m1.2.2.1.cmml">)</mo></mrow></msup></msub><mo lspace="0em" rspace="0em" id="S2.E3.m1.4.4.1.1.2.3" xref="S2.E3.m1.4.4.1.1.2.3.cmml">​</mo><msub id="S2.E3.m1.4.4.1.1.2.5" xref="S2.E3.m1.4.4.1.1.2.5.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E3.m1.4.4.1.1.2.5.2" xref="S2.E3.m1.4.4.1.1.2.5.2.cmml">ℒ</mi><mi id="S2.E3.m1.4.4.1.1.2.5.3" xref="S2.E3.m1.4.4.1.1.2.5.3.cmml">c</mi></msub><mo lspace="0em" rspace="0em" id="S2.E3.m1.4.4.1.1.2.3a" xref="S2.E3.m1.4.4.1.1.2.3.cmml">​</mo><mrow id="S2.E3.m1.4.4.1.1.2.2.2" xref="S2.E3.m1.4.4.1.1.2.2.3.cmml"><mo stretchy="false" id="S2.E3.m1.4.4.1.1.2.2.2.3" xref="S2.E3.m1.4.4.1.1.2.2.3.cmml">(</mo><msup id="S2.E3.m1.4.4.1.1.1.1.1.1" xref="S2.E3.m1.4.4.1.1.1.1.1.1.cmml"><mi id="S2.E3.m1.4.4.1.1.1.1.1.1.2" xref="S2.E3.m1.4.4.1.1.1.1.1.1.2.cmml">𝜽</mi><mrow id="S2.E3.m1.3.3.1.3" xref="S2.E3.m1.4.4.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.E3.m1.3.3.1.3.1" xref="S2.E3.m1.4.4.1.1.1.1.1.1.cmml">(</mo><mi id="S2.E3.m1.3.3.1.1" xref="S2.E3.m1.3.3.1.1.cmml">t</mi><mo stretchy="false" id="S2.E3.m1.3.3.1.3.2" xref="S2.E3.m1.4.4.1.1.1.1.1.1.cmml">)</mo></mrow></msup><mo id="S2.E3.m1.4.4.1.1.2.2.2.4" xref="S2.E3.m1.4.4.1.1.2.2.3.cmml">;</mo><msub id="S2.E3.m1.4.4.1.1.2.2.2.2" xref="S2.E3.m1.4.4.1.1.2.2.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E3.m1.4.4.1.1.2.2.2.2.2" xref="S2.E3.m1.4.4.1.1.2.2.2.2.2.cmml">𝒟</mi><mi id="S2.E3.m1.4.4.1.1.2.2.2.2.3" xref="S2.E3.m1.4.4.1.1.2.2.2.2.3.cmml">c</mi></msub><mo stretchy="false" id="S2.E3.m1.4.4.1.1.2.2.2.5" xref="S2.E3.m1.4.4.1.1.2.2.3.cmml">)</mo></mrow></mrow></mrow><mo lspace="0em" id="S2.E3.m1.4.4.1.2" xref="S2.E3.m1.4.4.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E3.m1.4b"><apply id="S2.E3.m1.4.4.1.1.cmml" xref="S2.E3.m1.4.4.1"><eq id="S2.E3.m1.4.4.1.1.3.cmml" xref="S2.E3.m1.4.4.1.1.3"></eq><apply id="S2.E3.m1.4.4.1.1.4.cmml" xref="S2.E3.m1.4.4.1.1.4"><csymbol cd="ambiguous" id="S2.E3.m1.4.4.1.1.4.1.cmml" xref="S2.E3.m1.4.4.1.1.4">superscript</csymbol><apply id="S2.E3.m1.4.4.1.1.4.2.cmml" xref="S2.E3.m1.4.4.1.1.4"><csymbol cd="ambiguous" id="S2.E3.m1.4.4.1.1.4.2.1.cmml" xref="S2.E3.m1.4.4.1.1.4">subscript</csymbol><ci id="S2.E3.m1.4.4.1.1.4.2.2.cmml" xref="S2.E3.m1.4.4.1.1.4.2.2">𝜽</ci><ci id="S2.E3.m1.4.4.1.1.4.2.3.cmml" xref="S2.E3.m1.4.4.1.1.4.2.3">𝑐</ci></apply><ci id="S2.E3.m1.1.1.1.1.cmml" xref="S2.E3.m1.1.1.1.1">𝑡</ci></apply><apply id="S2.E3.m1.4.4.1.1.2.cmml" xref="S2.E3.m1.4.4.1.1.2"><times id="S2.E3.m1.4.4.1.1.2.3.cmml" xref="S2.E3.m1.4.4.1.1.2.3"></times><apply id="S2.E3.m1.4.4.1.1.2.4.cmml" xref="S2.E3.m1.4.4.1.1.2.4"><csymbol cd="ambiguous" id="S2.E3.m1.4.4.1.1.2.4.1.cmml" xref="S2.E3.m1.4.4.1.1.2.4">subscript</csymbol><ci id="S2.E3.m1.4.4.1.1.2.4.2a.cmml" xref="S2.E3.m1.4.4.1.1.2.4.2"><mtext id="S2.E3.m1.4.4.1.1.2.4.2.cmml" xref="S2.E3.m1.4.4.1.1.2.4.2">argmin</mtext></ci><apply id="S2.E3.m1.2.2.1.cmml" xref="S2.E3.m1.2.2.1"><csymbol cd="ambiguous" id="S2.E3.m1.2.2.1.2.cmml" xref="S2.E3.m1.2.2.1">superscript</csymbol><ci id="S2.E3.m1.2.2.1.3.cmml" xref="S2.E3.m1.2.2.1.3">𝜽</ci><ci id="S2.E3.m1.2.2.1.1.1.1.cmml" xref="S2.E3.m1.2.2.1.1.1.1">𝑡</ci></apply></apply><apply id="S2.E3.m1.4.4.1.1.2.5.cmml" xref="S2.E3.m1.4.4.1.1.2.5"><csymbol cd="ambiguous" id="S2.E3.m1.4.4.1.1.2.5.1.cmml" xref="S2.E3.m1.4.4.1.1.2.5">subscript</csymbol><ci id="S2.E3.m1.4.4.1.1.2.5.2.cmml" xref="S2.E3.m1.4.4.1.1.2.5.2">ℒ</ci><ci id="S2.E3.m1.4.4.1.1.2.5.3.cmml" xref="S2.E3.m1.4.4.1.1.2.5.3">𝑐</ci></apply><list id="S2.E3.m1.4.4.1.1.2.2.3.cmml" xref="S2.E3.m1.4.4.1.1.2.2.2"><apply id="S2.E3.m1.4.4.1.1.1.1.1.1.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E3.m1.4.4.1.1.1.1.1.1.1.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.1">superscript</csymbol><ci id="S2.E3.m1.4.4.1.1.1.1.1.1.2.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.1.2">𝜽</ci><ci id="S2.E3.m1.3.3.1.1.cmml" xref="S2.E3.m1.3.3.1.1">𝑡</ci></apply><apply id="S2.E3.m1.4.4.1.1.2.2.2.2.cmml" xref="S2.E3.m1.4.4.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S2.E3.m1.4.4.1.1.2.2.2.2.1.cmml" xref="S2.E3.m1.4.4.1.1.2.2.2.2">subscript</csymbol><ci id="S2.E3.m1.4.4.1.1.2.2.2.2.2.cmml" xref="S2.E3.m1.4.4.1.1.2.2.2.2.2">𝒟</ci><ci id="S2.E3.m1.4.4.1.1.2.2.2.2.3.cmml" xref="S2.E3.m1.4.4.1.1.2.2.2.2.3">𝑐</ci></apply></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E3.m1.4c">\bm{\theta}_{c}^{(t)}=\text{argmin}_{\bm{\theta}^{(t)}}\mathcal{L}_{c}(\bm{\theta}^{(t)};\mathcal{D}_{c}).</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S2.I1.ix2.p1.6" class="ltx_p">The value <math id="S2.I1.ix2.p1.5.m1.1" class="ltx_Math" alttext="\bm{\theta}_{c}^{(t)}" display="inline"><semantics id="S2.I1.ix2.p1.5.m1.1a"><msubsup id="S2.I1.ix2.p1.5.m1.1.2" xref="S2.I1.ix2.p1.5.m1.1.2.cmml"><mi id="S2.I1.ix2.p1.5.m1.1.2.2.2" xref="S2.I1.ix2.p1.5.m1.1.2.2.2.cmml">𝜽</mi><mi id="S2.I1.ix2.p1.5.m1.1.2.2.3" xref="S2.I1.ix2.p1.5.m1.1.2.2.3.cmml">c</mi><mrow id="S2.I1.ix2.p1.5.m1.1.1.1.3" xref="S2.I1.ix2.p1.5.m1.1.2.cmml"><mo stretchy="false" id="S2.I1.ix2.p1.5.m1.1.1.1.3.1" xref="S2.I1.ix2.p1.5.m1.1.2.cmml">(</mo><mi id="S2.I1.ix2.p1.5.m1.1.1.1.1" xref="S2.I1.ix2.p1.5.m1.1.1.1.1.cmml">t</mi><mo stretchy="false" id="S2.I1.ix2.p1.5.m1.1.1.1.3.2" xref="S2.I1.ix2.p1.5.m1.1.2.cmml">)</mo></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S2.I1.ix2.p1.5.m1.1b"><apply id="S2.I1.ix2.p1.5.m1.1.2.cmml" xref="S2.I1.ix2.p1.5.m1.1.2"><csymbol cd="ambiguous" id="S2.I1.ix2.p1.5.m1.1.2.1.cmml" xref="S2.I1.ix2.p1.5.m1.1.2">superscript</csymbol><apply id="S2.I1.ix2.p1.5.m1.1.2.2.cmml" xref="S2.I1.ix2.p1.5.m1.1.2"><csymbol cd="ambiguous" id="S2.I1.ix2.p1.5.m1.1.2.2.1.cmml" xref="S2.I1.ix2.p1.5.m1.1.2">subscript</csymbol><ci id="S2.I1.ix2.p1.5.m1.1.2.2.2.cmml" xref="S2.I1.ix2.p1.5.m1.1.2.2.2">𝜽</ci><ci id="S2.I1.ix2.p1.5.m1.1.2.2.3.cmml" xref="S2.I1.ix2.p1.5.m1.1.2.2.3">𝑐</ci></apply><ci id="S2.I1.ix2.p1.5.m1.1.1.1.1.cmml" xref="S2.I1.ix2.p1.5.m1.1.1.1.1">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.ix2.p1.5.m1.1c">\bm{\theta}_{c}^{(t)}</annotation></semantics></math> is computed via gradient-based methods like stochastic gradient descent (SGD) and sent back to <math id="S2.I1.ix2.p1.6.m2.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S2.I1.ix2.p1.6.m2.1a"><mi id="S2.I1.ix2.p1.6.m2.1.1" xref="S2.I1.ix2.p1.6.m2.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S2.I1.ix2.p1.6.m2.1b"><ci id="S2.I1.ix2.p1.6.m2.1.1.cmml" xref="S2.I1.ix2.p1.6.m2.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.ix2.p1.6.m2.1c">S</annotation></semantics></math>.</p>
</div>
</li>
<li id="S2.I1.ix3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><math id="S2.I1.ix3.1.1.m1.1" class="ltx_Math" alttext="(iii)" display="inline"><semantics id="S2.I1.ix3.1.1.m1.1b"><mrow id="S2.I1.ix3.1.1.m1.1.1.1" xref="S2.I1.ix3.1.1.m1.1.1.1.1.cmml"><mo stretchy="false" id="S2.I1.ix3.1.1.m1.1.1.1.2" xref="S2.I1.ix3.1.1.m1.1.1.1.1.cmml">(</mo><mrow id="S2.I1.ix3.1.1.m1.1.1.1.1" xref="S2.I1.ix3.1.1.m1.1.1.1.1.cmml"><mi id="S2.I1.ix3.1.1.m1.1.1.1.1.2" xref="S2.I1.ix3.1.1.m1.1.1.1.1.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S2.I1.ix3.1.1.m1.1.1.1.1.1" xref="S2.I1.ix3.1.1.m1.1.1.1.1.1.cmml">​</mo><mi id="S2.I1.ix3.1.1.m1.1.1.1.1.3" xref="S2.I1.ix3.1.1.m1.1.1.1.1.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S2.I1.ix3.1.1.m1.1.1.1.1.1b" xref="S2.I1.ix3.1.1.m1.1.1.1.1.1.cmml">​</mo><mi id="S2.I1.ix3.1.1.m1.1.1.1.1.4" xref="S2.I1.ix3.1.1.m1.1.1.1.1.4.cmml">i</mi></mrow><mo stretchy="false" id="S2.I1.ix3.1.1.m1.1.1.1.3" xref="S2.I1.ix3.1.1.m1.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.ix3.1.1.m1.1c"><apply id="S2.I1.ix3.1.1.m1.1.1.1.1.cmml" xref="S2.I1.ix3.1.1.m1.1.1.1"><times id="S2.I1.ix3.1.1.m1.1.1.1.1.1.cmml" xref="S2.I1.ix3.1.1.m1.1.1.1.1.1"></times><ci id="S2.I1.ix3.1.1.m1.1.1.1.1.2.cmml" xref="S2.I1.ix3.1.1.m1.1.1.1.1.2">𝑖</ci><ci id="S2.I1.ix3.1.1.m1.1.1.1.1.3.cmml" xref="S2.I1.ix3.1.1.m1.1.1.1.1.3">𝑖</ci><ci id="S2.I1.ix3.1.1.m1.1.1.1.1.4.cmml" xref="S2.I1.ix3.1.1.m1.1.1.1.1.4">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.ix3.1.1.m1.1d">(iii)</annotation></semantics></math></span> 
<div id="S2.I1.ix3.p1" class="ltx_para">
<p id="S2.I1.ix3.p1.4" class="ltx_p"><math id="S2.I1.ix3.p1.1.m1.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S2.I1.ix3.p1.1.m1.1a"><mi id="S2.I1.ix3.p1.1.m1.1.1" xref="S2.I1.ix3.p1.1.m1.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S2.I1.ix3.p1.1.m1.1b"><ci id="S2.I1.ix3.p1.1.m1.1.1.cmml" xref="S2.I1.ix3.p1.1.m1.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.ix3.p1.1.m1.1c">S</annotation></semantics></math> computes <math id="S2.I1.ix3.p1.2.m2.4" class="ltx_Math" alttext="\bm{\theta}^{(t+1)}=\phi(\{\bm{\theta}_{c}^{(t)}~{}|~{}c\in\mathcal{C}^{(t)}\})" display="inline"><semantics id="S2.I1.ix3.p1.2.m2.4a"><mrow id="S2.I1.ix3.p1.2.m2.4.4" xref="S2.I1.ix3.p1.2.m2.4.4.cmml"><msup id="S2.I1.ix3.p1.2.m2.4.4.3" xref="S2.I1.ix3.p1.2.m2.4.4.3.cmml"><mi id="S2.I1.ix3.p1.2.m2.4.4.3.2" xref="S2.I1.ix3.p1.2.m2.4.4.3.2.cmml">𝜽</mi><mrow id="S2.I1.ix3.p1.2.m2.1.1.1.1" xref="S2.I1.ix3.p1.2.m2.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.I1.ix3.p1.2.m2.1.1.1.1.2" xref="S2.I1.ix3.p1.2.m2.1.1.1.1.1.cmml">(</mo><mrow id="S2.I1.ix3.p1.2.m2.1.1.1.1.1" xref="S2.I1.ix3.p1.2.m2.1.1.1.1.1.cmml"><mi id="S2.I1.ix3.p1.2.m2.1.1.1.1.1.2" xref="S2.I1.ix3.p1.2.m2.1.1.1.1.1.2.cmml">t</mi><mo id="S2.I1.ix3.p1.2.m2.1.1.1.1.1.1" xref="S2.I1.ix3.p1.2.m2.1.1.1.1.1.1.cmml">+</mo><mn id="S2.I1.ix3.p1.2.m2.1.1.1.1.1.3" xref="S2.I1.ix3.p1.2.m2.1.1.1.1.1.3.cmml">1</mn></mrow><mo stretchy="false" id="S2.I1.ix3.p1.2.m2.1.1.1.1.3" xref="S2.I1.ix3.p1.2.m2.1.1.1.1.1.cmml">)</mo></mrow></msup><mo id="S2.I1.ix3.p1.2.m2.4.4.2" xref="S2.I1.ix3.p1.2.m2.4.4.2.cmml">=</mo><mrow id="S2.I1.ix3.p1.2.m2.4.4.1" xref="S2.I1.ix3.p1.2.m2.4.4.1.cmml"><mi id="S2.I1.ix3.p1.2.m2.4.4.1.3" xref="S2.I1.ix3.p1.2.m2.4.4.1.3.cmml">ϕ</mi><mo lspace="0em" rspace="0em" id="S2.I1.ix3.p1.2.m2.4.4.1.2" xref="S2.I1.ix3.p1.2.m2.4.4.1.2.cmml">​</mo><mrow id="S2.I1.ix3.p1.2.m2.4.4.1.1.1" xref="S2.I1.ix3.p1.2.m2.4.4.1.cmml"><mo stretchy="false" id="S2.I1.ix3.p1.2.m2.4.4.1.1.1.2" xref="S2.I1.ix3.p1.2.m2.4.4.1.cmml">(</mo><mrow id="S2.I1.ix3.p1.2.m2.4.4.1.1.1.1.2" xref="S2.I1.ix3.p1.2.m2.4.4.1.1.1.1.3.cmml"><mo stretchy="false" id="S2.I1.ix3.p1.2.m2.4.4.1.1.1.1.2.3" xref="S2.I1.ix3.p1.2.m2.4.4.1.1.1.1.3.1.cmml">{</mo><msubsup id="S2.I1.ix3.p1.2.m2.4.4.1.1.1.1.1.1" xref="S2.I1.ix3.p1.2.m2.4.4.1.1.1.1.1.1.cmml"><mi id="S2.I1.ix3.p1.2.m2.4.4.1.1.1.1.1.1.2.2" xref="S2.I1.ix3.p1.2.m2.4.4.1.1.1.1.1.1.2.2.cmml">𝜽</mi><mi id="S2.I1.ix3.p1.2.m2.4.4.1.1.1.1.1.1.2.3" xref="S2.I1.ix3.p1.2.m2.4.4.1.1.1.1.1.1.2.3.cmml">c</mi><mrow id="S2.I1.ix3.p1.2.m2.2.2.1.3" xref="S2.I1.ix3.p1.2.m2.4.4.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.I1.ix3.p1.2.m2.2.2.1.3.1" xref="S2.I1.ix3.p1.2.m2.4.4.1.1.1.1.1.1.cmml">(</mo><mi id="S2.I1.ix3.p1.2.m2.2.2.1.1" xref="S2.I1.ix3.p1.2.m2.2.2.1.1.cmml">t</mi><mo stretchy="false" id="S2.I1.ix3.p1.2.m2.2.2.1.3.2" xref="S2.I1.ix3.p1.2.m2.4.4.1.1.1.1.1.1.cmml">)</mo></mrow></msubsup><mo lspace="0em" rspace="0.330em" id="S2.I1.ix3.p1.2.m2.4.4.1.1.1.1.2.4" xref="S2.I1.ix3.p1.2.m2.4.4.1.1.1.1.3.1.cmml">|</mo><mrow id="S2.I1.ix3.p1.2.m2.4.4.1.1.1.1.2.2" xref="S2.I1.ix3.p1.2.m2.4.4.1.1.1.1.2.2.cmml"><mi id="S2.I1.ix3.p1.2.m2.4.4.1.1.1.1.2.2.2" xref="S2.I1.ix3.p1.2.m2.4.4.1.1.1.1.2.2.2.cmml">c</mi><mo id="S2.I1.ix3.p1.2.m2.4.4.1.1.1.1.2.2.1" xref="S2.I1.ix3.p1.2.m2.4.4.1.1.1.1.2.2.1.cmml">∈</mo><msup id="S2.I1.ix3.p1.2.m2.4.4.1.1.1.1.2.2.3" xref="S2.I1.ix3.p1.2.m2.4.4.1.1.1.1.2.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.I1.ix3.p1.2.m2.4.4.1.1.1.1.2.2.3.2" xref="S2.I1.ix3.p1.2.m2.4.4.1.1.1.1.2.2.3.2.cmml">𝒞</mi><mrow id="S2.I1.ix3.p1.2.m2.3.3.1.3" xref="S2.I1.ix3.p1.2.m2.4.4.1.1.1.1.2.2.3.cmml"><mo stretchy="false" id="S2.I1.ix3.p1.2.m2.3.3.1.3.1" xref="S2.I1.ix3.p1.2.m2.4.4.1.1.1.1.2.2.3.cmml">(</mo><mi id="S2.I1.ix3.p1.2.m2.3.3.1.1" xref="S2.I1.ix3.p1.2.m2.3.3.1.1.cmml">t</mi><mo stretchy="false" id="S2.I1.ix3.p1.2.m2.3.3.1.3.2" xref="S2.I1.ix3.p1.2.m2.4.4.1.1.1.1.2.2.3.cmml">)</mo></mrow></msup></mrow><mo stretchy="false" id="S2.I1.ix3.p1.2.m2.4.4.1.1.1.1.2.5" xref="S2.I1.ix3.p1.2.m2.4.4.1.1.1.1.3.1.cmml">}</mo></mrow><mo stretchy="false" id="S2.I1.ix3.p1.2.m2.4.4.1.1.1.3" xref="S2.I1.ix3.p1.2.m2.4.4.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.ix3.p1.2.m2.4b"><apply id="S2.I1.ix3.p1.2.m2.4.4.cmml" xref="S2.I1.ix3.p1.2.m2.4.4"><eq id="S2.I1.ix3.p1.2.m2.4.4.2.cmml" xref="S2.I1.ix3.p1.2.m2.4.4.2"></eq><apply id="S2.I1.ix3.p1.2.m2.4.4.3.cmml" xref="S2.I1.ix3.p1.2.m2.4.4.3"><csymbol cd="ambiguous" id="S2.I1.ix3.p1.2.m2.4.4.3.1.cmml" xref="S2.I1.ix3.p1.2.m2.4.4.3">superscript</csymbol><ci id="S2.I1.ix3.p1.2.m2.4.4.3.2.cmml" xref="S2.I1.ix3.p1.2.m2.4.4.3.2">𝜽</ci><apply id="S2.I1.ix3.p1.2.m2.1.1.1.1.1.cmml" xref="S2.I1.ix3.p1.2.m2.1.1.1.1"><plus id="S2.I1.ix3.p1.2.m2.1.1.1.1.1.1.cmml" xref="S2.I1.ix3.p1.2.m2.1.1.1.1.1.1"></plus><ci id="S2.I1.ix3.p1.2.m2.1.1.1.1.1.2.cmml" xref="S2.I1.ix3.p1.2.m2.1.1.1.1.1.2">𝑡</ci><cn type="integer" id="S2.I1.ix3.p1.2.m2.1.1.1.1.1.3.cmml" xref="S2.I1.ix3.p1.2.m2.1.1.1.1.1.3">1</cn></apply></apply><apply id="S2.I1.ix3.p1.2.m2.4.4.1.cmml" xref="S2.I1.ix3.p1.2.m2.4.4.1"><times id="S2.I1.ix3.p1.2.m2.4.4.1.2.cmml" xref="S2.I1.ix3.p1.2.m2.4.4.1.2"></times><ci id="S2.I1.ix3.p1.2.m2.4.4.1.3.cmml" xref="S2.I1.ix3.p1.2.m2.4.4.1.3">italic-ϕ</ci><apply id="S2.I1.ix3.p1.2.m2.4.4.1.1.1.1.3.cmml" xref="S2.I1.ix3.p1.2.m2.4.4.1.1.1.1.2"><csymbol cd="latexml" id="S2.I1.ix3.p1.2.m2.4.4.1.1.1.1.3.1.cmml" xref="S2.I1.ix3.p1.2.m2.4.4.1.1.1.1.2.3">conditional-set</csymbol><apply id="S2.I1.ix3.p1.2.m2.4.4.1.1.1.1.1.1.cmml" xref="S2.I1.ix3.p1.2.m2.4.4.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.I1.ix3.p1.2.m2.4.4.1.1.1.1.1.1.1.cmml" xref="S2.I1.ix3.p1.2.m2.4.4.1.1.1.1.1.1">superscript</csymbol><apply id="S2.I1.ix3.p1.2.m2.4.4.1.1.1.1.1.1.2.cmml" xref="S2.I1.ix3.p1.2.m2.4.4.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.I1.ix3.p1.2.m2.4.4.1.1.1.1.1.1.2.1.cmml" xref="S2.I1.ix3.p1.2.m2.4.4.1.1.1.1.1.1">subscript</csymbol><ci id="S2.I1.ix3.p1.2.m2.4.4.1.1.1.1.1.1.2.2.cmml" xref="S2.I1.ix3.p1.2.m2.4.4.1.1.1.1.1.1.2.2">𝜽</ci><ci id="S2.I1.ix3.p1.2.m2.4.4.1.1.1.1.1.1.2.3.cmml" xref="S2.I1.ix3.p1.2.m2.4.4.1.1.1.1.1.1.2.3">𝑐</ci></apply><ci id="S2.I1.ix3.p1.2.m2.2.2.1.1.cmml" xref="S2.I1.ix3.p1.2.m2.2.2.1.1">𝑡</ci></apply><apply id="S2.I1.ix3.p1.2.m2.4.4.1.1.1.1.2.2.cmml" xref="S2.I1.ix3.p1.2.m2.4.4.1.1.1.1.2.2"><in id="S2.I1.ix3.p1.2.m2.4.4.1.1.1.1.2.2.1.cmml" xref="S2.I1.ix3.p1.2.m2.4.4.1.1.1.1.2.2.1"></in><ci id="S2.I1.ix3.p1.2.m2.4.4.1.1.1.1.2.2.2.cmml" xref="S2.I1.ix3.p1.2.m2.4.4.1.1.1.1.2.2.2">𝑐</ci><apply id="S2.I1.ix3.p1.2.m2.4.4.1.1.1.1.2.2.3.cmml" xref="S2.I1.ix3.p1.2.m2.4.4.1.1.1.1.2.2.3"><csymbol cd="ambiguous" id="S2.I1.ix3.p1.2.m2.4.4.1.1.1.1.2.2.3.1.cmml" xref="S2.I1.ix3.p1.2.m2.4.4.1.1.1.1.2.2.3">superscript</csymbol><ci id="S2.I1.ix3.p1.2.m2.4.4.1.1.1.1.2.2.3.2.cmml" xref="S2.I1.ix3.p1.2.m2.4.4.1.1.1.1.2.2.3.2">𝒞</ci><ci id="S2.I1.ix3.p1.2.m2.3.3.1.1.cmml" xref="S2.I1.ix3.p1.2.m2.3.3.1.1">𝑡</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.ix3.p1.2.m2.4c">\bm{\theta}^{(t+1)}=\phi(\{\bm{\theta}_{c}^{(t)}~{}|~{}c\in\mathcal{C}^{(t)}\})</annotation></semantics></math> as the updated global model, where <math id="S2.I1.ix3.p1.3.m3.1" class="ltx_Math" alttext="\phi:\mathbb{R}^{d^{m}}\mapsto\mathbb{R}^{d}" display="inline"><semantics id="S2.I1.ix3.p1.3.m3.1a"><mrow id="S2.I1.ix3.p1.3.m3.1.1" xref="S2.I1.ix3.p1.3.m3.1.1.cmml"><mi id="S2.I1.ix3.p1.3.m3.1.1.2" xref="S2.I1.ix3.p1.3.m3.1.1.2.cmml">ϕ</mi><mo lspace="0.278em" rspace="0.278em" id="S2.I1.ix3.p1.3.m3.1.1.1" xref="S2.I1.ix3.p1.3.m3.1.1.1.cmml">:</mo><mrow id="S2.I1.ix3.p1.3.m3.1.1.3" xref="S2.I1.ix3.p1.3.m3.1.1.3.cmml"><msup id="S2.I1.ix3.p1.3.m3.1.1.3.2" xref="S2.I1.ix3.p1.3.m3.1.1.3.2.cmml"><mi id="S2.I1.ix3.p1.3.m3.1.1.3.2.2" xref="S2.I1.ix3.p1.3.m3.1.1.3.2.2.cmml">ℝ</mi><msup id="S2.I1.ix3.p1.3.m3.1.1.3.2.3" xref="S2.I1.ix3.p1.3.m3.1.1.3.2.3.cmml"><mi id="S2.I1.ix3.p1.3.m3.1.1.3.2.3.2" xref="S2.I1.ix3.p1.3.m3.1.1.3.2.3.2.cmml">d</mi><mi id="S2.I1.ix3.p1.3.m3.1.1.3.2.3.3" xref="S2.I1.ix3.p1.3.m3.1.1.3.2.3.3.cmml">m</mi></msup></msup><mo stretchy="false" id="S2.I1.ix3.p1.3.m3.1.1.3.1" xref="S2.I1.ix3.p1.3.m3.1.1.3.1.cmml">↦</mo><msup id="S2.I1.ix3.p1.3.m3.1.1.3.3" xref="S2.I1.ix3.p1.3.m3.1.1.3.3.cmml"><mi id="S2.I1.ix3.p1.3.m3.1.1.3.3.2" xref="S2.I1.ix3.p1.3.m3.1.1.3.3.2.cmml">ℝ</mi><mi id="S2.I1.ix3.p1.3.m3.1.1.3.3.3" xref="S2.I1.ix3.p1.3.m3.1.1.3.3.3.cmml">d</mi></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.ix3.p1.3.m3.1b"><apply id="S2.I1.ix3.p1.3.m3.1.1.cmml" xref="S2.I1.ix3.p1.3.m3.1.1"><ci id="S2.I1.ix3.p1.3.m3.1.1.1.cmml" xref="S2.I1.ix3.p1.3.m3.1.1.1">:</ci><ci id="S2.I1.ix3.p1.3.m3.1.1.2.cmml" xref="S2.I1.ix3.p1.3.m3.1.1.2">italic-ϕ</ci><apply id="S2.I1.ix3.p1.3.m3.1.1.3.cmml" xref="S2.I1.ix3.p1.3.m3.1.1.3"><csymbol cd="latexml" id="S2.I1.ix3.p1.3.m3.1.1.3.1.cmml" xref="S2.I1.ix3.p1.3.m3.1.1.3.1">maps-to</csymbol><apply id="S2.I1.ix3.p1.3.m3.1.1.3.2.cmml" xref="S2.I1.ix3.p1.3.m3.1.1.3.2"><csymbol cd="ambiguous" id="S2.I1.ix3.p1.3.m3.1.1.3.2.1.cmml" xref="S2.I1.ix3.p1.3.m3.1.1.3.2">superscript</csymbol><ci id="S2.I1.ix3.p1.3.m3.1.1.3.2.2.cmml" xref="S2.I1.ix3.p1.3.m3.1.1.3.2.2">ℝ</ci><apply id="S2.I1.ix3.p1.3.m3.1.1.3.2.3.cmml" xref="S2.I1.ix3.p1.3.m3.1.1.3.2.3"><csymbol cd="ambiguous" id="S2.I1.ix3.p1.3.m3.1.1.3.2.3.1.cmml" xref="S2.I1.ix3.p1.3.m3.1.1.3.2.3">superscript</csymbol><ci id="S2.I1.ix3.p1.3.m3.1.1.3.2.3.2.cmml" xref="S2.I1.ix3.p1.3.m3.1.1.3.2.3.2">𝑑</ci><ci id="S2.I1.ix3.p1.3.m3.1.1.3.2.3.3.cmml" xref="S2.I1.ix3.p1.3.m3.1.1.3.2.3.3">𝑚</ci></apply></apply><apply id="S2.I1.ix3.p1.3.m3.1.1.3.3.cmml" xref="S2.I1.ix3.p1.3.m3.1.1.3.3"><csymbol cd="ambiguous" id="S2.I1.ix3.p1.3.m3.1.1.3.3.1.cmml" xref="S2.I1.ix3.p1.3.m3.1.1.3.3">superscript</csymbol><ci id="S2.I1.ix3.p1.3.m3.1.1.3.3.2.cmml" xref="S2.I1.ix3.p1.3.m3.1.1.3.3.2">ℝ</ci><ci id="S2.I1.ix3.p1.3.m3.1.1.3.3.3.cmml" xref="S2.I1.ix3.p1.3.m3.1.1.3.3.3">𝑑</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.ix3.p1.3.m3.1c">\phi:\mathbb{R}^{d^{m}}\mapsto\mathbb{R}^{d}</annotation></semantics></math> is an <em id="S2.I1.ix3.p1.4.1" class="ltx_emph ltx_font_italic">aggregation function</em>; for example, <math id="S2.I1.ix3.p1.4.m4.2" class="ltx_Math" alttext="\phi=\frac{1}{m}\sum_{c\in\mathcal{C}^{(t)}}\bm{\theta}_{c}^{(t)}" display="inline"><semantics id="S2.I1.ix3.p1.4.m4.2a"><mrow id="S2.I1.ix3.p1.4.m4.2.3" xref="S2.I1.ix3.p1.4.m4.2.3.cmml"><mi id="S2.I1.ix3.p1.4.m4.2.3.2" xref="S2.I1.ix3.p1.4.m4.2.3.2.cmml">ϕ</mi><mo id="S2.I1.ix3.p1.4.m4.2.3.1" xref="S2.I1.ix3.p1.4.m4.2.3.1.cmml">=</mo><mrow id="S2.I1.ix3.p1.4.m4.2.3.3" xref="S2.I1.ix3.p1.4.m4.2.3.3.cmml"><mfrac id="S2.I1.ix3.p1.4.m4.2.3.3.2" xref="S2.I1.ix3.p1.4.m4.2.3.3.2.cmml"><mn id="S2.I1.ix3.p1.4.m4.2.3.3.2.2" xref="S2.I1.ix3.p1.4.m4.2.3.3.2.2.cmml">1</mn><mi id="S2.I1.ix3.p1.4.m4.2.3.3.2.3" xref="S2.I1.ix3.p1.4.m4.2.3.3.2.3.cmml">m</mi></mfrac><mo lspace="0em" rspace="0em" id="S2.I1.ix3.p1.4.m4.2.3.3.1" xref="S2.I1.ix3.p1.4.m4.2.3.3.1.cmml">​</mo><mrow id="S2.I1.ix3.p1.4.m4.2.3.3.3" xref="S2.I1.ix3.p1.4.m4.2.3.3.3.cmml"><msub id="S2.I1.ix3.p1.4.m4.2.3.3.3.1" xref="S2.I1.ix3.p1.4.m4.2.3.3.3.1.cmml"><mo id="S2.I1.ix3.p1.4.m4.2.3.3.3.1.2" xref="S2.I1.ix3.p1.4.m4.2.3.3.3.1.2.cmml">∑</mo><mrow id="S2.I1.ix3.p1.4.m4.1.1.1" xref="S2.I1.ix3.p1.4.m4.1.1.1.cmml"><mi id="S2.I1.ix3.p1.4.m4.1.1.1.3" xref="S2.I1.ix3.p1.4.m4.1.1.1.3.cmml">c</mi><mo id="S2.I1.ix3.p1.4.m4.1.1.1.2" xref="S2.I1.ix3.p1.4.m4.1.1.1.2.cmml">∈</mo><msup id="S2.I1.ix3.p1.4.m4.1.1.1.4" xref="S2.I1.ix3.p1.4.m4.1.1.1.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.I1.ix3.p1.4.m4.1.1.1.4.2" xref="S2.I1.ix3.p1.4.m4.1.1.1.4.2.cmml">𝒞</mi><mrow id="S2.I1.ix3.p1.4.m4.1.1.1.1.1.3" xref="S2.I1.ix3.p1.4.m4.1.1.1.4.cmml"><mo stretchy="false" id="S2.I1.ix3.p1.4.m4.1.1.1.1.1.3.1" xref="S2.I1.ix3.p1.4.m4.1.1.1.4.cmml">(</mo><mi id="S2.I1.ix3.p1.4.m4.1.1.1.1.1.1" xref="S2.I1.ix3.p1.4.m4.1.1.1.1.1.1.cmml">t</mi><mo stretchy="false" id="S2.I1.ix3.p1.4.m4.1.1.1.1.1.3.2" xref="S2.I1.ix3.p1.4.m4.1.1.1.4.cmml">)</mo></mrow></msup></mrow></msub><msubsup id="S2.I1.ix3.p1.4.m4.2.3.3.3.2" xref="S2.I1.ix3.p1.4.m4.2.3.3.3.2.cmml"><mi id="S2.I1.ix3.p1.4.m4.2.3.3.3.2.2.2" xref="S2.I1.ix3.p1.4.m4.2.3.3.3.2.2.2.cmml">𝜽</mi><mi id="S2.I1.ix3.p1.4.m4.2.3.3.3.2.2.3" xref="S2.I1.ix3.p1.4.m4.2.3.3.3.2.2.3.cmml">c</mi><mrow id="S2.I1.ix3.p1.4.m4.2.2.1.3" xref="S2.I1.ix3.p1.4.m4.2.3.3.3.2.cmml"><mo stretchy="false" id="S2.I1.ix3.p1.4.m4.2.2.1.3.1" xref="S2.I1.ix3.p1.4.m4.2.3.3.3.2.cmml">(</mo><mi id="S2.I1.ix3.p1.4.m4.2.2.1.1" xref="S2.I1.ix3.p1.4.m4.2.2.1.1.cmml">t</mi><mo stretchy="false" id="S2.I1.ix3.p1.4.m4.2.2.1.3.2" xref="S2.I1.ix3.p1.4.m4.2.3.3.3.2.cmml">)</mo></mrow></msubsup></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.ix3.p1.4.m4.2b"><apply id="S2.I1.ix3.p1.4.m4.2.3.cmml" xref="S2.I1.ix3.p1.4.m4.2.3"><eq id="S2.I1.ix3.p1.4.m4.2.3.1.cmml" xref="S2.I1.ix3.p1.4.m4.2.3.1"></eq><ci id="S2.I1.ix3.p1.4.m4.2.3.2.cmml" xref="S2.I1.ix3.p1.4.m4.2.3.2">italic-ϕ</ci><apply id="S2.I1.ix3.p1.4.m4.2.3.3.cmml" xref="S2.I1.ix3.p1.4.m4.2.3.3"><times id="S2.I1.ix3.p1.4.m4.2.3.3.1.cmml" xref="S2.I1.ix3.p1.4.m4.2.3.3.1"></times><apply id="S2.I1.ix3.p1.4.m4.2.3.3.2.cmml" xref="S2.I1.ix3.p1.4.m4.2.3.3.2"><divide id="S2.I1.ix3.p1.4.m4.2.3.3.2.1.cmml" xref="S2.I1.ix3.p1.4.m4.2.3.3.2"></divide><cn type="integer" id="S2.I1.ix3.p1.4.m4.2.3.3.2.2.cmml" xref="S2.I1.ix3.p1.4.m4.2.3.3.2.2">1</cn><ci id="S2.I1.ix3.p1.4.m4.2.3.3.2.3.cmml" xref="S2.I1.ix3.p1.4.m4.2.3.3.2.3">𝑚</ci></apply><apply id="S2.I1.ix3.p1.4.m4.2.3.3.3.cmml" xref="S2.I1.ix3.p1.4.m4.2.3.3.3"><apply id="S2.I1.ix3.p1.4.m4.2.3.3.3.1.cmml" xref="S2.I1.ix3.p1.4.m4.2.3.3.3.1"><csymbol cd="ambiguous" id="S2.I1.ix3.p1.4.m4.2.3.3.3.1.1.cmml" xref="S2.I1.ix3.p1.4.m4.2.3.3.3.1">subscript</csymbol><sum id="S2.I1.ix3.p1.4.m4.2.3.3.3.1.2.cmml" xref="S2.I1.ix3.p1.4.m4.2.3.3.3.1.2"></sum><apply id="S2.I1.ix3.p1.4.m4.1.1.1.cmml" xref="S2.I1.ix3.p1.4.m4.1.1.1"><in id="S2.I1.ix3.p1.4.m4.1.1.1.2.cmml" xref="S2.I1.ix3.p1.4.m4.1.1.1.2"></in><ci id="S2.I1.ix3.p1.4.m4.1.1.1.3.cmml" xref="S2.I1.ix3.p1.4.m4.1.1.1.3">𝑐</ci><apply id="S2.I1.ix3.p1.4.m4.1.1.1.4.cmml" xref="S2.I1.ix3.p1.4.m4.1.1.1.4"><csymbol cd="ambiguous" id="S2.I1.ix3.p1.4.m4.1.1.1.4.1.cmml" xref="S2.I1.ix3.p1.4.m4.1.1.1.4">superscript</csymbol><ci id="S2.I1.ix3.p1.4.m4.1.1.1.4.2.cmml" xref="S2.I1.ix3.p1.4.m4.1.1.1.4.2">𝒞</ci><ci id="S2.I1.ix3.p1.4.m4.1.1.1.1.1.1.cmml" xref="S2.I1.ix3.p1.4.m4.1.1.1.1.1.1">𝑡</ci></apply></apply></apply><apply id="S2.I1.ix3.p1.4.m4.2.3.3.3.2.cmml" xref="S2.I1.ix3.p1.4.m4.2.3.3.3.2"><csymbol cd="ambiguous" id="S2.I1.ix3.p1.4.m4.2.3.3.3.2.1.cmml" xref="S2.I1.ix3.p1.4.m4.2.3.3.3.2">superscript</csymbol><apply id="S2.I1.ix3.p1.4.m4.2.3.3.3.2.2.cmml" xref="S2.I1.ix3.p1.4.m4.2.3.3.3.2"><csymbol cd="ambiguous" id="S2.I1.ix3.p1.4.m4.2.3.3.3.2.2.1.cmml" xref="S2.I1.ix3.p1.4.m4.2.3.3.3.2">subscript</csymbol><ci id="S2.I1.ix3.p1.4.m4.2.3.3.3.2.2.2.cmml" xref="S2.I1.ix3.p1.4.m4.2.3.3.3.2.2.2">𝜽</ci><ci id="S2.I1.ix3.p1.4.m4.2.3.3.3.2.2.3.cmml" xref="S2.I1.ix3.p1.4.m4.2.3.3.3.2.2.3">𝑐</ci></apply><ci id="S2.I1.ix3.p1.4.m4.2.2.1.1.cmml" xref="S2.I1.ix3.p1.4.m4.2.2.1.1">𝑡</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.ix3.p1.4.m4.2c">\phi=\frac{1}{m}\sum_{c\in\mathcal{C}^{(t)}}\bm{\theta}_{c}^{(t)}</annotation></semantics></math>, i.e., FedAvg or one of its variants <cite class="ltx_cite ltx_citemacro_citep">(Lu and Fan, <a href="#bib.bib51" title="" class="ltx_ref">2020</a>)</cite>.</p>
</div>
</li>
</ol>
<p id="S2.SS1.p3.13" class="ltx_p">A few alternatives to the scheme above are possible. For example, in step <math id="S2.SS1.p3.3.m1.1" class="ltx_Math" alttext="(ii)" display="inline"><semantics id="S2.SS1.p3.3.m1.1a"><mrow id="S2.SS1.p3.3.m1.1.1.1" xref="S2.SS1.p3.3.m1.1.1.1.1.cmml"><mo stretchy="false" id="S2.SS1.p3.3.m1.1.1.1.2" xref="S2.SS1.p3.3.m1.1.1.1.1.cmml">(</mo><mrow id="S2.SS1.p3.3.m1.1.1.1.1" xref="S2.SS1.p3.3.m1.1.1.1.1.cmml"><mi id="S2.SS1.p3.3.m1.1.1.1.1.2" xref="S2.SS1.p3.3.m1.1.1.1.1.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p3.3.m1.1.1.1.1.1" xref="S2.SS1.p3.3.m1.1.1.1.1.1.cmml">​</mo><mi id="S2.SS1.p3.3.m1.1.1.1.1.3" xref="S2.SS1.p3.3.m1.1.1.1.1.3.cmml">i</mi></mrow><mo stretchy="false" id="S2.SS1.p3.3.m1.1.1.1.3" xref="S2.SS1.p3.3.m1.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.3.m1.1b"><apply id="S2.SS1.p3.3.m1.1.1.1.1.cmml" xref="S2.SS1.p3.3.m1.1.1.1"><times id="S2.SS1.p3.3.m1.1.1.1.1.1.cmml" xref="S2.SS1.p3.3.m1.1.1.1.1.1"></times><ci id="S2.SS1.p3.3.m1.1.1.1.1.2.cmml" xref="S2.SS1.p3.3.m1.1.1.1.1.2">𝑖</ci><ci id="S2.SS1.p3.3.m1.1.1.1.1.3.cmml" xref="S2.SS1.p3.3.m1.1.1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.3.m1.1c">(ii)</annotation></semantics></math>, instead of sending the vector of parameters <math id="S2.SS1.p3.4.m2.1" class="ltx_Math" alttext="\bm{\theta}_{c}^{(t)}" display="inline"><semantics id="S2.SS1.p3.4.m2.1a"><msubsup id="S2.SS1.p3.4.m2.1.2" xref="S2.SS1.p3.4.m2.1.2.cmml"><mi id="S2.SS1.p3.4.m2.1.2.2.2" xref="S2.SS1.p3.4.m2.1.2.2.2.cmml">𝜽</mi><mi id="S2.SS1.p3.4.m2.1.2.2.3" xref="S2.SS1.p3.4.m2.1.2.2.3.cmml">c</mi><mrow id="S2.SS1.p3.4.m2.1.1.1.3" xref="S2.SS1.p3.4.m2.1.2.cmml"><mo stretchy="false" id="S2.SS1.p3.4.m2.1.1.1.3.1" xref="S2.SS1.p3.4.m2.1.2.cmml">(</mo><mi id="S2.SS1.p3.4.m2.1.1.1.1" xref="S2.SS1.p3.4.m2.1.1.1.1.cmml">t</mi><mo stretchy="false" id="S2.SS1.p3.4.m2.1.1.1.3.2" xref="S2.SS1.p3.4.m2.1.2.cmml">)</mo></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.4.m2.1b"><apply id="S2.SS1.p3.4.m2.1.2.cmml" xref="S2.SS1.p3.4.m2.1.2"><csymbol cd="ambiguous" id="S2.SS1.p3.4.m2.1.2.1.cmml" xref="S2.SS1.p3.4.m2.1.2">superscript</csymbol><apply id="S2.SS1.p3.4.m2.1.2.2.cmml" xref="S2.SS1.p3.4.m2.1.2"><csymbol cd="ambiguous" id="S2.SS1.p3.4.m2.1.2.2.1.cmml" xref="S2.SS1.p3.4.m2.1.2">subscript</csymbol><ci id="S2.SS1.p3.4.m2.1.2.2.2.cmml" xref="S2.SS1.p3.4.m2.1.2.2.2">𝜽</ci><ci id="S2.SS1.p3.4.m2.1.2.2.3.cmml" xref="S2.SS1.p3.4.m2.1.2.2.3">𝑐</ci></apply><ci id="S2.SS1.p3.4.m2.1.1.1.1.cmml" xref="S2.SS1.p3.4.m2.1.1.1.1">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.4.m2.1c">\bm{\theta}_{c}^{(t)}</annotation></semantics></math>, each selected client could transmit to the server its displacement vector compared to the global model received at the beginning of the round, i.e., <math id="S2.SS1.p3.5.m3.3" class="ltx_Math" alttext="\bm{u}_{c}^{(t)}=\bm{\theta}_{c}^{(t)}-\bm{\theta}^{(t)}" display="inline"><semantics id="S2.SS1.p3.5.m3.3a"><mrow id="S2.SS1.p3.5.m3.3.4" xref="S2.SS1.p3.5.m3.3.4.cmml"><msubsup id="S2.SS1.p3.5.m3.3.4.2" xref="S2.SS1.p3.5.m3.3.4.2.cmml"><mi id="S2.SS1.p3.5.m3.3.4.2.2.2" xref="S2.SS1.p3.5.m3.3.4.2.2.2.cmml">𝒖</mi><mi id="S2.SS1.p3.5.m3.3.4.2.2.3" xref="S2.SS1.p3.5.m3.3.4.2.2.3.cmml">c</mi><mrow id="S2.SS1.p3.5.m3.1.1.1.3" xref="S2.SS1.p3.5.m3.3.4.2.cmml"><mo stretchy="false" id="S2.SS1.p3.5.m3.1.1.1.3.1" xref="S2.SS1.p3.5.m3.3.4.2.cmml">(</mo><mi id="S2.SS1.p3.5.m3.1.1.1.1" xref="S2.SS1.p3.5.m3.1.1.1.1.cmml">t</mi><mo stretchy="false" id="S2.SS1.p3.5.m3.1.1.1.3.2" xref="S2.SS1.p3.5.m3.3.4.2.cmml">)</mo></mrow></msubsup><mo id="S2.SS1.p3.5.m3.3.4.1" xref="S2.SS1.p3.5.m3.3.4.1.cmml">=</mo><mrow id="S2.SS1.p3.5.m3.3.4.3" xref="S2.SS1.p3.5.m3.3.4.3.cmml"><msubsup id="S2.SS1.p3.5.m3.3.4.3.2" xref="S2.SS1.p3.5.m3.3.4.3.2.cmml"><mi id="S2.SS1.p3.5.m3.3.4.3.2.2.2" xref="S2.SS1.p3.5.m3.3.4.3.2.2.2.cmml">𝜽</mi><mi id="S2.SS1.p3.5.m3.3.4.3.2.2.3" xref="S2.SS1.p3.5.m3.3.4.3.2.2.3.cmml">c</mi><mrow id="S2.SS1.p3.5.m3.2.2.1.3" xref="S2.SS1.p3.5.m3.3.4.3.2.cmml"><mo stretchy="false" id="S2.SS1.p3.5.m3.2.2.1.3.1" xref="S2.SS1.p3.5.m3.3.4.3.2.cmml">(</mo><mi id="S2.SS1.p3.5.m3.2.2.1.1" xref="S2.SS1.p3.5.m3.2.2.1.1.cmml">t</mi><mo stretchy="false" id="S2.SS1.p3.5.m3.2.2.1.3.2" xref="S2.SS1.p3.5.m3.3.4.3.2.cmml">)</mo></mrow></msubsup><mo id="S2.SS1.p3.5.m3.3.4.3.1" xref="S2.SS1.p3.5.m3.3.4.3.1.cmml">−</mo><msup id="S2.SS1.p3.5.m3.3.4.3.3" xref="S2.SS1.p3.5.m3.3.4.3.3.cmml"><mi id="S2.SS1.p3.5.m3.3.4.3.3.2" xref="S2.SS1.p3.5.m3.3.4.3.3.2.cmml">𝜽</mi><mrow id="S2.SS1.p3.5.m3.3.3.1.3" xref="S2.SS1.p3.5.m3.3.4.3.3.cmml"><mo stretchy="false" id="S2.SS1.p3.5.m3.3.3.1.3.1" xref="S2.SS1.p3.5.m3.3.4.3.3.cmml">(</mo><mi id="S2.SS1.p3.5.m3.3.3.1.1" xref="S2.SS1.p3.5.m3.3.3.1.1.cmml">t</mi><mo stretchy="false" id="S2.SS1.p3.5.m3.3.3.1.3.2" xref="S2.SS1.p3.5.m3.3.4.3.3.cmml">)</mo></mrow></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.5.m3.3b"><apply id="S2.SS1.p3.5.m3.3.4.cmml" xref="S2.SS1.p3.5.m3.3.4"><eq id="S2.SS1.p3.5.m3.3.4.1.cmml" xref="S2.SS1.p3.5.m3.3.4.1"></eq><apply id="S2.SS1.p3.5.m3.3.4.2.cmml" xref="S2.SS1.p3.5.m3.3.4.2"><csymbol cd="ambiguous" id="S2.SS1.p3.5.m3.3.4.2.1.cmml" xref="S2.SS1.p3.5.m3.3.4.2">superscript</csymbol><apply id="S2.SS1.p3.5.m3.3.4.2.2.cmml" xref="S2.SS1.p3.5.m3.3.4.2"><csymbol cd="ambiguous" id="S2.SS1.p3.5.m3.3.4.2.2.1.cmml" xref="S2.SS1.p3.5.m3.3.4.2">subscript</csymbol><ci id="S2.SS1.p3.5.m3.3.4.2.2.2.cmml" xref="S2.SS1.p3.5.m3.3.4.2.2.2">𝒖</ci><ci id="S2.SS1.p3.5.m3.3.4.2.2.3.cmml" xref="S2.SS1.p3.5.m3.3.4.2.2.3">𝑐</ci></apply><ci id="S2.SS1.p3.5.m3.1.1.1.1.cmml" xref="S2.SS1.p3.5.m3.1.1.1.1">𝑡</ci></apply><apply id="S2.SS1.p3.5.m3.3.4.3.cmml" xref="S2.SS1.p3.5.m3.3.4.3"><minus id="S2.SS1.p3.5.m3.3.4.3.1.cmml" xref="S2.SS1.p3.5.m3.3.4.3.1"></minus><apply id="S2.SS1.p3.5.m3.3.4.3.2.cmml" xref="S2.SS1.p3.5.m3.3.4.3.2"><csymbol cd="ambiguous" id="S2.SS1.p3.5.m3.3.4.3.2.1.cmml" xref="S2.SS1.p3.5.m3.3.4.3.2">superscript</csymbol><apply id="S2.SS1.p3.5.m3.3.4.3.2.2.cmml" xref="S2.SS1.p3.5.m3.3.4.3.2"><csymbol cd="ambiguous" id="S2.SS1.p3.5.m3.3.4.3.2.2.1.cmml" xref="S2.SS1.p3.5.m3.3.4.3.2">subscript</csymbol><ci id="S2.SS1.p3.5.m3.3.4.3.2.2.2.cmml" xref="S2.SS1.p3.5.m3.3.4.3.2.2.2">𝜽</ci><ci id="S2.SS1.p3.5.m3.3.4.3.2.2.3.cmml" xref="S2.SS1.p3.5.m3.3.4.3.2.2.3">𝑐</ci></apply><ci id="S2.SS1.p3.5.m3.2.2.1.1.cmml" xref="S2.SS1.p3.5.m3.2.2.1.1">𝑡</ci></apply><apply id="S2.SS1.p3.5.m3.3.4.3.3.cmml" xref="S2.SS1.p3.5.m3.3.4.3.3"><csymbol cd="ambiguous" id="S2.SS1.p3.5.m3.3.4.3.3.1.cmml" xref="S2.SS1.p3.5.m3.3.4.3.3">superscript</csymbol><ci id="S2.SS1.p3.5.m3.3.4.3.3.2.cmml" xref="S2.SS1.p3.5.m3.3.4.3.3.2">𝜽</ci><ci id="S2.SS1.p3.5.m3.3.3.1.1.cmml" xref="S2.SS1.p3.5.m3.3.3.1.1">𝑡</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.5.m3.3c">\bm{u}_{c}^{(t)}=\bm{\theta}_{c}^{(t)}-\bm{\theta}^{(t)}</annotation></semantics></math>.
This way, in step <math id="S2.SS1.p3.6.m4.1" class="ltx_Math" alttext="(iii)" display="inline"><semantics id="S2.SS1.p3.6.m4.1a"><mrow id="S2.SS1.p3.6.m4.1.1.1" xref="S2.SS1.p3.6.m4.1.1.1.1.cmml"><mo stretchy="false" id="S2.SS1.p3.6.m4.1.1.1.2" xref="S2.SS1.p3.6.m4.1.1.1.1.cmml">(</mo><mrow id="S2.SS1.p3.6.m4.1.1.1.1" xref="S2.SS1.p3.6.m4.1.1.1.1.cmml"><mi id="S2.SS1.p3.6.m4.1.1.1.1.2" xref="S2.SS1.p3.6.m4.1.1.1.1.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p3.6.m4.1.1.1.1.1" xref="S2.SS1.p3.6.m4.1.1.1.1.1.cmml">​</mo><mi id="S2.SS1.p3.6.m4.1.1.1.1.3" xref="S2.SS1.p3.6.m4.1.1.1.1.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p3.6.m4.1.1.1.1.1a" xref="S2.SS1.p3.6.m4.1.1.1.1.1.cmml">​</mo><mi id="S2.SS1.p3.6.m4.1.1.1.1.4" xref="S2.SS1.p3.6.m4.1.1.1.1.4.cmml">i</mi></mrow><mo stretchy="false" id="S2.SS1.p3.6.m4.1.1.1.3" xref="S2.SS1.p3.6.m4.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.6.m4.1b"><apply id="S2.SS1.p3.6.m4.1.1.1.1.cmml" xref="S2.SS1.p3.6.m4.1.1.1"><times id="S2.SS1.p3.6.m4.1.1.1.1.1.cmml" xref="S2.SS1.p3.6.m4.1.1.1.1.1"></times><ci id="S2.SS1.p3.6.m4.1.1.1.1.2.cmml" xref="S2.SS1.p3.6.m4.1.1.1.1.2">𝑖</ci><ci id="S2.SS1.p3.6.m4.1.1.1.1.3.cmml" xref="S2.SS1.p3.6.m4.1.1.1.1.3">𝑖</ci><ci id="S2.SS1.p3.6.m4.1.1.1.1.4.cmml" xref="S2.SS1.p3.6.m4.1.1.1.1.4">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.6.m4.1c">(iii)</annotation></semantics></math>, the server will compute the new global model as <math id="S2.SS1.p3.7.m5.5" class="ltx_Math" alttext="\bm{\theta}^{(t+1)}=\bm{\theta}^{(t)}+\phi(\{\bm{u}_{c}^{(t)}~{}|~{}c\in\mathcal{C}^{(t)}\})" display="inline"><semantics id="S2.SS1.p3.7.m5.5a"><mrow id="S2.SS1.p3.7.m5.5.5" xref="S2.SS1.p3.7.m5.5.5.cmml"><msup id="S2.SS1.p3.7.m5.5.5.3" xref="S2.SS1.p3.7.m5.5.5.3.cmml"><mi id="S2.SS1.p3.7.m5.5.5.3.2" xref="S2.SS1.p3.7.m5.5.5.3.2.cmml">𝜽</mi><mrow id="S2.SS1.p3.7.m5.1.1.1.1" xref="S2.SS1.p3.7.m5.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.SS1.p3.7.m5.1.1.1.1.2" xref="S2.SS1.p3.7.m5.1.1.1.1.1.cmml">(</mo><mrow id="S2.SS1.p3.7.m5.1.1.1.1.1" xref="S2.SS1.p3.7.m5.1.1.1.1.1.cmml"><mi id="S2.SS1.p3.7.m5.1.1.1.1.1.2" xref="S2.SS1.p3.7.m5.1.1.1.1.1.2.cmml">t</mi><mo id="S2.SS1.p3.7.m5.1.1.1.1.1.1" xref="S2.SS1.p3.7.m5.1.1.1.1.1.1.cmml">+</mo><mn id="S2.SS1.p3.7.m5.1.1.1.1.1.3" xref="S2.SS1.p3.7.m5.1.1.1.1.1.3.cmml">1</mn></mrow><mo stretchy="false" id="S2.SS1.p3.7.m5.1.1.1.1.3" xref="S2.SS1.p3.7.m5.1.1.1.1.1.cmml">)</mo></mrow></msup><mo id="S2.SS1.p3.7.m5.5.5.2" xref="S2.SS1.p3.7.m5.5.5.2.cmml">=</mo><mrow id="S2.SS1.p3.7.m5.5.5.1" xref="S2.SS1.p3.7.m5.5.5.1.cmml"><msup id="S2.SS1.p3.7.m5.5.5.1.3" xref="S2.SS1.p3.7.m5.5.5.1.3.cmml"><mi id="S2.SS1.p3.7.m5.5.5.1.3.2" xref="S2.SS1.p3.7.m5.5.5.1.3.2.cmml">𝜽</mi><mrow id="S2.SS1.p3.7.m5.2.2.1.3" xref="S2.SS1.p3.7.m5.5.5.1.3.cmml"><mo stretchy="false" id="S2.SS1.p3.7.m5.2.2.1.3.1" xref="S2.SS1.p3.7.m5.5.5.1.3.cmml">(</mo><mi id="S2.SS1.p3.7.m5.2.2.1.1" xref="S2.SS1.p3.7.m5.2.2.1.1.cmml">t</mi><mo stretchy="false" id="S2.SS1.p3.7.m5.2.2.1.3.2" xref="S2.SS1.p3.7.m5.5.5.1.3.cmml">)</mo></mrow></msup><mo id="S2.SS1.p3.7.m5.5.5.1.2" xref="S2.SS1.p3.7.m5.5.5.1.2.cmml">+</mo><mrow id="S2.SS1.p3.7.m5.5.5.1.1" xref="S2.SS1.p3.7.m5.5.5.1.1.cmml"><mi id="S2.SS1.p3.7.m5.5.5.1.1.3" xref="S2.SS1.p3.7.m5.5.5.1.1.3.cmml">ϕ</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p3.7.m5.5.5.1.1.2" xref="S2.SS1.p3.7.m5.5.5.1.1.2.cmml">​</mo><mrow id="S2.SS1.p3.7.m5.5.5.1.1.1.1" xref="S2.SS1.p3.7.m5.5.5.1.1.cmml"><mo stretchy="false" id="S2.SS1.p3.7.m5.5.5.1.1.1.1.2" xref="S2.SS1.p3.7.m5.5.5.1.1.cmml">(</mo><mrow id="S2.SS1.p3.7.m5.5.5.1.1.1.1.1.2" xref="S2.SS1.p3.7.m5.5.5.1.1.1.1.1.3.cmml"><mo stretchy="false" id="S2.SS1.p3.7.m5.5.5.1.1.1.1.1.2.3" xref="S2.SS1.p3.7.m5.5.5.1.1.1.1.1.3.1.cmml">{</mo><msubsup id="S2.SS1.p3.7.m5.5.5.1.1.1.1.1.1.1" xref="S2.SS1.p3.7.m5.5.5.1.1.1.1.1.1.1.cmml"><mi id="S2.SS1.p3.7.m5.5.5.1.1.1.1.1.1.1.2.2" xref="S2.SS1.p3.7.m5.5.5.1.1.1.1.1.1.1.2.2.cmml">𝒖</mi><mi id="S2.SS1.p3.7.m5.5.5.1.1.1.1.1.1.1.2.3" xref="S2.SS1.p3.7.m5.5.5.1.1.1.1.1.1.1.2.3.cmml">c</mi><mrow id="S2.SS1.p3.7.m5.3.3.1.3" xref="S2.SS1.p3.7.m5.5.5.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.SS1.p3.7.m5.3.3.1.3.1" xref="S2.SS1.p3.7.m5.5.5.1.1.1.1.1.1.1.cmml">(</mo><mi id="S2.SS1.p3.7.m5.3.3.1.1" xref="S2.SS1.p3.7.m5.3.3.1.1.cmml">t</mi><mo stretchy="false" id="S2.SS1.p3.7.m5.3.3.1.3.2" xref="S2.SS1.p3.7.m5.5.5.1.1.1.1.1.1.1.cmml">)</mo></mrow></msubsup><mo lspace="0em" rspace="0.330em" id="S2.SS1.p3.7.m5.5.5.1.1.1.1.1.2.4" xref="S2.SS1.p3.7.m5.5.5.1.1.1.1.1.3.1.cmml">|</mo><mrow id="S2.SS1.p3.7.m5.5.5.1.1.1.1.1.2.2" xref="S2.SS1.p3.7.m5.5.5.1.1.1.1.1.2.2.cmml"><mi id="S2.SS1.p3.7.m5.5.5.1.1.1.1.1.2.2.2" xref="S2.SS1.p3.7.m5.5.5.1.1.1.1.1.2.2.2.cmml">c</mi><mo id="S2.SS1.p3.7.m5.5.5.1.1.1.1.1.2.2.1" xref="S2.SS1.p3.7.m5.5.5.1.1.1.1.1.2.2.1.cmml">∈</mo><msup id="S2.SS1.p3.7.m5.5.5.1.1.1.1.1.2.2.3" xref="S2.SS1.p3.7.m5.5.5.1.1.1.1.1.2.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p3.7.m5.5.5.1.1.1.1.1.2.2.3.2" xref="S2.SS1.p3.7.m5.5.5.1.1.1.1.1.2.2.3.2.cmml">𝒞</mi><mrow id="S2.SS1.p3.7.m5.4.4.1.3" xref="S2.SS1.p3.7.m5.5.5.1.1.1.1.1.2.2.3.cmml"><mo stretchy="false" id="S2.SS1.p3.7.m5.4.4.1.3.1" xref="S2.SS1.p3.7.m5.5.5.1.1.1.1.1.2.2.3.cmml">(</mo><mi id="S2.SS1.p3.7.m5.4.4.1.1" xref="S2.SS1.p3.7.m5.4.4.1.1.cmml">t</mi><mo stretchy="false" id="S2.SS1.p3.7.m5.4.4.1.3.2" xref="S2.SS1.p3.7.m5.5.5.1.1.1.1.1.2.2.3.cmml">)</mo></mrow></msup></mrow><mo stretchy="false" id="S2.SS1.p3.7.m5.5.5.1.1.1.1.1.2.5" xref="S2.SS1.p3.7.m5.5.5.1.1.1.1.1.3.1.cmml">}</mo></mrow><mo stretchy="false" id="S2.SS1.p3.7.m5.5.5.1.1.1.1.3" xref="S2.SS1.p3.7.m5.5.5.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.7.m5.5b"><apply id="S2.SS1.p3.7.m5.5.5.cmml" xref="S2.SS1.p3.7.m5.5.5"><eq id="S2.SS1.p3.7.m5.5.5.2.cmml" xref="S2.SS1.p3.7.m5.5.5.2"></eq><apply id="S2.SS1.p3.7.m5.5.5.3.cmml" xref="S2.SS1.p3.7.m5.5.5.3"><csymbol cd="ambiguous" id="S2.SS1.p3.7.m5.5.5.3.1.cmml" xref="S2.SS1.p3.7.m5.5.5.3">superscript</csymbol><ci id="S2.SS1.p3.7.m5.5.5.3.2.cmml" xref="S2.SS1.p3.7.m5.5.5.3.2">𝜽</ci><apply id="S2.SS1.p3.7.m5.1.1.1.1.1.cmml" xref="S2.SS1.p3.7.m5.1.1.1.1"><plus id="S2.SS1.p3.7.m5.1.1.1.1.1.1.cmml" xref="S2.SS1.p3.7.m5.1.1.1.1.1.1"></plus><ci id="S2.SS1.p3.7.m5.1.1.1.1.1.2.cmml" xref="S2.SS1.p3.7.m5.1.1.1.1.1.2">𝑡</ci><cn type="integer" id="S2.SS1.p3.7.m5.1.1.1.1.1.3.cmml" xref="S2.SS1.p3.7.m5.1.1.1.1.1.3">1</cn></apply></apply><apply id="S2.SS1.p3.7.m5.5.5.1.cmml" xref="S2.SS1.p3.7.m5.5.5.1"><plus id="S2.SS1.p3.7.m5.5.5.1.2.cmml" xref="S2.SS1.p3.7.m5.5.5.1.2"></plus><apply id="S2.SS1.p3.7.m5.5.5.1.3.cmml" xref="S2.SS1.p3.7.m5.5.5.1.3"><csymbol cd="ambiguous" id="S2.SS1.p3.7.m5.5.5.1.3.1.cmml" xref="S2.SS1.p3.7.m5.5.5.1.3">superscript</csymbol><ci id="S2.SS1.p3.7.m5.5.5.1.3.2.cmml" xref="S2.SS1.p3.7.m5.5.5.1.3.2">𝜽</ci><ci id="S2.SS1.p3.7.m5.2.2.1.1.cmml" xref="S2.SS1.p3.7.m5.2.2.1.1">𝑡</ci></apply><apply id="S2.SS1.p3.7.m5.5.5.1.1.cmml" xref="S2.SS1.p3.7.m5.5.5.1.1"><times id="S2.SS1.p3.7.m5.5.5.1.1.2.cmml" xref="S2.SS1.p3.7.m5.5.5.1.1.2"></times><ci id="S2.SS1.p3.7.m5.5.5.1.1.3.cmml" xref="S2.SS1.p3.7.m5.5.5.1.1.3">italic-ϕ</ci><apply id="S2.SS1.p3.7.m5.5.5.1.1.1.1.1.3.cmml" xref="S2.SS1.p3.7.m5.5.5.1.1.1.1.1.2"><csymbol cd="latexml" id="S2.SS1.p3.7.m5.5.5.1.1.1.1.1.3.1.cmml" xref="S2.SS1.p3.7.m5.5.5.1.1.1.1.1.2.3">conditional-set</csymbol><apply id="S2.SS1.p3.7.m5.5.5.1.1.1.1.1.1.1.cmml" xref="S2.SS1.p3.7.m5.5.5.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p3.7.m5.5.5.1.1.1.1.1.1.1.1.cmml" xref="S2.SS1.p3.7.m5.5.5.1.1.1.1.1.1.1">superscript</csymbol><apply id="S2.SS1.p3.7.m5.5.5.1.1.1.1.1.1.1.2.cmml" xref="S2.SS1.p3.7.m5.5.5.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p3.7.m5.5.5.1.1.1.1.1.1.1.2.1.cmml" xref="S2.SS1.p3.7.m5.5.5.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.SS1.p3.7.m5.5.5.1.1.1.1.1.1.1.2.2.cmml" xref="S2.SS1.p3.7.m5.5.5.1.1.1.1.1.1.1.2.2">𝒖</ci><ci id="S2.SS1.p3.7.m5.5.5.1.1.1.1.1.1.1.2.3.cmml" xref="S2.SS1.p3.7.m5.5.5.1.1.1.1.1.1.1.2.3">𝑐</ci></apply><ci id="S2.SS1.p3.7.m5.3.3.1.1.cmml" xref="S2.SS1.p3.7.m5.3.3.1.1">𝑡</ci></apply><apply id="S2.SS1.p3.7.m5.5.5.1.1.1.1.1.2.2.cmml" xref="S2.SS1.p3.7.m5.5.5.1.1.1.1.1.2.2"><in id="S2.SS1.p3.7.m5.5.5.1.1.1.1.1.2.2.1.cmml" xref="S2.SS1.p3.7.m5.5.5.1.1.1.1.1.2.2.1"></in><ci id="S2.SS1.p3.7.m5.5.5.1.1.1.1.1.2.2.2.cmml" xref="S2.SS1.p3.7.m5.5.5.1.1.1.1.1.2.2.2">𝑐</ci><apply id="S2.SS1.p3.7.m5.5.5.1.1.1.1.1.2.2.3.cmml" xref="S2.SS1.p3.7.m5.5.5.1.1.1.1.1.2.2.3"><csymbol cd="ambiguous" id="S2.SS1.p3.7.m5.5.5.1.1.1.1.1.2.2.3.1.cmml" xref="S2.SS1.p3.7.m5.5.5.1.1.1.1.1.2.2.3">superscript</csymbol><ci id="S2.SS1.p3.7.m5.5.5.1.1.1.1.1.2.2.3.2.cmml" xref="S2.SS1.p3.7.m5.5.5.1.1.1.1.1.2.2.3.2">𝒞</ci><ci id="S2.SS1.p3.7.m5.4.4.1.1.cmml" xref="S2.SS1.p3.7.m5.4.4.1.1">𝑡</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.7.m5.5c">\bm{\theta}^{(t+1)}=\bm{\theta}^{(t)}+\phi(\{\bm{u}_{c}^{(t)}~{}|~{}c\in\mathcal{C}^{(t)}\})</annotation></semantics></math>, namely the aggregation function is calculated on the local update vectors rather than the actual local models.
Similarly, sending local models (or their updates) <math id="S2.SS1.p3.8.m6.1" class="ltx_Math" alttext="\bm{\theta}_{c}^{(t)}" display="inline"><semantics id="S2.SS1.p3.8.m6.1a"><msubsup id="S2.SS1.p3.8.m6.1.2" xref="S2.SS1.p3.8.m6.1.2.cmml"><mi id="S2.SS1.p3.8.m6.1.2.2.2" xref="S2.SS1.p3.8.m6.1.2.2.2.cmml">𝜽</mi><mi id="S2.SS1.p3.8.m6.1.2.2.3" xref="S2.SS1.p3.8.m6.1.2.2.3.cmml">c</mi><mrow id="S2.SS1.p3.8.m6.1.1.1.3" xref="S2.SS1.p3.8.m6.1.2.cmml"><mo stretchy="false" id="S2.SS1.p3.8.m6.1.1.1.3.1" xref="S2.SS1.p3.8.m6.1.2.cmml">(</mo><mi id="S2.SS1.p3.8.m6.1.1.1.1" xref="S2.SS1.p3.8.m6.1.1.1.1.cmml">t</mi><mo stretchy="false" id="S2.SS1.p3.8.m6.1.1.1.3.2" xref="S2.SS1.p3.8.m6.1.2.cmml">)</mo></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.8.m6.1b"><apply id="S2.SS1.p3.8.m6.1.2.cmml" xref="S2.SS1.p3.8.m6.1.2"><csymbol cd="ambiguous" id="S2.SS1.p3.8.m6.1.2.1.cmml" xref="S2.SS1.p3.8.m6.1.2">superscript</csymbol><apply id="S2.SS1.p3.8.m6.1.2.2.cmml" xref="S2.SS1.p3.8.m6.1.2"><csymbol cd="ambiguous" id="S2.SS1.p3.8.m6.1.2.2.1.cmml" xref="S2.SS1.p3.8.m6.1.2">subscript</csymbol><ci id="S2.SS1.p3.8.m6.1.2.2.2.cmml" xref="S2.SS1.p3.8.m6.1.2.2.2">𝜽</ci><ci id="S2.SS1.p3.8.m6.1.2.2.3.cmml" xref="S2.SS1.p3.8.m6.1.2.2.3">𝑐</ci></apply><ci id="S2.SS1.p3.8.m6.1.1.1.1.cmml" xref="S2.SS1.p3.8.m6.1.1.1.1">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.8.m6.1c">\bm{\theta}_{c}^{(t)}</annotation></semantics></math> (<math id="S2.SS1.p3.9.m7.1" class="ltx_Math" alttext="\bm{u}_{c}^{(t)}" display="inline"><semantics id="S2.SS1.p3.9.m7.1a"><msubsup id="S2.SS1.p3.9.m7.1.2" xref="S2.SS1.p3.9.m7.1.2.cmml"><mi id="S2.SS1.p3.9.m7.1.2.2.2" xref="S2.SS1.p3.9.m7.1.2.2.2.cmml">𝒖</mi><mi id="S2.SS1.p3.9.m7.1.2.2.3" xref="S2.SS1.p3.9.m7.1.2.2.3.cmml">c</mi><mrow id="S2.SS1.p3.9.m7.1.1.1.3" xref="S2.SS1.p3.9.m7.1.2.cmml"><mo stretchy="false" id="S2.SS1.p3.9.m7.1.1.1.3.1" xref="S2.SS1.p3.9.m7.1.2.cmml">(</mo><mi id="S2.SS1.p3.9.m7.1.1.1.1" xref="S2.SS1.p3.9.m7.1.1.1.1.cmml">t</mi><mo stretchy="false" id="S2.SS1.p3.9.m7.1.1.1.3.2" xref="S2.SS1.p3.9.m7.1.2.cmml">)</mo></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.9.m7.1b"><apply id="S2.SS1.p3.9.m7.1.2.cmml" xref="S2.SS1.p3.9.m7.1.2"><csymbol cd="ambiguous" id="S2.SS1.p3.9.m7.1.2.1.cmml" xref="S2.SS1.p3.9.m7.1.2">superscript</csymbol><apply id="S2.SS1.p3.9.m7.1.2.2.cmml" xref="S2.SS1.p3.9.m7.1.2"><csymbol cd="ambiguous" id="S2.SS1.p3.9.m7.1.2.2.1.cmml" xref="S2.SS1.p3.9.m7.1.2">subscript</csymbol><ci id="S2.SS1.p3.9.m7.1.2.2.2.cmml" xref="S2.SS1.p3.9.m7.1.2.2.2">𝒖</ci><ci id="S2.SS1.p3.9.m7.1.2.2.3.cmml" xref="S2.SS1.p3.9.m7.1.2.2.3">𝑐</ci></apply><ci id="S2.SS1.p3.9.m7.1.1.1.1.cmml" xref="S2.SS1.p3.9.m7.1.1.1.1">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.9.m7.1c">\bm{u}_{c}^{(t)}</annotation></semantics></math>) is equivalent to sending “raw” gradients <math id="S2.SS1.p3.10.m8.1" class="ltx_Math" alttext="\nabla\mathcal{L}_{c}^{(t)}" display="inline"><semantics id="S2.SS1.p3.10.m8.1a"><mrow id="S2.SS1.p3.10.m8.1.2" xref="S2.SS1.p3.10.m8.1.2.cmml"><mo rspace="0.167em" id="S2.SS1.p3.10.m8.1.2.1" xref="S2.SS1.p3.10.m8.1.2.1.cmml">∇</mo><msubsup id="S2.SS1.p3.10.m8.1.2.2" xref="S2.SS1.p3.10.m8.1.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p3.10.m8.1.2.2.2.2" xref="S2.SS1.p3.10.m8.1.2.2.2.2.cmml">ℒ</mi><mi id="S2.SS1.p3.10.m8.1.2.2.2.3" xref="S2.SS1.p3.10.m8.1.2.2.2.3.cmml">c</mi><mrow id="S2.SS1.p3.10.m8.1.1.1.3" xref="S2.SS1.p3.10.m8.1.2.2.cmml"><mo stretchy="false" id="S2.SS1.p3.10.m8.1.1.1.3.1" xref="S2.SS1.p3.10.m8.1.2.2.cmml">(</mo><mi id="S2.SS1.p3.10.m8.1.1.1.1" xref="S2.SS1.p3.10.m8.1.1.1.1.cmml">t</mi><mo stretchy="false" id="S2.SS1.p3.10.m8.1.1.1.3.2" xref="S2.SS1.p3.10.m8.1.2.2.cmml">)</mo></mrow></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.10.m8.1b"><apply id="S2.SS1.p3.10.m8.1.2.cmml" xref="S2.SS1.p3.10.m8.1.2"><ci id="S2.SS1.p3.10.m8.1.2.1.cmml" xref="S2.SS1.p3.10.m8.1.2.1">∇</ci><apply id="S2.SS1.p3.10.m8.1.2.2.cmml" xref="S2.SS1.p3.10.m8.1.2.2"><csymbol cd="ambiguous" id="S2.SS1.p3.10.m8.1.2.2.1.cmml" xref="S2.SS1.p3.10.m8.1.2.2">superscript</csymbol><apply id="S2.SS1.p3.10.m8.1.2.2.2.cmml" xref="S2.SS1.p3.10.m8.1.2.2"><csymbol cd="ambiguous" id="S2.SS1.p3.10.m8.1.2.2.2.1.cmml" xref="S2.SS1.p3.10.m8.1.2.2">subscript</csymbol><ci id="S2.SS1.p3.10.m8.1.2.2.2.2.cmml" xref="S2.SS1.p3.10.m8.1.2.2.2.2">ℒ</ci><ci id="S2.SS1.p3.10.m8.1.2.2.2.3.cmml" xref="S2.SS1.p3.10.m8.1.2.2.2.3">𝑐</ci></apply><ci id="S2.SS1.p3.10.m8.1.1.1.1.cmml" xref="S2.SS1.p3.10.m8.1.1.1.1">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.10.m8.1c">\nabla\mathcal{L}_{c}^{(t)}</annotation></semantics></math> to the central server; in the latter case, <math id="S2.SS1.p3.11.m9.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S2.SS1.p3.11.m9.1a"><mi id="S2.SS1.p3.11.m9.1.1" xref="S2.SS1.p3.11.m9.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.11.m9.1b"><ci id="S2.SS1.p3.11.m9.1.1.cmml" xref="S2.SS1.p3.11.m9.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.11.m9.1c">S</annotation></semantics></math> simply aggregates the gradients and uses them to update the global model, i.e., <math id="S2.SS1.p3.12.m10.5" class="ltx_Math" alttext="\bm{\theta}^{(t+1)}=\bm{\theta}^{(t)}-\eta\phi(\{\nabla\mathcal{L}_{c}^{(t)}~{}|~{}c\in\mathcal{C}^{(t)}\})" display="inline"><semantics id="S2.SS1.p3.12.m10.5a"><mrow id="S2.SS1.p3.12.m10.5.5" xref="S2.SS1.p3.12.m10.5.5.cmml"><msup id="S2.SS1.p3.12.m10.5.5.3" xref="S2.SS1.p3.12.m10.5.5.3.cmml"><mi id="S2.SS1.p3.12.m10.5.5.3.2" xref="S2.SS1.p3.12.m10.5.5.3.2.cmml">𝜽</mi><mrow id="S2.SS1.p3.12.m10.1.1.1.1" xref="S2.SS1.p3.12.m10.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.SS1.p3.12.m10.1.1.1.1.2" xref="S2.SS1.p3.12.m10.1.1.1.1.1.cmml">(</mo><mrow id="S2.SS1.p3.12.m10.1.1.1.1.1" xref="S2.SS1.p3.12.m10.1.1.1.1.1.cmml"><mi id="S2.SS1.p3.12.m10.1.1.1.1.1.2" xref="S2.SS1.p3.12.m10.1.1.1.1.1.2.cmml">t</mi><mo id="S2.SS1.p3.12.m10.1.1.1.1.1.1" xref="S2.SS1.p3.12.m10.1.1.1.1.1.1.cmml">+</mo><mn id="S2.SS1.p3.12.m10.1.1.1.1.1.3" xref="S2.SS1.p3.12.m10.1.1.1.1.1.3.cmml">1</mn></mrow><mo stretchy="false" id="S2.SS1.p3.12.m10.1.1.1.1.3" xref="S2.SS1.p3.12.m10.1.1.1.1.1.cmml">)</mo></mrow></msup><mo id="S2.SS1.p3.12.m10.5.5.2" xref="S2.SS1.p3.12.m10.5.5.2.cmml">=</mo><mrow id="S2.SS1.p3.12.m10.5.5.1" xref="S2.SS1.p3.12.m10.5.5.1.cmml"><msup id="S2.SS1.p3.12.m10.5.5.1.3" xref="S2.SS1.p3.12.m10.5.5.1.3.cmml"><mi id="S2.SS1.p3.12.m10.5.5.1.3.2" xref="S2.SS1.p3.12.m10.5.5.1.3.2.cmml">𝜽</mi><mrow id="S2.SS1.p3.12.m10.2.2.1.3" xref="S2.SS1.p3.12.m10.5.5.1.3.cmml"><mo stretchy="false" id="S2.SS1.p3.12.m10.2.2.1.3.1" xref="S2.SS1.p3.12.m10.5.5.1.3.cmml">(</mo><mi id="S2.SS1.p3.12.m10.2.2.1.1" xref="S2.SS1.p3.12.m10.2.2.1.1.cmml">t</mi><mo stretchy="false" id="S2.SS1.p3.12.m10.2.2.1.3.2" xref="S2.SS1.p3.12.m10.5.5.1.3.cmml">)</mo></mrow></msup><mo id="S2.SS1.p3.12.m10.5.5.1.2" xref="S2.SS1.p3.12.m10.5.5.1.2.cmml">−</mo><mrow id="S2.SS1.p3.12.m10.5.5.1.1" xref="S2.SS1.p3.12.m10.5.5.1.1.cmml"><mi id="S2.SS1.p3.12.m10.5.5.1.1.3" xref="S2.SS1.p3.12.m10.5.5.1.1.3.cmml">η</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p3.12.m10.5.5.1.1.2" xref="S2.SS1.p3.12.m10.5.5.1.1.2.cmml">​</mo><mi id="S2.SS1.p3.12.m10.5.5.1.1.4" xref="S2.SS1.p3.12.m10.5.5.1.1.4.cmml">ϕ</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p3.12.m10.5.5.1.1.2a" xref="S2.SS1.p3.12.m10.5.5.1.1.2.cmml">​</mo><mrow id="S2.SS1.p3.12.m10.5.5.1.1.1.1" xref="S2.SS1.p3.12.m10.5.5.1.1.cmml"><mo stretchy="false" id="S2.SS1.p3.12.m10.5.5.1.1.1.1.2" xref="S2.SS1.p3.12.m10.5.5.1.1.cmml">(</mo><mrow id="S2.SS1.p3.12.m10.5.5.1.1.1.1.1.2" xref="S2.SS1.p3.12.m10.5.5.1.1.1.1.1.3.cmml"><mo stretchy="false" id="S2.SS1.p3.12.m10.5.5.1.1.1.1.1.2.3" xref="S2.SS1.p3.12.m10.5.5.1.1.1.1.1.3.1.cmml">{</mo><mrow id="S2.SS1.p3.12.m10.5.5.1.1.1.1.1.1.1" xref="S2.SS1.p3.12.m10.5.5.1.1.1.1.1.1.1.cmml"><mo rspace="0.167em" id="S2.SS1.p3.12.m10.5.5.1.1.1.1.1.1.1.1" xref="S2.SS1.p3.12.m10.5.5.1.1.1.1.1.1.1.1.cmml">∇</mo><msubsup id="S2.SS1.p3.12.m10.5.5.1.1.1.1.1.1.1.2" xref="S2.SS1.p3.12.m10.5.5.1.1.1.1.1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p3.12.m10.5.5.1.1.1.1.1.1.1.2.2.2" xref="S2.SS1.p3.12.m10.5.5.1.1.1.1.1.1.1.2.2.2.cmml">ℒ</mi><mi id="S2.SS1.p3.12.m10.5.5.1.1.1.1.1.1.1.2.2.3" xref="S2.SS1.p3.12.m10.5.5.1.1.1.1.1.1.1.2.2.3.cmml">c</mi><mrow id="S2.SS1.p3.12.m10.3.3.1.3" xref="S2.SS1.p3.12.m10.5.5.1.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S2.SS1.p3.12.m10.3.3.1.3.1" xref="S2.SS1.p3.12.m10.5.5.1.1.1.1.1.1.1.2.cmml">(</mo><mi id="S2.SS1.p3.12.m10.3.3.1.1" xref="S2.SS1.p3.12.m10.3.3.1.1.cmml">t</mi><mo stretchy="false" id="S2.SS1.p3.12.m10.3.3.1.3.2" xref="S2.SS1.p3.12.m10.5.5.1.1.1.1.1.1.1.2.cmml">)</mo></mrow></msubsup></mrow><mo lspace="0em" rspace="0.330em" id="S2.SS1.p3.12.m10.5.5.1.1.1.1.1.2.4" xref="S2.SS1.p3.12.m10.5.5.1.1.1.1.1.3.1.cmml">|</mo><mrow id="S2.SS1.p3.12.m10.5.5.1.1.1.1.1.2.2" xref="S2.SS1.p3.12.m10.5.5.1.1.1.1.1.2.2.cmml"><mi id="S2.SS1.p3.12.m10.5.5.1.1.1.1.1.2.2.2" xref="S2.SS1.p3.12.m10.5.5.1.1.1.1.1.2.2.2.cmml">c</mi><mo id="S2.SS1.p3.12.m10.5.5.1.1.1.1.1.2.2.1" xref="S2.SS1.p3.12.m10.5.5.1.1.1.1.1.2.2.1.cmml">∈</mo><msup id="S2.SS1.p3.12.m10.5.5.1.1.1.1.1.2.2.3" xref="S2.SS1.p3.12.m10.5.5.1.1.1.1.1.2.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p3.12.m10.5.5.1.1.1.1.1.2.2.3.2" xref="S2.SS1.p3.12.m10.5.5.1.1.1.1.1.2.2.3.2.cmml">𝒞</mi><mrow id="S2.SS1.p3.12.m10.4.4.1.3" xref="S2.SS1.p3.12.m10.5.5.1.1.1.1.1.2.2.3.cmml"><mo stretchy="false" id="S2.SS1.p3.12.m10.4.4.1.3.1" xref="S2.SS1.p3.12.m10.5.5.1.1.1.1.1.2.2.3.cmml">(</mo><mi id="S2.SS1.p3.12.m10.4.4.1.1" xref="S2.SS1.p3.12.m10.4.4.1.1.cmml">t</mi><mo stretchy="false" id="S2.SS1.p3.12.m10.4.4.1.3.2" xref="S2.SS1.p3.12.m10.5.5.1.1.1.1.1.2.2.3.cmml">)</mo></mrow></msup></mrow><mo stretchy="false" id="S2.SS1.p3.12.m10.5.5.1.1.1.1.1.2.5" xref="S2.SS1.p3.12.m10.5.5.1.1.1.1.1.3.1.cmml">}</mo></mrow><mo stretchy="false" id="S2.SS1.p3.12.m10.5.5.1.1.1.1.3" xref="S2.SS1.p3.12.m10.5.5.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.12.m10.5b"><apply id="S2.SS1.p3.12.m10.5.5.cmml" xref="S2.SS1.p3.12.m10.5.5"><eq id="S2.SS1.p3.12.m10.5.5.2.cmml" xref="S2.SS1.p3.12.m10.5.5.2"></eq><apply id="S2.SS1.p3.12.m10.5.5.3.cmml" xref="S2.SS1.p3.12.m10.5.5.3"><csymbol cd="ambiguous" id="S2.SS1.p3.12.m10.5.5.3.1.cmml" xref="S2.SS1.p3.12.m10.5.5.3">superscript</csymbol><ci id="S2.SS1.p3.12.m10.5.5.3.2.cmml" xref="S2.SS1.p3.12.m10.5.5.3.2">𝜽</ci><apply id="S2.SS1.p3.12.m10.1.1.1.1.1.cmml" xref="S2.SS1.p3.12.m10.1.1.1.1"><plus id="S2.SS1.p3.12.m10.1.1.1.1.1.1.cmml" xref="S2.SS1.p3.12.m10.1.1.1.1.1.1"></plus><ci id="S2.SS1.p3.12.m10.1.1.1.1.1.2.cmml" xref="S2.SS1.p3.12.m10.1.1.1.1.1.2">𝑡</ci><cn type="integer" id="S2.SS1.p3.12.m10.1.1.1.1.1.3.cmml" xref="S2.SS1.p3.12.m10.1.1.1.1.1.3">1</cn></apply></apply><apply id="S2.SS1.p3.12.m10.5.5.1.cmml" xref="S2.SS1.p3.12.m10.5.5.1"><minus id="S2.SS1.p3.12.m10.5.5.1.2.cmml" xref="S2.SS1.p3.12.m10.5.5.1.2"></minus><apply id="S2.SS1.p3.12.m10.5.5.1.3.cmml" xref="S2.SS1.p3.12.m10.5.5.1.3"><csymbol cd="ambiguous" id="S2.SS1.p3.12.m10.5.5.1.3.1.cmml" xref="S2.SS1.p3.12.m10.5.5.1.3">superscript</csymbol><ci id="S2.SS1.p3.12.m10.5.5.1.3.2.cmml" xref="S2.SS1.p3.12.m10.5.5.1.3.2">𝜽</ci><ci id="S2.SS1.p3.12.m10.2.2.1.1.cmml" xref="S2.SS1.p3.12.m10.2.2.1.1">𝑡</ci></apply><apply id="S2.SS1.p3.12.m10.5.5.1.1.cmml" xref="S2.SS1.p3.12.m10.5.5.1.1"><times id="S2.SS1.p3.12.m10.5.5.1.1.2.cmml" xref="S2.SS1.p3.12.m10.5.5.1.1.2"></times><ci id="S2.SS1.p3.12.m10.5.5.1.1.3.cmml" xref="S2.SS1.p3.12.m10.5.5.1.1.3">𝜂</ci><ci id="S2.SS1.p3.12.m10.5.5.1.1.4.cmml" xref="S2.SS1.p3.12.m10.5.5.1.1.4">italic-ϕ</ci><apply id="S2.SS1.p3.12.m10.5.5.1.1.1.1.1.3.cmml" xref="S2.SS1.p3.12.m10.5.5.1.1.1.1.1.2"><csymbol cd="latexml" id="S2.SS1.p3.12.m10.5.5.1.1.1.1.1.3.1.cmml" xref="S2.SS1.p3.12.m10.5.5.1.1.1.1.1.2.3">conditional-set</csymbol><apply id="S2.SS1.p3.12.m10.5.5.1.1.1.1.1.1.1.cmml" xref="S2.SS1.p3.12.m10.5.5.1.1.1.1.1.1.1"><ci id="S2.SS1.p3.12.m10.5.5.1.1.1.1.1.1.1.1.cmml" xref="S2.SS1.p3.12.m10.5.5.1.1.1.1.1.1.1.1">∇</ci><apply id="S2.SS1.p3.12.m10.5.5.1.1.1.1.1.1.1.2.cmml" xref="S2.SS1.p3.12.m10.5.5.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.SS1.p3.12.m10.5.5.1.1.1.1.1.1.1.2.1.cmml" xref="S2.SS1.p3.12.m10.5.5.1.1.1.1.1.1.1.2">superscript</csymbol><apply id="S2.SS1.p3.12.m10.5.5.1.1.1.1.1.1.1.2.2.cmml" xref="S2.SS1.p3.12.m10.5.5.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.SS1.p3.12.m10.5.5.1.1.1.1.1.1.1.2.2.1.cmml" xref="S2.SS1.p3.12.m10.5.5.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S2.SS1.p3.12.m10.5.5.1.1.1.1.1.1.1.2.2.2.cmml" xref="S2.SS1.p3.12.m10.5.5.1.1.1.1.1.1.1.2.2.2">ℒ</ci><ci id="S2.SS1.p3.12.m10.5.5.1.1.1.1.1.1.1.2.2.3.cmml" xref="S2.SS1.p3.12.m10.5.5.1.1.1.1.1.1.1.2.2.3">𝑐</ci></apply><ci id="S2.SS1.p3.12.m10.3.3.1.1.cmml" xref="S2.SS1.p3.12.m10.3.3.1.1">𝑡</ci></apply></apply><apply id="S2.SS1.p3.12.m10.5.5.1.1.1.1.1.2.2.cmml" xref="S2.SS1.p3.12.m10.5.5.1.1.1.1.1.2.2"><in id="S2.SS1.p3.12.m10.5.5.1.1.1.1.1.2.2.1.cmml" xref="S2.SS1.p3.12.m10.5.5.1.1.1.1.1.2.2.1"></in><ci id="S2.SS1.p3.12.m10.5.5.1.1.1.1.1.2.2.2.cmml" xref="S2.SS1.p3.12.m10.5.5.1.1.1.1.1.2.2.2">𝑐</ci><apply id="S2.SS1.p3.12.m10.5.5.1.1.1.1.1.2.2.3.cmml" xref="S2.SS1.p3.12.m10.5.5.1.1.1.1.1.2.2.3"><csymbol cd="ambiguous" id="S2.SS1.p3.12.m10.5.5.1.1.1.1.1.2.2.3.1.cmml" xref="S2.SS1.p3.12.m10.5.5.1.1.1.1.1.2.2.3">superscript</csymbol><ci id="S2.SS1.p3.12.m10.5.5.1.1.1.1.1.2.2.3.2.cmml" xref="S2.SS1.p3.12.m10.5.5.1.1.1.1.1.2.2.3.2">𝒞</ci><ci id="S2.SS1.p3.12.m10.4.4.1.1.cmml" xref="S2.SS1.p3.12.m10.4.4.1.1">𝑡</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.12.m10.5c">\bm{\theta}^{(t+1)}=\bm{\theta}^{(t)}-\eta\phi(\{\nabla\mathcal{L}_{c}^{(t)}~{}|~{}c\in\mathcal{C}^{(t)}\})</annotation></semantics></math>, where <math id="S2.SS1.p3.13.m11.1" class="ltx_Math" alttext="\eta" display="inline"><semantics id="S2.SS1.p3.13.m11.1a"><mi id="S2.SS1.p3.13.m11.1.1" xref="S2.SS1.p3.13.m11.1.1.cmml">η</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.13.m11.1b"><ci id="S2.SS1.p3.13.m11.1.1.cmml" xref="S2.SS1.p3.13.m11.1.1">𝜂</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.13.m11.1c">\eta</annotation></semantics></math> is the learning rate.</p>
</div>
<figure id="S2.F1" class="ltx_figure"><img src="/html/2308.04604/assets/fl.jpg" id="S2.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="359" height="287" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F1.2.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>. </span><span id="S2.F1.3.2" class="ltx_text" style="font-size:90%;">A general FL round. (1) The server samples a subset of available clients, initializes the model, and sends it to the selected workers. (2) Receiving clients train the model on their local datasets (3) and send back the updated models to the server. (4) The server aggregates the local models with some aggregation rule.</span></figcaption>
</figure>
<div id="S2.SS1.p4" class="ltx_para">
<p id="S2.SS1.p4.1" class="ltx_p">Broadly speaking, FL systems can be categorized according to four different axes: <span id="S2.SS1.p4.1.1" class="ltx_text ltx_font_italic">data partitioning</span>, <span id="S2.SS1.p4.1.2" class="ltx_text ltx_font_italic">machine learning model</span>, <span id="S2.SS1.p4.1.3" class="ltx_text ltx_font_italic">scale of federation</span>, and <span id="S2.SS1.p4.1.4" class="ltx_text ltx_font_italic">communication architecture</span>. Below, we review each of these aspects separately.</p>
</div>
<section id="S2.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.1.1. </span>Data Partitioning</h4>

<div id="S2.SS1.SSS1.p1" class="ltx_para">
<p id="S2.SS1.SSS1.p1.1" class="ltx_p">Data can be distributed over the sample and feature spaces, which creates a categorization in <span id="S2.SS1.SSS1.p1.1.1" class="ltx_text ltx_font_italic">horizontal</span>, <span id="S2.SS1.SSS1.p1.1.2" class="ltx_text ltx_font_italic">vertical</span>, and <span id="S2.SS1.SSS1.p1.1.3" class="ltx_text ltx_font_italic">hybrid</span> FL <cite class="ltx_cite ltx_citemacro_citep">(Yang et al<span class="ltx_text">.</span>, <a href="#bib.bib95" title="" class="ltx_ref">2019</a>)</cite>.</p>
</div>
<div id="S2.SS1.SSS1.p2" class="ltx_para">
<p id="S2.SS1.SSS1.p2.1" class="ltx_p">In <span id="S2.SS1.SSS1.p2.1.1" class="ltx_text ltx_font_italic">horizontal</span> FL, the datasets of different clients have the same feature space but little intersection on the sample space. The majority of studies on FL assume horizontal partitioning. Since the local data are in the same feature space, the parties can train the local models using their local data with the same model architecture, and the global model can simply be updated by averaging all the local models using standard FedAvg.
A typical example where horizontal FL comes into play is when two (or more) regional branches of a bank want to collaboratively train a loan prediction model for their customers. Each branch may have very different user groups due to its geographical location, and the common set of users shared between any two branches is very small. However, their business is very similar, so the feature spaces are likely the same.</p>
</div>
<div id="S2.SS1.SSS1.p3" class="ltx_para">
<p id="S2.SS1.SSS1.p3.1" class="ltx_p">In <span id="S2.SS1.SSS1.p3.1.1" class="ltx_text ltx_font_italic">vertical</span> FL, instead, the datasets of different clients have the same or similar sample space but differ in the feature space. It usually adopts entity alignment techniques <cite class="ltx_cite ltx_citemacro_citep">(Christen, <a href="#bib.bib17" title="" class="ltx_ref">2012</a>)</cite> to collect the overlapped samples of the parties, and then these data are used to train the machine learning model using encryption methods.
As an example, consider two different companies in the same city, e.g., a bank and an e-commerce business. Their customer bases are likely to contain most of the residents of the area, so the intersection of their user space is large. However, the bank may record the user’s revenue and expenditure behavior and credit rating, whereas the e-commerce collects the user’s browsing and purchasing history; thus, their feature spaces are different.</p>
</div>
<div id="S2.SS1.SSS1.p4" class="ltx_para">
<p id="S2.SS1.SSS1.p4.1" class="ltx_p">Finally, <span id="S2.SS1.SSS1.p4.1.1" class="ltx_text ltx_font_italic">hybrid</span> FL (also referred to as <span id="S2.SS1.SSS1.p4.1.2" class="ltx_text ltx_font_italic">federated transfer learning</span> or FTL) is a combination of horizontal and vertical data partitioning. FTL applies when any pair of datasets from federated clients differ both in samples and in feature space. For instance, consider two different companies that are also geographically distant from each other, e.g., a bank located in China and an e-commerce company located in the United States.
Due to geopolitical restrictions, the user groups of the two companies have a small intersection.
Moreover, due to the different businesses, only a small portion of the feature space from both parties overlaps. In this case, <span id="S2.SS1.SSS1.p4.1.3" class="ltx_text ltx_font_italic">transfer learning</span> <cite class="ltx_cite ltx_citemacro_citep">(Pan and Yang, <a href="#bib.bib67" title="" class="ltx_ref">2010</a>)</cite> techniques can be applied to provide solutions for the entire sample and feature space under a federation.</p>
</div>
</section>
<section id="S2.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.1.2. </span>Machine Learning Models</h4>

<div id="S2.SS1.SSS2.p1" class="ltx_para">
<p id="S2.SS1.SSS2.p1.1" class="ltx_p">FL is primarily used to jointly solve a machine learning task, which usually consists of collaboratively training a common model on several distributed private datasets.
The choice of the specific ML model to train depends on the problem at hand and the dataset.
The most popular family of models used within FL systems is Neural Networks (NNs) in all their flavors. Simpler models, such as Linear Regression (LinReg) or Logistic Regression (LogReg), and Decision Trees (DTs) or ensembles of those like the Gradient Boosting Decision Trees (GBDTs) are also successfully proposed in FL environments <cite class="ltx_cite ltx_citemacro_citep">(Hardy et al<span class="ltx_text">.</span>, <a href="#bib.bib27" title="" class="ltx_ref">2017</a>; Li et al<span class="ltx_text">.</span>, <a href="#bib.bib44" title="" class="ltx_ref">2020</a>)</cite>, mostly due to their high efficiency and interpretability.</p>
</div>
<div id="S2.SS1.SSS2.p2" class="ltx_para">
<p id="S2.SS1.SSS2.p2.1" class="ltx_p">Generally speaking, an FL system can consist of homogenous or heterogenous ML models. In the former case, all clients have the same model, and aggregation of gradients comes into play at the server. In the latter scenario, there is no need for aggregation since each client has a different model. Therefore, at the server’s end, aggregation methods are replaced by ensemble methods like majority voting.</p>
</div>
</section>
<section id="S2.SS1.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.1.3. </span>Scale of Federation</h4>

<div id="S2.SS1.SSS3.p1" class="ltx_para">
<p id="S2.SS1.SSS3.p1.1" class="ltx_p">FL systems can be categorized into <span id="S2.SS1.SSS3.p1.1.1" class="ltx_text ltx_font_italic">cross-silo</span> and <span id="S2.SS1.SSS3.p1.1.2" class="ltx_text ltx_font_italic">cross-device</span> <cite class="ltx_cite ltx_citemacro_citep">(Kairouz et al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2021</a>)</cite>.
The difference between the two concerns the number of parties involved and the overall amount of data available in the federation.
The simplest way to understand them is to associate cross-silo with large organizations or data centers and cross-devices with mobile devices.
In the case of cross-silo, the number of federated clients is usually small, but they have extensive computational abilities (e.g., a group of large medical institutions).
The main challenge of cross-silo FL is to create an efficient distributed computation under the constraint of privacy <cite class="ltx_cite ltx_citemacro_citep">(Zhou et al<span class="ltx_text">.</span>, <a href="#bib.bib104" title="" class="ltx_ref">2019b</a>)</cite>.
When it comes to cross-device, instead, FL systems are made of a massive number of clients, each one with limited computational power (e.g., Google Gboard).
In cross-device FL, the primary challenge relates to devices’ energy consumption, which limits the complexity of training tasks that they can perform.</p>
</div>
</section>
<section id="S2.SS1.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.1.4. </span>Communication Architecture</h4>

<div id="S2.SS1.SSS4.p1" class="ltx_para">
<p id="S2.SS1.SSS4.p1.1" class="ltx_p">There are two main types of architectures for FL systems: centralized and decentralized. The centralized architecture follows a client-server model, where a central entity (referred to as the server) acts as the <span id="S2.SS1.SSS4.p1.1.1" class="ltx_text ltx_font_italic">orchestrator</span>. Its role involves coordinating the entire distributed training process, including the aggregation of individual local models sent by the clients into a single global model. On the other hand, in a decentralized architecture, there is no clear distinction between client and server roles. Each client has the potential to act as a server, taking turns in aggregating the current global model and transmitting it to other clients in a random manner during each round.
Implementing <span id="S2.SS1.SSS4.p1.1.2" class="ltx_text ltx_font_italic">decentralized</span> FL systems poses significant challenges and can be categorized into two main categories: traditional distributed computing methods, such as peer-to-peer (P2P) approaches, and those utilizing Blockchain technology.
<br class="ltx_break">In this survey, we will examine and assess the most relevant approaches to decentralized FL that have been proposed in the existing literature.</p>
</div>
</section>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2. </span>Peer-to-Peer Systems (P2P)</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">Generally speaking, peer-to-peer (P2P) computing offers an alternative to the traditional client-server architecture <cite class="ltx_cite ltx_citemacro_citep">(Barkai, <a href="#bib.bib6" title="" class="ltx_ref">2000</a>)</cite>. In a client-server model, clients connect to a central server to make requests while the server processes and responds to those requests. In contrast, P2P distributed systems allow nodes in the network to act as both servers and clients, promoting decentralization.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p">Although it is customary to associate P2P systems with (illegal) content sharing, they have broader applications beyond that. Increasingly, P2P solutions are being deployed to address various problems that were traditionally reliant on centralized server-based approaches. Some examples of P2P systems are BitTorrent <cite class="ltx_cite ltx_citemacro_citep">(BitTorrent, <a href="#bib.bib11" title="" class="ltx_ref">2023</a>)</cite>, Gnutella <cite class="ltx_cite ltx_citemacro_citep">(Gnutella, <a href="#bib.bib24" title="" class="ltx_ref">2023</a>)</cite>, Napster <cite class="ltx_cite ltx_citemacro_citep">(Napster, <a href="#bib.bib59" title="" class="ltx_ref">2023</a>)</cite>, and Skype <cite class="ltx_cite ltx_citemacro_citep">(Skype, <a href="#bib.bib84" title="" class="ltx_ref">2023</a>)</cite>.
The fundamental principle of P2P networks is to enable resource sharing among end systems, including files, storage space, CPU cycles, and more. These systems create an overlay network over the Internet, facilitating communication between peers.</p>
</div>
<div id="S2.SS2.p3" class="ltx_para">
<p id="S2.SS2.p3.1" class="ltx_p">According to <cite class="ltx_cite ltx_citemacro_citep">(Roussopoulos et al<span class="ltx_text">.</span>, <a href="#bib.bib80" title="" class="ltx_ref">2003</a>)</cite>, there are three primary characteristics of a P2P system:</p>
<ul id="S2.I2" class="ltx_itemize">
<li id="S2.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I2.i1.p1" class="ltx_para">
<p id="S2.I2.i1.p1.1" class="ltx_p"><span id="S2.I2.i1.p1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Self-organizing</span>: Nodes must organize themselves to form an overlay network. There should be no assistance from a central node. Also, there should not be any global index that lists all the peers and/or the available resources.</p>
</div>
</li>
<li id="S2.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I2.i2.p1" class="ltx_para">
<p id="S2.I2.i2.p1.1" class="ltx_p"><span id="S2.I2.i2.p1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Symmetric communication</span>: All nodes must be equal (i.e., no node should be more important than any other node.) Also, peers should both request and offer services (i.e., they should act as both clients and servers).</p>
</div>
</li>
<li id="S2.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I2.i3.p1" class="ltx_para">
<p id="S2.I2.i3.p1.1" class="ltx_p"><span id="S2.I2.i3.p1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Decentralized control</span>: There should not be a central controlling authority that dictates behavior to individual nodes. Peers should be autonomous and must determine their level of participation in the network on their own.</p>
</div>
</li>
</ul>
</div>
<div id="S2.SS2.p4" class="ltx_para">
<p id="S2.SS2.p4.1" class="ltx_p">P2P networks offer some advantages over classical client-server architectures, such as eliminating the single-point-of-failure and single-source bottleneck.
The primary characteristics of P2P networks are <span id="S2.SS2.p4.1.1" class="ltx_text ltx_font_italic">reliability</span> <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib45" title="" class="ltx_ref">2010</a>)</cite> against nodes that disconnect or have a low latency or bandwidth; <span id="S2.SS2.p4.1.2" class="ltx_text ltx_font_italic">scalability</span> <cite class="ltx_cite ltx_citemacro_citep">(Kermarrec and Taiani, <a href="#bib.bib36" title="" class="ltx_ref">2015</a>)</cite> as the workload is no more concentrated in a server; <span id="S2.SS2.p4.1.3" class="ltx_text ltx_font_italic">privacy</span> <cite class="ltx_cite ltx_citemacro_citep">(Isdal et al<span class="ltx_text">.</span>, <a href="#bib.bib31" title="" class="ltx_ref">2010</a>)</cite> and <span id="S2.SS2.p4.1.4" class="ltx_text ltx_font_italic">anonimity</span> <cite class="ltx_cite ltx_citemacro_citep">(Marti and Garcia-Molina, <a href="#bib.bib53" title="" class="ltx_ref">2003</a>)</cite> via cryptographic protocols.</p>
</div>
<div id="S2.SS2.p5" class="ltx_para">
<p id="S2.SS2.p5.1" class="ltx_p">Still following <cite class="ltx_cite ltx_citemacro_citep">(Roussopoulos et al<span class="ltx_text">.</span>, <a href="#bib.bib80" title="" class="ltx_ref">2003</a>)</cite>, some of the key challenges of P2P systems are as follows:</p>
<ul id="S2.I3" class="ltx_itemize">
<li id="S2.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I3.i1.p1" class="ltx_para">
<p id="S2.I3.i1.p1.1" class="ltx_p"><span id="S2.I3.i1.p1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Budget:</span> The budget allocated to a solution influences the consideration of P2P architectures. If the budget is ample, the inefficiencies and complexities associated with P2P may not be deemed worthwhile. However, if the budget is limited, the low cost of entry for individual peers becomes an attractive factor despite the increased total system cost. Utilizing local components and surplus resources may be a justifiable approach within constrained budgets.</p>
</div>
</li>
<li id="S2.I3.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I3.i2.p1" class="ltx_para">
<p id="S2.I3.i2.p1.1" class="ltx_p"><span id="S2.I3.i2.p1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Resource relevance to participants:</span> The relevance of data to peers plays a significant role in P2P cooperation. If the probability of peers being interested in each other’s data is high, cooperation naturally evolves. Conversely, if relevance is low, artificial or extrinsic incentives may be necessary to foster cooperation.</p>
</div>
</li>
<li id="S2.I3.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I3.i3.p1" class="ltx_para">
<p id="S2.I3.i3.p1.1" class="ltx_p"><span id="S2.I3.i3.p1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Trust:</span> Trust among peers varies depending on the specific problem requirements. Mutual distrust can be either essential or negligible. However, the cost of mutual distrust in P2P systems is high, and its necessity must be justified based on the problem’s characteristics.</p>
</div>
</li>
<li id="S2.I3.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I3.i4.p1" class="ltx_para">
<p id="S2.I3.i4.p1.1" class="ltx_p"><span id="S2.I3.i4.p1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Rate of system change:</span> P2P systems may experience stable or rapidly changing participants, resources, and parameters. Rapid changes pose challenges in ensuring consistency guarantees, defending against flooding, and mitigating other attacks.</p>
</div>
</li>
<li id="S2.I3.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I3.i5.p1" class="ltx_para">
<p id="S2.I3.i5.p1.1" class="ltx_p"><span id="S2.I3.i5.p1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Criticality:</span> If the problem being solved is critical to users, centralized control may be demanded regardless of technical criteria. Even when P2P is not ruled out, the need for expensive security measures or extensive over-provisioning may render it economically unfeasible.</p>
</div>
</li>
<li id="S2.I3.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I3.i6.p1" class="ltx_para">
<p id="S2.I3.i6.p1.1" class="ltx_p"><span id="S2.I3.i6.p1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Security:</span> P2P networks are known to be vulnerable to various types of security attacks. For instance, malicious nodes can disrupt the network by flooding it with redundant data, manipulating trust values in trust-based systems, coordinating with other malicious nodes for distributed denial-of-service (DDoS) attacks, or performing <span id="S2.I3.i6.p1.1.2" class="ltx_text ltx_font_italic">Sybil</span> attacks by creating multiple fake identities within the network <cite class="ltx_cite ltx_citemacro_citep">(Pretre, <a href="#bib.bib73" title="" class="ltx_ref">2005</a>)</cite>.</p>
</div>
</li>
</ul>
</div>
<div id="S2.SS2.p6" class="ltx_para">
<p id="S2.SS2.p6.1" class="ltx_p">In recent years, <span id="S2.SS2.p6.1.1" class="ltx_text ltx_font_italic">decentralized</span> machine learning has gained popularity within P2P networks. The focus has been on solving the distributed consensus problem, aiming to find a global model that minimizes the sum of local loss functions <cite class="ltx_cite ltx_citemacro_citep">(Ram et al<span class="ltx_text">.</span>, <a href="#bib.bib77" title="" class="ltx_ref">2010</a>; Nedic and Ozdaglar, <a href="#bib.bib60" title="" class="ltx_ref">2009</a>)</cite>. Additionally, research has explored privacy-preserving approaches and scenarios where agents have distinct objectives <cite class="ltx_cite ltx_citemacro_citep">(Bellet et al<span class="ltx_text">.</span>, <a href="#bib.bib8" title="" class="ltx_ref">2018</a>)</cite>. These advancements enable collaborative learning and optimization in a decentralized manner.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3. </span>Blockchain</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">Simply put, a <span id="S2.SS3.p1.1.1" class="ltx_text ltx_font_italic">Blockchain</span> is an open and distributed ledger designed to record transactions between parties securely and permanently. It operates by facilitating the transfer of digital assets (e.g., cryptocurrencies) from one account to another. Transactions are grouped into <span id="S2.SS3.p1.1.2" class="ltx_text ltx_font_italic">blocks</span>, forming a chain where each block is linked to its predecessor using hash functions. Consensus mechanisms are used to achieve agreement within the Blockchain network. According to <cite class="ltx_cite ltx_citemacro_citep">(Yaga et al<span class="ltx_text">.</span>, <a href="#bib.bib94" title="" class="ltx_ref">2018</a>)</cite>, some key properties of this technology are:</p>
<ul id="S2.I4" class="ltx_itemize">
<li id="S2.I4.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I4.i1.p1" class="ltx_para">
<p id="S2.I4.i1.p1.1" class="ltx_p"><span id="S2.I4.i1.p1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Ledger</span>: Append-only ledger to provide full transactional history. Unlike traditional databases, transactions, and values in a Blockchain are not overridden.</p>
</div>
</li>
<li id="S2.I4.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I4.i2.p1" class="ltx_para">
<p id="S2.I4.i2.p1.1" class="ltx_p"><span id="S2.I4.i2.p1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Secure</span>: Cryptographically secure, the data within the ledger is attestable.</p>
</div>
</li>
<li id="S2.I4.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I4.i3.p1" class="ltx_para">
<p id="S2.I4.i3.p1.1" class="ltx_p"><span id="S2.I4.i3.p1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Shared</span>: The ledger is shared amongst multiple participants. This provides transparency across the node participants in the Blockchain network.</p>
</div>
</li>
<li id="S2.I4.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I4.i4.p1" class="ltx_para">
<p id="S2.I4.i4.p1.1" class="ltx_p"><span id="S2.I4.i4.p1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Distributed</span>: The Blockchain can be distributed. By increasing the number of nodes, the ability of a bad actor to impact the consensus protocol used by the Blockchain is reduced.</p>
</div>
</li>
</ul>
<p id="S2.SS3.p1.2" class="ltx_p">Blockchain technology has a recent impact, although it dates back 30 years. In 2008, a paper published pseudonymously by Satoshi Nakamoto <cite class="ltx_cite ltx_citemacro_citep">(Nakamoto, <a href="#bib.bib58" title="" class="ltx_ref">2009</a>)</cite> described <span id="S2.SS3.p1.2.1" class="ltx_text ltx_font_italic">Bitcoin</span>: a peer-to-peer electronic cash system that works like a chain of digital signatures.
Each owner transfers the coin to the next by digitally signing a hash of the previous transaction and the public key of the next owner and adding these to the end of the coin. A payee can verify the signatures to verify the chain of ownership. The consensus algorithm to decide which is the next block is called <span id="S2.SS3.p1.2.2" class="ltx_text ltx_font_italic">proof-of-work</span> (PoW), which is, in brief, a computationally expensive puzzle. When a node finds a PoW, it broadcasts it to all nodes.</p>
</div>
<div id="S2.SS3.p2" class="ltx_para">
<p id="S2.SS3.p2.1" class="ltx_p">After the introduction of Bitcoin, the concept of Blockchain expanded to include programmable capabilities. In 2015, Ethereum  <cite class="ltx_cite ltx_citemacro_citep">(Buterin, <a href="#bib.bib13" title="" class="ltx_ref">2013</a>)</cite> was introduced as a Blockchain platform with a built-in programming language, allowing the creation of smart contracts and decentralized applications (DApps).
Ethereum uses its cryptocurrency, called “Ether” as the internal fuel for executing transactions and running smart contracts. In Ethereum, there are two types of accounts: externally owned accounts controlled by private keys and contract accounts controlled by their contract code. Smart contracts enable users to define rules for ownership, transaction formats, and state transitions. The consensus protocol used in Ethereum is called <span id="S2.SS3.p2.1.1" class="ltx_text ltx_font_italic">proof-of-stake</span> (PoS), where validators stake their capital in Ethereum to propose and add new blocks to the Blockchain. Validators are incentivized to follow the rules, as deviations can result in penalties or loss of stake.</p>
</div>
<div id="S2.SS3.p3" class="ltx_para">
<p id="S2.SS3.p3.1" class="ltx_p">Blockchain technology has also found utility in various machine learning tasks <cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib15" title="" class="ltx_ref">2018</a>)</cite>. Researchers have explored different consensus algorithms that are particularly relevant to federated learning. These include <span id="S2.SS3.p3.1.1" class="ltx_text ltx_font_italic">proof-of-federated-learning</span> (PoFL), which repurposes the energy consumed in traditional PoW algorithms for solving meaningful puzzles in the context of FL <cite class="ltx_cite ltx_citemacro_citep">(Qu et al<span class="ltx_text">.</span>, <a href="#bib.bib74" title="" class="ltx_ref">2021b</a>)</cite>.
Moreover, <span id="S2.SS3.p3.1.2" class="ltx_text ltx_font_italic">proof-of-quality</span> (PoQ) introduces a consensus protocol based on Quality-of-Service (QoS) to ensure high-quality contributions to the Blockchain <cite class="ltx_cite ltx_citemacro_citep">(Yu et al<span class="ltx_text">.</span>, <a href="#bib.bib98" title="" class="ltx_ref">2019</a>)</cite>.
In addition, <span id="S2.SS3.p3.1.3" class="ltx_text ltx_font_italic">proof-of-authority</span> (PoA) relies on identity as a stake to achieve faster transaction processing <cite class="ltx_cite ltx_citemacro_citep">(Liu et al<span class="ltx_text">.</span>, <a href="#bib.bib49" title="" class="ltx_ref">2019</a>)</cite>.
Finally, committee-based consensus algorithms involve the validation of local gradients before appending them to the Blockchain, where a committee of honest nodes verifies and generates blocks <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib46" title="" class="ltx_ref">2021a</a>)</cite>.
All these advancements demonstrate the successful applicability of Blockchain technology to enhance the efficiency and security of FL systems.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>Research Method</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">We have chosen to follow the <span id="S3.p1.1.1" class="ltx_text ltx_font_italic">Preferred Reporting Items for Systematic Reviews and Meta-Analyses</span> (PRISMA) guidelines <cite class="ltx_cite ltx_citemacro_citep">(Page et al<span class="ltx_text">.</span>, <a href="#bib.bib66" title="" class="ltx_ref">2021</a>)</cite> for conducting our review.
Our approach consists of three primary steps.</p>
<ol id="S3.I1" class="ltx_enumerate">
<li id="S3.I1.ix1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><math id="S3.I1.ix1.1.1.m1.1" class="ltx_Math" alttext="(i)" display="inline"><semantics id="S3.I1.ix1.1.1.m1.1b"><mrow id="S3.I1.ix1.1.1.m1.1.2.2"><mo stretchy="false" id="S3.I1.ix1.1.1.m1.1.2.2.1">(</mo><mi id="S3.I1.ix1.1.1.m1.1.1" xref="S3.I1.ix1.1.1.m1.1.1.cmml">i</mi><mo stretchy="false" id="S3.I1.ix1.1.1.m1.1.2.2.2">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.I1.ix1.1.1.m1.1c"><ci id="S3.I1.ix1.1.1.m1.1.1.cmml" xref="S3.I1.ix1.1.1.m1.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.ix1.1.1.m1.1d">(i)</annotation></semantics></math></span> 
<div id="S3.I1.ix1.p1" class="ltx_para">
<p id="S3.I1.ix1.p1.1" class="ltx_p"><span id="S3.I1.ix1.p1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Identifying relevant works</span>: We find relevant articles by conducting a comprehensive literature search and screening titles, abstracts, and full-text articles. This process ensures that we select contributions that pertain to our specific research area and address our research question(s) of interest.</p>
</div>
</li>
<li id="S3.I1.ix2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><math id="S3.I1.ix2.1.1.m1.1" class="ltx_Math" alttext="(ii)" display="inline"><semantics id="S3.I1.ix2.1.1.m1.1b"><mrow id="S3.I1.ix2.1.1.m1.1.1.1" xref="S3.I1.ix2.1.1.m1.1.1.1.1.cmml"><mo stretchy="false" id="S3.I1.ix2.1.1.m1.1.1.1.2" xref="S3.I1.ix2.1.1.m1.1.1.1.1.cmml">(</mo><mrow id="S3.I1.ix2.1.1.m1.1.1.1.1" xref="S3.I1.ix2.1.1.m1.1.1.1.1.cmml"><mi id="S3.I1.ix2.1.1.m1.1.1.1.1.2" xref="S3.I1.ix2.1.1.m1.1.1.1.1.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.I1.ix2.1.1.m1.1.1.1.1.1" xref="S3.I1.ix2.1.1.m1.1.1.1.1.1.cmml">​</mo><mi id="S3.I1.ix2.1.1.m1.1.1.1.1.3" xref="S3.I1.ix2.1.1.m1.1.1.1.1.3.cmml">i</mi></mrow><mo stretchy="false" id="S3.I1.ix2.1.1.m1.1.1.1.3" xref="S3.I1.ix2.1.1.m1.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.I1.ix2.1.1.m1.1c"><apply id="S3.I1.ix2.1.1.m1.1.1.1.1.cmml" xref="S3.I1.ix2.1.1.m1.1.1.1"><times id="S3.I1.ix2.1.1.m1.1.1.1.1.1.cmml" xref="S3.I1.ix2.1.1.m1.1.1.1.1.1"></times><ci id="S3.I1.ix2.1.1.m1.1.1.1.1.2.cmml" xref="S3.I1.ix2.1.1.m1.1.1.1.1.2">𝑖</ci><ci id="S3.I1.ix2.1.1.m1.1.1.1.1.3.cmml" xref="S3.I1.ix2.1.1.m1.1.1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.ix2.1.1.m1.1d">(ii)</annotation></semantics></math></span> 
<div id="S3.I1.ix2.p1" class="ltx_para">
<p id="S3.I1.ix2.p1.1" class="ltx_p"><span id="S3.I1.ix2.p1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Appraising study quality</span>: We validate the quality of the included studies, taking into account factors such as study design, methodology, and potential biases. This step allows us to assess the strength of the evidence presented in the selected articles.</p>
</div>
</li>
<li id="S3.I1.ix3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><math id="S3.I1.ix3.1.1.m1.1" class="ltx_Math" alttext="(iii)" display="inline"><semantics id="S3.I1.ix3.1.1.m1.1b"><mrow id="S3.I1.ix3.1.1.m1.1.1.1" xref="S3.I1.ix3.1.1.m1.1.1.1.1.cmml"><mo stretchy="false" id="S3.I1.ix3.1.1.m1.1.1.1.2" xref="S3.I1.ix3.1.1.m1.1.1.1.1.cmml">(</mo><mrow id="S3.I1.ix3.1.1.m1.1.1.1.1" xref="S3.I1.ix3.1.1.m1.1.1.1.1.cmml"><mi id="S3.I1.ix3.1.1.m1.1.1.1.1.2" xref="S3.I1.ix3.1.1.m1.1.1.1.1.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.I1.ix3.1.1.m1.1.1.1.1.1" xref="S3.I1.ix3.1.1.m1.1.1.1.1.1.cmml">​</mo><mi id="S3.I1.ix3.1.1.m1.1.1.1.1.3" xref="S3.I1.ix3.1.1.m1.1.1.1.1.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.I1.ix3.1.1.m1.1.1.1.1.1b" xref="S3.I1.ix3.1.1.m1.1.1.1.1.1.cmml">​</mo><mi id="S3.I1.ix3.1.1.m1.1.1.1.1.4" xref="S3.I1.ix3.1.1.m1.1.1.1.1.4.cmml">i</mi></mrow><mo stretchy="false" id="S3.I1.ix3.1.1.m1.1.1.1.3" xref="S3.I1.ix3.1.1.m1.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.I1.ix3.1.1.m1.1c"><apply id="S3.I1.ix3.1.1.m1.1.1.1.1.cmml" xref="S3.I1.ix3.1.1.m1.1.1.1"><times id="S3.I1.ix3.1.1.m1.1.1.1.1.1.cmml" xref="S3.I1.ix3.1.1.m1.1.1.1.1.1"></times><ci id="S3.I1.ix3.1.1.m1.1.1.1.1.2.cmml" xref="S3.I1.ix3.1.1.m1.1.1.1.1.2">𝑖</ci><ci id="S3.I1.ix3.1.1.m1.1.1.1.1.3.cmml" xref="S3.I1.ix3.1.1.m1.1.1.1.1.3">𝑖</ci><ci id="S3.I1.ix3.1.1.m1.1.1.1.1.4.cmml" xref="S3.I1.ix3.1.1.m1.1.1.1.1.4">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.ix3.1.1.m1.1d">(iii)</annotation></semantics></math></span> 
<div id="S3.I1.ix3.p1" class="ltx_para">
<p id="S3.I1.ix3.p1.1" class="ltx_p"><span id="S3.I1.ix3.p1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Synthesizing findings and drawing conclusions</span>: We synthesize the findings from the included studies and draw meaningful conclusions. This involves analyzing the data, summarizing the results, and identifying any patterns or trends across the studies.</p>
</div>
</li>
</ol>
<p id="S3.p1.2" class="ltx_p">By following these steps, we aim to ensure a rigorous and comprehensive review process.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1. </span>Research Questions</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">In this survey, we started by formulating a set of <span id="S3.SS1.p1.1.1" class="ltx_text ltx_font_italic">research questions</span> (<span id="S3.SS1.p1.1.2" class="ltx_text ltx_font_bold">RQs</span>) to thoroughly explore the existing literature. Table <a href="#S3.T1" title="Table 1 ‣ 3.1. Research Questions ‣ 3. Research Method ‣ A Survey on Decentralized Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> presents the five distinct contexts and their corresponding eight research questions that we aimed to address. Our review encompasses an analysis of the application and problem domains addressed by <span id="S3.SS1.p1.1.3" class="ltx_text ltx_font_italic">decentralized federated learning</span> (DFL), an examination of the datasets used in the studies, an exploration of the key properties of available DFL frameworks, and a comprehensive investigation of experimental aspects.</p>
<div id="S3.SS1.p1.2" class="ltx_logical-block">
<figure id="S3.T1" class="ltx_table ltx_align_center">
<table id="S3.T1.2" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S3.T1.2.1" class="ltx_tr">
<td id="S3.T1.2.1.1" class="ltx_td ltx_align_center ltx_border_r">Context</td>
<td id="S3.T1.2.1.2" class="ltx_td ltx_align_center">Questions</td>
</tr>
<tr id="S3.T1.2.2" class="ltx_tr">
<td id="S3.T1.2.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Overview</td>
<td id="S3.T1.2.2.2" class="ltx_td ltx_align_center ltx_border_t">
<span id="S3.T1.2.2.2.1" class="ltx_text"></span> <span id="S3.T1.2.2.2.2" class="ltx_text">
<span id="S3.T1.2.2.2.2.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T1.2.2.2.2.1.1" class="ltx_tr">
<span id="S3.T1.2.2.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T1.2.2.2.2.1.1.1.1" class="ltx_text ltx_font_bold">RQ1:</span> What are the possible applications of DFL?</span></span>
<span id="S3.T1.2.2.2.2.1.2" class="ltx_tr">
<span id="S3.T1.2.2.2.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T1.2.2.2.2.1.2.1.1" class="ltx_text ltx_font_bold">RQ2:</span> Is the centralized orchestration problem solved?</span></span>
</span></span><span id="S3.T1.2.2.2.3" class="ltx_text"></span></td>
</tr>
<tr id="S3.T1.2.3" class="ltx_tr">
<td id="S3.T1.2.3.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Datasets</td>
<td id="S3.T1.2.3.2" class="ltx_td ltx_align_center ltx_border_t">
<span id="S3.T1.2.3.2.1" class="ltx_text ltx_font_bold">RQ3:</span> What are the datasets used?</td>
</tr>
<tr id="S3.T1.2.4" class="ltx_tr">
<td id="S3.T1.2.4.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">DFL Implementation</td>
<td id="S3.T1.2.4.2" class="ltx_td ltx_align_center ltx_border_t">
<span id="S3.T1.2.4.2.1" class="ltx_text"></span> <span id="S3.T1.2.4.2.2" class="ltx_text">
<span id="S3.T1.2.4.2.2.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T1.2.4.2.2.1.1" class="ltx_tr">
<span id="S3.T1.2.4.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T1.2.4.2.2.1.1.1.1" class="ltx_text ltx_font_bold">RQ4:</span> Is it a blockchain-based approach or not?</span></span>
<span id="S3.T1.2.4.2.2.1.2" class="ltx_tr">
<span id="S3.T1.2.4.2.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T1.2.4.2.2.1.2.1.1" class="ltx_text ltx_font_bold">RQ5:</span> What is the data partitioning strategy?</span></span>
<span id="S3.T1.2.4.2.2.1.3" class="ltx_tr">
<span id="S3.T1.2.4.2.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T1.2.4.2.2.1.3.1.1" class="ltx_text ltx_font_bold">RQ6:</span> What is the consensus algorithm used?</span></span>
</span></span><span id="S3.T1.2.4.2.3" class="ltx_text"></span></td>
</tr>
<tr id="S3.T1.2.5" class="ltx_tr">
<td id="S3.T1.2.5.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">Experimental</td>
<td id="S3.T1.2.5.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">
<span id="S3.T1.2.5.2.1" class="ltx_text"></span> <span id="S3.T1.2.5.2.2" class="ltx_text">
<span id="S3.T1.2.5.2.2.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T1.2.5.2.2.1.1" class="ltx_tr">
<span id="S3.T1.2.5.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T1.2.5.2.2.1.1.1.1" class="ltx_text ltx_font_bold">RQ7:</span> What are the performances of that approach?</span></span>
<span id="S3.T1.2.5.2.2.1.2" class="ltx_tr">
<span id="S3.T1.2.5.2.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T1.2.5.2.2.1.2.1.1" class="ltx_text ltx_font_bold">RQ8:</span> How is it robust to security risks?</span></span>
</span></span><span id="S3.T1.2.5.2.3" class="ltx_text"></span></td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S3.T1.3.1.1" class="ltx_text" style="font-size:90%;">Table 1</span>. </span><span id="S3.T1.4.2" class="ltx_text" style="font-size:90%;">Research Questions of interest for this survey.</span></figcaption>
</figure>
</div>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2. </span>Search Process</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">For the purpose of this review, we conducted a search within a specific time frame spanning from 2018 to 2023, with a focus on DFL.
We utilized several common databases, including IEEE Xplore, ScienceDirect, ACM Digital Library, and Google Scholar, employing advanced search options and boolean expressions (AND, OR).
Specifically, we use the following search queries to retrieve relevant work from the repositories above: "<span id="S3.SS2.p1.1.1" class="ltx_text ltx_font_italic">Fully Decentralized Federated Learning</span>"; "<span id="S3.SS2.p1.1.2" class="ltx_text ltx_font_italic">Decentralized Federated Learning</span>"; "<span id="S3.SS2.p1.1.3" class="ltx_text ltx_font_italic">P2P Federated Learning</span>"; "<span id="S3.SS2.p1.1.4" class="ltx_text ltx_font_italic">Peer-to-Peer Federated Learning</span>".</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">We paid special attention to the exclusion of articles that did not align with the scope of this survey. The search phrases were applied to titles, abstracts, and keywords in each database. To provide an overview of the article selection process and the statistics of articles considered in this survey, we present the PRISMA flow diagram in Fig. <a href="#S3.F2" title="Figure 2 ‣ 3.2. Search Process ‣ 3. Research Method ‣ A Survey on Decentralized Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. Each stage of the diagram will be discussed in detail in the following sections.</p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2308.04604/assets/selected-papers.jpeg" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_square" width="479" height="526" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F2.2.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>. </span><span id="S3.F2.3.2" class="ltx_text" style="font-size:90%;">Selection process of articles with the PRISMA flow diagram.</span></figcaption>
</figure>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3. </span>Inclusion/Exclusion Criteria</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.3" class="ltx_p">To guarantee a focused and relevant selection process in our review, predefined inclusion and exclusion criteria were utilized due to the large number of studies available. These criteria effectively narrow down the search to specific study types, ensuring that the chosen articles align with the research question and provide unbiased information.
The criteria prioritize the inclusion of articles that <math id="S3.SS3.p1.1.m1.1" class="ltx_Math" alttext="(i)" display="inline"><semantics id="S3.SS3.p1.1.m1.1a"><mrow id="S3.SS3.p1.1.m1.1.2.2"><mo stretchy="false" id="S3.SS3.p1.1.m1.1.2.2.1">(</mo><mi id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml">i</mi><mo stretchy="false" id="S3.SS3.p1.1.m1.1.2.2.2">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><ci id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">(i)</annotation></semantics></math> address the centralized orchestration problem, <math id="S3.SS3.p1.2.m2.1" class="ltx_Math" alttext="(ii)" display="inline"><semantics id="S3.SS3.p1.2.m2.1a"><mrow id="S3.SS3.p1.2.m2.1.1.1" xref="S3.SS3.p1.2.m2.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS3.p1.2.m2.1.1.1.2" xref="S3.SS3.p1.2.m2.1.1.1.1.cmml">(</mo><mrow id="S3.SS3.p1.2.m2.1.1.1.1" xref="S3.SS3.p1.2.m2.1.1.1.1.cmml"><mi id="S3.SS3.p1.2.m2.1.1.1.1.2" xref="S3.SS3.p1.2.m2.1.1.1.1.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.2.m2.1.1.1.1.1" xref="S3.SS3.p1.2.m2.1.1.1.1.1.cmml">​</mo><mi id="S3.SS3.p1.2.m2.1.1.1.1.3" xref="S3.SS3.p1.2.m2.1.1.1.1.3.cmml">i</mi></mrow><mo stretchy="false" id="S3.SS3.p1.2.m2.1.1.1.3" xref="S3.SS3.p1.2.m2.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.2.m2.1b"><apply id="S3.SS3.p1.2.m2.1.1.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1.1"><times id="S3.SS3.p1.2.m2.1.1.1.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1.1.1.1"></times><ci id="S3.SS3.p1.2.m2.1.1.1.1.2.cmml" xref="S3.SS3.p1.2.m2.1.1.1.1.2">𝑖</ci><ci id="S3.SS3.p1.2.m2.1.1.1.1.3.cmml" xref="S3.SS3.p1.2.m2.1.1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.2.m2.1c">(ii)</annotation></semantics></math> clearly define themselves as fully decentralized frameworks, and <math id="S3.SS3.p1.3.m3.1" class="ltx_Math" alttext="(iii)" display="inline"><semantics id="S3.SS3.p1.3.m3.1a"><mrow id="S3.SS3.p1.3.m3.1.1.1" xref="S3.SS3.p1.3.m3.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS3.p1.3.m3.1.1.1.2" xref="S3.SS3.p1.3.m3.1.1.1.1.cmml">(</mo><mrow id="S3.SS3.p1.3.m3.1.1.1.1" xref="S3.SS3.p1.3.m3.1.1.1.1.cmml"><mi id="S3.SS3.p1.3.m3.1.1.1.1.2" xref="S3.SS3.p1.3.m3.1.1.1.1.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.3.m3.1.1.1.1.1" xref="S3.SS3.p1.3.m3.1.1.1.1.1.cmml">​</mo><mi id="S3.SS3.p1.3.m3.1.1.1.1.3" xref="S3.SS3.p1.3.m3.1.1.1.1.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.3.m3.1.1.1.1.1a" xref="S3.SS3.p1.3.m3.1.1.1.1.1.cmml">​</mo><mi id="S3.SS3.p1.3.m3.1.1.1.1.4" xref="S3.SS3.p1.3.m3.1.1.1.1.4.cmml">i</mi></mrow><mo stretchy="false" id="S3.SS3.p1.3.m3.1.1.1.3" xref="S3.SS3.p1.3.m3.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.3.m3.1b"><apply id="S3.SS3.p1.3.m3.1.1.1.1.cmml" xref="S3.SS3.p1.3.m3.1.1.1"><times id="S3.SS3.p1.3.m3.1.1.1.1.1.cmml" xref="S3.SS3.p1.3.m3.1.1.1.1.1"></times><ci id="S3.SS3.p1.3.m3.1.1.1.1.2.cmml" xref="S3.SS3.p1.3.m3.1.1.1.1.2">𝑖</ci><ci id="S3.SS3.p1.3.m3.1.1.1.1.3.cmml" xref="S3.SS3.p1.3.m3.1.1.1.1.3">𝑖</ci><ci id="S3.SS3.p1.3.m3.1.1.1.1.4.cmml" xref="S3.SS3.p1.3.m3.1.1.1.1.4">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.3.m3.1c">(iii)</annotation></semantics></math> delegate aggregation to peers rather than a central entity.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.1" class="ltx_p">During the keyword search, articles were collected based on the presence of specific terms, even if mentioned only once in the paper. However, articles that did not meet the predetermined criteria or were deemed irrelevant were excluded from the review. Examples of excluded articles encompassed those that lacked full decentralization or exhibited hybrid characteristics, studies that did not focus on decentralization and centralized orchestration problems, as well as pre-prints, book parts, and abstracts. The inclusion and exclusion process is depicted in Fig. <a href="#S3.F2" title="Figure 2 ‣ 3.2. Search Process ‣ 3. Research Method ‣ A Survey on Decentralized Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<div id="S3.SS3.p3" class="ltx_para">
<p id="S3.SS3.p3.1" class="ltx_p">Initially, a total of 112 articles were retrieved from the specified databases. After removing duplicates, 81 articles remained for further analysis. These articles underwent two rounds of screening. Initially, the titles and abstracts were meticulously reviewed, resulting in the exclusion of 36 articles. Subsequently, the full texts of the remaining 45 articles were thoroughly examined, leading to the disqualification of an additional 21 papers. Ultimately, 24 articles were identified from the initial pool of 112 articles and included in the final review.</p>
</div>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4. </span>Data Extraction</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.1" class="ltx_p">The data collection process was centered on addressing the research questions of our study. Each of the 24 articles was individually examined, and distinct data points were extracted to inform our findings. The collected data were systematically recorded in a spreadsheet. The following information was extracted from each article:</p>
<ol id="S3.I2" class="ltx_enumerate">
<li id="S3.I2.ix1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><math id="S3.I2.ix1.1.1.m1.1" class="ltx_Math" alttext="(i)" display="inline"><semantics id="S3.I2.ix1.1.1.m1.1b"><mrow id="S3.I2.ix1.1.1.m1.1.2.2"><mo stretchy="false" id="S3.I2.ix1.1.1.m1.1.2.2.1">(</mo><mi id="S3.I2.ix1.1.1.m1.1.1" xref="S3.I2.ix1.1.1.m1.1.1.cmml">i</mi><mo stretchy="false" id="S3.I2.ix1.1.1.m1.1.2.2.2">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.I2.ix1.1.1.m1.1c"><ci id="S3.I2.ix1.1.1.m1.1.1.cmml" xref="S3.I2.ix1.1.1.m1.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.ix1.1.1.m1.1d">(i)</annotation></semantics></math></span> 
<div id="S3.I2.ix1.p1" class="ltx_para">
<p id="S3.I2.ix1.p1.1" class="ltx_p">Document title, publication year, and the name of the journal/conference in which it was published.</p>
</div>
</li>
<li id="S3.I2.ix2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><math id="S3.I2.ix2.1.1.m1.1" class="ltx_Math" alttext="(ii)" display="inline"><semantics id="S3.I2.ix2.1.1.m1.1b"><mrow id="S3.I2.ix2.1.1.m1.1.1.1" xref="S3.I2.ix2.1.1.m1.1.1.1.1.cmml"><mo stretchy="false" id="S3.I2.ix2.1.1.m1.1.1.1.2" xref="S3.I2.ix2.1.1.m1.1.1.1.1.cmml">(</mo><mrow id="S3.I2.ix2.1.1.m1.1.1.1.1" xref="S3.I2.ix2.1.1.m1.1.1.1.1.cmml"><mi id="S3.I2.ix2.1.1.m1.1.1.1.1.2" xref="S3.I2.ix2.1.1.m1.1.1.1.1.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.I2.ix2.1.1.m1.1.1.1.1.1" xref="S3.I2.ix2.1.1.m1.1.1.1.1.1.cmml">​</mo><mi id="S3.I2.ix2.1.1.m1.1.1.1.1.3" xref="S3.I2.ix2.1.1.m1.1.1.1.1.3.cmml">i</mi></mrow><mo stretchy="false" id="S3.I2.ix2.1.1.m1.1.1.1.3" xref="S3.I2.ix2.1.1.m1.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.I2.ix2.1.1.m1.1c"><apply id="S3.I2.ix2.1.1.m1.1.1.1.1.cmml" xref="S3.I2.ix2.1.1.m1.1.1.1"><times id="S3.I2.ix2.1.1.m1.1.1.1.1.1.cmml" xref="S3.I2.ix2.1.1.m1.1.1.1.1.1"></times><ci id="S3.I2.ix2.1.1.m1.1.1.1.1.2.cmml" xref="S3.I2.ix2.1.1.m1.1.1.1.1.2">𝑖</ci><ci id="S3.I2.ix2.1.1.m1.1.1.1.1.3.cmml" xref="S3.I2.ix2.1.1.m1.1.1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.ix2.1.1.m1.1d">(ii)</annotation></semantics></math></span> 
<div id="S3.I2.ix2.p1" class="ltx_para">
<p id="S3.I2.ix2.p1.1" class="ltx_p">Details of the datasets used and the federated settings in which they were employed.</p>
</div>
</li>
<li id="S3.I2.ix3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><math id="S3.I2.ix3.1.1.m1.1" class="ltx_Math" alttext="(iii)" display="inline"><semantics id="S3.I2.ix3.1.1.m1.1b"><mrow id="S3.I2.ix3.1.1.m1.1.1.1" xref="S3.I2.ix3.1.1.m1.1.1.1.1.cmml"><mo stretchy="false" id="S3.I2.ix3.1.1.m1.1.1.1.2" xref="S3.I2.ix3.1.1.m1.1.1.1.1.cmml">(</mo><mrow id="S3.I2.ix3.1.1.m1.1.1.1.1" xref="S3.I2.ix3.1.1.m1.1.1.1.1.cmml"><mi id="S3.I2.ix3.1.1.m1.1.1.1.1.2" xref="S3.I2.ix3.1.1.m1.1.1.1.1.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.I2.ix3.1.1.m1.1.1.1.1.1" xref="S3.I2.ix3.1.1.m1.1.1.1.1.1.cmml">​</mo><mi id="S3.I2.ix3.1.1.m1.1.1.1.1.3" xref="S3.I2.ix3.1.1.m1.1.1.1.1.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.I2.ix3.1.1.m1.1.1.1.1.1b" xref="S3.I2.ix3.1.1.m1.1.1.1.1.1.cmml">​</mo><mi id="S3.I2.ix3.1.1.m1.1.1.1.1.4" xref="S3.I2.ix3.1.1.m1.1.1.1.1.4.cmml">i</mi></mrow><mo stretchy="false" id="S3.I2.ix3.1.1.m1.1.1.1.3" xref="S3.I2.ix3.1.1.m1.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.I2.ix3.1.1.m1.1c"><apply id="S3.I2.ix3.1.1.m1.1.1.1.1.cmml" xref="S3.I2.ix3.1.1.m1.1.1.1"><times id="S3.I2.ix3.1.1.m1.1.1.1.1.1.cmml" xref="S3.I2.ix3.1.1.m1.1.1.1.1.1"></times><ci id="S3.I2.ix3.1.1.m1.1.1.1.1.2.cmml" xref="S3.I2.ix3.1.1.m1.1.1.1.1.2">𝑖</ci><ci id="S3.I2.ix3.1.1.m1.1.1.1.1.3.cmml" xref="S3.I2.ix3.1.1.m1.1.1.1.1.3">𝑖</ci><ci id="S3.I2.ix3.1.1.m1.1.1.1.1.4.cmml" xref="S3.I2.ix3.1.1.m1.1.1.1.1.4">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.ix3.1.1.m1.1d">(iii)</annotation></semantics></math></span> 
<div id="S3.I2.ix3.p1" class="ltx_para">
<p id="S3.I2.ix3.p1.1" class="ltx_p">Identification of whether the implementation utilized “standard” distributed computing approaches (e.g., P2P) or blockchain technology.</p>
</div>
</li>
<li id="S3.I2.ix4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><math id="S3.I2.ix4.1.1.m1.1" class="ltx_Math" alttext="(iv)" display="inline"><semantics id="S3.I2.ix4.1.1.m1.1b"><mrow id="S3.I2.ix4.1.1.m1.1.1.1" xref="S3.I2.ix4.1.1.m1.1.1.1.1.cmml"><mo stretchy="false" id="S3.I2.ix4.1.1.m1.1.1.1.2" xref="S3.I2.ix4.1.1.m1.1.1.1.1.cmml">(</mo><mrow id="S3.I2.ix4.1.1.m1.1.1.1.1" xref="S3.I2.ix4.1.1.m1.1.1.1.1.cmml"><mi id="S3.I2.ix4.1.1.m1.1.1.1.1.2" xref="S3.I2.ix4.1.1.m1.1.1.1.1.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.I2.ix4.1.1.m1.1.1.1.1.1" xref="S3.I2.ix4.1.1.m1.1.1.1.1.1.cmml">​</mo><mi id="S3.I2.ix4.1.1.m1.1.1.1.1.3" xref="S3.I2.ix4.1.1.m1.1.1.1.1.3.cmml">v</mi></mrow><mo stretchy="false" id="S3.I2.ix4.1.1.m1.1.1.1.3" xref="S3.I2.ix4.1.1.m1.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.I2.ix4.1.1.m1.1c"><apply id="S3.I2.ix4.1.1.m1.1.1.1.1.cmml" xref="S3.I2.ix4.1.1.m1.1.1.1"><times id="S3.I2.ix4.1.1.m1.1.1.1.1.1.cmml" xref="S3.I2.ix4.1.1.m1.1.1.1.1.1"></times><ci id="S3.I2.ix4.1.1.m1.1.1.1.1.2.cmml" xref="S3.I2.ix4.1.1.m1.1.1.1.1.2">𝑖</ci><ci id="S3.I2.ix4.1.1.m1.1.1.1.1.3.cmml" xref="S3.I2.ix4.1.1.m1.1.1.1.1.3">𝑣</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.ix4.1.1.m1.1d">(iv)</annotation></semantics></math></span> 
<div id="S3.I2.ix4.p1" class="ltx_para">
<p id="S3.I2.ix4.p1.1" class="ltx_p">The algorithms employed for training machine learning models.</p>
</div>
</li>
<li id="S3.I2.ix5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><math id="S3.I2.ix5.1.1.m1.1" class="ltx_Math" alttext="(v)" display="inline"><semantics id="S3.I2.ix5.1.1.m1.1b"><mrow id="S3.I2.ix5.1.1.m1.1.2.2"><mo stretchy="false" id="S3.I2.ix5.1.1.m1.1.2.2.1">(</mo><mi id="S3.I2.ix5.1.1.m1.1.1" xref="S3.I2.ix5.1.1.m1.1.1.cmml">v</mi><mo stretchy="false" id="S3.I2.ix5.1.1.m1.1.2.2.2">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.I2.ix5.1.1.m1.1c"><ci id="S3.I2.ix5.1.1.m1.1.1.cmml" xref="S3.I2.ix5.1.1.m1.1.1">𝑣</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.ix5.1.1.m1.1d">(v)</annotation></semantics></math></span> 
<div id="S3.I2.ix5.p1" class="ltx_para">
<p id="S3.I2.ix5.p1.1" class="ltx_p">Performance metrics, main results, and limitations.</p>
</div>
</li>
</ol>
<p id="S3.SS4.p1.2" class="ltx_p">By gathering this information, we aimed to obtain a comprehensive understanding of the articles’ content and to extract relevant data points for analysis in order to address our research questions effectively.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>A Taxonomy of Decentralized FL Approaches</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">Several attempts have been made to overcome the limitation posed by the centralized orchestration of standard FL.
In this section, we present the most relevant approaches toward DFL proposed in the literature.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.1" class="ltx_p">We broadly categorize existing methods into the following two-class taxonomy:</p>
<ul id="S4.I1" class="ltx_itemize">
<li id="S4.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i1.p1" class="ltx_para">
<p id="S4.I1.i1.p1.1" class="ltx_p"><span id="S4.I1.i1.p1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Traditional Distributed (TD-FL):</span> Methods in this class obtain FL decentralization through “standard” distributed computing techniques.</p>
</div>
</li>
<li id="S4.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i2.p1" class="ltx_para">
<p id="S4.I1.i2.p1.1" class="ltx_p"><span id="S4.I1.i2.p1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Blockchain-based (BC-FL):</span> This class contains all the approaches that achieve FL decentralization by exploiting Blockchain functionalities.</p>
</div>
</li>
</ul>
</div>
<div id="S4.p3" class="ltx_para">
<p id="S4.p3.1" class="ltx_p">In Table <a href="#S4.T2" title="Table 2 ‣ 4. A Taxonomy of Decentralized FL Approaches ‣ A Survey on Decentralized Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, we summarize the main characteristics of the approaches that will be discussed in this survey according to our taxonomy.</p>
<div id="S4.p3.2" class="ltx_logical-block">
<figure id="S4.T2" class="ltx_table ltx_align_center">
<div id="S4.T2.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:971.5pt;height:451pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="S4.T2.1.1" class="ltx_p"><span id="S4.T2.1.1.1" class="ltx_text">
<span id="S4.T2.1.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T2.1.1.1.1.2" class="ltx_tr">
<span id="S4.T2.1.1.1.1.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
Category</span>
<span id="S4.T2.1.1.1.1.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Approach</span>
<span id="S4.T2.1.1.1.1.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Model</span>
<span id="S4.T2.1.1.1.1.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Data Partitioning</span>
<span id="S4.T2.1.1.1.1.2.5" class="ltx_td ltx_align_center ltx_border_t">Dataset</span></span>
<span id="S4.T2.1.1.1.1.3" class="ltx_tr">
<span id="S4.T2.1.1.1.1.3.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t ltx_rowspan ltx_rowspan_12"><span id="S4.T2.1.1.1.1.3.1.1" class="ltx_text">TD-FL</span></span>
<span id="S4.T2.1.1.1.1.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">IPLS <cite class="ltx_cite ltx_citemacro_citep">(Pappas et al<span class="ltx_text">.</span>, <a href="#bib.bib68" title="" class="ltx_ref">2021</a>)</cite></span>
<span id="S4.T2.1.1.1.1.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">NN</span>
<span id="S4.T2.1.1.1.1.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Vertical, IID</span>
<span id="S4.T2.1.1.1.1.3.5" class="ltx_td ltx_align_center ltx_border_t">MNIST</span></span>
<span id="S4.T2.1.1.1.1.4" class="ltx_tr">
<span id="S4.T2.1.1.1.1.4.1" class="ltx_td ltx_align_center ltx_border_r">DFL-UN <cite class="ltx_cite ltx_citemacro_citep">(Qu et al<span class="ltx_text">.</span>, <a href="#bib.bib75" title="" class="ltx_ref">2021a</a>)</cite></span>
<span id="S4.T2.1.1.1.1.4.2" class="ltx_td ltx_align_center ltx_border_r">CNN</span>
<span id="S4.T2.1.1.1.1.4.3" class="ltx_td ltx_align_center ltx_border_r">Horizontal, Non-IID</span>
<span id="S4.T2.1.1.1.1.4.4" class="ltx_td ltx_align_center">N/A</span></span>
<span id="S4.T2.1.1.1.1.5" class="ltx_tr">
<span id="S4.T2.1.1.1.1.5.1" class="ltx_td ltx_align_center ltx_border_r">ProxyFL <cite class="ltx_cite ltx_citemacro_citep">(Kalra et al<span class="ltx_text">.</span>, <a href="#bib.bib34" title="" class="ltx_ref">2023</a>)</cite></span>
<span id="S4.T2.1.1.1.1.5.2" class="ltx_td ltx_align_center ltx_border_r">NN, CNN</span>
<span id="S4.T2.1.1.1.1.5.3" class="ltx_td ltx_align_center ltx_border_r">Horizontal, IID, Non-IID</span>
<span id="S4.T2.1.1.1.1.5.4" class="ltx_td ltx_align_center">MNIST, FMNIST, CIFAR-10</span></span>
<span id="S4.T2.1.1.1.1.6" class="ltx_tr">
<span id="S4.T2.1.1.1.1.6.1" class="ltx_td ltx_align_center ltx_border_r">PVD-FL <cite class="ltx_cite ltx_citemacro_citep">(Zhao et al<span class="ltx_text">.</span>, <a href="#bib.bib101" title="" class="ltx_ref">2022</a>)</cite></span>
<span id="S4.T2.1.1.1.1.6.2" class="ltx_td ltx_align_center ltx_border_r">NN</span>
<span id="S4.T2.1.1.1.1.6.3" class="ltx_td ltx_align_center ltx_border_r">Vertical, IID</span>
<span id="S4.T2.1.1.1.1.6.4" class="ltx_td ltx_align_center">MNIST, Thyroid, Breast Cancer, German Credit</span></span>
<span id="S4.T2.1.1.1.1.7" class="ltx_tr">
<span id="S4.T2.1.1.1.1.7.1" class="ltx_td ltx_align_center ltx_border_r">Trusted DFL <cite class="ltx_cite ltx_citemacro_citep">(Gholami et al<span class="ltx_text">.</span>, <a href="#bib.bib22" title="" class="ltx_ref">2022</a>)</cite></span>
<span id="S4.T2.1.1.1.1.7.2" class="ltx_td ltx_align_center ltx_border_r">NN</span>
<span id="S4.T2.1.1.1.1.7.3" class="ltx_td ltx_align_center ltx_border_r">Horizontal, Non-IID</span>
<span id="S4.T2.1.1.1.1.7.4" class="ltx_td ltx_align_center">N/A</span></span>
<span id="S4.T2.1.1.1.1.8" class="ltx_tr">
<span id="S4.T2.1.1.1.1.8.1" class="ltx_td ltx_align_center ltx_border_r">GossipFL <cite class="ltx_cite ltx_citemacro_citep">(Tang et al<span class="ltx_text">.</span>, <a href="#bib.bib86" title="" class="ltx_ref">2023</a>)</cite></span>
<span id="S4.T2.1.1.1.1.8.2" class="ltx_td ltx_align_center ltx_border_r">CNN, ResNet-20</span>
<span id="S4.T2.1.1.1.1.8.3" class="ltx_td ltx_align_center ltx_border_r">Horizontal, IID, Non-IID</span>
<span id="S4.T2.1.1.1.1.8.4" class="ltx_td ltx_align_center">MNIST, CIFAR-10</span></span>
<span id="S4.T2.1.1.1.1.9" class="ltx_tr">
<span id="S4.T2.1.1.1.1.9.1" class="ltx_td ltx_align_center ltx_border_r">Combo <cite class="ltx_cite ltx_citemacro_citep">(Hu et al<span class="ltx_text">.</span>, <a href="#bib.bib28" title="" class="ltx_ref">2019</a>)</cite></span>
<span id="S4.T2.1.1.1.1.9.2" class="ltx_td ltx_align_center ltx_border_r">CNN</span>
<span id="S4.T2.1.1.1.1.9.3" class="ltx_td ltx_align_center ltx_border_r">Horizontal, IID</span>
<span id="S4.T2.1.1.1.1.9.4" class="ltx_td ltx_align_center">CIFAR-10</span></span>
<span id="S4.T2.1.1.1.1.10" class="ltx_tr">
<span id="S4.T2.1.1.1.1.10.1" class="ltx_td ltx_align_center ltx_border_r">Def-KT <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib42" title="" class="ltx_ref">2022a</a>)</cite></span>
<span id="S4.T2.1.1.1.1.10.2" class="ltx_td ltx_align_center ltx_border_r">NN, CNN</span>
<span id="S4.T2.1.1.1.1.10.3" class="ltx_td ltx_align_center ltx_border_r">Horizontal, IID, Non-IID</span>
<span id="S4.T2.1.1.1.1.10.4" class="ltx_td ltx_align_center">MNIST, FMNIST, CIFAR-10, CIFAR-100</span></span>
<span id="S4.T2.1.1.1.1.11" class="ltx_tr">
<span id="S4.T2.1.1.1.1.11.1" class="ltx_td ltx_align_center ltx_border_r">P2P FL over graphs <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a href="#bib.bib90" title="" class="ltx_ref">2022</a>)</cite></span>
<span id="S4.T2.1.1.1.1.11.2" class="ltx_td ltx_align_center ltx_border_r">Bayesian Linear Regression</span>
<span id="S4.T2.1.1.1.1.11.3" class="ltx_td ltx_align_center ltx_border_r">Horizontal, Non-IID</span>
<span id="S4.T2.1.1.1.1.11.4" class="ltx_td ltx_align_center">MNIST, FMNIST, FEMNIST</span></span>
<span id="S4.T2.1.1.1.1.12" class="ltx_tr">
<span id="S4.T2.1.1.1.1.12.1" class="ltx_td ltx_align_center ltx_border_r">PANM <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a href="#bib.bib90" title="" class="ltx_ref">2022</a>)</cite></span>
<span id="S4.T2.1.1.1.1.12.2" class="ltx_td ltx_align_center ltx_border_r">NN, CNN</span>
<span id="S4.T2.1.1.1.1.12.3" class="ltx_td ltx_align_center ltx_border_r">Horizontal, Non-IID</span>
<span id="S4.T2.1.1.1.1.12.4" class="ltx_td ltx_align_center">MNIST, FMNIST, CIFAR-10</span></span>
<span id="S4.T2.1.1.1.1.13" class="ltx_tr">
<span id="S4.T2.1.1.1.1.13.1" class="ltx_td ltx_align_center ltx_border_r">FDFL <cite class="ltx_cite ltx_citemacro_citep">(Lalitha, <a href="#bib.bib40" title="" class="ltx_ref">2018</a>)</cite></span>
<span id="S4.T2.1.1.1.1.13.2" class="ltx_td ltx_align_center ltx_border_r">N/A</span>
<span id="S4.T2.1.1.1.1.13.3" class="ltx_td ltx_align_center ltx_border_r">Horizontal, Non-IID</span>
<span id="S4.T2.1.1.1.1.13.4" class="ltx_td ltx_align_center">N/A</span></span>
<span id="S4.T2.1.1.1.1.14" class="ltx_tr">
<span id="S4.T2.1.1.1.1.14.1" class="ltx_td ltx_align_center ltx_border_r">BrainTorrent <cite class="ltx_cite ltx_citemacro_citep">(Roy et al<span class="ltx_text">.</span>, <a href="#bib.bib81" title="" class="ltx_ref">2019</a>)</cite></span>
<span id="S4.T2.1.1.1.1.14.2" class="ltx_td ltx_align_center ltx_border_r">Quicknat</span>
<span id="S4.T2.1.1.1.1.14.3" class="ltx_td ltx_align_center ltx_border_r">Horizontal, Non-IID</span>
<span id="S4.T2.1.1.1.1.14.4" class="ltx_td ltx_align_center">MALC</span></span>
<span id="S4.T2.1.1.1.1.15" class="ltx_tr">
<span id="S4.T2.1.1.1.1.15.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t ltx_rowspan ltx_rowspan_12"><span id="S4.T2.1.1.1.1.15.1.1" class="ltx_text">BC-FL</span></span>
<span id="S4.T2.1.1.1.1.15.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">BlockFL <cite class="ltx_cite ltx_citemacro_citep">(Kim et al<span class="ltx_text">.</span>, <a href="#bib.bib37" title="" class="ltx_ref">2020</a>)</cite></span>
<span id="S4.T2.1.1.1.1.15.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">NN</span>
<span id="S4.T2.1.1.1.1.15.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Horizontal, IID</span>
<span id="S4.T2.1.1.1.1.15.5" class="ltx_td ltx_align_center ltx_border_t">N/A</span></span>
<span id="S4.T2.1.1.1.1.16" class="ltx_tr">
<span id="S4.T2.1.1.1.1.16.1" class="ltx_td ltx_align_center ltx_border_r">BAFL <cite class="ltx_cite ltx_citemacro_citep">(Feng et al<span class="ltx_text">.</span>, <a href="#bib.bib21" title="" class="ltx_ref">2022</a>)</cite></span>
<span id="S4.T2.1.1.1.1.16.2" class="ltx_td ltx_align_center ltx_border_r">CNN</span>
<span id="S4.T2.1.1.1.1.16.3" class="ltx_td ltx_align_center ltx_border_r">Horizontal, IID</span>
<span id="S4.T2.1.1.1.1.16.4" class="ltx_td ltx_align_center">MNIST</span></span>
<span id="S4.T2.1.1.1.1.1" class="ltx_tr">
<span id="S4.T2.1.1.1.1.1.2" class="ltx_td ltx_align_center ltx_border_r">BLADE-FL <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib43" title="" class="ltx_ref">2022c</a>)</cite></span>
<span id="S4.T2.1.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_r">NN, VGG<sub id="S4.T2.1.1.1.1.1.1.1" class="ltx_sub"><span id="S4.T2.1.1.1.1.1.1.1.1" class="ltx_text ltx_font_italic">11</span></sub></span>
<span id="S4.T2.1.1.1.1.1.3" class="ltx_td ltx_align_center ltx_border_r">Horizontal, Non-IID</span>
<span id="S4.T2.1.1.1.1.1.4" class="ltx_td ltx_align_center">MNIST, CIFAR-10, FMNIST, SVHN</span></span>
<span id="S4.T2.1.1.1.1.17" class="ltx_tr">
<span id="S4.T2.1.1.1.1.17.1" class="ltx_td ltx_align_center ltx_border_r">Privacy-Preserving for IoT Devices <cite class="ltx_cite ltx_citemacro_citep">(Zhao et al<span class="ltx_text">.</span>, <a href="#bib.bib103" title="" class="ltx_ref">2021</a>)</cite></span>
<span id="S4.T2.1.1.1.1.17.2" class="ltx_td ltx_align_center ltx_border_r">CNN</span>
<span id="S4.T2.1.1.1.1.17.3" class="ltx_td ltx_align_center ltx_border_r">Horizontal, IID</span>
<span id="S4.T2.1.1.1.1.17.4" class="ltx_td ltx_align_center">MNIST</span></span>
<span id="S4.T2.1.1.1.1.18" class="ltx_tr">
<span id="S4.T2.1.1.1.1.18.1" class="ltx_td ltx_align_center ltx_border_r">DeepChain <cite class="ltx_cite ltx_citemacro_citep">(Weng et al<span class="ltx_text">.</span>, <a href="#bib.bib91" title="" class="ltx_ref">2021</a>)</cite></span>
<span id="S4.T2.1.1.1.1.18.2" class="ltx_td ltx_align_center ltx_border_r">CNN</span>
<span id="S4.T2.1.1.1.1.18.3" class="ltx_td ltx_align_center ltx_border_r">Horizontal, IID</span>
<span id="S4.T2.1.1.1.1.18.4" class="ltx_td ltx_align_center">MNIST</span></span>
<span id="S4.T2.1.1.1.1.19" class="ltx_tr">
<span id="S4.T2.1.1.1.1.19.1" class="ltx_td ltx_align_center ltx_border_r">GFL <cite class="ltx_cite ltx_citemacro_citep">(Hu et al<span class="ltx_text">.</span>, <a href="#bib.bib29" title="" class="ltx_ref">2021</a>)</cite></span>
<span id="S4.T2.1.1.1.1.19.2" class="ltx_td ltx_align_center ltx_border_r">CNN</span>
<span id="S4.T2.1.1.1.1.19.3" class="ltx_td ltx_align_center ltx_border_r">Horizontal, Non-IID</span>
<span id="S4.T2.1.1.1.1.19.4" class="ltx_td ltx_align_center">MNIST, CIFAR-10, CIFAR-100</span></span>
<span id="S4.T2.1.1.1.1.20" class="ltx_tr">
<span id="S4.T2.1.1.1.1.20.1" class="ltx_td ltx_align_center ltx_border_r">FED-BC <cite class="ltx_cite ltx_citemacro_citep">(Wu et al<span class="ltx_text">.</span>, <a href="#bib.bib93" title="" class="ltx_ref">2020b</a>)</cite></span>
<span id="S4.T2.1.1.1.1.20.2" class="ltx_td ltx_align_center ltx_border_r">NN</span>
<span id="S4.T2.1.1.1.1.20.3" class="ltx_td ltx_align_center ltx_border_r">Horizontal, Non-IID</span>
<span id="S4.T2.1.1.1.1.20.4" class="ltx_td ltx_align_center">MNIST</span></span>
<span id="S4.T2.1.1.1.1.21" class="ltx_tr">
<span id="S4.T2.1.1.1.1.21.1" class="ltx_td ltx_align_center ltx_border_r">Biscotti <cite class="ltx_cite ltx_citemacro_citep">(Shayan et al<span class="ltx_text">.</span>, <a href="#bib.bib83" title="" class="ltx_ref">2021</a>)</cite></span>
<span id="S4.T2.1.1.1.1.21.2" class="ltx_td ltx_align_center ltx_border_r">Linear Regression, Softmax Classifier</span>
<span id="S4.T2.1.1.1.1.21.3" class="ltx_td ltx_align_center ltx_border_r">Horizontal, IID</span>
<span id="S4.T2.1.1.1.1.21.4" class="ltx_td ltx_align_center">Credit Card Fraud, MNIST</span></span>
<span id="S4.T2.1.1.1.1.22" class="ltx_tr">
<span id="S4.T2.1.1.1.1.22.1" class="ltx_td ltx_align_center ltx_border_r">BytoChain <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib48" title="" class="ltx_ref">2021b</a>)</cite></span>
<span id="S4.T2.1.1.1.1.22.2" class="ltx_td ltx_align_center ltx_border_r">CNN</span>
<span id="S4.T2.1.1.1.1.22.3" class="ltx_td ltx_align_center ltx_border_r">Horizontal, IID</span>
<span id="S4.T2.1.1.1.1.22.4" class="ltx_td ltx_align_center">MNIST</span></span>
<span id="S4.T2.1.1.1.1.23" class="ltx_tr">
<span id="S4.T2.1.1.1.1.23.1" class="ltx_td ltx_align_center ltx_border_r">PIRATE <cite class="ltx_cite ltx_citemacro_citep">(Zhou et al<span class="ltx_text">.</span>, <a href="#bib.bib106" title="" class="ltx_ref">2019a</a>)</cite></span>
<span id="S4.T2.1.1.1.1.23.2" class="ltx_td ltx_align_center ltx_border_r">NN</span>
<span id="S4.T2.1.1.1.1.23.3" class="ltx_td ltx_align_center ltx_border_r">Horizontal, IID</span>
<span id="S4.T2.1.1.1.1.23.4" class="ltx_td ltx_align_center">N/A</span></span>
<span id="S4.T2.1.1.1.1.24" class="ltx_tr">
<span id="S4.T2.1.1.1.1.24.1" class="ltx_td ltx_align_center ltx_border_r">Trustworthy FL <cite class="ltx_cite ltx_citemacro_citep">(Yang et al<span class="ltx_text">.</span>, <a href="#bib.bib97" title="" class="ltx_ref">2023</a>)</cite></span>
<span id="S4.T2.1.1.1.1.24.2" class="ltx_td ltx_align_center ltx_border_r">CNN, AlexNet, NN</span>
<span id="S4.T2.1.1.1.1.24.3" class="ltx_td ltx_align_center ltx_border_r">Horizontal, IID, Non-IID</span>
<span id="S4.T2.1.1.1.1.24.4" class="ltx_td ltx_align_center">MNIST, CIFAR-10, HeartActivity</span></span>
<span id="S4.T2.1.1.1.1.25" class="ltx_tr">
<span id="S4.T2.1.1.1.1.25.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">FedCoin <cite class="ltx_cite ltx_citemacro_citep">(Liu et al<span class="ltx_text">.</span>, <a href="#bib.bib50" title="" class="ltx_ref">2020</a>)</cite></span>
<span id="S4.T2.1.1.1.1.25.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">N/A</span>
<span id="S4.T2.1.1.1.1.25.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">Horizontal, IID</span>
<span id="S4.T2.1.1.1.1.25.4" class="ltx_td ltx_align_center ltx_border_b">MNIST</span></span>
</span></span></p>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T2.3.1.1" class="ltx_text" style="font-size:90%;">Table 2</span>. </span><span id="S4.T2.4.2" class="ltx_text" style="font-size:90%;">List of DFL approaches analyzed in this survey.</span></figcaption>
</figure>
</div>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1. </span>Traditional Distributed FL (TD-FL)</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">A possible solution to overcome the limitations of standard centralized FL is to adopt decentralized frameworks inspired by traditional distributed computing technologies, such as P2P networks.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p">In this work, we classify existing contributions falling into this category into four main groups: <span id="S4.SS1.p2.1.1" class="ltx_text ltx_font_italic">fault-tolerance and scalability</span>, <span id="S4.SS1.p2.1.2" class="ltx_text ltx_font_italic">privacy</span>, <span id="S4.SS1.p2.1.3" class="ltx_text ltx_font_italic">bandwidth utilization</span>, and <span id="S4.SS1.p2.1.4" class="ltx_text ltx_font_italic">data heterogeneity</span>. These categories succinctly represent the primary challenges encountered when dealing with TD-FL techniques and what the authors aim to solve. However, it is important to note that an article categorized into one group may also be susceptible to issues specific to other groups.</p>
</div>
<section id="S4.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.1. </span>Fault-tolerance and Scalability</h4>

<div id="S4.SS1.SSS1.p1" class="ltx_para">
<p id="S4.SS1.SSS1.p1.1" class="ltx_p">DFL systems could face problems regarding the failure of participants, or their connectivity medium, besides not scaling with the number of participants or not properly handling the joining of new peers.
In this section, we present two of the main works that tackle these issues.</p>
</div>
<div id="S4.SS1.SSS1.p2" class="ltx_para">
<p id="S4.SS1.SSS1.p2.1" class="ltx_p"><span id="S4.SS1.SSS1.p2.1.1" class="ltx_text ltx_font_bold ltx_font_italic">IPLS <cite class="ltx_cite ltx_citemacro_citep">(Pappas et al<span class="ltx_text">.</span>, <a href="#bib.bib68" title="" class="ltx_ref">2021</a>)</cite>.</span> This is a framework that operates as a fully decentralized system, leveraging the <span id="S4.SS1.SSS1.p2.1.2" class="ltx_text ltx_font_italic">interplanetary file system</span> (IPFS) <cite class="ltx_cite ltx_citemacro_citep">(Benet, <a href="#bib.bib9" title="" class="ltx_ref">2014</a>)</cite> and a private IPFS network, allowing any party to initiate or join an ongoing training process.
IPLS scales with the number of participants, remains robust against intermittent connectivity, and dynamically handles participant departures/arrivals while requiring minimal resources. Notably, the trained model’s accuracy quickly converges to that of a centralized FL framework with negligible accuracy drop (less than 1% in each case presented by the authors).
To further develop IPLS, several options are proposed. First, assessing its requirements and performance on heterogeneous devices is crucial. Additionally, exploring the feasibility of training state-of-the-art models within IPLS would be a priority. Enhancing performance by implementing a more sophisticated algorithm, allowing agents to dynamically adjust assigned partitions based on bandwidth and resources, would ensure timely updates. Integration of split learning techniques could enable devices with limited computational capabilities to participate effectively. Introducing an incentive mechanism within IPLS could motivate mobile users to share their resources and contribute to the ecosystem’s growth.</p>
</div>
<div id="S4.SS1.SSS1.p3" class="ltx_para">
<p id="S4.SS1.SSS1.p3.1" class="ltx_p"><span id="S4.SS1.SSS1.p3.1.1" class="ltx_text ltx_font_bold ltx_font_italic">DFL-UN <cite class="ltx_cite ltx_citemacro_citep">(Qu et al<span class="ltx_text">.</span>, <a href="#bib.bib75" title="" class="ltx_ref">2021a</a>)</cite>.</span> <span id="S4.SS1.SSS1.p3.1.2" class="ltx_text ltx_font_italic">Unmanned Aerial Vehicles</span> (UAVs), or drones, are envisioned to support extensive applications in next-generation wireless networks in both civil and military fields.
Centralized learning is discouraged in UAV networks, due to privacy concerns, and latency in transmitting raw data. However, centralized FL poses the challenge of relying on a single point of failure with unreliable links and nodes.
Therefore, the authors propose a DFL system over UAV Networks (DFL-UN) approach, where each UAV not only trains a local FL model over its own data, but also aggregates local models from one-hop neighboring UAVs and broadcasts the resulting model to them. This approach eliminates the need of a central entity for model aggregation, providing robustness and flexibility to the overall learning process, overcoming the concept of having a single global model for the entire network.
Authors also present preliminary results about model convergence and training latency on a small set of six UAVs with non-IID datasets and different computation or communication capabilities to simulate a real-world scenario. They demonstrate that the difference in terms of cross-entropy loss is less than <math id="S4.SS1.SSS1.p3.1.m1.1" class="ltx_Math" alttext="0.0229" display="inline"><semantics id="S4.SS1.SSS1.p3.1.m1.1a"><mn id="S4.SS1.SSS1.p3.1.m1.1.1" xref="S4.SS1.SSS1.p3.1.m1.1.1.cmml">0.0229</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.p3.1.m1.1b"><cn type="float" id="S4.SS1.SSS1.p3.1.m1.1.1.cmml" xref="S4.SS1.SSS1.p3.1.m1.1.1">0.0229</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.p3.1.m1.1c">0.0229</annotation></semantics></math> compared to the centralized counterpart, still maintaining the advantage. However, the latency for transmitting the updated local model to each one-hop neighbor opposed to the latency of broadcasting the global model to each UAV is always smaller.</p>
</div>
<div id="S4.SS1.SSS1.p4" class="ltx_para">
<p id="S4.SS1.SSS1.p4.1" class="ltx_p">There are a number of challenges to address. In highly dynamic UAV networks, the communication link between the coordinator and each UAV may be temporary, making it difficult to judge convergence in real-world contexts. Environmental factors such as mechanical vibrations and wind poses additional challenges. Moreover, the aerial-to-aerial (A2A) links used for communication are wireless and prone to failures.</p>
</div>
</section>
<section id="S4.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.2. </span>Privacy &amp; Security</h4>

<div id="S4.SS1.SSS2.p1" class="ltx_para">
<p id="S4.SS1.SSS2.p1.1" class="ltx_p">In a DFL setting, agents must implement some consensus mechanisms by exchanging local model updates. Despite bypassing the direct exchange of raw data between the collaborating agents, this scheme is still vulnerable to various security and privacy threats, such as model inversion attacks. To handle this problem, researchers devise privacy-preserving mechanisms.</p>
</div>
<div id="S4.SS1.SSS2.p2" class="ltx_para">
<p id="S4.SS1.SSS2.p2.1" class="ltx_p"><span id="S4.SS1.SSS2.p2.1.1" class="ltx_text ltx_font_bold ltx_font_italic">ProxyFL <cite class="ltx_cite ltx_citemacro_citep">(Kalra et al<span class="ltx_text">.</span>, <a href="#bib.bib34" title="" class="ltx_ref">2023</a>)</cite>.</span>
In this scheme, participants maintain two separate models: a private model and a publicly shared proxy model. The purpose of the proxy model is to protect the privacy of individual participants by not sharing the private model, while also enabling efficient information exchange among them without the need for a centralized server.
Key advantages of ProxyFL include reduced communication overhead and enhanced privacy protection. Participants can have their private models with different architectures, promoting model heterogeneity. Experimental results on image datasets and a cancer diagnostic problem show that ProxyFL outperforms existing alternatives in terms of communication efficiency and convergence speed.</p>
</div>
<div id="S4.SS1.SSS2.p3" class="ltx_para">
<p id="S4.SS1.SSS2.p3.1" class="ltx_p"><span id="S4.SS1.SSS2.p3.1.1" class="ltx_text ltx_font_bold ltx_font_italic">PVD-FL <cite class="ltx_cite ltx_citemacro_citep">(Zhao et al<span class="ltx_text">.</span>, <a href="#bib.bib101" title="" class="ltx_ref">2022</a>)</cite>.</span> This work presents a privacy-preserving and verifiable FL framework that ensures secure deep learning model training in a decentralized architecture. The authors introduce an efficient and verifiable cipher-based matrix multiplication (EVCM) algorithm, which is used as the basis for basic calculations in deep learning. Leveraging EVCM, they design a suite of decentralized algorithms to construct the PVD-FL framework, ensuring confidentiality for both the global model and local updates while verifying every training step.
Experiments were conducted on real-world datasets to demonstrate the practical performance and accuracy of PVD-FL. The results show that PVD-FL achieves lossless accuracy. However, the study acknowledges the need to verify the model’s integrity and assess its vulnerability to poisoning attacks, which could be potential areas for future research and investigation.</p>
</div>
<div id="S4.SS1.SSS2.p4" class="ltx_para">
<p id="S4.SS1.SSS2.p4.1" class="ltx_p"><span id="S4.SS1.SSS2.p4.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Trusted DFL <cite class="ltx_cite ltx_citemacro_citep">(Gholami et al<span class="ltx_text">.</span>, <a href="#bib.bib22" title="" class="ltx_ref">2022</a>)</cite>.</span> This work introduces a trusted DFL algorithm that relies on the concept of trust between network entities. Trust is seen as a relationship between different entities in the network who collaborate towards specific goals. This trust is established and updated based on evidence from previous collaborations. If the collaboration contributes positively to achieving the goal, trust between the parties increases, and if not, trust decreases.
Trust estimates play a crucial role in making decisions such as access control, resource allocation, agent participation, etc. The method for computing and aggregating trust within the network can vary based on the specific application. Trust inference is viewed as a consensus problem, focusing on both local and global trust estimates.
The proposed DFL algorithm integrates trust evaluation as a component within the FL framework. Experiments demonstrate that this approach can effectively defend against simple model poisoning attacks (i.e., randomly generated models by the attackers) during training.
One of the future directions for improvement involves considering packet losses in the algorithm to enhance its communication robustness.</p>
</div>
</section>
<section id="S4.SS1.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.3. </span>Bandwidth utilization</h4>

<div id="S4.SS1.SSS3.p1" class="ltx_para">
<p id="S4.SS1.SSS3.p1.1" class="ltx_p">When dealing with DFL, and more generally with P2P networks, participants must communicate with multiple peers, and in the worst case scenario the network topology could resemble a fully connected graph where each participant communicates with everyone.
Moreover, in real-world FL setups, the network capacities between nodes can vary significantly and are generally smaller than those typically found in centralized data centers. This non-uniform and limited distribution of network capacities poses a significant challenge for conventional FL approaches, as it hinders the efficient utilization of available network resources for communication and model updates. Thus, peer-selection strategies and methods to reduce the size of the communications are studied in the context of DFL.
Below, we review the most relevant works proposed in the literature attempting to address this issue.</p>
</div>
<div id="S4.SS1.SSS3.p2" class="ltx_para">
<p id="S4.SS1.SSS3.p2.1" class="ltx_p"><span id="S4.SS1.SSS3.p2.1.1" class="ltx_text ltx_font_bold ltx_font_italic">GossipFL <cite class="ltx_cite ltx_citemacro_citep">(Tang et al<span class="ltx_text">.</span>, <a href="#bib.bib86" title="" class="ltx_ref">2023</a>)</cite>.</span> This method introduces a communication-efficient DFL framework.
The authors propose a novel FL approach called GossipFL, designed to efficiently utilize network capacities in real-world setups. GossipFL introduces two key components: a <span id="S4.SS1.SSS3.p2.1.2" class="ltx_text ltx_font_italic">sparsification algorithm</span> and a <span id="S4.SS1.SSS3.p2.1.3" class="ltx_text ltx_font_italic">gossip matrix generation algorithm</span>.
The sparsification algorithm allows each client to communicate with only one peer during each communication round, exchanging a highly compressed model. This significantly reduces up-link and down-link communication traffic.
The gossip matrix generation algorithm enhances bandwidth resource utilization while preserving the convergence property. It dynamically determines peer selection for each client based on their connection bandwidth, ensuring efficient utilization of global bandwidth resources.
The GossipFL architecture involves two main roles: the coordinator and the clients. The coordinator acts as a central server managing the training process, while the clients, who possess local data, iteratively train the model. Clients exchange sparsified models with their assigned peers determined by the coordinator.
GossipFL is characterized by three key features:
</p>
<ul id="S4.I2" class="ltx_itemize">
<li id="S4.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i1.p1" class="ltx_para">
<p id="S4.I2.i1.p1.1" class="ltx_p"><span id="S4.I2.i1.p1.1.1" class="ltx_text ltx_font_italic">Reduced Communication Traffic</span>: Clients communicate with one peer, reducing communication overhead.</p>
</div>
</li>
<li id="S4.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i2.p1" class="ltx_para">
<p id="S4.I2.i2.p1.1" class="ltx_p"><span id="S4.I2.i2.p1.1.1" class="ltx_text ltx_font_italic">Efficient Bandwidth Utilization</span>: Peer selection is based on connection bandwidth, optimizing global resource usage.</p>
</div>
</li>
<li id="S4.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i3.p1" class="ltx_para">
<p id="S4.I2.i3.p1.1" class="ltx_p"><span id="S4.I2.i3.p1.1.1" class="ltx_text ltx_font_italic">Bandwidth-Aware Communication Topology</span>: The algorithm constructs a communication topology using a bandwidth-aware gossip matrix.</p>
</div>
</li>
</ul>
<p id="S4.SS1.SSS3.p2.2" class="ltx_p">The convergence property of GossipFL is theoretically analyzed, and extensive experiments are conducted using both IID and non-IID data to validate its effectiveness. The results demonstrate that GossipFL successfully reduces communication traffic, selects peers with higher bandwidth for efficient resource utilization, and maintains convergence performance.</p>
</div>
<div id="S4.SS1.SSS3.p3" class="ltx_para">
<p id="S4.SS1.SSS3.p3.1" class="ltx_p">GossipFL can be considered a “hybrid” approach since the communication is P2P, but the training process is coordinated through a central server. As a result, the central server does not experience communication pressure in this framework.</p>
</div>
<div id="S4.SS1.SSS3.p4" class="ltx_para">
<p id="S4.SS1.SSS3.p4.1" class="ltx_p"><span id="S4.SS1.SSS3.p4.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Combo <cite class="ltx_cite ltx_citemacro_citep">(Hu et al<span class="ltx_text">.</span>, <a href="#bib.bib28" title="" class="ltx_ref">2019</a>)</cite>.</span> Here, the authors propose a DFL framework that utilizes a <span id="S4.SS1.SSS3.p4.1.2" class="ltx_text ltx_font_italic">segmented gossip approach</span> to make full use of node-to-node bandwidth while maintaining good training convergence. The main contributions of this approach can be summarized as follows:</p>
<ul id="S4.I3" class="ltx_itemize">
<li id="S4.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I3.i1.p1" class="ltx_para">
<p id="S4.I3.i1.p1.2" class="ltx_p"><span id="S4.I3.i1.p1.2.1" class="ltx_text ltx_font_italic">Model Segmentation Level Synchronization</span>: The model is divided into non-overlapping subsets or segmentations, each containing the same number of model parameters. Workers update their local segmentations by aggregating them with the corresponding segments from a small subset of <math id="S4.I3.i1.p1.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S4.I3.i1.p1.1.m1.1a"><mi id="S4.I3.i1.p1.1.m1.1.1" xref="S4.I3.i1.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.I3.i1.p1.1.m1.1b"><ci id="S4.I3.i1.p1.1.m1.1.1.cmml" xref="S4.I3.i1.p1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.I3.i1.p1.1.m1.1c">k</annotation></semantics></math> other workers. The analysis shows that <math id="S4.I3.i1.p1.2.m2.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S4.I3.i1.p1.2.m2.1a"><mi id="S4.I3.i1.p1.2.m2.1.1" xref="S4.I3.i1.p1.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.I3.i1.p1.2.m2.1b"><ci id="S4.I3.i1.p1.2.m2.1.1.cmml" xref="S4.I3.i1.p1.2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.I3.i1.p1.2.m2.1c">k</annotation></semantics></math> can be much smaller than the total number of workers while still achieving satisfactory convergence during training.</p>
</div>
</li>
<li id="S4.I3.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I3.i2.p1" class="ltx_para">
<p id="S4.I3.i2.p1.1" class="ltx_p"><span id="S4.I3.i2.p1.1.1" class="ltx_text ltx_font_italic">Decentralized Gossip Protocol</span>: Inspired by the gossip protocol, each worker randomly selects a few other workers to exchange model segments during each training iteration. This approach aims to maximize the utilization of bandwidth capacities between workers. To enhance convergence, the “model replica” concept is introduced, ensuring sufficient information is acquired from different workers during the aggregation process.</p>
</div>
</li>
<li id="S4.I3.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I3.i3.p1" class="ltx_para">
<p id="S4.I3.i3.p1.1" class="ltx_p"><span id="S4.I3.i3.p1.1.1" class="ltx_text ltx_font_italic">Combo Prototype Development</span>: The proposed model segmentation and gossiping strategies are incorporated into a prototype called Combo. The performance of Combo is evaluated through experiments, demonstrating significant reductions in training time with only minimal accuracy degradation in practical network topologies and bandwidth configurations.</p>
</div>
</li>
</ul>
<p id="S4.SS1.SSS3.p4.2" class="ltx_p">Experiments show that Combo effectively utilize network bandwidth through segmented gossip aggregation while maintaining convergence performance better than FedAvg.</p>
</div>
</section>
<section id="S4.SS1.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.4. </span>Data heterogeneity</h4>

<div id="S4.SS1.SSS4.p1" class="ltx_para">
<p id="S4.SS1.SSS4.p1.1" class="ltx_p">Data heterogeneity refers to the problem where participants hold non-IID datasets. In this context, participants train models biased toward their local data distribution. Thus, when aggregating all them, the result could be sub-optimal or totally skewed <cite class="ltx_cite ltx_citemacro_citep">(Zhao et al<span class="ltx_text">.</span>, <a href="#bib.bib102" title="" class="ltx_ref">2018</a>)</cite>.
Below, we describe three methods to tackle this issue in a DFL context.</p>
</div>
<div id="S4.SS1.SSS4.p2" class="ltx_para">
<p id="S4.SS1.SSS4.p2.1" class="ltx_p"><span id="S4.SS1.SSS4.p2.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Def-KT <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib42" title="" class="ltx_ref">2022a</a>)</cite>.</span> In Def-KT, the authors addressed the DFL problem in IoT systems, wherein multiple IoT clients are responsible for training models for image classification tasks independently, without relying on a central server. This work presents a DFL solution, which leverages mutual knowledge transfer among local clients to mitigate performance degradation caused by client-drift in the presence of data heterogeneity. Def-KT demonstrates superiority over the selected baseline methods: FedAvg, FullAvg, and Combo.
Future studies can explore communication efficiency and theoretical analysis for Def-KT.</p>
</div>
<div id="S4.SS1.SSS4.p3" class="ltx_para">
<p id="S4.SS1.SSS4.p3.1" class="ltx_p"><span id="S4.SS1.SSS4.p3.1.1" class="ltx_text ltx_font_bold ltx_font_italic">P2P FL over graphs <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a href="#bib.bib90" title="" class="ltx_ref">2022</a>)</cite>.</span> In this work, local agents keep a posterior probability distribution over the parameters of a global model.
This approach provides the first theoretical guarantees for the realizable case, even in the presence of potentially non-IID local data distributions. It accommodates general network structures and non-IID data, providing theoretical guarantees of convergence for variational FL on any connected graph. Empirical evaluations demonstrate its practical advantage for handling non-IID data, especially as task complexity increases. The impact of social network structure on model convergence is illustrated, and the scalability of the approach in a time-varying asynchronous network is demonstrated. It also allows systematic treatment of model aggregation over arbitrarily connected graphs with consistent local labeled data, showing better accuracy over FedAvg on complex tasks when data is non-IID across agents. Additionally, the paper provides insights into how the selection of the underlying social network influences the convergence rate.</p>
</div>
<div id="S4.SS1.SSS4.p4" class="ltx_para">
<p id="S4.SS1.SSS4.p4.3" class="ltx_p"><span id="S4.SS1.SSS4.p4.3.1" class="ltx_text ltx_font_bold ltx_font_italic">PANM <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib47" title="" class="ltx_ref">2022b</a>)</cite>.</span> In PANM, authors deal with the problem of highly heterogeneous data by devising a method to cluster clients into similar groups without knowing in advance the number of clusters needed. The objective of this approach is to have one global model for each cluster, enabling better personalization. In essence, PANM is a two-stages algorithm to realize an adaptive topology based on clients similarities. This work is based on a previous study <cite class="ltx_cite ltx_citemacro_citep">(Onoszko et al<span class="ltx_text">.</span>, <a href="#bib.bib63" title="" class="ltx_ref">2021</a>)</cite>, but it improves their results by applying a different approach that reduces noisy neighbor estimations:</p>
<ol id="S4.I4" class="ltx_enumerate">
<li id="S4.I4.ix1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><math id="S4.I4.ix1.1.1.m1.1" class="ltx_Math" alttext="(i)" display="inline"><semantics id="S4.I4.ix1.1.1.m1.1b"><mrow id="S4.I4.ix1.1.1.m1.1.2.2"><mo stretchy="false" id="S4.I4.ix1.1.1.m1.1.2.2.1">(</mo><mi id="S4.I4.ix1.1.1.m1.1.1" xref="S4.I4.ix1.1.1.m1.1.1.cmml">i</mi><mo stretchy="false" id="S4.I4.ix1.1.1.m1.1.2.2.2">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.I4.ix1.1.1.m1.1c"><ci id="S4.I4.ix1.1.1.m1.1.1.cmml" xref="S4.I4.ix1.1.1.m1.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.I4.ix1.1.1.m1.1d">(i)</annotation></semantics></math></span> 
<div id="S4.I4.ix1.p1" class="ltx_para">
<p id="S4.I4.ix1.p1.1" class="ltx_p"><span id="S4.I4.ix1.p1.1.1" class="ltx_text ltx_font_italic">Neighbor Selection based on Monte Carlo</span> (NSMC): By introducing a gradient-based measure of similarity called <span id="S4.I4.ix1.p1.1.2" class="ltx_text ltx_font_italic">PANMGrad</span>, the aim is to identify the most similar peers as neighbors for each client. The Monte Carlo method enhances the neighborhood of each client by including randomly sampled peers in the candidate list. This approach ensures that the clients have a few neighbors with a high probability of being true neighbors.</p>
</div>
</li>
<li id="S4.I4.ix2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><math id="S4.I4.ix2.1.1.m1.1" class="ltx_Math" alttext="(ii)" display="inline"><semantics id="S4.I4.ix2.1.1.m1.1b"><mrow id="S4.I4.ix2.1.1.m1.1.1.1" xref="S4.I4.ix2.1.1.m1.1.1.1.1.cmml"><mo stretchy="false" id="S4.I4.ix2.1.1.m1.1.1.1.2" xref="S4.I4.ix2.1.1.m1.1.1.1.1.cmml">(</mo><mrow id="S4.I4.ix2.1.1.m1.1.1.1.1" xref="S4.I4.ix2.1.1.m1.1.1.1.1.cmml"><mi id="S4.I4.ix2.1.1.m1.1.1.1.1.2" xref="S4.I4.ix2.1.1.m1.1.1.1.1.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.I4.ix2.1.1.m1.1.1.1.1.1" xref="S4.I4.ix2.1.1.m1.1.1.1.1.1.cmml">​</mo><mi id="S4.I4.ix2.1.1.m1.1.1.1.1.3" xref="S4.I4.ix2.1.1.m1.1.1.1.1.3.cmml">i</mi></mrow><mo stretchy="false" id="S4.I4.ix2.1.1.m1.1.1.1.3" xref="S4.I4.ix2.1.1.m1.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.I4.ix2.1.1.m1.1c"><apply id="S4.I4.ix2.1.1.m1.1.1.1.1.cmml" xref="S4.I4.ix2.1.1.m1.1.1.1"><times id="S4.I4.ix2.1.1.m1.1.1.1.1.1.cmml" xref="S4.I4.ix2.1.1.m1.1.1.1.1.1"></times><ci id="S4.I4.ix2.1.1.m1.1.1.1.1.2.cmml" xref="S4.I4.ix2.1.1.m1.1.1.1.1.2">𝑖</ci><ci id="S4.I4.ix2.1.1.m1.1.1.1.1.3.cmml" xref="S4.I4.ix2.1.1.m1.1.1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I4.ix2.1.1.m1.1d">(ii)</annotation></semantics></math></span> 
<div id="S4.I4.ix2.p1" class="ltx_para">
<p id="S4.I4.ix2.p1.1" class="ltx_p"><span id="S4.I4.ix2.p1.1.1" class="ltx_text ltx_font_italic">Neighbor Augmentation Based on EM-GMM</span> (NAEM): With the GMM (Gaussian Mixture Model) assumption, given a set of randomly sampled peers, true neighbors with the same cluster identity follow a specific Gaussian distribution, while false neighbors follow another Gaussian distribution with a lower mean. Under this assumption, NAEM first samples clients from the neighborhood bag and non-neighbor set. Subsequently, the client computes the similarities that, according to the GMM assumption, adhere to two different Gaussian distributions. An adapted version of the Expectation-Maximization (EM) algorithm is then utilized to estimate distribution identities. This process enables clients to add new true neighbors while also eliminating outliers.</p>
</div>
</li>
</ol>
<p id="S4.SS1.SSS4.p4.2" class="ltx_p">PANM combines the previously described stages by initially applying NSMC for <math id="S4.SS1.SSS4.p4.1.m1.1" class="ltx_Math" alttext="T_{1}" display="inline"><semantics id="S4.SS1.SSS4.p4.1.m1.1a"><msub id="S4.SS1.SSS4.p4.1.m1.1.1" xref="S4.SS1.SSS4.p4.1.m1.1.1.cmml"><mi id="S4.SS1.SSS4.p4.1.m1.1.1.2" xref="S4.SS1.SSS4.p4.1.m1.1.1.2.cmml">T</mi><mn id="S4.SS1.SSS4.p4.1.m1.1.1.3" xref="S4.SS1.SSS4.p4.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS4.p4.1.m1.1b"><apply id="S4.SS1.SSS4.p4.1.m1.1.1.cmml" xref="S4.SS1.SSS4.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS4.p4.1.m1.1.1.1.cmml" xref="S4.SS1.SSS4.p4.1.m1.1.1">subscript</csymbol><ci id="S4.SS1.SSS4.p4.1.m1.1.1.2.cmml" xref="S4.SS1.SSS4.p4.1.m1.1.1.2">𝑇</ci><cn type="integer" id="S4.SS1.SSS4.p4.1.m1.1.1.3.cmml" xref="S4.SS1.SSS4.p4.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS4.p4.1.m1.1c">T_{1}</annotation></semantics></math> rounds and then proceeding with NAEM for <math id="S4.SS1.SSS4.p4.2.m2.1" class="ltx_Math" alttext="T_{2}" display="inline"><semantics id="S4.SS1.SSS4.p4.2.m2.1a"><msub id="S4.SS1.SSS4.p4.2.m2.1.1" xref="S4.SS1.SSS4.p4.2.m2.1.1.cmml"><mi id="S4.SS1.SSS4.p4.2.m2.1.1.2" xref="S4.SS1.SSS4.p4.2.m2.1.1.2.cmml">T</mi><mn id="S4.SS1.SSS4.p4.2.m2.1.1.3" xref="S4.SS1.SSS4.p4.2.m2.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS4.p4.2.m2.1b"><apply id="S4.SS1.SSS4.p4.2.m2.1.1.cmml" xref="S4.SS1.SSS4.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS4.p4.2.m2.1.1.1.cmml" xref="S4.SS1.SSS4.p4.2.m2.1.1">subscript</csymbol><ci id="S4.SS1.SSS4.p4.2.m2.1.1.2.cmml" xref="S4.SS1.SSS4.p4.2.m2.1.1.2">𝑇</ci><cn type="integer" id="S4.SS1.SSS4.p4.2.m2.1.1.3.cmml" xref="S4.SS1.SSS4.p4.2.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS4.p4.2.m2.1c">T_{2}</annotation></semantics></math> rounds, using the output neighbor bag from the first stage as input. The authors provide theoretical evidence of the effectiveness of their approach and extensively evaluate it against fixed and random topology methods, PENS, and Oracle – a method with ground-truth cluster information that represents the accuracy upper bound. Additionally, the authors compare their solution to centralized baselines. Overall, PANM demonstrates superior performance in most settings, even when compared to Oracle. Moreover, this method is well-suited for low communication budget networks.</p>
</div>
</section>
<section id="S4.SS1.SSS5" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.5. </span>Others</h4>

<div id="S4.SS1.SSS5.p1" class="ltx_para">
<p id="S4.SS1.SSS5.p1.1" class="ltx_p">In the following, we discuss all the remaining DFL approaches based on traditional distributed computing techniques that do not fall into any of the previous categories.
</p>
</div>
<div id="S4.SS1.SSS5.p2" class="ltx_para">
<p id="S4.SS1.SSS5.p2.1" class="ltx_p"><span id="S4.SS1.SSS5.p2.1.1" class="ltx_text ltx_font_bold ltx_font_italic">FDFL <cite class="ltx_cite ltx_citemacro_citep">(Lalitha, <a href="#bib.bib40" title="" class="ltx_ref">2018</a>)</cite>.</span>
This approach eliminates the need for a centralized controller and instead focuses on collaborative learning through local information exchange.
Specifically, clients adopt a Bayesian-like approach by introducing a belief over the model parameter space and using a distributed learning algorithm. Through information aggregation from neighbors, users update their beliefs to learn a model that best fits the observations across the entire network. The framework also allows users to sample points exclusively from smaller sub-spaces within the input space.
</p>
</div>
<div id="S4.SS1.SSS5.p3" class="ltx_para">
<p id="S4.SS1.SSS5.p3.1" class="ltx_p">The paper provides high probability bounds on the worst-case probability of error across the network and explores appropriate approximations for applying the algorithm to learn DNN models. However, it is important to note that the work lacks experimental validation and is primarily a theoretical study.
Future studies could potentially complement this work with empirical experiments to validate its practical performance.</p>
</div>
<div id="S4.SS1.SSS5.p4" class="ltx_para">
<p id="S4.SS1.SSS5.p4.2" class="ltx_p"><span id="S4.SS1.SSS5.p4.2.1" class="ltx_text ltx_font_bold ltx_font_italic">BrainTorrent <cite class="ltx_cite ltx_citemacro_citep">(Roy et al<span class="ltx_text">.</span>, <a href="#bib.bib81" title="" class="ltx_ref">2019</a>)</cite>.</span>
The proposed DFL community-based environment aims to ease the collaborative training of DNNs on medical images without relying on a central entity. By forming a fully connected network of peers, each participant maintains a vector containing its own version and the last versions of models received it used during merging.
The training process involves the following iterative steps:</p>
<ol id="S4.I5" class="ltx_enumerate">
<li id="S4.I5.ix1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><math id="S4.I5.ix1.1.1.m1.1" class="ltx_Math" alttext="(i)" display="inline"><semantics id="S4.I5.ix1.1.1.m1.1b"><mrow id="S4.I5.ix1.1.1.m1.1.2.2"><mo stretchy="false" id="S4.I5.ix1.1.1.m1.1.2.2.1">(</mo><mi id="S4.I5.ix1.1.1.m1.1.1" xref="S4.I5.ix1.1.1.m1.1.1.cmml">i</mi><mo stretchy="false" id="S4.I5.ix1.1.1.m1.1.2.2.2">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.I5.ix1.1.1.m1.1c"><ci id="S4.I5.ix1.1.1.m1.1.1.cmml" xref="S4.I5.ix1.1.1.m1.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.I5.ix1.1.1.m1.1d">(i)</annotation></semantics></math></span> 
<div id="S4.I5.ix1.p1" class="ltx_para">
<p id="S4.I5.ix1.p1.1" class="ltx_p">Each client trains its local model for a few iterations using its local dataset.</p>
</div>
</li>
<li id="S4.I5.ix2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><math id="S4.I5.ix2.1.1.m1.1" class="ltx_Math" alttext="(ii)" display="inline"><semantics id="S4.I5.ix2.1.1.m1.1b"><mrow id="S4.I5.ix2.1.1.m1.1.1.1" xref="S4.I5.ix2.1.1.m1.1.1.1.1.cmml"><mo stretchy="false" id="S4.I5.ix2.1.1.m1.1.1.1.2" xref="S4.I5.ix2.1.1.m1.1.1.1.1.cmml">(</mo><mrow id="S4.I5.ix2.1.1.m1.1.1.1.1" xref="S4.I5.ix2.1.1.m1.1.1.1.1.cmml"><mi id="S4.I5.ix2.1.1.m1.1.1.1.1.2" xref="S4.I5.ix2.1.1.m1.1.1.1.1.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.I5.ix2.1.1.m1.1.1.1.1.1" xref="S4.I5.ix2.1.1.m1.1.1.1.1.1.cmml">​</mo><mi id="S4.I5.ix2.1.1.m1.1.1.1.1.3" xref="S4.I5.ix2.1.1.m1.1.1.1.1.3.cmml">i</mi></mrow><mo stretchy="false" id="S4.I5.ix2.1.1.m1.1.1.1.3" xref="S4.I5.ix2.1.1.m1.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.I5.ix2.1.1.m1.1c"><apply id="S4.I5.ix2.1.1.m1.1.1.1.1.cmml" xref="S4.I5.ix2.1.1.m1.1.1.1"><times id="S4.I5.ix2.1.1.m1.1.1.1.1.1.cmml" xref="S4.I5.ix2.1.1.m1.1.1.1.1.1"></times><ci id="S4.I5.ix2.1.1.m1.1.1.1.1.2.cmml" xref="S4.I5.ix2.1.1.m1.1.1.1.1.2">𝑖</ci><ci id="S4.I5.ix2.1.1.m1.1.1.1.1.3.cmml" xref="S4.I5.ix2.1.1.m1.1.1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I5.ix2.1.1.m1.1d">(ii)</annotation></semantics></math></span> 
<div id="S4.I5.ix2.p1" class="ltx_para">
<p id="S4.I5.ix2.p1.1" class="ltx_p">A random client <math id="S4.I5.ix2.p1.1.m1.1" class="ltx_Math" alttext="\widetilde{c}" display="inline"><semantics id="S4.I5.ix2.p1.1.m1.1a"><mover accent="true" id="S4.I5.ix2.p1.1.m1.1.1" xref="S4.I5.ix2.p1.1.m1.1.1.cmml"><mi id="S4.I5.ix2.p1.1.m1.1.1.2" xref="S4.I5.ix2.p1.1.m1.1.1.2.cmml">c</mi><mo id="S4.I5.ix2.p1.1.m1.1.1.1" xref="S4.I5.ix2.p1.1.m1.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="S4.I5.ix2.p1.1.m1.1b"><apply id="S4.I5.ix2.p1.1.m1.1.1.cmml" xref="S4.I5.ix2.p1.1.m1.1.1"><ci id="S4.I5.ix2.p1.1.m1.1.1.1.cmml" xref="S4.I5.ix2.p1.1.m1.1.1.1">~</ci><ci id="S4.I5.ix2.p1.1.m1.1.1.2.cmml" xref="S4.I5.ix2.p1.1.m1.1.1.2">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I5.ix2.p1.1.m1.1c">\widetilde{c}</annotation></semantics></math> selected from the environment sends out a “ping request” to gather the latest model versions from all other clients.</p>
</div>
</li>
<li id="S4.I5.ix3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><math id="S4.I5.ix3.1.1.m1.1" class="ltx_Math" alttext="(iii)" display="inline"><semantics id="S4.I5.ix3.1.1.m1.1b"><mrow id="S4.I5.ix3.1.1.m1.1.1.1" xref="S4.I5.ix3.1.1.m1.1.1.1.1.cmml"><mo stretchy="false" id="S4.I5.ix3.1.1.m1.1.1.1.2" xref="S4.I5.ix3.1.1.m1.1.1.1.1.cmml">(</mo><mrow id="S4.I5.ix3.1.1.m1.1.1.1.1" xref="S4.I5.ix3.1.1.m1.1.1.1.1.cmml"><mi id="S4.I5.ix3.1.1.m1.1.1.1.1.2" xref="S4.I5.ix3.1.1.m1.1.1.1.1.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.I5.ix3.1.1.m1.1.1.1.1.1" xref="S4.I5.ix3.1.1.m1.1.1.1.1.1.cmml">​</mo><mi id="S4.I5.ix3.1.1.m1.1.1.1.1.3" xref="S4.I5.ix3.1.1.m1.1.1.1.1.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.I5.ix3.1.1.m1.1.1.1.1.1b" xref="S4.I5.ix3.1.1.m1.1.1.1.1.1.cmml">​</mo><mi id="S4.I5.ix3.1.1.m1.1.1.1.1.4" xref="S4.I5.ix3.1.1.m1.1.1.1.1.4.cmml">i</mi></mrow><mo stretchy="false" id="S4.I5.ix3.1.1.m1.1.1.1.3" xref="S4.I5.ix3.1.1.m1.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.I5.ix3.1.1.m1.1c"><apply id="S4.I5.ix3.1.1.m1.1.1.1.1.cmml" xref="S4.I5.ix3.1.1.m1.1.1.1"><times id="S4.I5.ix3.1.1.m1.1.1.1.1.1.cmml" xref="S4.I5.ix3.1.1.m1.1.1.1.1.1"></times><ci id="S4.I5.ix3.1.1.m1.1.1.1.1.2.cmml" xref="S4.I5.ix3.1.1.m1.1.1.1.1.2">𝑖</ci><ci id="S4.I5.ix3.1.1.m1.1.1.1.1.3.cmml" xref="S4.I5.ix3.1.1.m1.1.1.1.1.3">𝑖</ci><ci id="S4.I5.ix3.1.1.m1.1.1.1.1.4.cmml" xref="S4.I5.ix3.1.1.m1.1.1.1.1.4">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I5.ix3.1.1.m1.1d">(iii)</annotation></semantics></math></span> 
<div id="S4.I5.ix3.p1" class="ltx_para">
<p id="S4.I5.ix3.p1.1" class="ltx_p">Clients with updates send their weights and training sample size to <math id="S4.I5.ix3.p1.1.m1.1" class="ltx_Math" alttext="\widetilde{c}" display="inline"><semantics id="S4.I5.ix3.p1.1.m1.1a"><mover accent="true" id="S4.I5.ix3.p1.1.m1.1.1" xref="S4.I5.ix3.p1.1.m1.1.1.cmml"><mi id="S4.I5.ix3.p1.1.m1.1.1.2" xref="S4.I5.ix3.p1.1.m1.1.1.2.cmml">c</mi><mo id="S4.I5.ix3.p1.1.m1.1.1.1" xref="S4.I5.ix3.p1.1.m1.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="S4.I5.ix3.p1.1.m1.1b"><apply id="S4.I5.ix3.p1.1.m1.1.1.cmml" xref="S4.I5.ix3.p1.1.m1.1.1"><ci id="S4.I5.ix3.p1.1.m1.1.1.1.cmml" xref="S4.I5.ix3.p1.1.m1.1.1.1">~</ci><ci id="S4.I5.ix3.p1.1.m1.1.1.2.cmml" xref="S4.I5.ix3.p1.1.m1.1.1.2">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I5.ix3.p1.1.m1.1c">\widetilde{c}</annotation></semantics></math>.</p>
</div>
</li>
<li id="S4.I5.ix4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><math id="S4.I5.ix4.1.1.m1.1" class="ltx_Math" alttext="(iv)" display="inline"><semantics id="S4.I5.ix4.1.1.m1.1b"><mrow id="S4.I5.ix4.1.1.m1.1.1.1" xref="S4.I5.ix4.1.1.m1.1.1.1.1.cmml"><mo stretchy="false" id="S4.I5.ix4.1.1.m1.1.1.1.2" xref="S4.I5.ix4.1.1.m1.1.1.1.1.cmml">(</mo><mrow id="S4.I5.ix4.1.1.m1.1.1.1.1" xref="S4.I5.ix4.1.1.m1.1.1.1.1.cmml"><mi id="S4.I5.ix4.1.1.m1.1.1.1.1.2" xref="S4.I5.ix4.1.1.m1.1.1.1.1.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.I5.ix4.1.1.m1.1.1.1.1.1" xref="S4.I5.ix4.1.1.m1.1.1.1.1.1.cmml">​</mo><mi id="S4.I5.ix4.1.1.m1.1.1.1.1.3" xref="S4.I5.ix4.1.1.m1.1.1.1.1.3.cmml">v</mi></mrow><mo stretchy="false" id="S4.I5.ix4.1.1.m1.1.1.1.3" xref="S4.I5.ix4.1.1.m1.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.I5.ix4.1.1.m1.1c"><apply id="S4.I5.ix4.1.1.m1.1.1.1.1.cmml" xref="S4.I5.ix4.1.1.m1.1.1.1"><times id="S4.I5.ix4.1.1.m1.1.1.1.1.1.cmml" xref="S4.I5.ix4.1.1.m1.1.1.1.1.1"></times><ci id="S4.I5.ix4.1.1.m1.1.1.1.1.2.cmml" xref="S4.I5.ix4.1.1.m1.1.1.1.1.2">𝑖</ci><ci id="S4.I5.ix4.1.1.m1.1.1.1.1.3.cmml" xref="S4.I5.ix4.1.1.m1.1.1.1.1.3">𝑣</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I5.ix4.1.1.m1.1d">(iv)</annotation></semantics></math></span> 
<div id="S4.I5.ix4.p1" class="ltx_para">
<p id="S4.I5.ix4.p1.1" class="ltx_p">This subset of models is merged with the <math id="S4.I5.ix4.p1.1.m1.1" class="ltx_Math" alttext="\widetilde{c}" display="inline"><semantics id="S4.I5.ix4.p1.1.m1.1a"><mover accent="true" id="S4.I5.ix4.p1.1.m1.1.1" xref="S4.I5.ix4.p1.1.m1.1.1.cmml"><mi id="S4.I5.ix4.p1.1.m1.1.1.2" xref="S4.I5.ix4.p1.1.m1.1.1.2.cmml">c</mi><mo id="S4.I5.ix4.p1.1.m1.1.1.1" xref="S4.I5.ix4.p1.1.m1.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="S4.I5.ix4.p1.1.m1.1b"><apply id="S4.I5.ix4.p1.1.m1.1.1.cmml" xref="S4.I5.ix4.p1.1.m1.1.1"><ci id="S4.I5.ix4.p1.1.m1.1.1.1.cmml" xref="S4.I5.ix4.p1.1.m1.1.1.1">~</ci><ci id="S4.I5.ix4.p1.1.m1.1.1.2.cmml" xref="S4.I5.ix4.p1.1.m1.1.1.2">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I5.ix4.p1.1.m1.1c">\widetilde{c}</annotation></semantics></math> ’s current model into a single model by weighted averaging.</p>
</div>
</li>
</ol>
<p id="S4.SS1.SSS5.p4.1" class="ltx_p">This process facilitates collaboration among medical centers, ensuring resilience against failures and eliminating the need for a universally trusted authority. Any client can initiate the update process, leading to a faster convergence rate and comparable accuracy to centralized data pooling.
While the proposed method has advantages, there are two problems: firstly, the lack of sufficient experiments and utilization of non-standard metrics (i.e., DICE) limits the comprehensive evaluation of the approach’s performance. Secondly, when the random client <math id="S4.SS1.SSS5.p4.1.m1.1" class="ltx_Math" alttext="\widetilde{c}" display="inline"><semantics id="S4.SS1.SSS5.p4.1.m1.1a"><mover accent="true" id="S4.SS1.SSS5.p4.1.m1.1.1" xref="S4.SS1.SSS5.p4.1.m1.1.1.cmml"><mi id="S4.SS1.SSS5.p4.1.m1.1.1.2" xref="S4.SS1.SSS5.p4.1.m1.1.1.2.cmml">c</mi><mo id="S4.SS1.SSS5.p4.1.m1.1.1.1" xref="S4.SS1.SSS5.p4.1.m1.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS5.p4.1.m1.1b"><apply id="S4.SS1.SSS5.p4.1.m1.1.1.cmml" xref="S4.SS1.SSS5.p4.1.m1.1.1"><ci id="S4.SS1.SSS5.p4.1.m1.1.1.1.cmml" xref="S4.SS1.SSS5.p4.1.m1.1.1.1">~</ci><ci id="S4.SS1.SSS5.p4.1.m1.1.1.2.cmml" xref="S4.SS1.SSS5.p4.1.m1.1.1.2">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS5.p4.1.m1.1c">\widetilde{c}</annotation></semantics></math> initiating the update process fails, there is no recovery plan in place.</p>
</div>
</section>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2. </span>Blockchained-based FL (BC-FL)</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">The integration between Blockchain and FL is a natural consequence of their shared characteristics as distributed technologies. They can be combined to create a <span id="S4.SS2.p1.1.1" class="ltx_text ltx_font_italic">Blockchain-based FL</span> (BC-FL) system that offers unique advantages over traditional FL approaches.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">In BC-FL, each device participating in the learning process can take on the role of a leader, leading the aggregation process in a specific round of learning. This decentralized structure eliminates the need for a central server, enhancing the system’s fault tolerance.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.1" class="ltx_p">Entities participating in the training process are referred to as <span id="S4.SS2.p3.1.1" class="ltx_text ltx_font_italic">miners</span>. These miners are responsible for verifying and validating the local updates generated by participants before they are incorporated into the global model, employing a <span id="S4.SS2.p3.1.2" class="ltx_text ltx_font_italic">consensus algorithm</span>. This verification step ensures that only valid and trustworthy updates are included, enhancing the security of the system.</p>
</div>
<div id="S4.SS2.p4" class="ltx_para">
<p id="S4.SS2.p4.1" class="ltx_p">Additionally, BC-FL introduces a reward mechanism based on training sample sizes. Participants are incentivized with rewards proportional to the size of their training samples. This approach encourages the participation of more devices with a larger number of training samples. By aligning rewards with the contribution of training data, BC-FL promotes the involvement of devices with diverse and extensive datasets, leading to more comprehensive and accurate models.
In summary, the integration of Blockchain in FL offers a fully decentralized and secure approach to FL. It overcomes the single-point-of-failure problem and incentivizes collaboration through reward mechanisms based on training sample sizes.</p>
</div>
<div id="S4.SS2.p5" class="ltx_para">
<p id="S4.SS2.p5.1" class="ltx_p">According to <cite class="ltx_cite ltx_citemacro_citep">(Qu et al<span class="ltx_text">.</span>, <a href="#bib.bib76" title="" class="ltx_ref">2022</a>; Kim et al<span class="ltx_text">.</span>, <a href="#bib.bib37" title="" class="ltx_ref">2020</a>)</cite>, the training procedure of a generic BC-FL consists of the following steps:</p>
<ul id="S4.I6" class="ltx_itemize">
<li id="S4.I6.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I6.i1.p1" class="ltx_para">
<p id="S4.I6.i1.p1.1" class="ltx_p"><span id="S4.I6.i1.p1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Initialization:</span> A cluster of devices is defined, where each device possesses its own data sample. Each device is associated with a randomly selected miner from a cluster of miners.</p>
</div>
</li>
<li id="S4.I6.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I6.i2.p1" class="ltx_para">
<p id="S4.I6.i2.p1.1" class="ltx_p"><span id="S4.I6.i2.p1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Local model update:</span> The end devices train their local models for a specified number of iterations based on their respective data samples.</p>
</div>
</li>
<li id="S4.I6.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I6.i3.p1" class="ltx_para">
<p id="S4.I6.i3.p1.1" class="ltx_p"><span id="S4.I6.i3.p1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Local model upload:</span> The end devices upload their local model parameters to the associated miner. Additionally, the corresponding local computation time and local dataset size are uploaded for verification purposes.</p>
</div>
</li>
<li id="S4.I6.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I6.i4.p1" class="ltx_para">
<p id="S4.I6.i4.p1.1" class="ltx_p"><span id="S4.I6.i4.p1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Cross-verification:</span> Miners verify the model parameters and computing time of the associated end devices. The verification process is performed in a specific sequence, taking into account the proportional data size to determine the reliability of the model parameters. The verified data is stored in the miner’s potential block until all model parameters have been verified and stored in a block.</p>
</div>
</li>
<li id="S4.I6.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I6.i5.p1" class="ltx_para">
<p id="S4.I6.i5.p1.1" class="ltx_p"><span id="S4.I6.i5.p1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Block generation:</span> In each round, a consensus algorithm is executed. The process stops when a winning miner obtains the opportunity to generate a block and creates a candidate block.</p>
</div>
</li>
<li id="S4.I6.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I6.i6.p1" class="ltx_para">
<p id="S4.I6.i6.p1.1" class="ltx_p"><span id="S4.I6.i6.p1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Block propagation:</span> The winning miner broadcasts the candidate block to all parties as a new block. All miners in the system append the new block to their local ledgers if it passes the verification process. To prevent forking, a specially designed “ACK” signal is used and transmitted if a miner does not identify any forking.</p>
</div>
</li>
<li id="S4.I6.i7" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I6.i7.p1" class="ltx_para">
<p id="S4.I6.i7.p1.1" class="ltx_p"><span id="S4.I6.i7.p1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Global model update:</span> The selected miner aggregates all the local model parameters from the participants. The aggregated parameters are used to update the global model, which is then written into a block.</p>
</div>
</li>
<li id="S4.I6.i8" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I6.i8.p1" class="ltx_para">
<p id="S4.I6.i8.p1.1" class="ltx_p"><span id="S4.I6.i8.p1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Global model download:</span> All end devices are allowed to download the global parameters from the new block and decide whether to continue in the next round or not.</p>
</div>
</li>
</ul>
</div>
<div id="S4.SS2.p6" class="ltx_para">
<p id="S4.SS2.p6.1" class="ltx_p">In the following section, we analyze the prominent BC-FL approaches proposed in the literature and categorize them based on their consensus mechanisms. These mechanisms include approaches based on proof-of-work (PoW), proof-of-stake (PoS), and smart contracts (SC), as well as other unique methods in our selection, such as proof-of-federation (PoF), proof-of-accuracy (PoA), hotstuff, PBFT, and proof-of-Shapley-Value (PoSV).</p>
</div>
<section id="S4.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.1. </span>PoW-based</h4>

<div id="S4.SS2.SSS1.p1" class="ltx_para">
<p id="S4.SS2.SSS1.p1.1" class="ltx_p">In works based on PoW consensus, the nodes involved in the process are referred to as devices and miners; these terms are used interchangeably. Miners can be either randomly selected devices or separate nodes, such as network edges (e.g., base stations in cellular networks), that have sufficient energy resources for the mining process. The general approach in these works involves devices computing and uploading their local model updates to their associated miners in the Blockchain network. Miners then exchange and verify all the local model updates and perform the PoW process. Once a miner successfully completes the PoW, it generates a block that contains the verified local model updates. This block, storing the aggregate local model updates, is added to the Blockchain or distributed ledger, and it is subsequently downloaded by the devices. Each device computes the global model update from the new block <cite class="ltx_cite ltx_citemacro_citep">(Kim et al<span class="ltx_text">.</span>, <a href="#bib.bib37" title="" class="ltx_ref">2020</a>; Feng et al<span class="ltx_text">.</span>, <a href="#bib.bib21" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
<div id="S4.SS2.SSS1.p2" class="ltx_para">
<p id="S4.SS2.SSS1.p2.1" class="ltx_p">In this section, we will discuss works related to PoW-based consensus.</p>
</div>
<div id="S4.SS2.SSS1.p3" class="ltx_para">
<p id="S4.SS2.SSS1.p3.1" class="ltx_p"><span id="S4.SS2.SSS1.p3.1.1" class="ltx_text ltx_font_bold ltx_font_italic">BlockFL <cite class="ltx_cite ltx_citemacro_citep">(Kim et al<span class="ltx_text">.</span>, <a href="#bib.bib37" title="" class="ltx_ref">2020</a>)</cite>.</span> This work introduces a novel architecture, which facilitates the exchange and verification of local learning model updates.
It analyzes the end-to-end latency model, examining the optimal block generation rate considering communication, computation, and consensus delays. The tamper-proof and secure FL system offered by the Blockchain in BlockFL includes a distributed ledger to store device scores and models. BlockFL expands its federation to include untrustworthy devices within a public network through a validation process of local training results. Additionally, BlockFL incentivizes the inclusion of more devices with a higher number of training samples by offering rewards in proportion to the sample sizes used for training. However, it must address the additional delay caused by the Blockchain network. To tackle this challenge, BlockFL formulates an end-to-end latency model that takes into account communication, computation, and PoW delays. By adjusting the PoW difficulty, or the block generation rate, BlockFL minimizes the resulting latency.
</p>
</div>
<div id="S4.SS2.SSS1.p4" class="ltx_para">
<p id="S4.SS2.SSS1.p4.2" class="ltx_p"><span id="S4.SS2.SSS1.p4.2.1" class="ltx_text ltx_font_bold ltx_font_italic">BAFL <cite class="ltx_cite ltx_citemacro_citep">(Feng et al<span class="ltx_text">.</span>, <a href="#bib.bib21" title="" class="ltx_ref">2022</a>)</cite>.</span> The proposed Blockchain-Assisted FL (BAFL) is an asynchronous FL strategy that enables devices to upload their local models during global aggregation for fast convergence. The Blockchain ensures decentralized and secure data storage, incentivizing device participation through rewards. Two policies optimize BAFL’s workflow: <math id="S4.SS2.SSS1.p4.1.m1.1" class="ltx_Math" alttext="(i)" display="inline"><semantics id="S4.SS2.SSS1.p4.1.m1.1a"><mrow id="S4.SS2.SSS1.p4.1.m1.1.2.2"><mo stretchy="false" id="S4.SS2.SSS1.p4.1.m1.1.2.2.1">(</mo><mi id="S4.SS2.SSS1.p4.1.m1.1.1" xref="S4.SS2.SSS1.p4.1.m1.1.1.cmml">i</mi><mo stretchy="false" id="S4.SS2.SSS1.p4.1.m1.1.2.2.2">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS1.p4.1.m1.1b"><ci id="S4.SS2.SSS1.p4.1.m1.1.1.cmml" xref="S4.SS2.SSS1.p4.1.m1.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS1.p4.1.m1.1c">(i)</annotation></semantics></math> controlling block generation rate to reduce FL delays and <math id="S4.SS2.SSS1.p4.2.m2.1" class="ltx_Math" alttext="(ii)" display="inline"><semantics id="S4.SS2.SSS1.p4.2.m2.1a"><mrow id="S4.SS2.SSS1.p4.2.m2.1.1.1" xref="S4.SS2.SSS1.p4.2.m2.1.1.1.1.cmml"><mo stretchy="false" id="S4.SS2.SSS1.p4.2.m2.1.1.1.2" xref="S4.SS2.SSS1.p4.2.m2.1.1.1.1.cmml">(</mo><mrow id="S4.SS2.SSS1.p4.2.m2.1.1.1.1" xref="S4.SS2.SSS1.p4.2.m2.1.1.1.1.cmml"><mi id="S4.SS2.SSS1.p4.2.m2.1.1.1.1.2" xref="S4.SS2.SSS1.p4.2.m2.1.1.1.1.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.SS2.SSS1.p4.2.m2.1.1.1.1.1" xref="S4.SS2.SSS1.p4.2.m2.1.1.1.1.1.cmml">​</mo><mi id="S4.SS2.SSS1.p4.2.m2.1.1.1.1.3" xref="S4.SS2.SSS1.p4.2.m2.1.1.1.1.3.cmml">i</mi></mrow><mo stretchy="false" id="S4.SS2.SSS1.p4.2.m2.1.1.1.3" xref="S4.SS2.SSS1.p4.2.m2.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS1.p4.2.m2.1b"><apply id="S4.SS2.SSS1.p4.2.m2.1.1.1.1.cmml" xref="S4.SS2.SSS1.p4.2.m2.1.1.1"><times id="S4.SS2.SSS1.p4.2.m2.1.1.1.1.1.cmml" xref="S4.SS2.SSS1.p4.2.m2.1.1.1.1.1"></times><ci id="S4.SS2.SSS1.p4.2.m2.1.1.1.1.2.cmml" xref="S4.SS2.SSS1.p4.2.m2.1.1.1.1.2">𝑖</ci><ci id="S4.SS2.SSS1.p4.2.m2.1.1.1.1.3.cmml" xref="S4.SS2.SSS1.p4.2.m2.1.1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS1.p4.2.m2.1c">(ii)</annotation></semantics></math> dynamically adjusting training times to prevent transaction overloads. Unlike traditional FedAvg, BAFL evaluates device participation rank and proportion using entropy weight method, recorded in the Blockchain for trust. Energy consumption is considered and minimized through Pareto optimization to expedite model uploads without overloading the Blockchain. They also incorporate an application-level aspect that involves edge devices such as scanners, medical devices, and vehicles. The Blockchain ensures a tamper-proof and secure FL system by storing device scores and models in a distributed ledger. The optimal block generation rate was calculated to facilitate efficient transactions. A Pareto optimization approach was used to model energy consumption and delay of local devices, allowing for a trade-off to control model update speed and minimize transaction delays. The experimental results demonstrated that the proposed BAFL framework not only reduced resource consumption but also significantly improved global precision compared to the traditional FedAvg strategy.</p>
</div>
<div id="S4.SS2.SSS1.p5" class="ltx_para">
<p id="S4.SS2.SSS1.p5.3" class="ltx_p"><span id="S4.SS2.SSS1.p5.3.1" class="ltx_text ltx_font_bold ltx_font_italic">BLADE-FL <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib43" title="" class="ltx_ref">2022c</a>)</cite>.</span> In their paper, the authors propose a framework that integrates training and mining processes in each client, aiming to address the single-point-of-failure issue of centralized aggregation while preserving the privacy-enhancing capabilities of the FL system. They developed an upper bound on the loss function to evaluate the learning performance of BLADE-FL and verify its convexity concerning the total integrated rounds <math id="S4.SS2.SSS1.p5.1.m1.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S4.SS2.SSS1.p5.1.m1.1a"><mi id="S4.SS2.SSS1.p5.1.m1.1.1" xref="S4.SS2.SSS1.p5.1.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS1.p5.1.m1.1b"><ci id="S4.SS2.SSS1.p5.1.m1.1.1.cmml" xref="S4.SS2.SSS1.p5.1.m1.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS1.p5.1.m1.1c">T</annotation></semantics></math>, optimizing <math id="S4.SS2.SSS1.p5.2.m2.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S4.SS2.SSS1.p5.2.m2.1a"><mi id="S4.SS2.SSS1.p5.2.m2.1.1" xref="S4.SS2.SSS1.p5.2.m2.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS1.p5.2.m2.1b"><ci id="S4.SS2.SSS1.p5.2.m2.1.1.cmml" xref="S4.SS2.SSS1.p5.2.m2.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS1.p5.2.m2.1c">T</annotation></semantics></math> to minimize the upper bound. The system comprises <math id="S4.SS2.SSS1.p5.3.m3.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S4.SS2.SSS1.p5.3.m3.1a"><mi id="S4.SS2.SSS1.p5.3.m3.1.1" xref="S4.SS2.SSS1.p5.3.m3.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS1.p5.3.m3.1b"><ci id="S4.SS2.SSS1.p5.3.m3.1.1.cmml" xref="S4.SS2.SSS1.p5.3.m3.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS1.p5.3.m3.1c">N</annotation></semantics></math> clients, each possessing identical computing power measured by CPU cycles per second. Within this distributed system, every client plays dual roles as both a trainer and a miner, and the role transitions are designed as follows. Initially, each client acts as a trainer, training the local model and subsequently broadcasting it to the entire network as a requested Blockchain transaction. Later, the client transforms into a miner responsible for mining the block that contains all the local models prepared for aggregation. Upon generating the new block, it must undergo validation by the majority of clients before the models within it become immutable. Notably, the system operates without the involvement of any centralized server. Instead, each client independently performs global aggregation to update its local model, utilizing all the shared models from the validated block. They assume that the uploading and downloading phases are impervious to external attackers’ tampering. The authors highlight several potential future research directions related to BLADE-FL. One area of interest involves creating an efficient incentive mechanism to encourage active protocol compliance by all clients. Another challenging aspect is detecting plagiarism and discouraging laziness among clients. Additionally, they suggest further investigation into the learning performance of BLADE-FL without relying on convexity assumptions for the loss function.</p>
</div>
</section>
<section id="S4.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.2. </span>PoS-based</h4>

<div id="S4.SS2.SSS2.p1" class="ltx_para">
<p id="S4.SS2.SSS2.p1.1" class="ltx_p">In the realm of Blockchain systems, various consensus algorithms have been developed to enhance security and address byzantine behaviors. One such algorithm is <span id="S4.SS2.SSS2.p1.1.1" class="ltx_text ltx_font_italic">Algorand</span> <cite class="ltx_cite ltx_citemacro_citep">(Gilad et al<span class="ltx_text">.</span>, <a href="#bib.bib23" title="" class="ltx_ref">2017</a>)</cite>, which combines PoS with Byzantine Fault Tolerance (BFT) and utilizes verifiable random functions (VRFs) to select a subset of nodes for the committee.</p>
</div>
<div id="S4.SS2.SSS2.p2" class="ltx_para">
<p id="S4.SS2.SSS2.p2.1" class="ltx_p">Below, we present two approaches that incorporate Algorand into FL systems.</p>
</div>
<div id="S4.SS2.SSS2.p3" class="ltx_para">
<p id="S4.SS2.SSS2.p3.3" class="ltx_p"><span id="S4.SS2.SSS2.p3.3.1" class="ltx_text ltx_font_bold ltx_font_italic">Privacy-preserving FL for IoT devices <cite class="ltx_cite ltx_citemacro_citep">(Zhao et al<span class="ltx_text">.</span>, <a href="#bib.bib103" title="" class="ltx_ref">2021</a>)</cite>.</span> They designed a DFL system with a reputation mechanism to aid manufacturers in developing a smart home system. The DFL system allows manufacturers to train an ML model based on customers’ data, predicting their future requirements and consumption behaviors. The system comprises three main elements: <math id="S4.SS2.SSS2.p3.1.m1.1" class="ltx_Math" alttext="(i)" display="inline"><semantics id="S4.SS2.SSS2.p3.1.m1.1a"><mrow id="S4.SS2.SSS2.p3.1.m1.1.2.2"><mo stretchy="false" id="S4.SS2.SSS2.p3.1.m1.1.2.2.1">(</mo><mi id="S4.SS2.SSS2.p3.1.m1.1.1" xref="S4.SS2.SSS2.p3.1.m1.1.1.cmml">i</mi><mo stretchy="false" id="S4.SS2.SSS2.p3.1.m1.1.2.2.2">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p3.1.m1.1b"><ci id="S4.SS2.SSS2.p3.1.m1.1.1.cmml" xref="S4.SS2.SSS2.p3.1.m1.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p3.1.m1.1c">(i)</annotation></semantics></math> manufacturers, <math id="S4.SS2.SSS2.p3.2.m2.1" class="ltx_Math" alttext="(ii)" display="inline"><semantics id="S4.SS2.SSS2.p3.2.m2.1a"><mrow id="S4.SS2.SSS2.p3.2.m2.1.1.1" xref="S4.SS2.SSS2.p3.2.m2.1.1.1.1.cmml"><mo stretchy="false" id="S4.SS2.SSS2.p3.2.m2.1.1.1.2" xref="S4.SS2.SSS2.p3.2.m2.1.1.1.1.cmml">(</mo><mrow id="S4.SS2.SSS2.p3.2.m2.1.1.1.1" xref="S4.SS2.SSS2.p3.2.m2.1.1.1.1.cmml"><mi id="S4.SS2.SSS2.p3.2.m2.1.1.1.1.2" xref="S4.SS2.SSS2.p3.2.m2.1.1.1.1.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.SS2.SSS2.p3.2.m2.1.1.1.1.1" xref="S4.SS2.SSS2.p3.2.m2.1.1.1.1.1.cmml">​</mo><mi id="S4.SS2.SSS2.p3.2.m2.1.1.1.1.3" xref="S4.SS2.SSS2.p3.2.m2.1.1.1.1.3.cmml">i</mi></mrow><mo stretchy="false" id="S4.SS2.SSS2.p3.2.m2.1.1.1.3" xref="S4.SS2.SSS2.p3.2.m2.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p3.2.m2.1b"><apply id="S4.SS2.SSS2.p3.2.m2.1.1.1.1.cmml" xref="S4.SS2.SSS2.p3.2.m2.1.1.1"><times id="S4.SS2.SSS2.p3.2.m2.1.1.1.1.1.cmml" xref="S4.SS2.SSS2.p3.2.m2.1.1.1.1.1"></times><ci id="S4.SS2.SSS2.p3.2.m2.1.1.1.1.2.cmml" xref="S4.SS2.SSS2.p3.2.m2.1.1.1.1.2">𝑖</ci><ci id="S4.SS2.SSS2.p3.2.m2.1.1.1.1.3.cmml" xref="S4.SS2.SSS2.p3.2.m2.1.1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p3.2.m2.1c">(ii)</annotation></semantics></math> customers, and <math id="S4.SS2.SSS2.p3.3.m3.1" class="ltx_Math" alttext="(iii)" display="inline"><semantics id="S4.SS2.SSS2.p3.3.m3.1a"><mrow id="S4.SS2.SSS2.p3.3.m3.1.1.1" xref="S4.SS2.SSS2.p3.3.m3.1.1.1.1.cmml"><mo stretchy="false" id="S4.SS2.SSS2.p3.3.m3.1.1.1.2" xref="S4.SS2.SSS2.p3.3.m3.1.1.1.1.cmml">(</mo><mrow id="S4.SS2.SSS2.p3.3.m3.1.1.1.1" xref="S4.SS2.SSS2.p3.3.m3.1.1.1.1.cmml"><mi id="S4.SS2.SSS2.p3.3.m3.1.1.1.1.2" xref="S4.SS2.SSS2.p3.3.m3.1.1.1.1.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.SS2.SSS2.p3.3.m3.1.1.1.1.1" xref="S4.SS2.SSS2.p3.3.m3.1.1.1.1.1.cmml">​</mo><mi id="S4.SS2.SSS2.p3.3.m3.1.1.1.1.3" xref="S4.SS2.SSS2.p3.3.m3.1.1.1.1.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.SS2.SSS2.p3.3.m3.1.1.1.1.1a" xref="S4.SS2.SSS2.p3.3.m3.1.1.1.1.1.cmml">​</mo><mi id="S4.SS2.SSS2.p3.3.m3.1.1.1.1.4" xref="S4.SS2.SSS2.p3.3.m3.1.1.1.1.4.cmml">i</mi></mrow><mo stretchy="false" id="S4.SS2.SSS2.p3.3.m3.1.1.1.3" xref="S4.SS2.SSS2.p3.3.m3.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p3.3.m3.1b"><apply id="S4.SS2.SSS2.p3.3.m3.1.1.1.1.cmml" xref="S4.SS2.SSS2.p3.3.m3.1.1.1"><times id="S4.SS2.SSS2.p3.3.m3.1.1.1.1.1.cmml" xref="S4.SS2.SSS2.p3.3.m3.1.1.1.1.1"></times><ci id="S4.SS2.SSS2.p3.3.m3.1.1.1.1.2.cmml" xref="S4.SS2.SSS2.p3.3.m3.1.1.1.1.2">𝑖</ci><ci id="S4.SS2.SSS2.p3.3.m3.1.1.1.1.3.cmml" xref="S4.SS2.SSS2.p3.3.m3.1.1.1.1.3">𝑖</ci><ci id="S4.SS2.SSS2.p3.3.m3.1.1.1.1.4.cmml" xref="S4.SS2.SSS2.p3.3.m3.1.1.1.1.4">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p3.3.m3.1c">(iii)</annotation></semantics></math> Blockchain technology. In this setup, manufacturers initiate crowdsourcing FL tasks, and interested customers participate by submitting their trained models to the Blockchain. Acting as a centralized server, the Blockchain collects the customer models, and a designated miner calculates and generates the global FL model for home appliance manufacturers. It operates in two stages: customers use mobile phones and mobile-edge computing (MEC) servers to train the initial model, while manufacturers select customers or organizations as miners to calculate the averaged model. The miners then upload the model to the Blockchain at the end of the crowdsourcing task. To protect privacy and improve accuracy, they employ differential privacy (DP) and introduce a new normalization technique. Additionally, they create an incentive mechanism to encourage more customer participation in the crowdsourcing FL task. According to their experiments, the new normalization technique surpasses batch normalization when features are under DP protection. In the future, they aim to conduct more experiments and test the system with real-world home appliance datasets. Furthermore, they will strive to find the deterministically optimal balance between local epochs and global epochs to achieve improved test accuracy.</p>
</div>
<div id="S4.SS2.SSS2.p4" class="ltx_para">
<p id="S4.SS2.SSS2.p4.1" class="ltx_p"><span id="S4.SS2.SSS2.p4.1.1" class="ltx_text ltx_font_bold ltx_font_italic">DeepChain <cite class="ltx_cite ltx_citemacro_citep">(Weng et al<span class="ltx_text">.</span>, <a href="#bib.bib91" title="" class="ltx_ref">2021</a>)</cite>.</span> This paper introduces a collaborative training approach with an incentive mechanism to encourage joint participation and sharing of local gradients in deep learning model training. DeepChain prioritizes the privacy preservation of local gradients and ensures the verifiability of the training process. Through incentives and transactions, participants are motivated to act honestly during gradient collection and parameter updates, promoting fairness in collaboration training. They formalize this incentive mechanism based on Blockchain, ensuring compatibility and liveness properties, and demonstrate that participants are incentivized to behave correctly with high probability. A DeepChain prototype is implemented, and its performance is evaluated in terms of cipher size, throughput, training accuracy, and training time. The potential benefits of DeepChain include auditing the collaborative training process and the trained model, facilitating paid services in a mature model-based pricing market, and leveraging transfer learning techniques to enhance learning efficiency and accuracy. However, security concerns related to transfer learning require further analysis and definition.</p>
</div>
</section>
<section id="S4.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.3. </span>SC-based</h4>

<div id="S4.SS2.SSS3.p1" class="ltx_para">
<p id="S4.SS2.SSS3.p1.1" class="ltx_p"><span id="S4.SS2.SSS3.p1.1.1" class="ltx_text ltx_font_italic">Smart Contracts</span> <cite class="ltx_cite ltx_citemacro_citep">(Hu et al<span class="ltx_text">.</span>, <a href="#bib.bib29" title="" class="ltx_ref">2021</a>; Wu et al<span class="ltx_text">.</span>, <a href="#bib.bib93" title="" class="ltx_ref">2020b</a>)</cite> are employed to control the FL flow. The decentralized file system IPFS <cite class="ltx_cite ltx_citemacro_citep">(Benet, <a href="#bib.bib9" title="" class="ltx_ref">2014</a>)</cite> is utilized as off-chain storage in BC-FL due to block size limitations of Blockchain. It provides reliable and secure decentralized storage for files involved in the training process.</p>
</div>
<div id="S4.SS2.SSS3.p2" class="ltx_para">
<p id="S4.SS2.SSS3.p2.1" class="ltx_p">In this section, we will review the most prominent approaches based on smart contracts.</p>
</div>
<div id="S4.SS2.SSS3.p3" class="ltx_para">
<p id="S4.SS2.SSS3.p3.7" class="ltx_p"><span id="S4.SS2.SSS3.p3.7.1" class="ltx_text ltx_font_bold ltx_font_italic">GFL <cite class="ltx_cite ltx_citemacro_citep">(Hu et al<span class="ltx_text">.</span>, <a href="#bib.bib29" title="" class="ltx_ref">2021</a>)</cite>.</span> In their paper, the authors present the Galaxy FL Framework (GFL), a DFL framework based on Blockchain and a committee-based consensus. GFL incorporates the consistent hashing algorithm <cite class="ltx_cite ltx_citemacro_citep">(Lamping and Veach, <a href="#bib.bib41" title="" class="ltx_ref">2014</a>)</cite> to enhance communication performance and introduces a novel ring called RDFL to improve performance and bandwidth utilization. Based on the ring decentralized topology constructed by the consistent hash algorithm, GFL is executed using the RDFL algorithm. Each data node denoted as <math id="S4.SS2.SSS3.p3.1.m1.1" class="ltx_Math" alttext="DP_{k}" display="inline"><semantics id="S4.SS2.SSS3.p3.1.m1.1a"><mrow id="S4.SS2.SSS3.p3.1.m1.1.1" xref="S4.SS2.SSS3.p3.1.m1.1.1.cmml"><mi id="S4.SS2.SSS3.p3.1.m1.1.1.2" xref="S4.SS2.SSS3.p3.1.m1.1.1.2.cmml">D</mi><mo lspace="0em" rspace="0em" id="S4.SS2.SSS3.p3.1.m1.1.1.1" xref="S4.SS2.SSS3.p3.1.m1.1.1.1.cmml">​</mo><msub id="S4.SS2.SSS3.p3.1.m1.1.1.3" xref="S4.SS2.SSS3.p3.1.m1.1.1.3.cmml"><mi id="S4.SS2.SSS3.p3.1.m1.1.1.3.2" xref="S4.SS2.SSS3.p3.1.m1.1.1.3.2.cmml">P</mi><mi id="S4.SS2.SSS3.p3.1.m1.1.1.3.3" xref="S4.SS2.SSS3.p3.1.m1.1.1.3.3.cmml">k</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS3.p3.1.m1.1b"><apply id="S4.SS2.SSS3.p3.1.m1.1.1.cmml" xref="S4.SS2.SSS3.p3.1.m1.1.1"><times id="S4.SS2.SSS3.p3.1.m1.1.1.1.cmml" xref="S4.SS2.SSS3.p3.1.m1.1.1.1"></times><ci id="S4.SS2.SSS3.p3.1.m1.1.1.2.cmml" xref="S4.SS2.SSS3.p3.1.m1.1.1.2">𝐷</ci><apply id="S4.SS2.SSS3.p3.1.m1.1.1.3.cmml" xref="S4.SS2.SSS3.p3.1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.SS2.SSS3.p3.1.m1.1.1.3.1.cmml" xref="S4.SS2.SSS3.p3.1.m1.1.1.3">subscript</csymbol><ci id="S4.SS2.SSS3.p3.1.m1.1.1.3.2.cmml" xref="S4.SS2.SSS3.p3.1.m1.1.1.3.2">𝑃</ci><ci id="S4.SS2.SSS3.p3.1.m1.1.1.3.3.cmml" xref="S4.SS2.SSS3.p3.1.m1.1.1.3.3">𝑘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS3.p3.1.m1.1c">DP_{k}</annotation></semantics></math>, contributes its model <math id="S4.SS2.SSS3.p3.2.m2.1" class="ltx_Math" alttext="M_{k}" display="inline"><semantics id="S4.SS2.SSS3.p3.2.m2.1a"><msub id="S4.SS2.SSS3.p3.2.m2.1.1" xref="S4.SS2.SSS3.p3.2.m2.1.1.cmml"><mi id="S4.SS2.SSS3.p3.2.m2.1.1.2" xref="S4.SS2.SSS3.p3.2.m2.1.1.2.cmml">M</mi><mi id="S4.SS2.SSS3.p3.2.m2.1.1.3" xref="S4.SS2.SSS3.p3.2.m2.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS3.p3.2.m2.1b"><apply id="S4.SS2.SSS3.p3.2.m2.1.1.cmml" xref="S4.SS2.SSS3.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS3.p3.2.m2.1.1.1.cmml" xref="S4.SS2.SSS3.p3.2.m2.1.1">subscript</csymbol><ci id="S4.SS2.SSS3.p3.2.m2.1.1.2.cmml" xref="S4.SS2.SSS3.p3.2.m2.1.1.2">𝑀</ci><ci id="S4.SS2.SSS3.p3.2.m2.1.1.3.cmml" xref="S4.SS2.SSS3.p3.2.m2.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS3.p3.2.m2.1c">M_{k}</annotation></semantics></math>, and the algorithm involves <math id="S4.SS2.SSS3.p3.3.m3.1" class="ltx_Math" alttext="r" display="inline"><semantics id="S4.SS2.SSS3.p3.3.m3.1a"><mi id="S4.SS2.SSS3.p3.3.m3.1.1" xref="S4.SS2.SSS3.p3.3.m3.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS3.p3.3.m3.1b"><ci id="S4.SS2.SSS3.p3.3.m3.1.1.cmml" xref="S4.SS2.SSS3.p3.3.m3.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS3.p3.3.m3.1c">r</annotation></semantics></math> rounds of model synchronization among <math id="S4.SS2.SSS3.p3.4.m4.1" class="ltx_Math" alttext="m" display="inline"><semantics id="S4.SS2.SSS3.p3.4.m4.1a"><mi id="S4.SS2.SSS3.p3.4.m4.1.1" xref="S4.SS2.SSS3.p3.4.m4.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS3.p3.4.m4.1b"><ci id="S4.SS2.SSS3.p3.4.m4.1.1.cmml" xref="S4.SS2.SSS3.p3.4.m4.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS3.p3.4.m4.1c">m</annotation></semantics></math> trusted nodes. During each iteration, the steps include: <math id="S4.SS2.SSS3.p3.5.m5.1" class="ltx_Math" alttext="(i)" display="inline"><semantics id="S4.SS2.SSS3.p3.5.m5.1a"><mrow id="S4.SS2.SSS3.p3.5.m5.1.2.2"><mo stretchy="false" id="S4.SS2.SSS3.p3.5.m5.1.2.2.1">(</mo><mi id="S4.SS2.SSS3.p3.5.m5.1.1" xref="S4.SS2.SSS3.p3.5.m5.1.1.cmml">i</mi><mo stretchy="false" id="S4.SS2.SSS3.p3.5.m5.1.2.2.2">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS3.p3.5.m5.1b"><ci id="S4.SS2.SSS3.p3.5.m5.1.1.cmml" xref="S4.SS2.SSS3.p3.5.m5.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS3.p3.5.m5.1c">(i)</annotation></semantics></math> loading the global model for local training and synchronizing models in a clockwise direction, <math id="S4.SS2.SSS3.p3.6.m6.1" class="ltx_Math" alttext="(ii)" display="inline"><semantics id="S4.SS2.SSS3.p3.6.m6.1a"><mrow id="S4.SS2.SSS3.p3.6.m6.1.1.1" xref="S4.SS2.SSS3.p3.6.m6.1.1.1.1.cmml"><mo stretchy="false" id="S4.SS2.SSS3.p3.6.m6.1.1.1.2" xref="S4.SS2.SSS3.p3.6.m6.1.1.1.1.cmml">(</mo><mrow id="S4.SS2.SSS3.p3.6.m6.1.1.1.1" xref="S4.SS2.SSS3.p3.6.m6.1.1.1.1.cmml"><mi id="S4.SS2.SSS3.p3.6.m6.1.1.1.1.2" xref="S4.SS2.SSS3.p3.6.m6.1.1.1.1.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.SS2.SSS3.p3.6.m6.1.1.1.1.1" xref="S4.SS2.SSS3.p3.6.m6.1.1.1.1.1.cmml">​</mo><mi id="S4.SS2.SSS3.p3.6.m6.1.1.1.1.3" xref="S4.SS2.SSS3.p3.6.m6.1.1.1.1.3.cmml">i</mi></mrow><mo stretchy="false" id="S4.SS2.SSS3.p3.6.m6.1.1.1.3" xref="S4.SS2.SSS3.p3.6.m6.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS3.p3.6.m6.1b"><apply id="S4.SS2.SSS3.p3.6.m6.1.1.1.1.cmml" xref="S4.SS2.SSS3.p3.6.m6.1.1.1"><times id="S4.SS2.SSS3.p3.6.m6.1.1.1.1.1.cmml" xref="S4.SS2.SSS3.p3.6.m6.1.1.1.1.1"></times><ci id="S4.SS2.SSS3.p3.6.m6.1.1.1.1.2.cmml" xref="S4.SS2.SSS3.p3.6.m6.1.1.1.1.2">𝑖</ci><ci id="S4.SS2.SSS3.p3.6.m6.1.1.1.1.3.cmml" xref="S4.SS2.SSS3.p3.6.m6.1.1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS3.p3.6.m6.1c">(ii)</annotation></semantics></math> using knowledge distillation to converge the dark knowledge from other models owned by the trusted node to the local model and synchronizing it among trusted nodes, <math id="S4.SS2.SSS3.p3.7.m7.1" class="ltx_Math" alttext="(iii)" display="inline"><semantics id="S4.SS2.SSS3.p3.7.m7.1a"><mrow id="S4.SS2.SSS3.p3.7.m7.1.1.1" xref="S4.SS2.SSS3.p3.7.m7.1.1.1.1.cmml"><mo stretchy="false" id="S4.SS2.SSS3.p3.7.m7.1.1.1.2" xref="S4.SS2.SSS3.p3.7.m7.1.1.1.1.cmml">(</mo><mrow id="S4.SS2.SSS3.p3.7.m7.1.1.1.1" xref="S4.SS2.SSS3.p3.7.m7.1.1.1.1.cmml"><mi id="S4.SS2.SSS3.p3.7.m7.1.1.1.1.2" xref="S4.SS2.SSS3.p3.7.m7.1.1.1.1.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.SS2.SSS3.p3.7.m7.1.1.1.1.1" xref="S4.SS2.SSS3.p3.7.m7.1.1.1.1.1.cmml">​</mo><mi id="S4.SS2.SSS3.p3.7.m7.1.1.1.1.3" xref="S4.SS2.SSS3.p3.7.m7.1.1.1.1.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.SS2.SSS3.p3.7.m7.1.1.1.1.1a" xref="S4.SS2.SSS3.p3.7.m7.1.1.1.1.1.cmml">​</mo><mi id="S4.SS2.SSS3.p3.7.m7.1.1.1.1.4" xref="S4.SS2.SSS3.p3.7.m7.1.1.1.1.4.cmml">i</mi></mrow><mo stretchy="false" id="S4.SS2.SSS3.p3.7.m7.1.1.1.3" xref="S4.SS2.SSS3.p3.7.m7.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS3.p3.7.m7.1b"><apply id="S4.SS2.SSS3.p3.7.m7.1.1.1.1.cmml" xref="S4.SS2.SSS3.p3.7.m7.1.1.1"><times id="S4.SS2.SSS3.p3.7.m7.1.1.1.1.1.cmml" xref="S4.SS2.SSS3.p3.7.m7.1.1.1.1.1"></times><ci id="S4.SS2.SSS3.p3.7.m7.1.1.1.1.2.cmml" xref="S4.SS2.SSS3.p3.7.m7.1.1.1.1.2">𝑖</ci><ci id="S4.SS2.SSS3.p3.7.m7.1.1.1.1.3.cmml" xref="S4.SS2.SSS3.p3.7.m7.1.1.1.1.3">𝑖</ci><ci id="S4.SS2.SSS3.p3.7.m7.1.1.1.1.4.cmml" xref="S4.SS2.SSS3.p3.7.m7.1.1.1.1.4">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS3.p3.7.m7.1c">(iii)</annotation></semantics></math> executing FedAvg to generate a new global model and initiating the next iteration.
Moreover, GFL incorporates InterPlanetary File System (IPFS) and Blockchain to improve communication efficiency further and enhance the security of FL. Within GFL, two types of smart contracts are utilized. The first type is the <span id="S4.SS2.SSS3.p3.7.2" class="ltx_text ltx_font_italic">controller contract</span>, which oversees the execution of all FL tasks. The second type is the <span id="S4.SS2.SSS3.p3.7.3" class="ltx_text ltx_font_italic">storage contract</span>, which is responsible for preserving the IPFS hash of the model. Each FL task has its individual storage contract. Through their experiments, the authors demonstrate that GFL showcases superior communication performance compared to traditional decentralized FL frameworks. Additionally, they assess GFL’s resilience against data poisoning attacks, although they do not mention the specific type of attack considered.</p>
</div>
<div id="S4.SS2.SSS3.p4" class="ltx_para">
<p id="S4.SS2.SSS3.p4.3" class="ltx_p"><span id="S4.SS2.SSS3.p4.3.1" class="ltx_text ltx_font_bold ltx_font_italic">FED-BC <cite class="ltx_cite ltx_citemacro_citep">(Wu et al<span class="ltx_text">.</span>, <a href="#bib.bib93" title="" class="ltx_ref">2020b</a>)</cite>.</span> In this work, the authors present an FL setup that ensures decentralization in topology, control, storage, and key management, providing enhanced security and robustness compared to centralized methods. They also develop a training approach compatible with the architecture, achieving state-of-the-art accuracy performance by collaboratively training participating nodes. It avoids privacy leakage and single-point-of-failure associated with centralized structures, resulting in improved security and robustness. The participants in the network are arranged in a logical ring topology, but the physical topology only requires that the nodes are connected in some way.
All participating nodes are organized using Blockchain technology, and each node’s status within the framework is considered completely equal. The control and key management functions of the system are handled by smart contracts that are programs deployed on a Blockchain. The system is designed to remain unaffected by the failure or exit of any node, ensuring its normal operation. They conducted experiments to compare their FL approach against several baselines. The baselines included: <math id="S4.SS2.SSS3.p4.1.m1.1" class="ltx_Math" alttext="(i)" display="inline"><semantics id="S4.SS2.SSS3.p4.1.m1.1a"><mrow id="S4.SS2.SSS3.p4.1.m1.1.2.2"><mo stretchy="false" id="S4.SS2.SSS3.p4.1.m1.1.2.2.1">(</mo><mi id="S4.SS2.SSS3.p4.1.m1.1.1" xref="S4.SS2.SSS3.p4.1.m1.1.1.cmml">i</mi><mo stretchy="false" id="S4.SS2.SSS3.p4.1.m1.1.2.2.2">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS3.p4.1.m1.1b"><ci id="S4.SS2.SSS3.p4.1.m1.1.1.cmml" xref="S4.SS2.SSS3.p4.1.m1.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS3.p4.1.m1.1c">(i)</annotation></semantics></math> Training alone, where each node independently trained its local model without interacting with others; <math id="S4.SS2.SSS3.p4.2.m2.1" class="ltx_Math" alttext="(ii)" display="inline"><semantics id="S4.SS2.SSS3.p4.2.m2.1a"><mrow id="S4.SS2.SSS3.p4.2.m2.1.1.1" xref="S4.SS2.SSS3.p4.2.m2.1.1.1.1.cmml"><mo stretchy="false" id="S4.SS2.SSS3.p4.2.m2.1.1.1.2" xref="S4.SS2.SSS3.p4.2.m2.1.1.1.1.cmml">(</mo><mrow id="S4.SS2.SSS3.p4.2.m2.1.1.1.1" xref="S4.SS2.SSS3.p4.2.m2.1.1.1.1.cmml"><mi id="S4.SS2.SSS3.p4.2.m2.1.1.1.1.2" xref="S4.SS2.SSS3.p4.2.m2.1.1.1.1.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.SS2.SSS3.p4.2.m2.1.1.1.1.1" xref="S4.SS2.SSS3.p4.2.m2.1.1.1.1.1.cmml">​</mo><mi id="S4.SS2.SSS3.p4.2.m2.1.1.1.1.3" xref="S4.SS2.SSS3.p4.2.m2.1.1.1.1.3.cmml">i</mi></mrow><mo stretchy="false" id="S4.SS2.SSS3.p4.2.m2.1.1.1.3" xref="S4.SS2.SSS3.p4.2.m2.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS3.p4.2.m2.1b"><apply id="S4.SS2.SSS3.p4.2.m2.1.1.1.1.cmml" xref="S4.SS2.SSS3.p4.2.m2.1.1.1"><times id="S4.SS2.SSS3.p4.2.m2.1.1.1.1.1.cmml" xref="S4.SS2.SSS3.p4.2.m2.1.1.1.1.1"></times><ci id="S4.SS2.SSS3.p4.2.m2.1.1.1.1.2.cmml" xref="S4.SS2.SSS3.p4.2.m2.1.1.1.1.2">𝑖</ci><ci id="S4.SS2.SSS3.p4.2.m2.1.1.1.1.3.cmml" xref="S4.SS2.SSS3.p4.2.m2.1.1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS3.p4.2.m2.1c">(ii)</annotation></semantics></math> Training with dropout, where nodes might drop out during the FL process and are excluded from further participation; and <math id="S4.SS2.SSS3.p4.3.m3.1" class="ltx_Math" alttext="(iii)" display="inline"><semantics id="S4.SS2.SSS3.p4.3.m3.1a"><mrow id="S4.SS2.SSS3.p4.3.m3.1.1.1" xref="S4.SS2.SSS3.p4.3.m3.1.1.1.1.cmml"><mo stretchy="false" id="S4.SS2.SSS3.p4.3.m3.1.1.1.2" xref="S4.SS2.SSS3.p4.3.m3.1.1.1.1.cmml">(</mo><mrow id="S4.SS2.SSS3.p4.3.m3.1.1.1.1" xref="S4.SS2.SSS3.p4.3.m3.1.1.1.1.cmml"><mi id="S4.SS2.SSS3.p4.3.m3.1.1.1.1.2" xref="S4.SS2.SSS3.p4.3.m3.1.1.1.1.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.SS2.SSS3.p4.3.m3.1.1.1.1.1" xref="S4.SS2.SSS3.p4.3.m3.1.1.1.1.1.cmml">​</mo><mi id="S4.SS2.SSS3.p4.3.m3.1.1.1.1.3" xref="S4.SS2.SSS3.p4.3.m3.1.1.1.1.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.SS2.SSS3.p4.3.m3.1.1.1.1.1a" xref="S4.SS2.SSS3.p4.3.m3.1.1.1.1.1.cmml">​</mo><mi id="S4.SS2.SSS3.p4.3.m3.1.1.1.1.4" xref="S4.SS2.SSS3.p4.3.m3.1.1.1.1.4.cmml">i</mi></mrow><mo stretchy="false" id="S4.SS2.SSS3.p4.3.m3.1.1.1.3" xref="S4.SS2.SSS3.p4.3.m3.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS3.p4.3.m3.1b"><apply id="S4.SS2.SSS3.p4.3.m3.1.1.1.1.cmml" xref="S4.SS2.SSS3.p4.3.m3.1.1.1"><times id="S4.SS2.SSS3.p4.3.m3.1.1.1.1.1.cmml" xref="S4.SS2.SSS3.p4.3.m3.1.1.1.1.1"></times><ci id="S4.SS2.SSS3.p4.3.m3.1.1.1.1.2.cmml" xref="S4.SS2.SSS3.p4.3.m3.1.1.1.1.2">𝑖</ci><ci id="S4.SS2.SSS3.p4.3.m3.1.1.1.1.3.cmml" xref="S4.SS2.SSS3.p4.3.m3.1.1.1.1.3">𝑖</ci><ci id="S4.SS2.SSS3.p4.3.m3.1.1.1.1.4.cmml" xref="S4.SS2.SSS3.p4.3.m3.1.1.1.1.4">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS3.p4.3.m3.1c">(iii)</annotation></semantics></math> Training with differential privacy, where participating nodes utilized an existing differential privacy-based FL method. According to them, the proposed approach enables participating nodes to achieve higher model accuracy compared to training separately. Additionally, the framework remains effective even if some nodes drop out, as it assists the remaining nodes in continuing their training to obtain improved models.</p>
</div>
</section>
<section id="S4.SS2.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.4. </span>Others</h4>

<div id="S4.SS2.SSS4.p1" class="ltx_para">
<p id="S4.SS2.SSS4.p1.1" class="ltx_p">Below, we explore the remaining BC-FL approaches that utilize other consensus algorithms not related to any of the previously mentioned categories.</p>
</div>
<div id="S4.SS2.SSS4.p2" class="ltx_para">
<p id="S4.SS2.SSS4.p2.4" class="ltx_p"><span id="S4.SS2.SSS4.p2.4.1" class="ltx_text ltx_font_bold ltx_font_italic">Biscotti <cite class="ltx_cite ltx_citemacro_citep">(Shayan et al<span class="ltx_text">.</span>, <a href="#bib.bib83" title="" class="ltx_ref">2021</a>)</cite>.</span> This method is based on <span id="S4.SS2.SSS4.p2.4.2" class="ltx_text ltx_font_italic">proof-of-federation</span> (PoF) and pursues various objectives in the context of FL.
PoF is an extension of Proof-of-Stake (PoS), where a peer’s stake is determined by their contribution to the system.
Biscotti’s design objectives include <math id="S4.SS2.SSS4.p2.1.m1.1" class="ltx_Math" alttext="(i)" display="inline"><semantics id="S4.SS2.SSS4.p2.1.m1.1a"><mrow id="S4.SS2.SSS4.p2.1.m1.1.2.2"><mo stretchy="false" id="S4.SS2.SSS4.p2.1.m1.1.2.2.1">(</mo><mi id="S4.SS2.SSS4.p2.1.m1.1.1" xref="S4.SS2.SSS4.p2.1.m1.1.1.cmml">i</mi><mo stretchy="false" id="S4.SS2.SSS4.p2.1.m1.1.2.2.2">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS4.p2.1.m1.1b"><ci id="S4.SS2.SSS4.p2.1.m1.1.1.cmml" xref="S4.SS2.SSS4.p2.1.m1.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS4.p2.1.m1.1c">(i)</annotation></semantics></math> Converging to the optimal global model, similar to a model trained without adversaries in an FL setting; <math id="S4.SS2.SSS4.p2.2.m2.1" class="ltx_Math" alttext="(ii)" display="inline"><semantics id="S4.SS2.SSS4.p2.2.m2.1a"><mrow id="S4.SS2.SSS4.p2.2.m2.1.1.1" xref="S4.SS2.SSS4.p2.2.m2.1.1.1.1.cmml"><mo stretchy="false" id="S4.SS2.SSS4.p2.2.m2.1.1.1.2" xref="S4.SS2.SSS4.p2.2.m2.1.1.1.1.cmml">(</mo><mrow id="S4.SS2.SSS4.p2.2.m2.1.1.1.1" xref="S4.SS2.SSS4.p2.2.m2.1.1.1.1.cmml"><mi id="S4.SS2.SSS4.p2.2.m2.1.1.1.1.2" xref="S4.SS2.SSS4.p2.2.m2.1.1.1.1.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.SS2.SSS4.p2.2.m2.1.1.1.1.1" xref="S4.SS2.SSS4.p2.2.m2.1.1.1.1.1.cmml">​</mo><mi id="S4.SS2.SSS4.p2.2.m2.1.1.1.1.3" xref="S4.SS2.SSS4.p2.2.m2.1.1.1.1.3.cmml">i</mi></mrow><mo stretchy="false" id="S4.SS2.SSS4.p2.2.m2.1.1.1.3" xref="S4.SS2.SSS4.p2.2.m2.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS4.p2.2.m2.1b"><apply id="S4.SS2.SSS4.p2.2.m2.1.1.1.1.cmml" xref="S4.SS2.SSS4.p2.2.m2.1.1.1"><times id="S4.SS2.SSS4.p2.2.m2.1.1.1.1.1.cmml" xref="S4.SS2.SSS4.p2.2.m2.1.1.1.1.1"></times><ci id="S4.SS2.SSS4.p2.2.m2.1.1.1.1.2.cmml" xref="S4.SS2.SSS4.p2.2.m2.1.1.1.1.2">𝑖</ci><ci id="S4.SS2.SSS4.p2.2.m2.1.1.1.1.3.cmml" xref="S4.SS2.SSS4.p2.2.m2.1.1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS4.p2.2.m2.1c">(ii)</annotation></semantics></math> Preventing poisoning attacks by verifying peer model updates; <math id="S4.SS2.SSS4.p2.3.m3.1" class="ltx_Math" alttext="(iii)" display="inline"><semantics id="S4.SS2.SSS4.p2.3.m3.1a"><mrow id="S4.SS2.SSS4.p2.3.m3.1.1.1" xref="S4.SS2.SSS4.p2.3.m3.1.1.1.1.cmml"><mo stretchy="false" id="S4.SS2.SSS4.p2.3.m3.1.1.1.2" xref="S4.SS2.SSS4.p2.3.m3.1.1.1.1.cmml">(</mo><mrow id="S4.SS2.SSS4.p2.3.m3.1.1.1.1" xref="S4.SS2.SSS4.p2.3.m3.1.1.1.1.cmml"><mi id="S4.SS2.SSS4.p2.3.m3.1.1.1.1.2" xref="S4.SS2.SSS4.p2.3.m3.1.1.1.1.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.SS2.SSS4.p2.3.m3.1.1.1.1.1" xref="S4.SS2.SSS4.p2.3.m3.1.1.1.1.1.cmml">​</mo><mi id="S4.SS2.SSS4.p2.3.m3.1.1.1.1.3" xref="S4.SS2.SSS4.p2.3.m3.1.1.1.1.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.SS2.SSS4.p2.3.m3.1.1.1.1.1a" xref="S4.SS2.SSS4.p2.3.m3.1.1.1.1.1.cmml">​</mo><mi id="S4.SS2.SSS4.p2.3.m3.1.1.1.1.4" xref="S4.SS2.SSS4.p2.3.m3.1.1.1.1.4.cmml">i</mi></mrow><mo stretchy="false" id="S4.SS2.SSS4.p2.3.m3.1.1.1.3" xref="S4.SS2.SSS4.p2.3.m3.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS4.p2.3.m3.1b"><apply id="S4.SS2.SSS4.p2.3.m3.1.1.1.1.cmml" xref="S4.SS2.SSS4.p2.3.m3.1.1.1"><times id="S4.SS2.SSS4.p2.3.m3.1.1.1.1.1.cmml" xref="S4.SS2.SSS4.p2.3.m3.1.1.1.1.1"></times><ci id="S4.SS2.SSS4.p2.3.m3.1.1.1.1.2.cmml" xref="S4.SS2.SSS4.p2.3.m3.1.1.1.1.2">𝑖</ci><ci id="S4.SS2.SSS4.p2.3.m3.1.1.1.1.3.cmml" xref="S4.SS2.SSS4.p2.3.m3.1.1.1.1.3">𝑖</ci><ci id="S4.SS2.SSS4.p2.3.m3.1.1.1.1.4.cmml" xref="S4.SS2.SSS4.p2.3.m3.1.1.1.1.4">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS4.p2.3.m3.1c">(iii)</annotation></semantics></math> Protecting peer training data privacy by thwarting information leakage attacks; and <math id="S4.SS2.SSS4.p2.4.m4.1" class="ltx_Math" alttext="(iv)" display="inline"><semantics id="S4.SS2.SSS4.p2.4.m4.1a"><mrow id="S4.SS2.SSS4.p2.4.m4.1.1.1" xref="S4.SS2.SSS4.p2.4.m4.1.1.1.1.cmml"><mo stretchy="false" id="S4.SS2.SSS4.p2.4.m4.1.1.1.2" xref="S4.SS2.SSS4.p2.4.m4.1.1.1.1.cmml">(</mo><mrow id="S4.SS2.SSS4.p2.4.m4.1.1.1.1" xref="S4.SS2.SSS4.p2.4.m4.1.1.1.1.cmml"><mi id="S4.SS2.SSS4.p2.4.m4.1.1.1.1.2" xref="S4.SS2.SSS4.p2.4.m4.1.1.1.1.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.SS2.SSS4.p2.4.m4.1.1.1.1.1" xref="S4.SS2.SSS4.p2.4.m4.1.1.1.1.1.cmml">​</mo><mi id="S4.SS2.SSS4.p2.4.m4.1.1.1.1.3" xref="S4.SS2.SSS4.p2.4.m4.1.1.1.1.3.cmml">v</mi></mrow><mo stretchy="false" id="S4.SS2.SSS4.p2.4.m4.1.1.1.3" xref="S4.SS2.SSS4.p2.4.m4.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS4.p2.4.m4.1b"><apply id="S4.SS2.SSS4.p2.4.m4.1.1.1.1.cmml" xref="S4.SS2.SSS4.p2.4.m4.1.1.1"><times id="S4.SS2.SSS4.p2.4.m4.1.1.1.1.1.cmml" xref="S4.SS2.SSS4.p2.4.m4.1.1.1.1.1"></times><ci id="S4.SS2.SSS4.p2.4.m4.1.1.1.1.2.cmml" xref="S4.SS2.SSS4.p2.4.m4.1.1.1.1.2">𝑖</ci><ci id="S4.SS2.SSS4.p2.4.m4.1.1.1.1.3.cmml" xref="S4.SS2.SSS4.p2.4.m4.1.1.1.1.3">𝑣</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS4.p2.4.m4.1c">(iv)</annotation></semantics></math> Restricting colluding peers from gaining influence without obtaining sufficient stake.</p>
</div>
<div id="S4.SS2.SSS4.p3" class="ltx_para">
<p id="S4.SS2.SSS4.p3.1" class="ltx_p">To achieve these objectives, Biscotti utilizes a custom Blockchain design in combination with <span id="S4.SS2.SSS4.p3.1.1" class="ltx_text ltx_font_italic">verifiable random functions</span> (VRFs) <cite class="ltx_cite ltx_citemacro_citep">(Gilad et al<span class="ltx_text">.</span>, <a href="#bib.bib23" title="" class="ltx_ref">2017</a>)</cite> for secure randomness generation, where peers collaboratively train a global model. Each block in the distributed ledger represents a single iteration of stochastic gradient descent (SGD), and the ledger maintains the state of the global model at each iteration.</p>
</div>
<div id="S4.SS2.SSS4.p4" class="ltx_para">
<p id="S4.SS2.SSS4.p4.1" class="ltx_p">The evaluation of Biscotti demonstrates its efficiency, fault tolerance, and effectiveness in countering known attacks like Sybil attacks, poisoning attacks, and information leakage attacks. It successfully preserves the privacy of individual client updates while maintaining the optimal performance of the global model, even when the system includes a substantial proportion of malicious adversaries (up to <math id="S4.SS2.SSS4.p4.1.m1.1" class="ltx_Math" alttext="30\%" display="inline"><semantics id="S4.SS2.SSS4.p4.1.m1.1a"><mrow id="S4.SS2.SSS4.p4.1.m1.1.1" xref="S4.SS2.SSS4.p4.1.m1.1.1.cmml"><mn id="S4.SS2.SSS4.p4.1.m1.1.1.2" xref="S4.SS2.SSS4.p4.1.m1.1.1.2.cmml">30</mn><mo id="S4.SS2.SSS4.p4.1.m1.1.1.1" xref="S4.SS2.SSS4.p4.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS4.p4.1.m1.1b"><apply id="S4.SS2.SSS4.p4.1.m1.1.1.cmml" xref="S4.SS2.SSS4.p4.1.m1.1.1"><csymbol cd="latexml" id="S4.SS2.SSS4.p4.1.m1.1.1.1.cmml" xref="S4.SS2.SSS4.p4.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S4.SS2.SSS4.p4.1.m1.1.1.2.cmml" xref="S4.SS2.SSS4.p4.1.m1.1.1.2">30</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS4.p4.1.m1.1c">30\%</annotation></semantics></math>).
However, Biscotti has some limitations, including issues related to scalability on large deep learning models, potential leakage from the aggregate model, and limitations in stake mechanisms.</p>
</div>
<div id="S4.SS2.SSS4.p5" class="ltx_para">
<p id="S4.SS2.SSS4.p5.1" class="ltx_p"><span id="S4.SS2.SSS4.p5.1.1" class="ltx_text ltx_font_bold ltx_font_italic">BytoChain <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib48" title="" class="ltx_ref">2021b</a>)</cite>.</span>
The researchers propose a verification-efficient framework called BytoChain, which introduces verifiers to execute heavy verification workflows in parallel. BytoChain employs the <span id="S4.SS2.SSS4.p5.1.2" class="ltx_text ltx_font_italic">proof-of-accuracy</span> (PoA) consensus algorithm, allowing for offloading the verification overhead of miners. In PoA, miners prove their effective workload based on accuracy, utilizing two critical thresholds: the accuracy oscillation threshold (AOT) and the accuracy deviation threshold (ADT). The AOT limits the maximum allowable accuracy reduction for receiving models, while the ADT restricts the maximum absolute difference in validation accuracy of a model on different miners.</p>
</div>
<div id="S4.SS2.SSS4.p6" class="ltx_para">
<p id="S4.SS2.SSS4.p6.1" class="ltx_p">Miners traverse their transaction pools to identify a set of transactions that collectively produce an averaged model with the highest accuracy. The accuracy reduction from the averaged model is limited by a predefined threshold. The winning miner can then generate a new block containing the hash proof of the averaged model and broadcast it for consensus verification.</p>
</div>
<div id="S4.SS2.SSS4.p7" class="ltx_para">
<p id="S4.SS2.SSS4.p7.1" class="ltx_p">BytoChain’s framework comprises <span id="S4.SS2.SSS4.p7.1.1" class="ltx_text ltx_font_italic">data holders</span> within the end-side system, <span id="S4.SS2.SSS4.p7.1.2" class="ltx_text ltx_font_italic">verifiers</span>, <span id="S4.SS2.SSS4.p7.1.3" class="ltx_text ltx_font_italic">miners</span> at the network edge, and a <span id="S4.SS2.SSS4.p7.1.4" class="ltx_text ltx_font_italic">task publisher</span> in the Blockchain network. Data holders represent training devices possessing training data, while verifiers and miners, located at the network edge, are equipped with robust computing power and high bandwidth capabilities. Verifiers detect inferior local models submitted by potentially malicious data holders and generate transactions for miners. Miners mine legal global models and broadcast their blocks to achieve consensus. The task publisher is responsible for creating the genesis block to publish the training task and incentivizing other nodes by offering cryptocurrency rewards.</p>
</div>
<div id="S4.SS2.SSS4.p8" class="ltx_para">
<p id="S4.SS2.SSS4.p8.1" class="ltx_p">BytoChain utilizes two types of blocks: the genesis block and regular blocks. The genesis block initiates the system and training parameters, while regular blocks contain transactions with local models forming a Merkle tree. The global model obtained from these transactions is also included in regular blocks, enabling failure rollback and offline audit.</p>
</div>
<div id="S4.SS2.SSS4.p9" class="ltx_para">
<p id="S4.SS2.SSS4.p9.1" class="ltx_p">However, the paper identifies security concerns related to privacy attacks, confidentiality, and the presence of backdoors, which require further attention and investigation. These issues need to be addressed to ensure the robustness and security of the BytoChain framework.</p>
</div>
<div id="S4.SS2.SSS4.p10" class="ltx_para">
<p id="S4.SS2.SSS4.p10.3" class="ltx_p"><span id="S4.SS2.SSS4.p10.3.1" class="ltx_text ltx_font_bold ltx_font_italic">PIRATE <cite class="ltx_cite ltx_citemacro_citep">(Zhou et al<span class="ltx_text">.</span>, <a href="#bib.bib106" title="" class="ltx_ref">2019a</a>)</cite>.</span> PIRATE is designed as a Byzantine-resilient distributed stochastic gradient descent (D-SGD) framework under decentralized settings. The consensus algorithm is <span id="S4.SS2.SSS4.p10.3.2" class="ltx_text ltx_font_italic">hotstuff</span> <cite class="ltx_cite ltx_citemacro_citep">(Abraham et al<span class="ltx_text">.</span>, <a href="#bib.bib3" title="" class="ltx_ref">2018</a>)</cite> that solves the State Machine Replication (SMR) problem. At the core of SMR lies a protocol designed to determine a growing log of command requests made by clients. A set of state-machine replicas apply these commands in consistent sequence order. When a client sends a command request to all replicas, it awaits responses from <math id="S4.SS2.SSS4.p10.1.m1.1" class="ltx_Math" alttext="(f+1)" display="inline"><semantics id="S4.SS2.SSS4.p10.1.m1.1a"><mrow id="S4.SS2.SSS4.p10.1.m1.1.1.1" xref="S4.SS2.SSS4.p10.1.m1.1.1.1.1.cmml"><mo stretchy="false" id="S4.SS2.SSS4.p10.1.m1.1.1.1.2" xref="S4.SS2.SSS4.p10.1.m1.1.1.1.1.cmml">(</mo><mrow id="S4.SS2.SSS4.p10.1.m1.1.1.1.1" xref="S4.SS2.SSS4.p10.1.m1.1.1.1.1.cmml"><mi id="S4.SS2.SSS4.p10.1.m1.1.1.1.1.2" xref="S4.SS2.SSS4.p10.1.m1.1.1.1.1.2.cmml">f</mi><mo id="S4.SS2.SSS4.p10.1.m1.1.1.1.1.1" xref="S4.SS2.SSS4.p10.1.m1.1.1.1.1.1.cmml">+</mo><mn id="S4.SS2.SSS4.p10.1.m1.1.1.1.1.3" xref="S4.SS2.SSS4.p10.1.m1.1.1.1.1.3.cmml">1</mn></mrow><mo stretchy="false" id="S4.SS2.SSS4.p10.1.m1.1.1.1.3" xref="S4.SS2.SSS4.p10.1.m1.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS4.p10.1.m1.1b"><apply id="S4.SS2.SSS4.p10.1.m1.1.1.1.1.cmml" xref="S4.SS2.SSS4.p10.1.m1.1.1.1"><plus id="S4.SS2.SSS4.p10.1.m1.1.1.1.1.1.cmml" xref="S4.SS2.SSS4.p10.1.m1.1.1.1.1.1"></plus><ci id="S4.SS2.SSS4.p10.1.m1.1.1.1.1.2.cmml" xref="S4.SS2.SSS4.p10.1.m1.1.1.1.1.2">𝑓</ci><cn type="integer" id="S4.SS2.SSS4.p10.1.m1.1.1.1.1.3.cmml" xref="S4.SS2.SSS4.p10.1.m1.1.1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS4.p10.1.m1.1c">(f+1)</annotation></semantics></math> of them. By utilizing a sharding-based Blockchain protocol and taking advantage of 5G techniques, PIRATE ensures the protection of model parameters and gradient aggregations. Randomly splitting computing nodes into multiple committees and agreeing upon partial aggregations among committee members mitigates the burden of aggregation workload. The framework consists of two essential components: <math id="S4.SS2.SSS4.p10.2.m2.1" class="ltx_Math" alttext="(i)" display="inline"><semantics id="S4.SS2.SSS4.p10.2.m2.1a"><mrow id="S4.SS2.SSS4.p10.2.m2.1.2.2"><mo stretchy="false" id="S4.SS2.SSS4.p10.2.m2.1.2.2.1">(</mo><mi id="S4.SS2.SSS4.p10.2.m2.1.1" xref="S4.SS2.SSS4.p10.2.m2.1.1.cmml">i</mi><mo stretchy="false" id="S4.SS2.SSS4.p10.2.m2.1.2.2.2">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS4.p10.2.m2.1b"><ci id="S4.SS2.SSS4.p10.2.m2.1.1.cmml" xref="S4.SS2.SSS4.p10.2.m2.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS4.p10.2.m2.1c">(i)</annotation></semantics></math> reliability assessment and <math id="S4.SS2.SSS4.p10.3.m3.1" class="ltx_Math" alttext="(ii)" display="inline"><semantics id="S4.SS2.SSS4.p10.3.m3.1a"><mrow id="S4.SS2.SSS4.p10.3.m3.1.1.1" xref="S4.SS2.SSS4.p10.3.m3.1.1.1.1.cmml"><mo stretchy="false" id="S4.SS2.SSS4.p10.3.m3.1.1.1.2" xref="S4.SS2.SSS4.p10.3.m3.1.1.1.1.cmml">(</mo><mrow id="S4.SS2.SSS4.p10.3.m3.1.1.1.1" xref="S4.SS2.SSS4.p10.3.m3.1.1.1.1.cmml"><mi id="S4.SS2.SSS4.p10.3.m3.1.1.1.1.2" xref="S4.SS2.SSS4.p10.3.m3.1.1.1.1.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.SS2.SSS4.p10.3.m3.1.1.1.1.1" xref="S4.SS2.SSS4.p10.3.m3.1.1.1.1.1.cmml">​</mo><mi id="S4.SS2.SSS4.p10.3.m3.1.1.1.1.3" xref="S4.SS2.SSS4.p10.3.m3.1.1.1.1.3.cmml">i</mi></mrow><mo stretchy="false" id="S4.SS2.SSS4.p10.3.m3.1.1.1.3" xref="S4.SS2.SSS4.p10.3.m3.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS4.p10.3.m3.1b"><apply id="S4.SS2.SSS4.p10.3.m3.1.1.1.1.cmml" xref="S4.SS2.SSS4.p10.3.m3.1.1.1"><times id="S4.SS2.SSS4.p10.3.m3.1.1.1.1.1.cmml" xref="S4.SS2.SSS4.p10.3.m3.1.1.1.1.1"></times><ci id="S4.SS2.SSS4.p10.3.m3.1.1.1.1.2.cmml" xref="S4.SS2.SSS4.p10.3.m3.1.1.1.1.2">𝑖</ci><ci id="S4.SS2.SSS4.p10.3.m3.1.1.1.1.3.cmml" xref="S4.SS2.SSS4.p10.3.m3.1.1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS4.p10.3.m3.1c">(ii)</annotation></semantics></math> Blockchain (BC) systems for distributed SGD (D-SGD). Blockchain safeguards gradient aggregations and model parameters, while reliability assessment plays a crucial role in determining the participants involved in distributed learning tasks. In their evaluation, the researchers compare their prototype with another Blockchain-based SGD framework, LearningChain, under the assumption that no malicious nodes are present. The comparison involves assessing the gradient storage overhead in both frameworks and measuring the iteration time, which represents the time taken to broadcast a block containing essential information for nodes to progress in D-SGD. Simulation results demonstrate that the proposed framework outperforms in terms of communication time and storage complexity, and further analysis of robustness and resiliency is underway. Future directions involve protection against model poisoning attacks, decentralized permission control, and incentive mechanism.</p>
</div>
<div id="S4.SS2.SSS4.p11" class="ltx_para">
<p id="S4.SS2.SSS4.p11.2" class="ltx_p"><span id="S4.SS2.SSS4.p11.2.1" class="ltx_text ltx_font_bold ltx_font_italic">Trustworthy FL <cite class="ltx_cite ltx_citemacro_citep">(Yang et al<span class="ltx_text">.</span>, <a href="#bib.bib97" title="" class="ltx_ref">2023</a>)</cite>.</span>
A PBFT-based wireless architecture is proposed by combining permissioned Blockchain and wireless FL systems at the network edge. <span id="S4.SS2.SSS4.p11.2.2" class="ltx_text ltx_font_italic">Practical Byzantine Fault Tolerance</span> (PBFT) is a consensus protocol that offers lower energy consumption and higher effectiveness compared to PoW. While PoW is a permissionless protocol that can tolerate a <math id="S4.SS2.SSS4.p11.1.m1.1" class="ltx_Math" alttext="50\%" display="inline"><semantics id="S4.SS2.SSS4.p11.1.m1.1a"><mrow id="S4.SS2.SSS4.p11.1.m1.1.1" xref="S4.SS2.SSS4.p11.1.m1.1.1.cmml"><mn id="S4.SS2.SSS4.p11.1.m1.1.1.2" xref="S4.SS2.SSS4.p11.1.m1.1.1.2.cmml">50</mn><mo id="S4.SS2.SSS4.p11.1.m1.1.1.1" xref="S4.SS2.SSS4.p11.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS4.p11.1.m1.1b"><apply id="S4.SS2.SSS4.p11.1.m1.1.1.cmml" xref="S4.SS2.SSS4.p11.1.m1.1.1"><csymbol cd="latexml" id="S4.SS2.SSS4.p11.1.m1.1.1.1.cmml" xref="S4.SS2.SSS4.p11.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S4.SS2.SSS4.p11.1.m1.1.1.2.cmml" xref="S4.SS2.SSS4.p11.1.m1.1.1.2">50</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS4.p11.1.m1.1c">50\%</annotation></semantics></math> computing power attack, PBFT is a permissioned protocol that can withstand up to <math id="S4.SS2.SSS4.p11.2.m2.1" class="ltx_Math" alttext="33\%" display="inline"><semantics id="S4.SS2.SSS4.p11.2.m2.1a"><mrow id="S4.SS2.SSS4.p11.2.m2.1.1" xref="S4.SS2.SSS4.p11.2.m2.1.1.cmml"><mn id="S4.SS2.SSS4.p11.2.m2.1.1.2" xref="S4.SS2.SSS4.p11.2.m2.1.1.2.cmml">33</mn><mo id="S4.SS2.SSS4.p11.2.m2.1.1.1" xref="S4.SS2.SSS4.p11.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS4.p11.2.m2.1b"><apply id="S4.SS2.SSS4.p11.2.m2.1.1.cmml" xref="S4.SS2.SSS4.p11.2.m2.1.1"><csymbol cd="latexml" id="S4.SS2.SSS4.p11.2.m2.1.1.1.cmml" xref="S4.SS2.SSS4.p11.2.m2.1.1.1">percent</csymbol><cn type="integer" id="S4.SS2.SSS4.p11.2.m2.1.1.2.cmml" xref="S4.SS2.SSS4.p11.2.m2.1.1.2">33</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS4.p11.2.m2.1c">33\%</annotation></semantics></math> malicious edge servers. The PBFT consensus protocol is used to validate the correctness of global model updates in the wireless Trustworthy FL, leading to high effectiveness and low energy consumption. The detailed procedures of the PBFT-based wireless system are presented, highlighting the training latency that arises from the multiple rounds of cross-validation within the Blockchain consensus protocol. To tackle this challenge, a network optimization problem is formulated to jointly consider bandwidth and power allocation, aiming to minimize the long-term average training latency across progressive learning rounds. To efficiently solve this optimization problem, a Markov decision process framework is proposed, and a deep reinforcement learning (DRL)-based algorithm is employed, offering high system performance with low computational complexity. This research showcases the potential of PBFT-based wireless systems in providing trustworthy and efficient FL while addressing the latency challenges introduced by the Blockchain consensus protocol.</p>
</div>
<div id="S4.SS2.SSS4.p12" class="ltx_para">
<p id="S4.SS2.SSS4.p12.1" class="ltx_p"><span id="S4.SS2.SSS4.p12.1.1" class="ltx_text ltx_font_bold ltx_font_italic">FedCoin <cite class="ltx_cite ltx_citemacro_citep">(Liu et al<span class="ltx_text">.</span>, <a href="#bib.bib50" title="" class="ltx_ref">2020</a>)</cite>.</span>
This work presents an interesting Blockchain-based payment system for FL with a unique consensus algorithm called <span id="S4.SS2.SSS4.p12.1.2" class="ltx_text ltx_font_italic">proof-of-Shapley-Value</span> (PoSV). <span id="S4.SS2.SSS4.p12.1.3" class="ltx_text ltx_font_italic">Shapley Value</span> (SV) has gained popularity as a means of fairly distributing profits among contributors in a coalition. The SV finds applications in various fields like economics, information theory, and ML. It is valued for ensuring fairness, individual rationality, and additivity in payoff distribution. Unlike traditional Blockchain networks like Bitcoin, where miners solve meaningless puzzles to mine new blocks, FedCoin utilizes a PoSV-based consensus approach. Miners in FedCoin are required to calculate an SV vector, which represents the contribution of each FL client to the global FL model in a fair manner. FedCoin is divided into two parts, the FL network and the P2P Blockchain network. In the FL network, a centralized server, known as the FL server, is responsible for coordinating model training execution and receiving payment from the FL model requester. This approach can be classified as a hybrid one like GossipFL <cite class="ltx_cite ltx_citemacro_citep">(Tang et al<span class="ltx_text">.</span>, <a href="#bib.bib86" title="" class="ltx_ref">2023</a>)</cite>.
Based on the computed SVs, FedCoin proposes a scheme for dividing incentive payoffs among FL clients, ensuring nonrepudiation and tamper-resistance properties. All payment transactions are recorded immutably in the Blockchain, eliminating the need for a central FL server to distribute incentives. This decentralized payment system enables the inclusion of high-quality data from FL clients, as the SVs accurately reflect their contributions to the global FL model.</p>
</div>
<div id="S4.SS2.SSS4.p13" class="ltx_para">
<p id="S4.SS2.SSS4.p13.1" class="ltx_p">Experimental evaluations using real-world data demonstrate that FedCoin effectively computes SVs while imposing an upper limit on computational resources required for achieving consensus. This allows individuals who do not own data to participate in FL processes actively, opening up opportunities for wider participation and collaboration in FL. The integration of the SV concept into the consensus mechanism of FedCoin showcases a novel approach to incentivizing FL and promoting fairness in reward distribution.</p>
</div>
</section>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5. </span>Challenges of Decentralized FL</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.2" class="ltx_p">In this section, we discuss the primary open challenges of DFL, which can be categorized into the following two categories: <math id="S5.p1.1.m1.1" class="ltx_Math" alttext="(i)" display="inline"><semantics id="S5.p1.1.m1.1a"><mrow id="S5.p1.1.m1.1.2.2"><mo stretchy="false" id="S5.p1.1.m1.1.2.2.1">(</mo><mi id="S5.p1.1.m1.1.1" xref="S5.p1.1.m1.1.1.cmml">i</mi><mo stretchy="false" id="S5.p1.1.m1.1.2.2.2">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.p1.1.m1.1b"><ci id="S5.p1.1.m1.1.1.cmml" xref="S5.p1.1.m1.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.1.m1.1c">(i)</annotation></semantics></math> <span id="S5.p1.2.1" class="ltx_text ltx_font_italic">security against adversarial attacks</span>, and <math id="S5.p1.2.m2.1" class="ltx_Math" alttext="(ii)" display="inline"><semantics id="S5.p1.2.m2.1a"><mrow id="S5.p1.2.m2.1.1.1" xref="S5.p1.2.m2.1.1.1.1.cmml"><mo stretchy="false" id="S5.p1.2.m2.1.1.1.2" xref="S5.p1.2.m2.1.1.1.1.cmml">(</mo><mrow id="S5.p1.2.m2.1.1.1.1" xref="S5.p1.2.m2.1.1.1.1.cmml"><mi id="S5.p1.2.m2.1.1.1.1.2" xref="S5.p1.2.m2.1.1.1.1.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S5.p1.2.m2.1.1.1.1.1" xref="S5.p1.2.m2.1.1.1.1.1.cmml">​</mo><mi id="S5.p1.2.m2.1.1.1.1.3" xref="S5.p1.2.m2.1.1.1.1.3.cmml">i</mi></mrow><mo stretchy="false" id="S5.p1.2.m2.1.1.1.3" xref="S5.p1.2.m2.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.p1.2.m2.1b"><apply id="S5.p1.2.m2.1.1.1.1.cmml" xref="S5.p1.2.m2.1.1.1"><times id="S5.p1.2.m2.1.1.1.1.1.cmml" xref="S5.p1.2.m2.1.1.1.1.1"></times><ci id="S5.p1.2.m2.1.1.1.1.2.cmml" xref="S5.p1.2.m2.1.1.1.1.2">𝑖</ci><ci id="S5.p1.2.m2.1.1.1.1.3.cmml" xref="S5.p1.2.m2.1.1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.2.m2.1c">(ii)</annotation></semantics></math> <span id="S5.p1.2.2" class="ltx_text ltx_font_italic">lack of incentive mechanisms</span>.</p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1. </span>Security against Adversarial Attacks</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">Traditional FL faces a range of adversarial attacks. These attacks manifest in different forms and can adversely affect output accuracy, disrupt model convergence, and even result in unacceptable denial-of-services (DoS) for both servers and users. Similar threats are also shared by decentralized FL approaches.</p>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<p id="S5.SS1.p2.1" class="ltx_p">One major challenge is the presence of possibly <span id="S5.SS1.p2.1.1" class="ltx_text ltx_font_italic">malicious</span> nodes. These intentionally join the network to exploit P2P networking characteristics and harm the system. They may flood other nodes with random or redundant data, and collaborate with other malicious actors to execute DoS attacks. These malicious nodes pose a significant security and reliability challenge to the FL process.</p>
</div>
<div id="S5.SS1.p3" class="ltx_para">
<p id="S5.SS1.p3.1" class="ltx_p">The creation of federated models involves aggregating model updates submitted by participants. However, to protect the confidentiality of training data, the aggregator has no visibility into how these updates are generated. This limitation makes FL (and by extension, DFL) susceptible to several kind of poisoning attacks that aim to detriment the accuracy of the global model by either polluting the training set of some nodes with maliciously crafted examples (<em id="S5.SS1.p3.1.1" class="ltx_emph ltx_font_italic">data poisoning</em> <cite class="ltx_cite ltx_citemacro_citep">(Jagielski et al<span class="ltx_text">.</span>, <a href="#bib.bib32" title="" class="ltx_ref">2018</a>)</cite>), or by directly manipulating the model weights before they arrive to the aggregator (<em id="S5.SS1.p3.1.2" class="ltx_emph ltx_font_italic">model poisoning</em> <cite class="ltx_cite ltx_citemacro_citep">(Bhagoji et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2019</a>)</cite>). Furthermore, while in standard FL only the server has access to the model parameters sent by the clients, in DFL every participant can have access to them. This can be exploited by malicious actors to carry on model inversion attacks, where the private training set can be inferred from model parameters.</p>
</div>
<div id="S5.SS1.p4" class="ltx_para">
<p id="S5.SS1.p4.1" class="ltx_p">Below, we discuss the security challenges specific to each category of DFL approaches considered.</p>
</div>
<section id="S5.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.1. </span>TD-FL</h4>

<div id="S5.SS1.SSS1.p1" class="ltx_para">
<p id="S5.SS1.SSS1.p1.1" class="ltx_p">Robust TD-FL systems with security measures against adversarial attacks are currently limited to Trusted DFL <cite class="ltx_cite ltx_citemacro_citep">(Gholami et al<span class="ltx_text">.</span>, <a href="#bib.bib22" title="" class="ltx_ref">2022</a>)</cite>. Trusted DFL is tested against a model poisoning attack by transmitting randomly sampled weights within a given range, and its proposed algorithm demonstrates improved performance in the presence of attacked agents compared to a system without trust incorporation.
However, this is the simplest attack model to counter, and the literature lacks comprehensive analyses and evaluations against more advanced poisoning attacks (e.g., LIE <cite class="ltx_cite ltx_citemacro_citep">(Baruch et al<span class="ltx_text">.</span>, <a href="#bib.bib7" title="" class="ltx_ref">2019</a>)</cite>, OPT <cite class="ltx_cite ltx_citemacro_citep">(Fang et al<span class="ltx_text">.</span>, <a href="#bib.bib20" title="" class="ltx_ref">2020</a>)</cite>), as well as the incorporation of robust aggregation functions, such as Multi-Krum <cite class="ltx_cite ltx_citemacro_citep">(Blanchard et al<span class="ltx_text">.</span>, <a href="#bib.bib12" title="" class="ltx_ref">2017</a>)</cite> or more advanced techniques <cite class="ltx_cite ltx_citemacro_citep">(Tolomei et al<span class="ltx_text">.</span>, <a href="#bib.bib88" title="" class="ltx_ref">2023</a>)</cite>.</p>
</div>
</section>
<section id="S5.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.2. </span>BC-FL</h4>

<div id="S5.SS1.SSS2.p1" class="ltx_para">
<p id="S5.SS1.SSS2.p1.1" class="ltx_p">Existing BC-FL frameworks employ consensus <cite class="ltx_cite ltx_citemacro_citep">(Shayan et al<span class="ltx_text">.</span>, <a href="#bib.bib83" title="" class="ltx_ref">2021</a>; Zhao et al<span class="ltx_text">.</span>, <a href="#bib.bib103" title="" class="ltx_ref">2021</a>)</cite> and trust mechanisms <cite class="ltx_cite ltx_citemacro_citep">(Yang et al<span class="ltx_text">.</span>, <a href="#bib.bib97" title="" class="ltx_ref">2023</a>)</cite> to reinforce the system’s defense against potential attacks and ensure the integrity of the learning process. A few works demonstrate the robustness of these approaches through experiments.</p>
</div>
<div id="S5.SS1.SSS2.p2" class="ltx_para">
<p id="S5.SS1.SSS2.p2.1" class="ltx_p">For instance, Biscotti <cite class="ltx_cite ltx_citemacro_citep">(Shayan et al<span class="ltx_text">.</span>, <a href="#bib.bib83" title="" class="ltx_ref">2021</a>)</cite> tolerates label flipping attacks <cite class="ltx_cite ltx_citemacro_citep">(Miller et al<span class="ltx_text">.</span>, <a href="#bib.bib56" title="" class="ltx_ref">2014</a>)</cite> using Multi-Krum, which effectively rejects model updates deviating heavily from the majority direction of updates. Biscotti can handle poisonous updates from up to <math id="S5.SS1.SSS2.p2.1.m1.1" class="ltx_Math" alttext="30\%" display="inline"><semantics id="S5.SS1.SSS2.p2.1.m1.1a"><mrow id="S5.SS1.SSS2.p2.1.m1.1.1" xref="S5.SS1.SSS2.p2.1.m1.1.1.cmml"><mn id="S5.SS1.SSS2.p2.1.m1.1.1.2" xref="S5.SS1.SSS2.p2.1.m1.1.1.2.cmml">30</mn><mo id="S5.SS1.SSS2.p2.1.m1.1.1.1" xref="S5.SS1.SSS2.p2.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS2.p2.1.m1.1b"><apply id="S5.SS1.SSS2.p2.1.m1.1.1.cmml" xref="S5.SS1.SSS2.p2.1.m1.1.1"><csymbol cd="latexml" id="S5.SS1.SSS2.p2.1.m1.1.1.1.cmml" xref="S5.SS1.SSS2.p2.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S5.SS1.SSS2.p2.1.m1.1.1.2.cmml" xref="S5.SS1.SSS2.p2.1.m1.1.1.2">30</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS2.p2.1.m1.1c">30\%</annotation></semantics></math> malicious clients.</p>
</div>
<div id="S5.SS1.SSS2.p3" class="ltx_para">
<p id="S5.SS1.SSS2.p3.1" class="ltx_p">BAFL <cite class="ltx_cite ltx_citemacro_citep">(Feng et al<span class="ltx_text">.</span>, <a href="#bib.bib21" title="" class="ltx_ref">2022</a>)</cite> tackles Gaussian reverse attacks by ensuring security through the Blockchain and employing a consensus mechanism similar to Algorand <cite class="ltx_cite ltx_citemacro_citep">(Gilad et al<span class="ltx_text">.</span>, <a href="#bib.bib23" title="" class="ltx_ref">2017</a>)</cite>.</p>
</div>
<div id="S5.SS1.SSS2.p4" class="ltx_para">
<p id="S5.SS1.SSS2.p4.1" class="ltx_p">BytoChain <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib48" title="" class="ltx_ref">2021b</a>)</cite> proves its security by withstanding random poisoning and reverse poisoning attacks. Unlike basic FL, BytoChain maintains its accuracy even with <math id="S5.SS1.SSS2.p4.1.m1.1" class="ltx_Math" alttext="40\%" display="inline"><semantics id="S5.SS1.SSS2.p4.1.m1.1a"><mrow id="S5.SS1.SSS2.p4.1.m1.1.1" xref="S5.SS1.SSS2.p4.1.m1.1.1.cmml"><mn id="S5.SS1.SSS2.p4.1.m1.1.1.2" xref="S5.SS1.SSS2.p4.1.m1.1.1.2.cmml">40</mn><mo id="S5.SS1.SSS2.p4.1.m1.1.1.1" xref="S5.SS1.SSS2.p4.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS2.p4.1.m1.1b"><apply id="S5.SS1.SSS2.p4.1.m1.1.1.cmml" xref="S5.SS1.SSS2.p4.1.m1.1.1"><csymbol cd="latexml" id="S5.SS1.SSS2.p4.1.m1.1.1.1.cmml" xref="S5.SS1.SSS2.p4.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S5.SS1.SSS2.p4.1.m1.1.1.2.cmml" xref="S5.SS1.SSS2.p4.1.m1.1.1.2">40</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS2.p4.1.m1.1c">40\%</annotation></semantics></math> of data holders being attackers.</p>
</div>
<div id="S5.SS1.SSS2.p5" class="ltx_para">
<p id="S5.SS1.SSS2.p5.1" class="ltx_p">These experiments and implementations demonstrate the effectiveness of these approaches in countering adversarial attacks in BC-FL systems, providing essential insights for enhancing the resilience and security of decentralized FL in diverse scenarios.</p>
</div>
</section>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2. </span>Lack of Incentive Mechanisms</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">Another problem is the lack of an incentive mechanism for the devices that participate in the FL task. In a large-scale FL system, all devices want to participate in the learning process and improve their local model with the help of a federation. Since the aggregation of local updates costs computation power, it is necessary to choose devices with high-quality data and high computation power. Overall, incentives in FL serve as catalysts for addressing resource constraints, security concerns, data quality, and participant engagement. They help create a mutually beneficial environment where participants are motivated to contribute their resources and data, leading to improved training performance and the overall success of FL. Furthermore, since we have cross-silo and cross-device systems as defined in Section <a href="#S2" title="2. Background and Preliminaries ‣ A Survey on Decentralized Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, we have different reasons to create an incentive mechanism.</p>
</div>
<div id="S5.SS2.p2" class="ltx_para">
<p id="S5.SS2.p2.1" class="ltx_p">There are two main reasons why incentives are useful in cross-device FL <cite class="ltx_cite ltx_citemacro_citep">(Yang et al<span class="ltx_text">.</span>, <a href="#bib.bib96" title="" class="ltx_ref">2022</a>)</cite>. Firstly, privacy concerns and reluctance to dedicate computing resources can discourage mobile users from participating in DFL. Secondly, the current DFL approach rewards participants with the same global model parameters, regardless of their individual contributions. This lack of differentiation may discourage active participation. Incentives can address these issues by providing reassurance regarding privacy and compensating participants based on their level of contribution, thereby motivating more active and engaged participation in DFL.</p>
</div>
<div id="S5.SS2.p3" class="ltx_para">
<p id="S5.SS2.p3.1" class="ltx_p">In cross-silo FL <cite class="ltx_cite ltx_citemacro_citep">(Tang and Wong, <a href="#bib.bib85" title="" class="ltx_ref">2021</a>)</cite>, organizations have the freedom to choose their processing capacity for local training. This decision affects the accuracy of the global model and the computational costs incurred. Communication costs depend on the frequency of model updates exchanged with the central server. However, organizations may have different valuations on precision and varying computational and communication costs. To promote efficient cooperation and maximize social welfare, an incentive mechanism is needed to motivate organizations, even if they are independent and driven by self-interest. This mechanism should align individual interests with the goal of maximizing overall welfare in cross-silo FL.</p>
</div>
<div id="S5.SS2.p4" class="ltx_para">
<p id="S5.SS2.p4.1" class="ltx_p">Therefore, we discuss this problem in each category of DFL.</p>
</div>
<section id="S5.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.2.1. </span>TD-FL</h4>

<div id="S5.SS2.SSS1.p1" class="ltx_para">
<p id="S5.SS2.SSS1.p1.1" class="ltx_p">In this area, there is no study about incentive mechanisms. One of the reasons is that the challenge of the incentive mechanism in TD-FL revolves around encouraging active participation, ensuring fair compensation, and addressing privacy concerns among nodes in a decentralized network. Nodes must be motivated to contribute their computational resources willingly, despite potential free-riding. Only in IPLS <cite class="ltx_cite ltx_citemacro_citep">(Pappas et al<span class="ltx_text">.</span>, <a href="#bib.bib68" title="" class="ltx_ref">2021</a>)</cite> do the authors briefly introduce the fact that they want to incorporate an incentive mechanism like Flopcoin <cite class="ltx_cite ltx_citemacro_citep">(Chatzopoulos et al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2017</a>)</cite> to motivate mobile users to share their resources. In particular, this proposal follows the principles of the Hidden Market Design approach, granting users the ability to specify their resource contributions in the offloading system. The underlying algorithm, undisclosed to users, employs a truthful auction strategy and a peer-to-peer reputation exchange scheme.</p>
</div>
</section>
<section id="S5.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.2.2. </span>BC-FL</h4>

<div id="S5.SS2.SSS2.p1" class="ltx_para">
<p id="S5.SS2.SSS2.p1.1" class="ltx_p">In BC-FL there are some rewards for miners or devices, but they are based on the quality of the data <cite class="ltx_cite ltx_citemacro_citep">(Qu et al<span class="ltx_text">.</span>, <a href="#bib.bib76" title="" class="ltx_ref">2022</a>)</cite>. The participants have different computation power, and the contribution is dependent on the quality of data as well, so it is not really encouraging for all kinds of nodes. An intuitive idea is to reward participants according to their contributions, following the existing incentive mechanism designs for many other scenarios. Unfortunately, there are two main difficulties that make traditional incentive mechanisms unfit for FL. First, computing nodes do not share their decisions due to privacy concerns. Without the information of other nodes, it would be impossible for a participant to derive an optimal decision with close-form expression. Second, it is difficult to evaluate the contribution of participants to the accuracy of trained models. Pieces of evidence have shown that the relationship between model accuracy and the amount of training data is nonlinear. The model accuracy depends on the model complexity and data quality, and can hardly be predicted in advance. Without accurate evaluation of contributions, incentive mechanisms cannot correctively reward participants, leading to financial loss or a low participation rate.</p>
</div>
</section>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6. </span>Future Directions</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">In this section, we will outline potential future research directions aimed at addressing the two categories of challenges discussed above and enhancing existing solutions where applicable.</p>
<ul id="S6.I1" class="ltx_itemize">
<li id="S6.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i1.p1" class="ltx_para">
<p id="S6.I1.i1.p1.1" class="ltx_p"><span id="S6.I1.i1.p1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Security against Adversarial Attacks</span>:
In Blockchain-enabled FL systems, participants, including miners and users, are connected to the Blockchain. Consensus protocols select winners who collect and store transaction data (model updates) in Blockchain blocks. Trust management mechanisms can incentivize trustful operations and identify falsified data to prevent adversarial attacks. However, evolving attack nature presents new threats to Blockchain-enabled FL systems. Exploring distributed systems and defending them with robust aggregation algorithms or ad hoc consensus mechanisms is an intriguing area of research. In particular, ad hoc consensus mechanisms like DAG-Blockchain are not yet explored. According to this survey <cite class="ltx_cite ltx_citemacro_citep">(Ko et al<span class="ltx_text">.</span>, <a href="#bib.bib38" title="" class="ltx_ref">2023</a>)</cite> the term "DAG-based Blockchain" is used interchangeably with "DAG" or "DAG-based ledger". While DAG does not strictly conform to the linked list structure of traditional Blockchains, it is considered an extension of Blockchain, maintaining decentralization and ledger management through peer-to-peer connected nodes. The paper aims to compare DAG with Blockchain, emphasizing their shared functionality as decentralized ledgers. They also said that it is particularly suited for edge devices with limited hardware resources, as it does not require heavy computation resources for block mining like PoW-based Blockchains. This allows DAG to facilitate anomaly detection efficiently, as each node can validate its previous model parameter and compare its accuracy to send its own transaction without compromising performance.</p>
</div>
<div id="S6.I1.i1.p2" class="ltx_para">
<p id="S6.I1.i1.p2.1" class="ltx_p">Addressing improved model poisoning attacks, like <cite class="ltx_cite ltx_citemacro_citep">(Bagdasaryan et al<span class="ltx_text">.</span>, <a href="#bib.bib5" title="" class="ltx_ref">2020</a>)</cite>, also warrants attention. In most existing works based on Blockchain, the authors assert that poisoning attacks can be prevented through the verification mechanism of the Blockchain. However, in scenarios without transactions, data authentication becomes challenging as the data lacks causality. To address this issue on a Blockchain, a viable solution is to establish a trust management system. An intriguing area for further research involves creating a “hybrid” system that remains purely peer-to-peer (P2P) but incorporates certain characteristics suitable for non-transaction scenarios. An interesting experiment could involve building a TD-FL system and evaluating its performance compared to a BC-FL one. Especially, it is essential to initiate an analysis of a TD-FL system concerning various adversarial attacks and defenses. The survey <cite class="ltx_cite ltx_citemacro_citep">(Rodríguez-Barroso et al<span class="ltx_text">.</span>, <a href="#bib.bib79" title="" class="ltx_ref">2023</a>)</cite> delves into adversarial attacks like data poisoning, model poisoning, untargeted, targeted, and defenses such as robust aggregation, differential privacy, and SMC in centralized FL settings. Exploring these attacks and defenses in the context of TD-FL will hold significant importance. Furthermore, a future direction involves developing defenses (e.g., trust mechanism, anomaly detection) on P2P networks to counter Sybil attacks, insider vs. outsider attacks, and malicious attacks, as these are among the most prevalent attacks in a decentralized framework, as highlighted in the study by Nair et al. <cite class="ltx_cite ltx_citemacro_citep">(Nair et al<span class="ltx_text">.</span>, <a href="#bib.bib57" title="" class="ltx_ref">2023</a>)</cite>. Additionally, investigating the impact of a trust management system and its absence on the system’s effectiveness would be worthwhile. By exploring these aspects, we can better understand the advantages and drawbacks of different approaches in ensuring security and data integrity in DFL settings.</p>
</div>
</li>
<li id="S6.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i2.p1" class="ltx_para">
<p id="S6.I1.i2.p1.1" class="ltx_p"><span id="S6.I1.i2.p1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Incentive Mechanisms</span>:
The incentive mechanism used in traditional Blockchain systems, which involves distributing fixed rewards to winners, is not directly applicable to Blockchain-enabled FL due to varying computation power and data quality among participants. Introducing a new reward mechanism based on consensus participation could be beneficial. In a large-scale FL system, all devices aim to participate in the learning process to enhance their local models through collaboration, but significant differences exist in data quality and device capabilities. Since aggregating local updates requires substantial computation power, selecting devices with high-quality data and computation capabilities becomes crucial. While traditional PoW or PoS mechanisms are not perfectly feasible in this scenario, game theory offers a promising approach. Indeed, game theory can address intricate FL models, identifying equilibrium points like Nash equilibrium and Bayesian Nash equilibrium through non-cooperative and cooperative games. Coalition games foster teamwork among nodes, optimizing incentives and overall system performance. A survey <cite class="ltx_cite ltx_citemacro_citep">(Gupta and Gupta, <a href="#bib.bib26" title="" class="ltx_ref">2023</a>)</cite> explores the latest advancements in using game theory in Blockchain-based FL applications. Exploring this concept in traditional distributed FL systems might yield appealing insights worth investigating. Another survey <cite class="ltx_cite ltx_citemacro_citep">(Ihle et al<span class="ltx_text">.</span>, <a href="#bib.bib30" title="" class="ltx_ref">2023</a>)</cite> explores the incentive mechanisms in P2P networks; in particular, there are monetary (e.g., multiple currency economy like <cite class="ltx_cite ltx_citemacro_citep">(A., <a href="#bib.bib2" title="" class="ltx_ref">2004</a>)</cite>), auction (e.g., English auction, that maximizes the seller’s revenue by increasing the price until no bidder is willing to bid higher, a "marketplace" where peers accumulate points by providing data transmission services to others), deterministic (e.g., incentives pay out a fixed reward), reputation (e.g., observations are translated into a reputation value, which serves as a digital asset or metric indicating the likelihood of participants’ future actions, although it cannot be used to purchase goods or services directly), service (e.g., service that peers offer, like share-ratio <cite class="ltx_cite ltx_citemacro_citep">(Adamu, <a href="#bib.bib4" title="" class="ltx_ref">2021</a>)</cite>). The construction of a TD-FL system incorporating at least one of these types of incentive mechanisms would be worth pursuing.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7. </span>Conclusion</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">In recent years, <span id="S7.p1.1.1" class="ltx_text ltx_font_italic">federated learning</span> (FL) has gained popularity as a paradigm for training distributed, large-scale, and privacy-preserving machine learning systems. However, FL also faces several challenges.
One of the most critical issues is to overcome the centralized orchestration of the classical FL client-server architecture, which is vulnerable to single-point-of-failure risks. To address these concerns, <span id="S7.p1.1.2" class="ltx_text ltx_font_italic">decentralized</span> FL solutions (DFL) have emerged, allowing FL clients to cooperate and communicate without a central server.</p>
</div>
<div id="S7.p2" class="ltx_para">
<p id="S7.p2.1" class="ltx_p">This survey comprehensively summarizes and reviews existing DFL approaches proposed in the literature. Specifically, we scrutinized 112 research papers, 24 of which were selected for an in-depth analysis. We categorized existing approaches into two main categories: traditional distributed computing approaches (TD-FL) and Blockchain-based approaches (BC-FL). Furthermore, we identified two key challenges that affect DFL: security against adversarial attacks and the lack of an incentive mechanism to encourage participation in the federation.
Finally, we suggest several promising research directions for researchers and practitioners interested in exploring this emerging area of DFL to tackle the identified challenges.</p>
</div>
<div id="S7.p3" class="ltx_para">
<p id="S7.p3.1" class="ltx_p">We believe that this survey on DFL will serve as a valuable resource for researchers in the field, providing insights into the latest advancements, challenges, and potential directions for future research.
We hope that the findings presented here will inspire and guide other researchers in their endeavors to advance the field of DFL and address the pressing issues in this rapidly evolving area.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">        




</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">A. (2004)</span>
<span class="ltx_bibblock">
Turner D. A.
2004.

</span>
<span class="ltx_bibblock">A Lightweight Currency Paradigm for the P2P
Resource Market.

</span>
<span class="ltx_bibblock"><em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Proc. of Electronic Commerce Research</em>
(2004).

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://cir.nii.ac.jp/crid/1571417126210098048" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://cir.nii.ac.jp/crid/1571417126210098048</a>

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Abraham et al<span id="bib.bib3.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Ittai Abraham, Guy Gueta,
and Dahlia Malkhi. 2018.

</span>
<span class="ltx_bibblock">Hot-Stuff the Linear, Optimal-Resilience,
One-Message BFT Devil.

</span>
<span class="ltx_bibblock"><em id="bib.bib3.3.1" class="ltx_emph ltx_font_italic">CoRR</em> abs/1803.05069
(2018).

</span>
<span class="ltx_bibblock">arXiv:1803.05069

<a target="_blank" href="http://arxiv.org/abs/1803.05069" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/1803.05069</a>

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Adamu (2021)</span>
<span class="ltx_bibblock">
Aminu Adamu.
2021.

</span>
<span class="ltx_bibblock">Share-Ratio-Based Incentive Mechanism for File
Sharing With BitTorrent Protocol.

</span>
<span class="ltx_bibblock"><em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">IEEE Access</em> 9
(2021), 91524–91536.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bagdasaryan et al<span id="bib.bib5.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Eugene Bagdasaryan,
Andreas Veit, Yiqing Hua,
Deborah Estrin, and Vitaly Shmatikov.
2020.

</span>
<span class="ltx_bibblock">How To Backdoor Federated Learning. In
<em id="bib.bib5.3.1" class="ltx_emph ltx_font_italic">Proc. of AISTATS ’20</em>,
Silvia Chiappa and
Roberto Calandra (Eds.), Vol. 108.
PMLR, 2938–2948.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://proceedings.mlr.press/v108/bagdasaryan20a.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://proceedings.mlr.press/v108/bagdasaryan20a.html</a>

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Barkai (2000)</span>
<span class="ltx_bibblock">
David Barkai.
2000.

</span>
<span class="ltx_bibblock">An introduction to peer-to-peer computing.

</span>
<span class="ltx_bibblock"><em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">Intel Developer update magazine</em>
(2000), 1–7.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Baruch et al<span id="bib.bib7.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Gilad Baruch, Moran
Baruch, and Yoav Goldberg.
2019.

</span>
<span class="ltx_bibblock">A Little Is Enough: Circumventing Defenses for
Distributed Learning. In <em id="bib.bib7.3.1" class="ltx_emph ltx_font_italic">Proc. of NeurIPS ’19</em>.
8632–8642.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://proceedings.neurips.cc/paper/2019/hash/ec1c59141046cd1866bbbcdfb6ae31d4-Abstract.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://proceedings.neurips.cc/paper/2019/hash/ec1c59141046cd1866bbbcdfb6ae31d4-Abstract.html</a>

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bellet et al<span id="bib.bib8.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Aurélien Bellet, Rachid
Guerraoui, Mahsa Taziki, and Marc
Tommasi. 2018.

</span>
<span class="ltx_bibblock">Personalized and Private Peer-to-Peer Machine
Learning. In <em id="bib.bib8.3.1" class="ltx_emph ltx_font_italic">Proc. of AISTATS ’18</em>,
Amos Storkey and
Fernando Perez-Cruz (Eds.), Vol. 84.
PMLR, 473–481.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://proceedings.mlr.press/v84/bellet18a.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://proceedings.mlr.press/v84/bellet18a.html</a>

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Benet (2014)</span>
<span class="ltx_bibblock">
Juan Benet.
2014.

</span>
<span class="ltx_bibblock">IPFS - Content Addressed, Versioned, P2P File
System.

</span>
<span class="ltx_bibblock"><em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">CoRR</em> abs/1407.3561
(2014).

</span>
<span class="ltx_bibblock">arXiv:1407.3561

<a target="_blank" href="http://arxiv.org/abs/1407.3561" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/1407.3561</a>

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bhagoji et al<span id="bib.bib10.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Arjun Nitin Bhagoji,
Supriyo Chakraborty, Prateek Mittal,
and Seraphin Calo. 2019.

</span>
<span class="ltx_bibblock">Analyzing Federated Learning through an Adversarial
Lens. In <em id="bib.bib10.3.1" class="ltx_emph ltx_font_italic">Proc. of ICML</em>,
Kamalika Chaudhuri and
Ruslan Salakhutdinov (Eds.), Vol. 97.
PMLR, 634–643.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://proceedings.mlr.press/v97/bhagoji19a.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://proceedings.mlr.press/v97/bhagoji19a.html</a>

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">BitTorrent (2023)</span>
<span class="ltx_bibblock">
BitTorrent.
2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.bittorrent.com" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.bittorrent.com</a>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Blanchard et al<span id="bib.bib12.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Peva Blanchard, El Mahdi
El Mhamdi, Rachid Guerraoui, and Julien
Stainer. 2017.

</span>
<span class="ltx_bibblock">Machine Learning with Adversaries: Byzantine
Tolerant Gradient Descent. In <em id="bib.bib12.3.1" class="ltx_emph ltx_font_italic">Adv. in NeurIPS</em>,
I. Guyon, U. Von
Luxburg, S. Bengio, H. Wallach,
R. Fergus, S. Vishwanathan, and
R. Garnett (Eds.), Vol. 30.
Curran Associates, Inc.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://proceedings.neurips.cc/paper_files/paper/2017/file/f4b9ec30ad9f68f89b29639786cb62ef-Paper.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://proceedings.neurips.cc/paper_files/paper/2017/file/f4b9ec30ad9f68f89b29639786cb62ef-Paper.pdf</a>

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Buterin (2013)</span>
<span class="ltx_bibblock">
Vitalik Buterin.
2013.

</span>
<span class="ltx_bibblock">Ethereum White Paper: A Next Generation Smart
Contract &amp; Decentralized Application Platform.

</span>
<span class="ltx_bibblock">(2013).

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://github.com/ethereum/wiki/wiki/White-Paper" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/ethereum/wiki/wiki/White-Paper</a>

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chatzopoulos et al<span id="bib.bib14.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Dimitris Chatzopoulos,
Mahdieh Ahmadi, Sokol Kosta, and
Pan Hui. 2017.

</span>
<span class="ltx_bibblock">Flopcoin: A cryptocurrency for computation
offloading.

</span>
<span class="ltx_bibblock"><em id="bib.bib14.3.1" class="ltx_emph ltx_font_italic">IEEE Trans. Mob. Comput.</em>
17, 5 (2017),
1062–1075.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al<span id="bib.bib15.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Xuhui Chen, Jinlong Ji,
Changqing Luo, Weixian Liao, and
Pan Li. 2018.

</span>
<span class="ltx_bibblock">When Machine Learning Meets Blockchain: A
Decentralized, Privacy-preserving and Secure Design. In
<em id="bib.bib15.3.1" class="ltx_emph ltx_font_italic">IEEE Big Data</em>. 1178–1187.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/BigData.2018.8622598" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/BigData.2018.8622598</a>

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al<span id="bib.bib16.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Yiqiang Chen, Xin Qin,
Jindong Wang, Chaohui Yu, and
Wen Gao. 2020.

</span>
<span class="ltx_bibblock">FedHealth: A Federated Transfer Learning Framework
for Wearable Healthcare.

</span>
<span class="ltx_bibblock"><em id="bib.bib16.3.1" class="ltx_emph ltx_font_italic">IEEE Intell. Syst.</em> 35,
4 (2020), 83–93.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/MIS.2020.2988604" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/MIS.2020.2988604</a>

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Christen (2012)</span>
<span class="ltx_bibblock">
Peter Christen.
2012.

</span>
<span class="ltx_bibblock"><em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">Data Matching: Concepts and Techniques for
Record Linkage, Entity Resolution, and Duplicate Detection</em>.

</span>
<span class="ltx_bibblock">Springer Publishing Company, Incorporated.

</span>
<span class="ltx_bibblock">

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Costa et al<span id="bib.bib18.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Gabriele Costa, Fabio
Pinelli, Simone Soderi, and Gabriele
Tolomei. 2022.

</span>
<span class="ltx_bibblock">Turning Federated Learning Systems Into Covert
Channels.

</span>
<span class="ltx_bibblock"><em id="bib.bib18.3.1" class="ltx_emph ltx_font_italic">IEEE Access</em> 10
(2022), 130642–130656.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dwork and Roth (2014)</span>
<span class="ltx_bibblock">
Cynthia Dwork and Aaron
Roth. 2014.

</span>
<span class="ltx_bibblock">The Algorithmic Foundations of Differential
Privacy.

</span>
<span class="ltx_bibblock"><em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">Found. Trends Theor. Comput. Sci.</em>
9 (2014), 211–407.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fang et al<span id="bib.bib20.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Minghong Fang, Xiaoyu
Cao, Jinyuan Jia, and Neil Gong.
2020.

</span>
<span class="ltx_bibblock">Local Model Poisoning Attacks to Byzantine-Robust
Federated Learning. In <em id="bib.bib20.3.1" class="ltx_emph ltx_font_italic">Proc. of USENIX ’20</em>.
USENIX Association, 1605–1622.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Feng et al<span id="bib.bib21.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Lei Feng, Yiqi Zhao,
Shaoyong Guo, Xuesong Qiu,
Wenjing Li, and Peng Yu.
2022.

</span>
<span class="ltx_bibblock">BAFL: A Blockchain-Based Asynchronous Federated
Learning Framework.

</span>
<span class="ltx_bibblock"><em id="bib.bib21.3.1" class="ltx_emph ltx_font_italic">IEEE Trans. Comput.</em> 71,
5 (2022), 1092–1103.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/TC.2021.3072033" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/TC.2021.3072033</a>

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gholami et al<span id="bib.bib22.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Anousheh Gholami, Nariman
Torkzaban, and John S. Baras.
2022.

</span>
<span class="ltx_bibblock">Trusted Decentralized Federated Learning. In
<em id="bib.bib22.3.1" class="ltx_emph ltx_font_italic">IEEE CCNC</em>. 1–6.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/CCNC49033.2022.9700624" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/CCNC49033.2022.9700624</a>

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gilad et al<span id="bib.bib23.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Yossi Gilad, Rotem Hemo,
Silvio Micali, Georgios Vlachos, and
Nickolai Zeldovich. 2017.

</span>
<span class="ltx_bibblock">Algorand: Scaling Byzantine Agreements for
Cryptocurrencies. In <em id="bib.bib23.3.1" class="ltx_emph ltx_font_italic">Proc. of SOSP ’17</em>
(Shanghai, China). Association for Computing Machinery,
New York, NY, USA, 51–68.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3132747.3132757" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3132747.3132757</a>

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gnutella (2023)</span>
<span class="ltx_bibblock">
Gnutella. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://rfc-gnutella.sourceforge.net/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://rfc-gnutella.sourceforge.net/</a>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Goldreich (1999)</span>
<span class="ltx_bibblock">
Oded Goldreich.
1999.

</span>
<span class="ltx_bibblock">Secure Multi-Party Computation.

</span>
<span class="ltx_bibblock"><em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">Manuscript. Preliminary Version</em>
(03 1999).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gupta and Gupta (2023)</span>
<span class="ltx_bibblock">
Rajni Gupta and Juhi
Gupta. 2023.

</span>
<span class="ltx_bibblock">Federated learning using game strategies:
State-of-the-art and future trends.

</span>
<span class="ltx_bibblock"><em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">Computer Networks</em> 225
(2023), 109650.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1016/j.comnet.2023.109650" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1016/j.comnet.2023.109650</a>

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hardy et al<span id="bib.bib27.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Stephen Hardy, Wilko
Henecka, Hamish Ivey-Law, Richard
Nock, Giorgio Patrini, Guillaume Smith,
and Brian Thorne. 2017.

</span>
<span class="ltx_bibblock">Private federated learning on vertically
partitioned data via entity resolution and additively homomorphic
encryption.

</span>
<span class="ltx_bibblock"><em id="bib.bib27.3.1" class="ltx_emph ltx_font_italic">CoRR</em> abs/1711.10677
(2017).

</span>
<span class="ltx_bibblock">arXiv:1711.10677

<a target="_blank" href="http://arxiv.org/abs/1711.10677" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/1711.10677</a>

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et al<span id="bib.bib28.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Chenghao Hu, Jingyan
Jiang, and Zhi Wang. 2019.

</span>
<span class="ltx_bibblock">Decentralized Federated Learning: A Segmented Gossip
Approach.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:1908.07782 [cs.LG]

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et al<span id="bib.bib29.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Yifan Hu, Yuhang Zhou,
Jun Xiao, and Chao Wu.
2021.

</span>
<span class="ltx_bibblock">GFL: A Decentralized Federated Learning Framework
Based On Blockchain.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2010.10996 [cs.LG]

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ihle et al<span id="bib.bib30.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Cornelius Ihle, Dennis
Trautwein, Moritz Schubotz, Norman
Meuschke, and Bela Gipp.
2023.

</span>
<span class="ltx_bibblock">Peer-to-Peer Networks—A Systematic Literature
Review.

</span>
<span class="ltx_bibblock"><em id="bib.bib30.3.1" class="ltx_emph ltx_font_italic">ACM Comput. Surv</em> 56,
1 (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Isdal et al<span id="bib.bib31.2.2.1" class="ltx_text">.</span> (2010)</span>
<span class="ltx_bibblock">
Tomas Isdal, Michael
Piatek, Arvind Krishnamurthy, and
Thomas Anderson. 2010.

</span>
<span class="ltx_bibblock">Privacy-Preserving P2P Data Sharing with OneSwarm.
In <em id="bib.bib31.3.1" class="ltx_emph ltx_font_italic">Proc. of SIGCOMM ’10</em> (New Delhi, India).
Association for Computing Machinery,
New York, NY, USA, 111–122.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/1851182.1851198" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/1851182.1851198</a>

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jagielski et al<span id="bib.bib32.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Matthew Jagielski, Alina
Oprea, Battista Biggio, Chang Liu,
Cristina Nita-Rotaru, and Bo Li.
2018.

</span>
<span class="ltx_bibblock">Manipulating Machine Learning: Poisoning Attacks
and Countermeasures for Regression Learning. In
<em id="bib.bib32.3.1" class="ltx_emph ltx_font_italic">2018 IEEE Symposium on Security and Privacy (SP)</em>.
19–35.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/SP.2018.00057" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/SP.2018.00057</a>

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kairouz et al<span id="bib.bib33.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Peter Kairouz, H Brendan
McMahan, Brendan Avent, Aurélien
Bellet, Mehdi Bennis, Arjun Nitin
Bhagoji, Kallista Bonawitz, Zachary
Charles, Graham Cormode, Rachel
Cummings, et al<span id="bib.bib33.3.1" class="ltx_text">.</span> 2021.

</span>
<span class="ltx_bibblock">Advances and open problems in federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib33.4.1" class="ltx_emph ltx_font_italic">Foundations and Trends® in
Machine Learning</em> 14, 1–2
(2021), 1–210.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kalra et al<span id="bib.bib34.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Shivam Kalra, Junfeng
Wen, Jesse C Cresswell, Maksims Volkovs,
and HR Tizhoosh. 2023.

</span>
<span class="ltx_bibblock">Decentralized federated learning through proxy
model sharing.

</span>
<span class="ltx_bibblock"><em id="bib.bib34.3.1" class="ltx_emph ltx_font_italic">Nature Communications</em> 14,
1 (2023), 2899.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kang et al<span id="bib.bib35.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Jiawen Kang, Zehui Xiong,
Dusit Niyato, Han Yu,
Ying-Chang Liang, and Dong In Kim.
2019.

</span>
<span class="ltx_bibblock">Incentive Design for Efficient Federated Learning
in Mobile Networks: A Contract Theory Approach. In
<em id="bib.bib35.3.1" class="ltx_emph ltx_font_italic">2019 IEEE VTS Asia Pacific Wireless Communications
Symposium (APWCS)</em>. 1–5.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/VTS-APWCS.2019.8851649" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/VTS-APWCS.2019.8851649</a>

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kermarrec and Taiani (2015)</span>
<span class="ltx_bibblock">
Anne-Marie Kermarrec and
François Taiani. 2015.

</span>
<span class="ltx_bibblock">Want to scale in centralized systems? Think P2P.

</span>
<span class="ltx_bibblock"><em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">Journal of Internet Services and
Applications</em> 6 (08
2015).

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1186/s13174-015-0029-1" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1186/s13174-015-0029-1</a>

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim et al<span id="bib.bib37.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Hyesung Kim, Jihong Park,
Mehdi Bennis, and Seong-Lyun Kim.
2020.

</span>
<span class="ltx_bibblock">Blockchained On-Device Federated Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib37.3.1" class="ltx_emph ltx_font_italic">IEEE Communications Letters</em>
24, 6 (2020),
1279–1283.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/LCOMM.2019.2921755" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/LCOMM.2019.2921755</a>

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ko et al<span id="bib.bib38.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Seoyoung Ko, Keewoo Lee,
Hyunhum Cho, Yoonjae Hwang, and
Huisu Jang. 2023.

</span>
<span class="ltx_bibblock">Asynchronous federated learning with directed
acyclic graph-based blockchain in edge computing: Overview, design, and
challenges.

</span>
<span class="ltx_bibblock"><em id="bib.bib38.3.1" class="ltx_emph ltx_font_italic">Expert Systems with Applications</em>
(2023), 119896.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kumar et al<span id="bib.bib39.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Hemant H Kumar, Karthik
V R, and Mydhili K Nair.
2020.

</span>
<span class="ltx_bibblock">Federated K-Means Clustering: A Novel Edge AI Based
Approach for Privacy Preservation. In <em id="bib.bib39.3.1" class="ltx_emph ltx_font_italic">IEEE CCEM</em>.
52–56.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/CCEM50674.2020.00021" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/CCEM50674.2020.00021</a>

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lalitha (2018)</span>
<span class="ltx_bibblock">
Anusha Lalitha.
2018.

</span>
<span class="ltx_bibblock">Fully Decentralized Federated Learning.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lamping and Veach (2014)</span>
<span class="ltx_bibblock">
John Lamping and Eric
Veach. 2014.

</span>
<span class="ltx_bibblock">A Fast, Minimal Memory, Consistent Hash Algorithm.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:1406.2294 [cs.DS]

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib42.2.2.1" class="ltx_text">.</span> (2022a)</span>
<span class="ltx_bibblock">
Chengxi Li, Gang Li,
and Pramod K. Varshney.
2022a.

</span>
<span class="ltx_bibblock">Decentralized Federated Learning via Mutual
Knowledge Transfer.

</span>
<span class="ltx_bibblock"><em id="bib.bib42.3.1" class="ltx_emph ltx_font_italic">IEEE Internet of Things Journal</em>
9, 2 (2022),
1136–1147.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/JIOT.2021.3078543" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/JIOT.2021.3078543</a>

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib43.2.2.1" class="ltx_text">.</span> (2022c)</span>
<span class="ltx_bibblock">
Jun Li, Yumeng Shao,
Kang Wei, Ming Ding,
Chuan Ma, Long Shi, Zhu
Han, and H. Vincent Poor.
2022c.

</span>
<span class="ltx_bibblock">Blockchain Assisted Decentralized Federated
Learning (BLADE-FL): Performance Analysis and Resource Allocation.

</span>
<span class="ltx_bibblock"><em id="bib.bib43.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Parallel and Distributed
Systems</em> 33, 10 (2022),
2401–2415.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/TPDS.2021.3138848" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/TPDS.2021.3138848</a>

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib44.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Qinbin Li, Zeyi Wen,
and Bingsheng He. 2020.

</span>
<span class="ltx_bibblock">Practical Federated Gradient Boosting Decision
Trees.

</span>
<span class="ltx_bibblock"><em id="bib.bib44.3.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI Conference on
Artificial Intelligence</em> 34, 04
(Apr. 2020), 4642–4649.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1609/aaai.v34i04.5895" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1609/aaai.v34i04.5895</a>

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib45.2.2.1" class="ltx_text">.</span> (2010)</span>
<span class="ltx_bibblock">
Xiaohu Li, Peng Zhao,
and Linxiong Li. 2010.

</span>
<span class="ltx_bibblock">Resilience and reliability analysis of P2P network
systems.

</span>
<span class="ltx_bibblock"><em id="bib.bib45.3.1" class="ltx_emph ltx_font_italic">Operations Research Letters</em>
38, 1 (2010),
20–26.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1016/j.orl.2009.09.006" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1016/j.orl.2009.09.006</a>

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib46.2.2.1" class="ltx_text">.</span> (2021a)</span>
<span class="ltx_bibblock">
Yuzheng Li, Chuan Chen,
Nan Liu, Huawei Huang,
Zibin Zheng, and Qiang Yan.
2021a.

</span>
<span class="ltx_bibblock">A Blockchain-Based Decentralized Federated Learning
Framework with Committee Consensus.

</span>
<span class="ltx_bibblock"><em id="bib.bib46.3.1" class="ltx_emph ltx_font_italic">IEEE Network</em> 35,
1 (2021), 234–241.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/MNET.011.2000263" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/MNET.011.2000263</a>

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib47.2.2.1" class="ltx_text">.</span> (2022b)</span>
<span class="ltx_bibblock">
Zexi Li, Jiaxun Lu,
Shuang Luo, Didi Zhu,
Yunfeng Shao, Yinchuan Li,
Zhimeng Zhang, Yongheng Wang, and
Chao Wu. 2022b.

</span>
<span class="ltx_bibblock">Towards Effective Clustered Federated Learning: A
Peer-to-peer Framework with Adaptive Neighbor Matching.

</span>
<span class="ltx_bibblock"><em id="bib.bib47.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Big Data</em>
(2022), 1–16.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/TBDATA.2022.3222971" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/TBDATA.2022.3222971</a>

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib48.2.2.1" class="ltx_text">.</span> (2021b)</span>
<span class="ltx_bibblock">
Zonghang Li, Hongfang Yu,
Tianyao Zhou, Long Luo,
Mochan Fan, Zenglin Xu, and
Gang Sun. 2021b.

</span>
<span class="ltx_bibblock">Byzantine Resistant Secure Blockchained Federated
Learning at the Edge.

</span>
<span class="ltx_bibblock"><em id="bib.bib48.3.1" class="ltx_emph ltx_font_italic">IEEE Network</em> 35,
4 (2021), 295–301.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/MNET.011.2000604" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/MNET.011.2000604</a>

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al<span id="bib.bib49.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Xuefeng Liu, Gansen Zhao,
Xinming Wang, Yixing Lin,
Ziheng Zhou, Hua Tang, and
Bingchuan Chen. 2019.

</span>
<span class="ltx_bibblock">MDP-Based Quantitative Analysis Framework for Proof
of Authority.

</span>
<span class="ltx_bibblock"><em id="bib.bib49.3.1" class="ltx_emph ltx_font_italic">2019 International Conference on
Cyber-Enabled Distributed Computing and Knowledge Discovery (CyberC)</em>
(2019), 227–236.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al<span id="bib.bib50.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Yuan Liu, Shuai Sun,
Zhengpeng Ai, Shuangfeng Zhang,
Zelei Liu, and Han Yu.
2020.

</span>
<span class="ltx_bibblock">FedCoin: A Peer-to-Peer Payment System for Federated
Learning.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2002.11711 [cs.CR]

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lu and Fan (2020)</span>
<span class="ltx_bibblock">
Yanyang Lu and Lei
Fan. 2020.

</span>
<span class="ltx_bibblock">An efficient and robust aggregation algorithm for
learning federated cnn. In <em id="bib.bib51.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020
3rd International Conference on Signal Processing and Machine Learning</em>.
1–7.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ma et al<span id="bib.bib52.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Xiaodong Ma, Jia Zhu,
Zhihao Lin, Shanxuan Chen, and
Yangjie Qin. 2022.

</span>
<span class="ltx_bibblock">A State-of-the-Art Survey on Solving Non-IID Data
in Federated Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib52.3.1" class="ltx_emph ltx_font_italic">Future Generation Computer Systems</em>
135 (2022), 244–258.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1016/j.future.2022.05.003" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1016/j.future.2022.05.003</a>

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Marti and Garcia-Molina (2003)</span>
<span class="ltx_bibblock">
S. Marti and H.
Garcia-Molina. 2003.

</span>
<span class="ltx_bibblock">Identity crisis: anonymity vs reputation in P2P
systems. In <em id="bib.bib53.1.1" class="ltx_emph ltx_font_italic">Proceedings Third International
Conference on Peer-to-Peer Computing (P2P2003)</em>. 134–141.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/PTP.2003.1231513" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/PTP.2003.1231513</a>

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McMahan et al<span id="bib.bib54.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Brendan McMahan, Eider
Moore, Daniel Ramage, Seth Hampson,
and Blaise Aguera y Arcas.
2017.

</span>
<span class="ltx_bibblock">Communication-Efficient Learning of Deep Networks
from Decentralized Data. In <em id="bib.bib54.3.1" class="ltx_emph ltx_font_italic">Proc. of AISTATS
’17’</em>, Aarti Singh and
Jerry Zhu (Eds.), Vol. 54.
PMLR, 1273–1282.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://proceedings.mlr.press/v54/mcmahan17a.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://proceedings.mlr.press/v54/mcmahan17a.html</a>

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McMahan and Ramage (2017)</span>
<span class="ltx_bibblock">
Brendan McMahan and
Daniel Ramage. 2017.

</span>
<span class="ltx_bibblock">Federated learning: Collaborative machine learning
without centralized training data.

</span>
<span class="ltx_bibblock"><em id="bib.bib55.1.1" class="ltx_emph ltx_font_italic">Google Research Blog</em> 3
(2017).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Miller et al<span id="bib.bib56.2.2.1" class="ltx_text">.</span> (2014)</span>
<span class="ltx_bibblock">
Brad Miller, Alex
Kantchelian, Sadia Afroz, Rekha
Bachwani, Edwin Dauber, Ling Huang,
Michael Carl Tschantz, Anthony D. Joseph,
and J.D. Tygar. 2014.

</span>
<span class="ltx_bibblock">Adversarial Active Learning. In
<em id="bib.bib56.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2014 Workshop on Artificial
Intelligent and Security Workshop</em> (Scottsdale, Arizona, USA)
<em id="bib.bib56.4.2" class="ltx_emph ltx_font_italic">(AISec ’14)</em>. Association for
Computing Machinery, New York, NY, USA,
3–14.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/2666652.2666656" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/2666652.2666656</a>

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nair et al<span id="bib.bib57.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Akarsh K Nair, Ebin Deni
Raj, and Jayakrushna Sahoo.
2023.

</span>
<span class="ltx_bibblock">A robust analysis of adversarial attacks on
federated learning environments.

</span>
<span class="ltx_bibblock"><em id="bib.bib57.3.1" class="ltx_emph ltx_font_italic">Computer Standards &amp; Interfaces</em>
(2023), 103723.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nakamoto (2009)</span>
<span class="ltx_bibblock">
Satoshi Nakamoto.
2009.

</span>
<span class="ltx_bibblock">Bitcoin: A Peer-to-Peer Electronic Cash System.

</span>
<span class="ltx_bibblock">(May 2009).

</span>
<span class="ltx_bibblock">
<a target="_blank" href="http://www.bitcoin.org/bitcoin.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://www.bitcoin.org/bitcoin.pdf</a>

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Napster (2023)</span>
<span class="ltx_bibblock">
Napster. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.napster.com/it" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.napster.com/it</a>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nedic and Ozdaglar (2009)</span>
<span class="ltx_bibblock">
Angelia Nedic and Asuman
Ozdaglar. 2009.

</span>
<span class="ltx_bibblock">Distributed Subgradient Methods for Multi-Agent
Optimization.

</span>
<span class="ltx_bibblock"><em id="bib.bib60.1.1" class="ltx_emph ltx_font_italic">Automatic Control, IEEE Transactions on</em>
54 (02 2009),
48 – 61.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/TAC.2008.2009515" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/TAC.2008.2009515</a>

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nikolaenko et al<span id="bib.bib61.2.2.1" class="ltx_text">.</span> (2013)</span>
<span class="ltx_bibblock">
Valeria Nikolaenko, Udi
Weinsberg, Stratis Ioannidis, Marc Joye,
Dan Boneh, and Nina Taft.
2013.

</span>
<span class="ltx_bibblock">Privacy-Preserving Ridge Regression on Hundreds of
Millions of Records. In <em id="bib.bib61.3.1" class="ltx_emph ltx_font_italic">IEEE Symposium on Security
and Privacy</em>. 334–348.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nosowsky and Giordano (2006)</span>
<span class="ltx_bibblock">
Rachel Nosowsky and
Thomas J Giordano. 2006.

</span>
<span class="ltx_bibblock">The Health Insurance Portability and Accountability
Act of 1996 (HIPAA) privacy rule: implications for clinical research.

</span>
<span class="ltx_bibblock"><em id="bib.bib62.1.1" class="ltx_emph ltx_font_italic">Annu. Rev. Med.</em> 57
(2006), 575–590.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Onoszko et al<span id="bib.bib63.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Noa Onoszko, Gustav
Karlsson, Olof Mogren, and Edvin Listo
Zec. 2021.

</span>
<span class="ltx_bibblock">Decentralized federated learning of deep neural
networks on non-iid data.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2107.08517 [cs.LG]

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2023)</span>
<span class="ltx_bibblock">
OpenAI. 2023.

</span>
<span class="ltx_bibblock">GPT-4 Technical Report.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2303.08774 [cs.CL]

</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Oppenlaender (2022)</span>
<span class="ltx_bibblock">
Jonas Oppenlaender.
2022.

</span>
<span class="ltx_bibblock">The Creativity of Text-to-Image Generation. In
<em id="bib.bib65.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 25th International Academic
Mindtrek Conference</em>. ACM.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1145/3569219.3569352" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3569219.3569352</a>

</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Page et al<span id="bib.bib66.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Matthew J Page, Joanne E
McKenzie, Patrick M Bossuyt, Isabelle
Boutron, Tammy C Hoffmann, Cynthia D
Mulrow, Larissa Shamseer, Jennifer M
Tetzlaff, Elie A Akl, Sue E Brennan,
et al<span id="bib.bib66.3.1" class="ltx_text">.</span> 2021.

</span>
<span class="ltx_bibblock">The PRISMA 2020 statement: an updated guideline for
reporting systematic reviews.

</span>
<span class="ltx_bibblock"><em id="bib.bib66.4.1" class="ltx_emph ltx_font_italic">International journal of surgery</em>
88 (2021), 105906.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pan and Yang (2010)</span>
<span class="ltx_bibblock">
Sinno Jialin Pan and
Qiang Yang. 2010.

</span>
<span class="ltx_bibblock">A Survey on Transfer Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib67.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Knowledge and Data
Engineering</em> 22, 10
(2010), 1345–1359.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/TKDE.2009.191" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/TKDE.2009.191</a>

</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pappas et al<span id="bib.bib68.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Christodoulos Pappas,
Dimitris Chatzopoulos, Spyros Lalis,
and Manolis Vavalis. 2021.

</span>
<span class="ltx_bibblock">IPLS: A Framework for Decentralized Federated
Learning. In <em id="bib.bib68.3.1" class="ltx_emph ltx_font_italic">2021 IFIP Networking Conference (IFIP
Networking)</em>. 1–6.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.23919/IFIPNetworking52078.2021.9472790" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.23919/IFIPNetworking52078.2021.9472790</a>

</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Peng et al<span id="bib.bib69.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Zhe Peng, Jianliang Xu,
Xiaowen Chu, Shang Gao,
Yuan Yao, Rong Gu, and
Yuzhe Tang. 2022.

</span>
<span class="ltx_bibblock">VFChain: Enabling Verifiable and Auditable
Federated Learning via Blockchain Systems.

</span>
<span class="ltx_bibblock"><em id="bib.bib69.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Network Science and
Engineering</em> 9, 1
(2022), 173–186.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/TNSE.2021.3050781" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/TNSE.2021.3050781</a>

</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Phong et al<span id="bib.bib70.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Le Trieu Phong, Yoshinori
Aono, Takuya Hayashi, Lihua Wang, and
Shiho Moriai. 2018.

</span>
<span class="ltx_bibblock">Privacy-Preserving Deep Learning via Additively
Homomorphic Encryption.

</span>
<span class="ltx_bibblock"><em id="bib.bib70.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Information Forensics
and Security</em> 13, 5
(2018), 1333–1345.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/TIFS.2017.2787987" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/TIFS.2017.2787987</a>

</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pokhrel and Choi (2020)</span>
<span class="ltx_bibblock">
Shiva Raj Pokhrel and
Jinho Choi. 2020.

</span>
<span class="ltx_bibblock">A Decentralized Federated Learning Approach for
Connected Autonomous Vehicles. In <em id="bib.bib71.1.1" class="ltx_emph ltx_font_italic">2020 IEEE
Wireless Communications and Networking Conference Workshops (WCNCW)</em>.
1–6.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/WCNCW48565.2020.9124733" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/WCNCW48565.2020.9124733</a>

</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pouriyeh et al<span id="bib.bib72.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Seyedamin Pouriyeh, Osama
Shahid, Reza M. Parizi, Quan Z. Sheng,
Gautam Srivastava, Liang Zhao, and
Mohammad Nasajpour. 2022.

</span>
<span class="ltx_bibblock">Secure Smart Communication Efficiency in Federated
Learning: Achievements and Challenges.

</span>
<span class="ltx_bibblock"><em id="bib.bib72.3.1" class="ltx_emph ltx_font_italic">Applied Sciences</em> 12,
18 (2022).

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.3390/app12188980" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.3390/app12188980</a>

</span>
</li>
<li id="bib.bib73" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pretre (2005)</span>
<span class="ltx_bibblock">
Baptiste Pretre.
2005.

</span>
<span class="ltx_bibblock">Attacks on peer-to-peer networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib73.1.1" class="ltx_emph ltx_font_italic">Dept. of Computer Science Swiss Federal
Institute of Technology (ETH) Zurich Autumn</em> (2005).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib74" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qu et al<span id="bib.bib74.2.2.1" class="ltx_text">.</span> (2021b)</span>
<span class="ltx_bibblock">
Xidi Qu, Shengling Wang,
Qin Hu, and Xiuzhen Cheng.
2021b.

</span>
<span class="ltx_bibblock">Proof of Federated Learning: A Novel
Energy-Recycling Consensus Algorithm.

</span>
<span class="ltx_bibblock"><em id="bib.bib74.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Parallel and Distributed
Systems</em> 32, 8 (2021),
2074–2085.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/TPDS.2021.3056773" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/TPDS.2021.3056773</a>

</span>
</li>
<li id="bib.bib75" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qu et al<span id="bib.bib75.2.2.1" class="ltx_text">.</span> (2021a)</span>
<span class="ltx_bibblock">
Yuben Qu, Haipeng Dai,
Yan Zhuang, Jiafa Chen,
Chao Dong, Fan Wu, and
Song Guo. 2021a.

</span>
<span class="ltx_bibblock">Decentralized Federated Learning for UAV Networks:
Architecture, Challenges, and Opportunities.

</span>
<span class="ltx_bibblock"><em id="bib.bib75.3.1" class="ltx_emph ltx_font_italic">IEEE Network</em> 35,
6 (2021), 156–162.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/MNET.001.2100253" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/MNET.001.2100253</a>

</span>
</li>
<li id="bib.bib76" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qu et al<span id="bib.bib76.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Youyang Qu, Md Palash
Uddin, Chenquan Gan, Yong Xiang,
Longxiang Gao, and John Yearwood.
2022.

</span>
<span class="ltx_bibblock">Blockchain-Enabled Federated Learning: A Survey.

</span>
<span class="ltx_bibblock"><em id="bib.bib76.3.1" class="ltx_emph ltx_font_italic">ACM Comput. Surv.</em> 55,
4, Article 70 (nov
2022), 35 pages.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3524104" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3524104</a>

</span>
</li>
<li id="bib.bib77" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ram et al<span id="bib.bib77.2.2.1" class="ltx_text">.</span> (2010)</span>
<span class="ltx_bibblock">
S. Ram, Angelia Nedic,
and V. Veeravalli. 2010.

</span>
<span class="ltx_bibblock">Distributed Stochastic Subgradient Projection
Algorithms for Convex Optimization.

</span>
<span class="ltx_bibblock"><em id="bib.bib77.3.1" class="ltx_emph ltx_font_italic">Journal of Optimization Theory and
Applications</em> 147 (12
2010), 516–545.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1007/s10957-010-9737-7" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1007/s10957-010-9737-7</a>

</span>
</li>
<li id="bib.bib78" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ramesh et al<span id="bib.bib78.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Aditya Ramesh, Prafulla
Dhariwal, Alex Nichol, Casey Chu, and
Mark Chen. 2022.

</span>
<span class="ltx_bibblock">Hierarchical Text-Conditional Image Generation with
CLIP Latents.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2204.06125 [cs.CV]

</span>
</li>
<li id="bib.bib79" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rodríguez-Barroso et al<span id="bib.bib79.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Nuria Rodríguez-Barroso,
Daniel Jiménez-López, M Victoria
Luzón, Francisco Herrera, and
Eugenio Martínez-Cámara.
2023.

</span>
<span class="ltx_bibblock">Survey on federated learning threats: Concepts,
taxonomy on attacks and defences, experimental study and challenges.

</span>
<span class="ltx_bibblock"><em id="bib.bib79.3.1" class="ltx_emph ltx_font_italic">Information Fusion</em> 90
(2023), 148–173.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib80" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Roussopoulos et al<span id="bib.bib80.2.2.1" class="ltx_text">.</span> (2003)</span>
<span class="ltx_bibblock">
Mema Roussopoulos, Mary
Baker, David S. H. Rosenthal, Thomas J.
Giuli, Petros Maniatis, and Jeffrey C.
Mogul. 2003.

</span>
<span class="ltx_bibblock">2 P2P or Not 2 P2P?. In
<em id="bib.bib80.3.1" class="ltx_emph ltx_font_italic">International Workshop on Peer-to-Peer Systems</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib81" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Roy et al<span id="bib.bib81.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Abhijit Guha Roy, Shayan
Siddiqui, Sebastian Pölsterl,
Nassir Navab, and Christian Wachinger.
2019.

</span>
<span class="ltx_bibblock">BrainTorrent: A Peer-to-Peer Environment for
Decentralized Federated Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib81.3.1" class="ltx_emph ltx_font_italic">CoRR</em> abs/1905.06731
(2019).

</span>
<span class="ltx_bibblock">arXiv:1905.06731

<a target="_blank" href="http://arxiv.org/abs/1905.06731" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/1905.06731</a>

</span>
</li>
<li id="bib.bib82" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Seide et al<span id="bib.bib82.2.2.1" class="ltx_text">.</span> (2014)</span>
<span class="ltx_bibblock">
Frank Seide, Hao Fu,
Jasha Droppo, Gang Li, and
Dong Yu. 2014.

</span>
<span class="ltx_bibblock">1-bit stochastic gradient descent and its
application to data-parallel distributed training of speech DNNs. In
<em id="bib.bib82.3.1" class="ltx_emph ltx_font_italic">Interspeech</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib83" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shayan et al<span id="bib.bib83.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Muhammad Shayan, Clement
Fung, Chris J. M. Yoon, and Ivan
Beschastnikh. 2021.

</span>
<span class="ltx_bibblock">Biscotti: A Blockchain System for Private and
Secure Federated Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib83.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Parallel and Distributed
Systems</em> 32, 7 (2021),
1513–1525.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/TPDS.2020.3044223" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/TPDS.2020.3044223</a>

</span>
</li>
<li id="bib.bib84" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Skype (2023)</span>
<span class="ltx_bibblock">
Skype. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.skype.com" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.skype.com</a>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib85" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tang and Wong (2021)</span>
<span class="ltx_bibblock">
Ming Tang and Vincent WS
Wong. 2021.

</span>
<span class="ltx_bibblock">An incentive mechanism for cross-silo federated
learning: A public goods perspective. In <em id="bib.bib85.1.1" class="ltx_emph ltx_font_italic">IEEE
INFOCOM 2021-IEEE Conference on Computer Communications</em>. IEEE,
1–10.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib86" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tang et al<span id="bib.bib86.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Zhenheng Tang, Shaohuai
Shi, Bo Li, and Xiaowen Chu.
2023.

</span>
<span class="ltx_bibblock">GossipFL: A Decentralized Federated Learning
Framework With Sparsified and Adaptive Communication.

</span>
<span class="ltx_bibblock"><em id="bib.bib86.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Parallel and Distributed
Systems</em> 34, 3 (2023),
909–922.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/TPDS.2022.3230938" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/TPDS.2022.3230938</a>

</span>
</li>
<li id="bib.bib87" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tikkinen-Piri et al<span id="bib.bib87.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Christina Tikkinen-Piri,
Anna Rohunen, and Jouni Markkula.
2018.

</span>
<span class="ltx_bibblock">EU General Data Protection Regulation: Changes and
implications for personal data collecting companies.

</span>
<span class="ltx_bibblock"><em id="bib.bib87.3.1" class="ltx_emph ltx_font_italic">Computer Law &amp; Security Review</em>
34, 1 (2018),
134–153.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib88" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tolomei et al<span id="bib.bib88.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Gabriele Tolomei, Edoardo
Gabrielli, Dimitri Belli, and Vittorio
Miori. 2023.

</span>
<span class="ltx_bibblock">A Byzantine-Resilient Aggregation Scheme for
Federated Learning via Matrix Autoregression on Client Updates.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2303.16668

</span>
</li>
<li id="bib.bib89" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span id="bib.bib89.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Hongyi Wang, Scott
Sievert, Zachary Charles, Shengchao Liu,
Stephen Wright, and Dimitris
Papailiopoulos. 2018.

</span>
<span class="ltx_bibblock">ATOMO: Communication-Efficient Learning via Atomic
Sparsification. In <em id="bib.bib89.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 32nd
International Conference on Neural Information Processing Systems</em>
(Montréal, Canada) <em id="bib.bib89.4.2" class="ltx_emph ltx_font_italic">(NIPS’18)</em>.
Curran Associates Inc., Red Hook, NY,
USA, 9872–9883.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib90" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span id="bib.bib90.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Xinghan Wang, Anusha
Lalitha, Tara Javidi, and Farinaz
Koushanfar. 2022.

</span>
<span class="ltx_bibblock">Peer-to-Peer Variational Federated Learning Over
Arbitrary Graphs.

</span>
<span class="ltx_bibblock"><em id="bib.bib90.3.1" class="ltx_emph ltx_font_italic">IEEE Journal on Selected Areas in Information
Theory</em> 3, 2 (2022),
172–182.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/JSAIT.2022.3189051" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/JSAIT.2022.3189051</a>

</span>
</li>
<li id="bib.bib91" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Weng et al<span id="bib.bib91.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Jiasi Weng, Jian Weng,
Jilian Zhang, Ming Li,
Yue Zhang, and Weiqi Luo.
2021.

</span>
<span class="ltx_bibblock">DeepChain: Auditable and Privacy-Preserving Deep
Learning with Blockchain-Based Incentive.

</span>
<span class="ltx_bibblock"><em id="bib.bib91.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Dependable and Secure
Computing</em> 18, 5 (2021),
2438–2455.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/TDSC.2019.2952332" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/TDSC.2019.2952332</a>

</span>
</li>
<li id="bib.bib92" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al<span id="bib.bib92.2.2.1" class="ltx_text">.</span> (2020a)</span>
<span class="ltx_bibblock">
Qiong Wu, Kaiwen He,
and Xu Chen. 2020a.

</span>
<span class="ltx_bibblock">Personalized Federated Learning for Intelligent IoT
Applications: A Cloud-Edge Based Framework.

</span>
<span class="ltx_bibblock"><em id="bib.bib92.3.1" class="ltx_emph ltx_font_italic">IEEE Open Journal of the Computer Society</em>
1 (2020), 35–44.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/OJCS.2020.2993259" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/OJCS.2020.2993259</a>

</span>
</li>
<li id="bib.bib93" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al<span id="bib.bib93.2.2.1" class="ltx_text">.</span> (2020b)</span>
<span class="ltx_bibblock">
Xin Wu, Zhi Wang,
Jian Zhao, Yan Zhang, and
Yu Wu. 2020b.

</span>
<span class="ltx_bibblock">FedBC: Blockchain-based Decentralized Federated
Learning. In <em id="bib.bib93.3.1" class="ltx_emph ltx_font_italic">Proc. of ICAICA ’20</em>.
IEEE, 217–221.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/ICAICA50127.2020.9182705" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/ICAICA50127.2020.9182705</a>

</span>
</li>
<li id="bib.bib94" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yaga et al<span id="bib.bib94.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Dylan Yaga, Peter Mell,
Nik Roby, and Karen Scarfone.
2018.

</span>
<span class="ltx_bibblock">Blockchain Technology Overview.

</span>
<span class="ltx_bibblock"><em id="bib.bib94.3.1" class="ltx_emph ltx_font_italic">ArXiv</em> abs/1906.11078
(2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib95" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al<span id="bib.bib95.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Qiang Yang, Yang Liu,
Tianjian Chen, and Yongxin Tong.
2019.

</span>
<span class="ltx_bibblock">Federated Machine Learning: Concept and
Applications.

</span>
<span class="ltx_bibblock">10, 2, Article
12 (jan 2019),
19 pages.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3298981" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3298981</a>

</span>
</li>
<li id="bib.bib96" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al<span id="bib.bib96.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Wenti Yang, Naiyu Wang,
Zhitao Guan, Longfei Wu,
Xiaojiang Du, and Mohsen Guizani.
2022.

</span>
<span class="ltx_bibblock">A practical cross-device federated learning
framework over 5G networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib96.3.1" class="ltx_emph ltx_font_italic">IEEE Wireless Communications</em>
29, 6 (2022),
128–134.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib97" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al<span id="bib.bib97.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Zhanpeng Yang, Yuanming
Shi, Yong Zhou, Zixin Wang, and
Kai Yang. 2023.

</span>
<span class="ltx_bibblock">Trustworthy Federated Learning via Blockchain.

</span>
<span class="ltx_bibblock"><em id="bib.bib97.3.1" class="ltx_emph ltx_font_italic">IEEE Internet of Things Journal</em>
10, 1 (2023),
92–109.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/JIOT.2022.3201117" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/JIOT.2022.3201117</a>

</span>
</li>
<li id="bib.bib98" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al<span id="bib.bib98.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Bin Yu, Joseph Liu,
Surya Nepal, Jiangshan Yu, and
Paul Rimba. 2019.

</span>
<span class="ltx_bibblock">Proof-of-QoS: QoS Based Blockchain Consensus
Protocol.

</span>
<span class="ltx_bibblock"><em id="bib.bib98.3.1" class="ltx_emph ltx_font_italic">Computers &amp; Security</em> 87
(07 2019), 101580.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1016/j.cose.2019.101580" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1016/j.cose.2019.101580</a>

</span>
</li>
<li id="bib.bib99" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yuan and Yu (2014)</span>
<span class="ltx_bibblock">
Jiawei Yuan and Shucheng
Yu. 2014.

</span>
<span class="ltx_bibblock">Privacy Preserving Back-Propagation Neural Network
Learning Made Practical with Cloud Computing.

</span>
<span class="ltx_bibblock"><em id="bib.bib99.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Parallel and Distributed
Systems</em> 25, 1 (2014),
212–221.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/TPDS.2013.18" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/TPDS.2013.18</a>

</span>
</li>
<li id="bib.bib100" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span id="bib.bib100.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Hantian Zhang, Jerry Li,
Kaan Kara, Dan Alistarh,
Ji Liu, and Ce Zhang.
2017.

</span>
<span class="ltx_bibblock">ZipML: Training Linear Models with End-to-End Low
Precision, and a Little Bit of Deep Learning. In
<em id="bib.bib100.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 34th International Conference on
Machine Learning - Volume 70</em> (Sydney, NSW, Australia)
<em id="bib.bib100.4.2" class="ltx_emph ltx_font_italic">(ICML’17)</em>. JMLR.org,
4035–4043.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib101" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al<span id="bib.bib101.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Jiaqi Zhao, Hui Zhu,
Fengwei Wang, Rongxing Lu,
Zhe Liu, and Hui Li.
2022.

</span>
<span class="ltx_bibblock">PVD-FL: A Privacy-Preserving and Verifiable
Decentralized Federated Learning Framework.

</span>
<span class="ltx_bibblock"><em id="bib.bib101.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Information Forensics
and Security</em> 17 (2022),
2059–2073.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/TIFS.2022.3176191" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/TIFS.2022.3176191</a>

</span>
</li>
<li id="bib.bib102" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al<span id="bib.bib102.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Yue Zhao, Meng Li,
Liangzhen Lai, Naveen Suda,
Damon Civin, and Vikas Chandra.
2018.

</span>
<span class="ltx_bibblock">Federated Learning with Non-IID Data.

</span>
<span class="ltx_bibblock">(2018).

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/ARXIV.1806.00582" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/ARXIV.1806.00582</a>

</span>
</li>
<li id="bib.bib103" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al<span id="bib.bib103.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Yang Zhao, Jun Zhao,
Linshan Jiang, Rui Tan,
Dusit Niyato, Zengxiang Li,
Lingjuan Lyu, and Yingbo Liu.
2021.

</span>
<span class="ltx_bibblock">Privacy-Preserving Blockchain-Based Federated
Learning for IoT Devices.

</span>
<span class="ltx_bibblock"><em id="bib.bib103.3.1" class="ltx_emph ltx_font_italic">IEEE Internet of Things Journal</em>
8, 3 (2021),
1817–1829.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/JIOT.2020.3017377" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/JIOT.2020.3017377</a>

</span>
</li>
<li id="bib.bib104" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et al<span id="bib.bib104.2.2.1" class="ltx_text">.</span> (2019b)</span>
<span class="ltx_bibblock">
Amelie Chi Zhou, Yao
Xiao, Yifan Gong, Bingsheng He,
Jidong Zhai, and Rui Mao.
2019b.

</span>
<span class="ltx_bibblock">Privacy Regulation Aware Process Mapping in
Geo-Distributed Cloud Data Centers.

</span>
<span class="ltx_bibblock"><em id="bib.bib104.3.1" class="ltx_emph ltx_font_italic">IEEE Trans. Parallel Distributed Syst.</em>
30, 8 (2019),
1872–1888.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/TPDS.2019.2896894" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/TPDS.2019.2896894</a>

</span>
</li>
<li id="bib.bib105" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et al<span id="bib.bib105.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Chunyi Zhou, Anmin Fu,
Shui Yu, Wei Yang,
Huaqun Wang, and Yuqing Zhang.
2020.

</span>
<span class="ltx_bibblock">Privacy-Preserving Federated Learning in Fog
Computing.

</span>
<span class="ltx_bibblock"><em id="bib.bib105.3.1" class="ltx_emph ltx_font_italic">IEEE Internet of Things Journal</em>
7, 11 (2020),
10782–10793.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/JIOT.2020.2987958" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/JIOT.2020.2987958</a>

</span>
</li>
<li id="bib.bib106" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et al<span id="bib.bib106.2.2.1" class="ltx_text">.</span> (2019a)</span>
<span class="ltx_bibblock">
Sicong Zhou, Huawei
Huang, Wuhui Chen, Zibin Zheng, and
Song Guo. 2019a.

</span>
<span class="ltx_bibblock">PIRATE: A Blockchain-based Secure Framework of
Distributed Machine Learning in 5G Networks.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:1912.07860 [cs.DC]

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2308.04603" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2308.04604" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2308.04604">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2308.04604" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2308.04605" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Wed Feb 28 13:16:43 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
