<article class="ltx_document ltx_authors_1line">
 <h1 class="ltx_title ltx_font_bold ltx_title_document" style="font-size:173%;">
  From LLMs to Actions: Latent Codes as Bridges in
  <br class="ltx_break"/>
  Hierarchical Robot Control
 </h1>
 <div class="ltx_authors">
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Yide Shentu
    <sup class="ltx_sup" id="id3.3.id1">
     <span class="ltx_text ltx_font_italic" id="id3.3.id1.1">
      ∗
     </span>
    </sup>
    Philipp Wu
    <sup class="ltx_sup" id="id4.4.id2">
     <span class="ltx_text ltx_font_italic" id="id4.4.id2.1">
      ∗
     </span>
    </sup>
    Aravind Rajeswaran   Pieter Abbeel
    <br class="ltx_break"/>
    *Equal contribution
    <br class="ltx_break"/>
    University of California, Berkeley
   </span>
  </span>
 </div>
 <div class="ltx_abstract">
  <h6 class="ltx_title ltx_title_abstract">
   Abstract
  </h6>
  <p class="ltx_p" id="id5.id1">
   Hierarchical control for robotics has long been plagued by the need to have a well defined interface layer to communicate between high-level task planners and low-level policies. With the advent of LLMs, language has been emerging as a prospective interface layer. However, this has several limitations. Not all tasks can be decomposed into steps that are easily expressible in natural language (e.g. performing a dance routine). Further, it makes end-to-end finetuning on embodied data challenging due to domain shift and catastrophic forgetting. We introduce our method – Learnable Latent Codes as Bridges (LCB) – as an alternate architecture to overcome these limitations.
   <span class="ltx_text ltx_font_typewriter" id="id5.id1.1">
    LCB
   </span>
   uses a learnable latent code to act as a bridge between LLMs and low-level policies. This enables LLMs to flexibly communicate goals in the task plan without being entirely constrained by language limitations. Additionally, it enables end-to-end finetuning without destroying the embedding space of word tokens learned during pre-training. Through experiments on Language Table and Calvin, two common language based benchmarks for embodied agents, we find that
   <span class="ltx_text ltx_font_typewriter" id="id5.id1.2">
    LCB
   </span>
   outperforms baselines (including those w/ GPT-4V) that leverage pure language as the interface layer on tasks that require reasoning and multi-step behaviors.
  </p>
 </div>
 <section class="ltx_section" id="S1">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    I
   </span>
   <span class="ltx_text ltx_font_smallcaps" id="S1.1.1">
    INTRODUCTION
   </span>
  </h2>
  <div class="ltx_para" id="S1.p1">
   <p class="ltx_p" id="S1.p1.1">
    The field of robotics has long oscillated between two predominant architectural paradigms for enabling agents to solve complex tasks. At one end of the spectrum, we have seen
    <span class="ltx_text ltx_font_bold" id="S1.p1.1.1">
     modular hierarchical policies
    </span>
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib2" title="">
      2
     </a>
     ]
    </cite>
    for control that leverage rigid layers like symbolic planning, trajectory generation, and tracking. On the other end are
    <span class="ltx_text ltx_font_bold" id="S1.p1.1.2">
     end-to-end policies
    </span>
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib3" title="">
      3
     </a>
     ]
    </cite>
    that directly map sensory observations to actions through high-capacity neural networks. This dynamic history reflects the ongoing quest to reconcile the logical human-like reasoning with the flexible dexterity of human motor control.
   </p>
  </div>
  <div class="ltx_para" id="S1.p2">
   <p class="ltx_p" id="S1.p2.1">
    The advent of
    <span class="ltx_text ltx_font_italic" id="S1.p2.1.1">
     large language models
    </span>
    (LLMs)
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib4" title="">
      4
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib5" title="">
      5
     </a>
     ]
    </cite>
    and their remarkable language interpretation and reasoning capabilities have reignited interest in hierarchical control architectures. Recent works
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib6" title="">
      6
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib7" title="">
      7
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib8" title="">
      8
     </a>
     ]
    </cite>
    have leveraged LLMs and
    <span class="ltx_text ltx_font_italic" id="S1.p2.1.2">
     Multimodal Large Language Model
    </span>
    (abbreviated as LLM in this paper unless specified otherwise) in place of high-level symbolic planners, enabling impressive results like mobile rearrangement of objects based on open-vocabulary instructions. Despite these advances, the core deficiencies of hierarchical architectures remain – namely the need for a set of clearly defined control primitives and an interface between layers in the hierarchy. For example, LLMs leverage the semantic meaning of action verbs to coordinate low-level primitives like
    <span class="ltx_text ltx_font_italic" id="S1.p2.1.3">
     go-to
    </span>
    ,
    <span class="ltx_text ltx_font_italic" id="S1.p2.1.4">
     pick
    </span>
    ,
    <span class="ltx_text ltx_font_italic" id="S1.p2.1.5">
     place
    </span>
    etc. However, we humans perform a variety of movements with our body that contribute to our dexterity and daily function, yet
    <span class="ltx_text ltx_font_bold" id="S1.p2.1.6">
     cannot be easily described using language.
    </span>
   </p>
  </div>
  <div class="ltx_para" id="S1.p3">
   <p class="ltx_p" id="S1.p3.1">
    In this backdrop, we present
    <span class="ltx_text ltx_font_bold" id="S1.p3.1.1">
     L
    </span>
    atent
    <span class="ltx_text ltx_font_bold" id="S1.p3.1.2">
     C
    </span>
    odes as
    <span class="ltx_text ltx_font_bold" id="S1.p3.1.3">
     B
    </span>
    ridges, or
    <span class="ltx_text ltx_font_typewriter" id="S1.p3.1.4">
     LCB
    </span>
    , a new policy architecture for control that combines the benefits of modular hierarchical architectures with end-to-end learning (see Fig.
    <span class="ltx_ref ltx_missing_label ltx_ref_self">
     LABEL:fig:teaser
    </span>
    for an illustration). Specifically, not only can
    <span class="ltx_text ltx_font_typewriter" id="S1.p3.1.5">
     LCB
    </span>
    directly leverage LLMs for high-level reasoning and pre-trained skills/policies for low-level control, but it can also improve these components with end-to-end learning to transcend their initial capabilities.
This is achieved by learning an
    <span class="ltx_text ltx_font_typewriter" id="S1.p3.1.6">
     &lt;ACT&gt;
    </span>
    token at the interface layer which can modulate the low-level policies. As a result of this choice,
    <span class="ltx_text ltx_font_typewriter" id="S1.p3.1.7">
     LCB
    </span>
    can overcome the inherent limitations of solely relying on language as the interface layer, since several behaviors are hard to describe in language. Secondly, by leveraging a separate
    <span class="ltx_text ltx_font_typewriter" id="S1.p3.1.8">
     &lt;ACT&gt;
    </span>
    token, we do not destroy the core language generation and reasoning capabilities of the LLM during finetuning.
We test
    <span class="ltx_text ltx_font_typewriter" id="S1.p3.1.9">
     LCB
    </span>
    on a series of long-horizon and reasoning tasks in Language Table
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib9" title="">
      9
     </a>
     ]
    </cite>
    and Calvin
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib10" title="">
      10
     </a>
     ]
    </cite>
    , two common language based benchmarks for embodied agents. We find that
    <span class="ltx_text ltx_font_typewriter" id="S1.p3.1.10">
     LCB
    </span>
    considerably outperforms baselines that leverage LLMs to sequence low-level skills using pure language as the interface layer. See our
    <a class="ltx_ref ltx_href" href="https://fredshentu.github.io/LCB_site" target="_blank" title="">
     website
    </a>
    for more.
   </p>
  </div>
 </section>
 <section class="ltx_section" id="S2">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    II
   </span>
   <span class="ltx_text ltx_font_smallcaps" id="S2.1.1">
    RELATED WORK
   </span>
  </h2>
  <div class="ltx_para ltx_noindent" id="S2.p1">
   <p class="ltx_p" id="S2.p1.1">
    <span class="ltx_text ltx_font_bold" id="S2.p1.1.1">
     Hierarchical Control with LLMs
    </span>
    The proliferation of LLM technology, coupled with their capability to interpret user prompts and perform reasoning, has led to growing interest in utilizing LLMs for robotics
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib11" title="">
      11
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib12" title="">
      12
     </a>
     ]
    </cite>
    . Of particular notice and relevance are the use of LLMs for high-level reasoning in hierarchical control architectures. Prior work has demonstrated this by leveraging the few-shot prompt capabilities of LLMs
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib7" title="">
      7
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib6" title="">
      6
     </a>
     ]
    </cite>
    , their ability to code and compose functions
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib8" title="">
      8
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib13" title="">
      13
     </a>
     ]
    </cite>
    , or their ability to interact with human users through language
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib14" title="">
      14
     </a>
     ]
    </cite>
    . In contrast to these works that attempt to use LLMs “as-is” and compose low-level skills, our work performs end-to-end fine-tuning through learnable latent codes. This includes finetuning some layers of the LLM through LoRA
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib15" title="">
      15
     </a>
     ]
    </cite>
    . Empirically we show that such finetuning can outperform methods that use LLMs out-of-the-box.
   </p>
  </div>
  <div class="ltx_para ltx_noindent" id="S2.p2">
   <p class="ltx_p" id="S2.p2.1">
    <span class="ltx_text ltx_font_bold" id="S2.p2.1.1">
     Language Conditioned Imitation Learning
    </span>
    To leverage LLMs for task planning and reasoning, such models need to be able to call lower-level skills to affect change in the environment. This can be achieve in two ways: (a) by leveraging
    <span class="ltx_text ltx_font_italic" id="S2.p2.1.2">
     semantics
    </span>
    of the skills through language descriptions (e.g.
    <span class="ltx_text ltx_font_typewriter" id="S2.p2.1.3">
     go-to
    </span>
    ,
    <span class="ltx_text ltx_font_typewriter" id="S2.p2.1.4">
     reach
    </span>
    etc.) as described above; or alternatively (b) through language conditioned policies which accept a text description as input to directly produce an action
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib9" title="">
      9
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib16" title="">
      16
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib1" title="">
      1
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib17" title="">
      17
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib18" title="">
      18
     </a>
     ]
    </cite>
    . Such policies can typically perform only short horizon tasks and lack the reasoning and planning capabilities often found in LLMs. Our goal in this work is to leverage such “simple” or “primitive” language-conditioned policies along with LLMs to enable a hierarchical system to perform complex tasks that require multi-step planning and reasoning.
   </p>
  </div>
  <div class="ltx_para ltx_noindent" id="S2.p3">
   <p class="ltx_p" id="S2.p3.1">
    <span class="ltx_text ltx_font_bold" id="S2.p3.1.1">
     Large Pre-Trained Models for Embodied Agents
    </span>
    Recent years have witnessed growing interest in robotics to re-use large models originally trained for vision or language applications
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib19" title="">
      19
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib12" title="">
      12
     </a>
     ]
    </cite>
    or their architectures
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib20" title="">
      20
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib21" title="">
      21
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib22" title="">
      22
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib23" title="">
      23
     </a>
     ]
    </cite>
    . We are also starting to see large models and representations custom trained for robotics
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib1" title="">
      1
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib24" title="">
      24
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib25" title="">
      25
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib26" title="">
      26
     </a>
     ]
    </cite>
    . In our work, we leverage the recent class of Multimodal Large language models
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib27" title="">
      27
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib28" title="">
      28
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib29" title="">
      29
     </a>
     ]
    </cite>
    that extend the capability of text only LLMs to interpret other modalities like vision through alignment layers. Specifically, our instantiation of
    <span class="ltx_text ltx_font_typewriter" id="S2.p3.1.2">
     LCB
    </span>
    model builds on top of LLaVA
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib27" title="">
      27
     </a>
     ]
    </cite>
    and finetunes the model on a simulated dataset of embodied reasoning and long-horizon tasks. As the availability of embodied datasets paired with language annotations grow, we hope that our method can be extended to release generalist models that can be deployed zero shot in new domains.
   </p>
  </div>
 </section>
 <section class="ltx_section" id="S3">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    III
   </span>
   <span class="ltx_text ltx_font_smallcaps" id="S3.1.1">
    Method
   </span>
  </h2>
  <figure class="ltx_figure" id="S3.F2">
   <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="203" id="S3.F2.g1" src="/html/2405.04798/assets/all_methods.png" width="592"/>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     <span class="ltx_text" id="S3.F2.4.1.1" style="font-size:90%;">
      Figure 2
     </span>
     :
    </span>
    <span class="ltx_text" id="S3.F2.5.2" style="font-size:90%;">
     A high level architectural comparison of LLM-based hierarchical policies.
Predefined skills (left) uses a LLM to call predefined primitives. Language as an interface (middle) uses a LLM to output a simple language command, which is then passed into a language conditioned policy.
     <span class="ltx_text ltx_font_typewriter ltx_font_bold" id="S3.F2.5.2.1">
      LCB
     </span>
     (right) utilizes a latent code as a
     <span class="ltx_text ltx_font_bold" id="S3.F2.5.2.2">
      bridge
     </span>
     between the LLM and the low level policy, facilitating hierarchical control and end-to-end learning.
    </span>
   </figcaption>
  </figure>
  <div class="ltx_para" id="S3.p1">
   <p class="ltx_p" id="S3.p1.1">
    We wish to develop a hierarchical policy architecture that can enable robots to perform a variety of manipulation tasks when provided with free-form language descriptions. Specifically, we seek an architecture that can handle low-level actions for fine-grained or contact-rich tasks (e.g. pushing, 6D object manipulation) while also having the capability to reason and plan without any external step-by-step instructions. Before we present our architecture for this purpose, we first survey two other families of approaches and their deficiencies, which provides the intuition and basis for our method. These approaches are shown in
    <a class="ltx_ref ltx_refmacro_autoref" href="#S3.F2" title="Figure 2 ‣ III Method ‣ From LLMs to Actions: Latent Codes as Bridges in Hierarchical Robot Control">
     <span class="ltx_text ltx_ref_tag">
      Figure 2
     </span>
    </a>
    .
    <br class="ltx_break"/>
   </p>
  </div>
  <div class="ltx_para ltx_noindent" id="S3.p2">
   <p class="ltx_p" id="S3.p2.1">
    <span class="ltx_text ltx_font_bold" id="S3.p2.1.1">
     LLMs Leveraging Predefined Skills
    </span>
    First we can consider a hierarchical approach where LLMs perform high-level task planning by calling a set of pre-defined skills or APIs
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib6" title="">
      6
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib8" title="">
      8
     </a>
     ]
    </cite>
    . These APIs (e.g.
    <span class="ltx_text ltx_font_typewriter" id="S3.p2.1.2">
     go-to
    </span>
    ,
    <span class="ltx_text ltx_font_typewriter" id="S3.p2.1.3">
     push
    </span>
    ) are described and provided to the LLM as part of the main prompt. This approach suffers from two primary drawbacks. Firstly, for an LLM to plan with skills, they need to have
    <span class="ltx_text ltx_font_italic" id="S3.p2.1.4">
     semantics
    </span>
    attached to them that make linguistic sense. Secondly, this constrains the set of skills to a closed vocabulary, and prevents any form of generalization to new skills or capabilities. Furthermore, code-writing proficiency demands a high-quality LLM, a criterion met chiefly by proprietary commercial models such as GPT-4
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib2" title="">
      2
     </a>
     ]
    </cite>
    . Additionally, end-to-end fine-tuning is challenging since the LLM cannot adapt or compensate for limited prowess of the low-level skills
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib6" title="">
      6
     </a>
     ]
    </cite>
    .
    <br class="ltx_break"/>
   </p>
  </div>
  <div class="ltx_para ltx_noindent" id="S3.p3">
   <p class="ltx_p" id="S3.p3.1">
    <span class="ltx_text ltx_font_bold" id="S3.p3.1.1">
     Language as Interface
    </span>
    The second class of approaches can leverage
    <span class="ltx_text ltx_font_italic" id="S3.p3.1.2">
     language-conditioned low-level policies
    </span>
    as opposed to a finite set of low-level skills. Such policies can take a simple language command as input (e.g.
    <span class="ltx_text ltx_font_typewriter" id="S3.p3.1.3">
     pickup the red block
    </span>
    ) and produce actions that can (hopefully) accomplish the task. Since these policies can accept free-form text as input, at least theoretically, they have the capability to generalize to new instructions. Furthermore, they are amenable to end-to-end fine-tuning from high-level instructions, through an LLM, to the language conditioned policy, and ultimately the action. Nevertheless, this class of approaches also suffer from key limitations. Firstly, not all high level tasks can be decomposed into sub-tasks in simple language. For example, imagine trying to describe step-by-step instructions to make a robot dance to a song. Secondly, end-to-end fine-tuning with such an architecture can destroy planning and reasoning capabilities that the LLM originally had
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib30" title="">
      30
     </a>
     ]
    </cite>
    .
    <br class="ltx_break"/>
   </p>
  </div>
  <div class="ltx_para ltx_noindent" id="S3.p4">
   <p class="ltx_p" id="S3.p4.1">
    <span class="ltx_text ltx_font_bold" id="S3.p4.1.1">
     Latent Codes as a Bridge (Ours)
    </span>
    Finally we describe our method which can overcome the key limitations outlined above. Our key insight is that we can introduce an additional latent code to act as a bridge between the high-level LLM and low-level language conditioned policy. We augment the LLM’s tokenizer by adding a specialized
    <span class="ltx_text ltx_font_typewriter" id="S3.p4.1.2">
     &lt;ACT&gt;
    </span>
    token, prompting the model to predict this token in response to actionable questions. The last layer embedding of the
    <span class="ltx_text ltx_font_typewriter" id="S3.p4.1.3">
     &lt;ACT&gt;
    </span>
    token is then utilized as a latent goal for the downstream policy network. This learnable
    <span class="ltx_text ltx_font_typewriter" id="S3.p4.1.4">
     &lt;ACT&gt;
    </span>
    token’s embedding facilitates the transmission of abstract goals and nuances to the low-level policy – details that are not easily conveyed through language alone. Furthermore, by using this additional learnable token, we preserve the embedding space for language tokens, thus preventing any catastrophic forgetting during end-to-end fine-tuning. We describe more specific details of our architecture and implementation below.
   </p>
  </div>
  <section class="ltx_subsection" id="S3.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     <span class="ltx_text" id="S3.SS1.5.1.1">
      III-A
     </span>
    </span>
    <span class="ltx_text ltx_font_italic" id="S3.SS1.6.2">
     Architecture and Implementation Details of
    </span>
    <span class="ltx_text ltx_font_typewriter" id="S3.SS1.7.3">
     LCB
    </span>
   </h3>
   <div class="ltx_para" id="S3.SS1.p1">
    <p class="ltx_p" id="S3.SS1.p1.11">
     <span class="ltx_text ltx_font_typewriter" id="S3.SS1.p1.11.1">
      LCB
     </span>
     unifies the capabilities of a slow but powerful pretrained Multimodal Large Language Models (LLMs) with a fast and simpler decision-making policies to create a model that ingests vision and language inputs to output low-level actions. This integration involves a two-component system: a pretrained LLM, denoted as
     <math alttext="f_{\phi}" class="ltx_Math" display="inline" id="S3.SS1.p1.1.m1.1">
      <semantics id="S3.SS1.p1.1.m1.1a">
       <msub id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">
        <mi id="S3.SS1.p1.1.m1.1.1.2" xref="S3.SS1.p1.1.m1.1.1.2.cmml">
         f
        </mi>
        <mi id="S3.SS1.p1.1.m1.1.1.3" xref="S3.SS1.p1.1.m1.1.1.3.cmml">
         ϕ
        </mi>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b">
        <apply id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">
         <csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">
          subscript
         </csymbol>
         <ci id="S3.SS1.p1.1.m1.1.1.2.cmml" xref="S3.SS1.p1.1.m1.1.1.2">
          𝑓
         </ci>
         <ci id="S3.SS1.p1.1.m1.1.1.3.cmml" xref="S3.SS1.p1.1.m1.1.1.3">
          italic-ϕ
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">
        f_{\phi}
       </annotation>
      </semantics>
     </math>
     , and a pretrained policy,
     <math alttext="\pi_{\theta}" class="ltx_Math" display="inline" id="S3.SS1.p1.2.m2.1">
      <semantics id="S3.SS1.p1.2.m2.1a">
       <msub id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml">
        <mi id="S3.SS1.p1.2.m2.1.1.2" xref="S3.SS1.p1.2.m2.1.1.2.cmml">
         π
        </mi>
        <mi id="S3.SS1.p1.2.m2.1.1.3" xref="S3.SS1.p1.2.m2.1.1.3.cmml">
         θ
        </mi>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b">
        <apply id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">
         <csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.1.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">
          subscript
         </csymbol>
         <ci id="S3.SS1.p1.2.m2.1.1.2.cmml" xref="S3.SS1.p1.2.m2.1.1.2">
          𝜋
         </ci>
         <ci id="S3.SS1.p1.2.m2.1.1.3.cmml" xref="S3.SS1.p1.2.m2.1.1.3">
          𝜃
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">
        \pi_{\theta}
       </annotation>
      </semantics>
     </math>
     , parameterized by
     <math alttext="\phi" class="ltx_Math" display="inline" id="S3.SS1.p1.3.m3.1">
      <semantics id="S3.SS1.p1.3.m3.1a">
       <mi id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml">
        ϕ
       </mi>
       <annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b">
        <ci id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">
         italic-ϕ
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">
        \phi
       </annotation>
      </semantics>
     </math>
     and
     <math alttext="\theta" class="ltx_Math" display="inline" id="S3.SS1.p1.4.m4.1">
      <semantics id="S3.SS1.p1.4.m4.1a">
       <mi id="S3.SS1.p1.4.m4.1.1" xref="S3.SS1.p1.4.m4.1.1.cmml">
        θ
       </mi>
       <annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m4.1b">
        <ci id="S3.SS1.p1.4.m4.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1">
         𝜃
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS1.p1.4.m4.1c">
        \theta
       </annotation>
      </semantics>
     </math>
     respectively. The LLM consists of a text only large language model and a vision encoder, which projects images into the text only large language models embedding space, facilitating a multimodal understanding of textual and visual inputs. In this work, we leverage LLaVA
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib27" title="">
       27
      </a>
      ]
     </cite>
     as our pretrained LLM.
     <math alttext="f_{\phi}" class="ltx_Math" display="inline" id="S3.SS1.p1.5.m5.1">
      <semantics id="S3.SS1.p1.5.m5.1a">
       <msub id="S3.SS1.p1.5.m5.1.1" xref="S3.SS1.p1.5.m5.1.1.cmml">
        <mi id="S3.SS1.p1.5.m5.1.1.2" xref="S3.SS1.p1.5.m5.1.1.2.cmml">
         f
        </mi>
        <mi id="S3.SS1.p1.5.m5.1.1.3" xref="S3.SS1.p1.5.m5.1.1.3.cmml">
         ϕ
        </mi>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S3.SS1.p1.5.m5.1b">
        <apply id="S3.SS1.p1.5.m5.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1">
         <csymbol cd="ambiguous" id="S3.SS1.p1.5.m5.1.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1">
          subscript
         </csymbol>
         <ci id="S3.SS1.p1.5.m5.1.1.2.cmml" xref="S3.SS1.p1.5.m5.1.1.2">
          𝑓
         </ci>
         <ci id="S3.SS1.p1.5.m5.1.1.3.cmml" xref="S3.SS1.p1.5.m5.1.1.3">
          italic-ϕ
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS1.p1.5.m5.1c">
        f_{\phi}
       </annotation>
      </semantics>
     </math>
     takes in text tokens
     <math alttext="x_{txt}" class="ltx_Math" display="inline" id="S3.SS1.p1.6.m6.1">
      <semantics id="S3.SS1.p1.6.m6.1a">
       <msub id="S3.SS1.p1.6.m6.1.1" xref="S3.SS1.p1.6.m6.1.1.cmml">
        <mi id="S3.SS1.p1.6.m6.1.1.2" xref="S3.SS1.p1.6.m6.1.1.2.cmml">
         x
        </mi>
        <mrow id="S3.SS1.p1.6.m6.1.1.3" xref="S3.SS1.p1.6.m6.1.1.3.cmml">
         <mi id="S3.SS1.p1.6.m6.1.1.3.2" xref="S3.SS1.p1.6.m6.1.1.3.2.cmml">
          t
         </mi>
         <mo id="S3.SS1.p1.6.m6.1.1.3.1" lspace="0em" rspace="0em" xref="S3.SS1.p1.6.m6.1.1.3.1.cmml">
          ​
         </mo>
         <mi id="S3.SS1.p1.6.m6.1.1.3.3" xref="S3.SS1.p1.6.m6.1.1.3.3.cmml">
          x
         </mi>
         <mo id="S3.SS1.p1.6.m6.1.1.3.1a" lspace="0em" rspace="0em" xref="S3.SS1.p1.6.m6.1.1.3.1.cmml">
          ​
         </mo>
         <mi id="S3.SS1.p1.6.m6.1.1.3.4" xref="S3.SS1.p1.6.m6.1.1.3.4.cmml">
          t
         </mi>
        </mrow>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S3.SS1.p1.6.m6.1b">
        <apply id="S3.SS1.p1.6.m6.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1">
         <csymbol cd="ambiguous" id="S3.SS1.p1.6.m6.1.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1">
          subscript
         </csymbol>
         <ci id="S3.SS1.p1.6.m6.1.1.2.cmml" xref="S3.SS1.p1.6.m6.1.1.2">
          𝑥
         </ci>
         <apply id="S3.SS1.p1.6.m6.1.1.3.cmml" xref="S3.SS1.p1.6.m6.1.1.3">
          <times id="S3.SS1.p1.6.m6.1.1.3.1.cmml" xref="S3.SS1.p1.6.m6.1.1.3.1">
          </times>
          <ci id="S3.SS1.p1.6.m6.1.1.3.2.cmml" xref="S3.SS1.p1.6.m6.1.1.3.2">
           𝑡
          </ci>
          <ci id="S3.SS1.p1.6.m6.1.1.3.3.cmml" xref="S3.SS1.p1.6.m6.1.1.3.3">
           𝑥
          </ci>
          <ci id="S3.SS1.p1.6.m6.1.1.3.4.cmml" xref="S3.SS1.p1.6.m6.1.1.3.4">
           𝑡
          </ci>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS1.p1.6.m6.1c">
        x_{txt}
       </annotation>
      </semantics>
     </math>
     and images
     <math alttext="x_{img}" class="ltx_Math" display="inline" id="S3.SS1.p1.7.m7.1">
      <semantics id="S3.SS1.p1.7.m7.1a">
       <msub id="S3.SS1.p1.7.m7.1.1" xref="S3.SS1.p1.7.m7.1.1.cmml">
        <mi id="S3.SS1.p1.7.m7.1.1.2" xref="S3.SS1.p1.7.m7.1.1.2.cmml">
         x
        </mi>
        <mrow id="S3.SS1.p1.7.m7.1.1.3" xref="S3.SS1.p1.7.m7.1.1.3.cmml">
         <mi id="S3.SS1.p1.7.m7.1.1.3.2" xref="S3.SS1.p1.7.m7.1.1.3.2.cmml">
          i
         </mi>
         <mo id="S3.SS1.p1.7.m7.1.1.3.1" lspace="0em" rspace="0em" xref="S3.SS1.p1.7.m7.1.1.3.1.cmml">
          ​
         </mo>
         <mi id="S3.SS1.p1.7.m7.1.1.3.3" xref="S3.SS1.p1.7.m7.1.1.3.3.cmml">
          m
         </mi>
         <mo id="S3.SS1.p1.7.m7.1.1.3.1a" lspace="0em" rspace="0em" xref="S3.SS1.p1.7.m7.1.1.3.1.cmml">
          ​
         </mo>
         <mi id="S3.SS1.p1.7.m7.1.1.3.4" xref="S3.SS1.p1.7.m7.1.1.3.4.cmml">
          g
         </mi>
        </mrow>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S3.SS1.p1.7.m7.1b">
        <apply id="S3.SS1.p1.7.m7.1.1.cmml" xref="S3.SS1.p1.7.m7.1.1">
         <csymbol cd="ambiguous" id="S3.SS1.p1.7.m7.1.1.1.cmml" xref="S3.SS1.p1.7.m7.1.1">
          subscript
         </csymbol>
         <ci id="S3.SS1.p1.7.m7.1.1.2.cmml" xref="S3.SS1.p1.7.m7.1.1.2">
          𝑥
         </ci>
         <apply id="S3.SS1.p1.7.m7.1.1.3.cmml" xref="S3.SS1.p1.7.m7.1.1.3">
          <times id="S3.SS1.p1.7.m7.1.1.3.1.cmml" xref="S3.SS1.p1.7.m7.1.1.3.1">
          </times>
          <ci id="S3.SS1.p1.7.m7.1.1.3.2.cmml" xref="S3.SS1.p1.7.m7.1.1.3.2">
           𝑖
          </ci>
          <ci id="S3.SS1.p1.7.m7.1.1.3.3.cmml" xref="S3.SS1.p1.7.m7.1.1.3.3">
           𝑚
          </ci>
          <ci id="S3.SS1.p1.7.m7.1.1.3.4.cmml" xref="S3.SS1.p1.7.m7.1.1.3.4">
           𝑔
          </ci>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS1.p1.7.m7.1c">
        x_{img}
       </annotation>
      </semantics>
     </math>
     and outputs text tokens. The pretrained policy
     <math alttext="\pi_{\theta}" class="ltx_Math" display="inline" id="S3.SS1.p1.8.m8.1">
      <semantics id="S3.SS1.p1.8.m8.1a">
       <msub id="S3.SS1.p1.8.m8.1.1" xref="S3.SS1.p1.8.m8.1.1.cmml">
        <mi id="S3.SS1.p1.8.m8.1.1.2" xref="S3.SS1.p1.8.m8.1.1.2.cmml">
         π
        </mi>
        <mi id="S3.SS1.p1.8.m8.1.1.3" xref="S3.SS1.p1.8.m8.1.1.3.cmml">
         θ
        </mi>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S3.SS1.p1.8.m8.1b">
        <apply id="S3.SS1.p1.8.m8.1.1.cmml" xref="S3.SS1.p1.8.m8.1.1">
         <csymbol cd="ambiguous" id="S3.SS1.p1.8.m8.1.1.1.cmml" xref="S3.SS1.p1.8.m8.1.1">
          subscript
         </csymbol>
         <ci id="S3.SS1.p1.8.m8.1.1.2.cmml" xref="S3.SS1.p1.8.m8.1.1.2">
          𝜋
         </ci>
         <ci id="S3.SS1.p1.8.m8.1.1.3.cmml" xref="S3.SS1.p1.8.m8.1.1.3">
          𝜃
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS1.p1.8.m8.1c">
        \pi_{\theta}
       </annotation>
      </semantics>
     </math>
     takes as input environment observations at the current time step
     <math alttext="o_{t}" class="ltx_Math" display="inline" id="S3.SS1.p1.9.m9.1">
      <semantics id="S3.SS1.p1.9.m9.1a">
       <msub id="S3.SS1.p1.9.m9.1.1" xref="S3.SS1.p1.9.m9.1.1.cmml">
        <mi id="S3.SS1.p1.9.m9.1.1.2" xref="S3.SS1.p1.9.m9.1.1.2.cmml">
         o
        </mi>
        <mi id="S3.SS1.p1.9.m9.1.1.3" xref="S3.SS1.p1.9.m9.1.1.3.cmml">
         t
        </mi>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S3.SS1.p1.9.m9.1b">
        <apply id="S3.SS1.p1.9.m9.1.1.cmml" xref="S3.SS1.p1.9.m9.1.1">
         <csymbol cd="ambiguous" id="S3.SS1.p1.9.m9.1.1.1.cmml" xref="S3.SS1.p1.9.m9.1.1">
          subscript
         </csymbol>
         <ci id="S3.SS1.p1.9.m9.1.1.2.cmml" xref="S3.SS1.p1.9.m9.1.1.2">
          𝑜
         </ci>
         <ci id="S3.SS1.p1.9.m9.1.1.3.cmml" xref="S3.SS1.p1.9.m9.1.1.3">
          𝑡
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS1.p1.9.m9.1c">
        o_{t}
       </annotation>
      </semantics>
     </math>
     , with conditioning latent
     <math alttext="z" class="ltx_Math" display="inline" id="S3.SS1.p1.10.m10.1">
      <semantics id="S3.SS1.p1.10.m10.1a">
       <mi id="S3.SS1.p1.10.m10.1.1" xref="S3.SS1.p1.10.m10.1.1.cmml">
        z
       </mi>
       <annotation-xml encoding="MathML-Content" id="S3.SS1.p1.10.m10.1b">
        <ci id="S3.SS1.p1.10.m10.1.1.cmml" xref="S3.SS1.p1.10.m10.1.1">
         𝑧
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS1.p1.10.m10.1c">
        z
       </annotation>
      </semantics>
     </math>
     , and outputs the action at the current time step
     <math alttext="a_{t}" class="ltx_Math" display="inline" id="S3.SS1.p1.11.m11.1">
      <semantics id="S3.SS1.p1.11.m11.1a">
       <msub id="S3.SS1.p1.11.m11.1.1" xref="S3.SS1.p1.11.m11.1.1.cmml">
        <mi id="S3.SS1.p1.11.m11.1.1.2" xref="S3.SS1.p1.11.m11.1.1.2.cmml">
         a
        </mi>
        <mi id="S3.SS1.p1.11.m11.1.1.3" xref="S3.SS1.p1.11.m11.1.1.3.cmml">
         t
        </mi>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S3.SS1.p1.11.m11.1b">
        <apply id="S3.SS1.p1.11.m11.1.1.cmml" xref="S3.SS1.p1.11.m11.1.1">
         <csymbol cd="ambiguous" id="S3.SS1.p1.11.m11.1.1.1.cmml" xref="S3.SS1.p1.11.m11.1.1">
          subscript
         </csymbol>
         <ci id="S3.SS1.p1.11.m11.1.1.2.cmml" xref="S3.SS1.p1.11.m11.1.1.2">
          𝑎
         </ci>
         <ci id="S3.SS1.p1.11.m11.1.1.3.cmml" xref="S3.SS1.p1.11.m11.1.1.3">
          𝑡
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS1.p1.11.m11.1c">
        a_{t}
       </annotation>
      </semantics>
     </math>
     .
    </p>
   </div>
   <div class="ltx_para" id="S3.SS1.p2">
    <p class="ltx_p" id="S3.SS1.p2.2">
     We introduce an additional
     <span class="ltx_text ltx_font_typewriter" id="S3.SS1.p2.2.1">
      &lt;ACT&gt;
     </span>
     token into the vocabulary of the language model, which is a special token that enables the language model to generate an action embedding to control the lower level policy. The model is trained to output
     <span class="ltx_text ltx_font_typewriter" id="S3.SS1.p2.2.2">
      &lt;ACT&gt;
     </span>
     tokens when executable requests are provided to the model. We extract out the last-layer embedding features from the model of at the
     <span class="ltx_text ltx_font_typewriter" id="S3.SS1.p2.2.3">
      &lt;ACT&gt;
     </span>
     token, following the approach used in Language Instructed Segmentation Assistant (LISA)
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib31" title="">
       31
      </a>
      ]
     </cite>
     . This embedding is projected into the policy latent conditioning space by a linear layer to extract the latent feature
     <math alttext="z_{{\texttt{&lt;ACT&gt;}}}" class="ltx_Math" display="inline" id="S3.SS1.p2.1.m1.1">
      <semantics id="S3.SS1.p2.1.m1.1a">
       <msub id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml">
        <mi id="S3.SS1.p2.1.m1.1.1.2" xref="S3.SS1.p2.1.m1.1.1.2.cmml">
         z
        </mi>
        <mtext class="ltx_mathvariant_monospace" id="S3.SS1.p2.1.m1.1.1.3" xref="S3.SS1.p2.1.m1.1.1.3a.cmml">
         &lt;ACT&gt;
        </mtext>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b">
        <apply id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1">
         <csymbol cd="ambiguous" id="S3.SS1.p2.1.m1.1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1">
          subscript
         </csymbol>
         <ci id="S3.SS1.p2.1.m1.1.1.2.cmml" xref="S3.SS1.p2.1.m1.1.1.2">
          𝑧
         </ci>
         <ci id="S3.SS1.p2.1.m1.1.1.3a.cmml" xref="S3.SS1.p2.1.m1.1.1.3">
          <mtext class="ltx_mathvariant_monospace" id="S3.SS1.p2.1.m1.1.1.3.cmml" mathsize="70%" xref="S3.SS1.p2.1.m1.1.1.3">
           &lt;ACT&gt;
          </mtext>
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">
        z_{{\texttt{&lt;ACT&gt;}}}
       </annotation>
      </semantics>
     </math>
     which is then fed into the policy
     <math alttext="\pi_{\theta}" class="ltx_Math" display="inline" id="S3.SS1.p2.2.m2.1">
      <semantics id="S3.SS1.p2.2.m2.1a">
       <msub id="S3.SS1.p2.2.m2.1.1" xref="S3.SS1.p2.2.m2.1.1.cmml">
        <mi id="S3.SS1.p2.2.m2.1.1.2" xref="S3.SS1.p2.2.m2.1.1.2.cmml">
         π
        </mi>
        <mi id="S3.SS1.p2.2.m2.1.1.3" xref="S3.SS1.p2.2.m2.1.1.3.cmml">
         θ
        </mi>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.1b">
        <apply id="S3.SS1.p2.2.m2.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1">
         <csymbol cd="ambiguous" id="S3.SS1.p2.2.m2.1.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1">
          subscript
         </csymbol>
         <ci id="S3.SS1.p2.2.m2.1.1.2.cmml" xref="S3.SS1.p2.2.m2.1.1.2">
          𝜋
         </ci>
         <ci id="S3.SS1.p2.2.m2.1.1.3.cmml" xref="S3.SS1.p2.2.m2.1.1.3">
          𝜃
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.1c">
        \pi_{\theta}
       </annotation>
      </semantics>
     </math>
     .
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S3.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     <span class="ltx_text" id="S3.SS2.5.1.1">
      III-B
     </span>
    </span>
    <span class="ltx_text ltx_font_italic" id="S3.SS2.6.2">
     Data Processing
    </span>
   </h3>
   <div class="ltx_para" id="S3.SS2.p1">
    <p class="ltx_p" id="S3.SS2.p1.1">
     The
     <span class="ltx_text ltx_font_typewriter" id="S3.SS2.p1.1.1">
      LCB
     </span>
     framework necessitates diverse and strategically curated datasets to make the policy effective for language-guided action execution in varied contexts. We cater the data collection and preprocessing steps towards this goal, creating a small instruction tuning dataset.
    </p>
   </div>
   <div class="ltx_para" id="S3.SS2.p2">
    <p class="ltx_p" id="S3.SS2.p2.2">
     We convert in domain text conditioned policy data into the chat format of LLM assistants. Typical language conditioned trajectory datasets contain one language instruction and a list of (observation, action) pairs
     <math alttext="[x_{txt},(o_{0},a_{0},...,o_{t},a_{t},...)]" class="ltx_Math" display="inline" id="S3.SS2.p2.1.m1.4">
      <semantics id="S3.SS2.p2.1.m1.4a">
       <mrow id="S3.SS2.p2.1.m1.4.4.2" xref="S3.SS2.p2.1.m1.4.4.3.cmml">
        <mo id="S3.SS2.p2.1.m1.4.4.2.3" stretchy="false" xref="S3.SS2.p2.1.m1.4.4.3.cmml">
         [
        </mo>
        <msub id="S3.SS2.p2.1.m1.3.3.1.1" xref="S3.SS2.p2.1.m1.3.3.1.1.cmml">
         <mi id="S3.SS2.p2.1.m1.3.3.1.1.2" xref="S3.SS2.p2.1.m1.3.3.1.1.2.cmml">
          x
         </mi>
         <mrow id="S3.SS2.p2.1.m1.3.3.1.1.3" xref="S3.SS2.p2.1.m1.3.3.1.1.3.cmml">
          <mi id="S3.SS2.p2.1.m1.3.3.1.1.3.2" xref="S3.SS2.p2.1.m1.3.3.1.1.3.2.cmml">
           t
          </mi>
          <mo id="S3.SS2.p2.1.m1.3.3.1.1.3.1" lspace="0em" rspace="0em" xref="S3.SS2.p2.1.m1.3.3.1.1.3.1.cmml">
           ​
          </mo>
          <mi id="S3.SS2.p2.1.m1.3.3.1.1.3.3" xref="S3.SS2.p2.1.m1.3.3.1.1.3.3.cmml">
           x
          </mi>
          <mo id="S3.SS2.p2.1.m1.3.3.1.1.3.1a" lspace="0em" rspace="0em" xref="S3.SS2.p2.1.m1.3.3.1.1.3.1.cmml">
           ​
          </mo>
          <mi id="S3.SS2.p2.1.m1.3.3.1.1.3.4" xref="S3.SS2.p2.1.m1.3.3.1.1.3.4.cmml">
           t
          </mi>
         </mrow>
        </msub>
        <mo id="S3.SS2.p2.1.m1.4.4.2.4" xref="S3.SS2.p2.1.m1.4.4.3.cmml">
         ,
        </mo>
        <mrow id="S3.SS2.p2.1.m1.4.4.2.2.4" xref="S3.SS2.p2.1.m1.4.4.2.2.5.cmml">
         <mo id="S3.SS2.p2.1.m1.4.4.2.2.4.5" stretchy="false" xref="S3.SS2.p2.1.m1.4.4.2.2.5.cmml">
          (
         </mo>
         <msub id="S3.SS2.p2.1.m1.4.4.2.2.1.1" xref="S3.SS2.p2.1.m1.4.4.2.2.1.1.cmml">
          <mi id="S3.SS2.p2.1.m1.4.4.2.2.1.1.2" xref="S3.SS2.p2.1.m1.4.4.2.2.1.1.2.cmml">
           o
          </mi>
          <mn id="S3.SS2.p2.1.m1.4.4.2.2.1.1.3" xref="S3.SS2.p2.1.m1.4.4.2.2.1.1.3.cmml">
           0
          </mn>
         </msub>
         <mo id="S3.SS2.p2.1.m1.4.4.2.2.4.6" xref="S3.SS2.p2.1.m1.4.4.2.2.5.cmml">
          ,
         </mo>
         <msub id="S3.SS2.p2.1.m1.4.4.2.2.2.2" xref="S3.SS2.p2.1.m1.4.4.2.2.2.2.cmml">
          <mi id="S3.SS2.p2.1.m1.4.4.2.2.2.2.2" xref="S3.SS2.p2.1.m1.4.4.2.2.2.2.2.cmml">
           a
          </mi>
          <mn id="S3.SS2.p2.1.m1.4.4.2.2.2.2.3" xref="S3.SS2.p2.1.m1.4.4.2.2.2.2.3.cmml">
           0
          </mn>
         </msub>
         <mo id="S3.SS2.p2.1.m1.4.4.2.2.4.7" xref="S3.SS2.p2.1.m1.4.4.2.2.5.cmml">
          ,
         </mo>
         <mi id="S3.SS2.p2.1.m1.1.1" mathvariant="normal" xref="S3.SS2.p2.1.m1.1.1.cmml">
          …
         </mi>
         <mo id="S3.SS2.p2.1.m1.4.4.2.2.4.8" xref="S3.SS2.p2.1.m1.4.4.2.2.5.cmml">
          ,
         </mo>
         <msub id="S3.SS2.p2.1.m1.4.4.2.2.3.3" xref="S3.SS2.p2.1.m1.4.4.2.2.3.3.cmml">
          <mi id="S3.SS2.p2.1.m1.4.4.2.2.3.3.2" xref="S3.SS2.p2.1.m1.4.4.2.2.3.3.2.cmml">
           o
          </mi>
          <mi id="S3.SS2.p2.1.m1.4.4.2.2.3.3.3" xref="S3.SS2.p2.1.m1.4.4.2.2.3.3.3.cmml">
           t
          </mi>
         </msub>
         <mo id="S3.SS2.p2.1.m1.4.4.2.2.4.9" xref="S3.SS2.p2.1.m1.4.4.2.2.5.cmml">
          ,
         </mo>
         <msub id="S3.SS2.p2.1.m1.4.4.2.2.4.4" xref="S3.SS2.p2.1.m1.4.4.2.2.4.4.cmml">
          <mi id="S3.SS2.p2.1.m1.4.4.2.2.4.4.2" xref="S3.SS2.p2.1.m1.4.4.2.2.4.4.2.cmml">
           a
          </mi>
          <mi id="S3.SS2.p2.1.m1.4.4.2.2.4.4.3" xref="S3.SS2.p2.1.m1.4.4.2.2.4.4.3.cmml">
           t
          </mi>
         </msub>
         <mo id="S3.SS2.p2.1.m1.4.4.2.2.4.10" xref="S3.SS2.p2.1.m1.4.4.2.2.5.cmml">
          ,
         </mo>
         <mi id="S3.SS2.p2.1.m1.2.2" mathvariant="normal" xref="S3.SS2.p2.1.m1.2.2.cmml">
          …
         </mi>
         <mo id="S3.SS2.p2.1.m1.4.4.2.2.4.11" stretchy="false" xref="S3.SS2.p2.1.m1.4.4.2.2.5.cmml">
          )
         </mo>
        </mrow>
        <mo id="S3.SS2.p2.1.m1.4.4.2.5" stretchy="false" xref="S3.SS2.p2.1.m1.4.4.3.cmml">
         ]
        </mo>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.4b">
        <interval closure="closed" id="S3.SS2.p2.1.m1.4.4.3.cmml" xref="S3.SS2.p2.1.m1.4.4.2">
         <apply id="S3.SS2.p2.1.m1.3.3.1.1.cmml" xref="S3.SS2.p2.1.m1.3.3.1.1">
          <csymbol cd="ambiguous" id="S3.SS2.p2.1.m1.3.3.1.1.1.cmml" xref="S3.SS2.p2.1.m1.3.3.1.1">
           subscript
          </csymbol>
          <ci id="S3.SS2.p2.1.m1.3.3.1.1.2.cmml" xref="S3.SS2.p2.1.m1.3.3.1.1.2">
           𝑥
          </ci>
          <apply id="S3.SS2.p2.1.m1.3.3.1.1.3.cmml" xref="S3.SS2.p2.1.m1.3.3.1.1.3">
           <times id="S3.SS2.p2.1.m1.3.3.1.1.3.1.cmml" xref="S3.SS2.p2.1.m1.3.3.1.1.3.1">
           </times>
           <ci id="S3.SS2.p2.1.m1.3.3.1.1.3.2.cmml" xref="S3.SS2.p2.1.m1.3.3.1.1.3.2">
            𝑡
           </ci>
           <ci id="S3.SS2.p2.1.m1.3.3.1.1.3.3.cmml" xref="S3.SS2.p2.1.m1.3.3.1.1.3.3">
            𝑥
           </ci>
           <ci id="S3.SS2.p2.1.m1.3.3.1.1.3.4.cmml" xref="S3.SS2.p2.1.m1.3.3.1.1.3.4">
            𝑡
           </ci>
          </apply>
         </apply>
         <vector id="S3.SS2.p2.1.m1.4.4.2.2.5.cmml" xref="S3.SS2.p2.1.m1.4.4.2.2.4">
          <apply id="S3.SS2.p2.1.m1.4.4.2.2.1.1.cmml" xref="S3.SS2.p2.1.m1.4.4.2.2.1.1">
           <csymbol cd="ambiguous" id="S3.SS2.p2.1.m1.4.4.2.2.1.1.1.cmml" xref="S3.SS2.p2.1.m1.4.4.2.2.1.1">
            subscript
           </csymbol>
           <ci id="S3.SS2.p2.1.m1.4.4.2.2.1.1.2.cmml" xref="S3.SS2.p2.1.m1.4.4.2.2.1.1.2">
            𝑜
           </ci>
           <cn id="S3.SS2.p2.1.m1.4.4.2.2.1.1.3.cmml" type="integer" xref="S3.SS2.p2.1.m1.4.4.2.2.1.1.3">
            0
           </cn>
          </apply>
          <apply id="S3.SS2.p2.1.m1.4.4.2.2.2.2.cmml" xref="S3.SS2.p2.1.m1.4.4.2.2.2.2">
           <csymbol cd="ambiguous" id="S3.SS2.p2.1.m1.4.4.2.2.2.2.1.cmml" xref="S3.SS2.p2.1.m1.4.4.2.2.2.2">
            subscript
           </csymbol>
           <ci id="S3.SS2.p2.1.m1.4.4.2.2.2.2.2.cmml" xref="S3.SS2.p2.1.m1.4.4.2.2.2.2.2">
            𝑎
           </ci>
           <cn id="S3.SS2.p2.1.m1.4.4.2.2.2.2.3.cmml" type="integer" xref="S3.SS2.p2.1.m1.4.4.2.2.2.2.3">
            0
           </cn>
          </apply>
          <ci id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1">
           …
          </ci>
          <apply id="S3.SS2.p2.1.m1.4.4.2.2.3.3.cmml" xref="S3.SS2.p2.1.m1.4.4.2.2.3.3">
           <csymbol cd="ambiguous" id="S3.SS2.p2.1.m1.4.4.2.2.3.3.1.cmml" xref="S3.SS2.p2.1.m1.4.4.2.2.3.3">
            subscript
           </csymbol>
           <ci id="S3.SS2.p2.1.m1.4.4.2.2.3.3.2.cmml" xref="S3.SS2.p2.1.m1.4.4.2.2.3.3.2">
            𝑜
           </ci>
           <ci id="S3.SS2.p2.1.m1.4.4.2.2.3.3.3.cmml" xref="S3.SS2.p2.1.m1.4.4.2.2.3.3.3">
            𝑡
           </ci>
          </apply>
          <apply id="S3.SS2.p2.1.m1.4.4.2.2.4.4.cmml" xref="S3.SS2.p2.1.m1.4.4.2.2.4.4">
           <csymbol cd="ambiguous" id="S3.SS2.p2.1.m1.4.4.2.2.4.4.1.cmml" xref="S3.SS2.p2.1.m1.4.4.2.2.4.4">
            subscript
           </csymbol>
           <ci id="S3.SS2.p2.1.m1.4.4.2.2.4.4.2.cmml" xref="S3.SS2.p2.1.m1.4.4.2.2.4.4.2">
            𝑎
           </ci>
           <ci id="S3.SS2.p2.1.m1.4.4.2.2.4.4.3.cmml" xref="S3.SS2.p2.1.m1.4.4.2.2.4.4.3">
            𝑡
           </ci>
          </apply>
          <ci id="S3.SS2.p2.1.m1.2.2.cmml" xref="S3.SS2.p2.1.m1.2.2">
           …
          </ci>
         </vector>
        </interval>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.4c">
        [x_{txt},(o_{0},a_{0},...,o_{t},a_{t},...)]
       </annotation>
      </semantics>
     </math>
     per trajectory. We programmatically generate text data in the format of chat interactions using templates. A simple example of this user-assistant interaction, is “User: can you help me
     <math alttext="x_{txt}" class="ltx_Math" display="inline" id="S3.SS2.p2.2.m2.1">
      <semantics id="S3.SS2.p2.2.m2.1a">
       <msub id="S3.SS2.p2.2.m2.1.1" xref="S3.SS2.p2.2.m2.1.1.cmml">
        <mi id="S3.SS2.p2.2.m2.1.1.2" xref="S3.SS2.p2.2.m2.1.1.2.cmml">
         x
        </mi>
        <mrow id="S3.SS2.p2.2.m2.1.1.3" xref="S3.SS2.p2.2.m2.1.1.3.cmml">
         <mi id="S3.SS2.p2.2.m2.1.1.3.2" xref="S3.SS2.p2.2.m2.1.1.3.2.cmml">
          t
         </mi>
         <mo id="S3.SS2.p2.2.m2.1.1.3.1" lspace="0em" rspace="0em" xref="S3.SS2.p2.2.m2.1.1.3.1.cmml">
          ​
         </mo>
         <mi id="S3.SS2.p2.2.m2.1.1.3.3" xref="S3.SS2.p2.2.m2.1.1.3.3.cmml">
          x
         </mi>
         <mo id="S3.SS2.p2.2.m2.1.1.3.1a" lspace="0em" rspace="0em" xref="S3.SS2.p2.2.m2.1.1.3.1.cmml">
          ​
         </mo>
         <mi id="S3.SS2.p2.2.m2.1.1.3.4" xref="S3.SS2.p2.2.m2.1.1.3.4.cmml">
          t
         </mi>
        </mrow>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m2.1b">
        <apply id="S3.SS2.p2.2.m2.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1">
         <csymbol cd="ambiguous" id="S3.SS2.p2.2.m2.1.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1">
          subscript
         </csymbol>
         <ci id="S3.SS2.p2.2.m2.1.1.2.cmml" xref="S3.SS2.p2.2.m2.1.1.2">
          𝑥
         </ci>
         <apply id="S3.SS2.p2.2.m2.1.1.3.cmml" xref="S3.SS2.p2.2.m2.1.1.3">
          <times id="S3.SS2.p2.2.m2.1.1.3.1.cmml" xref="S3.SS2.p2.2.m2.1.1.3.1">
          </times>
          <ci id="S3.SS2.p2.2.m2.1.1.3.2.cmml" xref="S3.SS2.p2.2.m2.1.1.3.2">
           𝑡
          </ci>
          <ci id="S3.SS2.p2.2.m2.1.1.3.3.cmml" xref="S3.SS2.p2.2.m2.1.1.3.3">
           𝑥
          </ci>
          <ci id="S3.SS2.p2.2.m2.1.1.3.4.cmml" xref="S3.SS2.p2.2.m2.1.1.3.4">
           𝑡
          </ci>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS2.p2.2.m2.1c">
        x_{txt}
       </annotation>
      </semantics>
     </math>
     ? Assistant: yes,
     <span class="ltx_text ltx_font_typewriter" id="S3.SS2.p2.2.1">
      &lt;ACT&gt;
     </span>
     .” Specific templates for chat data generation are provided in Appendix
     <a class="ltx_ref" href="#A1" title="Appendix A Dataset Details For Language Table ‣ From LLMs to Actions: Latent Codes as Bridges in Hierarchical Robot Control">
      <span class="ltx_text ltx_ref_tag">
       A
      </span>
     </a>
     . This trains the model to recognize and respond to direct action requests, fostering a conversational interface that seamlessly transitions from dialogue to action.
    </p>
   </div>
   <div class="ltx_para" id="S3.SS2.p3">
    <p class="ltx_p" id="S3.SS2.p3.6">
     Moreover, we enrich our training material with additional datasets designed to prompt specific behaviors from the language model. One such data source is reasoning data, where the model is tasked with a more abstract goal and must reason about the scene to accomplish the goal. Such examples are framed within a chat-like interaction, encouraging the model to articulate its reasoning process before executing the
     <span class="ltx_text ltx_font_typewriter" id="S3.SS2.p3.6.1">
      &lt;ACT&gt;
     </span>
     command. For example, “User:
     <math alttext="x_{img}" class="ltx_Math" display="inline" id="S3.SS2.p3.1.m1.1">
      <semantics id="S3.SS2.p3.1.m1.1a">
       <msub id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml">
        <mi id="S3.SS2.p3.1.m1.1.1.2" xref="S3.SS2.p3.1.m1.1.1.2.cmml">
         x
        </mi>
        <mrow id="S3.SS2.p3.1.m1.1.1.3" xref="S3.SS2.p3.1.m1.1.1.3.cmml">
         <mi id="S3.SS2.p3.1.m1.1.1.3.2" xref="S3.SS2.p3.1.m1.1.1.3.2.cmml">
          i
         </mi>
         <mo id="S3.SS2.p3.1.m1.1.1.3.1" lspace="0em" rspace="0em" xref="S3.SS2.p3.1.m1.1.1.3.1.cmml">
          ​
         </mo>
         <mi id="S3.SS2.p3.1.m1.1.1.3.3" xref="S3.SS2.p3.1.m1.1.1.3.3.cmml">
          m
         </mi>
         <mo id="S3.SS2.p3.1.m1.1.1.3.1a" lspace="0em" rspace="0em" xref="S3.SS2.p3.1.m1.1.1.3.1.cmml">
          ​
         </mo>
         <mi id="S3.SS2.p3.1.m1.1.1.3.4" xref="S3.SS2.p3.1.m1.1.1.3.4.cmml">
          g
         </mi>
        </mrow>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b">
        <apply id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1">
         <csymbol cd="ambiguous" id="S3.SS2.p3.1.m1.1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1">
          subscript
         </csymbol>
         <ci id="S3.SS2.p3.1.m1.1.1.2.cmml" xref="S3.SS2.p3.1.m1.1.1.2">
          𝑥
         </ci>
         <apply id="S3.SS2.p3.1.m1.1.1.3.cmml" xref="S3.SS2.p3.1.m1.1.1.3">
          <times id="S3.SS2.p3.1.m1.1.1.3.1.cmml" xref="S3.SS2.p3.1.m1.1.1.3.1">
          </times>
          <ci id="S3.SS2.p3.1.m1.1.1.3.2.cmml" xref="S3.SS2.p3.1.m1.1.1.3.2">
           𝑖
          </ci>
          <ci id="S3.SS2.p3.1.m1.1.1.3.3.cmml" xref="S3.SS2.p3.1.m1.1.1.3.3">
           𝑚
          </ci>
          <ci id="S3.SS2.p3.1.m1.1.1.3.4.cmml" xref="S3.SS2.p3.1.m1.1.1.3.4">
           𝑔
          </ci>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">
        x_{img}
       </annotation>
      </semantics>
     </math>
     Can you
     <math alttext="{x_{txt}}" class="ltx_Math" display="inline" id="S3.SS2.p3.2.m2.1">
      <semantics id="S3.SS2.p3.2.m2.1a">
       <msub id="S3.SS2.p3.2.m2.1.1" xref="S3.SS2.p3.2.m2.1.1.cmml">
        <mi id="S3.SS2.p3.2.m2.1.1.2" xref="S3.SS2.p3.2.m2.1.1.2.cmml">
         x
        </mi>
        <mrow id="S3.SS2.p3.2.m2.1.1.3" xref="S3.SS2.p3.2.m2.1.1.3.cmml">
         <mi id="S3.SS2.p3.2.m2.1.1.3.2" xref="S3.SS2.p3.2.m2.1.1.3.2.cmml">
          t
         </mi>
         <mo id="S3.SS2.p3.2.m2.1.1.3.1" lspace="0em" rspace="0em" xref="S3.SS2.p3.2.m2.1.1.3.1.cmml">
          ​
         </mo>
         <mi id="S3.SS2.p3.2.m2.1.1.3.3" xref="S3.SS2.p3.2.m2.1.1.3.3.cmml">
          x
         </mi>
         <mo id="S3.SS2.p3.2.m2.1.1.3.1a" lspace="0em" rspace="0em" xref="S3.SS2.p3.2.m2.1.1.3.1.cmml">
          ​
         </mo>
         <mi id="S3.SS2.p3.2.m2.1.1.3.4" xref="S3.SS2.p3.2.m2.1.1.3.4.cmml">
          t
         </mi>
        </mrow>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.m2.1b">
        <apply id="S3.SS2.p3.2.m2.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1">
         <csymbol cd="ambiguous" id="S3.SS2.p3.2.m2.1.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1">
          subscript
         </csymbol>
         <ci id="S3.SS2.p3.2.m2.1.1.2.cmml" xref="S3.SS2.p3.2.m2.1.1.2">
          𝑥
         </ci>
         <apply id="S3.SS2.p3.2.m2.1.1.3.cmml" xref="S3.SS2.p3.2.m2.1.1.3">
          <times id="S3.SS2.p3.2.m2.1.1.3.1.cmml" xref="S3.SS2.p3.2.m2.1.1.3.1">
          </times>
          <ci id="S3.SS2.p3.2.m2.1.1.3.2.cmml" xref="S3.SS2.p3.2.m2.1.1.3.2">
           𝑡
          </ci>
          <ci id="S3.SS2.p3.2.m2.1.1.3.3.cmml" xref="S3.SS2.p3.2.m2.1.1.3.3">
           𝑥
          </ci>
          <ci id="S3.SS2.p3.2.m2.1.1.3.4.cmml" xref="S3.SS2.p3.2.m2.1.1.3.4">
           𝑡
          </ci>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS2.p3.2.m2.1c">
        {x_{txt}}
       </annotation>
      </semantics>
     </math>
     ? Assistant: I will
     <math alttext="x_{goal}" class="ltx_Math" display="inline" id="S3.SS2.p3.3.m3.1">
      <semantics id="S3.SS2.p3.3.m3.1a">
       <msub id="S3.SS2.p3.3.m3.1.1" xref="S3.SS2.p3.3.m3.1.1.cmml">
        <mi id="S3.SS2.p3.3.m3.1.1.2" xref="S3.SS2.p3.3.m3.1.1.2.cmml">
         x
        </mi>
        <mrow id="S3.SS2.p3.3.m3.1.1.3" xref="S3.SS2.p3.3.m3.1.1.3.cmml">
         <mi id="S3.SS2.p3.3.m3.1.1.3.2" xref="S3.SS2.p3.3.m3.1.1.3.2.cmml">
          g
         </mi>
         <mo id="S3.SS2.p3.3.m3.1.1.3.1" lspace="0em" rspace="0em" xref="S3.SS2.p3.3.m3.1.1.3.1.cmml">
          ​
         </mo>
         <mi id="S3.SS2.p3.3.m3.1.1.3.3" xref="S3.SS2.p3.3.m3.1.1.3.3.cmml">
          o
         </mi>
         <mo id="S3.SS2.p3.3.m3.1.1.3.1a" lspace="0em" rspace="0em" xref="S3.SS2.p3.3.m3.1.1.3.1.cmml">
          ​
         </mo>
         <mi id="S3.SS2.p3.3.m3.1.1.3.4" xref="S3.SS2.p3.3.m3.1.1.3.4.cmml">
          a
         </mi>
         <mo id="S3.SS2.p3.3.m3.1.1.3.1b" lspace="0em" rspace="0em" xref="S3.SS2.p3.3.m3.1.1.3.1.cmml">
          ​
         </mo>
         <mi id="S3.SS2.p3.3.m3.1.1.3.5" xref="S3.SS2.p3.3.m3.1.1.3.5.cmml">
          l
         </mi>
        </mrow>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S3.SS2.p3.3.m3.1b">
        <apply id="S3.SS2.p3.3.m3.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1">
         <csymbol cd="ambiguous" id="S3.SS2.p3.3.m3.1.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1">
          subscript
         </csymbol>
         <ci id="S3.SS2.p3.3.m3.1.1.2.cmml" xref="S3.SS2.p3.3.m3.1.1.2">
          𝑥
         </ci>
         <apply id="S3.SS2.p3.3.m3.1.1.3.cmml" xref="S3.SS2.p3.3.m3.1.1.3">
          <times id="S3.SS2.p3.3.m3.1.1.3.1.cmml" xref="S3.SS2.p3.3.m3.1.1.3.1">
          </times>
          <ci id="S3.SS2.p3.3.m3.1.1.3.2.cmml" xref="S3.SS2.p3.3.m3.1.1.3.2">
           𝑔
          </ci>
          <ci id="S3.SS2.p3.3.m3.1.1.3.3.cmml" xref="S3.SS2.p3.3.m3.1.1.3.3">
           𝑜
          </ci>
          <ci id="S3.SS2.p3.3.m3.1.1.3.4.cmml" xref="S3.SS2.p3.3.m3.1.1.3.4">
           𝑎
          </ci>
          <ci id="S3.SS2.p3.3.m3.1.1.3.5.cmml" xref="S3.SS2.p3.3.m3.1.1.3.5">
           𝑙
          </ci>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS2.p3.3.m3.1c">
        x_{goal}
       </annotation>
      </semantics>
     </math>
     <span class="ltx_text ltx_font_typewriter" id="S3.SS2.p3.6.2">
      &lt;ACT&gt;
     </span>
     ”. Where
     <math alttext="{x_{txt}}" class="ltx_Math" display="inline" id="S3.SS2.p3.4.m4.1">
      <semantics id="S3.SS2.p3.4.m4.1a">
       <msub id="S3.SS2.p3.4.m4.1.1" xref="S3.SS2.p3.4.m4.1.1.cmml">
        <mi id="S3.SS2.p3.4.m4.1.1.2" xref="S3.SS2.p3.4.m4.1.1.2.cmml">
         x
        </mi>
        <mrow id="S3.SS2.p3.4.m4.1.1.3" xref="S3.SS2.p3.4.m4.1.1.3.cmml">
         <mi id="S3.SS2.p3.4.m4.1.1.3.2" xref="S3.SS2.p3.4.m4.1.1.3.2.cmml">
          t
         </mi>
         <mo id="S3.SS2.p3.4.m4.1.1.3.1" lspace="0em" rspace="0em" xref="S3.SS2.p3.4.m4.1.1.3.1.cmml">
          ​
         </mo>
         <mi id="S3.SS2.p3.4.m4.1.1.3.3" xref="S3.SS2.p3.4.m4.1.1.3.3.cmml">
          x
         </mi>
         <mo id="S3.SS2.p3.4.m4.1.1.3.1a" lspace="0em" rspace="0em" xref="S3.SS2.p3.4.m4.1.1.3.1.cmml">
          ​
         </mo>
         <mi id="S3.SS2.p3.4.m4.1.1.3.4" xref="S3.SS2.p3.4.m4.1.1.3.4.cmml">
          t
         </mi>
        </mrow>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S3.SS2.p3.4.m4.1b">
        <apply id="S3.SS2.p3.4.m4.1.1.cmml" xref="S3.SS2.p3.4.m4.1.1">
         <csymbol cd="ambiguous" id="S3.SS2.p3.4.m4.1.1.1.cmml" xref="S3.SS2.p3.4.m4.1.1">
          subscript
         </csymbol>
         <ci id="S3.SS2.p3.4.m4.1.1.2.cmml" xref="S3.SS2.p3.4.m4.1.1.2">
          𝑥
         </ci>
         <apply id="S3.SS2.p3.4.m4.1.1.3.cmml" xref="S3.SS2.p3.4.m4.1.1.3">
          <times id="S3.SS2.p3.4.m4.1.1.3.1.cmml" xref="S3.SS2.p3.4.m4.1.1.3.1">
          </times>
          <ci id="S3.SS2.p3.4.m4.1.1.3.2.cmml" xref="S3.SS2.p3.4.m4.1.1.3.2">
           𝑡
          </ci>
          <ci id="S3.SS2.p3.4.m4.1.1.3.3.cmml" xref="S3.SS2.p3.4.m4.1.1.3.3">
           𝑥
          </ci>
          <ci id="S3.SS2.p3.4.m4.1.1.3.4.cmml" xref="S3.SS2.p3.4.m4.1.1.3.4">
           𝑡
          </ci>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS2.p3.4.m4.1c">
        {x_{txt}}
       </annotation>
      </semantics>
     </math>
     does not explicitly specify the target object and location. If
     <math alttext="{x_{txt}}" class="ltx_Math" display="inline" id="S3.SS2.p3.5.m5.1">
      <semantics id="S3.SS2.p3.5.m5.1a">
       <msub id="S3.SS2.p3.5.m5.1.1" xref="S3.SS2.p3.5.m5.1.1.cmml">
        <mi id="S3.SS2.p3.5.m5.1.1.2" xref="S3.SS2.p3.5.m5.1.1.2.cmml">
         x
        </mi>
        <mrow id="S3.SS2.p3.5.m5.1.1.3" xref="S3.SS2.p3.5.m5.1.1.3.cmml">
         <mi id="S3.SS2.p3.5.m5.1.1.3.2" xref="S3.SS2.p3.5.m5.1.1.3.2.cmml">
          t
         </mi>
         <mo id="S3.SS2.p3.5.m5.1.1.3.1" lspace="0em" rspace="0em" xref="S3.SS2.p3.5.m5.1.1.3.1.cmml">
          ​
         </mo>
         <mi id="S3.SS2.p3.5.m5.1.1.3.3" xref="S3.SS2.p3.5.m5.1.1.3.3.cmml">
          x
         </mi>
         <mo id="S3.SS2.p3.5.m5.1.1.3.1a" lspace="0em" rspace="0em" xref="S3.SS2.p3.5.m5.1.1.3.1.cmml">
          ​
         </mo>
         <mi id="S3.SS2.p3.5.m5.1.1.3.4" xref="S3.SS2.p3.5.m5.1.1.3.4.cmml">
          t
         </mi>
        </mrow>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S3.SS2.p3.5.m5.1b">
        <apply id="S3.SS2.p3.5.m5.1.1.cmml" xref="S3.SS2.p3.5.m5.1.1">
         <csymbol cd="ambiguous" id="S3.SS2.p3.5.m5.1.1.1.cmml" xref="S3.SS2.p3.5.m5.1.1">
          subscript
         </csymbol>
         <ci id="S3.SS2.p3.5.m5.1.1.2.cmml" xref="S3.SS2.p3.5.m5.1.1.2">
          𝑥
         </ci>
         <apply id="S3.SS2.p3.5.m5.1.1.3.cmml" xref="S3.SS2.p3.5.m5.1.1.3">
          <times id="S3.SS2.p3.5.m5.1.1.3.1.cmml" xref="S3.SS2.p3.5.m5.1.1.3.1">
          </times>
          <ci id="S3.SS2.p3.5.m5.1.1.3.2.cmml" xref="S3.SS2.p3.5.m5.1.1.3.2">
           𝑡
          </ci>
          <ci id="S3.SS2.p3.5.m5.1.1.3.3.cmml" xref="S3.SS2.p3.5.m5.1.1.3.3">
           𝑥
          </ci>
          <ci id="S3.SS2.p3.5.m5.1.1.3.4.cmml" xref="S3.SS2.p3.5.m5.1.1.3.4">
           𝑡
          </ci>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS2.p3.5.m5.1c">
        {x_{txt}}
       </annotation>
      </semantics>
     </math>
     is “move the block closest to the bottom right to the block of a similar color”, the assistant’s response,
     <math alttext="x_{goal}" class="ltx_Math" display="inline" id="S3.SS2.p3.6.m6.1">
      <semantics id="S3.SS2.p3.6.m6.1a">
       <msub id="S3.SS2.p3.6.m6.1.1" xref="S3.SS2.p3.6.m6.1.1.cmml">
        <mi id="S3.SS2.p3.6.m6.1.1.2" xref="S3.SS2.p3.6.m6.1.1.2.cmml">
         x
        </mi>
        <mrow id="S3.SS2.p3.6.m6.1.1.3" xref="S3.SS2.p3.6.m6.1.1.3.cmml">
         <mi id="S3.SS2.p3.6.m6.1.1.3.2" xref="S3.SS2.p3.6.m6.1.1.3.2.cmml">
          g
         </mi>
         <mo id="S3.SS2.p3.6.m6.1.1.3.1" lspace="0em" rspace="0em" xref="S3.SS2.p3.6.m6.1.1.3.1.cmml">
          ​
         </mo>
         <mi id="S3.SS2.p3.6.m6.1.1.3.3" xref="S3.SS2.p3.6.m6.1.1.3.3.cmml">
          o
         </mi>
         <mo id="S3.SS2.p3.6.m6.1.1.3.1a" lspace="0em" rspace="0em" xref="S3.SS2.p3.6.m6.1.1.3.1.cmml">
          ​
         </mo>
         <mi id="S3.SS2.p3.6.m6.1.1.3.4" xref="S3.SS2.p3.6.m6.1.1.3.4.cmml">
          a
         </mi>
         <mo id="S3.SS2.p3.6.m6.1.1.3.1b" lspace="0em" rspace="0em" xref="S3.SS2.p3.6.m6.1.1.3.1.cmml">
          ​
         </mo>
         <mi id="S3.SS2.p3.6.m6.1.1.3.5" xref="S3.SS2.p3.6.m6.1.1.3.5.cmml">
          l
         </mi>
        </mrow>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S3.SS2.p3.6.m6.1b">
        <apply id="S3.SS2.p3.6.m6.1.1.cmml" xref="S3.SS2.p3.6.m6.1.1">
         <csymbol cd="ambiguous" id="S3.SS2.p3.6.m6.1.1.1.cmml" xref="S3.SS2.p3.6.m6.1.1">
          subscript
         </csymbol>
         <ci id="S3.SS2.p3.6.m6.1.1.2.cmml" xref="S3.SS2.p3.6.m6.1.1.2">
          𝑥
         </ci>
         <apply id="S3.SS2.p3.6.m6.1.1.3.cmml" xref="S3.SS2.p3.6.m6.1.1.3">
          <times id="S3.SS2.p3.6.m6.1.1.3.1.cmml" xref="S3.SS2.p3.6.m6.1.1.3.1">
          </times>
          <ci id="S3.SS2.p3.6.m6.1.1.3.2.cmml" xref="S3.SS2.p3.6.m6.1.1.3.2">
           𝑔
          </ci>
          <ci id="S3.SS2.p3.6.m6.1.1.3.3.cmml" xref="S3.SS2.p3.6.m6.1.1.3.3">
           𝑜
          </ci>
          <ci id="S3.SS2.p3.6.m6.1.1.3.4.cmml" xref="S3.SS2.p3.6.m6.1.1.3.4">
           𝑎
          </ci>
          <ci id="S3.SS2.p3.6.m6.1.1.3.5.cmml" xref="S3.SS2.p3.6.m6.1.1.3.5">
           𝑙
          </ci>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS2.p3.6.m6.1c">
        x_{goal}
       </annotation>
      </semantics>
     </math>
     , provides an explanation of the task, such as “I will move the blue cube on the bottom right to the blue moon”.
    </p>
   </div>
   <div class="ltx_para" id="S3.SS2.p4">
    <p class="ltx_p" id="S3.SS2.p4.1">
     We also study long-horizon tasks and incorporate training sequences that require the model to plan and execute multiple steps to achieve a goal. This is achieved by defining task stages (start, regular, transition, stop) and incorporating the previous action as context in the language model’s input. This strategy trains the model to recognize task progression and adapt its actions accordingly, enabling it to manage tasks with evolving objectives.
Through this dataset strategy, our model is finely tuned as a versatile tool capable of understanding and executing a wide range of language-guided actions.
    </p>
   </div>
   <figure class="ltx_figure" id="S3.F3">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="506" id="S3.F3.g1" src="/html/2405.04798/assets/figures/env/env1.png" width="598"/>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      <span class="ltx_text" id="S3.F3.2.1.1" style="font-size:90%;">
       Figure 3
      </span>
      :
     </span>
     <span class="ltx_text" id="S3.F3.3.2" style="font-size:90%;">
      A visualization of the two environments along with exemplar tasks that we train and evaluate on. The top depicts the Language Table environment
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib9" title="">
        9
       </a>
       ]
      </cite>
      . We study reasoning tasks (first trajectory) and long horizon tasks (second trajectory). The bottom depicts the CALVIN long horizon benchmark
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib10" title="">
        10
       </a>
       ]
      </cite>
      , in which the agent must sequentially accomplish tasks.
     </span>
    </figcaption>
   </figure>
  </section>
  <section class="ltx_subsection" id="S3.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     <span class="ltx_text" id="S3.SS3.5.1.1">
      III-C
     </span>
    </span>
    <span class="ltx_text ltx_font_italic" id="S3.SS3.6.2">
     Training
    </span>
   </h3>
   <div class="ltx_para" id="S3.SS3.p1">
    <p class="ltx_p" id="S3.SS3.p1.2">
     The training of
     <span class="ltx_text ltx_font_typewriter" id="S3.SS3.p1.2.1">
      LCB
     </span>
     employs a combination of techniques to integrate the LLM and policy components.
We leverage Low Rank Adaptation
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib15" title="">
       15
      </a>
      ]
     </cite>
     (LoRA) for fine-tuning the LLM, allowing for more efficient training.
We adopt a cold start approach to policy training, reminiscent of staged training strategies seen in prior works, by first freezing the action decoder and only fine-tuning the language model.
This preliminary phase focuses on aligning the embeddings produced by the LLM with the feature space of the policy.
We find that adding an additional CLIP loss to regularize the latent embedding
     <math alttext="z_{{\texttt{&lt;ACT&gt;}}}" class="ltx_Math" display="inline" id="S3.SS3.p1.1.m1.1">
      <semantics id="S3.SS3.p1.1.m1.1a">
       <msub id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml">
        <mi id="S3.SS3.p1.1.m1.1.1.2" xref="S3.SS3.p1.1.m1.1.1.2.cmml">
         z
        </mi>
        <mtext class="ltx_mathvariant_monospace" id="S3.SS3.p1.1.m1.1.1.3" xref="S3.SS3.p1.1.m1.1.1.3a.cmml">
         &lt;ACT&gt;
        </mtext>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b">
        <apply id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1">
         <csymbol cd="ambiguous" id="S3.SS3.p1.1.m1.1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1">
          subscript
         </csymbol>
         <ci id="S3.SS3.p1.1.m1.1.1.2.cmml" xref="S3.SS3.p1.1.m1.1.1.2">
          𝑧
         </ci>
         <ci id="S3.SS3.p1.1.m1.1.1.3a.cmml" xref="S3.SS3.p1.1.m1.1.1.3">
          <mtext class="ltx_mathvariant_monospace" id="S3.SS3.p1.1.m1.1.1.3.cmml" mathsize="70%" xref="S3.SS3.p1.1.m1.1.1.3">
           &lt;ACT&gt;
          </mtext>
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">
        z_{{\texttt{&lt;ACT&gt;}}}
       </annotation>
      </semantics>
     </math>
     is necessary, ensuring that the embeddings from the language model remain well aligned with the lower level ground truth text description
     <math alttext="g_{txt}" class="ltx_Math" display="inline" id="S3.SS3.p1.2.m2.1">
      <semantics id="S3.SS3.p1.2.m2.1a">
       <msub id="S3.SS3.p1.2.m2.1.1" xref="S3.SS3.p1.2.m2.1.1.cmml">
        <mi id="S3.SS3.p1.2.m2.1.1.2" xref="S3.SS3.p1.2.m2.1.1.2.cmml">
         g
        </mi>
        <mrow id="S3.SS3.p1.2.m2.1.1.3" xref="S3.SS3.p1.2.m2.1.1.3.cmml">
         <mi id="S3.SS3.p1.2.m2.1.1.3.2" xref="S3.SS3.p1.2.m2.1.1.3.2.cmml">
          t
         </mi>
         <mo id="S3.SS3.p1.2.m2.1.1.3.1" lspace="0em" rspace="0em" xref="S3.SS3.p1.2.m2.1.1.3.1.cmml">
          ​
         </mo>
         <mi id="S3.SS3.p1.2.m2.1.1.3.3" xref="S3.SS3.p1.2.m2.1.1.3.3.cmml">
          x
         </mi>
         <mo id="S3.SS3.p1.2.m2.1.1.3.1a" lspace="0em" rspace="0em" xref="S3.SS3.p1.2.m2.1.1.3.1.cmml">
          ​
         </mo>
         <mi id="S3.SS3.p1.2.m2.1.1.3.4" xref="S3.SS3.p1.2.m2.1.1.3.4.cmml">
          t
         </mi>
        </mrow>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S3.SS3.p1.2.m2.1b">
        <apply id="S3.SS3.p1.2.m2.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1">
         <csymbol cd="ambiguous" id="S3.SS3.p1.2.m2.1.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1">
          subscript
         </csymbol>
         <ci id="S3.SS3.p1.2.m2.1.1.2.cmml" xref="S3.SS3.p1.2.m2.1.1.2">
          𝑔
         </ci>
         <apply id="S3.SS3.p1.2.m2.1.1.3.cmml" xref="S3.SS3.p1.2.m2.1.1.3">
          <times id="S3.SS3.p1.2.m2.1.1.3.1.cmml" xref="S3.SS3.p1.2.m2.1.1.3.1">
          </times>
          <ci id="S3.SS3.p1.2.m2.1.1.3.2.cmml" xref="S3.SS3.p1.2.m2.1.1.3.2">
           𝑡
          </ci>
          <ci id="S3.SS3.p1.2.m2.1.1.3.3.cmml" xref="S3.SS3.p1.2.m2.1.1.3.3">
           𝑥
          </ci>
          <ci id="S3.SS3.p1.2.m2.1.1.3.4.cmml" xref="S3.SS3.p1.2.m2.1.1.3.4">
           𝑡
          </ci>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS3.p1.2.m2.1c">
        g_{txt}
       </annotation>
      </semantics>
     </math>
     of the objective for the pre-trained policy.
In total, our loss function is comprised of 3 terms, and can be expressed as follows:
    </p>
   </div>
   <div class="ltx_para" id="S3.SS3.p2">
    <table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="A2.EGx1">
     <tbody id="S3.E1">
      <tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
       <td class="ltx_eqn_cell ltx_eqn_center_padleft">
       </td>
       <td class="ltx_td ltx_align_right ltx_eqn_cell">
        <math alttext="\displaystyle\mathcal{L}=" class="ltx_Math" display="inline" id="S3.E1.m1.1">
         <semantics id="S3.E1.m1.1a">
          <mrow id="S3.E1.m1.1.1" xref="S3.E1.m1.1.1.cmml">
           <mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.1.1.2" xref="S3.E1.m1.1.1.2.cmml">
            ℒ
           </mi>
           <mo id="S3.E1.m1.1.1.1" xref="S3.E1.m1.1.1.1.cmml">
            =
           </mo>
           <mi id="S3.E1.m1.1.1.3" xref="S3.E1.m1.1.1.3.cmml">
           </mi>
          </mrow>
          <annotation-xml encoding="MathML-Content" id="S3.E1.m1.1b">
           <apply id="S3.E1.m1.1.1.cmml" xref="S3.E1.m1.1.1">
            <eq id="S3.E1.m1.1.1.1.cmml" xref="S3.E1.m1.1.1.1">
            </eq>
            <ci id="S3.E1.m1.1.1.2.cmml" xref="S3.E1.m1.1.1.2">
             ℒ
            </ci>
            <csymbol cd="latexml" id="S3.E1.m1.1.1.3.cmml" xref="S3.E1.m1.1.1.3">
             absent
            </csymbol>
           </apply>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S3.E1.m1.1c">
           \displaystyle\mathcal{L}=
          </annotation>
         </semantics>
        </math>
       </td>
       <td class="ltx_td ltx_align_left ltx_eqn_cell">
        <math alttext="\displaystyle\lambda_{1}\mathcal{L}_{\text{policy}}(\pi_{\theta},o_{t},a_{t},z_{{\texttt{&lt;ACT&gt;}}})" class="ltx_Math" display="inline" id="S3.E1.m2.4">
         <semantics id="S3.E1.m2.4a">
          <mrow id="S3.E1.m2.4.4" xref="S3.E1.m2.4.4.cmml">
           <msub id="S3.E1.m2.4.4.6" xref="S3.E1.m2.4.4.6.cmml">
            <mi id="S3.E1.m2.4.4.6.2" xref="S3.E1.m2.4.4.6.2.cmml">
             λ
            </mi>
            <mn id="S3.E1.m2.4.4.6.3" xref="S3.E1.m2.4.4.6.3.cmml">
             1
            </mn>
           </msub>
           <mo id="S3.E1.m2.4.4.5" lspace="0em" rspace="0em" xref="S3.E1.m2.4.4.5.cmml">
            ​
           </mo>
           <msub id="S3.E1.m2.4.4.7" xref="S3.E1.m2.4.4.7.cmml">
            <mi class="ltx_font_mathcaligraphic" id="S3.E1.m2.4.4.7.2" xref="S3.E1.m2.4.4.7.2.cmml">
             ℒ
            </mi>
            <mtext id="S3.E1.m2.4.4.7.3" xref="S3.E1.m2.4.4.7.3a.cmml">
             policy
            </mtext>
           </msub>
           <mo id="S3.E1.m2.4.4.5a" lspace="0em" rspace="0em" xref="S3.E1.m2.4.4.5.cmml">
            ​
           </mo>
           <mrow id="S3.E1.m2.4.4.4.4" xref="S3.E1.m2.4.4.4.5.cmml">
            <mo id="S3.E1.m2.4.4.4.4.5" stretchy="false" xref="S3.E1.m2.4.4.4.5.cmml">
             (
            </mo>
            <msub id="S3.E1.m2.1.1.1.1.1" xref="S3.E1.m2.1.1.1.1.1.cmml">
             <mi id="S3.E1.m2.1.1.1.1.1.2" xref="S3.E1.m2.1.1.1.1.1.2.cmml">
              π
             </mi>
             <mi id="S3.E1.m2.1.1.1.1.1.3" xref="S3.E1.m2.1.1.1.1.1.3.cmml">
              θ
             </mi>
            </msub>
            <mo id="S3.E1.m2.4.4.4.4.6" xref="S3.E1.m2.4.4.4.5.cmml">
             ,
            </mo>
            <msub id="S3.E1.m2.2.2.2.2.2" xref="S3.E1.m2.2.2.2.2.2.cmml">
             <mi id="S3.E1.m2.2.2.2.2.2.2" xref="S3.E1.m2.2.2.2.2.2.2.cmml">
              o
             </mi>
             <mi id="S3.E1.m2.2.2.2.2.2.3" xref="S3.E1.m2.2.2.2.2.2.3.cmml">
              t
             </mi>
            </msub>
            <mo id="S3.E1.m2.4.4.4.4.7" xref="S3.E1.m2.4.4.4.5.cmml">
             ,
            </mo>
            <msub id="S3.E1.m2.3.3.3.3.3" xref="S3.E1.m2.3.3.3.3.3.cmml">
             <mi id="S3.E1.m2.3.3.3.3.3.2" xref="S3.E1.m2.3.3.3.3.3.2.cmml">
              a
             </mi>
             <mi id="S3.E1.m2.3.3.3.3.3.3" xref="S3.E1.m2.3.3.3.3.3.3.cmml">
              t
             </mi>
            </msub>
            <mo id="S3.E1.m2.4.4.4.4.8" xref="S3.E1.m2.4.4.4.5.cmml">
             ,
            </mo>
            <msub id="S3.E1.m2.4.4.4.4.4" xref="S3.E1.m2.4.4.4.4.4.cmml">
             <mi id="S3.E1.m2.4.4.4.4.4.2" xref="S3.E1.m2.4.4.4.4.4.2.cmml">
              z
             </mi>
             <mtext class="ltx_mathvariant_monospace" id="S3.E1.m2.4.4.4.4.4.3" xref="S3.E1.m2.4.4.4.4.4.3a.cmml">
              &lt;ACT&gt;
             </mtext>
            </msub>
            <mo id="S3.E1.m2.4.4.4.4.9" stretchy="false" xref="S3.E1.m2.4.4.4.5.cmml">
             )
            </mo>
           </mrow>
          </mrow>
          <annotation-xml encoding="MathML-Content" id="S3.E1.m2.4b">
           <apply id="S3.E1.m2.4.4.cmml" xref="S3.E1.m2.4.4">
            <times id="S3.E1.m2.4.4.5.cmml" xref="S3.E1.m2.4.4.5">
            </times>
            <apply id="S3.E1.m2.4.4.6.cmml" xref="S3.E1.m2.4.4.6">
             <csymbol cd="ambiguous" id="S3.E1.m2.4.4.6.1.cmml" xref="S3.E1.m2.4.4.6">
              subscript
             </csymbol>
             <ci id="S3.E1.m2.4.4.6.2.cmml" xref="S3.E1.m2.4.4.6.2">
              𝜆
             </ci>
             <cn id="S3.E1.m2.4.4.6.3.cmml" type="integer" xref="S3.E1.m2.4.4.6.3">
              1
             </cn>
            </apply>
            <apply id="S3.E1.m2.4.4.7.cmml" xref="S3.E1.m2.4.4.7">
             <csymbol cd="ambiguous" id="S3.E1.m2.4.4.7.1.cmml" xref="S3.E1.m2.4.4.7">
              subscript
             </csymbol>
             <ci id="S3.E1.m2.4.4.7.2.cmml" xref="S3.E1.m2.4.4.7.2">
              ℒ
             </ci>
             <ci id="S3.E1.m2.4.4.7.3a.cmml" xref="S3.E1.m2.4.4.7.3">
              <mtext id="S3.E1.m2.4.4.7.3.cmml" mathsize="70%" xref="S3.E1.m2.4.4.7.3">
               policy
              </mtext>
             </ci>
            </apply>
            <vector id="S3.E1.m2.4.4.4.5.cmml" xref="S3.E1.m2.4.4.4.4">
             <apply id="S3.E1.m2.1.1.1.1.1.cmml" xref="S3.E1.m2.1.1.1.1.1">
              <csymbol cd="ambiguous" id="S3.E1.m2.1.1.1.1.1.1.cmml" xref="S3.E1.m2.1.1.1.1.1">
               subscript
              </csymbol>
              <ci id="S3.E1.m2.1.1.1.1.1.2.cmml" xref="S3.E1.m2.1.1.1.1.1.2">
               𝜋
              </ci>
              <ci id="S3.E1.m2.1.1.1.1.1.3.cmml" xref="S3.E1.m2.1.1.1.1.1.3">
               𝜃
              </ci>
             </apply>
             <apply id="S3.E1.m2.2.2.2.2.2.cmml" xref="S3.E1.m2.2.2.2.2.2">
              <csymbol cd="ambiguous" id="S3.E1.m2.2.2.2.2.2.1.cmml" xref="S3.E1.m2.2.2.2.2.2">
               subscript
              </csymbol>
              <ci id="S3.E1.m2.2.2.2.2.2.2.cmml" xref="S3.E1.m2.2.2.2.2.2.2">
               𝑜
              </ci>
              <ci id="S3.E1.m2.2.2.2.2.2.3.cmml" xref="S3.E1.m2.2.2.2.2.2.3">
               𝑡
              </ci>
             </apply>
             <apply id="S3.E1.m2.3.3.3.3.3.cmml" xref="S3.E1.m2.3.3.3.3.3">
              <csymbol cd="ambiguous" id="S3.E1.m2.3.3.3.3.3.1.cmml" xref="S3.E1.m2.3.3.3.3.3">
               subscript
              </csymbol>
              <ci id="S3.E1.m2.3.3.3.3.3.2.cmml" xref="S3.E1.m2.3.3.3.3.3.2">
               𝑎
              </ci>
              <ci id="S3.E1.m2.3.3.3.3.3.3.cmml" xref="S3.E1.m2.3.3.3.3.3.3">
               𝑡
              </ci>
             </apply>
             <apply id="S3.E1.m2.4.4.4.4.4.cmml" xref="S3.E1.m2.4.4.4.4.4">
              <csymbol cd="ambiguous" id="S3.E1.m2.4.4.4.4.4.1.cmml" xref="S3.E1.m2.4.4.4.4.4">
               subscript
              </csymbol>
              <ci id="S3.E1.m2.4.4.4.4.4.2.cmml" xref="S3.E1.m2.4.4.4.4.4.2">
               𝑧
              </ci>
              <ci id="S3.E1.m2.4.4.4.4.4.3a.cmml" xref="S3.E1.m2.4.4.4.4.4.3">
               <mtext class="ltx_mathvariant_monospace" id="S3.E1.m2.4.4.4.4.4.3.cmml" mathsize="70%" xref="S3.E1.m2.4.4.4.4.4.3">
                &lt;ACT&gt;
               </mtext>
              </ci>
             </apply>
            </vector>
           </apply>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S3.E1.m2.4c">
           \displaystyle\lambda_{1}\mathcal{L}_{\text{policy}}(\pi_{\theta},o_{t},a_{t},z_{{\texttt{&lt;ACT&gt;}}})
          </annotation>
         </semantics>
        </math>
       </td>
       <td class="ltx_eqn_cell ltx_eqn_center_padright">
       </td>
       <td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1">
        <span class="ltx_tag ltx_tag_equation ltx_align_right">
         (1)
        </span>
       </td>
      </tr>
     </tbody>
     <tbody id="S3.E2">
      <tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
       <td class="ltx_eqn_cell ltx_eqn_center_padleft">
       </td>
       <td class="ltx_td ltx_align_right ltx_eqn_cell">
        <math alttext="\displaystyle+" class="ltx_Math" display="inline" id="S3.E2.m1.1">
         <semantics id="S3.E2.m1.1a">
          <mo id="S3.E2.m1.1.1" xref="S3.E2.m1.1.1.cmml">
           +
          </mo>
          <annotation-xml encoding="MathML-Content" id="S3.E2.m1.1b">
           <plus id="S3.E2.m1.1.1.cmml" xref="S3.E2.m1.1.1">
           </plus>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S3.E2.m1.1c">
           \displaystyle+
          </annotation>
         </semantics>
        </math>
       </td>
       <td class="ltx_td ltx_align_left ltx_eqn_cell">
        <math alttext="\displaystyle\lambda_{2}\mathcal{L}_{\text{LM}}(f_{\phi},x_{\text{txt}},x_{\text{img}})" class="ltx_Math" display="inline" id="S3.E2.m2.3">
         <semantics id="S3.E2.m2.3a">
          <mrow id="S3.E2.m2.3.3" xref="S3.E2.m2.3.3.cmml">
           <msub id="S3.E2.m2.3.3.5" xref="S3.E2.m2.3.3.5.cmml">
            <mi id="S3.E2.m2.3.3.5.2" xref="S3.E2.m2.3.3.5.2.cmml">
             λ
            </mi>
            <mn id="S3.E2.m2.3.3.5.3" xref="S3.E2.m2.3.3.5.3.cmml">
             2
            </mn>
           </msub>
           <mo id="S3.E2.m2.3.3.4" lspace="0em" rspace="0em" xref="S3.E2.m2.3.3.4.cmml">
            ​
           </mo>
           <msub id="S3.E2.m2.3.3.6" xref="S3.E2.m2.3.3.6.cmml">
            <mi class="ltx_font_mathcaligraphic" id="S3.E2.m2.3.3.6.2" xref="S3.E2.m2.3.3.6.2.cmml">
             ℒ
            </mi>
            <mtext id="S3.E2.m2.3.3.6.3" xref="S3.E2.m2.3.3.6.3a.cmml">
             LM
            </mtext>
           </msub>
           <mo id="S3.E2.m2.3.3.4a" lspace="0em" rspace="0em" xref="S3.E2.m2.3.3.4.cmml">
            ​
           </mo>
           <mrow id="S3.E2.m2.3.3.3.3" xref="S3.E2.m2.3.3.3.4.cmml">
            <mo id="S3.E2.m2.3.3.3.3.4" stretchy="false" xref="S3.E2.m2.3.3.3.4.cmml">
             (
            </mo>
            <msub id="S3.E2.m2.1.1.1.1.1" xref="S3.E2.m2.1.1.1.1.1.cmml">
             <mi id="S3.E2.m2.1.1.1.1.1.2" xref="S3.E2.m2.1.1.1.1.1.2.cmml">
              f
             </mi>
             <mi id="S3.E2.m2.1.1.1.1.1.3" xref="S3.E2.m2.1.1.1.1.1.3.cmml">
              ϕ
             </mi>
            </msub>
            <mo id="S3.E2.m2.3.3.3.3.5" xref="S3.E2.m2.3.3.3.4.cmml">
             ,
            </mo>
            <msub id="S3.E2.m2.2.2.2.2.2" xref="S3.E2.m2.2.2.2.2.2.cmml">
             <mi id="S3.E2.m2.2.2.2.2.2.2" xref="S3.E2.m2.2.2.2.2.2.2.cmml">
              x
             </mi>
             <mtext id="S3.E2.m2.2.2.2.2.2.3" xref="S3.E2.m2.2.2.2.2.2.3a.cmml">
              txt
             </mtext>
            </msub>
            <mo id="S3.E2.m2.3.3.3.3.6" xref="S3.E2.m2.3.3.3.4.cmml">
             ,
            </mo>
            <msub id="S3.E2.m2.3.3.3.3.3" xref="S3.E2.m2.3.3.3.3.3.cmml">
             <mi id="S3.E2.m2.3.3.3.3.3.2" xref="S3.E2.m2.3.3.3.3.3.2.cmml">
              x
             </mi>
             <mtext id="S3.E2.m2.3.3.3.3.3.3" xref="S3.E2.m2.3.3.3.3.3.3a.cmml">
              img
             </mtext>
            </msub>
            <mo id="S3.E2.m2.3.3.3.3.7" stretchy="false" xref="S3.E2.m2.3.3.3.4.cmml">
             )
            </mo>
           </mrow>
          </mrow>
          <annotation-xml encoding="MathML-Content" id="S3.E2.m2.3b">
           <apply id="S3.E2.m2.3.3.cmml" xref="S3.E2.m2.3.3">
            <times id="S3.E2.m2.3.3.4.cmml" xref="S3.E2.m2.3.3.4">
            </times>
            <apply id="S3.E2.m2.3.3.5.cmml" xref="S3.E2.m2.3.3.5">
             <csymbol cd="ambiguous" id="S3.E2.m2.3.3.5.1.cmml" xref="S3.E2.m2.3.3.5">
              subscript
             </csymbol>
             <ci id="S3.E2.m2.3.3.5.2.cmml" xref="S3.E2.m2.3.3.5.2">
              𝜆
             </ci>
             <cn id="S3.E2.m2.3.3.5.3.cmml" type="integer" xref="S3.E2.m2.3.3.5.3">
              2
             </cn>
            </apply>
            <apply id="S3.E2.m2.3.3.6.cmml" xref="S3.E2.m2.3.3.6">
             <csymbol cd="ambiguous" id="S3.E2.m2.3.3.6.1.cmml" xref="S3.E2.m2.3.3.6">
              subscript
             </csymbol>
             <ci id="S3.E2.m2.3.3.6.2.cmml" xref="S3.E2.m2.3.3.6.2">
              ℒ
             </ci>
             <ci id="S3.E2.m2.3.3.6.3a.cmml" xref="S3.E2.m2.3.3.6.3">
              <mtext id="S3.E2.m2.3.3.6.3.cmml" mathsize="70%" xref="S3.E2.m2.3.3.6.3">
               LM
              </mtext>
             </ci>
            </apply>
            <vector id="S3.E2.m2.3.3.3.4.cmml" xref="S3.E2.m2.3.3.3.3">
             <apply id="S3.E2.m2.1.1.1.1.1.cmml" xref="S3.E2.m2.1.1.1.1.1">
              <csymbol cd="ambiguous" id="S3.E2.m2.1.1.1.1.1.1.cmml" xref="S3.E2.m2.1.1.1.1.1">
               subscript
              </csymbol>
              <ci id="S3.E2.m2.1.1.1.1.1.2.cmml" xref="S3.E2.m2.1.1.1.1.1.2">
               𝑓
              </ci>
              <ci id="S3.E2.m2.1.1.1.1.1.3.cmml" xref="S3.E2.m2.1.1.1.1.1.3">
               italic-ϕ
              </ci>
             </apply>
             <apply id="S3.E2.m2.2.2.2.2.2.cmml" xref="S3.E2.m2.2.2.2.2.2">
              <csymbol cd="ambiguous" id="S3.E2.m2.2.2.2.2.2.1.cmml" xref="S3.E2.m2.2.2.2.2.2">
               subscript
              </csymbol>
              <ci id="S3.E2.m2.2.2.2.2.2.2.cmml" xref="S3.E2.m2.2.2.2.2.2.2">
               𝑥
              </ci>
              <ci id="S3.E2.m2.2.2.2.2.2.3a.cmml" xref="S3.E2.m2.2.2.2.2.2.3">
               <mtext id="S3.E2.m2.2.2.2.2.2.3.cmml" mathsize="70%" xref="S3.E2.m2.2.2.2.2.2.3">
                txt
               </mtext>
              </ci>
             </apply>
             <apply id="S3.E2.m2.3.3.3.3.3.cmml" xref="S3.E2.m2.3.3.3.3.3">
              <csymbol cd="ambiguous" id="S3.E2.m2.3.3.3.3.3.1.cmml" xref="S3.E2.m2.3.3.3.3.3">
               subscript
              </csymbol>
              <ci id="S3.E2.m2.3.3.3.3.3.2.cmml" xref="S3.E2.m2.3.3.3.3.3.2">
               𝑥
              </ci>
              <ci id="S3.E2.m2.3.3.3.3.3.3a.cmml" xref="S3.E2.m2.3.3.3.3.3.3">
               <mtext id="S3.E2.m2.3.3.3.3.3.3.cmml" mathsize="70%" xref="S3.E2.m2.3.3.3.3.3.3">
                img
               </mtext>
              </ci>
             </apply>
            </vector>
           </apply>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S3.E2.m2.3c">
           \displaystyle\lambda_{2}\mathcal{L}_{\text{LM}}(f_{\phi},x_{\text{txt}},x_{\text{img}})
          </annotation>
         </semantics>
        </math>
       </td>
       <td class="ltx_eqn_cell ltx_eqn_center_padright">
       </td>
       <td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1">
        <span class="ltx_tag ltx_tag_equation ltx_align_right">
         (2)
        </span>
       </td>
      </tr>
     </tbody>
     <tbody id="S3.E3">
      <tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
       <td class="ltx_eqn_cell ltx_eqn_center_padleft">
       </td>
       <td class="ltx_td ltx_align_right ltx_eqn_cell">
        <math alttext="\displaystyle+" class="ltx_Math" display="inline" id="S3.E3.m1.1">
         <semantics id="S3.E3.m1.1a">
          <mo id="S3.E3.m1.1.1" xref="S3.E3.m1.1.1.cmml">
           +
          </mo>
          <annotation-xml encoding="MathML-Content" id="S3.E3.m1.1b">
           <plus id="S3.E3.m1.1.1.cmml" xref="S3.E3.m1.1.1">
           </plus>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S3.E3.m1.1c">
           \displaystyle+
          </annotation>
         </semantics>
        </math>
       </td>
       <td class="ltx_td ltx_align_left ltx_eqn_cell">
        <math alttext="\displaystyle\lambda_{3}\mathcal{L}_{\text{CLIP}}(z_{{\texttt{&lt;ACT&gt;}}},g_{\text{txt}})" class="ltx_Math" display="inline" id="S3.E3.m2.2">
         <semantics id="S3.E3.m2.2a">
          <mrow id="S3.E3.m2.2.2" xref="S3.E3.m2.2.2.cmml">
           <msub id="S3.E3.m2.2.2.4" xref="S3.E3.m2.2.2.4.cmml">
            <mi id="S3.E3.m2.2.2.4.2" xref="S3.E3.m2.2.2.4.2.cmml">
             λ
            </mi>
            <mn id="S3.E3.m2.2.2.4.3" xref="S3.E3.m2.2.2.4.3.cmml">
             3
            </mn>
           </msub>
           <mo id="S3.E3.m2.2.2.3" lspace="0em" rspace="0em" xref="S3.E3.m2.2.2.3.cmml">
            ​
           </mo>
           <msub id="S3.E3.m2.2.2.5" xref="S3.E3.m2.2.2.5.cmml">
            <mi class="ltx_font_mathcaligraphic" id="S3.E3.m2.2.2.5.2" xref="S3.E3.m2.2.2.5.2.cmml">
             ℒ
            </mi>
            <mtext id="S3.E3.m2.2.2.5.3" xref="S3.E3.m2.2.2.5.3a.cmml">
             CLIP
            </mtext>
           </msub>
           <mo id="S3.E3.m2.2.2.3a" lspace="0em" rspace="0em" xref="S3.E3.m2.2.2.3.cmml">
            ​
           </mo>
           <mrow id="S3.E3.m2.2.2.2.2" xref="S3.E3.m2.2.2.2.3.cmml">
            <mo id="S3.E3.m2.2.2.2.2.3" stretchy="false" xref="S3.E3.m2.2.2.2.3.cmml">
             (
            </mo>
            <msub id="S3.E3.m2.1.1.1.1.1" xref="S3.E3.m2.1.1.1.1.1.cmml">
             <mi id="S3.E3.m2.1.1.1.1.1.2" xref="S3.E3.m2.1.1.1.1.1.2.cmml">
              z
             </mi>
             <mtext class="ltx_mathvariant_monospace" id="S3.E3.m2.1.1.1.1.1.3" xref="S3.E3.m2.1.1.1.1.1.3a.cmml">
              &lt;ACT&gt;
             </mtext>
            </msub>
            <mo id="S3.E3.m2.2.2.2.2.4" xref="S3.E3.m2.2.2.2.3.cmml">
             ,
            </mo>
            <msub id="S3.E3.m2.2.2.2.2.2" xref="S3.E3.m2.2.2.2.2.2.cmml">
             <mi id="S3.E3.m2.2.2.2.2.2.2" xref="S3.E3.m2.2.2.2.2.2.2.cmml">
              g
             </mi>
             <mtext id="S3.E3.m2.2.2.2.2.2.3" xref="S3.E3.m2.2.2.2.2.2.3a.cmml">
              txt
             </mtext>
            </msub>
            <mo id="S3.E3.m2.2.2.2.2.5" stretchy="false" xref="S3.E3.m2.2.2.2.3.cmml">
             )
            </mo>
           </mrow>
          </mrow>
          <annotation-xml encoding="MathML-Content" id="S3.E3.m2.2b">
           <apply id="S3.E3.m2.2.2.cmml" xref="S3.E3.m2.2.2">
            <times id="S3.E3.m2.2.2.3.cmml" xref="S3.E3.m2.2.2.3">
            </times>
            <apply id="S3.E3.m2.2.2.4.cmml" xref="S3.E3.m2.2.2.4">
             <csymbol cd="ambiguous" id="S3.E3.m2.2.2.4.1.cmml" xref="S3.E3.m2.2.2.4">
              subscript
             </csymbol>
             <ci id="S3.E3.m2.2.2.4.2.cmml" xref="S3.E3.m2.2.2.4.2">
              𝜆
             </ci>
             <cn id="S3.E3.m2.2.2.4.3.cmml" type="integer" xref="S3.E3.m2.2.2.4.3">
              3
             </cn>
            </apply>
            <apply id="S3.E3.m2.2.2.5.cmml" xref="S3.E3.m2.2.2.5">
             <csymbol cd="ambiguous" id="S3.E3.m2.2.2.5.1.cmml" xref="S3.E3.m2.2.2.5">
              subscript
             </csymbol>
             <ci id="S3.E3.m2.2.2.5.2.cmml" xref="S3.E3.m2.2.2.5.2">
              ℒ
             </ci>
             <ci id="S3.E3.m2.2.2.5.3a.cmml" xref="S3.E3.m2.2.2.5.3">
              <mtext id="S3.E3.m2.2.2.5.3.cmml" mathsize="70%" xref="S3.E3.m2.2.2.5.3">
               CLIP
              </mtext>
             </ci>
            </apply>
            <interval closure="open" id="S3.E3.m2.2.2.2.3.cmml" xref="S3.E3.m2.2.2.2.2">
             <apply id="S3.E3.m2.1.1.1.1.1.cmml" xref="S3.E3.m2.1.1.1.1.1">
              <csymbol cd="ambiguous" id="S3.E3.m2.1.1.1.1.1.1.cmml" xref="S3.E3.m2.1.1.1.1.1">
               subscript
              </csymbol>
              <ci id="S3.E3.m2.1.1.1.1.1.2.cmml" xref="S3.E3.m2.1.1.1.1.1.2">
               𝑧
              </ci>
              <ci id="S3.E3.m2.1.1.1.1.1.3a.cmml" xref="S3.E3.m2.1.1.1.1.1.3">
               <mtext class="ltx_mathvariant_monospace" id="S3.E3.m2.1.1.1.1.1.3.cmml" mathsize="70%" xref="S3.E3.m2.1.1.1.1.1.3">
                &lt;ACT&gt;
               </mtext>
              </ci>
             </apply>
             <apply id="S3.E3.m2.2.2.2.2.2.cmml" xref="S3.E3.m2.2.2.2.2.2">
              <csymbol cd="ambiguous" id="S3.E3.m2.2.2.2.2.2.1.cmml" xref="S3.E3.m2.2.2.2.2.2">
               subscript
              </csymbol>
              <ci id="S3.E3.m2.2.2.2.2.2.2.cmml" xref="S3.E3.m2.2.2.2.2.2.2">
               𝑔
              </ci>
              <ci id="S3.E3.m2.2.2.2.2.2.3a.cmml" xref="S3.E3.m2.2.2.2.2.2.3">
               <mtext id="S3.E3.m2.2.2.2.2.2.3.cmml" mathsize="70%" xref="S3.E3.m2.2.2.2.2.2.3">
                txt
               </mtext>
              </ci>
             </apply>
            </interval>
           </apply>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S3.E3.m2.2c">
           \displaystyle\lambda_{3}\mathcal{L}_{\text{CLIP}}(z_{{\texttt{&lt;ACT&gt;}}},g_{\text{txt}})
          </annotation>
         </semantics>
        </math>
       </td>
       <td class="ltx_eqn_cell ltx_eqn_center_padright">
       </td>
       <td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1">
        <span class="ltx_tag ltx_tag_equation ltx_align_right">
         (3)
        </span>
       </td>
      </tr>
     </tbody>
    </table>
   </div>
   <figure class="ltx_figure" id="S3.F4">
    <div class="ltx_flex_figure">
     <div class="ltx_flex_cell ltx_flex_size_1">
      <figure class="ltx_figure ltx_figure_panel" id="S3.F4.1">
       <img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="12" id="S3.F4.1.g1" src="/html/2405.04798/assets/x1.png" width="461"/>
      </figure>
     </div>
     <div class="ltx_flex_break">
     </div>
     <div class="ltx_flex_cell ltx_flex_size_2">
      <figure class="ltx_figure ltx_figure_panel" id="S3.F4.sf1">
       <img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="223" id="S3.F4.sf1.g1" src="/html/2405.04798/assets/x2.png" width="461"/>
       <figcaption class="ltx_caption">
        <span class="ltx_tag ltx_tag_figure">
         <span class="ltx_text" id="S3.F4.sf1.3.1.1" style="font-size:90%;">
          (a)
         </span>
        </span>
        <span class="ltx_text ltx_font_bold" id="S3.F4.sf1.4.2" style="font-size:90%;">
         Long Horizon
         <span class="ltx_text ltx_font_medium" id="S3.F4.sf1.4.2.1">
          Success rate for the multi-step tasks on Language Table. The task requires shorting some blocks based on color or shape in a given direction. The environment only provides the high level objective to each method. This task requires the policy to have more long term planning capabilities, whether explicitly or implicitly.
         </span>
        </span>
       </figcaption>
      </figure>
     </div>
     <div class="ltx_flex_cell ltx_flex_size_2">
      <figure class="ltx_figure ltx_figure_panel" id="S3.F4.sf2">
       <img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="227" id="S3.F4.sf2.g1" src="/html/2405.04798/assets/x3.png" width="461"/>
       <figcaption class="ltx_caption">
        <span class="ltx_tag ltx_tag_figure">
         <span class="ltx_text" id="S3.F4.sf2.3.1.1" style="font-size:90%;">
          (b)
         </span>
        </span>
        <span class="ltx_text" id="S3.F4.sf2.4.2" style="font-size:90%;">
         <span class="ltx_text ltx_font_bold" id="S3.F4.sf2.4.2.1">
          Reasoning:
         </span>
         Success rate for the reasoning tasks on Language Table. The reasoning task is specified as a variant of ”There is a block that is closest to i.e., top right corner. Push that block to the other block of the same shape/color.” This task requires the agent to understand object semantics and spacial relationships.
        </span>
       </figcaption>
      </figure>
     </div>
    </div>
    <figcaption class="ltx_caption">
     <span class="ltx_tag ltx_tag_figure">
      <span class="ltx_text" id="S3.F4.4.1.1" style="font-size:90%;">
       Figure 4
      </span>
      :
     </span>
     <span class="ltx_text" id="S3.F4.5.2" style="font-size:90%;">
      Task success rates on Language table. The tasks are drawn from the higher level Language Table tasks from PALM-E
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib32" title="">
        32
       </a>
       ]
      </cite>
      . LangTable refers to the original language table policy
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib9" title="">
        9
       </a>
       ]
      </cite>
      . +LLaVA (frozen) refers to composing the original language table with a frozen LLaVA model and few shot prompting. +GPT-4V similarly refers to composing the original policy with GPT-4V. +LLaVA (finetuned) refers to finetuning the LLaVA policy on our mixture dataset on the language only, then composing it with the policy. Our results show that leveraging
      <span class="ltx_text ltx_font_typewriter" id="S3.F4.5.2.1">
       LCB
      </span>
      is effective on tasks that require additional reasoning and planning. Note that the same model is evaluated between the long horizon and reasoning tasks.
     </span>
    </figcaption>
   </figure>
  </section>
 </section>
 <section class="ltx_section" id="S4">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    IV
   </span>
   <span class="ltx_text ltx_font_smallcaps" id="S4.1.1">
    Results
   </span>
  </h2>
  <div class="ltx_para" id="S4.p1">
   <p class="ltx_p" id="S4.p1.1">
    We systematically evaluated
    <span class="ltx_text ltx_font_typewriter" id="S4.p1.1.1">
     LCB
    </span>
    across a diverse set of environments and tasks to demonstrate the efficacy of integrating a pretrained Large Language Model (LLM) with a domain-specific, pretrained low-level policy. Our primary objective was to study the capabilities of the policy, specifically its high-level language understanding and low-level control.
Through our experiments, we aim to answer the following questions:
   </p>
  </div>
  <div class="ltx_para" id="S4.p2">
   <ul class="ltx_itemize" id="S4.I1">
    <li class="ltx_item" id="S4.I1.i1" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para" id="S4.I1.i1.p1">
      <p class="ltx_p" id="S4.I1.i1.p1.1">
       Does
       <span class="ltx_text ltx_font_typewriter" id="S4.I1.i1.p1.1.1">
        LCB
       </span>
       enable learning a bridge between the LLM and the policy more effectively than pure language?
      </p>
     </div>
    </li>
    <li class="ltx_item" id="S4.I1.i2" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para" id="S4.I1.i2.p1">
      <p class="ltx_p" id="S4.I1.i2.p1.1">
       Can
       <span class="ltx_text ltx_font_typewriter" id="S4.I1.i2.p1.1.1">
        LCB
       </span>
       leverage the pretrained capabilities of LLMs to solve long horizon tasks by decomposing the high level goals into the step by step latent commands?
      </p>
     </div>
    </li>
    <li class="ltx_item" id="S4.I1.i3" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para" id="S4.I1.i3.p1">
      <p class="ltx_p" id="S4.I1.i3.p1.1">
       Can
       <span class="ltx_text ltx_font_typewriter" id="S4.I1.i3.p1.1.1">
        LCB
       </span>
       outperform other baseline methods that leverage close-sourced state of the art LLMs such as GPT-4V?
      </p>
     </div>
    </li>
   </ul>
  </div>
  <div class="ltx_para" id="S4.p3">
   <p class="ltx_p" id="S4.p3.1">
    To answer these questions, we study how
    <span class="ltx_text ltx_font_typewriter" id="S4.p3.1.1">
     LCB
    </span>
    performs under various reasoning and long horizon settings in both the Language Table and CALVIN benchmarks. See
    <a class="ltx_ref ltx_refmacro_autoref" href="#S3.F3" title="Figure 3 ‣ III-B Data Processing ‣ III Method ‣ From LLMs to Actions: Latent Codes as Bridges in Hierarchical Robot Control">
     <span class="ltx_text ltx_ref_tag">
      Figure 3
     </span>
    </a>
    for a visualization of the environments and example tasks.
   </p>
  </div>
  <section class="ltx_subsection" id="S4.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     <span class="ltx_text" id="S4.SS1.5.1.1">
      IV-A
     </span>
    </span>
    <span class="ltx_text ltx_font_italic" id="S4.SS1.6.2">
     Evaluation on Language Table
    </span>
   </h3>
   <div class="ltx_para" id="S4.SS1.p1">
    <p class="ltx_p" id="S4.SS1.p1.1">
     Language Table offers a simulated tabletop environment for executing language-conditioned manipulation tasks
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib9" title="">
       9
      </a>
      ]
     </cite>
     . The environment features a flat surface populated with blocks of various colors and shapes, alongside a robot with 2D action space. Language Table provides observations in the form of the robot end effector position and third-person camera images. Despite its simplicity, it provides a reproducible and comprehensive environment to study challenges at the interface of high level language and low level contact-rich dynamics and feedback control.
    </p>
   </div>
   <figure class="ltx_table" id="S4.T1">
    <figcaption class="ltx_caption" style="font-size:90%;">
     <span class="ltx_tag ltx_tag_table">
      TABLE I:
     </span>
     Comparison on the original Language Table benchmark tasks. LangTable is the original language table policy
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib9" title="">
       9
      </a>
      ]
     </cite>
     .
     <span class="ltx_text ltx_font_typewriter" id="S4.T1.11.1">
      LCB
     </span>
     is our method applied only to the original Language Table dataset. We see that
     <span class="ltx_text ltx_font_typewriter" id="S4.T1.12.2">
      LCB
     </span>
     can help improve task performance by leveraging the vision language model for feature extraction. The tasks are: Block to Block (B2B), Block to Block Relative Location (B2RL), Seprate (S), Block to Relative Location (B2RL), and Block to Absolute Location (B2AL).
    </figcaption>
    <table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T1.13">
     <thead class="ltx_thead">
      <tr class="ltx_tr" id="S4.T1.13.1.1">
       <th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S4.T1.13.1.1.1">
        <span class="ltx_text" id="S4.T1.13.1.1.1.1" style="font-size:90%;">
         Model
        </span>
       </th>
       <th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S4.T1.13.1.1.2">
        <span class="ltx_text" id="S4.T1.13.1.1.2.1" style="font-size:90%;">
         B2B
        </span>
       </th>
       <th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S4.T1.13.1.1.3">
        <span class="ltx_text" id="S4.T1.13.1.1.3.1" style="font-size:90%;">
         B2BRL
        </span>
       </th>
       <th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S4.T1.13.1.1.4">
        <span class="ltx_text" id="S4.T1.13.1.1.4.1" style="font-size:90%;">
         S
        </span>
       </th>
       <th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S4.T1.13.1.1.5">
        <span class="ltx_text" id="S4.T1.13.1.1.5.1" style="font-size:90%;">
         B2RL
        </span>
       </th>
       <th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S4.T1.13.1.1.6">
        <span class="ltx_text" id="S4.T1.13.1.1.6.1" style="font-size:90%;">
         B2AL
        </span>
       </th>
       <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T1.13.1.1.7">
        <span class="ltx_text ltx_font_italic" id="S4.T1.13.1.1.7.1" style="font-size:90%;">
         Avg
        </span>
       </th>
      </tr>
     </thead>
     <tbody class="ltx_tbody">
      <tr class="ltx_tr" id="S4.T1.13.2.1">
       <td class="ltx_td ltx_align_left ltx_border_t" id="S4.T1.13.2.1.1">
        <span class="ltx_text" id="S4.T1.13.2.1.1.1" style="font-size:90%;">
         LangTable
        </span>
       </td>
       <td class="ltx_td ltx_align_left ltx_border_t" id="S4.T1.13.2.1.2">
        <span class="ltx_text" id="S4.T1.13.2.1.2.1" style="font-size:90%;">
         0.88
        </span>
       </td>
       <td class="ltx_td ltx_align_left ltx_border_t" id="S4.T1.13.2.1.3">
        <span class="ltx_text" id="S4.T1.13.2.1.3.1" style="font-size:90%;">
         0.70
        </span>
       </td>
       <td class="ltx_td ltx_align_left ltx_border_t" id="S4.T1.13.2.1.4">
        <span class="ltx_text" id="S4.T1.13.2.1.4.1" style="font-size:90%;">
         0.94
        </span>
       </td>
       <td class="ltx_td ltx_align_left ltx_border_t" id="S4.T1.13.2.1.5">
        <span class="ltx_text" id="S4.T1.13.2.1.5.1" style="font-size:90%;">
         0.68
        </span>
       </td>
       <td class="ltx_td ltx_align_left ltx_border_t" id="S4.T1.13.2.1.6">
        <span class="ltx_text" id="S4.T1.13.2.1.6.1" style="font-size:90%;">
         0.65
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.13.2.1.7">
        <span class="ltx_text" id="S4.T1.13.2.1.7.1" style="font-size:90%;">
         0.77
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S4.T1.13.3.2">
       <td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T1.13.3.2.1">
        <span class="ltx_text ltx_font_typewriter" id="S4.T1.13.3.2.1.1" style="font-size:90%;">
         LCB
        </span>
       </td>
       <td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T1.13.3.2.2">
        <span class="ltx_text" id="S4.T1.13.3.2.2.1" style="font-size:90%;">
         0.90
        </span>
       </td>
       <td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T1.13.3.2.3">
        <span class="ltx_text" id="S4.T1.13.3.2.3.1" style="font-size:90%;">
         0.66
        </span>
       </td>
       <td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T1.13.3.2.4">
        <span class="ltx_text" id="S4.T1.13.3.2.4.1" style="font-size:90%;">
         0.99
        </span>
       </td>
       <td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T1.13.3.2.5">
        <span class="ltx_text" id="S4.T1.13.3.2.5.1" style="font-size:90%;">
         0.73
        </span>
       </td>
       <td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T1.13.3.2.6">
        <span class="ltx_text" id="S4.T1.13.3.2.6.1" style="font-size:90%;">
         0.71
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.13.3.2.7">
        <span class="ltx_text ltx_font_bold" id="S4.T1.13.3.2.7.1" style="font-size:90%;">
         0.80
        </span>
       </td>
      </tr>
     </tbody>
    </table>
   </figure>
   <div class="ltx_para" id="S4.SS1.p2">
    <p class="ltx_p" id="S4.SS1.p2.1">
     We investigate the benefit of using
     <span class="ltx_text ltx_font_typewriter" id="S4.SS1.p2.1.1">
      LCB
     </span>
     on the original Language Table benchmark. Here we apply our method using the same dataset that the original language table model was trained on, translating the original language instructions into chat interactions with action tokens as specified in
     <a class="ltx_ref ltx_refmacro_autoref" href="#S3" title="III Method ‣ From LLMs to Actions: Latent Codes as Bridges in Hierarchical Robot Control">
      <span class="ltx_text ltx_ref_tag">
       section III
      </span>
     </a>
     . As shown in
     <a class="ltx_ref ltx_refmacro_autoref" href="#S4.T1" title="TABLE I ‣ IV-A Evaluation on Language Table ‣ IV Results ‣ From LLMs to Actions: Latent Codes as Bridges in Hierarchical Robot Control">
      <span class="ltx_text ltx_ref_tag">
       Table I
      </span>
     </a>
     , with the end to end optimization with the pretrained LLM, the success rate across the benchmark matches or exceeds the baseline Language Table approach. This signifies that
     <span class="ltx_text ltx_font_typewriter" id="S4.SS1.p2.1.2">
      LCB
     </span>
     is able to seamlessly adapt a pretrained LLM and policy together. We suspect that this is due to the flexibility in the latent representation
     <math alttext="z_{{\texttt{&lt;ACT&gt;}}}" class="ltx_Math" display="inline" id="S4.SS1.p2.1.m1.1">
      <semantics id="S4.SS1.p2.1.m1.1a">
       <msub id="S4.SS1.p2.1.m1.1.1" xref="S4.SS1.p2.1.m1.1.1.cmml">
        <mi id="S4.SS1.p2.1.m1.1.1.2" xref="S4.SS1.p2.1.m1.1.1.2.cmml">
         z
        </mi>
        <mtext class="ltx_mathvariant_monospace" id="S4.SS1.p2.1.m1.1.1.3" xref="S4.SS1.p2.1.m1.1.1.3a.cmml">
         &lt;ACT&gt;
        </mtext>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S4.SS1.p2.1.m1.1b">
        <apply id="S4.SS1.p2.1.m1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1">
         <csymbol cd="ambiguous" id="S4.SS1.p2.1.m1.1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1">
          subscript
         </csymbol>
         <ci id="S4.SS1.p2.1.m1.1.1.2.cmml" xref="S4.SS1.p2.1.m1.1.1.2">
          𝑧
         </ci>
         <ci id="S4.SS1.p2.1.m1.1.1.3a.cmml" xref="S4.SS1.p2.1.m1.1.1.3">
          <mtext class="ltx_mathvariant_monospace" id="S4.SS1.p2.1.m1.1.1.3.cmml" mathsize="70%" xref="S4.SS1.p2.1.m1.1.1.3">
           &lt;ACT&gt;
          </mtext>
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS1.p2.1.m1.1c">
        z_{{\texttt{&lt;ACT&gt;}}}
       </annotation>
      </semantics>
     </math>
     , allowed for by our approach as well as additional capacity afforded my the language model.
    </p>
   </div>
   <div class="ltx_para" id="S4.SS1.p3">
    <p class="ltx_p" id="S4.SS1.p3.1">
     We next investigate more complex language tasks that require reasoning and planning capabilities. We collect a small dataset for each capability, training models to compare the following approaches:
    </p>
    <ul class="ltx_itemize" id="S4.I2">
     <li class="ltx_item" id="S4.I2.i1" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S4.I2.i1.p1">
       <p class="ltx_p" id="S4.I2.i1.p1.1">
        <span class="ltx_text ltx_font_bold" id="S4.I2.i1.p1.1.1">
         LangTable:
        </span>
        The original Language Table Policy, as provided by
        <cite class="ltx_cite ltx_citemacro_cite">
         [
         <a class="ltx_ref" href="#bib.bib9" title="">
          9
         </a>
         ]
        </cite>
        .
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S4.I2.i2" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S4.I2.i2.p1">
       <p class="ltx_p" id="S4.I2.i2.p1.1">
        <span class="ltx_text ltx_font_bold" id="S4.I2.i2.p1.1.1">
         LangTable + LLaVA (Frozen):
        </span>
        The combination of the original policy and a non-fine-tuned LLaVA model interfacing through language. We prompt LLaVA to output language commands in the format and style as expected by LangTable.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S4.I2.i3" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S4.I2.i3.p1">
       <p class="ltx_p" id="S4.I2.i3.p1.1">
        <span class="ltx_text ltx_font_bold" id="S4.I2.i3.p1.1.1">
         LangTable + GPT-4V:
        </span>
        The integration of LangTable with the state-of-the-art proprietary Vision Language Model (GPT-4V). In order to bootstrap the spatial understanding of GPT-4V, we also incorporate the Set of Marker (SOM)
        <cite class="ltx_cite ltx_citemacro_cite">
         [
         <a class="ltx_ref" href="#bib.bib33" title="">
          33
         </a>
         ]
        </cite>
        technique to enhance the GPT-4V’s capability. We further include multi-modal few show contexts including language explanation of the tasks and image examples. More details are provided in Appendix
        <a class="ltx_ref" href="#A2" title="Appendix B GPT-4V Prompting Details ‣ From LLMs to Actions: Latent Codes as Bridges in Hierarchical Robot Control">
         <span class="ltx_text ltx_ref_tag">
          B
         </span>
        </a>
        .
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S4.I2.i4" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S4.I2.i4.p1">
       <p class="ltx_p" id="S4.I2.i4.p1.1">
        <span class="ltx_text ltx_font_bold" id="S4.I2.i4.p1.1.1">
         LangTable + LLaVA (Fine-tuned):
        </span>
        The original policy augmented by a LLaVA model that has been fine-tuned on the exact language needed for the action policy for the given task.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S4.I2.i5" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S4.I2.i5.p1">
       <p class="ltx_p" id="S4.I2.i5.p1.1">
        <span class="ltx_text ltx_font_typewriter ltx_font_bold" id="S4.I2.i5.p1.1.1">
         LCB
         <span class="ltx_text ltx_font_serif" id="S4.I2.i5.p1.1.1.1">
          :
         </span>
        </span>
        We take a pretrained LLaVA model and the pre-trained LangTable policy and apply
        <span class="ltx_text ltx_font_typewriter" id="S4.I2.i5.p1.1.2">
         LCB
        </span>
        , learning a latent interface between the two on the respective instruction dataset.
       </p>
      </div>
     </li>
    </ul>
   </div>
   <div class="ltx_para" id="S4.SS1.p4">
    <p class="ltx_p" id="S4.SS1.p4.1">
     Results for long horizon performance are provided in
     <a class="ltx_ref ltx_refmacro_autoref" href="#S3.F4.sf1" title="4(a) ‣ Figure 4 ‣ III-C Training ‣ III Method ‣ From LLMs to Actions: Latent Codes as Bridges in Hierarchical Robot Control">
      <span class="ltx_text ltx_ref_tag">
       4(a)
      </span>
     </a>
     . In this task, the agent must sort blocks based on shape or color into a specified corner of the board, requiring a long sequence of actions from which the agent could greatly benefit through high-level planning. We see that
     <span class="ltx_text ltx_font_typewriter" id="S4.SS1.p4.1.1">
      LCB
     </span>
     exhibits a competency for handling such tasks, as indicated by the heightened success rates, improving on pure language interface baselines. This is attributable to the method’s ability to generate a coherent sequence of latent action embeddings that guide the policy through the task’s duration, facilitating a more consistent and accurate alignment with the sequential nature of the task. During evaluation we run the higher level language model at a slower rate than the lower level policy, only updating the language models output every 40 environment steps. We find that this increases computational efficiency without compromising task performance suggesting the effectiveness of the model hierarchy.
    </p>
   </div>
   <div class="ltx_para" id="S4.SS1.p5">
    <p class="ltx_p" id="S4.SS1.p5.1">
     Results for reasoning performance are provided in
     <a class="ltx_ref ltx_refmacro_autoref" href="#S3.F4.sf2" title="4(b) ‣ Figure 4 ‣ III-C Training ‣ III Method ‣ From LLMs to Actions: Latent Codes as Bridges in Hierarchical Robot Control">
      <span class="ltx_text ltx_ref_tag">
       4(b)
      </span>
     </a>
     . Tasks here are of the form “There is a block that is closest to {corner}. Push that block to the other block of the same {shape/color}”. In order to successfully accomplish this task, the agent must identify which block is located closest to a given corner, identify the relevant property (i.e. shape or color) and consolidate that understanding into an executable instruction. We see that our approach is able to outperform baselines that involve zero-shot prompting as well as naively fine-tuning the language model to output the translated robot task. We see that fine-tuning the language model to output the ground truth language primitive is effective in reaching parity with the oracle language baseline, but that
     <span class="ltx_text ltx_font_typewriter" id="S4.SS1.p5.1.1">
      LCB
     </span>
     is able to match and even exceed that.
    </p>
   </div>
   <div class="ltx_para" id="S4.SS1.p6">
    <p class="ltx_p" id="S4.SS1.p6.1">
     We provide a qualitative assessment of the language output from the various top performing approaches in
     <a class="ltx_ref ltx_refmacro_autoref" href="#S4.F5" title="Figure 5 ‣ IV-A Evaluation on Language Table ‣ IV Results ‣ From LLMs to Actions: Latent Codes as Bridges in Hierarchical Robot Control">
      <span class="ltx_text ltx_ref_tag">
       Figure 5
      </span>
     </a>
     . LangTable + GPT-4V requires heavy prompt engineering and additional string parsing to extract out the final policy. LangTable + LLaVA is effectively fine-tuned by outputting the direct low level text command to the policy, but no longer is able to maintain a chat like interface to the user. In contrast,
     <span class="ltx_text ltx_font_typewriter" id="S4.SS1.p6.1.1">
      LCB
     </span>
     is able to output an effective embedding for the low level policy while also verbalizing its reasoning. This decouples the low level policy conditioning from the language models text outputs, offering increased flexibility during instruction fine-tuning.
    </p>
   </div>
   <figure class="ltx_figure" id="S4.F5">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="436" id="S4.F5.g1" src="/html/2405.04798/assets/figures/response_comparison/response.png" width="598"/>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      <span class="ltx_text" id="S4.F5.5.1.1" style="font-size:90%;">
       Figure 5
      </span>
      :
     </span>
     <span class="ltx_text" id="S4.F5.6.2" style="font-size:90%;">
      A comparison of the flow from a high level language task to the policy for different approaches.
      <span class="ltx_text ltx_font_bold" id="S4.F5.6.2.1">
       (Left) LangTable + GPT-4V
      </span>
      requires a prompt to understand the task and desired output format. GPT-4V can provide language reasoning to allow the user to introspect the decision process of the language model, but requires additional parsing to extract the relevant language instruction to provide to the model.
      <span class="ltx_text ltx_font_bold" id="S4.F5.6.2.2">
       (Middle) LangTable + LLaVA (Fine-tuned)
      </span>
      fine-tunes the language model to output the exact language instruction as in the training data, effectively acting as a language interface converter. This approach, while effective, removes the chat like capability from the language model.
      <span class="ltx_text ltx_font_bold" id="S4.F5.6.2.3">
       (Right)
       <span class="ltx_text ltx_font_typewriter" id="S4.F5.6.2.3.1">
        LCB
       </span>
      </span>
      fine-tunes the language model with a chat like interface and action token. The policy is directly conditioned on the latent feature from the action token provided by the model, enabling effective policy conditioning without losing the chat like language model interface.
     </span>
    </figcaption>
   </figure>
  </section>
  <section class="ltx_subsection" id="S4.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     <span class="ltx_text" id="S4.SS2.5.1.1">
      IV-B
     </span>
    </span>
    <span class="ltx_text ltx_font_italic" id="S4.SS2.6.2">
     Evaluation on CALVIN
    </span>
   </h3>
   <div class="ltx_para" id="S4.SS2.p1">
    <p class="ltx_p" id="S4.SS2.p1.1">
     CALVIN
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib10" title="">
       10
      </a>
      ]
     </cite>
     is an open-source simulated benchmark designed for learning long-horizon tasks conditioned by language. The environment features a 7-DOF Franka Emika Panda robotic arm equipped with a parallel gripper, situated at a desk with a variety of articulated furniture and objects for interaction. In each experiment, the robot needs to solve a sequence of complex full 6D manipulation tasks governed by real-world physics and guided by a series of language instructions. Each subtask is paired by a specific language instruction; upon successful completion, the robot proceeds to the next subtask accompanied by a new instruction. CALVIN encompasses four distinct environments A, B, C and D, with a shared set of language instructions and subtasks.
    </p>
   </div>
   <figure class="ltx_table" id="S4.T2">
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_table">
      <span class="ltx_text" id="S4.T2.2.1.1" style="font-size:90%;">
       TABLE II
      </span>
      :
     </span>
     <span class="ltx_text" id="S4.T2.3.2" style="font-size:90%;">
      Task completion rates for various methods on CALVIN
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib10" title="">
        10
       </a>
       ]
      </cite>
      long-horizon tasks. All methods were trained exclusively on the ABC split of Calvin with the original language annotations and tested on split D with GPT-4 enriched language annotations, following the RoboFlamingo enriched instruction evaluation setting
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib34" title="">
        34
       </a>
       ]
      </cite>
      . *RF denotes our own training of the RoboFlamingo model on the ABC Calvin split. 3DDA denotes the policy from 3D Diffuser Actor
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib35" title="">
        35
       </a>
       ]
      </cite>
      .
     </span>
    </figcaption>
    <table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T2.4">
     <tbody class="ltx_tbody">
      <tr class="ltx_tr" id="S4.T2.4.1.1">
       <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T2.4.1.1.1" rowspan="6" style="padding:0.9pt 8.0pt;">
        <span class="ltx_text" id="S4.T2.4.1.1.1.1" style="font-size:90%;">
         <span class="ltx_inline-block ltx_transformed_outer" id="S4.T2.4.1.1.1.1.1" style="width:33.0pt;height:85.3pt;vertical-align:-39.5pt;">
          <span class="ltx_transformed_inner" style="width:85.4pt;transform:translate(-26.18pt,20.03pt) rotate(-90deg) ;">
           <span class="ltx_block ltx_parbox ltx_align_middle" id="S4.T2.4.1.1.1.1.1.1" style="width:85.4pt;">
            <span class="ltx_p" id="S4.T2.4.1.1.1.1.1.1.1">
             Task Completed
            </span>
            <span class="ltx_p" id="S4.T2.4.1.1.1.1.1.1.2">
             in a Sequence
            </span>
            <span class="ltx_p" id="S4.T2.4.1.1.1.1.1.1.3">
             (Success Rate)
            </span>
           </span>
          </span>
         </span>
        </span>
       </th>
       <th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S4.T2.4.1.1.2" style="padding:0.9pt 8.0pt;">
        <span class="ltx_text" id="S4.T2.4.1.1.2.1" style="font-size:90%;">
         Model
        </span>
       </th>
       <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T2.4.1.1.3" style="padding:0.9pt 8.0pt;">
        <span class="ltx_text" id="S4.T2.4.1.1.3.1" style="font-size:90%;">
         RF
        </span>
        <cite class="ltx_cite ltx_citemacro_cite">
         <span class="ltx_text" id="S4.T2.4.1.1.3.2.1" style="font-size:90%;">
          [
         </span>
         <a class="ltx_ref" href="#bib.bib36" title="">
          36
         </a>
         <span class="ltx_text" id="S4.T2.4.1.1.3.3.2" style="font-size:90%;">
          ]
         </span>
        </cite>
       </th>
       <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T2.4.1.1.4" style="padding:0.9pt 8.0pt;">
        <span class="ltx_text" id="S4.T2.4.1.1.4.1" style="font-size:90%;">
         3DDA
        </span>
        <cite class="ltx_cite ltx_citemacro_cite">
         <span class="ltx_text" id="S4.T2.4.1.1.4.2.1" style="font-size:90%;">
          [
         </span>
         <a class="ltx_ref" href="#bib.bib35" title="">
          35
         </a>
         <span class="ltx_text" id="S4.T2.4.1.1.4.3.2" style="font-size:90%;">
          ]
         </span>
        </cite>
       </th>
       <th class="ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S4.T2.4.1.1.5" style="padding:0.9pt 8.0pt;">
        <span class="ltx_text ltx_font_typewriter ltx_font_bold" id="S4.T2.4.1.1.5.1" style="font-size:90%;">
         LCB
        </span>
       </th>
      </tr>
      <tr class="ltx_tr" id="S4.T2.4.2.2">
       <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.4.2.2.1" style="padding:0.9pt 8.0pt;">
        <span class="ltx_text" id="S4.T2.4.2.2.1.1" style="font-size:90%;">
         1/5
        </span>
       </td>
       <td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.4.2.2.2" style="padding:0.9pt 8.0pt;">
        <span class="ltx_text" id="S4.T2.4.2.2.2.1" style="font-size:90%;">
         0.620
        </span>
       </td>
       <td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.4.2.2.3" style="padding:0.9pt 8.0pt;">
        <span class="ltx_text" id="S4.T2.4.2.2.3.1" style="font-size:90%;">
         0.652
        </span>
       </td>
       <td class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t" id="S4.T2.4.2.2.4" style="padding:0.9pt 8.0pt;">
        <span class="ltx_text ltx_font_bold" id="S4.T2.4.2.2.4.1" style="font-size:90%;">
         0.736
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S4.T2.4.3.3">
       <td class="ltx_td ltx_align_center" id="S4.T2.4.3.3.1" style="padding:0.9pt 8.0pt;">
        <span class="ltx_text" id="S4.T2.4.3.3.1.1" style="font-size:90%;">
         2/5
        </span>
       </td>
       <td class="ltx_td ltx_align_left" id="S4.T2.4.3.3.2" style="padding:0.9pt 8.0pt;">
        <span class="ltx_text" id="S4.T2.4.3.3.2.1" style="font-size:90%;">
         0.330
        </span>
       </td>
       <td class="ltx_td ltx_align_left" id="S4.T2.4.3.3.3" style="padding:0.9pt 8.0pt;">
        <span class="ltx_text" id="S4.T2.4.3.3.3.1" style="font-size:90%;">
         0.391
        </span>
       </td>
       <td class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T2.4.3.3.4" style="padding:0.9pt 8.0pt;">
        <span class="ltx_text ltx_font_bold" id="S4.T2.4.3.3.4.1" style="font-size:90%;">
         0.502
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S4.T2.4.4.4">
       <td class="ltx_td ltx_align_center" id="S4.T2.4.4.4.1" style="padding:0.9pt 8.0pt;">
        <span class="ltx_text" id="S4.T2.4.4.4.1.1" style="font-size:90%;">
         3/5
        </span>
       </td>
       <td class="ltx_td ltx_align_left" id="S4.T2.4.4.4.2" style="padding:0.9pt 8.0pt;">
        <span class="ltx_text" id="S4.T2.4.4.4.2.1" style="font-size:90%;">
         0.164
        </span>
       </td>
       <td class="ltx_td ltx_align_left" id="S4.T2.4.4.4.3" style="padding:0.9pt 8.0pt;">
        <span class="ltx_text" id="S4.T2.4.4.4.3.1" style="font-size:90%;">
         0.203
        </span>
       </td>
       <td class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T2.4.4.4.4" style="padding:0.9pt 8.0pt;">
        <span class="ltx_text ltx_font_bold" id="S4.T2.4.4.4.4.1" style="font-size:90%;">
         0.285
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S4.T2.4.5.5">
       <td class="ltx_td ltx_align_center" id="S4.T2.4.5.5.1" style="padding:0.9pt 8.0pt;">
        <span class="ltx_text" id="S4.T2.4.5.5.1.1" style="font-size:90%;">
         4/5
        </span>
       </td>
       <td class="ltx_td ltx_align_left" id="S4.T2.4.5.5.2" style="padding:0.9pt 8.0pt;">
        <span class="ltx_text" id="S4.T2.4.5.5.2.1" style="font-size:90%;">
         0.086
        </span>
       </td>
       <td class="ltx_td ltx_align_left" id="S4.T2.4.5.5.3" style="padding:0.9pt 8.0pt;">
        <span class="ltx_text" id="S4.T2.4.5.5.3.1" style="font-size:90%;">
         0.117
        </span>
       </td>
       <td class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T2.4.5.5.4" style="padding:0.9pt 8.0pt;">
        <span class="ltx_text ltx_font_bold" id="S4.T2.4.5.5.4.1" style="font-size:90%;">
         0.160
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S4.T2.4.6.6">
       <td class="ltx_td ltx_align_center" id="S4.T2.4.6.6.1" style="padding:0.9pt 8.0pt;">
        <span class="ltx_text" id="S4.T2.4.6.6.1.1" style="font-size:90%;">
         5/5
        </span>
       </td>
       <td class="ltx_td ltx_align_left" id="S4.T2.4.6.6.2" style="padding:0.9pt 8.0pt;">
        <span class="ltx_text" id="S4.T2.4.6.6.2.1" style="font-size:90%;">
         0.046
        </span>
       </td>
       <td class="ltx_td ltx_align_left" id="S4.T2.4.6.6.3" style="padding:0.9pt 8.0pt;">
        <span class="ltx_text" id="S4.T2.4.6.6.3.1" style="font-size:90%;">
         0.061
        </span>
       </td>
       <td class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T2.4.6.6.4" style="padding:0.9pt 8.0pt;">
        <span class="ltx_text ltx_font_bold" id="S4.T2.4.6.6.4.1" style="font-size:90%;">
         0.099
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S4.T2.4.7.7">
       <td class="ltx_td ltx_border_bb ltx_border_t" id="S4.T2.4.7.7.1" style="padding:0.9pt 8.0pt;">
       </td>
       <td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S4.T2.4.7.7.2" style="padding:0.9pt 8.0pt;">
        <span class="ltx_text" id="S4.T2.4.7.7.2.1" style="font-size:90%;">
         Avg Len
        </span>
       </td>
       <td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S4.T2.4.7.7.3" style="padding:0.9pt 8.0pt;">
        <span class="ltx_text" id="S4.T2.4.7.7.3.1" style="font-size:90%;">
         0.40
        </span>
       </td>
       <td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S4.T2.4.7.7.4" style="padding:0.9pt 8.0pt;">
        <span class="ltx_text" id="S4.T2.4.7.7.4.1" style="font-size:90%;">
         1.42
        </span>
       </td>
       <td class="ltx_td ltx_nopad_r ltx_align_left ltx_border_bb ltx_border_t" id="S4.T2.4.7.7.5" style="padding:0.9pt 8.0pt;">
        <span class="ltx_text ltx_font_bold" id="S4.T2.4.7.7.5.1" style="font-size:90%;">
         1.78
        </span>
       </td>
      </tr>
     </tbody>
    </table>
   </figure>
   <div class="ltx_para" id="S4.SS2.p2">
    <p class="ltx_p" id="S4.SS2.p2.1">
     In order to demonstrate the generalization capabilities of
     <span class="ltx_text ltx_font_typewriter" id="S4.SS2.p2.1.1">
      LCB
     </span>
     cross various environments as well as its ability to comprehend and act upon the same instructions phrased differently in the CALVIN long horizon full 6D manipulation setting, we compare the following approaches:
     <br class="ltx_break"/>
    </p>
    <ul class="ltx_itemize" id="S4.I3">
     <li class="ltx_item" id="S4.I3.i1" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S4.I3.i1.p1">
       <p class="ltx_p" id="S4.I3.i1.p1.1">
        <span class="ltx_text ltx_font_bold" id="S4.I3.i1.p1.1.1">
         RoboFlamingo (RF):
        </span>
        RoboFlamingo
        <cite class="ltx_cite ltx_citemacro_cite">
         [
         <a class="ltx_ref" href="#bib.bib36" title="">
          36
         </a>
         ]
        </cite>
        adapts OpenFlamingo
        <cite class="ltx_cite ltx_citemacro_cite">
         [
         <a class="ltx_ref" href="#bib.bib37" title="">
          37
         </a>
         ]
        </cite>
        by fine-tuning solely the cross-attention layer to directly output actions, thus maintaining its language comprehension. However, this approach requires executing the entire LLM anew with each progression to a subsequent state, leading to inefficiencies.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S4.I3.i2" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S4.I3.i2.p1">
       <p class="ltx_p" id="S4.I3.i2.p1.1">
        <span class="ltx_text ltx_font_bold" id="S4.I3.i2.p1.1.1">
         3D Diffusion Actor (3DDA):
        </span>
        Incorporating a diffusion policy with 3D scene representation and CLIP
        <cite class="ltx_cite ltx_citemacro_cite">
         [
         <a class="ltx_ref" href="#bib.bib38" title="">
          38
         </a>
         ]
        </cite>
        language embedding, the 3D Diffusion Actor
        <cite class="ltx_cite ltx_citemacro_cite">
         [
         <a class="ltx_ref" href="#bib.bib35" title="">
          35
         </a>
         ]
        </cite>
        sets the current SOTA on the Calvin benchmark when provided with standard language instruction inputs. However, a notable limitation stems from the constraints of the CLIP text model it employs. 3DDA can not generalize well on language instruction outside of its training distribution.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S4.I3.i3" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S4.I3.i3.p1">
       <p class="ltx_p" id="S4.I3.i3.p1.1">
        <span class="ltx_text ltx_font_typewriter ltx_font_bold" id="S4.I3.i3.p1.1.1">
         LCB
         <span class="ltx_text ltx_font_serif" id="S4.I3.i3.p1.1.1.1">
          :
         </span>
        </span>
        <span class="ltx_text ltx_font_typewriter" id="S4.I3.i3.p1.1.2">
         LCB
        </span>
        for Calvin integrates a pre-trained LLaVA
        <cite class="ltx_cite ltx_citemacro_cite">
         [
         <a class="ltx_ref" href="#bib.bib27" title="">
          27
         </a>
         ]
        </cite>
        as the Multimodal Large Language Model backbone with a pre-trained 3D Diffusion Actor serving as the action policy. This combination leverages the SOTA capabilities of the 3D Diffusion Actor to achieve a synergistic effect:
        <span class="ltx_text ltx_font_typewriter" id="S4.I3.i3.p1.1.3">
         LCB
        </span>
        for Calvin excels in both language comprehension and low-level manipulation. Since RoboFlamingo runs the entire LLM on every environment step, in order to make a fair comparison, we also run the LLM part of
        <span class="ltx_text ltx_font_typewriter" id="S4.I3.i3.p1.1.4">
         LCB
        </span>
        synchronously with the downstream policy, although we notice no significant performance difference for Calvin.
       </p>
      </div>
     </li>
    </ul>
   </div>
   <div class="ltx_para" id="S4.SS2.p3">
    <p class="ltx_p" id="S4.SS2.p3.1">
     <a class="ltx_ref ltx_refmacro_autoref" href="#S4.T2" title="TABLE II ‣ IV-B Evaluation on CALVIN ‣ IV Results ‣ From LLMs to Actions: Latent Codes as Bridges in Hierarchical Robot Control">
      <span class="ltx_text ltx_ref_tag">
       Table II
      </span>
     </a>
     presents results for the CALVIN long-horizon, language-conditioned benchmark. In this setting, the robot executes a series of tasks in unfamiliar environments based on novel GPT-4 enriched
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib37" title="">
       37
      </a>
      ]
     </cite>
     instructions not encountered during training. The experimental outcomes demonstrate our approach’s distinct advantage over baseline methods.
     <span class="ltx_text ltx_font_typewriter" id="S4.SS2.p3.1.1">
      LCB
     </span>
     significantly surpasses all baselines in terms of task success rate at every stage and in average completed trajectory length.
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="S5">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    V
   </span>
   <span class="ltx_text ltx_font_smallcaps" id="S5.1.1">
    Conclusion
   </span>
  </h2>
  <div class="ltx_para" id="S5.p1">
   <p class="ltx_p" id="S5.p1.1">
    In this work, we introduce a novel approach, Latent Codes as Bridges, or
    <span class="ltx_text ltx_font_typewriter" id="S5.p1.1.1">
     LCB
    </span>
    , that combines the abstract reasoning capabilities of large language models with low-level action policies. Our methodology does not merely stack these capabilities as in prior works but integrates them in an end-to-end fashion through a learned latent interface. The empirical evidence from our evaluations on the Language Table and CALVIN benchmarks shows the model’s adeptness in interpreting and executing various reasoning and long horizon objectives. The flexibility and effectiveness of the hierarchy enabled by
    <span class="ltx_text ltx_font_typewriter" id="S5.p1.1.2">
     LCB
    </span>
    shows promise for real world robotic applications.
   </p>
  </div>
 </section>
 <section class="ltx_section" id="Sx1">
  <h2 class="ltx_title ltx_font_smallcaps ltx_title_section">
   ACKNOWLEDGMENTS
  </h2>
  <div class="ltx_para" id="Sx1.p1">
   <p class="ltx_p" id="Sx1.p1.1">
    Yide Shentu is supported in part by InnoHK Centre for Logistics Robotics and ONR MURI N00014-22-1-2773. Philipp Wu is supported in part by the NSF Graduate Research Fellowship Program. We thank Xinyang Geng and Fangchen Liu for valuable discussions regarding
    <span class="ltx_text ltx_font_typewriter" id="Sx1.p1.1.1">
     LCB
    </span>
    .
   </p>
  </div>
 </section>
 <section class="ltx_bibliography" id="bib">
  <h2 class="ltx_title ltx_title_bibliography">
   References
  </h2>
  <ul class="ltx_biblist">
   <li class="ltx_bibitem" id="bib.bib1">
    <span class="ltx_tag ltx_tag_bibitem">
     [1]
    </span>
    <span class="ltx_bibblock">
     A. B. et al., “Rt-2: Vision-language-action models transfer web knowledge to robotic control,” 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib2">
    <span class="ltx_tag ltx_tag_bibitem">
     [2]
    </span>
    <span class="ltx_bibblock">
     F. Liu, K. Fang, P. Abbeel, and S. Levine, “Moka: Open-vocabulary robotic manipulation through mark-based visual prompting,” 2024.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib3">
    <span class="ltx_tag ltx_tag_bibitem">
     [3]
    </span>
    <span class="ltx_bibblock">
     S. Levine, C. Finn, T. Darrell, and P. Abbeel, “End-to-end training of deep visuomotor policies,”
     <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">
      J. Mach. Learn. Res.
     </em>
     , vol. 17, pp. 39:1–39:40, 2015. [Online]. Available:
     <a class="ltx_ref ltx_url" href="https://api.semanticscholar.org/CorpusID:7242892" target="_blank" title="">
      https://api.semanticscholar.org/CorpusID:7242892
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib4">
    <span class="ltx_tag ltx_tag_bibitem">
     [4]
    </span>
    <span class="ltx_bibblock">
     OpenAI, “Gpt-4 technical report,” 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib5">
    <span class="ltx_tag ltx_tag_bibitem">
     [5]
    </span>
    <span class="ltx_bibblock">
     H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux, T. Lacroix, B. Rozière, N. Goyal, E. Hambro, F. Azhar, A. Rodriguez, A. Joulin, E. Grave, and G. Lample, “Llama: Open and efficient foundation language models,” 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib6">
    <span class="ltx_tag ltx_tag_bibitem">
     [6]
    </span>
    <span class="ltx_bibblock">
     M. Ahn, A. Brohan, N. Brown, Y. Chebotar, O. Cortes, B. David, C. Finn, C. Fu, K. Gopalakrishnan, K. Hausman, A. Herzog, D. Ho, J. Hsu, J. Ibarz, B. Ichter, A. Irpan, E. Jang, R. J. Ruano, K. Jeffrey, S. Jesmonth, N. J. Joshi, R. Julian, D. Kalashnikov, Y. Kuang, K.-H. Lee, S. Levine, Y. Lu, L. Luu, C. Parada, P. Pastor, J. Quiambao, K. Rao, J. Rettinghouse, D. Reyes, P. Sermanet, N. Sievers, C. Tan, A. Toshev, V. Vanhoucke, F. Xia, T. Xiao, P. Xu, S. Xu, M. Yan, and A. Zeng, “Do as I can, not as I say: Grounding language in robotic affordances,” Apr. 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib7">
    <span class="ltx_tag ltx_tag_bibitem">
     [7]
    </span>
    <span class="ltx_bibblock">
     W. Huang, P. Abbeel, D. Pathak, and I. Mordatch, “Language models as zero-shot planners: Extracting actionable knowledge for embodied agents,” Jan. 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib8">
    <span class="ltx_tag ltx_tag_bibitem">
     [8]
    </span>
    <span class="ltx_bibblock">
     J. Liang, W. Huang, F. Xia, P. Xu, K. Hausman, B. Ichter, P. Florence, and A. Zeng, “Code as policies: Language model programs for embodied control,” Sept. 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib9">
    <span class="ltx_tag ltx_tag_bibitem">
     [9]
    </span>
    <span class="ltx_bibblock">
     C. Lynch, A. Wahid, J. Tompson, T. Ding, J. Betker, R. Baruch, T. Armstrong, and P. Florence, “Interactive language: Talking to robots in real time,” Oct. 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib10">
    <span class="ltx_tag ltx_tag_bibitem">
     [10]
    </span>
    <span class="ltx_bibblock">
     O. Mees, L. Hermann, E. Rosete-Beas, and W. Burgard, “Calvin: A benchmark for language-conditioned policy learning for long-horizon robot manipulation tasks,” 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib11">
    <span class="ltx_tag ltx_tag_bibitem">
     [11]
    </span>
    <span class="ltx_bibblock">
     F. Zeng, W. Gan, Y. Wang, N. Liu, and P. S. Yu, “Large language models for robotics: A survey,”
     <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">
      ArXiv
     </em>
     , vol. abs/2311.07226, 2023. [Online]. Available:
     <a class="ltx_ref ltx_url" href="https://api.semanticscholar.org/CorpusID:265149884" target="_blank" title="">
      https://api.semanticscholar.org/CorpusID:265149884
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib12">
    <span class="ltx_tag ltx_tag_bibitem">
     [12]
    </span>
    <span class="ltx_bibblock">
     S. Vemprala, R. Bonatti, A. F. C. Bucker, and A. Kapoor, “Chatgpt for robotics: Design principles and model abilities,”
     <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">
      ArXiv
     </em>
     , vol. abs/2306.17582, 2023. [Online]. Available:
     <a class="ltx_ref ltx_url" href="https://api.semanticscholar.org/CorpusID:259141622" target="_blank" title="">
      https://api.semanticscholar.org/CorpusID:259141622
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib13">
    <span class="ltx_tag ltx_tag_bibitem">
     [13]
    </span>
    <span class="ltx_bibblock">
     I. Singh, V. Blukis, A. Mousavian, A. Goyal, D. Xu, J. Tremblay, D. Fox, J. Thomason, and A. Garg, “Progprompt: Generating situated robot task plans using large language models,” in
     <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">
      2023 IEEE International Conference on Robotics and Automation (ICRA)
     </em>
     .   IEEE, 2023, pp. 11 523–11 530.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib14">
    <span class="ltx_tag ltx_tag_bibitem">
     [14]
    </span>
    <span class="ltx_bibblock">
     B. Li, P. Wu, P. Abbeel, and J. Malik, “Interactive task planning with language models,” 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib15">
    <span class="ltx_tag ltx_tag_bibitem">
     [15]
    </span>
    <span class="ltx_bibblock">
     E. J. Hu, Y. Shen, P. Wallis, Z. Allen-Zhu, Y. Li, S. Wang, L. Wang, and W. Chen, “LoRA: Low-rank adaptation of large language models,” in
     <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">
      International Conference on Learning Representations
     </em>
     , 2022. [Online]. Available:
     <a class="ltx_ref ltx_url" href="https://openreview.net/forum?id=nZeVKeeFYf9" target="_blank" title="">
      https://openreview.net/forum?id=nZeVKeeFYf9
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib16">
    <span class="ltx_tag ltx_tag_bibitem">
     [16]
    </span>
    <span class="ltx_bibblock">
     E. Jang, A. Irpan, M. Khansari, D. Kappler, F. Ebert, C. Lynch, S. Levine, and C. Finn, “Bc-z: Zero-shot task generalization with robotic imitation learning,”
     <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">
      ArXiv
     </em>
     , vol. abs/2202.02005, 2022. [Online]. Available:
     <a class="ltx_ref ltx_url" href="https://api.semanticscholar.org/CorpusID:237257594" target="_blank" title="">
      https://api.semanticscholar.org/CorpusID:237257594
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib17">
    <span class="ltx_tag ltx_tag_bibitem">
     [17]
    </span>
    <span class="ltx_bibblock">
     X. Li, M. Liu, H. Zhang, C. Yu, J. Xu, H. Wu, C. Cheang, Y. Jing, W. Zhang, H. Liu, H. Li, and T. Kong, “Vision-language foundation models as effective robot imitators,”
     <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">
      arXiv preprint arXiv:2311.01378
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib18">
    <span class="ltx_tag ltx_tag_bibitem">
     [18]
    </span>
    <span class="ltx_bibblock">
     C. Lynch and P. Sermanet, “Language conditioned imitation learning over unstructured data,”
     <em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">
      Robotics: Science and Systems
     </em>
     , 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib19">
    <span class="ltx_tag ltx_tag_bibitem">
     [19]
    </span>
    <span class="ltx_bibblock">
     A. Kirillov, E. Mintun, N. Ravi, H. Mao, C. Rolland, L. Gustafson, T. Xiao, S. Whitehead, A. C. Berg, W.-Y. Lo, P. Dollár, and R. B. Girshick, “Segment anything,”
     <em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">
      2023 IEEE/CVF International Conference on Computer Vision (ICCV)
     </em>
     , pp. 3992–4003, 2023. [Online]. Available:
     <a class="ltx_ref ltx_url" href="https://api.semanticscholar.org/CorpusID:257952310" target="_blank" title="">
      https://api.semanticscholar.org/CorpusID:257952310
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib20">
    <span class="ltx_tag ltx_tag_bibitem">
     [20]
    </span>
    <span class="ltx_bibblock">
     L. Chen, K. Lu, A. Rajeswaran, K. Lee, A. Grover, M. Laskin, P. Abbeel, A. Srinivas, and I. Mordatch, “Decision transformer: Reinforcement learning via sequence modeling,” in
     <em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">
      Neural Information Processing Systems
     </em>
     , 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib21">
    <span class="ltx_tag ltx_tag_bibitem">
     [21]
    </span>
    <span class="ltx_bibblock">
     M. Janner, Q. Li, and S. Levine, “Offline reinforcement learning as one big sequence modeling problem,” in
     <em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">
      Advances in Neural Information Processing Systems
     </em>
     , 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib22">
    <span class="ltx_tag ltx_tag_bibitem">
     [22]
    </span>
    <span class="ltx_bibblock">
     P. Wu, A. Majumdar, K. Stone, Y. Lin, I. Mordatch, P. Abbeel, and A. Rajeswaran, “Masked trajectory models for prediction, representation, and control,” in
     <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">
      International Conference on Machine Learning
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib23">
    <span class="ltx_tag ltx_tag_bibitem">
     [23]
    </span>
    <span class="ltx_bibblock">
     F. Liu, H. Liu, A. Grover, and P. Abbeel, “Masked autoencoding for scalable and generalizable decision making,” 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib24">
    <span class="ltx_tag ltx_tag_bibitem">
     [24]
    </span>
    <span class="ltx_bibblock">
     S. Nair, A. Rajeswaran, V. Kumar, C. Finn, and A. Gupta, “R3m: A universal visual representation for robot manipulation,” in
     <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">
      Conference on Robot Learning
     </em>
     , 2022. [Online]. Available:
     <a class="ltx_ref ltx_url" href="https://api.semanticscholar.org/CorpusID:247618840" target="_blank" title="">
      https://api.semanticscholar.org/CorpusID:247618840
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib25">
    <span class="ltx_tag ltx_tag_bibitem">
     [25]
    </span>
    <span class="ltx_bibblock">
     A. Majumdar, K. Yadav, S. Arnaud, Y. J. Ma, C. Chen, S. Silwal, A. Jain, V.-P. Berges, P. Abbeel, J. Malik, D. Batra, Y. Lin, O. Maksymets, A. Rajeswaran, and F. Meier, “Where are we in the search for an artificial visual cortex for embodied intelligence?” 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib26">
    <span class="ltx_tag ltx_tag_bibitem">
     [26]
    </span>
    <span class="ltx_bibblock">
     M. Yang, Y. Du, K. Ghasemipour, J. Tompson, L. Kaelbling, D. Schuurmans, and P. Abbeel, “Learning interactive real-world simulators,” 2024.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib27">
    <span class="ltx_tag ltx_tag_bibitem">
     [27]
    </span>
    <span class="ltx_bibblock">
     H. Liu, C. Li, Q. Wu, and Y. J. Lee, “Visual instruction tuning,” 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib28">
    <span class="ltx_tag ltx_tag_bibitem">
     [28]
    </span>
    <span class="ltx_bibblock">
     D. Zhu, J. Chen, X. Shen, X. Li, and M. Elhoseiny, “Minigpt-4: Enhancing vision-language understanding with advanced large language models,”
     <em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">
      arXiv preprint arXiv:2304.10592
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib29">
    <span class="ltx_tag ltx_tag_bibitem">
     [29]
    </span>
    <span class="ltx_bibblock">
     J. Li, D. Li, S. Savarese, and S. C. H. Hoi, “Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models,” in
     <em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">
      International Conference on Machine Learning
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib30">
    <span class="ltx_tag ltx_tag_bibitem">
     [30]
    </span>
    <span class="ltx_bibblock">
     Y. Luo, Z. Yang, F. Meng, Y. Li, J. Zhou, and Y. Zhang, “An empirical study of catastrophic forgetting in large language models during continual fine-tuning,” 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib31">
    <span class="ltx_tag ltx_tag_bibitem">
     [31]
    </span>
    <span class="ltx_bibblock">
     X. Lai, Z. Tian, Y. Chen, Y. Li, Y. Yuan, S. Liu, and J. Jia, “Lisa: Reasoning segmentation via large language model,”
     <em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">
      arXiv preprint arXiv:2308.00692
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib32">
    <span class="ltx_tag ltx_tag_bibitem">
     [32]
    </span>
    <span class="ltx_bibblock">
     D. Driess, F. Xia, M. S. M. Sajjadi, C. Lynch, A. Chowdhery, B. Ichter, A. Wahid, J. Tompson, Q. Vuong, T. Yu, W. Huang, Y. Chebotar, P. Sermanet, D. Duckworth, S. Levine, V. Vanhoucke, K. Hausman, M. Toussaint, K. Greff, A. Zeng, I. Mordatch, and P. Florence, “PaLM-E: An embodied multimodal language model,” Mar. 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib33">
    <span class="ltx_tag ltx_tag_bibitem">
     [33]
    </span>
    <span class="ltx_bibblock">
     J. Yang, H. Zhang, F. Li, X. Zou, C. Li, and J. Gao, “Set-of-mark prompting unleashes extraordinary visual grounding in gpt-4v,” 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib34">
    <span class="ltx_tag ltx_tag_bibitem">
     [34]
    </span>
    <span class="ltx_bibblock">
     P. Liu, Y. Orru, J. Vakil, C. Paxton, N. M. M. Shafiullah, and L. Pinto, “Ok-robot: What really matters in integrating open-knowledge models for robotics,” 2024.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib35">
    <span class="ltx_tag ltx_tag_bibitem">
     [35]
    </span>
    <span class="ltx_bibblock">
     T.-W. Ke, N. Gkanatsios, and K. Fragkiadaki, “3d diffuser actor: Policy diffusion with 3d scene representations,” 2024.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib36">
    <span class="ltx_tag ltx_tag_bibitem">
     [36]
    </span>
    <span class="ltx_bibblock">
     X. Li, M. Liu, H. Zhang, C. Yu, J. Xu, H. Wu, C. Cheang, Y. Jing, W. Zhang, H. Liu, H. Li, and T. Kong, “Vision-language foundation models as effective robot imitators,” 2024.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib37">
    <span class="ltx_tag ltx_tag_bibitem">
     [37]
    </span>
    <span class="ltx_bibblock">
     A. Awadalla, I. Gao, J. Gardner, J. Hessel, Y. Hanafy, W. Zhu, K. Marathe, Y. Bitton, S. Gadre, S. Sagawa, J. Jitsev, S. Kornblith, P. W. Koh, G. Ilharco, M. Wortsman, and L. Schmidt, “Openflamingo: An open-source framework for training large autoregressive vision-language models,” 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib38">
    <span class="ltx_tag ltx_tag_bibitem">
     [38]
    </span>
    <span class="ltx_bibblock">
     A. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal, G. Sastry, A. Askell, P. Mishkin, J. Clark, G. Krueger, and I. Sutskever, “Learning transferable visual models from natural language supervision,” 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib39">
    <span class="ltx_tag ltx_tag_bibitem">
     [39]
    </span>
    <span class="ltx_bibblock">
     M. Shridhar, L. Manuelli, and D. Fox, “Cliport: What and where pathways for robotic manipulation,” 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib40">
    <span class="ltx_tag ltx_tag_bibitem">
     [40]
    </span>
    <span class="ltx_bibblock">
     Y. Jiang, A. Gupta, Z. Zhang, G. Wang, Y. Dou, Y. Chen, L. Fei-Fei, A. Anandkumar, Y. Zhu, and L. Fan, “Vima: General robot manipulation with multimodal prompts,” 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib41">
    <span class="ltx_tag ltx_tag_bibitem">
     [41]
    </span>
    <span class="ltx_bibblock">
     J. Wei, X. Wang, D. Schuurmans, M. Bosma, B. Ichter, F. Xia, E. Chi, Q. Le, and D. Zhou, “Chain-of-thought prompting elicits reasoning in large language models,” 2023.
    </span>
   </li>
  </ul>
 </section>
 <section class="ltx_appendix" id="A1">
  <h2 class="ltx_title ltx_title_appendix">
   <span class="ltx_tag ltx_tag_appendix">
    Appendix A
   </span>
   Dataset Details For Language Table
  </h2>
  <div class="ltx_para" id="A1.p1">
   <p class="ltx_p" id="A1.p1.1">
    Language table contains a low level text description for each trajectory. We convert this data into chat-like interactions using programmatic templates, common in language based robotics
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib18" title="">
      18
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib39" title="">
      39
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib40" title="">
      40
     </a>
     ]
    </cite>
    . Below in
    <a class="ltx_ref ltx_refmacro_autoref" href="#A1.F6" title="Figure 6 ‣ Appendix A Dataset Details For Language Table ‣ From LLMs to Actions: Latent Codes as Bridges in Hierarchical Robot Control">
     <span class="ltx_text ltx_ref_tag">
      Figure 6
     </span>
    </a>
    , we provide the pseudocode with (truncated) examples for how we generate chat question answer pairs for training.


basicstyle=
    <span class="ltx_text ltx_font_typewriter" id="A1.p1.1.1" style="font-size:90%;">
     ,
frame=single,
breaklines,
columns=fullflexible,
breakindent=1.2em,
breakatwhitespace,
escapeinside=(**),
    </span>
   </p>
  </div>
  <figure class="ltx_figure" id="A1.F6">
   <div class="ltx_listing ltx_lstlisting ltx_align_center ltx_listing" id="A1.F6.2">
    <div class="ltx_listing_data">
     <a download="" href="data:text/plain;base64,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">
      ⬇
     </a>
    </div>
    <div class="ltx_listingline" id="lstnumberx1">
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx1.1">
      QUESTION_LIST
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx1.2">
     </span>
     =
     <span class="ltx_text ltx_lst_space" id="lstnumberx1.3">
     </span>
     [
    </div>
    <div class="ltx_listingline" id="lstnumberx2">
     <span class="ltx_text ltx_lst_space" id="lstnumberx2.1">
     </span>
     ”
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx2.2">
      Can
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx2.3">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx2.4">
      you
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx2.5">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx2.6">
      control
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx2.7">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx2.8">
      the
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx2.9">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx2.10">
      robot
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx2.11">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx2.12">
      to
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx2.13">
     </span>
     {
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx2.14">
      instruction
     </span>
     }?”,
    </div>
    <div class="ltx_listingline" id="lstnumberx3">
     <span class="ltx_text ltx_lst_space" id="lstnumberx3.1">
     </span>
     ”
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx3.2">
      Can
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx3.3">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx3.4">
      you
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx3.5">
     </span>
     {
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx3.6">
      instruction
     </span>
     }?”,
    </div>
    <div class="ltx_listingline" id="lstnumberx4">
     <span class="ltx_text ltx_lst_space" id="lstnumberx4.1">
     </span>
     ”
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx4.2">
      Please
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx4.3">
     </span>
     {
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx4.4">
      instruction
     </span>
     }.”,
    </div>
    <div class="ltx_listingline" id="lstnumberx5">
     <span class="ltx_text ltx_lst_space" id="lstnumberx5.1">
     </span>
     ”
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx5.2">
      Given
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx5.3">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx5.4">
      the
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx5.5">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx5.6">
      current
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx5.7">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx5.8">
      observation
     </span>
     ,
     <span class="ltx_text ltx_lst_space" id="lstnumberx5.9">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx5.10">
      how
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx5.11">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx5.12">
      can
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx5.13">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx5.14">
      you
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx5.15">
     </span>
     {
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx5.16">
      instruction
     </span>
     }?.”,
    </div>
    <div class="ltx_listingline" id="lstnumberx6">
     ]
    </div>
    <div class="ltx_listingline" id="lstnumberx7">
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx7.1">
      def
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx7.2">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx7.3">
      followup
     </span>
     ():
    </div>
    <div class="ltx_listingline" id="lstnumberx8">
     <span class="ltx_text ltx_lst_space" id="lstnumberx8.1">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx8.2">
      start
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx8.3">
     </span>
     =
     <span class="ltx_text ltx_lst_space" id="lstnumberx8.4">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx8.5">
      np
     </span>
     .
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx8.6">
      random
     </span>
     .
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx8.7">
      choice
     </span>
     ([
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx8.8">
      None
     </span>
     ,
     <span class="ltx_text ltx_lst_space" id="lstnumberx8.9">
     </span>
     ”
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx8.10">
      first
     </span>
     ,
     <span class="ltx_text ltx_lst_space" id="lstnumberx8.11">
     </span>
     ”,
     <span class="ltx_text ltx_lst_space" id="lstnumberx8.12">
     </span>
     ”
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx8.13">
      please
     </span>
     ,
     <span class="ltx_text ltx_lst_space" id="lstnumberx8.14">
     </span>
     ”])
    </div>
    <div class="ltx_listingline" id="lstnumberx9">
     <span class="ltx_text ltx_lst_space" id="lstnumberx9.1">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.2">
      verb
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx9.3">
     </span>
     =
     <span class="ltx_text ltx_lst_space" id="lstnumberx9.4">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.5">
      np
     </span>
     .
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.6">
      random
     </span>
     .
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.7">
      choice
     </span>
     ([”
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.8">
      explain
     </span>
     ”,
     <span class="ltx_text ltx_lst_space" id="lstnumberx9.9">
     </span>
     ”
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.10">
      verbalize
     </span>
     ”])
    </div>
    <div class="ltx_listingline" id="lstnumberx10">
     <span class="ltx_text ltx_lst_space" id="lstnumberx10.1">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx10.2">
      core
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx10.3">
     </span>
     =
     <span class="ltx_text ltx_lst_space" id="lstnumberx10.4">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx10.5">
      np
     </span>
     .
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx10.6">
      random
     </span>
     .
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx10.7">
      choice
     </span>
     ([
    </div>
    <div class="ltx_listingline" id="lstnumberx11">
     <span class="ltx_text ltx_lst_space" id="lstnumberx11.1">
     </span>
     ”
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx11.2">
      how
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx11.3">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx11.4">
      you
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx11.5">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx11.6">
      would
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx11.7">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx11.8">
      accomplish
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx11.9">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx11.10">
      this
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx11.11">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx11.12">
      task
     </span>
     ”,
    </div>
    <div class="ltx_listingline" id="lstnumberx12">
     <span class="ltx_text ltx_lst_space" id="lstnumberx12.1">
     </span>
     ”
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx12.2">
      the
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx12.3">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx12.4">
      desired
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx12.5">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx12.6">
      action
     </span>
     ”,
    </div>
    <div class="ltx_listingline" id="lstnumberx13">
     <span class="ltx_text ltx_lst_space" id="lstnumberx13.1">
     </span>
     ”
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx13.2">
      the
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx13.3">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx13.4">
      next
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx13.5">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx13.6">
      step
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx13.7">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx13.8">
      you
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx13.9">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx13.10">
      are
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx13.11">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx13.12">
      going
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx13.13">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx13.14">
      to
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx13.15">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx13.16">
      do
     </span>
     ”,
    </div>
    <div class="ltx_listingline" id="lstnumberx14">
     <span class="ltx_text ltx_lst_space" id="lstnumberx14.1">
     </span>
     ])
    </div>
    <div class="ltx_listingline" id="lstnumberx15">
     <span class="ltx_text ltx_lst_space" id="lstnumberx15.1">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx15.2">
      act
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx15.3">
     </span>
     =
     <span class="ltx_text ltx_lst_space" id="lstnumberx15.4">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx15.5">
      np
     </span>
     .
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx15.6">
      random
     </span>
     .
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx15.7">
      choice
     </span>
     ([”
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx15.8">
      before
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx15.9">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx15.10">
      acting
     </span>
     ”,
     <span class="ltx_text ltx_lst_space" id="lstnumberx15.11">
     </span>
     ”
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx15.12">
      prior
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx15.13">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx15.14">
      to
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx15.15">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx15.16">
      acting
     </span>
     ”])
    </div>
    <div class="ltx_listingline" id="lstnumberx16">
    </div>
    <div class="ltx_listingline" id="lstnumberx17">
     <span class="ltx_text ltx_lst_space" id="lstnumberx17.1">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx17.2">
      if
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx17.3">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx17.4">
      start
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx17.5">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx17.6">
      is
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx17.7">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx17.8">
      None
     </span>
     :
    </div>
    <div class="ltx_listingline" id="lstnumberx18">
     <span class="ltx_text ltx_lst_space" id="lstnumberx18.1">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx18.2">
      sentence
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx18.3">
     </span>
     =
     <span class="ltx_text ltx_lst_space" id="lstnumberx18.4">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx18.5">
      verb
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx18.6">
     </span>
     +
     <span class="ltx_text ltx_lst_space" id="lstnumberx18.7">
     </span>
     ”
     <span class="ltx_text ltx_lst_space" id="lstnumberx18.8">
     </span>
     ”
     <span class="ltx_text ltx_lst_space" id="lstnumberx18.9">
     </span>
     +
     <span class="ltx_text ltx_lst_space" id="lstnumberx18.10">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx18.11">
      core
     </span>
    </div>
    <div class="ltx_listingline" id="lstnumberx19">
     <span class="ltx_text ltx_lst_space" id="lstnumberx19.1">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx19.2">
      else
     </span>
     :
    </div>
    <div class="ltx_listingline" id="lstnumberx20">
     <span class="ltx_text ltx_lst_space" id="lstnumberx20.1">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx20.2">
      sentence
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx20.3">
     </span>
     =
     <span class="ltx_text ltx_lst_space" id="lstnumberx20.4">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx20.5">
      start
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx20.6">
     </span>
     +
     <span class="ltx_text ltx_lst_space" id="lstnumberx20.7">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx20.8">
      verb
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx20.9">
     </span>
     +
     <span class="ltx_text ltx_lst_space" id="lstnumberx20.10">
     </span>
     ”
     <span class="ltx_text ltx_lst_space" id="lstnumberx20.11">
     </span>
     ”
     <span class="ltx_text ltx_lst_space" id="lstnumberx20.12">
     </span>
     +
     <span class="ltx_text ltx_lst_space" id="lstnumberx20.13">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx20.14">
      core
     </span>
    </div>
    <div class="ltx_listingline" id="lstnumberx21">
    </div>
    <div class="ltx_listingline" id="lstnumberx22">
     <span class="ltx_text ltx_lst_space" id="lstnumberx22.1">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx22.2">
      if
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx22.3">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx22.4">
      np
     </span>
     .
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx22.5">
      random
     </span>
     .
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx22.6">
      rand
     </span>
     ()
     <span class="ltx_text ltx_lst_space" id="lstnumberx22.7">
     </span>
     &gt;
     <span class="ltx_text ltx_lst_space" id="lstnumberx22.8">
     </span>
     0.5:
    </div>
    <div class="ltx_listingline" id="lstnumberx23">
     <span class="ltx_text ltx_lst_space" id="lstnumberx23.1">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx23.2">
      sentence
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx23.3">
     </span>
     =
     <span class="ltx_text ltx_lst_space" id="lstnumberx23.4">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx23.5">
      sentence
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx23.6">
     </span>
     +
     <span class="ltx_text ltx_lst_space" id="lstnumberx23.7">
     </span>
     ”
     <span class="ltx_text ltx_lst_space" id="lstnumberx23.8">
     </span>
     ”
     <span class="ltx_text ltx_lst_space" id="lstnumberx23.9">
     </span>
     +
     <span class="ltx_text ltx_lst_space" id="lstnumberx23.10">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx23.11">
      act
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx23.12">
     </span>
     +
     <span class="ltx_text ltx_lst_space" id="lstnumberx23.13">
     </span>
     ”.”
    </div>
    <div class="ltx_listingline" id="lstnumberx24">
     <span class="ltx_text ltx_lst_space" id="lstnumberx24.1">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx24.2">
      else
     </span>
     :
    </div>
    <div class="ltx_listingline" id="lstnumberx25">
     <span class="ltx_text ltx_lst_space" id="lstnumberx25.1">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx25.2">
      sentence
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx25.3">
     </span>
     =
     <span class="ltx_text ltx_lst_space" id="lstnumberx25.4">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx25.5">
      act
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx25.6">
     </span>
     +
     <span class="ltx_text ltx_lst_space" id="lstnumberx25.7">
     </span>
     ”,
     <span class="ltx_text ltx_lst_space" id="lstnumberx25.8">
     </span>
     ”
     <span class="ltx_text ltx_lst_space" id="lstnumberx25.9">
     </span>
     +
     <span class="ltx_text ltx_lst_space" id="lstnumberx25.10">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx25.11">
      sentence
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx25.12">
     </span>
     +
     <span class="ltx_text ltx_lst_space" id="lstnumberx25.13">
     </span>
     ”.”
    </div>
    <div class="ltx_listingline" id="lstnumberx26">
    </div>
    <div class="ltx_listingline" id="lstnumberx27">
     <span class="ltx_text ltx_lst_space" id="lstnumberx27.1">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx27.2">
      sentence
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx27.3">
     </span>
     =
     <span class="ltx_text ltx_lst_space" id="lstnumberx27.4">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx27.5">
      sentence
     </span>
     [0].
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx27.6">
      upper
     </span>
     ()
     <span class="ltx_text ltx_lst_space" id="lstnumberx27.7">
     </span>
     +
     <span class="ltx_text ltx_lst_space" id="lstnumberx27.8">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx27.9">
      sentence
     </span>
     [1:]
    </div>
    <div class="ltx_listingline" id="lstnumberx28">
     <span class="ltx_text ltx_lst_space" id="lstnumberx28.1">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx28.2">
      return
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx28.3">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx28.4">
      sentence
     </span>
    </div>
    <div class="ltx_listingline" id="lstnumberx29">
    </div>
    <div class="ltx_listingline" id="lstnumberx30">
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx30.1">
      def
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx30.2">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx30.3">
      process_instruction
     </span>
     (
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx30.4">
      instruction_string
     </span>
     ,
     <span class="ltx_text ltx_lst_space" id="lstnumberx30.5">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx30.6">
      use_extra
     </span>
     =
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx30.7">
      True
     </span>
     ):
    </div>
    <div class="ltx_listingline" id="lstnumberx31">
     <span class="ltx_text ltx_lst_space" id="lstnumberx31.1">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx31.2">
      i_string
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx31.3">
     </span>
     =
     <span class="ltx_text ltx_lst_space" id="lstnumberx31.4">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx31.5">
      instruction_string
     </span>
     .
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx31.6">
      lower
     </span>
     ()
    </div>
    <div class="ltx_listingline" id="lstnumberx32">
     <span class="ltx_text ltx_lst_space" id="lstnumberx32.1">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx32.2">
      question
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx32.3">
     </span>
     =
     <span class="ltx_text ltx_lst_space" id="lstnumberx32.4">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx32.5">
      np
     </span>
     .
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx32.6">
      random
     </span>
     .
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx32.7">
      choice
     </span>
     (
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx32.8">
      QUESTION_LIST
     </span>
     ).
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx32.9">
      format
     </span>
     (
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx32.10">
      instruction
     </span>
     =
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx32.11">
      i_string
     </span>
     )
    </div>
    <div class="ltx_listingline" id="lstnumberx33">
     <span class="ltx_text ltx_lst_space" id="lstnumberx33.1">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx33.2">
      if
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx33.3">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx33.4">
      use_extra
     </span>
     :
    </div>
    <div class="ltx_listingline" id="lstnumberx34">
     <span class="ltx_text ltx_lst_space" id="lstnumberx34.1">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx34.2">
      extra_instruction
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx34.3">
     </span>
     =
     <span class="ltx_text ltx_lst_space" id="lstnumberx34.4">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx34.5">
      followup
     </span>
     ()
    </div>
    <div class="ltx_listingline" id="lstnumberx35">
     <span class="ltx_text ltx_lst_space" id="lstnumberx35.1">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx35.2">
      question
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx35.3">
     </span>
     =
     <span class="ltx_text ltx_lst_space" id="lstnumberx35.4">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx35.5">
      question
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx35.6">
     </span>
     +
     <span class="ltx_text ltx_lst_space" id="lstnumberx35.7">
     </span>
     ”
     <span class="ltx_text ltx_lst_space" id="lstnumberx35.8">
     </span>
     ”
     <span class="ltx_text ltx_lst_space" id="lstnumberx35.9">
     </span>
     +
     <span class="ltx_text ltx_lst_space" id="lstnumberx35.10">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx35.11">
      extra_instruction
     </span>
    </div>
    <div class="ltx_listingline" id="lstnumberx36">
     <span class="ltx_text ltx_lst_space" id="lstnumberx36.1">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx36.2">
      return
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx36.3">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx36.4">
      question
     </span>
    </div>
    <div class="ltx_listingline" id="lstnumberx37">
    </div>
    <div class="ltx_listingline" id="lstnumberx38">
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx38.1">
      ANSWER_LIST
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx38.2">
     </span>
     =
     <span class="ltx_text ltx_lst_space" id="lstnumberx38.3">
     </span>
     [”
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx38.4">
      Sure
     </span>
     ,
     <span class="ltx_text ltx_lst_space" id="lstnumberx38.5">
     </span>
     [
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx38.6">
      ACT
     </span>
     ].”,
     <span class="ltx_text ltx_lst_space" id="lstnumberx38.7">
     </span>
     ”[
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx38.8">
      ACT
     </span>
     ].”,
     <span class="ltx_text ltx_lst_space" id="lstnumberx38.9">
     </span>
     ”
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx38.10">
      Let
     </span>
     ’
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx38.11">
      s
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx38.12">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx38.13">
      move
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx38.14">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx38.15">
      the
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx38.16">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx38.17">
      robot
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx38.18">
     </span>
     [
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx38.19">
      ACT
     </span>
     ].”]
    </div>
    <div class="ltx_listingline" id="lstnumberx39">
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx39.1">
      ANSWER_DETAILED_LIST
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx39.2">
     </span>
     =
     <span class="ltx_text ltx_lst_space" id="lstnumberx39.3">
     </span>
     [
    </div>
    <div class="ltx_listingline" id="lstnumberx40">
     <span class="ltx_text ltx_lst_space" id="lstnumberx40.1">
     </span>
     ”
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx40.2">
      I
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx40.3">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx40.4">
      will
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx40.5">
     </span>
     {
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx40.6">
      detailed_instuction
     </span>
     }
     <span class="ltx_text ltx_lst_space" id="lstnumberx40.7">
     </span>
     [
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx40.8">
      ACT
     </span>
     ].”,
    </div>
    <div class="ltx_listingline" id="lstnumberx41">
     <span class="ltx_text ltx_lst_space" id="lstnumberx41.1">
     </span>
     ”
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx41.2">
      Sure
     </span>
     ,
     <span class="ltx_text ltx_lst_space" id="lstnumberx41.3">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx41.4">
      I
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx41.5">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx41.6">
      will
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx41.7">
     </span>
     {
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx41.8">
      detailed_instuction
     </span>
     }
     <span class="ltx_text ltx_lst_space" id="lstnumberx41.9">
     </span>
     [
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx41.10">
      ACT
     </span>
     ].”,
    </div>
    <div class="ltx_listingline" id="lstnumberx42">
     <span class="ltx_text ltx_lst_space" id="lstnumberx42.1">
     </span>
     ”
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx42.2">
      I
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx42.3">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx42.4">
      should
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx42.5">
     </span>
     {
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx42.6">
      detailed_instuction
     </span>
     }
     <span class="ltx_text ltx_lst_space" id="lstnumberx42.7">
     </span>
     [
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx42.8">
      ACT
     </span>
     ].”,
    </div>
    <div class="ltx_listingline" id="lstnumberx43">
     ]
    </div>
    <div class="ltx_listingline" id="lstnumberx44">
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx44.1">
      def
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx44.2">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx44.3">
      process_ans_and_ques
     </span>
     (
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx44.4">
      instruction_string
     </span>
     ):
    </div>
    <div class="ltx_listingline" id="lstnumberx45">
     <span class="ltx_text ltx_lst_space" id="lstnumberx45.1">
     </span>
     #
     <span class="ltx_text ltx_lst_space" id="lstnumberx45.2">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx45.3">
      sometimes
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx45.4">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx45.5">
      add
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx45.6">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx45.7">
      more
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx45.8">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx45.9">
      details
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx45.10">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx45.11">
      to
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx45.12">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx45.13">
      instruction
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx45.14">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx45.15">
      and
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx45.16">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx45.17">
      privde
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx45.18">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx45.19">
      mode
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx45.20">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx45.21">
      details
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx45.22">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx45.23">
      to
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx45.24">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx45.25">
      the
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx45.26">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx45.27">
      answer
     </span>
    </div>
    <div class="ltx_listingline" id="lstnumberx46">
     <span class="ltx_text ltx_lst_space" id="lstnumberx46.1">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx46.2">
      if
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx46.3">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx46.4">
      np
     </span>
     .
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx46.5">
      random
     </span>
     .
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx46.6">
      rand
     </span>
     ()
     <span class="ltx_text ltx_lst_space" id="lstnumberx46.7">
     </span>
     &gt;
     <span class="ltx_text ltx_lst_space" id="lstnumberx46.8">
     </span>
     0.8:
    </div>
    <div class="ltx_listingline" id="lstnumberx47">
     <span class="ltx_text ltx_lst_space" id="lstnumberx47.1">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx47.2">
      question
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx47.3">
     </span>
     =
     <span class="ltx_text ltx_lst_space" id="lstnumberx47.4">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx47.5">
      process_short_horizon_instruction
     </span>
     (
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx47.6">
      instruction_string
     </span>
     ,
     <span class="ltx_text ltx_lst_space" id="lstnumberx47.7">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx47.8">
      use_extra
     </span>
     =
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx47.9">
      True
     </span>
     )
    </div>
    <div class="ltx_listingline" id="lstnumberx48">
     <span class="ltx_text ltx_lst_space" id="lstnumberx48.1">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx48.2">
      answer
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx48.3">
     </span>
     =
     <span class="ltx_text ltx_lst_space" id="lstnumberx48.4">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx48.5">
      np
     </span>
     .
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx48.6">
      random
     </span>
     .
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx48.7">
      choice
     </span>
     (
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx48.8">
      ANSWER_LIST
     </span>
     )
    </div>
    <div class="ltx_listingline" id="lstnumberx49">
     <span class="ltx_text ltx_lst_space" id="lstnumberx49.1">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx49.2">
      answer
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx49.3">
     </span>
     =
     <span class="ltx_text ltx_lst_space" id="lstnumberx49.4">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx49.5">
      answer
     </span>
     .
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx49.6">
      format
     </span>
     (
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx49.7">
      detailed_instuction
     </span>
     =
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx49.8">
      instruction_string
     </span>
     )
    </div>
    <div class="ltx_listingline" id="lstnumberx50">
     <span class="ltx_text ltx_lst_space" id="lstnumberx50.1">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx50.2">
      else
     </span>
     :
    </div>
    <div class="ltx_listingline" id="lstnumberx51">
     <span class="ltx_text ltx_lst_space" id="lstnumberx51.1">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx51.2">
      question
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx51.3">
     </span>
     =
     <span class="ltx_text ltx_lst_space" id="lstnumberx51.4">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx51.5">
      process_short_horizon_instruction
     </span>
     (
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx51.6">
      instruction_string
     </span>
     ,
     <span class="ltx_text ltx_lst_space" id="lstnumberx51.7">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx51.8">
      use_extra
     </span>
     =
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx51.9">
      False
     </span>
     )
    </div>
    <div class="ltx_listingline" id="lstnumberx52">
     <span class="ltx_text ltx_lst_space" id="lstnumberx52.1">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx52.2">
      answer
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx52.3">
     </span>
     =
     <span class="ltx_text ltx_lst_space" id="lstnumberx52.4">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx52.5">
      np
     </span>
     .
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx52.6">
      random
     </span>
     .
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx52.7">
      choice
     </span>
     (
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx52.8">
      PLANNER_ANSWER_LIST
     </span>
     )
    </div>
    <div class="ltx_listingline" id="lstnumberx53">
     <span class="ltx_text ltx_lst_space" id="lstnumberx53.1">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx53.2">
      return
     </span>
     <span class="ltx_text ltx_lst_space" id="lstnumberx53.3">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx53.4">
      question
     </span>
     ,
     <span class="ltx_text ltx_lst_space" id="lstnumberx53.5">
     </span>
     <span class="ltx_text ltx_lst_identifier" id="lstnumberx53.6">
      answer
     </span>
    </div>
   </div>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     <span class="ltx_text" id="A1.F6.4.1.1" style="font-size:90%;">
      Figure 6
     </span>
     :
    </span>
    <span class="ltx_text" id="A1.F6.5.2" style="font-size:90%;">
     Example programmatic generation for
     <span class="ltx_text ltx_font_typewriter" id="A1.F6.5.2.1">
      LCB
     </span>
     training with the original language table data.
    </span>
   </figcaption>
  </figure>
 </section>
 <section class="ltx_appendix" id="A2">
  <h2 class="ltx_title ltx_title_appendix">
   <span class="ltx_tag ltx_tag_appendix">
    Appendix B
   </span>
   GPT-4V Prompting Details
  </h2>
  <div class="ltx_para" id="A2.p1">
   <p class="ltx_p" id="A2.p1.1">
    GPT-4/GPT-4V is often used zero-shot in robotic applications, due to its strong general understanding. We finetuned our prompt for the language table tasks to achieve the best possible performance, levering prior prompting methods found to improve performance.
The prompt is seen in detail below in
    <a class="ltx_ref ltx_refmacro_autoref" href="#A2.F7" title="Figure 7 ‣ Appendix B GPT-4V Prompting Details ‣ From LLMs to Actions: Latent Codes as Bridges in Hierarchical Robot Control">
     <span class="ltx_text ltx_ref_tag">
      Figure 7
     </span>
    </a>
    . We use a comprehensive task prompt as well as Set-of- Mark
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib33" title="">
      33
     </a>
     ]
    </cite>
    , structured outputs, in context examples, and chain of thought prompting
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib41" title="">
      41
     </a>
     ]
    </cite>
    .
   </p>
  </div>
  <figure class="ltx_figure" id="A2.F7">
   <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="288" id="A2.F7.g1" src="/html/2405.04798/assets/x4.png" width="461"/>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     <span class="ltx_text" id="A2.F7.2.1.1" style="font-size:90%;">
      Figure 7
     </span>
     :
    </span>
    <span class="ltx_text" id="A2.F7.3.2" style="font-size:90%;">
     Prompt for using GPT-4V on Language Table as a pretrained VLM. “…” indicates truncation for brevity, but follows the rest of the text in the section.
    </span>
   </figcaption>
  </figure>
  <div class="ltx_pagination ltx_role_newpage">
  </div>
 </section>
</article>
