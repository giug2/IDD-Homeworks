<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2203.16622] Federated Learning for the Classification of Tumor Infiltrating Lymphocytes</title><meta property="og:description" content="We evaluate the performance of federated learning (FL) in developing deep learning models for analysis of digitized tissue sections. A classification application was considered as the example use case, on quantifiying …">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Federated Learning for the Classification of Tumor Infiltrating Lymphocytes">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Federated Learning for the Classification of Tumor Infiltrating Lymphocytes">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2203.16622">

<!--Generated on Mon Mar 11 07:26:20 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="federated learning,  classification,  histopathology,  digital pathology,  tumor infiltrating lymphocytes">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line"><span id="id1" class="ltx_note ltx_role_institutetext"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_note_type">institutetext: </span><span id="id1.1" class="ltx_text" style="font-size:70%;">Center for Biomedical Image Computing and Analytics (CBICA), University of Pennsylvania, Philadelphia, PA, USA
<span id="id1.1.1" class="ltx_note ltx_role_institutetext"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_note_type">institutetext: </span>Department of Pathology and Laboratory Medicine, Perelman School of Medicine, University of Pennsylvania, Philadelphia, PA, USA
</span></span></span><span id="id1.1.2" class="ltx_note ltx_role_institutetext"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_note_type">institutetext: </span>Department of Radiology, Perelman School of Medicine, University of Pennsylvania, Philadelphia, PA, USA
</span></span></span><span id="id1.1.3" class="ltx_note ltx_role_institutetext"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_note_type">institutetext: </span>Department of Informatics, Technical University of Munich, Munich, Germany
</span></span></span><span id="id1.1.4" class="ltx_note ltx_role_institutetext"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_note_type">institutetext: </span>Department of Biomedical Informatics, Stony Brook University, Stony Brook, NY, USA
</span></span></span><span id="id1.1.5" class="ltx_note ltx_role_institutetext"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_note_type">institutetext: </span>Department of Computer Science, Stony Brook University, Stony Brook, NY, USA
</span></span></span>

<br class="ltx_break"><sup id="id1.1.6" class="ltx_sup">*</sup> Corresponding author: <span id="id1.1.7" class="ltx_note ltx_role_email"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_note_type">email: </span>{sbakas@upenn.edu}</span></span></span></span></span></span></span>
<h1 class="ltx_title ltx_title_document">Federated Learning for the Classification of Tumor Infiltrating Lymphocytes</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Ujjwal Baid
</span><span class="ltx_author_notes">112233<a target="_blank" href="https://orcid.org/0000-0001-5246-2088" title="" class="ltx_ref ltx_href"><img src="/html/2203.16622/assets/figures/ORCIDiD_icon128x128.jpg" id="id1.1.1.g1" class="ltx_graphics ltx_img_square" width="21" height="21" alt="[Uncaptioned image]"></a><a target="_blank" href="https://orcid.org/0000-0001-5246-2088" title="" class="ltx_ref ltx_href"><img src="/html/2203.16622/assets/figures/ORCIDiD_icon128x128.jpg" id="id2.2.1.g1" class="ltx_graphics ltx_img_square" width="21" height="21" alt="[Uncaptioned image]"></a></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Sarthak Pati
</span><span class="ltx_author_notes">11223344<a target="_blank" href="https://orcid.org/0000-0003-2243-8487" title="" class="ltx_ref ltx_href"><img src="/html/2203.16622/assets/figures/ORCIDiD_icon128x128.jpg" id="id3.1.1.g1" class="ltx_graphics ltx_img_square" width="21" height="21" alt="[Uncaptioned image]"></a><a target="_blank" href="https://orcid.org/0000-0003-2243-8487" title="" class="ltx_ref ltx_href"><img src="/html/2203.16622/assets/figures/ORCIDiD_icon128x128.jpg" id="id4.2.1.g1" class="ltx_graphics ltx_img_square" width="21" height="21" alt="[Uncaptioned image]"></a></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Tahsin M. Kurc
</span><span class="ltx_author_notes">55</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Rajarsi Gupta
</span><span class="ltx_author_notes">55<a target="_blank" href="https://orcid.org/0000-0002-1577-8718" title="" class="ltx_ref ltx_href"><img src="/html/2203.16622/assets/figures/ORCIDiD_icon128x128.jpg" id="id5.1.1.g1" class="ltx_graphics ltx_img_square" width="21" height="21" alt="[Uncaptioned image]"></a><a target="_blank" href="https://orcid.org/0000-0002-1577-8718" title="" class="ltx_ref ltx_href"><img src="/html/2203.16622/assets/figures/ORCIDiD_icon128x128.jpg" id="id6.2.1.g1" class="ltx_graphics ltx_img_square" width="21" height="21" alt="[Uncaptioned image]"></a></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Erich Bremer
</span><span class="ltx_author_notes">55<a target="_blank" href="https://orcid.org/0000-0003-0223-1059" title="" class="ltx_ref ltx_href"><img src="/html/2203.16622/assets/figures/ORCIDiD_icon128x128.jpg" id="id7.1.1.g1" class="ltx_graphics ltx_img_square" width="21" height="21" alt="[Uncaptioned image]"></a><a target="_blank" href="https://orcid.org/0000-0003-0223-1059" title="" class="ltx_ref ltx_href"><img src="/html/2203.16622/assets/figures/ORCIDiD_icon128x128.jpg" id="id8.2.1.g1" class="ltx_graphics ltx_img_square" width="21" height="21" alt="[Uncaptioned image]"></a></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Shahira Abousamra
</span><span class="ltx_author_notes">6<a target="_blank" href="https://orcid.org/0000-0001-6214-1923" title="" class="ltx_ref ltx_href"><img src="/html/2203.16622/assets/figures/ORCIDiD_icon128x128.jpg" id="id9.1.1.g1" class="ltx_graphics ltx_img_square" width="21" height="21" alt="[Uncaptioned image]"></a>6<a target="_blank" href="https://orcid.org/0000-0001-6214-1923" title="" class="ltx_ref ltx_href"><img src="/html/2203.16622/assets/figures/ORCIDiD_icon128x128.jpg" id="id10.2.1.g1" class="ltx_graphics ltx_img_square" width="21" height="21" alt="[Uncaptioned image]"></a></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Siddhesh P. Thakur
</span><span class="ltx_author_notes">112233<a target="_blank" href="https://orcid.org/0000-0003-4807-2495" title="" class="ltx_ref ltx_href"><img src="/html/2203.16622/assets/figures/ORCIDiD_icon128x128.jpg" id="id11.1.1.g1" class="ltx_graphics ltx_img_square" width="21" height="21" alt="[Uncaptioned image]"></a><a target="_blank" href="https://orcid.org/0000-0003-4807-2495" title="" class="ltx_ref ltx_href"><img src="/html/2203.16622/assets/figures/ORCIDiD_icon128x128.jpg" id="id12.2.1.g1" class="ltx_graphics ltx_img_square" width="21" height="21" alt="[Uncaptioned image]"></a></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Joel H. Saltz
</span><span class="ltx_author_notes">55<a target="_blank" href="https://orcid.org/0000-0002-3451-2165" title="" class="ltx_ref ltx_href"><img src="/html/2203.16622/assets/figures/ORCIDiD_icon128x128.jpg" id="id13.1.1.g1" class="ltx_graphics ltx_img_square" width="21" height="21" alt="[Uncaptioned image]"></a><a target="_blank" href="https://orcid.org/0000-0002-3451-2165" title="" class="ltx_ref ltx_href"><img src="/html/2203.16622/assets/figures/ORCIDiD_icon128x128.jpg" id="id14.2.1.g1" class="ltx_graphics ltx_img_square" width="21" height="21" alt="[Uncaptioned image]"></a></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Spyridon Bakas
</span><span class="ltx_author_notes">112233**<a target="_blank" href="https://orcid.org/0000-0001-8734-6482" title="" class="ltx_ref ltx_href"><img src="/html/2203.16622/assets/figures/ORCIDiD_icon128x128.jpg" id="id15.1.1.g1" class="ltx_graphics ltx_img_square" width="21" height="21" alt="[Uncaptioned image]"></a><a target="_blank" href="https://orcid.org/0000-0001-8734-6482" title="" class="ltx_ref ltx_href"><img src="/html/2203.16622/assets/figures/ORCIDiD_icon128x128.jpg" id="id16.2.1.g1" class="ltx_graphics ltx_img_square" width="21" height="21" alt="[Uncaptioned image]"></a></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id17.1" class="ltx_p">We evaluate the performance of federated learning (FL) in developing deep learning models for analysis of digitized tissue sections. A classification application was considered as the example use case, on quantifiying the distribution of tumor infiltrating lymphocytes within whole slide images (WSIs). A deep learning classification model was trained using <math id="id17.1.m1.1" class="ltx_Math" alttext="50\times 50" display="inline"><semantics id="id17.1.m1.1a"><mrow id="id17.1.m1.1.1" xref="id17.1.m1.1.1.cmml"><mn id="id17.1.m1.1.1.2" xref="id17.1.m1.1.1.2.cmml">50</mn><mo lspace="0.222em" rspace="0.222em" id="id17.1.m1.1.1.1" xref="id17.1.m1.1.1.1.cmml">×</mo><mn id="id17.1.m1.1.1.3" xref="id17.1.m1.1.1.3.cmml">50</mn></mrow><annotation-xml encoding="MathML-Content" id="id17.1.m1.1b"><apply id="id17.1.m1.1.1.cmml" xref="id17.1.m1.1.1"><times id="id17.1.m1.1.1.1.cmml" xref="id17.1.m1.1.1.1"></times><cn type="integer" id="id17.1.m1.1.1.2.cmml" xref="id17.1.m1.1.1.2">50</cn><cn type="integer" id="id17.1.m1.1.1.3.cmml" xref="id17.1.m1.1.1.3">50</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id17.1.m1.1c">50\times 50</annotation></semantics></math> square micron patches extracted from the WSIs. We simulated a FL environment in which a dataset, generated from WSIs of cancer from numerous anatomical sites available by The Cancer Genome Atlas repository, is partitioned in 8 different nodes. Our results show that the model trained with the federated training approach achieves similar performance, both quantitatively and qualitatively, to that of a model trained with all the training data pooled at a centralized location. Our study shows that FL has tremendous potential for enabling development of more robust and accurate models for histopathology image analysis without having to collect large and diverse training data at a single location.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Keywords: </h6>federated learning, classification, histopathology, digital pathology, tumor infiltrating lymphocytes
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Advances in machine learning (<span id="S1.p1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">ML</span>), and particularly deep learning (<span id="S1.p1.1.2" class="ltx_text ltx_font_bold ltx_font_italic">DL</span>), have shown promise in healthcare. However, the availability of large amounts of data with increased diversity is essential to produce accurate and generalizable models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. This is currently addressed by pooling data to a centralized location, typically facilitated via use-inspired consortia <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. However, this centralization is challenging (and at times infeasible) due to numerous concerns relating to privacy, data-ownership, intellectual property, as well as compliance with varying regulatory policies (e.g., Health Insurance Portability and Accountability Act (HIPAA) of the United States <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> and the General Data Protection Regulation (GDPR) of the European Union <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>).</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">In contrast to this centralized paradigm, “federated learning” (<span id="S1.p2.1.1" class="ltx_text ltx_font_bold ltx_font_italic">FL</span>) describes an approach where ML/DL models are getting trained only by sharing model updates, while all data are always retained locally within the acquiring institution <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>. Several studies have demonstrated that the performance of FL models is comparable to their equivalent CL-trained models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>. As ML/DL methods increasingly become the primary means of analyzing large datasets, FL can offer a potential paradigm shift for multi-institutional collaborations, alleviating the need for data sharing, and hence increase access to geographically-distinct collaborators, thereby increasing the size and diversity of data used to train ML/DL models.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Electronic capture (digitisation) and analyses of whole slide images (WSIs) of tissue specimens are becoming ubiquitous. Digital Pathology interpretation is becoming increasingly common, where many sites are actively scanning archived glass tissue slides with commercially available high speed scanners to generate high-resolution gigapixel WSIs. Alongside these efforts, a great variety of AI algorithms have been developed to extract many salient tissue and tumor characteristics from WSIs. Examples include segmentation of tumor regions, histologic subtypes of tumors, microanatomic tissue compartments; detection and classification of immune cells to identify tumor infiltrating lymphocytes (TILs); and the detection and classification of cells and nuclei. TILs are lymphoplasmacytic cells that are spatially located in tumor regions, where their role as an important biomarker for the prediction of clinical outcomes in cancer patients is becoming increasingly recognised  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>, <a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>. Identification of the abundance and the patterns of spatial distribution of TILs in WSI represent a quantitative approach to characterizing important tumor immune interactions.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.5" class="ltx_p">The Stony Brook Biomedical Informatics group has actively contributed to this field of work for many years by characterizing the performance of DL pathology algorithms. Specifically, we have previously developed a DL based method to analyze WSIs to quantify distributions of TILs <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>, <a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>. This method partitions a WSI into a regular mesh of image patches. Each image patch covers an area of <math id="S1.p4.1.m1.1" class="ltx_Math" alttext="50\times 50" display="inline"><semantics id="S1.p4.1.m1.1a"><mrow id="S1.p4.1.m1.1.1" xref="S1.p4.1.m1.1.1.cmml"><mn id="S1.p4.1.m1.1.1.2" xref="S1.p4.1.m1.1.1.2.cmml">50</mn><mo lspace="0.222em" rspace="0.222em" id="S1.p4.1.m1.1.1.1" xref="S1.p4.1.m1.1.1.1.cmml">×</mo><mn id="S1.p4.1.m1.1.1.3" xref="S1.p4.1.m1.1.1.3.cmml">50</mn></mrow><annotation-xml encoding="MathML-Content" id="S1.p4.1.m1.1b"><apply id="S1.p4.1.m1.1.1.cmml" xref="S1.p4.1.m1.1.1"><times id="S1.p4.1.m1.1.1.1.cmml" xref="S1.p4.1.m1.1.1.1"></times><cn type="integer" id="S1.p4.1.m1.1.1.2.cmml" xref="S1.p4.1.m1.1.1.2">50</cn><cn type="integer" id="S1.p4.1.m1.1.1.3.cmml" xref="S1.p4.1.m1.1.1.3">50</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.1.m1.1c">50\times 50</annotation></semantics></math> square microns, which is equivalent to <math id="S1.p4.2.m2.1" class="ltx_Math" alttext="100\times 100" display="inline"><semantics id="S1.p4.2.m2.1a"><mrow id="S1.p4.2.m2.1.1" xref="S1.p4.2.m2.1.1.cmml"><mn id="S1.p4.2.m2.1.1.2" xref="S1.p4.2.m2.1.1.2.cmml">100</mn><mo lspace="0.222em" rspace="0.222em" id="S1.p4.2.m2.1.1.1" xref="S1.p4.2.m2.1.1.1.cmml">×</mo><mn id="S1.p4.2.m2.1.1.3" xref="S1.p4.2.m2.1.1.3.cmml">100</mn></mrow><annotation-xml encoding="MathML-Content" id="S1.p4.2.m2.1b"><apply id="S1.p4.2.m2.1.1.cmml" xref="S1.p4.2.m2.1.1"><times id="S1.p4.2.m2.1.1.1.cmml" xref="S1.p4.2.m2.1.1.1"></times><cn type="integer" id="S1.p4.2.m2.1.1.2.cmml" xref="S1.p4.2.m2.1.1.2">100</cn><cn type="integer" id="S1.p4.2.m2.1.1.3.cmml" xref="S1.p4.2.m2.1.1.3">100</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.2.m2.1c">100\times 100</annotation></semantics></math> and <math id="S1.p4.3.m3.1" class="ltx_Math" alttext="200\times 200" display="inline"><semantics id="S1.p4.3.m3.1a"><mrow id="S1.p4.3.m3.1.1" xref="S1.p4.3.m3.1.1.cmml"><mn id="S1.p4.3.m3.1.1.2" xref="S1.p4.3.m3.1.1.2.cmml">200</mn><mo lspace="0.222em" rspace="0.222em" id="S1.p4.3.m3.1.1.1" xref="S1.p4.3.m3.1.1.1.cmml">×</mo><mn id="S1.p4.3.m3.1.1.3" xref="S1.p4.3.m3.1.1.3.cmml">200</mn></mrow><annotation-xml encoding="MathML-Content" id="S1.p4.3.m3.1b"><apply id="S1.p4.3.m3.1.1.cmml" xref="S1.p4.3.m3.1.1"><times id="S1.p4.3.m3.1.1.1.cmml" xref="S1.p4.3.m3.1.1.1"></times><cn type="integer" id="S1.p4.3.m3.1.1.2.cmml" xref="S1.p4.3.m3.1.1.2">200</cn><cn type="integer" id="S1.p4.3.m3.1.1.3.cmml" xref="S1.p4.3.m3.1.1.3">200</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.3.m3.1c">200\times 200</annotation></semantics></math> square pixels in a WSI captured at <math id="S1.p4.4.m4.1" class="ltx_math_unparsed" alttext="20\times" display="inline"><semantics id="S1.p4.4.m4.1a"><mrow id="S1.p4.4.m4.1b"><mn id="S1.p4.4.m4.1.1">20</mn><mo lspace="0.222em" id="S1.p4.4.m4.1.2">×</mo></mrow><annotation encoding="application/x-tex" id="S1.p4.4.m4.1c">20\times</annotation></semantics></math> and <math id="S1.p4.5.m5.1" class="ltx_math_unparsed" alttext="40\times" display="inline"><semantics id="S1.p4.5.m5.1a"><mrow id="S1.p4.5.m5.1b"><mn id="S1.p4.5.m5.1.1">40</mn><mo lspace="0.222em" id="S1.p4.5.m5.1.2">×</mo></mrow><annotation encoding="application/x-tex" id="S1.p4.5.m5.1c">40\times</annotation></semantics></math> magnification level, respectively. The method trains a classification model (based on a VGG16 pre-trained on ImageNet) to predict if a given image patch is TIL-positive (i.e., the patch contains 2 or more lymphocytes) or TIL-negative. This classification model has been trained and evaluated with a set of TIL-positive and TIL-negative patches from multiple cancer types with comprehensive analyses carried out to characterize performance of this method  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">In this present study, we study the performance of federated learning using DL based detection of TILs as our model application. It is particularly useful to leverage an algorithm and WSI datasets with well known performance characteristics so that performance differences arising from FL can be easily understood. In our study, we assume that each node is responsible for all training required for slides from one or more cancer sites. This ensures that we will see significant out-of-distribution impacts as training carried out on WSIs from a given tumor type often imperfectly generalizes to WSIs from different cancer sites.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Methods</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Data</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">We created a training and validation dataset consisting of patches extracted from WSIs of cancer from 12 anatomical sites, comprising breast (BRCA), cervix (CESC), colon (COAD), lung (LUAD and LUSC), pancreas (PAAD), prostate (PRAD), rectum (READ), skin (SKCM), stomach (STAD), uterus (UCEC), uvea of the eye (UVM) cases, publicly available in The Cancer Genome Atlas (TCGA) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>. Tables <a href="#S2.T1" title="Table 1 ‣ 2.1 Data ‣ 2 Methods ‣ Federated Learning for the Classification of Tumor Infiltrating Lymphocytes" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> and <a href="#S2.T2" title="Table 2 ‣ 2.2 Data Sharding ‣ 2 Methods ‣ Federated Learning for the Classification of Tumor Infiltrating Lymphocytes" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> show the explicit breakdown of the dataset into individual network sites (Site 1-8).</p>
</div>
<figure id="S2.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S2.T1.2.1.1" class="ltx_text" style="font-size:90%;">Table 1</span>: </span><span id="S2.T1.3.2" class="ltx_text" style="font-size:90%;">Data sharding to collaborative network sites according to anatomy.</span></figcaption>
<table id="S2.T1.4" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S2.T1.4.1.1" class="ltx_tr">
<th id="S2.T1.4.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt"><span id="S2.T1.4.1.1.1.1" class="ltx_text ltx_font_bold">Node</span></th>
<th id="S2.T1.4.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt"><span id="S2.T1.4.1.1.2.1" class="ltx_text ltx_font_bold">Anatomy</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S2.T1.4.2.1" class="ltx_tr">
<td id="S2.T1.4.2.1.1" class="ltx_td ltx_align_left ltx_border_tt">Site1</td>
<td id="S2.T1.4.2.1.2" class="ltx_td ltx_align_left ltx_border_tt">Cervical squamous cell carcinoma (CESC)</td>
</tr>
<tr id="S2.T1.4.3.2" class="ltx_tr">
<td id="S2.T1.4.3.2.1" class="ltx_td ltx_align_left ltx_border_t">Site2</td>
<td id="S2.T1.4.3.2.2" class="ltx_td ltx_align_left ltx_border_t">Lung squamous cell carcinoma (LUSC)</td>
</tr>
<tr id="S2.T1.4.4.3" class="ltx_tr">
<td id="S2.T1.4.4.3.1" class="ltx_td ltx_align_left ltx_border_t" rowspan="3"><span id="S2.T1.4.4.3.1.1" class="ltx_text">Site3</span></td>
<td id="S2.T1.4.4.3.2" class="ltx_td ltx_align_left ltx_border_t">Colon adenocarcinoma (COAD)</td>
</tr>
<tr id="S2.T1.4.5.4" class="ltx_tr">
<td id="S2.T1.4.5.4.1" class="ltx_td ltx_align_left">Pancreatic adenocarcinoma (PAAD)</td>
</tr>
<tr id="S2.T1.4.6.5" class="ltx_tr">
<td id="S2.T1.4.6.5.1" class="ltx_td ltx_align_left">Uterine corpus endometrial carcinoma (UCEC)</td>
</tr>
<tr id="S2.T1.4.7.6" class="ltx_tr">
<td id="S2.T1.4.7.6.1" class="ltx_td ltx_align_left ltx_border_t">Site4</td>
<td id="S2.T1.4.7.6.2" class="ltx_td ltx_align_left ltx_border_t">Rectum adenocarcinoma (READ)</td>
</tr>
<tr id="S2.T1.4.8.7" class="ltx_tr">
<td id="S2.T1.4.8.7.1" class="ltx_td ltx_align_left ltx_border_t">Site5</td>
<td id="S2.T1.4.8.7.2" class="ltx_td ltx_align_left ltx_border_t">Stomach adenocarcinoma (STAD)</td>
</tr>
<tr id="S2.T1.4.9.8" class="ltx_tr">
<td id="S2.T1.4.9.8.1" class="ltx_td ltx_align_left ltx_border_t">Site6</td>
<td id="S2.T1.4.9.8.2" class="ltx_td ltx_align_left ltx_border_t">Uveal melanoma (UVM)</td>
</tr>
<tr id="S2.T1.4.10.9" class="ltx_tr">
<td id="S2.T1.4.10.9.1" class="ltx_td ltx_align_left ltx_border_t">Site7</td>
<td id="S2.T1.4.10.9.2" class="ltx_td ltx_align_left ltx_border_t">Lung adenocarcinoma (LUAD)</td>
</tr>
<tr id="S2.T1.4.11.10" class="ltx_tr">
<td id="S2.T1.4.11.10.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" rowspan="3"><span id="S2.T1.4.11.10.1.1" class="ltx_text">Site8</span></td>
<td id="S2.T1.4.11.10.2" class="ltx_td ltx_align_left ltx_border_t">Breast invasive carcinoma (BRCA)</td>
</tr>
<tr id="S2.T1.4.12.11" class="ltx_tr">
<td id="S2.T1.4.12.11.1" class="ltx_td ltx_align_left">Prostate adenocarcinoma (PRAD)</td>
</tr>
<tr id="S2.T1.4.13.12" class="ltx_tr">
<td id="S2.T1.4.13.12.1" class="ltx_td ltx_align_left ltx_border_bb">Skin cutaneous melanoma (SKCM)</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Data Sharding</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">The complete dataset was split into vertical partitions, i.e., include all the patients of a given type of cancer and assign all the associated training data to a single site (as is shown in Table <a href="#S2.T2" title="Table 2 ‣ 2.2 Data Sharding ‣ 2 Methods ‣ Federated Learning for the Classification of Tumor Infiltrating Lymphocytes" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>). With this strategy in mind, eight virtual network sites were created with each virtual site assigned to a separate computational node.</p>
</div>
<figure id="S2.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S2.T2.2.1.1" class="ltx_text" style="font-size:90%;">Table 2</span>: </span><span id="S2.T2.3.2" class="ltx_text" style="font-size:90%;">Data split amongst different network sites for training and validation cohorts</span></figcaption>
<table id="S2.T2.4" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S2.T2.4.1.1" class="ltx_tr">
<th id="S2.T2.4.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt"><span id="S2.T2.4.1.1.1.1" class="ltx_text ltx_font_bold">Cohort</span></th>
<th id="S2.T2.4.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">
<table id="S2.T2.4.1.1.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T2.4.1.1.2.1.1" class="ltx_tr">
<td id="S2.T2.4.1.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S2.T2.4.1.1.2.1.1.1.1" class="ltx_text ltx_font_bold">Total</span></td>
</tr>
<tr id="S2.T2.4.1.1.2.1.2" class="ltx_tr">
<td id="S2.T2.4.1.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S2.T2.4.1.1.2.1.2.1.1" class="ltx_text ltx_font_bold">Patients</span></td>
</tr>
</table>
</th>
<th id="S2.T2.4.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">
<table id="S2.T2.4.1.1.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T2.4.1.1.3.1.1" class="ltx_tr">
<td id="S2.T2.4.1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S2.T2.4.1.1.3.1.1.1.1" class="ltx_text ltx_font_bold">Total</span></td>
</tr>
<tr id="S2.T2.4.1.1.3.1.2" class="ltx_tr">
<td id="S2.T2.4.1.1.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S2.T2.4.1.1.3.1.2.1.1" class="ltx_text ltx_font_bold">Patches</span></td>
</tr>
</table>
</th>
<th id="S2.T2.4.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">
<table id="S2.T2.4.1.1.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T2.4.1.1.4.1.1" class="ltx_tr">
<td id="S2.T2.4.1.1.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S2.T2.4.1.1.4.1.1.1.1" class="ltx_text ltx_font_bold">Patients</span></td>
</tr>
<tr id="S2.T2.4.1.1.4.1.2" class="ltx_tr">
<td id="S2.T2.4.1.1.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S2.T2.4.1.1.4.1.2.1.1" class="ltx_text ltx_font_bold">in training</span></td>
</tr>
</table>
</th>
<th id="S2.T2.4.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">
<table id="S2.T2.4.1.1.5.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T2.4.1.1.5.1.1" class="ltx_tr">
<td id="S2.T2.4.1.1.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S2.T2.4.1.1.5.1.1.1.1" class="ltx_text ltx_font_bold">Training</span></td>
</tr>
<tr id="S2.T2.4.1.1.5.1.2" class="ltx_tr">
<td id="S2.T2.4.1.1.5.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S2.T2.4.1.1.5.1.2.1.1" class="ltx_text ltx_font_bold">patches</span></td>
</tr>
</table>
</th>
<th id="S2.T2.4.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">
<table id="S2.T2.4.1.1.6.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T2.4.1.1.6.1.1" class="ltx_tr">
<td id="S2.T2.4.1.1.6.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S2.T2.4.1.1.6.1.1.1.1" class="ltx_text ltx_font_bold">Patients</span></td>
</tr>
<tr id="S2.T2.4.1.1.6.1.2" class="ltx_tr">
<td id="S2.T2.4.1.1.6.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S2.T2.4.1.1.6.1.2.1.1" class="ltx_text ltx_font_bold">in validation</span></td>
</tr>
</table>
</th>
<th id="S2.T2.4.1.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">
<table id="S2.T2.4.1.1.7.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T2.4.1.1.7.1.1" class="ltx_tr">
<td id="S2.T2.4.1.1.7.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S2.T2.4.1.1.7.1.1.1.1" class="ltx_text ltx_font_bold">Validation</span></td>
</tr>
<tr id="S2.T2.4.1.1.7.1.2" class="ltx_tr">
<td id="S2.T2.4.1.1.7.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S2.T2.4.1.1.7.1.2.1.1" class="ltx_text ltx_font_bold">patches</span></td>
</tr>
</table>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S2.T2.4.2.1" class="ltx_tr">
<th id="S2.T2.4.2.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_tt">Site1</th>
<td id="S2.T2.4.2.1.2" class="ltx_td ltx_align_center ltx_border_tt">111</td>
<td id="S2.T2.4.2.1.3" class="ltx_td ltx_align_center ltx_border_tt">13144</td>
<td id="S2.T2.4.2.1.4" class="ltx_td ltx_align_center ltx_border_tt">89</td>
<td id="S2.T2.4.2.1.5" class="ltx_td ltx_align_center ltx_border_tt">10542</td>
<td id="S2.T2.4.2.1.6" class="ltx_td ltx_align_center ltx_border_tt">22</td>
<td id="S2.T2.4.2.1.7" class="ltx_td ltx_align_center ltx_border_tt">2602</td>
</tr>
<tr id="S2.T2.4.3.2" class="ltx_tr">
<th id="S2.T2.4.3.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">Site2</th>
<td id="S2.T2.4.3.2.2" class="ltx_td ltx_align_center">217</td>
<td id="S2.T2.4.3.2.3" class="ltx_td ltx_align_center">25624</td>
<td id="S2.T2.4.3.2.4" class="ltx_td ltx_align_center">174</td>
<td id="S2.T2.4.3.2.5" class="ltx_td ltx_align_center">20517</td>
<td id="S2.T2.4.3.2.6" class="ltx_td ltx_align_center">43</td>
<td id="S2.T2.4.3.2.7" class="ltx_td ltx_align_center">5107</td>
</tr>
<tr id="S2.T2.4.4.3" class="ltx_tr">
<th id="S2.T2.4.4.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">Site3</th>
<td id="S2.T2.4.4.3.2" class="ltx_td ltx_align_center">4</td>
<td id="S2.T2.4.4.3.3" class="ltx_td ltx_align_center">11276</td>
<td id="S2.T2.4.4.3.4" class="ltx_td ltx_align_center">3</td>
<td id="S2.T2.4.4.3.5" class="ltx_td ltx_align_center">11039</td>
<td id="S2.T2.4.4.3.6" class="ltx_td ltx_align_center">1</td>
<td id="S2.T2.4.4.3.7" class="ltx_td ltx_align_center">237</td>
</tr>
<tr id="S2.T2.4.5.4" class="ltx_tr">
<th id="S2.T2.4.5.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">Site4</th>
<td id="S2.T2.4.5.4.2" class="ltx_td ltx_align_center">40</td>
<td id="S2.T2.4.5.4.3" class="ltx_td ltx_align_center">4743</td>
<td id="S2.T2.4.5.4.4" class="ltx_td ltx_align_center">32</td>
<td id="S2.T2.4.5.4.5" class="ltx_td ltx_align_center">3793</td>
<td id="S2.T2.4.5.4.6" class="ltx_td ltx_align_center">8</td>
<td id="S2.T2.4.5.4.7" class="ltx_td ltx_align_center">950</td>
</tr>
<tr id="S2.T2.4.6.5" class="ltx_tr">
<th id="S2.T2.4.6.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">Site5</th>
<td id="S2.T2.4.6.5.2" class="ltx_td ltx_align_center">196</td>
<td id="S2.T2.4.6.5.3" class="ltx_td ltx_align_center">23258</td>
<td id="S2.T2.4.6.5.4" class="ltx_td ltx_align_center">156</td>
<td id="S2.T2.4.6.5.5" class="ltx_td ltx_align_center">18505</td>
<td id="S2.T2.4.6.5.6" class="ltx_td ltx_align_center">40</td>
<td id="S2.T2.4.6.5.7" class="ltx_td ltx_align_center">4753</td>
</tr>
<tr id="S2.T2.4.7.6" class="ltx_tr">
<th id="S2.T2.4.7.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">Site6</th>
<td id="S2.T2.4.7.6.2" class="ltx_td ltx_align_center">24</td>
<td id="S2.T2.4.7.6.3" class="ltx_td ltx_align_center">2438</td>
<td id="S2.T2.4.7.6.4" class="ltx_td ltx_align_center">19</td>
<td id="S2.T2.4.7.6.5" class="ltx_td ltx_align_center">1938</td>
<td id="S2.T2.4.7.6.6" class="ltx_td ltx_align_center">5</td>
<td id="S2.T2.4.7.6.7" class="ltx_td ltx_align_center">500</td>
</tr>
<tr id="S2.T2.4.8.7" class="ltx_tr">
<th id="S2.T2.4.8.7.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">Site7</th>
<td id="S2.T2.4.8.7.2" class="ltx_td ltx_align_center">10</td>
<td id="S2.T2.4.8.7.3" class="ltx_td ltx_align_center">23336</td>
<td id="S2.T2.4.8.7.4" class="ltx_td ltx_align_center">8</td>
<td id="S2.T2.4.8.7.5" class="ltx_td ltx_align_center">16265</td>
<td id="S2.T2.4.8.7.6" class="ltx_td ltx_align_center">2</td>
<td id="S2.T2.4.8.7.7" class="ltx_td ltx_align_center">7091</td>
</tr>
<tr id="S2.T2.4.9.8" class="ltx_tr">
<th id="S2.T2.4.9.8.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb">Site8</th>
<td id="S2.T2.4.9.8.2" class="ltx_td ltx_align_center ltx_border_bb">60</td>
<td id="S2.T2.4.9.8.3" class="ltx_td ltx_align_center ltx_border_bb">51522</td>
<td id="S2.T2.4.9.8.4" class="ltx_td ltx_align_center ltx_border_bb">48</td>
<td id="S2.T2.4.9.8.5" class="ltx_td ltx_align_center ltx_border_bb">39665</td>
<td id="S2.T2.4.9.8.6" class="ltx_td ltx_align_center ltx_border_bb">12</td>
<td id="S2.T2.4.9.8.7" class="ltx_td ltx_align_center ltx_border_bb">11857</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Model Architecture</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">In this study we used the VGG network architecture <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>, <a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> (Figure <a href="#S2.F1" title="Figure 1 ‣ 2.3 Model Architecture ‣ 2 Methods ‣ Federated Learning for the Classification of Tumor Infiltrating Lymphocytes" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>), which is well-known for performing classification and regression workloads, on the ImageNet classification challenge <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>.</p>
</div>
<figure id="S2.F1" class="ltx_figure"><img src="/html/2203.16622/assets/figures/vgg.png" id="S2.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="568" height="208" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F1.2.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S2.F1.3.2" class="ltx_text" style="font-size:90%;">Deep convolutional neural network based VGG type architecture. This figure was created using PlotNeuralNetwork tool <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>.</span></figcaption>
</figure>
<div id="S2.SS3.p2" class="ltx_para">
<p id="S2.SS3.p2.2" class="ltx_p">The VGG network used in the centralized configuration evaluated previously has 16 convolutional layers and 3 dense layers. We have modified the final classifier layers to include a global average pooling layer followed by a single dense layer, which allows greater flexibility for different types of workloads <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>. VGG uses <math id="S2.SS3.p2.1.m1.1" class="ltx_Math" alttext="3\times 3" display="inline"><semantics id="S2.SS3.p2.1.m1.1a"><mrow id="S2.SS3.p2.1.m1.1.1" xref="S2.SS3.p2.1.m1.1.1.cmml"><mn id="S2.SS3.p2.1.m1.1.1.2" xref="S2.SS3.p2.1.m1.1.1.2.cmml">3</mn><mo lspace="0.222em" rspace="0.222em" id="S2.SS3.p2.1.m1.1.1.1" xref="S2.SS3.p2.1.m1.1.1.1.cmml">×</mo><mn id="S2.SS3.p2.1.m1.1.1.3" xref="S2.SS3.p2.1.m1.1.1.3.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.1.m1.1b"><apply id="S2.SS3.p2.1.m1.1.1.cmml" xref="S2.SS3.p2.1.m1.1.1"><times id="S2.SS3.p2.1.m1.1.1.1.cmml" xref="S2.SS3.p2.1.m1.1.1.1"></times><cn type="integer" id="S2.SS3.p2.1.m1.1.1.2.cmml" xref="S2.SS3.p2.1.m1.1.1.2">3</cn><cn type="integer" id="S2.SS3.p2.1.m1.1.1.3.cmml" xref="S2.SS3.p2.1.m1.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.1.m1.1c">3\times 3</annotation></semantics></math> convolution filters and <math id="S2.SS3.p2.2.m2.1" class="ltx_Math" alttext="2\times 2" display="inline"><semantics id="S2.SS3.p2.2.m2.1a"><mrow id="S2.SS3.p2.2.m2.1.1" xref="S2.SS3.p2.2.m2.1.1.cmml"><mn id="S2.SS3.p2.2.m2.1.1.2" xref="S2.SS3.p2.2.m2.1.1.2.cmml">2</mn><mo lspace="0.222em" rspace="0.222em" id="S2.SS3.p2.2.m2.1.1.1" xref="S2.SS3.p2.2.m2.1.1.1.cmml">×</mo><mn id="S2.SS3.p2.2.m2.1.1.3" xref="S2.SS3.p2.2.m2.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.2.m2.1b"><apply id="S2.SS3.p2.2.m2.1.1.cmml" xref="S2.SS3.p2.2.m2.1.1"><times id="S2.SS3.p2.2.m2.1.1.1.cmml" xref="S2.SS3.p2.2.m2.1.1.1"></times><cn type="integer" id="S2.SS3.p2.2.m2.1.1.2.cmml" xref="S2.SS3.p2.2.m2.1.1.2">2</cn><cn type="integer" id="S2.SS3.p2.2.m2.1.1.3.cmml" xref="S2.SS3.p2.2.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.2.m2.1c">2\times 2</annotation></semantics></math> max-pooling layers with a stride of 2 throughout the architecture. The original architecture uses ReLU activation function <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite> and categorical cross-entropy loss function. The initial layers of the VGG perform feature extraction and the last sigmoid layers act as the classifier.</p>
</div>
<div id="S2.SS3.p3" class="ltx_para">
<p id="S2.SS3.p3.3" class="ltx_p">The model configuration used in the federated learning setting, was initialized using randomized weights and used as the starting point for all sites. The VGG network is trained with patch size of <math id="S2.SS3.p3.1.m1.1" class="ltx_Math" alttext="300\times 300" display="inline"><semantics id="S2.SS3.p3.1.m1.1a"><mrow id="S2.SS3.p3.1.m1.1.1" xref="S2.SS3.p3.1.m1.1.1.cmml"><mn id="S2.SS3.p3.1.m1.1.1.2" xref="S2.SS3.p3.1.m1.1.1.2.cmml">300</mn><mo lspace="0.222em" rspace="0.222em" id="S2.SS3.p3.1.m1.1.1.1" xref="S2.SS3.p3.1.m1.1.1.1.cmml">×</mo><mn id="S2.SS3.p3.1.m1.1.1.3" xref="S2.SS3.p3.1.m1.1.1.3.cmml">300</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p3.1.m1.1b"><apply id="S2.SS3.p3.1.m1.1.1.cmml" xref="S2.SS3.p3.1.m1.1.1"><times id="S2.SS3.p3.1.m1.1.1.1.cmml" xref="S2.SS3.p3.1.m1.1.1.1"></times><cn type="integer" id="S2.SS3.p3.1.m1.1.1.2.cmml" xref="S2.SS3.p3.1.m1.1.1.2">300</cn><cn type="integer" id="S2.SS3.p3.1.m1.1.1.3.cmml" xref="S2.SS3.p3.1.m1.1.1.3">300</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p3.1.m1.1c">300\times 300</annotation></semantics></math>, are normalised between <math id="S2.SS3.p3.2.m2.2" class="ltx_Math" alttext="[0,1]" display="inline"><semantics id="S2.SS3.p3.2.m2.2a"><mrow id="S2.SS3.p3.2.m2.2.3.2" xref="S2.SS3.p3.2.m2.2.3.1.cmml"><mo stretchy="false" id="S2.SS3.p3.2.m2.2.3.2.1" xref="S2.SS3.p3.2.m2.2.3.1.cmml">[</mo><mn id="S2.SS3.p3.2.m2.1.1" xref="S2.SS3.p3.2.m2.1.1.cmml">0</mn><mo id="S2.SS3.p3.2.m2.2.3.2.2" xref="S2.SS3.p3.2.m2.2.3.1.cmml">,</mo><mn id="S2.SS3.p3.2.m2.2.2" xref="S2.SS3.p3.2.m2.2.2.cmml">1</mn><mo stretchy="false" id="S2.SS3.p3.2.m2.2.3.2.3" xref="S2.SS3.p3.2.m2.2.3.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p3.2.m2.2b"><interval closure="closed" id="S2.SS3.p3.2.m2.2.3.1.cmml" xref="S2.SS3.p3.2.m2.2.3.2"><cn type="integer" id="S2.SS3.p3.2.m2.1.1.cmml" xref="S2.SS3.p3.2.m2.1.1">0</cn><cn type="integer" id="S2.SS3.p3.2.m2.2.2.cmml" xref="S2.SS3.p3.2.m2.2.2">1</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p3.2.m2.2c">[0,1]</annotation></semantics></math>. Sigmoid layer is used as final layer for classification. The model is trained with initial learning rate of <math id="S2.SS3.p3.3.m3.1" class="ltx_Math" alttext="0.001" display="inline"><semantics id="S2.SS3.p3.3.m3.1a"><mn id="S2.SS3.p3.3.m3.1.1" xref="S2.SS3.p3.3.m3.1.1.cmml">0.001</mn><annotation-xml encoding="MathML-Content" id="S2.SS3.p3.3.m3.1b"><cn type="float" id="S2.SS3.p3.3.m3.1.1.cmml" xref="S2.SS3.p3.3.m3.1.1">0.001</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p3.3.m3.1c">0.001</annotation></semantics></math>. The cross entropy loss with adam optimizer is used to update the weights of the model during training.</p>
</div>
</section>
<section id="S2.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.4 </span>Model Training and Prediction</h3>

<div id="S2.SS4.p1" class="ltx_para">
<p id="S2.SS4.p1.2" class="ltx_p">In a centralized training scenario, all of the training and validation patches are used to train a classification model. In the inference (prediction) phase, an input WSI is partitioned into patches of <math id="S2.SS4.p1.1.m1.1" class="ltx_Math" alttext="50\times 50" display="inline"><semantics id="S2.SS4.p1.1.m1.1a"><mrow id="S2.SS4.p1.1.m1.1.1" xref="S2.SS4.p1.1.m1.1.1.cmml"><mn id="S2.SS4.p1.1.m1.1.1.2" xref="S2.SS4.p1.1.m1.1.1.2.cmml">50</mn><mo lspace="0.222em" rspace="0.222em" id="S2.SS4.p1.1.m1.1.1.1" xref="S2.SS4.p1.1.m1.1.1.1.cmml">×</mo><mn id="S2.SS4.p1.1.m1.1.1.3" xref="S2.SS4.p1.1.m1.1.1.3.cmml">50</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS4.p1.1.m1.1b"><apply id="S2.SS4.p1.1.m1.1.1.cmml" xref="S2.SS4.p1.1.m1.1.1"><times id="S2.SS4.p1.1.m1.1.1.1.cmml" xref="S2.SS4.p1.1.m1.1.1.1"></times><cn type="integer" id="S2.SS4.p1.1.m1.1.1.2.cmml" xref="S2.SS4.p1.1.m1.1.1.2">50</cn><cn type="integer" id="S2.SS4.p1.1.m1.1.1.3.cmml" xref="S2.SS4.p1.1.m1.1.1.3">50</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p1.1.m1.1c">50\times 50</annotation></semantics></math> square microns. Each patch is processed by the trained model, and the model assigns a probability value between <math id="S2.SS4.p1.2.m2.2" class="ltx_Math" alttext="[0.0,1.0]" display="inline"><semantics id="S2.SS4.p1.2.m2.2a"><mrow id="S2.SS4.p1.2.m2.2.3.2" xref="S2.SS4.p1.2.m2.2.3.1.cmml"><mo stretchy="false" id="S2.SS4.p1.2.m2.2.3.2.1" xref="S2.SS4.p1.2.m2.2.3.1.cmml">[</mo><mn id="S2.SS4.p1.2.m2.1.1" xref="S2.SS4.p1.2.m2.1.1.cmml">0.0</mn><mo id="S2.SS4.p1.2.m2.2.3.2.2" xref="S2.SS4.p1.2.m2.2.3.1.cmml">,</mo><mn id="S2.SS4.p1.2.m2.2.2" xref="S2.SS4.p1.2.m2.2.2.cmml">1.0</mn><mo stretchy="false" id="S2.SS4.p1.2.m2.2.3.2.3" xref="S2.SS4.p1.2.m2.2.3.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS4.p1.2.m2.2b"><interval closure="closed" id="S2.SS4.p1.2.m2.2.3.1.cmml" xref="S2.SS4.p1.2.m2.2.3.2"><cn type="float" id="S2.SS4.p1.2.m2.1.1.cmml" xref="S2.SS4.p1.2.m2.1.1">0.0</cn><cn type="float" id="S2.SS4.p1.2.m2.2.2.cmml" xref="S2.SS4.p1.2.m2.2.2">1.0</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p1.2.m2.2c">[0.0,1.0]</annotation></semantics></math> of the patch being TIL-positive. After all of the patches are processed, a probability map is created to show the distribution of TIL patches across the WSI.</p>
</div>
<div id="S2.SS4.p2" class="ltx_para">
<p id="S2.SS4.p2.1" class="ltx_p">Each “federated training round” is defined as each site training the model on their data for a pre-defined number of epochs and providing model updates to be aggregated. For this study, the model was trained for <math id="S2.SS4.p2.1.m1.1" class="ltx_Math" alttext="500" display="inline"><semantics id="S2.SS4.p2.1.m1.1a"><mn id="S2.SS4.p2.1.m1.1.1" xref="S2.SS4.p2.1.m1.1.1.cmml">500</mn><annotation-xml encoding="MathML-Content" id="S2.SS4.p2.1.m1.1b"><cn type="integer" id="S2.SS4.p2.1.m1.1.1.cmml" xref="S2.SS4.p2.1.m1.1.1">500</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p2.1.m1.1c">500</annotation></semantics></math> federated rounds, where each site trained the model for a single epoch for each federated round by leveraging an independent aggregation server <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>.</p>
</div>
</section>
<section id="S2.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.5 </span>Experimental Design</h3>

<div id="S2.SS5.p1" class="ltx_para">
<p id="S2.SS5.p1.1" class="ltx_p">The complete study described here was facilitated by the model and training infrastructure provided by the Generally Nuanced Deep Learning Framework (GaNDLF) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>. We federate <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> the model and the entire training pipeline using the Open Federated Learning (OpenFL) library <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>, which allows the model to be trained across multiple sites across the collaborative network without sharing any data. The quantitative performance evaluation was done using balanced classification accuracy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>.

</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Results</h2>

<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Quantitative Evaluation</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">The performance evaluation in terms of balanced classification accuracy for each individual site and the consensus model is shown in Table <a href="#S3.T3" title="Table 3 ‣ 3.1 Quantitative Evaluation ‣ 3 Results ‣ Federated Learning for the Classification of Tumor Infiltrating Lymphocytes" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. In the centralized training scenario we achieved accuracy of <math id="S3.SS1.p1.1.m1.1" class="ltx_Math" alttext="0.75" display="inline"><semantics id="S3.SS1.p1.1.m1.1a"><mn id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">0.75</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><cn type="float" id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">0.75</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">0.75</annotation></semantics></math>.</p>
</div>
<figure id="S3.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S3.T3.2.1.1" class="ltx_text" style="font-size:90%;">Table 3</span>: </span><span id="S3.T3.3.2" class="ltx_text" style="font-size:90%;">Performance evaluation in terms of balanced classification accuracy for individual sites and the consensus model on the validation dataset</span></figcaption>
<table id="S3.T3.4" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T3.4.1.1" class="ltx_tr">
<th id="S3.T3.4.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Model(row)\Data(col)</th>
<th id="S3.T3.4.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Site1</th>
<th id="S3.T3.4.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Site2</th>
<th id="S3.T3.4.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Site3</th>
<th id="S3.T3.4.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Site4</th>
<th id="S3.T3.4.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Site5</th>
<th id="S3.T3.4.1.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Site6</th>
<th id="S3.T3.4.1.1.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Site7</th>
<th id="S3.T3.4.1.1.9" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Site8</th>
<th id="S3.T3.4.1.1.10" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Average</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T3.4.2.1" class="ltx_tr">
<td id="S3.T3.4.2.1.1" class="ltx_td ltx_align_center ltx_border_tt">Site 1 model</td>
<td id="S3.T3.4.2.1.2" class="ltx_td ltx_align_center ltx_border_tt">0.90</td>
<td id="S3.T3.4.2.1.3" class="ltx_td ltx_align_center ltx_border_tt">0.88</td>
<td id="S3.T3.4.2.1.4" class="ltx_td ltx_align_center ltx_border_tt">0.78</td>
<td id="S3.T3.4.2.1.5" class="ltx_td ltx_align_center ltx_border_tt">0.80</td>
<td id="S3.T3.4.2.1.6" class="ltx_td ltx_align_center ltx_border_tt">0.86</td>
<td id="S3.T3.4.2.1.7" class="ltx_td ltx_align_center ltx_border_tt">0.97</td>
<td id="S3.T3.4.2.1.8" class="ltx_td ltx_align_center ltx_border_tt">0.86</td>
<td id="S3.T3.4.2.1.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">0.82</td>
<td id="S3.T3.4.2.1.10" class="ltx_td ltx_align_center ltx_border_tt">0.86</td>
</tr>
<tr id="S3.T3.4.3.2" class="ltx_tr">
<td id="S3.T3.4.3.2.1" class="ltx_td ltx_align_center">Site 2 model</td>
<td id="S3.T3.4.3.2.2" class="ltx_td ltx_align_center">0.90</td>
<td id="S3.T3.4.3.2.3" class="ltx_td ltx_align_center">0.90</td>
<td id="S3.T3.4.3.2.4" class="ltx_td ltx_align_center">0.72</td>
<td id="S3.T3.4.3.2.5" class="ltx_td ltx_align_center">0.84</td>
<td id="S3.T3.4.3.2.6" class="ltx_td ltx_align_center">0.88</td>
<td id="S3.T3.4.3.2.7" class="ltx_td ltx_align_center">0.97</td>
<td id="S3.T3.4.3.2.8" class="ltx_td ltx_align_center">0.84</td>
<td id="S3.T3.4.3.2.9" class="ltx_td ltx_align_center ltx_border_r">0.79</td>
<td id="S3.T3.4.3.2.10" class="ltx_td ltx_align_center">0.85</td>
</tr>
<tr id="S3.T3.4.4.3" class="ltx_tr">
<td id="S3.T3.4.4.3.1" class="ltx_td ltx_align_center">Site 3 model</td>
<td id="S3.T3.4.4.3.2" class="ltx_td ltx_align_center">0.85</td>
<td id="S3.T3.4.4.3.3" class="ltx_td ltx_align_center">0.84</td>
<td id="S3.T3.4.4.3.4" class="ltx_td ltx_align_center">0.87</td>
<td id="S3.T3.4.4.3.5" class="ltx_td ltx_align_center">0.82</td>
<td id="S3.T3.4.4.3.6" class="ltx_td ltx_align_center">0.82</td>
<td id="S3.T3.4.4.3.7" class="ltx_td ltx_align_center">0.98</td>
<td id="S3.T3.4.4.3.8" class="ltx_td ltx_align_center">0.96</td>
<td id="S3.T3.4.4.3.9" class="ltx_td ltx_align_center ltx_border_r">0.84</td>
<td id="S3.T3.4.4.3.10" class="ltx_td ltx_align_center">0.87</td>
</tr>
<tr id="S3.T3.4.5.4" class="ltx_tr">
<td id="S3.T3.4.5.4.1" class="ltx_td ltx_align_center">Site 4 model</td>
<td id="S3.T3.4.5.4.2" class="ltx_td ltx_align_center">0.78</td>
<td id="S3.T3.4.5.4.3" class="ltx_td ltx_align_center">0.80</td>
<td id="S3.T3.4.5.4.4" class="ltx_td ltx_align_center">0.56</td>
<td id="S3.T3.4.5.4.5" class="ltx_td ltx_align_center">0.86</td>
<td id="S3.T3.4.5.4.6" class="ltx_td ltx_align_center">0.81</td>
<td id="S3.T3.4.5.4.7" class="ltx_td ltx_align_center">0.93</td>
<td id="S3.T3.4.5.4.8" class="ltx_td ltx_align_center">0.63</td>
<td id="S3.T3.4.5.4.9" class="ltx_td ltx_align_center ltx_border_r">0.72</td>
<td id="S3.T3.4.5.4.10" class="ltx_td ltx_align_center">0.76</td>
</tr>
<tr id="S3.T3.4.6.5" class="ltx_tr">
<td id="S3.T3.4.6.5.1" class="ltx_td ltx_align_center">Site 5 model</td>
<td id="S3.T3.4.6.5.2" class="ltx_td ltx_align_center">0.88</td>
<td id="S3.T3.4.6.5.3" class="ltx_td ltx_align_center">0.88</td>
<td id="S3.T3.4.6.5.4" class="ltx_td ltx_align_center">0.70</td>
<td id="S3.T3.4.6.5.5" class="ltx_td ltx_align_center">0.86</td>
<td id="S3.T3.4.6.5.6" class="ltx_td ltx_align_center">0.88</td>
<td id="S3.T3.4.6.5.7" class="ltx_td ltx_align_center">0.97</td>
<td id="S3.T3.4.6.5.8" class="ltx_td ltx_align_center">0.80</td>
<td id="S3.T3.4.6.5.9" class="ltx_td ltx_align_center ltx_border_r">0.79</td>
<td id="S3.T3.4.6.5.10" class="ltx_td ltx_align_center">0.85</td>
</tr>
<tr id="S3.T3.4.7.6" class="ltx_tr">
<td id="S3.T3.4.7.6.1" class="ltx_td ltx_align_center">Site 6 model</td>
<td id="S3.T3.4.7.6.2" class="ltx_td ltx_align_center">0.78</td>
<td id="S3.T3.4.7.6.3" class="ltx_td ltx_align_center">0.74</td>
<td id="S3.T3.4.7.6.4" class="ltx_td ltx_align_center">0.59</td>
<td id="S3.T3.4.7.6.5" class="ltx_td ltx_align_center">0.76</td>
<td id="S3.T3.4.7.6.6" class="ltx_td ltx_align_center">0.72</td>
<td id="S3.T3.4.7.6.7" class="ltx_td ltx_align_center">1.00</td>
<td id="S3.T3.4.7.6.8" class="ltx_td ltx_align_center">0.97</td>
<td id="S3.T3.4.7.6.9" class="ltx_td ltx_align_center ltx_border_r">0.73</td>
<td id="S3.T3.4.7.6.10" class="ltx_td ltx_align_center">0.79</td>
</tr>
<tr id="S3.T3.4.8.7" class="ltx_tr">
<td id="S3.T3.4.8.7.1" class="ltx_td ltx_align_center">Site 7 model</td>
<td id="S3.T3.4.8.7.2" class="ltx_td ltx_align_center">0.82</td>
<td id="S3.T3.4.8.7.3" class="ltx_td ltx_align_center">0.79</td>
<td id="S3.T3.4.8.7.4" class="ltx_td ltx_align_center">0.75</td>
<td id="S3.T3.4.8.7.5" class="ltx_td ltx_align_center">0.76</td>
<td id="S3.T3.4.8.7.6" class="ltx_td ltx_align_center">0.75</td>
<td id="S3.T3.4.8.7.7" class="ltx_td ltx_align_center">0.97</td>
<td id="S3.T3.4.8.7.8" class="ltx_td ltx_align_center">0.97</td>
<td id="S3.T3.4.8.7.9" class="ltx_td ltx_align_center ltx_border_r">0.80</td>
<td id="S3.T3.4.8.7.10" class="ltx_td ltx_align_center">0.83</td>
</tr>
<tr id="S3.T3.4.9.8" class="ltx_tr">
<td id="S3.T3.4.9.8.1" class="ltx_td ltx_align_center">Site 8 model</td>
<td id="S3.T3.4.9.8.2" class="ltx_td ltx_align_center">0.83</td>
<td id="S3.T3.4.9.8.3" class="ltx_td ltx_align_center">0.81</td>
<td id="S3.T3.4.9.8.4" class="ltx_td ltx_align_center">0.71</td>
<td id="S3.T3.4.9.8.5" class="ltx_td ltx_align_center">0.81</td>
<td id="S3.T3.4.9.8.6" class="ltx_td ltx_align_center">0.79</td>
<td id="S3.T3.4.9.8.7" class="ltx_td ltx_align_center">0.99</td>
<td id="S3.T3.4.9.8.8" class="ltx_td ltx_align_center">0.94</td>
<td id="S3.T3.4.9.8.9" class="ltx_td ltx_align_center ltx_border_r">0.88</td>
<td id="S3.T3.4.9.8.10" class="ltx_td ltx_align_center">0.84</td>
</tr>
<tr id="S3.T3.4.10.9" class="ltx_tr">
<td id="S3.T3.4.10.9.1" class="ltx_td ltx_align_center ltx_border_bb">Consensus model</td>
<td id="S3.T3.4.10.9.2" class="ltx_td ltx_align_center ltx_border_bb">0.88</td>
<td id="S3.T3.4.10.9.3" class="ltx_td ltx_align_center ltx_border_bb">0.88</td>
<td id="S3.T3.4.10.9.4" class="ltx_td ltx_align_center ltx_border_bb">0.81</td>
<td id="S3.T3.4.10.9.5" class="ltx_td ltx_align_center ltx_border_bb">0.85</td>
<td id="S3.T3.4.10.9.6" class="ltx_td ltx_align_center ltx_border_bb">0.86</td>
<td id="S3.T3.4.10.9.7" class="ltx_td ltx_align_center ltx_border_bb">0.98</td>
<td id="S3.T3.4.10.9.8" class="ltx_td ltx_align_center ltx_border_bb">0.95</td>
<td id="S3.T3.4.10.9.9" class="ltx_td ltx_align_center ltx_border_bb">0.87</td>
<td id="S3.T3.4.10.9.10" class="ltx_td ltx_align_center ltx_border_bb">0.89</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Qualitative Evaluation</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">Figure <a href="#S3.F2" title="Figure 2 ‣ 3.2 Qualitative Evaluation ‣ 3 Results ‣ Federated Learning for the Classification of Tumor Infiltrating Lymphocytes" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>(a) shows a visualization of patch-level probabilities from the original TIL classification model trained with all of the data in a centralized location. The patch-level probabilities are stitched together to generate a TIL heatmap overlaid on the source WSI. The RED-colored regions indicate high probability of TILs predicted by the models. The TIL predictions from the federated and site-specific models are shown in Figure <a href="#S3.F2" title="Figure 2 ‣ 3.2 Qualitative Evaluation ‣ 3 Results ‣ Federated Learning for the Classification of Tumor Infiltrating Lymphocytes" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>(b) and (c), respectively. The federated consensus model predicts a TIL map that is qualitatively similar to the curated TIL map generated by the centralized model. In this example, the site-specific model predictions also appear quite similar even though this model is not trained with the entire training dataset. Even though these TIL maps look similar overall, qualitative differences are evident in terms of both the abundance and spatial distribution of TILs when comparing the federated consensus model with the site-specific model.</p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2203.16622/assets/figures/models.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="568" height="142" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F2.2.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S3.F2.3.2" class="ltx_text" style="font-size:90%;">Predictions from different models displayed as heatmaps overlaid on the source whole slide image. (a) Predictions from the original model trained with all of the training data at a centralized location. (b) Predictions from the consensus model trained with the federated learning approach using data from all the sites. (c) Predictions from the model trained with data from a single site only.</span></figcaption>
</figure>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Discussion</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">In this study, we generated anatomic site-specific and a federated consensus model to classify tissue regions that contain TILs. Overall, TIL maps generated with the consensus model trained in a federated manner appear comparable to the output of the original VGG16 TIL model, trained by centrally collecting all of the data in a single location <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>. We have also shown that there are differences in performance when the TIL models are trained with anatomic site-specific data. We evaluated performance by using held-out local validation data from each anatomic cancer site. We also performed qualitative analysis on completely unseen held-out data.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.1" class="ltx_p">The detection of TILs across WSIs of cancer was conceived based on the fairly consistent appearance of lymphocytes in normal and cancer tissues across anatomical sites. Lymphocytes are typically 8-12 um in size, round to ovoid in shape with dark blue-purple nuclei, and contain scant cytoplasm. However, detecting lymphocytes, which are called TILs within the spatial context of cancer, is challenging based on the ability of the models to distinguish TILs from cancer and other types of cells that may have overlapping features. Therefore, the original TIL model was trained with a centralized approach to provide the model with plenty of examples of non-lymphocytes and non-TILs across the complex microscopic landscapes of both normal and cancer tissues to develop a robust pan-cancer model.</p>
</div>
<div id="S4.p3" class="ltx_para">
<p id="S4.p3.1" class="ltx_p">Figure <a href="#S4.F3" title="Figure 3 ‣ 4 Discussion ‣ Federated Learning for the Classification of Tumor Infiltrating Lymphocytes" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> expands upon Figure <a href="#S3.F2" title="Figure 2 ‣ 3.2 Qualitative Evaluation ‣ 3 Results ‣ Federated Learning for the Classification of Tumor Infiltrating Lymphocytes" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> to provide further insights into the nuances of model performance, where site-specific models (from Sites 1, 2, 3, and 5) generate TIL maps that appear quite similar. The TIL maps generated with models using training data from sites 4 and 8 also appear similar to one another with increased TILs in the left portion of the WSI at the left side of the displayed figure, which is qualitatively different from the TIL maps from site-specific models 1, 2, 3, and 5. The TIL map generated with the model from site 7 appears more conservative in comparison to models from sites 1-5 and 8, in terms of predicting less TILs globally. Notably, the model from site 6 does not predict any TILs since uveal melanoma (UVM) of the eye is typically not associated with TILs, which indicates the scarcity of TIL positive training patches. Furthermore, UVM is actually used as a negative control to test the specificity of the original TIL model in distinguishing TILs from melanoma tumor cells that can have features which mimic lymphocytes.</p>
</div>
<figure id="S4.F3" class="ltx_figure"><img src="/html/2203.16622/assets/figures/BreastCancer.png" id="S4.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="346" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F3.2.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S4.F3.3.2" class="ltx_text" style="font-size:90%;">TIL heatmaps from federated training corresponding to the hematoxylin and eosin (H&amp;E) stained WSI of breast cancer, TCGA-AO-A0JC-DX1. The TIL map from the original VGG16 TIL model, trained with all of the training data at a centralized location, is shown before displaying predicted TIL maps from models trained at each anatomic site. The consensus model trained with the federated training approach using data from all the sites is shown afterwards. Visually representing the TIL maps from the various models allows qualitative evaluation of model performance for each site and consensus with respect to the original centralized VGG16 TIL model within the federated training paradigm.</span></figcaption>
</figure>
<div id="S4.p4" class="ltx_para">
<p id="S4.p4.1" class="ltx_p">The performance of the models trained on site-specific data is dependent on the distribution of training data, specifically whether all training labels were present and if there were enough subjects in the site to warrant meaningful training. For example, it is observed (Table <a href="#S3.T3" title="Table 3 ‣ 3.1 Quantitative Evaluation ‣ 3 Results ‣ Federated Learning for the Classification of Tumor Infiltrating Lymphocytes" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>) that Site 6 has a perfect classification performance on its own validation dataset. After further investigation we confirmed that the validation data of Site 6 includes only non-TIL patches. This shows the value of training such models in a federated setting, which allows sites that do not have enough data to be able to learn from a global consensus, thus improving their own model performance. Also, from Table 3 it can be concluded that the federated consensus model performed better than the individual sites in terms of average balanced classification accuracy.</p>
</div>
<div id="S4.p5" class="ltx_para">
<p id="S4.p5.1" class="ltx_p">We have evaluated the federated training paradigm using a single network architecture, and this can be expanded to include multiple architecture types to analyze which one is more suitable with regards to communication efficiency, overall convergence stability, and data privacy. Additionally, a more rigorous analysis with varying data splits is needed to provide a holistic picture of the federated training paradigm in this vertical situation. Finally, the entire study was based on simulating a federated learning paradigm on a single institution’s network, but still using different computational nodes, and needs to be expanded to multiple institutions to showcase a more realistic deployment.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Funding</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">Research reported in this publication was partly supported by the National Institutes of Health (NIH) under award numbers NIH/NCI:U01CA242871, NIH/NINDS:R01NS042645, NIH/NCI:U24CA189523, NIH/NCI:UG3CA225021, NIH/NCI:4UH3CA225021, NIH/NCI:U24CA215109, and NCI/NIH:U24CA180924. The content of this publication is solely the responsibility of the authors and does not represent the official views of the NIH.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Z. Obermeyer and E. J. Emanuel, “Predicting the future—big data, machine
learning, and clinical medicine,” <span id="bib.bib1.1.1" class="ltx_text ltx_font_italic">The New England journal of medicine</span>,
vol. 375, no. 13, p. 1216, 2016.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
S. G. Armato III, G. McLennan, M. F. McNitt-Gray, C. R. Meyer, D. Yankelevitz,
D. R. Aberle, C. I. Henschke, E. A. Hoffman, E. A. Kazerooni, H. MacMahon,
<span id="bib.bib2.1.1" class="ltx_text ltx_font_italic">et al.</span>, “Lung image database consortium: developing a resource for the
medical imaging research community,” <span id="bib.bib2.2.2" class="ltx_text ltx_font_italic">Radiology</span>, vol. 232, no. 3,
pp. 739–748, 2004.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
P. M. Thompson, J. L. Stein, S. E. Medland, D. P. Hibar, A. A. Vasquez, M. E.
Renteria, R. Toro, N. Jahanshad, G. Schumann, B. Franke, <span id="bib.bib3.1.1" class="ltx_text ltx_font_italic">et al.</span>, “The
enigma consortium: large-scale collaborative analyses of neuroimaging and
genetic data,” <span id="bib.bib3.2.2" class="ltx_text ltx_font_italic">Brain imaging and behavior</span>, vol. 8, no. 2,
pp. 153–182, 2014.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
T. G. Consortium, “Glioma through the looking GLASS: molecular evolution of
diffuse gliomas and the Glioma Longitudinal Analysis Consortium,” <span id="bib.bib4.1.1" class="ltx_text ltx_font_italic">Neuro-Oncology</span>, vol. 20, pp. 873–884, 02 2018.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
S. Bakas, D. R. Ormond, K. D. Alfaro-Munoz, M. Smits, L. A. D. Cooper,
R. Verhaak, and L. M. Poisson, “iglass: imaging integration into the glioma
longitudinal analysis consortium,” <span id="bib.bib5.1.1" class="ltx_text ltx_font_italic">Neuro-oncology</span>, vol. 22, no. 10,
pp. 1545–1546, 2020.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
C. Davatzikos, J. S. Barnholtz-Sloan, S. Bakas, R. Colen, A. Mahajan, C. B.
Quintero, J. Capellades Font, J. Puig, R. Jain, A. E. Sloan, <span id="bib.bib6.1.1" class="ltx_text ltx_font_italic">et al.</span>,
“Ai-based prognostic imaging biomarkers for precision neuro-oncology: the
respond consortium,” <span id="bib.bib6.2.2" class="ltx_text ltx_font_italic">Neuro-oncology</span>, vol. 22, no. 6, pp. 886–888,
2020.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
M. Habes, R. Pomponio, H. Shou, J. Doshi, E. Mamourian, G. Erus, I. Nasrallah,
L. J. Launer, T. Rashid, M. Bilgel, <span id="bib.bib7.1.1" class="ltx_text ltx_font_italic">et al.</span>, “The brain chart of aging:
Machine-learning analytics reveals links between brain aging, white matter
disease, amyloid burden, and cognition in the istaging consortium of 10,216
harmonized mr scans,” <span id="bib.bib7.2.2" class="ltx_text ltx_font_italic">Alzheimer’s &amp; Dementia</span>, vol. 17, no. 1,
pp. 89–102, 2021.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
G. J. Annas <span id="bib.bib8.1.1" class="ltx_text ltx_font_italic">et al.</span>, “Hipaa regulations-a new era of medical-record
privacy?,” <span id="bib.bib8.2.2" class="ltx_text ltx_font_italic">New England Journal of Medicine</span>, vol. 348, no. 15,
pp. 1486–1490, 2003.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
P. Voigt and A. Von dem Bussche, “The eu general data protection regulation
(gdpr),” <span id="bib.bib9.1.1" class="ltx_text ltx_font_italic">A Practical Guide, 1st Ed., Cham: Springer International
Publishing</span>, vol. 10, p. 3152676, 2017.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas,
“Communication-efficient learning of deep networks from decentralized
data,” in <span id="bib.bib10.1.1" class="ltx_text ltx_font_italic">Artificial intelligence and statistics</span>, pp. 1273–1282,
PMLR, 2017.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
M. J. Sheller, G. A. Reina, B. Edwards, J. Martin, and S. Bakas,
“Multi-institutional deep learning modeling without sharing patient data: A
feasibility study on brain tumor segmentation,” in <span id="bib.bib11.1.1" class="ltx_text ltx_font_italic">International MICCAI
Brainlesion Workshop</span>, pp. 92–104, Springer, 2018.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
M. J. Sheller, B. Edwards, G. A. Reina, J. Martin, S. Pati, A. Kotrotsou,
M. Milchenko, W. Xu, D. Marcus, R. R. Colen, <span id="bib.bib12.1.1" class="ltx_text ltx_font_italic">et al.</span>, “Federated
learning in medicine: facilitating multi-institutional collaborations without
sharing patient data,” <span id="bib.bib12.2.2" class="ltx_text ltx_font_italic">Scientific reports</span>, vol. 10, no. 1, pp. 1–12,
2020.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
N. Rieke, J. Hancox, W. Li, F. Milletari, H. R. Roth, S. Albarqouni, S. Bakas,
M. N. Galtier, B. A. Landman, K. Maier-Hein, <span id="bib.bib13.1.1" class="ltx_text ltx_font_italic">et al.</span>, “The future of
digital health with federated learning,” <span id="bib.bib13.2.2" class="ltx_text ltx_font_italic">NPJ digital medicine</span>, vol. 3,
no. 1, pp. 1–7, 2020.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
I. Dayan, H. R. Roth, A. Zhong, A. Harouni, A. Gentili, A. Z. Abidin, A. Liu,
A. B. Costa, B. J. Wood, C.-S. Tsai, <span id="bib.bib14.1.1" class="ltx_text ltx_font_italic">et al.</span>, “Federated learning for
predicting clinical outcomes in patients with covid-19,” <span id="bib.bib14.2.2" class="ltx_text ltx_font_italic">Nature
medicine</span>, vol. 27, no. 10, pp. 1735–1743, 2021.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
K. Chang, N. Balachandar, C. Lam, D. Yi, J. Brown, A. Beers, B. Rosen, D. L.
Rubin, and J. Kalpathy-Cramer, “Distributed deep learning networks among
institutions for medical imaging,” <span id="bib.bib15.1.1" class="ltx_text ltx_font_italic">Journal of the American Medical
Informatics Association</span>, vol. 25, no. 8, pp. 945–954, 2018.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
A. Nilsson, S. Smith, G. Ulm, E. Gustavsson, and M. Jirstrand, “A performance
evaluation of federated learning algorithms,” in <span id="bib.bib16.1.1" class="ltx_text ltx_font_italic">Proceedings of the
Second Workshop on Distributed Infrastructures for Deep Learning</span>, pp. 1–8,
2018.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
K. V. Sarma, S. Harmon, T. Sanford, H. R. Roth, Z. Xu, J. Tetreault, D. Xu,
M. G. Flores, A. G. Raman, R. Kulkarni, <span id="bib.bib17.1.1" class="ltx_text ltx_font_italic">et al.</span>, “Federated learning
improves site performance in multicenter deep learning without data
sharing,” <span id="bib.bib17.2.2" class="ltx_text ltx_font_italic">Journal of the American Medical Informatics Association</span>,
vol. 28, no. 6, pp. 1259–1264, 2021.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
C. Shen, P. Wang, H. R. Roth, D. Yang, D. Xu, M. Oda, W. Wang, C.-S. Fuh, P.-T.
Chen, K.-L. Liu, <span id="bib.bib18.1.1" class="ltx_text ltx_font_italic">et al.</span>, “Multi-task federated learning for
heterogeneous pancreas segmentation,” in <span id="bib.bib18.2.2" class="ltx_text ltx_font_italic">Clinical Image-Based
Procedures, Distributed and Collaborative Learning, Artificial Intelligence
for Combating COVID-19 and Secure and Privacy-Preserving Machine Learning</span>,
pp. 101–110, Springer, 2021.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
D. Yang, Z. Xu, W. Li, A. Myronenko, H. R. Roth, S. Harmon, S. Xu, B. Turkbey,
E. Turkbey, X. Wang, <span id="bib.bib19.1.1" class="ltx_text ltx_font_italic">et al.</span>, “Federated semi-supervised learning for
covid region segmentation in chest ct using multi-national data from china,
italy, japan,” <span id="bib.bib19.2.2" class="ltx_text ltx_font_italic">Medical image analysis</span>, vol. 70, p. 101992, 2021.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
B. Mlecnik, M. Tosolini, A. Kirilovsky, A. Berger, G. Bindea, T. Meatchi,
P. Bruneval, Z. Trajanoski, W.-H. Fridman, F. Pagès, <span id="bib.bib20.1.1" class="ltx_text ltx_font_italic">et al.</span>,
“Histopathologic-based prognostic factors of colorectal cancers are
associated with the state of the local immune reaction,” <span id="bib.bib20.2.2" class="ltx_text ltx_font_italic">Journal of
clinical oncology</span>, vol. 29, no. 6, pp. 610–618, 2011.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
G. Badalamenti, D. Fanale, L. Incorvaia, N. Barraco, A. Listi, R. Maragliano,
B. Vincenzi, V. Calo, J. L. Iovanna, V. Bazan, <span id="bib.bib21.1.1" class="ltx_text ltx_font_italic">et al.</span>, “Role of
tumor-infiltrating lymphocytes in patients with solid tumors: Can a drop dig
a stone?,” <span id="bib.bib21.2.2" class="ltx_text ltx_font_italic">Cellular immunology</span>, vol. 343, p. 103753, 2019.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
G. E. Idos, J. Kwok, N. Bonthala, L. Kysh, S. B. Gruber, and C. Qu, “The
prognostic implications of tumor infiltrating lymphocytes in colorectal
cancer: a systematic review and meta-analysis,” <span id="bib.bib22.1.1" class="ltx_text ltx_font_italic">Scientific reports</span>,
vol. 10, no. 1, pp. 1–14, 2020.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
J. Saltz, R. Gupta, L. Hou, T. Kurc, P. Singh, V. Nguyen, D. Samaras, K. R.
Shroyer, T. Zhao, R. Batiste, <span id="bib.bib23.1.1" class="ltx_text ltx_font_italic">et al.</span>, “Spatial organization and
molecular correlation of tumor-infiltrating lymphocytes using deep learning
on pathology images,” <span id="bib.bib23.2.2" class="ltx_text ltx_font_italic">Cell reports</span>, vol. 23, no. 1, pp. 181–193,
2018.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
S. Abousamra, M. Gupta, L. Hou, R. Batiste, T. Zhao, A. Shankar, A. Rao,
C. Chen, D. Samaras, T. Kurc, <span id="bib.bib24.1.1" class="ltx_text ltx_font_italic">et al.</span>, “Deep learning-based mapping of
tumor infiltrating lymphocytes in whole slide images of 23 types of cancer,”
<span id="bib.bib24.2.2" class="ltx_text ltx_font_italic">Frontiers in oncology</span>, p. 5971, 2021.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
S. Abousamra, L. Hou, R. Gupta, C. Chen, D. Samaras, T. Kurc, R. Batiste,
T. Zhao, S. Kenneth, and J. Saltz, “Learning from thresholds: fully
automated classification of tumor infiltrating lymphocytes for multiple
cancer types,” <span id="bib.bib25.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1907.03960</span>, 2019.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
K. Simonyan and A. Zisserman, “Very deep convolutional networks for
large-scale image recognition,” <span id="bib.bib26.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1409.1556</span>, 2014.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
A. Ben-Cohen, I. Diamant, E. Klang, M. Amitai, and H. Greenspan, “Fully
convolutional network for liver segmentation and lesions detection,” in <span id="bib.bib27.1.1" class="ltx_text ltx_font_italic">Deep learning and data labeling for medical applications</span>, pp. 77–85,
Springer, 2016.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei, “Imagenet: A
large-scale hierarchical image database,” in <span id="bib.bib28.1.1" class="ltx_text ltx_font_italic">2009 IEEE conference on
computer vision and pattern recognition</span>, pp. 248–255, Ieee, 2009.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
H. Iqbal, “Harisiqbal88/plotneuralnet v1.0.0,” Dec. 2018.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
T.-Y. Hsiao, Y.-C. Chang, H.-H. Chou, and C.-T. Chiu, “Filter-based
deep-compression with global average pooling for convolutional networks,”
<span id="bib.bib30.1.1" class="ltx_text ltx_font_italic">Journal of Systems Architecture</span>, vol. 95, pp. 9–18, 2019.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
A. F. Agarap, “Deep learning using rectified linear units (relu),” <span id="bib.bib31.1.1" class="ltx_text ltx_font_italic">arXiv
preprint arXiv:1803.08375</span>, 2018.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
S. Pati, S. P. Thakur, M. Bhalerao, U. Baid, C. Grenko, B. Edwards, M. Sheller,
J. Agraz, B. Baheti, V. Bashyam, <span id="bib.bib32.1.1" class="ltx_text ltx_font_italic">et al.</span>, “Gandlf: A generally nuanced
deep learning framework for scalable end-to-end clinical workflows in medical
imaging,” <span id="bib.bib32.2.2" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2103.01006</span>, 2021.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
G. A. Reina, A. Gruzdev, P. Foley, O. Perepelkina, M. Sharma, I. Davidyuk,
I. Trushkin, M. Radionov, A. Mokrov, D. Agapov, <span id="bib.bib33.1.1" class="ltx_text ltx_font_italic">et al.</span>, “Openfl: An
open-source framework for federated learning,” <span id="bib.bib33.2.2" class="ltx_text ltx_font_italic">arXiv preprint
arXiv:2105.06413</span>, 2021.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
K. H. Brodersen, C. S. Ong, K. E. Stephan, and J. M. Buhmann, “The balanced
accuracy and its posterior distribution,” in <span id="bib.bib34.1.1" class="ltx_text ltx_font_italic">2010 20th international
conference on pattern recognition</span>, pp. 3121–3124, IEEE, 2010.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2203.16621" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2203.16622" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2203.16622">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2203.16622" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2203.16623" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Mon Mar 11 07:26:20 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
