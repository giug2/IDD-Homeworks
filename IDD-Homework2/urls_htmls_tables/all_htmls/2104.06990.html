<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2104.06990] Resource Rationing for Wireless Federated Learning: Concept, Benefits, and Challenges</title><meta property="og:description" content="We advocate a new resource allocation framework, which we term resource rationing, for wireless federated learning (FL). Unlike existing resource allocation methods for FL, resource rationing focuses on balancing resou‚Ä¶">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Resource Rationing for Wireless Federated Learning: Concept, Benefits, and Challenges">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Resource Rationing for Wireless Federated Learning: Concept, Benefits, and Challenges">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2104.06990">

<!--Generated on Sun Mar 17 03:25:30 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Resource Rationing for Wireless Federated Learning: Concept, Benefits, and Challenges</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Cong Shen, Jie Xu, Sihui Zheng, and Xiang Chen
</span><span class="ltx_author_notes">C. Shen is with the Charles L. Brown Department of Electrical and Computer Engineering, University of Virginia, Charlottesville, VA 22904, USA.J. Xu is with Department of Electrical and Computer Engineering, University of Miami, Coral Gables, FL 33124, USA.S. Zheng and X. Chen are with School of Electronics and Information Technology, Sun Yat-Sen University, China.</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">We advocate a new resource allocation framework, which we term <span id="id1.id1.1" class="ltx_text ltx_font_italic">resource rationing</span>, for wireless federated learning (FL). Unlike existing resource allocation methods for FL, resource rationing focuses on balancing resources across learning rounds so that their collective impact on the federated learning performance is explicitly captured. This new framework can be integrated seamlessly with existing resource allocation schemes to optimize the convergence of FL. In particular, a novel ‚Äúlater-is-better‚Äù principle is at the front and center of resource rationing, which is validated empirically in several instances of wireless FL. We also point out technical challenges and research opportunities that are worth pursuing. Resource rationing highlights the benefits of treating the emerging FL as a new class of <span id="id1.id1.2" class="ltx_text ltx_font_italic">service</span> that has its own characteristics, and designing communication algorithms for this particular service.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Federated Learning (FL) is an emerging distributed machine learning (ML) paradigm that has many attractive properties. In particular, FL caters to the growing trend that massive amount of the real-world data is generated at the edge devices, and the combination of growing storage and computational power of devices and the increasing concern over transmitting private information to a central server has made it attractive to store data and train ML models locally on each device. The power of FL has been realized in commercial devices (e.g., Pixel 2 uses FL to train ML models to personalize user experience) and ML tasks (e.g., Gboard uses FL for keyboard prediction) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Despite being recognized as one of the primary bottlenecks of FL since its inception <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>, research on the communication aspect in the FL pipeline has not been on par with the learning component. Early research on communication-efficient FL largely focused on reducing the amount of information to be transmitted, and did not touch the actual communication algorithm and protocol design <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>. More recent research started to fill this void from a wireless communication and networking point of view <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>. In general, the principle is to balance learning performance and communication efficiency via, e.g., device selection, bandwidth allocation, and power control. It has been shown that combining (communication-oriented) adaptive resource allocation with (ML-oriented) efficient model representation leads to a better overall implementation, in particular for wireless federated learning which is envisioned to be among the mainstream deployment scenarios of edge ML <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">While the early results demonstrate the potential of jointly optimizing communication and computation for wireless FL, the communication design has not been tailored to the unique characteristics of FL. In particular, an intrinsic and fundamental property of FL has largely been ignored: FL is a long-term process consisting of many progressive learning rounds that <span id="S1.p3.1.1" class="ltx_text ltx_font_italic">collectively</span> determine the learning performance. Because of this progressive nature, learning rounds may have varying significance towards the convergence rate and final model accuracy, and thus should weigh differently when allocating communication resources. However, almost all existing works treat every learning round as equally important and perform resource allocation independently across learning rounds. Specifically, the common underlying assumptions made in these works <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> include that, in every learning round, the same total bandwidth is available, the same (exact or average) number of mobile devices are selected, or the same energy constraints are imposed. Resource allocation is then performed within the round under these constraints. While this view of static resource allocation across time simplifies the problem, it may lead to inefficient utilization of the scarce communication resources and consequently degrade the FL performance.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">We advocate a novel resource allocation framework for wireless FL, which we term <span id="S1.p4.1.1" class="ltx_text ltx_font_italic">resource rationing</span> to emphasize balancing resources over time so that the long-term impact on the FL performance is explicitly captured. The fundamental principle that differentiates resource rationing from existing wireless resource allocation is the focus on allocating different resources across learning rounds (in addition to possible resource allocation within each round) to optimize the convergence of FL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>. This novel framework originates from a holistic view of the resource management problem in FL: in order to achieve the best possible learning outcome with fast convergence, one has to ‚Äúration‚Äù the limited resources, consuming little at the beginning and gradually increasing towards the end. We introduce the basic concept of resource rationing and show that the <span id="S1.p4.1.2" class="ltx_text ltx_font_italic">‚Äúlater-is-better‚Äù</span> principle is general and applies to different resources in a wireless FL system. We also discuss several technical challenges and research directions to advance resource rationing and wireless FL in general.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Resource Rationing for Wireless FL</span>
</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS1.5.1.1" class="ltx_text">II-A</span> </span><span id="S2.SS1.6.2" class="ltx_text ltx_font_italic">Motivation</span>
</h3>

<figure id="S2.F1" class="ltx_figure"><img src="/html/2104.06990/assets/figures/fig1new.png" id="S2.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="592" height="294" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Overview of the proposed resource rationing framework in a wireless FL system. The ‚Äúlater-is-better‚Äù principle for resource rationing is illustrated with the example of clients rationing that is discussed in Section¬†<a href="#S3.SS2" title="III-B Clients Rationing ‚Ä£ III Benefits of Resource Rationing ‚Ä£ Resource Rationing for Wireless Federated Learning: Concept, Benefits, and Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">III-B</span></span></a>.</figcaption>
</figure>
<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">A representative wireless FL system is depicted in Fig.¬†<a href="#S2.F1" title="Figure 1 ‚Ä£ II-A Motivation ‚Ä£ II Resource Rationing for Wireless FL ‚Ä£ Resource Rationing for Wireless Federated Learning: Concept, Benefits, and Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. It works by iteratively executing the following steps: (1) the parameter server broadcasts the current global ML model to participating mobile devices (downlink communication); (2) Starting from the received global model, each device trains a local model using its own dataset (local computation); (3) mobile devices upload their updated local models to the parameter server (uplink communication); (4) the parameter server then aggregates these updates to generate a new global model (global computation). These four steps are collectively called a learning round. In this way, FL lets each mobile device evolve its own model using local data, while synchronizing the model training among different mobile devices via occasional model aggregation.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">The primary drive for resource rationing is that FL is very different than most of the services for which current communication systems are designed. The purpose of communication in today‚Äôs system is to deliver the information bits efficiently and reliably from one point to another. Although this is still true for FL, the ultimate goal of communication is to facilitate machine learning (e.g., collaboratively training a neural network to achieve the best classification accuracy), which has its own characteristics. Thus, taking an isolated view of each individual communication phase and optimizing the resource allocation within each round, albeit still meaningful, misses the opportunity to allocate resource towards the ultimate prize ‚Äì enabling fast convergence of ML training to an accurate model. This has motivated us to treat FL as a new class of service that has its own characteristics, and the problem we want to solve is how to <span id="S2.SS1.p2.1.1" class="ltx_text ltx_font_italic">holistically</span> allocate the scarce wireless resource to optimize the particular service of FL.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS2.5.1.1" class="ltx_text">II-B</span> </span><span id="S2.SS2.6.2" class="ltx_text ltx_font_italic">Impact of Resource</span>
</h3>

<figure id="S2.F2" class="ltx_figure"><img src="/html/2104.06990/assets/figures/fig2v3.png" id="S2.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="538" height="338" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Bandwidth reduction and resource rationing on training a convolutional neural network (CNN) for the MNIST digit recognition task with IID local datasets. Tuned quantization and stochastic rounding are utilized. 10 out of a total of 2000 clients are uniformly randomly selected in each round. Each curve is obtained by averaging 10 independent runs of the FL process. The final model accuracy is averaged over the last 200 learning rounds for all methods.</figcaption>
</figure>
<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">The first step towards resource rationing is to understand the impact of resource to the overall learning accuracy and convergence. Taking communication bandwidth as an example.
It is well known that the power of deep learning comes from the ‚Äúdepth‚Äù of the network and, correspondingly, significantly many weight coefficients. For example, the original ResNet-50 has over 23 million parameters. Even for the widely popular MobileNet which is specifically designed for devices with limited computing resource or limited power, the most economical version has 0.2 million parameters (<span id="S2.SS2.p1.1.1" class="ltx_text ltx_font_italic">0.25 MobileNet-128</span> model, face attribute classification) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>. A standard 32-bit floating-point representation of the updated weight coefficients leads to an uplink transmission of <math id="S2.SS2.p1.1.m1.1" class="ltx_Math" alttext="6.4\times 10^{6}" display="inline"><semantics id="S2.SS2.p1.1.m1.1a"><mrow id="S2.SS2.p1.1.m1.1.1" xref="S2.SS2.p1.1.m1.1.1.cmml"><mn id="S2.SS2.p1.1.m1.1.1.2" xref="S2.SS2.p1.1.m1.1.1.2.cmml">6.4</mn><mo lspace="0.222em" rspace="0.222em" id="S2.SS2.p1.1.m1.1.1.1" xref="S2.SS2.p1.1.m1.1.1.1.cmml">√ó</mo><msup id="S2.SS2.p1.1.m1.1.1.3" xref="S2.SS2.p1.1.m1.1.1.3.cmml"><mn id="S2.SS2.p1.1.m1.1.1.3.2" xref="S2.SS2.p1.1.m1.1.1.3.2.cmml">10</mn><mn id="S2.SS2.p1.1.m1.1.1.3.3" xref="S2.SS2.p1.1.m1.1.1.3.3.cmml">6</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.1.m1.1b"><apply id="S2.SS2.p1.1.m1.1.1.cmml" xref="S2.SS2.p1.1.m1.1.1"><times id="S2.SS2.p1.1.m1.1.1.1.cmml" xref="S2.SS2.p1.1.m1.1.1.1"></times><cn type="float" id="S2.SS2.p1.1.m1.1.1.2.cmml" xref="S2.SS2.p1.1.m1.1.1.2">6.4</cn><apply id="S2.SS2.p1.1.m1.1.1.3.cmml" xref="S2.SS2.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S2.SS2.p1.1.m1.1.1.3.1.cmml" xref="S2.SS2.p1.1.m1.1.1.3">superscript</csymbol><cn type="integer" id="S2.SS2.p1.1.m1.1.1.3.2.cmml" xref="S2.SS2.p1.1.m1.1.1.3.2">10</cn><cn type="integer" id="S2.SS2.p1.1.m1.1.1.3.3.cmml" xref="S2.SS2.p1.1.m1.1.1.3.3">6</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.1.m1.1c">6.4\times 10^{6}</annotation></semantics></math> bits per user per round, which requires significant communication bandwidth. It is thus crucial to decide <span id="S2.SS2.p1.1.2" class="ltx_text ltx_font_italic">what</span> and <span id="S2.SS2.p1.1.3" class="ltx_text ltx_font_italic">how</span> to communicate for the latest model with limited communication resources.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.2" class="ltx_p">One way to reduce the communication bandwidth is to compress the weights before each uplink and downlink communication round. Intuitively, the uplink communication is more resource constrained since the mobile devices are less powerful than the parameter server (e.g., base station). We thus focus on quantizing the locally updated weights and evaluating the performance impact to the overall FL convergence in a well adopted MNIST digit recognition task <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>. Through a carefully designed quantization method <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> that adjusts the quantization gain based on the dynamic range of the weights, and the adoption of stochastic rounding, we are able to significantly reduce the communication bandwidth at negligible loss accuracy and convergence rate as shown in Fig.¬†<a href="#S2.F2" title="Figure 2 ‚Ä£ II-B Impact of Resource ‚Ä£ II Resource Rationing for Wireless FL ‚Ä£ Resource Rationing for Wireless Federated Learning: Concept, Benefits, and Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> ‚Äì this particular example shows that for the independent and identically distributed (IID) dataset, by using only <math id="S2.SS2.p2.1.m1.1" class="ltx_Math" alttext="9.4\%" display="inline"><semantics id="S2.SS2.p2.1.m1.1a"><mrow id="S2.SS2.p2.1.m1.1.1" xref="S2.SS2.p2.1.m1.1.1.cmml"><mn id="S2.SS2.p2.1.m1.1.1.2" xref="S2.SS2.p2.1.m1.1.1.2.cmml">9.4</mn><mo id="S2.SS2.p2.1.m1.1.1.1" xref="S2.SS2.p2.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.1.m1.1b"><apply id="S2.SS2.p2.1.m1.1.1.cmml" xref="S2.SS2.p2.1.m1.1.1"><csymbol cd="latexml" id="S2.SS2.p2.1.m1.1.1.1.cmml" xref="S2.SS2.p2.1.m1.1.1.1">percent</csymbol><cn type="float" id="S2.SS2.p2.1.m1.1.1.2.cmml" xref="S2.SS2.p2.1.m1.1.1.2">9.4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.1.m1.1c">9.4\%</annotation></semantics></math> bandwidth of the floating-point baseline, we are able to achieve
<math id="S2.SS2.p2.2.m2.1" class="ltx_Math" alttext="99.6\%" display="inline"><semantics id="S2.SS2.p2.2.m2.1a"><mrow id="S2.SS2.p2.2.m2.1.1" xref="S2.SS2.p2.2.m2.1.1.cmml"><mn id="S2.SS2.p2.2.m2.1.1.2" xref="S2.SS2.p2.2.m2.1.1.2.cmml">99.6</mn><mo id="S2.SS2.p2.2.m2.1.1.1" xref="S2.SS2.p2.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.2.m2.1b"><apply id="S2.SS2.p2.2.m2.1.1.cmml" xref="S2.SS2.p2.2.m2.1.1"><csymbol cd="latexml" id="S2.SS2.p2.2.m2.1.1.1.cmml" xref="S2.SS2.p2.2.m2.1.1.1">percent</csymbol><cn type="float" id="S2.SS2.p2.2.m2.1.1.2.cmml" xref="S2.SS2.p2.2.m2.1.1.2">99.6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.2.m2.1c">99.6\%</annotation></semantics></math> of the baseline accuracy, at a convergence rate that remains almost the same. Similar observation can be made from different ML tasks and different configurations; see <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> for more details. This shows that it is possible to significantly reduce the communication resources while preserving the learning performance.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS3.5.1.1" class="ltx_text">II-C</span> </span><span id="S2.SS3.6.2" class="ltx_text ltx_font_italic">‚ÄúLater-Is-Better‚Äù</span>
</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">With a better understanding of how much overall resource is needed, we now consider the general resource rationing framework that absorbs existing wireless-specific resource allocation and ‚Äúelevates‚Äù the problem dimension to manage resources over learning rounds. The immediate question is whether a general principle exists for resource rationing, i.e., for a given total resource budget, what is the rule of thumb to ration resources?</p>
</div>
<figure id="S2.F3" class="ltx_figure"><img src="/html/2104.06990/assets/figures/fig3.png" id="S2.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="419" height="304" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Early learning rounds have more leeway for gradient direction to be wrong than later rounds.</figcaption>
</figure>
<div id="S2.SS3.p2" class="ltx_para">
<p id="S2.SS3.p2.1" class="ltx_p">To gain some insight into this question, we need to build an understanding of how FL works across learning rounds. Predominantly, FL tasks involve training a deep neural network (DNN) with (mini-batch) stochastic gradient decent (SGD), which uses a smaller number of data samples to calculate an approximated gradient for updating the model parameters. When data is further distributed among multiple clients, FL lets each client perform SGD using their local data with occasional synchronization by model averaging. A careful examination of the weight update and model averaging mechanisms for FL, e.g., FedAvg <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>, reveals an important feature that has not been incorporated in FL resource allocation: when the current weight is far from the optimal value, a rough gradient estimate is enough to find a descent direction. As the weight starts approaching the optimal solution, however, noisy gradient estimates frequently fail to produce descent directions and do not reliably decrease the objective. An illustration of this critical hypothesis is given in Fig.¬†<a href="#S2.F3" title="Figure 3 ‚Ä£ II-C ‚ÄúLater-Is-Better‚Äù ‚Ä£ II Resource Rationing for Wireless FL ‚Ä£ Resource Rationing for Wireless Federated Learning: Concept, Benefits, and Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, where early rounds enjoy much larger leeway (the large green area) in choosing gradient directions than later rounds (the small yellow area), where the same level of gradient noise may lead to deviation from convergence. This naturally leads to a ‚Äúlater-is-better‚Äù resource rationing rule: preserve resources at the early rounds of FL to exploit the tolerance of noisy gradient estimates, and spend the saved resources at later rounds to produce more accurate gradient estimate, thereby achieving an overall better learning performance.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Benefits of Resource Rationing</span>
</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">We instantiate resource rationing and demonstrate its benefits with three specific examples. On the physical layer, we study how to ration a given bandwidth budget over the entire learning period and how different allocations affect the final model accuracy and convergence rate. On the MAC layer, we study varying client selection strategies and evaluate how the convergence responds to client rationing. Lastly, we give an example of joint design that simultaneously rations clients selection and power control.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS1.5.1.1" class="ltx_text">III-A</span> </span><span id="S3.SS1.6.2" class="ltx_text ltx_font_italic">Bandwidth Rationing</span>
</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.2" class="ltx_p">We have seen that for the specific experiment in Fig.¬†<a href="#S2.F2" title="Figure 2 ‚Ä£ II-B Impact of Resource ‚Ä£ II Resource Rationing for Wireless FL ‚Ä£ Resource Rationing for Wireless Federated Learning: Concept, Benefits, and Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, a 3-bit weight representation achieves near-optimal learning performance and clearly outperforms 2-bit and 1-bit representations, for a constant bandwidth allocation. We now elevate the problem setting and fix the total uplink communication bandwidth consumption across all learning rounds as <math id="S3.SS1.p1.1.m1.1" class="ltx_Math" alttext="2T" display="inline"><semantics id="S3.SS1.p1.1.m1.1a"><mrow id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml"><mn id="S3.SS1.p1.1.m1.1.1.2" xref="S3.SS1.p1.1.m1.1.1.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S3.SS1.p1.1.m1.1.1.1" xref="S3.SS1.p1.1.m1.1.1.1.cmml">‚Äã</mo><mi id="S3.SS1.p1.1.m1.1.1.3" xref="S3.SS1.p1.1.m1.1.1.3.cmml">T</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><apply id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1"><times id="S3.SS1.p1.1.m1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1.1"></times><cn type="integer" id="S3.SS1.p1.1.m1.1.1.2.cmml" xref="S3.SS1.p1.1.m1.1.1.2">2</cn><ci id="S3.SS1.p1.1.m1.1.1.3.cmml" xref="S3.SS1.p1.1.m1.1.1.3">ùëá</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">2T</annotation></semantics></math> per weight per client, where <math id="S3.SS1.p1.2.m2.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S3.SS1.p1.2.m2.1a"><mi id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><ci id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">ùëá</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">T</annotation></semantics></math> is the total rounds of FL. Note that this would correspond to a 2-bit weight representation in the constant allocation, but we now evaluate two different bit rationing schemes: smaller number of bits at the beginning and larger number of bits later, and vice versa. The results are also shown in Fig.¬†<a href="#S2.F2" title="Figure 2 ‚Ä£ II-B Impact of Resource ‚Ä£ II Resource Rationing for Wireless FL ‚Ä£ Resource Rationing for Wireless Federated Learning: Concept, Benefits, and Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, where the increasing pattern uses 1-bit weight representation for the first one third of the rounds, 2-bit for the middle one third, and 3-bit for the final one third. The decreasing pattern is the exact reverse of the increasing pattern. The results suggest that ‚Äúlater-is-better‚Äù indeed achieves much improved performance: with the same total bandwidth as the constant 2-bit representation, it achieves a final learning accuracy of the 3-bit representation. However, this model accuracy improvement comes at the cost of reduced convergence rate: since early rounds use less bandwidth, the initial convergence is rather slow, which is predicted by the SGD analysis in Section¬†<a href="#S2.SS3" title="II-C ‚ÄúLater-Is-Better‚Äù ‚Ä£ II Resource Rationing for Wireless FL ‚Ä£ Resource Rationing for Wireless Federated Learning: Concept, Benefits, and Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">II-C</span></span></a>. This phenomenon reveals a fundamental tradeoff that may exist between model accuracy and convergence rate, which is worth further investigation. We also see that the decreasing patter behaves poorly, as it starts out strong but ‚Äústarves‚Äù at the end, converging to the 1-bit weight performance.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS2.5.1.1" class="ltx_text">III-B</span> </span><span id="S3.SS2.6.2" class="ltx_text ltx_font_italic">Clients Rationing</span>
</h3>

<figure id="S3.F4" class="ltx_figure"><img src="/html/2104.06990/assets/x1.png" id="S3.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="311" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Convergence versus the communication rounds with varying client selection patterns. A pre-trained RNN that generates ASCII characters is refined via FL on the Shakespeare dataset, which is divided into 715 non-IID local datasets. A certain number of clients are uniformly randomly selected in each round according to the selection pattern. Each curve is obtained by averaging 30 independent runs of the FL process.</figcaption>
</figure>
<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">Similarly, one can also take a long-term perspective and study how different temporal client selection patterns lead to different learning performances. The experiment is on another standard FL task ‚Äì train a recurrent neural network (RNN) for text generation on the Shakespeare dataset with FedAvg <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>. Keeping the total number of participating clients throughout the entire FL process constant, we evaluate three patterns as follows. The state of the art corresponds to the <span id="S3.SS2.p1.1.1" class="ltx_text ltx_font_italic">Uniform</span> selection ‚Äì in each round, 5 clients are randomly selected. We consider two other rules: (1) <span id="S3.SS2.p1.1.2" class="ltx_text ltx_font_italic">Ascend</span> ‚Äì the number of randomly selected clients linearly increases from 0 to 10; (2) <span id="S3.SS2.p1.1.3" class="ltx_text ltx_font_italic">Descend</span> ‚Äì the number of randomly selected clients linearly decreases from 10 to 0. Fig. <a href="#S3.F4" title="Figure 4 ‚Ä£ III-B Clients Rationing ‚Ä£ III Benefits of Resource Rationing ‚Ä£ Resource Rationing for Wireless Federated Learning: Concept, Benefits, and Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> reports the convergence results of these three methods, which clearly show that selecting more clients in later FL rounds not only results in much higher model accuracy than selecting more clients in earlier FL rounds, but also is much more robust ‚Äì its standard deviation (shown as the green shaded area) at the end of training is significantly smaller than others (shown as the blue and orange shaded areas).</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS3.5.1.1" class="ltx_text">III-C</span> </span><span id="S3.SS3.6.2" class="ltx_text ltx_font_italic">Joint Design</span>
</h3>

<figure id="S3.F5" class="ltx_figure"><img src="/html/2104.06990/assets/x2.png" id="S3.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="311" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Convergence versus the communication rounds with a joint resource rationing design. A CNN for digit recognition is trained on the MNIST dataset, which is divided into 3383 local non-IID datasets. In every round, 10 clients are available and participating clients are selected among these clients. Each curve is obtained by averaging 30 independent runs of the FL process.</figcaption>
</figure>
<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">A joint design of resource rationing among multiple types of resource can also be done to improve the final FL performance <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>. Let us consider again the MINST digit recognition task, but the local datasets are non-IID. Three different client selection methods are investigated. The <span id="S3.SS3.p1.1.1" class="ltx_text ltx_font_italic">Select-All</span> method represents the ideal case, which selects all clients in every round and ignores the energy constraints; the <span id="S3.SS3.p1.1.2" class="ltx_text ltx_font_italic">Myopic</span> method imposes the same energy constraint in every round and selects as many clients as possible under this constraint, representing the state-of-the-art; the <span id="S3.SS3.p1.1.3" class="ltx_text ltx_font_italic">Proposed</span> method adaptively rations energy resources by performing joint client selection, bandwidth allocation and power control given the current wireless channel conditions, following the ‚Äúlater-is-better‚Äù principle (see <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> for the detailed design). The convergence results of these methods are shown in Fig. <a href="#S3.F5" title="Figure 5 ‚Ä£ III-C Joint Design ‚Ä£ III Benefits of Resource Rationing ‚Ä£ Resource Rationing for Wireless Federated Learning: Concept, Benefits, and Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>. The eventual FL accuracy by using the proposed method far outperforms <span id="S3.SS3.p1.1.4" class="ltx_text ltx_font_italic">Myopic</span> and is close to the ideal case <span id="S3.SS3.p1.1.5" class="ltx_text ltx_font_italic">Select-All</span>, despite significantly reduced energy consumption (roughly <math id="S3.SS3.p1.1.m1.1" class="ltx_Math" alttext="50\%" display="inline"><semantics id="S3.SS3.p1.1.m1.1a"><mrow id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml"><mn id="S3.SS3.p1.1.m1.1.1.2" xref="S3.SS3.p1.1.m1.1.1.2.cmml">50</mn><mo id="S3.SS3.p1.1.m1.1.1.1" xref="S3.SS3.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><apply id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1"><csymbol cd="latexml" id="S3.SS3.p1.1.m1.1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S3.SS3.p1.1.m1.1.1.2.cmml" xref="S3.SS3.p1.1.m1.1.1.2">50</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">50\%</annotation></semantics></math>).</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">Challenges and Opportunities</span>
</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">Through the understanding of FL convergence and specific resource rationing schemes of bandwidth and clients allocation, we have established a general ‚Äúlater-is-better‚Äù resource rationing principle. This is a promising framework that intimately connects communication to FL. In the following, we highlight some challenges associated with advancing this novel paradigm, and present research opportunities that we believe are worth pursuing.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS1.5.1.1" class="ltx_text">IV-A</span> </span><span id="S4.SS1.6.2" class="ltx_text ltx_font_italic">Theoretical Foundation</span>
</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">Resource rationing for wireless FL must rely on a rigorous analysis of the varying significance of different learning rounds, and a deeper understanding of how resource rationing across time influences the convergence of FL. We already had a glimpse, through the bandwidth allocation example, that there may exist a fundamental tradeoff between model accuracy and convergence rate with a given total budget. However, despite the significant effort in establishing the convergence behavior of different FL algorithms under various regularity conditions, there is no research to directly connect FL convergence to the varying resource at each learning round. This theoretical foundation is difficult to establish but, unfortunately, is absolutely critical to enable a <span id="S4.SS1.p1.1.1" class="ltx_text ltx_font_italic">principled</span> design for resource rationing algorithms with proven performance guarantees.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS2.5.1.1" class="ltx_text">IV-B</span> </span><span id="S4.SS2.6.2" class="ltx_text ltx_font_italic">Temporal Variation in Wireless Systems</span>
</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">Wireless channels are dynamic and unpredictable in nature. When wireless channel characteristics are incorporated, <span id="S4.SS2.p1.1.1" class="ltx_text ltx_font_italic">causality</span> issues may arise, making temporal resource rationing and applying the ‚Äúlater-is-better‚Äù principle challenging. For example, uploading the same updated model incurs different energy consumption under different wireless channel conditions. The problem becomes further complicated because FL is a multi-user system where mobile devices are heterogeneous in terms of the experienced wireless environments, computing capabilities and resource constraints. The proposed resource rationing framework, however, operates on the time scale of communication rounds, which allows for the flexibility to incorporate existing or future ‚Äúfast‚Äù resource allocation mechanisms or prediction methods to handle temporal variations. We illustrate this flexibility using transmit power control as a use case <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>, and Fig.¬†<a href="#S4.F6" title="Figure 6 ‚Ä£ IV-B Temporal Variation in Wireless Systems ‚Ä£ IV Challenges and Opportunities ‚Ä£ Resource Rationing for Wireless Federated Learning: Concept, Benefits, and Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> illustrates the performance advantage of combining the ‚Äúlater-is-better‚Äù principle of resource rationing with an inner-loop power control that handles channel fading and interference. Note that both ‚Äúequal power‚Äù and ‚Äú<math id="S4.SS2.p1.1.m1.1" class="ltx_Math" alttext="O(t^{2})" display="inline"><semantics id="S4.SS2.p1.1.m1.1a"><mrow id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml"><mi id="S4.SS2.p1.1.m1.1.1.3" xref="S4.SS2.p1.1.m1.1.1.3.cmml">O</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.1.m1.1.1.2" xref="S4.SS2.p1.1.m1.1.1.2.cmml">‚Äã</mo><mrow id="S4.SS2.p1.1.m1.1.1.1.1" xref="S4.SS2.p1.1.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.SS2.p1.1.m1.1.1.1.1.2" xref="S4.SS2.p1.1.m1.1.1.1.1.1.cmml">(</mo><msup id="S4.SS2.p1.1.m1.1.1.1.1.1" xref="S4.SS2.p1.1.m1.1.1.1.1.1.cmml"><mi id="S4.SS2.p1.1.m1.1.1.1.1.1.2" xref="S4.SS2.p1.1.m1.1.1.1.1.1.2.cmml">t</mi><mn id="S4.SS2.p1.1.m1.1.1.1.1.1.3" xref="S4.SS2.p1.1.m1.1.1.1.1.1.3.cmml">2</mn></msup><mo stretchy="false" id="S4.SS2.p1.1.m1.1.1.1.1.3" xref="S4.SS2.p1.1.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><apply id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1"><times id="S4.SS2.p1.1.m1.1.1.2.cmml" xref="S4.SS2.p1.1.m1.1.1.2"></times><ci id="S4.SS2.p1.1.m1.1.1.3.cmml" xref="S4.SS2.p1.1.m1.1.1.3">ùëÇ</ci><apply id="S4.SS2.p1.1.m1.1.1.1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.1.m1.1.1.1.1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1.1.1">superscript</csymbol><ci id="S4.SS2.p1.1.m1.1.1.1.1.1.2.cmml" xref="S4.SS2.p1.1.m1.1.1.1.1.1.2">ùë°</ci><cn type="integer" id="S4.SS2.p1.1.m1.1.1.1.1.1.3.cmml" xref="S4.SS2.p1.1.m1.1.1.1.1.1.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">O(t^{2})</annotation></semantics></math>-increased power‚Äù consume the same total energy, and both implement the power control method proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> to enable analog aggregation in each round. Clearly, by deploying the resource rationing principle on top of the existing power control method, we can further improve the learning performance to be very close to the noise free benchmark, which has perfect communications. This also leads to several interesting future research directions, such as jointly designing resource rationing with temporal prediction (possibly leveraging ML), and performing real-world experiments to validate and evaluate the developed resource rationing framework.</p>
</div>
<figure id="S4.F6" class="ltx_figure"><img src="/html/2104.06990/assets/x3.png" id="S4.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="314" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Comparing the performance of transmit power control <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> to the baselines with partial clients participation, model transmission and IID dataset for FL on the CIFAR-10 dataset. A single-cell multi-user cellular system with broadband analog aggregation in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> for <span id="S4.F6.2.1" class="ltx_text ltx_font_smallcaps">FedAvg</span> is simulated where user devices participate in FL over wireless uplink and downlink communications. The results are averaged over 10 independent runs.</figcaption>
</figure>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS3.5.1.1" class="ltx_text">IV-C</span> </span><span id="S4.SS3.6.2" class="ltx_text ltx_font_italic">Generalization and Extension</span>
</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">The concept of resource rationing is general and can be applied to a broad spectrum of resources whenever there is the flexibility to dynamically allocate them across learning rounds. In the physical layer, coding rate and modulation are another type of resource where we can attempt to develop novel adaptive coding and modulation methods to realize resource rationing. In addition, from a pure learning perspective, there is no difference whether the updated model or its other forms are communicated between the clients and the server. However, this choice would affect the communication efficiency. For example, transmitting only the model difference as opposed to the updated model itself reduces the dynamic range. How to combine this feature with bandwidth rationing is an interesting research problem <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>. At the same time, the model difference becomes more sparse as the global model gradually converges. How to leverage the <span id="S4.SS3.p1.1.1" class="ltx_text ltx_font_italic">sparsity</span> in model difference for the communication design is another interesting problem. At the MAC layer, how to apply resource rationing to client selection, bandwidth allocation, power control, or a combination of them to accelerate learning convergence and model accuracy is worth exploring. Cross-layer designs can also be considered, e.g., one may be able to trade off coding and modulation for participating clients. These different aspects collectively form the backbone of resource rationing in FL, and will constitute a major technological breakthrough that advances future applications.</p>
</div>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS4.5.1.1" class="ltx_text">IV-D</span> </span><span id="S4.SS4.6.2" class="ltx_text ltx_font_italic">Complexity and Scalability</span>
</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.1" class="ltx_p">The value of FL increases with more clients participating in the system, but the problem complexity of resource rationing will also increase considerably. Taking client selection in FL as an example, the selection space size is combinatorial with respect to the total number of clients. When there are many clients, searching for the optimal solution can be very difficult. To enable fast and effective resource rationing in large-scale wireless FL networks, designing low-complexity and/or distributed algorithms is essential. While pure optimization-based algorithms may still be worth exploring, it is interesting to leverage the generalization power of machine learning to develop a joint optimization and learning approach. A machine learning model may be trained on past resource rationing decisions and one can use this ML model to adjust future resource rationing.</p>
</div>
</section>
<section id="S4.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS5.5.1.1" class="ltx_text">IV-E</span> </span><span id="S4.SS5.6.2" class="ltx_text ltx_font_italic">Beyond Communication Resources</span>
</h3>

<div id="S4.SS5.p1" class="ltx_para">
<p id="S4.SS5.p1.1" class="ltx_p">The resource rationing principle can be extended beyond allocating communication resources. For example, to guarantee learning convergence, it is required in SGD that the stepsize vanishes as time evolves. Because of the decaying stepsize, learning in later rounds is forced to be slow. In addition, finding the optimal learning rate schedule also requires an expensive grid search over all possible parameter values. Can we avoid using a pre-determined decaying stepsize schedule but rather automatically adapt the stepsize in each learning round? We may attempt to apply the resource rationing principle to reduce the stepsize by evaluating its impact to the convergence rate.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">Conclusions</span>
</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this article, we have argued for a new resource rationing framework for wireless federated learning. Resource rationing takes a holistic view of the resource allocation problem and attempts to balance the resource consumption across the entire learning period, with the goal of maximizing the final ML model accuracy and convergence rate. This intuition has led to an interesting ‚Äúlater-is-better‚Äù principle, where we have demonstrated with several examples that reserving resources at the beginning and spending them later is beneficial to the performance of FL. A theoretical intuition was also provided based on stochastic gradient descent. Future directions and challenges were presented to spark research activities. Philosophically, resource rationing represents an example of tailoring communication to the characteristics of FL, and other components of the communication system for wireless FL may similarly benefit from this holistic view.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
K.¬†Bonawitz, H.¬†Eichner, W.¬†Grieskamp, D.¬†Huba, A.¬†Ingerman, V.¬†Ivanov,
C.¬†Kiddon, J.¬†Konecny, S.¬†Mazzocchi, H.¬†B. McMahan, T.¬†V. Overveldt,
D.¬†Petrou, D.¬†Ramage, and J.¬†Roselander, ‚ÄúTowards federated learning at
scale: System design,‚Äù in <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2nd SysML Conference</em>,
2019, pp. 1‚Äì15.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
B.¬†McMahan, E.¬†Moore, D.¬†Ramage, S.¬†Hampson, and B.¬†A. y¬†Arcas,
‚ÄúCommunication-efficient learning of deep networks from decentralized
data,‚Äù in <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 20th International Conference on
Artificial Intelligence and Statistics (AISTATS)</em>, Fort Lauderdale, FL, USA,
Apr. 2017, pp. 1273‚Äì1282.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
J.¬†Konecny, H.¬†B. McMahan, F.¬†X. Yu, P.¬†Richtarik, A.¬†T. Suresh, and D.¬†Bacon,
‚ÄúFederated learning: Strategies for improving communication efficiency,‚Äù in
<em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">NIPS Workshop on Private Multi-Party Machine Learning</em>, 2016.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
F.¬†Sattler, S.¬†Wiedemann, K.-R. M√ºller, and W.¬†Samek, ‚ÄúRobust and
communication-efficient federated learning from non-iid data,‚Äù <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">IEEE
Trans. Neural Netw. Learn. Syst.</em>, vol.¬†31, no.¬†9, pp. 3400‚Äì3413, 2020.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
S.¬†Wang, T.¬†Tuor, T.¬†Salonidis, K.¬†K. Leung, C.¬†Makaya, T.¬†He, and K.¬†Chan,
‚ÄúAdaptive federated learning in resource constrained edge computing
systems,‚Äù <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">IEEE J. Select. Areas Commun.</em>, vol.¬†37, no.¬†6, pp.
1205‚Äì1221, 2019.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
H.¬†H. Yang, Z.¬†Liu, T.¬†Q. Quek, and H.¬†V. Poor, ‚ÄúScheduling policies for
federated learning in wireless networks,‚Äù <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">IEEE Trans. Commun.</em>,
vol.¬†68, no.¬†1, pp. 317‚Äì333, 2020.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
G.¬†Zhu, Y.¬†Wang, and K.¬†Huang, ‚ÄúBroadband analog aggregation for low-latency
federated edge learning,‚Äù <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">IEEE Trans. Wireless Commun.</em>, vol.¬†19,
no.¬†1, pp. 491‚Äì506, 2020.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
M.¬†M. Amiri and D.¬†G√ºnd√ºz, ‚ÄúFederated learning over wireless fading
channels,‚Äù <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">IEEE Trans. Wireless Commun.</em>, vol.¬†19, no.¬†5, pp.
3546‚Äì3557, 2020.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
K.¬†Yang, T.¬†Jiang, Y.¬†Shi, and Z.¬†Ding, ‚ÄúFederated learning via over-the-air
computation,‚Äù <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">IEEE Trans. Wireless Commun.</em>, vol.¬†19, no.¬†3, pp.
2022‚Äì2035, 2020.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
J.¬†Xu and H.¬†Wang, ‚ÄúClient selection and bandwidth allocation in wireless
federated learning networks: A long-term perspective,‚Äù <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">IEEE Trans.
Wireless Commun.</em>, vol.¬†20, no.¬†2, pp. 1188‚Äì1200, 2021.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
S.¬†Zheng, C.¬†Shen, and X.¬†Chen, ‚ÄúDesign and analysis of uplink and
downlink communications for federated learning,‚Äù
<a target="_blank" href="https://arxiv.org/abs/2012.04057" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2012.04057</a>, 2021, Accessed on 2021-04-13.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
X.¬†Wei and C.¬†Shen, ‚ÄúFederated learning over noisy channels: Convergence
analysis and design examples,‚Äù <a target="_blank" href="https://arxiv.org/abs/2101.02198" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2101.02198</a>, 2021,
Accessed on 2021-04-13.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
G.¬†Zhu, D.¬†Liu, Y.¬†Du, C.¬†You, J.¬†Zhang, and K.¬†Huang, ‚ÄúToward an
intelligent edge: Wireless communication meets machine learning,‚Äù <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">IEEE
Commun. Mag.</em>, vol.¬†58, no.¬†1, pp. 19‚Äì25, 2020.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
W.¬†Y.¬†B. Lim, N.¬†C. Luong, D.¬†T. Hoang, Y.¬†Jiao, Y.-C. Liang, Q.¬†Yang,
D.¬†Niyato, and C.¬†Miao, ‚ÄúFederated learning in mobile edge networks: A
comprehensive survey,‚Äù <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">IEEE Commun. Surveys Tuts.</em>, vol.¬†22, no.¬†3,
pp. 2031‚Äì2063, 2020.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
A.¬†G. Howard, M.¬†Zhu, B.¬†Chen, D.¬†Kalenichenko, W.¬†Wang, T.¬†Weyand,
M.¬†Andreetto, and H.¬†Adam, ‚ÄúMobilenets: Efficient convolutional neural
networks for mobile vision applications,‚Äù
<a target="_blank" href="https://arxiv.org/abs/1704.04861" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/1704.04861</a>, Accessed on 2021-04-13.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2104.06988" class="ar5iv-nav-button ar5iv-nav-button-prev">‚óÑ</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2104.06990" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2104.06990">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2104.06990" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2104.06993" class="ar5iv-nav-button ar5iv-nav-button-next">‚ñ∫</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sun Mar 17 03:25:30 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "√ó";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
