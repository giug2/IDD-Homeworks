<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2107.03216] MuVAM: A Multi-View Attention-based Model for Medical Visual Question Answering</title><meta property="og:description" content="Medical Visual Question Answering (VQA) is a multi-modal challenging task widely considered by research communities of the computer vision and natural language processing. Since most current medical VQA models focus on…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="MuVAM: A Multi-View Attention-based Model for Medical Visual Question Answering">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="MuVAM: A Multi-View Attention-based Model for Medical Visual Question Answering">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2107.03216">

<!--Generated on Sat Mar  9 01:36:55 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">MuVAM: A Multi-View Attention-based Model for Medical Visual Question Answering</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Haiwei Pan
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> Shuning He
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> Kejia Zhang
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> Bo Qu
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> Chunling Chen
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> and Kun Shi
</span><span class="ltx_author_notes">The work was supported by the International Exchange Program of Harbin Engineering University for Innovation-oriented Talents Cultivation, by the National Natural Science Foundation of China under Grant No.62072135 and No.61672181. (Corresponding author: Kejia Zhang.)
Haiwei Pan, Shuning He, Kejia Zhang, Chunling Chen, and Kun Shi are with the College of Computer Science and Technology, Harbin Engineering University, Harbin 150001, China (e-mail: panhaiwei@hrbeu.edu.cn; shuning@hrbeu.edu.cn; kejiazhang@hrbeu.edu.cn; ccl_00@hrbeu.edu.cn; iamsxk@hrbeu.edu.cn).Bo Qu is with Harbin Medical University, Harbin 150081, China (e-mail: heaven_007@163.com).</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.1" class="ltx_p">Medical <em id="id1.1.1" class="ltx_emph ltx_font_italic">V</em>isual <em id="id1.1.2" class="ltx_emph ltx_font_italic">Q</em>uestion <em id="id1.1.3" class="ltx_emph ltx_font_italic">A</em>nswering (VQA) is a multi-modal challenging task widely considered by research communities of the computer vision and natural language processing. Since most current medical VQA models focus on visual content, ignoring the importance of text, this paper proposes a <em id="id1.1.4" class="ltx_emph ltx_font_italic">mu</em>lti-<em id="id1.1.5" class="ltx_emph ltx_font_italic">v</em>iew <em id="id1.1.6" class="ltx_emph ltx_font_italic">a</em>ttention-based <em id="id1.1.7" class="ltx_emph ltx_font_italic">m</em>odel(MuVAM) for medical visual question answering which integrates the high-level semantics of medical images on the basis of text description. Firstly, different methods are utilized to extract the features of the image and the question for the two modalities of vision and text. Secondly, this paper proposes a multi-view attention mechanism that include <em id="id1.1.8" class="ltx_emph ltx_font_italic">I</em>mage-to-<em id="id1.1.9" class="ltx_emph ltx_font_italic">Q</em>uestion (I2Q) attention and <em id="id1.1.10" class="ltx_emph ltx_font_italic">W</em>ord-to-<em id="id1.1.11" class="ltx_emph ltx_font_italic">T</em>ext (W2T) attention. Multi-view attention can correlate the question with image and word in order to better analyze the question and get an accurate answer. Thirdly, a composite loss is presented to predict the answer accurately after multi-modal feature fusion and improve the similarity between visual and textual cross-modal features. It consists of classification loss and <em id="id1.1.12" class="ltx_emph ltx_font_italic">i</em>mage-<em id="id1.1.13" class="ltx_emph ltx_font_italic">q</em>uestion <em id="id1.1.14" class="ltx_emph ltx_font_italic">c</em>omplementary (IQC) loss. Finally, for data errors and missing labels in the VQA-RAD dataset, we collaborate with medical experts to correct and complete this dataset and then construct an enhanced dataset, VQA-RAD<sup id="id1.1.15" class="ltx_sup"><span id="id1.1.15.1" class="ltx_text ltx_font_italic">Ph</span></sup>. The experiments on these two datasets show that the effectiveness of MuVAM surpasses the state-of-the-art method.</p>
</div>
<div id="p1" class="ltx_para">
<span id="p1.1" class="ltx_ERROR undefined">{IEEEkeywords}</span>
<p id="p1.2" class="ltx_p">Attention Mechanism, Deep Learning, Medical Visual Question Answering, Multi-Modal Fusion, Medical Images.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<span id="S1.p1.1" class="ltx_ERROR undefined">\IEEEPARstart</span>
<p id="S1.p1.2" class="ltx_p">According to different imaging principles, various levels of organ information is obtained, so as to understand our physical conditions comprehensively. Medical image <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> plays an important role for doctors in clinical diagnosis. At the same time, electronic medical records of patients and diagnostic information provided by doctors are significant basis for disease analysis. Medical text also has a major impact on diagnosis <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">With the continuous development of intelligent medical care, computer-aided diagnosis technologies are gradually being recognized by the public. It uses medical image and text to help doctors make judgments on disease areas <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>, thereby greatly reduce misdiagnosis and improve accuracy. Medical <em id="S1.p2.1.1" class="ltx_emph ltx_font_italic">V</em>isual <em id="S1.p2.1.2" class="ltx_emph ltx_font_italic">Q</em>uestion <em id="S1.p2.1.3" class="ltx_emph ltx_font_italic">A</em>nswering (VQA)<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> is one of the hot topics in the current research of computer-aided diagnosis technology. It is a multi-modal challenging task that has been widely considered by the two main research directions of computer vision and natural language processing. In order to infer the correct answer, it is required to have a deep understanding of the rich content of medical images and precise exploration of the complex semantics of clinical questions. The purpose of this task is to assist the doctor in the diagnosis and alleviate the difficulties of patients in seeking medical treatment.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">However, the current research on VQA technology based on the professional medical fields is very limited. The imaging principle of medical images is complicated and the visual perception effect is not obvious. Most medical images of the same body part of different people are very similar, which is mainly caused by the high similarity of human structure. For example, the two extremely similar images are both chest radiographs taken through X-ray imaging, as shown in Fig.(<a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ MuVAM: A Multi-View Attention-based Model for Medical Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>). The bilateral lungs on the left image are abnormally hyperinflated, and the lungs on the right image are normal in size.</p>
</div>
<figure id="S1.F1" class="ltx_figure">
<p id="S1.F1.1" class="ltx_p ltx_align_center"><span id="S1.F1.1.1" class="ltx_text"><img src="/html/2107.03216/assets/x1.png" id="S1.F1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="461" height="198" alt="Refer to caption"></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Using X-rays to take two extremely similar chest radiographs, the lung on the left is hyperinflated, and the lung on the right is of normal size.</figcaption>
</figure>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">Although the deep learning method has been proven to be effective in medical image analysis <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>, the current medical VQA dataset lacks large-scale labeled training data. The labeling of medical images requires a lot of professional knowledge and time, which is not feasible on a large scale. If the deep learning model pre-trained on the general VQA dataset is transferred to medical VQA and fine-tuned with a small amount of medical images, the final effect is not satisfactory due to the obvious difference between medical images and natural images. Therefore, a medical VQA framework <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> overcomes the limitations of labeled data. <em id="S1.p4.1.1" class="ltx_emph ltx_font_italic">M</em>odel-<em id="S1.p4.1.2" class="ltx_emph ltx_font_italic">A</em>gnostic <em id="S1.p4.1.3" class="ltx_emph ltx_font_italic">M</em>eta-<em id="S1.p4.1.4" class="ltx_emph ltx_font_italic">L</em>earning (MAML) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> and <em id="S1.p4.1.5" class="ltx_emph ltx_font_italic">C</em>onvolutional <em id="S1.p4.1.6" class="ltx_emph ltx_font_italic">D</em>enoising <em id="S1.p4.1.7" class="ltx_emph ltx_font_italic">A</em>uto-<em id="S1.p4.1.8" class="ltx_emph ltx_font_italic">E</em>ncoder (CDAE) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> are used to initialize the weights of image feature extraction. MAML can quickly adapt to new tasks with a small number of training images. The advantage of CDAE is to use large-scale unlabeled datasets and enhance the robustness of the model. Although this method has achieved better effect which has done a lot of work on medical image feature extraction in the VQA-RAD dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>, VQA involves not only computer vision, but also text analysis of clinical questions.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">Due to the obscurity of professional medical concepts, there are also challenges in understanding clinical texts. A Question Conditional Reasoning (QCR) module is proposed by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>, which aims to extract task information from questions to guide the modulation of multi-modal features. In order to emphasize the important part of each question, QCR applied an attention to obtain importance weights to different words, generally weakens the use of prepositions and articles, and highlights features such as nouns and verbs.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">The above methods have a deep understanding of medical images and text questions respectively. However, independently modeling the semantic level of text and the visual level of the image can not meet the requirements of multi-modal task. There are also correlations between images and questions. In this context, a <em id="S1.p6.1.1" class="ltx_emph ltx_font_italic">mu</em>lti-<em id="S1.p6.1.2" class="ltx_emph ltx_font_italic">v</em>iew <em id="S1.p6.1.3" class="ltx_emph ltx_font_italic">a</em>ttention-based <em id="S1.p6.1.4" class="ltx_emph ltx_font_italic">m</em>odel (MuVAM) for medical VQA is proposed which aims to fuse the high-level semantics of medical images on the basis of text. Firstly, the medical images and related questions are encoded and features are extracted. Then from the view of vision and words, <em id="S1.p6.1.5" class="ltx_emph ltx_font_italic">i</em>mage-to-<em id="S1.p6.1.6" class="ltx_emph ltx_font_italic">q</em>uestion (I2Q) attention and <em id="S1.p6.1.7" class="ltx_emph ltx_font_italic">w</em>ord-to-<em id="S1.p6.1.8" class="ltx_emph ltx_font_italic">t</em>ext (W2T) attention are used to act on the question. This process is called multi-view attention. In order to predict the answer accurately, a composite loss is proposed to train the MuVAM. It includes the classification loss after multi-modal fusion and <em id="S1.p6.1.9" class="ltx_emph ltx_font_italic">i</em>mage-<em id="S1.p6.1.10" class="ltx_emph ltx_font_italic">q</em>uestion <em id="S1.p6.1.11" class="ltx_emph ltx_font_italic">c</em>omplementary (IQC) loss that combines image representation and text semantics to guide question importance learning.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Works</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Visual Question Answering</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Since the seminal work of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> was proposed, the task of VQA has attracted much research attention.The current VQA framework is mainly composed of a question feature extractor, an image feature extractor, and multi-modal fusion. The question feature extraction usually uses <em id="S2.SS1.p1.1.1" class="ltx_emph ltx_font_italic">L</em>ong <em id="S2.SS1.p1.1.2" class="ltx_emph ltx_font_italic">S</em>hort-<em id="S2.SS1.p1.1.3" class="ltx_emph ltx_font_italic">T</em>erm <em id="S2.SS1.p1.1.4" class="ltx_emph ltx_font_italic">M</em>emory(LSTM) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>, <em id="S2.SS1.p1.1.5" class="ltx_emph ltx_font_italic">G</em>ated <em id="S2.SS1.p1.1.6" class="ltx_emph ltx_font_italic">R</em>ecurrent <em id="S2.SS1.p1.1.7" class="ltx_emph ltx_font_italic">U</em>nits (GRU) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>, and Skip-thought vectors <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>. The mainstream image feature extraction method is to use Faster R-CNN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> instead of the traditional CNN, so that the task is connected with the object detection to focus on the salient regions of the image related to the question <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>. However, in the professional field of medical VQA, this method is not applicable due to the lack of large-scale labeled training data in the dataset. In view of the particularity of the medical VQA dataset, MAML and CDAE were used to initialize the weights for image feature extraction in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>, so as to achieve the use of a small labeled training set to effectively train the effect of the medical VQA framework.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">Early multimodal fusion generally used simple summation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite> , element-wise multiplication <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> or vector concatenation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite> methods to combine text and image information. With further research, bilinear pooling is applied to feature fusion gradually <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib28" title="" class="ltx_ref">28</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>. It computes the outer product between two vectors for deep fusion. However, such operations lead to high feature dimensionality. Therefore, <em id="S2.SS1.p2.1.1" class="ltx_emph ltx_font_italic">M</em>ultimodal <em id="S2.SS1.p2.1.2" class="ltx_emph ltx_font_italic">C</em>ompact <em id="S2.SS1.p2.1.3" class="ltx_emph ltx_font_italic">B</em>ilinear pooling (MCB) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> was proposed to perform the outer product calculation in a low-dimensional space to effectively combine multi-modal features. <em id="S2.SS1.p2.1.4" class="ltx_emph ltx_font_italic">M</em>ultimodal <em id="S2.SS1.p2.1.5" class="ltx_emph ltx_font_italic">L</em>ow-rank <em id="S2.SS1.p2.1.6" class="ltx_emph ltx_font_italic">B</em>ilinear pooling (MLB) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite> was proposed to use Hadamard product and linear mapping to approximate the outer product to reduce computation complexity and reduce parameters. Bilinear pooling and attention mechanisms can also be combined. <em id="S2.SS1.p2.1.7" class="ltx_emph ltx_font_italic">B</em>ilinear <em id="S2.SS1.p2.1.8" class="ltx_emph ltx_font_italic">A</em>ttention <em id="S2.SS1.p2.1.9" class="ltx_emph ltx_font_italic">N</em>etwork (BAN) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite> considered the bilinear interaction between the image and the question on the basis of low-rank bilinear pooling technique and proposed a variant of the multi-modal residual network to effectively utilize the multiple bilinear attention maps generated. Some studies <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>, <a href="#bib.bib34" title="" class="ltx_ref">34</a>, <a href="#bib.bib35" title="" class="ltx_ref">35</a>, <a href="#bib.bib36" title="" class="ltx_ref">36</a>, <a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite> also extracted advanced semantic information from the attributes and visual relationships in the image. Image attributes and captions of the model mine richer VQA relationship in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Attention Mechanism</h3>

<figure id="S2.F2" class="ltx_figure">
<p id="S2.F2.1" class="ltx_p ltx_align_center"><span id="S2.F2.1.1" class="ltx_text"><img src="/html/2107.03216/assets/x2.png" id="S2.F2.1.1.g1" class="ltx_graphics ltx_img_landscape" width="922" height="353" alt="Refer to caption"></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>The training framework of MuVAM which includes a feature extraction module, a multi-view attention module and a compound loss module.</figcaption>
</figure>
<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">In order to obtain better results for VQA tasks, most of the methods currently are used to introduce the attention mechanism between feature extraction and multimodal fusion. When the proposed question is difficult to answer directly, a deeper understanding of the input question and the image is required. At this time, the attention mechanism appears particularly important. It turns out that the use of attention can improve the effect of most VQA tasks<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>, and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite>. The multi-glance attention mechanism was utilize in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> to make the clinical question match the relevant regions in the medical image to get an accurate answer. In this way, a deeper meaning between the image and the question can be mined. The Relation-aware Graph Attention Network (ReGAT) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite> used the interactive dynamics between different objects to understand the visual scene in the image. The graph was composed of each image encoded. The semantic relations, spatial relations, and implicit relations between objects were modeled separately via a graph attention mechanism to learn the relation representations of adaptive questions. The attention weight of each object in the image was calculated to obtain question-oriented visual features that joint embedding of the question to feed to the classifier <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>. The re-attention framework<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite> associated images with questions from a fine-grained perspective by calculating the similarity of each object-word pairs in the feature space. Then, for the corresponding visual objects in the re-attending image, the initial attention map was reconstructed and the attention consistency loss was used to minimize the difference in the attention weight of the images. A question-conditioned reasoning module to guide the selection of the importance of multi-modal fusion features was proposed <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>. It used the attention mechanism of word embedding and question representations to obtain more semantic information to infer the answer.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p">Most attention mechanisms generally use the semantic representation of the question as a query to search for relevant image regions, and assign weights to the image to obtain a text-based image feature representation. In addition, the medical method lacks the attention of the image to the question. And the accuracies of the current methods need to be further improved. Therefore, we propose the MuVAM model to solve the above problems.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>MuVAM for Medical VQA</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.2" class="ltx_p">The overall framework of MuVAM is shown in Fig. (<a href="#S2.F2" title="Figure 2 ‣ 2.2 Attention Mechanism ‣ 2 Related Works ‣ MuVAM: A Multi-View Attention-based Model for Medical Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>). Given a medical image <math id="S3.p1.1.m1.1" class="ltx_Math" alttext="v" display="inline"><semantics id="S3.p1.1.m1.1a"><mi id="S3.p1.1.m1.1.1" xref="S3.p1.1.m1.1.1.cmml">v</mi><annotation-xml encoding="MathML-Content" id="S3.p1.1.m1.1b"><ci id="S3.p1.1.m1.1.1.cmml" xref="S3.p1.1.m1.1.1">𝑣</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.1.m1.1c">v</annotation></semantics></math> and a question <math id="S3.p1.2.m2.1" class="ltx_Math" alttext="Q" display="inline"><semantics id="S3.p1.2.m2.1a"><mi id="S3.p1.2.m2.1.1" xref="S3.p1.2.m2.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S3.p1.2.m2.1b"><ci id="S3.p1.2.m2.1.1.cmml" xref="S3.p1.2.m2.1.1">𝑄</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.2.m2.1c">Q</annotation></semantics></math> related to the image, the correct answer is finally predicted. This can be specifically described as:</p>
</div>
<div id="S3.p2" class="ltx_para">
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.4" class="ltx_Math" alttext="\hat{y}=\mathop{\arg\max}_{a\in\mathcal{A}}P(a\,|\,Q,v,\theta)" display="block"><semantics id="S3.E1.m1.4a"><mrow id="S3.E1.m1.4.4" xref="S3.E1.m1.4.4.cmml"><mover accent="true" id="S3.E1.m1.4.4.3" xref="S3.E1.m1.4.4.3.cmml"><mi id="S3.E1.m1.4.4.3.2" xref="S3.E1.m1.4.4.3.2.cmml">y</mi><mo id="S3.E1.m1.4.4.3.1" xref="S3.E1.m1.4.4.3.1.cmml">^</mo></mover><mo id="S3.E1.m1.4.4.2" xref="S3.E1.m1.4.4.2.cmml">=</mo><mrow id="S3.E1.m1.4.4.1" xref="S3.E1.m1.4.4.1.cmml"><munder id="S3.E1.m1.4.4.1.2" xref="S3.E1.m1.4.4.1.2.cmml"><mrow id="S3.E1.m1.4.4.1.2.2" xref="S3.E1.m1.4.4.1.2.2.cmml"><mi id="S3.E1.m1.4.4.1.2.2.1" xref="S3.E1.m1.4.4.1.2.2.1.cmml">arg</mi><mo lspace="0.167em" id="S3.E1.m1.4.4.1.2.2a" xref="S3.E1.m1.4.4.1.2.2.cmml">⁡</mo><mi id="S3.E1.m1.4.4.1.2.2.2" xref="S3.E1.m1.4.4.1.2.2.2.cmml">max</mi></mrow><mrow id="S3.E1.m1.4.4.1.2.3" xref="S3.E1.m1.4.4.1.2.3.cmml"><mi id="S3.E1.m1.4.4.1.2.3.2" xref="S3.E1.m1.4.4.1.2.3.2.cmml">a</mi><mo id="S3.E1.m1.4.4.1.2.3.1" xref="S3.E1.m1.4.4.1.2.3.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.4.4.1.2.3.3" xref="S3.E1.m1.4.4.1.2.3.3.cmml">𝒜</mi></mrow></munder><mrow id="S3.E1.m1.4.4.1.1" xref="S3.E1.m1.4.4.1.1.cmml"><mi id="S3.E1.m1.4.4.1.1.3" xref="S3.E1.m1.4.4.1.1.3.cmml">P</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.4.4.1.1.2" xref="S3.E1.m1.4.4.1.1.2.cmml">​</mo><mrow id="S3.E1.m1.4.4.1.1.1.1" xref="S3.E1.m1.4.4.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E1.m1.4.4.1.1.1.1.2" xref="S3.E1.m1.4.4.1.1.1.1.1.cmml">(</mo><mrow id="S3.E1.m1.4.4.1.1.1.1.1" xref="S3.E1.m1.4.4.1.1.1.1.1.cmml"><mi id="S3.E1.m1.4.4.1.1.1.1.1.2" xref="S3.E1.m1.4.4.1.1.1.1.1.2.cmml">a</mi><mo fence="false" lspace="0.448em" rspace="0.448em" id="S3.E1.m1.4.4.1.1.1.1.1.1" xref="S3.E1.m1.4.4.1.1.1.1.1.1.cmml">|</mo><mrow id="S3.E1.m1.4.4.1.1.1.1.1.3.2" xref="S3.E1.m1.4.4.1.1.1.1.1.3.1.cmml"><mi id="S3.E1.m1.1.1" xref="S3.E1.m1.1.1.cmml">Q</mi><mo id="S3.E1.m1.4.4.1.1.1.1.1.3.2.1" xref="S3.E1.m1.4.4.1.1.1.1.1.3.1.cmml">,</mo><mi id="S3.E1.m1.2.2" xref="S3.E1.m1.2.2.cmml">v</mi><mo id="S3.E1.m1.4.4.1.1.1.1.1.3.2.2" xref="S3.E1.m1.4.4.1.1.1.1.1.3.1.cmml">,</mo><mi id="S3.E1.m1.3.3" xref="S3.E1.m1.3.3.cmml">θ</mi></mrow></mrow><mo stretchy="false" id="S3.E1.m1.4.4.1.1.1.1.3" xref="S3.E1.m1.4.4.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.4b"><apply id="S3.E1.m1.4.4.cmml" xref="S3.E1.m1.4.4"><eq id="S3.E1.m1.4.4.2.cmml" xref="S3.E1.m1.4.4.2"></eq><apply id="S3.E1.m1.4.4.3.cmml" xref="S3.E1.m1.4.4.3"><ci id="S3.E1.m1.4.4.3.1.cmml" xref="S3.E1.m1.4.4.3.1">^</ci><ci id="S3.E1.m1.4.4.3.2.cmml" xref="S3.E1.m1.4.4.3.2">𝑦</ci></apply><apply id="S3.E1.m1.4.4.1.cmml" xref="S3.E1.m1.4.4.1"><apply id="S3.E1.m1.4.4.1.2.cmml" xref="S3.E1.m1.4.4.1.2"><csymbol cd="ambiguous" id="S3.E1.m1.4.4.1.2.1.cmml" xref="S3.E1.m1.4.4.1.2">subscript</csymbol><apply id="S3.E1.m1.4.4.1.2.2.cmml" xref="S3.E1.m1.4.4.1.2.2"><arg id="S3.E1.m1.4.4.1.2.2.1.cmml" xref="S3.E1.m1.4.4.1.2.2.1"></arg><max id="S3.E1.m1.4.4.1.2.2.2.cmml" xref="S3.E1.m1.4.4.1.2.2.2"></max></apply><apply id="S3.E1.m1.4.4.1.2.3.cmml" xref="S3.E1.m1.4.4.1.2.3"><in id="S3.E1.m1.4.4.1.2.3.1.cmml" xref="S3.E1.m1.4.4.1.2.3.1"></in><ci id="S3.E1.m1.4.4.1.2.3.2.cmml" xref="S3.E1.m1.4.4.1.2.3.2">𝑎</ci><ci id="S3.E1.m1.4.4.1.2.3.3.cmml" xref="S3.E1.m1.4.4.1.2.3.3">𝒜</ci></apply></apply><apply id="S3.E1.m1.4.4.1.1.cmml" xref="S3.E1.m1.4.4.1.1"><times id="S3.E1.m1.4.4.1.1.2.cmml" xref="S3.E1.m1.4.4.1.1.2"></times><ci id="S3.E1.m1.4.4.1.1.3.cmml" xref="S3.E1.m1.4.4.1.1.3">𝑃</ci><apply id="S3.E1.m1.4.4.1.1.1.1.1.cmml" xref="S3.E1.m1.4.4.1.1.1.1"><csymbol cd="latexml" id="S3.E1.m1.4.4.1.1.1.1.1.1.cmml" xref="S3.E1.m1.4.4.1.1.1.1.1.1">conditional</csymbol><ci id="S3.E1.m1.4.4.1.1.1.1.1.2.cmml" xref="S3.E1.m1.4.4.1.1.1.1.1.2">𝑎</ci><list id="S3.E1.m1.4.4.1.1.1.1.1.3.1.cmml" xref="S3.E1.m1.4.4.1.1.1.1.1.3.2"><ci id="S3.E1.m1.1.1.cmml" xref="S3.E1.m1.1.1">𝑄</ci><ci id="S3.E1.m1.2.2.cmml" xref="S3.E1.m1.2.2">𝑣</ci><ci id="S3.E1.m1.3.3.cmml" xref="S3.E1.m1.3.3">𝜃</ci></list></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.4c">\hat{y}=\mathop{\arg\max}_{a\in\mathcal{A}}P(a\,|\,Q,v,\theta)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S3.p2.5" class="ltx_p">where <math id="S3.p2.1.m1.1" class="ltx_Math" alttext="\hat{y}" display="inline"><semantics id="S3.p2.1.m1.1a"><mover accent="true" id="S3.p2.1.m1.1.1" xref="S3.p2.1.m1.1.1.cmml"><mi id="S3.p2.1.m1.1.1.2" xref="S3.p2.1.m1.1.1.2.cmml">y</mi><mo id="S3.p2.1.m1.1.1.1" xref="S3.p2.1.m1.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.p2.1.m1.1b"><apply id="S3.p2.1.m1.1.1.cmml" xref="S3.p2.1.m1.1.1"><ci id="S3.p2.1.m1.1.1.1.cmml" xref="S3.p2.1.m1.1.1.1">^</ci><ci id="S3.p2.1.m1.1.1.2.cmml" xref="S3.p2.1.m1.1.1.2">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.1.m1.1c">\hat{y}</annotation></semantics></math> represents the final classification result. <math id="S3.p2.2.m2.1" class="ltx_Math" alttext="\mathcal{A}" display="inline"><semantics id="S3.p2.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S3.p2.2.m2.1.1" xref="S3.p2.2.m2.1.1.cmml">𝒜</mi><annotation-xml encoding="MathML-Content" id="S3.p2.2.m2.1b"><ci id="S3.p2.2.m2.1.1.cmml" xref="S3.p2.2.m2.1.1">𝒜</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.2.m2.1c">\mathcal{A}</annotation></semantics></math> and <math id="S3.p2.3.m3.1" class="ltx_Math" alttext="a" display="inline"><semantics id="S3.p2.3.m3.1a"><mi id="S3.p2.3.m3.1.1" xref="S3.p2.3.m3.1.1.cmml">a</mi><annotation-xml encoding="MathML-Content" id="S3.p2.3.m3.1b"><ci id="S3.p2.3.m3.1.1.cmml" xref="S3.p2.3.m3.1.1">𝑎</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.3.m3.1c">a</annotation></semantics></math> respectively indicates a set of candidate answers and one of the answers. <math id="S3.p2.4.m4.1" class="ltx_Math" alttext="P" display="inline"><semantics id="S3.p2.4.m4.1a"><mi id="S3.p2.4.m4.1.1" xref="S3.p2.4.m4.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S3.p2.4.m4.1b"><ci id="S3.p2.4.m4.1.1.cmml" xref="S3.p2.4.m4.1.1">𝑃</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.4.m4.1c">P</annotation></semantics></math> denotes the MuVAM framework and <math id="S3.p2.5.m5.1" class="ltx_Math" alttext="\theta" display="inline"><semantics id="S3.p2.5.m5.1a"><mi id="S3.p2.5.m5.1.1" xref="S3.p2.5.m5.1.1.cmml">θ</mi><annotation-xml encoding="MathML-Content" id="S3.p2.5.m5.1b"><ci id="S3.p2.5.m5.1.1.cmml" xref="S3.p2.5.m5.1.1">𝜃</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.5.m5.1c">\theta</annotation></semantics></math> represents all the parameters of the MuVAM.
The MuVAM framework is divided into three parts, which are feature extraction module, multi-view attention module, and composite loss module. In the feature extraction module, different methods are used to extract features for the medical image and the related question. Then the image feature and the question feature are fed to the multi-view attention module, which includes W2T attention and I2Q attention. They pay attention to the question from the views of words and images to obtain text features under the guidance of vision and two attention weights. Finally, the output of the multi-view attention module is passed to the composite loss module. In order to maximize the accuracy of the prediction results, the composite loss is composed of the classification loss and the IQC loss to train MuVAM together. Classification loss predicts answer distribution and IQC loss minimizes the difference between the importances of question learned by words and learned under the guidance of vision. The three modules are explained in detail in the following subsections.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Feature Extraction</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">Because different modalities have completely different description forms and complex coupling correspondences, it is necessary to solve the multi-modal data representation in a unified way. The accuracy of the extracted features is critical to the subsequent operations. In this part, different feature extraction methods are used for the image and the question respectively. The information of the two modalities is mapped to the same feature space to obtain feature representations.</p>
</div>
<section id="S3.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.1 </span>Image representation</h4>

<div id="S3.SS1.SSS1.p1" class="ltx_para">
<p id="S3.SS1.SSS1.p1.2" class="ltx_p">At present, most image feature extraction is based on the ResNet CNN within a Faster R-CNN framework <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> to extract more fine-grained image representations. Because this method requires a large amount of labeled training data that is not suitable for medical VQA problem for which the available datasets are relatively small, this paper adopts MAML and CDAE encoder to initialize the pre-trained weights for image representation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>. MAML consists of four 3*3 conolutional layers with stride 2 and ends with a mean pooling layer.Each convolutional layer contains 64 filters and a ReLu layer. CDAE encoder is a combination of a stack of convolutional layers and max pooling layers. MAML and CDAE encoder obtain 64-dimensional vector features respectively, which are concatenated to generate 128-dimensional image features. The feature of the image is represented as <math id="S3.SS1.SSS1.p1.1.m1.1" class="ltx_Math" alttext="v\in\mathcal{R}^{d_{k}}" display="inline"><semantics id="S3.SS1.SSS1.p1.1.m1.1a"><mrow id="S3.SS1.SSS1.p1.1.m1.1.1" xref="S3.SS1.SSS1.p1.1.m1.1.1.cmml"><mi id="S3.SS1.SSS1.p1.1.m1.1.1.2" xref="S3.SS1.SSS1.p1.1.m1.1.1.2.cmml">v</mi><mo id="S3.SS1.SSS1.p1.1.m1.1.1.1" xref="S3.SS1.SSS1.p1.1.m1.1.1.1.cmml">∈</mo><msup id="S3.SS1.SSS1.p1.1.m1.1.1.3" xref="S3.SS1.SSS1.p1.1.m1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.SSS1.p1.1.m1.1.1.3.2" xref="S3.SS1.SSS1.p1.1.m1.1.1.3.2.cmml">ℛ</mi><msub id="S3.SS1.SSS1.p1.1.m1.1.1.3.3" xref="S3.SS1.SSS1.p1.1.m1.1.1.3.3.cmml"><mi id="S3.SS1.SSS1.p1.1.m1.1.1.3.3.2" xref="S3.SS1.SSS1.p1.1.m1.1.1.3.3.2.cmml">d</mi><mi id="S3.SS1.SSS1.p1.1.m1.1.1.3.3.3" xref="S3.SS1.SSS1.p1.1.m1.1.1.3.3.3.cmml">k</mi></msub></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p1.1.m1.1b"><apply id="S3.SS1.SSS1.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS1.p1.1.m1.1.1"><in id="S3.SS1.SSS1.p1.1.m1.1.1.1.cmml" xref="S3.SS1.SSS1.p1.1.m1.1.1.1"></in><ci id="S3.SS1.SSS1.p1.1.m1.1.1.2.cmml" xref="S3.SS1.SSS1.p1.1.m1.1.1.2">𝑣</ci><apply id="S3.SS1.SSS1.p1.1.m1.1.1.3.cmml" xref="S3.SS1.SSS1.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p1.1.m1.1.1.3.1.cmml" xref="S3.SS1.SSS1.p1.1.m1.1.1.3">superscript</csymbol><ci id="S3.SS1.SSS1.p1.1.m1.1.1.3.2.cmml" xref="S3.SS1.SSS1.p1.1.m1.1.1.3.2">ℛ</ci><apply id="S3.SS1.SSS1.p1.1.m1.1.1.3.3.cmml" xref="S3.SS1.SSS1.p1.1.m1.1.1.3.3"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p1.1.m1.1.1.3.3.1.cmml" xref="S3.SS1.SSS1.p1.1.m1.1.1.3.3">subscript</csymbol><ci id="S3.SS1.SSS1.p1.1.m1.1.1.3.3.2.cmml" xref="S3.SS1.SSS1.p1.1.m1.1.1.3.3.2">𝑑</ci><ci id="S3.SS1.SSS1.p1.1.m1.1.1.3.3.3.cmml" xref="S3.SS1.SSS1.p1.1.m1.1.1.3.3.3">𝑘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p1.1.m1.1c">v\in\mathcal{R}^{d_{k}}</annotation></semantics></math>, <math id="S3.SS1.SSS1.p1.2.m2.1" class="ltx_Math" alttext="d_{k}=128" display="inline"><semantics id="S3.SS1.SSS1.p1.2.m2.1a"><mrow id="S3.SS1.SSS1.p1.2.m2.1.1" xref="S3.SS1.SSS1.p1.2.m2.1.1.cmml"><msub id="S3.SS1.SSS1.p1.2.m2.1.1.2" xref="S3.SS1.SSS1.p1.2.m2.1.1.2.cmml"><mi id="S3.SS1.SSS1.p1.2.m2.1.1.2.2" xref="S3.SS1.SSS1.p1.2.m2.1.1.2.2.cmml">d</mi><mi id="S3.SS1.SSS1.p1.2.m2.1.1.2.3" xref="S3.SS1.SSS1.p1.2.m2.1.1.2.3.cmml">k</mi></msub><mo id="S3.SS1.SSS1.p1.2.m2.1.1.1" xref="S3.SS1.SSS1.p1.2.m2.1.1.1.cmml">=</mo><mn id="S3.SS1.SSS1.p1.2.m2.1.1.3" xref="S3.SS1.SSS1.p1.2.m2.1.1.3.cmml">128</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p1.2.m2.1b"><apply id="S3.SS1.SSS1.p1.2.m2.1.1.cmml" xref="S3.SS1.SSS1.p1.2.m2.1.1"><eq id="S3.SS1.SSS1.p1.2.m2.1.1.1.cmml" xref="S3.SS1.SSS1.p1.2.m2.1.1.1"></eq><apply id="S3.SS1.SSS1.p1.2.m2.1.1.2.cmml" xref="S3.SS1.SSS1.p1.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p1.2.m2.1.1.2.1.cmml" xref="S3.SS1.SSS1.p1.2.m2.1.1.2">subscript</csymbol><ci id="S3.SS1.SSS1.p1.2.m2.1.1.2.2.cmml" xref="S3.SS1.SSS1.p1.2.m2.1.1.2.2">𝑑</ci><ci id="S3.SS1.SSS1.p1.2.m2.1.1.2.3.cmml" xref="S3.SS1.SSS1.p1.2.m2.1.1.2.3">𝑘</ci></apply><cn type="integer" id="S3.SS1.SSS1.p1.2.m2.1.1.3.cmml" xref="S3.SS1.SSS1.p1.2.m2.1.1.3">128</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p1.2.m2.1c">d_{k}=128</annotation></semantics></math> denotes the dimension of image features.</p>
</div>
</section>
<section id="S3.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.2 </span>Question representation</h4>

<div id="S3.SS1.SSS2.p1" class="ltx_para">
<p id="S3.SS1.SSS2.p1.7" class="ltx_p">Each question is unified into a sentence consisting of <math id="S3.SS1.SSS2.p1.1.m1.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S3.SS1.SSS2.p1.1.m1.1a"><mi id="S3.SS1.SSS2.p1.1.m1.1.1" xref="S3.SS1.SSS2.p1.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p1.1.m1.1b"><ci id="S3.SS1.SSS2.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS2.p1.1.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p1.1.m1.1c">n</annotation></semantics></math> words. Parts exceeding <math id="S3.SS1.SSS2.p1.2.m2.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S3.SS1.SSS2.p1.2.m2.1a"><mi id="S3.SS1.SSS2.p1.2.m2.1.1" xref="S3.SS1.SSS2.p1.2.m2.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p1.2.m2.1b"><ci id="S3.SS1.SSS2.p1.2.m2.1.1.cmml" xref="S3.SS1.SSS2.p1.2.m2.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p1.2.m2.1c">n</annotation></semantics></math> words will be deleted and parts less than <math id="S3.SS1.SSS2.p1.3.m3.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S3.SS1.SSS2.p1.3.m3.1a"><mi id="S3.SS1.SSS2.p1.3.m3.1.1" xref="S3.SS1.SSS2.p1.3.m3.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p1.3.m3.1b"><ci id="S3.SS1.SSS2.p1.3.m3.1.1.cmml" xref="S3.SS1.SSS2.p1.3.m3.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p1.3.m3.1c">n</annotation></semantics></math> words will be zero-padded . Words are represented by 300-dimensional GloVe word embedding <math id="S3.SS1.SSS2.p1.4.m4.2" class="ltx_Math" alttext="D=\{w_{1},w_{2}...w_{n}\}\in\mathcal{R}^{d_{h}*n}" display="inline"><semantics id="S3.SS1.SSS2.p1.4.m4.2a"><mrow id="S3.SS1.SSS2.p1.4.m4.2.2" xref="S3.SS1.SSS2.p1.4.m4.2.2.cmml"><mi id="S3.SS1.SSS2.p1.4.m4.2.2.4" xref="S3.SS1.SSS2.p1.4.m4.2.2.4.cmml">D</mi><mo id="S3.SS1.SSS2.p1.4.m4.2.2.5" xref="S3.SS1.SSS2.p1.4.m4.2.2.5.cmml">=</mo><mrow id="S3.SS1.SSS2.p1.4.m4.2.2.2.2" xref="S3.SS1.SSS2.p1.4.m4.2.2.2.3.cmml"><mo stretchy="false" id="S3.SS1.SSS2.p1.4.m4.2.2.2.2.3" xref="S3.SS1.SSS2.p1.4.m4.2.2.2.3.cmml">{</mo><msub id="S3.SS1.SSS2.p1.4.m4.1.1.1.1.1" xref="S3.SS1.SSS2.p1.4.m4.1.1.1.1.1.cmml"><mi id="S3.SS1.SSS2.p1.4.m4.1.1.1.1.1.2" xref="S3.SS1.SSS2.p1.4.m4.1.1.1.1.1.2.cmml">w</mi><mn id="S3.SS1.SSS2.p1.4.m4.1.1.1.1.1.3" xref="S3.SS1.SSS2.p1.4.m4.1.1.1.1.1.3.cmml">1</mn></msub><mo id="S3.SS1.SSS2.p1.4.m4.2.2.2.2.4" xref="S3.SS1.SSS2.p1.4.m4.2.2.2.3.cmml">,</mo><mrow id="S3.SS1.SSS2.p1.4.m4.2.2.2.2.2" xref="S3.SS1.SSS2.p1.4.m4.2.2.2.2.2.cmml"><msub id="S3.SS1.SSS2.p1.4.m4.2.2.2.2.2.2" xref="S3.SS1.SSS2.p1.4.m4.2.2.2.2.2.2.cmml"><mi id="S3.SS1.SSS2.p1.4.m4.2.2.2.2.2.2.2" xref="S3.SS1.SSS2.p1.4.m4.2.2.2.2.2.2.2.cmml">w</mi><mn id="S3.SS1.SSS2.p1.4.m4.2.2.2.2.2.2.3" xref="S3.SS1.SSS2.p1.4.m4.2.2.2.2.2.2.3.cmml">2</mn></msub><mo lspace="0em" rspace="0em" id="S3.SS1.SSS2.p1.4.m4.2.2.2.2.2.1" xref="S3.SS1.SSS2.p1.4.m4.2.2.2.2.2.1.cmml">​</mo><mi mathvariant="normal" id="S3.SS1.SSS2.p1.4.m4.2.2.2.2.2.3" xref="S3.SS1.SSS2.p1.4.m4.2.2.2.2.2.3.cmml">…</mi><mo lspace="0em" rspace="0em" id="S3.SS1.SSS2.p1.4.m4.2.2.2.2.2.1a" xref="S3.SS1.SSS2.p1.4.m4.2.2.2.2.2.1.cmml">​</mo><msub id="S3.SS1.SSS2.p1.4.m4.2.2.2.2.2.4" xref="S3.SS1.SSS2.p1.4.m4.2.2.2.2.2.4.cmml"><mi id="S3.SS1.SSS2.p1.4.m4.2.2.2.2.2.4.2" xref="S3.SS1.SSS2.p1.4.m4.2.2.2.2.2.4.2.cmml">w</mi><mi id="S3.SS1.SSS2.p1.4.m4.2.2.2.2.2.4.3" xref="S3.SS1.SSS2.p1.4.m4.2.2.2.2.2.4.3.cmml">n</mi></msub></mrow><mo stretchy="false" id="S3.SS1.SSS2.p1.4.m4.2.2.2.2.5" xref="S3.SS1.SSS2.p1.4.m4.2.2.2.3.cmml">}</mo></mrow><mo id="S3.SS1.SSS2.p1.4.m4.2.2.6" xref="S3.SS1.SSS2.p1.4.m4.2.2.6.cmml">∈</mo><msup id="S3.SS1.SSS2.p1.4.m4.2.2.7" xref="S3.SS1.SSS2.p1.4.m4.2.2.7.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.SSS2.p1.4.m4.2.2.7.2" xref="S3.SS1.SSS2.p1.4.m4.2.2.7.2.cmml">ℛ</mi><mrow id="S3.SS1.SSS2.p1.4.m4.2.2.7.3" xref="S3.SS1.SSS2.p1.4.m4.2.2.7.3.cmml"><msub id="S3.SS1.SSS2.p1.4.m4.2.2.7.3.2" xref="S3.SS1.SSS2.p1.4.m4.2.2.7.3.2.cmml"><mi id="S3.SS1.SSS2.p1.4.m4.2.2.7.3.2.2" xref="S3.SS1.SSS2.p1.4.m4.2.2.7.3.2.2.cmml">d</mi><mi id="S3.SS1.SSS2.p1.4.m4.2.2.7.3.2.3" xref="S3.SS1.SSS2.p1.4.m4.2.2.7.3.2.3.cmml">h</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.SSS2.p1.4.m4.2.2.7.3.1" xref="S3.SS1.SSS2.p1.4.m4.2.2.7.3.1.cmml">∗</mo><mi id="S3.SS1.SSS2.p1.4.m4.2.2.7.3.3" xref="S3.SS1.SSS2.p1.4.m4.2.2.7.3.3.cmml">n</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p1.4.m4.2b"><apply id="S3.SS1.SSS2.p1.4.m4.2.2.cmml" xref="S3.SS1.SSS2.p1.4.m4.2.2"><and id="S3.SS1.SSS2.p1.4.m4.2.2a.cmml" xref="S3.SS1.SSS2.p1.4.m4.2.2"></and><apply id="S3.SS1.SSS2.p1.4.m4.2.2b.cmml" xref="S3.SS1.SSS2.p1.4.m4.2.2"><eq id="S3.SS1.SSS2.p1.4.m4.2.2.5.cmml" xref="S3.SS1.SSS2.p1.4.m4.2.2.5"></eq><ci id="S3.SS1.SSS2.p1.4.m4.2.2.4.cmml" xref="S3.SS1.SSS2.p1.4.m4.2.2.4">𝐷</ci><set id="S3.SS1.SSS2.p1.4.m4.2.2.2.3.cmml" xref="S3.SS1.SSS2.p1.4.m4.2.2.2.2"><apply id="S3.SS1.SSS2.p1.4.m4.1.1.1.1.1.cmml" xref="S3.SS1.SSS2.p1.4.m4.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p1.4.m4.1.1.1.1.1.1.cmml" xref="S3.SS1.SSS2.p1.4.m4.1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.SSS2.p1.4.m4.1.1.1.1.1.2.cmml" xref="S3.SS1.SSS2.p1.4.m4.1.1.1.1.1.2">𝑤</ci><cn type="integer" id="S3.SS1.SSS2.p1.4.m4.1.1.1.1.1.3.cmml" xref="S3.SS1.SSS2.p1.4.m4.1.1.1.1.1.3">1</cn></apply><apply id="S3.SS1.SSS2.p1.4.m4.2.2.2.2.2.cmml" xref="S3.SS1.SSS2.p1.4.m4.2.2.2.2.2"><times id="S3.SS1.SSS2.p1.4.m4.2.2.2.2.2.1.cmml" xref="S3.SS1.SSS2.p1.4.m4.2.2.2.2.2.1"></times><apply id="S3.SS1.SSS2.p1.4.m4.2.2.2.2.2.2.cmml" xref="S3.SS1.SSS2.p1.4.m4.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p1.4.m4.2.2.2.2.2.2.1.cmml" xref="S3.SS1.SSS2.p1.4.m4.2.2.2.2.2.2">subscript</csymbol><ci id="S3.SS1.SSS2.p1.4.m4.2.2.2.2.2.2.2.cmml" xref="S3.SS1.SSS2.p1.4.m4.2.2.2.2.2.2.2">𝑤</ci><cn type="integer" id="S3.SS1.SSS2.p1.4.m4.2.2.2.2.2.2.3.cmml" xref="S3.SS1.SSS2.p1.4.m4.2.2.2.2.2.2.3">2</cn></apply><ci id="S3.SS1.SSS2.p1.4.m4.2.2.2.2.2.3.cmml" xref="S3.SS1.SSS2.p1.4.m4.2.2.2.2.2.3">…</ci><apply id="S3.SS1.SSS2.p1.4.m4.2.2.2.2.2.4.cmml" xref="S3.SS1.SSS2.p1.4.m4.2.2.2.2.2.4"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p1.4.m4.2.2.2.2.2.4.1.cmml" xref="S3.SS1.SSS2.p1.4.m4.2.2.2.2.2.4">subscript</csymbol><ci id="S3.SS1.SSS2.p1.4.m4.2.2.2.2.2.4.2.cmml" xref="S3.SS1.SSS2.p1.4.m4.2.2.2.2.2.4.2">𝑤</ci><ci id="S3.SS1.SSS2.p1.4.m4.2.2.2.2.2.4.3.cmml" xref="S3.SS1.SSS2.p1.4.m4.2.2.2.2.2.4.3">𝑛</ci></apply></apply></set></apply><apply id="S3.SS1.SSS2.p1.4.m4.2.2c.cmml" xref="S3.SS1.SSS2.p1.4.m4.2.2"><in id="S3.SS1.SSS2.p1.4.m4.2.2.6.cmml" xref="S3.SS1.SSS2.p1.4.m4.2.2.6"></in><share href="#S3.SS1.SSS2.p1.4.m4.2.2.2.cmml" id="S3.SS1.SSS2.p1.4.m4.2.2d.cmml" xref="S3.SS1.SSS2.p1.4.m4.2.2"></share><apply id="S3.SS1.SSS2.p1.4.m4.2.2.7.cmml" xref="S3.SS1.SSS2.p1.4.m4.2.2.7"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p1.4.m4.2.2.7.1.cmml" xref="S3.SS1.SSS2.p1.4.m4.2.2.7">superscript</csymbol><ci id="S3.SS1.SSS2.p1.4.m4.2.2.7.2.cmml" xref="S3.SS1.SSS2.p1.4.m4.2.2.7.2">ℛ</ci><apply id="S3.SS1.SSS2.p1.4.m4.2.2.7.3.cmml" xref="S3.SS1.SSS2.p1.4.m4.2.2.7.3"><times id="S3.SS1.SSS2.p1.4.m4.2.2.7.3.1.cmml" xref="S3.SS1.SSS2.p1.4.m4.2.2.7.3.1"></times><apply id="S3.SS1.SSS2.p1.4.m4.2.2.7.3.2.cmml" xref="S3.SS1.SSS2.p1.4.m4.2.2.7.3.2"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p1.4.m4.2.2.7.3.2.1.cmml" xref="S3.SS1.SSS2.p1.4.m4.2.2.7.3.2">subscript</csymbol><ci id="S3.SS1.SSS2.p1.4.m4.2.2.7.3.2.2.cmml" xref="S3.SS1.SSS2.p1.4.m4.2.2.7.3.2.2">𝑑</ci><ci id="S3.SS1.SSS2.p1.4.m4.2.2.7.3.2.3.cmml" xref="S3.SS1.SSS2.p1.4.m4.2.2.7.3.2.3">ℎ</ci></apply><ci id="S3.SS1.SSS2.p1.4.m4.2.2.7.3.3.cmml" xref="S3.SS1.SSS2.p1.4.m4.2.2.7.3.3">𝑛</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p1.4.m4.2c">D=\{w_{1},w_{2}...w_{n}\}\in\mathcal{R}^{d_{h}*n}</annotation></semantics></math>, <math id="S3.SS1.SSS2.p1.5.m5.1" class="ltx_Math" alttext="d_{h}=300" display="inline"><semantics id="S3.SS1.SSS2.p1.5.m5.1a"><mrow id="S3.SS1.SSS2.p1.5.m5.1.1" xref="S3.SS1.SSS2.p1.5.m5.1.1.cmml"><msub id="S3.SS1.SSS2.p1.5.m5.1.1.2" xref="S3.SS1.SSS2.p1.5.m5.1.1.2.cmml"><mi id="S3.SS1.SSS2.p1.5.m5.1.1.2.2" xref="S3.SS1.SSS2.p1.5.m5.1.1.2.2.cmml">d</mi><mi id="S3.SS1.SSS2.p1.5.m5.1.1.2.3" xref="S3.SS1.SSS2.p1.5.m5.1.1.2.3.cmml">h</mi></msub><mo id="S3.SS1.SSS2.p1.5.m5.1.1.1" xref="S3.SS1.SSS2.p1.5.m5.1.1.1.cmml">=</mo><mn id="S3.SS1.SSS2.p1.5.m5.1.1.3" xref="S3.SS1.SSS2.p1.5.m5.1.1.3.cmml">300</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p1.5.m5.1b"><apply id="S3.SS1.SSS2.p1.5.m5.1.1.cmml" xref="S3.SS1.SSS2.p1.5.m5.1.1"><eq id="S3.SS1.SSS2.p1.5.m5.1.1.1.cmml" xref="S3.SS1.SSS2.p1.5.m5.1.1.1"></eq><apply id="S3.SS1.SSS2.p1.5.m5.1.1.2.cmml" xref="S3.SS1.SSS2.p1.5.m5.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p1.5.m5.1.1.2.1.cmml" xref="S3.SS1.SSS2.p1.5.m5.1.1.2">subscript</csymbol><ci id="S3.SS1.SSS2.p1.5.m5.1.1.2.2.cmml" xref="S3.SS1.SSS2.p1.5.m5.1.1.2.2">𝑑</ci><ci id="S3.SS1.SSS2.p1.5.m5.1.1.2.3.cmml" xref="S3.SS1.SSS2.p1.5.m5.1.1.2.3">ℎ</ci></apply><cn type="integer" id="S3.SS1.SSS2.p1.5.m5.1.1.3.cmml" xref="S3.SS1.SSS2.p1.5.m5.1.1.3">300</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p1.5.m5.1c">d_{h}=300</annotation></semantics></math> denotes the dimension of each word representation. Finally, the word vectors are fed to the Gated Recurrent Units (GRU) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> network to encode the question embedding <math id="S3.SS1.SSS2.p1.6.m6.2" class="ltx_Math" alttext="Q=\{q_{1},q_{2}...q_{n}\}\in\mathcal{R}^{d_{s}*n}" display="inline"><semantics id="S3.SS1.SSS2.p1.6.m6.2a"><mrow id="S3.SS1.SSS2.p1.6.m6.2.2" xref="S3.SS1.SSS2.p1.6.m6.2.2.cmml"><mi id="S3.SS1.SSS2.p1.6.m6.2.2.4" xref="S3.SS1.SSS2.p1.6.m6.2.2.4.cmml">Q</mi><mo id="S3.SS1.SSS2.p1.6.m6.2.2.5" xref="S3.SS1.SSS2.p1.6.m6.2.2.5.cmml">=</mo><mrow id="S3.SS1.SSS2.p1.6.m6.2.2.2.2" xref="S3.SS1.SSS2.p1.6.m6.2.2.2.3.cmml"><mo stretchy="false" id="S3.SS1.SSS2.p1.6.m6.2.2.2.2.3" xref="S3.SS1.SSS2.p1.6.m6.2.2.2.3.cmml">{</mo><msub id="S3.SS1.SSS2.p1.6.m6.1.1.1.1.1" xref="S3.SS1.SSS2.p1.6.m6.1.1.1.1.1.cmml"><mi id="S3.SS1.SSS2.p1.6.m6.1.1.1.1.1.2" xref="S3.SS1.SSS2.p1.6.m6.1.1.1.1.1.2.cmml">q</mi><mn id="S3.SS1.SSS2.p1.6.m6.1.1.1.1.1.3" xref="S3.SS1.SSS2.p1.6.m6.1.1.1.1.1.3.cmml">1</mn></msub><mo id="S3.SS1.SSS2.p1.6.m6.2.2.2.2.4" xref="S3.SS1.SSS2.p1.6.m6.2.2.2.3.cmml">,</mo><mrow id="S3.SS1.SSS2.p1.6.m6.2.2.2.2.2" xref="S3.SS1.SSS2.p1.6.m6.2.2.2.2.2.cmml"><msub id="S3.SS1.SSS2.p1.6.m6.2.2.2.2.2.2" xref="S3.SS1.SSS2.p1.6.m6.2.2.2.2.2.2.cmml"><mi id="S3.SS1.SSS2.p1.6.m6.2.2.2.2.2.2.2" xref="S3.SS1.SSS2.p1.6.m6.2.2.2.2.2.2.2.cmml">q</mi><mn id="S3.SS1.SSS2.p1.6.m6.2.2.2.2.2.2.3" xref="S3.SS1.SSS2.p1.6.m6.2.2.2.2.2.2.3.cmml">2</mn></msub><mo lspace="0em" rspace="0em" id="S3.SS1.SSS2.p1.6.m6.2.2.2.2.2.1" xref="S3.SS1.SSS2.p1.6.m6.2.2.2.2.2.1.cmml">​</mo><mi mathvariant="normal" id="S3.SS1.SSS2.p1.6.m6.2.2.2.2.2.3" xref="S3.SS1.SSS2.p1.6.m6.2.2.2.2.2.3.cmml">…</mi><mo lspace="0em" rspace="0em" id="S3.SS1.SSS2.p1.6.m6.2.2.2.2.2.1a" xref="S3.SS1.SSS2.p1.6.m6.2.2.2.2.2.1.cmml">​</mo><msub id="S3.SS1.SSS2.p1.6.m6.2.2.2.2.2.4" xref="S3.SS1.SSS2.p1.6.m6.2.2.2.2.2.4.cmml"><mi id="S3.SS1.SSS2.p1.6.m6.2.2.2.2.2.4.2" xref="S3.SS1.SSS2.p1.6.m6.2.2.2.2.2.4.2.cmml">q</mi><mi id="S3.SS1.SSS2.p1.6.m6.2.2.2.2.2.4.3" xref="S3.SS1.SSS2.p1.6.m6.2.2.2.2.2.4.3.cmml">n</mi></msub></mrow><mo stretchy="false" id="S3.SS1.SSS2.p1.6.m6.2.2.2.2.5" xref="S3.SS1.SSS2.p1.6.m6.2.2.2.3.cmml">}</mo></mrow><mo id="S3.SS1.SSS2.p1.6.m6.2.2.6" xref="S3.SS1.SSS2.p1.6.m6.2.2.6.cmml">∈</mo><msup id="S3.SS1.SSS2.p1.6.m6.2.2.7" xref="S3.SS1.SSS2.p1.6.m6.2.2.7.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.SSS2.p1.6.m6.2.2.7.2" xref="S3.SS1.SSS2.p1.6.m6.2.2.7.2.cmml">ℛ</mi><mrow id="S3.SS1.SSS2.p1.6.m6.2.2.7.3" xref="S3.SS1.SSS2.p1.6.m6.2.2.7.3.cmml"><msub id="S3.SS1.SSS2.p1.6.m6.2.2.7.3.2" xref="S3.SS1.SSS2.p1.6.m6.2.2.7.3.2.cmml"><mi id="S3.SS1.SSS2.p1.6.m6.2.2.7.3.2.2" xref="S3.SS1.SSS2.p1.6.m6.2.2.7.3.2.2.cmml">d</mi><mi id="S3.SS1.SSS2.p1.6.m6.2.2.7.3.2.3" xref="S3.SS1.SSS2.p1.6.m6.2.2.7.3.2.3.cmml">s</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.SSS2.p1.6.m6.2.2.7.3.1" xref="S3.SS1.SSS2.p1.6.m6.2.2.7.3.1.cmml">∗</mo><mi id="S3.SS1.SSS2.p1.6.m6.2.2.7.3.3" xref="S3.SS1.SSS2.p1.6.m6.2.2.7.3.3.cmml">n</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p1.6.m6.2b"><apply id="S3.SS1.SSS2.p1.6.m6.2.2.cmml" xref="S3.SS1.SSS2.p1.6.m6.2.2"><and id="S3.SS1.SSS2.p1.6.m6.2.2a.cmml" xref="S3.SS1.SSS2.p1.6.m6.2.2"></and><apply id="S3.SS1.SSS2.p1.6.m6.2.2b.cmml" xref="S3.SS1.SSS2.p1.6.m6.2.2"><eq id="S3.SS1.SSS2.p1.6.m6.2.2.5.cmml" xref="S3.SS1.SSS2.p1.6.m6.2.2.5"></eq><ci id="S3.SS1.SSS2.p1.6.m6.2.2.4.cmml" xref="S3.SS1.SSS2.p1.6.m6.2.2.4">𝑄</ci><set id="S3.SS1.SSS2.p1.6.m6.2.2.2.3.cmml" xref="S3.SS1.SSS2.p1.6.m6.2.2.2.2"><apply id="S3.SS1.SSS2.p1.6.m6.1.1.1.1.1.cmml" xref="S3.SS1.SSS2.p1.6.m6.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p1.6.m6.1.1.1.1.1.1.cmml" xref="S3.SS1.SSS2.p1.6.m6.1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.SSS2.p1.6.m6.1.1.1.1.1.2.cmml" xref="S3.SS1.SSS2.p1.6.m6.1.1.1.1.1.2">𝑞</ci><cn type="integer" id="S3.SS1.SSS2.p1.6.m6.1.1.1.1.1.3.cmml" xref="S3.SS1.SSS2.p1.6.m6.1.1.1.1.1.3">1</cn></apply><apply id="S3.SS1.SSS2.p1.6.m6.2.2.2.2.2.cmml" xref="S3.SS1.SSS2.p1.6.m6.2.2.2.2.2"><times id="S3.SS1.SSS2.p1.6.m6.2.2.2.2.2.1.cmml" xref="S3.SS1.SSS2.p1.6.m6.2.2.2.2.2.1"></times><apply id="S3.SS1.SSS2.p1.6.m6.2.2.2.2.2.2.cmml" xref="S3.SS1.SSS2.p1.6.m6.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p1.6.m6.2.2.2.2.2.2.1.cmml" xref="S3.SS1.SSS2.p1.6.m6.2.2.2.2.2.2">subscript</csymbol><ci id="S3.SS1.SSS2.p1.6.m6.2.2.2.2.2.2.2.cmml" xref="S3.SS1.SSS2.p1.6.m6.2.2.2.2.2.2.2">𝑞</ci><cn type="integer" id="S3.SS1.SSS2.p1.6.m6.2.2.2.2.2.2.3.cmml" xref="S3.SS1.SSS2.p1.6.m6.2.2.2.2.2.2.3">2</cn></apply><ci id="S3.SS1.SSS2.p1.6.m6.2.2.2.2.2.3.cmml" xref="S3.SS1.SSS2.p1.6.m6.2.2.2.2.2.3">…</ci><apply id="S3.SS1.SSS2.p1.6.m6.2.2.2.2.2.4.cmml" xref="S3.SS1.SSS2.p1.6.m6.2.2.2.2.2.4"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p1.6.m6.2.2.2.2.2.4.1.cmml" xref="S3.SS1.SSS2.p1.6.m6.2.2.2.2.2.4">subscript</csymbol><ci id="S3.SS1.SSS2.p1.6.m6.2.2.2.2.2.4.2.cmml" xref="S3.SS1.SSS2.p1.6.m6.2.2.2.2.2.4.2">𝑞</ci><ci id="S3.SS1.SSS2.p1.6.m6.2.2.2.2.2.4.3.cmml" xref="S3.SS1.SSS2.p1.6.m6.2.2.2.2.2.4.3">𝑛</ci></apply></apply></set></apply><apply id="S3.SS1.SSS2.p1.6.m6.2.2c.cmml" xref="S3.SS1.SSS2.p1.6.m6.2.2"><in id="S3.SS1.SSS2.p1.6.m6.2.2.6.cmml" xref="S3.SS1.SSS2.p1.6.m6.2.2.6"></in><share href="#S3.SS1.SSS2.p1.6.m6.2.2.2.cmml" id="S3.SS1.SSS2.p1.6.m6.2.2d.cmml" xref="S3.SS1.SSS2.p1.6.m6.2.2"></share><apply id="S3.SS1.SSS2.p1.6.m6.2.2.7.cmml" xref="S3.SS1.SSS2.p1.6.m6.2.2.7"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p1.6.m6.2.2.7.1.cmml" xref="S3.SS1.SSS2.p1.6.m6.2.2.7">superscript</csymbol><ci id="S3.SS1.SSS2.p1.6.m6.2.2.7.2.cmml" xref="S3.SS1.SSS2.p1.6.m6.2.2.7.2">ℛ</ci><apply id="S3.SS1.SSS2.p1.6.m6.2.2.7.3.cmml" xref="S3.SS1.SSS2.p1.6.m6.2.2.7.3"><times id="S3.SS1.SSS2.p1.6.m6.2.2.7.3.1.cmml" xref="S3.SS1.SSS2.p1.6.m6.2.2.7.3.1"></times><apply id="S3.SS1.SSS2.p1.6.m6.2.2.7.3.2.cmml" xref="S3.SS1.SSS2.p1.6.m6.2.2.7.3.2"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p1.6.m6.2.2.7.3.2.1.cmml" xref="S3.SS1.SSS2.p1.6.m6.2.2.7.3.2">subscript</csymbol><ci id="S3.SS1.SSS2.p1.6.m6.2.2.7.3.2.2.cmml" xref="S3.SS1.SSS2.p1.6.m6.2.2.7.3.2.2">𝑑</ci><ci id="S3.SS1.SSS2.p1.6.m6.2.2.7.3.2.3.cmml" xref="S3.SS1.SSS2.p1.6.m6.2.2.7.3.2.3">𝑠</ci></apply><ci id="S3.SS1.SSS2.p1.6.m6.2.2.7.3.3.cmml" xref="S3.SS1.SSS2.p1.6.m6.2.2.7.3.3">𝑛</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p1.6.m6.2c">Q=\{q_{1},q_{2}...q_{n}\}\in\mathcal{R}^{d_{s}*n}</annotation></semantics></math>, <math id="S3.SS1.SSS2.p1.7.m7.1" class="ltx_Math" alttext="d_{s}=1024" display="inline"><semantics id="S3.SS1.SSS2.p1.7.m7.1a"><mrow id="S3.SS1.SSS2.p1.7.m7.1.1" xref="S3.SS1.SSS2.p1.7.m7.1.1.cmml"><msub id="S3.SS1.SSS2.p1.7.m7.1.1.2" xref="S3.SS1.SSS2.p1.7.m7.1.1.2.cmml"><mi id="S3.SS1.SSS2.p1.7.m7.1.1.2.2" xref="S3.SS1.SSS2.p1.7.m7.1.1.2.2.cmml">d</mi><mi id="S3.SS1.SSS2.p1.7.m7.1.1.2.3" xref="S3.SS1.SSS2.p1.7.m7.1.1.2.3.cmml">s</mi></msub><mo id="S3.SS1.SSS2.p1.7.m7.1.1.1" xref="S3.SS1.SSS2.p1.7.m7.1.1.1.cmml">=</mo><mn id="S3.SS1.SSS2.p1.7.m7.1.1.3" xref="S3.SS1.SSS2.p1.7.m7.1.1.3.cmml">1024</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p1.7.m7.1b"><apply id="S3.SS1.SSS2.p1.7.m7.1.1.cmml" xref="S3.SS1.SSS2.p1.7.m7.1.1"><eq id="S3.SS1.SSS2.p1.7.m7.1.1.1.cmml" xref="S3.SS1.SSS2.p1.7.m7.1.1.1"></eq><apply id="S3.SS1.SSS2.p1.7.m7.1.1.2.cmml" xref="S3.SS1.SSS2.p1.7.m7.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p1.7.m7.1.1.2.1.cmml" xref="S3.SS1.SSS2.p1.7.m7.1.1.2">subscript</csymbol><ci id="S3.SS1.SSS2.p1.7.m7.1.1.2.2.cmml" xref="S3.SS1.SSS2.p1.7.m7.1.1.2.2">𝑑</ci><ci id="S3.SS1.SSS2.p1.7.m7.1.1.2.3.cmml" xref="S3.SS1.SSS2.p1.7.m7.1.1.2.3">𝑠</ci></apply><cn type="integer" id="S3.SS1.SSS2.p1.7.m7.1.1.3.cmml" xref="S3.SS1.SSS2.p1.7.m7.1.1.3">1024</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p1.7.m7.1c">d_{s}=1024</annotation></semantics></math> is the dimension of each hidden state in GRU.</p>
</div>
</section>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Multi-View Attention </h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">For a question-answer pair, there is a correlation between the image and the question. In order to maximize the application of semantic information, a multi-view attention mechanism is proposed. It includes word-to-text attention and image-to-question attention, giving attentions to the question from two views of the word and the image.</p>
</div>
<section id="S3.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.1 </span>W2T attention mechanism</h4>

<div id="S3.SS2.SSS1.p1" class="ltx_para">
<p id="S3.SS2.SSS1.p1.4" class="ltx_p">We use the question conditional reasoning framework proposed by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> to emphasize the important part of the question. The question representation <math id="S3.SS2.SSS1.p1.1.m1.1" class="ltx_Math" alttext="Q" display="inline"><semantics id="S3.SS2.SSS1.p1.1.m1.1a"><mi id="S3.SS2.SSS1.p1.1.m1.1.1" xref="S3.SS2.SSS1.p1.1.m1.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p1.1.m1.1b"><ci id="S3.SS2.SSS1.p1.1.m1.1.1.cmml" xref="S3.SS2.SSS1.p1.1.m1.1.1">𝑄</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p1.1.m1.1c">Q</annotation></semantics></math> obtained by the feature extraction module has the same importance for different words, which is inconsistent with human brain focusing. In order to emphasize the significant part of the question, the attention mechanism is used to give full play to the advantages of word embedding and sentence vectors to assign different words with importance weights. This part gets the importance of each word in the question from the semantic level. Firstiy, the word embedding representation <math id="S3.SS2.SSS1.p1.2.m2.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S3.SS2.SSS1.p1.2.m2.1a"><mi id="S3.SS2.SSS1.p1.2.m2.1.1" xref="S3.SS2.SSS1.p1.2.m2.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p1.2.m2.1b"><ci id="S3.SS2.SSS1.p1.2.m2.1.1.cmml" xref="S3.SS2.SSS1.p1.2.m2.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p1.2.m2.1c">D</annotation></semantics></math> and the question embedding representation <math id="S3.SS2.SSS1.p1.3.m3.1" class="ltx_Math" alttext="Q" display="inline"><semantics id="S3.SS2.SSS1.p1.3.m3.1a"><mi id="S3.SS2.SSS1.p1.3.m3.1.1" xref="S3.SS2.SSS1.p1.3.m3.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p1.3.m3.1b"><ci id="S3.SS2.SSS1.p1.3.m3.1.1.cmml" xref="S3.SS2.SSS1.p1.3.m3.1.1">𝑄</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p1.3.m3.1c">Q</annotation></semantics></math> are concatenated to obtain <math id="S3.SS2.SSS1.p1.4.m4.1" class="ltx_Math" alttext="Q_{c}" display="inline"><semantics id="S3.SS2.SSS1.p1.4.m4.1a"><msub id="S3.SS2.SSS1.p1.4.m4.1.1" xref="S3.SS2.SSS1.p1.4.m4.1.1.cmml"><mi id="S3.SS2.SSS1.p1.4.m4.1.1.2" xref="S3.SS2.SSS1.p1.4.m4.1.1.2.cmml">Q</mi><mi id="S3.SS2.SSS1.p1.4.m4.1.1.3" xref="S3.SS2.SSS1.p1.4.m4.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p1.4.m4.1b"><apply id="S3.SS2.SSS1.p1.4.m4.1.1.cmml" xref="S3.SS2.SSS1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p1.4.m4.1.1.1.cmml" xref="S3.SS2.SSS1.p1.4.m4.1.1">subscript</csymbol><ci id="S3.SS2.SSS1.p1.4.m4.1.1.2.cmml" xref="S3.SS2.SSS1.p1.4.m4.1.1.2">𝑄</ci><ci id="S3.SS2.SSS1.p1.4.m4.1.1.3.cmml" xref="S3.SS2.SSS1.p1.4.m4.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p1.4.m4.1c">Q_{c}</annotation></semantics></math>.</p>
</div>
<div id="S3.SS2.SSS1.p2" class="ltx_para">
<table id="S3.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E2.m1.1" class="ltx_math_unparsed" alttext="Q_{c}=[D\,||\,Q]" display="block"><semantics id="S3.E2.m1.1a"><mrow id="S3.E2.m1.1b"><msub id="S3.E2.m1.1.1"><mi id="S3.E2.m1.1.1.2">Q</mi><mi id="S3.E2.m1.1.1.3">c</mi></msub><mo id="S3.E2.m1.1.2">=</mo><mrow id="S3.E2.m1.1.3"><mo stretchy="false" id="S3.E2.m1.1.3.1">[</mo><mi id="S3.E2.m1.1.3.2">D</mi><mo fence="false" lspace="0.170em" rspace="0.167em" stretchy="false" id="S3.E2.m1.1.3.3">|</mo><mo fence="false" rspace="0.337em" stretchy="false" id="S3.E2.m1.1.3.4">|</mo><mi id="S3.E2.m1.1.3.5">Q</mi><mo stretchy="false" id="S3.E2.m1.1.3.6">]</mo></mrow></mrow><annotation encoding="application/x-tex" id="S3.E2.m1.1c">Q_{c}=[D\,||\,Q]</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S3.SS2.SSS1.p2.2" class="ltx_p">where <math id="S3.SS2.SSS1.p2.1.m1.1" class="ltx_math_unparsed" alttext="||" display="inline"><semantics id="S3.SS2.SSS1.p2.1.m1.1a"><mrow id="S3.SS2.SSS1.p2.1.m1.1b"><mo fence="false" rspace="0.167em" stretchy="false" id="S3.SS2.SSS1.p2.1.m1.1.1">|</mo><mo fence="false" stretchy="false" id="S3.SS2.SSS1.p2.1.m1.1.2">|</mo></mrow><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p2.1.m1.1c">||</annotation></semantics></math> represents the concatenation of feature dimensions, <math id="S3.SS2.SSS1.p2.2.m2.1" class="ltx_Math" alttext="Q_{c}\in R^{(d_{h}+d_{s})*n}" display="inline"><semantics id="S3.SS2.SSS1.p2.2.m2.1a"><mrow id="S3.SS2.SSS1.p2.2.m2.1.2" xref="S3.SS2.SSS1.p2.2.m2.1.2.cmml"><msub id="S3.SS2.SSS1.p2.2.m2.1.2.2" xref="S3.SS2.SSS1.p2.2.m2.1.2.2.cmml"><mi id="S3.SS2.SSS1.p2.2.m2.1.2.2.2" xref="S3.SS2.SSS1.p2.2.m2.1.2.2.2.cmml">Q</mi><mi id="S3.SS2.SSS1.p2.2.m2.1.2.2.3" xref="S3.SS2.SSS1.p2.2.m2.1.2.2.3.cmml">c</mi></msub><mo id="S3.SS2.SSS1.p2.2.m2.1.2.1" xref="S3.SS2.SSS1.p2.2.m2.1.2.1.cmml">∈</mo><msup id="S3.SS2.SSS1.p2.2.m2.1.2.3" xref="S3.SS2.SSS1.p2.2.m2.1.2.3.cmml"><mi id="S3.SS2.SSS1.p2.2.m2.1.2.3.2" xref="S3.SS2.SSS1.p2.2.m2.1.2.3.2.cmml">R</mi><mrow id="S3.SS2.SSS1.p2.2.m2.1.1.1" xref="S3.SS2.SSS1.p2.2.m2.1.1.1.cmml"><mrow id="S3.SS2.SSS1.p2.2.m2.1.1.1.1.1" xref="S3.SS2.SSS1.p2.2.m2.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS2.SSS1.p2.2.m2.1.1.1.1.1.2" xref="S3.SS2.SSS1.p2.2.m2.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS2.SSS1.p2.2.m2.1.1.1.1.1.1" xref="S3.SS2.SSS1.p2.2.m2.1.1.1.1.1.1.cmml"><msub id="S3.SS2.SSS1.p2.2.m2.1.1.1.1.1.1.2" xref="S3.SS2.SSS1.p2.2.m2.1.1.1.1.1.1.2.cmml"><mi id="S3.SS2.SSS1.p2.2.m2.1.1.1.1.1.1.2.2" xref="S3.SS2.SSS1.p2.2.m2.1.1.1.1.1.1.2.2.cmml">d</mi><mi id="S3.SS2.SSS1.p2.2.m2.1.1.1.1.1.1.2.3" xref="S3.SS2.SSS1.p2.2.m2.1.1.1.1.1.1.2.3.cmml">h</mi></msub><mo id="S3.SS2.SSS1.p2.2.m2.1.1.1.1.1.1.1" xref="S3.SS2.SSS1.p2.2.m2.1.1.1.1.1.1.1.cmml">+</mo><msub id="S3.SS2.SSS1.p2.2.m2.1.1.1.1.1.1.3" xref="S3.SS2.SSS1.p2.2.m2.1.1.1.1.1.1.3.cmml"><mi id="S3.SS2.SSS1.p2.2.m2.1.1.1.1.1.1.3.2" xref="S3.SS2.SSS1.p2.2.m2.1.1.1.1.1.1.3.2.cmml">d</mi><mi id="S3.SS2.SSS1.p2.2.m2.1.1.1.1.1.1.3.3" xref="S3.SS2.SSS1.p2.2.m2.1.1.1.1.1.1.3.3.cmml">s</mi></msub></mrow><mo rspace="0.055em" stretchy="false" id="S3.SS2.SSS1.p2.2.m2.1.1.1.1.1.3" xref="S3.SS2.SSS1.p2.2.m2.1.1.1.1.1.1.cmml">)</mo></mrow><mo rspace="0.222em" id="S3.SS2.SSS1.p2.2.m2.1.1.1.2" xref="S3.SS2.SSS1.p2.2.m2.1.1.1.2.cmml">∗</mo><mi id="S3.SS2.SSS1.p2.2.m2.1.1.1.3" xref="S3.SS2.SSS1.p2.2.m2.1.1.1.3.cmml">n</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p2.2.m2.1b"><apply id="S3.SS2.SSS1.p2.2.m2.1.2.cmml" xref="S3.SS2.SSS1.p2.2.m2.1.2"><in id="S3.SS2.SSS1.p2.2.m2.1.2.1.cmml" xref="S3.SS2.SSS1.p2.2.m2.1.2.1"></in><apply id="S3.SS2.SSS1.p2.2.m2.1.2.2.cmml" xref="S3.SS2.SSS1.p2.2.m2.1.2.2"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p2.2.m2.1.2.2.1.cmml" xref="S3.SS2.SSS1.p2.2.m2.1.2.2">subscript</csymbol><ci id="S3.SS2.SSS1.p2.2.m2.1.2.2.2.cmml" xref="S3.SS2.SSS1.p2.2.m2.1.2.2.2">𝑄</ci><ci id="S3.SS2.SSS1.p2.2.m2.1.2.2.3.cmml" xref="S3.SS2.SSS1.p2.2.m2.1.2.2.3">𝑐</ci></apply><apply id="S3.SS2.SSS1.p2.2.m2.1.2.3.cmml" xref="S3.SS2.SSS1.p2.2.m2.1.2.3"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p2.2.m2.1.2.3.1.cmml" xref="S3.SS2.SSS1.p2.2.m2.1.2.3">superscript</csymbol><ci id="S3.SS2.SSS1.p2.2.m2.1.2.3.2.cmml" xref="S3.SS2.SSS1.p2.2.m2.1.2.3.2">𝑅</ci><apply id="S3.SS2.SSS1.p2.2.m2.1.1.1.cmml" xref="S3.SS2.SSS1.p2.2.m2.1.1.1"><times id="S3.SS2.SSS1.p2.2.m2.1.1.1.2.cmml" xref="S3.SS2.SSS1.p2.2.m2.1.1.1.2"></times><apply id="S3.SS2.SSS1.p2.2.m2.1.1.1.1.1.1.cmml" xref="S3.SS2.SSS1.p2.2.m2.1.1.1.1.1"><plus id="S3.SS2.SSS1.p2.2.m2.1.1.1.1.1.1.1.cmml" xref="S3.SS2.SSS1.p2.2.m2.1.1.1.1.1.1.1"></plus><apply id="S3.SS2.SSS1.p2.2.m2.1.1.1.1.1.1.2.cmml" xref="S3.SS2.SSS1.p2.2.m2.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p2.2.m2.1.1.1.1.1.1.2.1.cmml" xref="S3.SS2.SSS1.p2.2.m2.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.SS2.SSS1.p2.2.m2.1.1.1.1.1.1.2.2.cmml" xref="S3.SS2.SSS1.p2.2.m2.1.1.1.1.1.1.2.2">𝑑</ci><ci id="S3.SS2.SSS1.p2.2.m2.1.1.1.1.1.1.2.3.cmml" xref="S3.SS2.SSS1.p2.2.m2.1.1.1.1.1.1.2.3">ℎ</ci></apply><apply id="S3.SS2.SSS1.p2.2.m2.1.1.1.1.1.1.3.cmml" xref="S3.SS2.SSS1.p2.2.m2.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p2.2.m2.1.1.1.1.1.1.3.1.cmml" xref="S3.SS2.SSS1.p2.2.m2.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.SS2.SSS1.p2.2.m2.1.1.1.1.1.1.3.2.cmml" xref="S3.SS2.SSS1.p2.2.m2.1.1.1.1.1.1.3.2">𝑑</ci><ci id="S3.SS2.SSS1.p2.2.m2.1.1.1.1.1.1.3.3.cmml" xref="S3.SS2.SSS1.p2.2.m2.1.1.1.1.1.1.3.3">𝑠</ci></apply></apply><ci id="S3.SS2.SSS1.p2.2.m2.1.1.1.3.cmml" xref="S3.SS2.SSS1.p2.2.m2.1.1.1.3">𝑛</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p2.2.m2.1c">Q_{c}\in R^{(d_{h}+d_{s})*n}</annotation></semantics></math>.</p>
</div>
<div id="S3.SS2.SSS1.p3" class="ltx_para">
<p id="S3.SS2.SSS1.p3.1" class="ltx_p">Then the sigmoid activation function is used as a selection mechanism to filter out useless noise to control the output. We take the advantages of context-free (GloVe) and contextual embedding (GRU) to obtain <math id="S3.SS2.SSS1.p3.1.m1.1" class="ltx_Math" alttext="\widetilde{Q}\in R^{d_{s}*n}" display="inline"><semantics id="S3.SS2.SSS1.p3.1.m1.1a"><mrow id="S3.SS2.SSS1.p3.1.m1.1.1" xref="S3.SS2.SSS1.p3.1.m1.1.1.cmml"><mover accent="true" id="S3.SS2.SSS1.p3.1.m1.1.1.2" xref="S3.SS2.SSS1.p3.1.m1.1.1.2.cmml"><mi id="S3.SS2.SSS1.p3.1.m1.1.1.2.2" xref="S3.SS2.SSS1.p3.1.m1.1.1.2.2.cmml">Q</mi><mo id="S3.SS2.SSS1.p3.1.m1.1.1.2.1" xref="S3.SS2.SSS1.p3.1.m1.1.1.2.1.cmml">~</mo></mover><mo id="S3.SS2.SSS1.p3.1.m1.1.1.1" xref="S3.SS2.SSS1.p3.1.m1.1.1.1.cmml">∈</mo><msup id="S3.SS2.SSS1.p3.1.m1.1.1.3" xref="S3.SS2.SSS1.p3.1.m1.1.1.3.cmml"><mi id="S3.SS2.SSS1.p3.1.m1.1.1.3.2" xref="S3.SS2.SSS1.p3.1.m1.1.1.3.2.cmml">R</mi><mrow id="S3.SS2.SSS1.p3.1.m1.1.1.3.3" xref="S3.SS2.SSS1.p3.1.m1.1.1.3.3.cmml"><msub id="S3.SS2.SSS1.p3.1.m1.1.1.3.3.2" xref="S3.SS2.SSS1.p3.1.m1.1.1.3.3.2.cmml"><mi id="S3.SS2.SSS1.p3.1.m1.1.1.3.3.2.2" xref="S3.SS2.SSS1.p3.1.m1.1.1.3.3.2.2.cmml">d</mi><mi id="S3.SS2.SSS1.p3.1.m1.1.1.3.3.2.3" xref="S3.SS2.SSS1.p3.1.m1.1.1.3.3.2.3.cmml">s</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.SSS1.p3.1.m1.1.1.3.3.1" xref="S3.SS2.SSS1.p3.1.m1.1.1.3.3.1.cmml">∗</mo><mi id="S3.SS2.SSS1.p3.1.m1.1.1.3.3.3" xref="S3.SS2.SSS1.p3.1.m1.1.1.3.3.3.cmml">n</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p3.1.m1.1b"><apply id="S3.SS2.SSS1.p3.1.m1.1.1.cmml" xref="S3.SS2.SSS1.p3.1.m1.1.1"><in id="S3.SS2.SSS1.p3.1.m1.1.1.1.cmml" xref="S3.SS2.SSS1.p3.1.m1.1.1.1"></in><apply id="S3.SS2.SSS1.p3.1.m1.1.1.2.cmml" xref="S3.SS2.SSS1.p3.1.m1.1.1.2"><ci id="S3.SS2.SSS1.p3.1.m1.1.1.2.1.cmml" xref="S3.SS2.SSS1.p3.1.m1.1.1.2.1">~</ci><ci id="S3.SS2.SSS1.p3.1.m1.1.1.2.2.cmml" xref="S3.SS2.SSS1.p3.1.m1.1.1.2.2">𝑄</ci></apply><apply id="S3.SS2.SSS1.p3.1.m1.1.1.3.cmml" xref="S3.SS2.SSS1.p3.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p3.1.m1.1.1.3.1.cmml" xref="S3.SS2.SSS1.p3.1.m1.1.1.3">superscript</csymbol><ci id="S3.SS2.SSS1.p3.1.m1.1.1.3.2.cmml" xref="S3.SS2.SSS1.p3.1.m1.1.1.3.2">𝑅</ci><apply id="S3.SS2.SSS1.p3.1.m1.1.1.3.3.cmml" xref="S3.SS2.SSS1.p3.1.m1.1.1.3.3"><times id="S3.SS2.SSS1.p3.1.m1.1.1.3.3.1.cmml" xref="S3.SS2.SSS1.p3.1.m1.1.1.3.3.1"></times><apply id="S3.SS2.SSS1.p3.1.m1.1.1.3.3.2.cmml" xref="S3.SS2.SSS1.p3.1.m1.1.1.3.3.2"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p3.1.m1.1.1.3.3.2.1.cmml" xref="S3.SS2.SSS1.p3.1.m1.1.1.3.3.2">subscript</csymbol><ci id="S3.SS2.SSS1.p3.1.m1.1.1.3.3.2.2.cmml" xref="S3.SS2.SSS1.p3.1.m1.1.1.3.3.2.2">𝑑</ci><ci id="S3.SS2.SSS1.p3.1.m1.1.1.3.3.2.3.cmml" xref="S3.SS2.SSS1.p3.1.m1.1.1.3.3.2.3">𝑠</ci></apply><ci id="S3.SS2.SSS1.p3.1.m1.1.1.3.3.3.cmml" xref="S3.SS2.SSS1.p3.1.m1.1.1.3.3.3">𝑛</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p3.1.m1.1c">\widetilde{Q}\in R^{d_{s}*n}</annotation></semantics></math>.</p>
</div>
<div id="S3.SS2.SSS1.p4" class="ltx_para">
<table id="S3.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E3.m1.3" class="ltx_Math" alttext="\widetilde{Q}=\tanh(W_{1}Q_{c})\odot\sigma(W_{2}Q_{c})" display="block"><semantics id="S3.E3.m1.3a"><mrow id="S3.E3.m1.3.3" xref="S3.E3.m1.3.3.cmml"><mover accent="true" id="S3.E3.m1.3.3.4" xref="S3.E3.m1.3.3.4.cmml"><mi id="S3.E3.m1.3.3.4.2" xref="S3.E3.m1.3.3.4.2.cmml">Q</mi><mo id="S3.E3.m1.3.3.4.1" xref="S3.E3.m1.3.3.4.1.cmml">~</mo></mover><mo id="S3.E3.m1.3.3.3" xref="S3.E3.m1.3.3.3.cmml">=</mo><mrow id="S3.E3.m1.3.3.2" xref="S3.E3.m1.3.3.2.cmml"><mrow id="S3.E3.m1.2.2.1.1" xref="S3.E3.m1.2.2.1.1.cmml"><mrow id="S3.E3.m1.2.2.1.1.1.1" xref="S3.E3.m1.2.2.1.1.1.2.cmml"><mi id="S3.E3.m1.1.1" xref="S3.E3.m1.1.1.cmml">tanh</mi><mo id="S3.E3.m1.2.2.1.1.1.1a" xref="S3.E3.m1.2.2.1.1.1.2.cmml">⁡</mo><mrow id="S3.E3.m1.2.2.1.1.1.1.1" xref="S3.E3.m1.2.2.1.1.1.2.cmml"><mo stretchy="false" id="S3.E3.m1.2.2.1.1.1.1.1.2" xref="S3.E3.m1.2.2.1.1.1.2.cmml">(</mo><mrow id="S3.E3.m1.2.2.1.1.1.1.1.1" xref="S3.E3.m1.2.2.1.1.1.1.1.1.cmml"><msub id="S3.E3.m1.2.2.1.1.1.1.1.1.2" xref="S3.E3.m1.2.2.1.1.1.1.1.1.2.cmml"><mi id="S3.E3.m1.2.2.1.1.1.1.1.1.2.2" xref="S3.E3.m1.2.2.1.1.1.1.1.1.2.2.cmml">W</mi><mn id="S3.E3.m1.2.2.1.1.1.1.1.1.2.3" xref="S3.E3.m1.2.2.1.1.1.1.1.1.2.3.cmml">1</mn></msub><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.1.1.1.1.1" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.cmml">​</mo><msub id="S3.E3.m1.2.2.1.1.1.1.1.1.3" xref="S3.E3.m1.2.2.1.1.1.1.1.1.3.cmml"><mi id="S3.E3.m1.2.2.1.1.1.1.1.1.3.2" xref="S3.E3.m1.2.2.1.1.1.1.1.1.3.2.cmml">Q</mi><mi id="S3.E3.m1.2.2.1.1.1.1.1.1.3.3" xref="S3.E3.m1.2.2.1.1.1.1.1.1.3.3.cmml">c</mi></msub></mrow><mo rspace="0.055em" stretchy="false" id="S3.E3.m1.2.2.1.1.1.1.1.3" xref="S3.E3.m1.2.2.1.1.1.2.cmml">)</mo></mrow></mrow><mo rspace="0.222em" id="S3.E3.m1.2.2.1.1.2" xref="S3.E3.m1.2.2.1.1.2.cmml">⊙</mo><mi id="S3.E3.m1.2.2.1.1.3" xref="S3.E3.m1.2.2.1.1.3.cmml">σ</mi></mrow><mo lspace="0em" rspace="0em" id="S3.E3.m1.3.3.2.3" xref="S3.E3.m1.3.3.2.3.cmml">​</mo><mrow id="S3.E3.m1.3.3.2.2.1" xref="S3.E3.m1.3.3.2.2.1.1.cmml"><mo stretchy="false" id="S3.E3.m1.3.3.2.2.1.2" xref="S3.E3.m1.3.3.2.2.1.1.cmml">(</mo><mrow id="S3.E3.m1.3.3.2.2.1.1" xref="S3.E3.m1.3.3.2.2.1.1.cmml"><msub id="S3.E3.m1.3.3.2.2.1.1.2" xref="S3.E3.m1.3.3.2.2.1.1.2.cmml"><mi id="S3.E3.m1.3.3.2.2.1.1.2.2" xref="S3.E3.m1.3.3.2.2.1.1.2.2.cmml">W</mi><mn id="S3.E3.m1.3.3.2.2.1.1.2.3" xref="S3.E3.m1.3.3.2.2.1.1.2.3.cmml">2</mn></msub><mo lspace="0em" rspace="0em" id="S3.E3.m1.3.3.2.2.1.1.1" xref="S3.E3.m1.3.3.2.2.1.1.1.cmml">​</mo><msub id="S3.E3.m1.3.3.2.2.1.1.3" xref="S3.E3.m1.3.3.2.2.1.1.3.cmml"><mi id="S3.E3.m1.3.3.2.2.1.1.3.2" xref="S3.E3.m1.3.3.2.2.1.1.3.2.cmml">Q</mi><mi id="S3.E3.m1.3.3.2.2.1.1.3.3" xref="S3.E3.m1.3.3.2.2.1.1.3.3.cmml">c</mi></msub></mrow><mo stretchy="false" id="S3.E3.m1.3.3.2.2.1.3" xref="S3.E3.m1.3.3.2.2.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.3b"><apply id="S3.E3.m1.3.3.cmml" xref="S3.E3.m1.3.3"><eq id="S3.E3.m1.3.3.3.cmml" xref="S3.E3.m1.3.3.3"></eq><apply id="S3.E3.m1.3.3.4.cmml" xref="S3.E3.m1.3.3.4"><ci id="S3.E3.m1.3.3.4.1.cmml" xref="S3.E3.m1.3.3.4.1">~</ci><ci id="S3.E3.m1.3.3.4.2.cmml" xref="S3.E3.m1.3.3.4.2">𝑄</ci></apply><apply id="S3.E3.m1.3.3.2.cmml" xref="S3.E3.m1.3.3.2"><times id="S3.E3.m1.3.3.2.3.cmml" xref="S3.E3.m1.3.3.2.3"></times><apply id="S3.E3.m1.2.2.1.1.cmml" xref="S3.E3.m1.2.2.1.1"><csymbol cd="latexml" id="S3.E3.m1.2.2.1.1.2.cmml" xref="S3.E3.m1.2.2.1.1.2">direct-product</csymbol><apply id="S3.E3.m1.2.2.1.1.1.2.cmml" xref="S3.E3.m1.2.2.1.1.1.1"><tanh id="S3.E3.m1.1.1.cmml" xref="S3.E3.m1.1.1"></tanh><apply id="S3.E3.m1.2.2.1.1.1.1.1.1.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1"><times id="S3.E3.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1"></times><apply id="S3.E3.m1.2.2.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.1.1.1.1.2.1.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E3.m1.2.2.1.1.1.1.1.1.2.2.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.2.2">𝑊</ci><cn type="integer" id="S3.E3.m1.2.2.1.1.1.1.1.1.2.3.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.2.3">1</cn></apply><apply id="S3.E3.m1.2.2.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.1.1.1.1.3.1.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E3.m1.2.2.1.1.1.1.1.1.3.2.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.3.2">𝑄</ci><ci id="S3.E3.m1.2.2.1.1.1.1.1.1.3.3.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.3.3">𝑐</ci></apply></apply></apply><ci id="S3.E3.m1.2.2.1.1.3.cmml" xref="S3.E3.m1.2.2.1.1.3">𝜎</ci></apply><apply id="S3.E3.m1.3.3.2.2.1.1.cmml" xref="S3.E3.m1.3.3.2.2.1"><times id="S3.E3.m1.3.3.2.2.1.1.1.cmml" xref="S3.E3.m1.3.3.2.2.1.1.1"></times><apply id="S3.E3.m1.3.3.2.2.1.1.2.cmml" xref="S3.E3.m1.3.3.2.2.1.1.2"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.2.2.1.1.2.1.cmml" xref="S3.E3.m1.3.3.2.2.1.1.2">subscript</csymbol><ci id="S3.E3.m1.3.3.2.2.1.1.2.2.cmml" xref="S3.E3.m1.3.3.2.2.1.1.2.2">𝑊</ci><cn type="integer" id="S3.E3.m1.3.3.2.2.1.1.2.3.cmml" xref="S3.E3.m1.3.3.2.2.1.1.2.3">2</cn></apply><apply id="S3.E3.m1.3.3.2.2.1.1.3.cmml" xref="S3.E3.m1.3.3.2.2.1.1.3"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.2.2.1.1.3.1.cmml" xref="S3.E3.m1.3.3.2.2.1.1.3">subscript</csymbol><ci id="S3.E3.m1.3.3.2.2.1.1.3.2.cmml" xref="S3.E3.m1.3.3.2.2.1.1.3.2">𝑄</ci><ci id="S3.E3.m1.3.3.2.2.1.1.3.3.cmml" xref="S3.E3.m1.3.3.2.2.1.1.3.3">𝑐</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.3c">\widetilde{Q}=\tanh(W_{1}Q_{c})\odot\sigma(W_{2}Q_{c})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p id="S3.SS2.SSS1.p4.4" class="ltx_p">where <math id="S3.SS2.SSS1.p4.1.m1.3" class="ltx_Math" alttext="W_{1},W_{2}\in R^{d_{s}*(d_{h}+d_{s})}" display="inline"><semantics id="S3.SS2.SSS1.p4.1.m1.3a"><mrow id="S3.SS2.SSS1.p4.1.m1.3.3" xref="S3.SS2.SSS1.p4.1.m1.3.3.cmml"><mrow id="S3.SS2.SSS1.p4.1.m1.3.3.2.2" xref="S3.SS2.SSS1.p4.1.m1.3.3.2.3.cmml"><msub id="S3.SS2.SSS1.p4.1.m1.2.2.1.1.1" xref="S3.SS2.SSS1.p4.1.m1.2.2.1.1.1.cmml"><mi id="S3.SS2.SSS1.p4.1.m1.2.2.1.1.1.2" xref="S3.SS2.SSS1.p4.1.m1.2.2.1.1.1.2.cmml">W</mi><mn id="S3.SS2.SSS1.p4.1.m1.2.2.1.1.1.3" xref="S3.SS2.SSS1.p4.1.m1.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S3.SS2.SSS1.p4.1.m1.3.3.2.2.3" xref="S3.SS2.SSS1.p4.1.m1.3.3.2.3.cmml">,</mo><msub id="S3.SS2.SSS1.p4.1.m1.3.3.2.2.2" xref="S3.SS2.SSS1.p4.1.m1.3.3.2.2.2.cmml"><mi id="S3.SS2.SSS1.p4.1.m1.3.3.2.2.2.2" xref="S3.SS2.SSS1.p4.1.m1.3.3.2.2.2.2.cmml">W</mi><mn id="S3.SS2.SSS1.p4.1.m1.3.3.2.2.2.3" xref="S3.SS2.SSS1.p4.1.m1.3.3.2.2.2.3.cmml">2</mn></msub></mrow><mo id="S3.SS2.SSS1.p4.1.m1.3.3.3" xref="S3.SS2.SSS1.p4.1.m1.3.3.3.cmml">∈</mo><msup id="S3.SS2.SSS1.p4.1.m1.3.3.4" xref="S3.SS2.SSS1.p4.1.m1.3.3.4.cmml"><mi id="S3.SS2.SSS1.p4.1.m1.3.3.4.2" xref="S3.SS2.SSS1.p4.1.m1.3.3.4.2.cmml">R</mi><mrow id="S3.SS2.SSS1.p4.1.m1.1.1.1" xref="S3.SS2.SSS1.p4.1.m1.1.1.1.cmml"><msub id="S3.SS2.SSS1.p4.1.m1.1.1.1.3" xref="S3.SS2.SSS1.p4.1.m1.1.1.1.3.cmml"><mi id="S3.SS2.SSS1.p4.1.m1.1.1.1.3.2" xref="S3.SS2.SSS1.p4.1.m1.1.1.1.3.2.cmml">d</mi><mi id="S3.SS2.SSS1.p4.1.m1.1.1.1.3.3" xref="S3.SS2.SSS1.p4.1.m1.1.1.1.3.3.cmml">s</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.SSS1.p4.1.m1.1.1.1.2" xref="S3.SS2.SSS1.p4.1.m1.1.1.1.2.cmml">∗</mo><mrow id="S3.SS2.SSS1.p4.1.m1.1.1.1.1.1" xref="S3.SS2.SSS1.p4.1.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS2.SSS1.p4.1.m1.1.1.1.1.1.2" xref="S3.SS2.SSS1.p4.1.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS2.SSS1.p4.1.m1.1.1.1.1.1.1" xref="S3.SS2.SSS1.p4.1.m1.1.1.1.1.1.1.cmml"><msub id="S3.SS2.SSS1.p4.1.m1.1.1.1.1.1.1.2" xref="S3.SS2.SSS1.p4.1.m1.1.1.1.1.1.1.2.cmml"><mi id="S3.SS2.SSS1.p4.1.m1.1.1.1.1.1.1.2.2" xref="S3.SS2.SSS1.p4.1.m1.1.1.1.1.1.1.2.2.cmml">d</mi><mi id="S3.SS2.SSS1.p4.1.m1.1.1.1.1.1.1.2.3" xref="S3.SS2.SSS1.p4.1.m1.1.1.1.1.1.1.2.3.cmml">h</mi></msub><mo id="S3.SS2.SSS1.p4.1.m1.1.1.1.1.1.1.1" xref="S3.SS2.SSS1.p4.1.m1.1.1.1.1.1.1.1.cmml">+</mo><msub id="S3.SS2.SSS1.p4.1.m1.1.1.1.1.1.1.3" xref="S3.SS2.SSS1.p4.1.m1.1.1.1.1.1.1.3.cmml"><mi id="S3.SS2.SSS1.p4.1.m1.1.1.1.1.1.1.3.2" xref="S3.SS2.SSS1.p4.1.m1.1.1.1.1.1.1.3.2.cmml">d</mi><mi id="S3.SS2.SSS1.p4.1.m1.1.1.1.1.1.1.3.3" xref="S3.SS2.SSS1.p4.1.m1.1.1.1.1.1.1.3.3.cmml">s</mi></msub></mrow><mo stretchy="false" id="S3.SS2.SSS1.p4.1.m1.1.1.1.1.1.3" xref="S3.SS2.SSS1.p4.1.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p4.1.m1.3b"><apply id="S3.SS2.SSS1.p4.1.m1.3.3.cmml" xref="S3.SS2.SSS1.p4.1.m1.3.3"><in id="S3.SS2.SSS1.p4.1.m1.3.3.3.cmml" xref="S3.SS2.SSS1.p4.1.m1.3.3.3"></in><list id="S3.SS2.SSS1.p4.1.m1.3.3.2.3.cmml" xref="S3.SS2.SSS1.p4.1.m1.3.3.2.2"><apply id="S3.SS2.SSS1.p4.1.m1.2.2.1.1.1.cmml" xref="S3.SS2.SSS1.p4.1.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.cmml" xref="S3.SS2.SSS1.p4.1.m1.2.2.1.1.1">subscript</csymbol><ci id="S3.SS2.SSS1.p4.1.m1.2.2.1.1.1.2.cmml" xref="S3.SS2.SSS1.p4.1.m1.2.2.1.1.1.2">𝑊</ci><cn type="integer" id="S3.SS2.SSS1.p4.1.m1.2.2.1.1.1.3.cmml" xref="S3.SS2.SSS1.p4.1.m1.2.2.1.1.1.3">1</cn></apply><apply id="S3.SS2.SSS1.p4.1.m1.3.3.2.2.2.cmml" xref="S3.SS2.SSS1.p4.1.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p4.1.m1.3.3.2.2.2.1.cmml" xref="S3.SS2.SSS1.p4.1.m1.3.3.2.2.2">subscript</csymbol><ci id="S3.SS2.SSS1.p4.1.m1.3.3.2.2.2.2.cmml" xref="S3.SS2.SSS1.p4.1.m1.3.3.2.2.2.2">𝑊</ci><cn type="integer" id="S3.SS2.SSS1.p4.1.m1.3.3.2.2.2.3.cmml" xref="S3.SS2.SSS1.p4.1.m1.3.3.2.2.2.3">2</cn></apply></list><apply id="S3.SS2.SSS1.p4.1.m1.3.3.4.cmml" xref="S3.SS2.SSS1.p4.1.m1.3.3.4"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p4.1.m1.3.3.4.1.cmml" xref="S3.SS2.SSS1.p4.1.m1.3.3.4">superscript</csymbol><ci id="S3.SS2.SSS1.p4.1.m1.3.3.4.2.cmml" xref="S3.SS2.SSS1.p4.1.m1.3.3.4.2">𝑅</ci><apply id="S3.SS2.SSS1.p4.1.m1.1.1.1.cmml" xref="S3.SS2.SSS1.p4.1.m1.1.1.1"><times id="S3.SS2.SSS1.p4.1.m1.1.1.1.2.cmml" xref="S3.SS2.SSS1.p4.1.m1.1.1.1.2"></times><apply id="S3.SS2.SSS1.p4.1.m1.1.1.1.3.cmml" xref="S3.SS2.SSS1.p4.1.m1.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p4.1.m1.1.1.1.3.1.cmml" xref="S3.SS2.SSS1.p4.1.m1.1.1.1.3">subscript</csymbol><ci id="S3.SS2.SSS1.p4.1.m1.1.1.1.3.2.cmml" xref="S3.SS2.SSS1.p4.1.m1.1.1.1.3.2">𝑑</ci><ci id="S3.SS2.SSS1.p4.1.m1.1.1.1.3.3.cmml" xref="S3.SS2.SSS1.p4.1.m1.1.1.1.3.3">𝑠</ci></apply><apply id="S3.SS2.SSS1.p4.1.m1.1.1.1.1.1.1.cmml" xref="S3.SS2.SSS1.p4.1.m1.1.1.1.1.1"><plus id="S3.SS2.SSS1.p4.1.m1.1.1.1.1.1.1.1.cmml" xref="S3.SS2.SSS1.p4.1.m1.1.1.1.1.1.1.1"></plus><apply id="S3.SS2.SSS1.p4.1.m1.1.1.1.1.1.1.2.cmml" xref="S3.SS2.SSS1.p4.1.m1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p4.1.m1.1.1.1.1.1.1.2.1.cmml" xref="S3.SS2.SSS1.p4.1.m1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.SS2.SSS1.p4.1.m1.1.1.1.1.1.1.2.2.cmml" xref="S3.SS2.SSS1.p4.1.m1.1.1.1.1.1.1.2.2">𝑑</ci><ci id="S3.SS2.SSS1.p4.1.m1.1.1.1.1.1.1.2.3.cmml" xref="S3.SS2.SSS1.p4.1.m1.1.1.1.1.1.1.2.3">ℎ</ci></apply><apply id="S3.SS2.SSS1.p4.1.m1.1.1.1.1.1.1.3.cmml" xref="S3.SS2.SSS1.p4.1.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p4.1.m1.1.1.1.1.1.1.3.1.cmml" xref="S3.SS2.SSS1.p4.1.m1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.SS2.SSS1.p4.1.m1.1.1.1.1.1.1.3.2.cmml" xref="S3.SS2.SSS1.p4.1.m1.1.1.1.1.1.1.3.2">𝑑</ci><ci id="S3.SS2.SSS1.p4.1.m1.1.1.1.1.1.1.3.3.cmml" xref="S3.SS2.SSS1.p4.1.m1.1.1.1.1.1.1.3.3">𝑠</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p4.1.m1.3c">W_{1},W_{2}\in R^{d_{s}*(d_{h}+d_{s})}</annotation></semantics></math> are learned weights, <math id="S3.SS2.SSS1.p4.2.m2.1" class="ltx_Math" alttext="\odot" display="inline"><semantics id="S3.SS2.SSS1.p4.2.m2.1a"><mo id="S3.SS2.SSS1.p4.2.m2.1.1" xref="S3.SS2.SSS1.p4.2.m2.1.1.cmml">⊙</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p4.2.m2.1b"><csymbol cd="latexml" id="S3.SS2.SSS1.p4.2.m2.1.1.cmml" xref="S3.SS2.SSS1.p4.2.m2.1.1">direct-product</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p4.2.m2.1c">\odot</annotation></semantics></math> is the Hadamard product, <math id="S3.SS2.SSS1.p4.3.m3.1" class="ltx_math_unparsed" alttext="\tanh(.)" display="inline"><semantics id="S3.SS2.SSS1.p4.3.m3.1a"><mrow id="S3.SS2.SSS1.p4.3.m3.1b"><mi id="S3.SS2.SSS1.p4.3.m3.1.1">tanh</mi><mrow id="S3.SS2.SSS1.p4.3.m3.1.2"><mo stretchy="false" id="S3.SS2.SSS1.p4.3.m3.1.2.1">(</mo><mo lspace="0em" rspace="0.167em" id="S3.SS2.SSS1.p4.3.m3.1.2.2">.</mo><mo stretchy="false" id="S3.SS2.SSS1.p4.3.m3.1.2.3">)</mo></mrow></mrow><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p4.3.m3.1c">\tanh(.)</annotation></semantics></math> and <math id="S3.SS2.SSS1.p4.4.m4.1" class="ltx_math_unparsed" alttext="\sigma(.)" display="inline"><semantics id="S3.SS2.SSS1.p4.4.m4.1a"><mrow id="S3.SS2.SSS1.p4.4.m4.1b"><mi id="S3.SS2.SSS1.p4.4.m4.1.1">σ</mi><mrow id="S3.SS2.SSS1.p4.4.m4.1.2"><mo stretchy="false" id="S3.SS2.SSS1.p4.4.m4.1.2.1">(</mo><mo lspace="0em" rspace="0.167em" id="S3.SS2.SSS1.p4.4.m4.1.2.2">.</mo><mo stretchy="false" id="S3.SS2.SSS1.p4.4.m4.1.2.3">)</mo></mrow></mrow><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p4.4.m4.1c">\sigma(.)</annotation></semantics></math> are activation functions, called sigmoid and gated hyperbolic tangent respectively.</p>
</div>
<div id="S3.SS2.SSS1.p5" class="ltx_para">
<p id="S3.SS2.SSS1.p5.2" class="ltx_p">Finally, we get the attention weight <math id="S3.SS2.SSS1.p5.1.m1.1" class="ltx_Math" alttext="a_{q}\in R^{n*1}" display="inline"><semantics id="S3.SS2.SSS1.p5.1.m1.1a"><mrow id="S3.SS2.SSS1.p5.1.m1.1.1" xref="S3.SS2.SSS1.p5.1.m1.1.1.cmml"><msub id="S3.SS2.SSS1.p5.1.m1.1.1.2" xref="S3.SS2.SSS1.p5.1.m1.1.1.2.cmml"><mi id="S3.SS2.SSS1.p5.1.m1.1.1.2.2" xref="S3.SS2.SSS1.p5.1.m1.1.1.2.2.cmml">a</mi><mi id="S3.SS2.SSS1.p5.1.m1.1.1.2.3" xref="S3.SS2.SSS1.p5.1.m1.1.1.2.3.cmml">q</mi></msub><mo id="S3.SS2.SSS1.p5.1.m1.1.1.1" xref="S3.SS2.SSS1.p5.1.m1.1.1.1.cmml">∈</mo><msup id="S3.SS2.SSS1.p5.1.m1.1.1.3" xref="S3.SS2.SSS1.p5.1.m1.1.1.3.cmml"><mi id="S3.SS2.SSS1.p5.1.m1.1.1.3.2" xref="S3.SS2.SSS1.p5.1.m1.1.1.3.2.cmml">R</mi><mrow id="S3.SS2.SSS1.p5.1.m1.1.1.3.3" xref="S3.SS2.SSS1.p5.1.m1.1.1.3.3.cmml"><mi id="S3.SS2.SSS1.p5.1.m1.1.1.3.3.2" xref="S3.SS2.SSS1.p5.1.m1.1.1.3.3.2.cmml">n</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.SSS1.p5.1.m1.1.1.3.3.1" xref="S3.SS2.SSS1.p5.1.m1.1.1.3.3.1.cmml">∗</mo><mn id="S3.SS2.SSS1.p5.1.m1.1.1.3.3.3" xref="S3.SS2.SSS1.p5.1.m1.1.1.3.3.3.cmml">1</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p5.1.m1.1b"><apply id="S3.SS2.SSS1.p5.1.m1.1.1.cmml" xref="S3.SS2.SSS1.p5.1.m1.1.1"><in id="S3.SS2.SSS1.p5.1.m1.1.1.1.cmml" xref="S3.SS2.SSS1.p5.1.m1.1.1.1"></in><apply id="S3.SS2.SSS1.p5.1.m1.1.1.2.cmml" xref="S3.SS2.SSS1.p5.1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p5.1.m1.1.1.2.1.cmml" xref="S3.SS2.SSS1.p5.1.m1.1.1.2">subscript</csymbol><ci id="S3.SS2.SSS1.p5.1.m1.1.1.2.2.cmml" xref="S3.SS2.SSS1.p5.1.m1.1.1.2.2">𝑎</ci><ci id="S3.SS2.SSS1.p5.1.m1.1.1.2.3.cmml" xref="S3.SS2.SSS1.p5.1.m1.1.1.2.3">𝑞</ci></apply><apply id="S3.SS2.SSS1.p5.1.m1.1.1.3.cmml" xref="S3.SS2.SSS1.p5.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p5.1.m1.1.1.3.1.cmml" xref="S3.SS2.SSS1.p5.1.m1.1.1.3">superscript</csymbol><ci id="S3.SS2.SSS1.p5.1.m1.1.1.3.2.cmml" xref="S3.SS2.SSS1.p5.1.m1.1.1.3.2">𝑅</ci><apply id="S3.SS2.SSS1.p5.1.m1.1.1.3.3.cmml" xref="S3.SS2.SSS1.p5.1.m1.1.1.3.3"><times id="S3.SS2.SSS1.p5.1.m1.1.1.3.3.1.cmml" xref="S3.SS2.SSS1.p5.1.m1.1.1.3.3.1"></times><ci id="S3.SS2.SSS1.p5.1.m1.1.1.3.3.2.cmml" xref="S3.SS2.SSS1.p5.1.m1.1.1.3.3.2">𝑛</ci><cn type="integer" id="S3.SS2.SSS1.p5.1.m1.1.1.3.3.3.cmml" xref="S3.SS2.SSS1.p5.1.m1.1.1.3.3.3">1</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p5.1.m1.1c">a_{q}\in R^{n*1}</annotation></semantics></math> on the semantic level for the question embedding <math id="S3.SS2.SSS1.p5.2.m2.1" class="ltx_Math" alttext="Q" display="inline"><semantics id="S3.SS2.SSS1.p5.2.m2.1a"><mi id="S3.SS2.SSS1.p5.2.m2.1.1" xref="S3.SS2.SSS1.p5.2.m2.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p5.2.m2.1b"><ci id="S3.SS2.SSS1.p5.2.m2.1.1.cmml" xref="S3.SS2.SSS1.p5.2.m2.1.1">𝑄</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p5.2.m2.1c">Q</annotation></semantics></math>.</p>
</div>
<div id="S3.SS2.SSS1.p6" class="ltx_para">
<table id="S3.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E4.m1.1" class="ltx_Math" alttext="a_{q}=softmax((W_{3}\widetilde{Q})^{T})" display="block"><semantics id="S3.E4.m1.1a"><mrow id="S3.E4.m1.1.1" xref="S3.E4.m1.1.1.cmml"><msub id="S3.E4.m1.1.1.3" xref="S3.E4.m1.1.1.3.cmml"><mi id="S3.E4.m1.1.1.3.2" xref="S3.E4.m1.1.1.3.2.cmml">a</mi><mi id="S3.E4.m1.1.1.3.3" xref="S3.E4.m1.1.1.3.3.cmml">q</mi></msub><mo id="S3.E4.m1.1.1.2" xref="S3.E4.m1.1.1.2.cmml">=</mo><mrow id="S3.E4.m1.1.1.1" xref="S3.E4.m1.1.1.1.cmml"><mi id="S3.E4.m1.1.1.1.3" xref="S3.E4.m1.1.1.1.3.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.1.1.1.2" xref="S3.E4.m1.1.1.1.2.cmml">​</mo><mi id="S3.E4.m1.1.1.1.4" xref="S3.E4.m1.1.1.1.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.1.1.1.2a" xref="S3.E4.m1.1.1.1.2.cmml">​</mo><mi id="S3.E4.m1.1.1.1.5" xref="S3.E4.m1.1.1.1.5.cmml">f</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.1.1.1.2b" xref="S3.E4.m1.1.1.1.2.cmml">​</mo><mi id="S3.E4.m1.1.1.1.6" xref="S3.E4.m1.1.1.1.6.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.1.1.1.2c" xref="S3.E4.m1.1.1.1.2.cmml">​</mo><mi id="S3.E4.m1.1.1.1.7" xref="S3.E4.m1.1.1.1.7.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.1.1.1.2d" xref="S3.E4.m1.1.1.1.2.cmml">​</mo><mi id="S3.E4.m1.1.1.1.8" xref="S3.E4.m1.1.1.1.8.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.1.1.1.2e" xref="S3.E4.m1.1.1.1.2.cmml">​</mo><mi id="S3.E4.m1.1.1.1.9" xref="S3.E4.m1.1.1.1.9.cmml">x</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.1.1.1.2f" xref="S3.E4.m1.1.1.1.2.cmml">​</mo><mrow id="S3.E4.m1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E4.m1.1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.1.1.cmml">(</mo><msup id="S3.E4.m1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.cmml"><mrow id="S3.E4.m1.1.1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E4.m1.1.1.1.1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E4.m1.1.1.1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.cmml"><msub id="S3.E4.m1.1.1.1.1.1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S3.E4.m1.1.1.1.1.1.1.1.1.1.2.2" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.2.2.cmml">W</mi><mn id="S3.E4.m1.1.1.1.1.1.1.1.1.1.2.3" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.2.3.cmml">3</mn></msub><mo lspace="0em" rspace="0em" id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.cmml">​</mo><mover accent="true" id="S3.E4.m1.1.1.1.1.1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E4.m1.1.1.1.1.1.1.1.1.1.3.2" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.3.2.cmml">Q</mi><mo id="S3.E4.m1.1.1.1.1.1.1.1.1.1.3.1" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.3.1.cmml">~</mo></mover></mrow><mo stretchy="false" id="S3.E4.m1.1.1.1.1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mi id="S3.E4.m1.1.1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.1.1.3.cmml">T</mi></msup><mo stretchy="false" id="S3.E4.m1.1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.1b"><apply id="S3.E4.m1.1.1.cmml" xref="S3.E4.m1.1.1"><eq id="S3.E4.m1.1.1.2.cmml" xref="S3.E4.m1.1.1.2"></eq><apply id="S3.E4.m1.1.1.3.cmml" xref="S3.E4.m1.1.1.3"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.3.1.cmml" xref="S3.E4.m1.1.1.3">subscript</csymbol><ci id="S3.E4.m1.1.1.3.2.cmml" xref="S3.E4.m1.1.1.3.2">𝑎</ci><ci id="S3.E4.m1.1.1.3.3.cmml" xref="S3.E4.m1.1.1.3.3">𝑞</ci></apply><apply id="S3.E4.m1.1.1.1.cmml" xref="S3.E4.m1.1.1.1"><times id="S3.E4.m1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.2"></times><ci id="S3.E4.m1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.3">𝑠</ci><ci id="S3.E4.m1.1.1.1.4.cmml" xref="S3.E4.m1.1.1.1.4">𝑜</ci><ci id="S3.E4.m1.1.1.1.5.cmml" xref="S3.E4.m1.1.1.1.5">𝑓</ci><ci id="S3.E4.m1.1.1.1.6.cmml" xref="S3.E4.m1.1.1.1.6">𝑡</ci><ci id="S3.E4.m1.1.1.1.7.cmml" xref="S3.E4.m1.1.1.1.7">𝑚</ci><ci id="S3.E4.m1.1.1.1.8.cmml" xref="S3.E4.m1.1.1.1.8">𝑎</ci><ci id="S3.E4.m1.1.1.1.9.cmml" xref="S3.E4.m1.1.1.1.9">𝑥</ci><apply id="S3.E4.m1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.1">superscript</csymbol><apply id="S3.E4.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1"><times id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1"></times><apply id="S3.E4.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E4.m1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.2.2">𝑊</ci><cn type="integer" id="S3.E4.m1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.2.3">3</cn></apply><apply id="S3.E4.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.3"><ci id="S3.E4.m1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.3.1">~</ci><ci id="S3.E4.m1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.3.2">𝑄</ci></apply></apply><ci id="S3.E4.m1.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.3">𝑇</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.1c">a_{q}=softmax((W_{3}\widetilde{Q})^{T})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p id="S3.SS2.SSS1.p6.1" class="ltx_p">where <math id="S3.SS2.SSS1.p6.1.m1.1" class="ltx_Math" alttext="W_{3}\in R^{1*d_{s}}" display="inline"><semantics id="S3.SS2.SSS1.p6.1.m1.1a"><mrow id="S3.SS2.SSS1.p6.1.m1.1.1" xref="S3.SS2.SSS1.p6.1.m1.1.1.cmml"><msub id="S3.SS2.SSS1.p6.1.m1.1.1.2" xref="S3.SS2.SSS1.p6.1.m1.1.1.2.cmml"><mi id="S3.SS2.SSS1.p6.1.m1.1.1.2.2" xref="S3.SS2.SSS1.p6.1.m1.1.1.2.2.cmml">W</mi><mn id="S3.SS2.SSS1.p6.1.m1.1.1.2.3" xref="S3.SS2.SSS1.p6.1.m1.1.1.2.3.cmml">3</mn></msub><mo id="S3.SS2.SSS1.p6.1.m1.1.1.1" xref="S3.SS2.SSS1.p6.1.m1.1.1.1.cmml">∈</mo><msup id="S3.SS2.SSS1.p6.1.m1.1.1.3" xref="S3.SS2.SSS1.p6.1.m1.1.1.3.cmml"><mi id="S3.SS2.SSS1.p6.1.m1.1.1.3.2" xref="S3.SS2.SSS1.p6.1.m1.1.1.3.2.cmml">R</mi><mrow id="S3.SS2.SSS1.p6.1.m1.1.1.3.3" xref="S3.SS2.SSS1.p6.1.m1.1.1.3.3.cmml"><mn id="S3.SS2.SSS1.p6.1.m1.1.1.3.3.2" xref="S3.SS2.SSS1.p6.1.m1.1.1.3.3.2.cmml">1</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.SSS1.p6.1.m1.1.1.3.3.1" xref="S3.SS2.SSS1.p6.1.m1.1.1.3.3.1.cmml">∗</mo><msub id="S3.SS2.SSS1.p6.1.m1.1.1.3.3.3" xref="S3.SS2.SSS1.p6.1.m1.1.1.3.3.3.cmml"><mi id="S3.SS2.SSS1.p6.1.m1.1.1.3.3.3.2" xref="S3.SS2.SSS1.p6.1.m1.1.1.3.3.3.2.cmml">d</mi><mi id="S3.SS2.SSS1.p6.1.m1.1.1.3.3.3.3" xref="S3.SS2.SSS1.p6.1.m1.1.1.3.3.3.3.cmml">s</mi></msub></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p6.1.m1.1b"><apply id="S3.SS2.SSS1.p6.1.m1.1.1.cmml" xref="S3.SS2.SSS1.p6.1.m1.1.1"><in id="S3.SS2.SSS1.p6.1.m1.1.1.1.cmml" xref="S3.SS2.SSS1.p6.1.m1.1.1.1"></in><apply id="S3.SS2.SSS1.p6.1.m1.1.1.2.cmml" xref="S3.SS2.SSS1.p6.1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p6.1.m1.1.1.2.1.cmml" xref="S3.SS2.SSS1.p6.1.m1.1.1.2">subscript</csymbol><ci id="S3.SS2.SSS1.p6.1.m1.1.1.2.2.cmml" xref="S3.SS2.SSS1.p6.1.m1.1.1.2.2">𝑊</ci><cn type="integer" id="S3.SS2.SSS1.p6.1.m1.1.1.2.3.cmml" xref="S3.SS2.SSS1.p6.1.m1.1.1.2.3">3</cn></apply><apply id="S3.SS2.SSS1.p6.1.m1.1.1.3.cmml" xref="S3.SS2.SSS1.p6.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p6.1.m1.1.1.3.1.cmml" xref="S3.SS2.SSS1.p6.1.m1.1.1.3">superscript</csymbol><ci id="S3.SS2.SSS1.p6.1.m1.1.1.3.2.cmml" xref="S3.SS2.SSS1.p6.1.m1.1.1.3.2">𝑅</ci><apply id="S3.SS2.SSS1.p6.1.m1.1.1.3.3.cmml" xref="S3.SS2.SSS1.p6.1.m1.1.1.3.3"><times id="S3.SS2.SSS1.p6.1.m1.1.1.3.3.1.cmml" xref="S3.SS2.SSS1.p6.1.m1.1.1.3.3.1"></times><cn type="integer" id="S3.SS2.SSS1.p6.1.m1.1.1.3.3.2.cmml" xref="S3.SS2.SSS1.p6.1.m1.1.1.3.3.2">1</cn><apply id="S3.SS2.SSS1.p6.1.m1.1.1.3.3.3.cmml" xref="S3.SS2.SSS1.p6.1.m1.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p6.1.m1.1.1.3.3.3.1.cmml" xref="S3.SS2.SSS1.p6.1.m1.1.1.3.3.3">subscript</csymbol><ci id="S3.SS2.SSS1.p6.1.m1.1.1.3.3.3.2.cmml" xref="S3.SS2.SSS1.p6.1.m1.1.1.3.3.3.2">𝑑</ci><ci id="S3.SS2.SSS1.p6.1.m1.1.1.3.3.3.3.cmml" xref="S3.SS2.SSS1.p6.1.m1.1.1.3.3.3.3">𝑠</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p6.1.m1.1c">W_{3}\in R^{1*d_{s}}</annotation></semantics></math> is learned weights.</p>
</div>
</section>
<section id="S3.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.2 </span>I2Q attention mechanism</h4>

<div id="S3.SS2.SSS2.p1" class="ltx_para">
<p id="S3.SS2.SSS2.p1.1" class="ltx_p">In this part, we propose an I2Q attention mechanism that is introduced to establish the relation between the two modalities to observe the question from a visual perspective. This mechanism is derived from the Rosenthal effect in social psychology. It refers to a phenomenon that the ardent hopes of teachers for students can achieve the expected results dramatically. Inspired by the Rosenthal effect, we designed the Rosenthal expectation to correspond the image and the question to the teacher and the student respectively. The image assigns different attention weights to the words in the question and mines the most potential words. Based on this idea, the attention weight is used to accurately mine the degree of strong association between the image and the words in the question.</p>
</div>
<div id="S3.SS2.SSS2.p2" class="ltx_para">
<table id="S3.E5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E5.m1.2" class="ltx_Math" alttext="a_{m}=softmax(Q^{T}MLP(v))" display="block"><semantics id="S3.E5.m1.2a"><mrow id="S3.E5.m1.2.2" xref="S3.E5.m1.2.2.cmml"><msub id="S3.E5.m1.2.2.3" xref="S3.E5.m1.2.2.3.cmml"><mi id="S3.E5.m1.2.2.3.2" xref="S3.E5.m1.2.2.3.2.cmml">a</mi><mi id="S3.E5.m1.2.2.3.3" xref="S3.E5.m1.2.2.3.3.cmml">m</mi></msub><mo id="S3.E5.m1.2.2.2" xref="S3.E5.m1.2.2.2.cmml">=</mo><mrow id="S3.E5.m1.2.2.1" xref="S3.E5.m1.2.2.1.cmml"><mi id="S3.E5.m1.2.2.1.3" xref="S3.E5.m1.2.2.1.3.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.2.2.1.2" xref="S3.E5.m1.2.2.1.2.cmml">​</mo><mi id="S3.E5.m1.2.2.1.4" xref="S3.E5.m1.2.2.1.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.2.2.1.2a" xref="S3.E5.m1.2.2.1.2.cmml">​</mo><mi id="S3.E5.m1.2.2.1.5" xref="S3.E5.m1.2.2.1.5.cmml">f</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.2.2.1.2b" xref="S3.E5.m1.2.2.1.2.cmml">​</mo><mi id="S3.E5.m1.2.2.1.6" xref="S3.E5.m1.2.2.1.6.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.2.2.1.2c" xref="S3.E5.m1.2.2.1.2.cmml">​</mo><mi id="S3.E5.m1.2.2.1.7" xref="S3.E5.m1.2.2.1.7.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.2.2.1.2d" xref="S3.E5.m1.2.2.1.2.cmml">​</mo><mi id="S3.E5.m1.2.2.1.8" xref="S3.E5.m1.2.2.1.8.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.2.2.1.2e" xref="S3.E5.m1.2.2.1.2.cmml">​</mo><mi id="S3.E5.m1.2.2.1.9" xref="S3.E5.m1.2.2.1.9.cmml">x</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.2.2.1.2f" xref="S3.E5.m1.2.2.1.2.cmml">​</mo><mrow id="S3.E5.m1.2.2.1.1.1" xref="S3.E5.m1.2.2.1.1.1.1.cmml"><mo stretchy="false" id="S3.E5.m1.2.2.1.1.1.2" xref="S3.E5.m1.2.2.1.1.1.1.cmml">(</mo><mrow id="S3.E5.m1.2.2.1.1.1.1" xref="S3.E5.m1.2.2.1.1.1.1.cmml"><msup id="S3.E5.m1.2.2.1.1.1.1.2" xref="S3.E5.m1.2.2.1.1.1.1.2.cmml"><mi id="S3.E5.m1.2.2.1.1.1.1.2.2" xref="S3.E5.m1.2.2.1.1.1.1.2.2.cmml">Q</mi><mi id="S3.E5.m1.2.2.1.1.1.1.2.3" xref="S3.E5.m1.2.2.1.1.1.1.2.3.cmml">T</mi></msup><mo lspace="0em" rspace="0em" id="S3.E5.m1.2.2.1.1.1.1.1" xref="S3.E5.m1.2.2.1.1.1.1.1.cmml">​</mo><mi id="S3.E5.m1.2.2.1.1.1.1.3" xref="S3.E5.m1.2.2.1.1.1.1.3.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.2.2.1.1.1.1.1a" xref="S3.E5.m1.2.2.1.1.1.1.1.cmml">​</mo><mi id="S3.E5.m1.2.2.1.1.1.1.4" xref="S3.E5.m1.2.2.1.1.1.1.4.cmml">L</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.2.2.1.1.1.1.1b" xref="S3.E5.m1.2.2.1.1.1.1.1.cmml">​</mo><mi id="S3.E5.m1.2.2.1.1.1.1.5" xref="S3.E5.m1.2.2.1.1.1.1.5.cmml">P</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.2.2.1.1.1.1.1c" xref="S3.E5.m1.2.2.1.1.1.1.1.cmml">​</mo><mrow id="S3.E5.m1.2.2.1.1.1.1.6.2" xref="S3.E5.m1.2.2.1.1.1.1.cmml"><mo stretchy="false" id="S3.E5.m1.2.2.1.1.1.1.6.2.1" xref="S3.E5.m1.2.2.1.1.1.1.cmml">(</mo><mi id="S3.E5.m1.1.1" xref="S3.E5.m1.1.1.cmml">v</mi><mo stretchy="false" id="S3.E5.m1.2.2.1.1.1.1.6.2.2" xref="S3.E5.m1.2.2.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.E5.m1.2.2.1.1.1.3" xref="S3.E5.m1.2.2.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E5.m1.2b"><apply id="S3.E5.m1.2.2.cmml" xref="S3.E5.m1.2.2"><eq id="S3.E5.m1.2.2.2.cmml" xref="S3.E5.m1.2.2.2"></eq><apply id="S3.E5.m1.2.2.3.cmml" xref="S3.E5.m1.2.2.3"><csymbol cd="ambiguous" id="S3.E5.m1.2.2.3.1.cmml" xref="S3.E5.m1.2.2.3">subscript</csymbol><ci id="S3.E5.m1.2.2.3.2.cmml" xref="S3.E5.m1.2.2.3.2">𝑎</ci><ci id="S3.E5.m1.2.2.3.3.cmml" xref="S3.E5.m1.2.2.3.3">𝑚</ci></apply><apply id="S3.E5.m1.2.2.1.cmml" xref="S3.E5.m1.2.2.1"><times id="S3.E5.m1.2.2.1.2.cmml" xref="S3.E5.m1.2.2.1.2"></times><ci id="S3.E5.m1.2.2.1.3.cmml" xref="S3.E5.m1.2.2.1.3">𝑠</ci><ci id="S3.E5.m1.2.2.1.4.cmml" xref="S3.E5.m1.2.2.1.4">𝑜</ci><ci id="S3.E5.m1.2.2.1.5.cmml" xref="S3.E5.m1.2.2.1.5">𝑓</ci><ci id="S3.E5.m1.2.2.1.6.cmml" xref="S3.E5.m1.2.2.1.6">𝑡</ci><ci id="S3.E5.m1.2.2.1.7.cmml" xref="S3.E5.m1.2.2.1.7">𝑚</ci><ci id="S3.E5.m1.2.2.1.8.cmml" xref="S3.E5.m1.2.2.1.8">𝑎</ci><ci id="S3.E5.m1.2.2.1.9.cmml" xref="S3.E5.m1.2.2.1.9">𝑥</ci><apply id="S3.E5.m1.2.2.1.1.1.1.cmml" xref="S3.E5.m1.2.2.1.1.1"><times id="S3.E5.m1.2.2.1.1.1.1.1.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1"></times><apply id="S3.E5.m1.2.2.1.1.1.1.2.cmml" xref="S3.E5.m1.2.2.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E5.m1.2.2.1.1.1.1.2.1.cmml" xref="S3.E5.m1.2.2.1.1.1.1.2">superscript</csymbol><ci id="S3.E5.m1.2.2.1.1.1.1.2.2.cmml" xref="S3.E5.m1.2.2.1.1.1.1.2.2">𝑄</ci><ci id="S3.E5.m1.2.2.1.1.1.1.2.3.cmml" xref="S3.E5.m1.2.2.1.1.1.1.2.3">𝑇</ci></apply><ci id="S3.E5.m1.2.2.1.1.1.1.3.cmml" xref="S3.E5.m1.2.2.1.1.1.1.3">𝑀</ci><ci id="S3.E5.m1.2.2.1.1.1.1.4.cmml" xref="S3.E5.m1.2.2.1.1.1.1.4">𝐿</ci><ci id="S3.E5.m1.2.2.1.1.1.1.5.cmml" xref="S3.E5.m1.2.2.1.1.1.1.5">𝑃</ci><ci id="S3.E5.m1.1.1.cmml" xref="S3.E5.m1.1.1">𝑣</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E5.m1.2c">a_{m}=softmax(Q^{T}MLP(v))</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
<p id="S3.SS2.SSS2.p2.6" class="ltx_p">where <math id="S3.SS2.SSS2.p2.1.m1.1" class="ltx_math_unparsed" alttext="MLP(.)" display="inline"><semantics id="S3.SS2.SSS2.p2.1.m1.1a"><mrow id="S3.SS2.SSS2.p2.1.m1.1b"><mi id="S3.SS2.SSS2.p2.1.m1.1.1">M</mi><mi id="S3.SS2.SSS2.p2.1.m1.1.2">L</mi><mi id="S3.SS2.SSS2.p2.1.m1.1.3">P</mi><mrow id="S3.SS2.SSS2.p2.1.m1.1.4"><mo stretchy="false" id="S3.SS2.SSS2.p2.1.m1.1.4.1">(</mo><mo lspace="0em" rspace="0.167em" id="S3.SS2.SSS2.p2.1.m1.1.4.2">.</mo><mo stretchy="false" id="S3.SS2.SSS2.p2.1.m1.1.4.3">)</mo></mrow></mrow><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p2.1.m1.1c">MLP(.)</annotation></semantics></math> is a multi-layer perceptron used to align the dimension between <math id="S3.SS2.SSS2.p2.2.m2.1" class="ltx_Math" alttext="Q" display="inline"><semantics id="S3.SS2.SSS2.p2.2.m2.1a"><mi id="S3.SS2.SSS2.p2.2.m2.1.1" xref="S3.SS2.SSS2.p2.2.m2.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p2.2.m2.1b"><ci id="S3.SS2.SSS2.p2.2.m2.1.1.cmml" xref="S3.SS2.SSS2.p2.2.m2.1.1">𝑄</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p2.2.m2.1c">Q</annotation></semantics></math> and <math id="S3.SS2.SSS2.p2.3.m3.1" class="ltx_Math" alttext="v" display="inline"><semantics id="S3.SS2.SSS2.p2.3.m3.1a"><mi id="S3.SS2.SSS2.p2.3.m3.1.1" xref="S3.SS2.SSS2.p2.3.m3.1.1.cmml">v</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p2.3.m3.1b"><ci id="S3.SS2.SSS2.p2.3.m3.1.1.cmml" xref="S3.SS2.SSS2.p2.3.m3.1.1">𝑣</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p2.3.m3.1c">v</annotation></semantics></math>. Eq. (<a href="#S3.E5" title="In 3.2.2 I2Q attention mechanism ‣ 3.2 Multi-View Attention ‣ 3 MuVAM for Medical VQA ‣ MuVAM: A Multi-View Attention-based Model for Medical Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>) can be used to obtain the weight distribution <math id="S3.SS2.SSS2.p2.4.m4.1" class="ltx_Math" alttext="a_{m}\in R^{n*1}" display="inline"><semantics id="S3.SS2.SSS2.p2.4.m4.1a"><mrow id="S3.SS2.SSS2.p2.4.m4.1.1" xref="S3.SS2.SSS2.p2.4.m4.1.1.cmml"><msub id="S3.SS2.SSS2.p2.4.m4.1.1.2" xref="S3.SS2.SSS2.p2.4.m4.1.1.2.cmml"><mi id="S3.SS2.SSS2.p2.4.m4.1.1.2.2" xref="S3.SS2.SSS2.p2.4.m4.1.1.2.2.cmml">a</mi><mi id="S3.SS2.SSS2.p2.4.m4.1.1.2.3" xref="S3.SS2.SSS2.p2.4.m4.1.1.2.3.cmml">m</mi></msub><mo id="S3.SS2.SSS2.p2.4.m4.1.1.1" xref="S3.SS2.SSS2.p2.4.m4.1.1.1.cmml">∈</mo><msup id="S3.SS2.SSS2.p2.4.m4.1.1.3" xref="S3.SS2.SSS2.p2.4.m4.1.1.3.cmml"><mi id="S3.SS2.SSS2.p2.4.m4.1.1.3.2" xref="S3.SS2.SSS2.p2.4.m4.1.1.3.2.cmml">R</mi><mrow id="S3.SS2.SSS2.p2.4.m4.1.1.3.3" xref="S3.SS2.SSS2.p2.4.m4.1.1.3.3.cmml"><mi id="S3.SS2.SSS2.p2.4.m4.1.1.3.3.2" xref="S3.SS2.SSS2.p2.4.m4.1.1.3.3.2.cmml">n</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.SSS2.p2.4.m4.1.1.3.3.1" xref="S3.SS2.SSS2.p2.4.m4.1.1.3.3.1.cmml">∗</mo><mn id="S3.SS2.SSS2.p2.4.m4.1.1.3.3.3" xref="S3.SS2.SSS2.p2.4.m4.1.1.3.3.3.cmml">1</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p2.4.m4.1b"><apply id="S3.SS2.SSS2.p2.4.m4.1.1.cmml" xref="S3.SS2.SSS2.p2.4.m4.1.1"><in id="S3.SS2.SSS2.p2.4.m4.1.1.1.cmml" xref="S3.SS2.SSS2.p2.4.m4.1.1.1"></in><apply id="S3.SS2.SSS2.p2.4.m4.1.1.2.cmml" xref="S3.SS2.SSS2.p2.4.m4.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p2.4.m4.1.1.2.1.cmml" xref="S3.SS2.SSS2.p2.4.m4.1.1.2">subscript</csymbol><ci id="S3.SS2.SSS2.p2.4.m4.1.1.2.2.cmml" xref="S3.SS2.SSS2.p2.4.m4.1.1.2.2">𝑎</ci><ci id="S3.SS2.SSS2.p2.4.m4.1.1.2.3.cmml" xref="S3.SS2.SSS2.p2.4.m4.1.1.2.3">𝑚</ci></apply><apply id="S3.SS2.SSS2.p2.4.m4.1.1.3.cmml" xref="S3.SS2.SSS2.p2.4.m4.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p2.4.m4.1.1.3.1.cmml" xref="S3.SS2.SSS2.p2.4.m4.1.1.3">superscript</csymbol><ci id="S3.SS2.SSS2.p2.4.m4.1.1.3.2.cmml" xref="S3.SS2.SSS2.p2.4.m4.1.1.3.2">𝑅</ci><apply id="S3.SS2.SSS2.p2.4.m4.1.1.3.3.cmml" xref="S3.SS2.SSS2.p2.4.m4.1.1.3.3"><times id="S3.SS2.SSS2.p2.4.m4.1.1.3.3.1.cmml" xref="S3.SS2.SSS2.p2.4.m4.1.1.3.3.1"></times><ci id="S3.SS2.SSS2.p2.4.m4.1.1.3.3.2.cmml" xref="S3.SS2.SSS2.p2.4.m4.1.1.3.3.2">𝑛</ci><cn type="integer" id="S3.SS2.SSS2.p2.4.m4.1.1.3.3.3.cmml" xref="S3.SS2.SSS2.p2.4.m4.1.1.3.3.3">1</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p2.4.m4.1c">a_{m}\in R^{n*1}</annotation></semantics></math> of the <math id="S3.SS2.SSS2.p2.5.m5.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S3.SS2.SSS2.p2.5.m5.1a"><mi id="S3.SS2.SSS2.p2.5.m5.1.1" xref="S3.SS2.SSS2.p2.5.m5.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p2.5.m5.1b"><ci id="S3.SS2.SSS2.p2.5.m5.1.1.cmml" xref="S3.SS2.SSS2.p2.5.m5.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p2.5.m5.1c">n</annotation></semantics></math> keywords assigned to the question by the image in the question-answer pair. Each element in <math id="S3.SS2.SSS2.p2.6.m6.1" class="ltx_Math" alttext="a_{m}" display="inline"><semantics id="S3.SS2.SSS2.p2.6.m6.1a"><msub id="S3.SS2.SSS2.p2.6.m6.1.1" xref="S3.SS2.SSS2.p2.6.m6.1.1.cmml"><mi id="S3.SS2.SSS2.p2.6.m6.1.1.2" xref="S3.SS2.SSS2.p2.6.m6.1.1.2.cmml">a</mi><mi id="S3.SS2.SSS2.p2.6.m6.1.1.3" xref="S3.SS2.SSS2.p2.6.m6.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p2.6.m6.1b"><apply id="S3.SS2.SSS2.p2.6.m6.1.1.cmml" xref="S3.SS2.SSS2.p2.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p2.6.m6.1.1.1.cmml" xref="S3.SS2.SSS2.p2.6.m6.1.1">subscript</csymbol><ci id="S3.SS2.SSS2.p2.6.m6.1.1.2.cmml" xref="S3.SS2.SSS2.p2.6.m6.1.1.2">𝑎</ci><ci id="S3.SS2.SSS2.p2.6.m6.1.1.3.cmml" xref="S3.SS2.SSS2.p2.6.m6.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p2.6.m6.1c">a_{m}</annotation></semantics></math> corresponds to the degree of correlation between the keyword and the image. The larger the value of the element, the higher the correlation.</p>
</div>
<div id="S3.SS2.SSS2.p3" class="ltx_para">
<p id="S3.SS2.SSS2.p3.3" class="ltx_p">After generating the attention weight matrix <math id="S3.SS2.SSS2.p3.1.m1.1" class="ltx_Math" alttext="a_{m}" display="inline"><semantics id="S3.SS2.SSS2.p3.1.m1.1a"><msub id="S3.SS2.SSS2.p3.1.m1.1.1" xref="S3.SS2.SSS2.p3.1.m1.1.1.cmml"><mi id="S3.SS2.SSS2.p3.1.m1.1.1.2" xref="S3.SS2.SSS2.p3.1.m1.1.1.2.cmml">a</mi><mi id="S3.SS2.SSS2.p3.1.m1.1.1.3" xref="S3.SS2.SSS2.p3.1.m1.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p3.1.m1.1b"><apply id="S3.SS2.SSS2.p3.1.m1.1.1.cmml" xref="S3.SS2.SSS2.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p3.1.m1.1.1.1.cmml" xref="S3.SS2.SSS2.p3.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.SSS2.p3.1.m1.1.1.2.cmml" xref="S3.SS2.SSS2.p3.1.m1.1.1.2">𝑎</ci><ci id="S3.SS2.SSS2.p3.1.m1.1.1.3.cmml" xref="S3.SS2.SSS2.p3.1.m1.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p3.1.m1.1c">a_{m}</annotation></semantics></math> of the text guided by the vision, the result of Eq. (<a href="#S3.E5" title="In 3.2.2 I2Q attention mechanism ‣ 3.2 Multi-View Attention ‣ 3 MuVAM for Medical VQA ‣ MuVAM: A Multi-View Attention-based Model for Medical Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>) is applied to the question embedding <math id="S3.SS2.SSS2.p3.2.m2.1" class="ltx_Math" alttext="Q" display="inline"><semantics id="S3.SS2.SSS2.p3.2.m2.1a"><mi id="S3.SS2.SSS2.p3.2.m2.1.1" xref="S3.SS2.SSS2.p3.2.m2.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p3.2.m2.1b"><ci id="S3.SS2.SSS2.p3.2.m2.1.1.cmml" xref="S3.SS2.SSS2.p3.2.m2.1.1">𝑄</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p3.2.m2.1c">Q</annotation></semantics></math> of feature extraction. Finally, the module obtains the question embedding <math id="S3.SS2.SSS2.p3.3.m3.1" class="ltx_Math" alttext="Q_{m}" display="inline"><semantics id="S3.SS2.SSS2.p3.3.m3.1a"><msub id="S3.SS2.SSS2.p3.3.m3.1.1" xref="S3.SS2.SSS2.p3.3.m3.1.1.cmml"><mi id="S3.SS2.SSS2.p3.3.m3.1.1.2" xref="S3.SS2.SSS2.p3.3.m3.1.1.2.cmml">Q</mi><mi id="S3.SS2.SSS2.p3.3.m3.1.1.3" xref="S3.SS2.SSS2.p3.3.m3.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p3.3.m3.1b"><apply id="S3.SS2.SSS2.p3.3.m3.1.1.cmml" xref="S3.SS2.SSS2.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p3.3.m3.1.1.1.cmml" xref="S3.SS2.SSS2.p3.3.m3.1.1">subscript</csymbol><ci id="S3.SS2.SSS2.p3.3.m3.1.1.2.cmml" xref="S3.SS2.SSS2.p3.3.m3.1.1.2">𝑄</ci><ci id="S3.SS2.SSS2.p3.3.m3.1.1.3.cmml" xref="S3.SS2.SSS2.p3.3.m3.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p3.3.m3.1c">Q_{m}</annotation></semantics></math> with the image features fused. At this time, the question embedding not only includes the relevant features of the semantic mono-modality of the text, but also adds the image features. The features of these two modalities are combined through the I2Q attention. The combined features give full play to their respective advantages to achieve the purpose of accurately judging the fine-grained relationship between text and vision. According to the degree of relevance of each keyword to the image, different weights are assigned to each word in the question. The feature of the question affected by the vision can be obtained as shown in the following:</p>
</div>
<div id="S3.SS2.SSS2.p4" class="ltx_para">
<table id="S3.E6" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E6.m1.1" class="ltx_Math" alttext="{Q_{m}}={a_{m}}^{T}\odot Q" display="block"><semantics id="S3.E6.m1.1a"><mrow id="S3.E6.m1.1.1" xref="S3.E6.m1.1.1.cmml"><msub id="S3.E6.m1.1.1.2" xref="S3.E6.m1.1.1.2.cmml"><mi id="S3.E6.m1.1.1.2.2" xref="S3.E6.m1.1.1.2.2.cmml">Q</mi><mi id="S3.E6.m1.1.1.2.3" xref="S3.E6.m1.1.1.2.3.cmml">m</mi></msub><mo id="S3.E6.m1.1.1.1" xref="S3.E6.m1.1.1.1.cmml">=</mo><mrow id="S3.E6.m1.1.1.3" xref="S3.E6.m1.1.1.3.cmml"><mmultiscripts id="S3.E6.m1.1.1.3.2" xref="S3.E6.m1.1.1.3.2.cmml"><mi id="S3.E6.m1.1.1.3.2.2.2" xref="S3.E6.m1.1.1.3.2.2.2.cmml">a</mi><mi id="S3.E6.m1.1.1.3.2.2.3" xref="S3.E6.m1.1.1.3.2.2.3.cmml">m</mi><mrow id="S3.E6.m1.1.1.3.2a" xref="S3.E6.m1.1.1.3.2.cmml"></mrow><mrow id="S3.E6.m1.1.1.3.2b" xref="S3.E6.m1.1.1.3.2.cmml"></mrow><mi id="S3.E6.m1.1.1.3.2.3" xref="S3.E6.m1.1.1.3.2.3.cmml">T</mi></mmultiscripts><mo lspace="0.222em" rspace="0.222em" id="S3.E6.m1.1.1.3.1" xref="S3.E6.m1.1.1.3.1.cmml">⊙</mo><mi id="S3.E6.m1.1.1.3.3" xref="S3.E6.m1.1.1.3.3.cmml">Q</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E6.m1.1b"><apply id="S3.E6.m1.1.1.cmml" xref="S3.E6.m1.1.1"><eq id="S3.E6.m1.1.1.1.cmml" xref="S3.E6.m1.1.1.1"></eq><apply id="S3.E6.m1.1.1.2.cmml" xref="S3.E6.m1.1.1.2"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.2.1.cmml" xref="S3.E6.m1.1.1.2">subscript</csymbol><ci id="S3.E6.m1.1.1.2.2.cmml" xref="S3.E6.m1.1.1.2.2">𝑄</ci><ci id="S3.E6.m1.1.1.2.3.cmml" xref="S3.E6.m1.1.1.2.3">𝑚</ci></apply><apply id="S3.E6.m1.1.1.3.cmml" xref="S3.E6.m1.1.1.3"><csymbol cd="latexml" id="S3.E6.m1.1.1.3.1.cmml" xref="S3.E6.m1.1.1.3.1">direct-product</csymbol><apply id="S3.E6.m1.1.1.3.2.cmml" xref="S3.E6.m1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.3.2.1.cmml" xref="S3.E6.m1.1.1.3.2">superscript</csymbol><apply id="S3.E6.m1.1.1.3.2.2.cmml" xref="S3.E6.m1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.3.2.2.1.cmml" xref="S3.E6.m1.1.1.3.2">subscript</csymbol><ci id="S3.E6.m1.1.1.3.2.2.2.cmml" xref="S3.E6.m1.1.1.3.2.2.2">𝑎</ci><ci id="S3.E6.m1.1.1.3.2.2.3.cmml" xref="S3.E6.m1.1.1.3.2.2.3">𝑚</ci></apply><ci id="S3.E6.m1.1.1.3.2.3.cmml" xref="S3.E6.m1.1.1.3.2.3">𝑇</ci></apply><ci id="S3.E6.m1.1.1.3.3.cmml" xref="S3.E6.m1.1.1.3.3">𝑄</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E6.m1.1c">{Q_{m}}={a_{m}}^{T}\odot Q</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
<p id="S3.SS2.SSS2.p4.2" class="ltx_p">where <math id="S3.SS2.SSS2.p4.1.m1.1" class="ltx_Math" alttext="\odot" display="inline"><semantics id="S3.SS2.SSS2.p4.1.m1.1a"><mo id="S3.SS2.SSS2.p4.1.m1.1.1" xref="S3.SS2.SSS2.p4.1.m1.1.1.cmml">⊙</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p4.1.m1.1b"><csymbol cd="latexml" id="S3.SS2.SSS2.p4.1.m1.1.1.cmml" xref="S3.SS2.SSS2.p4.1.m1.1.1">direct-product</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p4.1.m1.1c">\odot</annotation></semantics></math> is the Hadamard product and finally the text feature <math id="S3.SS2.SSS2.p4.2.m2.1" class="ltx_Math" alttext="{Q_{m}}\in R^{d_{s}*n}" display="inline"><semantics id="S3.SS2.SSS2.p4.2.m2.1a"><mrow id="S3.SS2.SSS2.p4.2.m2.1.1" xref="S3.SS2.SSS2.p4.2.m2.1.1.cmml"><msub id="S3.SS2.SSS2.p4.2.m2.1.1.2" xref="S3.SS2.SSS2.p4.2.m2.1.1.2.cmml"><mi id="S3.SS2.SSS2.p4.2.m2.1.1.2.2" xref="S3.SS2.SSS2.p4.2.m2.1.1.2.2.cmml">Q</mi><mi id="S3.SS2.SSS2.p4.2.m2.1.1.2.3" xref="S3.SS2.SSS2.p4.2.m2.1.1.2.3.cmml">m</mi></msub><mo id="S3.SS2.SSS2.p4.2.m2.1.1.1" xref="S3.SS2.SSS2.p4.2.m2.1.1.1.cmml">∈</mo><msup id="S3.SS2.SSS2.p4.2.m2.1.1.3" xref="S3.SS2.SSS2.p4.2.m2.1.1.3.cmml"><mi id="S3.SS2.SSS2.p4.2.m2.1.1.3.2" xref="S3.SS2.SSS2.p4.2.m2.1.1.3.2.cmml">R</mi><mrow id="S3.SS2.SSS2.p4.2.m2.1.1.3.3" xref="S3.SS2.SSS2.p4.2.m2.1.1.3.3.cmml"><msub id="S3.SS2.SSS2.p4.2.m2.1.1.3.3.2" xref="S3.SS2.SSS2.p4.2.m2.1.1.3.3.2.cmml"><mi id="S3.SS2.SSS2.p4.2.m2.1.1.3.3.2.2" xref="S3.SS2.SSS2.p4.2.m2.1.1.3.3.2.2.cmml">d</mi><mi id="S3.SS2.SSS2.p4.2.m2.1.1.3.3.2.3" xref="S3.SS2.SSS2.p4.2.m2.1.1.3.3.2.3.cmml">s</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.SSS2.p4.2.m2.1.1.3.3.1" xref="S3.SS2.SSS2.p4.2.m2.1.1.3.3.1.cmml">∗</mo><mi id="S3.SS2.SSS2.p4.2.m2.1.1.3.3.3" xref="S3.SS2.SSS2.p4.2.m2.1.1.3.3.3.cmml">n</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p4.2.m2.1b"><apply id="S3.SS2.SSS2.p4.2.m2.1.1.cmml" xref="S3.SS2.SSS2.p4.2.m2.1.1"><in id="S3.SS2.SSS2.p4.2.m2.1.1.1.cmml" xref="S3.SS2.SSS2.p4.2.m2.1.1.1"></in><apply id="S3.SS2.SSS2.p4.2.m2.1.1.2.cmml" xref="S3.SS2.SSS2.p4.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p4.2.m2.1.1.2.1.cmml" xref="S3.SS2.SSS2.p4.2.m2.1.1.2">subscript</csymbol><ci id="S3.SS2.SSS2.p4.2.m2.1.1.2.2.cmml" xref="S3.SS2.SSS2.p4.2.m2.1.1.2.2">𝑄</ci><ci id="S3.SS2.SSS2.p4.2.m2.1.1.2.3.cmml" xref="S3.SS2.SSS2.p4.2.m2.1.1.2.3">𝑚</ci></apply><apply id="S3.SS2.SSS2.p4.2.m2.1.1.3.cmml" xref="S3.SS2.SSS2.p4.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p4.2.m2.1.1.3.1.cmml" xref="S3.SS2.SSS2.p4.2.m2.1.1.3">superscript</csymbol><ci id="S3.SS2.SSS2.p4.2.m2.1.1.3.2.cmml" xref="S3.SS2.SSS2.p4.2.m2.1.1.3.2">𝑅</ci><apply id="S3.SS2.SSS2.p4.2.m2.1.1.3.3.cmml" xref="S3.SS2.SSS2.p4.2.m2.1.1.3.3"><times id="S3.SS2.SSS2.p4.2.m2.1.1.3.3.1.cmml" xref="S3.SS2.SSS2.p4.2.m2.1.1.3.3.1"></times><apply id="S3.SS2.SSS2.p4.2.m2.1.1.3.3.2.cmml" xref="S3.SS2.SSS2.p4.2.m2.1.1.3.3.2"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p4.2.m2.1.1.3.3.2.1.cmml" xref="S3.SS2.SSS2.p4.2.m2.1.1.3.3.2">subscript</csymbol><ci id="S3.SS2.SSS2.p4.2.m2.1.1.3.3.2.2.cmml" xref="S3.SS2.SSS2.p4.2.m2.1.1.3.3.2.2">𝑑</ci><ci id="S3.SS2.SSS2.p4.2.m2.1.1.3.3.2.3.cmml" xref="S3.SS2.SSS2.p4.2.m2.1.1.3.3.2.3">𝑠</ci></apply><ci id="S3.SS2.SSS2.p4.2.m2.1.1.3.3.3.cmml" xref="S3.SS2.SSS2.p4.2.m2.1.1.3.3.3">𝑛</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p4.2.m2.1c">{Q_{m}}\in R^{d_{s}*n}</annotation></semantics></math> learned under the guidance of vision is obtained.</p>
</div>
</section>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Composite Loss</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">In the process of model optimization, in order to maximize the accuracy of VQA, we design a composite loss function with the following loss conditions to train the entire model. The loss module contains a total of two parts, namely classification loss and image-question complementary (IQC) loss.</p>
</div>
<section id="S3.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.1 </span>Classification Loss</h4>

<div id="S3.SS3.SSS1.p1" class="ltx_para">
<p id="S3.SS3.SSS1.p1.2" class="ltx_p">After obtaining the text features of the visual guidance, we use the TCR module proposed by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> to divide question-answer pairs into open-end and closed-end based on answer types in order to compare the accuracy of different types of question-answer pairs. The question representation <math id="S3.SS3.SSS1.p1.1.m1.1" class="ltx_Math" alttext="{Q_{m}}" display="inline"><semantics id="S3.SS3.SSS1.p1.1.m1.1a"><msub id="S3.SS3.SSS1.p1.1.m1.1.1" xref="S3.SS3.SSS1.p1.1.m1.1.1.cmml"><mi id="S3.SS3.SSS1.p1.1.m1.1.1.2" xref="S3.SS3.SSS1.p1.1.m1.1.1.2.cmml">Q</mi><mi id="S3.SS3.SSS1.p1.1.m1.1.1.3" xref="S3.SS3.SSS1.p1.1.m1.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p1.1.m1.1b"><apply id="S3.SS3.SSS1.p1.1.m1.1.1.cmml" xref="S3.SS3.SSS1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS1.p1.1.m1.1.1.1.cmml" xref="S3.SS3.SSS1.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.SSS1.p1.1.m1.1.1.2.cmml" xref="S3.SS3.SSS1.p1.1.m1.1.1.2">𝑄</ci><ci id="S3.SS3.SSS1.p1.1.m1.1.1.3.cmml" xref="S3.SS3.SSS1.p1.1.m1.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p1.1.m1.1c">{Q_{m}}</annotation></semantics></math> and the image feature <math id="S3.SS3.SSS1.p1.2.m2.1" class="ltx_Math" alttext="v" display="inline"><semantics id="S3.SS3.SSS1.p1.2.m2.1a"><mi id="S3.SS3.SSS1.p1.2.m2.1.1" xref="S3.SS3.SSS1.p1.2.m2.1.1.cmml">v</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p1.2.m2.1b"><ci id="S3.SS3.SSS1.p1.2.m2.1.1.cmml" xref="S3.SS3.SSS1.p1.2.m2.1.1">𝑣</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p1.2.m2.1c">v</annotation></semantics></math> of the two types are respectively passed into the general multimodal fusion model, and the fused multimodal features are output:</p>
</div>
<div id="S3.SS3.SSS1.p2" class="ltx_para">
<table id="S3.E7" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E7.m1.2" class="ltx_Math" alttext="M^{cl}=\mathcal{F}_{\Theta}(v^{cl},{Q_{m}^{cl}})" display="block"><semantics id="S3.E7.m1.2a"><mrow id="S3.E7.m1.2.2" xref="S3.E7.m1.2.2.cmml"><msup id="S3.E7.m1.2.2.4" xref="S3.E7.m1.2.2.4.cmml"><mi id="S3.E7.m1.2.2.4.2" xref="S3.E7.m1.2.2.4.2.cmml">M</mi><mrow id="S3.E7.m1.2.2.4.3" xref="S3.E7.m1.2.2.4.3.cmml"><mi id="S3.E7.m1.2.2.4.3.2" xref="S3.E7.m1.2.2.4.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.E7.m1.2.2.4.3.1" xref="S3.E7.m1.2.2.4.3.1.cmml">​</mo><mi id="S3.E7.m1.2.2.4.3.3" xref="S3.E7.m1.2.2.4.3.3.cmml">l</mi></mrow></msup><mo id="S3.E7.m1.2.2.3" xref="S3.E7.m1.2.2.3.cmml">=</mo><mrow id="S3.E7.m1.2.2.2" xref="S3.E7.m1.2.2.2.cmml"><msub id="S3.E7.m1.2.2.2.4" xref="S3.E7.m1.2.2.2.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E7.m1.2.2.2.4.2" xref="S3.E7.m1.2.2.2.4.2.cmml">ℱ</mi><mi mathvariant="normal" id="S3.E7.m1.2.2.2.4.3" xref="S3.E7.m1.2.2.2.4.3.cmml">Θ</mi></msub><mo lspace="0em" rspace="0em" id="S3.E7.m1.2.2.2.3" xref="S3.E7.m1.2.2.2.3.cmml">​</mo><mrow id="S3.E7.m1.2.2.2.2.2" xref="S3.E7.m1.2.2.2.2.3.cmml"><mo stretchy="false" id="S3.E7.m1.2.2.2.2.2.3" xref="S3.E7.m1.2.2.2.2.3.cmml">(</mo><msup id="S3.E7.m1.1.1.1.1.1.1" xref="S3.E7.m1.1.1.1.1.1.1.cmml"><mi id="S3.E7.m1.1.1.1.1.1.1.2" xref="S3.E7.m1.1.1.1.1.1.1.2.cmml">v</mi><mrow id="S3.E7.m1.1.1.1.1.1.1.3" xref="S3.E7.m1.1.1.1.1.1.1.3.cmml"><mi id="S3.E7.m1.1.1.1.1.1.1.3.2" xref="S3.E7.m1.1.1.1.1.1.1.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.E7.m1.1.1.1.1.1.1.3.1" xref="S3.E7.m1.1.1.1.1.1.1.3.1.cmml">​</mo><mi id="S3.E7.m1.1.1.1.1.1.1.3.3" xref="S3.E7.m1.1.1.1.1.1.1.3.3.cmml">l</mi></mrow></msup><mo id="S3.E7.m1.2.2.2.2.2.4" xref="S3.E7.m1.2.2.2.2.3.cmml">,</mo><msubsup id="S3.E7.m1.2.2.2.2.2.2" xref="S3.E7.m1.2.2.2.2.2.2.cmml"><mi id="S3.E7.m1.2.2.2.2.2.2.2.2" xref="S3.E7.m1.2.2.2.2.2.2.2.2.cmml">Q</mi><mi id="S3.E7.m1.2.2.2.2.2.2.2.3" xref="S3.E7.m1.2.2.2.2.2.2.2.3.cmml">m</mi><mrow id="S3.E7.m1.2.2.2.2.2.2.3" xref="S3.E7.m1.2.2.2.2.2.2.3.cmml"><mi id="S3.E7.m1.2.2.2.2.2.2.3.2" xref="S3.E7.m1.2.2.2.2.2.2.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.E7.m1.2.2.2.2.2.2.3.1" xref="S3.E7.m1.2.2.2.2.2.2.3.1.cmml">​</mo><mi id="S3.E7.m1.2.2.2.2.2.2.3.3" xref="S3.E7.m1.2.2.2.2.2.2.3.3.cmml">l</mi></mrow></msubsup><mo stretchy="false" id="S3.E7.m1.2.2.2.2.2.5" xref="S3.E7.m1.2.2.2.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E7.m1.2b"><apply id="S3.E7.m1.2.2.cmml" xref="S3.E7.m1.2.2"><eq id="S3.E7.m1.2.2.3.cmml" xref="S3.E7.m1.2.2.3"></eq><apply id="S3.E7.m1.2.2.4.cmml" xref="S3.E7.m1.2.2.4"><csymbol cd="ambiguous" id="S3.E7.m1.2.2.4.1.cmml" xref="S3.E7.m1.2.2.4">superscript</csymbol><ci id="S3.E7.m1.2.2.4.2.cmml" xref="S3.E7.m1.2.2.4.2">𝑀</ci><apply id="S3.E7.m1.2.2.4.3.cmml" xref="S3.E7.m1.2.2.4.3"><times id="S3.E7.m1.2.2.4.3.1.cmml" xref="S3.E7.m1.2.2.4.3.1"></times><ci id="S3.E7.m1.2.2.4.3.2.cmml" xref="S3.E7.m1.2.2.4.3.2">𝑐</ci><ci id="S3.E7.m1.2.2.4.3.3.cmml" xref="S3.E7.m1.2.2.4.3.3">𝑙</ci></apply></apply><apply id="S3.E7.m1.2.2.2.cmml" xref="S3.E7.m1.2.2.2"><times id="S3.E7.m1.2.2.2.3.cmml" xref="S3.E7.m1.2.2.2.3"></times><apply id="S3.E7.m1.2.2.2.4.cmml" xref="S3.E7.m1.2.2.2.4"><csymbol cd="ambiguous" id="S3.E7.m1.2.2.2.4.1.cmml" xref="S3.E7.m1.2.2.2.4">subscript</csymbol><ci id="S3.E7.m1.2.2.2.4.2.cmml" xref="S3.E7.m1.2.2.2.4.2">ℱ</ci><ci id="S3.E7.m1.2.2.2.4.3.cmml" xref="S3.E7.m1.2.2.2.4.3">Θ</ci></apply><interval closure="open" id="S3.E7.m1.2.2.2.2.3.cmml" xref="S3.E7.m1.2.2.2.2.2"><apply id="S3.E7.m1.1.1.1.1.1.1.cmml" xref="S3.E7.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.1.1.1.1.1.cmml" xref="S3.E7.m1.1.1.1.1.1.1">superscript</csymbol><ci id="S3.E7.m1.1.1.1.1.1.1.2.cmml" xref="S3.E7.m1.1.1.1.1.1.1.2">𝑣</ci><apply id="S3.E7.m1.1.1.1.1.1.1.3.cmml" xref="S3.E7.m1.1.1.1.1.1.1.3"><times id="S3.E7.m1.1.1.1.1.1.1.3.1.cmml" xref="S3.E7.m1.1.1.1.1.1.1.3.1"></times><ci id="S3.E7.m1.1.1.1.1.1.1.3.2.cmml" xref="S3.E7.m1.1.1.1.1.1.1.3.2">𝑐</ci><ci id="S3.E7.m1.1.1.1.1.1.1.3.3.cmml" xref="S3.E7.m1.1.1.1.1.1.1.3.3">𝑙</ci></apply></apply><apply id="S3.E7.m1.2.2.2.2.2.2.cmml" xref="S3.E7.m1.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E7.m1.2.2.2.2.2.2.1.cmml" xref="S3.E7.m1.2.2.2.2.2.2">superscript</csymbol><apply id="S3.E7.m1.2.2.2.2.2.2.2.cmml" xref="S3.E7.m1.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E7.m1.2.2.2.2.2.2.2.1.cmml" xref="S3.E7.m1.2.2.2.2.2.2">subscript</csymbol><ci id="S3.E7.m1.2.2.2.2.2.2.2.2.cmml" xref="S3.E7.m1.2.2.2.2.2.2.2.2">𝑄</ci><ci id="S3.E7.m1.2.2.2.2.2.2.2.3.cmml" xref="S3.E7.m1.2.2.2.2.2.2.2.3">𝑚</ci></apply><apply id="S3.E7.m1.2.2.2.2.2.2.3.cmml" xref="S3.E7.m1.2.2.2.2.2.2.3"><times id="S3.E7.m1.2.2.2.2.2.2.3.1.cmml" xref="S3.E7.m1.2.2.2.2.2.2.3.1"></times><ci id="S3.E7.m1.2.2.2.2.2.2.3.2.cmml" xref="S3.E7.m1.2.2.2.2.2.2.3.2">𝑐</ci><ci id="S3.E7.m1.2.2.2.2.2.2.3.3.cmml" xref="S3.E7.m1.2.2.2.2.2.2.3.3">𝑙</ci></apply></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E7.m1.2c">M^{cl}=\mathcal{F}_{\Theta}(v^{cl},{Q_{m}^{cl}})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(7)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS3.SSS1.p3" class="ltx_para">
<table id="S3.E8" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E8.m1.2" class="ltx_Math" alttext="M^{op}=\mathcal{F}_{\Theta}(v^{op},{Q_{m}^{op}})" display="block"><semantics id="S3.E8.m1.2a"><mrow id="S3.E8.m1.2.2" xref="S3.E8.m1.2.2.cmml"><msup id="S3.E8.m1.2.2.4" xref="S3.E8.m1.2.2.4.cmml"><mi id="S3.E8.m1.2.2.4.2" xref="S3.E8.m1.2.2.4.2.cmml">M</mi><mrow id="S3.E8.m1.2.2.4.3" xref="S3.E8.m1.2.2.4.3.cmml"><mi id="S3.E8.m1.2.2.4.3.2" xref="S3.E8.m1.2.2.4.3.2.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E8.m1.2.2.4.3.1" xref="S3.E8.m1.2.2.4.3.1.cmml">​</mo><mi id="S3.E8.m1.2.2.4.3.3" xref="S3.E8.m1.2.2.4.3.3.cmml">p</mi></mrow></msup><mo id="S3.E8.m1.2.2.3" xref="S3.E8.m1.2.2.3.cmml">=</mo><mrow id="S3.E8.m1.2.2.2" xref="S3.E8.m1.2.2.2.cmml"><msub id="S3.E8.m1.2.2.2.4" xref="S3.E8.m1.2.2.2.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E8.m1.2.2.2.4.2" xref="S3.E8.m1.2.2.2.4.2.cmml">ℱ</mi><mi mathvariant="normal" id="S3.E8.m1.2.2.2.4.3" xref="S3.E8.m1.2.2.2.4.3.cmml">Θ</mi></msub><mo lspace="0em" rspace="0em" id="S3.E8.m1.2.2.2.3" xref="S3.E8.m1.2.2.2.3.cmml">​</mo><mrow id="S3.E8.m1.2.2.2.2.2" xref="S3.E8.m1.2.2.2.2.3.cmml"><mo stretchy="false" id="S3.E8.m1.2.2.2.2.2.3" xref="S3.E8.m1.2.2.2.2.3.cmml">(</mo><msup id="S3.E8.m1.1.1.1.1.1.1" xref="S3.E8.m1.1.1.1.1.1.1.cmml"><mi id="S3.E8.m1.1.1.1.1.1.1.2" xref="S3.E8.m1.1.1.1.1.1.1.2.cmml">v</mi><mrow id="S3.E8.m1.1.1.1.1.1.1.3" xref="S3.E8.m1.1.1.1.1.1.1.3.cmml"><mi id="S3.E8.m1.1.1.1.1.1.1.3.2" xref="S3.E8.m1.1.1.1.1.1.1.3.2.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E8.m1.1.1.1.1.1.1.3.1" xref="S3.E8.m1.1.1.1.1.1.1.3.1.cmml">​</mo><mi id="S3.E8.m1.1.1.1.1.1.1.3.3" xref="S3.E8.m1.1.1.1.1.1.1.3.3.cmml">p</mi></mrow></msup><mo id="S3.E8.m1.2.2.2.2.2.4" xref="S3.E8.m1.2.2.2.2.3.cmml">,</mo><msubsup id="S3.E8.m1.2.2.2.2.2.2" xref="S3.E8.m1.2.2.2.2.2.2.cmml"><mi id="S3.E8.m1.2.2.2.2.2.2.2.2" xref="S3.E8.m1.2.2.2.2.2.2.2.2.cmml">Q</mi><mi id="S3.E8.m1.2.2.2.2.2.2.2.3" xref="S3.E8.m1.2.2.2.2.2.2.2.3.cmml">m</mi><mrow id="S3.E8.m1.2.2.2.2.2.2.3" xref="S3.E8.m1.2.2.2.2.2.2.3.cmml"><mi id="S3.E8.m1.2.2.2.2.2.2.3.2" xref="S3.E8.m1.2.2.2.2.2.2.3.2.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E8.m1.2.2.2.2.2.2.3.1" xref="S3.E8.m1.2.2.2.2.2.2.3.1.cmml">​</mo><mi id="S3.E8.m1.2.2.2.2.2.2.3.3" xref="S3.E8.m1.2.2.2.2.2.2.3.3.cmml">p</mi></mrow></msubsup><mo stretchy="false" id="S3.E8.m1.2.2.2.2.2.5" xref="S3.E8.m1.2.2.2.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E8.m1.2b"><apply id="S3.E8.m1.2.2.cmml" xref="S3.E8.m1.2.2"><eq id="S3.E8.m1.2.2.3.cmml" xref="S3.E8.m1.2.2.3"></eq><apply id="S3.E8.m1.2.2.4.cmml" xref="S3.E8.m1.2.2.4"><csymbol cd="ambiguous" id="S3.E8.m1.2.2.4.1.cmml" xref="S3.E8.m1.2.2.4">superscript</csymbol><ci id="S3.E8.m1.2.2.4.2.cmml" xref="S3.E8.m1.2.2.4.2">𝑀</ci><apply id="S3.E8.m1.2.2.4.3.cmml" xref="S3.E8.m1.2.2.4.3"><times id="S3.E8.m1.2.2.4.3.1.cmml" xref="S3.E8.m1.2.2.4.3.1"></times><ci id="S3.E8.m1.2.2.4.3.2.cmml" xref="S3.E8.m1.2.2.4.3.2">𝑜</ci><ci id="S3.E8.m1.2.2.4.3.3.cmml" xref="S3.E8.m1.2.2.4.3.3">𝑝</ci></apply></apply><apply id="S3.E8.m1.2.2.2.cmml" xref="S3.E8.m1.2.2.2"><times id="S3.E8.m1.2.2.2.3.cmml" xref="S3.E8.m1.2.2.2.3"></times><apply id="S3.E8.m1.2.2.2.4.cmml" xref="S3.E8.m1.2.2.2.4"><csymbol cd="ambiguous" id="S3.E8.m1.2.2.2.4.1.cmml" xref="S3.E8.m1.2.2.2.4">subscript</csymbol><ci id="S3.E8.m1.2.2.2.4.2.cmml" xref="S3.E8.m1.2.2.2.4.2">ℱ</ci><ci id="S3.E8.m1.2.2.2.4.3.cmml" xref="S3.E8.m1.2.2.2.4.3">Θ</ci></apply><interval closure="open" id="S3.E8.m1.2.2.2.2.3.cmml" xref="S3.E8.m1.2.2.2.2.2"><apply id="S3.E8.m1.1.1.1.1.1.1.cmml" xref="S3.E8.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E8.m1.1.1.1.1.1.1.1.cmml" xref="S3.E8.m1.1.1.1.1.1.1">superscript</csymbol><ci id="S3.E8.m1.1.1.1.1.1.1.2.cmml" xref="S3.E8.m1.1.1.1.1.1.1.2">𝑣</ci><apply id="S3.E8.m1.1.1.1.1.1.1.3.cmml" xref="S3.E8.m1.1.1.1.1.1.1.3"><times id="S3.E8.m1.1.1.1.1.1.1.3.1.cmml" xref="S3.E8.m1.1.1.1.1.1.1.3.1"></times><ci id="S3.E8.m1.1.1.1.1.1.1.3.2.cmml" xref="S3.E8.m1.1.1.1.1.1.1.3.2">𝑜</ci><ci id="S3.E8.m1.1.1.1.1.1.1.3.3.cmml" xref="S3.E8.m1.1.1.1.1.1.1.3.3">𝑝</ci></apply></apply><apply id="S3.E8.m1.2.2.2.2.2.2.cmml" xref="S3.E8.m1.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E8.m1.2.2.2.2.2.2.1.cmml" xref="S3.E8.m1.2.2.2.2.2.2">superscript</csymbol><apply id="S3.E8.m1.2.2.2.2.2.2.2.cmml" xref="S3.E8.m1.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E8.m1.2.2.2.2.2.2.2.1.cmml" xref="S3.E8.m1.2.2.2.2.2.2">subscript</csymbol><ci id="S3.E8.m1.2.2.2.2.2.2.2.2.cmml" xref="S3.E8.m1.2.2.2.2.2.2.2.2">𝑄</ci><ci id="S3.E8.m1.2.2.2.2.2.2.2.3.cmml" xref="S3.E8.m1.2.2.2.2.2.2.2.3">𝑚</ci></apply><apply id="S3.E8.m1.2.2.2.2.2.2.3.cmml" xref="S3.E8.m1.2.2.2.2.2.2.3"><times id="S3.E8.m1.2.2.2.2.2.2.3.1.cmml" xref="S3.E8.m1.2.2.2.2.2.2.3.1"></times><ci id="S3.E8.m1.2.2.2.2.2.2.3.2.cmml" xref="S3.E8.m1.2.2.2.2.2.2.3.2">𝑜</ci><ci id="S3.E8.m1.2.2.2.2.2.2.3.3.cmml" xref="S3.E8.m1.2.2.2.2.2.2.3.3">𝑝</ci></apply></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E8.m1.2c">M^{op}=\mathcal{F}_{\Theta}(v^{op},{Q_{m}^{op}})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(8)</span></td>
</tr></tbody>
</table>
<p id="S3.SS3.SSS1.p3.4" class="ltx_p">where <math id="S3.SS3.SSS1.p3.1.m1.1" class="ltx_Math" alttext="\mathcal{F}" display="inline"><semantics id="S3.SS3.SSS1.p3.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.SSS1.p3.1.m1.1.1" xref="S3.SS3.SSS1.p3.1.m1.1.1.cmml">ℱ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p3.1.m1.1b"><ci id="S3.SS3.SSS1.p3.1.m1.1.1.cmml" xref="S3.SS3.SSS1.p3.1.m1.1.1">ℱ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p3.1.m1.1c">\mathcal{F}</annotation></semantics></math> is a multi-modal feature fusion representation method. <math id="S3.SS3.SSS1.p3.2.m2.1" class="ltx_Math" alttext="cl" display="inline"><semantics id="S3.SS3.SSS1.p3.2.m2.1a"><mrow id="S3.SS3.SSS1.p3.2.m2.1.1" xref="S3.SS3.SSS1.p3.2.m2.1.1.cmml"><mi id="S3.SS3.SSS1.p3.2.m2.1.1.2" xref="S3.SS3.SSS1.p3.2.m2.1.1.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.SS3.SSS1.p3.2.m2.1.1.1" xref="S3.SS3.SSS1.p3.2.m2.1.1.1.cmml">​</mo><mi id="S3.SS3.SSS1.p3.2.m2.1.1.3" xref="S3.SS3.SSS1.p3.2.m2.1.1.3.cmml">l</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p3.2.m2.1b"><apply id="S3.SS3.SSS1.p3.2.m2.1.1.cmml" xref="S3.SS3.SSS1.p3.2.m2.1.1"><times id="S3.SS3.SSS1.p3.2.m2.1.1.1.cmml" xref="S3.SS3.SSS1.p3.2.m2.1.1.1"></times><ci id="S3.SS3.SSS1.p3.2.m2.1.1.2.cmml" xref="S3.SS3.SSS1.p3.2.m2.1.1.2">𝑐</ci><ci id="S3.SS3.SSS1.p3.2.m2.1.1.3.cmml" xref="S3.SS3.SSS1.p3.2.m2.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p3.2.m2.1c">cl</annotation></semantics></math> and <math id="S3.SS3.SSS1.p3.3.m3.1" class="ltx_Math" alttext="op" display="inline"><semantics id="S3.SS3.SSS1.p3.3.m3.1a"><mrow id="S3.SS3.SSS1.p3.3.m3.1.1" xref="S3.SS3.SSS1.p3.3.m3.1.1.cmml"><mi id="S3.SS3.SSS1.p3.3.m3.1.1.2" xref="S3.SS3.SSS1.p3.3.m3.1.1.2.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS3.SSS1.p3.3.m3.1.1.1" xref="S3.SS3.SSS1.p3.3.m3.1.1.1.cmml">​</mo><mi id="S3.SS3.SSS1.p3.3.m3.1.1.3" xref="S3.SS3.SSS1.p3.3.m3.1.1.3.cmml">p</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p3.3.m3.1b"><apply id="S3.SS3.SSS1.p3.3.m3.1.1.cmml" xref="S3.SS3.SSS1.p3.3.m3.1.1"><times id="S3.SS3.SSS1.p3.3.m3.1.1.1.cmml" xref="S3.SS3.SSS1.p3.3.m3.1.1.1"></times><ci id="S3.SS3.SSS1.p3.3.m3.1.1.2.cmml" xref="S3.SS3.SSS1.p3.3.m3.1.1.2">𝑜</ci><ci id="S3.SS3.SSS1.p3.3.m3.1.1.3.cmml" xref="S3.SS3.SSS1.p3.3.m3.1.1.3">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p3.3.m3.1c">op</annotation></semantics></math> stand for closed-ended and open-ended respectively. In this paper, bilinear attention network (BAN) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite> is used to learn joint representation, and <math id="S3.SS3.SSS1.p3.4.m4.1" class="ltx_Math" alttext="\Theta" display="inline"><semantics id="S3.SS3.SSS1.p3.4.m4.1a"><mi mathvariant="normal" id="S3.SS3.SSS1.p3.4.m4.1.1" xref="S3.SS3.SSS1.p3.4.m4.1.1.cmml">Θ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p3.4.m4.1b"><ci id="S3.SS3.SSS1.p3.4.m4.1.1.cmml" xref="S3.SS3.SSS1.p3.4.m4.1.1">Θ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p3.4.m4.1c">\Theta</annotation></semantics></math> is a trainable parameter in the fusion process.</p>
</div>
<div id="S3.SS3.SSS1.p4" class="ltx_para">
<p id="S3.SS3.SSS1.p4.5" class="ltx_p">The multi-modal features <math id="S3.SS3.SSS1.p4.1.m1.1" class="ltx_Math" alttext="M^{cl}" display="inline"><semantics id="S3.SS3.SSS1.p4.1.m1.1a"><msup id="S3.SS3.SSS1.p4.1.m1.1.1" xref="S3.SS3.SSS1.p4.1.m1.1.1.cmml"><mi id="S3.SS3.SSS1.p4.1.m1.1.1.2" xref="S3.SS3.SSS1.p4.1.m1.1.1.2.cmml">M</mi><mrow id="S3.SS3.SSS1.p4.1.m1.1.1.3" xref="S3.SS3.SSS1.p4.1.m1.1.1.3.cmml"><mi id="S3.SS3.SSS1.p4.1.m1.1.1.3.2" xref="S3.SS3.SSS1.p4.1.m1.1.1.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.SS3.SSS1.p4.1.m1.1.1.3.1" xref="S3.SS3.SSS1.p4.1.m1.1.1.3.1.cmml">​</mo><mi id="S3.SS3.SSS1.p4.1.m1.1.1.3.3" xref="S3.SS3.SSS1.p4.1.m1.1.1.3.3.cmml">l</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p4.1.m1.1b"><apply id="S3.SS3.SSS1.p4.1.m1.1.1.cmml" xref="S3.SS3.SSS1.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS1.p4.1.m1.1.1.1.cmml" xref="S3.SS3.SSS1.p4.1.m1.1.1">superscript</csymbol><ci id="S3.SS3.SSS1.p4.1.m1.1.1.2.cmml" xref="S3.SS3.SSS1.p4.1.m1.1.1.2">𝑀</ci><apply id="S3.SS3.SSS1.p4.1.m1.1.1.3.cmml" xref="S3.SS3.SSS1.p4.1.m1.1.1.3"><times id="S3.SS3.SSS1.p4.1.m1.1.1.3.1.cmml" xref="S3.SS3.SSS1.p4.1.m1.1.1.3.1"></times><ci id="S3.SS3.SSS1.p4.1.m1.1.1.3.2.cmml" xref="S3.SS3.SSS1.p4.1.m1.1.1.3.2">𝑐</ci><ci id="S3.SS3.SSS1.p4.1.m1.1.1.3.3.cmml" xref="S3.SS3.SSS1.p4.1.m1.1.1.3.3">𝑙</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p4.1.m1.1c">M^{cl}</annotation></semantics></math> and <math id="S3.SS3.SSS1.p4.2.m2.1" class="ltx_Math" alttext="M^{op}" display="inline"><semantics id="S3.SS3.SSS1.p4.2.m2.1a"><msup id="S3.SS3.SSS1.p4.2.m2.1.1" xref="S3.SS3.SSS1.p4.2.m2.1.1.cmml"><mi id="S3.SS3.SSS1.p4.2.m2.1.1.2" xref="S3.SS3.SSS1.p4.2.m2.1.1.2.cmml">M</mi><mrow id="S3.SS3.SSS1.p4.2.m2.1.1.3" xref="S3.SS3.SSS1.p4.2.m2.1.1.3.cmml"><mi id="S3.SS3.SSS1.p4.2.m2.1.1.3.2" xref="S3.SS3.SSS1.p4.2.m2.1.1.3.2.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS3.SSS1.p4.2.m2.1.1.3.1" xref="S3.SS3.SSS1.p4.2.m2.1.1.3.1.cmml">​</mo><mi id="S3.SS3.SSS1.p4.2.m2.1.1.3.3" xref="S3.SS3.SSS1.p4.2.m2.1.1.3.3.cmml">p</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p4.2.m2.1b"><apply id="S3.SS3.SSS1.p4.2.m2.1.1.cmml" xref="S3.SS3.SSS1.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS1.p4.2.m2.1.1.1.cmml" xref="S3.SS3.SSS1.p4.2.m2.1.1">superscript</csymbol><ci id="S3.SS3.SSS1.p4.2.m2.1.1.2.cmml" xref="S3.SS3.SSS1.p4.2.m2.1.1.2">𝑀</ci><apply id="S3.SS3.SSS1.p4.2.m2.1.1.3.cmml" xref="S3.SS3.SSS1.p4.2.m2.1.1.3"><times id="S3.SS3.SSS1.p4.2.m2.1.1.3.1.cmml" xref="S3.SS3.SSS1.p4.2.m2.1.1.3.1"></times><ci id="S3.SS3.SSS1.p4.2.m2.1.1.3.2.cmml" xref="S3.SS3.SSS1.p4.2.m2.1.1.3.2">𝑜</ci><ci id="S3.SS3.SSS1.p4.2.m2.1.1.3.3.cmml" xref="S3.SS3.SSS1.p4.2.m2.1.1.3.3">𝑝</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p4.2.m2.1c">M^{op}</annotation></semantics></math> are respectively passed to the classifier to predict the best answer. The classifier is composed of two-layer MLP to obtain the probabilities of candidate answers. The answers with the maximum probability in all candidate answers are selected as the final prediction <math id="S3.SS3.SSS1.p4.3.m3.1" class="ltx_Math" alttext="\hat{y^{cl}}" display="inline"><semantics id="S3.SS3.SSS1.p4.3.m3.1a"><mover accent="true" id="S3.SS3.SSS1.p4.3.m3.1.1" xref="S3.SS3.SSS1.p4.3.m3.1.1.cmml"><msup id="S3.SS3.SSS1.p4.3.m3.1.1.2" xref="S3.SS3.SSS1.p4.3.m3.1.1.2.cmml"><mi id="S3.SS3.SSS1.p4.3.m3.1.1.2.2" xref="S3.SS3.SSS1.p4.3.m3.1.1.2.2.cmml">y</mi><mrow id="S3.SS3.SSS1.p4.3.m3.1.1.2.3" xref="S3.SS3.SSS1.p4.3.m3.1.1.2.3.cmml"><mi id="S3.SS3.SSS1.p4.3.m3.1.1.2.3.2" xref="S3.SS3.SSS1.p4.3.m3.1.1.2.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.SS3.SSS1.p4.3.m3.1.1.2.3.1" xref="S3.SS3.SSS1.p4.3.m3.1.1.2.3.1.cmml">​</mo><mi id="S3.SS3.SSS1.p4.3.m3.1.1.2.3.3" xref="S3.SS3.SSS1.p4.3.m3.1.1.2.3.3.cmml">l</mi></mrow></msup><mo id="S3.SS3.SSS1.p4.3.m3.1.1.1" xref="S3.SS3.SSS1.p4.3.m3.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p4.3.m3.1b"><apply id="S3.SS3.SSS1.p4.3.m3.1.1.cmml" xref="S3.SS3.SSS1.p4.3.m3.1.1"><ci id="S3.SS3.SSS1.p4.3.m3.1.1.1.cmml" xref="S3.SS3.SSS1.p4.3.m3.1.1.1">^</ci><apply id="S3.SS3.SSS1.p4.3.m3.1.1.2.cmml" xref="S3.SS3.SSS1.p4.3.m3.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.SSS1.p4.3.m3.1.1.2.1.cmml" xref="S3.SS3.SSS1.p4.3.m3.1.1.2">superscript</csymbol><ci id="S3.SS3.SSS1.p4.3.m3.1.1.2.2.cmml" xref="S3.SS3.SSS1.p4.3.m3.1.1.2.2">𝑦</ci><apply id="S3.SS3.SSS1.p4.3.m3.1.1.2.3.cmml" xref="S3.SS3.SSS1.p4.3.m3.1.1.2.3"><times id="S3.SS3.SSS1.p4.3.m3.1.1.2.3.1.cmml" xref="S3.SS3.SSS1.p4.3.m3.1.1.2.3.1"></times><ci id="S3.SS3.SSS1.p4.3.m3.1.1.2.3.2.cmml" xref="S3.SS3.SSS1.p4.3.m3.1.1.2.3.2">𝑐</ci><ci id="S3.SS3.SSS1.p4.3.m3.1.1.2.3.3.cmml" xref="S3.SS3.SSS1.p4.3.m3.1.1.2.3.3">𝑙</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p4.3.m3.1c">\hat{y^{cl}}</annotation></semantics></math> and <math id="S3.SS3.SSS1.p4.4.m4.1" class="ltx_Math" alttext="\hat{y^{op}}" display="inline"><semantics id="S3.SS3.SSS1.p4.4.m4.1a"><mover accent="true" id="S3.SS3.SSS1.p4.4.m4.1.1" xref="S3.SS3.SSS1.p4.4.m4.1.1.cmml"><msup id="S3.SS3.SSS1.p4.4.m4.1.1.2" xref="S3.SS3.SSS1.p4.4.m4.1.1.2.cmml"><mi id="S3.SS3.SSS1.p4.4.m4.1.1.2.2" xref="S3.SS3.SSS1.p4.4.m4.1.1.2.2.cmml">y</mi><mrow id="S3.SS3.SSS1.p4.4.m4.1.1.2.3" xref="S3.SS3.SSS1.p4.4.m4.1.1.2.3.cmml"><mi id="S3.SS3.SSS1.p4.4.m4.1.1.2.3.2" xref="S3.SS3.SSS1.p4.4.m4.1.1.2.3.2.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS3.SSS1.p4.4.m4.1.1.2.3.1" xref="S3.SS3.SSS1.p4.4.m4.1.1.2.3.1.cmml">​</mo><mi id="S3.SS3.SSS1.p4.4.m4.1.1.2.3.3" xref="S3.SS3.SSS1.p4.4.m4.1.1.2.3.3.cmml">p</mi></mrow></msup><mo id="S3.SS3.SSS1.p4.4.m4.1.1.1" xref="S3.SS3.SSS1.p4.4.m4.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p4.4.m4.1b"><apply id="S3.SS3.SSS1.p4.4.m4.1.1.cmml" xref="S3.SS3.SSS1.p4.4.m4.1.1"><ci id="S3.SS3.SSS1.p4.4.m4.1.1.1.cmml" xref="S3.SS3.SSS1.p4.4.m4.1.1.1">^</ci><apply id="S3.SS3.SSS1.p4.4.m4.1.1.2.cmml" xref="S3.SS3.SSS1.p4.4.m4.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.SSS1.p4.4.m4.1.1.2.1.cmml" xref="S3.SS3.SSS1.p4.4.m4.1.1.2">superscript</csymbol><ci id="S3.SS3.SSS1.p4.4.m4.1.1.2.2.cmml" xref="S3.SS3.SSS1.p4.4.m4.1.1.2.2">𝑦</ci><apply id="S3.SS3.SSS1.p4.4.m4.1.1.2.3.cmml" xref="S3.SS3.SSS1.p4.4.m4.1.1.2.3"><times id="S3.SS3.SSS1.p4.4.m4.1.1.2.3.1.cmml" xref="S3.SS3.SSS1.p4.4.m4.1.1.2.3.1"></times><ci id="S3.SS3.SSS1.p4.4.m4.1.1.2.3.2.cmml" xref="S3.SS3.SSS1.p4.4.m4.1.1.2.3.2">𝑜</ci><ci id="S3.SS3.SSS1.p4.4.m4.1.1.2.3.3.cmml" xref="S3.SS3.SSS1.p4.4.m4.1.1.2.3.3">𝑝</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p4.4.m4.1c">\hat{y^{op}}</annotation></semantics></math>. In this stage, the binary cross-entropy loss <math id="S3.SS3.SSS1.p4.5.m5.1" class="ltx_Math" alttext="L_{c}" display="inline"><semantics id="S3.SS3.SSS1.p4.5.m5.1a"><msub id="S3.SS3.SSS1.p4.5.m5.1.1" xref="S3.SS3.SSS1.p4.5.m5.1.1.cmml"><mi id="S3.SS3.SSS1.p4.5.m5.1.1.2" xref="S3.SS3.SSS1.p4.5.m5.1.1.2.cmml">L</mi><mi id="S3.SS3.SSS1.p4.5.m5.1.1.3" xref="S3.SS3.SSS1.p4.5.m5.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p4.5.m5.1b"><apply id="S3.SS3.SSS1.p4.5.m5.1.1.cmml" xref="S3.SS3.SSS1.p4.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS1.p4.5.m5.1.1.1.cmml" xref="S3.SS3.SSS1.p4.5.m5.1.1">subscript</csymbol><ci id="S3.SS3.SSS1.p4.5.m5.1.1.2.cmml" xref="S3.SS3.SSS1.p4.5.m5.1.1.2">𝐿</ci><ci id="S3.SS3.SSS1.p4.5.m5.1.1.3.cmml" xref="S3.SS3.SSS1.p4.5.m5.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p4.5.m5.1c">L_{c}</annotation></semantics></math> is used in the training process.</p>
</div>
<div id="S3.SS3.SSS1.p5" class="ltx_para">
<table id="S3.E9" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E9.m1.4" class="ltx_Math" alttext="L_{c}=BCE(\hat{y^{cl}},y^{cl})+BCE(\hat{y^{op}},y^{op})" display="block"><semantics id="S3.E9.m1.4a"><mrow id="S3.E9.m1.4.4" xref="S3.E9.m1.4.4.cmml"><msub id="S3.E9.m1.4.4.4" xref="S3.E9.m1.4.4.4.cmml"><mi id="S3.E9.m1.4.4.4.2" xref="S3.E9.m1.4.4.4.2.cmml">L</mi><mi id="S3.E9.m1.4.4.4.3" xref="S3.E9.m1.4.4.4.3.cmml">c</mi></msub><mo id="S3.E9.m1.4.4.3" xref="S3.E9.m1.4.4.3.cmml">=</mo><mrow id="S3.E9.m1.4.4.2" xref="S3.E9.m1.4.4.2.cmml"><mrow id="S3.E9.m1.3.3.1.1" xref="S3.E9.m1.3.3.1.1.cmml"><mi id="S3.E9.m1.3.3.1.1.3" xref="S3.E9.m1.3.3.1.1.3.cmml">B</mi><mo lspace="0em" rspace="0em" id="S3.E9.m1.3.3.1.1.2" xref="S3.E9.m1.3.3.1.1.2.cmml">​</mo><mi id="S3.E9.m1.3.3.1.1.4" xref="S3.E9.m1.3.3.1.1.4.cmml">C</mi><mo lspace="0em" rspace="0em" id="S3.E9.m1.3.3.1.1.2a" xref="S3.E9.m1.3.3.1.1.2.cmml">​</mo><mi id="S3.E9.m1.3.3.1.1.5" xref="S3.E9.m1.3.3.1.1.5.cmml">E</mi><mo lspace="0em" rspace="0em" id="S3.E9.m1.3.3.1.1.2b" xref="S3.E9.m1.3.3.1.1.2.cmml">​</mo><mrow id="S3.E9.m1.3.3.1.1.1.1" xref="S3.E9.m1.3.3.1.1.1.2.cmml"><mo stretchy="false" id="S3.E9.m1.3.3.1.1.1.1.2" xref="S3.E9.m1.3.3.1.1.1.2.cmml">(</mo><mover accent="true" id="S3.E9.m1.1.1" xref="S3.E9.m1.1.1.cmml"><msup id="S3.E9.m1.1.1.2" xref="S3.E9.m1.1.1.2.cmml"><mi id="S3.E9.m1.1.1.2.2" xref="S3.E9.m1.1.1.2.2.cmml">y</mi><mrow id="S3.E9.m1.1.1.2.3" xref="S3.E9.m1.1.1.2.3.cmml"><mi id="S3.E9.m1.1.1.2.3.2" xref="S3.E9.m1.1.1.2.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.E9.m1.1.1.2.3.1" xref="S3.E9.m1.1.1.2.3.1.cmml">​</mo><mi id="S3.E9.m1.1.1.2.3.3" xref="S3.E9.m1.1.1.2.3.3.cmml">l</mi></mrow></msup><mo id="S3.E9.m1.1.1.1" xref="S3.E9.m1.1.1.1.cmml">^</mo></mover><mo id="S3.E9.m1.3.3.1.1.1.1.3" xref="S3.E9.m1.3.3.1.1.1.2.cmml">,</mo><msup id="S3.E9.m1.3.3.1.1.1.1.1" xref="S3.E9.m1.3.3.1.1.1.1.1.cmml"><mi id="S3.E9.m1.3.3.1.1.1.1.1.2" xref="S3.E9.m1.3.3.1.1.1.1.1.2.cmml">y</mi><mrow id="S3.E9.m1.3.3.1.1.1.1.1.3" xref="S3.E9.m1.3.3.1.1.1.1.1.3.cmml"><mi id="S3.E9.m1.3.3.1.1.1.1.1.3.2" xref="S3.E9.m1.3.3.1.1.1.1.1.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.E9.m1.3.3.1.1.1.1.1.3.1" xref="S3.E9.m1.3.3.1.1.1.1.1.3.1.cmml">​</mo><mi id="S3.E9.m1.3.3.1.1.1.1.1.3.3" xref="S3.E9.m1.3.3.1.1.1.1.1.3.3.cmml">l</mi></mrow></msup><mo stretchy="false" id="S3.E9.m1.3.3.1.1.1.1.4" xref="S3.E9.m1.3.3.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S3.E9.m1.4.4.2.3" xref="S3.E9.m1.4.4.2.3.cmml">+</mo><mrow id="S3.E9.m1.4.4.2.2" xref="S3.E9.m1.4.4.2.2.cmml"><mi id="S3.E9.m1.4.4.2.2.3" xref="S3.E9.m1.4.4.2.2.3.cmml">B</mi><mo lspace="0em" rspace="0em" id="S3.E9.m1.4.4.2.2.2" xref="S3.E9.m1.4.4.2.2.2.cmml">​</mo><mi id="S3.E9.m1.4.4.2.2.4" xref="S3.E9.m1.4.4.2.2.4.cmml">C</mi><mo lspace="0em" rspace="0em" id="S3.E9.m1.4.4.2.2.2a" xref="S3.E9.m1.4.4.2.2.2.cmml">​</mo><mi id="S3.E9.m1.4.4.2.2.5" xref="S3.E9.m1.4.4.2.2.5.cmml">E</mi><mo lspace="0em" rspace="0em" id="S3.E9.m1.4.4.2.2.2b" xref="S3.E9.m1.4.4.2.2.2.cmml">​</mo><mrow id="S3.E9.m1.4.4.2.2.1.1" xref="S3.E9.m1.4.4.2.2.1.2.cmml"><mo stretchy="false" id="S3.E9.m1.4.4.2.2.1.1.2" xref="S3.E9.m1.4.4.2.2.1.2.cmml">(</mo><mover accent="true" id="S3.E9.m1.2.2" xref="S3.E9.m1.2.2.cmml"><msup id="S3.E9.m1.2.2.2" xref="S3.E9.m1.2.2.2.cmml"><mi id="S3.E9.m1.2.2.2.2" xref="S3.E9.m1.2.2.2.2.cmml">y</mi><mrow id="S3.E9.m1.2.2.2.3" xref="S3.E9.m1.2.2.2.3.cmml"><mi id="S3.E9.m1.2.2.2.3.2" xref="S3.E9.m1.2.2.2.3.2.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E9.m1.2.2.2.3.1" xref="S3.E9.m1.2.2.2.3.1.cmml">​</mo><mi id="S3.E9.m1.2.2.2.3.3" xref="S3.E9.m1.2.2.2.3.3.cmml">p</mi></mrow></msup><mo id="S3.E9.m1.2.2.1" xref="S3.E9.m1.2.2.1.cmml">^</mo></mover><mo id="S3.E9.m1.4.4.2.2.1.1.3" xref="S3.E9.m1.4.4.2.2.1.2.cmml">,</mo><msup id="S3.E9.m1.4.4.2.2.1.1.1" xref="S3.E9.m1.4.4.2.2.1.1.1.cmml"><mi id="S3.E9.m1.4.4.2.2.1.1.1.2" xref="S3.E9.m1.4.4.2.2.1.1.1.2.cmml">y</mi><mrow id="S3.E9.m1.4.4.2.2.1.1.1.3" xref="S3.E9.m1.4.4.2.2.1.1.1.3.cmml"><mi id="S3.E9.m1.4.4.2.2.1.1.1.3.2" xref="S3.E9.m1.4.4.2.2.1.1.1.3.2.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E9.m1.4.4.2.2.1.1.1.3.1" xref="S3.E9.m1.4.4.2.2.1.1.1.3.1.cmml">​</mo><mi id="S3.E9.m1.4.4.2.2.1.1.1.3.3" xref="S3.E9.m1.4.4.2.2.1.1.1.3.3.cmml">p</mi></mrow></msup><mo stretchy="false" id="S3.E9.m1.4.4.2.2.1.1.4" xref="S3.E9.m1.4.4.2.2.1.2.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E9.m1.4b"><apply id="S3.E9.m1.4.4.cmml" xref="S3.E9.m1.4.4"><eq id="S3.E9.m1.4.4.3.cmml" xref="S3.E9.m1.4.4.3"></eq><apply id="S3.E9.m1.4.4.4.cmml" xref="S3.E9.m1.4.4.4"><csymbol cd="ambiguous" id="S3.E9.m1.4.4.4.1.cmml" xref="S3.E9.m1.4.4.4">subscript</csymbol><ci id="S3.E9.m1.4.4.4.2.cmml" xref="S3.E9.m1.4.4.4.2">𝐿</ci><ci id="S3.E9.m1.4.4.4.3.cmml" xref="S3.E9.m1.4.4.4.3">𝑐</ci></apply><apply id="S3.E9.m1.4.4.2.cmml" xref="S3.E9.m1.4.4.2"><plus id="S3.E9.m1.4.4.2.3.cmml" xref="S3.E9.m1.4.4.2.3"></plus><apply id="S3.E9.m1.3.3.1.1.cmml" xref="S3.E9.m1.3.3.1.1"><times id="S3.E9.m1.3.3.1.1.2.cmml" xref="S3.E9.m1.3.3.1.1.2"></times><ci id="S3.E9.m1.3.3.1.1.3.cmml" xref="S3.E9.m1.3.3.1.1.3">𝐵</ci><ci id="S3.E9.m1.3.3.1.1.4.cmml" xref="S3.E9.m1.3.3.1.1.4">𝐶</ci><ci id="S3.E9.m1.3.3.1.1.5.cmml" xref="S3.E9.m1.3.3.1.1.5">𝐸</ci><interval closure="open" id="S3.E9.m1.3.3.1.1.1.2.cmml" xref="S3.E9.m1.3.3.1.1.1.1"><apply id="S3.E9.m1.1.1.cmml" xref="S3.E9.m1.1.1"><ci id="S3.E9.m1.1.1.1.cmml" xref="S3.E9.m1.1.1.1">^</ci><apply id="S3.E9.m1.1.1.2.cmml" xref="S3.E9.m1.1.1.2"><csymbol cd="ambiguous" id="S3.E9.m1.1.1.2.1.cmml" xref="S3.E9.m1.1.1.2">superscript</csymbol><ci id="S3.E9.m1.1.1.2.2.cmml" xref="S3.E9.m1.1.1.2.2">𝑦</ci><apply id="S3.E9.m1.1.1.2.3.cmml" xref="S3.E9.m1.1.1.2.3"><times id="S3.E9.m1.1.1.2.3.1.cmml" xref="S3.E9.m1.1.1.2.3.1"></times><ci id="S3.E9.m1.1.1.2.3.2.cmml" xref="S3.E9.m1.1.1.2.3.2">𝑐</ci><ci id="S3.E9.m1.1.1.2.3.3.cmml" xref="S3.E9.m1.1.1.2.3.3">𝑙</ci></apply></apply></apply><apply id="S3.E9.m1.3.3.1.1.1.1.1.cmml" xref="S3.E9.m1.3.3.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E9.m1.3.3.1.1.1.1.1.1.cmml" xref="S3.E9.m1.3.3.1.1.1.1.1">superscript</csymbol><ci id="S3.E9.m1.3.3.1.1.1.1.1.2.cmml" xref="S3.E9.m1.3.3.1.1.1.1.1.2">𝑦</ci><apply id="S3.E9.m1.3.3.1.1.1.1.1.3.cmml" xref="S3.E9.m1.3.3.1.1.1.1.1.3"><times id="S3.E9.m1.3.3.1.1.1.1.1.3.1.cmml" xref="S3.E9.m1.3.3.1.1.1.1.1.3.1"></times><ci id="S3.E9.m1.3.3.1.1.1.1.1.3.2.cmml" xref="S3.E9.m1.3.3.1.1.1.1.1.3.2">𝑐</ci><ci id="S3.E9.m1.3.3.1.1.1.1.1.3.3.cmml" xref="S3.E9.m1.3.3.1.1.1.1.1.3.3">𝑙</ci></apply></apply></interval></apply><apply id="S3.E9.m1.4.4.2.2.cmml" xref="S3.E9.m1.4.4.2.2"><times id="S3.E9.m1.4.4.2.2.2.cmml" xref="S3.E9.m1.4.4.2.2.2"></times><ci id="S3.E9.m1.4.4.2.2.3.cmml" xref="S3.E9.m1.4.4.2.2.3">𝐵</ci><ci id="S3.E9.m1.4.4.2.2.4.cmml" xref="S3.E9.m1.4.4.2.2.4">𝐶</ci><ci id="S3.E9.m1.4.4.2.2.5.cmml" xref="S3.E9.m1.4.4.2.2.5">𝐸</ci><interval closure="open" id="S3.E9.m1.4.4.2.2.1.2.cmml" xref="S3.E9.m1.4.4.2.2.1.1"><apply id="S3.E9.m1.2.2.cmml" xref="S3.E9.m1.2.2"><ci id="S3.E9.m1.2.2.1.cmml" xref="S3.E9.m1.2.2.1">^</ci><apply id="S3.E9.m1.2.2.2.cmml" xref="S3.E9.m1.2.2.2"><csymbol cd="ambiguous" id="S3.E9.m1.2.2.2.1.cmml" xref="S3.E9.m1.2.2.2">superscript</csymbol><ci id="S3.E9.m1.2.2.2.2.cmml" xref="S3.E9.m1.2.2.2.2">𝑦</ci><apply id="S3.E9.m1.2.2.2.3.cmml" xref="S3.E9.m1.2.2.2.3"><times id="S3.E9.m1.2.2.2.3.1.cmml" xref="S3.E9.m1.2.2.2.3.1"></times><ci id="S3.E9.m1.2.2.2.3.2.cmml" xref="S3.E9.m1.2.2.2.3.2">𝑜</ci><ci id="S3.E9.m1.2.2.2.3.3.cmml" xref="S3.E9.m1.2.2.2.3.3">𝑝</ci></apply></apply></apply><apply id="S3.E9.m1.4.4.2.2.1.1.1.cmml" xref="S3.E9.m1.4.4.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.E9.m1.4.4.2.2.1.1.1.1.cmml" xref="S3.E9.m1.4.4.2.2.1.1.1">superscript</csymbol><ci id="S3.E9.m1.4.4.2.2.1.1.1.2.cmml" xref="S3.E9.m1.4.4.2.2.1.1.1.2">𝑦</ci><apply id="S3.E9.m1.4.4.2.2.1.1.1.3.cmml" xref="S3.E9.m1.4.4.2.2.1.1.1.3"><times id="S3.E9.m1.4.4.2.2.1.1.1.3.1.cmml" xref="S3.E9.m1.4.4.2.2.1.1.1.3.1"></times><ci id="S3.E9.m1.4.4.2.2.1.1.1.3.2.cmml" xref="S3.E9.m1.4.4.2.2.1.1.1.3.2">𝑜</ci><ci id="S3.E9.m1.4.4.2.2.1.1.1.3.3.cmml" xref="S3.E9.m1.4.4.2.2.1.1.1.3.3">𝑝</ci></apply></apply></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E9.m1.4c">L_{c}=BCE(\hat{y^{cl}},y^{cl})+BCE(\hat{y^{op}},y^{op})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(9)</span></td>
</tr></tbody>
</table>
<p id="S3.SS3.SSS1.p5.5" class="ltx_p">where <math id="S3.SS3.SSS1.p5.1.m1.1" class="ltx_math_unparsed" alttext="BCE(.)" display="inline"><semantics id="S3.SS3.SSS1.p5.1.m1.1a"><mrow id="S3.SS3.SSS1.p5.1.m1.1b"><mi id="S3.SS3.SSS1.p5.1.m1.1.1">B</mi><mi id="S3.SS3.SSS1.p5.1.m1.1.2">C</mi><mi id="S3.SS3.SSS1.p5.1.m1.1.3">E</mi><mrow id="S3.SS3.SSS1.p5.1.m1.1.4"><mo stretchy="false" id="S3.SS3.SSS1.p5.1.m1.1.4.1">(</mo><mo lspace="0em" rspace="0.167em" id="S3.SS3.SSS1.p5.1.m1.1.4.2">.</mo><mo stretchy="false" id="S3.SS3.SSS1.p5.1.m1.1.4.3">)</mo></mrow></mrow><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p5.1.m1.1c">BCE(.)</annotation></semantics></math> represents the binary cross-entropy loss function, <math id="S3.SS3.SSS1.p5.2.m2.1" class="ltx_Math" alttext="\hat{y}" display="inline"><semantics id="S3.SS3.SSS1.p5.2.m2.1a"><mover accent="true" id="S3.SS3.SSS1.p5.2.m2.1.1" xref="S3.SS3.SSS1.p5.2.m2.1.1.cmml"><mi id="S3.SS3.SSS1.p5.2.m2.1.1.2" xref="S3.SS3.SSS1.p5.2.m2.1.1.2.cmml">y</mi><mo id="S3.SS3.SSS1.p5.2.m2.1.1.1" xref="S3.SS3.SSS1.p5.2.m2.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p5.2.m2.1b"><apply id="S3.SS3.SSS1.p5.2.m2.1.1.cmml" xref="S3.SS3.SSS1.p5.2.m2.1.1"><ci id="S3.SS3.SSS1.p5.2.m2.1.1.1.cmml" xref="S3.SS3.SSS1.p5.2.m2.1.1.1">^</ci><ci id="S3.SS3.SSS1.p5.2.m2.1.1.2.cmml" xref="S3.SS3.SSS1.p5.2.m2.1.1.2">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p5.2.m2.1c">\hat{y}</annotation></semantics></math> is the predicted answer and <math id="S3.SS3.SSS1.p5.3.m3.1" class="ltx_Math" alttext="y" display="inline"><semantics id="S3.SS3.SSS1.p5.3.m3.1a"><mi id="S3.SS3.SSS1.p5.3.m3.1.1" xref="S3.SS3.SSS1.p5.3.m3.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p5.3.m3.1b"><ci id="S3.SS3.SSS1.p5.3.m3.1.1.cmml" xref="S3.SS3.SSS1.p5.3.m3.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p5.3.m3.1c">y</annotation></semantics></math> is the ground-truth answer. <math id="S3.SS3.SSS1.p5.4.m4.1" class="ltx_Math" alttext="cl" display="inline"><semantics id="S3.SS3.SSS1.p5.4.m4.1a"><mrow id="S3.SS3.SSS1.p5.4.m4.1.1" xref="S3.SS3.SSS1.p5.4.m4.1.1.cmml"><mi id="S3.SS3.SSS1.p5.4.m4.1.1.2" xref="S3.SS3.SSS1.p5.4.m4.1.1.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.SS3.SSS1.p5.4.m4.1.1.1" xref="S3.SS3.SSS1.p5.4.m4.1.1.1.cmml">​</mo><mi id="S3.SS3.SSS1.p5.4.m4.1.1.3" xref="S3.SS3.SSS1.p5.4.m4.1.1.3.cmml">l</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p5.4.m4.1b"><apply id="S3.SS3.SSS1.p5.4.m4.1.1.cmml" xref="S3.SS3.SSS1.p5.4.m4.1.1"><times id="S3.SS3.SSS1.p5.4.m4.1.1.1.cmml" xref="S3.SS3.SSS1.p5.4.m4.1.1.1"></times><ci id="S3.SS3.SSS1.p5.4.m4.1.1.2.cmml" xref="S3.SS3.SSS1.p5.4.m4.1.1.2">𝑐</ci><ci id="S3.SS3.SSS1.p5.4.m4.1.1.3.cmml" xref="S3.SS3.SSS1.p5.4.m4.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p5.4.m4.1c">cl</annotation></semantics></math> and <math id="S3.SS3.SSS1.p5.5.m5.1" class="ltx_Math" alttext="op" display="inline"><semantics id="S3.SS3.SSS1.p5.5.m5.1a"><mrow id="S3.SS3.SSS1.p5.5.m5.1.1" xref="S3.SS3.SSS1.p5.5.m5.1.1.cmml"><mi id="S3.SS3.SSS1.p5.5.m5.1.1.2" xref="S3.SS3.SSS1.p5.5.m5.1.1.2.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS3.SSS1.p5.5.m5.1.1.1" xref="S3.SS3.SSS1.p5.5.m5.1.1.1.cmml">​</mo><mi id="S3.SS3.SSS1.p5.5.m5.1.1.3" xref="S3.SS3.SSS1.p5.5.m5.1.1.3.cmml">p</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p5.5.m5.1b"><apply id="S3.SS3.SSS1.p5.5.m5.1.1.cmml" xref="S3.SS3.SSS1.p5.5.m5.1.1"><times id="S3.SS3.SSS1.p5.5.m5.1.1.1.cmml" xref="S3.SS3.SSS1.p5.5.m5.1.1.1"></times><ci id="S3.SS3.SSS1.p5.5.m5.1.1.2.cmml" xref="S3.SS3.SSS1.p5.5.m5.1.1.2">𝑜</ci><ci id="S3.SS3.SSS1.p5.5.m5.1.1.3.cmml" xref="S3.SS3.SSS1.p5.5.m5.1.1.3">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p5.5.m5.1c">op</annotation></semantics></math> stand for closed-ended and open-ended respectively.</p>
</div>
</section>
<section id="S3.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.2 </span>IQC loss</h4>

<div id="S3.SS3.SSS2.p1" class="ltx_para">
<p id="S3.SS3.SSS2.p1.2" class="ltx_p">This part uses the learned weight <math id="S3.SS3.SSS2.p1.1.m1.1" class="ltx_Math" alttext="a_{m}" display="inline"><semantics id="S3.SS3.SSS2.p1.1.m1.1a"><msub id="S3.SS3.SSS2.p1.1.m1.1.1" xref="S3.SS3.SSS2.p1.1.m1.1.1.cmml"><mi id="S3.SS3.SSS2.p1.1.m1.1.1.2" xref="S3.SS3.SSS2.p1.1.m1.1.1.2.cmml">a</mi><mi id="S3.SS3.SSS2.p1.1.m1.1.1.3" xref="S3.SS3.SSS2.p1.1.m1.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p1.1.m1.1b"><apply id="S3.SS3.SSS2.p1.1.m1.1.1.cmml" xref="S3.SS3.SSS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS2.p1.1.m1.1.1.1.cmml" xref="S3.SS3.SSS2.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.SSS2.p1.1.m1.1.1.2.cmml" xref="S3.SS3.SSS2.p1.1.m1.1.1.2">𝑎</ci><ci id="S3.SS3.SSS2.p1.1.m1.1.1.3.cmml" xref="S3.SS3.SSS2.p1.1.m1.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.p1.1.m1.1c">a_{m}</annotation></semantics></math> obtained by the W2T attention and the attention weight <math id="S3.SS3.SSS2.p1.2.m2.1" class="ltx_Math" alttext="a_{q}" display="inline"><semantics id="S3.SS3.SSS2.p1.2.m2.1a"><msub id="S3.SS3.SSS2.p1.2.m2.1.1" xref="S3.SS3.SSS2.p1.2.m2.1.1.cmml"><mi id="S3.SS3.SSS2.p1.2.m2.1.1.2" xref="S3.SS3.SSS2.p1.2.m2.1.1.2.cmml">a</mi><mi id="S3.SS3.SSS2.p1.2.m2.1.1.3" xref="S3.SS3.SSS2.p1.2.m2.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p1.2.m2.1b"><apply id="S3.SS3.SSS2.p1.2.m2.1.1.cmml" xref="S3.SS3.SSS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS2.p1.2.m2.1.1.1.cmml" xref="S3.SS3.SSS2.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS3.SSS2.p1.2.m2.1.1.2.cmml" xref="S3.SS3.SSS2.p1.2.m2.1.1.2">𝑎</ci><ci id="S3.SS3.SSS2.p1.2.m2.1.1.3.cmml" xref="S3.SS3.SSS2.p1.2.m2.1.1.3">𝑞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.p1.2.m2.1c">a_{q}</annotation></semantics></math> generated by the I2Q attention to jointly guide the learning of question importance.</p>
</div>
<div id="S3.SS3.SSS2.p2" class="ltx_para">
<p id="S3.SS3.SSS2.p2.3" class="ltx_p">Generally Multi-modal tasks use the complementarity property between multiple modalities to not only eliminate the redundancy, but also obtain more comprehensive and accurate information to enhance the reliability and fault tolerance of task learning. In the model training process, this paper minimizes the difference between the importances of question learned by words and learned under the guidance of vision in order to improve the similarity between visual-text cross-modal features. This method is to use <math id="S3.SS3.SSS2.p2.1.m1.1" class="ltx_Math" alttext="{a_{m}}" display="inline"><semantics id="S3.SS3.SSS2.p2.1.m1.1a"><msub id="S3.SS3.SSS2.p2.1.m1.1.1" xref="S3.SS3.SSS2.p2.1.m1.1.1.cmml"><mi id="S3.SS3.SSS2.p2.1.m1.1.1.2" xref="S3.SS3.SSS2.p2.1.m1.1.1.2.cmml">a</mi><mi id="S3.SS3.SSS2.p2.1.m1.1.1.3" xref="S3.SS3.SSS2.p2.1.m1.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p2.1.m1.1b"><apply id="S3.SS3.SSS2.p2.1.m1.1.1.cmml" xref="S3.SS3.SSS2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS2.p2.1.m1.1.1.1.cmml" xref="S3.SS3.SSS2.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.SSS2.p2.1.m1.1.1.2.cmml" xref="S3.SS3.SSS2.p2.1.m1.1.1.2">𝑎</ci><ci id="S3.SS3.SSS2.p2.1.m1.1.1.3.cmml" xref="S3.SS3.SSS2.p2.1.m1.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.p2.1.m1.1c">{a_{m}}</annotation></semantics></math> and <math id="S3.SS3.SSS2.p2.2.m2.1" class="ltx_Math" alttext="{a_{q}}" display="inline"><semantics id="S3.SS3.SSS2.p2.2.m2.1a"><msub id="S3.SS3.SSS2.p2.2.m2.1.1" xref="S3.SS3.SSS2.p2.2.m2.1.1.cmml"><mi id="S3.SS3.SSS2.p2.2.m2.1.1.2" xref="S3.SS3.SSS2.p2.2.m2.1.1.2.cmml">a</mi><mi id="S3.SS3.SSS2.p2.2.m2.1.1.3" xref="S3.SS3.SSS2.p2.2.m2.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p2.2.m2.1b"><apply id="S3.SS3.SSS2.p2.2.m2.1.1.cmml" xref="S3.SS3.SSS2.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS2.p2.2.m2.1.1.1.cmml" xref="S3.SS3.SSS2.p2.2.m2.1.1">subscript</csymbol><ci id="S3.SS3.SSS2.p2.2.m2.1.1.2.cmml" xref="S3.SS3.SSS2.p2.2.m2.1.1.2">𝑎</ci><ci id="S3.SS3.SSS2.p2.2.m2.1.1.3.cmml" xref="S3.SS3.SSS2.p2.2.m2.1.1.3">𝑞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.p2.2.m2.1c">{a_{q}}</annotation></semantics></math> to define the image-question complementary loss<math id="S3.SS3.SSS2.p2.3.m3.1" class="ltx_Math" alttext="L_{mq}" display="inline"><semantics id="S3.SS3.SSS2.p2.3.m3.1a"><msub id="S3.SS3.SSS2.p2.3.m3.1.1" xref="S3.SS3.SSS2.p2.3.m3.1.1.cmml"><mi id="S3.SS3.SSS2.p2.3.m3.1.1.2" xref="S3.SS3.SSS2.p2.3.m3.1.1.2.cmml">L</mi><mrow id="S3.SS3.SSS2.p2.3.m3.1.1.3" xref="S3.SS3.SSS2.p2.3.m3.1.1.3.cmml"><mi id="S3.SS3.SSS2.p2.3.m3.1.1.3.2" xref="S3.SS3.SSS2.p2.3.m3.1.1.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.SS3.SSS2.p2.3.m3.1.1.3.1" xref="S3.SS3.SSS2.p2.3.m3.1.1.3.1.cmml">​</mo><mi id="S3.SS3.SSS2.p2.3.m3.1.1.3.3" xref="S3.SS3.SSS2.p2.3.m3.1.1.3.3.cmml">q</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p2.3.m3.1b"><apply id="S3.SS3.SSS2.p2.3.m3.1.1.cmml" xref="S3.SS3.SSS2.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS2.p2.3.m3.1.1.1.cmml" xref="S3.SS3.SSS2.p2.3.m3.1.1">subscript</csymbol><ci id="S3.SS3.SSS2.p2.3.m3.1.1.2.cmml" xref="S3.SS3.SSS2.p2.3.m3.1.1.2">𝐿</ci><apply id="S3.SS3.SSS2.p2.3.m3.1.1.3.cmml" xref="S3.SS3.SSS2.p2.3.m3.1.1.3"><times id="S3.SS3.SSS2.p2.3.m3.1.1.3.1.cmml" xref="S3.SS3.SSS2.p2.3.m3.1.1.3.1"></times><ci id="S3.SS3.SSS2.p2.3.m3.1.1.3.2.cmml" xref="S3.SS3.SSS2.p2.3.m3.1.1.3.2">𝑚</ci><ci id="S3.SS3.SSS2.p2.3.m3.1.1.3.3.cmml" xref="S3.SS3.SSS2.p2.3.m3.1.1.3.3">𝑞</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.p2.3.m3.1c">L_{mq}</annotation></semantics></math>:</p>
</div>
<div id="S3.SS3.SSS2.p3" class="ltx_para">
<table id="S3.E10" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E10.m1.1" class="ltx_Math" alttext="L_{mq}=\left\|a_{m}-a_{q}\right\|_{2}^{2}" display="block"><semantics id="S3.E10.m1.1a"><mrow id="S3.E10.m1.1.1" xref="S3.E10.m1.1.1.cmml"><msub id="S3.E10.m1.1.1.3" xref="S3.E10.m1.1.1.3.cmml"><mi id="S3.E10.m1.1.1.3.2" xref="S3.E10.m1.1.1.3.2.cmml">L</mi><mrow id="S3.E10.m1.1.1.3.3" xref="S3.E10.m1.1.1.3.3.cmml"><mi id="S3.E10.m1.1.1.3.3.2" xref="S3.E10.m1.1.1.3.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.E10.m1.1.1.3.3.1" xref="S3.E10.m1.1.1.3.3.1.cmml">​</mo><mi id="S3.E10.m1.1.1.3.3.3" xref="S3.E10.m1.1.1.3.3.3.cmml">q</mi></mrow></msub><mo id="S3.E10.m1.1.1.2" xref="S3.E10.m1.1.1.2.cmml">=</mo><msubsup id="S3.E10.m1.1.1.1" xref="S3.E10.m1.1.1.1.cmml"><mrow id="S3.E10.m1.1.1.1.1.1.1" xref="S3.E10.m1.1.1.1.1.1.2.cmml"><mo id="S3.E10.m1.1.1.1.1.1.1.2" xref="S3.E10.m1.1.1.1.1.1.2.1.cmml">‖</mo><mrow id="S3.E10.m1.1.1.1.1.1.1.1" xref="S3.E10.m1.1.1.1.1.1.1.1.cmml"><msub id="S3.E10.m1.1.1.1.1.1.1.1.2" xref="S3.E10.m1.1.1.1.1.1.1.1.2.cmml"><mi id="S3.E10.m1.1.1.1.1.1.1.1.2.2" xref="S3.E10.m1.1.1.1.1.1.1.1.2.2.cmml">a</mi><mi id="S3.E10.m1.1.1.1.1.1.1.1.2.3" xref="S3.E10.m1.1.1.1.1.1.1.1.2.3.cmml">m</mi></msub><mo id="S3.E10.m1.1.1.1.1.1.1.1.1" xref="S3.E10.m1.1.1.1.1.1.1.1.1.cmml">−</mo><msub id="S3.E10.m1.1.1.1.1.1.1.1.3" xref="S3.E10.m1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E10.m1.1.1.1.1.1.1.1.3.2" xref="S3.E10.m1.1.1.1.1.1.1.1.3.2.cmml">a</mi><mi id="S3.E10.m1.1.1.1.1.1.1.1.3.3" xref="S3.E10.m1.1.1.1.1.1.1.1.3.3.cmml">q</mi></msub></mrow><mo id="S3.E10.m1.1.1.1.1.1.1.3" xref="S3.E10.m1.1.1.1.1.1.2.1.cmml">‖</mo></mrow><mn id="S3.E10.m1.1.1.1.1.3" xref="S3.E10.m1.1.1.1.1.3.cmml">2</mn><mn id="S3.E10.m1.1.1.1.3" xref="S3.E10.m1.1.1.1.3.cmml">2</mn></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S3.E10.m1.1b"><apply id="S3.E10.m1.1.1.cmml" xref="S3.E10.m1.1.1"><eq id="S3.E10.m1.1.1.2.cmml" xref="S3.E10.m1.1.1.2"></eq><apply id="S3.E10.m1.1.1.3.cmml" xref="S3.E10.m1.1.1.3"><csymbol cd="ambiguous" id="S3.E10.m1.1.1.3.1.cmml" xref="S3.E10.m1.1.1.3">subscript</csymbol><ci id="S3.E10.m1.1.1.3.2.cmml" xref="S3.E10.m1.1.1.3.2">𝐿</ci><apply id="S3.E10.m1.1.1.3.3.cmml" xref="S3.E10.m1.1.1.3.3"><times id="S3.E10.m1.1.1.3.3.1.cmml" xref="S3.E10.m1.1.1.3.3.1"></times><ci id="S3.E10.m1.1.1.3.3.2.cmml" xref="S3.E10.m1.1.1.3.3.2">𝑚</ci><ci id="S3.E10.m1.1.1.3.3.3.cmml" xref="S3.E10.m1.1.1.3.3.3">𝑞</ci></apply></apply><apply id="S3.E10.m1.1.1.1.cmml" xref="S3.E10.m1.1.1.1"><csymbol cd="ambiguous" id="S3.E10.m1.1.1.1.2.cmml" xref="S3.E10.m1.1.1.1">superscript</csymbol><apply id="S3.E10.m1.1.1.1.1.cmml" xref="S3.E10.m1.1.1.1"><csymbol cd="ambiguous" id="S3.E10.m1.1.1.1.1.2.cmml" xref="S3.E10.m1.1.1.1">subscript</csymbol><apply id="S3.E10.m1.1.1.1.1.1.2.cmml" xref="S3.E10.m1.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E10.m1.1.1.1.1.1.2.1.cmml" xref="S3.E10.m1.1.1.1.1.1.1.2">norm</csymbol><apply id="S3.E10.m1.1.1.1.1.1.1.1.cmml" xref="S3.E10.m1.1.1.1.1.1.1.1"><minus id="S3.E10.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E10.m1.1.1.1.1.1.1.1.1"></minus><apply id="S3.E10.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.E10.m1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E10.m1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E10.m1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E10.m1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E10.m1.1.1.1.1.1.1.1.2.2">𝑎</ci><ci id="S3.E10.m1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E10.m1.1.1.1.1.1.1.1.2.3">𝑚</ci></apply><apply id="S3.E10.m1.1.1.1.1.1.1.1.3.cmml" xref="S3.E10.m1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E10.m1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E10.m1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E10.m1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E10.m1.1.1.1.1.1.1.1.3.2">𝑎</ci><ci id="S3.E10.m1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E10.m1.1.1.1.1.1.1.1.3.3">𝑞</ci></apply></apply></apply><cn type="integer" id="S3.E10.m1.1.1.1.1.3.cmml" xref="S3.E10.m1.1.1.1.1.3">2</cn></apply><cn type="integer" id="S3.E10.m1.1.1.1.3.cmml" xref="S3.E10.m1.1.1.1.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E10.m1.1c">L_{mq}=\left\|a_{m}-a_{q}\right\|_{2}^{2}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(10)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS3.SSS2.p4" class="ltx_para">
<p id="S3.SS3.SSS2.p4.1" class="ltx_p">Therefore, the two parts of the composite loss module are used to jointly optimize the MuVAM:</p>
</div>
<div id="S3.SS3.SSS2.p5" class="ltx_para">
<table id="S3.E11" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E11.m1.1" class="ltx_Math" alttext="Loss=L_{c}+\gamma L_{mq}" display="block"><semantics id="S3.E11.m1.1a"><mrow id="S3.E11.m1.1.1" xref="S3.E11.m1.1.1.cmml"><mrow id="S3.E11.m1.1.1.2" xref="S3.E11.m1.1.1.2.cmml"><mi id="S3.E11.m1.1.1.2.2" xref="S3.E11.m1.1.1.2.2.cmml">L</mi><mo lspace="0em" rspace="0em" id="S3.E11.m1.1.1.2.1" xref="S3.E11.m1.1.1.2.1.cmml">​</mo><mi id="S3.E11.m1.1.1.2.3" xref="S3.E11.m1.1.1.2.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E11.m1.1.1.2.1a" xref="S3.E11.m1.1.1.2.1.cmml">​</mo><mi id="S3.E11.m1.1.1.2.4" xref="S3.E11.m1.1.1.2.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E11.m1.1.1.2.1b" xref="S3.E11.m1.1.1.2.1.cmml">​</mo><mi id="S3.E11.m1.1.1.2.5" xref="S3.E11.m1.1.1.2.5.cmml">s</mi></mrow><mo id="S3.E11.m1.1.1.1" xref="S3.E11.m1.1.1.1.cmml">=</mo><mrow id="S3.E11.m1.1.1.3" xref="S3.E11.m1.1.1.3.cmml"><msub id="S3.E11.m1.1.1.3.2" xref="S3.E11.m1.1.1.3.2.cmml"><mi id="S3.E11.m1.1.1.3.2.2" xref="S3.E11.m1.1.1.3.2.2.cmml">L</mi><mi id="S3.E11.m1.1.1.3.2.3" xref="S3.E11.m1.1.1.3.2.3.cmml">c</mi></msub><mo id="S3.E11.m1.1.1.3.1" xref="S3.E11.m1.1.1.3.1.cmml">+</mo><mrow id="S3.E11.m1.1.1.3.3" xref="S3.E11.m1.1.1.3.3.cmml"><mi id="S3.E11.m1.1.1.3.3.2" xref="S3.E11.m1.1.1.3.3.2.cmml">γ</mi><mo lspace="0em" rspace="0em" id="S3.E11.m1.1.1.3.3.1" xref="S3.E11.m1.1.1.3.3.1.cmml">​</mo><msub id="S3.E11.m1.1.1.3.3.3" xref="S3.E11.m1.1.1.3.3.3.cmml"><mi id="S3.E11.m1.1.1.3.3.3.2" xref="S3.E11.m1.1.1.3.3.3.2.cmml">L</mi><mrow id="S3.E11.m1.1.1.3.3.3.3" xref="S3.E11.m1.1.1.3.3.3.3.cmml"><mi id="S3.E11.m1.1.1.3.3.3.3.2" xref="S3.E11.m1.1.1.3.3.3.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.E11.m1.1.1.3.3.3.3.1" xref="S3.E11.m1.1.1.3.3.3.3.1.cmml">​</mo><mi id="S3.E11.m1.1.1.3.3.3.3.3" xref="S3.E11.m1.1.1.3.3.3.3.3.cmml">q</mi></mrow></msub></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E11.m1.1b"><apply id="S3.E11.m1.1.1.cmml" xref="S3.E11.m1.1.1"><eq id="S3.E11.m1.1.1.1.cmml" xref="S3.E11.m1.1.1.1"></eq><apply id="S3.E11.m1.1.1.2.cmml" xref="S3.E11.m1.1.1.2"><times id="S3.E11.m1.1.1.2.1.cmml" xref="S3.E11.m1.1.1.2.1"></times><ci id="S3.E11.m1.1.1.2.2.cmml" xref="S3.E11.m1.1.1.2.2">𝐿</ci><ci id="S3.E11.m1.1.1.2.3.cmml" xref="S3.E11.m1.1.1.2.3">𝑜</ci><ci id="S3.E11.m1.1.1.2.4.cmml" xref="S3.E11.m1.1.1.2.4">𝑠</ci><ci id="S3.E11.m1.1.1.2.5.cmml" xref="S3.E11.m1.1.1.2.5">𝑠</ci></apply><apply id="S3.E11.m1.1.1.3.cmml" xref="S3.E11.m1.1.1.3"><plus id="S3.E11.m1.1.1.3.1.cmml" xref="S3.E11.m1.1.1.3.1"></plus><apply id="S3.E11.m1.1.1.3.2.cmml" xref="S3.E11.m1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E11.m1.1.1.3.2.1.cmml" xref="S3.E11.m1.1.1.3.2">subscript</csymbol><ci id="S3.E11.m1.1.1.3.2.2.cmml" xref="S3.E11.m1.1.1.3.2.2">𝐿</ci><ci id="S3.E11.m1.1.1.3.2.3.cmml" xref="S3.E11.m1.1.1.3.2.3">𝑐</ci></apply><apply id="S3.E11.m1.1.1.3.3.cmml" xref="S3.E11.m1.1.1.3.3"><times id="S3.E11.m1.1.1.3.3.1.cmml" xref="S3.E11.m1.1.1.3.3.1"></times><ci id="S3.E11.m1.1.1.3.3.2.cmml" xref="S3.E11.m1.1.1.3.3.2">𝛾</ci><apply id="S3.E11.m1.1.1.3.3.3.cmml" xref="S3.E11.m1.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.E11.m1.1.1.3.3.3.1.cmml" xref="S3.E11.m1.1.1.3.3.3">subscript</csymbol><ci id="S3.E11.m1.1.1.3.3.3.2.cmml" xref="S3.E11.m1.1.1.3.3.3.2">𝐿</ci><apply id="S3.E11.m1.1.1.3.3.3.3.cmml" xref="S3.E11.m1.1.1.3.3.3.3"><times id="S3.E11.m1.1.1.3.3.3.3.1.cmml" xref="S3.E11.m1.1.1.3.3.3.3.1"></times><ci id="S3.E11.m1.1.1.3.3.3.3.2.cmml" xref="S3.E11.m1.1.1.3.3.3.3.2">𝑚</ci><ci id="S3.E11.m1.1.1.3.3.3.3.3.cmml" xref="S3.E11.m1.1.1.3.3.3.3.3">𝑞</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E11.m1.1c">Loss=L_{c}+\gamma L_{mq}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(11)</span></td>
</tr></tbody>
</table>
<p id="S3.SS3.SSS2.p5.1" class="ltx_p">where <math id="S3.SS3.SSS2.p5.1.m1.1" class="ltx_Math" alttext="\gamma" display="inline"><semantics id="S3.SS3.SSS2.p5.1.m1.1a"><mi id="S3.SS3.SSS2.p5.1.m1.1.1" xref="S3.SS3.SSS2.p5.1.m1.1.1.cmml">γ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p5.1.m1.1b"><ci id="S3.SS3.SSS2.p5.1.m1.1.1.cmml" xref="S3.SS3.SSS2.p5.1.m1.1.1">𝛾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.p5.1.m1.1c">\gamma</annotation></semantics></math> are hyper-parameters, and the final value is estimated in our experiment. Facts have proved that the IQC loss is effective in improving the accuracy of our model.</p>
</div>
<figure id="S3.F3" class="ltx_figure">
<p id="S3.F3.1" class="ltx_p ltx_align_center"><span id="S3.F3.1.1" class="ltx_text"><img src="/html/2107.03216/assets/x3.png" id="S3.F3.1.1.g1" class="ltx_graphics ltx_img_landscape" width="922" height="298" alt="Refer to caption"></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Examples of VQA-RAD dataset and VQA-RAD<sup id="S3.F3.5.1" class="ltx_sup"><span id="S3.F3.5.1.1" class="ltx_text ltx_font_italic">Ph</span></sup> dataset.</figcaption>
</figure>
<figure id="S3.F4" class="ltx_figure">
<p id="S3.F4.1" class="ltx_p ltx_align_center"><span id="S3.F4.1.1" class="ltx_text"><img src="/html/2107.03216/assets/x4.png" id="S3.F4.1.1.g1" class="ltx_graphics ltx_img_landscape" width="461" height="153" alt="Refer to caption"></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>The anomaly data of VQA-RAD dataset.</figcaption>
</figure>
</section>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiment</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.3" class="ltx_p">In this section, we conduct comprehensive experiments to evaluate the effectiveness of MuVAM. Firstly, we collaborate with medical experts to correct and complete the VQA-RAD datasetand then construct an enhanced dataset, VQA-RAD<sup id="S4.p1.3.1" class="ltx_sup"><span id="S4.p1.3.1.1" class="ltx_text ltx_font_italic">Ph</span></sup>. Secondly, MuVAM is compared with other current advanced models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>, and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite> on the VQA-RAD dataset. And MuVAM and Med-VQA models are evaluated on VQA-RAD<sup id="S4.p1.3.2" class="ltx_sup"><span id="S4.p1.3.2.1" class="ltx_text ltx_font_italic">Ph</span></sup>. Next, The ablation study is used to prove the necessity of the components and the hyperparameter <math id="S4.p1.3.m3.1" class="ltx_Math" alttext="\gamma" display="inline"><semantics id="S4.p1.3.m3.1a"><mi id="S4.p1.3.m3.1.1" xref="S4.p1.3.m3.1.1.cmml">γ</mi><annotation-xml encoding="MathML-Content" id="S4.p1.3.m3.1b"><ci id="S4.p1.3.m3.1.1.cmml" xref="S4.p1.3.m3.1.1">𝛾</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.3.m3.1c">\gamma</annotation></semantics></math> of the image-question complementary loss (IQC) is given the best value. Finally, the visualization evaluation is used to qualitatively analyze the MuVAM model.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Datasets and data quality improvement</h3>

<section id="S4.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.1 </span>VQA-RAD</h4>

<div id="S4.SS1.SSS1.p1" class="ltx_para">
<p id="S4.SS1.SSS1.p1.1" class="ltx_p">The VQA-RAD dataset is the first manually constructed dataset in the field of medical VQA. It contains a total of 315 medical radiology images that are evenly distributed on the head, chest and abdomen. The dataset is divided into a training set and a test set which contains 3064 and 451 question-answer pairs. Questions are classified into 11 categories, for example, organ system, modality, and location. According to the answer types, The question-answer pairs are split into open-ended and close-ended. Generally, the answer that is ”Yes/no” or to the either-or choice question is defined as the close-ended. The majority of the organ system and positional questions answered in the form of free text are open-ended. In our model, we use the TCR component proposed by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> to distinguish these two types.</p>
</div>
</section>
<section id="S4.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.2 </span>VQA-RAD<sup id="S4.SS1.SSS2.2.1" class="ltx_sup"><span id="S4.SS1.SSS2.2.1.1" class="ltx_text ltx_font_italic">Ph</span></sup>
</h4>

<div id="S4.SS1.SSS2.p1" class="ltx_para">
<p id="S4.SS1.SSS2.p1.1" class="ltx_p">The most common application of VQA in reality is to help the blind and visually impaired to obtain more information on the Internet or in the real world. It can even carry out real-time human-computer interaction, which will greatly improve their living conditions and convenience. But if there is a problem in the dataset itself and the wrong answer is eventually returned, then the incorrect answer in this situation will lead to a fatal accident. Especially for the VQA dataset in the medical vertical field, data quality is more emphasized.We invited medical imaging experts to check the dataset one by one and it was found that the question-answer pairs in the VQA-RAD dataset are not completely correct. As an example is shown in Fig. (<a href="#S3.F3" title="Figure 3 ‣ 3.3.2 IQC loss ‣ 3.3 Composite Loss ‣ 3 MuVAM for Medical VQA ‣ MuVAM: A Multi-View Attention-based Model for Medical Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>), for the question ”Is there an acute bleed present?”, this is obviously a closed-ended question, and the correct answer is ”Yes”. However, the reference answer in VQA-RAD dataset is the”Necrotic tissue” which is open-ended. We screened out the questionable data from all the question-answer pairs, discussed and revised them with experts in multiple medical fields to correct and complete the dataset.</p>
</div>
<div id="S4.SS1.SSS2.p2" class="ltx_para">
<p id="S4.SS1.SSS2.p2.1" class="ltx_p">In the experiment, it was found that a total of 48 question-answer pairs in the test set were not labeled is shown in Fig. (<a href="#S3.F4" title="Figure 4 ‣ 3.3.2 IQC loss ‣ 3.3 Composite Loss ‣ 3 MuVAM for Medical VQA ‣ MuVAM: A Multi-View Attention-based Model for Medical Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>). This phenomenon is called the fifth anomalous task in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite>, that is, the undefined answer. Although the undefined answer means that the image and question are from in-distribution, the answer is not among the candidate answers of the VQA model. When the correct answer does not exist, there will be an unanswerable situation. This situation is also the most common and realistic anomaly. In order to improve data quality and make the dataset available , we repair the anomaly data, and finally expand from 486 different answers to 521 according to the unique structure of the answer. The correct and complete dataset is called VQA-RAD<sup id="S4.SS1.SSS2.p2.1.1" class="ltx_sup"><span id="S4.SS1.SSS2.p2.1.1.1" class="ltx_text ltx_font_italic">Ph</span></sup>.</p>
</div>
</section>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Implementation Setup</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">All experiments are implemented on a server with GTX 1080ti GPU using pytorch. Each question is composed of 12 words and each word is embedded with GloVe. The sequence of word embedding is fed into GRU to obtain semantic features. The dimension of the hidden layer in GRU is set to 1024. The visual feature extraction component is composed of MAML and CDAE encoder to initialize the pre-training weights and the size of the relation feature is set to 128. BAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite> is used as a multi-modal feature fusion model in the fusion module. In our experiment, we use the Adamax optimizer for training with the minimum batch size as 64 and the learning rate is set to 0.005.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Evaluation Metrics</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">The accuracy is used as the evaluation index of the model in the experiment, that is, the proportion of the total amount that the model predicts correctly:</p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<table id="S4.E12" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E12.m1.1" class="ltx_Math" alttext="P_{Acc}=\frac{N_{C}}{N_{T}}*100\%" display="block"><semantics id="S4.E12.m1.1a"><mrow id="S4.E12.m1.1.1" xref="S4.E12.m1.1.1.cmml"><msub id="S4.E12.m1.1.1.2" xref="S4.E12.m1.1.1.2.cmml"><mi id="S4.E12.m1.1.1.2.2" xref="S4.E12.m1.1.1.2.2.cmml">P</mi><mrow id="S4.E12.m1.1.1.2.3" xref="S4.E12.m1.1.1.2.3.cmml"><mi id="S4.E12.m1.1.1.2.3.2" xref="S4.E12.m1.1.1.2.3.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S4.E12.m1.1.1.2.3.1" xref="S4.E12.m1.1.1.2.3.1.cmml">​</mo><mi id="S4.E12.m1.1.1.2.3.3" xref="S4.E12.m1.1.1.2.3.3.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.E12.m1.1.1.2.3.1a" xref="S4.E12.m1.1.1.2.3.1.cmml">​</mo><mi id="S4.E12.m1.1.1.2.3.4" xref="S4.E12.m1.1.1.2.3.4.cmml">c</mi></mrow></msub><mo id="S4.E12.m1.1.1.1" xref="S4.E12.m1.1.1.1.cmml">=</mo><mrow id="S4.E12.m1.1.1.3" xref="S4.E12.m1.1.1.3.cmml"><mfrac id="S4.E12.m1.1.1.3.2" xref="S4.E12.m1.1.1.3.2.cmml"><msub id="S4.E12.m1.1.1.3.2.2" xref="S4.E12.m1.1.1.3.2.2.cmml"><mi id="S4.E12.m1.1.1.3.2.2.2" xref="S4.E12.m1.1.1.3.2.2.2.cmml">N</mi><mi id="S4.E12.m1.1.1.3.2.2.3" xref="S4.E12.m1.1.1.3.2.2.3.cmml">C</mi></msub><msub id="S4.E12.m1.1.1.3.2.3" xref="S4.E12.m1.1.1.3.2.3.cmml"><mi id="S4.E12.m1.1.1.3.2.3.2" xref="S4.E12.m1.1.1.3.2.3.2.cmml">N</mi><mi id="S4.E12.m1.1.1.3.2.3.3" xref="S4.E12.m1.1.1.3.2.3.3.cmml">T</mi></msub></mfrac><mo lspace="0.222em" rspace="0.222em" id="S4.E12.m1.1.1.3.1" xref="S4.E12.m1.1.1.3.1.cmml">∗</mo><mrow id="S4.E12.m1.1.1.3.3" xref="S4.E12.m1.1.1.3.3.cmml"><mn id="S4.E12.m1.1.1.3.3.2" xref="S4.E12.m1.1.1.3.3.2.cmml">100</mn><mo id="S4.E12.m1.1.1.3.3.1" xref="S4.E12.m1.1.1.3.3.1.cmml">%</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E12.m1.1b"><apply id="S4.E12.m1.1.1.cmml" xref="S4.E12.m1.1.1"><eq id="S4.E12.m1.1.1.1.cmml" xref="S4.E12.m1.1.1.1"></eq><apply id="S4.E12.m1.1.1.2.cmml" xref="S4.E12.m1.1.1.2"><csymbol cd="ambiguous" id="S4.E12.m1.1.1.2.1.cmml" xref="S4.E12.m1.1.1.2">subscript</csymbol><ci id="S4.E12.m1.1.1.2.2.cmml" xref="S4.E12.m1.1.1.2.2">𝑃</ci><apply id="S4.E12.m1.1.1.2.3.cmml" xref="S4.E12.m1.1.1.2.3"><times id="S4.E12.m1.1.1.2.3.1.cmml" xref="S4.E12.m1.1.1.2.3.1"></times><ci id="S4.E12.m1.1.1.2.3.2.cmml" xref="S4.E12.m1.1.1.2.3.2">𝐴</ci><ci id="S4.E12.m1.1.1.2.3.3.cmml" xref="S4.E12.m1.1.1.2.3.3">𝑐</ci><ci id="S4.E12.m1.1.1.2.3.4.cmml" xref="S4.E12.m1.1.1.2.3.4">𝑐</ci></apply></apply><apply id="S4.E12.m1.1.1.3.cmml" xref="S4.E12.m1.1.1.3"><times id="S4.E12.m1.1.1.3.1.cmml" xref="S4.E12.m1.1.1.3.1"></times><apply id="S4.E12.m1.1.1.3.2.cmml" xref="S4.E12.m1.1.1.3.2"><divide id="S4.E12.m1.1.1.3.2.1.cmml" xref="S4.E12.m1.1.1.3.2"></divide><apply id="S4.E12.m1.1.1.3.2.2.cmml" xref="S4.E12.m1.1.1.3.2.2"><csymbol cd="ambiguous" id="S4.E12.m1.1.1.3.2.2.1.cmml" xref="S4.E12.m1.1.1.3.2.2">subscript</csymbol><ci id="S4.E12.m1.1.1.3.2.2.2.cmml" xref="S4.E12.m1.1.1.3.2.2.2">𝑁</ci><ci id="S4.E12.m1.1.1.3.2.2.3.cmml" xref="S4.E12.m1.1.1.3.2.2.3">𝐶</ci></apply><apply id="S4.E12.m1.1.1.3.2.3.cmml" xref="S4.E12.m1.1.1.3.2.3"><csymbol cd="ambiguous" id="S4.E12.m1.1.1.3.2.3.1.cmml" xref="S4.E12.m1.1.1.3.2.3">subscript</csymbol><ci id="S4.E12.m1.1.1.3.2.3.2.cmml" xref="S4.E12.m1.1.1.3.2.3.2">𝑁</ci><ci id="S4.E12.m1.1.1.3.2.3.3.cmml" xref="S4.E12.m1.1.1.3.2.3.3">𝑇</ci></apply></apply><apply id="S4.E12.m1.1.1.3.3.cmml" xref="S4.E12.m1.1.1.3.3"><csymbol cd="latexml" id="S4.E12.m1.1.1.3.3.1.cmml" xref="S4.E12.m1.1.1.3.3.1">percent</csymbol><cn type="integer" id="S4.E12.m1.1.1.3.3.2.cmml" xref="S4.E12.m1.1.1.3.3.2">100</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E12.m1.1c">P_{Acc}=\frac{N_{C}}{N_{T}}*100\%</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(12)</span></td>
</tr></tbody>
</table>
<p id="S4.SS3.p2.2" class="ltx_p">where <math id="S4.SS3.p2.1.m1.1" class="ltx_Math" alttext="N_{C}" display="inline"><semantics id="S4.SS3.p2.1.m1.1a"><msub id="S4.SS3.p2.1.m1.1.1" xref="S4.SS3.p2.1.m1.1.1.cmml"><mi id="S4.SS3.p2.1.m1.1.1.2" xref="S4.SS3.p2.1.m1.1.1.2.cmml">N</mi><mi id="S4.SS3.p2.1.m1.1.1.3" xref="S4.SS3.p2.1.m1.1.1.3.cmml">C</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.1.m1.1b"><apply id="S4.SS3.p2.1.m1.1.1.cmml" xref="S4.SS3.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS3.p2.1.m1.1.1.1.cmml" xref="S4.SS3.p2.1.m1.1.1">subscript</csymbol><ci id="S4.SS3.p2.1.m1.1.1.2.cmml" xref="S4.SS3.p2.1.m1.1.1.2">𝑁</ci><ci id="S4.SS3.p2.1.m1.1.1.3.cmml" xref="S4.SS3.p2.1.m1.1.1.3">𝐶</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.1.m1.1c">N_{C}</annotation></semantics></math> represents the number of correctly predicted answers to the questions, <math id="S4.SS3.p2.2.m2.1" class="ltx_Math" alttext="N_{T}" display="inline"><semantics id="S4.SS3.p2.2.m2.1a"><msub id="S4.SS3.p2.2.m2.1.1" xref="S4.SS3.p2.2.m2.1.1.cmml"><mi id="S4.SS3.p2.2.m2.1.1.2" xref="S4.SS3.p2.2.m2.1.1.2.cmml">N</mi><mi id="S4.SS3.p2.2.m2.1.1.3" xref="S4.SS3.p2.2.m2.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.2.m2.1b"><apply id="S4.SS3.p2.2.m2.1.1.cmml" xref="S4.SS3.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS3.p2.2.m2.1.1.1.cmml" xref="S4.SS3.p2.2.m2.1.1">subscript</csymbol><ci id="S4.SS3.p2.2.m2.1.1.2.cmml" xref="S4.SS3.p2.2.m2.1.1.2">𝑁</ci><ci id="S4.SS3.p2.2.m2.1.1.3.cmml" xref="S4.SS3.p2.2.m2.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.2.m2.1c">N_{T}</annotation></semantics></math> refers to the total number of questions.</p>
</div>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Baseline</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.1" class="ltx_p">We compare the proposed model with the advanced methods of medical VQA: MAML <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>, MEVF <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>, MMQ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite> , Med-VQA <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>.</p>
</div>
<div id="S4.SS4.p2" class="ltx_para">
<p id="S4.SS4.p2.1" class="ltx_p"><span id="S4.SS4.p2.1.1" class="ltx_text ltx_font_bold">MAML</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> introduced model-agnostic meta-learning to learn meta-weights that quickly adapt to visual concepts to overcome the problems caused by transfer learning to achieve image feature extraction.</p>
</div>
<div id="S4.SS4.p3" class="ltx_para">
<p id="S4.SS4.p3.1" class="ltx_p"><span id="S4.SS4.p3.1.1" class="ltx_text ltx_font_bold">MEVF</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> leveraged meta-learning and denoising auto-encoder to extract image features in order to overcome the limitation of labeled training data.</p>
</div>
<div id="S4.SS4.p4" class="ltx_para">
<p id="S4.SS4.p4.1" class="ltx_p"><span id="S4.SS4.p4.1.1" class="ltx_text ltx_font_bold">MMQ</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite> aimed to increase metadata through automatic annotations and process noisy labels , without external data to train the meta-model for better feature extraction of medical images.</p>
</div>
<div id="S4.SS4.p5" class="ltx_para">
<p id="S4.SS4.p5.1" class="ltx_p"><span id="S4.SS4.p5.1.1" class="ltx_text ltx_font_bold">Med-VQA</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> proposed a conditional reasoning framework that included QCR component and TCR component, aiming to automatically learn effective reasoning skills for various medical VQA tasks.</p>
</div>
<div id="S4.SS4.p6" class="ltx_para">
<p id="S4.SS4.p6.1" class="ltx_p">MAML, MEVF and MMQ use SAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite> and BAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite> fusion methods. Med-VQA and MuVAM use BAN fusion method.</p>
</div>
<figure id="S4.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span>Comparison of the accuracy of different medical vision question answering methods in the VQA-RAD test set. </figcaption>
<table id="S4.T1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T1.1.1.1" class="ltx_tr">
<th id="S4.T1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding:1.5pt 10.0pt;" colspan="2" rowspan="2"><span id="S4.T1.1.1.1.1.1" class="ltx_text">Model</span></th>
<th id="S4.T1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding:1.5pt 10.0pt;" colspan="3">VQA-RAD</th>
</tr>
<tr id="S4.T1.1.2.2" class="ltx_tr">
<th id="S4.T1.1.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding:1.5pt 10.0pt;">
<table id="S4.T1.1.2.2.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T1.1.2.2.1.1.1" class="ltx_tr">
<td id="S4.T1.1.2.2.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:1.5pt 10.0pt;">Open-ended</td>
</tr>
<tr id="S4.T1.1.2.2.1.1.2" class="ltx_tr">
<td id="S4.T1.1.2.2.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:1.5pt 10.0pt;">(%)</td>
</tr>
</table>
</th>
<th id="S4.T1.1.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding:1.5pt 10.0pt;">
<table id="S4.T1.1.2.2.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T1.1.2.2.2.1.1" class="ltx_tr">
<td id="S4.T1.1.2.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:1.5pt 10.0pt;">Closed-ended</td>
</tr>
<tr id="S4.T1.1.2.2.2.1.2" class="ltx_tr">
<td id="S4.T1.1.2.2.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:1.5pt 10.0pt;">(%)</td>
</tr>
</table>
</th>
<th id="S4.T1.1.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding:1.5pt 10.0pt;">
<table id="S4.T1.1.2.2.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T1.1.2.2.3.1.1" class="ltx_tr">
<td id="S4.T1.1.2.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:1.5pt 10.0pt;">Overall</td>
</tr>
<tr id="S4.T1.1.2.2.3.1.2" class="ltx_tr">
<td id="S4.T1.1.2.2.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:1.5pt 10.0pt;">(%)</td>
</tr>
</table>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T1.1.3.1" class="ltx_tr">
<td id="S4.T1.1.3.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:1.5pt 10.0pt;" rowspan="2"><span id="S4.T1.1.3.1.1.1" class="ltx_text">MAML</span></td>
<td id="S4.T1.1.3.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:1.5pt 10.0pt;">BAN</td>
<td id="S4.T1.1.3.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:1.5pt 10.0pt;">40.1</td>
<td id="S4.T1.1.3.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:1.5pt 10.0pt;">72.4</td>
<td id="S4.T1.1.3.1.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.5pt 10.0pt;">59.6</td>
</tr>
<tr id="S4.T1.1.4.2" class="ltx_tr">
<td id="S4.T1.1.4.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:1.5pt 10.0pt;">SAN</td>
<td id="S4.T1.1.4.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:1.5pt 10.0pt;">38.2</td>
<td id="S4.T1.1.4.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:1.5pt 10.0pt;">69.7</td>
<td id="S4.T1.1.4.2.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.5pt 10.0pt;">57.1</td>
</tr>
<tr id="S4.T1.1.5.3" class="ltx_tr">
<td id="S4.T1.1.5.3.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:1.5pt 10.0pt;" rowspan="2"><span id="S4.T1.1.5.3.1.1" class="ltx_text">MEVF</span></td>
<td id="S4.T1.1.5.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:1.5pt 10.0pt;">BAN</td>
<td id="S4.T1.1.5.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:1.5pt 10.0pt;">43.9</td>
<td id="S4.T1.1.5.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:1.5pt 10.0pt;">75.1</td>
<td id="S4.T1.1.5.3.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.5pt 10.0pt;">62.7</td>
</tr>
<tr id="S4.T1.1.6.4" class="ltx_tr">
<td id="S4.T1.1.6.4.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:1.5pt 10.0pt;">SAN</td>
<td id="S4.T1.1.6.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:1.5pt 10.0pt;">40.7</td>
<td id="S4.T1.1.6.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:1.5pt 10.0pt;">74.1</td>
<td id="S4.T1.1.6.4.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.5pt 10.0pt;">60.7</td>
</tr>
<tr id="S4.T1.1.7.5" class="ltx_tr">
<td id="S4.T1.1.7.5.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:1.5pt 10.0pt;" rowspan="2"><span id="S4.T1.1.7.5.1.1" class="ltx_text">MMQ</span></td>
<td id="S4.T1.1.7.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:1.5pt 10.0pt;">BAN</td>
<td id="S4.T1.1.7.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:1.5pt 10.0pt;">53.7</td>
<td id="S4.T1.1.7.5.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:1.5pt 10.0pt;">75.8</td>
<td id="S4.T1.1.7.5.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.5pt 10.0pt;">67.0</td>
</tr>
<tr id="S4.T1.1.8.6" class="ltx_tr">
<td id="S4.T1.1.8.6.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:1.5pt 10.0pt;">SAN</td>
<td id="S4.T1.1.8.6.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:1.5pt 10.0pt;">46.3</td>
<td id="S4.T1.1.8.6.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:1.5pt 10.0pt;">75.7</td>
<td id="S4.T1.1.8.6.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.5pt 10.0pt;">64.0</td>
</tr>
<tr id="S4.T1.1.9.7" class="ltx_tr">
<td id="S4.T1.1.9.7.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:1.5pt 10.0pt;" colspan="2">Med-VQA</td>
<td id="S4.T1.1.9.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:1.5pt 10.0pt;">60.0</td>
<td id="S4.T1.1.9.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:1.5pt 10.0pt;">79.3</td>
<td id="S4.T1.1.9.7.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.5pt 10.0pt;">71.6</td>
</tr>
<tr id="S4.T1.1.10.8" class="ltx_tr">
<td id="S4.T1.1.10.8.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding:1.5pt 10.0pt;" colspan="2"><span id="S4.T1.1.10.8.1.1" class="ltx_text ltx_font_bold">MuVAM</span></td>
<td id="S4.T1.1.10.8.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding:1.5pt 10.0pt;"><span id="S4.T1.1.10.8.2.1" class="ltx_text ltx_font_bold">63.3</span></td>
<td id="S4.T1.1.10.8.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding:1.5pt 10.0pt;"><span id="S4.T1.1.10.8.3.1" class="ltx_text ltx_font_bold">81.1</span></td>
<td id="S4.T1.1.10.8.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding:1.5pt 10.0pt;"><span id="S4.T1.1.10.8.4.1" class="ltx_text ltx_font_bold">72.2</span></td>
</tr>
</tbody>
</table>
</figure>
<figure id="S4.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span> Comparison of the accuracy of different medical vision question answering methods in the VQA-RAD<sup id="S4.T2.5.1" class="ltx_sup"><span id="S4.T2.5.1.1" class="ltx_text ltx_font_italic">Ph</span></sup> test set.</figcaption>
<table id="S4.T2.3" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T2.3.1" class="ltx_tr">
<th id="S4.T2.3.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" style="padding:1pt 12.8pt;" rowspan="2"><span id="S4.T2.3.1.2.1" class="ltx_text">Model</span></th>
<th id="S4.T2.3.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding:1pt 12.8pt;" colspan="3">VQA-RAD<sup id="S4.T2.3.1.1.1" class="ltx_sup"><span id="S4.T2.3.1.1.1.1" class="ltx_text ltx_font_italic">Ph</span></sup></th>
</tr>
<tr id="S4.T2.3.2.1" class="ltx_tr">
<th id="S4.T2.3.2.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding:1pt 12.8pt;">
<table id="S4.T2.3.2.1.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T2.3.2.1.1.1.1" class="ltx_tr">
<td id="S4.T2.3.2.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:1pt 12.8pt;">Open-ended</td>
</tr>
<tr id="S4.T2.3.2.1.1.1.2" class="ltx_tr">
<td id="S4.T2.3.2.1.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:1pt 12.8pt;">(%)</td>
</tr>
</table>
</th>
<th id="S4.T2.3.2.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding:1pt 12.8pt;">
<table id="S4.T2.3.2.1.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T2.3.2.1.2.1.1" class="ltx_tr">
<td id="S4.T2.3.2.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:1pt 12.8pt;">Closed-ended</td>
</tr>
<tr id="S4.T2.3.2.1.2.1.2" class="ltx_tr">
<td id="S4.T2.3.2.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:1pt 12.8pt;">(%)</td>
</tr>
</table>
</th>
<th id="S4.T2.3.2.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding:1pt 12.8pt;">
<table id="S4.T2.3.2.1.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T2.3.2.1.3.1.1" class="ltx_tr">
<td id="S4.T2.3.2.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:1pt 12.8pt;">Overall</td>
</tr>
<tr id="S4.T2.3.2.1.3.1.2" class="ltx_tr">
<td id="S4.T2.3.2.1.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:1pt 12.8pt;">(%)</td>
</tr>
</table>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T2.3.3.1" class="ltx_tr">
<th id="S4.T2.3.3.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding:1pt 12.8pt;">Med-VQA</th>
<td id="S4.T2.3.3.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:1pt 12.8pt;">56.11</td>
<td id="S4.T2.3.3.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:1pt 12.8pt;">78.96</td>
<td id="S4.T2.3.3.1.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:1pt 12.8pt;">68.07</td>
</tr>
<tr id="S4.T2.3.4.2" class="ltx_tr">
<th id="S4.T2.3.4.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t" style="padding:1pt 12.8pt;"><span id="S4.T2.3.4.2.1.1" class="ltx_text ltx_font_bold">MuVAM</span></th>
<td id="S4.T2.3.4.2.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding:1pt 12.8pt;"><span id="S4.T2.3.4.2.2.1" class="ltx_text ltx_font_bold">63.33</span></td>
<td id="S4.T2.3.4.2.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding:1pt 12.8pt;"><span id="S4.T2.3.4.2.3.1" class="ltx_text ltx_font_bold">82.66</span></td>
<td id="S4.T2.3.4.2.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding:1pt 12.8pt;"><span id="S4.T2.3.4.2.4.1" class="ltx_text ltx_font_bold">74.28</span></td>
</tr>
</tbody>
</table>
</figure>
<figure id="S4.T3" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3: </span>Analysis of the VQA-RAD and VQA-RAD<sup id="S4.T3.9.1" class="ltx_sup"><span id="S4.T3.9.1.1" class="ltx_text ltx_font_italic">Ph</span></sup> testset used for ablation research, where “baseline” is the basic model, the ”att” refers to the Image-to-Question attention mechanism , and the ”<math id="S4.T3.4.m2.1" class="ltx_Math" alttext="L_{mq}" display="inline"><semantics id="S4.T3.4.m2.1b"><msub id="S4.T3.4.m2.1.1" xref="S4.T3.4.m2.1.1.cmml"><mi id="S4.T3.4.m2.1.1.2" xref="S4.T3.4.m2.1.1.2.cmml">L</mi><mrow id="S4.T3.4.m2.1.1.3" xref="S4.T3.4.m2.1.1.3.cmml"><mi id="S4.T3.4.m2.1.1.3.2" xref="S4.T3.4.m2.1.1.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S4.T3.4.m2.1.1.3.1" xref="S4.T3.4.m2.1.1.3.1.cmml">​</mo><mi id="S4.T3.4.m2.1.1.3.3" xref="S4.T3.4.m2.1.1.3.3.cmml">q</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.T3.4.m2.1c"><apply id="S4.T3.4.m2.1.1.cmml" xref="S4.T3.4.m2.1.1"><csymbol cd="ambiguous" id="S4.T3.4.m2.1.1.1.cmml" xref="S4.T3.4.m2.1.1">subscript</csymbol><ci id="S4.T3.4.m2.1.1.2.cmml" xref="S4.T3.4.m2.1.1.2">𝐿</ci><apply id="S4.T3.4.m2.1.1.3.cmml" xref="S4.T3.4.m2.1.1.3"><times id="S4.T3.4.m2.1.1.3.1.cmml" xref="S4.T3.4.m2.1.1.3.1"></times><ci id="S4.T3.4.m2.1.1.3.2.cmml" xref="S4.T3.4.m2.1.1.3.2">𝑚</ci><ci id="S4.T3.4.m2.1.1.3.3.cmml" xref="S4.T3.4.m2.1.1.3.3">𝑞</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.4.m2.1d">L_{mq}</annotation></semantics></math>” indicates image-question complementary loss. </figcaption>
<table id="S4.T3.7" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T3.5.1" class="ltx_tr">
<th id="S4.T3.5.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" style="padding:2pt 17.1pt;" rowspan="2">      <span id="S4.T3.5.1.2.1" class="ltx_text">Method</span></th>
<th id="S4.T3.5.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding:2pt 17.1pt;" colspan="3">      VQA-RAD</th>
<th id="S4.T3.5.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding:2pt 17.1pt;" colspan="3">      VQA-RAD<sup id="S4.T3.5.1.1.1" class="ltx_sup"><span id="S4.T3.5.1.1.1.1" class="ltx_text ltx_font_italic">Ph</span></sup></th>
</tr>
<tr id="S4.T3.7.4.1" class="ltx_tr">
<th id="S4.T3.7.4.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding:2pt 17.1pt;">      
<table id="S4.T3.7.4.1.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T3.7.4.1.1.1.1" class="ltx_tr">
<td id="S4.T3.7.4.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:2pt 17.1pt;">      Open-ended</td>
</tr>
<tr id="S4.T3.7.4.1.1.1.2" class="ltx_tr">
<td id="S4.T3.7.4.1.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:2pt 17.1pt;">      (%)</td>
</tr>
</table></th>
<th id="S4.T3.7.4.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding:2pt 17.1pt;">      
<table id="S4.T3.7.4.1.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T3.7.4.1.2.1.1" class="ltx_tr">
<td id="S4.T3.7.4.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:2pt 17.1pt;">      Closed-ended</td>
</tr>
<tr id="S4.T3.7.4.1.2.1.2" class="ltx_tr">
<td id="S4.T3.7.4.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:2pt 17.1pt;">      (%)</td>
</tr>
</table></th>
<th id="S4.T3.7.4.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding:2pt 17.1pt;">      
<table id="S4.T3.7.4.1.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T3.7.4.1.3.1.1" class="ltx_tr">
<td id="S4.T3.7.4.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:2pt 17.1pt;">      Overall</td>
</tr>
<tr id="S4.T3.7.4.1.3.1.2" class="ltx_tr">
<td id="S4.T3.7.4.1.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:2pt 17.1pt;">      (%)</td>
</tr>
</table></th>
<th id="S4.T3.7.4.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding:2pt 17.1pt;">      
<table id="S4.T3.7.4.1.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T3.7.4.1.4.1.1" class="ltx_tr">
<td id="S4.T3.7.4.1.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:2pt 17.1pt;">      Open-ended</td>
</tr>
<tr id="S4.T3.7.4.1.4.1.2" class="ltx_tr">
<td id="S4.T3.7.4.1.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:2pt 17.1pt;">      (%)</td>
</tr>
</table></th>
<th id="S4.T3.7.4.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding:2pt 17.1pt;">      
<table id="S4.T3.7.4.1.5.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T3.7.4.1.5.1.1" class="ltx_tr">
<td id="S4.T3.7.4.1.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:2pt 17.1pt;">      Closed-ended</td>
</tr>
<tr id="S4.T3.7.4.1.5.1.2" class="ltx_tr">
<td id="S4.T3.7.4.1.5.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:2pt 17.1pt;">      (%)</td>
</tr>
</table></th>
<th id="S4.T3.7.4.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding:2pt 17.1pt;">      
<table id="S4.T3.7.4.1.6.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T3.7.4.1.6.1.1" class="ltx_tr">
<td id="S4.T3.7.4.1.6.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:2pt 17.1pt;">      Overall</td>
</tr>
<tr id="S4.T3.7.4.1.6.1.2" class="ltx_tr">
<td id="S4.T3.7.4.1.6.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:2pt 17.1pt;">      (%)</td>
</tr>
</table></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T3.7.5.1" class="ltx_tr">
<th id="S4.T3.7.5.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding:2pt 17.1pt;">      baseline</th>
<td id="S4.T3.7.5.1.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:2pt 17.1pt;">      57.01</td>
<td id="S4.T3.7.5.1.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:2pt 17.1pt;">      78.79</td>
<td id="S4.T3.7.5.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:2pt 17.1pt;">      70.06</td>
<td id="S4.T3.7.5.1.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:2pt 17.1pt;">      57.22</td>
<td id="S4.T3.7.5.1.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:2pt 17.1pt;">      79.11</td>
<td id="S4.T3.7.5.1.7" class="ltx_td ltx_align_center ltx_border_t" style="padding:2pt 17.1pt;">      70.28</td>
</tr>
<tr id="S4.T3.7.6.2" class="ltx_tr">
<th id="S4.T3.7.6.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding:2pt 17.1pt;">      baseline+att</th>
<td id="S4.T3.7.6.2.2" class="ltx_td ltx_align_center" style="padding:2pt 17.1pt;">      60.00</td>
<td id="S4.T3.7.6.2.3" class="ltx_td ltx_align_center" style="padding:2pt 17.1pt;">      81.54</td>
<td id="S4.T3.7.6.2.4" class="ltx_td ltx_align_center ltx_border_r" style="padding:2pt 17.1pt;">      72.06</td>
<td id="S4.T3.7.6.2.5" class="ltx_td ltx_align_center" style="padding:2pt 17.1pt;">      62.77</td>
<td id="S4.T3.7.6.2.6" class="ltx_td ltx_align_center" style="padding:2pt 17.1pt;">      80.07</td>
<td id="S4.T3.7.6.2.7" class="ltx_td ltx_align_center" style="padding:2pt 17.1pt;">      72.50</td>
</tr>
<tr id="S4.T3.6.2" class="ltx_tr">
<th id="S4.T3.6.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding:2pt 17.1pt;">      baseline+<math id="S4.T3.6.2.1.m1.1" class="ltx_Math" alttext="L_{mq}" display="inline"><semantics id="S4.T3.6.2.1.m1.1a"><msub id="S4.T3.6.2.1.m1.1.1" xref="S4.T3.6.2.1.m1.1.1.cmml"><mi id="S4.T3.6.2.1.m1.1.1.2" xref="S4.T3.6.2.1.m1.1.1.2.cmml">L</mi><mrow id="S4.T3.6.2.1.m1.1.1.3" xref="S4.T3.6.2.1.m1.1.1.3.cmml"><mi id="S4.T3.6.2.1.m1.1.1.3.2" xref="S4.T3.6.2.1.m1.1.1.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S4.T3.6.2.1.m1.1.1.3.1" xref="S4.T3.6.2.1.m1.1.1.3.1.cmml">​</mo><mi id="S4.T3.6.2.1.m1.1.1.3.3" xref="S4.T3.6.2.1.m1.1.1.3.3.cmml">q</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.T3.6.2.1.m1.1b"><apply id="S4.T3.6.2.1.m1.1.1.cmml" xref="S4.T3.6.2.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T3.6.2.1.m1.1.1.1.cmml" xref="S4.T3.6.2.1.m1.1.1">subscript</csymbol><ci id="S4.T3.6.2.1.m1.1.1.2.cmml" xref="S4.T3.6.2.1.m1.1.1.2">𝐿</ci><apply id="S4.T3.6.2.1.m1.1.1.3.cmml" xref="S4.T3.6.2.1.m1.1.1.3"><times id="S4.T3.6.2.1.m1.1.1.3.1.cmml" xref="S4.T3.6.2.1.m1.1.1.3.1"></times><ci id="S4.T3.6.2.1.m1.1.1.3.2.cmml" xref="S4.T3.6.2.1.m1.1.1.3.2">𝑚</ci><ci id="S4.T3.6.2.1.m1.1.1.3.3.cmml" xref="S4.T3.6.2.1.m1.1.1.3.3">𝑞</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.6.2.1.m1.1c">L_{mq}</annotation></semantics></math></th>
<td id="S4.T3.6.2.2" class="ltx_td ltx_align_center" style="padding:2pt 17.1pt;">      61.66</td>
<td id="S4.T3.6.2.3" class="ltx_td ltx_align_center" style="padding:2pt 17.1pt;">      81.48</td>
<td id="S4.T3.6.2.4" class="ltx_td ltx_align_center ltx_border_r" style="padding:2pt 17.1pt;">      71.62</td>
<td id="S4.T3.6.2.5" class="ltx_td ltx_align_center" style="padding:2pt 17.1pt;">      59.44</td>
<td id="S4.T3.6.2.6" class="ltx_td ltx_align_center" style="padding:2pt 17.1pt;">      81.18</td>
<td id="S4.T3.6.2.7" class="ltx_td ltx_align_center" style="padding:2pt 17.1pt;">      71.61</td>
</tr>
<tr id="S4.T3.7.3" class="ltx_tr">
<th id="S4.T3.7.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r" style="padding:2pt 17.1pt;">      baseline+att+<math id="S4.T3.7.3.1.m1.1" class="ltx_Math" alttext="L_{mq}" display="inline"><semantics id="S4.T3.7.3.1.m1.1a"><msub id="S4.T3.7.3.1.m1.1.1" xref="S4.T3.7.3.1.m1.1.1.cmml"><mi id="S4.T3.7.3.1.m1.1.1.2" xref="S4.T3.7.3.1.m1.1.1.2.cmml">L</mi><mrow id="S4.T3.7.3.1.m1.1.1.3" xref="S4.T3.7.3.1.m1.1.1.3.cmml"><mi id="S4.T3.7.3.1.m1.1.1.3.2" xref="S4.T3.7.3.1.m1.1.1.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S4.T3.7.3.1.m1.1.1.3.1" xref="S4.T3.7.3.1.m1.1.1.3.1.cmml">​</mo><mi id="S4.T3.7.3.1.m1.1.1.3.3" xref="S4.T3.7.3.1.m1.1.1.3.3.cmml">q</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.T3.7.3.1.m1.1b"><apply id="S4.T3.7.3.1.m1.1.1.cmml" xref="S4.T3.7.3.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T3.7.3.1.m1.1.1.1.cmml" xref="S4.T3.7.3.1.m1.1.1">subscript</csymbol><ci id="S4.T3.7.3.1.m1.1.1.2.cmml" xref="S4.T3.7.3.1.m1.1.1.2">𝐿</ci><apply id="S4.T3.7.3.1.m1.1.1.3.cmml" xref="S4.T3.7.3.1.m1.1.1.3"><times id="S4.T3.7.3.1.m1.1.1.3.1.cmml" xref="S4.T3.7.3.1.m1.1.1.3.1"></times><ci id="S4.T3.7.3.1.m1.1.1.3.2.cmml" xref="S4.T3.7.3.1.m1.1.1.3.2">𝑚</ci><ci id="S4.T3.7.3.1.m1.1.1.3.3.cmml" xref="S4.T3.7.3.1.m1.1.1.3.3">𝑞</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.7.3.1.m1.1c">L_{mq}</annotation></semantics></math></th>
<td id="S4.T3.7.3.2" class="ltx_td ltx_align_center ltx_border_b" style="padding:2pt 17.1pt;">      63.33</td>
<td id="S4.T3.7.3.3" class="ltx_td ltx_align_center ltx_border_b" style="padding:2pt 17.1pt;">      81.11</td>
<td id="S4.T3.7.3.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r" style="padding:2pt 17.1pt;">      72.28</td>
<td id="S4.T3.7.3.5" class="ltx_td ltx_align_center ltx_border_b" style="padding:2pt 17.1pt;">      63.33</td>
<td id="S4.T3.7.3.6" class="ltx_td ltx_align_center ltx_border_b" style="padding:2pt 17.1pt;">      82.66</td>
<td id="S4.T3.7.3.7" class="ltx_td ltx_align_center ltx_border_b" style="padding:2pt 17.1pt;">      74.28</td>
</tr>
</tbody>
</table>
</figure>
<figure id="S4.T4" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 4: </span><math id="S4.T4.3.m1.1" class="ltx_Math" alttext="\gamma" display="inline"><semantics id="S4.T4.3.m1.1b"><mi id="S4.T4.3.m1.1.1" xref="S4.T4.3.m1.1.1.cmml">γ</mi><annotation-xml encoding="MathML-Content" id="S4.T4.3.m1.1c"><ci id="S4.T4.3.m1.1.1.cmml" xref="S4.T4.3.m1.1.1">𝛾</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.3.m1.1d">\gamma</annotation></semantics></math>changes from 0 to 2.0 when the interval is 0.2 in Eq. (<a href="#S3.E11" title="In 3.3.2 IQC loss ‣ 3.3 Composite Loss ‣ 3 MuVAM for Medical VQA ‣ MuVAM: A Multi-View Attention-based Model for Medical Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a>) . The accuracy of the proposed model is evaluated in the VQA-RAD<sup id="S4.T4.7.1" class="ltx_sup"><span id="S4.T4.7.1.1" class="ltx_text ltx_font_italic">Ph</span></sup> testset. </figcaption>
<table id="S4.T4.5" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T4.5.1" class="ltx_tr">
<th id="S4.T4.5.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t" style="padding:2.5pt 9.4pt;" rowspan="2"><span id="S4.T4.5.1.2.1" class="ltx_text">Method</span></th>
<th id="S4.T4.5.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" style="padding:2.5pt 9.4pt;" rowspan="2"><span id="S4.T4.5.1.3.1" class="ltx_text">Type</span></th>
<th id="S4.T4.5.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding:2.5pt 9.4pt;" colspan="11"><math id="S4.T4.5.1.1.m1.1" class="ltx_Math" alttext="\gamma" display="inline"><semantics id="S4.T4.5.1.1.m1.1a"><mi id="S4.T4.5.1.1.m1.1.1" xref="S4.T4.5.1.1.m1.1.1.cmml">γ</mi><annotation-xml encoding="MathML-Content" id="S4.T4.5.1.1.m1.1b"><ci id="S4.T4.5.1.1.m1.1.1.cmml" xref="S4.T4.5.1.1.m1.1.1">𝛾</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.5.1.1.m1.1c">\gamma</annotation></semantics></math></th>
</tr>
<tr id="S4.T4.5.2.1" class="ltx_tr">
<td id="S4.T4.5.2.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:2.5pt 9.4pt;">0</td>
<td id="S4.T4.5.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:2.5pt 9.4pt;">0.2</td>
<td id="S4.T4.5.2.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:2.5pt 9.4pt;">0.4</td>
<td id="S4.T4.5.2.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:2.5pt 9.4pt;">0.6</td>
<td id="S4.T4.5.2.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:2.5pt 9.4pt;">0.8</td>
<td id="S4.T4.5.2.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:2.5pt 9.4pt;">1.0</td>
<td id="S4.T4.5.2.1.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:2.5pt 9.4pt;">1.2</td>
<td id="S4.T4.5.2.1.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:2.5pt 9.4pt;">1.4</td>
<td id="S4.T4.5.2.1.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:2.5pt 9.4pt;"><span id="S4.T4.5.2.1.9.1" class="ltx_text ltx_font_bold">1.6</span></td>
<td id="S4.T4.5.2.1.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:2.5pt 9.4pt;">1.8</td>
<td id="S4.T4.5.2.1.11" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:2.5pt 9.4pt;">2.0</td>
</tr>
<tr id="S4.T4.5.3.2" class="ltx_tr">
<th id="S4.T4.5.3.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t" style="padding:2.5pt 9.4pt;" rowspan="3"><span id="S4.T4.5.3.2.1.1" class="ltx_text">MuVAM</span></th>
<th id="S4.T4.5.3.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding:2.5pt 9.4pt;">Open-ended</th>
<td id="S4.T4.5.3.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:2.5pt 9.4pt;">62.77</td>
<td id="S4.T4.5.3.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:2.5pt 9.4pt;">61.67</td>
<td id="S4.T4.5.3.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:2.5pt 9.4pt;">62.22</td>
<td id="S4.T4.5.3.2.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:2.5pt 9.4pt;">60.00</td>
<td id="S4.T4.5.3.2.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:2.5pt 9.4pt;">61.11</td>
<td id="S4.T4.5.3.2.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:2.5pt 9.4pt;">62.22</td>
<td id="S4.T4.5.3.2.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:2.5pt 9.4pt;">60.56</td>
<td id="S4.T4.5.3.2.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:2.5pt 9.4pt;">61.67</td>
<td id="S4.T4.5.3.2.11" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:2.5pt 9.4pt;"><span id="S4.T4.5.3.2.11.1" class="ltx_text ltx_font_bold">63.33</span></td>
<td id="S4.T4.5.3.2.12" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:2.5pt 9.4pt;">62.22</td>
<td id="S4.T4.5.3.2.13" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:2.5pt 9.4pt;">60.77</td>
</tr>
<tr id="S4.T4.5.4.3" class="ltx_tr">
<th id="S4.T4.5.4.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding:2.5pt 9.4pt;">Closed-ended</th>
<td id="S4.T4.5.4.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:2.5pt 9.4pt;">80.07</td>
<td id="S4.T4.5.4.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:2.5pt 9.4pt;">80.81</td>
<td id="S4.T4.5.4.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:2.5pt 9.4pt;">80.81</td>
<td id="S4.T4.5.4.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:2.5pt 9.4pt;">80.00</td>
<td id="S4.T4.5.4.3.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:2.5pt 9.4pt;">80.40</td>
<td id="S4.T4.5.4.3.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:2.5pt 9.4pt;">81.18</td>
<td id="S4.T4.5.4.3.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:2.5pt 9.4pt;">81.92</td>
<td id="S4.T4.5.4.3.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:2.5pt 9.4pt;">79.70</td>
<td id="S4.T4.5.4.3.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:2.5pt 9.4pt;"><span id="S4.T4.5.4.3.10.1" class="ltx_text ltx_font_bold">82.66</span></td>
<td id="S4.T4.5.4.3.11" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:2.5pt 9.4pt;">80.00</td>
<td id="S4.T4.5.4.3.12" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:2.5pt 9.4pt;">80.44</td>
</tr>
<tr id="S4.T4.5.5.4" class="ltx_tr">
<th id="S4.T4.5.5.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t" style="padding:2.5pt 9.4pt;">Overall</th>
<td id="S4.T4.5.5.4.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding:2.5pt 9.4pt;">72.50</td>
<td id="S4.T4.5.5.4.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding:2.5pt 9.4pt;">72.28</td>
<td id="S4.T4.5.5.4.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding:2.5pt 9.4pt;">72.06</td>
<td id="S4.T4.5.5.4.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding:2.5pt 9.4pt;">71.62</td>
<td id="S4.T4.5.5.4.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding:2.5pt 9.4pt;">71.62</td>
<td id="S4.T4.5.5.4.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding:2.5pt 9.4pt;">72.51</td>
<td id="S4.T4.5.5.4.8" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding:2.5pt 9.4pt;">72.51</td>
<td id="S4.T4.5.5.4.9" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding:2.5pt 9.4pt;">70.95</td>
<td id="S4.T4.5.5.4.10" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding:2.5pt 9.4pt;"><span id="S4.T4.5.5.4.10.1" class="ltx_text ltx_font_bold">74.28</span></td>
<td id="S4.T4.5.5.4.11" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding:2.5pt 9.4pt;">72.28</td>
<td id="S4.T4.5.5.4.12" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding:2.5pt 9.4pt;">71.39</td>
</tr>
</tbody>
</table>
</figure>
<div id="S4.SS4.p7" class="ltx_para">
<p id="S4.SS4.p7.1" class="ltx_p">The results of our model and other advanced methods using the VQA-RAD dataset are compared in TABLE <a href="#S4.T1" title="Table 1 ‣ 4.4 Baseline ‣ 4 Experiment ‣ MuVAM: A Multi-View Attention-based Model for Medical Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. It can be shown that our results are superior to other baseline models in open-ended, closed-ended questions and overall. Compared with the Med-VQA method, all accuracy rates are improved by about 3% on average. MuVAM models the relationship between text and vision. Benefiting from it, the questions and images can be better understood to generate satisfactory answers. This shows the importance of the association between each word and the image, thus demonstrats the effectiveness of the MuVAM.</p>
</div>
<div id="S4.SS4.p8" class="ltx_para">
<p id="S4.SS4.p8.3" class="ltx_p">We use the VQA-RAD<sup id="S4.SS4.p8.3.1" class="ltx_sup"><span id="S4.SS4.p8.3.1.1" class="ltx_text ltx_font_italic">Ph</span></sup> dataset to evaluate the Med-VQA <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> and the MuVAM proposed in this paper. The results in TABLE <a href="#S4.T2" title="Table 2 ‣ 4.4 Baseline ‣ 4 Experiment ‣ MuVAM: A Multi-View Attention-based Model for Medical Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> show that the MuVAM is more effective. The experimental effect of Med-VQA in the VQA-RAD<sup id="S4.SS4.p8.3.2" class="ltx_sup"><span id="S4.SS4.p8.3.2.1" class="ltx_text ltx_font_italic">Ph</span></sup> dataset is slightly inferior to the test results in the VQA-RAD dataset. The performance of MuVAM on open-ended questions in these two datasets is basically the same. The closed-ended questions and overall results are more prominent in the VQA-RAD<sup id="S4.SS4.p8.3.3" class="ltx_sup"><span id="S4.SS4.p8.3.3.1" class="ltx_text ltx_font_italic">Ph</span></sup> dataset.</p>
</div>
<figure id="S4.F5" class="ltx_figure">
<p id="S4.F5.1" class="ltx_p ltx_align_center"><span id="S4.F5.1.1" class="ltx_text"><img src="/html/2107.03216/assets/x5.png" id="S4.F5.1.1.g1" class="ltx_graphics ltx_img_landscape" width="922" height="735" alt="Refer to caption"></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>The visualization of the proposed model, each typical example includes image, question, ground-truth answer, and predicted answer. The rectangular box in the image represents the relevant region located by the model, and the black text of the question denotes the keywords involved. A refers to the ground-truth answer. The green and red content of P-A indicate that the answer predicted by the model is correct and wrong.</figcaption>
</figure>
</section>
<section id="S4.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.5 </span>Ablation Study</h3>

<div id="S4.SS5.p1" class="ltx_para">
<p id="S4.SS5.p1.1" class="ltx_p">In this section, complete ablation experiments was implemented to verify the performance of the I2Q attention and the IQC loss in MuVAM on the VQA-RAD<sup id="S4.SS5.p1.1.1" class="ltx_sup"><span id="S4.SS5.p1.1.1.1" class="ltx_text ltx_font_italic">Ph</span></sup> dataset and VQA-RAD dataset. The basic model is ”MEVF+BAN+TCR” with only classification loss in the loss module, which is called the baseline, where ”TCR” is a component from <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> and ”MEVF+BAN” is the method of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>. For fairness, the baseline is re-implemented for the following ablation studies when the experimental parameters and equipment are consistent with our experiments.</p>
</div>
<div id="S4.SS5.p2" class="ltx_para">
<p id="S4.SS5.p2.7" class="ltx_p">The experimental results of the ablation study are shown in TABLE <a href="#S4.T3" title="Table 3 ‣ 4.4 Baseline ‣ 4 Experiment ‣ MuVAM: A Multi-View Attention-based Model for Medical Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. The proposed components are evaluated on VQA-RAD and VQA-RAD<sup id="S4.SS5.p2.7.1" class="ltx_sup"><span id="S4.SS5.p2.7.1.1" class="ltx_text ltx_font_italic">Ph</span></sup> respectively. ”Baseline+att” is used to verify the I2Q attention. ”Baseline+<math id="S4.SS5.p2.2.m2.1" class="ltx_Math" alttext="L_{mq}" display="inline"><semantics id="S4.SS5.p2.2.m2.1a"><msub id="S4.SS5.p2.2.m2.1.1" xref="S4.SS5.p2.2.m2.1.1.cmml"><mi id="S4.SS5.p2.2.m2.1.1.2" xref="S4.SS5.p2.2.m2.1.1.2.cmml">L</mi><mrow id="S4.SS5.p2.2.m2.1.1.3" xref="S4.SS5.p2.2.m2.1.1.3.cmml"><mi id="S4.SS5.p2.2.m2.1.1.3.2" xref="S4.SS5.p2.2.m2.1.1.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S4.SS5.p2.2.m2.1.1.3.1" xref="S4.SS5.p2.2.m2.1.1.3.1.cmml">​</mo><mi id="S4.SS5.p2.2.m2.1.1.3.3" xref="S4.SS5.p2.2.m2.1.1.3.3.cmml">q</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS5.p2.2.m2.1b"><apply id="S4.SS5.p2.2.m2.1.1.cmml" xref="S4.SS5.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS5.p2.2.m2.1.1.1.cmml" xref="S4.SS5.p2.2.m2.1.1">subscript</csymbol><ci id="S4.SS5.p2.2.m2.1.1.2.cmml" xref="S4.SS5.p2.2.m2.1.1.2">𝐿</ci><apply id="S4.SS5.p2.2.m2.1.1.3.cmml" xref="S4.SS5.p2.2.m2.1.1.3"><times id="S4.SS5.p2.2.m2.1.1.3.1.cmml" xref="S4.SS5.p2.2.m2.1.1.3.1"></times><ci id="S4.SS5.p2.2.m2.1.1.3.2.cmml" xref="S4.SS5.p2.2.m2.1.1.3.2">𝑚</ci><ci id="S4.SS5.p2.2.m2.1.1.3.3.cmml" xref="S4.SS5.p2.2.m2.1.1.3.3">𝑞</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p2.2.m2.1c">L_{mq}</annotation></semantics></math>” represents a benchmark model with image-to-question complementary loss and the purpose is to improve the similarity between visual-text cross-modal features. ”Baseline+att+<math id="S4.SS5.p2.3.m3.1" class="ltx_Math" alttext="L_{mq}" display="inline"><semantics id="S4.SS5.p2.3.m3.1a"><msub id="S4.SS5.p2.3.m3.1.1" xref="S4.SS5.p2.3.m3.1.1.cmml"><mi id="S4.SS5.p2.3.m3.1.1.2" xref="S4.SS5.p2.3.m3.1.1.2.cmml">L</mi><mrow id="S4.SS5.p2.3.m3.1.1.3" xref="S4.SS5.p2.3.m3.1.1.3.cmml"><mi id="S4.SS5.p2.3.m3.1.1.3.2" xref="S4.SS5.p2.3.m3.1.1.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S4.SS5.p2.3.m3.1.1.3.1" xref="S4.SS5.p2.3.m3.1.1.3.1.cmml">​</mo><mi id="S4.SS5.p2.3.m3.1.1.3.3" xref="S4.SS5.p2.3.m3.1.1.3.3.cmml">q</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS5.p2.3.m3.1b"><apply id="S4.SS5.p2.3.m3.1.1.cmml" xref="S4.SS5.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS5.p2.3.m3.1.1.1.cmml" xref="S4.SS5.p2.3.m3.1.1">subscript</csymbol><ci id="S4.SS5.p2.3.m3.1.1.2.cmml" xref="S4.SS5.p2.3.m3.1.1.2">𝐿</ci><apply id="S4.SS5.p2.3.m3.1.1.3.cmml" xref="S4.SS5.p2.3.m3.1.1.3"><times id="S4.SS5.p2.3.m3.1.1.3.1.cmml" xref="S4.SS5.p2.3.m3.1.1.3.1"></times><ci id="S4.SS5.p2.3.m3.1.1.3.2.cmml" xref="S4.SS5.p2.3.m3.1.1.3.2">𝑚</ci><ci id="S4.SS5.p2.3.m3.1.1.3.3.cmml" xref="S4.SS5.p2.3.m3.1.1.3.3">𝑞</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p2.3.m3.1c">L_{mq}</annotation></semantics></math>” implies that the attention and loss items work together. It can be seen from the results that the cooperation between the two components is superior to that of any one of them, but those are better than the baseline. Horizontal comparison shows that the volatility of ”baseline+att” and ”baseline+<math id="S4.SS5.p2.4.m4.1" class="ltx_Math" alttext="L_{mq}" display="inline"><semantics id="S4.SS5.p2.4.m4.1a"><msub id="S4.SS5.p2.4.m4.1.1" xref="S4.SS5.p2.4.m4.1.1.cmml"><mi id="S4.SS5.p2.4.m4.1.1.2" xref="S4.SS5.p2.4.m4.1.1.2.cmml">L</mi><mrow id="S4.SS5.p2.4.m4.1.1.3" xref="S4.SS5.p2.4.m4.1.1.3.cmml"><mi id="S4.SS5.p2.4.m4.1.1.3.2" xref="S4.SS5.p2.4.m4.1.1.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S4.SS5.p2.4.m4.1.1.3.1" xref="S4.SS5.p2.4.m4.1.1.3.1.cmml">​</mo><mi id="S4.SS5.p2.4.m4.1.1.3.3" xref="S4.SS5.p2.4.m4.1.1.3.3.cmml">q</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS5.p2.4.m4.1b"><apply id="S4.SS5.p2.4.m4.1.1.cmml" xref="S4.SS5.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS5.p2.4.m4.1.1.1.cmml" xref="S4.SS5.p2.4.m4.1.1">subscript</csymbol><ci id="S4.SS5.p2.4.m4.1.1.2.cmml" xref="S4.SS5.p2.4.m4.1.1.2">𝐿</ci><apply id="S4.SS5.p2.4.m4.1.1.3.cmml" xref="S4.SS5.p2.4.m4.1.1.3"><times id="S4.SS5.p2.4.m4.1.1.3.1.cmml" xref="S4.SS5.p2.4.m4.1.1.3.1"></times><ci id="S4.SS5.p2.4.m4.1.1.3.2.cmml" xref="S4.SS5.p2.4.m4.1.1.3.2">𝑚</ci><ci id="S4.SS5.p2.4.m4.1.1.3.3.cmml" xref="S4.SS5.p2.4.m4.1.1.3.3">𝑞</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p2.4.m4.1c">L_{mq}</annotation></semantics></math>” is relatively large in the open-ended questions of the two datasets. However, when ”att” and ”<math id="S4.SS5.p2.5.m5.1" class="ltx_Math" alttext="L_{mq}" display="inline"><semantics id="S4.SS5.p2.5.m5.1a"><msub id="S4.SS5.p2.5.m5.1.1" xref="S4.SS5.p2.5.m5.1.1.cmml"><mi id="S4.SS5.p2.5.m5.1.1.2" xref="S4.SS5.p2.5.m5.1.1.2.cmml">L</mi><mrow id="S4.SS5.p2.5.m5.1.1.3" xref="S4.SS5.p2.5.m5.1.1.3.cmml"><mi id="S4.SS5.p2.5.m5.1.1.3.2" xref="S4.SS5.p2.5.m5.1.1.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S4.SS5.p2.5.m5.1.1.3.1" xref="S4.SS5.p2.5.m5.1.1.3.1.cmml">​</mo><mi id="S4.SS5.p2.5.m5.1.1.3.3" xref="S4.SS5.p2.5.m5.1.1.3.3.cmml">q</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS5.p2.5.m5.1b"><apply id="S4.SS5.p2.5.m5.1.1.cmml" xref="S4.SS5.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S4.SS5.p2.5.m5.1.1.1.cmml" xref="S4.SS5.p2.5.m5.1.1">subscript</csymbol><ci id="S4.SS5.p2.5.m5.1.1.2.cmml" xref="S4.SS5.p2.5.m5.1.1.2">𝐿</ci><apply id="S4.SS5.p2.5.m5.1.1.3.cmml" xref="S4.SS5.p2.5.m5.1.1.3"><times id="S4.SS5.p2.5.m5.1.1.3.1.cmml" xref="S4.SS5.p2.5.m5.1.1.3.1"></times><ci id="S4.SS5.p2.5.m5.1.1.3.2.cmml" xref="S4.SS5.p2.5.m5.1.1.3.2">𝑚</ci><ci id="S4.SS5.p2.5.m5.1.1.3.3.cmml" xref="S4.SS5.p2.5.m5.1.1.3.3">𝑞</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p2.5.m5.1c">L_{mq}</annotation></semantics></math>” work together, they have a stabilizing effect and the best results. Most of the experimental results of VQA-RAD<sup id="S4.SS5.p2.7.2" class="ltx_sup"><span id="S4.SS5.p2.7.2.1" class="ltx_text ltx_font_italic">Ph</span></sup> are also better than VQA-RAD, indicating that the VQA-RAD<sup id="S4.SS5.p2.7.3" class="ltx_sup"><span id="S4.SS5.p2.7.3.1" class="ltx_text ltx_font_italic">Ph</span></sup> dataset improves the data quality and enhances the data availability.</p>
</div>
</section>
<section id="S4.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.6 </span>Hyperparameter Analysis</h3>

<div id="S4.SS6.p1" class="ltx_para">
<p id="S4.SS6.p1.2" class="ltx_p">In this section, we assign different values to the hyperparameters <math id="S4.SS6.p1.1.m1.1" class="ltx_Math" alttext="\gamma" display="inline"><semantics id="S4.SS6.p1.1.m1.1a"><mi id="S4.SS6.p1.1.m1.1.1" xref="S4.SS6.p1.1.m1.1.1.cmml">γ</mi><annotation-xml encoding="MathML-Content" id="S4.SS6.p1.1.m1.1b"><ci id="S4.SS6.p1.1.m1.1.1.cmml" xref="S4.SS6.p1.1.m1.1.1">𝛾</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS6.p1.1.m1.1c">\gamma</annotation></semantics></math> of image-question complementary loss in Eq. (<a href="#S3.E11" title="In 3.3.2 IQC loss ‣ 3.3 Composite Loss ‣ 3 MuVAM for Medical VQA ‣ MuVAM: A Multi-View Attention-based Model for Medical Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a>) to analyze the performance of our proposed method. When different values of <math id="S4.SS6.p1.2.m2.1" class="ltx_Math" alttext="\gamma" display="inline"><semantics id="S4.SS6.p1.2.m2.1a"><mi id="S4.SS6.p1.2.m2.1.1" xref="S4.SS6.p1.2.m2.1.1.cmml">γ</mi><annotation-xml encoding="MathML-Content" id="S4.SS6.p1.2.m2.1b"><ci id="S4.SS6.p1.2.m2.1.1.cmml" xref="S4.SS6.p1.2.m2.1.1">𝛾</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS6.p1.2.m2.1c">\gamma</annotation></semantics></math> are set in three different types: Open-ended, Closed-ended and Overall, the detailed accuracies of the proposed model are verified in TABLE <a href="#S4.T4" title="Table 4 ‣ 4.4 Baseline ‣ 4 Experiment ‣ MuVAM: A Multi-View Attention-based Model for Medical Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
<div id="S4.SS6.p2" class="ltx_para">
<p id="S4.SS6.p2.4" class="ltx_p">The results show that the performance varies along with the <math id="S4.SS6.p2.1.m1.1" class="ltx_Math" alttext="\gamma" display="inline"><semantics id="S4.SS6.p2.1.m1.1a"><mi id="S4.SS6.p2.1.m1.1.1" xref="S4.SS6.p2.1.m1.1.1.cmml">γ</mi><annotation-xml encoding="MathML-Content" id="S4.SS6.p2.1.m1.1b"><ci id="S4.SS6.p2.1.m1.1.1.cmml" xref="S4.SS6.p2.1.m1.1.1">𝛾</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS6.p2.1.m1.1c">\gamma</annotation></semantics></math>. As shown in TABLE <a href="#S4.T4" title="Table 4 ‣ 4.4 Baseline ‣ 4 Experiment ‣ MuVAM: A Multi-View Attention-based Model for Medical Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, when <math id="S4.SS6.p2.2.m2.1" class="ltx_Math" alttext="\gamma" display="inline"><semantics id="S4.SS6.p2.2.m2.1a"><mi id="S4.SS6.p2.2.m2.1.1" xref="S4.SS6.p2.2.m2.1.1.cmml">γ</mi><annotation-xml encoding="MathML-Content" id="S4.SS6.p2.2.m2.1b"><ci id="S4.SS6.p2.2.m2.1.1.cmml" xref="S4.SS6.p2.2.m2.1.1">𝛾</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS6.p2.2.m2.1c">\gamma</annotation></semantics></math> is 1.6, the accuracies of the three types are particularly prominent. The best results that can be obtained are 63.33%, 82.66% and 74.28%, respectively. Compared with the accuracies when <math id="S4.SS6.p2.3.m3.1" class="ltx_Math" alttext="\gamma" display="inline"><semantics id="S4.SS6.p2.3.m3.1a"><mi id="S4.SS6.p2.3.m3.1.1" xref="S4.SS6.p2.3.m3.1.1.cmml">γ</mi><annotation-xml encoding="MathML-Content" id="S4.SS6.p2.3.m3.1b"><ci id="S4.SS6.p2.3.m3.1.1.cmml" xref="S4.SS6.p2.3.m3.1.1">𝛾</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS6.p2.3.m3.1c">\gamma</annotation></semantics></math> is 0, the three types have been improved, so it can prove again that the IQC loss has a significant effect on the MuVAM model. In the section of ablation study and baseline, we set <math id="S4.SS6.p2.4.m4.1" class="ltx_Math" alttext="\gamma" display="inline"><semantics id="S4.SS6.p2.4.m4.1a"><mi id="S4.SS6.p2.4.m4.1.1" xref="S4.SS6.p2.4.m4.1.1.cmml">γ</mi><annotation-xml encoding="MathML-Content" id="S4.SS6.p2.4.m4.1b"><ci id="S4.SS6.p2.4.m4.1.1.cmml" xref="S4.SS6.p2.4.m4.1.1">𝛾</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS6.p2.4.m4.1c">\gamma</annotation></semantics></math> to 1.6.</p>
</div>
</section>
<section id="S4.SS7" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.7 </span>Visualization Evaluation</h3>

<div id="S4.SS7.p1" class="ltx_para">
<p id="S4.SS7.p1.2" class="ltx_p">the visualization evaluation of the MuVAM model on the VQA-RAD<sup id="S4.SS7.p1.2.1" class="ltx_sup"><span id="S4.SS7.p1.2.1.1" class="ltx_text ltx_font_italic">Ph</span></sup> dataset is shown in Fig. (<a href="#S4.F5" title="Figure 5 ‣ 4.4 Baseline ‣ 4 Experiment ‣ MuVAM: A Multi-View Attention-based Model for Medical Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>). The rectangular box of the image is the key part of the positioning and the bold words in the question are the meaningful words learned by the attention mechanism. P-A represents the answer predicted by the method, where green indicates correct prediction, and red indicates incorrect prediction. <math id="S4.SS7.p1.2.m2.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S4.SS7.p1.2.m2.1a"><mi id="S4.SS7.p1.2.m2.1.1" xref="S4.SS7.p1.2.m2.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S4.SS7.p1.2.m2.1b"><ci id="S4.SS7.p1.2.m2.1.1.cmml" xref="S4.SS7.p1.2.m2.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS7.p1.2.m2.1c">A</annotation></semantics></math> is the ground-truth answer. MuVAM can find the visual information and the key words of the text involved in the VQA tasks accurately. Taking the first closed-ended question of the chest as an example, our method gives the correct answer to this question according to location of the relevant region and the keywords learned through the attention mechanism focus on ”nodule” . It is worth noting that the actual location of the radiograph image is the exact opposite of what we see. The second sample of the head, the ground-truth answer ”right side” is predicted by an accurate understanding of the question and the image.</p>
</div>
<div id="S4.SS7.p2" class="ltx_para">
<p id="S4.SS7.p2.1" class="ltx_p">However, our model cannot always predict correctly. On the one hand, some common sense and experience are involved. taking the third sample of the chest as an example, the questions need to be answered based on the experience of professional doctors. It is impossible to answer the questions based on the attention mechanism alone. The proposed model cannot satisfy the prediction of such related tasks. On the other hand, the model fails to locate keywords and visual content accurately. For example, in the third task of the head, the model does not pay attention to the keyword ”adnormalities” . This makes it impossible to predict the correct answer in the end. These observations can help us make subsequent improvements to the model.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this paper, MuVAM is proposed which can solve medical VQA tasks effectively. It contains three modules. First, two feature extraction methods are used in the feature extraction module to obtain image representation and question representation. Second, in order to maximize the application of semantic information, this paper proposes a multi-view attention module. It includes image-to-question (I2Q) attention and word-to-text (W2T) attention, which explore the potential impact on the question from the word and the image. Third, a compound loss module is proposed to train the model to improve the accuracy of MuVAM. It consists of classification loss and image-question complementary (IQC) loss. It is worth noting that the IQC loss uses image representation and text semantics to jointly guide the question importance learning to strengthen the role of similarity and weaken the difference in visual-text cross-modal features. Our experiment corrects and completes the VQA-RAD dataset and constructs an enhanced dataset called VQA-RAD<sup id="S5.p1.1.1" class="ltx_sup"><span id="S5.p1.1.1.1" class="ltx_text ltx_font_italic">Ph</span></sup> to improve data quality. Various ablation studies are demonstrated the effectiveness of the proposed components for medical VQA tasks. And our method outperforms the state-of-the-art method.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Z. Chen, X. Guo, P. Y. Woo, and Y. Yuan, “Super-resolution enhanced medical
image diagnosis with sample affinity interaction,” <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions
on Medical Imaging</em>, vol. 40, no. 5, pp. 1377–1389, 2021.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
W. A. Al and I. D. Yun, “Partial policy-based reinforcement learning for
anatomical landmark localization in 3d medical images,” <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">IEEE
transactions on medical imaging</em>, vol. 39, no. 4, pp. 1245–1255, 2019.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
A. Jungo, R. Meier, E. Ermis, M. Blatti-Moreno, E. Herrmann, R. Wiest, and
M. Reyes, “On the effect of inter-observer variability for a reliable
estimation of uncertainty of medical image segmentation,” in
<em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">International Conference on Medical Image Computing and
Computer-Assisted Intervention</em>.   Springer, 2018, pp. 682–690.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Y. Tang, Y. Tang, Y. Zhu, J. Xiao, and R. M. Summers, “A disentangled
generative model for disease decomposition in chest x-rays via normal image
synthesis,” <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Medical Image Analysis</em>, vol. 67, p. 101839, 2021.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
H. Abdeltawab, F. Khalifa, F. Taher, N. S. Alghamdi, M. Ghazal, G. Beache,
T. Mohamed, R. Keynton, and A. El-Baz, “A deep learning-based approach for
automatic segmentation and quantification of the left ventricle from cardiac
cine mr images,” <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Computerized Medical Imaging and Graphics</em>, vol. 81,
p. 101717, 2020.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
X. Li, M. Cui, J. Li, R. Bai, Z. Lu, and U. Aickelin, “A hybrid medical text
classification framework: Integrating attentive rule construction and neural
network,” <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">Neurocomputing</em>, vol. 443, pp. 345–355, 2021.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Y. Fan, S. Zhou, Y. Li, and R. Zhang, “Deep learning approaches for extracting
adverse events and indications of dietary supplements from clinical text,”
<em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">Journal of the American Medical Informatics Association</em>, vol. 28,
no. 3, pp. 569–577, 2021.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
M. Alfano, B. Lenzitti, G. L. Bosco, C. Muriana, T. Piazza, and G. Vizzini,
“Design, development and validation of a system for automatic help to
medical text understanding,” <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">International journal of medical
informatics</em>, vol. 138, p. 104109, 2020.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
J.-J. Qiu, J. Yin, W. Qian, J.-H. Liu, Z.-X. Huang, H.-P. Yu, L. Ji, and X.-X.
Zeng, “A novel multiresolution-statistical texture analysis architecture:
Radiomics-aided diagnosis of pdac based on plain ct images,” <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">IEEE
Transactions on Medical Imaging</em>, 2020.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
H. Wang, S. N. Ahmed, and M. Mandal, “Computer-aided diagnosis of cavernous
malformations in brain mr images,” <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">Computerized Medical Imaging and
Graphics</em>, vol. 66, pp. 115–123, 2018.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Y. Ma, T. Xu, X. Huang, X. Wang, C. Li, J. Jerwick, Y. Ning, X. Zeng, B. Wang,
Y. Wang <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Computer-aided diagnosis of label-free 3-d optical
coherence microscopy images of human cervical tissue,” <em id="bib.bib11.2.2" class="ltx_emph ltx_font_italic">IEEE
Transactions on Biomedical Engineering</em>, vol. 66, no. 9, pp. 2447–2456,
2019.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
B. D. Nguyen, T.-T. Do, B. X. Nguyen, T. Do, E. Tjiputra, and Q. D. Tran,
“Overcoming data limitation in medical visual question answering,” in
<em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">International Conference on Medical Image Computing and
Computer-Assisted Intervention</em>.   Springer, 2019, pp. 522–530.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
L.-M. Zhan, B. Liu, L. Fan, J. Chen, and X.-M. Wu, “Medical visual question
answering via conditional reasoning,” in <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 28th ACM
International Conference on Multimedia</em>, 2020, pp. 2345–2354.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
M. H. Vu, T. Löfstedt, T. Nyholm, and R. Sznitman, “A question-centric
model for visual question answering in medical imaging,” <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">IEEE
transactions on medical imaging</em>, vol. 39, no. 9, pp. 2856–2868, 2020.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
X. Xie, J. Niu, X. Liu, Z. Chen, S. Tang, and S. Yu, “A survey on
incorporating domain knowledge into deep learning for medical image
analysis,” <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">Medical Image Analysis</em>, p. 101985, 2021.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
C. Finn, P. Abbeel, and S. Levine, “Model-agnostic meta-learning for fast
adaptation of deep networks,” in <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine
Learning</em>.   PMLR, 2017, pp. 1126–1135.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
J. Masci, U. Meier, D. Cireşan, and J. Schmidhuber, “Stacked
convolutional auto-encoders for hierarchical feature extraction,” in
<em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">International conference on artificial neural networks</em>.   Springer, 2011, pp. 52–59.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
J. J. Lau, S. Gayen, A. B. Abacha, and D. Demner-Fushman, “A dataset of
clinically generated visual questions and answers about radiology images,”
<em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">Scientific data</em>, vol. 5, no. 1, pp. 1–10, 2018.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
S. Antol, A. Agrawal, J. Lu, M. Mitchell, D. Batra, C. L. Zitnick, and
D. Parikh, “Vqa: Visual question answering,” in <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">Proceedings of the
IEEE international conference on computer vision</em>, 2015, pp. 2425–2433.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
S. Hochreiter and J. Schmidhuber, “Long short-term memory,” <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">Neural
computation</em>, vol. 9, no. 8, pp. 1735–1780, 1997.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
K. Cho, B. Van Merriënboer, C. Gulcehre, D. Bahdanau, F. Bougares,
H. Schwenk, and Y. Bengio, “Learning phrase representations using rnn
encoder-decoder for statistical machine translation,” <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:1406.1078</em>, 2014.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
R. Kiros, Y. Zhu, R. Salakhutdinov, R. S. Zemel, A. Torralba, R. Urtasun, and
S. Fidler, “Skip-thought vectors,” <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1506.06726</em>,
2015.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
S. Ren, K. He, R. Girshick, and J. Sun, “Faster r-cnn: towards real-time
object detection with region proposal networks,” <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">IEEE transactions on
pattern analysis and machine intelligence</em>, vol. 39, no. 6, pp. 1137–1149,
2016.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
D. Teney, P. Anderson, X. He, and A. Van Den Hengel, “Tips and tricks for
visual question answering: Learnings from the 2017 challenge,” in
<em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE conference on computer vision and pattern
recognition</em>, 2018, pp. 4223–4232.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
K. Saito, A. Shin, Y. Ushiku, and T. Harada, “Dualnet: Domain-invariant
network for visual question answering,” in <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">2017 IEEE International
Conference on Multimedia and Expo (ICME)</em>.   IEEE, 2017, pp. 829–834.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
B. Zhou, Y. Tian, S. Sukhbaatar, A. Szlam, and R. Fergus, “Simple baseline for
visual question answering,” <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1512.02167</em>, 2015.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
H. Ben-Younes, R. Cadene, M. Cord, and N. Thome, “Mutan: Multimodal tucker
fusion for visual question answering,” in <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE
international conference on computer vision</em>, 2017, pp. 2612–2620.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
Z. Yu, J. Yu, J. Fan, and D. Tao, “Multi-modal factorized bilinear pooling
with co-attention learning for visual question answering,” in
<em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE international conference on computer vision</em>,
2017, pp. 1821–1830.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
Z. Yu, J. Yu, C. Xiang, J. Fan, and D. Tao, “Beyond bilinear: Generalized
multimodal factorized high-order pooling for visual question answering,”
<em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">IEEE transactions on neural networks and learning systems</em>, vol. 29,
no. 12, pp. 5947–5959, 2018.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
A. Fukui, D. H. Park, D. Yang, A. Rohrbach, T. Darrell, and M. Rohrbach,
“Multimodal compact bilinear pooling for visual question answering and
visual grounding,” <em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1606.01847</em>, 2016.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
J.-H. Kim, K.-W. On, W. Lim, J. Kim, J.-W. Ha, and B.-T. Zhang, “Hadamard
product for low-rank bilinear pooling,” <em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:1610.04325</em>, 2016.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
J.-H. Kim, J. Jun, and B.-T. Zhang, “Bilinear attention networks,”
<em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1805.07932</em>, 2018.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
Q. Li, J. Fu, D. Yu, T. Mei, and J. Luo, “Tell-and-answer: Towards explainable
visual question answering using attributes and captions,” <em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">arXiv
preprint arXiv:1801.09041</em>, 2018.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
Q. Wu, C. Shen, P. Wang, A. Dick, and A. Van Den Hengel, “Image captioning and
visual question answering based on attributes and external knowledge,”
<em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">IEEE transactions on pattern analysis and machine intelligence</em>,
vol. 40, no. 6, pp. 1367–1381, 2017.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
P. Wang, Q. Wu, C. Shen, and A. van den Hengel, “The vqa-machine: Learning how
to use existing vision algorithms to answer new questions,” in
<em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE Conference on Computer Vision and Pattern
Recognition</em>, 2017, pp. 1173–1182.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
G. Li, H. Su, and W. Zhu, “Incorporating external knowledge to answer
open-domain visual questions with dynamic memory networks,” <em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">arXiv
preprint arXiv:1712.00733</em>, 2017.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
Q. Wu, P. Wang, C. Shen, A. Dick, and A. Van Den Hengel, “Ask me anything:
Free-form visual question answering based on knowledge from external
sources,” in <em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE conference on computer vision and
pattern recognition</em>, 2016, pp. 4622–4630.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
L. Li, Z. Gan, Y. Cheng, and J. Liu, “Relation-aware graph attention network
for visual question answering,” in <em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF
International Conference on Computer Vision</em>, 2019, pp. 10 313–10 322.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
P. Anderson, X. He, C. Buehler, D. Teney, M. Johnson, S. Gould, and L. Zhang,
“Bottom-up and top-down attention for image captioning and visual question
answering,” in <em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE conference on computer vision
and pattern recognition</em>, 2018, pp. 6077–6086.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
W. Guo, Y. Zhang, X. Wu, J. Yang, X. Cai, and X. Yuan, “Re-attention for
visual question answering,” in <em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI Conference on
Artificial Intelligence</em>, vol. 34, no. 01, 2020, pp. 91–98.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
D. Lee, Y. Cheon, and W.-S. Han, “Regularizing attention networks for anomaly
detection in visual question answering,” <em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:2009.10054</em>, 2020.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
T. Do, B. X. Nguyen, E. Tjiputra, M. Tran, Q. D. Tran, and A. Nguyen,
“Multiple meta-model quantifying for medical visual question answering,”
<em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2105.08913</em>, 2021.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
Z. Yang, X. He, J. Gao, L. Deng, and A. Smola, “Stacked attention networks for
image question answering,” in <em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE conference on
computer vision and pattern recognition</em>, 2016, pp. 21–29.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2107.03215" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2107.03216" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2107.03216">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2107.03216" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2107.03217" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sat Mar  9 01:36:55 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
