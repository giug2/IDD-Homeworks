<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2205.03257] Synthetic Data - what, why and how?</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Synthetic Data - what, why and how?">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Synthetic Data - what, why and how?">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2205.03257">

<!--Generated on Mon Mar 11 12:43:31 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<div id="id2" class="ltx_titlepage">
<div id="id2.2" class="ltx_block">
<p id="id2.2.1" class="ltx_p ltx_align_center"><span id="id2.2.1.1" class="ltx_text ltx_font_bold" style="font-size:173%;">Synthetic Data - what, why and how?<span id="id2.2.1.1.1" class="ltx_text ltx_font_medium"></span></span></p>
<table id="id2.2.2" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="id2.2.2.1.1" class="ltx_tr">
<td id="id2.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="id2.2.2.1.1.1.1" class="ltx_text" style="font-size:120%;">James Jordon</span></td>
<td id="id2.2.2.1.1.2" class="ltx_td ltx_nopad_l ltx_align_center"><span id="id2.2.2.1.1.2.1" class="ltx_text" style="font-size:120%;">Lukasz Szpruch</span></td>
</tr>
<tr id="id2.2.2.2.2" class="ltx_tr">
<td id="id2.2.2.2.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="id2.2.2.2.2.1.1" class="ltx_text" style="font-size:120%;">jjordon@turing.ac.uk</span></td>
<td id="id2.2.2.2.2.2" class="ltx_td ltx_nopad_l ltx_align_center"><span id="id2.2.2.2.2.2.1" class="ltx_text" style="font-size:120%;">l.szpruch@ed.ac.uk</span></td>
</tr>
<tr id="id2.2.2.3.3" class="ltx_tr">
<td id="id2.2.2.3.3.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="id2.2.2.3.3.1.1" class="ltx_text" style="font-size:120%;">Florimond Houssiau</span></td>
<td id="id2.2.2.3.3.2" class="ltx_td ltx_nopad_l ltx_align_center"><span id="id2.2.2.3.3.2.1" class="ltx_text" style="font-size:120%;">Mirko Bottarelli</span></td>
</tr>
<tr id="id2.2.2.4.4" class="ltx_tr">
<td id="id2.2.2.4.4.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="id2.2.2.4.4.1.1" class="ltx_text" style="font-size:120%;">fhoussiau@turing.ac.uk</span></td>
<td id="id2.2.2.4.4.2" class="ltx_td ltx_nopad_l ltx_align_center"><span id="id2.2.2.4.4.2.1" class="ltx_text" style="font-size:120%;">mirko.bottarelli@warwick.ac.uk</span></td>
</tr>
<tr id="id2.2.2.5.5" class="ltx_tr">
<td id="id2.2.2.5.5.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="id2.2.2.5.5.1.1" class="ltx_text" style="font-size:120%;">Giovanni Cherubin</span></td>
<td id="id2.2.2.5.5.2" class="ltx_td ltx_nopad_l ltx_align_center"><span id="id2.2.2.5.5.2.1" class="ltx_text" style="font-size:120%;">Carsten Maple</span></td>
</tr>
<tr id="id2.2.2.6.6" class="ltx_tr">
<td id="id2.2.2.6.6.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="id2.2.2.6.6.1.1" class="ltx_text" style="font-size:120%;">gcherubin@turing.ac.uk</span></td>
<td id="id2.2.2.6.6.2" class="ltx_td ltx_nopad_l ltx_align_center"><span id="id2.2.2.6.6.2.1" class="ltx_text" style="font-size:120%;">cm@warwick.ac.uk</span></td>
</tr>
<tr id="id2.2.2.7.7" class="ltx_tr">
<td id="id2.2.2.7.7.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="id2.2.2.7.7.1.1" class="ltx_text" style="font-size:120%;">Samuel N. Cohen</span></td>
<td id="id2.2.2.7.7.2" class="ltx_td ltx_nopad_l ltx_align_center"><span id="id2.2.2.7.7.2.1" class="ltx_text" style="font-size:120%;">Adrian Weller</span></td>
</tr>
<tr id="id2.2.2.8.8" class="ltx_tr">
<td id="id2.2.2.8.8.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="id2.2.2.8.8.1.1" class="ltx_text" style="font-size:120%;">scohen@turing.ac.uk</span></td>
<td id="id2.2.2.8.8.2" class="ltx_td ltx_nopad_l ltx_align_center"><span id="id2.2.2.8.8.2.1" class="ltx_text" style="font-size:120%;">aweller@turing.ac.uk</span></td>
</tr>
</tbody>
</table>
<img src="/html/2205.03257/assets/images/atiblack.png" id="id1.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="224" height="99" alt="[Uncaptioned image]"><img src="/html/2205.03257/assets/images/rslogo.png" id="id2.2.g2" class="ltx_graphics ltx_centering ltx_img_landscape" width="187" height="99" alt="[Uncaptioned image]">
<br class="ltx_break ltx_centering">
<p id="id2.2.3" class="ltx_p ltx_align_center"><span id="id2.2.3.1" class="ltx_text" style="font-size:120%;">This report was commissioned by the Royal Society.</span></p>
</div>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Executive Summary</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">This explainer document aims to provide an overview of the current state of the rapidly expanding work on synthetic data technologies, with a particular focus on privacy. The article is intended for a non-technical audience, though some formal definitions have been given to provide clarity to specialists. This article is intended to enable the reader to quickly become familiar with the notion of synthetic data, as well as understand some of the subtle intricacies that come with it. We do believe that synthetic data is a very useful tool, and our hope is that this report highlights that, while drawing attention to nuances that can easily be overlooked in its deployment.</p>
</div>
<div id="Sx1.p2" class="ltx_para">
<p id="Sx1.p2.1" class="ltx_p">The following are the key messages that we hope to convey.</p>
</div>
<section id="Sx1.SS0.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Synthetic data is a technology with significant promise.</h5>

<div id="Sx1.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="Sx1.SS0.SSS0.Px1.p1.1" class="ltx_p">There are many applications of synthetic data: privacy, fairness, and data augmentation, to name a few. Each of these applications has the potential for a tremendous impact but also comes with risks.</p>
</div>
</section>
<section id="Sx1.SS0.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Synthetic data can accelerate development.</h5>

<div id="Sx1.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="Sx1.SS0.SSS0.Px2.p1.1" class="ltx_p">Good quality synthetic data can significantly accelerate data science projects and reduce the cost of the software development lifecycle. When combined with secure research environments and federated learning techniques, it contributes to data democratisation.</p>
</div>
</section>
<section id="Sx1.SS0.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Synthetic data is not automatically private.</h5>

<div id="Sx1.SS0.SSS0.Px3.p1" class="ltx_para">
<p id="Sx1.SS0.SSS0.Px3.p1.1" class="ltx_p">A common misconception with synthetic data is that it is inherently private. This is not the case. Synthetic data has the capacity to leak information about the data it was derived from and is vulnerable to privacy attacks. Significant care is required to produce synthetic data that is useful and comes with privacy guarantees.</p>
</div>
</section>
<section id="Sx1.SS0.SSS0.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Synthetic data is not a replacement for real data.</h5>

<div id="Sx1.SS0.SSS0.Px4.p1" class="ltx_para">
<p id="Sx1.SS0.SSS0.Px4.p1.1" class="ltx_p">Synthetic data that comes with privacy guarantees is necessarily a distorted version of the real data. Therefore, any modelling or inference performed on synthetic data comes with additional risks. It is our belief that synthetic data should be used as a tool to accelerate the “research pipeline” but, ultimately, any final tools (that will be deployed in the real world) should be evaluated, and if necessary, fine-tuned, on the real data.</p>
</div>
</section>
<section id="Sx1.SS0.SSS0.Px5" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Outliers are hard to capture privately.</h5>

<div id="Sx1.SS0.SSS0.Px5.p1" class="ltx_para">
<p id="Sx1.SS0.SSS0.Px5.p1.1" class="ltx_p">Outliers and low probability events, as are often found in real data, are particularly difficult to capture and include in a synthetic dataset in a private way. For example, it would be very difficult to “hide” a multi-billionaire in synthetic data that contained information about wealth. A synthetic data generator would either not accurately replicate statistics regarding the very wealthy or would reveal potentially private information about these individuals.</p>
</div>
</section>
<section id="Sx1.SS0.SSS0.Px6" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Empirically evaluating the privacy of a single dataset can be problematic.</h5>

<div id="Sx1.SS0.SSS0.Px6.p1" class="ltx_para">
<p id="Sx1.SS0.SSS0.Px6.p1.1" class="ltx_p">Rigorous notions of privacy (e.g differential privacy) are a requirement on the <span id="Sx1.SS0.SSS0.Px6.p1.1.1" class="ltx_text ltx_font_italic">mechanism that generated</span> a synthetic dataset, rather than on the dataset itself. It is not possible to rigorously evaluate the privacy of a given synthetic dataset by directly comparing it with real data. Empirical evaluations can prove useful as tools to detect possible flaws in an algorithm or its implementation but may lead to false claims of privacy when there is none.</p>
</div>
</section>
<section id="Sx1.SS0.SSS0.Px7" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Black box models can be particularly opaque when it comes to generating synthetic data.</h5>

<div id="Sx1.SS0.SSS0.Px7.p1" class="ltx_para">
<p id="Sx1.SS0.SSS0.Px7.p1.1" class="ltx_p">Overparametrised generative models excel in producing high-dimensional synthetic data, but the levels of accuracy and privacy of these datasets are hard to estimate and can vary significantly across produced data points.</p>
</div>
</section>
<section id="Sx1.SS0.SSS0.Px8" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Synthetic data goes beyond privacy.</h5>

<div id="Sx1.SS0.SSS0.Px8.p1" class="ltx_para">
<p id="Sx1.SS0.SSS0.Px8.p1.1" class="ltx_p">Synthetic data provides promising tools to improve fairness, bias and the robustness of machine learning systems, but significantly more research is required to fully understand the opportunities and the limitations of this approach.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
<nav class="ltx_TOC ltx_list_toc ltx_toc_toc"><h6 class="ltx_title ltx_title_contents">Contents</h6>
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section">
<a href="#S1" title="In Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S1.SS1" title="In 1 Introduction ‣ Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1.1 </span>Report Structure</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a href="#S2" title="In Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>What is Synthetic Data?</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a href="#S2.SS1" title="In 2 What is Synthetic Data? ‣ Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Can synthetic data replace real data?</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S2.SS1.SSS1" title="In 2.1 Can synthetic data replace real data? ‣ 2 What is Synthetic Data? ‣ Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1.1 </span>How should we approach doing things <span class="ltx_text ltx_font_italic">with</span> synthetic data?</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S2.SS1.SSS2" title="In 2.1 Can synthetic data replace real data? ‣ 2 What is Synthetic Data? ‣ Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1.2 </span>Data Linking</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S2.SS2" title="In 2 What is Synthetic Data? ‣ Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Combining Synthetic Data with Other Technologies</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a href="#S3" title="In Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Why use Synthetic Data?</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S3.SS1" title="In 3 Why use Synthetic Data? ‣ Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Private Data Release</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S3.SS2" title="In 3 Why use Synthetic Data? ‣ Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>De-biasing</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S3.SS3" title="In 3 Why use Synthetic Data? ‣ Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Data Augmentation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a href="#S4" title="In Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Privacy in Machine Learning - An Overview</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S4.SS1" title="In 4 Privacy in Machine Learning - An Overview ‣ Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>The Threat Model View</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a href="#S4.SS2" title="In 4 Privacy in Machine Learning - An Overview ‣ Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Differential Privacy</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S4.SS2.SSS1" title="In 4.2 Differential Privacy ‣ 4 Privacy in Machine Learning - An Overview ‣ Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.1 </span>Limits of DP</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a href="#S5" title="In Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Utility, Fidelity and Privacy of Synthetic Data.</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S5.SS1" title="In 5 Utility, Fidelity and Privacy of Synthetic Data. ‣ Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Synthetic Data Desiderata</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a href="#S6" title="In Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Auditing Synthetic Data</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S6.SS1" title="In 6 Auditing Synthetic Data ‣ Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.1 </span>Empirically Evaluating the Privacy of Synthetic Data</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a href="#S6.SS2" title="In 6 Auditing Synthetic Data ‣ Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.2 </span>Evaluating the Utility and Fidelity of Synthetic Datasets</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S6.SS2.SSS1" title="In 6.2 Evaluating the Utility and Fidelity of Synthetic Datasets ‣ 6 Auditing Synthetic Data ‣ Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.2.1 </span>Utility-driven evaluation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S6.SS2.SSS2" title="In 6.2 Evaluating the Utility and Fidelity of Synthetic Datasets ‣ 6 Auditing Synthetic Data ‣ Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.2.2 </span>Fidelity-driven evaluation</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a href="#S7" title="In Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Private Synthetic Data Generation</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S7.SS1" title="In 7 Private Synthetic Data Generation ‣ Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.1 </span>Existing Methods and Technologies</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S7.SS2" title="In 7 Private Synthetic Data Generation ‣ Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.2 </span>Partially Synthetic Data</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a href="#S8" title="In Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8 </span>De-biased Synthetic Data Generation</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S8.SS1" title="In 8 De-biased Synthetic Data Generation ‣ Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8.1 </span>Notions of Fairness</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S8.SS2" title="In 8 De-biased Synthetic Data Generation ‣ Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8.2 </span>Limitations of Fair Synthetic Data Generation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S8.SS3" title="In 8 De-biased Synthetic Data Generation ‣ Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8.3 </span>Existing Methods</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S8.SS4" title="In 8 De-biased Synthetic Data Generation ‣ Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8.4 </span>Evaluating Utility and Fidelity</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a href="#S9" title="In Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">9 </span>Data Augmentation</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S9.SS1" title="In 9 Data Augmentation ‣ Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">9.1 </span>The Basic Principle</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S9.SS2" title="In 9 Data Augmentation ‣ Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">9.2 </span>What methods are used?</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a href="#S10" title="In Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">10 </span>Generative Modelling - An Overview</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a href="#S10.SS1" title="In 10 Generative Modelling - An Overview ‣ Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">10.1 </span>Existing Methodologies</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S10.SS1.SSS1" title="In 10.1 Existing Methodologies ‣ 10 Generative Modelling - An Overview ‣ Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">10.1.1 </span>Tabular data</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S10.SS1.SSS2" title="In 10.1 Existing Methodologies ‣ 10 Generative Modelling - An Overview ‣ Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">10.1.2 </span>Time-series data</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S10.SS1.SSS3" title="In 10.1 Existing Methodologies ‣ 10 Generative Modelling - An Overview ‣ Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">10.1.3 </span>Images</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S10.SS1.SSS4" title="In 10.1 Existing Methodologies ‣ 10 Generative Modelling - An Overview ‣ Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">10.1.4 </span>Audio</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S10.SS1.SSS5" title="In 10.1 Existing Methodologies ‣ 10 Generative Modelling - An Overview ‣ Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">10.1.5 </span>Video</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a href="#S11" title="In Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">11 </span>Messages from Industry/Start-ups</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a href="#S12" title="In Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">12 </span>Conclusion</span></a></li>
</ol></nav>
</section>
</section>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">The availability of high volume, high velocity and high variety datasets, together with advanced statistical tools for extracting information, has the potential to improve decision-making and accelerate research and innovation. At the same time, many large-scale datasets are highly sensitive (e.g. in health or finance) and sharing them may violate fundamental rights guarded by modern privacy regulations (e.g. GDPR or CCPA). A large number of real-world examples demonstrate that high-dimensional, often sparse, datasets are inherently vulnerable to privacy attacks and that existing anonymisation techniques do not provide adequate protection. This limits our ability to share these large datasets, creating a bottleneck on the development and deployment of machine learning and data science methods.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Synthetic data is generated by a model, often with the purpose of using it in place of real data. By controlling the data generation process, the end-user can, in principle, adjust the amount of private information released by synthetic data and control its resemblance to real data. As well as addressing privacy concerns, one can to adjust for biases in historical datasets and to produce plausible hypothetical scenarios.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">If used responsibly, synthetic data promises to enable learning across datasets when the privacy of the data needs to be preserved; or when data is incomplete, scarce or biased. It can help researchers and developers prototype data-driven models and be used to verify and validate machine learning pipelines, providing some assurance of performance. It can also fuel responsible innovation by creating digital sandbox environments used by startups and researchers in hackathon-style events.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">Each of these uses presents great opportunities, but also challenges that require tailor-made solutions. Synthetic data generation is a developing area of research, and systematic frameworks that would enable the deployment of this technology safely and responsibly are still missing.</p>
</div>
<section id="S1.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.1 </span>Report Structure</h3>

<div id="S1.SS1.p1" class="ltx_para">
<p id="S1.SS1.p1.1" class="ltx_p">This explainer is organised as follows. In Section <a href="#S2" title="2 What is Synthetic Data? ‣ Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> we introduce a definition for synthetic data, give a brief history of its inception, and begin to answer one of the core questions surrounding synthetic data: <span id="S1.SS1.p1.1.1" class="ltx_text ltx_font_italic">can it replace replace real data?</span> In Section <a href="#S3" title="3 Why use Synthetic Data? ‣ Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, we introduce key machine learning applications for synthetic data.</p>
</div>
<div id="S1.SS1.p2" class="ltx_para">
<p id="S1.SS1.p2.1" class="ltx_p">Sections <a href="#S4" title="4 Privacy in Machine Learning - An Overview ‣ Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>-<a href="#S7" title="7 Private Synthetic Data Generation ‣ Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> are dedicated to private synthetic data generation. In Section <a href="#S4" title="4 Privacy in Machine Learning - An Overview ‣ Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, we introduce privacy from a more general perspective than synthetic data, introducing differential privacy and discussing some of its limitations. In Section <a href="#S5" title="5 Utility, Fidelity and Privacy of Synthetic Data. ‣ Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> we discuss three key attributes for evaluation of private synthetic data: utility, fidelity, and privacy. In Section <a href="#S6" title="6 Auditing Synthetic Data ‣ Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>, we discuss empirical evaluations of synthetic data for these key attributes. In Section <a href="#S7" title="7 Private Synthetic Data Generation ‣ Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>, we discuss key differences between general privacy, and privacy as applied to the generation of synthetic data. We also survey existing methods in the space of private synthetic data generation. At the end of the section we discuss partially synthetic data, in which synthetic data is generated to create a hybrid real-synthetic dataset.</p>
</div>
<div id="S1.SS1.p3" class="ltx_para">
<p id="S1.SS1.p3.1" class="ltx_p">In Sections <a href="#S8" title="8 De-biased Synthetic Data Generation ‣ Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> and <a href="#S9" title="9 Data Augmentation ‣ Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a> we discuss synthetic data for fairness and data augmentation. In Section <a href="#S10" title="10 Generative Modelling - An Overview ‣ Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a>, we provide a more in-depth survey of existing generative models. Finally, in Section <a href="#S11" title="11 Messages from Industry/Start-ups ‣ Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a>, we summarise key themes from discussions with industry partners and start-ups in the field of synthetic data.</p>
</div>
</section>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>What is Synthetic Data?</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">Despite tremendous interest in synthetic data, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>, to the best of our knowledge there is no widely accepted definition. In order to encapsulate the full breadth of applications and approaches to synthetic data, we propose the following definition.</p>
</div>
<div id="Thmdefinition1" class="ltx_theorem ltx_theorem_definition">
<h6 class="ltx_title ltx_runin ltx_title_theorem"><span class="ltx_tag ltx_tag_theorem"><span id="Thmdefinition1.1.1.1" class="ltx_text ltx_font_bold">Definition 1</span></span></h6>
<div id="Thmdefinition1.p1" class="ltx_para">
<p id="Thmdefinition1.p1.1" class="ltx_p"><span id="Thmdefinition1.p1.1.1" class="ltx_text ltx_font_italic">Synthetic data is data that has been generated using a purpose-built mathematical model or algorithm, with the aim of solving a (set of) data science task(s).</span></p>
</div>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">We contrast synthetic data with real data, which is generated not by a model but by real world systems (e.g financial transactions, satellite images, medical tests etc.). The <span id="S2.p2.1.1" class="ltx_text ltx_font_italic">model</span> – the synthetic data generator – can take many forms, from deep learning architectures such as the popular Generative Adversarial Networks (GANs) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>, or Variational Auto-encoders (VAEs) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>, through agent-based and econometric models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>, to a set of (stochastic) differential equations modeling a physical or economic system <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">Using computer-generated synthetic data to solve particular tasks is not a new idea, and can be dated back at least as far as the pioneering work of Stanislaw Ulam and John von Neumann in the 1940s on Monte Carlo simulation methods. Synthetically generated data has been widely used in research, as it provides a ‘ground truth’, which is very useful in developing and evaluating machine learning pipelines.</p>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.1" class="ltx_p">The recent increase in data protection regulations has fueled the use of synthetic data to mitigate disclosure risk. The key hope, which goes back to work by Rubin and Little, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>, is to be able to use synthetic data in place of real data, to avoid privacy concerns <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>.</p>
</div>
<div id="S2.p5" class="ltx_para">
<p id="S2.p5.1" class="ltx_p">The need to extract actionable information from large datasets led to the development of complex, data-driven (machine learning) models. For these models, the role of data in driving model selection is more prominent than it is for simpler, handcrafted models. This means that the quality of the model’s output is directly dependent on the quality of the data used to train these models. This leads to a number of uses for synthetically generated data.
One such use is bias removal (e.g. historical biases in gender or race) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>, <a href="#bib.bib22" title="" class="ltx_ref">22</a>, <a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>. Given biased training data, a natural approach is to train models using available data; these biases can then be seen in the output of the trained models. Rather than attempting to de-bias each trained model individually, one could generate a de-biased synthetic dataset and use it to train each model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>, <a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>, creating a unified approach for handling biases across an organisation. Another use would be to use synthetic data to enlarge datasets that are too small, e.g. to provide robustness against “outlier” examples <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>, <a href="#bib.bib25" title="" class="ltx_ref">25</a>, <a href="#bib.bib26" title="" class="ltx_ref">26</a>, <a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib28" title="" class="ltx_ref">28</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>. Another key use case, to which we pay particular attention in this report, is the goal of using synthetic data to protect privacy. In each of these cases, the goal is to create synthetic data which resembles some aspects of the real data but not others. To maximise the utility of synthetic data, a fine balance must often be struck between competing objectives.</p>
</div>
<div id="S2.p6" class="ltx_para">
<p id="S2.p6.1" class="ltx_p">It is crucial to understand that synthetic data does <span id="S2.p6.1.1" class="ltx_text ltx_font_italic">not</span> automatically address any of these problems. Training an off-the-shelf generative model based on real data, and then using this trained model to generate synthetic data, is <span id="S2.p6.1.2" class="ltx_text ltx_font_italic">not inherently private</span>. Standard GANs do not generate private nor unbiased data. In fact, machine learning models have demonstrated the capability to (undesirably) memorise their training inputs <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>, <a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>. Applied to GANs, this can result in memorisation and regurgitation of the training data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>, undermining privacy in the synthetic data. At the other extreme, synthetic data can be generated without training data, e.g. using agent-based models that mimic the data generation process, such as agents transacting in a financial network. With no access to any real data, the synthetic data generator is private, but the data it generates is limited to the model’s predetermined configuration, and will not enable statistical inferences to be reliably drawn about the real world.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Can synthetic data replace real data?</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">The use of synthetic data raises two key questions:</p>
<ol id="S2.I1" class="ltx_enumerate">
<li id="S2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S2.I1.i1.p1" class="ltx_para">
<p id="S2.I1.i1.p1.1" class="ltx_p">Can we do the same things <span id="S2.I1.i1.p1.1.1" class="ltx_text ltx_font_italic">with</span> synthetic data that we do <span id="S2.I1.i1.p1.1.2" class="ltx_text ltx_font_italic">with</span> real data?</p>
</div>
</li>
<li id="S2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S2.I1.i2.p1" class="ltx_para">
<p id="S2.I1.i2.p1.1" class="ltx_p">Can we do the same things <span id="S2.I1.i2.p1.1.1" class="ltx_text ltx_font_italic">to</span> synthetic data that we do <span id="S2.I1.i2.p1.1.2" class="ltx_text ltx_font_italic">to</span> real data?</p>
</div>
</li>
</ol>
<p id="S2.SS1.p1.2" class="ltx_p">The sorts of things we may wish to do <span id="S2.SS1.p1.2.1" class="ltx_text ltx_font_italic">with</span> synthetic data are building models, performing data analysis, testing hypothesis, etc. Things one may wish to do <span id="S2.SS1.p1.2.2" class="ltx_text ltx_font_italic">to</span> synthetic data, for example, might be linking separate datasets together, or extending a synthetic dataset when new records are added to the original dataset.</p>
</div>
<section id="S2.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.1.1 </span>How should we approach doing things <span id="S2.SS1.SSS1.1.1" class="ltx_text ltx_font_italic">with</span> synthetic data?</h4>

<div id="S2.SS1.SSS1.p1" class="ltx_para">
<p id="S2.SS1.SSS1.p1.1" class="ltx_p">Ideally, one may hope that synthetic data can be simply plugged in wherever one might usually use real data (e.g. as training data for a model). Many papers on synthetic data evaluate it in this way. However, with private data, a more careful approach may lead to more accurate information being extracted from the synthetic data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>. In particular, conclusions from data analysis and hypothesis testing are necessarily weaker when using synthetic rather than real data, and the statistical significance of such analyses needs to be adjusted accordingly.</p>
</div>
<div id="S2.SS1.SSS1.p2" class="ltx_para">
<p id="S2.SS1.SSS1.p2.1" class="ltx_p">A particular concern for private data is bias. Ghalebikesabi et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite> warn against the risks of learning from synthetic data, and propose a methodology for learning unbiasedly from such data. Wilde et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> demonstrate superior performance when model parameters are updated using Bayesian inference, rather than approaches that fail to account for the fact the training data is synthetic.</p>
</div>
</section>
<section id="S2.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.1.2 </span>Data Linking</h4>

<div id="S2.SS1.SSS2.p1" class="ltx_para">
<p id="S2.SS1.SSS2.p1.1" class="ltx_p">Something that can naturally be done with real data is linking. One dataset may contain an individual’s lab test results, another may contain their genetic data, and another their hospital appointments. Each of these datasets can be linked to create a larger dataset containing information about inter-dataset correlations. If these datasets were synthesised independently, the 1-1 match between datasets will be broken; if, in the future, someone wished to pull together these synthetic datasets to investigate the correlations between, say, genetic data and lab test results, they would not be able to do so effectively.</p>
</div>
<div id="S2.SS1.SSS2.p2" class="ltx_para">
<p id="S2.SS1.SSS2.p2.1" class="ltx_p">One solution would be to encourage data holders to generate synthetic data with other (previously generated) synthetic datasets in mind. This may be appropriate in some situations (e.g. when the two datasets are being held by the same data holder), but in general this will not be the case. Moreover, the initial privacy loss suffered by an individual present in both datasets will be greater than if synthetic data was generated independently. This is particularly inefficient when linking the datasets might not be important, or the benefits of doing so are unclear.</p>
</div>
<div id="S2.SS1.SSS2.p3" class="ltx_para">
<p id="S2.SS1.SSS2.p3.1" class="ltx_p">In these situations, there is a need to be able to link two independently generated synthetic datasets (given access to real data) in a minimally privacy-leaking way. One workaround would be to simply generate a new joint dataset from the newly-joined underlying real datasets; but this does not leverage the existing synthetic data. A less naive approach would be to conditionally generate one of the two synthetic datasets based on the other (existing) synthetic dataset. This is a reduction in privacy cost over generating from scratch, but still fails to leverage the second already-generated synthetic dataset.</p>
</div>
</section>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Combining Synthetic Data with Other Technologies</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.5" class="ltx_p"><span id="S2.SS2.p1.5.1" class="ltx_text ltx_font_bold">Secure Research environment.</span> Synthetic data, in particular with differential privacy, has a natural application within secure research environments, in which decreasingly private data can be accessed in increasingly more “secure” environments. Consider releasing a dataset with strong privacy guarantees initially, evaluating a range of machine learning methods, then selecting the top <math id="S2.SS2.p1.1.m1.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S2.SS2.p1.1.m1.1a"><mi id="S2.SS2.p1.1.m1.1.1" xref="S2.SS2.p1.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.1.m1.1b"><ci id="S2.SS2.p1.1.m1.1.1.cmml" xref="S2.SS2.p1.1.m1.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.1.m1.1c">N</annotation></semantics></math> candidates, and giving them access to less private data. This can be repeated, giving a ‘tournament’ of methods. This raises the question of how to generate a series of datasets <math id="S2.SS2.p1.2.m2.3" class="ltx_Math" alttext="\mathcal{D}_{1},...,\mathcal{D}_{n}" display="inline"><semantics id="S2.SS2.p1.2.m2.3a"><mrow id="S2.SS2.p1.2.m2.3.3.2" xref="S2.SS2.p1.2.m2.3.3.3.cmml"><msub id="S2.SS2.p1.2.m2.2.2.1.1" xref="S2.SS2.p1.2.m2.2.2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p1.2.m2.2.2.1.1.2" xref="S2.SS2.p1.2.m2.2.2.1.1.2.cmml">𝒟</mi><mn id="S2.SS2.p1.2.m2.2.2.1.1.3" xref="S2.SS2.p1.2.m2.2.2.1.1.3.cmml">1</mn></msub><mo id="S2.SS2.p1.2.m2.3.3.2.3" xref="S2.SS2.p1.2.m2.3.3.3.cmml">,</mo><mi mathvariant="normal" id="S2.SS2.p1.2.m2.1.1" xref="S2.SS2.p1.2.m2.1.1.cmml">…</mi><mo id="S2.SS2.p1.2.m2.3.3.2.4" xref="S2.SS2.p1.2.m2.3.3.3.cmml">,</mo><msub id="S2.SS2.p1.2.m2.3.3.2.2" xref="S2.SS2.p1.2.m2.3.3.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p1.2.m2.3.3.2.2.2" xref="S2.SS2.p1.2.m2.3.3.2.2.2.cmml">𝒟</mi><mi id="S2.SS2.p1.2.m2.3.3.2.2.3" xref="S2.SS2.p1.2.m2.3.3.2.2.3.cmml">n</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.2.m2.3b"><list id="S2.SS2.p1.2.m2.3.3.3.cmml" xref="S2.SS2.p1.2.m2.3.3.2"><apply id="S2.SS2.p1.2.m2.2.2.1.1.cmml" xref="S2.SS2.p1.2.m2.2.2.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.2.m2.2.2.1.1.1.cmml" xref="S2.SS2.p1.2.m2.2.2.1.1">subscript</csymbol><ci id="S2.SS2.p1.2.m2.2.2.1.1.2.cmml" xref="S2.SS2.p1.2.m2.2.2.1.1.2">𝒟</ci><cn type="integer" id="S2.SS2.p1.2.m2.2.2.1.1.3.cmml" xref="S2.SS2.p1.2.m2.2.2.1.1.3">1</cn></apply><ci id="S2.SS2.p1.2.m2.1.1.cmml" xref="S2.SS2.p1.2.m2.1.1">…</ci><apply id="S2.SS2.p1.2.m2.3.3.2.2.cmml" xref="S2.SS2.p1.2.m2.3.3.2.2"><csymbol cd="ambiguous" id="S2.SS2.p1.2.m2.3.3.2.2.1.cmml" xref="S2.SS2.p1.2.m2.3.3.2.2">subscript</csymbol><ci id="S2.SS2.p1.2.m2.3.3.2.2.2.cmml" xref="S2.SS2.p1.2.m2.3.3.2.2.2">𝒟</ci><ci id="S2.SS2.p1.2.m2.3.3.2.2.3.cmml" xref="S2.SS2.p1.2.m2.3.3.2.2.3">𝑛</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.2.m2.3c">\mathcal{D}_{1},...,\mathcal{D}_{n}</annotation></semantics></math> which decrease in privacy individually and when taken together (so any subset <math id="S2.SS2.p1.3.m3.3" class="ltx_Math" alttext="\mathcal{D}_{1},...,\mathcal{D}_{j}" display="inline"><semantics id="S2.SS2.p1.3.m3.3a"><mrow id="S2.SS2.p1.3.m3.3.3.2" xref="S2.SS2.p1.3.m3.3.3.3.cmml"><msub id="S2.SS2.p1.3.m3.2.2.1.1" xref="S2.SS2.p1.3.m3.2.2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p1.3.m3.2.2.1.1.2" xref="S2.SS2.p1.3.m3.2.2.1.1.2.cmml">𝒟</mi><mn id="S2.SS2.p1.3.m3.2.2.1.1.3" xref="S2.SS2.p1.3.m3.2.2.1.1.3.cmml">1</mn></msub><mo id="S2.SS2.p1.3.m3.3.3.2.3" xref="S2.SS2.p1.3.m3.3.3.3.cmml">,</mo><mi mathvariant="normal" id="S2.SS2.p1.3.m3.1.1" xref="S2.SS2.p1.3.m3.1.1.cmml">…</mi><mo id="S2.SS2.p1.3.m3.3.3.2.4" xref="S2.SS2.p1.3.m3.3.3.3.cmml">,</mo><msub id="S2.SS2.p1.3.m3.3.3.2.2" xref="S2.SS2.p1.3.m3.3.3.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p1.3.m3.3.3.2.2.2" xref="S2.SS2.p1.3.m3.3.3.2.2.2.cmml">𝒟</mi><mi id="S2.SS2.p1.3.m3.3.3.2.2.3" xref="S2.SS2.p1.3.m3.3.3.2.2.3.cmml">j</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.3.m3.3b"><list id="S2.SS2.p1.3.m3.3.3.3.cmml" xref="S2.SS2.p1.3.m3.3.3.2"><apply id="S2.SS2.p1.3.m3.2.2.1.1.cmml" xref="S2.SS2.p1.3.m3.2.2.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.3.m3.2.2.1.1.1.cmml" xref="S2.SS2.p1.3.m3.2.2.1.1">subscript</csymbol><ci id="S2.SS2.p1.3.m3.2.2.1.1.2.cmml" xref="S2.SS2.p1.3.m3.2.2.1.1.2">𝒟</ci><cn type="integer" id="S2.SS2.p1.3.m3.2.2.1.1.3.cmml" xref="S2.SS2.p1.3.m3.2.2.1.1.3">1</cn></apply><ci id="S2.SS2.p1.3.m3.1.1.cmml" xref="S2.SS2.p1.3.m3.1.1">…</ci><apply id="S2.SS2.p1.3.m3.3.3.2.2.cmml" xref="S2.SS2.p1.3.m3.3.3.2.2"><csymbol cd="ambiguous" id="S2.SS2.p1.3.m3.3.3.2.2.1.cmml" xref="S2.SS2.p1.3.m3.3.3.2.2">subscript</csymbol><ci id="S2.SS2.p1.3.m3.3.3.2.2.2.cmml" xref="S2.SS2.p1.3.m3.3.3.2.2.2">𝒟</ci><ci id="S2.SS2.p1.3.m3.3.3.2.2.3.cmml" xref="S2.SS2.p1.3.m3.3.3.2.2.3">𝑗</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.3.m3.3c">\mathcal{D}_{1},...,\mathcal{D}_{j}</annotation></semantics></math>, <math id="S2.SS2.p1.4.m4.1" class="ltx_Math" alttext="j&lt;n" display="inline"><semantics id="S2.SS2.p1.4.m4.1a"><mrow id="S2.SS2.p1.4.m4.1.1" xref="S2.SS2.p1.4.m4.1.1.cmml"><mi id="S2.SS2.p1.4.m4.1.1.2" xref="S2.SS2.p1.4.m4.1.1.2.cmml">j</mi><mo id="S2.SS2.p1.4.m4.1.1.1" xref="S2.SS2.p1.4.m4.1.1.1.cmml">&lt;</mo><mi id="S2.SS2.p1.4.m4.1.1.3" xref="S2.SS2.p1.4.m4.1.1.3.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.4.m4.1b"><apply id="S2.SS2.p1.4.m4.1.1.cmml" xref="S2.SS2.p1.4.m4.1.1"><lt id="S2.SS2.p1.4.m4.1.1.1.cmml" xref="S2.SS2.p1.4.m4.1.1.1"></lt><ci id="S2.SS2.p1.4.m4.1.1.2.cmml" xref="S2.SS2.p1.4.m4.1.1.2">𝑗</ci><ci id="S2.SS2.p1.4.m4.1.1.3.cmml" xref="S2.SS2.p1.4.m4.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.4.m4.1c">j&lt;n</annotation></semantics></math> is as private as the terminal dataset, <math id="S2.SS2.p1.5.m5.1" class="ltx_Math" alttext="\mathcal{D}_{j}" display="inline"><semantics id="S2.SS2.p1.5.m5.1a"><msub id="S2.SS2.p1.5.m5.1.1" xref="S2.SS2.p1.5.m5.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p1.5.m5.1.1.2" xref="S2.SS2.p1.5.m5.1.1.2.cmml">𝒟</mi><mi id="S2.SS2.p1.5.m5.1.1.3" xref="S2.SS2.p1.5.m5.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.5.m5.1b"><apply id="S2.SS2.p1.5.m5.1.1.cmml" xref="S2.SS2.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.5.m5.1.1.1.cmml" xref="S2.SS2.p1.5.m5.1.1">subscript</csymbol><ci id="S2.SS2.p1.5.m5.1.1.2.cmml" xref="S2.SS2.p1.5.m5.1.1.2">𝒟</ci><ci id="S2.SS2.p1.5.m5.1.1.3.cmml" xref="S2.SS2.p1.5.m5.1.1.3">𝑗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.5.m5.1c">\mathcal{D}_{j}</annotation></semantics></math>).</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p"><span id="S2.SS2.p2.1.1" class="ltx_text ltx_font_bold">Federated learning.</span> Federated learning is an emerging technology that enables training across decentralised datasets without pooling these datasets together. This contrasts with traditional centralised machine learning techniques, where the data is uploaded to one server, as well as to classical decentralised approaches which often assume that local data samples are identically distributed.
In federated learning, distributed data holders allow an algorithm to be run on their private data, and only the (possibly noisy) outputs are released, without giving direct access to the data. The challenge with it is that, without accessing the data first, it might not be clear what algorithm one should run. Developing an algorithm on private synthetic data samples and evaluating its utility on real (distributed) data seems a very promising approach to this data bottleneck.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Why use Synthetic Data?</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">Synthetic data is being used as a solution to a variety of problems in many domains.
Three key areas that are of particular interest in a machine learning context are: (i) private data release (Section <a href="#S4" title="4 Privacy in Machine Learning - An Overview ‣ Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>); (ii) data de-biasing and fairness (Section <a href="#S8" title="8 De-biased Synthetic Data Generation ‣ Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>); and (iii) data augmentation for robustness (Section <a href="#S9" title="9 Data Augmentation ‣ Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>). Although these are the areas that appear to have the most promise, this list is not exhaustive. Before going into details for each of them, we outline the key ideas for these areas and some of the specific use cases (and non-use cases) below.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Private Data Release</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">The wide adoption of data-driven machine learning solutions as the prevailing approach to innovate has created a need to share data. Without access to quality data, scientists and developers cannot make meaningful progress. However, GDPR, HIPAA, and a host of privacy regulations require data on individuals not to be shared carelessly (rightly so). The result is typically a long series of “jumping through hoops” in an attempt to access the necessary data. Synthetic data offers a potential solution.</p>
</div>
<section id="S3.SS1.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Development of ML tools.</h5>

<div id="S3.SS1.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS1.SSS0.Px1.p1.1" class="ltx_p">In this use case, a data controller may wish to assess an ML group’s ability to solve a problem, or perhaps even assess several groups simultaneously to select the best partner with which to develop a final solution. In order to avoid privacy concerns, they plan to share synthetic data with their potential partners. For synthetic data to be useful in this setting, model development that is performed on the synthetic data should lead to the same conclusions as if it were carried out on the real data. More concretely, if a researcher comparing two models on the synthetic data were to conclude that model A outperforms model B for a given task, then the same conclusion should be reached when testing both algorithms on the real data. This suggests that, though the synthetic data would need to share many statistical properties with the real data, one can imagine that there are some properties that would not affect these comparisons. Once a final group/model has been determined, it can be taken to the real data for testing, tuning or even a complete re-training.</p>
</div>
</section>
<section id="S3.SS1.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Software testing.</h5>

<div id="S3.SS1.SSS0.Px2.p1" class="ltx_para">
<p id="S3.SS1.SSS0.Px2.p1.1" class="ltx_p">There is a significant appetite for vast amounts of test production data for both system testing and User Acceptance Testing. Synthetic data can remove the requirement of going through lengthy and repeated approvals (e.g GDPR) and sanitation processes and hence save significant time and effort in the development lifecycle. In this setting, it is important that synthetic data used for software testing is semantically correct, but it need not necessarily be statistically correct. Mathematically, this amounts to learning the <span id="S3.SS1.SSS0.Px2.p1.1.1" class="ltx_text ltx_font_italic">support</span> of the distribution and relevant structural properties (e.g time-series data), but not necessarily the distribution itself. Naturally, by not requiring statistical accuracy, there is much more room for increased privacy (or increased utility at the same privacy level). This is one of the design principles of OpenSafely <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>, where practitioners are able to test and develop algorithms on dummy data before running them once on the real data.</p>
</div>
</section>
<section id="S3.SS1.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Deploying private machine learning tools.</h5>

<div id="S3.SS1.SSS0.Px3.p1" class="ltx_para">
<p id="S3.SS1.SSS0.Px3.p1.1" class="ltx_p">Machine learning models are not inherently private. It is well known that neural networks have the capability to memorise training inputs. Membership inference attacks are possible against such networks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite> and, as such, privacy-enforcing training algorithms for machine learning models have been developed <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>, <a href="#bib.bib39" title="" class="ltx_ref">39</a>, <a href="#bib.bib40" title="" class="ltx_ref">40</a>, <a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite>. An apparent alternative (to enforcing privacy during the training of a model) would be to generate private data and then train a model using this data. <span id="S3.SS1.SSS0.Px3.p1.1.1" class="ltx_text ltx_font_italic">Perhaps</span> one advantage of such an approach would be that a single private synthetic dataset could create a unified approach to privacy (within a single organisation, say), but we believe that the cost in utility would outweigh the potential “simplicity” of the approach in most applications.</p>
</div>
<div id="S3.SS1.SSS0.Px3.p2" class="ltx_para">
<p id="S3.SS1.SSS0.Px3.p2.1" class="ltx_p">While training the model on private synthetic data might be appealing, it has limitations. Private data generation isn’t often able to capture all of the statistical structure that might be important to develop accurate models.
As such we believe it to be more prudent to focus efforts on the privacy of trained models, rather than on trying to generate private data with which to train.</p>
</div>
</section>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>De-biasing</h3>

<section id="S3.SS2.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Reducing/removing bias.</h5>

<div id="S3.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS2.SSS0.Px1.p1.1" class="ltx_p">When generating synthetic data, one can aim at producing samples that do not suffer from historical biases but are otherwise still statistically accurate. Such data can be used then for training ‘black box’ ML pipelines, while mitigating the risk of historical biases being amplified <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite>. Importantly, such data can be reused to train multiple models. This should be contrasted with the approach of correcting each trained model separately. The latter approach has an additional disadvantage, as it could lead to inconsistencies in the way ’fairness and bias’ are treated within an organisation. It must be recognised, however, that employing such methods to remove bias from the data introduces additional model risks that need to be quantified and monitored.</p>
</div>
</section>
<section id="S3.SS2.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">What-if-scenario generation.</h5>

<div id="S3.SS2.SSS0.Px2.p1" class="ltx_para">
<p id="S3.SS2.SSS0.Px2.p1.1" class="ltx_p">Adjacent to bias removal in datasets is the question of <span id="S3.SS2.SSS0.Px2.p1.1.1" class="ltx_text ltx_font_italic">causal modelling</span> – i.e. asking the question “What if?”. Synthetic data may allow us to explore data generated according to the same causal structure but adjusted distributions, or with different causal interventions placed on the data generating process.
One must be very careful to properly model causal relationships though, as causal modelling is sensitive to assumptions and is <span id="S3.SS2.SSS0.Px2.p1.1.2" class="ltx_text ltx_font_italic">not</span> the same as conditional generation. Indeed, the trustworthy deployment of data-driven models requires that these perform well in situations that differ from the real data. Of course, again, we stress that model risk is being introduced as generative models are being used to produce these new scenarios.</p>
</div>
</section>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Data Augmentation</h3>

<section id="S3.SS3.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Data labelling.</h5>

<div id="S3.SS3.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS3.SSS0.Px1.p1.1" class="ltx_p">Deep neural networks are state of the art technology in computer vision applications. However, training deep neural networks requires vast amounts of (correctly) labelled data, which is often costly to produce. Synthetically generated labelled data offers a cost-efficient solution to this challenge, and has already been adopted by industry <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite>. In this application, one trains a neural network on synthetic data with the intention to deploy it on real data. In general, privacy is not of primary concern in these applications, as the data is not being used to replace the real data but to be used alongside it.</p>
</div>
</section>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Privacy in Machine Learning - An Overview</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">Privacy is an incredibly large field, with practitioners coming from a wide variety of domains. Here, we present our view on privacy within the context of machine learning. We take a ground-up approach, motivating privacy through the notion of an adversary that has the potential to cause harm should too much information about an individual be revealed to them.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.1" class="ltx_p">Privacy is a fundamental human right and a prerequisite for freedom of thought and expression.
For this reason, a key requirement of privacy is the <span id="S4.p2.1.1" class="ltx_text ltx_font_italic">consent</span> of individuals to have their data collected.
This consent usually relies on the expectation that the collection of their data, and the subsequent release of information derived from it, will not cause them <span id="S4.p2.1.2" class="ltx_text ltx_font_italic">harm</span>.
For some types of information, such as an individual’s name, address, and phone number, the potential for harm is clear. For others, the potential for harm is more subtle: e.g. it might be that an insurance company would increase the price of an individual’s insurance premiums based on knowledge that the specific individual is a smoker, without explicitly requesting this information. This potential for harm is caused by the ability of an <span id="S4.p2.1.3" class="ltx_text ltx_font_italic">adversary</span> to gain information about an individual due to the release of data, or more generally from output that is derived from the data (again, this could be a synthetic dataset, or some other algorithm output).</p>
</div>
<div id="S4.p3" class="ltx_para">
<p id="S4.p3.1" class="ltx_p">On the other hand, there is a highly social aspect to working with data. Shared datasets that can be used to benchmark models create a community that promotes rapid advancement of technology (see, for example, the rapid progress made in image classification that was caused by the availability of the MNIST and CIFAR datasets <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>, <a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite>). In general, researchers want data, and it may not need to be too accurate for them to start being able to work with it.</p>
</div>
<div id="S4.p4" class="ltx_para">
<p id="S4.p4.1" class="ltx_p">Since the late 1990s, much research has been carried out within the realm of privacy. Early on, privacy was often tied together with the notion of <span id="S4.p4.1.1" class="ltx_text ltx_font_italic">anonymity</span>, which came in a variety of flavours, from basic name/address/birthday removal (“pseudonymisation”), to <math id="S4.p4.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S4.p4.1.m1.1a"><mi id="S4.p4.1.m1.1.1" xref="S4.p4.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.p4.1.m1.1b"><ci id="S4.p4.1.m1.1.1.cmml" xref="S4.p4.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.1.m1.1c">k</annotation></semantics></math>-anonymity <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite> (which itself had several iterations <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>, <a href="#bib.bib48" title="" class="ltx_ref">48</a>, <a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite>). Although these notions apply to data, they really only have meaning on the raw data itself, and moreover have been shown to be inadequate even for that <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib50" title="" class="ltx_ref">50</a>, <a href="#bib.bib51" title="" class="ltx_ref">51</a>]</cite>. These approaches were built to prevent against <span id="S4.p4.1.2" class="ltx_text ltx_font_italic">known</span> attacks. More recently, privacy is being studied with a view to prevent against abstract <span id="S4.p4.1.3" class="ltx_text ltx_font_italic">threat models</span> rather than specific instantiations of an attack.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>The Threat Model View</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">Threat model privacy attacks can be summarised into 3 types: membership inference; attribute inference; and reconstruction attacks.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<table id="S4.SS1.p2.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.SS1.p2.1.1.1" class="ltx_tr">
<th id="S4.SS1.p2.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.SS1.p2.1.1.1.1.1" class="ltx_text ltx_font_bold">Threat</span></th>
<td id="S4.SS1.p2.1.1.1.2" class="ltx_td ltx_align_justify">
<span id="S4.SS1.p2.1.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.SS1.p2.1.1.1.2.1.1" class="ltx_p"><span id="S4.SS1.p2.1.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Attacker’s knowledge of Targeted Individual</span></span>
</span>
</td>
<td id="S4.SS1.p2.1.1.1.3" class="ltx_td ltx_align_justify">
<span id="S4.SS1.p2.1.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.SS1.p2.1.1.1.3.1.1" class="ltx_p"><span id="S4.SS1.p2.1.1.1.3.1.1.1" class="ltx_text ltx_font_bold">Attacker’s goal</span></span>
</span>
</td>
</tr>
<tr id="S4.SS1.p2.1.2.2" class="ltx_tr">
<th id="S4.SS1.p2.1.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Membership inference</th>
<td id="S4.SS1.p2.1.2.2.2" class="ltx_td ltx_align_justify">
<span id="S4.SS1.p2.1.2.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.SS1.p2.1.2.2.2.1.1" class="ltx_p">Partial/Entire record</span>
</span>
</td>
<td id="S4.SS1.p2.1.2.2.3" class="ltx_td ltx_align_justify">
<span id="S4.SS1.p2.1.2.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.SS1.p2.1.2.2.3.1.1" class="ltx_p">Determine if Targeted Individual was in the original data</span>
</span>
</td>
</tr>
<tr id="S4.SS1.p2.1.3.3" class="ltx_tr">
<th id="S4.SS1.p2.1.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Attribute inference</th>
<td id="S4.SS1.p2.1.3.3.2" class="ltx_td ltx_align_justify">
<span id="S4.SS1.p2.1.3.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.SS1.p2.1.3.3.2.1.1" class="ltx_p">Partial record</span>
</span>
</td>
<td id="S4.SS1.p2.1.3.3.3" class="ltx_td ltx_align_justify">
<span id="S4.SS1.p2.1.3.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.SS1.p2.1.3.3.3.1.1" class="ltx_p">Recover missing attributes of Targeted Individual’s data</span>
</span>
</td>
</tr>
<tr id="S4.SS1.p2.1.4.4" class="ltx_tr">
<th id="S4.SS1.p2.1.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Reconstruction attack</th>
<td id="S4.SS1.p2.1.4.4.2" class="ltx_td ltx_align_justify">
<span id="S4.SS1.p2.1.4.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.SS1.p2.1.4.4.2.1.1" class="ltx_p">N/A</span>
</span>
</td>
<td id="S4.SS1.p2.1.4.4.3" class="ltx_td ltx_align_justify">
<span id="S4.SS1.p2.1.4.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.SS1.p2.1.4.4.3.1.1" class="ltx_p">Recover entire records from the original data</span>
</span>
</td>
</tr>
</tbody>
</table>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p id="S4.SS1.p3.1" class="ltx_p">These attacks differ both in their goals and in some of the assumptions placed on the adversary’s prior knowledge <span id="S4.SS1.p3.1.1" class="ltx_text ltx_font_italic">of the targeted individual</span>. It should be noted, however, that these attacks do not necessarily place any assumptions on the prior knowledge that an adversary might have about the individuals it is <span id="S4.SS1.p3.1.2" class="ltx_text ltx_font_italic">not</span> targeting. These attacks are not typically performed against a single individual but multiple individuals at once, with a breach of any individual’s privacy being considered a success by the adversary.</p>
</div>
<section id="S4.SS1.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Membership Inference.</h5>

<div id="S4.SS1.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px1.p1.1" class="ltx_p">Membership inference <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>, <a href="#bib.bib52" title="" class="ltx_ref">52</a>]</cite> aims to determine whether an individual (whose full record might be known to the adversary) was part of the data that was given as input to an algorithm, given the output of the algorithm (and, potentially, knowledge of the workings of the algorithm). On its own, this is only of relevance when membership in the dataset implies some information about an individual. For example, it is not particularly useful (or much of a privacy violation) to ascertain that a particular individual’s data was in the 2021 UK Census dataset. Following the example of the smoker, though, it is a violation to be able to ascertain that a given individual is in a dataset that contains only smokers (such as a dataset used in a scientific study of smokers).</p>
</div>
</section>
<section id="S4.SS1.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Attribute Inference.</h5>

<div id="S4.SS1.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px2.p1.1" class="ltx_p">Attribute inference <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib53" title="" class="ltx_ref">53</a>, <a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite> is slowly becoming infamous as a non-violation of privacy.
The goal with attribute inference is to determine some extra information about an individual given some prior knowledge about some of their attributes and access to an algorithm’s output (e.g. synthetic data, or a trained ML model). Of course, this is precisely what predictive models aim to do – predict (an) attribute(s) from a set of other attributes <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite>. But this leads to an almost paradoxical conclusion, how can a model that was trained <span id="S4.SS1.SSS0.Px2.p1.1.1" class="ltx_text ltx_font_italic">without</span> an individual’s data, violate their privacy? This almost-paradox has led to many privacy researchers abandoning attribute inference as a violation of privacy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib56" title="" class="ltx_ref">56</a>, <a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>.
However, the question should not be, “does this allow you to learn more about an individual?”, but rather, “does this allow you to learn more about an individual than if they had not been in the data?” It is still possible (in fact, with ML it is very likely <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite>) that a trained model will perform better on its training inputs than on inputs not used for its training. This indicates that the release of such a model does violate the privacy of the individuals in the training set <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite>. Recent work in the space has attempted to determine the feasibility of attribute inference attacks. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib60" title="" class="ltx_ref">60</a>]</cite> show that even when membership inference is possible, attribute inference may not be; they do, however, demonstrate that <span id="S4.SS1.SSS0.Px2.p1.1.2" class="ltx_text ltx_font_italic">approximate</span> attribute inference is possible.</p>
</div>
</section>
<section id="S4.SS1.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Reconstruction Attacks.</h5>

<div id="S4.SS1.SSS0.Px3.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px3.p1.1" class="ltx_p">Reconstruction attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib61" title="" class="ltx_ref">61</a>]</cite> aim to extract entire records from the training dataset, based on the output of an algorithm.
For instance, Dinur and Nissim showed how a database protected by a question-and-answer system can be reconstructed by an attacker if the level of the noise added to answers is low <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib61" title="" class="ltx_ref">61</a>]</cite>.
Another high profile example is the attack performed by researchers at the US Census bureau on aggregates from the 2010 Census. They were able to retrieve exact records for 46% of the US population using publicly released data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref">62</a>]</cite>.
Unlike membership and attribute inference attacks, reconstruction attacks are not <span id="S4.SS1.SSS0.Px3.p1.1.1" class="ltx_text ltx_font_italic">targeted</span>: they aim to retrieve records for any (or all) records in the original data. This could leverage prior knowledge about <span id="S4.SS1.SSS0.Px3.p1.1.2" class="ltx_text ltx_font_italic">some</span> of the individuals in the training set (with the remaining unknown individuals being considered the targets).
Note that the same caveat as for attribute inference attacks applies: even an algorithm sampling records uniformly at random in <math id="S4.SS1.SSS0.Px3.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{X}" display="inline"><semantics id="S4.SS1.SSS0.Px3.p1.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.SSS0.Px3.p1.1.m1.1.1" xref="S4.SS1.SSS0.Px3.p1.1.m1.1.1.cmml">𝒳</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px3.p1.1.m1.1b"><ci id="S4.SS1.SSS0.Px3.p1.1.m1.1.1.cmml" xref="S4.SS1.SSS0.Px3.p1.1.m1.1.1">𝒳</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px3.p1.1.m1.1c">\mathcal{X}</annotation></semantics></math> will reconstruct <span id="S4.SS1.SSS0.Px3.p1.1.3" class="ltx_text ltx_font_italic">some</span> records in the real data with nonzero probability. Evaluation of a reconstruction attack should therefore be contrastive, i.e. based on the difference of reconstruction likelihood for a record due to their presence in the data (although real-world attacks recover such large fractions of the data that this consideration is often not needed).</p>
</div>
</section>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Differential Privacy</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">Differential Privacy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib63" title="" class="ltx_ref">63</a>]</cite>, first proposed by Dwork et al. in 2006 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib64" title="" class="ltx_ref">64</a>]</cite>, is becoming increasingly accepted as a robust, meaningful, and practical definition of privacy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib65" title="" class="ltx_ref">65</a>, <a href="#bib.bib66" title="" class="ltx_ref">66</a>, <a href="#bib.bib67" title="" class="ltx_ref">67</a>]</cite>.
Informally, differential privacy requires that an algorithm’s (necessarily random) output not differ “too much” between <span id="S4.SS2.p1.1.1" class="ltx_text ltx_font_italic">adjacent</span> datasets. Intuitively, because the outcome cannot differ significantly, there cannot be too much “information leakage” from the dataset to the algorithm output. The definition rests on some notion of datasets being <span id="S4.SS2.p1.1.2" class="ltx_text ltx_font_italic">adjacent</span> to each other, and can be used to capture the notion of an individual’s data. This adjacency can be defined in different ways depending on the type of data structure. With so-called tabular data, adjacency between two datasets is typically defined to mean that one can be obtained from the other by either the removal/addition (unbounded differential privacy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>) or replacement (bounded differential privacy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>) of a row.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">Defining this adjacency amounts to deciding precisely what information should be protected <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib68" title="" class="ltx_ref">68</a>, <a href="#bib.bib69" title="" class="ltx_ref">69</a>]</cite>. With graph-like data, one could consider either entire nodes (along with all associated edges) to be important, or instead consider only the edges themselves to each be individually important <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib70" title="" class="ltx_ref">70</a>, <a href="#bib.bib71" title="" class="ltx_ref">71</a>]</cite>. With tabular data, one might define adjacency as datasets differing in precisely one value, allowing “feature-wise” differential privacy that protects each value contributed to the dataset, rather than rows as a whole. This would allow data contributors to decide to maintain the privacy of some, but potentially not all, of their data.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.1" class="ltx_p">A particularly important feature of differential privacy is that it is <span id="S4.SS2.p3.1.1" class="ltx_text ltx_font_italic">contrastive</span> – it compares the outcome of an algorithm when an individual is in the training data to the outcome when the individual is not in the training data, or some similar adjacent perturbation. This idea, that privacy cannot be breached when an individual is not in the data, is crucial in dismissing several more ad-hoc notions of privacy. Crucially, for synthetic data, just because one of the synthetic data points <span id="S4.SS2.p3.1.2" class="ltx_text ltx_font_italic">looks like</span> one of the original data points does not mean that privacy has been violated – the synthetic point might have been generated even without the original point being present in the training data.</p>
</div>
<div id="Thmdefinition2" class="ltx_theorem ltx_theorem_definition">
<h6 class="ltx_title ltx_runin ltx_title_theorem">
<span class="ltx_tag ltx_tag_theorem"><span id="Thmdefinition2.1.1.1" class="ltx_text ltx_font_bold">Definition 2</span></span><span id="Thmdefinition2.2.2" class="ltx_text ltx_font_bold"> (Differential Privacy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>)</span>
</h6>
<div id="Thmdefinition2.p1" class="ltx_para">
<p id="Thmdefinition2.p1.4" class="ltx_p"><span id="Thmdefinition2.p1.4.4" class="ltx_text ltx_font_italic">A <span id="Thmdefinition2.p1.4.4.1" class="ltx_text ltx_font_normal">randomized</span> algorithm, <math id="Thmdefinition2.p1.1.1.m1.1" class="ltx_Math" alttext="\mathcal{M}" display="inline"><semantics id="Thmdefinition2.p1.1.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="Thmdefinition2.p1.1.1.m1.1.1" xref="Thmdefinition2.p1.1.1.m1.1.1.cmml">ℳ</mi><annotation-xml encoding="MathML-Content" id="Thmdefinition2.p1.1.1.m1.1b"><ci id="Thmdefinition2.p1.1.1.m1.1.1.cmml" xref="Thmdefinition2.p1.1.1.m1.1.1">ℳ</ci></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition2.p1.1.1.m1.1c">\mathcal{M}</annotation></semantics></math>, is <math id="Thmdefinition2.p1.2.2.m2.2" class="ltx_Math" alttext="(\varepsilon,\delta)" display="inline"><semantics id="Thmdefinition2.p1.2.2.m2.2a"><mrow id="Thmdefinition2.p1.2.2.m2.2.3.2" xref="Thmdefinition2.p1.2.2.m2.2.3.1.cmml"><mo stretchy="false" id="Thmdefinition2.p1.2.2.m2.2.3.2.1" xref="Thmdefinition2.p1.2.2.m2.2.3.1.cmml">(</mo><mi id="Thmdefinition2.p1.2.2.m2.1.1" xref="Thmdefinition2.p1.2.2.m2.1.1.cmml">ε</mi><mo id="Thmdefinition2.p1.2.2.m2.2.3.2.2" xref="Thmdefinition2.p1.2.2.m2.2.3.1.cmml">,</mo><mi id="Thmdefinition2.p1.2.2.m2.2.2" xref="Thmdefinition2.p1.2.2.m2.2.2.cmml">δ</mi><mo stretchy="false" id="Thmdefinition2.p1.2.2.m2.2.3.2.3" xref="Thmdefinition2.p1.2.2.m2.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="Thmdefinition2.p1.2.2.m2.2b"><interval closure="open" id="Thmdefinition2.p1.2.2.m2.2.3.1.cmml" xref="Thmdefinition2.p1.2.2.m2.2.3.2"><ci id="Thmdefinition2.p1.2.2.m2.1.1.cmml" xref="Thmdefinition2.p1.2.2.m2.1.1">𝜀</ci><ci id="Thmdefinition2.p1.2.2.m2.2.2.cmml" xref="Thmdefinition2.p1.2.2.m2.2.2">𝛿</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition2.p1.2.2.m2.2c">(\varepsilon,\delta)</annotation></semantics></math>-differentially private if for all <math id="Thmdefinition2.p1.3.3.m3.1" class="ltx_Math" alttext="\mathcal{S}\subset\mathrm{Im}(\mathcal{M})" display="inline"><semantics id="Thmdefinition2.p1.3.3.m3.1a"><mrow id="Thmdefinition2.p1.3.3.m3.1.2" xref="Thmdefinition2.p1.3.3.m3.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="Thmdefinition2.p1.3.3.m3.1.2.2" xref="Thmdefinition2.p1.3.3.m3.1.2.2.cmml">𝒮</mi><mo id="Thmdefinition2.p1.3.3.m3.1.2.1" xref="Thmdefinition2.p1.3.3.m3.1.2.1.cmml">⊂</mo><mrow id="Thmdefinition2.p1.3.3.m3.1.2.3" xref="Thmdefinition2.p1.3.3.m3.1.2.3.cmml"><mi id="Thmdefinition2.p1.3.3.m3.1.2.3.2" xref="Thmdefinition2.p1.3.3.m3.1.2.3.2.cmml">Im</mi><mo lspace="0em" rspace="0em" id="Thmdefinition2.p1.3.3.m3.1.2.3.1" xref="Thmdefinition2.p1.3.3.m3.1.2.3.1.cmml">​</mo><mrow id="Thmdefinition2.p1.3.3.m3.1.2.3.3.2" xref="Thmdefinition2.p1.3.3.m3.1.2.3.cmml"><mo stretchy="false" id="Thmdefinition2.p1.3.3.m3.1.2.3.3.2.1" xref="Thmdefinition2.p1.3.3.m3.1.2.3.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="Thmdefinition2.p1.3.3.m3.1.1" xref="Thmdefinition2.p1.3.3.m3.1.1.cmml">ℳ</mi><mo stretchy="false" id="Thmdefinition2.p1.3.3.m3.1.2.3.3.2.2" xref="Thmdefinition2.p1.3.3.m3.1.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="Thmdefinition2.p1.3.3.m3.1b"><apply id="Thmdefinition2.p1.3.3.m3.1.2.cmml" xref="Thmdefinition2.p1.3.3.m3.1.2"><subset id="Thmdefinition2.p1.3.3.m3.1.2.1.cmml" xref="Thmdefinition2.p1.3.3.m3.1.2.1"></subset><ci id="Thmdefinition2.p1.3.3.m3.1.2.2.cmml" xref="Thmdefinition2.p1.3.3.m3.1.2.2">𝒮</ci><apply id="Thmdefinition2.p1.3.3.m3.1.2.3.cmml" xref="Thmdefinition2.p1.3.3.m3.1.2.3"><times id="Thmdefinition2.p1.3.3.m3.1.2.3.1.cmml" xref="Thmdefinition2.p1.3.3.m3.1.2.3.1"></times><ci id="Thmdefinition2.p1.3.3.m3.1.2.3.2.cmml" xref="Thmdefinition2.p1.3.3.m3.1.2.3.2">Im</ci><ci id="Thmdefinition2.p1.3.3.m3.1.1.cmml" xref="Thmdefinition2.p1.3.3.m3.1.1">ℳ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition2.p1.3.3.m3.1c">\mathcal{S}\subset\mathrm{Im}(\mathcal{M})</annotation></semantics></math> and for all neighboring datasets <math id="Thmdefinition2.p1.4.4.m4.2" class="ltx_Math" alttext="\mathcal{D},\mathcal{D}^{\prime}" display="inline"><semantics id="Thmdefinition2.p1.4.4.m4.2a"><mrow id="Thmdefinition2.p1.4.4.m4.2.2.1" xref="Thmdefinition2.p1.4.4.m4.2.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="Thmdefinition2.p1.4.4.m4.1.1" xref="Thmdefinition2.p1.4.4.m4.1.1.cmml">𝒟</mi><mo id="Thmdefinition2.p1.4.4.m4.2.2.1.2" xref="Thmdefinition2.p1.4.4.m4.2.2.2.cmml">,</mo><msup id="Thmdefinition2.p1.4.4.m4.2.2.1.1" xref="Thmdefinition2.p1.4.4.m4.2.2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="Thmdefinition2.p1.4.4.m4.2.2.1.1.2" xref="Thmdefinition2.p1.4.4.m4.2.2.1.1.2.cmml">𝒟</mi><mo id="Thmdefinition2.p1.4.4.m4.2.2.1.1.3" xref="Thmdefinition2.p1.4.4.m4.2.2.1.1.3.cmml">′</mo></msup></mrow><annotation-xml encoding="MathML-Content" id="Thmdefinition2.p1.4.4.m4.2b"><list id="Thmdefinition2.p1.4.4.m4.2.2.2.cmml" xref="Thmdefinition2.p1.4.4.m4.2.2.1"><ci id="Thmdefinition2.p1.4.4.m4.1.1.cmml" xref="Thmdefinition2.p1.4.4.m4.1.1">𝒟</ci><apply id="Thmdefinition2.p1.4.4.m4.2.2.1.1.cmml" xref="Thmdefinition2.p1.4.4.m4.2.2.1.1"><csymbol cd="ambiguous" id="Thmdefinition2.p1.4.4.m4.2.2.1.1.1.cmml" xref="Thmdefinition2.p1.4.4.m4.2.2.1.1">superscript</csymbol><ci id="Thmdefinition2.p1.4.4.m4.2.2.1.1.2.cmml" xref="Thmdefinition2.p1.4.4.m4.2.2.1.1.2">𝒟</ci><ci id="Thmdefinition2.p1.4.4.m4.2.2.1.1.3.cmml" xref="Thmdefinition2.p1.4.4.m4.2.2.1.1.3">′</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition2.p1.4.4.m4.2c">\mathcal{D},\mathcal{D}^{\prime}</annotation></semantics></math>:</span></p>
<table id="S4.Ex1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.Ex1.m1.3" class="ltx_Math" alttext="\mathbb{P}(\mathcal{M(\mathcal{D})}\in\mathcal{S})\leq e^{\varepsilon}\mathbb{P}(\mathcal{M(\mathcal{D}^{\prime})}\in\mathcal{S})+\delta" display="block"><semantics id="S4.Ex1.m1.3a"><mrow id="S4.Ex1.m1.3.3" xref="S4.Ex1.m1.3.3.cmml"><mrow id="S4.Ex1.m1.2.2.1" xref="S4.Ex1.m1.2.2.1.cmml"><mi id="S4.Ex1.m1.2.2.1.3" xref="S4.Ex1.m1.2.2.1.3.cmml">ℙ</mi><mo lspace="0em" rspace="0em" id="S4.Ex1.m1.2.2.1.2" xref="S4.Ex1.m1.2.2.1.2.cmml">​</mo><mrow id="S4.Ex1.m1.2.2.1.1.1" xref="S4.Ex1.m1.2.2.1.1.1.1.cmml"><mo stretchy="false" id="S4.Ex1.m1.2.2.1.1.1.2" xref="S4.Ex1.m1.2.2.1.1.1.1.cmml">(</mo><mrow id="S4.Ex1.m1.2.2.1.1.1.1" xref="S4.Ex1.m1.2.2.1.1.1.1.cmml"><mrow id="S4.Ex1.m1.2.2.1.1.1.1.2" xref="S4.Ex1.m1.2.2.1.1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.Ex1.m1.2.2.1.1.1.1.2.2" xref="S4.Ex1.m1.2.2.1.1.1.1.2.2.cmml">ℳ</mi><mo lspace="0em" rspace="0em" id="S4.Ex1.m1.2.2.1.1.1.1.2.1" xref="S4.Ex1.m1.2.2.1.1.1.1.2.1.cmml">​</mo><mrow id="S4.Ex1.m1.2.2.1.1.1.1.2.3.2" xref="S4.Ex1.m1.2.2.1.1.1.1.2.cmml"><mo stretchy="false" id="S4.Ex1.m1.2.2.1.1.1.1.2.3.2.1" xref="S4.Ex1.m1.2.2.1.1.1.1.2.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S4.Ex1.m1.1.1" xref="S4.Ex1.m1.1.1.cmml">𝒟</mi><mo stretchy="false" id="S4.Ex1.m1.2.2.1.1.1.1.2.3.2.2" xref="S4.Ex1.m1.2.2.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S4.Ex1.m1.2.2.1.1.1.1.1" xref="S4.Ex1.m1.2.2.1.1.1.1.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S4.Ex1.m1.2.2.1.1.1.1.3" xref="S4.Ex1.m1.2.2.1.1.1.1.3.cmml">𝒮</mi></mrow><mo stretchy="false" id="S4.Ex1.m1.2.2.1.1.1.3" xref="S4.Ex1.m1.2.2.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S4.Ex1.m1.3.3.3" xref="S4.Ex1.m1.3.3.3.cmml">≤</mo><mrow id="S4.Ex1.m1.3.3.2" xref="S4.Ex1.m1.3.3.2.cmml"><mrow id="S4.Ex1.m1.3.3.2.1" xref="S4.Ex1.m1.3.3.2.1.cmml"><msup id="S4.Ex1.m1.3.3.2.1.3" xref="S4.Ex1.m1.3.3.2.1.3.cmml"><mi id="S4.Ex1.m1.3.3.2.1.3.2" xref="S4.Ex1.m1.3.3.2.1.3.2.cmml">e</mi><mi id="S4.Ex1.m1.3.3.2.1.3.3" xref="S4.Ex1.m1.3.3.2.1.3.3.cmml">ε</mi></msup><mo lspace="0em" rspace="0em" id="S4.Ex1.m1.3.3.2.1.2" xref="S4.Ex1.m1.3.3.2.1.2.cmml">​</mo><mi id="S4.Ex1.m1.3.3.2.1.4" xref="S4.Ex1.m1.3.3.2.1.4.cmml">ℙ</mi><mo lspace="0em" rspace="0em" id="S4.Ex1.m1.3.3.2.1.2a" xref="S4.Ex1.m1.3.3.2.1.2.cmml">​</mo><mrow id="S4.Ex1.m1.3.3.2.1.1.1" xref="S4.Ex1.m1.3.3.2.1.1.1.1.cmml"><mo stretchy="false" id="S4.Ex1.m1.3.3.2.1.1.1.2" xref="S4.Ex1.m1.3.3.2.1.1.1.1.cmml">(</mo><mrow id="S4.Ex1.m1.3.3.2.1.1.1.1" xref="S4.Ex1.m1.3.3.2.1.1.1.1.cmml"><mrow id="S4.Ex1.m1.3.3.2.1.1.1.1.1" xref="S4.Ex1.m1.3.3.2.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.Ex1.m1.3.3.2.1.1.1.1.1.3" xref="S4.Ex1.m1.3.3.2.1.1.1.1.1.3.cmml">ℳ</mi><mo lspace="0em" rspace="0em" id="S4.Ex1.m1.3.3.2.1.1.1.1.1.2" xref="S4.Ex1.m1.3.3.2.1.1.1.1.1.2.cmml">​</mo><mrow id="S4.Ex1.m1.3.3.2.1.1.1.1.1.1.1" xref="S4.Ex1.m1.3.3.2.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.Ex1.m1.3.3.2.1.1.1.1.1.1.1.2" xref="S4.Ex1.m1.3.3.2.1.1.1.1.1.1.1.1.cmml">(</mo><msup id="S4.Ex1.m1.3.3.2.1.1.1.1.1.1.1.1" xref="S4.Ex1.m1.3.3.2.1.1.1.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.Ex1.m1.3.3.2.1.1.1.1.1.1.1.1.2" xref="S4.Ex1.m1.3.3.2.1.1.1.1.1.1.1.1.2.cmml">𝒟</mi><mo id="S4.Ex1.m1.3.3.2.1.1.1.1.1.1.1.1.3" xref="S4.Ex1.m1.3.3.2.1.1.1.1.1.1.1.1.3.cmml">′</mo></msup><mo stretchy="false" id="S4.Ex1.m1.3.3.2.1.1.1.1.1.1.1.3" xref="S4.Ex1.m1.3.3.2.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S4.Ex1.m1.3.3.2.1.1.1.1.2" xref="S4.Ex1.m1.3.3.2.1.1.1.1.2.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S4.Ex1.m1.3.3.2.1.1.1.1.3" xref="S4.Ex1.m1.3.3.2.1.1.1.1.3.cmml">𝒮</mi></mrow><mo stretchy="false" id="S4.Ex1.m1.3.3.2.1.1.1.3" xref="S4.Ex1.m1.3.3.2.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S4.Ex1.m1.3.3.2.2" xref="S4.Ex1.m1.3.3.2.2.cmml">+</mo><mi id="S4.Ex1.m1.3.3.2.3" xref="S4.Ex1.m1.3.3.2.3.cmml">δ</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.Ex1.m1.3b"><apply id="S4.Ex1.m1.3.3.cmml" xref="S4.Ex1.m1.3.3"><leq id="S4.Ex1.m1.3.3.3.cmml" xref="S4.Ex1.m1.3.3.3"></leq><apply id="S4.Ex1.m1.2.2.1.cmml" xref="S4.Ex1.m1.2.2.1"><times id="S4.Ex1.m1.2.2.1.2.cmml" xref="S4.Ex1.m1.2.2.1.2"></times><ci id="S4.Ex1.m1.2.2.1.3.cmml" xref="S4.Ex1.m1.2.2.1.3">ℙ</ci><apply id="S4.Ex1.m1.2.2.1.1.1.1.cmml" xref="S4.Ex1.m1.2.2.1.1.1"><in id="S4.Ex1.m1.2.2.1.1.1.1.1.cmml" xref="S4.Ex1.m1.2.2.1.1.1.1.1"></in><apply id="S4.Ex1.m1.2.2.1.1.1.1.2.cmml" xref="S4.Ex1.m1.2.2.1.1.1.1.2"><times id="S4.Ex1.m1.2.2.1.1.1.1.2.1.cmml" xref="S4.Ex1.m1.2.2.1.1.1.1.2.1"></times><ci id="S4.Ex1.m1.2.2.1.1.1.1.2.2.cmml" xref="S4.Ex1.m1.2.2.1.1.1.1.2.2">ℳ</ci><ci id="S4.Ex1.m1.1.1.cmml" xref="S4.Ex1.m1.1.1">𝒟</ci></apply><ci id="S4.Ex1.m1.2.2.1.1.1.1.3.cmml" xref="S4.Ex1.m1.2.2.1.1.1.1.3">𝒮</ci></apply></apply><apply id="S4.Ex1.m1.3.3.2.cmml" xref="S4.Ex1.m1.3.3.2"><plus id="S4.Ex1.m1.3.3.2.2.cmml" xref="S4.Ex1.m1.3.3.2.2"></plus><apply id="S4.Ex1.m1.3.3.2.1.cmml" xref="S4.Ex1.m1.3.3.2.1"><times id="S4.Ex1.m1.3.3.2.1.2.cmml" xref="S4.Ex1.m1.3.3.2.1.2"></times><apply id="S4.Ex1.m1.3.3.2.1.3.cmml" xref="S4.Ex1.m1.3.3.2.1.3"><csymbol cd="ambiguous" id="S4.Ex1.m1.3.3.2.1.3.1.cmml" xref="S4.Ex1.m1.3.3.2.1.3">superscript</csymbol><ci id="S4.Ex1.m1.3.3.2.1.3.2.cmml" xref="S4.Ex1.m1.3.3.2.1.3.2">𝑒</ci><ci id="S4.Ex1.m1.3.3.2.1.3.3.cmml" xref="S4.Ex1.m1.3.3.2.1.3.3">𝜀</ci></apply><ci id="S4.Ex1.m1.3.3.2.1.4.cmml" xref="S4.Ex1.m1.3.3.2.1.4">ℙ</ci><apply id="S4.Ex1.m1.3.3.2.1.1.1.1.cmml" xref="S4.Ex1.m1.3.3.2.1.1.1"><in id="S4.Ex1.m1.3.3.2.1.1.1.1.2.cmml" xref="S4.Ex1.m1.3.3.2.1.1.1.1.2"></in><apply id="S4.Ex1.m1.3.3.2.1.1.1.1.1.cmml" xref="S4.Ex1.m1.3.3.2.1.1.1.1.1"><times id="S4.Ex1.m1.3.3.2.1.1.1.1.1.2.cmml" xref="S4.Ex1.m1.3.3.2.1.1.1.1.1.2"></times><ci id="S4.Ex1.m1.3.3.2.1.1.1.1.1.3.cmml" xref="S4.Ex1.m1.3.3.2.1.1.1.1.1.3">ℳ</ci><apply id="S4.Ex1.m1.3.3.2.1.1.1.1.1.1.1.1.cmml" xref="S4.Ex1.m1.3.3.2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.Ex1.m1.3.3.2.1.1.1.1.1.1.1.1.1.cmml" xref="S4.Ex1.m1.3.3.2.1.1.1.1.1.1.1">superscript</csymbol><ci id="S4.Ex1.m1.3.3.2.1.1.1.1.1.1.1.1.2.cmml" xref="S4.Ex1.m1.3.3.2.1.1.1.1.1.1.1.1.2">𝒟</ci><ci id="S4.Ex1.m1.3.3.2.1.1.1.1.1.1.1.1.3.cmml" xref="S4.Ex1.m1.3.3.2.1.1.1.1.1.1.1.1.3">′</ci></apply></apply><ci id="S4.Ex1.m1.3.3.2.1.1.1.1.3.cmml" xref="S4.Ex1.m1.3.3.2.1.1.1.1.3">𝒮</ci></apply></apply><ci id="S4.Ex1.m1.3.3.2.3.cmml" xref="S4.Ex1.m1.3.3.2.3">𝛿</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.Ex1.m1.3c">\mathbb{P}(\mathcal{M(\mathcal{D})}\in\mathcal{S})\leq e^{\varepsilon}\mathbb{P}(\mathcal{M(\mathcal{D}^{\prime})}\in\mathcal{S})+\delta</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="Thmdefinition2.p1.7" class="ltx_p"><span id="Thmdefinition2.p1.7.3" class="ltx_text ltx_font_italic">When <math id="Thmdefinition2.p1.5.1.m1.1" class="ltx_Math" alttext="\delta=0" display="inline"><semantics id="Thmdefinition2.p1.5.1.m1.1a"><mrow id="Thmdefinition2.p1.5.1.m1.1.1" xref="Thmdefinition2.p1.5.1.m1.1.1.cmml"><mi id="Thmdefinition2.p1.5.1.m1.1.1.2" xref="Thmdefinition2.p1.5.1.m1.1.1.2.cmml">δ</mi><mo id="Thmdefinition2.p1.5.1.m1.1.1.1" xref="Thmdefinition2.p1.5.1.m1.1.1.1.cmml">=</mo><mn id="Thmdefinition2.p1.5.1.m1.1.1.3" xref="Thmdefinition2.p1.5.1.m1.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="Thmdefinition2.p1.5.1.m1.1b"><apply id="Thmdefinition2.p1.5.1.m1.1.1.cmml" xref="Thmdefinition2.p1.5.1.m1.1.1"><eq id="Thmdefinition2.p1.5.1.m1.1.1.1.cmml" xref="Thmdefinition2.p1.5.1.m1.1.1.1"></eq><ci id="Thmdefinition2.p1.5.1.m1.1.1.2.cmml" xref="Thmdefinition2.p1.5.1.m1.1.1.2">𝛿</ci><cn type="integer" id="Thmdefinition2.p1.5.1.m1.1.1.3.cmml" xref="Thmdefinition2.p1.5.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition2.p1.5.1.m1.1c">\delta=0</annotation></semantics></math>, <math id="Thmdefinition2.p1.6.2.m2.1" class="ltx_Math" alttext="\mathcal{M}" display="inline"><semantics id="Thmdefinition2.p1.6.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="Thmdefinition2.p1.6.2.m2.1.1" xref="Thmdefinition2.p1.6.2.m2.1.1.cmml">ℳ</mi><annotation-xml encoding="MathML-Content" id="Thmdefinition2.p1.6.2.m2.1b"><ci id="Thmdefinition2.p1.6.2.m2.1.1.cmml" xref="Thmdefinition2.p1.6.2.m2.1.1">ℳ</ci></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition2.p1.6.2.m2.1c">\mathcal{M}</annotation></semantics></math> is said to be <em id="Thmdefinition2.p1.7.3.1" class="ltx_emph ltx_font_upright">pure <math id="Thmdefinition2.p1.7.3.1.m1.1" class="ltx_Math" alttext="\varepsilon" display="inline"><semantics id="Thmdefinition2.p1.7.3.1.m1.1a"><mi id="Thmdefinition2.p1.7.3.1.m1.1.1" xref="Thmdefinition2.p1.7.3.1.m1.1.1.cmml">ε</mi><annotation-xml encoding="MathML-Content" id="Thmdefinition2.p1.7.3.1.m1.1b"><ci id="Thmdefinition2.p1.7.3.1.m1.1.1.cmml" xref="Thmdefinition2.p1.7.3.1.m1.1.1">𝜀</ci></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition2.p1.7.3.1.m1.1c">\varepsilon</annotation></semantics></math>-differentially private</em>.</span></p>
</div>
</div>
<div id="S4.SS2.p4" class="ltx_para">
<p id="S4.SS2.p4.1" class="ltx_p">Intuitively, the key promise of differential privacy is that <span id="S4.SS2.p4.1.1" class="ltx_text ltx_font_italic">any</span> analysis run on the output of a differentially private procedure will yield approximately the same result whether or not any individual contributes their record to the dataset.
This also includes potential harms that could be caused by the publication of potentially sensitive information.
For instance, assume that a DP procedure is used to train a ML model to detect a specific disease from sensitive medical records.
No operation performed on this model (e.g. inspecting its parameters, applying it to well chosen inputs) can reveal information about individual training records.
Hence, it serves as a form of statistical guarantee for individuals that the collection and use of their data will not yield negative consequences (that would not otherwise occur even if the data was not shared<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>A notorious <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> example of this is an insurance company updating premiums based on the result of a study showing correlation between smoking and lung cancer. A client’s premium might go up even if their data is not used in the study. Differential privacy here ensures that the result of the study would not change too much whether they give their data or not.</span></span></span>).
Formally, from a Bayesian point of view, this means that for all potential priors over datasets, the posterior computed after observing the outcome will be similar to the posterior obtained if any one user was removed from the dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib72" title="" class="ltx_ref">72</a>]</cite>.</p>
</div>
<section id="S4.SS2.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Bayesian interpretation of Differential Privacy</h5>

<div id="S4.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS2.SSS0.Px1.p1.5" class="ltx_p"><span id="S4.SS2.SSS0.Px1.p1.5.5" class="ltx_text ltx_font_italic">It is instructive to consider the Bayesian interpretation of privacy guarantees implied by differential privacy, which compares the adversary’s prior with the posterior. To that end it is useful to view <math id="S4.SS2.SSS0.Px1.p1.1.1.m1.1" class="ltx_Math" alttext="\mathcal{D}" display="inline"><semantics id="S4.SS2.SSS0.Px1.p1.1.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS2.SSS0.Px1.p1.1.1.m1.1.1" xref="S4.SS2.SSS0.Px1.p1.1.1.m1.1.1.cmml">𝒟</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px1.p1.1.1.m1.1b"><ci id="S4.SS2.SSS0.Px1.p1.1.1.m1.1.1.cmml" xref="S4.SS2.SSS0.Px1.p1.1.1.m1.1.1">𝒟</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px1.p1.1.1.m1.1c">\mathcal{D}</annotation></semantics></math> and <math id="S4.SS2.SSS0.Px1.p1.2.2.m2.1" class="ltx_Math" alttext="\mathcal{D}^{\prime}" display="inline"><semantics id="S4.SS2.SSS0.Px1.p1.2.2.m2.1a"><msup id="S4.SS2.SSS0.Px1.p1.2.2.m2.1.1" xref="S4.SS2.SSS0.Px1.p1.2.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS2.SSS0.Px1.p1.2.2.m2.1.1.2" xref="S4.SS2.SSS0.Px1.p1.2.2.m2.1.1.2.cmml">𝒟</mi><mo id="S4.SS2.SSS0.Px1.p1.2.2.m2.1.1.3" xref="S4.SS2.SSS0.Px1.p1.2.2.m2.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px1.p1.2.2.m2.1b"><apply id="S4.SS2.SSS0.Px1.p1.2.2.m2.1.1.cmml" xref="S4.SS2.SSS0.Px1.p1.2.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS0.Px1.p1.2.2.m2.1.1.1.cmml" xref="S4.SS2.SSS0.Px1.p1.2.2.m2.1.1">superscript</csymbol><ci id="S4.SS2.SSS0.Px1.p1.2.2.m2.1.1.2.cmml" xref="S4.SS2.SSS0.Px1.p1.2.2.m2.1.1.2">𝒟</ci><ci id="S4.SS2.SSS0.Px1.p1.2.2.m2.1.1.3.cmml" xref="S4.SS2.SSS0.Px1.p1.2.2.m2.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px1.p1.2.2.m2.1c">\mathcal{D}^{\prime}</annotation></semantics></math> as a realisation of a random variable <math id="S4.SS2.SSS0.Px1.p1.3.3.m3.1" class="ltx_Math" alttext="\bm{\mathcal{D}}" display="inline"><semantics id="S4.SS2.SSS0.Px1.p1.3.3.m3.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS2.SSS0.Px1.p1.3.3.m3.1.1" xref="S4.SS2.SSS0.Px1.p1.3.3.m3.1.1.cmml">𝓓</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px1.p1.3.3.m3.1b"><ci id="S4.SS2.SSS0.Px1.p1.3.3.m3.1.1.cmml" xref="S4.SS2.SSS0.Px1.p1.3.3.m3.1.1">𝓓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px1.p1.3.3.m3.1c">\bm{\mathcal{D}}</annotation></semantics></math>. That way we can model prior knowledge an adversary has about the dataset i.e <math id="S4.SS2.SSS0.Px1.p1.4.4.m4.1" class="ltx_Math" alttext="\mathbb{P}(\bm{\mathcal{D}}=\mathcal{D})" display="inline"><semantics id="S4.SS2.SSS0.Px1.p1.4.4.m4.1a"><mrow id="S4.SS2.SSS0.Px1.p1.4.4.m4.1.1" xref="S4.SS2.SSS0.Px1.p1.4.4.m4.1.1.cmml"><mi id="S4.SS2.SSS0.Px1.p1.4.4.m4.1.1.3" xref="S4.SS2.SSS0.Px1.p1.4.4.m4.1.1.3.cmml">ℙ</mi><mo lspace="0em" rspace="0em" id="S4.SS2.SSS0.Px1.p1.4.4.m4.1.1.2" xref="S4.SS2.SSS0.Px1.p1.4.4.m4.1.1.2.cmml">​</mo><mrow id="S4.SS2.SSS0.Px1.p1.4.4.m4.1.1.1.1" xref="S4.SS2.SSS0.Px1.p1.4.4.m4.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.SS2.SSS0.Px1.p1.4.4.m4.1.1.1.1.2" xref="S4.SS2.SSS0.Px1.p1.4.4.m4.1.1.1.1.1.cmml">(</mo><mrow id="S4.SS2.SSS0.Px1.p1.4.4.m4.1.1.1.1.1" xref="S4.SS2.SSS0.Px1.p1.4.4.m4.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS2.SSS0.Px1.p1.4.4.m4.1.1.1.1.1.2" xref="S4.SS2.SSS0.Px1.p1.4.4.m4.1.1.1.1.1.2.cmml">𝓓</mi><mo id="S4.SS2.SSS0.Px1.p1.4.4.m4.1.1.1.1.1.1" xref="S4.SS2.SSS0.Px1.p1.4.4.m4.1.1.1.1.1.1.cmml">=</mo><mi class="ltx_font_mathcaligraphic" id="S4.SS2.SSS0.Px1.p1.4.4.m4.1.1.1.1.1.3" xref="S4.SS2.SSS0.Px1.p1.4.4.m4.1.1.1.1.1.3.cmml">𝒟</mi></mrow><mo stretchy="false" id="S4.SS2.SSS0.Px1.p1.4.4.m4.1.1.1.1.3" xref="S4.SS2.SSS0.Px1.p1.4.4.m4.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px1.p1.4.4.m4.1b"><apply id="S4.SS2.SSS0.Px1.p1.4.4.m4.1.1.cmml" xref="S4.SS2.SSS0.Px1.p1.4.4.m4.1.1"><times id="S4.SS2.SSS0.Px1.p1.4.4.m4.1.1.2.cmml" xref="S4.SS2.SSS0.Px1.p1.4.4.m4.1.1.2"></times><ci id="S4.SS2.SSS0.Px1.p1.4.4.m4.1.1.3.cmml" xref="S4.SS2.SSS0.Px1.p1.4.4.m4.1.1.3">ℙ</ci><apply id="S4.SS2.SSS0.Px1.p1.4.4.m4.1.1.1.1.1.cmml" xref="S4.SS2.SSS0.Px1.p1.4.4.m4.1.1.1.1"><eq id="S4.SS2.SSS0.Px1.p1.4.4.m4.1.1.1.1.1.1.cmml" xref="S4.SS2.SSS0.Px1.p1.4.4.m4.1.1.1.1.1.1"></eq><ci id="S4.SS2.SSS0.Px1.p1.4.4.m4.1.1.1.1.1.2.cmml" xref="S4.SS2.SSS0.Px1.p1.4.4.m4.1.1.1.1.1.2">𝓓</ci><ci id="S4.SS2.SSS0.Px1.p1.4.4.m4.1.1.1.1.1.3.cmml" xref="S4.SS2.SSS0.Px1.p1.4.4.m4.1.1.1.1.1.3">𝒟</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px1.p1.4.4.m4.1c">\mathbb{P}(\bm{\mathcal{D}}=\mathcal{D})</annotation></semantics></math>. Note that <math id="S4.SS2.SSS0.Px1.p1.5.5.m5.2" class="ltx_Math" alttext="(\epsilon,0)" display="inline"><semantics id="S4.SS2.SSS0.Px1.p1.5.5.m5.2a"><mrow id="S4.SS2.SSS0.Px1.p1.5.5.m5.2.3.2" xref="S4.SS2.SSS0.Px1.p1.5.5.m5.2.3.1.cmml"><mo stretchy="false" id="S4.SS2.SSS0.Px1.p1.5.5.m5.2.3.2.1" xref="S4.SS2.SSS0.Px1.p1.5.5.m5.2.3.1.cmml">(</mo><mi id="S4.SS2.SSS0.Px1.p1.5.5.m5.1.1" xref="S4.SS2.SSS0.Px1.p1.5.5.m5.1.1.cmml">ϵ</mi><mo id="S4.SS2.SSS0.Px1.p1.5.5.m5.2.3.2.2" xref="S4.SS2.SSS0.Px1.p1.5.5.m5.2.3.1.cmml">,</mo><mn id="S4.SS2.SSS0.Px1.p1.5.5.m5.2.2" xref="S4.SS2.SSS0.Px1.p1.5.5.m5.2.2.cmml">0</mn><mo stretchy="false" id="S4.SS2.SSS0.Px1.p1.5.5.m5.2.3.2.3" xref="S4.SS2.SSS0.Px1.p1.5.5.m5.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px1.p1.5.5.m5.2b"><interval closure="open" id="S4.SS2.SSS0.Px1.p1.5.5.m5.2.3.1.cmml" xref="S4.SS2.SSS0.Px1.p1.5.5.m5.2.3.2"><ci id="S4.SS2.SSS0.Px1.p1.5.5.m5.1.1.cmml" xref="S4.SS2.SSS0.Px1.p1.5.5.m5.1.1">italic-ϵ</ci><cn type="integer" id="S4.SS2.SSS0.Px1.p1.5.5.m5.2.2.cmml" xref="S4.SS2.SSS0.Px1.p1.5.5.m5.2.2">0</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px1.p1.5.5.m5.2c">(\epsilon,0)</annotation></semantics></math>-differential privacy implies a bound on the Bayes factor</span></p>
<table id="S4.Ex2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.Ex2.m1.5" class="ltx_Math" alttext="\frac{\mathbb{P}(\mathcal{M}(\bm{\mathcal{D}})|\bm{\mathcal{D}}=\mathcal{D})}{\mathbb{P}(\mathcal{M}(\bm{\mathcal{D}})|\bm{\mathcal{D}}=\mathcal{D}^{\prime})}\leq e^{\epsilon}\,." display="block"><semantics id="S4.Ex2.m1.5a"><mrow id="S4.Ex2.m1.5.5.1" xref="S4.Ex2.m1.5.5.1.1.cmml"><mrow id="S4.Ex2.m1.5.5.1.1" xref="S4.Ex2.m1.5.5.1.1.cmml"><mfrac id="S4.Ex2.m1.4.4" xref="S4.Ex2.m1.4.4.cmml"><mrow id="S4.Ex2.m1.2.2.2" xref="S4.Ex2.m1.2.2.2.cmml"><mi id="S4.Ex2.m1.2.2.2.4" xref="S4.Ex2.m1.2.2.2.4.cmml">ℙ</mi><mo lspace="0em" rspace="0em" id="S4.Ex2.m1.2.2.2.3" xref="S4.Ex2.m1.2.2.2.3.cmml">​</mo><mrow id="S4.Ex2.m1.2.2.2.2.1" xref="S4.Ex2.m1.2.2.2.2.1.1.cmml"><mo stretchy="false" id="S4.Ex2.m1.2.2.2.2.1.2" xref="S4.Ex2.m1.2.2.2.2.1.1.cmml">(</mo><mrow id="S4.Ex2.m1.2.2.2.2.1.1" xref="S4.Ex2.m1.2.2.2.2.1.1.cmml"><mrow id="S4.Ex2.m1.2.2.2.2.1.1.2" xref="S4.Ex2.m1.2.2.2.2.1.1.2.cmml"><mrow id="S4.Ex2.m1.2.2.2.2.1.1.2.2" xref="S4.Ex2.m1.2.2.2.2.1.1.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.Ex2.m1.2.2.2.2.1.1.2.2.2" xref="S4.Ex2.m1.2.2.2.2.1.1.2.2.2.cmml">ℳ</mi><mo lspace="0em" rspace="0em" id="S4.Ex2.m1.2.2.2.2.1.1.2.2.1" xref="S4.Ex2.m1.2.2.2.2.1.1.2.2.1.cmml">​</mo><mrow id="S4.Ex2.m1.2.2.2.2.1.1.2.2.3.2" xref="S4.Ex2.m1.2.2.2.2.1.1.2.2.cmml"><mo stretchy="false" id="S4.Ex2.m1.2.2.2.2.1.1.2.2.3.2.1" xref="S4.Ex2.m1.2.2.2.2.1.1.2.2.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S4.Ex2.m1.1.1.1.1" xref="S4.Ex2.m1.1.1.1.1.cmml">𝓓</mi><mo stretchy="false" id="S4.Ex2.m1.2.2.2.2.1.1.2.2.3.2.2" xref="S4.Ex2.m1.2.2.2.2.1.1.2.2.cmml">)</mo></mrow></mrow><mo fence="false" id="S4.Ex2.m1.2.2.2.2.1.1.2.1" xref="S4.Ex2.m1.2.2.2.2.1.1.2.1.cmml">|</mo><mi class="ltx_font_mathcaligraphic" id="S4.Ex2.m1.2.2.2.2.1.1.2.3" xref="S4.Ex2.m1.2.2.2.2.1.1.2.3.cmml">𝓓</mi></mrow><mo id="S4.Ex2.m1.2.2.2.2.1.1.1" xref="S4.Ex2.m1.2.2.2.2.1.1.1.cmml">=</mo><mi class="ltx_font_mathcaligraphic" id="S4.Ex2.m1.2.2.2.2.1.1.3" xref="S4.Ex2.m1.2.2.2.2.1.1.3.cmml">𝒟</mi></mrow><mo stretchy="false" id="S4.Ex2.m1.2.2.2.2.1.3" xref="S4.Ex2.m1.2.2.2.2.1.1.cmml">)</mo></mrow></mrow><mrow id="S4.Ex2.m1.4.4.4" xref="S4.Ex2.m1.4.4.4.cmml"><mi id="S4.Ex2.m1.4.4.4.4" xref="S4.Ex2.m1.4.4.4.4.cmml">ℙ</mi><mo lspace="0em" rspace="0em" id="S4.Ex2.m1.4.4.4.3" xref="S4.Ex2.m1.4.4.4.3.cmml">​</mo><mrow id="S4.Ex2.m1.4.4.4.2.1" xref="S4.Ex2.m1.4.4.4.2.1.1.cmml"><mo stretchy="false" id="S4.Ex2.m1.4.4.4.2.1.2" xref="S4.Ex2.m1.4.4.4.2.1.1.cmml">(</mo><mrow id="S4.Ex2.m1.4.4.4.2.1.1" xref="S4.Ex2.m1.4.4.4.2.1.1.cmml"><mrow id="S4.Ex2.m1.4.4.4.2.1.1.2" xref="S4.Ex2.m1.4.4.4.2.1.1.2.cmml"><mrow id="S4.Ex2.m1.4.4.4.2.1.1.2.2" xref="S4.Ex2.m1.4.4.4.2.1.1.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.Ex2.m1.4.4.4.2.1.1.2.2.2" xref="S4.Ex2.m1.4.4.4.2.1.1.2.2.2.cmml">ℳ</mi><mo lspace="0em" rspace="0em" id="S4.Ex2.m1.4.4.4.2.1.1.2.2.1" xref="S4.Ex2.m1.4.4.4.2.1.1.2.2.1.cmml">​</mo><mrow id="S4.Ex2.m1.4.4.4.2.1.1.2.2.3.2" xref="S4.Ex2.m1.4.4.4.2.1.1.2.2.cmml"><mo stretchy="false" id="S4.Ex2.m1.4.4.4.2.1.1.2.2.3.2.1" xref="S4.Ex2.m1.4.4.4.2.1.1.2.2.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S4.Ex2.m1.3.3.3.1" xref="S4.Ex2.m1.3.3.3.1.cmml">𝓓</mi><mo stretchy="false" id="S4.Ex2.m1.4.4.4.2.1.1.2.2.3.2.2" xref="S4.Ex2.m1.4.4.4.2.1.1.2.2.cmml">)</mo></mrow></mrow><mo fence="false" id="S4.Ex2.m1.4.4.4.2.1.1.2.1" xref="S4.Ex2.m1.4.4.4.2.1.1.2.1.cmml">|</mo><mi class="ltx_font_mathcaligraphic" id="S4.Ex2.m1.4.4.4.2.1.1.2.3" xref="S4.Ex2.m1.4.4.4.2.1.1.2.3.cmml">𝓓</mi></mrow><mo id="S4.Ex2.m1.4.4.4.2.1.1.1" xref="S4.Ex2.m1.4.4.4.2.1.1.1.cmml">=</mo><msup id="S4.Ex2.m1.4.4.4.2.1.1.3" xref="S4.Ex2.m1.4.4.4.2.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.Ex2.m1.4.4.4.2.1.1.3.2" xref="S4.Ex2.m1.4.4.4.2.1.1.3.2.cmml">𝒟</mi><mo id="S4.Ex2.m1.4.4.4.2.1.1.3.3" xref="S4.Ex2.m1.4.4.4.2.1.1.3.3.cmml">′</mo></msup></mrow><mo stretchy="false" id="S4.Ex2.m1.4.4.4.2.1.3" xref="S4.Ex2.m1.4.4.4.2.1.1.cmml">)</mo></mrow></mrow></mfrac><mo id="S4.Ex2.m1.5.5.1.1.1" xref="S4.Ex2.m1.5.5.1.1.1.cmml">≤</mo><msup id="S4.Ex2.m1.5.5.1.1.2" xref="S4.Ex2.m1.5.5.1.1.2.cmml"><mi id="S4.Ex2.m1.5.5.1.1.2.2" xref="S4.Ex2.m1.5.5.1.1.2.2.cmml">e</mi><mi id="S4.Ex2.m1.5.5.1.1.2.3" xref="S4.Ex2.m1.5.5.1.1.2.3.cmml">ϵ</mi></msup></mrow><mo lspace="0em" id="S4.Ex2.m1.5.5.1.2" xref="S4.Ex2.m1.5.5.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.Ex2.m1.5b"><apply id="S4.Ex2.m1.5.5.1.1.cmml" xref="S4.Ex2.m1.5.5.1"><leq id="S4.Ex2.m1.5.5.1.1.1.cmml" xref="S4.Ex2.m1.5.5.1.1.1"></leq><apply id="S4.Ex2.m1.4.4.cmml" xref="S4.Ex2.m1.4.4"><divide id="S4.Ex2.m1.4.4.5.cmml" xref="S4.Ex2.m1.4.4"></divide><apply id="S4.Ex2.m1.2.2.2.cmml" xref="S4.Ex2.m1.2.2.2"><times id="S4.Ex2.m1.2.2.2.3.cmml" xref="S4.Ex2.m1.2.2.2.3"></times><ci id="S4.Ex2.m1.2.2.2.4.cmml" xref="S4.Ex2.m1.2.2.2.4">ℙ</ci><apply id="S4.Ex2.m1.2.2.2.2.1.1.cmml" xref="S4.Ex2.m1.2.2.2.2.1"><eq id="S4.Ex2.m1.2.2.2.2.1.1.1.cmml" xref="S4.Ex2.m1.2.2.2.2.1.1.1"></eq><apply id="S4.Ex2.m1.2.2.2.2.1.1.2.cmml" xref="S4.Ex2.m1.2.2.2.2.1.1.2"><csymbol cd="latexml" id="S4.Ex2.m1.2.2.2.2.1.1.2.1.cmml" xref="S4.Ex2.m1.2.2.2.2.1.1.2.1">conditional</csymbol><apply id="S4.Ex2.m1.2.2.2.2.1.1.2.2.cmml" xref="S4.Ex2.m1.2.2.2.2.1.1.2.2"><times id="S4.Ex2.m1.2.2.2.2.1.1.2.2.1.cmml" xref="S4.Ex2.m1.2.2.2.2.1.1.2.2.1"></times><ci id="S4.Ex2.m1.2.2.2.2.1.1.2.2.2.cmml" xref="S4.Ex2.m1.2.2.2.2.1.1.2.2.2">ℳ</ci><ci id="S4.Ex2.m1.1.1.1.1.cmml" xref="S4.Ex2.m1.1.1.1.1">𝓓</ci></apply><ci id="S4.Ex2.m1.2.2.2.2.1.1.2.3.cmml" xref="S4.Ex2.m1.2.2.2.2.1.1.2.3">𝓓</ci></apply><ci id="S4.Ex2.m1.2.2.2.2.1.1.3.cmml" xref="S4.Ex2.m1.2.2.2.2.1.1.3">𝒟</ci></apply></apply><apply id="S4.Ex2.m1.4.4.4.cmml" xref="S4.Ex2.m1.4.4.4"><times id="S4.Ex2.m1.4.4.4.3.cmml" xref="S4.Ex2.m1.4.4.4.3"></times><ci id="S4.Ex2.m1.4.4.4.4.cmml" xref="S4.Ex2.m1.4.4.4.4">ℙ</ci><apply id="S4.Ex2.m1.4.4.4.2.1.1.cmml" xref="S4.Ex2.m1.4.4.4.2.1"><eq id="S4.Ex2.m1.4.4.4.2.1.1.1.cmml" xref="S4.Ex2.m1.4.4.4.2.1.1.1"></eq><apply id="S4.Ex2.m1.4.4.4.2.1.1.2.cmml" xref="S4.Ex2.m1.4.4.4.2.1.1.2"><csymbol cd="latexml" id="S4.Ex2.m1.4.4.4.2.1.1.2.1.cmml" xref="S4.Ex2.m1.4.4.4.2.1.1.2.1">conditional</csymbol><apply id="S4.Ex2.m1.4.4.4.2.1.1.2.2.cmml" xref="S4.Ex2.m1.4.4.4.2.1.1.2.2"><times id="S4.Ex2.m1.4.4.4.2.1.1.2.2.1.cmml" xref="S4.Ex2.m1.4.4.4.2.1.1.2.2.1"></times><ci id="S4.Ex2.m1.4.4.4.2.1.1.2.2.2.cmml" xref="S4.Ex2.m1.4.4.4.2.1.1.2.2.2">ℳ</ci><ci id="S4.Ex2.m1.3.3.3.1.cmml" xref="S4.Ex2.m1.3.3.3.1">𝓓</ci></apply><ci id="S4.Ex2.m1.4.4.4.2.1.1.2.3.cmml" xref="S4.Ex2.m1.4.4.4.2.1.1.2.3">𝓓</ci></apply><apply id="S4.Ex2.m1.4.4.4.2.1.1.3.cmml" xref="S4.Ex2.m1.4.4.4.2.1.1.3"><csymbol cd="ambiguous" id="S4.Ex2.m1.4.4.4.2.1.1.3.1.cmml" xref="S4.Ex2.m1.4.4.4.2.1.1.3">superscript</csymbol><ci id="S4.Ex2.m1.4.4.4.2.1.1.3.2.cmml" xref="S4.Ex2.m1.4.4.4.2.1.1.3.2">𝒟</ci><ci id="S4.Ex2.m1.4.4.4.2.1.1.3.3.cmml" xref="S4.Ex2.m1.4.4.4.2.1.1.3.3">′</ci></apply></apply></apply></apply><apply id="S4.Ex2.m1.5.5.1.1.2.cmml" xref="S4.Ex2.m1.5.5.1.1.2"><csymbol cd="ambiguous" id="S4.Ex2.m1.5.5.1.1.2.1.cmml" xref="S4.Ex2.m1.5.5.1.1.2">superscript</csymbol><ci id="S4.Ex2.m1.5.5.1.1.2.2.cmml" xref="S4.Ex2.m1.5.5.1.1.2.2">𝑒</ci><ci id="S4.Ex2.m1.5.5.1.1.2.3.cmml" xref="S4.Ex2.m1.5.5.1.1.2.3">italic-ϵ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.Ex2.m1.5c">\frac{\mathbb{P}(\mathcal{M}(\bm{\mathcal{D}})|\bm{\mathcal{D}}=\mathcal{D})}{\mathbb{P}(\mathcal{M}(\bm{\mathcal{D}})|\bm{\mathcal{D}}=\mathcal{D}^{\prime})}\leq e^{\epsilon}\,.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S4.SS2.SSS0.Px1.p1.6" class="ltx_p"><span id="S4.SS2.SSS0.Px1.p1.6.1" class="ltx_text ltx_font_italic">This then implies a privacy guarantee on posterior beliefs regarding the value of <math id="S4.SS2.SSS0.Px1.p1.6.1.m1.1" class="ltx_Math" alttext="\bm{\mathcal{D}}" display="inline"><semantics id="S4.SS2.SSS0.Px1.p1.6.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS2.SSS0.Px1.p1.6.1.m1.1.1" xref="S4.SS2.SSS0.Px1.p1.6.1.m1.1.1.cmml">𝓓</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px1.p1.6.1.m1.1b"><ci id="S4.SS2.SSS0.Px1.p1.6.1.m1.1.1.cmml" xref="S4.SS2.SSS0.Px1.p1.6.1.m1.1.1">𝓓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px1.p1.6.1.m1.1c">\bm{\mathcal{D}}</annotation></semantics></math> given the output of a differentially private algorithm</span></p>
<table id="S4.Ex3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.Ex3.m1.13" class="ltx_Math" alttext="\frac{\mathbb{P}(\bm{\mathcal{D}}=\mathcal{D}|\mathcal{M}(\bm{\mathcal{D}}))}{\mathbb{P}(\bm{\mathcal{D}}=\mathcal{D}^{\prime}|\mathcal{M}(\bm{\mathcal{D}}))}=\frac{\mathbb{P}(\mathcal{M}(\bm{\mathcal{D}})|\bm{\mathcal{D}}=\mathcal{D})}{\mathbb{P}(\mathcal{M}(\bm{\mathcal{D}})|\bm{\mathcal{D}}=\mathcal{D}^{\prime})}\frac{\mathbb{P}(\bm{\mathcal{D}}=\mathcal{D})}{\mathbb{P}(\bm{\mathcal{D}}=\mathcal{D}^{\prime})}\leq e^{\epsilon}\frac{\mathbb{P}(\bm{\mathcal{D}}=\mathcal{D})}{\mathbb{P}(\bm{\mathcal{D}}=\mathcal{D}^{\prime})}\,." display="block"><semantics id="S4.Ex3.m1.13a"><mrow id="S4.Ex3.m1.13.13.1" xref="S4.Ex3.m1.13.13.1.1.cmml"><mrow id="S4.Ex3.m1.13.13.1.1" xref="S4.Ex3.m1.13.13.1.1.cmml"><mfrac id="S4.Ex3.m1.4.4" xref="S4.Ex3.m1.4.4.cmml"><mrow id="S4.Ex3.m1.2.2.2" xref="S4.Ex3.m1.2.2.2.cmml"><mi id="S4.Ex3.m1.2.2.2.4" xref="S4.Ex3.m1.2.2.2.4.cmml">ℙ</mi><mo lspace="0em" rspace="0em" id="S4.Ex3.m1.2.2.2.3" xref="S4.Ex3.m1.2.2.2.3.cmml">​</mo><mrow id="S4.Ex3.m1.2.2.2.2.1" xref="S4.Ex3.m1.2.2.2.2.1.1.cmml"><mo stretchy="false" id="S4.Ex3.m1.2.2.2.2.1.2" xref="S4.Ex3.m1.2.2.2.2.1.1.cmml">(</mo><mrow id="S4.Ex3.m1.2.2.2.2.1.1" xref="S4.Ex3.m1.2.2.2.2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.Ex3.m1.2.2.2.2.1.1.2" xref="S4.Ex3.m1.2.2.2.2.1.1.2.cmml">𝓓</mi><mo id="S4.Ex3.m1.2.2.2.2.1.1.1" xref="S4.Ex3.m1.2.2.2.2.1.1.1.cmml">=</mo><mrow id="S4.Ex3.m1.2.2.2.2.1.1.3" xref="S4.Ex3.m1.2.2.2.2.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.Ex3.m1.2.2.2.2.1.1.3.2" xref="S4.Ex3.m1.2.2.2.2.1.1.3.2.cmml">𝒟</mi><mo fence="false" id="S4.Ex3.m1.2.2.2.2.1.1.3.1" xref="S4.Ex3.m1.2.2.2.2.1.1.3.1.cmml">|</mo><mrow id="S4.Ex3.m1.2.2.2.2.1.1.3.3" xref="S4.Ex3.m1.2.2.2.2.1.1.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.Ex3.m1.2.2.2.2.1.1.3.3.2" xref="S4.Ex3.m1.2.2.2.2.1.1.3.3.2.cmml">ℳ</mi><mo lspace="0em" rspace="0em" id="S4.Ex3.m1.2.2.2.2.1.1.3.3.1" xref="S4.Ex3.m1.2.2.2.2.1.1.3.3.1.cmml">​</mo><mrow id="S4.Ex3.m1.2.2.2.2.1.1.3.3.3.2" xref="S4.Ex3.m1.2.2.2.2.1.1.3.3.cmml"><mo stretchy="false" id="S4.Ex3.m1.2.2.2.2.1.1.3.3.3.2.1" xref="S4.Ex3.m1.2.2.2.2.1.1.3.3.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S4.Ex3.m1.1.1.1.1" xref="S4.Ex3.m1.1.1.1.1.cmml">𝓓</mi><mo stretchy="false" id="S4.Ex3.m1.2.2.2.2.1.1.3.3.3.2.2" xref="S4.Ex3.m1.2.2.2.2.1.1.3.3.cmml">)</mo></mrow></mrow></mrow></mrow><mo stretchy="false" id="S4.Ex3.m1.2.2.2.2.1.3" xref="S4.Ex3.m1.2.2.2.2.1.1.cmml">)</mo></mrow></mrow><mrow id="S4.Ex3.m1.4.4.4" xref="S4.Ex3.m1.4.4.4.cmml"><mi id="S4.Ex3.m1.4.4.4.4" xref="S4.Ex3.m1.4.4.4.4.cmml">ℙ</mi><mo lspace="0em" rspace="0em" id="S4.Ex3.m1.4.4.4.3" xref="S4.Ex3.m1.4.4.4.3.cmml">​</mo><mrow id="S4.Ex3.m1.4.4.4.2.1" xref="S4.Ex3.m1.4.4.4.2.1.1.cmml"><mo stretchy="false" id="S4.Ex3.m1.4.4.4.2.1.2" xref="S4.Ex3.m1.4.4.4.2.1.1.cmml">(</mo><mrow id="S4.Ex3.m1.4.4.4.2.1.1" xref="S4.Ex3.m1.4.4.4.2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.Ex3.m1.4.4.4.2.1.1.2" xref="S4.Ex3.m1.4.4.4.2.1.1.2.cmml">𝓓</mi><mo id="S4.Ex3.m1.4.4.4.2.1.1.1" xref="S4.Ex3.m1.4.4.4.2.1.1.1.cmml">=</mo><mrow id="S4.Ex3.m1.4.4.4.2.1.1.3" xref="S4.Ex3.m1.4.4.4.2.1.1.3.cmml"><msup id="S4.Ex3.m1.4.4.4.2.1.1.3.2" xref="S4.Ex3.m1.4.4.4.2.1.1.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.Ex3.m1.4.4.4.2.1.1.3.2.2" xref="S4.Ex3.m1.4.4.4.2.1.1.3.2.2.cmml">𝒟</mi><mo id="S4.Ex3.m1.4.4.4.2.1.1.3.2.3" xref="S4.Ex3.m1.4.4.4.2.1.1.3.2.3.cmml">′</mo></msup><mo fence="false" id="S4.Ex3.m1.4.4.4.2.1.1.3.1" xref="S4.Ex3.m1.4.4.4.2.1.1.3.1.cmml">|</mo><mrow id="S4.Ex3.m1.4.4.4.2.1.1.3.3" xref="S4.Ex3.m1.4.4.4.2.1.1.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.Ex3.m1.4.4.4.2.1.1.3.3.2" xref="S4.Ex3.m1.4.4.4.2.1.1.3.3.2.cmml">ℳ</mi><mo lspace="0em" rspace="0em" id="S4.Ex3.m1.4.4.4.2.1.1.3.3.1" xref="S4.Ex3.m1.4.4.4.2.1.1.3.3.1.cmml">​</mo><mrow id="S4.Ex3.m1.4.4.4.2.1.1.3.3.3.2" xref="S4.Ex3.m1.4.4.4.2.1.1.3.3.cmml"><mo stretchy="false" id="S4.Ex3.m1.4.4.4.2.1.1.3.3.3.2.1" xref="S4.Ex3.m1.4.4.4.2.1.1.3.3.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S4.Ex3.m1.3.3.3.1" xref="S4.Ex3.m1.3.3.3.1.cmml">𝓓</mi><mo stretchy="false" id="S4.Ex3.m1.4.4.4.2.1.1.3.3.3.2.2" xref="S4.Ex3.m1.4.4.4.2.1.1.3.3.cmml">)</mo></mrow></mrow></mrow></mrow><mo stretchy="false" id="S4.Ex3.m1.4.4.4.2.1.3" xref="S4.Ex3.m1.4.4.4.2.1.1.cmml">)</mo></mrow></mrow></mfrac><mo id="S4.Ex3.m1.13.13.1.1.2" xref="S4.Ex3.m1.13.13.1.1.2.cmml">=</mo><mrow id="S4.Ex3.m1.13.13.1.1.3" xref="S4.Ex3.m1.13.13.1.1.3.cmml"><mfrac id="S4.Ex3.m1.8.8" xref="S4.Ex3.m1.8.8.cmml"><mrow id="S4.Ex3.m1.6.6.2" xref="S4.Ex3.m1.6.6.2.cmml"><mi id="S4.Ex3.m1.6.6.2.4" xref="S4.Ex3.m1.6.6.2.4.cmml">ℙ</mi><mo lspace="0em" rspace="0em" id="S4.Ex3.m1.6.6.2.3" xref="S4.Ex3.m1.6.6.2.3.cmml">​</mo><mrow id="S4.Ex3.m1.6.6.2.2.1" xref="S4.Ex3.m1.6.6.2.2.1.1.cmml"><mo stretchy="false" id="S4.Ex3.m1.6.6.2.2.1.2" xref="S4.Ex3.m1.6.6.2.2.1.1.cmml">(</mo><mrow id="S4.Ex3.m1.6.6.2.2.1.1" xref="S4.Ex3.m1.6.6.2.2.1.1.cmml"><mrow id="S4.Ex3.m1.6.6.2.2.1.1.2" xref="S4.Ex3.m1.6.6.2.2.1.1.2.cmml"><mrow id="S4.Ex3.m1.6.6.2.2.1.1.2.2" xref="S4.Ex3.m1.6.6.2.2.1.1.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.Ex3.m1.6.6.2.2.1.1.2.2.2" xref="S4.Ex3.m1.6.6.2.2.1.1.2.2.2.cmml">ℳ</mi><mo lspace="0em" rspace="0em" id="S4.Ex3.m1.6.6.2.2.1.1.2.2.1" xref="S4.Ex3.m1.6.6.2.2.1.1.2.2.1.cmml">​</mo><mrow id="S4.Ex3.m1.6.6.2.2.1.1.2.2.3.2" xref="S4.Ex3.m1.6.6.2.2.1.1.2.2.cmml"><mo stretchy="false" id="S4.Ex3.m1.6.6.2.2.1.1.2.2.3.2.1" xref="S4.Ex3.m1.6.6.2.2.1.1.2.2.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S4.Ex3.m1.5.5.1.1" xref="S4.Ex3.m1.5.5.1.1.cmml">𝓓</mi><mo stretchy="false" id="S4.Ex3.m1.6.6.2.2.1.1.2.2.3.2.2" xref="S4.Ex3.m1.6.6.2.2.1.1.2.2.cmml">)</mo></mrow></mrow><mo fence="false" id="S4.Ex3.m1.6.6.2.2.1.1.2.1" xref="S4.Ex3.m1.6.6.2.2.1.1.2.1.cmml">|</mo><mi class="ltx_font_mathcaligraphic" id="S4.Ex3.m1.6.6.2.2.1.1.2.3" xref="S4.Ex3.m1.6.6.2.2.1.1.2.3.cmml">𝓓</mi></mrow><mo id="S4.Ex3.m1.6.6.2.2.1.1.1" xref="S4.Ex3.m1.6.6.2.2.1.1.1.cmml">=</mo><mi class="ltx_font_mathcaligraphic" id="S4.Ex3.m1.6.6.2.2.1.1.3" xref="S4.Ex3.m1.6.6.2.2.1.1.3.cmml">𝒟</mi></mrow><mo stretchy="false" id="S4.Ex3.m1.6.6.2.2.1.3" xref="S4.Ex3.m1.6.6.2.2.1.1.cmml">)</mo></mrow></mrow><mrow id="S4.Ex3.m1.8.8.4" xref="S4.Ex3.m1.8.8.4.cmml"><mi id="S4.Ex3.m1.8.8.4.4" xref="S4.Ex3.m1.8.8.4.4.cmml">ℙ</mi><mo lspace="0em" rspace="0em" id="S4.Ex3.m1.8.8.4.3" xref="S4.Ex3.m1.8.8.4.3.cmml">​</mo><mrow id="S4.Ex3.m1.8.8.4.2.1" xref="S4.Ex3.m1.8.8.4.2.1.1.cmml"><mo stretchy="false" id="S4.Ex3.m1.8.8.4.2.1.2" xref="S4.Ex3.m1.8.8.4.2.1.1.cmml">(</mo><mrow id="S4.Ex3.m1.8.8.4.2.1.1" xref="S4.Ex3.m1.8.8.4.2.1.1.cmml"><mrow id="S4.Ex3.m1.8.8.4.2.1.1.2" xref="S4.Ex3.m1.8.8.4.2.1.1.2.cmml"><mrow id="S4.Ex3.m1.8.8.4.2.1.1.2.2" xref="S4.Ex3.m1.8.8.4.2.1.1.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.Ex3.m1.8.8.4.2.1.1.2.2.2" xref="S4.Ex3.m1.8.8.4.2.1.1.2.2.2.cmml">ℳ</mi><mo lspace="0em" rspace="0em" id="S4.Ex3.m1.8.8.4.2.1.1.2.2.1" xref="S4.Ex3.m1.8.8.4.2.1.1.2.2.1.cmml">​</mo><mrow id="S4.Ex3.m1.8.8.4.2.1.1.2.2.3.2" xref="S4.Ex3.m1.8.8.4.2.1.1.2.2.cmml"><mo stretchy="false" id="S4.Ex3.m1.8.8.4.2.1.1.2.2.3.2.1" xref="S4.Ex3.m1.8.8.4.2.1.1.2.2.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S4.Ex3.m1.7.7.3.1" xref="S4.Ex3.m1.7.7.3.1.cmml">𝓓</mi><mo stretchy="false" id="S4.Ex3.m1.8.8.4.2.1.1.2.2.3.2.2" xref="S4.Ex3.m1.8.8.4.2.1.1.2.2.cmml">)</mo></mrow></mrow><mo fence="false" id="S4.Ex3.m1.8.8.4.2.1.1.2.1" xref="S4.Ex3.m1.8.8.4.2.1.1.2.1.cmml">|</mo><mi class="ltx_font_mathcaligraphic" id="S4.Ex3.m1.8.8.4.2.1.1.2.3" xref="S4.Ex3.m1.8.8.4.2.1.1.2.3.cmml">𝓓</mi></mrow><mo id="S4.Ex3.m1.8.8.4.2.1.1.1" xref="S4.Ex3.m1.8.8.4.2.1.1.1.cmml">=</mo><msup id="S4.Ex3.m1.8.8.4.2.1.1.3" xref="S4.Ex3.m1.8.8.4.2.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.Ex3.m1.8.8.4.2.1.1.3.2" xref="S4.Ex3.m1.8.8.4.2.1.1.3.2.cmml">𝒟</mi><mo id="S4.Ex3.m1.8.8.4.2.1.1.3.3" xref="S4.Ex3.m1.8.8.4.2.1.1.3.3.cmml">′</mo></msup></mrow><mo stretchy="false" id="S4.Ex3.m1.8.8.4.2.1.3" xref="S4.Ex3.m1.8.8.4.2.1.1.cmml">)</mo></mrow></mrow></mfrac><mo lspace="0em" rspace="0em" id="S4.Ex3.m1.13.13.1.1.3.1" xref="S4.Ex3.m1.13.13.1.1.3.1.cmml">​</mo><mfrac id="S4.Ex3.m1.10.10" xref="S4.Ex3.m1.10.10.cmml"><mrow id="S4.Ex3.m1.9.9.1" xref="S4.Ex3.m1.9.9.1.cmml"><mi id="S4.Ex3.m1.9.9.1.3" xref="S4.Ex3.m1.9.9.1.3.cmml">ℙ</mi><mo lspace="0em" rspace="0em" id="S4.Ex3.m1.9.9.1.2" xref="S4.Ex3.m1.9.9.1.2.cmml">​</mo><mrow id="S4.Ex3.m1.9.9.1.1.1" xref="S4.Ex3.m1.9.9.1.1.1.1.cmml"><mo stretchy="false" id="S4.Ex3.m1.9.9.1.1.1.2" xref="S4.Ex3.m1.9.9.1.1.1.1.cmml">(</mo><mrow id="S4.Ex3.m1.9.9.1.1.1.1" xref="S4.Ex3.m1.9.9.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.Ex3.m1.9.9.1.1.1.1.2" xref="S4.Ex3.m1.9.9.1.1.1.1.2.cmml">𝓓</mi><mo id="S4.Ex3.m1.9.9.1.1.1.1.1" xref="S4.Ex3.m1.9.9.1.1.1.1.1.cmml">=</mo><mi class="ltx_font_mathcaligraphic" id="S4.Ex3.m1.9.9.1.1.1.1.3" xref="S4.Ex3.m1.9.9.1.1.1.1.3.cmml">𝒟</mi></mrow><mo stretchy="false" id="S4.Ex3.m1.9.9.1.1.1.3" xref="S4.Ex3.m1.9.9.1.1.1.1.cmml">)</mo></mrow></mrow><mrow id="S4.Ex3.m1.10.10.2" xref="S4.Ex3.m1.10.10.2.cmml"><mi id="S4.Ex3.m1.10.10.2.3" xref="S4.Ex3.m1.10.10.2.3.cmml">ℙ</mi><mo lspace="0em" rspace="0em" id="S4.Ex3.m1.10.10.2.2" xref="S4.Ex3.m1.10.10.2.2.cmml">​</mo><mrow id="S4.Ex3.m1.10.10.2.1.1" xref="S4.Ex3.m1.10.10.2.1.1.1.cmml"><mo stretchy="false" id="S4.Ex3.m1.10.10.2.1.1.2" xref="S4.Ex3.m1.10.10.2.1.1.1.cmml">(</mo><mrow id="S4.Ex3.m1.10.10.2.1.1.1" xref="S4.Ex3.m1.10.10.2.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.Ex3.m1.10.10.2.1.1.1.2" xref="S4.Ex3.m1.10.10.2.1.1.1.2.cmml">𝓓</mi><mo id="S4.Ex3.m1.10.10.2.1.1.1.1" xref="S4.Ex3.m1.10.10.2.1.1.1.1.cmml">=</mo><msup id="S4.Ex3.m1.10.10.2.1.1.1.3" xref="S4.Ex3.m1.10.10.2.1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.Ex3.m1.10.10.2.1.1.1.3.2" xref="S4.Ex3.m1.10.10.2.1.1.1.3.2.cmml">𝒟</mi><mo id="S4.Ex3.m1.10.10.2.1.1.1.3.3" xref="S4.Ex3.m1.10.10.2.1.1.1.3.3.cmml">′</mo></msup></mrow><mo stretchy="false" id="S4.Ex3.m1.10.10.2.1.1.3" xref="S4.Ex3.m1.10.10.2.1.1.1.cmml">)</mo></mrow></mrow></mfrac></mrow><mo id="S4.Ex3.m1.13.13.1.1.4" xref="S4.Ex3.m1.13.13.1.1.4.cmml">≤</mo><mrow id="S4.Ex3.m1.13.13.1.1.5" xref="S4.Ex3.m1.13.13.1.1.5.cmml"><msup id="S4.Ex3.m1.13.13.1.1.5.2" xref="S4.Ex3.m1.13.13.1.1.5.2.cmml"><mi id="S4.Ex3.m1.13.13.1.1.5.2.2" xref="S4.Ex3.m1.13.13.1.1.5.2.2.cmml">e</mi><mi id="S4.Ex3.m1.13.13.1.1.5.2.3" xref="S4.Ex3.m1.13.13.1.1.5.2.3.cmml">ϵ</mi></msup><mo lspace="0em" rspace="0em" id="S4.Ex3.m1.13.13.1.1.5.1" xref="S4.Ex3.m1.13.13.1.1.5.1.cmml">​</mo><mfrac id="S4.Ex3.m1.12.12" xref="S4.Ex3.m1.12.12.cmml"><mrow id="S4.Ex3.m1.11.11.1" xref="S4.Ex3.m1.11.11.1.cmml"><mi id="S4.Ex3.m1.11.11.1.3" xref="S4.Ex3.m1.11.11.1.3.cmml">ℙ</mi><mo lspace="0em" rspace="0em" id="S4.Ex3.m1.11.11.1.2" xref="S4.Ex3.m1.11.11.1.2.cmml">​</mo><mrow id="S4.Ex3.m1.11.11.1.1.1" xref="S4.Ex3.m1.11.11.1.1.1.1.cmml"><mo stretchy="false" id="S4.Ex3.m1.11.11.1.1.1.2" xref="S4.Ex3.m1.11.11.1.1.1.1.cmml">(</mo><mrow id="S4.Ex3.m1.11.11.1.1.1.1" xref="S4.Ex3.m1.11.11.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.Ex3.m1.11.11.1.1.1.1.2" xref="S4.Ex3.m1.11.11.1.1.1.1.2.cmml">𝓓</mi><mo id="S4.Ex3.m1.11.11.1.1.1.1.1" xref="S4.Ex3.m1.11.11.1.1.1.1.1.cmml">=</mo><mi class="ltx_font_mathcaligraphic" id="S4.Ex3.m1.11.11.1.1.1.1.3" xref="S4.Ex3.m1.11.11.1.1.1.1.3.cmml">𝒟</mi></mrow><mo stretchy="false" id="S4.Ex3.m1.11.11.1.1.1.3" xref="S4.Ex3.m1.11.11.1.1.1.1.cmml">)</mo></mrow></mrow><mrow id="S4.Ex3.m1.12.12.2" xref="S4.Ex3.m1.12.12.2.cmml"><mi id="S4.Ex3.m1.12.12.2.3" xref="S4.Ex3.m1.12.12.2.3.cmml">ℙ</mi><mo lspace="0em" rspace="0em" id="S4.Ex3.m1.12.12.2.2" xref="S4.Ex3.m1.12.12.2.2.cmml">​</mo><mrow id="S4.Ex3.m1.12.12.2.1.1" xref="S4.Ex3.m1.12.12.2.1.1.1.cmml"><mo stretchy="false" id="S4.Ex3.m1.12.12.2.1.1.2" xref="S4.Ex3.m1.12.12.2.1.1.1.cmml">(</mo><mrow id="S4.Ex3.m1.12.12.2.1.1.1" xref="S4.Ex3.m1.12.12.2.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.Ex3.m1.12.12.2.1.1.1.2" xref="S4.Ex3.m1.12.12.2.1.1.1.2.cmml">𝓓</mi><mo id="S4.Ex3.m1.12.12.2.1.1.1.1" xref="S4.Ex3.m1.12.12.2.1.1.1.1.cmml">=</mo><msup id="S4.Ex3.m1.12.12.2.1.1.1.3" xref="S4.Ex3.m1.12.12.2.1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.Ex3.m1.12.12.2.1.1.1.3.2" xref="S4.Ex3.m1.12.12.2.1.1.1.3.2.cmml">𝒟</mi><mo id="S4.Ex3.m1.12.12.2.1.1.1.3.3" xref="S4.Ex3.m1.12.12.2.1.1.1.3.3.cmml">′</mo></msup></mrow><mo stretchy="false" id="S4.Ex3.m1.12.12.2.1.1.3" xref="S4.Ex3.m1.12.12.2.1.1.1.cmml">)</mo></mrow></mrow></mfrac></mrow></mrow><mo lspace="0.170em" id="S4.Ex3.m1.13.13.1.2" xref="S4.Ex3.m1.13.13.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.Ex3.m1.13b"><apply id="S4.Ex3.m1.13.13.1.1.cmml" xref="S4.Ex3.m1.13.13.1"><and id="S4.Ex3.m1.13.13.1.1a.cmml" xref="S4.Ex3.m1.13.13.1"></and><apply id="S4.Ex3.m1.13.13.1.1b.cmml" xref="S4.Ex3.m1.13.13.1"><eq id="S4.Ex3.m1.13.13.1.1.2.cmml" xref="S4.Ex3.m1.13.13.1.1.2"></eq><apply id="S4.Ex3.m1.4.4.cmml" xref="S4.Ex3.m1.4.4"><divide id="S4.Ex3.m1.4.4.5.cmml" xref="S4.Ex3.m1.4.4"></divide><apply id="S4.Ex3.m1.2.2.2.cmml" xref="S4.Ex3.m1.2.2.2"><times id="S4.Ex3.m1.2.2.2.3.cmml" xref="S4.Ex3.m1.2.2.2.3"></times><ci id="S4.Ex3.m1.2.2.2.4.cmml" xref="S4.Ex3.m1.2.2.2.4">ℙ</ci><apply id="S4.Ex3.m1.2.2.2.2.1.1.cmml" xref="S4.Ex3.m1.2.2.2.2.1"><eq id="S4.Ex3.m1.2.2.2.2.1.1.1.cmml" xref="S4.Ex3.m1.2.2.2.2.1.1.1"></eq><ci id="S4.Ex3.m1.2.2.2.2.1.1.2.cmml" xref="S4.Ex3.m1.2.2.2.2.1.1.2">𝓓</ci><apply id="S4.Ex3.m1.2.2.2.2.1.1.3.cmml" xref="S4.Ex3.m1.2.2.2.2.1.1.3"><csymbol cd="latexml" id="S4.Ex3.m1.2.2.2.2.1.1.3.1.cmml" xref="S4.Ex3.m1.2.2.2.2.1.1.3.1">conditional</csymbol><ci id="S4.Ex3.m1.2.2.2.2.1.1.3.2.cmml" xref="S4.Ex3.m1.2.2.2.2.1.1.3.2">𝒟</ci><apply id="S4.Ex3.m1.2.2.2.2.1.1.3.3.cmml" xref="S4.Ex3.m1.2.2.2.2.1.1.3.3"><times id="S4.Ex3.m1.2.2.2.2.1.1.3.3.1.cmml" xref="S4.Ex3.m1.2.2.2.2.1.1.3.3.1"></times><ci id="S4.Ex3.m1.2.2.2.2.1.1.3.3.2.cmml" xref="S4.Ex3.m1.2.2.2.2.1.1.3.3.2">ℳ</ci><ci id="S4.Ex3.m1.1.1.1.1.cmml" xref="S4.Ex3.m1.1.1.1.1">𝓓</ci></apply></apply></apply></apply><apply id="S4.Ex3.m1.4.4.4.cmml" xref="S4.Ex3.m1.4.4.4"><times id="S4.Ex3.m1.4.4.4.3.cmml" xref="S4.Ex3.m1.4.4.4.3"></times><ci id="S4.Ex3.m1.4.4.4.4.cmml" xref="S4.Ex3.m1.4.4.4.4">ℙ</ci><apply id="S4.Ex3.m1.4.4.4.2.1.1.cmml" xref="S4.Ex3.m1.4.4.4.2.1"><eq id="S4.Ex3.m1.4.4.4.2.1.1.1.cmml" xref="S4.Ex3.m1.4.4.4.2.1.1.1"></eq><ci id="S4.Ex3.m1.4.4.4.2.1.1.2.cmml" xref="S4.Ex3.m1.4.4.4.2.1.1.2">𝓓</ci><apply id="S4.Ex3.m1.4.4.4.2.1.1.3.cmml" xref="S4.Ex3.m1.4.4.4.2.1.1.3"><csymbol cd="latexml" id="S4.Ex3.m1.4.4.4.2.1.1.3.1.cmml" xref="S4.Ex3.m1.4.4.4.2.1.1.3.1">conditional</csymbol><apply id="S4.Ex3.m1.4.4.4.2.1.1.3.2.cmml" xref="S4.Ex3.m1.4.4.4.2.1.1.3.2"><csymbol cd="ambiguous" id="S4.Ex3.m1.4.4.4.2.1.1.3.2.1.cmml" xref="S4.Ex3.m1.4.4.4.2.1.1.3.2">superscript</csymbol><ci id="S4.Ex3.m1.4.4.4.2.1.1.3.2.2.cmml" xref="S4.Ex3.m1.4.4.4.2.1.1.3.2.2">𝒟</ci><ci id="S4.Ex3.m1.4.4.4.2.1.1.3.2.3.cmml" xref="S4.Ex3.m1.4.4.4.2.1.1.3.2.3">′</ci></apply><apply id="S4.Ex3.m1.4.4.4.2.1.1.3.3.cmml" xref="S4.Ex3.m1.4.4.4.2.1.1.3.3"><times id="S4.Ex3.m1.4.4.4.2.1.1.3.3.1.cmml" xref="S4.Ex3.m1.4.4.4.2.1.1.3.3.1"></times><ci id="S4.Ex3.m1.4.4.4.2.1.1.3.3.2.cmml" xref="S4.Ex3.m1.4.4.4.2.1.1.3.3.2">ℳ</ci><ci id="S4.Ex3.m1.3.3.3.1.cmml" xref="S4.Ex3.m1.3.3.3.1">𝓓</ci></apply></apply></apply></apply></apply><apply id="S4.Ex3.m1.13.13.1.1.3.cmml" xref="S4.Ex3.m1.13.13.1.1.3"><times id="S4.Ex3.m1.13.13.1.1.3.1.cmml" xref="S4.Ex3.m1.13.13.1.1.3.1"></times><apply id="S4.Ex3.m1.8.8.cmml" xref="S4.Ex3.m1.8.8"><divide id="S4.Ex3.m1.8.8.5.cmml" xref="S4.Ex3.m1.8.8"></divide><apply id="S4.Ex3.m1.6.6.2.cmml" xref="S4.Ex3.m1.6.6.2"><times id="S4.Ex3.m1.6.6.2.3.cmml" xref="S4.Ex3.m1.6.6.2.3"></times><ci id="S4.Ex3.m1.6.6.2.4.cmml" xref="S4.Ex3.m1.6.6.2.4">ℙ</ci><apply id="S4.Ex3.m1.6.6.2.2.1.1.cmml" xref="S4.Ex3.m1.6.6.2.2.1"><eq id="S4.Ex3.m1.6.6.2.2.1.1.1.cmml" xref="S4.Ex3.m1.6.6.2.2.1.1.1"></eq><apply id="S4.Ex3.m1.6.6.2.2.1.1.2.cmml" xref="S4.Ex3.m1.6.6.2.2.1.1.2"><csymbol cd="latexml" id="S4.Ex3.m1.6.6.2.2.1.1.2.1.cmml" xref="S4.Ex3.m1.6.6.2.2.1.1.2.1">conditional</csymbol><apply id="S4.Ex3.m1.6.6.2.2.1.1.2.2.cmml" xref="S4.Ex3.m1.6.6.2.2.1.1.2.2"><times id="S4.Ex3.m1.6.6.2.2.1.1.2.2.1.cmml" xref="S4.Ex3.m1.6.6.2.2.1.1.2.2.1"></times><ci id="S4.Ex3.m1.6.6.2.2.1.1.2.2.2.cmml" xref="S4.Ex3.m1.6.6.2.2.1.1.2.2.2">ℳ</ci><ci id="S4.Ex3.m1.5.5.1.1.cmml" xref="S4.Ex3.m1.5.5.1.1">𝓓</ci></apply><ci id="S4.Ex3.m1.6.6.2.2.1.1.2.3.cmml" xref="S4.Ex3.m1.6.6.2.2.1.1.2.3">𝓓</ci></apply><ci id="S4.Ex3.m1.6.6.2.2.1.1.3.cmml" xref="S4.Ex3.m1.6.6.2.2.1.1.3">𝒟</ci></apply></apply><apply id="S4.Ex3.m1.8.8.4.cmml" xref="S4.Ex3.m1.8.8.4"><times id="S4.Ex3.m1.8.8.4.3.cmml" xref="S4.Ex3.m1.8.8.4.3"></times><ci id="S4.Ex3.m1.8.8.4.4.cmml" xref="S4.Ex3.m1.8.8.4.4">ℙ</ci><apply id="S4.Ex3.m1.8.8.4.2.1.1.cmml" xref="S4.Ex3.m1.8.8.4.2.1"><eq id="S4.Ex3.m1.8.8.4.2.1.1.1.cmml" xref="S4.Ex3.m1.8.8.4.2.1.1.1"></eq><apply id="S4.Ex3.m1.8.8.4.2.1.1.2.cmml" xref="S4.Ex3.m1.8.8.4.2.1.1.2"><csymbol cd="latexml" id="S4.Ex3.m1.8.8.4.2.1.1.2.1.cmml" xref="S4.Ex3.m1.8.8.4.2.1.1.2.1">conditional</csymbol><apply id="S4.Ex3.m1.8.8.4.2.1.1.2.2.cmml" xref="S4.Ex3.m1.8.8.4.2.1.1.2.2"><times id="S4.Ex3.m1.8.8.4.2.1.1.2.2.1.cmml" xref="S4.Ex3.m1.8.8.4.2.1.1.2.2.1"></times><ci id="S4.Ex3.m1.8.8.4.2.1.1.2.2.2.cmml" xref="S4.Ex3.m1.8.8.4.2.1.1.2.2.2">ℳ</ci><ci id="S4.Ex3.m1.7.7.3.1.cmml" xref="S4.Ex3.m1.7.7.3.1">𝓓</ci></apply><ci id="S4.Ex3.m1.8.8.4.2.1.1.2.3.cmml" xref="S4.Ex3.m1.8.8.4.2.1.1.2.3">𝓓</ci></apply><apply id="S4.Ex3.m1.8.8.4.2.1.1.3.cmml" xref="S4.Ex3.m1.8.8.4.2.1.1.3"><csymbol cd="ambiguous" id="S4.Ex3.m1.8.8.4.2.1.1.3.1.cmml" xref="S4.Ex3.m1.8.8.4.2.1.1.3">superscript</csymbol><ci id="S4.Ex3.m1.8.8.4.2.1.1.3.2.cmml" xref="S4.Ex3.m1.8.8.4.2.1.1.3.2">𝒟</ci><ci id="S4.Ex3.m1.8.8.4.2.1.1.3.3.cmml" xref="S4.Ex3.m1.8.8.4.2.1.1.3.3">′</ci></apply></apply></apply></apply><apply id="S4.Ex3.m1.10.10.cmml" xref="S4.Ex3.m1.10.10"><divide id="S4.Ex3.m1.10.10.3.cmml" xref="S4.Ex3.m1.10.10"></divide><apply id="S4.Ex3.m1.9.9.1.cmml" xref="S4.Ex3.m1.9.9.1"><times id="S4.Ex3.m1.9.9.1.2.cmml" xref="S4.Ex3.m1.9.9.1.2"></times><ci id="S4.Ex3.m1.9.9.1.3.cmml" xref="S4.Ex3.m1.9.9.1.3">ℙ</ci><apply id="S4.Ex3.m1.9.9.1.1.1.1.cmml" xref="S4.Ex3.m1.9.9.1.1.1"><eq id="S4.Ex3.m1.9.9.1.1.1.1.1.cmml" xref="S4.Ex3.m1.9.9.1.1.1.1.1"></eq><ci id="S4.Ex3.m1.9.9.1.1.1.1.2.cmml" xref="S4.Ex3.m1.9.9.1.1.1.1.2">𝓓</ci><ci id="S4.Ex3.m1.9.9.1.1.1.1.3.cmml" xref="S4.Ex3.m1.9.9.1.1.1.1.3">𝒟</ci></apply></apply><apply id="S4.Ex3.m1.10.10.2.cmml" xref="S4.Ex3.m1.10.10.2"><times id="S4.Ex3.m1.10.10.2.2.cmml" xref="S4.Ex3.m1.10.10.2.2"></times><ci id="S4.Ex3.m1.10.10.2.3.cmml" xref="S4.Ex3.m1.10.10.2.3">ℙ</ci><apply id="S4.Ex3.m1.10.10.2.1.1.1.cmml" xref="S4.Ex3.m1.10.10.2.1.1"><eq id="S4.Ex3.m1.10.10.2.1.1.1.1.cmml" xref="S4.Ex3.m1.10.10.2.1.1.1.1"></eq><ci id="S4.Ex3.m1.10.10.2.1.1.1.2.cmml" xref="S4.Ex3.m1.10.10.2.1.1.1.2">𝓓</ci><apply id="S4.Ex3.m1.10.10.2.1.1.1.3.cmml" xref="S4.Ex3.m1.10.10.2.1.1.1.3"><csymbol cd="ambiguous" id="S4.Ex3.m1.10.10.2.1.1.1.3.1.cmml" xref="S4.Ex3.m1.10.10.2.1.1.1.3">superscript</csymbol><ci id="S4.Ex3.m1.10.10.2.1.1.1.3.2.cmml" xref="S4.Ex3.m1.10.10.2.1.1.1.3.2">𝒟</ci><ci id="S4.Ex3.m1.10.10.2.1.1.1.3.3.cmml" xref="S4.Ex3.m1.10.10.2.1.1.1.3.3">′</ci></apply></apply></apply></apply></apply></apply><apply id="S4.Ex3.m1.13.13.1.1c.cmml" xref="S4.Ex3.m1.13.13.1"><leq id="S4.Ex3.m1.13.13.1.1.4.cmml" xref="S4.Ex3.m1.13.13.1.1.4"></leq><share href="#S4.Ex3.m1.13.13.1.1.3.cmml" id="S4.Ex3.m1.13.13.1.1d.cmml" xref="S4.Ex3.m1.13.13.1"></share><apply id="S4.Ex3.m1.13.13.1.1.5.cmml" xref="S4.Ex3.m1.13.13.1.1.5"><times id="S4.Ex3.m1.13.13.1.1.5.1.cmml" xref="S4.Ex3.m1.13.13.1.1.5.1"></times><apply id="S4.Ex3.m1.13.13.1.1.5.2.cmml" xref="S4.Ex3.m1.13.13.1.1.5.2"><csymbol cd="ambiguous" id="S4.Ex3.m1.13.13.1.1.5.2.1.cmml" xref="S4.Ex3.m1.13.13.1.1.5.2">superscript</csymbol><ci id="S4.Ex3.m1.13.13.1.1.5.2.2.cmml" xref="S4.Ex3.m1.13.13.1.1.5.2.2">𝑒</ci><ci id="S4.Ex3.m1.13.13.1.1.5.2.3.cmml" xref="S4.Ex3.m1.13.13.1.1.5.2.3">italic-ϵ</ci></apply><apply id="S4.Ex3.m1.12.12.cmml" xref="S4.Ex3.m1.12.12"><divide id="S4.Ex3.m1.12.12.3.cmml" xref="S4.Ex3.m1.12.12"></divide><apply id="S4.Ex3.m1.11.11.1.cmml" xref="S4.Ex3.m1.11.11.1"><times id="S4.Ex3.m1.11.11.1.2.cmml" xref="S4.Ex3.m1.11.11.1.2"></times><ci id="S4.Ex3.m1.11.11.1.3.cmml" xref="S4.Ex3.m1.11.11.1.3">ℙ</ci><apply id="S4.Ex3.m1.11.11.1.1.1.1.cmml" xref="S4.Ex3.m1.11.11.1.1.1"><eq id="S4.Ex3.m1.11.11.1.1.1.1.1.cmml" xref="S4.Ex3.m1.11.11.1.1.1.1.1"></eq><ci id="S4.Ex3.m1.11.11.1.1.1.1.2.cmml" xref="S4.Ex3.m1.11.11.1.1.1.1.2">𝓓</ci><ci id="S4.Ex3.m1.11.11.1.1.1.1.3.cmml" xref="S4.Ex3.m1.11.11.1.1.1.1.3">𝒟</ci></apply></apply><apply id="S4.Ex3.m1.12.12.2.cmml" xref="S4.Ex3.m1.12.12.2"><times id="S4.Ex3.m1.12.12.2.2.cmml" xref="S4.Ex3.m1.12.12.2.2"></times><ci id="S4.Ex3.m1.12.12.2.3.cmml" xref="S4.Ex3.m1.12.12.2.3">ℙ</ci><apply id="S4.Ex3.m1.12.12.2.1.1.1.cmml" xref="S4.Ex3.m1.12.12.2.1.1"><eq id="S4.Ex3.m1.12.12.2.1.1.1.1.cmml" xref="S4.Ex3.m1.12.12.2.1.1.1.1"></eq><ci id="S4.Ex3.m1.12.12.2.1.1.1.2.cmml" xref="S4.Ex3.m1.12.12.2.1.1.1.2">𝓓</ci><apply id="S4.Ex3.m1.12.12.2.1.1.1.3.cmml" xref="S4.Ex3.m1.12.12.2.1.1.1.3"><csymbol cd="ambiguous" id="S4.Ex3.m1.12.12.2.1.1.1.3.1.cmml" xref="S4.Ex3.m1.12.12.2.1.1.1.3">superscript</csymbol><ci id="S4.Ex3.m1.12.12.2.1.1.1.3.2.cmml" xref="S4.Ex3.m1.12.12.2.1.1.1.3.2">𝒟</ci><ci id="S4.Ex3.m1.12.12.2.1.1.1.3.3.cmml" xref="S4.Ex3.m1.12.12.2.1.1.1.3.3">′</ci></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.Ex3.m1.13c">\frac{\mathbb{P}(\bm{\mathcal{D}}=\mathcal{D}|\mathcal{M}(\bm{\mathcal{D}}))}{\mathbb{P}(\bm{\mathcal{D}}=\mathcal{D}^{\prime}|\mathcal{M}(\bm{\mathcal{D}}))}=\frac{\mathbb{P}(\mathcal{M}(\bm{\mathcal{D}})|\bm{\mathcal{D}}=\mathcal{D})}{\mathbb{P}(\mathcal{M}(\bm{\mathcal{D}})|\bm{\mathcal{D}}=\mathcal{D}^{\prime})}\frac{\mathbb{P}(\bm{\mathcal{D}}=\mathcal{D})}{\mathbb{P}(\bm{\mathcal{D}}=\mathcal{D}^{\prime})}\leq e^{\epsilon}\frac{\mathbb{P}(\bm{\mathcal{D}}=\mathcal{D})}{\mathbb{P}(\bm{\mathcal{D}}=\mathcal{D}^{\prime})}\,.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S4.SS2.SSS0.Px1.p1.8" class="ltx_p"><span id="S4.SS2.SSS0.Px1.p1.8.2" class="ltx_text ltx_font_italic">To put it another way, and due to symmetry between <math id="S4.SS2.SSS0.Px1.p1.7.1.m1.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S4.SS2.SSS0.Px1.p1.7.1.m1.1a"><mi id="S4.SS2.SSS0.Px1.p1.7.1.m1.1.1" xref="S4.SS2.SSS0.Px1.p1.7.1.m1.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px1.p1.7.1.m1.1b"><ci id="S4.SS2.SSS0.Px1.p1.7.1.m1.1.1.cmml" xref="S4.SS2.SSS0.Px1.p1.7.1.m1.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px1.p1.7.1.m1.1c">D</annotation></semantics></math> and <math id="S4.SS2.SSS0.Px1.p1.8.2.m2.1" class="ltx_Math" alttext="D^{\prime}" display="inline"><semantics id="S4.SS2.SSS0.Px1.p1.8.2.m2.1a"><msup id="S4.SS2.SSS0.Px1.p1.8.2.m2.1.1" xref="S4.SS2.SSS0.Px1.p1.8.2.m2.1.1.cmml"><mi id="S4.SS2.SSS0.Px1.p1.8.2.m2.1.1.2" xref="S4.SS2.SSS0.Px1.p1.8.2.m2.1.1.2.cmml">D</mi><mo id="S4.SS2.SSS0.Px1.p1.8.2.m2.1.1.3" xref="S4.SS2.SSS0.Px1.p1.8.2.m2.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px1.p1.8.2.m2.1b"><apply id="S4.SS2.SSS0.Px1.p1.8.2.m2.1.1.cmml" xref="S4.SS2.SSS0.Px1.p1.8.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS0.Px1.p1.8.2.m2.1.1.1.cmml" xref="S4.SS2.SSS0.Px1.p1.8.2.m2.1.1">superscript</csymbol><ci id="S4.SS2.SSS0.Px1.p1.8.2.m2.1.1.2.cmml" xref="S4.SS2.SSS0.Px1.p1.8.2.m2.1.1.2">𝐷</ci><ci id="S4.SS2.SSS0.Px1.p1.8.2.m2.1.1.3.cmml" xref="S4.SS2.SSS0.Px1.p1.8.2.m2.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px1.p1.8.2.m2.1c">D^{\prime}</annotation></semantics></math>, differential privacy implies that the log-odds cannot change significantly,</span></p>
<table id="S4.Ex4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.Ex4.m1.9" class="ltx_Math" alttext="\left|\log\left(\frac{\mathbb{P}(\bm{\mathcal{D}}=\mathcal{D}|\mathcal{M}(\bm{\mathcal{D}}))}{\mathbb{P}(\bm{\mathcal{D}}=\mathcal{D}^{\prime}|\mathcal{M}(\bm{\mathcal{D}}))}\right)-\log\left(\frac{\mathbb{P}(\bm{\mathcal{D}}=\mathcal{D})}{\mathbb{P}(\bm{\mathcal{D}}=\mathcal{D}^{\prime})}\right)\right|\leq\epsilon." display="block"><semantics id="S4.Ex4.m1.9a"><mrow id="S4.Ex4.m1.9.9.1" xref="S4.Ex4.m1.9.9.1.1.cmml"><mrow id="S4.Ex4.m1.9.9.1.1" xref="S4.Ex4.m1.9.9.1.1.cmml"><mrow id="S4.Ex4.m1.9.9.1.1.1.1" xref="S4.Ex4.m1.9.9.1.1.1.2.cmml"><mo id="S4.Ex4.m1.9.9.1.1.1.1.2" xref="S4.Ex4.m1.9.9.1.1.1.2.1.cmml">|</mo><mrow id="S4.Ex4.m1.9.9.1.1.1.1.1" xref="S4.Ex4.m1.9.9.1.1.1.1.1.cmml"><mrow id="S4.Ex4.m1.9.9.1.1.1.1.1.2.2" xref="S4.Ex4.m1.9.9.1.1.1.1.1.2.1.cmml"><mi id="S4.Ex4.m1.7.7" xref="S4.Ex4.m1.7.7.cmml">log</mi><mo id="S4.Ex4.m1.9.9.1.1.1.1.1.2.2a" xref="S4.Ex4.m1.9.9.1.1.1.1.1.2.1.cmml">⁡</mo><mrow id="S4.Ex4.m1.9.9.1.1.1.1.1.2.2.1" xref="S4.Ex4.m1.9.9.1.1.1.1.1.2.1.cmml"><mo id="S4.Ex4.m1.9.9.1.1.1.1.1.2.2.1.1" xref="S4.Ex4.m1.9.9.1.1.1.1.1.2.1.cmml">(</mo><mfrac id="S4.Ex4.m1.4.4" xref="S4.Ex4.m1.4.4.cmml"><mrow id="S4.Ex4.m1.2.2.2" xref="S4.Ex4.m1.2.2.2.cmml"><mi id="S4.Ex4.m1.2.2.2.4" xref="S4.Ex4.m1.2.2.2.4.cmml">ℙ</mi><mo lspace="0em" rspace="0em" id="S4.Ex4.m1.2.2.2.3" xref="S4.Ex4.m1.2.2.2.3.cmml">​</mo><mrow id="S4.Ex4.m1.2.2.2.2.1" xref="S4.Ex4.m1.2.2.2.2.1.1.cmml"><mo stretchy="false" id="S4.Ex4.m1.2.2.2.2.1.2" xref="S4.Ex4.m1.2.2.2.2.1.1.cmml">(</mo><mrow id="S4.Ex4.m1.2.2.2.2.1.1" xref="S4.Ex4.m1.2.2.2.2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.Ex4.m1.2.2.2.2.1.1.2" xref="S4.Ex4.m1.2.2.2.2.1.1.2.cmml">𝓓</mi><mo id="S4.Ex4.m1.2.2.2.2.1.1.1" xref="S4.Ex4.m1.2.2.2.2.1.1.1.cmml">=</mo><mrow id="S4.Ex4.m1.2.2.2.2.1.1.3" xref="S4.Ex4.m1.2.2.2.2.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.Ex4.m1.2.2.2.2.1.1.3.2" xref="S4.Ex4.m1.2.2.2.2.1.1.3.2.cmml">𝒟</mi><mo fence="false" id="S4.Ex4.m1.2.2.2.2.1.1.3.1" xref="S4.Ex4.m1.2.2.2.2.1.1.3.1.cmml">|</mo><mrow id="S4.Ex4.m1.2.2.2.2.1.1.3.3" xref="S4.Ex4.m1.2.2.2.2.1.1.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.Ex4.m1.2.2.2.2.1.1.3.3.2" xref="S4.Ex4.m1.2.2.2.2.1.1.3.3.2.cmml">ℳ</mi><mo lspace="0em" rspace="0em" id="S4.Ex4.m1.2.2.2.2.1.1.3.3.1" xref="S4.Ex4.m1.2.2.2.2.1.1.3.3.1.cmml">​</mo><mrow id="S4.Ex4.m1.2.2.2.2.1.1.3.3.3.2" xref="S4.Ex4.m1.2.2.2.2.1.1.3.3.cmml"><mo stretchy="false" id="S4.Ex4.m1.2.2.2.2.1.1.3.3.3.2.1" xref="S4.Ex4.m1.2.2.2.2.1.1.3.3.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S4.Ex4.m1.1.1.1.1" xref="S4.Ex4.m1.1.1.1.1.cmml">𝓓</mi><mo stretchy="false" id="S4.Ex4.m1.2.2.2.2.1.1.3.3.3.2.2" xref="S4.Ex4.m1.2.2.2.2.1.1.3.3.cmml">)</mo></mrow></mrow></mrow></mrow><mo stretchy="false" id="S4.Ex4.m1.2.2.2.2.1.3" xref="S4.Ex4.m1.2.2.2.2.1.1.cmml">)</mo></mrow></mrow><mrow id="S4.Ex4.m1.4.4.4" xref="S4.Ex4.m1.4.4.4.cmml"><mi id="S4.Ex4.m1.4.4.4.4" xref="S4.Ex4.m1.4.4.4.4.cmml">ℙ</mi><mo lspace="0em" rspace="0em" id="S4.Ex4.m1.4.4.4.3" xref="S4.Ex4.m1.4.4.4.3.cmml">​</mo><mrow id="S4.Ex4.m1.4.4.4.2.1" xref="S4.Ex4.m1.4.4.4.2.1.1.cmml"><mo stretchy="false" id="S4.Ex4.m1.4.4.4.2.1.2" xref="S4.Ex4.m1.4.4.4.2.1.1.cmml">(</mo><mrow id="S4.Ex4.m1.4.4.4.2.1.1" xref="S4.Ex4.m1.4.4.4.2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.Ex4.m1.4.4.4.2.1.1.2" xref="S4.Ex4.m1.4.4.4.2.1.1.2.cmml">𝓓</mi><mo id="S4.Ex4.m1.4.4.4.2.1.1.1" xref="S4.Ex4.m1.4.4.4.2.1.1.1.cmml">=</mo><mrow id="S4.Ex4.m1.4.4.4.2.1.1.3" xref="S4.Ex4.m1.4.4.4.2.1.1.3.cmml"><msup id="S4.Ex4.m1.4.4.4.2.1.1.3.2" xref="S4.Ex4.m1.4.4.4.2.1.1.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.Ex4.m1.4.4.4.2.1.1.3.2.2" xref="S4.Ex4.m1.4.4.4.2.1.1.3.2.2.cmml">𝒟</mi><mo id="S4.Ex4.m1.4.4.4.2.1.1.3.2.3" xref="S4.Ex4.m1.4.4.4.2.1.1.3.2.3.cmml">′</mo></msup><mo fence="false" id="S4.Ex4.m1.4.4.4.2.1.1.3.1" xref="S4.Ex4.m1.4.4.4.2.1.1.3.1.cmml">|</mo><mrow id="S4.Ex4.m1.4.4.4.2.1.1.3.3" xref="S4.Ex4.m1.4.4.4.2.1.1.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.Ex4.m1.4.4.4.2.1.1.3.3.2" xref="S4.Ex4.m1.4.4.4.2.1.1.3.3.2.cmml">ℳ</mi><mo lspace="0em" rspace="0em" id="S4.Ex4.m1.4.4.4.2.1.1.3.3.1" xref="S4.Ex4.m1.4.4.4.2.1.1.3.3.1.cmml">​</mo><mrow id="S4.Ex4.m1.4.4.4.2.1.1.3.3.3.2" xref="S4.Ex4.m1.4.4.4.2.1.1.3.3.cmml"><mo stretchy="false" id="S4.Ex4.m1.4.4.4.2.1.1.3.3.3.2.1" xref="S4.Ex4.m1.4.4.4.2.1.1.3.3.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S4.Ex4.m1.3.3.3.1" xref="S4.Ex4.m1.3.3.3.1.cmml">𝓓</mi><mo stretchy="false" id="S4.Ex4.m1.4.4.4.2.1.1.3.3.3.2.2" xref="S4.Ex4.m1.4.4.4.2.1.1.3.3.cmml">)</mo></mrow></mrow></mrow></mrow><mo stretchy="false" id="S4.Ex4.m1.4.4.4.2.1.3" xref="S4.Ex4.m1.4.4.4.2.1.1.cmml">)</mo></mrow></mrow></mfrac><mo id="S4.Ex4.m1.9.9.1.1.1.1.1.2.2.1.2" xref="S4.Ex4.m1.9.9.1.1.1.1.1.2.1.cmml">)</mo></mrow></mrow><mo id="S4.Ex4.m1.9.9.1.1.1.1.1.1" xref="S4.Ex4.m1.9.9.1.1.1.1.1.1.cmml">−</mo><mrow id="S4.Ex4.m1.9.9.1.1.1.1.1.3.2" xref="S4.Ex4.m1.9.9.1.1.1.1.1.3.1.cmml"><mi id="S4.Ex4.m1.8.8" xref="S4.Ex4.m1.8.8.cmml">log</mi><mo id="S4.Ex4.m1.9.9.1.1.1.1.1.3.2a" xref="S4.Ex4.m1.9.9.1.1.1.1.1.3.1.cmml">⁡</mo><mrow id="S4.Ex4.m1.9.9.1.1.1.1.1.3.2.1" xref="S4.Ex4.m1.9.9.1.1.1.1.1.3.1.cmml"><mo id="S4.Ex4.m1.9.9.1.1.1.1.1.3.2.1.1" xref="S4.Ex4.m1.9.9.1.1.1.1.1.3.1.cmml">(</mo><mfrac id="S4.Ex4.m1.6.6" xref="S4.Ex4.m1.6.6.cmml"><mrow id="S4.Ex4.m1.5.5.1" xref="S4.Ex4.m1.5.5.1.cmml"><mi id="S4.Ex4.m1.5.5.1.3" xref="S4.Ex4.m1.5.5.1.3.cmml">ℙ</mi><mo lspace="0em" rspace="0em" id="S4.Ex4.m1.5.5.1.2" xref="S4.Ex4.m1.5.5.1.2.cmml">​</mo><mrow id="S4.Ex4.m1.5.5.1.1.1" xref="S4.Ex4.m1.5.5.1.1.1.1.cmml"><mo stretchy="false" id="S4.Ex4.m1.5.5.1.1.1.2" xref="S4.Ex4.m1.5.5.1.1.1.1.cmml">(</mo><mrow id="S4.Ex4.m1.5.5.1.1.1.1" xref="S4.Ex4.m1.5.5.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.Ex4.m1.5.5.1.1.1.1.2" xref="S4.Ex4.m1.5.5.1.1.1.1.2.cmml">𝓓</mi><mo id="S4.Ex4.m1.5.5.1.1.1.1.1" xref="S4.Ex4.m1.5.5.1.1.1.1.1.cmml">=</mo><mi class="ltx_font_mathcaligraphic" id="S4.Ex4.m1.5.5.1.1.1.1.3" xref="S4.Ex4.m1.5.5.1.1.1.1.3.cmml">𝒟</mi></mrow><mo stretchy="false" id="S4.Ex4.m1.5.5.1.1.1.3" xref="S4.Ex4.m1.5.5.1.1.1.1.cmml">)</mo></mrow></mrow><mrow id="S4.Ex4.m1.6.6.2" xref="S4.Ex4.m1.6.6.2.cmml"><mi id="S4.Ex4.m1.6.6.2.3" xref="S4.Ex4.m1.6.6.2.3.cmml">ℙ</mi><mo lspace="0em" rspace="0em" id="S4.Ex4.m1.6.6.2.2" xref="S4.Ex4.m1.6.6.2.2.cmml">​</mo><mrow id="S4.Ex4.m1.6.6.2.1.1" xref="S4.Ex4.m1.6.6.2.1.1.1.cmml"><mo stretchy="false" id="S4.Ex4.m1.6.6.2.1.1.2" xref="S4.Ex4.m1.6.6.2.1.1.1.cmml">(</mo><mrow id="S4.Ex4.m1.6.6.2.1.1.1" xref="S4.Ex4.m1.6.6.2.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.Ex4.m1.6.6.2.1.1.1.2" xref="S4.Ex4.m1.6.6.2.1.1.1.2.cmml">𝓓</mi><mo id="S4.Ex4.m1.6.6.2.1.1.1.1" xref="S4.Ex4.m1.6.6.2.1.1.1.1.cmml">=</mo><msup id="S4.Ex4.m1.6.6.2.1.1.1.3" xref="S4.Ex4.m1.6.6.2.1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.Ex4.m1.6.6.2.1.1.1.3.2" xref="S4.Ex4.m1.6.6.2.1.1.1.3.2.cmml">𝒟</mi><mo id="S4.Ex4.m1.6.6.2.1.1.1.3.3" xref="S4.Ex4.m1.6.6.2.1.1.1.3.3.cmml">′</mo></msup></mrow><mo stretchy="false" id="S4.Ex4.m1.6.6.2.1.1.3" xref="S4.Ex4.m1.6.6.2.1.1.1.cmml">)</mo></mrow></mrow></mfrac><mo id="S4.Ex4.m1.9.9.1.1.1.1.1.3.2.1.2" xref="S4.Ex4.m1.9.9.1.1.1.1.1.3.1.cmml">)</mo></mrow></mrow></mrow><mo id="S4.Ex4.m1.9.9.1.1.1.1.3" xref="S4.Ex4.m1.9.9.1.1.1.2.1.cmml">|</mo></mrow><mo id="S4.Ex4.m1.9.9.1.1.2" xref="S4.Ex4.m1.9.9.1.1.2.cmml">≤</mo><mi id="S4.Ex4.m1.9.9.1.1.3" xref="S4.Ex4.m1.9.9.1.1.3.cmml">ϵ</mi></mrow><mo lspace="0em" id="S4.Ex4.m1.9.9.1.2" xref="S4.Ex4.m1.9.9.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.Ex4.m1.9b"><apply id="S4.Ex4.m1.9.9.1.1.cmml" xref="S4.Ex4.m1.9.9.1"><leq id="S4.Ex4.m1.9.9.1.1.2.cmml" xref="S4.Ex4.m1.9.9.1.1.2"></leq><apply id="S4.Ex4.m1.9.9.1.1.1.2.cmml" xref="S4.Ex4.m1.9.9.1.1.1.1"><abs id="S4.Ex4.m1.9.9.1.1.1.2.1.cmml" xref="S4.Ex4.m1.9.9.1.1.1.1.2"></abs><apply id="S4.Ex4.m1.9.9.1.1.1.1.1.cmml" xref="S4.Ex4.m1.9.9.1.1.1.1.1"><minus id="S4.Ex4.m1.9.9.1.1.1.1.1.1.cmml" xref="S4.Ex4.m1.9.9.1.1.1.1.1.1"></minus><apply id="S4.Ex4.m1.9.9.1.1.1.1.1.2.1.cmml" xref="S4.Ex4.m1.9.9.1.1.1.1.1.2.2"><log id="S4.Ex4.m1.7.7.cmml" xref="S4.Ex4.m1.7.7"></log><apply id="S4.Ex4.m1.4.4.cmml" xref="S4.Ex4.m1.4.4"><divide id="S4.Ex4.m1.4.4.5.cmml" xref="S4.Ex4.m1.4.4"></divide><apply id="S4.Ex4.m1.2.2.2.cmml" xref="S4.Ex4.m1.2.2.2"><times id="S4.Ex4.m1.2.2.2.3.cmml" xref="S4.Ex4.m1.2.2.2.3"></times><ci id="S4.Ex4.m1.2.2.2.4.cmml" xref="S4.Ex4.m1.2.2.2.4">ℙ</ci><apply id="S4.Ex4.m1.2.2.2.2.1.1.cmml" xref="S4.Ex4.m1.2.2.2.2.1"><eq id="S4.Ex4.m1.2.2.2.2.1.1.1.cmml" xref="S4.Ex4.m1.2.2.2.2.1.1.1"></eq><ci id="S4.Ex4.m1.2.2.2.2.1.1.2.cmml" xref="S4.Ex4.m1.2.2.2.2.1.1.2">𝓓</ci><apply id="S4.Ex4.m1.2.2.2.2.1.1.3.cmml" xref="S4.Ex4.m1.2.2.2.2.1.1.3"><csymbol cd="latexml" id="S4.Ex4.m1.2.2.2.2.1.1.3.1.cmml" xref="S4.Ex4.m1.2.2.2.2.1.1.3.1">conditional</csymbol><ci id="S4.Ex4.m1.2.2.2.2.1.1.3.2.cmml" xref="S4.Ex4.m1.2.2.2.2.1.1.3.2">𝒟</ci><apply id="S4.Ex4.m1.2.2.2.2.1.1.3.3.cmml" xref="S4.Ex4.m1.2.2.2.2.1.1.3.3"><times id="S4.Ex4.m1.2.2.2.2.1.1.3.3.1.cmml" xref="S4.Ex4.m1.2.2.2.2.1.1.3.3.1"></times><ci id="S4.Ex4.m1.2.2.2.2.1.1.3.3.2.cmml" xref="S4.Ex4.m1.2.2.2.2.1.1.3.3.2">ℳ</ci><ci id="S4.Ex4.m1.1.1.1.1.cmml" xref="S4.Ex4.m1.1.1.1.1">𝓓</ci></apply></apply></apply></apply><apply id="S4.Ex4.m1.4.4.4.cmml" xref="S4.Ex4.m1.4.4.4"><times id="S4.Ex4.m1.4.4.4.3.cmml" xref="S4.Ex4.m1.4.4.4.3"></times><ci id="S4.Ex4.m1.4.4.4.4.cmml" xref="S4.Ex4.m1.4.4.4.4">ℙ</ci><apply id="S4.Ex4.m1.4.4.4.2.1.1.cmml" xref="S4.Ex4.m1.4.4.4.2.1"><eq id="S4.Ex4.m1.4.4.4.2.1.1.1.cmml" xref="S4.Ex4.m1.4.4.4.2.1.1.1"></eq><ci id="S4.Ex4.m1.4.4.4.2.1.1.2.cmml" xref="S4.Ex4.m1.4.4.4.2.1.1.2">𝓓</ci><apply id="S4.Ex4.m1.4.4.4.2.1.1.3.cmml" xref="S4.Ex4.m1.4.4.4.2.1.1.3"><csymbol cd="latexml" id="S4.Ex4.m1.4.4.4.2.1.1.3.1.cmml" xref="S4.Ex4.m1.4.4.4.2.1.1.3.1">conditional</csymbol><apply id="S4.Ex4.m1.4.4.4.2.1.1.3.2.cmml" xref="S4.Ex4.m1.4.4.4.2.1.1.3.2"><csymbol cd="ambiguous" id="S4.Ex4.m1.4.4.4.2.1.1.3.2.1.cmml" xref="S4.Ex4.m1.4.4.4.2.1.1.3.2">superscript</csymbol><ci id="S4.Ex4.m1.4.4.4.2.1.1.3.2.2.cmml" xref="S4.Ex4.m1.4.4.4.2.1.1.3.2.2">𝒟</ci><ci id="S4.Ex4.m1.4.4.4.2.1.1.3.2.3.cmml" xref="S4.Ex4.m1.4.4.4.2.1.1.3.2.3">′</ci></apply><apply id="S4.Ex4.m1.4.4.4.2.1.1.3.3.cmml" xref="S4.Ex4.m1.4.4.4.2.1.1.3.3"><times id="S4.Ex4.m1.4.4.4.2.1.1.3.3.1.cmml" xref="S4.Ex4.m1.4.4.4.2.1.1.3.3.1"></times><ci id="S4.Ex4.m1.4.4.4.2.1.1.3.3.2.cmml" xref="S4.Ex4.m1.4.4.4.2.1.1.3.3.2">ℳ</ci><ci id="S4.Ex4.m1.3.3.3.1.cmml" xref="S4.Ex4.m1.3.3.3.1">𝓓</ci></apply></apply></apply></apply></apply></apply><apply id="S4.Ex4.m1.9.9.1.1.1.1.1.3.1.cmml" xref="S4.Ex4.m1.9.9.1.1.1.1.1.3.2"><log id="S4.Ex4.m1.8.8.cmml" xref="S4.Ex4.m1.8.8"></log><apply id="S4.Ex4.m1.6.6.cmml" xref="S4.Ex4.m1.6.6"><divide id="S4.Ex4.m1.6.6.3.cmml" xref="S4.Ex4.m1.6.6"></divide><apply id="S4.Ex4.m1.5.5.1.cmml" xref="S4.Ex4.m1.5.5.1"><times id="S4.Ex4.m1.5.5.1.2.cmml" xref="S4.Ex4.m1.5.5.1.2"></times><ci id="S4.Ex4.m1.5.5.1.3.cmml" xref="S4.Ex4.m1.5.5.1.3">ℙ</ci><apply id="S4.Ex4.m1.5.5.1.1.1.1.cmml" xref="S4.Ex4.m1.5.5.1.1.1"><eq id="S4.Ex4.m1.5.5.1.1.1.1.1.cmml" xref="S4.Ex4.m1.5.5.1.1.1.1.1"></eq><ci id="S4.Ex4.m1.5.5.1.1.1.1.2.cmml" xref="S4.Ex4.m1.5.5.1.1.1.1.2">𝓓</ci><ci id="S4.Ex4.m1.5.5.1.1.1.1.3.cmml" xref="S4.Ex4.m1.5.5.1.1.1.1.3">𝒟</ci></apply></apply><apply id="S4.Ex4.m1.6.6.2.cmml" xref="S4.Ex4.m1.6.6.2"><times id="S4.Ex4.m1.6.6.2.2.cmml" xref="S4.Ex4.m1.6.6.2.2"></times><ci id="S4.Ex4.m1.6.6.2.3.cmml" xref="S4.Ex4.m1.6.6.2.3">ℙ</ci><apply id="S4.Ex4.m1.6.6.2.1.1.1.cmml" xref="S4.Ex4.m1.6.6.2.1.1"><eq id="S4.Ex4.m1.6.6.2.1.1.1.1.cmml" xref="S4.Ex4.m1.6.6.2.1.1.1.1"></eq><ci id="S4.Ex4.m1.6.6.2.1.1.1.2.cmml" xref="S4.Ex4.m1.6.6.2.1.1.1.2">𝓓</ci><apply id="S4.Ex4.m1.6.6.2.1.1.1.3.cmml" xref="S4.Ex4.m1.6.6.2.1.1.1.3"><csymbol cd="ambiguous" id="S4.Ex4.m1.6.6.2.1.1.1.3.1.cmml" xref="S4.Ex4.m1.6.6.2.1.1.1.3">superscript</csymbol><ci id="S4.Ex4.m1.6.6.2.1.1.1.3.2.cmml" xref="S4.Ex4.m1.6.6.2.1.1.1.3.2">𝒟</ci><ci id="S4.Ex4.m1.6.6.2.1.1.1.3.3.cmml" xref="S4.Ex4.m1.6.6.2.1.1.1.3.3">′</ci></apply></apply></apply></apply></apply></apply></apply><ci id="S4.Ex4.m1.9.9.1.1.3.cmml" xref="S4.Ex4.m1.9.9.1.1.3">italic-ϵ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.Ex4.m1.9c">\left|\log\left(\frac{\mathbb{P}(\bm{\mathcal{D}}=\mathcal{D}|\mathcal{M}(\bm{\mathcal{D}}))}{\mathbb{P}(\bm{\mathcal{D}}=\mathcal{D}^{\prime}|\mathcal{M}(\bm{\mathcal{D}}))}\right)-\log\left(\frac{\mathbb{P}(\bm{\mathcal{D}}=\mathcal{D})}{\mathbb{P}(\bm{\mathcal{D}}=\mathcal{D}^{\prime})}\right)\right|\leq\epsilon.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div id="S4.SS2.SSS0.Px1.p2" class="ltx_para">
<p id="S4.SS2.SSS0.Px1.p2.1" class="ltx_p">In light of the threat model view introduced in Section <a href="#S4.SS1" title="4.1 The Threat Model View ‣ 4 Privacy in Machine Learning - An Overview ‣ Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>, it should be noted that differential privacy provides provable bounds on the ability of an adversary to perform such attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib73" title="" class="ltx_ref">73</a>]</cite>. These bounds assume worst-case prior information, knowledge of the algorithms, and computing power of the adversary. Differential Privacy also enjoys several nice properties that have helped with its adoption, such as composability, resistance to post-processing, and plausible deniability <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>. Composability and the post-processing theorem, in particular, allow for differentially private algorithms to be built out of smaller building blocks, which is precisely the driving force behind Differentially Private Stochastic Gradient Descent (DPSGD) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>, <a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>. DPSGD has enabled differential privacy to be applied to deep learning architectures. This, in turn, has allowed the development of several DPSGD-driven generative models for synthetic data (see Sec. <a href="#S7.SS1" title="7.1 Existing Methods and Technologies ‣ 7 Private Synthetic Data Generation ‣ Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7.1</span></a>).</p>
</div>
</section>
<section id="S4.SS2.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Flavours of Differential Privacy.</h5>

<div id="S4.SS2.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS2.SSS0.Px2.p1.2" class="ltx_p">Above, we introduced the two most common notions of differential privacy, pure- and approximate-differential privacy (<math id="S4.SS2.SSS0.Px2.p1.1.m1.1" class="ltx_Math" alttext="\varepsilon" display="inline"><semantics id="S4.SS2.SSS0.Px2.p1.1.m1.1a"><mi id="S4.SS2.SSS0.Px2.p1.1.m1.1.1" xref="S4.SS2.SSS0.Px2.p1.1.m1.1.1.cmml">ε</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px2.p1.1.m1.1b"><ci id="S4.SS2.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S4.SS2.SSS0.Px2.p1.1.m1.1.1">𝜀</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px2.p1.1.m1.1c">\varepsilon</annotation></semantics></math> and <math id="S4.SS2.SSS0.Px2.p1.2.m2.2" class="ltx_Math" alttext="(\varepsilon,\delta)" display="inline"><semantics id="S4.SS2.SSS0.Px2.p1.2.m2.2a"><mrow id="S4.SS2.SSS0.Px2.p1.2.m2.2.3.2" xref="S4.SS2.SSS0.Px2.p1.2.m2.2.3.1.cmml"><mo stretchy="false" id="S4.SS2.SSS0.Px2.p1.2.m2.2.3.2.1" xref="S4.SS2.SSS0.Px2.p1.2.m2.2.3.1.cmml">(</mo><mi id="S4.SS2.SSS0.Px2.p1.2.m2.1.1" xref="S4.SS2.SSS0.Px2.p1.2.m2.1.1.cmml">ε</mi><mo id="S4.SS2.SSS0.Px2.p1.2.m2.2.3.2.2" xref="S4.SS2.SSS0.Px2.p1.2.m2.2.3.1.cmml">,</mo><mi id="S4.SS2.SSS0.Px2.p1.2.m2.2.2" xref="S4.SS2.SSS0.Px2.p1.2.m2.2.2.cmml">δ</mi><mo stretchy="false" id="S4.SS2.SSS0.Px2.p1.2.m2.2.3.2.3" xref="S4.SS2.SSS0.Px2.p1.2.m2.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px2.p1.2.m2.2b"><interval closure="open" id="S4.SS2.SSS0.Px2.p1.2.m2.2.3.1.cmml" xref="S4.SS2.SSS0.Px2.p1.2.m2.2.3.2"><ci id="S4.SS2.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S4.SS2.SSS0.Px2.p1.2.m2.1.1">𝜀</ci><ci id="S4.SS2.SSS0.Px2.p1.2.m2.2.2.cmml" xref="S4.SS2.SSS0.Px2.p1.2.m2.2.2">𝛿</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px2.p1.2.m2.2c">(\varepsilon,\delta)</annotation></semantics></math>). There are in fact several relaxations of differential privacy, such as Renyi-Differential Privacy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib74" title="" class="ltx_ref">74</a>]</cite>; extensions, such as Label-DP <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib75" title="" class="ltx_ref">75</a>]</cite>; and even stronger notions, such as local differential privacy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib76" title="" class="ltx_ref">76</a>]</cite>. Depending on the task at hand, these notions may be more or less useful than vanilla DP.</p>
</div>
</section>
<section id="S4.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.1 </span>Limits of DP</h4>

<div id="S4.SS2.SSS1.p1" class="ltx_para">
<p id="S4.SS2.SSS1.p1.1" class="ltx_p">Despite being widely accepted as the best available privacy definition, differential privacy is not without its weaknesses.</p>
</div>
<section id="S4.SS2.SSS1.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Choosing parameters <math id="S4.SS2.SSS1.Px1.1.m1.2" class="ltx_Math" alttext="\varepsilon,\delta" display="inline"><semantics id="S4.SS2.SSS1.Px1.1.m1.2b"><mrow id="S4.SS2.SSS1.Px1.1.m1.2.3.2" xref="S4.SS2.SSS1.Px1.1.m1.2.3.1.cmml"><mi id="S4.SS2.SSS1.Px1.1.m1.1.1" xref="S4.SS2.SSS1.Px1.1.m1.1.1.cmml">ε</mi><mo id="S4.SS2.SSS1.Px1.1.m1.2.3.2.1" xref="S4.SS2.SSS1.Px1.1.m1.2.3.1.cmml">,</mo><mi id="S4.SS2.SSS1.Px1.1.m1.2.2" xref="S4.SS2.SSS1.Px1.1.m1.2.2.cmml">δ</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS1.Px1.1.m1.2c"><list id="S4.SS2.SSS1.Px1.1.m1.2.3.1.cmml" xref="S4.SS2.SSS1.Px1.1.m1.2.3.2"><ci id="S4.SS2.SSS1.Px1.1.m1.1.1.cmml" xref="S4.SS2.SSS1.Px1.1.m1.1.1">𝜀</ci><ci id="S4.SS2.SSS1.Px1.1.m1.2.2.cmml" xref="S4.SS2.SSS1.Px1.1.m1.2.2">𝛿</ci></list></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS1.Px1.1.m1.2d">\varepsilon,\delta</annotation></semantics></math>.</h5>

<div id="S4.SS2.SSS1.Px1.p1" class="ltx_para">
<p id="S4.SS2.SSS1.Px1.p1.2" class="ltx_p">The privacy protection afforded by a differentially private mechanism is controlled by parameters <math id="S4.SS2.SSS1.Px1.p1.1.m1.1" class="ltx_Math" alttext="\varepsilon" display="inline"><semantics id="S4.SS2.SSS1.Px1.p1.1.m1.1a"><mi id="S4.SS2.SSS1.Px1.p1.1.m1.1.1" xref="S4.SS2.SSS1.Px1.p1.1.m1.1.1.cmml">ε</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS1.Px1.p1.1.m1.1b"><ci id="S4.SS2.SSS1.Px1.p1.1.m1.1.1.cmml" xref="S4.SS2.SSS1.Px1.p1.1.m1.1.1">𝜀</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS1.Px1.p1.1.m1.1c">\varepsilon</annotation></semantics></math> and <math id="S4.SS2.SSS1.Px1.p1.2.m2.1" class="ltx_Math" alttext="\delta" display="inline"><semantics id="S4.SS2.SSS1.Px1.p1.2.m2.1a"><mi id="S4.SS2.SSS1.Px1.p1.2.m2.1.1" xref="S4.SS2.SSS1.Px1.p1.2.m2.1.1.cmml">δ</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS1.Px1.p1.2.m2.1b"><ci id="S4.SS2.SSS1.Px1.p1.2.m2.1.1.cmml" xref="S4.SS2.SSS1.Px1.p1.2.m2.1.1">𝛿</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS1.Px1.p1.2.m2.1c">\delta</annotation></semantics></math>.
Choosing appropriate values for these parameters is notoriously difficult (in part due to their opaqueness in interpretability), and strongly depends on the context <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib77" title="" class="ltx_ref">77</a>, <a href="#bib.bib78" title="" class="ltx_ref">78</a>, <a href="#bib.bib79" title="" class="ltx_ref">79</a>]</cite>.
This is further complicated by the fact that many methodologies lack a tight analysis of their privacy, leading to larger-than-necessary noise being injected into the system, hindering utility <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib80" title="" class="ltx_ref">80</a>]</cite>.</p>
</div>
</section>
<section id="S4.SS2.SSS1.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Relaxations.</h5>

<div id="S4.SS2.SSS1.Px2.p1" class="ltx_para">
<p id="S4.SS2.SSS1.Px2.p1.1" class="ltx_p">Though often celebrated as a strength, the lack of assumptions placed on an adversary’s knowledge and capabilities can lead to overly conservative computations, which hinder the utility of the output.
Researchers have proposed many relaxations of the original definition (which required <math id="S4.SS2.SSS1.Px2.p1.1.m1.1" class="ltx_Math" alttext="\delta=0" display="inline"><semantics id="S4.SS2.SSS1.Px2.p1.1.m1.1a"><mrow id="S4.SS2.SSS1.Px2.p1.1.m1.1.1" xref="S4.SS2.SSS1.Px2.p1.1.m1.1.1.cmml"><mi id="S4.SS2.SSS1.Px2.p1.1.m1.1.1.2" xref="S4.SS2.SSS1.Px2.p1.1.m1.1.1.2.cmml">δ</mi><mo id="S4.SS2.SSS1.Px2.p1.1.m1.1.1.1" xref="S4.SS2.SSS1.Px2.p1.1.m1.1.1.1.cmml">=</mo><mn id="S4.SS2.SSS1.Px2.p1.1.m1.1.1.3" xref="S4.SS2.SSS1.Px2.p1.1.m1.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS1.Px2.p1.1.m1.1b"><apply id="S4.SS2.SSS1.Px2.p1.1.m1.1.1.cmml" xref="S4.SS2.SSS1.Px2.p1.1.m1.1.1"><eq id="S4.SS2.SSS1.Px2.p1.1.m1.1.1.1.cmml" xref="S4.SS2.SSS1.Px2.p1.1.m1.1.1.1"></eq><ci id="S4.SS2.SSS1.Px2.p1.1.m1.1.1.2.cmml" xref="S4.SS2.SSS1.Px2.p1.1.m1.1.1.2">𝛿</ci><cn type="integer" id="S4.SS2.SSS1.Px2.p1.1.m1.1.1.3.cmml" xref="S4.SS2.SSS1.Px2.p1.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS1.Px2.p1.1.m1.1c">\delta=0</annotation></semantics></math>) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib81" title="" class="ltx_ref">81</a>]</cite>.
However, the privacy guarantees of these can be hard to understand and model. Similarly to the parameters issue, researchers have started using attacks to compare mechanisms using different definitions of privacy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib75" title="" class="ltx_ref">75</a>]</cite>.</p>
</div>
</section>
</section>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Utility, Fidelity and Privacy of Synthetic Data.</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">For synthetic data to be <span id="S5.p1.1.1" class="ltx_text ltx_font_italic">meaningful</span>, it must be similar to <span id="S5.p1.1.2" class="ltx_text ltx_font_italic">and</span> different from the original data in some sense. If synthetic data is being considered, then there is a reason that the original data is inappropriate or inadequate for the task at hand – be it because it is non-private, biased, or too small – and so synthetic data that is too similar to the original data will also suffer from the same problems. The “allowed” similarity (or rather the required non-similarity) will differ from task to task, and constitutes one of the 3 attributes that are fundamental to synthetic data generation: <span id="S5.p1.1.3" class="ltx_text ltx_font_italic">utility</span>, <span id="S5.p1.1.4" class="ltx_text ltx_font_italic">fidelity</span>, and <span id="S5.p1.1.5" class="ltx_text ltx_font_italic">privacy</span>.</p>
</div>
<section id="S5.SS0.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Utility:</h5>

<div id="S5.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S5.SS0.SSS0.Px1.p1.1" class="ltx_p">The utility of synthetic data often is determined by its usefulness for a given task or set of tasks. This often involves contrasting the performance of models trained on real vs synthetic data, and might involve inspecting concrete metrics such as accuracy, precision, root mean-squared error, etc.; and/or model fairness properties such as demographic parity, fairness through unawareness, or conditional fairness <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>. Doing so often requires the <em id="S5.SS0.SSS0.Px1.p1.1.1" class="ltx_emph ltx_font_italic">Train on Synthetic, Test on Real</em> (TSTR) paradigm <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> in which models are trained on synthetic data and their performance then evaluated on real data.</p>
</div>
</section>
<section id="S5.SS0.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Fidelity:</h5>

<div id="S5.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S5.SS0.SSS0.Px2.p1.1" class="ltx_p">Often lumped together with utility, we define fidelity to be measures that directly compare the synthetic dataset with the real one (rather than indirectly through a model, or through performance on a given task). From a high-level perspective, fidelity is how well the synthetic data “statistically” matches the real data. Measures of fidelity are often used because of an underlying intuition that a specific fidelity will correspond to improved performance on a wide range of tasks. In the most general case, full statistical similarity (i.e. matching the distributions of the synthetic and real data), should allow many tasks that would be performed on the real data to be performed on the synthetic. However, such a match is difficult, especially in the presence of privacy requirements <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib82" title="" class="ltx_ref">82</a>]</cite>, and even undesirable in the presence of biases <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>. Rather than seeking a “full” statistical match, one might inspect low-dimensional marginals <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib83" title="" class="ltx_ref">83</a>]</cite>, the syntactical accuracy of the synthetic data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib84" title="" class="ltx_ref">84</a>]</cite>, or look at the distribution of the remaining features conditional on a feature that is known to be biased in the original data.</p>
</div>
</section>
<section id="S5.SS0.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Utility vs. Fidelity:</h5>

<div id="S5.SS0.SSS0.Px3.p1" class="ltx_para">
<p id="S5.SS0.SSS0.Px3.p1.1" class="ltx_p">Much of the literature on synthetic data, in particular for private synthetic data, focuses on the 2-dimensional trade-off between utility and privacy, folding fidelity into utility. While the two are unavoidably linked, they are not synonymous nor perfectly correlated. In some scenarios, fidelity can be reduced while leaving utility unaltered (or vice versa), potentially “leaving room” for other benefits, for example, improved privacy.</p>
</div>
</section>
<section id="S5.SS0.SSS0.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Privacy:</h5>

<div id="S5.SS0.SSS0.Px4.p1" class="ltx_para">
<p id="S5.SS0.SSS0.Px4.p1.1" class="ltx_p">The privacy of synthetic data is determined by the amount of information that it reveals about the real data used to produce it. Depending on the use case, different privacy guarantees might be required. For example, internal synthetic data release within a secure environment will typically require less stringent privacy evaluation than data released to the general public. Theoretically sound notions such as differential privacy and its offspring exist, allowing for systematic analysis of the privacy of algorithms used to produce synthetic data. Less is known about the precise meaning of the privacy of a specific synthetic data sample if the data generation method is not revealed, or how to evaluate it, since privacy is typically defined as a statistical property over many instances. Of course, extra care is required to ensure that privacy that has been proven on paper is not lost through sloppy implementation of these algorithms in practice <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib80" title="" class="ltx_ref">80</a>]</cite>.</p>
</div>
</section>
<section id="S5.SS0.SSS0.Px5" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Privacy vs Fidelity:</h5>

<div id="S5.SS0.SSS0.Px5.p1" class="ltx_para">
<p id="S5.SS0.SSS0.Px5.p1.1" class="ltx_p">As a rule of thumb, when fidelity increases, the privacy of synthetic data decreases. This means that, in general, it is impossible to generate private synthetic data that will be useful for all use cases. Instead, one might group potential use cases in terms of the type of fidelity that is required (i.e. which features of the original dataset need to be captured by the synthetic data) and generate multiple synthetic datasets, each with user specified privacy guarantees.</p>
</div>
</section>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Synthetic Data Desiderata</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">A good synthetic data generator (SDG) should simultaneously satisfy the following properties:</p>
<ol id="S5.I1" class="ltx_enumerate">
<li id="S5.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S5.I1.i1.p1" class="ltx_para">
<p id="S5.I1.i1.p1.1" class="ltx_p"><span id="S5.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Syntactical accuracy</span>: The generated data should be plausible (e.g. a synthetically generated postcode should exist). However, this also requires that certain structural properties of the data are preserved. For example, with time-series data, one needs to ensure that data points are not generated using information from the future. Similarly, when synthesising financial transnational networks, the underlying graph structure of the data must be preserved.</p>
</div>
</li>
<li id="S5.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S5.I1.i2.p1" class="ltx_para">
<p id="S5.I1.i2.p1.1" class="ltx_p"><span id="S5.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Privacy</span>: It should be possible to precisely quantify how much information about the original data is revealed through the releasing of the synthetic sample. How exactly one measures privacy will depend on the specific task at hand. While differential privacy is one popular way of assessing the amount of information release through synthetic data generators, a different notion might be required when the data is sparse or one wants to move away from worst-case bounds.</p>
</div>
</li>
<li id="S5.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S5.I1.i3.p1" class="ltx_para">
<p id="S5.I1.i3.p1.1" class="ltx_p"><span id="S5.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">Statistical accuracy</span>: It should be possible to precisely quantify the statistical similarity (or lack thereof) between the synthetic and the original data. When measuring statistical accuracy, one might be interested in capturing certain marginal distributions and certain relationships between variables, but not others. A good synthetic data generator should allow for control over this.</p>
</div>
</li>
<li id="S5.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span> 
<div id="S5.I1.i4.p1" class="ltx_para">
<p id="S5.I1.i4.p1.1" class="ltx_p"><span id="S5.I1.i4.p1.1.1" class="ltx_text ltx_font_bold">Efficiency</span>: The algorithm should scale well with the dimension of the data space (i.e. feature space). It is well known that, in general, approximation of distributions can suffer from the curse of dimensionality, and consequently sampling from unstructured distributions is an NP-hard problem.</p>
</div>
</li>
</ol>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<p id="S5.SS1.p2.1" class="ltx_p">While it its relatively straightforward to design algorithms for which a subset of these properties hold, there is currently no systematic framework for developing SDGs for which all 4 properties are satisfied simultaneously. For example, generation of statistically accurate but private data is hard, as these goals may be in conflict. Specifically within the realm of differentially private <span id="S5.SS1.p2.1.1" class="ltx_text ltx_font_italic">synthetic data</span>, Ullman et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib82" title="" class="ltx_ref">82</a>]</cite> demonstrated that a computationally efficient algorithm (i.e. runs in polynomial time) that generates synthetic data that both: (i) satisfies differential privacy; and (ii) preserves the correlations between pairs of features, does not exist. This result holds in a general sense, in that for every algorithm that <span id="S5.SS1.p2.1.2" class="ltx_text ltx_font_italic">could</span> generate synthetic data, there is <span id="S5.SS1.p2.1.3" class="ltx_text ltx_font_italic">a</span> dataset that “will not work”. That said, it is possible that:</p>
<ul id="S5.I2" class="ltx_itemize">
<li id="S5.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I2.i1.p1" class="ltx_para">
<p id="S5.I2.i1.p1.1" class="ltx_p">for a specific application (e.g., dataset), it is possible to efficiently generate DP synthetic data;</p>
</div>
</li>
<li id="S5.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I2.i2.p1" class="ltx_para">
<p id="S5.I2.i2.p1.1" class="ltx_p">one may not be interested in the correlations being preserved (i.e. the application may demand a different fidelity notion).</p>
</div>
</li>
</ul>
<p id="S5.SS1.p2.2" class="ltx_p">Nevertheless, this impossibility result implies that one needs to assess the privacy and fidelity of the data on a per-case basis. Most importantly, there is no “one-size-fits-all” differentially private synthetic data generation method.</p>
</div>
<div id="S5.SS1.p3" class="ltx_para">
<p id="S5.SS1.p3.1" class="ltx_p">In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib85" title="" class="ltx_ref">85</a>]</cite>, the authors show that by reducing the requirement that all correlations be matched to the requirement that <span id="S5.SS1.p3.1.1" class="ltx_text ltx_font_italic">most</span> correlations be matched, a computationally efficient algorithm <span id="S5.SS1.p3.1.2" class="ltx_text ltx_font_italic">does</span> exist. Such a result is promising for synthetic data, but raises the question of being able to quantify what aspects of the data structure (i.e. which correlations) are <span id="S5.SS1.p3.1.3" class="ltx_text ltx_font_italic">not</span> being matched.</p>
</div>
<div id="S5.SS1.p4" class="ltx_para">
<p id="S5.SS1.p4.1" class="ltx_p">Such results highlight the need for synthetic data to not try to be too general – synthetic data should be generated with a use case in mind. For a given use case, relevant statistical properties can be preserved, while others can be ignored in the name of creating privacy. Below, we give some concrete examples of such use cases, alongside an application we believe to be a misguided endeavour.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Auditing Synthetic Data</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">In this section, we discuss various approaches for empirically evaluating synthetic data, both in terms of its privacy, and its utility and fidelity.</p>
</div>
<section id="S6.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1 </span>Empirically Evaluating the Privacy of Synthetic Data</h3>

<div id="S6.SS1.p1" class="ltx_para">
<p id="S6.SS1.p1.1" class="ltx_p">Given that differential privacy is a theoretical notion of privacy that must be proven, and correctly implemented, to be satisfied, a natural question is to ask whether or not one can verify some notion of privacy for a synthetically generated dataset, or a synthetic data generator, empirically. Given that the goal is to protect against the (abstract) threat models outlined in <a href="#S4.SS1" title="4.1 The Threat Model View ‣ 4 Privacy in Machine Learning - An Overview ‣ Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>, can one “prove” privacy by attempting to perform attacks against a given dataset?</p>
</div>
<section id="S6.SS1.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">DP verification.</h5>

<div id="S6.SS1.SSS0.Px1.p1" class="ltx_para">
<p id="S6.SS1.SSS0.Px1.p1.1" class="ltx_p">As mentioned above, the differential privacy of a synthetic dataset is more precisely a property of the algorithm that generated it, and <span id="S6.SS1.SSS0.Px1.p1.1.1" class="ltx_text ltx_font_italic">cannot</span> be verified by inspecting the synthetic dataset itself. Researchers have been investigating methods for checking that an algorithm meets DP requirements <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib86" title="" class="ltx_ref">86</a>, <a href="#bib.bib87" title="" class="ltx_ref">87</a>, <a href="#bib.bib88" title="" class="ltx_ref">88</a>]</cite>. These methods work either by querying the algorithm in search of violations of the privacy definition, or by running known attacks (e.g. membership inference) against it.</p>
</div>
<div id="S6.SS1.SSS0.Px1.p2" class="ltx_para">
<p id="S6.SS1.SSS0.Px1.p2.1" class="ltx_p">These are useful tools, which can be applied to SDG methods, as a way of testing/understanding their privacy. Perhaps the most useful application is to help us understand what values of <math id="S6.SS1.SSS0.Px1.p2.1.m1.1" class="ltx_Math" alttext="\varepsilon" display="inline"><semantics id="S6.SS1.SSS0.Px1.p2.1.m1.1a"><mi id="S6.SS1.SSS0.Px1.p2.1.m1.1.1" xref="S6.SS1.SSS0.Px1.p2.1.m1.1.1.cmml">ε</mi><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS0.Px1.p2.1.m1.1b"><ci id="S6.SS1.SSS0.Px1.p2.1.m1.1.1.cmml" xref="S6.SS1.SSS0.Px1.p2.1.m1.1.1">𝜀</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS0.Px1.p2.1.m1.1c">\varepsilon</annotation></semantics></math> make the most sense in a specific context. However, using these tools to “prove” differential privacy is not possible, as they are based on statistical analysis of the generating algorithm. What is possible is that one can show, with a certain confidence, that an algorithm is <span id="S6.SS1.SSS0.Px1.p2.1.1" class="ltx_text ltx_font_italic">likely</span> to be differentially private, but doing so would require sampling many, many times (and more samples would be needed for more complex outputs/algorithms, e.g. when the output is a dataset) from the algorithm with many, many different input datasets. Doing so would be <span id="S6.SS1.SSS0.Px1.p2.1.2" class="ltx_text ltx_font_italic">highly</span> computationally intractable if any sort of meaningful level of confidence was to be achieved.</p>
</div>
</section>
<section id="S6.SS1.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Leakage estimation.</h5>

<div id="S6.SS1.SSS0.Px2.p1" class="ltx_para">
<p id="S6.SS1.SSS0.Px2.p1.1" class="ltx_p">An alternative option for evaluating the privacy of algorithms is to use <span id="S6.SS1.SSS0.Px2.p1.1.1" class="ltx_text ltx_font_italic">leakage estimation</span> techniques <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib89" title="" class="ltx_ref">89</a>, <a href="#bib.bib90" title="" class="ltx_ref">90</a>]</cite>, which stem from the quantitative information flow community <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib91" title="" class="ltx_ref">91</a>]</cite>. These techniques enable quantifying the privacy of an algorithm with respect to a specific threat model (or adversary). For example, in the context of SDG, this means one could use leakage estimation for assessing the resilience of a method against membership inference or attribute inference attacks, which we described above.</p>
</div>
<div id="S6.SS1.SSS0.Px2.p2" class="ltx_para">
<p id="S6.SS1.SSS0.Px2.p2.1" class="ltx_p">A strong advantage of this approach, is that it does not require any formal analysis of the SDG method; additionally, it can be used for selecting the privacy parameters of a DP algorithm. Another advantage is that some of these methods enable a fully black-box analysis; that is, there is no need to describe the algorithm’s internals analytically. One disadvantage is that the leakage estimation analysis is done with a specific threat model (or attack) in mind, although there are ways of capturing many attacks with the same analysis <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib92" title="" class="ltx_ref">92</a>]</cite>. A second disadvantage is that, in the case of black-box leakage estimation methods, the formal guarantees derived via these approaches make the assumption that we can sample an arbitrary amount of data from the algorithm. Nevertheless, they have been shown to be effective when tackling real-world tasks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib93" title="" class="ltx_ref">93</a>]</cite>.</p>
</div>
</section>
<section id="S6.SS1.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Empirical privacy evaluation of datasets themselves.</h5>

<div id="S6.SS1.SSS0.Px3.p1" class="ltx_para">
<p id="S6.SS1.SSS0.Px3.p1.1" class="ltx_p">The empirical evaluation of privacy of synthetic data is a nascent and challenging area of research. Despite the fact that <span id="S6.SS1.SSS0.Px3.p1.1.1" class="ltx_text ltx_font_italic">differential</span> privacy cannot be established for a dataset in isolation, practitioners in the field of synthetic data have made use of a hold-out test set to evaluate (other notions of) the privacy of generated synthetic data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib94" title="" class="ltx_ref">94</a>]</cite>. The Nearest-Neighbour distance ratio (NNDR) has been used to inspect whether or not synthetic data points are closer than some hold-out test points to the underlying real data points (on average). This involves splitting the data into a training set, and a test set (as is similarly done in supervised learning problems). The training set is then used to train the model. Once trained, samples are drawn from the trained model, and the distance from these samples to the training data is compared with the distance from the test set to the training data.</p>
</div>
<div id="S6.SS1.SSS0.Px3.p2" class="ltx_para">
<p id="S6.SS1.SSS0.Px3.p2.1" class="ltx_p">Note that although this method is agnostic of the method used to train the data generator, it does rely on a hold-out test set being available. As noted in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib95" title="" class="ltx_ref">95</a>]</cite>, non-existence of points can be just as revealing as the existence of points in the synthetic dataset, but privacy analysis via NNDR does not capture this behaviour. Indeed it is possible to satisfy NNDR by creating “holes” in the synthetic data around the real data points, but such an approach would reveal where the real records should be.</p>
</div>
<div id="S6.SS1.SSS0.Px3.p3" class="ltx_para">
<p id="S6.SS1.SSS0.Px3.p3.1" class="ltx_p">A similar application of NNDR is performed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib96" title="" class="ltx_ref">96</a>]</cite> to attempt to ensure privacy of the generative model, which also does not control for the creation of such “holes”. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib83" title="" class="ltx_ref">83</a>]</cite>, they use a nearest-neighbour based classifier to quantify the risk of attribute disclosure but do so in a non-contrastive way, thus rendering the privacy analysis weak. An NNDR-type metric was also used in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib97" title="" class="ltx_ref">97</a>]</cite> to assess the relative privacy of several generative models proposed for health data.</p>
</div>
</section>
<section id="S6.SS1.SSS0.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Attacks against private synthetic data.</h5>

<div id="S6.SS1.SSS0.Px4.p1" class="ltx_para">
<p id="S6.SS1.SSS0.Px4.p1.1" class="ltx_p">As we explain in section <a href="#S4.SS1" title="4.1 The Threat Model View ‣ 4 Privacy in Machine Learning - An Overview ‣ Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>, one of the approaches to understand and analyse privacy is through the lens of attacks: what can a motivated attacker learn about users in the dataset?
In addition to being intuitive, this approach can help us evaluate whether a system protects user privacy in a given context, and compare methods built with different privacy definitions in mind.
This is particularly relevant for synthetic data generation: as we have presented in previous sections, a wide variety of SDG methods have been proposed, with widely different privacy definitions, choice of parameters, and assumptions.
Despite the potential of adversarial approaches to evaluate privacy risks of synthetic data, the development of privacy attacks against SDG remains underexplored. We here review existing attacks, and suggest promising research areas.</p>
</div>
<div id="S6.SS1.SSS0.Px4.p2" class="ltx_para">
<p id="S6.SS1.SSS0.Px4.p2.1" class="ltx_p">The main method to evaluate privacy risks in synthetic data was proposed by Stadler et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib80" title="" class="ltx_ref">80</a>]</cite> in a recent paper.
They propose a general methodology to apply membership and attribute inference attacks on <span id="S6.SS1.SSS0.Px4.p2.1.1" class="ltx_text ltx_font_italic">any</span> synthetic data generation model.
They assume black-box access to the SDG method, and specifically, being able to retrain the SDG model on new data.
Indeed, analysing the synthetic data alone (as in NNDR metrics) is, in general, not sufficient to properly understand information leakages: an algorithm sampling records uniformly at random might, by coincidence, replicate exactly some records from some private dataset, but this would not usually be considered a privacy violation.
Further, this assumption is a key transparency requirement: in order to audit synthetic data, it is necessary to be able to understand how it was generated. Therefore, privacy guarantees cannot usually be obtained by maintaining secrecy of the generating algorithm.
The method proposed by Stadler et al. uses <span id="S6.SS1.SSS0.Px4.p2.1.2" class="ltx_text ltx_font_italic">shadow modelling</span>: the attacker simulates many runs of the SDG algorithm, using auxiliary data, to generate synthetic datasets trained with or without a target user. A binary classifier is then trained on features extracted from these synthetic datasets to predict whether the target user is in the training dataset.
Empirical results suggest that current SDG methods either are vulnerable to this attack or, if the attack fails, lead to an accuracy worse than non-SDG methods for a range of data analysis tasks.</p>
</div>
<div id="S6.SS1.SSS0.Px4.p3" class="ltx_para">
<p id="S6.SS1.SSS0.Px4.p3.1" class="ltx_p">Outside of this specific paper, there is a rich literature on privacy attacks that can be leveraged to develop attacks against synthetic data.
We here detail two possible lines of research for this approach:</p>
<ol id="S6.I1" class="ltx_enumerate">
<li id="S6.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S6.I1.i1.p1" class="ltx_para">
<p id="S6.I1.i1.p1.1" class="ltx_p">Many synthetic data generation methods rely on Generative Adversarial Networks (see, e.g., <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib98" title="" class="ltx_ref">98</a>, <a href="#bib.bib99" title="" class="ltx_ref">99</a>, <a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>).
Researchers have demonstrated that such GANs can be vulnerable to white-box and black-box membership inference attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib100" title="" class="ltx_ref">100</a>, <a href="#bib.bib101" title="" class="ltx_ref">101</a>]</cite>.
A key question is then: how can these attacks be ported to the setup where the attacker has access to <span id="S6.I1.i1.p1.1.1" class="ltx_text ltx_font_italic">data</span> generated by the model, rather than the model itself.</p>
</div>
</li>
<li id="S6.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S6.I1.i2.p1" class="ltx_para">
<p id="S6.I1.i2.p1.1" class="ltx_p">Some methods built with specific use cases in mind can aim to closely replicate statistical properties of the training dataset, such as one-way marginals histograms or correlations.
Many membership inference attacks have been proposed against aggregate statistics, from simple statistical tests <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib102" title="" class="ltx_ref">102</a>, <a href="#bib.bib103" title="" class="ltx_ref">103</a>]</cite> to advanced attacks based on shadow models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib104" title="" class="ltx_ref">104</a>]</cite>.
If the synthetic data accurately reproduces many aggregates from the original data, one can apply these attacks to the synthetic data to infer membership of specific records in the training dataset.
This leads to an interesting question: how many statistics can be accurately reproduced from the original data, without enabling such attacks?</p>
</div>
</li>
</ol>
<p id="S6.SS1.SSS0.Px4.p3.2" class="ltx_p">These are only two prospective research directions for the adversarial evaluation of synthetic data, which is an open line of research.</p>
</div>
</section>
</section>
<section id="S6.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2 </span>Evaluating the Utility and Fidelity of Synthetic Datasets</h3>

<div id="S6.SS2.p1" class="ltx_para">
<p id="S6.SS2.p1.1" class="ltx_p">The methods presented in this section generally focus on privacy as their primary design goal, most often through explicit guarantees such as differential privacy.
In this section, we review approaches to evaluate the secondary goal of such datasets: their <span id="S6.SS2.p1.1.1" class="ltx_text ltx_font_italic">utility</span> and <span id="S6.SS2.p1.1.2" class="ltx_text ltx_font_italic">fidelity</span>.
The utility of a private synthetic dataset is determined entirely by its application.
Generating synthetic data to enable release of otherwise private data has almost as many use cases as there are machine learning problems – any data-driven problem might be derived from sensitive data and the data controllers may wish to investigate which ML methods might address the problem.
Below (<a href="#S6.SS2.SSS1" title="6.2.1 Utility-driven evaluation ‣ 6.2 Evaluating the Utility and Fidelity of Synthetic Datasets ‣ 6 Auditing Synthetic Data ‣ Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6.2.1</span></a>) we give example use-cases, and suggest how utility might be measured in such cases.
Fidelity is less well-defined: it generally aims at evaluating how close the <span id="S6.SS2.p1.1.3" class="ltx_text ltx_font_italic">distribution</span> of the synthetic dataset is to that of the real data, the idea being that if the distributions match, the synthetic data can be used to perform any task as accurately as with the real data.
We discuss this more general use case, and review works studying fidelity, in section <a href="#S6.SS2.SSS2" title="6.2.2 Fidelity-driven evaluation ‣ 6.2 Evaluating the Utility and Fidelity of Synthetic Datasets ‣ 6 Auditing Synthetic Data ‣ Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6.2.2</span></a>.</p>
</div>
<section id="S6.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">6.2.1 </span>Utility-driven evaluation</h4>

<div id="S6.SS2.SSS1.p1" class="ltx_para">
<p id="S6.SS2.SSS1.p1.1" class="ltx_p">The key use-case for privately-generated synthetic data is to enable research and industry data analysis tasks without access to sensitive data.
A particularly important application is the development of machine learning (ML) models to perform inference and classification tasks from data.
In this setting, the goal is to determine the best model (or a selection of best contenders), and train it (choose its parameters) to perform a given task.
In general, such a task will come with its own metric of performance (e.g. accuracy/AUROC in a classification task).
There are broadly two directions of research aiming to evaluate the suitability of synthetic data for ML training: (1) evaluating the performance of models trained on synthetic data, and (2) evaluating whether the <span id="S6.SS2.SSS1.p1.1.1" class="ltx_text ltx_font_italic">relative performances</span> of different models are similar on synthetic and real data.</p>
</div>
<div id="S6.SS2.SSS1.p2" class="ltx_para">
<p id="S6.SS2.SSS1.p2.1" class="ltx_p">The first approach assumes that analysts will train a machine learning model on the synthetic data, and use this model directly on real, future data.
In this situation, it is important that the accuracy of a model estimated with synthetic data reflects its accuracy on real data.
For instance, Beaulieu et al. evaluate their synthetic data generation method by measuring the accuracy of classifiers trained on synthetic datasets on the real sensitive medical data used to generate the synthetic data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib105" title="" class="ltx_ref">105</a>]</cite>.
Patki et al. pushed this further, by distributing synthetic datasets and real datasets randomly to teams of data scientists, and evaluating whether teams working on real and synthetic datasets would arrive at approximately the same conclusions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib106" title="" class="ltx_ref">106</a>]</cite>.
Similar approaches were used by Tao et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib107" title="" class="ltx_ref">107</a>]</cite>, where a XGBoost classifier is trained on synthetic data and evaluated on real data for a range of different tabular datasets.</p>
</div>
<div id="S6.SS2.SSS1.p3" class="ltx_para">
<p id="S6.SS2.SSS1.p3.1" class="ltx_p">Note that this approach makes some assumptions on the family of models that will be trained, since it is impossible to test <span id="S6.SS2.SSS1.p3.1.1" class="ltx_text ltx_font_italic">all possible classes of models</span>, as well as all possible choices of hyper-parameters.
When synthetic data is generated with a set of specific tasks in mind, custom metrics can also be developed that capture the accuracy on these specific tasks.
For instance, in the NIST challenge<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a target="_blank" href="https://www.nist.gov/ctl/pscr/open-innovation-prize-challenges/current-and-upcoming-prize-challenges/2020-differential" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.nist.gov/ctl/pscr/open-innovation-prize-challenges/current-and-upcoming-prize-challenges/2020-differential</a></span></span></span>, accuracy was measured by the error on the Gini coefficient of incomes and the gender pay gap in (real) demographic data with financial information, when estimated on synthetic data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib108" title="" class="ltx_ref">108</a>]</cite>.</p>
</div>
<div id="S6.SS2.SSS1.p4" class="ltx_para">
<p id="S6.SS2.SSS1.p4.1" class="ltx_p">The second approach studies whether, for a battery of models, their ranking in terms of accuracy would be the same when trained on synthetic or real data.
This setup assumes that analysts use synthetic data to <span id="S6.SS2.SSS1.p4.1.1" class="ltx_text ltx_font_italic">select</span> a model, which is then trained on a real dataset (for better real-world performances).
Crucially, the goal is that model development on synthetic data reflects model development on real data – when a comparison is made (e.g. between two choices of hyperparameters), it should mirror the comparison on the real data. The utility of the synthetic dataset is then given by how well the performance ranking of models on the synthetic data matches the ranking that would be determined by the real data. This is challenging to measure since, in theory, one would want to ensure that “all possible methods” are appropriately ranked, including those which have yet to be developed/discovered. One approach might be to approximate this by comparing a list of representative models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib109" title="" class="ltx_ref">109</a>]</cite>. It might also make sense to expand the list of representative models by incorporating small variations of each model (i.e. by varying the hyperparameters involved). Efficiently computing this for a broad enough class of models would be key, which may require new insights to ensure the class is indeed sufficiently broad.</p>
</div>
<div id="S6.SS2.SSS1.p5" class="ltx_para">
<p id="S6.SS2.SSS1.p5.1" class="ltx_p">An important thing to keep in mind when utilising synthetic data in this way is the variability of various models’ performances, especially the variability with respect to the real vs. synthetic data. In particular, if several synthetic datasets (each with decreasing privacy) are going to be used to narrow-down the best methodology, then the process needs to be aware of how the earlier (more private) synthetic datasets will typically create noisier rankings and so the notion of a method being statistically significantly better than another needs to be adjusted accordingly.</p>
</div>
</section>
<section id="S6.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">6.2.2 </span>Fidelity-driven evaluation</h4>

<div id="S6.SS2.SSS2.p1" class="ltx_para">
<p id="S6.SS2.SSS2.p1.2" class="ltx_p">A promise of synthetic data is that it “looks like” real data, and can thus be used for a variety of purposes.
From a statistical perspective, the goal that the distribution <math id="S6.SS2.SSS2.p1.1.m1.1" class="ltx_Math" alttext="\hat{\mathbb{p}P}" display="inline"><semantics id="S6.SS2.SSS2.p1.1.m1.1a"><mover accent="true" id="S6.SS2.SSS2.p1.1.m1.1.1" xref="S6.SS2.SSS2.p1.1.m1.1.1.cmml"><mrow id="S6.SS2.SSS2.p1.1.m1.1.1.2" xref="S6.SS2.SSS2.p1.1.m1.1.1.2.cmml"><mi id="S6.SS2.SSS2.p1.1.m1.1.1.2.2" xref="S6.SS2.SSS2.p1.1.m1.1.1.2.2.cmml">𝕡</mi><mo lspace="0em" rspace="0em" id="S6.SS2.SSS2.p1.1.m1.1.1.2.1" xref="S6.SS2.SSS2.p1.1.m1.1.1.2.1.cmml">​</mo><mi id="S6.SS2.SSS2.p1.1.m1.1.1.2.3" xref="S6.SS2.SSS2.p1.1.m1.1.1.2.3.cmml">P</mi></mrow><mo id="S6.SS2.SSS2.p1.1.m1.1.1.1" xref="S6.SS2.SSS2.p1.1.m1.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS2.p1.1.m1.1b"><apply id="S6.SS2.SSS2.p1.1.m1.1.1.cmml" xref="S6.SS2.SSS2.p1.1.m1.1.1"><ci id="S6.SS2.SSS2.p1.1.m1.1.1.1.cmml" xref="S6.SS2.SSS2.p1.1.m1.1.1.1">^</ci><apply id="S6.SS2.SSS2.p1.1.m1.1.1.2.cmml" xref="S6.SS2.SSS2.p1.1.m1.1.1.2"><times id="S6.SS2.SSS2.p1.1.m1.1.1.2.1.cmml" xref="S6.SS2.SSS2.p1.1.m1.1.1.2.1"></times><ci id="S6.SS2.SSS2.p1.1.m1.1.1.2.2.cmml" xref="S6.SS2.SSS2.p1.1.m1.1.1.2.2">𝕡</ci><ci id="S6.SS2.SSS2.p1.1.m1.1.1.2.3.cmml" xref="S6.SS2.SSS2.p1.1.m1.1.1.2.3">𝑃</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS2.p1.1.m1.1c">\hat{\mathbb{p}P}</annotation></semantics></math> used to generate synthetic data is <span id="S6.SS2.SSS2.p1.2.1" class="ltx_text ltx_font_italic">close to</span> the (unknown) real data distribution <math id="S6.SS2.SSS2.p1.2.m2.1" class="ltx_Math" alttext="\mathbb{P}" display="inline"><semantics id="S6.SS2.SSS2.p1.2.m2.1a"><mi id="S6.SS2.SSS2.p1.2.m2.1.1" xref="S6.SS2.SSS2.p1.2.m2.1.1.cmml">ℙ</mi><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS2.p1.2.m2.1b"><ci id="S6.SS2.SSS2.p1.2.m2.1.1.cmml" xref="S6.SS2.SSS2.p1.2.m2.1.1">ℙ</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS2.p1.2.m2.1c">\mathbb{P}</annotation></semantics></math>.
Typically, evaluating fidelity in this way involves choosing a distance with which to compare distributions, then evaluating this distance empirically from samples of the real and synthetic datasets.</p>
</div>
<div id="S6.SS2.SSS2.p2" class="ltx_para">
<p id="S6.SS2.SSS2.p2.1" class="ltx_p">A simple example is to focus on 1- and 2-way marginals of the data, which can be efficiently computed.
The difference between these marginals can be estimated with a wide range of metrics: total variational distance <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib107" title="" class="ltx_ref">107</a>]</cite>, correlations and Cramer’s V <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib107" title="" class="ltx_ref">107</a>]</cite>, or classical distances <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib108" title="" class="ltx_ref">108</a>]</cite>.
These metrics aim to capture whether the synthetic data captures basic properties of the real data, such as histograms of individual attributes and relations between pairs of attributes.</p>
</div>
<div id="S6.SS2.SSS2.p3" class="ltx_para">
<p id="S6.SS2.SSS2.p3.1" class="ltx_p">Estimating distributional distances in higher dimensions, capturing relations between several attributes at a time, is challenging.
Researchers have proposed ad hoc metrics, such as comparing the density of the synthetic and empirical distributions over random subsets of <math id="S6.SS2.SSS2.p3.1.m1.1" class="ltx_Math" alttext="\mathcal{X}" display="inline"><semantics id="S6.SS2.SSS2.p3.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S6.SS2.SSS2.p3.1.m1.1.1" xref="S6.SS2.SSS2.p3.1.m1.1.1.cmml">𝒳</mi><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS2.p3.1.m1.1b"><ci id="S6.SS2.SSS2.p3.1.m1.1.1.cmml" xref="S6.SS2.SSS2.p3.1.m1.1.1">𝒳</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS2.p3.1.m1.1c">\mathcal{X}</annotation></semantics></math> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib108" title="" class="ltx_ref">108</a>]</cite>.
Another solution is the <span id="S6.SS2.SSS2.p3.1.1" class="ltx_text ltx_font_italic">propensity score</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib110" title="" class="ltx_ref">110</a>, <a href="#bib.bib111" title="" class="ltx_ref">111</a>]</cite>, which captures the accuracy of a classifier trained to differentiate real from synthetic data points. Intuitively, if the classifier cannot distinguish the two, then the distribution of synthetic data points must be close to that of real data points (this is the basis of the original GAN framework <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>).</p>
</div>
<div id="S6.SS2.SSS2.p4" class="ltx_para">
<p id="S6.SS2.SSS2.p4.1" class="ltx_p">In the context of generative networks (and specifically, GANs), researchers have proposed measures to evaluate the fidelity of synthetic samples.
Sajjadi et al. proposed metrics of <span id="S6.SS2.SSS2.p4.1.1" class="ltx_text ltx_font_italic">precision</span> (the quality of synthetic samples) and <span id="S6.SS2.SSS2.p4.1.2" class="ltx_text ltx_font_italic">recall</span> (the diversity of synthetic samples), inspired by common failure modes of GANs <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib112" title="" class="ltx_ref">112</a>]</cite>.
The key question that these metrics seek to answer is how do the empirical and synthetic distributions <span id="S6.SS2.SSS2.p4.1.3" class="ltx_text ltx_font_italic">overlap</span>: precision (resp. recall) captures how much of the synthetic (resp. real) data falls within the support of real (resp. synthetic) data.
Researchers have proposed extensions of these metrics to increase their robustness to outliers and make them easier to compute <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib113" title="" class="ltx_ref">113</a>]</cite>
and account for the probability distribution rather than just the support <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib84" title="" class="ltx_ref">84</a>]</cite>.</p>
</div>
</section>
</section>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Private Synthetic Data Generation</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">Thus far, we have focused on privacy in a broader context than synthetic data. This is natural, because most privacy notions apply more generally. However, synthetic data has an additional property that most other (non-synthetic data) outputs do not have – it resides in the space of the real data. That is, the synthetic data takes values from precisely the same space as the original data. This allows us to use synthetic data in the place of real data, and also to compare the similarity of the synthetic and real data directly. We begin by highlighting some key considerations for private synthetic data generation.</p>
</div>
<section id="S7.SS0.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">The space of datasets can be very high-dimensional.</h5>

<div id="S7.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S7.SS0.SSS0.Px1.p1.1" class="ltx_p">Differential privacy has been conventionally applied to settings in which the dimensionality of the output space is relatively small, such as count queries on rows, classification tasks, etc. Synthetic data generation, on the other hand, gives output in a very high-dimensional space, i.e. the space of datasets (perhaps of a fixed size, <math id="S7.SS0.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S7.SS0.SSS0.Px1.p1.1.m1.1a"><mi id="S7.SS0.SSS0.Px1.p1.1.m1.1.1" xref="S7.SS0.SSS0.Px1.p1.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S7.SS0.SSS0.Px1.p1.1.m1.1b"><ci id="S7.SS0.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S7.SS0.SSS0.Px1.p1.1.m1.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS0.SSS0.Px1.p1.1.m1.1c">N</annotation></semantics></math>). Releasing such a high-dimensional object is challenging under differential privacy because it leads to higher (worst-case) sensitivity of the generating function (i.e. the algorithm mapping the input dataset to the output dataset).</p>
</div>
<div id="S7.SS0.SSS0.Px1.p2" class="ltx_para">
<p id="S7.SS0.SSS0.Px1.p2.1" class="ltx_p">Because of this increased worst case sensitivity, accurately constructing a dataset under differential privacy (according to some notion of accuracy) is likely to require a large privacy budget. A dataset of 1 million records, each with only 20 features, results in a 20 million dimensional output. Not only is the sensitivity of such a function likely to be high, but even trying to analyse the sensitivity can be an incredibly difficult task. By instead aiming to create a <span id="S7.SS0.SSS0.Px1.p2.1.1" class="ltx_text ltx_font_italic">private generator</span>, one can alleviate some of the difficulties - the complexity of the generator should not need to scale with the number of rows, but instead only with the dimensionality of the data (e.g. the number of columns in tabular data).</p>
</div>
</section>
<section id="S7.SS0.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Privacy is a property of the Algorithm, <span id="S7.SS0.SSS0.Px2.1.1" class="ltx_text ltx_font_italic">not</span> of the Data.</h5>

<div id="S7.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S7.SS0.SSS0.Px2.p1.1" class="ltx_p">An important-to-note property of differential privacy that it is a notion that is concern with probabilistic properties of the generated outputs and not a single realisation/output of the generator. A single output of the generator is is neither private, nor non-private. In a non-synthetic data setting this may be more obvious. If you query the average age of individuals in a dataset, and are given the response ‘35’, without being told how this was computed, you do not know (even with access to the original data) whether the number 35 was computed privately or not. The algorithm that computed this answer could simply be “always answer 35, regardless of input data” which clearly reveals no information. The point is there is nothing private or “unprivate” about the <span id="S7.SS0.SSS0.Px2.p1.1.1" class="ltx_text ltx_font_italic">number</span> 35.</p>
</div>
<div id="S7.SS0.SSS0.Px2.p2" class="ltx_para">
<p id="S7.SS0.SSS0.Px2.p2.1" class="ltx_p">What <span id="S7.SS0.SSS0.Px2.p2.1.1" class="ltx_text ltx_font_italic">is</span> private (or non-private) is the algorithm that produces the number, or in the case of this report, that produced the synthetic dataset. Crucially, this means that, at least from the perspective of differential privacy, it is <span id="S7.SS0.SSS0.Px2.p2.1.2" class="ltx_text ltx_font_italic">meaningless</span> to talk about the privacy as a property of a concrete synthetic dataset.</p>
</div>
</section>
<section id="S7.SS0.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Private Data vs. Private Generator.</h5>

<div id="S7.SS0.SSS0.Px3.p1" class="ltx_para">
<p id="S7.SS0.SSS0.Px3.p1.3" class="ltx_p">The most common approach to generating private synthetic data is to first train a <span id="S7.SS0.SSS0.Px3.p1.3.1" class="ltx_text ltx_font_italic">private generator</span> (e.g., <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib114" title="" class="ltx_ref">114</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib115" title="" class="ltx_ref">115</a>]</cite>) on the real data.
This model is then directly sampled from to generate individual datapoints and thus build up an entire synthetic dataset.
Due to the post-processing theorem <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>, if the procedure used to train the private generator is <math id="S7.SS0.SSS0.Px3.p1.1.m1.1" class="ltx_Math" alttext="\varepsilon" display="inline"><semantics id="S7.SS0.SSS0.Px3.p1.1.m1.1a"><mi id="S7.SS0.SSS0.Px3.p1.1.m1.1.1" xref="S7.SS0.SSS0.Px3.p1.1.m1.1.1.cmml">ε</mi><annotation-xml encoding="MathML-Content" id="S7.SS0.SSS0.Px3.p1.1.m1.1b"><ci id="S7.SS0.SSS0.Px3.p1.1.m1.1.1.cmml" xref="S7.SS0.SSS0.Px3.p1.1.m1.1.1">𝜀</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS0.SSS0.Px3.p1.1.m1.1c">\varepsilon</annotation></semantics></math>-differentially private (<math id="S7.SS0.SSS0.Px3.p1.2.m2.1" class="ltx_Math" alttext="\varepsilon" display="inline"><semantics id="S7.SS0.SSS0.Px3.p1.2.m2.1a"><mi id="S7.SS0.SSS0.Px3.p1.2.m2.1.1" xref="S7.SS0.SSS0.Px3.p1.2.m2.1.1.cmml">ε</mi><annotation-xml encoding="MathML-Content" id="S7.SS0.SSS0.Px3.p1.2.m2.1b"><ci id="S7.SS0.SSS0.Px3.p1.2.m2.1.1.cmml" xref="S7.SS0.SSS0.Px3.p1.2.m2.1.1">𝜀</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS0.SSS0.Px3.p1.2.m2.1c">\varepsilon</annotation></semantics></math>-DP), it can be used to generate arbitrarily many synthetic data records without affecting the privacy guarantees.
In fact, the procedure to generate the synthetic dataset (of arbitrary size) is itself <math id="S7.SS0.SSS0.Px3.p1.3.m3.1" class="ltx_Math" alttext="\varepsilon" display="inline"><semantics id="S7.SS0.SSS0.Px3.p1.3.m3.1a"><mi id="S7.SS0.SSS0.Px3.p1.3.m3.1.1" xref="S7.SS0.SSS0.Px3.p1.3.m3.1.1.cmml">ε</mi><annotation-xml encoding="MathML-Content" id="S7.SS0.SSS0.Px3.p1.3.m3.1b"><ci id="S7.SS0.SSS0.Px3.p1.3.m3.1.1.cmml" xref="S7.SS0.SSS0.Px3.p1.3.m3.1.1">𝜀</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS0.SSS0.Px3.p1.3.m3.1c">\varepsilon</annotation></semantics></math>-DP, which guarantees that individual records in the real data are protected from attacks.</p>
</div>
<div id="S7.SS0.SSS0.Px3.p2" class="ltx_para">
<p id="S7.SS0.SSS0.Px3.p2.1" class="ltx_p">However, training an <math id="S7.SS0.SSS0.Px3.p2.1.m1.1" class="ltx_Math" alttext="\varepsilon-" display="inline"><semantics id="S7.SS0.SSS0.Px3.p2.1.m1.1a"><mrow id="S7.SS0.SSS0.Px3.p2.1.m1.1.1" xref="S7.SS0.SSS0.Px3.p2.1.m1.1.1.cmml"><mi id="S7.SS0.SSS0.Px3.p2.1.m1.1.1.2" xref="S7.SS0.SSS0.Px3.p2.1.m1.1.1.2.cmml">ε</mi><mo id="S7.SS0.SSS0.Px3.p2.1.m1.1.1.3" xref="S7.SS0.SSS0.Px3.p2.1.m1.1.1.3.cmml">−</mo></mrow><annotation-xml encoding="MathML-Content" id="S7.SS0.SSS0.Px3.p2.1.m1.1b"><apply id="S7.SS0.SSS0.Px3.p2.1.m1.1.1.cmml" xref="S7.SS0.SSS0.Px3.p2.1.m1.1.1"><csymbol cd="latexml" id="S7.SS0.SSS0.Px3.p2.1.m1.1.1.1.cmml" xref="S7.SS0.SSS0.Px3.p2.1.m1.1.1">limit-from</csymbol><ci id="S7.SS0.SSS0.Px3.p2.1.m1.1.1.2.cmml" xref="S7.SS0.SSS0.Px3.p2.1.m1.1.1.2">𝜀</ci><minus id="S7.SS0.SSS0.Px3.p2.1.m1.1.1.3.cmml" xref="S7.SS0.SSS0.Px3.p2.1.m1.1.1.3"></minus></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS0.SSS0.Px3.p2.1.m1.1c">\varepsilon-</annotation></semantics></math>DP generator to then generate some fixed number of synthetic samples can lead to overly conservative privacy guarantees, and thus lower utility.
Intuitively, DP restricts the amount of information extracted from the real dataset when computing the output (the generator or dataset).
The generator acts as a bottleneck for information: any finite sample from a generator necessarily has less information from the original dataset, and thus typically results in lower utility.</p>
</div>
</section>
<section id="S7.SS0.SSS0.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Outliers and Fairness.</h5>

<div id="S7.SS0.SSS0.Px4.p1" class="ltx_para">
<p id="S7.SS0.SSS0.Px4.p1.1" class="ltx_p">Capturing outliers with private synthetic data is difficult. Outliers are precisely data points with <span id="S7.SS0.SSS0.Px4.p1.1.1" class="ltx_text ltx_font_italic">some</span> uniquely identifying features; this means that “hiding them in the masses” becomes impossible. In some scenarios, for example credit card fraud detection, detecting outliers is the goal. In such a setting, private synthetic data is unlikely to provide much utility, as the outliers will necessarily be suppressed by the need for privacy. Indeed, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib116" title="" class="ltx_ref">116</a>]</cite> posit that if outliers are to be captured, then an SDG method cannot attain both a high privacy and a high utility.</p>
</div>
<div id="S7.SS0.SSS0.Px4.p2" class="ltx_para">
<p id="S7.SS0.SSS0.Px4.p2.1" class="ltx_p">This has a problematic implication for fairness: minority groups, like outliers, can often end up being under-represented in synthetic data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib117" title="" class="ltx_ref">117</a>, <a href="#bib.bib118" title="" class="ltx_ref">118</a>]</cite>. Indeed, there is a clear tension between fairness and privacy, with fairness requiring that there is a good utility, even for minority groups, and privacy hiding the contributions of individuals, and thus collectively hiding the contribution of a minority group. Indeed, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib119" title="" class="ltx_ref">119</a>]</cite> posit that current mechanisms are unable to simultaneously achieve privacy, fairness and utility.</p>
</div>
</section>
<section id="S7.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.1 </span>Existing Methods and Technologies</h3>

<div id="S7.SS1.p1" class="ltx_para">
<p id="S7.SS1.p1.1" class="ltx_p">Much attention in the machine learning community is being given to the problem of <span id="S7.SS1.p1.1.1" class="ltx_text ltx_font_italic">generative modelling</span>. The goal of generative modelling is to generate samples with similar statistical properties to the available training data. Generative models are a key ingredient in synthetic data generation, but crucially require additional thought beyond their basic capability to “generate samples” - the problem of generating samplings from a distribution given training data is under-specified, and can be satisfied by memorising the training data and regurgitating when asked. We defer discussion of generative modelling in general to section <a href="#S10" title="10 Generative Modelling - An Overview ‣ Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a>, but draw attention to existing <span id="S7.SS1.p1.1.2" class="ltx_text ltx_font_italic">privacy-preserving</span> generative models here.</p>
</div>
<div id="S7.SS1.p2" class="ltx_para">
<p id="S7.SS1.p2.1" class="ltx_p">As already noted in section <a href="#S4.SS2" title="4.2 Differential Privacy ‣ 4 Privacy in Machine Learning - An Overview ‣ Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>, a key ingredient driving many of the deep learning based algorithms is DPSGD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite> (differentially private stochastic gradient descent), which enables differentially private training of general neural network based architectures. Though not designed specifically for generative models, DPSGD can be applied to both GANs <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib114" title="" class="ltx_ref">114</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib115" title="" class="ltx_ref">115</a>]</cite>, and VAEs <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib120" title="" class="ltx_ref">120</a>]</cite>. Other approaches leverage the popular PATE mechanism <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>, which can be applied to black-box models to create a private predictor. This has been used to replace the discriminator in a GAN model with a private PATE model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>, and as a means of passing gradients from discriminator to generator <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib98" title="" class="ltx_ref">98</a>]</cite>. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib121" title="" class="ltx_ref">121</a>]</cite> use a subsample-and-aggregate approach (similar to PATE) alongside differentially private expectation-maximisation (DP-EM) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib122" title="" class="ltx_ref">122</a>]</cite>.</p>
</div>
<div id="S7.SS1.p3" class="ltx_para">
<p id="S7.SS1.p3.1" class="ltx_p">Other popular approaches involve representing the data in a simple, low-dimensional form, such as using a Bayesian network to represent the data generation process as a series of low-dimensional marginal distributions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>, or leveraging the classical copula framework <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib123" title="" class="ltx_ref">123</a>]</cite> to learn the generation process <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib124" title="" class="ltx_ref">124</a>]</cite>. The recent NIST competition<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a target="_blank" href="https://www.nist.gov/ctl/pscr/open-innovation-prize-challenges/current-and-upcoming-prize-challenges/2020-differential" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.nist.gov/ctl/pscr/open-innovation-prize-challenges/current-and-upcoming-prize-challenges/2020-differential</a></span></span></span>, was won with an algorithm that learns all 2-way distributions (marginals) in a differentially private way, and then does post-processing to generate data from these (potentially inconsistent) marginals <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>. See also <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib125" title="" class="ltx_ref">125</a>]</cite> for similar ideas.</p>
</div>
<div id="S7.SS1.p4" class="ltx_para">
<p id="S7.SS1.p4.1" class="ltx_p">As should be clear from the proceeding discussion, there are many ways to enforce privacy, even when using the same underlying algorithm (e.g. a GAN). The question of where and how to enforce privacy is very much open. Intuitively, one wants to apply privacy simultaneously: (i) as close as possible to the output (e.g. to the generator of a GAN rather than the discriminator); (ii) wherever the tightest analysis of the privacy can be done (with GANs, the discriminator is typically easier to analyse). With GANs, we see examples of privacy being applied to the discriminator <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib114" title="" class="ltx_ref">114</a>]</cite>, and to the generator <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib98" title="" class="ltx_ref">98</a>]</cite>.</p>
</div>
</section>
<section id="S7.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.2 </span>Partially Synthetic Data</h3>

<div id="S7.SS2.p1" class="ltx_para">
<p id="S7.SS2.p1.3" class="ltx_p">For tabular data, where a user’s data is a <math id="S7.SS2.p1.1.m1.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S7.SS2.p1.1.m1.1a"><mi id="S7.SS2.p1.1.m1.1.1" xref="S7.SS2.p1.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S7.SS2.p1.1.m1.1b"><ci id="S7.SS2.p1.1.m1.1.1.cmml" xref="S7.SS2.p1.1.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS2.p1.1.m1.1c">n</annotation></semantics></math>-tuple of <span id="S7.SS2.p1.3.1" class="ltx_text ltx_font_italic">attributes</span> an alternative to the common flavour of SDG is <span id="S7.SS2.p1.3.2" class="ltx_text ltx_font_italic">partially synthetic data</span>.
In partially synthetic data, the attributes of user records are divided into two categories: <span id="S7.SS2.p1.3.3" class="ltx_text ltx_font_italic">quasi-identifiers</span> and <span id="S7.SS2.p1.3.4" class="ltx_text ltx_font_italic">sensitive attributes</span> (formally <math id="S7.SS2.p1.2.m2.1" class="ltx_Math" alttext="\mathcal{X}=\mathcal{X}_{\text{quasi}}\times\mathcal{X}_{\text{sensitive}}" display="inline"><semantics id="S7.SS2.p1.2.m2.1a"><mrow id="S7.SS2.p1.2.m2.1.1" xref="S7.SS2.p1.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S7.SS2.p1.2.m2.1.1.2" xref="S7.SS2.p1.2.m2.1.1.2.cmml">𝒳</mi><mo id="S7.SS2.p1.2.m2.1.1.1" xref="S7.SS2.p1.2.m2.1.1.1.cmml">=</mo><mrow id="S7.SS2.p1.2.m2.1.1.3" xref="S7.SS2.p1.2.m2.1.1.3.cmml"><msub id="S7.SS2.p1.2.m2.1.1.3.2" xref="S7.SS2.p1.2.m2.1.1.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S7.SS2.p1.2.m2.1.1.3.2.2" xref="S7.SS2.p1.2.m2.1.1.3.2.2.cmml">𝒳</mi><mtext id="S7.SS2.p1.2.m2.1.1.3.2.3" xref="S7.SS2.p1.2.m2.1.1.3.2.3a.cmml">quasi</mtext></msub><mo lspace="0.222em" rspace="0.222em" id="S7.SS2.p1.2.m2.1.1.3.1" xref="S7.SS2.p1.2.m2.1.1.3.1.cmml">×</mo><msub id="S7.SS2.p1.2.m2.1.1.3.3" xref="S7.SS2.p1.2.m2.1.1.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S7.SS2.p1.2.m2.1.1.3.3.2" xref="S7.SS2.p1.2.m2.1.1.3.3.2.cmml">𝒳</mi><mtext id="S7.SS2.p1.2.m2.1.1.3.3.3" xref="S7.SS2.p1.2.m2.1.1.3.3.3a.cmml">sensitive</mtext></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S7.SS2.p1.2.m2.1b"><apply id="S7.SS2.p1.2.m2.1.1.cmml" xref="S7.SS2.p1.2.m2.1.1"><eq id="S7.SS2.p1.2.m2.1.1.1.cmml" xref="S7.SS2.p1.2.m2.1.1.1"></eq><ci id="S7.SS2.p1.2.m2.1.1.2.cmml" xref="S7.SS2.p1.2.m2.1.1.2">𝒳</ci><apply id="S7.SS2.p1.2.m2.1.1.3.cmml" xref="S7.SS2.p1.2.m2.1.1.3"><times id="S7.SS2.p1.2.m2.1.1.3.1.cmml" xref="S7.SS2.p1.2.m2.1.1.3.1"></times><apply id="S7.SS2.p1.2.m2.1.1.3.2.cmml" xref="S7.SS2.p1.2.m2.1.1.3.2"><csymbol cd="ambiguous" id="S7.SS2.p1.2.m2.1.1.3.2.1.cmml" xref="S7.SS2.p1.2.m2.1.1.3.2">subscript</csymbol><ci id="S7.SS2.p1.2.m2.1.1.3.2.2.cmml" xref="S7.SS2.p1.2.m2.1.1.3.2.2">𝒳</ci><ci id="S7.SS2.p1.2.m2.1.1.3.2.3a.cmml" xref="S7.SS2.p1.2.m2.1.1.3.2.3"><mtext mathsize="70%" id="S7.SS2.p1.2.m2.1.1.3.2.3.cmml" xref="S7.SS2.p1.2.m2.1.1.3.2.3">quasi</mtext></ci></apply><apply id="S7.SS2.p1.2.m2.1.1.3.3.cmml" xref="S7.SS2.p1.2.m2.1.1.3.3"><csymbol cd="ambiguous" id="S7.SS2.p1.2.m2.1.1.3.3.1.cmml" xref="S7.SS2.p1.2.m2.1.1.3.3">subscript</csymbol><ci id="S7.SS2.p1.2.m2.1.1.3.3.2.cmml" xref="S7.SS2.p1.2.m2.1.1.3.3.2">𝒳</ci><ci id="S7.SS2.p1.2.m2.1.1.3.3.3a.cmml" xref="S7.SS2.p1.2.m2.1.1.3.3.3"><mtext mathsize="70%" id="S7.SS2.p1.2.m2.1.1.3.3.3.cmml" xref="S7.SS2.p1.2.m2.1.1.3.3.3">sensitive</mtext></ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS2.p1.2.m2.1c">\mathcal{X}=\mathcal{X}_{\text{quasi}}\times\mathcal{X}_{\text{sensitive}}</annotation></semantics></math>).
The quasi-identifiers are assumed to be non-sensitive and can be disclosed unchanged, while the sensitive attributes need to be protected.
Partially synthetic data is obtained by first fitting a statistical model <math id="S7.SS2.p1.3.m3.1" class="ltx_Math" alttext="f:\mathcal{X}_{\text{quasi}}\rightarrow\mathcal{X}_{\text{sensitive}}" display="inline"><semantics id="S7.SS2.p1.3.m3.1a"><mrow id="S7.SS2.p1.3.m3.1.1" xref="S7.SS2.p1.3.m3.1.1.cmml"><mi id="S7.SS2.p1.3.m3.1.1.2" xref="S7.SS2.p1.3.m3.1.1.2.cmml">f</mi><mo lspace="0.278em" rspace="0.278em" id="S7.SS2.p1.3.m3.1.1.1" xref="S7.SS2.p1.3.m3.1.1.1.cmml">:</mo><mrow id="S7.SS2.p1.3.m3.1.1.3" xref="S7.SS2.p1.3.m3.1.1.3.cmml"><msub id="S7.SS2.p1.3.m3.1.1.3.2" xref="S7.SS2.p1.3.m3.1.1.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S7.SS2.p1.3.m3.1.1.3.2.2" xref="S7.SS2.p1.3.m3.1.1.3.2.2.cmml">𝒳</mi><mtext id="S7.SS2.p1.3.m3.1.1.3.2.3" xref="S7.SS2.p1.3.m3.1.1.3.2.3a.cmml">quasi</mtext></msub><mo stretchy="false" id="S7.SS2.p1.3.m3.1.1.3.1" xref="S7.SS2.p1.3.m3.1.1.3.1.cmml">→</mo><msub id="S7.SS2.p1.3.m3.1.1.3.3" xref="S7.SS2.p1.3.m3.1.1.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S7.SS2.p1.3.m3.1.1.3.3.2" xref="S7.SS2.p1.3.m3.1.1.3.3.2.cmml">𝒳</mi><mtext id="S7.SS2.p1.3.m3.1.1.3.3.3" xref="S7.SS2.p1.3.m3.1.1.3.3.3a.cmml">sensitive</mtext></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S7.SS2.p1.3.m3.1b"><apply id="S7.SS2.p1.3.m3.1.1.cmml" xref="S7.SS2.p1.3.m3.1.1"><ci id="S7.SS2.p1.3.m3.1.1.1.cmml" xref="S7.SS2.p1.3.m3.1.1.1">:</ci><ci id="S7.SS2.p1.3.m3.1.1.2.cmml" xref="S7.SS2.p1.3.m3.1.1.2">𝑓</ci><apply id="S7.SS2.p1.3.m3.1.1.3.cmml" xref="S7.SS2.p1.3.m3.1.1.3"><ci id="S7.SS2.p1.3.m3.1.1.3.1.cmml" xref="S7.SS2.p1.3.m3.1.1.3.1">→</ci><apply id="S7.SS2.p1.3.m3.1.1.3.2.cmml" xref="S7.SS2.p1.3.m3.1.1.3.2"><csymbol cd="ambiguous" id="S7.SS2.p1.3.m3.1.1.3.2.1.cmml" xref="S7.SS2.p1.3.m3.1.1.3.2">subscript</csymbol><ci id="S7.SS2.p1.3.m3.1.1.3.2.2.cmml" xref="S7.SS2.p1.3.m3.1.1.3.2.2">𝒳</ci><ci id="S7.SS2.p1.3.m3.1.1.3.2.3a.cmml" xref="S7.SS2.p1.3.m3.1.1.3.2.3"><mtext mathsize="70%" id="S7.SS2.p1.3.m3.1.1.3.2.3.cmml" xref="S7.SS2.p1.3.m3.1.1.3.2.3">quasi</mtext></ci></apply><apply id="S7.SS2.p1.3.m3.1.1.3.3.cmml" xref="S7.SS2.p1.3.m3.1.1.3.3"><csymbol cd="ambiguous" id="S7.SS2.p1.3.m3.1.1.3.3.1.cmml" xref="S7.SS2.p1.3.m3.1.1.3.3">subscript</csymbol><ci id="S7.SS2.p1.3.m3.1.1.3.3.2.cmml" xref="S7.SS2.p1.3.m3.1.1.3.3.2">𝒳</ci><ci id="S7.SS2.p1.3.m3.1.1.3.3.3a.cmml" xref="S7.SS2.p1.3.m3.1.1.3.3.3"><mtext mathsize="70%" id="S7.SS2.p1.3.m3.1.1.3.3.3.cmml" xref="S7.SS2.p1.3.m3.1.1.3.3.3">sensitive</mtext></ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS2.p1.3.m3.1c">f:\mathcal{X}_{\text{quasi}}\rightarrow\mathcal{X}_{\text{sensitive}}</annotation></semantics></math> on the quasi-identifiers to predict the value of the sensitive attribute, then replacing the sensitive attributes of the data by values produced by the statistical model, a process known as multiple imputation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib126" title="" class="ltx_ref">126</a>]</cite>.
The synthetic data generated thus contains the quasi-identifiers of all real records.
Researchers have proposed partially SDG models using decision trees, support vector machines, and random forests <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib127" title="" class="ltx_ref">127</a>, <a href="#bib.bib128" title="" class="ltx_ref">128</a>]</cite> (see the <span id="S7.SS2.p1.3.5" class="ltx_text ltx_font_sansserif">synthpop</span> package <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib129" title="" class="ltx_ref">129</a>]</cite>).</p>
</div>
<div id="S7.SS2.p2" class="ltx_para">
<p id="S7.SS2.p2.2" class="ltx_p">Utility-wise, partially synthetic data have a clear advantage over <span id="S7.SS2.p2.2.1" class="ltx_text ltx_font_italic">fully</span> synthetic data, as they not require to estimate the full joint distribution <math id="S7.SS2.p2.1.m1.1" class="ltx_Math" alttext="\mathbb{P}(\mathcal{X})" display="inline"><semantics id="S7.SS2.p2.1.m1.1a"><mrow id="S7.SS2.p2.1.m1.1.2" xref="S7.SS2.p2.1.m1.1.2.cmml"><mi id="S7.SS2.p2.1.m1.1.2.2" xref="S7.SS2.p2.1.m1.1.2.2.cmml">ℙ</mi><mo lspace="0em" rspace="0em" id="S7.SS2.p2.1.m1.1.2.1" xref="S7.SS2.p2.1.m1.1.2.1.cmml">​</mo><mrow id="S7.SS2.p2.1.m1.1.2.3.2" xref="S7.SS2.p2.1.m1.1.2.cmml"><mo stretchy="false" id="S7.SS2.p2.1.m1.1.2.3.2.1" xref="S7.SS2.p2.1.m1.1.2.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S7.SS2.p2.1.m1.1.1" xref="S7.SS2.p2.1.m1.1.1.cmml">𝒳</mi><mo stretchy="false" id="S7.SS2.p2.1.m1.1.2.3.2.2" xref="S7.SS2.p2.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S7.SS2.p2.1.m1.1b"><apply id="S7.SS2.p2.1.m1.1.2.cmml" xref="S7.SS2.p2.1.m1.1.2"><times id="S7.SS2.p2.1.m1.1.2.1.cmml" xref="S7.SS2.p2.1.m1.1.2.1"></times><ci id="S7.SS2.p2.1.m1.1.2.2.cmml" xref="S7.SS2.p2.1.m1.1.2.2">ℙ</ci><ci id="S7.SS2.p2.1.m1.1.1.cmml" xref="S7.SS2.p2.1.m1.1.1">𝒳</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS2.p2.1.m1.1c">\mathbb{P}(\mathcal{X})</annotation></semantics></math> but only the conditional distribution <math id="S7.SS2.p2.2.m2.1" class="ltx_Math" alttext="\mathbb{P}(\mathcal{X}_{\text{sensitive}}|\mathcal{X}_{\text{quasi}})" display="inline"><semantics id="S7.SS2.p2.2.m2.1a"><mrow id="S7.SS2.p2.2.m2.1.1" xref="S7.SS2.p2.2.m2.1.1.cmml"><mi id="S7.SS2.p2.2.m2.1.1.3" xref="S7.SS2.p2.2.m2.1.1.3.cmml">ℙ</mi><mo lspace="0em" rspace="0em" id="S7.SS2.p2.2.m2.1.1.2" xref="S7.SS2.p2.2.m2.1.1.2.cmml">​</mo><mrow id="S7.SS2.p2.2.m2.1.1.1.1" xref="S7.SS2.p2.2.m2.1.1.1.1.1.cmml"><mo stretchy="false" id="S7.SS2.p2.2.m2.1.1.1.1.2" xref="S7.SS2.p2.2.m2.1.1.1.1.1.cmml">(</mo><mrow id="S7.SS2.p2.2.m2.1.1.1.1.1" xref="S7.SS2.p2.2.m2.1.1.1.1.1.cmml"><msub id="S7.SS2.p2.2.m2.1.1.1.1.1.2" xref="S7.SS2.p2.2.m2.1.1.1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S7.SS2.p2.2.m2.1.1.1.1.1.2.2" xref="S7.SS2.p2.2.m2.1.1.1.1.1.2.2.cmml">𝒳</mi><mtext id="S7.SS2.p2.2.m2.1.1.1.1.1.2.3" xref="S7.SS2.p2.2.m2.1.1.1.1.1.2.3a.cmml">sensitive</mtext></msub><mo fence="false" id="S7.SS2.p2.2.m2.1.1.1.1.1.1" xref="S7.SS2.p2.2.m2.1.1.1.1.1.1.cmml">|</mo><msub id="S7.SS2.p2.2.m2.1.1.1.1.1.3" xref="S7.SS2.p2.2.m2.1.1.1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S7.SS2.p2.2.m2.1.1.1.1.1.3.2" xref="S7.SS2.p2.2.m2.1.1.1.1.1.3.2.cmml">𝒳</mi><mtext id="S7.SS2.p2.2.m2.1.1.1.1.1.3.3" xref="S7.SS2.p2.2.m2.1.1.1.1.1.3.3a.cmml">quasi</mtext></msub></mrow><mo stretchy="false" id="S7.SS2.p2.2.m2.1.1.1.1.3" xref="S7.SS2.p2.2.m2.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S7.SS2.p2.2.m2.1b"><apply id="S7.SS2.p2.2.m2.1.1.cmml" xref="S7.SS2.p2.2.m2.1.1"><times id="S7.SS2.p2.2.m2.1.1.2.cmml" xref="S7.SS2.p2.2.m2.1.1.2"></times><ci id="S7.SS2.p2.2.m2.1.1.3.cmml" xref="S7.SS2.p2.2.m2.1.1.3">ℙ</ci><apply id="S7.SS2.p2.2.m2.1.1.1.1.1.cmml" xref="S7.SS2.p2.2.m2.1.1.1.1"><csymbol cd="latexml" id="S7.SS2.p2.2.m2.1.1.1.1.1.1.cmml" xref="S7.SS2.p2.2.m2.1.1.1.1.1.1">conditional</csymbol><apply id="S7.SS2.p2.2.m2.1.1.1.1.1.2.cmml" xref="S7.SS2.p2.2.m2.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S7.SS2.p2.2.m2.1.1.1.1.1.2.1.cmml" xref="S7.SS2.p2.2.m2.1.1.1.1.1.2">subscript</csymbol><ci id="S7.SS2.p2.2.m2.1.1.1.1.1.2.2.cmml" xref="S7.SS2.p2.2.m2.1.1.1.1.1.2.2">𝒳</ci><ci id="S7.SS2.p2.2.m2.1.1.1.1.1.2.3a.cmml" xref="S7.SS2.p2.2.m2.1.1.1.1.1.2.3"><mtext mathsize="70%" id="S7.SS2.p2.2.m2.1.1.1.1.1.2.3.cmml" xref="S7.SS2.p2.2.m2.1.1.1.1.1.2.3">sensitive</mtext></ci></apply><apply id="S7.SS2.p2.2.m2.1.1.1.1.1.3.cmml" xref="S7.SS2.p2.2.m2.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S7.SS2.p2.2.m2.1.1.1.1.1.3.1.cmml" xref="S7.SS2.p2.2.m2.1.1.1.1.1.3">subscript</csymbol><ci id="S7.SS2.p2.2.m2.1.1.1.1.1.3.2.cmml" xref="S7.SS2.p2.2.m2.1.1.1.1.1.3.2">𝒳</ci><ci id="S7.SS2.p2.2.m2.1.1.1.1.1.3.3a.cmml" xref="S7.SS2.p2.2.m2.1.1.1.1.1.3.3"><mtext mathsize="70%" id="S7.SS2.p2.2.m2.1.1.1.1.1.3.3.cmml" xref="S7.SS2.p2.2.m2.1.1.1.1.1.3.3">quasi</mtext></ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS2.p2.2.m2.1c">\mathbb{P}(\mathcal{X}_{\text{sensitive}}|\mathcal{X}_{\text{quasi}})</annotation></semantics></math>.
However, some reports suggest that the utility of such data in practice is not particularly appealing, and that they are probably best suited for preliminary data analyses <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib130" title="" class="ltx_ref">130</a>]</cite>, or when combined with restricted access to confidential data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib131" title="" class="ltx_ref">131</a>]</cite>.</p>
</div>
<div id="S7.SS2.p3" class="ltx_para">
<p id="S7.SS2.p3.1" class="ltx_p">Privacy-wise, there is the issue that revealing quasi-identifiers might be considered sensitive in some contexts (and this approach is trivially vulnerable to membership inference attacks).
Researchers have shown that current methods are vulnerable to record linkage attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib132" title="" class="ltx_ref">132</a>, <a href="#bib.bib133" title="" class="ltx_ref">133</a>]</cite>, where an attacker identifies which record belongs to a target user using the sensitive attributes.
Partially synthetic data generation methods are generally heuristic methods, and do not satisfy guarantees of privacy.
Label DP <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib134" title="" class="ltx_ref">134</a>]</cite> is an extension of differential privacy that fits this context well.</p>
</div>
</section>
</section>
<section id="S8" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8 </span>De-biased Synthetic Data Generation</h2>

<div id="S8.p1" class="ltx_para">
<p id="S8.p1.1" class="ltx_p">Machine learning models are known to inherit biases from their training data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib135" title="" class="ltx_ref">135</a>, <a href="#bib.bib136" title="" class="ltx_ref">136</a>, <a href="#bib.bib137" title="" class="ltx_ref">137</a>, <a href="#bib.bib138" title="" class="ltx_ref">138</a>]</cite>. De-biasing trained models requires expert knowledge of the model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib139" title="" class="ltx_ref">139</a>, <a href="#bib.bib140" title="" class="ltx_ref">140</a>]</cite>, and also an understanding of the different notions of fairness that one may wish to achieve (e.g. fairness through unawareness, demographic parity, conditional fairness <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>). An alternative approach that is being explored is to learn to de-bias the dataset itself, thus creating so-called <span id="S8.p1.1.1" class="ltx_text ltx_font_italic">fair data<cite class="ltx_cite ltx_citemacro_cite"><span id="S8.p1.1.1.1.1" class="ltx_text ltx_font_upright">[</span><a href="#bib.bib18" title="" class="ltx_ref">18</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a><span id="S8.p1.1.1.2.2" class="ltx_text ltx_font_upright">]</span></cite></span>.</p>
</div>
<div id="S8.p2" class="ltx_para">
<p id="S8.p2.1" class="ltx_p">This data de-biasing can be viewed as a sort of synthetic data generation, in which the synthetic data is the de-biased data. Some approaches take it a step further and explicitly model the problem of data de-biasing as a one of “ground-up” generation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>, <a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>. These approaches aim to learn a generative model that itself is fair. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>, they explore several notions of fairness and, via causal modelling, identify strategies for generating data that satisfy the given notions.</p>
</div>
<section id="S8.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">8.1 </span>Notions of Fairness</h3>

<div id="S8.SS1.p1" class="ltx_para">
<p id="S8.SS1.p1.1" class="ltx_p">As we have seen, identifying a meaningful, interpretable notion of privacy is difficult, and the same is true for fairness. These are both complex ethical questions that the machine learning community must address sooner rather than later. Unlike privacy, however, obvious notions of fairness <span id="S8.SS1.p1.1.1" class="ltx_text ltx_font_italic">do exist</span>, and are enforceable in a meaningful way<span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>This contrasts with the fact that, with privacy, the notion of not wanting your data to affect the output <span id="footnote4.1" class="ltx_text ltx_font_italic">at all</span> is not achievable without simply ignoring your data completely.</span></span></span>. Each notion typically requires some notion of a set of <span id="S8.SS1.p1.1.2" class="ltx_text ltx_font_italic">protected attributes</span>, along which fairness must be ensured (e.g. gender, race).</p>
</div>
<div id="S8.SS1.p2" class="ltx_para">
<p id="S8.SS1.p2.1" class="ltx_p"><span id="S8.SS1.p2.1.1" class="ltx_text ltx_font_bold">Fairness Through Unawareness (FTU)</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib141" title="" class="ltx_ref">141</a>, <a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> requires that the protected attributes, and only the protected attributes, not be used by the predictor. This aligns with the idea that two equally qualified people deserve the same job opportunities, independent of race or gender <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>. FTU, however, fails to take into account the effect that protected attributes might have on other unprotected attributes, such as an individual’s race resulting in them not being afforded the same educational opportunities as an individual of a different race (and thus resulting in them appearing to be disparately qualified).</p>
</div>
<div id="Thmdefinition3" class="ltx_theorem ltx_theorem_definition">
<h6 class="ltx_title ltx_runin ltx_title_theorem">
<span class="ltx_tag ltx_tag_theorem"><span id="Thmdefinition3.1.1.1" class="ltx_text ltx_font_bold">Definition 3</span></span><span id="Thmdefinition3.2.2" class="ltx_text ltx_font_bold"> (Fairness Through Unawareness <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>)</span>
</h6>
<div id="Thmdefinition3.p1" class="ltx_para">
<p id="Thmdefinition3.p1.4" class="ltx_p"><span id="Thmdefinition3.p1.4.4" class="ltx_text ltx_font_italic">A predictor <math id="Thmdefinition3.p1.1.1.m1.1" class="ltx_Math" alttext="f:\mathcal{X}\to\mathcal{Y}" display="inline"><semantics id="Thmdefinition3.p1.1.1.m1.1a"><mrow id="Thmdefinition3.p1.1.1.m1.1.1" xref="Thmdefinition3.p1.1.1.m1.1.1.cmml"><mi id="Thmdefinition3.p1.1.1.m1.1.1.2" xref="Thmdefinition3.p1.1.1.m1.1.1.2.cmml">f</mi><mo lspace="0.278em" rspace="0.278em" id="Thmdefinition3.p1.1.1.m1.1.1.1" xref="Thmdefinition3.p1.1.1.m1.1.1.1.cmml">:</mo><mrow id="Thmdefinition3.p1.1.1.m1.1.1.3" xref="Thmdefinition3.p1.1.1.m1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="Thmdefinition3.p1.1.1.m1.1.1.3.2" xref="Thmdefinition3.p1.1.1.m1.1.1.3.2.cmml">𝒳</mi><mo stretchy="false" id="Thmdefinition3.p1.1.1.m1.1.1.3.1" xref="Thmdefinition3.p1.1.1.m1.1.1.3.1.cmml">→</mo><mi class="ltx_font_mathcaligraphic" id="Thmdefinition3.p1.1.1.m1.1.1.3.3" xref="Thmdefinition3.p1.1.1.m1.1.1.3.3.cmml">𝒴</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="Thmdefinition3.p1.1.1.m1.1b"><apply id="Thmdefinition3.p1.1.1.m1.1.1.cmml" xref="Thmdefinition3.p1.1.1.m1.1.1"><ci id="Thmdefinition3.p1.1.1.m1.1.1.1.cmml" xref="Thmdefinition3.p1.1.1.m1.1.1.1">:</ci><ci id="Thmdefinition3.p1.1.1.m1.1.1.2.cmml" xref="Thmdefinition3.p1.1.1.m1.1.1.2">𝑓</ci><apply id="Thmdefinition3.p1.1.1.m1.1.1.3.cmml" xref="Thmdefinition3.p1.1.1.m1.1.1.3"><ci id="Thmdefinition3.p1.1.1.m1.1.1.3.1.cmml" xref="Thmdefinition3.p1.1.1.m1.1.1.3.1">→</ci><ci id="Thmdefinition3.p1.1.1.m1.1.1.3.2.cmml" xref="Thmdefinition3.p1.1.1.m1.1.1.3.2">𝒳</ci><ci id="Thmdefinition3.p1.1.1.m1.1.1.3.3.cmml" xref="Thmdefinition3.p1.1.1.m1.1.1.3.3">𝒴</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition3.p1.1.1.m1.1c">f:\mathcal{X}\to\mathcal{Y}</annotation></semantics></math> is fair if and only if protected attributes <math id="Thmdefinition3.p1.2.2.m2.1" class="ltx_Math" alttext="\mathcal{A}\subset\mathcal{X}" display="inline"><semantics id="Thmdefinition3.p1.2.2.m2.1a"><mrow id="Thmdefinition3.p1.2.2.m2.1.1" xref="Thmdefinition3.p1.2.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="Thmdefinition3.p1.2.2.m2.1.1.2" xref="Thmdefinition3.p1.2.2.m2.1.1.2.cmml">𝒜</mi><mo id="Thmdefinition3.p1.2.2.m2.1.1.1" xref="Thmdefinition3.p1.2.2.m2.1.1.1.cmml">⊂</mo><mi class="ltx_font_mathcaligraphic" id="Thmdefinition3.p1.2.2.m2.1.1.3" xref="Thmdefinition3.p1.2.2.m2.1.1.3.cmml">𝒳</mi></mrow><annotation-xml encoding="MathML-Content" id="Thmdefinition3.p1.2.2.m2.1b"><apply id="Thmdefinition3.p1.2.2.m2.1.1.cmml" xref="Thmdefinition3.p1.2.2.m2.1.1"><subset id="Thmdefinition3.p1.2.2.m2.1.1.1.cmml" xref="Thmdefinition3.p1.2.2.m2.1.1.1"></subset><ci id="Thmdefinition3.p1.2.2.m2.1.1.2.cmml" xref="Thmdefinition3.p1.2.2.m2.1.1.2">𝒜</ci><ci id="Thmdefinition3.p1.2.2.m2.1.1.3.cmml" xref="Thmdefinition3.p1.2.2.m2.1.1.3">𝒳</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition3.p1.2.2.m2.1c">\mathcal{A}\subset\mathcal{X}</annotation></semantics></math> are not explicitly used by <math id="Thmdefinition3.p1.3.3.m3.1" class="ltx_Math" alttext="f" display="inline"><semantics id="Thmdefinition3.p1.3.3.m3.1a"><mi id="Thmdefinition3.p1.3.3.m3.1.1" xref="Thmdefinition3.p1.3.3.m3.1.1.cmml">f</mi><annotation-xml encoding="MathML-Content" id="Thmdefinition3.p1.3.3.m3.1b"><ci id="Thmdefinition3.p1.3.3.m3.1.1.cmml" xref="Thmdefinition3.p1.3.3.m3.1.1">𝑓</ci></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition3.p1.3.3.m3.1c">f</annotation></semantics></math> to predict <math id="Thmdefinition3.p1.4.4.m4.1" class="ltx_Math" alttext="Y\in\mathcal{Y}" display="inline"><semantics id="Thmdefinition3.p1.4.4.m4.1a"><mrow id="Thmdefinition3.p1.4.4.m4.1.1" xref="Thmdefinition3.p1.4.4.m4.1.1.cmml"><mi id="Thmdefinition3.p1.4.4.m4.1.1.2" xref="Thmdefinition3.p1.4.4.m4.1.1.2.cmml">Y</mi><mo id="Thmdefinition3.p1.4.4.m4.1.1.1" xref="Thmdefinition3.p1.4.4.m4.1.1.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="Thmdefinition3.p1.4.4.m4.1.1.3" xref="Thmdefinition3.p1.4.4.m4.1.1.3.cmml">𝒴</mi></mrow><annotation-xml encoding="MathML-Content" id="Thmdefinition3.p1.4.4.m4.1b"><apply id="Thmdefinition3.p1.4.4.m4.1.1.cmml" xref="Thmdefinition3.p1.4.4.m4.1.1"><in id="Thmdefinition3.p1.4.4.m4.1.1.1.cmml" xref="Thmdefinition3.p1.4.4.m4.1.1.1"></in><ci id="Thmdefinition3.p1.4.4.m4.1.1.2.cmml" xref="Thmdefinition3.p1.4.4.m4.1.1.2">𝑌</ci><ci id="Thmdefinition3.p1.4.4.m4.1.1.3.cmml" xref="Thmdefinition3.p1.4.4.m4.1.1.3">𝒴</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition3.p1.4.4.m4.1c">Y\in\mathcal{Y}</annotation></semantics></math>.</span></p>
</div>
</div>
<div id="S8.SS1.p3" class="ltx_para">
<p id="S8.SS1.p3.1" class="ltx_p"><span id="S8.SS1.p3.1.1" class="ltx_text ltx_font_bold">Demographic Parity (DPa)</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib142" title="" class="ltx_ref">142</a>]</cite>, instead, requires that a predictors output’s not be correlated with the protected attributes. Indeed, with FTU, an attribute that is correlated with the protected attributes can be used as input to a predictor and thus the predictor can indirectly be correlated with the protected attributes (despite not having direct access to them). DPa is a significantly stronger notion of fairness than FTU, which requires adjusting the distributions of <span id="S8.SS1.p3.1.2" class="ltx_text ltx_font_italic">all</span> variables that are correlated with the protected attributes.</p>
</div>
<div id="Thmdefinition4" class="ltx_theorem ltx_theorem_definition">
<h6 class="ltx_title ltx_runin ltx_title_theorem">
<span class="ltx_tag ltx_tag_theorem"><span id="Thmdefinition4.1.1.1" class="ltx_text ltx_font_bold">Definition 4</span></span><span id="Thmdefinition4.2.2" class="ltx_text ltx_font_bold"> (Demographic Parity <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>)</span>
</h6>
<div id="Thmdefinition4.p1" class="ltx_para">
<p id="Thmdefinition4.p1.8" class="ltx_p"><span id="Thmdefinition4.p1.8.8" class="ltx_text ltx_font_italic">A predictor <math id="Thmdefinition4.p1.1.1.m1.1" class="ltx_Math" alttext="f:\mathcal{X}\to\mathcal{Y}" display="inline"><semantics id="Thmdefinition4.p1.1.1.m1.1a"><mrow id="Thmdefinition4.p1.1.1.m1.1.1" xref="Thmdefinition4.p1.1.1.m1.1.1.cmml"><mi id="Thmdefinition4.p1.1.1.m1.1.1.2" xref="Thmdefinition4.p1.1.1.m1.1.1.2.cmml">f</mi><mo lspace="0.278em" rspace="0.278em" id="Thmdefinition4.p1.1.1.m1.1.1.1" xref="Thmdefinition4.p1.1.1.m1.1.1.1.cmml">:</mo><mrow id="Thmdefinition4.p1.1.1.m1.1.1.3" xref="Thmdefinition4.p1.1.1.m1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="Thmdefinition4.p1.1.1.m1.1.1.3.2" xref="Thmdefinition4.p1.1.1.m1.1.1.3.2.cmml">𝒳</mi><mo stretchy="false" id="Thmdefinition4.p1.1.1.m1.1.1.3.1" xref="Thmdefinition4.p1.1.1.m1.1.1.3.1.cmml">→</mo><mi class="ltx_font_mathcaligraphic" id="Thmdefinition4.p1.1.1.m1.1.1.3.3" xref="Thmdefinition4.p1.1.1.m1.1.1.3.3.cmml">𝒴</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="Thmdefinition4.p1.1.1.m1.1b"><apply id="Thmdefinition4.p1.1.1.m1.1.1.cmml" xref="Thmdefinition4.p1.1.1.m1.1.1"><ci id="Thmdefinition4.p1.1.1.m1.1.1.1.cmml" xref="Thmdefinition4.p1.1.1.m1.1.1.1">:</ci><ci id="Thmdefinition4.p1.1.1.m1.1.1.2.cmml" xref="Thmdefinition4.p1.1.1.m1.1.1.2">𝑓</ci><apply id="Thmdefinition4.p1.1.1.m1.1.1.3.cmml" xref="Thmdefinition4.p1.1.1.m1.1.1.3"><ci id="Thmdefinition4.p1.1.1.m1.1.1.3.1.cmml" xref="Thmdefinition4.p1.1.1.m1.1.1.3.1">→</ci><ci id="Thmdefinition4.p1.1.1.m1.1.1.3.2.cmml" xref="Thmdefinition4.p1.1.1.m1.1.1.3.2">𝒳</ci><ci id="Thmdefinition4.p1.1.1.m1.1.1.3.3.cmml" xref="Thmdefinition4.p1.1.1.m1.1.1.3.3">𝒴</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition4.p1.1.1.m1.1c">f:\mathcal{X}\to\mathcal{Y}</annotation></semantics></math> is fair if and only if protected attributes <math id="Thmdefinition4.p1.2.2.m2.1" class="ltx_Math" alttext="\mathcal{A}\subset\mathcal{X}" display="inline"><semantics id="Thmdefinition4.p1.2.2.m2.1a"><mrow id="Thmdefinition4.p1.2.2.m2.1.1" xref="Thmdefinition4.p1.2.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="Thmdefinition4.p1.2.2.m2.1.1.2" xref="Thmdefinition4.p1.2.2.m2.1.1.2.cmml">𝒜</mi><mo id="Thmdefinition4.p1.2.2.m2.1.1.1" xref="Thmdefinition4.p1.2.2.m2.1.1.1.cmml">⊂</mo><mi class="ltx_font_mathcaligraphic" id="Thmdefinition4.p1.2.2.m2.1.1.3" xref="Thmdefinition4.p1.2.2.m2.1.1.3.cmml">𝒳</mi></mrow><annotation-xml encoding="MathML-Content" id="Thmdefinition4.p1.2.2.m2.1b"><apply id="Thmdefinition4.p1.2.2.m2.1.1.cmml" xref="Thmdefinition4.p1.2.2.m2.1.1"><subset id="Thmdefinition4.p1.2.2.m2.1.1.1.cmml" xref="Thmdefinition4.p1.2.2.m2.1.1.1"></subset><ci id="Thmdefinition4.p1.2.2.m2.1.1.2.cmml" xref="Thmdefinition4.p1.2.2.m2.1.1.2">𝒜</ci><ci id="Thmdefinition4.p1.2.2.m2.1.1.3.cmml" xref="Thmdefinition4.p1.2.2.m2.1.1.3">𝒳</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition4.p1.2.2.m2.1c">\mathcal{A}\subset\mathcal{X}</annotation></semantics></math> are independent of the predictions. That is, given a random variable <math id="Thmdefinition4.p1.3.3.m3.1" class="ltx_Math" alttext="X\in\mathcal{X}" display="inline"><semantics id="Thmdefinition4.p1.3.3.m3.1a"><mrow id="Thmdefinition4.p1.3.3.m3.1.1" xref="Thmdefinition4.p1.3.3.m3.1.1.cmml"><mi id="Thmdefinition4.p1.3.3.m3.1.1.2" xref="Thmdefinition4.p1.3.3.m3.1.1.2.cmml">X</mi><mo id="Thmdefinition4.p1.3.3.m3.1.1.1" xref="Thmdefinition4.p1.3.3.m3.1.1.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="Thmdefinition4.p1.3.3.m3.1.1.3" xref="Thmdefinition4.p1.3.3.m3.1.1.3.cmml">𝒳</mi></mrow><annotation-xml encoding="MathML-Content" id="Thmdefinition4.p1.3.3.m3.1b"><apply id="Thmdefinition4.p1.3.3.m3.1.1.cmml" xref="Thmdefinition4.p1.3.3.m3.1.1"><in id="Thmdefinition4.p1.3.3.m3.1.1.1.cmml" xref="Thmdefinition4.p1.3.3.m3.1.1.1"></in><ci id="Thmdefinition4.p1.3.3.m3.1.1.2.cmml" xref="Thmdefinition4.p1.3.3.m3.1.1.2">𝑋</ci><ci id="Thmdefinition4.p1.3.3.m3.1.1.3.cmml" xref="Thmdefinition4.p1.3.3.m3.1.1.3">𝒳</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition4.p1.3.3.m3.1c">X\in\mathcal{X}</annotation></semantics></math>, let <math id="Thmdefinition4.p1.4.4.m4.1" class="ltx_Math" alttext="A\in\mathcal{A}" display="inline"><semantics id="Thmdefinition4.p1.4.4.m4.1a"><mrow id="Thmdefinition4.p1.4.4.m4.1.1" xref="Thmdefinition4.p1.4.4.m4.1.1.cmml"><mi id="Thmdefinition4.p1.4.4.m4.1.1.2" xref="Thmdefinition4.p1.4.4.m4.1.1.2.cmml">A</mi><mo id="Thmdefinition4.p1.4.4.m4.1.1.1" xref="Thmdefinition4.p1.4.4.m4.1.1.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="Thmdefinition4.p1.4.4.m4.1.1.3" xref="Thmdefinition4.p1.4.4.m4.1.1.3.cmml">𝒜</mi></mrow><annotation-xml encoding="MathML-Content" id="Thmdefinition4.p1.4.4.m4.1b"><apply id="Thmdefinition4.p1.4.4.m4.1.1.cmml" xref="Thmdefinition4.p1.4.4.m4.1.1"><in id="Thmdefinition4.p1.4.4.m4.1.1.1.cmml" xref="Thmdefinition4.p1.4.4.m4.1.1.1"></in><ci id="Thmdefinition4.p1.4.4.m4.1.1.2.cmml" xref="Thmdefinition4.p1.4.4.m4.1.1.2">𝐴</ci><ci id="Thmdefinition4.p1.4.4.m4.1.1.3.cmml" xref="Thmdefinition4.p1.4.4.m4.1.1.3">𝒜</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition4.p1.4.4.m4.1c">A\in\mathcal{A}</annotation></semantics></math> be the components of <math id="Thmdefinition4.p1.5.5.m5.1" class="ltx_Math" alttext="X" display="inline"><semantics id="Thmdefinition4.p1.5.5.m5.1a"><mi id="Thmdefinition4.p1.5.5.m5.1.1" xref="Thmdefinition4.p1.5.5.m5.1.1.cmml">X</mi><annotation-xml encoding="MathML-Content" id="Thmdefinition4.p1.5.5.m5.1b"><ci id="Thmdefinition4.p1.5.5.m5.1.1.cmml" xref="Thmdefinition4.p1.5.5.m5.1.1">𝑋</ci></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition4.p1.5.5.m5.1c">X</annotation></semantics></math> that are protected. Then <math id="Thmdefinition4.p1.6.6.m6.1" class="ltx_Math" alttext="f" display="inline"><semantics id="Thmdefinition4.p1.6.6.m6.1a"><mi id="Thmdefinition4.p1.6.6.m6.1.1" xref="Thmdefinition4.p1.6.6.m6.1.1.cmml">f</mi><annotation-xml encoding="MathML-Content" id="Thmdefinition4.p1.6.6.m6.1b"><ci id="Thmdefinition4.p1.6.6.m6.1.1.cmml" xref="Thmdefinition4.p1.6.6.m6.1.1">𝑓</ci></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition4.p1.6.6.m6.1c">f</annotation></semantics></math> satisfies demographic parity if and only if <math id="Thmdefinition4.p1.7.7.m7.1" class="ltx_Math" alttext="f(X)" display="inline"><semantics id="Thmdefinition4.p1.7.7.m7.1a"><mrow id="Thmdefinition4.p1.7.7.m7.1.2" xref="Thmdefinition4.p1.7.7.m7.1.2.cmml"><mi id="Thmdefinition4.p1.7.7.m7.1.2.2" xref="Thmdefinition4.p1.7.7.m7.1.2.2.cmml">f</mi><mo lspace="0em" rspace="0em" id="Thmdefinition4.p1.7.7.m7.1.2.1" xref="Thmdefinition4.p1.7.7.m7.1.2.1.cmml">​</mo><mrow id="Thmdefinition4.p1.7.7.m7.1.2.3.2" xref="Thmdefinition4.p1.7.7.m7.1.2.cmml"><mo stretchy="false" id="Thmdefinition4.p1.7.7.m7.1.2.3.2.1" xref="Thmdefinition4.p1.7.7.m7.1.2.cmml">(</mo><mi id="Thmdefinition4.p1.7.7.m7.1.1" xref="Thmdefinition4.p1.7.7.m7.1.1.cmml">X</mi><mo stretchy="false" id="Thmdefinition4.p1.7.7.m7.1.2.3.2.2" xref="Thmdefinition4.p1.7.7.m7.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="Thmdefinition4.p1.7.7.m7.1b"><apply id="Thmdefinition4.p1.7.7.m7.1.2.cmml" xref="Thmdefinition4.p1.7.7.m7.1.2"><times id="Thmdefinition4.p1.7.7.m7.1.2.1.cmml" xref="Thmdefinition4.p1.7.7.m7.1.2.1"></times><ci id="Thmdefinition4.p1.7.7.m7.1.2.2.cmml" xref="Thmdefinition4.p1.7.7.m7.1.2.2">𝑓</ci><ci id="Thmdefinition4.p1.7.7.m7.1.1.cmml" xref="Thmdefinition4.p1.7.7.m7.1.1">𝑋</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition4.p1.7.7.m7.1c">f(X)</annotation></semantics></math> is independent of <math id="Thmdefinition4.p1.8.8.m8.1" class="ltx_Math" alttext="A" display="inline"><semantics id="Thmdefinition4.p1.8.8.m8.1a"><mi id="Thmdefinition4.p1.8.8.m8.1.1" xref="Thmdefinition4.p1.8.8.m8.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="Thmdefinition4.p1.8.8.m8.1b"><ci id="Thmdefinition4.p1.8.8.m8.1.1.cmml" xref="Thmdefinition4.p1.8.8.m8.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition4.p1.8.8.m8.1c">A</annotation></semantics></math>.</span></p>
</div>
</div>
<div id="S8.SS1.p4" class="ltx_para">
<p id="S8.SS1.p4.1" class="ltx_p">Under the graphical model approach used in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>, for example, DPa is ensured by deleting all edges that originate from a variable that has a protected attribute anywhere in its causal predecessors. Naturally, such an approach can significantly degrade performance, as many of these variables can be useful predictors of the target. A trade-off is present, in which some fairness may need to be sacrificed for performance, and vice-versa.</p>
</div>
</section>
<section id="S8.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">8.2 </span>Limitations of Fair Synthetic Data Generation</h3>

<div id="S8.SS2.p1" class="ltx_para">
<p id="S8.SS2.p1.1" class="ltx_p">Though one might hope that fair synthetic data would lead directly to fair predictors (which <span id="S8.SS2.p1.1.1" class="ltx_text ltx_font_italic">is</span> the case with private synthetic data and private predictors), this is not the case. Of particular importance to note is the fact that a predictor’s fairness is <span id="S8.SS2.p1.1.2" class="ltx_text ltx_font_italic">with respect to</span> a distribution of the features. Indeed, a predictor that is trained on synthetic data may not longer be fair when moved to real data due to a shift in the distribution of the real features. This is partly the reason that <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> take such an extreme approach in removing all contaminated features (rather than trying to only remove the influence of the protected attributes on contaminated unprotected ones).</p>
</div>
<div id="S8.SS2.p2" class="ltx_para">
<p id="S8.SS2.p2.1" class="ltx_p">Moreover, a synthetic dataset’s fairness is defined through a given predictor. Giving a more general definition for fair synthetic data, and determining whether or not predictors trained on such a synthetic dataset would be fair, are open problems. The hope that an organisation might make a single “fair” synthetic dataset for use across an organisation would require advancements in this space, requiring a shift in thinking from fair predictors to fair data.</p>
</div>
</section>
<section id="S8.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">8.3 </span>Existing Methods</h3>

<div id="S8.SS3.p1" class="ltx_para">
<p id="S8.SS3.p1.1" class="ltx_p">As noted above, fair synthetic data generation is a young field. While there is significant amounts of work on creating fair predictors (see e.g. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib143" title="" class="ltx_ref">143</a>]</cite> for a recent survey), the work on synthetic data for fairness is more limited.</p>
</div>
<div id="S8.SS3.p2" class="ltx_para">
<p id="S8.SS3.p2.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> take a causal, GAN-based approach, using several GAN networks, along with an assumed known causal graph to learn the generative process of the data. Armed with the causal graph, they then generate synthetic data by selectively dropping edges from the model depending on the notion of fairness being targeted.</p>
</div>
<div id="S8.SS3.p3" class="ltx_para">
<p id="S8.SS3.p3.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> use a more indirect approach to ensuring fairness. Again based on a GAN model, they instead opt to introduce an additional loss term that penalises disparity between protected attributes taking different values. This means that the learned model might still generate unfair data, but only if doing so results in an increase in the fidelity of the generated synthetic data. This trade-off is controlled by a hyperparameter than can be increased to more stringently ensure fairness.</p>
</div>
</section>
<section id="S8.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">8.4 </span>Evaluating Utility and Fidelity</h3>

<div id="S8.SS4.p1" class="ltx_para">
<p id="S8.SS4.p1.1" class="ltx_p">Much of the discussion found in Section <a href="#S6.SS2" title="6.2 Evaluating the Utility and Fidelity of Synthetic Datasets ‣ 6 Auditing Synthetic Data ‣ Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6.2</span></a> can be applied to fair synthetic data. An additional consideration will necessarily be whether or not the bias has been successfully removed, metrics for which can be found in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>. These typically involve a comparison between outputs of a predictor trained on the synthetic data when the input protected attributes are varied.</p>
</div>
</section>
</section>
<section id="S9" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">9 </span>Data Augmentation</h2>

<div id="S9.p1" class="ltx_para">
<p id="S9.p1.1" class="ltx_p">Perhaps the most successful use case (so far) for synthetic data has been for data augmentation - using synthetic data to enlarge datasets with additional samples to use for training <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>. This is often referred to as semi-supervised learning. The intuition is that synthetic data can act as a regulariser, reducing variance in the learned downstream model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>. Fortunately, there are several good surveys for data augmentation, and so we defer the reader to those for a more thorough background: time-series data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib144" title="" class="ltx_ref">144</a>]</cite>; image data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib145" title="" class="ltx_ref">145</a>]</cite>.</p>
</div>
<div id="S9.p2" class="ltx_para">
<p id="S9.p2.1" class="ltx_p">Of note is the fact that synthetic data driven techniques are more important in domains with less structure (such as with generic tabluar data). In the image domain, there is significant structure that can be exploited to create additional data, such as small rotations, image-flipping, cropping, etc. This structure often does not have a parallel in generic tabular data. As such, augmentation methods driven by synthetic data generators are a promising approach to fill this gap.</p>
</div>
<section id="S9.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">9.1 </span>The Basic Principle</h3>

<div id="S9.SS1.p1" class="ltx_para">
<p id="S9.SS1.p1.1" class="ltx_p">The key idea driving the use of synthetic data for data augmentation is that of <span id="S9.SS1.p1.1.1" class="ltx_text ltx_font_italic">generalisability</span>. The goal of a model is not just to perform well on its training data, but also on data that has not been seen before by the model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib146" title="" class="ltx_ref">146</a>]</cite>. The hope with synthetic data is that one can take the available training data and learn a generative model, such as a GAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>. This generative model will then be able to produce “realistic” samples of training data, and, <span id="S9.SS1.p1.1.2" class="ltx_text ltx_font_italic">hopefully</span> these samples will be sufficiently different from the original training data so as to be useful additional data points for the training of the model.</p>
</div>
<div id="S9.SS1.p2" class="ltx_para">
<p id="S9.SS1.p2.1" class="ltx_p">It is particularly important to stress that these samples need to be <span id="S9.SS1.p2.1.1" class="ltx_text ltx_font_italic">sufficiently different</span> from the original data. If these samples are too similar, then they will provide no benefit over using the original data on its own for training. As is hopefully clear by now, this need for dissimilarity is a common theme with synthetic data. In the context of data augmentation, this need is less strict; with privacy and fairness, the dissimilarity is a question of ethics and a failure to satisfy it can have both moral and legal repercussions. With data augmentation, this is unlikely to be the case.</p>
</div>
</section>
<section id="S9.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">9.2 </span>What methods are used?</h3>

<div id="S9.SS2.p1" class="ltx_para">
<p id="S9.SS2.p1.1" class="ltx_p">Depending on the domain in question, a variety of models exist that can perform the task of data augmentation. For the most part, the only real requirement is a generative model that is tailored to the domain in question. In Section <a href="#S10" title="10 Generative Modelling - An Overview ‣ Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a>, we discuss different types of generative models in more detail. Due to the need for (some level of) dissimilarity, training a generative model and hoping for the best may not be sufficient, however. Instead, one may wish to impose restrictions that enable this dissimilarity. The authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite> show that learning a perfect generator in a GAN leads to poor semi-supervised learning, but that a bad generator performs well, for example. This idea of dissimilarity is often referred to as a need for <span id="S9.SS2.p1.1.1" class="ltx_text ltx_font_italic">diversity</span> in the generated samples. Metrics for measuring this exist, such as the score presented in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib84" title="" class="ltx_ref">84</a>]</cite>.</p>
</div>
</section>
</section>
<section id="S10" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">10 </span>Generative Modelling - An Overview</h2>

<figure id="S10.F1" class="ltx_figure"><img src="/html/2205.03257/assets/x1.png" id="S10.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="322" height="128" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Generative modelling taxonomy based on the maximum likelihood from <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib147" title="" class="ltx_ref">147</a>]</cite> </figcaption>
</figure>
<div id="S10.p1" class="ltx_para">
<p id="S10.p1.1" class="ltx_p">Though there is a wealth of <span id="S10.p1.1.1" class="ltx_text ltx_font_italic">directed</span> work on synthetic data generation with a specific goal in mind (such as one of the ones discussed in sections <a href="#S4" title="4 Privacy in Machine Learning - An Overview ‣ Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, <a href="#S8" title="8 De-biased Synthetic Data Generation ‣ Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>, and <a href="#S9" title="9 Data Augmentation ‣ Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>), there is also a lot of work focused on generative modelling [for the sake of generative modelling]. The original GAN paper was introduced as a means to generate fake images, not because they wanted to create private, debiased, or even augmented image datasets, but because the task of generating realistic images was hard and the success was easy to evaluate even for non-experts in the field. To that end, there are several methodologies that exist that have yet to be applied to a specific problem.</p>
</div>
<div id="S10.p2" class="ltx_para">
<p id="S10.p2.1" class="ltx_p">The remainder of this section is more technical than the rest of this manuscript. Those that wish may skip to Section <a href="#S11" title="11 Messages from Industry/Start-ups ‣ Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a> without any loss of flow.</p>
</div>
<div id="S10.p3" class="ltx_para">
<p id="S10.p3.1" class="ltx_p">These methodologies could be taxonomised as in Figure <a href="#S10.F1" title="Figure 1 ‣ 10 Generative Modelling - An Overview ‣ Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, as proposed by Goodfellow <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib147" title="" class="ltx_ref">147</a>]</cite>, focusing on generative models whose parameters are trained to maximise the likelihood of the original data.
Such methods can be grouped into two main families, where the underlying density function is either explicitly or implicitly defined.
Within explicit models reside statistical methods where new samples are extracted from the distribution arising from the model’s definition, which, in turn, must strike a balance between the ability of the model to capture data complexity and to maintain computational tractability <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib148" title="" class="ltx_ref">148</a>, <a href="#bib.bib149" title="" class="ltx_ref">149</a>, <a href="#bib.bib150" title="" class="ltx_ref">150</a>, <a href="#bib.bib151" title="" class="ltx_ref">151</a>]</cite>.</p>
</div>
<div id="S10.p4" class="ltx_para">
<p id="S10.p4.1" class="ltx_p">Non-tractable density functions can be explicitly tackled through deterministic and stochastic approximations. Variational Auto-Encoders (VAEs) <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> define the loss functions as tractable lower bounds of the non-tractable log-likelihood densities. However, if these deterministic approximations are not carefully calibrated, the model may not converge to the target distribution and consequently generate inconsistent data. On the other hand, stochastic approximations are the basis of Markov chain approaches, where samples are repeatedly drawn after the application of a chosen transition operator. Deep Boltzmann Machines <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib152" title="" class="ltx_ref">152</a>]</cite> are the main representatives of this class, having all neural units composed of random variables, which simultaneously act as inputs and outputs of the closest layers. Such versatility results in difficulties with training, and thus it is preferable to consider the networks as composed of Restricted Boltzmann Machines (RBMs) <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib153" title="" class="ltx_ref">153</a>]</cite>, consisting of only one visible and one latent layer. In a two-pass learning process, RBMs are progressively trained and then globally fine-tuned. Gibbs-sampling is then used to extract synthetic values.</p>
</div>
<div id="S10.p5" class="ltx_para">
<p id="S10.p5.1" class="ltx_p">A completely different direction is taken by implicit generative models, which can be thought of as “black-boxes”, where distributions are not explicitly defined but indirectly revealed through sampling. A first example is Generative Stochastic Networks (GSNs), based on Markov chains. In these networks, the distribution is estimated indirectly, employing a parametric transition operator instead of a parametric model. Nonetheless, they are subject to scalability issues, being not efficiently applicable to high-dimensional scenarios.</p>
</div>
<div id="S10.p6" class="ltx_para">
<p id="S10.p6.1" class="ltx_p">Generative Adversarial Networks (GANs) <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> were designed to be jointly parallel and multi-modal (i.e. capable of simultaneously generating multiple valid outputs for the same input). GANs consist of two networks: the generator and the discriminator. These two networks are trained <span id="S10.p6.1.1" class="ltx_text ltx_font_italic">adversarially</span>. The generator creates artificial outputs that are passed to the discriminator along with real data. The discriminator is then tasked with identifying which outputs were real, and which were ‘fake’. The final goal here is to reach equilibrium, in which the generated samples follow the same distribution as the real data. When this happens, the discriminator can do no better than random guessing. Theoretically, GAN generators can perfectly imitate the original distribution provided that the network is sufficiently complex enough and the discriminator is optimal <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>. In practive, however, training a standard GAN discriminator to optimality can cause convergence issues and zero-gradients for the generator. Attempts to increase model stability include feature matching, label smoothing, and mini-batch discrimination <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib154" title="" class="ltx_ref">154</a>]</cite>. Alternatives to the Jensen-Shannon divergence (JSD) (that is implicitly used by standard GANs) have been investigated, such as the Wasserstein distance in WGAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib155" title="" class="ltx_ref">155</a>]</cite>, and the Maximum Mean Discrepancy in MMD-GAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib156" title="" class="ltx_ref">156</a>, <a href="#bib.bib157" title="" class="ltx_ref">157</a>]</cite>. A generalisation of the JSD to f-divergences has also been explored <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib158" title="" class="ltx_ref">158</a>]</cite>. Unfortunately, no method has proven to be a clear winner <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib159" title="" class="ltx_ref">159</a>]</cite>.
A further risk of GANs lies in mode-collapse, when the generator memorises only a subset of the training information, hence failing to capture the high-level characteristics of the distribution. To tackle this issue, new architectures have been proposed, such as Conditional GANs (CGANs) <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib160" title="" class="ltx_ref">160</a>]</cite>, where additional classification information is provided to both generator and discriminator networks as a form of semi-supervised learning, Deep Convolutional GANs (DCGANs) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib161" title="" class="ltx_ref">161</a>]</cite>, where convolutional layers substitute pooling layers and Information maximising GANs (InfoGANs) <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib162" title="" class="ltx_ref">162</a>]</cite> that takes an information-theoretic approach to controlling the generation process. Generative Moment Matching Networks (MMNs) <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib163" title="" class="ltx_ref">163</a>]</cite> constitute another emerging cluster of implicit models, replacing GANs’ discriminators with two-sample tests based on kernel maximum mean discrepancy to measure the distance between modelled and target distributions. Although MMNs offer theoretical guarantees, they are currently outperformed by GANs.</p>
</div>
<div id="S10.p7" class="ltx_para">
<p id="S10.p7.1" class="ltx_p">Research on generative models is exploding, both in the evolution of existing models as well as in the introduction of new ones. GAN models are the most popular approach, but their implicit nature necessitates the development of trust through the definition and application of rigorous methodologies and metrics, so far demonstrated to be a difficult task.</p>
</div>
<div id="S10.F2" class="ltx_figure ltx_transformed_outer" style="width:260.4pt;height:435.5pt;vertical-align:-0.0pt;"><div class="ltx_transformed_inner" style="width:435.5pt;transform:translate(-87.53pt,-87.03pt) rotate(-90deg) ;"><figure><img src="/html/2205.03257/assets/x2.png" id="S10.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="276" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Generative models for specific data types.</figcaption>
</figure></div></div>
<section id="S10.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">10.1 </span>Existing Methodologies</h3>

<div id="S10.SS1.p1" class="ltx_para">
<p id="S10.SS1.p1.1" class="ltx_p">The discussion above focused on generative models in the most general sense, without any consideration for the <span id="S10.SS1.p1.1.1" class="ltx_text ltx_font_italic">type</span> of data the model needs to generate. Much work in generative modelling has focused on the image domain with GANs, for example, being originally proposed as an image generation framework. Since their inception, however, many works have looked to generalise GANs to other domains. Below we overview some of the leading generative models that exist for a variety of different data types. Figure <a href="#S10.F2" title="Figure 2 ‣ 10 Generative Modelling - An Overview ‣ Synthetic Data - what, why and how?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> gives an overview of the taxonomy.</p>
</div>
<section id="S10.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">10.1.1 </span>Tabular data</h4>

<div id="S10.SS1.SSS1.p1" class="ltx_para">
<p id="S10.SS1.SSS1.p1.1" class="ltx_p">Tabular data consists of values stored in rows and columns, whose synthesis requires the simultaneous modelling of distinct column distributions, as well as row-wise and table-wise constraints.
Receiving less attention than image data in the generative domain, tabular data generation still has many obstacles to overcome. Initial generators relied on classifiers, as in the case of inverted decision-trees, vector machines and random forests, which struggle to strike a balance between classifier’s accuracy and the risk of leaking information <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib164" title="" class="ltx_ref">164</a>, <a href="#bib.bib165" title="" class="ltx_ref">165</a>, <a href="#bib.bib166" title="" class="ltx_ref">166</a>]</cite>. On the other hand, the application of GANs required the conversion of categorical, discrete columns to a continuous form using auto-encoders or through the decomposition in a variable number of Gaussian modes <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib167" title="" class="ltx_ref">167</a>, <a href="#bib.bib168" title="" class="ltx_ref">168</a>, <a href="#bib.bib169" title="" class="ltx_ref">169</a>]</cite>. Nonetheless, the independent generation of column values might result in invalid rows, whose semantic correctness requires either the training of additional classifiers <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib170" title="" class="ltx_ref">170</a>, <a href="#bib.bib171" title="" class="ltx_ref">171</a>]</cite> or techniques based on Gaussian Copulae <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib106" title="" class="ltx_ref">106</a>]</cite> and Bayesian networks <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib172" title="" class="ltx_ref">172</a>, <a href="#bib.bib173" title="" class="ltx_ref">173</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib174" title="" class="ltx_ref">174</a>]</cite>.</p>
</div>
</section>
<section id="S10.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">10.1.2 </span>Time-series data</h4>

<div id="S10.SS1.SSS2.p1" class="ltx_para">
<p id="S10.SS1.SSS2.p1.1" class="ltx_p">Time-series are series of data points indexed in time order (e.g. electronic health record data containing information about visits to a GP, or higher frequency financial data, such as stock prices).
Historically, they were generated via auto-regressive models <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib175" title="" class="ltx_ref">175</a>]</cite>, hardly applicable to practical scenarios where stationarity only holds in specific time regions and in the presence of skewed and heavy-tailed distributions. Conversely, most implicit models focused on conditional distributions of future events given the occurrence of past ones, instead of capturing the full joint-law <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib99" title="" class="ltx_ref">99</a>, <a href="#bib.bib176" title="" class="ltx_ref">176</a>, <a href="#bib.bib177" title="" class="ltx_ref">177</a>]</cite>. Recent developments allow training effort to be optimised by exploiting a reduced feature space, where the data stream is identified by its signature, resulting in a graded sequence of statistics <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib178" title="" class="ltx_ref">178</a>]</cite>.</p>
</div>
</section>
<section id="S10.SS1.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">10.1.3 </span>Images</h4>

<div id="S10.SS1.SSS3.p1" class="ltx_para">
<p id="S10.SS1.SSS3.p1.1" class="ltx_p">Applications of image synthesis are extremely diverse, ranging from the reconstruction of a damaged or missing region to the improvement of resolution and colour reproduction. The creation of an image consists in choosing a specific colour for each pixel, as the result of an image-to-image transformation or a text-to-image conversion.
Variational Auto-Encoders were somewhat successful <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib179" title="" class="ltx_ref">179</a>, <a href="#bib.bib180" title="" class="ltx_ref">180</a>]</cite>, however, they featured a pixel-wise loss and simple conditioning, as in the case of class labels and image captions. On the contrary, GANs employ a semantic loss which is more aligned with the human visual system as well as being better suited to highly multi-modal outputs, where several valid images could be created <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib181" title="" class="ltx_ref">181</a>]</cite>. Starting from vanilla GANs <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>, different architectures were proposed to generate plausible images in various datasets, as in the case of human faces <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib182" title="" class="ltx_ref">182</a>, <a href="#bib.bib183" title="" class="ltx_ref">183</a>, <a href="#bib.bib184" title="" class="ltx_ref">184</a>, <a href="#bib.bib185" title="" class="ltx_ref">185</a>, <a href="#bib.bib186" title="" class="ltx_ref">186</a>, <a href="#bib.bib187" title="" class="ltx_ref">187</a>, <a href="#bib.bib188" title="" class="ltx_ref">188</a>]</cite>, high-resolution photographs <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib189" title="" class="ltx_ref">189</a>, <a href="#bib.bib190" title="" class="ltx_ref">190</a>, <a href="#bib.bib191" title="" class="ltx_ref">191</a>]</cite> and multi-domain images <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib192" title="" class="ltx_ref">192</a>, <a href="#bib.bib193" title="" class="ltx_ref">193</a>]</cite>. In text-to-image scenarios, the generation process starts from a brief text description, which is used as additional training information <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib194" title="" class="ltx_ref">194</a>, <a href="#bib.bib195" title="" class="ltx_ref">195</a>]</cite> with the eventual aid of stacked architectures <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib196" title="" class="ltx_ref">196</a>, <a href="#bib.bib197" title="" class="ltx_ref">197</a>, <a href="#bib.bib198" title="" class="ltx_ref">198</a>]</cite> and attentive, semantic frameworks <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib199" title="" class="ltx_ref">199</a>, <a href="#bib.bib200" title="" class="ltx_ref">200</a>, <a href="#bib.bib201" title="" class="ltx_ref">201</a>]</cite> to preserve sentence-level consistency.</p>
</div>
</section>
<section id="S10.SS1.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">10.1.4 </span>Audio</h4>

<div id="S10.SS1.SSS4.p1" class="ltx_para">
<p id="S10.SS1.SSS4.p1.1" class="ltx_p">Similar to the generation of time-series, audio signals have a high temporal resolution, requiring representation and synthesis strategies capable of operating efficiently with a large number of dimensions. A significant attempt was the design of WaveNets <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib202" title="" class="ltx_ref">202</a>]</cite>, arising from the architecture of PixelRNN <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib203" title="" class="ltx_ref">203</a>]</cite> borrowed from the image domain, further evolved by considering the speed difference between the raw audio and the hidden semantic-signal, which is usually many times slower <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib204" title="" class="ltx_ref">204</a>, <a href="#bib.bib205" title="" class="ltx_ref">205</a>]</cite>. A different approach consisted in the use of spectrograms, i.e. the simultaneous representations of audio signals in time and frequency, which requires lossy assumptions to cope with their non-invertible nature, inevitably reducing the overall quality <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib206" title="" class="ltx_ref">206</a>, <a href="#bib.bib207" title="" class="ltx_ref">207</a>]</cite>.</p>
</div>
</section>
<section id="S10.SS1.SSS5" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">10.1.5 </span>Video</h4>

<div id="S10.SS1.SSS5.p1" class="ltx_para">
<p id="S10.SS1.SSS5.p1.1" class="ltx_p">The synthesis of a video can be considered as the generation of a sequence of images, where the main challenge stems from their inter-dependency and hidden temporal dimension. Unconditional video generation tried to maintain scene and foreground consistencies by separately focusing on objects’ motion and RGB frame generation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib208" title="" class="ltx_ref">208</a>, <a href="#bib.bib209" title="" class="ltx_ref">209</a>, <a href="#bib.bib210" title="" class="ltx_ref">210</a>, <a href="#bib.bib211" title="" class="ltx_ref">211</a>]</cite>. Conversely, conditional approaches required smaller training datasets and allowed for finer control of modes of distributions, as in the case of audio conditioning for synchronising speech with a talking character <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib212" title="" class="ltx_ref">212</a>, <a href="#bib.bib213" title="" class="ltx_ref">213</a>, <a href="#bib.bib214" title="" class="ltx_ref">214</a>]</cite>, text conditioning for video generation <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib215" title="" class="ltx_ref">215</a>, <a href="#bib.bib216" title="" class="ltx_ref">216</a>, <a href="#bib.bib217" title="" class="ltx_ref">217</a>]</cite>, image conditioning for the prediction of future frames <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib218" title="" class="ltx_ref">218</a>, <a href="#bib.bib219" title="" class="ltx_ref">219</a>, <a href="#bib.bib220" title="" class="ltx_ref">220</a>, <a href="#bib.bib221" title="" class="ltx_ref">221</a>, <a href="#bib.bib222" title="" class="ltx_ref">222</a>]</cite> and video-to-video for object animation <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib223" title="" class="ltx_ref">223</a>, <a href="#bib.bib224" title="" class="ltx_ref">224</a>, <a href="#bib.bib225" title="" class="ltx_ref">225</a>, <a href="#bib.bib226" title="" class="ltx_ref">226</a>]</cite>.</p>
</div>
</section>
</section>
</section>
<section id="S11" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">11 </span>Messages from Industry/Start-ups</h2>

<div id="S11.p1" class="ltx_para">
<p id="S11.p1.1" class="ltx_p">In preparation of this report, the authors interviewed several industry partners and start-ups in the space of synthetic data. In this section we highlight some of the key themes and messages that we received in response to our questions.</p>
</div>
<div id="S11.p2" class="ltx_para">
<p id="S11.p2.1" class="ltx_p"><span id="S11.p2.1.1" class="ltx_text ltx_font_bold">AI itself is in the early stages of mass adoption.</span> Though serious AI research has been ongoing for a long time now, widespread adoption of AI systems is in its infancy. Synthetic data is a younger field than the classical AI/ML problems of prediction, clustering, forecasting, etc. and significant research is required to fully benefit from this technology. That said, there is pressure for the adoption of private synthetic data (more than for other technologies) due to a heightening desire from the public for more privacy control.</p>
</div>
<div id="S11.p3" class="ltx_para">
<p id="S11.p3.1" class="ltx_p"><span id="S11.p3.1.1" class="ltx_text ltx_font_bold">Empirical evaluations are necessary.</span> Though differential privacy is an attractive theoretical notion of privacy, industries struggle to trust it without empirical supporting evidence of privacy. Understanding practical implications of differential privacy (i.e. its susceptibility to attacks, what the parameters actually correspond to) is crucial to enable widespread adoption of private synthetic data.</p>
</div>
<div id="S11.p4" class="ltx_para">
<p id="S11.p4.1" class="ltx_p"><span id="S11.p4.1.1" class="ltx_text ltx_font_bold">Synthetic data cannot wholly replace real data, or can it?</span> Opinions were more divided on this subject. The impossibility result of Ullman et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib82" title="" class="ltx_ref">82</a>]</cite> is a blow against the notion of a completely general-use synthetic dataset. The relaxed result of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib85" title="" class="ltx_ref">85</a>]</cite>, however, indicates it might still be possible in many cases. Several in industry believe that real data should remain at the core of model development, with the final models ultimately being tweaked or even completely re-trained on the real data. Others believe that it will be possible to completely replace real data with synthetic data in the future.</p>
</div>
<div id="S11.p5" class="ltx_para">
<p id="S11.p5.1" class="ltx_p"><span id="S11.p5.1.1" class="ltx_text ltx_font_bold">Synthetic data is about enabling.</span> The final takeaway is that synthetic data is about enabling processes that would otherwise not be possible, or that perhaps would drain a lot of resources (such as time). Synthetic data could be used to “access” data across legislative borders (e.g. in companies with an international presence), or to speed up model development times by allowing model designers access to <span id="S11.p5.1.2" class="ltx_text ltx_font_italic">something</span> as early as possible. Ultimately, data is very powerful, and synthetic data may allow many more people to tap into its true potential.</p>
</div>
</section>
<section id="S12" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">12 </span>Conclusion</h2>

<div id="S12.p1" class="ltx_para">
<p id="S12.p1.1" class="ltx_p">Synthetic data is a promising technology, with a wide variety of applications. For both privacy and fairness, there is a large cost to getting it wrong. The methods that exist today should be implemented with caution, and significantly more research is needed, from a machine learning perspective, but also from a societal perspective, in order to understand properly the methods that exist.</p>
</div>
</section>
<section id="Sx2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgements</h2>

<div id="Sx2.p1" class="ltx_para">
<p id="Sx2.p1.1" class="ltx_p">We would like to thank Accenture, Hazy, HSBC, MOSTLY AI, and the Office for National Statistics for their participation in our interviews.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jordon et al. [2020]</span>
<span class="ltx_bibblock">
James Jordon, Alan Wilson, and Mihaela van der Schaar.

</span>
<span class="ltx_bibblock">Synthetic data: Opening the data floodgates to enable faster, more
directed development of machine learning methods.

</span>
<span class="ltx_bibblock"><em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2012.04580</em>, 2020.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Assefa [2020]</span>
<span class="ltx_bibblock">
Samuel Assefa.

</span>
<span class="ltx_bibblock">Generating synthetic data in finance: opportunities, challenges and
pitfalls.

</span>
<span class="ltx_bibblock"><em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Challenges and Pitfalls (June 23, 2020)</em>, 2020.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mendelevitch and Lesh [2021]</span>
<span class="ltx_bibblock">
Ofer Mendelevitch and Michael D Lesh.

</span>
<span class="ltx_bibblock">Fidelity and privacy of synthetic medical data.

</span>
<span class="ltx_bibblock"><em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2101.08658</em>, 2021.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bellovin et al. [2019]</span>
<span class="ltx_bibblock">
Steven M Bellovin, Preetam K Dutta, and Nathan Reitinger.

</span>
<span class="ltx_bibblock">Privacy and synthetic datasets.

</span>
<span class="ltx_bibblock"><em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Stan. Tech. L. Rev.</em>, 22:1, 2019.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McKenna et al. [2021]</span>
<span class="ltx_bibblock">
Ryan McKenna, Gerome Miklau, and Daniel Sheldon.

</span>
<span class="ltx_bibblock">Winning the nist contest: A scalable and general approach to
differentially private synthetic data.

</span>
<span class="ltx_bibblock"><em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2108.04978</em>, 2021.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Goodfellow et al. [2020]</span>
<span class="ltx_bibblock">
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley,
Sherjil Ozair, Aaron Courville, and Yoshua Bengio.

</span>
<span class="ltx_bibblock">Generative adversarial networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">Communications of the ACM</em>, 63(11):139–144, 2020.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kingma and Welling [2013]</span>
<span class="ltx_bibblock">
Diederik P Kingma and Max Welling.

</span>
<span class="ltx_bibblock">Auto-encoding variational bayes.

</span>
<span class="ltx_bibblock"><em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1312.6114</em>, 2013.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bonabeau [2002]</span>
<span class="ltx_bibblock">
Eric Bonabeau.

</span>
<span class="ltx_bibblock">Agent-based modeling: Methods and techniques for simulating human
systems.

</span>
<span class="ltx_bibblock"><em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">Proceedings of the national academy of sciences</em>, 99(suppl 3):7280–7287, 2002.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Carmona and Delarue [2018]</span>
<span class="ltx_bibblock">
René Carmona and François Delarue.

</span>
<span class="ltx_bibblock"><em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">Probabilistic Theory of Mean Field Games with Applications</em>,
volume 84.

</span>
<span class="ltx_bibblock">Springer, 2018.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rubin [1987]</span>
<span class="ltx_bibblock">
Donald B Rubin.

</span>
<span class="ltx_bibblock"><em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">Multiple imputation for survey nonresponse</em>.

</span>
<span class="ltx_bibblock">New York: Wiley, 1987.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rubin [1993]</span>
<span class="ltx_bibblock">
Donald B Rubin.

</span>
<span class="ltx_bibblock">Discussion statistical disclosure limitation.

</span>
<span class="ltx_bibblock"><em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">Journal of official Statistics</em>, 9(2):461,
1993.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Little [1993]</span>
<span class="ltx_bibblock">
Roderick JA Little.

</span>
<span class="ltx_bibblock">Statistical analysis of masked data.

</span>
<span class="ltx_bibblock"><em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">Journal of Official statistics</em>, 9(2):407,
1993.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dwork et al. [2014]</span>
<span class="ltx_bibblock">
Cynthia Dwork, Aaron Roth, et al.

</span>
<span class="ltx_bibblock">The algorithmic foundations of differential privacy.

</span>
<span class="ltx_bibblock"><em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Foundations and Trends® in Theoretical Computer
Science</em>, 9(3–4):211–407, 2014.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. [2017a]</span>
<span class="ltx_bibblock">
Jun Zhang, Graham Cormode, Cecilia M Procopiuc, Divesh Srivastava, and Xiaokui
Xiao.

</span>
<span class="ltx_bibblock">Privbayes: Private data release via bayesian networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">ACM Transactions on Database Systems (TODS)</em>, 42(4):1–41, 2017a.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xie et al. [2018]</span>
<span class="ltx_bibblock">
Liyang Xie, Kaixiang Lin, Shu Wang, Fei Wang, and Jiayu Zhou.

</span>
<span class="ltx_bibblock">Differentially private generative adversarial network.

</span>
<span class="ltx_bibblock"><em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1802.06739</em>, 2018.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Esteban et al. [2017]</span>
<span class="ltx_bibblock">
Cristóbal Esteban, Stephanie L Hyland, and Gunnar Rätsch.

</span>
<span class="ltx_bibblock">Real-valued (medical) time series generation with recurrent
conditional gans.

</span>
<span class="ltx_bibblock"><em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1706.02633</em>, 2017.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jordon et al. [2018a]</span>
<span class="ltx_bibblock">
James Jordon, Jinsung Yoon, and Mihaela Van Der Schaar.

</span>
<span class="ltx_bibblock">Pate-gan: Generating synthetic data with differential privacy
guarantees.

</span>
<span class="ltx_bibblock">In <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">International conference on learning representations</em>,
2018a.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Feldman et al. [2015]</span>
<span class="ltx_bibblock">
Michael Feldman, Sorelle A Friedler, John Moeller, Carlos Scheidegger, and
Suresh Venkatasubramanian.

</span>
<span class="ltx_bibblock">Certifying and removing disparate impact.

</span>
<span class="ltx_bibblock">In <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">proceedings of the 21th ACM SIGKDD international conference
on knowledge discovery and data mining</em>, pages 259–268, 2015.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kamiran and Calders [2009]</span>
<span class="ltx_bibblock">
Faisal Kamiran and Toon Calders.

</span>
<span class="ltx_bibblock">Classifying without discriminating.

</span>
<span class="ltx_bibblock">In <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">2009 2nd international conference on computer, control and
communication</em>, pages 1–6. IEEE, 2009.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. [2016]</span>
<span class="ltx_bibblock">
Lu Zhang, Yongkai Wu, and Xintao Wu.

</span>
<span class="ltx_bibblock">A causal framework for discovering and removing direct and indirect
discrimination.

</span>
<span class="ltx_bibblock"><em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1611.07509</em>, 2016.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Calmon et al. [2017]</span>
<span class="ltx_bibblock">
Flavio Calmon, Dennis Wei, Bhanukiran Vinzamuri, Karthikeyan Natesan
Ramamurthy, and Kush R Varshney.

</span>
<span class="ltx_bibblock">Optimized pre-processing for discrimination prevention.

</span>
<span class="ltx_bibblock">In <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, pages
3992–4001, 2017.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al. [2018]</span>
<span class="ltx_bibblock">
Depeng Xu, Shuhan Yuan, Lu Zhang, and Xintao Wu.

</span>
<span class="ltx_bibblock">Fairgan: Fairness-aware generative adversarial networks.

</span>
<span class="ltx_bibblock">In <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">2018 IEEE International Conference on Big Data (Big Data)</em>,
pages 570–575. IEEE, 2018.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">van Breugel et al. [2021]</span>
<span class="ltx_bibblock">
Boris van Breugel, Trent Kyono, Jeroen Berrevoets, and Mihaela van der Schaar.

</span>
<span class="ltx_bibblock">Decaf: Generating fair synthetic data using causally-aware generative
networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, 34, 2021.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wong et al. [2016]</span>
<span class="ltx_bibblock">
Sebastien C Wong, Adam Gatt, Victor Stamatescu, and Mark D McDonnell.

</span>
<span class="ltx_bibblock">Understanding data augmentation for classification: when to warp?

</span>
<span class="ltx_bibblock">In <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">2016 international conference on digital image computing:
techniques and applications (DICTA)</em>, pages 1–6. IEEE, 2016.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Odena [2016]</span>
<span class="ltx_bibblock">
Augustus Odena.

</span>
<span class="ltx_bibblock">Semi-supervised learning with generative adversarial networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1606.01583</em>, 2016.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dai et al. [2017]</span>
<span class="ltx_bibblock">
Zihang Dai, Zhilin Yang, Fan Yang, William W Cohen, and Ruslan Salakhutdinov.

</span>
<span class="ltx_bibblock">Good semi-supervised learning that requires a bad gan.

</span>
<span class="ltx_bibblock"><em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1705.09783</em>, 2017.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kumar et al. [2017]</span>
<span class="ltx_bibblock">
Abhishek Kumar, Prasanna Sattigeri, and Tom Fletcher.

</span>
<span class="ltx_bibblock">Semi-supervised learning with gans: Manifold invariance with improved
inference.

</span>
<span class="ltx_bibblock"><em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, 30, 2017.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bandara et al. [2021]</span>
<span class="ltx_bibblock">
Kasun Bandara, Hansika Hewamalage, Yuan-Hao Liu, Yanfei Kang, and Christoph
Bergmeir.

</span>
<span class="ltx_bibblock">Improving the accuracy of global forecasting models using time series
data augmentation.

</span>
<span class="ltx_bibblock"><em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">Pattern Recognition</em>, 120:108148, 2021.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fawaz et al. [2018]</span>
<span class="ltx_bibblock">
Hassan Ismail Fawaz, Germain Forestier, Jonathan Weber, Lhassane Idoumghar, and
Pierre-Alain Muller.

</span>
<span class="ltx_bibblock">Data augmentation using synthetic data for time series classification
with deep residual networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1808.02455</em>, 2018.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Arpit et al. [2017]</span>
<span class="ltx_bibblock">
Devansh Arpit, Stanisław Jastrzebski, Nicolas Ballas, David Krueger,
Emmanuel Bengio, Maxinder S Kanwal, Tegan Maharaj, Asja Fischer, Aaron
Courville, Yoshua Bengio, et al.

</span>
<span class="ltx_bibblock">A closer look at memorization in deep networks.

</span>
<span class="ltx_bibblock">In <em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>, pages
233–242. PMLR, 2017.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Goodfellow et al. [2016]</span>
<span class="ltx_bibblock">
Ian Goodfellow, Yoshua Bengio, and Aaron Courville.

</span>
<span class="ltx_bibblock"><em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">Deep learning</em>.

</span>
<span class="ltx_bibblock">MIT press, 2016.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Srivastava et al. [2017]</span>
<span class="ltx_bibblock">
Akash Srivastava, Lazar Valkov, Chris Russell, Michael U Gutmann, and Charles
Sutton.

</span>
<span class="ltx_bibblock">Veegan: Reducing mode collapse in gans using implicit variational
learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 31st International Conference on Neural
Information Processing Systems</em>, pages 3310–3320, 2017.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Williams and McSherry [2010]</span>
<span class="ltx_bibblock">
Oliver Williams and Frank McSherry.

</span>
<span class="ltx_bibblock">Probabilistic inference and differential privacy.

</span>
<span class="ltx_bibblock"><em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>,
23:2451–2459, 2010.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ghalebikesabi et al. [2021]</span>
<span class="ltx_bibblock">
Sahra Ghalebikesabi, Harrison Wilde, Jack Jewson, Arnaud Doucet, Sebastian
Vollmer, and Chris Holmes.

</span>
<span class="ltx_bibblock">Bias mitigated learning from differentially private synthetic data: A
cautionary tale.

</span>
<span class="ltx_bibblock"><em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2108.10934</em>, 2021.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wilde et al. [2021]</span>
<span class="ltx_bibblock">
Harrison Wilde, Jack Jewson, Sebastian Vollmer, and Chris Holmes.

</span>
<span class="ltx_bibblock">Foundations of bayesian learning from synthetic data.

</span>
<span class="ltx_bibblock">In <em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">International Conference on Artificial Intelligence and
Statistics</em>, pages 541–549. PMLR, 2021.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Williamson et al. [2020]</span>
<span class="ltx_bibblock">
Elizabeth J Williamson, Alex J Walker, Krishnan Bhaskaran, Seb Bacon, Chris
Bates, Caroline E Morton, Helen J Curtis, Amir Mehrkar, David Evans, Peter
Inglesby, et al.

</span>
<span class="ltx_bibblock">Factors associated with covid-19-related death using opensafely.

</span>
<span class="ltx_bibblock"><em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">Nature</em>, 584(7821):430–436, 2020.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shokri et al. [2017]</span>
<span class="ltx_bibblock">
Reza Shokri, Marco Stronati, Congzheng Song, and Vitaly Shmatikov.

</span>
<span class="ltx_bibblock">Membership inference attacks against machine learning models.

</span>
<span class="ltx_bibblock">In <em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">2017 IEEE Symposium on Security and Privacy (SP)</em>, pages
3–18. IEEE, 2017.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Song et al. [2013]</span>
<span class="ltx_bibblock">
Shuang Song, Kamalika Chaudhuri, and Anand D Sarwate.

</span>
<span class="ltx_bibblock">Stochastic gradient descent with differentially private updates.

</span>
<span class="ltx_bibblock">In <em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">2013 IEEE Global Conference on Signal and Information
Processing</em>, pages 245–248. IEEE, 2013.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Abadi et al. [2016]</span>
<span class="ltx_bibblock">
Martin Abadi, Andy Chu, Ian Goodfellow, H Brendan McMahan, Ilya Mironov, Kunal
Talwar, and Li Zhang.

</span>
<span class="ltx_bibblock">Deep learning with differential privacy.

</span>
<span class="ltx_bibblock">In <em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2016 ACM SIGSAC conference on computer
and communications security</em>, pages 308–318, 2016.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Papernot et al. [2016]</span>
<span class="ltx_bibblock">
Nicolas Papernot, Martín Abadi, Ulfar Erlingsson, Ian Goodfellow, and
Kunal Talwar.

</span>
<span class="ltx_bibblock">Semi-supervised knowledge transfer for deep learning from private
training data.

</span>
<span class="ltx_bibblock"><em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1610.05755</em>, 2016.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Papernot et al. [2018]</span>
<span class="ltx_bibblock">
Nicolas Papernot, Shuang Song, Ilya Mironov, Ananth Raghunathan, Kunal Talwar,
and Úlfar Erlingsson.

</span>
<span class="ltx_bibblock">Scalable private learning with pate.

</span>
<span class="ltx_bibblock"><em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1802.08908</em>, 2018.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tiwald et al. [2021]</span>
<span class="ltx_bibblock">
Paul Tiwald, Alexandra Ebert, and Daniel T Soukup.

</span>
<span class="ltx_bibblock">Representative &amp; fair synthetic data.

</span>
<span class="ltx_bibblock"><em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2104.03007</em>, 2021.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nikolenko [2019]</span>
<span class="ltx_bibblock">
Sergey I Nikolenko.

</span>
<span class="ltx_bibblock"><em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">Synthetic data for deep learning</em>.

</span>
<span class="ltx_bibblock">Springer, 2019.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Deng [2012]</span>
<span class="ltx_bibblock">
Li Deng.

</span>
<span class="ltx_bibblock">The mnist database of handwritten digit images for machine learning
research [best of the web].

</span>
<span class="ltx_bibblock"><em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">IEEE signal processing magazine</em>, 29(6):141–142, 2012.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. [2017]</span>
<span class="ltx_bibblock">
Fei Wang, Mengqing Jiang, Chen Qian, Shuo Yang, Cheng Li, Honggang Zhang,
Xiaogang Wang, and Xiaoou Tang.

</span>
<span class="ltx_bibblock">Residual attention network for image classification.

</span>
<span class="ltx_bibblock">In <em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE conference on computer vision and
pattern recognition</em>, pages 3156–3164, 2017.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Aggarwal and Philip [2008]</span>
<span class="ltx_bibblock">
Charu C Aggarwal and S Yu Philip.

</span>
<span class="ltx_bibblock">A general survey of privacy-preserving data mining models and
algorithms.

</span>
<span class="ltx_bibblock">In <em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">Privacy-preserving data mining</em>, pages 11–52. Springer,
2008.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Machanavajjhala et al. [2007]</span>
<span class="ltx_bibblock">
Ashwin Machanavajjhala, Daniel Kifer, Johannes Gehrke, and Muthuramakrishnan
Venkitasubramaniam.

</span>
<span class="ltx_bibblock">l-diversity: Privacy beyond k-anonymity.

</span>
<span class="ltx_bibblock"><em id="bib.bib47.1.1" class="ltx_emph ltx_font_italic">ACM Transactions on Knowledge Discovery from Data (TKDD)</em>,
1(1):3–es, 2007.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. [2007]</span>
<span class="ltx_bibblock">
Ninghui Li, Tiancheng Li, and Suresh Venkatasubramanian.

</span>
<span class="ltx_bibblock">t-closeness: Privacy beyond k-anonymity and l-diversity.

</span>
<span class="ltx_bibblock">In <em id="bib.bib48.1.1" class="ltx_emph ltx_font_italic">2007 IEEE 23rd International Conference on Data
Engineering</em>, pages 106–115. IEEE, 2007.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nergiz et al. [2007]</span>
<span class="ltx_bibblock">
Mehmet Ercan Nergiz, Maurizio Atzori, and Chris Clifton.

</span>
<span class="ltx_bibblock">Hiding the presence of individuals from shared databases.

</span>
<span class="ltx_bibblock">In <em id="bib.bib49.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2007 ACM SIGMOD international conference
on Management of data</em>, pages 665–676, 2007.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Domingo-Ferrer and Torra [2008]</span>
<span class="ltx_bibblock">
Josep Domingo-Ferrer and Vicenç Torra.

</span>
<span class="ltx_bibblock">A critique of k-anonymity and some of its enhancements.

</span>
<span class="ltx_bibblock">In <em id="bib.bib50.1.1" class="ltx_emph ltx_font_italic">2008 Third International Conference on Availability,
Reliability and Security</em>, pages 990–993. IEEE, 2008.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Narayanan and Shmatikov [2008]</span>
<span class="ltx_bibblock">
Arvind Narayanan and Vitaly Shmatikov.

</span>
<span class="ltx_bibblock">Robust de-anonymization of large sparse datasets.

</span>
<span class="ltx_bibblock">In <em id="bib.bib51.1.1" class="ltx_emph ltx_font_italic">Security and Privacy, 2008. SP 2008. IEEE Symposium on</em>,
pages 111–125. IEEE, 2008.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et al. [2021]</span>
<span class="ltx_bibblock">
Hongsheng Hu, Zoran Salcic, Gillian Dobbie, and Xuyun Zhang.

</span>
<span class="ltx_bibblock">Membership inference attacks on machine learning: A survey.

</span>
<span class="ltx_bibblock"><em id="bib.bib52.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2103.07853</em>, 2021.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Al Zamal et al. [2012]</span>
<span class="ltx_bibblock">
Faiyaz Al Zamal, Wendy Liu, and Derek Ruths.

</span>
<span class="ltx_bibblock">Homophily and latent attribute inference: Inferring latent attributes
of twitter users from neighbors.

</span>
<span class="ltx_bibblock">In <em id="bib.bib53.1.1" class="ltx_emph ltx_font_italic">Sixth International AAAI Conference on Weblogs and Social
Media</em>, 2012.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kosinski et al. [2013a]</span>
<span class="ltx_bibblock">
Michal Kosinski, David Stillwell, and Thore Graepel.

</span>
<span class="ltx_bibblock">Private traits and attributes are predictable from digital records of
human behavior.

</span>
<span class="ltx_bibblock"><em id="bib.bib54.1.1" class="ltx_emph ltx_font_italic">Proceedings of the national academy of sciences</em>, 110(15):5802–5805, 2013a.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kosinski et al. [2013b]</span>
<span class="ltx_bibblock">
Michal Kosinski, David Stillwell, and Thore Graepel.

</span>
<span class="ltx_bibblock">Private traits and attributes are predictable from digital records of
human behavior.

</span>
<span class="ltx_bibblock"><em id="bib.bib55.1.1" class="ltx_emph ltx_font_italic">Proceedings of the national academy of sciences</em>, 110(15):5802–5805, 2013b.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bun et al. [2021]</span>
<span class="ltx_bibblock">
Mark Bun, Damien Desfontaines, Cynthia Dwork, Moni Naor, Kobbi Nissim, Aaron
Roth, Adam Smith, Thomas Steinke, Jonathan Ullman, and Salil Vadhan.

</span>
<span class="ltx_bibblock">Statistical inference is not a privacy violation, 2021.

</span>
<span class="ltx_bibblock">URL
<a target="_blank" href="https://differentialprivacy.org/inference-is-not-a-privacy-violation/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://differentialprivacy.org/inference-is-not-a-privacy-violation/</a>.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McSherry [2016]</span>
<span class="ltx_bibblock">
Frank McSherry.

</span>
<span class="ltx_bibblock">Statistical inference considered harmful, 2016.

</span>
<span class="ltx_bibblock">URL
<a target="_blank" href="https://github.com/frankmcsherry/blog/blob/master/posts/2016-06-14.md" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/frankmcsherry/blog/blob/master/posts/2016-06-14.md</a>.

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Neyshabur et al. [2017]</span>
<span class="ltx_bibblock">
Behnam Neyshabur, Srinadh Bhojanapalli, David McAllester, and Nathan Srebro.

</span>
<span class="ltx_bibblock">Exploring generalization in deep learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib58.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1706.08947</em>, 2017.

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yeom et al. [2018]</span>
<span class="ltx_bibblock">
Samuel Yeom, Irene Giacomelli, Matt Fredrikson, and Somesh Jha.

</span>
<span class="ltx_bibblock">Privacy risk in machine learning: Analyzing the connection to
overfitting.

</span>
<span class="ltx_bibblock">In <em id="bib.bib59.1.1" class="ltx_emph ltx_font_italic">2018 IEEE 31st Computer Security Foundations Symposium
(CSF)</em>, pages 268–282. IEEE, 2018.

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al. [2021a]</span>
<span class="ltx_bibblock">
Benjamin Zi Hao Zhao, Aviral Agrawal, Catisha Coburn, Hassan Jameel Asghar,
Raghav Bhaskar, Mohamed Ali Kaafar, Darren Webb, and Peter Dickinson.

</span>
<span class="ltx_bibblock">On the (in) feasibility of attribute inference attacks on machine
learning models.

</span>
<span class="ltx_bibblock"><em id="bib.bib60.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2103.07101</em>, 2021a.

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dinur and Nissim [2003]</span>
<span class="ltx_bibblock">
Irit Dinur and Kobbi Nissim.

</span>
<span class="ltx_bibblock">Revealing information while preserving privacy.

</span>
<span class="ltx_bibblock">In <em id="bib.bib61.1.1" class="ltx_emph ltx_font_italic">Proceedings of the twenty-second ACM SIGMOD-SIGACT-SIGART
symposium on Principles of database systems</em>, pages 202–210, 2003.

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bureau [2021]</span>
<span class="ltx_bibblock">
US Census Bureau.

</span>
<span class="ltx_bibblock">Disclosure avoidance for the 2020 census: An introduction, november
2021.

</span>
<span class="ltx_bibblock">URL
<a target="_blank" href="https://www.census.gov/library/publications/2021/decennial/2020-census-disclosure-avoidance-handbook.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.census.gov/library/publications/2021/decennial/2020-census-disclosure-avoidance-handbook.html</a>.

</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wood et al. [2018]</span>
<span class="ltx_bibblock">
Alexandra Wood, Micah Altman, Aaron Bembenek, Mark Bun, Marco Gaboardi, James
Honaker, Kobbi Nissim, David R O’Brien, Thomas Steinke, and Salil Vadhan.

</span>
<span class="ltx_bibblock">Differential privacy: A primer for a non-technical audience.

</span>
<span class="ltx_bibblock"><em id="bib.bib63.1.1" class="ltx_emph ltx_font_italic">Vand. J. Ent. &amp; Tech. L.</em>, 21:209, 2018.

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dwork [2006]</span>
<span class="ltx_bibblock">
Cynthia Dwork.

</span>
<span class="ltx_bibblock">Differential privacy.

</span>
<span class="ltx_bibblock">In <em id="bib.bib64.1.1" class="ltx_emph ltx_font_italic">International Colloquium on Automata, Languages, and
Programming</em>, pages 1–12. Springer, 2006.

</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[65]</span>
<span class="ltx_bibblock">
United States Census Bureau.

</span>
<span class="ltx_bibblock">Census bureau sets key parameters to protect privacy in 2020 census
results, 2021.

</span>
<span class="ltx_bibblock">URL
<a target="_blank" href="https://www.census.gov/newsroom/press-releases/2021/2020-census-key-parameters.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.census.gov/newsroom/press-releases/2021/2020-census-key-parameters.html</a>.

</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[66]</span>
<span class="ltx_bibblock">
Microsoft.

</span>
<span class="ltx_bibblock">How statistical noise is protecting your data privacy, 2020.

</span>
<span class="ltx_bibblock">URL
<a target="_blank" href="https://news.microsoft.com/on-the-issues/2020/08/27/statistical-noise-data-differential-privacy/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://news.microsoft.com/on-the-issues/2020/08/27/statistical-noise-data-differential-privacy/</a>.

</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[67]</span>
<span class="ltx_bibblock">
Facebook Research.

</span>
<span class="ltx_bibblock">New privacy-protected facebook data for independent research on
social media’s impact on democracy, 2020.

</span>
<span class="ltx_bibblock">URL
<a target="_blank" href="https://research.fb.com/blog/2020/02/new-privacy-protected-facebook-data-for-independent-research-on-social-medias-impact-on-democracy/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://research.fb.com/blog/2020/02/new-privacy-protected-facebook-data-for-independent-research-on-social-medias-impact-on-democracy/</a>.

</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McSherry and Mironov [2009]</span>
<span class="ltx_bibblock">
Frank McSherry and Ilya Mironov.

</span>
<span class="ltx_bibblock">Differentially private recommender systems: Building privacy into the
netflix prize contenders.

</span>
<span class="ltx_bibblock">In <em id="bib.bib68.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 15th ACM SIGKDD international conference
on Knowledge discovery and data mining</em>, pages 627–636, 2009.

</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hardt and Roth [2012]</span>
<span class="ltx_bibblock">
Moritz Hardt and Aaron Roth.

</span>
<span class="ltx_bibblock">Beating randomized response on incoherent matrices.

</span>
<span class="ltx_bibblock">In <em id="bib.bib69.1.1" class="ltx_emph ltx_font_italic">Proceedings of the forty-fourth annual ACM symposium on
Theory of computing</em>, pages 1255–1268, 2012.

</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hay et al. [2009]</span>
<span class="ltx_bibblock">
Michael Hay, Chao Li, Gerome Miklau, and David Jensen.

</span>
<span class="ltx_bibblock">Accurate estimation of the degree distribution of private networks.

</span>
<span class="ltx_bibblock">In <em id="bib.bib70.1.1" class="ltx_emph ltx_font_italic">2009 Ninth IEEE International Conference on Data Mining</em>,
pages 169–178. IEEE, 2009.

</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. [2014]</span>
<span class="ltx_bibblock">
Rui Chen, Benjamin CM Fung, S Yu Philip, and Bipin C Desai.

</span>
<span class="ltx_bibblock">Correlated network data publication via differential privacy.

</span>
<span class="ltx_bibblock"><em id="bib.bib71.1.1" class="ltx_emph ltx_font_italic">The VLDB Journal</em>, 23(4):653–676, 2014.

</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kasiviswanathan and Smith [2014]</span>
<span class="ltx_bibblock">
Shiva P Kasiviswanathan and Adam Smith.

</span>
<span class="ltx_bibblock">On the’semantics’ of differential privacy: A bayesian formulation.

</span>
<span class="ltx_bibblock"><em id="bib.bib72.1.1" class="ltx_emph ltx_font_italic">Journal of Privacy and Confidentiality</em>, 6(1), 2014.

</span>
</li>
<li id="bib.bib73" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wasserman and Zhou [2010]</span>
<span class="ltx_bibblock">
Larry Wasserman and Shuheng Zhou.

</span>
<span class="ltx_bibblock">A statistical framework for differential privacy.

</span>
<span class="ltx_bibblock"><em id="bib.bib73.1.1" class="ltx_emph ltx_font_italic">Journal of the American Statistical Association</em>, 105(489):375–389, 2010.

</span>
</li>
<li id="bib.bib74" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mironov [2017]</span>
<span class="ltx_bibblock">
Ilya Mironov.

</span>
<span class="ltx_bibblock">Rényi differential privacy.

</span>
<span class="ltx_bibblock">In <em id="bib.bib74.1.1" class="ltx_emph ltx_font_italic">2017 IEEE 30th Computer Security Foundations Symposium
(CSF)</em>, pages 263–275. IEEE, 2017.

</span>
</li>
<li id="bib.bib75" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Malek Esmaeili et al. [2021]</span>
<span class="ltx_bibblock">
Mani Malek Esmaeili, Ilya Mironov, Karthik Prasad, Igor Shilov, and Florian
Tramer.

</span>
<span class="ltx_bibblock">Antipodes of label differential privacy: Pate and alibi.

</span>
<span class="ltx_bibblock"><em id="bib.bib75.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, 34, 2021.

</span>
</li>
<li id="bib.bib76" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Duchi et al. [2013]</span>
<span class="ltx_bibblock">
John C Duchi, Michael I Jordan, and Martin J Wainwright.

</span>
<span class="ltx_bibblock">Local privacy and statistical minimax rates.

</span>
<span class="ltx_bibblock">In <em id="bib.bib76.1.1" class="ltx_emph ltx_font_italic">2013 IEEE 54th Annual Symposium on Foundations of Computer
Science</em>, pages 429–438. IEEE, 2013.

</span>
</li>
<li id="bib.bib77" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee and Clifton [2011]</span>
<span class="ltx_bibblock">
Jaewoo Lee and Chris Clifton.

</span>
<span class="ltx_bibblock">How much is enough? choosing <math id="bib.bib77.1.m1.1" class="ltx_Math" alttext="\varepsilon" display="inline"><semantics id="bib.bib77.1.m1.1a"><mi id="bib.bib77.1.m1.1.1" xref="bib.bib77.1.m1.1.1.cmml">ε</mi><annotation-xml encoding="MathML-Content" id="bib.bib77.1.m1.1b"><ci id="bib.bib77.1.m1.1.1.cmml" xref="bib.bib77.1.m1.1.1">𝜀</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib77.1.m1.1c">\varepsilon</annotation></semantics></math> for differential privacy.

</span>
<span class="ltx_bibblock">In <em id="bib.bib77.2.1" class="ltx_emph ltx_font_italic">International Conference on Information Security</em>, pages
325–340. Springer, 2011.

</span>
</li>
<li id="bib.bib78" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hsu et al. [2014]</span>
<span class="ltx_bibblock">
Justin Hsu, Marco Gaboardi, Andreas Haeberlen, Sanjeev Khanna, Arjun Narayan,
Benjamin C Pierce, and Aaron Roth.

</span>
<span class="ltx_bibblock">Differential privacy: An economic method for choosing epsilon.

</span>
<span class="ltx_bibblock">In <em id="bib.bib78.1.1" class="ltx_emph ltx_font_italic">2014 IEEE 27th Computer Security Foundations Symposium</em>,
pages 398–410. IEEE, 2014.

</span>
</li>
<li id="bib.bib79" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Abowd and Schmutte [2019]</span>
<span class="ltx_bibblock">
John M Abowd and Ian M Schmutte.

</span>
<span class="ltx_bibblock">An economic analysis of privacy protection and statistical accuracy
as social choices.

</span>
<span class="ltx_bibblock"><em id="bib.bib79.1.1" class="ltx_emph ltx_font_italic">American Economic Review</em>, 109(1):171–202,
2019.

</span>
</li>
<li id="bib.bib80" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Stadler et al. [2020]</span>
<span class="ltx_bibblock">
Theresa Stadler, Bristena Oprisanu, and Carmela Troncoso.

</span>
<span class="ltx_bibblock">Synthetic data–anonymisation groundhog day.

</span>
<span class="ltx_bibblock"><em id="bib.bib80.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2011.07018</em>, 2020.

</span>
</li>
<li id="bib.bib81" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Desfontaines and Pejó [2019]</span>
<span class="ltx_bibblock">
Damien Desfontaines and Balázs Pejó.

</span>
<span class="ltx_bibblock">Sok: differential privacies.

</span>
<span class="ltx_bibblock"><em id="bib.bib81.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1906.01337</em>, 2019.

</span>
</li>
<li id="bib.bib82" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ullman and Vadhan [2011]</span>
<span class="ltx_bibblock">
Jonathan Ullman and Salil Vadhan.

</span>
<span class="ltx_bibblock">Pcps and the hardness of generating private synthetic data.

</span>
<span class="ltx_bibblock">In <em id="bib.bib82.1.1" class="ltx_emph ltx_font_italic">Theory of Cryptography Conference</em>, pages 400–416.
Springer, 2011.

</span>
</li>
<li id="bib.bib83" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Choi et al. [2017]</span>
<span class="ltx_bibblock">
Edward Choi, Siddharth Biswal, Bradley Malin, Jon Duke, Walter F Stewart, and
Jimeng Sun.

</span>
<span class="ltx_bibblock">Generating multi-label discrete patient records using generative
adversarial networks.

</span>
<span class="ltx_bibblock">In <em id="bib.bib83.1.1" class="ltx_emph ltx_font_italic">Machine learning for healthcare conference</em>, pages 286–305.
PMLR, 2017.

</span>
</li>
<li id="bib.bib84" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Alaa et al. [2021]</span>
<span class="ltx_bibblock">
Ahmed M Alaa, Boris van Breugel, Evgeny Saveliev, and Mihaela van der Schaar.

</span>
<span class="ltx_bibblock">How faithful is your synthetic data? sample-level metrics for
evaluating and auditing generative models.

</span>
<span class="ltx_bibblock"><em id="bib.bib84.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2102.08921</em>, 2021.

</span>
</li>
<li id="bib.bib85" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Boedihardjo et al. [2021]</span>
<span class="ltx_bibblock">
March Boedihardjo, Thomas Strohmer, and Roman Vershynin.

</span>
<span class="ltx_bibblock">Covariance’s loss is privacy’s gain: Computationally efficient,
private and accurate synthetic data.

</span>
<span class="ltx_bibblock"><em id="bib.bib85.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2107.05824</em>, 2021.

</span>
</li>
<li id="bib.bib86" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ding et al. [2018]</span>
<span class="ltx_bibblock">
Zeyu Ding, Yuxin Wang, Guanhong Wang, Danfeng Zhang, and Daniel Kifer.

</span>
<span class="ltx_bibblock">Detecting violations of differential privacy.

</span>
<span class="ltx_bibblock">In <em id="bib.bib86.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 ACM SIGSAC Conference on Computer
and Communications Security</em>, pages 475–489, 2018.

</span>
</li>
<li id="bib.bib87" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jayaraman and Evans [2019]</span>
<span class="ltx_bibblock">
Bargav Jayaraman and David Evans.

</span>
<span class="ltx_bibblock">Evaluating differentially private machine learning in practice.

</span>
<span class="ltx_bibblock">In <em id="bib.bib87.4.4" class="ltx_emph ltx_font_italic">28th <math id="bib.bib87.1.1.m1.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib87.1.1.m1.1a"><mo stretchy="false" id="bib.bib87.1.1.m1.1.1" xref="bib.bib87.1.1.m1.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib87.1.1.m1.1b"><ci id="bib.bib87.1.1.m1.1.1.cmml" xref="bib.bib87.1.1.m1.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib87.1.1.m1.1c">\{</annotation></semantics></math>USENIX<math id="bib.bib87.2.2.m2.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib87.2.2.m2.1a"><mo stretchy="false" id="bib.bib87.2.2.m2.1.1" xref="bib.bib87.2.2.m2.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib87.2.2.m2.1b"><ci id="bib.bib87.2.2.m2.1.1.cmml" xref="bib.bib87.2.2.m2.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib87.2.2.m2.1c">\}</annotation></semantics></math> Security Symposium (<math id="bib.bib87.3.3.m3.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib87.3.3.m3.1a"><mo stretchy="false" id="bib.bib87.3.3.m3.1.1" xref="bib.bib87.3.3.m3.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib87.3.3.m3.1b"><ci id="bib.bib87.3.3.m3.1.1.cmml" xref="bib.bib87.3.3.m3.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib87.3.3.m3.1c">\{</annotation></semantics></math>USENIX<math id="bib.bib87.4.4.m4.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib87.4.4.m4.1a"><mo stretchy="false" id="bib.bib87.4.4.m4.1.1" xref="bib.bib87.4.4.m4.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib87.4.4.m4.1b"><ci id="bib.bib87.4.4.m4.1.1.cmml" xref="bib.bib87.4.4.m4.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib87.4.4.m4.1c">\}</annotation></semantics></math>
Security 19)</em>, pages 1895–1912, 2019.

</span>
</li>
<li id="bib.bib88" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jagielski et al. [2020]</span>
<span class="ltx_bibblock">
Matthew Jagielski, Jonathan Ullman, and Alina Oprea.

</span>
<span class="ltx_bibblock">Auditing differentially private machine learning: How private is
private sgd?

</span>
<span class="ltx_bibblock"><em id="bib.bib88.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2006.07709</em>, 2020.

</span>
</li>
<li id="bib.bib89" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chatzikokolakis et al. [2010]</span>
<span class="ltx_bibblock">
Konstantinos Chatzikokolakis, Tom Chothia, and Apratim Guha.

</span>
<span class="ltx_bibblock">Statistical measurement of information leakage.

</span>
<span class="ltx_bibblock">In <em id="bib.bib89.1.1" class="ltx_emph ltx_font_italic">International Conference on Tools and Algorithms for the
Construction and Analysis of Systems</em>, pages 390–404. Springer, 2010.

</span>
</li>
<li id="bib.bib90" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cherubin [2017]</span>
<span class="ltx_bibblock">
Giovanni Cherubin.

</span>
<span class="ltx_bibblock">Bayes, not naïve: Security bounds on website fingerprinting
defenses.

</span>
<span class="ltx_bibblock"><em id="bib.bib90.1.1" class="ltx_emph ltx_font_italic">Proceedings on Privacy Enhancing Technologies</em>, 4:135–151, 2017.

</span>
</li>
<li id="bib.bib91" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Smith [2009]</span>
<span class="ltx_bibblock">
Geoffrey Smith.

</span>
<span class="ltx_bibblock">On the foundations of quantitative information flow.

</span>
<span class="ltx_bibblock">In <em id="bib.bib91.1.1" class="ltx_emph ltx_font_italic">International Conference on Foundations of Software Science
and Computational Structures</em>, pages 288–302. Springer, 2009.

</span>
</li>
<li id="bib.bib92" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">M’rio et al. [2012]</span>
<span class="ltx_bibblock">
S Alvim M’rio, Kostas Chatzikokolakis, Catuscia Palamidessi, and Geoffrey
Smith.

</span>
<span class="ltx_bibblock">Measuring information leakage using generalized gain functions.

</span>
<span class="ltx_bibblock">In <em id="bib.bib92.1.1" class="ltx_emph ltx_font_italic">2012 IEEE 25th Computer Security Foundations Symposium</em>,
pages 265–279. IEEE, 2012.

</span>
</li>
<li id="bib.bib93" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cherubin et al. [2019]</span>
<span class="ltx_bibblock">
Giovanni Cherubin, Konstantinos Chatzikokolakis, and Catuscia Palamidessi.

</span>
<span class="ltx_bibblock">F-bleau: fast black-box leakage estimation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib93.1.1" class="ltx_emph ltx_font_italic">2019 IEEE Symposium on Security and Privacy (SP)</em>, pages
835–852. IEEE, 2019.

</span>
</li>
<li id="bib.bib94" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Platzer and Reutterer [2021]</span>
<span class="ltx_bibblock">
Michael Platzer and Thomas Reutterer.

</span>
<span class="ltx_bibblock">Holdout-based empirical assessment of mixed-type synthetic data.

</span>
<span class="ltx_bibblock"><em id="bib.bib94.1.1" class="ltx_emph ltx_font_italic">Frontiers in big Data</em>, 4, 2021.

</span>
</li>
<li id="bib.bib95" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[95]</span>
<span class="ltx_bibblock">
MOSTLY AI.

</span>
<span class="ltx_bibblock">Truly anonymous synthetic data - evolving legal definitions and
technologies (part ii), 2020.

</span>
<span class="ltx_bibblock">URL
<a target="_blank" href="https://mostly.ai/blog/truly-anonymous-synthetic-data-legal-definitions-part-ii/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://mostly.ai/blog/truly-anonymous-synthetic-data-legal-definitions-part-ii/</a>.

</span>
</li>
<li id="bib.bib96" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yoon et al. [2020]</span>
<span class="ltx_bibblock">
Jinsung Yoon, Lydia N Drumright, and Mihaela Van Der Schaar.

</span>
<span class="ltx_bibblock">Anonymization through data synthesis using generative adversarial
networks (ads-gan).

</span>
<span class="ltx_bibblock"><em id="bib.bib96.1.1" class="ltx_emph ltx_font_italic">IEEE journal of biomedical and health informatics</em>, 24(8):2378–2388, 2020.

</span>
</li>
<li id="bib.bib97" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yale et al. [2019]</span>
<span class="ltx_bibblock">
Andrew Yale, Saloni Dash, Ritik Dutta, Isabelle Guyon, Adrien Pavao, and
Kristin P Bennett.

</span>
<span class="ltx_bibblock">Assessing privacy and quality of synthetic health data.

</span>
<span class="ltx_bibblock">In <em id="bib.bib97.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Conference on Artificial Intelligence for
Data Discovery and Reuse</em>, pages 1–4, 2019.

</span>
</li>
<li id="bib.bib98" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Long et al. [2021]</span>
<span class="ltx_bibblock">
Yunhui Long, Boxin Wang, Zhuolin Yang, Bhavya Kailkhura, Aston Zhang, Carl
Gunter, and Bo Li.

</span>
<span class="ltx_bibblock">G-pate: Scalable differentially private data generator via private
aggregation of teacher discriminators.

</span>
<span class="ltx_bibblock"><em id="bib.bib98.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, 34, 2021.

</span>
</li>
<li id="bib.bib99" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yoon et al. [2019]</span>
<span class="ltx_bibblock">
Jinsung Yoon, Daniel Jarrett, and Mihaela van der Schaar.

</span>
<span class="ltx_bibblock">Time-series generative adversarial networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib99.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>,
32:5508–5518, 2019.

</span>
</li>
<li id="bib.bib100" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. [2020]</span>
<span class="ltx_bibblock">
Dingfan Chen, Ning Yu, Yang Zhang, and Mario Fritz.

</span>
<span class="ltx_bibblock">Gan-leaks: A taxonomy of membership inference attacks against
generative models.

</span>
<span class="ltx_bibblock">In <em id="bib.bib100.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020 ACM SIGSAC conference on computer
and communications security</em>, pages 343–362, 2020.

</span>
</li>
<li id="bib.bib101" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hayes et al. [2019]</span>
<span class="ltx_bibblock">
Jamie Hayes, Luca Melis, George Danezis, and Emiliano De Cristofaro.

</span>
<span class="ltx_bibblock">Logan: Membership inference attacks against generative models.

</span>
<span class="ltx_bibblock">In <em id="bib.bib101.1.1" class="ltx_emph ltx_font_italic">Proceedings on Privacy Enhancing Technologies (PoPETs)</em>,
volume 2019, pages 133–152. De Gruyter, 2019.

</span>
</li>
<li id="bib.bib102" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Homer et al. [2008]</span>
<span class="ltx_bibblock">
Nils Homer, Szabolcs Szelinger, Margot Redman, David Duggan, Waibhav Tembe,
Jill Muehling, John V Pearson, Dietrich A Stephan, Stanley F Nelson, and
David W Craig.

</span>
<span class="ltx_bibblock">Resolving individuals contributing trace amounts of dna to highly
complex mixtures using high-density snp genotyping microarrays.

</span>
<span class="ltx_bibblock"><em id="bib.bib102.1.1" class="ltx_emph ltx_font_italic">PLoS genetics</em>, 4(8):e1000167, 2008.

</span>
</li>
<li id="bib.bib103" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dwork et al. [2015]</span>
<span class="ltx_bibblock">
Cynthia Dwork, Adam Smith, Thomas Steinke, Jonathan Ullman, and Salil Vadhan.

</span>
<span class="ltx_bibblock">Robust traceability from trace amounts.

</span>
<span class="ltx_bibblock">In <em id="bib.bib103.1.1" class="ltx_emph ltx_font_italic">2015 IEEE 56th Annual Symposium on Foundations of Computer
Science</em>, pages 650–669. IEEE, 2015.

</span>
</li>
<li id="bib.bib104" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pyrgelis et al. [2017]</span>
<span class="ltx_bibblock">
Apostolos Pyrgelis, Carmela Troncoso, and Emiliano De Cristofaro.

</span>
<span class="ltx_bibblock">Knock knock, who’s there? membership inference on aggregate location
data.

</span>
<span class="ltx_bibblock"><em id="bib.bib104.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1708.06145</em>, 2017.

</span>
</li>
<li id="bib.bib105" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Beaulieu-Jones et al. [2019]</span>
<span class="ltx_bibblock">
Brett K Beaulieu-Jones, Zhiwei Steven Wu, Chris Williams, Ran Lee, Sanjeev P
Bhavnani, James Brian Byrd, and Casey S Greene.

</span>
<span class="ltx_bibblock">Privacy-preserving generative deep neural networks support clinical
data sharing.

</span>
<span class="ltx_bibblock"><em id="bib.bib105.1.1" class="ltx_emph ltx_font_italic">Circulation: Cardiovascular Quality and Outcomes</em>, 12(7):e005122, 2019.

</span>
</li>
<li id="bib.bib106" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Patki et al. [2016]</span>
<span class="ltx_bibblock">
Neha Patki, Roy Wedge, and Kalyan Veeramachaneni.

</span>
<span class="ltx_bibblock">The Synthetic Data Vault.

</span>
<span class="ltx_bibblock">In <em id="bib.bib106.1.1" class="ltx_emph ltx_font_italic">2016 IEEE International Conference on Data Science
and Advanced Analytics (DSAA)</em>, Montreal, QC, Canada, October 2016.
IEEE.

</span>
<span class="ltx_bibblock">ISBN 978-1-5090-5206-6.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1109/DSAA.2016.49</span>.

</span>
</li>
<li id="bib.bib107" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tao et al. [2021]</span>
<span class="ltx_bibblock">
Yuchao Tao, Ryan McKenna, Michael Hay, Ashwin Machanavajjhala, and Gerome
Miklau.

</span>
<span class="ltx_bibblock">Benchmarking differentially private synthetic data generation
algorithms.

</span>
<span class="ltx_bibblock"><em id="bib.bib107.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2112.09238</em>, 2021.

</span>
</li>
<li id="bib.bib108" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bowen and Snoke [2021]</span>
<span class="ltx_bibblock">
Claire McKay Bowen and Joshua Snoke.

</span>
<span class="ltx_bibblock">Comparative study of differentially private synthetic data algorithms
from the nist pscr differential privacy synthetic data challenge.

</span>
<span class="ltx_bibblock"><em id="bib.bib108.1.1" class="ltx_emph ltx_font_italic">Journal of Privacy and Confidentiality</em>, 11(1), Feb.
2021.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.29012/jpc.748</span>.

</span>
<span class="ltx_bibblock">URL
<a target="_blank" href="https://journalprivacyconfidentiality.org/index.php/jpc/article/view/748" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://journalprivacyconfidentiality.org/index.php/jpc/article/view/748</a>.

</span>
</li>
<li id="bib.bib109" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jordon et al. [2018b]</span>
<span class="ltx_bibblock">
James Jordon, Jinsung Yoon, and Mihaela van der Schaar.

</span>
<span class="ltx_bibblock">Measuring the quality of synthetic data for use in competitions.

</span>
<span class="ltx_bibblock"><em id="bib.bib109.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1806.11345</em>, 2018b.

</span>
</li>
<li id="bib.bib110" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Woo et al. [2009]</span>
<span class="ltx_bibblock">
Mi-Ja Woo, Jerome P Reiter, Anna Oganian, and Alan F Karr.

</span>
<span class="ltx_bibblock">Global measures of data utility for microdata masked for disclosure
limitation.

</span>
<span class="ltx_bibblock"><em id="bib.bib110.1.1" class="ltx_emph ltx_font_italic">Journal of Privacy and Confidentiality</em>, 1(1), 2009.

</span>
</li>
<li id="bib.bib111" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Snoke et al. [2018]</span>
<span class="ltx_bibblock">
Joshua Snoke, Gillian M Raab, Beata Nowok, Chris Dibben, and Aleksandra
Slavkovic.

</span>
<span class="ltx_bibblock">General and specific utility measures for synthetic data.

</span>
<span class="ltx_bibblock"><em id="bib.bib111.1.1" class="ltx_emph ltx_font_italic">Journal of the Royal Statistical Society: Series A (Statistics
in Society)</em>, 181(3):663–688, 2018.

</span>
</li>
<li id="bib.bib112" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sajjadi et al. [2018]</span>
<span class="ltx_bibblock">
Mehdi SM Sajjadi, Olivier Bachem, Mario Lucic, Olivier Bousquet, and Sylvain
Gelly.

</span>
<span class="ltx_bibblock">Assessing generative models via precision and recall.

</span>
<span class="ltx_bibblock"><em id="bib.bib112.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1806.00035</em>, 2018.

</span>
</li>
<li id="bib.bib113" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Naeem et al. [2020]</span>
<span class="ltx_bibblock">
Muhammad Ferjad Naeem, Seong Joon Oh, Youngjung Uh, Yunjey Choi, and Jaejun
Yoo.

</span>
<span class="ltx_bibblock">Reliable fidelity and diversity metrics for generative models.

</span>
<span class="ltx_bibblock">In <em id="bib.bib113.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>, pages
7176–7185. PMLR, 2020.

</span>
</li>
<li id="bib.bib114" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. [2018a]</span>
<span class="ltx_bibblock">
Xinyang Zhang, Shouling Ji, and Ting Wang.

</span>
<span class="ltx_bibblock">Differentially private releasing via deep generative model (technical
report).

</span>
<span class="ltx_bibblock"><em id="bib.bib114.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1801.01594</em>, 2018a.

</span>
</li>
<li id="bib.bib115" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Acs et al. [2018]</span>
<span class="ltx_bibblock">
Gergely Acs, Luca Melis, Claude Castelluccia, and Emiliano De Cristofaro.

</span>
<span class="ltx_bibblock">Differentially private mixture of generative neural networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib115.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Knowledge and Data Engineering</em>,
31(6):1109–1121, 2018.

</span>
</li>
<li id="bib.bib116" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Oprisanu et al. [2021]</span>
<span class="ltx_bibblock">
Bristena Oprisanu, Georgi Ganev, and Emiliano De Cristofaro.

</span>
<span class="ltx_bibblock">Measuring utility and privacy of synthetic genomic data.

</span>
<span class="ltx_bibblock"><em id="bib.bib116.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2102.03314</em>, 2021.

</span>
</li>
<li id="bib.bib117" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pereira et al. [2021]</span>
<span class="ltx_bibblock">
Mayana Pereira, Meghana Kshirsagar, Sumit Mukherjee, Rahul Dodhia, and
Juan Lavista Ferres.

</span>
<span class="ltx_bibblock">An analysis of the deployment of models trained on private tabular
synthetic data: Unexpected surprises.

</span>
<span class="ltx_bibblock"><em id="bib.bib117.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2106.10241</em>, 2021.

</span>
</li>
<li id="bib.bib118" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ganev et al. [2021]</span>
<span class="ltx_bibblock">
Georgi Ganev, Bristena Oprisanu, and Emiliano De Cristofaro.

</span>
<span class="ltx_bibblock">Robin hood and matthew effects–differential privacy has disparate
impact on synthetic data.

</span>
<span class="ltx_bibblock"><em id="bib.bib118.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2109.11429</em>, 2021.

</span>
</li>
<li id="bib.bib119" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cheng et al. [2021]</span>
<span class="ltx_bibblock">
Victoria Cheng, Vinith M Suriyakumar, Natalie Dullerud, Shalmali Joshi, and
Marzyeh Ghassemi.

</span>
<span class="ltx_bibblock">Can you fake it until you make it? impacts of differentially private
synthetic data on downstream classification fairness.

</span>
<span class="ltx_bibblock">In <em id="bib.bib119.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2021 ACM Conference on Fairness,
Accountability, and Transparency</em>, pages 149–160, 2021.

</span>
</li>
<li id="bib.bib120" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. [2018]</span>
<span class="ltx_bibblock">
Qingrong Chen, Chong Xiang, Minhui Xue, Bo Li, Nikita Borisov, Dali Kaarfar,
and Haojin Zhu.

</span>
<span class="ltx_bibblock">Differentially private data generative models.

</span>
<span class="ltx_bibblock"><em id="bib.bib120.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1812.02274</em>, 2018.

</span>
</li>
<li id="bib.bib121" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Abay et al. [2018]</span>
<span class="ltx_bibblock">
Nazmiye Ceren Abay, Yan Zhou, Murat Kantarcioglu, Bhavani Thuraisingham, and
Latanya Sweeney.

</span>
<span class="ltx_bibblock">Privacy preserving synthetic data release using deep learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib121.1.1" class="ltx_emph ltx_font_italic">Joint European Conference on Machine Learning and Knowledge
Discovery in Databases</em>, pages 510–526. Springer, 2018.

</span>
</li>
<li id="bib.bib122" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Park et al. [2017]</span>
<span class="ltx_bibblock">
Mijung Park, James Foulds, Kamalika Choudhary, and Max Welling.

</span>
<span class="ltx_bibblock">Dp-em: Differentially private expectation maximization.

</span>
<span class="ltx_bibblock">In <em id="bib.bib122.1.1" class="ltx_emph ltx_font_italic">Artificial Intelligence and Statistics</em>, pages 896–904.
PMLR, 2017.

</span>
</li>
<li id="bib.bib123" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nelsen [2007]</span>
<span class="ltx_bibblock">
Roger B Nelsen.

</span>
<span class="ltx_bibblock"><em id="bib.bib123.1.1" class="ltx_emph ltx_font_italic">An introduction to copulas</em>.

</span>
<span class="ltx_bibblock">Springer Science &amp; Business Media, 2007.

</span>
</li>
<li id="bib.bib124" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. [2014]</span>
<span class="ltx_bibblock">
Haoran Li, Li Xiong, and Xiaoqian Jiang.

</span>
<span class="ltx_bibblock">Differentially private synthesization of multi-dimensional data using
copula functions.

</span>
<span class="ltx_bibblock">In <em id="bib.bib124.1.1" class="ltx_emph ltx_font_italic">Advances in database technology: proceedings. International
conference on extending database technology</em>, volume 2014, page 475. NIH
Public Access, 2014.

</span>
</li>
<li id="bib.bib125" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. [2021]</span>
<span class="ltx_bibblock">
Zhikun Zhang, Tianhao Wang, Ninghui Li, Jean Honorio, Michael Backes, Shibo He,
Jiming Chen, and Yang Zhang.

</span>
<span class="ltx_bibblock">Privsyn: Differentially private data synthesis.

</span>
<span class="ltx_bibblock">In <em id="bib.bib125.4.4" class="ltx_emph ltx_font_italic">30th <math id="bib.bib125.1.1.m1.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib125.1.1.m1.1a"><mo stretchy="false" id="bib.bib125.1.1.m1.1.1" xref="bib.bib125.1.1.m1.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib125.1.1.m1.1b"><ci id="bib.bib125.1.1.m1.1.1.cmml" xref="bib.bib125.1.1.m1.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib125.1.1.m1.1c">\{</annotation></semantics></math>USENIX<math id="bib.bib125.2.2.m2.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib125.2.2.m2.1a"><mo stretchy="false" id="bib.bib125.2.2.m2.1.1" xref="bib.bib125.2.2.m2.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib125.2.2.m2.1b"><ci id="bib.bib125.2.2.m2.1.1.cmml" xref="bib.bib125.2.2.m2.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib125.2.2.m2.1c">\}</annotation></semantics></math> Security Symposium (<math id="bib.bib125.3.3.m3.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib125.3.3.m3.1a"><mo stretchy="false" id="bib.bib125.3.3.m3.1.1" xref="bib.bib125.3.3.m3.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib125.3.3.m3.1b"><ci id="bib.bib125.3.3.m3.1.1.cmml" xref="bib.bib125.3.3.m3.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib125.3.3.m3.1c">\{</annotation></semantics></math>USENIX<math id="bib.bib125.4.4.m4.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib125.4.4.m4.1a"><mo stretchy="false" id="bib.bib125.4.4.m4.1.1" xref="bib.bib125.4.4.m4.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib125.4.4.m4.1b"><ci id="bib.bib125.4.4.m4.1.1.cmml" xref="bib.bib125.4.4.m4.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib125.4.4.m4.1c">\}</annotation></semantics></math>
Security 21)</em>, 2021.

</span>
</li>
<li id="bib.bib126" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rubin [1996]</span>
<span class="ltx_bibblock">
Donald B Rubin.

</span>
<span class="ltx_bibblock">Multiple imputation after 18+ years.

</span>
<span class="ltx_bibblock"><em id="bib.bib126.1.1" class="ltx_emph ltx_font_italic">Journal of the American statistical Association</em>, 91(434):473–489, 1996.

</span>
</li>
<li id="bib.bib127" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Reiter [2005]</span>
<span class="ltx_bibblock">
Jerome P Reiter.

</span>
<span class="ltx_bibblock">Using cart to generate partially synthetic public use microdata.

</span>
<span class="ltx_bibblock"><em id="bib.bib127.1.1" class="ltx_emph ltx_font_italic">Journal of Official Statistics</em>, 21(3):441,
2005.

</span>
</li>
<li id="bib.bib128" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Caiola and Reiter [2010a]</span>
<span class="ltx_bibblock">
Gregory Caiola and Jerome P Reiter.

</span>
<span class="ltx_bibblock">Random forests for generating partially synthetic, categorical data.

</span>
<span class="ltx_bibblock"><em id="bib.bib128.1.1" class="ltx_emph ltx_font_italic">Trans. Data Priv.</em>, 3(1):27–42,
2010a.

</span>
</li>
<li id="bib.bib129" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nowok et al. [2016]</span>
<span class="ltx_bibblock">
Beata Nowok, Gillian M Raab, and Chris Dibben.

</span>
<span class="ltx_bibblock">synthpop: Bespoke creation of synthetic data in r.

</span>
<span class="ltx_bibblock"><em id="bib.bib129.1.1" class="ltx_emph ltx_font_italic">Journal of statistical software</em>, 74(1):1–26, 2016.

</span>
</li>
<li id="bib.bib130" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Loong et al. [2013]</span>
<span class="ltx_bibblock">
Bronwyn Loong, Alan M Zaslavsky, Yulei He, and David P Harrington.

</span>
<span class="ltx_bibblock">Disclosure control using partially synthetic data for large-scale
health surveys, with applications to cancors.

</span>
<span class="ltx_bibblock"><em id="bib.bib130.1.1" class="ltx_emph ltx_font_italic">Statistics in medicine</em>, 32(24):4139–4161,
2013.

</span>
</li>
<li id="bib.bib131" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Abowd and Woodcock [2001]</span>
<span class="ltx_bibblock">
John M Abowd and Simon D Woodcock.

</span>
<span class="ltx_bibblock">Disclosure limitation in longitudinal linked data.

</span>
<span class="ltx_bibblock"><em id="bib.bib131.1.1" class="ltx_emph ltx_font_italic">Confidentiality, Disclosure, and Data Access: Theory and
Practical Applications for Statistical Agencies</em>, 215277, 2001.

</span>
</li>
<li id="bib.bib132" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Drechsler and Reiter [2008]</span>
<span class="ltx_bibblock">
Jörg Drechsler and Jerome P Reiter.

</span>
<span class="ltx_bibblock">Accounting for intruder uncertainty due to sampling when estimating
identification disclosure risks in partially synthetic data.

</span>
<span class="ltx_bibblock">In <em id="bib.bib132.1.1" class="ltx_emph ltx_font_italic">International conference on privacy in statistical
databases</em>, pages 227–238. Springer, 2008.

</span>
</li>
<li id="bib.bib133" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Reiter and Mitra [2009]</span>
<span class="ltx_bibblock">
Jerome P Reiter and Robin Mitra.

</span>
<span class="ltx_bibblock">Estimating risks of identification disclosure in partially synthetic
data.

</span>
<span class="ltx_bibblock"><em id="bib.bib133.1.1" class="ltx_emph ltx_font_italic">Journal of Privacy and Confidentiality</em>, 1(1), 2009.

</span>
</li>
<li id="bib.bib134" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chaudhuri and Hsu [2011]</span>
<span class="ltx_bibblock">
Kamalika Chaudhuri and Daniel Hsu.

</span>
<span class="ltx_bibblock">Sample complexity bounds for differentially private learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib134.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 24th Annual Conference on Learning
Theory</em>, pages 155–186. JMLR Workshop and Conference Proceedings, 2011.

</span>
</li>
<li id="bib.bib135" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tashea [2017]</span>
<span class="ltx_bibblock">
Jason Tashea.

</span>
<span class="ltx_bibblock">Courts are using AI to sentence criminals. That must stop now.,
2017.

</span>
<span class="ltx_bibblock">URL
<a target="_blank" href="https://www.wired.com/2017/04/courts-using-ai-sentence-criminals-must-stop-now/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.wired.com/2017/04/courts-using-ai-sentence-criminals-must-stop-now/</a>.

</span>
</li>
<li id="bib.bib136" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lu et al. [2020]</span>
<span class="ltx_bibblock">
Kaiji Lu, Piotr Mardziel, Fangjing Wu, Preetam Amancharla, and Anupam Datta.

</span>
<span class="ltx_bibblock">Gender bias in neural natural language processing.

</span>
<span class="ltx_bibblock">In <em id="bib.bib136.1.1" class="ltx_emph ltx_font_italic">Logic, Language, and Security</em>, pages 189–202. Springer,
2020.

</span>
</li>
<li id="bib.bib137" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Buolamwini and Gebru [2018]</span>
<span class="ltx_bibblock">
Joy Buolamwini and Timnit Gebru.

</span>
<span class="ltx_bibblock">Gender shades: Intersectional accuracy disparities in commercial
gender classification.

</span>
<span class="ltx_bibblock">In <em id="bib.bib137.1.1" class="ltx_emph ltx_font_italic">Conference on fairness, accountability and transparency</em>,
pages 77–91. PMLR, 2018.

</span>
</li>
<li id="bib.bib138" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dastin [2018]</span>
<span class="ltx_bibblock">
Jeffrey Dastin.

</span>
<span class="ltx_bibblock">Amazon scraps secret AI recruiting tool that showed bias against
women., 2018.

</span>
<span class="ltx_bibblock">URL
<a target="_blank" href="https://www.reuters.com/article/us-amazon-com-jobs-automation-insight-idUSKCN1MK08G" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.reuters.com/article/us-amazon-com-jobs-automation-insight-idUSKCN1MK08G</a>.

</span>
</li>
<li id="bib.bib139" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hardt et al. [2016]</span>
<span class="ltx_bibblock">
Moritz Hardt, Eric Price, and Nati Srebro.

</span>
<span class="ltx_bibblock">Equality of opportunity in supervised learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib139.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>,
29:3315–3323, 2016.

</span>
</li>
<li id="bib.bib140" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kilbertus et al. [2017]</span>
<span class="ltx_bibblock">
Niki Kilbertus, Mateo Rojas-Carulla, Giambattista Parascandolo, Moritz Hardt,
Dominik Janzing, and Bernhard Schölkopf.

</span>
<span class="ltx_bibblock">Avoiding discrimination through causal reasoning.

</span>
<span class="ltx_bibblock"><em id="bib.bib140.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1706.02744</em>, 2017.

</span>
</li>
<li id="bib.bib141" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Grgic-Hlaca et al. [2016]</span>
<span class="ltx_bibblock">
Nina Grgic-Hlaca, Muhammad Bilal Zafar, Krishna P Gummadi, and Adrian Weller.

</span>
<span class="ltx_bibblock">The case for process fairness in learning: Feature selection for fair
decision making.

</span>
<span class="ltx_bibblock">In <em id="bib.bib141.1.1" class="ltx_emph ltx_font_italic">NIPS symposium on machine learning and the law</em>, volume 1,
page 2, 2016.

</span>
</li>
<li id="bib.bib142" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zafar et al. [2017]</span>
<span class="ltx_bibblock">
Muhammad Bilal Zafar, Isabel Valera, Manuel Gomez Rogriguez, and Krishna P
Gummadi.

</span>
<span class="ltx_bibblock">Fairness constraints: Mechanisms for fair classification.

</span>
<span class="ltx_bibblock">In <em id="bib.bib142.1.1" class="ltx_emph ltx_font_italic">Artificial Intelligence and Statistics</em>, pages 962–970.
PMLR, 2017.

</span>
</li>
<li id="bib.bib143" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mehrabi et al. [2021]</span>
<span class="ltx_bibblock">
Ninareh Mehrabi, Fred Morstatter, Nripsuta Saxena, Kristina Lerman, and Aram
Galstyan.

</span>
<span class="ltx_bibblock">A survey on bias and fairness in machine learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib143.1.1" class="ltx_emph ltx_font_italic">ACM Computing Surveys (CSUR)</em>, 54(6):1–35,
2021.

</span>
</li>
<li id="bib.bib144" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wen et al. [2020]</span>
<span class="ltx_bibblock">
Qingsong Wen, Liang Sun, Fan Yang, Xiaomin Song, Jingkun Gao, Xue Wang, and
Huan Xu.

</span>
<span class="ltx_bibblock">Time series data augmentation for deep learning: A survey.

</span>
<span class="ltx_bibblock"><em id="bib.bib144.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2002.12478</em>, 2020.

</span>
</li>
<li id="bib.bib145" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shorten and Khoshgoftaar [2019]</span>
<span class="ltx_bibblock">
Connor Shorten and Taghi M Khoshgoftaar.

</span>
<span class="ltx_bibblock">A survey on image data augmentation for deep learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib145.1.1" class="ltx_emph ltx_font_italic">Journal of Big Data</em>, 6(1):1–48, 2019.

</span>
</li>
<li id="bib.bib146" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">LeCun et al. [2015]</span>
<span class="ltx_bibblock">
Yann LeCun, Yoshua Bengio, and Geoffrey Hinton.

</span>
<span class="ltx_bibblock">Deep learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib146.1.1" class="ltx_emph ltx_font_italic">nature</em>, 521(7553):436, 2015.

</span>
</li>
<li id="bib.bib147" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Goodfellow [2017]</span>
<span class="ltx_bibblock">
Ian Goodfellow.

</span>
<span class="ltx_bibblock">NIPS 2016 Tutorial: Generative Adversarial Networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib147.1.1" class="ltx_emph ltx_font_italic">arXiv:1701.00160 [cs]</em>, 2017.

</span>
</li>
<li id="bib.bib148" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Frey et al. [1996]</span>
<span class="ltx_bibblock">
Brendan J Frey, Geoffrey E Hinton, and Peter Dayan.

</span>
<span class="ltx_bibblock">Does the Wake-sleep Algorithm Produce Good Density
Estimators?

</span>
<span class="ltx_bibblock">In <em id="bib.bib148.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>,
volume 8, 1996.

</span>
</li>
<li id="bib.bib149" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Breiman et al. [2017]</span>
<span class="ltx_bibblock">
Leo Breiman, Jerome H Friedman, Richard A Olshen, and Charles J Stone.

</span>
<span class="ltx_bibblock"><em id="bib.bib149.1.1" class="ltx_emph ltx_font_italic">Classification and regression trees</em>.

</span>
<span class="ltx_bibblock">Routledge, 2017.

</span>
</li>
<li id="bib.bib150" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rasmussen [1999]</span>
<span class="ltx_bibblock">
Carl Edward Rasmussen.

</span>
<span class="ltx_bibblock">The infinite gaussian mixture model.

</span>
<span class="ltx_bibblock">In <em id="bib.bib150.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 12th International Conference on Neural
Information Processing Systems</em>, NIPS’99, page 554–560, Cambridge, MA, USA,
1999. MIT Press.

</span>
</li>
<li id="bib.bib151" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et al. [2009]</span>
<span class="ltx_bibblock">
Liangxiao Jiang, Harry Zhang, and Zhihua Cai.

</span>
<span class="ltx_bibblock">A novel bayes model: Hidden naive bayes.

</span>
<span class="ltx_bibblock"><em id="bib.bib151.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Knowledge and Data Engineering</em>,
21(10):1361–1371, 2009.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1109/TKDE.2008.234</span>.

</span>
</li>
<li id="bib.bib152" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Salakhutdinov and Hinton [2009]</span>
<span class="ltx_bibblock">
Ruslan Salakhutdinov and Geoffrey Hinton.

</span>
<span class="ltx_bibblock">Deep Boltzmann Machines.

</span>
<span class="ltx_bibblock">In David van Dyk and Max Welling, editors, <em id="bib.bib152.1.1" class="ltx_emph ltx_font_italic">Proceedings of the
Twelth International Conference on Artificial Intelligence and
Statistics</em>, volume 5 of <em id="bib.bib152.2.2" class="ltx_emph ltx_font_italic">Proceedings of Machine Learning
Research</em>, pages 448–455, Hilton Clearwater Beach Resort, Clearwater
Beach, Florida USA, April 2009. PMLR.

</span>
</li>
<li id="bib.bib153" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Salakhutdinov et al. [2007]</span>
<span class="ltx_bibblock">
Ruslan Salakhutdinov, Andriy Mnih, and Geoffrey Hinton.

</span>
<span class="ltx_bibblock">Restricted Boltzmann machines for collaborative filtering.

</span>
<span class="ltx_bibblock">In <em id="bib.bib153.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 24th international conference on
Machine learning</em>, ICML ’07, pages 791–798, New York, NY, USA, June
2007. Association for Computing Machinery.

</span>
<span class="ltx_bibblock">ISBN 978-1-59593-793-3.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1145/1273496.1273596</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://doi.org/10.1145/1273496.1273596" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/1273496.1273596</a>.

</span>
</li>
<li id="bib.bib154" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Salimans et al. [2016]</span>
<span class="ltx_bibblock">
Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and
Xi Chen.

</span>
<span class="ltx_bibblock">Improved Techniques for Training GANs.

</span>
<span class="ltx_bibblock"><em id="bib.bib154.1.1" class="ltx_emph ltx_font_italic">arXiv:1606.03498 [cs]</em>, June 2016.

</span>
</li>
<li id="bib.bib155" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Arjovsky et al. [2017]</span>
<span class="ltx_bibblock">
Martin Arjovsky, Soumith Chintala, and Léon Bottou.

</span>
<span class="ltx_bibblock">Wasserstein GAN.

</span>
<span class="ltx_bibblock"><em id="bib.bib155.1.1" class="ltx_emph ltx_font_italic">arXiv:1701.07875 [cs, stat]</em>, December 2017.

</span>
</li>
<li id="bib.bib156" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. [2017a]</span>
<span class="ltx_bibblock">
Chun-Liang Li, Wei-Cheng Chang, Yu Cheng, Yiming Yang, and Barnabás
Póczos.

</span>
<span class="ltx_bibblock">Mmd gan: Towards deeper understanding of moment matching network.

</span>
<span class="ltx_bibblock"><em id="bib.bib156.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, 30,
2017a.

</span>
</li>
<li id="bib.bib157" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bińkowski et al. [2018]</span>
<span class="ltx_bibblock">
Mikołaj Bińkowski, Danica J Sutherland, Michael Arbel, and Arthur
Gretton.

</span>
<span class="ltx_bibblock">Demystifying mmd gans.

</span>
<span class="ltx_bibblock"><em id="bib.bib157.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1801.01401</em>, 2018.

</span>
</li>
<li id="bib.bib158" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nowozin et al. [2016]</span>
<span class="ltx_bibblock">
Sebastian Nowozin, Botond Cseke, and Ryota Tomioka.

</span>
<span class="ltx_bibblock">f-GAN: Training Generative Neural Samplers using
Variational Divergence Minimization.

</span>
<span class="ltx_bibblock"><em id="bib.bib158.1.1" class="ltx_emph ltx_font_italic">arXiv:1606.00709 [cs, stat]</em>, June 2016.

</span>
</li>
<li id="bib.bib159" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lucic et al. [2018]</span>
<span class="ltx_bibblock">
Mario Lucic, Karol Kurach, Marcin Michalski, Olivier Bousquet, and Sylvain
Gelly.

</span>
<span class="ltx_bibblock">Are GANs created equal? a large-scale study.

</span>
<span class="ltx_bibblock">In <em id="bib.bib159.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 32nd International Conference on
Neural Information Processing Systems</em>, NIPS’18, pages 698–707,
Red Hook, NY, USA, December 2018. Curran Associates Inc.

</span>
</li>
<li id="bib.bib160" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mirza and Osindero [2014]</span>
<span class="ltx_bibblock">
Mehdi Mirza and Simon Osindero.

</span>
<span class="ltx_bibblock">Conditional Generative Adversarial Nets.

</span>
<span class="ltx_bibblock"><em id="bib.bib160.1.1" class="ltx_emph ltx_font_italic">arXiv:1411.1784 [cs, stat]</em>, November 2014.

</span>
</li>
<li id="bib.bib161" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford et al. [2016]</span>
<span class="ltx_bibblock">
Alec Radford, Luke Metz, and Soumith Chintala.

</span>
<span class="ltx_bibblock">Unsupervised Representation Learning with Deep Convolutional
Generative Adversarial Networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib161.1.1" class="ltx_emph ltx_font_italic">arXiv:1511.06434 [cs]</em>, January 2016.

</span>
</li>
<li id="bib.bib162" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. [2016]</span>
<span class="ltx_bibblock">
Xi Chen, Yan Duan, Rein Houthooft, John Schulman, Ilya Sutskever, and Pieter
Abbeel.

</span>
<span class="ltx_bibblock">InfoGAN: Interpretable Representation Learning by
Information Maximizing Generative Adversarial Nets.

</span>
<span class="ltx_bibblock"><em id="bib.bib162.1.1" class="ltx_emph ltx_font_italic">arXiv:1606.03657 [cs, stat]</em>, June 2016.

</span>
</li>
<li id="bib.bib163" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. [2015]</span>
<span class="ltx_bibblock">
Yujia Li, Kevin Swersky, and Richard S. Zemel.

</span>
<span class="ltx_bibblock">Generative moment matching networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib163.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/1502.02761, 2015.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="http://arxiv.org/abs/1502.02761" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/1502.02761</a>.

</span>
</li>
<li id="bib.bib164" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Caiola and Reiter [2010b]</span>
<span class="ltx_bibblock">
Gregory Caiola and Jerome P. Reiter.

</span>
<span class="ltx_bibblock">Random Forests for Generating Partially Synthetic,
Categorical Data.

</span>
<span class="ltx_bibblock"><em id="bib.bib164.1.1" class="ltx_emph ltx_font_italic">Trans. Data Priv.</em>, 2010b.

</span>
</li>
<li id="bib.bib165" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Drechsler [2010]</span>
<span class="ltx_bibblock">
Jörg Drechsler.

</span>
<span class="ltx_bibblock">Using Support Vector Machines for Generating Synthetic
Datasets.

</span>
<span class="ltx_bibblock">In Josep Domingo-Ferrer and Emmanouil Magkos, editors, <em id="bib.bib165.1.1" class="ltx_emph ltx_font_italic">Privacy
in Statistical Databases</em>, Lecture Notes in Computer Science, pages
148–161, Berlin, Heidelberg, 2010. Springer.

</span>
<span class="ltx_bibblock">ISBN 978-3-642-15838-4.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1007/978-3-642-15838-4˙14</span>.

</span>
</li>
<li id="bib.bib166" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Eno and Thompson [2008]</span>
<span class="ltx_bibblock">
Joshua Eno and Craig Thompson.

</span>
<span class="ltx_bibblock">Generating Synthetic Data to Match Data Mining Patterns.

</span>
<span class="ltx_bibblock"><em id="bib.bib166.1.1" class="ltx_emph ltx_font_italic">Internet Computing, IEEE</em>, 12:78–82, June 2008.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1109/MIC.2008.55</span>.

</span>
</li>
<li id="bib.bib167" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Choi et al. [2018]</span>
<span class="ltx_bibblock">
Edward Choi, Siddharth Biswal, Bradley Malin, Jon Duke, Walter F. Stewart, and
Jimeng Sun.

</span>
<span class="ltx_bibblock">Generating Multi-label Discrete Patient Records using
Generative Adversarial Networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib167.1.1" class="ltx_emph ltx_font_italic">arXiv:1703.06490 [cs]</em>, January 2018.

</span>
</li>
<li id="bib.bib168" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al. [2019]</span>
<span class="ltx_bibblock">
Lei Xu, Maria Skoularidou, Alfredo Cuesta-Infante, and Kalyan Veeramachaneni.

</span>
<span class="ltx_bibblock">Modeling Tabular data using Conditional GAN.

</span>
<span class="ltx_bibblock"><em id="bib.bib168.1.1" class="ltx_emph ltx_font_italic">arXiv:1907.00503 [cs, stat]</em>, October 2019.

</span>
</li>
<li id="bib.bib169" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al. [2021b]</span>
<span class="ltx_bibblock">
Zilong Zhao, Aditya Kunar, Hiek Van der Scheer, Robert Birke, and Lydia Y.
Chen.

</span>
<span class="ltx_bibblock">CTAB-GAN: Effective Table Data Synthesizing.

</span>
<span class="ltx_bibblock"><em id="bib.bib169.1.1" class="ltx_emph ltx_font_italic">arXiv:2102.08369 [cs]</em>, May 2021b.

</span>
</li>
<li id="bib.bib170" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Park et al. [2018]</span>
<span class="ltx_bibblock">
Noseong Park, Mahmoud Mohammadi, Kshitij Gorde, Sushil Jajodia, Hongkyu Park,
and Youngmin Kim.

</span>
<span class="ltx_bibblock">Data Synthesis based on Generative Adversarial Networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib170.1.1" class="ltx_emph ltx_font_italic">Proceedings of the VLDB Endowment</em>, 11(10), June
2018.

</span>
<span class="ltx_bibblock">ISSN 2150-8097.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.14778/3231751.3231757</span>.

</span>
</li>
<li id="bib.bib171" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu and Veeramachaneni [2018]</span>
<span class="ltx_bibblock">
Lei Xu and Kalyan Veeramachaneni.

</span>
<span class="ltx_bibblock">Synthesizing Tabular Data using Generative Adversarial
Networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib171.1.1" class="ltx_emph ltx_font_italic">arXiv:1811.11264 [cs, stat]</em>, November 2018.

</span>
</li>
<li id="bib.bib172" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Abowd and Vilhuber [2008]</span>
<span class="ltx_bibblock">
John M. Abowd and Lars Vilhuber.

</span>
<span class="ltx_bibblock">How Protective Are Synthetic Data?

</span>
<span class="ltx_bibblock">In <em id="bib.bib172.1.1" class="ltx_emph ltx_font_italic">Proceedings of the UNESCO Chair in data privacy
international conference on Privacy in Statistical Databases</em>, PSD
’08, pages 239–246, Berlin, Heidelberg, September 2008. Springer-Verlag.

</span>
<span class="ltx_bibblock">ISBN 978-3-540-87470-6.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1007/978-3-540-87471-3˙20</span>.

</span>
</li>
<li id="bib.bib173" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ping et al. [2017]</span>
<span class="ltx_bibblock">
Haoyue Ping, Julia Stoyanovich, and Bill Howe.

</span>
<span class="ltx_bibblock">DataSynthesizer: Privacy-Preserving Synthetic Datasets.

</span>
<span class="ltx_bibblock">In <em id="bib.bib173.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 29th International Conference on
Scientific and Statistical Database Management</em>, Chicago IL USA, June
2017. ACM.

</span>
<span class="ltx_bibblock">ISBN 978-1-4503-5282-6.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1145/3085504.3091117</span>.

</span>
</li>
<li id="bib.bib174" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gogoshin et al. [2020]</span>
<span class="ltx_bibblock">
Grigoriy Gogoshin, Sergio Branciamore, and Andrei S Rodin.

</span>
<span class="ltx_bibblock">Synthetic data generation with probabilistic bayesian networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib174.1.1" class="ltx_emph ltx_font_italic">bioRxiv</em>, 2020.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1101/2020.06.14.151084</span>.

</span>
</li>
<li id="bib.bib175" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tsay [2002]</span>
<span class="ltx_bibblock">
Ruey S. Tsay.

</span>
<span class="ltx_bibblock"><em id="bib.bib175.1.1" class="ltx_emph ltx_font_italic">Analysis of financial time series</em>.

</span>
<span class="ltx_bibblock">Wiley, New York, 2002.

</span>
<span class="ltx_bibblock">ISBN 0-471-41544-8 978-0-471-41544-2.

</span>
</li>
<li id="bib.bib176" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fu et al. [2019]</span>
<span class="ltx_bibblock">
Rao Fu, Jie Chen, Shutian Zeng, Yiping Zhuang, and Agus Sudjianto.

</span>
<span class="ltx_bibblock">Time Series Simulation by Conditional Generative
Adversarial Net.

</span>
<span class="ltx_bibblock"><em id="bib.bib176.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1904.11419</em>, April 2019.

</span>
</li>
<li id="bib.bib177" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wiese et al. [2019]</span>
<span class="ltx_bibblock">
Magnus Wiese, Robert Knobloch, Ralf Korn, and Peter Kretschmer.

</span>
<span class="ltx_bibblock">Quant GANs: Deep Generation of Financial Time Series.

</span>
<span class="ltx_bibblock"><em id="bib.bib177.1.1" class="ltx_emph ltx_font_italic">Quantitative Finance</em>, July 2019.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1080/14697688.2020.1730426</span>.

</span>
</li>
<li id="bib.bib178" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ni et al. [2020]</span>
<span class="ltx_bibblock">
Hao Ni, Lukasz Szpruch, Magnus Wiese, Shujian Liao, and Baoren Xiao.

</span>
<span class="ltx_bibblock">Conditional Sig-Wasserstein GANs for Time Series
Generation.

</span>
<span class="ltx_bibblock"><em id="bib.bib178.1.1" class="ltx_emph ltx_font_italic">arXiv:2006.05421 [cs, stat]</em>, June 2020.

</span>
</li>
<li id="bib.bib179" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gregor et al. [2015]</span>
<span class="ltx_bibblock">
Karol Gregor, Ivo Danihelka, Alex Graves, Danilo Jimenez Rezende, and Daan
Wierstra.

</span>
<span class="ltx_bibblock">DRAW: A Recurrent Neural Network For Image
Generation.

</span>
<span class="ltx_bibblock"><em id="bib.bib179.1.1" class="ltx_emph ltx_font_italic">arXiv:1502.04623 [cs]</em>, May 2015.

</span>
</li>
<li id="bib.bib180" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mansimov et al. [2016]</span>
<span class="ltx_bibblock">
Elman Mansimov, Emilio Parisotto, Jimmy Lei Ba, and Ruslan Salakhutdinov.

</span>
<span class="ltx_bibblock">Generating Images from Captions with Attention.

</span>
<span class="ltx_bibblock"><em id="bib.bib180.1.1" class="ltx_emph ltx_font_italic">arXiv:1511.02793 [cs]</em>, February 2016.

</span>
</li>
<li id="bib.bib181" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">El-Kaddoury et al. [2019]</span>
<span class="ltx_bibblock">
Mohamed El-Kaddoury, Abdelhak Mahmoudi, and Mohammed Majid Himmi.

</span>
<span class="ltx_bibblock">Deep Generative Models for Image Generation: A Practical
Comparison Between Variational Autoencoders and Generative
Adversarial Networks.

</span>
<span class="ltx_bibblock">In Éric Renault, Selma Boumerdassi, Cherkaoui Leghris, and Samia
Bouzefrane, editors, <em id="bib.bib181.1.1" class="ltx_emph ltx_font_italic">Mobile, Secure, and Programmable
Networking</em>, volume 11557, pages 1–8. Springer International Publishing,
Cham, 2019.

</span>
<span class="ltx_bibblock">ISBN 978-3-030-22884-2 978-3-030-22885-9.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1007/978-3-030-22885-9˙1</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="http://link.springer.com/10.1007/978-3-030-22885-9_1" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://link.springer.com/10.1007/978-3-030-22885-9_1</a>.

</span>
</li>
<li id="bib.bib182" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Karras et al. [2018]</span>
<span class="ltx_bibblock">
Tero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen.

</span>
<span class="ltx_bibblock">Progressive Growing of GANs for Improved Quality,
Stability, and Variation.

</span>
<span class="ltx_bibblock"><em id="bib.bib182.1.1" class="ltx_emph ltx_font_italic">arXiv:1710.10196 [cs, stat]</em>, February 2018.

</span>
</li>
<li id="bib.bib183" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et al. [2017]</span>
<span class="ltx_bibblock">
Rui Huang, Shu Zhang, Tianyu Li, and Ran He.

</span>
<span class="ltx_bibblock">Beyond Face Rotation: Global and Local Perception GAN for
Photorealistic and Identity Preserving Frontal View Synthesis.

</span>
<span class="ltx_bibblock"><em id="bib.bib183.1.1" class="ltx_emph ltx_font_italic">arXiv:1704.04086 [cs]</em>, August 2017.

</span>
</li>
<li id="bib.bib184" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brock et al. [2017]</span>
<span class="ltx_bibblock">
Andrew Brock, Theodore Lim, J. M. Ritchie, and Nick Weston.

</span>
<span class="ltx_bibblock">Neural Photo Editing with Introspective Adversarial
Networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib184.1.1" class="ltx_emph ltx_font_italic">arXiv:1609.07093 [cs, stat]</em>, February 2017.

</span>
</li>
<li id="bib.bib185" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. [2017b]</span>
<span class="ltx_bibblock">
Yijun Li, Sifei Liu, Jimei Yang, and Ming-Hsuan Yang.

</span>
<span class="ltx_bibblock">Generative Face Completion.

</span>
<span class="ltx_bibblock"><em id="bib.bib185.1.1" class="ltx_emph ltx_font_italic">arXiv:1704.05838 [cs]</em>, April 2017b.

</span>
</li>
<li id="bib.bib186" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Antipov et al. [2017]</span>
<span class="ltx_bibblock">
Grigory Antipov, Moez Baccouche, and Jean-Luc Dugelay.

</span>
<span class="ltx_bibblock">Face aging with conditional generative adversarial networks.

</span>
<span class="ltx_bibblock">In <em id="bib.bib186.1.1" class="ltx_emph ltx_font_italic">2017 IEEE International Conference on Image
Processing (ICIP)</em>, September 2017.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1109/ICIP.2017.8296650</span>.

</span>
</li>
<li id="bib.bib187" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. [2017b]</span>
<span class="ltx_bibblock">
Zhifei Zhang, Yang Song, and Hairong Qi.

</span>
<span class="ltx_bibblock">Age Progression/Regression by Conditional Adversarial
Autoencoder.

</span>
<span class="ltx_bibblock"><em id="bib.bib187.1.1" class="ltx_emph ltx_font_italic">arXiv:1702.08423 [cs]</em>, March 2017b.

</span>
</li>
<li id="bib.bib188" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bin et al. [2017]</span>
<span class="ltx_bibblock">
Huang Bin, Chen Weihai, Wu Xingming, and Lin Chun-Liang.

</span>
<span class="ltx_bibblock">High-Quality Face Image SR Using Conditional Generative
Adversarial Networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib188.1.1" class="ltx_emph ltx_font_italic">arXiv:1707.00737 [cs]</em>, July 2017.

</span>
</li>
<li id="bib.bib189" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ledig et al. [2017]</span>
<span class="ltx_bibblock">
Christian Ledig, Lucas Theis, Ferenc Huszar, Jose Caballero, Andrew Cunningham,
Alejandro Acosta, Andrew Aitken, Alykhan Tejani, Johannes Totz, Zehan Wang,
and Wenzhe Shi.

</span>
<span class="ltx_bibblock">Photo-Realistic Single Image Super-Resolution Using a
Generative Adversarial Network.

</span>
<span class="ltx_bibblock"><em id="bib.bib189.1.1" class="ltx_emph ltx_font_italic">arXiv:1609.04802 [cs, stat]</em>, May 2017.

</span>
</li>
<li id="bib.bib190" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. [2019]</span>
<span class="ltx_bibblock">
He Zhang, Vishwanath Sindagi, and Vishal M. Patel.

</span>
<span class="ltx_bibblock">Image De-raining Using a Conditional Generative Adversarial
Network.

</span>
<span class="ltx_bibblock"><em id="bib.bib190.1.1" class="ltx_emph ltx_font_italic">arXiv:1701.05957 [cs]</em>, June 2019.

</span>
</li>
<li id="bib.bib191" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brock et al. [2019]</span>
<span class="ltx_bibblock">
Andrew Brock, Jeff Donahue, and Karen Simonyan.

</span>
<span class="ltx_bibblock">Large Scale GAN Training for High Fidelity Natural
Image Synthesis.

</span>
<span class="ltx_bibblock"><em id="bib.bib191.1.1" class="ltx_emph ltx_font_italic">arXiv:1809.11096 [cs, stat]</em>, February 2019.

</span>
</li>
<li id="bib.bib192" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Taigman et al. [2016]</span>
<span class="ltx_bibblock">
Yaniv Taigman, Adam Polyak, and Lior Wolf.

</span>
<span class="ltx_bibblock">Unsupervised Cross-Domain Image Generation.

</span>
<span class="ltx_bibblock"><em id="bib.bib192.1.1" class="ltx_emph ltx_font_italic">arXiv:1611.02200 [cs]</em>, November 2016.

</span>
</li>
<li id="bib.bib193" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu and Tuzel [2016]</span>
<span class="ltx_bibblock">
Ming-Yu Liu and Oncel Tuzel.

</span>
<span class="ltx_bibblock">Coupled Generative Adversarial Networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib193.1.1" class="ltx_emph ltx_font_italic">arXiv:1606.07536 [cs]</em>, September 2016.

</span>
</li>
<li id="bib.bib194" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Reed et al. [2016a]</span>
<span class="ltx_bibblock">
Scott Reed, Zeynep Akata, Xinchen Yan, Lajanugen Logeswaran, Bernt Schiele, and
Honglak Lee.

</span>
<span class="ltx_bibblock">Generative Adversarial Text to Image Synthesis.

</span>
<span class="ltx_bibblock"><em id="bib.bib194.1.1" class="ltx_emph ltx_font_italic">arXiv:1605.05396 [cs]</em>, June 2016a.

</span>
</li>
<li id="bib.bib195" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Reed et al. [2016b]</span>
<span class="ltx_bibblock">
Scott Reed, Zeynep Akata, Santosh Mohan, Samuel Tenka, Bernt Schiele, and
Honglak Lee.

</span>
<span class="ltx_bibblock">Learning What and Where to Draw.

</span>
<span class="ltx_bibblock"><em id="bib.bib195.1.1" class="ltx_emph ltx_font_italic">arXiv:1610.02454 [cs]</em>, October 2016b.

</span>
</li>
<li id="bib.bib196" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. [2017c]</span>
<span class="ltx_bibblock">
Han Zhang, Tao Xu, Hongsheng Li, Shaoting Zhang, Xiaogang Wang, Xiaolei Huang,
and Dimitris Metaxas.

</span>
<span class="ltx_bibblock">StackGAN: Text to Photo-realistic Image Synthesis with
Stacked Generative Adversarial Networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib196.1.1" class="ltx_emph ltx_font_italic">arXiv:1612.03242 [cs, stat]</em>, August 2017c.

</span>
</li>
<li id="bib.bib197" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sharma et al. [2018]</span>
<span class="ltx_bibblock">
Shikhar Sharma, Dendi Suhubdy, Vincent Michalski, Samira Ebrahimi Kahou, and
Yoshua Bengio.

</span>
<span class="ltx_bibblock">ChatPainter: Improving Text to Image Generation using
Dialogue.

</span>
<span class="ltx_bibblock"><em id="bib.bib197.1.1" class="ltx_emph ltx_font_italic">arXiv:1802.08216 [cs]</em>, February 2018.

</span>
</li>
<li id="bib.bib198" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. [2018b]</span>
<span class="ltx_bibblock">
Zizhao Zhang, Yuanpu Xie, and Lin Yang.

</span>
<span class="ltx_bibblock">Photographic Text-to-Image Synthesis with a
Hierarchically-nested Adversarial Network.

</span>
<span class="ltx_bibblock"><em id="bib.bib198.1.1" class="ltx_emph ltx_font_italic">arXiv:1802.09178 [cs]</em>, April 2018b.

</span>
</li>
<li id="bib.bib199" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al. [2017]</span>
<span class="ltx_bibblock">
Tao Xu, Pengchuan Zhang, Qiuyuan Huang, Han Zhang, Zhe Gan, Xiaolei Huang, and
Xiaodong He.

</span>
<span class="ltx_bibblock">AttnGAN: Fine-Grained Text to Image Generation with
Attentional Generative Adversarial Networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib199.1.1" class="ltx_emph ltx_font_italic">arXiv:1711.10485 [cs]</em>, November 2017.

</span>
</li>
<li id="bib.bib200" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qiao et al. [2019]</span>
<span class="ltx_bibblock">
Tingting Qiao, Jing Zhang, Duanqing Xu, and Dacheng Tao.

</span>
<span class="ltx_bibblock">MirrorGAN: Learning Text-to-image Generation by
Redescription.

</span>
<span class="ltx_bibblock"><em id="bib.bib200.1.1" class="ltx_emph ltx_font_italic">arXiv:1903.05854 [cs]</em>, March 2019.

</span>
</li>
<li id="bib.bib201" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hong et al. [2018]</span>
<span class="ltx_bibblock">
Seunghoon Hong, Dingdong Yang, Jongwook Choi, and Honglak Lee.

</span>
<span class="ltx_bibblock">Inferring Semantic Layout for Hierarchical Text-to-Image
Synthesis.

</span>
<span class="ltx_bibblock"><em id="bib.bib201.1.1" class="ltx_emph ltx_font_italic">arXiv:1801.05091 [cs]</em>, July 2018.

</span>
</li>
<li id="bib.bib202" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Oord et al. [2016a]</span>
<span class="ltx_bibblock">
Aaron van den Oord, Sander Dieleman, Heiga Zen, Karen Simonyan, Oriol Vinyals,
Alex Graves, Nal Kalchbrenner, Andrew Senior, and Koray Kavukcuoglu.

</span>
<span class="ltx_bibblock">WaveNet: A Generative Model for Raw Audio.

</span>
<span class="ltx_bibblock"><em id="bib.bib202.1.1" class="ltx_emph ltx_font_italic">arXiv:1609.03499 [cs]</em>, September 2016a.

</span>
</li>
<li id="bib.bib203" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Oord et al. [2016b]</span>
<span class="ltx_bibblock">
Aaron van den Oord, Nal Kalchbrenner, and Koray Kavukcuoglu.

</span>
<span class="ltx_bibblock">Pixel Recurrent Neural Networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib203.1.1" class="ltx_emph ltx_font_italic">arXiv:1601.06759 [cs]</em>, August 2016b.

</span>
</li>
<li id="bib.bib204" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mehri et al. [2017]</span>
<span class="ltx_bibblock">
Soroush Mehri, Kundan Kumar, Ishaan Gulrajani, Rithesh Kumar, Shubham Jain,
Jose Sotelo, Aaron Courville, and Yoshua Bengio.

</span>
<span class="ltx_bibblock">SampleRNN: An Unconditional End-to-End Neural Audio
Generation Model.

</span>
<span class="ltx_bibblock"><em id="bib.bib204.1.1" class="ltx_emph ltx_font_italic">arXiv:1612.07837 [cs]</em>, February 2017.

</span>
</li>
<li id="bib.bib205" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sotelo et al. [2017]</span>
<span class="ltx_bibblock">
Jose Sotelo, Soroush Mehri, Kundan Kumar, Joao Felipe Santos, Kyle Kastner,
Aaron Courville, and Yoshua Bengio.

</span>
<span class="ltx_bibblock">Char2Wav: End-to-End Speech Synthesis.

</span>
<span class="ltx_bibblock"><em id="bib.bib205.1.1" class="ltx_emph ltx_font_italic">ICLR 2017 Workshop track</em>, February 2017.

</span>
</li>
<li id="bib.bib206" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shen et al. [2018]</span>
<span class="ltx_bibblock">
Jonathan Shen, Ruoming Pang, Ron J. Weiss, Mike Schuster, Navdeep Jaitly,
Zongheng Yang, Zhifeng Chen, Yu Zhang, Yuxuan Wang, R. J. Skerry-Ryan, Rif A.
Saurous, Yannis Agiomyrgiannakis, and Yonghui Wu.

</span>
<span class="ltx_bibblock">Natural TTS Synthesis by Conditioning WaveNet on Mel
Spectrogram Predictions.

</span>
<span class="ltx_bibblock"><em id="bib.bib206.1.1" class="ltx_emph ltx_font_italic">arXiv:1712.05884 [cs]</em>, February 2018.

</span>
</li>
<li id="bib.bib207" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Donahue et al. [2019]</span>
<span class="ltx_bibblock">
Chris Donahue, Julian McAuley, and Miller Puckette.

</span>
<span class="ltx_bibblock">Adversarial Audio Synthesis.

</span>
<span class="ltx_bibblock"><em id="bib.bib207.1.1" class="ltx_emph ltx_font_italic">arXiv:1802.04208 [cs]</em>, February 2019.

</span>
</li>
<li id="bib.bib208" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vondrick et al. [2016]</span>
<span class="ltx_bibblock">
Carl Vondrick, Hamed Pirsiavash, and Antonio Torralba.

</span>
<span class="ltx_bibblock">Generating Videos with Scene Dynamics.

</span>
<span class="ltx_bibblock"><em id="bib.bib208.1.1" class="ltx_emph ltx_font_italic">arXiv:1609.02612 [cs]</em>, October 2016.

</span>
</li>
<li id="bib.bib209" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ohnishi et al. [2017]</span>
<span class="ltx_bibblock">
Katsunori Ohnishi, Shohei Yamamoto, Yoshitaka Ushiku, and Tatsuya Harada.

</span>
<span class="ltx_bibblock">Hierarchical Video Generation from Orthogonal Information:
Optical Flow and Texture.

</span>
<span class="ltx_bibblock"><em id="bib.bib209.1.1" class="ltx_emph ltx_font_italic">arXiv:1711.09618 [cs]</em>, December 2017.

</span>
</li>
<li id="bib.bib210" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tulyakov et al. [2017]</span>
<span class="ltx_bibblock">
Sergey Tulyakov, Ming-Yu Liu, Xiaodong Yang, and Jan Kautz.

</span>
<span class="ltx_bibblock">MoCoGAN: Decomposing Motion and Content for Video
Generation.

</span>
<span class="ltx_bibblock"><em id="bib.bib210.1.1" class="ltx_emph ltx_font_italic">arXiv:1707.04993 [cs]</em>, December 2017.

</span>
</li>
<li id="bib.bib211" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Saito et al. [2017]</span>
<span class="ltx_bibblock">
Masaki Saito, Eiichi Matsumoto, and Shunta Saito.

</span>
<span class="ltx_bibblock">Temporal Generative Adversarial Nets with Singular Value
Clipping.

</span>
<span class="ltx_bibblock"><em id="bib.bib211.1.1" class="ltx_emph ltx_font_italic">arXiv:1611.06624 [cs]</em>, August 2017.

</span>
</li>
<li id="bib.bib212" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vougioukas et al. [2018]</span>
<span class="ltx_bibblock">
Konstantinos Vougioukas, Stavros Petridis, and Maja Pantic.

</span>
<span class="ltx_bibblock">End-to-End Speech-Driven Facial Animation with Temporal
GANs.

</span>
<span class="ltx_bibblock"><em id="bib.bib212.1.1" class="ltx_emph ltx_font_italic">arXiv:1805.09313 [cs, eess]</em>, July 2018.

</span>
</li>
<li id="bib.bib213" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et al. [2019]</span>
<span class="ltx_bibblock">
Hang Zhou, Yu Liu, Ziwei Liu, Ping Luo, and Xiaogang Wang.

</span>
<span class="ltx_bibblock">Talking Face Generation by Adversarially Disentangled
Audio-Visual Representation.

</span>
<span class="ltx_bibblock"><em id="bib.bib213.1.1" class="ltx_emph ltx_font_italic">arXiv:1807.07860 [cs]</em>, April 2019.

</span>
</li>
<li id="bib.bib214" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mittal and Wang [2019]</span>
<span class="ltx_bibblock">
Gaurav Mittal and Baoyuan Wang.

</span>
<span class="ltx_bibblock">Animating Face using Disentangled Audio Representations.

</span>
<span class="ltx_bibblock"><em id="bib.bib214.1.1" class="ltx_emph ltx_font_italic">arXiv:1910.00726 [cs, eess]</em>, October 2019.

</span>
</li>
<li id="bib.bib215" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pan et al. [2018]</span>
<span class="ltx_bibblock">
Yingwei Pan, Zhaofan Qiu, Ting Yao, Houqiang Li, and Tao Mei.

</span>
<span class="ltx_bibblock">To Create What You Tell: Generating Videos from
Captions.

</span>
<span class="ltx_bibblock"><em id="bib.bib215.1.1" class="ltx_emph ltx_font_italic">arXiv:1804.08264 [cs]</em>, April 2018.

</span>
</li>
<li id="bib.bib216" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Balaji et al. [2019]</span>
<span class="ltx_bibblock">
Yogesh Balaji, Martin Renqiang Min, Bing Bai, Rama Chellappa, and Hans Peter
Graf.

</span>
<span class="ltx_bibblock">Conditional GAN with discriminative filter generation for
text-to-video synthesis.

</span>
<span class="ltx_bibblock">In <em id="bib.bib216.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 28th International Joint Conference
on Artificial Intelligence</em>, IJCAI’19, pages 1995–2001, Macao, China,
August 2019. AAAI Press.

</span>
<span class="ltx_bibblock">ISBN 978-0-9992411-4-1.

</span>
<span class="ltx_bibblock">ZSCC: 0000022.

</span>
</li>
<li id="bib.bib217" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. [2019]</span>
<span class="ltx_bibblock">
Yitong Li, Zhe Gan, Yelong Shen, Jingjing Liu, Yu Cheng, Yuexin Wu, Lawrence
Carin, David Carlson, and Jianfeng Gao.

</span>
<span class="ltx_bibblock">StoryGAN: A Sequential Conditional GAN for Story
Visualization.

</span>
<span class="ltx_bibblock"><em id="bib.bib217.1.1" class="ltx_emph ltx_font_italic">arXiv:1812.02784 [cs]</em>, April 2019.

</span>
</li>
<li id="bib.bib218" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mathieu et al. [2016]</span>
<span class="ltx_bibblock">
Michael Mathieu, Camille Couprie, and Yann LeCun.

</span>
<span class="ltx_bibblock">Deep multi-scale video prediction beyond mean square error.

</span>
<span class="ltx_bibblock"><em id="bib.bib218.1.1" class="ltx_emph ltx_font_italic">arXiv:1511.05440 [cs, stat]</em>, February 2016.

</span>
</li>
<li id="bib.bib219" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee et al. [2018]</span>
<span class="ltx_bibblock">
Alex X. Lee, Richard Zhang, Frederik Ebert, Pieter Abbeel, Chelsea Finn, and
Sergey Levine.

</span>
<span class="ltx_bibblock">Stochastic Adversarial Video Prediction.

</span>
<span class="ltx_bibblock"><em id="bib.bib219.1.1" class="ltx_emph ltx_font_italic">arXiv:1804.01523 [cs]</em>, April 2018.

</span>
</li>
<li id="bib.bib220" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Villegas et al. [2018]</span>
<span class="ltx_bibblock">
Ruben Villegas, Jimei Yang, Seunghoon Hong, Xunyu Lin, and Honglak Lee.

</span>
<span class="ltx_bibblock">Decomposing Motion and Content for Natural Video Sequence
Prediction.

</span>
<span class="ltx_bibblock"><em id="bib.bib220.1.1" class="ltx_emph ltx_font_italic">arXiv:1706.08033 [cs]</em>, January 2018.

</span>
</li>
<li id="bib.bib221" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Walker et al. [2017]</span>
<span class="ltx_bibblock">
Jacob Walker, Kenneth Marino, Abhinav Gupta, and Martial Hebert.

</span>
<span class="ltx_bibblock">The Pose Knows: Video Forecasting by Generating Pose
Futures.

</span>
<span class="ltx_bibblock"><em id="bib.bib221.1.1" class="ltx_emph ltx_font_italic">arXiv:1705.00053 [cs]</em>, April 2017.

</span>
</li>
<li id="bib.bib222" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liang et al. [2017]</span>
<span class="ltx_bibblock">
Xiaodan Liang, Lisa Lee, Wei Dai, and Eric P. Xing.

</span>
<span class="ltx_bibblock">Dual Motion GAN for Future-Flow Embedded Video
Prediction.

</span>
<span class="ltx_bibblock"><em id="bib.bib222.1.1" class="ltx_emph ltx_font_italic">arXiv:1708.00284 [cs]</em>, August 2017.

</span>
</li>
<li id="bib.bib223" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bansal et al. [2018]</span>
<span class="ltx_bibblock">
Aayush Bansal, Shugao Ma, Deva Ramanan, and Yaser Sheikh.

</span>
<span class="ltx_bibblock">Recycle-GAN: Unsupervised Video Retargeting.

</span>
<span class="ltx_bibblock"><em id="bib.bib223.1.1" class="ltx_emph ltx_font_italic">arXiv:1808.05174 [cs]</em>, August 2018.

</span>
</li>
<li id="bib.bib224" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chan et al. [2019]</span>
<span class="ltx_bibblock">
Caroline Chan, Shiry Ginosar, Tinghui Zhou, and Alexei A. Efros.

</span>
<span class="ltx_bibblock">Everybody Dance Now.

</span>
<span class="ltx_bibblock"><em id="bib.bib224.1.1" class="ltx_emph ltx_font_italic">arXiv:1808.07371 [cs]</em>, August 2019.

</span>
</li>
<li id="bib.bib225" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim et al. [2018]</span>
<span class="ltx_bibblock">
Hyeongwoo Kim, Pablo Garrido, Ayush Tewari, Weipeng Xu, Justus Thies, Matthias
Nießner, Patrick Pérez, Christian Richardt, Michael Zollhöfer, and
Christian Theobalt.

</span>
<span class="ltx_bibblock">Deep Video Portraits.

</span>
<span class="ltx_bibblock"><em id="bib.bib225.1.1" class="ltx_emph ltx_font_italic">arXiv:1805.11714 [cs]</em>, May 2018.

</span>
</li>
<li id="bib.bib226" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Siarohin et al. [2019]</span>
<span class="ltx_bibblock">
Aliaksandr Siarohin, Stéphane Lathuilière, Sergey Tulyakov, Elisa Ricci, and
Nicu Sebe.

</span>
<span class="ltx_bibblock">Animating Arbitrary Objects via Deep Motion Transfer.

</span>
<span class="ltx_bibblock"><em id="bib.bib226.1.1" class="ltx_emph ltx_font_italic">arXiv:1812.08861 [cs, stat]</em>, August 2019.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2205.03256" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2205.03257" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2205.03257">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2205.03257" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2205.03258" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Mon Mar 11 12:43:31 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
