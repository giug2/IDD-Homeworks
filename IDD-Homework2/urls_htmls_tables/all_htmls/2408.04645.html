<!DOCTYPE html>
<html lang="en" prefix="dcterms: http://purl.org/dc/terms/">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Evaluating the Impact of Advanced LLM Techniques on AI-Lecture Tutors for a Robotics Course</title>
<!--Generated on Fri Aug  2 19:47:05 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2408.04645v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#S1" title="In Evaluating the Impact of Advanced LLM Techniques on AI-Lecture Tutors for a Robotics Course"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#S2" title="In Evaluating the Impact of Advanced LLM Techniques on AI-Lecture Tutors for a Robotics Course"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Methods: Large Language Model as an AI Tutor</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#S2.SS1" title="In 2 Methods: Large Language Model as an AI Tutor ‣ Evaluating the Impact of Advanced LLM Techniques on AI-Lecture Tutors for a Robotics Course"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Advanced LLM Techniques</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#S2.SS2" title="In 2 Methods: Large Language Model as an AI Tutor ‣ Evaluating the Impact of Advanced LLM Techniques on AI-Lecture Tutors for a Robotics Course"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Preprocessing of Lecture Material</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#S2.SS3" title="In 2 Methods: Large Language Model as an AI Tutor ‣ Evaluating the Impact of Advanced LLM Techniques on AI-Lecture Tutors for a Robotics Course"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>Test and Fine-Tuning Dataset</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#S2.SS4" title="In 2 Methods: Large Language Model as an AI Tutor ‣ Evaluating the Impact of Advanced LLM Techniques on AI-Lecture Tutors for a Robotics Course"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.4 </span>Models and Fine-Tuning</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#S2.SS5" title="In 2 Methods: Large Language Model as an AI Tutor ‣ Evaluating the Impact of Advanced LLM Techniques on AI-Lecture Tutors for a Robotics Course"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.5 </span>Evaluation of LLMs in Question-Answering</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#S3" title="In Evaluating the Impact of Advanced LLM Techniques on AI-Lecture Tutors for a Robotics Course"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Results</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#S3.SS1" title="In 3 Results ‣ Evaluating the Impact of Advanced LLM Techniques on AI-Lecture Tutors for a Robotics Course"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Comparison of Different LLM Extension</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#S3.SS2" title="In 3 Results ‣ Evaluating the Impact of Advanced LLM Techniques on AI-Lecture Tutors for a Robotics Course"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Analysis of Evaluation Metrics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#S3.SS3" title="In 3 Results ‣ Evaluating the Impact of Advanced LLM Techniques on AI-Lecture Tutors for a Robotics Course"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Adaptation of LLM during Fine-Tuning</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#S4" title="In Evaluating the Impact of Advanced LLM Techniques on AI-Lecture Tutors for a Robotics Course"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Discussion and Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#A1" title="In Evaluating the Impact of Advanced LLM Techniques on AI-Lecture Tutors for a Robotics Course"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Overview Detailed Results for Evaluation of Different LLMs</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#A2" title="In Evaluating the Impact of Advanced LLM Techniques on AI-Lecture Tutors for a Robotics Course"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B </span>GPTSimilarity</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#A3" title="In Evaluating the Impact of Advanced LLM Techniques on AI-Lecture Tutors for a Robotics Course"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C </span>GPTRater</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#A4" title="In Evaluating the Impact of Advanced LLM Techniques on AI-Lecture Tutors for a Robotics Course"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">D </span>Comparison of Responses during Fine-Tuning</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#A5" title="In Evaluating the Impact of Advanced LLM Techniques on AI-Lecture Tutors for a Robotics Course"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">E </span>Overview human evaluation</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Evaluating the Impact of Advanced LLM Techniques on AI-Lecture Tutors for a Robotics Course</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><a class="ltx_ref ltx_href" href="https://orcid.org/0000-0002-8468-2808" title=""><span class="ltx_text" id="id1.1.1.1"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="8" id="id1.1.1.1.g1" src="x1.png" width="8"/></span> Sebastian Kahl</a>
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">fronyx GmbH, Rüttenscheider Str. 120, 45131 Essen
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Felix Löffler
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Autonomous Intelligent Systems Group, University of Münster
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Martin Maciol
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Autonomous Intelligent Systems Group, University of Münster
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Fabian Ridder
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Autonomous Intelligent Systems Group, University of Münster
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Marius Schmitz
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Autonomous Intelligent Systems Group, University of Münster
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Jennifer Spanagel
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Autonomous Intelligent Systems Group, University of Münster
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Jens Wienkamp
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Autonomous Intelligent Systems Group, University of Münster
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Christopher Burgahn
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">fronyx GmbH, Rüttenscheider Str. 120, 45131 Essen
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><a class="ltx_ref ltx_href" href="https://orcid.org/0000-0002-0849-483X" title=""><span class="ltx_text" id="id2.1.1.1"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="8" id="id2.1.1.1.g1" src="x2.png" width="8"/></span> Malte Schilling</a>
</span><span class="ltx_author_notes"><span class="ltx_text ltx_font_typewriter" id="id3.2.id1">malte.schilling@uni-muenster.de</span>
<span class="ltx_contact ltx_role_affiliation">Autonomous Intelligent Systems Group, University of Münster
</span></span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id4.id1">This study evaluates the performance of Large Language Models (LLMs) as an Artificial Intelligence-based tutor for a university course. In particular, different advanced techniques are utilized, such as prompt engineering, Retrieval-Augmented-Generation (RAG), and fine-tuning. We assessed the different models and applied techniques using common similarity metrics like BLEU-4, ROUGE, and BERTScore, complemented by a small human evaluation of helpfulness and trustworthiness. Our findings indicate that RAG combined with prompt engineering significantly enhances model responses and produces better factual answers. In the context of education, RAG appears as an ideal technique as it is based on enriching the input of the model with additional information and material which usually is already present for a university course. Fine-tuning, on the other hand, can produce quite small, still strong expert models, but poses the danger of overfitting. Our study further asks how we measure performance of LLMs and how well current measurements represent correctness or relevance? We find high correlation on similarity metrics and a bias of most of these metrics towards shorter responses. Overall, our research points to both the potential and challenges of integrating LLMs in educational settings, suggesting a need for balanced training approaches and advanced evaluation frameworks.</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para ltx_noindent" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Large Language Models have become popular with the introduction of ChatGPT. In particular, the novel dialogue capabilities of these Assistant Models <cite class="ltx_cite ltx_citemacro_citep">(Ouyang et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#bib.bib1" title="">2022</a>)</cite> has spurned an interest as these provide a flexibility that allows to apply LLMs in various sectors, including education. These Large Language Models (LLMs) are Transformer-based neural networks <cite class="ltx_cite ltx_citemacro_citep">(Vaswani et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#bib.bib2" title="">2017</a>)</cite> that were trained on massive text corpora and that exhibit impressive abilities to comprehend, process, and generate human-like language. Originally, Large Language Models—now often called Foundation Models—were trained with the goal to predict the following text token, taking into account long and diverse relationships of the given previous input. The models learnt from this to perform well on a large number of different tasks across a variety of topics. Importantly, early work on GPT-2 already demonstrated the flexibility of these models as these models can be explicitly directed to execute a specified language task simply through prompting these models accordingly <cite class="ltx_cite ltx_citemacro_citep">(Radford et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#bib.bib3" title="">2019</a>)</cite>. Early-on, these models had difficulties staying on track for a given task and often their responses lingered or drifted away from a topic. As a consequence, the earliest application were in specific and narrowly defined tasks as translation. In such a task the model could continuously be forced to follow the original input sequence. The work by <cite class="ltx_cite ltx_citemacro_cite">Ouyang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#bib.bib1" title="">2022</a>)</cite> changed this, as they further trained models to better imitate human behavior which lead to the emergence of Assistant Models as ChatGPT. These demonstrated for the first time the ability to provide a–to a certain degree–consistent partner for dialogue which can be engaged in a conversation. Modern models are now able to understand and generate language with remarkable fluency and coherence.
The success of such models has now spread and there is a growing number of models similar to ChatGPT that are further improving at a rapid pace (e.g., Meta’s LLaMA-2 as an open-source model <cite class="ltx_cite ltx_citemacro_citep">(Touvron et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#bib.bib4" title="">2023a</a>)</cite>; for an overview on the current landscape of LLMs see <cite class="ltx_cite ltx_citemacro_citep">(Naveed et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#bib.bib5" title="">2024</a>)</cite>). LLMs present now valuable opportunities to design and develop innovative assistant systems.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">In the area of education, the early debate on the impact of powerful LLMs has sadly mostly focused on negative consequences, e.g., how this might allow students to cheat as these models are capable of generating written course work—as currently used to test learning capabilities—or even parts or a full thesis work.
But LLMs can also be beneficial in education and teaching: LLMs as an assistant can be utilized to provide individualized teaching for every student. In particular, the possibility to prompt them to answer in a certain role—e.g., as a primary or high school teacher—and addressing a specific audience—e.g., a fourth grader or a grad student—offers novel possibilities for better adapted teaching that takes the need of the individual learner into account <cite class="ltx_cite ltx_citemacro_citep">(Extance, <a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#bib.bib6" title="">2023</a>)</cite>. This has lead to the idea of introducing LLMs as tutors for courses or lectures. There are already quite a number of different nice examples. One particular area is the area of coding assistants (e.g., Starcoder by Hugginface <cite class="ltx_cite ltx_citemacro_citep">(BigCode: Hugging Face and ServiceNow, <a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#bib.bib7" title="">2023</a>)</cite>; see as well <cite class="ltx_cite ltx_citemacro_citep">(Mehta et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#bib.bib8" title="">2023</a>)</cite> and for a systematic overview <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#bib.bib9" title="">2023</a>)</cite>). Other examples include assistants in language learning. Khan Academy’s assistant Khanmigo <cite class="ltx_cite ltx_citemacro_citep">(Khan Academy, <a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#bib.bib10" title="">2023</a>)</cite> is an early example in this area as they started to develop this in cooperation with OpenAI before the official release of ChatGPT. In general, Khan Academy has embraced LLMs as powerful tools for education and their founder has detailed a positive outlook how this not only can help to provide better teaching—in the sense of more individualized tutoring that supports learning—, but as well more engaging learning experiences <cite class="ltx_cite ltx_citemacro_citep">(Khan, <a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#bib.bib11" title="">2024</a>)</cite>. Following such a route, we are seeing an increasing number of LLM-based systems acting as tutors in university courses (as one example, see <cite class="ltx_cite ltx_citemacro_citep">(of Education, <a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#bib.bib12" title="">2023</a>)</cite>; for a broad review see <cite class="ltx_cite ltx_citemacro_citep">(García-Méndez et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#bib.bib13" title="">2024</a>)</cite>).</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">A significant challenge in deploying LLMs are hallucinations. Hallucinations in LLMs refer to cases in which the model generates plausible-sounding, but incorrect or nonsensical responses <cite class="ltx_cite ltx_citemacro_citep">(Maynez et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#bib.bib14" title="">2020</a>)</cite>. It is assumed that this occurs because the model relies solely on patterns in textual data it was trained on without any understanding of factual correctness <cite class="ltx_cite ltx_citemacro_citep">(Huang et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#bib.bib15" title="">2023</a>)</cite>. Detecting hallucinations has proven difficult, but different techniques and metrics have been proposed (for a comprehensive review see <cite class="ltx_cite ltx_citemacro_citep">(Huang et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#bib.bib15" title="">2023</a>)</cite> which outlines principles, a taxonomy, and open questions regarding hallucinations in LLMs, while as well providing insights on developing effective detection and mitigation strategies). The risk of hallucinations is particularly concerning for an educational setting and has to be addressed in such an area that demands factual correctness.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">One major focus in utilizing LLMs in education as a tutoring system is, therefore, in how to prevent hallucinations and restrict answers to the specific course <cite class="ltx_cite ltx_citemacro_citep">(Dong, <a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#bib.bib16" title="">2023</a>; Extance, <a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#bib.bib6" title="">2023</a>)</cite>. Our work is directed in this direction, as we aim for an LLM as a tutor for learning and in teaching of a University course on robotics. This LLM-powered tutor was envisioned as a supplementary resource, providing tailored assistance and facilitating personalized learning paths for participants. The explicit goal of the presented work was to develop a tutor-like system that is utilizing the flexibility of Assistant Models. By this, we want to address two main research questions: First, LLMs can show the tendency to provide wrong or hallucinated responses. We wanted to analyze how different—currently widely proposed—advanced techniques for LLMs can improve the responses of LLMs in a specific knowledge domain? Do such extended LLMs hallucinate less and provide more factual answers? Secondly, evaluation of the performance of LLMs has shown to be difficult and lead to inconsistent results. Therefore, we want to address how can we measure performance of LLMs and how good do currently applied measurements represent factuality? In particular, we are interested in how do different metrics relate to each other or overlap? Furthermore, can we identify biases that affect these measurements?</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">In this paper, we want to summarize our experience with current State-of-the-Art techniques in the area of LLMs and demonstrate how these differentially impact the behavior of the lecture tutoring system. Therefore, the paper covers current methods all applied in the area of a lecture tutor for an introductory robotics course. First, simply using an of-the-shelf LLM that is purely put to the task through prompt engineering. Secondly, enriching the input by course material through Retrieval-Augmented-Generation in which content from slides and the annotations of the lecture videos were also provided to the model. Third, an LLM. was fine-tuned for the specific task on a generated set of question-answer pairs.
The article is organized in the following way:
We first provide a detailed overview of our AI lecture tutor, explaining the design requirements, the different applied LLM extension techniques and how they are realized, the selected LLMs, as well as details on dataset and preparation.Then we present our results on an introduced test data set specific to the robotics course. One crucial aspect of our work is the evaluation of LLMs which still appears in its infancy. We describe our multi-faceted approach, combining automated benchmarks to quantify performance and a human-centered evaluation using questionnaires to garner qualitative insights into student interaction with the AI Lecture Tutor. Finally, we conclude with a critical reflection of our findings and highlighting potential avenues for future research in the domain of AI-powered educational technologies.
</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Methods: Large Language Model as an AI Tutor</h2>
<div class="ltx_para ltx_noindent" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">The proposed AI tutor will be integrated into the learning platform of the lecture and is designed as a chatbot that allows students to communicate via written messages. Regarding its function, the tutor system should consistently respond in a polite and helpful way, as a human tutor would do. It needs to be able to understand questions given in natural language and to generate answers that are both syntactically and semantically accurate. Most importantly, the answers should be consistent with the lecture which means, answers are, first, correct and the system should not tell falsehoods. Easy and general questions should be answerable based on the pre-trained model.Secondly, as the tutor should support the student in learning the concepts, the answers should relate to the content of the lecture as well as the way it is taught, e.g., picking up examples or providing references to content as the slides. Therefore, slides of the lecture as well as the transcripts of the recordings should be taken into account.
</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">These requirements guide the realization of the tutor system and in the following, we will introduce different advanced techniques for LLMs that will be applied in the tutoring system. We are interested in comparing how well an LLM can work as a lecture tutor. This requires an experimental setup in which different variations of the tutor are questioned in a systematic way and evaluated. In the following, we will introduce the necessary parts for such an evaluation and comparison. First, we introduce the different advanced techniques applied to the LLM, i.e., prompt engineering, Retrieval-Augmented-Generation, and fine-tuning. Secondly, we will briefly describe the preprocessing of the lecture material and, third, how we derived a test data set for evaluation and a data set for training. Fourth, we will briefly provide details on the used models and the fine-tuning process. Last, we introduce different evaluation metrics for the comparison.</p>
</div>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Advanced LLM Techniques</h3>
<div class="ltx_para ltx_noindent" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">Applying an off-the-shelf dialogue LLM as a lecture tutor can serve as a baseline. But it has to be assumed that it provides generic answers that—while hopefully will be correct—are not tailored to the specific course. There is now already an established set of different approaches for improving answers of an LLM. We will briefly describe these different approaches that will later be compared in our evaluation.</p>
</div>
<section class="ltx_subsubsection" id="S2.SS1.SSSx1">
<h4 class="ltx_title ltx_title_subsubsection">Guiding the Model: Prompt Engineering</h4>
<div class="ltx_para ltx_noindent" id="S2.SS1.SSSx1.p1">
<p class="ltx_p" id="S2.SS1.SSSx1.p1.1">A simple improvement can be achieved by enriching the prompt given by the user and tailoring the prompt towards the particular task as well as the given setting. Enriching the prompt can guide the model to generate more relevant and accurate answers <cite class="ltx_cite ltx_citemacro_citep">(Radford et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#bib.bib3" title="">2019</a>)</cite>. To improve a prompt, it is first necessary to understand what is required by the model acting as a tutor: The tutor is expected to answer as a human tutor would, which means it only tells the truth and cites it sources. Therefore, these aspects need to be incorporated into the prompt. Achieving the desired outcome through prompt engineering is often an iterative process in which a given prompt is tried, evaluated and iteratively improved <cite class="ltx_cite ltx_citemacro_citep">(Jones et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#bib.bib17" title="">2023</a>)</cite>. We achieved good results with initially starting from a very simple, basic system message and improve this stepwise to include more details: The AI Tutor was prompted that it is a lecture assistant, an expert in the field of robotics and should only answer according to the context of the lecture.
<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>”You are now a lecture assistant that helps students to understand the lecture.
You are an expert about the lecture topic autonomic systems and mobile robots.
You will always bring the answer in the context of the lecture.”
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://zivgitlab.uni-muenster.de/schillma/lecturellm/-/blob/main/prompts.py?ref_type=heads%23L74" title="">https://zivgitlab.uni-muenster.de/schillma/lecturellm/-/blob/main/prompts.py?ref_type=heads%23L74</a></span></span></span></p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS1.SSSx1.p2">
<p class="ltx_p" id="S2.SS1.SSSx1.p2.1">As the initial prompt didn’t suffice to turn the model into a tutor-like personality, additional traits as helpful, respectful, and honest were added. Furthermore, the model was explicitly instructed to exclude any form of racist, harmful, toxic, dangerous, illegal, or unethical content.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS1.SSSx1.p3">
<p class="ltx_p" id="S2.SS1.SSSx1.p3.1">One particular problematic area when using a standard LLM was the tendency to always try to generate some output, even though a question was not well understood or the model simply didn’t know the necessary facts for providing an answer. When providing additional information using RAG (see next section), as an additional instruction for the prompt it was added to restrict answers to the provided material.
<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>
”You are a helpful, respectful, and honest teaching assistant for lecture material that will be provided to you.
Your current task is to answer student queries. Always answer as helpfully as possible, while being safe.
Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content.
Please ensure that your responses are socially unbiased and positive in nature. If a question does not make sense,
or is not factually coherent, explain why instead of answering something incorrect.
If you don’t know the answer to a question, please do not share false information. You only have access to the lecture material provided to you.
Lecture material includes slides, images, and transcripts of videos.
The only thing you can do is write text, nothing else! Never, ever repeat yourself.”
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://zivgitlab.uni-muenster.de/schillma/lecturellm/-/blob/main/prompts.py?ref_type=heads%23L80" title="">https://zivgitlab.uni-muenster.de/schillma/lecturellm/-/blob/main/prompts.py?ref_type=heads%23L80</a>
</span></span></span></p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS1.SSSx1.p4">
<p class="ltx_p" id="S2.SS1.SSSx1.p4.1">As one further aspect, prompt engineering can be used to advise the model explicitly to break down a task or question and derive an answer in a step-wise manner. While this could be driven by an external loop calling a LLM multiple times and initially asking the model to divide the problem which means to generate questions that need to be answered beforehand or look-up necessary definitions <cite class="ltx_cite ltx_citemacro_citep">(Wei et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#bib.bib18" title="">2022</a>)</cite>.</p>
</div>
<figure class="ltx_figure" id="S2.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="230" id="S2.F1.g1" src="x3.png" width="408"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Overview of process for integrating RAG into the query to an LLM: The user asks a question (1) through an interface. For the embedded question additional information is retrieved from a vector database (2). The query to the LLM (3) integrates the original posed question and retrieved information into a—usually engineered—specific prompt. The LLM generates a completion as a response (4). Often, the reply has to be unwraped and can be passed to the user (5).</figcaption>
</figure>
</section>
<section class="ltx_subsubsection" id="S2.SS1.SSSx2">
<h4 class="ltx_title ltx_title_subsubsection">Enhancing the Input: Retrieval-Augmented Generation</h4>
<div class="ltx_para ltx_noindent" id="S2.SS1.SSSx2.p1">
<p class="ltx_p" id="S2.SS1.SSSx2.p1.1">One common extension for LLMs is to enrich the input to the system using external background data that relates to the given input and could potentially help in generating a response which is called Retrieval-Augmented Generation (RAG) <cite class="ltx_cite ltx_citemacro_citep">(Lewis et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#bib.bib19" title="">2020</a>)</cite>.
The main idea of RAG, visualized in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#S2.F1" title="Figure 1 ‣ Guiding the Model: Prompt Engineering ‣ 2.1 Advanced LLM Techniques ‣ 2 Methods: Large Language Model as an AI Tutor ‣ Evaluating the Impact of Advanced LLM Techniques on AI-Lecture Tutors for a Robotics Course"><span class="ltx_text ltx_ref_tag">1</span></a>, is to retrieve such related information from a provided database. The retrieved data is added to the prompt as additional context. <cite class="ltx_cite ltx_citemacro_cite">Lewis et al. (<a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#bib.bib19" title="">2020</a>)</cite> have shown that a model, that is supported with RAG, can outperform state-of-the-art approaches in open-domain Question Answering. It was also shown that such a model can approach the efficacy of systems with domain-specific architectures in Fact Verification.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS1.SSSx2.p2">
<p class="ltx_p" id="S2.SS1.SSSx2.p2.1">RAG appears as an ideal extension for a tutoring system as it
enriches responses with additional knowledge about the query, ensuring that answers are not only accurate but also relevant to the specific content covered in the lecture.
This approach can also prevent the inclusion of overly detailed information not discussed in the lecture. Additionally, RAG’s advancements in fact verification enable the AI tutor to identify and rectify inaccuracies presented by users during chat conversations. Lastly, RAG facilitates the integration of references into answers, for example, in our case, references to specific slides were included in the underlying database. This enables users to verify information, which should strengthen their trust in the model.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS1.SSSx2.p3">
<p class="ltx_p" id="S2.SS1.SSSx2.p3.1">As a method, Retrieval-Augmented Generation can be divided into two primary stages (for more details, see <cite class="ltx_cite ltx_citemacro_citep">(Zhao et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#bib.bib20" title="">2024</a>)</cite>): indexing and querying. The indexing stage involves the efficient storage of supplementary information. As an initial step, the data has to be segmented into manageable chunks which facilitates the search for specific content within the data. To enable semantic searches, a vector embedding is computed for each of these chunks. The database must store individual chunks and embeddings. Importantly, we want to be able to query the database semantically, which means it has to allow for a similarity search in the vector embedding space.
Such a system is referred to as vector storage. <span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>Vector storages: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://python.langchain.com/docs/modules/data_connection/vectorstores" title="">https://python.langchain.com/docs/modules/data_connection/vectorstores</a> (Accessed: 28.02.2024)</span></span></span></p>
</div>
<figure class="ltx_figure" id="S2.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="171" id="S2.F2.g1" src="x4.png" width="420"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Overview of the query process when using a fine-tuned model (the access process is identically to directly querying a given LLM, but can of course be extended to as well include RAG): The user asks a question (1) through an interface which is given to the LLM (2). The LLM generates a completion as a response (3) which is passed to the user (4). The important difference is that task specific knowledge or interaction specific patterns are entrained into the model beforehand, i.e. during the fine-tuning stage (shown on the right in red).
</figcaption>
</figure>
</section>
<section class="ltx_subsubsection" id="S2.SS1.SSSx3">
<h4 class="ltx_title ltx_title_subsubsection">Training the LLM: Fine-Tuning on Example Data</h4>
<div class="ltx_para ltx_noindent" id="S2.SS1.SSSx3.p1">
<p class="ltx_p" id="S2.SS1.SSSx3.p1.1">Large Language Models operate on two sources of knowledge: As a parametric form, information is entrained into the distributed neural network structure of the model during training. Relatively huge amounts of text are used during training that gradually shape the responses of the model. As a second form, LLMs integrate contextual knowledge given as an input which drives the generation of the response. RAG explicitly provides additional contextual knowledge and in prompt engineering contextual input (the prompt) is used to steer the generation process (see above). A different, but usually more involved approach, is to address the knowledge stored in a distributed fashion in the neural networks of the LLM. This can be achieved using further training and fine-tuning the model <cite class="ltx_cite ltx_citemacro_citep">(Devlin et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#bib.bib21" title="">2019</a>)</cite>.
Fine-tuning a large language model involves adjusting the model’s parameters and training it on a specific dataset to adapt it to a particular topic, in our case, the lecture on robotics. In fine-tuning, the neural network-based model is further trained in a supervised fashion on a specific data set. The goal is to to adapt the LLM towards a specific task and the model should become an expert in this task. Fine-tuning has shown to work well with relatively small data sets (of around a couple of hundreds to thousands example interactions), but when training on such a small data set, there is a danger of overfitting to these particular questions. The model might end up only providing memorized answers from this data set. In general, fine-tuning as a process can improve the model’s performance and accuracy for a targeted use case by by combining the knowledge of the base model with specific information from a new dataset.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Preprocessing of Lecture Material</h3>
<div class="ltx_para ltx_noindent" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.2">Integration of lecture material into the query process using RAG or deriving training data from it, requires significant preprocessing of the available information. First, the information has to be extracted, in our case from slides which consist of written text that could be directly extracted from the original files (in our case based on PDFs of the lecture slides). In addition, graphical information and images from the slides were extracted and transferred to textual descriptions using multimodal Large Language Models. The visual information was fed into LLMs (GPT-4) that were tasked with briefly describing the given figure. Secondly, the original audio was taken from lecture videos in which the specific slides were explained and discussed in more detail. This requires transcribing the audio (realized using OpenAI’s Whisper framework) and aligning the oral explanations with the content presented visually on the slides. The audio showed important providing complementing information and more detailed explanations. As a result of this process, we end up with a vast amount of data for eleven lectures (each one <math alttext="90" class="ltx_Math" display="inline" id="S2.SS2.p1.1.m1.1"><semantics id="S2.SS2.p1.1.m1.1a"><mn id="S2.SS2.p1.1.m1.1.1" xref="S2.SS2.p1.1.m1.1.1.cmml">90</mn><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.1.m1.1b"><cn id="S2.SS2.p1.1.m1.1.1.cmml" type="integer" xref="S2.SS2.p1.1.m1.1.1">90</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.1.m1.1c">90</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p1.1.m1.1d">90</annotation></semantics></math> minutes long, roughly around <math alttext="45" class="ltx_Math" display="inline" id="S2.SS2.p1.2.m2.1"><semantics id="S2.SS2.p1.2.m2.1a"><mn id="S2.SS2.p1.2.m2.1.1" xref="S2.SS2.p1.2.m2.1.1.cmml">45</mn><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.2.m2.1b"><cn id="S2.SS2.p1.2.m2.1.1.cmml" type="integer" xref="S2.SS2.p1.2.m2.1.1">45</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.2.m2.1c">45</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p1.2.m2.1d">45</annotation></semantics></math> slides per lecture) that is available to the system. During operation, the AI tutor should focus solely on relevant parts from the lecture and, therefore, needs an understanding of which different parts of the lecture and transcripts are necessary to answer the question. As an additional requirement, the AI tutor should provide information on its sources, e.g., pointing out which slides were used for a given answer (for example: "@10-slam-deck Slide 11"). This allows the user to check slides and verify the given answer.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1">Overall, the complete process should be executed quickly in general and efficiently to avoid compromising the user experience. For future application in real courses, factors regarding its scalability should be considered as well (both with respect to running an LLM as well as the necessary infrastructure for serving up background information from a database).</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Test and Fine-Tuning Dataset</h3>
<div class="ltx_para ltx_noindent" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.2">Evaluation of the different LLM techniques and models was done on the test data set. This data set consisted of chats (overall <math alttext="478" class="ltx_Math" display="inline" id="S2.SS3.p1.1.m1.1"><semantics id="S2.SS3.p1.1.m1.1a"><mn id="S2.SS3.p1.1.m1.1.1" xref="S2.SS3.p1.1.m1.1.1.cmml">478</mn><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.1.m1.1b"><cn id="S2.SS3.p1.1.m1.1.1.cmml" type="integer" xref="S2.SS3.p1.1.m1.1.1">478</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.1.m1.1c">478</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p1.1.m1.1d">478</annotation></semantics></math>) which each included a dialogue consisting of the question and a possible answer. Questions in the test set (and similarly in the training data set described below) were targeted for the specific robotics course and based on the material covered. In case of the test set, two lectures (on the topic of SLAM and navigation in robotics, lecture nine and ten) were used. Three students worked through the material of these lectures and generated by hand questions for the covered material which was then used again by the human writers to formulate an answer. Overall, for the test set <math alttext="478" class="ltx_Math" display="inline" id="S2.SS3.p1.2.m2.1"><semantics id="S2.SS3.p1.2.m2.1a"><mn id="S2.SS3.p1.2.m2.1.1" xref="S2.SS3.p1.2.m2.1.1.cmml">478</mn><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.2.m2.1b"><cn id="S2.SS3.p1.2.m2.1.1.cmml" type="integer" xref="S2.SS3.p1.2.m2.1.1">478</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.2.m2.1c">478</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p1.2.m2.1d">478</annotation></semantics></math> such chats were written.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS3.p2">
<p class="ltx_p" id="S2.SS3.p2.1">For fine-tuning a training data set for the robotics course was generated. It explicitly excluded the topics covered in the test set for which there where humanly written chats. But for generating the test set, a LLM was used which was advised through a prompt to generate question-answer pairs for specific slides (the prompt had quite detailed instructions on how to generate questions based on the content of a slide which could then be used in addition to generate a fitting answer that included a reference to that particular slide). In addition, an example question-answer pair written by a human was given in a form of one-shot learning. The generated chats were afterwards read and checked by humans and were found to be generally of sufficient quality. This produced overall <math alttext="2791" class="ltx_Math" display="inline" id="S2.SS3.p2.1.m1.1"><semantics id="S2.SS3.p2.1.m1.1a"><mn id="S2.SS3.p2.1.m1.1.1" xref="S2.SS3.p2.1.m1.1.1.cmml">2791</mn><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.1.m1.1b"><cn id="S2.SS3.p2.1.m1.1.1.cmml" type="integer" xref="S2.SS3.p2.1.m1.1.1">2791</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.1.m1.1c">2791</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p2.1.m1.1d">2791</annotation></semantics></math> chats for training that did not overlap with the test data set. The LLaMA-2 model was trained on this specific dataset of prototypical interaction.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.4 </span>Models and Fine-Tuning</h3>
<div class="ltx_para ltx_noindent" id="S2.SS4.p1">
<p class="ltx_p" id="S2.SS4.p1.1">There are many LLMs openly available which are accessible through specific APIs and even more so through standard libraries and frameworks like Huggingface or their APIs. For our tutor system, we focussed, first, on GPT-3.5 which is accessible through OpenAI and for which we used the OpenAI API for access (model can be queried through simple python function calls). We chose this particular model as it is widely used and can be considered a good, common benchmark. It provides high quality output. Prompt engineering and RAG can be applied easily.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS4.p2">
<p class="ltx_p" id="S2.SS4.p2.1">For RAG, the AI Tutor application uses a PostgreSQL Database equipped with the PGVector plugin. This database configuration allows for the storage of original text chunks alongside their respective embedding vectors in a distinct vector column <span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>PGVector: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/pgvector/pgvector" title="">https://github.com/pgvector/pgvector</a> (Accessed: 28.02.2024)</span></span></span>. The embedding vectors are derived using an OpenAI embedding model <span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span>OpenAIEmbedding: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://platform.openai.com/docs/guides/embeddings" title="">https://platform.openai.com/docs/guides/embeddings</a> (Accessed: 28.02.2024)</span></span></span>. The vector storage can be used to retrieve useful information during the query stage. The process is illustrated above in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#S2.F1" title="Figure 1 ‣ Guiding the Model: Prompt Engineering ‣ 2.1 Advanced LLM Techniques ‣ 2 Methods: Large Language Model as an AI Tutor ‣ Evaluating the Impact of Advanced LLM Techniques on AI-Lecture Tutors for a Robotics Course"><span class="ltx_text ltx_ref_tag">1</span></a>, where a search for a user’s query is started within the vector storage, retrieving the <math alttext="k" class="ltx_Math" display="inline" id="S2.SS4.p2.1.m1.1"><semantics id="S2.SS4.p2.1.m1.1a"><mi id="S2.SS4.p2.1.m1.1.1" xref="S2.SS4.p2.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.p2.1.m1.1b"><ci id="S2.SS4.p2.1.m1.1.1.cmml" xref="S2.SS4.p2.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p2.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p2.1.m1.1d">italic_k</annotation></semantics></math> most similar chunks for the given query (we experimented with different numbers of chunks and found good results with three chunks). These chunks are integrated as context into the prompt given to the Large Language Model (LLM).</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS4.p3">
<p class="ltx_p" id="S2.SS4.p3.1">One significant drawback of OpenAI’s models is the fact, that they are close-sourced and operated by OpenAI which might pose privacy issues and, at least early-on in the project, excluded the possibility of further training on specific data as envisioned in our project. In our case, we therefore used as an additional model Llama-2-13B from Meta as it is openly accessible and can be further trained locally <cite class="ltx_cite ltx_citemacro_citep">(Touvron et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#bib.bib22" title="">2023b</a>, <a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#bib.bib4" title="">a</a>)</cite>. Meta’s LLaMA series of models was trained only on publicly available data (overall around 1.25 trillion tokens, the majority of data is gained from CommonCrawl with about 850 billion tokens). This model was used in different setups: a baseline approach in which the model was directly queried and, again, a setup in which the prompt was enriched using the system message as well as RAG (prompt engineering and RAG are identical to the approach used with GPT-3.5).</p>
</div>
<figure class="ltx_table" id="S2.T1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span>Hyperparameters selected for Fine-Tuning the LLaMA-2 model (13B parameters).</figcaption>
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S2.T1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S2.T1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S2.T1.1.1.1.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_parbox ltx_align_middle" id="S2.T1.1.1.1.1.1" style="width:142.3pt;">
<span class="ltx_p" id="S2.T1.1.1.1.1.1.1">Parameter</span>
</span>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S2.T1.1.1.1.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_parbox ltx_align_middle" id="S2.T1.1.1.1.2.1" style="width:227.6pt;">
<span class="ltx_p" id="S2.T1.1.1.1.2.1.1">Value</span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S2.T1.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S2.T1.1.2.1.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">Optimizer</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.1.2.1.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">paged_adamw_32bbit</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S2.T1.1.3.2.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">Learning rate</th>
<td class="ltx_td ltx_align_center" id="S2.T1.1.3.2.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">1e-4</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S2.T1.1.4.3.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">LR scheduler type</th>
<td class="ltx_td ltx_align_center" id="S2.T1.1.4.3.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">cosine</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S2.T1.1.5.4.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">Warmup ratio</th>
<td class="ltx_td ltx_align_center" id="S2.T1.1.5.4.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.1</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S2.T1.1.6.5.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">Max grad norm</th>
<td class="ltx_td ltx_align_center" id="S2.T1.1.6.5.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.3</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.7.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S2.T1.1.7.6.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">Epochs</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S2.T1.1.7.6.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">up to 128000</td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para ltx_noindent" id="S2.SS4.p4">
<p class="ltx_p" id="S2.SS4.p4.1">As one further step, LLaMA-2 was used in a fine-tuned version. The model was hosted and trained locally (we used a workstation equipped with a NVIDIA RTX A6000 with 48 GB of RAM on the graphics card). Therefore, we decided to use the mid-size LLaMA for all our experiments (with 13 billion parameters) as this still allowed to train and fine-tune the model when using quantization and LoRA <cite class="ltx_cite ltx_citemacro_citep">(Hu et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#bib.bib23" title="">2021</a>)</cite>. For further details on training, see table <a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#S2.T1" title="Table 1 ‣ 2.4 Models and Fine-Tuning ‣ 2 Methods: Large Language Model as an AI Tutor ‣ Evaluating the Impact of Advanced LLM Techniques on AI-Lecture Tutors for a Robotics Course"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.5 </span>Evaluation of LLMs in Question-Answering</h3>
<div class="ltx_para ltx_noindent" id="S2.SS5.p1">
<p class="ltx_p" id="S2.SS5.p1.2">Measuring question-answering is difficult because for many questions there are multiple correct answers, e.g.,
two answers to a question might simply be formulated quite differently, using synonyms, or having a different sentence structure. None-the-less, both answers might be correct. This makes comparison to a ground truth difficult. There are different approaches for question-answering and quite a large number of metrics have been proposed. A couple of these focus on overlap between the model’s output and the ground truth response provided by a human. BLEU-4 is widely used as such a metric <cite class="ltx_cite ltx_citemacro_citep">(Papineni et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#bib.bib24" title="">2002</a>)</cite> providing values in the range of <math alttext="0" class="ltx_Math" display="inline" id="S2.SS5.p1.1.m1.1"><semantics id="S2.SS5.p1.1.m1.1a"><mn id="S2.SS5.p1.1.m1.1.1" xref="S2.SS5.p1.1.m1.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S2.SS5.p1.1.m1.1b"><cn id="S2.SS5.p1.1.m1.1.1.cmml" type="integer" xref="S2.SS5.p1.1.m1.1.1">0</cn></annotation-xml></semantics></math> to <math alttext="1" class="ltx_Math" display="inline" id="S2.SS5.p1.2.m2.1"><semantics id="S2.SS5.p1.2.m2.1a"><mn id="S2.SS5.p1.2.m2.1.1" xref="S2.SS5.p1.2.m2.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S2.SS5.p1.2.m2.1b"><cn id="S2.SS5.p1.2.m2.1.1.cmml" type="integer" xref="S2.SS5.p1.2.m2.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS5.p1.2.m2.1c">1</annotation><annotation encoding="application/x-llamapun" id="S2.SS5.p1.2.m2.1d">1</annotation></semantics></math>. Furthermore, we also use ROUGE-1 <cite class="ltx_cite ltx_citemacro_citep">(Lin, <a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#bib.bib25" title="">2004</a>)</cite> and METEOR <cite class="ltx_cite ltx_citemacro_citep">(Banerjee and Lavie, <a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#bib.bib26" title="">2005</a>)</cite> for evaluation which have been found to best correlate with human evaluation <cite class="ltx_cite ltx_citemacro_citep">(Kim et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#bib.bib27" title="">2020</a>)</cite>. As a further more modern metric, we in addition computed the BERTScore <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#bib.bib28" title="">2019</a>)</cite> which again is calculating the similarity between token in the output by the model compared to the ground truth. Importantly, while other metrics count exact matches, the BERTscore computes semantic similarity for token in the contextual embedding space.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS5.p2">
<p class="ltx_p" id="S2.SS5.p2.1">It is currently assumed that such metrics by itself are not sufficient to analyze LLMs <cite class="ltx_cite ltx_citemacro_citep">(Maynez et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#bib.bib14" title="">2020</a>)</cite>. Therefore, human evaluations are still used as a gold standard for assessing the capabilities. As a first step, we setup a web-based framework that present a question together with an answer to a user. The user is tasked with judging how helpful and how correct the given answer is. There is additional information provided for each question (the original slide for which we generated the question, plus a context of neighboring slides). This human evaluation has only been tested with two teaching assistants for the given robotics course which can be considered domain experts (detailed results are shown in the Appendix in table <a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#A5.T7" title="Table 7 ‣ Appendix E Overview human evaluation ‣ Evaluating the Impact of Advanced LLM Techniques on AI-Lecture Tutors for a Robotics Course"><span class="ltx_text ltx_ref_tag">7</span></a>). We will run this evaluation in the upcoming semester inside the robotics course.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS5.p3">
<p class="ltx_p" id="S2.SS5.p3.1">Using another LLM—and often a more capable one with larger parameter counts—is currently an active area of research. Approaches as LLMEval <cite class="ltx_cite ltx_citemacro_citep">(Lin and Chen, <a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#bib.bib29" title="">2023</a>)</cite> use an LLM for similarity rating itself, often using an elaborate prompt that guides the model to mimic a human-like evaluation. In general, LLMEval showed some promising results, but appears difficult to directly apply in our approach. In our case, the integration of RAG lead to quite long context inputs which has shown problematic for LLMEval. Therefore, we adapted their general approach and prompted an LLM (GPT-3.5) as an evaluator which was provided with the original question, the generated answer, and the ground truth answer. In particular, we developed three different prompts that addressed different parts of our evaluation. First, ‘GPTSimilarity’ is an evaluation of the similarity between the generated response and the ground-truth response in the test set. Secondly, for the metrics of the human evaluation, we introduced ‘GPTRater’ which evaluated independently trustworthiness and helpfulness on the same scale as given to human evaluators (details see below).</p>
</div>
<figure class="ltx_figure" id="S2.F3">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_block ltx_figure_panel ltx_parbox ltx_align_middle" id="S2.F3.1" style="width:433.6pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="356" id="S2.F3.1.g1" src="x5.png" width="830"/>
<p class="ltx_p ltx_align_center ltx_align_center" id="S2.F3.1.1"><span class="ltx_text" id="S2.F3.1.1.1">(a) BLEU-4 Score</span></p>
</div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_block ltx_figure_panel ltx_parbox ltx_align_middle" id="S2.F3.2" style="width:433.6pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="356" id="S2.F3.2.g1" src="x6.png" width="830"/>
<p class="ltx_p ltx_align_center ltx_align_center" id="S2.F3.2.1"><span class="ltx_text" id="S2.F3.2.1.1">(b) ROUGE Score</span></p>
</div>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Evaluation of Large Language Models: (a) BLEU-4 score which measures the precision of n-grams (here 4-grams) in the generated text compared to the ground truth text, while (b) ROUGE evaluates recall, measuring the overlap of n-grams between the generated and reference texts.</figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Results</h2>
<div class="ltx_para ltx_noindent" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">We tested the different LLM versions and different applied techniques in a question answering task with the questions tailored to the robotics course from the test set. As a first model, we used ChatGPT (GPT-3.5) as a standard high-performing and well-known general model. For GPT-3.5 we could apply prompt engineering and RAG as we accessed the model through OpenAI’s API and simply enriched the prompt. As we considered fine-tuning as a third step, we also evaluated an open model in LLaMA-2. This lead to multiple different setups and different groupings: On the one hand, we used two different models of quite different size (GPT-3.5 has around 175 billion parameters, LLaMA-2 in the midsize version of around 13 billion parameters). On the other hand, we used different input versions for both models: Simply providing a question as an input, prompt engineering using an optimized prompt that provides context on the use case, and, in addition, Retrieval-Augmented-Generation in which the input was further enriched using background information from the lecture as additional input to the model. In the case of LLaMA-2 we further used fine-tuning and trained the model on a training dataset of example questions and answers for the robotics course.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Comparison of Different LLM Extension</h3>
<div class="ltx_para ltx_noindent" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">As a first research question, we are interested in how well do different models perform and how do the different extension techniques affect the performance. Therefore, we evaluated these models on our test dataset. The different metrics compare the provided ground truth answer from the test set with the answer given by the model on the particular question (for detailed results see Appendix <a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#A1" title="Appendix A Overview Detailed Results for Evaluation of Different LLMs ‣ Evaluating the Impact of Advanced LLM Techniques on AI-Lecture Tutors for a Robotics Course"><span class="ltx_text ltx_ref_tag">A</span></a>, table <a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#A1.T2" title="Table 2 ‣ Appendix A Overview Detailed Results for Evaluation of Different LLMs ‣ Evaluating the Impact of Advanced LLM Techniques on AI-Lecture Tutors for a Robotics Course"><span class="ltx_text ltx_ref_tag">2</span></a> and table <a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#A1.T3" title="Table 3 ‣ Appendix A Overview Detailed Results for Evaluation of Different LLMs ‣ Evaluating the Impact of Advanced LLM Techniques on AI-Lecture Tutors for a Robotics Course"><span class="ltx_text ltx_ref_tag">3</span></a>). Given are the BLEU-4 and ROUGE similarity scores in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#S2.F3" title="Figure 3 ‣ 2.5 Evaluation of LLMs in Question-Answering ‣ 2 Methods: Large Language Model as an AI Tutor ‣ Evaluating the Impact of Advanced LLM Techniques on AI-Lecture Tutors for a Robotics Course"><span class="ltx_text ltx_ref_tag">3</span></a>. As a first observation, for both generic LLM models (indicated by colors: GPT-3.5 in blue, LLaMA-2 in orange) extending the prompt always improved the response considerably.
Just adding a simple system message that instructs the model to act as a tutoring system showed a considerable improvement (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#S2.F3" title="Figure 3 ‣ 2.5 Evaluation of LLMs in Question-Answering ‣ 2 Methods: Large Language Model as an AI Tutor ‣ Evaluating the Impact of Advanced LLM Techniques on AI-Lecture Tutors for a Robotics Course"><span class="ltx_text ltx_ref_tag">3</span></a>, lower part, comparison of GPT-3.5 with GPT-3.5 (System Message) in which a general message on the role and topic was provided to the model).
Retrieval-Augmented-Generation and prompt engineering show a further improvement and quite large positive effect.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.4">For the fine-tuned LLaMA-2 (shown in darker green and lighter green) these results differ slightly: Importantly, in training on our specific dataset the model was fine-tuned on a specific interaction structure that further included additional keywords, e.g., start and stop symbols. After learning these, the model tended to overproduce some of such tags which could be easily cleaned up as these were not fitting to the predefined structure. For example, when the model produced an end-tag but still continued to produce output, the text following that end-tag could be dropped. Therefore, we filtered the output of the fine-tuned model (the filtered and cleaned-up responses are shown in the figures in light green). This improved the similarity scores dramatically which might be partially explained as the texts were significantly shortened
(for the fine-tuned LLaMA-2 model output length dropped from <math alttext="413\pm 153" class="ltx_Math" display="inline" id="S3.SS1.p2.1.m1.1"><semantics id="S3.SS1.p2.1.m1.1a"><mrow id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml"><mn id="S3.SS1.p2.1.m1.1.1.2" xref="S3.SS1.p2.1.m1.1.1.2.cmml">413</mn><mo id="S3.SS1.p2.1.m1.1.1.1" xref="S3.SS1.p2.1.m1.1.1.1.cmml">±</mo><mn id="S3.SS1.p2.1.m1.1.1.3" xref="S3.SS1.p2.1.m1.1.1.3.cmml">153</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><apply id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1"><csymbol cd="latexml" id="S3.SS1.p2.1.m1.1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1.1">plus-or-minus</csymbol><cn id="S3.SS1.p2.1.m1.1.1.2.cmml" type="integer" xref="S3.SS1.p2.1.m1.1.1.2">413</cn><cn id="S3.SS1.p2.1.m1.1.1.3.cmml" type="integer" xref="S3.SS1.p2.1.m1.1.1.3">153</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">413\pm 153</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.1.m1.1d">413 ± 153</annotation></semantics></math> words to <math alttext="109\pm 81" class="ltx_Math" display="inline" id="S3.SS1.p2.2.m2.1"><semantics id="S3.SS1.p2.2.m2.1a"><mrow id="S3.SS1.p2.2.m2.1.1" xref="S3.SS1.p2.2.m2.1.1.cmml"><mn id="S3.SS1.p2.2.m2.1.1.2" xref="S3.SS1.p2.2.m2.1.1.2.cmml">109</mn><mo id="S3.SS1.p2.2.m2.1.1.1" xref="S3.SS1.p2.2.m2.1.1.1.cmml">±</mo><mn id="S3.SS1.p2.2.m2.1.1.3" xref="S3.SS1.p2.2.m2.1.1.3.cmml">81</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.1b"><apply id="S3.SS1.p2.2.m2.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1"><csymbol cd="latexml" id="S3.SS1.p2.2.m2.1.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1.1">plus-or-minus</csymbol><cn id="S3.SS1.p2.2.m2.1.1.2.cmml" type="integer" xref="S3.SS1.p2.2.m2.1.1.2">109</cn><cn id="S3.SS1.p2.2.m2.1.1.3.cmml" type="integer" xref="S3.SS1.p2.2.m2.1.1.3">81</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.1c">109\pm 81</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.2.m2.1d">109 ± 81</annotation></semantics></math> words after filtering; when integrating RAG output length dropped from <math alttext="246\pm 181" class="ltx_Math" display="inline" id="S3.SS1.p2.3.m3.1"><semantics id="S3.SS1.p2.3.m3.1a"><mrow id="S3.SS1.p2.3.m3.1.1" xref="S3.SS1.p2.3.m3.1.1.cmml"><mn id="S3.SS1.p2.3.m3.1.1.2" xref="S3.SS1.p2.3.m3.1.1.2.cmml">246</mn><mo id="S3.SS1.p2.3.m3.1.1.1" xref="S3.SS1.p2.3.m3.1.1.1.cmml">±</mo><mn id="S3.SS1.p2.3.m3.1.1.3" xref="S3.SS1.p2.3.m3.1.1.3.cmml">181</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.3.m3.1b"><apply id="S3.SS1.p2.3.m3.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1"><csymbol cd="latexml" id="S3.SS1.p2.3.m3.1.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1.1">plus-or-minus</csymbol><cn id="S3.SS1.p2.3.m3.1.1.2.cmml" type="integer" xref="S3.SS1.p2.3.m3.1.1.2">246</cn><cn id="S3.SS1.p2.3.m3.1.1.3.cmml" type="integer" xref="S3.SS1.p2.3.m3.1.1.3">181</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.3.m3.1c">246\pm 181</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.3.m3.1d">246 ± 181</annotation></semantics></math> words to <math alttext="173\pm 109" class="ltx_Math" display="inline" id="S3.SS1.p2.4.m4.1"><semantics id="S3.SS1.p2.4.m4.1a"><mrow id="S3.SS1.p2.4.m4.1.1" xref="S3.SS1.p2.4.m4.1.1.cmml"><mn id="S3.SS1.p2.4.m4.1.1.2" xref="S3.SS1.p2.4.m4.1.1.2.cmml">173</mn><mo id="S3.SS1.p2.4.m4.1.1.1" xref="S3.SS1.p2.4.m4.1.1.1.cmml">±</mo><mn id="S3.SS1.p2.4.m4.1.1.3" xref="S3.SS1.p2.4.m4.1.1.3.cmml">109</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.4.m4.1b"><apply id="S3.SS1.p2.4.m4.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1"><csymbol cd="latexml" id="S3.SS1.p2.4.m4.1.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1.1">plus-or-minus</csymbol><cn id="S3.SS1.p2.4.m4.1.1.2.cmml" type="integer" xref="S3.SS1.p2.4.m4.1.1.2">173</cn><cn id="S3.SS1.p2.4.m4.1.1.3.cmml" type="integer" xref="S3.SS1.p2.4.m4.1.1.3">109</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.4.m4.1c">173\pm 109</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.4.m4.1d">173 ± 109</annotation></semantics></math> words after filtering).
There is an assumed bias of such similarity metrics for shorter answers (see below our analysis and comparison on relation between the different metrics). One curious observation after filtering was that RAG and prompt engineering didn’t show an advantage for the fine-tuned version. This might be due to the training dataset to which the model fitted its interactions which didn’t include RAG.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.1">When considering fine-tuning, we compare the different versions of the LLaMA-2 model (all with 13 billion parameters), i.e., shown in orange and the fine-tuned version in green. Fine-tuning improved in all cases the results considerably, in particular when filtering the results afterwards. Last, when comparing the results of the fine-tuned model with GPT-3.5 (which is much larger with 175 billion parameters), we observed that a fine-tuned LLaMA-2 (with filtering) without additional prompting techniques performed considerably better as GPT-3.5. Adding RAG and prompting techniques (see above) improved GPT-3.5 by a huge margin and this model setup was the best we found in evaluation. But the margin towards fine-tuned LLaMA was slim and our fine-tuning training data appeared to have a detrimental effect to RAG which should be further analyzed (see note above).</p>
</div>
<figure class="ltx_figure" id="S3.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="356" id="S3.F4.g1" src="x7.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>BERTScore as an Evaluation Metrics for Large Language Models which uses BERT embeddings for semantic similarity computation.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S3.SS1.p4">
<p class="ltx_p" id="S3.SS1.p4.1">For the METEOR score most models perform almost equally good (not shown in detail). Except for the base model with raw data and question only, which performs slightly worse. In BERTScore, we, first, observe as a similar pattern that applying RAG and using a specific prompt dramatically improves the measured similarity (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#S3.F4" title="Figure 4 ‣ 3.1 Comparison of Different LLM Extension ‣ 3 Results ‣ Evaluating the Impact of Advanced LLM Techniques on AI-Lecture Tutors for a Robotics Course"><span class="ltx_text ltx_ref_tag">4</span></a>, comparing inside the specific models—LLaMA-2 respectively GPT-3.5—the versions with RAG and without RAG). Secondly, again similar reflecting the results from above, fine-tuning (showing in green) introduces a strong advantage compared to the original model (shown in orange). Again, integrating RAG after fine-tuning appears problematic. What is noteworthy from the BERTScore evaluation is that numbers appear overall more pronounced.</p>
</div>
<figure class="ltx_figure" id="S3.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="830" id="S3.F5.g1" src="x8.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Correlation Matrix of Evaluation Metrics: The color-coded matrix represents correlations between evaluation metrics used to assess the performance of LLMs (measured on our test set). Each cell in the matrix indicates the correlation coefficient between two metrics, with color intensity (from blue to red) reflecting the strength of the correlation. Metrics include traditional similarity scores like BLEU and ROUGE, as well as newer ones like BERTScore, and their relationships with model output features, e.g., token count and human evaluation scores on trustworthiness or helpfulness.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Analysis of Evaluation Metrics</h3>
<div class="ltx_para ltx_noindent" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">Evaluation of LLMs and their responses is difficult and there are multiple metrics and different approaches have been proposed. We further analyzed some of these metrics: First, we considered how the different metrics correlate with each other in order to understand better what these represent and how they might capture similar characteristics. In addition, we computed correlations to other characteristic features of the given responses. As one example, we considered the length of the response as it has often be assumed that there is a bias for shorter answers in some of the more traditional metrics.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1">We observed (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#S3.F5" title="Figure 5 ‣ 3.1 Comparison of Different LLM Extension ‣ 3 Results ‣ Evaluating the Impact of Advanced LLM Techniques on AI-Lecture Tutors for a Robotics Course"><span class="ltx_text ltx_ref_tag">5</span></a>) that the traditionally computed similarity metrics as BLEU, ROUGE, and BERTScore (to a slightly lesser extend) are highly correlated. Interestingly, all these metrics showed a negative correlation with the token count. In our case, we found the assumption confirmed that shorter sentences are preferred by these metrics.
METEOR also showed a positive—but smaller—correlation with the metrics above. It appeared nearly uncorrelated with the token counter (only a very small negative correlation). GPTSimilarity (results are shown in the appendix, Fig. <a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#A2.F7" title="Figure 7 ‣ Appendix B GPTSimilarity ‣ Evaluating the Impact of Advanced LLM Techniques on AI-Lecture Tutors for a Robotics Course"><span class="ltx_text ltx_ref_tag">7</span></a>), as a measurement that prompts an LLM to evaluate similarity, did not show any large correlation with the more traditional similarity metrics, but surprisingly has a positive correlation with the token count, meaning in our evaluation longer answers were usually favored (this should be further analyzed).</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.1">Secondly, we want to understand the relation of the different metrics to a human evaluation (considered as the gold standard). The human evaluation should produce reproducible assessments based on recognizable criteria, ensuring that the evaluations are objective and can be consistently applied. Our approach for the human evaluation follows the method described in tolokan.ai <span class="ltx_note ltx_role_footnote" id="footnote6"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span>https://toloka.ai/blog/perplexity-case/</span></span></span>. Their evaluation process utilizes two main criteria: Helpfulness and Trustworthiness (which should reflect how well the answer is backed up by argument or references). Each measured on a scale of five answers (helpfulness: not helpful – repetition – unclear – limited – helpful; trustworthiness: nonsense – false statement – general knowledge – partially proven –proven).
In the evaluation, each sentence of a model’s response is evaluated individually, allowing for a granular analysis of the output. Importantly, in this evaluation method a weighting of each rating for a sentence is additionally computed considering the length. This weighting is crucial for determining the proportional impact of each rating level on the overall response. As a consequence, the length of the full answer is not a direct criteria for good or bad answers. For example, as long as the answer provides helpful information with respect to the request, a long answer can still be useful to answer the request in more detail. As a first step, the evaluation was conducted by only two teaching assistants who assessed a randomly selected subset of the test set (<math alttext="130" class="ltx_Math" display="inline" id="S3.SS2.p3.1.m1.1"><semantics id="S3.SS2.p3.1.m1.1a"><mn id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml">130</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b"><cn id="S3.SS2.p3.1.m1.1.1.cmml" type="integer" xref="S3.SS2.p3.1.m1.1.1">130</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">130</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.1.m1.1d">130</annotation></semantics></math> question-answer pairs). This of course limits the reliability of the human feedback scores as the number of participants is too small. The study shall be repeated in the future, as we want to use it in an upcoming semester in the robotics course. Still, we hope that we can gain first insights from the human feedback. It is of further note that the evaluation was not done by naive subjects, but by experts on the topics of the course. This should have a positive impact on their knowledge of the topics of the course.
The human labelers were blindly presented responses from the different models and extensions and asked to label these for helpfulness and trustworthiness. Afterwards, this feedback was pooled together for each specific LLM configuration individually.
</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p4">
<p class="ltx_p" id="S3.SS2.p4.1">As a first observation, when adding RAG into any model (GPT-3.5 or LLaMA-2) this increased trustworthiness in the model (results are not shown in detail). This is to be expected as base models—without any extension—are not capable of providing references to back up their answers. Adding references appears to have a direct positive impact on trustworthiness.
For helpfulness we couldn’t find a clear trend (e.g., GPT-3.5 already proves as a strong baseline in this respect which gives always answers that relate to the question). Overall, we are interested in how the human evaluation correlates with the computed metrics (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#S3.F5" title="Figure 5 ‣ 3.1 Comparison of Different LLM Extension ‣ 3 Results ‣ Evaluating the Impact of Advanced LLM Techniques on AI-Lecture Tutors for a Robotics Course"><span class="ltx_text ltx_ref_tag">5</span></a>). There is a good correlation of trustworthiness with BLEU, Rouge, and BERTScore (as a cautious reminder: the human evaluation is currently only restricted to feedback by two teaching assistants). Trustworthiness is also negatively correlated with the token count. This appears reasonable as the scale of trustworthiness rewards answers that are backed up by argument. In contrast, well known facts that might be known from training data are evaluated as neutral. There is no strong correlation for helpfulness with respect to the other metrics, only a small correlation with BERTScore. Trustworthiness and Helpfulness appear correlated.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p5">
<p class="ltx_p" id="S3.SS2.p5.1">One interesting comparison is between the human feedback on trustworthiness and helpfulness compared to similar ratings obtained from an LLM—following the GPTRater approach which estimates trust and helpfulness on a given answer with respect to the ground truth answer using a LLM (scores for different LLM variations using the GPTRater approach, that evaluates trust and helpfulness using an LLM, are given in the appendix, Fig. <a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#A3.F8" title="Figure 8 ‣ Appendix C GPTRater ‣ Evaluating the Impact of Advanced LLM Techniques on AI-Lecture Tutors for a Robotics Course"><span class="ltx_text ltx_ref_tag">8</span></a>). For these we find small correlations, but again these should be handled carefully as long as there is only human feedback given by two participants.</p>
</div>
<figure class="ltx_figure" id="S3.F6">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S3.F6.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="234" id="S3.F6.sf1.g1" src="x9.png" width="540"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(a) </span>Development of BLEU-4 Score during training.</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S3.F6.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="234" id="S3.F6.sf2.g1" src="x10.png" width="540"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(b) </span>Development of ROUGE Score during training.</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Evaluation of LLM during fine-tuning: Development of metrics measured for different checkpoints during the training process. (a) BLEU-4 score which measures the precision of n-grams (up to 4-grams) in the generated text compared to the ground truth text, while (b) ROUGE evaluates recall, measuring the overlap of n-grams between the generated and reference texts. Compared are two models, first, a simple LLaMA model and, secondly, a configuration that included RAG.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Adaptation of LLM during Fine-Tuning</h3>
<div class="ltx_para ltx_noindent" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">During the fine-tuning of the model on the training dataset, we aimed to observe how the model’s responses evolved over the course of training. Specifically, we investigated how long it took for the model to adapt to the specific task structure and at what point the model began to overfit to the training data. Therefore, we recorded model weights
throughout the training process. A checkpoint was generated for every 250 training steps.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS3.p2">
<p class="ltx_p" id="S3.SS3.p2.10">For an analysis, we selected checkpoints exponentially spaced by a factor of <math alttext="2" class="ltx_Math" display="inline" id="S3.SS3.p2.1.m1.1"><semantics id="S3.SS3.p2.1.m1.1a"><mn id="S3.SS3.p2.1.m1.1.1" xref="S3.SS3.p2.1.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.1.m1.1b"><cn id="S3.SS3.p2.1.m1.1.1.cmml" type="integer" xref="S3.SS3.p2.1.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.1.m1.1c">2</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.1.m1.1d">2</annotation></semantics></math>, examining model responses after <math alttext="1000" class="ltx_Math" display="inline" id="S3.SS3.p2.2.m2.1"><semantics id="S3.SS3.p2.2.m2.1a"><mn id="S3.SS3.p2.2.m2.1.1" xref="S3.SS3.p2.2.m2.1.1.cmml">1000</mn><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.2.m2.1b"><cn id="S3.SS3.p2.2.m2.1.1.cmml" type="integer" xref="S3.SS3.p2.2.m2.1.1">1000</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.2.m2.1c">1000</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.2.m2.1d">1000</annotation></semantics></math>, <math alttext="2000" class="ltx_Math" display="inline" id="S3.SS3.p2.3.m3.1"><semantics id="S3.SS3.p2.3.m3.1a"><mn id="S3.SS3.p2.3.m3.1.1" xref="S3.SS3.p2.3.m3.1.1.cmml">2000</mn><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.3.m3.1b"><cn id="S3.SS3.p2.3.m3.1.1.cmml" type="integer" xref="S3.SS3.p2.3.m3.1.1">2000</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.3.m3.1c">2000</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.3.m3.1d">2000</annotation></semantics></math>, <math alttext="4000" class="ltx_Math" display="inline" id="S3.SS3.p2.4.m4.1"><semantics id="S3.SS3.p2.4.m4.1a"><mn id="S3.SS3.p2.4.m4.1.1" xref="S3.SS3.p2.4.m4.1.1.cmml">4000</mn><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.4.m4.1b"><cn id="S3.SS3.p2.4.m4.1.1.cmml" type="integer" xref="S3.SS3.p2.4.m4.1.1">4000</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.4.m4.1c">4000</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.4.m4.1d">4000</annotation></semantics></math>, <math alttext="8000" class="ltx_Math" display="inline" id="S3.SS3.p2.5.m5.1"><semantics id="S3.SS3.p2.5.m5.1a"><mn id="S3.SS3.p2.5.m5.1.1" xref="S3.SS3.p2.5.m5.1.1.cmml">8000</mn><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.5.m5.1b"><cn id="S3.SS3.p2.5.m5.1.1.cmml" type="integer" xref="S3.SS3.p2.5.m5.1.1">8000</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.5.m5.1c">8000</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.5.m5.1d">8000</annotation></semantics></math>, <math alttext="16000" class="ltx_Math" display="inline" id="S3.SS3.p2.6.m6.1"><semantics id="S3.SS3.p2.6.m6.1a"><mn id="S3.SS3.p2.6.m6.1.1" xref="S3.SS3.p2.6.m6.1.1.cmml">16000</mn><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.6.m6.1b"><cn id="S3.SS3.p2.6.m6.1.1.cmml" type="integer" xref="S3.SS3.p2.6.m6.1.1">16000</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.6.m6.1c">16000</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.6.m6.1d">16000</annotation></semantics></math>, <math alttext="32000" class="ltx_Math" display="inline" id="S3.SS3.p2.7.m7.1"><semantics id="S3.SS3.p2.7.m7.1a"><mn id="S3.SS3.p2.7.m7.1.1" xref="S3.SS3.p2.7.m7.1.1.cmml">32000</mn><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.7.m7.1b"><cn id="S3.SS3.p2.7.m7.1.1.cmml" type="integer" xref="S3.SS3.p2.7.m7.1.1">32000</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.7.m7.1c">32000</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.7.m7.1d">32000</annotation></semantics></math>, <math alttext="64000" class="ltx_Math" display="inline" id="S3.SS3.p2.8.m8.1"><semantics id="S3.SS3.p2.8.m8.1a"><mn id="S3.SS3.p2.8.m8.1.1" xref="S3.SS3.p2.8.m8.1.1.cmml">64000</mn><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.8.m8.1b"><cn id="S3.SS3.p2.8.m8.1.1.cmml" type="integer" xref="S3.SS3.p2.8.m8.1.1">64000</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.8.m8.1c">64000</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.8.m8.1d">64000</annotation></semantics></math>, <math alttext="128000" class="ltx_Math" display="inline" id="S3.SS3.p2.9.m9.1"><semantics id="S3.SS3.p2.9.m9.1a"><mn id="S3.SS3.p2.9.m9.1.1" xref="S3.SS3.p2.9.m9.1.1.cmml">128000</mn><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.9.m9.1b"><cn id="S3.SS3.p2.9.m9.1.1.cmml" type="integer" xref="S3.SS3.p2.9.m9.1.1">128000</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.9.m9.1c">128000</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.9.m9.1d">128000</annotation></semantics></math> training steps, and at the end of training (<math alttext="178000" class="ltx_Math" display="inline" id="S3.SS3.p2.10.m10.1"><semantics id="S3.SS3.p2.10.m10.1a"><mn id="S3.SS3.p2.10.m10.1.1" xref="S3.SS3.p2.10.m10.1.1.cmml">178000</mn><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.10.m10.1b"><cn id="S3.SS3.p2.10.m10.1.1.cmml" type="integer" xref="S3.SS3.p2.10.m10.1.1">178000</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.10.m10.1c">178000</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.10.m10.1d">178000</annotation></semantics></math> steps). Multiple sample answers generated by the fine-tuned models were evaluated in response to questions from the test set. Given the issues encountered when applying Retrieval-Augmented Generation (RAG) to a fine-tuned model, we run this evaluation in both kind of settings: Using the fine-tuned model or in addition applying RAG on the fine-tuned model.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS3.p3">
<p class="ltx_p" id="S3.SS3.p3.2">The selection of models was based, first, on human evaluations according to specifically defined criteria, including correctness of the answer, reference to the lecture, correct use of the specified formatting, the overall amount of formatting errors, and grammar. Ultimately, checkpoints <math alttext="2000" class="ltx_Math" display="inline" id="S3.SS3.p3.1.m1.1"><semantics id="S3.SS3.p3.1.m1.1a"><mn id="S3.SS3.p3.1.m1.1.1" xref="S3.SS3.p3.1.m1.1.1.cmml">2000</mn><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.1.m1.1b"><cn id="S3.SS3.p3.1.m1.1.1.cmml" type="integer" xref="S3.SS3.p3.1.m1.1.1">2000</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.1.m1.1c">2000</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.1.m1.1d">2000</annotation></semantics></math> and <math alttext="128000" class="ltx_Math" display="inline" id="S3.SS3.p3.2.m2.1"><semantics id="S3.SS3.p3.2.m2.1a"><mn id="S3.SS3.p3.2.m2.1.1" xref="S3.SS3.p3.2.m2.1.1.cmml">128000</mn><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.2.m2.1b"><cn id="S3.SS3.p3.2.m2.1.1.cmml" type="integer" xref="S3.SS3.p3.2.m2.1.1">128000</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.2.m2.1c">128000</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.2.m2.1d">128000</annotation></semantics></math> were selected for a broader comparison in human evaluation.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS3.p4">
<p class="ltx_p" id="S3.SS3.p4.2">Despite the limited scope of the human evaluation, some general trends were observed. Checkpoint <math alttext="128000" class="ltx_Math" display="inline" id="S3.SS3.p4.1.m1.1"><semantics id="S3.SS3.p4.1.m1.1a"><mn id="S3.SS3.p4.1.m1.1.1" xref="S3.SS3.p4.1.m1.1.1.cmml">128000</mn><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.1.m1.1b"><cn id="S3.SS3.p4.1.m1.1.1.cmml" type="integer" xref="S3.SS3.p4.1.m1.1.1">128000</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.1.m1.1c">128000</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p4.1.m1.1d">128000</annotation></semantics></math> yielded the best results for the ‘Fine-tuned LLaMA’ model configuration when used without applying RAG. In contrast, already checkpoint <math alttext="2000" class="ltx_Math" display="inline" id="S3.SS3.p4.2.m2.1"><semantics id="S3.SS3.p4.2.m2.1a"><mn id="S3.SS3.p4.2.m2.1.1" xref="S3.SS3.p4.2.m2.1.1.cmml">2000</mn><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.2.m2.1b"><cn id="S3.SS3.p4.2.m2.1.1.cmml" type="integer" xref="S3.SS3.p4.2.m2.1.1">2000</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.2.m2.1c">2000</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p4.2.m2.1d">2000</annotation></semantics></math> performed best for the model when used with RAG (‘Fine-tuned LLaMA + RAG’).
Example answers to a sample question are presented in the appendix (table <a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#A4.T4" title="Table 4 ‣ Appendix D Comparison of Responses during Fine-Tuning ‣ Evaluating the Impact of Advanced LLM Techniques on AI-Lecture Tutors for a Robotics Course"><span class="ltx_text ltx_ref_tag">4</span></a> shows the ground truth and the input question; Table <a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#A4.T5" title="Table 5 ‣ Appendix D Comparison of Responses during Fine-Tuning ‣ Evaluating the Impact of Advanced LLM Techniques on AI-Lecture Tutors for a Robotics Course"><span class="ltx_text ltx_ref_tag">5</span></a> compares the fine-tuned models response without using RAG for the two different checkpoints, i.e., early and late in training; table <a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#A4.T6" title="Table 6 ‣ Appendix D Comparison of Responses during Fine-Tuning ‣ Evaluating the Impact of Advanced LLM Techniques on AI-Lecture Tutors for a Robotics Course"><span class="ltx_text ltx_ref_tag">6</span></a> compares the fine-tuned models response when additionally integrating RAG for the two different checkpoints). The performance of the checkpoints deteriorates when the configurations are switched.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS3.p5">
<p class="ltx_p" id="S3.SS3.p5.2">Secondly, we computed the different metrics for these two type of settings throughout the training process.
Interestingly, there was a strong correspondence between the human assessments and the performance metrics at specific training points (see Fig. <a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#S3.F6" title="Figure 6 ‣ 3.2 Analysis of Evaluation Metrics ‣ 3 Results ‣ Evaluating the Impact of Advanced LLM Techniques on AI-Lecture Tutors for a Robotics Course"><span class="ltx_text ltx_ref_tag">6</span></a>). For the plain LLaMA-2 model without RAG, the scores (e.g., BLEU-4 and ROUGE, shown in blue in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#S3.F6" title="Figure 6 ‣ 3.2 Analysis of Evaluation Metrics ‣ 3 Results ‣ Evaluating the Impact of Advanced LLM Techniques on AI-Lecture Tutors for a Robotics Course"><span class="ltx_text ltx_ref_tag">6</span></a>) improved consistently over time and continued to improve late in training. In contrast, with RAG integration (shown in orange), fine-tuning peaked early and then dropped considerably. The metrics indicate an optimal performance around <math alttext="4000" class="ltx_Math" display="inline" id="S3.SS3.p5.1.m1.1"><semantics id="S3.SS3.p5.1.m1.1a"><mn id="S3.SS3.p5.1.m1.1.1" xref="S3.SS3.p5.1.m1.1.1.cmml">4000</mn><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.1.m1.1b"><cn id="S3.SS3.p5.1.m1.1.1.cmml" type="integer" xref="S3.SS3.p5.1.m1.1.1">4000</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.1.m1.1c">4000</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p5.1.m1.1d">4000</annotation></semantics></math> training steps, after which the system’s performance deteriorated drastically. This aligns well with the human assessment, which chose the model’s responses after <math alttext="2000" class="ltx_Math" display="inline" id="S3.SS3.p5.2.m2.1"><semantics id="S3.SS3.p5.2.m2.1a"><mn id="S3.SS3.p5.2.m2.1.1" xref="S3.SS3.p5.2.m2.1.1.cmml">2000</mn><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.2.m2.1b"><cn id="S3.SS3.p5.2.m2.1.1.cmml" type="integer" xref="S3.SS3.p5.2.m2.1.1">2000</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.2.m2.1c">2000</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p5.2.m2.1d">2000</annotation></semantics></math> training steps as optimal which is quite close and for which the model performed on a similar level when considering the metrics.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS3.p6">
<p class="ltx_p" id="S3.SS3.p6.1">We assume that extended training in the RAG configuration leads to overfitting towards the expected target structure.
It appears as an excessive over-adaptation to the input format which leads to overfitting and partial output of the system prompt. The model attempts to adhere strictly to this pattern, which might further cause hallucinations, although this requires further analysis and a more in-depth evaluation. Conversely, when considering the early stage of training—in our case checkpoint after <math alttext="2000" class="ltx_Math" display="inline" id="S3.SS3.p6.1.m1.1"><semantics id="S3.SS3.p6.1.m1.1a"><mn id="S3.SS3.p6.1.m1.1.1" xref="S3.SS3.p6.1.m1.1.1.cmml">2000</mn><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.1.m1.1b"><cn id="S3.SS3.p6.1.m1.1.1.cmml" type="integer" xref="S3.SS3.p6.1.m1.1.1">2000</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.1.m1.1c">2000</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p6.1.m1.1d">2000</annotation></semantics></math> steps—the fine-tuned configuration without RAG did not produce satisfactory results, likely because it had not undergone sufficient fine-tuning to accurately replicate the desired formatting for references and lecture content.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Discussion and Conclusion</h2>
<div class="ltx_para ltx_noindent" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">The evaluation of a Large Language Model-based tutoring system for a University robotics course highlighted several insights into the application of advanced LLM techniques and the resulting performance in an educational setting. First, our findings underscored the positive impact of Retrieval-Augmented-Generation (RAG) and prompt engineering, which consistently improved model performance across similarity metrics. Particularly, the use of RAG demonstrated a considerable enhancement in providing factual answers and is consistent with the general belief that RAG is reducing hallucinations <cite class="ltx_cite ltx_citemacro_citep">(Shuster et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.04645v1#bib.bib30" title="">2021</a>)</cite>. Furthermore, even though our human evaluation is currently restricted to two test subjects, their answers already point out that added references increases trustworthiness. Therefore, RAG appears as a very valuable technique that should be—together with some form of prompt engineering—considered first. As further advantages, in our experience RAG is quite straight forward to realize, in particular in a course setting in which well-curated background material is readily available. Furthermore, from a teaching point of view a tutor should stick to the lecture material, e.g., when going over a concept the tutoring system should carefully choose examples and ideally stick—or at least start—with the ones provided in the lecture. This should positively affect the learning of students.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.p2">
<p class="ltx_p" id="S4.p2.1">Fine-tuning has to be considered as a more involved technique. It requires additional effort in setting up a data set for training. As an advantage, in our case we saw that a quite small fine-tuned model (13 billion parameters) consistently performed on the same level—or better—as GPT-3.5 (175 billion parameters) when used without RAG. Fine-tuning produced a much more efficient expert which showed as quite capable. But, on the downside, the process of fine-tuning appeared as more delicate. In our data, we observed a curious drop-off when adding RAG to the fine-tuned model which was unexpected and would contradict our and others’ experience with RAG. As an explanation, fine-tuning aims to specialize a model to a specific task and a specific type of interaction. A fine-tuned model might loose some of its general flexibility. As a consequence, when interacting very differently with the model, the model might produce worse results or even behave erratically. The introduction of RAG drastically changes the input to a model and this change appears as problematic when RAG is introduced after fine-tuning. Therefore, the combination of techniques should be considered carefully beforehand. In the future, we want to further test how fine-tuning on interactions that include RAG affect the result which, unfortunately, requires a different data set.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.p3">
<p class="ltx_p" id="S4.p3.1">We further compared different metrics to evaluate question answering in LLMs and found a high correlation between BLEU-4, ROUGE, and BERTScore. The analysis of these metrics revealed an inherent preference for shorter responses, suggesting that these metrics might be biased against lengthier, albeit potentially more informative, answers. This observation is crucial for designing future LLM evaluation frameworks, as it challenges the effectiveness of current automated metrics in truly capturing response quality in educational settings.
LLM-based evaluations still appear difficult as we could not demonstrate a large correlation of a similarity evaluation with the more conventional metrics. With respect to trustworthiness and helpfulness, our human evaluation has to be based on a larger test group and we want to extend this in the future.</p>
</div>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_title_section">Acknowledgements</h2>
<div class="ltx_para ltx_noindent" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1">This research was supported by the ‘Institut für Angewandte Informatik’ at the University of Münster through an individual grant. The article is an extended version of a paper presented at the International Workshop on AI in Education and Educational Research (AIEER) at ECAI-2024 (27th European Conference on Artificial Intelligence).</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ouyang et al. [2022]</span>
<span class="ltx_bibblock">
Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela
Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al.

</span>
<span class="ltx_bibblock">Training language models to follow instructions with human feedback.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">Advances in neural information processing systems</em>,
35:27730–27744, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vaswani et al. [2017]</span>
<span class="ltx_bibblock">
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin.

</span>
<span class="ltx_bibblock">Attention is all you need.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">Advances in neural information processing systems</em>,
volume 30, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford et al. [2019]</span>
<span class="ltx_bibblock">
Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya
Sutskever, et al.

</span>
<span class="ltx_bibblock">Language models are unsupervised multitask learners.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">OpenAI blog</em>, 1(8):9, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et al. [2023a]</span>
<span class="ltx_bibblock">
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine
Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale,
et al.

</span>
<span class="ltx_bibblock">Llama 2: Open foundation and fine-tuned chat models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">arXiv preprint arXiv:2307.09288</em>, 2023a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Naveed et al. [2024]</span>
<span class="ltx_bibblock">
Humza Naveed, Asad Ullah Khan, Shi Qiu, Muhammad Saqib, Saeed Anwar, Muhammad
Usman, Nick Barnes, and Ajmal Mian.

</span>
<span class="ltx_bibblock">A comprehensive overview of large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">arXiv preprint arXiv:2307.06435</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Extance [2023]</span>
<span class="ltx_bibblock">
Andy Extance.

</span>
<span class="ltx_bibblock">Chatgpt has entered the classroom: how llms could transform
education.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">Nature</em>, 623(7987):474–477, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">BigCode: Hugging Face and ServiceNow [2023]</span>
<span class="ltx_bibblock">
BigCode: Hugging Face and ServiceNow.

</span>
<span class="ltx_bibblock">Starcoder: A state-of-the-art llm for code.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/blog/starcoder" title="">https://huggingface.co/blog/starcoder</a>, 2023.

</span>
<span class="ltx_bibblock">Accessed: 2024-06-16.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mehta et al. [2023]</span>
<span class="ltx_bibblock">
Atharva Mehta, Nipun Gupta, Dhruv Kumar, Pankaj Jalote, et al.

</span>
<span class="ltx_bibblock">Can chatgpt play the role of a teaching assistant in an introductory
programming course?

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">arXiv preprint arXiv:2312.07343</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. [2023]</span>
<span class="ltx_bibblock">
Qian Liu, Bing Wang, Yu Zhang, Qian Zhou, Yutao Li, and Xiang Huang.

</span>
<span class="ltx_bibblock">Large language models for software engineering: A systematic
literature review.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">arXiv preprint arXiv:2308.10620</em>, 2023.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2308.10620" title="">https://arxiv.org/abs/2308.10620</a>.

</span>
<span class="ltx_bibblock">Accessed: 2024-06-16.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Khan Academy [2023]</span>
<span class="ltx_bibblock">
Khan Academy.

</span>
<span class="ltx_bibblock">Khanmigo: Khan academy’s ai-powered teaching assistant.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.khanmigo.ai" title="">https://www.khanmigo.ai</a>, 2023.

</span>
<span class="ltx_bibblock">Accessed: 2024-06-16.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Khan [2024]</span>
<span class="ltx_bibblock">
Salman Khan.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">Brave New Words: How AI Will Revolutionize Education (and Why
That’s a Good Thing)</em>.

</span>
<span class="ltx_bibblock">Viking, New York, 2024.

</span>
<span class="ltx_bibblock">ISBN 9780593656952.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">of Education [2023]</span>
<span class="ltx_bibblock">
Berkeley School of Education.

</span>
<span class="ltx_bibblock">Leveraging ai to improve adaptive tutoring systems, 2023.

</span>
<span class="ltx_bibblock">URL
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://bse.berkeley.edu/leveraging-ai-improve-adaptive-tutoring-systems" title="">https://bse.berkeley.edu/leveraging-ai-improve-adaptive-tutoring-systems</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">García-Méndez et al. [2024]</span>
<span class="ltx_bibblock">
Silvia García-Méndez, Francisco de Arriba-Pérez, and María
del Carmen Somoza-López.

</span>
<span class="ltx_bibblock">A review on the use of large language models as virtual tutors.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">Science &amp; Education</em>, pages 1–16, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Maynez et al. [2020]</span>
<span class="ltx_bibblock">
Joshua Maynez, Shashi Narayan, Bernd Bohnet, and Ryan McDonald.

</span>
<span class="ltx_bibblock">On faithfulness and factuality in abstractive summarization.

</span>
<span class="ltx_bibblock">In Dan Jurafsky, Joyce Chai, Natalie Schluter, and Joel Tetreault,
editors, <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">Proceedings of the 58th Annual Meeting of the Association for
Computational Linguistics</em>, pages 1906–1919, Online, July 2020. Association
for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2020.acl-main.173" title="">10.18653/v1/2020.acl-main.173</a>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2020.acl-main.173" title="">https://aclanthology.org/2020.acl-main.173</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et al. [2023]</span>
<span class="ltx_bibblock">
Lei Huang, Weijiang Yu, Weitao Ma, Weihong Zhong, Zhangyin Feng, Haotian Wang,
Qianglong Chen, Weihua Peng, Xiaocheng Feng, Bing Qin, et al.

</span>
<span class="ltx_bibblock">A survey on hallucination in large language models: Principles,
taxonomy, challenges, and open questions.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">arXiv preprint arXiv:2311.05232</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dong [2023]</span>
<span class="ltx_bibblock">
Chenxi Dong.

</span>
<span class="ltx_bibblock">How to build an ai tutor that can adapt to any course and provide
accurate answers using large language model and retrieval-augmented
generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">arXiv preprint arXiv:2311.17696</em>, 2023.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2311.17696" title="">https://arxiv.org/abs/2311.17696</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jones et al. [2023]</span>
<span class="ltx_bibblock">
Erik Jones, Hamid Palangi, Clarisse Simões, Varun Chandrasekaran,
Subhabrata Mukherjee, Arindam Mitra, Ahmed Awadallah, and Ece Kamar.

</span>
<span class="ltx_bibblock">Teaching language models to hallucinate less with synthetic tasks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">arXiv preprint arXiv:2310.06827</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et al. [2022]</span>
<span class="ltx_bibblock">
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V
Le, Denny Zhou, et al.

</span>
<span class="ltx_bibblock">Chain-of-thought prompting elicits reasoning in large language
models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">Advances in neural information processing systems</em>,
35:24824–24837, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lewis et al. [2020]</span>
<span class="ltx_bibblock">
Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir
Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim
Rocktäschel, et al.

</span>
<span class="ltx_bibblock">Retrieval-augmented generation for knowledge-intensive nlp tasks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">Advances in Neural Information Processing Systems</em>,
33:9459–9474, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al. [2024]</span>
<span class="ltx_bibblock">
Penghao Zhao, Hailin Zhang, Qinhan Yu, Zhengren Wang, Yunteng Geng, Fangcheng
Fu, Ling Yang, Wentao Zhang, and Bin Cui.

</span>
<span class="ltx_bibblock">Retrieval-augmented generation for ai-generated content: A survey.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">arXiv preprint arXiv:2402.19473</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Devlin et al. [2019]</span>
<span class="ltx_bibblock">
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.

</span>
<span class="ltx_bibblock">BERT: Pre-training of deep bidirectional transformers for language
understanding.

</span>
<span class="ltx_bibblock">In Jill Burstein, Christy Doran, and Thamar Solorio, editors,
<em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">Proceedings of the 2019 Conference of the North American Chapter of
the Association for Computational Linguistics: Human Language Technologies,
Volume 1 (Long and Short Papers)</em>, pages 4171–4186, Minneapolis, Minnesota,
June 2019. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/N19-1423" title="">10.18653/v1/N19-1423</a>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/N19-1423" title="">https://aclanthology.org/N19-1423</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et al. [2023b]</span>
<span class="ltx_bibblock">
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne
Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric
Hambro, Faisal Azhar, et al.

</span>
<span class="ltx_bibblock">Llama: Open and efficient foundation language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">arXiv preprint arXiv:2302.13971</em>, 2023b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et al. [2021]</span>
<span class="ltx_bibblock">
Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean
Wang, Lu Wang, and Weizhu Chen.

</span>
<span class="ltx_bibblock">Lora: Low-rank adaptation of large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">arXiv preprint arXiv:2106.09685</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Papineni et al. [2002]</span>
<span class="ltx_bibblock">
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.

</span>
<span class="ltx_bibblock">Bleu: a method for automatic evaluation of machine translation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">Proceedings of the 40th annual meeting of the Association
for Computational Linguistics</em>, pages 311–318, 2002.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin [2004]</span>
<span class="ltx_bibblock">
Chin-Yew Lin.

</span>
<span class="ltx_bibblock">Rouge: A package for automatic evaluation of summaries.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">Text summarization branches out</em>, pages 74–81, 2004.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Banerjee and Lavie [2005]</span>
<span class="ltx_bibblock">
Satanjeev Banerjee and Alon Lavie.

</span>
<span class="ltx_bibblock">Meteor: An automatic metric for mt evaluation with improved
correlation with human judgments.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">Proceedings of the ACL workshop on intrinsic and extrinsic
evaluation measures for machine translation and/or summarization</em>, pages
65–72, 2005.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim et al. [2020]</span>
<span class="ltx_bibblock">
Seokhwan Kim, Mihail Eric, Karthik Gopalakrishnan, Behnam Hedayatnia, Yang Liu,
and Dilek Hakkani-Tur.

</span>
<span class="ltx_bibblock">Beyond domain apis: Task-oriented conversational modeling with
unstructured knowledge access.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">arXiv preprint arXiv:2006.03533</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. [2019]</span>
<span class="ltx_bibblock">
Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q Weinberger, and Yoav Artzi.

</span>
<span class="ltx_bibblock">Bertscore: Evaluating text generation with bert.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">arXiv preprint arXiv:1904.09675</em>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin and Chen [2023]</span>
<span class="ltx_bibblock">
Yen-Ting Lin and Yun-Nung Chen.

</span>
<span class="ltx_bibblock">Llm-eval: Unified multi-dimensional automatic evaluation for
open-domain conversations with large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">arXiv preprint arXiv:2305.13711</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shuster et al. [2021]</span>
<span class="ltx_bibblock">
Kurt Shuster, Spencer Poff, Moya Chen, Douwe Kiela, and Jason Weston.

</span>
<span class="ltx_bibblock">Retrieval augmentation reduces hallucination in conversation.

</span>
<span class="ltx_bibblock">In Marie-Francine Moens, Xuanjing Huang, Lucia Specia, and Scott
Wen-tau Yih, editors, <em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">Findings of the Association for Computational
Linguistics: EMNLP 2021</em>, pages 3784–3803, Punta Cana, Dominican Republic,
November 2021. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2021.findings-emnlp.320" title="">10.18653/v1/2021.findings-emnlp.320</a>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2021.findings-emnlp.320" title="">https://aclanthology.org/2021.findings-emnlp.320</a>.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section class="ltx_appendix" id="Ax1">
<h2 class="ltx_title ltx_title_appendix">Appendix</h2>
</section>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Overview Detailed Results for Evaluation of Different LLMs</h2>
<figure class="ltx_table" id="A1.T2">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span>Detailed overview of metrics for the different GPT-3.5 configurations, shown as a comparison between a full RAG including a system message as a prompt and simply using the question as an input. Best value is highlighted by green shading.</figcaption>
<div class="ltx_inline-block ltx_transformed_outer" id="A1.T2.26" style="width:433.6pt;height:248.1pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-7.8pt,4.4pt) scale(0.96534021495184,0.96534021495184) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A1.T2.26.26">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A1.T2.26.26.27.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt" id="A1.T2.26.26.27.1.1" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="A1.T2.26.26.27.1.1.1">Configuration</span></th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="A1.T2.26.26.27.1.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_parbox ltx_align_middle" id="A1.T2.26.26.27.1.2.1" style="width:156.5pt;">
<span class="ltx_p" id="A1.T2.26.26.27.1.2.1.1"><span class="ltx_text ltx_font_bold" id="A1.T2.26.26.27.1.2.1.1.1">GPT-3.5 
<br class="ltx_break"/>(RAG + System Message)</span></span>
</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A1.T2.26.26.27.1.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_parbox ltx_align_middle" id="A1.T2.26.26.27.1.3.1" style="width:156.5pt;">
<span class="ltx_p" id="A1.T2.26.26.27.1.3.1.1"><span class="ltx_text ltx_font_bold" id="A1.T2.26.26.27.1.3.1.1.1">GPT-3.5 
<br class="ltx_break"/>(Question Only)</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T2.2.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T2.2.2.2.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">GPTSimilarity</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T2.1.1.1.1" style="background-color:#CCFFCC;padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="A1.T2.1.1.1.1.1" style="background-color:#CCFFCC;">89.95 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T2.1.1.1.1.1.m1.1"><semantics id="A1.T2.1.1.1.1.1.m1.1a"><mo id="A1.T2.1.1.1.1.1.m1.1.1" mathbackground="#CCFFCC" xref="A1.T2.1.1.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T2.1.1.1.1.1.m1.1b"><csymbol cd="latexml" id="A1.T2.1.1.1.1.1.m1.1.1.cmml" xref="A1.T2.1.1.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.1.1.1.1.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T2.1.1.1.1.1.m1.1d">±</annotation></semantics></math> 16.57</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T2.2.2.2.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">88.81 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T2.2.2.2.2.m1.1"><semantics id="A1.T2.2.2.2.2.m1.1a"><mo id="A1.T2.2.2.2.2.m1.1.1" xref="A1.T2.2.2.2.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T2.2.2.2.2.m1.1b"><csymbol cd="latexml" id="A1.T2.2.2.2.2.m1.1.1.cmml" xref="A1.T2.2.2.2.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.2.2.2.2.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T2.2.2.2.2.m1.1d">±</annotation></semantics></math> 16.83</td>
</tr>
<tr class="ltx_tr" id="A1.T2.4.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T2.4.4.4.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">BLEU-4</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T2.3.3.3.1" style="background-color:#CCFFCC;padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="A1.T2.3.3.3.1.1" style="background-color:#CCFFCC;">0.10 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T2.3.3.3.1.1.m1.1"><semantics id="A1.T2.3.3.3.1.1.m1.1a"><mo id="A1.T2.3.3.3.1.1.m1.1.1" mathbackground="#CCFFCC" xref="A1.T2.3.3.3.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T2.3.3.3.1.1.m1.1b"><csymbol cd="latexml" id="A1.T2.3.3.3.1.1.m1.1.1.cmml" xref="A1.T2.3.3.3.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.3.3.3.1.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T2.3.3.3.1.1.m1.1d">±</annotation></semantics></math> 0.07</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T2.4.4.4.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.03 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T2.4.4.4.2.m1.1"><semantics id="A1.T2.4.4.4.2.m1.1a"><mo id="A1.T2.4.4.4.2.m1.1.1" xref="A1.T2.4.4.4.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T2.4.4.4.2.m1.1b"><csymbol cd="latexml" id="A1.T2.4.4.4.2.m1.1.1.cmml" xref="A1.T2.4.4.4.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.4.4.4.2.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T2.4.4.4.2.m1.1d">±</annotation></semantics></math> 0.02</td>
</tr>
<tr class="ltx_tr" id="A1.T2.6.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A1.T2.6.6.6.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">BLEU-3</th>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T2.5.5.5.1" style="background-color:#CCFFCC;padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="A1.T2.5.5.5.1.1" style="background-color:#CCFFCC;">0.13 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T2.5.5.5.1.1.m1.1"><semantics id="A1.T2.5.5.5.1.1.m1.1a"><mo id="A1.T2.5.5.5.1.1.m1.1.1" mathbackground="#CCFFCC" xref="A1.T2.5.5.5.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T2.5.5.5.1.1.m1.1b"><csymbol cd="latexml" id="A1.T2.5.5.5.1.1.m1.1.1.cmml" xref="A1.T2.5.5.5.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.5.5.5.1.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T2.5.5.5.1.1.m1.1d">±</annotation></semantics></math> 0.07</span></td>
<td class="ltx_td ltx_align_center" id="A1.T2.6.6.6.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.05 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T2.6.6.6.2.m1.1"><semantics id="A1.T2.6.6.6.2.m1.1a"><mo id="A1.T2.6.6.6.2.m1.1.1" xref="A1.T2.6.6.6.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T2.6.6.6.2.m1.1b"><csymbol cd="latexml" id="A1.T2.6.6.6.2.m1.1.1.cmml" xref="A1.T2.6.6.6.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.6.6.6.2.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T2.6.6.6.2.m1.1d">±</annotation></semantics></math> 0.02</td>
</tr>
<tr class="ltx_tr" id="A1.T2.8.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A1.T2.8.8.8.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">BLEU-2</th>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T2.7.7.7.1" style="background-color:#CCFFCC;padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="A1.T2.7.7.7.1.1" style="background-color:#CCFFCC;">0.18 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T2.7.7.7.1.1.m1.1"><semantics id="A1.T2.7.7.7.1.1.m1.1a"><mo id="A1.T2.7.7.7.1.1.m1.1.1" mathbackground="#CCFFCC" xref="A1.T2.7.7.7.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T2.7.7.7.1.1.m1.1b"><csymbol cd="latexml" id="A1.T2.7.7.7.1.1.m1.1.1.cmml" xref="A1.T2.7.7.7.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.7.7.7.1.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T2.7.7.7.1.1.m1.1d">±</annotation></semantics></math> 0.08</span></td>
<td class="ltx_td ltx_align_center" id="A1.T2.8.8.8.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.07 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T2.8.8.8.2.m1.1"><semantics id="A1.T2.8.8.8.2.m1.1a"><mo id="A1.T2.8.8.8.2.m1.1.1" xref="A1.T2.8.8.8.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T2.8.8.8.2.m1.1b"><csymbol cd="latexml" id="A1.T2.8.8.8.2.m1.1.1.cmml" xref="A1.T2.8.8.8.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.8.8.8.2.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T2.8.8.8.2.m1.1d">±</annotation></semantics></math> 0.03</td>
</tr>
<tr class="ltx_tr" id="A1.T2.10.10.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A1.T2.10.10.10.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">BLEU-1</th>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T2.9.9.9.1" style="background-color:#CCFFCC;padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="A1.T2.9.9.9.1.1" style="background-color:#CCFFCC;">0.26 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T2.9.9.9.1.1.m1.1"><semantics id="A1.T2.9.9.9.1.1.m1.1a"><mo id="A1.T2.9.9.9.1.1.m1.1.1" mathbackground="#CCFFCC" xref="A1.T2.9.9.9.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T2.9.9.9.1.1.m1.1b"><csymbol cd="latexml" id="A1.T2.9.9.9.1.1.m1.1.1.cmml" xref="A1.T2.9.9.9.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.9.9.9.1.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T2.9.9.9.1.1.m1.1d">±</annotation></semantics></math> 0.09</span></td>
<td class="ltx_td ltx_align_center" id="A1.T2.10.10.10.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.11 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T2.10.10.10.2.m1.1"><semantics id="A1.T2.10.10.10.2.m1.1a"><mo id="A1.T2.10.10.10.2.m1.1.1" xref="A1.T2.10.10.10.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T2.10.10.10.2.m1.1b"><csymbol cd="latexml" id="A1.T2.10.10.10.2.m1.1.1.cmml" xref="A1.T2.10.10.10.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.10.10.10.2.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T2.10.10.10.2.m1.1d">±</annotation></semantics></math> 0.04</td>
</tr>
<tr class="ltx_tr" id="A1.T2.12.12.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T2.12.12.12.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">METEOR</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T2.11.11.11.1" style="background-color:#CCFFCC;padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="A1.T2.11.11.11.1.1" style="background-color:#CCFFCC;">0.35 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T2.11.11.11.1.1.m1.1"><semantics id="A1.T2.11.11.11.1.1.m1.1a"><mo id="A1.T2.11.11.11.1.1.m1.1.1" mathbackground="#CCFFCC" xref="A1.T2.11.11.11.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T2.11.11.11.1.1.m1.1b"><csymbol cd="latexml" id="A1.T2.11.11.11.1.1.m1.1.1.cmml" xref="A1.T2.11.11.11.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.11.11.11.1.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T2.11.11.11.1.1.m1.1d">±</annotation></semantics></math> 0.10</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T2.12.12.12.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.28 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T2.12.12.12.2.m1.1"><semantics id="A1.T2.12.12.12.2.m1.1a"><mo id="A1.T2.12.12.12.2.m1.1.1" xref="A1.T2.12.12.12.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T2.12.12.12.2.m1.1b"><csymbol cd="latexml" id="A1.T2.12.12.12.2.m1.1.1.cmml" xref="A1.T2.12.12.12.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.12.12.12.2.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T2.12.12.12.2.m1.1d">±</annotation></semantics></math> 0.06</td>
</tr>
<tr class="ltx_tr" id="A1.T2.14.14.14">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T2.14.14.14.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">Rouge1.f1</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T2.13.13.13.1" style="background-color:#CCFFCC;padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="A1.T2.13.13.13.1.1" style="background-color:#CCFFCC;">0.43 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T2.13.13.13.1.1.m1.1"><semantics id="A1.T2.13.13.13.1.1.m1.1a"><mo id="A1.T2.13.13.13.1.1.m1.1.1" mathbackground="#CCFFCC" xref="A1.T2.13.13.13.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T2.13.13.13.1.1.m1.1b"><csymbol cd="latexml" id="A1.T2.13.13.13.1.1.m1.1.1.cmml" xref="A1.T2.13.13.13.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.13.13.13.1.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T2.13.13.13.1.1.m1.1d">±</annotation></semantics></math> 0.10</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T2.14.14.14.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.22 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T2.14.14.14.2.m1.1"><semantics id="A1.T2.14.14.14.2.m1.1a"><mo id="A1.T2.14.14.14.2.m1.1.1" xref="A1.T2.14.14.14.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T2.14.14.14.2.m1.1b"><csymbol cd="latexml" id="A1.T2.14.14.14.2.m1.1.1.cmml" xref="A1.T2.14.14.14.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.14.14.14.2.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T2.14.14.14.2.m1.1d">±</annotation></semantics></math> 0.06</td>
</tr>
<tr class="ltx_tr" id="A1.T2.16.16.16">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A1.T2.16.16.16.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">Rouge2.f1</th>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T2.15.15.15.1" style="background-color:#CCFFCC;padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="A1.T2.15.15.15.1.1" style="background-color:#CCFFCC;">0.21 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T2.15.15.15.1.1.m1.1"><semantics id="A1.T2.15.15.15.1.1.m1.1a"><mo id="A1.T2.15.15.15.1.1.m1.1.1" mathbackground="#CCFFCC" xref="A1.T2.15.15.15.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T2.15.15.15.1.1.m1.1b"><csymbol cd="latexml" id="A1.T2.15.15.15.1.1.m1.1.1.cmml" xref="A1.T2.15.15.15.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.15.15.15.1.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T2.15.15.15.1.1.m1.1d">±</annotation></semantics></math> 0.09</span></td>
<td class="ltx_td ltx_align_center" id="A1.T2.16.16.16.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.09 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T2.16.16.16.2.m1.1"><semantics id="A1.T2.16.16.16.2.m1.1a"><mo id="A1.T2.16.16.16.2.m1.1.1" xref="A1.T2.16.16.16.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T2.16.16.16.2.m1.1b"><csymbol cd="latexml" id="A1.T2.16.16.16.2.m1.1.1.cmml" xref="A1.T2.16.16.16.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.16.16.16.2.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T2.16.16.16.2.m1.1d">±</annotation></semantics></math> 0.04</td>
</tr>
<tr class="ltx_tr" id="A1.T2.18.18.18">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A1.T2.18.18.18.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">RougeL.f1</th>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T2.17.17.17.1" style="background-color:#CCFFCC;padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="A1.T2.17.17.17.1.1" style="background-color:#CCFFCC;">0.29 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T2.17.17.17.1.1.m1.1"><semantics id="A1.T2.17.17.17.1.1.m1.1a"><mo id="A1.T2.17.17.17.1.1.m1.1.1" mathbackground="#CCFFCC" xref="A1.T2.17.17.17.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T2.17.17.17.1.1.m1.1b"><csymbol cd="latexml" id="A1.T2.17.17.17.1.1.m1.1.1.cmml" xref="A1.T2.17.17.17.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.17.17.17.1.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T2.17.17.17.1.1.m1.1d">±</annotation></semantics></math> 0.09</span></td>
<td class="ltx_td ltx_align_center" id="A1.T2.18.18.18.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.15 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T2.18.18.18.2.m1.1"><semantics id="A1.T2.18.18.18.2.m1.1a"><mo id="A1.T2.18.18.18.2.m1.1.1" xref="A1.T2.18.18.18.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T2.18.18.18.2.m1.1b"><csymbol cd="latexml" id="A1.T2.18.18.18.2.m1.1.1.cmml" xref="A1.T2.18.18.18.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.18.18.18.2.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T2.18.18.18.2.m1.1d">±</annotation></semantics></math> 0.04</td>
</tr>
<tr class="ltx_tr" id="A1.T2.20.20.20">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T2.20.20.20.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">BertScore.f1</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T2.19.19.19.1" style="background-color:#CCFFCC;padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="A1.T2.19.19.19.1.1" style="background-color:#CCFFCC;">0.27 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T2.19.19.19.1.1.m1.1"><semantics id="A1.T2.19.19.19.1.1.m1.1a"><mo id="A1.T2.19.19.19.1.1.m1.1.1" mathbackground="#CCFFCC" xref="A1.T2.19.19.19.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T2.19.19.19.1.1.m1.1b"><csymbol cd="latexml" id="A1.T2.19.19.19.1.1.m1.1.1.cmml" xref="A1.T2.19.19.19.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.19.19.19.1.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T2.19.19.19.1.1.m1.1d">±</annotation></semantics></math> 0.12</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T2.20.20.20.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.04 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T2.20.20.20.2.m1.1"><semantics id="A1.T2.20.20.20.2.m1.1a"><mo id="A1.T2.20.20.20.2.m1.1.1" xref="A1.T2.20.20.20.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T2.20.20.20.2.m1.1b"><csymbol cd="latexml" id="A1.T2.20.20.20.2.m1.1.1.cmml" xref="A1.T2.20.20.20.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.20.20.20.2.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T2.20.20.20.2.m1.1d">±</annotation></semantics></math> 0.10</td>
</tr>
<tr class="ltx_tr" id="A1.T2.22.22.22">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T2.22.22.22.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">TokenCounter</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T2.21.21.21.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">197.89 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T2.21.21.21.1.m1.1"><semantics id="A1.T2.21.21.21.1.m1.1a"><mo id="A1.T2.21.21.21.1.m1.1.1" xref="A1.T2.21.21.21.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T2.21.21.21.1.m1.1b"><csymbol cd="latexml" id="A1.T2.21.21.21.1.m1.1.1.cmml" xref="A1.T2.21.21.21.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.21.21.21.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T2.21.21.21.1.m1.1d">±</annotation></semantics></math> 88.52</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T2.22.22.22.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">420.01 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T2.22.22.22.2.m1.1"><semantics id="A1.T2.22.22.22.2.m1.1a"><mo id="A1.T2.22.22.22.2.m1.1.1" xref="A1.T2.22.22.22.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T2.22.22.22.2.m1.1b"><csymbol cd="latexml" id="A1.T2.22.22.22.2.m1.1.1.cmml" xref="A1.T2.22.22.22.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.22.22.22.2.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T2.22.22.22.2.m1.1d">±</annotation></semantics></math> 99.85</td>
</tr>
<tr class="ltx_tr" id="A1.T2.24.24.24">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T2.24.24.24.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">GPTRater.helpfulness</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T2.23.23.23.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">84.98 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T2.23.23.23.1.m1.1"><semantics id="A1.T2.23.23.23.1.m1.1a"><mo id="A1.T2.23.23.23.1.m1.1.1" xref="A1.T2.23.23.23.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T2.23.23.23.1.m1.1b"><csymbol cd="latexml" id="A1.T2.23.23.23.1.m1.1.1.cmml" xref="A1.T2.23.23.23.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.23.23.23.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T2.23.23.23.1.m1.1d">±</annotation></semantics></math> 14.72</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T2.24.24.24.2" style="background-color:#CCFFCC;padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="A1.T2.24.24.24.2.1" style="background-color:#CCFFCC;">94.21 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T2.24.24.24.2.1.m1.1"><semantics id="A1.T2.24.24.24.2.1.m1.1a"><mo id="A1.T2.24.24.24.2.1.m1.1.1" mathbackground="#CCFFCC" xref="A1.T2.24.24.24.2.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T2.24.24.24.2.1.m1.1b"><csymbol cd="latexml" id="A1.T2.24.24.24.2.1.m1.1.1.cmml" xref="A1.T2.24.24.24.2.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.24.24.24.2.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T2.24.24.24.2.1.m1.1d">±</annotation></semantics></math> 4.58</span></td>
</tr>
<tr class="ltx_tr" id="A1.T2.26.26.26">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="A1.T2.26.26.26.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">GPTRater.trust</th>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="A1.T2.25.25.25.1" style="background-color:#CCFFCC;padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="A1.T2.25.25.25.1.1" style="background-color:#CCFFCC;">85.54 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T2.25.25.25.1.1.m1.1"><semantics id="A1.T2.25.25.25.1.1.m1.1a"><mo id="A1.T2.25.25.25.1.1.m1.1.1" mathbackground="#CCFFCC" xref="A1.T2.25.25.25.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T2.25.25.25.1.1.m1.1b"><csymbol cd="latexml" id="A1.T2.25.25.25.1.1.m1.1.1.cmml" xref="A1.T2.25.25.25.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.25.25.25.1.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T2.25.25.25.1.1.m1.1d">±</annotation></semantics></math> 11.39</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T2.26.26.26.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">83.88 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T2.26.26.26.2.m1.1"><semantics id="A1.T2.26.26.26.2.m1.1a"><mo id="A1.T2.26.26.26.2.m1.1.1" xref="A1.T2.26.26.26.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T2.26.26.26.2.m1.1b"><csymbol cd="latexml" id="A1.T2.26.26.26.2.m1.1.1.cmml" xref="A1.T2.26.26.26.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.26.26.26.2.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T2.26.26.26.2.m1.1d">±</annotation></semantics></math> 8.10</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<figure class="ltx_table" id="A1.T3">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3: </span>Detailed overview of metrics for the different LLaMA-2 (13B parameters) configurations. Shown is the comparison: First, between the base model and fine-tuned versions. Further-more, for all models we compare directly asking the model the question or enriching the input using RAG and a system message. In case of the fine-tuned versions, we further filtered the output.
</figcaption>
<div class="ltx_inline-block ltx_transformed_outer" id="A1.T3.78" style="width:512.1pt;height:244.6pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-49.4pt,23.5pt) scale(0.838215673044443,0.838215673044443) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A1.T3.78.78">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A1.T3.78.78.79.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt" id="A1.T3.78.78.79.1.1" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="A1.T3.78.78.79.1.1.1">Model Type</span></th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="4" id="A1.T3.78.78.79.1.2" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="A1.T3.78.78.79.1.2.1">Fine-Tuned</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="A1.T3.78.78.79.1.3" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="A1.T3.78.78.79.1.3.1">Base Model</span></td>
</tr>
<tr class="ltx_tr" id="A1.T3.78.78.80.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A1.T3.78.78.80.2.1" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="A1.T3.78.78.80.2.1.1">LLM Output</span></th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2" id="A1.T3.78.78.80.2.2" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="A1.T3.78.78.80.2.2.1">Filtered*</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2" id="A1.T3.78.78.80.2.3" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="A1.T3.78.78.80.2.3.1">Raw</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="2" id="A1.T3.78.78.80.2.4" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="A1.T3.78.78.80.2.4.1">Raw</span></td>
</tr>
<tr class="ltx_tr" id="A1.T3.78.78.81.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A1.T3.78.78.81.3.1" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="A1.T3.78.78.81.3.1.1">Prompting Type</span></th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.78.78.81.3.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_parbox ltx_align_middle" id="A1.T3.78.78.81.3.2.1" style="width:71.1pt;">
<span class="ltx_p" id="A1.T3.78.78.81.3.2.1.1">RAG +</span>
<span class="ltx_p ltx_align_center" id="A1.T3.78.78.81.3.2.1.2">System Message</span>
</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.78.78.81.3.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_parbox ltx_align_middle" id="A1.T3.78.78.81.3.3.1" style="width:71.1pt;">
<span class="ltx_p" id="A1.T3.78.78.81.3.3.1.1">Question</span>
<span class="ltx_p ltx_align_center" id="A1.T3.78.78.81.3.3.1.2">Only</span>
</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.78.78.81.3.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_parbox ltx_align_middle" id="A1.T3.78.78.81.3.4.1" style="width:71.1pt;">
<span class="ltx_p" id="A1.T3.78.78.81.3.4.1.1">RAG +</span>
<span class="ltx_p ltx_align_center" id="A1.T3.78.78.81.3.4.1.2">System Message</span>
</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.78.78.81.3.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_parbox ltx_align_middle" id="A1.T3.78.78.81.3.5.1" style="width:71.1pt;">
<span class="ltx_p" id="A1.T3.78.78.81.3.5.1.1">Question</span>
<span class="ltx_p ltx_align_center" id="A1.T3.78.78.81.3.5.1.2">Only</span>
</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.78.78.81.3.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_parbox ltx_align_middle" id="A1.T3.78.78.81.3.6.1" style="width:71.1pt;">
<span class="ltx_p" id="A1.T3.78.78.81.3.6.1.1">RAG +</span>
<span class="ltx_p ltx_align_center" id="A1.T3.78.78.81.3.6.1.2">System Message</span>
</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.78.78.81.3.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_parbox ltx_align_middle" id="A1.T3.78.78.81.3.7.1" style="width:71.1pt;">
<span class="ltx_p" id="A1.T3.78.78.81.3.7.1.1">Question</span>
<span class="ltx_p ltx_align_center" id="A1.T3.78.78.81.3.7.1.2">Only</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T3.6.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T3.6.6.6.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">GPTSimilarity</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.1.1.1.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">72.79 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.1.1.1.1.m1.1"><semantics id="A1.T3.1.1.1.1.m1.1a"><mo id="A1.T3.1.1.1.1.m1.1.1" xref="A1.T3.1.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.1.1.1.1.m1.1b"><csymbol cd="latexml" id="A1.T3.1.1.1.1.m1.1.1.cmml" xref="A1.T3.1.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.1.1.1.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.1.1.1.1.m1.1d">±</annotation></semantics></math> 27.96</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.2.2.2.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">59.10 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.2.2.2.2.m1.1"><semantics id="A1.T3.2.2.2.2.m1.1a"><mo id="A1.T3.2.2.2.2.m1.1.1" xref="A1.T3.2.2.2.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.2.2.2.2.m1.1b"><csymbol cd="latexml" id="A1.T3.2.2.2.2.m1.1.1.cmml" xref="A1.T3.2.2.2.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.2.2.2.2.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.2.2.2.2.m1.1d">±</annotation></semantics></math> 29.56</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.3.3.3.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">72.85 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.3.3.3.3.m1.1"><semantics id="A1.T3.3.3.3.3.m1.1a"><mo id="A1.T3.3.3.3.3.m1.1.1" xref="A1.T3.3.3.3.3.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.3.3.3.3.m1.1b"><csymbol cd="latexml" id="A1.T3.3.3.3.3.m1.1.1.cmml" xref="A1.T3.3.3.3.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.3.3.3.3.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.3.3.3.3.m1.1d">±</annotation></semantics></math> 28.12</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.4.4.4.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">55.00 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.4.4.4.4.m1.1"><semantics id="A1.T3.4.4.4.4.m1.1a"><mo id="A1.T3.4.4.4.4.m1.1.1" xref="A1.T3.4.4.4.4.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.4.4.4.4.m1.1b"><csymbol cd="latexml" id="A1.T3.4.4.4.4.m1.1.1.cmml" xref="A1.T3.4.4.4.4.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.4.4.4.4.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.4.4.4.4.m1.1d">±</annotation></semantics></math> 28.42</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.5.5.5.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">76.07 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.5.5.5.5.m1.1"><semantics id="A1.T3.5.5.5.5.m1.1a"><mo id="A1.T3.5.5.5.5.m1.1.1" xref="A1.T3.5.5.5.5.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.5.5.5.5.m1.1b"><csymbol cd="latexml" id="A1.T3.5.5.5.5.m1.1.1.cmml" xref="A1.T3.5.5.5.5.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.5.5.5.5.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.5.5.5.5.m1.1d">±</annotation></semantics></math> 24.03</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.6.6.6.6" style="background-color:#CCFFCC;padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="A1.T3.6.6.6.6.1" style="background-color:#CCFFCC;">78.02 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.6.6.6.6.1.m1.1"><semantics id="A1.T3.6.6.6.6.1.m1.1a"><mo id="A1.T3.6.6.6.6.1.m1.1.1" mathbackground="#CCFFCC" xref="A1.T3.6.6.6.6.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.6.6.6.6.1.m1.1b"><csymbol cd="latexml" id="A1.T3.6.6.6.6.1.m1.1.1.cmml" xref="A1.T3.6.6.6.6.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.6.6.6.6.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.6.6.6.6.1.m1.1d">±</annotation></semantics></math> 22.00</span></td>
</tr>
<tr class="ltx_tr" id="A1.T3.12.12.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T3.12.12.12.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">BLEU-4</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.7.7.7.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.09 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.7.7.7.1.m1.1"><semantics id="A1.T3.7.7.7.1.m1.1a"><mo id="A1.T3.7.7.7.1.m1.1.1" xref="A1.T3.7.7.7.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.7.7.7.1.m1.1b"><csymbol cd="latexml" id="A1.T3.7.7.7.1.m1.1.1.cmml" xref="A1.T3.7.7.7.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.7.7.7.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.7.7.7.1.m1.1d">±</annotation></semantics></math> 0.07</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.8.8.8.2" style="background-color:#CCFFCC;padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="A1.T3.8.8.8.2.1" style="background-color:#CCFFCC;">0.10 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.8.8.8.2.1.m1.1"><semantics id="A1.T3.8.8.8.2.1.m1.1a"><mo id="A1.T3.8.8.8.2.1.m1.1.1" mathbackground="#CCFFCC" xref="A1.T3.8.8.8.2.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.8.8.8.2.1.m1.1b"><csymbol cd="latexml" id="A1.T3.8.8.8.2.1.m1.1.1.cmml" xref="A1.T3.8.8.8.2.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.8.8.8.2.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.8.8.8.2.1.m1.1d">±</annotation></semantics></math> 0.08</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.9.9.9.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.08 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.9.9.9.3.m1.1"><semantics id="A1.T3.9.9.9.3.m1.1a"><mo id="A1.T3.9.9.9.3.m1.1.1" xref="A1.T3.9.9.9.3.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.9.9.9.3.m1.1b"><csymbol cd="latexml" id="A1.T3.9.9.9.3.m1.1.1.cmml" xref="A1.T3.9.9.9.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.9.9.9.3.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.9.9.9.3.m1.1d">±</annotation></semantics></math> 0.07</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.10.10.10.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.05 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.10.10.10.4.m1.1"><semantics id="A1.T3.10.10.10.4.m1.1a"><mo id="A1.T3.10.10.10.4.m1.1.1" xref="A1.T3.10.10.10.4.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.10.10.10.4.m1.1b"><csymbol cd="latexml" id="A1.T3.10.10.10.4.m1.1.1.cmml" xref="A1.T3.10.10.10.4.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.10.10.10.4.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.10.10.10.4.m1.1d">±</annotation></semantics></math> 0.04</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.11.11.11.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.07 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.11.11.11.5.m1.1"><semantics id="A1.T3.11.11.11.5.m1.1a"><mo id="A1.T3.11.11.11.5.m1.1.1" xref="A1.T3.11.11.11.5.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.11.11.11.5.m1.1b"><csymbol cd="latexml" id="A1.T3.11.11.11.5.m1.1.1.cmml" xref="A1.T3.11.11.11.5.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.11.11.11.5.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.11.11.11.5.m1.1d">±</annotation></semantics></math> 0.06</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.12.12.12.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.03 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.12.12.12.6.m1.1"><semantics id="A1.T3.12.12.12.6.m1.1a"><mo id="A1.T3.12.12.12.6.m1.1.1" xref="A1.T3.12.12.12.6.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.12.12.12.6.m1.1b"><csymbol cd="latexml" id="A1.T3.12.12.12.6.m1.1.1.cmml" xref="A1.T3.12.12.12.6.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.12.12.12.6.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.12.12.12.6.m1.1d">±</annotation></semantics></math> 0.02</td>
</tr>
<tr class="ltx_tr" id="A1.T3.18.18.18">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A1.T3.18.18.18.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">BLEU-3</th>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T3.13.13.13.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.11 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.13.13.13.1.m1.1"><semantics id="A1.T3.13.13.13.1.m1.1a"><mo id="A1.T3.13.13.13.1.m1.1.1" xref="A1.T3.13.13.13.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.13.13.13.1.m1.1b"><csymbol cd="latexml" id="A1.T3.13.13.13.1.m1.1.1.cmml" xref="A1.T3.13.13.13.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.13.13.13.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.13.13.13.1.m1.1d">±</annotation></semantics></math> 0.07</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T3.14.14.14.2" style="background-color:#CCFFCC;padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="A1.T3.14.14.14.2.1" style="background-color:#CCFFCC;">0.12 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.14.14.14.2.1.m1.1"><semantics id="A1.T3.14.14.14.2.1.m1.1a"><mo id="A1.T3.14.14.14.2.1.m1.1.1" mathbackground="#CCFFCC" xref="A1.T3.14.14.14.2.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.14.14.14.2.1.m1.1b"><csymbol cd="latexml" id="A1.T3.14.14.14.2.1.m1.1.1.cmml" xref="A1.T3.14.14.14.2.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.14.14.14.2.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.14.14.14.2.1.m1.1d">±</annotation></semantics></math> 0.08</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T3.15.15.15.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.10 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.15.15.15.3.m1.1"><semantics id="A1.T3.15.15.15.3.m1.1a"><mo id="A1.T3.15.15.15.3.m1.1.1" xref="A1.T3.15.15.15.3.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.15.15.15.3.m1.1b"><csymbol cd="latexml" id="A1.T3.15.15.15.3.m1.1.1.cmml" xref="A1.T3.15.15.15.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.15.15.15.3.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.15.15.15.3.m1.1d">±</annotation></semantics></math> 0.07</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T3.16.16.16.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.06 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.16.16.16.4.m1.1"><semantics id="A1.T3.16.16.16.4.m1.1a"><mo id="A1.T3.16.16.16.4.m1.1.1" xref="A1.T3.16.16.16.4.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.16.16.16.4.m1.1b"><csymbol cd="latexml" id="A1.T3.16.16.16.4.m1.1.1.cmml" xref="A1.T3.16.16.16.4.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.16.16.16.4.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.16.16.16.4.m1.1d">±</annotation></semantics></math> 0.05</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T3.17.17.17.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.09 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.17.17.17.5.m1.1"><semantics id="A1.T3.17.17.17.5.m1.1a"><mo id="A1.T3.17.17.17.5.m1.1.1" xref="A1.T3.17.17.17.5.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.17.17.17.5.m1.1b"><csymbol cd="latexml" id="A1.T3.17.17.17.5.m1.1.1.cmml" xref="A1.T3.17.17.17.5.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.17.17.17.5.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.17.17.17.5.m1.1d">±</annotation></semantics></math> 0.06</td>
<td class="ltx_td ltx_align_center" id="A1.T3.18.18.18.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.04 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.18.18.18.6.m1.1"><semantics id="A1.T3.18.18.18.6.m1.1a"><mo id="A1.T3.18.18.18.6.m1.1.1" xref="A1.T3.18.18.18.6.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.18.18.18.6.m1.1b"><csymbol cd="latexml" id="A1.T3.18.18.18.6.m1.1.1.cmml" xref="A1.T3.18.18.18.6.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.18.18.18.6.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.18.18.18.6.m1.1d">±</annotation></semantics></math> 0.02</td>
</tr>
<tr class="ltx_tr" id="A1.T3.24.24.24">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A1.T3.24.24.24.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">BLEU-2</th>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T3.19.19.19.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.15 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.19.19.19.1.m1.1"><semantics id="A1.T3.19.19.19.1.m1.1a"><mo id="A1.T3.19.19.19.1.m1.1.1" xref="A1.T3.19.19.19.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.19.19.19.1.m1.1b"><csymbol cd="latexml" id="A1.T3.19.19.19.1.m1.1.1.cmml" xref="A1.T3.19.19.19.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.19.19.19.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.19.19.19.1.m1.1d">±</annotation></semantics></math> 0.08</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T3.20.20.20.2" style="background-color:#CCFFCC;padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="A1.T3.20.20.20.2.1" style="background-color:#CCFFCC;">0.17 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.20.20.20.2.1.m1.1"><semantics id="A1.T3.20.20.20.2.1.m1.1a"><mo id="A1.T3.20.20.20.2.1.m1.1.1" mathbackground="#CCFFCC" xref="A1.T3.20.20.20.2.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.20.20.20.2.1.m1.1b"><csymbol cd="latexml" id="A1.T3.20.20.20.2.1.m1.1.1.cmml" xref="A1.T3.20.20.20.2.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.20.20.20.2.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.20.20.20.2.1.m1.1d">±</annotation></semantics></math> 0.09</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T3.21.21.21.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.13 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.21.21.21.3.m1.1"><semantics id="A1.T3.21.21.21.3.m1.1a"><mo id="A1.T3.21.21.21.3.m1.1.1" xref="A1.T3.21.21.21.3.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.21.21.21.3.m1.1b"><csymbol cd="latexml" id="A1.T3.21.21.21.3.m1.1.1.cmml" xref="A1.T3.21.21.21.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.21.21.21.3.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.21.21.21.3.m1.1d">±</annotation></semantics></math> 0.08</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T3.22.22.22.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.09 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.22.22.22.4.m1.1"><semantics id="A1.T3.22.22.22.4.m1.1a"><mo id="A1.T3.22.22.22.4.m1.1.1" xref="A1.T3.22.22.22.4.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.22.22.22.4.m1.1b"><csymbol cd="latexml" id="A1.T3.22.22.22.4.m1.1.1.cmml" xref="A1.T3.22.22.22.4.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.22.22.22.4.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.22.22.22.4.m1.1d">±</annotation></semantics></math> 0.06</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T3.23.23.23.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.12 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.23.23.23.5.m1.1"><semantics id="A1.T3.23.23.23.5.m1.1a"><mo id="A1.T3.23.23.23.5.m1.1.1" xref="A1.T3.23.23.23.5.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.23.23.23.5.m1.1b"><csymbol cd="latexml" id="A1.T3.23.23.23.5.m1.1.1.cmml" xref="A1.T3.23.23.23.5.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.23.23.23.5.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.23.23.23.5.m1.1d">±</annotation></semantics></math> 0.07</td>
<td class="ltx_td ltx_align_center" id="A1.T3.24.24.24.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.05 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.24.24.24.6.m1.1"><semantics id="A1.T3.24.24.24.6.m1.1a"><mo id="A1.T3.24.24.24.6.m1.1.1" xref="A1.T3.24.24.24.6.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.24.24.24.6.m1.1b"><csymbol cd="latexml" id="A1.T3.24.24.24.6.m1.1.1.cmml" xref="A1.T3.24.24.24.6.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.24.24.24.6.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.24.24.24.6.m1.1d">±</annotation></semantics></math> 0.02</td>
</tr>
<tr class="ltx_tr" id="A1.T3.30.30.30">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A1.T3.30.30.30.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">BLEU-1</th>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T3.25.25.25.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.22 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.25.25.25.1.m1.1"><semantics id="A1.T3.25.25.25.1.m1.1a"><mo id="A1.T3.25.25.25.1.m1.1.1" xref="A1.T3.25.25.25.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.25.25.25.1.m1.1b"><csymbol cd="latexml" id="A1.T3.25.25.25.1.m1.1.1.cmml" xref="A1.T3.25.25.25.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.25.25.25.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.25.25.25.1.m1.1d">±</annotation></semantics></math> 0.10</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T3.26.26.26.2" style="background-color:#CCFFCC;padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="A1.T3.26.26.26.2.1" style="background-color:#CCFFCC;">0.27 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.26.26.26.2.1.m1.1"><semantics id="A1.T3.26.26.26.2.1.m1.1a"><mo id="A1.T3.26.26.26.2.1.m1.1.1" mathbackground="#CCFFCC" xref="A1.T3.26.26.26.2.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.26.26.26.2.1.m1.1b"><csymbol cd="latexml" id="A1.T3.26.26.26.2.1.m1.1.1.cmml" xref="A1.T3.26.26.26.2.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.26.26.26.2.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.26.26.26.2.1.m1.1d">±</annotation></semantics></math> 0.10</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T3.27.27.27.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.20 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.27.27.27.3.m1.1"><semantics id="A1.T3.27.27.27.3.m1.1a"><mo id="A1.T3.27.27.27.3.m1.1.1" xref="A1.T3.27.27.27.3.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.27.27.27.3.m1.1b"><csymbol cd="latexml" id="A1.T3.27.27.27.3.m1.1.1.cmml" xref="A1.T3.27.27.27.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.27.27.27.3.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.27.27.27.3.m1.1d">±</annotation></semantics></math> 0.11</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T3.28.28.28.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.14 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.28.28.28.4.m1.1"><semantics id="A1.T3.28.28.28.4.m1.1a"><mo id="A1.T3.28.28.28.4.m1.1.1" xref="A1.T3.28.28.28.4.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.28.28.28.4.m1.1b"><csymbol cd="latexml" id="A1.T3.28.28.28.4.m1.1.1.cmml" xref="A1.T3.28.28.28.4.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.28.28.28.4.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.28.28.28.4.m1.1d">±</annotation></semantics></math> 0.08</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T3.29.29.29.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.18 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.29.29.29.5.m1.1"><semantics id="A1.T3.29.29.29.5.m1.1a"><mo id="A1.T3.29.29.29.5.m1.1.1" xref="A1.T3.29.29.29.5.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.29.29.29.5.m1.1b"><csymbol cd="latexml" id="A1.T3.29.29.29.5.m1.1.1.cmml" xref="A1.T3.29.29.29.5.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.29.29.29.5.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.29.29.29.5.m1.1d">±</annotation></semantics></math> 0.09</td>
<td class="ltx_td ltx_align_center" id="A1.T3.30.30.30.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.09 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.30.30.30.6.m1.1"><semantics id="A1.T3.30.30.30.6.m1.1a"><mo id="A1.T3.30.30.30.6.m1.1.1" xref="A1.T3.30.30.30.6.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.30.30.30.6.m1.1b"><csymbol cd="latexml" id="A1.T3.30.30.30.6.m1.1.1.cmml" xref="A1.T3.30.30.30.6.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.30.30.30.6.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.30.30.30.6.m1.1d">±</annotation></semantics></math> 0.03</td>
</tr>
<tr class="ltx_tr" id="A1.T3.36.36.36">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T3.36.36.36.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">METEOR</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.31.31.31.1" style="background-color:#CCFFCC;padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="A1.T3.31.31.31.1.1" style="background-color:#CCFFCC;">0.30 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.31.31.31.1.1.m1.1"><semantics id="A1.T3.31.31.31.1.1.m1.1a"><mo id="A1.T3.31.31.31.1.1.m1.1.1" mathbackground="#CCFFCC" xref="A1.T3.31.31.31.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.31.31.31.1.1.m1.1b"><csymbol cd="latexml" id="A1.T3.31.31.31.1.1.m1.1.1.cmml" xref="A1.T3.31.31.31.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.31.31.31.1.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.31.31.31.1.1.m1.1d">±</annotation></semantics></math> 0.11</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.32.32.32.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.29 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.32.32.32.2.m1.1"><semantics id="A1.T3.32.32.32.2.m1.1a"><mo id="A1.T3.32.32.32.2.m1.1.1" xref="A1.T3.32.32.32.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.32.32.32.2.m1.1b"><csymbol cd="latexml" id="A1.T3.32.32.32.2.m1.1.1.cmml" xref="A1.T3.32.32.32.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.32.32.32.2.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.32.32.32.2.m1.1d">±</annotation></semantics></math> 0.10</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.33.33.33.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.30 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.33.33.33.3.m1.1"><semantics id="A1.T3.33.33.33.3.m1.1a"><mo id="A1.T3.33.33.33.3.m1.1.1" xref="A1.T3.33.33.33.3.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.33.33.33.3.m1.1b"><csymbol cd="latexml" id="A1.T3.33.33.33.3.m1.1.1.cmml" xref="A1.T3.33.33.33.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.33.33.33.3.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.33.33.33.3.m1.1d">±</annotation></semantics></math> 0.10</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.34.34.34.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.29 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.34.34.34.4.m1.1"><semantics id="A1.T3.34.34.34.4.m1.1a"><mo id="A1.T3.34.34.34.4.m1.1.1" xref="A1.T3.34.34.34.4.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.34.34.34.4.m1.1b"><csymbol cd="latexml" id="A1.T3.34.34.34.4.m1.1.1.cmml" xref="A1.T3.34.34.34.4.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.34.34.34.4.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.34.34.34.4.m1.1d">±</annotation></semantics></math> 0.07</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.35.35.35.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.29 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.35.35.35.5.m1.1"><semantics id="A1.T3.35.35.35.5.m1.1a"><mo id="A1.T3.35.35.35.5.m1.1.1" xref="A1.T3.35.35.35.5.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.35.35.35.5.m1.1b"><csymbol cd="latexml" id="A1.T3.35.35.35.5.m1.1.1.cmml" xref="A1.T3.35.35.35.5.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.35.35.35.5.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.35.35.35.5.m1.1d">±</annotation></semantics></math> 0.09</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.36.36.36.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.24 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.36.36.36.6.m1.1"><semantics id="A1.T3.36.36.36.6.m1.1a"><mo id="A1.T3.36.36.36.6.m1.1.1" xref="A1.T3.36.36.36.6.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.36.36.36.6.m1.1b"><csymbol cd="latexml" id="A1.T3.36.36.36.6.m1.1.1.cmml" xref="A1.T3.36.36.36.6.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.36.36.36.6.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.36.36.36.6.m1.1d">±</annotation></semantics></math> 0.05</td>
</tr>
<tr class="ltx_tr" id="A1.T3.42.42.42">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T3.42.42.42.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">Rouge1.f1</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.37.37.37.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.36 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.37.37.37.1.m1.1"><semantics id="A1.T3.37.37.37.1.m1.1a"><mo id="A1.T3.37.37.37.1.m1.1.1" xref="A1.T3.37.37.37.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.37.37.37.1.m1.1b"><csymbol cd="latexml" id="A1.T3.37.37.37.1.m1.1.1.cmml" xref="A1.T3.37.37.37.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.37.37.37.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.37.37.37.1.m1.1d">±</annotation></semantics></math> 0.12</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.38.38.38.2" style="background-color:#CCFFCC;padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="A1.T3.38.38.38.2.1" style="background-color:#CCFFCC;">0.39 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.38.38.38.2.1.m1.1"><semantics id="A1.T3.38.38.38.2.1.m1.1a"><mo id="A1.T3.38.38.38.2.1.m1.1.1" mathbackground="#CCFFCC" xref="A1.T3.38.38.38.2.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.38.38.38.2.1.m1.1b"><csymbol cd="latexml" id="A1.T3.38.38.38.2.1.m1.1.1.cmml" xref="A1.T3.38.38.38.2.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.38.38.38.2.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.38.38.38.2.1.m1.1d">±</annotation></semantics></math> 0.10</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.39.39.39.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.33 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.39.39.39.3.m1.1"><semantics id="A1.T3.39.39.39.3.m1.1a"><mo id="A1.T3.39.39.39.3.m1.1.1" xref="A1.T3.39.39.39.3.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.39.39.39.3.m1.1b"><csymbol cd="latexml" id="A1.T3.39.39.39.3.m1.1.1.cmml" xref="A1.T3.39.39.39.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.39.39.39.3.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.39.39.39.3.m1.1d">±</annotation></semantics></math> 0.12</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.40.40.40.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.24 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.40.40.40.4.m1.1"><semantics id="A1.T3.40.40.40.4.m1.1a"><mo id="A1.T3.40.40.40.4.m1.1.1" xref="A1.T3.40.40.40.4.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.40.40.40.4.m1.1b"><csymbol cd="latexml" id="A1.T3.40.40.40.4.m1.1.1.cmml" xref="A1.T3.40.40.40.4.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.40.40.40.4.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.40.40.40.4.m1.1d">±</annotation></semantics></math> 0.10</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.41.41.41.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.32 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.41.41.41.5.m1.1"><semantics id="A1.T3.41.41.41.5.m1.1a"><mo id="A1.T3.41.41.41.5.m1.1.1" xref="A1.T3.41.41.41.5.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.41.41.41.5.m1.1b"><csymbol cd="latexml" id="A1.T3.41.41.41.5.m1.1.1.cmml" xref="A1.T3.41.41.41.5.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.41.41.41.5.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.41.41.41.5.m1.1d">±</annotation></semantics></math> 0.11</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.42.42.42.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.17 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.42.42.42.6.m1.1"><semantics id="A1.T3.42.42.42.6.m1.1a"><mo id="A1.T3.42.42.42.6.m1.1.1" xref="A1.T3.42.42.42.6.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.42.42.42.6.m1.1b"><csymbol cd="latexml" id="A1.T3.42.42.42.6.m1.1.1.cmml" xref="A1.T3.42.42.42.6.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.42.42.42.6.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.42.42.42.6.m1.1d">±</annotation></semantics></math> 0.05</td>
</tr>
<tr class="ltx_tr" id="A1.T3.48.48.48">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A1.T3.48.48.48.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">Rouge2.f1</th>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T3.43.43.43.1" style="background-color:#CCFFCC;padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="A1.T3.43.43.43.1.1" style="background-color:#CCFFCC;">0.17 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.43.43.43.1.1.m1.1"><semantics id="A1.T3.43.43.43.1.1.m1.1a"><mo id="A1.T3.43.43.43.1.1.m1.1.1" mathbackground="#CCFFCC" xref="A1.T3.43.43.43.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.43.43.43.1.1.m1.1b"><csymbol cd="latexml" id="A1.T3.43.43.43.1.1.m1.1.1.cmml" xref="A1.T3.43.43.43.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.43.43.43.1.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.43.43.43.1.1.m1.1d">±</annotation></semantics></math> 0.09</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T3.44.44.44.2" style="background-color:#CCFFCC;padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="A1.T3.44.44.44.2.1" style="background-color:#CCFFCC;">0.17 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.44.44.44.2.1.m1.1"><semantics id="A1.T3.44.44.44.2.1.m1.1a"><mo id="A1.T3.44.44.44.2.1.m1.1.1" mathbackground="#CCFFCC" xref="A1.T3.44.44.44.2.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.44.44.44.2.1.m1.1b"><csymbol cd="latexml" id="A1.T3.44.44.44.2.1.m1.1.1.cmml" xref="A1.T3.44.44.44.2.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.44.44.44.2.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.44.44.44.2.1.m1.1d">±</annotation></semantics></math> 0.08</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T3.45.45.45.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.15 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.45.45.45.3.m1.1"><semantics id="A1.T3.45.45.45.3.m1.1a"><mo id="A1.T3.45.45.45.3.m1.1.1" xref="A1.T3.45.45.45.3.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.45.45.45.3.m1.1b"><csymbol cd="latexml" id="A1.T3.45.45.45.3.m1.1.1.cmml" xref="A1.T3.45.45.45.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.45.45.45.3.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.45.45.45.3.m1.1d">±</annotation></semantics></math> 0.09</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T3.46.46.46.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.10 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.46.46.46.4.m1.1"><semantics id="A1.T3.46.46.46.4.m1.1a"><mo id="A1.T3.46.46.46.4.m1.1.1" xref="A1.T3.46.46.46.4.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.46.46.46.4.m1.1b"><csymbol cd="latexml" id="A1.T3.46.46.46.4.m1.1.1.cmml" xref="A1.T3.46.46.46.4.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.46.46.46.4.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.46.46.46.4.m1.1d">±</annotation></semantics></math> 0.05</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T3.47.47.47.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.14 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.47.47.47.5.m1.1"><semantics id="A1.T3.47.47.47.5.m1.1a"><mo id="A1.T3.47.47.47.5.m1.1.1" xref="A1.T3.47.47.47.5.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.47.47.47.5.m1.1b"><csymbol cd="latexml" id="A1.T3.47.47.47.5.m1.1.1.cmml" xref="A1.T3.47.47.47.5.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.47.47.47.5.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.47.47.47.5.m1.1d">±</annotation></semantics></math> 0.08</td>
<td class="ltx_td ltx_align_center" id="A1.T3.48.48.48.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.07 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.48.48.48.6.m1.1"><semantics id="A1.T3.48.48.48.6.m1.1a"><mo id="A1.T3.48.48.48.6.m1.1.1" xref="A1.T3.48.48.48.6.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.48.48.48.6.m1.1b"><csymbol cd="latexml" id="A1.T3.48.48.48.6.m1.1.1.cmml" xref="A1.T3.48.48.48.6.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.48.48.48.6.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.48.48.48.6.m1.1d">±</annotation></semantics></math> 0.03</td>
</tr>
<tr class="ltx_tr" id="A1.T3.54.54.54">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A1.T3.54.54.54.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">RougeL.f1</th>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T3.49.49.49.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.24 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.49.49.49.1.m1.1"><semantics id="A1.T3.49.49.49.1.m1.1a"><mo id="A1.T3.49.49.49.1.m1.1.1" xref="A1.T3.49.49.49.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.49.49.49.1.m1.1b"><csymbol cd="latexml" id="A1.T3.49.49.49.1.m1.1.1.cmml" xref="A1.T3.49.49.49.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.49.49.49.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.49.49.49.1.m1.1d">±</annotation></semantics></math> 0.09</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T3.50.50.50.2" style="background-color:#CCFFCC;padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="A1.T3.50.50.50.2.1" style="background-color:#CCFFCC;">0.26 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.50.50.50.2.1.m1.1"><semantics id="A1.T3.50.50.50.2.1.m1.1a"><mo id="A1.T3.50.50.50.2.1.m1.1.1" mathbackground="#CCFFCC" xref="A1.T3.50.50.50.2.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.50.50.50.2.1.m1.1b"><csymbol cd="latexml" id="A1.T3.50.50.50.2.1.m1.1.1.cmml" xref="A1.T3.50.50.50.2.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.50.50.50.2.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.50.50.50.2.1.m1.1d">±</annotation></semantics></math> 0.09</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T3.51.51.51.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.23 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.51.51.51.3.m1.1"><semantics id="A1.T3.51.51.51.3.m1.1a"><mo id="A1.T3.51.51.51.3.m1.1.1" xref="A1.T3.51.51.51.3.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.51.51.51.3.m1.1b"><csymbol cd="latexml" id="A1.T3.51.51.51.3.m1.1.1.cmml" xref="A1.T3.51.51.51.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.51.51.51.3.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.51.51.51.3.m1.1d">±</annotation></semantics></math> 0.09</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T3.52.52.52.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.17 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.52.52.52.4.m1.1"><semantics id="A1.T3.52.52.52.4.m1.1a"><mo id="A1.T3.52.52.52.4.m1.1.1" xref="A1.T3.52.52.52.4.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.52.52.52.4.m1.1b"><csymbol cd="latexml" id="A1.T3.52.52.52.4.m1.1.1.cmml" xref="A1.T3.52.52.52.4.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.52.52.52.4.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.52.52.52.4.m1.1d">±</annotation></semantics></math> 0.07</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T3.53.53.53.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.22 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.53.53.53.5.m1.1"><semantics id="A1.T3.53.53.53.5.m1.1a"><mo id="A1.T3.53.53.53.5.m1.1.1" xref="A1.T3.53.53.53.5.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.53.53.53.5.m1.1b"><csymbol cd="latexml" id="A1.T3.53.53.53.5.m1.1.1.cmml" xref="A1.T3.53.53.53.5.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.53.53.53.5.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.53.53.53.5.m1.1d">±</annotation></semantics></math> 0.08</td>
<td class="ltx_td ltx_align_center" id="A1.T3.54.54.54.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.12 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.54.54.54.6.m1.1"><semantics id="A1.T3.54.54.54.6.m1.1a"><mo id="A1.T3.54.54.54.6.m1.1.1" xref="A1.T3.54.54.54.6.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.54.54.54.6.m1.1b"><csymbol cd="latexml" id="A1.T3.54.54.54.6.m1.1.1.cmml" xref="A1.T3.54.54.54.6.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.54.54.54.6.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.54.54.54.6.m1.1d">±</annotation></semantics></math> 0.03</td>
</tr>
<tr class="ltx_tr" id="A1.T3.60.60.60">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T3.60.60.60.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">BertScore.f1</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.55.55.55.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.09 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.55.55.55.1.m1.1"><semantics id="A1.T3.55.55.55.1.m1.1a"><mo id="A1.T3.55.55.55.1.m1.1.1" xref="A1.T3.55.55.55.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.55.55.55.1.m1.1b"><csymbol cd="latexml" id="A1.T3.55.55.55.1.m1.1.1.cmml" xref="A1.T3.55.55.55.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.55.55.55.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.55.55.55.1.m1.1d">±</annotation></semantics></math> 0.49</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.56.56.56.2" style="background-color:#CCFFCC;padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="A1.T3.56.56.56.2.1" style="background-color:#CCFFCC;">0.24 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.56.56.56.2.1.m1.1"><semantics id="A1.T3.56.56.56.2.1.m1.1a"><mo id="A1.T3.56.56.56.2.1.m1.1.1" mathbackground="#CCFFCC" xref="A1.T3.56.56.56.2.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.56.56.56.2.1.m1.1b"><csymbol cd="latexml" id="A1.T3.56.56.56.2.1.m1.1.1.cmml" xref="A1.T3.56.56.56.2.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.56.56.56.2.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.56.56.56.2.1.m1.1d">±</annotation></semantics></math> 0.27</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.57.57.57.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.07 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.57.57.57.3.m1.1"><semantics id="A1.T3.57.57.57.3.m1.1a"><mo id="A1.T3.57.57.57.3.m1.1.1" xref="A1.T3.57.57.57.3.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.57.57.57.3.m1.1b"><csymbol cd="latexml" id="A1.T3.57.57.57.3.m1.1.1.cmml" xref="A1.T3.57.57.57.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.57.57.57.3.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.57.57.57.3.m1.1d">±</annotation></semantics></math> 0.18</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.58.58.58.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.02 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.58.58.58.4.m1.1"><semantics id="A1.T3.58.58.58.4.m1.1a"><mo id="A1.T3.58.58.58.4.m1.1.1" xref="A1.T3.58.58.58.4.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.58.58.58.4.m1.1b"><csymbol cd="latexml" id="A1.T3.58.58.58.4.m1.1.1.cmml" xref="A1.T3.58.58.58.4.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.58.58.58.4.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.58.58.58.4.m1.1d">±</annotation></semantics></math> 0.14</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.59.59.59.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.08 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.59.59.59.5.m1.1"><semantics id="A1.T3.59.59.59.5.m1.1a"><mo id="A1.T3.59.59.59.5.m1.1.1" xref="A1.T3.59.59.59.5.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.59.59.59.5.m1.1b"><csymbol cd="latexml" id="A1.T3.59.59.59.5.m1.1.1.cmml" xref="A1.T3.59.59.59.5.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.59.59.59.5.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.59.59.59.5.m1.1d">±</annotation></semantics></math> 0.14</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.60.60.60.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">-0.02 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.60.60.60.6.m1.1"><semantics id="A1.T3.60.60.60.6.m1.1a"><mo id="A1.T3.60.60.60.6.m1.1.1" xref="A1.T3.60.60.60.6.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.60.60.60.6.m1.1b"><csymbol cd="latexml" id="A1.T3.60.60.60.6.m1.1.1.cmml" xref="A1.T3.60.60.60.6.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.60.60.60.6.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.60.60.60.6.m1.1d">±</annotation></semantics></math> 0.08</td>
</tr>
<tr class="ltx_tr" id="A1.T3.66.66.66">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T3.66.66.66.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">TokenCounter</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.61.61.61.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">173.16 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.61.61.61.1.m1.1"><semantics id="A1.T3.61.61.61.1.m1.1a"><mo id="A1.T3.61.61.61.1.m1.1.1" xref="A1.T3.61.61.61.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.61.61.61.1.m1.1b"><csymbol cd="latexml" id="A1.T3.61.61.61.1.m1.1.1.cmml" xref="A1.T3.61.61.61.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.61.61.61.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.61.61.61.1.m1.1d">±</annotation></semantics></math> 109.48</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.62.62.62.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">108.78 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.62.62.62.2.m1.1"><semantics id="A1.T3.62.62.62.2.m1.1a"><mo id="A1.T3.62.62.62.2.m1.1.1" xref="A1.T3.62.62.62.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.62.62.62.2.m1.1b"><csymbol cd="latexml" id="A1.T3.62.62.62.2.m1.1.1.cmml" xref="A1.T3.62.62.62.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.62.62.62.2.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.62.62.62.2.m1.1d">±</annotation></semantics></math> 81.13</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.63.63.63.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">245.83 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.63.63.63.3.m1.1"><semantics id="A1.T3.63.63.63.3.m1.1a"><mo id="A1.T3.63.63.63.3.m1.1.1" xref="A1.T3.63.63.63.3.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.63.63.63.3.m1.1b"><csymbol cd="latexml" id="A1.T3.63.63.63.3.m1.1.1.cmml" xref="A1.T3.63.63.63.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.63.63.63.3.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.63.63.63.3.m1.1d">±</annotation></semantics></math> 180.82</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.64.64.64.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">412.92 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.64.64.64.4.m1.1"><semantics id="A1.T3.64.64.64.4.m1.1a"><mo id="A1.T3.64.64.64.4.m1.1.1" xref="A1.T3.64.64.64.4.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.64.64.64.4.m1.1b"><csymbol cd="latexml" id="A1.T3.64.64.64.4.m1.1.1.cmml" xref="A1.T3.64.64.64.4.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.64.64.64.4.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.64.64.64.4.m1.1d">±</annotation></semantics></math> 153.10</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.65.65.65.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">252.67 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.65.65.65.5.m1.1"><semantics id="A1.T3.65.65.65.5.m1.1a"><mo id="A1.T3.65.65.65.5.m1.1.1" xref="A1.T3.65.65.65.5.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.65.65.65.5.m1.1b"><csymbol cd="latexml" id="A1.T3.65.65.65.5.m1.1.1.cmml" xref="A1.T3.65.65.65.5.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.65.65.65.5.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.65.65.65.5.m1.1d">±</annotation></semantics></math> 144.88</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.66.66.66.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">503.85 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.66.66.66.6.m1.1"><semantics id="A1.T3.66.66.66.6.m1.1a"><mo id="A1.T3.66.66.66.6.m1.1.1" xref="A1.T3.66.66.66.6.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.66.66.66.6.m1.1b"><csymbol cd="latexml" id="A1.T3.66.66.66.6.m1.1.1.cmml" xref="A1.T3.66.66.66.6.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.66.66.66.6.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.66.66.66.6.m1.1d">±</annotation></semantics></math> 49.69</td>
</tr>
<tr class="ltx_tr" id="A1.T3.72.72.72">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T3.72.72.72.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">GPTRater.helpfulness</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.67.67.67.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">64.96 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.67.67.67.1.m1.1"><semantics id="A1.T3.67.67.67.1.m1.1a"><mo id="A1.T3.67.67.67.1.m1.1.1" xref="A1.T3.67.67.67.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.67.67.67.1.m1.1b"><csymbol cd="latexml" id="A1.T3.67.67.67.1.m1.1.1.cmml" xref="A1.T3.67.67.67.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.67.67.67.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.67.67.67.1.m1.1d">±</annotation></semantics></math> 27.25</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.68.68.68.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">63.11 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.68.68.68.2.m1.1"><semantics id="A1.T3.68.68.68.2.m1.1a"><mo id="A1.T3.68.68.68.2.m1.1.1" xref="A1.T3.68.68.68.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.68.68.68.2.m1.1b"><csymbol cd="latexml" id="A1.T3.68.68.68.2.m1.1.1.cmml" xref="A1.T3.68.68.68.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.68.68.68.2.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.68.68.68.2.m1.1d">±</annotation></semantics></math> 24.70</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.69.69.69.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">66.95 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.69.69.69.3.m1.1"><semantics id="A1.T3.69.69.69.3.m1.1a"><mo id="A1.T3.69.69.69.3.m1.1.1" xref="A1.T3.69.69.69.3.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.69.69.69.3.m1.1b"><csymbol cd="latexml" id="A1.T3.69.69.69.3.m1.1.1.cmml" xref="A1.T3.69.69.69.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.69.69.69.3.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.69.69.69.3.m1.1d">±</annotation></semantics></math> 26.95</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.70.70.70.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">62.08 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.70.70.70.4.m1.1"><semantics id="A1.T3.70.70.70.4.m1.1a"><mo id="A1.T3.70.70.70.4.m1.1.1" xref="A1.T3.70.70.70.4.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.70.70.70.4.m1.1b"><csymbol cd="latexml" id="A1.T3.70.70.70.4.m1.1.1.cmml" xref="A1.T3.70.70.70.4.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.70.70.70.4.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.70.70.70.4.m1.1d">±</annotation></semantics></math> 25.43</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.71.71.71.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">77.90 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.71.71.71.5.m1.1"><semantics id="A1.T3.71.71.71.5.m1.1a"><mo id="A1.T3.71.71.71.5.m1.1.1" xref="A1.T3.71.71.71.5.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.71.71.71.5.m1.1b"><csymbol cd="latexml" id="A1.T3.71.71.71.5.m1.1.1.cmml" xref="A1.T3.71.71.71.5.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.71.71.71.5.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.71.71.71.5.m1.1d">±</annotation></semantics></math> 22.10</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.72.72.72.6" style="background-color:#CCFFCC;padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="A1.T3.72.72.72.6.1" style="background-color:#CCFFCC;">92.83 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.72.72.72.6.1.m1.1"><semantics id="A1.T3.72.72.72.6.1.m1.1a"><mo id="A1.T3.72.72.72.6.1.m1.1.1" mathbackground="#CCFFCC" xref="A1.T3.72.72.72.6.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.72.72.72.6.1.m1.1b"><csymbol cd="latexml" id="A1.T3.72.72.72.6.1.m1.1.1.cmml" xref="A1.T3.72.72.72.6.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.72.72.72.6.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.72.72.72.6.1.m1.1d">±</annotation></semantics></math> 4.99</span></td>
</tr>
<tr class="ltx_tr" id="A1.T3.78.78.78">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="A1.T3.78.78.78.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">GPTRater.trust</th>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="A1.T3.73.73.73.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">64.47 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.73.73.73.1.m1.1"><semantics id="A1.T3.73.73.73.1.m1.1a"><mo id="A1.T3.73.73.73.1.m1.1.1" xref="A1.T3.73.73.73.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.73.73.73.1.m1.1b"><csymbol cd="latexml" id="A1.T3.73.73.73.1.m1.1.1.cmml" xref="A1.T3.73.73.73.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.73.73.73.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.73.73.73.1.m1.1d">±</annotation></semantics></math> 29.30</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="A1.T3.74.74.74.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">58.81 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.74.74.74.2.m1.1"><semantics id="A1.T3.74.74.74.2.m1.1a"><mo id="A1.T3.74.74.74.2.m1.1.1" xref="A1.T3.74.74.74.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.74.74.74.2.m1.1b"><csymbol cd="latexml" id="A1.T3.74.74.74.2.m1.1.1.cmml" xref="A1.T3.74.74.74.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.74.74.74.2.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.74.74.74.2.m1.1d">±</annotation></semantics></math> 25.38</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="A1.T3.75.75.75.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">67.62 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.75.75.75.3.m1.1"><semantics id="A1.T3.75.75.75.3.m1.1a"><mo id="A1.T3.75.75.75.3.m1.1.1" xref="A1.T3.75.75.75.3.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.75.75.75.3.m1.1b"><csymbol cd="latexml" id="A1.T3.75.75.75.3.m1.1.1.cmml" xref="A1.T3.75.75.75.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.75.75.75.3.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.75.75.75.3.m1.1d">±</annotation></semantics></math> 29.47</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="A1.T3.76.76.76.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">55.19 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.76.76.76.4.m1.1"><semantics id="A1.T3.76.76.76.4.m1.1a"><mo id="A1.T3.76.76.76.4.m1.1.1" xref="A1.T3.76.76.76.4.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.76.76.76.4.m1.1b"><csymbol cd="latexml" id="A1.T3.76.76.76.4.m1.1.1.cmml" xref="A1.T3.76.76.76.4.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.76.76.76.4.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.76.76.76.4.m1.1d">±</annotation></semantics></math> 27.20</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="A1.T3.77.77.77.5" style="background-color:#CCFFCC;padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="A1.T3.77.77.77.5.1" style="background-color:#CCFFCC;">77.78 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.77.77.77.5.1.m1.1"><semantics id="A1.T3.77.77.77.5.1.m1.1a"><mo id="A1.T3.77.77.77.5.1.m1.1.1" mathbackground="#CCFFCC" xref="A1.T3.77.77.77.5.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.77.77.77.5.1.m1.1b"><csymbol cd="latexml" id="A1.T3.77.77.77.5.1.m1.1.1.cmml" xref="A1.T3.77.77.77.5.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.77.77.77.5.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.77.77.77.5.1.m1.1d">±</annotation></semantics></math> 22.41</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T3.78.78.78.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">76.79 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.78.78.78.6.m1.1"><semantics id="A1.T3.78.78.78.6.m1.1a"><mo id="A1.T3.78.78.78.6.m1.1.1" xref="A1.T3.78.78.78.6.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.78.78.78.6.m1.1b"><csymbol cd="latexml" id="A1.T3.78.78.78.6.m1.1.1.cmml" xref="A1.T3.78.78.78.6.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.78.78.78.6.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.78.78.78.6.m1.1d">±</annotation></semantics></math> 13.39</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_appendix" id="A2">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>GPTSimilarity</h2>
<figure class="ltx_figure" id="A2.F7"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="356" id="A2.F7.g1" src="x11.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Evaluation of different LLM variations: GPTSimilarity Score on question answering is evaluated as a score by an LLM (GPT-3.5) that is specifically prompted for this task.
</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_appendix" id="A3">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>GPTRater</h2>
<figure class="ltx_figure" id="A3.F8">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F8.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="356" id="A3.F8.sf1.g1" src="x12.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(a) </span>GPTRater.Trust Score</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F8.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="356" id="A3.F8.sf2.g1" src="x13.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(b) </span>GPTRater.Helpfulness Score</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>Evaluation of different LLM variations: GPTRater scores on question answering are evaluated as a score by an LLM (GPT-3.5) that is specifically prompted on an estimate for trust and helpfulness.
</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_appendix" id="A4">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>Comparison of Responses during Fine-Tuning</h2>
<figure class="ltx_table" id="A4.T4">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>Example pair of question together with the Ground Truth answer.</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A4.T4.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A4.T4.1.1.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt" id="A4.T4.1.1.1.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A4.T4.1.1.1.1.1">
<span class="ltx_p" id="A4.T4.1.1.1.1.1.1" style="width:216.8pt;"><span class="ltx_text ltx_font_bold" id="A4.T4.1.1.1.1.1.1.1">Sample question</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A4.T4.1.1.1.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A4.T4.1.1.1.2.1">
<span class="ltx_p" id="A4.T4.1.1.1.2.1.1" style="width:216.8pt;"><span class="ltx_text ltx_font_bold" id="A4.T4.1.1.1.2.1.1.1">Ground Truth answer</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A4.T4.1.2.2">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t" id="A4.T4.1.2.2.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A4.T4.1.2.2.1.1">
<span class="ltx_p" id="A4.T4.1.2.2.1.1.1" style="width:216.8pt;"><span class="ltx_text ltx_font_typewriter" id="A4.T4.1.2.2.1.1.1.1" style="color:#0000FF;">Provide an overview of different types of legal moves or operators that can be used in pathfinding algorithms for robot navigation.</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" id="A4.T4.1.2.2.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A4.T4.1.2.2.2.1">
<span class="ltx_p" id="A4.T4.1.2.2.2.1.1" style="width:216.8pt;"><span class="ltx_text ltx_font_typewriter" id="A4.T4.1.2.2.2.1.1.1">In pathfinding algorithms for robot navigation, legal moves or operators are typically described as possible atomic moves of the robot that are collision-free <span class="ltx_text" id="A4.T4.1.2.2.2.1.1.1.1" style="color:#00FF00;">(@10-slam-deck Slide 11)</span> such as single steps between grid cells with four or eight connectivity <span class="ltx_text" id="A4.T4.1.2.2.2.1.1.1.2" style="color:#00FF00;">(@10-slam-deck Slide 12)</span>. These legal moves must use an abstracted form of actions as primitives and might be associated with a cost <span class="ltx_text" id="A4.T4.1.2.2.2.1.1.1.3" style="color:#00FF00;">(@10-slam-deck Slide 10)</span>. Different planning strategies may also involve increasing the size of obstacles by considering the size of the robot when determining legal moves <span class="ltx_text" id="A4.T4.1.2.2.2.1.1.1.4" style="color:#00FF00;">(@10-slam-deck Slide 12)</span>.</span></span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
<figure class="ltx_table" id="A4.T5">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>Comparison of responses from different fine-tuned LLaMA-2 versions (after <math alttext="2000" class="ltx_Math" display="inline" id="A4.T5.3.m1.1"><semantics id="A4.T5.3.m1.1b"><mn id="A4.T5.3.m1.1.1" xref="A4.T5.3.m1.1.1.cmml">2000</mn><annotation-xml encoding="MathML-Content" id="A4.T5.3.m1.1c"><cn id="A4.T5.3.m1.1.1.cmml" type="integer" xref="A4.T5.3.m1.1.1">2000</cn></annotation-xml><annotation encoding="application/x-tex" id="A4.T5.3.m1.1d">2000</annotation><annotation encoding="application/x-llamapun" id="A4.T5.3.m1.1e">2000</annotation></semantics></math> and <math alttext="128000" class="ltx_Math" display="inline" id="A4.T5.4.m2.1"><semantics id="A4.T5.4.m2.1b"><mn id="A4.T5.4.m2.1.1" xref="A4.T5.4.m2.1.1.cmml">128000</mn><annotation-xml encoding="MathML-Content" id="A4.T5.4.m2.1c"><cn id="A4.T5.4.m2.1.1.cmml" type="integer" xref="A4.T5.4.m2.1.1">128000</cn></annotation-xml><annotation encoding="application/x-tex" id="A4.T5.4.m2.1d">128000</annotation><annotation encoding="application/x-llamapun" id="A4.T5.4.m2.1e">128000</annotation></semantics></math> steps), without using RAG.</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A4.T5.5">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A4.T5.5.1.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt" id="A4.T5.5.1.1.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A4.T5.5.1.1.1.1">
<span class="ltx_p" id="A4.T5.5.1.1.1.1.1" style="width:216.8pt;">
<span class="ltx_inline-block ltx_parbox ltx_align_middle" id="A4.T5.5.1.1.1.1.1.1" style="width:199.2pt;">
<span class="ltx_p" id="A4.T5.5.1.1.1.1.1.1.1">Fine-tuned LLaMA-2,</span>
<span class="ltx_p" id="A4.T5.5.1.1.1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="A4.T5.5.1.1.1.1.1.1.2.1">2000 Training Steps</span></span>
</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A4.T5.5.1.1.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A4.T5.5.1.1.2.1">
<span class="ltx_p" id="A4.T5.5.1.1.2.1.1" style="width:216.8pt;">
<span class="ltx_inline-block ltx_parbox ltx_align_middle" id="A4.T5.5.1.1.2.1.1.1" style="width:199.2pt;">
<span class="ltx_p" id="A4.T5.5.1.1.2.1.1.1.1">Fine-tuned LLaMA-2,</span>
<span class="ltx_p" id="A4.T5.5.1.1.2.1.1.1.2"><span class="ltx_text ltx_font_bold" id="A4.T5.5.1.1.2.1.1.1.2.1">128000 Training Steps</span></span>
</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A4.T5.5.2.2">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t" id="A4.T5.5.2.2.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A4.T5.5.2.2.1.1">
<span class="ltx_p" id="A4.T5.5.2.2.1.1.1" style="width:216.8pt;"><span class="ltx_text ltx_font_typewriter" id="A4.T5.5.2.2.1.1.1.1">Pathfinding algorithms for robot navigation often rely on various legal moves or operators to determine the sequence of actions that a robot can take to reach a goal. These legal moves that the robot does not violate any constraints or obstacles in its environment. Here’s an overview of different types of legal moves or operators commonly used in pathfinding algorithms for robot navigation: \n\n 1. Forward Movement (F): This operator allows the robot to move forward in a straight line, without any turns or [...]</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" id="A4.T5.5.2.2.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A4.T5.5.2.2.2.1">
<span class="ltx_p" id="A4.T5.5.2.2.2.1.1" style="width:216.8pt;"><span class="ltx_text ltx_font_typewriter" id="A4.T5.5.2.2.2.1.1.1" style="color:#00FF00;">[RESP]<span class="ltx_text" id="A4.T5.5.2.2.2.1.1.1.1" style="color:#000000;"> In the context of robot navigation and pathfinding, different types of legal moves or operators can refer to various options for allowing a navigation algorithm to consider different types of actions while planning a path for a robot. These may include options such as forward, backward, turn left or right, combine movements, etc. The specific types of legal moves available will depend on the particular algorithm being used and the environment being navigated </span>(@09-Localization-deck Slide 52)<span class="ltx_text" id="A4.T5.5.2.2.2.1.1.1.2" style="color:#000000;">. </span>[/RESP]</span></span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
<figure class="ltx_table" id="A4.T6">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6: </span>Comparison of responses from different fine-tuned LLaMA-2 versions (after <math alttext="2000" class="ltx_Math" display="inline" id="A4.T6.3.m1.1"><semantics id="A4.T6.3.m1.1b"><mn id="A4.T6.3.m1.1.1" xref="A4.T6.3.m1.1.1.cmml">2000</mn><annotation-xml encoding="MathML-Content" id="A4.T6.3.m1.1c"><cn id="A4.T6.3.m1.1.1.cmml" type="integer" xref="A4.T6.3.m1.1.1">2000</cn></annotation-xml><annotation encoding="application/x-tex" id="A4.T6.3.m1.1d">2000</annotation><annotation encoding="application/x-llamapun" id="A4.T6.3.m1.1e">2000</annotation></semantics></math> and <math alttext="128000" class="ltx_Math" display="inline" id="A4.T6.4.m2.1"><semantics id="A4.T6.4.m2.1b"><mn id="A4.T6.4.m2.1.1" xref="A4.T6.4.m2.1.1.cmml">128000</mn><annotation-xml encoding="MathML-Content" id="A4.T6.4.m2.1c"><cn id="A4.T6.4.m2.1.1.cmml" type="integer" xref="A4.T6.4.m2.1.1">128000</cn></annotation-xml><annotation encoding="application/x-tex" id="A4.T6.4.m2.1d">128000</annotation><annotation encoding="application/x-llamapun" id="A4.T6.4.m2.1e">128000</annotation></semantics></math> steps) when enriching the input using RAG and prompt engineering.</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A4.T6.5">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A4.T6.5.1.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt" id="A4.T6.5.1.1.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A4.T6.5.1.1.1.1">
<span class="ltx_p" id="A4.T6.5.1.1.1.1.1" style="width:216.8pt;">
<span class="ltx_inline-block ltx_parbox ltx_align_middle" id="A4.T6.5.1.1.1.1.1.1" style="width:199.2pt;">
<span class="ltx_p" id="A4.T6.5.1.1.1.1.1.1.1">Fine-Tuned LLaMA-2 + RAG and</span>
<span class="ltx_p" id="A4.T6.5.1.1.1.1.1.1.2">System Message, <span class="ltx_text ltx_font_bold" id="A4.T6.5.1.1.1.1.1.1.2.1">2000 Steps</span></span>
</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A4.T6.5.1.1.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A4.T6.5.1.1.2.1">
<span class="ltx_p" id="A4.T6.5.1.1.2.1.1" style="width:216.8pt;">
<span class="ltx_inline-block ltx_parbox ltx_align_middle" id="A4.T6.5.1.1.2.1.1.1" style="width:199.2pt;">
<span class="ltx_p" id="A4.T6.5.1.1.2.1.1.1.1">Fine-Tuned LLaMA-2 + RAG and</span>
<span class="ltx_p" id="A4.T6.5.1.1.2.1.1.1.2">System Message, <span class="ltx_text ltx_font_bold" id="A4.T6.5.1.1.2.1.1.1.2.1">128000 Steps</span></span>
</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A4.T6.5.2.2">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t" id="A4.T6.5.2.2.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A4.T6.5.2.2.1.1">
<span class="ltx_p" id="A4.T6.5.2.2.1.1.1" style="width:216.8pt;"><span class="ltx_text ltx_font_typewriter" id="A4.T6.5.2.2.1.1.1.1">Based on the lecture material, different types of legal moves or operators that can be used in pathfinding algorithms for robot navigation include:\n\n * Operators: Describe legal moves from state to state using an abstracted form of actions as primitives. <span class="ltx_text" id="A4.T6.5.2.2.1.1.1.1.1" style="color:#00FF00;">(@Slide 10-slam-deck 10)</span>\n * Operators: Explain how to control a mobile robot in order to move the robot towards some well-specified target using locomotion. <span class="ltx_text" id="A4.T6.5.2.2.1.1.1.1.2" style="color:#00FF00;">(@Slide 09-Localization-deck 47)</span>\n * Operators: Guide forms of [...]</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" id="A4.T6.5.2.2.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A4.T6.5.2.2.2.1">
<span class="ltx_p" id="A4.T6.5.2.2.2.1.1" style="width:216.8pt;"><span class="ltx_text ltx_font_typewriter" id="A4.T6.5.2.2.2.1.1.1">\n <span class="ltx_text" id="A4.T6.5.2.2.2.1.1.1.1" style="color:#FF0000;">### The lecture material and your chat with the student. Now, do the following steps:\n\n Requests: Based on your latest message, understand what the student wants to know by listing the request/requests based on your latest chat message.\n Evaluate whether the request is understandable and can be answered with the lecture material above or not.\n Use this format for referencing slides or Images by always incorporating the slide number and the lecture Title: (@Slide &lt;name of</span> [...]</span></span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_appendix" id="A5">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix E </span>Overview human evaluation</h2>
<figure class="ltx_table" id="A5.T7">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 7: </span>Human evaluation of the different LLM versions (evaluation was conducted by only two teaching assistants who assessed a randomly selected subset of the evaluation set). Each sentence of an answer was presented to human labelers together with context. The labelers were tasked to rate this along two dimensions: Trust and Helpfulness. Each dimension was given on a five step scale. Trust: Nonsense – False statement – General knowledge – Partially proven and shown – Proven (with proof / reference in answer); Helpfulness: Not helpful – Repetition – Unclear – Limited extent helpful – Helpful.</figcaption>
<div class="ltx_inline-block ltx_transformed_outer" id="A5.T7.1" style="width:433.6pt;height:224.4pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-11.1pt,5.7pt) scale(0.951258644277379,0.951258644277379) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A5.T7.1.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A5.T7.1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt" id="A5.T7.1.1.1.1.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_parbox ltx_align_middle" id="A5.T7.1.1.1.1.1.1" style="width:85.4pt;">
<span class="ltx_p" id="A5.T7.1.1.1.1.1.1.1">Class</span>
</span>
</th>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A5.T7.1.1.1.1.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_parbox ltx_align_middle" id="A5.T7.1.1.1.1.2.1" style="width:42.7pt;">
<span class="ltx_p" id="A5.T7.1.1.1.1.2.1.1">GPT-3.5</span>
</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="A5.T7.1.1.1.1.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_parbox ltx_align_middle" id="A5.T7.1.1.1.1.3.1" style="width:42.7pt;">
<span class="ltx_p" id="A5.T7.1.1.1.1.3.1.1">LLaMA-2</span>
</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A5.T7.1.1.1.1.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_parbox ltx_align_middle" id="A5.T7.1.1.1.1.4.1" style="width:42.7pt;">
<span class="ltx_p" id="A5.T7.1.1.1.1.4.1.1">GPT +RAG</span>
</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="A5.T7.1.1.1.1.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_parbox ltx_align_middle" id="A5.T7.1.1.1.1.5.1" style="width:42.7pt;">
<span class="ltx_p" id="A5.T7.1.1.1.1.5.1.1">LLaMA +RAG</span>
</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A5.T7.1.1.1.1.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_parbox ltx_align_middle" id="A5.T7.1.1.1.1.6.1" style="width:51.2pt;">
<span class="ltx_p" id="A5.T7.1.1.1.1.6.1.1">fine-tuned LLaMA</span>
</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A5.T7.1.1.1.1.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_parbox ltx_align_middle" id="A5.T7.1.1.1.1.7.1" style="width:51.2pt;">
<span class="ltx_p" id="A5.T7.1.1.1.1.7.1.1">LLaMA-ft +RAG</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A5.T7.1.1.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" colspan="7" id="A5.T7.1.1.2.2.1" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="A5.T7.1.1.2.2.1.1">Trust</span></th>
</tr>
<tr class="ltx_tr" id="A5.T7.1.1.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A5.T7.1.1.3.3.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">    Nonsense</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T7.1.1.3.3.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">0</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T7.1.1.3.3.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.005</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T7.1.1.3.3.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">0</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T7.1.1.3.3.5" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="A5.T7.1.1.3.3.5.1">0.165</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T7.1.1.3.3.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T7.1.1.3.3.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.095</td>
</tr>
<tr class="ltx_tr" id="A5.T7.1.1.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A5.T7.1.1.4.4.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">    False Statement</th>
<td class="ltx_td ltx_align_center" id="A5.T7.1.1.4.4.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">0</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A5.T7.1.1.4.4.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.015</td>
<td class="ltx_td ltx_align_center" id="A5.T7.1.1.4.4.4" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="A5.T7.1.1.4.4.4.1">0.035</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A5.T7.1.1.4.4.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.03</td>
<td class="ltx_td ltx_align_center" id="A5.T7.1.1.4.4.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.015</td>
<td class="ltx_td ltx_align_center" id="A5.T7.1.1.4.4.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.03</td>
</tr>
<tr class="ltx_tr" id="A5.T7.1.1.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A5.T7.1.1.5.5.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">    General Knowledge</th>
<td class="ltx_td ltx_align_center" id="A5.T7.1.1.5.5.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.04</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A5.T7.1.1.5.5.3" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="A5.T7.1.1.5.5.3.1">0.175</span></td>
<td class="ltx_td ltx_align_center" id="A5.T7.1.1.5.5.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.005</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A5.T7.1.1.5.5.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.135</td>
<td class="ltx_td ltx_align_center" id="A5.T7.1.1.5.5.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.055</td>
<td class="ltx_td ltx_align_center" id="A5.T7.1.1.5.5.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.125</td>
</tr>
<tr class="ltx_tr" id="A5.T7.1.1.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A5.T7.1.1.6.6.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">    Partial</th>
<td class="ltx_td ltx_align_center" id="A5.T7.1.1.6.6.2" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="A5.T7.1.1.6.6.2.1">0.95</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A5.T7.1.1.6.6.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.795</td>
<td class="ltx_td ltx_align_center" id="A5.T7.1.1.6.6.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.05</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A5.T7.1.1.6.6.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.12</td>
<td class="ltx_td ltx_align_center" id="A5.T7.1.1.6.6.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.275</td>
<td class="ltx_td ltx_align_center" id="A5.T7.1.1.6.6.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.22</td>
</tr>
<tr class="ltx_tr" id="A5.T7.1.1.7.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A5.T7.1.1.7.7.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">    Proven</th>
<td class="ltx_td ltx_align_center" id="A5.T7.1.1.7.7.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">0</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A5.T7.1.1.7.7.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">0</td>
<td class="ltx_td ltx_align_center" id="A5.T7.1.1.7.7.4" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="A5.T7.1.1.7.7.4.1">0.905</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A5.T7.1.1.7.7.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.53</td>
<td class="ltx_td ltx_align_center" id="A5.T7.1.1.7.7.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.655</td>
<td class="ltx_td ltx_align_center" id="A5.T7.1.1.7.7.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.515</td>
</tr>
<tr class="ltx_tr" id="A5.T7.1.1.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" colspan="7" id="A5.T7.1.1.8.8.1" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="A5.T7.1.1.8.8.1.1">Helpfulness</span></th>
</tr>
<tr class="ltx_tr" id="A5.T7.1.1.9.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A5.T7.1.1.9.9.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">    Not Helpful</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T7.1.1.9.9.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.025</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T7.1.1.9.9.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.02</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T7.1.1.9.9.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.035</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T7.1.1.9.9.5" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="A5.T7.1.1.9.9.5.1">0.25</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T7.1.1.9.9.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.105</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T7.1.1.9.9.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.175</td>
</tr>
<tr class="ltx_tr" id="A5.T7.1.1.10.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A5.T7.1.1.10.10.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">    Repetition</th>
<td class="ltx_td ltx_align_center" id="A5.T7.1.1.10.10.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.015</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A5.T7.1.1.10.10.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.055</td>
<td class="ltx_td ltx_align_center" id="A5.T7.1.1.10.10.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.07</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A5.T7.1.1.10.10.5" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="A5.T7.1.1.10.10.5.1">0.12</span></td>
<td class="ltx_td ltx_align_center" id="A5.T7.1.1.10.10.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">0</td>
<td class="ltx_td ltx_align_center" id="A5.T7.1.1.10.10.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.07</td>
</tr>
<tr class="ltx_tr" id="A5.T7.1.1.11.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A5.T7.1.1.11.11.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">    Unclear</th>
<td class="ltx_td ltx_align_center" id="A5.T7.1.1.11.11.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.005</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A5.T7.1.1.11.11.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.015</td>
<td class="ltx_td ltx_align_center" id="A5.T7.1.1.11.11.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.025</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A5.T7.1.1.11.11.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.04</td>
<td class="ltx_td ltx_align_center" id="A5.T7.1.1.11.11.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.03</td>
<td class="ltx_td ltx_align_center" id="A5.T7.1.1.11.11.7" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="A5.T7.1.1.11.11.7.1">0.135</span></td>
</tr>
<tr class="ltx_tr" id="A5.T7.1.1.12.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A5.T7.1.1.12.12.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">    Limited</th>
<td class="ltx_td ltx_align_center" id="A5.T7.1.1.12.12.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.085</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A5.T7.1.1.12.12.3" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="A5.T7.1.1.12.12.3.1">0.28</span></td>
<td class="ltx_td ltx_align_center" id="A5.T7.1.1.12.12.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.19</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A5.T7.1.1.12.12.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.065</td>
<td class="ltx_td ltx_align_center" id="A5.T7.1.1.12.12.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.275</td>
<td class="ltx_td ltx_align_center" id="A5.T7.1.1.12.12.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.23</td>
</tr>
<tr class="ltx_tr" id="A5.T7.1.1.13.13">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="A5.T7.1.1.13.13.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">    Helpful</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A5.T7.1.1.13.13.2" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="A5.T7.1.1.13.13.2.1">0.86</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="A5.T7.1.1.13.13.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.615</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A5.T7.1.1.13.13.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.67</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="A5.T7.1.1.13.13.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.52</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A5.T7.1.1.13.13.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.585</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A5.T7.1.1.13.13.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.365</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section><div about="" class="ltx_rdf" content="David S. Hippocampus, Elias D. Striatum" property="dcterms:creator"></div>
<div about="" class="ltx_rdf" content="First keyword, Second keyword, More" property="dcterms:subject"></div>
<div about="" class="ltx_rdf" content="q-bio.NC, q-bio.QM" property="dcterms:subject"></div>
<div about="" class="ltx_rdf" content="A template for the arxiv style" property="dcterms:title"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Fri Aug  2 19:47:05 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
