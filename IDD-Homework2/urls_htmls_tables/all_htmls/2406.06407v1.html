<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>A Taxonomy of Challenges to Curating Fair Datasets</title>
<!--Generated on Mon Jun 10 15:48:45 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2406.06407v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#S1" title="In A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#S2" title="In A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#S3" title="In A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Methods</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#S3.SS1" title="In 3 Methods ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Participant Recruitment</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#S3.SS2" title="In 3 Methods ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Thematic Analysis</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#S4" title="In A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Challenges During the Dataset Lifecycle</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#S4.SS1" title="In 4 Challenges During the Dataset Lifecycle ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Requirements</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#S4.SS2" title="In 4 Challenges During the Dataset Lifecycle ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Design</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#S4.SS3" title="In 4 Challenges During the Dataset Lifecycle ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Implementation</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#S4.SS3.SSS1" title="In 4.3 Implementation ‣ 4 Challenges During the Dataset Lifecycle ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3.1 </span>Data Collection</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#S4.SS3.SSS2" title="In 4.3 Implementation ‣ 4 Challenges During the Dataset Lifecycle ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3.2 </span>Data Annotation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#S4.SS3.SSS3" title="In 4.3 Implementation ‣ 4 Challenges During the Dataset Lifecycle ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3.3 </span>Implementation Processes</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#S4.SS4" title="In 4 Challenges During the Dataset Lifecycle ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4 </span>Evaluation</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#S4.SS4.SSS1" title="In 4.4 Evaluation ‣ 4 Challenges During the Dataset Lifecycle ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4.1 </span>Assessing Data Quality</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#S4.SS4.SSS2" title="In 4.4 Evaluation ‣ 4 Challenges During the Dataset Lifecycle ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4.2 </span>Evaluating Data Utility</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#S4.SS5" title="In 4 Challenges During the Dataset Lifecycle ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.5 </span>Maintenance</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#S5" title="In A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Challenges Overarching the Broader Landscape of Fairness</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#S5.SS1" title="In 5 Challenges Overarching the Broader Landscape of Fairness ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Individual Level</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#S5.SS2" title="In 5 Challenges Overarching the Broader Landscape of Fairness ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Discipline Level</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#S5.SS3" title="In 5 Challenges Overarching the Broader Landscape of Fairness ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3 </span>Organization Level</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#S5.SS4" title="In 5 Challenges Overarching the Broader Landscape of Fairness ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.4 </span>Regulatory Level</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#S5.SS5" title="In 5 Challenges Overarching the Broader Landscape of Fairness ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.5 </span>Socio-Political Level</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#S6" title="In A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Considerations for Enabling Fair Dataset Curation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#S7" title="In A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#A1" title="In A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Additional Methodological Details</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#A1.SS1" title="In Appendix A Additional Methodological Details ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.1 </span>Additional Recruitment Details</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#A1.SS2" title="In Appendix A Additional Methodological Details ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.2 </span>Participant Anonymity</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#A1.SS3" title="In Appendix A Additional Methodological Details ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.3 </span>Interview Protocol</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#A2" title="In A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B </span>Additional Figures and Tables</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#A3" title="In Appendix B Additional Figures and Tables ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text" style="font-size:70%;">C</span> </span><span class="ltx_text" style="font-size:70%;">Detailed Recommendations for Enabling Fair Dataset Curation</span></span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#A3.SS1" title="In Appendix C Detailed Recommendations for Enabling Fair Dataset Curation ‣ Appendix B Additional Figures and Tables ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C.1 </span>Recommendations Overarching the Broader Landscape of Fairness</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#A3.SS1.SSS1" title="In C.1 Recommendations Overarching the Broader Landscape of Fairness ‣ Appendix C Detailed Recommendations for Enabling Fair Dataset Curation ‣ Appendix B Additional Figures and Tables ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C.1.1 </span>Socio-Political Level</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#A3.SS1.SSS2" title="In C.1 Recommendations Overarching the Broader Landscape of Fairness ‣ Appendix C Detailed Recommendations for Enabling Fair Dataset Curation ‣ Appendix B Additional Figures and Tables ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C.1.2 </span>Regulatory Level</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#A3.SS1.SSS3" title="In C.1 Recommendations Overarching the Broader Landscape of Fairness ‣ Appendix C Detailed Recommendations for Enabling Fair Dataset Curation ‣ Appendix B Additional Figures and Tables ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C.1.3 </span>Organization Level</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#A3.SS1.SSS4" title="In C.1 Recommendations Overarching the Broader Landscape of Fairness ‣ Appendix C Detailed Recommendations for Enabling Fair Dataset Curation ‣ Appendix B Additional Figures and Tables ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C.1.4 </span>Discipline Level</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#A3.SS1.SSS5" title="In C.1 Recommendations Overarching the Broader Landscape of Fairness ‣ Appendix C Detailed Recommendations for Enabling Fair Dataset Curation ‣ Appendix B Additional Figures and Tables ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C.1.5 </span>Individual Level</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#A3.SS2" title="In Appendix C Detailed Recommendations for Enabling Fair Dataset Curation ‣ Appendix B Additional Figures and Tables ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C.2 </span>Recommendations During the Dataset Lifecycle</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#A3.SS2.SSS1" title="In C.2 Recommendations During the Dataset Lifecycle ‣ Appendix C Detailed Recommendations for Enabling Fair Dataset Curation ‣ Appendix B Additional Figures and Tables ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C.2.1 </span>Requirements</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#A3.SS2.SSS2" title="In C.2 Recommendations During the Dataset Lifecycle ‣ Appendix C Detailed Recommendations for Enabling Fair Dataset Curation ‣ Appendix B Additional Figures and Tables ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C.2.2 </span>Design</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#A3.SS2.SSS3" title="In C.2 Recommendations During the Dataset Lifecycle ‣ Appendix C Detailed Recommendations for Enabling Fair Dataset Curation ‣ Appendix B Additional Figures and Tables ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C.2.3 </span>Implementation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#A3.SS2.SSS4" title="In C.2 Recommendations During the Dataset Lifecycle ‣ Appendix C Detailed Recommendations for Enabling Fair Dataset Curation ‣ Appendix B Additional Figures and Tables ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C.2.4 </span>Evaluation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#A3.SS2.SSS5" title="In C.2 Recommendations During the Dataset Lifecycle ‣ Appendix C Detailed Recommendations for Enabling Fair Dataset Curation ‣ Appendix B Additional Figures and Tables ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C.2.5 </span>Maintenance</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#A4" title="In Appendix C Detailed Recommendations for Enabling Fair Dataset Curation ‣ Appendix B Additional Figures and Tables ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text" style="font-size:70%;">D</span> </span><span class="ltx_text" style="font-size:70%;">Limitations</span></span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#A5" title="In Appendix D Limitations ‣ Appendix C Detailed Recommendations for Enabling Fair Dataset Curation ‣ Appendix B Additional Figures and Tables ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text" style="font-size:70%;">E</span> </span><span class="ltx_text" style="font-size:70%;">Broader Impacts</span></span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#A6" title="In Appendix E Broader Impacts ‣ Appendix D Limitations ‣ Appendix C Detailed Recommendations for Enabling Fair Dataset Curation ‣ Appendix B Additional Figures and Tables ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text" style="font-size:70%;">F</span> </span><span class="ltx_text" style="font-size:70%;">Author Contributions</span></span></a></li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">A Taxonomy of Challenges to Curating Fair Datasets</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Dora Zhao
<br class="ltx_break"/>Stanford University
Morgan Klaus Scheuerman<span class="ltx_note ltx_role_footnotemark" id="footnotex1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">1</span></span></span></span>
<br class="ltx_break"/>Sony AI
Pooja Chitre
<br class="ltx_break"/>Arizona State University
Jerone T. A. Andrews<span class="ltx_note ltx_role_footnotemark" id="footnotex2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">2</span></span></span></span>
<br class="ltx_break"/>Sony AI
Georgia Panagiotidou
<br class="ltx_break"/>King’s College London
Shawn Walker
<br class="ltx_break"/>Arizona State University
Kathleen H. Pine<span class="ltx_note ltx_role_footnotemark" id="footnotex3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">3</span></span></span></span>
<br class="ltx_break"/>Arizona State University
Alice Xiang<span class="ltx_note ltx_role_footnotemark" id="footnotex4"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">3</span></span></span></span>
<br class="ltx_break"/>Sony AI
</span><span class="ltx_author_notes">Joint first authorJoint second authorJoint last author</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id1.id1">Despite extensive efforts to create <em class="ltx_emph ltx_font_italic" id="id1.id1.1">fairer</em> machine learning (ML) datasets, there remains a limited understanding of the practical aspects of dataset curation.
Drawing from interviews with 30 ML dataset curators, we present a comprehensive taxonomy of the challenges and trade-offs encountered throughout the dataset curation lifecycle.
Our findings underscore overarching issues within the broader fairness landscape that impact data curation.
We conclude with recommendations aimed at fostering systemic changes to better facilitate fair dataset curation practices.</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Persistent concerns from academia, government, industry, and the public sphere center on the disparate impact and unfairness in machine learning (ML) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib20" title="">20</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib72" title="">72</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib26" title="">26</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib137" title="">137</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib91" title="">91</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib30" title="">30</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib75" title="">75</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib154" title="">154</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib68" title="">68</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib67" title="">67</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib69" title="">69</a>]</cite>. Data is often viewed as a primary culprit, perpetuating biases and compromising fairness <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib50" title="">50</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib34" title="">34</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib159" title="">159</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib86" title="">86</a>]</cite>. In response, substantial attention has been directed towards <em class="ltx_emph ltx_font_italic" id="S1.p1.1.1">fair</em> dataset collection practices <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib44" title="">44</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib41" title="">41</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib156" title="">156</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib130" title="">130</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib159" title="">159</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib63" title="">63</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib111" title="">111</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib60" title="">60</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib117" title="">117</a>]</cite>. However, there remains a significant gap in understanding both the practices and practicalities of fair dataset curation.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">To address this gap, we shift from theoretical, guideline-focused scholarship <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib49" title="">49</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib3" title="">3</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib61" title="">61</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib40" title="">40</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib114" title="">114</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib76" title="">76</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib78" title="">78</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib100" title="">100</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib39" title="">39</a>]</cite> to empirical inquiry, exploring the grounded practices of fair dataset curation. Following a well-established tradition in human-computer interaction (HCI) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib73" title="">73</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib144" title="">144</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib120" title="">120</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib94" title="">94</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib65" title="">65</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib104" title="">104</a>]</cite>, we conducted interviews with 30 dataset curators from both academia and industry who have experience curating fair vision, language, or multi-modal datasets. Through these interviews, we uncover practical challenges and trade-offs to ensuring fairness in dataset curation. Our use of qualitative methodology allowed us to surface nuanced challenges and trade-offs that regularly appear throughout the curation process and gain insights into considerations that may otherwise remain undisclosed.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">We first provide three dimensions of fairness—<em class="ltx_emph ltx_font_italic" id="S1.p3.1.1">composition</em>, <em class="ltx_emph ltx_font_italic" id="S1.p3.1.2">process</em>, and <em class="ltx_emph ltx_font_italic" id="S1.p3.1.3">release</em>—that participants considered during curation. Fairness is not only a property of the final artifact—the dataset—but also a constant consideration curators must account for throughout the curation process. Through our empirical findings, we identify various challenges that obstruct different fairness goals. Building on <cite class="ltx_cite ltx_citemacro_citet">Hutchinson et al. [<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib76" title="">76</a>]</cite>’s conception of the dataset lifecycle, we contribute a taxonomy of challenges dataset curators encounter, both during the dataset lifecycle (<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#S4" title="4 Challenges During the Dataset Lifecycle ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">4</span></a>) and within the broader landscape of fairness in ML (<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#S5" title="5 Challenges Overarching the Broader Landscape of Fairness ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">5</span></a>).</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">By conducting in-depth interviews with those engaged in fair dataset work on the ground, we provide empirical support for prior work <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib108" title="">108</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib89" title="">89</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib78" title="">78</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib3" title="">3</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib76" title="">76</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib40" title="">40</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib90" title="">90</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib53" title="">53</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib77" title="">77</a>]</cite>, which has focused on identifying implicit challenges in the fairness literature. We conclude with recommendations aimed at fostering systemic changes to better facilitate fair dataset curation practices (<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#S6" title="6 Considerations for Enabling Fair Dataset Curation ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">6</span></a>).</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">Our work aligns with existing recommendations for fair dataset curation <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib3" title="">3</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib78" title="">78</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib126" title="">126</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib114" title="">114</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib49" title="">49</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib76" title="">76</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib100" title="">100</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib99" title="">99</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib40" title="">40</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib108" title="">108</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib12" title="">12</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib95" title="">95</a>]</cite> and aims to deepen stakeholders’ understanding of the specific challenges involved. By illuminating these issues, we hope to expedite more effective solutions and promote further investigation into the complexities of fairness in dataset curation.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>
<div class="ltx_para ltx_noindent" id="S2.p1">
<p class="ltx_p" id="S2.p1.1"><span class="ltx_text ltx_font_bold" id="S2.p1.1.1">Issues with existing dataset curation practices.</span> Poor training data can lead to representational harms <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib20" title="">20</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib71" title="">71</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib48" title="">48</a>]</cite>, such as stereotyping <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib131" title="">131</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib21" title="">21</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib18" title="">18</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib47" title="">47</a>]</cite>, spurious correlations <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib97" title="">97</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib149" title="">149</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib160" title="">160</a>]</cite>, and poor performance or total erasure of certain populations <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib153" title="">153</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib20" title="">20</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib159" title="">159</a>]</cite>. Poor evaluation data means harmful model outcomes may be overlooked or missed, especially as they cascade into various (often unintended) domains <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib120" title="">120</a>]</cite>. Beyond data’s impact on models directly, ML datasets are increasingly scrutinized for violating the ethical values of privacy and consent <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib3" title="">3</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib102" title="">102</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib33" title="">33</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib110" title="">110</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib108" title="">108</a>]</cite>, reinforcing disputable social constructs <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib125" title="">125</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib62" title="">62</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib82" title="">82</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib10" title="">10</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib16" title="">16</a>]</cite>, including highly offensive content <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib12" title="">12</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib159" title="">159</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib14" title="">14</a>]</cite>, and exploiting vulnerable populations for both data and annotations <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib135" title="">135</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib57" title="">57</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib147" title="">147</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">Practices for collecting large-scale data, such as web scraping, have consistently failed to meet many legal standards at the local and national level, violating copyright laws <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib59" title="">59</a>]</cite>, biometric laws <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib70" title="">70</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib158" title="">158</a>]</cite>, and even including child exploitation content <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib15" title="">15</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib138" title="">138</a>]</cite>. The difficulty of authoring and maintaining a comprehensively “fair” dataset is exacerbated by differential definitions of fairness and how to measure it (or whether it can be measured at all) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib96" title="">96</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib141" title="">141</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib4" title="">4</a>]</cite>. Current approaches to dataset documentation also obscure the inherently collaborative work that dataset authors must engage in and negotiate <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib99" title="">99</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib98" title="">98</a>]</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.p3">
<p class="ltx_p" id="S2.p3.1"><span class="ltx_text ltx_font_bold" id="S2.p3.1.1">Improving dataset curation practices.</span> Given the vast and varied issues with ML datasets, there has been a extensive line of work focused on improving dataset collection practices. These efforts have evolved substantially beyond <em class="ltx_emph ltx_font_italic" id="S2.p3.1.2">ante hoc</em> calls for more transparent and robust documentation of existing datasets <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib49" title="">49</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib114" title="">114</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib27" title="">27</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib40" title="">40</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib106" title="">106</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib8" title="">8</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib95" title="">95</a>]</cite>, such as
datasheets, which often result in a <em class="ltx_emph ltx_font_italic" id="S2.p3.1.3">ante hoc</em> approach, thus failing to capture decisions and trade-offs which might have occurred prior to and during data collection.
Thus, scholars are attempting to provide frameworks at different levels of granularity of considering the responsibility of dataset authors
leading to frameworks or design guidelines for both <em class="ltx_emph ltx_font_italic" id="S2.p3.1.4">pre hoc</em> and <em class="ltx_emph ltx_font_italic" id="S2.p3.1.5">per hoc</em> dataset curation <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib3" title="">3</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib126" title="">126</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib107" title="">107</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib56" title="">56</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib52" title="">52</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib152" title="">152</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib104" title="">104</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S2.p4">
<p class="ltx_p" id="S2.p4.1">For example, at a higher level, <cite class="ltx_cite ltx_citemacro_citet">Scheuerman et al. [<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib126" title="">126</a>]</cite> proposed a value-centric framework that centers values like positional expertise and contextually-relevant annotations. <cite class="ltx_cite ltx_citemacro_citet">Andrews et al. [<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib3" title="">3</a>]</cite> released a comprehensive set of considerations for responsibly curating human-centric computer vision datasets, covering topics like consent, human diversity, and subject revocation. Recent work from <cite class="ltx_cite ltx_citemacro_citet">Orr and Crawford [<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib104" title="">104</a>]</cite> distilled seven recommendations from interviews with 18 dataset curators. Their work highlights high-level themes such as advocating for more dataset auditing, ensuring participant privacy, and encouraging more documentation. Scholars are also increasingly providing highly contextual and specific guidance for collecting data on certain subgroups and vulnerable populations, such as children <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib148" title="">148</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib70" title="">70</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib152" title="">152</a>]</cite>, who are increasingly ending up in large web-scraped datasets <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib15" title="">15</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib138" title="">138</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S2.p5">
<p class="ltx_p" id="S2.p5.1">The scholarship focused on providing considerations and guidance for ethical dataset curation has been invaluable. However, how authors actually approach curating fair datasets is still opaque—especially given documented gaps between guidance and practice. Prior work has uncovered numerous barriers to incorporating fairness into practice <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib73" title="">73</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib65" title="">65</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib36" title="">36</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib94" title="">94</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib93" title="">93</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib146" title="">146</a>]</cite>, including misalignments between available toolkits and product needs <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib36" title="">36</a>]</cite>, organizational trade-offs that make auditing methods less effective <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib37" title="">37</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib103" title="">103</a>]</cite>, and difficulty negotiating expectations across roles <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib38" title="">38</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib93" title="">93</a>]</cite>. Yet literature on the challenges to creating fair datasets currently lacks a holistic framing of fairness that involves not only the composition of datasets, but the practices of producing and maintaining them. Identifying the challenges currently facing dataset curators focused on creating fair datasets is crucial to enabling fairer dataset curation in both industry and academic settings.</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Methods</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">To understand the challenges in collecting fair datasets, we conducted 30 semi-structured interviews with ML dataset collectors, each lasting between 45–60 minutes. Interviews were conducted between November 2023 and March 2024. Participants were asked to define fairness in ML datasets, describe their process for collecting fair datasets, highlight challenges faced, and discuss any trade-offs encountered during the dataset collection process. The study was approved by Arizona State University’s Institutional Review Board.</p>
</div>
<figure class="ltx_table" id="S3.T1">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S3.T1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T1.1.1.1">
<th class="ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_t" id="S3.T1.1.1.1.1" style="padding-top:2pt;padding-bottom:2pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.1.1.1.1.1">
<span class="ltx_p" id="S3.T1.1.1.1.1.1.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S3.T1.1.1.1.1.1.1.1" style="font-size:80%;">Type</span></span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_t" id="S3.T1.1.1.1.2" style="padding-top:2pt;padding-bottom:2pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.1.1.1.2.1">
<span class="ltx_p" id="S3.T1.1.1.1.2.1.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S3.T1.1.1.1.2.1.1.1" style="font-size:80%;">Count</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T1.1.2.1">
<td class="ltx_td ltx_align_justify ltx_border_t" id="S3.T1.1.2.1.1" style="padding-top:2pt;padding-bottom:2pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.1.2.1.1.1">
<span class="ltx_p" id="S3.T1.1.2.1.1.1.1"><span class="ltx_text" id="S3.T1.1.2.1.1.1.1.1" style="font-size:80%;">Role</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_border_t" id="S3.T1.1.2.1.2" style="padding-top:2pt;padding-bottom:2pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.1.2.1.2.1">
<span class="ltx_p" id="S3.T1.1.2.1.2.1.1"><span class="ltx_text" id="S3.T1.1.2.1.2.1.1.1" style="font-size:80%;">Graduate student (13), Post-Doctorate Researcher (6), Faculty (4), Researcher [Industry] (3), Researcher [Institute-based] (2), Other (2)</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.3.2">
<td class="ltx_td ltx_align_justify" id="S3.T1.1.3.2.1" style="padding-top:2pt;padding-bottom:2pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.1.3.2.1.1">
<span class="ltx_p" id="S3.T1.1.3.2.1.1.1"><span class="ltx_text" id="S3.T1.1.3.2.1.1.1.1" style="font-size:80%;">Setting</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="S3.T1.1.3.2.2" style="padding-top:2pt;padding-bottom:2pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.1.3.2.2.1">
<span class="ltx_p" id="S3.T1.1.3.2.2.1.1"><span class="ltx_text" id="S3.T1.1.3.2.2.1.1.1" style="font-size:80%;">University (23), Industry (4), Academic Research Institute (2), Think Tank (1)</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.4.3">
<td class="ltx_td ltx_align_justify" id="S3.T1.1.4.3.1" style="padding-top:2pt;padding-bottom:2pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.1.4.3.1.1">
<span class="ltx_p" id="S3.T1.1.4.3.1.1.1"><span class="ltx_text" id="S3.T1.1.4.3.1.1.1.1" style="font-size:80%;">Modality</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="S3.T1.1.4.3.2" style="padding-top:2pt;padding-bottom:2pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.1.4.3.2.1">
<span class="ltx_p" id="S3.T1.1.4.3.2.1.1"><span class="ltx_text" id="S3.T1.1.4.3.2.1.1.1" style="font-size:80%;">Language (16), Vision (9), Multi-modal (5), Tabular (3)</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.5.4">
<td class="ltx_td ltx_align_justify ltx_border_b" id="S3.T1.1.5.4.1" style="padding-top:2pt;padding-bottom:2pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.1.5.4.1.1">
<span class="ltx_p" id="S3.T1.1.5.4.1.1.1"><span class="ltx_text" id="S3.T1.1.5.4.1.1.1.1" style="font-size:80%;">Location</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_border_b" id="S3.T1.1.5.4.2" style="padding-top:2pt;padding-bottom:2pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.1.5.4.2.1">
<span class="ltx_p" id="S3.T1.1.5.4.2.1.1"><span class="ltx_text" id="S3.T1.1.5.4.2.1.1.1" style="font-size:80%;">Northern America (19), Southern Europe (3), Western Europe (3), Northern Europe (2), Latin American &amp; the Caribbean (1), Western Africa (1), Southern Asia (1)</span></span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table">Table 1: </span><span class="ltx_text" id="S3.T1.4.1" style="font-size:113%;">Summary statistics of participant demographics. The locations are coded at the region level according to the United Nations geoscheme. Since some participants had experience collecting datasets in more than one modality, the counts in this row exceed 30.</span></figcaption>
</figure>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Participant Recruitment</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">To qualify for our study, participants must have previously collected at least one “fair” ML dataset. Considering the extensive discourse on language and vision dataset practices <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib3" title="">3</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib108" title="">108</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib78" title="">78</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib15" title="">15</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib12" title="">12</a>]</cite>, we prioritized participants specializing in these domains. As shown in <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#S3.T1" title="In 3 Methods ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">1</span></a>, participants came from both industry and academia in addition to having experience across many data modalities. To accommodate diverse perspectives, we refrained from prescribing a specific definition of “fair”. Participants were initially recruited through purposive sampling, involving outreach to authors from a list of public datasets. To expand our sample, we advertised on social media platforms and relevant mailing lists, and employed snowball sampling. Refer to <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#A1" title="Appendix A Additional Methodological Details ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_tag">Appendix</span> <span class="ltx_text ltx_ref_tag">A</span></a> for further methodological details.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Thematic Analysis</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">To analyze our interviews, we use an abductive approach <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib139" title="">139</a>]</cite>, building upon existing knowledge about data curation with our qualitative interviews. We start with an initial set of codes related to challenges in fair data collection processes that arose from our literature review. Then, all authors independently coded the same interview surfacing additional themes, followed by a subsequent interview to create a refined codebook. Themes evolved iteratively, resulting in high-level codes on dataset taxonomy, fairness definitions, motivation, and collection processes. Remaining interviews were equally divided among the research team for qualitative analysis.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Challenges During the Dataset Lifecycle</h2>
<figure class="ltx_figure" id="S4.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="328" id="S4.F1.g1" src="extracted/5656716/Input/Process.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>A circular process diagram showing how each challenge we identified maps to each phase and subphase of the dataset lifecycle.</figcaption>
</figure>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">We present challenges participants encountered across the dataset lifecycle, taxonomizing them into requirements, design, implementation, evaluation, and maintenance phases (see <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#S4.F1" title="In 4 Challenges During the Dataset Lifecycle ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">1</span></a>). Recognizing the multi-faceted nature of <em class="ltx_emph ltx_font_italic" id="S4.p1.1.1">fairness</em>, we did not impose a specific definition during our interviews. Instead, we empowered participants to articulate their own definitions. Based on these definitions, we identified three dimensions of fairness: <em class="ltx_emph ltx_font_italic" id="S4.p1.1.2">composition</em>, which is achieved through diverse representations; <em class="ltx_emph ltx_font_italic" id="S4.p1.1.3">process</em>, which includes equitable compensation for data subjects and workers as well as recognition for curation efforts; and <em class="ltx_emph ltx_font_italic" id="S4.p1.1.4">release</em>, which emphasizes the importance of transparent and openly accessible data. The challenges we surface span all three dimensions of fairness. Refer to <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#A2" title="Appendix B Additional Figures and Tables ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_tag">Appendix</span> <span class="ltx_text ltx_ref_tag">B</span></a> for additional examples.</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Requirements</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">The <em class="ltx_emph ltx_font_italic" id="S4.SS1.p1.1.1">requirements phase</em> involves establishing a dataset’s purpose (e.g., intended tasks such as image tagging) and defining the fairness criteria to be operationalized within the dataset (e.g., group fairness).</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.p2.1.1">Scoping a dataset.</span>
Participants sought to balance fairness with utility (P8<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>To protect participant anonymity, we use the shortened “PX” to refer to individual participants, where “P” stands for “Participant” and “X” is the participant’s ID number (e.g., P8).</span></span></span>, P23, P26, P30). On the one hand, careful curation can lead to more nuanced insights compared to general-purpose datasets. As P26 explained, they would ideally “<span class="ltx_text ltx_font_italic" id="S4.SS1.p2.1.2">design smaller datasets for smaller models for specific applications, nothing that is deployed on a [South Asian] scale, because that definitely won’t work properly because of the [region’s] geographical diversity</span>.” Moreover, datasets containing billions of entries, such as LAION <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib128" title="">128</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib129" title="">129</a>]</cite>, make oversight difficult and, as a result, may include “<span class="ltx_text ltx_font_italic" id="S4.SS1.p2.1.3">unfair</span>” data (P18) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib14" title="">14</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S4.SS1.p3">
<p class="ltx_p" id="S4.SS1.p3.1">Nonetheless, participants also had to consider utility. P13 noted ML is “<span class="ltx_text ltx_font_italic" id="S4.SS1.p3.1.1">in this age of scale,</span>” making them
“<span class="ltx_text ltx_font_italic" id="S4.SS1.p3.1.2">a bit skeptical as [to] whether people are going to openly use fair datasets for training unless they’re very large.</span>” P21 highlighted a similar tension between “<span class="ltx_text ltx_font_italic" id="S4.SS1.p3.1.3">technical reasons why you need large open datasets</span>” and “<span class="ltx_text ltx_font_italic" id="S4.SS1.p3.1.4">ethical reasons on why that shouldn’t be the case.</span>” Fairness trade-offs pushed some (P12, P13) towards focusing on smaller evaluation datasets.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p4">
<p class="ltx_p" id="S4.SS1.p4.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.p4.1.1">Determining fairness definitions.</span> Nearly all participants stressed the <em class="ltx_emph ltx_font_italic" id="S4.SS1.p4.1.2">contextual</em> nature of fairness. Key factors shaping their definitions included domain (e.g., healthcare), task (e.g., sentiment analysis), and cultural context. For example, P2 highlighted the importance of cultural specificity, stating, “<span class="ltx_text ltx_font_italic" id="S4.SS1.p4.1.3">you see a lot of work that talks about fairness in gender or in race. But for a [South Asian] country, race does not manifest like it manifests for America.</span>” Participants also made trade-offs due to the multitude of fairness definitions available <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib101" title="">101</a>]</cite> (<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#S5.SS5" title="5.5 Socio-Political Level ‣ 5 Challenges Overarching the Broader Landscape of Fairness ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">5.5</span></a>). P19 noted that “<span class="ltx_text ltx_font_italic" id="S4.SS1.p4.1.4">there’s more than two dozen different fairness definitions … used in the literature.</span>” This diversity necessitated sacrifices in other dimensions, as emphasized by P18, who illustrated this with the “‘<span class="ltx_text ltx_font_italic" id="S4.SS1.p4.1.5">no free lunch theorem</span>”, stating, “<span class="ltx_text ltx_font_italic" id="S4.SS1.p4.1.6">You can’t have complete diversity with respect to, say, races,…geographies,…times of the day, and other domains. Everything is not possible. Once you clamp on one, the other one goes away.</span>”</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Design</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">In the <em class="ltx_emph ltx_font_italic" id="S4.SS2.p1.1.1">design phase</em>, curators determine how to operationalize dataset requirements, including defining the dataset’s taxonomy. For example, curators specify attributes for measuring fairness (e.g., skin tone) and the categories within those attributes <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib140" title="">140</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib66" title="">66</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib111" title="">111</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib64" title="">64</a>]</cite>. This phase also involves decisions on data collection and annotation methodologies (e.g., web scraping, hiring vendors).</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.p2.1.1">Creating fair taxonomies.</span> Participants struggled to find a fair taxonomy under the inherent unfairness of categorization. For example, P18 devised a geographic taxonomy featuring categories for the U.S. and Asia, acknowledging that the regions “<span class="ltx_text ltx_font_italic" id="S4.SS2.p2.1.2">are not homogeneous, they’re very heterogenous.</span>” P2 also noted a theoretically ideal taxonomy is as granular as possible, but practical constraints, such as data availability (<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#S4.SS2" title="4.2 Design ‣ 4 Challenges During the Dataset Lifecycle ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">4.2</span></a>) and time (<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#S5.SS3" title="5.3 Organization Level ‣ 5 Challenges Overarching the Broader Landscape of Fairness ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">5.3</span></a>), necessitated using coarser categories. Finally, the challenge of creating a fair taxonomy was compounded by the inadequacies of existing domain taxonomies. For example, P1 and P5 pointed out that the common binary operationalization of gender in medical data erases many gender identities. Nonetheless, participants felt compelled to utilize inadequate taxonomies due to practical constraints, even if it contradicted their personal beliefs. Participants were forced to align their notions of fairness with disciplinary norms (<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#S5.SS2" title="5.2 Discipline Level ‣ 5 Challenges Overarching the Broader Landscape of Fairness ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">5.2</span></a>).</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p3">
<p class="ltx_p" id="S4.SS2.p3.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.p3.1.1">Data availability in taxonomy design.</span>
Similar to when designing taxonomies, participants had to balance their ideal data collection methods with practical constraints. For example, P3’s dataset only included Spanish and Arabic even though they <span class="ltx_text ltx_font_italic" id="S4.SS2.p3.1.2">“wanted to look at other languages, but … didn’t have training data.”</span>
Participants questioned prevailing data collection paradigms, such as web scraping <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib3" title="">3</a>]</cite>, which were seen as unethical when performed indiscriminately. For legal compliance, P25 manually collected data for two years: <em class="ltx_emph ltx_font_italic" id="S4.SS2.p3.1.3">“I was downloading, like clicking and clicking, because they didn’t allow me to do web scraping or didn’t have an API.</em>”</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Implementation</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">The <em class="ltx_emph ltx_font_italic" id="S4.SS3.p1.1.1">implementation phase</em> marks the execution of plans formulated in the design phase, where curators collect, annotate, and package the data into a dataset. This phase broadly encompasses two subphases: data collection and data annotation.</p>
</div>
<section class="ltx_subsubsection" id="S4.SS3.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.1 </span>Data Collection</h4>
<div class="ltx_para" id="S4.SS3.SSS1.p1">
<p class="ltx_p" id="S4.SS3.SSS1.p1.1"><em class="ltx_emph ltx_font_italic" id="S4.SS3.SSS1.p1.1.1">Data collection</em> involves gathering relevant data to fulfill dataset requirements. Challenges during this subphase prevented participants from attaining fairness goals relevant to dataset diversity.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS3.SSS1.p2">
<p class="ltx_p" id="S4.SS3.SSS1.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS3.SSS1.p2.1.1">Diverse data availability.</span> Similar to concerns raised regarding dataset taxonomies (<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#S4.SS2" title="4.2 Design ‣ 4 Challenges During the Dataset Lifecycle ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">4.2</span></a>), participants raised concerns about data availability for creating a fair dataset. For example, P28 described how sexist stereotypes permeate web data, such as <em class="ltx_emph ltx_font_italic" id="S4.SS3.SSS1.p2.1.2">“women [being] associated with nurse more often than men.”</em> Additionally, P18 encountered difficulties sourcing web data from <em class="ltx_emph ltx_font_italic" id="S4.SS3.SSS1.p2.1.3">“Middle Eastern”</em> and “<em class="ltx_emph ltx_font_italic" id="S4.SS3.SSS1.p2.1.4">African countries”</em> but found “<em class="ltx_emph ltx_font_italic" id="S4.SS3.SSS1.p2.1.5">lots and lots and lots of images from India, Japan and [the] U.S., which are like the three most dominant geographies in uploading pictures.</em>” Participants also lamented the inaccessibility of specialized or proprietary data, such as medical records or data from private companies, which could significantly improve the creation of fair datasets. P4 stated that <em class="ltx_emph ltx_font_italic" id="S4.SS3.SSS1.p2.1.6">“because people don’t own large e-commerce platforms or social media platforms, or whatever, we just kind of have to deal with things that we can gather from existing systems.”</em></p>
</div>
<div class="ltx_para" id="S4.SS3.SSS1.p3">
<p class="ltx_p" id="S4.SS3.SSS1.p3.1">Interestingly, synthetic data, sometimes presented as a potential solution to biased data <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib6" title="">6</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib136" title="">136</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib116" title="">116</a>]</cite>, was met with skepticism as it could perpetuate stereotypes or inadequately represent underrepresented groups <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib151" title="">151</a>]</cite>. As P19 pointed out, <em class="ltx_emph ltx_font_italic" id="S4.SS3.SSS1.p3.1.1">“You might address some of the missing data points [with synthetic data] but at the end of the day it’s still the same underlying data distribution, right?”</em></p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS3.SSS1.p4">
<p class="ltx_p" id="S4.SS3.SSS1.p4.1"><span class="ltx_text ltx_font_bold" id="S4.SS3.SSS1.p4.1.1">Data collector availability.</span> Many participants associated fairness with geographically diverse data. For example, P22 expressed how they would <em class="ltx_emph ltx_font_italic" id="S4.SS3.SSS1.p4.1.2">“proactively sample more data from underrepresented regions.”</em> Yet, actualizing this objective proved challenging, as P12 highlighted the difficulty in <em class="ltx_emph ltx_font_italic" id="S4.SS3.SSS1.p4.1.3">“get[ting] hold of people … from very, very small regions.”</em> Infrastructure hurdles, such as limited internet and mobile phone access, further complicated the process <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib78" title="">78</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib3" title="">3</a>]</cite>. Equipping data collectors with necessary equipment is costly (<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#S5.SS3" title="5.3 Organization Level ‣ 5 Challenges Overarching the Broader Landscape of Fairness ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">5.3</span></a>) and logistically challenging, as <em class="ltx_emph ltx_font_italic" id="S4.SS3.SSS1.p4.1.4">“you might have to give people smartphones to start and you’d also need more labor on the ground … who are working in these different regions to come together and do this”</em> (P12).</p>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS3.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.2 </span>Data Annotation</h4>
<div class="ltx_para" id="S4.SS3.SSS2.p1">
<p class="ltx_p" id="S4.SS3.SSS2.p1.1"><em class="ltx_emph ltx_font_italic" id="S4.SS3.SSS2.p1.1.1">Data annotation</em> involves labeling data with attributes specified during design. Participants faced challenges recruiting annotators who had requisite expertise or came from diverse backgrounds. Upholding fair labor practices (<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#S4.SS3.SSS3" title="4.3.3 Implementation Processes ‣ 4.3 Implementation ‣ 4 Challenges During the Dataset Lifecycle ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">4.3.3</span></a>) during annotation also presented challenges.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS3.SSS2.p2">
<p class="ltx_p" id="S4.SS3.SSS2.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS3.SSS2.p2.1.1">Data annotator diversity and expertise.</span>
The interpretation and application of annotation categories can vary based on an annotator’s perspective <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib7" title="">7</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib23" title="">23</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib79" title="">79</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib2" title="">2</a>]</cite>. P22 described finding annotators for labelling building styles across different geographies: <em class="ltx_emph ltx_font_italic" id="S4.SS3.SSS2.p2.1.2">“You give this same image to a local labeler who is in that culture, who is an expert in, you know, their architecture … then you get a much better label.”</em> Yet, participants had difficulty hiring annotators that met their desired aims. While P2 highlighted the value of diverse annotator backgrounds or beliefs to ensure annotations reflected a wide range of experiences, accessing diverse annotators was challenging, <em class="ltx_emph ltx_font_italic" id="S4.SS3.SSS2.p2.1.3">“because some of the attributes of [annotators’] personal lives might even be illegal to ask about in a particular country.”</em> Participants also confronted challenges in recruiting annotators with specialized expertise. For example, despite offering “<em class="ltx_emph ltx_font_italic" id="S4.SS3.SSS2.p2.1.4">$75 or $100 per hour,</em>” P1 faced difficulties finding and incentivizing medical experts to annotate radiology data. Annotators who lack diversity or expertise in data concepts may lead to issues with data quality, including inaccuracies <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib74" title="">74</a>]</cite>, biases <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib122" title="">122</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib42" title="">42</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib46" title="">46</a>]</cite>, and overly homogeneous annotations <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib112" title="">112</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib46" title="">46</a>]</cite>. Notably, P13 highlighted that crowdsourced annotators regularly embed gender biases into datasets such that <em class="ltx_emph ltx_font_italic" id="S4.SS3.SSS2.p2.1.5">“researchers [need] to make sure that annotators represent everyone because [if] not, you’re just gonna have a skewed pool of annotations as well.”</em></p>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS3.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.3 </span>Implementation Processes</h4>
<div class="ltx_para" id="S4.SS3.SSS3.p1">
<p class="ltx_p" id="S4.SS3.SSS3.p1.1">Participants expressed challenges not only with dataset content but also with the <em class="ltx_emph ltx_font_italic" id="S4.SS3.SSS3.p1.1.1">implementation</em> of data collection and annotation. We provide three main considerations discussed by participants.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS3.SSS3.p2">
<p class="ltx_p" id="S4.SS3.SSS3.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS3.SSS3.p2.1.1">Vendor transparency.</span> Collaborating with data vendors introduced transparency challenges, hindering fairness efforts. First, as prior research documented <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib123" title="">123</a>]</cite>, vendors may prohibit access to data worker identities, such as demographic details or location (as described by P2 in <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#S4.SS3.SSS2" title="4.3.2 Data Annotation ‣ 4.3 Implementation ‣ 4 Challenges During the Dataset Lifecycle ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">4.3.2</span></a>). Thus, it is impossible to evaluate potential biases or expertise linked to identity characteristics, such as how an annotator’s cultural identity may influence their engagement with data concepts. Second, participants had little oversight into worker compensation or encountered communication restrictions imposed by vendors. As P12 said, <em class="ltx_emph ltx_font_italic" id="S4.SS3.SSS3.p2.1.2">“I think [pay] was fair in terms of [being] calibrated across different countries … but we weren’t able to get exact numbers, because that was confidential.”</em> P6 described how vendor platform design inhibited direct collection of feedback from data workers, impeding efforts to improve fairness in dataset creation and labor conditions (e.g., <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib99" title="">99</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib98" title="">98</a>]</cite>) (<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#S5.SS5" title="5.5 Socio-Political Level ‣ 5 Challenges Overarching the Broader Landscape of Fairness ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">5.5</span></a>).</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS3.SSS3.p3">
<p class="ltx_p" id="S4.SS3.SSS3.p3.1"><span class="ltx_text ltx_font_bold" id="S4.SS3.SSS3.p3.1.1">Language barriers.</span> Curating fair datasets often involves collecting geographically diverse data, which may require data workers proficient in languages different from those of curators. Language barriers can hinder effective communication, necessitating fairness concepts established in the design phase (<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#S4.SS2" title="4.2 Design ‣ 4 Challenges During the Dataset Lifecycle ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">4.2</span></a>) to be accurately translated into the workers’ native languages. Improper translations can result in misinterpreted labels or instructions and may even lead to contract breaches, particularly concerning subject consent. Addressing language barriers often involves resorting to translation services, which may be constrained by cost (<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#S5.SS3" title="5.3 Organization Level ‣ 5 Challenges Overarching the Broader Landscape of Fairness ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">5.3</span></a>) or introduce its own fairness concerns. Further, participants had to ensure translations accurately reflected their intentions, but as P3 noted, <em class="ltx_emph ltx_font_italic" id="S4.SS3.SSS3.p3.1.2">“We relied on our translators to come up with those sorts of decisions in terms of Spanish.”</em></p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS3.SSS3.p4">
<p class="ltx_p" id="S4.SS3.SSS3.p4.1"><span class="ltx_text ltx_font_bold" id="S4.SS3.SSS3.p4.1.1">Fair data labor.</span> Several participants (P6, P11, P12, P14, P16, P24, P28) expressed concern about engaging in fair labor practices when working with data workers, but systemic organizational (<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#S5.SS3" title="5.3 Organization Level ‣ 5 Challenges Overarching the Broader Landscape of Fairness ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">5.3</span></a>) and regulatory (<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#S5.SS4" title="5.4 Regulatory Level ‣ 5 Challenges Overarching the Broader Landscape of Fairness ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">5.4</span></a>) issues made achieving these standards difficult.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S4.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Evaluation</h3>
<div class="ltx_para" id="S4.SS4.p1">
<p class="ltx_p" id="S4.SS4.p1.1">The <em class="ltx_emph ltx_font_italic" id="S4.SS4.p1.1.1">evaluation phase</em> involves assessing data quality and testing dataset utility. Challenges here can lead to homogeneous annotations, difficulties in benchmarking, and spurious correlations.</p>
</div>
<section class="ltx_subsubsection" id="S4.SS4.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.4.1 </span>Assessing Data Quality</h4>
<div class="ltx_para" id="S4.SS4.SSS1.p1">
<p class="ltx_p" id="S4.SS4.SSS1.p1.1"><em class="ltx_emph ltx_font_italic" id="S4.SS4.SSS1.p1.1.1">Assessing data quality</em> entails validating and refining the data and its annotations to ensure clarity and consistency with project requirements. (Re)alignment of data and annotations with the guidelines from the design phase is often referred to as <em class="ltx_emph ltx_font_italic" id="S4.SS4.SSS1.p1.1.2">quality assurance</em>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS4.SSS1.p2">
<p class="ltx_p" id="S4.SS4.SSS1.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS4.SSS1.p2.1.1">Gold standard paradigms.</span> Participants often sought to capture a diversity of perspectives across annotators. Thus, prevailing practices for validation and cleaning, such as majority voting and annotator agreement metrics, may be unsuitable. As P24 emphasized, majority voting can “<span class="ltx_text ltx_font_italic" id="S4.SS4.SSS1.p2.1.2">squash or stifle diverse opinions when it comes to subjective tasks</span>.” When disagreement is integral to the objective, annotator agreement metrics become inappropriate, making it difficult to “validate” annotation quality. Gold standard paradigms are intrinsically tied to disciplinary challenges (<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#S5.SS2" title="5.2 Discipline Level ‣ 5 Challenges Overarching the Broader Landscape of Fairness ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">5.2</span></a>); if submitting a publication involving dataset creation, reviewers might still call for annotator agreement metrics and believe the quality of the data is poor if agreement is low.</p>
</div>
<div class="ltx_para" id="S4.SS4.SSS1.p3">
<p class="ltx_p" id="S4.SS4.SSS1.p3.1">Similarly, common practices used to clean or filter data can perpetuate dominant cultural beliefs. Data that might appear noisy or incorrect can hold significance for certain communities. P14 explained how quality filters resulted in “<span class="ltx_text ltx_font_italic" id="S4.SS4.SSS1.p3.1.1">get[ting] rid of vernacular that’s not perfect English but is maybe like African-American vernacular or like Hispanic-American vernacular, and that also introduces bias and lowers the diversity of the dataset.</span>” This echoes prior work <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib9" title="">9</a>]</cite> which found that standard data filters might disproportionately exclude content from already marginalized groups.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS4.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.4.2 </span>Evaluating Data Utility</h4>
<div class="ltx_para" id="S4.SS4.SSS2.p1">
<p class="ltx_p" id="S4.SS4.SSS2.p1.1">To ensure dataset utility, curators must evaluate its effectiveness, often through <em class="ltx_emph ltx_font_italic" id="S4.SS4.SSS2.p1.1.1">requirements testing</em> to confirm its suitability for the intended purpose. Participants aimed to align the dataset with fairness definitions and mitigate any potential biases present in the data.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS4.SSS2.p2">
<p class="ltx_p" id="S4.SS4.SSS2.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS4.SSS2.p2.1.1">Lack of benchmarking datasets.</span>
Curators often seek to benchmark their datasets to showcase their utility. However, since many participants aimed to create unprecedented fair datasets to address existing gaps, this norm posed a challenge as comparable datasets were non-existent. Reflecting on the struggles with a novel geodiverse dataset, P12 explained, “<span class="ltx_text ltx_font_italic" id="S4.SS4.SSS2.p2.1.2">We couldn’t measure it unless we had a dataset that actually was fair. Since we don’t have a dataset that is fair…, you are arguing in circles.</span>” Furthermore, even if comparable datasets exist, they may harbor fairness issues of their own.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS4.SSS2.p3">
<p class="ltx_p" id="S4.SS4.SSS2.p3.1"><span class="ltx_text ltx_font_bold" id="S4.SS4.SSS2.p3.1.1">Evaluating immeasurable constructs.</span>
Evaluating whether a dataset aligns with fairness definitions presupposes that fairness is a construct amenable to measurement. While some participants offered quantifiable indicators of fairness, such as demographic diversity, others argued that fairness defies quantification. P14 criticized measurement-oriented perspectives, stating, “<span class="ltx_text ltx_font_italic" id="S4.SS4.SSS2.p3.1.2">They also assume that fairness can be measured, can be evaluated, and can be improved. And I think that all of this is a more positivist mindset.</span>” Even with a definition in mind, testing may feel incomplete. As P28 said, “<span class="ltx_text ltx_font_italic" id="S4.SS4.SSS2.p3.1.3">Even when you provide a way to measure fairness, you’re probably overlooking something.</span>”</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS4.SSS2.p4">
<p class="ltx_p" id="S4.SS4.SSS2.p4.1"><span class="ltx_text ltx_font_bold" id="S4.SS4.SSS2.p4.1.1">Spurious correlations.</span>
Several participants (P6, P23, P28) aimed to avoid introducing spurious correlations that affected the fairness of the dataset’s composition <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib80" title="">80</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib51" title="">51</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib22" title="">22</a>]</cite>. While these correlations may not be “<span class="ltx_text ltx_font_italic" id="S4.SS4.SSS2.p4.1.2">connected with any demographic or social variable</span>” (P23), they can still influence downstream models and result in biased decisions. However, as recent research <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib97" title="">97</a>]</cite> has revealed, spurious correlations with demographic attributes are ubiquitous. Thus, enumerating and removing all possible correlations is virtually impossible.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S4.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.5 </span>Maintenance</h3>
<div class="ltx_para" id="S4.SS5.p1">
<p class="ltx_p" id="S4.SS5.p1.1">In the <em class="ltx_emph ltx_font_italic" id="S4.SS5.p1.1.1">maintenance phase</em>, curators must consider both how their dataset is released and strategies for ensuring its ongoing utility over time. Challenges at this stage often linked back to participant concerns around fairness in dataset release (i.e., ensuring the data is transparent and openly accessible).</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS5.p2">
<p class="ltx_p" id="S4.SS5.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS5.p2.1.1">Unstable infrastructural ecosystems.</span> Digital data is intrinsically impermanent. Some participants (P1, P8, P30) emphasized the risk of data instances disappearing due to broken links or shifts in platform popularity or ownership, as observed with platforms like Twitter. Therefore, curators must then not only monitor for missing data but also find suitable replacements that match the original dataset’s distribution. This can be particularly burdensome when the data was expensive (<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#S5.SS3" title="5.3 Organization Level ‣ 5 Challenges Overarching the Broader Landscape of Fairness ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">5.3</span></a>) or difficult to collect (<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#S4.SS3.SSS1" title="4.3.1 Data Collection ‣ 4.3 Implementation ‣ 4 Challenges During the Dataset Lifecycle ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">4.3.1</span></a>). As data goes missing, datasets can become unbalanced and thus “unfair,” demonstrating how fairness issues with data release are linked to concerns about composition.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS5.p3">
<p class="ltx_p" id="S4.SS5.p3.1"><span class="ltx_text ltx_font_bold" id="S4.SS5.p3.1.1">Dataset traceability mechanisms.</span>
The challenge of dataset stewardship is exacerbated by inadequate traceability mechanisms <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib127" title="">127</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib109" title="">109</a>]</cite>. Participants underscored their inability to track users and usage patterns of their datasets. One commonly used proxy is citations in academic papers, but it was hard to <span class="ltx_text ltx_font_italic" id="S4.SS5.p3.1.2">“distinguish citations that use the data versus citations that use the broader idea of the paper</span>” (P2). This is concerning, especially if fair datasets are repurposed in unintended ways. While prior works <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib3" title="">3</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib109" title="">109</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib127" title="">127</a>]</cite> have suggested data usage policies to mitigate such risks, enforcing them becomes impractical when curators are unaware of actual data users.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Challenges Overarching the Broader Landscape of Fairness</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">Many challenges that were surfaced cut across all phases of the lifecycle, impacting the broader <em class="ltx_emph ltx_font_italic" id="S5.p1.1.1">landscape</em> of dataset fairness. We identified five levels within this broader landscape. Challenges may arise from one or more levels of this landscape to impact dataset curation at every phase of the dataset lifecycle (see <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#S5.F2" title="In 5 Challenges Overarching the Broader Landscape of Fairness ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">2</span></a>). Refer to <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#A2" title="Appendix B Additional Figures and Tables ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_tag">Appendix</span> <span class="ltx_text ltx_ref_tag">B</span></a> for additional examples.</p>
</div>
<figure class="ltx_figure" id="S5.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="299" id="S5.F2.g1" src="extracted/5656716/Input/Overarching.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>A social ecological <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib19" title="">19</a>]</cite> representation of challenges in each layer in the overarching landscape of fairness. A social ecological model shows how each layer is nested but interconnected.</figcaption>
</figure>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Individual Level</h3>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">The <em class="ltx_emph ltx_font_italic" id="S5.SS1.p1.1.1">individual level</em> of the dataset curation landscape refers to the contributors of fair datasets, such as data curators, data subjects, and data workers.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS1.p2">
<p class="ltx_p" id="S5.SS1.p2.1"><span class="ltx_text ltx_font_bold" id="S5.SS1.p2.1.1">Individual contributor positionality.</span> Decisions made by contributors were inevitably influenced by their own unique perspectives <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib121" title="">121</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib124" title="">124</a>]</cite>. As P24 said, <em class="ltx_emph ltx_font_italic" id="S5.SS1.p2.1.2">“There’s this stuff we swim in that we don’t really realize is even there.”</em> Despite recognizing this influence, assessing its tangible impact on the dataset remained elusive. Addressing and diversifying contributor positionality is further complicated by other challenges within the dataset curation landscape, such as cost and power differentials. Positionality was evident in instances where participants felt they had to make trade-offs during processes like designing taxonomies that may erase others’ experiences. P27 encouraged reflecting on personal values: “<span class="ltx_text ltx_font_italic" id="S5.SS1.p2.1.3">Is this [research] actually in line with your life philosophy? Was it in line with your gender, with your sexuality… If it’s not, would you still want to be doing this?</span>”</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Discipline Level</h3>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">The <em class="ltx_emph ltx_font_italic" id="S5.SS2.p1.1.1">discipline level</em> of the dataset curation landscape centers on the norms and practices governing specific academic disciplines, particularly ML <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib13" title="">13</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib43" title="">43</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib115" title="">115</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib126" title="">126</a>]</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS2.p2">
<p class="ltx_p" id="S5.SS2.p2.1"><span class="ltx_text ltx_font_bold" id="S5.SS2.p2.1.1">Recognition for fair dataset work.</span> Despite the growing demand for data in ML, according to participants, fair dataset curation efforts were not seen as significant contributions to the field. P11 described a <em class="ltx_emph ltx_font_italic" id="S5.SS2.p2.1.2">“lack of general disciplinary value of datasets as contributions.”</em> While some major conferences like NeurIPS <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib143" title="">143</a>]</cite> have introduced dataset tracks, few venues prioritize dataset-focused work. This lack of appreciation discourages efforts to ensure dataset stability and longevity <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib126" title="">126</a>]</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS2.p3">
<p class="ltx_p" id="S5.SS2.p3.1"><span class="ltx_text ltx_font_bold" id="S5.SS2.p3.1.1">Incentive mechanisms.</span> Incentives in ML do not align well with the costs of fair dataset curation. According to P11, there’s <em class="ltx_emph ltx_font_italic" id="S5.SS2.p3.1.2">“just [a] total lack of resources and time to actually deeply engage with labeling and sourcing those labels and getting people who are representative of those labels to be the data workers.”</em> Participants echoed well-documented observations that model work is valued over data work <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib120" title="">120</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib126" title="">126</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib119" title="">119</a>]</cite>, with P21 stating that <em class="ltx_emph ltx_font_italic" id="S5.SS2.p3.1.3">“data is kind of a second-class citizen in ML research.”</em> Consequently, P25 felt <em class="ltx_emph ltx_font_italic" id="S5.SS2.p3.1.4">“people are [not] seriously talking about fairness … people are still just get[ting] whatever [data] they get to do their research, or publish, or whatever.”</em></p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS2.p4">
<p class="ltx_p" id="S5.SS2.p4.1"><span class="ltx_text ltx_font_bold" id="S5.SS2.p4.1.1">Awareness of existing resources and guidelines.</span> Participants had limited awareness of existing guidance for fair dataset curation. This lack of awareness may be attributed to some of these resources (e.g., <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib40" title="">40</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib78" title="">78</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib76" title="">76</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib114" title="">114</a>]</cite>) being disseminated outside of traditional ML venues (e.g., NeurIPS, *CL, ICML, CVPR). As P29 admitted, <em class="ltx_emph ltx_font_italic" id="S5.SS2.p4.1.2">“I don’t remember any explicit guidelines that I’ve stumbled through for fair dataset collection. Honestly!”</em> Promoting interdisciplinary awareness of fairness efforts among those primarily involved in ML is challenging due to highly disciplinary norms that prioritize novelty in ML methods over discussions on fair dataset curation.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS2.p5">
<p class="ltx_p" id="S5.SS2.p5.1"><span class="ltx_text ltx_font_bold" id="S5.SS2.p5.1.1">Responsibility for fairness.</span> The burden of responsibility for fairness weighs most heavily on individuals aware of fairness concerns in ML. Participants echoed findings from prior research <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib13" title="">13</a>]</cite> that document how fairness is not a top priority for many ML researchers. For example, P25 said that “<span class="ltx_text ltx_font_italic" id="S5.SS2.p5.1.2">[in] the team I work with… I never heard them talking about [how] the dataset has to be fair.</span>” In P25’s experience, the norm was to cursorily engage with fairness issues without substantive changes to research practices.
Given the lower prioritization of fairness in ML, the onus falls on individual researchers who “<span class="ltx_text ltx_font_italic" id="S5.SS2.p5.1.3">have a strong sense of justice and fairness</span>” (P24) or are part of fairness-oriented communities to elevate these concerns. However, this commitment often lacks external recognition and may hinder resource allocation and research progress. Participants recognized that collecting fair data is more challenging and resource-intensive compared to conventional methods: “<span class="ltx_text ltx_font_italic" id="S5.SS2.p5.1.4">If you want to build a fair dataset, maybe the most efficient way to do that is to scrape the web, but getting really diverse data in an ethical way is really hard and really expensive</span>” (P11).</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Organization Level</h3>
<div class="ltx_para" id="S5.SS3.p1">
<p class="ltx_p" id="S5.SS3.p1.1">The <em class="ltx_emph ltx_font_italic" id="S5.SS3.p1.1.1">organization level</em> refers to the organizations where individuals conduct fair dataset curation work, which could vary in size or nature, such as academic or industry settings.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS3.p2">
<p class="ltx_p" id="S5.SS3.p2.1"><span class="ltx_text ltx_font_bold" id="S5.SS3.p2.1.1">Lack of resources.</span> Insufficient resources were a significant challenge across all phases of the dataset lifecycle. As P1 declared: ‘<em class="ltx_emph ltx_font_italic" id="S5.SS3.p2.1.2">‘Money?! (laughs) If you have money, you can have a very high quality of data.”</em> Fair data collection methods are costly, especially concerning data quality and annotation, which often require hiring experts. Convincing funders or stakeholders of the value of investing in fair datasets proved difficult, as noted by P24: <em class="ltx_emph ltx_font_italic" id="S5.SS3.p2.1.3">“It’s hard to convince somebody to spend thousands and thousands to collect [a] dataset of recordings.”</em> Moreover, participants aimed to compensate data subjects and workers fairly, <em class="ltx_emph ltx_font_italic" id="S5.SS3.p2.1.4">“not just the minimum wages that many times academia gives”</em> (P29). Longterm maintenance costs added to the financial burden, with difficulties in securing ongoing funding. P1 stated no academic or industry organization <em class="ltx_emph ltx_font_italic" id="S5.SS3.p2.1.5">“[wants] to spend another millions of money every year … to maintain those products.”</em></p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS3.p3">
<p class="ltx_p" id="S5.SS3.p3.1"><span class="ltx_text ltx_font_bold" id="S5.SS3.p3.1.1">Ethics washing.</span> Participants disapproved of organizations that superficially promote fair ML but fail to meaningfully integrate fairness into their practices <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib146" title="">146</a>]</cite>. According to P16, the <em class="ltx_emph ltx_font_italic" id="S5.SS3.p3.1.2">“language of fairness is simply external lip service [that] ultimately boils down to looking at the maximization of other imperatives, such as economic ones.”</em> Resource constraints exacerbate this issue, leading organizations to prioritize efficiency and cost-effectiveness over fairness. As P22 noted, <em class="ltx_emph ltx_font_italic" id="S5.SS3.p3.1.3">“A lot of big companies do responsible AI shenanigans … for marketing … And then a new shiny thing comes down the road, and then they join that instead.”</em> When fairness is valued primarily for its marketing appeal rather than its impact on product development, it is not prioritized for monetary or labor investment.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4 </span>Regulatory Level</h3>
<div class="ltx_para" id="S5.SS4.p1">
<p class="ltx_p" id="S5.SS4.p1.1">The <em class="ltx_emph ltx_font_italic" id="S5.SS4.p1.1.1">regulatory level</em> concerns laws and policies governing dataset curation and use. Participants expressed anxieties about violating regulations they were not necessarily equipped to fully understand.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS4.p2">
<p class="ltx_p" id="S5.SS4.p2.1"><span class="ltx_text ltx_font_bold" id="S5.SS4.p2.1.1">Differing legal practices.</span> Contextual laws and regulations posed a challenge for participants. P2 described how <em class="ltx_emph ltx_font_italic" id="S5.SS4.p2.1.2">“laws in America or laws in Europe … might not be directly applicable to a [South Asian] country that has a very different societal situation.”</em> Contextually contingent laws and policies further complicated efforts to obtain data from diverse, underrepresented populations (<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#S4.SS3.SSS1" title="4.3.1 Data Collection ‣ 4.3 Implementation ‣ 4 Challenges During the Dataset Lifecycle ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">4.3.1</span></a>).</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS4.p3">
<p class="ltx_p" id="S5.SS4.p3.1"><span class="ltx_text ltx_font_bold" id="S5.SS4.p3.1.1">Legal risk.</span> Throughout the dataset lifecycle, participants faced the looming risk of unintentionally violating laws and regulations, potentially leading to breaches of privacy, labor, or data ownership laws. Instances of inadvertent violations are not uncommon, as highlighted by participants’ experiences with web scraping practices. For example, P21 was aware that <em class="ltx_emph ltx_font_italic" id="S5.SS4.p3.1.2">“people discovered links to child pornography”</em> in a widely used benchmark dataset <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib15" title="">15</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib138" title="">138</a>]</cite>. In another instance, P5 described working on a clinical dataset only to learn that releasing it was <em class="ltx_emph ltx_font_italic" id="S5.SS4.p3.1.3">“not possible because it’s not consistent with the privacy laws in France.”</em> To mitigate these risks, some participants adopted highly cautious practices, such as exclusively collecting royalty-free or Creative Commons images, and storing only image URLs to avoid any copyright violations. However, these strategies can result in dataset instability, as observed by P8, who faced issues with broken URLs.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS4.p4">
<p class="ltx_p" id="S5.SS4.p4.1"><span class="ltx_text ltx_font_bold" id="S5.SS4.p4.1.1">Limited regulatory literacy.</span> Insufficient understanding about navigating the law intensified concerns about legal risk. P8 described it as <em class="ltx_emph ltx_font_italic" id="S5.SS4.p4.1.2">“a big learning curve to understand what we were allowed to store and what we weren’t.”</em> As a result, P8 consulted an intellectual property lawyer. However, depending on the other constraints dataset curators are under, such as discipline (<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#S5.SS2" title="5.2 Discipline Level ‣ 5 Challenges Overarching the Broader Landscape of Fairness ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">5.2</span></a>) or organization (<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#S5.SS3" title="5.3 Organization Level ‣ 5 Challenges Overarching the Broader Landscape of Fairness ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">5.3</span></a>) level constraints, hiring legal counsel may be untenable.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.5 </span>Socio-Political Level</h3>
<div class="ltx_para" id="S5.SS5.p1">
<p class="ltx_p" id="S5.SS5.p1.1">The <em class="ltx_emph ltx_font_italic" id="S5.SS5.p1.1.1">socio-political level</em> covers the shifting social and political contexts around fairness in which curators operate. These challenges can be conceptualized as thorny, fluid, and arguably insoluble.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS5.p2">
<p class="ltx_p" id="S5.SS5.p2.1"><span class="ltx_text ltx_font_bold" id="S5.SS5.p2.1.1">Evolution and contestability of fairness.</span> According to P3, fairness will <em class="ltx_emph ltx_font_italic" id="S5.SS5.p2.1.2">“always be up for debate,”</em> making it <em class="ltx_emph ltx_font_italic" id="S5.SS5.p2.1.3">“sort of impossible for there to be like a gold standard.”</em> Fairness is subjectively perceived, influenced by individual contexts, experiences, and beliefs <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib124" title="">124</a>]</cite>. This subjectivity fuels ongoing scholarly debates <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib40" title="">40</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib87" title="">87</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib132" title="">132</a>]</cite>; it also fueled diverse perspectives among participants. As P30 pointed out, <em class="ltx_emph ltx_font_italic" id="S5.SS5.p2.1.4">“There are people from the audience who say that we have a good definition [of fairness], and there are some people who say that we have a terrible definition. And there’s no way to make everyone happy.”</em> The absence of a universally accepted definition complicated participants’ efforts to operationalize fairness in dataset curation. Further, existing guidelines may not suit every notion of fairness, leading to divergent curation methodologies. As P14 highlighted, <em class="ltx_emph ltx_font_italic" id="S5.SS5.p2.1.5">“It’s kind of like a philosophical question … while the quantitative method says that fairness can be achieved, contrast it to qualitative that we are just trying to understand the experience here.”</em> Beyond disagreements about what fairness means (or should mean), participants also noted that current definitions are not stable. As P16 put it, fairness <em class="ltx_emph ltx_font_italic" id="S5.SS5.p2.1.6">“should be a notion that is able to evolve within society, and certain forms of injustice that were not considered injustice[s] in the past now are … there might be other evolution towards the future that we currently do not incorporate in our definition of fairness, and we need to account for that.”</em> This perpetual evolution presents challenges for dataset curators. They must decide whether to regularly update datasets or retract them as definitions evolve. However, both approaches have limitations in addressing the continued use of previously released datasets <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib109" title="">109</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib90" title="">90</a>]</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS5.p3">
<p class="ltx_p" id="S5.SS5.p3.1"><span class="ltx_text ltx_font_bold" id="S5.SS5.p3.1.1">Social realities versus model realities.</span> P8 described how the real world is different than “<em class="ltx_emph ltx_font_italic" id="S5.SS5.p3.1.2">what’s experimentally valid and testable.</em>” Due to the complexity of the real world, certain groups inevitably remain underrepresented, misrepresented, or overlooked entirely despite best efforts. For example, P12 mentioned that while they wanted to collect images from underrepresented countries, data collector availability constrained their options (<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#S4.SS3.SSS1" title="4.3.1 Data Collection ‣ 4.3 Implementation ‣ 4 Challenges During the Dataset Lifecycle ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_tag">section</span> <span class="ltx_text ltx_ref_tag">4.3.1</span></a>). Participants also questioned whether balanced representation was even the best approach. As P1 pointed out, <em class="ltx_emph ltx_font_italic" id="S5.SS5.p3.1.3">“The problem is when you actually apply such a model to the real world, the real world is imbalanced, right?”</em> This echoes the classic trade-off between fairness and accuracy in algorithmic fairness work <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib29" title="">29</a>]</cite>. Curators must wrestle not only with the impossible task of how to best account for every human experience in a dataset, but also whether or not they should be.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS5.p4">
<p class="ltx_p" id="S5.SS5.p4.1"><span class="ltx_text ltx_font_bold" id="S5.SS5.p4.1.1">Power differentials.</span> Power imbalances contribute to fairness issues during the curation process that are not visible in the dataset’s composition. Participants noted how more elite institutions and companies dominate efforts to create fair datasets, largely owing to their access to resources (<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#S5.SS3" title="5.3 Organization Level ‣ 5 Challenges Overarching the Broader Landscape of Fairness ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">5.3</span></a>). Similar to findings from prior work <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib83" title="">83</a>]</cite>, P21 described how most public datasets are not used, with the majority of <em class="ltx_emph ltx_font_italic" id="S5.SS5.p4.1.2">“the datasets that get used in ML research [being] created by a very, very small elite cadre of … academic institutions that have close affiliations with top industry researchers.”</em> Similarly, P16 felt it was problematic that the <em class="ltx_emph ltx_font_italic" id="S5.SS5.p4.1.3">“most important tools”</em> remain in the hands of a few companies, <em class="ltx_emph ltx_font_italic" id="S5.SS5.p4.1.4">“yet they are given the freedom to define what is fair, and their definition is used, and then the safeguards that do exist might not always align or ensure protection.”</em>. Thinking on a geopolitical scale, P2 noted that <em class="ltx_emph ltx_font_italic" id="S5.SS5.p4.1.5">“the field of algorithmic fairness has been dominated by the Western perspective.”</em> This imbalanced representation exacerbates other challenges previously outlined, including those at the implementation, disciplinary, and organizational levels.</p>
</div>
<div class="ltx_para" id="S5.SS5.p5">
<p class="ltx_p" id="S5.SS5.p5.1">Power differentials also permeate the relationship between dataset curators and other stakeholders, such as between curators and data subjects or workers <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib147" title="">147</a>]</cite>. For example, P6 described how curators have complete oversight over worker compensation: <em class="ltx_emph ltx_font_italic" id="S5.SS5.p5.1.1">“So many platforms don’t actually ensure that you’re fairly compensating workers. And it’s really up to the individual researchers which is a crazy system that sets absolutely the wrong incentives.”</em> P10 compared the impulse to collect data cost-effectively, at the expense of data subjects, as <em class="ltx_emph ltx_font_italic" id="S5.SS5.p5.1.2">“a particular kind of colonial impulse, like, this is just up for grabs.”</em> Similarly, curator decisions have profound implications downstream. P22 described the difficulty of <em class="ltx_emph ltx_font_italic" id="S5.SS5.p5.1.3">“fighting”</em> clients who do not prioritize model performance on heavily under-resourced populations, given they are not central to business incentives: <em class="ltx_emph ltx_font_italic" id="S5.SS5.p5.1.4">“It’s like, ‘99% of my customer[s] will be fine, why do I need to care about that last 1%?”</em> Overall, dataset curation was seen as <em class="ltx_emph ltx_font_italic" id="S5.SS5.p5.1.5">“a very unfair process, no matter how you do it … unless you’re going to literally tackle society”</em> (P8).</p>
</div>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Considerations for Enabling Fair Dataset Curation</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">Finally, we highlight recommendations across the three dimensions of fairness for facilitating fair dataset curation. We focus on top-down efforts, reflecting the need for systemic changes rather than relying solely on individual contributions. See <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#A3" title="Appendix C Detailed Recommendations for Enabling Fair Dataset Curation ‣ Appendix B Additional Figures and Tables ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_tag">Appendix</span> <span class="ltx_text ltx_ref_tag">C</span></a> for more details.</p>
</div>
<div class="ltx_para ltx_noindent" id="S6.p2">
<p class="ltx_p" id="S6.p2.1"><span class="ltx_text ltx_font_bold" id="S6.p2.1.1">Composition.</span> To better enable fair dataset <em class="ltx_emph ltx_font_italic" id="S6.p2.1.2">composition</em>, we encourage interventions for more flexible and robust data practices. For example, at the design phase (<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#S4.SS2" title="4.2 Design ‣ 4 Challenges During the Dataset Lifecycle ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">4.2</span></a>), flexible taxonomies can facilitate different operationalizations rather than forcing curators to use only one taxonomy (e.g., protected attributes can include self-reported and third-party labels). At the discipline level (<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#S5.SS2" title="5.2 Discipline Level ‣ 5 Challenges Overarching the Broader Landscape of Fairness ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">5.2</span></a>), we advocate for more communication across academic communities. Papers published outside traditional ML venues (e.g., CHI, FAccT, CSCW) have provided guidance on data curation, such as annotation practices <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib81" title="">81</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib40" title="">40</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib150" title="">150</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib28" title="">28</a>]</cite> or considerations on taxonomies <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib7" title="">7</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib82" title="">82</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib62" title="">62</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib155" title="">155</a>]</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S6.p3">
<p class="ltx_p" id="S6.p3.1"><span class="ltx_text ltx_font_bold" id="S6.p3.1.1">Process.</span> A change in the fair dataset curation <em class="ltx_emph ltx_font_italic" id="S6.p3.1.2">process</em> requires not only norm-setting within fairness communities, but also legal and policy interventions. For example, at the implementation phase (<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#S4.SS3.SSS3" title="4.3.3 Implementation Processes ‣ 4.3 Implementation ‣ 4 Challenges During the Dataset Lifecycle ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">4.3.3</span></a>), participants were concerned about labor rights for data workers. As a discipline, we should have norms about compensating workers, at least at the local minimum wage, for their labor and support efforts to introduce policies that offer codified protection for data workers. Furthermore, at the regulatory level (<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#S5.SS4" title="5.4 Regulatory Level ‣ 5 Challenges Overarching the Broader Landscape of Fairness ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">5.4</span></a>), rather than expecting curators to develop legal expertise, we advocate for the creation of accessible resources on legal practices regarding dataset collection.</p>
</div>
<div class="ltx_para ltx_noindent" id="S6.p4">
<p class="ltx_p" id="S6.p4.1"><span class="ltx_text ltx_font_bold" id="S6.p4.1.1">Release.</span> We encourage interventions that allow for fairness post-<em class="ltx_emph ltx_font_italic" id="S6.p4.1.2">release</em>. For example, at the maintenance phase (<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#S4.SS5" title="4.5 Maintenance ‣ 4 Challenges During the Dataset Lifecycle ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">4.5</span></a>), efforts to build tools and policies to enable better dataset traceability could alleviate concerns with dataset misuse. Additionally, at the organization level (<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#S5.SS3" title="5.3 Organization Level ‣ 5 Challenges Overarching the Broader Landscape of Fairness ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">5.3</span></a>), funding entities should invest in maintenance, rather than solely focusing on modeling research. Monetarily valuing long-term maintenance plans as research contributions may help shift perspectives about revision, maintenance, and use policies at the discipline level (<a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#S5.SS2" title="5.2 Discipline Level ‣ 5 Challenges Overarching the Broader Landscape of Fairness ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">5.2</span></a>).</p>
</div>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusion</h2>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p" id="S7.p1.1">Through interviews with fair dataset curators, we developed a taxonomy of challenges appearing across the dataset lifecycle and the fairness landscape. Our participants navigated difficult trade-offs between ideal fairness goals and practical concerns, such as data availability, resources, and time. While we acknowledge limitations of our methodologies (see <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#A4" title="Appendix D Limitations ‣ Appendix C Detailed Recommendations for Enabling Fair Dataset Curation ‣ Appendix B Additional Figures and Tables ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_tag">Appendix</span> <span class="ltx_text ltx_ref_tag">D</span></a>), taxonomizing these challenges is a crucial first step in developing long-lasting solutions to support fair dataset curation.</p>
</div>
<div class="ltx_para" id="S7.p2">
<p class="ltx_p" id="S7.p2.1">Addressing these challenges requires effort from individual data curators as well as systemic changes at the organizational, disciplinary, and regulatory levels. Beyond providing dataset curators grounded evidence to refer to in the quest for building fair datasets, our taxonomy offers stakeholders a pathway to tackling each challenge individually and opens avenues to further, more targeted investigation into the many challenges to curating fair datasets.</p>
</div>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_title_section">Acknowledgments and Disclosure of Funding</h2>
<div class="ltx_para" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1">This work was funded by Sony Research.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Announcing the NeurIPS Code of Ethics 2013; NeurIPS Blog — blog.neurips.cc.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://blog.neurips.cc/2023/04/20/announcing-the-neurips-code-of-ethics/" title="">https://blog.neurips.cc/2023/04/20/announcing-the-neurips-code-of-ethics/</a>.

</span>
<span class="ltx_bibblock">[Accessed 14-08-2023].

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Andrews et al. [2023a]</span>
<span class="ltx_bibblock">
Jerone T. A. Andrews, Przemyslaw Joniak, and Alice Xiang.

</span>
<span class="ltx_bibblock">A view from somewhere: Human-centric face representations.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">International Conference on Learning Representations (ICLR)</em>, 2023a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Andrews et al. [2023b]</span>
<span class="ltx_bibblock">
Jerone T. A. Andrews, Dora Zhao, William Thong, Apostolos Modas, Orestis Papakyriakopoulos, and Alice Xiang.

</span>
<span class="ltx_bibblock">Ethical considerations for responsible data curation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">Neural Information Processing Systems Datasets and Benchmarks Track (NeurIPS D&amp;B)</em>, 2023b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Andrus et al. [2021]</span>
<span class="ltx_bibblock">
McKane Andrus, Elena Spitzer, Jeffrey Brown, and Alice Xiang.

</span>
<span class="ltx_bibblock">What we can’t measure, we can’t understand: Challenges to demographic data procurement in the pursuit of fairness.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">ACM Conference on Fairness, Accountability, and Transparency (FAccT)</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Asano et al. [2021]</span>
<span class="ltx_bibblock">
Yuki M Asano, Christian Rupprecht, Andrew Zisserman, and Andrea Vedaldi.

</span>
<span class="ltx_bibblock">Pass: An imagenet replacement for self-supervised pretraining without humans.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">f</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bae et al. [2023]</span>
<span class="ltx_bibblock">
Gwangbin Bae, Martin de La Gorce, Tadas Baltrušaitis, Charlie Hewitt, Dong Chen, Julien Valentin, Roberto Cipolla, and Jingjing Shen.

</span>
<span class="ltx_bibblock">Digiface-1m: 1 million digital face images for face recognition.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Barrett et al. [2023]</span>
<span class="ltx_bibblock">
Teanna Barrett, Quanze Chen, and Amy Zhang.

</span>
<span class="ltx_bibblock">Skin deep: Investigating subjectivity in skin tone annotations for computer vision benchmark datasets.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">ACM Conference on Fairness, Accountability, and Transparency (FAccT)</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bender and Friedman [2018]</span>
<span class="ltx_bibblock">
Emily M. Bender and Batya Friedman.

</span>
<span class="ltx_bibblock">Data statements for natural language processing: Toward mitigating system bias and enabling better science.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">Transactions of the Association for Computational Linguistics (TACL)</em>, 6:587–604, December 2018.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1162/tacl_a_00041</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bender et al. [2021]</span>
<span class="ltx_bibblock">
Emily M Bender, Timnit Gebru, Angelina McMillan-Major, and Shmargaret Shmitchell.

</span>
<span class="ltx_bibblock">On the dangers of stochastic parrots: Can language models be too big?

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">ACM Conference on Fairness, Accountability, and Transparency (FAccT)</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Benthall and Haynes [2019]</span>
<span class="ltx_bibblock">
Sebastian Benthall and Bruce D Haynes.

</span>
<span class="ltx_bibblock">Racial categories in machine learning.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">ACM Conference on Fairness, Accountability, and Transparency (FAccT)</em>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Beygelzimer et al. [2021]</span>
<span class="ltx_bibblock">
Alina Beygelzimer, Yann Dauphin, Percy Liang, and Jennifer Wortman Vaughan.

</span>
<span class="ltx_bibblock">Introducing the neurips 2021 paper checklist.

</span>
<span class="ltx_bibblock">2021.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://blog.neurips.cc/2021/03/26/introducing-the-neurips-2021-paper-checklist/" title="">https://blog.neurips.cc/2021/03/26/introducing-the-neurips-2021-paper-checklist/</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Birhane and Prabhu [2021]</span>
<span class="ltx_bibblock">
Abeba Birhane and Vinay Uday Prabhu.

</span>
<span class="ltx_bibblock">Large image datasets: A pyrrhic win for computer vision?

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Birhane et al. [2022]</span>
<span class="ltx_bibblock">
Abeba Birhane, Pratyusha Kalluri, Dallas Card, William Agnew, Ravit Dotan, and Michelle Bao.

</span>
<span class="ltx_bibblock">The values encoded in machine learning research.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">ACM Conference on Fairness, Accountability, and Transparency (FAccT)</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Birhane et al. [2023]</span>
<span class="ltx_bibblock">
Abeba Birhane, Vinay Prabhu, Sang Han, and Vishnu Naresh Boddeti.

</span>
<span class="ltx_bibblock">On hate scaling laws for data-swamps.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">arXiv preprint arXiv:2306.13141</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Birhane et al. [2024]</span>
<span class="ltx_bibblock">
Abeba Birhane, Sanghyun Han, Vishnu Boddeti, Sasha Luccioni, et al.

</span>
<span class="ltx_bibblock">Into the laion’s den: Investigating hate in multimodal datasets.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">Advances in Neural Information Processing Systems Datasets and Benchmarks Track (NeurIPS D&amp;B)</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Blili-Hamelin and Hancox-Li [2023]</span>
<span class="ltx_bibblock">
Borhane Blili-Hamelin and Leif Hancox-Li.

</span>
<span class="ltx_bibblock">Making intelligence: Ethical values in iq and ml benchmarks.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">ACM Conference on Fairness, Accountability, and Transparency (FAccT)</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Blodgett et al. [2020]</span>
<span class="ltx_bibblock">
Su Lin Blodgett, Solon Barocas, Hal Daumé III, and Hanna Wallach.

</span>
<span class="ltx_bibblock">Language (technology) is power: A critical survey of “bias” in nlp.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">Annual Meeting of the Association for Computational Linguistics (ACL)</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bolukbasi et al. [2016]</span>
<span class="ltx_bibblock">
Tolga Bolukbasi, Kai-Wei Chang, James Y Zou, Venkatesh Saligrama, and Adam T Kalai.

</span>
<span class="ltx_bibblock">Man is to computer programmer as woman is to homemaker? debiasing word embeddings.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">Advances in Neural Information Processing Systems (NeurIPS)</em>, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bronfenbrenner et al. [1994]</span>
<span class="ltx_bibblock">
Urie Bronfenbrenner et al.

</span>
<span class="ltx_bibblock">Ecological models of human development.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">International encyclopedia of education</em>, 3(2):37–43, 1994.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Buolamwini and Gebru [2018]</span>
<span class="ltx_bibblock">
Joy Buolamwini and Timnit Gebru.

</span>
<span class="ltx_bibblock">Gender shades: Intersectional accuracy disparities in commercial gender classification.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">ACM Conference on Fairness, Accountability, and Transparency (FAccT)</em>, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Caliskan et al. [2017]</span>
<span class="ltx_bibblock">
Aylin Caliskan, Joanna J Bryson, and Arvind Narayanan.

</span>
<span class="ltx_bibblock">Semantics derived automatically from language corpora contain human-like biases.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">Science</em>, 356(6334):183–186, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Calude and Longo [2017]</span>
<span class="ltx_bibblock">
Cristian S Calude and Giuseppe Longo.

</span>
<span class="ltx_bibblock">The deluge of spurious correlations in big data.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">Foundations of science</em>, 22:595–612, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cambo and Gergle [2022]</span>
<span class="ltx_bibblock">
Scott Allen Cambo and Darren Gergle.

</span>
<span class="ltx_bibblock">Model positionality and computational reflexivity: Promoting reflexivity in data science.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">ACM CHI Conference on Human Factors in Computing Systems</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chan et al. [2021]</span>
<span class="ltx_bibblock">
Alan Chan, Chinasa T Okolo, Zachary Terner, and Angelina Wang.

</span>
<span class="ltx_bibblock">The limits of global inclusion in ai development.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">arXiv preprint arXiv:2102.01265</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chan et al. [2023]</span>
<span class="ltx_bibblock">
Alan Chan, Herbie Bradley, and Nitarshan Rajkumar.

</span>
<span class="ltx_bibblock">Reclaiming the digital commons: A public data trust for training data.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">AAAI/ACM Conference on AI, Ethics, and Society (AIES)</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cheng et al. [2023]</span>
<span class="ltx_bibblock">
Myra Cheng, Esin Durmus, and Dan Jurafsky.

</span>
<span class="ltx_bibblock">Marked personas: Using natural language prompts to measure stereotypes in language models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) (ACL)</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chmielinski et al. [2022]</span>
<span class="ltx_bibblock">
Kasia S Chmielinski, Sarah Newman, Matt Taylor, Josh Joseph, Kemi Thomas, Jessica Yurkofsky, and Yue Chelsea Qiu.

</span>
<span class="ltx_bibblock">The dataset nutrition label (2nd gen): Leveraging context to mitigate harms in artificial intelligence.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">arXiv preprint arXiv:2201.03954</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Collins et al. [2022]</span>
<span class="ltx_bibblock">
Katherine M Collins, Umang Bhatt, and Adrian Weller.

</span>
<span class="ltx_bibblock">Eliciting and learning with soft labels from every annotator.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">AAAI Conference on Human Computation and Crowdsourcing (HCOMP)</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Corbett-Davies et al. [2017]</span>
<span class="ltx_bibblock">
Sam Corbett-Davies, Emma Pierson, Avi Feller, Sharad Goel, and Aziz Huq.

</span>
<span class="ltx_bibblock">Algorithmic decision making and the cost of fairness.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</em>, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Council of Europe [n.d.]</span>
<span class="ltx_bibblock">
Council of Europe.

</span>
<span class="ltx_bibblock">Inclusion and anti-discrimination: Ai &amp; discrimination.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.coe.int/en/web/inclusion-and-antidiscrimination/ai-and-discrimination" title="">https://www.coe.int/en/web/inclusion-and-antidiscrimination/ai-and-discrimination</a>, n.d.

</span>
<span class="ltx_bibblock">Accessed November 24, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Davani et al. [2022]</span>
<span class="ltx_bibblock">
Aida Mostafazadeh Davani, Mark Díaz, and Vinodkumar Prabhakaran.

</span>
<span class="ltx_bibblock">Dealing with disagreements: Looking beyond the majority vote in subjective annotations.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">Transactions of the Association for Computational Linguistics (TACL)</em>, 10:92–110, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">de Freitas Netto et al. [2020]</span>
<span class="ltx_bibblock">
Sebastião Vieira de Freitas Netto, Marcos Felipe Falcão Sobral, Ana Regina Bezerra Ribeiro, and Gleibson Robert da Luz Soares.

</span>
<span class="ltx_bibblock">Concepts and forms of greenwashing: A systematic review.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">Environmental Sciences Europe</em>, 32:1–12, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">De Hert and Papakonstantinou [2016]</span>
<span class="ltx_bibblock">
Paul De Hert and Vagelis Papakonstantinou.

</span>
<span class="ltx_bibblock">The new general data protection regulation: Still a sound system for the protection of individuals?

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">Computer law &amp; security review</em>, 32(2):179–194, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dehkharghanian et al. [2023]</span>
<span class="ltx_bibblock">
Taher Dehkharghanian, Azam Asilian Bidgoli, Abtin Riasatian, Pooria Mazaheri, Clinton JV Campbell, Liron Pantanowitz, HR Tizhoosh, and Shahryar Rahnamayan.

</span>
<span class="ltx_bibblock">Biased data, biased ai: deep networks predict the acquisition site of tcga images.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">Diagnostic pathology</em>, 18(1):67, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Deng et al. [2009]</span>
<span class="ltx_bibblock">
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei.

</span>
<span class="ltx_bibblock">Imagenet: A large-scale hierarchical image database.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2009.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Deng et al. [2022]</span>
<span class="ltx_bibblock">
Wesley Hanwen Deng, Manish Nagireddy, Michelle Seng Ah Lee, Jatinder Singh, Zhiwei Steven Wu, Kenneth Holstein, and Haiyi Zhu.

</span>
<span class="ltx_bibblock">Exploring how machine learning practitioners (try to) use fairness toolkits.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">ACM Conference on Fairness, Accountability, and Transparency (FAccT)</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Deng et al. [2023a]</span>
<span class="ltx_bibblock">
Wesley Hanwen Deng, Boyuan Guo, Alicia Devrio, Hong Shen, Motahhare Eslami, and Kenneth Holstein.

</span>
<span class="ltx_bibblock">Understanding practices, challenges, and opportunities for user-engaged algorithm auditing in industry practice.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">ACM Conference on Fairness, Accountability, and Transparency (FAccT)</em>, 2023a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Deng et al. [2023b]</span>
<span class="ltx_bibblock">
Wesley Hanwen Deng, Nur Yildirim, Monica Chang, Motahhare Eslami, Kenneth Holstein, and Michael Madaio.

</span>
<span class="ltx_bibblock">Investigating practices and opportunities for cross-functional collaboration around ai fairness in industry practice.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">ACM Conference on Fairness, Accountability, and Transparency (FAccT)</em>, 2023b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Denton et al. [2020]</span>
<span class="ltx_bibblock">
Emily Denton, Alex Hanna, Razvan Amironesei, Andrew Smart, Hilary Nicole, and Morgan Klaus Scheuerman.

</span>
<span class="ltx_bibblock">Bringing the people back in: Contesting benchmark machine learning datasets.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">arXiv preprint arXiv:2007.07399</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Díaz et al. [2022]</span>
<span class="ltx_bibblock">
Mark Díaz, Ian Kivlichan, Rachel Rosen, Dylan Baker, Razvan Amironesei, Vinodkumar Prabhakaran, and Emily Denton.

</span>
<span class="ltx_bibblock">Crowdworksheets: Accounting for individual and collective identities underlying crowdsourced dataset annotation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">ACM Conference on Fairness, Accountability, and Transparency (FAccT)</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ding et al. [2021]</span>
<span class="ltx_bibblock">
Frances Ding, Moritz Hardt, John Miller, and Ludwig Schmidt.

</span>
<span class="ltx_bibblock">Retiring adult: New datasets for fair machine learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib41.1.1">Advances in Neural Information Processing Systems (NeurIPS)</em>, 34, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ding et al. [2022]</span>
<span class="ltx_bibblock">
Yi Ding, Jacob You, Tonja-Katrin Machulla, Jennifer Jacobs, Pradeep Sen, and Tobias Höllerer.

</span>
<span class="ltx_bibblock">Impact of annotator demographics on sentiment dataset labeling.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1">Proceedings of the ACM on Human-Computer Interaction</em>, 6(CSCW2), 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dotan and Milli [2020]</span>
<span class="ltx_bibblock">
Ravit Dotan and Smitha Milli.

</span>
<span class="ltx_bibblock">Value-laden disciplinary shifts in machine learning.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">ACM Conference on Fairness, Accountability, and Transparency (FAccT)</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fabris et al. [2022]</span>
<span class="ltx_bibblock">
Alessandro Fabris, Stefano Messina, Gianmaria Silvello, and Gian Antonio Susto.

</span>
<span class="ltx_bibblock">Algorithmic fairness datasets: the story so far.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib44.1.1">Data Mining and Knowledge Discovery</em>, 36(6):2074–2152, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Faden and Beauchamp [1986]</span>
<span class="ltx_bibblock">
Ruth R Faden and Tom L Beauchamp.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib45.1.1">A history and theory of informed consent</em>.

</span>
<span class="ltx_bibblock">Oxford University Press, 1986.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fan et al. [2022]</span>
<span class="ltx_bibblock">
Shaoyang Fan, Pinar Barlas, Evgenia Christoforou, Jahna Otterbacher, Shazia Sadiq, and Gianluca Demartini.

</span>
<span class="ltx_bibblock">Socio-economic diversity in human annotations.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib46.1.1">ACM Web Science Conference (WebSci)</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gallegos et al. [2023]</span>
<span class="ltx_bibblock">
Isabel O Gallegos, Ryan A Rossi, Joe Barrow, Md Mehrab Tanjim, Sungchul Kim, Franck Dernoncourt, Tong Yu, Ruiyi Zhang, and Nesreen K Ahmed.

</span>
<span class="ltx_bibblock">Bias and fairness in large language models: A survey.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib47.1.1">arXiv preprint arXiv:2309.00770</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Garcia et al. [2023]</span>
<span class="ltx_bibblock">
Noa Garcia, Yusuke Hirota, Yankun Wu, and Yuta Nakashima.

</span>
<span class="ltx_bibblock">Uncurated image-text datasets: Shedding light on demographic bias.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib48.1.1">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gebru et al. [2021]</span>
<span class="ltx_bibblock">
Timnit Gebru, Jamie Morgenstern, Briana Vecchione, Jennifer Wortman Vaughan, Hanna Wallach, Hal Daumé Iii, and Kate Crawford.

</span>
<span class="ltx_bibblock">Datasheets for datasets.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib49.1.1">Communications of the ACM</em>, 64(12):86–92, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Geiger et al. [2020]</span>
<span class="ltx_bibblock">
R Stuart Geiger, Kevin Yu, Yanlai Yang, Mindy Dai, Jie Qiu, Rebekah Tang, and Jenny Huang.

</span>
<span class="ltx_bibblock">Garbage in, garbage out? Do machine learning application papers in social computing report where human-labeled training data comes from?

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib50.1.1">ACM Conference on Fairness, Accountability, and Transparency (FAccT)</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Geirhos et al. [2020]</span>
<span class="ltx_bibblock">
Robert Geirhos, Jörn-Henrik Jacobsen, Claudio Michaelis, Richard Zemel, Wieland Brendel, Matthias Bethge, and Felix A Wichmann.

</span>
<span class="ltx_bibblock">Shortcut learning in deep neural networks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib51.1.1">Nature Machine Intelligence</em>, 2(11):665–673, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gondimalla et al. [2024]</span>
<span class="ltx_bibblock">
Apoorva Gondimalla, Varshinee Sreekanth, Govind Joshi, Whitney Nelson, Eunsol Choi, Stephen C Slota, Sherri R Greenberg, Kenneth R Fleischmann, and Min Kyung Lee.

</span>
<span class="ltx_bibblock">Aligning data with the goals of an organization and its workers: Designing data labeling for social service case notes.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib52.1.1">ACM CHI Conference on Human Factors in Computing Systems</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Google PAIR [2019]</span>
<span class="ltx_bibblock">
Google PAIR.

</span>
<span class="ltx_bibblock">Google pair. people + ai guidebook.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://pair.withgoogle.com/guidebook" title="">https://pair.withgoogle.com/guidebook</a>, 2019.

</span>
<span class="ltx_bibblock">Accessed February 1, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gordon et al. [2021]</span>
<span class="ltx_bibblock">
Mitchell L Gordon, Kaitlyn Zhou, Kayur Patel, Tatsunori Hashimoto, and Michael S Bernstein.

</span>
<span class="ltx_bibblock">The disagreement deconvolution: Bringing machine learning performance metrics in line with reality.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib54.1.1">ACM CHI Conference on Human Factors in Computing Systems</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gordon et al. [2022]</span>
<span class="ltx_bibblock">
Mitchell L Gordon, Michelle S Lam, Joon Sung Park, Kayur Patel, Jeff Hancock, Tatsunori Hashimoto, and Michael S Bernstein.

</span>
<span class="ltx_bibblock">Jury learning: Integrating dissenting voices into machine learning models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib55.1.1">ACM CHI Conference on Human Factors in Computing Systems</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gray et al. [2024]</span>
<span class="ltx_bibblock">
Colin M Gray, Ike Obi, Shruthi Sai Chivukula, Ziqing Li, Thomas V Carlock, Matthew S Will, Anne C Pivonka, Janna Johns, Brookley Rigsbee, Ambika R Menon, et al.

</span>
<span class="ltx_bibblock">Building an ethics-focused action plan: Roles, process moves, and trajectories.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib56.1.1">ACM CHI Conference on Human Factors in Computing Systems</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gray and Suri [2019]</span>
<span class="ltx_bibblock">
Mary L Gray and Siddharth Suri.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib57.1.1">Ghost work: How to stop Silicon Valley from building a new global underclass</em>.

</span>
<span class="ltx_bibblock">Eamon Dolan Books, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Grosz et al. [2019]</span>
<span class="ltx_bibblock">
Barbara J Grosz, David Gray Grant, Kate Vredenburgh, Jeff Behrends, Lily Hu, Alison Simmons, and Jim Waldo.

</span>
<span class="ltx_bibblock">Embedded ethics: integrating ethics across cs education.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib58.1.1">Communications of the ACM</em>, 62(8):54–61, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib59">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Grynbaum and Mac [2023]</span>
<span class="ltx_bibblock">
Michael M. Grynbaum and Ryan Mac.

</span>
<span class="ltx_bibblock">The times sues openai and microsoft over a.i. use of copyrighted work.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib59.1.1">New York Times</em>, 2023.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.nytimes.com/2023/12/27/business/media/new-york-times-open-ai-microsoft-lawsuit.html" title="">https://www.nytimes.com/2023/12/27/business/media/new-york-times-open-ai-microsoft-lawsuit.html</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib60">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gustafson et al. [2023]</span>
<span class="ltx_bibblock">
Laura Gustafson, Chloe Rolland, Nikhila Ravi, Quentin Duval, Aaron Adcock, Cheng-Yang Fu, Melissa Hall, and Candace Ross.

</span>
<span class="ltx_bibblock">Facet: Fairness in computer vision evaluation benchmark.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib60.1.1">IEEE/CVF International Conference on Computer Vision (ICCV)</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib61">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hanley et al. [2020]</span>
<span class="ltx_bibblock">
Margot Hanley, Apoorv Khandelwal, Hadar Averbuch-Elor, Noah Snavely, and Helen Nissenbaum.

</span>
<span class="ltx_bibblock">An ethical highlighter for people-centric dataset creation.

</span>
<span class="ltx_bibblock">2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib62">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hanna et al. [2020]</span>
<span class="ltx_bibblock">
Alex Hanna, Emily Denton, Andrew Smart, and Jamila Smith-Loud.

</span>
<span class="ltx_bibblock">Towards a critical race methodology in algorithmic fairness.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib62.1.1">ACM Conference on Fairness, Accountability, and Transparency (FAccT)</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib63">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hazirbas et al. [2021a]</span>
<span class="ltx_bibblock">
Caner Hazirbas, Joanna Bitton, Brian Dolhansky, Jacqueline Pan, Albert Gordo, and Cristian Canton Ferrer.

</span>
<span class="ltx_bibblock">Casual conversations: A dataset for measuring fairness in ai.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib63.1.1">IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)</em>, 2021a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib64">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hazirbas et al. [2021b]</span>
<span class="ltx_bibblock">
Caner Hazirbas, Joanna Bitton, Brian Dolhansky, Jacqueline Pan, Albert Gordo, and Cristian Canton Ferrer.

</span>
<span class="ltx_bibblock">Towards measuring fairness in ai: the casual conversations dataset.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib64.1.1">IEEE Transactions on Biometrics, Behavior, and Identity Science</em>, 2021b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib65">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Heger et al. [2022]</span>
<span class="ltx_bibblock">
Amy K Heger, Liz B Marquis, Mihaela Vorvoreanu, Hanna Wallach, and Jennifer Wortman Vaughan.

</span>
<span class="ltx_bibblock">Understanding machine learning practitioners’ data documentation perceptions, needs, challenges, and desiderata.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib65.1.1">Proceedings of the ACM on Human-Computer Interaction</em>, 6(CSCW2):1–29, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib66">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Heldreth et al. [2024]</span>
<span class="ltx_bibblock">
Courtney M Heldreth, Ellis P Monk, Alan T Clark, Candice Schumann, Xango Eyee, and Susanna Ricco.

</span>
<span class="ltx_bibblock">Which skin tone measures are the most inclusive? an investigation of skin tone measures for artificial intelligence.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib66.1.1">ACM Journal on Responsible Computing</em>, 1(1):1–21, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib67">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hern [2015]</span>
<span class="ltx_bibblock">
Alex Hern.

</span>
<span class="ltx_bibblock">Flickr faces complaints over ’offensive’ auto-tagging for photos, May 2015.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.theguardian.com/technology/2015/may/20/flickr-complaints-offensive-auto-tagging-photos" title="">https://www.theguardian.com/technology/2015/may/20/flickr-complaints-offensive-auto-tagging-photos</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib68">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hern [2018]</span>
<span class="ltx_bibblock">
Alex Hern.

</span>
<span class="ltx_bibblock">Google’s solution to accidental algorithmic racism: Ban gorillas, January 2018.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.theguardian.com/technology/2018/jan/12/google-racism-ban-gorilla-black-people" title="">https://www.theguardian.com/technology/2018/jan/12/google-racism-ban-gorilla-black-people</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib69">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hern [2020]</span>
<span class="ltx_bibblock">
Alex Hern.

</span>
<span class="ltx_bibblock">Twitter apologises for ’racist’ image-cropping algorithm, September 2020.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.theguardian.com/technology/2020/sep/21/twitter-apologises-for-racist-image-cropping-algorithm" title="">https://www.theguardian.com/technology/2020/sep/21/twitter-apologises-for-racist-image-cropping-algorithm</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib70">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hill and Krolik [2019]</span>
<span class="ltx_bibblock">
Kashmir Hill and Aaron Krolik.

</span>
<span class="ltx_bibblock">How photos of your kids are powering surveillance technology.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib70.1.1">New York Times</em>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib71">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hirota et al. [2022]</span>
<span class="ltx_bibblock">
Yusuke Hirota, Yuta Nakashima, and Noa Garcia.

</span>
<span class="ltx_bibblock">Gender and racial bias in visual question answering datasets.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib71.1.1">ACM Conference on Fairness, Accountability, and Transparency (FAccT)</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib72">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hofmann et al. [2024]</span>
<span class="ltx_bibblock">
Valentin Hofmann, Pratyusha Ria Kalluri, Dan Jurafsky, and Sharese King.

</span>
<span class="ltx_bibblock">Dialect prejudice predicts ai decisions about people’s character, employability, and criminality.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib72.1.1">arXiv preprint arXiv:2403.00742</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib73">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Holstein et al. [2019]</span>
<span class="ltx_bibblock">
Kenneth Holstein, Jennifer Wortman Vaughan, Hal Daumé III, Miro Dudik, and Hanna Wallach.

</span>
<span class="ltx_bibblock">Improving fairness in machine learning systems: What do industry practitioners need?

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib73.1.1">ACM CHI Conference on Human Factors in Computing Systems</em>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib74">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hsueh et al. [2009]</span>
<span class="ltx_bibblock">
Pei-Yun Hsueh, Prem Melville, and Vikas Sindhwani.

</span>
<span class="ltx_bibblock">Data quality from crowdsourcing: a study of annotation selection criteria.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib74.1.1">Workshop on Active Learning for Natural Language Processing at Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL)</em>, 2009.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib75">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hundt et al. [2022]</span>
<span class="ltx_bibblock">
Andrew Hundt, William Agnew, Vicky Zeng, Severin Kacianka, and Matthew Gombolay.

</span>
<span class="ltx_bibblock">Robots enact malignant stereotypes.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib75.1.1">ACM Conference on Fairness, Accountability, and Transparency (FAccT)</em>, pages 743–756, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib76">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hutchinson et al. [2021]</span>
<span class="ltx_bibblock">
Ben Hutchinson, Andrew Smart, Alex Hanna, Emily Denton, Christina Greer, Oddur Kjartansson, Parker Barnes, and Margaret Mitchell.

</span>
<span class="ltx_bibblock">Towards accountability for machine learning datasets: Practices from software engineering and infrastructure.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib76.1.1">ACM Conference on Fairness, Accountability, and Transparency (FAccT)</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib77">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">IBM [2019]</span>
<span class="ltx_bibblock">
IBM.

</span>
<span class="ltx_bibblock">Design for ai.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.ibm.com/design/ai" title="">https://www.ibm.com/design/ai</a>, 2019.

</span>
<span class="ltx_bibblock">Accessed February 1, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib78">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jo and Gebru [2020]</span>
<span class="ltx_bibblock">
Eun Seo Jo and Timnit Gebru.

</span>
<span class="ltx_bibblock">Lessons from archives: Strategies for collecting sociocultural data in machine learning.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib78.1.1">ACM Conference on Fairness, Accountability and Transparency (FAccT)</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib79">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kapania et al. [2023]</span>
<span class="ltx_bibblock">
Shivani Kapania, Alex S Taylor, and Ding Wang.

</span>
<span class="ltx_bibblock">A hunt for the snark: Annotator diversity in data practices.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib79.1.1">ACM CHI Conference on Human Factors in Computing Systems</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib80">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Katzman et al. [2023]</span>
<span class="ltx_bibblock">
Jared Katzman, Angelina Wang, Morgan Scheuerman, Su Lin Blodgett, Kristen Laird, Hanna Wallach, and Solon Barocas.

</span>
<span class="ltx_bibblock">Taxonomizing and measuring representational harms: A look at image tagging.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib80.1.1">AAAI Conference on Artificial Intelligence (AAAI)</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib81">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kazimzade and Miceli [2020]</span>
<span class="ltx_bibblock">
Gunay Kazimzade and Milagros Miceli.

</span>
<span class="ltx_bibblock">Biased priorities, biased outcomes: three recommendations for ethics-oriented data annotation practices.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib81.1.1">AAAI/ACM Conference on AI, Ethics, and Society (AIES)</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib82">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Khan and Fu [2021]</span>
<span class="ltx_bibblock">
Zaid Khan and Yun Fu.

</span>
<span class="ltx_bibblock">One label, one billion faces: Usage and consistency of racial categories in computer vision.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib82.1.1">ACM Conference on Fairness, Accountability, and Transparency (FAccT)</em>, pages 587–597, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib83">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Koch et al. [2021]</span>
<span class="ltx_bibblock">
Bernard Koch, Emily Denton, Alex Hanna, and Jacob Gates Foster.

</span>
<span class="ltx_bibblock">Reduced, reused and recycled: The life of a dataset in machine learning research.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib83.1.1">Advances in Neural Information Processing Systems Datasets and Benchmarks Track (NeurIPS D&amp;B)</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib84">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kuo et al. [2024]</span>
<span class="ltx_bibblock">
Tzu-Sheng Kuo, Aaron Lee Halfaker, Zirui Cheng, Jiwoo Kim, Meng-Hsin Wu, Tongshuang Wu, Kenneth Holstein, and Haiyi Zhu.

</span>
<span class="ltx_bibblock">Wikibench: Community-driven data curation for ai evaluation on wikipedia.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib84.1.1">ACM CHI Conference on Human Factors in Computing Systems</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib85">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kuznetsova et al. [2020]</span>
<span class="ltx_bibblock">
Alina Kuznetsova, Hassan Rom, Neil Alldrin, Jasper Uijlings, Ivan Krasin, Jordi Pont-Tuset, Shahab Kamali, Stefan Popov, Matteo Malloci, Alexander Kolesnikov, et al.

</span>
<span class="ltx_bibblock">The open images dataset v4: Unified image classification, object detection, and visual relationship detection at scale.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib85.1.1">International Journal of Computer Vision (IJCV)</em>, 128(7):1956–1981, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib86">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ladhak et al. [2023]</span>
<span class="ltx_bibblock">
Faisal Ladhak, Esin Durmus, Mirac Suzgun, Tianyi Zhang, Dan Jurafsky, Kathleen McKeown, and Tatsunori B Hashimoto.

</span>
<span class="ltx_bibblock">When do pre-training biases propagate to downstream tasks? a case study in text summarization.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib86.1.1">Conference of the European Chapter of the Association for Computational Linguistics (EACL)</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib87">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lebovitz et al. [2021]</span>
<span class="ltx_bibblock">
Sarah Lebovitz, Natalia Levina, and Hila Lifshitz-Assaf.

</span>
<span class="ltx_bibblock">Is ai ground truth really true? the dangers of training and evaluating ai tools based on experts’ know-what.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib87.1.1">MIS Q.</em>, 45, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib88">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Leonardelli et al. [2021]</span>
<span class="ltx_bibblock">
Elisa Leonardelli, Stefano Menini, Alessio Palmero Aprosio, Marco Guerini, and Sara Tonelli.

</span>
<span class="ltx_bibblock">Agreeing to disagree: Annotating offensive language datasets with annotators’ disagreement.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib88.1.1">Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib89">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liang et al. [2022]</span>
<span class="ltx_bibblock">
Weixin Liang, Girmaw Abebe Tadesse, Daniel Ho, Li Fei-Fei, Matei Zaharia, Ce Zhang, and James Zou.

</span>
<span class="ltx_bibblock">Advances, challenges and opportunities in creating data for trustworthy AI.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib89.1.1">Nature Machine Intelligence</em>, 4(8):669–677, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib90">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Luccioni et al. [2022]</span>
<span class="ltx_bibblock">
Alexandra Sasha Luccioni, Frances Corry, Hamsini Sridharan, Mike Ananny, Jason Schultz, and Kate Crawford.

</span>
<span class="ltx_bibblock">A framework for deprecating datasets: Standardizing documentation, identification, and communication.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib90.1.1">ACM Conference on Fairness, Accountability, and Transparency (FAccT)</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib91">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Luccioni et al. [2024]</span>
<span class="ltx_bibblock">
Alexandra Sasha Luccioni, Christopher Akiki, Margaret Mitchell, and Yacine Jernite.

</span>
<span class="ltx_bibblock">Stable bias: Evaluating societal representations in diffusion models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib91.1.1">Advances in Neural Information Processing Systems (NeurIPS)</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib92">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Luzzini et al. [2014]</span>
<span class="ltx_bibblock">
Davide Luzzini, Federico Caniato, and Gianluca Spina.

</span>
<span class="ltx_bibblock">Designing vendor evaluation systems: An empirical analysis.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib92.1.1">Journal of Purchasing and Supply Management</em>, 20(2):113–129, 2014.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib93">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Madaio et al. [2022]</span>
<span class="ltx_bibblock">
Michael Madaio, Lisa Egede, Hariharan Subramonyam, Jennifer Wortman Vaughan, and Hanna Wallach.

</span>
<span class="ltx_bibblock">Assessing the fairness of ai systems: Ai practitioners’ processes, challenges, and needs for support.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib93.1.1">Proceedings of the ACM on Human-Computer Interaction</em>, 6(CSCW1):1–26, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib94">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Madaio et al. [2020]</span>
<span class="ltx_bibblock">
Michael A Madaio, Luke Stark, Jennifer Wortman Vaughan, and Hanna Wallach.

</span>
<span class="ltx_bibblock">Co-designing checklists to understand organizational challenges and opportunities around fairness in ai.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib94.1.1">ACM CHI Conference on Human Factors in Computing Systems</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib95">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McMillan-Major et al. [2024]</span>
<span class="ltx_bibblock">
Angelina McMillan-Major, Emily M Bender, and Batya Friedman.

</span>
<span class="ltx_bibblock">Data statements: From technical concept to community practice.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib95.1.1">ACM Journal on Responsible Computing</em>, 1(1):1–17, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib96">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mehrabi et al. [2021]</span>
<span class="ltx_bibblock">
Ninareh Mehrabi, Fred Morstatter, Nripsuta Saxena, Kristina Lerman, and Aram Galstyan.

</span>
<span class="ltx_bibblock">A survey on bias and fairness in machine learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib96.1.1">ACM Computing Surveys (CSUR)</em>, 54(6):1–35, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib97">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Meister et al. [2023]</span>
<span class="ltx_bibblock">
Nicole Meister, Dora Zhao, Angelina Wang, Vikram V Ramaswamy, Ruth Fong, and Olga Russakovsky.

</span>
<span class="ltx_bibblock">Gender artifacts in visual datasets.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib97.1.1">IEEE/CVF International Conference on Computer Vision (ICCV)</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib98">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Miceli et al. [2020]</span>
<span class="ltx_bibblock">
Milagros Miceli, Martin Schuessler, and Tianling Yang.

</span>
<span class="ltx_bibblock">Between subjectivity and imposition: Power dynamics in data annotation for computer vision.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib98.1.1">Proceedings of the ACM on Human-Computer Interaction</em>, 4(CSCW2):1–25, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib99">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Miceli et al. [2021]</span>
<span class="ltx_bibblock">
Milagros Miceli, Tianling Yang, Laurens Naudts, Martin Schuessler, Diana Serbanescu, and Alex Hanna.

</span>
<span class="ltx_bibblock">Documenting computer vision datasets: An invitation to reflexive data practices.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib99.1.1">ACM Conference on Fairness, Accountability, and Transparency (FAccT)</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib100">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Miceli et al. [2022]</span>
<span class="ltx_bibblock">
Milagros Miceli, Julian Posada, and Tianling Yang.

</span>
<span class="ltx_bibblock">Studying up machine learning data: Why talk about bias when we mean power?

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib100.1.1">Proceedings of the ACM on Human-Computer Interaction</em>, 6(GROUP):1–14, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib101">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mitchell et al. [2021]</span>
<span class="ltx_bibblock">
Shira Mitchell, Eric Potash, Solon Barocas, Alexander D’Amour, and Kristian Lum.

</span>
<span class="ltx_bibblock">Algorithmic fairness: Choices, assumptions, and definitions.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib101.1.1">Annual review of statistics and its application</em>, 8:141–163, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib102">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mittelstadt and Floridi [2016]</span>
<span class="ltx_bibblock">
Brent Daniel Mittelstadt and Luciano Floridi.

</span>
<span class="ltx_bibblock">The ethics of big data: current and foreseeable issues in biomedical contexts.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib102.1.1">The ethics of biomedical big data</em>, pages 445–480, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib103">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ojewale et al. [2024]</span>
<span class="ltx_bibblock">
Victor Ojewale, Ryan Steed, Briana Vecchione, Abeba Birhane, and Inioluwa Deborah Raji.

</span>
<span class="ltx_bibblock">Towards ai accountability infrastructure: Gaps and opportunities in ai audit tooling.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib103.1.1">arXiv preprint arXiv:2402.17861</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib104">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Orr and Crawford [2024]</span>
<span class="ltx_bibblock">
Will Orr and Kate Crawford.

</span>
<span class="ltx_bibblock">Building better datasets: Seven recommendations for responsible design from dataset creators.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib104.1.1">Journal of Data-centric Machine Learning Research</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib105">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">P Simmons et al. [2021]</span>
<span class="ltx_bibblock">
Joseph P Simmons, Leif D Nelson, and Uri Simonsohn.

</span>
<span class="ltx_bibblock">Pre-registration: Why and how.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib105.1.1">Journal of Consumer Psychology</em>, 31(1):151–162, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib106">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Papakyriakopoulos et al. [2023]</span>
<span class="ltx_bibblock">
Orestis Papakyriakopoulos, Anna Seo Gyeong Choi, William Thong, Dora Zhao, Jerone Andrews, Rebecca Bourke, Alice Xiang, and Allison Koenecke.

</span>
<span class="ltx_bibblock">Augmented datasheets for speech datasets and ethical decision-making.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib106.1.1">ACM Conference on Fairness, Accountability, and Transparency (FAccT)</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib107">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Park et al. [2021]</span>
<span class="ltx_bibblock">
Joon Sung Park, Danielle Bragg, Ece Kamar, and Meredith Ringel Morris.

</span>
<span class="ltx_bibblock">Designing an online infrastructure for collecting ai data from people with disabilities.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib107.1.1">ACM Conference on Fairness, Accountability, and Transparency (FAccT)</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib108">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Paullada et al. [2021]</span>
<span class="ltx_bibblock">
Amandalynne Paullada, Inioluwa Deborah Raji, Emily M Bender, Emily Denton, and Alex Hanna.

</span>
<span class="ltx_bibblock">Data and its (dis) contents: A survey of dataset development and use in machine learning research.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib108.1.1">Patterns</em>, 2(11), 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib109">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Peng et al. [2021]</span>
<span class="ltx_bibblock">
Kenny Peng, Arunesh Mathur, and Arvind Narayanan.

</span>
<span class="ltx_bibblock">Mitigating dataset harms requires stewardship: Lessons from 1000 papers.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib109.1.1">Advances in Neural Information Processing Systems Datasets and Benchmarks Track (NeurIPS D&amp;B)</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib110">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Politou et al. [2018]</span>
<span class="ltx_bibblock">
Eugenia Politou, Efthimios Alepis, and Constantinos Patsakis.

</span>
<span class="ltx_bibblock">Forgetting personal data and revoking consent under the gdpr: Challenges and proposed solutions.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib110.1.1">Journal of cybersecurity</em>, 4(1):tyy001, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib111">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Porgali et al. [2023]</span>
<span class="ltx_bibblock">
Bilal Porgali, Vítor Albiero, Jordan Ryda, Cristian Canton Ferrer, and Caner Hazirbas.

</span>
<span class="ltx_bibblock">The casual conversations v2 dataset.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib111.1.1">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib112">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Prabhakaran et al. [2021]</span>
<span class="ltx_bibblock">
Vinodkumar Prabhakaran, Aida Mostafazadeh Davani, and Mark Díaz.

</span>
<span class="ltx_bibblock">On releasing annotator-level labels and information in datasets.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib112.1.1">Linguistic Annotation Workshop (LAW) and Designing Meaning Representations (DMR) Workshop</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib113">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Prabhakaran et al. [2023]</span>
<span class="ltx_bibblock">
Vinodkumar Prabhakaran, Christopher Homan, Lora Aroyo, Alicia Parrish, Alex Taylor, Mark Díaz, and Ding Wang.

</span>
<span class="ltx_bibblock">A framework to assess (dis) agreement among diverse rater groups.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib113.1.1">arXiv preprint arXiv:2311.05074</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib114">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pushkarna et al. [2022]</span>
<span class="ltx_bibblock">
Mahima Pushkarna, Andrew Zaldivar, and Oddur Kjartansson.

</span>
<span class="ltx_bibblock">Data cards: Purposeful and transparent dataset documentation for responsible ai.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib114.1.1">ACM Conference on Fairness, Accountability, and Transparency (FAccT)</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib115">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Raji et al. [2021]</span>
<span class="ltx_bibblock">
Deborah Raji, Emily Denton, Emily M. Bender, Alex Hanna, and Amandalynne Paullada.

</span>
<span class="ltx_bibblock">AI and the everything in the whole wide world benchmark.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib115.1.1">Advances in Neural Information Processing Systems Datasets and Benchmarks Track (NeurIPS D&amp;B)</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib116">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ramaswamy et al. [2021]</span>
<span class="ltx_bibblock">
Vikram V Ramaswamy, Sunnie SY Kim, and Olga Russakovsky.

</span>
<span class="ltx_bibblock">Fair attribute classification through latent space de-biasing.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib116.1.1">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib117">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ramaswamy et al. [2024]</span>
<span class="ltx_bibblock">
Vikram V Ramaswamy, Sing Yu Lin, Dora Zhao, Aaron Adcock, Laurens van der Maaten, Deepti Ghadiyaram, and Olga Russakovsky.

</span>
<span class="ltx_bibblock">Geode: a geographically diverse evaluation dataset for object recognition.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib117.1.1">Advances in Neural Information Processing Systems Datasets and Benchmarks Track (NeurIPS D&amp;B)</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib118">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rojas et al. [2022]</span>
<span class="ltx_bibblock">
William A Gaviria Rojas, Sudnya Diamos, Keertan Ranjan Kini, David Kanter, Vijay Janapa Reddi, and Cody Coleman.

</span>
<span class="ltx_bibblock">The dollar street dataset: Images representing the geographic and socioeconomic diversity of the world.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib118.1.1">Advances in Neural Information Processing Systems Datasets and Benchmarks Track (NeurIPS D&amp;B)</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib119">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rondina et al. [2023]</span>
<span class="ltx_bibblock">
Marco Rondina, Antonio Vetrò, and Juan Carlos De Martin.

</span>
<span class="ltx_bibblock">Completeness of datasets documentation on ml/ai repositories: An empirical investigation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib119.1.1">EPIA Conference on Artificial Intelligence</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib120">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sambasivan et al. [2021]</span>
<span class="ltx_bibblock">
Nithya Sambasivan, Shivani Kapania, Hannah Highfill, Diana Akrong, Praveen Paritosh, and Lora M Aroyo.

</span>
<span class="ltx_bibblock">"everyone wants to do the model work, not the data work": Data cascades in high-stakes AI.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib120.1.1">ACM CHI Conference on Human Factors in Computing Systems</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib121">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[121]</span>
<span class="ltx_bibblock">
Sebastin Santy, Jenny Liang, Ronan Le Bras, Katharina Reinecke, and Maarten Sap.

</span>
<span class="ltx_bibblock">NLPositionality: Characterizing design biases of datasets and models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib121.1.1">Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) (ACL)</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib122">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sap et al. [2022]</span>
<span class="ltx_bibblock">
Maarten Sap, Swabha Swayamdipta, Laura Vianna, Xuhui Zhou, Yejin Choi, and Noah A Smith.

</span>
<span class="ltx_bibblock">Annotators with attitudes: How annotator beliefs and identities bias toxic language detection.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib122.1.1">Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL)</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib123">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Scheuerman [2024]</span>
<span class="ltx_bibblock">
Morgan Klaus Scheuerman.

</span>
<span class="ltx_bibblock">In the walled garden: Challenges and opportunities for research on the practices of the ai tech industry.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib123.1.1">ACM Conference on Fairness, Accountability, and Transparency (FAccT)</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib124">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Scheuerman and Brubaker [2024]</span>
<span class="ltx_bibblock">
Morgan Klaus Scheuerman and Jed R. Brubaker.

</span>
<span class="ltx_bibblock">Products of positionality: How tech workers shape identity concepts in computer vision.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib124.1.1">ACM CHI Conference on Human Factors in Computing Systems</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib125">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Scheuerman et al. [2020]</span>
<span class="ltx_bibblock">
Morgan Klaus Scheuerman, Kandrea Wade, Caitlin Lustig, and Jed R Brubaker.

</span>
<span class="ltx_bibblock">How we’ve taught algorithms to see identity: Constructing race and gender in image databases for facial analysis.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib125.1.1">Proceedings of the ACM on Human-computer Interaction</em>, 4(CSCW1):1–35, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib126">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Scheuerman et al. [2021]</span>
<span class="ltx_bibblock">
Morgan Klaus Scheuerman, Alex Hanna, and Emily Denton.

</span>
<span class="ltx_bibblock">Do datasets have politics? disciplinary values in computer vision dataset development.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib126.1.1">Proceedings of the ACM on Human-Computer Interaction</em>, 5(CSCW2):1–37, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib127">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Scheuerman et al. [2023]</span>
<span class="ltx_bibblock">
Morgan Klaus Scheuerman, Katy Weathington, Tarun Mugunthan, Emily Denton, and Casey Fiesler.

</span>
<span class="ltx_bibblock">From human to data to dataset: Mapping the traceability of human subjects in computer vision datasets.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib127.1.1">Proceedings of the ACM on Human-Computer Interaction</em>, 7(CSCW1):1–33, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib128">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schuhmann et al. [2021]</span>
<span class="ltx_bibblock">
Christoph Schuhmann, Richard Vencu, Romain Beaumont, Robert Kaczmarczyk, Clayton Mullis, Aarush Katta, Theo Coombes, Jenia Jitsev, and Aran Komatsuzaki.

</span>
<span class="ltx_bibblock">Laion-400m: Open dataset of clip-filtered 400 million image-text pairs.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib128.1.1">arXiv preprint arXiv:2111.02114</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib129">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schuhmann et al. [2022]</span>
<span class="ltx_bibblock">
Christoph Schuhmann, Romain Beaumont, Richard Vencu, Cade Gordon, Ross Wightman, Mehdi Cherti, Theo Coombes, Aarush Katta, Clayton Mullis, Mitchell Wortsman, et al.

</span>
<span class="ltx_bibblock">Laion-5b: An open large-scale dataset for training next generation image-text models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib129.1.1">Advances in Neural Information Processing Systems Datasets and Benchmarks Track (NeurIPS D&amp;B)</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib130">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schumann et al. [2021]</span>
<span class="ltx_bibblock">
Candice Schumann, Susanna Ricco, Utsav Prabhu, Vittorio Ferrari, and Caroline Rebecca Pantofaru.

</span>
<span class="ltx_bibblock">A step toward more inclusive people annotations for fairness.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib130.1.1">AAAI/ACM Conference on AI, Ethics, and Society (AIES)</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib131">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schwemmer et al. [2020]</span>
<span class="ltx_bibblock">
Carsten Schwemmer, Carly Knight, Emily D Bello-Pardo, Stan Oklobdzija, Martijn Schoonvelde, and Jeffrey W Lockhart.

</span>
<span class="ltx_bibblock">Diagnosing gender bias in image recognition systems.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib131.1.1">Socius</em>, 6:2378023120967171, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib132">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sen et al. [2015]</span>
<span class="ltx_bibblock">
Shilad Sen, Margaret E Giesel, Rebecca Gold, Benjamin Hillmann, Matt Lesicko, Samuel Naden, Jesse Russell, Zixiao Wang, and Brent Hecht.

</span>
<span class="ltx_bibblock">Turkers, scholars," arafat" and" peace" cultural communities and algorithmic gold standards.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib132.1.1">ACM Conference on Computer Supported Cooperative Work &amp; Social Computing</em>, pages 826–838, 2015.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib133">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Septiandri et al. [2023]</span>
<span class="ltx_bibblock">
Ali Akbar Septiandri, Marios Constantinides, Mohammad Tahaei, and Daniele Quercia.

</span>
<span class="ltx_bibblock">Weird faccts: How western, educated, industrialized, rich, and democratic is facct?

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib133.1.1">ACM Conference on Fairness, Accountability, and Transparency (FAccT)</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib134">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shen et al. [2022]</span>
<span class="ltx_bibblock">
Hong Shen, Leijie Wang, Wesley H Deng, Ciell Brusse, Ronald Velgersdijk, and Haiyi Zhu.

</span>
<span class="ltx_bibblock">The model card authoring toolkit: Toward community-centered, deliberation-driven ai design.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib134.1.1">ACM Conference on Fairness, Accountability, and Transparency (FAccT)</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib135">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Smart et al. [2024]</span>
<span class="ltx_bibblock">
Andrew Smart, Ding Wang, Ellis Monk, Mark Díaz, Atoosa Kasirzadeh, Erin Van Liemt, and Sonja Schmer-Galunder.

</span>
<span class="ltx_bibblock">Discipline and label: A weird genealogy and social theory of data annotation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib135.1.1">arXiv preprint arXiv:2402.06811</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib136">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Smith et al. [2023]</span>
<span class="ltx_bibblock">
Brandon Abreu Smith, Miguel Farinha, Siobhan Mackenzie Hall, Hannah Rose Kirk, Aleksandar Shtedritski, and Max Bain.

</span>
<span class="ltx_bibblock">Balancing the picture: Debiasing vision-language datasets with synthetic contrast sets.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib136.1.1">NeurIPS 2023 Workshop on Synthetic Data Generation with Generative AI</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib137">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tamkin et al. [2023]</span>
<span class="ltx_bibblock">
Alex Tamkin, Amanda Askell, Liane Lovitt, Esin Durmus, Nicholas Joseph, Shauna Kravec, Karina Nguyen, Jared Kaplan, and Deep Ganguli.

</span>
<span class="ltx_bibblock">Evaluating and mitigating discrimination in language model decisions.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib137.1.1">arXiv preprint arXiv:2312.03689</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib138">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Thiel [2023]</span>
<span class="ltx_bibblock">
David Thiel.

</span>
<span class="ltx_bibblock">Identifying and Eliminating CSAM in Generative ML Training Data and Models.

</span>
<span class="ltx_bibblock">2023.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.25740/kh752sm9123</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://purl.stanford.edu/kh752sm9123" title="">https://purl.stanford.edu/kh752sm9123</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib139">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Thompson [2022]</span>
<span class="ltx_bibblock">
Jamie Thompson.

</span>
<span class="ltx_bibblock">A guide to abductive thematic analysis.

</span>
<span class="ltx_bibblock">2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib140">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Thong et al. [2023]</span>
<span class="ltx_bibblock">
William Thong, Przemyslaw Joniak, and Alice Xiang.

</span>
<span class="ltx_bibblock">Beyond skin tone: A multidimensional measure of apparent skin color.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib140.1.1">IEEE/CVF International Conference on Computer Vision (ICCV)</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib141">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tomasev et al. [2021]</span>
<span class="ltx_bibblock">
Nenad Tomasev, Kevin R McKee, Jackie Kay, and Shakir Mohamed.

</span>
<span class="ltx_bibblock">Fairness for unobserved characteristics: Insights from technological impacts on queer communities.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib141.1.1">AAAI/ACM Conference on AI, Ethics, and Society (AIES)</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib142">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Toxtli et al. [2021]</span>
<span class="ltx_bibblock">
Carlos Toxtli, Siddharth Suri, and Saiph Savage.

</span>
<span class="ltx_bibblock">Quantifying the invisible labor in crowd work.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib142.1.1">Proceedings of the ACM on human-computer interaction</em>, 5(CSCW2):1–26, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib143">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vanschoren and Yeung [2021]</span>
<span class="ltx_bibblock">
Joaquin Vanschoren and Serena Yeung.

</span>
<span class="ltx_bibblock">Announcing the neurips 2021 datasets and benchmarks track.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib143.1.1">Medium</em>, 2021.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://neuripsconf.medium.com/announcing-the-neurips-2021-datasets-and-benchmarks-track-644e27c1e66c" title="">https://neuripsconf.medium.com/announcing-the-neurips-2021-datasets-and-benchmarks-track-644e27c1e66c</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib144">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Varanasi and Goyal [2023]</span>
<span class="ltx_bibblock">
Rama Adithya Varanasi and Nitesh Goyal.

</span>
<span class="ltx_bibblock">“It is currently hodgepodge”: Examining AI/ML practitioners’ challenges during co-production of responsible ai values.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib144.1.1">ACM CHI Conference on Human Factors in Computing Systems</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib145">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wan et al. [2023]</span>
<span class="ltx_bibblock">
Ruyuan Wan, Jaehyung Kim, and Dongyeop Kang.

</span>
<span class="ltx_bibblock">Everyone’s voice matters: Quantifying annotation disagreement using demographic information.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib145.1.1">AAAI Conference on Artificial Intelligence (AAAI)</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib146">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. [2024a]</span>
<span class="ltx_bibblock">
Angelina Wang, Teresa Datta, and John P Dickerson.

</span>
<span class="ltx_bibblock">Strategies for increasing corporate responsible ai prioritization.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib146.1.1">arXiv preprint arXiv:2405.03855</em>, 2024a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib147">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. [2022]</span>
<span class="ltx_bibblock">
Ding Wang, Shantanu Prabhat, and Nithya Sambasivan.

</span>
<span class="ltx_bibblock">Whose AI dream? In search of the aspiration in data annotation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib147.1.1">ACM CHI Conference on Human Factors in Computing Systems</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib148">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. [2024b]</span>
<span class="ltx_bibblock">
Ge Wang, Jun Zhao, Max Van Kleek, and Nigel Shadbolt.

</span>
<span class="ltx_bibblock">Challenges and opportunities in translating ethical ai principles into practice for children.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib148.1.1">Nature Machine Intelligence</em>, pages 1–6, 2024b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib149">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. [2019]</span>
<span class="ltx_bibblock">
Tianlu Wang, Jieyu Zhao, Mark Yatskar, Kai-Wei Chang, and Vicente Ordonez.

</span>
<span class="ltx_bibblock">Balanced datasets are not enough: Estimating and mitigating gender bias in deep image representations.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib149.1.1">IEEE/CVF International Conference on Computer Vision (ICCV)</em>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib150">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Whiting et al. [2019]</span>
<span class="ltx_bibblock">
Mark E Whiting, Grant Hugh, and Michael S Bernstein.

</span>
<span class="ltx_bibblock">Fair work: Crowd work minimum wage with one line of code.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib150.1.1">AAAI Conference on Human Computation and Crowdsourcing (HCOMP)</em>, volume 7, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib151">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Whitney and Norman [2024]</span>
<span class="ltx_bibblock">
Cedric Deslandes Whitney and Justin Norman.

</span>
<span class="ltx_bibblock">Real risks of fake data: Synthetic data, diversity-washing and consent circumvention.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib151.1.1">ACM Conference on Fairness, Accountability, and Transparency (FAccT)</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib152">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wilcox et al. [2023]</span>
<span class="ltx_bibblock">
Lauren Wilcox, Robin Brewer, and Fernando Diaz.

</span>
<span class="ltx_bibblock">Ai consent futures: A case study on voice data collection with clinicians.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib152.1.1">Proceedings of the ACM on Human-Computer Interaction</em>, 7(CSCW2):1–30, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib153">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wilson et al. [2019]</span>
<span class="ltx_bibblock">
Benjamin Wilson, Judy Hoffman, and Jamie Morgenstern.

</span>
<span class="ltx_bibblock">Predictive inequity in object detection.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib153.1.1">IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)</em>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib154">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">World Health Organization and others [2021]</span>
<span class="ltx_bibblock">
World Health Organization and others.

</span>
<span class="ltx_bibblock">Ethics and governance of artificial intelligence for health: Who guidance.

</span>
<span class="ltx_bibblock">2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib155">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xiang [2024]</span>
<span class="ltx_bibblock">
Alice Xiang.

</span>
<span class="ltx_bibblock">Mirror, mirror, on the wall, who’s the fairest of them all?

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib155.1.1">Dædalus</em>, 153(1):250–267, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib156">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al. [2020]</span>
<span class="ltx_bibblock">
Kaiyu Yang, Klint Qinami, Li Fei-Fei, Jia Deng, and Olga Russakovsky.

</span>
<span class="ltx_bibblock">Towards fairer datasets: Filtering and balancing the distribution of the people subtree in the imagenet hierarchy.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib156.1.1">ACM Conference on Fairness, Accountability, and Transparency (FAccT)</em>, pages 547–558, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib157">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al. [2022]</span>
<span class="ltx_bibblock">
Yu Yang, Aayush Gupta, Jianwei Feng, Prateek Singhal, Vivek Yadav, Yue Wu, Pradeep Natarajan, Varsha Hedau, and Jungseock Joo.

</span>
<span class="ltx_bibblock">Enhancing fairness in face detection in computer vision systems by demographic bias mitigation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib157.1.1">AAAI/ACM Conference on AI, Ethics, and Society (AIES)</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib158">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yew and Xiang [2022]</span>
<span class="ltx_bibblock">
Rui-Jie Yew and Alice Xiang.

</span>
<span class="ltx_bibblock">Regulating facial processing technologies: Tensions between legal and technical considerations in the application of illinois bipa.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib158.1.1">ACM Conference on Fairness, Accountability, and Transparency (FAccT)</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib159">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al. [2021]</span>
<span class="ltx_bibblock">
Dora Zhao, Angelina Wang, and Olga Russakovsky.

</span>
<span class="ltx_bibblock">Understanding and evaluating racial biases in image captioning.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib159.1.1">IEEE/CVF International Conference on Computer Vision (ICCV)</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib160">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al. [2017]</span>
<span class="ltx_bibblock">
Jieyu Zhao, Tianlu Wang, Mark Yatskar, Vicente Ordonez, and Kai-Wei Chang.

</span>
<span class="ltx_bibblock">Men also like shopping: Reducing gender bias amplification using corpus-level constraints.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib160.1.1">Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>, 2017.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Additional Methodological Details</h2>
<figure class="ltx_table" id="A1.T2">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A1.T2.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A1.T2.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_t" colspan="3" id="A1.T2.1.1.1.1" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold" id="A1.T2.1.1.1.1.1">Participants</span></th>
</tr>
<tr class="ltx_tr" id="A1.T2.1.2.2">
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_th_row ltx_border_t" id="A1.T2.1.2.2.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">  <em class="ltx_emph ltx_font_bold ltx_font_italic" id="A1.T2.1.2.2.1.1">Participant ID</em>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A1.T2.1.2.2.2" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold ltx_font_italic" id="A1.T2.1.2.2.2.1">Organization Type</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A1.T2.1.2.2.3" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold ltx_font_italic" id="A1.T2.1.2.2.3.1">Dataset Focus</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A1.T2.1.3.1">
<th class="ltx_td ltx_align_justify ltx_th ltx_th_row ltx_border_t" id="A1.T2.1.3.1.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.3.1.1.1">
<span class="ltx_p" id="A1.T2.1.3.1.1.1.1">P1</span>
</span>
</th>
<td class="ltx_td ltx_align_justify ltx_border_t" id="A1.T2.1.3.1.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.3.1.2.1">
<span class="ltx_p" id="A1.T2.1.3.1.2.1.1">Academia</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_border_t" id="A1.T2.1.3.1.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.3.1.3.1">
<span class="ltx_p" id="A1.T2.1.3.1.3.1.1">Language</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.4.2">
<th class="ltx_td ltx_align_justify ltx_th ltx_th_row" id="A1.T2.1.4.2.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.4.2.1.1">
<span class="ltx_p" id="A1.T2.1.4.2.1.1.1">P2</span>
</span>
</th>
<td class="ltx_td ltx_align_justify" id="A1.T2.1.4.2.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.4.2.2.1">
<span class="ltx_p" id="A1.T2.1.4.2.2.1.1">Academia</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A1.T2.1.4.2.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.4.2.3.1">
<span class="ltx_p" id="A1.T2.1.4.2.3.1.1">Language</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.5.3">
<th class="ltx_td ltx_align_justify ltx_th ltx_th_row" id="A1.T2.1.5.3.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.5.3.1.1">
<span class="ltx_p" id="A1.T2.1.5.3.1.1.1">P3</span>
</span>
</th>
<td class="ltx_td ltx_align_justify" id="A1.T2.1.5.3.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.5.3.2.1">
<span class="ltx_p" id="A1.T2.1.5.3.2.1.1">Academia</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A1.T2.1.5.3.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.5.3.3.1">
<span class="ltx_p" id="A1.T2.1.5.3.3.1.1">Language</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.6.4">
<th class="ltx_td ltx_align_justify ltx_th ltx_th_row" id="A1.T2.1.6.4.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.6.4.1.1">
<span class="ltx_p" id="A1.T2.1.6.4.1.1.1">P4</span>
</span>
</th>
<td class="ltx_td ltx_align_justify" id="A1.T2.1.6.4.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.6.4.2.1">
<span class="ltx_p" id="A1.T2.1.6.4.2.1.1">Academia</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A1.T2.1.6.4.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.6.4.3.1">
<span class="ltx_p" id="A1.T2.1.6.4.3.1.1">Other</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.7.5">
<th class="ltx_td ltx_align_justify ltx_th ltx_th_row" id="A1.T2.1.7.5.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.7.5.1.1">
<span class="ltx_p" id="A1.T2.1.7.5.1.1.1">P5</span>
</span>
</th>
<td class="ltx_td ltx_align_justify" id="A1.T2.1.7.5.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.7.5.2.1">
<span class="ltx_p" id="A1.T2.1.7.5.2.1.1">Academia</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A1.T2.1.7.5.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.7.5.3.1">
<span class="ltx_p" id="A1.T2.1.7.5.3.1.1">Language</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.8.6">
<th class="ltx_td ltx_align_justify ltx_th ltx_th_row" id="A1.T2.1.8.6.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.8.6.1.1">
<span class="ltx_p" id="A1.T2.1.8.6.1.1.1">P6</span>
</span>
</th>
<td class="ltx_td ltx_align_justify" id="A1.T2.1.8.6.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.8.6.2.1">
<span class="ltx_p" id="A1.T2.1.8.6.2.1.1">Industry</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A1.T2.1.8.6.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.8.6.3.1">
<span class="ltx_p" id="A1.T2.1.8.6.3.1.1">Language</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.9.7">
<th class="ltx_td ltx_align_justify ltx_th ltx_th_row" id="A1.T2.1.9.7.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.9.7.1.1">
<span class="ltx_p" id="A1.T2.1.9.7.1.1.1">P7</span>
</span>
</th>
<td class="ltx_td ltx_align_justify" id="A1.T2.1.9.7.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.9.7.2.1">
<span class="ltx_p" id="A1.T2.1.9.7.2.1.1">Industry</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A1.T2.1.9.7.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.9.7.3.1">
<span class="ltx_p" id="A1.T2.1.9.7.3.1.1">Language</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.10.8">
<th class="ltx_td ltx_align_justify ltx_th ltx_th_row" id="A1.T2.1.10.8.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.10.8.1.1">
<span class="ltx_p" id="A1.T2.1.10.8.1.1.1">P8</span>
</span>
</th>
<td class="ltx_td ltx_align_justify" id="A1.T2.1.10.8.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.10.8.2.1">
<span class="ltx_p" id="A1.T2.1.10.8.2.1.1">Academia</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A1.T2.1.10.8.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.10.8.3.1">
<span class="ltx_p" id="A1.T2.1.10.8.3.1.1">Multi-modal</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.11.9">
<th class="ltx_td ltx_align_justify ltx_th ltx_th_row" id="A1.T2.1.11.9.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.11.9.1.1">
<span class="ltx_p" id="A1.T2.1.11.9.1.1.1">P9</span>
</span>
</th>
<td class="ltx_td ltx_align_justify" id="A1.T2.1.11.9.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.11.9.2.1">
<span class="ltx_p" id="A1.T2.1.11.9.2.1.1">Academia</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A1.T2.1.11.9.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.11.9.3.1">
<span class="ltx_p" id="A1.T2.1.11.9.3.1.1">Language</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.12.10">
<th class="ltx_td ltx_align_justify ltx_th ltx_th_row" id="A1.T2.1.12.10.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.12.10.1.1">
<span class="ltx_p" id="A1.T2.1.12.10.1.1.1">P10</span>
</span>
</th>
<td class="ltx_td ltx_align_justify" id="A1.T2.1.12.10.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.12.10.2.1">
<span class="ltx_p" id="A1.T2.1.12.10.2.1.1">Academia</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A1.T2.1.12.10.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.12.10.3.1">
<span class="ltx_p" id="A1.T2.1.12.10.3.1.1">Language</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.13.11">
<th class="ltx_td ltx_align_justify ltx_th ltx_th_row" id="A1.T2.1.13.11.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.13.11.1.1">
<span class="ltx_p" id="A1.T2.1.13.11.1.1.1">P11</span>
</span>
</th>
<td class="ltx_td ltx_align_justify" id="A1.T2.1.13.11.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.13.11.2.1">
<span class="ltx_p" id="A1.T2.1.13.11.2.1.1">Academia</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A1.T2.1.13.11.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.13.11.3.1">
<span class="ltx_p" id="A1.T2.1.13.11.3.1.1">Vision</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.14.12">
<th class="ltx_td ltx_align_justify ltx_th ltx_th_row" id="A1.T2.1.14.12.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.14.12.1.1">
<span class="ltx_p" id="A1.T2.1.14.12.1.1.1">P12</span>
</span>
</th>
<td class="ltx_td ltx_align_justify" id="A1.T2.1.14.12.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.14.12.2.1">
<span class="ltx_p" id="A1.T2.1.14.12.2.1.1">Academia</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A1.T2.1.14.12.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.14.12.3.1">
<span class="ltx_p" id="A1.T2.1.14.12.3.1.1">Vision</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.15.13">
<th class="ltx_td ltx_align_justify ltx_th ltx_th_row" id="A1.T2.1.15.13.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.15.13.1.1">
<span class="ltx_p" id="A1.T2.1.15.13.1.1.1">P13</span>
</span>
</th>
<td class="ltx_td ltx_align_justify" id="A1.T2.1.15.13.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.15.13.2.1">
<span class="ltx_p" id="A1.T2.1.15.13.2.1.1">Industry</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A1.T2.1.15.13.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.15.13.3.1">
<span class="ltx_p" id="A1.T2.1.15.13.3.1.1">Vision</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.16.14">
<th class="ltx_td ltx_align_justify ltx_th ltx_th_row" id="A1.T2.1.16.14.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.16.14.1.1">
<span class="ltx_p" id="A1.T2.1.16.14.1.1.1">P14</span>
</span>
</th>
<td class="ltx_td ltx_align_justify" id="A1.T2.1.16.14.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.16.14.2.1">
<span class="ltx_p" id="A1.T2.1.16.14.2.1.1">University</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A1.T2.1.16.14.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.16.14.3.1">
<span class="ltx_p" id="A1.T2.1.16.14.3.1.1">Vision, Language, Other</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.17.15">
<th class="ltx_td ltx_align_justify ltx_th ltx_th_row" id="A1.T2.1.17.15.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.17.15.1.1">
<span class="ltx_p" id="A1.T2.1.17.15.1.1.1">P15</span>
</span>
</th>
<td class="ltx_td ltx_align_justify" id="A1.T2.1.17.15.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.17.15.2.1">
<span class="ltx_p" id="A1.T2.1.17.15.2.1.1">University</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A1.T2.1.17.15.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.17.15.3.1">
<span class="ltx_p" id="A1.T2.1.17.15.3.1.1">Vision</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.18.16">
<th class="ltx_td ltx_align_justify ltx_th ltx_th_row" id="A1.T2.1.18.16.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.18.16.1.1">
<span class="ltx_p" id="A1.T2.1.18.16.1.1.1">P16</span>
</span>
</th>
<td class="ltx_td ltx_align_justify" id="A1.T2.1.18.16.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.18.16.2.1">
<span class="ltx_p" id="A1.T2.1.18.16.2.1.1">Academia</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A1.T2.1.18.16.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.18.16.3.1">
<span class="ltx_p" id="A1.T2.1.18.16.3.1.1">Other</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.19.17">
<th class="ltx_td ltx_align_justify ltx_th ltx_th_row" id="A1.T2.1.19.17.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.19.17.1.1">
<span class="ltx_p" id="A1.T2.1.19.17.1.1.1">P17</span>
</span>
</th>
<td class="ltx_td ltx_align_justify" id="A1.T2.1.19.17.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.19.17.2.1">
<span class="ltx_p" id="A1.T2.1.19.17.2.1.1">Academia</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A1.T2.1.19.17.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.19.17.3.1">
<span class="ltx_p" id="A1.T2.1.19.17.3.1.1">Multi-modal</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.20.18">
<th class="ltx_td ltx_align_justify ltx_th ltx_th_row" id="A1.T2.1.20.18.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.20.18.1.1">
<span class="ltx_p" id="A1.T2.1.20.18.1.1.1">P18</span>
</span>
</th>
<td class="ltx_td ltx_align_justify" id="A1.T2.1.20.18.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.20.18.2.1">
<span class="ltx_p" id="A1.T2.1.20.18.2.1.1">Academia</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A1.T2.1.20.18.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.20.18.3.1">
<span class="ltx_p" id="A1.T2.1.20.18.3.1.1">Vision</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.21.19">
<th class="ltx_td ltx_align_justify ltx_th ltx_th_row" id="A1.T2.1.21.19.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.21.19.1.1">
<span class="ltx_p" id="A1.T2.1.21.19.1.1.1">P19</span>
</span>
</th>
<td class="ltx_td ltx_align_justify" id="A1.T2.1.21.19.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.21.19.2.1">
<span class="ltx_p" id="A1.T2.1.21.19.2.1.1">Academia</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A1.T2.1.21.19.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.21.19.3.1">
<span class="ltx_p" id="A1.T2.1.21.19.3.1.1">Other</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.22.20">
<th class="ltx_td ltx_align_justify ltx_th ltx_th_row" id="A1.T2.1.22.20.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.22.20.1.1">
<span class="ltx_p" id="A1.T2.1.22.20.1.1.1">P20</span>
</span>
</th>
<td class="ltx_td ltx_align_justify" id="A1.T2.1.22.20.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.22.20.2.1">
<span class="ltx_p" id="A1.T2.1.22.20.2.1.1">Academia</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A1.T2.1.22.20.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.22.20.3.1">
<span class="ltx_p" id="A1.T2.1.22.20.3.1.1">Vision</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.23.21">
<th class="ltx_td ltx_align_justify ltx_th ltx_th_row" id="A1.T2.1.23.21.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.23.21.1.1">
<span class="ltx_p" id="A1.T2.1.23.21.1.1.1">P21</span>
</span>
</th>
<td class="ltx_td ltx_align_justify" id="A1.T2.1.23.21.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.23.21.2.1">
<span class="ltx_p" id="A1.T2.1.23.21.2.1.1">Academia</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A1.T2.1.23.21.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.23.21.3.1">
<span class="ltx_p" id="A1.T2.1.23.21.3.1.1">Language</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.24.22">
<th class="ltx_td ltx_align_justify ltx_th ltx_th_row" id="A1.T2.1.24.22.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.24.22.1.1">
<span class="ltx_p" id="A1.T2.1.24.22.1.1.1">P22</span>
</span>
</th>
<td class="ltx_td ltx_align_justify" id="A1.T2.1.24.22.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.24.22.2.1">
<span class="ltx_p" id="A1.T2.1.24.22.2.1.1">Industry</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A1.T2.1.24.22.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.24.22.3.1">
<span class="ltx_p" id="A1.T2.1.24.22.3.1.1">Language, Vision</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.25.23">
<th class="ltx_td ltx_align_justify ltx_th ltx_th_row" id="A1.T2.1.25.23.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.25.23.1.1">
<span class="ltx_p" id="A1.T2.1.25.23.1.1.1">P23</span>
</span>
</th>
<td class="ltx_td ltx_align_justify" id="A1.T2.1.25.23.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.25.23.2.1">
<span class="ltx_p" id="A1.T2.1.25.23.2.1.1">Academia</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A1.T2.1.25.23.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.25.23.3.1">
<span class="ltx_p" id="A1.T2.1.25.23.3.1.1">Language, Multi-modal</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.26.24">
<th class="ltx_td ltx_align_justify ltx_th ltx_th_row" id="A1.T2.1.26.24.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.26.24.1.1">
<span class="ltx_p" id="A1.T2.1.26.24.1.1.1">P24</span>
</span>
</th>
<td class="ltx_td ltx_align_justify" id="A1.T2.1.26.24.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.26.24.2.1">
<span class="ltx_p" id="A1.T2.1.26.24.2.1.1">Academia</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A1.T2.1.26.24.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.26.24.3.1">
<span class="ltx_p" id="A1.T2.1.26.24.3.1.1">Language</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.27.25">
<th class="ltx_td ltx_align_justify ltx_th ltx_th_row" id="A1.T2.1.27.25.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.27.25.1.1">
<span class="ltx_p" id="A1.T2.1.27.25.1.1.1">P25</span>
</span>
</th>
<td class="ltx_td ltx_align_justify" id="A1.T2.1.27.25.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.27.25.2.1">
<span class="ltx_p" id="A1.T2.1.27.25.2.1.1">Academia</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A1.T2.1.27.25.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.27.25.3.1">
<span class="ltx_p" id="A1.T2.1.27.25.3.1.1">Language</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.28.26">
<th class="ltx_td ltx_align_justify ltx_th ltx_th_row" id="A1.T2.1.28.26.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.28.26.1.1">
<span class="ltx_p" id="A1.T2.1.28.26.1.1.1">P26</span>
</span>
</th>
<td class="ltx_td ltx_align_justify" id="A1.T2.1.28.26.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.28.26.2.1">
<span class="ltx_p" id="A1.T2.1.28.26.2.1.1">Academia</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A1.T2.1.28.26.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.28.26.3.1">
<span class="ltx_p" id="A1.T2.1.28.26.3.1.1">Vision</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.29.27">
<th class="ltx_td ltx_align_justify ltx_th ltx_th_row" id="A1.T2.1.29.27.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.29.27.1.1">
<span class="ltx_p" id="A1.T2.1.29.27.1.1.1">P27</span>
</span>
</th>
<td class="ltx_td ltx_align_justify" id="A1.T2.1.29.27.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.29.27.2.1">
<span class="ltx_p" id="A1.T2.1.29.27.2.1.1">Academia</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A1.T2.1.29.27.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.29.27.3.1">
<span class="ltx_p" id="A1.T2.1.29.27.3.1.1">Language</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.30.28">
<th class="ltx_td ltx_align_justify ltx_th ltx_th_row" id="A1.T2.1.30.28.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.30.28.1.1">
<span class="ltx_p" id="A1.T2.1.30.28.1.1.1">P28</span>
</span>
</th>
<td class="ltx_td ltx_align_justify" id="A1.T2.1.30.28.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.30.28.2.1">
<span class="ltx_p" id="A1.T2.1.30.28.2.1.1">Academia</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A1.T2.1.30.28.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.30.28.3.1">
<span class="ltx_p" id="A1.T2.1.30.28.3.1.1">Multi-modal</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.31.29">
<th class="ltx_td ltx_align_justify ltx_th ltx_th_row" id="A1.T2.1.31.29.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.31.29.1.1">
<span class="ltx_p" id="A1.T2.1.31.29.1.1.1">P29</span>
</span>
</th>
<td class="ltx_td ltx_align_justify" id="A1.T2.1.31.29.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.31.29.2.1">
<span class="ltx_p" id="A1.T2.1.31.29.2.1.1">Academia</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A1.T2.1.31.29.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.31.29.3.1">
<span class="ltx_p" id="A1.T2.1.31.29.3.1.1">Language</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.32.30">
<th class="ltx_td ltx_align_justify ltx_th ltx_th_row ltx_border_b" id="A1.T2.1.32.30.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.32.30.1.1">
<span class="ltx_p" id="A1.T2.1.32.30.1.1.1">P30</span>
</span>
</th>
<td class="ltx_td ltx_align_justify ltx_border_b" id="A1.T2.1.32.30.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.32.30.2.1">
<span class="ltx_p" id="A1.T2.1.32.30.2.1.1">Academia</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_border_b" id="A1.T2.1.32.30.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.32.30.3.1">
<span class="ltx_p" id="A1.T2.1.32.30.3.1.1">Multi-modal</span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span><span class="ltx_text" id="A1.T2.2.1" style="font-size:90%;">A of participants we interviewed for this study. Organization type refers to whether participants were in academia or industry. Dataset focus refers to the type of data participants collected for their dataset. “Vision” refers to visual data such as images and/or videos. “Language” refers to natural language data, such as textual data and/or spoken language data. “Multi-modal” refers to datasets which included both vision and language data. “Other” refers to datasets that fall outside of this schema, such as tabular datasets.</span></figcaption>
</figure>
<section class="ltx_subsection" id="A1.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.1 </span>Additional Recruitment Details</h3>
<div class="ltx_para" id="A1.SS1.p1">
<p class="ltx_p" id="A1.SS1.p1.1">In total, we reached out to 204 individuals with 95 no responses, 51 declines, and 28 who did not meet our participant criteria. We concluded recruitment with 30 participants as we had reached thematic saturation. As shown in <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#A1.T2" title="In Appendix A Additional Methodological Details ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">2</span></a>, the 30 participants represent diverse backgrounds and experiences, with a predominant presence from academia. Compensation consisted of a $75 Amazon gift card, or the equivalent in the participant’s local currency.</p>
</div>
</section>
<section class="ltx_subsection" id="A1.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.2 </span>Participant Anonymity</h3>
<div class="ltx_para" id="A1.SS2.p1">
<p class="ltx_p" id="A1.SS2.p1.1">To preserve participant anonymity, participant recruiting and interviews were conducted only by members of the research team from Arizona State University. The interviews were then transcribed and any identifying details were removed from transcripts. Only the redacted interviews were shared with other members of the research team for analysis.</p>
</div>
</section>
<section class="ltx_subsection" id="A1.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.3 </span>Interview Protocol</h3>
<div class="ltx_para" id="A1.SS3.p1">
<p class="ltx_p" id="A1.SS3.p1.1">We provide the protocol used to guide the semi-structured interview process conducted with participants. The interview questions were designed based on considerations around fair dataset curation that had been raised in the existing literature. Depending on the answers that the participants provided, the interviewers asked relevant follow-up questions. The questions are as follows:</p>
</div>
<div class="ltx_para" id="A1.SS3.p2">
<ul class="ltx_itemize" id="A1.I1">
<li class="ltx_item" id="A1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i1.p1">
<p class="ltx_p" id="A1.I1.i1.p1.1">Please briefly describe your current role and responsibilities. What way(s) does your current role interface with dataset collection for machine learning?</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i2.p1">
<p class="ltx_p" id="A1.I1.i2.p1.1">What is the role of machine learning in your organization?</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i3.p1">
<p class="ltx_p" id="A1.I1.i3.p1.1">What types of data do you collect to train and/or evaluate ML algorithms? What are the sources of this data?</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i4.p1">
<p class="ltx_p" id="A1.I1.i4.p1.1">Do you have any processes or are you currently developing any processes to ensure the fairness of data collected and used to train and/or evaluate ML algorithms?</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i5.p1">
<p class="ltx_p" id="A1.I1.i5.p1.1">How does your organization define “fairness” of datasets? Do you have a formal, codified definition of fairness?</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i6.p1">
<p class="ltx_p" id="A1.I1.i6.p1.1">How did your organization decide on the definition for fairness? Which factors influence this?</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i7" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i7.p1">
<p class="ltx_p" id="A1.I1.i7.p1.1">How do you ensure collection of fair datasets to train and/or evaluate ML algorithms? Or fairness when repurposing collected datasets?</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i8" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i8.p1">
<p class="ltx_p" id="A1.I1.i8.p1.1">Can you walk me through the process of making data collection and or data sets fair, as you do and experience it?</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i9" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i9.p1">
<p class="ltx_p" id="A1.I1.i9.p1.1">Which best practices did you employ to ensure the collection or making of fair datasets?</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i10" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i10.p1">
<p class="ltx_p" id="A1.I1.i10.p1.1">Which factors, in your experience, influence the making/collection of fair datasets?</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i11" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i11.p1">
<p class="ltx_p" id="A1.I1.i11.p1.1">What challenges did you experience during the process of making/collecting datasets?</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i12" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i12.p1">
<p class="ltx_p" id="A1.I1.i12.p1.1">How did you handle those challenges?</p>
<ul class="ltx_itemize" id="A1.I1.i12.I1">
<li class="ltx_item" id="A1.I1.i12.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="A1.I1.i12.I1.i1.1.1.1">–</span></span>
<div class="ltx_para" id="A1.I1.i12.I1.i1.p1">
<p class="ltx_p" id="A1.I1.i12.I1.i1.p1.1">What were some workarounds/ solutions?</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i12.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="A1.I1.i12.I1.i2.1.1.1">–</span></span>
<div class="ltx_para" id="A1.I1.i12.I1.i2.p1">
<p class="ltx_p" id="A1.I1.i12.I1.i2.p1.1">If you cannot recall any challenges, what about the process made it relatively smooth / why do you think there were not challenges?</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i12.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="A1.I1.i12.I1.i3.1.1.1">–</span></span>
<div class="ltx_para" id="A1.I1.i12.I1.i3.p1">
<p class="ltx_p" id="A1.I1.i12.I1.i3.p1.1">Were any parts easier or more difficult than expected?</p>
</div>
</li>
</ul>
</div>
</li>
<li class="ltx_item" id="A1.I1.i13" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i13.p1">
<p class="ltx_p" id="A1.I1.i13.p1.1">Thinking back to the process of making or collecting datasets, I’d like you to tell me a story about a time when you experienced any trade-off related to fairness of the dataset during that process — meaning, you had to sacrifice something to increase the fairness of the dataset, or you sacrificed fairness to achieve something else.</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i14" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i14.p1">
<p class="ltx_p" id="A1.I1.i14.p1.1">What challenges has your organization had in maintaining fairness in your datasets?</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i15" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i15.p1">
<p class="ltx_p" id="A1.I1.i15.p1.1">Since collecting fair datasets, have you released any of these datasets?</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i16" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i16.p1">
<p class="ltx_p" id="A1.I1.i16.p1.1">Thinking beyond your specific domain, what items should be included in more general guidelines for the creation and maintenance of fair datasets to train and/or evaluate ML algorithms? Are there any gaps in our current practices?</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i17" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i17.p1">
<p class="ltx_p" id="A1.I1.i17.p1.1">Do you have any comments or other points to make? Is there anything we did not cover in the interview which you would like to talk about?</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i18" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i18.p1">
<p class="ltx_p" id="A1.I1.i18.p1.1">Do you have any suggestions/advice about who we should talk to next?</p>
</div>
</li>
</ul>
</div>
</section>
</section>
<section class="ltx_appendix" id="A2">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Additional Figures and Tables</h2>
<div class="ltx_para" id="A2.p1">
<p class="ltx_p" id="A2.p1.1">We provide detailed examples from our interviews to illustrate our findings on the challenges to fair dataset collection in <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#A2" title="Appendix B Additional Figures and Tables ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_tag">Appendix</span> <span class="ltx_text ltx_ref_tag">B</span></a> and the overarching landscape of fairness challenges in <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#A2" title="Appendix B Additional Figures and Tables ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_tag">Appendix</span> <span class="ltx_text ltx_ref_tag">B</span></a>.</p>
</div>
<figure class="ltx_table ltx_figure_panel" id="A2.1.1">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel" id="A2.1.1.2"><span class="ltx_text ltx_font_bold" id="A2.1.1.2.1" style="font-size:90%;">Taxonomy of Challenges to Creating Fair Datasets<span class="ltx_text ltx_font_medium" id="A2.1.1.2.1.1"></span></span></p>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel" id="A2.1.1.3"><span class="ltx_text ltx_inline-block" id="A2.1.1.3.1" style="font-size:70%;width:433.6pt;">
<span class="ltx_tabular ltx_align_middle" id="A2.1.1.3.1.1">
<span class="ltx_tbody">
<span class="ltx_tr" id="A2.1.1.3.1.1.1.1">
<span class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_colspan ltx_colspan_5" id="A2.1.1.3.1.1.1.1.1" style="padding-top:3.5pt;padding-bottom:3.5pt;"><span class="ltx_rule" style="width:100%;height:0.8pt;background:black;display:inline-block;"> </span></span></span>
<span class="ltx_tr" id="A2.1.1.3.1.1.2.2">
<span class="ltx_td ltx_align_justify" id="A2.1.1.3.1.1.2.2.1" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.3.1.1.2.2.1.1">
<span class="ltx_p" id="A2.1.1.3.1.1.2.2.1.1.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="A2.1.1.3.1.1.2.2.1.1.1.1">Phase</span></span>
</span></span>
<span class="ltx_td" id="A2.1.1.3.1.1.2.2.2" style="padding-top:3.5pt;padding-bottom:3.5pt;"></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.3.1.1.2.2.3" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.3.1.1.2.2.3.1">
<span class="ltx_p" id="A2.1.1.3.1.1.2.2.3.1.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="A2.1.1.3.1.1.2.2.3.1.1.1">Challenge(s)</span></span>
</span></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.3.1.1.2.2.4" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.3.1.1.2.2.4.1">
<span class="ltx_p" id="A2.1.1.3.1.1.2.2.4.1.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="A2.1.1.3.1.1.2.2.4.1.1.1">Definition</span></span>
</span></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.3.1.1.2.2.5" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.3.1.1.2.2.5.1">
<span class="ltx_p" id="A2.1.1.3.1.1.2.2.5.1.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="A2.1.1.3.1.1.2.2.5.1.1.1">Example</span></span>
</span></span></span>
<span class="ltx_tr" id="A2.1.1.3.1.1.3.3">
<span class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_colspan ltx_colspan_5" id="A2.1.1.3.1.1.3.3.1" style="padding-top:3.5pt;padding-bottom:3.5pt;"><span class="ltx_rule" style="width:100%;height:0.8pt;background:black;display:inline-block;"> </span></span></span>
<span class="ltx_tr" id="A2.1.1.3.1.1.4.4">
<span class="ltx_td" id="A2.1.1.3.1.1.4.4.1" style="padding-top:3.5pt;padding-bottom:3.5pt;"></span>
<span class="ltx_td" id="A2.1.1.3.1.1.4.4.2" style="padding-top:3.5pt;padding-bottom:3.5pt;"></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.3.1.1.4.4.3" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.3.1.1.4.4.3.1">
<span class="ltx_p" id="A2.1.1.3.1.1.4.4.3.1.1">Scoping a dataset</span>
</span></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.3.1.1.4.4.4" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.3.1.1.4.4.4.1">
<span class="ltx_p" id="A2.1.1.3.1.1.4.4.4.1.1">Determining the size and scope of the dataset and its taxonomy while remaining true to fairness goals</span>
</span></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.3.1.1.4.4.5" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.3.1.1.4.4.5.1">
<span class="ltx_p" id="A2.1.1.3.1.1.4.4.5.1.1"><em class="ltx_emph ltx_font_italic" id="A2.1.1.3.1.1.4.4.5.1.1.1">“If the face images are on a billion scale, there’s no way we can identify each of this person in real world to reach out to them ask if they are okay with it.”</em> (P18)</span>
</span></span></span>
<span class="ltx_tr" id="A2.1.1.3.1.1.5.5">
<span class="ltx_td ltx_nopad_r ltx_align_justify" id="A2.1.1.3.1.1.5.5.1" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.3.1.1.5.5.1.1"><span class="ltx_ERROR undefined" id="A2.1.1.3.1.1.5.5.1.1.1">\cdashline</span>
<span class="ltx_p" id="A2.1.1.3.1.1.5.5.1.1.2">2-5

<span class="ltx_text" id="A2.1.1.3.1.1.5.5.1.1.2.1">
<span class="ltx_inline-block ltx_transformed_outer" id="A2.1.1.3.1.1.5.5.1.1.2.1.1" style="width:10.5pt;height:99.6pt;vertical-align:-46.9pt;"><span class="ltx_transformed_inner" style="width:99.6pt;transform:translate(-44.53pt,3.5pt) rotate(-90deg) ;">
<span class="ltx_p" id="A2.1.1.3.1.1.5.5.1.1.2.1.1.1"><span class="ltx_text" id="A2.1.1.3.1.1.5.5.1.1.2.1.1.1.1" style="font-size:171%;">– Requirements –</span></span>
</span></span></span></span>
</span></span>
<span class="ltx_td" id="A2.1.1.3.1.1.5.5.2" style="padding-top:3.5pt;padding-bottom:3.5pt;"></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.3.1.1.5.5.3" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.3.1.1.5.5.3.1">
<span class="ltx_p" id="A2.1.1.3.1.1.5.5.3.1.1">Determining fairness definitions</span>
</span></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.3.1.1.5.5.4" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.3.1.1.5.5.4.1">
<span class="ltx_p" id="A2.1.1.3.1.1.5.5.4.1.1">Deciding which definition of fairness to adopt and which not to</span>
</span></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.3.1.1.5.5.5" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.3.1.1.5.5.5.1">
<span class="ltx_p" id="A2.1.1.3.1.1.5.5.5.1.1"><em class="ltx_emph ltx_font_italic" id="A2.1.1.3.1.1.5.5.5.1.1.1">“Other work does not explicitly define fairness and that assumption can change the way you look at something. And so, being explicit about your intentions and about your working definitions and the inclusions and the exclusions of the scope of work, … is getting attention now more.”</em> (P2)</span>
</span></span></span>
<span class="ltx_tr" id="A2.1.1.3.1.1.6.6">
<span class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_colspan ltx_colspan_5" id="A2.1.1.3.1.1.6.6.1" style="padding-top:3.5pt;padding-bottom:3.5pt;"><span class="ltx_rule" style="width:100%;height:0.8pt;background:black;display:inline-block;"> </span></span></span>
<span class="ltx_tr" id="A2.1.1.3.1.1.7.7">
<span class="ltx_td" id="A2.1.1.3.1.1.7.7.1" style="padding-top:3.5pt;padding-bottom:3.5pt;"></span>
<span class="ltx_td" id="A2.1.1.3.1.1.7.7.2" style="padding-top:3.5pt;padding-bottom:3.5pt;"></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.3.1.1.7.7.3" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.3.1.1.7.7.3.1">
<span class="ltx_p" id="A2.1.1.3.1.1.7.7.3.1.1">Creating fair taxonomies</span>
</span></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.3.1.1.7.7.4" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.3.1.1.7.7.4.1">
<span class="ltx_p" id="A2.1.1.3.1.1.7.7.4.1.1">Establishing a system of classification that aligns with fairness definitions, despite classifications being inherently imperfect</span>
</span></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.3.1.1.7.7.5" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.3.1.1.7.7.5.1">
<span class="ltx_p" id="A2.1.1.3.1.1.7.7.5.1.1"><em class="ltx_emph ltx_font_italic" id="A2.1.1.3.1.1.7.7.5.1.1.1">“There are power relationships within what the model represents and what it represents is hegemony and it represents rigidity and classification, and it does not represent all of that queerness.”</em> (P27)</span>
</span></span></span>
<span class="ltx_tr" id="A2.1.1.3.1.1.8.8">
<span class="ltx_td ltx_nopad_r ltx_align_justify" id="A2.1.1.3.1.1.8.8.1" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.3.1.1.8.8.1.1"><span class="ltx_ERROR undefined" id="A2.1.1.3.1.1.8.8.1.1.1">\cdashline</span>
<span class="ltx_p" id="A2.1.1.3.1.1.8.8.1.1.2">2-5</span>
<span class="ltx_p" id="A2.1.1.3.1.1.8.8.1.1.3">
<span class="ltx_inline-block ltx_transformed_outer" id="A2.1.1.3.1.1.8.8.1.1.3.1" style="width:10.5pt;height:95.3pt;vertical-align:-44.7pt;"><span class="ltx_transformed_inner" style="width:95.2pt;transform:translate(-42.35pt,3.5pt) rotate(-90deg) ;">
<span class="ltx_p" id="A2.1.1.3.1.1.8.8.1.1.3.1.1"><span class="ltx_text" id="A2.1.1.3.1.1.8.8.1.1.3.1.1.1" style="font-size:171%;">—— Design ——</span></span>
</span></span></span>
</span></span>
<span class="ltx_td" id="A2.1.1.3.1.1.8.8.2" style="padding-top:3.5pt;padding-bottom:3.5pt;"></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.3.1.1.8.8.3" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.3.1.1.8.8.3.1">
<span class="ltx_p" id="A2.1.1.3.1.1.8.8.3.1.1">Data availability in taxonomy design</span>
</span></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.3.1.1.8.8.4" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.3.1.1.8.8.4.1">
<span class="ltx_p" id="A2.1.1.3.1.1.8.8.4.1.1">Designing taxonomy with knowledge of data (un)availability in mind</span>
</span></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.3.1.1.8.8.5" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.3.1.1.8.8.5.1">
<span class="ltx_p" id="A2.1.1.3.1.1.8.8.5.1.1"><em class="ltx_emph ltx_font_italic" id="A2.1.1.3.1.1.8.8.5.1.1.1">“The basic challenge is actually the availability of the data … So, you need to set up boundaries in your research. I discuss the certain limitation on this issue in [our] paper. We don’t have information on gender because the healthcare system does not adopt non-binary gender attributes.”</em> (P1)</span>
</span></span></span>
<span class="ltx_tr" id="A2.1.1.3.1.1.9.9">
<span class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_colspan ltx_colspan_5" id="A2.1.1.3.1.1.9.9.1" style="padding-top:3.5pt;padding-bottom:3.5pt;"><span class="ltx_rule" style="width:100%;height:0.8pt;background:black;display:inline-block;"> </span></span></span>
<span class="ltx_tr" id="A2.1.1.3.1.1.10.10">
<span class="ltx_td" id="A2.1.1.3.1.1.10.10.1" style="padding-top:3.5pt;padding-bottom:3.5pt;"></span>
<span class="ltx_td" id="A2.1.1.3.1.1.10.10.2" style="padding-top:3.5pt;padding-bottom:3.5pt;"></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.3.1.1.10.10.3" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.3.1.1.10.10.3.1">
<span class="ltx_p" id="A2.1.1.3.1.1.10.10.3.1.1">Vendor transparency</span>
</span></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.3.1.1.10.10.4" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.3.1.1.10.10.4.1">
<span class="ltx_p" id="A2.1.1.3.1.1.10.10.4.1.1">Working with data vendors can hinder fairness efforts</span>
</span></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.3.1.1.10.10.5" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.3.1.1.10.10.5.1">
<span class="ltx_p" id="A2.1.1.3.1.1.10.10.5.1.1"><em class="ltx_emph ltx_font_italic" id="A2.1.1.3.1.1.10.10.5.1.1.1">“Communication is difficult on platforms like [ANONYMIZED VENDOR PLATFORM]. It’s a little bit easier on other platforms, but that has definitely been a blocker. It is like easy communication just doesn’t exist.”</em> (P6)</span>
</span></span></span>
<span class="ltx_tr" id="A2.1.1.3.1.1.11.11">
<span class="ltx_td ltx_nopad_r ltx_align_justify" id="A2.1.1.3.1.1.11.11.1" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.3.1.1.11.11.1.1"><span class="ltx_ERROR undefined" id="A2.1.1.3.1.1.11.11.1.1.1">\cdashline</span>
<span class="ltx_p" id="A2.1.1.3.1.1.11.11.1.1.2">2-5</span>
</span></span>
<span class="ltx_td" id="A2.1.1.3.1.1.11.11.2" style="padding-top:3.5pt;padding-bottom:3.5pt;"></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.3.1.1.11.11.3" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.3.1.1.11.11.3.1">
<span class="ltx_p" id="A2.1.1.3.1.1.11.11.3.1.1">Language barriers</span>
</span></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.3.1.1.11.11.4" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.3.1.1.11.11.4.1">
<span class="ltx_p" id="A2.1.1.3.1.1.11.11.4.1.1">Navigating language barriers between curators and data workers and/or data</span>
</span></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.3.1.1.11.11.5" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.3.1.1.11.11.5.1">
<span class="ltx_p" id="A2.1.1.3.1.1.11.11.5.1.1"><em class="ltx_emph ltx_font_italic" id="A2.1.1.3.1.1.11.11.5.1.1.1">“So, we relied on our translators to come up with those sorts of decisions in terms in terms of Spanish. We did. Some of us didn’t know Spanish, not natively and fluently.”</em> (P3)</span>
</span></span></span>
<span class="ltx_tr" id="A2.1.1.3.1.1.12.12">
<span class="ltx_td ltx_nopad_r ltx_align_justify" id="A2.1.1.3.1.1.12.12.1" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.3.1.1.12.12.1.1"><span class="ltx_ERROR undefined" id="A2.1.1.3.1.1.12.12.1.1.1">\cdashline</span>
<span class="ltx_p" id="A2.1.1.3.1.1.12.12.1.1.2">2-5</span>
</span></span>
<span class="ltx_td" id="A2.1.1.3.1.1.12.12.2" style="padding-top:3.5pt;padding-bottom:3.5pt;"></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.3.1.1.12.12.3" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.3.1.1.12.12.3.1">
<span class="ltx_p" id="A2.1.1.3.1.1.12.12.3.1.1">Fair data labor</span>
</span></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.3.1.1.12.12.4" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.3.1.1.12.12.4.1">
<span class="ltx_p" id="A2.1.1.3.1.1.12.12.4.1.1">Ensuring data workers are treated and compensated fairly while navigating resource and regulatory constraints</span>
</span></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.3.1.1.12.12.5" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.3.1.1.12.12.5.1">
<span class="ltx_p" id="A2.1.1.3.1.1.12.12.5.1.1"><em class="ltx_emph ltx_font_italic" id="A2.1.1.3.1.1.12.12.5.1.1.1">“Especially, because so many platforms don’t actually ensure that you’re fairly compensating workers. And it’s really up to the individual researchers which is a crazy system that sets absolutely the wrong incentives.”</em> (P6)</span>
</span></span></span>
<span class="ltx_tr" id="A2.1.1.3.1.1.13.13">
<span class="ltx_td" id="A2.1.1.3.1.1.13.13.1" style="padding-top:3.5pt;padding-bottom:3.5pt;"></span>
<span class="ltx_td ltx_border_t" id="A2.1.1.3.1.1.13.13.2" style="padding-top:3.5pt;padding-bottom:3.5pt;"></span>
<span class="ltx_td ltx_align_justify ltx_border_t" id="A2.1.1.3.1.1.13.13.3" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.3.1.1.13.13.3.1">
<span class="ltx_p" id="A2.1.1.3.1.1.13.13.3.1.1">Diverse data availability</span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_border_t" id="A2.1.1.3.1.1.13.13.4" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.3.1.1.13.13.4.1">
<span class="ltx_p" id="A2.1.1.3.1.1.13.13.4.1.1">Difficulties collecting sufficiently diverse or representative data during the data collection process</span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_border_t" id="A2.1.1.3.1.1.13.13.5" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.3.1.1.13.13.5.1">
<span class="ltx_p" id="A2.1.1.3.1.1.13.13.5.1.1"><em class="ltx_emph ltx_font_italic" id="A2.1.1.3.1.1.13.13.5.1.1.1">“Because when I look at images of stoves on the Internet….. The reason those images are up on the Internet is because they satisfy something other than someone’s going to use to train a machine learning model. So, people put them up because they think it’s something new or exciting, or something different in some way. So, a lot of stoves that are there for ImageNet are basically like product images from stores that they sell. So, the stoves always look very clean and new and things like that.”</em> (P12)</span>
</span></span></span>
<span class="ltx_tr" id="A2.1.1.3.1.1.14.14">
<span class="ltx_td ltx_nopad_r ltx_align_justify" id="A2.1.1.3.1.1.14.14.1" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.3.1.1.14.14.1.1"><span class="ltx_ERROR undefined" id="A2.1.1.3.1.1.14.14.1.1.1">\cdashline</span>
<span class="ltx_p" id="A2.1.1.3.1.1.14.14.1.1.2">3-5</span>
</span></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.3.1.1.14.14.2" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.3.1.1.14.14.2.1">
<span class="ltx_p" id="A2.1.1.3.1.1.14.14.2.1.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="A2.1.1.3.1.1.14.14.2.1.1.1">Data Collection</span></span>
</span></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.3.1.1.14.14.3" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.3.1.1.14.14.3.1">
<span class="ltx_p" id="A2.1.1.3.1.1.14.14.3.1.1">Data collector availability</span>
</span></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.3.1.1.14.14.4" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.3.1.1.14.14.4.1">
<span class="ltx_p" id="A2.1.1.3.1.1.14.14.4.1.1">Identifying data collectors who can collect underrepresented data</span>
</span></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.3.1.1.14.14.5" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.3.1.1.14.14.5.1">
<span class="ltx_p" id="A2.1.1.3.1.1.14.14.5.1.1"><em class="ltx_emph ltx_font_italic" id="A2.1.1.3.1.1.14.14.5.1.1.1">“Because it very much depends on where we can get hold of people, right? And by that, I mean where it is up and has its workforce. And also how much money [does it cost] because it becomes more expensive as you’re trying to get a lot of people from very, very small regions.”</em> (P12)</span>
</span></span></span>
<span class="ltx_tr" id="A2.1.1.3.1.1.15.15">
<span class="ltx_td ltx_align_justify" id="A2.1.1.3.1.1.15.15.1" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.3.1.1.15.15.1.1">
<span class="ltx_p" id="A2.1.1.3.1.1.15.15.1.1.1">
<span class="ltx_inline-block ltx_transformed_outer" id="A2.1.1.3.1.1.15.15.1.1.1.1" style="width:10.7pt;height:398.6pt;vertical-align:-196.3pt;"><span class="ltx_transformed_inner" style="width:398.7pt;transform:translate(-194pt,3.5pt) rotate(-90deg) ;">
<span class="ltx_p" id="A2.1.1.3.1.1.15.15.1.1.1.1.1"><span class="ltx_text" id="A2.1.1.3.1.1.15.15.1.1.1.1.1.1" style="font-size:171%;">————————————– Implementation ————————————–</span></span>
</span></span></span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_border_t" id="A2.1.1.3.1.1.15.15.2" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.3.1.1.15.15.2.1">
<span class="ltx_p" id="A2.1.1.3.1.1.15.15.2.1.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="A2.1.1.3.1.1.15.15.2.1.1.1">Data Annotation</span></span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_border_t" id="A2.1.1.3.1.1.15.15.3" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.3.1.1.15.15.3.1">
<span class="ltx_p" id="A2.1.1.3.1.1.15.15.3.1.1">Data annotator diversity and expertise</span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_border_t" id="A2.1.1.3.1.1.15.15.4" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.3.1.1.15.15.4.1">
<span class="ltx_p" id="A2.1.1.3.1.1.15.15.4.1.1">Identifying data annotators with situated expertise</span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_border_t" id="A2.1.1.3.1.1.15.15.5" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.3.1.1.15.15.5.1">
<span class="ltx_p" id="A2.1.1.3.1.1.15.15.5.1.1"><em class="ltx_emph ltx_font_italic" id="A2.1.1.3.1.1.15.15.5.1.1.1">“The challenges in actually getting diverse annotators. Especially for like, let’s say, there have been recent studies, or there has been one paper that talks about how the views of a person or a kind of how the views of the person affect the annotations that they do for hate speech. So, like people with certain social, certain political viewpoints, might annotate something as hate while others might not. And so how do you get diversity in your annotators? Because some of the attributes of their personal lives might even be illegal to ask about in a particular country … And once you have it, how do you contextualize their annotations to their lived experiences?”</em> (P2)</span>
</span></span></span>
<span class="ltx_tr" id="A2.1.1.3.1.1.16.16">
<span class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_colspan ltx_colspan_5" id="A2.1.1.3.1.1.16.16.1" style="padding-top:3.5pt;padding-bottom:3.5pt;"><span class="ltx_rule" style="width:100%;height:0.8pt;background:black;display:inline-block;"> </span></span></span>
<span class="ltx_tr" id="A2.1.1.3.1.1.17.17">
<span class="ltx_td ltx_align_right ltx_colspan ltx_colspan_5" id="A2.1.1.3.1.1.17.17.1" style="padding-top:3.5pt;padding-bottom:3.5pt;"><span class="ltx_text" id="A2.1.1.3.1.1.17.17.1.1" style="font-size:71%;">(Continued on next page…)</span></span></span>
</span>
</span>
</span><span class="ltx_text" id="A2.1.1.3.2" style="font-size:70%;"></span></p>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel" id="A2.1.1.4"><span class="ltx_text ltx_inline-block" id="A2.1.1.4.1" style="font-size:70%;width:433.6pt;">
<span class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A2.1.1.4.1.1">
<span class="ltx_thead">
<span class="ltx_tr" id="A2.1.1.4.1.1.1.1">
<span class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_th ltx_th_column ltx_colspan ltx_colspan_5" id="A2.1.1.4.1.1.1.1.1" style="padding-top:3.5pt;padding-bottom:3.5pt;"><span class="ltx_rule" style="width:100%;height:0.8pt;background:black;display:inline-block;"> </span></span></span>
<span class="ltx_tr" id="A2.1.1.4.1.1.2.2">
<span class="ltx_td ltx_align_justify ltx_th ltx_th_column" id="A2.1.1.4.1.1.2.2.1" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.4.1.1.2.2.1.1">
<span class="ltx_p" id="A2.1.1.4.1.1.2.2.1.1.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="A2.1.1.4.1.1.2.2.1.1.1.1">Phase</span></span>
</span></span>
<span class="ltx_td ltx_th ltx_th_column" id="A2.1.1.4.1.1.2.2.2" style="padding-top:3.5pt;padding-bottom:3.5pt;"></span>
<span class="ltx_td ltx_align_justify ltx_th ltx_th_column" id="A2.1.1.4.1.1.2.2.3" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.4.1.1.2.2.3.1">
<span class="ltx_p" id="A2.1.1.4.1.1.2.2.3.1.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="A2.1.1.4.1.1.2.2.3.1.1.1">Challenge(s)</span></span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_th ltx_th_column" id="A2.1.1.4.1.1.2.2.4" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.4.1.1.2.2.4.1">
<span class="ltx_p" id="A2.1.1.4.1.1.2.2.4.1.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="A2.1.1.4.1.1.2.2.4.1.1.1">Definition</span></span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_th ltx_th_column" id="A2.1.1.4.1.1.2.2.5" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.4.1.1.2.2.5.1">
<span class="ltx_p" id="A2.1.1.4.1.1.2.2.5.1.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="A2.1.1.4.1.1.2.2.5.1.1.1">Example</span></span>
</span></span></span>
<span class="ltx_tr" id="A2.1.1.4.1.1.3.3">
<span class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_th ltx_th_column ltx_colspan ltx_colspan_5" id="A2.1.1.4.1.1.3.3.1" style="padding-top:3.5pt;padding-bottom:3.5pt;"><span class="ltx_rule" style="width:100%;height:0.8pt;background:black;display:inline-block;"> </span></span></span>
</span>
<span class="ltx_tbody">
<span class="ltx_tr" id="A2.1.1.4.1.1.4.1">
<span class="ltx_td" id="A2.1.1.4.1.1.4.1.1" style="padding-top:3.5pt;padding-bottom:3.5pt;"></span>
<span class="ltx_td ltx_align_justify ltx_th ltx_th_column" id="A2.1.1.4.1.1.4.1.2" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.4.1.1.4.1.2.1">
<span class="ltx_p" id="A2.1.1.4.1.1.4.1.2.1.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="A2.1.1.4.1.1.4.1.2.1.1.1">Data Quality</span></span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_th ltx_th_column" id="A2.1.1.4.1.1.4.1.3" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.4.1.1.4.1.3.1">
<span class="ltx_p" id="A2.1.1.4.1.1.4.1.3.1.1">Gold standard paradigms</span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_th ltx_th_column" id="A2.1.1.4.1.1.4.1.4" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.4.1.1.4.1.4.1">
<span class="ltx_p" id="A2.1.1.4.1.1.4.1.4.1.1">Models for assessing dataset quality can promote “unfairness”</span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_th ltx_th_column" id="A2.1.1.4.1.1.4.1.5" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.4.1.1.4.1.5.1">
<span class="ltx_p" id="A2.1.1.4.1.1.4.1.5.1.1"><em class="ltx_emph ltx_font_italic" id="A2.1.1.4.1.1.4.1.5.1.1.1">“There is no ground truth to that question.It can vary from a person’s lived experiences to the next. So, it is inherently a subjective question. So, we did not want to squash those annotations down to a majority quote.”</em> (P2)</span>
</span></span></span>
<span class="ltx_tr" id="A2.1.1.4.1.1.5.2">
<span class="ltx_td" id="A2.1.1.4.1.1.5.2.1" style="padding-top:3.5pt;padding-bottom:3.5pt;"></span>
<span class="ltx_td ltx_border_t" id="A2.1.1.4.1.1.5.2.2" style="padding-top:3.5pt;padding-bottom:3.5pt;"></span>
<span class="ltx_td ltx_align_justify ltx_border_t" id="A2.1.1.4.1.1.5.2.3" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.4.1.1.5.2.3.1">
<span class="ltx_p" id="A2.1.1.4.1.1.5.2.3.1.1">Lack of benchmarking datasets</span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_border_t" id="A2.1.1.4.1.1.5.2.4" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.4.1.1.5.2.4.1">
<span class="ltx_p" id="A2.1.1.4.1.1.5.2.4.1.1">Comparable benchmark datasets for which to evaluate new fair datasets are not available</span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_border_t" id="A2.1.1.4.1.1.5.2.5" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.4.1.1.5.2.5.1">
<span class="ltx_p" id="A2.1.1.4.1.1.5.2.5.1.1"><em class="ltx_emph ltx_font_italic" id="A2.1.1.4.1.1.5.2.5.1.1.1">“There’s a lot of pressure to do well benchmark data sets. And so, there’s a risk of them being used overused because you need to show that you did well on the data set that everyone recognizes, even if it might not be the most appropriate.”</em> (P21)</span>
</span></span></span>
<span class="ltx_tr" id="A2.1.1.4.1.1.6.3">
<span class="ltx_td ltx_nopad_r ltx_align_justify" id="A2.1.1.4.1.1.6.3.1" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.4.1.1.6.3.1.1"><span class="ltx_ERROR undefined" id="A2.1.1.4.1.1.6.3.1.1.1">\cdashline</span>
<span class="ltx_p" id="A2.1.1.4.1.1.6.3.1.1.2">3-5</span>
</span></span>
<span class="ltx_td" id="A2.1.1.4.1.1.6.3.2" style="padding-top:3.5pt;padding-bottom:3.5pt;"></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.4.1.1.6.3.3" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.4.1.1.6.3.3.1">
<span class="ltx_p" id="A2.1.1.4.1.1.6.3.3.1.1">Evaluating immeasurable constructs</span>
</span></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.4.1.1.6.3.4" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.4.1.1.6.3.4.1">
<span class="ltx_p" id="A2.1.1.4.1.1.6.3.4.1.1">Proving dataset quality when fairness constructs are not quantifiable</span>
</span></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.4.1.1.6.3.5" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.4.1.1.6.3.5.1">
<span class="ltx_p" id="A2.1.1.4.1.1.6.3.5.1.1"><em class="ltx_emph ltx_font_italic" id="A2.1.1.4.1.1.6.3.5.1.1.1">“I think quantitative methods almost always assume that fairness can be achieved in some way and they also often assume that there is already a robust definition of fairness that we’ve conceptualized and that we can use to test our systems. They also assume that fairness can be measured, can be evaluated and can be improved. And I think that all of this is a more positivist mindset.”</em> (P14)</span>
</span></span></span>
<span class="ltx_tr" id="A2.1.1.4.1.1.7.4">
<span class="ltx_td ltx_nopad_r ltx_align_justify" id="A2.1.1.4.1.1.7.4.1" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.4.1.1.7.4.1.1"><span class="ltx_ERROR undefined" id="A2.1.1.4.1.1.7.4.1.1.1">\cdashline</span>
<span class="ltx_p" id="A2.1.1.4.1.1.7.4.1.1.2">3-5

<span class="ltx_text" id="A2.1.1.4.1.1.7.4.1.1.2.1">
<span class="ltx_inline-block ltx_transformed_outer" id="A2.1.1.4.1.1.7.4.1.1.2.1.1" style="width:8.3pt;height:311.1pt;vertical-align:-151.4pt;"><span class="ltx_transformed_inner" style="width:311.1pt;transform:translate(-151.39pt,0pt) rotate(-90deg) ;">
<span class="ltx_p" id="A2.1.1.4.1.1.7.4.1.1.2.1.1.1"><span class="ltx_text" id="A2.1.1.4.1.1.7.4.1.1.2.1.1.1.1" style="font-size:171%;">—————————— Evaluation —————————— </span></span>
</span></span></span></span>
</span></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.4.1.1.7.4.2" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.4.1.1.7.4.2.1">
<span class="ltx_p" id="A2.1.1.4.1.1.7.4.2.1.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="A2.1.1.4.1.1.7.4.2.1.1.1">Data Utility</span></span>
</span></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.4.1.1.7.4.3" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.4.1.1.7.4.3.1">
<span class="ltx_p" id="A2.1.1.4.1.1.7.4.3.1.1">Spurious correlations</span>
</span></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.4.1.1.7.4.4" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.4.1.1.7.4.4.1">
<span class="ltx_p" id="A2.1.1.4.1.1.7.4.4.1.1">Accounting for and controlling spurious correlations</span>
</span></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.4.1.1.7.4.5" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.4.1.1.7.4.5.1">
<span class="ltx_p" id="A2.1.1.4.1.1.7.4.5.1.1"><em class="ltx_emph ltx_font_italic" id="A2.1.1.4.1.1.7.4.5.1.1.1">“So, then, what happens is there is a geography bias which is being incurred in this data sets implicitly, which is not really explicit. I’m gonna train the models on this. The models just exaggerate the bias and when this model is deployed on, say, android phones, or software or laptops, or anything, the consumers are worldwide, right?”</em> (P18)</span>
</span></span></span>
<span class="ltx_tr" id="A2.1.1.4.1.1.8.5">
<span class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_colspan ltx_colspan_5" id="A2.1.1.4.1.1.8.5.1" style="padding-top:3.5pt;padding-bottom:3.5pt;"><span class="ltx_rule" style="width:100%;height:0.8pt;background:black;display:inline-block;"> </span></span></span>
<span class="ltx_tr" id="A2.1.1.4.1.1.9.6">
<span class="ltx_td" id="A2.1.1.4.1.1.9.6.1" style="padding-top:3.5pt;padding-bottom:3.5pt;"></span>
<span class="ltx_td" id="A2.1.1.4.1.1.9.6.2" style="padding-top:3.5pt;padding-bottom:3.5pt;"></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.4.1.1.9.6.3" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.4.1.1.9.6.3.1">
<span class="ltx_p" id="A2.1.1.4.1.1.9.6.3.1.1">Unstable infrastructural ecosystems</span>
</span></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.4.1.1.9.6.4" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.4.1.1.9.6.4.1">
<span class="ltx_p" id="A2.1.1.4.1.1.9.6.4.1.1">Data in datasets may go missing or become deprecated, resulting in fairness issues</span>
</span></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.4.1.1.9.6.5" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.4.1.1.9.6.5.1">
<span class="ltx_p" id="A2.1.1.4.1.1.9.6.5.1.1"><em class="ltx_emph ltx_font_italic" id="A2.1.1.4.1.1.9.6.5.1.1.1">“I think maintenance is more going to be a matter of making sure that when links become deprecated, we maintain the same principles of trying to find a diverse range of images to replace it.”</em> (P8)</span>
</span></span></span>
<span class="ltx_tr" id="A2.1.1.4.1.1.10.7">
<span class="ltx_td ltx_nopad_r ltx_align_justify" id="A2.1.1.4.1.1.10.7.1" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.4.1.1.10.7.1.1"><span class="ltx_ERROR undefined" id="A2.1.1.4.1.1.10.7.1.1.1">\cdashline</span>
<span class="ltx_p" id="A2.1.1.4.1.1.10.7.1.1.2">2-5

<span class="ltx_text" id="A2.1.1.4.1.1.10.7.1.1.2.1">
<span class="ltx_inline-block ltx_transformed_outer" id="A2.1.1.4.1.1.10.7.1.1.2.1.1" style="width:8.2pt;height:106.6pt;vertical-align:-49.2pt;"><span class="ltx_transformed_inner" style="width:106.7pt;transform:translate(-49.23pt,0pt) rotate(-90deg) ;">
<span class="ltx_p" id="A2.1.1.4.1.1.10.7.1.1.2.1.1.1"><span class="ltx_text" id="A2.1.1.4.1.1.10.7.1.1.2.1.1.1.1" style="font-size:171%;">—- Maintenance —-</span></span>
</span></span></span></span>
</span></span>
<span class="ltx_td" id="A2.1.1.4.1.1.10.7.2" style="padding-top:3.5pt;padding-bottom:3.5pt;"></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.4.1.1.10.7.3" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.4.1.1.10.7.3.1">
<span class="ltx_p" id="A2.1.1.4.1.1.10.7.3.1.1">Dataset traceability mechanisms</span>
</span></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.4.1.1.10.7.4" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.4.1.1.10.7.4.1">
<span class="ltx_p" id="A2.1.1.4.1.1.10.7.4.1.1">Inability to track dataset usage or prevent misuses</span>
</span></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.4.1.1.10.7.5" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.4.1.1.10.7.5.1">
<span class="ltx_p" id="A2.1.1.4.1.1.10.7.5.1.1"><em class="ltx_emph ltx_font_italic" id="A2.1.1.4.1.1.10.7.5.1.1.1">“ there have been cases where a researcher reached out to me and said, ‘Hey, I tried this with your data set. I’m getting like these confusing results. Can we talk?’ And then I find out they’re using it in a way that wasn’t intended.”</em> (P6)</span>
</span></span></span>
<span class="ltx_tr" id="A2.1.1.4.1.1.11.8">
<span class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_colspan ltx_colspan_5" id="A2.1.1.4.1.1.11.8.1" style="padding-top:3.5pt;padding-bottom:3.5pt;"><span class="ltx_rule" style="width:100%;height:0.8pt;background:black;display:inline-block;"> </span></span></span>
</span>
</span>
</span><span class="ltx_text" id="A2.1.1.4.2" style="font-size:70%;"></span></p>
</div>
</div>
<figcaption class="ltx_caption" style="font-size:70%;"><span class="ltx_tag ltx_tag_table">Table 3: </span><span class="ltx_text" id="A2.1.1.7.1" style="font-size:129%;">A table describing each of the challenges throughout the phases of the dataset lifecycle.</span></figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_table ltx_figure_panel" id="A2.1.1.tab1">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel" id="A2.1.1.tab1.1"><span class="ltx_text ltx_inline-block" id="A2.1.1.tab1.1.1" style="font-size:70%;width:433.6pt;">
<span class="ltx_tabular ltx_align_middle" id="A2.1.1.tab1.1.1.1">
<span class="ltx_tbody">
<span class="ltx_tr" id="A2.1.1.tab1.1.1.1.1.1">
<span class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_colspan ltx_colspan_5" id="A2.1.1.tab1.1.1.1.1.1.1" style="padding-top:3.5pt;padding-bottom:3.5pt;"><span class="ltx_rule" style="width:100%;height:0.8pt;background:black;display:inline-block;"> </span></span></span>
<span class="ltx_tr" id="A2.1.1.tab1.1.1.1.2.2">
<span class="ltx_td ltx_align_justify" id="A2.1.1.tab1.1.1.1.2.2.1" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.tab1.1.1.1.2.2.1.1">
<span class="ltx_p" id="A2.1.1.tab1.1.1.1.2.2.1.1.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="A2.1.1.tab1.1.1.1.2.2.1.1.1.1">Phase</span></span>
</span></span>
<span class="ltx_td" id="A2.1.1.tab1.1.1.1.2.2.2" style="padding-top:3.5pt;padding-bottom:3.5pt;"></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.tab1.1.1.1.2.2.3" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.tab1.1.1.1.2.2.3.1">
<span class="ltx_p" id="A2.1.1.tab1.1.1.1.2.2.3.1.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="A2.1.1.tab1.1.1.1.2.2.3.1.1.1">Challenge(s)</span></span>
</span></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.tab1.1.1.1.2.2.4" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.tab1.1.1.1.2.2.4.1">
<span class="ltx_p" id="A2.1.1.tab1.1.1.1.2.2.4.1.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="A2.1.1.tab1.1.1.1.2.2.4.1.1.1">Definition</span></span>
</span></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.tab1.1.1.1.2.2.5" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.tab1.1.1.1.2.2.5.1">
<span class="ltx_p" id="A2.1.1.tab1.1.1.1.2.2.5.1.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="A2.1.1.tab1.1.1.1.2.2.5.1.1.1">Example</span></span>
</span></span></span>
<span class="ltx_tr" id="A2.1.1.tab1.1.1.1.3.3">
<span class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_colspan ltx_colspan_5" id="A2.1.1.tab1.1.1.1.3.3.1" style="padding-top:3.5pt;padding-bottom:3.5pt;"><span class="ltx_rule" style="width:100%;height:0.8pt;background:black;display:inline-block;"> </span></span></span>
<span class="ltx_tr" id="A2.1.1.tab1.1.1.1.4.4">
<span class="ltx_td" id="A2.1.1.tab1.1.1.1.4.4.1" style="padding-top:3.5pt;padding-bottom:3.5pt;"></span>
<span class="ltx_td ltx_align_justify ltx_rowspan ltx_rowspan_3" id="A2.1.1.tab1.1.1.1.4.4.2" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.tab1.1.1.1.4.4.2.1">
<span class="ltx_p" id="A2.1.1.tab1.1.1.1.4.4.2.1.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="A2.1.1.tab1.1.1.1.4.4.2.1.1.1">Individual</span></span>
</span></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.tab1.1.1.1.4.4.3" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.tab1.1.1.1.4.4.3.1">
<span class="ltx_p" id="A2.1.1.tab1.1.1.1.4.4.3.1.1">Individual contributor positionality</span>
</span></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.tab1.1.1.1.4.4.4" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.tab1.1.1.1.4.4.4.1">
<span class="ltx_p" id="A2.1.1.tab1.1.1.1.4.4.4.1.1">Every contributor to a dataset has their own positionality, including biases</span>
</span></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.tab1.1.1.1.4.4.5" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.tab1.1.1.1.4.4.5.1">
<span class="ltx_p" id="A2.1.1.tab1.1.1.1.4.4.5.1.1"><em class="ltx_emph ltx_font_italic" id="A2.1.1.tab1.1.1.1.4.4.5.1.1.1">“Even the idea of the perspectivism … Most obviously in my work is the research questions, and then the way it informs the direction of research, and even possibly down to the way we qualify how good a data set and how interesting a dataset is!”</em> (P24)</span>
</span></span></span>
<span class="ltx_tr" id="A2.1.1.tab1.1.1.1.5.5">
<span class="ltx_td" id="A2.1.1.tab1.1.1.1.5.5.1" style="padding-top:3.5pt;padding-bottom:3.5pt;"></span>
<span class="ltx_td ltx_align_justify ltx_border_t" id="A2.1.1.tab1.1.1.1.5.5.2" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.tab1.1.1.1.5.5.2.1">
<span class="ltx_p" id="A2.1.1.tab1.1.1.1.5.5.2.1.1">Recognition for fair dataset work</span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_border_t" id="A2.1.1.tab1.1.1.1.5.5.3" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.tab1.1.1.1.5.5.3.1">
<span class="ltx_p" id="A2.1.1.tab1.1.1.1.5.5.3.1.1">Datasets are undervalued in machine learning</span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_border_t" id="A2.1.1.tab1.1.1.1.5.5.4" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.tab1.1.1.1.5.5.4.1">
<span class="ltx_p" id="A2.1.1.tab1.1.1.1.5.5.4.1.1"><em class="ltx_emph ltx_font_italic" id="A2.1.1.tab1.1.1.1.5.5.4.1.1.1">“The right way is also rewarding people for doing it the right way right like the idea that you should be able to publish a data set and that be a valuable contribution, because in machine learning, it’s an extremely valuable contribution. And yet it’s not something that is valued.”</em> (P21)</span>
</span></span></span>
<span class="ltx_tr" id="A2.1.1.tab1.1.1.1.6.6">
<span class="ltx_td ltx_nopad_r ltx_align_justify" id="A2.1.1.tab1.1.1.1.6.6.1" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.tab1.1.1.1.6.6.1.1"><span class="ltx_ERROR undefined" id="A2.1.1.tab1.1.1.1.6.6.1.1.1">\cdashline</span>
<span class="ltx_p" id="A2.1.1.tab1.1.1.1.6.6.1.1.2">3-5</span>
</span></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.tab1.1.1.1.6.6.2" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.tab1.1.1.1.6.6.2.1">
<span class="ltx_p" id="A2.1.1.tab1.1.1.1.6.6.2.1.1">Awareness of existing resources and guidelines</span>
</span></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.tab1.1.1.1.6.6.3" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.tab1.1.1.1.6.6.3.1">
<span class="ltx_p" id="A2.1.1.tab1.1.1.1.6.6.3.1.1">Curators are unaware of existing resources for fair datasets or how to apply them</span>
</span></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.tab1.1.1.1.6.6.4" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.tab1.1.1.1.6.6.4.1">
<span class="ltx_p" id="A2.1.1.tab1.1.1.1.6.6.4.1.1"><em class="ltx_emph ltx_font_italic" id="A2.1.1.tab1.1.1.1.6.6.4.1.1.1">“If I recall like, I don’t like remember any explicit guidelines that I’ve stumbled through for fair data set collection. Honestly!”</em> (P29)</span>
</span></span></span>
<span class="ltx_tr" id="A2.1.1.tab1.1.1.1.7.7">
<span class="ltx_td ltx_nopad_r ltx_align_justify" id="A2.1.1.tab1.1.1.1.7.7.1" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.tab1.1.1.1.7.7.1.1"><span class="ltx_ERROR undefined" id="A2.1.1.tab1.1.1.1.7.7.1.1.1">\cdashline</span>
<span class="ltx_p" id="A2.1.1.tab1.1.1.1.7.7.1.1.2">3-5</span>
</span></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.tab1.1.1.1.7.7.2" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.tab1.1.1.1.7.7.2.1">
<span class="ltx_p" id="A2.1.1.tab1.1.1.1.7.7.2.1.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="A2.1.1.tab1.1.1.1.7.7.2.1.1.1">Discipline</span></span>
</span></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.tab1.1.1.1.7.7.3" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.tab1.1.1.1.7.7.3.1">
<span class="ltx_p" id="A2.1.1.tab1.1.1.1.7.7.3.1.1">Responsibility for fairness</span>
</span></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.tab1.1.1.1.7.7.4" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.tab1.1.1.1.7.7.4.1">
<span class="ltx_p" id="A2.1.1.tab1.1.1.1.7.7.4.1.1">Those with an awareness about fairness issues feel a responsibility to do fairness work, while those who are not aware are excused from fairness work</span>
</span></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.tab1.1.1.1.7.7.5" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.tab1.1.1.1.7.7.5.1">
<span class="ltx_p" id="A2.1.1.tab1.1.1.1.7.7.5.1.1"><em class="ltx_emph ltx_font_italic" id="A2.1.1.tab1.1.1.1.7.7.5.1.1.1">“In general, I will say the motivation is having fairness because you have this responsibility of understanding and improving transparency and improving general oversight on what we deploy.”</em> (P28)</span>
</span></span></span>
<span class="ltx_tr" id="A2.1.1.tab1.1.1.1.8.8">
<span class="ltx_td" id="A2.1.1.tab1.1.1.1.8.8.1" style="padding-top:3.5pt;padding-bottom:3.5pt;"></span>
<span class="ltx_td ltx_border_t" id="A2.1.1.tab1.1.1.1.8.8.2" style="padding-top:3.5pt;padding-bottom:3.5pt;"></span>
<span class="ltx_td ltx_align_justify ltx_border_t" id="A2.1.1.tab1.1.1.1.8.8.3" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.tab1.1.1.1.8.8.3.1">
<span class="ltx_p" id="A2.1.1.tab1.1.1.1.8.8.3.1.1">Lack of resources</span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_border_t" id="A2.1.1.tab1.1.1.1.8.8.4" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.tab1.1.1.1.8.8.4.1">
<span class="ltx_p" id="A2.1.1.tab1.1.1.1.8.8.4.1.1">Fair dataset work is not given resources in the form of time, money, personnel, tools, etc.</span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_border_t" id="A2.1.1.tab1.1.1.1.8.8.5" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.tab1.1.1.1.8.8.5.1">
<span class="ltx_p" id="A2.1.1.tab1.1.1.1.8.8.5.1.1"><em class="ltx_emph ltx_font_italic" id="A2.1.1.tab1.1.1.1.8.8.5.1.1.1">“Research is driven by building bigger and bigger models and that is increasingly, punitively expensive. From a resource standpoint, from a money standpoint, from an environmental standpoint. And data has, in general, been undervalued in machine learning. </em> (P21)</span>
</span></span></span>
<span class="ltx_tr" id="A2.1.1.tab1.1.1.1.9.9">
<span class="ltx_td ltx_nopad_r ltx_align_justify" id="A2.1.1.tab1.1.1.1.9.9.1" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.tab1.1.1.1.9.9.1.1"><span class="ltx_ERROR undefined" id="A2.1.1.tab1.1.1.1.9.9.1.1.1">\cdashline</span>
<span class="ltx_p" id="A2.1.1.tab1.1.1.1.9.9.1.1.2">3-5</span>
</span></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.tab1.1.1.1.9.9.2" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.tab1.1.1.1.9.9.2.1">
<span class="ltx_p" id="A2.1.1.tab1.1.1.1.9.9.2.1.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="A2.1.1.tab1.1.1.1.9.9.2.1.1.1">Organization</span></span>
</span></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.tab1.1.1.1.9.9.3" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.tab1.1.1.1.9.9.3.1">
<span class="ltx_p" id="A2.1.1.tab1.1.1.1.9.9.3.1.1">Ethics washing</span>
</span></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.tab1.1.1.1.9.9.4" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.tab1.1.1.1.9.9.4.1">
<span class="ltx_p" id="A2.1.1.tab1.1.1.1.9.9.4.1.1">Fairness is treated as a marketing tactic rather than necessary</span>
</span></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.tab1.1.1.1.9.9.5" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.tab1.1.1.1.9.9.5.1">
<span class="ltx_p" id="A2.1.1.tab1.1.1.1.9.9.5.1.1"><em class="ltx_emph ltx_font_italic" id="A2.1.1.tab1.1.1.1.9.9.5.1.1.1">“One of the big reasons a lot of big companies do responsible AI shenanigans is for marketing … then a new shiny thing comes down the road and then they join that instead.”</em> (P22)</span>
</span></span></span>
<span class="ltx_tr" id="A2.1.1.tab1.1.1.1.10.10">
<span class="ltx_td" id="A2.1.1.tab1.1.1.1.10.10.1" style="padding-top:3.5pt;padding-bottom:3.5pt;"></span>
<span class="ltx_td ltx_border_t" id="A2.1.1.tab1.1.1.1.10.10.2" style="padding-top:3.5pt;padding-bottom:3.5pt;"></span>
<span class="ltx_td ltx_align_justify ltx_border_t" id="A2.1.1.tab1.1.1.1.10.10.3" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.tab1.1.1.1.10.10.3.1">
<span class="ltx_p" id="A2.1.1.tab1.1.1.1.10.10.3.1.1">Differing legal practices</span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_border_t" id="A2.1.1.tab1.1.1.1.10.10.4" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.tab1.1.1.1.10.10.4.1">
<span class="ltx_p" id="A2.1.1.tab1.1.1.1.10.10.4.1.1">Laws, regulations, and policies governing fairness differ by context</span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_border_t" id="A2.1.1.tab1.1.1.1.10.10.5" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.tab1.1.1.1.10.10.5.1">
<span class="ltx_p" id="A2.1.1.tab1.1.1.1.10.10.5.1.1"><em class="ltx_emph ltx_font_italic" id="A2.1.1.tab1.1.1.1.10.10.5.1.1.1">“Laws in America or laws in Europe … might not be directly applicable to a country like [in South Asia] that has very different societal situation.”</em> (P2)</span>
</span></span></span>
<span class="ltx_tr" id="A2.1.1.tab1.1.1.1.11.11">
<span class="ltx_td ltx_nopad_r ltx_align_justify" id="A2.1.1.tab1.1.1.1.11.11.1" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.tab1.1.1.1.11.11.1.1"><span class="ltx_ERROR undefined" id="A2.1.1.tab1.1.1.1.11.11.1.1.1">\cdashline</span>
<span class="ltx_p" id="A2.1.1.tab1.1.1.1.11.11.1.1.2">3-5</span>
</span></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.tab1.1.1.1.11.11.2" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.tab1.1.1.1.11.11.2.1">
<span class="ltx_p" id="A2.1.1.tab1.1.1.1.11.11.2.1.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="A2.1.1.tab1.1.1.1.11.11.2.1.1.1">Regulatory</span></span>
</span></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.tab1.1.1.1.11.11.3" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.tab1.1.1.1.11.11.3.1">
<span class="ltx_p" id="A2.1.1.tab1.1.1.1.11.11.3.1.1">Limited regulatory literacy</span>
</span></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.tab1.1.1.1.11.11.4" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.tab1.1.1.1.11.11.4.1">
<span class="ltx_p" id="A2.1.1.tab1.1.1.1.11.11.4.1.1">Dataset curators are not equipped to understand the regulatory landscape</span>
</span></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.tab1.1.1.1.11.11.5" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.tab1.1.1.1.11.11.5.1">
<span class="ltx_p" id="A2.1.1.tab1.1.1.1.11.11.5.1.1"><em class="ltx_emph ltx_font_italic" id="A2.1.1.tab1.1.1.1.11.11.5.1.1.1">“It was a big learning curve to understand what we were allowed to store and what we weren’t in terms of the legal sense. So, it was a challenge to us personally, because we didn’t have experience. So, we consulted with an IP lawyer to get insight into that, but really just making sure that what we were presenting and storing was legal.”</em> (P8)</span>
</span></span></span>
<span class="ltx_tr" id="A2.1.1.tab1.1.1.1.12.12">
<span class="ltx_td" id="A2.1.1.tab1.1.1.1.12.12.1" style="padding-top:3.5pt;padding-bottom:3.5pt;"></span>
<span class="ltx_td ltx_border_t" id="A2.1.1.tab1.1.1.1.12.12.2" style="padding-top:3.5pt;padding-bottom:3.5pt;"></span>
<span class="ltx_td ltx_align_justify ltx_border_t" id="A2.1.1.tab1.1.1.1.12.12.3" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.tab1.1.1.1.12.12.3.1">
<span class="ltx_p" id="A2.1.1.tab1.1.1.1.12.12.3.1.1">Evolution and contestability of fairness</span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_border_t" id="A2.1.1.tab1.1.1.1.12.12.4" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.tab1.1.1.1.12.12.4.1">
<span class="ltx_p" id="A2.1.1.tab1.1.1.1.12.12.4.1.1">Perspectives and policies on fairness evolve over time, constantly evolving the landscape of what a fair dataset is</span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_border_t" id="A2.1.1.tab1.1.1.1.12.12.5" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.tab1.1.1.1.12.12.5.1">
<span class="ltx_p" id="A2.1.1.tab1.1.1.1.12.12.5.1.1"><em class="ltx_emph ltx_font_italic" id="A2.1.1.tab1.1.1.1.12.12.5.1.1.1">“The question [of] whether fairness should be defined through a singular definition within a specific instrument is tricky because … It should be a notion that is able to evolve within society, and certain forms of injustice that were not considered injustice in in the past now are. If we looked at the position of members of the LGBTQIA+ community, it was criminalized. Racism was also accepted. Now we clearly say it’s not so. There might be other evolution towards the future that we currently do not incorporate in our definition of fairness, and we need to account for that.”</em> (P16)</span>
</span></span></span>
<span class="ltx_tr" id="A2.1.1.tab1.1.1.1.13.13">
<span class="ltx_td ltx_nopad_r ltx_align_justify" id="A2.1.1.tab1.1.1.1.13.13.1" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.tab1.1.1.1.13.13.1.1"><span class="ltx_ERROR undefined" id="A2.1.1.tab1.1.1.1.13.13.1.1.1">\cdashline</span>
<span class="ltx_p" id="A2.1.1.tab1.1.1.1.13.13.1.1.2">3-5</span>
</span></span>
<span class="ltx_td" id="A2.1.1.tab1.1.1.1.13.13.2" style="padding-top:3.5pt;padding-bottom:3.5pt;"></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.tab1.1.1.1.13.13.3" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.tab1.1.1.1.13.13.3.1">
<span class="ltx_p" id="A2.1.1.tab1.1.1.1.13.13.3.1.1">Social realities versus model realities</span>
</span></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.tab1.1.1.1.13.13.4" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.tab1.1.1.1.13.13.4.1">
<span class="ltx_p" id="A2.1.1.tab1.1.1.1.13.13.4.1.1">The “real” world is inherently complex and multifaceted, but machine learning datasets (and downstream models) require more simplistic approaches</span>
</span></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.tab1.1.1.1.13.13.5" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.tab1.1.1.1.13.13.5.1">
<span class="ltx_p" id="A2.1.1.tab1.1.1.1.13.13.5.1.1"><em class="ltx_emph ltx_font_italic" id="A2.1.1.tab1.1.1.1.13.13.5.1.1.1">“Benchmark[s] which are made for fairness … still have a very structured, kind of neutral way of portraying things like race or gender that don’t actually engage with the socio-historical meaning of that.</em> (P11)</span>
</span></span></span>
<span class="ltx_tr" id="A2.1.1.tab1.1.1.1.14.14">
<span class="ltx_td ltx_nopad_r ltx_align_justify" id="A2.1.1.tab1.1.1.1.14.14.1" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.tab1.1.1.1.14.14.1.1"><span class="ltx_ERROR undefined" id="A2.1.1.tab1.1.1.1.14.14.1.1.1">\cdashline</span>
<span class="ltx_p" id="A2.1.1.tab1.1.1.1.14.14.1.1.2">3-5</span>
<span class="ltx_p" id="A2.1.1.tab1.1.1.1.14.14.1.1.3">
<span class="ltx_inline-block ltx_transformed_outer" id="A2.1.1.tab1.1.1.1.14.14.1.1.3.1" style="width:17.2pt;height:435.7pt;vertical-align:-218.1pt;"><span class="ltx_transformed_inner" style="width:435.7pt;transform:translate(-209.28pt,13.25pt) rotate(-90deg) ;">
<span class="ltx_p" id="A2.1.1.tab1.1.1.1.14.14.1.1.3.1.1"><span class="ltx_text" id="A2.1.1.tab1.1.1.1.14.14.1.1.3.1.1.1" style="font-size:171%;">———————————————————————— Overarching ———————————————————————</span></span>
</span></span></span>
</span></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.tab1.1.1.1.14.14.2" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.tab1.1.1.1.14.14.2.1">
<span class="ltx_p" id="A2.1.1.tab1.1.1.1.14.14.2.1.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="A2.1.1.tab1.1.1.1.14.14.2.1.1.1">Socio-Political</span></span>
</span></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.tab1.1.1.1.14.14.3" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.tab1.1.1.1.14.14.3.1">
<span class="ltx_p" id="A2.1.1.tab1.1.1.1.14.14.3.1.1">Power differentials</span>
</span></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.tab1.1.1.1.14.14.4" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.tab1.1.1.1.14.14.4.1">
<span class="ltx_p" id="A2.1.1.tab1.1.1.1.14.14.4.1.1">Different institutions (e.g., industry vs. academia; elite universities vs. R3s), actors (e.g., data curators vs data workers), and regions (e.g., the West vs the Rest) have different power to shape fairness concepts and practices</span>
</span></span>
<span class="ltx_td ltx_align_justify" id="A2.1.1.tab1.1.1.1.14.14.5" style="padding-top:3.5pt;padding-bottom:3.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.1.1.tab1.1.1.1.14.14.5.1">
<span class="ltx_p" id="A2.1.1.tab1.1.1.1.14.14.5.1.1"><em class="ltx_emph ltx_font_italic" id="A2.1.1.tab1.1.1.1.14.14.5.1.1.1">“I mean you hear of data coming from these marginalized regions but then this is centralization process with one institution getting credit for it and the reputations of other countries not sharing that credits and some not reaping benefits of it. So, there’s especially in countries that are poorer, there’s then less incentive for them to actually contribute to datasets.”</em> (P8)</span>
</span></span></span>
<span class="ltx_tr" id="A2.1.1.tab1.1.1.1.15.15">
<span class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_colspan ltx_colspan_5" id="A2.1.1.tab1.1.1.1.15.15.1" style="padding-top:3.5pt;padding-bottom:3.5pt;"><span class="ltx_rule" style="width:100%;height:0.8pt;background:black;display:inline-block;"> </span></span></span>
</span>
</span>
</span><span class="ltx_text" id="A2.1.1.tab1.1.2" style="font-size:70%;"></span></p>
</div>
</div>
<figcaption class="ltx_caption" style="font-size:70%;"><span class="ltx_tag ltx_tag_table">Table 4: </span><span class="ltx_text" id="A2.1.1.tab1.4.1" style="font-size:129%;">A table describing each of the challenges overarching the broader landscape of fairness</span></figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<section class="ltx_appendix ltx_figure_panel" id="A3">
<h2 class="ltx_title ltx_title_appendix" style="font-size:70%;">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Detailed Recommendations for Enabling Fair Dataset Curation</h2>
<div class="ltx_para" id="A3.p1">
<p class="ltx_p" id="A3.p1.1"><span class="ltx_text" id="A3.p1.1.1" style="font-size:70%;">Recommendations are aimed at diverse stakeholders influencing fair dataset curation, including—but not limited to—individual contributors, academic institutions and venues, industrial organizations, policymakers, and the affected public. Unlike in the main body of the text, where we describe the challenges with the dataset lifecycle first and the challenges with the overarching landscape of fairness second, here, we present considerations with the overarching landscape foremost. We also begin with the highest level of the dataset landscape, the </span><em class="ltx_emph ltx_font_italic" id="A3.p1.1.2" style="font-size:70%;">socio-political level</em><span class="ltx_text" id="A3.p1.1.3" style="font-size:70%;">, rather than the lowest, the </span><em class="ltx_emph ltx_font_italic" id="A3.p1.1.4" style="font-size:70%;">individual level</em><span class="ltx_text" id="A3.p1.1.5" style="font-size:70%;">. Our goal is to underscore how top-down changes can have broader impacts downstream on individual data curators and the dataset lifecycle. We advocate for more systemic changes rather than placing the onus of fairness onto individuals. The following recommendations in </span><a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#A3.SS1" style="font-size:70%;" title="C.1 Recommendations Overarching the Broader Landscape of Fairness ‣ Appendix C Detailed Recommendations for Enabling Fair Dataset Curation ‣ Appendix B Additional Figures and Tables ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_tag">Sections</span> <span class="ltx_text ltx_ref_tag">C.1</span></a><span class="ltx_text" id="A3.p1.1.6" style="font-size:70%;"> and </span><a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#A3.SS2" style="font-size:70%;" title="C.2 Recommendations During the Dataset Lifecycle ‣ Appendix C Detailed Recommendations for Enabling Fair Dataset Curation ‣ Appendix B Additional Figures and Tables ‣ A Taxonomy of Challenges to Curating Fair Datasets"><span class="ltx_text ltx_ref_tag">C.2</span></a><span class="ltx_text" id="A3.p1.1.7" style="font-size:70%;"> are examples. We imagine there are many more interventions which would be effective in improving fair dataset curation.</span></p>
</div>
<section class="ltx_subsection" id="A3.SS1">
<h3 class="ltx_title ltx_title_subsection" style="font-size:70%;">
<span class="ltx_tag ltx_tag_subsection">C.1 </span>Recommendations Overarching the Broader Landscape of Fairness </h3>
<section class="ltx_subsubsection" id="A3.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection" style="font-size:70%;">
<span class="ltx_tag ltx_tag_subsubsection">C.1.1 </span>Socio-Political Level</h4>
<div class="ltx_para ltx_noindent" id="A3.SS1.SSS1.p1">
<p class="ltx_p" id="A3.SS1.SSS1.p1.1"><span class="ltx_text ltx_font_bold" id="A3.SS1.SSS1.p1.1.1" style="font-size:70%;">Evolution and contestability of fairness.</span><span class="ltx_text" id="A3.SS1.SSS1.p1.1.2" style="font-size:70%;"> As conceptualizations of fairness inevitably change, curators should aim to keep datasets up-to-date. For example, we recommend that curators revise and amend datasets to comply with new conceptualizations of fairness. For example, </span><cite class="ltx_cite ltx_citemacro_citet">Yang et al. <span class="ltx_text" id="A3.SS1.SSS1.p1.1.3.1.1.1" style="font-size:70%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib157" title="">157</a><span class="ltx_text" id="A3.SS1.SSS1.p1.1.4.2.2.1" style="font-size:70%;">]</span></cite><span class="ltx_text" id="A3.SS1.SSS1.p1.1.5" style="font-size:70%;"> obfuscated faces in ImageNet after release as an effort to mitigate concerns about data subject privacy. Furthermore, when datasets cannot be aligned with new standards, norms, laws, or policies surrounding fairness, they ought to be deprecated and no longer used. Curators can refer to </span><cite class="ltx_cite ltx_citemacro_citet">Luccioni et al. <span class="ltx_text" id="A3.SS1.SSS1.p1.1.6.1.1.1" style="font-size:70%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib90" title="">90</a><span class="ltx_text" id="A3.SS1.SSS1.p1.1.7.2.2.1" style="font-size:70%;">]</span></cite><span class="ltx_text" id="A3.SS1.SSS1.p1.1.8" style="font-size:70%;">’s framework for retracting and deprecating datasets to better understand this process.</span></p>
</div>
<div class="ltx_para" id="A3.SS1.SSS1.p2">
<p class="ltx_p" id="A3.SS1.SSS1.p2.1"><span class="ltx_text" id="A3.SS1.SSS1.p2.1.1" style="font-size:70%;">We also recommend that data curators clearly document the decisions that were made about contextually and temporally relevant definitions of fairness. Thus, even if the original curator cannot afford to update the dataset, others can continue to maintain its documentation pointing toward new research showing the issues with past fairness operationalizations.</span></p>
</div>
<div class="ltx_para ltx_noindent" id="A3.SS1.SSS1.p3">
<p class="ltx_p" id="A3.SS1.SSS1.p3.1"><span class="ltx_text ltx_font_bold" id="A3.SS1.SSS1.p3.1.1" style="font-size:70%;">Social realities versus model realities.</span><span class="ltx_text" id="A3.SS1.SSS1.p3.1.2" style="font-size:70%;">
We recommend dataset curators engage with affected communities to understand the needs and potential impacts datasets and downstream models have on the lives of real people. This includes situating data curation decisions in the experiences and perspectives of affected communities. For example, </span><cite class="ltx_cite ltx_citemacro_citet">Kuo et al. <span class="ltx_text" id="A3.SS1.SSS1.p3.1.3.1.1.1" style="font-size:70%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib84" title="">84</a><span class="ltx_text" id="A3.SS1.SSS1.p3.1.4.2.2.1" style="font-size:70%;">]</span></cite><span class="ltx_text" id="A3.SS1.SSS1.p3.1.5" style="font-size:70%;"> introduced WikiBench, a system for creating community-driven evaluation dataset on Wikipedia. Using WikiBench, community members can work together to select, label, and discuss instances for an evaluation dataset. Adopting a more participatory and bottom-up approach allows dataset curators to ensure that they are capturing the concepts most relevant to impacted communities.</span></p>
</div>
<div class="ltx_para ltx_noindent" id="A3.SS1.SSS1.p4">
<p class="ltx_p" id="A3.SS1.SSS1.p4.1"><span class="ltx_text ltx_font_bold" id="A3.SS1.SSS1.p4.1.1" style="font-size:70%;">Power differentials.</span><span class="ltx_text" id="A3.SS1.SSS1.p4.1.2" style="font-size:70%;">
First, we recommend incentivizing dataset curation with fairness perspectives outside of the West and Global North </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="A3.SS1.SSS1.p4.1.3.1" style="font-size:70%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib133" title="">133</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib24" title="">24</a><span class="ltx_text" id="A3.SS1.SSS1.p4.1.4.2" style="font-size:70%;">]</span></cite><span class="ltx_text" id="A3.SS1.SSS1.p4.1.5" style="font-size:70%;">. For program committees or conference chairs, potential actions can include having special tracks for these datasets or offering travel scholarship for researchers to the conference.
We advocate for approaches that empower researchers from the Global South to create their own datasets.</span></p>
</div>
<div class="ltx_para" id="A3.SS1.SSS1.p5">
<p class="ltx_p" id="A3.SS1.SSS1.p5.1"><span class="ltx_text" id="A3.SS1.SSS1.p5.1.1" style="font-size:70%;">Another power differential participants discussed was between researchers and data subjects or annotators. To address this, we urge curators to center the agency and consent of data subjects as well as the expertise of data workers. Rather than treating data workers as “ghost workers” </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="A3.SS1.SSS1.p5.1.2.1" style="font-size:70%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib57" title="">57</a><span class="ltx_text" id="A3.SS1.SSS1.p5.1.3.2" style="font-size:70%;">]</span></cite><span class="ltx_text" id="A3.SS1.SSS1.p5.1.4" style="font-size:70%;">, curators should ensure that data workers are meaningfully involved throughout the data curation process and thought of as contributors rather than solely as a labor source.</span></p>
</div>
</section>
<section class="ltx_subsubsection" id="A3.SS1.SSS2">
<h4 class="ltx_title ltx_title_subsubsection" style="font-size:70%;">
<span class="ltx_tag ltx_tag_subsubsection">C.1.2 </span>Regulatory Level</h4>
<div class="ltx_para" id="A3.SS1.SSS2.p1">
<p class="ltx_p" id="A3.SS1.SSS2.p1.1"><span class="ltx_text" id="A3.SS1.SSS2.p1.1.1" style="font-size:70%;">To help minimize legal risk, our first recommendation is for the the discipline to develop ethical review processes to assess for potential legal implications of dataset collection. Venues, such as NeurIPS, have instituted impact statements and paper checklists for submitted works </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="A3.SS1.SSS2.p1.1.2.1" style="font-size:70%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib11" title="">11</a><span class="ltx_text" id="A3.SS1.SSS2.p1.1.3.2" style="font-size:70%;">]</span></cite><span class="ltx_text" id="A3.SS1.SSS2.p1.1.4" style="font-size:70%;">. We recommend that this reviews extends to include legal risks. We advocate for this discipline-wide approach as it can defray potential concerns regarding resource mismatches when it comes to consulting legal counsel. By developing a standardized procedure for legal compliance across datasets, it also reduces the burden on individual curators who may have limited regulatory literacy.</span></p>
</div>
<div class="ltx_para" id="A3.SS1.SSS2.p2">
<p class="ltx_p" id="A3.SS1.SSS2.p2.1"><span class="ltx_text" id="A3.SS1.SSS2.p2.1.1" style="font-size:70%;">Nonetheless, we still recommend that individual curators pay particular care when collecting data containing people or about people. One alternative here, such as that taken by </span><cite class="ltx_cite ltx_citemacro_citet">Asano et al. <span class="ltx_text" id="A3.SS1.SSS2.p2.1.2.1.1.1" style="font-size:70%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib5" title="">5</a><span class="ltx_text" id="A3.SS1.SSS2.p2.1.3.2.2.1" style="font-size:70%;">]</span></cite><span class="ltx_text" id="A3.SS1.SSS2.p2.1.4" style="font-size:70%;"> and </span><cite class="ltx_cite ltx_citemacro_citet">Ramaswamy et al. <span class="ltx_text" id="A3.SS1.SSS2.p2.1.5.1.1.1" style="font-size:70%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib117" title="">117</a><span class="ltx_text" id="A3.SS1.SSS2.p2.1.6.2.2.1" style="font-size:70%;">]</span></cite><span class="ltx_text" id="A3.SS1.SSS2.p2.1.7" style="font-size:70%;">, is to ensure there are no people in the dataset. Of course, there is still a need for human-centric datasets. In this case, we urge curators to recognize that using royalty-free or Creative Commons licenses does not absolve the data of potential ethical or legal issues regarding privacy or consent </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="A3.SS1.SSS2.p2.1.8.1" style="font-size:70%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib3" title="">3</a><span class="ltx_text" id="A3.SS1.SSS2.p2.1.9.2" style="font-size:70%;">]</span></cite><span class="ltx_text" id="A3.SS1.SSS2.p2.1.10" style="font-size:70%;">. Instead, curators ought to obtain informed consent from data subjects following well-established protocols from human subjects research </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="A3.SS1.SSS2.p2.1.11.1" style="font-size:70%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib45" title="">45</a><span class="ltx_text" id="A3.SS1.SSS2.p2.1.12.2" style="font-size:70%;">]</span></cite><span class="ltx_text" id="A3.SS1.SSS2.p2.1.13" style="font-size:70%;">.</span></p>
</div>
</section>
<section class="ltx_subsubsection" id="A3.SS1.SSS3">
<h4 class="ltx_title ltx_title_subsubsection" style="font-size:70%;">
<span class="ltx_tag ltx_tag_subsubsection">C.1.3 </span>Organization Level</h4>
<div class="ltx_para ltx_noindent" id="A3.SS1.SSS3.p1">
<p class="ltx_p" id="A3.SS1.SSS3.p1.1"><span class="ltx_text ltx_font_bold" id="A3.SS1.SSS3.p1.1.1" style="font-size:70%;">Ethics washing.</span><span class="ltx_text" id="A3.SS1.SSS3.p1.1.2" style="font-size:70%;"> Participants were disillusioned by organizations that treated fairness as “lip service” and engaging in the practices of ethics-washing. Echoing </span><cite class="ltx_cite ltx_citemacro_citet">Wang et al. <span class="ltx_text" id="A3.SS1.SSS3.p1.1.3.1.1.1" style="font-size:70%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib146" title="">146</a><span class="ltx_text" id="A3.SS1.SSS3.p1.1.4.2.2.1" style="font-size:70%;">]</span></cite><span class="ltx_text" id="A3.SS1.SSS3.p1.1.5" style="font-size:70%;">, we recommend institutional efforts to keep organizations liable for the ethical AI promises that they make. In addition to relying on individual contributions from researchers and journalists, having watchdog organizations monitor for ethics-washing. This recommendation draws from existing practices of monitoring companies for “greenwashing”, or manipulative promises from companies that they are engaging in environmentally friendly actions </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="A3.SS1.SSS3.p1.1.6.1" style="font-size:70%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib32" title="">32</a><span class="ltx_text" id="A3.SS1.SSS3.p1.1.7.2" style="font-size:70%;">]</span></cite><span class="ltx_text" id="A3.SS1.SSS3.p1.1.8" style="font-size:70%;">.</span></p>
</div>
</section>
<section class="ltx_subsubsection" id="A3.SS1.SSS4">
<h4 class="ltx_title ltx_title_subsubsection" style="font-size:70%;">
<span class="ltx_tag ltx_tag_subsubsection">C.1.4 </span>Discipline Level</h4>
<div class="ltx_para ltx_noindent" id="A3.SS1.SSS4.p1">
<p class="ltx_p" id="A3.SS1.SSS4.p1.1"><span class="ltx_text ltx_font_bold" id="A3.SS1.SSS4.p1.1.1" style="font-size:70%;">Lack of recognition and incentives.</span><span class="ltx_text" id="A3.SS1.SSS4.p1.1.2" style="font-size:70%;">
Since 2021, there have been efforts to introduce more dataset-focused tracks, such as the Datasets and Benchmarks track at NeurIPS </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="A3.SS1.SSS4.p1.1.3.1" style="font-size:70%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib1" title="">1</a><span class="ltx_text" id="A3.SS1.SSS4.p1.1.4.2" style="font-size:70%;">]</span></cite><span class="ltx_text" id="A3.SS1.SSS4.p1.1.5" style="font-size:70%;"> or the Journal of Data-Centric Machine Learning Research (DMLR). We recommend building on this trend and encouraging more dataset-focused tracks, including some that have specific sub-areas dedicated to fairness-oriented datasets. This can help address the lack of recognition and incentives for fair dataset work.</span></p>
</div>
<div class="ltx_para ltx_noindent" id="A3.SS1.SSS4.p2">
<p class="ltx_p" id="A3.SS1.SSS4.p2.1"><span class="ltx_text ltx_font_bold" id="A3.SS1.SSS4.p2.1.1" style="font-size:70%;">Responsibility for fairness.</span><span class="ltx_text" id="A3.SS1.SSS4.p2.1.2" style="font-size:70%;">
Fairness-oriented changes ought to be widely adopted amongst ML dataset creators, not only those who may be more “fairness’ or “justice” oriented. To encourage this shift, we recommend adopting more educational training on these subjects. Universities can include fairness and ethics into computer science courses. An example of this are the Embedded EthiCS programs at universities which encourage students to think critically about the technology they are learning about in their computer science courses </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="A3.SS1.SSS4.p2.1.3.1" style="font-size:70%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib58" title="">58</a><span class="ltx_text" id="A3.SS1.SSS4.p2.1.4.2" style="font-size:70%;">]</span></cite><span class="ltx_text" id="A3.SS1.SSS4.p2.1.5" style="font-size:70%;">. Beyond university courses, AI ethics review processes can also mandate certifications that researchers must complete prior to getting approval similar to the trainings that researchers must complete before receiving IRB approval.</span></p>
</div>
</section>
<section class="ltx_subsubsection" id="A3.SS1.SSS5">
<h4 class="ltx_title ltx_title_subsubsection" style="font-size:70%;">
<span class="ltx_tag ltx_tag_subsubsection">C.1.5 </span>Individual Level</h4>
<div class="ltx_para ltx_noindent" id="A3.SS1.SSS5.p1">
<p class="ltx_p" id="A3.SS1.SSS5.p1.1"><span class="ltx_text ltx_font_bold" id="A3.SS1.SSS5.p1.1.1" style="font-size:70%;">Individual contributor positionality.</span><span class="ltx_text" id="A3.SS1.SSS5.p1.1.2" style="font-size:70%;"> Contributor biases are inevitable. Our recommendations here focus not on removing all individual biases but rather on encouraging curators to get multiple perspectives and reflect on what biases they may be bringing prior to data collection. One recommendation is to institute a “pre-registration” system similar to what social scientists have in place </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="A3.SS1.SSS5.p1.1.3.1" style="font-size:70%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib105" title="">105</a><span class="ltx_text" id="A3.SS1.SSS5.p1.1.4.2" style="font-size:70%;">]</span></cite><span class="ltx_text" id="A3.SS1.SSS5.p1.1.5" style="font-size:70%;">. Pre-registration requires social scientists to publicly state their hypotheses, methods, data collection process, and analysis plans prior to beginning their experiment. Filling out a pre-registration prior to data collection could encourage curators to think through design biases and justify the choices they have made in a transparent and standardized manner.</span></p>
</div>
</section>
</section>
<section class="ltx_subsection" id="A3.SS2">
<h3 class="ltx_title ltx_title_subsection" style="font-size:70%;">
<span class="ltx_tag ltx_tag_subsection">C.2 </span>Recommendations During the Dataset Lifecycle</h3>
<section class="ltx_subsubsection" id="A3.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection" style="font-size:70%;">
<span class="ltx_tag ltx_tag_subsubsection">C.2.1 </span>Requirements</h4>
<div class="ltx_para ltx_noindent" id="A3.SS2.SSS1.p1">
<p class="ltx_p" id="A3.SS2.SSS1.p1.1"><span class="ltx_text ltx_font_bold" id="A3.SS2.SSS1.p1.1.1" style="font-size:70%;">Determining fairness definitions.</span><span class="ltx_text" id="A3.SS2.SSS1.p1.1.2" style="font-size:70%;">
Participants considered fairness to be highly contextual. To ensure that the definitions of fairness match those of impacted communities, we recommend that curators solicit and incorporate community feedback into the design and evaluation of fairness criteria </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="A3.SS2.SSS1.p1.1.3.1" style="font-size:70%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib17" title="">17</a><span class="ltx_text" id="A3.SS2.SSS1.p1.1.4.2" style="font-size:70%;">]</span></cite><span class="ltx_text" id="A3.SS2.SSS1.p1.1.5" style="font-size:70%;">. This can help ensure that the dataset reflects the needs and values of diverse populations. As an example for how this can be done, curators can look to works such as </span><cite class="ltx_cite ltx_citemacro_citet">Shen et al. <span class="ltx_text" id="A3.SS2.SSS1.p1.1.6.1.1.1" style="font-size:70%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib134" title="">134</a><span class="ltx_text" id="A3.SS2.SSS1.p1.1.7.2.2.1" style="font-size:70%;">]</span></cite><span class="ltx_text" id="A3.SS2.SSS1.p1.1.8" style="font-size:70%;"> which aimed to involve community members in deliberative processes for defining AI systems. Similar participatory processes can be adapted for determining fairness definitions in datasets.</span></p>
</div>
</section>
<section class="ltx_subsubsection" id="A3.SS2.SSS2">
<h4 class="ltx_title ltx_title_subsubsection" style="font-size:70%;">
<span class="ltx_tag ltx_tag_subsubsection">C.2.2 </span>Design</h4>
<div class="ltx_para ltx_noindent" id="A3.SS2.SSS2.p1">
<p class="ltx_p" id="A3.SS2.SSS2.p1.1"><span class="ltx_text ltx_font_bold" id="A3.SS2.SSS2.p1.1.1" style="font-size:70%;">Creating fair taxonomies.</span><span class="ltx_text" id="A3.SS2.SSS2.p1.1.2" style="font-size:70%;">
When designing a label taxonomy, we encourage curators to evaluate trade-offs associated with adopting coarser categories, such as loss of granularity versus feasibility and practicality. Data curators should report both their ideal data collection scenario and the actual approach taken. This information is useful not only from a transparency perspective but also for other researchers who may face similar issues in the future.</span></p>
</div>
<div class="ltx_para" id="A3.SS2.SSS2.p2">
<p class="ltx_p" id="A3.SS2.SSS2.p2.1"><span class="ltx_text" id="A3.SS2.SSS2.p2.1.1" style="font-size:70%;">In addition, these taxonomies should be designed with scalability in mind. Curators should make provisions to ensure the taxonomy is flexible enough to incorporate new data if collected. For example, the OpenImages dataset </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="A3.SS2.SSS2.p2.1.2.1" style="font-size:70%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib85" title="">85</a><span class="ltx_text" id="A3.SS2.SSS2.p2.1.3.2" style="font-size:70%;">]</span></cite><span class="ltx_text" id="A3.SS2.SSS2.p2.1.4" style="font-size:70%;"> has had several new versions and additions since its initial release, including </span><cite class="ltx_cite ltx_citemacro_citet">Schumann et al. <span class="ltx_text" id="A3.SS2.SSS2.p2.1.5.1.1.1" style="font-size:70%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib130" title="">130</a><span class="ltx_text" id="A3.SS2.SSS2.p2.1.6.2.2.1" style="font-size:70%;">]</span></cite><span class="ltx_text" id="A3.SS2.SSS2.p2.1.7" style="font-size:70%;">’s new demographic annotations which are aimed to aid with fairness research.</span></p>
</div>
</section>
<section class="ltx_subsubsection" id="A3.SS2.SSS3">
<h4 class="ltx_title ltx_title_subsubsection" style="font-size:70%;">
<span class="ltx_tag ltx_tag_subsubsection">C.2.3 </span>Implementation</h4>
<div class="ltx_para ltx_noindent" id="A3.SS2.SSS3.p1">
<p class="ltx_p" id="A3.SS2.SSS3.p1.1"><span class="ltx_text ltx_font_bold" id="A3.SS2.SSS3.p1.1.1" style="font-size:70%;">Vendor transparency.</span><span class="ltx_text" id="A3.SS2.SSS3.p1.1.2" style="font-size:70%;">
As third-party vendors offer an alternative path for data collection, we recommend curators prioritize transparency both in negotiations with these vendors and when reporting their results. In negotiations with data vendors, curators should prioritize transparency clauses in the contract. For example, curators should advocate for transparency in data worker identities and compensation handling. This can help to ensure that they have access to necessary information for evaluating dataset fairness. During the collection process, data vendors should be held accountable for transparency practices through regular monitoring and evaluation. This could involve conducting audits or assessments to ensure compliance with transparency agreements and guidelines.</span></p>
</div>
<div class="ltx_para" id="A3.SS2.SSS3.p2">
<p class="ltx_p" id="A3.SS2.SSS3.p2.1"><span class="ltx_text" id="A3.SS2.SSS3.p2.1.1" style="font-size:70%;">To reduce the burden on individual curators, there should be a discipline-wide effort to evaluate and benchmark data vendors based on transparency and ethical data collection practices. From management studies, there is a line of work on vendor evaluation systems and vendor scorecards that can be adapted for third-party data curation services </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="A3.SS2.SSS3.p2.1.2.1" style="font-size:70%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib92" title="">92</a><span class="ltx_text" id="A3.SS2.SSS3.p2.1.3.2" style="font-size:70%;">]</span></cite><span class="ltx_text" id="A3.SS2.SSS3.p2.1.4" style="font-size:70%;">.</span></p>
</div>
<div class="ltx_para ltx_noindent" id="A3.SS2.SSS3.p3">
<p class="ltx_p" id="A3.SS2.SSS3.p3.1"><span class="ltx_text ltx_font_bold" id="A3.SS2.SSS3.p3.1.1" style="font-size:70%;">Language barriers.</span><span class="ltx_text" id="A3.SS2.SSS3.p3.1.2" style="font-size:70%;">
When faced with language barriers, the data curation team should ensure that they have members who have an understanding of the data collection project’s context, goals, and data requirements such that they can provide more contextually appropriate translations. If this is not possible, we recommend establishing partnerships with local community organizations or language schools to access language resources at reduced costs.</span></p>
</div>
<div class="ltx_para ltx_noindent" id="A3.SS2.SSS3.p4">
<p class="ltx_p" id="A3.SS2.SSS3.p4.1"><span class="ltx_text ltx_font_bold" id="A3.SS2.SSS3.p4.1.1" style="font-size:70%;">Fair data labor.</span><span class="ltx_text" id="A3.SS2.SSS3.p4.1.2" style="font-size:70%;">
To ensure fair data labor practices, we recommend curators create clear guidelines and protocols for hiring, training, and evaluating data workers to promote fairness and prevent exploitation. Following prior works </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="A3.SS2.SSS3.p4.1.3.1" style="font-size:70%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib150" title="">150</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib3" title="">3</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib24" title="">24</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib142" title="">142</a><span class="ltx_text" id="A3.SS2.SSS3.p4.1.4.2" style="font-size:70%;">]</span></cite><span class="ltx_text" id="A3.SS2.SSS3.p4.1.5" style="font-size:70%;">, we also advocate for transparent and equitable compensation structures for data workers. When possible, curators should provide opportunities for professional development and advancement for data workers.</span></p>
</div>
<div class="ltx_para ltx_noindent" id="A3.SS2.SSS3.p5">
<p class="ltx_p" id="A3.SS2.SSS3.p5.1"><span class="ltx_text ltx_font_bold" id="A3.SS2.SSS3.p5.1.1" style="font-size:70%;">Diverse data availability.</span><span class="ltx_text" id="A3.SS2.SSS3.p5.1.2" style="font-size:70%;">
Curators should consider using alternative data sources beyond web data, such as community-driven platforms or public repositories, to supplement dataset diversity. To support this, organizations should invest in creating public data trusts </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="A3.SS2.SSS3.p5.1.3.1" style="font-size:70%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib25" title="">25</a><span class="ltx_text" id="A3.SS2.SSS3.p5.1.4.2" style="font-size:70%;">]</span></cite><span class="ltx_text" id="A3.SS2.SSS3.p5.1.5" style="font-size:70%;"> or data consortia </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="A3.SS2.SSS3.p5.1.6.1" style="font-size:70%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib78" title="">78</a><span class="ltx_text" id="A3.SS2.SSS3.p5.1.7.2" style="font-size:70%;">]</span></cite><span class="ltx_text" id="A3.SS2.SSS3.p5.1.8" style="font-size:70%;"> as an alternative source for large-scale data.</span></p>
</div>
<div class="ltx_para ltx_noindent" id="A3.SS2.SSS3.p6">
<p class="ltx_p" id="A3.SS2.SSS3.p6.1"><span class="ltx_text ltx_font_bold" id="A3.SS2.SSS3.p6.1.1" style="font-size:70%;">Data collector availability.</span><span class="ltx_text" id="A3.SS2.SSS3.p6.1.2" style="font-size:70%;">
To address a lack of data collector availability, we recommend curators form partnerships with universities, organizations (e.g., NGOs, non-profits), or community groups, operating in underrepresented regions. These partnerships can help the recruitment of data collectors from the target regions, leveraging existing networks and/or local expertise to overcome challenges. For example, </span><cite class="ltx_cite ltx_citemacro_citet">Rojas et al. <span class="ltx_text" id="A3.SS2.SSS3.p6.1.3.1.1.1" style="font-size:70%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib118" title="">118</a><span class="ltx_text" id="A3.SS2.SSS3.p6.1.4.2.2.1" style="font-size:70%;">]</span></cite><span class="ltx_text" id="A3.SS2.SSS3.p6.1.5" style="font-size:70%;"> partnered with Gapminder and individual photographers to collect geographically diverse images for the DollarStreet dataset.</span></p>
</div>
<div class="ltx_para ltx_noindent" id="A3.SS2.SSS3.p7">
<p class="ltx_p" id="A3.SS2.SSS3.p7.1"><span class="ltx_text ltx_font_bold" id="A3.SS2.SSS3.p7.1.1" style="font-size:70%;">Data annotator diversity and expertise.</span><span class="ltx_text" id="A3.SS2.SSS3.p7.1.2" style="font-size:70%;">
When recruiting data annotators, curators should research and understand which personal attributes are legally protected and cannot be asked about during the hiring process. Further, they should be cognizant of cultural nuances. For example, disclosing sexuality can potentially endanger workers. Thus, rather than directly asking sensitive personal attributes, curators can utilize alternative methods for assessing annotator qualifications and suitability for the project. This is especially helpful when annotators may not want to disclose certain attributes. Finally, curators should offer training and resources to annotators to help them understand the cultural significance of the data they are annotating.</span></p>
</div>
</section>
<section class="ltx_subsubsection" id="A3.SS2.SSS4">
<h4 class="ltx_title ltx_title_subsubsection" style="font-size:70%;">
<span class="ltx_tag ltx_tag_subsubsection">C.2.4 </span>Evaluation</h4>
<div class="ltx_para ltx_noindent" id="A3.SS2.SSS4.p1">
<p class="ltx_p" id="A3.SS2.SSS4.p1.1"><span class="ltx_text ltx_font_bold" id="A3.SS2.SSS4.p1.1.1" style="font-size:70%;">Gold standard paradigms.</span><span class="ltx_text" id="A3.SS2.SSS4.p1.1.2" style="font-size:70%;">
Dataset curators can adopt evaluation methods that embrace diverse perspectives rather than only using consensus-based methods, which may only showcase the viewpoint of the majority. Works from both machine learning </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="A3.SS2.SSS4.p1.1.3.1" style="font-size:70%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib31" title="">31</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib88" title="">88</a><span class="ltx_text" id="A3.SS2.SSS4.p1.1.4.2" style="font-size:70%;">]</span></cite><span class="ltx_text" id="A3.SS2.SSS4.p1.1.5" style="font-size:70%;"> and human-computer interaction </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="A3.SS2.SSS4.p1.1.6.1" style="font-size:70%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib54" title="">54</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib55" title="">55</a><span class="ltx_text" id="A3.SS2.SSS4.p1.1.7.2" style="font-size:70%;">]</span></cite><span class="ltx_text" id="A3.SS2.SSS4.p1.1.8" style="font-size:70%;"> have encourage using a multiplicity of annotations, which can showcase disagreement, rather than using majority voting. For example, a curator may capture a diversity of annotations from each annotator, with qualitative explanations as to why the annotator chose each label. Prior works </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="A3.SS2.SSS4.p1.1.9.1" style="font-size:70%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib113" title="">113</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib145" title="">145</a><span class="ltx_text" id="A3.SS2.SSS4.p1.1.10.2" style="font-size:70%;">]</span></cite><span class="ltx_text" id="A3.SS2.SSS4.p1.1.11" style="font-size:70%;"> have also provided frameworks for quantifying disagreement across diverse groups of annotators that can be used as an alternative measure to consensus-based approaches.</span></p>
</div>
<div class="ltx_para ltx_noindent" id="A3.SS2.SSS4.p2">
<p class="ltx_p" id="A3.SS2.SSS4.p2.1"><span class="ltx_text ltx_font_bold" id="A3.SS2.SSS4.p2.1.1" style="font-size:70%;">Evaluating immeasurable constructs.</span><span class="ltx_text" id="A3.SS2.SSS4.p2.1.2" style="font-size:70%;">
When it comes to evaluating immeasurable constructs, curators can supplement quantitative metrics with qualitative approaches. This could include interviews with data workers to better understand their point of view and reveal any potential biases or ethical issues that arose during the collection process. Furthermore, as </span><cite class="ltx_cite ltx_citemacro_citet">Miceli et al. <span class="ltx_text" id="A3.SS2.SSS4.p2.1.3.1.1.1" style="font-size:70%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib99" title="">99</a><span class="ltx_text" id="A3.SS2.SSS4.p2.1.4.2.2.1" style="font-size:70%;">]</span></cite><span class="ltx_text" id="A3.SS2.SSS4.p2.1.5" style="font-size:70%;"> advocate for in their work, there should be more reflexivity in the data collection process. Concretely, refereed publications should require more critical reflection on the limitations and trade-offs of the dataset by the curators.</span></p>
</div>
</section>
<section class="ltx_subsubsection" id="A3.SS2.SSS5">
<h4 class="ltx_title ltx_title_subsubsection" style="font-size:70%;">
<span class="ltx_tag ltx_tag_subsubsection">C.2.5 </span>Maintenance</h4>
<div class="ltx_para ltx_noindent" id="A3.SS2.SSS5.p1">
<p class="ltx_p" id="A3.SS2.SSS5.p1.1"><span class="ltx_text ltx_font_bold" id="A3.SS2.SSS5.p1.1.1" style="font-size:70%;">Unstable infrastructural ecosystems.</span><span class="ltx_text" id="A3.SS2.SSS5.p1.1.2" style="font-size:70%;"> To manage unstable infrastructural ecosystems, we recommend building standardized methods for checking the availability of data sources and creating protocols to replace instances if they have been deprecated. For example, P8 mentioned developing automated scripts that would periodically check whether their dataset instances were still available. Rather than waiting for dataset users to notify curators that certain instances are no longer available, this allows for proactive maintenance.</span></p>
</div>
<div class="ltx_para" id="A3.SS2.SSS5.p2">
<p class="ltx_p" id="A3.SS2.SSS5.p2.1"><span class="ltx_text" id="A3.SS2.SSS5.p2.1.1" style="font-size:70%;">Going hand-in-hand with this, once curators are aware that certain instances are deprecated, they should have a plan for replacing them in a way that maintains the overall composition of the dataset. This can be challenging, especially for datasets where compositional fairness is prioritized. We recommend that dataset curators create a protocol for identifying alternative data sources that match the distribution and characteristics of the original dataset at the design phase. For example, dataset curators can keep a portion of collected data as “backup” that they can use to replace instances that are deprecated or removed.</span></p>
</div>
<div class="ltx_para ltx_noindent" id="A3.SS2.SSS5.p3">
<p class="ltx_p" id="A3.SS2.SSS5.p3.1"><span class="ltx_text ltx_font_bold" id="A3.SS2.SSS5.p3.1.1" style="font-size:70%;">Dataset traceability mechanisms.</span><span class="ltx_text" id="A3.SS2.SSS5.p3.1.2" style="font-size:70%;">
One challenge curators faced was tracing how their dataset was used after release. Often they relied on citation metrics as a proxy; however, it was difficult to disambiguate whether the citation meant the authors were using the dataset or referring to concepts in the paper. As an alternative, we recommend curators require users to register or authenticate their identity before accessing datasets, enabling better tracking and accountability. For example, ImageNet </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="A3.SS2.SSS5.p3.1.3.1" style="font-size:70%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib35" title="">35</a><span class="ltx_text" id="A3.SS2.SSS5.p3.1.4.2" style="font-size:70%;">]</span></cite><span class="ltx_text" id="A3.SS2.SSS5.p3.1.5" style="font-size:70%;"> requires users to sign in to their platform before downloading data. Another option can be to use permanent digital identifiers, such as DOIs, which is already a standard for some journals such as </span><span class="ltx_text ltx_font_italic" id="A3.SS2.SSS5.p3.1.6" style="font-size:70%;">Nature</span><span class="ltx_text" id="A3.SS2.SSS5.p3.1.7" style="font-size:70%;">.</span><span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>https://www.nature.com/ncomms/editorial-policies/reporting-standards</span></span></span><span class="ltx_text" id="A3.SS2.SSS5.p3.1.8" style="font-size:70%;"> Similarly, curators can use centralized data repositories (e.g., Hugging Face, Kaggle, Zenodo, Harvard Dataverse, Mendeley data).</span></p>
</div>
</section>
</section>
<section class="ltx_appendix" id="A4">
<h2 class="ltx_title ltx_title_appendix" style="font-size:70%;">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>Limitations</h2>
<div class="ltx_para" id="A4.p1">
<p class="ltx_p" id="A4.p1.1"><span class="ltx_text" id="A4.p1.1.1" style="font-size:70%;">The participant sample we recruited is skewed both in terms of location and organization type. In total, three of the 30 participants we recruited were from regions outside of North America or Europe. In part, our sample may reflect the Western-centric nature of machine learning and algorithmic fairness research </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="A4.p1.1.2.1" style="font-size:70%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib133" title="">133</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib83" title="">83</a><span class="ltx_text" id="A4.p1.1.3.2" style="font-size:70%;">]</span></cite><span class="ltx_text" id="A4.p1.1.4" style="font-size:70%;">. Given the challenges participants raised about creating culturally contextualized datasets and power differentials across geographies, future work that draws from a more geographically diverse sample can provide more nuanced insight. We also note that most of our participants were situated in academia. There may be specific challenges to dataset curation in an industry context (compared to an academic one) that we are not highlighting in our taxonomy.</span></p>
</div>
<div class="ltx_para" id="A4.p2">
<p class="ltx_p" id="A4.p2.1"><span class="ltx_text" id="A4.p2.1.1" style="font-size:70%;">Overall, a consistent theme from our interviews is that fairness is contextual and the datasets curators collect are often designed specifically for their task or domain. Inherently this means that the qualitative data we collect will be constrained to the slices of perspective that our participants have. While we do distill our findings from shared themes across interviews, these challenges are neither necessarily applicable nor entirely representative for all dataset curators.</span></p>
</div>
<section class="ltx_appendix" id="A5">
<h2 class="ltx_title ltx_title_appendix" style="font-size:70%;">
<span class="ltx_tag ltx_tag_appendix">Appendix E </span>Broader Impacts</h2>
<div class="ltx_para" id="A5.p1">
<p class="ltx_p" id="A5.p1.1"><span class="ltx_text" id="A5.p1.1.1" style="font-size:70%;">Our work focuses on understanding the challenges with fair dataset collection by conducting on-the-ground interviews with dataset curators. We provide a taxonomy of challenges that curators face throughout the dataset lifecycle and an exploration into the broader landscape of challenges curators face. For dataset curators, this work provides valuable insight into the nuance and trade-offs related to dataset creation that may not appear in publications. By formalizing this otherwise tacit knowledge, we hope to make the process of fair dataset collection more accessible for curators. More broadly, we intend for our work to have an impact on machine learning as a discipline. We seek to emphasize the importance of dataset curators’ labor, which often is undervalued </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="A5.p1.1.2.1" style="font-size:70%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib120" title="">120</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib126" title="">126</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06407v1#bib.bib119" title="">119</a><span class="ltx_text" id="A5.p1.1.3.2" style="font-size:70%;">]</span></cite><span class="ltx_text" id="A5.p1.1.4" style="font-size:70%;">. Furthermore, we provide an extensive set of recommendations that can be implemented by either individual contributors or from the top-down. By using these recommendations and the challenges we have surfaced, we hope to help facilitate better fair dataset curation practices within the machine learning community.</span></p>
</div>
<section class="ltx_appendix" id="A6">
<h2 class="ltx_title ltx_title_appendix" style="font-size:70%;">
<span class="ltx_tag ltx_tag_appendix">Appendix F </span>Author Contributions</h2>
<div class="ltx_para" id="A6.p1">
<p class="ltx_p" id="A6.p1.1"><span class="ltx_text" id="A6.p1.1.1" style="font-size:70%;">D.Z. and J.T.A.A. conceived of the idea for the project in this paper. D.Z., M.S., P.C., J.T.A.A., G.P., S.W., and K.P. were involved in discussing the themes of the overarching project. J.T.A.A. and A.X. acquired the financial support for the project. J.T.A.A., S.W., K.P, and A.X. provided oversight and leadership to the research team working on the project.</span></p>
</div>
<div class="ltx_para" id="A6.p2">
<p class="ltx_p" id="A6.p2.1"><span class="ltx_text" id="A6.p2.1.1" style="font-size:70%;">D.Z., J.T.A, P.C., S.W., and K.P. were involved in developing the interview protocol. P.C., S.W., and K.P. recruited participants and conducted the interviews. P.C. transcribed and redacted the interviews.</span></p>
</div>
<div class="ltx_para" id="A6.p3">
<p class="ltx_p" id="A6.p3.1"><span class="ltx_text" id="A6.p3.1.1" style="font-size:70%;">D.Z., M.S., J.T.A.A., P.C., G.P., S.W., and K.P. were involved in developing the thematic codebook from the interviews. D.Z., M.S., J.T.A, and K.P. conducted analysis of the interviews, applying themes from the codebook.</span></p>
</div>
<div class="ltx_para" id="A6.p4">
<p class="ltx_p" id="A6.p4.1"><span class="ltx_text" id="A6.p4.1.1" style="font-size:70%;">D.Z. and M.S. drafted the manuscript. J.T.A.A., G.P., S.W., K.P., and A.X. commented on the manuscript. M.S., P.C., and D.Z. created the figures and tables in the manuscript.</span></p>
</div>
</section>
</section>
</section>
</section>
</div>
</div>
</figure>
</div>
</div>
</figure>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Mon Jun 10 15:48:45 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
