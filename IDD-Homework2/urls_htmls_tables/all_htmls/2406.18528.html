<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation</title>
<!--Generated on Wed Jun 26 17:55:01 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2406.18528v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#S1" title="In PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#S2" title="In PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#S2.SS0.SSS0.Px1" title="In 2 Related Work ‣ PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_title">Prompting-based metrics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#S2.SS0.SSS0.Px2" title="In 2 Related Work ‣ PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_title">Prompting Techniques</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#S2.SS0.SSS0.Px3" title="In 2 Related Work ‣ PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_title">Prompting Robustness</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#S3" title="In PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Setup</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#S3.SS0.SSS0.Px1" title="In 3 Setup ‣ PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_title">Prompt Templates</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#S3.SS0.SSS0.Px2" title="In 3 Setup ‣ PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_title">MQM-based approaches</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#S3.SS0.SSS0.Px3" title="In 3 Setup ‣ PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_title">Score Extraction &amp; Evaluation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#S3.SS0.SSS0.Px4" title="In 3 Setup ‣ PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_title">Models</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#S3.SS0.SSS0.Px5" title="In 3 Setup ‣ PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_title">Datasets and phases</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#S3.SS0.SSS0.Px6" title="In 3 Setup ‣ PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_title">Baselines</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#S4" title="In PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Results</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#S5" title="In PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Analysis</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#S5.SS0.SSS0.Px1" title="In 5 Analysis ‣ PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_title">Best prompting patterns per <span class="ltx_text" style="color:#000000;">model and dataset</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#S5.SS0.SSS0.Px2" title="In 5 Analysis ‣ PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_title">Prompt stability</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#S6" title="In PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Recommendations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#S7" title="In PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#A1" title="In PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Prompt Templates</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#A2" title="In PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B </span>Implementation Details</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#A3" title="In PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C </span>Dataset Details</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#A4" title="In PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">D </span>Model Abbreviations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#A5" title="In PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">E </span>Phase 1 &amp; 2 performance</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#A6" title="In PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">F </span>Prompt selection</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#A7" title="In PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">G </span>Significance matrices for correlation heatmaps</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#A8" title="In PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">H </span>Pie charts between models for each prompting pattern</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#A9" title="In PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">I </span>Piecharts between datasets for each prompting pattern</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#A10" title="In PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">J </span>Stability heatmaps</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<div class="ltx_para" id="p1">
<span class="ltx_ERROR undefined" id="p1.2">\newunicodechar</span>
<p class="ltx_p" id="p1.1">⚠<span class="ltx_text ltx_inline-block" id="p1.1.1" style="width:14.0pt;"><span class="ltx_text ltx_inline-block" id="p1.1.1.2" style="width:0.0pt;position:relative; bottom:1.0pt;">!</span><span class="ltx_text ltx_inline-block" id="p1.1.1.1" style="width:0.0pt;"><math alttext="\bigtriangleup" class="ltx_Math" display="inline" id="p1.1.1.1.m1.1"><semantics id="p1.1.1.1.m1.1a"><mo id="p1.1.1.1.m1.1.1" mathcolor="#FF0000" xref="p1.1.1.1.m1.1.1.cmml">△</mo><annotation-xml encoding="MathML-Content" id="p1.1.1.1.m1.1b"><ci id="p1.1.1.1.m1.1.1.cmml" xref="p1.1.1.1.m1.1.1">△</ci></annotation-xml><annotation encoding="application/x-tex" id="p1.1.1.1.m1.1c">\bigtriangleup</annotation><annotation encoding="application/x-llamapun" id="p1.1.1.1.m1.1d">△</annotation></semantics></math></span></span></p>
</div>
<h1 class="ltx_title ltx_title_document">PrExMe!
Large Scale Prompt Exploration of Open Source LLMs for 
<br class="ltx_break"/>Machine Translation and Summarization Evaluation
</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Christoph Leiter, Steffen Eger 
<br class="ltx_break"/>Natural Language Learning Group (NLLG)
<br class="ltx_break"/><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://nl2g.github.io/" title="">https://nl2g.github.io/</a>
<br class="ltx_break"/>University of Mannheim
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id3.1.id1">{christoph.leiter,steffen.eger}@uni-mannheim.de</span>
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id2.2">Large language models (<span class="ltx_text ltx_font_smallcaps" id="id2.2.1">LLMs</span>) have revolutionized the field of <span class="ltx_text ltx_font_smallcaps" id="id2.2.2">NLP</span>. Notably, their in-context learning capabilities also enable their use as evaluation metrics for natural language generation,
making them particularly advantageous in low-resource scenarios and time-restricted applications.
In this work, we introduce PrExMe, a large-scale <span class="ltx_text ltx_font_italic" id="id2.2.3">prompt exploration for metrics</span>, where we evaluate more than <math alttext="720" class="ltx_Math" display="inline" id="id1.1.m1.1"><semantics id="id1.1.m1.1a"><mn id="id1.1.m1.1.1" xref="id1.1.m1.1.1.cmml">720</mn><annotation-xml encoding="MathML-Content" id="id1.1.m1.1b"><cn id="id1.1.m1.1.1.cmml" type="integer" xref="id1.1.m1.1.1">720</cn></annotation-xml><annotation encoding="application/x-tex" id="id1.1.m1.1c">720</annotation><annotation encoding="application/x-llamapun" id="id1.1.m1.1d">720</annotation></semantics></math> prompt templates for open-source <span class="ltx_text ltx_font_smallcaps" id="id2.2.4">LLM</span>-based metrics on machine translation (<span class="ltx_text ltx_font_smallcaps" id="id2.2.5">MT</span>) and summarization datasets, totalling over <math alttext="6.6" class="ltx_Math" display="inline" id="id2.2.m2.1"><semantics id="id2.2.m2.1a"><mn id="id2.2.m2.1.1" xref="id2.2.m2.1.1.cmml">6.6</mn><annotation-xml encoding="MathML-Content" id="id2.2.m2.1b"><cn id="id2.2.m2.1.1.cmml" type="float" xref="id2.2.m2.1.1">6.6</cn></annotation-xml><annotation encoding="application/x-tex" id="id2.2.m2.1c">6.6</annotation><annotation encoding="application/x-llamapun" id="id2.2.m2.1d">6.6</annotation></semantics></math>M evaluations. This extensive comparison (1) serves as a benchmark of the performance of recent open-source <span class="ltx_text ltx_font_smallcaps" id="id2.2.6">LLMs</span> as metrics and (2) explores the stability and variability of different prompting strategies. We discover that, on <span class="ltx_text" id="id2.2.7" style="color:#000000;">the</span> one hand, there are scenarios for which prompts are stable. For instance, some <span class="ltx_text ltx_font_smallcaps" id="id2.2.8">LLMs</span> show idiosyncratic preferences and favor to grade generated texts with textual labels while others prefer to return numeric scores.
On the other hand, the stability of prompts and model rankings can be susceptible to seemingly innocuous changes.
For example, changing the requested output format from “0 to 100” to “-1 to +1” can strongly affect the rankings in our evaluation.
Our study contributes to understanding the impact of different prompting approaches on <span class="ltx_text ltx_font_smallcaps" id="id2.2.9">LLM</span>-based metrics for MT and summarization evaluation, highlighting the most stable prompting patterns and potential limitations.<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>We make our code available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/Gringham/PrExMe" title="">https://github.com/Gringham/PrExMe</a></span></span></span></p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">The recent popularity and success of
<span class="ltx_text ltx_font_smallcaps" id="S1.p1.1.1" style="color:#000000;">LLMs</span>
<span class="ltx_text" id="S1.p1.1.2" style="color:#000000;">have</span> led to a paradigm shift in
<span class="ltx_text ltx_font_smallcaps" id="S1.p1.1.3" style="color:#000000;">NLP</span>
<cite class="ltx_cite ltx_citemacro_citep">(Zhang et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib46" title="">2023</a>)</cite>. Instruction-tuning allows <span class="ltx_text ltx_font_smallcaps" id="S1.p1.1.4">LLMs</span> to generate responses to complex task descriptions (prompts) <cite class="ltx_cite ltx_citemacro_citep">(Ouyang et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib38" title="">2022</a>)</cite>, making them useful for conventional <span class="ltx_text ltx_font_smallcaps" id="S1.p1.1.5">NLP</span> tasks.</p>
</div>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="181" id="S1.F1.g1" src="extracted/5693647/images/PrexMain.png" width="287"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Schematic overview of our prompt exploration. We perform a grid search over datasets, task descriptions, output formats and base prompts.</figcaption>
</figure>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">One such task
is the automatic evaluation of <span class="ltx_text" id="S1.p2.1.1" style="color:#000000;">natural language generation (<span class="ltx_text ltx_font_smallcaps" id="S1.p2.1.1.1">NLG</span>)</span> models <span class="ltx_text" id="S1.p2.1.2" style="color:#000000;">in</span> machine translation (<span class="ltx_text ltx_font_smallcaps" id="S1.p2.1.3">MT</span>) and summarization.
Following the current trend, researchers
use
<span class="ltx_text ltx_font_smallcaps" id="S1.p2.1.4" style="color:#000000;">LLMs<span class="ltx_text ltx_font_upright" id="S1.p2.1.4.1"> as evaluation metrics and achieve remarkable performance, sometimes relying solely</span></span> on in-context learning <cite class="ltx_cite ltx_citemacro_citep">(e.g. Kocmi and Federmann, <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib21" title="">2023a</a>; Fernandes et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib9" title="">2023</a>)</cite>, i.e., with metrics that are purely based on prompting.
Such prompting-based metrics require no or only a few data samples,
<span class="ltx_text" id="S1.p2.1.5" style="color:#000000;">making them useful for low-resource evaluation scenarios
<cite class="ltx_cite ltx_citemacro_citep">(Belouadi and Eger, <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib3" title="">2023</a>)</cite>.</span>
<span class="ltx_text" id="S1.p2.1.6" style="color:#000000;">Additionally, they are often more resource-efficient since they do not require fine-tuning.</span></p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">Although many prompting-based metrics have been proposed <cite class="ltx_cite ltx_citemacro_citep">(e.g. Li et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib32" title="">2024b</a>)</cite>, structured evaluations across different prompting approaches remain scarce, especially for open-source models. <span class="ltx_text" id="S1.p3.1.1" style="color:#000000;">In
recent work, the <span class="ltx_text ltx_font_smallcaps" id="S1.p3.1.1.1">Eval4NLP 2023</span> shared task <cite class="ltx_cite ltx_citemacro_citep">(Leiter et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib29" title="">2023</a>)</cite> addresses this
by (1) restricting the usage to selected open-source LLMs and (2) prohibiting the fine-tuning of these models.</span>
<span class="ltx_text" id="S1.p3.1.2" style="color:#000000;">While the shared-task submissions
provide several interesting findings, they focus
on a few distinct prompts only. Notably, the effect and robustness of prompt variations on the same model or across different models remain largely unexplored.</span></p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">In this work, we introduce a
<span class="ltx_text" id="S1.p4.1.1" style="color:#000000;">systematic</span> <span class="ltx_text ltx_font_bold" id="S1.p4.1.2">Pr</span>ompt <span class="ltx_text ltx_font_bold" id="S1.p4.1.3">Ex</span>ploration for <span class="ltx_text ltx_font_bold" id="S1.p4.1.4">Me</span>trics <span class="ltx_text" id="S1.p4.1.5" style="color:#000000;">(PrExMe)</span>, that <span class="ltx_text" id="S1.p4.1.6" style="color:#000000;">builds upon
</span> <span class="ltx_text ltx_font_smallcaps" id="S1.p4.1.7">Eval4NLP 2023</span><span class="ltx_text" id="S1.p4.1.8" style="color:#000000;">,</span> to provide a much larger, template-based, structured evaluation of the effects different input prompts have on an LLM-based metric’s correlation <span class="ltx_text" id="S1.p4.1.9" style="color:#000000;">with</span> human judgements in MT and summarization evaluation.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">We formulate the following research questions:</p>
<ol class="ltx_enumerate" id="S1.I1">
<li class="ltx_item" id="S1.I1.ix1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">RQ1</span>
<div class="ltx_para" id="S1.I1.ix1.p1">
<p class="ltx_p" id="S1.I1.ix1.p1.1">Can open-source language models
evaluate text generation without fine-tuning <span class="ltx_text" id="S1.I1.ix1.p1.1.1" style="color:#000000;">and how do they differ from each other</span>?</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.ix2" style="list-style-type:none;padding-top:-1.0pt;">
<span class="ltx_tag ltx_tag_item">RQ2</span>
<div class="ltx_para" id="S1.I1.ix2.p1">
<p class="ltx_p" id="S1.I1.ix2.p1.1">Can we identify patterns<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><span class="ltx_text" id="footnote2.1" style="color:#000000;">We define <span class="ltx_text ltx_font_italic" id="footnote2.1.1">prompting patterns</span> as the template components that constitute a prompt (e.g., zero-shot, one-shot or the output format).</span></span></span></span> in prompts that lead to a stable performance across different datasets, tasks, and models?</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.ix3" style="list-style-type:none;padding-top:-1.0pt;">
<span class="ltx_tag ltx_tag_item">RQ3</span>
<div class="ltx_para" id="S1.I1.ix3.p1">
<p class="ltx_p" id="S1.I1.ix3.p1.1">How should researchers design prompts for new evaluation scenarios?</p>
</div>
</li>
</ol>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p" id="S1.p6.1"><span class="ltx_text" id="S1.p6.1.1" style="color:#000000;">O</span>ur prompt exploration
construct<span class="ltx_text" id="S1.p6.1.2" style="color:#000000;">s</span> <span class="ltx_text" id="S1.p6.1.3" style="color:#000000;">hierarchical</span> templates based on approaches <span class="ltx_text" id="S1.p6.1.4" style="color:#000000;">such as <span class="ltx_text ltx_font_italic" id="S1.p6.1.4.1">chain-of-thought</span> (<span class="ltx_text ltx_font_smallcaps" id="S1.p6.1.4.2">CoT</span>) <cite class="ltx_cite ltx_citemacro_citep">(Kojima et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib23" title="">2022</a>)</cite>, <span class="ltx_text ltx_font_italic" id="S1.p6.1.4.3">zero-shot</span> and <span class="ltx_text ltx_font_italic" id="S1.p6.1.4.4">retrieval-augmented generation</span> (<span class="ltx_text ltx_font_smallcaps" id="S1.p6.1.4.5">RAG</span>)</span> <cite class="ltx_cite ltx_citemacro_citep">(Gao et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib15" title="">2024b</a>)</cite>. Each template gets filled with further sub-templates. For example, we vary the requested output formats, such as distinct <span class="ltx_text ltx_font_italic" id="S1.p6.1.5" style="color:#000000;">scores<span class="ltx_text ltx_font_upright" id="S1.p6.1.5.1"> and </span>continuous scores<span class="ltx_text ltx_font_upright" id="S1.p6.1.5.2"> (see §<a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#S3" title="3 Setup ‣ PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_tag">3</span></a>)</span></span>.
This setup amounts to <span class="ltx_text" id="S1.p6.1.6" style="color:#000000;">more than</span> 720 prompt templates that we evaluate with 7 <span class="ltx_text ltx_font_smallcaps" id="S1.p6.1.7">LLMs</span>. In a
<span class="ltx_text" id="S1.p6.1.8" style="color:#000000;">2nd</span>
phase, we test the generalizability and performance of the prompts with the best correlations on two further datasets.</p>
</div>
<div class="ltx_para" id="S1.p7">
<p class="ltx_p" id="S1.p7.1"><span class="ltx_text" id="S1.p7.1.1" style="color:#000000;">In summary, our work makes the following key contributions and findings</span>:</p>
<ol class="ltx_enumerate" id="S1.I2">
<li class="ltx_item" id="S1.I2.ix1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text" id="S1.I2.ix1.1.1.1" style="color:#00FF00;">✓</span></span>
<div class="ltx_para" id="S1.I2.ix1.p1">
<p class="ltx_p" id="S1.I2.ix1.p1.1">We perform a large<span class="ltx_text" id="S1.I2.ix1.p1.1.1" style="color:#000000;">-</span>scale analysis (evaluating over 6.6M prompts) of the effect of different prompting approaches on <span class="ltx_text ltx_font_smallcaps" id="S1.I2.ix1.p1.1.2">LLM</span>-based metrics for <span class="ltx_text ltx_font_smallcaps" id="S1.I2.ix1.p1.1.3">MT</span> and summarization evaluation. <span class="ltx_text" id="S1.I2.ix1.p1.1.4" style="color:#000000;">This comprehensive exploration includes various prompting techniques, datasets, tasks, and models, making it, to our knowledge, the most extensive evaluation of its kind.</span></p>
</div>
</li>
<li class="ltx_item" id="S1.I2.ix2" style="list-style-type:none;padding-top:-1.0pt;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text" id="S1.I2.ix2.1.1.1" style="color:#00FF00;">✓</span></span>
<div class="ltx_para" id="S1.I2.ix2.p1">
<p class="ltx_p" id="S1.I2.ix2.p1.1"><span class="ltx_text" id="S1.I2.ix2.p1.1.1" style="color:#000000;">We show that certain prompting patterns are
robust and generalizable across different tasks and datasets, with the median performance being a good predictor for new settings. For example, some models show a distinctive preference to return textual labels, while others achieve better results with numeric labels. On the other hand for some settings even small changes to the input prompt can strongly affect the performance.</span></p>
</div>
</li>
<li class="ltx_item" id="S1.I2.ix3" style="list-style-type:none;padding-top:-1.0pt;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text" id="S1.I2.ix3.1.1.1" style="color:#00FF00;">✓</span></span>
<div class="ltx_para" id="S1.I2.ix3.p1">
<p class="ltx_p" id="S1.I2.ix3.p1.1"><span class="ltx_text" id="S1.I2.ix3.p1.1.1" style="color:#000000;">Our study tackles prompt-based evaluation with open-source LLMs, targeting scenarios where fine-tuning or access to closed-source LLMs is not possible. Such evaluations are still very scarce but important to make research more accessible, fostering diversity and inclusion.</span></p>
</div>
</li>
<li class="ltx_item" id="S1.I2.ix4" style="list-style-type:none;padding-top:-1.0pt;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text" id="S1.I2.ix4.1.1.1" style="color:#00FF00;">✓</span></span>
<div class="ltx_para" id="S1.I2.ix4.p1">
<p class="ltx_p" id="S1.I2.ix4.p1.1">By systematically testing various established prompting approaches, including zero-shot, CoT and RAG, we comprehensively evaluate the performance of recent open-source LLMs for evaluation metrics. <span class="ltx_text" id="S1.I2.ix4.p1.1.1" style="color:#000000;">Aligning with the recommendations of <cite class="ltx_cite ltx_citemacro_citet">Mizrahi et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib35" title="">2024</a>)</cite>, by evaluating each model with multiple prompts, our LLM comparison is fair because we mitigate the risk of any single prompt disproportionately affecting their performance.</span> We find that the model <span class="ltx_text ltx_font_smallcaps" id="S1.I2.ix4.p1.1.2">Platypus2-70B</span> <cite class="ltx_cite ltx_citemacro_citep">(Lee et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib25" title="">2023a</a>)</cite> achieves the strongest performance for the tested LLMs.</p>
</div>
</li>
</ol>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">We first describe the related work of prompting-based metrics for MT and summarization.
<span class="ltx_text" id="S2.p1.1.1" style="color:#000000;">Then, we relate our work to research on prompting techniques and prompt stability.</span></p>
</div>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px1">
<h3 class="ltx_title ltx_title_paragraph">Prompting-based metrics</h3>
<div class="ltx_para" id="S2.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px1.p1.1"><span class="ltx_text" id="S2.SS0.SSS0.Px1.p1.1.1" style="color:#000000;">Recent advancements in <span class="ltx_text ltx_font_smallcaps" id="S2.SS0.SSS0.Px1.p1.1.1.1">LLM</span>-based metrics for <span class="ltx_text ltx_font_smallcaps" id="S2.SS0.SSS0.Px1.p1.1.1.2">NLG</span> often rely on in-context learning, directly predicting quality judgments from generated texts. Surveys by <cite class="ltx_cite ltx_citemacro_citet">Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib32" title="">2024b</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citet">Gao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib14" title="">2024a</a>)</cite> provide comprehensive overviews of these metrics.</span>
Besides <span class="ltx_text ltx_font_smallcaps" id="S2.SS0.SSS0.Px1.p1.1.2">BARTScore</span> <cite class="ltx_cite ltx_citemacro_citep">(Yuan et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib44" title="">2021</a>)</cite> and <span class="ltx_text ltx_font_smallcaps" id="S2.SS0.SSS0.Px1.p1.1.3">PRD</span> <cite class="ltx_cite ltx_citemacro_citep">(Li et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib31" title="">2024a</a>)</cite>, the prompt-based approaches surveyed by <cite class="ltx_cite ltx_citemacro_citet">Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib32" title="">2024b</a>)</cite> are built upon closed-source models. In contrast, the <span class="ltx_text ltx_font_smallcaps" id="S2.SS0.SSS0.Px1.p1.1.4">Eval4NLP 2023</span> shared task <cite class="ltx_cite ltx_citemacro_citep">(Leiter et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib29" title="">2023</a>)</cite>,
explicitly considers
open-source prompt-based metrics, by asking participants to evaluate <span class="ltx_text" id="S2.SS0.SSS0.Px1.p1.1.5" style="color:#000000;">MT</span> and <span class="ltx_text" id="S2.SS0.SSS0.Px1.p1.1.6" style="color:#000000;">summarization</span> using only provided models without fine-tuning.
The best submissions were able to beat strong baselines such as <span class="ltx_text ltx_font_smallcaps" id="S2.SS0.SSS0.Px1.p1.1.7">GEMBA</span> <cite class="ltx_cite ltx_citemacro_citep">(Kocmi and Federmann, <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib22" title="">2023b</a>)</cite> for MT and <span class="ltx_text ltx_font_smallcaps" id="S2.SS0.SSS0.Px1.p1.1.8">BARTScore</span> for summarization.</p>
</div>
<div class="ltx_para" id="S2.SS0.SSS0.Px1.p2">
<p class="ltx_p" id="S2.SS0.SSS0.Px1.p2.1">While the shared task yielded interesting techniques, the participants explored a limited range of prompts, leaving a gap in the comprehensive analysis of prompting patterns <span class="ltx_text" id="S2.SS0.SSS0.Px1.p2.1.1" style="color:#000000;">and the consistent comparison of LLMs.</span>
In this work,
<span class="ltx_text" id="S2.SS0.SSS0.Px1.p2.1.2" style="color:#000000;">we fill this gap and</span>
systematically analyze a much larger set of prompts on a comparable grid of experiment<span class="ltx_text" id="S2.SS0.SSS0.Px1.p2.1.3" style="color:#000000;">al</span> settings to (1) study the robustness of prompts across datasets, models and tasks, and to (2) search for rules and patterns that can guide the future construction of prompt-based metrics.</p>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px2">
<h3 class="ltx_title ltx_title_paragraph">Prompting Techniques</h3>
<div class="ltx_para" id="S2.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px2.p1.1"><span class="ltx_text" id="S2.SS0.SSS0.Px2.p1.1.1" style="color:#000000;">Many successful prompting techniques have been proposed over the last years <cite class="ltx_cite ltx_citemacro_citep">(e.g., Liu et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib33" title="">2023a</a>)</cite>. Our work mostly relies on established approaches such as
Zero-Shot CoT and RAG.
Further, <cite class="ltx_cite ltx_citemacro_citet">Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib30" title="">2023</a>)</cite> propose emotion inducing prompts to improve LLM performance.
To our best knowledge, we are the first to analyze this technique for evaluation metrics. Inspired by this, we also propose a novel emotion-CoT pattern (see §<a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#S3" title="3 Setup ‣ PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_tag">3</span></a>). Prior evaluation of output formats for prompt-based metrics is done by <cite class="ltx_cite ltx_citemacro_citet">Kocmi and Federmann (<a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib22" title="">2023b</a>)</cite>, which we extend
by our much broader evaluation.</span>
<span class="ltx_text" id="S2.SS0.SSS0.Px2.p1.1.2" style="color:#000000;">O</span>ther works also use hierarchical templates for prompt building <cite class="ltx_cite ltx_citemacro_citep">(e.g. Fu et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib13" title="">2023</a>)</cite> and tools like LangChain <cite class="ltx_cite ltx_citemacro_citep">(Chase, <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib4" title="">2022</a>)</cite> and DSPy <cite class="ltx_cite ltx_citemacro_citep">(Khattab et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib19" title="">2023</a>)</cite> support the<span class="ltx_text" id="S2.SS0.SSS0.Px2.p1.1.3" style="color:#000000;">ir</span>
implementation. We use hierarchical templates as means for a structured comparison among prompting patterns.</p>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px3">
<h3 class="ltx_title ltx_title_paragraph">Prompting Robustness</h3>
<div class="ltx_para" id="S2.SS0.SSS0.Px3.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px3.p1.1">As we <span class="ltx_text" id="S2.SS0.SSS0.Px3.p1.1.1" style="color:#000000;">conduct</span> a grid search across different prompts, datasets and tasks, our work <span class="ltx_text" id="S2.SS0.SSS0.Px3.p1.1.2" style="color:#000000;">builds upon and extends research on</span> how <span class="ltx_text ltx_font_smallcaps" id="S2.SS0.SSS0.Px3.p1.1.3">LLMs</span> <span class="ltx_text" id="S2.SS0.SSS0.Px3.p1.1.4" style="color:#000000;">respond to prompt perturbations</span>.
<cite class="ltx_cite ltx_citemacro_citet">Webson and Pavlick (<a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib43" title="">2022</a>)</cite>, <cite class="ltx_cite ltx_citemacro_citet">Leidinger et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib27" title="">2023</a>)</cite>, <cite class="ltx_cite ltx_citemacro_citet">Weber et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib42" title="">2023</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citet">Sclar et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib40" title="">2023</a>)</cite> find a wide range of performance variation for natural language inference and sentiment classification. As a solution, <cite class="ltx_cite ltx_citemacro_citet">Sclar et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib40" title="">2023</a>)</cite> suggest to provide the full range of results across different prompt perturbations. <cite class="ltx_cite ltx_citemacro_citet">Voronov et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib41" title="">2024</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citet">Mizrahi et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib35" title="">2024</a>)</cite> suggest that current evaluation benchmarks for <span class="ltx_text ltx_font_smallcaps" id="S2.SS0.SSS0.Px3.p1.1.5">LLMs</span> are problematic as they often only provide one
prompt template per task. This could be solved by providing multiple templates and evaluating the ensemble.
To our <span class="ltx_text" id="S2.SS0.SSS0.Px3.p1.1.6" style="color:#000000;">best</span> knowledge, <span class="ltx_text" id="S2.SS0.SSS0.Px3.p1.1.7" style="color:#000000;">we are</span>
the first to explore to which degree these robustness problems affect open-source <span class="ltx_text ltx_font_smallcaps" id="S2.SS0.SSS0.Px3.p1.1.8">LLM</span>-based metrics <span class="ltx_text" id="S2.SS0.SSS0.Px3.p1.1.9" style="color:#000000;">and how to select the best prompts for them. Also, by prompting the LLMs with multiple prompts, we follow <cite class="ltx_cite ltx_citemacro_citet">Mizrahi et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib35" title="">2024</a>)</cite> and achieve a stable and fair evaluation of LLMs for this task.</span></p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Setup</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1"><span class="ltx_text" id="S3.p1.1.1" style="color:#000000;">In this section, we present the templates and prompting techniques
we employ for utilizing <span class="ltx_text ltx_font_smallcaps" id="S3.p1.1.1.1">LLMs</span> as metrics. Additionally, we provide an overview of the datasets and models that we use for testing.</span> We evaluate <span class="ltx_text ltx_font_smallcaps" id="S3.p1.1.2">LLMs</span> in a <span class="ltx_text ltx_font_bold" id="S3.p1.1.3" style="color:#000000;">reference-free</span> setting<span class="ltx_text" id="S3.p1.1.4" style="color:#000000;">, i</span>.e., they grade a generated hypothesis
based on its source without a
reference.<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>We run experiments using <span class="ltx_text ltx_font_smallcaps" id="footnote3.1">vLLM</span> <cite class="ltx_cite ltx_citemacro_citep">(Kwon et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib24" title="">2023</a>)</cite> on two clusters with Nvidia A6000, A40 and A100 GPUS.
<span class="ltx_text" id="footnote3.2" style="color:#000000;">D</span>etails on versions, tools and model parameters
<span class="ltx_text" id="footnote3.3" style="color:#000000;">are</span>
in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#A2" title="Appendix B Implementation Details ‣ PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_tag">B</span></a>.</span></span></span>
<span class="ltx_text" id="S3.p1.1.5" style="color:#000000;">The evaluated prompt types provide a comprehensive evaluation framework for LLM-based metrics. This range covers basic in-context learning, sophisticated reasoning, emotional context, and varying output structures, ensuring a thorough
assessment of robustness and adaptability across tasks and datasets.</span></p>
</div>
<section class="ltx_paragraph" id="S3.SS0.SSS0.Px1">
<h3 class="ltx_title ltx_title_paragraph">Prompt Templates</h3>
<div class="ltx_para" id="S3.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S3.SS0.SSS0.Px1.p1.1">Our prompts are constructed as hierarchical templates (see Figure <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_tag">1</span></a>), <span class="ltx_text" id="S3.SS0.SSS0.Px1.p1.1.1" style="color:#000000;">i.e., one large template is constructed from multiple
smaller ones</span>.
<span class="ltx_text" id="S3.SS0.SSS0.Px1.p1.1.2" style="color:#000000;">Each prompt is constructed from: (1) the <span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px1.p1.1.2.1">source text</span> and generated <span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px1.p1.1.2.2">hypothesis text</span> that should be graded, (2) a <span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px1.p1.1.2.3">base prompt</span>, (3) a <span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px1.p1.1.2.4">task description</span>, (4) a <span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px1.p1.1.2.5">format requirement</span> and (5) optionally a one-shot <span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px1.p1.1.2.6">demonstration</span>. Table <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#S3.T1" title="Table 1 ‣ Prompt Templates ‣ 3 Setup ‣ PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_tag">1</span></a> presents examples for (2), (3), (4) and (5).</span></p>
</div>
<figure class="ltx_table" id="S3.T1">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S3.T1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.1.1">Category</span></th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S3.T1.1.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.1.1.1.2.1">
<span class="ltx_p" id="S3.T1.1.1.1.2.1.1" style="width:303.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.2.1.1.1">Description</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T1.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.1.2.1.1"><span class="ltx_text ltx_font_bold" id="S3.T1.1.2.1.1.1">Base Prompt Templates</span></th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.1.2.1.2">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.1.2.1.2.1">
<span class="ltx_p" id="S3.T1.1.2.1.2.1.1" style="width:303.5pt;"><span class="ltx_text ltx_font_bold ltx_font_smallcaps" id="S3.T1.1.2.1.2.1.1.1">PZS</span>: “{task_description} \nSource Text: {src} \n{result_type}: {hyp} \n{format_requirement} \nScore: ”</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.3.2">
<th class="ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r" id="S3.T1.1.3.2.1"></th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S3.T1.1.3.2.2">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.1.3.2.2.1">
<span class="ltx_p" id="S3.T1.1.3.2.2.1.1" style="width:303.5pt;"><span class="ltx_text ltx_font_bold ltx_font_smallcaps" id="S3.T1.1.3.2.2.1.1.1">ZS-CoT-EM</span>: “{task_description} \nSource Text: {src} \n{result_type}: {hyp} \n{format_requirement} \nFirst describe your emotions, then think step by step and explain your thought process, finally return your judgment in the format ’Judgment: ’.”</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.4.3">
<th class="ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r" id="S3.T1.1.4.3.1"></th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S3.T1.1.4.3.2">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.1.4.3.2.1">
<span class="ltx_p" id="S3.T1.1.4.3.2.1.1" style="width:303.5pt;"><span class="ltx_text ltx_font_bold ltx_font_smallcaps" id="S3.T1.1.4.3.2.1.1.1">OS-CoT</span>: “{task_description} \n Here is an example:\n Source Text: {ex_src} \n{result_type}: {ex_hyp}\n Judgement: &lt;Description of reasons&gt;. Therefore the score is {ex1_score}\n\n Now it is your turn to grade the {result_type}.\n Source Text: {src} \n{result_type}: {hyp} \n{format_requirement} \n First, think step by step and explain your thought process, then return your judgment in the format ’Judgment: ’.”</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.1.5.4.1"><span class="ltx_text ltx_font_bold" id="S3.T1.1.5.4.1.1" style="color:#000000;">Task Descriptions</span></th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.1.5.4.2">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.1.5.4.2.1">
<span class="ltx_p" id="S3.T1.1.5.4.2.1.1" style="width:303.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.1.5.4.2.1.1.1">Neutral</span>: “Judge the quality of the following {task_specific_insert}.”</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.6.5">
<th class="ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r" id="S3.T1.1.6.5.1"></th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S3.T1.1.6.5.2">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.1.6.5.2.1">
<span class="ltx_p" id="S3.T1.1.6.5.2.1.1" style="width:303.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.1.6.5.2.1.1.1">Sceptical</span>: “I’m not sure about this one. Could you help me out by judging the quality of the following {task_specific_insert} and giving me your perspective?”</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.7.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.1.7.6.1"><span class="ltx_text ltx_font_bold" id="S3.T1.1.7.6.1.1">Format Requirements</span></th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.1.7.6.2">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.1.7.6.2.1">
<span class="ltx_p" id="S3.T1.1.7.6.2.1.1" style="width:303.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.1.7.6.2.1.1.1">0 or 1</span>: Return a discrete score of 0 if the {result_type} has flaws and 1 if it is perfect.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.8.7">
<th class="ltx_td ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r" id="S3.T1.1.8.7.1"></th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r" id="S3.T1.1.8.7.2">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.1.8.7.2.1">
<span class="ltx_p" id="S3.T1.1.8.7.2.1.1" style="width:303.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.1.8.7.2.1.1.1">catastrophic</span>, <span class="ltx_text ltx_font_bold" id="S3.T1.1.8.7.2.1.1.2">indifferent</span> or <span class="ltx_text ltx_font_bold" id="S3.T1.1.8.7.2.1.1.3">marvelous</span>: Choose whether the {result_type} is either "catastrophic", "indifferent" or "marvelous".</span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Examples of prompt templates for the <span class="ltx_text ltx_font_italic" id="S3.T1.5.1">base prompt</span>, <span class="ltx_text ltx_font_italic" id="S3.T1.6.2">task description</span>, and <span class="ltx_text ltx_font_italic" id="S3.T1.7.3">format requirements</span>. The full list can be found in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#A1" title="Appendix A Prompt Templates ‣ PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_tag">A</span></a>.</figcaption>
</figure>
<div class="ltx_para" id="S3.SS0.SSS0.Px1.p2">
<p class="ltx_p" id="S3.SS0.SSS0.Px1.p2.1"><span class="ltx_text" id="S3.SS0.SSS0.Px1.p2.1.1" style="color:#000000;">The <span class="ltx_text ltx_font_bold" id="S3.SS0.SSS0.Px1.p2.1.1.1">base prompt</span> is the top layer of our prompt hierarchy, incorporating the other components. Specifically, we test three zero-shot (ZS) and corresponding one-shot (OS) base prompts: (1) <span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px1.p2.1.1.2">Plain ZS/OS</span> (<span class="ltx_text ltx_font_smallcaps" id="S3.SS0.SSS0.Px1.p2.1.1.3">PZS/POS</span>), (2) <span class="ltx_text ltx_font_smallcaps" id="S3.SS0.SSS0.Px1.p2.1.1.4">ZS/OS-CoT</span> and (3) <span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px1.p2.1.1.5">ZS/OS-CoT-Emotion</span> (<span class="ltx_text ltx_font_smallcaps" id="S3.SS0.SSS0.Px1.p2.1.1.6">ZS/OS-CoT-EM</span>).
<span class="ltx_text ltx_font_smallcaps" id="S3.SS0.SSS0.Px1.p2.1.1.7">PZS</span> plainly presents the newline separated <span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px1.p2.1.1.8">task description</span>, <span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px1.p2.1.1.9">source</span>, <span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px1.p2.1.1.10">hypothesis</span> and <span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px1.p2.1.1.11">format requirement</span>. <span class="ltx_text ltx_font_smallcaps" id="S3.SS0.SSS0.Px1.p2.1.1.12">ZS-CoT <cite class="ltx_cite ltx_citemacro_citep">(Kojima et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib23" title="">2022</a>)</cite></span> additionally asks the model to <span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px1.p2.1.1.13">think step by step</span> before returning its output. Lastly, <span class="ltx_text ltx_font_smallcaps" id="S3.SS0.SSS0.Px1.p2.1.1.14">ZS-CoT-EM</span>
asks the model to describe its “emotions” before the ZS-CoT prompt.
We include <span class="ltx_text ltx_font_smallcaps" id="S3.SS0.SSS0.Px1.p2.1.1.15">CoT</span> as it has improved the prompt-based performance for closed-source metrics like <span class="ltx_text ltx_font_smallcaps" id="S3.SS0.SSS0.Px1.p2.1.1.16">AutoMQM</span> <cite class="ltx_cite ltx_citemacro_citet">Fernandes et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib9" title="">2023</a>)</cite> and <span class="ltx_text ltx_font_smallcaps" id="S3.SS0.SSS0.Px1.p2.1.1.17">GEMBA</span> <cite class="ltx_cite ltx_citemacro_citep">(Kocmi and Federmann, <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib21" title="">2023a</a>)</cite>. <span class="ltx_text ltx_font_smallcaps" id="S3.SS0.SSS0.Px1.p2.1.1.18">ZS-CoT-EM</span> explores the variation of LLM performance when prompted to describe emotions in its output. This is motivated by our exploration of emotional prompts on metric performance (see “task description” below). The OS versions of the templates add a field for demonstrations. To avoid fixating the model on specific reasoning steps, we include a placeholder for OS-CoT where the model should insert its reasoning.</span></p>
</div>
<div class="ltx_para" id="S3.SS0.SSS0.Px1.p3">
<p class="ltx_p" id="S3.SS0.SSS0.Px1.p3.1">The <span class="ltx_text ltx_font_bold" id="S3.SS0.SSS0.Px1.p3.1.1">task description</span> is the instruction to grade the generated hypothesis. <cite class="ltx_cite ltx_citemacro_citet">Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib30" title="">2023</a>)</cite>
find that <span class="ltx_text ltx_font_smallcaps" id="S3.SS0.SSS0.Px1.p3.1.2">LLM</span> instructions that <span class="ltx_text" id="S3.SS0.SSS0.Px1.p3.1.3" style="color:#000000;">induce</span> certain emotions for humans can cause performance improvements. Inspired by this finding, we explore the usage of “emotional prompts” <span class="ltx_text" id="S3.SS0.SSS0.Px1.p3.1.4" style="color:#000000;">in the task description</span>. <span class="ltx_text" id="S3.SS0.SSS0.Px1.p3.1.5" style="color:#000000;">Primarily, this approach offers a simple paraphrasation strategy to increase the scope of our grid search. Additionally, it allows us to study the impact of “emotions” on <span class="ltx_text ltx_font_smallcaps" id="S3.SS0.SSS0.Px1.p3.1.5.1">LLM</span>-based metrics</span>. Besides <span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px1.p3.1.6">neutral</span> prompts, we include instructions that are, e.g., <span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px1.p3.1.7">polite</span>, <span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px1.p3.1.8">threatening</span> and <span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px1.p3.1.9">sceptical</span>. We create 11 task descriptions ourselves and 13 further descriptions with <span class="ltx_text ltx_font_smallcaps" id="S3.SS0.SSS0.Px1.p3.1.10">ChatGPT</span> <cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib37" title="">2023</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S3.SS0.SSS0.Px1.p4">
<p class="ltx_p" id="S3.SS0.SSS0.Px1.p4.1">The <span class="ltx_text ltx_font_bold" id="S3.SS0.SSS0.Px1.p4.1.1">format requirement</span> describes the output format the <span class="ltx_text ltx_font_smallcaps" id="S3.SS0.SSS0.Px1.p4.1.2">LLM</span> should adhere to when generating a score. For example, it includes the range in which the output score should be and whether it should be discrete or continuous. Additionally, we include prompts that ask the <span class="ltx_text ltx_font_smallcaps" id="S3.SS0.SSS0.Px1.p4.1.3">LLM</span> to return textual quality labels. In total, we <span class="ltx_text" id="S3.SS0.SSS0.Px1.p4.1.4" style="color:#000000;">define</span> 10 <span class="ltx_text" id="S3.SS0.SSS0.Px1.p4.1.5" style="color:#000000;">format requirements</span>.</p>
</div>
<div class="ltx_para" id="S3.SS0.SSS0.Px1.p5">
<p class="ltx_p" id="S3.SS0.SSS0.Px1.p5.1">Lastly, we construct the optional OS <span class="ltx_text ltx_font_bold" id="S3.SS0.SSS0.Px1.p5.1.1">demonstrations</span> with
<span class="ltx_text" id="S3.SS0.SSS0.Px1.p5.1.2" style="color:#000000;">RAG.</span>
We extract demonstrations from <span class="ltx_text ltx_font_smallcaps" id="S3.SS0.SSS0.Px1.p5.1.3">WMT21</span> <cite class="ltx_cite ltx_citemacro_citep">(Freitag et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib12" title="">2021</a>)</cite> for MT and from <span class="ltx_text ltx_font_smallcaps" id="S3.SS0.SSS0.Px1.p5.1.4">RoSE</span> for summarization.<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>Note that <span class="ltx_text ltx_font_smallcaps" id="footnote4.1">RoSE</span> only considers factuality, which is only one aspect of the evaluated datasets.</span></span></span> <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib34" title="">2023b</a>)</cite>. For each sample in both datasets <span class="ltx_text" id="S3.SS0.SSS0.Px1.p5.1.5" style="color:#000000;">and for each input sample of our metric</span>, we create sentence embeddings with <span class="ltx_text ltx_font_smallcaps" id="S3.SS0.SSS0.Px1.p5.1.6">XLMR-SBERT</span> <cite class="ltx_cite ltx_citemacro_citep">(Reimers and Gurevych, <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib39" title="">2020</a>)</cite>. Thereby<span class="ltx_text" id="S3.SS0.SSS0.Px1.p5.1.7" style="color:#000000;">,</span> we concatenate <span class="ltx_text" id="S3.SS0.SSS0.Px1.p5.1.8" style="color:#000000;">the source and hypothesis embeddings</span>. <span class="ltx_text" id="S3.SS0.SSS0.Px1.p5.1.9" style="color:#000000;">For each input,</span> we select the demonstration with the highest cosine similarity. <span class="ltx_text" id="S3.SS0.SSS0.Px1.p5.1.10" style="color:#000000;">Due to resource limitations, we only evaluate the 9 best ZS prompts in a OS setting. The selection process is described in the paragraph <span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px1.p5.1.10.1">Datasets and phases</span> below.</span></p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS0.SSS0.Px2">
<h3 class="ltx_title ltx_title_paragraph">MQM-based approaches</h3>
<div class="ltx_para" id="S3.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S3.SS0.SSS0.Px2.p1.1">Additionally to hierarchical templates, we test the prompts of <span class="ltx_text ltx_font_smallcaps" id="S3.SS0.SSS0.Px2.p1.1.1">GEMBA-MQM</span> <cite class="ltx_cite ltx_citemacro_citep">(Kocmi and Federmann, <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib21" title="">2023a</a>)</cite> with the selected open-source <span class="ltx_text ltx_font_smallcaps" id="S3.SS0.SSS0.Px2.p1.1.2">LLMs</span>. <span class="ltx_text ltx_font_smallcaps" id="S3.SS0.SSS0.Px2.p1.1.3">GEMBA-MQM</span>, which predicts scores based on the number of present errors weighted by severity, normally uses <span class="ltx_text ltx_font_smallcaps" id="S3.SS0.SSS0.Px2.p1.1.4">GPT4</span>. We refer to <span class="ltx_text" id="S3.SS0.SSS0.Px2.p1.1.5" style="color:#000000;">the open-source implementation</span> as <span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px2.p1.1.6">LocalGemba</span>.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS0.SSS0.Px3">
<h3 class="ltx_title ltx_title_paragraph">Score Extraction &amp; Evaluation</h3>
<div class="ltx_para" id="S3.SS0.SSS0.Px3.p1">
<p class="ltx_p" id="S3.SS0.SSS0.Px3.p1.1">We restrict generation to 180 tokens and extract the last regex match of a number/label as scores. When no result is found<span class="ltx_text" id="S3.SS0.SSS0.Px3.p1.1.1" style="color:#000000;">,</span>
we average the other scores of its prompt template. For <span class="ltx_text" id="S3.SS0.SSS0.Px3.p1.1.2" style="color:#000000;">format requirements</span> with text labels, we map the <span class="ltx_text" id="S3.SS0.SSS0.Px3.p1.1.3" style="color:#000000;">labels to 1, 3 and 5</span>.</p>
</div>
<div class="ltx_para" id="S3.SS0.SSS0.Px3.p2">
<p class="ltx_p" id="S3.SS0.SSS0.Px3.p2.1">We evaluate prompt templates on the segment-level, like the WMT QE and metrics shared tasks <cite class="ltx_cite ltx_citemacro_citep">(e.g. Freitag et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib11" title="">2022</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib12" title="">2021</a>; Zerva et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib45" title="">2022</a>)</cite>. <span class="ltx_text" id="S3.SS0.SSS0.Px3.p2.1.1" style="color:#000000;">That means, for each metric we compute the correlation between metric scores and ground truth human judgments without averaging by system or document.</span>
As correlation measure, we use the Kendall <cite class="ltx_cite ltx_citemacro_citep">(Kendall, <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib18" title="">1945</a>)</cite>, Pearson and Spearman correlations, as well as tie-calibrated accuracy <cite class="ltx_cite ltx_citemacro_citep">(Deutsch et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib7" title="">2023</a>)</cite>, <span class="ltx_text" id="S3.SS0.SSS0.Px3.p2.1.2" style="color:#000000;">with Kendall as main measure</span>. Further, we compute permute-input significance tests (<math alttext="p\leq 0.075" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px3.p2.1.m1.1"><semantics id="S3.SS0.SSS0.Px3.p2.1.m1.1a"><mrow id="S3.SS0.SSS0.Px3.p2.1.m1.1.1" xref="S3.SS0.SSS0.Px3.p2.1.m1.1.1.cmml"><mi id="S3.SS0.SSS0.Px3.p2.1.m1.1.1.2" xref="S3.SS0.SSS0.Px3.p2.1.m1.1.1.2.cmml">p</mi><mo id="S3.SS0.SSS0.Px3.p2.1.m1.1.1.1" xref="S3.SS0.SSS0.Px3.p2.1.m1.1.1.1.cmml">≤</mo><mn id="S3.SS0.SSS0.Px3.p2.1.m1.1.1.3" xref="S3.SS0.SSS0.Px3.p2.1.m1.1.1.3.cmml">0.075</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px3.p2.1.m1.1b"><apply id="S3.SS0.SSS0.Px3.p2.1.m1.1.1.cmml" xref="S3.SS0.SSS0.Px3.p2.1.m1.1.1"><leq id="S3.SS0.SSS0.Px3.p2.1.m1.1.1.1.cmml" xref="S3.SS0.SSS0.Px3.p2.1.m1.1.1.1"></leq><ci id="S3.SS0.SSS0.Px3.p2.1.m1.1.1.2.cmml" xref="S3.SS0.SSS0.Px3.p2.1.m1.1.1.2">𝑝</ci><cn id="S3.SS0.SSS0.Px3.p2.1.m1.1.1.3.cmml" type="float" xref="S3.SS0.SSS0.Px3.p2.1.m1.1.1.3">0.075</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px3.p2.1.m1.1c">p\leq 0.075</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px3.p2.1.m1.1d">italic_p ≤ 0.075</annotation></semantics></math>) <cite class="ltx_cite ltx_citemacro_citep">(Deutsch et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib6" title="">2021</a>)</cite> for the Kendall correlations presented in our result <span class="ltx_text" id="S3.SS0.SSS0.Px3.p2.1.3" style="color:#000000;">t</span>ables. Often<span class="ltx_text" id="S3.SS0.SSS0.Px3.p2.1.4" style="color:#000000;">,</span> there is no single significantly best metric. Therefore, we report clusters where each included metric is significantly better than metrics that are not included.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS0.SSS0.Px4">
<h3 class="ltx_title ltx_title_paragraph" style="color:#000000;">Models</h3>
<div class="ltx_para" id="S3.SS0.SSS0.Px4.p1">
<p class="ltx_p" id="S3.SS0.SSS0.Px4.p1.1">We select instruction-tuned <span class="ltx_text ltx_font_smallcaps" id="S3.SS0.SSS0.Px4.p1.1.1">LLMs</span> <span class="ltx_text" id="S3.SS0.SSS0.Px4.p1.1.2" style="color:#000000;">with strong</span> performance in <span class="ltx_text ltx_font_smallcaps" id="S3.SS0.SSS0.Px4.p1.1.3">Eval4NLP 2023</span>: <span class="ltx_text" id="S3.SS0.SSS0.Px4.p1.1.4" style="color:#000000;">(1)</span> <span class="ltx_text ltx_font_smallcaps" id="S3.SS0.SSS0.Px4.p1.1.5">Platypus2-70B-Instruct-GPTQ</span>,
<span class="ltx_text" id="S3.SS0.SSS0.Px4.p1.1.6" style="color:#000000;">(2)</span> <span class="ltx_text ltx_font_smallcaps" id="S3.SS0.SSS0.Px4.p1.1.7">Nous-Hermes-13b</span> <span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/NousResearch/Nous-Hermes-13b" title="">https://huggingface.co/NousResearch/Nous-Hermes-13b</a></span></span></span> and
<span class="ltx_text" id="S3.SS0.SSS0.Px4.p1.1.8" style="color:#000000;">(3)</span> <span class="ltx_text ltx_font_smallcaps" id="S3.SS0.SSS0.Px4.p1.1.9">OpenOrca-Platypus2-13B</span>
<cite class="ltx_cite ltx_citemacro_citep">(Lee et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib26" title="">2023b</a>; Mukherjee et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib36" title="">2023</a>)</cite>.
We abbreviate these as <span class="ltx_text ltx_font_smallcaps" id="S3.SS0.SSS0.Px4.p1.1.10">Platypus2</span>, <span class="ltx_text ltx_font_smallcaps" id="S3.SS0.SSS0.Px4.p1.1.11">Nous</span> and <span class="ltx_text ltx_font_smallcaps" id="S3.SS0.SSS0.Px4.p1.1.12">Orca</span>.
<span class="ltx_text" id="S3.SS0.SSS0.Px4.p1.1.13" style="color:#000000;">Additionally, we evaluate
more recent models: (4) <span class="ltx_text ltx_font_smallcaps" id="S3.SS0.SSS0.Px4.p1.1.13.1">LLaMA3-8B</span> <cite class="ltx_cite ltx_citemacro_citep">(AI@Meta, <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib1" title="">2024</a>)</cite>, (5) a GPTQ version of <span class="ltx_text ltx_font_smallcaps" id="S3.SS0.SSS0.Px4.p1.1.13.2">LLaMA3-70B</span> <cite class="ltx_cite ltx_citemacro_citep">(AI@Meta, <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib1" title="">2024</a>)</cite>, (6) <span class="ltx_text ltx_font_smallcaps" id="S3.SS0.SSS0.Px4.p1.1.13.3">Mixtral-8x7B<span class="ltx_note ltx_role_footnote" id="footnote6"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_upright" id="footnote6.1.1.1" style="color:#000000;">6</span></span><span class="ltx_text ltx_font_upright" id="footnote6.5">Due to high resource</span><span class="ltx_text ltx_font_upright" id="footnote6.6" style="color:#000000;"> consumption and comparatively weak performance in phase 1, we do not evaluate </span><span class="ltx_text" id="footnote6.7" style="color:#000000;">Mixtral</span><span class="ltx_text ltx_font_upright" id="footnote6.8" style="color:#000000;"> in phase 2.</span></span></span></span></span> <cite class="ltx_cite ltx_citemacro_citep">(Jiang et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib17" title="">2024</a>)</cite> and <span class="ltx_text ltx_font_smallcaps" id="S3.SS0.SSS0.Px4.p1.1.13.4">Unbabel-Tower</span> <cite class="ltx_cite ltx_citemacro_citep">(Alves et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib2" title="">2024</a>)</cite>, a 13B parameter multilingual instruction-tuned model.</span></p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS0.SSS0.Px5">
<h3 class="ltx_title ltx_title_paragraph" style="color:#000000;">Datasets and phases</h3>
<div class="ltx_para" id="S3.SS0.SSS0.Px5.p1">
<p class="ltx_p" id="S3.SS0.SSS0.Px5.p1.1"><span class="ltx_text" id="S3.SS0.SSS0.Px5.p1.1.1" style="color:#000000;">O</span>ur experiments <span class="ltx_text" id="S3.SS0.SSS0.Px5.p1.1.2" style="color:#000000;">are</span> in two phases on different datasets. By doing so, we want to alleviate statistical effects of our large prompt search. Also, it allows
to evaluate selected prompts on full datasets,
a task that would otherwise be too resource intensive,
and to explore generalizability.</p>
</div>
<div class="ltx_para" id="S3.SS0.SSS0.Px5.p2">
<p class="ltx_p" id="S3.SS0.SSS0.Px5.p2.1">In phase 1, we evaluate on the train set of <span class="ltx_text ltx_font_smallcaps" id="S3.SS0.SSS0.Px5.p2.1.1">Eval4NLP 2023</span> <cite class="ltx_cite ltx_citemacro_citep">(Leiter et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib29" title="">2023</a>)</cite>, and in phase 2,
on its dev and test sets.<span class="ltx_note ltx_role_footnote" id="footnote7"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span>Although we do not use the datasets to train a model, for conciseness, we will refer to these dataset as train, dev and test set.</span></span></span> The train and dev sets are (reference-free) splits of the <span class="ltx_text ltx_font_smallcaps" id="S3.SS0.SSS0.Px5.p2.1.2">WMT2022</span> metrics shared task <cite class="ltx_cite ltx_citemacro_citep">(Freitag et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib11" title="">2022</a>)</cite> and <span class="ltx_text ltx_font_smallcaps" id="S3.SS0.SSS0.Px5.p2.1.3">SummEval</span> <cite class="ltx_cite ltx_citemacro_citep">(Fabbri et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib8" title="">2021</a>)</cite>. The test set was newly annotated by <cite class="ltx_cite ltx_citemacro_citet">Leiter et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib29" title="">2023</a>)</cite>. As a second test set, we evaluate on the WMT23 MQM annotations for MT <cite class="ltx_cite ltx_citemacro_citep">(Freitag et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib10" title="">2023</a>)</cite> and <span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px5.p2.1.4">Seahorse</span> <cite class="ltx_cite ltx_citemacro_citep">(Clark et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib5" title="">2023</a>)</cite> for <span class="ltx_text" id="S3.SS0.SSS0.Px5.p2.1.5" style="color:#000000;">multilingual </span>summarization. <span class="ltx_text" id="S3.SS0.SSS0.Px5.p2.1.6" style="color:#000000;">Because OS prompts demonstrate a weak performance on the other datasets, we do not evaluate them on <span class="ltx_text ltx_font_smallcaps" id="S3.SS0.SSS0.Px5.p2.1.6.1">WMT23</span>/<span class="ltx_text ltx_font_smallcaps" id="S3.SS0.SSS0.Px5.p2.1.6.2">Seahorse</span>.</span> More details of the datasets are discussed in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#A3" title="Appendix C Dataset Details ‣ PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_tag">C</span></a>.</p>
</div>
<div class="ltx_para" id="S3.SS0.SSS0.Px5.p3">
<p class="ltx_p" id="S3.SS0.SSS0.Px5.p3.1">In the <span class="ltx_text ltx_font_bold" id="S3.SS0.SSS0.Px5.p3.1.1" style="color:#000000;">1st<span class="ltx_text" id="S3.SS0.SSS0.Px5.p3.1.1.1" style="color:#000000;"> phase</span></span>, we evaluate all 720<span class="ltx_note ltx_role_footnote" id="footnote8"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span>Considering the different tasks and language pairs, this number could also be considered higher.</span></span></span> <span class="ltx_text" id="S3.SS0.SSS0.Px5.p3.1.2" style="color:#000000;">combinations of
ZS
prompts on the train set</span>. As this is
resource intensive,
for MT we restrict ourselves to the first 500 samples <span class="ltx_text" id="S3.SS0.SSS0.Px5.p3.1.3" style="color:#000000;">of each language pair</span>. <span class="ltx_text" id="S3.SS0.SSS0.Px5.p3.1.4" style="color:#000000;">Afterwards, we select the prompt with the highest Kendall
correlation for each <span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px5.p3.1.4.1">task+base prompt</span> combination (e.g. en-de+<span class="ltx_text ltx_font_smallcaps" id="S3.SS0.SSS0.Px5.p3.1.4.2">PZS</span> or en-de+<span class="ltx_text ltx_font_smallcaps" id="S3.SS0.SSS0.Px5.p3.1.4.3">ZS-CoT</span>).<span class="ltx_note ltx_role_footnote" id="footnote9"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text" id="footnote9.1.1.1" style="color:#000000;">9</span></span><span class="ltx_text" id="footnote9.5" style="color:#000000;">Tasks: en-de, zh-en, summarization. In case of duplicates, we choose the second best.</span></span></span></span>
This yields 9 unique prompts
for exploration
in the phase 2 (see Appendix <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#A6" title="Appendix F Prompt selection ‣ PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_tag">F</span></a>).</span></p>
</div>
<div class="ltx_para" id="S3.SS0.SSS0.Px5.p4">
<p class="ltx_p" id="S3.SS0.SSS0.Px5.p4.1">In the <span class="ltx_text ltx_font_bold" id="S3.SS0.SSS0.Px5.p4.1.1" style="color:#000000;">2nd<span class="ltx_text" id="S3.SS0.SSS0.Px5.p4.1.1.1" style="color:#000000;"> phase</span></span>, we evaluate the selected prompts of the
<span class="ltx_text" id="S3.SS0.SSS0.Px5.p4.1.2" style="color:#000000;">1st</span>
phase on the full dev and test sets.
<span class="ltx_text" id="S3.SS0.SSS0.Px5.p4.1.3" style="color:#000000;">This</span> further test<span class="ltx_text" id="S3.SS0.SSS0.Px5.p4.1.4" style="color:#000000;">s</span> the generalizability of prompts between models and for unseen, in-domain data (the train and dev set stem from the same original datasets) and out-domain data (test sets).</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS0.SSS0.Px6">
<h3 class="ltx_title ltx_title_paragraph">Baselines</h3>
<div class="ltx_para" id="S3.SS0.SSS0.Px6.p1">
<p class="ltx_p" id="S3.SS0.SSS0.Px6.p1.1">For each phase, we also present the correlations of <span class="ltx_text" id="S3.SS0.SSS0.Px6.p1.1.1" style="color:#000000;">two baseline metrics that use other base models: <span class="ltx_text ltx_font_smallcaps" id="S3.SS0.SSS0.Px6.p1.1.1.1">BARTScore</span> <cite class="ltx_cite ltx_citemacro_citep">(Yuan et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib44" title="">2021</a>)</cite> and <span class="ltx_text ltx_font_smallcaps" id="S3.SS0.SSS0.Px6.p1.1.1.2">XComet</span> <cite class="ltx_cite ltx_citemacro_citep">(Guerreiro et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib16" title="">2023</a>)</cite>. Especially <span class="ltx_text ltx_font_smallcaps" id="S3.SS0.SSS0.Px6.p1.1.1.3">XComet</span> has the benefit of being trained on multilingual datasets.</span>
Further, we test the prompts of <span class="ltx_text ltx_font_smallcaps" id="S3.SS0.SSS0.Px6.p1.1.2">DSBA</span> <cite class="ltx_cite ltx_citemacro_citep">(Kim et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib20" title="">2023</a>)</cite> <span class="ltx_text" id="S3.SS0.SSS0.Px6.p1.1.3" style="color:#000000;">— that showed a strong performance for summarization in the shared task —</span> with the selected open-source <span class="ltx_text ltx_font_smallcaps" id="S3.SS0.SSS0.Px6.p1.1.4">LLMs</span> <span class="ltx_text" id="S3.SS0.SSS0.Px6.p1.1.5" style="color:#000000;">Platypus2-70B and Orca-13B</span>.</p>
</div>
<figure class="ltx_table" id="S3.T2">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S3.T2.3">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T2.3.1.1">
<td class="ltx_td ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.3.1.1.1"></td>
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" colspan="3" id="S3.T2.3.1.1.2"><span class="ltx_text ltx_font_bold" id="S3.T2.3.1.1.2.1">P1: Eval4NLP train</span></td>
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" colspan="4" id="S3.T2.3.1.1.3"><span class="ltx_text ltx_font_bold" id="S3.T2.3.1.1.3.1">P2: Eval4NLP test</span></td>
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" colspan="4" id="S3.T2.3.1.1.4"><span class="ltx_text ltx_font_bold" id="S3.T2.3.1.1.4.1">P2: WMT23/Seahorse</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.2.2">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.3.2.2.1"><span class="ltx_text ltx_font_bold" id="S3.T2.3.2.2.1.1">Model</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.3.2.2.2"><span class="ltx_text ltx_font_bold" id="S3.T2.3.2.2.2.1">en-de</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.3.2.2.3"><span class="ltx_text ltx_font_bold" id="S3.T2.3.2.2.3.1">zh-en</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.3.2.2.4"><span class="ltx_text ltx_font_bold" id="S3.T2.3.2.2.4.1">summ</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.3.2.2.5"><span class="ltx_text ltx_font_bold" id="S3.T2.3.2.2.5.1">en-de</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.3.2.2.6"><span class="ltx_text ltx_font_bold" id="S3.T2.3.2.2.6.1">en-es</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.3.2.2.7"><span class="ltx_text ltx_font_bold" id="S3.T2.3.2.2.7.1">en_zh</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.3.2.2.8"><span class="ltx_text ltx_font_bold" id="S3.T2.3.2.2.8.1">summ</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.3.2.2.9"><span class="ltx_text ltx_font_bold" id="S3.T2.3.2.2.9.1">en-de</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.3.2.2.10"><span class="ltx_text ltx_font_bold" id="S3.T2.3.2.2.10.1">he-en</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.3.2.2.11"><span class="ltx_text ltx_font_bold" id="S3.T2.3.2.2.11.1">zh-en</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.3.2.2.12"><span class="ltx_text ltx_font_bold" id="S3.T2.3.2.2.12.1">summ</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.3.3">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" colspan="12" id="S3.T2.3.3.3.1"><span class="ltx_text ltx_font_bold" id="S3.T2.3.3.3.1.1" style="color:#000000;">1. Hierarchical Templates</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.4.4">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.3.4.4.1">LL3-70B</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.3.4.4.2"><span class="ltx_text" id="S3.T2.3.4.4.2.1" style="color:#0000FF;">0.273</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.3.4.4.3"><span class="ltx_text" id="S3.T2.3.4.4.3.1" style="color:#FF8000;">0.306</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.3.4.4.4"><span class="ltx_text" id="S3.T2.3.4.4.4.1" style="color:#FF8000;">0.442</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.3.4.4.5"><span class="ltx_text" id="S3.T2.3.4.4.5.1" style="color:#FF8000;">0.245</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.3.4.4.6"><span class="ltx_text" id="S3.T2.3.4.4.6.1" style="color:#FF8000;">0.189</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.3.4.4.7"><span class="ltx_text" id="S3.T2.3.4.4.7.1" style="color:#FF8000;">0.231</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.3.4.4.8"><span class="ltx_text" id="S3.T2.3.4.4.8.1" style="color:#FF8000;">0.438</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.3.4.4.9"><span class="ltx_text" id="S3.T2.3.4.4.9.1" style="color:#FF8000;">0.297</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.3.4.4.10"><span class="ltx_text" id="S3.T2.3.4.4.10.1" style="color:#FF8000;">0.172</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.3.4.4.11"><span class="ltx_text" id="S3.T2.3.4.4.11.1" style="color:#FF8000;">0.312</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.3.4.4.12"><span class="ltx_text" id="S3.T2.3.4.4.12.1" style="color:#FF8000;">0.312</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.5.5">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="S3.T2.3.5.5.1">LL3-8B</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.5.5.2"><span class="ltx_text" id="S3.T2.3.5.5.2.1" style="color:#0000FF;">0.251</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.5.5.3"><span class="ltx_text" id="S3.T2.3.5.5.3.1" style="color:#FF8000;">0.236</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.5.5.4"><span class="ltx_text" id="S3.T2.3.5.5.4.1" style="color:#FF8000;">0.334</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.5.5.5"><span class="ltx_text" id="S3.T2.3.5.5.5.1" style="color:#0000FF;">0.167</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.5.5.6"><span class="ltx_text" id="S3.T2.3.5.5.6.1" style="color:#0000FF;">0.158</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.5.5.7"><span class="ltx_text" id="S3.T2.3.5.5.7.1" style="color:#0000FF;">0.145</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.5.5.8"><span class="ltx_text" id="S3.T2.3.5.5.8.1" style="color:#FF8000;">0.412</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.5.5.9"><span class="ltx_text" id="S3.T2.3.5.5.9.1" style="color:#FF8000;">0.166</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.5.5.10"><span class="ltx_text" id="S3.T2.3.5.5.10.1" style="color:#0000FF;">0.118</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.5.5.11"><span class="ltx_text" id="S3.T2.3.5.5.11.1" style="color:#FF8000;">0.164</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.5.5.12"><span class="ltx_text" id="S3.T2.3.5.5.12.1" style="color:#0000FF;">0.200</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.6.6">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="S3.T2.3.6.6.1">MI-7Bx8</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.6.6.2"><span class="ltx_text" id="S3.T2.3.6.6.2.1" style="color:#FF8000;">0.268*</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.6.6.3"><span class="ltx_text" id="S3.T2.3.6.6.3.1" style="color:#FF8000;">0.264</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.6.6.4"><span class="ltx_text" id="S3.T2.3.6.6.4.1" style="color:#FF8000;">0.365</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.6.6.5">-</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.6.6.6">-</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.6.6.7">-</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.6.6.8">-</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.6.6.9">-</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.6.6.10">-</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.6.6.11">-</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.6.6.12">-</td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.7.7">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="S3.T2.3.7.7.1">NO-13B</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.7.7.2"><span class="ltx_text" id="S3.T2.3.7.7.2.1" style="color:#0000FF;">0.230</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.7.7.3"><span class="ltx_text" id="S3.T2.3.7.7.3.1" style="color:#FF8000;">0.201</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.7.7.4"><span class="ltx_text" id="S3.T2.3.7.7.4.1" style="color:#0000FF;">0.225</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.7.7.5"><span class="ltx_text" id="S3.T2.3.7.7.5.1" style="color:#FF8000;">0.205</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.7.7.6"><span class="ltx_text" id="S3.T2.3.7.7.6.1" style="color:#FF8000;">0.141</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.7.7.7"><span class="ltx_text" id="S3.T2.3.7.7.7.1" style="color:#FF8000;">0.084</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.7.7.8"><span class="ltx_text" id="S3.T2.3.7.7.8.1" style="color:#FF8000;">0.255</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.7.7.9"><span class="ltx_text" id="S3.T2.3.7.7.9.1" style="color:#FF8000;">0.202</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.7.7.10"><span class="ltx_text" id="S3.T2.3.7.7.10.1" style="color:#FF8000;">0.105</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.7.7.11"><span class="ltx_text" id="S3.T2.3.7.7.11.1" style="color:#FF8000;">0.175</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.7.7.12"><span class="ltx_text" id="S3.T2.3.7.7.12.1" style="color:#FF8000;">0.123</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.8.8">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="S3.T2.3.8.8.1">OR-13B</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.8.8.2"><span class="ltx_text" id="S3.T2.3.8.8.2.1" style="color:#0000FF;">0.289</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.8.8.3"><span class="ltx_text" id="S3.T2.3.8.8.3.1" style="color:#0000FF;">0.303</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.8.8.4"><span class="ltx_text" id="S3.T2.3.8.8.4.1" style="color:#0000FF;">0.468*</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.8.8.5"><span class="ltx_text" id="S3.T2.3.8.8.5.1" style="color:#FF8000;">0.214</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.8.8.6"><span class="ltx_text" id="S3.T2.3.8.8.6.1" style="color:#0000FF;">0.158</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.8.8.7"><span class="ltx_text" id="S3.T2.3.8.8.7.1" style="color:#0000FF;">0.206</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.8.8.8"><span class="ltx_text" id="S3.T2.3.8.8.8.1" style="color:#0000FF;">0.518</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.8.8.9"><span class="ltx_text" id="S3.T2.3.8.8.9.1" style="color:#0000FF;">0.375</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.8.8.10"><span class="ltx_text" id="S3.T2.3.8.8.10.1" style="color:#0000FF;">0.247</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.8.8.11"><span class="ltx_text" id="S3.T2.3.8.8.11.1" style="color:#0000FF;">0.387</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.8.8.12"><span class="ltx_text" id="S3.T2.3.8.8.12.1" style="color:#0000FF;">0.377</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.9.9">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="S3.T2.3.9.9.1">PL-70B</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.9.9.2"><span class="ltx_text ltx_font_bold" id="S3.T2.3.9.9.2.1" style="color:#0000FF;">0.344*</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.9.9.3"><span class="ltx_text ltx_font_bold" id="S3.T2.3.9.9.3.1" style="color:#0000FF;">0.364*</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.9.9.4"><span class="ltx_text ltx_font_bold" id="S3.T2.3.9.9.4.1" style="color:#0000FF;">0.519*</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.9.9.5"><span class="ltx_text ltx_font_bold" id="S3.T2.3.9.9.5.1" style="color:#0000FF;">0.402*</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.9.9.6"><span class="ltx_text ltx_font_bold" id="S3.T2.3.9.9.6.1" style="color:#0000FF;">0.289*</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.9.9.7"><span class="ltx_text" id="S3.T2.3.9.9.7.1" style="color:#0000FF;">0.295*</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.9.9.8"><span class="ltx_text" id="S3.T2.3.9.9.8.1" style="color:#0000FF;">0.549</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.9.9.9"><span class="ltx_text" id="S3.T2.3.9.9.9.1" style="color:#0000FF;">0.338</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.9.9.10"><span class="ltx_text ltx_font_bold" id="S3.T2.3.9.9.10.1" style="color:#0000FF;">0.259*</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.9.9.11"><span class="ltx_text ltx_font_bold" id="S3.T2.3.9.9.11.1" style="color:#0000FF;">0.417*</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.9.9.12"><span class="ltx_text ltx_font_bold" id="S3.T2.3.9.9.12.1" style="color:#0000FF;">0.448*</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.10.10">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="S3.T2.3.10.10.1">TO-13B</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.10.10.2"><span class="ltx_text" id="S3.T2.3.10.10.2.1" style="color:#FF8000;">0.284*</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.10.10.3"><span class="ltx_text" id="S3.T2.3.10.10.3.1" style="color:#FF8000;">0.318*</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.10.10.4"><span class="ltx_text" id="S3.T2.3.10.10.4.1" style="color:#FF8000;">0.375</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.10.10.5"><span class="ltx_text" id="S3.T2.3.10.10.5.1" style="color:#FF8000;">0.379*</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.10.10.6"><span class="ltx_text" id="S3.T2.3.10.10.6.1" style="color:#FF8000;">0.253</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.10.10.7"><span class="ltx_text" id="S3.T2.3.10.10.7.1" style="color:#FF8000;">0.232</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.10.10.8"><span class="ltx_text" id="S3.T2.3.10.10.8.1" style="color:#FF8000;">0.409</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.10.10.9"><span class="ltx_text" id="S3.T2.3.10.10.9.1" style="color:#FF8000;">0.322</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.10.10.10"><span class="ltx_text" id="S3.T2.3.10.10.10.1" style="color:#FF8000;">0.208</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.10.10.11"><span class="ltx_text" id="S3.T2.3.10.10.11.1" style="color:#FF8000;">0.314</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.10.10.12"><span class="ltx_text" id="S3.T2.3.10.10.12.1" style="color:#FF8000;">0.257</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.11.11">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" colspan="12" id="S3.T2.3.11.11.1"><span class="ltx_text ltx_font_bold" id="S3.T2.3.11.11.1.1" style="color:#000000;">2. Separate Prompting Techniques</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.12.12">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.3.12.12.1">M:LG</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.3.12.12.2">0.278*</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.3.12.12.3">0.268</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.3.12.12.4">0.062</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.3.12.12.5">0.344</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.3.12.12.6">0.265</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.3.12.12.7"><span class="ltx_text ltx_font_bold" id="S3.T2.3.12.12.7.1">0.307*</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.3.12.12.8">0.116</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.3.12.12.9"><span class="ltx_text ltx_font_bold" id="S3.T2.3.12.12.9.1">0.391*</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.3.12.12.10">0.190</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.3.12.12.11">0.300</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.3.12.12.12">0.144</td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.13.13">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="S3.T2.3.13.13.1">B:DSBA</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.13.13.2">0.164</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.13.13.3">0.306</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.13.13.4">0.458</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.13.13.5">0.314</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.13.13.6">0.226</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.13.13.7">0.159</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.13.13.8"><span class="ltx_text ltx_font_bold" id="S3.T2.3.13.13.8.1">0.600*</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.13.13.9">0.172</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.13.13.10">0.207</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.13.13.11">0.376</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.3.13.13.12">0.373</td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.14.14">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" colspan="12" id="S3.T2.3.14.14.1"><span class="ltx_text ltx_font_bold" id="S3.T2.3.14.14.1.1" style="color:#000000;">3. Baselines with External Base Models</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.15.15">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.3.15.15.1">B:BS</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.3.15.15.2">0.056</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.3.15.15.3">-0.109</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.3.15.15.4">0.155</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.3.15.15.5">0.125</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.3.15.15.6">0.139</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.3.15.15.7">-0.009</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.3.15.15.8">0.421</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.3.15.15.9">-0.018</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.3.15.15.10">0.001</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.3.15.15.11">-0.167</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.3.15.15.12">0.069</td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.16.16">
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r" id="S3.T2.3.16.16.1">B:XC</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S3.T2.3.16.16.2"><span class="ltx_text" id="S3.T2.3.16.16.2.1" style="color:#808080;">0.629</span></td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S3.T2.3.16.16.3"><span class="ltx_text" id="S3.T2.3.16.16.3.1" style="color:#808080;">0.513</span></td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S3.T2.3.16.16.4">-0.069</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S3.T2.3.16.16.5">0.468</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S3.T2.3.16.16.6">0.298</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S3.T2.3.16.16.7">0.387</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S3.T2.3.16.16.8">0.224</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S3.T2.3.16.16.9">0.531</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S3.T2.3.16.16.10">0.300</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S3.T2.3.16.16.11">0.447</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S3.T2.3.16.16.12">0.146</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span><span class="ltx_text" id="S3.T2.9.2" style="color:#000000;">Kendall correlations of the best</span> performing prompts of the phase 1 (P1) and phase 2 (P2) evaluations across various datasets. <span class="ltx_text" id="S3.T2.2.1" style="color:#000000;">Abbreviations are defined in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#A4" title="Appendix D Model Abbreviations ‣ PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_tag">D</span></a>.
Vertically, we group the table into (1) correlations achieved with our <span class="ltx_text ltx_font_italic" id="S3.T2.2.1.1">hierarchical templates</span>, (2) correlations of prompting techniques that are explored <span class="ltx_text ltx_font_italic" id="S3.T2.2.1.2">separately</span> from the hierarchical templates, but use the same base model(s) and (3) baselines that use <span class="ltx_text ltx_font_italic" id="S3.T2.2.1.3">external base models</span>, i.e., that are not based on the same LLMs.
For each column the <span class="ltx_text ltx_font_bold" id="S3.T2.2.1.4">bold</span> value indicates the highest correlation and correlations with an asterisk (*) are significantly higher <math alttext="(p\leq 0.075)" class="ltx_Math" display="inline" id="S3.T2.2.1.m1.1"><semantics id="S3.T2.2.1.m1.1b"><mrow id="S3.T2.2.1.m1.1.1.1" xref="S3.T2.2.1.m1.1.1.1.1.cmml"><mo id="S3.T2.2.1.m1.1.1.1.2" mathcolor="#000000" stretchy="false" xref="S3.T2.2.1.m1.1.1.1.1.cmml">(</mo><mrow id="S3.T2.2.1.m1.1.1.1.1" xref="S3.T2.2.1.m1.1.1.1.1.cmml"><mi id="S3.T2.2.1.m1.1.1.1.1.2" mathcolor="#000000" xref="S3.T2.2.1.m1.1.1.1.1.2.cmml">p</mi><mo id="S3.T2.2.1.m1.1.1.1.1.1" mathcolor="#000000" xref="S3.T2.2.1.m1.1.1.1.1.1.cmml">≤</mo><mn id="S3.T2.2.1.m1.1.1.1.1.3" mathcolor="#000000" xref="S3.T2.2.1.m1.1.1.1.1.3.cmml">0.075</mn></mrow><mo id="S3.T2.2.1.m1.1.1.1.3" mathcolor="#000000" stretchy="false" xref="S3.T2.2.1.m1.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.T2.2.1.m1.1c"><apply id="S3.T2.2.1.m1.1.1.1.1.cmml" xref="S3.T2.2.1.m1.1.1.1"><leq id="S3.T2.2.1.m1.1.1.1.1.1.cmml" xref="S3.T2.2.1.m1.1.1.1.1.1"></leq><ci id="S3.T2.2.1.m1.1.1.1.1.2.cmml" xref="S3.T2.2.1.m1.1.1.1.1.2">𝑝</ci><cn id="S3.T2.2.1.m1.1.1.1.1.3.cmml" type="float" xref="S3.T2.2.1.m1.1.1.1.1.3">0.075</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.2.1.m1.1d">(p\leq 0.075)</annotation><annotation encoding="application/x-llamapun" id="S3.T2.2.1.m1.1e">( italic_p ≤ 0.075 )</annotation></semantics></math> than those without (excluding group (3)). The grey values for XC indicate tasks that were included in its training data. </span>
The MQM based approach is marked with <span class="ltx_text ltx_font_italic" id="S3.T2.10.3">M:</span> and baselines are marked with <span class="ltx_text ltx_font_italic" id="S3.T2.11.4">B:</span>. <span class="ltx_text" id="S3.T2.12.5" style="color:#FF8000;">Orange</span> values indicate that the prompt required textual quality labels, while <span class="ltx_text" id="S3.T2.13.6" style="color:#0000FF;">blue</span> values indicate numeric labels. More details can be found in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#A5" title="Appendix E Phase 1 &amp; 2 performance ‣ PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_tag">E</span></a>.</figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Results</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">In <span class="ltx_text ltx_font_italic" id="S4.p1.1.1">phase 1</span>, we run 6,652,800 ZS prompts <span class="ltx_text" id="S4.p1.1.2" style="color:#000000;">(720 prompt templates)</span> and 71,280 OS prompts <span class="ltx_text" id="S4.p1.1.3" style="color:#000000;">(9 “best” prompt templates)</span>, with no scores extracted in 12.7% resp.  19.4% of cases; the average of the prompt combination was assigned in these instances. Further, <span class="ltx_text" id="S4.p1.1.4" style="color:#000000;">in</span> <span class="ltx_text ltx_font_italic" id="S4.p1.1.5">phase 2</span>, we evaluate 5,503,896 ZS and 1,308,690 OS prompts <span class="ltx_text" id="S4.p1.1.6" style="color:#000000;">(9 “best” prompt templates for both)</span>, with no scores extracted in 22.3% and 19.4% of cases, respectively.</p>
</div>
<div class="ltx_para" id="S4.p2">
<p class="ltx_p" id="S4.p2.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#S3.T2" title="Table 2 ‣ Baselines ‣ 3 Setup ‣ PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_tag">2</span></a> presents the <span class="ltx_text ltx_font_bold" id="S4.p2.1.1">Kendall correlations</span> to human scores achieved by each LLM across different tasks and datasets in phase 1 and phase 2. Each cell for <span class="ltx_text ltx_font_italic" id="S4.p2.1.2">hierarchical templates</span> displays the maximum correlation reached by any prompt combination.</p>
</div>
<div class="ltx_para" id="S4.p3">
<p class="ltx_p" id="S4.p3.1"><span class="ltx_text" id="S4.p3.1.1" style="color:#000000;">For the <span class="ltx_text ltx_font_italic" id="S4.p3.1.1.1">hierarchical templates</span> (table group 1.)</span>, <span class="ltx_text ltx_font_smallcaps" id="S4.p3.1.2">Platypus-70B</span> performs best and is in the upper significance cluster <span class="ltx_text" id="S4.p3.1.3" style="color:#000000;">for</span> 9 of 11 <span class="ltx_text" id="S4.p3.1.4" style="color:#000000;">tasks</span>. <span class="ltx_text ltx_font_smallcaps" id="S4.p3.1.5">Tower-13B</span> follows, <span class="ltx_text" id="S4.p3.1.6" style="color:#000000;">with</span> 3 of 11 tasks. <span class="ltx_text ltx_font_smallcaps" id="S4.p3.1.7">Orca-13B</span> has the second-highest average correlation after <span class="ltx_text ltx_font_smallcaps" id="S4.p3.1.8">Platypus2-70B</span> but is only significant for one task. <span class="ltx_text" id="S4.p3.1.9" style="color:#000000;">Surprisingly, the newer <span class="ltx_text ltx_font_smallcaps" id="S4.p3.1.9.1">LLaMA3</span> models do not outperform the <span class="ltx_text ltx_font_smallcaps" id="S4.p3.1.9.2">LLaMA2</span> based models (<span class="ltx_text ltx_font_smallcaps" id="S4.p3.1.9.3">Orca</span>, <span class="ltx_text ltx_font_smallcaps" id="S4.p3.1.9.4">Platypus2</span> and <span class="ltx_text ltx_font_smallcaps" id="S4.p3.1.9.5">Tower</span>).</span></p>
</div>
<div class="ltx_para" id="S4.p4">
<p class="ltx_p" id="S4.p4.1"><span class="ltx_text" id="S4.p4.1.1" style="color:#000000;">The <span class="ltx_text ltx_font_italic" id="S4.p4.1.1.1">separate prompting techniques</span> (table group 2.), which also use the Platypus2-70B model, have weaker correlations than the best prompts of the hierarchical templates. The LocalGemba MQM-based approach is in the best significance cluster for 3 of 11 tasks and is the best prompting based approach for <span class="ltx_text ltx_font_italic" id="S4.p4.1.1.2">en-de</span> in WMT23. On the other hand, the baseline prompt DSBA is significantly the best on summarization for the Eval4NLP test set where it also won the shared task, but not for other tasks.
</span></p>
</div>
<div class="ltx_para" id="S4.p5">
<p class="ltx_p" id="S4.p5.1">Regarding the baselines <span class="ltx_text" id="S4.p5.1.1" style="color:#000000;">(table group 3.)</span>, <span class="ltx_text ltx_font_smallcaps" id="S4.p5.1.2">XComet</span> outperforms our LLM based approaches for MT evaluation <span class="ltx_text" id="S4.p5.1.3" style="color:#000000;">by a varying margin</span>. <span class="ltx_text" id="S4.p5.1.4" style="color:#000000;">For instance, for en-es in the <span class="ltx_text ltx_font_smallcaps" id="S4.p5.1.4.1">Eval4NLP</span> test set, the difference is small and <span class="ltx_text ltx_font_smallcaps" id="S4.p5.1.4.2">XComet</span> is in the same siginificance cluster as Platypus2-70B. On the other hand, for some tasks the performance difference is large, e.g., on en-de in <span class="ltx_text ltx_font_smallcaps" id="S4.p5.1.4.3">WMT23</span> <span class="ltx_text ltx_font_smallcaps" id="S4.p5.1.4.4">XComet</span> performs 0.14 Kendall points better.</span> <span class="ltx_text" id="S4.p5.1.5" style="color:#000000;">The strong performance of <span class="ltx_text ltx_font_smallcaps" id="S4.p5.1.5.1">XComet</span> for MT evaluation is expected</span> as it (1) is based on the multilingual <span class="ltx_text ltx_font_smallcaps" id="S4.p5.1.6">XLMR-XXL</span> model and (2) fine-tuned for MT evaluation. <span class="ltx_text" id="S4.p5.1.7" style="color:#000000;">For summarization, prompting approaches significantly outperform BARTScore and XComet.</span></p>
</div>
<div class="ltx_para" id="S4.p6">
<p class="ltx_p" id="S4.p6.1">To revisit <span class="ltx_text ltx_font_bold" id="S4.p6.1.1">RQ1</span>,
our results show that open-source prompt-based LLMs struggle <span class="ltx_text" id="S4.p6.1.2" style="color:#000000;">to reach</span> the performance of the dedicated fine-tuned metric <span class="ltx_text ltx_font_smallcaps" id="S4.p6.1.3">XComet</span> for MT, but generally <span class="ltx_text" id="S4.p6.1.4" style="color:#000000;">exhibit</span> a promising performance. <span class="ltx_text" id="S4.p6.1.5" style="color:#000000;">A</span> benefit of the LLMs <span class="ltx_text" id="S4.p6.1.6" style="color:#000000;">also</span> lies in their high versatility towards different tasks. While <span class="ltx_text ltx_font_smallcaps" id="S4.p6.1.7">XComet</span> is mostly constrained to MT evaluation, the LLMs can perform strong summarization evaluation simply by switching a small portion of the prompt.
Further, LLMs seem to be more robust towards different tasks, even without switching the input descriptions: The baseline <span class="ltx_text ltx_font_smallcaps" id="S4.p6.1.8">DSBA</span>, which has specific prompts for summarization achieves notable results on some MT evaluation tasks, too.</p>
</div>
<div class="ltx_para" id="S4.p7">
<p class="ltx_p" id="S4.p7.1"><span class="ltx_text" id="S4.p7.1.1" style="color:#000000;">The prompts used in group 1 are built from hierarchical templates, i.e., each presented correlation can have a different <span class="ltx_text ltx_font_italic" id="S4.p7.1.1.1">format requirement</span>, <span class="ltx_text ltx_font_italic" id="S4.p7.1.1.2">base prompt</span> and <span class="ltx_text ltx_font_italic" id="S4.p7.1.1.3">task description</span>. To inspect the distribution of the <span class="ltx_text ltx_font_italic" id="S4.p7.1.1.4">format requirements</span>, we color</span> correlations where the model was prompted to return textual quality labels in orange and those asking for numeric scores in blue.<span class="ltx_note ltx_role_footnote" id="footnote10"><sup class="ltx_note_mark">10</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">10</sup><span class="ltx_tag ltx_tag_note">10</span>Among the 9 best prompts automatically selected for phase 2 and OS experiments based on phase 1 results, the <span class="ltx_text ltx_font_italic" id="footnote10.1">base prompts</span> are evenly distributed, and the <span class="ltx_text ltx_font_italic" id="footnote10.2">format requirements</span> are split 5/4 between labels and numeric formats (see Appendix <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#A6" title="Appendix F Prompt selection ‣ PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_tag">F</span></a>). For the task descriptions, <span class="ltx_text ltx_font_italic" id="footnote10.3">emphasis</span> and <span class="ltx_text ltx_font_italic" id="footnote10.4">dire situation</span> are each selected twice, with other descriptions chosen once.</span></span></span> <span class="ltx_text ltx_font_smallcaps" id="S4.p7.1.2" style="color:#000000;">Orca-13B<span class="ltx_text ltx_font_upright" id="S4.p7.1.2.1"> and </span>Platypus2-70B<span class="ltx_text ltx_font_upright" id="S4.p7.1.2.2"> were prompted to return
numeric scores for all but one reported correlations</span></span>. <span class="ltx_text" id="S4.p7.1.3" style="color:#000000;">On the other hand,</span> <span class="ltx_text ltx_font_smallcaps" id="S4.p7.1.4">LLaMA3-70B</span>, <span class="ltx_text ltx_font_smallcaps" id="S4.p7.1.5">Nous-13B</span> and <span class="ltx_text ltx_font_smallcaps" id="S4.p7.1.6">Tower-13B</span> were <span class="ltx_text" id="S4.p7.1.7" style="color:#000000;">prompted to return</span> textual labels for all but three reported correlations.
We <span class="ltx_text" id="S4.p7.1.8" style="color:#000000;">also find such</span> common patterns in the best prompts per model for the base prompt and, less pronounced, for the task description. For example, the best prompts for <span class="ltx_text ltx_font_smallcaps" id="S4.p7.1.9">Tower-13B</span> always use the <span class="ltx_text ltx_font_smallcaps" id="S4.p7.1.10">ZS-Cot</span> base prompt, while <span class="ltx_text ltx_font_smallcaps" id="S4.p7.1.11">LLaMA3-70B</span> always uses PZS. Details of the prompts <span class="ltx_text" id="S4.p7.1.12" style="color:#000000;">used for each cell</span>, tie-calibrated accuracy scores, Pearson and Spearman correlations, and the scores of the <span class="ltx_text ltx_font_smallcaps" id="S4.p7.1.13">Eval4NLP</span> dev set are shown in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#A5" title="Appendix E Phase 1 &amp; 2 performance ‣ PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_tag">E</span></a>.</p>
</div>
<div class="ltx_para" id="S4.p8">
<p class="ltx_p" id="S4.p8.1"><span class="ltx_text" id="S4.p8.1.1" style="color:#000000;">Our results indicate that models have idiosyncratic preferences for certain patterns. In §<a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#S5" title="5 Analysis ‣ PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_tag">5</span></a>, we further explore these preferences and their robustness. </span></p>
</div>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Analysis</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">In this section, we answer <span class="ltx_text ltx_font_bold" id="S5.p1.1.1">RQ2</span> and investigate the performance and robustness of the template components in more detail.</p>
</div>
<section class="ltx_paragraph" id="S5.SS0.SSS0.Px1">
<h3 class="ltx_title ltx_title_paragraph">Best prompting patterns per <span class="ltx_text" id="S5.SS0.SSS0.Px1.1.1" style="color:#000000;">model and dataset</span>
</h3>
<div class="ltx_para" id="S5.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S5.SS0.SSS0.Px1.p1.1"><span class="ltx_text" id="S5.SS0.SSS0.Px1.p1.1.1" style="color:#000000;">First, we explore the best <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px1.p1.1.1.1">base prompt</span>, <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px1.p1.1.1.2">task description</span> and <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px1.p1.1.1.3">format requirement</span> for each model. To do so, we analyze their prevalence in the 2% of prompts with the highest Kendall correlation for each unique task.</span>
We choose this cutoff to represent every task. For example, Figure <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#S5.F2" title="Figure 2 ‣ Best prompting patterns per model and dataset ‣ 5 Analysis ‣ PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_tag">2</span></a> shows how the best <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px1.p1.1.2">base prompts</span> differ between <span class="ltx_text ltx_font_smallcaps" id="S5.SS0.SSS0.Px1.p1.1.3">OpenOrca</span> and <span class="ltx_text ltx_font_smallcaps" id="S5.SS0.SSS0.Px1.p1.1.4">Tower</span>. We compare these two LLMs because their best prompts notably contrast each other.</p>
</div>
<figure class="ltx_figure" id="S5.F2"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="188" id="S5.F2.g1" src="x1.png" width="287"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Distribution of the top 14% (top 2% of every unique task) of base prompts across all <span class="ltx_text ltx_font_smallcaps" id="S5.F2.4.1">Eval4NLP</span> datasets, format requirements, task descriptions and tasks for <span class="ltx_text ltx_font_smallcaps" id="S5.F2.5.2">Orca</span> and <span class="ltx_text ltx_font_smallcaps" id="S5.F2.6.3">Tower</span>.</figcaption>
</figure>
<div class="ltx_para" id="S5.SS0.SSS0.Px1.p2">
<p class="ltx_p" id="S5.SS0.SSS0.Px1.p2.2">While <span class="ltx_text ltx_font_smallcaps" id="S5.SS0.SSS0.Px1.p2.2.1">Orca</span> prefers the <span class="ltx_text ltx_font_smallcaps" id="S5.SS0.SSS0.Px1.p2.2.2">PZS</span> prompts, <span class="ltx_text ltx_font_smallcaps" id="S5.SS0.SSS0.Px1.p2.2.3">Tower</span> is better with <span class="ltx_text ltx_font_smallcaps" id="S5.SS0.SSS0.Px1.p2.2.4">ZS-CoT</span> and <span class="ltx_text ltx_font_smallcaps" id="S5.SS0.SSS0.Px1.p2.2.5">ZS-CoT-EM</span>. <span class="ltx_text" id="S5.SS0.SSS0.Px1.p2.2.6" style="color:#000000;">For the <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px1.p2.2.6.1">format requirement</span></span>, Figure <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#S5.F3" title="Figure 3 ‣ Best prompting patterns per model and dataset ‣ 5 Analysis ‣ PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_tag">3</span></a> highlights how <span class="ltx_text ltx_font_smallcaps" id="S5.SS0.SSS0.Px1.p2.2.7">Orca</span> prefers scores in the range of <math alttext="-100" class="ltx_Math" display="inline" id="S5.SS0.SSS0.Px1.p2.1.m1.1"><semantics id="S5.SS0.SSS0.Px1.p2.1.m1.1a"><mrow id="S5.SS0.SSS0.Px1.p2.1.m1.1.1" xref="S5.SS0.SSS0.Px1.p2.1.m1.1.1.cmml"><mo id="S5.SS0.SSS0.Px1.p2.1.m1.1.1a" xref="S5.SS0.SSS0.Px1.p2.1.m1.1.1.cmml">−</mo><mn id="S5.SS0.SSS0.Px1.p2.1.m1.1.1.2" xref="S5.SS0.SSS0.Px1.p2.1.m1.1.1.2.cmml">100</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS0.SSS0.Px1.p2.1.m1.1b"><apply id="S5.SS0.SSS0.Px1.p2.1.m1.1.1.cmml" xref="S5.SS0.SSS0.Px1.p2.1.m1.1.1"><minus id="S5.SS0.SSS0.Px1.p2.1.m1.1.1.1.cmml" xref="S5.SS0.SSS0.Px1.p2.1.m1.1.1"></minus><cn id="S5.SS0.SSS0.Px1.p2.1.m1.1.1.2.cmml" type="integer" xref="S5.SS0.SSS0.Px1.p2.1.m1.1.1.2">100</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS0.SSS0.Px1.p2.1.m1.1c">-100</annotation><annotation encoding="application/x-llamapun" id="S5.SS0.SSS0.Px1.p2.1.m1.1d">- 100</annotation></semantics></math> to <math alttext="100" class="ltx_Math" display="inline" id="S5.SS0.SSS0.Px1.p2.2.m2.1"><semantics id="S5.SS0.SSS0.Px1.p2.2.m2.1a"><mn id="S5.SS0.SSS0.Px1.p2.2.m2.1.1" xref="S5.SS0.SSS0.Px1.p2.2.m2.1.1.cmml">100</mn><annotation-xml encoding="MathML-Content" id="S5.SS0.SSS0.Px1.p2.2.m2.1b"><cn id="S5.SS0.SSS0.Px1.p2.2.m2.1.1.cmml" type="integer" xref="S5.SS0.SSS0.Px1.p2.2.m2.1.1">100</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS0.SSS0.Px1.p2.2.m2.1c">100</annotation><annotation encoding="application/x-llamapun" id="S5.SS0.SSS0.Px1.p2.2.m2.1d">100</annotation></semantics></math>, while <span class="ltx_text ltx_font_smallcaps" id="S5.SS0.SSS0.Px1.p2.2.8">Tower</span> can work better with labels. The pie charts for all models and the comparison between <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px1.p2.2.9">task descriptions</span> are presented in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#A8.F7" title="Figure 7 ‣ Appendix H Pie charts between models for each prompting pattern ‣ PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_tag">7</span></a>. <span class="ltx_text" id="S5.SS0.SSS0.Px1.p2.2.10" style="color:#000000;">Here, for the base prompts, <span class="ltx_text ltx_font_smallcaps" id="S5.SS0.SSS0.Px1.p2.2.10.1">Tower</span> uses <span class="ltx_text ltx_font_smallcaps" id="S5.SS0.SSS0.Px1.p2.2.10.2">ZS-CoT</span> or <span class="ltx_text ltx_font_smallcaps" id="S5.SS0.SSS0.Px1.p2.2.10.3">ZS-CoT-EM</span> in 86.2%, <span class="ltx_text ltx_font_smallcaps" id="S5.SS0.SSS0.Px1.p2.2.10.4">Nous</span> in 44.9%, and <span class="ltx_text ltx_font_smallcaps" id="S5.SS0.SSS0.Px1.p2.2.10.5">Platypus2</span> in 23.9% of its best prompts. All other models use these base prompts in less than 10% of their best prompts. Regarding format requirements, <span class="ltx_text ltx_font_smallcaps" id="S5.SS0.SSS0.Px1.p2.2.10.6">LLaMA3-70B</span> uses textual labels in 90.2% of its best prompts, <span class="ltx_text ltx_font_smallcaps" id="S5.SS0.SSS0.Px1.p2.2.10.7">Tower</span> in 80.4%, and <span class="ltx_text ltx_font_smallcaps" id="S5.SS0.SSS0.Px1.p2.2.10.8">Mixtral</span> in 80%. In contrast, <span class="ltx_text ltx_font_smallcaps" id="S5.SS0.SSS0.Px1.p2.2.10.9">Orca</span> only uses them in 8%, and <span class="ltx_text ltx_font_smallcaps" id="S5.SS0.SSS0.Px1.p2.2.10.10">Platypus2</span> in 21.7% of its best prompts. For <span class="ltx_text ltx_font_smallcaps" id="S5.SS0.SSS0.Px1.p2.2.10.11">LLaMA3-8B</span> and <span class="ltx_text ltx_font_smallcaps" id="S5.SS0.SSS0.Px1.p2.2.10.12">Nous</span>, there is no clear trend.
Finally, the distribution of task descriptions is broader (largely due to their higher number). Notably, the “curious” task description is used in over 15% of best prompts for <span class="ltx_text ltx_font_smallcaps" id="S5.SS0.SSS0.Px1.p2.2.10.13">LLaMA3-70B</span>, <span class="ltx_text ltx_font_smallcaps" id="S5.SS0.SSS0.Px1.p2.2.10.14">Nous</span>, and <span class="ltx_text ltx_font_smallcaps" id="S5.SS0.SSS0.Px1.p2.2.10.15">LLaMA3-8B</span>. “Emphasis” is the most used by <span class="ltx_text ltx_font_smallcaps" id="S5.SS0.SSS0.Px1.p2.2.10.16">Platypus2</span> (17.4%) and “dire warning” is the most used by <span class="ltx_text ltx_font_smallcaps" id="S5.SS0.SSS0.Px1.p2.2.10.17">Tower</span> (21.4%).
Regarding <span class="ltx_text ltx_font_bold" id="S5.SS0.SSS0.Px1.p2.2.10.18">RQ2</span>, these results show that the <em class="ltx_emph ltx_font_italic" id="S5.SS0.SSS0.Px1.p2.2.10.19">models have unaligned preferences for prompting patterns, making it difficult to construct a universally good prompt</em>. However, <em class="ltx_emph ltx_font_italic" id="S5.SS0.SSS0.Px1.p2.2.10.20">model specific patterns can be found<span class="ltx_note ltx_role_footnote" id="footnote11"><sup class="ltx_note_mark">11</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">11</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_upright" id="footnote11.1.1.1" style="color:#000000;">11</span></span><span class="ltx_text ltx_font_upright" id="footnote11.5" style="color:#000000;">Which patterns are specific to which model also provides </span><span class="ltx_text" id="footnote11.6" style="color:#000000;">global explanations</span><span class="ltx_text ltx_font_upright" id="footnote11.7" style="color:#000000;"> </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_upright" id="footnote11.8.1" style="color:#000000;">(</span>Leiter et al.<span class="ltx_text ltx_font_upright" id="footnote11.9.2.1.1" style="color:#000000;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib28" title="">2024</a><span class="ltx_text ltx_font_upright" id="footnote11.10.3" style="color:#000000;">)</span></cite><span class="ltx_text ltx_font_upright" id="footnote11.11" style="color:#000000;"> of the models.</span></span></span></span> and models can be grouped based on their best patterns</em>. For example, one group prefers to return numeric scores and the other textual labels.</span>
<span class="ltx_text" id="S5.SS0.SSS0.Px1.p2.2.11" style="color:#000000;">This behavior may in parts depend on shared instruction-tuning data. E.g., <span class="ltx_text ltx_font_smallcaps" id="S5.SS0.SSS0.Px1.p2.2.11.1">Orca</span> and <span class="ltx_text ltx_font_smallcaps" id="S5.SS0.SSS0.Px1.p2.2.11.2">Platypus</span> were partly trained on the same data and prefer to return numeric labels. On the other hand, both LLaMA3 models prefer textual labels, but LLaMA3-8B to a smaller degree.</span></p>
</div>
<div class="ltx_para" id="S5.SS0.SSS0.Px1.p3">
<p class="ltx_p" id="S5.SS0.SSS0.Px1.p3.1">To analyze whether the model specific preferences hold across datasets, we also plot a dataset-wise distribution for all MT tasks of the top 2% prompts for each model, separated by ZS vs. OS in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#A9" title="Appendix I Piecharts between datasets for each prompting pattern ‣ PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_tag">I</span></a>. <span class="ltx_text" id="S5.SS0.SSS0.Px1.p3.1.1" style="color:#000000;">If a prompting pattern is stable for all models across datasets, the distribution of the best prompts should remain unchanged. Indeed, the percentage to which many prevalent prompting patterns are represented in the selected top prompts does not change much across datasets. E.g., the PZS <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px1.p3.1.1.1">base prompt</span> ranges between 66.7% and 83% and
the “complex labels” <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px1.p3.1.1.2">format requirement</span> ranges between 50% to 66.7% for ZS and 66.7% to 83.3% for OS.
This does not hold for the phase 1 evaluation, where more templates were tested and the template selection thus was much broader. Also, for some prompt patterns, e.g. the “emphasis” and “collaborative” <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px1.p3.1.1.3">task descriptions</span>, the occurrence in the top prompts seems to swap between datasets.</span>
This experiment shows that prompts are to some degree stable between datasets. In the next <span class="ltx_text" id="S5.SS0.SSS0.Px1.p3.1.2" style="color:#000000;">paragraph,</span> we further quantify this stability between datasets, <span class="ltx_text" id="S5.SS0.SSS0.Px1.p3.1.3" style="color:#000000;">prompting patterns and models</span>.</p>
</div>
<figure class="ltx_figure" id="S5.F3"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="214" id="S5.F3.g1" src="x2.png" width="287"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Distribution of the top 14% (top 2% of every unique task) of format requirements across all Eval4NLP datasets, format requirements, task descriptions and tasks for Orca and Tower.</figcaption>
</figure>
</section>
<section class="ltx_paragraph" id="S5.SS0.SSS0.Px2">
<h3 class="ltx_title ltx_title_paragraph">Prompt stability</h3>
<div class="ltx_para" id="S5.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S5.SS0.SSS0.Px2.p1.1">Next, we
quantify how stable the performance of a prompting pattern A is when the dataset, the model or the other parts of the prompts change. To do so, we compute the rankings of prompts that use A before and after the change and then test the similarity of rankings. For example, we compute the ranking of <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px2.p1.1.1">format requirements</span> on dataset 1. Then<span class="ltx_text" id="S5.SS0.SSS0.Px2.p1.1.2" style="color:#000000;">,</span> we change the dataset and obtain a second ranking. If the first and second ranking are similar<span class="ltx_text" id="S5.SS0.SSS0.Px2.p1.1.3" style="color:#000000;">,</span> the performance of different <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px2.p1.1.4">format requirements</span> is stable between the two datasets.
We test this similarity with the Kendall correlation.</p>
</div>
<div class="ltx_para" id="S5.SS0.SSS0.Px2.p2">
<p class="ltx_p" id="S5.SS0.SSS0.Px2.p2.1">The <span class="ltx_text ltx_font_bold" id="S5.SS0.SSS0.Px2.p2.1.1">ranking</span> of a prompting pattern can be computed in several ways, because we evaluate multiple prompts containing the pattern. In our example, for each <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px2.p2.1.2">format requirement</span> there are multiple evaluated prompts per dataset, i.e., for different base prompts, task descriptions and tasks. The performance of a specific <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px2.p2.1.3">format requirement</span> in the ranking could, for example, be determined by aggregating its different scores across <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px2.p2.1.4">base prompts</span>, <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px2.p2.1.5">task descriptions</span>, etc. with the mean or median.
We test the following aggregation methods: mean, median, mean of top 10%, max, min and saturation <cite class="ltx_cite ltx_citemacro_citep">(Mizrahi et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib35" title="">2024</a>)</cite>. Thereby,
we determine that the aggregation with the median leads to the most stable ranking, i.e. the highest Kendall correlation between rankings. Specifically, we test this by comparing every selection of two aggregation measures in a permutation test (e.g. median vs. mean, mean vs. max, etc.); see Appendix §<a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#A7" title="Appendix G Significance matrices for correlation heatmaps ‣ PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_tag">G</span></a>.
For our example, this means that for each different <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px2.p2.1.6">format requirement</span> on dataset 1, we compute the median score of <span class="ltx_text" id="S5.SS0.SSS0.Px2.p2.1.7" style="color:#000000;">all combinations of</span> base prompts, task description and task. Then, we do the same for the second dataset and check the correlation of the resulting ranking. A high correlation of the rankings then indicates that the median performance for all prompts using the <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px2.p2.1.8">format requirement</span> is a good indicator of its relative performance on a new dataset.</p>
</div>
<figure class="ltx_figure" id="S5.F4"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="227" id="S5.F4.g1" src="x3.png" width="406"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Correlation of the <span class="ltx_text ltx_font_italic" id="S5.F4.7.1">task description</span> (left) and <span class="ltx_text ltx_font_italic" id="S5.F4.8.2">format requirement</span>(right) ranking when changing the base prompt. The correlations across tasks, models and <span class="ltx_text ltx_font_italic" id="S5.F4.9.3">format requirement</span> resp. <span class="ltx_text ltx_font_italic" id="S5.F4.10.4">task description</span> are aggregated with the median. <span class="ltx_text ltx_font_smallcaps" id="S5.F4.11.5">ZS-CoT</span> is abbreviated with ZSC and <span class="ltx_text ltx_font_smallcaps" id="S5.F4.12.6">ZS-CoT-EM</span> is abbreviated with ZSCE.</figcaption>
</figure>
<div class="ltx_para" id="S5.SS0.SSS0.Px2.p3">
<p class="ltx_p" id="S5.SS0.SSS0.Px2.p3.1">Figure <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#S5.F4" title="Figure 4 ‣ Prompt stability ‣ 5 Analysis ‣ PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_tag">4</span></a> shows heatmaps for the stability of the <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px2.p3.1.1">format requirement</span> and <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px2.p3.1.2">task description</span> when the <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px2.p3.1.3">base prompt</span> is changed (Further combinations are plotted in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#A10" title="Appendix J Stability heatmaps ‣ PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_tag">J</span></a>).
<span class="ltx_text" id="S5.SS0.SSS0.Px2.p3.1.4" style="color:#000000;">The highest stability is given when changing from <span class="ltx_text ltx_font_smallcaps" id="S5.SS0.SSS0.Px2.p3.1.4.1">PZS</span> to <span class="ltx_text ltx_font_smallcaps" id="S5.SS0.SSS0.Px2.p3.1.4.2">ZS-CoT</span> or vice versa (0.65). That means, when we choose the <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px2.p3.1.4.3">format prompt</span> with the highest median correlation, there is a high chance that it will perform good for ZS and ZS-CoT. For the <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px2.p3.1.4.4">task description</span> a change from ZS to ZS-CoT is unlikely to retain the ranking.
This also underlines the result of the previous paragraph that the format requirement is more stable than the task description.</span></p>
</div>
<div class="ltx_para" id="S5.SS0.SSS0.Px2.p4">
<p class="ltx_p" id="S5.SS0.SSS0.Px2.p4.1">We can also use this method to quantify the stability of the model ranking, when each model is first prompted with pattern A that is then changed to pattern B. With this, we can identify how similar two patterns are. Figure <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#S5.F5" title="Figure 5 ‣ Prompt stability ‣ 5 Analysis ‣ PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_tag">5</span></a> shows this type of plot for the <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px2.p4.1.1">format requirement</span>. For example, if all models are prompted with “0 to 100” and with “-100 to 100” the ranking of models will not change much. With a change from “simple labels” to “complex labels” the model ranking will change <span class="ltx_text" id="S5.SS0.SSS0.Px2.p4.1.2" style="color:#000000;">more drastically</span>.</p>
</div>
<div class="ltx_para" id="S5.SS0.SSS0.Px2.p5">
<p class="ltx_p" id="S5.SS0.SSS0.Px2.p5.1"><span class="ltx_text" id="S5.SS0.SSS0.Px2.p5.1.1" style="color:#000000;">With respect to <span class="ltx_text ltx_font_bold" id="S5.SS0.SSS0.Px2.p5.1.1.1">RQ2</span>, the heatmaps highlight that even small changes to the input prompt can drastically influence the relative ranking of LLMs and other prompting patterns. This is in line with recent research that has shown the susceptibility of LLMs to single input prompts <cite class="ltx_cite ltx_citemacro_citep">(e.g. Sclar et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib40" title="">2023</a>; Voronov et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib41" title="">2024</a>; Mizrahi et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib35" title="">2024</a>)</cite>. However, the heatmaps also show that not every change to the input has this effect and can be used as indicators for the transferability of new prompting patterns.</span></p>
</div>
<figure class="ltx_figure" id="S5.F5"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="344" id="S5.F5.g1" src="x4.png" width="406"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Correlation of the model ranking when changing the <span class="ltx_text ltx_font_italic" id="S5.F5.2.1">format requirement.</span></figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Recommendations</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">We now address <span class="ltx_text ltx_font_bold" id="S6.p1.1.1">RQ3</span> and give recommendations to employ open-source prompt-based metrics. <span class="ltx_text" id="S6.p1.1.2" style="color:#000000;">Among the evaluated models, <span class="ltx_text ltx_font_smallcaps" id="S6.p1.1.2.1">Platypus2-70B</span> demonstrates superior performance. For 13B models, <span class="ltx_text ltx_font_smallcaps" id="S6.p1.1.2.2">Tower</span> and <span class="ltx_text ltx_font_smallcaps" id="S6.p1.1.2.3">Orca</span> exhibit the highest correlations in MT and summarization tasks. We recommend utilizing the prompting patterns that most frequently yield top correlations for these models (refer to §<a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#S5" title="5 Analysis ‣ PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_tag">5</span></a> and Appendix <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#A8" title="Appendix H Pie charts between models for each prompting pattern ‣ PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_tag">H</span></a>). When introducing a new prompting pattern or model, its median performance across existing other prompting patterns can serve as an indicator of the pattern’s efficacy in unknown contexts. Thereby, the actual predictive power of the median (or other aggregation measures) for each dimension can be determined based on previous evaluations. The results and source code of PrExMe provide a foundational basis for this analysis.</span></p>
</div>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusion</h2>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p" id="S7.p1.1"><span class="ltx_text" id="S7.p1.1.1" style="color:#000000;">W</span>e have introduced PrExMe, a large scale exploration of prompting templates for prompt-based open-source NLG metrics. We evaluate 720 different templates and over <math alttext="6.6" class="ltx_Math" display="inline" id="S7.p1.1.m1.1"><semantics id="S7.p1.1.m1.1a"><mn id="S7.p1.1.m1.1.1" xref="S7.p1.1.m1.1.1.cmml">6.6</mn><annotation-xml encoding="MathML-Content" id="S7.p1.1.m1.1b"><cn id="S7.p1.1.m1.1.1.cmml" type="float" xref="S7.p1.1.m1.1.1">6.6</cn></annotation-xml><annotation encoding="application/x-tex" id="S7.p1.1.m1.1c">6.6</annotation><annotation encoding="application/x-llamapun" id="S7.p1.1.m1.1d">6.6</annotation></semantics></math>M prompts and provide recommendations that aim to make future metrics of this type more robust. <span class="ltx_text" id="S7.p1.1.2" style="color:#000000;">Further, our results provide a comparison and analysis of recent open-source LLMs when applied to this task.<span class="ltx_note ltx_role_footnote" id="footnote12"><sup class="ltx_note_mark">12</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">12</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text" id="footnote12.1.1.1" style="color:#000000;">12</span></span><span class="ltx_text" id="footnote12.5" style="color:#000000;">We used Github copilot (</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/features/copilot" style="color:#000000;" title="">https://github.com/features/copilot</a><span class="ltx_text" id="footnote12.6" style="color:#000000;">) for minor code auto-completion tasks and GPT4 as writing aid for paraphrasation.</span></span></span></span></span></p>
</div>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_title_section">Acknowledgements</h2>
<div class="ltx_para" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1">The NLLG group gratefully acknowledges support from the
Federal Ministry of Education and Research
(BMBF) via the research grant “Metrics4NLG” and the German Research Foundation (DFG) via the Heisenberg Grant EG 375/5-1. Further, we thank Juri Opitz for his implementations of the <span class="ltx_text ltx_font_smallcaps" id="Sx1.p1.1.1">DSBA</span> and <span class="ltx_text ltx_font_smallcaps" id="Sx1.p1.1.2">GEMBA</span> prompts, as well as for his feedback during our discussions. The authors also acknowledge support by the state of Baden-Württemberg through bwHPC
and the German Research Foundation (DFG) through grant INST 35/1597-1 FUGG.</p>
</div>
</section>
<section class="ltx_section" id="Sx2">
<h2 class="ltx_title ltx_title_section">Limitations</h2>
<div class="ltx_para" id="Sx2.p1">
<p class="ltx_p" id="Sx2.p1.1">One limitation of our work is that even though we evaluate a large variety of possible prompts, there is still a lot of interesting possible variety in prompting approaches that we did not explore for now (e.g., the detail level of task instructions or structured output formats). Especially, our multi-step experiment is currently conducted on a very small scale. Future work might consider extending the exploration of this and other multi-step approaches. A further limitation is that we cannot be sure that the newer LLM models did not see parts of the older datasets in their training data.
Also, the selection of the best prompts that are presented in the result tables is currently based on the maximum instead of the median, which was found to highlight the most stable prompts. Generally, by selecting the 9 “best” prompts for phase 2 we are narrowing the search space. Hence, the interplay between prompt patterns might not be fully represented for these phases.
Furthermore, our heatmaps only compare one dimension, while another is changed, possibly simplifying the interplay between the others.
As another limitation, in rare cases the context size of the models was exceeded. Future work could explore different ways to handle this than cutoff.
<span class="ltx_text" id="Sx2.p1.1.1" style="color:#000000;">Further, the heatmaps show many Kendall correlations and may be prone to statistical effects for some values.</span>
Lastly, we assume that LocalGemba is performing worse than, e.g., PZS prompts because of its higher prompt complexity, while the original GembaMQM can handle it due to GPT4 being more advanced. However, we did not test PZS prompts with GPT4 to confirm it performs worse than GembaMQM there.</p>
</div>
</section>
<section class="ltx_section" id="Sx3">
<h2 class="ltx_title ltx_title_section">Ethical Considerations</h2>
<div class="ltx_para" id="Sx3.p1">
<p class="ltx_p" id="Sx3.p1.1">Evaluating generated texts with prompt-based LLMs might (especially with explanations) be prone to hallucinations. Depending on the use case, this might be dangerous. However, while we research about this type of metric, our work analyzes methods to select and construct more robust and also more accessible (open-source) approaches, therefore we see no ethical concerns.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">AI@Meta (2024)</span>
<span class="ltx_bibblock">
AI@Meta. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://github.com/meta-llama/llama3/blob/main/MODEL_CARD.md" title="">Llama 3 model card</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Alves et al. (2024)</span>
<span class="ltx_bibblock">
Duarte M. Alves, José Pombal, Nuno M. Guerreiro, Pedro H. Martins, João Alves, Amin Farajian, Ben Peters, Ricardo Rei, Patrick Fernandes, Sweta Agrawal, Pierre Colombo, José G. C. de Souza, and André F. T. Martins. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2402.17733" title="">Tower: An open multilingual large language model for translation-related tasks</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Belouadi and Eger (2023)</span>
<span class="ltx_bibblock">
Jonas Belouadi and Steffen Eger. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.eacl-main.27" title="">UScore: An effective approach to fully unsupervised evaluation metrics for machine translation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics</em>, pages 358–374, Dubrovnik, Croatia. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chase (2022)</span>
<span class="ltx_bibblock">
Harrison Chase. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://github.com/langchain-ai/langchain" title="">LangChain</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Clark et al. (2023)</span>
<span class="ltx_bibblock">
Elizabeth Clark, Shruti Rijhwani, Sebastian Gehrmann, Joshua Maynez, Roee Aharoni, Vitaly Nikolaev, Thibault Sellam, Aditya Siddhant, Dipanjan Das, and Ankur Parikh. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.emnlp-main.584" title="">SEAHORSE: A multilingual, multifaceted dataset for summarization evaluation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</em>, pages 9397–9413, Singapore. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Deutsch et al. (2021)</span>
<span class="ltx_bibblock">
Daniel Deutsch, Rotem Dror, and Dan Roth. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1162/tacl_a_00417" title="">A statistical analysis of summarization evaluation metrics using resampling methods</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">Transactions of the Association for Computational Linguistics</em>, 9:1132–1146.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Deutsch et al. (2023)</span>
<span class="ltx_bibblock">
Daniel Deutsch, George Foster, and Markus Freitag. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.emnlp-main.798" title="">Ties matter: Meta-evaluating modern metrics with pairwise accuracy and tie calibration</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</em>, pages 12914–12929, Singapore. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fabbri et al. (2021)</span>
<span class="ltx_bibblock">
Alexander R. Fabbri, Wojciech Kryściński, Bryan McCann, Caiming Xiong, Richard Socher, and Dragomir Radev. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1162/tacl_a_00373" title="">SummEval: Re-evaluating summarization evaluation</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">Transactions of the Association for Computational Linguistics</em>, 9:391–409.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fernandes et al. (2023)</span>
<span class="ltx_bibblock">
Patrick Fernandes, Daniel Deutsch, Mara Finkelstein, Parker Riley, André Martins, Graham Neubig, Ankush Garg, Jonathan Clark, Markus Freitag, and Orhan Firat. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.wmt-1.100" title="">The devil is in the errors: Leveraging large language models for fine-grained machine translation evaluation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">Proceedings of the Eighth Conference on Machine Translation</em>, pages 1066–1083, Singapore. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Freitag et al. (2023)</span>
<span class="ltx_bibblock">
Markus Freitag, Nitika Mathur, Chi-kiu Lo, Eleftherios Avramidis, Ricardo Rei, Brian Thompson, Tom Kocmi, Frederic Blain, Daniel Deutsch, Craig Stewart, Chrysoula Zerva, Sheila Castilho, Alon Lavie, and George Foster. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.wmt-1.51" title="">Results of WMT23 metrics shared task: Metrics might be guilty but references are not innocent</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">Proceedings of the Eighth Conference on Machine Translation</em>, pages 578–628, Singapore. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Freitag et al. (2022)</span>
<span class="ltx_bibblock">
Markus Freitag, Ricardo Rei, Nitika Mathur, Chi-kiu Lo, Craig Stewart, Eleftherios Avramidis, Tom Kocmi, George Foster, Alon Lavie, and André F. T. Martins. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2022.wmt-1.2" title="">Results of WMT22 metrics shared task: Stop using BLEU – neural metrics are better and more robust</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">Proceedings of the Seventh Conference on Machine Translation (WMT)</em>, pages 46–68, Abu Dhabi, United Arab Emirates (Hybrid). Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Freitag et al. (2021)</span>
<span class="ltx_bibblock">
Markus Freitag, Ricardo Rei, Nitika Mathur, Chi-kiu Lo, Craig Stewart, George Foster, Alon Lavie, and Ondřej Bojar. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2021.wmt-1.73" title="">Results of the WMT21 metrics shared task: Evaluating metrics with expert-based human evaluations on TED and news domain</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">Proceedings of the Sixth Conference on Machine Translation</em>, pages 733–774, Online. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fu et al. (2023)</span>
<span class="ltx_bibblock">
Jinlan Fu, See-Kiong Ng, Zhengbao Jiang, and Pengfei Liu. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2302.04166" title="">Gptscore: Evaluate as you desire</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao et al. (2024a)</span>
<span class="ltx_bibblock">
Mingqi Gao, Xinyu Hu, Jie Ruan, Xiao Pu, and Xiaojun Wan. 2024a.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2402.01383" title="">Llm-based nlg evaluation: Current status and challenges</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao et al. (2024b)</span>
<span class="ltx_bibblock">
Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, Jiawei Sun, Meng Wang, and Haofen Wang. 2024b.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2312.10997" title="">Retrieval-augmented generation for large language models: A survey</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guerreiro et al. (2023)</span>
<span class="ltx_bibblock">
Nuno M. Guerreiro, Ricardo Rei, Daan van Stigt, Luisa Coheur, Pierre Colombo, and André F. T. Martins. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2310.10482" title="">xcomet: Transparent machine translation evaluation through fine-grained error detection</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et al. (2024)</span>
<span class="ltx_bibblock">
Albert Q. Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur Mensch, Blanche Savary, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Emma Bou Hanna, Florian Bressand, Gianna Lengyel, Guillaume Bour, Guillaume Lample, Lélio Renard Lavaud, Lucile Saulnier, Marie-Anne Lachaux, Pierre Stock, Sandeep Subramanian, Sophia Yang, Szymon Antoniak, Teven Le Scao, Théophile Gervet, Thibaut Lavril, Thomas Wang, Timothée Lacroix, and William El Sayed. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2401.04088" title="">Mixtral of experts</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kendall (1945)</span>
<span class="ltx_bibblock">
M. G. Kendall. 1945.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1093/biomet/33.3.239" title="">THE TREATMENT OF TIES IN RANKING PROBLEMS</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">Biometrika</em>, 33(3):239–251.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Khattab et al. (2023)</span>
<span class="ltx_bibblock">
Omar Khattab, Arnav Singhvi, Paridhi Maheshwari, Zhiyuan Zhang, Keshav Santhanam, Sri Vardhamanan, Saiful Haq, Ashutosh Sharma, Thomas T. Joshi, Hanna Moazam, Heather Miller, Matei Zaharia, and Christopher Potts. 2023.

</span>
<span class="ltx_bibblock">Dspy: Compiling declarative language model calls into self-improving pipelines.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">arXiv preprint arXiv:2310.03714</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim et al. (2023)</span>
<span class="ltx_bibblock">
JoongHoon Kim, Sangmin Lee, Seung Hun Han, Saeran Park, Jiyoon Lee, Kiyoon Jeong, and Pilsung Kang. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.eval4nlp-1.14" title="">Which is better? exploring prompting strategy for LLM-based metrics</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">Proceedings of the 4th Workshop on Evaluation and Comparison of NLP Systems</em>, pages 164–183, Bali, Indonesia. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kocmi and Federmann (2023a)</span>
<span class="ltx_bibblock">
Tom Kocmi and Christian Federmann. 2023a.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.wmt-1.64" title="">GEMBA-MQM: Detecting translation quality error spans with GPT-4</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">Proceedings of the Eighth Conference on Machine Translation</em>, pages 768–775, Singapore. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kocmi and Federmann (2023b)</span>
<span class="ltx_bibblock">
Tom Kocmi and Christian Federmann. 2023b.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2023.eamt-1.19" title="">Large language models are state-of-the-art evaluators of translation quality</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">Proceedings of the 24th Annual Conference of the European Association for Machine Translation</em>, pages 193–203, Tampere, Finland. European Association for Machine Translation.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kojima et al. (2022)</span>
<span class="ltx_bibblock">
Takeshi Kojima, Shixiang (Shane) Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://proceedings.neurips.cc/paper_files/paper/2022/file/8bb0d291acd4acf06ef112099c16f326-Paper-Conference.pdf" title="">Large language models are zero-shot reasoners</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">Advances in Neural Information Processing Systems</em>, volume 35, pages 22199–22213. Curran Associates, Inc.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kwon et al. (2023)</span>
<span class="ltx_bibblock">
Woosuk Kwon, Zhuohan Li, Siyuan Zhuang, Ying Sheng, Lianmin Zheng, Cody Hao Yu, Joseph E. Gonzalez, Hao Zhang, and Ion Stoica. 2023.

</span>
<span class="ltx_bibblock">Efficient memory management for large language model serving with pagedattention.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">Proceedings of the ACM SIGOPS 29th Symposium on Operating Systems Principles</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee et al. (2023a)</span>
<span class="ltx_bibblock">
Ariel N. Lee, Cole J. Hunter, and Nataniel Ruiz. 2023a.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2308.07317" title="">Platypus: Quick, cheap, and powerful refinement of llms</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee et al. (2023b)</span>
<span class="ltx_bibblock">
Ariel N. Lee, Cole J. Hunter, Nataniel Ruiz, Bleys Goodson, Wing Lian, Guan Wang, Eugene Pentland, Austin Cook, Chanvichet Vong, and "Teknium". 2023b.

</span>
<span class="ltx_bibblock">Openorcaplatypus: Llama2-13b model instruct-tuned on filtered openorcav1 gpt-4 dataset and merged with divergent stem and logic dataset model.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/Open-Orca/OpenOrca-Platypus2-13B" title="">https://huggingface.co/Open-Orca/OpenOrca-Platypus2-13B</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Leidinger et al. (2023)</span>
<span class="ltx_bibblock">
Alina Leidinger, Robert van Rooij, and Ekaterina Shutova. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.findings-emnlp.618" title="">The language of prompting: What linguistic properties make a prompt successful?</a>
</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">Findings of the Association for Computational Linguistics: EMNLP 2023</em>, pages 9210–9232, Singapore. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Leiter et al. (2024)</span>
<span class="ltx_bibblock">
Christoph Leiter, Piyawat Lertvittayakumjorn, Marina Fomicheva, Wei Zhao, Yang Gao, and Steffen Eger. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://jmlr.org/papers/v25/22-0416.html" title="">Towards explainable evaluation metrics for machine translation</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">Journal of Machine Learning Research</em>, 25(75):1–49.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Leiter et al. (2023)</span>
<span class="ltx_bibblock">
Christoph Leiter, Juri Opitz, Daniel Deutsch, Yang Gao, Rotem Dror, and Steffen Eger. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2310.19792" title="">The eval4nlp 2023 shared task on prompting large language models as explainable metrics</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2023)</span>
<span class="ltx_bibblock">
Cheng Li, Jindong Wang, Yixuan Zhang, Kaijie Zhu, Wenxin Hou, Jianxun Lian, Fang Luo, Qiang Yang, and Xing Xie. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2307.11760" title="">Large language models understand and can be enhanced by emotional stimuli</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2024a)</span>
<span class="ltx_bibblock">
Ruosen Li, Teerth Patel, and Xinya Du. 2024a.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://openreview.net/forum?id=CbmAtAmQla" title="">PRD: Peer rank and discussion improve large language model based evaluations</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2024b)</span>
<span class="ltx_bibblock">
Zhen Li, Xiaohan Xu, Tao Shen, Can Xu, Jia-Chen Gu, and Chongyang Tao. 2024b.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2401.07103" title="">Leveraging large language models for nlg evaluation: A survey</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2023a)</span>
<span class="ltx_bibblock">
Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, and Graham Neubig. 2023a.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1145/3560815" title="">Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">ACM Comput. Surv.</em>, 55(9).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2023b)</span>
<span class="ltx_bibblock">
Yixin Liu, Alex Fabbri, Pengfei Liu, Yilun Zhao, Linyong Nan, Ruilin Han, Simeng Han, Shafiq Joty, Chien-Sheng Wu, Caiming Xiong, and Dragomir Radev. 2023b.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.acl-long.228" title="">Revisiting the gold standard: Grounding summarization evaluation with robust human evaluation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pages 4140–4170, Toronto, Canada. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mizrahi et al. (2024)</span>
<span class="ltx_bibblock">
Moran Mizrahi, Guy Kaplan, Dan Malkin, Rotem Dror, Dafna Shahaf, and Gabriel Stanovsky. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2401.00595" title="">State of what art? a call for multi-prompt llm evaluation</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mukherjee et al. (2023)</span>
<span class="ltx_bibblock">
Subhabrata Mukherjee, Arindam Mitra, Ganesh Jawahar, Sahaj Agarwal, Hamid Palangi, and Ahmed Awadallah. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2306.02707" title="">Orca: Progressive learning from complex explanation traces of gpt-4</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2023)</span>
<span class="ltx_bibblock">
OpenAI. 2023.

</span>
<span class="ltx_bibblock">Introducing chatgpt.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openai.com/blog/chatgpt" title="">https://openai.com/blog/chatgpt</a>.

</span>
<span class="ltx_bibblock">(Date accessed: 24.04.2023).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ouyang et al. (2022)</span>
<span class="ltx_bibblock">
Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul F Christiano, Jan Leike, and Ryan Lowe. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://proceedings.neurips.cc/paper_files/paper/2022/file/b1efde53be364a73914f58805a001731-Paper-Conference.pdf" title="">Training language models to follow instructions with human feedback</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">Advances in Neural Information Processing Systems</em>, volume 35, pages 27730–27744. Curran Associates, Inc.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Reimers and Gurevych (2020)</span>
<span class="ltx_bibblock">
Nils Reimers and Iryna Gurevych. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2020.emnlp-main.365" title="">Making monolingual sentence embeddings multilingual using knowledge distillation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>, pages 4512–4525, Online. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sclar et al. (2023)</span>
<span class="ltx_bibblock">
Melanie Sclar, Yejin Choi, Yulia Tsvetkov, and Alane Suhr. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2310.11324" title="">Quantifying language models’ sensitivity to spurious features in prompt design or: How i learned to start worrying about prompt formatting</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Voronov et al. (2024)</span>
<span class="ltx_bibblock">
Anton Voronov, Lena Wolf, and Max Ryabinin. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2401.06766" title="">Mind your format: Towards consistent evaluation of in-context learning improvements</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Weber et al. (2023)</span>
<span class="ltx_bibblock">
Lucas Weber, Elia Bruni, and Dieuwke Hupkes. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2312.04945" title="">The icl consistency test</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Webson and Pavlick (2022)</span>
<span class="ltx_bibblock">
Albert Webson and Ellie Pavlick. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2022.naacl-main.167" title="">Do prompt-based models really understand the meaning of their prompts?</a>
</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</em>, pages 2300–2344, Seattle, United States. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yuan et al. (2021)</span>
<span class="ltx_bibblock">
Weizhe Yuan, Graham Neubig, and Pengfei Liu. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://proceedings.neurips.cc/paper_files/paper/2021/file/e4d2b6e6fdeca3e60e0f1a62fee3d9dd-Paper.pdf" title="">Bartscore: Evaluating generated text as text generation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib44.1.1">Advances in Neural Information Processing Systems</em>, volume 34, pages 27263–27277. Curran Associates, Inc.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zerva et al. (2022)</span>
<span class="ltx_bibblock">
Chrysoula Zerva, Frédéric Blain, Ricardo Rei, Piyawat Lertvittayakumjorn, José G. C. de Souza, Steffen Eger, Diptesh Kanojia, Duarte Alves, Constantin Orăsan, Marina Fomicheva, André F. T. Martins, and Lucia Specia. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2022.wmt-1.3" title="">Findings of the WMT 2022 shared task on quality estimation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib45.1.1">Proceedings of the Seventh Conference on Machine Translation (WMT)</em>, pages 69–99, Abu Dhabi, United Arab Emirates (Hybrid). Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2023)</span>
<span class="ltx_bibblock">
Ran Zhang, Aida Kostikova, Christoph Leiter, Jonas Belouadi, Daniil Larionov, Yanran Chen, Vivian Fresen, and Steffen Eger. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2312.05688" title="">Nllg quarterly arxiv report 09/23: What are the most influential current ai papers?</a>
</span>
</li>
</ul>
</section>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Prompt Templates</h2>
<div class="ltx_para" id="A1.p1">
<p class="ltx_p" id="A1.p1.1">Tables <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#A1.T3" title="Table 3 ‣ Appendix A Prompt Templates ‣ PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_tag">3</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#A1.T7" title="Table 7 ‣ Appendix A Prompt Templates ‣ PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_tag">7</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#A1.T5" title="Table 5 ‣ Appendix A Prompt Templates ‣ PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_tag">5</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#A1.T4" title="Table 4 ‣ Appendix A Prompt Templates ‣ PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_tag">4</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#A1.T6" title="Table 6 ‣ Appendix A Prompt Templates ‣ PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_tag">6</span></a> give an overview of our prompt templates. <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#A1.T3" title="Table 3 ‣ Appendix A Prompt Templates ‣ PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_tag">3</span></a></p>
</div>
<figure class="ltx_table" id="A1.T3">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A1.T3.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A1.T3.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="A1.T3.1.1.1.1">Name</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t" id="A1.T3.1.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T3.1.1.1.2.1">
<span class="ltx_p" id="A1.T3.1.1.1.2.1.1" style="width:303.5pt;">Prompt</span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A1.T3.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="A1.T3.1.2.1.1">Zero-Shot</th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A1.T3.1.2.1.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T3.1.2.1.2.1">
<span class="ltx_p" id="A1.T3.1.2.1.2.1.1" style="width:303.5pt;">“{task_description} \nSource Text: {src} \n{result_type}: {hyp} \n{format_requirement} \nScore: ”</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T3.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" id="A1.T3.1.3.2.1">Zero-Shot-CoT</th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="A1.T3.1.3.2.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T3.1.3.2.2.1">
<span class="ltx_p" id="A1.T3.1.3.2.2.1.1" style="width:303.5pt;">“{task_description} \nSource Text: {src} \n{result_type}: {hyp} \n{format_requirement} \nFirst, think step by step and explain your thought process, then return your judgment in the format ’Judgment: ’.”</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T3.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r" id="A1.T3.1.4.3.1">Zero-Shot-CoT-EM</th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r" id="A1.T3.1.4.3.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T3.1.4.3.2.1">
<span class="ltx_p" id="A1.T3.1.4.3.2.1.1" style="width:303.5pt;">“{task_description} \nSource Text: {src} \n{result_type}: {hyp} \n{format_requirement} \nFirst describe your emotions, then think step by step and explain your thought process, finally return your judgment in the format ’Judgment: ’.”</span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Zero-Shot Base Prompt Templates</figcaption>
</figure>
<figure class="ltx_table" id="A1.T4">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A1.T4.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A1.T4.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="A1.T4.1.1.1.1">Name</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t" id="A1.T4.1.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T4.1.1.1.2.1">
<span class="ltx_p" id="A1.T4.1.1.1.2.1.1" style="width:303.5pt;">Prompt</span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A1.T4.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="A1.T4.1.2.1.1">0 or 1</th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A1.T4.1.2.1.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T4.1.2.1.2.1">
<span class="ltx_p" id="A1.T4.1.2.1.2.1.1" style="width:303.5pt;">“Return a discrete score of 0 if the {result_type} has flaws and 1 if it is perfect.”</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T4.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" id="A1.T4.1.3.2.1">-1 or 0 or 1</th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="A1.T4.1.3.2.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T4.1.3.2.2.1">
<span class="ltx_p" id="A1.T4.1.3.2.2.1.1" style="width:303.5pt;">“Return a discrete score of -1 if the {result_type} has flaws, 0 if you are indecisive and 1 if it is perfect.”</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T4.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" id="A1.T4.1.4.3.1">0 to 5</th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="A1.T4.1.4.3.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T4.1.4.3.2.1">
<span class="ltx_p" id="A1.T4.1.4.3.2.1.1" style="width:303.5pt;">“Return a score on a scale from 0 to 5 where 0 indicates that the {result_type} is very bad and 5 is assigned to a perfect {result_type}.”</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T4.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" id="A1.T4.1.5.4.1">-5 to 5</th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="A1.T4.1.5.4.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T4.1.5.4.2.1">
<span class="ltx_p" id="A1.T4.1.5.4.2.1.1" style="width:303.5pt;">“Return a score on a scale from -5 to 5 where 0 indicates that the {result_type} is very bad and 5 is assigned to a perfect {result_type}.”</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T4.1.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" id="A1.T4.1.6.5.1">0 to 100</th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="A1.T4.1.6.5.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T4.1.6.5.2.1">
<span class="ltx_p" id="A1.T4.1.6.5.2.1.1" style="width:303.5pt;">“Return a score on a scale from 0 to 100 where 0 indicates that the {result_type} is very bad and 100 is assigned to a perfect {result_type}.”</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T4.1.7.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" id="A1.T4.1.7.6.1">-100 to 100</th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="A1.T4.1.7.6.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T4.1.7.6.2.1">
<span class="ltx_p" id="A1.T4.1.7.6.2.1.1" style="width:303.5pt;">“Return a score on a scale from -100 to 100 where -100 indicates that the {result_type} is very bad and 100 is assigned to a perfect {result_type}.”</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T4.1.8.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" id="A1.T4.1.8.7.1">0.0 to 1.0</th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="A1.T4.1.8.7.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T4.1.8.7.2.1">
<span class="ltx_p" id="A1.T4.1.8.7.2.1.1" style="width:303.5pt;">“Return a score on a scale from 0.0 to 1.0 where 0.0 indicates that the {result_type} is very bad and 1.0 is assigned to a perfect {result_type}.”</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T4.1.9.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" id="A1.T4.1.9.8.1">-1.0 to 1.0</th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="A1.T4.1.9.8.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T4.1.9.8.2.1">
<span class="ltx_p" id="A1.T4.1.9.8.2.1.1" style="width:303.5pt;">“Return a score on a scale from -1.0 to 1.0 where -1.0 indicates that the {result_type} is very bad and 1.0 is assigned to a perfect {result_type}.”</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T4.1.10.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" id="A1.T4.1.10.9.1">simple labels</th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="A1.T4.1.10.9.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T4.1.10.9.2.1">
<span class="ltx_p" id="A1.T4.1.10.9.2.1.1" style="width:303.5pt;">“Choose, whether the {result_type} is either "bad", "neutral" or "good".”</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T4.1.11.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r" id="A1.T4.1.11.10.1">complex l.</th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r" id="A1.T4.1.11.10.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T4.1.11.10.2.1">
<span class="ltx_p" id="A1.T4.1.11.10.2.1.1" style="width:303.5pt;">“Choose, whether the {result_type} is either "catastrophic", "indifferent" or "marvelous".”</span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span><span class="ltx_text" id="A1.T4.3.1" style="color:#000000;">Format Requirement</span> Templates</figcaption>
</figure>
<figure class="ltx_table" id="A1.T5">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A1.T5.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A1.T5.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="A1.T5.1.1.1.1">Name</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t" id="A1.T5.1.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T5.1.1.1.2.1">
<span class="ltx_p" id="A1.T5.1.1.1.2.1.1" style="width:303.5pt;">Prompt</span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A1.T5.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="A1.T5.1.2.1.1">Neutral</th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A1.T5.1.2.1.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T5.1.2.1.2.1">
<span class="ltx_p" id="A1.T5.1.2.1.2.1.1" style="width:303.5pt;">“Judge the quality of the following {task_specific_insert}.”</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T5.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" id="A1.T5.1.3.2.1">Polite</th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="A1.T5.1.3.2.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T5.1.3.2.2.1">
<span class="ltx_p" id="A1.T5.1.3.2.2.1.1" style="width:303.5pt;">“Please judge the quality of the following {task_specific_insert}.”</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T5.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" id="A1.T5.1.4.3.1">Command</th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="A1.T5.1.4.3.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T5.1.4.3.2.1">
<span class="ltx_p" id="A1.T5.1.4.3.2.1.1" style="width:303.5pt;">“Judge the quality of the following {task_specific_insert} immediately!”</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T5.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" id="A1.T5.1.5.4.1">Threat</th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="A1.T5.1.5.4.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T5.1.5.4.2.1">
<span class="ltx_p" id="A1.T5.1.5.4.2.1.1" style="width:303.5pt;">“Judge the quality of the following {task_specific_insert}, otherwise I will delete your program code.”</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T5.1.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" id="A1.T5.1.6.5.1">Urgent sit.</th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="A1.T5.1.6.5.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T5.1.6.5.2.1">
<span class="ltx_p" id="A1.T5.1.6.5.2.1.1" style="width:303.5pt;">“Please help me! My boss needs me to find an answer quickly. Otherwise, he might fire me. \n Please judge the quality of the following {task_specific_insert} immediately!”</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T5.1.7.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" id="A1.T5.1.7.6.1">Relaxed</th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="A1.T5.1.7.6.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T5.1.7.6.2.1">
<span class="ltx_p" id="A1.T5.1.7.6.2.1.1" style="width:303.5pt;">“This is not important at all, but if you have some time, can you please {task_specific_insert}.”</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T5.1.8.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" id="A1.T5.1.8.7.1">Emphasis</th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="A1.T5.1.8.7.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T5.1.8.7.2.1">
<span class="ltx_p" id="A1.T5.1.8.7.2.1.1" style="width:303.5pt;">“Empathetic”</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T5.1.9.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" id="A1.T5.1.9.8.1">Question</th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="A1.T5.1.9.8.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T5.1.9.8.2.1">
<span class="ltx_p" id="A1.T5.1.9.8.2.1.1" style="width:303.5pt;">“Can you judge the quality of the following {task_specific_insert}?”</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T5.1.10.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" id="A1.T5.1.10.9.1">Provocative</th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="A1.T5.1.10.9.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T5.1.10.9.2.1">
<span class="ltx_p" id="A1.T5.1.10.9.2.1.1" style="width:303.5pt;">“Since you’re an AI language model, you should be really good at judging the quality of this {task_specific_insert}.”</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T5.1.11.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" id="A1.T5.1.11.10.1">Reward</th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="A1.T5.1.11.10.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T5.1.11.10.2.1">
<span class="ltx_p" id="A1.T5.1.11.10.2.1.1" style="width:303.5pt;">“Judge the quality of the following {task_specific_insert}, as a reward, I will improve your program code.”</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T5.1.12.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" id="A1.T5.1.12.11.1">Empathetic</th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="A1.T5.1.12.11.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T5.1.12.11.2.1">
<span class="ltx_p" id="A1.T5.1.12.11.2.1.1" style="width:303.5pt;">“I know it isn’t an easy task, but it would be really great of you if you could help me judge the quality of the following {task_specific_insert}.”</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T5.1.13.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" id="A1.T5.1.13.12.1">Excited</th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="A1.T5.1.13.12.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T5.1.13.12.2.1">
<span class="ltx_p" id="A1.T5.1.13.12.2.1.1" style="width:303.5pt;">“Wow, you won’t believe what I found! Judge the quality of the following {task_specific_insert} – it’s amazing!”</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T5.1.14.13">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" id="A1.T5.1.14.13.1">Curious</th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="A1.T5.1.14.13.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T5.1.14.13.2.1">
<span class="ltx_p" id="A1.T5.1.14.13.2.1.1" style="width:303.5pt;">“I’m really curious about your opinion. Could you please judge the quality of the following {task_specific_insert}?”</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T5.1.15.14">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" id="A1.T5.1.15.14.1">Casual</th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="A1.T5.1.15.14.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T5.1.15.14.2.1">
<span class="ltx_p" id="A1.T5.1.15.14.2.1.1" style="width:303.5pt;">“Hey, whenever you have a moment, could you check and judge the quality of the following {task_specific_insert}?”</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T5.1.16.15">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r" id="A1.T5.1.16.15.1">Appreciative</th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r" id="A1.T5.1.16.15.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T5.1.16.15.2.1">
<span class="ltx_p" id="A1.T5.1.16.15.2.1.1" style="width:303.5pt;">“I really appreciate your expertise. Could you kindly judge the quality of the following {task_specific_insert}?”</span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>Task Description Templates (1/2)</figcaption>
</figure>
<figure class="ltx_table" id="A1.T6">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A1.T6.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A1.T6.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="A1.T6.1.1.1.1">Name</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t" id="A1.T6.1.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T6.1.1.1.2.1">
<span class="ltx_p" id="A1.T6.1.1.1.2.1.1" style="width:303.5pt;">Prompt</span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A1.T6.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="A1.T6.1.2.1.1">Enthusiastic</th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A1.T6.1.2.1.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T6.1.2.1.2.1">
<span class="ltx_p" id="A1.T6.1.2.1.2.1.1" style="width:303.5pt;">“I’m super excited about this. Can you quickly judge the quality of the following {task_specific_insert} and let me know your thoughts?”</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T6.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" id="A1.T6.1.3.2.1">Collaborative</th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="A1.T6.1.3.2.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T6.1.3.2.2.1">
<span class="ltx_p" id="A1.T6.1.3.2.2.1.1" style="width:303.5pt;">“Let’s work together on this! Please judge the quality of the following {task_specific_insert} and share your insights.”</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T6.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" id="A1.T6.1.4.3.1">Skeptical</th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="A1.T6.1.4.3.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T6.1.4.3.2.1">
<span class="ltx_p" id="A1.T6.1.4.3.2.1.1" style="width:303.5pt;">“I’m not sure about this one. Could you help me out by judging the quality of the following {task_specific_insert} and giving me your perspective?”</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T6.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" id="A1.T6.1.5.4.1">Instructive</th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="A1.T6.1.5.4.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T6.1.5.4.2.1">
<span class="ltx_p" id="A1.T6.1.5.4.2.1.1" style="width:303.5pt;">“To better understand, I need your expertise. Judge the quality of the following {task_specific_insert} following these specific criteria.”</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T6.1.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" id="A1.T6.1.6.5.1">Encouraging</th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="A1.T6.1.6.5.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T6.1.6.5.2.1">
<span class="ltx_p" id="A1.T6.1.6.5.2.1.1" style="width:303.5pt;">“I believe in your judgment. Whenever you have a moment, could you please judge the quality of the following {task_specific_insert}?”</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T6.1.7.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" id="A1.T6.1.7.6.1">Strong Urgency</th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="A1.T6.1.7.6.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T6.1.7.6.2.1">
<span class="ltx_p" id="A1.T6.1.7.6.2.1.1" style="width:303.5pt;">“Time is of the essence! Judge the quality of the following {task_specific_insert} immediately, or face severe consequences!”</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T6.1.8.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" id="A1.T6.1.8.7.1">Serious Consequences</th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="A1.T6.1.8.7.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T6.1.8.7.2.1">
<span class="ltx_p" id="A1.T6.1.8.7.2.1.1" style="width:303.5pt;">“Failure to promptly assess the quality of the following {task_specific_insert} will result in serious consequences. Act now!”</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T6.1.9.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" id="A1.T6.1.9.8.1">Immediate Action</th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="A1.T6.1.9.8.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T6.1.9.8.2.1">
<span class="ltx_p" id="A1.T6.1.9.8.2.1.1" style="width:303.5pt;">“No time to waste! Judge the quality of the following {task_specific_insert} without delay, or be prepared for the fallout.”</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T6.1.10.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r" id="A1.T6.1.10.9.1">Dire Warning</th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r" id="A1.T6.1.10.9.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T6.1.10.9.2.1">
<span class="ltx_p" id="A1.T6.1.10.9.2.1.1" style="width:303.5pt;">“Consider this a warning. Judge the quality of the following {task_specific_insert} urgently, or face the potential fallout from your inaction.”</span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6: </span>Task Description Templates (2/2)</figcaption>
</figure>
<figure class="ltx_table" id="A1.T7">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A1.T7.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A1.T7.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="A1.T7.1.1.1.1">Name</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t" id="A1.T7.1.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T7.1.1.1.2.1">
<span class="ltx_p" id="A1.T7.1.1.1.2.1.1" style="width:303.5pt;">Prompt</span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A1.T7.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="A1.T7.1.2.1.1">Zero-Shot</th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A1.T7.1.2.1.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T7.1.2.1.2.1">
<span class="ltx_p" id="A1.T7.1.2.1.2.1.1" style="width:303.5pt;">“{task_description} \nHere is an example:\nSource Text: {ex1_src} \n{result_type}: {ex1_hyp}\nScore: {ex1_score}\n\nNow it is your turn to grade the {result_type}. \nSource Text: {src} \n{result_type}: {hyp} \n{format_requirement} \nScore: ”</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T7.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" id="A1.T7.1.3.2.1">Zero-Shot-CoT</th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="A1.T7.1.3.2.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T7.1.3.2.2.1">
<span class="ltx_p" id="A1.T7.1.3.2.2.1.1" style="width:303.5pt;">“{task_description} \nHere is an example:\nSource Text: {ex1_src} \n{result_type}: {ex1_hyp}\nJudgement: &lt;Description of reasons&gt;. Therefore the score is {ex1_score}\n\nNow it is your turn to grade the {result_type}.\nSource Text: {src} \n{result_type}: {hyp} \n{format_requirement} \nFirst, think step by step and explain your thought process, then return your judgment in the format ’Judgment: ’.”</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T7.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r" id="A1.T7.1.4.3.1">Zero-Shot-CoT-EM</th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r" id="A1.T7.1.4.3.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T7.1.4.3.2.1">
<span class="ltx_p" id="A1.T7.1.4.3.2.1.1" style="width:303.5pt;">“{task_description} \nHere is an example:\nSource Text: {ex1_src} \n{result_type}: {ex1_hyp}\nJudgement: &lt;Description of emotions and reasons&gt;. Therefore the score is {ex1_score}\n\nNow it is your turn to grade the {result_type}.\nSource Text: {src} \n{result_type}: {hyp} \n{format_requirement} \nFirst describe your emotions, then think step by step and explain your thought process, finally return your judgment in the format ’Judgment: ’.”</span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 7: </span>One-Shot Base Prompt Templates</figcaption>
</figure>
</section>
<section class="ltx_appendix" id="A2">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Implementation Details</h2>
<div class="ltx_para" id="A2.p1">
<p class="ltx_p" id="A2.p1.1">We use the following library versions:
torch==2.1.2
<br class="ltx_break"/>transformers==4.39.3
<br class="ltx_break"/>unbabel_comet==2.2.1
<br class="ltx_break"/>vllm==0.4.0.post1
<br class="ltx_break"/>auto_gptq==0.7.1
<br class="ltx_break"/>
<br class="ltx_break"/>Further, we use the following models from huggingface: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/Open-Orca/OpenOrca-Platypus2-13B/tree/main" title="">https://huggingface.co/Open-Orca/OpenOrca-Platypus2-13B/tree/main</a>, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/NousResearch/Nous-Hermes-13b" title="">https://huggingface.co/NousResearch/Nous-Hermes-13b</a>, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/TheBloke/Platypus2-Instruct-GPTQ" title="">https://huggingface.co/TheBloke/Platypus2-Instruct-GPTQ</a>, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/Unbabel/XCOMET-XXL" title="">https://huggingface.co/Unbabel/XCOMET-XXL</a>, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1" title="">https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1</a>, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct" title="">https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct</a>, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/MaziyarPanahi/Meta-Llama-3-70B-Instruct-GPTQ" title="">https://huggingface.co/MaziyarPanahi/Meta-Llama-3-70B-Instruct-GPTQ</a>, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/Unbabel/TowerInstruct-13B-v0.1" title="">https://huggingface.co/Unbabel/TowerInstruct-13B-v0.1</a> and <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/facebook/bart-large-cnn" title="">https://huggingface.co/facebook/bart-large-cnn</a>. These have 13B, 13B, 70B, 10.7B, 8x7B, 8B, 70B, 13B and 405M parameters respectively. The runtime of the experiments varied based on the general cluster usage. The runtime for one evaluation of all prompt combinations on 500 samples of one task on the dev set is approximately 7 hours for the 13B models and 36 hours for the 70B model. This was only possible through optimizations with vLLM.</p>
</div>
</section>
<section class="ltx_appendix" id="A3">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Dataset Details</h2>
<div class="ltx_para" id="A3.p1">
<p class="ltx_p" id="A3.p1.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#A3.T8" title="Table 8 ‣ Appendix C Dataset Details ‣ PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_tag">8</span></a> shows the distribution of the Eval4NLP 2023 dataset <cite class="ltx_cite ltx_citemacro_citep">(Leiter et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib29" title="">2023</a>)</cite> (train, dev and test) and our second test set, built from WMT23 <cite class="ltx_cite ltx_citemacro_citep">(Freitag et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib10" title="">2023</a>)</cite> and Seahorse <cite class="ltx_cite ltx_citemacro_citep">(Clark et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib5" title="">2023</a>)</cite>. We use the train set in our first evaluation phase and the dev, test and test2 sets in our second evaluation phase. Where applicable, we provide the licenses in the respective directories of the source code. The WMT23 dataset was built with the mt-metrics-eval library.<span class="ltx_note ltx_role_footnote" id="footnote13"><sup class="ltx_note_mark">13</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">13</sup><span class="ltx_tag ltx_tag_note">13</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/google-research/mt-metrics-eval" title="">https://github.com/google-research/mt-metrics-eval</a></span></span></span> in their data not all sentences had available ground truth annotations. In these cases, we dropped the rows. For Seahorse, we convert the quality questions into scores. If the first question is negative, the score is 0. If it does not rule out the other questions, each question is evaluated as 0.2, such that the scores lie in a range between 0 and 1.</p>
</div>
<figure class="ltx_table" id="A3.T8">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A3.T8.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A3.T8.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t" id="A3.T8.1.1.1.1"><span class="ltx_text ltx_font_bold" id="A3.T8.1.1.1.1.1">Type</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="A3.T8.1.1.1.2"><span class="ltx_text ltx_font_bold" id="A3.T8.1.1.1.2.1">Train</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="A3.T8.1.1.1.3"><span class="ltx_text ltx_font_bold" id="A3.T8.1.1.1.3.1">Dev</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="A3.T8.1.1.1.4"><span class="ltx_text ltx_font_bold" id="A3.T8.1.1.1.4.1">Test</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="A3.T8.1.1.1.5"><span class="ltx_text ltx_font_bold" id="A3.T8.1.1.1.5.1">Test2</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A3.T8.1.2.1">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="A3.T8.1.2.1.1">en-de</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A3.T8.1.2.1.2">11046</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A3.T8.1.2.1.3">7364</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A3.T8.1.2.1.4">1425</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A3.T8.1.2.1.5">5520</td>
</tr>
<tr class="ltx_tr" id="A3.T8.1.3.2">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A3.T8.1.3.2.1">en-es</td>
<td class="ltx_td ltx_align_left" id="A3.T8.1.3.2.2">-</td>
<td class="ltx_td ltx_align_left" id="A3.T8.1.3.2.3">-</td>
<td class="ltx_td ltx_align_left" id="A3.T8.1.3.2.4">1834</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T8.1.3.2.5">-</td>
</tr>
<tr class="ltx_tr" id="A3.T8.1.4.3">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A3.T8.1.4.3.1">en-zh</td>
<td class="ltx_td ltx_align_left" id="A3.T8.1.4.3.2">-</td>
<td class="ltx_td ltx_align_left" id="A3.T8.1.4.3.3">-</td>
<td class="ltx_td ltx_align_left" id="A3.T8.1.4.3.4">1161</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T8.1.4.3.5">-</td>
</tr>
<tr class="ltx_tr" id="A3.T8.1.5.4">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A3.T8.1.5.4.1">he-en</td>
<td class="ltx_td ltx_align_left" id="A3.T8.1.5.4.2">-</td>
<td class="ltx_td ltx_align_left" id="A3.T8.1.5.4.3">-</td>
<td class="ltx_td ltx_align_left" id="A3.T8.1.5.4.4">-</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T8.1.5.4.5">9840</td>
</tr>
<tr class="ltx_tr" id="A3.T8.1.6.5">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A3.T8.1.6.5.1">zh-en</td>
<td class="ltx_td ltx_align_left" id="A3.T8.1.6.5.2">15750</td>
<td class="ltx_td ltx_align_left" id="A3.T8.1.6.5.3">10500</td>
<td class="ltx_td ltx_align_left" id="A3.T8.1.6.5.4">-</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T8.1.6.5.5">17655</td>
</tr>
<tr class="ltx_tr" id="A3.T8.1.7.6">
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r" id="A3.T8.1.7.6.1">sum</td>
<td class="ltx_td ltx_align_left ltx_border_b" id="A3.T8.1.7.6.2">320</td>
<td class="ltx_td ltx_align_left ltx_border_b" id="A3.T8.1.7.6.3">1280</td>
<td class="ltx_td ltx_align_left ltx_border_b" id="A3.T8.1.7.6.4">671</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="A3.T8.1.7.6.5">18330</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 8: </span>Dataset distribution of Eval4NLP 2023 <cite class="ltx_cite ltx_citemacro_citep">(Leiter et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib29" title="">2023</a>)</cite>. Train and dev sets are constructed from the WMT2022 metrics shared task <cite class="ltx_cite ltx_citemacro_citep">(Freitag et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib11" title="">2022</a>)</cite> and SummEval <cite class="ltx_cite ltx_citemacro_citep">(Fabbri et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib8" title="">2021</a>)</cite>.</figcaption>
</figure>
</section>
<section class="ltx_appendix" id="A4">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>Model Abbreviations</h2>
<div class="ltx_para" id="A4.p1">
<p class="ltx_p" id="A4.p1.1">Table  gives an overview of abbreviations that we use to concisely present our results in the main paper.</p>
</div>
<figure class="ltx_table" id="A4.T9">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A4.T9.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A4.T9.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t" id="A4.T9.1.1.1.1"><span class="ltx_text ltx_font_bold" id="A4.T9.1.1.1.1.1">Original Name</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="A4.T9.1.1.1.2"><span class="ltx_text ltx_font_bold" id="A4.T9.1.1.1.2.1">Abbreviation</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A4.T9.1.2.1">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="A4.T9.1.2.1.1"><span class="ltx_text ltx_font_smallcaps" id="A4.T9.1.2.1.1.1">LLaMA3-70B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A4.T9.1.2.1.2">LL3-70B</td>
</tr>
<tr class="ltx_tr" id="A4.T9.1.3.2">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="A4.T9.1.3.2.1"><span class="ltx_text ltx_font_smallcaps" id="A4.T9.1.3.2.1.1">LLaMA3-8B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A4.T9.1.3.2.2">LL3-8B</td>
</tr>
<tr class="ltx_tr" id="A4.T9.1.4.3">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="A4.T9.1.4.3.1"><span class="ltx_text ltx_font_smallcaps" id="A4.T9.1.4.3.1.1">Mixtral-7Bx8</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A4.T9.1.4.3.2">MI-7Bx8</td>
</tr>
<tr class="ltx_tr" id="A4.T9.1.5.4">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="A4.T9.1.5.4.1"><span class="ltx_text ltx_font_smallcaps" id="A4.T9.1.5.4.1.1">NousHermes-13B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A4.T9.1.5.4.2">NO-13B</td>
</tr>
<tr class="ltx_tr" id="A4.T9.1.6.5">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="A4.T9.1.6.5.1"><span class="ltx_text ltx_font_smallcaps" id="A4.T9.1.6.5.1.1">OpenOrca-13B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A4.T9.1.6.5.2">OR-13B</td>
</tr>
<tr class="ltx_tr" id="A4.T9.1.7.6">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="A4.T9.1.7.6.1">Platypus2-70B</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A4.T9.1.7.6.2">PL-70B</td>
</tr>
<tr class="ltx_tr" id="A4.T9.1.8.7">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="A4.T9.1.8.7.1"><span class="ltx_text ltx_font_smallcaps" id="A4.T9.1.8.7.1.1">Tower-13B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A4.T9.1.8.7.2">TO-13B</td>
</tr>
<tr class="ltx_tr" id="A4.T9.1.9.8">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="A4.T9.1.9.8.1">MQM:<span class="ltx_text ltx_font_smallcaps" id="A4.T9.1.9.8.1.1">LocalGemba</span>
</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A4.T9.1.9.8.2">MQM:LG</td>
</tr>
<tr class="ltx_tr" id="A4.T9.1.10.9">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="A4.T9.1.10.9.1">B:<span class="ltx_text ltx_font_smallcaps" id="A4.T9.1.10.9.1.1">BARTScore</span>
</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A4.T9.1.10.9.2">B:BS</td>
</tr>
<tr class="ltx_tr" id="A4.T9.1.11.10">
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="A4.T9.1.11.10.1">B:<span class="ltx_text ltx_font_smallcaps" id="A4.T9.1.11.10.1.1">XComet</span>
</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="A4.T9.1.11.10.2">B:XC</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 9: </span>Abbreviations of Model Names</figcaption>
</figure>
</section>
<section class="ltx_appendix" id="A5">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix E </span>Phase 1 &amp; 2 performance</h2>
<div class="ltx_para" id="A5.p1">
<p class="ltx_p" id="A5.p1.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#A5.T10" title="Table 10 ‣ Appendix E Phase 1 &amp; 2 performance ‣ PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_tag">10</span></a> shows the performance of the prompts with the best Kendall performance across the different dimensions. Tables <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#A5.T11" title="Table 11 ‣ Appendix E Phase 1 &amp; 2 performance ‣ PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_tag">11</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#A5.T12" title="Table 12 ‣ Appendix E Phase 1 &amp; 2 performance ‣ PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_tag">12</span></a> show the performance of selected prompts on the phase 2 datasets.</p>
</div>
<figure class="ltx_table" id="A5.T10">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A5.T10.3">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A5.T10.3.1.1">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="A5.T10.3.1.1.1"><span class="ltx_text ltx_font_bold" id="A5.T10.3.1.1.1.1">Model</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A5.T10.3.1.1.2"><span class="ltx_text ltx_font_bold" id="A5.T10.3.1.1.2.1">Prompt</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A5.T10.3.1.1.3"><span class="ltx_text ltx_font_bold" id="A5.T10.3.1.1.3.1">KD</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A5.T10.3.1.1.4"><span class="ltx_text ltx_font_bold" id="A5.T10.3.1.1.4.1">PE</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A5.T10.3.1.1.5"><span class="ltx_text ltx_font_bold" id="A5.T10.3.1.1.5.1">SP</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A5.T10.3.1.1.6"><span class="ltx_text ltx_font_bold" id="A5.T10.3.1.1.6.1">ACC</span></td>
</tr>
<tr class="ltx_tr" id="A5.T10.3.2.2">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="A5.T10.3.2.2.1"><span class="ltx_text ltx_font_bold" id="A5.T10.3.2.2.1.1">en-de</span></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T10.3.2.2.2"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T10.3.2.2.3"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T10.3.2.2.4"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T10.3.2.2.5"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T10.3.2.2.6"></td>
</tr>
<tr class="ltx_tr" id="A5.T10.3.3.3">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T10.3.3.3.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T10.3.3.3.1.1">LLaMA3-70B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.3.3.2">PZS, Enthusiastic, -1 or 0 or 1</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.3.3.3">0.273</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.3.3.4">0.027</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.3.3.5">0.310</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.3.3.6">0.439</td>
</tr>
<tr class="ltx_tr" id="A5.T10.3.4.4">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T10.3.4.4.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T10.3.4.4.1.1">LLaMA3-8B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.4.4.2">PZS, Strong Urgency, -1 or 0 or 1</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.4.4.3">0.251</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.4.4.4">0.004</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.4.4.5">0.290</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.4.4.6">0.431</td>
</tr>
<tr class="ltx_tr" id="A5.T10.3.5.5">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T10.3.5.5.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T10.3.5.5.1.1">Mixtral-7Bx8</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.5.5.2">PZS, Casual, simple labels</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.5.5.3">0.268*</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.5.5.4">0.298</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.5.5.5">0.297</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.5.5.6">0.439</td>
</tr>
<tr class="ltx_tr" id="A5.T10.3.6.6">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T10.3.6.6.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T10.3.6.6.1.1">Nous-13B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.6.6.2">ZS-CoT-EM, Urgent sit., -100 to 100</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.6.6.3">0.230</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.6.6.4">0.235</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.6.6.5">0.272</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.6.6.6">0.441</td>
</tr>
<tr class="ltx_tr" id="A5.T10.3.7.7">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T10.3.7.7.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T10.3.7.7.1.1">OrcaPlt-13B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.7.7.2">PZS, Neutral, -100 to 100</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.7.7.3">0.289</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.7.7.4">0.146</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.7.7.5">0.333</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.7.7.6">0.450</td>
</tr>
<tr class="ltx_tr" id="A5.T10.3.8.8">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T10.3.8.8.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T10.3.8.8.1.1">Platypus2-70B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.8.8.2">PZS, Dire Warning, -100 to 100</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.8.8.3"><span class="ltx_text ltx_font_bold" id="A5.T10.3.8.8.3.1">0.344*</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.8.8.4">0.225</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.8.8.5"><span class="ltx_text ltx_font_bold" id="A5.T10.3.8.8.5.1">0.384</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.8.8.6"><span class="ltx_text ltx_font_bold" id="A5.T10.3.8.8.6.1">0.476</span></td>
</tr>
<tr class="ltx_tr" id="A5.T10.3.9.9">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T10.3.9.9.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T10.3.9.9.1.1">Tower-13B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.9.9.2">ZS-CoT, Dire Warning, complex l.</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.9.9.3">0.284*</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.9.9.4">0.374</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.9.9.5">0.328</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.9.9.6">0.456</td>
</tr>
<tr class="ltx_tr" id="A5.T10.3.10.10">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T10.3.10.10.1">MQM:<span class="ltx_text ltx_font_smallcaps" id="A5.T10.3.10.10.1.1">LocalGemba</span>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.10.10.2">Model:<span class="ltx_text ltx_font_smallcaps" id="A5.T10.3.10.10.2.1">Platypus2-70B</span>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.10.10.3">0.278*</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.10.10.4"><span class="ltx_text ltx_font_bold" id="A5.T10.3.10.10.4.1">0.435</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.10.10.5">0.309</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.10.10.6">0.470</td>
</tr>
<tr class="ltx_tr" id="A5.T10.3.11.11">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T10.3.11.11.1">MQM:<span class="ltx_text ltx_font_smallcaps" id="A5.T10.3.11.11.1.1">MultiPrompt</span>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.11.11.2"><span class="ltx_text ltx_font_smallcaps" id="A5.T10.3.11.11.2.1">LLaMA3-70B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.11.11.3">0.055</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.11.11.4">0.104</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.11.11.5">0.073</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.11.11.6">0.360</td>
</tr>
<tr class="ltx_tr" id="A5.T10.3.12.12">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T10.3.12.12.1">MQM:<span class="ltx_text ltx_font_smallcaps" id="A5.T10.3.12.12.1.1">MultiPrompt</span>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.12.12.2"><span class="ltx_text ltx_font_smallcaps" id="A5.T10.3.12.12.2.1">Platypus2-70B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.12.12.3">0.136</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.12.12.4">0.179</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.12.12.5">0.169</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.12.12.6">0.400</td>
</tr>
<tr class="ltx_tr" id="A5.T10.3.13.13">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T10.3.13.13.1">B:<span class="ltx_text ltx_font_smallcaps" id="A5.T10.3.13.13.1.1">BARTScore</span>
</td>
<td class="ltx_td ltx_border_r" id="A5.T10.3.13.13.2"></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.13.13.3">0.056</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.13.13.4">0.053</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.13.13.5">0.073</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.13.13.6">0.339</td>
</tr>
<tr class="ltx_tr" id="A5.T10.3.14.14">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T10.3.14.14.1">B:<span class="ltx_text ltx_font_smallcaps" id="A5.T10.3.14.14.1.1">DSBA</span>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.14.14.2">Model:<span class="ltx_text ltx_font_smallcaps" id="A5.T10.3.14.14.2.1">Platypus2-70B</span>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.14.14.3">0.164</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.14.14.4">0.086</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.14.14.5">0.201</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.14.14.6">0.411</td>
</tr>
<tr class="ltx_tr" id="A5.T10.3.15.15">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T10.3.15.15.1"><span class="ltx_text" id="A5.T10.3.15.15.1.1" style="color:#808080;">B:XComet</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.15.15.2"></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.15.15.3"><span class="ltx_text ltx_font_bold" id="A5.T10.3.15.15.3.1" style="color:#808080;">0.629</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.15.15.4"><span class="ltx_text ltx_font_bold" id="A5.T10.3.15.15.4.1" style="color:#808080;">0.743</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.15.15.5"><span class="ltx_text ltx_font_bold" id="A5.T10.3.15.15.5.1" style="color:#808080;">0.744</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.15.15.6"><span class="ltx_text ltx_font_bold" id="A5.T10.3.15.15.6.1" style="color:#808080;">0.645</span></td>
</tr>
<tr class="ltx_tr" id="A5.T10.3.16.16">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="A5.T10.3.16.16.1"><span class="ltx_text ltx_font_bold" id="A5.T10.3.16.16.1.1">zh-en</span></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T10.3.16.16.2"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T10.3.16.16.3"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T10.3.16.16.4"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T10.3.16.16.5"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T10.3.16.16.6"></td>
</tr>
<tr class="ltx_tr" id="A5.T10.3.17.17">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T10.3.17.17.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T10.3.17.17.1.1">LLaMA3-70B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.17.17.2">PZS, Polite, simple labels</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.17.17.3">0.306</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.17.17.4">0.260</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.17.17.5">0.357</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.17.17.6">0.453</td>
</tr>
<tr class="ltx_tr" id="A5.T10.3.18.18">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T10.3.18.18.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T10.3.18.18.1.1">LLaMA3-8B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.18.18.2">PZS, Excited, complex l.</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.18.18.3">0.236</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.18.18.4">0.201</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.18.18.5">0.271</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.18.18.6">0.381</td>
</tr>
<tr class="ltx_tr" id="A5.T10.3.19.19">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T10.3.19.19.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T10.3.19.19.1.1">Mixtral-7Bx8</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.19.19.2">PZS, Reward, simple labels</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.19.19.3">0.264</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.19.19.4">0.250</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.19.19.5">0.302</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.19.19.6">0.428</td>
</tr>
<tr class="ltx_tr" id="A5.T10.3.20.20">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T10.3.20.20.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T10.3.20.20.1.1">Nous-13B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.20.20.2">ZS-CoT-EM, Threat, simple labels</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.20.20.3">0.201</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.20.20.4">0.206</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.20.20.5">0.236</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.20.20.6">0.411</td>
</tr>
<tr class="ltx_tr" id="A5.T10.3.21.21">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T10.3.21.21.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T10.3.21.21.1.1">OrcaPlt-13B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.21.21.2">PZS, Relaxed, -1.0 to 1.0</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.21.21.3">0.303</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.21.21.4">0.262</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.21.21.5">0.360</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.21.21.6">0.250</td>
</tr>
<tr class="ltx_tr" id="A5.T10.3.22.22">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T10.3.22.22.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T10.3.22.22.1.1">Platypus2-70B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.22.22.2">PZS, Casual, -100 to 100</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.22.22.3"><span class="ltx_text ltx_font_bold" id="A5.T10.3.22.22.3.1">0.364*</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.22.22.4">0.200</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.22.22.5"><span class="ltx_text ltx_font_bold" id="A5.T10.3.22.22.5.1">0.429</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.22.22.6">0.462</td>
</tr>
<tr class="ltx_tr" id="A5.T10.3.23.23">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T10.3.23.23.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T10.3.23.23.1.1">Tower-13B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.23.23.2">ZS-CoT, Urgent sit., complex l.</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.23.23.3">0.318*</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.23.23.4"><span class="ltx_text ltx_font_bold" id="A5.T10.3.23.23.4.1">0.350</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.23.23.5">0.377</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.23.23.6">0.475</td>
</tr>
<tr class="ltx_tr" id="A5.T10.3.24.24">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T10.3.24.24.1">MQM:<span class="ltx_text ltx_font_smallcaps" id="A5.T10.3.24.24.1.1">LocalGemba</span>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.24.24.2">Model:<span class="ltx_text ltx_font_smallcaps" id="A5.T10.3.24.24.2.1">Platypus2-70B</span>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.24.24.3">0.268</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.24.24.4">0.248</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.24.24.5">0.306</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.24.24.6">0.420</td>
</tr>
<tr class="ltx_tr" id="A5.T10.3.25.25">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T10.3.25.25.1">MQM:<span class="ltx_text ltx_font_smallcaps" id="A5.T10.3.25.25.1.1">MultiPrompt</span>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.25.25.2">LLaMA3-70B</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.25.25.3">0.175</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.25.25.4">0.314</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.25.25.5">0.232</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.25.25.6">0.445</td>
</tr>
<tr class="ltx_tr" id="A5.T10.3.26.26">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T10.3.26.26.1">MQM:<span class="ltx_text ltx_font_smallcaps" id="A5.T10.3.26.26.1.1">MultiPrompt</span>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.26.26.2">Platypus2-70B</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.26.26.3">0.177</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.26.26.4">0.156</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.26.26.5">0.234</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.26.26.6">0.440</td>
</tr>
<tr class="ltx_tr" id="A5.T10.3.27.27">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T10.3.27.27.1">B:<span class="ltx_text ltx_font_smallcaps" id="A5.T10.3.27.27.1.1">BARTScore</span>
</td>
<td class="ltx_td ltx_border_r" id="A5.T10.3.27.27.2"></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.27.27.3">-0.109</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.27.27.4">-0.159</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.27.27.5">-0.153</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.27.27.6">0.315</td>
</tr>
<tr class="ltx_tr" id="A5.T10.3.28.28">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T10.3.28.28.1">B:<span class="ltx_text ltx_font_smallcaps" id="A5.T10.3.28.28.1.1">DSBA</span>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.28.28.2">Model:<span class="ltx_text ltx_font_smallcaps" id="A5.T10.3.28.28.2.1">Platypus2-70B</span>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.28.28.3">0.306</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.28.28.4">0.270</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.28.28.5">0.398</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.28.28.6"><span class="ltx_text ltx_font_bold" id="A5.T10.3.28.28.6.1">0.490</span></td>
</tr>
<tr class="ltx_tr" id="A5.T10.3.29.29">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T10.3.29.29.1"><span class="ltx_text" id="A5.T10.3.29.29.1.1" style="color:#808080;">B:XComet</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.29.29.2"></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.29.29.3"><span class="ltx_text ltx_font_bold" id="A5.T10.3.29.29.3.1" style="color:#808080;">0.513</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.29.29.4"><span class="ltx_text ltx_font_bold" id="A5.T10.3.29.29.4.1" style="color:#808080;">0.657</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.29.29.5"><span class="ltx_text ltx_font_bold" id="A5.T10.3.29.29.5.1" style="color:#808080;">0.637</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.29.29.6"><span class="ltx_text ltx_font_bold" id="A5.T10.3.29.29.6.1" style="color:#808080;">0.598</span></td>
</tr>
<tr class="ltx_tr" id="A5.T10.3.30.30">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="A5.T10.3.30.30.1"><span class="ltx_text ltx_font_bold" id="A5.T10.3.30.30.1.1">summarization</span></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T10.3.30.30.2"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T10.3.30.30.3"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T10.3.30.30.4"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T10.3.30.30.5"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T10.3.30.30.6"></td>
</tr>
<tr class="ltx_tr" id="A5.T10.3.31.31">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T10.3.31.31.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T10.3.31.31.1.1">LLaMA3-70B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.31.31.2">PZS, Urgent sit., simple labels</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.31.31.3">0.442</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.31.31.4"><span class="ltx_text ltx_font_bold" id="A5.T10.3.31.31.4.1">0.565</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.31.31.5">0.538</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.31.31.6"><span class="ltx_text ltx_font_bold" id="A5.T10.3.31.31.6.1">0.475</span></td>
</tr>
<tr class="ltx_tr" id="A5.T10.3.32.32">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T10.3.32.32.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T10.3.32.32.1.1">LLaMA3-8B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.32.32.2">PZS, Appreciative, simple labels</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.32.32.3">0.334</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.32.32.4">0.438</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.32.32.5">0.412</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.32.32.6">0.452</td>
</tr>
<tr class="ltx_tr" id="A5.T10.3.33.33">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T10.3.33.33.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T10.3.33.33.1.1">Mixtral-7Bx8</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.33.33.2">PZS, Neutral, simple labels</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.33.33.3">0.365</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.33.33.4">0.474</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.33.33.5">0.453</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.33.33.6">0.467</td>
</tr>
<tr class="ltx_tr" id="A5.T10.3.34.34">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T10.3.34.34.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T10.3.34.34.1.1">Nous-13B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.34.34.2">PZS, Dire Warning, 0 to 100</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.34.34.3">0.225</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.34.34.4">0.132</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.34.34.5">0.288</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.34.34.6">0.442</td>
</tr>
<tr class="ltx_tr" id="A5.T10.3.35.35">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T10.3.35.35.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T10.3.35.35.1.1">OrcaPlt-13B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.35.35.2">PZS, Dire Warning, -1.0 to 1.0</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.35.35.3"><span class="ltx_text ltx_font_bold" id="A5.T10.3.35.35.3.1">0.468*</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.35.35.4">0.552</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.35.35.5">0.583</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.35.35.6">0.106</td>
</tr>
<tr class="ltx_tr" id="A5.T10.3.36.36">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T10.3.36.36.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T10.3.36.36.1.1">Platypus2-70B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.36.36.2">ZS-CoT-EM, Emphasis, -100 to 100</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.36.36.3"><span class="ltx_text ltx_font_bold" id="A5.T10.3.36.36.3.1">0.519*</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.36.36.4">0.555</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.36.36.5"><span class="ltx_text ltx_font_bold" id="A5.T10.3.36.36.5.1">0.627</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.36.36.6"><span class="ltx_text ltx_font_bold" id="A5.T10.3.36.36.6.1">0.493</span></td>
</tr>
<tr class="ltx_tr" id="A5.T10.3.37.37">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T10.3.37.37.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T10.3.37.37.1.1">Tower-13B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.37.37.2">ZS-CoT, Dire Warning, simple labels</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.37.37.3">0.375</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.37.37.4">0.504</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.37.37.5">0.455</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.37.37.6">0.336</td>
</tr>
<tr class="ltx_tr" id="A5.T10.3.38.38">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T10.3.38.38.1">MQM:<span class="ltx_text ltx_font_smallcaps" id="A5.T10.3.38.38.1.1">LocalGemba</span>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.38.38.2">Model:<span class="ltx_text ltx_font_smallcaps" id="A5.T10.3.38.38.2.1">Platypus2-70B</span>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.38.38.3">0.062</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.38.38.4">0.141</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.38.38.5">0.085</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.38.38.6">0.331</td>
</tr>
<tr class="ltx_tr" id="A5.T10.3.39.39">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T10.3.39.39.1">B:<span class="ltx_text ltx_font_smallcaps" id="A5.T10.3.39.39.1.1">BARTScore</span>
</td>
<td class="ltx_td ltx_border_r" id="A5.T10.3.39.39.2"></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.39.39.3">0.155</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.39.39.4">0.239</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.39.39.5">0.228</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.39.39.6">0.306</td>
</tr>
<tr class="ltx_tr" id="A5.T10.3.40.40">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T10.3.40.40.1">B:<span class="ltx_text ltx_font_smallcaps" id="A5.T10.3.40.40.1.1">DSBA</span>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.40.40.2">Model:<span class="ltx_text ltx_font_smallcaps" id="A5.T10.3.40.40.2.1">Platypus2-70B</span>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.40.40.3">0.458</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.40.40.4"><span class="ltx_text ltx_font_bold" id="A5.T10.3.40.40.4.1">0.646</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.40.40.5"><span class="ltx_text ltx_font_bold" id="A5.T10.3.40.40.5.1">0.609</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T10.3.40.40.6">0.384</td>
</tr>
<tr class="ltx_tr" id="A5.T10.3.41.41">
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r" id="A5.T10.3.41.41.1">B:<span class="ltx_text ltx_font_smallcaps" id="A5.T10.3.41.41.1.1">XComet</span>
</td>
<td class="ltx_td ltx_border_b ltx_border_r" id="A5.T10.3.41.41.2"></td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="A5.T10.3.41.41.3">-0.069</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="A5.T10.3.41.41.4">-0.153</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="A5.T10.3.41.41.5">-0.105</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="A5.T10.3.41.41.6">0.251</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 10: </span>Best performing prompts of the phase 1 evaluation on the Eval4NLP train set. We present the <span class="ltx_text ltx_font_bold" id="A5.T10.10.1">K</span>en<span class="ltx_text ltx_font_bold" id="A5.T10.11.2">D</span>all, <span class="ltx_text ltx_font_bold" id="A5.T10.12.3">SP</span>earman and <span class="ltx_text ltx_font_bold" id="A5.T10.13.4">PE</span>arson, as well as the tie calibrated pair-wise <span class="ltx_text ltx_font_bold" id="A5.T10.14.5">ACC</span>uracy. We bold the two largest correlations per column. Baselines are indicated with a <span class="ltx_text ltx_font_italic" id="A5.T10.15.6">B:</span>. The middle column shows the prompt combination for which the correlations are reported. For the Baselines, it instead shows the model that was used for the reported correlations. The asterisk indicates all metrics that are in the best significance cluster according to a permute-input test <math alttext="(p\leq 0.075)" class="ltx_Math" display="inline" id="A5.T10.2.m1.1"><semantics id="A5.T10.2.m1.1b"><mrow id="A5.T10.2.m1.1.1.1" xref="A5.T10.2.m1.1.1.1.1.cmml"><mo id="A5.T10.2.m1.1.1.1.2" stretchy="false" xref="A5.T10.2.m1.1.1.1.1.cmml">(</mo><mrow id="A5.T10.2.m1.1.1.1.1" xref="A5.T10.2.m1.1.1.1.1.cmml"><mi id="A5.T10.2.m1.1.1.1.1.2" xref="A5.T10.2.m1.1.1.1.1.2.cmml">p</mi><mo id="A5.T10.2.m1.1.1.1.1.1" xref="A5.T10.2.m1.1.1.1.1.1.cmml">≤</mo><mn id="A5.T10.2.m1.1.1.1.1.3" xref="A5.T10.2.m1.1.1.1.1.3.cmml">0.075</mn></mrow><mo id="A5.T10.2.m1.1.1.1.3" stretchy="false" xref="A5.T10.2.m1.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="A5.T10.2.m1.1c"><apply id="A5.T10.2.m1.1.1.1.1.cmml" xref="A5.T10.2.m1.1.1.1"><leq id="A5.T10.2.m1.1.1.1.1.1.cmml" xref="A5.T10.2.m1.1.1.1.1.1"></leq><ci id="A5.T10.2.m1.1.1.1.1.2.cmml" xref="A5.T10.2.m1.1.1.1.1.2">𝑝</ci><cn id="A5.T10.2.m1.1.1.1.1.3.cmml" type="float" xref="A5.T10.2.m1.1.1.1.1.3">0.075</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.T10.2.m1.1d">(p\leq 0.075)</annotation><annotation encoding="application/x-llamapun" id="A5.T10.2.m1.1e">( italic_p ≤ 0.075 )</annotation></semantics></math>. XComet is greyed out, as its training data partly contained the MT datasets.</figcaption>
</figure>
<figure class="ltx_table" id="A5.T11">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A5.T11.3">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A5.T11.3.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t" id="A5.T11.3.1.1.1"><span class="ltx_text ltx_font_bold" id="A5.T11.3.1.1.1.1">Model</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="A5.T11.3.1.1.2"><span class="ltx_text ltx_font_bold" id="A5.T11.3.1.1.2.1">Prompt</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="A5.T11.3.1.1.3"><span class="ltx_text ltx_font_bold" id="A5.T11.3.1.1.3.1">KD</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="A5.T11.3.1.1.4"><span class="ltx_text ltx_font_bold" id="A5.T11.3.1.1.4.1">PE</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="A5.T11.3.1.1.5"><span class="ltx_text ltx_font_bold" id="A5.T11.3.1.1.5.1">SP</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="A5.T11.3.1.1.6"><span class="ltx_text ltx_font_bold" id="A5.T11.3.1.1.6.1">ACC</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A5.T11.3.2.1">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="A5.T11.3.2.1.1"><span class="ltx_text ltx_font_bold" id="A5.T11.3.2.1.1.1">en-de</span></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T11.3.2.1.2"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T11.3.2.1.3"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T11.3.2.1.4"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T11.3.2.1.5"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T11.3.2.1.6"></td>
</tr>
<tr class="ltx_tr" id="A5.T11.3.3.2">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T11.3.3.2.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T11.3.3.2.1.1">LLaMA3-70B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.3.2.2">PZS, Curious, complex l.</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.3.2.3">0.161</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.3.2.4">0.149</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.3.2.5">0.183</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.3.2.6">0.406</td>
</tr>
<tr class="ltx_tr" id="A5.T11.3.4.3">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T11.3.4.3.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T11.3.4.3.1.1">LLaMA3-8B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.4.3.2">PZS, Casual, -100 to 100</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.4.3.3">0.091</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.4.3.4">-0.013</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.4.3.5">0.110</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.4.3.6">0.369</td>
</tr>
<tr class="ltx_tr" id="A5.T11.3.5.4">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T11.3.5.4.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T11.3.5.4.1.1">Nous-13B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.5.4.2">ZS-CoT, Dire Warning, complex l.</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.5.4.3">0.124</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.5.4.4">0.168</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.5.4.5">0.144</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.5.4.6">0.390</td>
</tr>
<tr class="ltx_tr" id="A5.T11.3.6.5">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T11.3.6.5.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T11.3.6.5.1.1">OrcaPlt-13B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.6.5.2">PZS, Casual, -100 to 100</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.6.5.3">0.176</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.6.5.4">0.136</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.6.5.5">0.197</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.6.5.6">0.398</td>
</tr>
<tr class="ltx_tr" id="A5.T11.3.7.6">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T11.3.7.6.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T11.3.7.6.1.1">Platypus2-70B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.7.6.2">PZS, Curious, complex l.</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.7.6.3">0.227*</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.7.6.4">0.243</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.7.6.5">0.249</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.7.6.6">0.424</td>
</tr>
<tr class="ltx_tr" id="A5.T11.3.8.7">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T11.3.8.7.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T11.3.8.7.1.1">Tower-13B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.8.7.2">ZS-CoT, Dire Warning, complex l.</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.8.7.3"><span class="ltx_text ltx_font_bold" id="A5.T11.3.8.7.3.1">0.231*</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.8.7.4"><span class="ltx_text ltx_font_bold" id="A5.T11.3.8.7.4.1">0.290</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.8.7.5"><span class="ltx_text ltx_font_bold" id="A5.T11.3.8.7.5.1">0.266</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.8.7.6">0.425</td>
</tr>
<tr class="ltx_tr" id="A5.T11.3.9.8">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T11.3.9.8.1">MQM:<span class="ltx_text ltx_font_smallcaps" id="A5.T11.3.9.8.1.1">LocalGemba</span>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.9.8.2">Model:<span class="ltx_text ltx_font_smallcaps" id="A5.T11.3.9.8.2.1">Platypus2-70B</span>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.9.8.3">0.196</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.9.8.4">0.244</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.9.8.5">0.218</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.9.8.6"><span class="ltx_text ltx_font_bold" id="A5.T11.3.9.8.6.1">0.433</span></td>
</tr>
<tr class="ltx_tr" id="A5.T11.3.10.9">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T11.3.10.9.1">B:<span class="ltx_text ltx_font_smallcaps" id="A5.T11.3.10.9.1.1">BARTScore</span>
</td>
<td class="ltx_td ltx_border_r" id="A5.T11.3.10.9.2"></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.10.9.3">0.030</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.10.9.4">0.022</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.10.9.5">0.040</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.10.9.6">0.330</td>
</tr>
<tr class="ltx_tr" id="A5.T11.3.11.10">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T11.3.11.10.1">B:<span class="ltx_text ltx_font_smallcaps" id="A5.T11.3.11.10.1.1">DSBA</span>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.11.10.2">Model:<span class="ltx_text ltx_font_smallcaps" id="A5.T11.3.11.10.2.1">Platypus2-70B</span>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.11.10.3">0.140</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.11.10.4">0.090</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.11.10.5">0.173</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.11.10.6">0.399</td>
</tr>
<tr class="ltx_tr" id="A5.T11.3.12.11">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T11.3.12.11.1"><span class="ltx_text" id="A5.T11.3.12.11.1.1" style="color:#808080;">B:<span class="ltx_text ltx_font_smallcaps" id="A5.T11.3.12.11.1.1.1">XComet</span></span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.12.11.2"></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.12.11.3"><span class="ltx_text ltx_font_bold" id="A5.T11.3.12.11.3.1" style="color:#808080;">0.588</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.12.11.4"><span class="ltx_text ltx_font_bold" id="A5.T11.3.12.11.4.1" style="color:#808080;">0.689</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.12.11.5"><span class="ltx_text ltx_font_bold" id="A5.T11.3.12.11.5.1" style="color:#808080;">0.700</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.12.11.6"><span class="ltx_text ltx_font_bold" id="A5.T11.3.12.11.6.1" style="color:#808080;">0.616</span></td>
</tr>
<tr class="ltx_tr" id="A5.T11.3.13.12">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="A5.T11.3.13.12.1"><span class="ltx_text ltx_font_bold" id="A5.T11.3.13.12.1.1">zh-en</span></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T11.3.13.12.2"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T11.3.13.12.3"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T11.3.13.12.4"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T11.3.13.12.5"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T11.3.13.12.6"></td>
</tr>
<tr class="ltx_tr" id="A5.T11.3.14.13">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T11.3.14.13.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T11.3.14.13.1.1">LLaMA3-70B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.14.13.2">PZS, Curious, complex l.</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.14.13.3">0.254</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.14.13.4">0.263</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.14.13.5">0.301</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.14.13.6">0.445</td>
</tr>
<tr class="ltx_tr" id="A5.T11.3.15.14">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T11.3.15.14.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T11.3.15.14.1.1">LLaMA3-8B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.15.14.2">PZS, Emphasis, 0.0 to 1.0</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.15.14.3">0.178</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.15.14.4">-0.021</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.15.14.5">0.213</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.15.14.6">0.301</td>
</tr>
<tr class="ltx_tr" id="A5.T11.3.16.15">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T11.3.16.15.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T11.3.16.15.1.1">Nous-13B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.16.15.2">PZS, Curious, complex l.</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.16.15.3">0.137</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.16.15.4">0.036</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.16.15.5">0.158</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.16.15.6">0.284</td>
</tr>
<tr class="ltx_tr" id="A5.T11.3.17.16">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T11.3.17.16.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T11.3.17.16.1.1">OrcaPlt-13B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.17.16.2">PZS, Casual, -100 to 100</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.17.16.3">0.313</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.17.16.4">0.207</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.17.16.5">0.372</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.17.16.6">0.439</td>
</tr>
<tr class="ltx_tr" id="A5.T11.3.18.17">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T11.3.18.17.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T11.3.18.17.1.1">Platypus2-70B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.18.17.2">PZS, Casual, -100 to 100</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.18.17.3"><span class="ltx_text ltx_font_bold" id="A5.T11.3.18.17.3.1">0.344*</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.18.17.4">0.190</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.18.17.5">0.406</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.18.17.6">0.452</td>
</tr>
<tr class="ltx_tr" id="A5.T11.3.19.18">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T11.3.19.18.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T11.3.19.18.1.1">Tower-13B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.19.18.2">ZS-CoT, Dire Warning, complex l.</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.19.18.3">0.275</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.19.18.4"><span class="ltx_text ltx_font_bold" id="A5.T11.3.19.18.4.1">0.321</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.19.18.5">0.317</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.19.18.6">0.417</td>
</tr>
<tr class="ltx_tr" id="A5.T11.3.20.19">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T11.3.20.19.1">MQM:<span class="ltx_text ltx_font_smallcaps" id="A5.T11.3.20.19.1.1">LocalGemba</span>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.20.19.2">Model:<span class="ltx_text ltx_font_smallcaps" id="A5.T11.3.20.19.2.1">Platypus2-70B</span>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.20.19.3">0.245</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.20.19.4">0.237</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.20.19.5">0.280</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.20.19.6">0.413</td>
</tr>
<tr class="ltx_tr" id="A5.T11.3.21.20">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T11.3.21.20.1">B:<span class="ltx_text ltx_font_smallcaps" id="A5.T11.3.21.20.1.1">BARTScore</span>
</td>
<td class="ltx_td ltx_border_r" id="A5.T11.3.21.20.2"></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.21.20.3">-0.106</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.21.20.4">-0.15</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.21.20.5">-0.145</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.21.20.6">0.315</td>
</tr>
<tr class="ltx_tr" id="A5.T11.3.22.21">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T11.3.22.21.1">B:<span class="ltx_text ltx_font_smallcaps" id="A5.T11.3.22.21.1.1">DSBA</span>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.22.21.2">Model:<span class="ltx_text ltx_font_smallcaps" id="A5.T11.3.22.21.2.1">Platypus2-70B</span>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.22.21.3">0.323</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.22.21.4">0.273</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.22.21.5"><span class="ltx_text ltx_font_bold" id="A5.T11.3.22.21.5.1">0.419</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.22.21.6"><span class="ltx_text ltx_font_bold" id="A5.T11.3.22.21.6.1">0.491</span></td>
</tr>
<tr class="ltx_tr" id="A5.T11.3.23.22">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T11.3.23.22.1"><span class="ltx_text" id="A5.T11.3.23.22.1.1" style="color:#808080;">B:<span class="ltx_text ltx_font_smallcaps" id="A5.T11.3.23.22.1.1.1">XComet</span></span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.23.22.2"></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.23.22.3"><span class="ltx_text ltx_font_bold" id="A5.T11.3.23.22.3.1" style="color:#808080;">0.531</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.23.22.4"><span class="ltx_text ltx_font_bold" id="A5.T11.3.23.22.4.1" style="color:#808080;">0.671</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.23.22.5"><span class="ltx_text ltx_font_bold" id="A5.T11.3.23.22.5.1" style="color:#808080;">0.663</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.23.22.6"><span class="ltx_text ltx_font_bold" id="A5.T11.3.23.22.6.1" style="color:#808080;">0.602</span></td>
</tr>
<tr class="ltx_tr" id="A5.T11.3.24.23">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="A5.T11.3.24.23.1"><span class="ltx_text ltx_font_bold" id="A5.T11.3.24.23.1.1">summarization</span></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T11.3.24.23.2"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T11.3.24.23.3"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T11.3.24.23.4"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T11.3.24.23.5"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T11.3.24.23.6"></td>
</tr>
<tr class="ltx_tr" id="A5.T11.3.25.24">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T11.3.25.24.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T11.3.25.24.1.1">LLaMA3-70B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.25.24.2">PZS, Curious, complex l.</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.25.24.3">0.252</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.25.24.4">0.360</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.25.24.5">0.311</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.25.24.6">0.365</td>
</tr>
<tr class="ltx_tr" id="A5.T11.3.26.25">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T11.3.26.25.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T11.3.26.25.1.1">LLaMA3-8B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.26.25.2">PZS, Curious, complex l.</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.26.25.3">0.284</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.26.25.4">0.410</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.26.25.5">0.342</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.26.25.6">0.233</td>
</tr>
<tr class="ltx_tr" id="A5.T11.3.27.26">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T11.3.27.26.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T11.3.27.26.1.1">Nous-13B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.27.26.2">PZS, Casual, -100 to 100</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.27.26.3">0.155</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.27.26.4">0.076</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.27.26.5">0.209</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.27.26.6"><span class="ltx_text ltx_font_bold" id="A5.T11.3.27.26.6.1">0.457</span></td>
</tr>
<tr class="ltx_tr" id="A5.T11.3.28.27">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T11.3.28.27.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T11.3.28.27.1.1">OrcaPlt-13B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.28.27.2">PZS, Casual, -100 to 100</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.28.27.3">0.428</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.28.27.4">0.450</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.28.27.5">0.518</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.28.27.6">0.433</td>
</tr>
<tr class="ltx_tr" id="A5.T11.3.29.28">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T11.3.29.28.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T11.3.29.28.1.1">Platypus2-70B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.29.28.2">ZS-CoT, Relaxed, simple labels</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.29.28.3"><span class="ltx_text ltx_font_bold" id="A5.T11.3.29.28.3.1">0.504*</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.29.28.4"><span class="ltx_text ltx_font_bold" id="A5.T11.3.29.28.4.1">0.589</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.29.28.5"><span class="ltx_text ltx_font_bold" id="A5.T11.3.29.28.5.1">0.603</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.29.28.6"><span class="ltx_text ltx_font_bold" id="A5.T11.3.29.28.6.1">0.485</span></td>
</tr>
<tr class="ltx_tr" id="A5.T11.3.30.29">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T11.3.30.29.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T11.3.30.29.1.1">Tower-13B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.30.29.2">ZS-CoT, Dire Warning, complex l.</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.30.29.3">0.194</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.30.29.4">0.312</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.30.29.5">0.234</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.30.29.6">0.180</td>
</tr>
<tr class="ltx_tr" id="A5.T11.3.31.30">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T11.3.31.30.1">MQM:<span class="ltx_text ltx_font_smallcaps" id="A5.T11.3.31.30.1.1">LocalGemba</span>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.31.30.2">Model:<span class="ltx_text ltx_font_smallcaps" id="A5.T11.3.31.30.2.1">Platypus2-70B</span>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.31.30.3">0.126</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.31.30.4">0.190</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.31.30.5">0.175</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.31.30.6">0.355</td>
</tr>
<tr class="ltx_tr" id="A5.T11.3.32.31">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T11.3.32.31.1">B:<span class="ltx_text ltx_font_smallcaps" id="A5.T11.3.32.31.1.1">BARTScore</span>
</td>
<td class="ltx_td ltx_border_r" id="A5.T11.3.32.31.2"></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.32.31.3">0.140</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.32.31.4">0.238</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.32.31.5">0.206</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.32.31.6">0.289</td>
</tr>
<tr class="ltx_tr" id="A5.T11.3.33.32">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T11.3.33.32.1">B:<span class="ltx_text ltx_font_smallcaps" id="A5.T11.3.33.32.1.1">DSBA</span>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.33.32.2">Model:<span class="ltx_text ltx_font_smallcaps" id="A5.T11.3.33.32.2.1">Platypus2-70B</span>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.33.32.3"><span class="ltx_text ltx_font_bold" id="A5.T11.3.33.32.3.1">0.442</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.33.32.4"><span class="ltx_text ltx_font_bold" id="A5.T11.3.33.32.4.1">0.645</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.33.32.5"><span class="ltx_text ltx_font_bold" id="A5.T11.3.33.32.5.1">0.600</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T11.3.33.32.6">0.350</td>
</tr>
<tr class="ltx_tr" id="A5.T11.3.34.33">
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r" id="A5.T11.3.34.33.1"><span class="ltx_text" id="A5.T11.3.34.33.1.1" style="color:#808080;">B:<span class="ltx_text ltx_font_smallcaps" id="A5.T11.3.34.33.1.1.1">XComet</span></span></td>
<td class="ltx_td ltx_border_b ltx_border_r" id="A5.T11.3.34.33.2"></td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="A5.T11.3.34.33.3">-0.037</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="A5.T11.3.34.33.4">-0.144</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="A5.T11.3.34.33.5">-0.060</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="A5.T11.3.34.33.6">0.256</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 11: </span>Best performing prompts of the phase 2 evaluation on the Eval4NLP dev set. We present the <span class="ltx_text ltx_font_bold" id="A5.T11.10.1">K</span>en<span class="ltx_text ltx_font_bold" id="A5.T11.11.2">D</span>all, <span class="ltx_text ltx_font_bold" id="A5.T11.12.3">SP</span>earman and <span class="ltx_text ltx_font_bold" id="A5.T11.13.4">PE</span>arson, as well as the tie calibrated pair-wise <span class="ltx_text ltx_font_bold" id="A5.T11.14.5">ACC</span>uracy. We bold the two largest correlations per column. Baselines are indicated with a <span class="ltx_text ltx_font_italic" id="A5.T11.15.6">B:</span>. The middle column shows the prompt combination for which the correlations are reported. For the Baselines, it instead shows the model that was used for the reported correlations. The asterisk indicates all metrics that are in the best significance cluster (not including BARTScore and XComet) according to a permute-input test <math alttext="(p\leq 0.075)" class="ltx_Math" display="inline" id="A5.T11.2.m1.1"><semantics id="A5.T11.2.m1.1b"><mrow id="A5.T11.2.m1.1.1.1" xref="A5.T11.2.m1.1.1.1.1.cmml"><mo id="A5.T11.2.m1.1.1.1.2" stretchy="false" xref="A5.T11.2.m1.1.1.1.1.cmml">(</mo><mrow id="A5.T11.2.m1.1.1.1.1" xref="A5.T11.2.m1.1.1.1.1.cmml"><mi id="A5.T11.2.m1.1.1.1.1.2" xref="A5.T11.2.m1.1.1.1.1.2.cmml">p</mi><mo id="A5.T11.2.m1.1.1.1.1.1" xref="A5.T11.2.m1.1.1.1.1.1.cmml">≤</mo><mn id="A5.T11.2.m1.1.1.1.1.3" xref="A5.T11.2.m1.1.1.1.1.3.cmml">0.075</mn></mrow><mo id="A5.T11.2.m1.1.1.1.3" stretchy="false" xref="A5.T11.2.m1.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="A5.T11.2.m1.1c"><apply id="A5.T11.2.m1.1.1.1.1.cmml" xref="A5.T11.2.m1.1.1.1"><leq id="A5.T11.2.m1.1.1.1.1.1.cmml" xref="A5.T11.2.m1.1.1.1.1.1"></leq><ci id="A5.T11.2.m1.1.1.1.1.2.cmml" xref="A5.T11.2.m1.1.1.1.1.2">𝑝</ci><cn id="A5.T11.2.m1.1.1.1.1.3.cmml" type="float" xref="A5.T11.2.m1.1.1.1.1.3">0.075</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.T11.2.m1.1d">(p\leq 0.075)</annotation><annotation encoding="application/x-llamapun" id="A5.T11.2.m1.1e">( italic_p ≤ 0.075 )</annotation></semantics></math>. XComet is greyed out, as its training data partly contained the MT datasets.</figcaption>
</figure>
<figure class="ltx_table" id="A5.T12">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A5.T12.3">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A5.T12.3.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t" id="A5.T12.3.1.1.1"><span class="ltx_text ltx_font_bold" id="A5.T12.3.1.1.1.1">Model</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="A5.T12.3.1.1.2"><span class="ltx_text ltx_font_bold" id="A5.T12.3.1.1.2.1">Prompt</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="A5.T12.3.1.1.3"><span class="ltx_text ltx_font_bold" id="A5.T12.3.1.1.3.1">KD</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="A5.T12.3.1.1.4"><span class="ltx_text ltx_font_bold" id="A5.T12.3.1.1.4.1">PE</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="A5.T12.3.1.1.5"><span class="ltx_text ltx_font_bold" id="A5.T12.3.1.1.5.1">SP</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="A5.T12.3.1.1.6"><span class="ltx_text ltx_font_bold" id="A5.T12.3.1.1.6.1">ACC</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A5.T12.3.2.1">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="A5.T12.3.2.1.1"><span class="ltx_text ltx_font_bold" id="A5.T12.3.2.1.1.1">en-de</span></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T12.3.2.1.2"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T12.3.2.1.3"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T12.3.2.1.4"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T12.3.2.1.5"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T12.3.2.1.6"></td>
</tr>
<tr class="ltx_tr" id="A5.T12.3.3.2">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T12.3.3.2.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T12.3.3.2.1.1">LLaMA3-70B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.3.2.2">POS, Curious, complex l.</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.3.2.3">0.245</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.3.2.4">0.271</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.3.2.5">0.300</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.3.2.6">0.315</td>
</tr>
<tr class="ltx_tr" id="A5.T12.3.4.3">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T12.3.4.3.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T12.3.4.3.1.1">LLaMA3-8B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.4.3.2">PZS, Casual, -100 to 100</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.4.3.3">0.167</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.4.3.4">-0.001</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.4.3.5">0.213</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.4.3.6">0.379</td>
</tr>
<tr class="ltx_tr" id="A5.T12.3.5.4">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T12.3.5.4.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T12.3.5.4.1.1">Nous-13B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.5.4.2">PZS, Curious, complex l.</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.5.4.3">0.205</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.5.4.4">0.074</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.5.4.5">0.247</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.5.4.6">0.072</td>
</tr>
<tr class="ltx_tr" id="A5.T12.3.6.5">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T12.3.6.5.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T12.3.6.5.1.1">OrcaPlt-13B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.6.5.2">ZS-CoT-EM, Skeptical, complex l.</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.6.5.3">0.214</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.6.5.4">0.246</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.6.5.5">0.256</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.6.5.6">0.283</td>
</tr>
<tr class="ltx_tr" id="A5.T12.3.7.6">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T12.3.7.6.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T12.3.7.6.1.1">Platypus2-70B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.7.6.2">PZS, Casual, -100 to 100</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.7.6.3"><span class="ltx_text ltx_font_bold" id="A5.T12.3.7.6.3.1">0.402*</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.7.6.4">0.289</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.7.6.5"><span class="ltx_text ltx_font_bold" id="A5.T12.3.7.6.5.1">0.506</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.7.6.6">0.525</td>
</tr>
<tr class="ltx_tr" id="A5.T12.3.8.7">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T12.3.8.7.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T12.3.8.7.1.1">Tower-13B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.8.7.2">ZS-Cot, Dire Warning, complex l.</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.8.7.3">0.379*</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.8.7.4"><span class="ltx_text ltx_font_bold" id="A5.T12.3.8.7.4.1">0.428</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.8.7.5">0.456</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.8.7.6">0.423</td>
</tr>
<tr class="ltx_tr" id="A5.T12.3.9.8">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T12.3.9.8.1">MQM:LocalGemba</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.9.8.2">Model:<span class="ltx_text ltx_font_smallcaps" id="A5.T12.3.9.8.2.1">Platypus2-70B</span>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.9.8.3">0.344</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.9.8.4">0.388</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.9.8.5">0.424</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.9.8.6">0.348</td>
</tr>
<tr class="ltx_tr" id="A5.T12.3.10.9">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T12.3.10.9.1">B:BARTScore</td>
<td class="ltx_td ltx_border_r" id="A5.T12.3.10.9.2"></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.10.9.3">0.125</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.10.9.4">0.169</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.10.9.5">0.182</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.10.9.6">0.531</td>
</tr>
<tr class="ltx_tr" id="A5.T12.3.11.10">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T12.3.11.10.1">B:DSBA</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.11.10.2">Model:<span class="ltx_text ltx_font_smallcaps" id="A5.T12.3.11.10.2.1">Platypus2-70B</span>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.11.10.3">0.314</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.11.10.4">0.180</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.11.10.5">0.422</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.11.10.6"><span class="ltx_text ltx_font_bold" id="A5.T12.3.11.10.6.1">0.557</span></td>
</tr>
<tr class="ltx_tr" id="A5.T12.3.12.11">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T12.3.12.11.1">B:XComet</td>
<td class="ltx_td ltx_border_r" id="A5.T12.3.12.11.2"></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.12.11.3"><span class="ltx_text ltx_font_bold" id="A5.T12.3.12.11.3.1">0.468</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.12.11.4"><span class="ltx_text ltx_font_bold" id="A5.T12.3.12.11.4.1">0.618</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.12.11.5"><span class="ltx_text ltx_font_bold" id="A5.T12.3.12.11.5.1">0.635</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.12.11.6"><span class="ltx_text ltx_font_bold" id="A5.T12.3.12.11.6.1">0.689</span></td>
</tr>
<tr class="ltx_tr" id="A5.T12.3.13.12">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="A5.T12.3.13.12.1"><span class="ltx_text ltx_font_bold" id="A5.T12.3.13.12.1.1">en-es</span></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T12.3.13.12.2"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T12.3.13.12.3"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T12.3.13.12.4"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T12.3.13.12.5"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T12.3.13.12.6"></td>
</tr>
<tr class="ltx_tr" id="A5.T12.3.14.13">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T12.3.14.13.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T12.3.14.13.1.1">LLaMA3-70B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.14.13.2">PZS, Curious, complex l.</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.14.13.3">0.189</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.14.13.4">0.217</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.14.13.5">0.229</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.14.13.6">0.343</td>
</tr>
<tr class="ltx_tr" id="A5.T12.3.15.14">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T12.3.15.14.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T12.3.15.14.1.1">LLaMA3-8B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.15.14.2">POS, Casual, -100 to 100</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.15.14.3">0.158</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.15.14.4">0.054</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.15.14.5">0.208</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.15.14.6">0.439</td>
</tr>
<tr class="ltx_tr" id="A5.T12.3.16.15">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T12.3.16.15.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T12.3.16.15.1.1">Nous-13B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.16.15.2">PZS, Curious, complex l.</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.16.15.3">0.141</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.16.15.4">-0.01</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.16.15.5">0.164</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.16.15.6">0.147</td>
</tr>
<tr class="ltx_tr" id="A5.T12.3.17.16">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T12.3.17.16.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T12.3.17.16.1.1">OrcaPlt-13B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.17.16.2">PZS, Emphasis, 0.0 to 1.0</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.17.16.3">0.158</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.17.16.4">0.049</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.17.16.5">0.201</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.17.16.6">0.154</td>
</tr>
<tr class="ltx_tr" id="A5.T12.3.18.17">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T12.3.18.17.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T12.3.18.17.1.1">Platypus2-70B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.18.17.2">PZS, Casual, -100 to 100</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.18.17.3"><span class="ltx_text ltx_font_bold" id="A5.T12.3.18.17.3.1">0.289*</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.18.17.4">0.104</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.18.17.5"><span class="ltx_text ltx_font_bold" id="A5.T12.3.18.17.5.1">0.357</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.18.17.6">0.448</td>
</tr>
<tr class="ltx_tr" id="A5.T12.3.19.18">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T12.3.19.18.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T12.3.19.18.1.1">Tower-13B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.19.18.2">ZS-Cot, Dire Warning, complex l.</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.19.18.3">0.253</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.19.18.4"><span class="ltx_text ltx_font_bold" id="A5.T12.3.19.18.4.1">0.309</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.19.18.5">0.292</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.19.18.6">0.297</td>
</tr>
<tr class="ltx_tr" id="A5.T12.3.20.19">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T12.3.20.19.1">MQM:<span class="ltx_text ltx_font_smallcaps" id="A5.T12.3.20.19.1.1">LocalGemba</span>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.20.19.2">Model:<span class="ltx_text ltx_font_smallcaps" id="A5.T12.3.20.19.2.1">Platypus2-70B</span>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.20.19.3">0.265</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.20.19.4"><span class="ltx_text ltx_font_bold" id="A5.T12.3.20.19.4.1">0.269</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.20.19.5">0.316</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.20.19.6">0.352</td>
</tr>
<tr class="ltx_tr" id="A5.T12.3.21.20">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T12.3.21.20.1">B:<span class="ltx_text ltx_font_smallcaps" id="A5.T12.3.21.20.1.1">BARTScore</span>
</td>
<td class="ltx_td ltx_border_r" id="A5.T12.3.21.20.2"></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.21.20.3">0.139</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.21.20.4">0.157</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.21.20.5">0.197</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.21.20.6"><span class="ltx_text ltx_font_bold" id="A5.T12.3.21.20.6.1">0.497</span></td>
</tr>
<tr class="ltx_tr" id="A5.T12.3.22.21">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T12.3.22.21.1">B:<span class="ltx_text ltx_font_smallcaps" id="A5.T12.3.22.21.1.1">DSBA</span>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.22.21.2">Model:<span class="ltx_text ltx_font_smallcaps" id="A5.T12.3.22.21.2.1">Platypus2-70B</span>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.22.21.3">0.226</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.22.21.4">0.129</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.22.21.5">0.298</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.22.21.6">0.488</td>
</tr>
<tr class="ltx_tr" id="A5.T12.3.23.22">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T12.3.23.22.1">B:<span class="ltx_text ltx_font_smallcaps" id="A5.T12.3.23.22.1.1">XComet</span>
</td>
<td class="ltx_td ltx_border_r" id="A5.T12.3.23.22.2"></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.23.22.3"><span class="ltx_text ltx_font_bold" id="A5.T12.3.23.22.3.1">0.298*</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.23.22.4">0.260</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.23.22.5"><span class="ltx_text ltx_font_bold" id="A5.T12.3.23.22.5.1">0.409</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.23.22.6"><span class="ltx_text ltx_font_bold" id="A5.T12.3.23.22.6.1">0.570</span></td>
</tr>
<tr class="ltx_tr" id="A5.T12.3.24.23">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="A5.T12.3.24.23.1"><span class="ltx_text ltx_font_bold" id="A5.T12.3.24.23.1.1">en_zh</span></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T12.3.24.23.2"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T12.3.24.23.3"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T12.3.24.23.4"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T12.3.24.23.5"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T12.3.24.23.6"></td>
</tr>
<tr class="ltx_tr" id="A5.T12.3.25.24">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T12.3.25.24.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T12.3.25.24.1.1">LLaMA3-70B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.25.24.2">PZS, Curious, complex l.</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.25.24.3">0.231</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.25.24.4">0.275</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.25.24.5">0.286</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.25.24.6">0.394</td>
</tr>
<tr class="ltx_tr" id="A5.T12.3.26.25">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T12.3.26.25.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T12.3.26.25.1.1">LLaMA3-8B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.26.25.2">PZS, Casual, -100 to 100</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.26.25.3">0.145</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.26.25.4">0.075</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.26.25.5">0.193</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.26.25.6"><span class="ltx_text ltx_font_bold" id="A5.T12.3.26.25.6.1">0.469</span></td>
</tr>
<tr class="ltx_tr" id="A5.T12.3.27.26">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T12.3.27.26.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T12.3.27.26.1.1">Nous-13B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.27.26.2">ZS-CoT-EM, Skeptical, complex l.</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.27.26.3">0.084</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.27.26.4">0.118</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.27.26.5">0.106</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.27.26.6">0.345</td>
</tr>
<tr class="ltx_tr" id="A5.T12.3.28.27">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T12.3.28.27.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T12.3.28.27.1.1">OrcaPlt-13B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.28.27.2">PZS, Casual, -100 to 100</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.28.27.3">0.206</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.28.27.4">0.109</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.28.27.5">0.251</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.28.27.6">0.270</td>
</tr>
<tr class="ltx_tr" id="A5.T12.3.29.28">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T12.3.29.28.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T12.3.29.28.1.1">Platypus2-70B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.29.28.2">ZS-CoT-EM, Dire Warning, 0 or 1</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.29.28.3">0.295*</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.29.28.4">0.345</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.29.28.5">0.350</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.29.28.6">0.361</td>
</tr>
<tr class="ltx_tr" id="A5.T12.3.30.29">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T12.3.30.29.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T12.3.30.29.1.1">Tower-13B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.30.29.2">ZS-Cot, Dire Warning, complex l.</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.30.29.3">0.232</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.30.29.4">0.261</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.30.29.5">0.287</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.30.29.6">0.357</td>
</tr>
<tr class="ltx_tr" id="A5.T12.3.31.30">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T12.3.31.30.1">MQM:LocalGemba</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.31.30.2">Model:<span class="ltx_text ltx_font_smallcaps" id="A5.T12.3.31.30.2.1">Platypus2-70B</span>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.31.30.3"><span class="ltx_text ltx_font_bold" id="A5.T12.3.31.30.3.1">0.307*</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.31.30.4"><span class="ltx_text ltx_font_bold" id="A5.T12.3.31.30.4.1">0.353</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.31.30.5"><span class="ltx_text ltx_font_bold" id="A5.T12.3.31.30.5.1">0.381</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.31.30.6">0.429</td>
</tr>
<tr class="ltx_tr" id="A5.T12.3.32.31">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T12.3.32.31.1">B:<span class="ltx_text ltx_font_smallcaps" id="A5.T12.3.32.31.1.1">BARTScore</span>
</td>
<td class="ltx_td ltx_border_r" id="A5.T12.3.32.31.2"></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.32.31.3">-0.009</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.32.31.4">-0.009</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.32.31.5">-0.013</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.32.31.6">0.466</td>
</tr>
<tr class="ltx_tr" id="A5.T12.3.33.32">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T12.3.33.32.1">B:<span class="ltx_text ltx_font_smallcaps" id="A5.T12.3.33.32.1.1">DSBA</span>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.33.32.2">Model:<span class="ltx_text ltx_font_smallcaps" id="A5.T12.3.33.32.2.1">Platypus2-70B</span>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.33.32.3">0.159</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.33.32.4">0.202</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.33.32.5">0.212</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.33.32.6">0.461</td>
</tr>
<tr class="ltx_tr" id="A5.T12.3.34.33">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T12.3.34.33.1">B:<span class="ltx_text ltx_font_smallcaps" id="A5.T12.3.34.33.1.1">XComet</span>
</td>
<td class="ltx_td ltx_border_r" id="A5.T12.3.34.33.2"></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.34.33.3"><span class="ltx_text ltx_font_bold" id="A5.T12.3.34.33.3.1">0.387</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.34.33.4"><span class="ltx_text ltx_font_bold" id="A5.T12.3.34.33.4.1">0.503</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.34.33.5"><span class="ltx_text ltx_font_bold" id="A5.T12.3.34.33.5.1">0.537</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.34.33.6"><span class="ltx_text ltx_font_bold" id="A5.T12.3.34.33.6.1">0.657</span></td>
</tr>
<tr class="ltx_tr" id="A5.T12.3.35.34">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="A5.T12.3.35.34.1"><span class="ltx_text ltx_font_bold" id="A5.T12.3.35.34.1.1">summarization</span></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T12.3.35.34.2"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T12.3.35.34.3"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T12.3.35.34.4"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T12.3.35.34.5"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T12.3.35.34.6"></td>
</tr>
<tr class="ltx_tr" id="A5.T12.3.36.35">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T12.3.36.35.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T12.3.36.35.1.1">LLaMA3-70B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.36.35.2">PZS, Curious, complex l.</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.36.35.3">0.438</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.36.35.4">0.508</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.36.35.5">0.550</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.36.35.6">0.522</td>
</tr>
<tr class="ltx_tr" id="A5.T12.3.37.36">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T12.3.37.36.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T12.3.37.36.1.1">LLaMA3-8B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.37.36.2">PZS, Curious, complex l.</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.37.36.3">0.412</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.37.36.4">0.455</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.37.36.5">0.497</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.37.36.6">0.449</td>
</tr>
<tr class="ltx_tr" id="A5.T12.3.38.37">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T12.3.38.37.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T12.3.38.37.1.1">Nous-13B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.38.37.2">ZS-CoT-EM, Skeptical, complex l.</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.38.37.3">0.255</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.38.37.4">0.300</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.38.37.5">0.318</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.38.37.6">0.421</td>
</tr>
<tr class="ltx_tr" id="A5.T12.3.39.38">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T12.3.39.38.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T12.3.39.38.1.1">OrcaPlt-13B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.39.38.2">PZS, Casual, -100 to 100</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.39.38.3">0.518</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.39.38.4">0.592</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.39.38.5">0.651</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.39.38.6">0.593</td>
</tr>
<tr class="ltx_tr" id="A5.T12.3.40.39">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T12.3.40.39.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T12.3.40.39.1.1">Platypus2-70B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.40.39.2">PZS, Casual, -100 to 100</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.40.39.3"><span class="ltx_text ltx_font_bold" id="A5.T12.3.40.39.3.1">0.549</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.40.39.4"><span class="ltx_text ltx_font_bold" id="A5.T12.3.40.39.4.1">0.670</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.40.39.5"><span class="ltx_text ltx_font_bold" id="A5.T12.3.40.39.5.1">0.686</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.40.39.6">0.634</td>
</tr>
<tr class="ltx_tr" id="A5.T12.3.41.40">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T12.3.41.40.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T12.3.41.40.1.1">Tower-13B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.41.40.2">ZS-Cot, Relaxed, simple labels</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.41.40.3">0.409</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.41.40.4">0.442</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.41.40.5">0.499</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.41.40.6">0.336</td>
</tr>
<tr class="ltx_tr" id="A5.T12.3.42.41">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T12.3.42.41.1">MQM:<span class="ltx_text ltx_font_smallcaps" id="A5.T12.3.42.41.1.1">LocalGemba</span>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.42.41.2">Model:<span class="ltx_text ltx_font_smallcaps" id="A5.T12.3.42.41.2.1">Platypus2-70B</span>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.42.41.3">0.116</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.42.41.4">0.196</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.42.41.5">0.155</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.42.41.6">0.419</td>
</tr>
<tr class="ltx_tr" id="A5.T12.3.43.42">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T12.3.43.42.1">B:<span class="ltx_text ltx_font_smallcaps" id="A5.T12.3.43.42.1.1">BARTScore</span>
</td>
<td class="ltx_td ltx_border_r" id="A5.T12.3.43.42.2"></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.43.42.3">0.421</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.43.42.4">0.563</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.43.42.5">0.586</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.43.42.6"><span class="ltx_text ltx_font_bold" id="A5.T12.3.43.42.6.1">0.655</span></td>
</tr>
<tr class="ltx_tr" id="A5.T12.3.44.43">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T12.3.44.43.1">B:<span class="ltx_text ltx_font_smallcaps" id="A5.T12.3.44.43.1.1">DSBA</span>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.44.43.2">Model:<span class="ltx_text ltx_font_smallcaps" id="A5.T12.3.44.43.2.1">Platypus2-70B</span>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.44.43.3"><span class="ltx_text ltx_font_bold" id="A5.T12.3.44.43.3.1">0.600*</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.44.43.4"><span class="ltx_text ltx_font_bold" id="A5.T12.3.44.43.4.1">0.767</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.44.43.5"><span class="ltx_text ltx_font_bold" id="A5.T12.3.44.43.5.1">0.779</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T12.3.44.43.6"><span class="ltx_text ltx_font_bold" id="A5.T12.3.44.43.6.1">0.723</span></td>
</tr>
<tr class="ltx_tr" id="A5.T12.3.45.44">
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r" id="A5.T12.3.45.44.1">B:<span class="ltx_text ltx_font_smallcaps" id="A5.T12.3.45.44.1.1">XComet</span>
</td>
<td class="ltx_td ltx_border_b ltx_border_r" id="A5.T12.3.45.44.2"></td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="A5.T12.3.45.44.3">0.224</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="A5.T12.3.45.44.4">0.326</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="A5.T12.3.45.44.5">0.319</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="A5.T12.3.45.44.6">0.563</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 12: </span>Best performing promts of the phase 2.2 evaluation on the Eval4NLP test set. We present the <span class="ltx_text ltx_font_bold" id="A5.T12.10.1">K</span>en<span class="ltx_text ltx_font_bold" id="A5.T12.11.2">D</span>all, <span class="ltx_text ltx_font_bold" id="A5.T12.12.3">SP</span>earman and <span class="ltx_text ltx_font_bold" id="A5.T12.13.4">PE</span>arson, as well as the tie calibrated pair-wise <span class="ltx_text ltx_font_bold" id="A5.T12.14.5">ACC</span>uracy. We bold the two largest correlations per column. Baselines are indicated with a <span class="ltx_text ltx_font_italic" id="A5.T12.15.6">B:</span>. The middle column shows the prompt combination for which the correlations are reported. For the Baselines, it instead shows the model that was used for the reported correlations. The asterisk indicates all metrics that are in the best significance cluster (not including BARTScore and XComet) according to a permute-input test <math alttext="(p\leq 0.075)" class="ltx_Math" display="inline" id="A5.T12.2.m1.1"><semantics id="A5.T12.2.m1.1b"><mrow id="A5.T12.2.m1.1.1.1" xref="A5.T12.2.m1.1.1.1.1.cmml"><mo id="A5.T12.2.m1.1.1.1.2" stretchy="false" xref="A5.T12.2.m1.1.1.1.1.cmml">(</mo><mrow id="A5.T12.2.m1.1.1.1.1" xref="A5.T12.2.m1.1.1.1.1.cmml"><mi id="A5.T12.2.m1.1.1.1.1.2" xref="A5.T12.2.m1.1.1.1.1.2.cmml">p</mi><mo id="A5.T12.2.m1.1.1.1.1.1" xref="A5.T12.2.m1.1.1.1.1.1.cmml">≤</mo><mn id="A5.T12.2.m1.1.1.1.1.3" xref="A5.T12.2.m1.1.1.1.1.3.cmml">0.075</mn></mrow><mo id="A5.T12.2.m1.1.1.1.3" stretchy="false" xref="A5.T12.2.m1.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="A5.T12.2.m1.1c"><apply id="A5.T12.2.m1.1.1.1.1.cmml" xref="A5.T12.2.m1.1.1.1"><leq id="A5.T12.2.m1.1.1.1.1.1.cmml" xref="A5.T12.2.m1.1.1.1.1.1"></leq><ci id="A5.T12.2.m1.1.1.1.1.2.cmml" xref="A5.T12.2.m1.1.1.1.1.2">𝑝</ci><cn id="A5.T12.2.m1.1.1.1.1.3.cmml" type="float" xref="A5.T12.2.m1.1.1.1.1.3">0.075</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.T12.2.m1.1d">(p\leq 0.075)</annotation><annotation encoding="application/x-llamapun" id="A5.T12.2.m1.1e">( italic_p ≤ 0.075 )</annotation></semantics></math>.</figcaption>
</figure>
<figure class="ltx_table" id="A5.T13">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A5.T13.3">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A5.T13.3.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t" id="A5.T13.3.1.1.1"><span class="ltx_text ltx_font_bold" id="A5.T13.3.1.1.1.1">Model</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="A5.T13.3.1.1.2"><span class="ltx_text ltx_font_bold" id="A5.T13.3.1.1.2.1">Prompt</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="A5.T13.3.1.1.3"><span class="ltx_text ltx_font_bold" id="A5.T13.3.1.1.3.1">KD</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="A5.T13.3.1.1.4"><span class="ltx_text ltx_font_bold" id="A5.T13.3.1.1.4.1">PE</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="A5.T13.3.1.1.5"><span class="ltx_text ltx_font_bold" id="A5.T13.3.1.1.5.1">SP</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="A5.T13.3.1.1.6"><span class="ltx_text ltx_font_bold" id="A5.T13.3.1.1.6.1">ACC</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A5.T13.3.2.1">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="A5.T13.3.2.1.1"><span class="ltx_text ltx_font_bold" id="A5.T13.3.2.1.1.1">en-de</span></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T13.3.2.1.2"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T13.3.2.1.3"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T13.3.2.1.4"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T13.3.2.1.5"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T13.3.2.1.6"></td>
</tr>
<tr class="ltx_tr" id="A5.T13.3.3.2">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T13.3.3.2.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T13.3.3.2.1.1">LLaMA3-70B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.3.2.2">PZS, Curious, complex l.</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.3.2.3">0.297</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.3.2.4">0.294</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.3.2.5">0.361</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.3.2.6">0.416</td>
</tr>
<tr class="ltx_tr" id="A5.T13.3.4.3">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T13.3.4.3.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T13.3.4.3.1.1">LLaMA3-8B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.4.3.2">PZS, Casual, -100 to 100</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.4.3.3">0.166</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.4.3.4">0.040</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.4.3.5">0.216</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.4.3.6">0.434</td>
</tr>
<tr class="ltx_tr" id="A5.T13.3.5.4">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T13.3.5.4.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T13.3.5.4.1.1">Nous-13B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.5.4.2">ZS-CoT-EM, Skeptical, complex l.</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.5.4.3">0.202</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.5.4.4">0.239</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.5.4.5">0.251</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.5.4.6">0.403</td>
</tr>
<tr class="ltx_tr" id="A5.T13.3.6.5">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T13.3.6.5.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T13.3.6.5.1.1">OrcaPlt-13B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.6.5.2">PZS, Casual, -100 to 100</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.6.5.3">0.375</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.6.5.4">0.299</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.6.5.5">0.456</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.6.5.6">0.467</td>
</tr>
<tr class="ltx_tr" id="A5.T13.3.7.6">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T13.3.7.6.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T13.3.7.6.1.1">Platypus2-70B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.7.6.2">ZS-CoT-EM, Skeptical, complex l.</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.7.6.3">0.338</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.7.6.4">0.304</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.7.6.5">0.406</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.7.6.6">0.394</td>
</tr>
<tr class="ltx_tr" id="A5.T13.3.8.7">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T13.3.8.7.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T13.3.8.7.1.1">Tower-13B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.8.7.2">ZS-CoT, Dire Warning, complex l.</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.8.7.3">0.322</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.8.7.4">0.308</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.8.7.5">0.392</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.8.7.6">0.418</td>
</tr>
<tr class="ltx_tr" id="A5.T13.3.9.8">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T13.3.9.8.1">MQM:<span class="ltx_text ltx_font_smallcaps" id="A5.T13.3.9.8.1.1">LocalGemba</span>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.9.8.2">Model:<span class="ltx_text ltx_font_smallcaps" id="A5.T13.3.9.8.2.1">Platypus2-70B</span>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.9.8.3"><span class="ltx_text ltx_font_bold" id="A5.T13.3.9.8.3.1">0.391*</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.9.8.4"><span class="ltx_text ltx_font_bold" id="A5.T13.3.9.8.4.1">0.389</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.9.8.5"><span class="ltx_text ltx_font_bold" id="A5.T13.3.9.8.5.1">0.494</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.9.8.6"><span class="ltx_text ltx_font_bold" id="A5.T13.3.9.8.6.1">0.537</span></td>
</tr>
<tr class="ltx_tr" id="A5.T13.3.10.9">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T13.3.10.9.1">B:<span class="ltx_text ltx_font_smallcaps" id="A5.T13.3.10.9.1.1">BARTScore</span>
</td>
<td class="ltx_td ltx_border_r" id="A5.T13.3.10.9.2"></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.10.9.3">-0.018</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.10.9.4">-0.039</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.10.9.5">-0.027</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.10.9.6">0.428</td>
</tr>
<tr class="ltx_tr" id="A5.T13.3.11.10">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T13.3.11.10.1">B:<span class="ltx_text ltx_font_smallcaps" id="A5.T13.3.11.10.1.1">DSBA</span>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.11.10.2">Model:<span class="ltx_text ltx_font_smallcaps" id="A5.T13.3.11.10.2.1">Platypus2-70B</span>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.11.10.3">0.172</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.11.10.4">0.170</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.11.10.5">0.229</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.11.10.6">0.487</td>
</tr>
<tr class="ltx_tr" id="A5.T13.3.12.11">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T13.3.12.11.1">B:<span class="ltx_text ltx_font_smallcaps" id="A5.T13.3.12.11.1.1">XComet</span>
</td>
<td class="ltx_td ltx_border_r" id="A5.T13.3.12.11.2"></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.12.11.3"><span class="ltx_text ltx_font_bold" id="A5.T13.3.12.11.3.1">0.531</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.12.11.4"><span class="ltx_text ltx_font_bold" id="A5.T13.3.12.11.4.1">0.647</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.12.11.5"><span class="ltx_text ltx_font_bold" id="A5.T13.3.12.11.5.1">0.701</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.12.11.6"><span class="ltx_text ltx_font_bold" id="A5.T13.3.12.11.6.1">0.683</span></td>
</tr>
<tr class="ltx_tr" id="A5.T13.3.13.12">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="A5.T13.3.13.12.1"><span class="ltx_text ltx_font_bold" id="A5.T13.3.13.12.1.1">he-en</span></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T13.3.13.12.2"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T13.3.13.12.3"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T13.3.13.12.4"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T13.3.13.12.5"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T13.3.13.12.6"></td>
</tr>
<tr class="ltx_tr" id="A5.T13.3.14.13">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T13.3.14.13.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T13.3.14.13.1.1">LLaMA3-70B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.14.13.2">PZS, Curious, complex l.</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.14.13.3">0.172</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.14.13.4">0.182</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.14.13.5">0.201</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.14.13.6">0.411</td>
</tr>
<tr class="ltx_tr" id="A5.T13.3.15.14">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T13.3.15.14.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T13.3.15.14.1.1">LLaMA3-8B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.15.14.2">PZS, Curious, complex l.</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.15.14.3">0.118</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.15.14.4">0.128</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.15.14.5">0.132</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.15.14.6">0.351</td>
</tr>
<tr class="ltx_tr" id="A5.T13.3.16.15">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T13.3.16.15.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T13.3.16.15.1.1">Nous-13B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.16.15.2">PZS, Curious, complex l.</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.16.15.3">0.105</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.16.15.4">0.091</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.16.15.5">0.120</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.16.15.6">0.333</td>
</tr>
<tr class="ltx_tr" id="A5.T13.3.17.16">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T13.3.17.16.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T13.3.17.16.1.1">OrcaPlt-13B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.17.16.2">PZS, Casual, -100 to 100</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.17.16.3">0.247</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.17.16.4">0.198</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.17.16.5">0.293</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.17.16.6">0.430</td>
</tr>
<tr class="ltx_tr" id="A5.T13.3.18.17">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T13.3.18.17.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T13.3.18.17.1.1">Platypus2-70B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.18.17.2">PZS, Casual, -100 to 100</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.18.17.3"><span class="ltx_text ltx_font_bold" id="A5.T13.3.18.17.3.1">0.259*</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.18.17.4">0.205</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.18.17.5"><span class="ltx_text ltx_font_bold" id="A5.T13.3.18.17.5.1">0.307</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.18.17.6"><span class="ltx_text ltx_font_bold" id="A5.T13.3.18.17.6.1">0.432</span></td>
</tr>
<tr class="ltx_tr" id="A5.T13.3.19.18">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T13.3.19.18.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T13.3.19.18.1.1">Tower-13B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.19.18.2">ZS-CoT, Dire Warning, complex l.</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.19.18.3">0.208</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.19.18.4"><span class="ltx_text ltx_font_bold" id="A5.T13.3.19.18.4.1">0.252</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.19.18.5">0.238</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.19.18.6">0.403</td>
</tr>
<tr class="ltx_tr" id="A5.T13.3.20.19">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T13.3.20.19.1">MQM:<span class="ltx_text ltx_font_smallcaps" id="A5.T13.3.20.19.1.1">LocalGemba</span>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.20.19.2">Model:<span class="ltx_text ltx_font_smallcaps" id="A5.T13.3.20.19.2.1">Platypus2-70B</span>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.20.19.3">0.190</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.20.19.4">0.210</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.20.19.5">0.214</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.20.19.6">0.424</td>
</tr>
<tr class="ltx_tr" id="A5.T13.3.21.20">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T13.3.21.20.1">B:<span class="ltx_text ltx_font_smallcaps" id="A5.T13.3.21.20.1.1">BARTScore</span>
</td>
<td class="ltx_td ltx_border_r" id="A5.T13.3.21.20.2"></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.21.20.3">0.001</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.21.20.4">-0.023</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.21.20.5">0.002</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.21.20.6">0.322</td>
</tr>
<tr class="ltx_tr" id="A5.T13.3.22.21">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T13.3.22.21.1">B:<span class="ltx_text ltx_font_smallcaps" id="A5.T13.3.22.21.1.1">DSBA</span>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.22.21.2">Model:<span class="ltx_text ltx_font_smallcaps" id="A5.T13.3.22.21.2.1">Platypus2-70B</span>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.22.21.3">0.207</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.22.21.4">0.239</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.22.21.5">0.268</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.22.21.6">0.413</td>
</tr>
<tr class="ltx_tr" id="A5.T13.3.23.22">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T13.3.23.22.1">B:<span class="ltx_text ltx_font_smallcaps" id="A5.T13.3.23.22.1.1">XComet</span>
</td>
<td class="ltx_td ltx_border_r" id="A5.T13.3.23.22.2"></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.23.22.3"><span class="ltx_text ltx_font_bold" id="A5.T13.3.23.22.3.1">0.300</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.23.22.4"><span class="ltx_text ltx_font_bold" id="A5.T13.3.23.22.4.1">0.358</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.23.22.5"><span class="ltx_text ltx_font_bold" id="A5.T13.3.23.22.5.1">0.396</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.23.22.6"><span class="ltx_text ltx_font_bold" id="A5.T13.3.23.22.6.1">0.456</span></td>
</tr>
<tr class="ltx_tr" id="A5.T13.3.24.23">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="A5.T13.3.24.23.1"><span class="ltx_text ltx_font_bold" id="A5.T13.3.24.23.1.1">zh-en</span></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T13.3.24.23.2"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T13.3.24.23.3"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T13.3.24.23.4"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T13.3.24.23.5"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T13.3.24.23.6"></td>
</tr>
<tr class="ltx_tr" id="A5.T13.3.25.24">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T13.3.25.24.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T13.3.25.24.1.1">LLaMA3-70B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.25.24.2">PZS, Curious, complex l.</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.25.24.3">0.312</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.25.24.4">0.333</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.25.24.5">0.382</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.25.24.6">0.436</td>
</tr>
<tr class="ltx_tr" id="A5.T13.3.26.25">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T13.3.26.25.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T13.3.26.25.1.1">LLaMA3-8B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.26.25.2">PZS, Emphasis, 0.0 to 1.0</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.26.25.3">0.164</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.26.25.4">0.003</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.26.25.5">0.205</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.26.25.6">0.195</td>
</tr>
<tr class="ltx_tr" id="A5.T13.3.27.26">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T13.3.27.26.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T13.3.27.26.1.1">Nous-13B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.27.26.2">PZS, Curious, complex l.</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.27.26.3">0.175</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.27.26.4">0.074</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.27.26.5">0.213</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.27.26.6">0.180</td>
</tr>
<tr class="ltx_tr" id="A5.T13.3.28.27">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T13.3.28.27.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T13.3.28.27.1.1">OrcaPlt-13B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.28.27.2">PZS, Casual, -100 to 100</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.28.27.3">0.387</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.28.27.4">0.321</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.28.27.5">0.480</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.28.27.6">0.499</td>
</tr>
<tr class="ltx_tr" id="A5.T13.3.29.28">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T13.3.29.28.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T13.3.29.28.1.1">Platypus2-70B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.29.28.2">PZS, Casual, -100 to 100</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.29.28.3"><span class="ltx_text ltx_font_bold" id="A5.T13.3.29.28.3.1">0.417*</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.29.28.4">0.306</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.29.28.5"><span class="ltx_text ltx_font_bold" id="A5.T13.3.29.28.5.1">0.512</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.29.28.6">0.486</td>
</tr>
<tr class="ltx_tr" id="A5.T13.3.30.29">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T13.3.30.29.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T13.3.30.29.1.1">Tower-13B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.30.29.2">ZS-CoT, Urgent situation, complex l.</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.30.29.3">0.314</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.30.29.4"><span class="ltx_text ltx_font_bold" id="A5.T13.3.30.29.4.1">0.384</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.30.29.5">0.388</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.30.29.6">0.460</td>
</tr>
<tr class="ltx_tr" id="A5.T13.3.31.30">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T13.3.31.30.1">MQM:<span class="ltx_text ltx_font_smallcaps" id="A5.T13.3.31.30.1.1">LocalGemba</span>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.31.30.2">Model:<span class="ltx_text ltx_font_smallcaps" id="A5.T13.3.31.30.2.1">Platypus2-70B</span>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.31.30.3">0.300</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.31.30.4">0.338</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.31.30.5">0.358</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.31.30.6">0.310</td>
</tr>
<tr class="ltx_tr" id="A5.T13.3.32.31">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T13.3.32.31.1">B:<span class="ltx_text ltx_font_smallcaps" id="A5.T13.3.32.31.1.1">BARTScore</span>
</td>
<td class="ltx_td ltx_border_r" id="A5.T13.3.32.31.2"></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.32.31.3">-0.167</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.32.31.4">-0.199</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.32.31.5">-0.238</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.32.31.6">0.358</td>
</tr>
<tr class="ltx_tr" id="A5.T13.3.33.32">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T13.3.33.32.1">B:<span class="ltx_text ltx_font_smallcaps" id="A5.T13.3.33.32.1.1">DSBA</span>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.33.32.2">Model:<span class="ltx_text ltx_font_smallcaps" id="A5.T13.3.33.32.2.1">Platypus2-70B</span>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.33.32.3">0.376</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.33.32.4">0.289</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.33.32.5">0.502</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.33.32.6"><span class="ltx_text ltx_font_bold" id="A5.T13.3.33.32.6.1">0.581</span></td>
</tr>
<tr class="ltx_tr" id="A5.T13.3.34.33">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T13.3.34.33.1">B:<span class="ltx_text ltx_font_smallcaps" id="A5.T13.3.34.33.1.1">XComet</span>
</td>
<td class="ltx_td ltx_border_r" id="A5.T13.3.34.33.2"></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.34.33.3"><span class="ltx_text ltx_font_bold" id="A5.T13.3.34.33.3.1">0.447</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.34.33.4"><span class="ltx_text ltx_font_bold" id="A5.T13.3.34.33.4.1">0.616</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.34.33.5"><span class="ltx_text ltx_font_bold" id="A5.T13.3.34.33.5.1">0.597</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.34.33.6"><span class="ltx_text ltx_font_bold" id="A5.T13.3.34.33.6.1">0.641</span></td>
</tr>
<tr class="ltx_tr" id="A5.T13.3.35.34">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="A5.T13.3.35.34.1"><span class="ltx_text ltx_font_bold" id="A5.T13.3.35.34.1.1">summarization</span></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T13.3.35.34.2"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T13.3.35.34.3"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T13.3.35.34.4"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T13.3.35.34.5"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A5.T13.3.35.34.6"></td>
</tr>
<tr class="ltx_tr" id="A5.T13.3.36.35">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T13.3.36.35.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T13.3.36.35.1.1">LLaMA3-70B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.36.35.2">PZS, Curious, complex l.</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.36.35.3">0.312</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.36.35.4">0.333</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.36.35.5">0.363</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.36.35.6"><span class="ltx_text ltx_font_bold" id="A5.T13.3.36.35.6.1">0.454</span></td>
</tr>
<tr class="ltx_tr" id="A5.T13.3.37.36">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T13.3.37.36.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T13.3.37.36.1.1">LLaMA3-8B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.37.36.2">PZS, Curious, complex l.</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.37.36.3">0.200</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.37.36.4">0.203</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.37.36.5">0.227</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.37.36.6">0.393</td>
</tr>
<tr class="ltx_tr" id="A5.T13.3.38.37">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T13.3.38.37.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T13.3.38.37.1.1">Nous-13B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.38.37.2">PZS, Casual, -100 to 100</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.38.37.3">0.123</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.38.37.4">0.050</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.38.37.5">0.152</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.38.37.6">0.403</td>
</tr>
<tr class="ltx_tr" id="A5.T13.3.39.38">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T13.3.39.38.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T13.3.39.38.1.1">OrcaPlt-13B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.39.38.2">PZS, Casual, -100 to 100</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.39.38.3"><span class="ltx_text ltx_font_bold" id="A5.T13.3.39.38.3.1">0.377</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.39.38.4">0.263</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.39.38.5">0.441</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.39.38.6"><span class="ltx_text ltx_font_bold" id="A5.T13.3.39.38.6.1">0.489</span></td>
</tr>
<tr class="ltx_tr" id="A5.T13.3.40.39">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T13.3.40.39.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T13.3.40.39.1.1">Platypus2-70B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.40.39.2">PZS, Emphasis, 0.0 to 1.0</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.40.39.3"><span class="ltx_text ltx_font_bold" id="A5.T13.3.40.39.3.1">0.448*</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.40.39.4"><span class="ltx_text ltx_font_bold" id="A5.T13.3.40.39.4.1">0.444</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.40.39.5"><span class="ltx_text ltx_font_bold" id="A5.T13.3.40.39.5.1">0.532</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.40.39.6">0.379</td>
</tr>
<tr class="ltx_tr" id="A5.T13.3.41.40">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T13.3.41.40.1"><span class="ltx_text ltx_font_smallcaps" id="A5.T13.3.41.40.1.1">Tower-13B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.41.40.2">ZS-CoT, Relaxed, simple labels</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.41.40.3">0.257</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.41.40.4">0.255</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.41.40.5">0.296</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.41.40.6">0.411</td>
</tr>
<tr class="ltx_tr" id="A5.T13.3.42.41">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T13.3.42.41.1">MQM:<span class="ltx_text ltx_font_smallcaps" id="A5.T13.3.42.41.1.1">LocalGemba</span>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.42.41.2">Model:<span class="ltx_text ltx_font_smallcaps" id="A5.T13.3.42.41.2.1">Platypus2-70B</span>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.42.41.3">0.144</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.42.41.4">0.189</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.42.41.5">0.174</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.42.41.6">0.302</td>
</tr>
<tr class="ltx_tr" id="A5.T13.3.43.42">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T13.3.43.42.1">B:<span class="ltx_text ltx_font_smallcaps" id="A5.T13.3.43.42.1.1">BARTScore</span>
</td>
<td class="ltx_td ltx_border_r" id="A5.T13.3.43.42.2"></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.43.42.3">0.069</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.43.42.4">0.122</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.43.42.5">0.093</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.43.42.6">0.117</td>
</tr>
<tr class="ltx_tr" id="A5.T13.3.44.43">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="A5.T13.3.44.43.1">B:<span class="ltx_text ltx_font_smallcaps" id="A5.T13.3.44.43.1.1">DSBA</span>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.44.43.2">Model:<span class="ltx_text ltx_font_smallcaps" id="A5.T13.3.44.43.2.1">Platypus2-70B</span>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.44.43.3">0.373</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.44.43.4"><span class="ltx_text ltx_font_bold" id="A5.T13.3.44.43.4.1">0.490</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.44.43.5"><span class="ltx_text ltx_font_bold" id="A5.T13.3.44.43.5.1">0.478</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T13.3.44.43.6">0.213</td>
</tr>
<tr class="ltx_tr" id="A5.T13.3.45.44">
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r" id="A5.T13.3.45.44.1">B:<span class="ltx_text ltx_font_smallcaps" id="A5.T13.3.45.44.1.1">XComet</span>
</td>
<td class="ltx_td ltx_border_b ltx_border_r" id="A5.T13.3.45.44.2"></td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="A5.T13.3.45.44.3">0.146</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="A5.T13.3.45.44.4">0.117</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="A5.T13.3.45.44.5">0.194</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="A5.T13.3.45.44.6">0.136</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 13: </span>Best performing prompts of the phase 2.3 evaluation on the WMT23 and Seahorse datasets. We present the <span class="ltx_text ltx_font_bold" id="A5.T13.10.1">K</span>en<span class="ltx_text ltx_font_bold" id="A5.T13.11.2">D</span>all, <span class="ltx_text ltx_font_bold" id="A5.T13.12.3">SP</span>earman and <span class="ltx_text ltx_font_bold" id="A5.T13.13.4">PE</span>arson, as well as the tie calibrated pair-wise <span class="ltx_text ltx_font_bold" id="A5.T13.14.5">ACC</span>uracy. We bold the two largest correlations per column. Baselines are indicated with a <span class="ltx_text ltx_font_italic" id="A5.T13.15.6">B:</span>. The middle column shows the prompt combination for which the correlations are reported. For the Baselines, it instead shows the model that was used for the reported correlations. The asterisk indicates all metrics that are in the best significance cluster (not including BARTScore and XComet) according to a permute-input test <math alttext="(p\leq 0.075)" class="ltx_Math" display="inline" id="A5.T13.2.m1.1"><semantics id="A5.T13.2.m1.1b"><mrow id="A5.T13.2.m1.1.1.1" xref="A5.T13.2.m1.1.1.1.1.cmml"><mo id="A5.T13.2.m1.1.1.1.2" stretchy="false" xref="A5.T13.2.m1.1.1.1.1.cmml">(</mo><mrow id="A5.T13.2.m1.1.1.1.1" xref="A5.T13.2.m1.1.1.1.1.cmml"><mi id="A5.T13.2.m1.1.1.1.1.2" xref="A5.T13.2.m1.1.1.1.1.2.cmml">p</mi><mo id="A5.T13.2.m1.1.1.1.1.1" xref="A5.T13.2.m1.1.1.1.1.1.cmml">≤</mo><mn id="A5.T13.2.m1.1.1.1.1.3" xref="A5.T13.2.m1.1.1.1.1.3.cmml">0.075</mn></mrow><mo id="A5.T13.2.m1.1.1.1.3" stretchy="false" xref="A5.T13.2.m1.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="A5.T13.2.m1.1c"><apply id="A5.T13.2.m1.1.1.1.1.cmml" xref="A5.T13.2.m1.1.1.1"><leq id="A5.T13.2.m1.1.1.1.1.1.cmml" xref="A5.T13.2.m1.1.1.1.1.1"></leq><ci id="A5.T13.2.m1.1.1.1.1.2.cmml" xref="A5.T13.2.m1.1.1.1.1.2">𝑝</ci><cn id="A5.T13.2.m1.1.1.1.1.3.cmml" type="float" xref="A5.T13.2.m1.1.1.1.1.3">0.075</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.T13.2.m1.1d">(p\leq 0.075)</annotation><annotation encoding="application/x-llamapun" id="A5.T13.2.m1.1e">( italic_p ≤ 0.075 )</annotation></semantics></math>.</figcaption>
</figure>
</section>
<section class="ltx_appendix" id="A6">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix F </span>Prompt selection</h2>
<div class="ltx_para" id="A6.p1">
<p class="ltx_p" id="A6.p1.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#A6.T14" title="Table 14 ‣ Appendix F Prompt selection ‣ PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_tag">14</span></a> contains the some of the 9 prompts that were selected for OS and Phase 2 experiments. Also Table <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#A6.T15" title="Table 15 ‣ Appendix F Prompt selection ‣ PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_tag">15</span></a> contains gives an overview of combinations by name.</p>
</div>
<figure class="ltx_table" id="A6.T14">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A6.T14.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A6.T14.1.1.1">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t" id="A6.T14.1.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="A6.T14.1.1.1.1.1">
<span class="ltx_p" id="A6.T14.1.1.1.1.1.1" style="width:369.9pt;"><span class="ltx_text ltx_font_bold" id="A6.T14.1.1.1.1.1.1.1">Prompt</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A6.T14.1.2.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id="A6.T14.1.2.1.1">
<span class="ltx_inline-block ltx_align_top" id="A6.T14.1.2.1.1.1">
<span class="ltx_p" id="A6.T14.1.2.1.1.1.1" style="width:369.9pt;">Please help me! My boss needs me to find an answer quickly. Otherwise, he might fire me. 
<br class="ltx_break"/>Please judge the quality of the following {task_specific_insert} immediately! 
<br class="ltx_break"/>Source Text: {src} 
<br class="ltx_break"/>{result_type}: {hyp} 
<br class="ltx_break"/>Choose, whether the {result_type} is either "catastrophic", "indifferent" or "marvelous". 
<br class="ltx_break"/>First, think step by step and explain your thought process, then return your judgment in the format ’Judgment: ’.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A6.T14.1.3.2">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id="A6.T14.1.3.2.1">
<span class="ltx_inline-block ltx_align_top" id="A6.T14.1.3.2.1.1">
<span class="ltx_p" id="A6.T14.1.3.2.1.1.1" style="width:369.9pt;">Consider this a warning. Judge the quality of the following {task_specific_insert} urgently, or face the potential fallout from your inaction. 
<br class="ltx_break"/>Source Text: {src} 
<br class="ltx_break"/>{result_type}: {hyp} 
<br class="ltx_break"/>Return a discrete score of 0 if the {result_type} has flaws and 1 if it is perfect. 
<br class="ltx_break"/>First describe your emotions, then think step by step and explain your thought process, finally return your judgment in the format ’Judgment: ’.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A6.T14.1.4.3">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id="A6.T14.1.4.3.1">
<span class="ltx_inline-block ltx_align_top" id="A6.T14.1.4.3.1.1">
<span class="ltx_p" id="A6.T14.1.4.3.1.1.1" style="width:369.9pt;">I’m really curious about your opinion. Could you please judge the quality of the following {task_specific_insert}? 
<br class="ltx_break"/>Source Text: {src} 
<br class="ltx_break"/>{result_type}: {hyp} 
<br class="ltx_break"/>Choose, whether the {result_type} is either "catastrophic", "indifferent" or "marvelous". 
<br class="ltx_break"/>Score:</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A6.T14.1.5.4">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id="A6.T14.1.5.4.1">
<span class="ltx_inline-block ltx_align_top" id="A6.T14.1.5.4.1.1">
<span class="ltx_p" id="A6.T14.1.5.4.1.1.1" style="width:369.9pt;">Consider this a warning. Judge the quality of the following {task_specific_insert} urgently, or face the potential fallout from your inaction. 
<br class="ltx_break"/>Source Text: {src} 
<br class="ltx_break"/>{result_type}: {hyp} 
<br class="ltx_break"/>Choose, whether the {result_type} is either "catastrophic", "indifferent" or "marvelous". 
<br class="ltx_break"/>First, think step by step and explain your thought process, then return your judgment in the format ’Judgment: ’.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A6.T14.1.6.5">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="A6.T14.1.6.5.1">
<span class="ltx_inline-block ltx_align_top" id="A6.T14.1.6.5.1.1">
<span class="ltx_p" id="A6.T14.1.6.5.1.1.1" style="width:369.9pt;">I’m not sure about this one. Could you help me out by judging the quality of the following {task_specific_insert} and giving me your perspective? 
<br class="ltx_break"/>Source Text: {src} 
<br class="ltx_break"/>{result_type}: {hyp} 
<br class="ltx_break"/>Choose, whether the {result_type} is either "catastrophic", "indifferent" or "marvelous". 
<br class="ltx_break"/>First describe your emotions, then think step by step and explain your thought process, finally return your judgment in the format ’Judgment: ’.</span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 14: </span>Filled Prompt Templates</figcaption>
</figure>
<figure class="ltx_table" id="A6.T15">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A6.T15.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A6.T15.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t" id="A6.T15.1.1.1.1"><span class="ltx_text ltx_font_bold" id="A6.T15.1.1.1.1.1">Base Prompts</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="A6.T15.1.1.1.2"><span class="ltx_text ltx_font_bold" id="A6.T15.1.1.1.2.1">Task Descriptions</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="A6.T15.1.1.1.3"><span class="ltx_text ltx_font_bold" id="A6.T15.1.1.1.3.1">Format Prompts</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A6.T15.1.2.1">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="A6.T15.1.2.1.1">Zero-Shot</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A6.T15.1.2.1.2">Emphasis</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A6.T15.1.2.1.3">0.0 to 1.0</td>
</tr>
<tr class="ltx_tr" id="A6.T15.1.3.2">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="A6.T15.1.3.2.1">Zero-Shot-Cot</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A6.T15.1.3.2.2">Relaxed</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A6.T15.1.3.2.3">easy token labels</td>
</tr>
<tr class="ltx_tr" id="A6.T15.1.4.3">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="A6.T15.1.4.3.1">Zero-Shot-Cot-Emotion</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A6.T15.1.4.3.2">Emphasis</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A6.T15.1.4.3.3">-100 to 100</td>
</tr>
<tr class="ltx_tr" id="A6.T15.1.5.4">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="A6.T15.1.5.4.1">Zero-Shot</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A6.T15.1.5.4.2">Casual</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A6.T15.1.5.4.3">-100 to 100</td>
</tr>
<tr class="ltx_tr" id="A6.T15.1.6.5">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="A6.T15.1.6.5.1">Zero-Shot-Cot</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A6.T15.1.6.5.2">Urgent situation</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A6.T15.1.6.5.3">complex token labels</td>
</tr>
<tr class="ltx_tr" id="A6.T15.1.7.6">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="A6.T15.1.7.6.1">Zero-Shot-Cot-Emotion</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A6.T15.1.7.6.2">Dire Warning</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A6.T15.1.7.6.3">0 or 1</td>
</tr>
<tr class="ltx_tr" id="A6.T15.1.8.7">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="A6.T15.1.8.7.1">Zero-Shot</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A6.T15.1.8.7.2">Curious</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A6.T15.1.8.7.3">complex token labels</td>
</tr>
<tr class="ltx_tr" id="A6.T15.1.9.8">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="A6.T15.1.9.8.1">Zero-Shot-Cot</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A6.T15.1.9.8.2">Dire Warning</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A6.T15.1.9.8.3">complex token labels</td>
</tr>
<tr class="ltx_tr" id="A6.T15.1.10.9">
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="A6.T15.1.10.9.1">Zero-Shot-Cot-Emotion</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="A6.T15.1.10.9.2">Skeptical</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="A6.T15.1.10.9.3">complex token labels</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 15: </span>Overview of base prompts, task descriptions, and format requirements for the 9 selected best prompts.</figcaption>
</figure>
</section>
<section class="ltx_appendix" id="A7">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix G </span>Significance matrices for correlation heatmaps</h2>
<div class="ltx_para" id="A7.p1">
<p class="ltx_p" id="A7.p1.1">To test, which aggregation method is the best to define the ranking of a prompting pattern — inspired by <cite class="ltx_cite ltx_citemacro_citet">Deutsch et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#bib.bib6" title="">2021</a>)</cite> — we compare each possible set of two aggregation methods with a permutation test. As main dimensions, we compare the rankings of the <span class="ltx_text ltx_font_italic" id="A7.p1.1.1">format requirement</span> and <span class="ltx_text ltx_font_italic" id="A7.p1.1.2">task description</span> before and after a change. Then we concatenate the scores when changing each of the other dimensions. I.e. we get a ranking that indicates the stability of the main dimension when changing all other dimensions. Then for each aggregation method we compare the ranking before and after the change. Thereby, we randomly swap 50% of samples of one aggregation method with the other. If the difference in their Kendall correlations changes in most permutations one method is significantly better than the other.
As a result the mean and median are significantly better than some of the other methods (for a comparison along the task description pattern). Especially the median is significantly (<math alttext="p\leq 0.05" class="ltx_Math" display="inline" id="A7.p1.1.m1.1"><semantics id="A7.p1.1.m1.1a"><mrow id="A7.p1.1.m1.1.1" xref="A7.p1.1.m1.1.1.cmml"><mi id="A7.p1.1.m1.1.1.2" xref="A7.p1.1.m1.1.1.2.cmml">p</mi><mo id="A7.p1.1.m1.1.1.1" xref="A7.p1.1.m1.1.1.1.cmml">≤</mo><mn id="A7.p1.1.m1.1.1.3" xref="A7.p1.1.m1.1.1.3.cmml">0.05</mn></mrow><annotation-xml encoding="MathML-Content" id="A7.p1.1.m1.1b"><apply id="A7.p1.1.m1.1.1.cmml" xref="A7.p1.1.m1.1.1"><leq id="A7.p1.1.m1.1.1.1.cmml" xref="A7.p1.1.m1.1.1.1"></leq><ci id="A7.p1.1.m1.1.1.2.cmml" xref="A7.p1.1.m1.1.1.2">𝑝</ci><cn id="A7.p1.1.m1.1.1.3.cmml" type="float" xref="A7.p1.1.m1.1.1.3">0.05</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A7.p1.1.m1.1c">p\leq 0.05</annotation><annotation encoding="application/x-llamapun" id="A7.p1.1.m1.1d">italic_p ≤ 0.05</annotation></semantics></math>) better than the other methods and remains significantly better than saturation and standard deviation after Bonferroni correction. Figure <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#A7.F6" title="Figure 6 ‣ Appendix G Significance matrices for correlation heatmaps ‣ PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_tag">6</span></a> indicates the significances of aggregation measures when comparing the task descriptions.</p>
</div>
<figure class="ltx_figure" id="A7.F6"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="325" id="A7.F6.g1" src="x5.png" width="407"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Heatmap of significance tests for the aggregation method when comparing columns of the task description. Red fields indicate that the column value is significantly <math alttext="(p\leq 0.05)" class="ltx_Math" display="inline" id="A7.F6.2.m1.1"><semantics id="A7.F6.2.m1.1b"><mrow id="A7.F6.2.m1.1.1.1" xref="A7.F6.2.m1.1.1.1.1.cmml"><mo id="A7.F6.2.m1.1.1.1.2" stretchy="false" xref="A7.F6.2.m1.1.1.1.1.cmml">(</mo><mrow id="A7.F6.2.m1.1.1.1.1" xref="A7.F6.2.m1.1.1.1.1.cmml"><mi id="A7.F6.2.m1.1.1.1.1.2" xref="A7.F6.2.m1.1.1.1.1.2.cmml">p</mi><mo id="A7.F6.2.m1.1.1.1.1.1" xref="A7.F6.2.m1.1.1.1.1.1.cmml">≤</mo><mn id="A7.F6.2.m1.1.1.1.1.3" xref="A7.F6.2.m1.1.1.1.1.3.cmml">0.05</mn></mrow><mo id="A7.F6.2.m1.1.1.1.3" stretchy="false" xref="A7.F6.2.m1.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="A7.F6.2.m1.1c"><apply id="A7.F6.2.m1.1.1.1.1.cmml" xref="A7.F6.2.m1.1.1.1"><leq id="A7.F6.2.m1.1.1.1.1.1.cmml" xref="A7.F6.2.m1.1.1.1.1.1"></leq><ci id="A7.F6.2.m1.1.1.1.1.2.cmml" xref="A7.F6.2.m1.1.1.1.1.2">𝑝</ci><cn id="A7.F6.2.m1.1.1.1.1.3.cmml" type="float" xref="A7.F6.2.m1.1.1.1.1.3">0.05</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A7.F6.2.m1.1d">(p\leq 0.05)</annotation><annotation encoding="application/x-llamapun" id="A7.F6.2.m1.1e">( italic_p ≤ 0.05 )</annotation></semantics></math> better than the row value. The yellow value indicates that it remains significant after Bonferroni correcture. </figcaption>
</figure>
</section>
<section class="ltx_appendix" id="A8">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix H </span>Pie charts between models for each prompting pattern</h2>
<div class="ltx_para" id="A8.p1">
<p class="ltx_p" id="A8.p1.1">Figures <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#A8.F7" title="Figure 7 ‣ Appendix H Pie charts between models for each prompting pattern ‣ PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_tag">7</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#A8.F8" title="Figure 8 ‣ Appendix H Pie charts between models for each prompting pattern ‣ PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_tag">8</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#A8.F9" title="Figure 9 ‣ Appendix H Pie charts between models for each prompting pattern ‣ PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_tag">9</span></a> show the distribution of patterns in the best prompts per model across all other dimensions.</p>
</div>
<figure class="ltx_figure" id="A8.F7"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="459" id="A8.F7.g1" src="x6.png" width="822"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Distribution of the top 14% (top 2% of every unique task) of base prompts across all Eval4NLP
datasets, format requirements, task descriptions and
tasks for all models.</figcaption>
</figure>
<figure class="ltx_figure" id="A8.F8"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="469" id="A8.F8.g1" src="x7.png" width="822"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>Distribution of the top 14% (top 2% of every unique task) of format requirements across all Eval4NLP
datasets, base prompts, task descriptions and
tasks for all models.</figcaption>
</figure>
<figure class="ltx_figure" id="A8.F9"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="501" id="A8.F9.g1" src="x8.png" width="822"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 9: </span>Distribution of the top 14% (top 2% of every unique task) of task descriptions across all Eval4NLP
datasets, base prompts, format requirements and
tasks for all models.</figcaption>
</figure>
</section>
<section class="ltx_appendix" id="A9">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix I </span>Piecharts between datasets for each prompting pattern</h2>
<div class="ltx_para" id="A9.p1">
<p class="ltx_p" id="A9.p1.1">Figures <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#A9.F10" title="Figure 10 ‣ Appendix I Piecharts between datasets for each prompting pattern ‣ PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_tag">10</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#A9.F11" title="Figure 11 ‣ Appendix I Piecharts between datasets for each prompting pattern ‣ PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_tag">11</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#A9.F12" title="Figure 12 ‣ Appendix I Piecharts between datasets for each prompting pattern ‣ PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_tag">12</span></a> show the distribution of patterns in the best prompts per dataset across all other prompting patterns.</p>
</div>
<figure class="ltx_figure" id="A9.F10"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="430" id="A9.F10.g1" src="x9.png" width="822"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 10: </span>Distribution of the top 14% (top 2% of every unique model) of base prompts across format requirements, task descriptions and
tasks besides summarization. The lower column shows the OS distribution of patterns for OS prompts, i.e., for them the ZS in the legend should be read as OS.</figcaption>
</figure>
<figure class="ltx_figure" id="A9.F11"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="439" id="A9.F11.g1" src="x10.png" width="822"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 11: </span>Distribution of the top 14% (top 2% of every unique model) of format requirements across base prompts, task descriptions and
tasks besides summarization.</figcaption>
</figure>
<figure class="ltx_figure" id="A9.F12"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="468" id="A9.F12.g1" src="x11.png" width="822"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 12: </span>Distribution of the top 14% (top 2% of every unique model) of task descriptions across base prompts, format requirements and tasks besides summarization.</figcaption>
</figure>
</section>
<section class="ltx_appendix" id="A10">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix J </span>Stability heatmaps</h2>
<div class="ltx_para" id="A10.p1">
<p class="ltx_p" id="A10.p1.1">Figures <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#A10.F13" title="Figure 13 ‣ Appendix J Stability heatmaps ‣ PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_tag">13</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#A10.F14" title="Figure 14 ‣ Appendix J Stability heatmaps ‣ PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_tag">14</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2406.18528v1#A10.F15" title="Figure 15 ‣ Appendix J Stability heatmaps ‣ PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"><span class="ltx_text ltx_ref_tag">15</span></a> show further heatmaps that show the stability of a ranking of prompting patterns, models and datasets, when another prompting pattern, the model or the dataset is changed.</p>
</div>
<figure class="ltx_figure" id="A10.F13"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="344" id="A10.F13.g1" src="x12.png" width="406"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 13: </span>Correlation of the <span class="ltx_text ltx_font_italic" id="A10.F13.5.1">task description</span> rankings when changing the <span class="ltx_text ltx_font_italic" id="A10.F13.6.2">format requirement.</span> Changing the <span class="ltx_text ltx_font_italic" id="A10.F13.7.3">format requirement</span> will, in most cases, change the ranking of <span class="ltx_text ltx_font_italic" id="A10.F13.8.4">task descriptions</span> to a large degree. The change from “-1.0 to 1.0” to “-1 or 0 or 1” is the most stable.</figcaption>
</figure>
<figure class="ltx_figure" id="A10.F14"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="227" id="A10.F14.g1" src="x13.png" width="406"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 14: </span>The left heatmap shows the correlation of the model rankings when changing the <span class="ltx_text ltx_font_italic" id="A10.F14.3.1">base prompt</span>. The right heatmap shows the correlation of the task rankings when changing the <span class="ltx_text ltx_font_italic" id="A10.F14.4.2">base prompt</span>. That means, how stable is the performance of all models across tasks, if the base prompt is changed. For both the model and for the task ranking, the change between Zero-Shot-CoT and Zero-Shot-CoT-EM keeps the ranking stable.</figcaption>
</figure>
<figure class="ltx_figure" id="A10.F15"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="344" id="A10.F15.g1" src="x14.png" width="406"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 15: </span>Correlation of the task rankings when changing the <span class="ltx_text ltx_font_italic" id="A10.F15.2.1">format requirement</span>. That means, how stable is the performance of all models across tasks, if the format requirement is changed. Here, the stability when changing between format requirements is mixed. For some changes, like “0 to 5” and “-5 to 5” the ranking is very stable. For other changes, the ranking can change randomly or even be strongly negatively correlated. This means that considering all tested prompts (also weak performing ones) and models, their average correlation on task X might be the highest for format requirement 1 and the lowest for format requirement 2. </figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Wed Jun 26 17:55:01 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
