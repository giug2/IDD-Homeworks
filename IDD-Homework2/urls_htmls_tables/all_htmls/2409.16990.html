<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Single Image, Any Face: Generalisable 3D Face Generation</title>
<!--Generated on Wed Sep 25 14:51:24 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="3D Head Generation Multi-view Diffusion Novel View Synthesis" lang="en" name="keywords"/>
<base href="/html/2409.16990v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#S1" title="In Single Image, Any Face: Generalisable 3D Face Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#S2" title="In Single Image, Any Face: Generalisable 3D Face Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#S3" title="In Single Image, Any Face: Generalisable 3D Face Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Method</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#S3.SS1" title="In 3 Method â€£ Single Image, Any Face: Generalisable 3D Face Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Preliminaries: 2D Diffusion and 3D Diffusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#S3.SS2" title="In 3 Method â€£ Single Image, Any Face: Generalisable 3D Face Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Gen3D-Face</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#S4" title="In Single Image, Any Face: Generalisable 3D Face Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#S4.SS1" title="In 4 Experiments â€£ Single Image, Any Face: Generalisable 3D Face Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Evaluations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#S4.SS2" title="In 4 Experiments â€£ Single Image, Any Face: Generalisable 3D Face Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Ablation studies</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#S5" title="In Single Image, Any Face: Generalisable 3D Face Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Conclusion</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line"><span class="ltx_note ltx_role_institutetext" id="id1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">institutetext: </span>University of Surrey, United Kingdom
</span></span></span>
<h1 class="ltx_title ltx_title_document">Single Image, Any Face: Generalisable 3D Face Generation</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Wenqing Wang 
</span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Haosen Yang
</span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Josef Kittler
</span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Xiatian Zhu
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id1.id1">The creation of 3D human face avatars from a single unconstrained image is a fundamental task that underlies numerous real-world vision and graphics applications. Despite the significant progress made in generative models, existing methods are either less suited in design for human faces or fail to generalise from the restrictive training domain to unconstrained facial images. To address these limitations, we propose a novel model, <span class="ltx_text ltx_font_bold" id="id1.id1.1">Gen3D-Face</span>, which generates 3D human faces with unconstrained single image input within a multi-view consistent diffusion framework. Given a specific input image, our model first produces multi-view images, followed by neural surface construction. To incorporate face geometry information in a generalisable manner, we utilise input-conditioned mesh estimation instead of ground-truth mesh along with synthetic multi-view training data. Importantly, we introduce a multi-view joint generation scheme to enhance appearance consistency among different views. To the best of our knowledge, this is the first attempt and benchmark for creating photorealistic 3D human face avatars from single images for generic human subject across domains. Extensive experiments demonstrate the superiority of our method over previous alternatives for out-of-domain singe image 3D face generation and top competition for in-domain setting.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Keywords: </h6>3D Head Generation Multi-view Diffusion Novel View Synthesis
</div>
<figure class="ltx_figure" id="S0.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="297" id="S0.F1.1.g1" src="x1.png" width="822"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S0.F1.3.1.1" style="font-size:90%;">Figure 1</span>: </span><span class="ltx_text" id="S0.F1.4.2" style="font-size:90%;">
3D human face avatar from (a) a single unconstrained image by (c) prior art model <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib7" title="">7</a>]</cite> (note newly added hat and clear identity shift), vs. (d) our model.
</span></figcaption>
</figure>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Generating photorealistic 3D face avatars from a single image input benefits a wide range of real applications in computer graphics and computer vision, e.g. video conferencing, virtual modeling, entertainment, augmented and enhanced reality <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib36" title="">36</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib13" title="">13</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib53" title="">53</a>]</cite>. The majority of existing 3D face modelling methods not only need costly per-identity optimisation, but also demand a large amount of input in the form of text <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib64" title="">64</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib17" title="">17</a>]</cite>, and multi-view images or videos <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib21" title="">21</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib60" title="">60</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib69" title="">69</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib39" title="">39</a>]</cite>. Text-guided 3D avatar generation often struggles to ensure authenticity and identity control, as it faces the daunting task of accurately capturing human identity and face appearance in high detail, unlike image/video-based approaches.
On the other hand, the latter typically rely on multiple view calibrated images, making them less useful and applicable in practice as in many situations such input data is just unavailable.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Inspired by the remarkable success of generative diffusion models <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib20" title="">20</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib46" title="">46</a>]</cite> and driven by the aforementioned challenges, <span class="ltx_text ltx_font_italic" id="S1.p2.1.1">single-image 3D face generation</span> has become a trendy topic with the key challenges in figuring out both geometry and appearance information from only a single face image of a generic human identity.
This seemingly impossible task now becomes hopeful for two reasons:
<span class="ltx_text ltx_font_italic" id="S1.p2.1.2">The first</span> lies in the availability of unprecedentedly rich and comprehensive knowledge captured by off-the-shelf generative models, providing a chance of extracting and transferring useful information for particular downstream tasks (human face in this work) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib38" title="">38</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib54" title="">54</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib29" title="">29</a>]</cite>.
For example, Stable Diffusion was trained with a massive (unknown) text-image pairs from the Internet, including a diversity of facial images from a broad range of subjects like the celebrities <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib67" title="">67</a>]</cite>.
<span class="ltx_text ltx_font_italic" id="S1.p2.1.3">The second</span> is the enormous technical advance in multi-view image generation <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib48" title="">48</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib30" title="">30</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib31" title="">31</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib51" title="">51</a>]</cite>, and 3D representation, reconstruction, and generation <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib34" title="">34</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib57" title="">57</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib24" title="">24</a>]</cite>.
Combining these building blocks all together properly could be the basis of plausible solutions to tackling this challenge.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">Building on the pillars discussed above, an intuitive approach is to learn a generic 3D face generation model from a large, diverse collection of data with multi-view images per human identity, so that the model could generalize to generic unseen single face images.
There are some early attempts pursuing this strategy by training on large synthetic
digital avatars created by 3D artists <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib55" title="">55</a>]</cite>.
This however raises a synthetic domain to real domain generalisation challenge,
resulting in unrealistic face generation.
Besides, the collection of human face data is much more restricted, due to both the intrinsic complexity and diversity, as well as the intricate privacy considerations.
As a result, existing 3D face benchmarks are often limited in size and diversity in practice, e.g. containing only a few hundreds identities <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib61" title="">61</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib35" title="">35</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib25" title="">25</a>]</cite>, making them insufficient for model training.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">To mitigate this data scarcity challenge, the latest attempt for single-image 3D face generation leverages the human geometric priors by incorporating ground-truth mesh in multi-view synthesis <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib7" title="">7</a>]</cite>. A promising finding from this work is that properly blending image appearance and meshâ€™s geometric knowledge enables the model to work across different views at good quality.
However, we find that their method suffers from several limitations that significantly hampers its generalisation to unconstrained face images shown in FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#S0.F1" title="Figure 1 â€£ Single Image, Any Face: Generalisable 3D Face Generation"><span class="ltx_text ltx_ref_tag">1</span></a>:
(i) <span class="ltx_text ltx_font_italic" id="S1.p4.1.1">Over reliance on the ground-truth mesh</span>, which is often unavailable in practice;
(ii) <span class="ltx_text ltx_font_italic" id="S1.p4.1.2">Overfitting to the training domain</span> due to the stringent need with training data, thus limited data availability, so that the model just cannot generalise to different unseen styles.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">In this work, to overcome these limitations
we propose a novel diffusion generative approach, <span class="ltx_text ltx_font_bold" id="S1.p5.1.1">Gen3D-Face</span>, for more generalisable 3D face generation using unconstrained single images.
Our model first generates consistent multi-view images and then conducts the neural surface construction. Instead of requiring ground-truth mesh, we exploit input-conditioned mesh estimation for not only mitigating the modelâ€™s over reliance on the geometric prior, but also enabling the model to generalise to typical cases without the ground-truth mesh, and with distinct appearance styles.
To enhance data diversity, we further generate synthetic 3D face images with off-the-shelf model <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib2" title="">2</a>]</cite>.
To improve multi-view consistency, we introduce a multi-view joint generation scheme.</p>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">Our <span class="ltx_text ltx_font_bold" id="S1.p6.1.1">contributions</span> are summarised as follows:
<span class="ltx_text ltx_font_bold" id="S1.p6.1.2">(1)</span> Investigating the under-studied single-image 3D face generation problem with a particular focus on the ability of generalising the model to unconstrained unseen face imagery so that the developed more would be more practically useful and deployable. To the best of our knowledge, this is the very first attempt at tackling this meaningful problem setting in single image 3D face generation.
<span class="ltx_text ltx_font_bold" id="S1.p6.1.3">(2)</span> A novel approach Gen3D-Face characterised by generalisable incorporation of face geometric priors, multi-view joint generation, and joint mining of both real and synthetic 3D face data.
<span class="ltx_text ltx_font_bold" id="S1.p6.1.4">(3)</span> Extensive evaluation on generalised single image 3D face generation demonstrating the superior performance of our model over the state-of-the-art alternatives.</p>
</div>
<figure class="ltx_figure" id="S1.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="350" id="S1.F2.1.g1" src="x2.png" width="747"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S1.F2.30.13.1" style="font-size:90%;">Figure 2</span>: </span><span class="ltx_text ltx_font_bold" id="S1.F2.25.12" style="font-size:90%;">Overview of our Gen3D-Face method<span class="ltx_text ltx_font_medium" id="S1.F2.25.12.12">. It adopts the latent diffusion paradigm involving the learning of multi-step denoising.
Each step denoises <math alttext="N" class="ltx_Math" display="inline" id="S1.F2.14.1.1.m1.1"><semantics id="S1.F2.14.1.1.m1.1b"><mi id="S1.F2.14.1.1.m1.1.1" xref="S1.F2.14.1.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S1.F2.14.1.1.m1.1c"><ci id="S1.F2.14.1.1.m1.1.1.cmml" xref="S1.F2.14.1.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.F2.14.1.1.m1.1d">N</annotation><annotation encoding="application/x-llamapun" id="S1.F2.14.1.1.m1.1e">italic_N</annotation></semantics></math> novel views with condition on a single face image <math alttext="y" class="ltx_Math" display="inline" id="S1.F2.15.2.2.m2.1"><semantics id="S1.F2.15.2.2.m2.1b"><mi id="S1.F2.15.2.2.m2.1.1" xref="S1.F2.15.2.2.m2.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S1.F2.15.2.2.m2.1c"><ci id="S1.F2.15.2.2.m2.1.1.cmml" xref="S1.F2.15.2.2.m2.1.1">ğ‘¦</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.F2.15.2.2.m2.1d">y</annotation><annotation encoding="application/x-llamapun" id="S1.F2.15.2.2.m2.1e">italic_y</annotation></semantics></math> and the mesh <math alttext="\mathbb{M}" class="ltx_Math" display="inline" id="S1.F2.16.3.3.m3.1"><semantics id="S1.F2.16.3.3.m3.1b"><mi id="S1.F2.16.3.3.m3.1.1" xref="S1.F2.16.3.3.m3.1.1.cmml">ğ•„</mi><annotation-xml encoding="MathML-Content" id="S1.F2.16.3.3.m3.1c"><ci id="S1.F2.16.3.3.m3.1.1.cmml" xref="S1.F2.16.3.3.m3.1.1">ğ•„</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.F2.16.3.3.m3.1d">\mathbb{M}</annotation><annotation encoding="application/x-llamapun" id="S1.F2.16.3.3.m3.1e">blackboard_M</annotation></semantics></math> estimated from <math alttext="y" class="ltx_Math" display="inline" id="S1.F2.17.4.4.m4.1"><semantics id="S1.F2.17.4.4.m4.1b"><mi id="S1.F2.17.4.4.m4.1.1" xref="S1.F2.17.4.4.m4.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S1.F2.17.4.4.m4.1c"><ci id="S1.F2.17.4.4.m4.1.1.cmml" xref="S1.F2.17.4.4.m4.1.1">ğ‘¦</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.F2.17.4.4.m4.1d">y</annotation><annotation encoding="application/x-llamapun" id="S1.F2.17.4.4.m4.1e">italic_y</annotation></semantics></math>,
following the process as below:
(a) Using an encoder to integrate the previous stepâ€™s noise multi-view images <math alttext="\mathbf{x}^{(1:N)}_{t}" class="ltx_Math" display="inline" id="S1.F2.18.5.5.m5.1"><semantics id="S1.F2.18.5.5.m5.1b"><msubsup id="S1.F2.18.5.5.m5.1.2" xref="S1.F2.18.5.5.m5.1.2.cmml"><mi id="S1.F2.18.5.5.m5.1.2.2.2" xref="S1.F2.18.5.5.m5.1.2.2.2.cmml">ğ±</mi><mi id="S1.F2.18.5.5.m5.1.2.3" xref="S1.F2.18.5.5.m5.1.2.3.cmml">t</mi><mrow id="S1.F2.18.5.5.m5.1.1.1.1" xref="S1.F2.18.5.5.m5.1.1.1.1.1.cmml"><mo id="S1.F2.18.5.5.m5.1.1.1.1.2" stretchy="false" xref="S1.F2.18.5.5.m5.1.1.1.1.1.cmml">(</mo><mrow id="S1.F2.18.5.5.m5.1.1.1.1.1" xref="S1.F2.18.5.5.m5.1.1.1.1.1.cmml"><mn id="S1.F2.18.5.5.m5.1.1.1.1.1.2" xref="S1.F2.18.5.5.m5.1.1.1.1.1.2.cmml">1</mn><mo id="S1.F2.18.5.5.m5.1.1.1.1.1.1" lspace="0.278em" rspace="0.278em" xref="S1.F2.18.5.5.m5.1.1.1.1.1.1.cmml">:</mo><mi id="S1.F2.18.5.5.m5.1.1.1.1.1.3" xref="S1.F2.18.5.5.m5.1.1.1.1.1.3.cmml">N</mi></mrow><mo id="S1.F2.18.5.5.m5.1.1.1.1.3" stretchy="false" xref="S1.F2.18.5.5.m5.1.1.1.1.1.cmml">)</mo></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S1.F2.18.5.5.m5.1c"><apply id="S1.F2.18.5.5.m5.1.2.cmml" xref="S1.F2.18.5.5.m5.1.2"><csymbol cd="ambiguous" id="S1.F2.18.5.5.m5.1.2.1.cmml" xref="S1.F2.18.5.5.m5.1.2">subscript</csymbol><apply id="S1.F2.18.5.5.m5.1.2.2.cmml" xref="S1.F2.18.5.5.m5.1.2"><csymbol cd="ambiguous" id="S1.F2.18.5.5.m5.1.2.2.1.cmml" xref="S1.F2.18.5.5.m5.1.2">superscript</csymbol><ci id="S1.F2.18.5.5.m5.1.2.2.2.cmml" xref="S1.F2.18.5.5.m5.1.2.2.2">ğ±</ci><apply id="S1.F2.18.5.5.m5.1.1.1.1.1.cmml" xref="S1.F2.18.5.5.m5.1.1.1.1"><ci id="S1.F2.18.5.5.m5.1.1.1.1.1.1.cmml" xref="S1.F2.18.5.5.m5.1.1.1.1.1.1">:</ci><cn id="S1.F2.18.5.5.m5.1.1.1.1.1.2.cmml" type="integer" xref="S1.F2.18.5.5.m5.1.1.1.1.1.2">1</cn><ci id="S1.F2.18.5.5.m5.1.1.1.1.1.3.cmml" xref="S1.F2.18.5.5.m5.1.1.1.1.1.3">ğ‘</ci></apply></apply><ci id="S1.F2.18.5.5.m5.1.2.3.cmml" xref="S1.F2.18.5.5.m5.1.2.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F2.18.5.5.m5.1d">\mathbf{x}^{(1:N)}_{t}</annotation><annotation encoding="application/x-llamapun" id="S1.F2.18.5.5.m5.1e">bold_x start_POSTSUPERSCRIPT ( 1 : italic_N ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> with with camera angles and time embedding;
(b) Interpolating its output with a predefined 3D voxel to obtain the <span class="ltx_text ltx_font_italic" id="S1.F2.25.12.12.1">appearance feature volume</span> <math alttext="F_{a}" class="ltx_Math" display="inline" id="S1.F2.19.6.6.m6.1"><semantics id="S1.F2.19.6.6.m6.1b"><msub id="S1.F2.19.6.6.m6.1.1" xref="S1.F2.19.6.6.m6.1.1.cmml"><mi id="S1.F2.19.6.6.m6.1.1.2" xref="S1.F2.19.6.6.m6.1.1.2.cmml">F</mi><mi id="S1.F2.19.6.6.m6.1.1.3" xref="S1.F2.19.6.6.m6.1.1.3.cmml">a</mi></msub><annotation-xml encoding="MathML-Content" id="S1.F2.19.6.6.m6.1c"><apply id="S1.F2.19.6.6.m6.1.1.cmml" xref="S1.F2.19.6.6.m6.1.1"><csymbol cd="ambiguous" id="S1.F2.19.6.6.m6.1.1.1.cmml" xref="S1.F2.19.6.6.m6.1.1">subscript</csymbol><ci id="S1.F2.19.6.6.m6.1.1.2.cmml" xref="S1.F2.19.6.6.m6.1.1.2">ğ¹</ci><ci id="S1.F2.19.6.6.m6.1.1.3.cmml" xref="S1.F2.19.6.6.m6.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F2.19.6.6.m6.1d">F_{a}</annotation><annotation encoding="application/x-llamapun" id="S1.F2.19.6.6.m6.1e">italic_F start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT</annotation></semantics></math>;
(c) Further combining <math alttext="F_{a}" class="ltx_Math" display="inline" id="S1.F2.20.7.7.m7.1"><semantics id="S1.F2.20.7.7.m7.1b"><msub id="S1.F2.20.7.7.m7.1.1" xref="S1.F2.20.7.7.m7.1.1.cmml"><mi id="S1.F2.20.7.7.m7.1.1.2" xref="S1.F2.20.7.7.m7.1.1.2.cmml">F</mi><mi id="S1.F2.20.7.7.m7.1.1.3" xref="S1.F2.20.7.7.m7.1.1.3.cmml">a</mi></msub><annotation-xml encoding="MathML-Content" id="S1.F2.20.7.7.m7.1c"><apply id="S1.F2.20.7.7.m7.1.1.cmml" xref="S1.F2.20.7.7.m7.1.1"><csymbol cd="ambiguous" id="S1.F2.20.7.7.m7.1.1.1.cmml" xref="S1.F2.20.7.7.m7.1.1">subscript</csymbol><ci id="S1.F2.20.7.7.m7.1.1.2.cmml" xref="S1.F2.20.7.7.m7.1.1.2">ğ¹</ci><ci id="S1.F2.20.7.7.m7.1.1.3.cmml" xref="S1.F2.20.7.7.m7.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F2.20.7.7.m7.1d">F_{a}</annotation><annotation encoding="application/x-llamapun" id="S1.F2.20.7.7.m7.1e">italic_F start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT</annotation></semantics></math> with the geometry prior <math alttext="\mathbb{M}" class="ltx_Math" display="inline" id="S1.F2.21.8.8.m8.1"><semantics id="S1.F2.21.8.8.m8.1b"><mi id="S1.F2.21.8.8.m8.1.1" xref="S1.F2.21.8.8.m8.1.1.cmml">ğ•„</mi><annotation-xml encoding="MathML-Content" id="S1.F2.21.8.8.m8.1c"><ci id="S1.F2.21.8.8.m8.1.1.cmml" xref="S1.F2.21.8.8.m8.1.1">ğ•„</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.F2.21.8.8.m8.1d">\mathbb{M}</annotation><annotation encoding="application/x-llamapun" id="S1.F2.21.8.8.m8.1e">blackboard_M</annotation></semantics></math> to obtain the <span class="ltx_text ltx_font_italic" id="S1.F2.25.12.12.2">hybrid feature volume</span> <math alttext="F_{ag}" class="ltx_Math" display="inline" id="S1.F2.22.9.9.m9.1"><semantics id="S1.F2.22.9.9.m9.1b"><msub id="S1.F2.22.9.9.m9.1.1" xref="S1.F2.22.9.9.m9.1.1.cmml"><mi id="S1.F2.22.9.9.m9.1.1.2" xref="S1.F2.22.9.9.m9.1.1.2.cmml">F</mi><mrow id="S1.F2.22.9.9.m9.1.1.3" xref="S1.F2.22.9.9.m9.1.1.3.cmml"><mi id="S1.F2.22.9.9.m9.1.1.3.2" xref="S1.F2.22.9.9.m9.1.1.3.2.cmml">a</mi><mo id="S1.F2.22.9.9.m9.1.1.3.1" xref="S1.F2.22.9.9.m9.1.1.3.1.cmml">â¢</mo><mi id="S1.F2.22.9.9.m9.1.1.3.3" xref="S1.F2.22.9.9.m9.1.1.3.3.cmml">g</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S1.F2.22.9.9.m9.1c"><apply id="S1.F2.22.9.9.m9.1.1.cmml" xref="S1.F2.22.9.9.m9.1.1"><csymbol cd="ambiguous" id="S1.F2.22.9.9.m9.1.1.1.cmml" xref="S1.F2.22.9.9.m9.1.1">subscript</csymbol><ci id="S1.F2.22.9.9.m9.1.1.2.cmml" xref="S1.F2.22.9.9.m9.1.1.2">ğ¹</ci><apply id="S1.F2.22.9.9.m9.1.1.3.cmml" xref="S1.F2.22.9.9.m9.1.1.3"><times id="S1.F2.22.9.9.m9.1.1.3.1.cmml" xref="S1.F2.22.9.9.m9.1.1.3.1"></times><ci id="S1.F2.22.9.9.m9.1.1.3.2.cmml" xref="S1.F2.22.9.9.m9.1.1.3.2">ğ‘</ci><ci id="S1.F2.22.9.9.m9.1.1.3.3.cmml" xref="S1.F2.22.9.9.m9.1.1.3.3">ğ‘”</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F2.22.9.9.m9.1d">F_{ag}</annotation><annotation encoding="application/x-llamapun" id="S1.F2.22.9.9.m9.1e">italic_F start_POSTSUBSCRIPT italic_a italic_g end_POSTSUBSCRIPT</annotation></semantics></math>;
(d)
Finally obtaining the denoised views <math alttext="\mathbf{x}^{(1:N)}_{t-1}" class="ltx_Math" display="inline" id="S1.F2.23.10.10.m10.1"><semantics id="S1.F2.23.10.10.m10.1b"><msubsup id="S1.F2.23.10.10.m10.1.2" xref="S1.F2.23.10.10.m10.1.2.cmml"><mi id="S1.F2.23.10.10.m10.1.2.2.2" xref="S1.F2.23.10.10.m10.1.2.2.2.cmml">ğ±</mi><mrow id="S1.F2.23.10.10.m10.1.2.3" xref="S1.F2.23.10.10.m10.1.2.3.cmml"><mi id="S1.F2.23.10.10.m10.1.2.3.2" xref="S1.F2.23.10.10.m10.1.2.3.2.cmml">t</mi><mo id="S1.F2.23.10.10.m10.1.2.3.1" xref="S1.F2.23.10.10.m10.1.2.3.1.cmml">âˆ’</mo><mn id="S1.F2.23.10.10.m10.1.2.3.3" xref="S1.F2.23.10.10.m10.1.2.3.3.cmml">1</mn></mrow><mrow id="S1.F2.23.10.10.m10.1.1.1.1" xref="S1.F2.23.10.10.m10.1.1.1.1.1.cmml"><mo id="S1.F2.23.10.10.m10.1.1.1.1.2" stretchy="false" xref="S1.F2.23.10.10.m10.1.1.1.1.1.cmml">(</mo><mrow id="S1.F2.23.10.10.m10.1.1.1.1.1" xref="S1.F2.23.10.10.m10.1.1.1.1.1.cmml"><mn id="S1.F2.23.10.10.m10.1.1.1.1.1.2" xref="S1.F2.23.10.10.m10.1.1.1.1.1.2.cmml">1</mn><mo id="S1.F2.23.10.10.m10.1.1.1.1.1.1" lspace="0.278em" rspace="0.278em" xref="S1.F2.23.10.10.m10.1.1.1.1.1.1.cmml">:</mo><mi id="S1.F2.23.10.10.m10.1.1.1.1.1.3" xref="S1.F2.23.10.10.m10.1.1.1.1.1.3.cmml">N</mi></mrow><mo id="S1.F2.23.10.10.m10.1.1.1.1.3" stretchy="false" xref="S1.F2.23.10.10.m10.1.1.1.1.1.cmml">)</mo></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S1.F2.23.10.10.m10.1c"><apply id="S1.F2.23.10.10.m10.1.2.cmml" xref="S1.F2.23.10.10.m10.1.2"><csymbol cd="ambiguous" id="S1.F2.23.10.10.m10.1.2.1.cmml" xref="S1.F2.23.10.10.m10.1.2">subscript</csymbol><apply id="S1.F2.23.10.10.m10.1.2.2.cmml" xref="S1.F2.23.10.10.m10.1.2"><csymbol cd="ambiguous" id="S1.F2.23.10.10.m10.1.2.2.1.cmml" xref="S1.F2.23.10.10.m10.1.2">superscript</csymbol><ci id="S1.F2.23.10.10.m10.1.2.2.2.cmml" xref="S1.F2.23.10.10.m10.1.2.2.2">ğ±</ci><apply id="S1.F2.23.10.10.m10.1.1.1.1.1.cmml" xref="S1.F2.23.10.10.m10.1.1.1.1"><ci id="S1.F2.23.10.10.m10.1.1.1.1.1.1.cmml" xref="S1.F2.23.10.10.m10.1.1.1.1.1.1">:</ci><cn id="S1.F2.23.10.10.m10.1.1.1.1.1.2.cmml" type="integer" xref="S1.F2.23.10.10.m10.1.1.1.1.1.2">1</cn><ci id="S1.F2.23.10.10.m10.1.1.1.1.1.3.cmml" xref="S1.F2.23.10.10.m10.1.1.1.1.1.3">ğ‘</ci></apply></apply><apply id="S1.F2.23.10.10.m10.1.2.3.cmml" xref="S1.F2.23.10.10.m10.1.2.3"><minus id="S1.F2.23.10.10.m10.1.2.3.1.cmml" xref="S1.F2.23.10.10.m10.1.2.3.1"></minus><ci id="S1.F2.23.10.10.m10.1.2.3.2.cmml" xref="S1.F2.23.10.10.m10.1.2.3.2">ğ‘¡</ci><cn id="S1.F2.23.10.10.m10.1.2.3.3.cmml" type="integer" xref="S1.F2.23.10.10.m10.1.2.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F2.23.10.10.m10.1d">\mathbf{x}^{(1:N)}_{t-1}</annotation><annotation encoding="application/x-llamapun" id="S1.F2.23.10.10.m10.1e">bold_x start_POSTSUPERSCRIPT ( 1 : italic_N ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT</annotation></semantics></math> by injecting <math alttext="F_{ag}" class="ltx_Math" display="inline" id="S1.F2.24.11.11.m11.1"><semantics id="S1.F2.24.11.11.m11.1b"><msub id="S1.F2.24.11.11.m11.1.1" xref="S1.F2.24.11.11.m11.1.1.cmml"><mi id="S1.F2.24.11.11.m11.1.1.2" xref="S1.F2.24.11.11.m11.1.1.2.cmml">F</mi><mrow id="S1.F2.24.11.11.m11.1.1.3" xref="S1.F2.24.11.11.m11.1.1.3.cmml"><mi id="S1.F2.24.11.11.m11.1.1.3.2" xref="S1.F2.24.11.11.m11.1.1.3.2.cmml">a</mi><mo id="S1.F2.24.11.11.m11.1.1.3.1" xref="S1.F2.24.11.11.m11.1.1.3.1.cmml">â¢</mo><mi id="S1.F2.24.11.11.m11.1.1.3.3" xref="S1.F2.24.11.11.m11.1.1.3.3.cmml">g</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S1.F2.24.11.11.m11.1c"><apply id="S1.F2.24.11.11.m11.1.1.cmml" xref="S1.F2.24.11.11.m11.1.1"><csymbol cd="ambiguous" id="S1.F2.24.11.11.m11.1.1.1.cmml" xref="S1.F2.24.11.11.m11.1.1">subscript</csymbol><ci id="S1.F2.24.11.11.m11.1.1.2.cmml" xref="S1.F2.24.11.11.m11.1.1.2">ğ¹</ci><apply id="S1.F2.24.11.11.m11.1.1.3.cmml" xref="S1.F2.24.11.11.m11.1.1.3"><times id="S1.F2.24.11.11.m11.1.1.3.1.cmml" xref="S1.F2.24.11.11.m11.1.1.3.1"></times><ci id="S1.F2.24.11.11.m11.1.1.3.2.cmml" xref="S1.F2.24.11.11.m11.1.1.3.2">ğ‘</ci><ci id="S1.F2.24.11.11.m11.1.1.3.3.cmml" xref="S1.F2.24.11.11.m11.1.1.3.3">ğ‘”</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F2.24.11.11.m11.1d">F_{ag}</annotation><annotation encoding="application/x-llamapun" id="S1.F2.24.11.11.m11.1e">italic_F start_POSTSUBSCRIPT italic_a italic_g end_POSTSUBSCRIPT</annotation></semantics></math> to a light 3D CNN to get view frustum volume <math alttext="F_{vf}" class="ltx_Math" display="inline" id="S1.F2.25.12.12.m12.1"><semantics id="S1.F2.25.12.12.m12.1b"><msub id="S1.F2.25.12.12.m12.1.1" xref="S1.F2.25.12.12.m12.1.1.cmml"><mi id="S1.F2.25.12.12.m12.1.1.2" xref="S1.F2.25.12.12.m12.1.1.2.cmml">F</mi><mrow id="S1.F2.25.12.12.m12.1.1.3" xref="S1.F2.25.12.12.m12.1.1.3.cmml"><mi id="S1.F2.25.12.12.m12.1.1.3.2" xref="S1.F2.25.12.12.m12.1.1.3.2.cmml">v</mi><mo id="S1.F2.25.12.12.m12.1.1.3.1" xref="S1.F2.25.12.12.m12.1.1.3.1.cmml">â¢</mo><mi id="S1.F2.25.12.12.m12.1.1.3.3" xref="S1.F2.25.12.12.m12.1.1.3.3.cmml">f</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S1.F2.25.12.12.m12.1c"><apply id="S1.F2.25.12.12.m12.1.1.cmml" xref="S1.F2.25.12.12.m12.1.1"><csymbol cd="ambiguous" id="S1.F2.25.12.12.m12.1.1.1.cmml" xref="S1.F2.25.12.12.m12.1.1">subscript</csymbol><ci id="S1.F2.25.12.12.m12.1.1.2.cmml" xref="S1.F2.25.12.12.m12.1.1.2">ğ¹</ci><apply id="S1.F2.25.12.12.m12.1.1.3.cmml" xref="S1.F2.25.12.12.m12.1.1.3"><times id="S1.F2.25.12.12.m12.1.1.3.1.cmml" xref="S1.F2.25.12.12.m12.1.1.3.1"></times><ci id="S1.F2.25.12.12.m12.1.1.3.2.cmml" xref="S1.F2.25.12.12.m12.1.1.3.2">ğ‘£</ci><ci id="S1.F2.25.12.12.m12.1.1.3.3.cmml" xref="S1.F2.25.12.12.m12.1.1.3.3">ğ‘“</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F2.25.12.12.m12.1d">F_{vf}</annotation><annotation encoding="application/x-llamapun" id="S1.F2.25.12.12.m12.1e">italic_F start_POSTSUBSCRIPT italic_v italic_f end_POSTSUBSCRIPT</annotation></semantics></math>, which into the diffusion backbone as the condition. </span></span></figcaption>
</figure>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>
<div class="ltx_para ltx_noindent" id="S2.p1">
<p class="ltx_p" id="S2.p1.1"><span class="ltx_text ltx_font_bold" id="S2.p1.1.1">Novel view synthesis</span>
Neural fields <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib34" title="">34</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib21" title="">21</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib59" title="">59</a>]</cite> and 3D Gaussian Splatting <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib24" title="">24</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib66" title="">66</a>]</cite> have emerged as the most effective 3D object and scene representations, capable of producing photorealistic images from arbitrary novel views of a scene. However, the first generation is reconstruction-based, necessitating densely captured views.
To relax this assumption, follow-up approaches <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib63" title="">63</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib44" title="">44</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib22" title="">22</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib50" title="">50</a>]</cite> propose learning-based methods requiring only a few views, by utilising scene priors from other existing datasets <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib63" title="">63</a>]</cite>, or explicitly mapping the input image to one 3D Gaussian per pixel <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib50" title="">50</a>]</cite>.
Commonly, these methods tend to be restricted to reconstructing relatively simple objects, or confined to low-resolution, due to their limited expressive capacity.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.p2">
<p class="ltx_p" id="S2.p2.1"><span class="ltx_text ltx_font_bold" id="S2.p2.1.1">3D avatars from a single image</span>
In addition to reconstruction techniques, various methods have been developed to generate 3D avatars utilising Generative Adversarial Networks (GANs) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib4" title="">4</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib2" title="">2</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib11" title="">11</a>]</cite> or more recently diffusion models <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib20" title="">20</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib46" title="">46</a>]</cite>. 3D-aware GANs learn 3D representation by integrating tri-planes <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib4" title="">4</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib11" title="">11</a>]</cite> or tri-grids <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib2" title="">2</a>]</cite> combined with camera position.
To achieve a single image to 3D avatar generation, typically GAN inversion to fit the input image is required, which is computationally expensive and time-consuming.
Live3D <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib53" title="">53</a>]</cite> train an image-to-triplane encoder to map an unposed image to a canonical triplane 3D representation instead of GAN inversion, while still limited in large output angles.
On the other hand, diffusion methods specifically designed for human avatar suffer from limited training data <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib7" title="">7</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib47" title="">47</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib1" title="">1</a>]</cite>, as a 3D diffusion model is hard to learn from 2D image collections. Therefore, these methods rely on pretrained models <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib46" title="">46</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib29" title="">29</a>]</cite> and incorporate 3D physical constraints <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib32" title="">32</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib28" title="">28</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib61" title="">61</a>]</cite> as prior knowledge. However, their stringent input requirements significantly restrict their ability to generalise across out-of-domain face images and the situations without ground-truth mesh. In this work, we tackle these challenges with proper model design and data synthesis.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.p3">
<p class="ltx_p" id="S2.p3.1"><span class="ltx_text ltx_font_bold" id="S2.p3.1.1">Multi-view diffusion models</span>
Recent works <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib29" title="">29</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib5" title="">5</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib16" title="">16</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib52" title="">52</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib30" title="">30</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib31" title="">31</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib48" title="">48</a>]</cite> extend 2D diffusion models to generate consistent multi-view images from single-view images.
Their success benefits from the existence of large-scale 3D datasets <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib9" title="">9</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib8" title="">8</a>]</cite>.
Expanding this direction, our work focuses on human face avatar generation with special requirement on model generalisation to unconstrained imagery.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.p4">
<p class="ltx_p" id="S2.p4.1"><span class="ltx_text ltx_font_bold" id="S2.p4.1.1">Learning from synthetic data</span>
Photorealistic synthetic data is effective in handling data scarcity
<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib56" title="">56</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib41" title="">41</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib18" title="">18</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib62" title="">62</a>]</cite>. Recent methods have been developed to utilise synthetic data, either explicitly <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib26" title="">26</a>]</cite> or implicitly <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib53" title="">53</a>]</cite>, to enhance performance in generative tasks.
In this work, we extend and validate this generic idea for more challenge single image 3D face generation in unconstrained settings.</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Method</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">Given a single face image <math alttext="y" class="ltx_Math" display="inline" id="S3.p1.1.m1.1"><semantics id="S3.p1.1.m1.1a"><mi id="S3.p1.1.m1.1.1" xref="S3.p1.1.m1.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S3.p1.1.m1.1b"><ci id="S3.p1.1.m1.1.1.cmml" xref="S3.p1.1.m1.1.1">ğ‘¦</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.1.m1.1c">y</annotation><annotation encoding="application/x-llamapun" id="S3.p1.1.m1.1d">italic_y</annotation></semantics></math> as input,
we aim to generate a 3D face avatar for this person.
To that end,
we propose a new latent diffusion approach, <span class="ltx_text ltx_font_bold" id="S3.p1.1.1">Gen3D-Face</span>,
with the architecture depicted in FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#S1.F2" title="Figure 2 â€£ 1 Introduction â€£ Single Image, Any Face: Generalisable 3D Face Generation"><span class="ltx_text ltx_ref_tag">2</span></a>.
It generates multi-view consistent images from the single image,
which can then be fed into existing neural surface construction methods (e.g. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib57" title="">57</a>]</cite>).
For the former, we adopt the off-the-shelf Stable Diffusion <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib46" title="">46</a>]</cite> as the backbone
where the diffusion and denoising take place in a latent feature embedding space (e.g. a pretrained VAE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib43" title="">43</a>]</cite>).
For self-containing, we first brief 2D diffusion and 3D diffusion next.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Preliminaries: 2D Diffusion and 3D Diffusion</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.4">Diffusion models <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib20" title="">20</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib46" title="">46</a>]</cite> aim to gradually generate structured outputs of a target distribution from random noise through learning an iterative denoising model.
Given a noise input <math alttext="x_{t}" class="ltx_Math" display="inline" id="S3.SS1.p1.1.m1.1"><semantics id="S3.SS1.p1.1.m1.1a"><msub id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml"><mi id="S3.SS1.p1.1.m1.1.1.2" xref="S3.SS1.p1.1.m1.1.1.2.cmml">x</mi><mi id="S3.SS1.p1.1.m1.1.1.3" xref="S3.SS1.p1.1.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><apply id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.p1.1.m1.1.1.2.cmml" xref="S3.SS1.p1.1.m1.1.1.2">ğ‘¥</ci><ci id="S3.SS1.p1.1.m1.1.1.3.cmml" xref="S3.SS1.p1.1.m1.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">x_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.1.m1.1d">italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math>, where <math alttext="t\in(0,T)" class="ltx_Math" display="inline" id="S3.SS1.p1.2.m2.2"><semantics id="S3.SS1.p1.2.m2.2a"><mrow id="S3.SS1.p1.2.m2.2.3" xref="S3.SS1.p1.2.m2.2.3.cmml"><mi id="S3.SS1.p1.2.m2.2.3.2" xref="S3.SS1.p1.2.m2.2.3.2.cmml">t</mi><mo id="S3.SS1.p1.2.m2.2.3.1" xref="S3.SS1.p1.2.m2.2.3.1.cmml">âˆˆ</mo><mrow id="S3.SS1.p1.2.m2.2.3.3.2" xref="S3.SS1.p1.2.m2.2.3.3.1.cmml"><mo id="S3.SS1.p1.2.m2.2.3.3.2.1" stretchy="false" xref="S3.SS1.p1.2.m2.2.3.3.1.cmml">(</mo><mn id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml">0</mn><mo id="S3.SS1.p1.2.m2.2.3.3.2.2" xref="S3.SS1.p1.2.m2.2.3.3.1.cmml">,</mo><mi id="S3.SS1.p1.2.m2.2.2" xref="S3.SS1.p1.2.m2.2.2.cmml">T</mi><mo id="S3.SS1.p1.2.m2.2.3.3.2.3" stretchy="false" xref="S3.SS1.p1.2.m2.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.2b"><apply id="S3.SS1.p1.2.m2.2.3.cmml" xref="S3.SS1.p1.2.m2.2.3"><in id="S3.SS1.p1.2.m2.2.3.1.cmml" xref="S3.SS1.p1.2.m2.2.3.1"></in><ci id="S3.SS1.p1.2.m2.2.3.2.cmml" xref="S3.SS1.p1.2.m2.2.3.2">ğ‘¡</ci><interval closure="open" id="S3.SS1.p1.2.m2.2.3.3.1.cmml" xref="S3.SS1.p1.2.m2.2.3.3.2"><cn id="S3.SS1.p1.2.m2.1.1.cmml" type="integer" xref="S3.SS1.p1.2.m2.1.1">0</cn><ci id="S3.SS1.p1.2.m2.2.2.cmml" xref="S3.SS1.p1.2.m2.2.2">ğ‘‡</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.2c">t\in(0,T)</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.2.m2.2d">italic_t âˆˆ ( 0 , italic_T )</annotation></semantics></math> denotes the steps with a total of <math alttext="T" class="ltx_Math" display="inline" id="S3.SS1.p1.3.m3.1"><semantics id="S3.SS1.p1.3.m3.1a"><mi id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><ci id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">T</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.3.m3.1d">italic_T</annotation></semantics></math>,
the model is trained to predict the added noise, with which removed, a less noisy version <math alttext="x_{t-1}" class="ltx_Math" display="inline" id="S3.SS1.p1.4.m4.1"><semantics id="S3.SS1.p1.4.m4.1a"><msub id="S3.SS1.p1.4.m4.1.1" xref="S3.SS1.p1.4.m4.1.1.cmml"><mi id="S3.SS1.p1.4.m4.1.1.2" xref="S3.SS1.p1.4.m4.1.1.2.cmml">x</mi><mrow id="S3.SS1.p1.4.m4.1.1.3" xref="S3.SS1.p1.4.m4.1.1.3.cmml"><mi id="S3.SS1.p1.4.m4.1.1.3.2" xref="S3.SS1.p1.4.m4.1.1.3.2.cmml">t</mi><mo id="S3.SS1.p1.4.m4.1.1.3.1" xref="S3.SS1.p1.4.m4.1.1.3.1.cmml">âˆ’</mo><mn id="S3.SS1.p1.4.m4.1.1.3.3" xref="S3.SS1.p1.4.m4.1.1.3.3.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m4.1b"><apply id="S3.SS1.p1.4.m4.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.4.m4.1.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1">subscript</csymbol><ci id="S3.SS1.p1.4.m4.1.1.2.cmml" xref="S3.SS1.p1.4.m4.1.1.2">ğ‘¥</ci><apply id="S3.SS1.p1.4.m4.1.1.3.cmml" xref="S3.SS1.p1.4.m4.1.1.3"><minus id="S3.SS1.p1.4.m4.1.1.3.1.cmml" xref="S3.SS1.p1.4.m4.1.1.3.1"></minus><ci id="S3.SS1.p1.4.m4.1.1.3.2.cmml" xref="S3.SS1.p1.4.m4.1.1.3.2">ğ‘¡</ci><cn id="S3.SS1.p1.4.m4.1.1.3.3.cmml" type="integer" xref="S3.SS1.p1.4.m4.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m4.1c">x_{t-1}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.4.m4.1d">italic_x start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT</annotation></semantics></math> can be revealed.
Whilst these models can generate novel-view images, it is shown that multi-view consistency is hard to be maintained <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib29" title="">29</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.4">To address this issue, multi-view diffusion has been recently developed <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib30" title="">30</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib48" title="">48</a>]</cite>.
The key idea is to jointly denoise the images for multiple predefined viewpoints with condition on the same input <math alttext="y" class="ltx_Math" display="inline" id="S3.SS1.p2.1.m1.1"><semantics id="S3.SS1.p2.1.m1.1a"><mi id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><ci id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1">ğ‘¦</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">y</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.1.m1.1d">italic_y</annotation></semantics></math>,
so that a conditional joint distribution of all these views <math alttext="p_{\theta}(x^{(1)}_{0},\cdots,x^{(N)}_{0}|y)" class="ltx_Math" display="inline" id="S3.SS1.p2.2.m2.5"><semantics id="S3.SS1.p2.2.m2.5a"><mrow id="S3.SS1.p2.2.m2.5.5" xref="S3.SS1.p2.2.m2.5.5.cmml"><msub id="S3.SS1.p2.2.m2.5.5.4" xref="S3.SS1.p2.2.m2.5.5.4.cmml"><mi id="S3.SS1.p2.2.m2.5.5.4.2" xref="S3.SS1.p2.2.m2.5.5.4.2.cmml">p</mi><mi id="S3.SS1.p2.2.m2.5.5.4.3" xref="S3.SS1.p2.2.m2.5.5.4.3.cmml">Î¸</mi></msub><mo id="S3.SS1.p2.2.m2.5.5.3" xref="S3.SS1.p2.2.m2.5.5.3.cmml">â¢</mo><mrow id="S3.SS1.p2.2.m2.5.5.2.2" xref="S3.SS1.p2.2.m2.5.5.2.3.cmml"><mo id="S3.SS1.p2.2.m2.5.5.2.2.3" stretchy="false" xref="S3.SS1.p2.2.m2.5.5.2.3.cmml">(</mo><msubsup id="S3.SS1.p2.2.m2.4.4.1.1.1" xref="S3.SS1.p2.2.m2.4.4.1.1.1.cmml"><mi id="S3.SS1.p2.2.m2.4.4.1.1.1.2.2" xref="S3.SS1.p2.2.m2.4.4.1.1.1.2.2.cmml">x</mi><mn id="S3.SS1.p2.2.m2.4.4.1.1.1.3" xref="S3.SS1.p2.2.m2.4.4.1.1.1.3.cmml">0</mn><mrow id="S3.SS1.p2.2.m2.1.1.1.3" xref="S3.SS1.p2.2.m2.4.4.1.1.1.cmml"><mo id="S3.SS1.p2.2.m2.1.1.1.3.1" stretchy="false" xref="S3.SS1.p2.2.m2.4.4.1.1.1.cmml">(</mo><mn id="S3.SS1.p2.2.m2.1.1.1.1" xref="S3.SS1.p2.2.m2.1.1.1.1.cmml">1</mn><mo id="S3.SS1.p2.2.m2.1.1.1.3.2" stretchy="false" xref="S3.SS1.p2.2.m2.4.4.1.1.1.cmml">)</mo></mrow></msubsup><mo id="S3.SS1.p2.2.m2.5.5.2.2.4" xref="S3.SS1.p2.2.m2.5.5.2.3.cmml">,</mo><mi id="S3.SS1.p2.2.m2.3.3" mathvariant="normal" xref="S3.SS1.p2.2.m2.3.3.cmml">â‹¯</mi><mo id="S3.SS1.p2.2.m2.5.5.2.2.5" xref="S3.SS1.p2.2.m2.5.5.2.3.cmml">,</mo><mrow id="S3.SS1.p2.2.m2.5.5.2.2.2" xref="S3.SS1.p2.2.m2.5.5.2.2.2.cmml"><msubsup id="S3.SS1.p2.2.m2.5.5.2.2.2.2" xref="S3.SS1.p2.2.m2.5.5.2.2.2.2.cmml"><mi id="S3.SS1.p2.2.m2.5.5.2.2.2.2.2.2" xref="S3.SS1.p2.2.m2.5.5.2.2.2.2.2.2.cmml">x</mi><mn id="S3.SS1.p2.2.m2.5.5.2.2.2.2.3" xref="S3.SS1.p2.2.m2.5.5.2.2.2.2.3.cmml">0</mn><mrow id="S3.SS1.p2.2.m2.2.2.1.3" xref="S3.SS1.p2.2.m2.5.5.2.2.2.2.cmml"><mo id="S3.SS1.p2.2.m2.2.2.1.3.1" stretchy="false" xref="S3.SS1.p2.2.m2.5.5.2.2.2.2.cmml">(</mo><mi id="S3.SS1.p2.2.m2.2.2.1.1" xref="S3.SS1.p2.2.m2.2.2.1.1.cmml">N</mi><mo id="S3.SS1.p2.2.m2.2.2.1.3.2" stretchy="false" xref="S3.SS1.p2.2.m2.5.5.2.2.2.2.cmml">)</mo></mrow></msubsup><mo fence="false" id="S3.SS1.p2.2.m2.5.5.2.2.2.1" xref="S3.SS1.p2.2.m2.5.5.2.2.2.1.cmml">|</mo><mi id="S3.SS1.p2.2.m2.5.5.2.2.2.3" xref="S3.SS1.p2.2.m2.5.5.2.2.2.3.cmml">y</mi></mrow><mo id="S3.SS1.p2.2.m2.5.5.2.2.6" stretchy="false" xref="S3.SS1.p2.2.m2.5.5.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.5b"><apply id="S3.SS1.p2.2.m2.5.5.cmml" xref="S3.SS1.p2.2.m2.5.5"><times id="S3.SS1.p2.2.m2.5.5.3.cmml" xref="S3.SS1.p2.2.m2.5.5.3"></times><apply id="S3.SS1.p2.2.m2.5.5.4.cmml" xref="S3.SS1.p2.2.m2.5.5.4"><csymbol cd="ambiguous" id="S3.SS1.p2.2.m2.5.5.4.1.cmml" xref="S3.SS1.p2.2.m2.5.5.4">subscript</csymbol><ci id="S3.SS1.p2.2.m2.5.5.4.2.cmml" xref="S3.SS1.p2.2.m2.5.5.4.2">ğ‘</ci><ci id="S3.SS1.p2.2.m2.5.5.4.3.cmml" xref="S3.SS1.p2.2.m2.5.5.4.3">ğœƒ</ci></apply><vector id="S3.SS1.p2.2.m2.5.5.2.3.cmml" xref="S3.SS1.p2.2.m2.5.5.2.2"><apply id="S3.SS1.p2.2.m2.4.4.1.1.1.cmml" xref="S3.SS1.p2.2.m2.4.4.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.2.m2.4.4.1.1.1.1.cmml" xref="S3.SS1.p2.2.m2.4.4.1.1.1">subscript</csymbol><apply id="S3.SS1.p2.2.m2.4.4.1.1.1.2.cmml" xref="S3.SS1.p2.2.m2.4.4.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.2.m2.4.4.1.1.1.2.1.cmml" xref="S3.SS1.p2.2.m2.4.4.1.1.1">superscript</csymbol><ci id="S3.SS1.p2.2.m2.4.4.1.1.1.2.2.cmml" xref="S3.SS1.p2.2.m2.4.4.1.1.1.2.2">ğ‘¥</ci><cn id="S3.SS1.p2.2.m2.1.1.1.1.cmml" type="integer" xref="S3.SS1.p2.2.m2.1.1.1.1">1</cn></apply><cn id="S3.SS1.p2.2.m2.4.4.1.1.1.3.cmml" type="integer" xref="S3.SS1.p2.2.m2.4.4.1.1.1.3">0</cn></apply><ci id="S3.SS1.p2.2.m2.3.3.cmml" xref="S3.SS1.p2.2.m2.3.3">â‹¯</ci><apply id="S3.SS1.p2.2.m2.5.5.2.2.2.cmml" xref="S3.SS1.p2.2.m2.5.5.2.2.2"><csymbol cd="latexml" id="S3.SS1.p2.2.m2.5.5.2.2.2.1.cmml" xref="S3.SS1.p2.2.m2.5.5.2.2.2.1">conditional</csymbol><apply id="S3.SS1.p2.2.m2.5.5.2.2.2.2.cmml" xref="S3.SS1.p2.2.m2.5.5.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p2.2.m2.5.5.2.2.2.2.1.cmml" xref="S3.SS1.p2.2.m2.5.5.2.2.2.2">subscript</csymbol><apply id="S3.SS1.p2.2.m2.5.5.2.2.2.2.2.cmml" xref="S3.SS1.p2.2.m2.5.5.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p2.2.m2.5.5.2.2.2.2.2.1.cmml" xref="S3.SS1.p2.2.m2.5.5.2.2.2.2">superscript</csymbol><ci id="S3.SS1.p2.2.m2.5.5.2.2.2.2.2.2.cmml" xref="S3.SS1.p2.2.m2.5.5.2.2.2.2.2.2">ğ‘¥</ci><ci id="S3.SS1.p2.2.m2.2.2.1.1.cmml" xref="S3.SS1.p2.2.m2.2.2.1.1">ğ‘</ci></apply><cn id="S3.SS1.p2.2.m2.5.5.2.2.2.2.3.cmml" type="integer" xref="S3.SS1.p2.2.m2.5.5.2.2.2.2.3">0</cn></apply><ci id="S3.SS1.p2.2.m2.5.5.2.2.2.3.cmml" xref="S3.SS1.p2.2.m2.5.5.2.2.2.3">ğ‘¦</ci></apply></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.5c">p_{\theta}(x^{(1)}_{0},\cdots,x^{(N)}_{0}|y)</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.2.m2.5d">italic_p start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT ( italic_x start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , â‹¯ , italic_x start_POSTSUPERSCRIPT ( italic_N ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT | italic_y )</annotation></semantics></math> can be learned instead, where <math alttext="N" class="ltx_Math" display="inline" id="S3.SS1.p2.3.m3.1"><semantics id="S3.SS1.p2.3.m3.1a"><mi id="S3.SS1.p2.3.m3.1.1" xref="S3.SS1.p2.3.m3.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.3.m3.1b"><ci id="S3.SS1.p2.3.m3.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.3.m3.1c">N</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.3.m3.1d">italic_N</annotation></semantics></math> specifies the view number.
The forward process adds noise to every viewpoint independently at time <math alttext="t" class="ltx_Math" display="inline" id="S3.SS1.p2.4.m4.1"><semantics id="S3.SS1.p2.4.m4.1a"><mi id="S3.SS1.p2.4.m4.1.1" xref="S3.SS1.p2.4.m4.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.4.m4.1b"><ci id="S3.SS1.p2.4.m4.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.4.m4.1c">t</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.4.m4.1d">italic_t</annotation></semantics></math>, and the reverse process is constructed as:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="p_{\theta}(\mathbf{x}_{0:T}^{(1:N)})=p(\mathbf{x}^{(1:N)}_{T})\prod_{t=1}^{T}%
\prod_{n=1}^{N}p_{\theta}(\mathbf{x}^{(n)}_{t-1}|\mathbf{x}^{(1:N)}_{t})," class="ltx_Math" display="block" id="S3.E1.m1.5"><semantics id="S3.E1.m1.5a"><mrow id="S3.E1.m1.5.5.1" xref="S3.E1.m1.5.5.1.1.cmml"><mrow id="S3.E1.m1.5.5.1.1" xref="S3.E1.m1.5.5.1.1.cmml"><mrow id="S3.E1.m1.5.5.1.1.1" xref="S3.E1.m1.5.5.1.1.1.cmml"><msub id="S3.E1.m1.5.5.1.1.1.3" xref="S3.E1.m1.5.5.1.1.1.3.cmml"><mi id="S3.E1.m1.5.5.1.1.1.3.2" xref="S3.E1.m1.5.5.1.1.1.3.2.cmml">p</mi><mi id="S3.E1.m1.5.5.1.1.1.3.3" xref="S3.E1.m1.5.5.1.1.1.3.3.cmml">Î¸</mi></msub><mo id="S3.E1.m1.5.5.1.1.1.2" xref="S3.E1.m1.5.5.1.1.1.2.cmml">â¢</mo><mrow id="S3.E1.m1.5.5.1.1.1.1.1" xref="S3.E1.m1.5.5.1.1.1.1.1.1.cmml"><mo id="S3.E1.m1.5.5.1.1.1.1.1.2" stretchy="false" xref="S3.E1.m1.5.5.1.1.1.1.1.1.cmml">(</mo><msubsup id="S3.E1.m1.5.5.1.1.1.1.1.1" xref="S3.E1.m1.5.5.1.1.1.1.1.1.cmml"><mi id="S3.E1.m1.5.5.1.1.1.1.1.1.2.2" xref="S3.E1.m1.5.5.1.1.1.1.1.1.2.2.cmml">ğ±</mi><mrow id="S3.E1.m1.5.5.1.1.1.1.1.1.2.3" xref="S3.E1.m1.5.5.1.1.1.1.1.1.2.3.cmml"><mn id="S3.E1.m1.5.5.1.1.1.1.1.1.2.3.2" xref="S3.E1.m1.5.5.1.1.1.1.1.1.2.3.2.cmml">0</mn><mo id="S3.E1.m1.5.5.1.1.1.1.1.1.2.3.1" lspace="0.278em" rspace="0.278em" xref="S3.E1.m1.5.5.1.1.1.1.1.1.2.3.1.cmml">:</mo><mi id="S3.E1.m1.5.5.1.1.1.1.1.1.2.3.3" xref="S3.E1.m1.5.5.1.1.1.1.1.1.2.3.3.cmml">T</mi></mrow><mrow id="S3.E1.m1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.cmml"><mo id="S3.E1.m1.1.1.1.1.2" stretchy="false" xref="S3.E1.m1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E1.m1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.cmml"><mn id="S3.E1.m1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.2.cmml">1</mn><mo id="S3.E1.m1.1.1.1.1.1.1" lspace="0.278em" rspace="0.278em" xref="S3.E1.m1.1.1.1.1.1.1.cmml">:</mo><mi id="S3.E1.m1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.3.cmml">N</mi></mrow><mo id="S3.E1.m1.1.1.1.1.3" stretchy="false" xref="S3.E1.m1.1.1.1.1.1.cmml">)</mo></mrow></msubsup><mo id="S3.E1.m1.5.5.1.1.1.1.1.3" stretchy="false" xref="S3.E1.m1.5.5.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.5.5.1.1.4" xref="S3.E1.m1.5.5.1.1.4.cmml">=</mo><mrow id="S3.E1.m1.5.5.1.1.3" xref="S3.E1.m1.5.5.1.1.3.cmml"><mi id="S3.E1.m1.5.5.1.1.3.4" xref="S3.E1.m1.5.5.1.1.3.4.cmml">p</mi><mo id="S3.E1.m1.5.5.1.1.3.3" xref="S3.E1.m1.5.5.1.1.3.3.cmml">â¢</mo><mrow id="S3.E1.m1.5.5.1.1.2.1.1" xref="S3.E1.m1.5.5.1.1.2.1.1.1.cmml"><mo id="S3.E1.m1.5.5.1.1.2.1.1.2" stretchy="false" xref="S3.E1.m1.5.5.1.1.2.1.1.1.cmml">(</mo><msubsup id="S3.E1.m1.5.5.1.1.2.1.1.1" xref="S3.E1.m1.5.5.1.1.2.1.1.1.cmml"><mi id="S3.E1.m1.5.5.1.1.2.1.1.1.2.2" xref="S3.E1.m1.5.5.1.1.2.1.1.1.2.2.cmml">ğ±</mi><mi id="S3.E1.m1.5.5.1.1.2.1.1.1.3" xref="S3.E1.m1.5.5.1.1.2.1.1.1.3.cmml">T</mi><mrow id="S3.E1.m1.2.2.1.1" xref="S3.E1.m1.2.2.1.1.1.cmml"><mo id="S3.E1.m1.2.2.1.1.2" stretchy="false" xref="S3.E1.m1.2.2.1.1.1.cmml">(</mo><mrow id="S3.E1.m1.2.2.1.1.1" xref="S3.E1.m1.2.2.1.1.1.cmml"><mn id="S3.E1.m1.2.2.1.1.1.2" xref="S3.E1.m1.2.2.1.1.1.2.cmml">1</mn><mo id="S3.E1.m1.2.2.1.1.1.1" lspace="0.278em" rspace="0.278em" xref="S3.E1.m1.2.2.1.1.1.1.cmml">:</mo><mi id="S3.E1.m1.2.2.1.1.1.3" xref="S3.E1.m1.2.2.1.1.1.3.cmml">N</mi></mrow><mo id="S3.E1.m1.2.2.1.1.3" stretchy="false" xref="S3.E1.m1.2.2.1.1.1.cmml">)</mo></mrow></msubsup><mo id="S3.E1.m1.5.5.1.1.2.1.1.3" stretchy="false" xref="S3.E1.m1.5.5.1.1.2.1.1.1.cmml">)</mo></mrow><mo id="S3.E1.m1.5.5.1.1.3.3a" xref="S3.E1.m1.5.5.1.1.3.3.cmml">â¢</mo><mrow id="S3.E1.m1.5.5.1.1.3.2" xref="S3.E1.m1.5.5.1.1.3.2.cmml"><munderover id="S3.E1.m1.5.5.1.1.3.2.2" xref="S3.E1.m1.5.5.1.1.3.2.2.cmml"><mo id="S3.E1.m1.5.5.1.1.3.2.2.2.2" movablelimits="false" rspace="0em" xref="S3.E1.m1.5.5.1.1.3.2.2.2.2.cmml">âˆ</mo><mrow id="S3.E1.m1.5.5.1.1.3.2.2.2.3" xref="S3.E1.m1.5.5.1.1.3.2.2.2.3.cmml"><mi id="S3.E1.m1.5.5.1.1.3.2.2.2.3.2" xref="S3.E1.m1.5.5.1.1.3.2.2.2.3.2.cmml">t</mi><mo id="S3.E1.m1.5.5.1.1.3.2.2.2.3.1" xref="S3.E1.m1.5.5.1.1.3.2.2.2.3.1.cmml">=</mo><mn id="S3.E1.m1.5.5.1.1.3.2.2.2.3.3" xref="S3.E1.m1.5.5.1.1.3.2.2.2.3.3.cmml">1</mn></mrow><mi id="S3.E1.m1.5.5.1.1.3.2.2.3" xref="S3.E1.m1.5.5.1.1.3.2.2.3.cmml">T</mi></munderover><mrow id="S3.E1.m1.5.5.1.1.3.2.1" xref="S3.E1.m1.5.5.1.1.3.2.1.cmml"><munderover id="S3.E1.m1.5.5.1.1.3.2.1.2" xref="S3.E1.m1.5.5.1.1.3.2.1.2.cmml"><mo id="S3.E1.m1.5.5.1.1.3.2.1.2.2.2" movablelimits="false" xref="S3.E1.m1.5.5.1.1.3.2.1.2.2.2.cmml">âˆ</mo><mrow id="S3.E1.m1.5.5.1.1.3.2.1.2.2.3" xref="S3.E1.m1.5.5.1.1.3.2.1.2.2.3.cmml"><mi id="S3.E1.m1.5.5.1.1.3.2.1.2.2.3.2" xref="S3.E1.m1.5.5.1.1.3.2.1.2.2.3.2.cmml">n</mi><mo id="S3.E1.m1.5.5.1.1.3.2.1.2.2.3.1" xref="S3.E1.m1.5.5.1.1.3.2.1.2.2.3.1.cmml">=</mo><mn id="S3.E1.m1.5.5.1.1.3.2.1.2.2.3.3" xref="S3.E1.m1.5.5.1.1.3.2.1.2.2.3.3.cmml">1</mn></mrow><mi id="S3.E1.m1.5.5.1.1.3.2.1.2.3" xref="S3.E1.m1.5.5.1.1.3.2.1.2.3.cmml">N</mi></munderover><mrow id="S3.E1.m1.5.5.1.1.3.2.1.1" xref="S3.E1.m1.5.5.1.1.3.2.1.1.cmml"><msub id="S3.E1.m1.5.5.1.1.3.2.1.1.3" xref="S3.E1.m1.5.5.1.1.3.2.1.1.3.cmml"><mi id="S3.E1.m1.5.5.1.1.3.2.1.1.3.2" xref="S3.E1.m1.5.5.1.1.3.2.1.1.3.2.cmml">p</mi><mi id="S3.E1.m1.5.5.1.1.3.2.1.1.3.3" xref="S3.E1.m1.5.5.1.1.3.2.1.1.3.3.cmml">Î¸</mi></msub><mo id="S3.E1.m1.5.5.1.1.3.2.1.1.2" xref="S3.E1.m1.5.5.1.1.3.2.1.1.2.cmml">â¢</mo><mrow id="S3.E1.m1.5.5.1.1.3.2.1.1.1.1" xref="S3.E1.m1.5.5.1.1.3.2.1.1.1.1.1.cmml"><mo id="S3.E1.m1.5.5.1.1.3.2.1.1.1.1.2" stretchy="false" xref="S3.E1.m1.5.5.1.1.3.2.1.1.1.1.1.cmml">(</mo><mrow id="S3.E1.m1.5.5.1.1.3.2.1.1.1.1.1" xref="S3.E1.m1.5.5.1.1.3.2.1.1.1.1.1.cmml"><msubsup id="S3.E1.m1.5.5.1.1.3.2.1.1.1.1.1.2" xref="S3.E1.m1.5.5.1.1.3.2.1.1.1.1.1.2.cmml"><mi id="S3.E1.m1.5.5.1.1.3.2.1.1.1.1.1.2.2.2" xref="S3.E1.m1.5.5.1.1.3.2.1.1.1.1.1.2.2.2.cmml">ğ±</mi><mrow id="S3.E1.m1.5.5.1.1.3.2.1.1.1.1.1.2.3" xref="S3.E1.m1.5.5.1.1.3.2.1.1.1.1.1.2.3.cmml"><mi id="S3.E1.m1.5.5.1.1.3.2.1.1.1.1.1.2.3.2" xref="S3.E1.m1.5.5.1.1.3.2.1.1.1.1.1.2.3.2.cmml">t</mi><mo id="S3.E1.m1.5.5.1.1.3.2.1.1.1.1.1.2.3.1" xref="S3.E1.m1.5.5.1.1.3.2.1.1.1.1.1.2.3.1.cmml">âˆ’</mo><mn id="S3.E1.m1.5.5.1.1.3.2.1.1.1.1.1.2.3.3" xref="S3.E1.m1.5.5.1.1.3.2.1.1.1.1.1.2.3.3.cmml">1</mn></mrow><mrow id="S3.E1.m1.3.3.1.3" xref="S3.E1.m1.5.5.1.1.3.2.1.1.1.1.1.2.cmml"><mo id="S3.E1.m1.3.3.1.3.1" stretchy="false" xref="S3.E1.m1.5.5.1.1.3.2.1.1.1.1.1.2.cmml">(</mo><mi id="S3.E1.m1.3.3.1.1" xref="S3.E1.m1.3.3.1.1.cmml">n</mi><mo id="S3.E1.m1.3.3.1.3.2" stretchy="false" xref="S3.E1.m1.5.5.1.1.3.2.1.1.1.1.1.2.cmml">)</mo></mrow></msubsup><mo fence="false" id="S3.E1.m1.5.5.1.1.3.2.1.1.1.1.1.1" xref="S3.E1.m1.5.5.1.1.3.2.1.1.1.1.1.1.cmml">|</mo><msubsup id="S3.E1.m1.5.5.1.1.3.2.1.1.1.1.1.3" xref="S3.E1.m1.5.5.1.1.3.2.1.1.1.1.1.3.cmml"><mi id="S3.E1.m1.5.5.1.1.3.2.1.1.1.1.1.3.2.2" xref="S3.E1.m1.5.5.1.1.3.2.1.1.1.1.1.3.2.2.cmml">ğ±</mi><mi id="S3.E1.m1.5.5.1.1.3.2.1.1.1.1.1.3.3" xref="S3.E1.m1.5.5.1.1.3.2.1.1.1.1.1.3.3.cmml">t</mi><mrow id="S3.E1.m1.4.4.1.1" xref="S3.E1.m1.4.4.1.1.1.cmml"><mo id="S3.E1.m1.4.4.1.1.2" stretchy="false" xref="S3.E1.m1.4.4.1.1.1.cmml">(</mo><mrow id="S3.E1.m1.4.4.1.1.1" xref="S3.E1.m1.4.4.1.1.1.cmml"><mn id="S3.E1.m1.4.4.1.1.1.2" xref="S3.E1.m1.4.4.1.1.1.2.cmml">1</mn><mo id="S3.E1.m1.4.4.1.1.1.1" lspace="0.278em" rspace="0.278em" xref="S3.E1.m1.4.4.1.1.1.1.cmml">:</mo><mi id="S3.E1.m1.4.4.1.1.1.3" xref="S3.E1.m1.4.4.1.1.1.3.cmml">N</mi></mrow><mo id="S3.E1.m1.4.4.1.1.3" stretchy="false" xref="S3.E1.m1.4.4.1.1.1.cmml">)</mo></mrow></msubsup></mrow><mo id="S3.E1.m1.5.5.1.1.3.2.1.1.1.1.3" stretchy="false" xref="S3.E1.m1.5.5.1.1.3.2.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow></mrow></mrow><mo id="S3.E1.m1.5.5.1.2" xref="S3.E1.m1.5.5.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.5b"><apply id="S3.E1.m1.5.5.1.1.cmml" xref="S3.E1.m1.5.5.1"><eq id="S3.E1.m1.5.5.1.1.4.cmml" xref="S3.E1.m1.5.5.1.1.4"></eq><apply id="S3.E1.m1.5.5.1.1.1.cmml" xref="S3.E1.m1.5.5.1.1.1"><times id="S3.E1.m1.5.5.1.1.1.2.cmml" xref="S3.E1.m1.5.5.1.1.1.2"></times><apply id="S3.E1.m1.5.5.1.1.1.3.cmml" xref="S3.E1.m1.5.5.1.1.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.5.5.1.1.1.3.1.cmml" xref="S3.E1.m1.5.5.1.1.1.3">subscript</csymbol><ci id="S3.E1.m1.5.5.1.1.1.3.2.cmml" xref="S3.E1.m1.5.5.1.1.1.3.2">ğ‘</ci><ci id="S3.E1.m1.5.5.1.1.1.3.3.cmml" xref="S3.E1.m1.5.5.1.1.1.3.3">ğœƒ</ci></apply><apply id="S3.E1.m1.5.5.1.1.1.1.1.1.cmml" xref="S3.E1.m1.5.5.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.5.5.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.5.5.1.1.1.1.1">superscript</csymbol><apply id="S3.E1.m1.5.5.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.5.5.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.5.5.1.1.1.1.1.1.2.1.cmml" xref="S3.E1.m1.5.5.1.1.1.1.1">subscript</csymbol><ci id="S3.E1.m1.5.5.1.1.1.1.1.1.2.2.cmml" xref="S3.E1.m1.5.5.1.1.1.1.1.1.2.2">ğ±</ci><apply id="S3.E1.m1.5.5.1.1.1.1.1.1.2.3.cmml" xref="S3.E1.m1.5.5.1.1.1.1.1.1.2.3"><ci id="S3.E1.m1.5.5.1.1.1.1.1.1.2.3.1.cmml" xref="S3.E1.m1.5.5.1.1.1.1.1.1.2.3.1">:</ci><cn id="S3.E1.m1.5.5.1.1.1.1.1.1.2.3.2.cmml" type="integer" xref="S3.E1.m1.5.5.1.1.1.1.1.1.2.3.2">0</cn><ci id="S3.E1.m1.5.5.1.1.1.1.1.1.2.3.3.cmml" xref="S3.E1.m1.5.5.1.1.1.1.1.1.2.3.3">ğ‘‡</ci></apply></apply><apply id="S3.E1.m1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1"><ci id="S3.E1.m1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1">:</ci><cn id="S3.E1.m1.1.1.1.1.1.2.cmml" type="integer" xref="S3.E1.m1.1.1.1.1.1.2">1</cn><ci id="S3.E1.m1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.1.3">ğ‘</ci></apply></apply></apply><apply id="S3.E1.m1.5.5.1.1.3.cmml" xref="S3.E1.m1.5.5.1.1.3"><times id="S3.E1.m1.5.5.1.1.3.3.cmml" xref="S3.E1.m1.5.5.1.1.3.3"></times><ci id="S3.E1.m1.5.5.1.1.3.4.cmml" xref="S3.E1.m1.5.5.1.1.3.4">ğ‘</ci><apply id="S3.E1.m1.5.5.1.1.2.1.1.1.cmml" xref="S3.E1.m1.5.5.1.1.2.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.5.5.1.1.2.1.1.1.1.cmml" xref="S3.E1.m1.5.5.1.1.2.1.1">subscript</csymbol><apply id="S3.E1.m1.5.5.1.1.2.1.1.1.2.cmml" xref="S3.E1.m1.5.5.1.1.2.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.5.5.1.1.2.1.1.1.2.1.cmml" xref="S3.E1.m1.5.5.1.1.2.1.1">superscript</csymbol><ci id="S3.E1.m1.5.5.1.1.2.1.1.1.2.2.cmml" xref="S3.E1.m1.5.5.1.1.2.1.1.1.2.2">ğ±</ci><apply id="S3.E1.m1.2.2.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1"><ci id="S3.E1.m1.2.2.1.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1">:</ci><cn id="S3.E1.m1.2.2.1.1.1.2.cmml" type="integer" xref="S3.E1.m1.2.2.1.1.1.2">1</cn><ci id="S3.E1.m1.2.2.1.1.1.3.cmml" xref="S3.E1.m1.2.2.1.1.1.3">ğ‘</ci></apply></apply><ci id="S3.E1.m1.5.5.1.1.2.1.1.1.3.cmml" xref="S3.E1.m1.5.5.1.1.2.1.1.1.3">ğ‘‡</ci></apply><apply id="S3.E1.m1.5.5.1.1.3.2.cmml" xref="S3.E1.m1.5.5.1.1.3.2"><apply id="S3.E1.m1.5.5.1.1.3.2.2.cmml" xref="S3.E1.m1.5.5.1.1.3.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.5.5.1.1.3.2.2.1.cmml" xref="S3.E1.m1.5.5.1.1.3.2.2">superscript</csymbol><apply id="S3.E1.m1.5.5.1.1.3.2.2.2.cmml" xref="S3.E1.m1.5.5.1.1.3.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.5.5.1.1.3.2.2.2.1.cmml" xref="S3.E1.m1.5.5.1.1.3.2.2">subscript</csymbol><csymbol cd="latexml" id="S3.E1.m1.5.5.1.1.3.2.2.2.2.cmml" xref="S3.E1.m1.5.5.1.1.3.2.2.2.2">product</csymbol><apply id="S3.E1.m1.5.5.1.1.3.2.2.2.3.cmml" xref="S3.E1.m1.5.5.1.1.3.2.2.2.3"><eq id="S3.E1.m1.5.5.1.1.3.2.2.2.3.1.cmml" xref="S3.E1.m1.5.5.1.1.3.2.2.2.3.1"></eq><ci id="S3.E1.m1.5.5.1.1.3.2.2.2.3.2.cmml" xref="S3.E1.m1.5.5.1.1.3.2.2.2.3.2">ğ‘¡</ci><cn id="S3.E1.m1.5.5.1.1.3.2.2.2.3.3.cmml" type="integer" xref="S3.E1.m1.5.5.1.1.3.2.2.2.3.3">1</cn></apply></apply><ci id="S3.E1.m1.5.5.1.1.3.2.2.3.cmml" xref="S3.E1.m1.5.5.1.1.3.2.2.3">ğ‘‡</ci></apply><apply id="S3.E1.m1.5.5.1.1.3.2.1.cmml" xref="S3.E1.m1.5.5.1.1.3.2.1"><apply id="S3.E1.m1.5.5.1.1.3.2.1.2.cmml" xref="S3.E1.m1.5.5.1.1.3.2.1.2"><csymbol cd="ambiguous" id="S3.E1.m1.5.5.1.1.3.2.1.2.1.cmml" xref="S3.E1.m1.5.5.1.1.3.2.1.2">superscript</csymbol><apply id="S3.E1.m1.5.5.1.1.3.2.1.2.2.cmml" xref="S3.E1.m1.5.5.1.1.3.2.1.2"><csymbol cd="ambiguous" id="S3.E1.m1.5.5.1.1.3.2.1.2.2.1.cmml" xref="S3.E1.m1.5.5.1.1.3.2.1.2">subscript</csymbol><csymbol cd="latexml" id="S3.E1.m1.5.5.1.1.3.2.1.2.2.2.cmml" xref="S3.E1.m1.5.5.1.1.3.2.1.2.2.2">product</csymbol><apply id="S3.E1.m1.5.5.1.1.3.2.1.2.2.3.cmml" xref="S3.E1.m1.5.5.1.1.3.2.1.2.2.3"><eq id="S3.E1.m1.5.5.1.1.3.2.1.2.2.3.1.cmml" xref="S3.E1.m1.5.5.1.1.3.2.1.2.2.3.1"></eq><ci id="S3.E1.m1.5.5.1.1.3.2.1.2.2.3.2.cmml" xref="S3.E1.m1.5.5.1.1.3.2.1.2.2.3.2">ğ‘›</ci><cn id="S3.E1.m1.5.5.1.1.3.2.1.2.2.3.3.cmml" type="integer" xref="S3.E1.m1.5.5.1.1.3.2.1.2.2.3.3">1</cn></apply></apply><ci id="S3.E1.m1.5.5.1.1.3.2.1.2.3.cmml" xref="S3.E1.m1.5.5.1.1.3.2.1.2.3">ğ‘</ci></apply><apply id="S3.E1.m1.5.5.1.1.3.2.1.1.cmml" xref="S3.E1.m1.5.5.1.1.3.2.1.1"><times id="S3.E1.m1.5.5.1.1.3.2.1.1.2.cmml" xref="S3.E1.m1.5.5.1.1.3.2.1.1.2"></times><apply id="S3.E1.m1.5.5.1.1.3.2.1.1.3.cmml" xref="S3.E1.m1.5.5.1.1.3.2.1.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.5.5.1.1.3.2.1.1.3.1.cmml" xref="S3.E1.m1.5.5.1.1.3.2.1.1.3">subscript</csymbol><ci id="S3.E1.m1.5.5.1.1.3.2.1.1.3.2.cmml" xref="S3.E1.m1.5.5.1.1.3.2.1.1.3.2">ğ‘</ci><ci id="S3.E1.m1.5.5.1.1.3.2.1.1.3.3.cmml" xref="S3.E1.m1.5.5.1.1.3.2.1.1.3.3">ğœƒ</ci></apply><apply id="S3.E1.m1.5.5.1.1.3.2.1.1.1.1.1.cmml" xref="S3.E1.m1.5.5.1.1.3.2.1.1.1.1"><csymbol cd="latexml" id="S3.E1.m1.5.5.1.1.3.2.1.1.1.1.1.1.cmml" xref="S3.E1.m1.5.5.1.1.3.2.1.1.1.1.1.1">conditional</csymbol><apply id="S3.E1.m1.5.5.1.1.3.2.1.1.1.1.1.2.cmml" xref="S3.E1.m1.5.5.1.1.3.2.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E1.m1.5.5.1.1.3.2.1.1.1.1.1.2.1.cmml" xref="S3.E1.m1.5.5.1.1.3.2.1.1.1.1.1.2">subscript</csymbol><apply id="S3.E1.m1.5.5.1.1.3.2.1.1.1.1.1.2.2.cmml" xref="S3.E1.m1.5.5.1.1.3.2.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E1.m1.5.5.1.1.3.2.1.1.1.1.1.2.2.1.cmml" xref="S3.E1.m1.5.5.1.1.3.2.1.1.1.1.1.2">superscript</csymbol><ci id="S3.E1.m1.5.5.1.1.3.2.1.1.1.1.1.2.2.2.cmml" xref="S3.E1.m1.5.5.1.1.3.2.1.1.1.1.1.2.2.2">ğ±</ci><ci id="S3.E1.m1.3.3.1.1.cmml" xref="S3.E1.m1.3.3.1.1">ğ‘›</ci></apply><apply id="S3.E1.m1.5.5.1.1.3.2.1.1.1.1.1.2.3.cmml" xref="S3.E1.m1.5.5.1.1.3.2.1.1.1.1.1.2.3"><minus id="S3.E1.m1.5.5.1.1.3.2.1.1.1.1.1.2.3.1.cmml" xref="S3.E1.m1.5.5.1.1.3.2.1.1.1.1.1.2.3.1"></minus><ci id="S3.E1.m1.5.5.1.1.3.2.1.1.1.1.1.2.3.2.cmml" xref="S3.E1.m1.5.5.1.1.3.2.1.1.1.1.1.2.3.2">ğ‘¡</ci><cn id="S3.E1.m1.5.5.1.1.3.2.1.1.1.1.1.2.3.3.cmml" type="integer" xref="S3.E1.m1.5.5.1.1.3.2.1.1.1.1.1.2.3.3">1</cn></apply></apply><apply id="S3.E1.m1.5.5.1.1.3.2.1.1.1.1.1.3.cmml" xref="S3.E1.m1.5.5.1.1.3.2.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.5.5.1.1.3.2.1.1.1.1.1.3.1.cmml" xref="S3.E1.m1.5.5.1.1.3.2.1.1.1.1.1.3">subscript</csymbol><apply id="S3.E1.m1.5.5.1.1.3.2.1.1.1.1.1.3.2.cmml" xref="S3.E1.m1.5.5.1.1.3.2.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.5.5.1.1.3.2.1.1.1.1.1.3.2.1.cmml" xref="S3.E1.m1.5.5.1.1.3.2.1.1.1.1.1.3">superscript</csymbol><ci id="S3.E1.m1.5.5.1.1.3.2.1.1.1.1.1.3.2.2.cmml" xref="S3.E1.m1.5.5.1.1.3.2.1.1.1.1.1.3.2.2">ğ±</ci><apply id="S3.E1.m1.4.4.1.1.1.cmml" xref="S3.E1.m1.4.4.1.1"><ci id="S3.E1.m1.4.4.1.1.1.1.cmml" xref="S3.E1.m1.4.4.1.1.1.1">:</ci><cn id="S3.E1.m1.4.4.1.1.1.2.cmml" type="integer" xref="S3.E1.m1.4.4.1.1.1.2">1</cn><ci id="S3.E1.m1.4.4.1.1.1.3.cmml" xref="S3.E1.m1.4.4.1.1.1.3">ğ‘</ci></apply></apply><ci id="S3.E1.m1.5.5.1.1.3.2.1.1.1.1.1.3.3.cmml" xref="S3.E1.m1.5.5.1.1.3.2.1.1.1.1.1.3.3">ğ‘¡</ci></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.5c">p_{\theta}(\mathbf{x}_{0:T}^{(1:N)})=p(\mathbf{x}^{(1:N)}_{T})\prod_{t=1}^{T}%
\prod_{n=1}^{N}p_{\theta}(\mathbf{x}^{(n)}_{t-1}|\mathbf{x}^{(1:N)}_{t}),</annotation><annotation encoding="application/x-llamapun" id="S3.E1.m1.5d">italic_p start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT ( bold_x start_POSTSUBSCRIPT 0 : italic_T end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( 1 : italic_N ) end_POSTSUPERSCRIPT ) = italic_p ( bold_x start_POSTSUPERSCRIPT ( 1 : italic_N ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT ) âˆ start_POSTSUBSCRIPT italic_t = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT âˆ start_POSTSUBSCRIPT italic_n = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT italic_p start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT ( bold_x start_POSTSUPERSCRIPT ( italic_n ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT | bold_x start_POSTSUPERSCRIPT ( 1 : italic_N ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS1.p2.13">where the per-step per-view denoising is formulated by a Gaussian distribution:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="p_{\theta}(\mathbf{x}^{(n)}_{t-1}|\mathbf{x}^{(1:N)}_{t})=\mathcal{N}(\mathbf{%
x}^{(n)}_{t-1};\mathbf{\mu}^{(n)}_{\theta}(\mathbf{x}^{(1:N)}_{t},t),\sigma^{2%
}_{t}\mathbf{I})," class="ltx_Math" display="block" id="S3.E2.m1.7"><semantics id="S3.E2.m1.7a"><mrow id="S3.E2.m1.7.7.1" xref="S3.E2.m1.7.7.1.1.cmml"><mrow id="S3.E2.m1.7.7.1.1" xref="S3.E2.m1.7.7.1.1.cmml"><mrow id="S3.E2.m1.7.7.1.1.1" xref="S3.E2.m1.7.7.1.1.1.cmml"><msub id="S3.E2.m1.7.7.1.1.1.3" xref="S3.E2.m1.7.7.1.1.1.3.cmml"><mi id="S3.E2.m1.7.7.1.1.1.3.2" xref="S3.E2.m1.7.7.1.1.1.3.2.cmml">p</mi><mi id="S3.E2.m1.7.7.1.1.1.3.3" xref="S3.E2.m1.7.7.1.1.1.3.3.cmml">Î¸</mi></msub><mo id="S3.E2.m1.7.7.1.1.1.2" xref="S3.E2.m1.7.7.1.1.1.2.cmml">â¢</mo><mrow id="S3.E2.m1.7.7.1.1.1.1.1" xref="S3.E2.m1.7.7.1.1.1.1.1.1.cmml"><mo id="S3.E2.m1.7.7.1.1.1.1.1.2" stretchy="false" xref="S3.E2.m1.7.7.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E2.m1.7.7.1.1.1.1.1.1" xref="S3.E2.m1.7.7.1.1.1.1.1.1.cmml"><msubsup id="S3.E2.m1.7.7.1.1.1.1.1.1.2" xref="S3.E2.m1.7.7.1.1.1.1.1.1.2.cmml"><mi id="S3.E2.m1.7.7.1.1.1.1.1.1.2.2.2" xref="S3.E2.m1.7.7.1.1.1.1.1.1.2.2.2.cmml">ğ±</mi><mrow id="S3.E2.m1.7.7.1.1.1.1.1.1.2.3" xref="S3.E2.m1.7.7.1.1.1.1.1.1.2.3.cmml"><mi id="S3.E2.m1.7.7.1.1.1.1.1.1.2.3.2" xref="S3.E2.m1.7.7.1.1.1.1.1.1.2.3.2.cmml">t</mi><mo id="S3.E2.m1.7.7.1.1.1.1.1.1.2.3.1" xref="S3.E2.m1.7.7.1.1.1.1.1.1.2.3.1.cmml">âˆ’</mo><mn id="S3.E2.m1.7.7.1.1.1.1.1.1.2.3.3" xref="S3.E2.m1.7.7.1.1.1.1.1.1.2.3.3.cmml">1</mn></mrow><mrow id="S3.E2.m1.1.1.1.3" xref="S3.E2.m1.7.7.1.1.1.1.1.1.2.cmml"><mo id="S3.E2.m1.1.1.1.3.1" stretchy="false" xref="S3.E2.m1.7.7.1.1.1.1.1.1.2.cmml">(</mo><mi id="S3.E2.m1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.cmml">n</mi><mo id="S3.E2.m1.1.1.1.3.2" stretchy="false" xref="S3.E2.m1.7.7.1.1.1.1.1.1.2.cmml">)</mo></mrow></msubsup><mo fence="false" id="S3.E2.m1.7.7.1.1.1.1.1.1.1" xref="S3.E2.m1.7.7.1.1.1.1.1.1.1.cmml">|</mo><msubsup id="S3.E2.m1.7.7.1.1.1.1.1.1.3" xref="S3.E2.m1.7.7.1.1.1.1.1.1.3.cmml"><mi id="S3.E2.m1.7.7.1.1.1.1.1.1.3.2.2" xref="S3.E2.m1.7.7.1.1.1.1.1.1.3.2.2.cmml">ğ±</mi><mi id="S3.E2.m1.7.7.1.1.1.1.1.1.3.3" xref="S3.E2.m1.7.7.1.1.1.1.1.1.3.3.cmml">t</mi><mrow id="S3.E2.m1.2.2.1.1" xref="S3.E2.m1.2.2.1.1.1.cmml"><mo id="S3.E2.m1.2.2.1.1.2" stretchy="false" xref="S3.E2.m1.2.2.1.1.1.cmml">(</mo><mrow id="S3.E2.m1.2.2.1.1.1" xref="S3.E2.m1.2.2.1.1.1.cmml"><mn id="S3.E2.m1.2.2.1.1.1.2" xref="S3.E2.m1.2.2.1.1.1.2.cmml">1</mn><mo id="S3.E2.m1.2.2.1.1.1.1" lspace="0.278em" rspace="0.278em" xref="S3.E2.m1.2.2.1.1.1.1.cmml">:</mo><mi id="S3.E2.m1.2.2.1.1.1.3" xref="S3.E2.m1.2.2.1.1.1.3.cmml">N</mi></mrow><mo id="S3.E2.m1.2.2.1.1.3" stretchy="false" xref="S3.E2.m1.2.2.1.1.1.cmml">)</mo></mrow></msubsup></mrow><mo id="S3.E2.m1.7.7.1.1.1.1.1.3" stretchy="false" xref="S3.E2.m1.7.7.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E2.m1.7.7.1.1.5" xref="S3.E2.m1.7.7.1.1.5.cmml">=</mo><mrow id="S3.E2.m1.7.7.1.1.4" xref="S3.E2.m1.7.7.1.1.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.7.7.1.1.4.5" xref="S3.E2.m1.7.7.1.1.4.5.cmml">ğ’©</mi><mo id="S3.E2.m1.7.7.1.1.4.4" xref="S3.E2.m1.7.7.1.1.4.4.cmml">â¢</mo><mrow id="S3.E2.m1.7.7.1.1.4.3.3" xref="S3.E2.m1.7.7.1.1.4.3.4.cmml"><mo id="S3.E2.m1.7.7.1.1.4.3.3.4" stretchy="false" xref="S3.E2.m1.7.7.1.1.4.3.4.cmml">(</mo><msubsup id="S3.E2.m1.7.7.1.1.2.1.1.1" xref="S3.E2.m1.7.7.1.1.2.1.1.1.cmml"><mi id="S3.E2.m1.7.7.1.1.2.1.1.1.2.2" xref="S3.E2.m1.7.7.1.1.2.1.1.1.2.2.cmml">ğ±</mi><mrow id="S3.E2.m1.7.7.1.1.2.1.1.1.3" xref="S3.E2.m1.7.7.1.1.2.1.1.1.3.cmml"><mi id="S3.E2.m1.7.7.1.1.2.1.1.1.3.2" xref="S3.E2.m1.7.7.1.1.2.1.1.1.3.2.cmml">t</mi><mo id="S3.E2.m1.7.7.1.1.2.1.1.1.3.1" xref="S3.E2.m1.7.7.1.1.2.1.1.1.3.1.cmml">âˆ’</mo><mn id="S3.E2.m1.7.7.1.1.2.1.1.1.3.3" xref="S3.E2.m1.7.7.1.1.2.1.1.1.3.3.cmml">1</mn></mrow><mrow id="S3.E2.m1.3.3.1.3" xref="S3.E2.m1.7.7.1.1.2.1.1.1.cmml"><mo id="S3.E2.m1.3.3.1.3.1" stretchy="false" xref="S3.E2.m1.7.7.1.1.2.1.1.1.cmml">(</mo><mi id="S3.E2.m1.3.3.1.1" xref="S3.E2.m1.3.3.1.1.cmml">n</mi><mo id="S3.E2.m1.3.3.1.3.2" stretchy="false" xref="S3.E2.m1.7.7.1.1.2.1.1.1.cmml">)</mo></mrow></msubsup><mo id="S3.E2.m1.7.7.1.1.4.3.3.5" xref="S3.E2.m1.7.7.1.1.4.3.4.cmml">;</mo><mrow id="S3.E2.m1.7.7.1.1.3.2.2.2" xref="S3.E2.m1.7.7.1.1.3.2.2.2.cmml"><msubsup id="S3.E2.m1.7.7.1.1.3.2.2.2.3" xref="S3.E2.m1.7.7.1.1.3.2.2.2.3.cmml"><mi id="S3.E2.m1.7.7.1.1.3.2.2.2.3.2.2" xref="S3.E2.m1.7.7.1.1.3.2.2.2.3.2.2.cmml">Î¼</mi><mi id="S3.E2.m1.7.7.1.1.3.2.2.2.3.3" xref="S3.E2.m1.7.7.1.1.3.2.2.2.3.3.cmml">Î¸</mi><mrow id="S3.E2.m1.4.4.1.3" xref="S3.E2.m1.7.7.1.1.3.2.2.2.3.cmml"><mo id="S3.E2.m1.4.4.1.3.1" stretchy="false" xref="S3.E2.m1.7.7.1.1.3.2.2.2.3.cmml">(</mo><mi id="S3.E2.m1.4.4.1.1" xref="S3.E2.m1.4.4.1.1.cmml">n</mi><mo id="S3.E2.m1.4.4.1.3.2" stretchy="false" xref="S3.E2.m1.7.7.1.1.3.2.2.2.3.cmml">)</mo></mrow></msubsup><mo id="S3.E2.m1.7.7.1.1.3.2.2.2.2" xref="S3.E2.m1.7.7.1.1.3.2.2.2.2.cmml">â¢</mo><mrow id="S3.E2.m1.7.7.1.1.3.2.2.2.1.1" xref="S3.E2.m1.7.7.1.1.3.2.2.2.1.2.cmml"><mo id="S3.E2.m1.7.7.1.1.3.2.2.2.1.1.2" stretchy="false" xref="S3.E2.m1.7.7.1.1.3.2.2.2.1.2.cmml">(</mo><msubsup id="S3.E2.m1.7.7.1.1.3.2.2.2.1.1.1" xref="S3.E2.m1.7.7.1.1.3.2.2.2.1.1.1.cmml"><mi id="S3.E2.m1.7.7.1.1.3.2.2.2.1.1.1.2.2" xref="S3.E2.m1.7.7.1.1.3.2.2.2.1.1.1.2.2.cmml">ğ±</mi><mi id="S3.E2.m1.7.7.1.1.3.2.2.2.1.1.1.3" xref="S3.E2.m1.7.7.1.1.3.2.2.2.1.1.1.3.cmml">t</mi><mrow id="S3.E2.m1.5.5.1.1" xref="S3.E2.m1.5.5.1.1.1.cmml"><mo id="S3.E2.m1.5.5.1.1.2" stretchy="false" xref="S3.E2.m1.5.5.1.1.1.cmml">(</mo><mrow id="S3.E2.m1.5.5.1.1.1" xref="S3.E2.m1.5.5.1.1.1.cmml"><mn id="S3.E2.m1.5.5.1.1.1.2" xref="S3.E2.m1.5.5.1.1.1.2.cmml">1</mn><mo id="S3.E2.m1.5.5.1.1.1.1" lspace="0.278em" rspace="0.278em" xref="S3.E2.m1.5.5.1.1.1.1.cmml">:</mo><mi id="S3.E2.m1.5.5.1.1.1.3" xref="S3.E2.m1.5.5.1.1.1.3.cmml">N</mi></mrow><mo id="S3.E2.m1.5.5.1.1.3" stretchy="false" xref="S3.E2.m1.5.5.1.1.1.cmml">)</mo></mrow></msubsup><mo id="S3.E2.m1.7.7.1.1.3.2.2.2.1.1.3" xref="S3.E2.m1.7.7.1.1.3.2.2.2.1.2.cmml">,</mo><mi id="S3.E2.m1.6.6" xref="S3.E2.m1.6.6.cmml">t</mi><mo id="S3.E2.m1.7.7.1.1.3.2.2.2.1.1.4" stretchy="false" xref="S3.E2.m1.7.7.1.1.3.2.2.2.1.2.cmml">)</mo></mrow></mrow><mo id="S3.E2.m1.7.7.1.1.4.3.3.6" xref="S3.E2.m1.7.7.1.1.4.3.4.cmml">,</mo><mrow id="S3.E2.m1.7.7.1.1.4.3.3.3" xref="S3.E2.m1.7.7.1.1.4.3.3.3.cmml"><msubsup id="S3.E2.m1.7.7.1.1.4.3.3.3.2" xref="S3.E2.m1.7.7.1.1.4.3.3.3.2.cmml"><mi id="S3.E2.m1.7.7.1.1.4.3.3.3.2.2.2" xref="S3.E2.m1.7.7.1.1.4.3.3.3.2.2.2.cmml">Ïƒ</mi><mi id="S3.E2.m1.7.7.1.1.4.3.3.3.2.3" xref="S3.E2.m1.7.7.1.1.4.3.3.3.2.3.cmml">t</mi><mn id="S3.E2.m1.7.7.1.1.4.3.3.3.2.2.3" xref="S3.E2.m1.7.7.1.1.4.3.3.3.2.2.3.cmml">2</mn></msubsup><mo id="S3.E2.m1.7.7.1.1.4.3.3.3.1" xref="S3.E2.m1.7.7.1.1.4.3.3.3.1.cmml">â¢</mo><mi id="S3.E2.m1.7.7.1.1.4.3.3.3.3" xref="S3.E2.m1.7.7.1.1.4.3.3.3.3.cmml">ğˆ</mi></mrow><mo id="S3.E2.m1.7.7.1.1.4.3.3.7" stretchy="false" xref="S3.E2.m1.7.7.1.1.4.3.4.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E2.m1.7.7.1.2" xref="S3.E2.m1.7.7.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.7b"><apply id="S3.E2.m1.7.7.1.1.cmml" xref="S3.E2.m1.7.7.1"><eq id="S3.E2.m1.7.7.1.1.5.cmml" xref="S3.E2.m1.7.7.1.1.5"></eq><apply id="S3.E2.m1.7.7.1.1.1.cmml" xref="S3.E2.m1.7.7.1.1.1"><times id="S3.E2.m1.7.7.1.1.1.2.cmml" xref="S3.E2.m1.7.7.1.1.1.2"></times><apply id="S3.E2.m1.7.7.1.1.1.3.cmml" xref="S3.E2.m1.7.7.1.1.1.3"><csymbol cd="ambiguous" id="S3.E2.m1.7.7.1.1.1.3.1.cmml" xref="S3.E2.m1.7.7.1.1.1.3">subscript</csymbol><ci id="S3.E2.m1.7.7.1.1.1.3.2.cmml" xref="S3.E2.m1.7.7.1.1.1.3.2">ğ‘</ci><ci id="S3.E2.m1.7.7.1.1.1.3.3.cmml" xref="S3.E2.m1.7.7.1.1.1.3.3">ğœƒ</ci></apply><apply id="S3.E2.m1.7.7.1.1.1.1.1.1.cmml" xref="S3.E2.m1.7.7.1.1.1.1.1"><csymbol cd="latexml" id="S3.E2.m1.7.7.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.7.7.1.1.1.1.1.1.1">conditional</csymbol><apply id="S3.E2.m1.7.7.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.7.7.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.7.7.1.1.1.1.1.1.2.1.cmml" xref="S3.E2.m1.7.7.1.1.1.1.1.1.2">subscript</csymbol><apply id="S3.E2.m1.7.7.1.1.1.1.1.1.2.2.cmml" xref="S3.E2.m1.7.7.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.7.7.1.1.1.1.1.1.2.2.1.cmml" xref="S3.E2.m1.7.7.1.1.1.1.1.1.2">superscript</csymbol><ci id="S3.E2.m1.7.7.1.1.1.1.1.1.2.2.2.cmml" xref="S3.E2.m1.7.7.1.1.1.1.1.1.2.2.2">ğ±</ci><ci id="S3.E2.m1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1">ğ‘›</ci></apply><apply id="S3.E2.m1.7.7.1.1.1.1.1.1.2.3.cmml" xref="S3.E2.m1.7.7.1.1.1.1.1.1.2.3"><minus id="S3.E2.m1.7.7.1.1.1.1.1.1.2.3.1.cmml" xref="S3.E2.m1.7.7.1.1.1.1.1.1.2.3.1"></minus><ci id="S3.E2.m1.7.7.1.1.1.1.1.1.2.3.2.cmml" xref="S3.E2.m1.7.7.1.1.1.1.1.1.2.3.2">ğ‘¡</ci><cn id="S3.E2.m1.7.7.1.1.1.1.1.1.2.3.3.cmml" type="integer" xref="S3.E2.m1.7.7.1.1.1.1.1.1.2.3.3">1</cn></apply></apply><apply id="S3.E2.m1.7.7.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.7.7.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E2.m1.7.7.1.1.1.1.1.1.3.1.cmml" xref="S3.E2.m1.7.7.1.1.1.1.1.1.3">subscript</csymbol><apply id="S3.E2.m1.7.7.1.1.1.1.1.1.3.2.cmml" xref="S3.E2.m1.7.7.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E2.m1.7.7.1.1.1.1.1.1.3.2.1.cmml" xref="S3.E2.m1.7.7.1.1.1.1.1.1.3">superscript</csymbol><ci id="S3.E2.m1.7.7.1.1.1.1.1.1.3.2.2.cmml" xref="S3.E2.m1.7.7.1.1.1.1.1.1.3.2.2">ğ±</ci><apply id="S3.E2.m1.2.2.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1"><ci id="S3.E2.m1.2.2.1.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1">:</ci><cn id="S3.E2.m1.2.2.1.1.1.2.cmml" type="integer" xref="S3.E2.m1.2.2.1.1.1.2">1</cn><ci id="S3.E2.m1.2.2.1.1.1.3.cmml" xref="S3.E2.m1.2.2.1.1.1.3">ğ‘</ci></apply></apply><ci id="S3.E2.m1.7.7.1.1.1.1.1.1.3.3.cmml" xref="S3.E2.m1.7.7.1.1.1.1.1.1.3.3">ğ‘¡</ci></apply></apply></apply><apply id="S3.E2.m1.7.7.1.1.4.cmml" xref="S3.E2.m1.7.7.1.1.4"><times id="S3.E2.m1.7.7.1.1.4.4.cmml" xref="S3.E2.m1.7.7.1.1.4.4"></times><ci id="S3.E2.m1.7.7.1.1.4.5.cmml" xref="S3.E2.m1.7.7.1.1.4.5">ğ’©</ci><list id="S3.E2.m1.7.7.1.1.4.3.4.cmml" xref="S3.E2.m1.7.7.1.1.4.3.3"><apply id="S3.E2.m1.7.7.1.1.2.1.1.1.cmml" xref="S3.E2.m1.7.7.1.1.2.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.7.7.1.1.2.1.1.1.1.cmml" xref="S3.E2.m1.7.7.1.1.2.1.1.1">subscript</csymbol><apply id="S3.E2.m1.7.7.1.1.2.1.1.1.2.cmml" xref="S3.E2.m1.7.7.1.1.2.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.7.7.1.1.2.1.1.1.2.1.cmml" xref="S3.E2.m1.7.7.1.1.2.1.1.1">superscript</csymbol><ci id="S3.E2.m1.7.7.1.1.2.1.1.1.2.2.cmml" xref="S3.E2.m1.7.7.1.1.2.1.1.1.2.2">ğ±</ci><ci id="S3.E2.m1.3.3.1.1.cmml" xref="S3.E2.m1.3.3.1.1">ğ‘›</ci></apply><apply id="S3.E2.m1.7.7.1.1.2.1.1.1.3.cmml" xref="S3.E2.m1.7.7.1.1.2.1.1.1.3"><minus id="S3.E2.m1.7.7.1.1.2.1.1.1.3.1.cmml" xref="S3.E2.m1.7.7.1.1.2.1.1.1.3.1"></minus><ci id="S3.E2.m1.7.7.1.1.2.1.1.1.3.2.cmml" xref="S3.E2.m1.7.7.1.1.2.1.1.1.3.2">ğ‘¡</ci><cn id="S3.E2.m1.7.7.1.1.2.1.1.1.3.3.cmml" type="integer" xref="S3.E2.m1.7.7.1.1.2.1.1.1.3.3">1</cn></apply></apply><apply id="S3.E2.m1.7.7.1.1.3.2.2.2.cmml" xref="S3.E2.m1.7.7.1.1.3.2.2.2"><times id="S3.E2.m1.7.7.1.1.3.2.2.2.2.cmml" xref="S3.E2.m1.7.7.1.1.3.2.2.2.2"></times><apply id="S3.E2.m1.7.7.1.1.3.2.2.2.3.cmml" xref="S3.E2.m1.7.7.1.1.3.2.2.2.3"><csymbol cd="ambiguous" id="S3.E2.m1.7.7.1.1.3.2.2.2.3.1.cmml" xref="S3.E2.m1.7.7.1.1.3.2.2.2.3">subscript</csymbol><apply id="S3.E2.m1.7.7.1.1.3.2.2.2.3.2.cmml" xref="S3.E2.m1.7.7.1.1.3.2.2.2.3"><csymbol cd="ambiguous" id="S3.E2.m1.7.7.1.1.3.2.2.2.3.2.1.cmml" xref="S3.E2.m1.7.7.1.1.3.2.2.2.3">superscript</csymbol><ci id="S3.E2.m1.7.7.1.1.3.2.2.2.3.2.2.cmml" xref="S3.E2.m1.7.7.1.1.3.2.2.2.3.2.2">ğœ‡</ci><ci id="S3.E2.m1.4.4.1.1.cmml" xref="S3.E2.m1.4.4.1.1">ğ‘›</ci></apply><ci id="S3.E2.m1.7.7.1.1.3.2.2.2.3.3.cmml" xref="S3.E2.m1.7.7.1.1.3.2.2.2.3.3">ğœƒ</ci></apply><interval closure="open" id="S3.E2.m1.7.7.1.1.3.2.2.2.1.2.cmml" xref="S3.E2.m1.7.7.1.1.3.2.2.2.1.1"><apply id="S3.E2.m1.7.7.1.1.3.2.2.2.1.1.1.cmml" xref="S3.E2.m1.7.7.1.1.3.2.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.7.7.1.1.3.2.2.2.1.1.1.1.cmml" xref="S3.E2.m1.7.7.1.1.3.2.2.2.1.1.1">subscript</csymbol><apply id="S3.E2.m1.7.7.1.1.3.2.2.2.1.1.1.2.cmml" xref="S3.E2.m1.7.7.1.1.3.2.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.7.7.1.1.3.2.2.2.1.1.1.2.1.cmml" xref="S3.E2.m1.7.7.1.1.3.2.2.2.1.1.1">superscript</csymbol><ci id="S3.E2.m1.7.7.1.1.3.2.2.2.1.1.1.2.2.cmml" xref="S3.E2.m1.7.7.1.1.3.2.2.2.1.1.1.2.2">ğ±</ci><apply id="S3.E2.m1.5.5.1.1.1.cmml" xref="S3.E2.m1.5.5.1.1"><ci id="S3.E2.m1.5.5.1.1.1.1.cmml" xref="S3.E2.m1.5.5.1.1.1.1">:</ci><cn id="S3.E2.m1.5.5.1.1.1.2.cmml" type="integer" xref="S3.E2.m1.5.5.1.1.1.2">1</cn><ci id="S3.E2.m1.5.5.1.1.1.3.cmml" xref="S3.E2.m1.5.5.1.1.1.3">ğ‘</ci></apply></apply><ci id="S3.E2.m1.7.7.1.1.3.2.2.2.1.1.1.3.cmml" xref="S3.E2.m1.7.7.1.1.3.2.2.2.1.1.1.3">ğ‘¡</ci></apply><ci id="S3.E2.m1.6.6.cmml" xref="S3.E2.m1.6.6">ğ‘¡</ci></interval></apply><apply id="S3.E2.m1.7.7.1.1.4.3.3.3.cmml" xref="S3.E2.m1.7.7.1.1.4.3.3.3"><times id="S3.E2.m1.7.7.1.1.4.3.3.3.1.cmml" xref="S3.E2.m1.7.7.1.1.4.3.3.3.1"></times><apply id="S3.E2.m1.7.7.1.1.4.3.3.3.2.cmml" xref="S3.E2.m1.7.7.1.1.4.3.3.3.2"><csymbol cd="ambiguous" id="S3.E2.m1.7.7.1.1.4.3.3.3.2.1.cmml" xref="S3.E2.m1.7.7.1.1.4.3.3.3.2">subscript</csymbol><apply id="S3.E2.m1.7.7.1.1.4.3.3.3.2.2.cmml" xref="S3.E2.m1.7.7.1.1.4.3.3.3.2"><csymbol cd="ambiguous" id="S3.E2.m1.7.7.1.1.4.3.3.3.2.2.1.cmml" xref="S3.E2.m1.7.7.1.1.4.3.3.3.2">superscript</csymbol><ci id="S3.E2.m1.7.7.1.1.4.3.3.3.2.2.2.cmml" xref="S3.E2.m1.7.7.1.1.4.3.3.3.2.2.2">ğœ</ci><cn id="S3.E2.m1.7.7.1.1.4.3.3.3.2.2.3.cmml" type="integer" xref="S3.E2.m1.7.7.1.1.4.3.3.3.2.2.3">2</cn></apply><ci id="S3.E2.m1.7.7.1.1.4.3.3.3.2.3.cmml" xref="S3.E2.m1.7.7.1.1.4.3.3.3.2.3">ğ‘¡</ci></apply><ci id="S3.E2.m1.7.7.1.1.4.3.3.3.3.cmml" xref="S3.E2.m1.7.7.1.1.4.3.3.3.3">ğˆ</ci></apply></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.7c">p_{\theta}(\mathbf{x}^{(n)}_{t-1}|\mathbf{x}^{(1:N)}_{t})=\mathcal{N}(\mathbf{%
x}^{(n)}_{t-1};\mathbf{\mu}^{(n)}_{\theta}(\mathbf{x}^{(1:N)}_{t},t),\sigma^{2%
}_{t}\mathbf{I}),</annotation><annotation encoding="application/x-llamapun" id="S3.E2.m1.7d">italic_p start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT ( bold_x start_POSTSUPERSCRIPT ( italic_n ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT | bold_x start_POSTSUPERSCRIPT ( 1 : italic_N ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) = caligraphic_N ( bold_x start_POSTSUPERSCRIPT ( italic_n ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT ; italic_Î¼ start_POSTSUPERSCRIPT ( italic_n ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT ( bold_x start_POSTSUPERSCRIPT ( 1 : italic_N ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_t ) , italic_Ïƒ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT bold_I ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS1.p2.6">where the learnable mean for the <math alttext="n" class="ltx_Math" display="inline" id="S3.SS1.p2.5.m1.1"><semantics id="S3.SS1.p2.5.m1.1a"><mi id="S3.SS1.p2.5.m1.1.1" xref="S3.SS1.p2.5.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.5.m1.1b"><ci id="S3.SS1.p2.5.m1.1.1.cmml" xref="S3.SS1.p2.5.m1.1.1">ğ‘›</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.5.m1.1c">n</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.5.m1.1d">italic_n</annotation></semantics></math>-th view at step <math alttext="t" class="ltx_Math" display="inline" id="S3.SS1.p2.6.m2.1"><semantics id="S3.SS1.p2.6.m2.1a"><mi id="S3.SS1.p2.6.m2.1.1" xref="S3.SS1.p2.6.m2.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.6.m2.1b"><ci id="S3.SS1.p2.6.m2.1.1.cmml" xref="S3.SS1.p2.6.m2.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.6.m2.1c">t</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.6.m2.1d">italic_t</annotation></semantics></math> is defined as:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathbf{\mu}^{(n)}_{\theta}(\mathbf{x}^{(1:N)}_{t},t)=\frac{1}{\sqrt{\alpha}_{%
t}}\left(\mathbf{x}^{(n)}_{t}-\frac{\beta_{t}}{\sqrt{1-\bar{\alpha}_{t}}}%
\mathbf{\epsilon}^{(n)}_{\theta}(\mathbf{x}^{(1:N)}_{t},t)\right)," class="ltx_Math" display="block" id="S3.E3.m1.8"><semantics id="S3.E3.m1.8a"><mrow id="S3.E3.m1.8.8.1" xref="S3.E3.m1.8.8.1.1.cmml"><mrow id="S3.E3.m1.8.8.1.1" xref="S3.E3.m1.8.8.1.1.cmml"><mrow id="S3.E3.m1.8.8.1.1.1" xref="S3.E3.m1.8.8.1.1.1.cmml"><msubsup id="S3.E3.m1.8.8.1.1.1.3" xref="S3.E3.m1.8.8.1.1.1.3.cmml"><mi id="S3.E3.m1.8.8.1.1.1.3.2.2" xref="S3.E3.m1.8.8.1.1.1.3.2.2.cmml">Î¼</mi><mi id="S3.E3.m1.8.8.1.1.1.3.3" xref="S3.E3.m1.8.8.1.1.1.3.3.cmml">Î¸</mi><mrow id="S3.E3.m1.1.1.1.3" xref="S3.E3.m1.8.8.1.1.1.3.cmml"><mo id="S3.E3.m1.1.1.1.3.1" stretchy="false" xref="S3.E3.m1.8.8.1.1.1.3.cmml">(</mo><mi id="S3.E3.m1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.cmml">n</mi><mo id="S3.E3.m1.1.1.1.3.2" stretchy="false" xref="S3.E3.m1.8.8.1.1.1.3.cmml">)</mo></mrow></msubsup><mo id="S3.E3.m1.8.8.1.1.1.2" xref="S3.E3.m1.8.8.1.1.1.2.cmml">â¢</mo><mrow id="S3.E3.m1.8.8.1.1.1.1.1" xref="S3.E3.m1.8.8.1.1.1.1.2.cmml"><mo id="S3.E3.m1.8.8.1.1.1.1.1.2" stretchy="false" xref="S3.E3.m1.8.8.1.1.1.1.2.cmml">(</mo><msubsup id="S3.E3.m1.8.8.1.1.1.1.1.1" xref="S3.E3.m1.8.8.1.1.1.1.1.1.cmml"><mi id="S3.E3.m1.8.8.1.1.1.1.1.1.2.2" xref="S3.E3.m1.8.8.1.1.1.1.1.1.2.2.cmml">ğ±</mi><mi id="S3.E3.m1.8.8.1.1.1.1.1.1.3" xref="S3.E3.m1.8.8.1.1.1.1.1.1.3.cmml">t</mi><mrow id="S3.E3.m1.2.2.1.1" xref="S3.E3.m1.2.2.1.1.1.cmml"><mo id="S3.E3.m1.2.2.1.1.2" stretchy="false" xref="S3.E3.m1.2.2.1.1.1.cmml">(</mo><mrow id="S3.E3.m1.2.2.1.1.1" xref="S3.E3.m1.2.2.1.1.1.cmml"><mn id="S3.E3.m1.2.2.1.1.1.2" xref="S3.E3.m1.2.2.1.1.1.2.cmml">1</mn><mo id="S3.E3.m1.2.2.1.1.1.1" lspace="0.278em" rspace="0.278em" xref="S3.E3.m1.2.2.1.1.1.1.cmml">:</mo><mi id="S3.E3.m1.2.2.1.1.1.3" xref="S3.E3.m1.2.2.1.1.1.3.cmml">N</mi></mrow><mo id="S3.E3.m1.2.2.1.1.3" stretchy="false" xref="S3.E3.m1.2.2.1.1.1.cmml">)</mo></mrow></msubsup><mo id="S3.E3.m1.8.8.1.1.1.1.1.3" xref="S3.E3.m1.8.8.1.1.1.1.2.cmml">,</mo><mi id="S3.E3.m1.6.6" xref="S3.E3.m1.6.6.cmml">t</mi><mo id="S3.E3.m1.8.8.1.1.1.1.1.4" stretchy="false" xref="S3.E3.m1.8.8.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S3.E3.m1.8.8.1.1.3" xref="S3.E3.m1.8.8.1.1.3.cmml">=</mo><mrow id="S3.E3.m1.8.8.1.1.2" xref="S3.E3.m1.8.8.1.1.2.cmml"><mfrac id="S3.E3.m1.8.8.1.1.2.3" xref="S3.E3.m1.8.8.1.1.2.3.cmml"><mn id="S3.E3.m1.8.8.1.1.2.3.2" xref="S3.E3.m1.8.8.1.1.2.3.2.cmml">1</mn><msub id="S3.E3.m1.8.8.1.1.2.3.3" xref="S3.E3.m1.8.8.1.1.2.3.3.cmml"><msqrt id="S3.E3.m1.8.8.1.1.2.3.3.2" xref="S3.E3.m1.8.8.1.1.2.3.3.2.cmml"><mi id="S3.E3.m1.8.8.1.1.2.3.3.2.2" xref="S3.E3.m1.8.8.1.1.2.3.3.2.2.cmml">Î±</mi></msqrt><mi id="S3.E3.m1.8.8.1.1.2.3.3.3" xref="S3.E3.m1.8.8.1.1.2.3.3.3.cmml">t</mi></msub></mfrac><mo id="S3.E3.m1.8.8.1.1.2.2" xref="S3.E3.m1.8.8.1.1.2.2.cmml">â¢</mo><mrow id="S3.E3.m1.8.8.1.1.2.1.1" xref="S3.E3.m1.8.8.1.1.2.1.1.1.cmml"><mo id="S3.E3.m1.8.8.1.1.2.1.1.2" xref="S3.E3.m1.8.8.1.1.2.1.1.1.cmml">(</mo><mrow id="S3.E3.m1.8.8.1.1.2.1.1.1" xref="S3.E3.m1.8.8.1.1.2.1.1.1.cmml"><msubsup id="S3.E3.m1.8.8.1.1.2.1.1.1.3" xref="S3.E3.m1.8.8.1.1.2.1.1.1.3.cmml"><mi id="S3.E3.m1.8.8.1.1.2.1.1.1.3.2.2" xref="S3.E3.m1.8.8.1.1.2.1.1.1.3.2.2.cmml">ğ±</mi><mi id="S3.E3.m1.8.8.1.1.2.1.1.1.3.3" xref="S3.E3.m1.8.8.1.1.2.1.1.1.3.3.cmml">t</mi><mrow id="S3.E3.m1.3.3.1.3" xref="S3.E3.m1.8.8.1.1.2.1.1.1.3.cmml"><mo id="S3.E3.m1.3.3.1.3.1" stretchy="false" xref="S3.E3.m1.8.8.1.1.2.1.1.1.3.cmml">(</mo><mi id="S3.E3.m1.3.3.1.1" xref="S3.E3.m1.3.3.1.1.cmml">n</mi><mo id="S3.E3.m1.3.3.1.3.2" stretchy="false" xref="S3.E3.m1.8.8.1.1.2.1.1.1.3.cmml">)</mo></mrow></msubsup><mo id="S3.E3.m1.8.8.1.1.2.1.1.1.2" xref="S3.E3.m1.8.8.1.1.2.1.1.1.2.cmml">âˆ’</mo><mrow id="S3.E3.m1.8.8.1.1.2.1.1.1.1" xref="S3.E3.m1.8.8.1.1.2.1.1.1.1.cmml"><mfrac id="S3.E3.m1.8.8.1.1.2.1.1.1.1.3" xref="S3.E3.m1.8.8.1.1.2.1.1.1.1.3.cmml"><msub id="S3.E3.m1.8.8.1.1.2.1.1.1.1.3.2" xref="S3.E3.m1.8.8.1.1.2.1.1.1.1.3.2.cmml"><mi id="S3.E3.m1.8.8.1.1.2.1.1.1.1.3.2.2" xref="S3.E3.m1.8.8.1.1.2.1.1.1.1.3.2.2.cmml">Î²</mi><mi id="S3.E3.m1.8.8.1.1.2.1.1.1.1.3.2.3" xref="S3.E3.m1.8.8.1.1.2.1.1.1.1.3.2.3.cmml">t</mi></msub><msqrt id="S3.E3.m1.8.8.1.1.2.1.1.1.1.3.3" xref="S3.E3.m1.8.8.1.1.2.1.1.1.1.3.3.cmml"><mrow id="S3.E3.m1.8.8.1.1.2.1.1.1.1.3.3.2" xref="S3.E3.m1.8.8.1.1.2.1.1.1.1.3.3.2.cmml"><mn id="S3.E3.m1.8.8.1.1.2.1.1.1.1.3.3.2.2" xref="S3.E3.m1.8.8.1.1.2.1.1.1.1.3.3.2.2.cmml">1</mn><mo id="S3.E3.m1.8.8.1.1.2.1.1.1.1.3.3.2.1" xref="S3.E3.m1.8.8.1.1.2.1.1.1.1.3.3.2.1.cmml">âˆ’</mo><msub id="S3.E3.m1.8.8.1.1.2.1.1.1.1.3.3.2.3" xref="S3.E3.m1.8.8.1.1.2.1.1.1.1.3.3.2.3.cmml"><mover accent="true" id="S3.E3.m1.8.8.1.1.2.1.1.1.1.3.3.2.3.2" xref="S3.E3.m1.8.8.1.1.2.1.1.1.1.3.3.2.3.2.cmml"><mi id="S3.E3.m1.8.8.1.1.2.1.1.1.1.3.3.2.3.2.2" xref="S3.E3.m1.8.8.1.1.2.1.1.1.1.3.3.2.3.2.2.cmml">Î±</mi><mo id="S3.E3.m1.8.8.1.1.2.1.1.1.1.3.3.2.3.2.1" xref="S3.E3.m1.8.8.1.1.2.1.1.1.1.3.3.2.3.2.1.cmml">Â¯</mo></mover><mi id="S3.E3.m1.8.8.1.1.2.1.1.1.1.3.3.2.3.3" xref="S3.E3.m1.8.8.1.1.2.1.1.1.1.3.3.2.3.3.cmml">t</mi></msub></mrow></msqrt></mfrac><mo id="S3.E3.m1.8.8.1.1.2.1.1.1.1.2" xref="S3.E3.m1.8.8.1.1.2.1.1.1.1.2.cmml">â¢</mo><msubsup id="S3.E3.m1.8.8.1.1.2.1.1.1.1.4" xref="S3.E3.m1.8.8.1.1.2.1.1.1.1.4.cmml"><mi id="S3.E3.m1.8.8.1.1.2.1.1.1.1.4.2.2" xref="S3.E3.m1.8.8.1.1.2.1.1.1.1.4.2.2.cmml">Ïµ</mi><mi id="S3.E3.m1.8.8.1.1.2.1.1.1.1.4.3" xref="S3.E3.m1.8.8.1.1.2.1.1.1.1.4.3.cmml">Î¸</mi><mrow id="S3.E3.m1.4.4.1.3" xref="S3.E3.m1.8.8.1.1.2.1.1.1.1.4.cmml"><mo id="S3.E3.m1.4.4.1.3.1" stretchy="false" xref="S3.E3.m1.8.8.1.1.2.1.1.1.1.4.cmml">(</mo><mi id="S3.E3.m1.4.4.1.1" xref="S3.E3.m1.4.4.1.1.cmml">n</mi><mo id="S3.E3.m1.4.4.1.3.2" stretchy="false" xref="S3.E3.m1.8.8.1.1.2.1.1.1.1.4.cmml">)</mo></mrow></msubsup><mo id="S3.E3.m1.8.8.1.1.2.1.1.1.1.2a" xref="S3.E3.m1.8.8.1.1.2.1.1.1.1.2.cmml">â¢</mo><mrow id="S3.E3.m1.8.8.1.1.2.1.1.1.1.1.1" xref="S3.E3.m1.8.8.1.1.2.1.1.1.1.1.2.cmml"><mo id="S3.E3.m1.8.8.1.1.2.1.1.1.1.1.1.2" stretchy="false" xref="S3.E3.m1.8.8.1.1.2.1.1.1.1.1.2.cmml">(</mo><msubsup id="S3.E3.m1.8.8.1.1.2.1.1.1.1.1.1.1" xref="S3.E3.m1.8.8.1.1.2.1.1.1.1.1.1.1.cmml"><mi id="S3.E3.m1.8.8.1.1.2.1.1.1.1.1.1.1.2.2" xref="S3.E3.m1.8.8.1.1.2.1.1.1.1.1.1.1.2.2.cmml">ğ±</mi><mi id="S3.E3.m1.8.8.1.1.2.1.1.1.1.1.1.1.3" xref="S3.E3.m1.8.8.1.1.2.1.1.1.1.1.1.1.3.cmml">t</mi><mrow id="S3.E3.m1.5.5.1.1" xref="S3.E3.m1.5.5.1.1.1.cmml"><mo id="S3.E3.m1.5.5.1.1.2" stretchy="false" xref="S3.E3.m1.5.5.1.1.1.cmml">(</mo><mrow id="S3.E3.m1.5.5.1.1.1" xref="S3.E3.m1.5.5.1.1.1.cmml"><mn id="S3.E3.m1.5.5.1.1.1.2" xref="S3.E3.m1.5.5.1.1.1.2.cmml">1</mn><mo id="S3.E3.m1.5.5.1.1.1.1" lspace="0.278em" rspace="0.278em" xref="S3.E3.m1.5.5.1.1.1.1.cmml">:</mo><mi id="S3.E3.m1.5.5.1.1.1.3" xref="S3.E3.m1.5.5.1.1.1.3.cmml">N</mi></mrow><mo id="S3.E3.m1.5.5.1.1.3" stretchy="false" xref="S3.E3.m1.5.5.1.1.1.cmml">)</mo></mrow></msubsup><mo id="S3.E3.m1.8.8.1.1.2.1.1.1.1.1.1.3" xref="S3.E3.m1.8.8.1.1.2.1.1.1.1.1.2.cmml">,</mo><mi id="S3.E3.m1.7.7" xref="S3.E3.m1.7.7.cmml">t</mi><mo id="S3.E3.m1.8.8.1.1.2.1.1.1.1.1.1.4" stretchy="false" xref="S3.E3.m1.8.8.1.1.2.1.1.1.1.1.2.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E3.m1.8.8.1.1.2.1.1.3" xref="S3.E3.m1.8.8.1.1.2.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E3.m1.8.8.1.2" xref="S3.E3.m1.8.8.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.8b"><apply id="S3.E3.m1.8.8.1.1.cmml" xref="S3.E3.m1.8.8.1"><eq id="S3.E3.m1.8.8.1.1.3.cmml" xref="S3.E3.m1.8.8.1.1.3"></eq><apply id="S3.E3.m1.8.8.1.1.1.cmml" xref="S3.E3.m1.8.8.1.1.1"><times id="S3.E3.m1.8.8.1.1.1.2.cmml" xref="S3.E3.m1.8.8.1.1.1.2"></times><apply id="S3.E3.m1.8.8.1.1.1.3.cmml" xref="S3.E3.m1.8.8.1.1.1.3"><csymbol cd="ambiguous" id="S3.E3.m1.8.8.1.1.1.3.1.cmml" xref="S3.E3.m1.8.8.1.1.1.3">subscript</csymbol><apply id="S3.E3.m1.8.8.1.1.1.3.2.cmml" xref="S3.E3.m1.8.8.1.1.1.3"><csymbol cd="ambiguous" id="S3.E3.m1.8.8.1.1.1.3.2.1.cmml" xref="S3.E3.m1.8.8.1.1.1.3">superscript</csymbol><ci id="S3.E3.m1.8.8.1.1.1.3.2.2.cmml" xref="S3.E3.m1.8.8.1.1.1.3.2.2">ğœ‡</ci><ci id="S3.E3.m1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1">ğ‘›</ci></apply><ci id="S3.E3.m1.8.8.1.1.1.3.3.cmml" xref="S3.E3.m1.8.8.1.1.1.3.3">ğœƒ</ci></apply><interval closure="open" id="S3.E3.m1.8.8.1.1.1.1.2.cmml" xref="S3.E3.m1.8.8.1.1.1.1.1"><apply id="S3.E3.m1.8.8.1.1.1.1.1.1.cmml" xref="S3.E3.m1.8.8.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.8.8.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.8.8.1.1.1.1.1.1">subscript</csymbol><apply id="S3.E3.m1.8.8.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.8.8.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.8.8.1.1.1.1.1.1.2.1.cmml" xref="S3.E3.m1.8.8.1.1.1.1.1.1">superscript</csymbol><ci id="S3.E3.m1.8.8.1.1.1.1.1.1.2.2.cmml" xref="S3.E3.m1.8.8.1.1.1.1.1.1.2.2">ğ±</ci><apply id="S3.E3.m1.2.2.1.1.1.cmml" xref="S3.E3.m1.2.2.1.1"><ci id="S3.E3.m1.2.2.1.1.1.1.cmml" xref="S3.E3.m1.2.2.1.1.1.1">:</ci><cn id="S3.E3.m1.2.2.1.1.1.2.cmml" type="integer" xref="S3.E3.m1.2.2.1.1.1.2">1</cn><ci id="S3.E3.m1.2.2.1.1.1.3.cmml" xref="S3.E3.m1.2.2.1.1.1.3">ğ‘</ci></apply></apply><ci id="S3.E3.m1.8.8.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.8.8.1.1.1.1.1.1.3">ğ‘¡</ci></apply><ci id="S3.E3.m1.6.6.cmml" xref="S3.E3.m1.6.6">ğ‘¡</ci></interval></apply><apply id="S3.E3.m1.8.8.1.1.2.cmml" xref="S3.E3.m1.8.8.1.1.2"><times id="S3.E3.m1.8.8.1.1.2.2.cmml" xref="S3.E3.m1.8.8.1.1.2.2"></times><apply id="S3.E3.m1.8.8.1.1.2.3.cmml" xref="S3.E3.m1.8.8.1.1.2.3"><divide id="S3.E3.m1.8.8.1.1.2.3.1.cmml" xref="S3.E3.m1.8.8.1.1.2.3"></divide><cn id="S3.E3.m1.8.8.1.1.2.3.2.cmml" type="integer" xref="S3.E3.m1.8.8.1.1.2.3.2">1</cn><apply id="S3.E3.m1.8.8.1.1.2.3.3.cmml" xref="S3.E3.m1.8.8.1.1.2.3.3"><csymbol cd="ambiguous" id="S3.E3.m1.8.8.1.1.2.3.3.1.cmml" xref="S3.E3.m1.8.8.1.1.2.3.3">subscript</csymbol><apply id="S3.E3.m1.8.8.1.1.2.3.3.2.cmml" xref="S3.E3.m1.8.8.1.1.2.3.3.2"><root id="S3.E3.m1.8.8.1.1.2.3.3.2a.cmml" xref="S3.E3.m1.8.8.1.1.2.3.3.2"></root><ci id="S3.E3.m1.8.8.1.1.2.3.3.2.2.cmml" xref="S3.E3.m1.8.8.1.1.2.3.3.2.2">ğ›¼</ci></apply><ci id="S3.E3.m1.8.8.1.1.2.3.3.3.cmml" xref="S3.E3.m1.8.8.1.1.2.3.3.3">ğ‘¡</ci></apply></apply><apply id="S3.E3.m1.8.8.1.1.2.1.1.1.cmml" xref="S3.E3.m1.8.8.1.1.2.1.1"><minus id="S3.E3.m1.8.8.1.1.2.1.1.1.2.cmml" xref="S3.E3.m1.8.8.1.1.2.1.1.1.2"></minus><apply id="S3.E3.m1.8.8.1.1.2.1.1.1.3.cmml" xref="S3.E3.m1.8.8.1.1.2.1.1.1.3"><csymbol cd="ambiguous" id="S3.E3.m1.8.8.1.1.2.1.1.1.3.1.cmml" xref="S3.E3.m1.8.8.1.1.2.1.1.1.3">subscript</csymbol><apply id="S3.E3.m1.8.8.1.1.2.1.1.1.3.2.cmml" xref="S3.E3.m1.8.8.1.1.2.1.1.1.3"><csymbol cd="ambiguous" id="S3.E3.m1.8.8.1.1.2.1.1.1.3.2.1.cmml" xref="S3.E3.m1.8.8.1.1.2.1.1.1.3">superscript</csymbol><ci id="S3.E3.m1.8.8.1.1.2.1.1.1.3.2.2.cmml" xref="S3.E3.m1.8.8.1.1.2.1.1.1.3.2.2">ğ±</ci><ci id="S3.E3.m1.3.3.1.1.cmml" xref="S3.E3.m1.3.3.1.1">ğ‘›</ci></apply><ci id="S3.E3.m1.8.8.1.1.2.1.1.1.3.3.cmml" xref="S3.E3.m1.8.8.1.1.2.1.1.1.3.3">ğ‘¡</ci></apply><apply id="S3.E3.m1.8.8.1.1.2.1.1.1.1.cmml" xref="S3.E3.m1.8.8.1.1.2.1.1.1.1"><times id="S3.E3.m1.8.8.1.1.2.1.1.1.1.2.cmml" xref="S3.E3.m1.8.8.1.1.2.1.1.1.1.2"></times><apply id="S3.E3.m1.8.8.1.1.2.1.1.1.1.3.cmml" xref="S3.E3.m1.8.8.1.1.2.1.1.1.1.3"><divide id="S3.E3.m1.8.8.1.1.2.1.1.1.1.3.1.cmml" xref="S3.E3.m1.8.8.1.1.2.1.1.1.1.3"></divide><apply id="S3.E3.m1.8.8.1.1.2.1.1.1.1.3.2.cmml" xref="S3.E3.m1.8.8.1.1.2.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E3.m1.8.8.1.1.2.1.1.1.1.3.2.1.cmml" xref="S3.E3.m1.8.8.1.1.2.1.1.1.1.3.2">subscript</csymbol><ci id="S3.E3.m1.8.8.1.1.2.1.1.1.1.3.2.2.cmml" xref="S3.E3.m1.8.8.1.1.2.1.1.1.1.3.2.2">ğ›½</ci><ci id="S3.E3.m1.8.8.1.1.2.1.1.1.1.3.2.3.cmml" xref="S3.E3.m1.8.8.1.1.2.1.1.1.1.3.2.3">ğ‘¡</ci></apply><apply id="S3.E3.m1.8.8.1.1.2.1.1.1.1.3.3.cmml" xref="S3.E3.m1.8.8.1.1.2.1.1.1.1.3.3"><root id="S3.E3.m1.8.8.1.1.2.1.1.1.1.3.3a.cmml" xref="S3.E3.m1.8.8.1.1.2.1.1.1.1.3.3"></root><apply id="S3.E3.m1.8.8.1.1.2.1.1.1.1.3.3.2.cmml" xref="S3.E3.m1.8.8.1.1.2.1.1.1.1.3.3.2"><minus id="S3.E3.m1.8.8.1.1.2.1.1.1.1.3.3.2.1.cmml" xref="S3.E3.m1.8.8.1.1.2.1.1.1.1.3.3.2.1"></minus><cn id="S3.E3.m1.8.8.1.1.2.1.1.1.1.3.3.2.2.cmml" type="integer" xref="S3.E3.m1.8.8.1.1.2.1.1.1.1.3.3.2.2">1</cn><apply id="S3.E3.m1.8.8.1.1.2.1.1.1.1.3.3.2.3.cmml" xref="S3.E3.m1.8.8.1.1.2.1.1.1.1.3.3.2.3"><csymbol cd="ambiguous" id="S3.E3.m1.8.8.1.1.2.1.1.1.1.3.3.2.3.1.cmml" xref="S3.E3.m1.8.8.1.1.2.1.1.1.1.3.3.2.3">subscript</csymbol><apply id="S3.E3.m1.8.8.1.1.2.1.1.1.1.3.3.2.3.2.cmml" xref="S3.E3.m1.8.8.1.1.2.1.1.1.1.3.3.2.3.2"><ci id="S3.E3.m1.8.8.1.1.2.1.1.1.1.3.3.2.3.2.1.cmml" xref="S3.E3.m1.8.8.1.1.2.1.1.1.1.3.3.2.3.2.1">Â¯</ci><ci id="S3.E3.m1.8.8.1.1.2.1.1.1.1.3.3.2.3.2.2.cmml" xref="S3.E3.m1.8.8.1.1.2.1.1.1.1.3.3.2.3.2.2">ğ›¼</ci></apply><ci id="S3.E3.m1.8.8.1.1.2.1.1.1.1.3.3.2.3.3.cmml" xref="S3.E3.m1.8.8.1.1.2.1.1.1.1.3.3.2.3.3">ğ‘¡</ci></apply></apply></apply></apply><apply id="S3.E3.m1.8.8.1.1.2.1.1.1.1.4.cmml" xref="S3.E3.m1.8.8.1.1.2.1.1.1.1.4"><csymbol cd="ambiguous" id="S3.E3.m1.8.8.1.1.2.1.1.1.1.4.1.cmml" xref="S3.E3.m1.8.8.1.1.2.1.1.1.1.4">subscript</csymbol><apply id="S3.E3.m1.8.8.1.1.2.1.1.1.1.4.2.cmml" xref="S3.E3.m1.8.8.1.1.2.1.1.1.1.4"><csymbol cd="ambiguous" id="S3.E3.m1.8.8.1.1.2.1.1.1.1.4.2.1.cmml" xref="S3.E3.m1.8.8.1.1.2.1.1.1.1.4">superscript</csymbol><ci id="S3.E3.m1.8.8.1.1.2.1.1.1.1.4.2.2.cmml" xref="S3.E3.m1.8.8.1.1.2.1.1.1.1.4.2.2">italic-Ïµ</ci><ci id="S3.E3.m1.4.4.1.1.cmml" xref="S3.E3.m1.4.4.1.1">ğ‘›</ci></apply><ci id="S3.E3.m1.8.8.1.1.2.1.1.1.1.4.3.cmml" xref="S3.E3.m1.8.8.1.1.2.1.1.1.1.4.3">ğœƒ</ci></apply><interval closure="open" id="S3.E3.m1.8.8.1.1.2.1.1.1.1.1.2.cmml" xref="S3.E3.m1.8.8.1.1.2.1.1.1.1.1.1"><apply id="S3.E3.m1.8.8.1.1.2.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.8.8.1.1.2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.8.8.1.1.2.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.8.8.1.1.2.1.1.1.1.1.1.1">subscript</csymbol><apply id="S3.E3.m1.8.8.1.1.2.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.8.8.1.1.2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.8.8.1.1.2.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E3.m1.8.8.1.1.2.1.1.1.1.1.1.1">superscript</csymbol><ci id="S3.E3.m1.8.8.1.1.2.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E3.m1.8.8.1.1.2.1.1.1.1.1.1.1.2.2">ğ±</ci><apply id="S3.E3.m1.5.5.1.1.1.cmml" xref="S3.E3.m1.5.5.1.1"><ci id="S3.E3.m1.5.5.1.1.1.1.cmml" xref="S3.E3.m1.5.5.1.1.1.1">:</ci><cn id="S3.E3.m1.5.5.1.1.1.2.cmml" type="integer" xref="S3.E3.m1.5.5.1.1.1.2">1</cn><ci id="S3.E3.m1.5.5.1.1.1.3.cmml" xref="S3.E3.m1.5.5.1.1.1.3">ğ‘</ci></apply></apply><ci id="S3.E3.m1.8.8.1.1.2.1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.8.8.1.1.2.1.1.1.1.1.1.1.3">ğ‘¡</ci></apply><ci id="S3.E3.m1.7.7.cmml" xref="S3.E3.m1.7.7">ğ‘¡</ci></interval></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.8c">\mathbf{\mu}^{(n)}_{\theta}(\mathbf{x}^{(1:N)}_{t},t)=\frac{1}{\sqrt{\alpha}_{%
t}}\left(\mathbf{x}^{(n)}_{t}-\frac{\beta_{t}}{\sqrt{1-\bar{\alpha}_{t}}}%
\mathbf{\epsilon}^{(n)}_{\theta}(\mathbf{x}^{(1:N)}_{t},t)\right),</annotation><annotation encoding="application/x-llamapun" id="S3.E3.m1.8d">italic_Î¼ start_POSTSUPERSCRIPT ( italic_n ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT ( bold_x start_POSTSUPERSCRIPT ( 1 : italic_N ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_t ) = divide start_ARG 1 end_ARG start_ARG square-root start_ARG italic_Î± end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG ( bold_x start_POSTSUPERSCRIPT ( italic_n ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT - divide start_ARG italic_Î² start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG start_ARG square-root start_ARG 1 - overÂ¯ start_ARG italic_Î± end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG end_ARG italic_Ïµ start_POSTSUPERSCRIPT ( italic_n ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT ( bold_x start_POSTSUPERSCRIPT ( 1 : italic_N ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_t ) ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS1.p2.12">where <math alttext="\mathbf{\epsilon}^{(n)}_{\theta}" class="ltx_Math" display="inline" id="S3.SS1.p2.7.m1.1"><semantics id="S3.SS1.p2.7.m1.1a"><msubsup id="S3.SS1.p2.7.m1.1.2" xref="S3.SS1.p2.7.m1.1.2.cmml"><mi id="S3.SS1.p2.7.m1.1.2.2.2" xref="S3.SS1.p2.7.m1.1.2.2.2.cmml">Ïµ</mi><mi id="S3.SS1.p2.7.m1.1.2.3" xref="S3.SS1.p2.7.m1.1.2.3.cmml">Î¸</mi><mrow id="S3.SS1.p2.7.m1.1.1.1.3" xref="S3.SS1.p2.7.m1.1.2.cmml"><mo id="S3.SS1.p2.7.m1.1.1.1.3.1" stretchy="false" xref="S3.SS1.p2.7.m1.1.2.cmml">(</mo><mi id="S3.SS1.p2.7.m1.1.1.1.1" xref="S3.SS1.p2.7.m1.1.1.1.1.cmml">n</mi><mo id="S3.SS1.p2.7.m1.1.1.1.3.2" stretchy="false" xref="S3.SS1.p2.7.m1.1.2.cmml">)</mo></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.7.m1.1b"><apply id="S3.SS1.p2.7.m1.1.2.cmml" xref="S3.SS1.p2.7.m1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p2.7.m1.1.2.1.cmml" xref="S3.SS1.p2.7.m1.1.2">subscript</csymbol><apply id="S3.SS1.p2.7.m1.1.2.2.cmml" xref="S3.SS1.p2.7.m1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p2.7.m1.1.2.2.1.cmml" xref="S3.SS1.p2.7.m1.1.2">superscript</csymbol><ci id="S3.SS1.p2.7.m1.1.2.2.2.cmml" xref="S3.SS1.p2.7.m1.1.2.2.2">italic-Ïµ</ci><ci id="S3.SS1.p2.7.m1.1.1.1.1.cmml" xref="S3.SS1.p2.7.m1.1.1.1.1">ğ‘›</ci></apply><ci id="S3.SS1.p2.7.m1.1.2.3.cmml" xref="S3.SS1.p2.7.m1.1.2.3">ğœƒ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.7.m1.1c">\mathbf{\epsilon}^{(n)}_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.7.m1.1d">italic_Ïµ start_POSTSUPERSCRIPT ( italic_n ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT</annotation></semantics></math> denotes
the trainable noise predictor for the <math alttext="n" class="ltx_Math" display="inline" id="S3.SS1.p2.8.m2.1"><semantics id="S3.SS1.p2.8.m2.1a"><mi id="S3.SS1.p2.8.m2.1.1" xref="S3.SS1.p2.8.m2.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.8.m2.1b"><ci id="S3.SS1.p2.8.m2.1.1.cmml" xref="S3.SS1.p2.8.m2.1.1">ğ‘›</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.8.m2.1c">n</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.8.m2.1d">italic_n</annotation></semantics></math>-th view, <math alttext="\beta_{t}" class="ltx_Math" display="inline" id="S3.SS1.p2.9.m3.1"><semantics id="S3.SS1.p2.9.m3.1a"><msub id="S3.SS1.p2.9.m3.1.1" xref="S3.SS1.p2.9.m3.1.1.cmml"><mi id="S3.SS1.p2.9.m3.1.1.2" xref="S3.SS1.p2.9.m3.1.1.2.cmml">Î²</mi><mi id="S3.SS1.p2.9.m3.1.1.3" xref="S3.SS1.p2.9.m3.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.9.m3.1b"><apply id="S3.SS1.p2.9.m3.1.1.cmml" xref="S3.SS1.p2.9.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.9.m3.1.1.1.cmml" xref="S3.SS1.p2.9.m3.1.1">subscript</csymbol><ci id="S3.SS1.p2.9.m3.1.1.2.cmml" xref="S3.SS1.p2.9.m3.1.1.2">ğ›½</ci><ci id="S3.SS1.p2.9.m3.1.1.3.cmml" xref="S3.SS1.p2.9.m3.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.9.m3.1c">\beta_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.9.m3.1d">italic_Î² start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> specifies the noise schedule, <math alttext="{\alpha}_{t}" class="ltx_Math" display="inline" id="S3.SS1.p2.10.m4.1"><semantics id="S3.SS1.p2.10.m4.1a"><msub id="S3.SS1.p2.10.m4.1.1" xref="S3.SS1.p2.10.m4.1.1.cmml"><mi id="S3.SS1.p2.10.m4.1.1.2" xref="S3.SS1.p2.10.m4.1.1.2.cmml">Î±</mi><mi id="S3.SS1.p2.10.m4.1.1.3" xref="S3.SS1.p2.10.m4.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.10.m4.1b"><apply id="S3.SS1.p2.10.m4.1.1.cmml" xref="S3.SS1.p2.10.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.10.m4.1.1.1.cmml" xref="S3.SS1.p2.10.m4.1.1">subscript</csymbol><ci id="S3.SS1.p2.10.m4.1.1.2.cmml" xref="S3.SS1.p2.10.m4.1.1.2">ğ›¼</ci><ci id="S3.SS1.p2.10.m4.1.1.3.cmml" xref="S3.SS1.p2.10.m4.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.10.m4.1c">{\alpha}_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.10.m4.1d">italic_Î± start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="\bar{\alpha}_{t}" class="ltx_Math" display="inline" id="S3.SS1.p2.11.m5.1"><semantics id="S3.SS1.p2.11.m5.1a"><msub id="S3.SS1.p2.11.m5.1.1" xref="S3.SS1.p2.11.m5.1.1.cmml"><mover accent="true" id="S3.SS1.p2.11.m5.1.1.2" xref="S3.SS1.p2.11.m5.1.1.2.cmml"><mi id="S3.SS1.p2.11.m5.1.1.2.2" xref="S3.SS1.p2.11.m5.1.1.2.2.cmml">Î±</mi><mo id="S3.SS1.p2.11.m5.1.1.2.1" xref="S3.SS1.p2.11.m5.1.1.2.1.cmml">Â¯</mo></mover><mi id="S3.SS1.p2.11.m5.1.1.3" xref="S3.SS1.p2.11.m5.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.11.m5.1b"><apply id="S3.SS1.p2.11.m5.1.1.cmml" xref="S3.SS1.p2.11.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.11.m5.1.1.1.cmml" xref="S3.SS1.p2.11.m5.1.1">subscript</csymbol><apply id="S3.SS1.p2.11.m5.1.1.2.cmml" xref="S3.SS1.p2.11.m5.1.1.2"><ci id="S3.SS1.p2.11.m5.1.1.2.1.cmml" xref="S3.SS1.p2.11.m5.1.1.2.1">Â¯</ci><ci id="S3.SS1.p2.11.m5.1.1.2.2.cmml" xref="S3.SS1.p2.11.m5.1.1.2.2">ğ›¼</ci></apply><ci id="S3.SS1.p2.11.m5.1.1.3.cmml" xref="S3.SS1.p2.11.m5.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.11.m5.1c">\bar{\alpha}_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.11.m5.1d">overÂ¯ start_ARG italic_Î± end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> are two scaling constants derived from <math alttext="\beta_{t}" class="ltx_Math" display="inline" id="S3.SS1.p2.12.m6.1"><semantics id="S3.SS1.p2.12.m6.1a"><msub id="S3.SS1.p2.12.m6.1.1" xref="S3.SS1.p2.12.m6.1.1.cmml"><mi id="S3.SS1.p2.12.m6.1.1.2" xref="S3.SS1.p2.12.m6.1.1.2.cmml">Î²</mi><mi id="S3.SS1.p2.12.m6.1.1.3" xref="S3.SS1.p2.12.m6.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.12.m6.1b"><apply id="S3.SS1.p2.12.m6.1.1.cmml" xref="S3.SS1.p2.12.m6.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.12.m6.1.1.1.cmml" xref="S3.SS1.p2.12.m6.1.1">subscript</csymbol><ci id="S3.SS1.p2.12.m6.1.1.2.cmml" xref="S3.SS1.p2.12.m6.1.1.2">ğ›½</ci><ci id="S3.SS1.p2.12.m6.1.1.3.cmml" xref="S3.SS1.p2.12.m6.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.12.m6.1c">\beta_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.12.m6.1d">italic_Î² start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math></p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Gen3D-Face</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">Extending prior multi-view diffusion,
we take a step forward for generalisable single image 3D face avatar generation
where single unconstrained face images are present without ground-truth mesh.
To that end, we first need to address the data scarcity issue as discussed earlier
by multi-view face images synthesis for training data augmentation.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p2.1.1">Multi-view face synthesis</span>
We adopt the Panohead <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib2" title="">2</a>]</cite> to generate additional training images.
We generated 25,000 virtual human identities, each represented by 48 images, with azimuth ranging from -180 to 180 degrees, and elevation angle from -40 to 40 degrees (see FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#S3.F3" title="Figure 3 â€£ 3.2 Gen3D-Face â€£ 3 Method â€£ Single Image, Any Face: Generalisable 3D Face Generation"><span class="ltx_text ltx_ref_tag">3</span></a>).</p>
</div>
<figure class="ltx_figure" id="S3.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="108" id="S3.F3.1.g1" src="x3.png" width="822"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F3.3.1.1" style="font-size:90%;">Figure 3</span>: </span><span class="ltx_text" id="S3.F3.4.2" style="font-size:90%;">Examples of synthetic face images. </span></figcaption>
</figure>
<div class="ltx_para" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.2">As the synthesis process is less controllable, the output quality is often varying <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib26" title="">26</a>]</cite>.
To filter out low-quality face images, we design a pruning process for dealing with two problems.
(1) <span class="ltx_text ltx_font_italic" id="S3.SS2.p3.2.1">The Janus problem</span>: We observe cases where the back-view images present blurry faces. To identify such cases, we construct a binary classifier with CLIP <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib42" title="">42</a>]</cite> using the class names as <span class="ltx_text ltx_font_typewriter" id="S3.SS2.p3.2.2">back of human head</span> and <span class="ltx_text ltx_font_typewriter" id="S3.SS2.p3.2.3">human front face</span>,
and then classify all the back-view face images.
We remove those back-view images with the score of the <span class="ltx_text ltx_font_typewriter" id="S3.SS2.p3.2.4">human front face</span> class exceeding a threshold <math alttext="\tau_{bv}" class="ltx_Math" display="inline" id="S3.SS2.p3.1.m1.1"><semantics id="S3.SS2.p3.1.m1.1a"><msub id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml"><mi id="S3.SS2.p3.1.m1.1.1.2" xref="S3.SS2.p3.1.m1.1.1.2.cmml">Ï„</mi><mrow id="S3.SS2.p3.1.m1.1.1.3" xref="S3.SS2.p3.1.m1.1.1.3.cmml"><mi id="S3.SS2.p3.1.m1.1.1.3.2" xref="S3.SS2.p3.1.m1.1.1.3.2.cmml">b</mi><mo id="S3.SS2.p3.1.m1.1.1.3.1" xref="S3.SS2.p3.1.m1.1.1.3.1.cmml">â¢</mo><mi id="S3.SS2.p3.1.m1.1.1.3.3" xref="S3.SS2.p3.1.m1.1.1.3.3.cmml">v</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b"><apply id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.1.m1.1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.p3.1.m1.1.1.2.cmml" xref="S3.SS2.p3.1.m1.1.1.2">ğœ</ci><apply id="S3.SS2.p3.1.m1.1.1.3.cmml" xref="S3.SS2.p3.1.m1.1.1.3"><times id="S3.SS2.p3.1.m1.1.1.3.1.cmml" xref="S3.SS2.p3.1.m1.1.1.3.1"></times><ci id="S3.SS2.p3.1.m1.1.1.3.2.cmml" xref="S3.SS2.p3.1.m1.1.1.3.2">ğ‘</ci><ci id="S3.SS2.p3.1.m1.1.1.3.3.cmml" xref="S3.SS2.p3.1.m1.1.1.3.3">ğ‘£</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">\tau_{bv}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.1.m1.1d">italic_Ï„ start_POSTSUBSCRIPT italic_b italic_v end_POSTSUBSCRIPT</annotation></semantics></math>.
(2) <span class="ltx_text ltx_font_italic" id="S3.SS2.p3.2.5">Identity inconsistency</span>:
Multi-view face images generated by Panohead <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib2" title="">2</a>]</cite> are likely to be identity inconsistent.
To detect this, we estimate the identity consistency using the average pairwise similarity of views with face embeddings <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib10" title="">10</a>]</cite> for every individual identity and
keep only the top-<math alttext="\tau_{ii}" class="ltx_Math" display="inline" id="S3.SS2.p3.2.m2.1"><semantics id="S3.SS2.p3.2.m2.1a"><msub id="S3.SS2.p3.2.m2.1.1" xref="S3.SS2.p3.2.m2.1.1.cmml"><mi id="S3.SS2.p3.2.m2.1.1.2" xref="S3.SS2.p3.2.m2.1.1.2.cmml">Ï„</mi><mrow id="S3.SS2.p3.2.m2.1.1.3" xref="S3.SS2.p3.2.m2.1.1.3.cmml"><mi id="S3.SS2.p3.2.m2.1.1.3.2" xref="S3.SS2.p3.2.m2.1.1.3.2.cmml">i</mi><mo id="S3.SS2.p3.2.m2.1.1.3.1" xref="S3.SS2.p3.2.m2.1.1.3.1.cmml">â¢</mo><mi id="S3.SS2.p3.2.m2.1.1.3.3" xref="S3.SS2.p3.2.m2.1.1.3.3.cmml">i</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.m2.1b"><apply id="S3.SS2.p3.2.m2.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.2.m2.1.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.p3.2.m2.1.1.2.cmml" xref="S3.SS2.p3.2.m2.1.1.2">ğœ</ci><apply id="S3.SS2.p3.2.m2.1.1.3.cmml" xref="S3.SS2.p3.2.m2.1.1.3"><times id="S3.SS2.p3.2.m2.1.1.3.1.cmml" xref="S3.SS2.p3.2.m2.1.1.3.1"></times><ci id="S3.SS2.p3.2.m2.1.1.3.2.cmml" xref="S3.SS2.p3.2.m2.1.1.3.2">ğ‘–</ci><ci id="S3.SS2.p3.2.m2.1.1.3.3.cmml" xref="S3.SS2.p3.2.m2.1.1.3.3">ğ‘–</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.2.m2.1c">\tau_{ii}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.2.m2.1d">italic_Ï„ start_POSTSUBSCRIPT italic_i italic_i end_POSTSUBSCRIPT</annotation></semantics></math> virtual identities for model training.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p4">
<p class="ltx_p" id="S3.SS2.p4.2"><span class="ltx_text ltx_font_bold" id="S3.SS2.p4.2.1">Face geometry prior</span>
To facilitate the 3D face modeling from single images,
we integrate the human head mesh as a prior as <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib7" title="">7</a>]</cite>.
A key difference however is that we suggest to use the estimated mesh
from the input image, rather than requiring the ground-truth as <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib7" title="">7</a>]</cite>.
The reasons are two-fold:
(1) Often no ground-truth mesh in many real applications;
(2) Using ground-truth mesh tends to make the model over rely on this prior,
whilst largely ignore the appearance of the input image.
Specifically, we estimate the FLAME mesh <math alttext="\mathbb{M}" class="ltx_Math" display="inline" id="S3.SS2.p4.1.m1.1"><semantics id="S3.SS2.p4.1.m1.1a"><mi id="S3.SS2.p4.1.m1.1.1" xref="S3.SS2.p4.1.m1.1.1.cmml">ğ•„</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.1.m1.1b"><ci id="S3.SS2.p4.1.m1.1.1.cmml" xref="S3.SS2.p4.1.m1.1.1">ğ•„</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.1.m1.1c">\mathbb{M}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.1.m1.1d">blackboard_M</annotation></semantics></math> with <math alttext="v" class="ltx_Math" display="inline" id="S3.SS2.p4.2.m2.1"><semantics id="S3.SS2.p4.2.m2.1a"><mi id="S3.SS2.p4.2.m2.1.1" xref="S3.SS2.p4.2.m2.1.1.cmml">v</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.2.m2.1b"><ci id="S3.SS2.p4.2.m2.1.1.cmml" xref="S3.SS2.p4.2.m2.1.1">ğ‘£</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.2.m2.1c">v</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.2.m2.1d">italic_v</annotation></semantics></math> vertices from a single image <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib12" title="">12</a>]</cite> during both training and inference. As we show in experiments,
this design choice is a key to make our model more generalisable.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p5">
<p class="ltx_p" id="S3.SS2.p5.2"><span class="ltx_text ltx_font_bold" id="S3.SS2.p5.2.1">Joint conditioning of appearance and geometry</span>
The key in our context is how to effectively condition the multi-view diffusion process with both the appearance of the single image <math alttext="y" class="ltx_Math" display="inline" id="S3.SS2.p5.1.m1.1"><semantics id="S3.SS2.p5.1.m1.1a"><mi id="S3.SS2.p5.1.m1.1.1" xref="S3.SS2.p5.1.m1.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.1.m1.1b"><ci id="S3.SS2.p5.1.m1.1.1.cmml" xref="S3.SS2.p5.1.m1.1.1">ğ‘¦</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.1.m1.1c">y</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p5.1.m1.1d">italic_y</annotation></semantics></math> and the geometry of the estimated mesh <math alttext="\mathbb{M}" class="ltx_Math" display="inline" id="S3.SS2.p5.2.m2.1"><semantics id="S3.SS2.p5.2.m2.1a"><mi id="S3.SS2.p5.2.m2.1.1" xref="S3.SS2.p5.2.m2.1.1.cmml">ğ•„</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.2.m2.1b"><ci id="S3.SS2.p5.2.m2.1.1.cmml" xref="S3.SS2.p5.2.m2.1.1">ğ•„</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.2.m2.1c">\mathbb{M}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p5.2.m2.1d">blackboard_M</annotation></semantics></math> (Sec. <a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#S3.SS1" title="3.1 Preliminaries: 2D Diffusion and 3D Diffusion â€£ 3 Method â€£ Single Image, Any Face: Generalisable 3D Face Generation"><span class="ltx_text ltx_ref_tag">3.1</span></a>).</p>
</div>
<div class="ltx_para" id="S3.SS2.p6">
<p class="ltx_p" id="S3.SS2.p6.11">Specifically, let <math alttext="N" class="ltx_Math" display="inline" id="S3.SS2.p6.1.m1.1"><semantics id="S3.SS2.p6.1.m1.1a"><mi id="S3.SS2.p6.1.m1.1.1" xref="S3.SS2.p6.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.1.m1.1b"><ci id="S3.SS2.p6.1.m1.1.1.cmml" xref="S3.SS2.p6.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.1.m1.1c">N</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p6.1.m1.1d">italic_N</annotation></semantics></math> noisy target views at time <math alttext="t" class="ltx_Math" display="inline" id="S3.SS2.p6.2.m2.1"><semantics id="S3.SS2.p6.2.m2.1a"><mi id="S3.SS2.p6.2.m2.1.1" xref="S3.SS2.p6.2.m2.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.2.m2.1b"><ci id="S3.SS2.p6.2.m2.1.1.cmml" xref="S3.SS2.p6.2.m2.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.2.m2.1c">t</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p6.2.m2.1d">italic_t</annotation></semantics></math> denoted as <math alttext="\mathbf{x}^{(1:N)}_{t}" class="ltx_Math" display="inline" id="S3.SS2.p6.3.m3.1"><semantics id="S3.SS2.p6.3.m3.1a"><msubsup id="S3.SS2.p6.3.m3.1.2" xref="S3.SS2.p6.3.m3.1.2.cmml"><mi id="S3.SS2.p6.3.m3.1.2.2.2" xref="S3.SS2.p6.3.m3.1.2.2.2.cmml">ğ±</mi><mi id="S3.SS2.p6.3.m3.1.2.3" xref="S3.SS2.p6.3.m3.1.2.3.cmml">t</mi><mrow id="S3.SS2.p6.3.m3.1.1.1.1" xref="S3.SS2.p6.3.m3.1.1.1.1.1.cmml"><mo id="S3.SS2.p6.3.m3.1.1.1.1.2" stretchy="false" xref="S3.SS2.p6.3.m3.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS2.p6.3.m3.1.1.1.1.1" xref="S3.SS2.p6.3.m3.1.1.1.1.1.cmml"><mn id="S3.SS2.p6.3.m3.1.1.1.1.1.2" xref="S3.SS2.p6.3.m3.1.1.1.1.1.2.cmml">1</mn><mo id="S3.SS2.p6.3.m3.1.1.1.1.1.1" lspace="0.278em" rspace="0.278em" xref="S3.SS2.p6.3.m3.1.1.1.1.1.1.cmml">:</mo><mi id="S3.SS2.p6.3.m3.1.1.1.1.1.3" xref="S3.SS2.p6.3.m3.1.1.1.1.1.3.cmml">N</mi></mrow><mo id="S3.SS2.p6.3.m3.1.1.1.1.3" stretchy="false" xref="S3.SS2.p6.3.m3.1.1.1.1.1.cmml">)</mo></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.3.m3.1b"><apply id="S3.SS2.p6.3.m3.1.2.cmml" xref="S3.SS2.p6.3.m3.1.2"><csymbol cd="ambiguous" id="S3.SS2.p6.3.m3.1.2.1.cmml" xref="S3.SS2.p6.3.m3.1.2">subscript</csymbol><apply id="S3.SS2.p6.3.m3.1.2.2.cmml" xref="S3.SS2.p6.3.m3.1.2"><csymbol cd="ambiguous" id="S3.SS2.p6.3.m3.1.2.2.1.cmml" xref="S3.SS2.p6.3.m3.1.2">superscript</csymbol><ci id="S3.SS2.p6.3.m3.1.2.2.2.cmml" xref="S3.SS2.p6.3.m3.1.2.2.2">ğ±</ci><apply id="S3.SS2.p6.3.m3.1.1.1.1.1.cmml" xref="S3.SS2.p6.3.m3.1.1.1.1"><ci id="S3.SS2.p6.3.m3.1.1.1.1.1.1.cmml" xref="S3.SS2.p6.3.m3.1.1.1.1.1.1">:</ci><cn id="S3.SS2.p6.3.m3.1.1.1.1.1.2.cmml" type="integer" xref="S3.SS2.p6.3.m3.1.1.1.1.1.2">1</cn><ci id="S3.SS2.p6.3.m3.1.1.1.1.1.3.cmml" xref="S3.SS2.p6.3.m3.1.1.1.1.1.3">ğ‘</ci></apply></apply><ci id="S3.SS2.p6.3.m3.1.2.3.cmml" xref="S3.SS2.p6.3.m3.1.2.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.3.m3.1c">\mathbf{x}^{(1:N)}_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p6.3.m3.1d">bold_x start_POSTSUPERSCRIPT ( 1 : italic_N ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> in our multi-view diffusion process.
To impose viewpoint information,
we deploy an encoder to project the camera angles and time embedding to the latent image space, which is then added to each novel viewâ€™s feature embedding <math alttext="\mathbf{x}^{(1:N)}_{t}" class="ltx_Math" display="inline" id="S3.SS2.p6.4.m4.1"><semantics id="S3.SS2.p6.4.m4.1a"><msubsup id="S3.SS2.p6.4.m4.1.2" xref="S3.SS2.p6.4.m4.1.2.cmml"><mi id="S3.SS2.p6.4.m4.1.2.2.2" xref="S3.SS2.p6.4.m4.1.2.2.2.cmml">ğ±</mi><mi id="S3.SS2.p6.4.m4.1.2.3" xref="S3.SS2.p6.4.m4.1.2.3.cmml">t</mi><mrow id="S3.SS2.p6.4.m4.1.1.1.1" xref="S3.SS2.p6.4.m4.1.1.1.1.1.cmml"><mo id="S3.SS2.p6.4.m4.1.1.1.1.2" stretchy="false" xref="S3.SS2.p6.4.m4.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS2.p6.4.m4.1.1.1.1.1" xref="S3.SS2.p6.4.m4.1.1.1.1.1.cmml"><mn id="S3.SS2.p6.4.m4.1.1.1.1.1.2" xref="S3.SS2.p6.4.m4.1.1.1.1.1.2.cmml">1</mn><mo id="S3.SS2.p6.4.m4.1.1.1.1.1.1" lspace="0.278em" rspace="0.278em" xref="S3.SS2.p6.4.m4.1.1.1.1.1.1.cmml">:</mo><mi id="S3.SS2.p6.4.m4.1.1.1.1.1.3" xref="S3.SS2.p6.4.m4.1.1.1.1.1.3.cmml">N</mi></mrow><mo id="S3.SS2.p6.4.m4.1.1.1.1.3" stretchy="false" xref="S3.SS2.p6.4.m4.1.1.1.1.1.cmml">)</mo></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.4.m4.1b"><apply id="S3.SS2.p6.4.m4.1.2.cmml" xref="S3.SS2.p6.4.m4.1.2"><csymbol cd="ambiguous" id="S3.SS2.p6.4.m4.1.2.1.cmml" xref="S3.SS2.p6.4.m4.1.2">subscript</csymbol><apply id="S3.SS2.p6.4.m4.1.2.2.cmml" xref="S3.SS2.p6.4.m4.1.2"><csymbol cd="ambiguous" id="S3.SS2.p6.4.m4.1.2.2.1.cmml" xref="S3.SS2.p6.4.m4.1.2">superscript</csymbol><ci id="S3.SS2.p6.4.m4.1.2.2.2.cmml" xref="S3.SS2.p6.4.m4.1.2.2.2">ğ±</ci><apply id="S3.SS2.p6.4.m4.1.1.1.1.1.cmml" xref="S3.SS2.p6.4.m4.1.1.1.1"><ci id="S3.SS2.p6.4.m4.1.1.1.1.1.1.cmml" xref="S3.SS2.p6.4.m4.1.1.1.1.1.1">:</ci><cn id="S3.SS2.p6.4.m4.1.1.1.1.1.2.cmml" type="integer" xref="S3.SS2.p6.4.m4.1.1.1.1.1.2">1</cn><ci id="S3.SS2.p6.4.m4.1.1.1.1.1.3.cmml" xref="S3.SS2.p6.4.m4.1.1.1.1.1.3">ğ‘</ci></apply></apply><ci id="S3.SS2.p6.4.m4.1.2.3.cmml" xref="S3.SS2.p6.4.m4.1.2.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.4.m4.1c">\mathbf{x}^{(1:N)}_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p6.4.m4.1d">bold_x start_POSTSUPERSCRIPT ( 1 : italic_N ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> respectively.
To represent these views in 3D space,
we construct a 3D volume with its vertex <math alttext="\mathbb{V}\in\mathbb{R}^{L\times L\times L}" class="ltx_Math" display="inline" id="S3.SS2.p6.5.m5.1"><semantics id="S3.SS2.p6.5.m5.1a"><mrow id="S3.SS2.p6.5.m5.1.1" xref="S3.SS2.p6.5.m5.1.1.cmml"><mi id="S3.SS2.p6.5.m5.1.1.2" xref="S3.SS2.p6.5.m5.1.1.2.cmml">ğ•</mi><mo id="S3.SS2.p6.5.m5.1.1.1" xref="S3.SS2.p6.5.m5.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS2.p6.5.m5.1.1.3" xref="S3.SS2.p6.5.m5.1.1.3.cmml"><mi id="S3.SS2.p6.5.m5.1.1.3.2" xref="S3.SS2.p6.5.m5.1.1.3.2.cmml">â„</mi><mrow id="S3.SS2.p6.5.m5.1.1.3.3" xref="S3.SS2.p6.5.m5.1.1.3.3.cmml"><mi id="S3.SS2.p6.5.m5.1.1.3.3.2" xref="S3.SS2.p6.5.m5.1.1.3.3.2.cmml">L</mi><mo id="S3.SS2.p6.5.m5.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S3.SS2.p6.5.m5.1.1.3.3.1.cmml">Ã—</mo><mi id="S3.SS2.p6.5.m5.1.1.3.3.3" xref="S3.SS2.p6.5.m5.1.1.3.3.3.cmml">L</mi><mo id="S3.SS2.p6.5.m5.1.1.3.3.1a" lspace="0.222em" rspace="0.222em" xref="S3.SS2.p6.5.m5.1.1.3.3.1.cmml">Ã—</mo><mi id="S3.SS2.p6.5.m5.1.1.3.3.4" xref="S3.SS2.p6.5.m5.1.1.3.3.4.cmml">L</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.5.m5.1b"><apply id="S3.SS2.p6.5.m5.1.1.cmml" xref="S3.SS2.p6.5.m5.1.1"><in id="S3.SS2.p6.5.m5.1.1.1.cmml" xref="S3.SS2.p6.5.m5.1.1.1"></in><ci id="S3.SS2.p6.5.m5.1.1.2.cmml" xref="S3.SS2.p6.5.m5.1.1.2">ğ•</ci><apply id="S3.SS2.p6.5.m5.1.1.3.cmml" xref="S3.SS2.p6.5.m5.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p6.5.m5.1.1.3.1.cmml" xref="S3.SS2.p6.5.m5.1.1.3">superscript</csymbol><ci id="S3.SS2.p6.5.m5.1.1.3.2.cmml" xref="S3.SS2.p6.5.m5.1.1.3.2">â„</ci><apply id="S3.SS2.p6.5.m5.1.1.3.3.cmml" xref="S3.SS2.p6.5.m5.1.1.3.3"><times id="S3.SS2.p6.5.m5.1.1.3.3.1.cmml" xref="S3.SS2.p6.5.m5.1.1.3.3.1"></times><ci id="S3.SS2.p6.5.m5.1.1.3.3.2.cmml" xref="S3.SS2.p6.5.m5.1.1.3.3.2">ğ¿</ci><ci id="S3.SS2.p6.5.m5.1.1.3.3.3.cmml" xref="S3.SS2.p6.5.m5.1.1.3.3.3">ğ¿</ci><ci id="S3.SS2.p6.5.m5.1.1.3.3.4.cmml" xref="S3.SS2.p6.5.m5.1.1.3.3.4">ğ¿</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.5.m5.1c">\mathbb{V}\in\mathbb{R}^{L\times L\times L}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p6.5.m5.1d">blackboard_V âˆˆ blackboard_R start_POSTSUPERSCRIPT italic_L Ã— italic_L Ã— italic_L end_POSTSUPERSCRIPT</annotation></semantics></math> extracted by linear sampling along each dimension (where <math alttext="L" class="ltx_Math" display="inline" id="S3.SS2.p6.6.m6.1"><semantics id="S3.SS2.p6.6.m6.1a"><mi id="S3.SS2.p6.6.m6.1.1" xref="S3.SS2.p6.6.m6.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.6.m6.1b"><ci id="S3.SS2.p6.6.m6.1.1.cmml" xref="S3.SS2.p6.6.m6.1.1">ğ¿</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.6.m6.1c">L</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p6.6.m6.1d">italic_L</annotation></semantics></math> is the number of voxels in each dimension).
For each novel view <math alttext="n" class="ltx_Math" display="inline" id="S3.SS2.p6.7.m7.1"><semantics id="S3.SS2.p6.7.m7.1a"><mi id="S3.SS2.p6.7.m7.1.1" xref="S3.SS2.p6.7.m7.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.7.m7.1b"><ci id="S3.SS2.p6.7.m7.1.1.cmml" xref="S3.SS2.p6.7.m7.1.1">ğ‘›</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.7.m7.1c">n</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p6.7.m7.1d">italic_n</annotation></semantics></math>, we then warp <math alttext="\mathbb{V}" class="ltx_Math" display="inline" id="S3.SS2.p6.8.m8.1"><semantics id="S3.SS2.p6.8.m8.1a"><mi id="S3.SS2.p6.8.m8.1.1" xref="S3.SS2.p6.8.m8.1.1.cmml">ğ•</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.8.m8.1b"><ci id="S3.SS2.p6.8.m8.1.1.cmml" xref="S3.SS2.p6.8.m8.1.1">ğ•</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.8.m8.1c">\mathbb{V}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p6.8.m8.1d">blackboard_V</annotation></semantics></math> according to this viewâ€™s extrinsic camera parameters into which the viewâ€™s feature embedding <math alttext="\mathbf{x}^{(n)}_{t}" class="ltx_Math" display="inline" id="S3.SS2.p6.9.m9.1"><semantics id="S3.SS2.p6.9.m9.1a"><msubsup id="S3.SS2.p6.9.m9.1.2" xref="S3.SS2.p6.9.m9.1.2.cmml"><mi id="S3.SS2.p6.9.m9.1.2.2.2" xref="S3.SS2.p6.9.m9.1.2.2.2.cmml">ğ±</mi><mi id="S3.SS2.p6.9.m9.1.2.3" xref="S3.SS2.p6.9.m9.1.2.3.cmml">t</mi><mrow id="S3.SS2.p6.9.m9.1.1.1.3" xref="S3.SS2.p6.9.m9.1.2.cmml"><mo id="S3.SS2.p6.9.m9.1.1.1.3.1" stretchy="false" xref="S3.SS2.p6.9.m9.1.2.cmml">(</mo><mi id="S3.SS2.p6.9.m9.1.1.1.1" xref="S3.SS2.p6.9.m9.1.1.1.1.cmml">n</mi><mo id="S3.SS2.p6.9.m9.1.1.1.3.2" stretchy="false" xref="S3.SS2.p6.9.m9.1.2.cmml">)</mo></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.9.m9.1b"><apply id="S3.SS2.p6.9.m9.1.2.cmml" xref="S3.SS2.p6.9.m9.1.2"><csymbol cd="ambiguous" id="S3.SS2.p6.9.m9.1.2.1.cmml" xref="S3.SS2.p6.9.m9.1.2">subscript</csymbol><apply id="S3.SS2.p6.9.m9.1.2.2.cmml" xref="S3.SS2.p6.9.m9.1.2"><csymbol cd="ambiguous" id="S3.SS2.p6.9.m9.1.2.2.1.cmml" xref="S3.SS2.p6.9.m9.1.2">superscript</csymbol><ci id="S3.SS2.p6.9.m9.1.2.2.2.cmml" xref="S3.SS2.p6.9.m9.1.2.2.2">ğ±</ci><ci id="S3.SS2.p6.9.m9.1.1.1.1.cmml" xref="S3.SS2.p6.9.m9.1.1.1.1">ğ‘›</ci></apply><ci id="S3.SS2.p6.9.m9.1.2.3.cmml" xref="S3.SS2.p6.9.m9.1.2.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.9.m9.1c">\mathbf{x}^{(n)}_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p6.9.m9.1d">bold_x start_POSTSUPERSCRIPT ( italic_n ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> is interpolated.
This results in an <span class="ltx_text ltx_font_italic" id="S3.SS2.p6.11.1">appearance feature volume</span> <math alttext="F_{a}" class="ltx_Math" display="inline" id="S3.SS2.p6.10.m10.1"><semantics id="S3.SS2.p6.10.m10.1a"><msub id="S3.SS2.p6.10.m10.1.1" xref="S3.SS2.p6.10.m10.1.1.cmml"><mi id="S3.SS2.p6.10.m10.1.1.2" xref="S3.SS2.p6.10.m10.1.1.2.cmml">F</mi><mi id="S3.SS2.p6.10.m10.1.1.3" xref="S3.SS2.p6.10.m10.1.1.3.cmml">a</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.10.m10.1b"><apply id="S3.SS2.p6.10.m10.1.1.cmml" xref="S3.SS2.p6.10.m10.1.1"><csymbol cd="ambiguous" id="S3.SS2.p6.10.m10.1.1.1.cmml" xref="S3.SS2.p6.10.m10.1.1">subscript</csymbol><ci id="S3.SS2.p6.10.m10.1.1.2.cmml" xref="S3.SS2.p6.10.m10.1.1.2">ğ¹</ci><ci id="S3.SS2.p6.10.m10.1.1.3.cmml" xref="S3.SS2.p6.10.m10.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.10.m10.1c">F_{a}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p6.10.m10.1d">italic_F start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT</annotation></semantics></math> containing <math alttext="N" class="ltx_Math" display="inline" id="S3.SS2.p6.11.m11.1"><semantics id="S3.SS2.p6.11.m11.1a"><mi id="S3.SS2.p6.11.m11.1.1" xref="S3.SS2.p6.11.m11.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.11.m11.1b"><ci id="S3.SS2.p6.11.m11.1.1.cmml" xref="S3.SS2.p6.11.m11.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.11.m11.1c">N</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p6.11.m11.1d">italic_N</annotation></semantics></math> noisy target view features.</p>
</div>
<div class="ltx_para" id="S3.SS2.p7">
<p class="ltx_p" id="S3.SS2.p7.7">To integrate the geometry prior from the estimated mesh <math alttext="\mathbb{M}" class="ltx_Math" display="inline" id="S3.SS2.p7.1.m1.1"><semantics id="S3.SS2.p7.1.m1.1a"><mi id="S3.SS2.p7.1.m1.1.1" xref="S3.SS2.p7.1.m1.1.1.cmml">ğ•„</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p7.1.m1.1b"><ci id="S3.SS2.p7.1.m1.1.1.cmml" xref="S3.SS2.p7.1.m1.1.1">ğ•„</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p7.1.m1.1c">\mathbb{M}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p7.1.m1.1d">blackboard_M</annotation></semantics></math>,
we adopt a sparse 3D ConvNet <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib15" title="">15</a>]</cite> to interpolate <math alttext="F_{a}" class="ltx_Math" display="inline" id="S3.SS2.p7.2.m2.1"><semantics id="S3.SS2.p7.2.m2.1a"><msub id="S3.SS2.p7.2.m2.1.1" xref="S3.SS2.p7.2.m2.1.1.cmml"><mi id="S3.SS2.p7.2.m2.1.1.2" xref="S3.SS2.p7.2.m2.1.1.2.cmml">F</mi><mi id="S3.SS2.p7.2.m2.1.1.3" xref="S3.SS2.p7.2.m2.1.1.3.cmml">a</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p7.2.m2.1b"><apply id="S3.SS2.p7.2.m2.1.1.cmml" xref="S3.SS2.p7.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p7.2.m2.1.1.1.cmml" xref="S3.SS2.p7.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.p7.2.m2.1.1.2.cmml" xref="S3.SS2.p7.2.m2.1.1.2">ğ¹</ci><ci id="S3.SS2.p7.2.m2.1.1.3.cmml" xref="S3.SS2.p7.2.m2.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p7.2.m2.1c">F_{a}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p7.2.m2.1d">italic_F start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT</annotation></semantics></math> with <math alttext="\mathbb{M}" class="ltx_Math" display="inline" id="S3.SS2.p7.3.m3.1"><semantics id="S3.SS2.p7.3.m3.1a"><mi id="S3.SS2.p7.3.m3.1.1" xref="S3.SS2.p7.3.m3.1.1.cmml">ğ•„</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p7.3.m3.1b"><ci id="S3.SS2.p7.3.m3.1.1.cmml" xref="S3.SS2.p7.3.m3.1.1">ğ•„</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p7.3.m3.1c">\mathbb{M}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p7.3.m3.1d">blackboard_M</annotation></semantics></math>,
leading to a <span class="ltx_text ltx_font_italic" id="S3.SS2.p7.7.1">hybrid feature volume</span> <math alttext="F_{ag}" class="ltx_Math" display="inline" id="S3.SS2.p7.4.m4.1"><semantics id="S3.SS2.p7.4.m4.1a"><msub id="S3.SS2.p7.4.m4.1.1" xref="S3.SS2.p7.4.m4.1.1.cmml"><mi id="S3.SS2.p7.4.m4.1.1.2" xref="S3.SS2.p7.4.m4.1.1.2.cmml">F</mi><mrow id="S3.SS2.p7.4.m4.1.1.3" xref="S3.SS2.p7.4.m4.1.1.3.cmml"><mi id="S3.SS2.p7.4.m4.1.1.3.2" xref="S3.SS2.p7.4.m4.1.1.3.2.cmml">a</mi><mo id="S3.SS2.p7.4.m4.1.1.3.1" xref="S3.SS2.p7.4.m4.1.1.3.1.cmml">â¢</mo><mi id="S3.SS2.p7.4.m4.1.1.3.3" xref="S3.SS2.p7.4.m4.1.1.3.3.cmml">g</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p7.4.m4.1b"><apply id="S3.SS2.p7.4.m4.1.1.cmml" xref="S3.SS2.p7.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.p7.4.m4.1.1.1.cmml" xref="S3.SS2.p7.4.m4.1.1">subscript</csymbol><ci id="S3.SS2.p7.4.m4.1.1.2.cmml" xref="S3.SS2.p7.4.m4.1.1.2">ğ¹</ci><apply id="S3.SS2.p7.4.m4.1.1.3.cmml" xref="S3.SS2.p7.4.m4.1.1.3"><times id="S3.SS2.p7.4.m4.1.1.3.1.cmml" xref="S3.SS2.p7.4.m4.1.1.3.1"></times><ci id="S3.SS2.p7.4.m4.1.1.3.2.cmml" xref="S3.SS2.p7.4.m4.1.1.3.2">ğ‘</ci><ci id="S3.SS2.p7.4.m4.1.1.3.3.cmml" xref="S3.SS2.p7.4.m4.1.1.3.3">ğ‘”</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p7.4.m4.1c">F_{ag}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p7.4.m4.1d">italic_F start_POSTSUBSCRIPT italic_a italic_g end_POSTSUBSCRIPT</annotation></semantics></math> with both appearance and geometry information.
With <math alttext="F_{ag}" class="ltx_Math" display="inline" id="S3.SS2.p7.5.m5.1"><semantics id="S3.SS2.p7.5.m5.1a"><msub id="S3.SS2.p7.5.m5.1.1" xref="S3.SS2.p7.5.m5.1.1.cmml"><mi id="S3.SS2.p7.5.m5.1.1.2" xref="S3.SS2.p7.5.m5.1.1.2.cmml">F</mi><mrow id="S3.SS2.p7.5.m5.1.1.3" xref="S3.SS2.p7.5.m5.1.1.3.cmml"><mi id="S3.SS2.p7.5.m5.1.1.3.2" xref="S3.SS2.p7.5.m5.1.1.3.2.cmml">a</mi><mo id="S3.SS2.p7.5.m5.1.1.3.1" xref="S3.SS2.p7.5.m5.1.1.3.1.cmml">â¢</mo><mi id="S3.SS2.p7.5.m5.1.1.3.3" xref="S3.SS2.p7.5.m5.1.1.3.3.cmml">g</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p7.5.m5.1b"><apply id="S3.SS2.p7.5.m5.1.1.cmml" xref="S3.SS2.p7.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.p7.5.m5.1.1.1.cmml" xref="S3.SS2.p7.5.m5.1.1">subscript</csymbol><ci id="S3.SS2.p7.5.m5.1.1.2.cmml" xref="S3.SS2.p7.5.m5.1.1.2">ğ¹</ci><apply id="S3.SS2.p7.5.m5.1.1.3.cmml" xref="S3.SS2.p7.5.m5.1.1.3"><times id="S3.SS2.p7.5.m5.1.1.3.1.cmml" xref="S3.SS2.p7.5.m5.1.1.3.1"></times><ci id="S3.SS2.p7.5.m5.1.1.3.2.cmml" xref="S3.SS2.p7.5.m5.1.1.3.2">ğ‘</ci><ci id="S3.SS2.p7.5.m5.1.1.3.3.cmml" xref="S3.SS2.p7.5.m5.1.1.3.3">ğ‘”</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p7.5.m5.1c">F_{ag}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p7.5.m5.1d">italic_F start_POSTSUBSCRIPT italic_a italic_g end_POSTSUBSCRIPT</annotation></semantics></math>, we produce the <span class="ltx_text ltx_font_italic" id="S3.SS2.p7.7.2">view frustum volume</span> <math alttext="F_{vf}" class="ltx_Math" display="inline" id="S3.SS2.p7.6.m6.1"><semantics id="S3.SS2.p7.6.m6.1a"><msub id="S3.SS2.p7.6.m6.1.1" xref="S3.SS2.p7.6.m6.1.1.cmml"><mi id="S3.SS2.p7.6.m6.1.1.2" xref="S3.SS2.p7.6.m6.1.1.2.cmml">F</mi><mrow id="S3.SS2.p7.6.m6.1.1.3" xref="S3.SS2.p7.6.m6.1.1.3.cmml"><mi id="S3.SS2.p7.6.m6.1.1.3.2" xref="S3.SS2.p7.6.m6.1.1.3.2.cmml">v</mi><mo id="S3.SS2.p7.6.m6.1.1.3.1" xref="S3.SS2.p7.6.m6.1.1.3.1.cmml">â¢</mo><mi id="S3.SS2.p7.6.m6.1.1.3.3" xref="S3.SS2.p7.6.m6.1.1.3.3.cmml">f</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p7.6.m6.1b"><apply id="S3.SS2.p7.6.m6.1.1.cmml" xref="S3.SS2.p7.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS2.p7.6.m6.1.1.1.cmml" xref="S3.SS2.p7.6.m6.1.1">subscript</csymbol><ci id="S3.SS2.p7.6.m6.1.1.2.cmml" xref="S3.SS2.p7.6.m6.1.1.2">ğ¹</ci><apply id="S3.SS2.p7.6.m6.1.1.3.cmml" xref="S3.SS2.p7.6.m6.1.1.3"><times id="S3.SS2.p7.6.m6.1.1.3.1.cmml" xref="S3.SS2.p7.6.m6.1.1.3.1"></times><ci id="S3.SS2.p7.6.m6.1.1.3.2.cmml" xref="S3.SS2.p7.6.m6.1.1.3.2">ğ‘£</ci><ci id="S3.SS2.p7.6.m6.1.1.3.3.cmml" xref="S3.SS2.p7.6.m6.1.1.3.3">ğ‘“</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p7.6.m6.1c">F_{vf}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p7.6.m6.1d">italic_F start_POSTSUBSCRIPT italic_v italic_f end_POSTSUBSCRIPT</annotation></semantics></math> with a light FrustumTV3DNet <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib30" title="">30</a>]</cite>.
This <math alttext="F_{vf}" class="ltx_Math" display="inline" id="S3.SS2.p7.7.m7.1"><semantics id="S3.SS2.p7.7.m7.1a"><msub id="S3.SS2.p7.7.m7.1.1" xref="S3.SS2.p7.7.m7.1.1.cmml"><mi id="S3.SS2.p7.7.m7.1.1.2" xref="S3.SS2.p7.7.m7.1.1.2.cmml">F</mi><mrow id="S3.SS2.p7.7.m7.1.1.3" xref="S3.SS2.p7.7.m7.1.1.3.cmml"><mi id="S3.SS2.p7.7.m7.1.1.3.2" xref="S3.SS2.p7.7.m7.1.1.3.2.cmml">v</mi><mo id="S3.SS2.p7.7.m7.1.1.3.1" xref="S3.SS2.p7.7.m7.1.1.3.1.cmml">â¢</mo><mi id="S3.SS2.p7.7.m7.1.1.3.3" xref="S3.SS2.p7.7.m7.1.1.3.3.cmml">f</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p7.7.m7.1b"><apply id="S3.SS2.p7.7.m7.1.1.cmml" xref="S3.SS2.p7.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS2.p7.7.m7.1.1.1.cmml" xref="S3.SS2.p7.7.m7.1.1">subscript</csymbol><ci id="S3.SS2.p7.7.m7.1.1.2.cmml" xref="S3.SS2.p7.7.m7.1.1.2">ğ¹</ci><apply id="S3.SS2.p7.7.m7.1.1.3.cmml" xref="S3.SS2.p7.7.m7.1.1.3"><times id="S3.SS2.p7.7.m7.1.1.3.1.cmml" xref="S3.SS2.p7.7.m7.1.1.3.1"></times><ci id="S3.SS2.p7.7.m7.1.1.3.2.cmml" xref="S3.SS2.p7.7.m7.1.1.3.2">ğ‘£</ci><ci id="S3.SS2.p7.7.m7.1.1.3.3.cmml" xref="S3.SS2.p7.7.m7.1.1.3.3">ğ‘“</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p7.7.m7.1c">F_{vf}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p7.7.m7.1d">italic_F start_POSTSUBSCRIPT italic_v italic_f end_POSTSUBSCRIPT</annotation></semantics></math> would then serve as a joint condition for multi-view diffusion
by injecting into the backbone diffusion model (e.g., Stable Diffusionâ€™s UNet).</p>
</div>
<div class="ltx_para" id="S3.SS2.p8">
<p class="ltx_p" id="S3.SS2.p8.5">As seen from Eq (<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#S3.E2" title="Equation 2 â€£ 3.1 Preliminaries: 2D Diffusion and 3D Diffusion â€£ 3 Method â€£ Single Image, Any Face: Generalisable 3D Face Generation"><span class="ltx_text ltx_ref_tag">2</span></a>), previous methods <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib7" title="">7</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib30" title="">30</a>]</cite> often denoise a single view each time individually with condition on the previous stepâ€™s output of all the views.
This design requires <math alttext="N" class="ltx_Math" display="inline" id="S3.SS2.p8.1.m1.1"><semantics id="S3.SS2.p8.1.m1.1a"><mi id="S3.SS2.p8.1.m1.1.1" xref="S3.SS2.p8.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p8.1.m1.1b"><ci id="S3.SS2.p8.1.m1.1.1.cmml" xref="S3.SS2.p8.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p8.1.m1.1c">N</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p8.1.m1.1d">italic_N</annotation></semantics></math> denoising times each for one view, which we consider is inferior in maintaining the view consistency.
To overcome this issue, we propose a <span class="ltx_text ltx_font_bold ltx_font_italic" id="S3.SS2.p8.5.1">multi-view joint generation</span> algorithm that instead denoises all the views concurrently at one time so that multi-view information interaction can be imposed and exploited.
Specifically, instead of feeding one view <math alttext="\mathbf{x}^{(n)}_{t}" class="ltx_Math" display="inline" id="S3.SS2.p8.2.m2.1"><semantics id="S3.SS2.p8.2.m2.1a"><msubsup id="S3.SS2.p8.2.m2.1.2" xref="S3.SS2.p8.2.m2.1.2.cmml"><mi id="S3.SS2.p8.2.m2.1.2.2.2" xref="S3.SS2.p8.2.m2.1.2.2.2.cmml">ğ±</mi><mi id="S3.SS2.p8.2.m2.1.2.3" xref="S3.SS2.p8.2.m2.1.2.3.cmml">t</mi><mrow id="S3.SS2.p8.2.m2.1.1.1.3" xref="S3.SS2.p8.2.m2.1.2.cmml"><mo id="S3.SS2.p8.2.m2.1.1.1.3.1" stretchy="false" xref="S3.SS2.p8.2.m2.1.2.cmml">(</mo><mi id="S3.SS2.p8.2.m2.1.1.1.1" xref="S3.SS2.p8.2.m2.1.1.1.1.cmml">n</mi><mo id="S3.SS2.p8.2.m2.1.1.1.3.2" stretchy="false" xref="S3.SS2.p8.2.m2.1.2.cmml">)</mo></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p8.2.m2.1b"><apply id="S3.SS2.p8.2.m2.1.2.cmml" xref="S3.SS2.p8.2.m2.1.2"><csymbol cd="ambiguous" id="S3.SS2.p8.2.m2.1.2.1.cmml" xref="S3.SS2.p8.2.m2.1.2">subscript</csymbol><apply id="S3.SS2.p8.2.m2.1.2.2.cmml" xref="S3.SS2.p8.2.m2.1.2"><csymbol cd="ambiguous" id="S3.SS2.p8.2.m2.1.2.2.1.cmml" xref="S3.SS2.p8.2.m2.1.2">superscript</csymbol><ci id="S3.SS2.p8.2.m2.1.2.2.2.cmml" xref="S3.SS2.p8.2.m2.1.2.2.2">ğ±</ci><ci id="S3.SS2.p8.2.m2.1.1.1.1.cmml" xref="S3.SS2.p8.2.m2.1.1.1.1">ğ‘›</ci></apply><ci id="S3.SS2.p8.2.m2.1.2.3.cmml" xref="S3.SS2.p8.2.m2.1.2.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p8.2.m2.1c">\mathbf{x}^{(n)}_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p8.2.m2.1d">bold_x start_POSTSUPERSCRIPT ( italic_n ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> as the decoderâ€™s query at a time,
we input all the views <math alttext="\mathbf{x}^{(1:N)}_{t}" class="ltx_Math" display="inline" id="S3.SS2.p8.3.m3.1"><semantics id="S3.SS2.p8.3.m3.1a"><msubsup id="S3.SS2.p8.3.m3.1.2" xref="S3.SS2.p8.3.m3.1.2.cmml"><mi id="S3.SS2.p8.3.m3.1.2.2.2" xref="S3.SS2.p8.3.m3.1.2.2.2.cmml">ğ±</mi><mi id="S3.SS2.p8.3.m3.1.2.3" xref="S3.SS2.p8.3.m3.1.2.3.cmml">t</mi><mrow id="S3.SS2.p8.3.m3.1.1.1.1" xref="S3.SS2.p8.3.m3.1.1.1.1.1.cmml"><mo id="S3.SS2.p8.3.m3.1.1.1.1.2" stretchy="false" xref="S3.SS2.p8.3.m3.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS2.p8.3.m3.1.1.1.1.1" xref="S3.SS2.p8.3.m3.1.1.1.1.1.cmml"><mn id="S3.SS2.p8.3.m3.1.1.1.1.1.2" xref="S3.SS2.p8.3.m3.1.1.1.1.1.2.cmml">1</mn><mo id="S3.SS2.p8.3.m3.1.1.1.1.1.1" lspace="0.278em" rspace="0.278em" xref="S3.SS2.p8.3.m3.1.1.1.1.1.1.cmml">:</mo><mi id="S3.SS2.p8.3.m3.1.1.1.1.1.3" xref="S3.SS2.p8.3.m3.1.1.1.1.1.3.cmml">N</mi></mrow><mo id="S3.SS2.p8.3.m3.1.1.1.1.3" stretchy="false" xref="S3.SS2.p8.3.m3.1.1.1.1.1.cmml">)</mo></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p8.3.m3.1b"><apply id="S3.SS2.p8.3.m3.1.2.cmml" xref="S3.SS2.p8.3.m3.1.2"><csymbol cd="ambiguous" id="S3.SS2.p8.3.m3.1.2.1.cmml" xref="S3.SS2.p8.3.m3.1.2">subscript</csymbol><apply id="S3.SS2.p8.3.m3.1.2.2.cmml" xref="S3.SS2.p8.3.m3.1.2"><csymbol cd="ambiguous" id="S3.SS2.p8.3.m3.1.2.2.1.cmml" xref="S3.SS2.p8.3.m3.1.2">superscript</csymbol><ci id="S3.SS2.p8.3.m3.1.2.2.2.cmml" xref="S3.SS2.p8.3.m3.1.2.2.2">ğ±</ci><apply id="S3.SS2.p8.3.m3.1.1.1.1.1.cmml" xref="S3.SS2.p8.3.m3.1.1.1.1"><ci id="S3.SS2.p8.3.m3.1.1.1.1.1.1.cmml" xref="S3.SS2.p8.3.m3.1.1.1.1.1.1">:</ci><cn id="S3.SS2.p8.3.m3.1.1.1.1.1.2.cmml" type="integer" xref="S3.SS2.p8.3.m3.1.1.1.1.1.2">1</cn><ci id="S3.SS2.p8.3.m3.1.1.1.1.1.3.cmml" xref="S3.SS2.p8.3.m3.1.1.1.1.1.3">ğ‘</ci></apply></apply><ci id="S3.SS2.p8.3.m3.1.2.3.cmml" xref="S3.SS2.p8.3.m3.1.2.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p8.3.m3.1c">\mathbf{x}^{(1:N)}_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p8.3.m3.1d">bold_x start_POSTSUPERSCRIPT ( 1 : italic_N ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> together.
This difference enables us to additionally perform the 3D self attention operation <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib48" title="">48</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib3" title="">3</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib68" title="">68</a>]</cite> among all the novel views <math alttext="\mathbf{x}^{(1:N)}_{t}" class="ltx_Math" display="inline" id="S3.SS2.p8.4.m4.1"><semantics id="S3.SS2.p8.4.m4.1a"><msubsup id="S3.SS2.p8.4.m4.1.2" xref="S3.SS2.p8.4.m4.1.2.cmml"><mi id="S3.SS2.p8.4.m4.1.2.2.2" xref="S3.SS2.p8.4.m4.1.2.2.2.cmml">ğ±</mi><mi id="S3.SS2.p8.4.m4.1.2.3" xref="S3.SS2.p8.4.m4.1.2.3.cmml">t</mi><mrow id="S3.SS2.p8.4.m4.1.1.1.1" xref="S3.SS2.p8.4.m4.1.1.1.1.1.cmml"><mo id="S3.SS2.p8.4.m4.1.1.1.1.2" stretchy="false" xref="S3.SS2.p8.4.m4.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS2.p8.4.m4.1.1.1.1.1" xref="S3.SS2.p8.4.m4.1.1.1.1.1.cmml"><mn id="S3.SS2.p8.4.m4.1.1.1.1.1.2" xref="S3.SS2.p8.4.m4.1.1.1.1.1.2.cmml">1</mn><mo id="S3.SS2.p8.4.m4.1.1.1.1.1.1" lspace="0.278em" rspace="0.278em" xref="S3.SS2.p8.4.m4.1.1.1.1.1.1.cmml">:</mo><mi id="S3.SS2.p8.4.m4.1.1.1.1.1.3" xref="S3.SS2.p8.4.m4.1.1.1.1.1.3.cmml">N</mi></mrow><mo id="S3.SS2.p8.4.m4.1.1.1.1.3" stretchy="false" xref="S3.SS2.p8.4.m4.1.1.1.1.1.cmml">)</mo></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p8.4.m4.1b"><apply id="S3.SS2.p8.4.m4.1.2.cmml" xref="S3.SS2.p8.4.m4.1.2"><csymbol cd="ambiguous" id="S3.SS2.p8.4.m4.1.2.1.cmml" xref="S3.SS2.p8.4.m4.1.2">subscript</csymbol><apply id="S3.SS2.p8.4.m4.1.2.2.cmml" xref="S3.SS2.p8.4.m4.1.2"><csymbol cd="ambiguous" id="S3.SS2.p8.4.m4.1.2.2.1.cmml" xref="S3.SS2.p8.4.m4.1.2">superscript</csymbol><ci id="S3.SS2.p8.4.m4.1.2.2.2.cmml" xref="S3.SS2.p8.4.m4.1.2.2.2">ğ±</ci><apply id="S3.SS2.p8.4.m4.1.1.1.1.1.cmml" xref="S3.SS2.p8.4.m4.1.1.1.1"><ci id="S3.SS2.p8.4.m4.1.1.1.1.1.1.cmml" xref="S3.SS2.p8.4.m4.1.1.1.1.1.1">:</ci><cn id="S3.SS2.p8.4.m4.1.1.1.1.1.2.cmml" type="integer" xref="S3.SS2.p8.4.m4.1.1.1.1.1.2">1</cn><ci id="S3.SS2.p8.4.m4.1.1.1.1.1.3.cmml" xref="S3.SS2.p8.4.m4.1.1.1.1.1.3">ğ‘</ci></apply></apply><ci id="S3.SS2.p8.4.m4.1.2.3.cmml" xref="S3.SS2.p8.4.m4.1.2.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p8.4.m4.1c">\mathbf{x}^{(1:N)}_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p8.4.m4.1d">bold_x start_POSTSUPERSCRIPT ( 1 : italic_N ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> and the input <math alttext="y" class="ltx_Math" display="inline" id="S3.SS2.p8.5.m5.1"><semantics id="S3.SS2.p8.5.m5.1a"><mi id="S3.SS2.p8.5.m5.1.1" xref="S3.SS2.p8.5.m5.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p8.5.m5.1b"><ci id="S3.SS2.p8.5.m5.1.1.cmml" xref="S3.SS2.p8.5.m5.1.1">ğ‘¦</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p8.5.m5.1c">y</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p8.5.m5.1d">italic_y</annotation></semantics></math>
for information exchange and enhancing view consistency.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p9">
<p class="ltx_p" id="S3.SS2.p9.7"><span class="ltx_text ltx_font_bold" id="S3.SS2.p9.7.1">Model training</span>
Our objective function is a multi-view diffusion loss defined as</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E4">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\ell(\theta)=\mathbb{E}_{t,y,c,\mathbf{x}^{(1:N)}_{0},(1:N),\mathbf{\epsilon}^%
{(1:N)}}\left[\|\mathbf{\epsilon}^{(1:N)}-\mathbf{\epsilon}^{(1:N)}_{\theta}(%
\mathbf{x}^{(1:N)}_{t},t)\|_{2}\right]," class="ltx_Math" display="block" id="S3.E4.m1.14"><semantics id="S3.E4.m1.14a"><mrow id="S3.E4.m1.14.14.1" xref="S3.E4.m1.14.14.1.1.cmml"><mrow id="S3.E4.m1.14.14.1.1" xref="S3.E4.m1.14.14.1.1.cmml"><mrow id="S3.E4.m1.14.14.1.1.3" xref="S3.E4.m1.14.14.1.1.3.cmml"><mi id="S3.E4.m1.14.14.1.1.3.2" mathvariant="normal" xref="S3.E4.m1.14.14.1.1.3.2.cmml">â„“</mi><mo id="S3.E4.m1.14.14.1.1.3.1" xref="S3.E4.m1.14.14.1.1.3.1.cmml">â¢</mo><mrow id="S3.E4.m1.14.14.1.1.3.3.2" xref="S3.E4.m1.14.14.1.1.3.cmml"><mo id="S3.E4.m1.14.14.1.1.3.3.2.1" stretchy="false" xref="S3.E4.m1.14.14.1.1.3.cmml">(</mo><mi id="S3.E4.m1.12.12" xref="S3.E4.m1.12.12.cmml">Î¸</mi><mo id="S3.E4.m1.14.14.1.1.3.3.2.2" stretchy="false" xref="S3.E4.m1.14.14.1.1.3.cmml">)</mo></mrow></mrow><mo id="S3.E4.m1.14.14.1.1.2" xref="S3.E4.m1.14.14.1.1.2.cmml">=</mo><mrow id="S3.E4.m1.14.14.1.1.1" xref="S3.E4.m1.14.14.1.1.1.cmml"><msub id="S3.E4.m1.14.14.1.1.1.3" xref="S3.E4.m1.14.14.1.1.1.3.cmml"><mi id="S3.E4.m1.14.14.1.1.1.3.2" xref="S3.E4.m1.14.14.1.1.1.3.2.cmml">ğ”¼</mi><mrow id="S3.E4.m1.8.8.8.8" xref="S3.E4.m1.8.8.8.9.cmml"><mrow id="S3.E4.m1.6.6.6.6.1.1" xref="S3.E4.m1.6.6.6.6.1.2.cmml"><mi id="S3.E4.m1.3.3.3.3" xref="S3.E4.m1.3.3.3.3.cmml">t</mi><mo id="S3.E4.m1.6.6.6.6.1.1.2" xref="S3.E4.m1.6.6.6.6.1.2.cmml">,</mo><mi id="S3.E4.m1.4.4.4.4" xref="S3.E4.m1.4.4.4.4.cmml">y</mi><mo id="S3.E4.m1.6.6.6.6.1.1.3" xref="S3.E4.m1.6.6.6.6.1.2.cmml">,</mo><mi id="S3.E4.m1.5.5.5.5" xref="S3.E4.m1.5.5.5.5.cmml">c</mi><mo id="S3.E4.m1.6.6.6.6.1.1.4" xref="S3.E4.m1.6.6.6.6.1.2.cmml">,</mo><msubsup id="S3.E4.m1.6.6.6.6.1.1.1" xref="S3.E4.m1.6.6.6.6.1.1.1.cmml"><mi id="S3.E4.m1.6.6.6.6.1.1.1.2.2" xref="S3.E4.m1.6.6.6.6.1.1.1.2.2.cmml">ğ±</mi><mn id="S3.E4.m1.6.6.6.6.1.1.1.3" xref="S3.E4.m1.6.6.6.6.1.1.1.3.cmml">0</mn><mrow id="S3.E4.m1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.1.cmml"><mo id="S3.E4.m1.1.1.1.1.1.1.2" stretchy="false" xref="S3.E4.m1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E4.m1.1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.1.cmml"><mn id="S3.E4.m1.1.1.1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.1.1.1.2.cmml">1</mn><mo id="S3.E4.m1.1.1.1.1.1.1.1.1" lspace="0.278em" rspace="0.278em" xref="S3.E4.m1.1.1.1.1.1.1.1.1.cmml">:</mo><mi id="S3.E4.m1.1.1.1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.1.1.1.3.cmml">N</mi></mrow><mo id="S3.E4.m1.1.1.1.1.1.1.3" stretchy="false" xref="S3.E4.m1.1.1.1.1.1.1.1.cmml">)</mo></mrow></msubsup></mrow><mo id="S3.E4.m1.8.8.8.8.4" xref="S3.E4.m1.8.8.8.9.cmml">,</mo><mrow id="S3.E4.m1.7.7.7.7.2.1" xref="S3.E4.m1.7.7.7.7.2.1.1.cmml"><mo id="S3.E4.m1.7.7.7.7.2.1.2" stretchy="false" xref="S3.E4.m1.7.7.7.7.2.1.1.cmml">(</mo><mrow id="S3.E4.m1.7.7.7.7.2.1.1" xref="S3.E4.m1.7.7.7.7.2.1.1.cmml"><mn id="S3.E4.m1.7.7.7.7.2.1.1.2" xref="S3.E4.m1.7.7.7.7.2.1.1.2.cmml">1</mn><mo id="S3.E4.m1.7.7.7.7.2.1.1.1" lspace="0.278em" rspace="0.278em" xref="S3.E4.m1.7.7.7.7.2.1.1.1.cmml">:</mo><mi id="S3.E4.m1.7.7.7.7.2.1.1.3" xref="S3.E4.m1.7.7.7.7.2.1.1.3.cmml">N</mi></mrow><mo id="S3.E4.m1.7.7.7.7.2.1.3" stretchy="false" xref="S3.E4.m1.7.7.7.7.2.1.1.cmml">)</mo></mrow><mo id="S3.E4.m1.8.8.8.8.5" xref="S3.E4.m1.8.8.8.9.cmml">,</mo><msup id="S3.E4.m1.8.8.8.8.3" xref="S3.E4.m1.8.8.8.8.3.cmml"><mi id="S3.E4.m1.8.8.8.8.3.2" xref="S3.E4.m1.8.8.8.8.3.2.cmml">Ïµ</mi><mrow id="S3.E4.m1.2.2.2.2.1.1" xref="S3.E4.m1.2.2.2.2.1.1.1.cmml"><mo id="S3.E4.m1.2.2.2.2.1.1.2" stretchy="false" xref="S3.E4.m1.2.2.2.2.1.1.1.cmml">(</mo><mrow id="S3.E4.m1.2.2.2.2.1.1.1" xref="S3.E4.m1.2.2.2.2.1.1.1.cmml"><mn id="S3.E4.m1.2.2.2.2.1.1.1.2" xref="S3.E4.m1.2.2.2.2.1.1.1.2.cmml">1</mn><mo id="S3.E4.m1.2.2.2.2.1.1.1.1" lspace="0.278em" rspace="0.278em" xref="S3.E4.m1.2.2.2.2.1.1.1.1.cmml">:</mo><mi id="S3.E4.m1.2.2.2.2.1.1.1.3" xref="S3.E4.m1.2.2.2.2.1.1.1.3.cmml">N</mi></mrow><mo id="S3.E4.m1.2.2.2.2.1.1.3" stretchy="false" xref="S3.E4.m1.2.2.2.2.1.1.1.cmml">)</mo></mrow></msup></mrow></msub><mo id="S3.E4.m1.14.14.1.1.1.2" xref="S3.E4.m1.14.14.1.1.1.2.cmml">â¢</mo><mrow id="S3.E4.m1.14.14.1.1.1.1.1" xref="S3.E4.m1.14.14.1.1.1.1.2.cmml"><mo id="S3.E4.m1.14.14.1.1.1.1.1.2" xref="S3.E4.m1.14.14.1.1.1.1.2.1.cmml">[</mo><msub id="S3.E4.m1.14.14.1.1.1.1.1.1" xref="S3.E4.m1.14.14.1.1.1.1.1.1.cmml"><mrow id="S3.E4.m1.14.14.1.1.1.1.1.1.1.1" xref="S3.E4.m1.14.14.1.1.1.1.1.1.1.2.cmml"><mo id="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.E4.m1.14.14.1.1.1.1.1.1.1.2.1.cmml">â€–</mo><mrow id="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1" xref="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.cmml"><msup id="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.3" xref="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.3.2" xref="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.3.2.cmml">Ïµ</mi><mrow id="S3.E4.m1.9.9.1.1" xref="S3.E4.m1.9.9.1.1.1.cmml"><mo id="S3.E4.m1.9.9.1.1.2" stretchy="false" xref="S3.E4.m1.9.9.1.1.1.cmml">(</mo><mrow id="S3.E4.m1.9.9.1.1.1" xref="S3.E4.m1.9.9.1.1.1.cmml"><mn id="S3.E4.m1.9.9.1.1.1.2" xref="S3.E4.m1.9.9.1.1.1.2.cmml">1</mn><mo id="S3.E4.m1.9.9.1.1.1.1" lspace="0.278em" rspace="0.278em" xref="S3.E4.m1.9.9.1.1.1.1.cmml">:</mo><mi id="S3.E4.m1.9.9.1.1.1.3" xref="S3.E4.m1.9.9.1.1.1.3.cmml">N</mi></mrow><mo id="S3.E4.m1.9.9.1.1.3" stretchy="false" xref="S3.E4.m1.9.9.1.1.1.cmml">)</mo></mrow></msup><mo id="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.2" xref="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.2.cmml">âˆ’</mo><mrow id="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.1" xref="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.1.cmml"><msubsup id="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.1.3.2.2" xref="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.1.3.2.2.cmml">Ïµ</mi><mi id="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.1.3.3" xref="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.1.3.3.cmml">Î¸</mi><mrow id="S3.E4.m1.10.10.1.1" xref="S3.E4.m1.10.10.1.1.1.cmml"><mo id="S3.E4.m1.10.10.1.1.2" stretchy="false" xref="S3.E4.m1.10.10.1.1.1.cmml">(</mo><mrow id="S3.E4.m1.10.10.1.1.1" xref="S3.E4.m1.10.10.1.1.1.cmml"><mn id="S3.E4.m1.10.10.1.1.1.2" xref="S3.E4.m1.10.10.1.1.1.2.cmml">1</mn><mo id="S3.E4.m1.10.10.1.1.1.1" lspace="0.278em" rspace="0.278em" xref="S3.E4.m1.10.10.1.1.1.1.cmml">:</mo><mi id="S3.E4.m1.10.10.1.1.1.3" xref="S3.E4.m1.10.10.1.1.1.3.cmml">N</mi></mrow><mo id="S3.E4.m1.10.10.1.1.3" stretchy="false" xref="S3.E4.m1.10.10.1.1.1.cmml">)</mo></mrow></msubsup><mo id="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.1.2.cmml">â¢</mo><mrow id="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.1.1.2.cmml"><mo id="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.1.1.2.cmml">(</mo><msubsup id="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2" xref="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml">ğ±</mi><mi id="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">t</mi><mrow id="S3.E4.m1.11.11.1.1" xref="S3.E4.m1.11.11.1.1.1.cmml"><mo id="S3.E4.m1.11.11.1.1.2" stretchy="false" xref="S3.E4.m1.11.11.1.1.1.cmml">(</mo><mrow id="S3.E4.m1.11.11.1.1.1" xref="S3.E4.m1.11.11.1.1.1.cmml"><mn id="S3.E4.m1.11.11.1.1.1.2" xref="S3.E4.m1.11.11.1.1.1.2.cmml">1</mn><mo id="S3.E4.m1.11.11.1.1.1.1" lspace="0.278em" rspace="0.278em" xref="S3.E4.m1.11.11.1.1.1.1.cmml">:</mo><mi id="S3.E4.m1.11.11.1.1.1.3" xref="S3.E4.m1.11.11.1.1.1.3.cmml">N</mi></mrow><mo id="S3.E4.m1.11.11.1.1.3" stretchy="false" xref="S3.E4.m1.11.11.1.1.1.cmml">)</mo></mrow></msubsup><mo id="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.1.1.2.cmml">,</mo><mi id="S3.E4.m1.13.13" xref="S3.E4.m1.13.13.cmml">t</mi><mo id="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.1.1.1.4" stretchy="false" xref="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.1.1.2.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S3.E4.m1.14.14.1.1.1.1.1.1.1.2.1.cmml">â€–</mo></mrow><mn id="S3.E4.m1.14.14.1.1.1.1.1.1.3" xref="S3.E4.m1.14.14.1.1.1.1.1.1.3.cmml">2</mn></msub><mo id="S3.E4.m1.14.14.1.1.1.1.1.3" xref="S3.E4.m1.14.14.1.1.1.1.2.1.cmml">]</mo></mrow></mrow></mrow><mo id="S3.E4.m1.14.14.1.2" xref="S3.E4.m1.14.14.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.14b"><apply id="S3.E4.m1.14.14.1.1.cmml" xref="S3.E4.m1.14.14.1"><eq id="S3.E4.m1.14.14.1.1.2.cmml" xref="S3.E4.m1.14.14.1.1.2"></eq><apply id="S3.E4.m1.14.14.1.1.3.cmml" xref="S3.E4.m1.14.14.1.1.3"><times id="S3.E4.m1.14.14.1.1.3.1.cmml" xref="S3.E4.m1.14.14.1.1.3.1"></times><ci id="S3.E4.m1.14.14.1.1.3.2.cmml" xref="S3.E4.m1.14.14.1.1.3.2">â„“</ci><ci id="S3.E4.m1.12.12.cmml" xref="S3.E4.m1.12.12">ğœƒ</ci></apply><apply id="S3.E4.m1.14.14.1.1.1.cmml" xref="S3.E4.m1.14.14.1.1.1"><times id="S3.E4.m1.14.14.1.1.1.2.cmml" xref="S3.E4.m1.14.14.1.1.1.2"></times><apply id="S3.E4.m1.14.14.1.1.1.3.cmml" xref="S3.E4.m1.14.14.1.1.1.3"><csymbol cd="ambiguous" id="S3.E4.m1.14.14.1.1.1.3.1.cmml" xref="S3.E4.m1.14.14.1.1.1.3">subscript</csymbol><ci id="S3.E4.m1.14.14.1.1.1.3.2.cmml" xref="S3.E4.m1.14.14.1.1.1.3.2">ğ”¼</ci><list id="S3.E4.m1.8.8.8.9.cmml" xref="S3.E4.m1.8.8.8.8"><list id="S3.E4.m1.6.6.6.6.1.2.cmml" xref="S3.E4.m1.6.6.6.6.1.1"><ci id="S3.E4.m1.3.3.3.3.cmml" xref="S3.E4.m1.3.3.3.3">ğ‘¡</ci><ci id="S3.E4.m1.4.4.4.4.cmml" xref="S3.E4.m1.4.4.4.4">ğ‘¦</ci><ci id="S3.E4.m1.5.5.5.5.cmml" xref="S3.E4.m1.5.5.5.5">ğ‘</ci><apply id="S3.E4.m1.6.6.6.6.1.1.1.cmml" xref="S3.E4.m1.6.6.6.6.1.1.1"><csymbol cd="ambiguous" id="S3.E4.m1.6.6.6.6.1.1.1.1.cmml" xref="S3.E4.m1.6.6.6.6.1.1.1">subscript</csymbol><apply id="S3.E4.m1.6.6.6.6.1.1.1.2.cmml" xref="S3.E4.m1.6.6.6.6.1.1.1"><csymbol cd="ambiguous" id="S3.E4.m1.6.6.6.6.1.1.1.2.1.cmml" xref="S3.E4.m1.6.6.6.6.1.1.1">superscript</csymbol><ci id="S3.E4.m1.6.6.6.6.1.1.1.2.2.cmml" xref="S3.E4.m1.6.6.6.6.1.1.1.2.2">ğ±</ci><apply id="S3.E4.m1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1"><ci id="S3.E4.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1">:</ci><cn id="S3.E4.m1.1.1.1.1.1.1.1.2.cmml" type="integer" xref="S3.E4.m1.1.1.1.1.1.1.1.2">1</cn><ci id="S3.E4.m1.1.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.3">ğ‘</ci></apply></apply><cn id="S3.E4.m1.6.6.6.6.1.1.1.3.cmml" type="integer" xref="S3.E4.m1.6.6.6.6.1.1.1.3">0</cn></apply></list><apply id="S3.E4.m1.7.7.7.7.2.1.1.cmml" xref="S3.E4.m1.7.7.7.7.2.1"><ci id="S3.E4.m1.7.7.7.7.2.1.1.1.cmml" xref="S3.E4.m1.7.7.7.7.2.1.1.1">:</ci><cn id="S3.E4.m1.7.7.7.7.2.1.1.2.cmml" type="integer" xref="S3.E4.m1.7.7.7.7.2.1.1.2">1</cn><ci id="S3.E4.m1.7.7.7.7.2.1.1.3.cmml" xref="S3.E4.m1.7.7.7.7.2.1.1.3">ğ‘</ci></apply><apply id="S3.E4.m1.8.8.8.8.3.cmml" xref="S3.E4.m1.8.8.8.8.3"><csymbol cd="ambiguous" id="S3.E4.m1.8.8.8.8.3.1.cmml" xref="S3.E4.m1.8.8.8.8.3">superscript</csymbol><ci id="S3.E4.m1.8.8.8.8.3.2.cmml" xref="S3.E4.m1.8.8.8.8.3.2">italic-Ïµ</ci><apply id="S3.E4.m1.2.2.2.2.1.1.1.cmml" xref="S3.E4.m1.2.2.2.2.1.1"><ci id="S3.E4.m1.2.2.2.2.1.1.1.1.cmml" xref="S3.E4.m1.2.2.2.2.1.1.1.1">:</ci><cn id="S3.E4.m1.2.2.2.2.1.1.1.2.cmml" type="integer" xref="S3.E4.m1.2.2.2.2.1.1.1.2">1</cn><ci id="S3.E4.m1.2.2.2.2.1.1.1.3.cmml" xref="S3.E4.m1.2.2.2.2.1.1.1.3">ğ‘</ci></apply></apply></list></apply><apply id="S3.E4.m1.14.14.1.1.1.1.2.cmml" xref="S3.E4.m1.14.14.1.1.1.1.1"><csymbol cd="latexml" id="S3.E4.m1.14.14.1.1.1.1.2.1.cmml" xref="S3.E4.m1.14.14.1.1.1.1.1.2">delimited-[]</csymbol><apply id="S3.E4.m1.14.14.1.1.1.1.1.1.cmml" xref="S3.E4.m1.14.14.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E4.m1.14.14.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.14.14.1.1.1.1.1.1">subscript</csymbol><apply id="S3.E4.m1.14.14.1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.14.14.1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E4.m1.14.14.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.2">norm</csymbol><apply id="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1"><minus id="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.2"></minus><apply id="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.3">superscript</csymbol><ci id="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.3.2">italic-Ïµ</ci><apply id="S3.E4.m1.9.9.1.1.1.cmml" xref="S3.E4.m1.9.9.1.1"><ci id="S3.E4.m1.9.9.1.1.1.1.cmml" xref="S3.E4.m1.9.9.1.1.1.1">:</ci><cn id="S3.E4.m1.9.9.1.1.1.2.cmml" type="integer" xref="S3.E4.m1.9.9.1.1.1.2">1</cn><ci id="S3.E4.m1.9.9.1.1.1.3.cmml" xref="S3.E4.m1.9.9.1.1.1.3">ğ‘</ci></apply></apply><apply id="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.1"><times id="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.1.2"></times><apply id="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.1.3">subscript</csymbol><apply id="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.1.3.2.1.cmml" xref="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.1.3">superscript</csymbol><ci id="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.1.3.2.2.cmml" xref="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.1.3.2.2">italic-Ïµ</ci><apply id="S3.E4.m1.10.10.1.1.1.cmml" xref="S3.E4.m1.10.10.1.1"><ci id="S3.E4.m1.10.10.1.1.1.1.cmml" xref="S3.E4.m1.10.10.1.1.1.1">:</ci><cn id="S3.E4.m1.10.10.1.1.1.2.cmml" type="integer" xref="S3.E4.m1.10.10.1.1.1.2">1</cn><ci id="S3.E4.m1.10.10.1.1.1.3.cmml" xref="S3.E4.m1.10.10.1.1.1.3">ğ‘</ci></apply></apply><ci id="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.1.3.3">ğœƒ</ci></apply><interval closure="open" id="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.1.1.1"><apply id="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><apply id="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.1.1.1.1">superscript</csymbol><ci id="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2">ğ±</ci><apply id="S3.E4.m1.11.11.1.1.1.cmml" xref="S3.E4.m1.11.11.1.1"><ci id="S3.E4.m1.11.11.1.1.1.1.cmml" xref="S3.E4.m1.11.11.1.1.1.1">:</ci><cn id="S3.E4.m1.11.11.1.1.1.2.cmml" type="integer" xref="S3.E4.m1.11.11.1.1.1.2">1</cn><ci id="S3.E4.m1.11.11.1.1.1.3.cmml" xref="S3.E4.m1.11.11.1.1.1.3">ğ‘</ci></apply></apply><ci id="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.14.14.1.1.1.1.1.1.1.1.1.1.1.1.1.3">ğ‘¡</ci></apply><ci id="S3.E4.m1.13.13.cmml" xref="S3.E4.m1.13.13">ğ‘¡</ci></interval></apply></apply></apply><cn id="S3.E4.m1.14.14.1.1.1.1.1.1.3.cmml" type="integer" xref="S3.E4.m1.14.14.1.1.1.1.1.1.3">2</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.14c">\ell(\theta)=\mathbb{E}_{t,y,c,\mathbf{x}^{(1:N)}_{0},(1:N),\mathbf{\epsilon}^%
{(1:N)}}\left[\|\mathbf{\epsilon}^{(1:N)}-\mathbf{\epsilon}^{(1:N)}_{\theta}(%
\mathbf{x}^{(1:N)}_{t},t)\|_{2}\right],</annotation><annotation encoding="application/x-llamapun" id="S3.E4.m1.14d">roman_â„“ ( italic_Î¸ ) = blackboard_E start_POSTSUBSCRIPT italic_t , italic_y , italic_c , bold_x start_POSTSUPERSCRIPT ( 1 : italic_N ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , ( 1 : italic_N ) , italic_Ïµ start_POSTSUPERSCRIPT ( 1 : italic_N ) end_POSTSUPERSCRIPT end_POSTSUBSCRIPT [ âˆ¥ italic_Ïµ start_POSTSUPERSCRIPT ( 1 : italic_N ) end_POSTSUPERSCRIPT - italic_Ïµ start_POSTSUPERSCRIPT ( 1 : italic_N ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT ( bold_x start_POSTSUPERSCRIPT ( 1 : italic_N ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_t ) âˆ¥ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ] ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS2.p9.6">where <math alttext="y" class="ltx_Math" display="inline" id="S3.SS2.p9.1.m1.1"><semantics id="S3.SS2.p9.1.m1.1a"><mi id="S3.SS2.p9.1.m1.1.1" xref="S3.SS2.p9.1.m1.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p9.1.m1.1b"><ci id="S3.SS2.p9.1.m1.1.1.cmml" xref="S3.SS2.p9.1.m1.1.1">ğ‘¦</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p9.1.m1.1c">y</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p9.1.m1.1d">italic_y</annotation></semantics></math> is the input image, <math alttext="c" class="ltx_Math" display="inline" id="S3.SS2.p9.2.m2.1"><semantics id="S3.SS2.p9.2.m2.1a"><mi id="S3.SS2.p9.2.m2.1.1" xref="S3.SS2.p9.2.m2.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p9.2.m2.1b"><ci id="S3.SS2.p9.2.m2.1.1.cmml" xref="S3.SS2.p9.2.m2.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p9.2.m2.1c">c</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p9.2.m2.1d">italic_c</annotation></semantics></math> is the camera parameters, <math alttext="\mathbf{x}^{(1:N)}_{0}" class="ltx_Math" display="inline" id="S3.SS2.p9.3.m3.1"><semantics id="S3.SS2.p9.3.m3.1a"><msubsup id="S3.SS2.p9.3.m3.1.2" xref="S3.SS2.p9.3.m3.1.2.cmml"><mi id="S3.SS2.p9.3.m3.1.2.2.2" xref="S3.SS2.p9.3.m3.1.2.2.2.cmml">ğ±</mi><mn id="S3.SS2.p9.3.m3.1.2.3" xref="S3.SS2.p9.3.m3.1.2.3.cmml">0</mn><mrow id="S3.SS2.p9.3.m3.1.1.1.1" xref="S3.SS2.p9.3.m3.1.1.1.1.1.cmml"><mo id="S3.SS2.p9.3.m3.1.1.1.1.2" stretchy="false" xref="S3.SS2.p9.3.m3.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS2.p9.3.m3.1.1.1.1.1" xref="S3.SS2.p9.3.m3.1.1.1.1.1.cmml"><mn id="S3.SS2.p9.3.m3.1.1.1.1.1.2" xref="S3.SS2.p9.3.m3.1.1.1.1.1.2.cmml">1</mn><mo id="S3.SS2.p9.3.m3.1.1.1.1.1.1" lspace="0.278em" rspace="0.278em" xref="S3.SS2.p9.3.m3.1.1.1.1.1.1.cmml">:</mo><mi id="S3.SS2.p9.3.m3.1.1.1.1.1.3" xref="S3.SS2.p9.3.m3.1.1.1.1.1.3.cmml">N</mi></mrow><mo id="S3.SS2.p9.3.m3.1.1.1.1.3" stretchy="false" xref="S3.SS2.p9.3.m3.1.1.1.1.1.cmml">)</mo></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p9.3.m3.1b"><apply id="S3.SS2.p9.3.m3.1.2.cmml" xref="S3.SS2.p9.3.m3.1.2"><csymbol cd="ambiguous" id="S3.SS2.p9.3.m3.1.2.1.cmml" xref="S3.SS2.p9.3.m3.1.2">subscript</csymbol><apply id="S3.SS2.p9.3.m3.1.2.2.cmml" xref="S3.SS2.p9.3.m3.1.2"><csymbol cd="ambiguous" id="S3.SS2.p9.3.m3.1.2.2.1.cmml" xref="S3.SS2.p9.3.m3.1.2">superscript</csymbol><ci id="S3.SS2.p9.3.m3.1.2.2.2.cmml" xref="S3.SS2.p9.3.m3.1.2.2.2">ğ±</ci><apply id="S3.SS2.p9.3.m3.1.1.1.1.1.cmml" xref="S3.SS2.p9.3.m3.1.1.1.1"><ci id="S3.SS2.p9.3.m3.1.1.1.1.1.1.cmml" xref="S3.SS2.p9.3.m3.1.1.1.1.1.1">:</ci><cn id="S3.SS2.p9.3.m3.1.1.1.1.1.2.cmml" type="integer" xref="S3.SS2.p9.3.m3.1.1.1.1.1.2">1</cn><ci id="S3.SS2.p9.3.m3.1.1.1.1.1.3.cmml" xref="S3.SS2.p9.3.m3.1.1.1.1.1.3">ğ‘</ci></apply></apply><cn id="S3.SS2.p9.3.m3.1.2.3.cmml" type="integer" xref="S3.SS2.p9.3.m3.1.2.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p9.3.m3.1c">\mathbf{x}^{(1:N)}_{0}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p9.3.m3.1d">bold_x start_POSTSUPERSCRIPT ( 1 : italic_N ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math> denotes the <math alttext="N" class="ltx_Math" display="inline" id="S3.SS2.p9.4.m4.1"><semantics id="S3.SS2.p9.4.m4.1a"><mi id="S3.SS2.p9.4.m4.1.1" xref="S3.SS2.p9.4.m4.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p9.4.m4.1b"><ci id="S3.SS2.p9.4.m4.1.1.cmml" xref="S3.SS2.p9.4.m4.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p9.4.m4.1c">N</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p9.4.m4.1d">italic_N</annotation></semantics></math> target-view images,
<math alttext="\mathbf{\epsilon}^{(1:N)}" class="ltx_Math" display="inline" id="S3.SS2.p9.5.m5.1"><semantics id="S3.SS2.p9.5.m5.1a"><msup id="S3.SS2.p9.5.m5.1.2" xref="S3.SS2.p9.5.m5.1.2.cmml"><mi id="S3.SS2.p9.5.m5.1.2.2" xref="S3.SS2.p9.5.m5.1.2.2.cmml">Ïµ</mi><mrow id="S3.SS2.p9.5.m5.1.1.1.1" xref="S3.SS2.p9.5.m5.1.1.1.1.1.cmml"><mo id="S3.SS2.p9.5.m5.1.1.1.1.2" stretchy="false" xref="S3.SS2.p9.5.m5.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS2.p9.5.m5.1.1.1.1.1" xref="S3.SS2.p9.5.m5.1.1.1.1.1.cmml"><mn id="S3.SS2.p9.5.m5.1.1.1.1.1.2" xref="S3.SS2.p9.5.m5.1.1.1.1.1.2.cmml">1</mn><mo id="S3.SS2.p9.5.m5.1.1.1.1.1.1" lspace="0.278em" rspace="0.278em" xref="S3.SS2.p9.5.m5.1.1.1.1.1.1.cmml">:</mo><mi id="S3.SS2.p9.5.m5.1.1.1.1.1.3" xref="S3.SS2.p9.5.m5.1.1.1.1.1.3.cmml">N</mi></mrow><mo id="S3.SS2.p9.5.m5.1.1.1.1.3" stretchy="false" xref="S3.SS2.p9.5.m5.1.1.1.1.1.cmml">)</mo></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p9.5.m5.1b"><apply id="S3.SS2.p9.5.m5.1.2.cmml" xref="S3.SS2.p9.5.m5.1.2"><csymbol cd="ambiguous" id="S3.SS2.p9.5.m5.1.2.1.cmml" xref="S3.SS2.p9.5.m5.1.2">superscript</csymbol><ci id="S3.SS2.p9.5.m5.1.2.2.cmml" xref="S3.SS2.p9.5.m5.1.2.2">italic-Ïµ</ci><apply id="S3.SS2.p9.5.m5.1.1.1.1.1.cmml" xref="S3.SS2.p9.5.m5.1.1.1.1"><ci id="S3.SS2.p9.5.m5.1.1.1.1.1.1.cmml" xref="S3.SS2.p9.5.m5.1.1.1.1.1.1">:</ci><cn id="S3.SS2.p9.5.m5.1.1.1.1.1.2.cmml" type="integer" xref="S3.SS2.p9.5.m5.1.1.1.1.1.2">1</cn><ci id="S3.SS2.p9.5.m5.1.1.1.1.1.3.cmml" xref="S3.SS2.p9.5.m5.1.1.1.1.1.3">ğ‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p9.5.m5.1c">\mathbf{\epsilon}^{(1:N)}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p9.5.m5.1d">italic_Ïµ start_POSTSUPERSCRIPT ( 1 : italic_N ) end_POSTSUPERSCRIPT</annotation></semantics></math> is the added Gaussian noise, and <math alttext="\mathbf{\epsilon}^{(1:N)}_{\theta}" class="ltx_Math" display="inline" id="S3.SS2.p9.6.m6.1"><semantics id="S3.SS2.p9.6.m6.1a"><msubsup id="S3.SS2.p9.6.m6.1.2" xref="S3.SS2.p9.6.m6.1.2.cmml"><mi id="S3.SS2.p9.6.m6.1.2.2.2" xref="S3.SS2.p9.6.m6.1.2.2.2.cmml">Ïµ</mi><mi id="S3.SS2.p9.6.m6.1.2.3" xref="S3.SS2.p9.6.m6.1.2.3.cmml">Î¸</mi><mrow id="S3.SS2.p9.6.m6.1.1.1.1" xref="S3.SS2.p9.6.m6.1.1.1.1.1.cmml"><mo id="S3.SS2.p9.6.m6.1.1.1.1.2" stretchy="false" xref="S3.SS2.p9.6.m6.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS2.p9.6.m6.1.1.1.1.1" xref="S3.SS2.p9.6.m6.1.1.1.1.1.cmml"><mn id="S3.SS2.p9.6.m6.1.1.1.1.1.2" xref="S3.SS2.p9.6.m6.1.1.1.1.1.2.cmml">1</mn><mo id="S3.SS2.p9.6.m6.1.1.1.1.1.1" lspace="0.278em" rspace="0.278em" xref="S3.SS2.p9.6.m6.1.1.1.1.1.1.cmml">:</mo><mi id="S3.SS2.p9.6.m6.1.1.1.1.1.3" xref="S3.SS2.p9.6.m6.1.1.1.1.1.3.cmml">N</mi></mrow><mo id="S3.SS2.p9.6.m6.1.1.1.1.3" stretchy="false" xref="S3.SS2.p9.6.m6.1.1.1.1.1.cmml">)</mo></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p9.6.m6.1b"><apply id="S3.SS2.p9.6.m6.1.2.cmml" xref="S3.SS2.p9.6.m6.1.2"><csymbol cd="ambiguous" id="S3.SS2.p9.6.m6.1.2.1.cmml" xref="S3.SS2.p9.6.m6.1.2">subscript</csymbol><apply id="S3.SS2.p9.6.m6.1.2.2.cmml" xref="S3.SS2.p9.6.m6.1.2"><csymbol cd="ambiguous" id="S3.SS2.p9.6.m6.1.2.2.1.cmml" xref="S3.SS2.p9.6.m6.1.2">superscript</csymbol><ci id="S3.SS2.p9.6.m6.1.2.2.2.cmml" xref="S3.SS2.p9.6.m6.1.2.2.2">italic-Ïµ</ci><apply id="S3.SS2.p9.6.m6.1.1.1.1.1.cmml" xref="S3.SS2.p9.6.m6.1.1.1.1"><ci id="S3.SS2.p9.6.m6.1.1.1.1.1.1.cmml" xref="S3.SS2.p9.6.m6.1.1.1.1.1.1">:</ci><cn id="S3.SS2.p9.6.m6.1.1.1.1.1.2.cmml" type="integer" xref="S3.SS2.p9.6.m6.1.1.1.1.1.2">1</cn><ci id="S3.SS2.p9.6.m6.1.1.1.1.1.3.cmml" xref="S3.SS2.p9.6.m6.1.1.1.1.1.3">ğ‘</ci></apply></apply><ci id="S3.SS2.p9.6.m6.1.2.3.cmml" xref="S3.SS2.p9.6.m6.1.2.3">ğœƒ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p9.6.m6.1c">\mathbf{\epsilon}^{(1:N)}_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p9.6.m6.1d">italic_Ïµ start_POSTSUPERSCRIPT ( 1 : italic_N ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT</annotation></semantics></math> is the noise predictor.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1"><span class="ltx_text ltx_font_bold" id="S4.p1.1.1">Datasets:</span>
For model training, we use the 323 out of 359 identities from the Facescape dataset <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib61" title="">61</a>]</cite>, following the setting of <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib7" title="">7</a>]</cite>.
The same real training data is used for all compared models,
whilst our model also uses synthetic data purposefully.
For <span class="ltx_text ltx_font_typewriter" id="S4.p1.1.2">out-of-domain</span> generalised evaluation, we randomly select 1,024 images from FFHQ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib23" title="">23</a>]</cite> with background removed using <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib40" title="">40</a>]</cite>.
For <span class="ltx_text ltx_font_typewriter" id="S4.p1.1.3">in-domain</span> evaluation, as <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib7" title="">7</a>]</cite> we use the same 36 test identities.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.p2">
<p class="ltx_p" id="S4.p2.1"><span class="ltx_text ltx_font_bold" id="S4.p2.1.1">Metrics:</span> For generalised <span class="ltx_text ltx_font_typewriter" id="S4.p2.1.2">out-of-domain</span> evaluation without access to the ground-truth images, we use four metrics:
(1) Frechet Inception Distance (FID) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib19" title="">19</a>]</cite>,
(2) Output-to-output ID consistency: calculated as the mean of Arcface cosine similarity <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib10" title="">10</a>]</cite> across all pairs of the 40 target views generated from the same input image,
(3) Input-to-output ID consistency: averaging the Arcface cosine similarity <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib10" title="">10</a>]</cite> between the input image and all generated views, which we propose here to emphasise the importance of preserving the identity of input image,
(4) CLIP Similarity <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib42" title="">42</a>]</cite>.
For typical <span class="ltx_text ltx_font_typewriter" id="S4.p2.1.3">in-domain</span> evaluation, following <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib7" title="">7</a>]</cite> we adopt four metrics: SSIM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib58" title="">58</a>]</cite>, LPIPS <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib65" title="">65</a>]</cite>, FID <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib19" title="">19</a>]</cite>, and face re-identification accuracy (Re-ID) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib37" title="">37</a>]</cite>,
calculated between the ground truth and the generated images.
For Re-ID metric, we consider two variants:
(a) Re-ID(match): As <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib7" title="">7</a>]</cite>, we calculate the percentage of matching the generated image with the ground truth at the Euclidean distance threshold of 0.6;
(b) Re-ID(dist): The average Euclidean distance between the generated image and the ground truth, which offers additional insight into the quantity degree of matching.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.p3">
<p class="ltx_p" id="S4.p3.3"><span class="ltx_text ltx_font_bold" id="S4.p3.3.1">Implementation:</span> We use the AdamW <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib33" title="">33</a>]</cite> optimizer with a batch size of 8 for 48k iterations.
The learning rate for training the backbone UNet has been raised from 1e-6 to 5e-5 with 100 warm-up steps <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib14" title="">14</a>]</cite>, and is kept at 5e-4 for all other trainable modules.
For inference, it takes about 25 seconds to generate 16 target views from a single input images using 50 DDIM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib49" title="">49</a>]</cite> steps with an NVIDIA RTX 3090 GPU.
We set <math alttext="N=16" class="ltx_Math" display="inline" id="S4.p3.1.m1.1"><semantics id="S4.p3.1.m1.1a"><mrow id="S4.p3.1.m1.1.1" xref="S4.p3.1.m1.1.1.cmml"><mi id="S4.p3.1.m1.1.1.2" xref="S4.p3.1.m1.1.1.2.cmml">N</mi><mo id="S4.p3.1.m1.1.1.1" xref="S4.p3.1.m1.1.1.1.cmml">=</mo><mn id="S4.p3.1.m1.1.1.3" xref="S4.p3.1.m1.1.1.3.cmml">16</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.p3.1.m1.1b"><apply id="S4.p3.1.m1.1.1.cmml" xref="S4.p3.1.m1.1.1"><eq id="S4.p3.1.m1.1.1.1.cmml" xref="S4.p3.1.m1.1.1.1"></eq><ci id="S4.p3.1.m1.1.1.2.cmml" xref="S4.p3.1.m1.1.1.2">ğ‘</ci><cn id="S4.p3.1.m1.1.1.3.cmml" type="integer" xref="S4.p3.1.m1.1.1.3">16</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.1.m1.1c">N=16</annotation><annotation encoding="application/x-llamapun" id="S4.p3.1.m1.1d">italic_N = 16</annotation></semantics></math> viewpoints, <math alttext="\tau_{bv}=0.93" class="ltx_Math" display="inline" id="S4.p3.2.m2.1"><semantics id="S4.p3.2.m2.1a"><mrow id="S4.p3.2.m2.1.1" xref="S4.p3.2.m2.1.1.cmml"><msub id="S4.p3.2.m2.1.1.2" xref="S4.p3.2.m2.1.1.2.cmml"><mi id="S4.p3.2.m2.1.1.2.2" xref="S4.p3.2.m2.1.1.2.2.cmml">Ï„</mi><mrow id="S4.p3.2.m2.1.1.2.3" xref="S4.p3.2.m2.1.1.2.3.cmml"><mi id="S4.p3.2.m2.1.1.2.3.2" xref="S4.p3.2.m2.1.1.2.3.2.cmml">b</mi><mo id="S4.p3.2.m2.1.1.2.3.1" xref="S4.p3.2.m2.1.1.2.3.1.cmml">â¢</mo><mi id="S4.p3.2.m2.1.1.2.3.3" xref="S4.p3.2.m2.1.1.2.3.3.cmml">v</mi></mrow></msub><mo id="S4.p3.2.m2.1.1.1" xref="S4.p3.2.m2.1.1.1.cmml">=</mo><mn id="S4.p3.2.m2.1.1.3" xref="S4.p3.2.m2.1.1.3.cmml">0.93</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.p3.2.m2.1b"><apply id="S4.p3.2.m2.1.1.cmml" xref="S4.p3.2.m2.1.1"><eq id="S4.p3.2.m2.1.1.1.cmml" xref="S4.p3.2.m2.1.1.1"></eq><apply id="S4.p3.2.m2.1.1.2.cmml" xref="S4.p3.2.m2.1.1.2"><csymbol cd="ambiguous" id="S4.p3.2.m2.1.1.2.1.cmml" xref="S4.p3.2.m2.1.1.2">subscript</csymbol><ci id="S4.p3.2.m2.1.1.2.2.cmml" xref="S4.p3.2.m2.1.1.2.2">ğœ</ci><apply id="S4.p3.2.m2.1.1.2.3.cmml" xref="S4.p3.2.m2.1.1.2.3"><times id="S4.p3.2.m2.1.1.2.3.1.cmml" xref="S4.p3.2.m2.1.1.2.3.1"></times><ci id="S4.p3.2.m2.1.1.2.3.2.cmml" xref="S4.p3.2.m2.1.1.2.3.2">ğ‘</ci><ci id="S4.p3.2.m2.1.1.2.3.3.cmml" xref="S4.p3.2.m2.1.1.2.3.3">ğ‘£</ci></apply></apply><cn id="S4.p3.2.m2.1.1.3.cmml" type="float" xref="S4.p3.2.m2.1.1.3">0.93</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.2.m2.1c">\tau_{bv}=0.93</annotation><annotation encoding="application/x-llamapun" id="S4.p3.2.m2.1d">italic_Ï„ start_POSTSUBSCRIPT italic_b italic_v end_POSTSUBSCRIPT = 0.93</annotation></semantics></math> for back-view image filtering, <math alttext="\tau_{ii}=70\%" class="ltx_Math" display="inline" id="S4.p3.3.m3.1"><semantics id="S4.p3.3.m3.1a"><mrow id="S4.p3.3.m3.1.1" xref="S4.p3.3.m3.1.1.cmml"><msub id="S4.p3.3.m3.1.1.2" xref="S4.p3.3.m3.1.1.2.cmml"><mi id="S4.p3.3.m3.1.1.2.2" xref="S4.p3.3.m3.1.1.2.2.cmml">Ï„</mi><mrow id="S4.p3.3.m3.1.1.2.3" xref="S4.p3.3.m3.1.1.2.3.cmml"><mi id="S4.p3.3.m3.1.1.2.3.2" xref="S4.p3.3.m3.1.1.2.3.2.cmml">i</mi><mo id="S4.p3.3.m3.1.1.2.3.1" xref="S4.p3.3.m3.1.1.2.3.1.cmml">â¢</mo><mi id="S4.p3.3.m3.1.1.2.3.3" xref="S4.p3.3.m3.1.1.2.3.3.cmml">i</mi></mrow></msub><mo id="S4.p3.3.m3.1.1.1" xref="S4.p3.3.m3.1.1.1.cmml">=</mo><mrow id="S4.p3.3.m3.1.1.3" xref="S4.p3.3.m3.1.1.3.cmml"><mn id="S4.p3.3.m3.1.1.3.2" xref="S4.p3.3.m3.1.1.3.2.cmml">70</mn><mo id="S4.p3.3.m3.1.1.3.1" xref="S4.p3.3.m3.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.p3.3.m3.1b"><apply id="S4.p3.3.m3.1.1.cmml" xref="S4.p3.3.m3.1.1"><eq id="S4.p3.3.m3.1.1.1.cmml" xref="S4.p3.3.m3.1.1.1"></eq><apply id="S4.p3.3.m3.1.1.2.cmml" xref="S4.p3.3.m3.1.1.2"><csymbol cd="ambiguous" id="S4.p3.3.m3.1.1.2.1.cmml" xref="S4.p3.3.m3.1.1.2">subscript</csymbol><ci id="S4.p3.3.m3.1.1.2.2.cmml" xref="S4.p3.3.m3.1.1.2.2">ğœ</ci><apply id="S4.p3.3.m3.1.1.2.3.cmml" xref="S4.p3.3.m3.1.1.2.3"><times id="S4.p3.3.m3.1.1.2.3.1.cmml" xref="S4.p3.3.m3.1.1.2.3.1"></times><ci id="S4.p3.3.m3.1.1.2.3.2.cmml" xref="S4.p3.3.m3.1.1.2.3.2">ğ‘–</ci><ci id="S4.p3.3.m3.1.1.2.3.3.cmml" xref="S4.p3.3.m3.1.1.2.3.3">ğ‘–</ci></apply></apply><apply id="S4.p3.3.m3.1.1.3.cmml" xref="S4.p3.3.m3.1.1.3"><csymbol cd="latexml" id="S4.p3.3.m3.1.1.3.1.cmml" xref="S4.p3.3.m3.1.1.3.1">percent</csymbol><cn id="S4.p3.3.m3.1.1.3.2.cmml" type="integer" xref="S4.p3.3.m3.1.1.3.2">70</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.3.m3.1c">\tau_{ii}=70\%</annotation><annotation encoding="application/x-llamapun" id="S4.p3.3.m3.1d">italic_Ï„ start_POSTSUBSCRIPT italic_i italic_i end_POSTSUBSCRIPT = 70 %</annotation></semantics></math> for identity consistency filtering.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.p4">
<p class="ltx_p" id="S4.p4.1"><span class="ltx_text ltx_font_bold" id="S4.p4.1.1">Competitors:</span> We compare extensively with existing art nerf-based methods pixelNeRF <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib63" title="">63</a>]</cite>, SSD-NeRF <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib6" title="">6</a>]</cite>, and diffusion models including Era3D <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib27" title="">27</a>]</cite>, Zero-1-to-3 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib29" title="">29</a>]</cite>, SyncDreamer <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib30" title="">30</a>]</cite>, Morphable Diffusion <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib7" title="">7</a>]</cite>, and GAN-based methods EG3D <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib4" title="">4</a>]</cite> and our data generator PanoHead <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib2" title="">2</a>]</cite>.
Under the proposed out-of-domain setting,
we exclude pixelNeRF <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib63" title="">63</a>]</cite> and SSD-NeRF <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib6" title="">6</a>]</cite>
due to no precise camera parameters as required, and
improve the generalisation of Morphable Diffusion <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib7" title="">7</a>]</cite>
by using the FLAME <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib28" title="">28</a>]</cite> meshes obtained by fitting the ground truth 3D keypoints, otherwise (originally using ground truth bilinear meshes), it completely falls apart. All methods are fine tuned on in-domain training data except Era3D <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib27" title="">27</a>]</cite> as it claims that can have good results on human head.</p>
</div>
<figure class="ltx_table" id="S4.T1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T1.3.1.1" style="font-size:90%;">Table 1</span>: </span><span class="ltx_text ltx_font_italic" id="S4.T1.4.2" style="font-size:90%;">Out-of-domain<span class="ltx_text ltx_font_upright" id="S4.T1.4.2.1"> single image 3D face generation results on FFHQ.</span></span></figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.T1.5">
<tr class="ltx_tr" id="S4.T1.5.1">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S4.T1.5.1.1">Method</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.5.1.2">
<span class="ltx_text" id="S4.T1.5.1.2.1"></span> <span class="ltx_text" id="S4.T1.5.1.2.2">
<span class="ltx_tabular ltx_align_middle" id="S4.T1.5.1.2.2.1">
<span class="ltx_tr" id="S4.T1.5.1.2.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T1.5.1.2.2.1.1.1">FIDâ†“</span></span>
</span></span><span class="ltx_text" id="S4.T1.5.1.2.3"></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.5.1.3">
<span class="ltx_text" id="S4.T1.5.1.3.1"></span> <span class="ltx_text" id="S4.T1.5.1.3.2">
<span class="ltx_tabular ltx_align_middle" id="S4.T1.5.1.3.2.1">
<span class="ltx_tr" id="S4.T1.5.1.3.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T1.5.1.3.2.1.1.1">Output-to-Output</span></span>
<span class="ltx_tr" id="S4.T1.5.1.3.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T1.5.1.3.2.1.2.1">ID Consistencyâ†‘</span></span>
</span></span><span class="ltx_text" id="S4.T1.5.1.3.3"></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.5.1.4">CLIPâ†‘</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.5.1.5">
<span class="ltx_text" id="S4.T1.5.1.5.1"></span> <span class="ltx_text" id="S4.T1.5.1.5.2">
<span class="ltx_tabular ltx_align_middle" id="S4.T1.5.1.5.2.1">
<span class="ltx_tr" id="S4.T1.5.1.5.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T1.5.1.5.2.1.1.1">Input-to-Output</span></span>
<span class="ltx_tr" id="S4.T1.5.1.5.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T1.5.1.5.2.1.2.1">ID Consistencyâ†‘</span></span>
</span></span><span class="ltx_text" id="S4.T1.5.1.5.3"></span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.2">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_tt" id="S4.T1.5.2.1">Zero-1-to-3<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib29" title="">29</a>]</cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S4.T1.5.2.2">78.8543</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S4.T1.5.2.3">0.4483</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S4.T1.5.2.4">0.5597</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S4.T1.5.2.5">0.1300</td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.3">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="S4.T1.5.3.1">SyncDreamer<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib30" title="">30</a>]</cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.3.2">68.0294</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.3.3">0.4420</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.3.4">0.5883</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.3.5">0.1572</td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.4">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="S4.T1.5.4.1">EG3D<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib4" title="">4</a>]</cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.4.2">66.1578</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.4.3">0.4623</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.4.4">0.5142</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.4.5">0.1531</td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.5">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="S4.T1.5.5.1">PanoHead<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib2" title="">2</a>]</cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.5.2">58.1578</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.5.3">0.4821</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.5.4">0.5644</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.5.5">0.1611</td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.6">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S4.T1.5.6.1">Morphable Diffusion<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib7" title="">7</a>]</cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.5.6.2">89.7443</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.5.6.3"><span class="ltx_text ltx_font_bold" id="S4.T1.5.6.3.1">0.5171</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.5.6.4">0.5359</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.5.6.5">0.1146</td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.7">
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r" id="S4.T1.5.7.1"><span class="ltx_text ltx_font_bold" id="S4.T1.5.7.1.1">Gen3D-Face (Ours)</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="S4.T1.5.7.2"><span class="ltx_text ltx_font_bold" id="S4.T1.5.7.2.1">55.4901</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="S4.T1.5.7.3">0.4536</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="S4.T1.5.7.4"><span class="ltx_text ltx_font_bold" id="S4.T1.5.7.4.1">0.6765</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="S4.T1.5.7.5"><span class="ltx_text ltx_font_bold" id="S4.T1.5.7.5.1">0.1716</span></td>
</tr>
</table>
</figure>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Evaluations</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.p1.1.1">Out-of-domain evaluation: </span>
From the quantitative results in Table Â <a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#S4.T1" title="Table 1 â€£ 4 Experiments â€£ Single Image, Any Face: Generalisable 3D Face Generation"><span class="ltx_text ltx_ref_tag">1</span></a>,
we observe that:
<span class="ltx_text ltx_font_bold" id="S4.SS1.p1.1.2">(1)</span> Interestingly, generic object diffusion models
(Zero-1-to-3 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib29" title="">29</a>]</cite>, SyncDreamer <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib30" title="">30</a>]</cite>) and earlier GAN models (PanoHead <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib2" title="">2</a>]</cite>) even outperforms the latest face focused diffusion model (Morphable Diffusion <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib7" title="">7</a>]</cite>) on the three out of four metrics.
This is an <span class="ltx_text ltx_font_italic" id="S4.SS1.p1.1.3">opposite phenomenon</span> under this more challenging setting as compared to what was discovered in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib7" title="">7</a>]</cite>,
suggesting that the evaluation setting <span class="ltx_text ltx_font_italic" id="S4.SS1.p1.1.4">matters</span>, fundamentally.
This also implies that the way of imposing human geometry as <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib7" title="">7</a>]</cite>
pays the generalisation cost implicitly in exchange of better performance for the limited in-domain setting.
<span class="ltx_text ltx_font_bold" id="S4.SS1.p1.1.5">(2)</span> Overall our Gen3D-Face is the best performer, except being secondary to Morphable Diffusion <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib7" title="">7</a>]</cite> on the output-to-output ID consistency metric. We note that looking at this metric <span class="ltx_text ltx_font_italic" id="S4.SS1.p1.1.6">alone</span> however is not comprehensive and even misleading since it overlooked the divergence of generated images from the input (e.g. being consistent multi-view images of a totally difference identity).
Instead, we should jointly consider both input-to-output and output-to-output ID consistency.
Fusing the two metrics could make the comparison easier but hard to make sense.</p>
</div>
<div class="ltx_para" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1">Qualitative evaluation is presented in FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#S4.F6" title="Figure 6 â€£ 4.2 Ablation studies â€£ 4 Experiments â€£ Single Image, Any Face: Generalisable 3D Face Generation"><span class="ltx_text ltx_ref_tag">6</span></a> and FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#S4.F8" title="Figure 8 â€£ 4.2 Ablation studies â€£ 4 Experiments â€£ Single Image, Any Face: Generalisable 3D Face Generation"><span class="ltx_text ltx_ref_tag">8</span></a>. We try to make sure that each method shows the same view for each row, but still have tiny difference even we give same evaluation camera views because different methods use different camera parameters for training, especially for Era3D <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib27" title="">27</a>]</cite>.
We make these observations:
<span class="ltx_text ltx_font_bold" id="S4.SS1.p2.1.1">(1)</span> Zero-1-to-3 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib29" title="">29</a>]</cite> tends to produce cartoon style images;
<span class="ltx_text ltx_font_bold" id="S4.SS1.p2.1.2">(2)</span> Era3D <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib27" title="">27</a>]</cite> is the newest single-image-to-3D method, we do not calculate the quantitative metrics because it can only generate 6 views, and it shows unrealistic geometry in visual.
<span class="ltx_text ltx_font_bold" id="S4.SS1.p2.1.3">(3)</span> SyncDreamer <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib30" title="">30</a>]</cite> and Morphable Diffusion <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib7" title="">7</a>]</cite> struggle in preserving the identity;
<span class="ltx_text ltx_font_bold" id="S4.SS1.p2.1.4">(4)</span> Morphable Diffusion <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib7" title="">7</a>]</cite> has more consistent generated images but suffers from overfitting to the training domain (e.g. added hat for all cases);
<span class="ltx_text ltx_font_bold" id="S4.SS1.p2.1.5">(5)</span> EG3D <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib4" title="">4</a>]</cite> and Panohead <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib2" title="">2</a>]</cite> tends to yield more blurry images,
despite taking 20<math alttext="\times" class="ltx_Math" display="inline" id="S4.SS1.p2.1.m1.1"><semantics id="S4.SS1.p2.1.m1.1a"><mo id="S4.SS1.p2.1.m1.1.1" xref="S4.SS1.p2.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.1.m1.1b"><times id="S4.SS1.p2.1.m1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p2.1.m1.1d">Ã—</annotation></semantics></math> more training time by PTI inversion <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib45" title="">45</a>]</cite>;
<span class="ltx_text ltx_font_bold" id="S4.SS1.p2.1.6">(6)</span> Our Gen3D-Face achieves the overall best result in terms of ID preservation and consistency, and wider pose variation.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p3">
<p class="ltx_p" id="S4.SS1.p3.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.p3.1.1">In-domain evaluation: </span>
While this work stresses the importance of out-of-domain generalisation,
we still evaluate the conventional in-domain setting.
From Table Â <a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#S4.T2" title="Table 2 â€£ 4.1 Evaluations â€£ 4 Experiments â€£ Single Image, Any Face: Generalisable 3D Face Generation"><span class="ltx_text ltx_ref_tag">2</span></a> we observe that our method performs on par with the previous art model Morphable Diffusion <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib7" title="">7</a>]</cite>.
This suggests that our model does not sacrifice the training domain performance while enhancing the model generalisation. The qualitative evaluations in FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#S4.F7" title="Figure 7 â€£ 4.2 Ablation studies â€£ 4 Experiments â€£ Single Image, Any Face: Generalisable 3D Face Generation"><span class="ltx_text ltx_ref_tag">7</span></a> to display our method keep good identity consistency.</p>
</div>
<figure class="ltx_table" id="S4.T2">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T2.3.1.1" style="font-size:90%;">Table 2</span>: </span><span class="ltx_text ltx_font_italic" id="S4.T2.4.2" style="font-size:90%;">In-domain<span class="ltx_text ltx_font_upright" id="S4.T2.4.2.1"> single image 3D face generation result on Facescape.</span></span></figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.T2.5">
<tr class="ltx_tr" id="S4.T2.5.1">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S4.T2.5.1.1">Method</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.5.1.2">SSIMâ†‘</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.5.1.3">LPIPSâ†“</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.5.1.4">FIDâ†“</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.5.1.5">Re-ID(match)â†‘</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.5.1.6">Re-ID(dist)â†“</td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.2">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_tt" id="S4.T2.5.2.1">pixelNeRF<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib63" title="">63</a>]</cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S4.T2.5.2.2">0.7898</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S4.T2.5.2.3">0.2200</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S4.T2.5.2.4">92.61</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S4.T2.5.2.5">0.9746</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S4.T2.5.2.6">0.3912</td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.3">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="S4.T2.5.3.1">Zero-1-to-3<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib29" title="">29</a>]</cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.3.2">0.5656</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.3.3">0.4248</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.3.4">10.97</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.3.5">0.9677</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.3.6">0.4193</td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.4">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="S4.T2.5.4.1">SSD-NeRF <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib6" title="">6</a>]</cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.4.2">0.7225</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.4.3">0.2225</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.4.4">34.88</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.4.5">0.9874</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.4.6">0.3855</td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.5">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="S4.T2.5.5.1">SyncDreamer<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib30" title="">30</a>]</cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.5.2">0.7732</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.5.3">0.1854</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.5.4"><span class="ltx_text ltx_font_bold" id="S4.T2.5.5.4.1">6.05</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.5.5">0.9960</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.5.6">0.3391</td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.6">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="S4.T2.5.6.1">PanoHead<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib2" title="">2</a>]</cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.6.2">0.7871</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.6.3">0.1914</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.6.4">7.10</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.6.5">0.9915</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.6.6">0.3412</td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.7">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="S4.T2.5.7.1">Morphable<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib7" title="">7</a>]</cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.7.2"><span class="ltx_text ltx_font_bold" id="S4.T2.5.7.2.1">0.8064</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.7.3"><span class="ltx_text ltx_font_bold" id="S4.T2.5.7.3.1">0.1653</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.7.4">6.73</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.7.5"><span class="ltx_text ltx_font_bold" id="S4.T2.5.7.5.1">0.9986</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.7.6"><span class="ltx_text ltx_font_bold" id="S4.T2.5.7.6.1">0.3372</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.8">
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r" id="S4.T2.5.8.1"><span class="ltx_text ltx_font_bold" id="S4.T2.5.8.1.1">Gen3D-Face (Ours)</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="S4.T2.5.8.2">0.7995</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="S4.T2.5.8.3">0.1701</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="S4.T2.5.8.4">6.1231</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="S4.T2.5.8.5">0.9981</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="S4.T2.5.8.6">0.3375</td>
</tr>
</table>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Ablation studies</h3>
<figure class="ltx_table" id="S4.T3">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T3.2.1.1" style="font-size:90%;">Table 3</span>: </span><span class="ltx_text" id="S4.T3.3.2" style="font-size:90%;">Ablation on the effect of synthetic and real training data.</span></figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.T3.4">
<tr class="ltx_tr" id="S4.T3.4.1">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S4.T3.4.1.1">Method</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.4.1.2">
<span class="ltx_text" id="S4.T3.4.1.2.1"></span> <span class="ltx_text" id="S4.T3.4.1.2.2">
<span class="ltx_tabular ltx_align_middle" id="S4.T3.4.1.2.2.1">
<span class="ltx_tr" id="S4.T3.4.1.2.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.4.1.2.2.1.1.1">FIDâ†“</span></span>
</span></span><span class="ltx_text" id="S4.T3.4.1.2.3"></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.4.1.3">
<span class="ltx_text" id="S4.T3.4.1.3.1"></span> <span class="ltx_text" id="S4.T3.4.1.3.2">
<span class="ltx_tabular ltx_align_middle" id="S4.T3.4.1.3.2.1">
<span class="ltx_tr" id="S4.T3.4.1.3.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.4.1.3.2.1.1.1">Output-to-Output</span></span>
<span class="ltx_tr" id="S4.T3.4.1.3.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.4.1.3.2.1.2.1">ID Consistencyâ†‘</span></span>
</span></span><span class="ltx_text" id="S4.T3.4.1.3.3"></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.4.1.4">CLIPâ†‘</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.4.1.5">
<span class="ltx_text" id="S4.T3.4.1.5.1"></span> <span class="ltx_text" id="S4.T3.4.1.5.2">
<span class="ltx_tabular ltx_align_middle" id="S4.T3.4.1.5.2.1">
<span class="ltx_tr" id="S4.T3.4.1.5.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.4.1.5.2.1.1.1">Input-to-Output</span></span>
<span class="ltx_tr" id="S4.T3.4.1.5.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.4.1.5.2.1.2.1">ID Consistencyâ†‘</span></span>
</span></span><span class="ltx_text" id="S4.T3.4.1.5.3"></span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.4.2">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_tt" id="S4.T3.4.2.1">Real data only</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S4.T3.4.2.2">71.2882</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S4.T3.4.2.3">0.4317</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S4.T3.4.2.4">0.5910</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S4.T3.4.2.5">0.1428</td>
</tr>
<tr class="ltx_tr" id="S4.T3.4.3">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="S4.T3.4.3.1">Synthetic data only</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.4.3.2">105.5801</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.4.3.3"><span class="ltx_text ltx_font_bold" id="S4.T3.4.3.3.1">0.5355</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.4.3.4">0.5149</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.4.3.5">0.1011</td>
</tr>
<tr class="ltx_tr" id="S4.T3.4.4">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="S4.T3.4.4.1">w/o Data Pruning</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.4.4.2">57.3138</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.4.4.3">0.4451</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.4.4.4">0.6624</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.4.4.5"><span class="ltx_text ltx_font_bold" id="S4.T3.4.4.5.1">0.1659</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.4.5">
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r" id="S4.T3.4.5.1">w/ Data Pruning</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="S4.T3.4.5.2"><span class="ltx_text ltx_font_bold" id="S4.T3.4.5.2.1">55.4901</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="S4.T3.4.5.3">0.4536</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="S4.T3.4.5.4"><span class="ltx_text ltx_font_bold" id="S4.T3.4.5.4.1">0.6765</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="S4.T3.4.5.5"><span class="ltx_text ltx_font_bold" id="S4.T3.4.5.5.1">0.1716</span></td>
</tr>
</table>
</figure>
<div class="ltx_para ltx_noindent" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.p1.1.1">Training data</span>
We evaluate the effect of synthetic and real training data.
As shown in TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#S4.T3" title="Table 3 â€£ 4.2 Ablation studies â€£ 4 Experiments â€£ Single Image, Any Face: Generalisable 3D Face Generation"><span class="ltx_text ltx_ref_tag">3</span></a>,
we find that (1) both real and synthetic data contribute positively,
and real data is more useful despite smaller size;
(2) Using both could significantly boost the performance, validating our motivation
of training data expansion by synthesis;
(3) The significant decrease for only use synthesis data is because training and evaluating camera view not same.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.p2.1.1">Data pruning</span>
We show examples of Janus problem and Identity inconsistency in FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#S4.F4" title="Figure 4 â€£ 4.2 Ablation studies â€£ 4 Experiments â€£ Single Image, Any Face: Generalisable 3D Face Generation"><span class="ltx_text ltx_ref_tag">4</span></a>, which are filtered out using our pruning process, and the effect of pruning shows in TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#S4.T3" title="Table 3 â€£ 4.2 Ablation studies â€£ 4 Experiments â€£ Single Image, Any Face: Generalisable 3D Face Generation"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<figure class="ltx_figure" id="S4.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="282" id="S4.F4.1.g1" src="x4.png" width="822"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F4.3.1.1" style="font-size:90%;">Figure 4</span>: </span><span class="ltx_text" id="S4.F4.4.2" style="font-size:90%;">Janus problem and Identity inconsistency in Synthesis Dataset.</span></figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S4.SS2.p3">
<p class="ltx_p" id="S4.SS2.p3.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.p3.1.1">Mesh prior effect</span>
We evaluate the effect of models trained with different mesh priors:
(1) ground-truth fitted mesh <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib7" title="">7</a>]</cite>,
and
(2) input-estimated FLAME mesh as proposed in our work.
And provide different input images and the same mesh which is randomly chosen from the Facescape testing set to different mesh prior models separately.
From FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#S4.F5" title="Figure 5 â€£ 4.2 Ablation studies â€£ 4 Experiments â€£ Single Image, Any Face: Generalisable 3D Face Generation"><span class="ltx_text ltx_ref_tag">5</span></a> we find that using ground-truth mesh will
lead to the challenge of preserving the input identity and appearance information, and the tendency of overfitting to the training domain.
In contrast, our idea can largely mitigate these issues, validating our design choice.</p>
</div>
<figure class="ltx_figure" id="S4.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="438" id="S4.F5.1.g1" src="x5.png" width="821"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F5.3.1.1" style="font-size:90%;">Figure 5</span>: </span><span class="ltx_text" id="S4.F5.4.2" style="font-size:90%;">Geometry priors:
(a) Ground-truth fitted mesh <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#bib.bib7" title="">7</a>]</cite>; (b) Our input-estimated mesh.</span></figcaption>
</figure>
<figure class="ltx_table" id="S4.T4">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T4.2.1.1" style="font-size:90%;">Table 4</span>: </span><span class="ltx_text" id="S4.T4.3.2" style="font-size:90%;">Ablation on the effect of multi-view joint generation (MVJG) on the whole dataset.</span></figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.T4.4">
<tr class="ltx_tr" id="S4.T4.4.1">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S4.T4.4.1.1">Number of subset</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.4.1.2">
<span class="ltx_text" id="S4.T4.4.1.2.1"></span> <span class="ltx_text" id="S4.T4.4.1.2.2">
<span class="ltx_tabular ltx_align_middle" id="S4.T4.4.1.2.2.1">
<span class="ltx_tr" id="S4.T4.4.1.2.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T4.4.1.2.2.1.1.1">FIDâ†“</span></span>
</span></span><span class="ltx_text" id="S4.T4.4.1.2.3"></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.4.1.3">
<span class="ltx_text" id="S4.T4.4.1.3.1"></span> <span class="ltx_text" id="S4.T4.4.1.3.2">
<span class="ltx_tabular ltx_align_middle" id="S4.T4.4.1.3.2.1">
<span class="ltx_tr" id="S4.T4.4.1.3.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T4.4.1.3.2.1.1.1">Output-to-Output</span></span>
<span class="ltx_tr" id="S4.T4.4.1.3.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T4.4.1.3.2.1.2.1">ID Consistencyâ†‘</span></span>
</span></span><span class="ltx_text" id="S4.T4.4.1.3.3"></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.4.1.4">CLIPâ†‘</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.4.1.5">
<span class="ltx_text" id="S4.T4.4.1.5.1"></span> <span class="ltx_text" id="S4.T4.4.1.5.2">
<span class="ltx_tabular ltx_align_middle" id="S4.T4.4.1.5.2.1">
<span class="ltx_tr" id="S4.T4.4.1.5.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T4.4.1.5.2.1.1.1">Input-to-Output</span></span>
<span class="ltx_tr" id="S4.T4.4.1.5.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T4.4.1.5.2.1.2.1">ID Consistencyâ†‘</span></span>
</span></span><span class="ltx_text" id="S4.T4.4.1.5.3"></span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.4.2">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_tt" id="S4.T4.4.2.1">No</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S4.T4.4.2.2">58.4648</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S4.T4.4.2.3">0.4441</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S4.T4.4.2.4">0.6181</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S4.T4.4.2.5">0.1571</td>
</tr>
<tr class="ltx_tr" id="S4.T4.4.3">
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r" id="S4.T4.4.3.1">Yes</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="S4.T4.4.3.2"><span class="ltx_text ltx_font_bold" id="S4.T4.4.3.2.1">55.4901</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="S4.T4.4.3.3"><span class="ltx_text ltx_font_bold" id="S4.T4.4.3.3.1">0.4536</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="S4.T4.4.3.4"><span class="ltx_text ltx_font_bold" id="S4.T4.4.3.4.1">0.6765</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="S4.T4.4.3.5"><span class="ltx_text ltx_font_bold" id="S4.T4.4.3.5.1">0.1716</span></td>
</tr>
</table>
</figure>
<div class="ltx_para ltx_noindent" id="S4.SS2.p4">
<p class="ltx_p" id="S4.SS2.p4.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.p4.1.1">Multi-view joint generation</span>
We evaluate the effect of our multi-view joint generation.
From Table <a class="ltx_ref" href="https://arxiv.org/html/2409.16990v1#S4.T4" title="Table 4 â€£ 4.2 Ablation studies â€£ 4 Experiments â€£ Single Image, Any Face: Generalisable 3D Face Generation"><span class="ltx_text ltx_ref_tag">4</span></a> we find that this design helps improve all the metrics,
suggesting a good contribution.</p>
</div>
<figure class="ltx_figure" id="S4.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_portrait" height="1267" id="S4.F6.1.g1" src="x6.png" width="822"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F6.4.1.1" style="font-size:90%;">Figure 6</span>: </span><span class="ltx_text" id="S4.F6.5.2" style="font-size:90%;">Examples of novel view generation on FFHQ (<span class="ltx_text ltx_font_italic" id="S4.F6.5.2.1">out-of-domain</span> setting). </span></figcaption>
</figure>
<figure class="ltx_figure" id="S4.F7"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="856" id="S4.F7.1.g1" src="x7.png" width="822"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F7.4.1.1" style="font-size:90%;">Figure 7</span>: </span><span class="ltx_text" id="S4.F7.5.2" style="font-size:90%;">Examples of novel view generation on Facescape (<span class="ltx_text ltx_font_italic" id="S4.F7.5.2.1">in-domain</span> setting). </span></figcaption>
</figure>
<figure class="ltx_figure" id="S4.F8"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_portrait" height="1188" id="S4.F8.1.g1" src="x8.png" width="822"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F8.4.1.1" style="font-size:90%;">Figure 8</span>: </span><span class="ltx_text" id="S4.F8.5.2" style="font-size:90%;">More examples of novel view generation on FFHQ (<span class="ltx_text ltx_font_italic" id="S4.F8.5.2.1">out-of-domain</span> setting). </span></figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">In this work, we investigate for the first time the single image 3D face generation problem in unconstrained, out-of-domain scenarios.
Established on recent multi-view diffusion,
we present a novel generative method, Gen3D-Face, that can generate photorealistic 3D human face avatars from single, unconstrained images. We show that specific designs such as enhanced training data, input-conditioned mesh estimation, and multi-view joint generation matters to the final model generalisation.
We benchmark this more challenging task with existing generative methods
using more comprehensive metrics.
Extensive experiments show that our method excels in creating unconstrained avatars for generic human subjects, whilst achieving competitive performance under the constrained in-domain setting.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
AlBahar, B., Saito, S., Tseng, H.Y., Kim, C., Kopf, J., Huang, J.B.: Single-image 3d human digitization with shape-guided diffusion. In: SIGGRAPH Asia 2023 Conference Papers. pp. 1â€“11 (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
An, S., Xu, H., Shi, Y., Song, G., Ogras, U.Y., Luo, L.: Panohead: Geometry-aware 3d full-head synthesis in 360deg. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). pp. 20950â€“20959 (June 2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Blattmann, A., Rombach, R., Ling, H., Dockhorn, T., Kim, S.W., Fidler, S., Kreis, K.: Align your latents: High-resolution video synthesis with latent diffusion models. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 22563â€“22575 (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Chan, E.R., Lin, C.Z., Chan, M.A., Nagano, K., Pan, B., DeÂ Mello, S., Gallo, O., Guibas, L.J., Tremblay, J., Khamis, S., etÂ al.: Efficient geometry-aware 3d generative adversarial networks. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 16123â€“16133 (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Chan, E.R., Nagano, K., Chan, M.A., Bergman, A.W., Park, J.J., Levy, A., Aittala, M., DeÂ Mello, S., Karras, T., Wetzstein, G.: Generative novel view synthesis with 3d-aware diffusion models. arXiv preprint arXiv:2304.02602 (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Chen, H., Gu, J., Chen, A., Tian, W., Tu, Z., Liu, L., Su, H.: Single-stage diffusion nerf: A unified approach to 3d generation and reconstruction. arXiv preprint arXiv:2304.06714 (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Chen, X., Mihajlovic, M., Wang, S., Prokudin, S., Tang, S.: Morphable diffusion: 3d-consistent diffusion for single-image avatar creation (2024)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Deitke, M., Liu, R., Wallingford, M., Ngo, H., Michel, O., Kusupati, A., Fan, A., Laforte, C., Voleti, V., Gadre, S.Y., etÂ al.: Objaverse-xl: A universe of 10m+ 3d objects. Advances in Neural Information Processing Systems <span class="ltx_text ltx_font_bold" id="bib.bib8.1.1">36</span> (2024)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Deitke, M., Schwenk, D., Salvador, J., Weihs, L., Michel, O., VanderBilt, E., Schmidt, L., Ehsani, K., Kembhavi, A., Farhadi, A.: Objaverse: A universe of annotated 3d objects. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 13142â€“13153 (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Deng, J., Guo, J., Xue, N., Zafeiriou, S.: Arcface: Additive angular margin loss for deep face recognition. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. pp. 4690â€“4699 (2019)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Dong, Z., Chen, X., Yang, J., Black, M.J., Hilliges, O., Geiger, A.: Ag3d: Learning to generate 3d avatars from 2d image collections. In: Proceedings of the IEEE/CVF International Conference on Computer Vision. pp. 14916â€“14927 (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Feng, Y., Feng, H., Black, M.J., Bolkart, T.: Learning an animatable detailed 3d face model from in-the-wild images. ACM Transactions on Graphics (ToG) <span class="ltx_text ltx_font_bold" id="bib.bib12.1.1">40</span>(4), 1â€“13 (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Gafni, G., Thies, J., Zollhofer, M., NieÃŸner, M.: Dynamic neural radiance fields for monocular 4d facial avatar reconstruction. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 8649â€“8658 (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Goyal, P., DollÃ¡r, P., Girshick, R., Noordhuis, P., Wesolowski, L., Kyrola, A., Tulloch, A., Jia, Y., He, K.: Accurate, large minibatch sgd: Training imagenet in 1 hour. arXiv preprint arXiv:1706.02677 (2017)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Graham, B., Engelcke, M., Van DerÂ Maaten, L.: 3d semantic segmentation with submanifold sparse convolutional networks. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 9224â€“9232 (2018)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Gu, J., Trevithick, A., Lin, K.E., Susskind, J.M., Theobalt, C., Liu, L., Ramamoorthi, R.: Nerfdiff: Single-image view synthesis with nerf-guided distillation from 3d-aware diffusion. In: International Conference on Machine Learning. pp. 11808â€“11826. PMLR (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Han, X., Cao, Y., Han, K., Zhu, X., Deng, J., Song, Y.Z., Xiang, T., Wong, K.Y.K.: Headsculpt: Crafting 3d head avatars with text. In: Thirty-seventh Conference on Neural Information Processing Systems (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
He, R., Sun, S., Yu, X., Xue, C., Zhang, W., Torr, P., Bai, S., Qi, X.: Is synthetic data from generative models ready for image recognition? arXiv preprint arXiv:2210.07574 (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Heusel, M., Ramsauer, H., Unterthiner, T., Nessler, B., Hochreiter, S.: Gans trained by a two time-scale update rule converge to a local nash equilibrium. Advances in neural information processing systems <span class="ltx_text ltx_font_bold" id="bib.bib19.1.1">30</span> (2017)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Ho, J., Jain, A., Abbeel, P.: Denoising diffusion probabilistic models. Advances in neural information processing systems <span class="ltx_text ltx_font_bold" id="bib.bib20.1.1">33</span>, 6840â€“6851 (2020)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Hong, Y., Peng, B., Xiao, H., Liu, L., Zhang, J.: Headnerf: A real-time nerf-based parametric head model. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 20374â€“20384 (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Hu, S., Hong, F., Pan, L., Mei, H., Yang, L., Liu, Z.: Sherf: Generalizable human nerf from a single image. In: Proceedings of the IEEE/CVF International Conference on Computer Vision. pp. 9352â€“9364 (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Karras, T., Laine, S., Aila, T.: A style-based generator architecture for generative adversarial networks. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. pp. 4401â€“4410 (2019)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
Kerbl, B., Kopanas, G., LeimkÃ¼hler, T., Drettakis, G.: 3d gaussian splatting for real-time radiance field rendering. ACM Transactions on Graphics <span class="ltx_text ltx_font_bold" id="bib.bib24.1.1">42</span>(4), 1â€“14 (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
Kirschstein, T., Qian, S., Giebenhain, S., Walter, T., NieÃŸner, M.: Nersemble: Multi-view radiance field reconstruction of human heads. ACM Transactions on Graphics (TOG) <span class="ltx_text ltx_font_bold" id="bib.bib25.1.1">42</span>(4), 1â€“14 (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
Lan, Y., Tan, F., Qiu, D., Xu, Q., Genova, K., Huang, Z., Fanello, S., Pandey, R., Funkhouser, T., Loy, C.C., Zhang, Y.: Gaussian3diff: 3d gaussian diffusion for 3d full head synthesis and editing. arXiv (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
Li, P., Liu, Y., Long, X., Zhang, F., Lin, C., Li, M., Qi, X., Zhang, S., Luo, W., Tan, P., etÂ al.: Era3d: High-resolution multiview diffusion using efficient row-wise attention. arXiv preprint arXiv:2405.11616 (2024)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
Li, T., Bolkart, T., Black, M.J., Li, H., Romero, J.: Learning a model of facial shape and expression from 4d scans. ACM Trans. Graph. <span class="ltx_text ltx_font_bold" id="bib.bib28.1.1">36</span>(6), 194â€“1 (2017)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
Liu, R., Wu, R., Hoorick, B.V., Tokmakov, P., Zakharov, S., Vondrick, C.: Zero-1-to-3: Zero-shot one image to 3d object (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
Liu, Y., Lin, C., Zeng, Z., Long, X., Liu, L., Komura, T., Wang, W.: Syncdreamer: Generating multiview-consistent images from a single-view image. arXiv preprint arXiv:2309.03453 (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
Long, X., Guo, Y.C., Lin, C., Liu, Y., Dou, Z., Liu, L., Ma, Y., Zhang, S.H., Habermann, M., Theobalt, C., etÂ al.: Wonder3d: Single image to 3d using cross-domain diffusion. arXiv preprint arXiv:2310.15008 (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
Loper, M., Mahmood, N., Romero, J., Pons-Moll, G., Black, M.J.: SMPL: A skinned multi-person linear model. ACM Trans. Graphics (Proc. SIGGRAPH Asia) <span class="ltx_text ltx_font_bold" id="bib.bib32.1.1">34</span>(6), 248:1â€“248:16 (Oct 2015)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
Loshchilov, I., Hutter, F.: Decoupled weight decay regularization. arXiv preprint arXiv:1711.05101 (2017)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
Mildenhall, B., Srinivasan, P.P., Tancik, M., Barron, J.T., Ramamoorthi, R., Ng, R.: Nerf: Representing scenes as neural radiance fields for view synthesis. Communications of the ACM <span class="ltx_text ltx_font_bold" id="bib.bib34.1.1">65</span>(1), 99â€“106 (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
Pan, D., Zhuo, L., Piao, J., Luo, H., Cheng, W., Wang, Y., Fan, S., Liu, S., Yang, L., Dai, B., etÂ al.: Renderme-360: A large digital asset library and benchmarks towards high-fidelity head avatars. Advances in Neural Information Processing Systems <span class="ltx_text ltx_font_bold" id="bib.bib35.1.1">36</span> (2024)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
Peng, S., Zhang, Y., Xu, Y., Wang, Q., Shuai, Q., Bao, H., Zhou, X.: Neural body: Implicit neural representations with structured latent codes for novel view synthesis of dynamic humans. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 9054â€“9063 (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
Phillips, P.J., Moon, H., Rizvi, S.A., Rauss, P.J.: The feret evaluation methodology for face-recognition algorithms. IEEE Transactions on pattern analysis and machine intelligence <span class="ltx_text ltx_font_bold" id="bib.bib37.1.1">22</span>(10), 1090â€“1104 (2000)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
Poole, B., Jain, A., Barron, J.T., Mildenhall, B.: Dreamfusion: Text-to-3d using 2d diffusion. arXiv preprint arXiv:2209.14988 (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
Qian, S., Kirschstein, T., Schoneveld, L., Davoli, D., Giebenhain, S., NieÃŸner, M.: Gaussianavatars: Photorealistic head avatars with rigged 3d gaussians. arXiv preprint arXiv:2312.02069 (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
Qin, X., Zhang, Z., Huang, C., Dehghan, M., Zaiane, O., Jagersand, M.: U2-net: Going deeper with nested u-structure for salient object detection. vol.Â 106, p. 107404 (2020)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
Qiu, H., Yu, B., Gong, D., Li, Z., Liu, W., Tao, D.: Synface: Face recognition with synthetic data. In: Proceedings of the IEEE/CVF International Conference on Computer Vision. pp. 10880â€“10890 (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
Radford, A., Kim, J.W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., Sastry, G., Askell, A., Mishkin, P., Clark, J., etÂ al.: Learning transferable visual models from natural language supervision. In: International conference on machine learning. pp. 8748â€“8763. PMLR (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
Razavi, A., VanÂ den Oord, A., Vinyals, O.: Generating diverse high-fidelity images with vq-vae-2. Advances in neural information processing systems <span class="ltx_text ltx_font_bold" id="bib.bib43.1.1">32</span> (2019)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
Rebain, D., Matthews, M., Yi, K.M., Lagun, D., Tagliasacchi, A.: Lolnerf: Learn from one look. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 1558â€“1567 (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
Roich, D., Mokady, R., Bermano, A.H., Cohen-Or, D.: Pivotal tuning for latent-based editing of real images. ACM Transactions on graphics (TOG) <span class="ltx_text ltx_font_bold" id="bib.bib45.1.1">42</span>(1), 1â€“13 (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
Rombach, R., Blattmann, A., Lorenz, D., Esser, P., Ommer, B.: High-resolution image synthesis with latent diffusion models. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. pp. 10684â€“10695 (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
Sengupta, A., Alldieck, T., Kolotouros, N., Corona, E., Zanfir, A., Sminchisescu, C.: Diffhuman: Probabilistic photorealistic 3d reconstruction of humans. arXiv preprint arXiv:2404.00485 (2024)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
Shi, Y., Wang, P., Ye, J., Mai, L., Li, K., Yang, X.: Mvdream: Multi-view diffusion for 3d generation. arXiv:2308.16512 (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
Song, J., Meng, C., Ermon, S.: Denoising diffusion implicit models. arXiv preprint arXiv:2010.02502 (2020)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
Szymanowicz, S., Rupprecht, C., Vedaldi, A.: Splatter image: Ultra-fast single-view 3d reconstruction. arXiv preprint arXiv:2312.13150 (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock">
Tang, J., Chen, Z., Chen, X., Wang, T., Zeng, G., Liu, Z.: Lgm: Large multi-view gaussian model for high-resolution 3d content creation. arXiv preprint arXiv:2402.05054 (2024)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock">
Tang, J., Wang, T., Zhang, B., Zhang, T., Yi, R., Ma, L., Chen, D.: Make-it-3d: High-fidelity 3d creation from a single image with diffusion prior. arXiv preprint arXiv:2303.14184 (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock">
Trevithick, A., Chan, M., Stengel, M., Chan, E.R., Liu, C., Yu, Z., Khamis, S., Chandraker, M., Ramamoorthi, R., Nagano, K.: Real-time radiance fields for single-image portrait view synthesis. In: ACM Transactions on Graphics (SIGGRAPH) (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock">
Wang, H., Du, X., Li, J., Yeh, R.A., Shakhnarovich, G.: Score jacobian chaining: Lifting pretrained 2d diffusion models for 3d generation. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 12619â€“12629 (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock">
Wang, T., Zhang, B., Zhang, T., Gu, S., Bao, J., Baltrusaitis, T., Shen, J., Chen, D., Wen, F., Chen, Q., etÂ al.: Rodin: A generative model for sculpting 3d digital avatars using diffusion. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 4563â€“4573 (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock">
Wang, W., Zhang, L., Pun, C.M., Xie, J.C.: Boosting face recognition performance with synthetic data and limited real data. In: ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). pp.Â 1â€“5. IEEE (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock">
Wang, Y., Han, Q., Habermann, M., Daniilidis, K., Theobalt, C., Liu, L.: Neus2: Fast learning of neural implicit surfaces for multi-view reconstruction. In: Proceedings of the IEEE/CVF International Conference on Computer Vision. pp. 3295â€“3306 (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock">
Wang, Z., Bovik, A.C., Sheikh, H.R., Simoncelli, E.P.: Image quality assessment: from error visibility to structural similarity. IEEE transactions on image processing <span class="ltx_text ltx_font_bold" id="bib.bib58.1.1">13</span>(4), 600â€“612 (2004)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib59">
<span class="ltx_tag ltx_tag_bibitem">[59]</span>
<span class="ltx_bibblock">
Watson, D., Chan, W., Martin-Brualla, R., Ho, J., Tagliasacchi, A., Norouzi, M.: Novel view synthesis with diffusion models. arXiv preprint arXiv:2210.04628 (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib60">
<span class="ltx_tag ltx_tag_bibitem">[60]</span>
<span class="ltx_bibblock">
Xu, B., Zhang, J., Lin, K.Y., Qian, C., He, Y.: Deformable model driven neural rendering for high-fidelity 3d reconstruction of human heads under low-view settings. arXiv preprint arXiv:2303.13855 (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib61">
<span class="ltx_tag ltx_tag_bibitem">[61]</span>
<span class="ltx_bibblock">
Yang, H., Zhu, H., Wang, Y., Huang, M., Shen, Q., Yang, R., Cao, X.: Facescape: A large-scale high quality 3d face dataset and detailed riggable 3d face prediction. In: IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) (June 2020)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib62">
<span class="ltx_tag ltx_tag_bibitem">[62]</span>
<span class="ltx_bibblock">
Yang, L., Xu, X., Kang, B., Shi, Y., Zhao, H.: Freemask: Synthetic images with dense annotations make stronger segmentation models. Advances in Neural Information Processing Systems <span class="ltx_text ltx_font_bold" id="bib.bib62.1.1">36</span> (2024)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib63">
<span class="ltx_tag ltx_tag_bibitem">[63]</span>
<span class="ltx_bibblock">
Yu, A., Ye, V., Tancik, M., Kanazawa, A.: pixelnerf: Neural radiance fields from one or few images. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 4578â€“4587 (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib64">
<span class="ltx_tag ltx_tag_bibitem">[64]</span>
<span class="ltx_bibblock">
Zhang, L., Qiu, Q., Lin, H., Zhang, Q., Shi, C., Yang, W., Shi, Y., Yang, S., Xu, L., Yu, J.: Dreamface: Progressive generation of animatable 3d faces under text guidance. arXiv preprint arXiv:2304.03117 (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib65">
<span class="ltx_tag ltx_tag_bibitem">[65]</span>
<span class="ltx_bibblock">
Zhang, R., Isola, P., Efros, A.A., Shechtman, E., Wang, O.: The unreasonable effectiveness of deep features as a perceptual metric. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 586â€“595 (2018)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib66">
<span class="ltx_tag ltx_tag_bibitem">[66]</span>
<span class="ltx_bibblock">
Zheng, S., Zhou, B., Shao, R., Liu, B., Zhang, S., Nie, L., Liu, Y.: Gps-gaussian: Generalizable pixel-wise 3d gaussian splatting for real-time human novel view synthesis. arXiv preprint arXiv:2312.02155 (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib67">
<span class="ltx_tag ltx_tag_bibitem">[67]</span>
<span class="ltx_bibblock">
Zheng, Y., Yang, H., Zhang, T., Bao, J., Chen, D., Huang, Y., Yuan, L., Chen, D., Zeng, M., Wen, F.: General facial representation learning in a visual-linguistic manner. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 18697â€“18709 (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib68">
<span class="ltx_tag ltx_tag_bibitem">[68]</span>
<span class="ltx_bibblock">
Zhou, Y., Zhou, D., Cheng, M.M., Feng, J., Hou, Q.: Storydiffusion: Consistent self-attention for long-range image and video generation. arXiv preprint arXiv:2405.01434 (2024)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib69">
<span class="ltx_tag ltx_tag_bibitem">[69]</span>
<span class="ltx_bibblock">
Zielonka, W., Bolkart, T., Thies, J.: Instant volumetric head avatars. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 4574â€“4584 (2023)

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Wed Sep 25 14:51:24 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
