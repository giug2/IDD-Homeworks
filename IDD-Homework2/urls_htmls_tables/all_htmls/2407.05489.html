<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>How Effective are State Space Models for Machine Translation?</title>
<!--Generated on Sun Jul  7 20:14:59 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2407.05489v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#S1" title="In How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#S2" title="In How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Background</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#S2.SS1" title="In 2 Background ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Transformers</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#S2.SS2" title="In 2 Background ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Linear Attention</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#S2.SS2.SSS0.Px1" title="In 2.2 Linear Attention ‣ 2 Background ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_title">Retentive Networks (RetNet).</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#S2.SS3" title="In 2 Background ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>State Space Models (SSMs)</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#S2.SS3.SSS0.Px1" title="In 2.3 State Space Models (SSMs) ‣ 2 Background ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_title">Mamba.</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#S3" title="In How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Experimental Setup</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#S3.SS1" title="In 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Datasets</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#S3.SS2" title="In 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Models</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection">
<a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#S3.SS2.SSS1" title="In 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.1 </span>Standard Models</span></a>
<ol class="ltx_toclist ltx_toclist_subsubsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#S3.SS2.SSS1.Px1" title="In 3.2.1 Standard Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_title">Transformers.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#S3.SS2.SSS1.Px2" title="In 3.2.1 Standard Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_title">Linear recurrent models.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsubsection">
<a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#S3.SS2.SSS2" title="In 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.2 </span>Hybrid Models</span></a>
<ol class="ltx_toclist ltx_toclist_subsubsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#S3.SS2.SSS2.Px1" title="In 3.2.2 Hybrid Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_title">Mamba-MHA.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#S3.SS2.SSS2.Px2" title="In 3.2.2 Hybrid Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_title">Mamba-Local.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#S3.SS2.SSS2.Px3" title="In 3.2.2 Hybrid Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_title">Mamba Enc-Dec.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsubsection">
<a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#S3.SS2.SSS3" title="In 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.3 </span>Pretrained Models</span></a>
<ol class="ltx_toclist ltx_toclist_subsubsection">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#S3.SS3" title="In 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Training and Evaluation</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#S4" title="In 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Sentence-level Translation</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#S4.SS1" title="In 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Discussion</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#S4.SS1.SSS0.Px1" title="In 4.1 Discussion ‣ 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_title">Mamba is competitive when trained from scratch.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#S4.SS1.SSS0.Px2" title="In 4.1 Discussion ‣ 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_title">Attention benefits Mamba.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#S4.SS1.SSS0.Px3" title="In 4.1 Discussion ‣ 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_title">Pretraining improves all models.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#S4.SS1.SSS0.Px4" title="In 4.1 Discussion ‣ 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_title">Larger models achieve top results.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#S4.SS2" title="In 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Recall of Named Entities</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#S5" title="In 4.2 Recall of Named Entities ‣ 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Paragraph-level translation</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#S5.SS1" title="In 5 Paragraph-level translation ‣ 4.2 Recall of Named Entities ‣ 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Discussion</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#S5.SS1.SSS0.Px1" title="In 5.1 Discussion ‣ 5 Paragraph-level translation ‣ 4.2 Recall of Named Entities ‣ 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_title">Concatenation helps.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph">
<a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#S5.SS1.SSS0.Px2" title="In 5.1 Discussion ‣ 5 Paragraph-level translation ‣ 4.2 Recall of Named Entities ‣ 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_title">Finetuning outperforms training from scratch.</span></a>
<ol class="ltx_toclist ltx_toclist_paragraph">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#S5.SS2" title="In Finetuning outperforms training from scratch. ‣ 5.1 Discussion ‣ 5 Paragraph-level translation ‣ 4.2 Recall of Named Entities ‣ 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Sensitivity to Input Length</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph">
<a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#S5.SS2.SSS0.Px1" title="In 5.2 Sensitivity to Input Length ‣ Finetuning outperforms training from scratch. ‣ 5.1 Discussion ‣ 5 Paragraph-level translation ‣ 4.2 Recall of Named Entities ‣ 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_title">Discussion.</span></a>
<ol class="ltx_toclist ltx_toclist_paragraph">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#S5.SS3" title="In Discussion. ‣ 5.2 Sensitivity to Input Length ‣ Finetuning outperforms training from scratch. ‣ 5.1 Discussion ‣ 5 Paragraph-level translation ‣ 4.2 Recall of Named Entities ‣ 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3 </span>Inference Cost</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#S6" title="In 5.3 Inference Cost ‣ Discussion. ‣ 5.2 Sensitivity to Input Length ‣ Finetuning outperforms training from scratch. ‣ 5.1 Discussion ‣ 5 Paragraph-level translation ‣ 4.2 Recall of Named Entities ‣ 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Related Works</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#S6.SS0.SSS0.Px1" title="In 6 Related Works ‣ 5.3 Inference Cost ‣ Discussion. ‣ 5.2 Sensitivity to Input Length ‣ Finetuning outperforms training from scratch. ‣ 5.1 Discussion ‣ 5 Paragraph-level translation ‣ 4.2 Recall of Named Entities ‣ 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_title">Linear recurrent models for MT.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#S6.SS0.SSS0.Px2" title="In 6 Related Works ‣ 5.3 Inference Cost ‣ Discussion. ‣ 5.2 Sensitivity to Input Length ‣ Finetuning outperforms training from scratch. ‣ 5.1 Discussion ‣ 5 Paragraph-level translation ‣ 4.2 Recall of Named Entities ‣ 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_title">Linear recurrent models’ limitations.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph">
<a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#S6.SS0.SSS0.Px3" title="In 6 Related Works ‣ 5.3 Inference Cost ‣ Discussion. ‣ 5.2 Sensitivity to Input Length ‣ Finetuning outperforms training from scratch. ‣ 5.1 Discussion ‣ 5 Paragraph-level translation ‣ 4.2 Recall of Named Entities ‣ 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_title">Sentence concatenation</span></a>
<ol class="ltx_toclist ltx_toclist_paragraph">
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#S7" title="In Sentence concatenation ‣ 6 Related Works ‣ 5.3 Inference Cost ‣ Discussion. ‣ 5.2 Sensitivity to Input Length ‣ Finetuning outperforms training from scratch. ‣ 5.1 Discussion ‣ 5 Paragraph-level translation ‣ 4.2 Recall of Named Entities ‣ 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Conclusion</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#A1" title="In Potential Risks ‣ Limitations ‣ Acknowledgments ‣ 7 Conclusion ‣ Sentence concatenation ‣ 6 Related Works ‣ 5.3 Inference Cost ‣ Discussion. ‣ 5.2 Sensitivity to Input Length ‣ Finetuning outperforms training from scratch. ‣ 5.1 Discussion ‣ 5 Paragraph-level translation ‣ 4.2 Recall of Named Entities ‣ 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Implementation and Training Details</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#A1.SS1" title="In Appendix A Implementation and Training Details ‣ Potential Risks ‣ Limitations ‣ Acknowledgments ‣ 7 Conclusion ‣ Sentence concatenation ‣ 6 Related Works ‣ 5.3 Inference Cost ‣ Discussion. ‣ 5.2 Sensitivity to Input Length ‣ Finetuning outperforms training from scratch. ‣ 5.1 Discussion ‣ 5 Paragraph-level translation ‣ 4.2 Recall of Named Entities ‣ 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.1 </span>Training from Scratch</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#A1.SS2" title="In A.1 Training from Scratch ‣ Appendix A Implementation and Training Details ‣ Potential Risks ‣ Limitations ‣ Acknowledgments ‣ 7 Conclusion ‣ Sentence concatenation ‣ 6 Related Works ‣ 5.3 Inference Cost ‣ Discussion. ‣ 5.2 Sensitivity to Input Length ‣ Finetuning outperforms training from scratch. ‣ 5.1 Discussion ‣ 5 Paragraph-level translation ‣ 4.2 Recall of Named Entities ‣ 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.2 </span>Finetuning Pretrained Checkpoints</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#A1.SS3" title="In A.2 Finetuning Pretrained Checkpoints ‣ A.1 Training from Scratch ‣ Appendix A Implementation and Training Details ‣ Potential Risks ‣ Limitations ‣ Acknowledgments ‣ 7 Conclusion ‣ Sentence concatenation ‣ 6 Related Works ‣ 5.3 Inference Cost ‣ Discussion. ‣ 5.2 Sensitivity to Input Length ‣ Finetuning outperforms training from scratch. ‣ 5.1 Discussion ‣ 5 Paragraph-level translation ‣ 4.2 Recall of Named Entities ‣ 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.3 </span>Inference Cost</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#A2" title="In A.3 Inference Cost ‣ A.2 Finetuning Pretrained Checkpoints ‣ A.1 Training from Scratch ‣ Appendix A Implementation and Training Details ‣ Potential Risks ‣ Limitations ‣ Acknowledgments ‣ 7 Conclusion ‣ Sentence concatenation ‣ 6 Related Works ‣ 5.3 Inference Cost ‣ Discussion. ‣ 5.2 Sensitivity to Input Length ‣ Finetuning outperforms training from scratch. ‣ 5.1 Discussion ‣ 5 Paragraph-level translation ‣ 4.2 Recall of Named Entities ‣ 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B </span>Hybrid Models Ablation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#A3" title="In A.3 Inference Cost ‣ A.2 Finetuning Pretrained Checkpoints ‣ A.1 Training from Scratch ‣ Appendix A Implementation and Training Details ‣ Potential Risks ‣ Limitations ‣ Acknowledgments ‣ 7 Conclusion ‣ Sentence concatenation ‣ 6 Related Works ‣ 5.3 Inference Cost ‣ Discussion. ‣ 5.2 Sensitivity to Input Length ‣ Finetuning outperforms training from scratch. ‣ 5.1 Discussion ‣ 5 Paragraph-level translation ‣ 4.2 Recall of Named Entities ‣ 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C </span>Exploring Length-related Issues</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#A3.SS1" title="In Appendix C Exploring Length-related Issues ‣ A.3 Inference Cost ‣ A.2 Finetuning Pretrained Checkpoints ‣ A.1 Training from Scratch ‣ Appendix A Implementation and Training Details ‣ Potential Risks ‣ Limitations ‣ Acknowledgments ‣ 7 Conclusion ‣ Sentence concatenation ‣ 6 Related Works ‣ 5.3 Inference Cost ‣ Discussion. ‣ 5.2 Sensitivity to Input Length ‣ Finetuning outperforms training from scratch. ‣ 5.1 Discussion ‣ 5 Paragraph-level translation ‣ 4.2 Recall of Named Entities ‣ 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C.1 </span>Preliminary Sentence-level Experiments</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#A3.SS2" title="In Appendix C Exploring Length-related Issues ‣ A.3 Inference Cost ‣ A.2 Finetuning Pretrained Checkpoints ‣ A.1 Training from Scratch ‣ Appendix A Implementation and Training Details ‣ Potential Risks ‣ Limitations ‣ Acknowledgments ‣ 7 Conclusion ‣ Sentence concatenation ‣ 6 Related Works ‣ 5.3 Inference Cost ‣ Discussion. ‣ 5.2 Sensitivity to Input Length ‣ Finetuning outperforms training from scratch. ‣ 5.1 Discussion ‣ 5 Paragraph-level translation ‣ 4.2 Recall of Named Entities ‣ 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C.2 </span>Sensitivity to Input Length</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#A3.SS3" title="In Appendix C Exploring Length-related Issues ‣ A.3 Inference Cost ‣ A.2 Finetuning Pretrained Checkpoints ‣ A.1 Training from Scratch ‣ Appendix A Implementation and Training Details ‣ Potential Risks ‣ Limitations ‣ Acknowledgments ‣ 7 Conclusion ‣ Sentence concatenation ‣ 6 Related Works ‣ 5.3 Inference Cost ‣ Discussion. ‣ 5.2 Sensitivity to Input Length ‣ Finetuning outperforms training from scratch. ‣ 5.1 Discussion ‣ 5 Paragraph-level translation ‣ 4.2 Recall of Named Entities ‣ 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C.3 </span>Extrapolation to Longer Sequences</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#A3.SS3.SSS0.Px1" title="In C.3 Extrapolation to Longer Sequences ‣ Appendix C Exploring Length-related Issues ‣ A.3 Inference Cost ‣ A.2 Finetuning Pretrained Checkpoints ‣ A.1 Training from Scratch ‣ Appendix A Implementation and Training Details ‣ Potential Risks ‣ Limitations ‣ Acknowledgments ‣ 7 Conclusion ‣ Sentence concatenation ‣ 6 Related Works ‣ 5.3 Inference Cost ‣ Discussion. ‣ 5.2 Sensitivity to Input Length ‣ Finetuning outperforms training from scratch. ‣ 5.1 Discussion ‣ 5 Paragraph-level translation ‣ 4.2 Recall of Named Entities ‣ 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_title">Discussion.</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#A4" title="In A.3 Inference Cost ‣ A.2 Finetuning Pretrained Checkpoints ‣ A.1 Training from Scratch ‣ Appendix A Implementation and Training Details ‣ Potential Risks ‣ Limitations ‣ Acknowledgments ‣ 7 Conclusion ‣ Sentence concatenation ‣ 6 Related Works ‣ 5.3 Inference Cost ‣ Discussion. ‣ 5.2 Sensitivity to Input Length ‣ Finetuning outperforms training from scratch. ‣ 5.1 Discussion ‣ 5 Paragraph-level translation ‣ 4.2 Recall of Named Entities ‣ 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">D </span>Full Paragraph-Level Results</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#A5" title="In Appendix D Full Paragraph-Level Results ‣ A.3 Inference Cost ‣ A.2 Finetuning Pretrained Checkpoints ‣ A.1 Training from Scratch ‣ Appendix A Implementation and Training Details ‣ Potential Risks ‣ Limitations ‣ Acknowledgments ‣ 7 Conclusion ‣ Sentence concatenation ‣ 6 Related Works ‣ 5.3 Inference Cost ‣ Discussion. ‣ 5.2 Sensitivity to Input Length ‣ Finetuning outperforms training from scratch. ‣ 5.1 Discussion ‣ 5 Paragraph-level translation ‣ 4.2 Recall of Named Entities ‣ 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">E </span>AI assistants</span></a></li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<h1 class="ltx_title ltx_title_document">How Effective are State Space Models for Machine Translation?</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
<span class="ltx_text ltx_font_bold" id="id1.1.id1">Hugo Pitorro<sup class="ltx_sup" id="id1.1.id1.1">1</sup></span>,
<span class="ltx_text ltx_font_bold" id="id2.2.id2">Pavlo Vasylenko<span class="ltx_note ltx_role_footnotemark" id="footnotex1"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">footnotemark: </span></span></span></span><sup class="ltx_sup" id="id2.2.id2.1">2,3</sup></span>,
<span class="ltx_text ltx_font_bold" id="id3.3.id3">Marcos Treviso<sup class="ltx_sup" id="id3.3.id3.1">3</sup></span>,
<span class="ltx_text ltx_font_bold" id="id4.4.id4">André F. T. Martins<sup class="ltx_sup" id="id4.4.id4.1">2,3,4,5</sup></span>
<br class="ltx_break"/><sup class="ltx_sup" id="id5.5.id5">1</sup>TU Munich,
<sup class="ltx_sup" id="id6.6.id6">2</sup>Instituto Superior Técnico, University of Lisbon

<br class="ltx_break"/><sup class="ltx_sup" id="id7.7.id7">3</sup>Instituto de Telecomunicações,
<sup class="ltx_sup" id="id8.8.id8">4</sup>Unbabel,
<sup class="ltx_sup" id="id9.9.id9">5</sup>ELLIS Unit Lisbon
</span><span class="ltx_author_notes"><span class="ltx_text ltx_font_bold" id="id10.10.id1">  Equal contribution.</span></span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id11.id1">Transformers are the current architecture of choice for NLP, but their attention layers do not scale well to long contexts.
Recent works propose to replace attention with linear recurrent layers—this is the case for state space models, which enjoy efficient training and inference.
However, it remains unclear whether these models are competitive with transformers in machine translation (MT).
In this paper, we provide a rigorous and comprehensive experimental comparison between transformers and linear recurrent models for MT.
Concretely, we experiment with RetNet, Mamba, and hybrid versions of Mamba which incorporate attention mechanisms.
Our findings demonstrate that Mamba is highly competitive with transformers on sentence and paragraph-level datasets, where in the latter both models benefit from shifting the training distribution towards longer sequences.
Further analysis show that integrating attention into Mamba improves translation quality, robustness to sequence length extrapolation, and the ability to recall named entities.</p>
</div>
<div class="ltx_para ltx_noindent" id="p1">
<div class="ltx_block ltx_align_bottom" id="p1.1">
<p class="ltx_p" id="p1.1.1"><span class="ltx_text ltx_font_bold" id="p1.1.1.1">How Effective are State Space Models for Machine Translation?</span></p>
<br class="ltx_break ltx_centering"/>
<p class="ltx_p ltx_align_center" id="p1.1.2" style="width:433.6pt;"><span class="ltx_text ltx_inline-block" id="p1.1.2.1" style="width:0.0pt;">
<span class="ltx_tabular ltx_align_top" id="p1.1.2.1.1">
<span class="ltx_tr" id="p1.1.2.1.1.1">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.1.1"><span class="ltx_text ltx_font_bold" id="p1.1.2.1.1.1.1.1">
Hugo Pitorro<span class="ltx_note ltx_role_thanks" id="p1.1.2.1.1.1.1.1.1"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">thanks: </span>  Equal contribution.</span></span></span><sup class="ltx_sup" id="p1.1.2.1.1.1.1.1.2">1</sup>,
Pavlo Vasylenko<span class="ltx_note ltx_role_footnotemark" id="footnotex2"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">footnotemark: </span></span></span></span><sup class="ltx_sup" id="p1.1.2.1.1.1.1.1.3">2,3</sup>,
Marcos Treviso<sup class="ltx_sup" id="p1.1.2.1.1.1.1.1.4">3</sup>,
André F. T. Martins<sup class="ltx_sup" id="p1.1.2.1.1.1.1.1.5">2,3,4,5</sup></span></span></span>
<span class="ltx_tr" id="p1.1.2.1.1.2">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.2.1"><sup class="ltx_sup" id="p1.1.2.1.1.2.1.1">1</sup>TU Munich,
<sup class="ltx_sup" id="p1.1.2.1.1.2.1.2">2</sup>Instituto Superior Técnico, University of Lisbon</span></span>
<span class="ltx_tr" id="p1.1.2.1.1.3">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.3.1"><sup class="ltx_sup" id="p1.1.2.1.1.3.1.1">3</sup>Instituto de Telecomunicações,
<sup class="ltx_sup" id="p1.1.2.1.1.3.1.2">4</sup>Unbabel,
<sup class="ltx_sup" id="p1.1.2.1.1.3.1.3">5</sup>ELLIS Unit Lisbon</span></span>
</span></span></p>
<br class="ltx_break ltx_centering"/>
</div>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">The inherent design of attention—the underlying mechanism of transformers—leads to quadratic computational costs and challenges in length generalization <cite class="ltx_cite ltx_citemacro_citep">(Varis and Bojar, <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib43" title="">2021</a>)</cite>.
As an alternative, recent works propose to replace attention with linear recurrent approaches, which enjoy efficient training and inference, and obtain competitive results in language modeling tasks <cite class="ltx_cite ltx_citemacro_citep">(Katharopoulos et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib25" title="">2020</a>; Gu et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib21" title="">2022</a>; Peng et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib28" title="">2023</a>; Sun et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib38" title="">2023a</a>; Gu and Dao, <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib19" title="">2023</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">In machine translation (MT), there is an increasing demand for supporting longer context lengths, such as paragraphs or entire documents <cite class="ltx_cite ltx_citemacro_citep">(Fernandes et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib13" title="">2021</a>; Wang et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib45" title="">2023</a>; Kocmi et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib26" title="">2023</a>)</cite>.
Given this trend, it has become increasingly important to design models capable of efficiently handling longer sequences.
Previous research indicates that models like state space models (SSMs), exemplified by S4 <cite class="ltx_cite ltx_citemacro_citep">(Gu et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib21" title="">2022</a>)</cite>, still lag behind transformers in MT <cite class="ltx_cite ltx_citemacro_citep">(Vardasbi et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib42" title="">2023</a>)</cite>.
However, it remains unclear whether these findings hold true for recent, more expressive variations of linear recurrent models, such as RetNet <cite class="ltx_cite ltx_citemacro_citep">(Sun et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib38" title="">2023a</a>)</cite> and Mamba <cite class="ltx_cite ltx_citemacro_citep">(Gu and Dao, <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib19" title="">2023</a>)</cite>, especially on settings that involve the use of pretrained models and long context datasets.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">In this paper, we provide a rigorous and comprehensive experimental comparison between transformers, RetNet, Mamba, as well as hybrid versions of Mamba that incorporate attention mechanisms (§<a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#S4" title="4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_tag">4</span></a>).
We also compare with pretrained Mamba and Pythia <cite class="ltx_cite ltx_citemacro_citep">(Biderman et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib6" title="">2023</a>)</cite> at two parameter scales, <math alttext="\sim" class="ltx_Math" display="inline" id="S1.p3.1.m1.1"><semantics id="S1.p3.1.m1.1a"><mo id="S1.p3.1.m1.1.1" xref="S1.p3.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S1.p3.1.m1.1b"><csymbol cd="latexml" id="S1.p3.1.m1.1.1.cmml" xref="S1.p3.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S1.p3.1.m1.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S1.p3.1.m1.1d">∼</annotation></semantics></math>400M and 1.4B.
Building on existing literature that explores the capabilities of linear recurrent models in language modeling <cite class="ltx_cite ltx_citemacro_citep">(Arora et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib3" title="">2023</a>; Jelassi et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib24" title="">2024</a>)</cite>,
we further investigate the performance of models trained from scratch in recalling context tokens during the translation process (§<a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#S4.SS2" title="4.2 Recall of Named Entities ‣ 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_tag">4.2</span></a>).
Moreover, we extend our analysis by investigating the models’ ability to handle long contexts, on paragraph-level datasets (§<a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#S5" title="5 Paragraph-level translation ‣ 4.2 Recall of Named Entities ‣ 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_tag">5</span></a>), along with
measuring their sensitivity to different sequence lengths (§<a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#S5.SS2" title="5.2 Sensitivity to Input Length ‣ Finetuning outperforms training from scratch. ‣ 5.1 Discussion ‣ 5 Paragraph-level translation ‣ 4.2 Recall of Named Entities ‣ 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_tag">5.2</span></a>) and inference cost (§<a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#S5.SS3" title="5.3 Inference Cost ‣ Discussion. ‣ 5.2 Sensitivity to Input Length ‣ Finetuning outperforms training from scratch. ‣ 5.1 Discussion ‣ 5 Paragraph-level translation ‣ 4.2 Recall of Named Entities ‣ 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_tag">5.3</span></a>).
Overall, our main findings are:<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/deep-spin/ssm-mt" title="">https://github.com/deep-spin/ssm-mt</a></span></span></span></p>
</div>
<div class="ltx_para" id="S1.p4">
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">For sentence-level experiments, we show that Mamba exhibits competitive performance compared to transformers, for both trained-from-scratch and pretrained models.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">At the paragraph level, we find that Mamba is sensitive to the training distribution’s sequence length and struggles with longer inputs. However, shifting the distribution towards longer sequence lengths helps to close the gap with transformers.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">We observe that integrating attention and state space models creates a strong model in terms of translation quality, robustness to sequence length extrapolation, and ability to recall named entities.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Background</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">In this section, we present an overview of transformers, and the foundation of the linear recurrent models covered in this paper: linear attention (RetNet) and state space models (Mamba).</p>
</div>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Transformers</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.5">The key component in the transformer architecture is the attention mechanism, which is responsible for contextualizing information within and across input sequences.
Concretely, given query
<math alttext="\bm{Q}\in\mathbb{R}^{n\times d}" class="ltx_Math" display="inline" id="S2.SS1.p1.1.m1.1"><semantics id="S2.SS1.p1.1.m1.1a"><mrow id="S2.SS1.p1.1.m1.1.1" xref="S2.SS1.p1.1.m1.1.1.cmml"><mi id="S2.SS1.p1.1.m1.1.1.2" xref="S2.SS1.p1.1.m1.1.1.2.cmml">𝑸</mi><mo id="S2.SS1.p1.1.m1.1.1.1" xref="S2.SS1.p1.1.m1.1.1.1.cmml">∈</mo><msup id="S2.SS1.p1.1.m1.1.1.3" xref="S2.SS1.p1.1.m1.1.1.3.cmml"><mi id="S2.SS1.p1.1.m1.1.1.3.2" xref="S2.SS1.p1.1.m1.1.1.3.2.cmml">ℝ</mi><mrow id="S2.SS1.p1.1.m1.1.1.3.3" xref="S2.SS1.p1.1.m1.1.1.3.3.cmml"><mi id="S2.SS1.p1.1.m1.1.1.3.3.2" xref="S2.SS1.p1.1.m1.1.1.3.3.2.cmml">n</mi><mo id="S2.SS1.p1.1.m1.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S2.SS1.p1.1.m1.1.1.3.3.1.cmml">×</mo><mi id="S2.SS1.p1.1.m1.1.1.3.3.3" xref="S2.SS1.p1.1.m1.1.1.3.3.3.cmml">d</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.1.m1.1b"><apply id="S2.SS1.p1.1.m1.1.1.cmml" xref="S2.SS1.p1.1.m1.1.1"><in id="S2.SS1.p1.1.m1.1.1.1.cmml" xref="S2.SS1.p1.1.m1.1.1.1"></in><ci id="S2.SS1.p1.1.m1.1.1.2.cmml" xref="S2.SS1.p1.1.m1.1.1.2">𝑸</ci><apply id="S2.SS1.p1.1.m1.1.1.3.cmml" xref="S2.SS1.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S2.SS1.p1.1.m1.1.1.3.1.cmml" xref="S2.SS1.p1.1.m1.1.1.3">superscript</csymbol><ci id="S2.SS1.p1.1.m1.1.1.3.2.cmml" xref="S2.SS1.p1.1.m1.1.1.3.2">ℝ</ci><apply id="S2.SS1.p1.1.m1.1.1.3.3.cmml" xref="S2.SS1.p1.1.m1.1.1.3.3"><times id="S2.SS1.p1.1.m1.1.1.3.3.1.cmml" xref="S2.SS1.p1.1.m1.1.1.3.3.1"></times><ci id="S2.SS1.p1.1.m1.1.1.3.3.2.cmml" xref="S2.SS1.p1.1.m1.1.1.3.3.2">𝑛</ci><ci id="S2.SS1.p1.1.m1.1.1.3.3.3.cmml" xref="S2.SS1.p1.1.m1.1.1.3.3.3">𝑑</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.1.m1.1c">\bm{Q}\in\mathbb{R}^{n\times d}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.1.m1.1d">bold_italic_Q ∈ blackboard_R start_POSTSUPERSCRIPT italic_n × italic_d end_POSTSUPERSCRIPT</annotation></semantics></math>, key <math alttext="\bm{K}\in\mathbb{R}^{n\times d}" class="ltx_Math" display="inline" id="S2.SS1.p1.2.m2.1"><semantics id="S2.SS1.p1.2.m2.1a"><mrow id="S2.SS1.p1.2.m2.1.1" xref="S2.SS1.p1.2.m2.1.1.cmml"><mi id="S2.SS1.p1.2.m2.1.1.2" xref="S2.SS1.p1.2.m2.1.1.2.cmml">𝑲</mi><mo id="S2.SS1.p1.2.m2.1.1.1" xref="S2.SS1.p1.2.m2.1.1.1.cmml">∈</mo><msup id="S2.SS1.p1.2.m2.1.1.3" xref="S2.SS1.p1.2.m2.1.1.3.cmml"><mi id="S2.SS1.p1.2.m2.1.1.3.2" xref="S2.SS1.p1.2.m2.1.1.3.2.cmml">ℝ</mi><mrow id="S2.SS1.p1.2.m2.1.1.3.3" xref="S2.SS1.p1.2.m2.1.1.3.3.cmml"><mi id="S2.SS1.p1.2.m2.1.1.3.3.2" xref="S2.SS1.p1.2.m2.1.1.3.3.2.cmml">n</mi><mo id="S2.SS1.p1.2.m2.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S2.SS1.p1.2.m2.1.1.3.3.1.cmml">×</mo><mi id="S2.SS1.p1.2.m2.1.1.3.3.3" xref="S2.SS1.p1.2.m2.1.1.3.3.3.cmml">d</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.2.m2.1b"><apply id="S2.SS1.p1.2.m2.1.1.cmml" xref="S2.SS1.p1.2.m2.1.1"><in id="S2.SS1.p1.2.m2.1.1.1.cmml" xref="S2.SS1.p1.2.m2.1.1.1"></in><ci id="S2.SS1.p1.2.m2.1.1.2.cmml" xref="S2.SS1.p1.2.m2.1.1.2">𝑲</ci><apply id="S2.SS1.p1.2.m2.1.1.3.cmml" xref="S2.SS1.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S2.SS1.p1.2.m2.1.1.3.1.cmml" xref="S2.SS1.p1.2.m2.1.1.3">superscript</csymbol><ci id="S2.SS1.p1.2.m2.1.1.3.2.cmml" xref="S2.SS1.p1.2.m2.1.1.3.2">ℝ</ci><apply id="S2.SS1.p1.2.m2.1.1.3.3.cmml" xref="S2.SS1.p1.2.m2.1.1.3.3"><times id="S2.SS1.p1.2.m2.1.1.3.3.1.cmml" xref="S2.SS1.p1.2.m2.1.1.3.3.1"></times><ci id="S2.SS1.p1.2.m2.1.1.3.3.2.cmml" xref="S2.SS1.p1.2.m2.1.1.3.3.2">𝑛</ci><ci id="S2.SS1.p1.2.m2.1.1.3.3.3.cmml" xref="S2.SS1.p1.2.m2.1.1.3.3.3">𝑑</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.2.m2.1c">\bm{K}\in\mathbb{R}^{n\times d}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.2.m2.1d">bold_italic_K ∈ blackboard_R start_POSTSUPERSCRIPT italic_n × italic_d end_POSTSUPERSCRIPT</annotation></semantics></math>, and value <math alttext="\bm{V}\in\mathbb{R}^{n\times d}" class="ltx_Math" display="inline" id="S2.SS1.p1.3.m3.1"><semantics id="S2.SS1.p1.3.m3.1a"><mrow id="S2.SS1.p1.3.m3.1.1" xref="S2.SS1.p1.3.m3.1.1.cmml"><mi id="S2.SS1.p1.3.m3.1.1.2" xref="S2.SS1.p1.3.m3.1.1.2.cmml">𝑽</mi><mo id="S2.SS1.p1.3.m3.1.1.1" xref="S2.SS1.p1.3.m3.1.1.1.cmml">∈</mo><msup id="S2.SS1.p1.3.m3.1.1.3" xref="S2.SS1.p1.3.m3.1.1.3.cmml"><mi id="S2.SS1.p1.3.m3.1.1.3.2" xref="S2.SS1.p1.3.m3.1.1.3.2.cmml">ℝ</mi><mrow id="S2.SS1.p1.3.m3.1.1.3.3" xref="S2.SS1.p1.3.m3.1.1.3.3.cmml"><mi id="S2.SS1.p1.3.m3.1.1.3.3.2" xref="S2.SS1.p1.3.m3.1.1.3.3.2.cmml">n</mi><mo id="S2.SS1.p1.3.m3.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S2.SS1.p1.3.m3.1.1.3.3.1.cmml">×</mo><mi id="S2.SS1.p1.3.m3.1.1.3.3.3" xref="S2.SS1.p1.3.m3.1.1.3.3.3.cmml">d</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.3.m3.1b"><apply id="S2.SS1.p1.3.m3.1.1.cmml" xref="S2.SS1.p1.3.m3.1.1"><in id="S2.SS1.p1.3.m3.1.1.1.cmml" xref="S2.SS1.p1.3.m3.1.1.1"></in><ci id="S2.SS1.p1.3.m3.1.1.2.cmml" xref="S2.SS1.p1.3.m3.1.1.2">𝑽</ci><apply id="S2.SS1.p1.3.m3.1.1.3.cmml" xref="S2.SS1.p1.3.m3.1.1.3"><csymbol cd="ambiguous" id="S2.SS1.p1.3.m3.1.1.3.1.cmml" xref="S2.SS1.p1.3.m3.1.1.3">superscript</csymbol><ci id="S2.SS1.p1.3.m3.1.1.3.2.cmml" xref="S2.SS1.p1.3.m3.1.1.3.2">ℝ</ci><apply id="S2.SS1.p1.3.m3.1.1.3.3.cmml" xref="S2.SS1.p1.3.m3.1.1.3.3"><times id="S2.SS1.p1.3.m3.1.1.3.3.1.cmml" xref="S2.SS1.p1.3.m3.1.1.3.3.1"></times><ci id="S2.SS1.p1.3.m3.1.1.3.3.2.cmml" xref="S2.SS1.p1.3.m3.1.1.3.3.2">𝑛</ci><ci id="S2.SS1.p1.3.m3.1.1.3.3.3.cmml" xref="S2.SS1.p1.3.m3.1.1.3.3.3">𝑑</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.3.m3.1c">\bm{V}\in\mathbb{R}^{n\times d}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.3.m3.1d">bold_italic_V ∈ blackboard_R start_POSTSUPERSCRIPT italic_n × italic_d end_POSTSUPERSCRIPT</annotation></semantics></math> matrices as input, where <math alttext="n" class="ltx_Math" display="inline" id="S2.SS1.p1.4.m4.1"><semantics id="S2.SS1.p1.4.m4.1a"><mi id="S2.SS1.p1.4.m4.1.1" xref="S2.SS1.p1.4.m4.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.4.m4.1b"><ci id="S2.SS1.p1.4.m4.1.1.cmml" xref="S2.SS1.p1.4.m4.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.4.m4.1c">n</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.4.m4.1d">italic_n</annotation></semantics></math> is the sequence length and <math alttext="d" class="ltx_Math" display="inline" id="S2.SS1.p1.5.m5.1"><semantics id="S2.SS1.p1.5.m5.1a"><mi id="S2.SS1.p1.5.m5.1.1" xref="S2.SS1.p1.5.m5.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.5.m5.1b"><ci id="S2.SS1.p1.5.m5.1.1.cmml" xref="S2.SS1.p1.5.m5.1.1">𝑑</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.5.m5.1c">d</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.5.m5.1d">italic_d</annotation></semantics></math> the hidden size,
the single head <span class="ltx_text ltx_font_italic" id="S2.SS1.p1.5.1">self-attention mechanism</span> is defined as follows <cite class="ltx_cite ltx_citemacro_citep">(Vaswani et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib44" title="">2017</a>)</cite>:</p>
<table class="ltx_equation ltx_eqn_table" id="S2.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\bm{Y}=\textsf{softmax}\Bigg{(}\frac{\bm{Q}\bm{K}^{\top}}{\sqrt{d}}\Bigg{)}\bm%
{V}\in\mathbb{R}^{n\times d}." class="ltx_Math" display="block" id="S2.E1.m1.2"><semantics id="S2.E1.m1.2a"><mrow id="S2.E1.m1.2.2.1" xref="S2.E1.m1.2.2.1.1.cmml"><mrow id="S2.E1.m1.2.2.1.1" xref="S2.E1.m1.2.2.1.1.cmml"><mi id="S2.E1.m1.2.2.1.1.2" xref="S2.E1.m1.2.2.1.1.2.cmml">𝒀</mi><mo id="S2.E1.m1.2.2.1.1.3" xref="S2.E1.m1.2.2.1.1.3.cmml">=</mo><mrow id="S2.E1.m1.2.2.1.1.4" xref="S2.E1.m1.2.2.1.1.4.cmml"><mtext class="ltx_mathvariant_sans-serif" id="S2.E1.m1.2.2.1.1.4.2" xref="S2.E1.m1.2.2.1.1.4.2a.cmml">softmax</mtext><mo id="S2.E1.m1.2.2.1.1.4.1" xref="S2.E1.m1.2.2.1.1.4.1.cmml">⁢</mo><mrow id="S2.E1.m1.2.2.1.1.4.3.2" xref="S2.E1.m1.1.1.cmml"><mo id="S2.E1.m1.2.2.1.1.4.3.2.1" maxsize="260%" minsize="260%" xref="S2.E1.m1.1.1.cmml">(</mo><mfrac id="S2.E1.m1.1.1" xref="S2.E1.m1.1.1.cmml"><mrow id="S2.E1.m1.1.1.2" xref="S2.E1.m1.1.1.2.cmml"><mi id="S2.E1.m1.1.1.2.2" xref="S2.E1.m1.1.1.2.2.cmml">𝑸</mi><mo id="S2.E1.m1.1.1.2.1" xref="S2.E1.m1.1.1.2.1.cmml">⁢</mo><msup id="S2.E1.m1.1.1.2.3" xref="S2.E1.m1.1.1.2.3.cmml"><mi id="S2.E1.m1.1.1.2.3.2" xref="S2.E1.m1.1.1.2.3.2.cmml">𝑲</mi><mo id="S2.E1.m1.1.1.2.3.3" xref="S2.E1.m1.1.1.2.3.3.cmml">⊤</mo></msup></mrow><msqrt id="S2.E1.m1.1.1.3" xref="S2.E1.m1.1.1.3.cmml"><mi id="S2.E1.m1.1.1.3.2" xref="S2.E1.m1.1.1.3.2.cmml">d</mi></msqrt></mfrac><mo id="S2.E1.m1.2.2.1.1.4.3.2.2" maxsize="260%" minsize="260%" xref="S2.E1.m1.1.1.cmml">)</mo></mrow><mo id="S2.E1.m1.2.2.1.1.4.1a" xref="S2.E1.m1.2.2.1.1.4.1.cmml">⁢</mo><mi id="S2.E1.m1.2.2.1.1.4.4" xref="S2.E1.m1.2.2.1.1.4.4.cmml">𝑽</mi></mrow><mo id="S2.E1.m1.2.2.1.1.5" xref="S2.E1.m1.2.2.1.1.5.cmml">∈</mo><msup id="S2.E1.m1.2.2.1.1.6" xref="S2.E1.m1.2.2.1.1.6.cmml"><mi id="S2.E1.m1.2.2.1.1.6.2" xref="S2.E1.m1.2.2.1.1.6.2.cmml">ℝ</mi><mrow id="S2.E1.m1.2.2.1.1.6.3" xref="S2.E1.m1.2.2.1.1.6.3.cmml"><mi id="S2.E1.m1.2.2.1.1.6.3.2" xref="S2.E1.m1.2.2.1.1.6.3.2.cmml">n</mi><mo id="S2.E1.m1.2.2.1.1.6.3.1" lspace="0.222em" rspace="0.222em" xref="S2.E1.m1.2.2.1.1.6.3.1.cmml">×</mo><mi id="S2.E1.m1.2.2.1.1.6.3.3" xref="S2.E1.m1.2.2.1.1.6.3.3.cmml">d</mi></mrow></msup></mrow><mo id="S2.E1.m1.2.2.1.2" lspace="0em" xref="S2.E1.m1.2.2.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.2b"><apply id="S2.E1.m1.2.2.1.1.cmml" xref="S2.E1.m1.2.2.1"><and id="S2.E1.m1.2.2.1.1a.cmml" xref="S2.E1.m1.2.2.1"></and><apply id="S2.E1.m1.2.2.1.1b.cmml" xref="S2.E1.m1.2.2.1"><eq id="S2.E1.m1.2.2.1.1.3.cmml" xref="S2.E1.m1.2.2.1.1.3"></eq><ci id="S2.E1.m1.2.2.1.1.2.cmml" xref="S2.E1.m1.2.2.1.1.2">𝒀</ci><apply id="S2.E1.m1.2.2.1.1.4.cmml" xref="S2.E1.m1.2.2.1.1.4"><times id="S2.E1.m1.2.2.1.1.4.1.cmml" xref="S2.E1.m1.2.2.1.1.4.1"></times><ci id="S2.E1.m1.2.2.1.1.4.2a.cmml" xref="S2.E1.m1.2.2.1.1.4.2"><mtext class="ltx_mathvariant_sans-serif" id="S2.E1.m1.2.2.1.1.4.2.cmml" xref="S2.E1.m1.2.2.1.1.4.2">softmax</mtext></ci><apply id="S2.E1.m1.1.1.cmml" xref="S2.E1.m1.2.2.1.1.4.3.2"><divide id="S2.E1.m1.1.1.1.cmml" xref="S2.E1.m1.2.2.1.1.4.3.2"></divide><apply id="S2.E1.m1.1.1.2.cmml" xref="S2.E1.m1.1.1.2"><times id="S2.E1.m1.1.1.2.1.cmml" xref="S2.E1.m1.1.1.2.1"></times><ci id="S2.E1.m1.1.1.2.2.cmml" xref="S2.E1.m1.1.1.2.2">𝑸</ci><apply id="S2.E1.m1.1.1.2.3.cmml" xref="S2.E1.m1.1.1.2.3"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.2.3.1.cmml" xref="S2.E1.m1.1.1.2.3">superscript</csymbol><ci id="S2.E1.m1.1.1.2.3.2.cmml" xref="S2.E1.m1.1.1.2.3.2">𝑲</ci><csymbol cd="latexml" id="S2.E1.m1.1.1.2.3.3.cmml" xref="S2.E1.m1.1.1.2.3.3">top</csymbol></apply></apply><apply id="S2.E1.m1.1.1.3.cmml" xref="S2.E1.m1.1.1.3"><root id="S2.E1.m1.1.1.3a.cmml" xref="S2.E1.m1.1.1.3"></root><ci id="S2.E1.m1.1.1.3.2.cmml" xref="S2.E1.m1.1.1.3.2">𝑑</ci></apply></apply><ci id="S2.E1.m1.2.2.1.1.4.4.cmml" xref="S2.E1.m1.2.2.1.1.4.4">𝑽</ci></apply></apply><apply id="S2.E1.m1.2.2.1.1c.cmml" xref="S2.E1.m1.2.2.1"><in id="S2.E1.m1.2.2.1.1.5.cmml" xref="S2.E1.m1.2.2.1.1.5"></in><share href="https://arxiv.org/html/2407.05489v1#S2.E1.m1.2.2.1.1.4.cmml" id="S2.E1.m1.2.2.1.1d.cmml" xref="S2.E1.m1.2.2.1"></share><apply id="S2.E1.m1.2.2.1.1.6.cmml" xref="S2.E1.m1.2.2.1.1.6"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.1.1.6.1.cmml" xref="S2.E1.m1.2.2.1.1.6">superscript</csymbol><ci id="S2.E1.m1.2.2.1.1.6.2.cmml" xref="S2.E1.m1.2.2.1.1.6.2">ℝ</ci><apply id="S2.E1.m1.2.2.1.1.6.3.cmml" xref="S2.E1.m1.2.2.1.1.6.3"><times id="S2.E1.m1.2.2.1.1.6.3.1.cmml" xref="S2.E1.m1.2.2.1.1.6.3.1"></times><ci id="S2.E1.m1.2.2.1.1.6.3.2.cmml" xref="S2.E1.m1.2.2.1.1.6.3.2">𝑛</ci><ci id="S2.E1.m1.2.2.1.1.6.3.3.cmml" xref="S2.E1.m1.2.2.1.1.6.3.3">𝑑</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.2c">\bm{Y}=\textsf{softmax}\Bigg{(}\frac{\bm{Q}\bm{K}^{\top}}{\sqrt{d}}\Bigg{)}\bm%
{V}\in\mathbb{R}^{n\times d}.</annotation><annotation encoding="application/x-llamapun" id="S2.E1.m1.2d">bold_italic_Y = softmax ( divide start_ARG bold_italic_Q bold_italic_K start_POSTSUPERSCRIPT ⊤ end_POSTSUPERSCRIPT end_ARG start_ARG square-root start_ARG italic_d end_ARG end_ARG ) bold_italic_V ∈ blackboard_R start_POSTSUPERSCRIPT italic_n × italic_d end_POSTSUPERSCRIPT .</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S2.SS1.p1.8">For decoder-only models, a causal mask is used to ignore future tokens.
Notably, the <math alttext="\bm{Q}\bm{K}^{\top}" class="ltx_Math" display="inline" id="S2.SS1.p1.6.m1.1"><semantics id="S2.SS1.p1.6.m1.1a"><mrow id="S2.SS1.p1.6.m1.1.1" xref="S2.SS1.p1.6.m1.1.1.cmml"><mi id="S2.SS1.p1.6.m1.1.1.2" xref="S2.SS1.p1.6.m1.1.1.2.cmml">𝑸</mi><mo id="S2.SS1.p1.6.m1.1.1.1" xref="S2.SS1.p1.6.m1.1.1.1.cmml">⁢</mo><msup id="S2.SS1.p1.6.m1.1.1.3" xref="S2.SS1.p1.6.m1.1.1.3.cmml"><mi id="S2.SS1.p1.6.m1.1.1.3.2" xref="S2.SS1.p1.6.m1.1.1.3.2.cmml">𝑲</mi><mo id="S2.SS1.p1.6.m1.1.1.3.3" xref="S2.SS1.p1.6.m1.1.1.3.3.cmml">⊤</mo></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.6.m1.1b"><apply id="S2.SS1.p1.6.m1.1.1.cmml" xref="S2.SS1.p1.6.m1.1.1"><times id="S2.SS1.p1.6.m1.1.1.1.cmml" xref="S2.SS1.p1.6.m1.1.1.1"></times><ci id="S2.SS1.p1.6.m1.1.1.2.cmml" xref="S2.SS1.p1.6.m1.1.1.2">𝑸</ci><apply id="S2.SS1.p1.6.m1.1.1.3.cmml" xref="S2.SS1.p1.6.m1.1.1.3"><csymbol cd="ambiguous" id="S2.SS1.p1.6.m1.1.1.3.1.cmml" xref="S2.SS1.p1.6.m1.1.1.3">superscript</csymbol><ci id="S2.SS1.p1.6.m1.1.1.3.2.cmml" xref="S2.SS1.p1.6.m1.1.1.3.2">𝑲</ci><csymbol cd="latexml" id="S2.SS1.p1.6.m1.1.1.3.3.cmml" xref="S2.SS1.p1.6.m1.1.1.3.3">top</csymbol></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.6.m1.1c">\bm{Q}\bm{K}^{\top}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.6.m1.1d">bold_italic_Q bold_italic_K start_POSTSUPERSCRIPT ⊤ end_POSTSUPERSCRIPT</annotation></semantics></math> operation leads to a <math alttext="\mathcal{O}\left(n^{2}\right)" class="ltx_Math" display="inline" id="S2.SS1.p1.7.m2.1"><semantics id="S2.SS1.p1.7.m2.1a"><mrow id="S2.SS1.p1.7.m2.1.1" xref="S2.SS1.p1.7.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p1.7.m2.1.1.3" xref="S2.SS1.p1.7.m2.1.1.3.cmml">𝒪</mi><mo id="S2.SS1.p1.7.m2.1.1.2" xref="S2.SS1.p1.7.m2.1.1.2.cmml">⁢</mo><mrow id="S2.SS1.p1.7.m2.1.1.1.1" xref="S2.SS1.p1.7.m2.1.1.1.1.1.cmml"><mo id="S2.SS1.p1.7.m2.1.1.1.1.2" xref="S2.SS1.p1.7.m2.1.1.1.1.1.cmml">(</mo><msup id="S2.SS1.p1.7.m2.1.1.1.1.1" xref="S2.SS1.p1.7.m2.1.1.1.1.1.cmml"><mi id="S2.SS1.p1.7.m2.1.1.1.1.1.2" xref="S2.SS1.p1.7.m2.1.1.1.1.1.2.cmml">n</mi><mn id="S2.SS1.p1.7.m2.1.1.1.1.1.3" xref="S2.SS1.p1.7.m2.1.1.1.1.1.3.cmml">2</mn></msup><mo id="S2.SS1.p1.7.m2.1.1.1.1.3" xref="S2.SS1.p1.7.m2.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.7.m2.1b"><apply id="S2.SS1.p1.7.m2.1.1.cmml" xref="S2.SS1.p1.7.m2.1.1"><times id="S2.SS1.p1.7.m2.1.1.2.cmml" xref="S2.SS1.p1.7.m2.1.1.2"></times><ci id="S2.SS1.p1.7.m2.1.1.3.cmml" xref="S2.SS1.p1.7.m2.1.1.3">𝒪</ci><apply id="S2.SS1.p1.7.m2.1.1.1.1.1.cmml" xref="S2.SS1.p1.7.m2.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.7.m2.1.1.1.1.1.1.cmml" xref="S2.SS1.p1.7.m2.1.1.1.1">superscript</csymbol><ci id="S2.SS1.p1.7.m2.1.1.1.1.1.2.cmml" xref="S2.SS1.p1.7.m2.1.1.1.1.1.2">𝑛</ci><cn id="S2.SS1.p1.7.m2.1.1.1.1.1.3.cmml" type="integer" xref="S2.SS1.p1.7.m2.1.1.1.1.1.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.7.m2.1c">\mathcal{O}\left(n^{2}\right)</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.7.m2.1d">caligraphic_O ( italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT )</annotation></semantics></math> cost during training, and <math alttext="\mathcal{O}\left(n\right)" class="ltx_Math" display="inline" id="S2.SS1.p1.8.m3.1"><semantics id="S2.SS1.p1.8.m3.1a"><mrow id="S2.SS1.p1.8.m3.1.2" xref="S2.SS1.p1.8.m3.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p1.8.m3.1.2.2" xref="S2.SS1.p1.8.m3.1.2.2.cmml">𝒪</mi><mo id="S2.SS1.p1.8.m3.1.2.1" xref="S2.SS1.p1.8.m3.1.2.1.cmml">⁢</mo><mrow id="S2.SS1.p1.8.m3.1.2.3.2" xref="S2.SS1.p1.8.m3.1.2.cmml"><mo id="S2.SS1.p1.8.m3.1.2.3.2.1" xref="S2.SS1.p1.8.m3.1.2.cmml">(</mo><mi id="S2.SS1.p1.8.m3.1.1" xref="S2.SS1.p1.8.m3.1.1.cmml">n</mi><mo id="S2.SS1.p1.8.m3.1.2.3.2.2" xref="S2.SS1.p1.8.m3.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.8.m3.1b"><apply id="S2.SS1.p1.8.m3.1.2.cmml" xref="S2.SS1.p1.8.m3.1.2"><times id="S2.SS1.p1.8.m3.1.2.1.cmml" xref="S2.SS1.p1.8.m3.1.2.1"></times><ci id="S2.SS1.p1.8.m3.1.2.2.cmml" xref="S2.SS1.p1.8.m3.1.2.2">𝒪</ci><ci id="S2.SS1.p1.8.m3.1.1.cmml" xref="S2.SS1.p1.8.m3.1.1">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.8.m3.1c">\mathcal{O}\left(n\right)</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.8.m3.1d">caligraphic_O ( italic_n )</annotation></semantics></math> during inference with caching and causal masking.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Linear Attention</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.4">Denote by <math alttext="\bm{q}_{i},\bm{k}_{i},\bm{v}_{i},\bm{y}_{i}\in\mathbb{R}^{d}" class="ltx_Math" display="inline" id="S2.SS2.p1.1.m1.4"><semantics id="S2.SS2.p1.1.m1.4a"><mrow id="S2.SS2.p1.1.m1.4.4" xref="S2.SS2.p1.1.m1.4.4.cmml"><mrow id="S2.SS2.p1.1.m1.4.4.4.4" xref="S2.SS2.p1.1.m1.4.4.4.5.cmml"><msub id="S2.SS2.p1.1.m1.1.1.1.1.1" xref="S2.SS2.p1.1.m1.1.1.1.1.1.cmml"><mi id="S2.SS2.p1.1.m1.1.1.1.1.1.2" xref="S2.SS2.p1.1.m1.1.1.1.1.1.2.cmml">𝒒</mi><mi id="S2.SS2.p1.1.m1.1.1.1.1.1.3" xref="S2.SS2.p1.1.m1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S2.SS2.p1.1.m1.4.4.4.4.5" xref="S2.SS2.p1.1.m1.4.4.4.5.cmml">,</mo><msub id="S2.SS2.p1.1.m1.2.2.2.2.2" xref="S2.SS2.p1.1.m1.2.2.2.2.2.cmml"><mi id="S2.SS2.p1.1.m1.2.2.2.2.2.2" xref="S2.SS2.p1.1.m1.2.2.2.2.2.2.cmml">𝒌</mi><mi id="S2.SS2.p1.1.m1.2.2.2.2.2.3" xref="S2.SS2.p1.1.m1.2.2.2.2.2.3.cmml">i</mi></msub><mo id="S2.SS2.p1.1.m1.4.4.4.4.6" xref="S2.SS2.p1.1.m1.4.4.4.5.cmml">,</mo><msub id="S2.SS2.p1.1.m1.3.3.3.3.3" xref="S2.SS2.p1.1.m1.3.3.3.3.3.cmml"><mi id="S2.SS2.p1.1.m1.3.3.3.3.3.2" xref="S2.SS2.p1.1.m1.3.3.3.3.3.2.cmml">𝒗</mi><mi id="S2.SS2.p1.1.m1.3.3.3.3.3.3" xref="S2.SS2.p1.1.m1.3.3.3.3.3.3.cmml">i</mi></msub><mo id="S2.SS2.p1.1.m1.4.4.4.4.7" xref="S2.SS2.p1.1.m1.4.4.4.5.cmml">,</mo><msub id="S2.SS2.p1.1.m1.4.4.4.4.4" xref="S2.SS2.p1.1.m1.4.4.4.4.4.cmml"><mi id="S2.SS2.p1.1.m1.4.4.4.4.4.2" xref="S2.SS2.p1.1.m1.4.4.4.4.4.2.cmml">𝒚</mi><mi id="S2.SS2.p1.1.m1.4.4.4.4.4.3" xref="S2.SS2.p1.1.m1.4.4.4.4.4.3.cmml">i</mi></msub></mrow><mo id="S2.SS2.p1.1.m1.4.4.5" xref="S2.SS2.p1.1.m1.4.4.5.cmml">∈</mo><msup id="S2.SS2.p1.1.m1.4.4.6" xref="S2.SS2.p1.1.m1.4.4.6.cmml"><mi id="S2.SS2.p1.1.m1.4.4.6.2" xref="S2.SS2.p1.1.m1.4.4.6.2.cmml">ℝ</mi><mi id="S2.SS2.p1.1.m1.4.4.6.3" xref="S2.SS2.p1.1.m1.4.4.6.3.cmml">d</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.1.m1.4b"><apply id="S2.SS2.p1.1.m1.4.4.cmml" xref="S2.SS2.p1.1.m1.4.4"><in id="S2.SS2.p1.1.m1.4.4.5.cmml" xref="S2.SS2.p1.1.m1.4.4.5"></in><list id="S2.SS2.p1.1.m1.4.4.4.5.cmml" xref="S2.SS2.p1.1.m1.4.4.4.4"><apply id="S2.SS2.p1.1.m1.1.1.1.1.1.cmml" xref="S2.SS2.p1.1.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.1.m1.1.1.1.1.1.1.cmml" xref="S2.SS2.p1.1.m1.1.1.1.1.1">subscript</csymbol><ci id="S2.SS2.p1.1.m1.1.1.1.1.1.2.cmml" xref="S2.SS2.p1.1.m1.1.1.1.1.1.2">𝒒</ci><ci id="S2.SS2.p1.1.m1.1.1.1.1.1.3.cmml" xref="S2.SS2.p1.1.m1.1.1.1.1.1.3">𝑖</ci></apply><apply id="S2.SS2.p1.1.m1.2.2.2.2.2.cmml" xref="S2.SS2.p1.1.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="S2.SS2.p1.1.m1.2.2.2.2.2.1.cmml" xref="S2.SS2.p1.1.m1.2.2.2.2.2">subscript</csymbol><ci id="S2.SS2.p1.1.m1.2.2.2.2.2.2.cmml" xref="S2.SS2.p1.1.m1.2.2.2.2.2.2">𝒌</ci><ci id="S2.SS2.p1.1.m1.2.2.2.2.2.3.cmml" xref="S2.SS2.p1.1.m1.2.2.2.2.2.3">𝑖</ci></apply><apply id="S2.SS2.p1.1.m1.3.3.3.3.3.cmml" xref="S2.SS2.p1.1.m1.3.3.3.3.3"><csymbol cd="ambiguous" id="S2.SS2.p1.1.m1.3.3.3.3.3.1.cmml" xref="S2.SS2.p1.1.m1.3.3.3.3.3">subscript</csymbol><ci id="S2.SS2.p1.1.m1.3.3.3.3.3.2.cmml" xref="S2.SS2.p1.1.m1.3.3.3.3.3.2">𝒗</ci><ci id="S2.SS2.p1.1.m1.3.3.3.3.3.3.cmml" xref="S2.SS2.p1.1.m1.3.3.3.3.3.3">𝑖</ci></apply><apply id="S2.SS2.p1.1.m1.4.4.4.4.4.cmml" xref="S2.SS2.p1.1.m1.4.4.4.4.4"><csymbol cd="ambiguous" id="S2.SS2.p1.1.m1.4.4.4.4.4.1.cmml" xref="S2.SS2.p1.1.m1.4.4.4.4.4">subscript</csymbol><ci id="S2.SS2.p1.1.m1.4.4.4.4.4.2.cmml" xref="S2.SS2.p1.1.m1.4.4.4.4.4.2">𝒚</ci><ci id="S2.SS2.p1.1.m1.4.4.4.4.4.3.cmml" xref="S2.SS2.p1.1.m1.4.4.4.4.4.3">𝑖</ci></apply></list><apply id="S2.SS2.p1.1.m1.4.4.6.cmml" xref="S2.SS2.p1.1.m1.4.4.6"><csymbol cd="ambiguous" id="S2.SS2.p1.1.m1.4.4.6.1.cmml" xref="S2.SS2.p1.1.m1.4.4.6">superscript</csymbol><ci id="S2.SS2.p1.1.m1.4.4.6.2.cmml" xref="S2.SS2.p1.1.m1.4.4.6.2">ℝ</ci><ci id="S2.SS2.p1.1.m1.4.4.6.3.cmml" xref="S2.SS2.p1.1.m1.4.4.6.3">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.1.m1.4c">\bm{q}_{i},\bm{k}_{i},\bm{v}_{i},\bm{y}_{i}\in\mathbb{R}^{d}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p1.1.m1.4d">bold_italic_q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_k start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT</annotation></semantics></math> respectively the (column) vectors corresponding to the <math alttext="i\textsuperscript{th}" class="ltx_Math" display="inline" id="S2.SS2.p1.2.m2.1"><semantics id="S2.SS2.p1.2.m2.1a"><mrow id="S2.SS2.p1.2.m2.1.1" xref="S2.SS2.p1.2.m2.1.1.cmml"><mi id="S2.SS2.p1.2.m2.1.1.2" xref="S2.SS2.p1.2.m2.1.1.2.cmml">i</mi><mo id="S2.SS2.p1.2.m2.1.1.1" xref="S2.SS2.p1.2.m2.1.1.1.cmml">⁢</mo><mtext id="S2.SS2.p1.2.m2.1.1.3" xref="S2.SS2.p1.2.m2.1.1.3b.cmml"><sup class="ltx_sup" id="S2.SS2.p1.2.m2.1.1.3.1nest">th</sup></mtext></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.2.m2.1b"><apply id="S2.SS2.p1.2.m2.1.1.cmml" xref="S2.SS2.p1.2.m2.1.1"><times id="S2.SS2.p1.2.m2.1.1.1.cmml" xref="S2.SS2.p1.2.m2.1.1.1"></times><ci id="S2.SS2.p1.2.m2.1.1.2.cmml" xref="S2.SS2.p1.2.m2.1.1.2">𝑖</ci><ci id="S2.SS2.p1.2.m2.1.1.3b.cmml" xref="S2.SS2.p1.2.m2.1.1.3"><mtext id="S2.SS2.p1.2.m2.1.1.3.cmml" xref="S2.SS2.p1.2.m2.1.1.3"><sup class="ltx_sup" id="S2.SS2.p1.2.m2.1.1.3.1anest">th</sup></mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.2.m2.1c">i\textsuperscript{th}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p1.2.m2.1d">italic_i</annotation></semantics></math> rows of the matrices <math alttext="\bm{Q},\bm{K},\bm{V},\bm{Y}" class="ltx_Math" display="inline" id="S2.SS2.p1.3.m3.4"><semantics id="S2.SS2.p1.3.m3.4a"><mrow id="S2.SS2.p1.3.m3.4.5.2" xref="S2.SS2.p1.3.m3.4.5.1.cmml"><mi id="S2.SS2.p1.3.m3.1.1" xref="S2.SS2.p1.3.m3.1.1.cmml">𝑸</mi><mo id="S2.SS2.p1.3.m3.4.5.2.1" xref="S2.SS2.p1.3.m3.4.5.1.cmml">,</mo><mi id="S2.SS2.p1.3.m3.2.2" xref="S2.SS2.p1.3.m3.2.2.cmml">𝑲</mi><mo id="S2.SS2.p1.3.m3.4.5.2.2" xref="S2.SS2.p1.3.m3.4.5.1.cmml">,</mo><mi id="S2.SS2.p1.3.m3.3.3" xref="S2.SS2.p1.3.m3.3.3.cmml">𝑽</mi><mo id="S2.SS2.p1.3.m3.4.5.2.3" xref="S2.SS2.p1.3.m3.4.5.1.cmml">,</mo><mi id="S2.SS2.p1.3.m3.4.4" xref="S2.SS2.p1.3.m3.4.4.cmml">𝒀</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.3.m3.4b"><list id="S2.SS2.p1.3.m3.4.5.1.cmml" xref="S2.SS2.p1.3.m3.4.5.2"><ci id="S2.SS2.p1.3.m3.1.1.cmml" xref="S2.SS2.p1.3.m3.1.1">𝑸</ci><ci id="S2.SS2.p1.3.m3.2.2.cmml" xref="S2.SS2.p1.3.m3.2.2">𝑲</ci><ci id="S2.SS2.p1.3.m3.3.3.cmml" xref="S2.SS2.p1.3.m3.3.3">𝑽</ci><ci id="S2.SS2.p1.3.m3.4.4.cmml" xref="S2.SS2.p1.3.m3.4.4">𝒀</ci></list></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.3.m3.4c">\bm{Q},\bm{K},\bm{V},\bm{Y}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p1.3.m3.4d">bold_italic_Q , bold_italic_K , bold_italic_V , bold_italic_Y</annotation></semantics></math> defined above.
<cite class="ltx_cite ltx_citemacro_citet">Katharopoulos et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib25" title="">2020</a>)</cite> reformulate the attention mechanism by casting the role of the softmax as a similarity function <math alttext="\textsf{sim}\left(\bm{q},\bm{k}\right)=\exp\left(\nicefrac{{\bm{q}^{\top}\bm{k%
}}}{{\sqrt{d}}}\right)" class="ltx_Math" display="inline" id="S2.SS2.p1.4.m4.4"><semantics id="S2.SS2.p1.4.m4.4a"><mrow id="S2.SS2.p1.4.m4.4.5" xref="S2.SS2.p1.4.m4.4.5.cmml"><mrow id="S2.SS2.p1.4.m4.4.5.2" xref="S2.SS2.p1.4.m4.4.5.2.cmml"><mtext class="ltx_mathvariant_sans-serif" id="S2.SS2.p1.4.m4.4.5.2.2" xref="S2.SS2.p1.4.m4.4.5.2.2a.cmml">sim</mtext><mo id="S2.SS2.p1.4.m4.4.5.2.1" xref="S2.SS2.p1.4.m4.4.5.2.1.cmml">⁢</mo><mrow id="S2.SS2.p1.4.m4.4.5.2.3.2" xref="S2.SS2.p1.4.m4.4.5.2.3.1.cmml"><mo id="S2.SS2.p1.4.m4.4.5.2.3.2.1" xref="S2.SS2.p1.4.m4.4.5.2.3.1.cmml">(</mo><mi id="S2.SS2.p1.4.m4.1.1" xref="S2.SS2.p1.4.m4.1.1.cmml">𝒒</mi><mo id="S2.SS2.p1.4.m4.4.5.2.3.2.2" xref="S2.SS2.p1.4.m4.4.5.2.3.1.cmml">,</mo><mi id="S2.SS2.p1.4.m4.2.2" xref="S2.SS2.p1.4.m4.2.2.cmml">𝒌</mi><mo id="S2.SS2.p1.4.m4.4.5.2.3.2.3" xref="S2.SS2.p1.4.m4.4.5.2.3.1.cmml">)</mo></mrow></mrow><mo id="S2.SS2.p1.4.m4.4.5.1" xref="S2.SS2.p1.4.m4.4.5.1.cmml">=</mo><mrow id="S2.SS2.p1.4.m4.4.5.3.2" xref="S2.SS2.p1.4.m4.4.5.3.1.cmml"><mi id="S2.SS2.p1.4.m4.3.3" xref="S2.SS2.p1.4.m4.3.3.cmml">exp</mi><mo id="S2.SS2.p1.4.m4.4.5.3.2a" xref="S2.SS2.p1.4.m4.4.5.3.1.cmml">⁡</mo><mrow id="S2.SS2.p1.4.m4.4.5.3.2.1" xref="S2.SS2.p1.4.m4.4.5.3.1.cmml"><mo id="S2.SS2.p1.4.m4.4.5.3.2.1.1" xref="S2.SS2.p1.4.m4.4.5.3.1.cmml">(</mo><mrow id="S2.SS2.p1.4.m4.4.4" xref="S2.SS2.p1.4.m4.4.4.cmml"><mpadded id="S2.SS2.p1.4.m4.4.4.2" voffset="0.3em" xref="S2.SS2.p1.4.m4.4.4.2.cmml"><msup id="S2.SS2.p1.4.m4.4.4.2.2" xref="S2.SS2.p1.4.m4.4.4.2.2.cmml"><mi id="S2.SS2.p1.4.m4.4.4.2.2.2" mathsize="70%" xref="S2.SS2.p1.4.m4.4.4.2.2.2.cmml">𝒒</mi><mo id="S2.SS2.p1.4.m4.4.4.2.2.3" mathsize="71%" xref="S2.SS2.p1.4.m4.4.4.2.2.3.cmml">⊤</mo></msup><mo id="S2.SS2.p1.4.m4.4.4.2.1" xref="S2.SS2.p1.4.m4.4.4.2.1.cmml">⁢</mo><mi id="S2.SS2.p1.4.m4.4.4.2.3" mathsize="70%" xref="S2.SS2.p1.4.m4.4.4.2.3.cmml">𝒌</mi></mpadded><mpadded id="S2.SS2.p1.4.m4.4.4.1" lspace="-0.1em" width="-0.15em" xref="S2.SS2.p1.4.m4.4.4.1.cmml"><mo id="S2.SS2.p1.4.m4.4.4.1a" stretchy="true" symmetric="true" xref="S2.SS2.p1.4.m4.4.4.1.cmml">/</mo></mpadded><msqrt id="S2.SS2.p1.4.m4.4.4.3" xref="S2.SS2.p1.4.m4.4.4.3.cmml"><mi id="S2.SS2.p1.4.m4.4.4.3.2" mathsize="70%" xref="S2.SS2.p1.4.m4.4.4.3.2.cmml">d</mi></msqrt></mrow><mo id="S2.SS2.p1.4.m4.4.5.3.2.1.2" xref="S2.SS2.p1.4.m4.4.5.3.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.4.m4.4b"><apply id="S2.SS2.p1.4.m4.4.5.cmml" xref="S2.SS2.p1.4.m4.4.5"><eq id="S2.SS2.p1.4.m4.4.5.1.cmml" xref="S2.SS2.p1.4.m4.4.5.1"></eq><apply id="S2.SS2.p1.4.m4.4.5.2.cmml" xref="S2.SS2.p1.4.m4.4.5.2"><times id="S2.SS2.p1.4.m4.4.5.2.1.cmml" xref="S2.SS2.p1.4.m4.4.5.2.1"></times><ci id="S2.SS2.p1.4.m4.4.5.2.2a.cmml" xref="S2.SS2.p1.4.m4.4.5.2.2"><mtext class="ltx_mathvariant_sans-serif" id="S2.SS2.p1.4.m4.4.5.2.2.cmml" xref="S2.SS2.p1.4.m4.4.5.2.2">sim</mtext></ci><interval closure="open" id="S2.SS2.p1.4.m4.4.5.2.3.1.cmml" xref="S2.SS2.p1.4.m4.4.5.2.3.2"><ci id="S2.SS2.p1.4.m4.1.1.cmml" xref="S2.SS2.p1.4.m4.1.1">𝒒</ci><ci id="S2.SS2.p1.4.m4.2.2.cmml" xref="S2.SS2.p1.4.m4.2.2">𝒌</ci></interval></apply><apply id="S2.SS2.p1.4.m4.4.5.3.1.cmml" xref="S2.SS2.p1.4.m4.4.5.3.2"><exp id="S2.SS2.p1.4.m4.3.3.cmml" xref="S2.SS2.p1.4.m4.3.3"></exp><apply id="S2.SS2.p1.4.m4.4.4.cmml" xref="S2.SS2.p1.4.m4.4.4"><divide id="S2.SS2.p1.4.m4.4.4.1.cmml" xref="S2.SS2.p1.4.m4.4.4.1"></divide><apply id="S2.SS2.p1.4.m4.4.4.2.cmml" xref="S2.SS2.p1.4.m4.4.4.2"><times id="S2.SS2.p1.4.m4.4.4.2.1.cmml" xref="S2.SS2.p1.4.m4.4.4.2.1"></times><apply id="S2.SS2.p1.4.m4.4.4.2.2.cmml" xref="S2.SS2.p1.4.m4.4.4.2.2"><csymbol cd="ambiguous" id="S2.SS2.p1.4.m4.4.4.2.2.1.cmml" xref="S2.SS2.p1.4.m4.4.4.2.2">superscript</csymbol><ci id="S2.SS2.p1.4.m4.4.4.2.2.2.cmml" xref="S2.SS2.p1.4.m4.4.4.2.2.2">𝒒</ci><csymbol cd="latexml" id="S2.SS2.p1.4.m4.4.4.2.2.3.cmml" xref="S2.SS2.p1.4.m4.4.4.2.2.3">top</csymbol></apply><ci id="S2.SS2.p1.4.m4.4.4.2.3.cmml" xref="S2.SS2.p1.4.m4.4.4.2.3">𝒌</ci></apply><apply id="S2.SS2.p1.4.m4.4.4.3.cmml" xref="S2.SS2.p1.4.m4.4.4.3"><root id="S2.SS2.p1.4.m4.4.4.3a.cmml" xref="S2.SS2.p1.4.m4.4.4.3"></root><ci id="S2.SS2.p1.4.m4.4.4.3.2.cmml" xref="S2.SS2.p1.4.m4.4.4.3.2">𝑑</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.4.m4.4c">\textsf{sim}\left(\bm{q},\bm{k}\right)=\exp\left(\nicefrac{{\bm{q}^{\top}\bm{k%
}}}{{\sqrt{d}}}\right)</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p1.4.m4.4d">sim ( bold_italic_q , bold_italic_k ) = roman_exp ( / start_ARG bold_italic_q start_POSTSUPERSCRIPT ⊤ end_POSTSUPERSCRIPT bold_italic_k end_ARG start_ARG square-root start_ARG italic_d end_ARG end_ARG )</annotation></semantics></math>:</p>
<table class="ltx_equation ltx_eqn_table" id="S2.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\bm{y}_{i}=\frac{\sum_{j=1}^{n}\textsf{sim}(\bm{q}_{i},\bm{k}_{j})\bm{v}_{j}}{%
\sum_{j=1}^{n}\textsf{sim}(\bm{q}_{i},\bm{k}_{j})}." class="ltx_Math" display="block" id="S2.E2.m1.5"><semantics id="S2.E2.m1.5a"><mrow id="S2.E2.m1.5.5.1" xref="S2.E2.m1.5.5.1.1.cmml"><mrow id="S2.E2.m1.5.5.1.1" xref="S2.E2.m1.5.5.1.1.cmml"><msub id="S2.E2.m1.5.5.1.1.2" xref="S2.E2.m1.5.5.1.1.2.cmml"><mi id="S2.E2.m1.5.5.1.1.2.2" xref="S2.E2.m1.5.5.1.1.2.2.cmml">𝒚</mi><mi id="S2.E2.m1.5.5.1.1.2.3" xref="S2.E2.m1.5.5.1.1.2.3.cmml">i</mi></msub><mo id="S2.E2.m1.5.5.1.1.1" xref="S2.E2.m1.5.5.1.1.1.cmml">=</mo><mfrac id="S2.E2.m1.4.4" xref="S2.E2.m1.4.4.cmml"><mrow id="S2.E2.m1.2.2.2" xref="S2.E2.m1.2.2.2.cmml"><msubsup id="S2.E2.m1.2.2.2.3" xref="S2.E2.m1.2.2.2.3.cmml"><mo id="S2.E2.m1.2.2.2.3.2.2" xref="S2.E2.m1.2.2.2.3.2.2.cmml">∑</mo><mrow id="S2.E2.m1.2.2.2.3.2.3" xref="S2.E2.m1.2.2.2.3.2.3.cmml"><mi id="S2.E2.m1.2.2.2.3.2.3.2" xref="S2.E2.m1.2.2.2.3.2.3.2.cmml">j</mi><mo id="S2.E2.m1.2.2.2.3.2.3.1" xref="S2.E2.m1.2.2.2.3.2.3.1.cmml">=</mo><mn id="S2.E2.m1.2.2.2.3.2.3.3" xref="S2.E2.m1.2.2.2.3.2.3.3.cmml">1</mn></mrow><mi id="S2.E2.m1.2.2.2.3.3" xref="S2.E2.m1.2.2.2.3.3.cmml">n</mi></msubsup><mrow id="S2.E2.m1.2.2.2.2" xref="S2.E2.m1.2.2.2.2.cmml"><mtext class="ltx_mathvariant_sans-serif" id="S2.E2.m1.2.2.2.2.4" xref="S2.E2.m1.2.2.2.2.4a.cmml">sim</mtext><mo id="S2.E2.m1.2.2.2.2.3" xref="S2.E2.m1.2.2.2.2.3.cmml">⁢</mo><mrow id="S2.E2.m1.2.2.2.2.2.2" xref="S2.E2.m1.2.2.2.2.2.3.cmml"><mo id="S2.E2.m1.2.2.2.2.2.2.3" stretchy="false" xref="S2.E2.m1.2.2.2.2.2.3.cmml">(</mo><msub id="S2.E2.m1.1.1.1.1.1.1.1" xref="S2.E2.m1.1.1.1.1.1.1.1.cmml"><mi id="S2.E2.m1.1.1.1.1.1.1.1.2" xref="S2.E2.m1.1.1.1.1.1.1.1.2.cmml">𝒒</mi><mi id="S2.E2.m1.1.1.1.1.1.1.1.3" xref="S2.E2.m1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S2.E2.m1.2.2.2.2.2.2.4" xref="S2.E2.m1.2.2.2.2.2.3.cmml">,</mo><msub id="S2.E2.m1.2.2.2.2.2.2.2" xref="S2.E2.m1.2.2.2.2.2.2.2.cmml"><mi id="S2.E2.m1.2.2.2.2.2.2.2.2" xref="S2.E2.m1.2.2.2.2.2.2.2.2.cmml">𝒌</mi><mi id="S2.E2.m1.2.2.2.2.2.2.2.3" xref="S2.E2.m1.2.2.2.2.2.2.2.3.cmml">j</mi></msub><mo id="S2.E2.m1.2.2.2.2.2.2.5" stretchy="false" xref="S2.E2.m1.2.2.2.2.2.3.cmml">)</mo></mrow><mo id="S2.E2.m1.2.2.2.2.3a" xref="S2.E2.m1.2.2.2.2.3.cmml">⁢</mo><msub id="S2.E2.m1.2.2.2.2.5" xref="S2.E2.m1.2.2.2.2.5.cmml"><mi id="S2.E2.m1.2.2.2.2.5.2" xref="S2.E2.m1.2.2.2.2.5.2.cmml">𝒗</mi><mi id="S2.E2.m1.2.2.2.2.5.3" xref="S2.E2.m1.2.2.2.2.5.3.cmml">j</mi></msub></mrow></mrow><mrow id="S2.E2.m1.4.4.4" xref="S2.E2.m1.4.4.4.cmml"><msubsup id="S2.E2.m1.4.4.4.3" xref="S2.E2.m1.4.4.4.3.cmml"><mo id="S2.E2.m1.4.4.4.3.2.2" xref="S2.E2.m1.4.4.4.3.2.2.cmml">∑</mo><mrow id="S2.E2.m1.4.4.4.3.2.3" xref="S2.E2.m1.4.4.4.3.2.3.cmml"><mi id="S2.E2.m1.4.4.4.3.2.3.2" xref="S2.E2.m1.4.4.4.3.2.3.2.cmml">j</mi><mo id="S2.E2.m1.4.4.4.3.2.3.1" xref="S2.E2.m1.4.4.4.3.2.3.1.cmml">=</mo><mn id="S2.E2.m1.4.4.4.3.2.3.3" xref="S2.E2.m1.4.4.4.3.2.3.3.cmml">1</mn></mrow><mi id="S2.E2.m1.4.4.4.3.3" xref="S2.E2.m1.4.4.4.3.3.cmml">n</mi></msubsup><mrow id="S2.E2.m1.4.4.4.2" xref="S2.E2.m1.4.4.4.2.cmml"><mtext class="ltx_mathvariant_sans-serif" id="S2.E2.m1.4.4.4.2.4" xref="S2.E2.m1.4.4.4.2.4a.cmml">sim</mtext><mo id="S2.E2.m1.4.4.4.2.3" xref="S2.E2.m1.4.4.4.2.3.cmml">⁢</mo><mrow id="S2.E2.m1.4.4.4.2.2.2" xref="S2.E2.m1.4.4.4.2.2.3.cmml"><mo id="S2.E2.m1.4.4.4.2.2.2.3" stretchy="false" xref="S2.E2.m1.4.4.4.2.2.3.cmml">(</mo><msub id="S2.E2.m1.3.3.3.1.1.1.1" xref="S2.E2.m1.3.3.3.1.1.1.1.cmml"><mi id="S2.E2.m1.3.3.3.1.1.1.1.2" xref="S2.E2.m1.3.3.3.1.1.1.1.2.cmml">𝒒</mi><mi id="S2.E2.m1.3.3.3.1.1.1.1.3" xref="S2.E2.m1.3.3.3.1.1.1.1.3.cmml">i</mi></msub><mo id="S2.E2.m1.4.4.4.2.2.2.4" xref="S2.E2.m1.4.4.4.2.2.3.cmml">,</mo><msub id="S2.E2.m1.4.4.4.2.2.2.2" xref="S2.E2.m1.4.4.4.2.2.2.2.cmml"><mi id="S2.E2.m1.4.4.4.2.2.2.2.2" xref="S2.E2.m1.4.4.4.2.2.2.2.2.cmml">𝒌</mi><mi id="S2.E2.m1.4.4.4.2.2.2.2.3" xref="S2.E2.m1.4.4.4.2.2.2.2.3.cmml">j</mi></msub><mo id="S2.E2.m1.4.4.4.2.2.2.5" stretchy="false" xref="S2.E2.m1.4.4.4.2.2.3.cmml">)</mo></mrow></mrow></mrow></mfrac></mrow><mo id="S2.E2.m1.5.5.1.2" lspace="0em" xref="S2.E2.m1.5.5.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E2.m1.5b"><apply id="S2.E2.m1.5.5.1.1.cmml" xref="S2.E2.m1.5.5.1"><eq id="S2.E2.m1.5.5.1.1.1.cmml" xref="S2.E2.m1.5.5.1.1.1"></eq><apply id="S2.E2.m1.5.5.1.1.2.cmml" xref="S2.E2.m1.5.5.1.1.2"><csymbol cd="ambiguous" id="S2.E2.m1.5.5.1.1.2.1.cmml" xref="S2.E2.m1.5.5.1.1.2">subscript</csymbol><ci id="S2.E2.m1.5.5.1.1.2.2.cmml" xref="S2.E2.m1.5.5.1.1.2.2">𝒚</ci><ci id="S2.E2.m1.5.5.1.1.2.3.cmml" xref="S2.E2.m1.5.5.1.1.2.3">𝑖</ci></apply><apply id="S2.E2.m1.4.4.cmml" xref="S2.E2.m1.4.4"><divide id="S2.E2.m1.4.4.5.cmml" xref="S2.E2.m1.4.4"></divide><apply id="S2.E2.m1.2.2.2.cmml" xref="S2.E2.m1.2.2.2"><apply id="S2.E2.m1.2.2.2.3.cmml" xref="S2.E2.m1.2.2.2.3"><csymbol cd="ambiguous" id="S2.E2.m1.2.2.2.3.1.cmml" xref="S2.E2.m1.2.2.2.3">superscript</csymbol><apply id="S2.E2.m1.2.2.2.3.2.cmml" xref="S2.E2.m1.2.2.2.3"><csymbol cd="ambiguous" id="S2.E2.m1.2.2.2.3.2.1.cmml" xref="S2.E2.m1.2.2.2.3">subscript</csymbol><sum id="S2.E2.m1.2.2.2.3.2.2.cmml" xref="S2.E2.m1.2.2.2.3.2.2"></sum><apply id="S2.E2.m1.2.2.2.3.2.3.cmml" xref="S2.E2.m1.2.2.2.3.2.3"><eq id="S2.E2.m1.2.2.2.3.2.3.1.cmml" xref="S2.E2.m1.2.2.2.3.2.3.1"></eq><ci id="S2.E2.m1.2.2.2.3.2.3.2.cmml" xref="S2.E2.m1.2.2.2.3.2.3.2">𝑗</ci><cn id="S2.E2.m1.2.2.2.3.2.3.3.cmml" type="integer" xref="S2.E2.m1.2.2.2.3.2.3.3">1</cn></apply></apply><ci id="S2.E2.m1.2.2.2.3.3.cmml" xref="S2.E2.m1.2.2.2.3.3">𝑛</ci></apply><apply id="S2.E2.m1.2.2.2.2.cmml" xref="S2.E2.m1.2.2.2.2"><times id="S2.E2.m1.2.2.2.2.3.cmml" xref="S2.E2.m1.2.2.2.2.3"></times><ci id="S2.E2.m1.2.2.2.2.4a.cmml" xref="S2.E2.m1.2.2.2.2.4"><mtext class="ltx_mathvariant_sans-serif" id="S2.E2.m1.2.2.2.2.4.cmml" xref="S2.E2.m1.2.2.2.2.4">sim</mtext></ci><interval closure="open" id="S2.E2.m1.2.2.2.2.2.3.cmml" xref="S2.E2.m1.2.2.2.2.2.2"><apply id="S2.E2.m1.1.1.1.1.1.1.1.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.1.1.1.1.1.1.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.E2.m1.1.1.1.1.1.1.1.2.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.2">𝒒</ci><ci id="S2.E2.m1.1.1.1.1.1.1.1.3.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.3">𝑖</ci></apply><apply id="S2.E2.m1.2.2.2.2.2.2.2.cmml" xref="S2.E2.m1.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S2.E2.m1.2.2.2.2.2.2.2.1.cmml" xref="S2.E2.m1.2.2.2.2.2.2.2">subscript</csymbol><ci id="S2.E2.m1.2.2.2.2.2.2.2.2.cmml" xref="S2.E2.m1.2.2.2.2.2.2.2.2">𝒌</ci><ci id="S2.E2.m1.2.2.2.2.2.2.2.3.cmml" xref="S2.E2.m1.2.2.2.2.2.2.2.3">𝑗</ci></apply></interval><apply id="S2.E2.m1.2.2.2.2.5.cmml" xref="S2.E2.m1.2.2.2.2.5"><csymbol cd="ambiguous" id="S2.E2.m1.2.2.2.2.5.1.cmml" xref="S2.E2.m1.2.2.2.2.5">subscript</csymbol><ci id="S2.E2.m1.2.2.2.2.5.2.cmml" xref="S2.E2.m1.2.2.2.2.5.2">𝒗</ci><ci id="S2.E2.m1.2.2.2.2.5.3.cmml" xref="S2.E2.m1.2.2.2.2.5.3">𝑗</ci></apply></apply></apply><apply id="S2.E2.m1.4.4.4.cmml" xref="S2.E2.m1.4.4.4"><apply id="S2.E2.m1.4.4.4.3.cmml" xref="S2.E2.m1.4.4.4.3"><csymbol cd="ambiguous" id="S2.E2.m1.4.4.4.3.1.cmml" xref="S2.E2.m1.4.4.4.3">superscript</csymbol><apply id="S2.E2.m1.4.4.4.3.2.cmml" xref="S2.E2.m1.4.4.4.3"><csymbol cd="ambiguous" id="S2.E2.m1.4.4.4.3.2.1.cmml" xref="S2.E2.m1.4.4.4.3">subscript</csymbol><sum id="S2.E2.m1.4.4.4.3.2.2.cmml" xref="S2.E2.m1.4.4.4.3.2.2"></sum><apply id="S2.E2.m1.4.4.4.3.2.3.cmml" xref="S2.E2.m1.4.4.4.3.2.3"><eq id="S2.E2.m1.4.4.4.3.2.3.1.cmml" xref="S2.E2.m1.4.4.4.3.2.3.1"></eq><ci id="S2.E2.m1.4.4.4.3.2.3.2.cmml" xref="S2.E2.m1.4.4.4.3.2.3.2">𝑗</ci><cn id="S2.E2.m1.4.4.4.3.2.3.3.cmml" type="integer" xref="S2.E2.m1.4.4.4.3.2.3.3">1</cn></apply></apply><ci id="S2.E2.m1.4.4.4.3.3.cmml" xref="S2.E2.m1.4.4.4.3.3">𝑛</ci></apply><apply id="S2.E2.m1.4.4.4.2.cmml" xref="S2.E2.m1.4.4.4.2"><times id="S2.E2.m1.4.4.4.2.3.cmml" xref="S2.E2.m1.4.4.4.2.3"></times><ci id="S2.E2.m1.4.4.4.2.4a.cmml" xref="S2.E2.m1.4.4.4.2.4"><mtext class="ltx_mathvariant_sans-serif" id="S2.E2.m1.4.4.4.2.4.cmml" xref="S2.E2.m1.4.4.4.2.4">sim</mtext></ci><interval closure="open" id="S2.E2.m1.4.4.4.2.2.3.cmml" xref="S2.E2.m1.4.4.4.2.2.2"><apply id="S2.E2.m1.3.3.3.1.1.1.1.cmml" xref="S2.E2.m1.3.3.3.1.1.1.1"><csymbol cd="ambiguous" id="S2.E2.m1.3.3.3.1.1.1.1.1.cmml" xref="S2.E2.m1.3.3.3.1.1.1.1">subscript</csymbol><ci id="S2.E2.m1.3.3.3.1.1.1.1.2.cmml" xref="S2.E2.m1.3.3.3.1.1.1.1.2">𝒒</ci><ci id="S2.E2.m1.3.3.3.1.1.1.1.3.cmml" xref="S2.E2.m1.3.3.3.1.1.1.1.3">𝑖</ci></apply><apply id="S2.E2.m1.4.4.4.2.2.2.2.cmml" xref="S2.E2.m1.4.4.4.2.2.2.2"><csymbol cd="ambiguous" id="S2.E2.m1.4.4.4.2.2.2.2.1.cmml" xref="S2.E2.m1.4.4.4.2.2.2.2">subscript</csymbol><ci id="S2.E2.m1.4.4.4.2.2.2.2.2.cmml" xref="S2.E2.m1.4.4.4.2.2.2.2.2">𝒌</ci><ci id="S2.E2.m1.4.4.4.2.2.2.2.3.cmml" xref="S2.E2.m1.4.4.4.2.2.2.2.3">𝑗</ci></apply></interval></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E2.m1.5c">\bm{y}_{i}=\frac{\sum_{j=1}^{n}\textsf{sim}(\bm{q}_{i},\bm{k}_{j})\bm{v}_{j}}{%
\sum_{j=1}^{n}\textsf{sim}(\bm{q}_{i},\bm{k}_{j})}.</annotation><annotation encoding="application/x-llamapun" id="S2.E2.m1.5d">bold_italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = divide start_ARG ∑ start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT sim ( bold_italic_q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_k start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) bold_italic_v start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT end_ARG start_ARG ∑ start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT sim ( bold_italic_q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_k start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) end_ARG .</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S2.SS2.p1.7">However, any kernel <math alttext="k(\bm{x},\bm{y}):\mathbb{R}^{d}\times\mathbb{R}^{d}\to\mathbb{R}" class="ltx_Math" display="inline" id="S2.SS2.p1.5.m1.2"><semantics id="S2.SS2.p1.5.m1.2a"><mrow id="S2.SS2.p1.5.m1.2.3" xref="S2.SS2.p1.5.m1.2.3.cmml"><mrow id="S2.SS2.p1.5.m1.2.3.2" xref="S2.SS2.p1.5.m1.2.3.2.cmml"><mi id="S2.SS2.p1.5.m1.2.3.2.2" xref="S2.SS2.p1.5.m1.2.3.2.2.cmml">k</mi><mo id="S2.SS2.p1.5.m1.2.3.2.1" xref="S2.SS2.p1.5.m1.2.3.2.1.cmml">⁢</mo><mrow id="S2.SS2.p1.5.m1.2.3.2.3.2" xref="S2.SS2.p1.5.m1.2.3.2.3.1.cmml"><mo id="S2.SS2.p1.5.m1.2.3.2.3.2.1" stretchy="false" xref="S2.SS2.p1.5.m1.2.3.2.3.1.cmml">(</mo><mi id="S2.SS2.p1.5.m1.1.1" xref="S2.SS2.p1.5.m1.1.1.cmml">𝒙</mi><mo id="S2.SS2.p1.5.m1.2.3.2.3.2.2" xref="S2.SS2.p1.5.m1.2.3.2.3.1.cmml">,</mo><mi id="S2.SS2.p1.5.m1.2.2" xref="S2.SS2.p1.5.m1.2.2.cmml">𝒚</mi><mo id="S2.SS2.p1.5.m1.2.3.2.3.2.3" rspace="0.278em" stretchy="false" xref="S2.SS2.p1.5.m1.2.3.2.3.1.cmml">)</mo></mrow></mrow><mo id="S2.SS2.p1.5.m1.2.3.1" rspace="0.278em" xref="S2.SS2.p1.5.m1.2.3.1.cmml">:</mo><mrow id="S2.SS2.p1.5.m1.2.3.3" xref="S2.SS2.p1.5.m1.2.3.3.cmml"><mrow id="S2.SS2.p1.5.m1.2.3.3.2" xref="S2.SS2.p1.5.m1.2.3.3.2.cmml"><msup id="S2.SS2.p1.5.m1.2.3.3.2.2" xref="S2.SS2.p1.5.m1.2.3.3.2.2.cmml"><mi id="S2.SS2.p1.5.m1.2.3.3.2.2.2" xref="S2.SS2.p1.5.m1.2.3.3.2.2.2.cmml">ℝ</mi><mi id="S2.SS2.p1.5.m1.2.3.3.2.2.3" xref="S2.SS2.p1.5.m1.2.3.3.2.2.3.cmml">d</mi></msup><mo id="S2.SS2.p1.5.m1.2.3.3.2.1" lspace="0.222em" rspace="0.222em" xref="S2.SS2.p1.5.m1.2.3.3.2.1.cmml">×</mo><msup id="S2.SS2.p1.5.m1.2.3.3.2.3" xref="S2.SS2.p1.5.m1.2.3.3.2.3.cmml"><mi id="S2.SS2.p1.5.m1.2.3.3.2.3.2" xref="S2.SS2.p1.5.m1.2.3.3.2.3.2.cmml">ℝ</mi><mi id="S2.SS2.p1.5.m1.2.3.3.2.3.3" xref="S2.SS2.p1.5.m1.2.3.3.2.3.3.cmml">d</mi></msup></mrow><mo id="S2.SS2.p1.5.m1.2.3.3.1" stretchy="false" xref="S2.SS2.p1.5.m1.2.3.3.1.cmml">→</mo><mi id="S2.SS2.p1.5.m1.2.3.3.3" xref="S2.SS2.p1.5.m1.2.3.3.3.cmml">ℝ</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.5.m1.2b"><apply id="S2.SS2.p1.5.m1.2.3.cmml" xref="S2.SS2.p1.5.m1.2.3"><ci id="S2.SS2.p1.5.m1.2.3.1.cmml" xref="S2.SS2.p1.5.m1.2.3.1">:</ci><apply id="S2.SS2.p1.5.m1.2.3.2.cmml" xref="S2.SS2.p1.5.m1.2.3.2"><times id="S2.SS2.p1.5.m1.2.3.2.1.cmml" xref="S2.SS2.p1.5.m1.2.3.2.1"></times><ci id="S2.SS2.p1.5.m1.2.3.2.2.cmml" xref="S2.SS2.p1.5.m1.2.3.2.2">𝑘</ci><interval closure="open" id="S2.SS2.p1.5.m1.2.3.2.3.1.cmml" xref="S2.SS2.p1.5.m1.2.3.2.3.2"><ci id="S2.SS2.p1.5.m1.1.1.cmml" xref="S2.SS2.p1.5.m1.1.1">𝒙</ci><ci id="S2.SS2.p1.5.m1.2.2.cmml" xref="S2.SS2.p1.5.m1.2.2">𝒚</ci></interval></apply><apply id="S2.SS2.p1.5.m1.2.3.3.cmml" xref="S2.SS2.p1.5.m1.2.3.3"><ci id="S2.SS2.p1.5.m1.2.3.3.1.cmml" xref="S2.SS2.p1.5.m1.2.3.3.1">→</ci><apply id="S2.SS2.p1.5.m1.2.3.3.2.cmml" xref="S2.SS2.p1.5.m1.2.3.3.2"><times id="S2.SS2.p1.5.m1.2.3.3.2.1.cmml" xref="S2.SS2.p1.5.m1.2.3.3.2.1"></times><apply id="S2.SS2.p1.5.m1.2.3.3.2.2.cmml" xref="S2.SS2.p1.5.m1.2.3.3.2.2"><csymbol cd="ambiguous" id="S2.SS2.p1.5.m1.2.3.3.2.2.1.cmml" xref="S2.SS2.p1.5.m1.2.3.3.2.2">superscript</csymbol><ci id="S2.SS2.p1.5.m1.2.3.3.2.2.2.cmml" xref="S2.SS2.p1.5.m1.2.3.3.2.2.2">ℝ</ci><ci id="S2.SS2.p1.5.m1.2.3.3.2.2.3.cmml" xref="S2.SS2.p1.5.m1.2.3.3.2.2.3">𝑑</ci></apply><apply id="S2.SS2.p1.5.m1.2.3.3.2.3.cmml" xref="S2.SS2.p1.5.m1.2.3.3.2.3"><csymbol cd="ambiguous" id="S2.SS2.p1.5.m1.2.3.3.2.3.1.cmml" xref="S2.SS2.p1.5.m1.2.3.3.2.3">superscript</csymbol><ci id="S2.SS2.p1.5.m1.2.3.3.2.3.2.cmml" xref="S2.SS2.p1.5.m1.2.3.3.2.3.2">ℝ</ci><ci id="S2.SS2.p1.5.m1.2.3.3.2.3.3.cmml" xref="S2.SS2.p1.5.m1.2.3.3.2.3.3">𝑑</ci></apply></apply><ci id="S2.SS2.p1.5.m1.2.3.3.3.cmml" xref="S2.SS2.p1.5.m1.2.3.3.3">ℝ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.5.m1.2c">k(\bm{x},\bm{y}):\mathbb{R}^{d}\times\mathbb{R}^{d}\to\mathbb{R}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p1.5.m1.2d">italic_k ( bold_italic_x , bold_italic_y ) : blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT × blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT → blackboard_R</annotation></semantics></math>
is a suitable candidate for the similarity function <cite class="ltx_cite ltx_citemacro_citep">(Smola and Schölkopf, <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib35" title="">1998</a>; Tsai et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib41" title="">2019</a>)</cite>.
In particular, a kernel <math alttext="k(\bm{x},\bm{y})=\bm{\phi}(\bm{x})^{\top}\bm{\phi}(\bm{y})" class="ltx_Math" display="inline" id="S2.SS2.p1.6.m2.4"><semantics id="S2.SS2.p1.6.m2.4a"><mrow id="S2.SS2.p1.6.m2.4.5" xref="S2.SS2.p1.6.m2.4.5.cmml"><mrow id="S2.SS2.p1.6.m2.4.5.2" xref="S2.SS2.p1.6.m2.4.5.2.cmml"><mi id="S2.SS2.p1.6.m2.4.5.2.2" xref="S2.SS2.p1.6.m2.4.5.2.2.cmml">k</mi><mo id="S2.SS2.p1.6.m2.4.5.2.1" xref="S2.SS2.p1.6.m2.4.5.2.1.cmml">⁢</mo><mrow id="S2.SS2.p1.6.m2.4.5.2.3.2" xref="S2.SS2.p1.6.m2.4.5.2.3.1.cmml"><mo id="S2.SS2.p1.6.m2.4.5.2.3.2.1" stretchy="false" xref="S2.SS2.p1.6.m2.4.5.2.3.1.cmml">(</mo><mi id="S2.SS2.p1.6.m2.1.1" xref="S2.SS2.p1.6.m2.1.1.cmml">𝒙</mi><mo id="S2.SS2.p1.6.m2.4.5.2.3.2.2" xref="S2.SS2.p1.6.m2.4.5.2.3.1.cmml">,</mo><mi id="S2.SS2.p1.6.m2.2.2" xref="S2.SS2.p1.6.m2.2.2.cmml">𝒚</mi><mo id="S2.SS2.p1.6.m2.4.5.2.3.2.3" stretchy="false" xref="S2.SS2.p1.6.m2.4.5.2.3.1.cmml">)</mo></mrow></mrow><mo id="S2.SS2.p1.6.m2.4.5.1" xref="S2.SS2.p1.6.m2.4.5.1.cmml">=</mo><mrow id="S2.SS2.p1.6.m2.4.5.3" xref="S2.SS2.p1.6.m2.4.5.3.cmml"><mi class="ltx_mathvariant_bold-italic" id="S2.SS2.p1.6.m2.4.5.3.2" mathvariant="bold-italic" xref="S2.SS2.p1.6.m2.4.5.3.2.cmml">ϕ</mi><mo id="S2.SS2.p1.6.m2.4.5.3.1" xref="S2.SS2.p1.6.m2.4.5.3.1.cmml">⁢</mo><msup id="S2.SS2.p1.6.m2.4.5.3.3" xref="S2.SS2.p1.6.m2.4.5.3.3.cmml"><mrow id="S2.SS2.p1.6.m2.4.5.3.3.2.2" xref="S2.SS2.p1.6.m2.4.5.3.3.cmml"><mo id="S2.SS2.p1.6.m2.4.5.3.3.2.2.1" stretchy="false" xref="S2.SS2.p1.6.m2.4.5.3.3.cmml">(</mo><mi id="S2.SS2.p1.6.m2.3.3" xref="S2.SS2.p1.6.m2.3.3.cmml">𝒙</mi><mo id="S2.SS2.p1.6.m2.4.5.3.3.2.2.2" stretchy="false" xref="S2.SS2.p1.6.m2.4.5.3.3.cmml">)</mo></mrow><mo id="S2.SS2.p1.6.m2.4.5.3.3.3" xref="S2.SS2.p1.6.m2.4.5.3.3.3.cmml">⊤</mo></msup><mo id="S2.SS2.p1.6.m2.4.5.3.1a" xref="S2.SS2.p1.6.m2.4.5.3.1.cmml">⁢</mo><mi class="ltx_mathvariant_bold-italic" id="S2.SS2.p1.6.m2.4.5.3.4" mathvariant="bold-italic" xref="S2.SS2.p1.6.m2.4.5.3.4.cmml">ϕ</mi><mo id="S2.SS2.p1.6.m2.4.5.3.1b" xref="S2.SS2.p1.6.m2.4.5.3.1.cmml">⁢</mo><mrow id="S2.SS2.p1.6.m2.4.5.3.5.2" xref="S2.SS2.p1.6.m2.4.5.3.cmml"><mo id="S2.SS2.p1.6.m2.4.5.3.5.2.1" stretchy="false" xref="S2.SS2.p1.6.m2.4.5.3.cmml">(</mo><mi id="S2.SS2.p1.6.m2.4.4" xref="S2.SS2.p1.6.m2.4.4.cmml">𝒚</mi><mo id="S2.SS2.p1.6.m2.4.5.3.5.2.2" stretchy="false" xref="S2.SS2.p1.6.m2.4.5.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.6.m2.4b"><apply id="S2.SS2.p1.6.m2.4.5.cmml" xref="S2.SS2.p1.6.m2.4.5"><eq id="S2.SS2.p1.6.m2.4.5.1.cmml" xref="S2.SS2.p1.6.m2.4.5.1"></eq><apply id="S2.SS2.p1.6.m2.4.5.2.cmml" xref="S2.SS2.p1.6.m2.4.5.2"><times id="S2.SS2.p1.6.m2.4.5.2.1.cmml" xref="S2.SS2.p1.6.m2.4.5.2.1"></times><ci id="S2.SS2.p1.6.m2.4.5.2.2.cmml" xref="S2.SS2.p1.6.m2.4.5.2.2">𝑘</ci><interval closure="open" id="S2.SS2.p1.6.m2.4.5.2.3.1.cmml" xref="S2.SS2.p1.6.m2.4.5.2.3.2"><ci id="S2.SS2.p1.6.m2.1.1.cmml" xref="S2.SS2.p1.6.m2.1.1">𝒙</ci><ci id="S2.SS2.p1.6.m2.2.2.cmml" xref="S2.SS2.p1.6.m2.2.2">𝒚</ci></interval></apply><apply id="S2.SS2.p1.6.m2.4.5.3.cmml" xref="S2.SS2.p1.6.m2.4.5.3"><times id="S2.SS2.p1.6.m2.4.5.3.1.cmml" xref="S2.SS2.p1.6.m2.4.5.3.1"></times><ci id="S2.SS2.p1.6.m2.4.5.3.2.cmml" xref="S2.SS2.p1.6.m2.4.5.3.2">bold-italic-ϕ</ci><apply id="S2.SS2.p1.6.m2.4.5.3.3.cmml" xref="S2.SS2.p1.6.m2.4.5.3.3"><csymbol cd="ambiguous" id="S2.SS2.p1.6.m2.4.5.3.3.1.cmml" xref="S2.SS2.p1.6.m2.4.5.3.3">superscript</csymbol><ci id="S2.SS2.p1.6.m2.3.3.cmml" xref="S2.SS2.p1.6.m2.3.3">𝒙</ci><csymbol cd="latexml" id="S2.SS2.p1.6.m2.4.5.3.3.3.cmml" xref="S2.SS2.p1.6.m2.4.5.3.3.3">top</csymbol></apply><ci id="S2.SS2.p1.6.m2.4.5.3.4.cmml" xref="S2.SS2.p1.6.m2.4.5.3.4">bold-italic-ϕ</ci><ci id="S2.SS2.p1.6.m2.4.4.cmml" xref="S2.SS2.p1.6.m2.4.4">𝒚</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.6.m2.4c">k(\bm{x},\bm{y})=\bm{\phi}(\bm{x})^{\top}\bm{\phi}(\bm{y})</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p1.6.m2.4d">italic_k ( bold_italic_x , bold_italic_y ) = bold_italic_ϕ ( bold_italic_x ) start_POSTSUPERSCRIPT ⊤ end_POSTSUPERSCRIPT bold_italic_ϕ ( bold_italic_y )</annotation></semantics></math>, where <math alttext="\bm{\phi}:\mathbb{R}^{d}\rightarrow\mathbb{R}^{r}" class="ltx_Math" display="inline" id="S2.SS2.p1.7.m3.1"><semantics id="S2.SS2.p1.7.m3.1a"><mrow id="S2.SS2.p1.7.m3.1.1" xref="S2.SS2.p1.7.m3.1.1.cmml"><mi class="ltx_mathvariant_bold-italic" id="S2.SS2.p1.7.m3.1.1.2" mathvariant="bold-italic" xref="S2.SS2.p1.7.m3.1.1.2.cmml">ϕ</mi><mo id="S2.SS2.p1.7.m3.1.1.1" lspace="0.278em" rspace="0.278em" xref="S2.SS2.p1.7.m3.1.1.1.cmml">:</mo><mrow id="S2.SS2.p1.7.m3.1.1.3" xref="S2.SS2.p1.7.m3.1.1.3.cmml"><msup id="S2.SS2.p1.7.m3.1.1.3.2" xref="S2.SS2.p1.7.m3.1.1.3.2.cmml"><mi id="S2.SS2.p1.7.m3.1.1.3.2.2" xref="S2.SS2.p1.7.m3.1.1.3.2.2.cmml">ℝ</mi><mi id="S2.SS2.p1.7.m3.1.1.3.2.3" xref="S2.SS2.p1.7.m3.1.1.3.2.3.cmml">d</mi></msup><mo id="S2.SS2.p1.7.m3.1.1.3.1" stretchy="false" xref="S2.SS2.p1.7.m3.1.1.3.1.cmml">→</mo><msup id="S2.SS2.p1.7.m3.1.1.3.3" xref="S2.SS2.p1.7.m3.1.1.3.3.cmml"><mi id="S2.SS2.p1.7.m3.1.1.3.3.2" xref="S2.SS2.p1.7.m3.1.1.3.3.2.cmml">ℝ</mi><mi id="S2.SS2.p1.7.m3.1.1.3.3.3" xref="S2.SS2.p1.7.m3.1.1.3.3.3.cmml">r</mi></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.7.m3.1b"><apply id="S2.SS2.p1.7.m3.1.1.cmml" xref="S2.SS2.p1.7.m3.1.1"><ci id="S2.SS2.p1.7.m3.1.1.1.cmml" xref="S2.SS2.p1.7.m3.1.1.1">:</ci><ci id="S2.SS2.p1.7.m3.1.1.2.cmml" xref="S2.SS2.p1.7.m3.1.1.2">bold-italic-ϕ</ci><apply id="S2.SS2.p1.7.m3.1.1.3.cmml" xref="S2.SS2.p1.7.m3.1.1.3"><ci id="S2.SS2.p1.7.m3.1.1.3.1.cmml" xref="S2.SS2.p1.7.m3.1.1.3.1">→</ci><apply id="S2.SS2.p1.7.m3.1.1.3.2.cmml" xref="S2.SS2.p1.7.m3.1.1.3.2"><csymbol cd="ambiguous" id="S2.SS2.p1.7.m3.1.1.3.2.1.cmml" xref="S2.SS2.p1.7.m3.1.1.3.2">superscript</csymbol><ci id="S2.SS2.p1.7.m3.1.1.3.2.2.cmml" xref="S2.SS2.p1.7.m3.1.1.3.2.2">ℝ</ci><ci id="S2.SS2.p1.7.m3.1.1.3.2.3.cmml" xref="S2.SS2.p1.7.m3.1.1.3.2.3">𝑑</ci></apply><apply id="S2.SS2.p1.7.m3.1.1.3.3.cmml" xref="S2.SS2.p1.7.m3.1.1.3.3"><csymbol cd="ambiguous" id="S2.SS2.p1.7.m3.1.1.3.3.1.cmml" xref="S2.SS2.p1.7.m3.1.1.3.3">superscript</csymbol><ci id="S2.SS2.p1.7.m3.1.1.3.3.2.cmml" xref="S2.SS2.p1.7.m3.1.1.3.3.2">ℝ</ci><ci id="S2.SS2.p1.7.m3.1.1.3.3.3.cmml" xref="S2.SS2.p1.7.m3.1.1.3.3.3">𝑟</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.7.m3.1c">\bm{\phi}:\mathbb{R}^{d}\rightarrow\mathbb{R}^{r}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p1.7.m3.1d">bold_italic_ϕ : blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT → blackboard_R start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT</annotation></semantics></math> is a feature map, leads to:</p>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="A5.EGx1">
<tbody id="S2.Ex1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\bm{y}_{i}" class="ltx_Math" display="inline" id="S2.Ex1.m1.1"><semantics id="S2.Ex1.m1.1a"><msub id="S2.Ex1.m1.1.1" xref="S2.Ex1.m1.1.1.cmml"><mi id="S2.Ex1.m1.1.1.2" xref="S2.Ex1.m1.1.1.2.cmml">𝒚</mi><mi id="S2.Ex1.m1.1.1.3" xref="S2.Ex1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.Ex1.m1.1b"><apply id="S2.Ex1.m1.1.1.cmml" xref="S2.Ex1.m1.1.1"><csymbol cd="ambiguous" id="S2.Ex1.m1.1.1.1.cmml" xref="S2.Ex1.m1.1.1">subscript</csymbol><ci id="S2.Ex1.m1.1.1.2.cmml" xref="S2.Ex1.m1.1.1.2">𝒚</ci><ci id="S2.Ex1.m1.1.1.3.cmml" xref="S2.Ex1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex1.m1.1c">\displaystyle\bm{y}_{i}</annotation><annotation encoding="application/x-llamapun" id="S2.Ex1.m1.1d">bold_italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle=\frac{\sum_{j=1}^{n}\bm{\phi}(\bm{q}_{i})^{\top}\bm{\phi}(\bm{k}%
_{j})\bm{v}_{j}}{\sum_{j=1}^{n}\bm{\phi}(\bm{q}_{i})^{\top}\bm{\phi}(\bm{k}_{j%
})}" class="ltx_Math" display="inline" id="S2.Ex1.m2.4"><semantics id="S2.Ex1.m2.4a"><mrow id="S2.Ex1.m2.4.5" xref="S2.Ex1.m2.4.5.cmml"><mi id="S2.Ex1.m2.4.5.2" xref="S2.Ex1.m2.4.5.2.cmml"></mi><mo id="S2.Ex1.m2.4.5.1" xref="S2.Ex1.m2.4.5.1.cmml">=</mo><mstyle displaystyle="true" id="S2.Ex1.m2.4.4" xref="S2.Ex1.m2.4.4.cmml"><mfrac id="S2.Ex1.m2.4.4a" xref="S2.Ex1.m2.4.4.cmml"><mrow id="S2.Ex1.m2.2.2.2" xref="S2.Ex1.m2.2.2.2.cmml"><msubsup id="S2.Ex1.m2.2.2.2.3" xref="S2.Ex1.m2.2.2.2.3.cmml"><mo id="S2.Ex1.m2.2.2.2.3.2.2" xref="S2.Ex1.m2.2.2.2.3.2.2.cmml">∑</mo><mrow id="S2.Ex1.m2.2.2.2.3.2.3" xref="S2.Ex1.m2.2.2.2.3.2.3.cmml"><mi id="S2.Ex1.m2.2.2.2.3.2.3.2" xref="S2.Ex1.m2.2.2.2.3.2.3.2.cmml">j</mi><mo id="S2.Ex1.m2.2.2.2.3.2.3.1" xref="S2.Ex1.m2.2.2.2.3.2.3.1.cmml">=</mo><mn id="S2.Ex1.m2.2.2.2.3.2.3.3" xref="S2.Ex1.m2.2.2.2.3.2.3.3.cmml">1</mn></mrow><mi id="S2.Ex1.m2.2.2.2.3.3" xref="S2.Ex1.m2.2.2.2.3.3.cmml">n</mi></msubsup><mrow id="S2.Ex1.m2.2.2.2.2" xref="S2.Ex1.m2.2.2.2.2.cmml"><mi class="ltx_mathvariant_bold-italic" id="S2.Ex1.m2.2.2.2.2.4" mathvariant="bold-italic" xref="S2.Ex1.m2.2.2.2.2.4.cmml">ϕ</mi><mo id="S2.Ex1.m2.2.2.2.2.3" xref="S2.Ex1.m2.2.2.2.2.3.cmml">⁢</mo><msup id="S2.Ex1.m2.1.1.1.1.1" xref="S2.Ex1.m2.1.1.1.1.1.cmml"><mrow id="S2.Ex1.m2.1.1.1.1.1.1.1" xref="S2.Ex1.m2.1.1.1.1.1.1.1.1.cmml"><mo id="S2.Ex1.m2.1.1.1.1.1.1.1.2" stretchy="false" xref="S2.Ex1.m2.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S2.Ex1.m2.1.1.1.1.1.1.1.1" xref="S2.Ex1.m2.1.1.1.1.1.1.1.1.cmml"><mi id="S2.Ex1.m2.1.1.1.1.1.1.1.1.2" xref="S2.Ex1.m2.1.1.1.1.1.1.1.1.2.cmml">𝒒</mi><mi id="S2.Ex1.m2.1.1.1.1.1.1.1.1.3" xref="S2.Ex1.m2.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S2.Ex1.m2.1.1.1.1.1.1.1.3" stretchy="false" xref="S2.Ex1.m2.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="S2.Ex1.m2.1.1.1.1.1.3" xref="S2.Ex1.m2.1.1.1.1.1.3.cmml">⊤</mo></msup><mo id="S2.Ex1.m2.2.2.2.2.3a" xref="S2.Ex1.m2.2.2.2.2.3.cmml">⁢</mo><mi class="ltx_mathvariant_bold-italic" id="S2.Ex1.m2.2.2.2.2.5" mathvariant="bold-italic" xref="S2.Ex1.m2.2.2.2.2.5.cmml">ϕ</mi><mo id="S2.Ex1.m2.2.2.2.2.3b" xref="S2.Ex1.m2.2.2.2.2.3.cmml">⁢</mo><mrow id="S2.Ex1.m2.2.2.2.2.2.1" xref="S2.Ex1.m2.2.2.2.2.2.1.1.cmml"><mo id="S2.Ex1.m2.2.2.2.2.2.1.2" stretchy="false" xref="S2.Ex1.m2.2.2.2.2.2.1.1.cmml">(</mo><msub id="S2.Ex1.m2.2.2.2.2.2.1.1" xref="S2.Ex1.m2.2.2.2.2.2.1.1.cmml"><mi id="S2.Ex1.m2.2.2.2.2.2.1.1.2" xref="S2.Ex1.m2.2.2.2.2.2.1.1.2.cmml">𝒌</mi><mi id="S2.Ex1.m2.2.2.2.2.2.1.1.3" xref="S2.Ex1.m2.2.2.2.2.2.1.1.3.cmml">j</mi></msub><mo id="S2.Ex1.m2.2.2.2.2.2.1.3" stretchy="false" xref="S2.Ex1.m2.2.2.2.2.2.1.1.cmml">)</mo></mrow><mo id="S2.Ex1.m2.2.2.2.2.3c" xref="S2.Ex1.m2.2.2.2.2.3.cmml">⁢</mo><msub id="S2.Ex1.m2.2.2.2.2.6" xref="S2.Ex1.m2.2.2.2.2.6.cmml"><mi id="S2.Ex1.m2.2.2.2.2.6.2" xref="S2.Ex1.m2.2.2.2.2.6.2.cmml">𝒗</mi><mi id="S2.Ex1.m2.2.2.2.2.6.3" xref="S2.Ex1.m2.2.2.2.2.6.3.cmml">j</mi></msub></mrow></mrow><mrow id="S2.Ex1.m2.4.4.4" xref="S2.Ex1.m2.4.4.4.cmml"><msubsup id="S2.Ex1.m2.4.4.4.3" xref="S2.Ex1.m2.4.4.4.3.cmml"><mo id="S2.Ex1.m2.4.4.4.3.2.2" xref="S2.Ex1.m2.4.4.4.3.2.2.cmml">∑</mo><mrow id="S2.Ex1.m2.4.4.4.3.2.3" xref="S2.Ex1.m2.4.4.4.3.2.3.cmml"><mi id="S2.Ex1.m2.4.4.4.3.2.3.2" xref="S2.Ex1.m2.4.4.4.3.2.3.2.cmml">j</mi><mo id="S2.Ex1.m2.4.4.4.3.2.3.1" xref="S2.Ex1.m2.4.4.4.3.2.3.1.cmml">=</mo><mn id="S2.Ex1.m2.4.4.4.3.2.3.3" xref="S2.Ex1.m2.4.4.4.3.2.3.3.cmml">1</mn></mrow><mi id="S2.Ex1.m2.4.4.4.3.3" xref="S2.Ex1.m2.4.4.4.3.3.cmml">n</mi></msubsup><mrow id="S2.Ex1.m2.4.4.4.2" xref="S2.Ex1.m2.4.4.4.2.cmml"><mi class="ltx_mathvariant_bold-italic" id="S2.Ex1.m2.4.4.4.2.4" mathvariant="bold-italic" xref="S2.Ex1.m2.4.4.4.2.4.cmml">ϕ</mi><mo id="S2.Ex1.m2.4.4.4.2.3" xref="S2.Ex1.m2.4.4.4.2.3.cmml">⁢</mo><msup id="S2.Ex1.m2.3.3.3.1.1" xref="S2.Ex1.m2.3.3.3.1.1.cmml"><mrow id="S2.Ex1.m2.3.3.3.1.1.1.1" xref="S2.Ex1.m2.3.3.3.1.1.1.1.1.cmml"><mo id="S2.Ex1.m2.3.3.3.1.1.1.1.2" stretchy="false" xref="S2.Ex1.m2.3.3.3.1.1.1.1.1.cmml">(</mo><msub id="S2.Ex1.m2.3.3.3.1.1.1.1.1" xref="S2.Ex1.m2.3.3.3.1.1.1.1.1.cmml"><mi id="S2.Ex1.m2.3.3.3.1.1.1.1.1.2" xref="S2.Ex1.m2.3.3.3.1.1.1.1.1.2.cmml">𝒒</mi><mi id="S2.Ex1.m2.3.3.3.1.1.1.1.1.3" xref="S2.Ex1.m2.3.3.3.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S2.Ex1.m2.3.3.3.1.1.1.1.3" stretchy="false" xref="S2.Ex1.m2.3.3.3.1.1.1.1.1.cmml">)</mo></mrow><mo id="S2.Ex1.m2.3.3.3.1.1.3" xref="S2.Ex1.m2.3.3.3.1.1.3.cmml">⊤</mo></msup><mo id="S2.Ex1.m2.4.4.4.2.3a" xref="S2.Ex1.m2.4.4.4.2.3.cmml">⁢</mo><mi class="ltx_mathvariant_bold-italic" id="S2.Ex1.m2.4.4.4.2.5" mathvariant="bold-italic" xref="S2.Ex1.m2.4.4.4.2.5.cmml">ϕ</mi><mo id="S2.Ex1.m2.4.4.4.2.3b" xref="S2.Ex1.m2.4.4.4.2.3.cmml">⁢</mo><mrow id="S2.Ex1.m2.4.4.4.2.2.1" xref="S2.Ex1.m2.4.4.4.2.2.1.1.cmml"><mo id="S2.Ex1.m2.4.4.4.2.2.1.2" stretchy="false" xref="S2.Ex1.m2.4.4.4.2.2.1.1.cmml">(</mo><msub id="S2.Ex1.m2.4.4.4.2.2.1.1" xref="S2.Ex1.m2.4.4.4.2.2.1.1.cmml"><mi id="S2.Ex1.m2.4.4.4.2.2.1.1.2" xref="S2.Ex1.m2.4.4.4.2.2.1.1.2.cmml">𝒌</mi><mi id="S2.Ex1.m2.4.4.4.2.2.1.1.3" xref="S2.Ex1.m2.4.4.4.2.2.1.1.3.cmml">j</mi></msub><mo id="S2.Ex1.m2.4.4.4.2.2.1.3" stretchy="false" xref="S2.Ex1.m2.4.4.4.2.2.1.1.cmml">)</mo></mrow></mrow></mrow></mfrac></mstyle></mrow><annotation-xml encoding="MathML-Content" id="S2.Ex1.m2.4b"><apply id="S2.Ex1.m2.4.5.cmml" xref="S2.Ex1.m2.4.5"><eq id="S2.Ex1.m2.4.5.1.cmml" xref="S2.Ex1.m2.4.5.1"></eq><csymbol cd="latexml" id="S2.Ex1.m2.4.5.2.cmml" xref="S2.Ex1.m2.4.5.2">absent</csymbol><apply id="S2.Ex1.m2.4.4.cmml" xref="S2.Ex1.m2.4.4"><divide id="S2.Ex1.m2.4.4.5.cmml" xref="S2.Ex1.m2.4.4"></divide><apply id="S2.Ex1.m2.2.2.2.cmml" xref="S2.Ex1.m2.2.2.2"><apply id="S2.Ex1.m2.2.2.2.3.cmml" xref="S2.Ex1.m2.2.2.2.3"><csymbol cd="ambiguous" id="S2.Ex1.m2.2.2.2.3.1.cmml" xref="S2.Ex1.m2.2.2.2.3">superscript</csymbol><apply id="S2.Ex1.m2.2.2.2.3.2.cmml" xref="S2.Ex1.m2.2.2.2.3"><csymbol cd="ambiguous" id="S2.Ex1.m2.2.2.2.3.2.1.cmml" xref="S2.Ex1.m2.2.2.2.3">subscript</csymbol><sum id="S2.Ex1.m2.2.2.2.3.2.2.cmml" xref="S2.Ex1.m2.2.2.2.3.2.2"></sum><apply id="S2.Ex1.m2.2.2.2.3.2.3.cmml" xref="S2.Ex1.m2.2.2.2.3.2.3"><eq id="S2.Ex1.m2.2.2.2.3.2.3.1.cmml" xref="S2.Ex1.m2.2.2.2.3.2.3.1"></eq><ci id="S2.Ex1.m2.2.2.2.3.2.3.2.cmml" xref="S2.Ex1.m2.2.2.2.3.2.3.2">𝑗</ci><cn id="S2.Ex1.m2.2.2.2.3.2.3.3.cmml" type="integer" xref="S2.Ex1.m2.2.2.2.3.2.3.3">1</cn></apply></apply><ci id="S2.Ex1.m2.2.2.2.3.3.cmml" xref="S2.Ex1.m2.2.2.2.3.3">𝑛</ci></apply><apply id="S2.Ex1.m2.2.2.2.2.cmml" xref="S2.Ex1.m2.2.2.2.2"><times id="S2.Ex1.m2.2.2.2.2.3.cmml" xref="S2.Ex1.m2.2.2.2.2.3"></times><ci id="S2.Ex1.m2.2.2.2.2.4.cmml" xref="S2.Ex1.m2.2.2.2.2.4">bold-italic-ϕ</ci><apply id="S2.Ex1.m2.1.1.1.1.1.cmml" xref="S2.Ex1.m2.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.Ex1.m2.1.1.1.1.1.2.cmml" xref="S2.Ex1.m2.1.1.1.1.1">superscript</csymbol><apply id="S2.Ex1.m2.1.1.1.1.1.1.1.1.cmml" xref="S2.Ex1.m2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.Ex1.m2.1.1.1.1.1.1.1.1.1.cmml" xref="S2.Ex1.m2.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.Ex1.m2.1.1.1.1.1.1.1.1.2.cmml" xref="S2.Ex1.m2.1.1.1.1.1.1.1.1.2">𝒒</ci><ci id="S2.Ex1.m2.1.1.1.1.1.1.1.1.3.cmml" xref="S2.Ex1.m2.1.1.1.1.1.1.1.1.3">𝑖</ci></apply><csymbol cd="latexml" id="S2.Ex1.m2.1.1.1.1.1.3.cmml" xref="S2.Ex1.m2.1.1.1.1.1.3">top</csymbol></apply><ci id="S2.Ex1.m2.2.2.2.2.5.cmml" xref="S2.Ex1.m2.2.2.2.2.5">bold-italic-ϕ</ci><apply id="S2.Ex1.m2.2.2.2.2.2.1.1.cmml" xref="S2.Ex1.m2.2.2.2.2.2.1"><csymbol cd="ambiguous" id="S2.Ex1.m2.2.2.2.2.2.1.1.1.cmml" xref="S2.Ex1.m2.2.2.2.2.2.1">subscript</csymbol><ci id="S2.Ex1.m2.2.2.2.2.2.1.1.2.cmml" xref="S2.Ex1.m2.2.2.2.2.2.1.1.2">𝒌</ci><ci id="S2.Ex1.m2.2.2.2.2.2.1.1.3.cmml" xref="S2.Ex1.m2.2.2.2.2.2.1.1.3">𝑗</ci></apply><apply id="S2.Ex1.m2.2.2.2.2.6.cmml" xref="S2.Ex1.m2.2.2.2.2.6"><csymbol cd="ambiguous" id="S2.Ex1.m2.2.2.2.2.6.1.cmml" xref="S2.Ex1.m2.2.2.2.2.6">subscript</csymbol><ci id="S2.Ex1.m2.2.2.2.2.6.2.cmml" xref="S2.Ex1.m2.2.2.2.2.6.2">𝒗</ci><ci id="S2.Ex1.m2.2.2.2.2.6.3.cmml" xref="S2.Ex1.m2.2.2.2.2.6.3">𝑗</ci></apply></apply></apply><apply id="S2.Ex1.m2.4.4.4.cmml" xref="S2.Ex1.m2.4.4.4"><apply id="S2.Ex1.m2.4.4.4.3.cmml" xref="S2.Ex1.m2.4.4.4.3"><csymbol cd="ambiguous" id="S2.Ex1.m2.4.4.4.3.1.cmml" xref="S2.Ex1.m2.4.4.4.3">superscript</csymbol><apply id="S2.Ex1.m2.4.4.4.3.2.cmml" xref="S2.Ex1.m2.4.4.4.3"><csymbol cd="ambiguous" id="S2.Ex1.m2.4.4.4.3.2.1.cmml" xref="S2.Ex1.m2.4.4.4.3">subscript</csymbol><sum id="S2.Ex1.m2.4.4.4.3.2.2.cmml" xref="S2.Ex1.m2.4.4.4.3.2.2"></sum><apply id="S2.Ex1.m2.4.4.4.3.2.3.cmml" xref="S2.Ex1.m2.4.4.4.3.2.3"><eq id="S2.Ex1.m2.4.4.4.3.2.3.1.cmml" xref="S2.Ex1.m2.4.4.4.3.2.3.1"></eq><ci id="S2.Ex1.m2.4.4.4.3.2.3.2.cmml" xref="S2.Ex1.m2.4.4.4.3.2.3.2">𝑗</ci><cn id="S2.Ex1.m2.4.4.4.3.2.3.3.cmml" type="integer" xref="S2.Ex1.m2.4.4.4.3.2.3.3">1</cn></apply></apply><ci id="S2.Ex1.m2.4.4.4.3.3.cmml" xref="S2.Ex1.m2.4.4.4.3.3">𝑛</ci></apply><apply id="S2.Ex1.m2.4.4.4.2.cmml" xref="S2.Ex1.m2.4.4.4.2"><times id="S2.Ex1.m2.4.4.4.2.3.cmml" xref="S2.Ex1.m2.4.4.4.2.3"></times><ci id="S2.Ex1.m2.4.4.4.2.4.cmml" xref="S2.Ex1.m2.4.4.4.2.4">bold-italic-ϕ</ci><apply id="S2.Ex1.m2.3.3.3.1.1.cmml" xref="S2.Ex1.m2.3.3.3.1.1"><csymbol cd="ambiguous" id="S2.Ex1.m2.3.3.3.1.1.2.cmml" xref="S2.Ex1.m2.3.3.3.1.1">superscript</csymbol><apply id="S2.Ex1.m2.3.3.3.1.1.1.1.1.cmml" xref="S2.Ex1.m2.3.3.3.1.1.1.1"><csymbol cd="ambiguous" id="S2.Ex1.m2.3.3.3.1.1.1.1.1.1.cmml" xref="S2.Ex1.m2.3.3.3.1.1.1.1">subscript</csymbol><ci id="S2.Ex1.m2.3.3.3.1.1.1.1.1.2.cmml" xref="S2.Ex1.m2.3.3.3.1.1.1.1.1.2">𝒒</ci><ci id="S2.Ex1.m2.3.3.3.1.1.1.1.1.3.cmml" xref="S2.Ex1.m2.3.3.3.1.1.1.1.1.3">𝑖</ci></apply><csymbol cd="latexml" id="S2.Ex1.m2.3.3.3.1.1.3.cmml" xref="S2.Ex1.m2.3.3.3.1.1.3">top</csymbol></apply><ci id="S2.Ex1.m2.4.4.4.2.5.cmml" xref="S2.Ex1.m2.4.4.4.2.5">bold-italic-ϕ</ci><apply id="S2.Ex1.m2.4.4.4.2.2.1.1.cmml" xref="S2.Ex1.m2.4.4.4.2.2.1"><csymbol cd="ambiguous" id="S2.Ex1.m2.4.4.4.2.2.1.1.1.cmml" xref="S2.Ex1.m2.4.4.4.2.2.1">subscript</csymbol><ci id="S2.Ex1.m2.4.4.4.2.2.1.1.2.cmml" xref="S2.Ex1.m2.4.4.4.2.2.1.1.2">𝒌</ci><ci id="S2.Ex1.m2.4.4.4.2.2.1.1.3.cmml" xref="S2.Ex1.m2.4.4.4.2.2.1.1.3">𝑗</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex1.m2.4c">\displaystyle=\frac{\sum_{j=1}^{n}\bm{\phi}(\bm{q}_{i})^{\top}\bm{\phi}(\bm{k}%
_{j})\bm{v}_{j}}{\sum_{j=1}^{n}\bm{\phi}(\bm{q}_{i})^{\top}\bm{\phi}(\bm{k}_{j%
})}</annotation><annotation encoding="application/x-llamapun" id="S2.Ex1.m2.4d">= divide start_ARG ∑ start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT bold_italic_ϕ ( bold_italic_q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT ⊤ end_POSTSUPERSCRIPT bold_italic_ϕ ( bold_italic_k start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) bold_italic_v start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT end_ARG start_ARG ∑ start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT bold_italic_ϕ ( bold_italic_q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT ⊤ end_POSTSUPERSCRIPT bold_italic_ϕ ( bold_italic_k start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) end_ARG</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="S2.Ex2"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle=\frac{\sum_{j=1}^{n}\bm{v}_{j}\bm{\phi}(\bm{k}_{j})^{\top}\bm{%
\phi}(\bm{q}_{i})}{\sum_{j=1}^{n}\bm{\phi}(\bm{k}_{j})^{\top}\bm{\phi}(\bm{q}_%
{i})}" class="ltx_Math" display="inline" id="S2.Ex2.m1.4"><semantics id="S2.Ex2.m1.4a"><mrow id="S2.Ex2.m1.4.5" xref="S2.Ex2.m1.4.5.cmml"><mi id="S2.Ex2.m1.4.5.2" xref="S2.Ex2.m1.4.5.2.cmml"></mi><mo id="S2.Ex2.m1.4.5.1" xref="S2.Ex2.m1.4.5.1.cmml">=</mo><mstyle displaystyle="true" id="S2.Ex2.m1.4.4" xref="S2.Ex2.m1.4.4.cmml"><mfrac id="S2.Ex2.m1.4.4a" xref="S2.Ex2.m1.4.4.cmml"><mrow id="S2.Ex2.m1.2.2.2" xref="S2.Ex2.m1.2.2.2.cmml"><msubsup id="S2.Ex2.m1.2.2.2.3" xref="S2.Ex2.m1.2.2.2.3.cmml"><mo id="S2.Ex2.m1.2.2.2.3.2.2" xref="S2.Ex2.m1.2.2.2.3.2.2.cmml">∑</mo><mrow id="S2.Ex2.m1.2.2.2.3.2.3" xref="S2.Ex2.m1.2.2.2.3.2.3.cmml"><mi id="S2.Ex2.m1.2.2.2.3.2.3.2" xref="S2.Ex2.m1.2.2.2.3.2.3.2.cmml">j</mi><mo id="S2.Ex2.m1.2.2.2.3.2.3.1" xref="S2.Ex2.m1.2.2.2.3.2.3.1.cmml">=</mo><mn id="S2.Ex2.m1.2.2.2.3.2.3.3" xref="S2.Ex2.m1.2.2.2.3.2.3.3.cmml">1</mn></mrow><mi id="S2.Ex2.m1.2.2.2.3.3" xref="S2.Ex2.m1.2.2.2.3.3.cmml">n</mi></msubsup><mrow id="S2.Ex2.m1.2.2.2.2" xref="S2.Ex2.m1.2.2.2.2.cmml"><msub id="S2.Ex2.m1.2.2.2.2.4" xref="S2.Ex2.m1.2.2.2.2.4.cmml"><mi id="S2.Ex2.m1.2.2.2.2.4.2" xref="S2.Ex2.m1.2.2.2.2.4.2.cmml">𝒗</mi><mi id="S2.Ex2.m1.2.2.2.2.4.3" xref="S2.Ex2.m1.2.2.2.2.4.3.cmml">j</mi></msub><mo id="S2.Ex2.m1.2.2.2.2.3" xref="S2.Ex2.m1.2.2.2.2.3.cmml">⁢</mo><mi class="ltx_mathvariant_bold-italic" id="S2.Ex2.m1.2.2.2.2.5" mathvariant="bold-italic" xref="S2.Ex2.m1.2.2.2.2.5.cmml">ϕ</mi><mo id="S2.Ex2.m1.2.2.2.2.3a" xref="S2.Ex2.m1.2.2.2.2.3.cmml">⁢</mo><msup id="S2.Ex2.m1.1.1.1.1.1" xref="S2.Ex2.m1.1.1.1.1.1.cmml"><mrow id="S2.Ex2.m1.1.1.1.1.1.1.1" xref="S2.Ex2.m1.1.1.1.1.1.1.1.1.cmml"><mo id="S2.Ex2.m1.1.1.1.1.1.1.1.2" stretchy="false" xref="S2.Ex2.m1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S2.Ex2.m1.1.1.1.1.1.1.1.1" xref="S2.Ex2.m1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.Ex2.m1.1.1.1.1.1.1.1.1.2" xref="S2.Ex2.m1.1.1.1.1.1.1.1.1.2.cmml">𝒌</mi><mi id="S2.Ex2.m1.1.1.1.1.1.1.1.1.3" xref="S2.Ex2.m1.1.1.1.1.1.1.1.1.3.cmml">j</mi></msub><mo id="S2.Ex2.m1.1.1.1.1.1.1.1.3" stretchy="false" xref="S2.Ex2.m1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="S2.Ex2.m1.1.1.1.1.1.3" xref="S2.Ex2.m1.1.1.1.1.1.3.cmml">⊤</mo></msup><mo id="S2.Ex2.m1.2.2.2.2.3b" xref="S2.Ex2.m1.2.2.2.2.3.cmml">⁢</mo><mi class="ltx_mathvariant_bold-italic" id="S2.Ex2.m1.2.2.2.2.6" mathvariant="bold-italic" xref="S2.Ex2.m1.2.2.2.2.6.cmml">ϕ</mi><mo id="S2.Ex2.m1.2.2.2.2.3c" xref="S2.Ex2.m1.2.2.2.2.3.cmml">⁢</mo><mrow id="S2.Ex2.m1.2.2.2.2.2.1" xref="S2.Ex2.m1.2.2.2.2.2.1.1.cmml"><mo id="S2.Ex2.m1.2.2.2.2.2.1.2" stretchy="false" xref="S2.Ex2.m1.2.2.2.2.2.1.1.cmml">(</mo><msub id="S2.Ex2.m1.2.2.2.2.2.1.1" xref="S2.Ex2.m1.2.2.2.2.2.1.1.cmml"><mi id="S2.Ex2.m1.2.2.2.2.2.1.1.2" xref="S2.Ex2.m1.2.2.2.2.2.1.1.2.cmml">𝒒</mi><mi id="S2.Ex2.m1.2.2.2.2.2.1.1.3" xref="S2.Ex2.m1.2.2.2.2.2.1.1.3.cmml">i</mi></msub><mo id="S2.Ex2.m1.2.2.2.2.2.1.3" stretchy="false" xref="S2.Ex2.m1.2.2.2.2.2.1.1.cmml">)</mo></mrow></mrow></mrow><mrow id="S2.Ex2.m1.4.4.4" xref="S2.Ex2.m1.4.4.4.cmml"><msubsup id="S2.Ex2.m1.4.4.4.3" xref="S2.Ex2.m1.4.4.4.3.cmml"><mo id="S2.Ex2.m1.4.4.4.3.2.2" xref="S2.Ex2.m1.4.4.4.3.2.2.cmml">∑</mo><mrow id="S2.Ex2.m1.4.4.4.3.2.3" xref="S2.Ex2.m1.4.4.4.3.2.3.cmml"><mi id="S2.Ex2.m1.4.4.4.3.2.3.2" xref="S2.Ex2.m1.4.4.4.3.2.3.2.cmml">j</mi><mo id="S2.Ex2.m1.4.4.4.3.2.3.1" xref="S2.Ex2.m1.4.4.4.3.2.3.1.cmml">=</mo><mn id="S2.Ex2.m1.4.4.4.3.2.3.3" xref="S2.Ex2.m1.4.4.4.3.2.3.3.cmml">1</mn></mrow><mi id="S2.Ex2.m1.4.4.4.3.3" xref="S2.Ex2.m1.4.4.4.3.3.cmml">n</mi></msubsup><mrow id="S2.Ex2.m1.4.4.4.2" xref="S2.Ex2.m1.4.4.4.2.cmml"><mi class="ltx_mathvariant_bold-italic" id="S2.Ex2.m1.4.4.4.2.4" mathvariant="bold-italic" xref="S2.Ex2.m1.4.4.4.2.4.cmml">ϕ</mi><mo id="S2.Ex2.m1.4.4.4.2.3" xref="S2.Ex2.m1.4.4.4.2.3.cmml">⁢</mo><msup id="S2.Ex2.m1.3.3.3.1.1" xref="S2.Ex2.m1.3.3.3.1.1.cmml"><mrow id="S2.Ex2.m1.3.3.3.1.1.1.1" xref="S2.Ex2.m1.3.3.3.1.1.1.1.1.cmml"><mo id="S2.Ex2.m1.3.3.3.1.1.1.1.2" stretchy="false" xref="S2.Ex2.m1.3.3.3.1.1.1.1.1.cmml">(</mo><msub id="S2.Ex2.m1.3.3.3.1.1.1.1.1" xref="S2.Ex2.m1.3.3.3.1.1.1.1.1.cmml"><mi id="S2.Ex2.m1.3.3.3.1.1.1.1.1.2" xref="S2.Ex2.m1.3.3.3.1.1.1.1.1.2.cmml">𝒌</mi><mi id="S2.Ex2.m1.3.3.3.1.1.1.1.1.3" xref="S2.Ex2.m1.3.3.3.1.1.1.1.1.3.cmml">j</mi></msub><mo id="S2.Ex2.m1.3.3.3.1.1.1.1.3" stretchy="false" xref="S2.Ex2.m1.3.3.3.1.1.1.1.1.cmml">)</mo></mrow><mo id="S2.Ex2.m1.3.3.3.1.1.3" xref="S2.Ex2.m1.3.3.3.1.1.3.cmml">⊤</mo></msup><mo id="S2.Ex2.m1.4.4.4.2.3a" xref="S2.Ex2.m1.4.4.4.2.3.cmml">⁢</mo><mi class="ltx_mathvariant_bold-italic" id="S2.Ex2.m1.4.4.4.2.5" mathvariant="bold-italic" xref="S2.Ex2.m1.4.4.4.2.5.cmml">ϕ</mi><mo id="S2.Ex2.m1.4.4.4.2.3b" xref="S2.Ex2.m1.4.4.4.2.3.cmml">⁢</mo><mrow id="S2.Ex2.m1.4.4.4.2.2.1" xref="S2.Ex2.m1.4.4.4.2.2.1.1.cmml"><mo id="S2.Ex2.m1.4.4.4.2.2.1.2" stretchy="false" xref="S2.Ex2.m1.4.4.4.2.2.1.1.cmml">(</mo><msub id="S2.Ex2.m1.4.4.4.2.2.1.1" xref="S2.Ex2.m1.4.4.4.2.2.1.1.cmml"><mi id="S2.Ex2.m1.4.4.4.2.2.1.1.2" xref="S2.Ex2.m1.4.4.4.2.2.1.1.2.cmml">𝒒</mi><mi id="S2.Ex2.m1.4.4.4.2.2.1.1.3" xref="S2.Ex2.m1.4.4.4.2.2.1.1.3.cmml">i</mi></msub><mo id="S2.Ex2.m1.4.4.4.2.2.1.3" stretchy="false" xref="S2.Ex2.m1.4.4.4.2.2.1.1.cmml">)</mo></mrow></mrow></mrow></mfrac></mstyle></mrow><annotation-xml encoding="MathML-Content" id="S2.Ex2.m1.4b"><apply id="S2.Ex2.m1.4.5.cmml" xref="S2.Ex2.m1.4.5"><eq id="S2.Ex2.m1.4.5.1.cmml" xref="S2.Ex2.m1.4.5.1"></eq><csymbol cd="latexml" id="S2.Ex2.m1.4.5.2.cmml" xref="S2.Ex2.m1.4.5.2">absent</csymbol><apply id="S2.Ex2.m1.4.4.cmml" xref="S2.Ex2.m1.4.4"><divide id="S2.Ex2.m1.4.4.5.cmml" xref="S2.Ex2.m1.4.4"></divide><apply id="S2.Ex2.m1.2.2.2.cmml" xref="S2.Ex2.m1.2.2.2"><apply id="S2.Ex2.m1.2.2.2.3.cmml" xref="S2.Ex2.m1.2.2.2.3"><csymbol cd="ambiguous" id="S2.Ex2.m1.2.2.2.3.1.cmml" xref="S2.Ex2.m1.2.2.2.3">superscript</csymbol><apply id="S2.Ex2.m1.2.2.2.3.2.cmml" xref="S2.Ex2.m1.2.2.2.3"><csymbol cd="ambiguous" id="S2.Ex2.m1.2.2.2.3.2.1.cmml" xref="S2.Ex2.m1.2.2.2.3">subscript</csymbol><sum id="S2.Ex2.m1.2.2.2.3.2.2.cmml" xref="S2.Ex2.m1.2.2.2.3.2.2"></sum><apply id="S2.Ex2.m1.2.2.2.3.2.3.cmml" xref="S2.Ex2.m1.2.2.2.3.2.3"><eq id="S2.Ex2.m1.2.2.2.3.2.3.1.cmml" xref="S2.Ex2.m1.2.2.2.3.2.3.1"></eq><ci id="S2.Ex2.m1.2.2.2.3.2.3.2.cmml" xref="S2.Ex2.m1.2.2.2.3.2.3.2">𝑗</ci><cn id="S2.Ex2.m1.2.2.2.3.2.3.3.cmml" type="integer" xref="S2.Ex2.m1.2.2.2.3.2.3.3">1</cn></apply></apply><ci id="S2.Ex2.m1.2.2.2.3.3.cmml" xref="S2.Ex2.m1.2.2.2.3.3">𝑛</ci></apply><apply id="S2.Ex2.m1.2.2.2.2.cmml" xref="S2.Ex2.m1.2.2.2.2"><times id="S2.Ex2.m1.2.2.2.2.3.cmml" xref="S2.Ex2.m1.2.2.2.2.3"></times><apply id="S2.Ex2.m1.2.2.2.2.4.cmml" xref="S2.Ex2.m1.2.2.2.2.4"><csymbol cd="ambiguous" id="S2.Ex2.m1.2.2.2.2.4.1.cmml" xref="S2.Ex2.m1.2.2.2.2.4">subscript</csymbol><ci id="S2.Ex2.m1.2.2.2.2.4.2.cmml" xref="S2.Ex2.m1.2.2.2.2.4.2">𝒗</ci><ci id="S2.Ex2.m1.2.2.2.2.4.3.cmml" xref="S2.Ex2.m1.2.2.2.2.4.3">𝑗</ci></apply><ci id="S2.Ex2.m1.2.2.2.2.5.cmml" xref="S2.Ex2.m1.2.2.2.2.5">bold-italic-ϕ</ci><apply id="S2.Ex2.m1.1.1.1.1.1.cmml" xref="S2.Ex2.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.Ex2.m1.1.1.1.1.1.2.cmml" xref="S2.Ex2.m1.1.1.1.1.1">superscript</csymbol><apply id="S2.Ex2.m1.1.1.1.1.1.1.1.1.cmml" xref="S2.Ex2.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.Ex2.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.Ex2.m1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.Ex2.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.Ex2.m1.1.1.1.1.1.1.1.1.2">𝒌</ci><ci id="S2.Ex2.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.Ex2.m1.1.1.1.1.1.1.1.1.3">𝑗</ci></apply><csymbol cd="latexml" id="S2.Ex2.m1.1.1.1.1.1.3.cmml" xref="S2.Ex2.m1.1.1.1.1.1.3">top</csymbol></apply><ci id="S2.Ex2.m1.2.2.2.2.6.cmml" xref="S2.Ex2.m1.2.2.2.2.6">bold-italic-ϕ</ci><apply id="S2.Ex2.m1.2.2.2.2.2.1.1.cmml" xref="S2.Ex2.m1.2.2.2.2.2.1"><csymbol cd="ambiguous" id="S2.Ex2.m1.2.2.2.2.2.1.1.1.cmml" xref="S2.Ex2.m1.2.2.2.2.2.1">subscript</csymbol><ci id="S2.Ex2.m1.2.2.2.2.2.1.1.2.cmml" xref="S2.Ex2.m1.2.2.2.2.2.1.1.2">𝒒</ci><ci id="S2.Ex2.m1.2.2.2.2.2.1.1.3.cmml" xref="S2.Ex2.m1.2.2.2.2.2.1.1.3">𝑖</ci></apply></apply></apply><apply id="S2.Ex2.m1.4.4.4.cmml" xref="S2.Ex2.m1.4.4.4"><apply id="S2.Ex2.m1.4.4.4.3.cmml" xref="S2.Ex2.m1.4.4.4.3"><csymbol cd="ambiguous" id="S2.Ex2.m1.4.4.4.3.1.cmml" xref="S2.Ex2.m1.4.4.4.3">superscript</csymbol><apply id="S2.Ex2.m1.4.4.4.3.2.cmml" xref="S2.Ex2.m1.4.4.4.3"><csymbol cd="ambiguous" id="S2.Ex2.m1.4.4.4.3.2.1.cmml" xref="S2.Ex2.m1.4.4.4.3">subscript</csymbol><sum id="S2.Ex2.m1.4.4.4.3.2.2.cmml" xref="S2.Ex2.m1.4.4.4.3.2.2"></sum><apply id="S2.Ex2.m1.4.4.4.3.2.3.cmml" xref="S2.Ex2.m1.4.4.4.3.2.3"><eq id="S2.Ex2.m1.4.4.4.3.2.3.1.cmml" xref="S2.Ex2.m1.4.4.4.3.2.3.1"></eq><ci id="S2.Ex2.m1.4.4.4.3.2.3.2.cmml" xref="S2.Ex2.m1.4.4.4.3.2.3.2">𝑗</ci><cn id="S2.Ex2.m1.4.4.4.3.2.3.3.cmml" type="integer" xref="S2.Ex2.m1.4.4.4.3.2.3.3">1</cn></apply></apply><ci id="S2.Ex2.m1.4.4.4.3.3.cmml" xref="S2.Ex2.m1.4.4.4.3.3">𝑛</ci></apply><apply id="S2.Ex2.m1.4.4.4.2.cmml" xref="S2.Ex2.m1.4.4.4.2"><times id="S2.Ex2.m1.4.4.4.2.3.cmml" xref="S2.Ex2.m1.4.4.4.2.3"></times><ci id="S2.Ex2.m1.4.4.4.2.4.cmml" xref="S2.Ex2.m1.4.4.4.2.4">bold-italic-ϕ</ci><apply id="S2.Ex2.m1.3.3.3.1.1.cmml" xref="S2.Ex2.m1.3.3.3.1.1"><csymbol cd="ambiguous" id="S2.Ex2.m1.3.3.3.1.1.2.cmml" xref="S2.Ex2.m1.3.3.3.1.1">superscript</csymbol><apply id="S2.Ex2.m1.3.3.3.1.1.1.1.1.cmml" xref="S2.Ex2.m1.3.3.3.1.1.1.1"><csymbol cd="ambiguous" id="S2.Ex2.m1.3.3.3.1.1.1.1.1.1.cmml" xref="S2.Ex2.m1.3.3.3.1.1.1.1">subscript</csymbol><ci id="S2.Ex2.m1.3.3.3.1.1.1.1.1.2.cmml" xref="S2.Ex2.m1.3.3.3.1.1.1.1.1.2">𝒌</ci><ci id="S2.Ex2.m1.3.3.3.1.1.1.1.1.3.cmml" xref="S2.Ex2.m1.3.3.3.1.1.1.1.1.3">𝑗</ci></apply><csymbol cd="latexml" id="S2.Ex2.m1.3.3.3.1.1.3.cmml" xref="S2.Ex2.m1.3.3.3.1.1.3">top</csymbol></apply><ci id="S2.Ex2.m1.4.4.4.2.5.cmml" xref="S2.Ex2.m1.4.4.4.2.5">bold-italic-ϕ</ci><apply id="S2.Ex2.m1.4.4.4.2.2.1.1.cmml" xref="S2.Ex2.m1.4.4.4.2.2.1"><csymbol cd="ambiguous" id="S2.Ex2.m1.4.4.4.2.2.1.1.1.cmml" xref="S2.Ex2.m1.4.4.4.2.2.1">subscript</csymbol><ci id="S2.Ex2.m1.4.4.4.2.2.1.1.2.cmml" xref="S2.Ex2.m1.4.4.4.2.2.1.1.2">𝒒</ci><ci id="S2.Ex2.m1.4.4.4.2.2.1.1.3.cmml" xref="S2.Ex2.m1.4.4.4.2.2.1.1.3">𝑖</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex2.m1.4c">\displaystyle=\frac{\sum_{j=1}^{n}\bm{v}_{j}\bm{\phi}(\bm{k}_{j})^{\top}\bm{%
\phi}(\bm{q}_{i})}{\sum_{j=1}^{n}\bm{\phi}(\bm{k}_{j})^{\top}\bm{\phi}(\bm{q}_%
{i})}</annotation><annotation encoding="application/x-llamapun" id="S2.Ex2.m1.4d">= divide start_ARG ∑ start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT bold_italic_v start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT bold_italic_ϕ ( bold_italic_k start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT ⊤ end_POSTSUPERSCRIPT bold_italic_ϕ ( bold_italic_q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) end_ARG start_ARG ∑ start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT bold_italic_ϕ ( bold_italic_k start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT ⊤ end_POSTSUPERSCRIPT bold_italic_ϕ ( bold_italic_q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) end_ARG</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="S2.E3"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle=\frac{\bm{S}^{\top}\bm{\phi}(\bm{q}_{i})}{\bm{z}^{\top}\bm{\phi}%
(\bm{q}_{i})}," class="ltx_Math" display="inline" id="S2.E3.m1.3"><semantics id="S2.E3.m1.3a"><mrow id="S2.E3.m1.3.3.1" xref="S2.E3.m1.3.3.1.1.cmml"><mrow id="S2.E3.m1.3.3.1.1" xref="S2.E3.m1.3.3.1.1.cmml"><mi id="S2.E3.m1.3.3.1.1.2" xref="S2.E3.m1.3.3.1.1.2.cmml"></mi><mo id="S2.E3.m1.3.3.1.1.1" xref="S2.E3.m1.3.3.1.1.1.cmml">=</mo><mstyle displaystyle="true" id="S2.E3.m1.2.2" xref="S2.E3.m1.2.2.cmml"><mfrac id="S2.E3.m1.2.2a" xref="S2.E3.m1.2.2.cmml"><mrow id="S2.E3.m1.1.1.1" xref="S2.E3.m1.1.1.1.cmml"><msup id="S2.E3.m1.1.1.1.3" xref="S2.E3.m1.1.1.1.3.cmml"><mi id="S2.E3.m1.1.1.1.3.2" xref="S2.E3.m1.1.1.1.3.2.cmml">𝑺</mi><mo id="S2.E3.m1.1.1.1.3.3" xref="S2.E3.m1.1.1.1.3.3.cmml">⊤</mo></msup><mo id="S2.E3.m1.1.1.1.2" xref="S2.E3.m1.1.1.1.2.cmml">⁢</mo><mi class="ltx_mathvariant_bold-italic" id="S2.E3.m1.1.1.1.4" mathvariant="bold-italic" xref="S2.E3.m1.1.1.1.4.cmml">ϕ</mi><mo id="S2.E3.m1.1.1.1.2a" xref="S2.E3.m1.1.1.1.2.cmml">⁢</mo><mrow id="S2.E3.m1.1.1.1.1.1" xref="S2.E3.m1.1.1.1.1.1.1.cmml"><mo id="S2.E3.m1.1.1.1.1.1.2" stretchy="false" xref="S2.E3.m1.1.1.1.1.1.1.cmml">(</mo><msub id="S2.E3.m1.1.1.1.1.1.1" xref="S2.E3.m1.1.1.1.1.1.1.cmml"><mi id="S2.E3.m1.1.1.1.1.1.1.2" xref="S2.E3.m1.1.1.1.1.1.1.2.cmml">𝒒</mi><mi id="S2.E3.m1.1.1.1.1.1.1.3" xref="S2.E3.m1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S2.E3.m1.1.1.1.1.1.3" stretchy="false" xref="S2.E3.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mrow id="S2.E3.m1.2.2.2" xref="S2.E3.m1.2.2.2.cmml"><msup id="S2.E3.m1.2.2.2.3" xref="S2.E3.m1.2.2.2.3.cmml"><mi id="S2.E3.m1.2.2.2.3.2" xref="S2.E3.m1.2.2.2.3.2.cmml">𝒛</mi><mo id="S2.E3.m1.2.2.2.3.3" xref="S2.E3.m1.2.2.2.3.3.cmml">⊤</mo></msup><mo id="S2.E3.m1.2.2.2.2" xref="S2.E3.m1.2.2.2.2.cmml">⁢</mo><mi class="ltx_mathvariant_bold-italic" id="S2.E3.m1.2.2.2.4" mathvariant="bold-italic" xref="S2.E3.m1.2.2.2.4.cmml">ϕ</mi><mo id="S2.E3.m1.2.2.2.2a" xref="S2.E3.m1.2.2.2.2.cmml">⁢</mo><mrow id="S2.E3.m1.2.2.2.1.1" xref="S2.E3.m1.2.2.2.1.1.1.cmml"><mo id="S2.E3.m1.2.2.2.1.1.2" stretchy="false" xref="S2.E3.m1.2.2.2.1.1.1.cmml">(</mo><msub id="S2.E3.m1.2.2.2.1.1.1" xref="S2.E3.m1.2.2.2.1.1.1.cmml"><mi id="S2.E3.m1.2.2.2.1.1.1.2" xref="S2.E3.m1.2.2.2.1.1.1.2.cmml">𝒒</mi><mi id="S2.E3.m1.2.2.2.1.1.1.3" xref="S2.E3.m1.2.2.2.1.1.1.3.cmml">i</mi></msub><mo id="S2.E3.m1.2.2.2.1.1.3" stretchy="false" xref="S2.E3.m1.2.2.2.1.1.1.cmml">)</mo></mrow></mrow></mfrac></mstyle></mrow><mo id="S2.E3.m1.3.3.1.2" xref="S2.E3.m1.3.3.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E3.m1.3b"><apply id="S2.E3.m1.3.3.1.1.cmml" xref="S2.E3.m1.3.3.1"><eq id="S2.E3.m1.3.3.1.1.1.cmml" xref="S2.E3.m1.3.3.1.1.1"></eq><csymbol cd="latexml" id="S2.E3.m1.3.3.1.1.2.cmml" xref="S2.E3.m1.3.3.1.1.2">absent</csymbol><apply id="S2.E3.m1.2.2.cmml" xref="S2.E3.m1.2.2"><divide id="S2.E3.m1.2.2.3.cmml" xref="S2.E3.m1.2.2"></divide><apply id="S2.E3.m1.1.1.1.cmml" xref="S2.E3.m1.1.1.1"><times id="S2.E3.m1.1.1.1.2.cmml" xref="S2.E3.m1.1.1.1.2"></times><apply id="S2.E3.m1.1.1.1.3.cmml" xref="S2.E3.m1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E3.m1.1.1.1.3.1.cmml" xref="S2.E3.m1.1.1.1.3">superscript</csymbol><ci id="S2.E3.m1.1.1.1.3.2.cmml" xref="S2.E3.m1.1.1.1.3.2">𝑺</ci><csymbol cd="latexml" id="S2.E3.m1.1.1.1.3.3.cmml" xref="S2.E3.m1.1.1.1.3.3">top</csymbol></apply><ci id="S2.E3.m1.1.1.1.4.cmml" xref="S2.E3.m1.1.1.1.4">bold-italic-ϕ</ci><apply id="S2.E3.m1.1.1.1.1.1.1.cmml" xref="S2.E3.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E3.m1.1.1.1.1.1.1.1.cmml" xref="S2.E3.m1.1.1.1.1.1">subscript</csymbol><ci id="S2.E3.m1.1.1.1.1.1.1.2.cmml" xref="S2.E3.m1.1.1.1.1.1.1.2">𝒒</ci><ci id="S2.E3.m1.1.1.1.1.1.1.3.cmml" xref="S2.E3.m1.1.1.1.1.1.1.3">𝑖</ci></apply></apply><apply id="S2.E3.m1.2.2.2.cmml" xref="S2.E3.m1.2.2.2"><times id="S2.E3.m1.2.2.2.2.cmml" xref="S2.E3.m1.2.2.2.2"></times><apply id="S2.E3.m1.2.2.2.3.cmml" xref="S2.E3.m1.2.2.2.3"><csymbol cd="ambiguous" id="S2.E3.m1.2.2.2.3.1.cmml" xref="S2.E3.m1.2.2.2.3">superscript</csymbol><ci id="S2.E3.m1.2.2.2.3.2.cmml" xref="S2.E3.m1.2.2.2.3.2">𝒛</ci><csymbol cd="latexml" id="S2.E3.m1.2.2.2.3.3.cmml" xref="S2.E3.m1.2.2.2.3.3">top</csymbol></apply><ci id="S2.E3.m1.2.2.2.4.cmml" xref="S2.E3.m1.2.2.2.4">bold-italic-ϕ</ci><apply id="S2.E3.m1.2.2.2.1.1.1.cmml" xref="S2.E3.m1.2.2.2.1.1"><csymbol cd="ambiguous" id="S2.E3.m1.2.2.2.1.1.1.1.cmml" xref="S2.E3.m1.2.2.2.1.1">subscript</csymbol><ci id="S2.E3.m1.2.2.2.1.1.1.2.cmml" xref="S2.E3.m1.2.2.2.1.1.1.2">𝒒</ci><ci id="S2.E3.m1.2.2.2.1.1.1.3.cmml" xref="S2.E3.m1.2.2.2.1.1.1.3">𝑖</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E3.m1.3c">\displaystyle=\frac{\bm{S}^{\top}\bm{\phi}(\bm{q}_{i})}{\bm{z}^{\top}\bm{\phi}%
(\bm{q}_{i})},</annotation><annotation encoding="application/x-llamapun" id="S2.E3.m1.3d">= divide start_ARG bold_italic_S start_POSTSUPERSCRIPT ⊤ end_POSTSUPERSCRIPT bold_italic_ϕ ( bold_italic_q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) end_ARG start_ARG bold_italic_z start_POSTSUPERSCRIPT ⊤ end_POSTSUPERSCRIPT bold_italic_ϕ ( bold_italic_q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) end_ARG ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S2.SS2.p1.11">where <math alttext="\bm{S}=\sum_{j=1}^{n}\bm{\phi}(\bm{k}_{j})\bm{v}_{j}^{\top}\in\mathbb{R}^{r%
\times d}" class="ltx_Math" display="inline" id="S2.SS2.p1.8.m1.1"><semantics id="S2.SS2.p1.8.m1.1a"><mrow id="S2.SS2.p1.8.m1.1.1" xref="S2.SS2.p1.8.m1.1.1.cmml"><mi id="S2.SS2.p1.8.m1.1.1.3" xref="S2.SS2.p1.8.m1.1.1.3.cmml">𝑺</mi><mo id="S2.SS2.p1.8.m1.1.1.4" rspace="0.111em" xref="S2.SS2.p1.8.m1.1.1.4.cmml">=</mo><mrow id="S2.SS2.p1.8.m1.1.1.1" xref="S2.SS2.p1.8.m1.1.1.1.cmml"><msubsup id="S2.SS2.p1.8.m1.1.1.1.2" xref="S2.SS2.p1.8.m1.1.1.1.2.cmml"><mo id="S2.SS2.p1.8.m1.1.1.1.2.2.2" xref="S2.SS2.p1.8.m1.1.1.1.2.2.2.cmml">∑</mo><mrow id="S2.SS2.p1.8.m1.1.1.1.2.2.3" xref="S2.SS2.p1.8.m1.1.1.1.2.2.3.cmml"><mi id="S2.SS2.p1.8.m1.1.1.1.2.2.3.2" xref="S2.SS2.p1.8.m1.1.1.1.2.2.3.2.cmml">j</mi><mo id="S2.SS2.p1.8.m1.1.1.1.2.2.3.1" xref="S2.SS2.p1.8.m1.1.1.1.2.2.3.1.cmml">=</mo><mn id="S2.SS2.p1.8.m1.1.1.1.2.2.3.3" xref="S2.SS2.p1.8.m1.1.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S2.SS2.p1.8.m1.1.1.1.2.3" xref="S2.SS2.p1.8.m1.1.1.1.2.3.cmml">n</mi></msubsup><mrow id="S2.SS2.p1.8.m1.1.1.1.1" xref="S2.SS2.p1.8.m1.1.1.1.1.cmml"><mi class="ltx_mathvariant_bold-italic" id="S2.SS2.p1.8.m1.1.1.1.1.3" mathvariant="bold-italic" xref="S2.SS2.p1.8.m1.1.1.1.1.3.cmml">ϕ</mi><mo id="S2.SS2.p1.8.m1.1.1.1.1.2" xref="S2.SS2.p1.8.m1.1.1.1.1.2.cmml">⁢</mo><mrow id="S2.SS2.p1.8.m1.1.1.1.1.1.1" xref="S2.SS2.p1.8.m1.1.1.1.1.1.1.1.cmml"><mo id="S2.SS2.p1.8.m1.1.1.1.1.1.1.2" stretchy="false" xref="S2.SS2.p1.8.m1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S2.SS2.p1.8.m1.1.1.1.1.1.1.1" xref="S2.SS2.p1.8.m1.1.1.1.1.1.1.1.cmml"><mi id="S2.SS2.p1.8.m1.1.1.1.1.1.1.1.2" xref="S2.SS2.p1.8.m1.1.1.1.1.1.1.1.2.cmml">𝒌</mi><mi id="S2.SS2.p1.8.m1.1.1.1.1.1.1.1.3" xref="S2.SS2.p1.8.m1.1.1.1.1.1.1.1.3.cmml">j</mi></msub><mo id="S2.SS2.p1.8.m1.1.1.1.1.1.1.3" stretchy="false" xref="S2.SS2.p1.8.m1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="S2.SS2.p1.8.m1.1.1.1.1.2a" xref="S2.SS2.p1.8.m1.1.1.1.1.2.cmml">⁢</mo><msubsup id="S2.SS2.p1.8.m1.1.1.1.1.4" xref="S2.SS2.p1.8.m1.1.1.1.1.4.cmml"><mi id="S2.SS2.p1.8.m1.1.1.1.1.4.2.2" xref="S2.SS2.p1.8.m1.1.1.1.1.4.2.2.cmml">𝒗</mi><mi id="S2.SS2.p1.8.m1.1.1.1.1.4.2.3" xref="S2.SS2.p1.8.m1.1.1.1.1.4.2.3.cmml">j</mi><mo id="S2.SS2.p1.8.m1.1.1.1.1.4.3" xref="S2.SS2.p1.8.m1.1.1.1.1.4.3.cmml">⊤</mo></msubsup></mrow></mrow><mo id="S2.SS2.p1.8.m1.1.1.5" xref="S2.SS2.p1.8.m1.1.1.5.cmml">∈</mo><msup id="S2.SS2.p1.8.m1.1.1.6" xref="S2.SS2.p1.8.m1.1.1.6.cmml"><mi id="S2.SS2.p1.8.m1.1.1.6.2" xref="S2.SS2.p1.8.m1.1.1.6.2.cmml">ℝ</mi><mrow id="S2.SS2.p1.8.m1.1.1.6.3" xref="S2.SS2.p1.8.m1.1.1.6.3.cmml"><mi id="S2.SS2.p1.8.m1.1.1.6.3.2" xref="S2.SS2.p1.8.m1.1.1.6.3.2.cmml">r</mi><mo id="S2.SS2.p1.8.m1.1.1.6.3.1" lspace="0.222em" rspace="0.222em" xref="S2.SS2.p1.8.m1.1.1.6.3.1.cmml">×</mo><mi id="S2.SS2.p1.8.m1.1.1.6.3.3" xref="S2.SS2.p1.8.m1.1.1.6.3.3.cmml">d</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.8.m1.1b"><apply id="S2.SS2.p1.8.m1.1.1.cmml" xref="S2.SS2.p1.8.m1.1.1"><and id="S2.SS2.p1.8.m1.1.1a.cmml" xref="S2.SS2.p1.8.m1.1.1"></and><apply id="S2.SS2.p1.8.m1.1.1b.cmml" xref="S2.SS2.p1.8.m1.1.1"><eq id="S2.SS2.p1.8.m1.1.1.4.cmml" xref="S2.SS2.p1.8.m1.1.1.4"></eq><ci id="S2.SS2.p1.8.m1.1.1.3.cmml" xref="S2.SS2.p1.8.m1.1.1.3">𝑺</ci><apply id="S2.SS2.p1.8.m1.1.1.1.cmml" xref="S2.SS2.p1.8.m1.1.1.1"><apply id="S2.SS2.p1.8.m1.1.1.1.2.cmml" xref="S2.SS2.p1.8.m1.1.1.1.2"><csymbol cd="ambiguous" id="S2.SS2.p1.8.m1.1.1.1.2.1.cmml" xref="S2.SS2.p1.8.m1.1.1.1.2">superscript</csymbol><apply id="S2.SS2.p1.8.m1.1.1.1.2.2.cmml" xref="S2.SS2.p1.8.m1.1.1.1.2"><csymbol cd="ambiguous" id="S2.SS2.p1.8.m1.1.1.1.2.2.1.cmml" xref="S2.SS2.p1.8.m1.1.1.1.2">subscript</csymbol><sum id="S2.SS2.p1.8.m1.1.1.1.2.2.2.cmml" xref="S2.SS2.p1.8.m1.1.1.1.2.2.2"></sum><apply id="S2.SS2.p1.8.m1.1.1.1.2.2.3.cmml" xref="S2.SS2.p1.8.m1.1.1.1.2.2.3"><eq id="S2.SS2.p1.8.m1.1.1.1.2.2.3.1.cmml" xref="S2.SS2.p1.8.m1.1.1.1.2.2.3.1"></eq><ci id="S2.SS2.p1.8.m1.1.1.1.2.2.3.2.cmml" xref="S2.SS2.p1.8.m1.1.1.1.2.2.3.2">𝑗</ci><cn id="S2.SS2.p1.8.m1.1.1.1.2.2.3.3.cmml" type="integer" xref="S2.SS2.p1.8.m1.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="S2.SS2.p1.8.m1.1.1.1.2.3.cmml" xref="S2.SS2.p1.8.m1.1.1.1.2.3">𝑛</ci></apply><apply id="S2.SS2.p1.8.m1.1.1.1.1.cmml" xref="S2.SS2.p1.8.m1.1.1.1.1"><times id="S2.SS2.p1.8.m1.1.1.1.1.2.cmml" xref="S2.SS2.p1.8.m1.1.1.1.1.2"></times><ci id="S2.SS2.p1.8.m1.1.1.1.1.3.cmml" xref="S2.SS2.p1.8.m1.1.1.1.1.3">bold-italic-ϕ</ci><apply id="S2.SS2.p1.8.m1.1.1.1.1.1.1.1.cmml" xref="S2.SS2.p1.8.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.8.m1.1.1.1.1.1.1.1.1.cmml" xref="S2.SS2.p1.8.m1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.SS2.p1.8.m1.1.1.1.1.1.1.1.2.cmml" xref="S2.SS2.p1.8.m1.1.1.1.1.1.1.1.2">𝒌</ci><ci id="S2.SS2.p1.8.m1.1.1.1.1.1.1.1.3.cmml" xref="S2.SS2.p1.8.m1.1.1.1.1.1.1.1.3">𝑗</ci></apply><apply id="S2.SS2.p1.8.m1.1.1.1.1.4.cmml" xref="S2.SS2.p1.8.m1.1.1.1.1.4"><csymbol cd="ambiguous" id="S2.SS2.p1.8.m1.1.1.1.1.4.1.cmml" xref="S2.SS2.p1.8.m1.1.1.1.1.4">superscript</csymbol><apply id="S2.SS2.p1.8.m1.1.1.1.1.4.2.cmml" xref="S2.SS2.p1.8.m1.1.1.1.1.4"><csymbol cd="ambiguous" id="S2.SS2.p1.8.m1.1.1.1.1.4.2.1.cmml" xref="S2.SS2.p1.8.m1.1.1.1.1.4">subscript</csymbol><ci id="S2.SS2.p1.8.m1.1.1.1.1.4.2.2.cmml" xref="S2.SS2.p1.8.m1.1.1.1.1.4.2.2">𝒗</ci><ci id="S2.SS2.p1.8.m1.1.1.1.1.4.2.3.cmml" xref="S2.SS2.p1.8.m1.1.1.1.1.4.2.3">𝑗</ci></apply><csymbol cd="latexml" id="S2.SS2.p1.8.m1.1.1.1.1.4.3.cmml" xref="S2.SS2.p1.8.m1.1.1.1.1.4.3">top</csymbol></apply></apply></apply></apply><apply id="S2.SS2.p1.8.m1.1.1c.cmml" xref="S2.SS2.p1.8.m1.1.1"><in id="S2.SS2.p1.8.m1.1.1.5.cmml" xref="S2.SS2.p1.8.m1.1.1.5"></in><share href="https://arxiv.org/html/2407.05489v1#S2.SS2.p1.8.m1.1.1.1.cmml" id="S2.SS2.p1.8.m1.1.1d.cmml" xref="S2.SS2.p1.8.m1.1.1"></share><apply id="S2.SS2.p1.8.m1.1.1.6.cmml" xref="S2.SS2.p1.8.m1.1.1.6"><csymbol cd="ambiguous" id="S2.SS2.p1.8.m1.1.1.6.1.cmml" xref="S2.SS2.p1.8.m1.1.1.6">superscript</csymbol><ci id="S2.SS2.p1.8.m1.1.1.6.2.cmml" xref="S2.SS2.p1.8.m1.1.1.6.2">ℝ</ci><apply id="S2.SS2.p1.8.m1.1.1.6.3.cmml" xref="S2.SS2.p1.8.m1.1.1.6.3"><times id="S2.SS2.p1.8.m1.1.1.6.3.1.cmml" xref="S2.SS2.p1.8.m1.1.1.6.3.1"></times><ci id="S2.SS2.p1.8.m1.1.1.6.3.2.cmml" xref="S2.SS2.p1.8.m1.1.1.6.3.2">𝑟</ci><ci id="S2.SS2.p1.8.m1.1.1.6.3.3.cmml" xref="S2.SS2.p1.8.m1.1.1.6.3.3">𝑑</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.8.m1.1c">\bm{S}=\sum_{j=1}^{n}\bm{\phi}(\bm{k}_{j})\bm{v}_{j}^{\top}\in\mathbb{R}^{r%
\times d}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p1.8.m1.1d">bold_italic_S = ∑ start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT bold_italic_ϕ ( bold_italic_k start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) bold_italic_v start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ⊤ end_POSTSUPERSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT italic_r × italic_d end_POSTSUPERSCRIPT</annotation></semantics></math> and <math alttext="\bm{z}=\sum_{j=1}^{n}\bm{\phi}(\bm{k}_{j})\in\mathbb{R}^{r}" class="ltx_Math" display="inline" id="S2.SS2.p1.9.m2.1"><semantics id="S2.SS2.p1.9.m2.1a"><mrow id="S2.SS2.p1.9.m2.1.1" xref="S2.SS2.p1.9.m2.1.1.cmml"><mi id="S2.SS2.p1.9.m2.1.1.3" xref="S2.SS2.p1.9.m2.1.1.3.cmml">𝒛</mi><mo id="S2.SS2.p1.9.m2.1.1.4" rspace="0.111em" xref="S2.SS2.p1.9.m2.1.1.4.cmml">=</mo><mrow id="S2.SS2.p1.9.m2.1.1.1" xref="S2.SS2.p1.9.m2.1.1.1.cmml"><msubsup id="S2.SS2.p1.9.m2.1.1.1.2" xref="S2.SS2.p1.9.m2.1.1.1.2.cmml"><mo id="S2.SS2.p1.9.m2.1.1.1.2.2.2" xref="S2.SS2.p1.9.m2.1.1.1.2.2.2.cmml">∑</mo><mrow id="S2.SS2.p1.9.m2.1.1.1.2.2.3" xref="S2.SS2.p1.9.m2.1.1.1.2.2.3.cmml"><mi id="S2.SS2.p1.9.m2.1.1.1.2.2.3.2" xref="S2.SS2.p1.9.m2.1.1.1.2.2.3.2.cmml">j</mi><mo id="S2.SS2.p1.9.m2.1.1.1.2.2.3.1" xref="S2.SS2.p1.9.m2.1.1.1.2.2.3.1.cmml">=</mo><mn id="S2.SS2.p1.9.m2.1.1.1.2.2.3.3" xref="S2.SS2.p1.9.m2.1.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S2.SS2.p1.9.m2.1.1.1.2.3" xref="S2.SS2.p1.9.m2.1.1.1.2.3.cmml">n</mi></msubsup><mrow id="S2.SS2.p1.9.m2.1.1.1.1" xref="S2.SS2.p1.9.m2.1.1.1.1.cmml"><mi class="ltx_mathvariant_bold-italic" id="S2.SS2.p1.9.m2.1.1.1.1.3" mathvariant="bold-italic" xref="S2.SS2.p1.9.m2.1.1.1.1.3.cmml">ϕ</mi><mo id="S2.SS2.p1.9.m2.1.1.1.1.2" xref="S2.SS2.p1.9.m2.1.1.1.1.2.cmml">⁢</mo><mrow id="S2.SS2.p1.9.m2.1.1.1.1.1.1" xref="S2.SS2.p1.9.m2.1.1.1.1.1.1.1.cmml"><mo id="S2.SS2.p1.9.m2.1.1.1.1.1.1.2" stretchy="false" xref="S2.SS2.p1.9.m2.1.1.1.1.1.1.1.cmml">(</mo><msub id="S2.SS2.p1.9.m2.1.1.1.1.1.1.1" xref="S2.SS2.p1.9.m2.1.1.1.1.1.1.1.cmml"><mi id="S2.SS2.p1.9.m2.1.1.1.1.1.1.1.2" xref="S2.SS2.p1.9.m2.1.1.1.1.1.1.1.2.cmml">𝒌</mi><mi id="S2.SS2.p1.9.m2.1.1.1.1.1.1.1.3" xref="S2.SS2.p1.9.m2.1.1.1.1.1.1.1.3.cmml">j</mi></msub><mo id="S2.SS2.p1.9.m2.1.1.1.1.1.1.3" stretchy="false" xref="S2.SS2.p1.9.m2.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="S2.SS2.p1.9.m2.1.1.5" xref="S2.SS2.p1.9.m2.1.1.5.cmml">∈</mo><msup id="S2.SS2.p1.9.m2.1.1.6" xref="S2.SS2.p1.9.m2.1.1.6.cmml"><mi id="S2.SS2.p1.9.m2.1.1.6.2" xref="S2.SS2.p1.9.m2.1.1.6.2.cmml">ℝ</mi><mi id="S2.SS2.p1.9.m2.1.1.6.3" xref="S2.SS2.p1.9.m2.1.1.6.3.cmml">r</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.9.m2.1b"><apply id="S2.SS2.p1.9.m2.1.1.cmml" xref="S2.SS2.p1.9.m2.1.1"><and id="S2.SS2.p1.9.m2.1.1a.cmml" xref="S2.SS2.p1.9.m2.1.1"></and><apply id="S2.SS2.p1.9.m2.1.1b.cmml" xref="S2.SS2.p1.9.m2.1.1"><eq id="S2.SS2.p1.9.m2.1.1.4.cmml" xref="S2.SS2.p1.9.m2.1.1.4"></eq><ci id="S2.SS2.p1.9.m2.1.1.3.cmml" xref="S2.SS2.p1.9.m2.1.1.3">𝒛</ci><apply id="S2.SS2.p1.9.m2.1.1.1.cmml" xref="S2.SS2.p1.9.m2.1.1.1"><apply id="S2.SS2.p1.9.m2.1.1.1.2.cmml" xref="S2.SS2.p1.9.m2.1.1.1.2"><csymbol cd="ambiguous" id="S2.SS2.p1.9.m2.1.1.1.2.1.cmml" xref="S2.SS2.p1.9.m2.1.1.1.2">superscript</csymbol><apply id="S2.SS2.p1.9.m2.1.1.1.2.2.cmml" xref="S2.SS2.p1.9.m2.1.1.1.2"><csymbol cd="ambiguous" id="S2.SS2.p1.9.m2.1.1.1.2.2.1.cmml" xref="S2.SS2.p1.9.m2.1.1.1.2">subscript</csymbol><sum id="S2.SS2.p1.9.m2.1.1.1.2.2.2.cmml" xref="S2.SS2.p1.9.m2.1.1.1.2.2.2"></sum><apply id="S2.SS2.p1.9.m2.1.1.1.2.2.3.cmml" xref="S2.SS2.p1.9.m2.1.1.1.2.2.3"><eq id="S2.SS2.p1.9.m2.1.1.1.2.2.3.1.cmml" xref="S2.SS2.p1.9.m2.1.1.1.2.2.3.1"></eq><ci id="S2.SS2.p1.9.m2.1.1.1.2.2.3.2.cmml" xref="S2.SS2.p1.9.m2.1.1.1.2.2.3.2">𝑗</ci><cn id="S2.SS2.p1.9.m2.1.1.1.2.2.3.3.cmml" type="integer" xref="S2.SS2.p1.9.m2.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="S2.SS2.p1.9.m2.1.1.1.2.3.cmml" xref="S2.SS2.p1.9.m2.1.1.1.2.3">𝑛</ci></apply><apply id="S2.SS2.p1.9.m2.1.1.1.1.cmml" xref="S2.SS2.p1.9.m2.1.1.1.1"><times id="S2.SS2.p1.9.m2.1.1.1.1.2.cmml" xref="S2.SS2.p1.9.m2.1.1.1.1.2"></times><ci id="S2.SS2.p1.9.m2.1.1.1.1.3.cmml" xref="S2.SS2.p1.9.m2.1.1.1.1.3">bold-italic-ϕ</ci><apply id="S2.SS2.p1.9.m2.1.1.1.1.1.1.1.cmml" xref="S2.SS2.p1.9.m2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.9.m2.1.1.1.1.1.1.1.1.cmml" xref="S2.SS2.p1.9.m2.1.1.1.1.1.1">subscript</csymbol><ci id="S2.SS2.p1.9.m2.1.1.1.1.1.1.1.2.cmml" xref="S2.SS2.p1.9.m2.1.1.1.1.1.1.1.2">𝒌</ci><ci id="S2.SS2.p1.9.m2.1.1.1.1.1.1.1.3.cmml" xref="S2.SS2.p1.9.m2.1.1.1.1.1.1.1.3">𝑗</ci></apply></apply></apply></apply><apply id="S2.SS2.p1.9.m2.1.1c.cmml" xref="S2.SS2.p1.9.m2.1.1"><in id="S2.SS2.p1.9.m2.1.1.5.cmml" xref="S2.SS2.p1.9.m2.1.1.5"></in><share href="https://arxiv.org/html/2407.05489v1#S2.SS2.p1.9.m2.1.1.1.cmml" id="S2.SS2.p1.9.m2.1.1d.cmml" xref="S2.SS2.p1.9.m2.1.1"></share><apply id="S2.SS2.p1.9.m2.1.1.6.cmml" xref="S2.SS2.p1.9.m2.1.1.6"><csymbol cd="ambiguous" id="S2.SS2.p1.9.m2.1.1.6.1.cmml" xref="S2.SS2.p1.9.m2.1.1.6">superscript</csymbol><ci id="S2.SS2.p1.9.m2.1.1.6.2.cmml" xref="S2.SS2.p1.9.m2.1.1.6.2">ℝ</ci><ci id="S2.SS2.p1.9.m2.1.1.6.3.cmml" xref="S2.SS2.p1.9.m2.1.1.6.3">𝑟</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.9.m2.1c">\bm{z}=\sum_{j=1}^{n}\bm{\phi}(\bm{k}_{j})\in\mathbb{R}^{r}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p1.9.m2.1d">bold_italic_z = ∑ start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT bold_italic_ϕ ( bold_italic_k start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) ∈ blackboard_R start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT</annotation></semantics></math>.
Notably, if initial states are initialized as <math alttext="\bm{S}_{0}=\bm{0}_{r\times d}" class="ltx_Math" display="inline" id="S2.SS2.p1.10.m3.1"><semantics id="S2.SS2.p1.10.m3.1a"><mrow id="S2.SS2.p1.10.m3.1.1" xref="S2.SS2.p1.10.m3.1.1.cmml"><msub id="S2.SS2.p1.10.m3.1.1.2" xref="S2.SS2.p1.10.m3.1.1.2.cmml"><mi id="S2.SS2.p1.10.m3.1.1.2.2" xref="S2.SS2.p1.10.m3.1.1.2.2.cmml">𝑺</mi><mn id="S2.SS2.p1.10.m3.1.1.2.3" xref="S2.SS2.p1.10.m3.1.1.2.3.cmml">0</mn></msub><mo id="S2.SS2.p1.10.m3.1.1.1" xref="S2.SS2.p1.10.m3.1.1.1.cmml">=</mo><msub id="S2.SS2.p1.10.m3.1.1.3" xref="S2.SS2.p1.10.m3.1.1.3.cmml"><mn id="S2.SS2.p1.10.m3.1.1.3.2" xref="S2.SS2.p1.10.m3.1.1.3.2.cmml">𝟎</mn><mrow id="S2.SS2.p1.10.m3.1.1.3.3" xref="S2.SS2.p1.10.m3.1.1.3.3.cmml"><mi id="S2.SS2.p1.10.m3.1.1.3.3.2" xref="S2.SS2.p1.10.m3.1.1.3.3.2.cmml">r</mi><mo id="S2.SS2.p1.10.m3.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S2.SS2.p1.10.m3.1.1.3.3.1.cmml">×</mo><mi id="S2.SS2.p1.10.m3.1.1.3.3.3" xref="S2.SS2.p1.10.m3.1.1.3.3.3.cmml">d</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.10.m3.1b"><apply id="S2.SS2.p1.10.m3.1.1.cmml" xref="S2.SS2.p1.10.m3.1.1"><eq id="S2.SS2.p1.10.m3.1.1.1.cmml" xref="S2.SS2.p1.10.m3.1.1.1"></eq><apply id="S2.SS2.p1.10.m3.1.1.2.cmml" xref="S2.SS2.p1.10.m3.1.1.2"><csymbol cd="ambiguous" id="S2.SS2.p1.10.m3.1.1.2.1.cmml" xref="S2.SS2.p1.10.m3.1.1.2">subscript</csymbol><ci id="S2.SS2.p1.10.m3.1.1.2.2.cmml" xref="S2.SS2.p1.10.m3.1.1.2.2">𝑺</ci><cn id="S2.SS2.p1.10.m3.1.1.2.3.cmml" type="integer" xref="S2.SS2.p1.10.m3.1.1.2.3">0</cn></apply><apply id="S2.SS2.p1.10.m3.1.1.3.cmml" xref="S2.SS2.p1.10.m3.1.1.3"><csymbol cd="ambiguous" id="S2.SS2.p1.10.m3.1.1.3.1.cmml" xref="S2.SS2.p1.10.m3.1.1.3">subscript</csymbol><cn id="S2.SS2.p1.10.m3.1.1.3.2.cmml" type="integer" xref="S2.SS2.p1.10.m3.1.1.3.2">0</cn><apply id="S2.SS2.p1.10.m3.1.1.3.3.cmml" xref="S2.SS2.p1.10.m3.1.1.3.3"><times id="S2.SS2.p1.10.m3.1.1.3.3.1.cmml" xref="S2.SS2.p1.10.m3.1.1.3.3.1"></times><ci id="S2.SS2.p1.10.m3.1.1.3.3.2.cmml" xref="S2.SS2.p1.10.m3.1.1.3.3.2">𝑟</ci><ci id="S2.SS2.p1.10.m3.1.1.3.3.3.cmml" xref="S2.SS2.p1.10.m3.1.1.3.3.3">𝑑</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.10.m3.1c">\bm{S}_{0}=\bm{0}_{r\times d}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p1.10.m3.1d">bold_italic_S start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT = bold_0 start_POSTSUBSCRIPT italic_r × italic_d end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="\bm{z}_{0}=\bm{0}_{r}" class="ltx_Math" display="inline" id="S2.SS2.p1.11.m4.1"><semantics id="S2.SS2.p1.11.m4.1a"><mrow id="S2.SS2.p1.11.m4.1.1" xref="S2.SS2.p1.11.m4.1.1.cmml"><msub id="S2.SS2.p1.11.m4.1.1.2" xref="S2.SS2.p1.11.m4.1.1.2.cmml"><mi id="S2.SS2.p1.11.m4.1.1.2.2" xref="S2.SS2.p1.11.m4.1.1.2.2.cmml">𝒛</mi><mn id="S2.SS2.p1.11.m4.1.1.2.3" xref="S2.SS2.p1.11.m4.1.1.2.3.cmml">0</mn></msub><mo id="S2.SS2.p1.11.m4.1.1.1" xref="S2.SS2.p1.11.m4.1.1.1.cmml">=</mo><msub id="S2.SS2.p1.11.m4.1.1.3" xref="S2.SS2.p1.11.m4.1.1.3.cmml"><mn id="S2.SS2.p1.11.m4.1.1.3.2" xref="S2.SS2.p1.11.m4.1.1.3.2.cmml">𝟎</mn><mi id="S2.SS2.p1.11.m4.1.1.3.3" xref="S2.SS2.p1.11.m4.1.1.3.3.cmml">r</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.11.m4.1b"><apply id="S2.SS2.p1.11.m4.1.1.cmml" xref="S2.SS2.p1.11.m4.1.1"><eq id="S2.SS2.p1.11.m4.1.1.1.cmml" xref="S2.SS2.p1.11.m4.1.1.1"></eq><apply id="S2.SS2.p1.11.m4.1.1.2.cmml" xref="S2.SS2.p1.11.m4.1.1.2"><csymbol cd="ambiguous" id="S2.SS2.p1.11.m4.1.1.2.1.cmml" xref="S2.SS2.p1.11.m4.1.1.2">subscript</csymbol><ci id="S2.SS2.p1.11.m4.1.1.2.2.cmml" xref="S2.SS2.p1.11.m4.1.1.2.2">𝒛</ci><cn id="S2.SS2.p1.11.m4.1.1.2.3.cmml" type="integer" xref="S2.SS2.p1.11.m4.1.1.2.3">0</cn></apply><apply id="S2.SS2.p1.11.m4.1.1.3.cmml" xref="S2.SS2.p1.11.m4.1.1.3"><csymbol cd="ambiguous" id="S2.SS2.p1.11.m4.1.1.3.1.cmml" xref="S2.SS2.p1.11.m4.1.1.3">subscript</csymbol><cn id="S2.SS2.p1.11.m4.1.1.3.2.cmml" type="integer" xref="S2.SS2.p1.11.m4.1.1.3.2">0</cn><ci id="S2.SS2.p1.11.m4.1.1.3.3.cmml" xref="S2.SS2.p1.11.m4.1.1.3.3">𝑟</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.11.m4.1c">\bm{z}_{0}=\bm{0}_{r}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p1.11.m4.1d">bold_italic_z start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT = bold_0 start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT</annotation></semantics></math>, intermediate states can be computed in a recurrent fashion:</p>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="A5.EGx2">
<tbody id="S2.Ex3"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\bm{S}_{i}" class="ltx_Math" display="inline" id="S2.Ex3.m1.1"><semantics id="S2.Ex3.m1.1a"><msub id="S2.Ex3.m1.1.1" xref="S2.Ex3.m1.1.1.cmml"><mi id="S2.Ex3.m1.1.1.2" xref="S2.Ex3.m1.1.1.2.cmml">𝑺</mi><mi id="S2.Ex3.m1.1.1.3" xref="S2.Ex3.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.Ex3.m1.1b"><apply id="S2.Ex3.m1.1.1.cmml" xref="S2.Ex3.m1.1.1"><csymbol cd="ambiguous" id="S2.Ex3.m1.1.1.1.cmml" xref="S2.Ex3.m1.1.1">subscript</csymbol><ci id="S2.Ex3.m1.1.1.2.cmml" xref="S2.Ex3.m1.1.1.2">𝑺</ci><ci id="S2.Ex3.m1.1.1.3.cmml" xref="S2.Ex3.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex3.m1.1c">\displaystyle\bm{S}_{i}</annotation><annotation encoding="application/x-llamapun" id="S2.Ex3.m1.1d">bold_italic_S start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle=\bm{S}_{i-1}+\bm{\phi}(\bm{k}_{i})\bm{v}_{i}^{\top}," class="ltx_Math" display="inline" id="S2.Ex3.m2.1"><semantics id="S2.Ex3.m2.1a"><mrow id="S2.Ex3.m2.1.1.1" xref="S2.Ex3.m2.1.1.1.1.cmml"><mrow id="S2.Ex3.m2.1.1.1.1" xref="S2.Ex3.m2.1.1.1.1.cmml"><mi id="S2.Ex3.m2.1.1.1.1.3" xref="S2.Ex3.m2.1.1.1.1.3.cmml"></mi><mo id="S2.Ex3.m2.1.1.1.1.2" xref="S2.Ex3.m2.1.1.1.1.2.cmml">=</mo><mrow id="S2.Ex3.m2.1.1.1.1.1" xref="S2.Ex3.m2.1.1.1.1.1.cmml"><msub id="S2.Ex3.m2.1.1.1.1.1.3" xref="S2.Ex3.m2.1.1.1.1.1.3.cmml"><mi id="S2.Ex3.m2.1.1.1.1.1.3.2" xref="S2.Ex3.m2.1.1.1.1.1.3.2.cmml">𝑺</mi><mrow id="S2.Ex3.m2.1.1.1.1.1.3.3" xref="S2.Ex3.m2.1.1.1.1.1.3.3.cmml"><mi id="S2.Ex3.m2.1.1.1.1.1.3.3.2" xref="S2.Ex3.m2.1.1.1.1.1.3.3.2.cmml">i</mi><mo id="S2.Ex3.m2.1.1.1.1.1.3.3.1" xref="S2.Ex3.m2.1.1.1.1.1.3.3.1.cmml">−</mo><mn id="S2.Ex3.m2.1.1.1.1.1.3.3.3" xref="S2.Ex3.m2.1.1.1.1.1.3.3.3.cmml">1</mn></mrow></msub><mo id="S2.Ex3.m2.1.1.1.1.1.2" xref="S2.Ex3.m2.1.1.1.1.1.2.cmml">+</mo><mrow id="S2.Ex3.m2.1.1.1.1.1.1" xref="S2.Ex3.m2.1.1.1.1.1.1.cmml"><mi class="ltx_mathvariant_bold-italic" id="S2.Ex3.m2.1.1.1.1.1.1.3" mathvariant="bold-italic" xref="S2.Ex3.m2.1.1.1.1.1.1.3.cmml">ϕ</mi><mo id="S2.Ex3.m2.1.1.1.1.1.1.2" xref="S2.Ex3.m2.1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S2.Ex3.m2.1.1.1.1.1.1.1.1" xref="S2.Ex3.m2.1.1.1.1.1.1.1.1.1.cmml"><mo id="S2.Ex3.m2.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S2.Ex3.m2.1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S2.Ex3.m2.1.1.1.1.1.1.1.1.1" xref="S2.Ex3.m2.1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.Ex3.m2.1.1.1.1.1.1.1.1.1.2" xref="S2.Ex3.m2.1.1.1.1.1.1.1.1.1.2.cmml">𝒌</mi><mi id="S2.Ex3.m2.1.1.1.1.1.1.1.1.1.3" xref="S2.Ex3.m2.1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S2.Ex3.m2.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S2.Ex3.m2.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="S2.Ex3.m2.1.1.1.1.1.1.2a" xref="S2.Ex3.m2.1.1.1.1.1.1.2.cmml">⁢</mo><msubsup id="S2.Ex3.m2.1.1.1.1.1.1.4" xref="S2.Ex3.m2.1.1.1.1.1.1.4.cmml"><mi id="S2.Ex3.m2.1.1.1.1.1.1.4.2.2" xref="S2.Ex3.m2.1.1.1.1.1.1.4.2.2.cmml">𝒗</mi><mi id="S2.Ex3.m2.1.1.1.1.1.1.4.2.3" xref="S2.Ex3.m2.1.1.1.1.1.1.4.2.3.cmml">i</mi><mo id="S2.Ex3.m2.1.1.1.1.1.1.4.3" xref="S2.Ex3.m2.1.1.1.1.1.1.4.3.cmml">⊤</mo></msubsup></mrow></mrow></mrow><mo id="S2.Ex3.m2.1.1.1.2" xref="S2.Ex3.m2.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.Ex3.m2.1b"><apply id="S2.Ex3.m2.1.1.1.1.cmml" xref="S2.Ex3.m2.1.1.1"><eq id="S2.Ex3.m2.1.1.1.1.2.cmml" xref="S2.Ex3.m2.1.1.1.1.2"></eq><csymbol cd="latexml" id="S2.Ex3.m2.1.1.1.1.3.cmml" xref="S2.Ex3.m2.1.1.1.1.3">absent</csymbol><apply id="S2.Ex3.m2.1.1.1.1.1.cmml" xref="S2.Ex3.m2.1.1.1.1.1"><plus id="S2.Ex3.m2.1.1.1.1.1.2.cmml" xref="S2.Ex3.m2.1.1.1.1.1.2"></plus><apply id="S2.Ex3.m2.1.1.1.1.1.3.cmml" xref="S2.Ex3.m2.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.Ex3.m2.1.1.1.1.1.3.1.cmml" xref="S2.Ex3.m2.1.1.1.1.1.3">subscript</csymbol><ci id="S2.Ex3.m2.1.1.1.1.1.3.2.cmml" xref="S2.Ex3.m2.1.1.1.1.1.3.2">𝑺</ci><apply id="S2.Ex3.m2.1.1.1.1.1.3.3.cmml" xref="S2.Ex3.m2.1.1.1.1.1.3.3"><minus id="S2.Ex3.m2.1.1.1.1.1.3.3.1.cmml" xref="S2.Ex3.m2.1.1.1.1.1.3.3.1"></minus><ci id="S2.Ex3.m2.1.1.1.1.1.3.3.2.cmml" xref="S2.Ex3.m2.1.1.1.1.1.3.3.2">𝑖</ci><cn id="S2.Ex3.m2.1.1.1.1.1.3.3.3.cmml" type="integer" xref="S2.Ex3.m2.1.1.1.1.1.3.3.3">1</cn></apply></apply><apply id="S2.Ex3.m2.1.1.1.1.1.1.cmml" xref="S2.Ex3.m2.1.1.1.1.1.1"><times id="S2.Ex3.m2.1.1.1.1.1.1.2.cmml" xref="S2.Ex3.m2.1.1.1.1.1.1.2"></times><ci id="S2.Ex3.m2.1.1.1.1.1.1.3.cmml" xref="S2.Ex3.m2.1.1.1.1.1.1.3">bold-italic-ϕ</ci><apply id="S2.Ex3.m2.1.1.1.1.1.1.1.1.1.cmml" xref="S2.Ex3.m2.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.Ex3.m2.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.Ex3.m2.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.Ex3.m2.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.Ex3.m2.1.1.1.1.1.1.1.1.1.2">𝒌</ci><ci id="S2.Ex3.m2.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.Ex3.m2.1.1.1.1.1.1.1.1.1.3">𝑖</ci></apply><apply id="S2.Ex3.m2.1.1.1.1.1.1.4.cmml" xref="S2.Ex3.m2.1.1.1.1.1.1.4"><csymbol cd="ambiguous" id="S2.Ex3.m2.1.1.1.1.1.1.4.1.cmml" xref="S2.Ex3.m2.1.1.1.1.1.1.4">superscript</csymbol><apply id="S2.Ex3.m2.1.1.1.1.1.1.4.2.cmml" xref="S2.Ex3.m2.1.1.1.1.1.1.4"><csymbol cd="ambiguous" id="S2.Ex3.m2.1.1.1.1.1.1.4.2.1.cmml" xref="S2.Ex3.m2.1.1.1.1.1.1.4">subscript</csymbol><ci id="S2.Ex3.m2.1.1.1.1.1.1.4.2.2.cmml" xref="S2.Ex3.m2.1.1.1.1.1.1.4.2.2">𝒗</ci><ci id="S2.Ex3.m2.1.1.1.1.1.1.4.2.3.cmml" xref="S2.Ex3.m2.1.1.1.1.1.1.4.2.3">𝑖</ci></apply><csymbol cd="latexml" id="S2.Ex3.m2.1.1.1.1.1.1.4.3.cmml" xref="S2.Ex3.m2.1.1.1.1.1.1.4.3">top</csymbol></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex3.m2.1c">\displaystyle=\bm{S}_{i-1}+\bm{\phi}(\bm{k}_{i})\bm{v}_{i}^{\top},</annotation><annotation encoding="application/x-llamapun" id="S2.Ex3.m2.1d">= bold_italic_S start_POSTSUBSCRIPT italic_i - 1 end_POSTSUBSCRIPT + bold_italic_ϕ ( bold_italic_k start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) bold_italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ⊤ end_POSTSUPERSCRIPT ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="S2.E4"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\bm{z}_{i}" class="ltx_Math" display="inline" id="S2.E4.m1.1"><semantics id="S2.E4.m1.1a"><msub id="S2.E4.m1.1.1" xref="S2.E4.m1.1.1.cmml"><mi id="S2.E4.m1.1.1.2" xref="S2.E4.m1.1.1.2.cmml">𝒛</mi><mi id="S2.E4.m1.1.1.3" xref="S2.E4.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.E4.m1.1b"><apply id="S2.E4.m1.1.1.cmml" xref="S2.E4.m1.1.1"><csymbol cd="ambiguous" id="S2.E4.m1.1.1.1.cmml" xref="S2.E4.m1.1.1">subscript</csymbol><ci id="S2.E4.m1.1.1.2.cmml" xref="S2.E4.m1.1.1.2">𝒛</ci><ci id="S2.E4.m1.1.1.3.cmml" xref="S2.E4.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E4.m1.1c">\displaystyle\bm{z}_{i}</annotation><annotation encoding="application/x-llamapun" id="S2.E4.m1.1d">bold_italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle=\bm{z}_{i-1}+\bm{\phi}(\bm{k}_{i})." class="ltx_Math" display="inline" id="S2.E4.m2.1"><semantics id="S2.E4.m2.1a"><mrow id="S2.E4.m2.1.1.1" xref="S2.E4.m2.1.1.1.1.cmml"><mrow id="S2.E4.m2.1.1.1.1" xref="S2.E4.m2.1.1.1.1.cmml"><mi id="S2.E4.m2.1.1.1.1.3" xref="S2.E4.m2.1.1.1.1.3.cmml"></mi><mo id="S2.E4.m2.1.1.1.1.2" xref="S2.E4.m2.1.1.1.1.2.cmml">=</mo><mrow id="S2.E4.m2.1.1.1.1.1" xref="S2.E4.m2.1.1.1.1.1.cmml"><msub id="S2.E4.m2.1.1.1.1.1.3" xref="S2.E4.m2.1.1.1.1.1.3.cmml"><mi id="S2.E4.m2.1.1.1.1.1.3.2" xref="S2.E4.m2.1.1.1.1.1.3.2.cmml">𝒛</mi><mrow id="S2.E4.m2.1.1.1.1.1.3.3" xref="S2.E4.m2.1.1.1.1.1.3.3.cmml"><mi id="S2.E4.m2.1.1.1.1.1.3.3.2" xref="S2.E4.m2.1.1.1.1.1.3.3.2.cmml">i</mi><mo id="S2.E4.m2.1.1.1.1.1.3.3.1" xref="S2.E4.m2.1.1.1.1.1.3.3.1.cmml">−</mo><mn id="S2.E4.m2.1.1.1.1.1.3.3.3" xref="S2.E4.m2.1.1.1.1.1.3.3.3.cmml">1</mn></mrow></msub><mo id="S2.E4.m2.1.1.1.1.1.2" xref="S2.E4.m2.1.1.1.1.1.2.cmml">+</mo><mrow id="S2.E4.m2.1.1.1.1.1.1" xref="S2.E4.m2.1.1.1.1.1.1.cmml"><mi class="ltx_mathvariant_bold-italic" id="S2.E4.m2.1.1.1.1.1.1.3" mathvariant="bold-italic" xref="S2.E4.m2.1.1.1.1.1.1.3.cmml">ϕ</mi><mo id="S2.E4.m2.1.1.1.1.1.1.2" xref="S2.E4.m2.1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S2.E4.m2.1.1.1.1.1.1.1.1" xref="S2.E4.m2.1.1.1.1.1.1.1.1.1.cmml"><mo id="S2.E4.m2.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S2.E4.m2.1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S2.E4.m2.1.1.1.1.1.1.1.1.1" xref="S2.E4.m2.1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.E4.m2.1.1.1.1.1.1.1.1.1.2" xref="S2.E4.m2.1.1.1.1.1.1.1.1.1.2.cmml">𝒌</mi><mi id="S2.E4.m2.1.1.1.1.1.1.1.1.1.3" xref="S2.E4.m2.1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S2.E4.m2.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S2.E4.m2.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S2.E4.m2.1.1.1.2" lspace="0em" xref="S2.E4.m2.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E4.m2.1b"><apply id="S2.E4.m2.1.1.1.1.cmml" xref="S2.E4.m2.1.1.1"><eq id="S2.E4.m2.1.1.1.1.2.cmml" xref="S2.E4.m2.1.1.1.1.2"></eq><csymbol cd="latexml" id="S2.E4.m2.1.1.1.1.3.cmml" xref="S2.E4.m2.1.1.1.1.3">absent</csymbol><apply id="S2.E4.m2.1.1.1.1.1.cmml" xref="S2.E4.m2.1.1.1.1.1"><plus id="S2.E4.m2.1.1.1.1.1.2.cmml" xref="S2.E4.m2.1.1.1.1.1.2"></plus><apply id="S2.E4.m2.1.1.1.1.1.3.cmml" xref="S2.E4.m2.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E4.m2.1.1.1.1.1.3.1.cmml" xref="S2.E4.m2.1.1.1.1.1.3">subscript</csymbol><ci id="S2.E4.m2.1.1.1.1.1.3.2.cmml" xref="S2.E4.m2.1.1.1.1.1.3.2">𝒛</ci><apply id="S2.E4.m2.1.1.1.1.1.3.3.cmml" xref="S2.E4.m2.1.1.1.1.1.3.3"><minus id="S2.E4.m2.1.1.1.1.1.3.3.1.cmml" xref="S2.E4.m2.1.1.1.1.1.3.3.1"></minus><ci id="S2.E4.m2.1.1.1.1.1.3.3.2.cmml" xref="S2.E4.m2.1.1.1.1.1.3.3.2">𝑖</ci><cn id="S2.E4.m2.1.1.1.1.1.3.3.3.cmml" type="integer" xref="S2.E4.m2.1.1.1.1.1.3.3.3">1</cn></apply></apply><apply id="S2.E4.m2.1.1.1.1.1.1.cmml" xref="S2.E4.m2.1.1.1.1.1.1"><times id="S2.E4.m2.1.1.1.1.1.1.2.cmml" xref="S2.E4.m2.1.1.1.1.1.1.2"></times><ci id="S2.E4.m2.1.1.1.1.1.1.3.cmml" xref="S2.E4.m2.1.1.1.1.1.1.3">bold-italic-ϕ</ci><apply id="S2.E4.m2.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E4.m2.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E4.m2.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E4.m2.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.E4.m2.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E4.m2.1.1.1.1.1.1.1.1.1.2">𝒌</ci><ci id="S2.E4.m2.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E4.m2.1.1.1.1.1.1.1.1.1.3">𝑖</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E4.m2.1c">\displaystyle=\bm{z}_{i-1}+\bm{\phi}(\bm{k}_{i}).</annotation><annotation encoding="application/x-llamapun" id="S2.E4.m2.1d">= bold_italic_z start_POSTSUBSCRIPT italic_i - 1 end_POSTSUBSCRIPT + bold_italic_ϕ ( bold_italic_k start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) .</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S2.SS2.p1.15">Since we can reuse the same <math alttext="\bm{S}_{i}" class="ltx_Math" display="inline" id="S2.SS2.p1.12.m1.1"><semantics id="S2.SS2.p1.12.m1.1a"><msub id="S2.SS2.p1.12.m1.1.1" xref="S2.SS2.p1.12.m1.1.1.cmml"><mi id="S2.SS2.p1.12.m1.1.1.2" xref="S2.SS2.p1.12.m1.1.1.2.cmml">𝑺</mi><mi id="S2.SS2.p1.12.m1.1.1.3" xref="S2.SS2.p1.12.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.12.m1.1b"><apply id="S2.SS2.p1.12.m1.1.1.cmml" xref="S2.SS2.p1.12.m1.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.12.m1.1.1.1.cmml" xref="S2.SS2.p1.12.m1.1.1">subscript</csymbol><ci id="S2.SS2.p1.12.m1.1.1.2.cmml" xref="S2.SS2.p1.12.m1.1.1.2">𝑺</ci><ci id="S2.SS2.p1.12.m1.1.1.3.cmml" xref="S2.SS2.p1.12.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.12.m1.1c">\bm{S}_{i}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p1.12.m1.1d">bold_italic_S start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="\bm{z}_{i}" class="ltx_Math" display="inline" id="S2.SS2.p1.13.m2.1"><semantics id="S2.SS2.p1.13.m2.1a"><msub id="S2.SS2.p1.13.m2.1.1" xref="S2.SS2.p1.13.m2.1.1.cmml"><mi id="S2.SS2.p1.13.m2.1.1.2" xref="S2.SS2.p1.13.m2.1.1.2.cmml">𝒛</mi><mi id="S2.SS2.p1.13.m2.1.1.3" xref="S2.SS2.p1.13.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.13.m2.1b"><apply id="S2.SS2.p1.13.m2.1.1.cmml" xref="S2.SS2.p1.13.m2.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.13.m2.1.1.1.cmml" xref="S2.SS2.p1.13.m2.1.1">subscript</csymbol><ci id="S2.SS2.p1.13.m2.1.1.2.cmml" xref="S2.SS2.p1.13.m2.1.1.2">𝒛</ci><ci id="S2.SS2.p1.13.m2.1.1.3.cmml" xref="S2.SS2.p1.13.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.13.m2.1c">\bm{z}_{i}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p1.13.m2.1d">bold_italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> for all queries, this recurrent variant offers a <math alttext="\mathcal{O}\left(n\right)" class="ltx_Math" display="inline" id="S2.SS2.p1.14.m3.1"><semantics id="S2.SS2.p1.14.m3.1a"><mrow id="S2.SS2.p1.14.m3.1.2" xref="S2.SS2.p1.14.m3.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p1.14.m3.1.2.2" xref="S2.SS2.p1.14.m3.1.2.2.cmml">𝒪</mi><mo id="S2.SS2.p1.14.m3.1.2.1" xref="S2.SS2.p1.14.m3.1.2.1.cmml">⁢</mo><mrow id="S2.SS2.p1.14.m3.1.2.3.2" xref="S2.SS2.p1.14.m3.1.2.cmml"><mo id="S2.SS2.p1.14.m3.1.2.3.2.1" xref="S2.SS2.p1.14.m3.1.2.cmml">(</mo><mi id="S2.SS2.p1.14.m3.1.1" xref="S2.SS2.p1.14.m3.1.1.cmml">n</mi><mo id="S2.SS2.p1.14.m3.1.2.3.2.2" xref="S2.SS2.p1.14.m3.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.14.m3.1b"><apply id="S2.SS2.p1.14.m3.1.2.cmml" xref="S2.SS2.p1.14.m3.1.2"><times id="S2.SS2.p1.14.m3.1.2.1.cmml" xref="S2.SS2.p1.14.m3.1.2.1"></times><ci id="S2.SS2.p1.14.m3.1.2.2.cmml" xref="S2.SS2.p1.14.m3.1.2.2">𝒪</ci><ci id="S2.SS2.p1.14.m3.1.1.cmml" xref="S2.SS2.p1.14.m3.1.1">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.14.m3.1c">\mathcal{O}\left(n\right)</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p1.14.m3.1d">caligraphic_O ( italic_n )</annotation></semantics></math> complexity during training and enjoys a <math alttext="\mathcal{O}\left(1\right)" class="ltx_Math" display="inline" id="S2.SS2.p1.15.m4.1"><semantics id="S2.SS2.p1.15.m4.1a"><mrow id="S2.SS2.p1.15.m4.1.2" xref="S2.SS2.p1.15.m4.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p1.15.m4.1.2.2" xref="S2.SS2.p1.15.m4.1.2.2.cmml">𝒪</mi><mo id="S2.SS2.p1.15.m4.1.2.1" xref="S2.SS2.p1.15.m4.1.2.1.cmml">⁢</mo><mrow id="S2.SS2.p1.15.m4.1.2.3.2" xref="S2.SS2.p1.15.m4.1.2.cmml"><mo id="S2.SS2.p1.15.m4.1.2.3.2.1" xref="S2.SS2.p1.15.m4.1.2.cmml">(</mo><mn id="S2.SS2.p1.15.m4.1.1" xref="S2.SS2.p1.15.m4.1.1.cmml">1</mn><mo id="S2.SS2.p1.15.m4.1.2.3.2.2" xref="S2.SS2.p1.15.m4.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.15.m4.1b"><apply id="S2.SS2.p1.15.m4.1.2.cmml" xref="S2.SS2.p1.15.m4.1.2"><times id="S2.SS2.p1.15.m4.1.2.1.cmml" xref="S2.SS2.p1.15.m4.1.2.1"></times><ci id="S2.SS2.p1.15.m4.1.2.2.cmml" xref="S2.SS2.p1.15.m4.1.2.2">𝒪</ci><cn id="S2.SS2.p1.15.m4.1.1.cmml" type="integer" xref="S2.SS2.p1.15.m4.1.1">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.15.m4.1c">\mathcal{O}\left(1\right)</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p1.15.m4.1d">caligraphic_O ( 1 )</annotation></semantics></math> complexity for inference.<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>In practice, however, this recurrent view is not parallelizable, leading to chunkwise-recurrent variations for training <cite class="ltx_cite ltx_citemacro_citep">(Hua et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib23" title="">2022</a>; Sun et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib38" title="">2023a</a>; Yang et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib46" title="">2024</a>)</cite>.</span></span></span></p>
</div>
<section class="ltx_paragraph" id="S2.SS2.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Retentive Networks (RetNet).</h5>
<div class="ltx_para" id="S2.SS2.SSS0.Px1.p1">
<p class="ltx_p" id="S2.SS2.SSS0.Px1.p1.3"><cite class="ltx_cite ltx_citemacro_citet">Sun et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib38" title="">2023a</a>)</cite> set <math alttext="\bm{\phi}" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px1.p1.1.m1.1"><semantics id="S2.SS2.SSS0.Px1.p1.1.m1.1a"><mi class="ltx_mathvariant_bold-italic" id="S2.SS2.SSS0.Px1.p1.1.m1.1.1" mathvariant="bold-italic" xref="S2.SS2.SSS0.Px1.p1.1.m1.1.1.cmml">ϕ</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p1.1.m1.1b"><ci id="S2.SS2.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.1.m1.1.1">bold-italic-ϕ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p1.1.m1.1c">\bm{\phi}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px1.p1.1.m1.1d">bold_italic_ϕ</annotation></semantics></math> as the identity function, i.e., <math alttext="k(\bm{q},\bm{k})=\bm{q}^{\top}\bm{k}" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px1.p1.2.m2.2"><semantics id="S2.SS2.SSS0.Px1.p1.2.m2.2a"><mrow id="S2.SS2.SSS0.Px1.p1.2.m2.2.3" xref="S2.SS2.SSS0.Px1.p1.2.m2.2.3.cmml"><mrow id="S2.SS2.SSS0.Px1.p1.2.m2.2.3.2" xref="S2.SS2.SSS0.Px1.p1.2.m2.2.3.2.cmml"><mi id="S2.SS2.SSS0.Px1.p1.2.m2.2.3.2.2" xref="S2.SS2.SSS0.Px1.p1.2.m2.2.3.2.2.cmml">k</mi><mo id="S2.SS2.SSS0.Px1.p1.2.m2.2.3.2.1" xref="S2.SS2.SSS0.Px1.p1.2.m2.2.3.2.1.cmml">⁢</mo><mrow id="S2.SS2.SSS0.Px1.p1.2.m2.2.3.2.3.2" xref="S2.SS2.SSS0.Px1.p1.2.m2.2.3.2.3.1.cmml"><mo id="S2.SS2.SSS0.Px1.p1.2.m2.2.3.2.3.2.1" stretchy="false" xref="S2.SS2.SSS0.Px1.p1.2.m2.2.3.2.3.1.cmml">(</mo><mi id="S2.SS2.SSS0.Px1.p1.2.m2.1.1" xref="S2.SS2.SSS0.Px1.p1.2.m2.1.1.cmml">𝒒</mi><mo id="S2.SS2.SSS0.Px1.p1.2.m2.2.3.2.3.2.2" xref="S2.SS2.SSS0.Px1.p1.2.m2.2.3.2.3.1.cmml">,</mo><mi id="S2.SS2.SSS0.Px1.p1.2.m2.2.2" xref="S2.SS2.SSS0.Px1.p1.2.m2.2.2.cmml">𝒌</mi><mo id="S2.SS2.SSS0.Px1.p1.2.m2.2.3.2.3.2.3" stretchy="false" xref="S2.SS2.SSS0.Px1.p1.2.m2.2.3.2.3.1.cmml">)</mo></mrow></mrow><mo id="S2.SS2.SSS0.Px1.p1.2.m2.2.3.1" xref="S2.SS2.SSS0.Px1.p1.2.m2.2.3.1.cmml">=</mo><mrow id="S2.SS2.SSS0.Px1.p1.2.m2.2.3.3" xref="S2.SS2.SSS0.Px1.p1.2.m2.2.3.3.cmml"><msup id="S2.SS2.SSS0.Px1.p1.2.m2.2.3.3.2" xref="S2.SS2.SSS0.Px1.p1.2.m2.2.3.3.2.cmml"><mi id="S2.SS2.SSS0.Px1.p1.2.m2.2.3.3.2.2" xref="S2.SS2.SSS0.Px1.p1.2.m2.2.3.3.2.2.cmml">𝒒</mi><mo id="S2.SS2.SSS0.Px1.p1.2.m2.2.3.3.2.3" xref="S2.SS2.SSS0.Px1.p1.2.m2.2.3.3.2.3.cmml">⊤</mo></msup><mo id="S2.SS2.SSS0.Px1.p1.2.m2.2.3.3.1" xref="S2.SS2.SSS0.Px1.p1.2.m2.2.3.3.1.cmml">⁢</mo><mi id="S2.SS2.SSS0.Px1.p1.2.m2.2.3.3.3" xref="S2.SS2.SSS0.Px1.p1.2.m2.2.3.3.3.cmml">𝒌</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p1.2.m2.2b"><apply id="S2.SS2.SSS0.Px1.p1.2.m2.2.3.cmml" xref="S2.SS2.SSS0.Px1.p1.2.m2.2.3"><eq id="S2.SS2.SSS0.Px1.p1.2.m2.2.3.1.cmml" xref="S2.SS2.SSS0.Px1.p1.2.m2.2.3.1"></eq><apply id="S2.SS2.SSS0.Px1.p1.2.m2.2.3.2.cmml" xref="S2.SS2.SSS0.Px1.p1.2.m2.2.3.2"><times id="S2.SS2.SSS0.Px1.p1.2.m2.2.3.2.1.cmml" xref="S2.SS2.SSS0.Px1.p1.2.m2.2.3.2.1"></times><ci id="S2.SS2.SSS0.Px1.p1.2.m2.2.3.2.2.cmml" xref="S2.SS2.SSS0.Px1.p1.2.m2.2.3.2.2">𝑘</ci><interval closure="open" id="S2.SS2.SSS0.Px1.p1.2.m2.2.3.2.3.1.cmml" xref="S2.SS2.SSS0.Px1.p1.2.m2.2.3.2.3.2"><ci id="S2.SS2.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.2.m2.1.1">𝒒</ci><ci id="S2.SS2.SSS0.Px1.p1.2.m2.2.2.cmml" xref="S2.SS2.SSS0.Px1.p1.2.m2.2.2">𝒌</ci></interval></apply><apply id="S2.SS2.SSS0.Px1.p1.2.m2.2.3.3.cmml" xref="S2.SS2.SSS0.Px1.p1.2.m2.2.3.3"><times id="S2.SS2.SSS0.Px1.p1.2.m2.2.3.3.1.cmml" xref="S2.SS2.SSS0.Px1.p1.2.m2.2.3.3.1"></times><apply id="S2.SS2.SSS0.Px1.p1.2.m2.2.3.3.2.cmml" xref="S2.SS2.SSS0.Px1.p1.2.m2.2.3.3.2"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px1.p1.2.m2.2.3.3.2.1.cmml" xref="S2.SS2.SSS0.Px1.p1.2.m2.2.3.3.2">superscript</csymbol><ci id="S2.SS2.SSS0.Px1.p1.2.m2.2.3.3.2.2.cmml" xref="S2.SS2.SSS0.Px1.p1.2.m2.2.3.3.2.2">𝒒</ci><csymbol cd="latexml" id="S2.SS2.SSS0.Px1.p1.2.m2.2.3.3.2.3.cmml" xref="S2.SS2.SSS0.Px1.p1.2.m2.2.3.3.2.3">top</csymbol></apply><ci id="S2.SS2.SSS0.Px1.p1.2.m2.2.3.3.3.cmml" xref="S2.SS2.SSS0.Px1.p1.2.m2.2.3.3.3">𝒌</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p1.2.m2.2c">k(\bm{q},\bm{k})=\bm{q}^{\top}\bm{k}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px1.p1.2.m2.2d">italic_k ( bold_italic_q , bold_italic_k ) = bold_italic_q start_POSTSUPERSCRIPT ⊤ end_POSTSUPERSCRIPT bold_italic_k</annotation></semantics></math>, ignore the normalizer in Equation <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#S2.E2" title="In 2.2 Linear Attention ‣ 2 Background ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_tag">2</span></a>, and introduce an exponential decay mask <math alttext="\gamma" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px1.p1.3.m3.1"><semantics id="S2.SS2.SSS0.Px1.p1.3.m3.1a"><mi id="S2.SS2.SSS0.Px1.p1.3.m3.1.1" xref="S2.SS2.SSS0.Px1.p1.3.m3.1.1.cmml">γ</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p1.3.m3.1b"><ci id="S2.SS2.SSS0.Px1.p1.3.m3.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.3.m3.1.1">𝛾</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p1.3.m3.1c">\gamma</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px1.p1.3.m3.1d">italic_γ</annotation></semantics></math>, leading to:</p>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="A5.EGx3">
<tbody id="S2.Ex4"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\bm{S}_{i}" class="ltx_Math" display="inline" id="S2.Ex4.m1.1"><semantics id="S2.Ex4.m1.1a"><msub id="S2.Ex4.m1.1.1" xref="S2.Ex4.m1.1.1.cmml"><mi id="S2.Ex4.m1.1.1.2" xref="S2.Ex4.m1.1.1.2.cmml">𝑺</mi><mi id="S2.Ex4.m1.1.1.3" xref="S2.Ex4.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.Ex4.m1.1b"><apply id="S2.Ex4.m1.1.1.cmml" xref="S2.Ex4.m1.1.1"><csymbol cd="ambiguous" id="S2.Ex4.m1.1.1.1.cmml" xref="S2.Ex4.m1.1.1">subscript</csymbol><ci id="S2.Ex4.m1.1.1.2.cmml" xref="S2.Ex4.m1.1.1.2">𝑺</ci><ci id="S2.Ex4.m1.1.1.3.cmml" xref="S2.Ex4.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex4.m1.1c">\displaystyle\bm{S}_{i}</annotation><annotation encoding="application/x-llamapun" id="S2.Ex4.m1.1d">bold_italic_S start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle=\gamma\bm{S}_{i-1}+\bm{k}_{i}\bm{v}_{i}^{\top}," class="ltx_Math" display="inline" id="S2.Ex4.m2.1"><semantics id="S2.Ex4.m2.1a"><mrow id="S2.Ex4.m2.1.1.1" xref="S2.Ex4.m2.1.1.1.1.cmml"><mrow id="S2.Ex4.m2.1.1.1.1" xref="S2.Ex4.m2.1.1.1.1.cmml"><mi id="S2.Ex4.m2.1.1.1.1.2" xref="S2.Ex4.m2.1.1.1.1.2.cmml"></mi><mo id="S2.Ex4.m2.1.1.1.1.1" xref="S2.Ex4.m2.1.1.1.1.1.cmml">=</mo><mrow id="S2.Ex4.m2.1.1.1.1.3" xref="S2.Ex4.m2.1.1.1.1.3.cmml"><mrow id="S2.Ex4.m2.1.1.1.1.3.2" xref="S2.Ex4.m2.1.1.1.1.3.2.cmml"><mi id="S2.Ex4.m2.1.1.1.1.3.2.2" xref="S2.Ex4.m2.1.1.1.1.3.2.2.cmml">γ</mi><mo id="S2.Ex4.m2.1.1.1.1.3.2.1" xref="S2.Ex4.m2.1.1.1.1.3.2.1.cmml">⁢</mo><msub id="S2.Ex4.m2.1.1.1.1.3.2.3" xref="S2.Ex4.m2.1.1.1.1.3.2.3.cmml"><mi id="S2.Ex4.m2.1.1.1.1.3.2.3.2" xref="S2.Ex4.m2.1.1.1.1.3.2.3.2.cmml">𝑺</mi><mrow id="S2.Ex4.m2.1.1.1.1.3.2.3.3" xref="S2.Ex4.m2.1.1.1.1.3.2.3.3.cmml"><mi id="S2.Ex4.m2.1.1.1.1.3.2.3.3.2" xref="S2.Ex4.m2.1.1.1.1.3.2.3.3.2.cmml">i</mi><mo id="S2.Ex4.m2.1.1.1.1.3.2.3.3.1" xref="S2.Ex4.m2.1.1.1.1.3.2.3.3.1.cmml">−</mo><mn id="S2.Ex4.m2.1.1.1.1.3.2.3.3.3" xref="S2.Ex4.m2.1.1.1.1.3.2.3.3.3.cmml">1</mn></mrow></msub></mrow><mo id="S2.Ex4.m2.1.1.1.1.3.1" xref="S2.Ex4.m2.1.1.1.1.3.1.cmml">+</mo><mrow id="S2.Ex4.m2.1.1.1.1.3.3" xref="S2.Ex4.m2.1.1.1.1.3.3.cmml"><msub id="S2.Ex4.m2.1.1.1.1.3.3.2" xref="S2.Ex4.m2.1.1.1.1.3.3.2.cmml"><mi id="S2.Ex4.m2.1.1.1.1.3.3.2.2" xref="S2.Ex4.m2.1.1.1.1.3.3.2.2.cmml">𝒌</mi><mi id="S2.Ex4.m2.1.1.1.1.3.3.2.3" xref="S2.Ex4.m2.1.1.1.1.3.3.2.3.cmml">i</mi></msub><mo id="S2.Ex4.m2.1.1.1.1.3.3.1" xref="S2.Ex4.m2.1.1.1.1.3.3.1.cmml">⁢</mo><msubsup id="S2.Ex4.m2.1.1.1.1.3.3.3" xref="S2.Ex4.m2.1.1.1.1.3.3.3.cmml"><mi id="S2.Ex4.m2.1.1.1.1.3.3.3.2.2" xref="S2.Ex4.m2.1.1.1.1.3.3.3.2.2.cmml">𝒗</mi><mi id="S2.Ex4.m2.1.1.1.1.3.3.3.2.3" xref="S2.Ex4.m2.1.1.1.1.3.3.3.2.3.cmml">i</mi><mo id="S2.Ex4.m2.1.1.1.1.3.3.3.3" xref="S2.Ex4.m2.1.1.1.1.3.3.3.3.cmml">⊤</mo></msubsup></mrow></mrow></mrow><mo id="S2.Ex4.m2.1.1.1.2" xref="S2.Ex4.m2.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.Ex4.m2.1b"><apply id="S2.Ex4.m2.1.1.1.1.cmml" xref="S2.Ex4.m2.1.1.1"><eq id="S2.Ex4.m2.1.1.1.1.1.cmml" xref="S2.Ex4.m2.1.1.1.1.1"></eq><csymbol cd="latexml" id="S2.Ex4.m2.1.1.1.1.2.cmml" xref="S2.Ex4.m2.1.1.1.1.2">absent</csymbol><apply id="S2.Ex4.m2.1.1.1.1.3.cmml" xref="S2.Ex4.m2.1.1.1.1.3"><plus id="S2.Ex4.m2.1.1.1.1.3.1.cmml" xref="S2.Ex4.m2.1.1.1.1.3.1"></plus><apply id="S2.Ex4.m2.1.1.1.1.3.2.cmml" xref="S2.Ex4.m2.1.1.1.1.3.2"><times id="S2.Ex4.m2.1.1.1.1.3.2.1.cmml" xref="S2.Ex4.m2.1.1.1.1.3.2.1"></times><ci id="S2.Ex4.m2.1.1.1.1.3.2.2.cmml" xref="S2.Ex4.m2.1.1.1.1.3.2.2">𝛾</ci><apply id="S2.Ex4.m2.1.1.1.1.3.2.3.cmml" xref="S2.Ex4.m2.1.1.1.1.3.2.3"><csymbol cd="ambiguous" id="S2.Ex4.m2.1.1.1.1.3.2.3.1.cmml" xref="S2.Ex4.m2.1.1.1.1.3.2.3">subscript</csymbol><ci id="S2.Ex4.m2.1.1.1.1.3.2.3.2.cmml" xref="S2.Ex4.m2.1.1.1.1.3.2.3.2">𝑺</ci><apply id="S2.Ex4.m2.1.1.1.1.3.2.3.3.cmml" xref="S2.Ex4.m2.1.1.1.1.3.2.3.3"><minus id="S2.Ex4.m2.1.1.1.1.3.2.3.3.1.cmml" xref="S2.Ex4.m2.1.1.1.1.3.2.3.3.1"></minus><ci id="S2.Ex4.m2.1.1.1.1.3.2.3.3.2.cmml" xref="S2.Ex4.m2.1.1.1.1.3.2.3.3.2">𝑖</ci><cn id="S2.Ex4.m2.1.1.1.1.3.2.3.3.3.cmml" type="integer" xref="S2.Ex4.m2.1.1.1.1.3.2.3.3.3">1</cn></apply></apply></apply><apply id="S2.Ex4.m2.1.1.1.1.3.3.cmml" xref="S2.Ex4.m2.1.1.1.1.3.3"><times id="S2.Ex4.m2.1.1.1.1.3.3.1.cmml" xref="S2.Ex4.m2.1.1.1.1.3.3.1"></times><apply id="S2.Ex4.m2.1.1.1.1.3.3.2.cmml" xref="S2.Ex4.m2.1.1.1.1.3.3.2"><csymbol cd="ambiguous" id="S2.Ex4.m2.1.1.1.1.3.3.2.1.cmml" xref="S2.Ex4.m2.1.1.1.1.3.3.2">subscript</csymbol><ci id="S2.Ex4.m2.1.1.1.1.3.3.2.2.cmml" xref="S2.Ex4.m2.1.1.1.1.3.3.2.2">𝒌</ci><ci id="S2.Ex4.m2.1.1.1.1.3.3.2.3.cmml" xref="S2.Ex4.m2.1.1.1.1.3.3.2.3">𝑖</ci></apply><apply id="S2.Ex4.m2.1.1.1.1.3.3.3.cmml" xref="S2.Ex4.m2.1.1.1.1.3.3.3"><csymbol cd="ambiguous" id="S2.Ex4.m2.1.1.1.1.3.3.3.1.cmml" xref="S2.Ex4.m2.1.1.1.1.3.3.3">superscript</csymbol><apply id="S2.Ex4.m2.1.1.1.1.3.3.3.2.cmml" xref="S2.Ex4.m2.1.1.1.1.3.3.3"><csymbol cd="ambiguous" id="S2.Ex4.m2.1.1.1.1.3.3.3.2.1.cmml" xref="S2.Ex4.m2.1.1.1.1.3.3.3">subscript</csymbol><ci id="S2.Ex4.m2.1.1.1.1.3.3.3.2.2.cmml" xref="S2.Ex4.m2.1.1.1.1.3.3.3.2.2">𝒗</ci><ci id="S2.Ex4.m2.1.1.1.1.3.3.3.2.3.cmml" xref="S2.Ex4.m2.1.1.1.1.3.3.3.2.3">𝑖</ci></apply><csymbol cd="latexml" id="S2.Ex4.m2.1.1.1.1.3.3.3.3.cmml" xref="S2.Ex4.m2.1.1.1.1.3.3.3.3">top</csymbol></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex4.m2.1c">\displaystyle=\gamma\bm{S}_{i-1}+\bm{k}_{i}\bm{v}_{i}^{\top},</annotation><annotation encoding="application/x-llamapun" id="S2.Ex4.m2.1d">= italic_γ bold_italic_S start_POSTSUBSCRIPT italic_i - 1 end_POSTSUBSCRIPT + bold_italic_k start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT bold_italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ⊤ end_POSTSUPERSCRIPT ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="S2.E5"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\bm{y}_{i}" class="ltx_Math" display="inline" id="S2.E5.m1.1"><semantics id="S2.E5.m1.1a"><msub id="S2.E5.m1.1.1" xref="S2.E5.m1.1.1.cmml"><mi id="S2.E5.m1.1.1.2" xref="S2.E5.m1.1.1.2.cmml">𝒚</mi><mi id="S2.E5.m1.1.1.3" xref="S2.E5.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.E5.m1.1b"><apply id="S2.E5.m1.1.1.cmml" xref="S2.E5.m1.1.1"><csymbol cd="ambiguous" id="S2.E5.m1.1.1.1.cmml" xref="S2.E5.m1.1.1">subscript</csymbol><ci id="S2.E5.m1.1.1.2.cmml" xref="S2.E5.m1.1.1.2">𝒚</ci><ci id="S2.E5.m1.1.1.3.cmml" xref="S2.E5.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E5.m1.1c">\displaystyle\bm{y}_{i}</annotation><annotation encoding="application/x-llamapun" id="S2.E5.m1.1d">bold_italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle=\bm{S}_{i}^{\top}\bm{q}_{i}." class="ltx_Math" display="inline" id="S2.E5.m2.1"><semantics id="S2.E5.m2.1a"><mrow id="S2.E5.m2.1.1.1" xref="S2.E5.m2.1.1.1.1.cmml"><mrow id="S2.E5.m2.1.1.1.1" xref="S2.E5.m2.1.1.1.1.cmml"><mi id="S2.E5.m2.1.1.1.1.2" xref="S2.E5.m2.1.1.1.1.2.cmml"></mi><mo id="S2.E5.m2.1.1.1.1.1" xref="S2.E5.m2.1.1.1.1.1.cmml">=</mo><mrow id="S2.E5.m2.1.1.1.1.3" xref="S2.E5.m2.1.1.1.1.3.cmml"><msubsup id="S2.E5.m2.1.1.1.1.3.2" xref="S2.E5.m2.1.1.1.1.3.2.cmml"><mi id="S2.E5.m2.1.1.1.1.3.2.2.2" xref="S2.E5.m2.1.1.1.1.3.2.2.2.cmml">𝑺</mi><mi id="S2.E5.m2.1.1.1.1.3.2.2.3" xref="S2.E5.m2.1.1.1.1.3.2.2.3.cmml">i</mi><mo id="S2.E5.m2.1.1.1.1.3.2.3" xref="S2.E5.m2.1.1.1.1.3.2.3.cmml">⊤</mo></msubsup><mo id="S2.E5.m2.1.1.1.1.3.1" xref="S2.E5.m2.1.1.1.1.3.1.cmml">⁢</mo><msub id="S2.E5.m2.1.1.1.1.3.3" xref="S2.E5.m2.1.1.1.1.3.3.cmml"><mi id="S2.E5.m2.1.1.1.1.3.3.2" xref="S2.E5.m2.1.1.1.1.3.3.2.cmml">𝒒</mi><mi id="S2.E5.m2.1.1.1.1.3.3.3" xref="S2.E5.m2.1.1.1.1.3.3.3.cmml">i</mi></msub></mrow></mrow><mo id="S2.E5.m2.1.1.1.2" lspace="0em" xref="S2.E5.m2.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E5.m2.1b"><apply id="S2.E5.m2.1.1.1.1.cmml" xref="S2.E5.m2.1.1.1"><eq id="S2.E5.m2.1.1.1.1.1.cmml" xref="S2.E5.m2.1.1.1.1.1"></eq><csymbol cd="latexml" id="S2.E5.m2.1.1.1.1.2.cmml" xref="S2.E5.m2.1.1.1.1.2">absent</csymbol><apply id="S2.E5.m2.1.1.1.1.3.cmml" xref="S2.E5.m2.1.1.1.1.3"><times id="S2.E5.m2.1.1.1.1.3.1.cmml" xref="S2.E5.m2.1.1.1.1.3.1"></times><apply id="S2.E5.m2.1.1.1.1.3.2.cmml" xref="S2.E5.m2.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S2.E5.m2.1.1.1.1.3.2.1.cmml" xref="S2.E5.m2.1.1.1.1.3.2">superscript</csymbol><apply id="S2.E5.m2.1.1.1.1.3.2.2.cmml" xref="S2.E5.m2.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S2.E5.m2.1.1.1.1.3.2.2.1.cmml" xref="S2.E5.m2.1.1.1.1.3.2">subscript</csymbol><ci id="S2.E5.m2.1.1.1.1.3.2.2.2.cmml" xref="S2.E5.m2.1.1.1.1.3.2.2.2">𝑺</ci><ci id="S2.E5.m2.1.1.1.1.3.2.2.3.cmml" xref="S2.E5.m2.1.1.1.1.3.2.2.3">𝑖</ci></apply><csymbol cd="latexml" id="S2.E5.m2.1.1.1.1.3.2.3.cmml" xref="S2.E5.m2.1.1.1.1.3.2.3">top</csymbol></apply><apply id="S2.E5.m2.1.1.1.1.3.3.cmml" xref="S2.E5.m2.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S2.E5.m2.1.1.1.1.3.3.1.cmml" xref="S2.E5.m2.1.1.1.1.3.3">subscript</csymbol><ci id="S2.E5.m2.1.1.1.1.3.3.2.cmml" xref="S2.E5.m2.1.1.1.1.3.3.2">𝒒</ci><ci id="S2.E5.m2.1.1.1.1.3.3.3.cmml" xref="S2.E5.m2.1.1.1.1.3.3.3">𝑖</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E5.m2.1c">\displaystyle=\bm{S}_{i}^{\top}\bm{q}_{i}.</annotation><annotation encoding="application/x-llamapun" id="S2.E5.m2.1d">= bold_italic_S start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ⊤ end_POSTSUPERSCRIPT bold_italic_q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT .</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S2.SS2.SSS0.Px1.p1.4">This formulation effectively biases the attention mechanism to focus on closer token interactions.
RetNet also uses XPos <cite class="ltx_cite ltx_citemacro_citep">(Sun et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib39" title="">2023b</a>)</cite>, a relative positional encoding method, to improve its context extrapolation abilities.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>State Space Models (SSMs)</h3>
<div class="ltx_para" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.4">SSMs <cite class="ltx_cite ltx_citemacro_citep">(Gu et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib20" title="">2020</a>)</cite> provide an alternative sequence mixing layer
by processing sequences <math alttext="\bm{x}_{1},...,\bm{x}_{n}" class="ltx_Math" display="inline" id="S2.SS3.p1.1.m1.3"><semantics id="S2.SS3.p1.1.m1.3a"><mrow id="S2.SS3.p1.1.m1.3.3.2" xref="S2.SS3.p1.1.m1.3.3.3.cmml"><msub id="S2.SS3.p1.1.m1.2.2.1.1" xref="S2.SS3.p1.1.m1.2.2.1.1.cmml"><mi id="S2.SS3.p1.1.m1.2.2.1.1.2" xref="S2.SS3.p1.1.m1.2.2.1.1.2.cmml">𝒙</mi><mn id="S2.SS3.p1.1.m1.2.2.1.1.3" xref="S2.SS3.p1.1.m1.2.2.1.1.3.cmml">1</mn></msub><mo id="S2.SS3.p1.1.m1.3.3.2.3" xref="S2.SS3.p1.1.m1.3.3.3.cmml">,</mo><mi id="S2.SS3.p1.1.m1.1.1" mathvariant="normal" xref="S2.SS3.p1.1.m1.1.1.cmml">…</mi><mo id="S2.SS3.p1.1.m1.3.3.2.4" xref="S2.SS3.p1.1.m1.3.3.3.cmml">,</mo><msub id="S2.SS3.p1.1.m1.3.3.2.2" xref="S2.SS3.p1.1.m1.3.3.2.2.cmml"><mi id="S2.SS3.p1.1.m1.3.3.2.2.2" xref="S2.SS3.p1.1.m1.3.3.2.2.2.cmml">𝒙</mi><mi id="S2.SS3.p1.1.m1.3.3.2.2.3" xref="S2.SS3.p1.1.m1.3.3.2.2.3.cmml">n</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.1.m1.3b"><list id="S2.SS3.p1.1.m1.3.3.3.cmml" xref="S2.SS3.p1.1.m1.3.3.2"><apply id="S2.SS3.p1.1.m1.2.2.1.1.cmml" xref="S2.SS3.p1.1.m1.2.2.1.1"><csymbol cd="ambiguous" id="S2.SS3.p1.1.m1.2.2.1.1.1.cmml" xref="S2.SS3.p1.1.m1.2.2.1.1">subscript</csymbol><ci id="S2.SS3.p1.1.m1.2.2.1.1.2.cmml" xref="S2.SS3.p1.1.m1.2.2.1.1.2">𝒙</ci><cn id="S2.SS3.p1.1.m1.2.2.1.1.3.cmml" type="integer" xref="S2.SS3.p1.1.m1.2.2.1.1.3">1</cn></apply><ci id="S2.SS3.p1.1.m1.1.1.cmml" xref="S2.SS3.p1.1.m1.1.1">…</ci><apply id="S2.SS3.p1.1.m1.3.3.2.2.cmml" xref="S2.SS3.p1.1.m1.3.3.2.2"><csymbol cd="ambiguous" id="S2.SS3.p1.1.m1.3.3.2.2.1.cmml" xref="S2.SS3.p1.1.m1.3.3.2.2">subscript</csymbol><ci id="S2.SS3.p1.1.m1.3.3.2.2.2.cmml" xref="S2.SS3.p1.1.m1.3.3.2.2.2">𝒙</ci><ci id="S2.SS3.p1.1.m1.3.3.2.2.3.cmml" xref="S2.SS3.p1.1.m1.3.3.2.2.3">𝑛</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.1.m1.3c">\bm{x}_{1},...,\bm{x}_{n}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p1.1.m1.3d">bold_italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , bold_italic_x start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT</annotation></semantics></math>, where each <math alttext="\bm{x}_{i}\in\mathbb{R}^{d}" class="ltx_Math" display="inline" id="S2.SS3.p1.2.m2.1"><semantics id="S2.SS3.p1.2.m2.1a"><mrow id="S2.SS3.p1.2.m2.1.1" xref="S2.SS3.p1.2.m2.1.1.cmml"><msub id="S2.SS3.p1.2.m2.1.1.2" xref="S2.SS3.p1.2.m2.1.1.2.cmml"><mi id="S2.SS3.p1.2.m2.1.1.2.2" xref="S2.SS3.p1.2.m2.1.1.2.2.cmml">𝒙</mi><mi id="S2.SS3.p1.2.m2.1.1.2.3" xref="S2.SS3.p1.2.m2.1.1.2.3.cmml">i</mi></msub><mo id="S2.SS3.p1.2.m2.1.1.1" xref="S2.SS3.p1.2.m2.1.1.1.cmml">∈</mo><msup id="S2.SS3.p1.2.m2.1.1.3" xref="S2.SS3.p1.2.m2.1.1.3.cmml"><mi id="S2.SS3.p1.2.m2.1.1.3.2" xref="S2.SS3.p1.2.m2.1.1.3.2.cmml">ℝ</mi><mi id="S2.SS3.p1.2.m2.1.1.3.3" xref="S2.SS3.p1.2.m2.1.1.3.3.cmml">d</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.2.m2.1b"><apply id="S2.SS3.p1.2.m2.1.1.cmml" xref="S2.SS3.p1.2.m2.1.1"><in id="S2.SS3.p1.2.m2.1.1.1.cmml" xref="S2.SS3.p1.2.m2.1.1.1"></in><apply id="S2.SS3.p1.2.m2.1.1.2.cmml" xref="S2.SS3.p1.2.m2.1.1.2"><csymbol cd="ambiguous" id="S2.SS3.p1.2.m2.1.1.2.1.cmml" xref="S2.SS3.p1.2.m2.1.1.2">subscript</csymbol><ci id="S2.SS3.p1.2.m2.1.1.2.2.cmml" xref="S2.SS3.p1.2.m2.1.1.2.2">𝒙</ci><ci id="S2.SS3.p1.2.m2.1.1.2.3.cmml" xref="S2.SS3.p1.2.m2.1.1.2.3">𝑖</ci></apply><apply id="S2.SS3.p1.2.m2.1.1.3.cmml" xref="S2.SS3.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S2.SS3.p1.2.m2.1.1.3.1.cmml" xref="S2.SS3.p1.2.m2.1.1.3">superscript</csymbol><ci id="S2.SS3.p1.2.m2.1.1.3.2.cmml" xref="S2.SS3.p1.2.m2.1.1.3.2">ℝ</ci><ci id="S2.SS3.p1.2.m2.1.1.3.3.cmml" xref="S2.SS3.p1.2.m2.1.1.3.3">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.2.m2.1c">\bm{x}_{i}\in\mathbb{R}^{d}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p1.2.m2.1d">bold_italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT</annotation></semantics></math>, through a linear recurrence.
Letting <math alttext="\bm{H}_{i}\in\mathbb{R}^{r\times d}" class="ltx_Math" display="inline" id="S2.SS3.p1.3.m3.1"><semantics id="S2.SS3.p1.3.m3.1a"><mrow id="S2.SS3.p1.3.m3.1.1" xref="S2.SS3.p1.3.m3.1.1.cmml"><msub id="S2.SS3.p1.3.m3.1.1.2" xref="S2.SS3.p1.3.m3.1.1.2.cmml"><mi id="S2.SS3.p1.3.m3.1.1.2.2" xref="S2.SS3.p1.3.m3.1.1.2.2.cmml">𝑯</mi><mi id="S2.SS3.p1.3.m3.1.1.2.3" xref="S2.SS3.p1.3.m3.1.1.2.3.cmml">i</mi></msub><mo id="S2.SS3.p1.3.m3.1.1.1" xref="S2.SS3.p1.3.m3.1.1.1.cmml">∈</mo><msup id="S2.SS3.p1.3.m3.1.1.3" xref="S2.SS3.p1.3.m3.1.1.3.cmml"><mi id="S2.SS3.p1.3.m3.1.1.3.2" xref="S2.SS3.p1.3.m3.1.1.3.2.cmml">ℝ</mi><mrow id="S2.SS3.p1.3.m3.1.1.3.3" xref="S2.SS3.p1.3.m3.1.1.3.3.cmml"><mi id="S2.SS3.p1.3.m3.1.1.3.3.2" xref="S2.SS3.p1.3.m3.1.1.3.3.2.cmml">r</mi><mo id="S2.SS3.p1.3.m3.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S2.SS3.p1.3.m3.1.1.3.3.1.cmml">×</mo><mi id="S2.SS3.p1.3.m3.1.1.3.3.3" xref="S2.SS3.p1.3.m3.1.1.3.3.3.cmml">d</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.3.m3.1b"><apply id="S2.SS3.p1.3.m3.1.1.cmml" xref="S2.SS3.p1.3.m3.1.1"><in id="S2.SS3.p1.3.m3.1.1.1.cmml" xref="S2.SS3.p1.3.m3.1.1.1"></in><apply id="S2.SS3.p1.3.m3.1.1.2.cmml" xref="S2.SS3.p1.3.m3.1.1.2"><csymbol cd="ambiguous" id="S2.SS3.p1.3.m3.1.1.2.1.cmml" xref="S2.SS3.p1.3.m3.1.1.2">subscript</csymbol><ci id="S2.SS3.p1.3.m3.1.1.2.2.cmml" xref="S2.SS3.p1.3.m3.1.1.2.2">𝑯</ci><ci id="S2.SS3.p1.3.m3.1.1.2.3.cmml" xref="S2.SS3.p1.3.m3.1.1.2.3">𝑖</ci></apply><apply id="S2.SS3.p1.3.m3.1.1.3.cmml" xref="S2.SS3.p1.3.m3.1.1.3"><csymbol cd="ambiguous" id="S2.SS3.p1.3.m3.1.1.3.1.cmml" xref="S2.SS3.p1.3.m3.1.1.3">superscript</csymbol><ci id="S2.SS3.p1.3.m3.1.1.3.2.cmml" xref="S2.SS3.p1.3.m3.1.1.3.2">ℝ</ci><apply id="S2.SS3.p1.3.m3.1.1.3.3.cmml" xref="S2.SS3.p1.3.m3.1.1.3.3"><times id="S2.SS3.p1.3.m3.1.1.3.3.1.cmml" xref="S2.SS3.p1.3.m3.1.1.3.3.1"></times><ci id="S2.SS3.p1.3.m3.1.1.3.3.2.cmml" xref="S2.SS3.p1.3.m3.1.1.3.3.2">𝑟</ci><ci id="S2.SS3.p1.3.m3.1.1.3.3.3.cmml" xref="S2.SS3.p1.3.m3.1.1.3.3.3">𝑑</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.3.m3.1c">\bm{H}_{i}\in\mathbb{R}^{r\times d}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p1.3.m3.1d">bold_italic_H start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT italic_r × italic_d end_POSTSUPERSCRIPT</annotation></semantics></math> denote the “state” at the <math alttext="i\textsuperscript{th}" class="ltx_Math" display="inline" id="S2.SS3.p1.4.m4.1"><semantics id="S2.SS3.p1.4.m4.1a"><mrow id="S2.SS3.p1.4.m4.1.1" xref="S2.SS3.p1.4.m4.1.1.cmml"><mi id="S2.SS3.p1.4.m4.1.1.2" xref="S2.SS3.p1.4.m4.1.1.2.cmml">i</mi><mo id="S2.SS3.p1.4.m4.1.1.1" xref="S2.SS3.p1.4.m4.1.1.1.cmml">⁢</mo><mtext id="S2.SS3.p1.4.m4.1.1.3" xref="S2.SS3.p1.4.m4.1.1.3b.cmml"><sup class="ltx_sup" id="S2.SS3.p1.4.m4.1.1.3.1nest">th</sup></mtext></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.4.m4.1b"><apply id="S2.SS3.p1.4.m4.1.1.cmml" xref="S2.SS3.p1.4.m4.1.1"><times id="S2.SS3.p1.4.m4.1.1.1.cmml" xref="S2.SS3.p1.4.m4.1.1.1"></times><ci id="S2.SS3.p1.4.m4.1.1.2.cmml" xref="S2.SS3.p1.4.m4.1.1.2">𝑖</ci><ci id="S2.SS3.p1.4.m4.1.1.3b.cmml" xref="S2.SS3.p1.4.m4.1.1.3"><mtext id="S2.SS3.p1.4.m4.1.1.3.cmml" xref="S2.SS3.p1.4.m4.1.1.3"><sup class="ltx_sup" id="S2.SS3.p1.4.m4.1.1.3.1anest">th</sup></mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.4.m4.1c">i\textsuperscript{th}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p1.4.m4.1d">italic_i</annotation></semantics></math> time step, a discrete SSM is defined as follows:<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>A discretization step is needed in order to obtain discrete parameters. For example, a possible method for this step is the zero-order hold rule, used by Mamba <cite class="ltx_cite ltx_citemacro_citep">(Gu and Dao, <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib19" title="">2023</a>)</cite>.</span></span></span></p>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="A5.EGx4">
<tbody id="S2.Ex5"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\bm{H}_{i}" class="ltx_Math" display="inline" id="S2.Ex5.m1.1"><semantics id="S2.Ex5.m1.1a"><msub id="S2.Ex5.m1.1.1" xref="S2.Ex5.m1.1.1.cmml"><mi id="S2.Ex5.m1.1.1.2" xref="S2.Ex5.m1.1.1.2.cmml">𝑯</mi><mi id="S2.Ex5.m1.1.1.3" xref="S2.Ex5.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.Ex5.m1.1b"><apply id="S2.Ex5.m1.1.1.cmml" xref="S2.Ex5.m1.1.1"><csymbol cd="ambiguous" id="S2.Ex5.m1.1.1.1.cmml" xref="S2.Ex5.m1.1.1">subscript</csymbol><ci id="S2.Ex5.m1.1.1.2.cmml" xref="S2.Ex5.m1.1.1.2">𝑯</ci><ci id="S2.Ex5.m1.1.1.3.cmml" xref="S2.Ex5.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex5.m1.1c">\displaystyle\bm{H}_{i}</annotation><annotation encoding="application/x-llamapun" id="S2.Ex5.m1.1d">bold_italic_H start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle=\bm{A}\bm{H}_{i-1}+\bm{b}\bm{x}_{i}^{\top}," class="ltx_Math" display="inline" id="S2.Ex5.m2.1"><semantics id="S2.Ex5.m2.1a"><mrow id="S2.Ex5.m2.1.1.1" xref="S2.Ex5.m2.1.1.1.1.cmml"><mrow id="S2.Ex5.m2.1.1.1.1" xref="S2.Ex5.m2.1.1.1.1.cmml"><mi id="S2.Ex5.m2.1.1.1.1.2" xref="S2.Ex5.m2.1.1.1.1.2.cmml"></mi><mo id="S2.Ex5.m2.1.1.1.1.1" xref="S2.Ex5.m2.1.1.1.1.1.cmml">=</mo><mrow id="S2.Ex5.m2.1.1.1.1.3" xref="S2.Ex5.m2.1.1.1.1.3.cmml"><mrow id="S2.Ex5.m2.1.1.1.1.3.2" xref="S2.Ex5.m2.1.1.1.1.3.2.cmml"><mi id="S2.Ex5.m2.1.1.1.1.3.2.2" xref="S2.Ex5.m2.1.1.1.1.3.2.2.cmml">𝑨</mi><mo id="S2.Ex5.m2.1.1.1.1.3.2.1" xref="S2.Ex5.m2.1.1.1.1.3.2.1.cmml">⁢</mo><msub id="S2.Ex5.m2.1.1.1.1.3.2.3" xref="S2.Ex5.m2.1.1.1.1.3.2.3.cmml"><mi id="S2.Ex5.m2.1.1.1.1.3.2.3.2" xref="S2.Ex5.m2.1.1.1.1.3.2.3.2.cmml">𝑯</mi><mrow id="S2.Ex5.m2.1.1.1.1.3.2.3.3" xref="S2.Ex5.m2.1.1.1.1.3.2.3.3.cmml"><mi id="S2.Ex5.m2.1.1.1.1.3.2.3.3.2" xref="S2.Ex5.m2.1.1.1.1.3.2.3.3.2.cmml">i</mi><mo id="S2.Ex5.m2.1.1.1.1.3.2.3.3.1" xref="S2.Ex5.m2.1.1.1.1.3.2.3.3.1.cmml">−</mo><mn id="S2.Ex5.m2.1.1.1.1.3.2.3.3.3" xref="S2.Ex5.m2.1.1.1.1.3.2.3.3.3.cmml">1</mn></mrow></msub></mrow><mo id="S2.Ex5.m2.1.1.1.1.3.1" xref="S2.Ex5.m2.1.1.1.1.3.1.cmml">+</mo><mrow id="S2.Ex5.m2.1.1.1.1.3.3" xref="S2.Ex5.m2.1.1.1.1.3.3.cmml"><mi id="S2.Ex5.m2.1.1.1.1.3.3.2" xref="S2.Ex5.m2.1.1.1.1.3.3.2.cmml">𝒃</mi><mo id="S2.Ex5.m2.1.1.1.1.3.3.1" xref="S2.Ex5.m2.1.1.1.1.3.3.1.cmml">⁢</mo><msubsup id="S2.Ex5.m2.1.1.1.1.3.3.3" xref="S2.Ex5.m2.1.1.1.1.3.3.3.cmml"><mi id="S2.Ex5.m2.1.1.1.1.3.3.3.2.2" xref="S2.Ex5.m2.1.1.1.1.3.3.3.2.2.cmml">𝒙</mi><mi id="S2.Ex5.m2.1.1.1.1.3.3.3.2.3" xref="S2.Ex5.m2.1.1.1.1.3.3.3.2.3.cmml">i</mi><mo id="S2.Ex5.m2.1.1.1.1.3.3.3.3" xref="S2.Ex5.m2.1.1.1.1.3.3.3.3.cmml">⊤</mo></msubsup></mrow></mrow></mrow><mo id="S2.Ex5.m2.1.1.1.2" xref="S2.Ex5.m2.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.Ex5.m2.1b"><apply id="S2.Ex5.m2.1.1.1.1.cmml" xref="S2.Ex5.m2.1.1.1"><eq id="S2.Ex5.m2.1.1.1.1.1.cmml" xref="S2.Ex5.m2.1.1.1.1.1"></eq><csymbol cd="latexml" id="S2.Ex5.m2.1.1.1.1.2.cmml" xref="S2.Ex5.m2.1.1.1.1.2">absent</csymbol><apply id="S2.Ex5.m2.1.1.1.1.3.cmml" xref="S2.Ex5.m2.1.1.1.1.3"><plus id="S2.Ex5.m2.1.1.1.1.3.1.cmml" xref="S2.Ex5.m2.1.1.1.1.3.1"></plus><apply id="S2.Ex5.m2.1.1.1.1.3.2.cmml" xref="S2.Ex5.m2.1.1.1.1.3.2"><times id="S2.Ex5.m2.1.1.1.1.3.2.1.cmml" xref="S2.Ex5.m2.1.1.1.1.3.2.1"></times><ci id="S2.Ex5.m2.1.1.1.1.3.2.2.cmml" xref="S2.Ex5.m2.1.1.1.1.3.2.2">𝑨</ci><apply id="S2.Ex5.m2.1.1.1.1.3.2.3.cmml" xref="S2.Ex5.m2.1.1.1.1.3.2.3"><csymbol cd="ambiguous" id="S2.Ex5.m2.1.1.1.1.3.2.3.1.cmml" xref="S2.Ex5.m2.1.1.1.1.3.2.3">subscript</csymbol><ci id="S2.Ex5.m2.1.1.1.1.3.2.3.2.cmml" xref="S2.Ex5.m2.1.1.1.1.3.2.3.2">𝑯</ci><apply id="S2.Ex5.m2.1.1.1.1.3.2.3.3.cmml" xref="S2.Ex5.m2.1.1.1.1.3.2.3.3"><minus id="S2.Ex5.m2.1.1.1.1.3.2.3.3.1.cmml" xref="S2.Ex5.m2.1.1.1.1.3.2.3.3.1"></minus><ci id="S2.Ex5.m2.1.1.1.1.3.2.3.3.2.cmml" xref="S2.Ex5.m2.1.1.1.1.3.2.3.3.2">𝑖</ci><cn id="S2.Ex5.m2.1.1.1.1.3.2.3.3.3.cmml" type="integer" xref="S2.Ex5.m2.1.1.1.1.3.2.3.3.3">1</cn></apply></apply></apply><apply id="S2.Ex5.m2.1.1.1.1.3.3.cmml" xref="S2.Ex5.m2.1.1.1.1.3.3"><times id="S2.Ex5.m2.1.1.1.1.3.3.1.cmml" xref="S2.Ex5.m2.1.1.1.1.3.3.1"></times><ci id="S2.Ex5.m2.1.1.1.1.3.3.2.cmml" xref="S2.Ex5.m2.1.1.1.1.3.3.2">𝒃</ci><apply id="S2.Ex5.m2.1.1.1.1.3.3.3.cmml" xref="S2.Ex5.m2.1.1.1.1.3.3.3"><csymbol cd="ambiguous" id="S2.Ex5.m2.1.1.1.1.3.3.3.1.cmml" xref="S2.Ex5.m2.1.1.1.1.3.3.3">superscript</csymbol><apply id="S2.Ex5.m2.1.1.1.1.3.3.3.2.cmml" xref="S2.Ex5.m2.1.1.1.1.3.3.3"><csymbol cd="ambiguous" id="S2.Ex5.m2.1.1.1.1.3.3.3.2.1.cmml" xref="S2.Ex5.m2.1.1.1.1.3.3.3">subscript</csymbol><ci id="S2.Ex5.m2.1.1.1.1.3.3.3.2.2.cmml" xref="S2.Ex5.m2.1.1.1.1.3.3.3.2.2">𝒙</ci><ci id="S2.Ex5.m2.1.1.1.1.3.3.3.2.3.cmml" xref="S2.Ex5.m2.1.1.1.1.3.3.3.2.3">𝑖</ci></apply><csymbol cd="latexml" id="S2.Ex5.m2.1.1.1.1.3.3.3.3.cmml" xref="S2.Ex5.m2.1.1.1.1.3.3.3.3">top</csymbol></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex5.m2.1c">\displaystyle=\bm{A}\bm{H}_{i-1}+\bm{b}\bm{x}_{i}^{\top},</annotation><annotation encoding="application/x-llamapun" id="S2.Ex5.m2.1d">= bold_italic_A bold_italic_H start_POSTSUBSCRIPT italic_i - 1 end_POSTSUBSCRIPT + bold_italic_b bold_italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ⊤ end_POSTSUPERSCRIPT ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="S2.E6"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\bm{y}_{i}" class="ltx_Math" display="inline" id="S2.E6.m1.1"><semantics id="S2.E6.m1.1a"><msub id="S2.E6.m1.1.1" xref="S2.E6.m1.1.1.cmml"><mi id="S2.E6.m1.1.1.2" xref="S2.E6.m1.1.1.2.cmml">𝒚</mi><mi id="S2.E6.m1.1.1.3" xref="S2.E6.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.E6.m1.1b"><apply id="S2.E6.m1.1.1.cmml" xref="S2.E6.m1.1.1"><csymbol cd="ambiguous" id="S2.E6.m1.1.1.1.cmml" xref="S2.E6.m1.1.1">subscript</csymbol><ci id="S2.E6.m1.1.1.2.cmml" xref="S2.E6.m1.1.1.2">𝒚</ci><ci id="S2.E6.m1.1.1.3.cmml" xref="S2.E6.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E6.m1.1c">\displaystyle\bm{y}_{i}</annotation><annotation encoding="application/x-llamapun" id="S2.E6.m1.1d">bold_italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle=\bm{H}_{i}^{\top}\bm{c}," class="ltx_Math" display="inline" id="S2.E6.m2.1"><semantics id="S2.E6.m2.1a"><mrow id="S2.E6.m2.1.1.1" xref="S2.E6.m2.1.1.1.1.cmml"><mrow id="S2.E6.m2.1.1.1.1" xref="S2.E6.m2.1.1.1.1.cmml"><mi id="S2.E6.m2.1.1.1.1.2" xref="S2.E6.m2.1.1.1.1.2.cmml"></mi><mo id="S2.E6.m2.1.1.1.1.1" xref="S2.E6.m2.1.1.1.1.1.cmml">=</mo><mrow id="S2.E6.m2.1.1.1.1.3" xref="S2.E6.m2.1.1.1.1.3.cmml"><msubsup id="S2.E6.m2.1.1.1.1.3.2" xref="S2.E6.m2.1.1.1.1.3.2.cmml"><mi id="S2.E6.m2.1.1.1.1.3.2.2.2" xref="S2.E6.m2.1.1.1.1.3.2.2.2.cmml">𝑯</mi><mi id="S2.E6.m2.1.1.1.1.3.2.2.3" xref="S2.E6.m2.1.1.1.1.3.2.2.3.cmml">i</mi><mo id="S2.E6.m2.1.1.1.1.3.2.3" xref="S2.E6.m2.1.1.1.1.3.2.3.cmml">⊤</mo></msubsup><mo id="S2.E6.m2.1.1.1.1.3.1" xref="S2.E6.m2.1.1.1.1.3.1.cmml">⁢</mo><mi id="S2.E6.m2.1.1.1.1.3.3" xref="S2.E6.m2.1.1.1.1.3.3.cmml">𝒄</mi></mrow></mrow><mo id="S2.E6.m2.1.1.1.2" xref="S2.E6.m2.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E6.m2.1b"><apply id="S2.E6.m2.1.1.1.1.cmml" xref="S2.E6.m2.1.1.1"><eq id="S2.E6.m2.1.1.1.1.1.cmml" xref="S2.E6.m2.1.1.1.1.1"></eq><csymbol cd="latexml" id="S2.E6.m2.1.1.1.1.2.cmml" xref="S2.E6.m2.1.1.1.1.2">absent</csymbol><apply id="S2.E6.m2.1.1.1.1.3.cmml" xref="S2.E6.m2.1.1.1.1.3"><times id="S2.E6.m2.1.1.1.1.3.1.cmml" xref="S2.E6.m2.1.1.1.1.3.1"></times><apply id="S2.E6.m2.1.1.1.1.3.2.cmml" xref="S2.E6.m2.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S2.E6.m2.1.1.1.1.3.2.1.cmml" xref="S2.E6.m2.1.1.1.1.3.2">superscript</csymbol><apply id="S2.E6.m2.1.1.1.1.3.2.2.cmml" xref="S2.E6.m2.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S2.E6.m2.1.1.1.1.3.2.2.1.cmml" xref="S2.E6.m2.1.1.1.1.3.2">subscript</csymbol><ci id="S2.E6.m2.1.1.1.1.3.2.2.2.cmml" xref="S2.E6.m2.1.1.1.1.3.2.2.2">𝑯</ci><ci id="S2.E6.m2.1.1.1.1.3.2.2.3.cmml" xref="S2.E6.m2.1.1.1.1.3.2.2.3">𝑖</ci></apply><csymbol cd="latexml" id="S2.E6.m2.1.1.1.1.3.2.3.cmml" xref="S2.E6.m2.1.1.1.1.3.2.3">top</csymbol></apply><ci id="S2.E6.m2.1.1.1.1.3.3.cmml" xref="S2.E6.m2.1.1.1.1.3.3">𝒄</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E6.m2.1c">\displaystyle=\bm{H}_{i}^{\top}\bm{c},</annotation><annotation encoding="application/x-llamapun" id="S2.E6.m2.1d">= bold_italic_H start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ⊤ end_POSTSUPERSCRIPT bold_italic_c ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S2.SS3.p1.12">where <math alttext="\bm{A}\in\mathbb{R}^{r\times r}" class="ltx_Math" display="inline" id="S2.SS3.p1.5.m1.1"><semantics id="S2.SS3.p1.5.m1.1a"><mrow id="S2.SS3.p1.5.m1.1.1" xref="S2.SS3.p1.5.m1.1.1.cmml"><mi id="S2.SS3.p1.5.m1.1.1.2" xref="S2.SS3.p1.5.m1.1.1.2.cmml">𝑨</mi><mo id="S2.SS3.p1.5.m1.1.1.1" xref="S2.SS3.p1.5.m1.1.1.1.cmml">∈</mo><msup id="S2.SS3.p1.5.m1.1.1.3" xref="S2.SS3.p1.5.m1.1.1.3.cmml"><mi id="S2.SS3.p1.5.m1.1.1.3.2" xref="S2.SS3.p1.5.m1.1.1.3.2.cmml">ℝ</mi><mrow id="S2.SS3.p1.5.m1.1.1.3.3" xref="S2.SS3.p1.5.m1.1.1.3.3.cmml"><mi id="S2.SS3.p1.5.m1.1.1.3.3.2" xref="S2.SS3.p1.5.m1.1.1.3.3.2.cmml">r</mi><mo id="S2.SS3.p1.5.m1.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S2.SS3.p1.5.m1.1.1.3.3.1.cmml">×</mo><mi id="S2.SS3.p1.5.m1.1.1.3.3.3" xref="S2.SS3.p1.5.m1.1.1.3.3.3.cmml">r</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.5.m1.1b"><apply id="S2.SS3.p1.5.m1.1.1.cmml" xref="S2.SS3.p1.5.m1.1.1"><in id="S2.SS3.p1.5.m1.1.1.1.cmml" xref="S2.SS3.p1.5.m1.1.1.1"></in><ci id="S2.SS3.p1.5.m1.1.1.2.cmml" xref="S2.SS3.p1.5.m1.1.1.2">𝑨</ci><apply id="S2.SS3.p1.5.m1.1.1.3.cmml" xref="S2.SS3.p1.5.m1.1.1.3"><csymbol cd="ambiguous" id="S2.SS3.p1.5.m1.1.1.3.1.cmml" xref="S2.SS3.p1.5.m1.1.1.3">superscript</csymbol><ci id="S2.SS3.p1.5.m1.1.1.3.2.cmml" xref="S2.SS3.p1.5.m1.1.1.3.2">ℝ</ci><apply id="S2.SS3.p1.5.m1.1.1.3.3.cmml" xref="S2.SS3.p1.5.m1.1.1.3.3"><times id="S2.SS3.p1.5.m1.1.1.3.3.1.cmml" xref="S2.SS3.p1.5.m1.1.1.3.3.1"></times><ci id="S2.SS3.p1.5.m1.1.1.3.3.2.cmml" xref="S2.SS3.p1.5.m1.1.1.3.3.2">𝑟</ci><ci id="S2.SS3.p1.5.m1.1.1.3.3.3.cmml" xref="S2.SS3.p1.5.m1.1.1.3.3.3">𝑟</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.5.m1.1c">\bm{A}\in\mathbb{R}^{r\times r}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p1.5.m1.1d">bold_italic_A ∈ blackboard_R start_POSTSUPERSCRIPT italic_r × italic_r end_POSTSUPERSCRIPT</annotation></semantics></math>, <math alttext="\bm{b}\in\mathbb{R}^{r}" class="ltx_Math" display="inline" id="S2.SS3.p1.6.m2.1"><semantics id="S2.SS3.p1.6.m2.1a"><mrow id="S2.SS3.p1.6.m2.1.1" xref="S2.SS3.p1.6.m2.1.1.cmml"><mi id="S2.SS3.p1.6.m2.1.1.2" xref="S2.SS3.p1.6.m2.1.1.2.cmml">𝒃</mi><mo id="S2.SS3.p1.6.m2.1.1.1" xref="S2.SS3.p1.6.m2.1.1.1.cmml">∈</mo><msup id="S2.SS3.p1.6.m2.1.1.3" xref="S2.SS3.p1.6.m2.1.1.3.cmml"><mi id="S2.SS3.p1.6.m2.1.1.3.2" xref="S2.SS3.p1.6.m2.1.1.3.2.cmml">ℝ</mi><mi id="S2.SS3.p1.6.m2.1.1.3.3" xref="S2.SS3.p1.6.m2.1.1.3.3.cmml">r</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.6.m2.1b"><apply id="S2.SS3.p1.6.m2.1.1.cmml" xref="S2.SS3.p1.6.m2.1.1"><in id="S2.SS3.p1.6.m2.1.1.1.cmml" xref="S2.SS3.p1.6.m2.1.1.1"></in><ci id="S2.SS3.p1.6.m2.1.1.2.cmml" xref="S2.SS3.p1.6.m2.1.1.2">𝒃</ci><apply id="S2.SS3.p1.6.m2.1.1.3.cmml" xref="S2.SS3.p1.6.m2.1.1.3"><csymbol cd="ambiguous" id="S2.SS3.p1.6.m2.1.1.3.1.cmml" xref="S2.SS3.p1.6.m2.1.1.3">superscript</csymbol><ci id="S2.SS3.p1.6.m2.1.1.3.2.cmml" xref="S2.SS3.p1.6.m2.1.1.3.2">ℝ</ci><ci id="S2.SS3.p1.6.m2.1.1.3.3.cmml" xref="S2.SS3.p1.6.m2.1.1.3.3">𝑟</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.6.m2.1c">\bm{b}\in\mathbb{R}^{r}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p1.6.m2.1d">bold_italic_b ∈ blackboard_R start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT</annotation></semantics></math>, and <math alttext="\bm{c}\in\mathbb{R}^{r}" class="ltx_Math" display="inline" id="S2.SS3.p1.7.m3.1"><semantics id="S2.SS3.p1.7.m3.1a"><mrow id="S2.SS3.p1.7.m3.1.1" xref="S2.SS3.p1.7.m3.1.1.cmml"><mi id="S2.SS3.p1.7.m3.1.1.2" xref="S2.SS3.p1.7.m3.1.1.2.cmml">𝒄</mi><mo id="S2.SS3.p1.7.m3.1.1.1" xref="S2.SS3.p1.7.m3.1.1.1.cmml">∈</mo><msup id="S2.SS3.p1.7.m3.1.1.3" xref="S2.SS3.p1.7.m3.1.1.3.cmml"><mi id="S2.SS3.p1.7.m3.1.1.3.2" xref="S2.SS3.p1.7.m3.1.1.3.2.cmml">ℝ</mi><mi id="S2.SS3.p1.7.m3.1.1.3.3" xref="S2.SS3.p1.7.m3.1.1.3.3.cmml">r</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.7.m3.1b"><apply id="S2.SS3.p1.7.m3.1.1.cmml" xref="S2.SS3.p1.7.m3.1.1"><in id="S2.SS3.p1.7.m3.1.1.1.cmml" xref="S2.SS3.p1.7.m3.1.1.1"></in><ci id="S2.SS3.p1.7.m3.1.1.2.cmml" xref="S2.SS3.p1.7.m3.1.1.2">𝒄</ci><apply id="S2.SS3.p1.7.m3.1.1.3.cmml" xref="S2.SS3.p1.7.m3.1.1.3"><csymbol cd="ambiguous" id="S2.SS3.p1.7.m3.1.1.3.1.cmml" xref="S2.SS3.p1.7.m3.1.1.3">superscript</csymbol><ci id="S2.SS3.p1.7.m3.1.1.3.2.cmml" xref="S2.SS3.p1.7.m3.1.1.3.2">ℝ</ci><ci id="S2.SS3.p1.7.m3.1.1.3.3.cmml" xref="S2.SS3.p1.7.m3.1.1.3.3">𝑟</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.7.m3.1c">\bm{c}\in\mathbb{R}^{r}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p1.7.m3.1d">bold_italic_c ∈ blackboard_R start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT</annotation></semantics></math> are (discrete) parameters.<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>The SSM equations are commonly written independenty for each input dimension <math alttext="j\in[d]" class="ltx_Math" display="inline" id="footnote4.m1.1"><semantics id="footnote4.m1.1b"><mrow id="footnote4.m1.1.2" xref="footnote4.m1.1.2.cmml"><mi id="footnote4.m1.1.2.2" xref="footnote4.m1.1.2.2.cmml">j</mi><mo id="footnote4.m1.1.2.1" xref="footnote4.m1.1.2.1.cmml">∈</mo><mrow id="footnote4.m1.1.2.3.2" xref="footnote4.m1.1.2.3.1.cmml"><mo id="footnote4.m1.1.2.3.2.1" stretchy="false" xref="footnote4.m1.1.2.3.1.1.cmml">[</mo><mi id="footnote4.m1.1.1" xref="footnote4.m1.1.1.cmml">d</mi><mo id="footnote4.m1.1.2.3.2.2" stretchy="false" xref="footnote4.m1.1.2.3.1.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="footnote4.m1.1c"><apply id="footnote4.m1.1.2.cmml" xref="footnote4.m1.1.2"><in id="footnote4.m1.1.2.1.cmml" xref="footnote4.m1.1.2.1"></in><ci id="footnote4.m1.1.2.2.cmml" xref="footnote4.m1.1.2.2">𝑗</ci><apply id="footnote4.m1.1.2.3.1.cmml" xref="footnote4.m1.1.2.3.2"><csymbol cd="latexml" id="footnote4.m1.1.2.3.1.1.cmml" xref="footnote4.m1.1.2.3.2.1">delimited-[]</csymbol><ci id="footnote4.m1.1.1.cmml" xref="footnote4.m1.1.1">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="footnote4.m1.1d">j\in[d]</annotation><annotation encoding="application/x-llamapun" id="footnote4.m1.1e">italic_j ∈ [ italic_d ]</annotation></semantics></math> as

<span class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="A5.EGx5">
<span id="S2.Ex6"><span class="ltx_equation ltx_eqn_row ltx_align_baseline">
<span class="ltx_eqn_cell ltx_eqn_center_padleft"></span>
<span class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\bm{h}_{i}^{(j)}" class="ltx_Math" display="inline" id="S2.Ex6.m1.1"><semantics id="S2.Ex6.m1.1b"><msubsup id="S2.Ex6.m1.1.2" xref="S2.Ex6.m1.1.2.cmml"><mi id="S2.Ex6.m1.1.2.2.2" xref="S2.Ex6.m1.1.2.2.2.cmml">𝒉</mi><mi id="S2.Ex6.m1.1.2.2.3" xref="S2.Ex6.m1.1.2.2.3.cmml">i</mi><mrow id="S2.Ex6.m1.1.1.1.3" xref="S2.Ex6.m1.1.2.cmml"><mo id="S2.Ex6.m1.1.1.1.3.1" stretchy="false" xref="S2.Ex6.m1.1.2.cmml">(</mo><mi id="S2.Ex6.m1.1.1.1.1" xref="S2.Ex6.m1.1.1.1.1.cmml">j</mi><mo id="S2.Ex6.m1.1.1.1.3.2" stretchy="false" xref="S2.Ex6.m1.1.2.cmml">)</mo></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S2.Ex6.m1.1c"><apply id="S2.Ex6.m1.1.2.cmml" xref="S2.Ex6.m1.1.2"><csymbol cd="ambiguous" id="S2.Ex6.m1.1.2.1.cmml" xref="S2.Ex6.m1.1.2">superscript</csymbol><apply id="S2.Ex6.m1.1.2.2.cmml" xref="S2.Ex6.m1.1.2"><csymbol cd="ambiguous" id="S2.Ex6.m1.1.2.2.1.cmml" xref="S2.Ex6.m1.1.2">subscript</csymbol><ci id="S2.Ex6.m1.1.2.2.2.cmml" xref="S2.Ex6.m1.1.2.2.2">𝒉</ci><ci id="S2.Ex6.m1.1.2.2.3.cmml" xref="S2.Ex6.m1.1.2.2.3">𝑖</ci></apply><ci id="S2.Ex6.m1.1.1.1.1.cmml" xref="S2.Ex6.m1.1.1.1.1">𝑗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex6.m1.1d">\displaystyle\bm{h}_{i}^{(j)}</annotation><annotation encoding="application/x-llamapun" id="S2.Ex6.m1.1e">bold_italic_h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_j ) end_POSTSUPERSCRIPT</annotation></semantics></math></span>
<span class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle=\bm{A}\bm{h}_{i-1}^{(j)}+\bm{b}x_{i}^{(j)},\quad y_{i}^{(j)}=\bm%
{c}^{\top}\bm{h}_{i}^{(j)}," class="ltx_Math" display="inline" id="S2.Ex6.m2.5"><semantics id="S2.Ex6.m2.5b"><mrow id="S2.Ex6.m2.5.5.1"><mrow id="S2.Ex6.m2.5.5.1.1.2" xref="S2.Ex6.m2.5.5.1.1.3.cmml"><mrow id="S2.Ex6.m2.5.5.1.1.1.1" xref="S2.Ex6.m2.5.5.1.1.1.1.cmml"><mi id="S2.Ex6.m2.5.5.1.1.1.1.2" xref="S2.Ex6.m2.5.5.1.1.1.1.2.cmml"></mi><mo id="S2.Ex6.m2.5.5.1.1.1.1.1" xref="S2.Ex6.m2.5.5.1.1.1.1.1.cmml">=</mo><mrow id="S2.Ex6.m2.5.5.1.1.1.1.3" xref="S2.Ex6.m2.5.5.1.1.1.1.3.cmml"><mrow id="S2.Ex6.m2.5.5.1.1.1.1.3.2" xref="S2.Ex6.m2.5.5.1.1.1.1.3.2.cmml"><mi id="S2.Ex6.m2.5.5.1.1.1.1.3.2.2" xref="S2.Ex6.m2.5.5.1.1.1.1.3.2.2.cmml">𝑨</mi><mo id="S2.Ex6.m2.5.5.1.1.1.1.3.2.1" xref="S2.Ex6.m2.5.5.1.1.1.1.3.2.1.cmml">⁢</mo><msubsup id="S2.Ex6.m2.5.5.1.1.1.1.3.2.3" xref="S2.Ex6.m2.5.5.1.1.1.1.3.2.3.cmml"><mi id="S2.Ex6.m2.5.5.1.1.1.1.3.2.3.2.2" xref="S2.Ex6.m2.5.5.1.1.1.1.3.2.3.2.2.cmml">𝒉</mi><mrow id="S2.Ex6.m2.5.5.1.1.1.1.3.2.3.2.3" xref="S2.Ex6.m2.5.5.1.1.1.1.3.2.3.2.3.cmml"><mi id="S2.Ex6.m2.5.5.1.1.1.1.3.2.3.2.3.2" xref="S2.Ex6.m2.5.5.1.1.1.1.3.2.3.2.3.2.cmml">i</mi><mo id="S2.Ex6.m2.5.5.1.1.1.1.3.2.3.2.3.1" xref="S2.Ex6.m2.5.5.1.1.1.1.3.2.3.2.3.1.cmml">−</mo><mn id="S2.Ex6.m2.5.5.1.1.1.1.3.2.3.2.3.3" xref="S2.Ex6.m2.5.5.1.1.1.1.3.2.3.2.3.3.cmml">1</mn></mrow><mrow id="S2.Ex6.m2.1.1.1.3" xref="S2.Ex6.m2.5.5.1.1.1.1.3.2.3.cmml"><mo id="S2.Ex6.m2.1.1.1.3.1" stretchy="false" xref="S2.Ex6.m2.5.5.1.1.1.1.3.2.3.cmml">(</mo><mi id="S2.Ex6.m2.1.1.1.1" xref="S2.Ex6.m2.1.1.1.1.cmml">j</mi><mo id="S2.Ex6.m2.1.1.1.3.2" stretchy="false" xref="S2.Ex6.m2.5.5.1.1.1.1.3.2.3.cmml">)</mo></mrow></msubsup></mrow><mo id="S2.Ex6.m2.5.5.1.1.1.1.3.1" xref="S2.Ex6.m2.5.5.1.1.1.1.3.1.cmml">+</mo><mrow id="S2.Ex6.m2.5.5.1.1.1.1.3.3" xref="S2.Ex6.m2.5.5.1.1.1.1.3.3.cmml"><mi id="S2.Ex6.m2.5.5.1.1.1.1.3.3.2" xref="S2.Ex6.m2.5.5.1.1.1.1.3.3.2.cmml">𝒃</mi><mo id="S2.Ex6.m2.5.5.1.1.1.1.3.3.1" xref="S2.Ex6.m2.5.5.1.1.1.1.3.3.1.cmml">⁢</mo><msubsup id="S2.Ex6.m2.5.5.1.1.1.1.3.3.3" xref="S2.Ex6.m2.5.5.1.1.1.1.3.3.3.cmml"><mi id="S2.Ex6.m2.5.5.1.1.1.1.3.3.3.2.2" xref="S2.Ex6.m2.5.5.1.1.1.1.3.3.3.2.2.cmml">x</mi><mi id="S2.Ex6.m2.5.5.1.1.1.1.3.3.3.2.3" xref="S2.Ex6.m2.5.5.1.1.1.1.3.3.3.2.3.cmml">i</mi><mrow id="S2.Ex6.m2.2.2.1.3" xref="S2.Ex6.m2.5.5.1.1.1.1.3.3.3.cmml"><mo id="S2.Ex6.m2.2.2.1.3.1" stretchy="false" xref="S2.Ex6.m2.5.5.1.1.1.1.3.3.3.cmml">(</mo><mi id="S2.Ex6.m2.2.2.1.1" xref="S2.Ex6.m2.2.2.1.1.cmml">j</mi><mo id="S2.Ex6.m2.2.2.1.3.2" stretchy="false" xref="S2.Ex6.m2.5.5.1.1.1.1.3.3.3.cmml">)</mo></mrow></msubsup></mrow></mrow></mrow><mo id="S2.Ex6.m2.5.5.1.1.2.3" rspace="1.167em" xref="S2.Ex6.m2.5.5.1.1.3a.cmml">,</mo><mrow id="S2.Ex6.m2.5.5.1.1.2.2" xref="S2.Ex6.m2.5.5.1.1.2.2.cmml"><msubsup id="S2.Ex6.m2.5.5.1.1.2.2.2" xref="S2.Ex6.m2.5.5.1.1.2.2.2.cmml"><mi id="S2.Ex6.m2.5.5.1.1.2.2.2.2.2" xref="S2.Ex6.m2.5.5.1.1.2.2.2.2.2.cmml">y</mi><mi id="S2.Ex6.m2.5.5.1.1.2.2.2.2.3" xref="S2.Ex6.m2.5.5.1.1.2.2.2.2.3.cmml">i</mi><mrow id="S2.Ex6.m2.3.3.1.3" xref="S2.Ex6.m2.5.5.1.1.2.2.2.cmml"><mo id="S2.Ex6.m2.3.3.1.3.1" stretchy="false" xref="S2.Ex6.m2.5.5.1.1.2.2.2.cmml">(</mo><mi id="S2.Ex6.m2.3.3.1.1" xref="S2.Ex6.m2.3.3.1.1.cmml">j</mi><mo id="S2.Ex6.m2.3.3.1.3.2" stretchy="false" xref="S2.Ex6.m2.5.5.1.1.2.2.2.cmml">)</mo></mrow></msubsup><mo id="S2.Ex6.m2.5.5.1.1.2.2.1" xref="S2.Ex6.m2.5.5.1.1.2.2.1.cmml">=</mo><mrow id="S2.Ex6.m2.5.5.1.1.2.2.3" xref="S2.Ex6.m2.5.5.1.1.2.2.3.cmml"><msup id="S2.Ex6.m2.5.5.1.1.2.2.3.2" xref="S2.Ex6.m2.5.5.1.1.2.2.3.2.cmml"><mi id="S2.Ex6.m2.5.5.1.1.2.2.3.2.2" xref="S2.Ex6.m2.5.5.1.1.2.2.3.2.2.cmml">𝒄</mi><mo id="S2.Ex6.m2.5.5.1.1.2.2.3.2.3" xref="S2.Ex6.m2.5.5.1.1.2.2.3.2.3.cmml">⊤</mo></msup><mo id="S2.Ex6.m2.5.5.1.1.2.2.3.1" xref="S2.Ex6.m2.5.5.1.1.2.2.3.1.cmml">⁢</mo><msubsup id="S2.Ex6.m2.5.5.1.1.2.2.3.3" xref="S2.Ex6.m2.5.5.1.1.2.2.3.3.cmml"><mi id="S2.Ex6.m2.5.5.1.1.2.2.3.3.2.2" xref="S2.Ex6.m2.5.5.1.1.2.2.3.3.2.2.cmml">𝒉</mi><mi id="S2.Ex6.m2.5.5.1.1.2.2.3.3.2.3" xref="S2.Ex6.m2.5.5.1.1.2.2.3.3.2.3.cmml">i</mi><mrow id="S2.Ex6.m2.4.4.1.3" xref="S2.Ex6.m2.5.5.1.1.2.2.3.3.cmml"><mo id="S2.Ex6.m2.4.4.1.3.1" stretchy="false" xref="S2.Ex6.m2.5.5.1.1.2.2.3.3.cmml">(</mo><mi id="S2.Ex6.m2.4.4.1.1" xref="S2.Ex6.m2.4.4.1.1.cmml">j</mi><mo id="S2.Ex6.m2.4.4.1.3.2" stretchy="false" xref="S2.Ex6.m2.5.5.1.1.2.2.3.3.cmml">)</mo></mrow></msubsup></mrow></mrow></mrow><mo id="S2.Ex6.m2.5.5.1.2">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.Ex6.m2.5c"><apply id="S2.Ex6.m2.5.5.1.1.3.cmml" xref="S2.Ex6.m2.5.5.1.1.2"><csymbol cd="ambiguous" id="S2.Ex6.m2.5.5.1.1.3a.cmml" xref="S2.Ex6.m2.5.5.1.1.2.3">formulae-sequence</csymbol><apply id="S2.Ex6.m2.5.5.1.1.1.1.cmml" xref="S2.Ex6.m2.5.5.1.1.1.1"><eq id="S2.Ex6.m2.5.5.1.1.1.1.1.cmml" xref="S2.Ex6.m2.5.5.1.1.1.1.1"></eq><csymbol cd="latexml" id="S2.Ex6.m2.5.5.1.1.1.1.2.cmml" xref="S2.Ex6.m2.5.5.1.1.1.1.2">absent</csymbol><apply id="S2.Ex6.m2.5.5.1.1.1.1.3.cmml" xref="S2.Ex6.m2.5.5.1.1.1.1.3"><plus id="S2.Ex6.m2.5.5.1.1.1.1.3.1.cmml" xref="S2.Ex6.m2.5.5.1.1.1.1.3.1"></plus><apply id="S2.Ex6.m2.5.5.1.1.1.1.3.2.cmml" xref="S2.Ex6.m2.5.5.1.1.1.1.3.2"><times id="S2.Ex6.m2.5.5.1.1.1.1.3.2.1.cmml" xref="S2.Ex6.m2.5.5.1.1.1.1.3.2.1"></times><ci id="S2.Ex6.m2.5.5.1.1.1.1.3.2.2.cmml" xref="S2.Ex6.m2.5.5.1.1.1.1.3.2.2">𝑨</ci><apply id="S2.Ex6.m2.5.5.1.1.1.1.3.2.3.cmml" xref="S2.Ex6.m2.5.5.1.1.1.1.3.2.3"><csymbol cd="ambiguous" id="S2.Ex6.m2.5.5.1.1.1.1.3.2.3.1.cmml" xref="S2.Ex6.m2.5.5.1.1.1.1.3.2.3">superscript</csymbol><apply id="S2.Ex6.m2.5.5.1.1.1.1.3.2.3.2.cmml" xref="S2.Ex6.m2.5.5.1.1.1.1.3.2.3"><csymbol cd="ambiguous" id="S2.Ex6.m2.5.5.1.1.1.1.3.2.3.2.1.cmml" xref="S2.Ex6.m2.5.5.1.1.1.1.3.2.3">subscript</csymbol><ci id="S2.Ex6.m2.5.5.1.1.1.1.3.2.3.2.2.cmml" xref="S2.Ex6.m2.5.5.1.1.1.1.3.2.3.2.2">𝒉</ci><apply id="S2.Ex6.m2.5.5.1.1.1.1.3.2.3.2.3.cmml" xref="S2.Ex6.m2.5.5.1.1.1.1.3.2.3.2.3"><minus id="S2.Ex6.m2.5.5.1.1.1.1.3.2.3.2.3.1.cmml" xref="S2.Ex6.m2.5.5.1.1.1.1.3.2.3.2.3.1"></minus><ci id="S2.Ex6.m2.5.5.1.1.1.1.3.2.3.2.3.2.cmml" xref="S2.Ex6.m2.5.5.1.1.1.1.3.2.3.2.3.2">𝑖</ci><cn id="S2.Ex6.m2.5.5.1.1.1.1.3.2.3.2.3.3.cmml" type="integer" xref="S2.Ex6.m2.5.5.1.1.1.1.3.2.3.2.3.3">1</cn></apply></apply><ci id="S2.Ex6.m2.1.1.1.1.cmml" xref="S2.Ex6.m2.1.1.1.1">𝑗</ci></apply></apply><apply id="S2.Ex6.m2.5.5.1.1.1.1.3.3.cmml" xref="S2.Ex6.m2.5.5.1.1.1.1.3.3"><times id="S2.Ex6.m2.5.5.1.1.1.1.3.3.1.cmml" xref="S2.Ex6.m2.5.5.1.1.1.1.3.3.1"></times><ci id="S2.Ex6.m2.5.5.1.1.1.1.3.3.2.cmml" xref="S2.Ex6.m2.5.5.1.1.1.1.3.3.2">𝒃</ci><apply id="S2.Ex6.m2.5.5.1.1.1.1.3.3.3.cmml" xref="S2.Ex6.m2.5.5.1.1.1.1.3.3.3"><csymbol cd="ambiguous" id="S2.Ex6.m2.5.5.1.1.1.1.3.3.3.1.cmml" xref="S2.Ex6.m2.5.5.1.1.1.1.3.3.3">superscript</csymbol><apply id="S2.Ex6.m2.5.5.1.1.1.1.3.3.3.2.cmml" xref="S2.Ex6.m2.5.5.1.1.1.1.3.3.3"><csymbol cd="ambiguous" id="S2.Ex6.m2.5.5.1.1.1.1.3.3.3.2.1.cmml" xref="S2.Ex6.m2.5.5.1.1.1.1.3.3.3">subscript</csymbol><ci id="S2.Ex6.m2.5.5.1.1.1.1.3.3.3.2.2.cmml" xref="S2.Ex6.m2.5.5.1.1.1.1.3.3.3.2.2">𝑥</ci><ci id="S2.Ex6.m2.5.5.1.1.1.1.3.3.3.2.3.cmml" xref="S2.Ex6.m2.5.5.1.1.1.1.3.3.3.2.3">𝑖</ci></apply><ci id="S2.Ex6.m2.2.2.1.1.cmml" xref="S2.Ex6.m2.2.2.1.1">𝑗</ci></apply></apply></apply></apply><apply id="S2.Ex6.m2.5.5.1.1.2.2.cmml" xref="S2.Ex6.m2.5.5.1.1.2.2"><eq id="S2.Ex6.m2.5.5.1.1.2.2.1.cmml" xref="S2.Ex6.m2.5.5.1.1.2.2.1"></eq><apply id="S2.Ex6.m2.5.5.1.1.2.2.2.cmml" xref="S2.Ex6.m2.5.5.1.1.2.2.2"><csymbol cd="ambiguous" id="S2.Ex6.m2.5.5.1.1.2.2.2.1.cmml" xref="S2.Ex6.m2.5.5.1.1.2.2.2">superscript</csymbol><apply id="S2.Ex6.m2.5.5.1.1.2.2.2.2.cmml" xref="S2.Ex6.m2.5.5.1.1.2.2.2"><csymbol cd="ambiguous" id="S2.Ex6.m2.5.5.1.1.2.2.2.2.1.cmml" xref="S2.Ex6.m2.5.5.1.1.2.2.2">subscript</csymbol><ci id="S2.Ex6.m2.5.5.1.1.2.2.2.2.2.cmml" xref="S2.Ex6.m2.5.5.1.1.2.2.2.2.2">𝑦</ci><ci id="S2.Ex6.m2.5.5.1.1.2.2.2.2.3.cmml" xref="S2.Ex6.m2.5.5.1.1.2.2.2.2.3">𝑖</ci></apply><ci id="S2.Ex6.m2.3.3.1.1.cmml" xref="S2.Ex6.m2.3.3.1.1">𝑗</ci></apply><apply id="S2.Ex6.m2.5.5.1.1.2.2.3.cmml" xref="S2.Ex6.m2.5.5.1.1.2.2.3"><times id="S2.Ex6.m2.5.5.1.1.2.2.3.1.cmml" xref="S2.Ex6.m2.5.5.1.1.2.2.3.1"></times><apply id="S2.Ex6.m2.5.5.1.1.2.2.3.2.cmml" xref="S2.Ex6.m2.5.5.1.1.2.2.3.2"><csymbol cd="ambiguous" id="S2.Ex6.m2.5.5.1.1.2.2.3.2.1.cmml" xref="S2.Ex6.m2.5.5.1.1.2.2.3.2">superscript</csymbol><ci id="S2.Ex6.m2.5.5.1.1.2.2.3.2.2.cmml" xref="S2.Ex6.m2.5.5.1.1.2.2.3.2.2">𝒄</ci><csymbol cd="latexml" id="S2.Ex6.m2.5.5.1.1.2.2.3.2.3.cmml" xref="S2.Ex6.m2.5.5.1.1.2.2.3.2.3">top</csymbol></apply><apply id="S2.Ex6.m2.5.5.1.1.2.2.3.3.cmml" xref="S2.Ex6.m2.5.5.1.1.2.2.3.3"><csymbol cd="ambiguous" id="S2.Ex6.m2.5.5.1.1.2.2.3.3.1.cmml" xref="S2.Ex6.m2.5.5.1.1.2.2.3.3">superscript</csymbol><apply id="S2.Ex6.m2.5.5.1.1.2.2.3.3.2.cmml" xref="S2.Ex6.m2.5.5.1.1.2.2.3.3"><csymbol cd="ambiguous" id="S2.Ex6.m2.5.5.1.1.2.2.3.3.2.1.cmml" xref="S2.Ex6.m2.5.5.1.1.2.2.3.3">subscript</csymbol><ci id="S2.Ex6.m2.5.5.1.1.2.2.3.3.2.2.cmml" xref="S2.Ex6.m2.5.5.1.1.2.2.3.3.2.2">𝒉</ci><ci id="S2.Ex6.m2.5.5.1.1.2.2.3.3.2.3.cmml" xref="S2.Ex6.m2.5.5.1.1.2.2.3.3.2.3">𝑖</ci></apply><ci id="S2.Ex6.m2.4.4.1.1.cmml" xref="S2.Ex6.m2.4.4.1.1">𝑗</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex6.m2.5d">\displaystyle=\bm{A}\bm{h}_{i-1}^{(j)}+\bm{b}x_{i}^{(j)},\quad y_{i}^{(j)}=\bm%
{c}^{\top}\bm{h}_{i}^{(j)},</annotation><annotation encoding="application/x-llamapun" id="S2.Ex6.m2.5e">= bold_italic_A bold_italic_h start_POSTSUBSCRIPT italic_i - 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_j ) end_POSTSUPERSCRIPT + bold_italic_b italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_j ) end_POSTSUPERSCRIPT , italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_j ) end_POSTSUPERSCRIPT = bold_italic_c start_POSTSUPERSCRIPT ⊤ end_POSTSUPERSCRIPT bold_italic_h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_j ) end_POSTSUPERSCRIPT ,</annotation></semantics></math></span>
<span class="ltx_eqn_cell ltx_eqn_center_padright"></span></span></span>
</span>
with <math alttext="\bm{A}" class="ltx_Math" display="inline" id="footnote4.m2.1"><semantics id="footnote4.m2.1b"><mi id="footnote4.m2.1.1" xref="footnote4.m2.1.1.cmml">𝑨</mi><annotation-xml encoding="MathML-Content" id="footnote4.m2.1c"><ci id="footnote4.m2.1.1.cmml" xref="footnote4.m2.1.1">𝑨</ci></annotation-xml><annotation encoding="application/x-tex" id="footnote4.m2.1d">\bm{A}</annotation><annotation encoding="application/x-llamapun" id="footnote4.m2.1e">bold_italic_A</annotation></semantics></math>, <math alttext="\bm{b}" class="ltx_Math" display="inline" id="footnote4.m3.1"><semantics id="footnote4.m3.1b"><mi id="footnote4.m3.1.1" xref="footnote4.m3.1.1.cmml">𝒃</mi><annotation-xml encoding="MathML-Content" id="footnote4.m3.1c"><ci id="footnote4.m3.1.1.cmml" xref="footnote4.m3.1.1">𝒃</ci></annotation-xml><annotation encoding="application/x-tex" id="footnote4.m3.1d">\bm{b}</annotation><annotation encoding="application/x-llamapun" id="footnote4.m3.1e">bold_italic_b</annotation></semantics></math>, and <math alttext="\bm{c}" class="ltx_Math" display="inline" id="footnote4.m4.1"><semantics id="footnote4.m4.1b"><mi id="footnote4.m4.1.1" xref="footnote4.m4.1.1.cmml">𝒄</mi><annotation-xml encoding="MathML-Content" id="footnote4.m4.1c"><ci id="footnote4.m4.1.1.cmml" xref="footnote4.m4.1.1">𝒄</ci></annotation-xml><annotation encoding="application/x-tex" id="footnote4.m4.1d">\bm{c}</annotation><annotation encoding="application/x-llamapun" id="footnote4.m4.1e">bold_italic_c</annotation></semantics></math> shared across input dimensions. This is equivalent to (<a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#S2.Ex5" title="2.3 State Space Models (SSMs) ‣ 2 Background ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_tag">2.3</span></a>), where the <math alttext="j\textsuperscript{th}" class="ltx_Math" display="inline" id="footnote4.m5.1"><semantics id="footnote4.m5.1b"><mrow id="footnote4.m5.1.1" xref="footnote4.m5.1.1.cmml"><mi id="footnote4.m5.1.1.2" xref="footnote4.m5.1.1.2.cmml">j</mi><mo id="footnote4.m5.1.1.1" xref="footnote4.m5.1.1.1.cmml">⁢</mo><mtext id="footnote4.m5.1.1.3" xref="footnote4.m5.1.1.3b.cmml"><sup class="ltx_sup" id="footnote4.m5.1.1.3.1nest">th</sup></mtext></mrow><annotation-xml encoding="MathML-Content" id="footnote4.m5.1c"><apply id="footnote4.m5.1.1.cmml" xref="footnote4.m5.1.1"><times id="footnote4.m5.1.1.1.cmml" xref="footnote4.m5.1.1.1"></times><ci id="footnote4.m5.1.1.2.cmml" xref="footnote4.m5.1.1.2">𝑗</ci><ci id="footnote4.m5.1.1.3b.cmml" xref="footnote4.m5.1.1.3"><mtext id="footnote4.m5.1.1.3.cmml" xref="footnote4.m5.1.1.3"><sup class="ltx_sup" id="footnote4.m5.1.1.3.1anest">th</sup></mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="footnote4.m5.1d">j\textsuperscript{th}</annotation><annotation encoding="application/x-llamapun" id="footnote4.m5.1e">italic_j</annotation></semantics></math>-column of <math alttext="\bm{H}_{i}" class="ltx_Math" display="inline" id="footnote4.m6.1"><semantics id="footnote4.m6.1b"><msub id="footnote4.m6.1.1" xref="footnote4.m6.1.1.cmml"><mi id="footnote4.m6.1.1.2" xref="footnote4.m6.1.1.2.cmml">𝑯</mi><mi id="footnote4.m6.1.1.3" xref="footnote4.m6.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="footnote4.m6.1c"><apply id="footnote4.m6.1.1.cmml" xref="footnote4.m6.1.1"><csymbol cd="ambiguous" id="footnote4.m6.1.1.1.cmml" xref="footnote4.m6.1.1">subscript</csymbol><ci id="footnote4.m6.1.1.2.cmml" xref="footnote4.m6.1.1.2">𝑯</ci><ci id="footnote4.m6.1.1.3.cmml" xref="footnote4.m6.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="footnote4.m6.1d">\bm{H}_{i}</annotation><annotation encoding="application/x-llamapun" id="footnote4.m6.1e">bold_italic_H start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> equals <math alttext="\bm{h}_{i}^{(j)}" class="ltx_Math" display="inline" id="footnote4.m7.1"><semantics id="footnote4.m7.1b"><msubsup id="footnote4.m7.1.2" xref="footnote4.m7.1.2.cmml"><mi id="footnote4.m7.1.2.2.2" xref="footnote4.m7.1.2.2.2.cmml">𝒉</mi><mi id="footnote4.m7.1.2.2.3" xref="footnote4.m7.1.2.2.3.cmml">i</mi><mrow id="footnote4.m7.1.1.1.3" xref="footnote4.m7.1.2.cmml"><mo id="footnote4.m7.1.1.1.3.1" stretchy="false" xref="footnote4.m7.1.2.cmml">(</mo><mi id="footnote4.m7.1.1.1.1" xref="footnote4.m7.1.1.1.1.cmml">j</mi><mo id="footnote4.m7.1.1.1.3.2" stretchy="false" xref="footnote4.m7.1.2.cmml">)</mo></mrow></msubsup><annotation-xml encoding="MathML-Content" id="footnote4.m7.1c"><apply id="footnote4.m7.1.2.cmml" xref="footnote4.m7.1.2"><csymbol cd="ambiguous" id="footnote4.m7.1.2.1.cmml" xref="footnote4.m7.1.2">superscript</csymbol><apply id="footnote4.m7.1.2.2.cmml" xref="footnote4.m7.1.2"><csymbol cd="ambiguous" id="footnote4.m7.1.2.2.1.cmml" xref="footnote4.m7.1.2">subscript</csymbol><ci id="footnote4.m7.1.2.2.2.cmml" xref="footnote4.m7.1.2.2.2">𝒉</ci><ci id="footnote4.m7.1.2.2.3.cmml" xref="footnote4.m7.1.2.2.3">𝑖</ci></apply><ci id="footnote4.m7.1.1.1.1.cmml" xref="footnote4.m7.1.1.1.1">𝑗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="footnote4.m7.1d">\bm{h}_{i}^{(j)}</annotation><annotation encoding="application/x-llamapun" id="footnote4.m7.1e">bold_italic_h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_j ) end_POSTSUPERSCRIPT</annotation></semantics></math>.</span></span></span> Since the same parameters are used for both relevant and irrelevant inputs, this model is deemed <em class="ltx_emph ltx_font_italic" id="S2.SS3.p1.12.1">input-independent</em>,
which, in turn, makes the model unable to reset or overwrite its hidden states. S4 <cite class="ltx_cite ltx_citemacro_citep">(Gu et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib21" title="">2022</a>)</cite> is an instance of this model, which enjoys a <math alttext="\mathcal{O}\left(n\log n\right)" class="ltx_Math" display="inline" id="S2.SS3.p1.8.m4.1"><semantics id="S2.SS3.p1.8.m4.1a"><mrow id="S2.SS3.p1.8.m4.1.1" xref="S2.SS3.p1.8.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS3.p1.8.m4.1.1.3" xref="S2.SS3.p1.8.m4.1.1.3.cmml">𝒪</mi><mo id="S2.SS3.p1.8.m4.1.1.2" xref="S2.SS3.p1.8.m4.1.1.2.cmml">⁢</mo><mrow id="S2.SS3.p1.8.m4.1.1.1.1" xref="S2.SS3.p1.8.m4.1.1.1.1.1.cmml"><mo id="S2.SS3.p1.8.m4.1.1.1.1.2" xref="S2.SS3.p1.8.m4.1.1.1.1.1.cmml">(</mo><mrow id="S2.SS3.p1.8.m4.1.1.1.1.1" xref="S2.SS3.p1.8.m4.1.1.1.1.1.cmml"><mi id="S2.SS3.p1.8.m4.1.1.1.1.1.2" xref="S2.SS3.p1.8.m4.1.1.1.1.1.2.cmml">n</mi><mo id="S2.SS3.p1.8.m4.1.1.1.1.1.1" lspace="0.167em" xref="S2.SS3.p1.8.m4.1.1.1.1.1.1.cmml">⁢</mo><mrow id="S2.SS3.p1.8.m4.1.1.1.1.1.3" xref="S2.SS3.p1.8.m4.1.1.1.1.1.3.cmml"><mi id="S2.SS3.p1.8.m4.1.1.1.1.1.3.1" xref="S2.SS3.p1.8.m4.1.1.1.1.1.3.1.cmml">log</mi><mo id="S2.SS3.p1.8.m4.1.1.1.1.1.3a" lspace="0.167em" xref="S2.SS3.p1.8.m4.1.1.1.1.1.3.cmml">⁡</mo><mi id="S2.SS3.p1.8.m4.1.1.1.1.1.3.2" xref="S2.SS3.p1.8.m4.1.1.1.1.1.3.2.cmml">n</mi></mrow></mrow><mo id="S2.SS3.p1.8.m4.1.1.1.1.3" xref="S2.SS3.p1.8.m4.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.8.m4.1b"><apply id="S2.SS3.p1.8.m4.1.1.cmml" xref="S2.SS3.p1.8.m4.1.1"><times id="S2.SS3.p1.8.m4.1.1.2.cmml" xref="S2.SS3.p1.8.m4.1.1.2"></times><ci id="S2.SS3.p1.8.m4.1.1.3.cmml" xref="S2.SS3.p1.8.m4.1.1.3">𝒪</ci><apply id="S2.SS3.p1.8.m4.1.1.1.1.1.cmml" xref="S2.SS3.p1.8.m4.1.1.1.1"><times id="S2.SS3.p1.8.m4.1.1.1.1.1.1.cmml" xref="S2.SS3.p1.8.m4.1.1.1.1.1.1"></times><ci id="S2.SS3.p1.8.m4.1.1.1.1.1.2.cmml" xref="S2.SS3.p1.8.m4.1.1.1.1.1.2">𝑛</ci><apply id="S2.SS3.p1.8.m4.1.1.1.1.1.3.cmml" xref="S2.SS3.p1.8.m4.1.1.1.1.1.3"><log id="S2.SS3.p1.8.m4.1.1.1.1.1.3.1.cmml" xref="S2.SS3.p1.8.m4.1.1.1.1.1.3.1"></log><ci id="S2.SS3.p1.8.m4.1.1.1.1.1.3.2.cmml" xref="S2.SS3.p1.8.m4.1.1.1.1.1.3.2">𝑛</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.8.m4.1c">\mathcal{O}\left(n\log n\right)</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p1.8.m4.1d">caligraphic_O ( italic_n roman_log italic_n )</annotation></semantics></math> time complexity during training, and <math alttext="\mathcal{O}\left(1\right)" class="ltx_Math" display="inline" id="S2.SS3.p1.9.m5.1"><semantics id="S2.SS3.p1.9.m5.1a"><mrow id="S2.SS3.p1.9.m5.1.2" xref="S2.SS3.p1.9.m5.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS3.p1.9.m5.1.2.2" xref="S2.SS3.p1.9.m5.1.2.2.cmml">𝒪</mi><mo id="S2.SS3.p1.9.m5.1.2.1" xref="S2.SS3.p1.9.m5.1.2.1.cmml">⁢</mo><mrow id="S2.SS3.p1.9.m5.1.2.3.2" xref="S2.SS3.p1.9.m5.1.2.cmml"><mo id="S2.SS3.p1.9.m5.1.2.3.2.1" xref="S2.SS3.p1.9.m5.1.2.cmml">(</mo><mn id="S2.SS3.p1.9.m5.1.1" xref="S2.SS3.p1.9.m5.1.1.cmml">1</mn><mo id="S2.SS3.p1.9.m5.1.2.3.2.2" xref="S2.SS3.p1.9.m5.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.9.m5.1b"><apply id="S2.SS3.p1.9.m5.1.2.cmml" xref="S2.SS3.p1.9.m5.1.2"><times id="S2.SS3.p1.9.m5.1.2.1.cmml" xref="S2.SS3.p1.9.m5.1.2.1"></times><ci id="S2.SS3.p1.9.m5.1.2.2.cmml" xref="S2.SS3.p1.9.m5.1.2.2">𝒪</ci><cn id="S2.SS3.p1.9.m5.1.1.cmml" type="integer" xref="S2.SS3.p1.9.m5.1.1">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.9.m5.1c">\mathcal{O}\left(1\right)</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p1.9.m5.1d">caligraphic_O ( 1 )</annotation></semantics></math> during inference.
<cite class="ltx_cite ltx_citemacro_citet">Vardasbi et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib42" title="">2023</a>)</cite> shows that S4 still underperforms transformers for MT.
Finally, note the similarity between Eq. <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#S2.Ex4" title="Retentive Networks (RetNet). ‣ 2.2 Linear Attention ‣ 2 Background ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_tag">2.2</span></a> and Eq. <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#S2.Ex5" title="2.3 State Space Models (SSMs) ‣ 2 Background ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_tag">2.3</span></a>: RetNets can be seen as state space models with <math alttext="\bm{A}=\gamma\bm{I}" class="ltx_Math" display="inline" id="S2.SS3.p1.10.m6.1"><semantics id="S2.SS3.p1.10.m6.1a"><mrow id="S2.SS3.p1.10.m6.1.1" xref="S2.SS3.p1.10.m6.1.1.cmml"><mi id="S2.SS3.p1.10.m6.1.1.2" xref="S2.SS3.p1.10.m6.1.1.2.cmml">𝑨</mi><mo id="S2.SS3.p1.10.m6.1.1.1" xref="S2.SS3.p1.10.m6.1.1.1.cmml">=</mo><mrow id="S2.SS3.p1.10.m6.1.1.3" xref="S2.SS3.p1.10.m6.1.1.3.cmml"><mi id="S2.SS3.p1.10.m6.1.1.3.2" xref="S2.SS3.p1.10.m6.1.1.3.2.cmml">γ</mi><mo id="S2.SS3.p1.10.m6.1.1.3.1" xref="S2.SS3.p1.10.m6.1.1.3.1.cmml">⁢</mo><mi id="S2.SS3.p1.10.m6.1.1.3.3" xref="S2.SS3.p1.10.m6.1.1.3.3.cmml">𝑰</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.10.m6.1b"><apply id="S2.SS3.p1.10.m6.1.1.cmml" xref="S2.SS3.p1.10.m6.1.1"><eq id="S2.SS3.p1.10.m6.1.1.1.cmml" xref="S2.SS3.p1.10.m6.1.1.1"></eq><ci id="S2.SS3.p1.10.m6.1.1.2.cmml" xref="S2.SS3.p1.10.m6.1.1.2">𝑨</ci><apply id="S2.SS3.p1.10.m6.1.1.3.cmml" xref="S2.SS3.p1.10.m6.1.1.3"><times id="S2.SS3.p1.10.m6.1.1.3.1.cmml" xref="S2.SS3.p1.10.m6.1.1.3.1"></times><ci id="S2.SS3.p1.10.m6.1.1.3.2.cmml" xref="S2.SS3.p1.10.m6.1.1.3.2">𝛾</ci><ci id="S2.SS3.p1.10.m6.1.1.3.3.cmml" xref="S2.SS3.p1.10.m6.1.1.3.3">𝑰</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.10.m6.1c">\bm{A}=\gamma\bm{I}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p1.10.m6.1d">bold_italic_A = italic_γ bold_italic_I</annotation></semantics></math> and data-dependent <math alttext="\bm{b}" class="ltx_Math" display="inline" id="S2.SS3.p1.11.m7.1"><semantics id="S2.SS3.p1.11.m7.1a"><mi id="S2.SS3.p1.11.m7.1.1" xref="S2.SS3.p1.11.m7.1.1.cmml">𝒃</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.11.m7.1b"><ci id="S2.SS3.p1.11.m7.1.1.cmml" xref="S2.SS3.p1.11.m7.1.1">𝒃</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.11.m7.1c">\bm{b}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p1.11.m7.1d">bold_italic_b</annotation></semantics></math> and <math alttext="\bm{c}" class="ltx_Math" display="inline" id="S2.SS3.p1.12.m8.1"><semantics id="S2.SS3.p1.12.m8.1a"><mi id="S2.SS3.p1.12.m8.1.1" xref="S2.SS3.p1.12.m8.1.1.cmml">𝒄</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.12.m8.1b"><ci id="S2.SS3.p1.12.m8.1.1.cmml" xref="S2.SS3.p1.12.m8.1.1">𝒄</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.12.m8.1c">\bm{c}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p1.12.m8.1d">bold_italic_c</annotation></semantics></math>.</p>
</div>
<section class="ltx_paragraph" id="S2.SS3.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Mamba.</h5>
<div class="ltx_para" id="S2.SS3.SSS0.Px1.p1">
<p class="ltx_p" id="S2.SS3.SSS0.Px1.p1.2">To make the SSM parameters <em class="ltx_emph ltx_font_italic" id="S2.SS3.SSS0.Px1.p1.2.1">data-dependent</em>, Mamba <cite class="ltx_cite ltx_citemacro_citep">(Gu and Dao, <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib19" title="">2023</a>)</cite> introduces a selection mechanism that uses learnable linear projections over <math alttext="\bm{x}" class="ltx_Math" display="inline" id="S2.SS3.SSS0.Px1.p1.1.m1.1"><semantics id="S2.SS3.SSS0.Px1.p1.1.m1.1a"><mi id="S2.SS3.SSS0.Px1.p1.1.m1.1.1" xref="S2.SS3.SSS0.Px1.p1.1.m1.1.1.cmml">𝒙</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS0.Px1.p1.1.m1.1b"><ci id="S2.SS3.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S2.SS3.SSS0.Px1.p1.1.m1.1.1">𝒙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS0.Px1.p1.1.m1.1c">\bm{x}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.SSS0.Px1.p1.1.m1.1d">bold_italic_x</annotation></semantics></math> prior to the discretization step, effectively making all parameters dependent on the <math alttext="i\textsuperscript{th}" class="ltx_Math" display="inline" id="S2.SS3.SSS0.Px1.p1.2.m2.1"><semantics id="S2.SS3.SSS0.Px1.p1.2.m2.1a"><mrow id="S2.SS3.SSS0.Px1.p1.2.m2.1.1" xref="S2.SS3.SSS0.Px1.p1.2.m2.1.1.cmml"><mi id="S2.SS3.SSS0.Px1.p1.2.m2.1.1.2" xref="S2.SS3.SSS0.Px1.p1.2.m2.1.1.2.cmml">i</mi><mo id="S2.SS3.SSS0.Px1.p1.2.m2.1.1.1" xref="S2.SS3.SSS0.Px1.p1.2.m2.1.1.1.cmml">⁢</mo><mtext id="S2.SS3.SSS0.Px1.p1.2.m2.1.1.3" xref="S2.SS3.SSS0.Px1.p1.2.m2.1.1.3b.cmml"><sup class="ltx_sup" id="S2.SS3.SSS0.Px1.p1.2.m2.1.1.3.1nest">th</sup></mtext></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS0.Px1.p1.2.m2.1b"><apply id="S2.SS3.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S2.SS3.SSS0.Px1.p1.2.m2.1.1"><times id="S2.SS3.SSS0.Px1.p1.2.m2.1.1.1.cmml" xref="S2.SS3.SSS0.Px1.p1.2.m2.1.1.1"></times><ci id="S2.SS3.SSS0.Px1.p1.2.m2.1.1.2.cmml" xref="S2.SS3.SSS0.Px1.p1.2.m2.1.1.2">𝑖</ci><ci id="S2.SS3.SSS0.Px1.p1.2.m2.1.1.3b.cmml" xref="S2.SS3.SSS0.Px1.p1.2.m2.1.1.3"><mtext id="S2.SS3.SSS0.Px1.p1.2.m2.1.1.3.cmml" xref="S2.SS3.SSS0.Px1.p1.2.m2.1.1.3"><sup class="ltx_sup" id="S2.SS3.SSS0.Px1.p1.2.m2.1.1.3.1anest">th</sup></mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS0.Px1.p1.2.m2.1c">i\textsuperscript{th}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.SSS0.Px1.p1.2.m2.1d">italic_i</annotation></semantics></math> input. This leads to:</p>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="A5.EGx6">
<tbody id="S2.Ex7"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\bm{H}_{i}" class="ltx_Math" display="inline" id="S2.Ex7.m1.1"><semantics id="S2.Ex7.m1.1a"><msub id="S2.Ex7.m1.1.1" xref="S2.Ex7.m1.1.1.cmml"><mi id="S2.Ex7.m1.1.1.2" xref="S2.Ex7.m1.1.1.2.cmml">𝑯</mi><mi id="S2.Ex7.m1.1.1.3" xref="S2.Ex7.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.Ex7.m1.1b"><apply id="S2.Ex7.m1.1.1.cmml" xref="S2.Ex7.m1.1.1"><csymbol cd="ambiguous" id="S2.Ex7.m1.1.1.1.cmml" xref="S2.Ex7.m1.1.1">subscript</csymbol><ci id="S2.Ex7.m1.1.1.2.cmml" xref="S2.Ex7.m1.1.1.2">𝑯</ci><ci id="S2.Ex7.m1.1.1.3.cmml" xref="S2.Ex7.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex7.m1.1c">\displaystyle\bm{H}_{i}</annotation><annotation encoding="application/x-llamapun" id="S2.Ex7.m1.1d">bold_italic_H start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle=\bm{A}_{i}\odot\bm{H}_{i-1}+\bm{B}_{i}\odot\bm{X}_{i}," class="ltx_Math" display="inline" id="S2.Ex7.m2.1"><semantics id="S2.Ex7.m2.1a"><mrow id="S2.Ex7.m2.1.1.1" xref="S2.Ex7.m2.1.1.1.1.cmml"><mrow id="S2.Ex7.m2.1.1.1.1" xref="S2.Ex7.m2.1.1.1.1.cmml"><mi id="S2.Ex7.m2.1.1.1.1.2" xref="S2.Ex7.m2.1.1.1.1.2.cmml"></mi><mo id="S2.Ex7.m2.1.1.1.1.1" xref="S2.Ex7.m2.1.1.1.1.1.cmml">=</mo><mrow id="S2.Ex7.m2.1.1.1.1.3" xref="S2.Ex7.m2.1.1.1.1.3.cmml"><mrow id="S2.Ex7.m2.1.1.1.1.3.2" xref="S2.Ex7.m2.1.1.1.1.3.2.cmml"><msub id="S2.Ex7.m2.1.1.1.1.3.2.2" xref="S2.Ex7.m2.1.1.1.1.3.2.2.cmml"><mi id="S2.Ex7.m2.1.1.1.1.3.2.2.2" xref="S2.Ex7.m2.1.1.1.1.3.2.2.2.cmml">𝑨</mi><mi id="S2.Ex7.m2.1.1.1.1.3.2.2.3" xref="S2.Ex7.m2.1.1.1.1.3.2.2.3.cmml">i</mi></msub><mo id="S2.Ex7.m2.1.1.1.1.3.2.1" lspace="0.222em" rspace="0.222em" xref="S2.Ex7.m2.1.1.1.1.3.2.1.cmml">⊙</mo><msub id="S2.Ex7.m2.1.1.1.1.3.2.3" xref="S2.Ex7.m2.1.1.1.1.3.2.3.cmml"><mi id="S2.Ex7.m2.1.1.1.1.3.2.3.2" xref="S2.Ex7.m2.1.1.1.1.3.2.3.2.cmml">𝑯</mi><mrow id="S2.Ex7.m2.1.1.1.1.3.2.3.3" xref="S2.Ex7.m2.1.1.1.1.3.2.3.3.cmml"><mi id="S2.Ex7.m2.1.1.1.1.3.2.3.3.2" xref="S2.Ex7.m2.1.1.1.1.3.2.3.3.2.cmml">i</mi><mo id="S2.Ex7.m2.1.1.1.1.3.2.3.3.1" xref="S2.Ex7.m2.1.1.1.1.3.2.3.3.1.cmml">−</mo><mn id="S2.Ex7.m2.1.1.1.1.3.2.3.3.3" xref="S2.Ex7.m2.1.1.1.1.3.2.3.3.3.cmml">1</mn></mrow></msub></mrow><mo id="S2.Ex7.m2.1.1.1.1.3.1" xref="S2.Ex7.m2.1.1.1.1.3.1.cmml">+</mo><mrow id="S2.Ex7.m2.1.1.1.1.3.3" xref="S2.Ex7.m2.1.1.1.1.3.3.cmml"><msub id="S2.Ex7.m2.1.1.1.1.3.3.2" xref="S2.Ex7.m2.1.1.1.1.3.3.2.cmml"><mi id="S2.Ex7.m2.1.1.1.1.3.3.2.2" xref="S2.Ex7.m2.1.1.1.1.3.3.2.2.cmml">𝑩</mi><mi id="S2.Ex7.m2.1.1.1.1.3.3.2.3" xref="S2.Ex7.m2.1.1.1.1.3.3.2.3.cmml">i</mi></msub><mo id="S2.Ex7.m2.1.1.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S2.Ex7.m2.1.1.1.1.3.3.1.cmml">⊙</mo><msub id="S2.Ex7.m2.1.1.1.1.3.3.3" xref="S2.Ex7.m2.1.1.1.1.3.3.3.cmml"><mi id="S2.Ex7.m2.1.1.1.1.3.3.3.2" xref="S2.Ex7.m2.1.1.1.1.3.3.3.2.cmml">𝑿</mi><mi id="S2.Ex7.m2.1.1.1.1.3.3.3.3" xref="S2.Ex7.m2.1.1.1.1.3.3.3.3.cmml">i</mi></msub></mrow></mrow></mrow><mo id="S2.Ex7.m2.1.1.1.2" xref="S2.Ex7.m2.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.Ex7.m2.1b"><apply id="S2.Ex7.m2.1.1.1.1.cmml" xref="S2.Ex7.m2.1.1.1"><eq id="S2.Ex7.m2.1.1.1.1.1.cmml" xref="S2.Ex7.m2.1.1.1.1.1"></eq><csymbol cd="latexml" id="S2.Ex7.m2.1.1.1.1.2.cmml" xref="S2.Ex7.m2.1.1.1.1.2">absent</csymbol><apply id="S2.Ex7.m2.1.1.1.1.3.cmml" xref="S2.Ex7.m2.1.1.1.1.3"><plus id="S2.Ex7.m2.1.1.1.1.3.1.cmml" xref="S2.Ex7.m2.1.1.1.1.3.1"></plus><apply id="S2.Ex7.m2.1.1.1.1.3.2.cmml" xref="S2.Ex7.m2.1.1.1.1.3.2"><csymbol cd="latexml" id="S2.Ex7.m2.1.1.1.1.3.2.1.cmml" xref="S2.Ex7.m2.1.1.1.1.3.2.1">direct-product</csymbol><apply id="S2.Ex7.m2.1.1.1.1.3.2.2.cmml" xref="S2.Ex7.m2.1.1.1.1.3.2.2"><csymbol cd="ambiguous" id="S2.Ex7.m2.1.1.1.1.3.2.2.1.cmml" xref="S2.Ex7.m2.1.1.1.1.3.2.2">subscript</csymbol><ci id="S2.Ex7.m2.1.1.1.1.3.2.2.2.cmml" xref="S2.Ex7.m2.1.1.1.1.3.2.2.2">𝑨</ci><ci id="S2.Ex7.m2.1.1.1.1.3.2.2.3.cmml" xref="S2.Ex7.m2.1.1.1.1.3.2.2.3">𝑖</ci></apply><apply id="S2.Ex7.m2.1.1.1.1.3.2.3.cmml" xref="S2.Ex7.m2.1.1.1.1.3.2.3"><csymbol cd="ambiguous" id="S2.Ex7.m2.1.1.1.1.3.2.3.1.cmml" xref="S2.Ex7.m2.1.1.1.1.3.2.3">subscript</csymbol><ci id="S2.Ex7.m2.1.1.1.1.3.2.3.2.cmml" xref="S2.Ex7.m2.1.1.1.1.3.2.3.2">𝑯</ci><apply id="S2.Ex7.m2.1.1.1.1.3.2.3.3.cmml" xref="S2.Ex7.m2.1.1.1.1.3.2.3.3"><minus id="S2.Ex7.m2.1.1.1.1.3.2.3.3.1.cmml" xref="S2.Ex7.m2.1.1.1.1.3.2.3.3.1"></minus><ci id="S2.Ex7.m2.1.1.1.1.3.2.3.3.2.cmml" xref="S2.Ex7.m2.1.1.1.1.3.2.3.3.2">𝑖</ci><cn id="S2.Ex7.m2.1.1.1.1.3.2.3.3.3.cmml" type="integer" xref="S2.Ex7.m2.1.1.1.1.3.2.3.3.3">1</cn></apply></apply></apply><apply id="S2.Ex7.m2.1.1.1.1.3.3.cmml" xref="S2.Ex7.m2.1.1.1.1.3.3"><csymbol cd="latexml" id="S2.Ex7.m2.1.1.1.1.3.3.1.cmml" xref="S2.Ex7.m2.1.1.1.1.3.3.1">direct-product</csymbol><apply id="S2.Ex7.m2.1.1.1.1.3.3.2.cmml" xref="S2.Ex7.m2.1.1.1.1.3.3.2"><csymbol cd="ambiguous" id="S2.Ex7.m2.1.1.1.1.3.3.2.1.cmml" xref="S2.Ex7.m2.1.1.1.1.3.3.2">subscript</csymbol><ci id="S2.Ex7.m2.1.1.1.1.3.3.2.2.cmml" xref="S2.Ex7.m2.1.1.1.1.3.3.2.2">𝑩</ci><ci id="S2.Ex7.m2.1.1.1.1.3.3.2.3.cmml" xref="S2.Ex7.m2.1.1.1.1.3.3.2.3">𝑖</ci></apply><apply id="S2.Ex7.m2.1.1.1.1.3.3.3.cmml" xref="S2.Ex7.m2.1.1.1.1.3.3.3"><csymbol cd="ambiguous" id="S2.Ex7.m2.1.1.1.1.3.3.3.1.cmml" xref="S2.Ex7.m2.1.1.1.1.3.3.3">subscript</csymbol><ci id="S2.Ex7.m2.1.1.1.1.3.3.3.2.cmml" xref="S2.Ex7.m2.1.1.1.1.3.3.3.2">𝑿</ci><ci id="S2.Ex7.m2.1.1.1.1.3.3.3.3.cmml" xref="S2.Ex7.m2.1.1.1.1.3.3.3.3">𝑖</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex7.m2.1c">\displaystyle=\bm{A}_{i}\odot\bm{H}_{i-1}+\bm{B}_{i}\odot\bm{X}_{i},</annotation><annotation encoding="application/x-llamapun" id="S2.Ex7.m2.1d">= bold_italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ⊙ bold_italic_H start_POSTSUBSCRIPT italic_i - 1 end_POSTSUBSCRIPT + bold_italic_B start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ⊙ bold_italic_X start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="S2.E7"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\bm{y}_{i}" class="ltx_Math" display="inline" id="S2.E7.m1.1"><semantics id="S2.E7.m1.1a"><msub id="S2.E7.m1.1.1" xref="S2.E7.m1.1.1.cmml"><mi id="S2.E7.m1.1.1.2" xref="S2.E7.m1.1.1.2.cmml">𝒚</mi><mi id="S2.E7.m1.1.1.3" xref="S2.E7.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.E7.m1.1b"><apply id="S2.E7.m1.1.1.cmml" xref="S2.E7.m1.1.1"><csymbol cd="ambiguous" id="S2.E7.m1.1.1.1.cmml" xref="S2.E7.m1.1.1">subscript</csymbol><ci id="S2.E7.m1.1.1.2.cmml" xref="S2.E7.m1.1.1.2">𝒚</ci><ci id="S2.E7.m1.1.1.3.cmml" xref="S2.E7.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E7.m1.1c">\displaystyle\bm{y}_{i}</annotation><annotation encoding="application/x-llamapun" id="S2.E7.m1.1d">bold_italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle=\bm{H}_{i}^{\top}\bm{c}_{i}," class="ltx_Math" display="inline" id="S2.E7.m2.1"><semantics id="S2.E7.m2.1a"><mrow id="S2.E7.m2.1.1.1" xref="S2.E7.m2.1.1.1.1.cmml"><mrow id="S2.E7.m2.1.1.1.1" xref="S2.E7.m2.1.1.1.1.cmml"><mi id="S2.E7.m2.1.1.1.1.2" xref="S2.E7.m2.1.1.1.1.2.cmml"></mi><mo id="S2.E7.m2.1.1.1.1.1" xref="S2.E7.m2.1.1.1.1.1.cmml">=</mo><mrow id="S2.E7.m2.1.1.1.1.3" xref="S2.E7.m2.1.1.1.1.3.cmml"><msubsup id="S2.E7.m2.1.1.1.1.3.2" xref="S2.E7.m2.1.1.1.1.3.2.cmml"><mi id="S2.E7.m2.1.1.1.1.3.2.2.2" xref="S2.E7.m2.1.1.1.1.3.2.2.2.cmml">𝑯</mi><mi id="S2.E7.m2.1.1.1.1.3.2.2.3" xref="S2.E7.m2.1.1.1.1.3.2.2.3.cmml">i</mi><mo id="S2.E7.m2.1.1.1.1.3.2.3" xref="S2.E7.m2.1.1.1.1.3.2.3.cmml">⊤</mo></msubsup><mo id="S2.E7.m2.1.1.1.1.3.1" xref="S2.E7.m2.1.1.1.1.3.1.cmml">⁢</mo><msub id="S2.E7.m2.1.1.1.1.3.3" xref="S2.E7.m2.1.1.1.1.3.3.cmml"><mi id="S2.E7.m2.1.1.1.1.3.3.2" xref="S2.E7.m2.1.1.1.1.3.3.2.cmml">𝒄</mi><mi id="S2.E7.m2.1.1.1.1.3.3.3" xref="S2.E7.m2.1.1.1.1.3.3.3.cmml">i</mi></msub></mrow></mrow><mo id="S2.E7.m2.1.1.1.2" xref="S2.E7.m2.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E7.m2.1b"><apply id="S2.E7.m2.1.1.1.1.cmml" xref="S2.E7.m2.1.1.1"><eq id="S2.E7.m2.1.1.1.1.1.cmml" xref="S2.E7.m2.1.1.1.1.1"></eq><csymbol cd="latexml" id="S2.E7.m2.1.1.1.1.2.cmml" xref="S2.E7.m2.1.1.1.1.2">absent</csymbol><apply id="S2.E7.m2.1.1.1.1.3.cmml" xref="S2.E7.m2.1.1.1.1.3"><times id="S2.E7.m2.1.1.1.1.3.1.cmml" xref="S2.E7.m2.1.1.1.1.3.1"></times><apply id="S2.E7.m2.1.1.1.1.3.2.cmml" xref="S2.E7.m2.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S2.E7.m2.1.1.1.1.3.2.1.cmml" xref="S2.E7.m2.1.1.1.1.3.2">superscript</csymbol><apply id="S2.E7.m2.1.1.1.1.3.2.2.cmml" xref="S2.E7.m2.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S2.E7.m2.1.1.1.1.3.2.2.1.cmml" xref="S2.E7.m2.1.1.1.1.3.2">subscript</csymbol><ci id="S2.E7.m2.1.1.1.1.3.2.2.2.cmml" xref="S2.E7.m2.1.1.1.1.3.2.2.2">𝑯</ci><ci id="S2.E7.m2.1.1.1.1.3.2.2.3.cmml" xref="S2.E7.m2.1.1.1.1.3.2.2.3">𝑖</ci></apply><csymbol cd="latexml" id="S2.E7.m2.1.1.1.1.3.2.3.cmml" xref="S2.E7.m2.1.1.1.1.3.2.3">top</csymbol></apply><apply id="S2.E7.m2.1.1.1.1.3.3.cmml" xref="S2.E7.m2.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S2.E7.m2.1.1.1.1.3.3.1.cmml" xref="S2.E7.m2.1.1.1.1.3.3">subscript</csymbol><ci id="S2.E7.m2.1.1.1.1.3.3.2.cmml" xref="S2.E7.m2.1.1.1.1.3.3.2">𝒄</ci><ci id="S2.E7.m2.1.1.1.1.3.3.3.cmml" xref="S2.E7.m2.1.1.1.1.3.3.3">𝑖</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E7.m2.1c">\displaystyle=\bm{H}_{i}^{\top}\bm{c}_{i},</annotation><annotation encoding="application/x-llamapun" id="S2.E7.m2.1d">= bold_italic_H start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ⊤ end_POSTSUPERSCRIPT bold_italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(7)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S2.SS3.SSS0.Px1.p1.17">where <math alttext="\bm{X}_{i}=\bm{1}_{r}\bm{x}_{i}^{\top}\in\mathbb{R}^{r\times d}" class="ltx_Math" display="inline" id="S2.SS3.SSS0.Px1.p1.3.m1.1"><semantics id="S2.SS3.SSS0.Px1.p1.3.m1.1a"><mrow id="S2.SS3.SSS0.Px1.p1.3.m1.1.1" xref="S2.SS3.SSS0.Px1.p1.3.m1.1.1.cmml"><msub id="S2.SS3.SSS0.Px1.p1.3.m1.1.1.2" xref="S2.SS3.SSS0.Px1.p1.3.m1.1.1.2.cmml"><mi id="S2.SS3.SSS0.Px1.p1.3.m1.1.1.2.2" xref="S2.SS3.SSS0.Px1.p1.3.m1.1.1.2.2.cmml">𝑿</mi><mi id="S2.SS3.SSS0.Px1.p1.3.m1.1.1.2.3" xref="S2.SS3.SSS0.Px1.p1.3.m1.1.1.2.3.cmml">i</mi></msub><mo id="S2.SS3.SSS0.Px1.p1.3.m1.1.1.3" xref="S2.SS3.SSS0.Px1.p1.3.m1.1.1.3.cmml">=</mo><mrow id="S2.SS3.SSS0.Px1.p1.3.m1.1.1.4" xref="S2.SS3.SSS0.Px1.p1.3.m1.1.1.4.cmml"><msub id="S2.SS3.SSS0.Px1.p1.3.m1.1.1.4.2" xref="S2.SS3.SSS0.Px1.p1.3.m1.1.1.4.2.cmml"><mn id="S2.SS3.SSS0.Px1.p1.3.m1.1.1.4.2.2" xref="S2.SS3.SSS0.Px1.p1.3.m1.1.1.4.2.2.cmml">𝟏</mn><mi id="S2.SS3.SSS0.Px1.p1.3.m1.1.1.4.2.3" xref="S2.SS3.SSS0.Px1.p1.3.m1.1.1.4.2.3.cmml">r</mi></msub><mo id="S2.SS3.SSS0.Px1.p1.3.m1.1.1.4.1" xref="S2.SS3.SSS0.Px1.p1.3.m1.1.1.4.1.cmml">⁢</mo><msubsup id="S2.SS3.SSS0.Px1.p1.3.m1.1.1.4.3" xref="S2.SS3.SSS0.Px1.p1.3.m1.1.1.4.3.cmml"><mi id="S2.SS3.SSS0.Px1.p1.3.m1.1.1.4.3.2.2" xref="S2.SS3.SSS0.Px1.p1.3.m1.1.1.4.3.2.2.cmml">𝒙</mi><mi id="S2.SS3.SSS0.Px1.p1.3.m1.1.1.4.3.2.3" xref="S2.SS3.SSS0.Px1.p1.3.m1.1.1.4.3.2.3.cmml">i</mi><mo id="S2.SS3.SSS0.Px1.p1.3.m1.1.1.4.3.3" xref="S2.SS3.SSS0.Px1.p1.3.m1.1.1.4.3.3.cmml">⊤</mo></msubsup></mrow><mo id="S2.SS3.SSS0.Px1.p1.3.m1.1.1.5" xref="S2.SS3.SSS0.Px1.p1.3.m1.1.1.5.cmml">∈</mo><msup id="S2.SS3.SSS0.Px1.p1.3.m1.1.1.6" xref="S2.SS3.SSS0.Px1.p1.3.m1.1.1.6.cmml"><mi id="S2.SS3.SSS0.Px1.p1.3.m1.1.1.6.2" xref="S2.SS3.SSS0.Px1.p1.3.m1.1.1.6.2.cmml">ℝ</mi><mrow id="S2.SS3.SSS0.Px1.p1.3.m1.1.1.6.3" xref="S2.SS3.SSS0.Px1.p1.3.m1.1.1.6.3.cmml"><mi id="S2.SS3.SSS0.Px1.p1.3.m1.1.1.6.3.2" xref="S2.SS3.SSS0.Px1.p1.3.m1.1.1.6.3.2.cmml">r</mi><mo id="S2.SS3.SSS0.Px1.p1.3.m1.1.1.6.3.1" lspace="0.222em" rspace="0.222em" xref="S2.SS3.SSS0.Px1.p1.3.m1.1.1.6.3.1.cmml">×</mo><mi id="S2.SS3.SSS0.Px1.p1.3.m1.1.1.6.3.3" xref="S2.SS3.SSS0.Px1.p1.3.m1.1.1.6.3.3.cmml">d</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS0.Px1.p1.3.m1.1b"><apply id="S2.SS3.SSS0.Px1.p1.3.m1.1.1.cmml" xref="S2.SS3.SSS0.Px1.p1.3.m1.1.1"><and id="S2.SS3.SSS0.Px1.p1.3.m1.1.1a.cmml" xref="S2.SS3.SSS0.Px1.p1.3.m1.1.1"></and><apply id="S2.SS3.SSS0.Px1.p1.3.m1.1.1b.cmml" xref="S2.SS3.SSS0.Px1.p1.3.m1.1.1"><eq id="S2.SS3.SSS0.Px1.p1.3.m1.1.1.3.cmml" xref="S2.SS3.SSS0.Px1.p1.3.m1.1.1.3"></eq><apply id="S2.SS3.SSS0.Px1.p1.3.m1.1.1.2.cmml" xref="S2.SS3.SSS0.Px1.p1.3.m1.1.1.2"><csymbol cd="ambiguous" id="S2.SS3.SSS0.Px1.p1.3.m1.1.1.2.1.cmml" xref="S2.SS3.SSS0.Px1.p1.3.m1.1.1.2">subscript</csymbol><ci id="S2.SS3.SSS0.Px1.p1.3.m1.1.1.2.2.cmml" xref="S2.SS3.SSS0.Px1.p1.3.m1.1.1.2.2">𝑿</ci><ci id="S2.SS3.SSS0.Px1.p1.3.m1.1.1.2.3.cmml" xref="S2.SS3.SSS0.Px1.p1.3.m1.1.1.2.3">𝑖</ci></apply><apply id="S2.SS3.SSS0.Px1.p1.3.m1.1.1.4.cmml" xref="S2.SS3.SSS0.Px1.p1.3.m1.1.1.4"><times id="S2.SS3.SSS0.Px1.p1.3.m1.1.1.4.1.cmml" xref="S2.SS3.SSS0.Px1.p1.3.m1.1.1.4.1"></times><apply id="S2.SS3.SSS0.Px1.p1.3.m1.1.1.4.2.cmml" xref="S2.SS3.SSS0.Px1.p1.3.m1.1.1.4.2"><csymbol cd="ambiguous" id="S2.SS3.SSS0.Px1.p1.3.m1.1.1.4.2.1.cmml" xref="S2.SS3.SSS0.Px1.p1.3.m1.1.1.4.2">subscript</csymbol><cn id="S2.SS3.SSS0.Px1.p1.3.m1.1.1.4.2.2.cmml" type="integer" xref="S2.SS3.SSS0.Px1.p1.3.m1.1.1.4.2.2">1</cn><ci id="S2.SS3.SSS0.Px1.p1.3.m1.1.1.4.2.3.cmml" xref="S2.SS3.SSS0.Px1.p1.3.m1.1.1.4.2.3">𝑟</ci></apply><apply id="S2.SS3.SSS0.Px1.p1.3.m1.1.1.4.3.cmml" xref="S2.SS3.SSS0.Px1.p1.3.m1.1.1.4.3"><csymbol cd="ambiguous" id="S2.SS3.SSS0.Px1.p1.3.m1.1.1.4.3.1.cmml" xref="S2.SS3.SSS0.Px1.p1.3.m1.1.1.4.3">superscript</csymbol><apply id="S2.SS3.SSS0.Px1.p1.3.m1.1.1.4.3.2.cmml" xref="S2.SS3.SSS0.Px1.p1.3.m1.1.1.4.3"><csymbol cd="ambiguous" id="S2.SS3.SSS0.Px1.p1.3.m1.1.1.4.3.2.1.cmml" xref="S2.SS3.SSS0.Px1.p1.3.m1.1.1.4.3">subscript</csymbol><ci id="S2.SS3.SSS0.Px1.p1.3.m1.1.1.4.3.2.2.cmml" xref="S2.SS3.SSS0.Px1.p1.3.m1.1.1.4.3.2.2">𝒙</ci><ci id="S2.SS3.SSS0.Px1.p1.3.m1.1.1.4.3.2.3.cmml" xref="S2.SS3.SSS0.Px1.p1.3.m1.1.1.4.3.2.3">𝑖</ci></apply><csymbol cd="latexml" id="S2.SS3.SSS0.Px1.p1.3.m1.1.1.4.3.3.cmml" xref="S2.SS3.SSS0.Px1.p1.3.m1.1.1.4.3.3">top</csymbol></apply></apply></apply><apply id="S2.SS3.SSS0.Px1.p1.3.m1.1.1c.cmml" xref="S2.SS3.SSS0.Px1.p1.3.m1.1.1"><in id="S2.SS3.SSS0.Px1.p1.3.m1.1.1.5.cmml" xref="S2.SS3.SSS0.Px1.p1.3.m1.1.1.5"></in><share href="https://arxiv.org/html/2407.05489v1#S2.SS3.SSS0.Px1.p1.3.m1.1.1.4.cmml" id="S2.SS3.SSS0.Px1.p1.3.m1.1.1d.cmml" xref="S2.SS3.SSS0.Px1.p1.3.m1.1.1"></share><apply id="S2.SS3.SSS0.Px1.p1.3.m1.1.1.6.cmml" xref="S2.SS3.SSS0.Px1.p1.3.m1.1.1.6"><csymbol cd="ambiguous" id="S2.SS3.SSS0.Px1.p1.3.m1.1.1.6.1.cmml" xref="S2.SS3.SSS0.Px1.p1.3.m1.1.1.6">superscript</csymbol><ci id="S2.SS3.SSS0.Px1.p1.3.m1.1.1.6.2.cmml" xref="S2.SS3.SSS0.Px1.p1.3.m1.1.1.6.2">ℝ</ci><apply id="S2.SS3.SSS0.Px1.p1.3.m1.1.1.6.3.cmml" xref="S2.SS3.SSS0.Px1.p1.3.m1.1.1.6.3"><times id="S2.SS3.SSS0.Px1.p1.3.m1.1.1.6.3.1.cmml" xref="S2.SS3.SSS0.Px1.p1.3.m1.1.1.6.3.1"></times><ci id="S2.SS3.SSS0.Px1.p1.3.m1.1.1.6.3.2.cmml" xref="S2.SS3.SSS0.Px1.p1.3.m1.1.1.6.3.2">𝑟</ci><ci id="S2.SS3.SSS0.Px1.p1.3.m1.1.1.6.3.3.cmml" xref="S2.SS3.SSS0.Px1.p1.3.m1.1.1.6.3.3">𝑑</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS0.Px1.p1.3.m1.1c">\bm{X}_{i}=\bm{1}_{r}\bm{x}_{i}^{\top}\in\mathbb{R}^{r\times d}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.SSS0.Px1.p1.3.m1.1d">bold_italic_X start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = bold_1 start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT bold_italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ⊤ end_POSTSUPERSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT italic_r × italic_d end_POSTSUPERSCRIPT</annotation></semantics></math> is an <math alttext="r" class="ltx_Math" display="inline" id="S2.SS3.SSS0.Px1.p1.4.m2.1"><semantics id="S2.SS3.SSS0.Px1.p1.4.m2.1a"><mi id="S2.SS3.SSS0.Px1.p1.4.m2.1.1" xref="S2.SS3.SSS0.Px1.p1.4.m2.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS0.Px1.p1.4.m2.1b"><ci id="S2.SS3.SSS0.Px1.p1.4.m2.1.1.cmml" xref="S2.SS3.SSS0.Px1.p1.4.m2.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS0.Px1.p1.4.m2.1c">r</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.SSS0.Px1.p1.4.m2.1d">italic_r</annotation></semantics></math>-sized stack of the input, <math alttext="\bm{A}_{i}\in\mathbb{R}^{r\times d}" class="ltx_Math" display="inline" id="S2.SS3.SSS0.Px1.p1.5.m3.1"><semantics id="S2.SS3.SSS0.Px1.p1.5.m3.1a"><mrow id="S2.SS3.SSS0.Px1.p1.5.m3.1.1" xref="S2.SS3.SSS0.Px1.p1.5.m3.1.1.cmml"><msub id="S2.SS3.SSS0.Px1.p1.5.m3.1.1.2" xref="S2.SS3.SSS0.Px1.p1.5.m3.1.1.2.cmml"><mi id="S2.SS3.SSS0.Px1.p1.5.m3.1.1.2.2" xref="S2.SS3.SSS0.Px1.p1.5.m3.1.1.2.2.cmml">𝑨</mi><mi id="S2.SS3.SSS0.Px1.p1.5.m3.1.1.2.3" xref="S2.SS3.SSS0.Px1.p1.5.m3.1.1.2.3.cmml">i</mi></msub><mo id="S2.SS3.SSS0.Px1.p1.5.m3.1.1.1" xref="S2.SS3.SSS0.Px1.p1.5.m3.1.1.1.cmml">∈</mo><msup id="S2.SS3.SSS0.Px1.p1.5.m3.1.1.3" xref="S2.SS3.SSS0.Px1.p1.5.m3.1.1.3.cmml"><mi id="S2.SS3.SSS0.Px1.p1.5.m3.1.1.3.2" xref="S2.SS3.SSS0.Px1.p1.5.m3.1.1.3.2.cmml">ℝ</mi><mrow id="S2.SS3.SSS0.Px1.p1.5.m3.1.1.3.3" xref="S2.SS3.SSS0.Px1.p1.5.m3.1.1.3.3.cmml"><mi id="S2.SS3.SSS0.Px1.p1.5.m3.1.1.3.3.2" xref="S2.SS3.SSS0.Px1.p1.5.m3.1.1.3.3.2.cmml">r</mi><mo id="S2.SS3.SSS0.Px1.p1.5.m3.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S2.SS3.SSS0.Px1.p1.5.m3.1.1.3.3.1.cmml">×</mo><mi id="S2.SS3.SSS0.Px1.p1.5.m3.1.1.3.3.3" xref="S2.SS3.SSS0.Px1.p1.5.m3.1.1.3.3.3.cmml">d</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS0.Px1.p1.5.m3.1b"><apply id="S2.SS3.SSS0.Px1.p1.5.m3.1.1.cmml" xref="S2.SS3.SSS0.Px1.p1.5.m3.1.1"><in id="S2.SS3.SSS0.Px1.p1.5.m3.1.1.1.cmml" xref="S2.SS3.SSS0.Px1.p1.5.m3.1.1.1"></in><apply id="S2.SS3.SSS0.Px1.p1.5.m3.1.1.2.cmml" xref="S2.SS3.SSS0.Px1.p1.5.m3.1.1.2"><csymbol cd="ambiguous" id="S2.SS3.SSS0.Px1.p1.5.m3.1.1.2.1.cmml" xref="S2.SS3.SSS0.Px1.p1.5.m3.1.1.2">subscript</csymbol><ci id="S2.SS3.SSS0.Px1.p1.5.m3.1.1.2.2.cmml" xref="S2.SS3.SSS0.Px1.p1.5.m3.1.1.2.2">𝑨</ci><ci id="S2.SS3.SSS0.Px1.p1.5.m3.1.1.2.3.cmml" xref="S2.SS3.SSS0.Px1.p1.5.m3.1.1.2.3">𝑖</ci></apply><apply id="S2.SS3.SSS0.Px1.p1.5.m3.1.1.3.cmml" xref="S2.SS3.SSS0.Px1.p1.5.m3.1.1.3"><csymbol cd="ambiguous" id="S2.SS3.SSS0.Px1.p1.5.m3.1.1.3.1.cmml" xref="S2.SS3.SSS0.Px1.p1.5.m3.1.1.3">superscript</csymbol><ci id="S2.SS3.SSS0.Px1.p1.5.m3.1.1.3.2.cmml" xref="S2.SS3.SSS0.Px1.p1.5.m3.1.1.3.2">ℝ</ci><apply id="S2.SS3.SSS0.Px1.p1.5.m3.1.1.3.3.cmml" xref="S2.SS3.SSS0.Px1.p1.5.m3.1.1.3.3"><times id="S2.SS3.SSS0.Px1.p1.5.m3.1.1.3.3.1.cmml" xref="S2.SS3.SSS0.Px1.p1.5.m3.1.1.3.3.1"></times><ci id="S2.SS3.SSS0.Px1.p1.5.m3.1.1.3.3.2.cmml" xref="S2.SS3.SSS0.Px1.p1.5.m3.1.1.3.3.2">𝑟</ci><ci id="S2.SS3.SSS0.Px1.p1.5.m3.1.1.3.3.3.cmml" xref="S2.SS3.SSS0.Px1.p1.5.m3.1.1.3.3.3">𝑑</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS0.Px1.p1.5.m3.1c">\bm{A}_{i}\in\mathbb{R}^{r\times d}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.SSS0.Px1.p1.5.m3.1d">bold_italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT italic_r × italic_d end_POSTSUPERSCRIPT</annotation></semantics></math> represents <math alttext="d" class="ltx_Math" display="inline" id="S2.SS3.SSS0.Px1.p1.6.m4.1"><semantics id="S2.SS3.SSS0.Px1.p1.6.m4.1a"><mi id="S2.SS3.SSS0.Px1.p1.6.m4.1.1" xref="S2.SS3.SSS0.Px1.p1.6.m4.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS0.Px1.p1.6.m4.1b"><ci id="S2.SS3.SSS0.Px1.p1.6.m4.1.1.cmml" xref="S2.SS3.SSS0.Px1.p1.6.m4.1.1">𝑑</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS0.Px1.p1.6.m4.1c">d</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.SSS0.Px1.p1.6.m4.1d">italic_d</annotation></semantics></math> diagonal matrices of size <math alttext="r\times r" class="ltx_Math" display="inline" id="S2.SS3.SSS0.Px1.p1.7.m5.1"><semantics id="S2.SS3.SSS0.Px1.p1.7.m5.1a"><mrow id="S2.SS3.SSS0.Px1.p1.7.m5.1.1" xref="S2.SS3.SSS0.Px1.p1.7.m5.1.1.cmml"><mi id="S2.SS3.SSS0.Px1.p1.7.m5.1.1.2" xref="S2.SS3.SSS0.Px1.p1.7.m5.1.1.2.cmml">r</mi><mo id="S2.SS3.SSS0.Px1.p1.7.m5.1.1.1" lspace="0.222em" rspace="0.222em" xref="S2.SS3.SSS0.Px1.p1.7.m5.1.1.1.cmml">×</mo><mi id="S2.SS3.SSS0.Px1.p1.7.m5.1.1.3" xref="S2.SS3.SSS0.Px1.p1.7.m5.1.1.3.cmml">r</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS0.Px1.p1.7.m5.1b"><apply id="S2.SS3.SSS0.Px1.p1.7.m5.1.1.cmml" xref="S2.SS3.SSS0.Px1.p1.7.m5.1.1"><times id="S2.SS3.SSS0.Px1.p1.7.m5.1.1.1.cmml" xref="S2.SS3.SSS0.Px1.p1.7.m5.1.1.1"></times><ci id="S2.SS3.SSS0.Px1.p1.7.m5.1.1.2.cmml" xref="S2.SS3.SSS0.Px1.p1.7.m5.1.1.2">𝑟</ci><ci id="S2.SS3.SSS0.Px1.p1.7.m5.1.1.3.cmml" xref="S2.SS3.SSS0.Px1.p1.7.m5.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS0.Px1.p1.7.m5.1c">r\times r</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.SSS0.Px1.p1.7.m5.1d">italic_r × italic_r</annotation></semantics></math>, <math alttext="\bm{B}_{i}\in\mathbb{R}^{r\times d}" class="ltx_Math" display="inline" id="S2.SS3.SSS0.Px1.p1.8.m6.1"><semantics id="S2.SS3.SSS0.Px1.p1.8.m6.1a"><mrow id="S2.SS3.SSS0.Px1.p1.8.m6.1.1" xref="S2.SS3.SSS0.Px1.p1.8.m6.1.1.cmml"><msub id="S2.SS3.SSS0.Px1.p1.8.m6.1.1.2" xref="S2.SS3.SSS0.Px1.p1.8.m6.1.1.2.cmml"><mi id="S2.SS3.SSS0.Px1.p1.8.m6.1.1.2.2" xref="S2.SS3.SSS0.Px1.p1.8.m6.1.1.2.2.cmml">𝑩</mi><mi id="S2.SS3.SSS0.Px1.p1.8.m6.1.1.2.3" xref="S2.SS3.SSS0.Px1.p1.8.m6.1.1.2.3.cmml">i</mi></msub><mo id="S2.SS3.SSS0.Px1.p1.8.m6.1.1.1" xref="S2.SS3.SSS0.Px1.p1.8.m6.1.1.1.cmml">∈</mo><msup id="S2.SS3.SSS0.Px1.p1.8.m6.1.1.3" xref="S2.SS3.SSS0.Px1.p1.8.m6.1.1.3.cmml"><mi id="S2.SS3.SSS0.Px1.p1.8.m6.1.1.3.2" xref="S2.SS3.SSS0.Px1.p1.8.m6.1.1.3.2.cmml">ℝ</mi><mrow id="S2.SS3.SSS0.Px1.p1.8.m6.1.1.3.3" xref="S2.SS3.SSS0.Px1.p1.8.m6.1.1.3.3.cmml"><mi id="S2.SS3.SSS0.Px1.p1.8.m6.1.1.3.3.2" xref="S2.SS3.SSS0.Px1.p1.8.m6.1.1.3.3.2.cmml">r</mi><mo id="S2.SS3.SSS0.Px1.p1.8.m6.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S2.SS3.SSS0.Px1.p1.8.m6.1.1.3.3.1.cmml">×</mo><mi id="S2.SS3.SSS0.Px1.p1.8.m6.1.1.3.3.3" xref="S2.SS3.SSS0.Px1.p1.8.m6.1.1.3.3.3.cmml">d</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS0.Px1.p1.8.m6.1b"><apply id="S2.SS3.SSS0.Px1.p1.8.m6.1.1.cmml" xref="S2.SS3.SSS0.Px1.p1.8.m6.1.1"><in id="S2.SS3.SSS0.Px1.p1.8.m6.1.1.1.cmml" xref="S2.SS3.SSS0.Px1.p1.8.m6.1.1.1"></in><apply id="S2.SS3.SSS0.Px1.p1.8.m6.1.1.2.cmml" xref="S2.SS3.SSS0.Px1.p1.8.m6.1.1.2"><csymbol cd="ambiguous" id="S2.SS3.SSS0.Px1.p1.8.m6.1.1.2.1.cmml" xref="S2.SS3.SSS0.Px1.p1.8.m6.1.1.2">subscript</csymbol><ci id="S2.SS3.SSS0.Px1.p1.8.m6.1.1.2.2.cmml" xref="S2.SS3.SSS0.Px1.p1.8.m6.1.1.2.2">𝑩</ci><ci id="S2.SS3.SSS0.Px1.p1.8.m6.1.1.2.3.cmml" xref="S2.SS3.SSS0.Px1.p1.8.m6.1.1.2.3">𝑖</ci></apply><apply id="S2.SS3.SSS0.Px1.p1.8.m6.1.1.3.cmml" xref="S2.SS3.SSS0.Px1.p1.8.m6.1.1.3"><csymbol cd="ambiguous" id="S2.SS3.SSS0.Px1.p1.8.m6.1.1.3.1.cmml" xref="S2.SS3.SSS0.Px1.p1.8.m6.1.1.3">superscript</csymbol><ci id="S2.SS3.SSS0.Px1.p1.8.m6.1.1.3.2.cmml" xref="S2.SS3.SSS0.Px1.p1.8.m6.1.1.3.2">ℝ</ci><apply id="S2.SS3.SSS0.Px1.p1.8.m6.1.1.3.3.cmml" xref="S2.SS3.SSS0.Px1.p1.8.m6.1.1.3.3"><times id="S2.SS3.SSS0.Px1.p1.8.m6.1.1.3.3.1.cmml" xref="S2.SS3.SSS0.Px1.p1.8.m6.1.1.3.3.1"></times><ci id="S2.SS3.SSS0.Px1.p1.8.m6.1.1.3.3.2.cmml" xref="S2.SS3.SSS0.Px1.p1.8.m6.1.1.3.3.2">𝑟</ci><ci id="S2.SS3.SSS0.Px1.p1.8.m6.1.1.3.3.3.cmml" xref="S2.SS3.SSS0.Px1.p1.8.m6.1.1.3.3.3">𝑑</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS0.Px1.p1.8.m6.1c">\bm{B}_{i}\in\mathbb{R}^{r\times d}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.SSS0.Px1.p1.8.m6.1d">bold_italic_B start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT italic_r × italic_d end_POSTSUPERSCRIPT</annotation></semantics></math>, <math alttext="\bm{c}_{i}\in\mathbb{R}^{r}" class="ltx_Math" display="inline" id="S2.SS3.SSS0.Px1.p1.9.m7.1"><semantics id="S2.SS3.SSS0.Px1.p1.9.m7.1a"><mrow id="S2.SS3.SSS0.Px1.p1.9.m7.1.1" xref="S2.SS3.SSS0.Px1.p1.9.m7.1.1.cmml"><msub id="S2.SS3.SSS0.Px1.p1.9.m7.1.1.2" xref="S2.SS3.SSS0.Px1.p1.9.m7.1.1.2.cmml"><mi id="S2.SS3.SSS0.Px1.p1.9.m7.1.1.2.2" xref="S2.SS3.SSS0.Px1.p1.9.m7.1.1.2.2.cmml">𝒄</mi><mi id="S2.SS3.SSS0.Px1.p1.9.m7.1.1.2.3" xref="S2.SS3.SSS0.Px1.p1.9.m7.1.1.2.3.cmml">i</mi></msub><mo id="S2.SS3.SSS0.Px1.p1.9.m7.1.1.1" xref="S2.SS3.SSS0.Px1.p1.9.m7.1.1.1.cmml">∈</mo><msup id="S2.SS3.SSS0.Px1.p1.9.m7.1.1.3" xref="S2.SS3.SSS0.Px1.p1.9.m7.1.1.3.cmml"><mi id="S2.SS3.SSS0.Px1.p1.9.m7.1.1.3.2" xref="S2.SS3.SSS0.Px1.p1.9.m7.1.1.3.2.cmml">ℝ</mi><mi id="S2.SS3.SSS0.Px1.p1.9.m7.1.1.3.3" xref="S2.SS3.SSS0.Px1.p1.9.m7.1.1.3.3.cmml">r</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS0.Px1.p1.9.m7.1b"><apply id="S2.SS3.SSS0.Px1.p1.9.m7.1.1.cmml" xref="S2.SS3.SSS0.Px1.p1.9.m7.1.1"><in id="S2.SS3.SSS0.Px1.p1.9.m7.1.1.1.cmml" xref="S2.SS3.SSS0.Px1.p1.9.m7.1.1.1"></in><apply id="S2.SS3.SSS0.Px1.p1.9.m7.1.1.2.cmml" xref="S2.SS3.SSS0.Px1.p1.9.m7.1.1.2"><csymbol cd="ambiguous" id="S2.SS3.SSS0.Px1.p1.9.m7.1.1.2.1.cmml" xref="S2.SS3.SSS0.Px1.p1.9.m7.1.1.2">subscript</csymbol><ci id="S2.SS3.SSS0.Px1.p1.9.m7.1.1.2.2.cmml" xref="S2.SS3.SSS0.Px1.p1.9.m7.1.1.2.2">𝒄</ci><ci id="S2.SS3.SSS0.Px1.p1.9.m7.1.1.2.3.cmml" xref="S2.SS3.SSS0.Px1.p1.9.m7.1.1.2.3">𝑖</ci></apply><apply id="S2.SS3.SSS0.Px1.p1.9.m7.1.1.3.cmml" xref="S2.SS3.SSS0.Px1.p1.9.m7.1.1.3"><csymbol cd="ambiguous" id="S2.SS3.SSS0.Px1.p1.9.m7.1.1.3.1.cmml" xref="S2.SS3.SSS0.Px1.p1.9.m7.1.1.3">superscript</csymbol><ci id="S2.SS3.SSS0.Px1.p1.9.m7.1.1.3.2.cmml" xref="S2.SS3.SSS0.Px1.p1.9.m7.1.1.3.2">ℝ</ci><ci id="S2.SS3.SSS0.Px1.p1.9.m7.1.1.3.3.cmml" xref="S2.SS3.SSS0.Px1.p1.9.m7.1.1.3.3">𝑟</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS0.Px1.p1.9.m7.1c">\bm{c}_{i}\in\mathbb{R}^{r}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.SSS0.Px1.p1.9.m7.1d">bold_italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT</annotation></semantics></math>, and <math alttext="\odot" class="ltx_Math" display="inline" id="S2.SS3.SSS0.Px1.p1.10.m8.1"><semantics id="S2.SS3.SSS0.Px1.p1.10.m8.1a"><mo id="S2.SS3.SSS0.Px1.p1.10.m8.1.1" xref="S2.SS3.SSS0.Px1.p1.10.m8.1.1.cmml">⊙</mo><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS0.Px1.p1.10.m8.1b"><csymbol cd="latexml" id="S2.SS3.SSS0.Px1.p1.10.m8.1.1.cmml" xref="S2.SS3.SSS0.Px1.p1.10.m8.1.1">direct-product</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS0.Px1.p1.10.m8.1c">\odot</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.SSS0.Px1.p1.10.m8.1d">⊙</annotation></semantics></math> is the Hadamard product.
Note that, unlike S4, where the same <math alttext="\bm{A}" class="ltx_Math" display="inline" id="S2.SS3.SSS0.Px1.p1.11.m9.1"><semantics id="S2.SS3.SSS0.Px1.p1.11.m9.1a"><mi id="S2.SS3.SSS0.Px1.p1.11.m9.1.1" xref="S2.SS3.SSS0.Px1.p1.11.m9.1.1.cmml">𝑨</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS0.Px1.p1.11.m9.1b"><ci id="S2.SS3.SSS0.Px1.p1.11.m9.1.1.cmml" xref="S2.SS3.SSS0.Px1.p1.11.m9.1.1">𝑨</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS0.Px1.p1.11.m9.1c">\bm{A}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.SSS0.Px1.p1.11.m9.1d">bold_italic_A</annotation></semantics></math> and <math alttext="\bm{B}" class="ltx_Math" display="inline" id="S2.SS3.SSS0.Px1.p1.12.m10.1"><semantics id="S2.SS3.SSS0.Px1.p1.12.m10.1a"><mi id="S2.SS3.SSS0.Px1.p1.12.m10.1.1" xref="S2.SS3.SSS0.Px1.p1.12.m10.1.1.cmml">𝑩</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS0.Px1.p1.12.m10.1b"><ci id="S2.SS3.SSS0.Px1.p1.12.m10.1.1.cmml" xref="S2.SS3.SSS0.Px1.p1.12.m10.1.1">𝑩</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS0.Px1.p1.12.m10.1c">\bm{B}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.SSS0.Px1.p1.12.m10.1d">bold_italic_B</annotation></semantics></math> parameters are shared across all hidden dimensions <math alttext="1\leq h\leq d" class="ltx_Math" display="inline" id="S2.SS3.SSS0.Px1.p1.13.m11.1"><semantics id="S2.SS3.SSS0.Px1.p1.13.m11.1a"><mrow id="S2.SS3.SSS0.Px1.p1.13.m11.1.1" xref="S2.SS3.SSS0.Px1.p1.13.m11.1.1.cmml"><mn id="S2.SS3.SSS0.Px1.p1.13.m11.1.1.2" xref="S2.SS3.SSS0.Px1.p1.13.m11.1.1.2.cmml">1</mn><mo id="S2.SS3.SSS0.Px1.p1.13.m11.1.1.3" xref="S2.SS3.SSS0.Px1.p1.13.m11.1.1.3.cmml">≤</mo><mi id="S2.SS3.SSS0.Px1.p1.13.m11.1.1.4" xref="S2.SS3.SSS0.Px1.p1.13.m11.1.1.4.cmml">h</mi><mo id="S2.SS3.SSS0.Px1.p1.13.m11.1.1.5" xref="S2.SS3.SSS0.Px1.p1.13.m11.1.1.5.cmml">≤</mo><mi id="S2.SS3.SSS0.Px1.p1.13.m11.1.1.6" xref="S2.SS3.SSS0.Px1.p1.13.m11.1.1.6.cmml">d</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS0.Px1.p1.13.m11.1b"><apply id="S2.SS3.SSS0.Px1.p1.13.m11.1.1.cmml" xref="S2.SS3.SSS0.Px1.p1.13.m11.1.1"><and id="S2.SS3.SSS0.Px1.p1.13.m11.1.1a.cmml" xref="S2.SS3.SSS0.Px1.p1.13.m11.1.1"></and><apply id="S2.SS3.SSS0.Px1.p1.13.m11.1.1b.cmml" xref="S2.SS3.SSS0.Px1.p1.13.m11.1.1"><leq id="S2.SS3.SSS0.Px1.p1.13.m11.1.1.3.cmml" xref="S2.SS3.SSS0.Px1.p1.13.m11.1.1.3"></leq><cn id="S2.SS3.SSS0.Px1.p1.13.m11.1.1.2.cmml" type="integer" xref="S2.SS3.SSS0.Px1.p1.13.m11.1.1.2">1</cn><ci id="S2.SS3.SSS0.Px1.p1.13.m11.1.1.4.cmml" xref="S2.SS3.SSS0.Px1.p1.13.m11.1.1.4">ℎ</ci></apply><apply id="S2.SS3.SSS0.Px1.p1.13.m11.1.1c.cmml" xref="S2.SS3.SSS0.Px1.p1.13.m11.1.1"><leq id="S2.SS3.SSS0.Px1.p1.13.m11.1.1.5.cmml" xref="S2.SS3.SSS0.Px1.p1.13.m11.1.1.5"></leq><share href="https://arxiv.org/html/2407.05489v1#S2.SS3.SSS0.Px1.p1.13.m11.1.1.4.cmml" id="S2.SS3.SSS0.Px1.p1.13.m11.1.1d.cmml" xref="S2.SS3.SSS0.Px1.p1.13.m11.1.1"></share><ci id="S2.SS3.SSS0.Px1.p1.13.m11.1.1.6.cmml" xref="S2.SS3.SSS0.Px1.p1.13.m11.1.1.6">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS0.Px1.p1.13.m11.1c">1\leq h\leq d</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.SSS0.Px1.p1.13.m11.1d">1 ≤ italic_h ≤ italic_d</annotation></semantics></math>,
Mamba defines <math alttext="\bm{A}_{i}" class="ltx_Math" display="inline" id="S2.SS3.SSS0.Px1.p1.14.m12.1"><semantics id="S2.SS3.SSS0.Px1.p1.14.m12.1a"><msub id="S2.SS3.SSS0.Px1.p1.14.m12.1.1" xref="S2.SS3.SSS0.Px1.p1.14.m12.1.1.cmml"><mi id="S2.SS3.SSS0.Px1.p1.14.m12.1.1.2" xref="S2.SS3.SSS0.Px1.p1.14.m12.1.1.2.cmml">𝑨</mi><mi id="S2.SS3.SSS0.Px1.p1.14.m12.1.1.3" xref="S2.SS3.SSS0.Px1.p1.14.m12.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS0.Px1.p1.14.m12.1b"><apply id="S2.SS3.SSS0.Px1.p1.14.m12.1.1.cmml" xref="S2.SS3.SSS0.Px1.p1.14.m12.1.1"><csymbol cd="ambiguous" id="S2.SS3.SSS0.Px1.p1.14.m12.1.1.1.cmml" xref="S2.SS3.SSS0.Px1.p1.14.m12.1.1">subscript</csymbol><ci id="S2.SS3.SSS0.Px1.p1.14.m12.1.1.2.cmml" xref="S2.SS3.SSS0.Px1.p1.14.m12.1.1.2">𝑨</ci><ci id="S2.SS3.SSS0.Px1.p1.14.m12.1.1.3.cmml" xref="S2.SS3.SSS0.Px1.p1.14.m12.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS0.Px1.p1.14.m12.1c">\bm{A}_{i}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.SSS0.Px1.p1.14.m12.1d">bold_italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="\bm{B}_{i}" class="ltx_Math" display="inline" id="S2.SS3.SSS0.Px1.p1.15.m13.1"><semantics id="S2.SS3.SSS0.Px1.p1.15.m13.1a"><msub id="S2.SS3.SSS0.Px1.p1.15.m13.1.1" xref="S2.SS3.SSS0.Px1.p1.15.m13.1.1.cmml"><mi id="S2.SS3.SSS0.Px1.p1.15.m13.1.1.2" xref="S2.SS3.SSS0.Px1.p1.15.m13.1.1.2.cmml">𝑩</mi><mi id="S2.SS3.SSS0.Px1.p1.15.m13.1.1.3" xref="S2.SS3.SSS0.Px1.p1.15.m13.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS0.Px1.p1.15.m13.1b"><apply id="S2.SS3.SSS0.Px1.p1.15.m13.1.1.cmml" xref="S2.SS3.SSS0.Px1.p1.15.m13.1.1"><csymbol cd="ambiguous" id="S2.SS3.SSS0.Px1.p1.15.m13.1.1.1.cmml" xref="S2.SS3.SSS0.Px1.p1.15.m13.1.1">subscript</csymbol><ci id="S2.SS3.SSS0.Px1.p1.15.m13.1.1.2.cmml" xref="S2.SS3.SSS0.Px1.p1.15.m13.1.1.2">𝑩</ci><ci id="S2.SS3.SSS0.Px1.p1.15.m13.1.1.3.cmml" xref="S2.SS3.SSS0.Px1.p1.15.m13.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS0.Px1.p1.15.m13.1c">\bm{B}_{i}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.SSS0.Px1.p1.15.m13.1d">bold_italic_B start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> with a shape of <math alttext="(\ldots,d)" class="ltx_Math" display="inline" id="S2.SS3.SSS0.Px1.p1.16.m14.2"><semantics id="S2.SS3.SSS0.Px1.p1.16.m14.2a"><mrow id="S2.SS3.SSS0.Px1.p1.16.m14.2.3.2" xref="S2.SS3.SSS0.Px1.p1.16.m14.2.3.1.cmml"><mo id="S2.SS3.SSS0.Px1.p1.16.m14.2.3.2.1" stretchy="false" xref="S2.SS3.SSS0.Px1.p1.16.m14.2.3.1.cmml">(</mo><mi id="S2.SS3.SSS0.Px1.p1.16.m14.1.1" mathvariant="normal" xref="S2.SS3.SSS0.Px1.p1.16.m14.1.1.cmml">…</mi><mo id="S2.SS3.SSS0.Px1.p1.16.m14.2.3.2.2" xref="S2.SS3.SSS0.Px1.p1.16.m14.2.3.1.cmml">,</mo><mi id="S2.SS3.SSS0.Px1.p1.16.m14.2.2" xref="S2.SS3.SSS0.Px1.p1.16.m14.2.2.cmml">d</mi><mo id="S2.SS3.SSS0.Px1.p1.16.m14.2.3.2.3" stretchy="false" xref="S2.SS3.SSS0.Px1.p1.16.m14.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS0.Px1.p1.16.m14.2b"><interval closure="open" id="S2.SS3.SSS0.Px1.p1.16.m14.2.3.1.cmml" xref="S2.SS3.SSS0.Px1.p1.16.m14.2.3.2"><ci id="S2.SS3.SSS0.Px1.p1.16.m14.1.1.cmml" xref="S2.SS3.SSS0.Px1.p1.16.m14.1.1">…</ci><ci id="S2.SS3.SSS0.Px1.p1.16.m14.2.2.cmml" xref="S2.SS3.SSS0.Px1.p1.16.m14.2.2">𝑑</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS0.Px1.p1.16.m14.2c">(\ldots,d)</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.SSS0.Px1.p1.16.m14.2d">( … , italic_d )</annotation></semantics></math>, allowing for unique parameters in each hidden dimension.
While this formulation makes Mamba more expressive, it disrupts the convolutional approach used for training in S4. To address this, <cite class="ltx_cite ltx_citemacro_citet">Gu and Dao (<a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib19" title="">2023</a>)</cite> propose an efficient IO-aware and parallelizable associative scan algorithm for training <cite class="ltx_cite ltx_citemacro_citep">(Smith et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib34" title="">2023</a>)</cite>.
Nonetheless, the recurrent view can still be used for inference with a <math alttext="\mathcal{O}\left(1\right)" class="ltx_Math" display="inline" id="S2.SS3.SSS0.Px1.p1.17.m15.1"><semantics id="S2.SS3.SSS0.Px1.p1.17.m15.1a"><mrow id="S2.SS3.SSS0.Px1.p1.17.m15.1.2" xref="S2.SS3.SSS0.Px1.p1.17.m15.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS3.SSS0.Px1.p1.17.m15.1.2.2" xref="S2.SS3.SSS0.Px1.p1.17.m15.1.2.2.cmml">𝒪</mi><mo id="S2.SS3.SSS0.Px1.p1.17.m15.1.2.1" xref="S2.SS3.SSS0.Px1.p1.17.m15.1.2.1.cmml">⁢</mo><mrow id="S2.SS3.SSS0.Px1.p1.17.m15.1.2.3.2" xref="S2.SS3.SSS0.Px1.p1.17.m15.1.2.cmml"><mo id="S2.SS3.SSS0.Px1.p1.17.m15.1.2.3.2.1" xref="S2.SS3.SSS0.Px1.p1.17.m15.1.2.cmml">(</mo><mn id="S2.SS3.SSS0.Px1.p1.17.m15.1.1" xref="S2.SS3.SSS0.Px1.p1.17.m15.1.1.cmml">1</mn><mo id="S2.SS3.SSS0.Px1.p1.17.m15.1.2.3.2.2" xref="S2.SS3.SSS0.Px1.p1.17.m15.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS0.Px1.p1.17.m15.1b"><apply id="S2.SS3.SSS0.Px1.p1.17.m15.1.2.cmml" xref="S2.SS3.SSS0.Px1.p1.17.m15.1.2"><times id="S2.SS3.SSS0.Px1.p1.17.m15.1.2.1.cmml" xref="S2.SS3.SSS0.Px1.p1.17.m15.1.2.1"></times><ci id="S2.SS3.SSS0.Px1.p1.17.m15.1.2.2.cmml" xref="S2.SS3.SSS0.Px1.p1.17.m15.1.2.2">𝒪</ci><cn id="S2.SS3.SSS0.Px1.p1.17.m15.1.1.cmml" type="integer" xref="S2.SS3.SSS0.Px1.p1.17.m15.1.1">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS0.Px1.p1.17.m15.1c">\mathcal{O}\left(1\right)</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.SSS0.Px1.p1.17.m15.1d">caligraphic_O ( 1 )</annotation></semantics></math> time complexity.</p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Experimental Setup</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">We conduct experiments with transformers, RetNet, and Mamba for MT in §<a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#S4" title="4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_tag">4</span></a> and §<a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#S5" title="5 Paragraph-level translation ‣ 4.2 Recall of Named Entities ‣ 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_tag">5</span></a>.
In this section, we detail the sentence and paragraph-level datasets used in our experiments, along with the settings for our models, which are trained in two distinct regimes: from scratch, or finetuned from a pretrained checkpoint.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Datasets</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.4">For sentence-level experiments, we focus on WMT14 <span class="ltx_text ltx_font_smallcaps" id="S3.SS1.p1.1.1">de<math alttext="\to" class="ltx_Math" display="inline" id="S3.SS1.p1.1.1.m1.1"><semantics id="S3.SS1.p1.1.1.m1.1a"><mo id="S3.SS1.p1.1.1.m1.1.1" stretchy="false" xref="S3.SS1.p1.1.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.1.m1.1b"><ci id="S3.SS1.p1.1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.1.m1.1c">\to</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.1.1.m1.1d">→</annotation></semantics></math>en</span> and WMT16 <span class="ltx_text ltx_font_smallcaps" id="S3.SS1.p1.2.2">ro<math alttext="\to" class="ltx_Math" display="inline" id="S3.SS1.p1.2.2.m1.1"><semantics id="S3.SS1.p1.2.2.m1.1a"><mo id="S3.SS1.p1.2.2.m1.1.1" stretchy="false" xref="S3.SS1.p1.2.2.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.2.m1.1b"><ci id="S3.SS1.p1.2.2.m1.1.1.cmml" xref="S3.SS1.p1.2.2.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.2.m1.1c">\to</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.2.2.m1.1d">→</annotation></semantics></math>en</span> for consistency with previous works <cite class="ltx_cite ltx_citemacro_citep">(Vardasbi et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib42" title="">2023</a>)</cite>, using the standard training, validation and test splits.
For paragraph level, we use the more recent WMT23 dataset <cite class="ltx_cite ltx_citemacro_citep">(Kocmi et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib26" title="">2023</a>)</cite>, which contains <math alttext="\sim" class="ltx_Math" display="inline" id="S3.SS1.p1.3.m1.1"><semantics id="S3.SS1.p1.3.m1.1a"><mo id="S3.SS1.p1.3.m1.1.1" xref="S3.SS1.p1.3.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m1.1b"><csymbol cd="latexml" id="S3.SS1.p1.3.m1.1.1.cmml" xref="S3.SS1.p1.3.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m1.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.3.m1.1d">∼</annotation></semantics></math>300M training samples and <math alttext="\sim" class="ltx_Math" display="inline" id="S3.SS1.p1.4.m2.1"><semantics id="S3.SS1.p1.4.m2.1a"><mo id="S3.SS1.p1.4.m2.1.1" xref="S3.SS1.p1.4.m2.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m2.1b"><csymbol cd="latexml" id="S3.SS1.p1.4.m2.1.1.cmml" xref="S3.SS1.p1.4.m2.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m2.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.4.m2.1d">∼</annotation></semantics></math>1K test samples incorporating multi-sentence passages.
In order to obtain a small high-quality subset for training, we exclude ParaCrawl and CommonCrawl samples from the original dataset and clean the remaining data.
Our cleaning process includes three steps. First, we identify and remove samples in incorrect languages via <span class="ltx_text ltx_font_typewriter" id="S3.SS1.p1.4.3">langdetect<span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_serif" id="footnote5.1.1.1">5</span></span><a class="ltx_ref ltx_url" href="https://github.com/Mimino666/langdetect" title="">https://github.com/Mimino666/langdetect</a></span></span></span></span>. Second, we eliminate duplicates. Third, we rank the samples using <span class="ltx_text ltx_font_smallcaps" id="S3.SS1.p1.4.4">CometKiwi-22</span> <cite class="ltx_cite ltx_citemacro_citep">(Rei et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib31" title="">2022b</a>)</cite> a state-of-the-art translation quality estimator, and keep only the top 6M samples. We call the refined dataset WMT23-6M.
Datasets statistics are shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#S3.SS1" title="3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_tag">3.1</span></a>.</p>
</div>
<figure class="ltx_table" id="S3.SS1.18">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_1">
<table class="ltx_tabular ltx_figure_panel ltx_align_middle" id="S3.SS1.18.18">
<tr class="ltx_tr" id="S3.SS1.18.18.19">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S3.SS1.18.18.19.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_smallcaps" id="S3.SS1.18.18.19.1.1">Dataset</span></td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="S3.SS1.18.18.19.2" style="padding-left:4.0pt;padding-right:4.0pt;"># <span class="ltx_text ltx_font_smallcaps" id="S3.SS1.18.18.19.2.1">Samples</span>
</td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="S3.SS1.18.18.19.3" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_smallcaps" id="S3.SS1.18.18.19.3.1"># Tokens</span></td>
</tr>
<tr class="ltx_tr" id="S3.SS1.2.2.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.SS1.1.1.1.1" style="padding-left:4.0pt;padding-right:4.0pt;">IWSLT17 (<span class="ltx_text ltx_font_smallcaps" id="S3.SS1.1.1.1.1.1">de<math alttext="\leftrightarrow" class="ltx_Math" display="inline" id="S3.SS1.1.1.1.1.1.m1.1"><semantics id="S3.SS1.1.1.1.1.1.m1.1a"><mo id="S3.SS1.1.1.1.1.1.m1.1.1" stretchy="false" xref="S3.SS1.1.1.1.1.1.m1.1.1.cmml">↔</mo><annotation-xml encoding="MathML-Content" id="S3.SS1.1.1.1.1.1.m1.1b"><ci id="S3.SS1.1.1.1.1.1.m1.1.1.cmml" xref="S3.SS1.1.1.1.1.1.m1.1.1">↔</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.1.1.1.1.1.m1.1c">\leftrightarrow</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.1.1.1.1.1.m1.1d">↔</annotation></semantics></math>en</span>)</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.SS1.2.2.2.3" style="padding-left:4.0pt;padding-right:4.0pt;">200K</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.SS1.2.2.2.2" style="padding-left:4.0pt;padding-right:4.0pt;">45.2 <math alttext="\pm" class="ltx_Math" display="inline" id="S3.SS1.2.2.2.2.m1.1"><semantics id="S3.SS1.2.2.2.2.m1.1a"><mo id="S3.SS1.2.2.2.2.m1.1.1" mathcolor="#808080" xref="S3.SS1.2.2.2.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.SS1.2.2.2.2.m1.1b"><csymbol cd="latexml" id="S3.SS1.2.2.2.2.m1.1.1.cmml" xref="S3.SS1.2.2.2.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.2.2.2.2.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.2.2.2.2.m1.1d">±</annotation></semantics></math><span class="ltx_text" id="S3.SS1.2.2.2.2.1" style="color:#808080;"> 29.5</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.SS1.4.4.4">
<td class="ltx_td ltx_align_left" id="S3.SS1.3.3.3.1" style="padding-left:4.0pt;padding-right:4.0pt;">WMT16 (<span class="ltx_text ltx_font_smallcaps" id="S3.SS1.3.3.3.1.1">ro<math alttext="\leftrightarrow" class="ltx_Math" display="inline" id="S3.SS1.3.3.3.1.1.m1.1"><semantics id="S3.SS1.3.3.3.1.1.m1.1a"><mo id="S3.SS1.3.3.3.1.1.m1.1.1" stretchy="false" xref="S3.SS1.3.3.3.1.1.m1.1.1.cmml">↔</mo><annotation-xml encoding="MathML-Content" id="S3.SS1.3.3.3.1.1.m1.1b"><ci id="S3.SS1.3.3.3.1.1.m1.1.1.cmml" xref="S3.SS1.3.3.3.1.1.m1.1.1">↔</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.3.3.3.1.1.m1.1c">\leftrightarrow</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.3.3.3.1.1.m1.1d">↔</annotation></semantics></math>en</span>)</td>
<td class="ltx_td ltx_align_left" id="S3.SS1.4.4.4.3" style="padding-left:4.0pt;padding-right:4.0pt;">610K</td>
<td class="ltx_td ltx_align_left" id="S3.SS1.4.4.4.2" style="padding-left:4.0pt;padding-right:4.0pt;">58.9 <math alttext="\pm" class="ltx_Math" display="inline" id="S3.SS1.4.4.4.2.m1.1"><semantics id="S3.SS1.4.4.4.2.m1.1a"><mo id="S3.SS1.4.4.4.2.m1.1.1" mathcolor="#808080" xref="S3.SS1.4.4.4.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.SS1.4.4.4.2.m1.1b"><csymbol cd="latexml" id="S3.SS1.4.4.4.2.m1.1.1.cmml" xref="S3.SS1.4.4.4.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.4.4.4.2.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.4.4.4.2.m1.1d">±</annotation></semantics></math><span class="ltx_text" id="S3.SS1.4.4.4.2.1" style="color:#808080;"> 31.1</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.SS1.6.6.6">
<td class="ltx_td ltx_align_left" id="S3.SS1.5.5.5.1" style="padding-left:4.0pt;padding-right:4.0pt;">WMT14 (<span class="ltx_text ltx_font_smallcaps" id="S3.SS1.5.5.5.1.1">de<math alttext="\leftrightarrow" class="ltx_Math" display="inline" id="S3.SS1.5.5.5.1.1.m1.1"><semantics id="S3.SS1.5.5.5.1.1.m1.1a"><mo id="S3.SS1.5.5.5.1.1.m1.1.1" stretchy="false" xref="S3.SS1.5.5.5.1.1.m1.1.1.cmml">↔</mo><annotation-xml encoding="MathML-Content" id="S3.SS1.5.5.5.1.1.m1.1b"><ci id="S3.SS1.5.5.5.1.1.m1.1.1.cmml" xref="S3.SS1.5.5.5.1.1.m1.1.1">↔</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.5.5.5.1.1.m1.1c">\leftrightarrow</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.5.5.5.1.1.m1.1d">↔</annotation></semantics></math>en</span>)</td>
<td class="ltx_td ltx_align_left" id="S3.SS1.6.6.6.3" style="padding-left:4.0pt;padding-right:4.0pt;">4.5M</td>
<td class="ltx_td ltx_align_left" id="S3.SS1.6.6.6.2" style="padding-left:4.0pt;padding-right:4.0pt;">62.1 <math alttext="\pm" class="ltx_Math" display="inline" id="S3.SS1.6.6.6.2.m1.1"><semantics id="S3.SS1.6.6.6.2.m1.1a"><mo id="S3.SS1.6.6.6.2.m1.1.1" mathcolor="#808080" xref="S3.SS1.6.6.6.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.SS1.6.6.6.2.m1.1b"><csymbol cd="latexml" id="S3.SS1.6.6.6.2.m1.1.1.cmml" xref="S3.SS1.6.6.6.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.6.6.6.2.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.6.6.6.2.m1.1d">±</annotation></semantics></math><span class="ltx_text" id="S3.SS1.6.6.6.2.1" style="color:#808080;"> 45.6</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.SS1.8.8.8">
<td class="ltx_td ltx_align_left" id="S3.SS1.7.7.7.1" style="padding-left:4.0pt;padding-right:4.0pt;">WMT23-6M (<span class="ltx_text ltx_font_smallcaps" id="S3.SS1.7.7.7.1.1">de<math alttext="\leftrightarrow" class="ltx_Math" display="inline" id="S3.SS1.7.7.7.1.1.m1.1"><semantics id="S3.SS1.7.7.7.1.1.m1.1a"><mo id="S3.SS1.7.7.7.1.1.m1.1.1" stretchy="false" xref="S3.SS1.7.7.7.1.1.m1.1.1.cmml">↔</mo><annotation-xml encoding="MathML-Content" id="S3.SS1.7.7.7.1.1.m1.1b"><ci id="S3.SS1.7.7.7.1.1.m1.1.1.cmml" xref="S3.SS1.7.7.7.1.1.m1.1.1">↔</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.7.7.7.1.1.m1.1c">\leftrightarrow</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.7.7.7.1.1.m1.1d">↔</annotation></semantics></math>en</span>)</td>
<td class="ltx_td ltx_align_left" id="S3.SS1.8.8.8.3" style="padding-left:4.0pt;padding-right:4.0pt;">6M</td>
<td class="ltx_td ltx_align_left" id="S3.SS1.8.8.8.2" style="padding-left:4.0pt;padding-right:4.0pt;">58.4 <math alttext="\pm" class="ltx_Math" display="inline" id="S3.SS1.8.8.8.2.m1.1"><semantics id="S3.SS1.8.8.8.2.m1.1a"><mo id="S3.SS1.8.8.8.2.m1.1.1" mathcolor="#808080" xref="S3.SS1.8.8.8.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.SS1.8.8.8.2.m1.1b"><csymbol cd="latexml" id="S3.SS1.8.8.8.2.m1.1.1.cmml" xref="S3.SS1.8.8.8.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.8.8.8.2.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.8.8.8.2.m1.1d">±</annotation></semantics></math><span class="ltx_text" id="S3.SS1.8.8.8.2.1" style="color:#808080;"> 32.9</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.SS1.10.10.10">
<td class="ltx_td ltx_align_left" id="S3.SS1.9.9.9.1" style="padding-left:4.0pt;padding-right:4.0pt;">
<span class="ltx_ERROR undefined" id="S3.SS1.9.9.9.1.2">\cdashline</span>1-3[.4pt/2pt]

WMT23-CAT-5 (<span class="ltx_text ltx_font_smallcaps" id="S3.SS1.9.9.9.1.1">de<math alttext="\leftrightarrow" class="ltx_Math" display="inline" id="S3.SS1.9.9.9.1.1.m1.1"><semantics id="S3.SS1.9.9.9.1.1.m1.1a"><mo id="S3.SS1.9.9.9.1.1.m1.1.1" stretchy="false" xref="S3.SS1.9.9.9.1.1.m1.1.1.cmml">↔</mo><annotation-xml encoding="MathML-Content" id="S3.SS1.9.9.9.1.1.m1.1b"><ci id="S3.SS1.9.9.9.1.1.m1.1.1.cmml" xref="S3.SS1.9.9.9.1.1.m1.1.1">↔</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.9.9.9.1.1.m1.1c">\leftrightarrow</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.9.9.9.1.1.m1.1d">↔</annotation></semantics></math>en</span>)</td>
<td class="ltx_td ltx_align_left" id="S3.SS1.10.10.10.3" style="padding-left:4.0pt;padding-right:4.0pt;">2M</td>
<td class="ltx_td ltx_align_left" id="S3.SS1.10.10.10.2" style="padding-left:4.0pt;padding-right:4.0pt;">171.3 <math alttext="\pm" class="ltx_Math" display="inline" id="S3.SS1.10.10.10.2.m1.1"><semantics id="S3.SS1.10.10.10.2.m1.1a"><mo id="S3.SS1.10.10.10.2.m1.1.1" mathcolor="#808080" xref="S3.SS1.10.10.10.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.SS1.10.10.10.2.m1.1b"><csymbol cd="latexml" id="S3.SS1.10.10.10.2.m1.1.1.cmml" xref="S3.SS1.10.10.10.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.10.10.10.2.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.10.10.10.2.m1.1d">±</annotation></semantics></math><span class="ltx_text" id="S3.SS1.10.10.10.2.1" style="color:#808080;"> 134.9</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.SS1.12.12.12">
<td class="ltx_td ltx_align_left" id="S3.SS1.11.11.11.1" style="padding-left:4.0pt;padding-right:4.0pt;">WMT23-CAT-10 (<span class="ltx_text ltx_font_smallcaps" id="S3.SS1.11.11.11.1.1">de<math alttext="\leftrightarrow" class="ltx_Math" display="inline" id="S3.SS1.11.11.11.1.1.m1.1"><semantics id="S3.SS1.11.11.11.1.1.m1.1a"><mo id="S3.SS1.11.11.11.1.1.m1.1.1" stretchy="false" xref="S3.SS1.11.11.11.1.1.m1.1.1.cmml">↔</mo><annotation-xml encoding="MathML-Content" id="S3.SS1.11.11.11.1.1.m1.1b"><ci id="S3.SS1.11.11.11.1.1.m1.1.1.cmml" xref="S3.SS1.11.11.11.1.1.m1.1.1">↔</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.11.11.11.1.1.m1.1c">\leftrightarrow</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.11.11.11.1.1.m1.1d">↔</annotation></semantics></math>en</span>)</td>
<td class="ltx_td ltx_align_left" id="S3.SS1.12.12.12.3" style="padding-left:4.0pt;padding-right:4.0pt;">1M</td>
<td class="ltx_td ltx_align_left" id="S3.SS1.12.12.12.2" style="padding-left:4.0pt;padding-right:4.0pt;">312.4 <math alttext="\pm" class="ltx_Math" display="inline" id="S3.SS1.12.12.12.2.m1.1"><semantics id="S3.SS1.12.12.12.2.m1.1a"><mo id="S3.SS1.12.12.12.2.m1.1.1" mathcolor="#808080" xref="S3.SS1.12.12.12.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.SS1.12.12.12.2.m1.1b"><csymbol cd="latexml" id="S3.SS1.12.12.12.2.m1.1.1.cmml" xref="S3.SS1.12.12.12.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.12.12.12.2.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.12.12.12.2.m1.1d">±</annotation></semantics></math><span class="ltx_text" id="S3.SS1.12.12.12.2.1" style="color:#808080;"> 282.3</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.SS1.14.14.14">
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.SS1.13.13.13.1" style="padding-left:4.0pt;padding-right:4.0pt;">Ted Talks Val. (<span class="ltx_text ltx_font_smallcaps" id="S3.SS1.13.13.13.1.1">de<math alttext="\leftrightarrow" class="ltx_Math" display="inline" id="S3.SS1.13.13.13.1.1.m1.1"><semantics id="S3.SS1.13.13.13.1.1.m1.1a"><mo id="S3.SS1.13.13.13.1.1.m1.1.1" stretchy="false" xref="S3.SS1.13.13.13.1.1.m1.1.1.cmml">↔</mo><annotation-xml encoding="MathML-Content" id="S3.SS1.13.13.13.1.1.m1.1b"><ci id="S3.SS1.13.13.13.1.1.m1.1.1.cmml" xref="S3.SS1.13.13.13.1.1.m1.1.1">↔</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.13.13.13.1.1.m1.1c">\leftrightarrow</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.13.13.13.1.1.m1.1d">↔</annotation></semantics></math>en</span>)</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.SS1.14.14.14.3" style="padding-left:4.0pt;padding-right:4.0pt;">995</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.SS1.14.14.14.2" style="padding-left:4.0pt;padding-right:4.0pt;">268.5 <math alttext="\pm" class="ltx_Math" display="inline" id="S3.SS1.14.14.14.2.m1.1"><semantics id="S3.SS1.14.14.14.2.m1.1a"><mo id="S3.SS1.14.14.14.2.m1.1.1" mathcolor="#808080" xref="S3.SS1.14.14.14.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.SS1.14.14.14.2.m1.1b"><csymbol cd="latexml" id="S3.SS1.14.14.14.2.m1.1.1.cmml" xref="S3.SS1.14.14.14.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.14.14.14.2.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.14.14.14.2.m1.1d">±</annotation></semantics></math><span class="ltx_text" id="S3.SS1.14.14.14.2.1" style="color:#808080;"> 189.6</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.SS1.16.16.16">
<td class="ltx_td ltx_align_left" id="S3.SS1.15.15.15.1" style="padding-left:4.0pt;padding-right:4.0pt;">WMT23 Test (<span class="ltx_text ltx_font_smallcaps" id="S3.SS1.15.15.15.1.1">de<math alttext="\to" class="ltx_Math" display="inline" id="S3.SS1.15.15.15.1.1.m1.1"><semantics id="S3.SS1.15.15.15.1.1.m1.1a"><mo id="S3.SS1.15.15.15.1.1.m1.1.1" stretchy="false" xref="S3.SS1.15.15.15.1.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S3.SS1.15.15.15.1.1.m1.1b"><ci id="S3.SS1.15.15.15.1.1.m1.1.1.cmml" xref="S3.SS1.15.15.15.1.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.15.15.15.1.1.m1.1c">\to</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.15.15.15.1.1.m1.1d">→</annotation></semantics></math>en</span>)</td>
<td class="ltx_td ltx_align_left" id="S3.SS1.16.16.16.3" style="padding-left:4.0pt;padding-right:4.0pt;">549</td>
<td class="ltx_td ltx_align_left" id="S3.SS1.16.16.16.2" style="padding-left:4.0pt;padding-right:4.0pt;">135.1 <math alttext="\pm" class="ltx_Math" display="inline" id="S3.SS1.16.16.16.2.m1.1"><semantics id="S3.SS1.16.16.16.2.m1.1a"><mo id="S3.SS1.16.16.16.2.m1.1.1" mathcolor="#808080" xref="S3.SS1.16.16.16.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.SS1.16.16.16.2.m1.1b"><csymbol cd="latexml" id="S3.SS1.16.16.16.2.m1.1.1.cmml" xref="S3.SS1.16.16.16.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.16.16.16.2.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.16.16.16.2.m1.1d">±</annotation></semantics></math><span class="ltx_text" id="S3.SS1.16.16.16.2.1" style="color:#808080;"> 147.7</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.SS1.18.18.18">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S3.SS1.17.17.17.1" style="padding-left:4.0pt;padding-right:4.0pt;">WMT23 Test (<span class="ltx_text ltx_font_smallcaps" id="S3.SS1.17.17.17.1.1">en<math alttext="\to" class="ltx_Math" display="inline" id="S3.SS1.17.17.17.1.1.m1.1"><semantics id="S3.SS1.17.17.17.1.1.m1.1a"><mo id="S3.SS1.17.17.17.1.1.m1.1.1" stretchy="false" xref="S3.SS1.17.17.17.1.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S3.SS1.17.17.17.1.1.m1.1b"><ci id="S3.SS1.17.17.17.1.1.m1.1.1.cmml" xref="S3.SS1.17.17.17.1.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.17.17.17.1.1.m1.1c">\to</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.17.17.17.1.1.m1.1d">→</annotation></semantics></math>de</span>)</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S3.SS1.18.18.18.3" style="padding-left:4.0pt;padding-right:4.0pt;">557</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S3.SS1.18.18.18.2" style="padding-left:4.0pt;padding-right:4.0pt;">185.2 <math alttext="\pm" class="ltx_Math" display="inline" id="S3.SS1.18.18.18.2.m1.1"><semantics id="S3.SS1.18.18.18.2.m1.1a"><mo id="S3.SS1.18.18.18.2.m1.1.1" mathcolor="#808080" xref="S3.SS1.18.18.18.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.SS1.18.18.18.2.m1.1b"><csymbol cd="latexml" id="S3.SS1.18.18.18.2.m1.1.1.cmml" xref="S3.SS1.18.18.18.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.18.18.18.2.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.18.18.18.2.m1.1d">±</annotation></semantics></math><span class="ltx_text" id="S3.SS1.18.18.18.2.1" style="color:#808080;"> 188.2</span>
</td>
</tr>
</table>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span>Sentence and paragraph-level datasets statistics.</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<section class="ltx_subsection ltx_figure_panel" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Models</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">We make a broad selection of models spanning both trained-from-scratch and finetuned versions. In the first setting, we compare standard transformers, linear recurrent models, and also hybrid approaches that integrate attention into Mamba. For finetuned models, we experiment with released Pythia and Mamba checkpoints. We describe each model next.</p>
</div>
<section class="ltx_subsubsection" id="S3.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.1 </span>Standard Models</h4>
<section class="ltx_paragraph" id="S3.SS2.SSS1.Px1">
<h5 class="ltx_title ltx_title_paragraph">Transformers.</h5>
<div class="ltx_para" id="S3.SS2.SSS1.Px1.p1">
<p class="ltx_p" id="S3.SS2.SSS1.Px1.p1.1">We select two variants of the transformer model as baselines: a base encoder-decoder formulation and a modern decoder-only version. The <span class="ltx_text ltx_font_bold" id="S3.SS2.SSS1.Px1.p1.1.1">Transformer Enc-Dec.</span> model, as described in the original paper <cite class="ltx_cite ltx_citemacro_citep">(Vaswani et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib44" title="">2017</a>)</cite>, has 77M parameters, and uses sinusoidal positional embeddings and standard ReLU activations. The second variant, <span class="ltx_text ltx_font_bold" id="S3.SS2.SSS1.Px1.p1.1.2">Transformer++</span>, is a decoder-only formulation incorporating recent advancements, such as rotary positional embeddings <cite class="ltx_cite ltx_citemacro_citep">(Su et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib37" title="">2023</a>)</cite> and the SwiGLU layer <cite class="ltx_cite ltx_citemacro_citep">(Shazeer, <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib33" title="">2020</a>)</cite>.
Specifically, we use the LLaMA architecture <cite class="ltx_cite ltx_citemacro_citep">(Touvron et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib40" title="">2023</a>)</cite>, adjusting the embedding dimension to match the parameter count of the base transformer (79M), consistent with the version employed in <cite class="ltx_cite ltx_citemacro_citep">(Gu and Dao, <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib19" title="">2023</a>)</cite>.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS2.SSS1.Px2">
<h5 class="ltx_title ltx_title_paragraph">Linear recurrent models.</h5>
<div class="ltx_para" id="S3.SS2.SSS1.Px2.p1">
<p class="ltx_p" id="S3.SS2.SSS1.Px2.p1.1">We select two representative recurrent models, <span class="ltx_text ltx_font_bold" id="S3.SS2.SSS1.Px2.p1.1.1">RetNet</span> <cite class="ltx_cite ltx_citemacro_citep">(Sun et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib38" title="">2023a</a>)</cite> and <span class="ltx_text ltx_font_bold" id="S3.SS2.SSS1.Px2.p1.1.2">Mamba</span> <cite class="ltx_cite ltx_citemacro_citep">(Gu and Dao, <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib19" title="">2023</a>)</cite>.
Both models are tested with 77M parameters to approximately match the number of parameters in the transformer models.</p>
</div>
</section>
</section>
<section class="ltx_subsubsection" id="S3.SS2.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.2 </span>Hybrid Models</h4>
<div class="ltx_para" id="S3.SS2.SSS2.p1">
<p class="ltx_p" id="S3.SS2.SSS2.p1.1">Previous work has shown that incorporating attention into linear recurrent models leads to strong performance in language modeling <cite class="ltx_cite ltx_citemacro_citep">(Fu et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib16" title="">2023</a>; Arora et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib4" title="">2024</a>; De et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib12" title="">2024</a>)</cite>. Therefore, we aim to examine if this is also the case for MT by exploring three hybrid variants, detailed next.</p>
</div>
<section class="ltx_paragraph" id="S3.SS2.SSS2.Px1">
<h5 class="ltx_title ltx_title_paragraph">Mamba-MHA.</h5>
<div class="ltx_para" id="S3.SS2.SSS2.Px1.p1">
<p class="ltx_p" id="S3.SS2.SSS2.Px1.p1.1">The simplest hybrid formulation involves replacing some of the Mamba layers with attention. Some natural questions then arise: how many attention layers are needed, and where to place them?
After careful ablations, detailed in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#A2" title="Appendix B Hybrid Models Ablation ‣ A.3 Inference Cost ‣ A.2 Finetuning Pretrained Checkpoints ‣ A.1 Training from Scratch ‣ Appendix A Implementation and Training Details ‣ Potential Risks ‣ Limitations ‣ Acknowledgments ‣ 7 Conclusion ‣ Sentence concatenation ‣ 6 Related Works ‣ 5.3 Inference Cost ‣ Discussion. ‣ 5.2 Sensitivity to Input Length ‣ Finetuning outperforms training from scratch. ‣ 5.1 Discussion ‣ 5 Paragraph-level translation ‣ 4.2 Recall of Named Entities ‣ 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_tag">B</span></a>, we use two attention layers placed at the middle and at the output of the network, resembling the hybrid version of H3 <cite class="ltx_cite ltx_citemacro_citep">(Fu et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib16" title="">2023</a>)</cite>.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS2.SSS2.Px2">
<h5 class="ltx_title ltx_title_paragraph">Mamba-Local.</h5>
<div class="ltx_para" id="S3.SS2.SSS2.Px2.p1">
<p class="ltx_p" id="S3.SS2.SSS2.Px2.p1.1">While aiming to achieve robust performance, the introduction of full attention to Mamba disrupts its efficiency gains. Thus, we consider local attention variants such as sliding window attention <cite class="ltx_cite ltx_citemacro_citep">(Beltagy et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib5" title="">2020</a>; Child et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib10" title="">2019</a>)</cite>, employed in recent hybrid models <cite class="ltx_cite ltx_citemacro_citep">(Arora et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib4" title="">2024</a>; De et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib12" title="">2024</a>)</cite>.
We use a window size of <math alttext="64" class="ltx_Math" display="inline" id="S3.SS2.SSS2.Px2.p1.1.m1.1"><semantics id="S3.SS2.SSS2.Px2.p1.1.m1.1a"><mn id="S3.SS2.SSS2.Px2.p1.1.m1.1.1" xref="S3.SS2.SSS2.Px2.p1.1.m1.1.1.cmml">64</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.Px2.p1.1.m1.1b"><cn id="S3.SS2.SSS2.Px2.p1.1.m1.1.1.cmml" type="integer" xref="S3.SS2.SSS2.Px2.p1.1.m1.1.1">64</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.Px2.p1.1.m1.1c">64</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.Px2.p1.1.m1.1d">64</annotation></semantics></math> based on the average sequence length shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#S3.SS1" title="3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_tag">3.1</span></a> and ablations in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#A2" title="Appendix B Hybrid Models Ablation ‣ A.3 Inference Cost ‣ A.2 Finetuning Pretrained Checkpoints ‣ A.1 Training from Scratch ‣ Appendix A Implementation and Training Details ‣ Potential Risks ‣ Limitations ‣ Acknowledgments ‣ 7 Conclusion ‣ Sentence concatenation ‣ 6 Related Works ‣ 5.3 Inference Cost ‣ Discussion. ‣ 5.2 Sensitivity to Input Length ‣ Finetuning outperforms training from scratch. ‣ 5.1 Discussion ‣ 5 Paragraph-level translation ‣ 4.2 Recall of Named Entities ‣ 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_tag">B</span></a>.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS2.SSS2.Px3">
<h5 class="ltx_title ltx_title_paragraph">Mamba Enc-Dec.</h5>
<div class="ltx_para" id="S3.SS2.SSS2.Px3.p1">
<p class="ltx_p" id="S3.SS2.SSS2.Px3.p1.2">Lastly, inspired by the S4-based encoder-decoder model from <cite class="ltx_cite ltx_citemacro_citet">Vardasbi et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib42" title="">2023</a>)</cite>, we replace the self-attention mechanism in transformers with a Mamba block and keep the cross-attention component intact.
In terms of complexity, since this variant computes attention over the source sentence, it incurs an additional <math alttext="\mathcal{O}\left(n^{2}\right)" class="ltx_Math" display="inline" id="S3.SS2.SSS2.Px3.p1.1.m1.1"><semantics id="S3.SS2.SSS2.Px3.p1.1.m1.1a"><mrow id="S3.SS2.SSS2.Px3.p1.1.m1.1.1" xref="S3.SS2.SSS2.Px3.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.SSS2.Px3.p1.1.m1.1.1.3" xref="S3.SS2.SSS2.Px3.p1.1.m1.1.1.3.cmml">𝒪</mi><mo id="S3.SS2.SSS2.Px3.p1.1.m1.1.1.2" xref="S3.SS2.SSS2.Px3.p1.1.m1.1.1.2.cmml">⁢</mo><mrow id="S3.SS2.SSS2.Px3.p1.1.m1.1.1.1.1" xref="S3.SS2.SSS2.Px3.p1.1.m1.1.1.1.1.1.cmml"><mo id="S3.SS2.SSS2.Px3.p1.1.m1.1.1.1.1.2" xref="S3.SS2.SSS2.Px3.p1.1.m1.1.1.1.1.1.cmml">(</mo><msup id="S3.SS2.SSS2.Px3.p1.1.m1.1.1.1.1.1" xref="S3.SS2.SSS2.Px3.p1.1.m1.1.1.1.1.1.cmml"><mi id="S3.SS2.SSS2.Px3.p1.1.m1.1.1.1.1.1.2" xref="S3.SS2.SSS2.Px3.p1.1.m1.1.1.1.1.1.2.cmml">n</mi><mn id="S3.SS2.SSS2.Px3.p1.1.m1.1.1.1.1.1.3" xref="S3.SS2.SSS2.Px3.p1.1.m1.1.1.1.1.1.3.cmml">2</mn></msup><mo id="S3.SS2.SSS2.Px3.p1.1.m1.1.1.1.1.3" xref="S3.SS2.SSS2.Px3.p1.1.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.Px3.p1.1.m1.1b"><apply id="S3.SS2.SSS2.Px3.p1.1.m1.1.1.cmml" xref="S3.SS2.SSS2.Px3.p1.1.m1.1.1"><times id="S3.SS2.SSS2.Px3.p1.1.m1.1.1.2.cmml" xref="S3.SS2.SSS2.Px3.p1.1.m1.1.1.2"></times><ci id="S3.SS2.SSS2.Px3.p1.1.m1.1.1.3.cmml" xref="S3.SS2.SSS2.Px3.p1.1.m1.1.1.3">𝒪</ci><apply id="S3.SS2.SSS2.Px3.p1.1.m1.1.1.1.1.1.cmml" xref="S3.SS2.SSS2.Px3.p1.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.Px3.p1.1.m1.1.1.1.1.1.1.cmml" xref="S3.SS2.SSS2.Px3.p1.1.m1.1.1.1.1">superscript</csymbol><ci id="S3.SS2.SSS2.Px3.p1.1.m1.1.1.1.1.1.2.cmml" xref="S3.SS2.SSS2.Px3.p1.1.m1.1.1.1.1.1.2">𝑛</ci><cn id="S3.SS2.SSS2.Px3.p1.1.m1.1.1.1.1.1.3.cmml" type="integer" xref="S3.SS2.SSS2.Px3.p1.1.m1.1.1.1.1.1.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.Px3.p1.1.m1.1c">\mathcal{O}\left(n^{2}\right)</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.Px3.p1.1.m1.1d">caligraphic_O ( italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT )</annotation></semantics></math> cost for training and <math alttext="\mathcal{O}\left(n\right)" class="ltx_Math" display="inline" id="S3.SS2.SSS2.Px3.p1.2.m2.1"><semantics id="S3.SS2.SSS2.Px3.p1.2.m2.1a"><mrow id="S3.SS2.SSS2.Px3.p1.2.m2.1.2" xref="S3.SS2.SSS2.Px3.p1.2.m2.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.SSS2.Px3.p1.2.m2.1.2.2" xref="S3.SS2.SSS2.Px3.p1.2.m2.1.2.2.cmml">𝒪</mi><mo id="S3.SS2.SSS2.Px3.p1.2.m2.1.2.1" xref="S3.SS2.SSS2.Px3.p1.2.m2.1.2.1.cmml">⁢</mo><mrow id="S3.SS2.SSS2.Px3.p1.2.m2.1.2.3.2" xref="S3.SS2.SSS2.Px3.p1.2.m2.1.2.cmml"><mo id="S3.SS2.SSS2.Px3.p1.2.m2.1.2.3.2.1" xref="S3.SS2.SSS2.Px3.p1.2.m2.1.2.cmml">(</mo><mi id="S3.SS2.SSS2.Px3.p1.2.m2.1.1" xref="S3.SS2.SSS2.Px3.p1.2.m2.1.1.cmml">n</mi><mo id="S3.SS2.SSS2.Px3.p1.2.m2.1.2.3.2.2" xref="S3.SS2.SSS2.Px3.p1.2.m2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.Px3.p1.2.m2.1b"><apply id="S3.SS2.SSS2.Px3.p1.2.m2.1.2.cmml" xref="S3.SS2.SSS2.Px3.p1.2.m2.1.2"><times id="S3.SS2.SSS2.Px3.p1.2.m2.1.2.1.cmml" xref="S3.SS2.SSS2.Px3.p1.2.m2.1.2.1"></times><ci id="S3.SS2.SSS2.Px3.p1.2.m2.1.2.2.cmml" xref="S3.SS2.SSS2.Px3.p1.2.m2.1.2.2">𝒪</ci><ci id="S3.SS2.SSS2.Px3.p1.2.m2.1.1.cmml" xref="S3.SS2.SSS2.Px3.p1.2.m2.1.1">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.Px3.p1.2.m2.1c">\mathcal{O}\left(n\right)</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.Px3.p1.2.m2.1d">caligraphic_O ( italic_n )</annotation></semantics></math> for inference.</p>
</div>
</section>
</section>
<section class="ltx_subsubsection" id="S3.SS2.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.3 </span>Pretrained Models</h4>
<div class="ltx_para" id="S3.SS2.SSS3.p1">
<p class="ltx_p" id="S3.SS2.SSS3.p1.1">In order to fairly evaluate the relative performance between pretrained models, we need to ensure consistency between their pretraining data.
Taking this into account, we consider two strong models pretrained on The Pile <cite class="ltx_cite ltx_citemacro_citep">(Gao et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib17" title="">2020</a>)</cite>: Pythia <cite class="ltx_cite ltx_citemacro_citep">(Biderman et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib6" title="">2023</a>)</cite>, a modern transformer, and Mamba, a modern SSM.
Note, however, that Pythia was pretrained on more tokens than Mamba (see Table <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#A1.T6" title="Table 6 ‣ A.2 Finetuning Pretrained Checkpoints ‣ A.1 Training from Scratch ‣ Appendix A Implementation and Training Details ‣ Potential Risks ‣ Limitations ‣ Acknowledgments ‣ 7 Conclusion ‣ Sentence concatenation ‣ 6 Related Works ‣ 5.3 Inference Cost ‣ Discussion. ‣ 5.2 Sensitivity to Input Length ‣ Finetuning outperforms training from scratch. ‣ 5.1 Discussion ‣ 5 Paragraph-level translation ‣ 4.2 Recall of Named Entities ‣ 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_tag">6</span></a>), hence the comparison might be slightly unfavorable to Mamba.
We experiment with two model scales, <em class="ltx_emph ltx_font_italic" id="S3.SS2.SSS3.p1.1.1">small</em> (S) and <em class="ltx_emph ltx_font_italic" id="S3.SS2.SSS3.p1.1.2">medium</em> (M).
Concretely, we experiment with Pythia 410M and 1.4B, and with Mamba 370M and 1.4B.</p>
</div>
<figure class="ltx_table" id="S3.SS2.SSS3.4">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_1">
<table class="ltx_tabular ltx_figure_panel ltx_align_middle" id="S3.SS2.SSS3.4.4">
<tr class="ltx_tr" id="S3.SS2.SSS3.4.4.5">
<td class="ltx_td ltx_border_tt" id="S3.SS2.SSS3.4.4.5.1" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_border_tt" id="S3.SS2.SSS3.4.4.5.2" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_border_tt" id="S3.SS2.SSS3.4.4.5.3" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="5" id="S3.SS2.SSS3.4.4.5.4" style="padding-left:4.0pt;padding-right:4.0pt;">WMT16</td>
<td class="ltx_td ltx_border_tt" id="S3.SS2.SSS3.4.4.5.5" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="5" id="S3.SS2.SSS3.4.4.5.6" style="padding-left:4.0pt;padding-right:4.0pt;">WMT14</td>
</tr>
<tr class="ltx_tr" id="S3.SS2.SSS3.4.4.4">
<td class="ltx_td" id="S3.SS2.SSS3.4.4.4.5" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td" id="S3.SS2.SSS3.4.4.4.6" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td" id="S3.SS2.SSS3.4.4.4.7" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="2" id="S3.SS2.SSS3.1.1.1.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_smallcaps" id="S3.SS2.SSS3.1.1.1.1.1">ro<math alttext="\to" class="ltx_Math" display="inline" id="S3.SS2.SSS3.1.1.1.1.1.m1.1"><semantics id="S3.SS2.SSS3.1.1.1.1.1.m1.1a"><mo id="S3.SS2.SSS3.1.1.1.1.1.m1.1.1" stretchy="false" xref="S3.SS2.SSS3.1.1.1.1.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.1.1.1.1.1.m1.1b"><ci id="S3.SS2.SSS3.1.1.1.1.1.m1.1.1.cmml" xref="S3.SS2.SSS3.1.1.1.1.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.1.1.1.1.1.m1.1c">\to</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS3.1.1.1.1.1.m1.1d">→</annotation></semantics></math>en</span></td>
<td class="ltx_td ltx_border_t" id="S3.SS2.SSS3.4.4.4.8" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="2" id="S3.SS2.SSS3.2.2.2.2" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_smallcaps" id="S3.SS2.SSS3.2.2.2.2.1">en<math alttext="\to" class="ltx_Math" display="inline" id="S3.SS2.SSS3.2.2.2.2.1.m1.1"><semantics id="S3.SS2.SSS3.2.2.2.2.1.m1.1a"><mo id="S3.SS2.SSS3.2.2.2.2.1.m1.1.1" stretchy="false" xref="S3.SS2.SSS3.2.2.2.2.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.2.2.2.2.1.m1.1b"><ci id="S3.SS2.SSS3.2.2.2.2.1.m1.1.1.cmml" xref="S3.SS2.SSS3.2.2.2.2.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.2.2.2.2.1.m1.1c">\to</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS3.2.2.2.2.1.m1.1d">→</annotation></semantics></math>ro</span></td>
<td class="ltx_td" id="S3.SS2.SSS3.4.4.4.9" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="2" id="S3.SS2.SSS3.3.3.3.3" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_smallcaps" id="S3.SS2.SSS3.3.3.3.3.1">de<math alttext="\to" class="ltx_Math" display="inline" id="S3.SS2.SSS3.3.3.3.3.1.m1.1"><semantics id="S3.SS2.SSS3.3.3.3.3.1.m1.1a"><mo id="S3.SS2.SSS3.3.3.3.3.1.m1.1.1" stretchy="false" xref="S3.SS2.SSS3.3.3.3.3.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.3.3.3.3.1.m1.1b"><ci id="S3.SS2.SSS3.3.3.3.3.1.m1.1.1.cmml" xref="S3.SS2.SSS3.3.3.3.3.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.3.3.3.3.1.m1.1c">\to</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS3.3.3.3.3.1.m1.1d">→</annotation></semantics></math>en</span></td>
<td class="ltx_td ltx_border_t" id="S3.SS2.SSS3.4.4.4.10" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="2" id="S3.SS2.SSS3.4.4.4.4" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_smallcaps" id="S3.SS2.SSS3.4.4.4.4.1">en<math alttext="\to" class="ltx_Math" display="inline" id="S3.SS2.SSS3.4.4.4.4.1.m1.1"><semantics id="S3.SS2.SSS3.4.4.4.4.1.m1.1a"><mo id="S3.SS2.SSS3.4.4.4.4.1.m1.1.1" stretchy="false" xref="S3.SS2.SSS3.4.4.4.4.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.4.4.4.4.1.m1.1b"><ci id="S3.SS2.SSS3.4.4.4.4.1.m1.1.1.cmml" xref="S3.SS2.SSS3.4.4.4.4.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.4.4.4.4.1.m1.1c">\to</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS3.4.4.4.4.1.m1.1d">→</annotation></semantics></math>de</span></td>
</tr>
<tr class="ltx_tr" id="S3.SS2.SSS3.4.4.6">
<td class="ltx_td ltx_align_left" id="S3.SS2.SSS3.4.4.6.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_smallcaps" id="S3.SS2.SSS3.4.4.6.1.1">Model</span></td>
<td class="ltx_td ltx_align_left" id="S3.SS2.SSS3.4.4.6.2" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_smallcaps" id="S3.SS2.SSS3.4.4.6.2.1">Size</span></td>
<td class="ltx_td" id="S3.SS2.SSS3.4.4.6.3" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" id="S3.SS2.SSS3.4.4.6.4" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_smallcaps" id="S3.SS2.SSS3.4.4.6.4.1">bleu</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.SS2.SSS3.4.4.6.5" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_smallcaps" id="S3.SS2.SSS3.4.4.6.5.1">comet</span></td>
<td class="ltx_td" id="S3.SS2.SSS3.4.4.6.6" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" id="S3.SS2.SSS3.4.4.6.7" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_smallcaps" id="S3.SS2.SSS3.4.4.6.7.1">bleu</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.SS2.SSS3.4.4.6.8" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_smallcaps" id="S3.SS2.SSS3.4.4.6.8.1">comet</span></td>
<td class="ltx_td" id="S3.SS2.SSS3.4.4.6.9" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" id="S3.SS2.SSS3.4.4.6.10" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_smallcaps" id="S3.SS2.SSS3.4.4.6.10.1">bleu</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.SS2.SSS3.4.4.6.11" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_smallcaps" id="S3.SS2.SSS3.4.4.6.11.1">comet</span></td>
<td class="ltx_td" id="S3.SS2.SSS3.4.4.6.12" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" id="S3.SS2.SSS3.4.4.6.13" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_smallcaps" id="S3.SS2.SSS3.4.4.6.13.1">bleu</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.SS2.SSS3.4.4.6.14" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_smallcaps" id="S3.SS2.SSS3.4.4.6.14.1">comet</span></td>
</tr>
<tr class="ltx_tr" id="S3.SS2.SSS3.4.4.7">
<td class="ltx_td ltx_align_left ltx_border_t" colspan="10" id="S3.SS2.SSS3.4.4.7.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_italic" id="S3.SS2.SSS3.4.4.7.1.1">Trained from scratch</span></td>
<td class="ltx_td ltx_border_t" id="S3.SS2.SSS3.4.4.7.2" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_border_t" id="S3.SS2.SSS3.4.4.7.3" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_border_t" id="S3.SS2.SSS3.4.4.7.4" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_border_t" id="S3.SS2.SSS3.4.4.7.5" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
</tr>
<tr class="ltx_tr" id="S3.SS2.SSS3.4.4.8">
<td class="ltx_td ltx_align_left" id="S3.SS2.SSS3.4.4.8.1" style="padding-left:4.0pt;padding-right:4.0pt;">Transf. Enc-Dec</td>
<td class="ltx_td ltx_align_left" id="S3.SS2.SSS3.4.4.8.2" style="padding-left:4.0pt;padding-right:4.0pt;">77M</td>
<td class="ltx_td" id="S3.SS2.SSS3.4.4.8.3" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.SS2.SSS3.4.4.8.4" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S3.SS2.SSS3.4.4.8.4.1">29.2</span></td>
<td class="ltx_td ltx_align_center" id="S3.SS2.SSS3.4.4.8.5" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.SS2.SSS3.4.4.8.5.1">74.8</span></td>
<td class="ltx_td" id="S3.SS2.SSS3.4.4.8.6" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.SS2.SSS3.4.4.8.7" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.SS2.SSS3.4.4.8.7.1">22.0</span></td>
<td class="ltx_td ltx_align_center" id="S3.SS2.SSS3.4.4.8.8" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S3.SS2.SSS3.4.4.8.8.1">78.6</span></td>
<td class="ltx_td" id="S3.SS2.SSS3.4.4.8.9" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.SS2.SSS3.4.4.8.10" style="padding-left:4.0pt;padding-right:4.0pt;">27.4</td>
<td class="ltx_td ltx_align_center" id="S3.SS2.SSS3.4.4.8.11" style="padding-left:4.0pt;padding-right:4.0pt;">78.6</td>
<td class="ltx_td" id="S3.SS2.SSS3.4.4.8.12" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.SS2.SSS3.4.4.8.13" style="padding-left:4.0pt;padding-right:4.0pt;">22.3</td>
<td class="ltx_td ltx_align_center" id="S3.SS2.SSS3.4.4.8.14" style="padding-left:4.0pt;padding-right:4.0pt;">77.1</td>
</tr>
<tr class="ltx_tr" id="S3.SS2.SSS3.4.4.9">
<td class="ltx_td ltx_align_left" id="S3.SS2.SSS3.4.4.9.1" style="padding-left:4.0pt;padding-right:4.0pt;">Transformer++</td>
<td class="ltx_td ltx_align_left" id="S3.SS2.SSS3.4.4.9.2" style="padding-left:4.0pt;padding-right:4.0pt;">79M</td>
<td class="ltx_td" id="S3.SS2.SSS3.4.4.9.3" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.SS2.SSS3.4.4.9.4" style="padding-left:4.0pt;padding-right:4.0pt;">26.4</td>
<td class="ltx_td ltx_align_center" id="S3.SS2.SSS3.4.4.9.5" style="padding-left:4.0pt;padding-right:4.0pt;">72.6</td>
<td class="ltx_td" id="S3.SS2.SSS3.4.4.9.6" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.SS2.SSS3.4.4.9.7" style="padding-left:4.0pt;padding-right:4.0pt;">21.7</td>
<td class="ltx_td ltx_align_center" id="S3.SS2.SSS3.4.4.9.8" style="padding-left:4.0pt;padding-right:4.0pt;">72.7</td>
<td class="ltx_td" id="S3.SS2.SSS3.4.4.9.9" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.SS2.SSS3.4.4.9.10" style="padding-left:4.0pt;padding-right:4.0pt;">26.9</td>
<td class="ltx_td ltx_align_center" id="S3.SS2.SSS3.4.4.9.11" style="padding-left:4.0pt;padding-right:4.0pt;">79.0</td>
<td class="ltx_td" id="S3.SS2.SSS3.4.4.9.12" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.SS2.SSS3.4.4.9.13" style="padding-left:4.0pt;padding-right:4.0pt;">22.8</td>
<td class="ltx_td ltx_align_center" id="S3.SS2.SSS3.4.4.9.14" style="padding-left:4.0pt;padding-right:4.0pt;">77.9</td>
</tr>
<tr class="ltx_tr" id="S3.SS2.SSS3.4.4.10">
<td class="ltx_td ltx_align_left" id="S3.SS2.SSS3.4.4.10.1" style="padding-left:4.0pt;padding-right:4.0pt;">RetNet</td>
<td class="ltx_td ltx_align_left" id="S3.SS2.SSS3.4.4.10.2" style="padding-left:4.0pt;padding-right:4.0pt;">77M</td>
<td class="ltx_td" id="S3.SS2.SSS3.4.4.10.3" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.SS2.SSS3.4.4.10.4" style="padding-left:4.0pt;padding-right:4.0pt;">26.4</td>
<td class="ltx_td ltx_align_center" id="S3.SS2.SSS3.4.4.10.5" style="padding-left:4.0pt;padding-right:4.0pt;">72.4</td>
<td class="ltx_td" id="S3.SS2.SSS3.4.4.10.6" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.SS2.SSS3.4.4.10.7" style="padding-left:4.0pt;padding-right:4.0pt;">19.9</td>
<td class="ltx_td ltx_align_center" id="S3.SS2.SSS3.4.4.10.8" style="padding-left:4.0pt;padding-right:4.0pt;">76.0</td>
<td class="ltx_td" id="S3.SS2.SSS3.4.4.10.9" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.SS2.SSS3.4.4.10.10" style="padding-left:4.0pt;padding-right:4.0pt;">23.4</td>
<td class="ltx_td ltx_align_center" id="S3.SS2.SSS3.4.4.10.11" style="padding-left:4.0pt;padding-right:4.0pt;">74.7</td>
<td class="ltx_td" id="S3.SS2.SSS3.4.4.10.12" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.SS2.SSS3.4.4.10.13" style="padding-left:4.0pt;padding-right:4.0pt;">19.6</td>
<td class="ltx_td ltx_align_center" id="S3.SS2.SSS3.4.4.10.14" style="padding-left:4.0pt;padding-right:4.0pt;">71.7</td>
</tr>
<tr class="ltx_tr" id="S3.SS2.SSS3.4.4.11">
<td class="ltx_td ltx_align_left" id="S3.SS2.SSS3.4.4.11.1" style="padding-left:4.0pt;padding-right:4.0pt;">Mamba</td>
<td class="ltx_td ltx_align_left" id="S3.SS2.SSS3.4.4.11.2" style="padding-left:4.0pt;padding-right:4.0pt;">77M</td>
<td class="ltx_td" id="S3.SS2.SSS3.4.4.11.3" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.SS2.SSS3.4.4.11.4" style="padding-left:4.0pt;padding-right:4.0pt;">27.0</td>
<td class="ltx_td ltx_align_center" id="S3.SS2.SSS3.4.4.11.5" style="padding-left:4.0pt;padding-right:4.0pt;">73.8</td>
<td class="ltx_td" id="S3.SS2.SSS3.4.4.11.6" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.SS2.SSS3.4.4.11.7" style="padding-left:4.0pt;padding-right:4.0pt;">21.4</td>
<td class="ltx_td ltx_align_center" id="S3.SS2.SSS3.4.4.11.8" style="padding-left:4.0pt;padding-right:4.0pt;">77.9</td>
<td class="ltx_td" id="S3.SS2.SSS3.4.4.11.9" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.SS2.SSS3.4.4.11.10" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S3.SS2.SSS3.4.4.11.10.1">27.5</span></td>
<td class="ltx_td ltx_align_center" id="S3.SS2.SSS3.4.4.11.11" style="padding-left:4.0pt;padding-right:4.0pt;">80.2</td>
<td class="ltx_td" id="S3.SS2.SSS3.4.4.11.12" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.SS2.SSS3.4.4.11.13" style="padding-left:4.0pt;padding-right:4.0pt;">22.4</td>
<td class="ltx_td ltx_align_center" id="S3.SS2.SSS3.4.4.11.14" style="padding-left:4.0pt;padding-right:4.0pt;">77.8</td>
</tr>
<tr class="ltx_tr" id="S3.SS2.SSS3.4.4.12">
<td class="ltx_td ltx_align_left" id="S3.SS2.SSS3.4.4.12.1" style="padding-left:4.0pt;padding-right:4.0pt;">
<span class="ltx_ERROR undefined" id="S3.SS2.SSS3.4.4.12.1.1">\cdashline</span>1-14[.4pt/2pt]

Mamba-MHA</td>
<td class="ltx_td ltx_align_left" id="S3.SS2.SSS3.4.4.12.2" style="padding-left:4.0pt;padding-right:4.0pt;">78M</td>
<td class="ltx_td" id="S3.SS2.SSS3.4.4.12.3" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.SS2.SSS3.4.4.12.4" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.SS2.SSS3.4.4.12.4.1">28.5</span></td>
<td class="ltx_td ltx_align_center" id="S3.SS2.SSS3.4.4.12.5" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S3.SS2.SSS3.4.4.12.5.1">75.1</span></td>
<td class="ltx_td" id="S3.SS2.SSS3.4.4.12.6" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.SS2.SSS3.4.4.12.7" style="padding-left:4.0pt;padding-right:4.0pt;">21.7</td>
<td class="ltx_td ltx_align_center" id="S3.SS2.SSS3.4.4.12.8" style="padding-left:4.0pt;padding-right:4.0pt;">78.3</td>
<td class="ltx_td" id="S3.SS2.SSS3.4.4.12.9" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.SS2.SSS3.4.4.12.10" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.SS2.SSS3.4.4.12.10.1">27.4</span></td>
<td class="ltx_td ltx_align_center" id="S3.SS2.SSS3.4.4.12.11" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S3.SS2.SSS3.4.4.12.11.1">80.6</span></td>
<td class="ltx_td" id="S3.SS2.SSS3.4.4.12.12" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.SS2.SSS3.4.4.12.13" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S3.SS2.SSS3.4.4.12.13.1">23.2</span></td>
<td class="ltx_td ltx_align_center" id="S3.SS2.SSS3.4.4.12.14" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S3.SS2.SSS3.4.4.12.14.1">79.9</span></td>
</tr>
<tr class="ltx_tr" id="S3.SS2.SSS3.4.4.13">
<td class="ltx_td ltx_align_left" id="S3.SS2.SSS3.4.4.13.1" style="padding-left:4.0pt;padding-right:4.0pt;">Mamba-Local</td>
<td class="ltx_td ltx_align_left" id="S3.SS2.SSS3.4.4.13.2" style="padding-left:4.0pt;padding-right:4.0pt;">78M</td>
<td class="ltx_td" id="S3.SS2.SSS3.4.4.13.3" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.SS2.SSS3.4.4.13.4" style="padding-left:4.0pt;padding-right:4.0pt;">25.9</td>
<td class="ltx_td ltx_align_center" id="S3.SS2.SSS3.4.4.13.5" style="padding-left:4.0pt;padding-right:4.0pt;">73.9</td>
<td class="ltx_td" id="S3.SS2.SSS3.4.4.13.6" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.SS2.SSS3.4.4.13.7" style="padding-left:4.0pt;padding-right:4.0pt;">20.9</td>
<td class="ltx_td ltx_align_center" id="S3.SS2.SSS3.4.4.13.8" style="padding-left:4.0pt;padding-right:4.0pt;">76.9</td>
<td class="ltx_td" id="S3.SS2.SSS3.4.4.13.9" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.SS2.SSS3.4.4.13.10" style="padding-left:4.0pt;padding-right:4.0pt;">27.2</td>
<td class="ltx_td ltx_align_center" id="S3.SS2.SSS3.4.4.13.11" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.SS2.SSS3.4.4.13.11.1">80.1</span></td>
<td class="ltx_td" id="S3.SS2.SSS3.4.4.13.12" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.SS2.SSS3.4.4.13.13" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.SS2.SSS3.4.4.13.13.1">23.2</span></td>
<td class="ltx_td ltx_align_center" id="S3.SS2.SSS3.4.4.13.14" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.SS2.SSS3.4.4.13.14.1">79.5</span></td>
</tr>
<tr class="ltx_tr" id="S3.SS2.SSS3.4.4.14">
<td class="ltx_td ltx_align_left" id="S3.SS2.SSS3.4.4.14.1" style="padding-left:4.0pt;padding-right:4.0pt;">Mamba Enc-Dec</td>
<td class="ltx_td ltx_align_left" id="S3.SS2.SSS3.4.4.14.2" style="padding-left:4.0pt;padding-right:4.0pt;">82M</td>
<td class="ltx_td" id="S3.SS2.SSS3.4.4.14.3" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.SS2.SSS3.4.4.14.4" style="padding-left:4.0pt;padding-right:4.0pt;">28.5</td>
<td class="ltx_td ltx_align_center" id="S3.SS2.SSS3.4.4.14.5" style="padding-left:4.0pt;padding-right:4.0pt;">74.4</td>
<td class="ltx_td" id="S3.SS2.SSS3.4.4.14.6" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.SS2.SSS3.4.4.14.7" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S3.SS2.SSS3.4.4.14.7.1">22.7</span></td>
<td class="ltx_td ltx_align_center" id="S3.SS2.SSS3.4.4.14.8" style="padding-left:4.0pt;padding-right:4.0pt;">77.9</td>
<td class="ltx_td" id="S3.SS2.SSS3.4.4.14.9" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.SS2.SSS3.4.4.14.10" style="padding-left:4.0pt;padding-right:4.0pt;">27.2</td>
<td class="ltx_td ltx_align_center" id="S3.SS2.SSS3.4.4.14.11" style="padding-left:4.0pt;padding-right:4.0pt;">80.0</td>
<td class="ltx_td" id="S3.SS2.SSS3.4.4.14.12" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.SS2.SSS3.4.4.14.13" style="padding-left:4.0pt;padding-right:4.0pt;">21.6</td>
<td class="ltx_td ltx_align_center" id="S3.SS2.SSS3.4.4.14.14" style="padding-left:4.0pt;padding-right:4.0pt;">78.8</td>
</tr>
<tr class="ltx_tr" id="S3.SS2.SSS3.4.4.15">
<td class="ltx_td ltx_align_left ltx_border_t" colspan="10" id="S3.SS2.SSS3.4.4.15.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_italic" id="S3.SS2.SSS3.4.4.15.1.1">Finetuned</span></td>
<td class="ltx_td ltx_border_t" id="S3.SS2.SSS3.4.4.15.2" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_border_t" id="S3.SS2.SSS3.4.4.15.3" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_border_t" id="S3.SS2.SSS3.4.4.15.4" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_border_t" id="S3.SS2.SSS3.4.4.15.5" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
</tr>
<tr class="ltx_tr" id="S3.SS2.SSS3.4.4.16">
<td class="ltx_td ltx_align_left" id="S3.SS2.SSS3.4.4.16.1" style="padding-left:4.0pt;padding-right:4.0pt;">Pythia-S</td>
<td class="ltx_td ltx_align_left" id="S3.SS2.SSS3.4.4.16.2" style="padding-left:4.0pt;padding-right:4.0pt;">410M</td>
<td class="ltx_td" id="S3.SS2.SSS3.4.4.16.3" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.SS2.SSS3.4.4.16.4" style="padding-left:4.0pt;padding-right:4.0pt;">33.4</td>
<td class="ltx_td ltx_align_center" id="S3.SS2.SSS3.4.4.16.5" style="padding-left:4.0pt;padding-right:4.0pt;">82.0</td>
<td class="ltx_td" id="S3.SS2.SSS3.4.4.16.6" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.SS2.SSS3.4.4.16.7" style="padding-left:4.0pt;padding-right:4.0pt;">24.1</td>
<td class="ltx_td ltx_align_center" id="S3.SS2.SSS3.4.4.16.8" style="padding-left:4.0pt;padding-right:4.0pt;">85.8</td>
<td class="ltx_td" id="S3.SS2.SSS3.4.4.16.9" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.SS2.SSS3.4.4.16.10" style="padding-left:4.0pt;padding-right:4.0pt;">30.9</td>
<td class="ltx_td ltx_align_center" id="S3.SS2.SSS3.4.4.16.11" style="padding-left:4.0pt;padding-right:4.0pt;">83.6</td>
<td class="ltx_td" id="S3.SS2.SSS3.4.4.16.12" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.SS2.SSS3.4.4.16.13" style="padding-left:4.0pt;padding-right:4.0pt;">25.2</td>
<td class="ltx_td ltx_align_center" id="S3.SS2.SSS3.4.4.16.14" style="padding-left:4.0pt;padding-right:4.0pt;">84.0</td>
</tr>
<tr class="ltx_tr" id="S3.SS2.SSS3.4.4.17">
<td class="ltx_td ltx_align_left" id="S3.SS2.SSS3.4.4.17.1" style="padding-left:4.0pt;padding-right:4.0pt;">Mamba-S</td>
<td class="ltx_td ltx_align_left" id="S3.SS2.SSS3.4.4.17.2" style="padding-left:4.0pt;padding-right:4.0pt;">370M</td>
<td class="ltx_td" id="S3.SS2.SSS3.4.4.17.3" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.SS2.SSS3.4.4.17.4" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S3.SS2.SSS3.4.4.17.4.1">34.1</span></td>
<td class="ltx_td ltx_align_center" id="S3.SS2.SSS3.4.4.17.5" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S3.SS2.SSS3.4.4.17.5.1">83.2</span></td>
<td class="ltx_td" id="S3.SS2.SSS3.4.4.17.6" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.SS2.SSS3.4.4.17.7" style="padding-left:4.0pt;padding-right:4.0pt;">24.2</td>
<td class="ltx_td ltx_align_center" id="S3.SS2.SSS3.4.4.17.8" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.SS2.SSS3.4.4.17.8.1">86.4</span></td>
<td class="ltx_td" id="S3.SS2.SSS3.4.4.17.9" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.SS2.SSS3.4.4.17.10" style="padding-left:4.0pt;padding-right:4.0pt;">29.8</td>
<td class="ltx_td ltx_align_center" id="S3.SS2.SSS3.4.4.17.11" style="padding-left:4.0pt;padding-right:4.0pt;">83.3</td>
<td class="ltx_td" id="S3.SS2.SSS3.4.4.17.12" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.SS2.SSS3.4.4.17.13" style="padding-left:4.0pt;padding-right:4.0pt;">25.0</td>
<td class="ltx_td ltx_align_center" id="S3.SS2.SSS3.4.4.17.14" style="padding-left:4.0pt;padding-right:4.0pt;">83.2</td>
</tr>
<tr class="ltx_tr" id="S3.SS2.SSS3.4.4.18">
<td class="ltx_td ltx_align_left" id="S3.SS2.SSS3.4.4.18.1" style="padding-left:4.0pt;padding-right:4.0pt;">Pythia-M</td>
<td class="ltx_td ltx_align_left" id="S3.SS2.SSS3.4.4.18.2" style="padding-left:4.0pt;padding-right:4.0pt;">1.4B</td>
<td class="ltx_td" id="S3.SS2.SSS3.4.4.18.3" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.SS2.SSS3.4.4.18.4" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.SS2.SSS3.4.4.18.4.1">33.9</span></td>
<td class="ltx_td ltx_align_center" id="S3.SS2.SSS3.4.4.18.5" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S3.SS2.SSS3.4.4.18.5.1">83.2</span></td>
<td class="ltx_td" id="S3.SS2.SSS3.4.4.18.6" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.SS2.SSS3.4.4.18.7" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S3.SS2.SSS3.4.4.18.7.1">24.9</span></td>
<td class="ltx_td ltx_align_center" id="S3.SS2.SSS3.4.4.18.8" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S3.SS2.SSS3.4.4.18.8.1">87.1</span></td>
<td class="ltx_td" id="S3.SS2.SSS3.4.4.18.9" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.SS2.SSS3.4.4.18.10" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S3.SS2.SSS3.4.4.18.10.1">32.2</span></td>
<td class="ltx_td ltx_align_center" id="S3.SS2.SSS3.4.4.18.11" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S3.SS2.SSS3.4.4.18.11.1">84.5</span></td>
<td class="ltx_td" id="S3.SS2.SSS3.4.4.18.12" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.SS2.SSS3.4.4.18.13" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S3.SS2.SSS3.4.4.18.13.1">26.7</span></td>
<td class="ltx_td ltx_align_center" id="S3.SS2.SSS3.4.4.18.14" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S3.SS2.SSS3.4.4.18.14.1">84.9</span></td>
</tr>
<tr class="ltx_tr" id="S3.SS2.SSS3.4.4.19">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S3.SS2.SSS3.4.4.19.1" style="padding-left:4.0pt;padding-right:4.0pt;">Mamba-M</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S3.SS2.SSS3.4.4.19.2" style="padding-left:4.0pt;padding-right:4.0pt;">1.4B</td>
<td class="ltx_td ltx_border_bb" id="S3.SS2.SSS3.4.4.19.3" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb" id="S3.SS2.SSS3.4.4.19.4" style="padding-left:4.0pt;padding-right:4.0pt;">33.8</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.SS2.SSS3.4.4.19.5" style="padding-left:4.0pt;padding-right:4.0pt;">83.1</td>
<td class="ltx_td ltx_border_bb" id="S3.SS2.SSS3.4.4.19.6" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb" id="S3.SS2.SSS3.4.4.19.7" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.SS2.SSS3.4.4.19.7.1">24.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.SS2.SSS3.4.4.19.8" style="padding-left:4.0pt;padding-right:4.0pt;">86.2</td>
<td class="ltx_td ltx_border_bb" id="S3.SS2.SSS3.4.4.19.9" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb" id="S3.SS2.SSS3.4.4.19.10" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.SS2.SSS3.4.4.19.10.1">31.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.SS2.SSS3.4.4.19.11" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S3.SS2.SSS3.4.4.19.11.1">84.5</span></td>
<td class="ltx_td ltx_border_bb" id="S3.SS2.SSS3.4.4.19.12" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb" id="S3.SS2.SSS3.4.4.19.13" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.SS2.SSS3.4.4.19.13.1">26.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.SS2.SSS3.4.4.19.14" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.SS2.SSS3.4.4.19.14.1">84.2</span></td>
</tr>
</table>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span>Sentence-level results in terms of BLEU and COMET for models trained from scratch (top) and models finetuned from a pretrained checkpoint (bottom). <span class="ltx_text ltx_font_bold" id="S3.SS2.SSS3.4.7.1">Bold</span> represents top results; <span class="ltx_text ltx_framed ltx_framed_underline" id="S3.SS2.SSS3.4.8.2">underline</span> represents second-best.</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<section class="ltx_subsection ltx_figure_panel" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Training and Evaluation</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">For models trained from scratch, we follow the settings proposed in <cite class="ltx_cite ltx_citemacro_citep">(Vardasbi et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib42" title="">2023</a>)</cite>, whereas for pretrained models, we follow the finetuning settings used by Mamba <cite class="ltx_cite ltx_citemacro_citep">(Gu and Dao, <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib19" title="">2023</a>)</cite>.
For decoder-only models, we pass a concatenation of the source and target sequences separated by a special token as input.
We evaluate all models with BLEU <cite class="ltx_cite ltx_citemacro_citep">(Post, <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib29" title="">2018</a>)</cite><span class="ltx_note ltx_role_footnote" id="footnote6"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span>SacreBLEU signature: <span class="ltx_text ltx_font_typewriter" id="footnote6.1">|1|mixed|no|13a|exp|</span></span></span></span> and COMET <cite class="ltx_cite ltx_citemacro_citep">(Rei et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib30" title="">2022a</a>)</cite>.<span class="ltx_note ltx_role_footnote" id="footnote7"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span><a class="ltx_ref ltx_href ltx_font_typewriter" href="https://huggingface.co/Unbabel/wmt22-comet-da" title="">huggingface.co/Unbabel/wmt22-comet-da</a></span></span></span>
We base our analysis on the latter, given its strong correlation with human judgments on sentence and paragraph-level data <cite class="ltx_cite ltx_citemacro_citep">(Freitag et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib15" title="">2022</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib14" title="">2023</a>)</cite>.
More training details can be found in §<a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#A1" title="Appendix A Implementation and Training Details ‣ Potential Risks ‣ Limitations ‣ Acknowledgments ‣ 7 Conclusion ‣ Sentence concatenation ‣ 6 Related Works ‣ 5.3 Inference Cost ‣ Discussion. ‣ 5.2 Sensitivity to Input Length ‣ Finetuning outperforms training from scratch. ‣ 5.1 Discussion ‣ 5 Paragraph-level translation ‣ 4.2 Recall of Named Entities ‣ 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_tag">A</span></a>.</p>
</div>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Sentence-level Translation</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.2">We start by evaluating our standard, hybrid, and finetuned models on the sentence-level WMT16 <span class="ltx_text ltx_font_smallcaps" id="S4.p1.1.1">ro<math alttext="\leftrightarrow" class="ltx_Math" display="inline" id="S4.p1.1.1.m1.1"><semantics id="S4.p1.1.1.m1.1a"><mo id="S4.p1.1.1.m1.1.1" stretchy="false" xref="S4.p1.1.1.m1.1.1.cmml">↔</mo><annotation-xml encoding="MathML-Content" id="S4.p1.1.1.m1.1b"><ci id="S4.p1.1.1.m1.1.1.cmml" xref="S4.p1.1.1.m1.1.1">↔</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.1.1.m1.1c">\leftrightarrow</annotation><annotation encoding="application/x-llamapun" id="S4.p1.1.1.m1.1d">↔</annotation></semantics></math>en</span> and WMT14 <span class="ltx_text ltx_font_smallcaps" id="S4.p1.2.2">de<math alttext="\leftrightarrow" class="ltx_Math" display="inline" id="S4.p1.2.2.m1.1"><semantics id="S4.p1.2.2.m1.1a"><mo id="S4.p1.2.2.m1.1.1" stretchy="false" xref="S4.p1.2.2.m1.1.1.cmml">↔</mo><annotation-xml encoding="MathML-Content" id="S4.p1.2.2.m1.1b"><ci id="S4.p1.2.2.m1.1.1.cmml" xref="S4.p1.2.2.m1.1.1">↔</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.2.2.m1.1c">\leftrightarrow</annotation><annotation encoding="application/x-llamapun" id="S4.p1.2.2.m1.1d">↔</annotation></semantics></math>en</span> datasets.
Results can be found in Table <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#S3.SS2.SSS3" title="3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_tag">3.2.3</span></a> in terms of BLEU and COMET. Next, we discuss the key findings.</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Discussion</h3>
<section class="ltx_paragraph" id="S4.SS1.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Mamba is competitive when trained from scratch.</h5>
<div class="ltx_para" id="S4.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS1.SSS0.Px1.p1.2">Mamba, a decoder-only model, not only outperforms a decoder-only transformer (Transformer++) across the board, but also an encoder-decoder transformer (Transf. Enc-Dec) in the larger WMT14 for both <span class="ltx_text ltx_font_smallcaps" id="S4.SS1.SSS0.Px1.p1.1.1">de<math alttext="\leftrightarrow" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px1.p1.1.1.m1.1"><semantics id="S4.SS1.SSS0.Px1.p1.1.1.m1.1a"><mo id="S4.SS1.SSS0.Px1.p1.1.1.m1.1.1" stretchy="false" xref="S4.SS1.SSS0.Px1.p1.1.1.m1.1.1.cmml">↔</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px1.p1.1.1.m1.1b"><ci id="S4.SS1.SSS0.Px1.p1.1.1.m1.1.1.cmml" xref="S4.SS1.SSS0.Px1.p1.1.1.m1.1.1">↔</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px1.p1.1.1.m1.1c">\leftrightarrow</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS0.Px1.p1.1.1.m1.1d">↔</annotation></semantics></math>en</span> language pairs.
This creates a contrast with the S4 results obtained by <cite class="ltx_cite ltx_citemacro_citet">Vardasbi et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib42" title="">2023</a>)</cite>.
We hypothesize that Mamba’s good results are due to its data-dependent state updates (Eq. <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#S2.Ex7" title="Mamba. ‣ 2.3 State Space Models (SSMs) ‣ 2 Background ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_tag">2.3</span></a>), which allows for more precise information retention in its hidden state.
On the other hand, RetNet’s performance is generally subpar compared to other models, likely due to its strong locality bias (induced by <math alttext="\gamma" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px1.p1.2.m1.1"><semantics id="S4.SS1.SSS0.Px1.p1.2.m1.1a"><mi id="S4.SS1.SSS0.Px1.p1.2.m1.1.1" xref="S4.SS1.SSS0.Px1.p1.2.m1.1.1.cmml">γ</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px1.p1.2.m1.1b"><ci id="S4.SS1.SSS0.Px1.p1.2.m1.1.1.cmml" xref="S4.SS1.SSS0.Px1.p1.2.m1.1.1">𝛾</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px1.p1.2.m1.1c">\gamma</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS0.Px1.p1.2.m1.1d">italic_γ</annotation></semantics></math> in Eq. <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#S2.Ex4" title="Retentive Networks (RetNet). ‣ 2.2 Linear Attention ‣ 2 Background ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_tag">2.2</span></a>), which may hinder performance in MT,
a task where the source input servers as a prefix to the translation, and it requires “focused attention” during decoding.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS1.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">Attention benefits Mamba.</h5>
<div class="ltx_para" id="S4.SS1.SSS0.Px2.p1">
<p class="ltx_p" id="S4.SS1.SSS0.Px2.p1.1">By including attention layers in Mamba’s architecture, we find that Mamba-MHA, which employs only two attention layers, is able to outperform both transformers and Mamba for almost all language pairs.
While Mamba-Local retains constant inference complexity via windowed attention, it is not as strong as the full attention variant.
Finally, Mamba Enc-Dec’s performance is also competitive, falling just short of Mamba-MHA and echoing the S4 encoder-decoder findings of <cite class="ltx_cite ltx_citemacro_citet">Vardasbi et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib42" title="">2023</a>)</cite>.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS1.SSS0.Px3">
<h5 class="ltx_title ltx_title_paragraph">Pretraining improves all models.</h5>
<div class="ltx_para" id="S4.SS1.SSS0.Px3.p1">
<p class="ltx_p" id="S4.SS1.SSS0.Px3.p1.1">We note a large COMET gap, roughly 4-8 COMET points, between the finetuned models and those trained from scratch for all language pairs.
This is expected, since not only are these models bigger, but they also have strong data-driven priors, which are beneficial in downstream tasks <cite class="ltx_cite ltx_citemacro_citep">(Amos et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib2" title="">2024</a>)</cite>.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS1.SSS0.Px4">
<h5 class="ltx_title ltx_title_paragraph">Larger models achieve top results.</h5>
<div class="ltx_para" id="S4.SS1.SSS0.Px4.p1">
<p class="ltx_p" id="S4.SS1.SSS0.Px4.p1.5">For small models, Mamba outperforms Pythia for <span class="ltx_text ltx_font_smallcaps" id="S4.SS1.SSS0.Px4.p1.1.1">ro<math alttext="\leftrightarrow" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px4.p1.1.1.m1.1"><semantics id="S4.SS1.SSS0.Px4.p1.1.1.m1.1a"><mo id="S4.SS1.SSS0.Px4.p1.1.1.m1.1.1" stretchy="false" xref="S4.SS1.SSS0.Px4.p1.1.1.m1.1.1.cmml">↔</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px4.p1.1.1.m1.1b"><ci id="S4.SS1.SSS0.Px4.p1.1.1.m1.1.1.cmml" xref="S4.SS1.SSS0.Px4.p1.1.1.m1.1.1">↔</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px4.p1.1.1.m1.1c">\leftrightarrow</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS0.Px4.p1.1.1.m1.1d">↔</annotation></semantics></math>en</span> in terms of COMET and BLEU. However, Pythia is superior on the larger <span class="ltx_text ltx_font_smallcaps" id="S4.SS1.SSS0.Px4.p1.2.2">de<math alttext="\leftrightarrow" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px4.p1.2.2.m1.1"><semantics id="S4.SS1.SSS0.Px4.p1.2.2.m1.1a"><mo id="S4.SS1.SSS0.Px4.p1.2.2.m1.1.1" stretchy="false" xref="S4.SS1.SSS0.Px4.p1.2.2.m1.1.1.cmml">↔</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px4.p1.2.2.m1.1b"><ci id="S4.SS1.SSS0.Px4.p1.2.2.m1.1.1.cmml" xref="S4.SS1.SSS0.Px4.p1.2.2.m1.1.1">↔</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px4.p1.2.2.m1.1c">\leftrightarrow</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS0.Px4.p1.2.2.m1.1d">↔</annotation></semantics></math>en</span> datasets.
Moving to larger models, we note that Mamba improves COMET scores by <math alttext="\sim" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px4.p1.3.m1.1"><semantics id="S4.SS1.SSS0.Px4.p1.3.m1.1a"><mo id="S4.SS1.SSS0.Px4.p1.3.m1.1.1" xref="S4.SS1.SSS0.Px4.p1.3.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px4.p1.3.m1.1b"><csymbol cd="latexml" id="S4.SS1.SSS0.Px4.p1.3.m1.1.1.cmml" xref="S4.SS1.SSS0.Px4.p1.3.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px4.p1.3.m1.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS0.Px4.p1.3.m1.1d">∼</annotation></semantics></math>1 point on <span class="ltx_text ltx_font_smallcaps" id="S4.SS1.SSS0.Px4.p1.4.3">en<math alttext="\leftrightarrow" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px4.p1.4.3.m1.1"><semantics id="S4.SS1.SSS0.Px4.p1.4.3.m1.1a"><mo id="S4.SS1.SSS0.Px4.p1.4.3.m1.1.1" stretchy="false" xref="S4.SS1.SSS0.Px4.p1.4.3.m1.1.1.cmml">↔</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px4.p1.4.3.m1.1b"><ci id="S4.SS1.SSS0.Px4.p1.4.3.m1.1.1.cmml" xref="S4.SS1.SSS0.Px4.p1.4.3.m1.1.1">↔</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px4.p1.4.3.m1.1c">\leftrightarrow</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS0.Px4.p1.4.3.m1.1d">↔</annotation></semantics></math>de</span> while dropping only 0.1-0.2 on <span class="ltx_text ltx_font_smallcaps" id="S4.SS1.SSS0.Px4.p1.5.4">en<math alttext="\leftrightarrow" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px4.p1.5.4.m1.1"><semantics id="S4.SS1.SSS0.Px4.p1.5.4.m1.1a"><mo id="S4.SS1.SSS0.Px4.p1.5.4.m1.1.1" stretchy="false" xref="S4.SS1.SSS0.Px4.p1.5.4.m1.1.1.cmml">↔</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px4.p1.5.4.m1.1b"><ci id="S4.SS1.SSS0.Px4.p1.5.4.m1.1.1.cmml" xref="S4.SS1.SSS0.Px4.p1.5.4.m1.1.1">↔</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px4.p1.5.4.m1.1c">\leftrightarrow</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS0.Px4.p1.5.4.m1.1d">↔</annotation></semantics></math>ro</span> datasets.
On the other hand, Pythia improves results consistently for all language pairs with a larger model size, outperforming or matching the results of other models.
On average,
we find that both their gaps decrease when moving from smaller to medium-sized models but Pythia benefits more in terms of COMET.
It is worth noting that Mamba is pretrained on fewer samples than Pythia (see Table <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#A1.T6" title="Table 6 ‣ A.2 Finetuning Pretrained Checkpoints ‣ A.1 Training from Scratch ‣ Appendix A Implementation and Training Details ‣ Potential Risks ‣ Limitations ‣ Acknowledgments ‣ 7 Conclusion ‣ Sentence concatenation ‣ 6 Related Works ‣ 5.3 Inference Cost ‣ Discussion. ‣ 5.2 Sensitivity to Input Length ‣ Finetuning outperforms training from scratch. ‣ 5.1 Discussion ‣ 5 Paragraph-level translation ‣ 4.2 Recall of Named Entities ‣ 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_tag">6</span></a>) and that the impact of pretraining data quality can also play a role in downstream task performance.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Recall of Named Entities</h3>
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F1"><img alt="Refer to caption" class="ltx_graphics ltx_figure_panel ltx_img_landscape" height="181" id="S4.SS2.1.g1" src="x1.png" width="830"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Recall in recovering named entities on the WMT16 <span class="ltx_text ltx_font_smallcaps" id="S4.F1.4.1">ro<math alttext="\to" class="ltx_Math" display="inline" id="S4.F1.4.1.m1.1"><semantics id="S4.F1.4.1.m1.1b"><mo id="S4.F1.4.1.m1.1.1" stretchy="false" xref="S4.F1.4.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.F1.4.1.m1.1c"><ci id="S4.F1.4.1.m1.1.1.cmml" xref="S4.F1.4.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F1.4.1.m1.1d">\to</annotation><annotation encoding="application/x-llamapun" id="S4.F1.4.1.m1.1e">→</annotation></semantics></math>en</span> dataset by their training set frequency: <span class="ltx_text ltx_font_italic" id="S4.F1.10.2">unseen</span> entities do not appear in the training data, while <span class="ltx_text ltx_font_italic" id="S4.F1.11.3">regular</span> and <span class="ltx_text ltx_font_italic" id="S4.F1.12.4">frequent</span> entities appear <math alttext="[1,16)" class="ltx_Math" display="inline" id="S4.F1.5.m1.2"><semantics id="S4.F1.5.m1.2b"><mrow id="S4.F1.5.m1.2.3.2" xref="S4.F1.5.m1.2.3.1.cmml"><mo id="S4.F1.5.m1.2.3.2.1" stretchy="false" xref="S4.F1.5.m1.2.3.1.cmml">[</mo><mn id="S4.F1.5.m1.1.1" xref="S4.F1.5.m1.1.1.cmml">1</mn><mo id="S4.F1.5.m1.2.3.2.2" xref="S4.F1.5.m1.2.3.1.cmml">,</mo><mn id="S4.F1.5.m1.2.2" xref="S4.F1.5.m1.2.2.cmml">16</mn><mo id="S4.F1.5.m1.2.3.2.3" stretchy="false" xref="S4.F1.5.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.F1.5.m1.2c"><interval closure="closed-open" id="S4.F1.5.m1.2.3.1.cmml" xref="S4.F1.5.m1.2.3.2"><cn id="S4.F1.5.m1.1.1.cmml" type="integer" xref="S4.F1.5.m1.1.1">1</cn><cn id="S4.F1.5.m1.2.2.cmml" type="integer" xref="S4.F1.5.m1.2.2">16</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.F1.5.m1.2d">[1,16)</annotation><annotation encoding="application/x-llamapun" id="S4.F1.5.m1.2e">[ 1 , 16 )</annotation></semantics></math> and <math alttext="16+" class="ltx_Math" display="inline" id="S4.F1.6.m2.1"><semantics id="S4.F1.6.m2.1b"><mrow id="S4.F1.6.m2.1.1" xref="S4.F1.6.m2.1.1.cmml"><mn id="S4.F1.6.m2.1.1.2" xref="S4.F1.6.m2.1.1.2.cmml">16</mn><mo id="S4.F1.6.m2.1.1.3" xref="S4.F1.6.m2.1.1.3.cmml">+</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.F1.6.m2.1c"><apply id="S4.F1.6.m2.1.1.cmml" xref="S4.F1.6.m2.1.1"><csymbol cd="latexml" id="S4.F1.6.m2.1.1.1.cmml" xref="S4.F1.6.m2.1.1">limit-from</csymbol><cn id="S4.F1.6.m2.1.1.2.cmml" type="integer" xref="S4.F1.6.m2.1.1.2">16</cn><plus id="S4.F1.6.m2.1.1.3.cmml" xref="S4.F1.6.m2.1.1.3"></plus></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F1.6.m2.1d">16+</annotation><annotation encoding="application/x-llamapun" id="S4.F1.6.m2.1e">16 +</annotation></semantics></math> times.</figcaption>
</figure>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">Following our discussion of sentence-level translation, we now focus on how well these models recall context tokens during translation.
Inspired by prior studies investigating the recall of context tokens in language modeling with state space models <cite class="ltx_cite ltx_citemacro_citep">(Arora et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib3" title="">2023</a>; Jelassi et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib24" title="">2024</a>)</cite>, we conduct a similar experiment for MT.
Unlike language modeling, where token patterns often recur within a near context, MT presents a challenge due to the distinct spelling of words across languages. Therefore, we focus on the recall of named entities (NEs) that appear verbatim in both source and target sentences, using NLTK for NE recognition <cite class="ltx_cite ltx_citemacro_citep">(Bird, <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib7" title="">2006</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1">We assess the models’ ability to recall NEs from the WMT16 <span class="ltx_text ltx_font_smallcaps" id="S4.SS2.p2.1.1">ro<math alttext="\to" class="ltx_Math" display="inline" id="S4.SS2.p2.1.1.m1.1"><semantics id="S4.SS2.p2.1.1.m1.1a"><mo id="S4.SS2.p2.1.1.m1.1.1" stretchy="false" xref="S4.SS2.p2.1.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.1.1.m1.1b"><ci id="S4.SS2.p2.1.1.m1.1.1.cmml" xref="S4.SS2.p2.1.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.1.1.m1.1c">\to</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p2.1.1.m1.1d">→</annotation></semantics></math>en</span> dataset according to their frequency in the training set, as illustrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#S4.F1" title="Figure 1 ‣ 4.2 Recall of Named Entities ‣ 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_tag">1</span></a>.
The results reveal a clear correlation between NE frequency and their chance to be recalled in the translation process, as more frequent NEs are recalled more often.
Notably, we note a disparity in performance with unseen entities, which provides a more illustrative view of recall ability.
In this respect, transformers and Mamba perform on par, while RetNet shows inferior results.
As before, the hybrid models are promising, with Mamba-MHA outperforming all models, followed closely by Mamba Enc-Dec.</p>
</div>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Paragraph-level translation</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">While Mamba shows competitive performance with transformers on sentence-level datasets (see Table <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#S3.SS2.SSS3" title="3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_tag">3.2.3</span></a>), it was originally designed to handle long sequences.
Thus, we now turn our attention to paragraph-level datasets.
This allows us to study the models’ sensitivity to long sequence lengths along with their robustness in handling sequences that are longer than the ones seen during training.<span class="ltx_note ltx_role_footnote" id="footnote8"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span>We dropped RetNet and Mamba-Local as they already achieve poor results on long <em class="ltx_emph ltx_font_italic" id="footnote8.1">sentence-level</em> inputs (see Fig. <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#A3.F3" title="Figure 3 ‣ Appendix C Exploring Length-related Issues ‣ A.3 Inference Cost ‣ A.2 Finetuning Pretrained Checkpoints ‣ A.1 Training from Scratch ‣ Appendix A Implementation and Training Details ‣ Potential Risks ‣ Limitations ‣ Acknowledgments ‣ 7 Conclusion ‣ Sentence concatenation ‣ 6 Related Works ‣ 5.3 Inference Cost ‣ Discussion. ‣ 5.2 Sensitivity to Input Length ‣ Finetuning outperforms training from scratch. ‣ 5.1 Discussion ‣ 5 Paragraph-level translation ‣ 4.2 Recall of Named Entities ‣ 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_tag">3</span></a>).</span></span></span></p>
</div>
<div class="ltx_para" id="S5.p2">
<p class="ltx_p" id="S5.p2.1">To this end we focus on the WMT23-6M dataset (§<a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#S3.SS1" title="3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_tag">3.1</span></a>), from which the training and test sets are composed of sentence and paragraph-level passages, respectively.
In order to see the impact of training on long sequences, we propose to artificially construct multi-sentence datasets, which we call WMT23-CAT-<math alttext="N" class="ltx_Math" display="inline" id="S5.p2.1.m1.1"><semantics id="S5.p2.1.m1.1a"><mi id="S5.p2.1.m1.1.1" xref="S5.p2.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S5.p2.1.m1.1b"><ci id="S5.p2.1.m1.1.1.cmml" xref="S5.p2.1.m1.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.1.m1.1c">N</annotation><annotation encoding="application/x-llamapun" id="S5.p2.1.m1.1d">italic_N</annotation></semantics></math>. Our procedure is as follows:</p>
<ol class="ltx_enumerate" id="S5.I1">
<li class="ltx_item" id="S5.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S5.I1.i1.p1">
<p class="ltx_p" id="S5.I1.i1.p1.1">We first retain the original training samples from WMT23-6M with a probability of <math alttext="50\%" class="ltx_Math" display="inline" id="S5.I1.i1.p1.1.m1.1"><semantics id="S5.I1.i1.p1.1.m1.1a"><mrow id="S5.I1.i1.p1.1.m1.1.1" xref="S5.I1.i1.p1.1.m1.1.1.cmml"><mn id="S5.I1.i1.p1.1.m1.1.1.2" xref="S5.I1.i1.p1.1.m1.1.1.2.cmml">50</mn><mo id="S5.I1.i1.p1.1.m1.1.1.1" xref="S5.I1.i1.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.I1.i1.p1.1.m1.1b"><apply id="S5.I1.i1.p1.1.m1.1.1.cmml" xref="S5.I1.i1.p1.1.m1.1.1"><csymbol cd="latexml" id="S5.I1.i1.p1.1.m1.1.1.1.cmml" xref="S5.I1.i1.p1.1.m1.1.1.1">percent</csymbol><cn id="S5.I1.i1.p1.1.m1.1.1.2.cmml" type="integer" xref="S5.I1.i1.p1.1.m1.1.1.2">50</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.I1.i1.p1.1.m1.1c">50\%</annotation><annotation encoding="application/x-llamapun" id="S5.I1.i1.p1.1.m1.1d">50 %</annotation></semantics></math>.</p>
</div>
</li>
<li class="ltx_item" id="S5.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S5.I1.i2.p1">
<p class="ltx_p" id="S5.I1.i2.p1.1">Next, for the remaining part, we concatenate <math alttext="N" class="ltx_Math" display="inline" id="S5.I1.i2.p1.1.m1.1"><semantics id="S5.I1.i2.p1.1.m1.1a"><mi id="S5.I1.i2.p1.1.m1.1.1" xref="S5.I1.i2.p1.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S5.I1.i2.p1.1.m1.1b"><ci id="S5.I1.i2.p1.1.m1.1.1.cmml" xref="S5.I1.i2.p1.1.m1.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.I1.i2.p1.1.m1.1c">N</annotation><annotation encoding="application/x-llamapun" id="S5.I1.i2.p1.1.m1.1d">italic_N</annotation></semantics></math> random training samples.</p>
</div>
</li>
</ol>
<p class="ltx_p" id="S5.p2.4">This approach ensures that we consistently maintain a <math alttext="50\%" class="ltx_Math" display="inline" id="S5.p2.2.m1.1"><semantics id="S5.p2.2.m1.1a"><mrow id="S5.p2.2.m1.1.1" xref="S5.p2.2.m1.1.1.cmml"><mn id="S5.p2.2.m1.1.1.2" xref="S5.p2.2.m1.1.1.2.cmml">50</mn><mo id="S5.p2.2.m1.1.1.1" xref="S5.p2.2.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.p2.2.m1.1b"><apply id="S5.p2.2.m1.1.1.cmml" xref="S5.p2.2.m1.1.1"><csymbol cd="latexml" id="S5.p2.2.m1.1.1.1.cmml" xref="S5.p2.2.m1.1.1.1">percent</csymbol><cn id="S5.p2.2.m1.1.1.2.cmml" type="integer" xref="S5.p2.2.m1.1.1.2">50</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.2.m1.1c">50\%</annotation><annotation encoding="application/x-llamapun" id="S5.p2.2.m1.1d">50 %</annotation></semantics></math> ratio between single-sentence and multi-sentence samples.
For validation, we sample 1-to-10-sentence passages from the TED Talks dataset <cite class="ltx_cite ltx_citemacro_citep">(Cettolo et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib9" title="">2012</a>)</cite>.
Statistics for CAT-<math alttext="N" class="ltx_Math" display="inline" id="S5.p2.3.m2.1"><semantics id="S5.p2.3.m2.1a"><mi id="S5.p2.3.m2.1.1" xref="S5.p2.3.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S5.p2.3.m2.1b"><ci id="S5.p2.3.m2.1.1.cmml" xref="S5.p2.3.m2.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.3.m2.1c">N</annotation><annotation encoding="application/x-llamapun" id="S5.p2.3.m2.1d">italic_N</annotation></semantics></math> datasets can be found in Table <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#S3.SS1" title="3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_tag">3.1</span></a>.
COMET scores on the WMT23 <span class="ltx_text ltx_font_smallcaps" id="S5.p2.4.1">en<math alttext="\leftrightarrow" class="ltx_Math" display="inline" id="S5.p2.4.1.m1.1"><semantics id="S5.p2.4.1.m1.1a"><mo id="S5.p2.4.1.m1.1.1" stretchy="false" xref="S5.p2.4.1.m1.1.1.cmml">↔</mo><annotation-xml encoding="MathML-Content" id="S5.p2.4.1.m1.1b"><ci id="S5.p2.4.1.m1.1.1.cmml" xref="S5.p2.4.1.m1.1.1">↔</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.4.1.m1.1c">\leftrightarrow</annotation><annotation encoding="application/x-llamapun" id="S5.p2.4.1.m1.1d">↔</annotation></semantics></math>de</span> test sets are shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#S5" title="5 Paragraph-level translation ‣ 4.2 Recall of Named Entities ‣ 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_tag">5</span></a>. We provide additional BLEU scores in Table <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#A4" title="Appendix D Full Paragraph-Level Results ‣ A.3 Inference Cost ‣ A.2 Finetuning Pretrained Checkpoints ‣ A.1 Training from Scratch ‣ Appendix A Implementation and Training Details ‣ Potential Risks ‣ Limitations ‣ Acknowledgments ‣ 7 Conclusion ‣ Sentence concatenation ‣ 6 Related Works ‣ 5.3 Inference Cost ‣ Discussion. ‣ 5.2 Sensitivity to Input Length ‣ Finetuning outperforms training from scratch. ‣ 5.1 Discussion ‣ 5 Paragraph-level translation ‣ 4.2 Recall of Named Entities ‣ 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_tag">D</span></a> in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#A4" title="Appendix D Full Paragraph-Level Results ‣ A.3 Inference Cost ‣ A.2 Finetuning Pretrained Checkpoints ‣ A.1 Training from Scratch ‣ Appendix A Implementation and Training Details ‣ Potential Risks ‣ Limitations ‣ Acknowledgments ‣ 7 Conclusion ‣ Sentence concatenation ‣ 6 Related Works ‣ 5.3 Inference Cost ‣ Discussion. ‣ 5.2 Sensitivity to Input Length ‣ Finetuning outperforms training from scratch. ‣ 5.1 Discussion ‣ 5 Paragraph-level translation ‣ 4.2 Recall of Named Entities ‣ 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_tag">D</span></a>.
Next, we discuss our key findings.</p>
</div>
<figure class="ltx_table" id="S5.4">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_1">
<table class="ltx_tabular ltx_figure_panel ltx_align_middle" id="S5.2.2">
<tr class="ltx_tr" id="S5.2.2.2">
<td class="ltx_td ltx_border_tt" id="S5.2.2.2.3" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_border_tt" id="S5.2.2.2.4" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_r ltx_border_tt" id="S5.2.2.2.5" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="S5.1.1.1.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_smallcaps" id="S5.1.1.1.1.1">de<math alttext="\to" class="ltx_Math" display="inline" id="S5.1.1.1.1.1.m1.1"><semantics id="S5.1.1.1.1.1.m1.1a"><mo id="S5.1.1.1.1.1.m1.1.1" stretchy="false" xref="S5.1.1.1.1.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S5.1.1.1.1.1.m1.1b"><ci id="S5.1.1.1.1.1.m1.1.1.cmml" xref="S5.1.1.1.1.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.1.1.1.1.1.m1.1c">\to</annotation><annotation encoding="application/x-llamapun" id="S5.1.1.1.1.1.m1.1d">→</annotation></semantics></math>en</span></td>
<td class="ltx_td ltx_nopad_r ltx_border_tt" id="S5.2.2.2.6" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="S5.2.2.2.2" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_smallcaps" id="S5.2.2.2.2.1">en<math alttext="\to" class="ltx_Math" display="inline" id="S5.2.2.2.2.1.m1.1"><semantics id="S5.2.2.2.2.1.m1.1a"><mo id="S5.2.2.2.2.1.m1.1.1" stretchy="false" xref="S5.2.2.2.2.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S5.2.2.2.2.1.m1.1b"><ci id="S5.2.2.2.2.1.m1.1.1.cmml" xref="S5.2.2.2.2.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.2.2.2.2.1.m1.1c">\to</annotation><annotation encoding="application/x-llamapun" id="S5.2.2.2.2.1.m1.1d">→</annotation></semantics></math>de</span></td>
</tr>
<tr class="ltx_tr" id="S5.2.2.3">
<td class="ltx_td ltx_align_left" id="S5.2.2.3.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_smallcaps" id="S5.2.2.3.1.1">Model</span></td>
<td class="ltx_td ltx_align_left" id="S5.2.2.3.2" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_smallcaps" id="S5.2.2.3.2.1">Size</span></td>
<td class="ltx_td ltx_nopad_r ltx_border_t" id="S5.2.2.3.3" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" id="S5.2.2.3.4" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_smallcaps" id="S5.2.2.3.4.1">orig.</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.2.2.3.5" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_smallcaps" id="S5.2.2.3.5.1">cat5</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.2.2.3.6" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_smallcaps" id="S5.2.2.3.6.1">cat10</span></td>
<td class="ltx_td ltx_nopad_r ltx_border_t" id="S5.2.2.3.7" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" id="S5.2.2.3.8" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_smallcaps" id="S5.2.2.3.8.1">orig.</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.2.2.3.9" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_smallcaps" id="S5.2.2.3.9.1">cat5</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.2.2.3.10" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_smallcaps" id="S5.2.2.3.10.1">cat10</span></td>
</tr>
<tr class="ltx_tr" id="S5.2.2.4">
<td class="ltx_td ltx_align_left ltx_border_t" colspan="8" id="S5.2.2.4.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_italic" id="S5.2.2.4.1.1">Trained from scratch</span></td>
<td class="ltx_td ltx_border_t" id="S5.2.2.4.2" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.2.2.4.3" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
</tr>
<tr class="ltx_tr" id="S5.2.2.5">
<td class="ltx_td ltx_align_left" id="S5.2.2.5.1" style="padding-left:4.0pt;padding-right:4.0pt;">Transf. Enc-Dec</td>
<td class="ltx_td ltx_align_left" id="S5.2.2.5.2" style="padding-left:4.0pt;padding-right:4.0pt;">77M</td>
<td class="ltx_td ltx_nopad_r" id="S5.2.2.5.3" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S5.2.2.5.4" style="padding-left:4.0pt;padding-right:4.0pt;">72.4</td>
<td class="ltx_td ltx_align_center" id="S5.2.2.5.5" style="padding-left:4.0pt;padding-right:4.0pt;">74.6</td>
<td class="ltx_td ltx_align_center" id="S5.2.2.5.6" style="padding-left:4.0pt;padding-right:4.0pt;">69.6</td>
<td class="ltx_td ltx_nopad_r" id="S5.2.2.5.7" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S5.2.2.5.8" style="padding-left:4.0pt;padding-right:4.0pt;">65.2</td>
<td class="ltx_td ltx_align_center" id="S5.2.2.5.9" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.2.2.5.9.1">70.3</span></td>
<td class="ltx_td ltx_align_center" id="S5.2.2.5.10" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.2.2.5.10.1">70.3</span></td>
</tr>
<tr class="ltx_tr" id="S5.2.2.6">
<td class="ltx_td ltx_align_left" id="S5.2.2.6.1" style="padding-left:4.0pt;padding-right:4.0pt;">Transformer++</td>
<td class="ltx_td ltx_align_left" id="S5.2.2.6.2" style="padding-left:4.0pt;padding-right:4.0pt;">79M</td>
<td class="ltx_td ltx_nopad_r" id="S5.2.2.6.3" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S5.2.2.6.4" style="padding-left:4.0pt;padding-right:4.0pt;">70.7</td>
<td class="ltx_td ltx_align_center" id="S5.2.2.6.5" style="padding-left:4.0pt;padding-right:4.0pt;">73.6</td>
<td class="ltx_td ltx_align_center" id="S5.2.2.6.6" style="padding-left:4.0pt;padding-right:4.0pt;">72.8</td>
<td class="ltx_td ltx_nopad_r" id="S5.2.2.6.7" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S5.2.2.6.8" style="padding-left:4.0pt;padding-right:4.0pt;">64.8</td>
<td class="ltx_td ltx_align_center" id="S5.2.2.6.9" style="padding-left:4.0pt;padding-right:4.0pt;">69.1</td>
<td class="ltx_td ltx_align_center" id="S5.2.2.6.10" style="padding-left:4.0pt;padding-right:4.0pt;">68.8</td>
</tr>
<tr class="ltx_tr" id="S5.2.2.7">
<td class="ltx_td ltx_align_left" id="S5.2.2.7.1" style="padding-left:4.0pt;padding-right:4.0pt;">Mamba</td>
<td class="ltx_td ltx_align_left" id="S5.2.2.7.2" style="padding-left:4.0pt;padding-right:4.0pt;">77M</td>
<td class="ltx_td ltx_nopad_r" id="S5.2.2.7.3" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S5.2.2.7.4" style="padding-left:4.0pt;padding-right:4.0pt;">70.0</td>
<td class="ltx_td ltx_align_center" id="S5.2.2.7.5" style="padding-left:4.0pt;padding-right:4.0pt;">73.3</td>
<td class="ltx_td ltx_align_center" id="S5.2.2.7.6" style="padding-left:4.0pt;padding-right:4.0pt;">72.3</td>
<td class="ltx_td ltx_nopad_r" id="S5.2.2.7.7" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S5.2.2.7.8" style="padding-left:4.0pt;padding-right:4.0pt;">63.3</td>
<td class="ltx_td ltx_align_center" id="S5.2.2.7.9" style="padding-left:4.0pt;padding-right:4.0pt;">67.5</td>
<td class="ltx_td ltx_align_center" id="S5.2.2.7.10" style="padding-left:4.0pt;padding-right:4.0pt;">67.8</td>
</tr>
<tr class="ltx_tr" id="S5.2.2.8">
<td class="ltx_td ltx_align_left" id="S5.2.2.8.1" style="padding-left:4.0pt;padding-right:4.0pt;">
<span class="ltx_ERROR undefined" id="S5.2.2.8.1.1">\cdashline</span>1-10[.4pt/2pt]

Mamba-MHA</td>
<td class="ltx_td ltx_align_left" id="S5.2.2.8.2" style="padding-left:4.0pt;padding-right:4.0pt;">78M</td>
<td class="ltx_td ltx_nopad_r" id="S5.2.2.8.3" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S5.2.2.8.4" style="padding-left:4.0pt;padding-right:4.0pt;">72.7</td>
<td class="ltx_td ltx_align_center" id="S5.2.2.8.5" style="padding-left:4.0pt;padding-right:4.0pt;">74.2</td>
<td class="ltx_td ltx_align_center" id="S5.2.2.8.6" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.2.2.8.6.1">74.5</span></td>
<td class="ltx_td ltx_nopad_r" id="S5.2.2.8.7" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S5.2.2.8.8" style="padding-left:4.0pt;padding-right:4.0pt;">67.0</td>
<td class="ltx_td ltx_align_center" id="S5.2.2.8.9" style="padding-left:4.0pt;padding-right:4.0pt;">68.6</td>
<td class="ltx_td ltx_align_center" id="S5.2.2.8.10" style="padding-left:4.0pt;padding-right:4.0pt;">69.7</td>
</tr>
<tr class="ltx_tr" id="S5.2.2.9">
<td class="ltx_td ltx_align_left" id="S5.2.2.9.1" style="padding-left:4.0pt;padding-right:4.0pt;">Mamba Enc-Dec</td>
<td class="ltx_td ltx_align_left" id="S5.2.2.9.2" style="padding-left:4.0pt;padding-right:4.0pt;">82M</td>
<td class="ltx_td ltx_nopad_r" id="S5.2.2.9.3" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S5.2.2.9.4" style="padding-left:4.0pt;padding-right:4.0pt;">70.7</td>
<td class="ltx_td ltx_align_center" id="S5.2.2.9.5" style="padding-left:4.0pt;padding-right:4.0pt;">73.8</td>
<td class="ltx_td ltx_align_center" id="S5.2.2.9.6" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S5.2.2.9.6.1">75.6</span></td>
<td class="ltx_td ltx_nopad_r" id="S5.2.2.9.7" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S5.2.2.9.8" style="padding-left:4.0pt;padding-right:4.0pt;">65.3</td>
<td class="ltx_td ltx_align_center" id="S5.2.2.9.9" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S5.2.2.9.9.1">71.0</span></td>
<td class="ltx_td ltx_align_center" id="S5.2.2.9.10" style="padding-left:4.0pt;padding-right:4.0pt;">70.1</td>
</tr>
<tr class="ltx_tr" id="S5.2.2.10">
<td class="ltx_td ltx_align_left ltx_border_t" colspan="8" id="S5.2.2.10.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_italic" id="S5.2.2.10.1.1">Finetuned</span></td>
<td class="ltx_td ltx_border_t" id="S5.2.2.10.2" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.2.2.10.3" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
</tr>
<tr class="ltx_tr" id="S5.2.2.11">
<td class="ltx_td ltx_align_left" id="S5.2.2.11.1" style="padding-left:4.0pt;padding-right:4.0pt;">Pythia-S</td>
<td class="ltx_td ltx_align_left" id="S5.2.2.11.2" style="padding-left:4.0pt;padding-right:4.0pt;">410M</td>
<td class="ltx_td ltx_nopad_r" id="S5.2.2.11.3" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S5.2.2.11.4" style="padding-left:4.0pt;padding-right:4.0pt;">77.4</td>
<td class="ltx_td ltx_align_center" id="S5.2.2.11.5" style="padding-left:4.0pt;padding-right:4.0pt;">78.4</td>
<td class="ltx_td ltx_align_center" id="S5.2.2.11.6" style="padding-left:4.0pt;padding-right:4.0pt;">79.0</td>
<td class="ltx_td ltx_nopad_r" id="S5.2.2.11.7" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S5.2.2.11.8" style="padding-left:4.0pt;padding-right:4.0pt;">76.7</td>
<td class="ltx_td ltx_align_center" id="S5.2.2.11.9" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.2.2.11.9.1">77.8</span></td>
<td class="ltx_td ltx_align_center" id="S5.2.2.11.10" style="padding-left:4.0pt;padding-right:4.0pt;">77.1</td>
</tr>
<tr class="ltx_tr" id="S5.2.2.12">
<td class="ltx_td ltx_align_left" id="S5.2.2.12.1" style="padding-left:4.0pt;padding-right:4.0pt;">Mamba-S</td>
<td class="ltx_td ltx_align_left" id="S5.2.2.12.2" style="padding-left:4.0pt;padding-right:4.0pt;">370M</td>
<td class="ltx_td ltx_nopad_r" id="S5.2.2.12.3" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S5.2.2.12.4" style="padding-left:4.0pt;padding-right:4.0pt;">77.2</td>
<td class="ltx_td ltx_align_center" id="S5.2.2.12.5" style="padding-left:4.0pt;padding-right:4.0pt;">78.2</td>
<td class="ltx_td ltx_align_center" id="S5.2.2.12.6" style="padding-left:4.0pt;padding-right:4.0pt;">78.3</td>
<td class="ltx_td ltx_nopad_r" id="S5.2.2.12.7" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S5.2.2.12.8" style="padding-left:4.0pt;padding-right:4.0pt;">72.4</td>
<td class="ltx_td ltx_align_center" id="S5.2.2.12.9" style="padding-left:4.0pt;padding-right:4.0pt;">74.2</td>
<td class="ltx_td ltx_align_center" id="S5.2.2.12.10" style="padding-left:4.0pt;padding-right:4.0pt;">73.1</td>
</tr>
<tr class="ltx_tr" id="S5.2.2.13">
<td class="ltx_td ltx_align_left" id="S5.2.2.13.1" style="padding-left:4.0pt;padding-right:4.0pt;">Pythia-M</td>
<td class="ltx_td ltx_align_left" id="S5.2.2.13.2" style="padding-left:4.0pt;padding-right:4.0pt;">1.4B</td>
<td class="ltx_td ltx_nopad_r" id="S5.2.2.13.3" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S5.2.2.13.4" style="padding-left:4.0pt;padding-right:4.0pt;">76.2</td>
<td class="ltx_td ltx_align_center" id="S5.2.2.13.5" style="padding-left:4.0pt;padding-right:4.0pt;">78.6</td>
<td class="ltx_td ltx_align_center" id="S5.2.2.13.6" style="padding-left:4.0pt;padding-right:4.0pt;">79.4</td>
<td class="ltx_td ltx_nopad_r" id="S5.2.2.13.7" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S5.2.2.13.8" style="padding-left:4.0pt;padding-right:4.0pt;">75.8</td>
<td class="ltx_td ltx_align_center" id="S5.2.2.13.9" style="padding-left:4.0pt;padding-right:4.0pt;">77.4</td>
<td class="ltx_td ltx_align_center" id="S5.2.2.13.10" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S5.2.2.13.10.1">79.0</span></td>
</tr>
<tr class="ltx_tr" id="S5.2.2.14">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S5.2.2.14.1" style="padding-left:4.0pt;padding-right:4.0pt;">Mamba-M</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S5.2.2.14.2" style="padding-left:4.0pt;padding-right:4.0pt;">1.4B</td>
<td class="ltx_td ltx_nopad_r ltx_border_bb" id="S5.2.2.14.3" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb" id="S5.2.2.14.4" style="padding-left:4.0pt;padding-right:4.0pt;">74.6</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.2.2.14.5" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S5.2.2.14.5.1">79.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.2.2.14.6" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.2.2.14.6.1">79.5</span></td>
<td class="ltx_td ltx_nopad_r ltx_border_bb" id="S5.2.2.14.7" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb" id="S5.2.2.14.8" style="padding-left:4.0pt;padding-right:4.0pt;">73.4</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.2.2.14.9" style="padding-left:4.0pt;padding-right:4.0pt;">77.5</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.2.2.14.10" style="padding-left:4.0pt;padding-right:4.0pt;">77.3</td>
</tr>
</table>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3: </span>Paragraph-level results in terms of COMET for models trained from scratch (top) and models finetuned from a pretrained checkpoint (bottom) on WMT23 <span class="ltx_text ltx_font_smallcaps" id="S5.4.4.1">en<math alttext="\leftrightarrow" class="ltx_Math" display="inline" id="S5.4.4.1.m1.1"><semantics id="S5.4.4.1.m1.1b"><mo id="S5.4.4.1.m1.1.1" stretchy="false" xref="S5.4.4.1.m1.1.1.cmml">↔</mo><annotation-xml encoding="MathML-Content" id="S5.4.4.1.m1.1c"><ci id="S5.4.4.1.m1.1.1.cmml" xref="S5.4.4.1.m1.1.1">↔</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.4.4.1.m1.1d">\leftrightarrow</annotation><annotation encoding="application/x-llamapun" id="S5.4.4.1.m1.1e">↔</annotation></semantics></math>de</span> test set, according to the training dataset: original WMT23-6M, WMT23-CAT-5 and WMT23-CAT-10.
<span class="ltx_text ltx_font_bold" id="S5.4.7.2">Bold</span> represents top results; <span class="ltx_text ltx_framed ltx_framed_underline" id="S5.4.8.3">underline</span> represents second-best.</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<section class="ltx_subsection ltx_figure_panel" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Discussion</h3>
<section class="ltx_paragraph" id="S5.SS1.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Concatenation helps.</h5>
<div class="ltx_para" id="S5.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="S5.SS1.SSS0.Px1.p1.2">Our strategy of concatenating sentences proves beneficial for almost all models, as COMET scores tipically improve with the CAT-5 and CAT-10 datasets, whether models are trained from scratch or finetuned.
Among models trained from scratch, Transformer Enc-Dec, Mamba-MHA, and Mamba Enc-Dec show substantial improvements, with Mamba Enc-Dec achieving the best overall results.
For finetuned models, concatenation benefits larger models; Mamba-M outperforms Pythia-M in <span class="ltx_text ltx_font_smallcaps" id="S5.SS1.SSS0.Px1.p1.1.1">de<math alttext="\to" class="ltx_Math" display="inline" id="S5.SS1.SSS0.Px1.p1.1.1.m1.1"><semantics id="S5.SS1.SSS0.Px1.p1.1.1.m1.1a"><mo id="S5.SS1.SSS0.Px1.p1.1.1.m1.1.1" stretchy="false" xref="S5.SS1.SSS0.Px1.p1.1.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px1.p1.1.1.m1.1b"><ci id="S5.SS1.SSS0.Px1.p1.1.1.m1.1.1.cmml" xref="S5.SS1.SSS0.Px1.p1.1.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px1.p1.1.1.m1.1c">\to</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS0.Px1.p1.1.1.m1.1d">→</annotation></semantics></math>en</span> but underperforms in <span class="ltx_text ltx_font_smallcaps" id="S5.SS1.SSS0.Px1.p1.2.2">en<math alttext="\to" class="ltx_Math" display="inline" id="S5.SS1.SSS0.Px1.p1.2.2.m1.1"><semantics id="S5.SS1.SSS0.Px1.p1.2.2.m1.1a"><mo id="S5.SS1.SSS0.Px1.p1.2.2.m1.1.1" stretchy="false" xref="S5.SS1.SSS0.Px1.p1.2.2.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px1.p1.2.2.m1.1b"><ci id="S5.SS1.SSS0.Px1.p1.2.2.m1.1.1.cmml" xref="S5.SS1.SSS0.Px1.p1.2.2.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px1.p1.2.2.m1.1c">\to</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS0.Px1.p1.2.2.m1.1d">→</annotation></semantics></math>de</span>.
Interestingly, for both training regimes, the concatenation strategy can lead to COMET gains of up to 5 points.</p>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS1.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">Finetuning outperforms training from scratch.</h5>
<div class="ltx_para" id="S5.SS1.SSS0.Px2.p1">
<p class="ltx_p" id="S5.SS1.SSS0.Px2.p1.1">Finetuned models consistently achieve higher COMET scores, with larger models attaining the top results overall.
Similar to sentence-level experiments, Pythia outperforms Mamba when trained on the original, WMT23-6M dataset.
However, both Pythia and Mamba benefit from our concatenation strategy.
While these results indicate that our concatenation strategy helps in translating long inputs, it remains unclear whether performance on short inputs is compromised or if the models can handle longer inputs than those seen during training. We investigate these issues next.</p>
</div>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Sensitivity to Input Length</h3>
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F2">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_figure_panel ltx_img_landscape" height="203" id="S5.SS2.1.g1" src="x2.png" width="830"/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="195" id="S5.SS2.2.g2" src="x3.png" width="797"/></div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Sensitivity to input length, measured by the number of sources tokens, on the WMT23 <span class="ltx_text ltx_font_smallcaps" id="S5.F2.2.1">de<math alttext="\to" class="ltx_Math" display="inline" id="S5.F2.2.1.m1.1"><semantics id="S5.F2.2.1.m1.1b"><mo id="S5.F2.2.1.m1.1.1" stretchy="false" xref="S5.F2.2.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S5.F2.2.1.m1.1c"><ci id="S5.F2.2.1.m1.1.1.cmml" xref="S5.F2.2.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.F2.2.1.m1.1d">\to</annotation><annotation encoding="application/x-llamapun" id="S5.F2.2.1.m1.1e">→</annotation></semantics></math>en</span> datset, for models trained from scratch (top) and finetuned from a pretrained checkpoint (bottom).
</figcaption>
</figure>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.2">Based on the previous observations, we notice that performance between models varies considerably after being exposed to different sequence lengths during training.
In this subsection, we investigate how robust each model is to length distribution shifts between training and test.
Results are shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#S5.F2" title="Figure 2 ‣ 5.2 Sensitivity to Input Length ‣ Finetuning outperforms training from scratch. ‣ 5.1 Discussion ‣ 5 Paragraph-level translation ‣ 4.2 Recall of Named Entities ‣ 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_tag">2</span></a> for both training regimes on the WMT23 <span class="ltx_text ltx_font_smallcaps" id="S5.SS2.p1.1.1">de<math alttext="\to" class="ltx_Math" display="inline" id="S5.SS2.p1.1.1.m1.1"><semantics id="S5.SS2.p1.1.1.m1.1a"><mo id="S5.SS2.p1.1.1.m1.1.1" stretchy="false" xref="S5.SS2.p1.1.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.1.1.m1.1b"><ci id="S5.SS2.p1.1.1.m1.1.1.cmml" xref="S5.SS2.p1.1.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.1.1.m1.1c">\to</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p1.1.1.m1.1d">→</annotation></semantics></math>en</span> dataset. Results are consistent for <span class="ltx_text ltx_font_smallcaps" id="S5.SS2.p1.2.2">en<math alttext="\to" class="ltx_Math" display="inline" id="S5.SS2.p1.2.2.m1.1"><semantics id="S5.SS2.p1.2.2.m1.1a"><mo id="S5.SS2.p1.2.2.m1.1.1" stretchy="false" xref="S5.SS2.p1.2.2.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.2.2.m1.1b"><ci id="S5.SS2.p1.2.2.m1.1.1.cmml" xref="S5.SS2.p1.2.2.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.2.2.m1.1c">\to</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p1.2.2.m1.1d">→</annotation></semantics></math>de</span>, shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#A3.F4" title="Figure 4 ‣ C.1 Preliminary Sentence-level Experiments ‣ Appendix C Exploring Length-related Issues ‣ A.3 Inference Cost ‣ A.2 Finetuning Pretrained Checkpoints ‣ A.1 Training from Scratch ‣ Appendix A Implementation and Training Details ‣ Potential Risks ‣ Limitations ‣ Acknowledgments ‣ 7 Conclusion ‣ Sentence concatenation ‣ 6 Related Works ‣ 5.3 Inference Cost ‣ Discussion. ‣ 5.2 Sensitivity to Input Length ‣ Finetuning outperforms training from scratch. ‣ 5.1 Discussion ‣ 5 Paragraph-level translation ‣ 4.2 Recall of Named Entities ‣ 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_tag">4</span></a>, Appendix <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#A3" title="Appendix C Exploring Length-related Issues ‣ A.3 Inference Cost ‣ A.2 Finetuning Pretrained Checkpoints ‣ A.1 Training from Scratch ‣ Appendix A Implementation and Training Details ‣ Potential Risks ‣ Limitations ‣ Acknowledgments ‣ 7 Conclusion ‣ Sentence concatenation ‣ 6 Related Works ‣ 5.3 Inference Cost ‣ Discussion. ‣ 5.2 Sensitivity to Input Length ‣ Finetuning outperforms training from scratch. ‣ 5.1 Discussion ‣ 5 Paragraph-level translation ‣ 4.2 Recall of Named Entities ‣ 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_tag">C</span></a>.</p>
</div>
<section class="ltx_paragraph" id="S5.SS2.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Discussion.</h5>
<div class="ltx_para" id="S5.SS2.SSS0.Px1.p1">
<p class="ltx_p" id="S5.SS2.SSS0.Px1.p1.1">When training on WMT23-6M, we observe a decline in performance for all models on long sequences, affecting both trained-from-scratch and finetuned variants.
Interestingly, this degradation is evident in Mamba, as expected due to its finite hidden state capacity. However, it is also challenging for transformers despite their relative positional embeddings.
Moreover, both finetuned and hybrid models exhibit more consistent performance across different sequence lengths, even on the original sentence-level dataset, suggesting a more robust capability for dealing with long-context inputs.</p>
</div>
<div class="ltx_para" id="S5.SS2.SSS0.Px1.p2">
<p class="ltx_p" id="S5.SS2.SSS0.Px1.p2.1">Overall, our concatenation approach has largely mitigated the performance issues with long inputs present in models trained on WMT23-6M, as models trained on CAT datasets produce higher-quality translations for longer sequences.
This improvement is uniform across all models, with CAT-10 yielding consistently better translations in the longest bin (257+ tokens).
However, the CAT-10 dataset seems to reduce translation quality for shorter samples in some models, though this effect is minimal or absent in hybrid and finetuned models.
We further examine the ability to extrapolate to even longer sentences (up to 2048 tokens) than those seen during training in §<a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#A3" title="Appendix C Exploring Length-related Issues ‣ A.3 Inference Cost ‣ A.2 Finetuning Pretrained Checkpoints ‣ A.1 Training from Scratch ‣ Appendix A Implementation and Training Details ‣ Potential Risks ‣ Limitations ‣ Acknowledgments ‣ 7 Conclusion ‣ Sentence concatenation ‣ 6 Related Works ‣ 5.3 Inference Cost ‣ Discussion. ‣ 5.2 Sensitivity to Input Length ‣ Finetuning outperforms training from scratch. ‣ 5.1 Discussion ‣ 5 Paragraph-level translation ‣ 4.2 Recall of Named Entities ‣ 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_tag">C</span></a>, finding that finetuned versions of Mamba are more robust than Pythia when trained on CAT-10.</p>
</div>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Inference Cost</h3>
<div class="ltx_para" id="S5.SS3.p1">
<p class="ltx_p" id="S5.SS3.p1.7">In §<a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#S2" title="2 Background ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_tag">2</span></a> we covered the theoretical time complexity of our models
in training and inference time.
Here, we examine the wallclock time and memory usage of Pythia and Mamba in a realistic setting
where inputs are WMT23 <span class="ltx_text ltx_font_smallcaps" id="S5.SS3.p1.1.1">de<math alttext="\to" class="ltx_Math" display="inline" id="S5.SS3.p1.1.1.m1.1"><semantics id="S5.SS3.p1.1.1.m1.1a"><mo id="S5.SS3.p1.1.1.m1.1.1" stretchy="false" xref="S5.SS3.p1.1.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.1.1.m1.1b"><ci id="S5.SS3.p1.1.1.m1.1.1.cmml" xref="S5.SS3.p1.1.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.1.1.m1.1c">\to</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p1.1.1.m1.1d">→</annotation></semantics></math>en</span> test samples, and outputs continue to be generated until they reach exactly <math alttext="L\in\{512,1024\}" class="ltx_Math" display="inline" id="S5.SS3.p1.2.m1.2"><semantics id="S5.SS3.p1.2.m1.2a"><mrow id="S5.SS3.p1.2.m1.2.3" xref="S5.SS3.p1.2.m1.2.3.cmml"><mi id="S5.SS3.p1.2.m1.2.3.2" xref="S5.SS3.p1.2.m1.2.3.2.cmml">L</mi><mo id="S5.SS3.p1.2.m1.2.3.1" xref="S5.SS3.p1.2.m1.2.3.1.cmml">∈</mo><mrow id="S5.SS3.p1.2.m1.2.3.3.2" xref="S5.SS3.p1.2.m1.2.3.3.1.cmml"><mo id="S5.SS3.p1.2.m1.2.3.3.2.1" stretchy="false" xref="S5.SS3.p1.2.m1.2.3.3.1.cmml">{</mo><mn id="S5.SS3.p1.2.m1.1.1" xref="S5.SS3.p1.2.m1.1.1.cmml">512</mn><mo id="S5.SS3.p1.2.m1.2.3.3.2.2" xref="S5.SS3.p1.2.m1.2.3.3.1.cmml">,</mo><mn id="S5.SS3.p1.2.m1.2.2" xref="S5.SS3.p1.2.m1.2.2.cmml">1024</mn><mo id="S5.SS3.p1.2.m1.2.3.3.2.3" stretchy="false" xref="S5.SS3.p1.2.m1.2.3.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.2.m1.2b"><apply id="S5.SS3.p1.2.m1.2.3.cmml" xref="S5.SS3.p1.2.m1.2.3"><in id="S5.SS3.p1.2.m1.2.3.1.cmml" xref="S5.SS3.p1.2.m1.2.3.1"></in><ci id="S5.SS3.p1.2.m1.2.3.2.cmml" xref="S5.SS3.p1.2.m1.2.3.2">𝐿</ci><set id="S5.SS3.p1.2.m1.2.3.3.1.cmml" xref="S5.SS3.p1.2.m1.2.3.3.2"><cn id="S5.SS3.p1.2.m1.1.1.cmml" type="integer" xref="S5.SS3.p1.2.m1.1.1">512</cn><cn id="S5.SS3.p1.2.m1.2.2.cmml" type="integer" xref="S5.SS3.p1.2.m1.2.2">1024</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.2.m1.2c">L\in\{512,1024\}</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p1.2.m1.2d">italic_L ∈ { 512 , 1024 }</annotation></semantics></math> tokens.
Table <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#S5.T4" title="Table 4 ‣ 5.3 Inference Cost ‣ Discussion. ‣ 5.2 Sensitivity to Input Length ‣ Finetuning outperforms training from scratch. ‣ 5.1 Discussion ‣ 5 Paragraph-level translation ‣ 4.2 Recall of Named Entities ‣ 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_tag">4</span></a> shows that
Mamba’s memory usage is significantly lower than Pythia’s, with gaps of <math alttext="\sim" class="ltx_Math" display="inline" id="S5.SS3.p1.3.m2.1"><semantics id="S5.SS3.p1.3.m2.1a"><mo id="S5.SS3.p1.3.m2.1.1" xref="S5.SS3.p1.3.m2.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.3.m2.1b"><csymbol cd="latexml" id="S5.SS3.p1.3.m2.1.1.cmml" xref="S5.SS3.p1.3.m2.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.3.m2.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p1.3.m2.1d">∼</annotation></semantics></math> 3-5x overall.
The wallclock time difference is not as notable but still substantial, especially for larger models, where Mamba-M is <math alttext="2" class="ltx_Math" display="inline" id="S5.SS3.p1.4.m3.1"><semantics id="S5.SS3.p1.4.m3.1a"><mn id="S5.SS3.p1.4.m3.1.1" xref="S5.SS3.p1.4.m3.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.4.m3.1b"><cn id="S5.SS3.p1.4.m3.1.1.cmml" type="integer" xref="S5.SS3.p1.4.m3.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.4.m3.1c">2</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p1.4.m3.1d">2</annotation></semantics></math>x faster than Pythia-M for <math alttext="L=1024" class="ltx_Math" display="inline" id="S5.SS3.p1.5.m4.1"><semantics id="S5.SS3.p1.5.m4.1a"><mrow id="S5.SS3.p1.5.m4.1.1" xref="S5.SS3.p1.5.m4.1.1.cmml"><mi id="S5.SS3.p1.5.m4.1.1.2" xref="S5.SS3.p1.5.m4.1.1.2.cmml">L</mi><mo id="S5.SS3.p1.5.m4.1.1.1" xref="S5.SS3.p1.5.m4.1.1.1.cmml">=</mo><mn id="S5.SS3.p1.5.m4.1.1.3" xref="S5.SS3.p1.5.m4.1.1.3.cmml">1024</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.5.m4.1b"><apply id="S5.SS3.p1.5.m4.1.1.cmml" xref="S5.SS3.p1.5.m4.1.1"><eq id="S5.SS3.p1.5.m4.1.1.1.cmml" xref="S5.SS3.p1.5.m4.1.1.1"></eq><ci id="S5.SS3.p1.5.m4.1.1.2.cmml" xref="S5.SS3.p1.5.m4.1.1.2">𝐿</ci><cn id="S5.SS3.p1.5.m4.1.1.3.cmml" type="integer" xref="S5.SS3.p1.5.m4.1.1.3">1024</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.5.m4.1c">L=1024</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p1.5.m4.1d">italic_L = 1024</annotation></semantics></math>.
In other words, Mamba-M throughputs <math alttext="\sim" class="ltx_Math" display="inline" id="S5.SS3.p1.6.m5.1"><semantics id="S5.SS3.p1.6.m5.1a"><mo id="S5.SS3.p1.6.m5.1.1" xref="S5.SS3.p1.6.m5.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.6.m5.1b"><csymbol cd="latexml" id="S5.SS3.p1.6.m5.1.1.cmml" xref="S5.SS3.p1.6.m5.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.6.m5.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p1.6.m5.1d">∼</annotation></semantics></math>806 tokens/s while Pythia-M outputs <math alttext="\sim" class="ltx_Math" display="inline" id="S5.SS3.p1.7.m6.1"><semantics id="S5.SS3.p1.7.m6.1a"><mo id="S5.SS3.p1.7.m6.1.1" xref="S5.SS3.p1.7.m6.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.7.m6.1b"><csymbol cd="latexml" id="S5.SS3.p1.7.m6.1.1.cmml" xref="S5.SS3.p1.7.m6.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.7.m6.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p1.7.m6.1d">∼</annotation></semantics></math>405 tokens/s, aligning with <cite class="ltx_cite ltx_citemacro_citep">(Gu and Dao, <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib19" title="">2023</a>)</cite>.<span class="ltx_note ltx_role_footnote" id="footnote9"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note">9</span>Computed as <math alttext="\text{batch-size}\times L/\text{wallclock-time}" class="ltx_Math" display="inline" id="footnote9.m1.1"><semantics id="footnote9.m1.1b"><mrow id="footnote9.m1.1.1" xref="footnote9.m1.1.1.cmml"><mrow id="footnote9.m1.1.1.2" xref="footnote9.m1.1.1.2.cmml"><mtext id="footnote9.m1.1.1.2.2" xref="footnote9.m1.1.1.2.2a.cmml">batch-size</mtext><mo id="footnote9.m1.1.1.2.1" lspace="0.222em" rspace="0.222em" xref="footnote9.m1.1.1.2.1.cmml">×</mo><mi id="footnote9.m1.1.1.2.3" xref="footnote9.m1.1.1.2.3.cmml">L</mi></mrow><mo id="footnote9.m1.1.1.1" xref="footnote9.m1.1.1.1.cmml">/</mo><mtext id="footnote9.m1.1.1.3" xref="footnote9.m1.1.1.3a.cmml">wallclock-time</mtext></mrow><annotation-xml encoding="MathML-Content" id="footnote9.m1.1c"><apply id="footnote9.m1.1.1.cmml" xref="footnote9.m1.1.1"><divide id="footnote9.m1.1.1.1.cmml" xref="footnote9.m1.1.1.1"></divide><apply id="footnote9.m1.1.1.2.cmml" xref="footnote9.m1.1.1.2"><times id="footnote9.m1.1.1.2.1.cmml" xref="footnote9.m1.1.1.2.1"></times><ci id="footnote9.m1.1.1.2.2a.cmml" xref="footnote9.m1.1.1.2.2"><mtext id="footnote9.m1.1.1.2.2.cmml" xref="footnote9.m1.1.1.2.2">batch-size</mtext></ci><ci id="footnote9.m1.1.1.2.3.cmml" xref="footnote9.m1.1.1.2.3">𝐿</ci></apply><ci id="footnote9.m1.1.1.3a.cmml" xref="footnote9.m1.1.1.3"><mtext id="footnote9.m1.1.1.3.cmml" xref="footnote9.m1.1.1.3">wallclock-time</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="footnote9.m1.1d">\text{batch-size}\times L/\text{wallclock-time}</annotation><annotation encoding="application/x-llamapun" id="footnote9.m1.1e">batch-size × italic_L / wallclock-time</annotation></semantics></math>.</span></span></span></p>
</div>
<figure class="ltx_table" id="S5.T4">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S5.T4.3">
<tr class="ltx_tr" id="S5.T4.3.1">
<td class="ltx_td ltx_border_tt" id="S5.T4.3.1.1" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_border_tt" id="S5.T4.3.1.2" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S5.T4.3.1.3" style="padding-left:4.0pt;padding-right:4.0pt;">512</td>
<td class="ltx_td ltx_border_tt" id="S5.T4.3.1.4" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S5.T4.3.1.5" style="padding-left:4.0pt;padding-right:4.0pt;">1024</td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.2">
<td class="ltx_td ltx_align_left" id="S5.T4.3.2.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_smallcaps" id="S5.T4.3.2.1.1">Model</span></td>
<td class="ltx_td ltx_border_t" id="S5.T4.3.2.2" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" id="S5.T4.3.2.3" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_smallcaps" id="S5.T4.3.2.3.1">T (s)</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T4.3.2.4" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_smallcaps" id="S5.T4.3.2.4.1">M (GB)</span></td>
<td class="ltx_td ltx_border_t" id="S5.T4.3.2.5" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" id="S5.T4.3.2.6" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_smallcaps" id="S5.T4.3.2.6.1">T (s)</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T4.3.2.7" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_smallcaps" id="S5.T4.3.2.7.1">M (GB)</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.3">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T4.3.3.1" style="padding-left:4.0pt;padding-right:4.0pt;">Pythia-S</td>
<td class="ltx_td ltx_border_t" id="S5.T4.3.3.2" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" id="S5.T4.3.3.3" style="padding-left:4.0pt;padding-right:4.0pt;">11.52</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T4.3.3.4" style="padding-left:4.0pt;padding-right:4.0pt;">2.472</td>
<td class="ltx_td ltx_border_t" id="S5.T4.3.3.5" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" id="S5.T4.3.3.6" style="padding-left:4.0pt;padding-right:4.0pt;">25.80</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T4.3.3.7" style="padding-left:4.0pt;padding-right:4.0pt;">3.934</td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.4">
<td class="ltx_td ltx_align_left" id="S5.T4.3.4.1" style="padding-left:4.0pt;padding-right:4.0pt;">Mamba-S</td>
<td class="ltx_td" id="S5.T4.3.4.2" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T4.3.4.3" style="padding-left:4.0pt;padding-right:4.0pt;">10.38</td>
<td class="ltx_td ltx_align_right" id="S5.T4.3.4.4" style="padding-left:4.0pt;padding-right:4.0pt;">0.839</td>
<td class="ltx_td" id="S5.T4.3.4.5" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T4.3.4.6" style="padding-left:4.0pt;padding-right:4.0pt;">20.59</td>
<td class="ltx_td ltx_align_right" id="S5.T4.3.4.7" style="padding-left:4.0pt;padding-right:4.0pt;">1.607</td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.5">
<td class="ltx_td ltx_align_left" id="S5.T4.3.5.1" style="padding-left:4.0pt;padding-right:4.0pt;">Pythia-M</td>
<td class="ltx_td" id="S5.T4.3.5.2" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T4.3.5.3" style="padding-left:4.0pt;padding-right:4.0pt;">14.88</td>
<td class="ltx_td ltx_align_right" id="S5.T4.3.5.4" style="padding-left:4.0pt;padding-right:4.0pt;">4.789</td>
<td class="ltx_td" id="S5.T4.3.5.5" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T4.3.5.6" style="padding-left:4.0pt;padding-right:4.0pt;">40.41</td>
<td class="ltx_td ltx_align_right" id="S5.T4.3.5.7" style="padding-left:4.0pt;padding-right:4.0pt;">7.841</td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.6">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S5.T4.3.6.1" style="padding-left:4.0pt;padding-right:4.0pt;">Mamba-M</td>
<td class="ltx_td ltx_border_bb" id="S5.T4.3.6.2" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_bb" id="S5.T4.3.6.3" style="padding-left:4.0pt;padding-right:4.0pt;">10.29</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S5.T4.3.6.4" style="padding-left:4.0pt;padding-right:4.0pt;">0.913</td>
<td class="ltx_td ltx_border_bb" id="S5.T4.3.6.5" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_bb" id="S5.T4.3.6.6" style="padding-left:4.0pt;padding-right:4.0pt;">20.31</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S5.T4.3.6.7" style="padding-left:4.0pt;padding-right:4.0pt;">1.668</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>Average time (T) and maximum allocated memory (M) of 30 inference runs with batch size 16 on WMT23 <span class="ltx_text ltx_font_smallcaps" id="S5.T4.2.1">de<math alttext="\to" class="ltx_Math" display="inline" id="S5.T4.2.1.m1.1"><semantics id="S5.T4.2.1.m1.1b"><mo id="S5.T4.2.1.m1.1.1" stretchy="false" xref="S5.T4.2.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S5.T4.2.1.m1.1c"><ci id="S5.T4.2.1.m1.1.1.cmml" xref="S5.T4.2.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.2.1.m1.1d">\to</annotation><annotation encoding="application/x-llamapun" id="S5.T4.2.1.m1.1e">→</annotation></semantics></math>en</span>.</figcaption>
</figure>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Related Works</h2>
<section class="ltx_paragraph" id="S6.SS0.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Linear recurrent models for MT.</h5>
<div class="ltx_para" id="S6.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S6.SS0.SSS0.Px1.p1.1">Our work is closely related to <cite class="ltx_cite ltx_citemacro_citep">(Vardasbi et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib42" title="">2023</a>)</cite>, which compares SSMs and transformers.
Furthermore, they also experiment with hybrid architectures composed of S4 and attention layers, an approach that has since become common <cite class="ltx_cite ltx_citemacro_citep">(Arora et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib4" title="">2024</a>; De et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib12" title="">2024</a>; Glorioso et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib18" title="">2024</a>)</cite>.
In this work, we experiment with more recent linear recurrent models and their respective hybrid versions while also including larger and pretrained variants.
Our analysis further includes investigating each model’s ability to recall named entities, along with measuring translation performance across different sequence lengths on paragraph-level datasets.
In contrast to <cite class="ltx_cite ltx_citemacro_citet">Vardasbi et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib42" title="">2023</a>)</cite>’s results showing that S4 lags behind transformer baselines in MT tasks, we observe that Mamba, a modern SSM, is competitive with transformers on sentence and paragraph-level datasets, whether trained from scratch or fine-tuned from a pretrained checkpoint, especially in the first setting when equipped with attention mechanisms.</p>
</div>
</section>
<section class="ltx_paragraph" id="S6.SS0.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">Linear recurrent models’ limitations.</h5>
<div class="ltx_para" id="S6.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S6.SS0.SSS0.Px2.p1.1">Recent works show that Mamba struggles in tasks that involve recalling context tokens <cite class="ltx_cite ltx_citemacro_citep">(Arora et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib3" title="">2023</a>; Jelassi et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib24" title="">2024</a>)</cite>, such as the synthetic Multi-Query Associative Recall task.
In MT, however, context tokens (source and translation prefix) are not often replicated in the output (translation).
In this work, we study this phenomenon with named entities and analyze the recall ability of transformers and linear recurrent models in §<a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#S4.SS2" title="4.2 Recall of Named Entities ‣ 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_tag">4.2</span></a>.</p>
</div>
</section>
<section class="ltx_paragraph" id="S6.SS0.SSS0.Px3">
<h5 class="ltx_title ltx_title_paragraph">Sentence concatenation</h5>
<div class="ltx_para" id="S6.SS0.SSS0.Px3.p1">
<p class="ltx_p" id="S6.SS0.SSS0.Px3.p1.1"><cite class="ltx_cite ltx_citemacro_citet">Kondo et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib27" title="">2022</a>); Varis and Bojar (<a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib43" title="">2021</a>)</cite> analyze transformers’ generalization towards sequence length.
They show that transformers are susceptible to the training distribution of context length and that concatenating multiple sentences can improve the translation of longer sentences.
Specifically, <cite class="ltx_cite ltx_citemacro_citet">Kondo et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib27" title="">2022</a>)</cite> augment the original data with samples containing concatenations of two random sentences, while <cite class="ltx_cite ltx_citemacro_citet">Varis and Bojar (<a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib43" title="">2021</a>)</cite> concatenate up to six sentences.
While these studies focused on sentence-level translation with sequence lengths up to 120 tokens, in this work, we extend the analysis to much longer sequences and test on paragraph-level data from the WMT2023 dataset.</p>
</div>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusion</h2>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p" id="S7.p1.1">We set out to evaluate recent linear recurrent models, particularly RetNet and Mamba, in MT tasks while thoroughly comparing them to transformer baselines and hybrid models, which combine Mamba and attention.
We find that Mamba models are competitive with transformers, both when they are trained from scratch and when they are finetuned from a pretrained checkpoint; however, the performance delta is smaller in the latter regime.
Our paragraph-level experiments reveal that models are hindered by the mismatch in the training and test length distributions; however, a simple concatenation approach helps to mitigate the issue.
We find that hybrid models are only slightly affected by this issue while also being competitive or outperforming transformers.
Finally, we note that Mamba models also exhibit a faster runtime and consume less memory than transformers.</p>
</div>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_title_section">Acknowledgments</h2>
<div class="ltx_para" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1">We thank Haau-Sing Li, Saul Santos, Patrick Fernandes, Sweta Agrawal and Nuno Guerreiro for their useful and constructive comments.
This work was supported by the Portuguese Recovery and Resilience Plan through project C645008882-00000055 (Center for ResponsibleAI), by the EU’s Horizon Europe Research and Innovation Actions (UTTER, contract 101070631), by the project DECOLLAGE (ERC-2022-CoG 101088763), and by Fundação para a Ciência e Tecnologia through contract UIDB/50008/2020.</p>
</div>
<section class="ltx_section" id="Sx2">
<h2 class="ltx_title ltx_title_section">Limitations</h2>
<div class="ltx_para" id="Sx2.p1">
<p class="ltx_p" id="Sx2.p1.1">We point out some limitations of the presented study. First, one limitation is that we refrain from pretraining the hybrid models due to the high associated compute costs. To this effect, while our trained-from-scratch results are promising, validating them with a larger scale and strong language priors would strengthen our claim of their good performance.
Secondly, our experiments (§<a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#A3.SS3" title="C.3 Extrapolation to Longer Sequences ‣ Appendix C Exploring Length-related Issues ‣ A.3 Inference Cost ‣ A.2 Finetuning Pretrained Checkpoints ‣ A.1 Training from Scratch ‣ Appendix A Implementation and Training Details ‣ Potential Risks ‣ Limitations ‣ Acknowledgments ‣ 7 Conclusion ‣ Sentence concatenation ‣ 6 Related Works ‣ 5.3 Inference Cost ‣ Discussion. ‣ 5.2 Sensitivity to Input Length ‣ Finetuning outperforms training from scratch. ‣ 5.1 Discussion ‣ 5 Paragraph-level translation ‣ 4.2 Recall of Named Entities ‣ 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_tag">C.3</span></a>) appear to indicate larger models are more robust to sequence length issues.
Nonetheless, we limited our study to models with parameter scales between 370M and 1.4B since, in preliminary sentence-level experiments, translation quality gains plateaued at the latter scale.</p>
</div>
<div class="ltx_para" id="Sx2.p2">
<p class="ltx_p" id="Sx2.p2.1">In another direction, we mainly rely on automated metrics for evaluating translation quality, which might not fully capture the accuracy of the translation.
We alleviate this fault by considering the recollection of NEs in translations (§<a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#S4.SS2" title="4.2 Recall of Named Entities ‣ 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_tag">4.2</span></a>).
Furthermore, our experiments in §<a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#S5.SS2" title="5.2 Sensitivity to Input Length ‣ Finetuning outperforms training from scratch. ‣ 5.1 Discussion ‣ 5 Paragraph-level translation ‣ 4.2 Recall of Named Entities ‣ 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_tag">5.2</span></a> do not have a notion of translation difficulty, which might help explain the differences between models and associated datasets in different length buckets (albeit sentence length and difficulty may be connected).</p>
</div>
<section class="ltx_section" id="Sx3">
<h2 class="ltx_title ltx_title_section">Potential Risks</h2>
<div class="ltx_para" id="Sx3.p1">
<p class="ltx_p" id="Sx3.p1.1">Translation biases and error modes inherent in transformed-based LLMs could also be manifested in the linear recurrent models studied in this paper.
Careful evaluation and mitigation strategies, such as detecting and overcoming hallucinations <cite class="ltx_cite ltx_citemacro_citep">(Guerreiro et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib22" title="">2023</a>; Dale et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib11" title="">2023</a>)</cite>, can alleviate these risks and ensure models’ responsible use.
It should also be noted that although SSMs are potentially more energy efficient than transformer-based models, they still pose energy consumption concerns, particularly due to the large size of the models.</p>
</div>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Akyürek et al. (2024)</span>
<span class="ltx_bibblock">
Ekin Akyürek, Bailin Wang, Yoon Kim, and Jacob Andreas. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2401.12973" title="">In-context language learning: Arhitectures and algorithms</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">Preprint</em>, arXiv:2401.12973.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Amos et al. (2024)</span>
<span class="ltx_bibblock">
Ido Amos, Jonathan Berant, and Ankit Gupta. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://openreview.net/forum?id=PdaPky8MUn" title="">Never train from scratch: Fair comparison of long-sequence models requires data-driven priors</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">The Twelfth International Conference on Learning Representations</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Arora et al. (2023)</span>
<span class="ltx_bibblock">
Simran Arora, Sabri Eyuboglu, Aman Timalsina, Isys Johnson, Michael Poli, James Zou, Atri Rudra, and Christopher Ré. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2312.04927" title="">Zoology: Measuring and improving recall in efficient language models</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">Preprint</em>, arXiv:2312.04927.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Arora et al. (2024)</span>
<span class="ltx_bibblock">
Simran Arora, Sabri Eyuboglu, Michael Zhang, Aman Timalsina, Silas Alberti, Dylan Zinsley, James Zou, Atri Rudra, and Christopher Ré. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2402.18668" title="">Simple linear attention language models balance the recall-throughput tradeoff</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">Preprint</em>, arXiv:2402.18668.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Beltagy et al. (2020)</span>
<span class="ltx_bibblock">
Iz Beltagy, Matthew E. Peters, and Arman Cohan. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2004.05150" title="">Longformer: The long-document transformer</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">Preprint</em>, arXiv:2004.05150.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Biderman et al. (2023)</span>
<span class="ltx_bibblock">
Stella Biderman, Hailey Schoelkopf, Quentin Anthony, Herbie Bradley, Kyle O’Brien, Eric Hallahan, Mohammad Aflah Khan, Shivanshu Purohit, USVSN Sai Prashanth, Edward Raff, Aviya Skowron, Lintang Sutawika, and Oskar Van Der Wal. 2023.

</span>
<span class="ltx_bibblock">Pythia: a suite for analyzing large language models across training and scaling.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">Proceedings of the 40th International Conference on Machine Learning</em>, ICML’23. JMLR.org.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bird (2006)</span>
<span class="ltx_bibblock">
Steven Bird. 2006.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.3115/1225403.1225421" title="">NLTK: The Natural Language Toolkit</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">Proceedings of the COLING/ACL 2006 Interactive Presentation Sessions</em>, pages 69–72, Sydney, Australia. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cettolo et al. (2017)</span>
<span class="ltx_bibblock">
Mauro Cettolo, Marcello Federico, Luisa Bentivogli, Jan Niehues, Sebastian Stüker, Katsuhito Sudoh, Koichiro Yoshino, and Christian Federmann. 2017.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2017.iwslt-1.1" title="">Overview of the IWSLT 2017 evaluation campaign</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">Proceedings of the 14th International Conference on Spoken Language Translation</em>, pages 2–14, Tokyo, Japan. International Workshop on Spoken Language Translation.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cettolo et al. (2012)</span>
<span class="ltx_bibblock">
Mauro Cettolo, Christian Girardi, and Marcello Federico. 2012.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2012.eamt-1.60" title="">WIT3: Web inventory of transcribed and translated talks</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">Proceedings of the 16th Annual Conference of the European Association for Machine Translation</em>, pages 261–268, Trento, Italy. European Association for Machine Translation.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Child et al. (2019)</span>
<span class="ltx_bibblock">
Rewon Child, Scott Gray, Alec Radford, and Ilya Sutskever. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/1904.10509" title="">Generating long sequences with sparse transformers</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">Preprint</em>, arXiv:1904.10509.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dale et al. (2023)</span>
<span class="ltx_bibblock">
David Dale, Elena Voita, Loic Barrault, and Marta R. Costa-jussà. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.acl-long.3" title="">Detecting and mitigating hallucinations in machine translation: Model internal workings alone do well, sentence similarity Even better</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pages 36–50, Toronto, Canada. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">De et al. (2024)</span>
<span class="ltx_bibblock">
Soham De, Samuel L. Smith, Anushan Fernando, Aleksandar Botev, George Cristian-Muraru, Albert Gu, Ruba Haroun, Leonard Berrada, Yutian Chen, Srivatsan Srinivasan, Guillaume Desjardins, Arnaud Doucet, David Budden, Yee Whye Teh, Razvan Pascanu, Nando De Freitas, and Caglar Gulcehre. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2402.19427" title="">Griffin: Mixing gated linear recurrences with local attention for efficient language models</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">Preprint</em>, arXiv:2402.19427.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fernandes et al. (2021)</span>
<span class="ltx_bibblock">
Patrick Fernandes, Kayo Yin, Graham Neubig, and André F. T. Martins. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2021.acl-long.505" title="">Measuring and increasing context usage in context-aware machine translation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</em>, pages 6467–6478, Online. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Freitag et al. (2023)</span>
<span class="ltx_bibblock">
Markus Freitag, Nitika Mathur, Chi-kiu Lo, Eleftherios Avramidis, Ricardo Rei, Brian Thompson, Tom Kocmi, Frederic Blain, Daniel Deutsch, Craig Stewart, Chrysoula Zerva, Sheila Castilho, Alon Lavie, and George Foster. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.wmt-1.51" title="">Results of WMT23 metrics shared task: Metrics might be guilty but references are not innocent</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">Proceedings of the Eighth Conference on Machine Translation</em>, pages 578–628, Singapore. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Freitag et al. (2022)</span>
<span class="ltx_bibblock">
Markus Freitag, Ricardo Rei, Nitika Mathur, Chi-kiu Lo, Craig Stewart, Eleftherios Avramidis, Tom Kocmi, George Foster, Alon Lavie, and André F. T. Martins. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2022.wmt-1.2" title="">Results of WMT22 metrics shared task: Stop using BLEU – neural metrics are better and more robust</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">Proceedings of the Seventh Conference on Machine Translation (WMT)</em>, pages 46–68, Abu Dhabi, United Arab Emirates (Hybrid). Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fu et al. (2023)</span>
<span class="ltx_bibblock">
Daniel Y Fu, Tri Dao, Khaled Kamal Saab, Armin W Thomas, Atri Rudra, and Christopher Re. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://openreview.net/forum?id=COZDy0WYGg" title="">Hungry hungry hippos: Towards language modeling with state space models</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">The Eleventh International Conference on Learning Representations</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao et al. (2020)</span>
<span class="ltx_bibblock">
Leo Gao, Stella Biderman, Sid Black, Laurence Golding, Travis Hoppe, Charles Foster, Jason Phang, Horace He, Anish Thite, Noa Nabeshima, Shawn Presser, and Connor Leahy. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2101.00027" title="">The pile: An 800gb dataset of diverse text for language modeling</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">Preprint</em>, arXiv:2101.00027.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Glorioso et al. (2024)</span>
<span class="ltx_bibblock">
Paolo Glorioso, Quentin Anthony, Yury Tokpanov, James Whittington, Jonathan Pilault, Adam Ibrahim, and Beren Millidge. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2405.16712" title="">Zamba: A compact 7b ssm hybrid model</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">Preprint</em>, arXiv:2405.16712.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gu and Dao (2023)</span>
<span class="ltx_bibblock">
Albert Gu and Tri Dao. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2312.00752" title="">Mamba: Linear-time sequence modeling with selective state spaces</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">Preprint</em>, arXiv:2312.00752.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gu et al. (2020)</span>
<span class="ltx_bibblock">
Albert Gu, Tri Dao, Stefano Ermon, Atri Rudra, and Christopher Ré. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://proceedings.neurips.cc/paper_files/paper/2020/file/102f0bb6efb3a6128a3c750dd16729be-Paper.pdf" title="">Hippo: Recurrent memory with optimal polynomial projections</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">Advances in Neural Information Processing Systems</em>, volume 33, pages 1474–1487. Curran Associates, Inc.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gu et al. (2022)</span>
<span class="ltx_bibblock">
Albert Gu, Karan Goel, and Christopher Re. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://openreview.net/forum?id=uYLFoz1vlAC" title="">Efficiently modeling long sequences with structured state spaces</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">International Conference on Learning Representations</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guerreiro et al. (2023)</span>
<span class="ltx_bibblock">
Nuno M. Guerreiro, Elena Voita, and André Martins. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.eacl-main.75" title="">Looking for a needle in a haystack: A comprehensive study of hallucinations in neural machine translation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics</em>, pages 1059–1075, Dubrovnik, Croatia. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hua et al. (2022)</span>
<span class="ltx_bibblock">
Weizhe Hua, Zihang Dai, Hanxiao Liu, and Quoc Le. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://proceedings.mlr.press/v162/hua22a.html" title="">Transformer quality in linear time</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">Proceedings of the 39th International Conference on Machine Learning</em>, volume 162 of <em class="ltx_emph ltx_font_italic" id="bib.bib23.2.2">Proceedings of Machine Learning Research</em>, pages 9099–9117. PMLR.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jelassi et al. (2024)</span>
<span class="ltx_bibblock">
Samy Jelassi, David Brandfonbrener, Sham M. Kakade, and Eran Malach. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2402.01032" title="">Repeat after me: Transformers are better than state space models at copying</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">Preprint</em>, arXiv:2402.01032.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Katharopoulos et al. (2020)</span>
<span class="ltx_bibblock">
Angelos Katharopoulos, Apoorv Vyas, Nikolaos Pappas, and François Fleuret. 2020.

</span>
<span class="ltx_bibblock">Transformers are rnns: fast autoregressive transformers with linear attention.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">Proceedings of the 37th International Conference on Machine Learning</em>, ICML’20. JMLR.org.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kocmi et al. (2023)</span>
<span class="ltx_bibblock">
Tom Kocmi, Eleftherios Avramidis, Rachel Bawden, Ondřej Bojar, Anton Dvorkovich, Christian Federmann, Mark Fishel, Markus Freitag, Thamme Gowda, Roman Grundkiewicz, Barry Haddow, Philipp Koehn, Benjamin Marie, Christof Monz, Makoto Morishita, Kenton Murray, Makoto Nagata, Toshiaki Nakazawa, Martin Popel, Maja Popović, and Mariya Shmatova. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.wmt-1.1" title="">Findings of the 2023 conference on machine translation (WMT23): LLMs are here but not quite there yet</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">Proceedings of the Eighth Conference on Machine Translation</em>, pages 1–42, Singapore. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kondo et al. (2022)</span>
<span class="ltx_bibblock">
Seiichiro Kondo, Naoya Ueda, Teruaki Oka, Masakazu Sugiyama, Asahi Hentona, and Mamoru Komachi. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2022.paclic-1.12" title="">Japanese named entity recognition from automatic speech recognition using pre-trained models</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">Proceedings of the 36th Pacific Asia Conference on Language, Information and Computation</em>, pages 102–108, Manila, Philippines. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Peng et al. (2023)</span>
<span class="ltx_bibblock">
Bo Peng, Eric Alcaide, Quentin Anthony, Alon Albalak, Samuel Arcadinho, Stella Biderman, Huanqi Cao, Xin Cheng, Michael Chung, Leon Derczynski, Xingjian Du, Matteo Grella, Kranthi Gv, Xuzheng He, Haowen Hou, Przemyslaw Kazienko, Jan Kocon, Jiaming Kong, Bartłomiej Koptyra, Hayden Lau, Jiaju Lin, Krishna Sri Ipsit Mantri, Ferdinand Mom, Atsushi Saito, Guangyu Song, Xiangru Tang, Johan Wind, Stanisław Woźniak, Zhenyuan Zhang, Qinghua Zhou, Jian Zhu, and Rui-Jie Zhu. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.findings-emnlp.936" title="">RWKV: Reinventing RNNs for the transformer era</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">Findings of the Association for Computational Linguistics: EMNLP 2023</em>, pages 14048–14077, Singapore. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Post (2018)</span>
<span class="ltx_bibblock">
Matt Post. 2018.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/W18-6319" title="">A call for clarity in reporting BLEU scores</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">Proceedings of the Third Conference on Machine Translation: Research Papers</em>, pages 186–191, Brussels, Belgium. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rei et al. (2022a)</span>
<span class="ltx_bibblock">
Ricardo Rei, José G. C. de Souza, Duarte Alves, Chrysoula Zerva, Ana C Farinha, Taisiya Glushkova, Alon Lavie, Luisa Coheur, and André F. T. Martins. 2022a.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2022.wmt-1.52" title="">COMET-22: Unbabel-IST 2022 submission for the metrics shared task</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">Proceedings of the Seventh Conference on Machine Translation (WMT)</em>, pages 578–585, Abu Dhabi, United Arab Emirates (Hybrid). Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rei et al. (2022b)</span>
<span class="ltx_bibblock">
Ricardo Rei, Marcos Treviso, Nuno M. Guerreiro, Chrysoula Zerva, Ana C Farinha, Christine Maroti, José G. C. de Souza, Taisiya Glushkova, Duarte Alves, Luisa Coheur, Alon Lavie, and André F. T. Martins. 2022b.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2022.wmt-1.60" title="">CometKiwi: IST-unbabel 2022 submission for the quality estimation shared task</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">Proceedings of the Seventh Conference on Machine Translation (WMT)</em>, pages 634–645, Abu Dhabi, United Arab Emirates (Hybrid). Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sennrich et al. (2016)</span>
<span class="ltx_bibblock">
Rico Sennrich, Barry Haddow, and Alexandra Birch. 2016.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/P16-1162" title="">Neural machine translation of rare words with subword units</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pages 1715–1725, Berlin, Germany. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shazeer (2020)</span>
<span class="ltx_bibblock">
Noam Shazeer. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2002.05202" title="">Glu variants improve transformer</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">Preprint</em>, arXiv:2002.05202.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Smith et al. (2023)</span>
<span class="ltx_bibblock">
Jimmy T.H. Smith, Andrew Warrington, and Scott Linderman. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://openreview.net/forum?id=Ai8Hw3AXqks" title="">Simplified state space layers for sequence modeling</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">The Eleventh International Conference on Learning Representations</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Smola and Schölkopf (1998)</span>
<span class="ltx_bibblock">
Alex J Smola and Bernhard Schölkopf. 1998.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">Learning with kernels</em>, volume 4.

</span>
<span class="ltx_bibblock">Citeseer.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Srivastava et al. (2014)</span>
<span class="ltx_bibblock">
Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. 2014.

</span>
<span class="ltx_bibblock">Dropout: a simple way to prevent neural networks from overfitting.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">The journal of machine learning research</em>, 15(1):1929–1958.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Su et al. (2023)</span>
<span class="ltx_bibblock">
Jianlin Su, Yu Lu, Shengfeng Pan, Ahmed Murtadha, Bo Wen, and Yunfeng Liu. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2104.09864" title="">Roformer: Enhanced transformer with rotary position embedding</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">Preprint</em>, arXiv:2104.09864.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et al. (2023a)</span>
<span class="ltx_bibblock">
Yutao Sun, Li Dong, Shaohan Huang, Shuming Ma, Yuqing Xia, Jilong Xue, Jianyong Wang, and Furu Wei. 2023a.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2307.08621" title="">Retentive network: A successor to transformer for large language models</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">Preprint</em>, arXiv:2307.08621.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et al. (2023b)</span>
<span class="ltx_bibblock">
Yutao Sun, Li Dong, Barun Patra, Shuming Ma, Shaohan Huang, Alon Benhaim, Vishrav Chaudhary, Xia Song, and Furu Wei. 2023b.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.acl-long.816" title="">A length-extrapolatable transformer</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pages 14590–14604, Toronto, Canada. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et al. (2023)</span>
<span class="ltx_bibblock">
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, and Guillaume Lample. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2302.13971" title="">Llama: Open and efficient foundation language models</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">Preprint</em>, arXiv:2302.13971.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tsai et al. (2019)</span>
<span class="ltx_bibblock">
Yao-Hung Hubert Tsai, Shaojie Bai, Makoto Yamada, Louis-Philippe Morency, and Ruslan Salakhutdinov. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/D19-1443" title="">Transformer dissection: An unified understanding for transformer’s attention via the lens of kernel</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib41.1.1">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</em>, pages 4344–4353, Hong Kong, China. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vardasbi et al. (2023)</span>
<span class="ltx_bibblock">
Ali Vardasbi, Telmo Pessoa Pires, Robin Schmidt, and Stephan Peitz. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2023.eamt-1.20" title="">State spaces aren’t enough: Machine translation needs attention</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1">Proceedings of the 24th Annual Conference of the European Association for Machine Translation</em>, pages 205–216, Tampere, Finland. European Association for Machine Translation.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Varis and Bojar (2021)</span>
<span class="ltx_bibblock">
Dusan Varis and Ondřej Bojar. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2021.emnlp-main.650" title="">Sequence length is a domain: Length-based overfitting in transformer models</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</em>. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vaswani et al. (2017)</span>
<span class="ltx_bibblock">
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Ł ukasz Kaiser, and Illia Polosukhin. 2017.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf" title="">Attention is all you need</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib44.1.1">Advances in Neural Information Processing Systems</em>, volume 30. Curran Associates, Inc.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2023)</span>
<span class="ltx_bibblock">
Longyue Wang, Chenyang Lyu, Tianbo Ji, Zhirui Zhang, Dian Yu, Shuming Shi, and Zhaopeng Tu. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.emnlp-main.1036" title="">Document-level machine translation with large language models</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib45.1.1">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</em>, pages 16646–16661, Singapore. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al. (2024)</span>
<span class="ltx_bibblock">
Songlin Yang, Bailin Wang, Yikang Shen, Rameswar Panda, and Yoon Kim. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2312.06635" title="">Gated linear attention transformers with hardware-efficient training</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib46.1.1">Preprint</em>, arXiv:2312.06635.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Implementation and Training Details</h2>
<div class="ltx_para" id="A1.p1">
<p class="ltx_p" id="A1.p1.1">All experiments were carried on Nvidia RTX A6000 GPUS with 48GB VRAM, and the training framework is constructed around PyTorch Lightning.<span class="ltx_note ltx_role_footnote" id="footnote10"><sup class="ltx_note_mark">10</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">10</sup><span class="ltx_tag ltx_tag_note">10</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://lightning.ai/docs/pytorch/" title="">https://lightning.ai/docs/pytorch/</a></span></span></span>
To train and generate translations in batches, we use a left-padding strategy. However, for Mamba, additional functionality is required to avoid processing padding tokens.
To address this, we zero out inputs before and after convolution at the positions of the padding tokens and sacrifice some efficiency by using the slow path in Mamba<span class="ltx_note ltx_role_footnote" id="footnote11"><sup class="ltx_note_mark">11</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">11</sup><span class="ltx_tag ltx_tag_note">11</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/state-spaces/mamba/issues/216" title="">https://github.com/state-spaces/mamba/issues/216</a></span></span></span>. Notably, during inference, the slow path affects only the initial processing of the prompt and does not impact the actual generation.
Moreover, we added Dropout <cite class="ltx_cite ltx_citemacro_citep">(Srivastava et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib36" title="">2014</a>)</cite> to Mamba blocks, which was missing in the original implementation. Specifically, dropout is applied after the last linear projection of the Mamba block.
Additionally, following the findings in <cite class="ltx_cite ltx_citemacro_citep">(Vardasbi et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib42" title="">2023</a>)</cite>, we calculate cross-entropy loss only for target tokens.
During training, we use greedy decoding and select the top model using BLEU as the validation metric, as it is faster to compute in comparison to COMET.
For inference, we use beam search with a beam size of 5. Due to the time-consuming nature of our experiments, we report the results of a single run for all experiments.
The overall model structure and hyperparameters across both training regimes, from-scratch (§<a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#A1.SS1" title="A.1 Training from Scratch ‣ Appendix A Implementation and Training Details ‣ Potential Risks ‣ Limitations ‣ Acknowledgments ‣ 7 Conclusion ‣ Sentence concatenation ‣ 6 Related Works ‣ 5.3 Inference Cost ‣ Discussion. ‣ 5.2 Sensitivity to Input Length ‣ Finetuning outperforms training from scratch. ‣ 5.1 Discussion ‣ 5 Paragraph-level translation ‣ 4.2 Recall of Named Entities ‣ 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_tag">A.1</span></a>) and finetuning (§<a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#A1.SS2" title="A.2 Finetuning Pretrained Checkpoints ‣ A.1 Training from Scratch ‣ Appendix A Implementation and Training Details ‣ Potential Risks ‣ Limitations ‣ Acknowledgments ‣ 7 Conclusion ‣ Sentence concatenation ‣ 6 Related Works ‣ 5.3 Inference Cost ‣ Discussion. ‣ 5.2 Sensitivity to Input Length ‣ Finetuning outperforms training from scratch. ‣ 5.1 Discussion ‣ 5 Paragraph-level translation ‣ 4.2 Recall of Named Entities ‣ 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_tag">A.2</span></a>), are shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#A1" title="Appendix A Implementation and Training Details ‣ Potential Risks ‣ Limitations ‣ Acknowledgments ‣ 7 Conclusion ‣ Sentence concatenation ‣ 6 Related Works ‣ 5.3 Inference Cost ‣ Discussion. ‣ 5.2 Sensitivity to Input Length ‣ Finetuning outperforms training from scratch. ‣ 5.1 Discussion ‣ 5 Paragraph-level translation ‣ 4.2 Recall of Named Entities ‣ 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_tag">A</span></a>.
Furthermore, all models were trained with <code class="ltx_verbatim ltx_font_typewriter" id="A1.p1.1.1">bfloat16</code> precision.</p>
</div>
<figure class="ltx_table" id="A1.tab1">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_1">
<table class="ltx_tabular ltx_figure_panel ltx_align_middle" id="A1.tab1.1">
<tr class="ltx_tr" id="A1.tab1.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="A1.tab1.1.1.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_smallcaps" id="A1.tab1.1.1.1.1">Model</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A1.tab1.1.1.2" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_smallcaps" id="A1.tab1.1.1.2.1">Size</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A1.tab1.1.1.3" style="padding-left:4.0pt;padding-right:4.0pt;">LR</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A1.tab1.1.1.4" style="padding-left:4.0pt;padding-right:4.0pt;">L</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A1.tab1.1.1.5" style="padding-left:4.0pt;padding-right:4.0pt;">H</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A1.tab1.1.1.6" style="padding-left:4.0pt;padding-right:4.0pt;">D</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A1.tab1.1.1.7" style="padding-left:4.0pt;padding-right:4.0pt;">FFN</td>
</tr>
<tr class="ltx_tr" id="A1.tab1.1.2">
<td class="ltx_td ltx_align_left ltx_border_t" colspan="5" id="A1.tab1.1.2.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_italic" id="A1.tab1.1.2.1.1">Trained from scratch</span></td>
<td class="ltx_td ltx_border_t" id="A1.tab1.1.2.2" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_border_t" id="A1.tab1.1.2.3" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
</tr>
<tr class="ltx_tr" id="A1.tab1.1.3">
<td class="ltx_td ltx_align_left" id="A1.tab1.1.3.1" style="padding-left:4.0pt;padding-right:4.0pt;">Transf. Enc-Dec</td>
<td class="ltx_td ltx_align_center" id="A1.tab1.1.3.2" style="padding-left:4.0pt;padding-right:4.0pt;">77M</td>
<td class="ltx_td ltx_align_center" id="A1.tab1.1.3.3" style="padding-left:4.0pt;padding-right:4.0pt;">4e-4</td>
<td class="ltx_td ltx_align_center" id="A1.tab1.1.3.4" style="padding-left:4.0pt;padding-right:4.0pt;">6-6</td>
<td class="ltx_td ltx_align_center" id="A1.tab1.1.3.5" style="padding-left:4.0pt;padding-right:4.0pt;">8</td>
<td class="ltx_td ltx_align_center" id="A1.tab1.1.3.6" style="padding-left:4.0pt;padding-right:4.0pt;">512</td>
<td class="ltx_td ltx_align_center" id="A1.tab1.1.3.7" style="padding-left:4.0pt;padding-right:4.0pt;">2048</td>
</tr>
<tr class="ltx_tr" id="A1.tab1.1.4">
<td class="ltx_td ltx_align_left" id="A1.tab1.1.4.1" style="padding-left:4.0pt;padding-right:4.0pt;">Transf.++</td>
<td class="ltx_td ltx_align_center" id="A1.tab1.1.4.2" style="padding-left:4.0pt;padding-right:4.0pt;">79M</td>
<td class="ltx_td ltx_align_center" id="A1.tab1.1.4.3" style="padding-left:4.0pt;padding-right:4.0pt;">4e-4</td>
<td class="ltx_td ltx_align_center" id="A1.tab1.1.4.4" style="padding-left:4.0pt;padding-right:4.0pt;">12</td>
<td class="ltx_td ltx_align_center" id="A1.tab1.1.4.5" style="padding-left:4.0pt;padding-right:4.0pt;">8</td>
<td class="ltx_td ltx_align_center" id="A1.tab1.1.4.6" style="padding-left:4.0pt;padding-right:4.0pt;">496</td>
<td class="ltx_td ltx_align_center" id="A1.tab1.1.4.7" style="padding-left:4.0pt;padding-right:4.0pt;">1984</td>
</tr>
<tr class="ltx_tr" id="A1.tab1.1.5">
<td class="ltx_td ltx_align_left" id="A1.tab1.1.5.1" style="padding-left:4.0pt;padding-right:4.0pt;">RetNet</td>
<td class="ltx_td ltx_align_center" id="A1.tab1.1.5.2" style="padding-left:4.0pt;padding-right:4.0pt;">77M</td>
<td class="ltx_td ltx_align_center" id="A1.tab1.1.5.3" style="padding-left:4.0pt;padding-right:4.0pt;">1e-3</td>
<td class="ltx_td ltx_align_center" id="A1.tab1.1.5.4" style="padding-left:4.0pt;padding-right:4.0pt;">12</td>
<td class="ltx_td ltx_align_center" id="A1.tab1.1.5.5" style="padding-left:4.0pt;padding-right:4.0pt;">4</td>
<td class="ltx_td ltx_align_center" id="A1.tab1.1.5.6" style="padding-left:4.0pt;padding-right:4.0pt;">512</td>
<td class="ltx_td ltx_align_center" id="A1.tab1.1.5.7" style="padding-left:4.0pt;padding-right:4.0pt;">1024</td>
</tr>
<tr class="ltx_tr" id="A1.tab1.1.6">
<td class="ltx_td ltx_align_left" id="A1.tab1.1.6.1" style="padding-left:4.0pt;padding-right:4.0pt;">Mamba</td>
<td class="ltx_td ltx_align_center" id="A1.tab1.1.6.2" style="padding-left:4.0pt;padding-right:4.0pt;">77M</td>
<td class="ltx_td ltx_align_center" id="A1.tab1.1.6.3" style="padding-left:4.0pt;padding-right:4.0pt;">1e-3</td>
<td class="ltx_td ltx_align_center" id="A1.tab1.1.6.4" style="padding-left:4.0pt;padding-right:4.0pt;">24</td>
<td class="ltx_td ltx_align_center" id="A1.tab1.1.6.5" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center" id="A1.tab1.1.6.6" style="padding-left:4.0pt;padding-right:4.0pt;">610</td>
<td class="ltx_td ltx_align_center" id="A1.tab1.1.6.7" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
</tr>
<tr class="ltx_tr" id="A1.tab1.1.7">
<td class="ltx_td ltx_align_left" id="A1.tab1.1.7.1" style="padding-left:4.0pt;padding-right:4.0pt;">
<span class="ltx_ERROR undefined" id="A1.tab1.1.7.1.1">\cdashline</span>1-7[.4pt/2pt]

Mamba-MHA</td>
<td class="ltx_td ltx_align_center" id="A1.tab1.1.7.2" style="padding-left:4.0pt;padding-right:4.0pt;">78M</td>
<td class="ltx_td ltx_align_center" id="A1.tab1.1.7.3" style="padding-left:4.0pt;padding-right:4.0pt;">7e-4</td>
<td class="ltx_td ltx_align_center" id="A1.tab1.1.7.4" style="padding-left:4.0pt;padding-right:4.0pt;">24</td>
<td class="ltx_td ltx_align_center" id="A1.tab1.1.7.5" style="padding-left:4.0pt;padding-right:4.0pt;">8</td>
<td class="ltx_td ltx_align_center" id="A1.tab1.1.7.6" style="padding-left:4.0pt;padding-right:4.0pt;">624</td>
<td class="ltx_td ltx_align_center" id="A1.tab1.1.7.7" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
</tr>
<tr class="ltx_tr" id="A1.tab1.1.8">
<td class="ltx_td ltx_align_left" id="A1.tab1.1.8.1" style="padding-left:4.0pt;padding-right:4.0pt;">Mamba-Local</td>
<td class="ltx_td ltx_align_center" id="A1.tab1.1.8.2" style="padding-left:4.0pt;padding-right:4.0pt;">78M</td>
<td class="ltx_td ltx_align_center" id="A1.tab1.1.8.3" style="padding-left:4.0pt;padding-right:4.0pt;">7e-4</td>
<td class="ltx_td ltx_align_center" id="A1.tab1.1.8.4" style="padding-left:4.0pt;padding-right:4.0pt;">24</td>
<td class="ltx_td ltx_align_center" id="A1.tab1.1.8.5" style="padding-left:4.0pt;padding-right:4.0pt;">8</td>
<td class="ltx_td ltx_align_center" id="A1.tab1.1.8.6" style="padding-left:4.0pt;padding-right:4.0pt;">624</td>
<td class="ltx_td ltx_align_center" id="A1.tab1.1.8.7" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
</tr>
<tr class="ltx_tr" id="A1.tab1.1.9">
<td class="ltx_td ltx_align_left" id="A1.tab1.1.9.1" style="padding-left:4.0pt;padding-right:4.0pt;">Mamba Enc-Dec</td>
<td class="ltx_td ltx_align_center" id="A1.tab1.1.9.2" style="padding-left:4.0pt;padding-right:4.0pt;">82M</td>
<td class="ltx_td ltx_align_center" id="A1.tab1.1.9.3" style="padding-left:4.0pt;padding-right:4.0pt;">7e-4</td>
<td class="ltx_td ltx_align_center" id="A1.tab1.1.9.4" style="padding-left:4.0pt;padding-right:4.0pt;">8-6</td>
<td class="ltx_td ltx_align_center" id="A1.tab1.1.9.5" style="padding-left:4.0pt;padding-right:4.0pt;">8</td>
<td class="ltx_td ltx_align_center" id="A1.tab1.1.9.6" style="padding-left:4.0pt;padding-right:4.0pt;">512</td>
<td class="ltx_td ltx_align_center" id="A1.tab1.1.9.7" style="padding-left:4.0pt;padding-right:4.0pt;">2048</td>
</tr>
<tr class="ltx_tr" id="A1.tab1.1.10">
<td class="ltx_td ltx_align_left ltx_border_t" colspan="5" id="A1.tab1.1.10.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_italic" id="A1.tab1.1.10.1.1">Finetuned</span></td>
<td class="ltx_td ltx_border_t" id="A1.tab1.1.10.2" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_border_t" id="A1.tab1.1.10.3" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
</tr>
<tr class="ltx_tr" id="A1.tab1.1.11">
<td class="ltx_td ltx_align_left" id="A1.tab1.1.11.1" style="padding-left:4.0pt;padding-right:4.0pt;">Pythia-S</td>
<td class="ltx_td ltx_align_center" id="A1.tab1.1.11.2" style="padding-left:4.0pt;padding-right:4.0pt;">410M</td>
<td class="ltx_td ltx_align_center" id="A1.tab1.1.11.3" style="padding-left:4.0pt;padding-right:4.0pt;">1e-5</td>
<td class="ltx_td ltx_align_center" id="A1.tab1.1.11.4" style="padding-left:4.0pt;padding-right:4.0pt;">24</td>
<td class="ltx_td ltx_align_center" id="A1.tab1.1.11.5" style="padding-left:4.0pt;padding-right:4.0pt;">16</td>
<td class="ltx_td ltx_align_center" id="A1.tab1.1.11.6" style="padding-left:4.0pt;padding-right:4.0pt;">1024</td>
<td class="ltx_td ltx_align_center" id="A1.tab1.1.11.7" style="padding-left:4.0pt;padding-right:4.0pt;">4096</td>
</tr>
<tr class="ltx_tr" id="A1.tab1.1.12">
<td class="ltx_td ltx_align_left" id="A1.tab1.1.12.1" style="padding-left:4.0pt;padding-right:4.0pt;">Mamba-S</td>
<td class="ltx_td ltx_align_center" id="A1.tab1.1.12.2" style="padding-left:4.0pt;padding-right:4.0pt;">370M</td>
<td class="ltx_td ltx_align_center" id="A1.tab1.1.12.3" style="padding-left:4.0pt;padding-right:4.0pt;">3e-4</td>
<td class="ltx_td ltx_align_center" id="A1.tab1.1.12.4" style="padding-left:4.0pt;padding-right:4.0pt;">24</td>
<td class="ltx_td ltx_align_center" id="A1.tab1.1.12.5" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center" id="A1.tab1.1.12.6" style="padding-left:4.0pt;padding-right:4.0pt;">1024</td>
<td class="ltx_td ltx_align_center" id="A1.tab1.1.12.7" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
</tr>
<tr class="ltx_tr" id="A1.tab1.1.13">
<td class="ltx_td ltx_align_left" id="A1.tab1.1.13.1" style="padding-left:4.0pt;padding-right:4.0pt;">Pythia-M</td>
<td class="ltx_td ltx_align_center" id="A1.tab1.1.13.2" style="padding-left:4.0pt;padding-right:4.0pt;">1.4B</td>
<td class="ltx_td ltx_align_center" id="A1.tab1.1.13.3" style="padding-left:4.0pt;padding-right:4.0pt;">1e-5</td>
<td class="ltx_td ltx_align_center" id="A1.tab1.1.13.4" style="padding-left:4.0pt;padding-right:4.0pt;">24</td>
<td class="ltx_td ltx_align_center" id="A1.tab1.1.13.5" style="padding-left:4.0pt;padding-right:4.0pt;">16</td>
<td class="ltx_td ltx_align_center" id="A1.tab1.1.13.6" style="padding-left:4.0pt;padding-right:4.0pt;">2048</td>
<td class="ltx_td ltx_align_center" id="A1.tab1.1.13.7" style="padding-left:4.0pt;padding-right:4.0pt;">8192</td>
</tr>
<tr class="ltx_tr" id="A1.tab1.1.14">
<td class="ltx_td ltx_align_left ltx_border_bb" id="A1.tab1.1.14.1" style="padding-left:4.0pt;padding-right:4.0pt;">Mamba-M</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.tab1.1.14.2" style="padding-left:4.0pt;padding-right:4.0pt;">1.4B</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.tab1.1.14.3" style="padding-left:4.0pt;padding-right:4.0pt;">3e-4</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.tab1.1.14.4" style="padding-left:4.0pt;padding-right:4.0pt;">24</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.tab1.1.14.5" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.tab1.1.14.6" style="padding-left:4.0pt;padding-right:4.0pt;">2048</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.tab1.1.14.7" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
</tr>
</table>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 5: </span>Detailing the full set of hyperparameters for the different models. Encoder-Decoder models have their number of layers separated by each module. LR represents the Learning Rate; L represents the number of layers; H is the number of Attention Heads; D is the model dimension; FFN is the size of the inner feed-forward network.
</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<section class="ltx_subsection ltx_figure_panel" id="A1.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.1 </span>Training from Scratch</h3>
<div class="ltx_para" id="A1.SS1.p1">
<p class="ltx_p" id="A1.SS1.p1.3">Regarding tokenization, we leverage the HuggingFace <span class="ltx_text ltx_font_italic" id="A1.SS1.p1.3.1">tokenizers</span> library<span class="ltx_note ltx_role_footnote" id="footnote12"><sup class="ltx_note_mark">12</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">12</sup><span class="ltx_tag ltx_tag_note">12</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/huggingface/tokenizers" title="">https://github.com/huggingface/tokenizers</a> </span></span></span> and construct a separate BPE tokenizer <cite class="ltx_cite ltx_citemacro_citep">(Sennrich et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib32" title="">2016</a>)</cite> per dataset. The total vocabulary size is 32000 tokens.
We carried out a hyperparameter search to select appropriate dropout values, learning rates and architectural decisions, with the latter two detailed in Table <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#A1" title="Appendix A Implementation and Training Details ‣ Potential Risks ‣ Limitations ‣ Acknowledgments ‣ 7 Conclusion ‣ Sentence concatenation ‣ 6 Related Works ‣ 5.3 Inference Cost ‣ Discussion. ‣ 5.2 Sensitivity to Input Length ‣ Finetuning outperforms training from scratch. ‣ 5.1 Discussion ‣ 5 Paragraph-level translation ‣ 4.2 Recall of Named Entities ‣ 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_tag">A</span></a>. We employ a dropout of <math alttext="0.3" class="ltx_Math" display="inline" id="A1.SS1.p1.1.m1.1"><semantics id="A1.SS1.p1.1.m1.1a"><mn id="A1.SS1.p1.1.m1.1.1" xref="A1.SS1.p1.1.m1.1.1.cmml">0.3</mn><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.1.m1.1b"><cn id="A1.SS1.p1.1.m1.1.1.cmml" type="float" xref="A1.SS1.p1.1.m1.1.1">0.3</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.1.m1.1c">0.3</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p1.1.m1.1d">0.3</annotation></semantics></math> and <math alttext="0.1" class="ltx_Math" display="inline" id="A1.SS1.p1.2.m2.1"><semantics id="A1.SS1.p1.2.m2.1a"><mn id="A1.SS1.p1.2.m2.1.1" xref="A1.SS1.p1.2.m2.1.1.cmml">0.1</mn><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.2.m2.1b"><cn id="A1.SS1.p1.2.m2.1.1.cmml" type="float" xref="A1.SS1.p1.2.m2.1.1">0.1</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.2.m2.1c">0.1</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p1.2.m2.1d">0.1</annotation></semantics></math> for both WMT14 and the different variations of WMT23. Other hyperparameters were kept intact. Concretely, we use the Inverse Square Root learning rate scheduler <cite class="ltx_cite ltx_citemacro_citep">(Vaswani et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib44" title="">2017</a>)</cite> with 4000 warmup steps and a weight decay of <math alttext="0.001" class="ltx_Math" display="inline" id="A1.SS1.p1.3.m3.1"><semantics id="A1.SS1.p1.3.m3.1a"><mn id="A1.SS1.p1.3.m3.1.1" xref="A1.SS1.p1.3.m3.1.1.cmml">0.001</mn><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.3.m3.1b"><cn id="A1.SS1.p1.3.m3.1.1.cmml" type="float" xref="A1.SS1.p1.3.m3.1.1">0.001</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.3.m3.1c">0.001</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p1.3.m3.1d">0.001</annotation></semantics></math>.</p>
</div>
<section class="ltx_subsection" id="A1.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.2 </span>Finetuning Pretrained Checkpoints</h3>
<div class="ltx_para" id="A1.SS2.p1">
<p class="ltx_p" id="A1.SS2.p1.2">We employ pretrained models and corresponding tokenizers from the Huggingface library. Table <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#A1.T6" title="Table 6 ‣ A.2 Finetuning Pretrained Checkpoints ‣ A.1 Training from Scratch ‣ Appendix A Implementation and Training Details ‣ Potential Risks ‣ Limitations ‣ Acknowledgments ‣ 7 Conclusion ‣ Sentence concatenation ‣ 6 Related Works ‣ 5.3 Inference Cost ‣ Discussion. ‣ 5.2 Sensitivity to Input Length ‣ Finetuning outperforms training from scratch. ‣ 5.1 Discussion ‣ 5 Paragraph-level translation ‣ 4.2 Recall of Named Entities ‣ 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_tag">6</span></a> shows the number of tokens and the size of the context window used during pretraining. For finetuning, in all experiments, we use a dropout of 0.1 with the exception of WMT16 <span class="ltx_text ltx_font_smallcaps" id="A1.SS2.p1.1.1">en<math alttext="\leftrightarrow" class="ltx_Math" display="inline" id="A1.SS2.p1.1.1.m1.1"><semantics id="A1.SS2.p1.1.1.m1.1a"><mo id="A1.SS2.p1.1.1.m1.1.1" stretchy="false" xref="A1.SS2.p1.1.1.m1.1.1.cmml">↔</mo><annotation-xml encoding="MathML-Content" id="A1.SS2.p1.1.1.m1.1b"><ci id="A1.SS2.p1.1.1.m1.1.1.cmml" xref="A1.SS2.p1.1.1.m1.1.1">↔</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p1.1.1.m1.1c">\leftrightarrow</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.p1.1.1.m1.1d">↔</annotation></semantics></math>ro</span>, where dropout varies from 0.1 to 0.3. Moreover, we use weight decay only in Mamba-M, with a value of <math alttext="2\cdot 10^{-4}" class="ltx_Math" display="inline" id="A1.SS2.p1.2.m1.1"><semantics id="A1.SS2.p1.2.m1.1a"><mrow id="A1.SS2.p1.2.m1.1.1" xref="A1.SS2.p1.2.m1.1.1.cmml"><mn id="A1.SS2.p1.2.m1.1.1.2" xref="A1.SS2.p1.2.m1.1.1.2.cmml">2</mn><mo id="A1.SS2.p1.2.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="A1.SS2.p1.2.m1.1.1.1.cmml">⋅</mo><msup id="A1.SS2.p1.2.m1.1.1.3" xref="A1.SS2.p1.2.m1.1.1.3.cmml"><mn id="A1.SS2.p1.2.m1.1.1.3.2" xref="A1.SS2.p1.2.m1.1.1.3.2.cmml">10</mn><mrow id="A1.SS2.p1.2.m1.1.1.3.3" xref="A1.SS2.p1.2.m1.1.1.3.3.cmml"><mo id="A1.SS2.p1.2.m1.1.1.3.3a" xref="A1.SS2.p1.2.m1.1.1.3.3.cmml">−</mo><mn id="A1.SS2.p1.2.m1.1.1.3.3.2" xref="A1.SS2.p1.2.m1.1.1.3.3.2.cmml">4</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="A1.SS2.p1.2.m1.1b"><apply id="A1.SS2.p1.2.m1.1.1.cmml" xref="A1.SS2.p1.2.m1.1.1"><ci id="A1.SS2.p1.2.m1.1.1.1.cmml" xref="A1.SS2.p1.2.m1.1.1.1">⋅</ci><cn id="A1.SS2.p1.2.m1.1.1.2.cmml" type="integer" xref="A1.SS2.p1.2.m1.1.1.2">2</cn><apply id="A1.SS2.p1.2.m1.1.1.3.cmml" xref="A1.SS2.p1.2.m1.1.1.3"><csymbol cd="ambiguous" id="A1.SS2.p1.2.m1.1.1.3.1.cmml" xref="A1.SS2.p1.2.m1.1.1.3">superscript</csymbol><cn id="A1.SS2.p1.2.m1.1.1.3.2.cmml" type="integer" xref="A1.SS2.p1.2.m1.1.1.3.2">10</cn><apply id="A1.SS2.p1.2.m1.1.1.3.3.cmml" xref="A1.SS2.p1.2.m1.1.1.3.3"><minus id="A1.SS2.p1.2.m1.1.1.3.3.1.cmml" xref="A1.SS2.p1.2.m1.1.1.3.3"></minus><cn id="A1.SS2.p1.2.m1.1.1.3.3.2.cmml" type="integer" xref="A1.SS2.p1.2.m1.1.1.3.3.2">4</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p1.2.m1.1c">2\cdot 10^{-4}</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.p1.2.m1.1d">2 ⋅ 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT</annotation></semantics></math>. Additionally, learning rates and models’ attributes are shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#A1" title="Appendix A Implementation and Training Details ‣ Potential Risks ‣ Limitations ‣ Acknowledgments ‣ 7 Conclusion ‣ Sentence concatenation ‣ 6 Related Works ‣ 5.3 Inference Cost ‣ Discussion. ‣ 5.2 Sensitivity to Input Length ‣ Finetuning outperforms training from scratch. ‣ 5.1 Discussion ‣ 5 Paragraph-level translation ‣ 4.2 Recall of Named Entities ‣ 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_tag">A</span></a>.</p>
</div>
<figure class="ltx_table" id="A1.T6">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A1.T6.1">
<tr class="ltx_tr" id="A1.T6.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="A1.T6.1.1.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_smallcaps" id="A1.T6.1.1.1.1">Model</span></td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="A1.T6.1.1.2" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_smallcaps" id="A1.T6.1.1.2.1">Size</span></td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="A1.T6.1.1.3" style="padding-left:4.0pt;padding-right:4.0pt;">
<span class="ltx_text" id="A1.T6.1.1.3.1"></span> <span class="ltx_text" id="A1.T6.1.1.3.2">
<span class="ltx_tabular ltx_align_middle" id="A1.T6.1.1.3.2.1">
<span class="ltx_tr" id="A1.T6.1.1.3.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A1.T6.1.1.3.2.1.1.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_smallcaps" id="A1.T6.1.1.3.2.1.1.1.1">Training</span></span></span>
<span class="ltx_tr" id="A1.T6.1.1.3.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A1.T6.1.1.3.2.1.2.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_smallcaps" id="A1.T6.1.1.3.2.1.2.1.1">tokens</span></span></span>
</span></span><span class="ltx_text" id="A1.T6.1.1.3.3"></span></td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="A1.T6.1.1.4" style="padding-left:4.0pt;padding-right:4.0pt;">
<span class="ltx_text" id="A1.T6.1.1.4.1"></span> <span class="ltx_text" id="A1.T6.1.1.4.2">
<span class="ltx_tabular ltx_align_middle" id="A1.T6.1.1.4.2.1">
<span class="ltx_tr" id="A1.T6.1.1.4.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A1.T6.1.1.4.2.1.1.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_smallcaps" id="A1.T6.1.1.4.2.1.1.1.1">Context</span></span></span>
<span class="ltx_tr" id="A1.T6.1.1.4.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A1.T6.1.1.4.2.1.2.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_smallcaps" id="A1.T6.1.1.4.2.1.2.1.1">tokens</span></span></span>
</span></span><span class="ltx_text" id="A1.T6.1.1.4.3"></span></td>
</tr>
<tr class="ltx_tr" id="A1.T6.1.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T6.1.2.1" style="padding-left:4.0pt;padding-right:4.0pt;">Pythia-S</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T6.1.2.2" style="padding-left:4.0pt;padding-right:4.0pt;">410M</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T6.1.2.3" style="padding-left:4.0pt;padding-right:4.0pt;">300B</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T6.1.2.4" style="padding-left:4.0pt;padding-right:4.0pt;">2048</td>
</tr>
<tr class="ltx_tr" id="A1.T6.1.3">
<td class="ltx_td ltx_align_left" id="A1.T6.1.3.1" style="padding-left:4.0pt;padding-right:4.0pt;">Pythia-M</td>
<td class="ltx_td ltx_align_left" id="A1.T6.1.3.2" style="padding-left:4.0pt;padding-right:4.0pt;">1.4B</td>
<td class="ltx_td ltx_align_left" id="A1.T6.1.3.3" style="padding-left:4.0pt;padding-right:4.0pt;">300B</td>
<td class="ltx_td ltx_align_left" id="A1.T6.1.3.4" style="padding-left:4.0pt;padding-right:4.0pt;">2048</td>
</tr>
<tr class="ltx_tr" id="A1.T6.1.4">
<td class="ltx_td ltx_align_left" id="A1.T6.1.4.1" style="padding-left:4.0pt;padding-right:4.0pt;">Mamba-S</td>
<td class="ltx_td ltx_align_left" id="A1.T6.1.4.2" style="padding-left:4.0pt;padding-right:4.0pt;">370M</td>
<td class="ltx_td ltx_align_left" id="A1.T6.1.4.3" style="padding-left:4.0pt;padding-right:4.0pt;">7B</td>
<td class="ltx_td ltx_align_left" id="A1.T6.1.4.4" style="padding-left:4.0pt;padding-right:4.0pt;">2048</td>
</tr>
<tr class="ltx_tr" id="A1.T6.1.5">
<td class="ltx_td ltx_align_left ltx_border_bb" id="A1.T6.1.5.1" style="padding-left:4.0pt;padding-right:4.0pt;">Mamba-M</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="A1.T6.1.5.2" style="padding-left:4.0pt;padding-right:4.0pt;">1.4B</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="A1.T6.1.5.3" style="padding-left:4.0pt;padding-right:4.0pt;">26B</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="A1.T6.1.5.4" style="padding-left:4.0pt;padding-right:4.0pt;">2048</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6: </span>Pre-training details. All models were pretrained on The Pile <cite class="ltx_cite ltx_citemacro_citep">(Gao et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib17" title="">2020</a>)</cite>.</figcaption>
</figure>
<section class="ltx_subsection" id="A1.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.3 </span>Inference Cost</h3>
<div class="ltx_para" id="A1.SS3.p1">
<p class="ltx_p" id="A1.SS3.p1.1">For the inference cost experiments, we measure
overall wallclock time using cuda events and cuda synchronization from <span class="ltx_text ltx_font_typewriter" id="A1.SS3.p1.1.1">torch.cuda</span> module. The overall time includes the entire generation pipeline.
Moreover, we use <span class="ltx_text ltx_font_typewriter" id="A1.SS3.p1.1.2">torch.cuda.max_memory_allocated</span> to measure memory usage.</p>
</div>
<section class="ltx_appendix" id="A2">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Hybrid Models Ablation</h2>
<div class="ltx_para" id="A2.p1">
<p class="ltx_p" id="A2.p1.1">Building on the shortcomings of linear models <cite class="ltx_cite ltx_citemacro_citep">(Akyürek et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib1" title="">2024</a>; Arora et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib3" title="">2023</a>; Jelassi et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib24" title="">2024</a>)</cite>, we designed hybrid models to complement SSMs with attention mechanisms.
In this section, we ablate the design choices leading to the construction of our hybrid models.
These experiments were conducted using the IWSLT17 <span class="ltx_text ltx_font_smallcaps" id="A2.p1.1.1">de<math alttext="\leftrightarrow" class="ltx_Math" display="inline" id="A2.p1.1.1.m1.1"><semantics id="A2.p1.1.1.m1.1a"><mo id="A2.p1.1.1.m1.1.1" stretchy="false" xref="A2.p1.1.1.m1.1.1.cmml">↔</mo><annotation-xml encoding="MathML-Content" id="A2.p1.1.1.m1.1b"><ci id="A2.p1.1.1.m1.1.1.cmml" xref="A2.p1.1.1.m1.1.1">↔</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.p1.1.1.m1.1c">\leftrightarrow</annotation><annotation encoding="application/x-llamapun" id="A2.p1.1.1.m1.1d">↔</annotation></semantics></math>en</span> dataset <cite class="ltx_cite ltx_citemacro_citep">(Cettolo et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib8" title="">2017</a>)</cite>. Results are shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#A2.T7" title="Table 7 ‣ Appendix B Hybrid Models Ablation ‣ A.3 Inference Cost ‣ A.2 Finetuning Pretrained Checkpoints ‣ A.1 Training from Scratch ‣ Appendix A Implementation and Training Details ‣ Potential Risks ‣ Limitations ‣ Acknowledgments ‣ 7 Conclusion ‣ Sentence concatenation ‣ 6 Related Works ‣ 5.3 Inference Cost ‣ Discussion. ‣ 5.2 Sensitivity to Input Length ‣ Finetuning outperforms training from scratch. ‣ 5.1 Discussion ‣ 5 Paragraph-level translation ‣ 4.2 Recall of Named Entities ‣ 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_tag">7</span></a>.</p>
</div>
<figure class="ltx_table" id="A2.T7">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A2.T7.2">
<tr class="ltx_tr" id="A2.T7.2.2">
<td class="ltx_td ltx_border_tt" id="A2.T7.2.2.3" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="A2.T7.1.1.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_smallcaps" id="A2.T7.1.1.1.1">de<math alttext="\to" class="ltx_Math" display="inline" id="A2.T7.1.1.1.1.m1.1"><semantics id="A2.T7.1.1.1.1.m1.1a"><mo id="A2.T7.1.1.1.1.m1.1.1" stretchy="false" xref="A2.T7.1.1.1.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="A2.T7.1.1.1.1.m1.1b"><ci id="A2.T7.1.1.1.1.m1.1.1.cmml" xref="A2.T7.1.1.1.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.T7.1.1.1.1.m1.1c">\to</annotation><annotation encoding="application/x-llamapun" id="A2.T7.1.1.1.1.m1.1d">→</annotation></semantics></math>en</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="A2.T7.2.2.2" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_smallcaps" id="A2.T7.2.2.2.1">en<math alttext="\to" class="ltx_Math" display="inline" id="A2.T7.2.2.2.1.m1.1"><semantics id="A2.T7.2.2.2.1.m1.1a"><mo id="A2.T7.2.2.2.1.m1.1.1" stretchy="false" xref="A2.T7.2.2.2.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="A2.T7.2.2.2.1.m1.1b"><ci id="A2.T7.2.2.2.1.m1.1.1.cmml" xref="A2.T7.2.2.2.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.T7.2.2.2.1.m1.1c">\to</annotation><annotation encoding="application/x-llamapun" id="A2.T7.2.2.2.1.m1.1d">→</annotation></semantics></math>de</span></td>
</tr>
<tr class="ltx_tr" id="A2.T7.2.3">
<td class="ltx_td" id="A2.T7.2.3.1" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T7.2.3.2" style="padding-left:4.0pt;padding-right:4.0pt;">BLEU</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T7.2.3.3" style="padding-left:4.0pt;padding-right:4.0pt;">COMET</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T7.2.3.4" style="padding-left:4.0pt;padding-right:4.0pt;">BLEU</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T7.2.3.5" style="padding-left:4.0pt;padding-right:4.0pt;">COMET</td>
</tr>
<tr class="ltx_tr" id="A2.T7.2.4">
<td class="ltx_td ltx_align_left ltx_border_t" colspan="5" id="A2.T7.2.4.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_italic" id="A2.T7.2.4.1.1">Mamba-MHA</span></td>
</tr>
<tr class="ltx_tr" id="A2.T7.2.5">
<td class="ltx_td ltx_align_left" id="A2.T7.2.5.1" style="padding-left:4.0pt;padding-right:4.0pt;">Interleaved</td>
<td class="ltx_td ltx_align_center" id="A2.T7.2.5.2" style="padding-left:4.0pt;padding-right:4.0pt;">30.81</td>
<td class="ltx_td ltx_align_center" id="A2.T7.2.5.3" style="padding-left:4.0pt;padding-right:4.0pt;">77.98</td>
<td class="ltx_td ltx_align_center" id="A2.T7.2.5.4" style="padding-left:4.0pt;padding-right:4.0pt;">24.40</td>
<td class="ltx_td ltx_align_center" id="A2.T7.2.5.5" style="padding-left:4.0pt;padding-right:4.0pt;">72.48</td>
</tr>
<tr class="ltx_tr" id="A2.T7.2.6">
<td class="ltx_td ltx_align_left" id="A2.T7.2.6.1" style="padding-left:4.0pt;padding-right:4.0pt;">L1,11</td>
<td class="ltx_td ltx_align_center" id="A2.T7.2.6.2" style="padding-left:4.0pt;padding-right:4.0pt;">30.52</td>
<td class="ltx_td ltx_align_center" id="A2.T7.2.6.3" style="padding-left:4.0pt;padding-right:4.0pt;">78.10</td>
<td class="ltx_td ltx_align_center" id="A2.T7.2.6.4" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="A2.T7.2.6.4.1">24.99</span></td>
<td class="ltx_td ltx_align_center" id="A2.T7.2.6.5" style="padding-left:4.0pt;padding-right:4.0pt;">73.76</td>
</tr>
<tr class="ltx_tr" id="A2.T7.2.7">
<td class="ltx_td ltx_align_left" id="A2.T7.2.7.1" style="padding-left:4.0pt;padding-right:4.0pt;">L11,23</td>
<td class="ltx_td ltx_align_center" id="A2.T7.2.7.2" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="A2.T7.2.7.2.1">30.81</span></td>
<td class="ltx_td ltx_align_center" id="A2.T7.2.7.3" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="A2.T7.2.7.3.1">78.30</span></td>
<td class="ltx_td ltx_align_center" id="A2.T7.2.7.4" style="padding-left:4.0pt;padding-right:4.0pt;">24.40</td>
<td class="ltx_td ltx_align_center" id="A2.T7.2.7.5" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="A2.T7.2.7.5.1">73.94</span></td>
</tr>
<tr class="ltx_tr" id="A2.T7.2.8">
<td class="ltx_td ltx_align_left ltx_border_t" colspan="5" id="A2.T7.2.8.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_italic" id="A2.T7.2.8.1.1">Mamba-Local</span></td>
</tr>
<tr class="ltx_tr" id="A2.T7.2.9">
<td class="ltx_td ltx_align_left" id="A2.T7.2.9.1" style="padding-left:4.0pt;padding-right:4.0pt;">Interleaved - w64</td>
<td class="ltx_td ltx_align_center" id="A2.T7.2.9.2" style="padding-left:4.0pt;padding-right:4.0pt;">28.85</td>
<td class="ltx_td ltx_align_center" id="A2.T7.2.9.3" style="padding-left:4.0pt;padding-right:4.0pt;">76.76</td>
<td class="ltx_td ltx_align_center" id="A2.T7.2.9.4" style="padding-left:4.0pt;padding-right:4.0pt;">23.61</td>
<td class="ltx_td ltx_align_center" id="A2.T7.2.9.5" style="padding-left:4.0pt;padding-right:4.0pt;">72.10</td>
</tr>
<tr class="ltx_tr" id="A2.T7.2.10">
<td class="ltx_td ltx_align_left" id="A2.T7.2.10.1" style="padding-left:4.0pt;padding-right:4.0pt;">L11,23 - w16</td>
<td class="ltx_td ltx_align_center" id="A2.T7.2.10.2" style="padding-left:4.0pt;padding-right:4.0pt;">29.37</td>
<td class="ltx_td ltx_align_center" id="A2.T7.2.10.3" style="padding-left:4.0pt;padding-right:4.0pt;">77.19</td>
<td class="ltx_td ltx_align_center" id="A2.T7.2.10.4" style="padding-left:4.0pt;padding-right:4.0pt;">24.12</td>
<td class="ltx_td ltx_align_center" id="A2.T7.2.10.5" style="padding-left:4.0pt;padding-right:4.0pt;">72.88</td>
</tr>
<tr class="ltx_tr" id="A2.T7.2.11">
<td class="ltx_td ltx_align_left" id="A2.T7.2.11.1" style="padding-left:4.0pt;padding-right:4.0pt;">L11,23 - w32</td>
<td class="ltx_td ltx_align_center" id="A2.T7.2.11.2" style="padding-left:4.0pt;padding-right:4.0pt;">28.24</td>
<td class="ltx_td ltx_align_center" id="A2.T7.2.11.3" style="padding-left:4.0pt;padding-right:4.0pt;">76.44</td>
<td class="ltx_td ltx_align_center" id="A2.T7.2.11.4" style="padding-left:4.0pt;padding-right:4.0pt;">23.20</td>
<td class="ltx_td ltx_align_center" id="A2.T7.2.11.5" style="padding-left:4.0pt;padding-right:4.0pt;">72.22</td>
</tr>
<tr class="ltx_tr" id="A2.T7.2.12">
<td class="ltx_td ltx_align_left" id="A2.T7.2.12.1" style="padding-left:4.0pt;padding-right:4.0pt;">L11,23 - w64</td>
<td class="ltx_td ltx_align_center" id="A2.T7.2.12.2" style="padding-left:4.0pt;padding-right:4.0pt;">29.40</td>
<td class="ltx_td ltx_align_center" id="A2.T7.2.12.3" style="padding-left:4.0pt;padding-right:4.0pt;">77.56</td>
<td class="ltx_td ltx_align_center" id="A2.T7.2.12.4" style="padding-left:4.0pt;padding-right:4.0pt;">24.41</td>
<td class="ltx_td ltx_align_center" id="A2.T7.2.12.5" style="padding-left:4.0pt;padding-right:4.0pt;">72.98</td>
</tr>
<tr class="ltx_tr" id="A2.T7.2.13">
<td class="ltx_td ltx_align_left ltx_border_bb" id="A2.T7.2.13.1" style="padding-left:4.0pt;padding-right:4.0pt;">L11,23 - w128</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A2.T7.2.13.2" style="padding-left:4.0pt;padding-right:4.0pt;">30.49</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A2.T7.2.13.3" style="padding-left:4.0pt;padding-right:4.0pt;">77.98</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A2.T7.2.13.4" style="padding-left:4.0pt;padding-right:4.0pt;">24.85</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A2.T7.2.13.5" style="padding-left:4.0pt;padding-right:4.0pt;">73.58</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 7: </span>Hybrid models ablations with BLEU and COMET scores on the IWSLT17 dataset. Different window sizes are denoted as w<math alttext="\{16,32,64,128\}" class="ltx_Math" display="inline" id="A2.T7.8.m1.4"><semantics id="A2.T7.8.m1.4b"><mrow id="A2.T7.8.m1.4.5.2" xref="A2.T7.8.m1.4.5.1.cmml"><mo id="A2.T7.8.m1.4.5.2.1" stretchy="false" xref="A2.T7.8.m1.4.5.1.cmml">{</mo><mn id="A2.T7.8.m1.1.1" xref="A2.T7.8.m1.1.1.cmml">16</mn><mo id="A2.T7.8.m1.4.5.2.2" xref="A2.T7.8.m1.4.5.1.cmml">,</mo><mn id="A2.T7.8.m1.2.2" xref="A2.T7.8.m1.2.2.cmml">32</mn><mo id="A2.T7.8.m1.4.5.2.3" xref="A2.T7.8.m1.4.5.1.cmml">,</mo><mn id="A2.T7.8.m1.3.3" xref="A2.T7.8.m1.3.3.cmml">64</mn><mo id="A2.T7.8.m1.4.5.2.4" xref="A2.T7.8.m1.4.5.1.cmml">,</mo><mn id="A2.T7.8.m1.4.4" xref="A2.T7.8.m1.4.4.cmml">128</mn><mo id="A2.T7.8.m1.4.5.2.5" stretchy="false" xref="A2.T7.8.m1.4.5.1.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="A2.T7.8.m1.4c"><set id="A2.T7.8.m1.4.5.1.cmml" xref="A2.T7.8.m1.4.5.2"><cn id="A2.T7.8.m1.1.1.cmml" type="integer" xref="A2.T7.8.m1.1.1">16</cn><cn id="A2.T7.8.m1.2.2.cmml" type="integer" xref="A2.T7.8.m1.2.2">32</cn><cn id="A2.T7.8.m1.3.3.cmml" type="integer" xref="A2.T7.8.m1.3.3">64</cn><cn id="A2.T7.8.m1.4.4.cmml" type="integer" xref="A2.T7.8.m1.4.4">128</cn></set></annotation-xml><annotation encoding="application/x-tex" id="A2.T7.8.m1.4d">\{16,32,64,128\}</annotation><annotation encoding="application/x-llamapun" id="A2.T7.8.m1.4e">{ 16 , 32 , 64 , 128 }</annotation></semantics></math>. <span class="ltx_text ltx_font_italic" id="A2.T7.16.1">Interleaved</span> refers to alternating Mamba and attention layers. L<span class="ltx_text ltx_font_italic" id="A2.T7.17.2">1,11</span> and L<span class="ltx_text ltx_font_italic" id="A2.T7.18.3">11,23</span> refer to placing attention in layers <math alttext="2" class="ltx_Math" display="inline" id="A2.T7.9.m2.1"><semantics id="A2.T7.9.m2.1b"><mn id="A2.T7.9.m2.1.1" xref="A2.T7.9.m2.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="A2.T7.9.m2.1c"><cn id="A2.T7.9.m2.1.1.cmml" type="integer" xref="A2.T7.9.m2.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.T7.9.m2.1d">2</annotation><annotation encoding="application/x-llamapun" id="A2.T7.9.m2.1e">2</annotation></semantics></math> - <math alttext="N/2" class="ltx_Math" display="inline" id="A2.T7.10.m3.1"><semantics id="A2.T7.10.m3.1b"><mrow id="A2.T7.10.m3.1.1" xref="A2.T7.10.m3.1.1.cmml"><mi id="A2.T7.10.m3.1.1.2" xref="A2.T7.10.m3.1.1.2.cmml">N</mi><mo id="A2.T7.10.m3.1.1.1" xref="A2.T7.10.m3.1.1.1.cmml">/</mo><mn id="A2.T7.10.m3.1.1.3" xref="A2.T7.10.m3.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="A2.T7.10.m3.1c"><apply id="A2.T7.10.m3.1.1.cmml" xref="A2.T7.10.m3.1.1"><divide id="A2.T7.10.m3.1.1.1.cmml" xref="A2.T7.10.m3.1.1.1"></divide><ci id="A2.T7.10.m3.1.1.2.cmml" xref="A2.T7.10.m3.1.1.2">𝑁</ci><cn id="A2.T7.10.m3.1.1.3.cmml" type="integer" xref="A2.T7.10.m3.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T7.10.m3.1d">N/2</annotation><annotation encoding="application/x-llamapun" id="A2.T7.10.m3.1e">italic_N / 2</annotation></semantics></math> and <math alttext="N/2" class="ltx_Math" display="inline" id="A2.T7.11.m4.1"><semantics id="A2.T7.11.m4.1b"><mrow id="A2.T7.11.m4.1.1" xref="A2.T7.11.m4.1.1.cmml"><mi id="A2.T7.11.m4.1.1.2" xref="A2.T7.11.m4.1.1.2.cmml">N</mi><mo id="A2.T7.11.m4.1.1.1" xref="A2.T7.11.m4.1.1.1.cmml">/</mo><mn id="A2.T7.11.m4.1.1.3" xref="A2.T7.11.m4.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="A2.T7.11.m4.1c"><apply id="A2.T7.11.m4.1.1.cmml" xref="A2.T7.11.m4.1.1"><divide id="A2.T7.11.m4.1.1.1.cmml" xref="A2.T7.11.m4.1.1.1"></divide><ci id="A2.T7.11.m4.1.1.2.cmml" xref="A2.T7.11.m4.1.1.2">𝑁</ci><cn id="A2.T7.11.m4.1.1.3.cmml" type="integer" xref="A2.T7.11.m4.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T7.11.m4.1d">N/2</annotation><annotation encoding="application/x-llamapun" id="A2.T7.11.m4.1e">italic_N / 2</annotation></semantics></math> - <math alttext="N" class="ltx_Math" display="inline" id="A2.T7.12.m5.1"><semantics id="A2.T7.12.m5.1b"><mi id="A2.T7.12.m5.1.1" xref="A2.T7.12.m5.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="A2.T7.12.m5.1c"><ci id="A2.T7.12.m5.1.1.cmml" xref="A2.T7.12.m5.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.T7.12.m5.1d">N</annotation><annotation encoding="application/x-llamapun" id="A2.T7.12.m5.1e">italic_N</annotation></semantics></math>, respectively.</figcaption>
</figure>
<div class="ltx_para" id="A2.p2">
<p class="ltx_p" id="A2.p2.2">Since our Mamba-MHA model replaces a set of Mamba layers with attention modules, we ablated various configurations to determine the optimal number and placement of attention layers.
Our analysis of COMET scores indicated that incorporating two attention layers significantly boosted performance, aligning with findings in previous studies <cite class="ltx_cite ltx_citemacro_citep">(Fu et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#bib.bib16" title="">2023</a>)</cite>. The placement of these layers had a minimal effect, leading us to select the configuration with layers at positions <math alttext="N/2" class="ltx_Math" display="inline" id="A2.p2.1.m1.1"><semantics id="A2.p2.1.m1.1a"><mrow id="A2.p2.1.m1.1.1" xref="A2.p2.1.m1.1.1.cmml"><mi id="A2.p2.1.m1.1.1.2" xref="A2.p2.1.m1.1.1.2.cmml">N</mi><mo id="A2.p2.1.m1.1.1.1" xref="A2.p2.1.m1.1.1.1.cmml">/</mo><mn id="A2.p2.1.m1.1.1.3" xref="A2.p2.1.m1.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="A2.p2.1.m1.1b"><apply id="A2.p2.1.m1.1.1.cmml" xref="A2.p2.1.m1.1.1"><divide id="A2.p2.1.m1.1.1.1.cmml" xref="A2.p2.1.m1.1.1.1"></divide><ci id="A2.p2.1.m1.1.1.2.cmml" xref="A2.p2.1.m1.1.1.2">𝑁</ci><cn id="A2.p2.1.m1.1.1.3.cmml" type="integer" xref="A2.p2.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.p2.1.m1.1c">N/2</annotation><annotation encoding="application/x-llamapun" id="A2.p2.1.m1.1d">italic_N / 2</annotation></semantics></math> and <math alttext="N" class="ltx_Math" display="inline" id="A2.p2.2.m2.1"><semantics id="A2.p2.2.m2.1a"><mi id="A2.p2.2.m2.1.1" xref="A2.p2.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="A2.p2.2.m2.1b"><ci id="A2.p2.2.m2.1.1.cmml" xref="A2.p2.2.m2.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.p2.2.m2.1c">N</annotation><annotation encoding="application/x-llamapun" id="A2.p2.2.m2.1d">italic_N</annotation></semantics></math> for further experiments due to its consistently higher COMET scores.</p>
</div>
<div class="ltx_para" id="A2.p3">
<p class="ltx_p" id="A2.p3.1">In the case of Mamba-Local, which uses a sliding window attention, we explored various window sizes.
Our experiments revealed that performance generally improved with window size in a linear way.
Ultimately, a 128-token window nearly matched full attention performance, and two layers of 64-token windowed attention provided a good balance between performance and efficiency for our experiments.</p>
</div>
</section>
<section class="ltx_appendix" id="A3">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Exploring Length-related Issues</h2>
<figure class="ltx_figure" id="A3.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="522" id="A3.F3.g1" src="x4.png" width="789"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>COMET scores per sequence length on WMT14 <span class="ltx_text ltx_font_smallcaps" id="A3.F3.2.1">de<math alttext="\to" class="ltx_Math" display="inline" id="A3.F3.2.1.m1.1"><semantics id="A3.F3.2.1.m1.1b"><mo id="A3.F3.2.1.m1.1.1" stretchy="false" xref="A3.F3.2.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="A3.F3.2.1.m1.1c"><ci id="A3.F3.2.1.m1.1.1.cmml" xref="A3.F3.2.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.F3.2.1.m1.1d">\to</annotation><annotation encoding="application/x-llamapun" id="A3.F3.2.1.m1.1e">→</annotation></semantics></math>en</span> for trained-from-scratch models.</figcaption>
</figure>
<section class="ltx_subsection" id="A3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.1 </span>Preliminary Sentence-level Experiments</h3>
<div class="ltx_para" id="A3.SS1.p1">
<p class="ltx_p" id="A3.SS1.p1.1">Before experimenting with paragraph-level data, we analyze how our trained-from-scratch models perform on different sequence lengths. To this end, we study their sensitivity to input length when trained and tested on WMT14 <span class="ltx_text ltx_font_smallcaps" id="A3.SS1.p1.1.1">de<math alttext="\to" class="ltx_Math" display="inline" id="A3.SS1.p1.1.1.m1.1"><semantics id="A3.SS1.p1.1.1.m1.1a"><mo id="A3.SS1.p1.1.1.m1.1.1" stretchy="false" xref="A3.SS1.p1.1.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="A3.SS1.p1.1.1.m1.1b"><ci id="A3.SS1.p1.1.1.m1.1.1.cmml" xref="A3.SS1.p1.1.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.SS1.p1.1.1.m1.1c">\to</annotation><annotation encoding="application/x-llamapun" id="A3.SS1.p1.1.1.m1.1d">→</annotation></semantics></math>en</span>. The results are shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#A3.F3" title="Figure 3 ‣ Appendix C Exploring Length-related Issues ‣ A.3 Inference Cost ‣ A.2 Finetuning Pretrained Checkpoints ‣ A.1 Training from Scratch ‣ Appendix A Implementation and Training Details ‣ Potential Risks ‣ Limitations ‣ Acknowledgments ‣ 7 Conclusion ‣ Sentence concatenation ‣ 6 Related Works ‣ 5.3 Inference Cost ‣ Discussion. ‣ 5.2 Sensitivity to Input Length ‣ Finetuning outperforms training from scratch. ‣ 5.1 Discussion ‣ 5 Paragraph-level translation ‣ 4.2 Recall of Named Entities ‣ 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_tag">3</span></a>. While all models show a deterioration in performance as sequence length increases, this effect is more pronounced for Transformer++, RetNet, and Mamba-Local, with a significant drop in performance for samples longer than 64 tokens.</p>
</div>
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F4">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_figure_panel ltx_img_landscape" height="203" id="A3.SS1.1.g1" src="x5.png" width="830"/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="195" id="A3.SS1.2.g2" src="x6.png" width="797"/></div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Sensitivity to input length, measured by the number of sources tokens, on the WMT23 <span class="ltx_text ltx_font_smallcaps" id="A3.F4.2.1">en<math alttext="\to" class="ltx_Math" display="inline" id="A3.F4.2.1.m1.1"><semantics id="A3.F4.2.1.m1.1b"><mo id="A3.F4.2.1.m1.1.1" stretchy="false" xref="A3.F4.2.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="A3.F4.2.1.m1.1c"><ci id="A3.F4.2.1.m1.1.1.cmml" xref="A3.F4.2.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.F4.2.1.m1.1d">\to</annotation><annotation encoding="application/x-llamapun" id="A3.F4.2.1.m1.1e">→</annotation></semantics></math>de</span> datset, for models trained from scratch (top) and finetuned from a pretrained checkpoint (bottom).
</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="A3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.2 </span>Sensitivity to Input Length</h3>
<div class="ltx_para" id="A3.SS2.p1">
<p class="ltx_p" id="A3.SS2.p1.1">Following the discussion in §<a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#S5.SS2" title="5.2 Sensitivity to Input Length ‣ Finetuning outperforms training from scratch. ‣ 5.1 Discussion ‣ 5 Paragraph-level translation ‣ 4.2 Recall of Named Entities ‣ 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_tag">5.2</span></a>, we further investigate the sensitivity of our models to input length using the WMT23 <span class="ltx_text ltx_font_smallcaps" id="A3.SS2.p1.1.1">en<math alttext="\rightarrow" class="ltx_Math" display="inline" id="A3.SS2.p1.1.1.m1.1"><semantics id="A3.SS2.p1.1.1.m1.1a"><mo id="A3.SS2.p1.1.1.m1.1.1" stretchy="false" xref="A3.SS2.p1.1.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="A3.SS2.p1.1.1.m1.1b"><ci id="A3.SS2.p1.1.1.m1.1.1.cmml" xref="A3.SS2.p1.1.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.SS2.p1.1.1.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="A3.SS2.p1.1.1.m1.1d">→</annotation></semantics></math>de</span> test set, with results shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#A3.F4" title="Figure 4 ‣ C.1 Preliminary Sentence-level Experiments ‣ Appendix C Exploring Length-related Issues ‣ A.3 Inference Cost ‣ A.2 Finetuning Pretrained Checkpoints ‣ A.1 Training from Scratch ‣ Appendix A Implementation and Training Details ‣ Potential Risks ‣ Limitations ‣ Acknowledgments ‣ 7 Conclusion ‣ Sentence concatenation ‣ 6 Related Works ‣ 5.3 Inference Cost ‣ Discussion. ‣ 5.2 Sensitivity to Input Length ‣ Finetuning outperforms training from scratch. ‣ 5.1 Discussion ‣ 5 Paragraph-level translation ‣ 4.2 Recall of Named Entities ‣ 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_tag">4</span></a>. Notably, our takeaways remain broadly the same: concatenating samples in the training data is indeed helpful when handling longer sequences, and models trained on the WMT23-CAT-10 dataset are much better in the longer bin (257+) with minimal translation quality degradation in shorter samples.
However, when considering each of the training datasets’ histograms in Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#A3.F5" title="Figure 5 ‣ C.2 Sensitivity to Input Length ‣ Appendix C Exploring Length-related Issues ‣ A.3 Inference Cost ‣ A.2 Finetuning Pretrained Checkpoints ‣ A.1 Training from Scratch ‣ Appendix A Implementation and Training Details ‣ Potential Risks ‣ Limitations ‣ Acknowledgments ‣ 7 Conclusion ‣ Sentence concatenation ‣ 6 Related Works ‣ 5.3 Inference Cost ‣ Discussion. ‣ 5.2 Sensitivity to Input Length ‣ Finetuning outperforms training from scratch. ‣ 5.1 Discussion ‣ 5 Paragraph-level translation ‣ 4.2 Recall of Named Entities ‣ 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_tag">5</span></a>, we can observe that models have been exposed to the longest samples during training, even if in low quantities.
This implies that the previous experiments do not represent an extrapolation setting, where inference is done on longer sequence lengths than those seen during training.
We cover extrapolation to longer sequences next.</p>
</div>
<figure class="ltx_figure" id="A3.F5">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="274" id="A3.F5.g1" src="x7.png" width="365"/></div>
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="274" id="A3.F5.g2" src="x8.png" width="365"/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="274" id="A3.F5.g3" src="x9.png" width="365"/></div>
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="274" id="A3.F5.g4" src="x10.png" width="365"/></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Distribution of source length in 1) the training datasets: WMT23 <span class="ltx_text ltx_font_smallcaps" id="A3.F5.5.1">de<math alttext="\to" class="ltx_Math" display="inline" id="A3.F5.5.1.m1.1"><semantics id="A3.F5.5.1.m1.1b"><mo id="A3.F5.5.1.m1.1.1" stretchy="false" xref="A3.F5.5.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="A3.F5.5.1.m1.1c"><ci id="A3.F5.5.1.m1.1.1.cmml" xref="A3.F5.5.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.F5.5.1.m1.1d">\to</annotation><annotation encoding="application/x-llamapun" id="A3.F5.5.1.m1.1e">→</annotation></semantics></math>en</span> (top left), WMT23 <span class="ltx_text ltx_font_smallcaps" id="A3.F5.6.2">en<math alttext="\to" class="ltx_Math" display="inline" id="A3.F5.6.2.m1.1"><semantics id="A3.F5.6.2.m1.1b"><mo id="A3.F5.6.2.m1.1.1" stretchy="false" xref="A3.F5.6.2.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="A3.F5.6.2.m1.1c"><ci id="A3.F5.6.2.m1.1.1.cmml" xref="A3.F5.6.2.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.F5.6.2.m1.1d">\to</annotation><annotation encoding="application/x-llamapun" id="A3.F5.6.2.m1.1e">→</annotation></semantics></math>de</span> (top right), and 2) the test datasets: WMT23 <span class="ltx_text ltx_font_smallcaps" id="A3.F5.7.3">de<math alttext="\leftrightarrow" class="ltx_Math" display="inline" id="A3.F5.7.3.m1.1"><semantics id="A3.F5.7.3.m1.1b"><mo id="A3.F5.7.3.m1.1.1" stretchy="false" xref="A3.F5.7.3.m1.1.1.cmml">↔</mo><annotation-xml encoding="MathML-Content" id="A3.F5.7.3.m1.1c"><ci id="A3.F5.7.3.m1.1.1.cmml" xref="A3.F5.7.3.m1.1.1">↔</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.F5.7.3.m1.1d">\leftrightarrow</annotation><annotation encoding="application/x-llamapun" id="A3.F5.7.3.m1.1e">↔</annotation></semantics></math>en</span> (bottom left), our custom TED Talks <span class="ltx_text ltx_font_smallcaps" id="A3.F5.8.4">de<math alttext="\to" class="ltx_Math" display="inline" id="A3.F5.8.4.m1.1"><semantics id="A3.F5.8.4.m1.1b"><mo id="A3.F5.8.4.m1.1.1" stretchy="false" xref="A3.F5.8.4.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="A3.F5.8.4.m1.1c"><ci id="A3.F5.8.4.m1.1.1.cmml" xref="A3.F5.8.4.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.F5.8.4.m1.1d">\to</annotation><annotation encoding="application/x-llamapun" id="A3.F5.8.4.m1.1e">→</annotation></semantics></math>en</span> (bottom right). </figcaption>
</figure>
</section>
<section class="ltx_subsection" id="A3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.3 </span>Extrapolation to Longer Sequences</h3>
<div class="ltx_para" id="A3.SS3.p1">
<p class="ltx_p" id="A3.SS3.p1.1">Following the previous discussion, to further explore the impact of sequence length on our models, we create a new test set sampled from TED Talks <span class="ltx_text ltx_font_smallcaps" id="A3.SS3.p1.1.1">de<math alttext="\to" class="ltx_Math" display="inline" id="A3.SS3.p1.1.1.m1.1"><semantics id="A3.SS3.p1.1.1.m1.1a"><mo id="A3.SS3.p1.1.1.m1.1.1" stretchy="false" xref="A3.SS3.p1.1.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="A3.SS3.p1.1.1.m1.1b"><ci id="A3.SS3.p1.1.1.m1.1.1.cmml" xref="A3.SS3.p1.1.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.SS3.p1.1.1.m1.1c">\to</annotation><annotation encoding="application/x-llamapun" id="A3.SS3.p1.1.1.m1.1d">→</annotation></semantics></math>en</span> passages that is much larger (2200 samples) and contains much longer sequences.
The source length distribution can be seen in Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#A3.F5" title="Figure 5 ‣ C.2 Sensitivity to Input Length ‣ Appendix C Exploring Length-related Issues ‣ A.3 Inference Cost ‣ A.2 Finetuning Pretrained Checkpoints ‣ A.1 Training from Scratch ‣ Appendix A Implementation and Training Details ‣ Potential Risks ‣ Limitations ‣ Acknowledgments ‣ 7 Conclusion ‣ Sentence concatenation ‣ 6 Related Works ‣ 5.3 Inference Cost ‣ Discussion. ‣ 5.2 Sensitivity to Input Length ‣ Finetuning outperforms training from scratch. ‣ 5.1 Discussion ‣ 5 Paragraph-level translation ‣ 4.2 Recall of Named Entities ‣ 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_tag">5</span></a> (bottom right).
After evaluating our models in this dataset, we plot COMET scores per sentence length in Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#A3.F6" title="Figure 6 ‣ C.3 Extrapolation to Longer Sequences ‣ Appendix C Exploring Length-related Issues ‣ A.3 Inference Cost ‣ A.2 Finetuning Pretrained Checkpoints ‣ A.1 Training from Scratch ‣ Appendix A Implementation and Training Details ‣ Potential Risks ‣ Limitations ‣ Acknowledgments ‣ 7 Conclusion ‣ Sentence concatenation ‣ 6 Related Works ‣ 5.3 Inference Cost ‣ Discussion. ‣ 5.2 Sensitivity to Input Length ‣ Finetuning outperforms training from scratch. ‣ 5.1 Discussion ‣ 5 Paragraph-level translation ‣ 4.2 Recall of Named Entities ‣ 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_tag">6</span></a>. Note that the dashed vertical line represents the bin containing the longest sentences the model has been exposed to during training.</p>
</div>
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F6">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_figure_panel ltx_img_landscape" height="180" id="A3.SS3.1.g1" src="x11.png" width="830"/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="203" id="A3.SS3.2.g2" src="x12.png" width="830"/></div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Sensitivity to input length, measured by the number of sources tokens, on the Ted Talks <span class="ltx_text ltx_font_smallcaps" id="A3.F6.2.1">de<math alttext="\to" class="ltx_Math" display="inline" id="A3.F6.2.1.m1.1"><semantics id="A3.F6.2.1.m1.1b"><mo id="A3.F6.2.1.m1.1.1" stretchy="false" xref="A3.F6.2.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="A3.F6.2.1.m1.1c"><ci id="A3.F6.2.1.m1.1.1.cmml" xref="A3.F6.2.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.F6.2.1.m1.1d">\to</annotation><annotation encoding="application/x-llamapun" id="A3.F6.2.1.m1.1e">→</annotation></semantics></math>en</span> dataset, for models trained from scratch (top) and finetuned from a pretrained checkpoint (bottom).
The dashed vertical line represents the bin containing the longest sentence in the training set.
</figcaption>
</figure>
<section class="ltx_paragraph" id="A3.SS3.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Discussion.</h5>
<div class="ltx_para" id="A3.SS3.SSS0.Px1.p1">
<p class="ltx_p" id="A3.SS3.SSS0.Px1.p1.2">We observe some interesting behavior: when training from scratch, the translation quality of Transformer++, Mamba, and Mamba-MHA falls sharply when handling 769+ tokens, whereas Mamba Enc-Dec excels even in pure extrapolation settings on the longest inputs.
With the finetuned models,
we also see decreasing translation quality over longer sequences, consistent with previous experiments.
Nonetheless, Mamba models show a more robust trend. In particular, Mamba-M extrapolates well to longer sequences when trained on CAT-10.
For example, for models trained on CAT-10, the best COMET score for inputs longer than 1024 tokens for Pythia-M is <math alttext="\sim" class="ltx_Math" display="inline" id="A3.SS3.SSS0.Px1.p1.1.m1.1"><semantics id="A3.SS3.SSS0.Px1.p1.1.m1.1a"><mo id="A3.SS3.SSS0.Px1.p1.1.m1.1.1" xref="A3.SS3.SSS0.Px1.p1.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="A3.SS3.SSS0.Px1.p1.1.m1.1b"><csymbol cd="latexml" id="A3.SS3.SSS0.Px1.p1.1.m1.1.1.cmml" xref="A3.SS3.SSS0.Px1.p1.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A3.SS3.SSS0.Px1.p1.1.m1.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="A3.SS3.SSS0.Px1.p1.1.m1.1d">∼</annotation></semantics></math>68, while Mamba-M is able to achieve a score of <math alttext="\sim" class="ltx_Math" display="inline" id="A3.SS3.SSS0.Px1.p1.2.m2.1"><semantics id="A3.SS3.SSS0.Px1.p1.2.m2.1a"><mo id="A3.SS3.SSS0.Px1.p1.2.m2.1.1" xref="A3.SS3.SSS0.Px1.p1.2.m2.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="A3.SS3.SSS0.Px1.p1.2.m2.1b"><csymbol cd="latexml" id="A3.SS3.SSS0.Px1.p1.2.m2.1.1.cmml" xref="A3.SS3.SSS0.Px1.p1.2.m2.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A3.SS3.SSS0.Px1.p1.2.m2.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="A3.SS3.SSS0.Px1.p1.2.m2.1d">∼</annotation></semantics></math>75. The gap increases and reaches almost 20 points as we increase the sequence length.</p>
</div>
</section>
</section>
</section>
<section class="ltx_appendix" id="A4">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>Full Paragraph-Level Results</h2>
<div class="ltx_para" id="A4.p1">
<p class="ltx_p" id="A4.p1.1">For completeness, we report paragraph-level results in terms of BLEU and COMET for all language pairs and models in Table <a class="ltx_ref" href="https://arxiv.org/html/2407.05489v1#A4" title="Appendix D Full Paragraph-Level Results ‣ A.3 Inference Cost ‣ A.2 Finetuning Pretrained Checkpoints ‣ A.1 Training from Scratch ‣ Appendix A Implementation and Training Details ‣ Potential Risks ‣ Limitations ‣ Acknowledgments ‣ 7 Conclusion ‣ Sentence concatenation ‣ 6 Related Works ‣ 5.3 Inference Cost ‣ Discussion. ‣ 5.2 Sensitivity to Input Length ‣ Finetuning outperforms training from scratch. ‣ 5.1 Discussion ‣ 5 Paragraph-level translation ‣ 4.2 Recall of Named Entities ‣ 4 Sentence-level Translation ‣ 3.3 Training and Evaluation ‣ 3.2.3 Pretrained Models ‣ 3.2 Models ‣ 3.1 Datasets ‣ 3 Experimental Setup ‣ How Effective are State Space Models for Machine Translation?"><span class="ltx_text ltx_ref_tag">D</span></a>.</p>
</div>
<figure class="ltx_table" id="A4.4">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_1">
<table class="ltx_tabular ltx_figure_panel ltx_align_middle" id="A4.2.2">
<tr class="ltx_tr" id="A4.2.2.2">
<td class="ltx_td ltx_border_tt" id="A4.2.2.2.3" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_border_tt" id="A4.2.2.2.4" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="A4.1.1.1.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_smallcaps" id="A4.1.1.1.1.1">de<math alttext="\to" class="ltx_Math" display="inline" id="A4.1.1.1.1.1.m1.1"><semantics id="A4.1.1.1.1.1.m1.1a"><mo id="A4.1.1.1.1.1.m1.1.1" stretchy="false" xref="A4.1.1.1.1.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="A4.1.1.1.1.1.m1.1b"><ci id="A4.1.1.1.1.1.m1.1.1.cmml" xref="A4.1.1.1.1.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.1.1.1.1.1.m1.1c">\to</annotation><annotation encoding="application/x-llamapun" id="A4.1.1.1.1.1.m1.1d">→</annotation></semantics></math>en</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="A4.2.2.2.2" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_smallcaps" id="A4.2.2.2.2.1">en<math alttext="\to" class="ltx_Math" display="inline" id="A4.2.2.2.2.1.m1.1"><semantics id="A4.2.2.2.2.1.m1.1a"><mo id="A4.2.2.2.2.1.m1.1.1" stretchy="false" xref="A4.2.2.2.2.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="A4.2.2.2.2.1.m1.1b"><ci id="A4.2.2.2.2.1.m1.1.1.cmml" xref="A4.2.2.2.2.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.2.2.2.2.1.m1.1c">\to</annotation><annotation encoding="application/x-llamapun" id="A4.2.2.2.2.1.m1.1d">→</annotation></semantics></math>de</span></td>
</tr>
<tr class="ltx_tr" id="A4.2.2.3">
<td class="ltx_td ltx_align_left" id="A4.2.2.3.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_smallcaps" id="A4.2.2.3.1.1">Model</span></td>
<td class="ltx_td ltx_align_center" id="A4.2.2.3.2" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_smallcaps" id="A4.2.2.3.2.1">Training data</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.2.2.3.3" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_smallcaps" id="A4.2.2.3.3.1">BLEU</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.2.2.3.4" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_smallcaps" id="A4.2.2.3.4.1">COMET</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.2.2.3.5" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_smallcaps" id="A4.2.2.3.5.1">BLEU</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.2.2.3.6" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_smallcaps" id="A4.2.2.3.6.1">COMET</span></td>
</tr>
<tr class="ltx_tr" id="A4.2.2.4">
<td class="ltx_td ltx_align_left ltx_border_t" id="A4.2.2.4.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_italic" id="A4.2.2.4.1.1">Trained from scratch</span></td>
<td class="ltx_td ltx_border_t" id="A4.2.2.4.2" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_border_t" id="A4.2.2.4.3" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_border_t" id="A4.2.2.4.4" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_border_t" id="A4.2.2.4.5" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_border_t" id="A4.2.2.4.6" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
</tr>
<tr class="ltx_tr" id="A4.2.2.5">
<td class="ltx_td ltx_align_left" id="A4.2.2.5.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="A4.2.2.5.1.1">Transformer Enc-Dec</span></td>
<td class="ltx_td ltx_align_center" id="A4.2.2.5.2" rowspan="5" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="A4.2.2.5.2.1">WMT23-6M</span></td>
<td class="ltx_td ltx_align_center" id="A4.2.2.5.3" style="padding-left:4.0pt;padding-right:4.0pt;">25.4</td>
<td class="ltx_td ltx_align_center" id="A4.2.2.5.4" style="padding-left:4.0pt;padding-right:4.0pt;">72.4</td>
<td class="ltx_td ltx_align_center" id="A4.2.2.5.5" style="padding-left:4.0pt;padding-right:4.0pt;">22.4</td>
<td class="ltx_td ltx_align_center" id="A4.2.2.5.6" style="padding-left:4.0pt;padding-right:4.0pt;">65.2</td>
</tr>
<tr class="ltx_tr" id="A4.2.2.6">
<td class="ltx_td ltx_align_left" id="A4.2.2.6.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="A4.2.2.6.1.1">Transformer++</span></td>
<td class="ltx_td ltx_align_center" id="A4.2.2.6.2" style="padding-left:4.0pt;padding-right:4.0pt;">21.6</td>
<td class="ltx_td ltx_align_center" id="A4.2.2.6.3" style="padding-left:4.0pt;padding-right:4.0pt;">70.7</td>
<td class="ltx_td ltx_align_center" id="A4.2.2.6.4" style="padding-left:4.0pt;padding-right:4.0pt;">20.2</td>
<td class="ltx_td ltx_align_center" id="A4.2.2.6.5" style="padding-left:4.0pt;padding-right:4.0pt;">64.8</td>
</tr>
<tr class="ltx_tr" id="A4.2.2.7">
<td class="ltx_td ltx_align_left" id="A4.2.2.7.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="A4.2.2.7.1.1">Mamba</span></td>
<td class="ltx_td ltx_align_center" id="A4.2.2.7.2" style="padding-left:4.0pt;padding-right:4.0pt;">19.0</td>
<td class="ltx_td ltx_align_center" id="A4.2.2.7.3" style="padding-left:4.0pt;padding-right:4.0pt;">70.0</td>
<td class="ltx_td ltx_align_center" id="A4.2.2.7.4" style="padding-left:4.0pt;padding-right:4.0pt;">15.8</td>
<td class="ltx_td ltx_align_center" id="A4.2.2.7.5" style="padding-left:4.0pt;padding-right:4.0pt;">63.3</td>
</tr>
<tr class="ltx_tr" id="A4.2.2.8">
<td class="ltx_td ltx_align_left" id="A4.2.2.8.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="A4.2.2.8.1.1">Mamba-MHA</span></td>
<td class="ltx_td ltx_align_center" id="A4.2.2.8.2" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="A4.2.2.8.2.1">23.9</span></td>
<td class="ltx_td ltx_align_center" id="A4.2.2.8.3" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="A4.2.2.8.3.1">72.7</span></td>
<td class="ltx_td ltx_align_center" id="A4.2.2.8.4" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="A4.2.2.8.4.1">23.2</span></td>
<td class="ltx_td ltx_align_center" id="A4.2.2.8.5" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="A4.2.2.8.5.1">67.0</span></td>
</tr>
<tr class="ltx_tr" id="A4.2.2.9">
<td class="ltx_td ltx_align_left" id="A4.2.2.9.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="A4.2.2.9.1.1">Mamba Enc-Dec</span></td>
<td class="ltx_td ltx_align_center" id="A4.2.2.9.2" style="padding-left:4.0pt;padding-right:4.0pt;">22.7</td>
<td class="ltx_td ltx_align_center" id="A4.2.2.9.3" style="padding-left:4.0pt;padding-right:4.0pt;">70.7</td>
<td class="ltx_td ltx_align_center" id="A4.2.2.9.4" style="padding-left:4.0pt;padding-right:4.0pt;">21.5</td>
<td class="ltx_td ltx_align_center" id="A4.2.2.9.5" style="padding-left:4.0pt;padding-right:4.0pt;">65.3</td>
</tr>
<tr class="ltx_tr" id="A4.2.2.10">
<td class="ltx_td ltx_align_left" id="A4.2.2.10.1" style="padding-left:4.0pt;padding-right:4.0pt;">
<span class="ltx_ERROR undefined" id="A4.2.2.10.1.1">\cdashline</span>1-6[.4pt/2pt]

<span class="ltx_text" id="A4.2.2.10.1.2">Transformer Enc-Dec</span>
</td>
<td class="ltx_td ltx_align_center" id="A4.2.2.10.2" rowspan="5" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="A4.2.2.10.2.1">WMT23-CAT-5</span></td>
<td class="ltx_td ltx_align_center" id="A4.2.2.10.3" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="A4.2.2.10.3.1">30.8</span></td>
<td class="ltx_td ltx_align_center" id="A4.2.2.10.4" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="A4.2.2.10.4.1">74.6</span></td>
<td class="ltx_td ltx_align_center" id="A4.2.2.10.5" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="A4.2.2.10.5.1">29.9</span></td>
<td class="ltx_td ltx_align_center" id="A4.2.2.10.6" style="padding-left:4.0pt;padding-right:4.0pt;">70.3</td>
</tr>
<tr class="ltx_tr" id="A4.2.2.11">
<td class="ltx_td ltx_align_left" id="A4.2.2.11.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="A4.2.2.11.1.1">Transformer++</span></td>
<td class="ltx_td ltx_align_center" id="A4.2.2.11.2" style="padding-left:4.0pt;padding-right:4.0pt;">28.9</td>
<td class="ltx_td ltx_align_center" id="A4.2.2.11.3" style="padding-left:4.0pt;padding-right:4.0pt;">73.6</td>
<td class="ltx_td ltx_align_center" id="A4.2.2.11.4" style="padding-left:4.0pt;padding-right:4.0pt;">28.1</td>
<td class="ltx_td ltx_align_center" id="A4.2.2.11.5" style="padding-left:4.0pt;padding-right:4.0pt;">69.1</td>
</tr>
<tr class="ltx_tr" id="A4.2.2.12">
<td class="ltx_td ltx_align_left" id="A4.2.2.12.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="A4.2.2.12.1.1">Mamba</span></td>
<td class="ltx_td ltx_align_center" id="A4.2.2.12.2" style="padding-left:4.0pt;padding-right:4.0pt;">26.1</td>
<td class="ltx_td ltx_align_center" id="A4.2.2.12.3" style="padding-left:4.0pt;padding-right:4.0pt;">73.3</td>
<td class="ltx_td ltx_align_center" id="A4.2.2.12.4" style="padding-left:4.0pt;padding-right:4.0pt;">23.8</td>
<td class="ltx_td ltx_align_center" id="A4.2.2.12.5" style="padding-left:4.0pt;padding-right:4.0pt;">67.5</td>
</tr>
<tr class="ltx_tr" id="A4.2.2.13">
<td class="ltx_td ltx_align_left" id="A4.2.2.13.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="A4.2.2.13.1.1">Mamba-MHA</span></td>
<td class="ltx_td ltx_align_center" id="A4.2.2.13.2" style="padding-left:4.0pt;padding-right:4.0pt;">29.5</td>
<td class="ltx_td ltx_align_center" id="A4.2.2.13.3" style="padding-left:4.0pt;padding-right:4.0pt;">74.2</td>
<td class="ltx_td ltx_align_center" id="A4.2.2.13.4" style="padding-left:4.0pt;padding-right:4.0pt;">23.5</td>
<td class="ltx_td ltx_align_center" id="A4.2.2.13.5" style="padding-left:4.0pt;padding-right:4.0pt;">68.6</td>
</tr>
<tr class="ltx_tr" id="A4.2.2.14">
<td class="ltx_td ltx_align_left" id="A4.2.2.14.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="A4.2.2.14.1.1">Mamba Enc-Dec</span></td>
<td class="ltx_td ltx_align_center" id="A4.2.2.14.2" style="padding-left:4.0pt;padding-right:4.0pt;">27.3</td>
<td class="ltx_td ltx_align_center" id="A4.2.2.14.3" style="padding-left:4.0pt;padding-right:4.0pt;">73.8</td>
<td class="ltx_td ltx_align_center" id="A4.2.2.14.4" style="padding-left:4.0pt;padding-right:4.0pt;">29.1</td>
<td class="ltx_td ltx_align_center" id="A4.2.2.14.5" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="A4.2.2.14.5.1">71.0</span></td>
</tr>
<tr class="ltx_tr" id="A4.2.2.15">
<td class="ltx_td ltx_align_left" id="A4.2.2.15.1" style="padding-left:4.0pt;padding-right:4.0pt;">
<span class="ltx_ERROR undefined" id="A4.2.2.15.1.1">\cdashline</span>1-6[.4pt/2pt]

<span class="ltx_text" id="A4.2.2.15.1.2">Transformer Enc-Dec</span>
</td>
<td class="ltx_td ltx_align_center" id="A4.2.2.15.2" rowspan="5" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="A4.2.2.15.2.1">WMT23-CAT-10</span></td>
<td class="ltx_td ltx_align_center" id="A4.2.2.15.3" style="padding-left:4.0pt;padding-right:4.0pt;">28.3</td>
<td class="ltx_td ltx_align_center" id="A4.2.2.15.4" style="padding-left:4.0pt;padding-right:4.0pt;">69.6</td>
<td class="ltx_td ltx_align_center" id="A4.2.2.15.5" style="padding-left:4.0pt;padding-right:4.0pt;">29.3</td>
<td class="ltx_td ltx_align_center" id="A4.2.2.15.6" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="A4.2.2.15.6.1">70.3</span></td>
</tr>
<tr class="ltx_tr" id="A4.2.2.16">
<td class="ltx_td ltx_align_left" id="A4.2.2.16.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="A4.2.2.16.1.1">Transformer++</span></td>
<td class="ltx_td ltx_align_center" id="A4.2.2.16.2" style="padding-left:4.0pt;padding-right:4.0pt;">29.8</td>
<td class="ltx_td ltx_align_center" id="A4.2.2.16.3" style="padding-left:4.0pt;padding-right:4.0pt;">72.8</td>
<td class="ltx_td ltx_align_center" id="A4.2.2.16.4" style="padding-left:4.0pt;padding-right:4.0pt;">29.1</td>
<td class="ltx_td ltx_align_center" id="A4.2.2.16.5" style="padding-left:4.0pt;padding-right:4.0pt;">68.8</td>
</tr>
<tr class="ltx_tr" id="A4.2.2.17">
<td class="ltx_td ltx_align_left" id="A4.2.2.17.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="A4.2.2.17.1.1">Mamba</span></td>
<td class="ltx_td ltx_align_center" id="A4.2.2.17.2" style="padding-left:4.0pt;padding-right:4.0pt;">25.9</td>
<td class="ltx_td ltx_align_center" id="A4.2.2.17.3" style="padding-left:4.0pt;padding-right:4.0pt;">72.3</td>
<td class="ltx_td ltx_align_center" id="A4.2.2.17.4" style="padding-left:4.0pt;padding-right:4.0pt;">25.5</td>
<td class="ltx_td ltx_align_center" id="A4.2.2.17.5" style="padding-left:4.0pt;padding-right:4.0pt;">67.8</td>
</tr>
<tr class="ltx_tr" id="A4.2.2.18">
<td class="ltx_td ltx_align_left" id="A4.2.2.18.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="A4.2.2.18.1.1">Mamba-MHA</span></td>
<td class="ltx_td ltx_align_center" id="A4.2.2.18.2" style="padding-left:4.0pt;padding-right:4.0pt;">27.8</td>
<td class="ltx_td ltx_align_center" id="A4.2.2.18.3" style="padding-left:4.0pt;padding-right:4.0pt;">74.5</td>
<td class="ltx_td ltx_align_center" id="A4.2.2.18.4" style="padding-left:4.0pt;padding-right:4.0pt;">25.9</td>
<td class="ltx_td ltx_align_center" id="A4.2.2.18.5" style="padding-left:4.0pt;padding-right:4.0pt;">69.7</td>
</tr>
<tr class="ltx_tr" id="A4.2.2.19">
<td class="ltx_td ltx_align_left" id="A4.2.2.19.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="A4.2.2.19.1.1">Mamba Enc-Dec</span></td>
<td class="ltx_td ltx_align_center" id="A4.2.2.19.2" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="A4.2.2.19.2.1">31.4</span></td>
<td class="ltx_td ltx_align_center" id="A4.2.2.19.3" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="A4.2.2.19.3.1">75.6</span></td>
<td class="ltx_td ltx_align_center" id="A4.2.2.19.4" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="A4.2.2.19.4.1">30.1</span></td>
<td class="ltx_td ltx_align_center" id="A4.2.2.19.5" style="padding-left:4.0pt;padding-right:4.0pt;">70.1</td>
</tr>
<tr class="ltx_tr" id="A4.2.2.20">
<td class="ltx_td ltx_align_left ltx_border_t" id="A4.2.2.20.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_italic" id="A4.2.2.20.1.1">Finetuned</span></td>
<td class="ltx_td ltx_border_t" id="A4.2.2.20.2" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_border_t" id="A4.2.2.20.3" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_border_t" id="A4.2.2.20.4" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_border_t" id="A4.2.2.20.5" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_border_t" id="A4.2.2.20.6" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
</tr>
<tr class="ltx_tr" id="A4.2.2.21">
<td class="ltx_td ltx_align_left" id="A4.2.2.21.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="A4.2.2.21.1.1">Mamba-S</span></td>
<td class="ltx_td ltx_align_center" id="A4.2.2.21.2" rowspan="4" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="A4.2.2.21.2.1">WMT23-6M</span></td>
<td class="ltx_td ltx_align_center" id="A4.2.2.21.3" style="padding-left:4.0pt;padding-right:4.0pt;">21.8</td>
<td class="ltx_td ltx_align_center" id="A4.2.2.21.4" style="padding-left:4.0pt;padding-right:4.0pt;">77.2</td>
<td class="ltx_td ltx_align_center" id="A4.2.2.21.5" style="padding-left:4.0pt;padding-right:4.0pt;">21.4</td>
<td class="ltx_td ltx_align_center" id="A4.2.2.21.6" style="padding-left:4.0pt;padding-right:4.0pt;">72.4</td>
</tr>
<tr class="ltx_tr" id="A4.2.2.22">
<td class="ltx_td ltx_align_left" id="A4.2.2.22.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="A4.2.2.22.1.1">Pythia-S</span></td>
<td class="ltx_td ltx_align_center" id="A4.2.2.22.2" style="padding-left:4.0pt;padding-right:4.0pt;">23.9</td>
<td class="ltx_td ltx_align_center" id="A4.2.2.22.3" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="A4.2.2.22.3.1">77.4</span></td>
<td class="ltx_td ltx_align_center" id="A4.2.2.22.4" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="A4.2.2.22.4.1">25.9</span></td>
<td class="ltx_td ltx_align_center" id="A4.2.2.22.5" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="A4.2.2.22.5.1">76.7</span></td>
</tr>
<tr class="ltx_tr" id="A4.2.2.23">
<td class="ltx_td ltx_align_left" id="A4.2.2.23.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="A4.2.2.23.1.1">Mamba-M</span></td>
<td class="ltx_td ltx_align_center" id="A4.2.2.23.2" style="padding-left:4.0pt;padding-right:4.0pt;">20.7</td>
<td class="ltx_td ltx_align_center" id="A4.2.2.23.3" style="padding-left:4.0pt;padding-right:4.0pt;">74.6</td>
<td class="ltx_td ltx_align_center" id="A4.2.2.23.4" style="padding-left:4.0pt;padding-right:4.0pt;">22.5</td>
<td class="ltx_td ltx_align_center" id="A4.2.2.23.5" style="padding-left:4.0pt;padding-right:4.0pt;">73.4</td>
</tr>
<tr class="ltx_tr" id="A4.2.2.24">
<td class="ltx_td ltx_align_left" id="A4.2.2.24.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="A4.2.2.24.1.1">Pythia-M</span></td>
<td class="ltx_td ltx_align_center" id="A4.2.2.24.2" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="A4.2.2.24.2.1">26.0</span></td>
<td class="ltx_td ltx_align_center" id="A4.2.2.24.3" style="padding-left:4.0pt;padding-right:4.0pt;">76.2</td>
<td class="ltx_td ltx_align_center" id="A4.2.2.24.4" style="padding-left:4.0pt;padding-right:4.0pt;">25.2</td>
<td class="ltx_td ltx_align_center" id="A4.2.2.24.5" style="padding-left:4.0pt;padding-right:4.0pt;">75.8</td>
</tr>
<tr class="ltx_tr" id="A4.2.2.25">
<td class="ltx_td ltx_align_left" id="A4.2.2.25.1" style="padding-left:4.0pt;padding-right:4.0pt;">
<span class="ltx_ERROR undefined" id="A4.2.2.25.1.1">\cdashline</span>1-6[.4pt/2pt]

<span class="ltx_text" id="A4.2.2.25.1.2">Mamba-S</span>
</td>
<td class="ltx_td ltx_align_center" id="A4.2.2.25.2" rowspan="4" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="A4.2.2.25.2.1">WMT23-CAT-5</span></td>
<td class="ltx_td ltx_align_center" id="A4.2.2.25.3" style="padding-left:4.0pt;padding-right:4.0pt;">24.3</td>
<td class="ltx_td ltx_align_center" id="A4.2.2.25.4" style="padding-left:4.0pt;padding-right:4.0pt;">78.2</td>
<td class="ltx_td ltx_align_center" id="A4.2.2.25.5" style="padding-left:4.0pt;padding-right:4.0pt;">23.3</td>
<td class="ltx_td ltx_align_center" id="A4.2.2.25.6" style="padding-left:4.0pt;padding-right:4.0pt;">74.2</td>
</tr>
<tr class="ltx_tr" id="A4.2.2.26">
<td class="ltx_td ltx_align_left" id="A4.2.2.26.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="A4.2.2.26.1.1">Pythia-S</span></td>
<td class="ltx_td ltx_align_center" id="A4.2.2.26.2" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="A4.2.2.26.2.1">27.0</span></td>
<td class="ltx_td ltx_align_center" id="A4.2.2.26.3" style="padding-left:4.0pt;padding-right:4.0pt;">78.4</td>
<td class="ltx_td ltx_align_center" id="A4.2.2.26.4" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="A4.2.2.26.4.1">28.6</span></td>
<td class="ltx_td ltx_align_center" id="A4.2.2.26.5" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="A4.2.2.26.5.1">77.8</span></td>
</tr>
<tr class="ltx_tr" id="A4.2.2.27">
<td class="ltx_td ltx_align_left" id="A4.2.2.27.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="A4.2.2.27.1.1">Mamba-M</span></td>
<td class="ltx_td ltx_align_center" id="A4.2.2.27.2" style="padding-left:4.0pt;padding-right:4.0pt;">26.4</td>
<td class="ltx_td ltx_align_center" id="A4.2.2.27.3" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="A4.2.2.27.3.1">79.6</span></td>
<td class="ltx_td ltx_align_center" id="A4.2.2.27.4" style="padding-left:4.0pt;padding-right:4.0pt;">27.5</td>
<td class="ltx_td ltx_align_center" id="A4.2.2.27.5" style="padding-left:4.0pt;padding-right:4.0pt;">77.5</td>
</tr>
<tr class="ltx_tr" id="A4.2.2.28">
<td class="ltx_td ltx_align_left" id="A4.2.2.28.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="A4.2.2.28.1.1">Pythia-M</span></td>
<td class="ltx_td ltx_align_center" id="A4.2.2.28.2" style="padding-left:4.0pt;padding-right:4.0pt;">25.8</td>
<td class="ltx_td ltx_align_center" id="A4.2.2.28.3" style="padding-left:4.0pt;padding-right:4.0pt;">78.6</td>
<td class="ltx_td ltx_align_center" id="A4.2.2.28.4" style="padding-left:4.0pt;padding-right:4.0pt;">27.5</td>
<td class="ltx_td ltx_align_center" id="A4.2.2.28.5" style="padding-left:4.0pt;padding-right:4.0pt;">77.4</td>
</tr>
<tr class="ltx_tr" id="A4.2.2.29">
<td class="ltx_td ltx_align_left" id="A4.2.2.29.1" style="padding-left:4.0pt;padding-right:4.0pt;">
<span class="ltx_ERROR undefined" id="A4.2.2.29.1.1">\cdashline</span>1-6[.4pt/2pt]

<span class="ltx_text" id="A4.2.2.29.1.2">Mamba-S</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A4.2.2.29.2" rowspan="4" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="A4.2.2.29.2.1">WMT23-CAT-10</span></td>
<td class="ltx_td ltx_align_center" id="A4.2.2.29.3" style="padding-left:4.0pt;padding-right:4.0pt;">25.6</td>
<td class="ltx_td ltx_align_center" id="A4.2.2.29.4" style="padding-left:4.0pt;padding-right:4.0pt;">78.3</td>
<td class="ltx_td ltx_align_center" id="A4.2.2.29.5" style="padding-left:4.0pt;padding-right:4.0pt;">22.5</td>
<td class="ltx_td ltx_align_center" id="A4.2.2.29.6" style="padding-left:4.0pt;padding-right:4.0pt;">73.1</td>
</tr>
<tr class="ltx_tr" id="A4.2.2.30">
<td class="ltx_td ltx_align_left" id="A4.2.2.30.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="A4.2.2.30.1.1">Pythia-S</span></td>
<td class="ltx_td ltx_align_center" id="A4.2.2.30.2" style="padding-left:4.0pt;padding-right:4.0pt;">26.8</td>
<td class="ltx_td ltx_align_center" id="A4.2.2.30.3" style="padding-left:4.0pt;padding-right:4.0pt;">79.0</td>
<td class="ltx_td ltx_align_center" id="A4.2.2.30.4" style="padding-left:4.0pt;padding-right:4.0pt;">29.3</td>
<td class="ltx_td ltx_align_center" id="A4.2.2.30.5" style="padding-left:4.0pt;padding-right:4.0pt;">77.1</td>
</tr>
<tr class="ltx_tr" id="A4.2.2.31">
<td class="ltx_td ltx_align_left" id="A4.2.2.31.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="A4.2.2.31.1.1">Mamba-M</span></td>
<td class="ltx_td ltx_align_center" id="A4.2.2.31.2" style="padding-left:4.0pt;padding-right:4.0pt;">32.5</td>
<td class="ltx_td ltx_align_center" id="A4.2.2.31.3" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="A4.2.2.31.3.1">79.5</span></td>
<td class="ltx_td ltx_align_center" id="A4.2.2.31.4" style="padding-left:4.0pt;padding-right:4.0pt;">27.5</td>
<td class="ltx_td ltx_align_center" id="A4.2.2.31.5" style="padding-left:4.0pt;padding-right:4.0pt;">77.3</td>
</tr>
<tr class="ltx_tr" id="A4.2.2.32">
<td class="ltx_td ltx_align_left ltx_border_bb" id="A4.2.2.32.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="A4.2.2.32.1.1">Pythia-M</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A4.2.2.32.2" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="A4.2.2.32.2.1">33.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A4.2.2.32.3" style="padding-left:4.0pt;padding-right:4.0pt;">79.4</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A4.2.2.32.4" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="A4.2.2.32.4.1">33.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A4.2.2.32.5" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="A4.2.2.32.5.1">79.0</span></td>
</tr>
</table>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 8: </span>Paragraph-level results in terms of BLEU and COMET on the WMT23 <span class="ltx_text ltx_font_smallcaps" id="A4.4.4.1">en<math alttext="\leftrightarrow" class="ltx_Math" display="inline" id="A4.4.4.1.m1.1"><semantics id="A4.4.4.1.m1.1b"><mo id="A4.4.4.1.m1.1.1" stretchy="false" xref="A4.4.4.1.m1.1.1.cmml">↔</mo><annotation-xml encoding="MathML-Content" id="A4.4.4.1.m1.1c"><ci id="A4.4.4.1.m1.1.1.cmml" xref="A4.4.4.1.m1.1.1">↔</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.4.4.1.m1.1d">\leftrightarrow</annotation><annotation encoding="application/x-llamapun" id="A4.4.4.1.m1.1e">↔</annotation></semantics></math>de</span> test set.</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<section class="ltx_appendix ltx_figure_panel" id="A5">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix E </span>AI assistants</h2>
<div class="ltx_para" id="A5.p1">
<p class="ltx_p" id="A5.p1.1">We have used Github Copilot<span class="ltx_note ltx_role_footnote" id="footnote13"><sup class="ltx_note_mark">13</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">13</sup><span class="ltx_tag ltx_tag_note">13</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/features/copilot" title="">https://github.com/features/copilot</a></span></span></span> during code development, and ChatGPT<span class="ltx_note ltx_role_footnote" id="footnote14"><sup class="ltx_note_mark">14</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">14</sup><span class="ltx_tag ltx_tag_note">14</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://chat.openai.com/" title="">https://chat.openai.com/</a></span></span></span> during paper writing for paraphrasing or polishing original contents.</p>
</div>
</section>
</div>
</div>
</figure>
</section>
</section>
</section>
</section>
</div>
</div>
</figure>
</section>
</section>
</section>
</section>
</section>
</section>
</section>
</section>
</section>
</section>
</section>
</section>
</div>
</div>
</figure>
</section>
</section>
</section>
</section>
</div>
</div>
</figure>
</section>
</section>
</div>
</div>
</figure>
</section>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Sun Jul  7 20:14:59 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
