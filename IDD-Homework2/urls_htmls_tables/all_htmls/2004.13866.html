<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2004.13866] Deflating Dataset Bias Using Synthetic Data Augmentation</title><meta property="og:description" content="Deep Learning has seen an unprecedented increase in vision applications since the publication of large-scale object recognition datasets and introduction of scalable compute hardware. State-of-the-art methods for most …">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Deflating Dataset Bias Using Synthetic Data Augmentation">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Deflating Dataset Bias Using Synthetic Data Augmentation">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2004.13866">

<!--Generated on Sun Mar 17 06:23:23 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Deflating Dataset Bias Using Synthetic Data Augmentation</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Nikita Jaipuria, Xianling Zhang, Rohan Bhasin, Mayar Arafa 
<br class="ltx_break">Punarjay Chakravarty, Shubham Shrivastava, Sagar Manglani, Vidya N. Murali
<br class="ltx_break">Ford Greenfield Labs, Palo Alto
<br class="ltx_break"><span id="id1.1.id1" class="ltx_text ltx_font_typewriter" style="font-size:80%;">{njaipuri, xzhan258, rbhasin, marafa, pchakra5, sshriva5, smanglan, vnariyam}@ford.com</span>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id2.id1" class="ltx_p">Deep Learning has seen an unprecedented increase in vision applications since the publication of large-scale object recognition datasets and introduction of scalable compute hardware. State-of-the-art methods for most vision tasks for Autonomous Vehicles (AVs) rely on supervised learning and often fail to generalize to domain shifts and/or outliers. Dataset diversity is thus key to successful real-world deployment. No matter how big the size of the dataset, capturing long tails of the distribution pertaining to task-specific environmental factors is impractical. The goal of this paper is to investigate the use of targeted synthetic data augmentation - combining the benefits of gaming engine simulations and sim2real style transfer techniques - for filling gaps in real datasets for vision tasks. Empirical studies on three different computer vision tasks of practical use to AVs - parking slot detection, lane detection and monocular depth estimation - consistently show that having synthetic data in the training mix provides a significant boost in cross-dataset generalization performance as compared to training on real data only, for the same size of the training set.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Data-hungry Deep Neural Networks (DNNs) thrive when trained on large datasets. The release of large-scale datasets (such as ImageNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>, COCO <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>, KITTI <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> and the relatively recent BDD100K <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite>) coupled with progress in scalable compute has led to the use of DNNs for a wide variety of vision tasks for autonomous driving. State-of-the-art methods for most of these tasks, such as object detection, semantic segmentation and depth estimation to name a few <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>, rely on supervised learning and often fail to generalize to unseen scenarios and/or datasets. Thus, dataset diversity is key to achieving successful deployment of DNNs for real-world vision tasks, especially in safety-critical applications.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Presence of bias in static datasets, such as selection bias, capture bias, label bias and negative set bias <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>, <a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite> is a known problem in computer vision famously shown by the <em id="S1.p2.1.1" class="ltx_emph ltx_font_italic">Name That Dataset</em> experiment from Torralba <em id="S1.p2.1.2" class="ltx_emph ltx_font_italic">et al</em>.<span id="S1.p2.1.3" class="ltx_text"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>.
However, most of these well studied biases are task-agnostic and too general in nature.
For instance, consider the task of lane detection which is one of the most common vision applications in autonomous driving. One way of addressing generic dataset selection biases is to simply augment data from multiple sources like highways, cities etc. But no matter how big the size of the dataset, it is extremely difficult to capture long tails of the distribution, and on the contrary, as shown in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>, <a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>, mixing different datasets often ends up hurting the final performance!
This begs the question if it is ever possible to completely avoid such biases in realistic settings by means of careful data collection <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>.</p>
</div>
<figure id="S1.F1" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2004.13866/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" width="184" height="186" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2004.13866/assets/x2.png" id="S1.F1.g2" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="240" height="187" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.3.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S1.F1.4.2" class="ltx_text" style="font-size:90%;">Comparison of confusion matrices from the ResNet-50 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> based <em id="S1.F1.4.2.1" class="ltx_emph ltx_font_italic">Name That Dataset</em> classifiers described in Section <a href="#S3.SS1" title="3.1 Revisiting “Name That Dataset” ‣ 3 Deflating Dataset Bias ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a> trained to distinguish between five different lane-detection datasets (left) and between the same five datasets with two of them (3 and 5) augmented with synthetic data (right). Note that synthetic data augmentation helps diffuse the strength of the diagonal indicating deflated dataset bias.</span></figcaption>
</figure>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">In this work, we focus on bias in the context of the noise distribution pertaining to task-specific environmental factors. We refer to it as <em id="S1.p3.1.1" class="ltx_emph ltx_font_italic">noise factor distribution bias</em>. For instance, instead of handling diversity by blindly collecting more data in our lane detection example, we chose to augment data with respect to task-specific noise factors, such as diversifying lane marker types, number of lanes in the scene, condition of lane markers, type of lane markers, weather and lighting effects etc. We show how this could go a long-way in improving algorithm performance. Hoping to obtain such targeted diversity in real data from dashboard cameras in cars is likely futile because of the time it will take and the unavailability of sources.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">One approach is to leverage advances in generative modeling to generate synthetic data for augmentation. Generative Adversarial Networks (GANs) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> have shown immense progress in the past few years in image generation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>. While they have had huge success in graphics applications <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>, <a href="#bib.bib38" title="" class="ltx_ref">38</a>, <a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>, synthetic data augmentation for improving performance of recognition models has seen limited success. One reason is the presence of noisy artifacts and semantic inconsistencies in the generated images <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>. Alternatively, gaming-engine simulations can be used to generate semantically consistent data of desired task-specific scenarios, but the perceptual quality is far from realistic.Why not have the best of both worlds? In contrast to performing augmentation with either generated or simulated data, we first simply simulate candidate examples and then translate via unsupervised sim2real generative models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a>, <a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite>.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">We show that this simple two-stage augmentation when targeted to encourage task-specific noise diversity leads to huge gains in cross-dataset generalization performance. We demonstrate this empirically using three different case studies of computer vision tasks in an AV perception stack: (i) parking slot detection; (ii) lane detection; and (iii) monocular depth estimation. To isolate the effect of simply training on more data, in all of these tasks, synthetic data was used to replace some amount of real data in the training set. Results showed a significant boost in cross-dataset generalization performance, especially in cases where the real dataset was small in size and heavily biased. Moreover, model performance on the original test set was not hurt which further confirms that targeted synthetic data augmentation can go a long way in enriching the real biased dataset.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">Related work on dealing with dataset bias falls under two main categories: (i) Domain Adaptation (DA); and (ii) Transfer Learning. DA is one way of dealing with inherent bias in datasets and the problem of perception algorithms failing to generalize to different datasets. Fernando <em id="S2.p1.1.1" class="ltx_emph ltx_font_italic">et al</em>.<span id="S2.p1.1.2" class="ltx_text"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> addressed DA by learning a mapping between the source and target datasets in the form of a common subspace between their distributions. One can also learn data specific embeddings subject to minimization of MMD between them <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite> in an effort to bring the two distributions closer. A classifier can then act on the learnt embeddings. Optimal transport techniques have also been used to solve DA, with <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> minimizing the Wasserstein distance between the joint embedding and classifier label distributions of the two datasets. Wang <em id="S2.p1.1.3" class="ltx_emph ltx_font_italic">et al</em>.<span id="S2.p1.1.4" class="ltx_text"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite> provide a good taxonomy of DA techniques, including the more recent adversarial techniques based on GANs. Instead of relying on a hand-engineered loss function to bring the source and target data distributions close, these techniques use an adversarially trained discriminator network that attempts to differentiate between data from the two distributions. This discrimination can happen in: (i) the pixel space - where data from one domain is translated into the other using style transfer before being passed to the discriminator <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>, <a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>; (ii) latent space - where a discriminator learns to differentiate between the learned embeddings from the two domains <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite> and; (ii) both the pixel and embedding space <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>. In cases where one has access to unpaired and unannotated data only from the two domains, one can use cycle consistency losses <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>, <a href="#bib.bib42" title="" class="ltx_ref">42</a>, <a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite> for learning a common embedding between the two spaces. Often, we are concerned with DA for a particular task - for example image segmentation or depth estimation. Recent work has shown that using losses from an auxiliary task like image segmentation can help regularize the feature embeddings <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>. These methods are most relevant to our work and future work will investigate how they fare against our approach of targeted synthetic data augmentation.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">Transfer Learning is another way of dealing with dataset bias <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>. In contrast to such approaches, our method assumes no training data is available from the target domain (both for the task network and sim2real models), and that the target task is the same as the source task. Recent work <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> has also focused on using synthetic data to augment real datasets for AV perception tasks. Meta-sim <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> parameterizes scene-grammar to generate a synthetic data distribution that is similar to real data and is optimized for a down-stream task and Alhaija <em id="S2.p2.1.1" class="ltx_emph ltx_font_italic">et al</em>.<span id="S2.p2.1.2" class="ltx_text"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> augment real scene backgrounds with synthetically inserted objects for improved instance segmentation and object detection performance on real datasets. Our method, in contrast, investigates a general purpose, task agnostic approach to enriching real-world datasets using synthetic data.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Deflating Dataset Bias</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">The main objective of this paper is to test the hypothesis that targeted synthetic data augmentation can help deflate inherent bias in large-scale image datasets. For brevity, we will refer to this hypothesis as <span id="S3.p1.1.1" class="ltx_text ltx_font_typewriter">H</span>. One way of testing <span id="S3.p1.1.2" class="ltx_text ltx_font_typewriter">H</span> is to compare cross-dataset generalization performance of models trained on the original dataset (real) with models trained on augmented datasets (<math id="S3.p1.1.m1.1" class="ltx_Math" alttext="\text{real}+\text{synthetic}" display="inline"><semantics id="S3.p1.1.m1.1a"><mrow id="S3.p1.1.m1.1.1" xref="S3.p1.1.m1.1.1.cmml"><mtext id="S3.p1.1.m1.1.1.2" xref="S3.p1.1.m1.1.1.2a.cmml">real</mtext><mo id="S3.p1.1.m1.1.1.1" xref="S3.p1.1.m1.1.1.1.cmml">+</mo><mtext id="S3.p1.1.m1.1.1.3" xref="S3.p1.1.m1.1.1.3a.cmml">synthetic</mtext></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.1.m1.1b"><apply id="S3.p1.1.m1.1.1.cmml" xref="S3.p1.1.m1.1.1"><plus id="S3.p1.1.m1.1.1.1.cmml" xref="S3.p1.1.m1.1.1.1"></plus><ci id="S3.p1.1.m1.1.1.2a.cmml" xref="S3.p1.1.m1.1.1.2"><mtext id="S3.p1.1.m1.1.1.2.cmml" xref="S3.p1.1.m1.1.1.2">real</mtext></ci><ci id="S3.p1.1.m1.1.1.3a.cmml" xref="S3.p1.1.m1.1.1.3"><mtext id="S3.p1.1.m1.1.1.3.cmml" xref="S3.p1.1.m1.1.1.3">synthetic</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.1.m1.1c">\text{real}+\text{synthetic}</annotation></semantics></math>). In this paper, three supervised learning-based computer vision tasks: (i) parking slot detection; (ii) traffic lane detection; and (iii) monocular depth estimation are used as test-beds for the motivating hypothesis <span id="S3.p1.1.3" class="ltx_text ltx_font_typewriter">H</span>, using the following methodology:</p>
<ol id="S3.I1" class="ltx_enumerate">
<li id="S3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S3.I1.i1.p1" class="ltx_para">
<p id="S3.I1.i1.p1.1" class="ltx_p">Simulate images and corresponding annotation using gaming engines for a diverse set of task-specific noise factors.</p>
</div>
</li>
<li id="S3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S3.I1.i2.p1" class="ltx_para">
<p id="S3.I1.i2.p1.1" class="ltx_p">Use unsupervised generative modeling based sim2real methods such as <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a>, <a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite> to translate the simulated images into photorealistic ones, that look like they are from the training domain.</p>
</div>
</li>
<li id="S3.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S3.I1.i3.p1" class="ltx_para">
<p id="S3.I1.i3.p1.1" class="ltx_p">Train task networks with different ratios of real and simulated data (from Step 1) or real and sim2real data (from Step 2). The size of the training set is kept constant across all experiments to isolate the improvement one can obtain by simply training on more data from the improvement due to deflated dataset bias. Also, the ratio of synthetic data in the training set was increased from 0% to 100% in continuous intervals of 10%.</p>
</div>
</li>
<li id="S3.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span> 
<div id="S3.I1.i4.p1" class="ltx_para">
<p id="S3.I1.i4.p1.1" class="ltx_p">Evaluate and compare cross-dataset generalization performance of all models from Step 3.</p>
</div>
</li>
</ol>
<p id="S3.p1.2" class="ltx_p">Sections <a href="#S4" title="4 Case Study: Parking Slot Detection ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, <a href="#S5" title="5 Case Study: Traffic Lane Detection ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> and <a href="#S6" title="6 Case Study: Monocular Depth Estimation ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> describe the task-specific datasets, experiments and results.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Revisiting “Name That Dataset”</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.2" class="ltx_p">Torralba <em id="S3.SS1.p1.2.1" class="ltx_emph ltx_font_italic">et al</em>.<span id="S3.SS1.p1.2.2" class="ltx_text"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite> investigated the then state of object recognition datasets using the <em id="S3.SS1.p1.2.3" class="ltx_emph ltx_font_italic">Name That Dataset</em> experiment in which a 12-way linear SVM classifier was trained to distinguish between 12 datasets. The results showed strong <em id="S3.SS1.p1.2.4" class="ltx_emph ltx_font_italic">signatures</em> for each dataset - indicating inherent <em id="S3.SS1.p1.2.5" class="ltx_emph ltx_font_italic">bias</em> - despite the best efforts of their creators. We repeat the <em id="S3.SS1.p1.2.6" class="ltx_emph ltx_font_italic">Name That Dataset</em> experiment in the era of deep learning with a ResNet-50 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> (pre-trained on ImageNet) trained to distinguish between five different lane-detection datasets - ApolloScape <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>, BDD100K <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite>, CULane <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>, Mapillary <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite> and TuSimple<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a target="_blank" href="https://github.com/TuSimple/tusimple-benchmark/tree/master/doc/lane_detection" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/TuSimple/tusimple-benchmark/tree/master/doc/lane_detection</a></span></span></span>. <math id="S3.SS1.p1.1.m1.1" class="ltx_Math" alttext="6000" display="inline"><semantics id="S3.SS1.p1.1.m1.1a"><mn id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">6000</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><cn type="integer" id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">6000</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">6000</annotation></semantics></math> images were randomly selected from each dataset and divided into training, validation and test sets. In a subsequent experiment, we replace <math id="S3.SS1.p1.2.m2.1" class="ltx_Math" alttext="50\%" display="inline"><semantics id="S3.SS1.p1.2.m2.1a"><mrow id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml"><mn id="S3.SS1.p1.2.m2.1.1.2" xref="S3.SS1.p1.2.m2.1.1.2.cmml">50</mn><mo id="S3.SS1.p1.2.m2.1.1.1" xref="S3.SS1.p1.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><apply id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1"><csymbol cd="latexml" id="S3.SS1.p1.2.m2.1.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1.1">percent</csymbol><cn type="integer" id="S3.SS1.p1.2.m2.1.1.2.cmml" xref="S3.SS1.p1.2.m2.1.1.2">50</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">50\%</annotation></semantics></math> of the real data in two datasets - CULane and TuSimple - with sim2real translated images from VAE-GAN models based off of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> and trained on unpaired simulated and real CULane and simulated and real TuSimple images respectively. We chose to apply data augmentation to only these two datasets as they are also used for the lane detection experiments in Section <a href="#S5" title="5 Case Study: Traffic Lane Detection ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> with readily available sim2real data on hand. Fig. <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> compares the confusion matrices of the two classifiers, with and without synthetic data augmentation. Here, the labels 1, 2, 3, 4 and 5 denote the ApolloScape, BDD100K, CULane, Mapillary and TuSimple datasets respectively. Consistent with the motivating hypothesis <span id="S3.SS1.p1.2.7" class="ltx_text ltx_font_typewriter">H</span>, synthetic data augmentation diffuses the strength of the diagonal indicating deflated dataset bias.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Case Study: Parking Slot Detection</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">The objective of this task is to detect empty parking slots in images taken from side vehicle cameras (see Fig. <a href="#S4.F2" title="Figure 2 ‣ 4 Case Study: Parking Slot Detection ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>).</p>
</div>
<figure id="S4.F2" class="ltx_figure"><img src="/html/2004.13866/assets/figs/slot/slot_detection.png" id="S4.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="509" height="184" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F2.2.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S4.F2.3.2" class="ltx_text" style="font-size:90%;">Illustrative example of empty parking slots detected (right) in a parking lot image (left).</span></figcaption>
</figure>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Dataset Description</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.2" class="ltx_p"><span id="S4.SS1.p1.2.1" class="ltx_text ltx_font_bold">Real Data:</span> An internal parking dataset of bright daytime scenarios from two different parking lots (in Dearborn and Palo Alto) is used as the source of real data for this task. The Dearborn dataset has a total of <math id="S4.SS1.p1.1.m1.1" class="ltx_Math" alttext="5907" display="inline"><semantics id="S4.SS1.p1.1.m1.1a"><mn id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml">5907</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><cn type="integer" id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1">5907</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">5907</annotation></semantics></math> images, for brevity, we will refer to this dataset as <em id="S4.SS1.p1.2.2" class="ltx_emph ltx_font_italic">Parking A</em>. The Palo Alto dataset has <math id="S4.SS1.p1.2.m2.1" class="ltx_Math" alttext="602" display="inline"><semantics id="S4.SS1.p1.2.m2.1a"><mn id="S4.SS1.p1.2.m2.1.1" xref="S4.SS1.p1.2.m2.1.1.cmml">602</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.2.m2.1b"><cn type="integer" id="S4.SS1.p1.2.m2.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1">602</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.2.m2.1c">602</annotation></semantics></math> images. We will refer to this dataset as <em id="S4.SS1.p1.2.3" class="ltx_emph ltx_font_italic">Parking B.</em> Fig. <a href="#S4.F3.sf1" title="In Figure 3 ‣ 4.1 Dataset Description ‣ 4 Case Study: Parking Slot Detection ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3(a)</span></a> and Fig. <a href="#S4.F3.sf2" title="In Figure 3 ‣ 4.1 Dataset Description ‣ 4 Case Study: Parking Slot Detection ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3(b)</span></a> show example images from the Parking A and Parking B datasets respectively to further motivate the large domain gap between them.

<br class="ltx_break"><span id="S4.SS1.p1.2.4" class="ltx_text ltx_font_bold">Synthetic Data:</span> Simulated data for this task is generated using an Unreal Engine<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a target="_blank" href="https://www.unrealengine.com/en-US/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.unrealengine.com/en-US/</a></span></span></span>-based simulation pipeline for a diverse set of noise factors such as different times of the day, cloud density, shadow intensity/cast location, ground textures, parking line damage levels and parking density. The variety of shadow intensities and locations, along with parking line damage and car density are in stark contrast to the homogeneity of the parking A dataset. Fig. <a href="#S4.F3.sf3" title="In Figure 3 ‣ 4.1 Dataset Description ‣ 4 Case Study: Parking Slot Detection ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3(c)</span></a> shows an example simulated image, visualizing the large domain gap between the simulated and real data from parking A. A sim2real VAE-GAN model (based on <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>) trained on unpaired simulated images and real images from the Parking A dataset is used to translate the generated simulated data to look photorealistic. Fig. <a href="#S4.F3.sf4" title="In Figure 3 ‣ 4.1 Dataset Description ‣ 4 Case Study: Parking Slot Detection ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3(d)</span></a> shows the sim2real translated output for Fig. <a href="#S4.F3.sf3" title="In Figure 3 ‣ 4.1 Dataset Description ‣ 4 Case Study: Parking Slot Detection ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3(c)</span></a>. Note the realistic ground textures and lighting effects in Fig. <a href="#S4.F3.sf4" title="In Figure 3 ‣ 4.1 Dataset Description ‣ 4 Case Study: Parking Slot Detection ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3(d)</span></a> in contrast to Fig. <a href="#S4.F3.sf3" title="In Figure 3 ‣ 4.1 Dataset Description ‣ 4 Case Study: Parking Slot Detection ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3(c)</span></a>.</p>
</div>
<figure id="S4.F3" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F3.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2004.13866/assets/figs/slot/dearborn.png" id="S4.F3.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="151" height="90" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F3.sf1.3.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S4.F3.sf1.4.2" class="ltx_text" style="font-size:90%;">Real - Parking A</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F3.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2004.13866/assets/x3.png" id="S4.F3.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="110" height="69" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F3.sf2.3.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S4.F3.sf2.4.2" class="ltx_text" style="font-size:90%;">Real - Parking B</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F3.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2004.13866/assets/x4.png" id="S4.F3.sf3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="113" height="71" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F3.sf3.3.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="S4.F3.sf3.4.2" class="ltx_text" style="font-size:90%;">Simulated</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F3.sf4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2004.13866/assets/x5.png" id="S4.F3.sf4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="113" height="71" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F3.sf4.3.1.1" class="ltx_text" style="font-size:90%;">(d)</span> </span><span id="S4.F3.sf4.4.2" class="ltx_text" style="font-size:90%;">Sim2Real Translated</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F3.2.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S4.F3.3.2" class="ltx_text" style="font-size:90%;">Example images from the real and synthetic data used for the slot detection experiments.</span></figcaption>
</figure>
<figure id="S4.F4" class="ltx_figure"><img src="/html/2004.13866/assets/x6.png" id="S4.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="392" height="231" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F4.2.1.1" class="ltx_text" style="font-size:90%;">Figure 4</span>: </span><span id="S4.F4.3.2" class="ltx_text" style="font-size:90%;">Plot of F-measure for slot detection models trained on a mix of real (Parking A) and synthetic images (either from simulation or from sim2real GAN) and tested on real Parking B images. As you move from left to right, the ratio of synthetic data in the training set increases.</span></figcaption>
</figure>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.3" class="ltx_p">For the slot detection experiments in this paper, MobileNetV2 SSD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>, <a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>, pre-trained on COCO <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>, was trained and tested on <math id="S4.SS1.p2.1.m1.1" class="ltx_Math" alttext="300\times 300" display="inline"><semantics id="S4.SS1.p2.1.m1.1a"><mrow id="S4.SS1.p2.1.m1.1.1" xref="S4.SS1.p2.1.m1.1.1.cmml"><mn id="S4.SS1.p2.1.m1.1.1.2" xref="S4.SS1.p2.1.m1.1.1.2.cmml">300</mn><mo lspace="0.222em" rspace="0.222em" id="S4.SS1.p2.1.m1.1.1.1" xref="S4.SS1.p2.1.m1.1.1.1.cmml">×</mo><mn id="S4.SS1.p2.1.m1.1.1.3" xref="S4.SS1.p2.1.m1.1.1.3.cmml">300</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.1.m1.1b"><apply id="S4.SS1.p2.1.m1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1"><times id="S4.SS1.p2.1.m1.1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1.1"></times><cn type="integer" id="S4.SS1.p2.1.m1.1.1.2.cmml" xref="S4.SS1.p2.1.m1.1.1.2">300</cn><cn type="integer" id="S4.SS1.p2.1.m1.1.1.3.cmml" xref="S4.SS1.p2.1.m1.1.1.3">300</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.1.m1.1c">300\times 300</annotation></semantics></math> parking lot images to detect open parking slots, as shown in Fig. <a href="#S4.F2" title="Figure 2 ‣ 4 Case Study: Parking Slot Detection ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. The Parking A dataset was split into a train and test set with <math id="S4.SS1.p2.2.m2.1" class="ltx_Math" alttext="3545" display="inline"><semantics id="S4.SS1.p2.2.m2.1a"><mn id="S4.SS1.p2.2.m2.1.1" xref="S4.SS1.p2.2.m2.1.1.cmml">3545</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.2.m2.1b"><cn type="integer" id="S4.SS1.p2.2.m2.1.1.cmml" xref="S4.SS1.p2.2.m2.1.1">3545</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.2.m2.1c">3545</annotation></semantics></math> images and <math id="S4.SS1.p2.3.m3.1" class="ltx_Math" alttext="2362" display="inline"><semantics id="S4.SS1.p2.3.m3.1a"><mn id="S4.SS1.p2.3.m3.1.1" xref="S4.SS1.p2.3.m3.1.1.cmml">2362</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.3.m3.1b"><cn type="integer" id="S4.SS1.p2.3.m3.1.1.cmml" xref="S4.SS1.p2.3.m3.1.1">2362</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.3.m3.1c">2362</annotation></semantics></math> images respectively. Given the small size of the Parking B dataset (602 images), it was used for testing only. Intersection over Union (IoU) of detected slots with ground truth empty slots is used as the metric for quantitative evaluation. Post training, model checkpoint with the best F-measure for 50% IoU on the Parking A test set is used for inference. The rest of this section describes the experiments performed to test our motivating hypothesis <span id="S4.SS1.p2.3.1" class="ltx_text ltx_font_typewriter">H</span>.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Results</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">Fig. <a href="#S4.F4" title="Figure 4 ‣ 4.1 Dataset Description ‣ 4 Case Study: Parking Slot Detection ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> shows the results of all slot detection models on the Parking B test set. Notice models trained on a mix of real and synthetic data (green and blue) significantly outperform the model trained on real data only (yellow). Moreover, across all ratios, models trained on a mix of real Parking A images and sim2real translated images (blue) do better than the models trained on a mix of real Parking A images and corresponding simulated images from Unreal Engine (green). Overall best performance (F-measure of 32.4%) is achieved by the model trained on a mix of real and GAN data in a 50:50 ratio. Table <a href="#S4.T1" title="Table 1 ‣ 4.2 Results ‣ 4 Case Study: Parking Slot Detection ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> summarizes the results from the plots in Fig. <a href="#S4.F4" title="Figure 4 ‣ 4.1 Dataset Description ‣ 4 Case Study: Parking Slot Detection ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. For the synthetic data augmentation experiments, results are shown for the best model in terms of F-measure on cross-dataset testing. Additional insights into the number of true positives and false positives for cross-dataset testing with the models from Table <a href="#S4.T1" title="Table 1 ‣ 4.2 Results ‣ 4 Case Study: Parking Slot Detection ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> are provided in the Supplementary Material.</p>
</div>
<figure id="S4.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table"><span id="S4.T1.12.1.1" class="ltx_text" style="font-size:113%;">Table 1</span>: </span><span id="S4.T1.13.2" class="ltx_text" style="font-size:113%;">Summary of results in Fig. <a href="#S4.F4" title="Figure 4 ‣ 4.1 Dataset Description ‣ 4 Case Study: Parking Slot Detection ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. Here, A and B denote the Parking A and Parking B datasets. S denotes simulated images and G denotes the sim2real translated equivalent of S. For synthetic data augmentation rows, results are shown for the best model in terms of F-measure on cross-dataset testing in green for A + S and in blue for A + G.</span></figcaption>
<table id="S4.T1.7" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T1.3.3" class="ltx_tr">
<th id="S4.T1.3.3.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_tt"><span id="S4.T1.3.3.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Train</span></th>
<th id="S4.T1.3.3.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt"><span id="S4.T1.3.3.5.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Test</span></th>
<th id="S4.T1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt">
<span id="S4.T1.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Precision</span><span id="S4.T1.1.1.1.2" class="ltx_text" style="font-size:80%;"> (</span><math id="S4.T1.1.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T1.1.1.1.m1.1a"><mo mathsize="80%" stretchy="false" id="S4.T1.1.1.1.m1.1.1" xref="S4.T1.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T1.1.1.1.m1.1b"><ci id="S4.T1.1.1.1.m1.1.1.cmml" xref="S4.T1.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.1.1.1.m1.1c">\uparrow</annotation></semantics></math><span id="S4.T1.1.1.1.3" class="ltx_text" style="font-size:80%;">)</span>
</th>
<th id="S4.T1.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt">
<span id="S4.T1.2.2.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Recall</span><span id="S4.T1.2.2.2.2" class="ltx_text" style="font-size:80%;"> (</span><math id="S4.T1.2.2.2.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T1.2.2.2.m1.1a"><mo mathsize="80%" stretchy="false" id="S4.T1.2.2.2.m1.1.1" xref="S4.T1.2.2.2.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T1.2.2.2.m1.1b"><ci id="S4.T1.2.2.2.m1.1.1.cmml" xref="S4.T1.2.2.2.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.2.2.2.m1.1c">\uparrow</annotation></semantics></math><span id="S4.T1.2.2.2.3" class="ltx_text" style="font-size:80%;">)</span>
</th>
<th id="S4.T1.3.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt">
<span id="S4.T1.3.3.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">F-Measure</span><span id="S4.T1.3.3.3.2" class="ltx_text" style="font-size:80%;"> (</span><math id="S4.T1.3.3.3.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T1.3.3.3.m1.1a"><mo mathsize="80%" stretchy="false" id="S4.T1.3.3.3.m1.1.1" xref="S4.T1.3.3.3.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T1.3.3.3.m1.1b"><ci id="S4.T1.3.3.3.m1.1.1.cmml" xref="S4.T1.3.3.3.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.3.3.3.m1.1c">\uparrow</annotation></semantics></math><span id="S4.T1.3.3.3.3" class="ltx_text" style="font-size:80%;">)</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T1.7.8.1" class="ltx_tr">
<th id="S4.T1.7.8.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="S4.T1.7.8.1.1.1" class="ltx_text" style="font-size:80%;">A</span></th>
<td id="S4.T1.7.8.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.7.8.1.2.1" class="ltx_text" style="font-size:80%;">A</span></td>
<td id="S4.T1.7.8.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.7.8.1.3.1" class="ltx_text" style="font-size:80%;">95.1%</span></td>
<td id="S4.T1.7.8.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.7.8.1.4.1" class="ltx_text" style="font-size:80%;">87.9%</span></td>
<td id="S4.T1.7.8.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.7.8.1.5.1" class="ltx_text" style="font-size:80%;">91.4%</span></td>
</tr>
<tr id="S4.T1.4.4" class="ltx_tr">
<th id="S4.T1.4.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r"><math id="S4.T1.4.4.1.m1.1" class="ltx_Math" alttext="\text{A}+\text{S}\ (40\%)" display="inline"><semantics id="S4.T1.4.4.1.m1.1a"><mrow id="S4.T1.4.4.1.m1.1.1" xref="S4.T1.4.4.1.m1.1.1.cmml"><mtext mathsize="80%" id="S4.T1.4.4.1.m1.1.1.3" xref="S4.T1.4.4.1.m1.1.1.3a.cmml">A</mtext><mo mathsize="80%" id="S4.T1.4.4.1.m1.1.1.2" xref="S4.T1.4.4.1.m1.1.1.2.cmml">+</mo><mrow id="S4.T1.4.4.1.m1.1.1.1" xref="S4.T1.4.4.1.m1.1.1.1.cmml"><mtext mathsize="80%" id="S4.T1.4.4.1.m1.1.1.1.3" xref="S4.T1.4.4.1.m1.1.1.1.3a.cmml">S</mtext><mo lspace="0.400em" rspace="0em" id="S4.T1.4.4.1.m1.1.1.1.2" xref="S4.T1.4.4.1.m1.1.1.1.2.cmml">​</mo><mrow id="S4.T1.4.4.1.m1.1.1.1.1.1" xref="S4.T1.4.4.1.m1.1.1.1.1.1.1.cmml"><mo maxsize="80%" minsize="80%" id="S4.T1.4.4.1.m1.1.1.1.1.1.2" xref="S4.T1.4.4.1.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.T1.4.4.1.m1.1.1.1.1.1.1" xref="S4.T1.4.4.1.m1.1.1.1.1.1.1.cmml"><mn mathsize="80%" id="S4.T1.4.4.1.m1.1.1.1.1.1.1.2" xref="S4.T1.4.4.1.m1.1.1.1.1.1.1.2.cmml">40</mn><mo mathsize="80%" id="S4.T1.4.4.1.m1.1.1.1.1.1.1.1" xref="S4.T1.4.4.1.m1.1.1.1.1.1.1.1.cmml">%</mo></mrow><mo maxsize="80%" minsize="80%" id="S4.T1.4.4.1.m1.1.1.1.1.1.3" xref="S4.T1.4.4.1.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.4.4.1.m1.1b"><apply id="S4.T1.4.4.1.m1.1.1.cmml" xref="S4.T1.4.4.1.m1.1.1"><plus id="S4.T1.4.4.1.m1.1.1.2.cmml" xref="S4.T1.4.4.1.m1.1.1.2"></plus><ci id="S4.T1.4.4.1.m1.1.1.3a.cmml" xref="S4.T1.4.4.1.m1.1.1.3"><mtext mathsize="80%" id="S4.T1.4.4.1.m1.1.1.3.cmml" xref="S4.T1.4.4.1.m1.1.1.3">A</mtext></ci><apply id="S4.T1.4.4.1.m1.1.1.1.cmml" xref="S4.T1.4.4.1.m1.1.1.1"><times id="S4.T1.4.4.1.m1.1.1.1.2.cmml" xref="S4.T1.4.4.1.m1.1.1.1.2"></times><ci id="S4.T1.4.4.1.m1.1.1.1.3a.cmml" xref="S4.T1.4.4.1.m1.1.1.1.3"><mtext mathsize="80%" id="S4.T1.4.4.1.m1.1.1.1.3.cmml" xref="S4.T1.4.4.1.m1.1.1.1.3">S</mtext></ci><apply id="S4.T1.4.4.1.m1.1.1.1.1.1.1.cmml" xref="S4.T1.4.4.1.m1.1.1.1.1.1"><csymbol cd="latexml" id="S4.T1.4.4.1.m1.1.1.1.1.1.1.1.cmml" xref="S4.T1.4.4.1.m1.1.1.1.1.1.1.1">percent</csymbol><cn type="integer" id="S4.T1.4.4.1.m1.1.1.1.1.1.1.2.cmml" xref="S4.T1.4.4.1.m1.1.1.1.1.1.1.2">40</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.4.4.1.m1.1c">\text{A}+\text{S}\ (40\%)</annotation></semantics></math></th>
<td id="S4.T1.4.4.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.4.4.2.1" class="ltx_text" style="font-size:80%;">A</span></td>
<td id="S4.T1.4.4.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.4.4.3.1" class="ltx_text" style="font-size:80%;">93.8%</span></td>
<td id="S4.T1.4.4.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.4.4.4.1" class="ltx_text" style="font-size:80%;">87.7%</span></td>
<td id="S4.T1.4.4.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.4.4.5.1" class="ltx_text" style="font-size:80%;">90.7%</span></td>
</tr>
<tr id="S4.T1.5.5" class="ltx_tr">
<th id="S4.T1.5.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r"><math id="S4.T1.5.5.1.m1.1" class="ltx_Math" alttext="\text{A}+\text{G}\ (50\%)" display="inline"><semantics id="S4.T1.5.5.1.m1.1a"><mrow id="S4.T1.5.5.1.m1.1.1" xref="S4.T1.5.5.1.m1.1.1.cmml"><mtext mathsize="80%" id="S4.T1.5.5.1.m1.1.1.3" xref="S4.T1.5.5.1.m1.1.1.3a.cmml">A</mtext><mo mathsize="80%" id="S4.T1.5.5.1.m1.1.1.2" xref="S4.T1.5.5.1.m1.1.1.2.cmml">+</mo><mrow id="S4.T1.5.5.1.m1.1.1.1" xref="S4.T1.5.5.1.m1.1.1.1.cmml"><mtext mathsize="80%" id="S4.T1.5.5.1.m1.1.1.1.3" xref="S4.T1.5.5.1.m1.1.1.1.3a.cmml">G</mtext><mo lspace="0.400em" rspace="0em" id="S4.T1.5.5.1.m1.1.1.1.2" xref="S4.T1.5.5.1.m1.1.1.1.2.cmml">​</mo><mrow id="S4.T1.5.5.1.m1.1.1.1.1.1" xref="S4.T1.5.5.1.m1.1.1.1.1.1.1.cmml"><mo maxsize="80%" minsize="80%" id="S4.T1.5.5.1.m1.1.1.1.1.1.2" xref="S4.T1.5.5.1.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.T1.5.5.1.m1.1.1.1.1.1.1" xref="S4.T1.5.5.1.m1.1.1.1.1.1.1.cmml"><mn mathsize="80%" id="S4.T1.5.5.1.m1.1.1.1.1.1.1.2" xref="S4.T1.5.5.1.m1.1.1.1.1.1.1.2.cmml">50</mn><mo mathsize="80%" id="S4.T1.5.5.1.m1.1.1.1.1.1.1.1" xref="S4.T1.5.5.1.m1.1.1.1.1.1.1.1.cmml">%</mo></mrow><mo maxsize="80%" minsize="80%" id="S4.T1.5.5.1.m1.1.1.1.1.1.3" xref="S4.T1.5.5.1.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.5.5.1.m1.1b"><apply id="S4.T1.5.5.1.m1.1.1.cmml" xref="S4.T1.5.5.1.m1.1.1"><plus id="S4.T1.5.5.1.m1.1.1.2.cmml" xref="S4.T1.5.5.1.m1.1.1.2"></plus><ci id="S4.T1.5.5.1.m1.1.1.3a.cmml" xref="S4.T1.5.5.1.m1.1.1.3"><mtext mathsize="80%" id="S4.T1.5.5.1.m1.1.1.3.cmml" xref="S4.T1.5.5.1.m1.1.1.3">A</mtext></ci><apply id="S4.T1.5.5.1.m1.1.1.1.cmml" xref="S4.T1.5.5.1.m1.1.1.1"><times id="S4.T1.5.5.1.m1.1.1.1.2.cmml" xref="S4.T1.5.5.1.m1.1.1.1.2"></times><ci id="S4.T1.5.5.1.m1.1.1.1.3a.cmml" xref="S4.T1.5.5.1.m1.1.1.1.3"><mtext mathsize="80%" id="S4.T1.5.5.1.m1.1.1.1.3.cmml" xref="S4.T1.5.5.1.m1.1.1.1.3">G</mtext></ci><apply id="S4.T1.5.5.1.m1.1.1.1.1.1.1.cmml" xref="S4.T1.5.5.1.m1.1.1.1.1.1"><csymbol cd="latexml" id="S4.T1.5.5.1.m1.1.1.1.1.1.1.1.cmml" xref="S4.T1.5.5.1.m1.1.1.1.1.1.1.1">percent</csymbol><cn type="integer" id="S4.T1.5.5.1.m1.1.1.1.1.1.1.2.cmml" xref="S4.T1.5.5.1.m1.1.1.1.1.1.1.2">50</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.5.5.1.m1.1c">\text{A}+\text{G}\ (50\%)</annotation></semantics></math></th>
<td id="S4.T1.5.5.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.5.5.2.1" class="ltx_text" style="font-size:80%;">A</span></td>
<td id="S4.T1.5.5.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.5.5.3.1" class="ltx_text" style="font-size:80%;">94.2%</span></td>
<td id="S4.T1.5.5.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.5.5.4.1" class="ltx_text" style="font-size:80%;">86.5%</span></td>
<td id="S4.T1.5.5.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.5.5.5.1" class="ltx_text" style="font-size:80%;">90.2%</span></td>
</tr>
<tr id="S4.T1.7.9.2" class="ltx_tr">
<th id="S4.T1.7.9.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="S4.T1.7.9.2.1.1" class="ltx_text" style="font-size:80%;">A</span></th>
<td id="S4.T1.7.9.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.7.9.2.2.1" class="ltx_text" style="font-size:80%;">B</span></td>
<td id="S4.T1.7.9.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.7.9.2.3.1" class="ltx_text" style="font-size:80%;">0%</span></td>
<td id="S4.T1.7.9.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.7.9.2.4.1" class="ltx_text" style="font-size:80%;">0%</span></td>
<td id="S4.T1.7.9.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.7.9.2.5.1" class="ltx_text" style="font-size:80%;">0%</span></td>
</tr>
<tr id="S4.T1.6.6" class="ltx_tr">
<th id="S4.T1.6.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r"><math id="S4.T1.6.6.1.m1.1" class="ltx_Math" alttext="\text{A}+\text{S}\ (40\%)" display="inline"><semantics id="S4.T1.6.6.1.m1.1a"><mrow id="S4.T1.6.6.1.m1.1.1" xref="S4.T1.6.6.1.m1.1.1.cmml"><mtext mathsize="80%" id="S4.T1.6.6.1.m1.1.1.3" xref="S4.T1.6.6.1.m1.1.1.3a.cmml">A</mtext><mo mathsize="80%" id="S4.T1.6.6.1.m1.1.1.2" xref="S4.T1.6.6.1.m1.1.1.2.cmml">+</mo><mrow id="S4.T1.6.6.1.m1.1.1.1" xref="S4.T1.6.6.1.m1.1.1.1.cmml"><mtext mathsize="80%" id="S4.T1.6.6.1.m1.1.1.1.3" xref="S4.T1.6.6.1.m1.1.1.1.3a.cmml">S</mtext><mo lspace="0.400em" rspace="0em" id="S4.T1.6.6.1.m1.1.1.1.2" xref="S4.T1.6.6.1.m1.1.1.1.2.cmml">​</mo><mrow id="S4.T1.6.6.1.m1.1.1.1.1.1" xref="S4.T1.6.6.1.m1.1.1.1.1.1.1.cmml"><mo maxsize="80%" minsize="80%" id="S4.T1.6.6.1.m1.1.1.1.1.1.2" xref="S4.T1.6.6.1.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.T1.6.6.1.m1.1.1.1.1.1.1" xref="S4.T1.6.6.1.m1.1.1.1.1.1.1.cmml"><mn mathsize="80%" id="S4.T1.6.6.1.m1.1.1.1.1.1.1.2" xref="S4.T1.6.6.1.m1.1.1.1.1.1.1.2.cmml">40</mn><mo mathsize="80%" id="S4.T1.6.6.1.m1.1.1.1.1.1.1.1" xref="S4.T1.6.6.1.m1.1.1.1.1.1.1.1.cmml">%</mo></mrow><mo maxsize="80%" minsize="80%" id="S4.T1.6.6.1.m1.1.1.1.1.1.3" xref="S4.T1.6.6.1.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.6.6.1.m1.1b"><apply id="S4.T1.6.6.1.m1.1.1.cmml" xref="S4.T1.6.6.1.m1.1.1"><plus id="S4.T1.6.6.1.m1.1.1.2.cmml" xref="S4.T1.6.6.1.m1.1.1.2"></plus><ci id="S4.T1.6.6.1.m1.1.1.3a.cmml" xref="S4.T1.6.6.1.m1.1.1.3"><mtext mathsize="80%" id="S4.T1.6.6.1.m1.1.1.3.cmml" xref="S4.T1.6.6.1.m1.1.1.3">A</mtext></ci><apply id="S4.T1.6.6.1.m1.1.1.1.cmml" xref="S4.T1.6.6.1.m1.1.1.1"><times id="S4.T1.6.6.1.m1.1.1.1.2.cmml" xref="S4.T1.6.6.1.m1.1.1.1.2"></times><ci id="S4.T1.6.6.1.m1.1.1.1.3a.cmml" xref="S4.T1.6.6.1.m1.1.1.1.3"><mtext mathsize="80%" id="S4.T1.6.6.1.m1.1.1.1.3.cmml" xref="S4.T1.6.6.1.m1.1.1.1.3">S</mtext></ci><apply id="S4.T1.6.6.1.m1.1.1.1.1.1.1.cmml" xref="S4.T1.6.6.1.m1.1.1.1.1.1"><csymbol cd="latexml" id="S4.T1.6.6.1.m1.1.1.1.1.1.1.1.cmml" xref="S4.T1.6.6.1.m1.1.1.1.1.1.1.1">percent</csymbol><cn type="integer" id="S4.T1.6.6.1.m1.1.1.1.1.1.1.2.cmml" xref="S4.T1.6.6.1.m1.1.1.1.1.1.1.2">40</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.6.6.1.m1.1c">\text{A}+\text{S}\ (40\%)</annotation></semantics></math></th>
<td id="S4.T1.6.6.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.6.6.2.1" class="ltx_text" style="font-size:80%;">B</span></td>
<td id="S4.T1.6.6.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.6.6.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;color:#00FF00;">71.8%</span></td>
<td id="S4.T1.6.6.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.6.6.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;color:#00FF00;">6.3%</span></td>
<td id="S4.T1.6.6.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.6.6.5.1" class="ltx_text ltx_font_bold" style="font-size:80%;color:#00FF00;">11.6%</span></td>
</tr>
<tr id="S4.T1.7.7" class="ltx_tr">
<th id="S4.T1.7.7.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_l ltx_border_r"><math id="S4.T1.7.7.1.m1.1" class="ltx_Math" alttext="\text{A}+\text{G}\ (50\%)" display="inline"><semantics id="S4.T1.7.7.1.m1.1a"><mrow id="S4.T1.7.7.1.m1.1.1" xref="S4.T1.7.7.1.m1.1.1.cmml"><mtext mathsize="80%" id="S4.T1.7.7.1.m1.1.1.3" xref="S4.T1.7.7.1.m1.1.1.3a.cmml">A</mtext><mo mathsize="80%" id="S4.T1.7.7.1.m1.1.1.2" xref="S4.T1.7.7.1.m1.1.1.2.cmml">+</mo><mrow id="S4.T1.7.7.1.m1.1.1.1" xref="S4.T1.7.7.1.m1.1.1.1.cmml"><mtext mathsize="80%" id="S4.T1.7.7.1.m1.1.1.1.3" xref="S4.T1.7.7.1.m1.1.1.1.3a.cmml">G</mtext><mo lspace="0.400em" rspace="0em" id="S4.T1.7.7.1.m1.1.1.1.2" xref="S4.T1.7.7.1.m1.1.1.1.2.cmml">​</mo><mrow id="S4.T1.7.7.1.m1.1.1.1.1.1" xref="S4.T1.7.7.1.m1.1.1.1.1.1.1.cmml"><mo maxsize="80%" minsize="80%" id="S4.T1.7.7.1.m1.1.1.1.1.1.2" xref="S4.T1.7.7.1.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.T1.7.7.1.m1.1.1.1.1.1.1" xref="S4.T1.7.7.1.m1.1.1.1.1.1.1.cmml"><mn mathsize="80%" id="S4.T1.7.7.1.m1.1.1.1.1.1.1.2" xref="S4.T1.7.7.1.m1.1.1.1.1.1.1.2.cmml">50</mn><mo mathsize="80%" id="S4.T1.7.7.1.m1.1.1.1.1.1.1.1" xref="S4.T1.7.7.1.m1.1.1.1.1.1.1.1.cmml">%</mo></mrow><mo maxsize="80%" minsize="80%" id="S4.T1.7.7.1.m1.1.1.1.1.1.3" xref="S4.T1.7.7.1.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.7.7.1.m1.1b"><apply id="S4.T1.7.7.1.m1.1.1.cmml" xref="S4.T1.7.7.1.m1.1.1"><plus id="S4.T1.7.7.1.m1.1.1.2.cmml" xref="S4.T1.7.7.1.m1.1.1.2"></plus><ci id="S4.T1.7.7.1.m1.1.1.3a.cmml" xref="S4.T1.7.7.1.m1.1.1.3"><mtext mathsize="80%" id="S4.T1.7.7.1.m1.1.1.3.cmml" xref="S4.T1.7.7.1.m1.1.1.3">A</mtext></ci><apply id="S4.T1.7.7.1.m1.1.1.1.cmml" xref="S4.T1.7.7.1.m1.1.1.1"><times id="S4.T1.7.7.1.m1.1.1.1.2.cmml" xref="S4.T1.7.7.1.m1.1.1.1.2"></times><ci id="S4.T1.7.7.1.m1.1.1.1.3a.cmml" xref="S4.T1.7.7.1.m1.1.1.1.3"><mtext mathsize="80%" id="S4.T1.7.7.1.m1.1.1.1.3.cmml" xref="S4.T1.7.7.1.m1.1.1.1.3">G</mtext></ci><apply id="S4.T1.7.7.1.m1.1.1.1.1.1.1.cmml" xref="S4.T1.7.7.1.m1.1.1.1.1.1"><csymbol cd="latexml" id="S4.T1.7.7.1.m1.1.1.1.1.1.1.1.cmml" xref="S4.T1.7.7.1.m1.1.1.1.1.1.1.1">percent</csymbol><cn type="integer" id="S4.T1.7.7.1.m1.1.1.1.1.1.1.2.cmml" xref="S4.T1.7.7.1.m1.1.1.1.1.1.1.2">50</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.7.7.1.m1.1c">\text{A}+\text{G}\ (50\%)</annotation></semantics></math></th>
<td id="S4.T1.7.7.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S4.T1.7.7.2.1" class="ltx_text" style="font-size:80%;">B</span></td>
<td id="S4.T1.7.7.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S4.T1.7.7.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;color:#0000FF;">67.0%</span></td>
<td id="S4.T1.7.7.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S4.T1.7.7.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;color:#0000FF;">21.4%</span></td>
<td id="S4.T1.7.7.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S4.T1.7.7.5.1" class="ltx_text ltx_font_bold" style="font-size:80%;color:#0000FF;">32.4%</span></td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Experiment Details</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">As shown in Table <a href="#S4.T1" title="Table 1 ‣ 4.2 Results ‣ 4 Case Study: Parking Slot Detection ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, MobileNetV2 SSD trained on Parking A results in a F-Measure of 91.4% on the Parking A test set (1<sup id="S4.SS3.p1.1.1" class="ltx_sup">st</sup> row). However, the same model when tested on the Parking B dataset results in a F-measure of 0% (4<sup id="S4.SS3.p1.1.2" class="ltx_sup">th</sup> row). It is a well known fact that supervised learning-based methods do not generalize across different domains. In this particular case the generalization performance is much worse than one might expect because of two main reasons: (i) the small size (relative to large-scale image datasets such as ImageNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> and COCO <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>) and low diversity (all daytime images from the same parking lot) of the Parking A dataset; (ii) the large domain gap between the two datasets. Increasing dropout regularization did not help improve generalization performance either - F-Measure remained constant at 0% for varying levels of dropout. The only improvement observed was in the number of false positives (more details are provided in Supplementary Material).</p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.1" class="ltx_p">Thus, these results are consistent with the motivating hypothesis <span id="S4.SS3.p2.1.1" class="ltx_text ltx_font_typewriter">H</span>. Additionally, as shown in the 2<sup id="S4.SS3.p2.1.2" class="ltx_sup">nd</sup> and 3<sup id="S4.SS3.p2.1.3" class="ltx_sup">rd</sup> rows of Table <a href="#S4.T1" title="Table 1 ‣ 4.2 Results ‣ 4 Case Study: Parking Slot Detection ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, synthetic data augmentation did not adversely affect the results on the Parking A test set which further strengthens the case for the use of synthetic data and especially GAN-translated data to enrich real-world datasets for supervised learning tasks.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Case Study: Traffic Lane Detection</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">The objective of this task is to detect lane boundaries in images taken from a front vehicle camera (see Fig. <a href="#S5.F5" title="Figure 5 ‣ 5 Case Study: Traffic Lane Detection ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>).</p>
</div>
<figure id="S5.F5" class="ltx_figure"><img src="/html/2004.13866/assets/figs/lane/lane_detection_process.png" id="S5.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="509" height="117" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F5.2.1.1" class="ltx_text" style="font-size:90%;">Figure 5</span>: </span><span id="S5.F5.3.2" class="ltx_text" style="font-size:90%;">Lane detection schematic.</span></figcaption>
</figure>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">Pan <em id="S5.p2.1.1" class="ltx_emph ltx_font_italic">et al</em>.<span id="S5.p2.1.2" class="ltx_text"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> achieved state-of-the-art performance on this task with Spatial Convolutional Neural Networks (SCNNs). Their formulation is used as-is for all the lane detection experiments in this paper.</p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Dataset Description</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p"><span id="S5.SS1.p1.1.1" class="ltx_text ltx_font_bold">Real Data:</span> Following Pan  <em id="S5.SS1.p1.1.2" class="ltx_emph ltx_font_italic">et al</em>.<span id="S5.SS1.p1.1.3" class="ltx_text"></span> in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>, the <em id="S5.SS1.p1.1.4" class="ltx_emph ltx_font_italic">CULane</em> and <em id="S5.SS1.p1.1.5" class="ltx_emph ltx_font_italic">TuSimple</em><span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a target="_blank" href="https://github.com/TuSimple/tusimple-benchmark/tree/master/doc/lane_detection" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/TuSimple/tusimple-benchmark/tree/master/doc/lane_detection</a></span></span></span> datasets are used as real-world data sources. The CULane dataset has 88880 training images, 9675 validation images and 34680 test images - collected across diverse scenarios including urban, rural and highway environments. The TuSimple dataset has 3268, 358, and 2782 images for training, validation and testing respectively. Compared to CULane, TuSimple has highway scenes only.</p>
</div>
<figure id="S5.F6" class="ltx_figure"><img src="/html/2004.13866/assets/x7.png" id="S5.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="365" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F6.2.1.1" class="ltx_text" style="font-size:90%;">Figure 6</span>: </span><span id="S5.F6.3.2" class="ltx_text" style="font-size:90%;">Example real, simulated and GAN-translated images used for lane detection.
</span></figcaption>
</figure>
<div id="S5.SS1.p2" class="ltx_para">
<p id="S5.SS1.p2.1" class="ltx_p"><span id="S5.SS1.p2.1.1" class="ltx_text ltx_font_bold">Synthetic Data:</span> For augmenting CULane, 88880 daytime highway images were generated using Unreal Engine by varying several noise factors such as the number of lanes, traffic density, sun intensity, location and brightness, road curvature, lane marker wear and tear etc. In testing the original implementation of SCNN, we found that the model performed poorest when lane lines were faint, in shadows or occluded by other vehicles. The change in sun intensity, its location and brightness helped create different shadow effects around the lane lines, giving the network more diverse data to train on. Varying traffic density and road curvature allowed for different occlusions of the lane line markings to produce more diverse data. Example synthetic images generated for this task are shown in Fig. <a href="#S5.F6" title="Figure 6 ‣ 5.1 Dataset Description ‣ 5 Case Study: Traffic Lane Detection ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>. Following the method outlined in Section <a href="#S3" title="3 Deflating Dataset Bias ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, a sim2real VAE-GAN model (based on <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>) trained on unpaired simulated images and real images from CULane was used to translate the generated simulated data to look photorealistic. Fig. <a href="#S5.F6" title="Figure 6 ‣ 5.1 Dataset Description ‣ 5 Case Study: Traffic Lane Detection ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> shows the sim2real translated output for the given simulated image. Note the realistic ground textures and lighting effects in the GAN image in contrast to the simulated image.</p>
</div>
<figure id="S5.F7" class="ltx_figure"><img src="/html/2004.13866/assets/x8.png" id="S5.F7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="392" height="216" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F7.2.1.1" class="ltx_text" style="font-size:90%;">Figure 7</span>: </span><span id="S5.F7.3.2" class="ltx_text" style="font-size:90%;">Plot of F-measure for models trained on a mix of CULane and synthetic images (from simulation or from sim2real VAE-GAN) and tested on TuSimple images.</span></figcaption>
</figure>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Experiment Details</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.4" class="ltx_p">For the lane detection experiments in this paper, two types of experiments were performed:
<br class="ltx_break"><span id="S5.SS2.p1.4.1" class="ltx_text ltx_font_bold">Experiment I:</span> Following Section <a href="#S3" title="3 Deflating Dataset Bias ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, SCNN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> is trained on a mix of CULane and synthetic images and tested on TuSimple. For results from SCNN trained on a mix of TuSimple and synthetic images and tested on CULane, please refer Supplementary Material. Models are trained on <math id="S5.SS2.p1.1.m1.1" class="ltx_Math" alttext="800\times 288" display="inline"><semantics id="S5.SS2.p1.1.m1.1a"><mrow id="S5.SS2.p1.1.m1.1.1" xref="S5.SS2.p1.1.m1.1.1.cmml"><mn id="S5.SS2.p1.1.m1.1.1.2" xref="S5.SS2.p1.1.m1.1.1.2.cmml">800</mn><mo lspace="0.222em" rspace="0.222em" id="S5.SS2.p1.1.m1.1.1.1" xref="S5.SS2.p1.1.m1.1.1.1.cmml">×</mo><mn id="S5.SS2.p1.1.m1.1.1.3" xref="S5.SS2.p1.1.m1.1.1.3.cmml">288</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.1.m1.1b"><apply id="S5.SS2.p1.1.m1.1.1.cmml" xref="S5.SS2.p1.1.m1.1.1"><times id="S5.SS2.p1.1.m1.1.1.1.cmml" xref="S5.SS2.p1.1.m1.1.1.1"></times><cn type="integer" id="S5.SS2.p1.1.m1.1.1.2.cmml" xref="S5.SS2.p1.1.m1.1.1.2">800</cn><cn type="integer" id="S5.SS2.p1.1.m1.1.1.3.cmml" xref="S5.SS2.p1.1.m1.1.1.3">288</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.1.m1.1c">800\times 288</annotation></semantics></math> images. For cross-testing, TuSimple images are padded (along width) to match the training resolution of <math id="S5.SS2.p1.2.m2.1" class="ltx_Math" alttext="800\times 288" display="inline"><semantics id="S5.SS2.p1.2.m2.1a"><mrow id="S5.SS2.p1.2.m2.1.1" xref="S5.SS2.p1.2.m2.1.1.cmml"><mn id="S5.SS2.p1.2.m2.1.1.2" xref="S5.SS2.p1.2.m2.1.1.2.cmml">800</mn><mo lspace="0.222em" rspace="0.222em" id="S5.SS2.p1.2.m2.1.1.1" xref="S5.SS2.p1.2.m2.1.1.1.cmml">×</mo><mn id="S5.SS2.p1.2.m2.1.1.3" xref="S5.SS2.p1.2.m2.1.1.3.cmml">288</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.2.m2.1b"><apply id="S5.SS2.p1.2.m2.1.1.cmml" xref="S5.SS2.p1.2.m2.1.1"><times id="S5.SS2.p1.2.m2.1.1.1.cmml" xref="S5.SS2.p1.2.m2.1.1.1"></times><cn type="integer" id="S5.SS2.p1.2.m2.1.1.2.cmml" xref="S5.SS2.p1.2.m2.1.1.2">800</cn><cn type="integer" id="S5.SS2.p1.2.m2.1.1.3.cmml" xref="S5.SS2.p1.2.m2.1.1.3">288</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.2.m2.1c">800\times 288</annotation></semantics></math> while simultaneously maintaining the original aspect ratio. IoU of detected lane lines with ground truth lane lines is used as the metric for quantitative evaluation.
<br class="ltx_break"><span id="S5.SS2.p1.4.2" class="ltx_text ltx_font_bold">Experiment II:</span> In addition to the experiments described in Section <a href="#S3" title="3 Deflating Dataset Bias ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, given that the TuSimple dataset has only daytime images while the CULane dataset has a diverse set of weather and lighting conditions (refer Section <a href="#S5.SS1" title="5.1 Dataset Description ‣ 5 Case Study: Traffic Lane Detection ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.1</span></a>), we performed an additional set of experiments for this task to further test the motivating hypothesis <span id="S5.SS2.p1.4.3" class="ltx_text ltx_font_typewriter">H</span> particularly in scenarios where synthetic data augmentation addresses the specific bias of weather and lighting effects. All synthetic data was generated by applying day-to-night and clear-to-cloudy VAE-GAN models (based off of the architecture in Ref. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite> and trained on BDD100K <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite>) to TuSimple images. Fig. <a href="#S5.F6" title="Figure 6 ‣ 5.1 Dataset Description ‣ 5 Case Study: Traffic Lane Detection ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> shows an example GAN night and cloudy image. SCNN was trained on <math id="S5.SS2.p1.3.m3.1" class="ltx_Math" alttext="512\times 288" display="inline"><semantics id="S5.SS2.p1.3.m3.1a"><mrow id="S5.SS2.p1.3.m3.1.1" xref="S5.SS2.p1.3.m3.1.1.cmml"><mn id="S5.SS2.p1.3.m3.1.1.2" xref="S5.SS2.p1.3.m3.1.1.2.cmml">512</mn><mo lspace="0.222em" rspace="0.222em" id="S5.SS2.p1.3.m3.1.1.1" xref="S5.SS2.p1.3.m3.1.1.1.cmml">×</mo><mn id="S5.SS2.p1.3.m3.1.1.3" xref="S5.SS2.p1.3.m3.1.1.3.cmml">288</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.3.m3.1b"><apply id="S5.SS2.p1.3.m3.1.1.cmml" xref="S5.SS2.p1.3.m3.1.1"><times id="S5.SS2.p1.3.m3.1.1.1.cmml" xref="S5.SS2.p1.3.m3.1.1.1"></times><cn type="integer" id="S5.SS2.p1.3.m3.1.1.2.cmml" xref="S5.SS2.p1.3.m3.1.1.2">512</cn><cn type="integer" id="S5.SS2.p1.3.m3.1.1.3.cmml" xref="S5.SS2.p1.3.m3.1.1.3">288</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.3.m3.1c">512\times 288</annotation></semantics></math> images for this set of experiments and tested on downsized and then padded (along height) versions of CULane images that match the training resolution of <math id="S5.SS2.p1.4.m4.1" class="ltx_Math" alttext="512\times 288" display="inline"><semantics id="S5.SS2.p1.4.m4.1a"><mrow id="S5.SS2.p1.4.m4.1.1" xref="S5.SS2.p1.4.m4.1.1.cmml"><mn id="S5.SS2.p1.4.m4.1.1.2" xref="S5.SS2.p1.4.m4.1.1.2.cmml">512</mn><mo lspace="0.222em" rspace="0.222em" id="S5.SS2.p1.4.m4.1.1.1" xref="S5.SS2.p1.4.m4.1.1.1.cmml">×</mo><mn id="S5.SS2.p1.4.m4.1.1.3" xref="S5.SS2.p1.4.m4.1.1.3.cmml">288</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.4.m4.1b"><apply id="S5.SS2.p1.4.m4.1.1.cmml" xref="S5.SS2.p1.4.m4.1.1"><times id="S5.SS2.p1.4.m4.1.1.1.cmml" xref="S5.SS2.p1.4.m4.1.1.1"></times><cn type="integer" id="S5.SS2.p1.4.m4.1.1.2.cmml" xref="S5.SS2.p1.4.m4.1.1.2">512</cn><cn type="integer" id="S5.SS2.p1.4.m4.1.1.3.cmml" xref="S5.SS2.p1.4.m4.1.1.3">288</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.4.m4.1c">512\times 288</annotation></semantics></math> while simultaneously maintaining the original aspect ratio.</p>
</div>
<figure id="S5.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table"><span id="S5.T2.23.1.1" class="ltx_text" style="font-size:113%;">Table 2</span>: </span><span id="S5.T2.24.2" class="ltx_text" style="font-size:113%;">Summary of results in Fig. <a href="#S5.F7" title="Figure 7 ‣ 5.1 Dataset Description ‣ 5 Case Study: Traffic Lane Detection ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>. Here, A, A<sub id="S5.T2.24.2.1" class="ltx_sub">N</sub> and B denote the CULane, CULane Night only and TuSimple datasets. S denotes simulated images and G denotes the sim2real translated equivalent of S. G<sub id="S5.T2.24.2.2" class="ltx_sub">N</sub> and G<sub id="S5.T2.24.2.3" class="ltx_sub">C</sub> denote real TuSimple images translated to nighttime and cloudy respectively. For synthetic data augmentation rows, results are shown for the best model in terms of F-measure on cross-dataset testing in green for A + S and in blue for A + G.</span></figcaption>
<table id="S5.T2.12" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T2.3.3" class="ltx_tr">
<th id="S5.T2.3.3.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_tt"><span id="S5.T2.3.3.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Train</span></th>
<th id="S5.T2.3.3.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt"><span id="S5.T2.3.3.5.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Test</span></th>
<th id="S5.T2.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt">
<span id="S5.T2.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Precision</span><span id="S5.T2.1.1.1.2" class="ltx_text" style="font-size:80%;"> (</span><math id="S5.T2.1.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S5.T2.1.1.1.m1.1a"><mo mathsize="80%" stretchy="false" id="S5.T2.1.1.1.m1.1.1" xref="S5.T2.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S5.T2.1.1.1.m1.1b"><ci id="S5.T2.1.1.1.m1.1.1.cmml" xref="S5.T2.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.1.1.1.m1.1c">\uparrow</annotation></semantics></math><span id="S5.T2.1.1.1.3" class="ltx_text" style="font-size:80%;">)</span>
</th>
<th id="S5.T2.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt">
<span id="S5.T2.2.2.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Recall</span><span id="S5.T2.2.2.2.2" class="ltx_text" style="font-size:80%;"> (</span><math id="S5.T2.2.2.2.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S5.T2.2.2.2.m1.1a"><mo mathsize="80%" stretchy="false" id="S5.T2.2.2.2.m1.1.1" xref="S5.T2.2.2.2.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S5.T2.2.2.2.m1.1b"><ci id="S5.T2.2.2.2.m1.1.1.cmml" xref="S5.T2.2.2.2.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.2.2.2.m1.1c">\uparrow</annotation></semantics></math><span id="S5.T2.2.2.2.3" class="ltx_text" style="font-size:80%;">)</span>
</th>
<th id="S5.T2.3.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt">
<span id="S5.T2.3.3.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">F-Measure</span><span id="S5.T2.3.3.3.2" class="ltx_text" style="font-size:80%;"> (</span><math id="S5.T2.3.3.3.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S5.T2.3.3.3.m1.1a"><mo mathsize="80%" stretchy="false" id="S5.T2.3.3.3.m1.1.1" xref="S5.T2.3.3.3.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S5.T2.3.3.3.m1.1b"><ci id="S5.T2.3.3.3.m1.1.1.cmml" xref="S5.T2.3.3.3.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.3.3.3.m1.1c">\uparrow</annotation></semantics></math><span id="S5.T2.3.3.3.3" class="ltx_text" style="font-size:80%;">)</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T2.12.13.1" class="ltx_tr">
<th id="S5.T2.12.13.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="S5.T2.12.13.1.1.1" class="ltx_text" style="font-size:80%;">A</span></th>
<td id="S5.T2.12.13.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T2.12.13.1.2.1" class="ltx_text" style="font-size:80%;">A</span></td>
<td id="S5.T2.12.13.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T2.12.13.1.3.1" class="ltx_text" style="font-size:80%;">53.6%</span></td>
<td id="S5.T2.12.13.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T2.12.13.1.4.1" class="ltx_text" style="font-size:80%;">70.6%</span></td>
<td id="S5.T2.12.13.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T2.12.13.1.5.1" class="ltx_text" style="font-size:80%;">60.9%</span></td>
</tr>
<tr id="S5.T2.4.4" class="ltx_tr">
<th id="S5.T2.4.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r"><math id="S5.T2.4.4.1.m1.1" class="ltx_Math" alttext="\text{A}+\text{S}\ (30\%)" display="inline"><semantics id="S5.T2.4.4.1.m1.1a"><mrow id="S5.T2.4.4.1.m1.1.1" xref="S5.T2.4.4.1.m1.1.1.cmml"><mtext mathsize="80%" id="S5.T2.4.4.1.m1.1.1.3" xref="S5.T2.4.4.1.m1.1.1.3a.cmml">A</mtext><mo mathsize="80%" id="S5.T2.4.4.1.m1.1.1.2" xref="S5.T2.4.4.1.m1.1.1.2.cmml">+</mo><mrow id="S5.T2.4.4.1.m1.1.1.1" xref="S5.T2.4.4.1.m1.1.1.1.cmml"><mtext mathsize="80%" id="S5.T2.4.4.1.m1.1.1.1.3" xref="S5.T2.4.4.1.m1.1.1.1.3a.cmml">S</mtext><mo lspace="0.400em" rspace="0em" id="S5.T2.4.4.1.m1.1.1.1.2" xref="S5.T2.4.4.1.m1.1.1.1.2.cmml">​</mo><mrow id="S5.T2.4.4.1.m1.1.1.1.1.1" xref="S5.T2.4.4.1.m1.1.1.1.1.1.1.cmml"><mo maxsize="80%" minsize="80%" id="S5.T2.4.4.1.m1.1.1.1.1.1.2" xref="S5.T2.4.4.1.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S5.T2.4.4.1.m1.1.1.1.1.1.1" xref="S5.T2.4.4.1.m1.1.1.1.1.1.1.cmml"><mn mathsize="80%" id="S5.T2.4.4.1.m1.1.1.1.1.1.1.2" xref="S5.T2.4.4.1.m1.1.1.1.1.1.1.2.cmml">30</mn><mo mathsize="80%" id="S5.T2.4.4.1.m1.1.1.1.1.1.1.1" xref="S5.T2.4.4.1.m1.1.1.1.1.1.1.1.cmml">%</mo></mrow><mo maxsize="80%" minsize="80%" id="S5.T2.4.4.1.m1.1.1.1.1.1.3" xref="S5.T2.4.4.1.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.4.4.1.m1.1b"><apply id="S5.T2.4.4.1.m1.1.1.cmml" xref="S5.T2.4.4.1.m1.1.1"><plus id="S5.T2.4.4.1.m1.1.1.2.cmml" xref="S5.T2.4.4.1.m1.1.1.2"></plus><ci id="S5.T2.4.4.1.m1.1.1.3a.cmml" xref="S5.T2.4.4.1.m1.1.1.3"><mtext mathsize="80%" id="S5.T2.4.4.1.m1.1.1.3.cmml" xref="S5.T2.4.4.1.m1.1.1.3">A</mtext></ci><apply id="S5.T2.4.4.1.m1.1.1.1.cmml" xref="S5.T2.4.4.1.m1.1.1.1"><times id="S5.T2.4.4.1.m1.1.1.1.2.cmml" xref="S5.T2.4.4.1.m1.1.1.1.2"></times><ci id="S5.T2.4.4.1.m1.1.1.1.3a.cmml" xref="S5.T2.4.4.1.m1.1.1.1.3"><mtext mathsize="80%" id="S5.T2.4.4.1.m1.1.1.1.3.cmml" xref="S5.T2.4.4.1.m1.1.1.1.3">S</mtext></ci><apply id="S5.T2.4.4.1.m1.1.1.1.1.1.1.cmml" xref="S5.T2.4.4.1.m1.1.1.1.1.1"><csymbol cd="latexml" id="S5.T2.4.4.1.m1.1.1.1.1.1.1.1.cmml" xref="S5.T2.4.4.1.m1.1.1.1.1.1.1.1">percent</csymbol><cn type="integer" id="S5.T2.4.4.1.m1.1.1.1.1.1.1.2.cmml" xref="S5.T2.4.4.1.m1.1.1.1.1.1.1.2">30</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.4.4.1.m1.1c">\text{A}+\text{S}\ (30\%)</annotation></semantics></math></th>
<td id="S5.T2.4.4.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.4.4.2.1" class="ltx_text" style="font-size:80%;">A</span></td>
<td id="S5.T2.4.4.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.4.4.3.1" class="ltx_text" style="font-size:80%;">53.5%</span></td>
<td id="S5.T2.4.4.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.4.4.4.1" class="ltx_text" style="font-size:80%;">70.8%</span></td>
<td id="S5.T2.4.4.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.4.4.5.1" class="ltx_text" style="font-size:80%;">60.9%</span></td>
</tr>
<tr id="S5.T2.5.5" class="ltx_tr">
<th id="S5.T2.5.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r"><math id="S5.T2.5.5.1.m1.1" class="ltx_Math" alttext="\text{A}+\text{G}\ (60\%)" display="inline"><semantics id="S5.T2.5.5.1.m1.1a"><mrow id="S5.T2.5.5.1.m1.1.1" xref="S5.T2.5.5.1.m1.1.1.cmml"><mtext mathsize="80%" id="S5.T2.5.5.1.m1.1.1.3" xref="S5.T2.5.5.1.m1.1.1.3a.cmml">A</mtext><mo mathsize="80%" id="S5.T2.5.5.1.m1.1.1.2" xref="S5.T2.5.5.1.m1.1.1.2.cmml">+</mo><mrow id="S5.T2.5.5.1.m1.1.1.1" xref="S5.T2.5.5.1.m1.1.1.1.cmml"><mtext mathsize="80%" id="S5.T2.5.5.1.m1.1.1.1.3" xref="S5.T2.5.5.1.m1.1.1.1.3a.cmml">G</mtext><mo lspace="0.400em" rspace="0em" id="S5.T2.5.5.1.m1.1.1.1.2" xref="S5.T2.5.5.1.m1.1.1.1.2.cmml">​</mo><mrow id="S5.T2.5.5.1.m1.1.1.1.1.1" xref="S5.T2.5.5.1.m1.1.1.1.1.1.1.cmml"><mo maxsize="80%" minsize="80%" id="S5.T2.5.5.1.m1.1.1.1.1.1.2" xref="S5.T2.5.5.1.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S5.T2.5.5.1.m1.1.1.1.1.1.1" xref="S5.T2.5.5.1.m1.1.1.1.1.1.1.cmml"><mn mathsize="80%" id="S5.T2.5.5.1.m1.1.1.1.1.1.1.2" xref="S5.T2.5.5.1.m1.1.1.1.1.1.1.2.cmml">60</mn><mo mathsize="80%" id="S5.T2.5.5.1.m1.1.1.1.1.1.1.1" xref="S5.T2.5.5.1.m1.1.1.1.1.1.1.1.cmml">%</mo></mrow><mo maxsize="80%" minsize="80%" id="S5.T2.5.5.1.m1.1.1.1.1.1.3" xref="S5.T2.5.5.1.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.5.5.1.m1.1b"><apply id="S5.T2.5.5.1.m1.1.1.cmml" xref="S5.T2.5.5.1.m1.1.1"><plus id="S5.T2.5.5.1.m1.1.1.2.cmml" xref="S5.T2.5.5.1.m1.1.1.2"></plus><ci id="S5.T2.5.5.1.m1.1.1.3a.cmml" xref="S5.T2.5.5.1.m1.1.1.3"><mtext mathsize="80%" id="S5.T2.5.5.1.m1.1.1.3.cmml" xref="S5.T2.5.5.1.m1.1.1.3">A</mtext></ci><apply id="S5.T2.5.5.1.m1.1.1.1.cmml" xref="S5.T2.5.5.1.m1.1.1.1"><times id="S5.T2.5.5.1.m1.1.1.1.2.cmml" xref="S5.T2.5.5.1.m1.1.1.1.2"></times><ci id="S5.T2.5.5.1.m1.1.1.1.3a.cmml" xref="S5.T2.5.5.1.m1.1.1.1.3"><mtext mathsize="80%" id="S5.T2.5.5.1.m1.1.1.1.3.cmml" xref="S5.T2.5.5.1.m1.1.1.1.3">G</mtext></ci><apply id="S5.T2.5.5.1.m1.1.1.1.1.1.1.cmml" xref="S5.T2.5.5.1.m1.1.1.1.1.1"><csymbol cd="latexml" id="S5.T2.5.5.1.m1.1.1.1.1.1.1.1.cmml" xref="S5.T2.5.5.1.m1.1.1.1.1.1.1.1">percent</csymbol><cn type="integer" id="S5.T2.5.5.1.m1.1.1.1.1.1.1.2.cmml" xref="S5.T2.5.5.1.m1.1.1.1.1.1.1.2">60</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.5.5.1.m1.1c">\text{A}+\text{G}\ (60\%)</annotation></semantics></math></th>
<td id="S5.T2.5.5.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.5.5.2.1" class="ltx_text" style="font-size:80%;">A</span></td>
<td id="S5.T2.5.5.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.5.5.3.1" class="ltx_text" style="font-size:80%;">51.6%</span></td>
<td id="S5.T2.5.5.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.5.5.4.1" class="ltx_text" style="font-size:80%;">68.0%</span></td>
<td id="S5.T2.5.5.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.5.5.5.1" class="ltx_text" style="font-size:80%;">58.7%</span></td>
</tr>
<tr id="S5.T2.12.14.2" class="ltx_tr">
<th id="S5.T2.12.14.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="S5.T2.12.14.2.1.1" class="ltx_text" style="font-size:80%;">A</span></th>
<td id="S5.T2.12.14.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T2.12.14.2.2.1" class="ltx_text" style="font-size:80%;">B</span></td>
<td id="S5.T2.12.14.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T2.12.14.2.3.1" class="ltx_text" style="font-size:80%;">47.8%</span></td>
<td id="S5.T2.12.14.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T2.12.14.2.4.1" class="ltx_text" style="font-size:80%;">51.9%</span></td>
<td id="S5.T2.12.14.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T2.12.14.2.5.1" class="ltx_text" style="font-size:80%;">49.8%</span></td>
</tr>
<tr id="S5.T2.6.6" class="ltx_tr">
<th id="S5.T2.6.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r"><math id="S5.T2.6.6.1.m1.1" class="ltx_Math" alttext="\text{A}+\text{S}\ (30\%)" display="inline"><semantics id="S5.T2.6.6.1.m1.1a"><mrow id="S5.T2.6.6.1.m1.1.1" xref="S5.T2.6.6.1.m1.1.1.cmml"><mtext mathsize="80%" id="S5.T2.6.6.1.m1.1.1.3" xref="S5.T2.6.6.1.m1.1.1.3a.cmml">A</mtext><mo mathsize="80%" id="S5.T2.6.6.1.m1.1.1.2" xref="S5.T2.6.6.1.m1.1.1.2.cmml">+</mo><mrow id="S5.T2.6.6.1.m1.1.1.1" xref="S5.T2.6.6.1.m1.1.1.1.cmml"><mtext mathsize="80%" id="S5.T2.6.6.1.m1.1.1.1.3" xref="S5.T2.6.6.1.m1.1.1.1.3a.cmml">S</mtext><mo lspace="0.400em" rspace="0em" id="S5.T2.6.6.1.m1.1.1.1.2" xref="S5.T2.6.6.1.m1.1.1.1.2.cmml">​</mo><mrow id="S5.T2.6.6.1.m1.1.1.1.1.1" xref="S5.T2.6.6.1.m1.1.1.1.1.1.1.cmml"><mo maxsize="80%" minsize="80%" id="S5.T2.6.6.1.m1.1.1.1.1.1.2" xref="S5.T2.6.6.1.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S5.T2.6.6.1.m1.1.1.1.1.1.1" xref="S5.T2.6.6.1.m1.1.1.1.1.1.1.cmml"><mn mathsize="80%" id="S5.T2.6.6.1.m1.1.1.1.1.1.1.2" xref="S5.T2.6.6.1.m1.1.1.1.1.1.1.2.cmml">30</mn><mo mathsize="80%" id="S5.T2.6.6.1.m1.1.1.1.1.1.1.1" xref="S5.T2.6.6.1.m1.1.1.1.1.1.1.1.cmml">%</mo></mrow><mo maxsize="80%" minsize="80%" id="S5.T2.6.6.1.m1.1.1.1.1.1.3" xref="S5.T2.6.6.1.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.6.6.1.m1.1b"><apply id="S5.T2.6.6.1.m1.1.1.cmml" xref="S5.T2.6.6.1.m1.1.1"><plus id="S5.T2.6.6.1.m1.1.1.2.cmml" xref="S5.T2.6.6.1.m1.1.1.2"></plus><ci id="S5.T2.6.6.1.m1.1.1.3a.cmml" xref="S5.T2.6.6.1.m1.1.1.3"><mtext mathsize="80%" id="S5.T2.6.6.1.m1.1.1.3.cmml" xref="S5.T2.6.6.1.m1.1.1.3">A</mtext></ci><apply id="S5.T2.6.6.1.m1.1.1.1.cmml" xref="S5.T2.6.6.1.m1.1.1.1"><times id="S5.T2.6.6.1.m1.1.1.1.2.cmml" xref="S5.T2.6.6.1.m1.1.1.1.2"></times><ci id="S5.T2.6.6.1.m1.1.1.1.3a.cmml" xref="S5.T2.6.6.1.m1.1.1.1.3"><mtext mathsize="80%" id="S5.T2.6.6.1.m1.1.1.1.3.cmml" xref="S5.T2.6.6.1.m1.1.1.1.3">S</mtext></ci><apply id="S5.T2.6.6.1.m1.1.1.1.1.1.1.cmml" xref="S5.T2.6.6.1.m1.1.1.1.1.1"><csymbol cd="latexml" id="S5.T2.6.6.1.m1.1.1.1.1.1.1.1.cmml" xref="S5.T2.6.6.1.m1.1.1.1.1.1.1.1">percent</csymbol><cn type="integer" id="S5.T2.6.6.1.m1.1.1.1.1.1.1.2.cmml" xref="S5.T2.6.6.1.m1.1.1.1.1.1.1.2">30</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.6.6.1.m1.1c">\text{A}+\text{S}\ (30\%)</annotation></semantics></math></th>
<td id="S5.T2.6.6.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.6.6.2.1" class="ltx_text" style="font-size:80%;">B</span></td>
<td id="S5.T2.6.6.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.6.6.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;color:#00FF00;">63.6%</span></td>
<td id="S5.T2.6.6.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.6.6.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;color:#00FF00;">70.6%</span></td>
<td id="S5.T2.6.6.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.6.6.5.1" class="ltx_text ltx_font_bold" style="font-size:80%;color:#00FF00;">66.9%</span></td>
</tr>
<tr id="S5.T2.7.7" class="ltx_tr">
<th id="S5.T2.7.7.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r"><math id="S5.T2.7.7.1.m1.1" class="ltx_Math" alttext="\text{A}+\text{G}\ (60\%)" display="inline"><semantics id="S5.T2.7.7.1.m1.1a"><mrow id="S5.T2.7.7.1.m1.1.1" xref="S5.T2.7.7.1.m1.1.1.cmml"><mtext mathsize="80%" id="S5.T2.7.7.1.m1.1.1.3" xref="S5.T2.7.7.1.m1.1.1.3a.cmml">A</mtext><mo mathsize="80%" id="S5.T2.7.7.1.m1.1.1.2" xref="S5.T2.7.7.1.m1.1.1.2.cmml">+</mo><mrow id="S5.T2.7.7.1.m1.1.1.1" xref="S5.T2.7.7.1.m1.1.1.1.cmml"><mtext mathsize="80%" id="S5.T2.7.7.1.m1.1.1.1.3" xref="S5.T2.7.7.1.m1.1.1.1.3a.cmml">G</mtext><mo lspace="0.400em" rspace="0em" id="S5.T2.7.7.1.m1.1.1.1.2" xref="S5.T2.7.7.1.m1.1.1.1.2.cmml">​</mo><mrow id="S5.T2.7.7.1.m1.1.1.1.1.1" xref="S5.T2.7.7.1.m1.1.1.1.1.1.1.cmml"><mo maxsize="80%" minsize="80%" id="S5.T2.7.7.1.m1.1.1.1.1.1.2" xref="S5.T2.7.7.1.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S5.T2.7.7.1.m1.1.1.1.1.1.1" xref="S5.T2.7.7.1.m1.1.1.1.1.1.1.cmml"><mn mathsize="80%" id="S5.T2.7.7.1.m1.1.1.1.1.1.1.2" xref="S5.T2.7.7.1.m1.1.1.1.1.1.1.2.cmml">60</mn><mo mathsize="80%" id="S5.T2.7.7.1.m1.1.1.1.1.1.1.1" xref="S5.T2.7.7.1.m1.1.1.1.1.1.1.1.cmml">%</mo></mrow><mo maxsize="80%" minsize="80%" id="S5.T2.7.7.1.m1.1.1.1.1.1.3" xref="S5.T2.7.7.1.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.7.7.1.m1.1b"><apply id="S5.T2.7.7.1.m1.1.1.cmml" xref="S5.T2.7.7.1.m1.1.1"><plus id="S5.T2.7.7.1.m1.1.1.2.cmml" xref="S5.T2.7.7.1.m1.1.1.2"></plus><ci id="S5.T2.7.7.1.m1.1.1.3a.cmml" xref="S5.T2.7.7.1.m1.1.1.3"><mtext mathsize="80%" id="S5.T2.7.7.1.m1.1.1.3.cmml" xref="S5.T2.7.7.1.m1.1.1.3">A</mtext></ci><apply id="S5.T2.7.7.1.m1.1.1.1.cmml" xref="S5.T2.7.7.1.m1.1.1.1"><times id="S5.T2.7.7.1.m1.1.1.1.2.cmml" xref="S5.T2.7.7.1.m1.1.1.1.2"></times><ci id="S5.T2.7.7.1.m1.1.1.1.3a.cmml" xref="S5.T2.7.7.1.m1.1.1.1.3"><mtext mathsize="80%" id="S5.T2.7.7.1.m1.1.1.1.3.cmml" xref="S5.T2.7.7.1.m1.1.1.1.3">G</mtext></ci><apply id="S5.T2.7.7.1.m1.1.1.1.1.1.1.cmml" xref="S5.T2.7.7.1.m1.1.1.1.1.1"><csymbol cd="latexml" id="S5.T2.7.7.1.m1.1.1.1.1.1.1.1.cmml" xref="S5.T2.7.7.1.m1.1.1.1.1.1.1.1">percent</csymbol><cn type="integer" id="S5.T2.7.7.1.m1.1.1.1.1.1.1.2.cmml" xref="S5.T2.7.7.1.m1.1.1.1.1.1.1.2">60</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.7.7.1.m1.1c">\text{A}+\text{G}\ (60\%)</annotation></semantics></math></th>
<td id="S5.T2.7.7.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.7.7.2.1" class="ltx_text" style="font-size:80%;">B</span></td>
<td id="S5.T2.7.7.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.7.7.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;color:#0000FF;">67.8%</span></td>
<td id="S5.T2.7.7.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.7.7.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;color:#0000FF;">71.6%</span></td>
<td id="S5.T2.7.7.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.7.7.5.1" class="ltx_text ltx_font_bold" style="font-size:80%;color:#0000FF;">69.7%</span></td>
</tr>
<tr id="S5.T2.12.15.3" class="ltx_tr">
<th id="S5.T2.12.15.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_tt"><span id="S5.T2.12.15.3.1.1" class="ltx_text" style="font-size:80%;">B</span></th>
<td id="S5.T2.12.15.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span id="S5.T2.12.15.3.2.1" class="ltx_text" style="font-size:80%;">B</span></td>
<td id="S5.T2.12.15.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span id="S5.T2.12.15.3.3.1" class="ltx_text" style="font-size:80%;">80.2%</span></td>
<td id="S5.T2.12.15.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span id="S5.T2.12.15.3.4.1" class="ltx_text" style="font-size:80%;">91.7%</span></td>
<td id="S5.T2.12.15.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span id="S5.T2.12.15.3.5.1" class="ltx_text" style="font-size:80%;">85.6%</span></td>
</tr>
<tr id="S5.T2.8.8" class="ltx_tr">
<th id="S5.T2.8.8.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r"><math id="S5.T2.8.8.1.m1.1" class="ltx_Math" alttext="\text{B}+\text{G}\textsubscript{N}\ (10\%)" display="inline"><semantics id="S5.T2.8.8.1.m1.1a"><mrow id="S5.T2.8.8.1.m1.1.1" xref="S5.T2.8.8.1.m1.1.1.cmml"><mtext mathsize="80%" id="S5.T2.8.8.1.m1.1.1.3" xref="S5.T2.8.8.1.m1.1.1.3a.cmml">B</mtext><mo mathsize="80%" id="S5.T2.8.8.1.m1.1.1.2" xref="S5.T2.8.8.1.m1.1.1.2.cmml">+</mo><mrow id="S5.T2.8.8.1.m1.1.1.1" xref="S5.T2.8.8.1.m1.1.1.1.cmml"><mrow id="S5.T2.8.8.1.m1.1.1.1.3" xref="S5.T2.8.8.1.m1.1.1.1.3e.cmml"><mtext mathsize="80%" id="S5.T2.8.8.1.m1.1.1.1.3a" xref="S5.T2.8.8.1.m1.1.1.1.3e.cmml">G</mtext><mtext id="S5.T2.8.8.1.m1.1.1.1.3b" xref="S5.T2.8.8.1.m1.1.1.1.3e.cmml"><sub id="S5.T2.8.8.1.m1.1.1.1.3.2nest" class="ltx_sub"><span id="S5.T2.8.8.1.m1.1.1.1.3.2.1nest" class="ltx_text" style="font-size:80%;">N</span></sub></mtext></mrow><mo lspace="0em" rspace="0em" id="S5.T2.8.8.1.m1.1.1.1.2" xref="S5.T2.8.8.1.m1.1.1.1.2.cmml">​</mo><mrow id="S5.T2.8.8.1.m1.1.1.1.1.1" xref="S5.T2.8.8.1.m1.1.1.1.1.1.1.cmml"><mo maxsize="80%" minsize="80%" id="S5.T2.8.8.1.m1.1.1.1.1.1.2" xref="S5.T2.8.8.1.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S5.T2.8.8.1.m1.1.1.1.1.1.1" xref="S5.T2.8.8.1.m1.1.1.1.1.1.1.cmml"><mn mathsize="80%" id="S5.T2.8.8.1.m1.1.1.1.1.1.1.2" xref="S5.T2.8.8.1.m1.1.1.1.1.1.1.2.cmml">10</mn><mo mathsize="80%" id="S5.T2.8.8.1.m1.1.1.1.1.1.1.1" xref="S5.T2.8.8.1.m1.1.1.1.1.1.1.1.cmml">%</mo></mrow><mo maxsize="80%" minsize="80%" id="S5.T2.8.8.1.m1.1.1.1.1.1.3" xref="S5.T2.8.8.1.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.8.8.1.m1.1b"><apply id="S5.T2.8.8.1.m1.1.1.cmml" xref="S5.T2.8.8.1.m1.1.1"><plus id="S5.T2.8.8.1.m1.1.1.2.cmml" xref="S5.T2.8.8.1.m1.1.1.2"></plus><ci id="S5.T2.8.8.1.m1.1.1.3a.cmml" xref="S5.T2.8.8.1.m1.1.1.3"><mtext mathsize="80%" id="S5.T2.8.8.1.m1.1.1.3.cmml" xref="S5.T2.8.8.1.m1.1.1.3">B</mtext></ci><apply id="S5.T2.8.8.1.m1.1.1.1.cmml" xref="S5.T2.8.8.1.m1.1.1.1"><times id="S5.T2.8.8.1.m1.1.1.1.2.cmml" xref="S5.T2.8.8.1.m1.1.1.1.2"></times><ci id="S5.T2.8.8.1.m1.1.1.1.3e.cmml" xref="S5.T2.8.8.1.m1.1.1.1.3"><mrow id="S5.T2.8.8.1.m1.1.1.1.3.cmml" xref="S5.T2.8.8.1.m1.1.1.1.3"><mtext mathsize="80%" id="S5.T2.8.8.1.m1.1.1.1.3a.cmml" xref="S5.T2.8.8.1.m1.1.1.1.3">G</mtext><mtext id="S5.T2.8.8.1.m1.1.1.1.3b.cmml" xref="S5.T2.8.8.1.m1.1.1.1.3"><sub id="S5.T2.8.8.1.m1.1.1.1.3.2anest" class="ltx_sub"><span id="S5.T2.8.8.1.m1.1.1.1.3.2.1anest" class="ltx_text" style="font-size:80%;">N</span></sub></mtext></mrow></ci><apply id="S5.T2.8.8.1.m1.1.1.1.1.1.1.cmml" xref="S5.T2.8.8.1.m1.1.1.1.1.1"><csymbol cd="latexml" id="S5.T2.8.8.1.m1.1.1.1.1.1.1.1.cmml" xref="S5.T2.8.8.1.m1.1.1.1.1.1.1.1">percent</csymbol><cn type="integer" id="S5.T2.8.8.1.m1.1.1.1.1.1.1.2.cmml" xref="S5.T2.8.8.1.m1.1.1.1.1.1.1.2">10</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.8.8.1.m1.1c">\text{B}+\text{G}\textsubscript{N}\ (10\%)</annotation></semantics></math></th>
<td id="S5.T2.8.8.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.8.8.2.1" class="ltx_text" style="font-size:80%;">B</span></td>
<td id="S5.T2.8.8.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.8.8.3.1" class="ltx_text" style="font-size:80%;">80.3%</span></td>
<td id="S5.T2.8.8.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.8.8.4.1" class="ltx_text" style="font-size:80%;">91.9%</span></td>
<td id="S5.T2.8.8.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.8.8.5.1" class="ltx_text" style="font-size:80%;">85.7%</span></td>
</tr>
<tr id="S5.T2.9.9" class="ltx_tr">
<th id="S5.T2.9.9.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r"><math id="S5.T2.9.9.1.m1.1" class="ltx_Math" alttext="\text{B}+\text{G}\textsubscript{C}\ (80\%)" display="inline"><semantics id="S5.T2.9.9.1.m1.1a"><mrow id="S5.T2.9.9.1.m1.1.1" xref="S5.T2.9.9.1.m1.1.1.cmml"><mtext mathsize="80%" id="S5.T2.9.9.1.m1.1.1.3" xref="S5.T2.9.9.1.m1.1.1.3a.cmml">B</mtext><mo mathsize="80%" id="S5.T2.9.9.1.m1.1.1.2" xref="S5.T2.9.9.1.m1.1.1.2.cmml">+</mo><mrow id="S5.T2.9.9.1.m1.1.1.1" xref="S5.T2.9.9.1.m1.1.1.1.cmml"><mrow id="S5.T2.9.9.1.m1.1.1.1.3" xref="S5.T2.9.9.1.m1.1.1.1.3e.cmml"><mtext mathsize="80%" id="S5.T2.9.9.1.m1.1.1.1.3a" xref="S5.T2.9.9.1.m1.1.1.1.3e.cmml">G</mtext><mtext id="S5.T2.9.9.1.m1.1.1.1.3b" xref="S5.T2.9.9.1.m1.1.1.1.3e.cmml"><sub id="S5.T2.9.9.1.m1.1.1.1.3.2nest" class="ltx_sub"><span id="S5.T2.9.9.1.m1.1.1.1.3.2.1nest" class="ltx_text" style="font-size:80%;">C</span></sub></mtext></mrow><mo lspace="0em" rspace="0em" id="S5.T2.9.9.1.m1.1.1.1.2" xref="S5.T2.9.9.1.m1.1.1.1.2.cmml">​</mo><mrow id="S5.T2.9.9.1.m1.1.1.1.1.1" xref="S5.T2.9.9.1.m1.1.1.1.1.1.1.cmml"><mo maxsize="80%" minsize="80%" id="S5.T2.9.9.1.m1.1.1.1.1.1.2" xref="S5.T2.9.9.1.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S5.T2.9.9.1.m1.1.1.1.1.1.1" xref="S5.T2.9.9.1.m1.1.1.1.1.1.1.cmml"><mn mathsize="80%" id="S5.T2.9.9.1.m1.1.1.1.1.1.1.2" xref="S5.T2.9.9.1.m1.1.1.1.1.1.1.2.cmml">80</mn><mo mathsize="80%" id="S5.T2.9.9.1.m1.1.1.1.1.1.1.1" xref="S5.T2.9.9.1.m1.1.1.1.1.1.1.1.cmml">%</mo></mrow><mo maxsize="80%" minsize="80%" id="S5.T2.9.9.1.m1.1.1.1.1.1.3" xref="S5.T2.9.9.1.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.9.9.1.m1.1b"><apply id="S5.T2.9.9.1.m1.1.1.cmml" xref="S5.T2.9.9.1.m1.1.1"><plus id="S5.T2.9.9.1.m1.1.1.2.cmml" xref="S5.T2.9.9.1.m1.1.1.2"></plus><ci id="S5.T2.9.9.1.m1.1.1.3a.cmml" xref="S5.T2.9.9.1.m1.1.1.3"><mtext mathsize="80%" id="S5.T2.9.9.1.m1.1.1.3.cmml" xref="S5.T2.9.9.1.m1.1.1.3">B</mtext></ci><apply id="S5.T2.9.9.1.m1.1.1.1.cmml" xref="S5.T2.9.9.1.m1.1.1.1"><times id="S5.T2.9.9.1.m1.1.1.1.2.cmml" xref="S5.T2.9.9.1.m1.1.1.1.2"></times><ci id="S5.T2.9.9.1.m1.1.1.1.3e.cmml" xref="S5.T2.9.9.1.m1.1.1.1.3"><mrow id="S5.T2.9.9.1.m1.1.1.1.3.cmml" xref="S5.T2.9.9.1.m1.1.1.1.3"><mtext mathsize="80%" id="S5.T2.9.9.1.m1.1.1.1.3a.cmml" xref="S5.T2.9.9.1.m1.1.1.1.3">G</mtext><mtext id="S5.T2.9.9.1.m1.1.1.1.3b.cmml" xref="S5.T2.9.9.1.m1.1.1.1.3"><sub id="S5.T2.9.9.1.m1.1.1.1.3.2anest" class="ltx_sub"><span id="S5.T2.9.9.1.m1.1.1.1.3.2.1anest" class="ltx_text" style="font-size:80%;">C</span></sub></mtext></mrow></ci><apply id="S5.T2.9.9.1.m1.1.1.1.1.1.1.cmml" xref="S5.T2.9.9.1.m1.1.1.1.1.1"><csymbol cd="latexml" id="S5.T2.9.9.1.m1.1.1.1.1.1.1.1.cmml" xref="S5.T2.9.9.1.m1.1.1.1.1.1.1.1">percent</csymbol><cn type="integer" id="S5.T2.9.9.1.m1.1.1.1.1.1.1.2.cmml" xref="S5.T2.9.9.1.m1.1.1.1.1.1.1.2">80</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.9.9.1.m1.1c">\text{B}+\text{G}\textsubscript{C}\ (80\%)</annotation></semantics></math></th>
<td id="S5.T2.9.9.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.9.9.2.1" class="ltx_text" style="font-size:80%;">B</span></td>
<td id="S5.T2.9.9.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.9.9.3.1" class="ltx_text" style="font-size:80%;">79.4%</span></td>
<td id="S5.T2.9.9.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.9.9.4.1" class="ltx_text" style="font-size:80%;">90.6%</span></td>
<td id="S5.T2.9.9.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.9.9.5.1" class="ltx_text" style="font-size:80%;">84.7%</span></td>
</tr>
<tr id="S5.T2.12.16.4" class="ltx_tr">
<th id="S5.T2.12.16.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="S5.T2.12.16.4.1.1" class="ltx_text" style="font-size:80%;">B</span></th>
<td id="S5.T2.12.16.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T2.12.16.4.2.1" class="ltx_text" style="font-size:80%;">A</span></td>
<td id="S5.T2.12.16.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T2.12.16.4.3.1" class="ltx_text" style="font-size:80%;">2.8%</span></td>
<td id="S5.T2.12.16.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T2.12.16.4.4.1" class="ltx_text" style="font-size:80%;">3.7%</span></td>
<td id="S5.T2.12.16.4.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T2.12.16.4.5.1" class="ltx_text" style="font-size:80%;">3.2%</span></td>
</tr>
<tr id="S5.T2.10.10" class="ltx_tr">
<th id="S5.T2.10.10.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r"><math id="S5.T2.10.10.1.m1.1" class="ltx_Math" alttext="\text{B}+\text{G}\textsubscript{N}\ (10\%)" display="inline"><semantics id="S5.T2.10.10.1.m1.1a"><mrow id="S5.T2.10.10.1.m1.1.1" xref="S5.T2.10.10.1.m1.1.1.cmml"><mtext mathsize="80%" id="S5.T2.10.10.1.m1.1.1.3" xref="S5.T2.10.10.1.m1.1.1.3a.cmml">B</mtext><mo mathsize="80%" id="S5.T2.10.10.1.m1.1.1.2" xref="S5.T2.10.10.1.m1.1.1.2.cmml">+</mo><mrow id="S5.T2.10.10.1.m1.1.1.1" xref="S5.T2.10.10.1.m1.1.1.1.cmml"><mrow id="S5.T2.10.10.1.m1.1.1.1.3" xref="S5.T2.10.10.1.m1.1.1.1.3e.cmml"><mtext mathsize="80%" id="S5.T2.10.10.1.m1.1.1.1.3a" xref="S5.T2.10.10.1.m1.1.1.1.3e.cmml">G</mtext><mtext id="S5.T2.10.10.1.m1.1.1.1.3b" xref="S5.T2.10.10.1.m1.1.1.1.3e.cmml"><sub id="S5.T2.10.10.1.m1.1.1.1.3.2nest" class="ltx_sub"><span id="S5.T2.10.10.1.m1.1.1.1.3.2.1nest" class="ltx_text" style="font-size:80%;">N</span></sub></mtext></mrow><mo lspace="0em" rspace="0em" id="S5.T2.10.10.1.m1.1.1.1.2" xref="S5.T2.10.10.1.m1.1.1.1.2.cmml">​</mo><mrow id="S5.T2.10.10.1.m1.1.1.1.1.1" xref="S5.T2.10.10.1.m1.1.1.1.1.1.1.cmml"><mo maxsize="80%" minsize="80%" id="S5.T2.10.10.1.m1.1.1.1.1.1.2" xref="S5.T2.10.10.1.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S5.T2.10.10.1.m1.1.1.1.1.1.1" xref="S5.T2.10.10.1.m1.1.1.1.1.1.1.cmml"><mn mathsize="80%" id="S5.T2.10.10.1.m1.1.1.1.1.1.1.2" xref="S5.T2.10.10.1.m1.1.1.1.1.1.1.2.cmml">10</mn><mo mathsize="80%" id="S5.T2.10.10.1.m1.1.1.1.1.1.1.1" xref="S5.T2.10.10.1.m1.1.1.1.1.1.1.1.cmml">%</mo></mrow><mo maxsize="80%" minsize="80%" id="S5.T2.10.10.1.m1.1.1.1.1.1.3" xref="S5.T2.10.10.1.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.10.10.1.m1.1b"><apply id="S5.T2.10.10.1.m1.1.1.cmml" xref="S5.T2.10.10.1.m1.1.1"><plus id="S5.T2.10.10.1.m1.1.1.2.cmml" xref="S5.T2.10.10.1.m1.1.1.2"></plus><ci id="S5.T2.10.10.1.m1.1.1.3a.cmml" xref="S5.T2.10.10.1.m1.1.1.3"><mtext mathsize="80%" id="S5.T2.10.10.1.m1.1.1.3.cmml" xref="S5.T2.10.10.1.m1.1.1.3">B</mtext></ci><apply id="S5.T2.10.10.1.m1.1.1.1.cmml" xref="S5.T2.10.10.1.m1.1.1.1"><times id="S5.T2.10.10.1.m1.1.1.1.2.cmml" xref="S5.T2.10.10.1.m1.1.1.1.2"></times><ci id="S5.T2.10.10.1.m1.1.1.1.3e.cmml" xref="S5.T2.10.10.1.m1.1.1.1.3"><mrow id="S5.T2.10.10.1.m1.1.1.1.3.cmml" xref="S5.T2.10.10.1.m1.1.1.1.3"><mtext mathsize="80%" id="S5.T2.10.10.1.m1.1.1.1.3a.cmml" xref="S5.T2.10.10.1.m1.1.1.1.3">G</mtext><mtext id="S5.T2.10.10.1.m1.1.1.1.3b.cmml" xref="S5.T2.10.10.1.m1.1.1.1.3"><sub id="S5.T2.10.10.1.m1.1.1.1.3.2anest" class="ltx_sub"><span id="S5.T2.10.10.1.m1.1.1.1.3.2.1anest" class="ltx_text" style="font-size:80%;">N</span></sub></mtext></mrow></ci><apply id="S5.T2.10.10.1.m1.1.1.1.1.1.1.cmml" xref="S5.T2.10.10.1.m1.1.1.1.1.1"><csymbol cd="latexml" id="S5.T2.10.10.1.m1.1.1.1.1.1.1.1.cmml" xref="S5.T2.10.10.1.m1.1.1.1.1.1.1.1">percent</csymbol><cn type="integer" id="S5.T2.10.10.1.m1.1.1.1.1.1.1.2.cmml" xref="S5.T2.10.10.1.m1.1.1.1.1.1.1.2">10</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.10.10.1.m1.1c">\text{B}+\text{G}\textsubscript{N}\ (10\%)</annotation></semantics></math></th>
<td id="S5.T2.10.10.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.10.10.2.1" class="ltx_text" style="font-size:80%;">A</span></td>
<td id="S5.T2.10.10.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.10.10.3.1" class="ltx_text" style="font-size:80%;">5.9%</span></td>
<td id="S5.T2.10.10.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.10.10.4.1" class="ltx_text" style="font-size:80%;">7.8%</span></td>
<td id="S5.T2.10.10.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.10.10.5.1" class="ltx_text" style="font-size:80%;">6.7%</span></td>
</tr>
<tr id="S5.T2.11.11" class="ltx_tr">
<th id="S5.T2.11.11.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r"><math id="S5.T2.11.11.1.m1.1" class="ltx_Math" alttext="\text{B}+\text{G}\textsubscript{C}\ (80\%)" display="inline"><semantics id="S5.T2.11.11.1.m1.1a"><mrow id="S5.T2.11.11.1.m1.1.1" xref="S5.T2.11.11.1.m1.1.1.cmml"><mtext mathsize="80%" id="S5.T2.11.11.1.m1.1.1.3" xref="S5.T2.11.11.1.m1.1.1.3a.cmml">B</mtext><mo mathsize="80%" id="S5.T2.11.11.1.m1.1.1.2" xref="S5.T2.11.11.1.m1.1.1.2.cmml">+</mo><mrow id="S5.T2.11.11.1.m1.1.1.1" xref="S5.T2.11.11.1.m1.1.1.1.cmml"><mrow id="S5.T2.11.11.1.m1.1.1.1.3" xref="S5.T2.11.11.1.m1.1.1.1.3e.cmml"><mtext mathsize="80%" id="S5.T2.11.11.1.m1.1.1.1.3a" xref="S5.T2.11.11.1.m1.1.1.1.3e.cmml">G</mtext><mtext id="S5.T2.11.11.1.m1.1.1.1.3b" xref="S5.T2.11.11.1.m1.1.1.1.3e.cmml"><sub id="S5.T2.11.11.1.m1.1.1.1.3.2nest" class="ltx_sub"><span id="S5.T2.11.11.1.m1.1.1.1.3.2.1nest" class="ltx_text" style="font-size:80%;">C</span></sub></mtext></mrow><mo lspace="0em" rspace="0em" id="S5.T2.11.11.1.m1.1.1.1.2" xref="S5.T2.11.11.1.m1.1.1.1.2.cmml">​</mo><mrow id="S5.T2.11.11.1.m1.1.1.1.1.1" xref="S5.T2.11.11.1.m1.1.1.1.1.1.1.cmml"><mo maxsize="80%" minsize="80%" id="S5.T2.11.11.1.m1.1.1.1.1.1.2" xref="S5.T2.11.11.1.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S5.T2.11.11.1.m1.1.1.1.1.1.1" xref="S5.T2.11.11.1.m1.1.1.1.1.1.1.cmml"><mn mathsize="80%" id="S5.T2.11.11.1.m1.1.1.1.1.1.1.2" xref="S5.T2.11.11.1.m1.1.1.1.1.1.1.2.cmml">80</mn><mo mathsize="80%" id="S5.T2.11.11.1.m1.1.1.1.1.1.1.1" xref="S5.T2.11.11.1.m1.1.1.1.1.1.1.1.cmml">%</mo></mrow><mo maxsize="80%" minsize="80%" id="S5.T2.11.11.1.m1.1.1.1.1.1.3" xref="S5.T2.11.11.1.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.11.11.1.m1.1b"><apply id="S5.T2.11.11.1.m1.1.1.cmml" xref="S5.T2.11.11.1.m1.1.1"><plus id="S5.T2.11.11.1.m1.1.1.2.cmml" xref="S5.T2.11.11.1.m1.1.1.2"></plus><ci id="S5.T2.11.11.1.m1.1.1.3a.cmml" xref="S5.T2.11.11.1.m1.1.1.3"><mtext mathsize="80%" id="S5.T2.11.11.1.m1.1.1.3.cmml" xref="S5.T2.11.11.1.m1.1.1.3">B</mtext></ci><apply id="S5.T2.11.11.1.m1.1.1.1.cmml" xref="S5.T2.11.11.1.m1.1.1.1"><times id="S5.T2.11.11.1.m1.1.1.1.2.cmml" xref="S5.T2.11.11.1.m1.1.1.1.2"></times><ci id="S5.T2.11.11.1.m1.1.1.1.3e.cmml" xref="S5.T2.11.11.1.m1.1.1.1.3"><mrow id="S5.T2.11.11.1.m1.1.1.1.3.cmml" xref="S5.T2.11.11.1.m1.1.1.1.3"><mtext mathsize="80%" id="S5.T2.11.11.1.m1.1.1.1.3a.cmml" xref="S5.T2.11.11.1.m1.1.1.1.3">G</mtext><mtext id="S5.T2.11.11.1.m1.1.1.1.3b.cmml" xref="S5.T2.11.11.1.m1.1.1.1.3"><sub id="S5.T2.11.11.1.m1.1.1.1.3.2anest" class="ltx_sub"><span id="S5.T2.11.11.1.m1.1.1.1.3.2.1anest" class="ltx_text" style="font-size:80%;">C</span></sub></mtext></mrow></ci><apply id="S5.T2.11.11.1.m1.1.1.1.1.1.1.cmml" xref="S5.T2.11.11.1.m1.1.1.1.1.1"><csymbol cd="latexml" id="S5.T2.11.11.1.m1.1.1.1.1.1.1.1.cmml" xref="S5.T2.11.11.1.m1.1.1.1.1.1.1.1">percent</csymbol><cn type="integer" id="S5.T2.11.11.1.m1.1.1.1.1.1.1.2.cmml" xref="S5.T2.11.11.1.m1.1.1.1.1.1.1.2">80</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.11.11.1.m1.1c">\text{B}+\text{G}\textsubscript{C}\ (80\%)</annotation></semantics></math></th>
<td id="S5.T2.11.11.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.11.11.2.1" class="ltx_text" style="font-size:80%;">A</span></td>
<td id="S5.T2.11.11.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.11.11.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">6.6%</span></td>
<td id="S5.T2.11.11.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.11.11.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">8.7%</span></td>
<td id="S5.T2.11.11.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.11.11.5.1" class="ltx_text ltx_font_bold" style="font-size:80%;">7.5%</span></td>
</tr>
<tr id="S5.T2.12.17.5" class="ltx_tr">
<th id="S5.T2.12.17.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="S5.T2.12.17.5.1.1" class="ltx_text" style="font-size:80%;">B</span></th>
<td id="S5.T2.12.17.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="S5.T2.12.17.5.2.1" class="ltx_text" style="font-size:80%;">A</span><sub id="S5.T2.12.17.5.2.2" class="ltx_sub"><span id="S5.T2.12.17.5.2.2.1" class="ltx_text" style="font-size:80%;">N</span></sub>
</td>
<td id="S5.T2.12.17.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T2.12.17.5.3.1" class="ltx_text" style="font-size:80%;">0.2%</span></td>
<td id="S5.T2.12.17.5.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T2.12.17.5.4.1" class="ltx_text" style="font-size:80%;">0.3%</span></td>
<td id="S5.T2.12.17.5.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T2.12.17.5.5.1" class="ltx_text" style="font-size:80%;">0.2%</span></td>
</tr>
<tr id="S5.T2.12.12" class="ltx_tr">
<th id="S5.T2.12.12.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_l ltx_border_r"><math id="S5.T2.12.12.1.m1.1" class="ltx_Math" alttext="\text{B}+\text{G}\textsubscript{N}\ (10\%)" display="inline"><semantics id="S5.T2.12.12.1.m1.1a"><mrow id="S5.T2.12.12.1.m1.1.1" xref="S5.T2.12.12.1.m1.1.1.cmml"><mtext mathsize="80%" id="S5.T2.12.12.1.m1.1.1.3" xref="S5.T2.12.12.1.m1.1.1.3a.cmml">B</mtext><mo mathsize="80%" id="S5.T2.12.12.1.m1.1.1.2" xref="S5.T2.12.12.1.m1.1.1.2.cmml">+</mo><mrow id="S5.T2.12.12.1.m1.1.1.1" xref="S5.T2.12.12.1.m1.1.1.1.cmml"><mrow id="S5.T2.12.12.1.m1.1.1.1.3" xref="S5.T2.12.12.1.m1.1.1.1.3e.cmml"><mtext mathsize="80%" id="S5.T2.12.12.1.m1.1.1.1.3a" xref="S5.T2.12.12.1.m1.1.1.1.3e.cmml">G</mtext><mtext id="S5.T2.12.12.1.m1.1.1.1.3b" xref="S5.T2.12.12.1.m1.1.1.1.3e.cmml"><sub id="S5.T2.12.12.1.m1.1.1.1.3.2nest" class="ltx_sub"><span id="S5.T2.12.12.1.m1.1.1.1.3.2.1nest" class="ltx_text" style="font-size:80%;">N</span></sub></mtext></mrow><mo lspace="0em" rspace="0em" id="S5.T2.12.12.1.m1.1.1.1.2" xref="S5.T2.12.12.1.m1.1.1.1.2.cmml">​</mo><mrow id="S5.T2.12.12.1.m1.1.1.1.1.1" xref="S5.T2.12.12.1.m1.1.1.1.1.1.1.cmml"><mo maxsize="80%" minsize="80%" id="S5.T2.12.12.1.m1.1.1.1.1.1.2" xref="S5.T2.12.12.1.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S5.T2.12.12.1.m1.1.1.1.1.1.1" xref="S5.T2.12.12.1.m1.1.1.1.1.1.1.cmml"><mn mathsize="80%" id="S5.T2.12.12.1.m1.1.1.1.1.1.1.2" xref="S5.T2.12.12.1.m1.1.1.1.1.1.1.2.cmml">10</mn><mo mathsize="80%" id="S5.T2.12.12.1.m1.1.1.1.1.1.1.1" xref="S5.T2.12.12.1.m1.1.1.1.1.1.1.1.cmml">%</mo></mrow><mo maxsize="80%" minsize="80%" id="S5.T2.12.12.1.m1.1.1.1.1.1.3" xref="S5.T2.12.12.1.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.12.12.1.m1.1b"><apply id="S5.T2.12.12.1.m1.1.1.cmml" xref="S5.T2.12.12.1.m1.1.1"><plus id="S5.T2.12.12.1.m1.1.1.2.cmml" xref="S5.T2.12.12.1.m1.1.1.2"></plus><ci id="S5.T2.12.12.1.m1.1.1.3a.cmml" xref="S5.T2.12.12.1.m1.1.1.3"><mtext mathsize="80%" id="S5.T2.12.12.1.m1.1.1.3.cmml" xref="S5.T2.12.12.1.m1.1.1.3">B</mtext></ci><apply id="S5.T2.12.12.1.m1.1.1.1.cmml" xref="S5.T2.12.12.1.m1.1.1.1"><times id="S5.T2.12.12.1.m1.1.1.1.2.cmml" xref="S5.T2.12.12.1.m1.1.1.1.2"></times><ci id="S5.T2.12.12.1.m1.1.1.1.3e.cmml" xref="S5.T2.12.12.1.m1.1.1.1.3"><mrow id="S5.T2.12.12.1.m1.1.1.1.3.cmml" xref="S5.T2.12.12.1.m1.1.1.1.3"><mtext mathsize="80%" id="S5.T2.12.12.1.m1.1.1.1.3a.cmml" xref="S5.T2.12.12.1.m1.1.1.1.3">G</mtext><mtext id="S5.T2.12.12.1.m1.1.1.1.3b.cmml" xref="S5.T2.12.12.1.m1.1.1.1.3"><sub id="S5.T2.12.12.1.m1.1.1.1.3.2anest" class="ltx_sub"><span id="S5.T2.12.12.1.m1.1.1.1.3.2.1anest" class="ltx_text" style="font-size:80%;">N</span></sub></mtext></mrow></ci><apply id="S5.T2.12.12.1.m1.1.1.1.1.1.1.cmml" xref="S5.T2.12.12.1.m1.1.1.1.1.1"><csymbol cd="latexml" id="S5.T2.12.12.1.m1.1.1.1.1.1.1.1.cmml" xref="S5.T2.12.12.1.m1.1.1.1.1.1.1.1">percent</csymbol><cn type="integer" id="S5.T2.12.12.1.m1.1.1.1.1.1.1.2.cmml" xref="S5.T2.12.12.1.m1.1.1.1.1.1.1.2">10</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.12.12.1.m1.1c">\text{B}+\text{G}\textsubscript{N}\ (10\%)</annotation></semantics></math></th>
<td id="S5.T2.12.12.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">
<span id="S5.T2.12.12.2.1" class="ltx_text" style="font-size:80%;">A</span><sub id="S5.T2.12.12.2.2" class="ltx_sub"><span id="S5.T2.12.12.2.2.1" class="ltx_text" style="font-size:80%;">N</span></sub>
</td>
<td id="S5.T2.12.12.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S5.T2.12.12.3.1" class="ltx_text" style="font-size:80%;">2.3%</span></td>
<td id="S5.T2.12.12.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S5.T2.12.12.4.1" class="ltx_text" style="font-size:80%;">3.1%</span></td>
<td id="S5.T2.12.12.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S5.T2.12.12.5.1" class="ltx_text" style="font-size:80%;">2.6%</span></td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Results</h3>

<div id="S5.SS3.p1" class="ltx_para">
<p id="S5.SS3.p1.1" class="ltx_p"><span id="S5.SS3.p1.1.1" class="ltx_text ltx_font_bold">Experiment I:</span> Consistent with the cross-testing results in Section <a href="#S4" title="4 Case Study: Parking Slot Detection ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, as shown in Table <a href="#S5.T2" title="Table 2 ‣ 5.2 Experiment Details ‣ 5 Case Study: Traffic Lane Detection ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, SCNN trained on CULane results in a F-Measure of 60.9% on the CULane test set (1<sup id="S5.SS3.p1.1.2" class="ltx_sup">st</sup> row) versus 49.8% on the TuSimple test set (4<sup id="S5.SS3.p1.1.3" class="ltx_sup">th</sup> row). This drop in accuracy can again be attributed to the large domain gap between the two datasets (see Fig. <a href="#S5.F6" title="Figure 6 ‣ 5.1 Dataset Description ‣ 5 Case Study: Traffic Lane Detection ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>). Fig. <a href="#S5.F7" title="Figure 7 ‣ 5.1 Dataset Description ‣ 5 Case Study: Traffic Lane Detection ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> shows that models trained with a mix of real and sim2real translated data (blue) consistently outperform models trained with a mix of real and simulated data (green) in cross-testing. Moreover, as the ratio of synthetic data in the training set increases, the gap between models trained on GAN data and simulated data grows wider. Both these observations together verify the closeness of the GAN data to the real data as compared to just simulated data. More interestingly, for certain ratios of synthetic data, the models trained on a mix of real and synthetic data significantly outperform models trained with 100% real data. Table <a href="#S5.T2" title="Table 2 ‣ 5.2 Experiment Details ‣ 5 Case Study: Traffic Lane Detection ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> (top) summarizes the results from the best models in terms of F-Measure - 69.7% for model trained on a 40:60 mix of real and GAN data and 66.9% for model trained on a 70:30 mix of real and sim data versus just 49.8% for model trained on 100% real data (note the size of the training dataset was held constant across all experiments). These results confirm that synthetic data augmentation can help deflate dataset bias and thus improve cross-dataset generalization performance. Again, similar to the observations in Section <a href="#S4.SS2" title="4.2 Results ‣ 4 Case Study: Parking Slot Detection ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>, the drop in accuracy on the original test set is minimal.

<br class="ltx_break"><span id="S5.SS3.p1.1.4" class="ltx_text ltx_font_bold">Experiment II:</span> Consistent with previous results, SCNN trained on TuSimple gives an F-measure of 85.6% on the TuSimple test set versus only 3.2% on the CULane test set (7<sup id="S5.SS3.p1.1.5" class="ltx_sup">th</sup> row vs. 10<sup id="S5.SS3.p1.1.6" class="ltx_sup">th</sup> row in Table <a href="#S5.T2" title="Table 2 ‣ 5.2 Experiment Details ‣ 5 Case Study: Traffic Lane Detection ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>). The drop in accuracy is more prominent in this case as TuSimple is a much simpler dataset as compared to CULane both in terms of quantity and diversity. Table <a href="#S5.T2" title="Table 2 ‣ 5.2 Experiment Details ‣ 5 Case Study: Traffic Lane Detection ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> shows that adding nighttime and cloudy data helps improve cross-dataset generalization performance, with models trained on a mix of real and GAN-generated cloudy data faring the best among all (12<sup id="S5.SS3.p1.1.7" class="ltx_sup">th</sup> row in green). Since CULane had the nighttime images labeled in their test set, we compared the performance of models trained on TuSimple only with models trained on a mix of TuSimple and GAN nighttime images and again, consistent with our motivating hypothesis <span id="S5.SS3.p1.1.8" class="ltx_text ltx_font_typewriter">H</span>, the latter models do better (last row).</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Case Study: Monocular Depth Estimation</h2>

<figure id="S6.F8" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S6.F8.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2004.13866/assets/figs/depth/real_000055.png" id="S6.F8.1.g1" class="ltx_graphics ltx_img_landscape" width="598" height="115" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S6.F8.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2004.13866/assets/figs/depth/sim_00055.png" id="S6.F8.2.g1" class="ltx_graphics ltx_img_landscape" width="598" height="115" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S6.F8.3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2004.13866/assets/figs/depth/s2r_00055.png" id="S6.F8.3.g1" class="ltx_graphics ltx_img_landscape" width="598" height="106" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S6.F8.4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2004.13866/assets/figs/depth/depth_gt_00055.png" id="S6.F8.4.g1" class="ltx_graphics ltx_img_landscape" width="598" height="115" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S6.F8.5" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2004.13866/assets/figs/depth/depth_sim_40_60_000055.png" id="S6.F8.5.g1" class="ltx_graphics ltx_img_landscape" width="598" height="114" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S6.F8.6" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2004.13866/assets/figs/depth/depth_s2r_40_60_000055.png" id="S6.F8.6.g1" class="ltx_graphics ltx_img_landscape" width="598" height="114" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S6.F8.7" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2004.13866/assets/figs/depth/depth_s2r_20_80_000055.png" id="S6.F8.7.g1" class="ltx_graphics ltx_img_landscape" width="598" height="114" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S6.F8.15.4.1" class="ltx_text" style="font-size:90%;">Figure 8</span>: </span><span id="S6.F8.13.3" class="ltx_text" style="font-size:90%;">From top to bottom: KITTI RGB, vKITTI RGB, sim2real, ground truth depth, estimated depth A+S (<math id="S6.F8.11.1.m1.1" class="ltx_Math" alttext="60\%" display="inline"><semantics id="S6.F8.11.1.m1.1b"><mrow id="S6.F8.11.1.m1.1.1" xref="S6.F8.11.1.m1.1.1.cmml"><mn id="S6.F8.11.1.m1.1.1.2" xref="S6.F8.11.1.m1.1.1.2.cmml">60</mn><mo id="S6.F8.11.1.m1.1.1.1" xref="S6.F8.11.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.F8.11.1.m1.1c"><apply id="S6.F8.11.1.m1.1.1.cmml" xref="S6.F8.11.1.m1.1.1"><csymbol cd="latexml" id="S6.F8.11.1.m1.1.1.1.cmml" xref="S6.F8.11.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S6.F8.11.1.m1.1.1.2.cmml" xref="S6.F8.11.1.m1.1.1.2">60</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.F8.11.1.m1.1d">60\%</annotation></semantics></math>), estimated depth A+G (<math id="S6.F8.12.2.m2.1" class="ltx_Math" alttext="60\%" display="inline"><semantics id="S6.F8.12.2.m2.1b"><mrow id="S6.F8.12.2.m2.1.1" xref="S6.F8.12.2.m2.1.1.cmml"><mn id="S6.F8.12.2.m2.1.1.2" xref="S6.F8.12.2.m2.1.1.2.cmml">60</mn><mo id="S6.F8.12.2.m2.1.1.1" xref="S6.F8.12.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.F8.12.2.m2.1c"><apply id="S6.F8.12.2.m2.1.1.cmml" xref="S6.F8.12.2.m2.1.1"><csymbol cd="latexml" id="S6.F8.12.2.m2.1.1.1.cmml" xref="S6.F8.12.2.m2.1.1.1">percent</csymbol><cn type="integer" id="S6.F8.12.2.m2.1.1.2.cmml" xref="S6.F8.12.2.m2.1.1.2">60</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.F8.12.2.m2.1d">60\%</annotation></semantics></math>) and estimated depth A+G (<math id="S6.F8.13.3.m3.1" class="ltx_Math" alttext="20\%" display="inline"><semantics id="S6.F8.13.3.m3.1b"><mrow id="S6.F8.13.3.m3.1.1" xref="S6.F8.13.3.m3.1.1.cmml"><mn id="S6.F8.13.3.m3.1.1.2" xref="S6.F8.13.3.m3.1.1.2.cmml">20</mn><mo id="S6.F8.13.3.m3.1.1.1" xref="S6.F8.13.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.F8.13.3.m3.1c"><apply id="S6.F8.13.3.m3.1.1.cmml" xref="S6.F8.13.3.m3.1.1"><csymbol cd="latexml" id="S6.F8.13.3.m3.1.1.1.cmml" xref="S6.F8.13.3.m3.1.1.1">percent</csymbol><cn type="integer" id="S6.F8.13.3.m3.1.1.2.cmml" xref="S6.F8.13.3.m3.1.1.2">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.F8.13.3.m3.1d">20\%</annotation></semantics></math>). Networks were trained with unpaired data. Paired images are used for illustrative purposes only.
</span></figcaption>
</figure>
<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">In this case study, experiments are conducted for the task of estimating the depth in a scene from a single RGB image  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite>. We employ an encoder-decoder architecture with skip connections and train the network in a supervised fashion with MSE and edge-aware losses <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> between the ground truth and estimated depth maps.</p>
</div>
<section id="S6.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1 </span>Dataset Description</h3>

<div id="S6.SS1.p1" class="ltx_para">
<p id="S6.SS1.p1.1" class="ltx_p">We use KITTI <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> and virtual KITTI (vKITTI) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> as our real and simulated datasets. The vKITTI dataset is a scene-by-scene recreation of the KITTI tracking dataset, also using the Unreal gaming engine. However, we don’t use any paired data for our experiments. We also do not use data from the same sequences as the real data for our simulated data.

<br class="ltx_break"><span id="S6.SS1.p1.1.1" class="ltx_text ltx_font_bold">Real Data:</span>
We use the KITTI odometry sequence 00, with a total of 4,540 images as our real training set - <span id="S6.SS1.p1.1.2" class="ltx_text ltx_font_bold">A</span>. The KITTI Odometry sequences 02 and 05, with a cumulative 500 images, are used as the real test set - <span id="S6.SS1.p1.1.3" class="ltx_text ltx_font_bold">B</span>. Ground truth depth is generated by using the OpenCV implementation of the stereo algorithm SGBM with WLS filtering on the left and right images. Note that since we did not make use of paired images between the simulated and real datasets, we could not use simulated depth as ground truth. Moreover, while the simulated recreation in vKITTI approaches that of real KITTI, the simulacrum is not exact, and this would have resulted in systematic biases in the learning of depth. This can be seen in rows 1 and 2 (KITTI and vKITTI) of Figure <a href="#S6.F8" title="Figure 8 ‣ 6 Case Study: Monocular Depth Estimation ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>, where the virtual clone of the tree trunk on the right sidewalk is subtly different and slightly shifted.

<br class="ltx_break"><span id="S6.SS1.p1.1.4" class="ltx_text ltx_font_bold">Synthetic Data:</span>
We use data from vKITTI scenes 1, 2, 6, 18 and 20, under the Clone, Morning, 15L and 15R subsets, resulting in a total of 2,126 images per subset, and an overall total of 8,504 images.
These vKITTI scenes are clones of the KITTI Tracking dataset (Clone), with variation in camera angles (15L/R) and time of the day (Morning).
Note that the KITTI Tracking sequences (duplicated in vKITTI) are captured in a different environment compared to the KITTI Odometry dataset, which form part of our Real set. This variation in sequence geographical location, time of the day and camera pan angles represent the noise factors for this task.
A set of randomly picked 4,540 images from this total is used as the source of simulated data for training - <span id="S6.SS1.p1.1.5" class="ltx_text ltx_font_bold">S</span>. We use cycleGAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite>, trained with unpaired images from KITTI and vKITTI to convert the 4,540 sampled images from vKITTI to make them more realistic. This forms our sim2real translated dataset - <span id="S6.SS1.p1.1.6" class="ltx_text ltx_font_bold">G</span>.
<br class="ltx_break"></p>
</div>
</section>
<section id="S6.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2 </span>Experiment Details</h3>

<div id="S6.SS2.p1" class="ltx_para">
<p id="S6.SS2.p1.2" class="ltx_p">As with the other tasks, we train the task network with different percentages of simulated (<span id="S6.SS2.p1.2.1" class="ltx_text ltx_font_bold">A + S</span>) and sim2real (<span id="S6.SS2.p1.2.2" class="ltx_text ltx_font_bold">A + G</span>) data, starting from <math id="S6.SS2.p1.1.m1.1" class="ltx_Math" alttext="0\%" display="inline"><semantics id="S6.SS2.p1.1.m1.1a"><mrow id="S6.SS2.p1.1.m1.1.1" xref="S6.SS2.p1.1.m1.1.1.cmml"><mn id="S6.SS2.p1.1.m1.1.1.2" xref="S6.SS2.p1.1.m1.1.1.2.cmml">0</mn><mo id="S6.SS2.p1.1.m1.1.1.1" xref="S6.SS2.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.SS2.p1.1.m1.1b"><apply id="S6.SS2.p1.1.m1.1.1.cmml" xref="S6.SS2.p1.1.m1.1.1"><csymbol cd="latexml" id="S6.SS2.p1.1.m1.1.1.1.cmml" xref="S6.SS2.p1.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S6.SS2.p1.1.m1.1.1.2.cmml" xref="S6.SS2.p1.1.m1.1.1.2">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.p1.1.m1.1c">0\%</annotation></semantics></math> to <math id="S6.SS2.p1.2.m2.1" class="ltx_Math" alttext="100\%" display="inline"><semantics id="S6.SS2.p1.2.m2.1a"><mrow id="S6.SS2.p1.2.m2.1.1" xref="S6.SS2.p1.2.m2.1.1.cmml"><mn id="S6.SS2.p1.2.m2.1.1.2" xref="S6.SS2.p1.2.m2.1.1.2.cmml">100</mn><mo id="S6.SS2.p1.2.m2.1.1.1" xref="S6.SS2.p1.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.SS2.p1.2.m2.1b"><apply id="S6.SS2.p1.2.m2.1.1.cmml" xref="S6.SS2.p1.2.m2.1.1"><csymbol cd="latexml" id="S6.SS2.p1.2.m2.1.1.1.cmml" xref="S6.SS2.p1.2.m2.1.1.1">percent</csymbol><cn type="integer" id="S6.SS2.p1.2.m2.1.1.2.cmml" xref="S6.SS2.p1.2.m2.1.1.2">100</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.p1.2.m2.1c">100\%</annotation></semantics></math> and test on KITTI sequences that were not seen during training (<span id="S6.SS2.p1.2.3" class="ltx_text ltx_font_bold">B</span>). We use the Root Mean Squared Error (RMSE) metric to determine the performance of the network trained on a particular sim/real or sim2real/real mix, after limiting maximum depth to 100m.
We provide detailed RMSE results in Figure <a href="#S6.F9" title="Figure 9 ‣ 6.3 Results ‣ 6 Case Study: Monocular Depth Estimation ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>. We also tested this task based on accuracy of depth estimation, measured as the ratio of correctly estimated depth pixels to the total number of depth pixels. These results are summarized, along with RMSE in Table <a href="#S6.T3" title="Table 3 ‣ 6.3 Results ‣ 6 Case Study: Monocular Depth Estimation ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> and more detailed results for accuracy are provided in the Supplementary Material. RMSE and accuracy are common metrics used in prior work on single image depth <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>. A lower value of RMSE indicates better performance while the same is true for a higher value for accuracy.</p>
</div>
</section>
<section id="S6.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.3 </span>Results</h3>

<div id="S6.SS3.p1" class="ltx_para">
<p id="S6.SS3.p1.1" class="ltx_p">Figure <a href="#S6.F9" title="Figure 9 ‣ 6.3 Results ‣ 6 Case Study: Monocular Depth Estimation ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a> shows RMSE for the different mixes of real (yellow), real + simulated (A+S, Sim, green) and real + sim2real (A+G, GAN, blue) training data. Some important highlights of the same are shown in Table <a href="#S6.T3" title="Table 3 ‣ 6.3 Results ‣ 6 Case Study: Monocular Depth Estimation ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
<div id="S6.SS3.p1.2" class="ltx_logical-block">
<figure id="S6.F9" class="ltx_figure ltx_align_center"><img src="/html/2004.13866/assets/x9.png" id="S6.F9.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="392" height="259" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S6.F9.2.1.1" class="ltx_text" style="font-size:90%;">Figure 9</span>: </span><span id="S6.F9.3.2" class="ltx_text" style="font-size:90%;">RMSE results for the single image depth task (lower is better).</span></figcaption>
</figure>
</div>
</div>
<div id="S6.SS3.p2" class="ltx_para">
<p id="S6.SS3.p2.7" class="ltx_p">From the RMSE numbers, one result is clear: having either simulated or sim2real data in the training mix is better than using only real data, for the same amount of total training data. This is shown by the yellow bar (only real data) being higher than the other mixes. Equally, having simulated (sim/sim2real) data alone (the last pair of bars in the RMSE figure) gives the worst results. The trends indicate that mixing sim2real (after converting the simulated data with the sim2real GAN pipeline) with real is better than mixing sim with real, when the percentage of sim/sim2real data is lower or equal to the percentage of real data (<math id="S6.SS3.p2.1.m1.1" class="ltx_Math" alttext="10-50\%" display="inline"><semantics id="S6.SS3.p2.1.m1.1a"><mrow id="S6.SS3.p2.1.m1.1.1" xref="S6.SS3.p2.1.m1.1.1.cmml"><mn id="S6.SS3.p2.1.m1.1.1.2" xref="S6.SS3.p2.1.m1.1.1.2.cmml">10</mn><mo id="S6.SS3.p2.1.m1.1.1.1" xref="S6.SS3.p2.1.m1.1.1.1.cmml">−</mo><mrow id="S6.SS3.p2.1.m1.1.1.3" xref="S6.SS3.p2.1.m1.1.1.3.cmml"><mn id="S6.SS3.p2.1.m1.1.1.3.2" xref="S6.SS3.p2.1.m1.1.1.3.2.cmml">50</mn><mo id="S6.SS3.p2.1.m1.1.1.3.1" xref="S6.SS3.p2.1.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S6.SS3.p2.1.m1.1b"><apply id="S6.SS3.p2.1.m1.1.1.cmml" xref="S6.SS3.p2.1.m1.1.1"><minus id="S6.SS3.p2.1.m1.1.1.1.cmml" xref="S6.SS3.p2.1.m1.1.1.1"></minus><cn type="integer" id="S6.SS3.p2.1.m1.1.1.2.cmml" xref="S6.SS3.p2.1.m1.1.1.2">10</cn><apply id="S6.SS3.p2.1.m1.1.1.3.cmml" xref="S6.SS3.p2.1.m1.1.1.3"><csymbol cd="latexml" id="S6.SS3.p2.1.m1.1.1.3.1.cmml" xref="S6.SS3.p2.1.m1.1.1.3.1">percent</csymbol><cn type="integer" id="S6.SS3.p2.1.m1.1.1.3.2.cmml" xref="S6.SS3.p2.1.m1.1.1.3.2">50</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.p2.1.m1.1c">10-50\%</annotation></semantics></math> sim/sim2real), in the left half of the bar graphs. In other words, A + G seems to give a slight performance gain over A + S in the <math id="S6.SS3.p2.2.m2.1" class="ltx_Math" alttext="10-50\%" display="inline"><semantics id="S6.SS3.p2.2.m2.1a"><mrow id="S6.SS3.p2.2.m2.1.1" xref="S6.SS3.p2.2.m2.1.1.cmml"><mn id="S6.SS3.p2.2.m2.1.1.2" xref="S6.SS3.p2.2.m2.1.1.2.cmml">10</mn><mo id="S6.SS3.p2.2.m2.1.1.1" xref="S6.SS3.p2.2.m2.1.1.1.cmml">−</mo><mrow id="S6.SS3.p2.2.m2.1.1.3" xref="S6.SS3.p2.2.m2.1.1.3.cmml"><mn id="S6.SS3.p2.2.m2.1.1.3.2" xref="S6.SS3.p2.2.m2.1.1.3.2.cmml">50</mn><mo id="S6.SS3.p2.2.m2.1.1.3.1" xref="S6.SS3.p2.2.m2.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S6.SS3.p2.2.m2.1b"><apply id="S6.SS3.p2.2.m2.1.1.cmml" xref="S6.SS3.p2.2.m2.1.1"><minus id="S6.SS3.p2.2.m2.1.1.1.cmml" xref="S6.SS3.p2.2.m2.1.1.1"></minus><cn type="integer" id="S6.SS3.p2.2.m2.1.1.2.cmml" xref="S6.SS3.p2.2.m2.1.1.2">10</cn><apply id="S6.SS3.p2.2.m2.1.1.3.cmml" xref="S6.SS3.p2.2.m2.1.1.3"><csymbol cd="latexml" id="S6.SS3.p2.2.m2.1.1.3.1.cmml" xref="S6.SS3.p2.2.m2.1.1.3.1">percent</csymbol><cn type="integer" id="S6.SS3.p2.2.m2.1.1.3.2.cmml" xref="S6.SS3.p2.2.m2.1.1.3.2">50</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.p2.2.m2.1c">10-50\%</annotation></semantics></math> range. From Table <a href="#S6.T3" title="Table 3 ‣ 6.3 Results ‣ 6 Case Study: Monocular Depth Estimation ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, we see that the absolute best performer in terms of RMSE is <math id="S6.SS3.p2.3.m3.1" class="ltx_Math" alttext="20\%" display="inline"><semantics id="S6.SS3.p2.3.m3.1a"><mrow id="S6.SS3.p2.3.m3.1.1" xref="S6.SS3.p2.3.m3.1.1.cmml"><mn id="S6.SS3.p2.3.m3.1.1.2" xref="S6.SS3.p2.3.m3.1.1.2.cmml">20</mn><mo id="S6.SS3.p2.3.m3.1.1.1" xref="S6.SS3.p2.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.SS3.p2.3.m3.1b"><apply id="S6.SS3.p2.3.m3.1.1.cmml" xref="S6.SS3.p2.3.m3.1.1"><csymbol cd="latexml" id="S6.SS3.p2.3.m3.1.1.1.cmml" xref="S6.SS3.p2.3.m3.1.1.1">percent</csymbol><cn type="integer" id="S6.SS3.p2.3.m3.1.1.2.cmml" xref="S6.SS3.p2.3.m3.1.1.2">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.p2.3.m3.1c">20\%</annotation></semantics></math> A + G and <math id="S6.SS3.p2.4.m4.1" class="ltx_Math" alttext="60\%" display="inline"><semantics id="S6.SS3.p2.4.m4.1a"><mrow id="S6.SS3.p2.4.m4.1.1" xref="S6.SS3.p2.4.m4.1.1.cmml"><mn id="S6.SS3.p2.4.m4.1.1.2" xref="S6.SS3.p2.4.m4.1.1.2.cmml">60</mn><mo id="S6.SS3.p2.4.m4.1.1.1" xref="S6.SS3.p2.4.m4.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.SS3.p2.4.m4.1b"><apply id="S6.SS3.p2.4.m4.1.1.cmml" xref="S6.SS3.p2.4.m4.1.1"><csymbol cd="latexml" id="S6.SS3.p2.4.m4.1.1.1.cmml" xref="S6.SS3.p2.4.m4.1.1.1">percent</csymbol><cn type="integer" id="S6.SS3.p2.4.m4.1.1.2.cmml" xref="S6.SS3.p2.4.m4.1.1.2">60</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.p2.4.m4.1c">60\%</annotation></semantics></math> A + S. Qualitative results are shown for a single image in Figure <a href="#S6.F8" title="Figure 8 ‣ 6 Case Study: Monocular Depth Estimation ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>. Visually, the A + G (<math id="S6.SS3.p2.5.m5.1" class="ltx_Math" alttext="60\%" display="inline"><semantics id="S6.SS3.p2.5.m5.1a"><mrow id="S6.SS3.p2.5.m5.1.1" xref="S6.SS3.p2.5.m5.1.1.cmml"><mn id="S6.SS3.p2.5.m5.1.1.2" xref="S6.SS3.p2.5.m5.1.1.2.cmml">60</mn><mo id="S6.SS3.p2.5.m5.1.1.1" xref="S6.SS3.p2.5.m5.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.SS3.p2.5.m5.1b"><apply id="S6.SS3.p2.5.m5.1.1.cmml" xref="S6.SS3.p2.5.m5.1.1"><csymbol cd="latexml" id="S6.SS3.p2.5.m5.1.1.1.cmml" xref="S6.SS3.p2.5.m5.1.1.1">percent</csymbol><cn type="integer" id="S6.SS3.p2.5.m5.1.1.2.cmml" xref="S6.SS3.p2.5.m5.1.1.2">60</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.p2.5.m5.1c">60\%</annotation></semantics></math>) network (trained with a 40/60 mix of real and sim2real data) seems to perform the best on this image, followed by A + S (<math id="S6.SS3.p2.6.m6.1" class="ltx_Math" alttext="60\%" display="inline"><semantics id="S6.SS3.p2.6.m6.1a"><mrow id="S6.SS3.p2.6.m6.1.1" xref="S6.SS3.p2.6.m6.1.1.cmml"><mn id="S6.SS3.p2.6.m6.1.1.2" xref="S6.SS3.p2.6.m6.1.1.2.cmml">60</mn><mo id="S6.SS3.p2.6.m6.1.1.1" xref="S6.SS3.p2.6.m6.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.SS3.p2.6.m6.1b"><apply id="S6.SS3.p2.6.m6.1.1.cmml" xref="S6.SS3.p2.6.m6.1.1"><csymbol cd="latexml" id="S6.SS3.p2.6.m6.1.1.1.cmml" xref="S6.SS3.p2.6.m6.1.1.1">percent</csymbol><cn type="integer" id="S6.SS3.p2.6.m6.1.1.2.cmml" xref="S6.SS3.p2.6.m6.1.1.2">60</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.p2.6.m6.1c">60\%</annotation></semantics></math>). The top performer in terms of RMSE, A + G (<math id="S6.SS3.p2.7.m7.1" class="ltx_Math" alttext="20\%" display="inline"><semantics id="S6.SS3.p2.7.m7.1a"><mrow id="S6.SS3.p2.7.m7.1.1" xref="S6.SS3.p2.7.m7.1.1.cmml"><mn id="S6.SS3.p2.7.m7.1.1.2" xref="S6.SS3.p2.7.m7.1.1.2.cmml">20</mn><mo id="S6.SS3.p2.7.m7.1.1.1" xref="S6.SS3.p2.7.m7.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.SS3.p2.7.m7.1b"><apply id="S6.SS3.p2.7.m7.1.1.cmml" xref="S6.SS3.p2.7.m7.1.1"><csymbol cd="latexml" id="S6.SS3.p2.7.m7.1.1.1.cmml" xref="S6.SS3.p2.7.m7.1.1.1">percent</csymbol><cn type="integer" id="S6.SS3.p2.7.m7.1.1.2.cmml" xref="S6.SS3.p2.7.m7.1.1.2">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.p2.7.m7.1c">20\%</annotation></semantics></math>) looks visually slightly worse.</p>
</div>
<figure id="S6.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table"><span id="S6.T3.8.1.1" class="ltx_text" style="font-size:113%;">Table 3</span>: </span><span id="S6.T3.9.2" class="ltx_text" style="font-size:113%;">Summary of results for the single image depth task. Best results for A + S are in green, and best results for A + G are in blue.</span></figcaption>
<table id="S6.T3.4" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S6.T3.4.4" class="ltx_tr">
<th id="S6.T3.4.4.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_tt"><span id="S6.T3.4.4.5.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Train</span></th>
<th id="S6.T3.4.4.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt"><span id="S6.T3.4.4.6.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Test</span></th>
<th id="S6.T3.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt">
<math id="S6.T3.1.1.1.m1.1" class="ltx_Math" alttext="\mathbf{RMSE}" display="inline"><semantics id="S6.T3.1.1.1.m1.1a"><mi mathsize="80%" id="S6.T3.1.1.1.m1.1.1" xref="S6.T3.1.1.1.m1.1.1.cmml">𝐑𝐌𝐒𝐄</mi><annotation-xml encoding="MathML-Content" id="S6.T3.1.1.1.m1.1b"><ci id="S6.T3.1.1.1.m1.1.1.cmml" xref="S6.T3.1.1.1.m1.1.1">𝐑𝐌𝐒𝐄</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T3.1.1.1.m1.1c">\mathbf{RMSE}</annotation></semantics></math><span id="S6.T3.2.2.2.1" class="ltx_text" style="font-size:80%;"> (</span><math id="S6.T3.2.2.2.m2.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S6.T3.2.2.2.m2.1a"><mo mathsize="80%" stretchy="false" id="S6.T3.2.2.2.m2.1.1" xref="S6.T3.2.2.2.m2.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S6.T3.2.2.2.m2.1b"><ci id="S6.T3.2.2.2.m2.1.1.cmml" xref="S6.T3.2.2.2.m2.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T3.2.2.2.m2.1c">\downarrow</annotation></semantics></math><span id="S6.T3.2.2.2.2" class="ltx_text" style="font-size:80%;">)</span>
</th>
<th id="S6.T3.4.4.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt">
<math id="S6.T3.3.3.3.m1.1" class="ltx_Math" alttext="\mathbf{Accuracy}" display="inline"><semantics id="S6.T3.3.3.3.m1.1a"><mi mathsize="80%" id="S6.T3.3.3.3.m1.1.1" xref="S6.T3.3.3.3.m1.1.1.cmml">𝐀𝐜𝐜𝐮𝐫𝐚𝐜𝐲</mi><annotation-xml encoding="MathML-Content" id="S6.T3.3.3.3.m1.1b"><ci id="S6.T3.3.3.3.m1.1.1.cmml" xref="S6.T3.3.3.3.m1.1.1">𝐀𝐜𝐜𝐮𝐫𝐚𝐜𝐲</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T3.3.3.3.m1.1c">\mathbf{Accuracy}</annotation></semantics></math><span id="S6.T3.4.4.4.1" class="ltx_text" style="font-size:80%;">(</span><math id="S6.T3.4.4.4.m2.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S6.T3.4.4.4.m2.1a"><mo mathsize="80%" stretchy="false" id="S6.T3.4.4.4.m2.1.1" xref="S6.T3.4.4.4.m2.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S6.T3.4.4.4.m2.1b"><ci id="S6.T3.4.4.4.m2.1.1.cmml" xref="S6.T3.4.4.4.m2.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T3.4.4.4.m2.1c">\uparrow</annotation></semantics></math><span id="S6.T3.4.4.4.2" class="ltx_text" style="font-size:80%;">)</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S6.T3.4.5.1" class="ltx_tr">
<th id="S6.T3.4.5.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="S6.T3.4.5.1.1.1" class="ltx_text" style="font-size:80%;">A</span></th>
<td id="S6.T3.4.5.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S6.T3.4.5.1.2.1" class="ltx_text" style="font-size:80%;">B</span></td>
<td id="S6.T3.4.5.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S6.T3.4.5.1.3.1" class="ltx_text" style="font-size:80%;">6.7205</span></td>
<td id="S6.T3.4.5.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S6.T3.4.5.1.4.1" class="ltx_text" style="font-size:80%;">0.9559</span></td>
</tr>
<tr id="S6.T3.4.6.2" class="ltx_tr">
<th id="S6.T3.4.6.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r">
<span id="S6.T3.4.6.2.1.1" class="ltx_text" style="font-size:80%;">A</span><span id="S6.T3.4.6.2.1.2" class="ltx_text" style="font-size:80%;"> + </span><span id="S6.T3.4.6.2.1.3" class="ltx_text" style="font-size:80%;">S</span><span id="S6.T3.4.6.2.1.4" class="ltx_text" style="font-size:80%;"> (20%)</span>
</th>
<td id="S6.T3.4.6.2.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S6.T3.4.6.2.2.1" class="ltx_text" style="font-size:80%;">B</span></td>
<td id="S6.T3.4.6.2.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S6.T3.4.6.2.3.1" class="ltx_text" style="font-size:80%;">5.3366</span></td>
<td id="S6.T3.4.6.2.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S6.T3.4.6.2.4.1" class="ltx_text" style="font-size:80%;">0.9705</span></td>
</tr>
<tr id="S6.T3.4.7.3" class="ltx_tr">
<th id="S6.T3.4.7.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r">
<span id="S6.T3.4.7.3.1.1" class="ltx_text" style="font-size:80%;">A</span><span id="S6.T3.4.7.3.1.2" class="ltx_text" style="font-size:80%;"> + </span><span id="S6.T3.4.7.3.1.3" class="ltx_text" style="font-size:80%;">G</span><span id="S6.T3.4.7.3.1.4" class="ltx_text" style="font-size:80%;"> (20%)</span>
</th>
<td id="S6.T3.4.7.3.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S6.T3.4.7.3.2.1" class="ltx_text" style="font-size:80%;">B</span></td>
<td id="S6.T3.4.7.3.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S6.T3.4.7.3.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;color:#0000FF;">5.0231</span></td>
<td id="S6.T3.4.7.3.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S6.T3.4.7.3.4.1" class="ltx_text" style="font-size:80%;">0.9712</span></td>
</tr>
<tr id="S6.T3.4.8.4" class="ltx_tr">
<th id="S6.T3.4.8.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r">
<span id="S6.T3.4.8.4.1.1" class="ltx_text" style="font-size:80%;">A</span><span id="S6.T3.4.8.4.1.2" class="ltx_text" style="font-size:80%;"> + </span><span id="S6.T3.4.8.4.1.3" class="ltx_text" style="font-size:80%;">S</span><span id="S6.T3.4.8.4.1.4" class="ltx_text" style="font-size:80%;"> (50%)</span>
</th>
<td id="S6.T3.4.8.4.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S6.T3.4.8.4.2.1" class="ltx_text" style="font-size:80%;">B</span></td>
<td id="S6.T3.4.8.4.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S6.T3.4.8.4.3.1" class="ltx_text" style="font-size:80%;">5.3218</span></td>
<td id="S6.T3.4.8.4.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S6.T3.4.8.4.4.1" class="ltx_text" style="font-size:80%;">0.9702</span></td>
</tr>
<tr id="S6.T3.4.9.5" class="ltx_tr">
<th id="S6.T3.4.9.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r">
<span id="S6.T3.4.9.5.1.1" class="ltx_text" style="font-size:80%;">A</span><span id="S6.T3.4.9.5.1.2" class="ltx_text" style="font-size:80%;"> + </span><span id="S6.T3.4.9.5.1.3" class="ltx_text" style="font-size:80%;">G</span><span id="S6.T3.4.9.5.1.4" class="ltx_text" style="font-size:80%;"> (50%)</span>
</th>
<td id="S6.T3.4.9.5.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S6.T3.4.9.5.2.1" class="ltx_text" style="font-size:80%;">B</span></td>
<td id="S6.T3.4.9.5.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S6.T3.4.9.5.3.1" class="ltx_text" style="font-size:80%;">5.0779</span></td>
<td id="S6.T3.4.9.5.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S6.T3.4.9.5.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;color:#0000FF;">0.9721</span></td>
</tr>
<tr id="S6.T3.4.10.6" class="ltx_tr">
<th id="S6.T3.4.10.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r">
<span id="S6.T3.4.10.6.1.1" class="ltx_text" style="font-size:80%;">A</span><span id="S6.T3.4.10.6.1.2" class="ltx_text" style="font-size:80%;"> + </span><span id="S6.T3.4.10.6.1.3" class="ltx_text" style="font-size:80%;">S</span><span id="S6.T3.4.10.6.1.4" class="ltx_text" style="font-size:80%;"> (60%)</span>
</th>
<td id="S6.T3.4.10.6.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S6.T3.4.10.6.2.1" class="ltx_text" style="font-size:80%;">B</span></td>
<td id="S6.T3.4.10.6.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S6.T3.4.10.6.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;color:#00FF00;">4.9840</span></td>
<td id="S6.T3.4.10.6.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S6.T3.4.10.6.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;color:#00FF00;">0.9723</span></td>
</tr>
<tr id="S6.T3.4.11.7" class="ltx_tr">
<th id="S6.T3.4.11.7.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_l ltx_border_r">
<span id="S6.T3.4.11.7.1.1" class="ltx_text" style="font-size:80%;">A</span><span id="S6.T3.4.11.7.1.2" class="ltx_text" style="font-size:80%;"> + </span><span id="S6.T3.4.11.7.1.3" class="ltx_text" style="font-size:80%;">G</span><span id="S6.T3.4.11.7.1.4" class="ltx_text" style="font-size:80%;"> (60%)</span>
</th>
<td id="S6.T3.4.11.7.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S6.T3.4.11.7.2.1" class="ltx_text" style="font-size:80%;">B</span></td>
<td id="S6.T3.4.11.7.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S6.T3.4.11.7.3.1" class="ltx_text" style="font-size:80%;">5.2102</span></td>
<td id="S6.T3.4.11.7.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S6.T3.4.11.7.4.1" class="ltx_text" style="font-size:80%;">0.9682</span></td>
</tr>
</tbody>
</table>
</figure>
<div id="S6.SS3.p3" class="ltx_para">
<p id="S6.SS3.p3.1" class="ltx_p">Another important result to be highlighted is the fact that the network trained on just simulation data gains about <math id="S6.SS3.p3.1.m1.1" class="ltx_Math" alttext="7\%" display="inline"><semantics id="S6.SS3.p3.1.m1.1a"><mrow id="S6.SS3.p3.1.m1.1.1" xref="S6.SS3.p3.1.m1.1.1.cmml"><mn id="S6.SS3.p3.1.m1.1.1.2" xref="S6.SS3.p3.1.m1.1.1.2.cmml">7</mn><mo id="S6.SS3.p3.1.m1.1.1.1" xref="S6.SS3.p3.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.SS3.p3.1.m1.1b"><apply id="S6.SS3.p3.1.m1.1.1.cmml" xref="S6.SS3.p3.1.m1.1.1"><csymbol cd="latexml" id="S6.SS3.p3.1.m1.1.1.1.cmml" xref="S6.SS3.p3.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S6.SS3.p3.1.m1.1.1.2.cmml" xref="S6.SS3.p3.1.m1.1.1.2">7</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.p3.1.m1.1c">7\%</annotation></semantics></math> in terms of RMSE with the sim2real transformation, when tested on real data when using the accuracy numbers. This shows that sim2real from simulation to the source dataset,
without any labelling from the source set, already gives a baseline boost. This, when mixed with real labelled data from the source set allows single image depth performance on the target set to rise further, and the perfect mix of real and simulated data lies in the 80/20 to 40/60 range, with sim2real showing minor improvements over just using simulated data in the mix.</p>
</div>
<div id="S6.SS3.p4" class="ltx_para">
<p id="S6.SS3.p4.1" class="ltx_p">We also conducted single image depth experiments using the NuScenes dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> for real data and the CARLA simulation environment <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> for simulation data. These experiments indicated that the estimation of a depth map from a single image is highly dependent on the focal length and other intrinsic camera parameters. We were able to get good results on the NuScenes dataset by using data from CARLA, when the simulated camera on CARLA had been matched with the intrinsics the NuScenes camera. However, any mix of KITTI with NuScenes/CARLA during training completely confounded the algorithm and we do not include these experiments in this paper. We consider camera intrinsics an important consideration when generating simulation and sim2real data and one has to match these with the target dataset. The mixing of data across datasets captured with different focal length cameras requires more sophisticated techniques that are beyond the scope of this paper.</p>
</div>
</section>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Discussion</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">As motivated in Section <a href="#S1" title="1 Introduction ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, dataset bias is a known problem in computer vision. However, most of the well studied sources of bias are task-agnostic. In this work, we focus on bias in the context of the noise distribution pertaining to task-specific environmental factors, referred to as <em id="S7.p1.1.1" class="ltx_emph ltx_font_italic">noise factor distribution bias</em>, and show that targeted synthetic data augmentation can help deflate this bias. For empirical verification, we use three different computer vision tasks of immense practical use - parking slot detection, lane detection and monocular depth estimation. Synthetic data for these tasks is generated via a simple two step process: (i) simulate images for a diverse set of task-specific noise factors and obtain corresponding ground truth; (ii) perform sim2real translation using GANs to make simulated images look like they are from the real training domain. The rest of this section summarizes the key insights obtained.</p>
</div>
<div id="S7.p2" class="ltx_para">
<p id="S7.p2.1" class="ltx_p">Across all three tasks, having synthetic data in the training mix provides a significant boost in cross-dataset generalization performance as compared to training on real data only, for the same size of the training set. Moreover, performance on the source domain test set was not adversely impacted which makes the case for synthetic data augmentation to enrich training datasets for these tasks stronger.</p>
</div>
<div id="S7.p3" class="ltx_para">
<p id="S7.p3.1" class="ltx_p">For both the slot detection and lane detection tasks, the best models in terms of F-Measure were those trained on a mix of real and sim2real translated data. For slot detection, the best model with 50% sim2real data in the training mix provided about 30% absolute improvement over the model trained on 100% real data. For lane detection, the best model with 60% sim2real data in the training mix performed about 40% better than the one trained on 100% real data. Another consistent observation across the two tasks is that models with a higher ratio of synthetic data (<math id="S7.p3.1.m1.1" class="ltx_Math" alttext="&gt;" display="inline"><semantics id="S7.p3.1.m1.1a"><mo id="S7.p3.1.m1.1.1" xref="S7.p3.1.m1.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S7.p3.1.m1.1b"><gt id="S7.p3.1.m1.1.1.cmml" xref="S7.p3.1.m1.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S7.p3.1.m1.1c">&gt;</annotation></semantics></math> 50%) in the training mix do much better when the source of the synthetic data is sim2real data as opposed to simulated data.</p>
</div>
<div id="S7.p4" class="ltx_para">
<p id="S7.p4.1" class="ltx_p">In contrast, for the depth estimation task, the best model in terms of both RMSE and accuracy was the one with 60% simulated data (and not sim2real data) in the training mix that achieved a 25% improvement in RMSE over the model trained with 100% real data. We think this is because of two main reasons. First, depth estimation from a sensor (RGB camera) that is missing the 3<sup id="S7.p4.1.1" class="ltx_sup">rd</sup> dimension is an inherently hard task with every pixel contributing to the error metric. If we were solving some other problem in which 3D estimation can be parameterized - <em id="S7.p4.1.2" class="ltx_emph ltx_font_italic">e.g</em>.<span id="S7.p4.1.3" class="ltx_text"></span> 3D bounding box detection from 2D images - instead of requiring prediction on a pixel level, we would expect to see a bigger gain with sim and sim2real data added in the training mix. Secondly, slot detection and lane detection are mostly dependent on higher-level features (such as edges) and appearance (such as exposure and lighting conditions). Sim2real is good at doing exactly this - matching higher-level features between the generated and real images and thus these two tasks significantly benefit from sim2real. Depth estimation, however, is dependent more on low-level features. Artifacts introduced by the GAN make it difficult to bridge the low-level feature discrepancies between the sim2real images and corresponding ground truth annotation obtained from simulation. Thus, as expected, for this task, as you go higher in terms of the ratio of synthetic data in the training mix (<math id="S7.p4.1.m1.1" class="ltx_Math" alttext="&gt;" display="inline"><semantics id="S7.p4.1.m1.1a"><mo id="S7.p4.1.m1.1.1" xref="S7.p4.1.m1.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S7.p4.1.m1.1b"><gt id="S7.p4.1.m1.1.1.cmml" xref="S7.p4.1.m1.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S7.p4.1.m1.1c">&gt;</annotation></semantics></math> 50%), models trained on a mix of real and simulated data do better than those trained on a mix of real and sim2real data. However, the model trained on 100% sim2real data outperforms the one trained on 100% simulated data for this task as well.</p>
</div>
<div id="S7.p5" class="ltx_para">
<p id="S7.p5.1" class="ltx_p">Another interesting finding is that across all three tasks, the best models in terms of the chosen metrics were always those with 50%-60% synthetic data in the training mix. Although this makes intuitive sense, it requires more in-depth investigation which will be part of future work.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:80%;">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock"><span id="bib.bib1.1.1" class="ltx_text" style="font-size:80%;">
Hassan Abu Alhaija, Siva Karthik Mustikovela, Lars Mescheder, Andreas Geiger,
and Carsten Rother.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.2.1" class="ltx_text" style="font-size:80%;">Augmented reality meets computer vision: Efficient data generation
for urban driving scenes.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.3.1" class="ltx_text ltx_font_italic" style="font-size:80%;">International Journal of Computer Vision</span><span id="bib.bib1.4.2" class="ltx_text" style="font-size:80%;">, 126(9):961–972,
2018.
</span>
</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock"><span id="bib.bib2.1.1" class="ltx_text" style="font-size:80%;">
Bharath Bhushan Damodaran, Benjamin Kellenberger, Rémi Flamary, Devis Tuia,
and Nicolas Courty.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.2.1" class="ltx_text" style="font-size:80%;">Deepjdot: Deep joint distribution optimal transport for unsupervised
domain adaptation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.3.1" class="ltx_text" style="font-size:80%;">In </span><span id="bib.bib2.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">Proceedings of the European Conference on Computer Vision
(ECCV)</span><span id="bib.bib2.5.3" class="ltx_text" style="font-size:80%;">, pages 447–463, 2018.
</span>
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock"><span id="bib.bib3.1.1" class="ltx_text" style="font-size:80%;">
Holger Caesar, Varun Bankiti, Alex H Lang, Sourabh Vora, Venice Erin Liong,
Qiang Xu, Anush Krishnan, Yu Pan, Giancarlo Baldan, and Oscar Beijbom.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.2.1" class="ltx_text" style="font-size:80%;">nuscenes: A multimodal dataset for autonomous driving.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.3.1" class="ltx_text ltx_font_italic" style="font-size:80%;">arXiv preprint arXiv:1903.11027</span><span id="bib.bib3.4.2" class="ltx_text" style="font-size:80%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock"><span id="bib.bib4.1.1" class="ltx_text" style="font-size:80%;">
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.2.1" class="ltx_text" style="font-size:80%;">Imagenet: A large-scale hierarchical image database.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.3.1" class="ltx_text" style="font-size:80%;">In </span><span id="bib.bib4.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">2009 IEEE conference on computer vision and pattern
recognition</span><span id="bib.bib4.5.3" class="ltx_text" style="font-size:80%;">, pages 248–255. Ieee, 2009.
</span>
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock"><span id="bib.bib5.1.1" class="ltx_text" style="font-size:80%;">
Alexey Dosovitskiy, German Ros, Felipe Codevilla, Antonio Lopez, and Vladlen
Koltun.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.2.1" class="ltx_text" style="font-size:80%;">Carla: An open urban driving simulator.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.3.1" class="ltx_text ltx_font_italic" style="font-size:80%;">arXiv preprint arXiv:1711.03938</span><span id="bib.bib5.4.2" class="ltx_text" style="font-size:80%;">, 2017.
</span>
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock"><span id="bib.bib6.1.1" class="ltx_text" style="font-size:80%;">
David Eigen, Christian Puhrsch, and Rob Fergus.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.2.1" class="ltx_text" style="font-size:80%;">Depth map prediction from a single image using a multi-scale deep
network.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.3.1" class="ltx_text" style="font-size:80%;">In </span><span id="bib.bib6.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">Advances in neural information processing systems</span><span id="bib.bib6.5.3" class="ltx_text" style="font-size:80%;">, pages
2366–2374, 2014.
</span>
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock"><span id="bib.bib7.1.1" class="ltx_text" style="font-size:80%;">
Basura Fernando, Amaury Habrard, Marc Sebban, and Tinne Tuytelaars.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.2.1" class="ltx_text" style="font-size:80%;">Unsupervised visual domain adaptation using subspace alignment.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.3.1" class="ltx_text" style="font-size:80%;">In </span><span id="bib.bib7.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">Proceedings of the IEEE international conference on computer
vision</span><span id="bib.bib7.5.3" class="ltx_text" style="font-size:80%;">, pages 2960–2967, 2013.
</span>
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock"><span id="bib.bib8.1.1" class="ltx_text" style="font-size:80%;">
Adrien Gaidon, Qiao Wang, Yohann Cabon, and Eleonora Vig.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.2.1" class="ltx_text" style="font-size:80%;">Virtual worlds as proxy for multi-object tracking analysis.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.3.1" class="ltx_text" style="font-size:80%;">In </span><span id="bib.bib8.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">Proceedings of the IEEE conference on computer vision and
pattern recognition</span><span id="bib.bib8.5.3" class="ltx_text" style="font-size:80%;">, pages 4340–4349, 2016.
</span>
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock"><span id="bib.bib9.1.1" class="ltx_text" style="font-size:80%;">
Ravi Garg, Vijay Kumar BG, Gustavo Carneiro, and Ian Reid.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.2.1" class="ltx_text" style="font-size:80%;">Unsupervised cnn for single view depth estimation: Geometry to the
rescue.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.3.1" class="ltx_text" style="font-size:80%;">In </span><span id="bib.bib9.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">European Conference on Computer Vision</span><span id="bib.bib9.5.3" class="ltx_text" style="font-size:80%;">, pages 740–756.
Springer, 2016.
</span>
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text" style="font-size:80%;">
Andreas Geiger, Philip Lenz, and Raquel Urtasun.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.2.1" class="ltx_text" style="font-size:80%;">Are we ready for autonomous driving? the kitti vision benchmark
suite.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.3.1" class="ltx_text" style="font-size:80%;">In </span><span id="bib.bib10.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">2012 IEEE Conference on Computer Vision and Pattern
Recognition</span><span id="bib.bib10.5.3" class="ltx_text" style="font-size:80%;">, pages 3354–3361. IEEE, 2012.
</span>
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text" style="font-size:80%;">
Clément Godard, Oisin Mac Aodha, and Gabriel J Brostow.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.2.1" class="ltx_text" style="font-size:80%;">Unsupervised monocular depth estimation with left-right consistency.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.3.1" class="ltx_text" style="font-size:80%;">In </span><span id="bib.bib11.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">CVPR</span><span id="bib.bib11.5.3" class="ltx_text" style="font-size:80%;">, volume 2, page 7, 2017.
</span>
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock"><span id="bib.bib12.1.1" class="ltx_text" style="font-size:80%;">
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley,
Sherjil Ozair, Aaron Courville, and Yoshua Bengio.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.2.1" class="ltx_text" style="font-size:80%;">Generative adversarial nets.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.3.1" class="ltx_text" style="font-size:80%;">In </span><span id="bib.bib12.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">Advances in neural information processing systems</span><span id="bib.bib12.5.3" class="ltx_text" style="font-size:80%;">, pages
2672–2680, 2014.
</span>
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text" style="font-size:80%;">
Kaiming He, Georgia Gkioxari, Piotr Dollár, and Ross Girshick.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.2.1" class="ltx_text" style="font-size:80%;">Mask r-cnn.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.3.1" class="ltx_text" style="font-size:80%;">In </span><span id="bib.bib13.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">Proceedings of the IEEE international conference on computer
vision</span><span id="bib.bib13.5.3" class="ltx_text" style="font-size:80%;">, pages 2961–2969, 2017.
</span>
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock"><span id="bib.bib14.1.1" class="ltx_text" style="font-size:80%;">
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.2.1" class="ltx_text" style="font-size:80%;">Deep residual learning for image recognition.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.3.1" class="ltx_text" style="font-size:80%;">In </span><span id="bib.bib14.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">Proceedings of the IEEE conference on computer vision and
pattern recognition</span><span id="bib.bib14.5.3" class="ltx_text" style="font-size:80%;">, pages 770–778, 2016.
</span>
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock"><span id="bib.bib15.1.1" class="ltx_text" style="font-size:80%;">
Judy Hoffman, Eric Tzeng, Taesung Park, Jun-Yan Zhu, Phillip Isola, Kate
Saenko, Alexei A Efros, and Trevor Darrell.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.2.1" class="ltx_text" style="font-size:80%;">Cycada: Cycle-consistent adversarial domain adaptation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.3.1" class="ltx_text ltx_font_italic" style="font-size:80%;">arXiv preprint arXiv:1711.03213</span><span id="bib.bib15.4.2" class="ltx_text" style="font-size:80%;">, 2017.
</span>
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock"><span id="bib.bib16.1.1" class="ltx_text" style="font-size:80%;">
Xinyu Huang, Peng Wang, Xinjing Cheng, Dingfu Zhou, Qichuan Geng, and Ruigang
Yang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.2.1" class="ltx_text" style="font-size:80%;">The apolloscape open dataset for autonomous driving and its
application.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.3.1" class="ltx_text ltx_font_italic" style="font-size:80%;">arXiv preprint arXiv:1803.06184</span><span id="bib.bib16.4.2" class="ltx_text" style="font-size:80%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock"><span id="bib.bib17.1.1" class="ltx_text" style="font-size:80%;">
Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, and Alexei A Efros.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.2.1" class="ltx_text" style="font-size:80%;">Image-to-image translation with conditional adversarial networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.3.1" class="ltx_text" style="font-size:80%;">In </span><span id="bib.bib17.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">Proceedings of the IEEE conference on computer vision and
pattern recognition</span><span id="bib.bib17.5.3" class="ltx_text" style="font-size:80%;">, pages 1125–1134, 2017.
</span>
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock"><span id="bib.bib18.1.1" class="ltx_text" style="font-size:80%;">
Nikita Jaipuria, Shubh Gupta, Praveen Narayanan, and Vidya N Murali.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.2.1" class="ltx_text" style="font-size:80%;">On the role of receptive field in unsupervised sim-to-real image
translation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.3.1" class="ltx_text ltx_font_italic" style="font-size:80%;">arXiv preprint arXiv:2001.09257</span><span id="bib.bib18.4.2" class="ltx_text" style="font-size:80%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock"><span id="bib.bib19.1.1" class="ltx_text" style="font-size:80%;">
Amlan Kar, Aayush Prakash, Ming-Yu Liu, Eric Cameracci, Justin Yuan, Matt
Rusiniak, David Acuna, Antonio Torralba, and Sanja Fidler.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.2.1" class="ltx_text" style="font-size:80%;">Meta-sim: Learning to generate synthetic datasets.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.3.1" class="ltx_text" style="font-size:80%;">In </span><span id="bib.bib19.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">Proceedings of the IEEE International Conference on Computer
Vision</span><span id="bib.bib19.5.3" class="ltx_text" style="font-size:80%;">, pages 4551–4560, 2019.
</span>
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock"><span id="bib.bib20.1.1" class="ltx_text" style="font-size:80%;">
Tero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.2.1" class="ltx_text" style="font-size:80%;">Progressive growing of gans for improved quality, stability, and
variation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.3.1" class="ltx_text ltx_font_italic" style="font-size:80%;">arXiv preprint arXiv:1710.10196</span><span id="bib.bib20.4.2" class="ltx_text" style="font-size:80%;">, 2017.
</span>
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock"><span id="bib.bib21.1.1" class="ltx_text" style="font-size:80%;">
Tero Karras, Samuli Laine, and Timo Aila.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.2.1" class="ltx_text" style="font-size:80%;">A style-based generator architecture for generative adversarial
networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.3.1" class="ltx_text" style="font-size:80%;">In </span><span id="bib.bib21.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib21.5.3" class="ltx_text" style="font-size:80%;">, pages 4401–4410, 2019.
</span>
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock"><span id="bib.bib22.1.1" class="ltx_text" style="font-size:80%;">
Aditya Khosla, Tinghui Zhou, Tomasz Malisiewicz, Alexei A Efros, and Antonio
Torralba.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.2.1" class="ltx_text" style="font-size:80%;">Undoing the damage of dataset bias.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.3.1" class="ltx_text" style="font-size:80%;">In </span><span id="bib.bib22.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">European Conference on Computer Vision</span><span id="bib.bib22.5.3" class="ltx_text" style="font-size:80%;">, pages 158–171.
Springer, 2012.
</span>
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock"><span id="bib.bib23.1.1" class="ltx_text" style="font-size:80%;">
Christian Ledig, Lucas Theis, Ferenc Huszár, Jose Caballero, Andrew
Cunningham, Alejandro Acosta, Andrew Aitken, Alykhan Tejani, Johannes Totz,
Zehan Wang, et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.2.1" class="ltx_text" style="font-size:80%;">Photo-realistic single image super-resolution using a generative
adversarial network.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.3.1" class="ltx_text" style="font-size:80%;">In </span><span id="bib.bib23.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">Proceedings of the IEEE conference on computer vision and
pattern recognition</span><span id="bib.bib23.5.3" class="ltx_text" style="font-size:80%;">, pages 4681–4690, 2017.
</span>
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock"><span id="bib.bib24.1.1" class="ltx_text" style="font-size:80%;">
Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva
Ramanan, Piotr Dollár, and C Lawrence Zitnick.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.2.1" class="ltx_text" style="font-size:80%;">Microsoft coco: Common objects in context.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.3.1" class="ltx_text" style="font-size:80%;">In </span><span id="bib.bib24.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">European conference on computer vision</span><span id="bib.bib24.5.3" class="ltx_text" style="font-size:80%;">, pages 740–755.
Springer, 2014.
</span>
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock"><span id="bib.bib25.1.1" class="ltx_text" style="font-size:80%;">
Ming-Yu Liu, Thomas Breuel, and Jan Kautz.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.2.1" class="ltx_text" style="font-size:80%;">Unsupervised image-to-image translation networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.3.1" class="ltx_text" style="font-size:80%;">In </span><span id="bib.bib25.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">Advances in neural information processing systems</span><span id="bib.bib25.5.3" class="ltx_text" style="font-size:80%;">, pages
700–708, 2017.
</span>
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock"><span id="bib.bib26.1.1" class="ltx_text" style="font-size:80%;">
Ming-Yu Liu and Oncel Tuzel.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.2.1" class="ltx_text" style="font-size:80%;">Coupled generative adversarial networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.3.1" class="ltx_text" style="font-size:80%;">In </span><span id="bib.bib26.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">Advances in neural information processing systems</span><span id="bib.bib26.5.3" class="ltx_text" style="font-size:80%;">, pages
469–477, 2016.
</span>
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock"><span id="bib.bib27.1.1" class="ltx_text" style="font-size:80%;">
Wei Liu, Dragomir Anguelov, Dumitru Erhan, Christian Szegedy, Scott Reed,
Cheng-Yang Fu, and Alexander C Berg.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.2.1" class="ltx_text" style="font-size:80%;">Ssd: Single shot multibox detector.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.3.1" class="ltx_text" style="font-size:80%;">In </span><span id="bib.bib27.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">European conference on computer vision</span><span id="bib.bib27.5.3" class="ltx_text" style="font-size:80%;">, pages 21–37.
Springer, 2016.
</span>
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock"><span id="bib.bib28.1.1" class="ltx_text" style="font-size:80%;">
Gerhard Neuhold, Tobias Ollmann, Samuel Rota Bulo, and Peter Kontschieder.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.2.1" class="ltx_text" style="font-size:80%;">The mapillary vistas dataset for semantic understanding of street
scenes.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.3.1" class="ltx_text" style="font-size:80%;">In </span><span id="bib.bib28.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">Proceedings of the IEEE International Conference on Computer
Vision</span><span id="bib.bib28.5.3" class="ltx_text" style="font-size:80%;">, pages 4990–4999, 2017.
</span>
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock"><span id="bib.bib29.1.1" class="ltx_text" style="font-size:80%;">
Xingang Pan, Jianping Shi, Ping Luo, Xiaogang Wang, and Xiaoou Tang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.2.1" class="ltx_text" style="font-size:80%;">Spatial as deep: Spatial cnn for traffic scene understanding.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.3.1" class="ltx_text" style="font-size:80%;">In </span><span id="bib.bib29.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">Thirty-Second AAAI Conference on Artificial Intelligence</span><span id="bib.bib29.5.3" class="ltx_text" style="font-size:80%;">,
2018.
</span>
</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock"><span id="bib.bib30.1.1" class="ltx_text" style="font-size:80%;">
Taesung Park, Ming-Yu Liu, Ting-Chun Wang, and Jun-Yan Zhu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.2.1" class="ltx_text" style="font-size:80%;">Semantic image synthesis with spatially-adaptive normalization.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.3.1" class="ltx_text" style="font-size:80%;">In </span><span id="bib.bib30.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib30.5.3" class="ltx_text" style="font-size:80%;">, pages 2337–2346, 2019.
</span>
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock"><span id="bib.bib31.1.1" class="ltx_text" style="font-size:80%;">
Suman Ravuri and Oriol Vinyals.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.2.1" class="ltx_text" style="font-size:80%;">Classification accuracy score for conditional generative models.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.3.1" class="ltx_text" style="font-size:80%;">In </span><span id="bib.bib31.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">Advances in Neural Information Processing Systems</span><span id="bib.bib31.5.3" class="ltx_text" style="font-size:80%;">, pages
12247–12258, 2019.
</span>
</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock"><span id="bib.bib32.1.1" class="ltx_text" style="font-size:80%;">
Benjamin Recht, Rebecca Roelofs, Ludwig Schmidt, and Vaishaal Shankar.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.2.1" class="ltx_text" style="font-size:80%;">Do imagenet classifiers generalize to imagenet?
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.3.1" class="ltx_text ltx_font_italic" style="font-size:80%;">arXiv preprint arXiv:1902.10811</span><span id="bib.bib32.4.2" class="ltx_text" style="font-size:80%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock"><span id="bib.bib33.1.1" class="ltx_text" style="font-size:80%;">
Mengye Ren, Wenyuan Zeng, Bin Yang, and Raquel Urtasun.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.2.1" class="ltx_text" style="font-size:80%;">Learning to reweight examples for robust deep learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.3.1" class="ltx_text ltx_font_italic" style="font-size:80%;">arXiv preprint arXiv:1803.09050</span><span id="bib.bib33.4.2" class="ltx_text" style="font-size:80%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock"><span id="bib.bib34.1.1" class="ltx_text" style="font-size:80%;">
Artem Rozantsev, Mathieu Salzmann, and Pascal Fua.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.2.1" class="ltx_text" style="font-size:80%;">Beyond sharing weights for deep domain adaptation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.3.1" class="ltx_text ltx_font_italic" style="font-size:80%;">IEEE transactions on pattern analysis and machine intelligence</span><span id="bib.bib34.4.2" class="ltx_text" style="font-size:80%;">,
41(4):801–814, 2018.
</span>
</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock"><span id="bib.bib35.1.1" class="ltx_text" style="font-size:80%;">
Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, and Liang-Chieh
Chen.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.2.1" class="ltx_text" style="font-size:80%;">Mobilenetv2: Inverted residuals and linear bottlenecks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.3.1" class="ltx_text" style="font-size:80%;">In </span><span id="bib.bib35.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">Proceedings of the IEEE conference on computer vision and
pattern recognition</span><span id="bib.bib35.5.3" class="ltx_text" style="font-size:80%;">, pages 4510–4520, 2018.
</span>
</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock"><span id="bib.bib36.1.1" class="ltx_text" style="font-size:80%;">
Swami Sankaranarayanan, Yogesh Balaji, Arpit Jain, Ser Nam Lim, and Rama
Chellappa.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.2.1" class="ltx_text" style="font-size:80%;">Unsupervised domain adaptation for semantic segmentation with gans.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.3.1" class="ltx_text ltx_font_italic" style="font-size:80%;">arXiv preprint arXiv:1711.06969</span><span id="bib.bib36.4.2" class="ltx_text" style="font-size:80%;">, 2, 2017.
</span>
</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock"><span id="bib.bib37.1.1" class="ltx_text" style="font-size:80%;">
Swami Sankaranarayanan, Yogesh Balaji, Arpit Jain, Ser Nam Lim, and Rama
Chellappa.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.2.1" class="ltx_text" style="font-size:80%;">Learning from synthetic data: Addressing domain shift for semantic
segmentation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.3.1" class="ltx_text" style="font-size:80%;">In </span><span id="bib.bib37.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib37.5.3" class="ltx_text" style="font-size:80%;">, pages 3752–3761, 2018.
</span>
</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock"><span id="bib.bib38.1.1" class="ltx_text" style="font-size:80%;">
Tamar Rott Shaham, Tali Dekel, and Tomer Michaeli.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.2.1" class="ltx_text" style="font-size:80%;">Singan: Learning a generative model from a single natural image.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.3.1" class="ltx_text" style="font-size:80%;">In </span><span id="bib.bib38.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">Proceedings of the IEEE International Conference on Computer
Vision</span><span id="bib.bib38.5.3" class="ltx_text" style="font-size:80%;">, pages 4570–4580, 2019.
</span>
</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock"><span id="bib.bib39.1.1" class="ltx_text" style="font-size:80%;">
Flood Sung, Yongxin Yang, Li Zhang, Tao Xiang, Philip HS Torr, and Timothy M
Hospedales.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.2.1" class="ltx_text" style="font-size:80%;">Learning to compare: Relation network for few-shot learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.3.1" class="ltx_text" style="font-size:80%;">In </span><span id="bib.bib39.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib39.5.3" class="ltx_text" style="font-size:80%;">, pages 1199–1208, 2018.
</span>
</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock"><span id="bib.bib40.1.1" class="ltx_text" style="font-size:80%;">
Antonio Torralba, Alexei A Efros, et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.2.1" class="ltx_text" style="font-size:80%;">Unbiased look at dataset bias.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.3.1" class="ltx_text" style="font-size:80%;">In </span><span id="bib.bib40.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">Computer Vision and Pattern Recognition Conference</span><span id="bib.bib40.5.3" class="ltx_text" style="font-size:80%;">,
volume 1, page 7. Citeseer, 2011.
</span>
</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock"><span id="bib.bib41.1.1" class="ltx_text" style="font-size:80%;">
Mei Wang and Weihong Deng.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib41.2.1" class="ltx_text" style="font-size:80%;">Deep visual domain adaptation: A survey.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib41.3.1" class="ltx_text ltx_font_italic" style="font-size:80%;">Neurocomputing</span><span id="bib.bib41.4.2" class="ltx_text" style="font-size:80%;">, 312:135–153, 2018.
</span>
</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock"><span id="bib.bib42.1.1" class="ltx_text" style="font-size:80%;">
Zili Yi, Hao Zhang, Ping Tan, and Minglun Gong.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.2.1" class="ltx_text" style="font-size:80%;">Dualgan: Unsupervised dual learning for image-to-image translation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.3.1" class="ltx_text" style="font-size:80%;">In </span><span id="bib.bib42.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">Proceedings of the IEEE international conference on computer
vision</span><span id="bib.bib42.5.3" class="ltx_text" style="font-size:80%;">, pages 2849–2857, 2017.
</span>
</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock"><span id="bib.bib43.1.1" class="ltx_text" style="font-size:80%;">
Fisher Yu, Wenqi Xian, Yingying Chen, Fangchen Liu, Mike Liao, Vashisht
Madhavan, and Trevor Darrell.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib43.2.1" class="ltx_text" style="font-size:80%;">Bdd100k: A diverse driving video database with scalable annotation
tooling.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib43.3.1" class="ltx_text ltx_font_italic" style="font-size:80%;">arXiv preprint arXiv:1805.04687</span><span id="bib.bib43.4.2" class="ltx_text" style="font-size:80%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock"><span id="bib.bib44.1.1" class="ltx_text" style="font-size:80%;">
Tinghui Zhou, Matthew Brown, Noah Snavely, and David G Lowe.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib44.2.1" class="ltx_text" style="font-size:80%;">Unsupervised learning of depth and ego-motion from video.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib44.3.1" class="ltx_text" style="font-size:80%;">In </span><span id="bib.bib44.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">CVPR</span><span id="bib.bib44.5.3" class="ltx_text" style="font-size:80%;">, volume 2, page 7, 2017.
</span>
</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock"><span id="bib.bib45.1.1" class="ltx_text" style="font-size:80%;">
Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei A Efros.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib45.2.1" class="ltx_text" style="font-size:80%;">Unpaired image-to-image translation using cycle-consistent
adversarial networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib45.3.1" class="ltx_text" style="font-size:80%;">In </span><span id="bib.bib45.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">Proceedings of the IEEE international conference on computer
vision</span><span id="bib.bib45.5.3" class="ltx_text" style="font-size:80%;">, pages 2223–2232, 2017.
</span>
</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="S1a" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">A </span>Supplementary Material</h2>

<div id="S1a.p1" class="ltx_para">
<p id="S1a.p1.1" class="ltx_p">Section <a href="#S1.SS1" title="A.1 Noise Factor Distribution of Simulated Data ‣ A Supplementary Material ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.1</span></a> of this supplementary material gives a deeper insight into the noise factor distribution of simulated data generated using Unreal Engine<span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><a target="_blank" href="https://www.unrealengine.com/en-US/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.unrealengine.com/en-US/</a></span></span></span> for the targeted synthetic data augmentation case studies of parking slot detection and traffic lane detection. Since simulated data used for the third case study of monocular depth estimation was sampled from the publicly available virtual KITTI <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> dataset with source details provided in the main paper, we do not include any additional statistics here. Example simulated images used for the depth estimation task are shown in Fig. <a href="#S1.F15" title="Figure 15 ‣ A.5 Case Studies: Additional Quantitative Results ‣ A Supplementary Material ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">15</span></a> in Section <a href="#S1.SS5" title="A.5 Case Studies: Additional Quantitative Results ‣ A Supplementary Material ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.5</span></a>.</p>
</div>
<div id="S1a.p2" class="ltx_para">
<p id="S1a.p2.1" class="ltx_p">Qualitative results of targeted synthetic data augmentation are also included in this supplementary material in Sections <a href="#S1.SS2" title="A.2 Parking Slot Detection: Qualitative Results ‣ A Supplementary Material ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.2</span></a>, <a href="#S1.SS3" title="A.3 Traffic Lane Detection: Qualitative Results ‣ A Supplementary Material ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.3</span></a> and <a href="#S1.SS4" title="A.4 Depth Estimation: Qualitative Results ‣ A Supplementary Material ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.4</span></a> for the tasks of slot detection, lane detection and depth estimation respectively. Fig. <a href="#S1.F10" title="Figure 10 ‣ A.2 Parking Slot Detection: Qualitative Results ‣ A Supplementary Material ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a> shows qualitative results of cross-dataset generalization experiments from the paper for the task of parking slot detection. Note the significant improvement in the number of true positives and their confidence scores as we move from left to right with the leftmost column showing results from the model trained on 100% real data, middle column showing results from the best model trained on a mix of real and simulated data (A + S) and right most column showing results from the best model trained on a mix of real and sim2real data (A + G). Fig. <a href="#S1.F11" title="Figure 11 ‣ A.3 Traffic Lane Detection: Qualitative Results ‣ A Supplementary Material ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a> shows qualitative results of the cross-dataset generalization experiments from the paper for the task of lane detection.
The baseline model trained on 100% real CULane <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> data (first column in Fig. <a href="#S1.F11" title="Figure 11 ‣ A.3 Traffic Lane Detection: Qualitative Results ‣ A Supplementary Material ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a>) results in lots of false negatives (highlighted in red squares) and false positives (highlighted in yellow squares) when tested on the TuSimple<span id="footnote5" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span><a target="_blank" href="https://github.com/TuSimple/tusimple-benchmark/tree/master/doc/lane_detection" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/TuSimple/tusimple-benchmark/tree/master/doc/lane_detection</a></span></span></span> dataset. Among the models trained with a mix of real and simulated data from Unreal Engine (A + S), the best model is the one trained on 70% real and 30% sim data (second column in Fig. <a href="#S1.F11" title="Figure 11 ‣ A.3 Traffic Lane Detection: Qualitative Results ‣ A Supplementary Material ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a>) and results in fewer false negatives as compared to the baseline, but the number of false positives goes up. Overall, the best results are obtained with a model trained on 40% real and 60% sim2real data (A + G) with a significantly reduced number of false positives and negatives (last column in Fig. <a href="#S1.F11" title="Figure 11 ‣ A.3 Traffic Lane Detection: Qualitative Results ‣ A Supplementary Material ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a>).
Fig. <a href="#S1.F12" title="Figure 12 ‣ A.4 Depth Estimation: Qualitative Results ‣ A Supplementary Material ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">12</span></a> shows qualitative results of the cross-data generalization experiments for the single-image depth task. The best result is achieved by the model trained on a mix of 40% real and 60% sim data (A + S). For sim2real data augmentation, quantitatively, the best result is achieved by the model trained on a mix of 50% real and 50% sim2real data (A + G). However, for the sake of fair comparison, results in Fig. <a href="#S1.F12" title="Figure 12 ‣ A.4 Depth Estimation: Qualitative Results ‣ A Supplementary Material ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">12</span></a> are shown with the A + G model with 60% synthetic data. As highlighted by the zoomed-in section within each depth map, it can be clearly seen that training on a mix of real and simulated data improves the quality of depth map, especially around periphery of the vehicle silhouettes (Row 3). Moreover, adding sim2real data to the real dataset improves the quality of the predicted depth maps even further (Row 4).</p>
</div>
<div id="S1a.p3" class="ltx_para">
<p id="S1a.p3.1" class="ltx_p">Section <a href="#S1.SS5" title="A.5 Case Studies: Additional Quantitative Results ‣ A Supplementary Material ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.5</span></a> provides additional quantitative results for the three tasks. In particular, Table. <a href="#S1.T7" title="Table 7 ‣ A.5 Case Studies: Additional Quantitative Results ‣ A Supplementary Material ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> provides additional quantitative insights into the role of synthetic data augmentation in improving the number of true positives and false positives for the slot detection task. Table <a href="#S1.T6" title="Table 6 ‣ A.5 Case Studies: Additional Quantitative Results ‣ A Supplementary Material ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> shows how increasing dropout regularization does not help improve generalization performance of models trained on 100% real data. Fig. <a href="#S1.F14" title="Figure 14 ‣ A.5 Case Studies: Additional Quantitative Results ‣ A Supplementary Material ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">14</span></a> and Table <a href="#S1.T8" title="Table 8 ‣ A.5 Case Studies: Additional Quantitative Results ‣ A Supplementary Material ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> together provide a summary of cross-dataset testing results for lane detection models trained on TuSimple and tested on CULane. Consistent with the results in the main paper from models trained on CULane and tested on TuSimple, synthetic data augmentation helps deflate inherent bias in the TuSimple dataset and improve cross dataset generalization performance. Fig. <a href="#S1.F16" title="Figure 16 ‣ A.5 Case Studies: Additional Quantitative Results ‣ A Supplementary Material ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">16</span></a> provides additional quantitative results from the cross-dataset generalization experiments for the task of depth estimation.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="S1.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.1 </span>Noise Factor Distribution of Simulated Data</h3>

<div id="S1.SS1.p1" class="ltx_para">
<p id="S1.SS1.p1.1" class="ltx_p">The simulated data for both the parking slot detection and lane detection tasks was generated using an in-house Unreal Engine-based pipeline. Table <a href="#S1.T4" title="Table 4 ‣ A.1 Noise Factor Distribution of Simulated Data ‣ A Supplementary Material ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> lists the noise factors along with their range of variation that were used to generate the simulated data for the lane detection task. For each noise factor, values were randomly sampled from a uniform distribution within the specified range. The road spline was randomly generated as well but with some checks to ensure the spline was smooth and did not break or loop back on itself. A total of 300 scenarios were thus created with 300 frames in each leading to a total of 90000 simulated images. Table <a href="#S1.T5" title="Table 5 ‣ A.1 Noise Factor Distribution of Simulated Data ‣ A Supplementary Material ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> lists the noise factors varied for the parking slot detection task to generate 7 simulated scenarios resulting in a total of 15565 images for training.</p>
</div>
<figure id="S1.T4" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table"><span id="S1.T4.4.1.1" class="ltx_text" style="font-size:113%;">Table 4</span>: </span><span id="S1.T4.5.2" class="ltx_text" style="font-size:113%;">List of noise factors along with their range of variation used for generating the simulated data for the lane detection task. All factors except for sun intensity and cloud density are integer values. Factors for which no units are specified are unitless by design.</span></figcaption>
<table id="S1.T4.6" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S1.T4.6.1.1" class="ltx_tr">
<th id="S1.T4.6.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_tt"><span id="S1.T4.6.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Noise Factor</span></th>
<td id="S1.T4.6.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span id="S1.T4.6.1.1.2.1" class="ltx_text" style="font-size:80%;">Sun Intensity</span></td>
<td id="S1.T4.6.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span id="S1.T4.6.1.1.3.1" class="ltx_text" style="font-size:80%;">Cloud Density</span></td>
<td id="S1.T4.6.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span id="S1.T4.6.1.1.4.1" class="ltx_text" style="font-size:80%;">Sun Angle</span></td>
<td id="S1.T4.6.1.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span id="S1.T4.6.1.1.5.1" class="ltx_text" style="font-size:80%;">Traffic Density</span></td>
<td id="S1.T4.6.1.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span id="S1.T4.6.1.1.6.1" class="ltx_text" style="font-size:80%;">Traffic Speed</span></td>
<td id="S1.T4.6.1.1.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span id="S1.T4.6.1.1.7.1" class="ltx_text" style="font-size:80%;">No. of Lanes</span></td>
<td id="S1.T4.6.1.1.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span id="S1.T4.6.1.1.8.1" class="ltx_text" style="font-size:80%;">Speed Limit</span></td>
</tr>
<tr id="S1.T4.6.2.2" class="ltx_tr">
<th id="S1.T4.6.2.2.1" class="ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_rr"></th>
<td id="S1.T4.6.2.2.2" class="ltx_td ltx_border_r"></td>
<td id="S1.T4.6.2.2.3" class="ltx_td ltx_border_r"></td>
<td id="S1.T4.6.2.2.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T4.6.2.2.4.1" class="ltx_text" style="font-size:80%;">Pitch + Yaw (deg)</span></td>
<td id="S1.T4.6.2.2.5" class="ltx_td ltx_border_r"></td>
<td id="S1.T4.6.2.2.6" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T4.6.2.2.6.1" class="ltx_text" style="font-size:80%;">Std. Dev.</span></td>
<td id="S1.T4.6.2.2.7" class="ltx_td ltx_border_r"></td>
<td id="S1.T4.6.2.2.8" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T4.6.2.2.8.1" class="ltx_text" style="font-size:80%;">(mph)</span></td>
</tr>
<tr id="S1.T4.6.3.3" class="ltx_tr">
<th id="S1.T4.6.3.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_l ltx_border_rr ltx_border_t"><span id="S1.T4.6.3.3.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Range</span></th>
<td id="S1.T4.6.3.3.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t"><span id="S1.T4.6.3.3.2.1" class="ltx_text" style="font-size:80%;">[0, 3]</span></td>
<td id="S1.T4.6.3.3.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t"><span id="S1.T4.6.3.3.3.1" class="ltx_text" style="font-size:80%;">[0, 2.5]</span></td>
<td id="S1.T4.6.3.3.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t"><span id="S1.T4.6.3.3.4.1" class="ltx_text" style="font-size:80%;">[0, 180]</span></td>
<td id="S1.T4.6.3.3.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t"><span id="S1.T4.6.3.3.5.1" class="ltx_text" style="font-size:80%;">[5,20]</span></td>
<td id="S1.T4.6.3.3.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t"><span id="S1.T4.6.3.3.6.1" class="ltx_text" style="font-size:80%;">[0, 30]</span></td>
<td id="S1.T4.6.3.3.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t"><span id="S1.T4.6.3.3.7.1" class="ltx_text" style="font-size:80%;">[1, 4]</span></td>
<td id="S1.T4.6.3.3.8" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t"><span id="S1.T4.6.3.3.8.1" class="ltx_text" style="font-size:80%;">[50, 90]</span></td>
</tr>
</tbody>
</table>
</figure>
<figure id="S1.T5" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table"><span id="S1.T5.4.1.1" class="ltx_text" style="font-size:113%;">Table 5</span>: </span><span id="S1.T5.5.2" class="ltx_text" style="font-size:113%;">List of noise factors varied for generating simulated data for the slot detection task. The header S.No. stands for scenarios numbers, which indicate the 7 different scenarios simulated based on the noise factors descriptions listed against them.</span></figcaption>
<table id="S1.T5.6" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S1.T5.6.1.1" class="ltx_tr">
<th id="S1.T5.6.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_tt"><span id="S1.T5.6.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">S.No.</span></th>
<th id="S1.T5.6.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt"><span id="S1.T5.6.1.1.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Weather</span></th>
<th id="S1.T5.6.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt"><span id="S1.T5.6.1.1.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Parking</span></th>
<th id="S1.T5.6.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt"><span id="S1.T5.6.1.1.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Line</span></th>
<th id="S1.T5.6.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt"><span id="S1.T5.6.1.1.5.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Line</span></th>
<th id="S1.T5.6.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt"><span id="S1.T5.6.1.1.6.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Line</span></th>
<th id="S1.T5.6.1.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt"><span id="S1.T5.6.1.1.7.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Time</span></th>
<th id="S1.T5.6.1.1.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt"><span id="S1.T5.6.1.1.8.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Sun</span></th>
<th id="S1.T5.6.1.1.9" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt"><span id="S1.T5.6.1.1.9.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Sun</span></th>
<th id="S1.T5.6.1.1.10" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt"><span id="S1.T5.6.1.1.10.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Ground</span></th>
<th id="S1.T5.6.1.1.11" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt"><span id="S1.T5.6.1.1.11.1" class="ltx_text ltx_font_bold" style="font-size:80%;">True</span></th>
<th id="S1.T5.6.1.1.12" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt"><span id="S1.T5.6.1.1.12.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Cloud</span></th>
<th id="S1.T5.6.1.1.13" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt"><span id="S1.T5.6.1.1.13.1" class="ltx_text ltx_font_bold" style="font-size:80%;">No. of</span></th>
</tr>
<tr id="S1.T5.6.2.2" class="ltx_tr">
<th id="S1.T5.6.2.2.1" class="ltx_td ltx_th ltx_th_column ltx_border_l ltx_border_r"></th>
<th id="S1.T5.6.2.2.2" class="ltx_td ltx_th ltx_th_column ltx_border_r"></th>
<th id="S1.T5.6.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r"><span id="S1.T5.6.2.2.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Density</span></th>
<th id="S1.T5.6.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r"><span id="S1.T5.6.2.2.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Color</span></th>
<th id="S1.T5.6.2.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r"><span id="S1.T5.6.2.2.5.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Damage</span></th>
<th id="S1.T5.6.2.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r"><span id="S1.T5.6.2.2.6.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Thickness</span></th>
<th id="S1.T5.6.2.2.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r"><span id="S1.T5.6.2.2.7.1" class="ltx_text ltx_font_bold" style="font-size:80%;">of Day</span></th>
<th id="S1.T5.6.2.2.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r"><span id="S1.T5.6.2.2.8.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Angle</span></th>
<th id="S1.T5.6.2.2.9" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r"><span id="S1.T5.6.2.2.9.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Intensity</span></th>
<th id="S1.T5.6.2.2.10" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r"><span id="S1.T5.6.2.2.10.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Material</span></th>
<th id="S1.T5.6.2.2.11" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r"><span id="S1.T5.6.2.2.11.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Negatives</span></th>
<th id="S1.T5.6.2.2.12" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r"><span id="S1.T5.6.2.2.12.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Opacity</span></th>
<th id="S1.T5.6.2.2.13" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r"><span id="S1.T5.6.2.2.13.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Frames</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S1.T5.6.3.1" class="ltx_tr">
<td id="S1.T5.6.3.1.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t"><span id="S1.T5.6.3.1.1.1" class="ltx_text" style="font-size:80%;">1</span></td>
<td id="S1.T5.6.3.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S1.T5.6.3.1.2.1" class="ltx_text" style="font-size:80%;">clear</span></td>
<td id="S1.T5.6.3.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S1.T5.6.3.1.3.1" class="ltx_text" style="font-size:80%;">heavy</span></td>
<td id="S1.T5.6.3.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S1.T5.6.3.1.4.1" class="ltx_text" style="font-size:80%;">yellow</span></td>
<td id="S1.T5.6.3.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S1.T5.6.3.1.5.1" class="ltx_text" style="font-size:80%;">1</span></td>
<td id="S1.T5.6.3.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S1.T5.6.3.1.6.1" class="ltx_text" style="font-size:80%;">0.05</span></td>
<td id="S1.T5.6.3.1.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S1.T5.6.3.1.7.1" class="ltx_text" style="font-size:80%;">10 am</span></td>
<td id="S1.T5.6.3.1.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S1.T5.6.3.1.8.1" class="ltx_text" style="font-size:80%;">(-60, 45)</span></td>
<td id="S1.T5.6.3.1.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S1.T5.6.3.1.9.1" class="ltx_text" style="font-size:80%;">5</span></td>
<td id="S1.T5.6.3.1.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S1.T5.6.3.1.10.1" class="ltx_text" style="font-size:80%;">cracked</span></td>
<td id="S1.T5.6.3.1.11" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S1.T5.6.3.1.11.1" class="ltx_text" style="font-size:80%;">trees, signs</span></td>
<td id="S1.T5.6.3.1.12" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S1.T5.6.3.1.12.1" class="ltx_text" style="font-size:80%;">1</span></td>
<td id="S1.T5.6.3.1.13" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S1.T5.6.3.1.13.1" class="ltx_text" style="font-size:80%;">2084</span></td>
</tr>
<tr id="S1.T5.6.4.2" class="ltx_tr">
<td id="S1.T5.6.4.2.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r"><span id="S1.T5.6.4.2.1.1" class="ltx_text" style="font-size:80%;">2</span></td>
<td id="S1.T5.6.4.2.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T5.6.4.2.2.1" class="ltx_text" style="font-size:80%;">clear</span></td>
<td id="S1.T5.6.4.2.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T5.6.4.2.3.1" class="ltx_text" style="font-size:80%;">medium</span></td>
<td id="S1.T5.6.4.2.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T5.6.4.2.4.1" class="ltx_text" style="font-size:80%;">white</span></td>
<td id="S1.T5.6.4.2.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T5.6.4.2.5.1" class="ltx_text" style="font-size:80%;">0.1</span></td>
<td id="S1.T5.6.4.2.6" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T5.6.4.2.6.1" class="ltx_text" style="font-size:80%;">0.12</span></td>
<td id="S1.T5.6.4.2.7" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T5.6.4.2.7.1" class="ltx_text" style="font-size:80%;">8 am</span></td>
<td id="S1.T5.6.4.2.8" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T5.6.4.2.8.1" class="ltx_text" style="font-size:80%;">(-30, 45)</span></td>
<td id="S1.T5.6.4.2.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T5.6.4.2.9.1" class="ltx_text" style="font-size:80%;">3</span></td>
<td id="S1.T5.6.4.2.10" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T5.6.4.2.10.1" class="ltx_text" style="font-size:80%;">asphalt</span></td>
<td id="S1.T5.6.4.2.11" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T5.6.4.2.11.1" class="ltx_text" style="font-size:80%;">trees, signs</span></td>
<td id="S1.T5.6.4.2.12" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T5.6.4.2.12.1" class="ltx_text" style="font-size:80%;">1</span></td>
<td id="S1.T5.6.4.2.13" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T5.6.4.2.13.1" class="ltx_text" style="font-size:80%;">2071</span></td>
</tr>
<tr id="S1.T5.6.5.3" class="ltx_tr">
<td id="S1.T5.6.5.3.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r"><span id="S1.T5.6.5.3.1.1" class="ltx_text" style="font-size:80%;">3</span></td>
<td id="S1.T5.6.5.3.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T5.6.5.3.2.1" class="ltx_text" style="font-size:80%;">clear</span></td>
<td id="S1.T5.6.5.3.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T5.6.5.3.3.1" class="ltx_text" style="font-size:80%;">medium</span></td>
<td id="S1.T5.6.5.3.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T5.6.5.3.4.1" class="ltx_text" style="font-size:80%;">yellow</span></td>
<td id="S1.T5.6.5.3.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T5.6.5.3.5.1" class="ltx_text" style="font-size:80%;">0.1</span></td>
<td id="S1.T5.6.5.3.6" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T5.6.5.3.6.1" class="ltx_text" style="font-size:80%;">0.15</span></td>
<td id="S1.T5.6.5.3.7" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T5.6.5.3.7.1" class="ltx_text" style="font-size:80%;">10 am</span></td>
<td id="S1.T5.6.5.3.8" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T5.6.5.3.8.1" class="ltx_text" style="font-size:80%;">(-60, 90)</span></td>
<td id="S1.T5.6.5.3.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T5.6.5.3.9.1" class="ltx_text" style="font-size:80%;">10</span></td>
<td id="S1.T5.6.5.3.10" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T5.6.5.3.10.1" class="ltx_text" style="font-size:80%;">cracked</span></td>
<td id="S1.T5.6.5.3.11" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T5.6.5.3.11.1" class="ltx_text" style="font-size:80%;">side walk</span></td>
<td id="S1.T5.6.5.3.12" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T5.6.5.3.12.1" class="ltx_text" style="font-size:80%;">1</span></td>
<td id="S1.T5.6.5.3.13" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T5.6.5.3.13.1" class="ltx_text" style="font-size:80%;">2427</span></td>
</tr>
<tr id="S1.T5.6.6.4" class="ltx_tr">
<td id="S1.T5.6.6.4.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r"><span id="S1.T5.6.6.4.1.1" class="ltx_text" style="font-size:80%;">4</span></td>
<td id="S1.T5.6.6.4.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T5.6.6.4.2.1" class="ltx_text" style="font-size:80%;">clear</span></td>
<td id="S1.T5.6.6.4.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T5.6.6.4.3.1" class="ltx_text" style="font-size:80%;">light</span></td>
<td id="S1.T5.6.6.4.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T5.6.6.4.4.1" class="ltx_text" style="font-size:80%;">white</span></td>
<td id="S1.T5.6.6.4.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T5.6.6.4.5.1" class="ltx_text" style="font-size:80%;">0.5</span></td>
<td id="S1.T5.6.6.4.6" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T5.6.6.4.6.1" class="ltx_text" style="font-size:80%;">0.15</span></td>
<td id="S1.T5.6.6.4.7" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T5.6.6.4.7.1" class="ltx_text" style="font-size:80%;">12 pm</span></td>
<td id="S1.T5.6.6.4.8" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T5.6.6.4.8.1" class="ltx_text" style="font-size:80%;">(-90, 90)</span></td>
<td id="S1.T5.6.6.4.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T5.6.6.4.9.1" class="ltx_text" style="font-size:80%;">8</span></td>
<td id="S1.T5.6.6.4.10" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T5.6.6.4.10.1" class="ltx_text" style="font-size:80%;">cracked</span></td>
<td id="S1.T5.6.6.4.11" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T5.6.6.4.11.1" class="ltx_text" style="font-size:80%;">side walk</span></td>
<td id="S1.T5.6.6.4.12" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T5.6.6.4.12.1" class="ltx_text" style="font-size:80%;">3</span></td>
<td id="S1.T5.6.6.4.13" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T5.6.6.4.13.1" class="ltx_text" style="font-size:80%;">2415</span></td>
</tr>
<tr id="S1.T5.6.7.5" class="ltx_tr">
<td id="S1.T5.6.7.5.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r"><span id="S1.T5.6.7.5.1.1" class="ltx_text" style="font-size:80%;">5</span></td>
<td id="S1.T5.6.7.5.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T5.6.7.5.2.1" class="ltx_text" style="font-size:80%;">clear</span></td>
<td id="S1.T5.6.7.5.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T5.6.7.5.3.1" class="ltx_text" style="font-size:80%;">light</span></td>
<td id="S1.T5.6.7.5.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T5.6.7.5.4.1" class="ltx_text" style="font-size:80%;">yellow</span></td>
<td id="S1.T5.6.7.5.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T5.6.7.5.5.1" class="ltx_text" style="font-size:80%;">0.2</span></td>
<td id="S1.T5.6.7.5.6" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T5.6.7.5.6.1" class="ltx_text" style="font-size:80%;">0.1</span></td>
<td id="S1.T5.6.7.5.7" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T5.6.7.5.7.1" class="ltx_text" style="font-size:80%;">2 pm</span></td>
<td id="S1.T5.6.7.5.8" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T5.6.7.5.8.1" class="ltx_text" style="font-size:80%;">(-120, 60)</span></td>
<td id="S1.T5.6.7.5.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T5.6.7.5.9.1" class="ltx_text" style="font-size:80%;">10</span></td>
<td id="S1.T5.6.7.5.10" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T5.6.7.5.10.1" class="ltx_text" style="font-size:80%;">asphalt</span></td>
<td id="S1.T5.6.7.5.11" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T5.6.7.5.11.1" class="ltx_text" style="font-size:80%;">side walk</span></td>
<td id="S1.T5.6.7.5.12" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T5.6.7.5.12.1" class="ltx_text" style="font-size:80%;">1</span></td>
<td id="S1.T5.6.7.5.13" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T5.6.7.5.13.1" class="ltx_text" style="font-size:80%;">2133</span></td>
</tr>
<tr id="S1.T5.6.8.6" class="ltx_tr">
<td id="S1.T5.6.8.6.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r"><span id="S1.T5.6.8.6.1.1" class="ltx_text" style="font-size:80%;">6</span></td>
<td id="S1.T5.6.8.6.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T5.6.8.6.2.1" class="ltx_text" style="font-size:80%;">overcast</span></td>
<td id="S1.T5.6.8.6.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T5.6.8.6.3.1" class="ltx_text" style="font-size:80%;">heavy</span></td>
<td id="S1.T5.6.8.6.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T5.6.8.6.4.1" class="ltx_text" style="font-size:80%;">white</span></td>
<td id="S1.T5.6.8.6.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T5.6.8.6.5.1" class="ltx_text" style="font-size:80%;">0.5</span></td>
<td id="S1.T5.6.8.6.6" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T5.6.8.6.6.1" class="ltx_text" style="font-size:80%;">0.1</span></td>
<td id="S1.T5.6.8.6.7" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T5.6.8.6.7.1" class="ltx_text" style="font-size:80%;">4 pm</span></td>
<td id="S1.T5.6.8.6.8" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T5.6.8.6.8.1" class="ltx_text" style="font-size:80%;">(-160, 75)</span></td>
<td id="S1.T5.6.8.6.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T5.6.8.6.9.1" class="ltx_text" style="font-size:80%;">1</span></td>
<td id="S1.T5.6.8.6.10" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T5.6.8.6.10.1" class="ltx_text" style="font-size:80%;">cracked</span></td>
<td id="S1.T5.6.8.6.11" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T5.6.8.6.11.1" class="ltx_text" style="font-size:80%;">side walk</span></td>
<td id="S1.T5.6.8.6.12" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T5.6.8.6.12.1" class="ltx_text" style="font-size:80%;">3</span></td>
<td id="S1.T5.6.8.6.13" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T5.6.8.6.13.1" class="ltx_text" style="font-size:80%;">1632</span></td>
</tr>
<tr id="S1.T5.6.9.7" class="ltx_tr">
<td id="S1.T5.6.9.7.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_l ltx_border_r"><span id="S1.T5.6.9.7.1.1" class="ltx_text" style="font-size:80%;">7</span></td>
<td id="S1.T5.6.9.7.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S1.T5.6.9.7.2.1" class="ltx_text" style="font-size:80%;">overcast</span></td>
<td id="S1.T5.6.9.7.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S1.T5.6.9.7.3.1" class="ltx_text" style="font-size:80%;">light</span></td>
<td id="S1.T5.6.9.7.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S1.T5.6.9.7.4.1" class="ltx_text" style="font-size:80%;">yellow</span></td>
<td id="S1.T5.6.9.7.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S1.T5.6.9.7.5.1" class="ltx_text" style="font-size:80%;">0.5</span></td>
<td id="S1.T5.6.9.7.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S1.T5.6.9.7.6.1" class="ltx_text" style="font-size:80%;">0.05</span></td>
<td id="S1.T5.6.9.7.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S1.T5.6.9.7.7.1" class="ltx_text" style="font-size:80%;">8 am</span></td>
<td id="S1.T5.6.9.7.8" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S1.T5.6.9.7.8.1" class="ltx_text" style="font-size:80%;">(-30, 60)</span></td>
<td id="S1.T5.6.9.7.9" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S1.T5.6.9.7.9.1" class="ltx_text" style="font-size:80%;">1</span></td>
<td id="S1.T5.6.9.7.10" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S1.T5.6.9.7.10.1" class="ltx_text" style="font-size:80%;">asphalt</span></td>
<td id="S1.T5.6.9.7.11" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S1.T5.6.9.7.11.1" class="ltx_text" style="font-size:80%;">grass</span></td>
<td id="S1.T5.6.9.7.12" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S1.T5.6.9.7.12.1" class="ltx_text" style="font-size:80%;">1</span></td>
<td id="S1.T5.6.9.7.13" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S1.T5.6.9.7.13.1" class="ltx_text" style="font-size:80%;">2803</span></td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="S1.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.2 </span>Parking Slot Detection: Qualitative Results</h3>

<figure id="S1.F10" class="ltx_figure"><img src="/html/2004.13866/assets/x10.png" id="S1.F10.g1" class="ltx_graphics ltx_centering ltx_img_square" width="461" height="420" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F10.2.1.1" class="ltx_text" style="font-size:90%;">Figure 10</span>: </span><span id="S1.F10.3.2" class="ltx_text" style="font-size:90%;">Qualitative comparison of slot detection results on the held-out Parking B test set. Each row shows results on one example test image. Here, black boxes denote ground truth and green boxes are model predictions. The three columns from left to right show results from models trained on real Parking A dataset only, models trained on a mix of real and simulated data and models trained on a mix of real and sim2real data translated to look like Parking A real data. Note the number of true positives (TPs) and confidence scores increases from left to right. The first row shows how the number of TPs increases and the last row shows how confidence score goes from undetected to detected with a confidence improvement from 31% to 93% confidence for the same image. Confidence scores are best viewed by zooming into the relevant figure.</span></figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="S1.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.3 </span>Traffic Lane Detection: Qualitative Results</h3>

<figure id="S1.F11" class="ltx_figure"><img src="/html/2004.13866/assets/x11.png" id="S1.F11.g1" class="ltx_graphics ltx_centering ltx_img_square" width="528" height="529" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F11.2.1.1" class="ltx_text" style="font-size:90%;">Figure 11</span>: </span><span id="S1.F11.3.2" class="ltx_text" style="font-size:90%;">Qualitative results from the cross-dataset generalization experiments (train on CULane, test on TuSimple) in the paper for the task of lane detection. Columns (a), (b) and (c) show the results from models trained on 100% real data, 70% real + 30% sim data and 40% real + 60% sim2real data respectively. The red dashed squares highlight false negatives and the yellow dashed squares highlight false positives.</span></figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="S1.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.4 </span>Depth Estimation: Qualitative Results</h3>

<figure id="S1.F12" class="ltx_figure"><img src="/html/2004.13866/assets/figs/depth/rgb2depth_qualitative.jpg" id="S1.F12.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="685" height="262" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F12.2.1.1" class="ltx_text" style="font-size:90%;">Figure 12</span>: </span><span id="S1.F12.3.2" class="ltx_text" style="font-size:90%;">Qualitative comparison of results from single-image depth estimation models trained on the KITTI Odometry Sequence 00 + Virtual KITTI datasets and tested on the KITTI Tracking dataset. Row 1 shows two different test images from KITTI tracking dataset, Row 2 shows the corresponding depth estimation results from a model trained on 100% real data, Row 3 shows the depth estimation results from a model trained on 40% real + 60% sim and Row 4 shows the depth estimation results from a model trained on 40% real + 60% sim2real data.The addition of sim and sim2real data in the training mix (rows 3 and 4) improves the crispness of the depth estimation along vehicle boundaries as shown by the expanded insets.
</span></figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="S1.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.5 </span>Case Studies: Additional Quantitative Results</h3>

<figure id="S1.T6" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table"><span id="S1.T6.5.1.1" class="ltx_text" style="font-size:113%;">Table 6</span>: </span><span id="S1.T6.6.2" class="ltx_text" style="font-size:113%;">Summary of MobileNetV2 SSD based parking slot detection cross-dataset testing results (train on Parking A, test on Parking B) for varying dropout percentages. F-Measure was 0% for all models.</span></figcaption>
<table id="S1.T6.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S1.T6.1.2.1" class="ltx_tr">
<th id="S1.T6.1.2.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_rr ltx_border_tt"><span id="S1.T6.1.2.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Dropout</span></th>
<th id="S1.T6.1.2.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt"><span id="S1.T6.1.2.1.2.1" class="ltx_text" style="font-size:80%;">0%</span></th>
<th id="S1.T6.1.2.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt"><span id="S1.T6.1.2.1.3.1" class="ltx_text" style="font-size:80%;">0.5%</span></th>
<th id="S1.T6.1.2.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt"><span id="S1.T6.1.2.1.4.1" class="ltx_text" style="font-size:80%;">1%</span></th>
<th id="S1.T6.1.2.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt"><span id="S1.T6.1.2.1.5.1" class="ltx_text" style="font-size:80%;">10%</span></th>
<th id="S1.T6.1.2.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt"><span id="S1.T6.1.2.1.6.1" class="ltx_text" style="font-size:80%;">90%</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S1.T6.1.1" class="ltx_tr">
<td id="S1.T6.1.1.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_l ltx_border_rr ltx_border_t">
<span id="S1.T6.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">False Positives</span><span id="S1.T6.1.1.1.2" class="ltx_text" style="font-size:80%;"> (</span><math id="S1.T6.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S1.T6.1.1.1.m1.1a"><mo mathsize="80%" stretchy="false" id="S1.T6.1.1.1.m1.1.1" xref="S1.T6.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S1.T6.1.1.1.m1.1b"><ci id="S1.T6.1.1.1.m1.1.1.cmml" xref="S1.T6.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T6.1.1.1.m1.1c">\downarrow</annotation></semantics></math><span id="S1.T6.1.1.1.3" class="ltx_text" style="font-size:80%;">)</span>
</td>
<td id="S1.T6.1.1.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t"><span id="S1.T6.1.1.2.1" class="ltx_text" style="font-size:80%;">252</span></td>
<td id="S1.T6.1.1.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t"><span id="S1.T6.1.1.3.1" class="ltx_text" style="font-size:80%;">58</span></td>
<td id="S1.T6.1.1.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t"><span id="S1.T6.1.1.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;color:#00FF00;">3</span></td>
<td id="S1.T6.1.1.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t"><span id="S1.T6.1.1.5.1" class="ltx_text" style="font-size:80%;">91</span></td>
<td id="S1.T6.1.1.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t"><span id="S1.T6.1.1.6.1" class="ltx_text" style="font-size:80%;">920</span></td>
</tr>
</tbody>
</table>
</figure>
<figure id="S1.T7" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table"><span id="S1.T7.8.1.1" class="ltx_text" style="font-size:113%;">Table 7</span>: </span><span id="S1.T7.9.2" class="ltx_text" style="font-size:113%;">Summary of cross-dataset testing results for parking slot detection. Here, TP and FP denote the number of true positives and false positives respectively.</span></figcaption>
<table id="S1.T7.4" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S1.T7.2.2" class="ltx_tr">
<th id="S1.T7.2.2.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_tt"><span id="S1.T7.2.2.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Train</span></th>
<th id="S1.T7.2.2.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt"><span id="S1.T7.2.2.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Test</span></th>
<th id="S1.T7.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_tt">
<span id="S1.T7.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">TP</span><span id="S1.T7.1.1.1.2" class="ltx_text" style="font-size:80%;"> (</span><math id="S1.T7.1.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S1.T7.1.1.1.m1.1a"><mo mathsize="80%" stretchy="false" id="S1.T7.1.1.1.m1.1.1" xref="S1.T7.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S1.T7.1.1.1.m1.1b"><ci id="S1.T7.1.1.1.m1.1.1.cmml" xref="S1.T7.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T7.1.1.1.m1.1c">\uparrow</annotation></semantics></math><span id="S1.T7.1.1.1.3" class="ltx_text" style="font-size:80%;">)</span>
</th>
<th id="S1.T7.2.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_tt">
<span id="S1.T7.2.2.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">FP</span><span id="S1.T7.2.2.2.2" class="ltx_text" style="font-size:80%;"> (</span><math id="S1.T7.2.2.2.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S1.T7.2.2.2.m1.1a"><mo mathsize="80%" stretchy="false" id="S1.T7.2.2.2.m1.1.1" xref="S1.T7.2.2.2.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S1.T7.2.2.2.m1.1b"><ci id="S1.T7.2.2.2.m1.1.1.cmml" xref="S1.T7.2.2.2.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T7.2.2.2.m1.1c">\downarrow</annotation></semantics></math><span id="S1.T7.2.2.2.3" class="ltx_text" style="font-size:80%;">)</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S1.T7.4.5.1" class="ltx_tr">
<th id="S1.T7.4.5.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="S1.T7.4.5.1.1.1" class="ltx_text" style="font-size:80%;">A</span></th>
<th id="S1.T7.4.5.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S1.T7.4.5.1.2.1" class="ltx_text" style="font-size:80%;">B</span></th>
<td id="S1.T7.4.5.1.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S1.T7.4.5.1.3.1" class="ltx_text" style="font-size:80%;">0</span></td>
<td id="S1.T7.4.5.1.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S1.T7.4.5.1.4.1" class="ltx_text" style="font-size:80%;">252</span></td>
</tr>
<tr id="S1.T7.3.3" class="ltx_tr">
<th id="S1.T7.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r"><math id="S1.T7.3.3.1.m1.1" class="ltx_Math" alttext="\text{A}+\text{S}\ (40\%)" display="inline"><semantics id="S1.T7.3.3.1.m1.1a"><mrow id="S1.T7.3.3.1.m1.1.1" xref="S1.T7.3.3.1.m1.1.1.cmml"><mtext mathsize="80%" id="S1.T7.3.3.1.m1.1.1.3" xref="S1.T7.3.3.1.m1.1.1.3a.cmml">A</mtext><mo mathsize="80%" id="S1.T7.3.3.1.m1.1.1.2" xref="S1.T7.3.3.1.m1.1.1.2.cmml">+</mo><mrow id="S1.T7.3.3.1.m1.1.1.1" xref="S1.T7.3.3.1.m1.1.1.1.cmml"><mtext mathsize="80%" id="S1.T7.3.3.1.m1.1.1.1.3" xref="S1.T7.3.3.1.m1.1.1.1.3a.cmml">S</mtext><mo lspace="0.400em" rspace="0em" id="S1.T7.3.3.1.m1.1.1.1.2" xref="S1.T7.3.3.1.m1.1.1.1.2.cmml">​</mo><mrow id="S1.T7.3.3.1.m1.1.1.1.1.1" xref="S1.T7.3.3.1.m1.1.1.1.1.1.1.cmml"><mo maxsize="80%" minsize="80%" id="S1.T7.3.3.1.m1.1.1.1.1.1.2" xref="S1.T7.3.3.1.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S1.T7.3.3.1.m1.1.1.1.1.1.1" xref="S1.T7.3.3.1.m1.1.1.1.1.1.1.cmml"><mn mathsize="80%" id="S1.T7.3.3.1.m1.1.1.1.1.1.1.2" xref="S1.T7.3.3.1.m1.1.1.1.1.1.1.2.cmml">40</mn><mo mathsize="80%" id="S1.T7.3.3.1.m1.1.1.1.1.1.1.1" xref="S1.T7.3.3.1.m1.1.1.1.1.1.1.1.cmml">%</mo></mrow><mo maxsize="80%" minsize="80%" id="S1.T7.3.3.1.m1.1.1.1.1.1.3" xref="S1.T7.3.3.1.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S1.T7.3.3.1.m1.1b"><apply id="S1.T7.3.3.1.m1.1.1.cmml" xref="S1.T7.3.3.1.m1.1.1"><plus id="S1.T7.3.3.1.m1.1.1.2.cmml" xref="S1.T7.3.3.1.m1.1.1.2"></plus><ci id="S1.T7.3.3.1.m1.1.1.3a.cmml" xref="S1.T7.3.3.1.m1.1.1.3"><mtext mathsize="80%" id="S1.T7.3.3.1.m1.1.1.3.cmml" xref="S1.T7.3.3.1.m1.1.1.3">A</mtext></ci><apply id="S1.T7.3.3.1.m1.1.1.1.cmml" xref="S1.T7.3.3.1.m1.1.1.1"><times id="S1.T7.3.3.1.m1.1.1.1.2.cmml" xref="S1.T7.3.3.1.m1.1.1.1.2"></times><ci id="S1.T7.3.3.1.m1.1.1.1.3a.cmml" xref="S1.T7.3.3.1.m1.1.1.1.3"><mtext mathsize="80%" id="S1.T7.3.3.1.m1.1.1.1.3.cmml" xref="S1.T7.3.3.1.m1.1.1.1.3">S</mtext></ci><apply id="S1.T7.3.3.1.m1.1.1.1.1.1.1.cmml" xref="S1.T7.3.3.1.m1.1.1.1.1.1"><csymbol cd="latexml" id="S1.T7.3.3.1.m1.1.1.1.1.1.1.1.cmml" xref="S1.T7.3.3.1.m1.1.1.1.1.1.1.1">percent</csymbol><cn type="integer" id="S1.T7.3.3.1.m1.1.1.1.1.1.1.2.cmml" xref="S1.T7.3.3.1.m1.1.1.1.1.1.1.2">40</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.T7.3.3.1.m1.1c">\text{A}+\text{S}\ (40\%)</annotation></semantics></math></th>
<th id="S1.T7.3.3.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r"><span id="S1.T7.3.3.2.1" class="ltx_text" style="font-size:80%;">B</span></th>
<td id="S1.T7.3.3.3" class="ltx_td ltx_align_left ltx_border_r"><span id="S1.T7.3.3.3.1" class="ltx_text" style="font-size:80%;">89</span></td>
<td id="S1.T7.3.3.4" class="ltx_td ltx_align_left ltx_border_r"><span id="S1.T7.3.3.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">35</span></td>
</tr>
<tr id="S1.T7.4.4" class="ltx_tr">
<th id="S1.T7.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_l ltx_border_r"><math id="S1.T7.4.4.1.m1.1" class="ltx_Math" alttext="\text{A}+\text{G}\ (50\%)" display="inline"><semantics id="S1.T7.4.4.1.m1.1a"><mrow id="S1.T7.4.4.1.m1.1.1" xref="S1.T7.4.4.1.m1.1.1.cmml"><mtext mathsize="80%" id="S1.T7.4.4.1.m1.1.1.3" xref="S1.T7.4.4.1.m1.1.1.3a.cmml">A</mtext><mo mathsize="80%" id="S1.T7.4.4.1.m1.1.1.2" xref="S1.T7.4.4.1.m1.1.1.2.cmml">+</mo><mrow id="S1.T7.4.4.1.m1.1.1.1" xref="S1.T7.4.4.1.m1.1.1.1.cmml"><mtext mathsize="80%" id="S1.T7.4.4.1.m1.1.1.1.3" xref="S1.T7.4.4.1.m1.1.1.1.3a.cmml">G</mtext><mo lspace="0.400em" rspace="0em" id="S1.T7.4.4.1.m1.1.1.1.2" xref="S1.T7.4.4.1.m1.1.1.1.2.cmml">​</mo><mrow id="S1.T7.4.4.1.m1.1.1.1.1.1" xref="S1.T7.4.4.1.m1.1.1.1.1.1.1.cmml"><mo maxsize="80%" minsize="80%" id="S1.T7.4.4.1.m1.1.1.1.1.1.2" xref="S1.T7.4.4.1.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S1.T7.4.4.1.m1.1.1.1.1.1.1" xref="S1.T7.4.4.1.m1.1.1.1.1.1.1.cmml"><mn mathsize="80%" id="S1.T7.4.4.1.m1.1.1.1.1.1.1.2" xref="S1.T7.4.4.1.m1.1.1.1.1.1.1.2.cmml">50</mn><mo mathsize="80%" id="S1.T7.4.4.1.m1.1.1.1.1.1.1.1" xref="S1.T7.4.4.1.m1.1.1.1.1.1.1.1.cmml">%</mo></mrow><mo maxsize="80%" minsize="80%" id="S1.T7.4.4.1.m1.1.1.1.1.1.3" xref="S1.T7.4.4.1.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S1.T7.4.4.1.m1.1b"><apply id="S1.T7.4.4.1.m1.1.1.cmml" xref="S1.T7.4.4.1.m1.1.1"><plus id="S1.T7.4.4.1.m1.1.1.2.cmml" xref="S1.T7.4.4.1.m1.1.1.2"></plus><ci id="S1.T7.4.4.1.m1.1.1.3a.cmml" xref="S1.T7.4.4.1.m1.1.1.3"><mtext mathsize="80%" id="S1.T7.4.4.1.m1.1.1.3.cmml" xref="S1.T7.4.4.1.m1.1.1.3">A</mtext></ci><apply id="S1.T7.4.4.1.m1.1.1.1.cmml" xref="S1.T7.4.4.1.m1.1.1.1"><times id="S1.T7.4.4.1.m1.1.1.1.2.cmml" xref="S1.T7.4.4.1.m1.1.1.1.2"></times><ci id="S1.T7.4.4.1.m1.1.1.1.3a.cmml" xref="S1.T7.4.4.1.m1.1.1.1.3"><mtext mathsize="80%" id="S1.T7.4.4.1.m1.1.1.1.3.cmml" xref="S1.T7.4.4.1.m1.1.1.1.3">G</mtext></ci><apply id="S1.T7.4.4.1.m1.1.1.1.1.1.1.cmml" xref="S1.T7.4.4.1.m1.1.1.1.1.1"><csymbol cd="latexml" id="S1.T7.4.4.1.m1.1.1.1.1.1.1.1.cmml" xref="S1.T7.4.4.1.m1.1.1.1.1.1.1.1">percent</csymbol><cn type="integer" id="S1.T7.4.4.1.m1.1.1.1.1.1.1.2.cmml" xref="S1.T7.4.4.1.m1.1.1.1.1.1.1.2">50</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.T7.4.4.1.m1.1c">\text{A}+\text{G}\ (50\%)</annotation></semantics></math></th>
<th id="S1.T7.4.4.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r"><span id="S1.T7.4.4.2.1" class="ltx_text" style="font-size:80%;">B</span></th>
<td id="S1.T7.4.4.3" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r"><span id="S1.T7.4.4.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">303</span></td>
<td id="S1.T7.4.4.4" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r"><span id="S1.T7.4.4.4.1" class="ltx_text" style="font-size:80%;">149</span></td>
</tr>
</tbody>
</table>
</figure>
<figure id="S1.F13" class="ltx_figure"><img src="/html/2004.13866/assets/x12.png" id="S1.F13.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="346" height="78" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F13.2.1.1" class="ltx_text" style="font-size:90%;">Figure 13</span>: </span><span id="S1.F13.3.2" class="ltx_text" style="font-size:90%;">Example real, simulated and sim2real translated images used for training models in Fig. <a href="#S1.F14" title="Figure 14 ‣ A.5 Case Studies: Additional Quantitative Results ‣ A Supplementary Material ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">14</span></a> and Table. <a href="#S1.T8" title="Table 8 ‣ A.5 Case Studies: Additional Quantitative Results ‣ A Supplementary Material ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a></span></figcaption>
</figure>
<figure id="S1.T8" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table"><span id="S1.T8.19.3.1" class="ltx_text" style="font-size:113%;">Table 8</span>: </span><span id="S1.T8.4.2" class="ltx_text" style="font-size:113%;">Summary of results in Fig. <a href="#S1.F14" title="Figure 14 ‣ A.5 Case Studies: Additional Quantitative Results ‣ A Supplementary Material ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">14</span></a>. Here, A and B denote the CULane and TuSimple datasets respectively. S denotes simulated images and G denotes the sim-to-real GAN translated equivalent of S. Example B, G and D images are shown in Fig. <a href="#S1.F13" title="Figure 13 ‣ A.5 Case Studies: Additional Quantitative Results ‣ A Supplementary Material ‣ Deflating Dataset Bias Using Synthetic Data Augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">13</span></a>. For all these experiments, SCNN was trained on <math id="S1.T8.3.1.m1.1" class="ltx_Math" alttext="512\times 288" display="inline"><semantics id="S1.T8.3.1.m1.1b"><mrow id="S1.T8.3.1.m1.1.1" xref="S1.T8.3.1.m1.1.1.cmml"><mn id="S1.T8.3.1.m1.1.1.2" xref="S1.T8.3.1.m1.1.1.2.cmml">512</mn><mo lspace="0.222em" rspace="0.222em" id="S1.T8.3.1.m1.1.1.1" xref="S1.T8.3.1.m1.1.1.1.cmml">×</mo><mn id="S1.T8.3.1.m1.1.1.3" xref="S1.T8.3.1.m1.1.1.3.cmml">288</mn></mrow><annotation-xml encoding="MathML-Content" id="S1.T8.3.1.m1.1c"><apply id="S1.T8.3.1.m1.1.1.cmml" xref="S1.T8.3.1.m1.1.1"><times id="S1.T8.3.1.m1.1.1.1.cmml" xref="S1.T8.3.1.m1.1.1.1"></times><cn type="integer" id="S1.T8.3.1.m1.1.1.2.cmml" xref="S1.T8.3.1.m1.1.1.2">512</cn><cn type="integer" id="S1.T8.3.1.m1.1.1.3.cmml" xref="S1.T8.3.1.m1.1.1.3">288</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.T8.3.1.m1.1d">512\times 288</annotation></semantics></math> images. For cross-dataset testing, CULane images were downsized and then padded (along height) to match the training resolution of <math id="S1.T8.4.2.m2.1" class="ltx_Math" alttext="512\times 288" display="inline"><semantics id="S1.T8.4.2.m2.1b"><mrow id="S1.T8.4.2.m2.1.1" xref="S1.T8.4.2.m2.1.1.cmml"><mn id="S1.T8.4.2.m2.1.1.2" xref="S1.T8.4.2.m2.1.1.2.cmml">512</mn><mo lspace="0.222em" rspace="0.222em" id="S1.T8.4.2.m2.1.1.1" xref="S1.T8.4.2.m2.1.1.1.cmml">×</mo><mn id="S1.T8.4.2.m2.1.1.3" xref="S1.T8.4.2.m2.1.1.3.cmml">288</mn></mrow><annotation-xml encoding="MathML-Content" id="S1.T8.4.2.m2.1c"><apply id="S1.T8.4.2.m2.1.1.cmml" xref="S1.T8.4.2.m2.1.1"><times id="S1.T8.4.2.m2.1.1.1.cmml" xref="S1.T8.4.2.m2.1.1.1"></times><cn type="integer" id="S1.T8.4.2.m2.1.1.2.cmml" xref="S1.T8.4.2.m2.1.1.2">512</cn><cn type="integer" id="S1.T8.4.2.m2.1.1.3.cmml" xref="S1.T8.4.2.m2.1.1.3">288</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.T8.4.2.m2.1d">512\times 288</annotation></semantics></math> while simultaneously maintaining the original aspect ratio. For synthetic data augmentation rows, results are shown for the best model in terms of F-measure on cross-dataset testing in green for A + S and in blue for A + G.</span></figcaption>
<table id="S1.T8.11" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S1.T8.7.3" class="ltx_tr">
<th id="S1.T8.7.3.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_tt"><span id="S1.T8.7.3.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Train</span></th>
<th id="S1.T8.7.3.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt"><span id="S1.T8.7.3.5.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Test</span></th>
<th id="S1.T8.5.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt">
<span id="S1.T8.5.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Precision</span><span id="S1.T8.5.1.1.2" class="ltx_text" style="font-size:80%;"> (</span><math id="S1.T8.5.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S1.T8.5.1.1.m1.1a"><mo mathsize="80%" stretchy="false" id="S1.T8.5.1.1.m1.1.1" xref="S1.T8.5.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S1.T8.5.1.1.m1.1b"><ci id="S1.T8.5.1.1.m1.1.1.cmml" xref="S1.T8.5.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T8.5.1.1.m1.1c">\uparrow</annotation></semantics></math><span id="S1.T8.5.1.1.3" class="ltx_text" style="font-size:80%;">)</span>
</th>
<th id="S1.T8.6.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt">
<span id="S1.T8.6.2.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Recall</span><span id="S1.T8.6.2.2.2" class="ltx_text" style="font-size:80%;"> (</span><math id="S1.T8.6.2.2.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S1.T8.6.2.2.m1.1a"><mo mathsize="80%" stretchy="false" id="S1.T8.6.2.2.m1.1.1" xref="S1.T8.6.2.2.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S1.T8.6.2.2.m1.1b"><ci id="S1.T8.6.2.2.m1.1.1.cmml" xref="S1.T8.6.2.2.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T8.6.2.2.m1.1c">\uparrow</annotation></semantics></math><span id="S1.T8.6.2.2.3" class="ltx_text" style="font-size:80%;">)</span>
</th>
<th id="S1.T8.7.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt">
<span id="S1.T8.7.3.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">F-Measure</span><span id="S1.T8.7.3.3.2" class="ltx_text" style="font-size:80%;"> (</span><math id="S1.T8.7.3.3.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S1.T8.7.3.3.m1.1a"><mo mathsize="80%" stretchy="false" id="S1.T8.7.3.3.m1.1.1" xref="S1.T8.7.3.3.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S1.T8.7.3.3.m1.1b"><ci id="S1.T8.7.3.3.m1.1.1.cmml" xref="S1.T8.7.3.3.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T8.7.3.3.m1.1c">\uparrow</annotation></semantics></math><span id="S1.T8.7.3.3.3" class="ltx_text" style="font-size:80%;">)</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S1.T8.11.8.1" class="ltx_tr">
<th id="S1.T8.11.8.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="S1.T8.11.8.1.1.1" class="ltx_text" style="font-size:80%;">B</span></th>
<td id="S1.T8.11.8.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S1.T8.11.8.1.2.1" class="ltx_text" style="font-size:80%;">B</span></td>
<td id="S1.T8.11.8.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S1.T8.11.8.1.3.1" class="ltx_text" style="font-size:80%;">80.2%</span></td>
<td id="S1.T8.11.8.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S1.T8.11.8.1.4.1" class="ltx_text" style="font-size:80%;">91.7%</span></td>
<td id="S1.T8.11.8.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S1.T8.11.8.1.5.1" class="ltx_text" style="font-size:80%;">85.6%</span></td>
</tr>
<tr id="S1.T8.8.4" class="ltx_tr">
<th id="S1.T8.8.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r"><math id="S1.T8.8.4.1.m1.1" class="ltx_Math" alttext="\text{B}+\text{S}\ (40\%)" display="inline"><semantics id="S1.T8.8.4.1.m1.1a"><mrow id="S1.T8.8.4.1.m1.1.1" xref="S1.T8.8.4.1.m1.1.1.cmml"><mtext mathsize="80%" id="S1.T8.8.4.1.m1.1.1.3" xref="S1.T8.8.4.1.m1.1.1.3a.cmml">B</mtext><mo mathsize="80%" id="S1.T8.8.4.1.m1.1.1.2" xref="S1.T8.8.4.1.m1.1.1.2.cmml">+</mo><mrow id="S1.T8.8.4.1.m1.1.1.1" xref="S1.T8.8.4.1.m1.1.1.1.cmml"><mtext mathsize="80%" id="S1.T8.8.4.1.m1.1.1.1.3" xref="S1.T8.8.4.1.m1.1.1.1.3a.cmml">S</mtext><mo lspace="0.400em" rspace="0em" id="S1.T8.8.4.1.m1.1.1.1.2" xref="S1.T8.8.4.1.m1.1.1.1.2.cmml">​</mo><mrow id="S1.T8.8.4.1.m1.1.1.1.1.1" xref="S1.T8.8.4.1.m1.1.1.1.1.1.1.cmml"><mo maxsize="80%" minsize="80%" id="S1.T8.8.4.1.m1.1.1.1.1.1.2" xref="S1.T8.8.4.1.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S1.T8.8.4.1.m1.1.1.1.1.1.1" xref="S1.T8.8.4.1.m1.1.1.1.1.1.1.cmml"><mn mathsize="80%" id="S1.T8.8.4.1.m1.1.1.1.1.1.1.2" xref="S1.T8.8.4.1.m1.1.1.1.1.1.1.2.cmml">40</mn><mo mathsize="80%" id="S1.T8.8.4.1.m1.1.1.1.1.1.1.1" xref="S1.T8.8.4.1.m1.1.1.1.1.1.1.1.cmml">%</mo></mrow><mo maxsize="80%" minsize="80%" id="S1.T8.8.4.1.m1.1.1.1.1.1.3" xref="S1.T8.8.4.1.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S1.T8.8.4.1.m1.1b"><apply id="S1.T8.8.4.1.m1.1.1.cmml" xref="S1.T8.8.4.1.m1.1.1"><plus id="S1.T8.8.4.1.m1.1.1.2.cmml" xref="S1.T8.8.4.1.m1.1.1.2"></plus><ci id="S1.T8.8.4.1.m1.1.1.3a.cmml" xref="S1.T8.8.4.1.m1.1.1.3"><mtext mathsize="80%" id="S1.T8.8.4.1.m1.1.1.3.cmml" xref="S1.T8.8.4.1.m1.1.1.3">B</mtext></ci><apply id="S1.T8.8.4.1.m1.1.1.1.cmml" xref="S1.T8.8.4.1.m1.1.1.1"><times id="S1.T8.8.4.1.m1.1.1.1.2.cmml" xref="S1.T8.8.4.1.m1.1.1.1.2"></times><ci id="S1.T8.8.4.1.m1.1.1.1.3a.cmml" xref="S1.T8.8.4.1.m1.1.1.1.3"><mtext mathsize="80%" id="S1.T8.8.4.1.m1.1.1.1.3.cmml" xref="S1.T8.8.4.1.m1.1.1.1.3">S</mtext></ci><apply id="S1.T8.8.4.1.m1.1.1.1.1.1.1.cmml" xref="S1.T8.8.4.1.m1.1.1.1.1.1"><csymbol cd="latexml" id="S1.T8.8.4.1.m1.1.1.1.1.1.1.1.cmml" xref="S1.T8.8.4.1.m1.1.1.1.1.1.1.1">percent</csymbol><cn type="integer" id="S1.T8.8.4.1.m1.1.1.1.1.1.1.2.cmml" xref="S1.T8.8.4.1.m1.1.1.1.1.1.1.2">40</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.T8.8.4.1.m1.1c">\text{B}+\text{S}\ (40\%)</annotation></semantics></math></th>
<td id="S1.T8.8.4.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T8.8.4.2.1" class="ltx_text" style="font-size:80%;">B</span></td>
<td id="S1.T8.8.4.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T8.8.4.3.1" class="ltx_text" style="font-size:80%;">80.1%</span></td>
<td id="S1.T8.8.4.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T8.8.4.4.1" class="ltx_text" style="font-size:80%;">91.5%</span></td>
<td id="S1.T8.8.4.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T8.8.4.5.1" class="ltx_text" style="font-size:80%;">85.4%</span></td>
</tr>
<tr id="S1.T8.9.5" class="ltx_tr">
<th id="S1.T8.9.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r"><math id="S1.T8.9.5.1.m1.1" class="ltx_Math" alttext="\text{B}+\text{G}\ (20\%)" display="inline"><semantics id="S1.T8.9.5.1.m1.1a"><mrow id="S1.T8.9.5.1.m1.1.1" xref="S1.T8.9.5.1.m1.1.1.cmml"><mtext mathsize="80%" id="S1.T8.9.5.1.m1.1.1.3" xref="S1.T8.9.5.1.m1.1.1.3a.cmml">B</mtext><mo mathsize="80%" id="S1.T8.9.5.1.m1.1.1.2" xref="S1.T8.9.5.1.m1.1.1.2.cmml">+</mo><mrow id="S1.T8.9.5.1.m1.1.1.1" xref="S1.T8.9.5.1.m1.1.1.1.cmml"><mtext mathsize="80%" id="S1.T8.9.5.1.m1.1.1.1.3" xref="S1.T8.9.5.1.m1.1.1.1.3a.cmml">G</mtext><mo lspace="0.400em" rspace="0em" id="S1.T8.9.5.1.m1.1.1.1.2" xref="S1.T8.9.5.1.m1.1.1.1.2.cmml">​</mo><mrow id="S1.T8.9.5.1.m1.1.1.1.1.1" xref="S1.T8.9.5.1.m1.1.1.1.1.1.1.cmml"><mo maxsize="80%" minsize="80%" id="S1.T8.9.5.1.m1.1.1.1.1.1.2" xref="S1.T8.9.5.1.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S1.T8.9.5.1.m1.1.1.1.1.1.1" xref="S1.T8.9.5.1.m1.1.1.1.1.1.1.cmml"><mn mathsize="80%" id="S1.T8.9.5.1.m1.1.1.1.1.1.1.2" xref="S1.T8.9.5.1.m1.1.1.1.1.1.1.2.cmml">20</mn><mo mathsize="80%" id="S1.T8.9.5.1.m1.1.1.1.1.1.1.1" xref="S1.T8.9.5.1.m1.1.1.1.1.1.1.1.cmml">%</mo></mrow><mo maxsize="80%" minsize="80%" id="S1.T8.9.5.1.m1.1.1.1.1.1.3" xref="S1.T8.9.5.1.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S1.T8.9.5.1.m1.1b"><apply id="S1.T8.9.5.1.m1.1.1.cmml" xref="S1.T8.9.5.1.m1.1.1"><plus id="S1.T8.9.5.1.m1.1.1.2.cmml" xref="S1.T8.9.5.1.m1.1.1.2"></plus><ci id="S1.T8.9.5.1.m1.1.1.3a.cmml" xref="S1.T8.9.5.1.m1.1.1.3"><mtext mathsize="80%" id="S1.T8.9.5.1.m1.1.1.3.cmml" xref="S1.T8.9.5.1.m1.1.1.3">B</mtext></ci><apply id="S1.T8.9.5.1.m1.1.1.1.cmml" xref="S1.T8.9.5.1.m1.1.1.1"><times id="S1.T8.9.5.1.m1.1.1.1.2.cmml" xref="S1.T8.9.5.1.m1.1.1.1.2"></times><ci id="S1.T8.9.5.1.m1.1.1.1.3a.cmml" xref="S1.T8.9.5.1.m1.1.1.1.3"><mtext mathsize="80%" id="S1.T8.9.5.1.m1.1.1.1.3.cmml" xref="S1.T8.9.5.1.m1.1.1.1.3">G</mtext></ci><apply id="S1.T8.9.5.1.m1.1.1.1.1.1.1.cmml" xref="S1.T8.9.5.1.m1.1.1.1.1.1"><csymbol cd="latexml" id="S1.T8.9.5.1.m1.1.1.1.1.1.1.1.cmml" xref="S1.T8.9.5.1.m1.1.1.1.1.1.1.1">percent</csymbol><cn type="integer" id="S1.T8.9.5.1.m1.1.1.1.1.1.1.2.cmml" xref="S1.T8.9.5.1.m1.1.1.1.1.1.1.2">20</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.T8.9.5.1.m1.1c">\text{B}+\text{G}\ (20\%)</annotation></semantics></math></th>
<td id="S1.T8.9.5.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T8.9.5.2.1" class="ltx_text" style="font-size:80%;">B</span></td>
<td id="S1.T8.9.5.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T8.9.5.3.1" class="ltx_text" style="font-size:80%;">79.1%</span></td>
<td id="S1.T8.9.5.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T8.9.5.4.1" class="ltx_text" style="font-size:80%;">90.1%</span></td>
<td id="S1.T8.9.5.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T8.9.5.5.1" class="ltx_text" style="font-size:80%;">84.2%</span></td>
</tr>
<tr id="S1.T8.11.9.2" class="ltx_tr">
<th id="S1.T8.11.9.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="S1.T8.11.9.2.1.1" class="ltx_text" style="font-size:80%;">B</span></th>
<td id="S1.T8.11.9.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S1.T8.11.9.2.2.1" class="ltx_text" style="font-size:80%;">A</span></td>
<td id="S1.T8.11.9.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S1.T8.11.9.2.3.1" class="ltx_text" style="font-size:80%;">2.8%</span></td>
<td id="S1.T8.11.9.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S1.T8.11.9.2.4.1" class="ltx_text" style="font-size:80%;">3.7%</span></td>
<td id="S1.T8.11.9.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S1.T8.11.9.2.5.1" class="ltx_text" style="font-size:80%;">3.2%</span></td>
</tr>
<tr id="S1.T8.10.6" class="ltx_tr">
<th id="S1.T8.10.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r"><math id="S1.T8.10.6.1.m1.1" class="ltx_Math" alttext="\text{B}+\text{S}\ (40\%)" display="inline"><semantics id="S1.T8.10.6.1.m1.1a"><mrow id="S1.T8.10.6.1.m1.1.1" xref="S1.T8.10.6.1.m1.1.1.cmml"><mtext mathsize="80%" id="S1.T8.10.6.1.m1.1.1.3" xref="S1.T8.10.6.1.m1.1.1.3a.cmml">B</mtext><mo mathsize="80%" id="S1.T8.10.6.1.m1.1.1.2" xref="S1.T8.10.6.1.m1.1.1.2.cmml">+</mo><mrow id="S1.T8.10.6.1.m1.1.1.1" xref="S1.T8.10.6.1.m1.1.1.1.cmml"><mtext mathsize="80%" id="S1.T8.10.6.1.m1.1.1.1.3" xref="S1.T8.10.6.1.m1.1.1.1.3a.cmml">S</mtext><mo lspace="0.400em" rspace="0em" id="S1.T8.10.6.1.m1.1.1.1.2" xref="S1.T8.10.6.1.m1.1.1.1.2.cmml">​</mo><mrow id="S1.T8.10.6.1.m1.1.1.1.1.1" xref="S1.T8.10.6.1.m1.1.1.1.1.1.1.cmml"><mo maxsize="80%" minsize="80%" id="S1.T8.10.6.1.m1.1.1.1.1.1.2" xref="S1.T8.10.6.1.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S1.T8.10.6.1.m1.1.1.1.1.1.1" xref="S1.T8.10.6.1.m1.1.1.1.1.1.1.cmml"><mn mathsize="80%" id="S1.T8.10.6.1.m1.1.1.1.1.1.1.2" xref="S1.T8.10.6.1.m1.1.1.1.1.1.1.2.cmml">40</mn><mo mathsize="80%" id="S1.T8.10.6.1.m1.1.1.1.1.1.1.1" xref="S1.T8.10.6.1.m1.1.1.1.1.1.1.1.cmml">%</mo></mrow><mo maxsize="80%" minsize="80%" id="S1.T8.10.6.1.m1.1.1.1.1.1.3" xref="S1.T8.10.6.1.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S1.T8.10.6.1.m1.1b"><apply id="S1.T8.10.6.1.m1.1.1.cmml" xref="S1.T8.10.6.1.m1.1.1"><plus id="S1.T8.10.6.1.m1.1.1.2.cmml" xref="S1.T8.10.6.1.m1.1.1.2"></plus><ci id="S1.T8.10.6.1.m1.1.1.3a.cmml" xref="S1.T8.10.6.1.m1.1.1.3"><mtext mathsize="80%" id="S1.T8.10.6.1.m1.1.1.3.cmml" xref="S1.T8.10.6.1.m1.1.1.3">B</mtext></ci><apply id="S1.T8.10.6.1.m1.1.1.1.cmml" xref="S1.T8.10.6.1.m1.1.1.1"><times id="S1.T8.10.6.1.m1.1.1.1.2.cmml" xref="S1.T8.10.6.1.m1.1.1.1.2"></times><ci id="S1.T8.10.6.1.m1.1.1.1.3a.cmml" xref="S1.T8.10.6.1.m1.1.1.1.3"><mtext mathsize="80%" id="S1.T8.10.6.1.m1.1.1.1.3.cmml" xref="S1.T8.10.6.1.m1.1.1.1.3">S</mtext></ci><apply id="S1.T8.10.6.1.m1.1.1.1.1.1.1.cmml" xref="S1.T8.10.6.1.m1.1.1.1.1.1"><csymbol cd="latexml" id="S1.T8.10.6.1.m1.1.1.1.1.1.1.1.cmml" xref="S1.T8.10.6.1.m1.1.1.1.1.1.1.1">percent</csymbol><cn type="integer" id="S1.T8.10.6.1.m1.1.1.1.1.1.1.2.cmml" xref="S1.T8.10.6.1.m1.1.1.1.1.1.1.2">40</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.T8.10.6.1.m1.1c">\text{B}+\text{S}\ (40\%)</annotation></semantics></math></th>
<td id="S1.T8.10.6.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T8.10.6.2.1" class="ltx_text" style="font-size:80%;">A</span></td>
<td id="S1.T8.10.6.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T8.10.6.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;color:#00FF00;">5.3%</span></td>
<td id="S1.T8.10.6.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T8.10.6.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;color:#00FF00;">6.6%</span></td>
<td id="S1.T8.10.6.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S1.T8.10.6.5.1" class="ltx_text ltx_font_bold" style="font-size:80%;color:#00FF00;">5.9%</span></td>
</tr>
<tr id="S1.T8.11.7" class="ltx_tr">
<th id="S1.T8.11.7.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_l ltx_border_r"><math id="S1.T8.11.7.1.m1.1" class="ltx_Math" alttext="\text{B}+\text{G}\ (20\%)" display="inline"><semantics id="S1.T8.11.7.1.m1.1a"><mrow id="S1.T8.11.7.1.m1.1.1" xref="S1.T8.11.7.1.m1.1.1.cmml"><mtext mathsize="80%" id="S1.T8.11.7.1.m1.1.1.3" xref="S1.T8.11.7.1.m1.1.1.3a.cmml">B</mtext><mo mathsize="80%" id="S1.T8.11.7.1.m1.1.1.2" xref="S1.T8.11.7.1.m1.1.1.2.cmml">+</mo><mrow id="S1.T8.11.7.1.m1.1.1.1" xref="S1.T8.11.7.1.m1.1.1.1.cmml"><mtext mathsize="80%" id="S1.T8.11.7.1.m1.1.1.1.3" xref="S1.T8.11.7.1.m1.1.1.1.3a.cmml">G</mtext><mo lspace="0.400em" rspace="0em" id="S1.T8.11.7.1.m1.1.1.1.2" xref="S1.T8.11.7.1.m1.1.1.1.2.cmml">​</mo><mrow id="S1.T8.11.7.1.m1.1.1.1.1.1" xref="S1.T8.11.7.1.m1.1.1.1.1.1.1.cmml"><mo maxsize="80%" minsize="80%" id="S1.T8.11.7.1.m1.1.1.1.1.1.2" xref="S1.T8.11.7.1.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S1.T8.11.7.1.m1.1.1.1.1.1.1" xref="S1.T8.11.7.1.m1.1.1.1.1.1.1.cmml"><mn mathsize="80%" id="S1.T8.11.7.1.m1.1.1.1.1.1.1.2" xref="S1.T8.11.7.1.m1.1.1.1.1.1.1.2.cmml">20</mn><mo mathsize="80%" id="S1.T8.11.7.1.m1.1.1.1.1.1.1.1" xref="S1.T8.11.7.1.m1.1.1.1.1.1.1.1.cmml">%</mo></mrow><mo maxsize="80%" minsize="80%" id="S1.T8.11.7.1.m1.1.1.1.1.1.3" xref="S1.T8.11.7.1.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S1.T8.11.7.1.m1.1b"><apply id="S1.T8.11.7.1.m1.1.1.cmml" xref="S1.T8.11.7.1.m1.1.1"><plus id="S1.T8.11.7.1.m1.1.1.2.cmml" xref="S1.T8.11.7.1.m1.1.1.2"></plus><ci id="S1.T8.11.7.1.m1.1.1.3a.cmml" xref="S1.T8.11.7.1.m1.1.1.3"><mtext mathsize="80%" id="S1.T8.11.7.1.m1.1.1.3.cmml" xref="S1.T8.11.7.1.m1.1.1.3">B</mtext></ci><apply id="S1.T8.11.7.1.m1.1.1.1.cmml" xref="S1.T8.11.7.1.m1.1.1.1"><times id="S1.T8.11.7.1.m1.1.1.1.2.cmml" xref="S1.T8.11.7.1.m1.1.1.1.2"></times><ci id="S1.T8.11.7.1.m1.1.1.1.3a.cmml" xref="S1.T8.11.7.1.m1.1.1.1.3"><mtext mathsize="80%" id="S1.T8.11.7.1.m1.1.1.1.3.cmml" xref="S1.T8.11.7.1.m1.1.1.1.3">G</mtext></ci><apply id="S1.T8.11.7.1.m1.1.1.1.1.1.1.cmml" xref="S1.T8.11.7.1.m1.1.1.1.1.1"><csymbol cd="latexml" id="S1.T8.11.7.1.m1.1.1.1.1.1.1.1.cmml" xref="S1.T8.11.7.1.m1.1.1.1.1.1.1.1">percent</csymbol><cn type="integer" id="S1.T8.11.7.1.m1.1.1.1.1.1.1.2.cmml" xref="S1.T8.11.7.1.m1.1.1.1.1.1.1.2">20</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.T8.11.7.1.m1.1c">\text{B}+\text{G}\ (20\%)</annotation></semantics></math></th>
<td id="S1.T8.11.7.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S1.T8.11.7.2.1" class="ltx_text" style="font-size:80%;">A</span></td>
<td id="S1.T8.11.7.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S1.T8.11.7.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;color:#0000FF;">5.9%</span></td>
<td id="S1.T8.11.7.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S1.T8.11.7.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;color:#0000FF;">7.8%</span></td>
<td id="S1.T8.11.7.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S1.T8.11.7.5.1" class="ltx_text ltx_font_bold" style="font-size:80%;color:#0000FF;">6.8%</span></td>
</tr>
</tbody>
</table>
</figure>
<figure id="S1.F14" class="ltx_figure"><img src="/html/2004.13866/assets/x13.png" id="S1.F14.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="276" height="152" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F14.2.1.1" class="ltx_text" style="font-size:90%;">Figure 14</span>: </span><span id="S1.F14.3.2" class="ltx_text" style="font-size:90%;">Plot of F-measure for cross-dataset testing of lane detection models trained on a mix of real TuSimple (dataset B) and synthetic images (either simulated or sim2real translated) and tested on real CULane (dataset A) images. As you move from left to right, the ratio of synthetic data in the training set increases.</span></figcaption>
</figure>
<figure id="S1.F15" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S1.F15.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2004.13866/assets/figs/depth/vkittiClone.png" id="S1.F15.1.g1" class="ltx_graphics ltx_img_landscape" width="598" height="119" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S1.F15.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2004.13866/assets/figs/depth/vkitti15L.png" id="S1.F15.2.g1" class="ltx_graphics ltx_img_landscape" width="598" height="117" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S1.F15.3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2004.13866/assets/figs/depth/vkitti15R.png" id="S1.F15.3.g1" class="ltx_graphics ltx_img_landscape" width="598" height="117" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S1.F15.4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2004.13866/assets/figs/depth/vkittiMorning.png" id="S1.F15.4.g1" class="ltx_graphics ltx_img_landscape" width="598" height="117" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F15.6.1.1" class="ltx_text" style="font-size:90%;">Figure 15</span>: </span><span id="S1.F15.7.2" class="ltx_text" style="font-size:90%;">From top to bottom: Images from vKITTI Clone, 15L, 15R and Morning subsets used as simulation data for the single image depth task.
</span></figcaption>
</figure>
<figure id="S1.F16" class="ltx_figure ltx_align_center"><img src="/html/2004.13866/assets/x14.png" id="S1.F16.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="276" height="176" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F16.2.1.1" class="ltx_text" style="font-size:90%;">Figure 16</span>: </span><span id="S1.F16.3.2" class="ltx_text" style="font-size:90%;">Accuracy results for the single image depth task (higher is better).</span></figcaption>
</figure>
</section>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2004.13865" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2004.13866" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2004.13866">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2004.13866" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2004.13867" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sun Mar 17 06:23:23 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
