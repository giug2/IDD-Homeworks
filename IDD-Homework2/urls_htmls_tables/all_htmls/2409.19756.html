<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2409.19756] Advances in Privacy Preserving Federated Learning to Realize a Truly Learning Healthcare System</title><meta property="og:description" content="The concept of a learning healthcare system (LHS) envisions a self-improving network where multimodal data from patient care are continuously analyzed to enhance future healthcare outcomes. However, realizing this visi…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Advances in Privacy Preserving Federated Learning to Realize a Truly Learning Healthcare System">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Advances in Privacy Preserving Federated Learning to Realize a Truly Learning Healthcare System">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2409.19756">

<!--Generated on Sat Oct  5 21:27:28 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="
Privacy-Preserving Federated Learning,  Learning Healthcare System,  Data Privacy,  Healthcare Innovation,  Collaborative Learning.
">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Advances in Privacy Preserving Federated Learning to Realize a Truly Learning Healthcare System
</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Ravi Madduri
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id1.1.id1" class="ltx_text ltx_font_italic">Data Science and Learning Division</span>
<br class="ltx_break"><span id="id2.2.id2" class="ltx_text ltx_font_italic">Argonne National Laboratory
<br class="ltx_break"></span>Lemont, IL USA 
<br class="ltx_break">madduri@anl.gov
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Zilinghan Li
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id3.1.id1" class="ltx_text ltx_font_italic">Data Science and Learning Division</span>
<br class="ltx_break"><span id="id4.2.id2" class="ltx_text ltx_font_italic">Argonne National Laboratory
<br class="ltx_break"></span>Lemont, IL USA 
<br class="ltx_break">zilinghan.li@anl.gov
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Tarak Nandi
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id5.1.id1" class="ltx_text ltx_font_italic">Data Science and Learning Division</span>
<br class="ltx_break"><span id="id6.2.id2" class="ltx_text ltx_font_italic">Argonne National Laboratory
<br class="ltx_break"></span>Lemont, IL USA 
<br class="ltx_break">tnandi@anl.gov
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Kibaek Kim
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id7.1.id1" class="ltx_text ltx_font_italic">Mathematics and Computer Science</span>
<br class="ltx_break"><span id="id8.2.id2" class="ltx_text ltx_font_italic">Argonne National Laboratory
<br class="ltx_break"></span>Lemont, IL USA 
<br class="ltx_break">kimk@anl.gov
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Minseok Ryu
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id9.1.id1" class="ltx_text ltx_font_italic">School of Computing and Augmented Intelligence</span>
<br class="ltx_break"><span id="id10.2.id2" class="ltx_text ltx_font_italic">Arizona State University
<br class="ltx_break"></span>Tempe, AZ USA 
<br class="ltx_break">minseok.ryu@asu.edu
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Alex Rodriguez
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id11.1.id1" class="ltx_text ltx_font_italic">Data Science and Learning</span>
<br class="ltx_break"><span id="id12.2.id2" class="ltx_text ltx_font_italic">Argonne National Laboratory
<br class="ltx_break"></span>Lemont, IL USA 
<br class="ltx_break">a.rodriguez@anl.gov
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id13.id1" class="ltx_p">The concept of a learning healthcare system (LHS) envisions a self-improving network where multimodal data from patient care are continuously analyzed to enhance future healthcare outcomes. However, realizing this vision faces significant challenges in data sharing and privacy protection. Privacy-Preserving Federated Learning (PPFL) is a transformative and promising approach that has the potential to address these challenges by enabling collaborative learning from decentralized data while safeguarding patient privacy. This paper proposes a vision for integrating PPFL into the healthcare ecosystem to achieve a truly LHS as defined by the Institute of Medicine (IOM) Roundtable.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
Privacy-Preserving Federated Learning, Learning Healthcare System, Data Privacy, Healthcare Innovation, Collaborative Learning.

</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<figure id="S1.F1" class="ltx_figure">
<p id="S1.F1.1" class="ltx_p ltx_align_center"><span id="S1.F1.1.1" class="ltx_text"><img src="/html/2409.19756/assets/x1.png" id="S1.F1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="461" height="149" alt="Refer to caption"></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>An envisioned privacy-preserving federated learning framework for a truly learning healthcare system: Under the coordination of a trusted and secure server, multiple hospitals collaboratively train robust, generalized machine learning models using multimodal biomedical data stored in their cloud or on-premise facilities. With continuous learning capabilities integrated into the framework, the models can detect and avoid performance degradation, adapt dynamically in real time to any shifts in data distributions, availability of new patient data, and evolving health trends.</figcaption>
</figure>
<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Biomedical health data is often generated across various instruments, hospitals, or departments that are administratively and geographically disparate. Efforts are usually required to move data to a central location for analysis, requiring considerable time and infrastructure investments to facilitate. These efforts result in the creation of clinical data warehouses and disease-specific consortiums, which often evolve into data silos making data discovery and sharing cumbersome. To realize a truly learning healthcare system as defined by the Institute of Medicine—and to deliver personalized prognosis, diagnosis, and treatment planning—it is essential to learn from and synthesize multimodal biomedical data collected and stored across diverse administrative and geographical boundaries. Biomedical data are inherently multimodal, encompassing electronic health records, genomic information, medical imaging, laboratory results, and data from wearable devices, among others. However, these rich datasets are often soloed due to administrative disparities, privacy concerns, and regulatory constraints, which impede comprehensive analysis and integration.
Furthermore, additional efforts are needed to extract, transform, and load data to gain insights. Recent advances in artificial intelligence (AI) have demonstrated the potential for rapid insight generation from scientific and biomedical data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>, however, developing effective biomedical AI models requires substantial data and computing resources <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>. The conventional paradigm of building large-scale AI models includes collecting extensive data and training models at a central location. With the increasing volume and velocity of data generation, such a centralized model development paradigm is becoming impractical in some scientific domains. In biomedical health, the central collection of data from multiple data generation sources, especially those across different administrative boundaries, is often not possible due to data privacy and federal policies like HIPAA<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>, GDPR<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>. Nonetheless, models trained on limited data sets from a single source frequently fail to perform in real-world situations (performance degradation) when the distribution of real-world data differs from the distribution of the training data, a phenomenon known as model shift.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Privacy Preserving Federated Learning</span>
</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">Several approaches have been proposed to alleviate model drift, detect performance degradation and facilitate the development of robust AI models that perform reliably in the real world. Federated learning (FL), a distributed learning approach where a global model is created by aggregating model weights from models trained on data at various sites, can address the challenges of building robust AI models that are resistant to model drift without direct data sharing <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>. Though no data are directly shared among sites, however, FL by itself does not guarantee the privacy of data, because the information extracted from the communication of FL algorithms can be accumulated and utilized to infer the private local data used for training <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>. Differential Privacy (DP)<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>, a privacy-enhancing technology (PET), when integrated with FL is shown to prevent data reconstruction by attackers. DP adds noise to model updates to prevent accurate data reconstruction by attackers. Infrastructure challenges in the implementation of FL at scale include dealing with heterogeneity of computational resources available to researchers, identity and access management challenges to setup end-to-end secure federations, ease of use in setting up and running FL experiments, addressing privacy issues for different data types, and FAIRness constructs when performing AI experiments to enable reproducibility <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">To address these issues, we have developed the Advanced Privacy-Preserving Federated Learning (APPFL) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> framework with advances in differential privacy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>. APPFL enables the training of AI models in a distributed setting across multiple institutions, where sensitive data are located, with the ability to scale on distributed, heterogeneous computing resources to help create robust, trust-worthy AI models in biomedical health applications where data privacy is essential. Setting up a secure FL experiment across administrative boundaries that involves heterogeneous high-performance computational resources across distributed sites or cloud computing facilities requires technical capabilities that may not be available for all. Additionally, most existing PPFL frameworks typically involve downloading and configuring complex software, manually creating trust boundaries to enable secure gradient aggregation, and understanding the technical details of underlying deep learning software stack <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>, all of which can be cumbersome and technically demanding. Therefore, to reduce these barriers and empower domain experts to leverage PPFL, we created the Advanced Privacy-Preserving Federated Learning as a service (APPFLx) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> platform, which streamlines cross-silo PPFL using an easy-to-use web interface for managing, deploying, analyzing, and visualizing PPFL experiments. APPFLx ensures secure federations using end-to-end strong Identity and Access Management via Globus Auth <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>, enabling members to create new federations or join ones using their institutional identities, perform privacy-preserving training on datasets at their respective institutions, and securely share the model weights with the service for secure aggregation. Additionally, determining quality of training data is paramount in developing biomedical health AI models as low-quality or biased data leads to ineffective and unreliable AI models. Therefore, to ensure the integrity of training data before committing significant computing resources to training jobs, APPFL incorporates the AI Data Readiness Inspector (AIDRIN) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>, an open-source toolkit. AIDRIN integration allows for a distributed quantitative assessment of data readiness, providing data scientists with vital metrics that streamline data preparation and facilitate informed decisions regarding the suitability of data for AI applications. It not only saves time but also optimizes the effort invested in the initial stages of model development.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">While APPFL and APPFLx have significantly streamlined traditional PPFL experiments and facilitated the training of unimodal biomedical AI models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>, there remains considerable progress to be made. As illustrated in Figure <a href="#S1.F1" title="Figure 1 ‣ I Introduction ‣ Advances in Privacy Preserving Federated Learning to Realize a Truly Learning Healthcare System" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, our envisioned PPFL framework aims to advance a truly learning healthcare system that is capable of providing more precise diagnoses, prognoses, treatments, and preventative measures. Such a framework utilizes a trusted server, secured with privacy-enhancing techniques and robust cybersecurity algorithms, to orchestrate PPFL experiments among client hospitals with heterogeneous cloud or on-premise computing and storage systems. Through this collaboration, multiple healthcare delivery organizations can jointly train robust machine learning models that effectively generalize across diverse patient populations by leveraging multimodal biomedical data stored within their private infrastructures. Moreover, addition of continuous learning to PPFL framework, allows for early detection of any performance degradation, real-time adaptation of models to new patient data, and evolving health trends across multiple healthcare provides. In the following sections, we will provide details about the essential building blocks of this envisioned framework, including federated training for multimodal biomedical models, hierarchical FL for collaborative training beyond limited trust boundaries, federated continuous training, and cost-aware FL on the cloud.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Federated Training of Multimodal Biomedical Models</span>
</h2>

<figure id="S3.F2" class="ltx_figure">
<p id="S3.F2.1" class="ltx_p ltx_align_center"><span id="S3.F2.1.1" class="ltx_text"><img src="/html/2409.19756/assets/x2.png" id="S3.F2.1.1.g1" class="ltx_graphics ltx_img_landscape" width="368" height="137" alt="Refer to caption"></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Different sample and multimodal feature distribution patterns among clients in multimodal federated learning. </figcaption>
</figure>
<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">Biomedical health data are inherently multimodal, encompassing electronic health records, genomic information, medical imaging, laboratory results, and data from wearable devices, among others <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>, <a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>. In practice, clinicians typically integrate multiple available data types when making diagnoses or treatment decisions, most current biomedical health AI models are limited to specific tasks based on single data sources, such as imaging or text <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>. Multimodal AI models, which can utilize data from diverse sources like genetics, imaging, clinical records, and environmental factors, offer a promising solution to this limitation. These models have the potential to handle the complexity and high dimensionality of biomedical data, which is crucial for understanding interactions within biological systems and predicting complex diseases. As biomedical data increasingly become multimodal, such models are poised to revolutionize personalized medicine, digital clinical trials, and real-time health surveillance <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>. Currently, most FL applications in biomedicine use traditional horizontal FL, where all the clients share the same feature space and collaboratively train the same model architecture under the orchestration of a central server. These applications primarily rely on uni-modal data such as electronic health records and medical imaging <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib30" title="" class="ltx_ref">30</a>, <a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>. However, given the inherently multimodal nature of biomedical data, it is important to explore the feasibility of employing PPFL to train robust, generalized multimodal AI models by using the diverse biomedical health data available across diverse administrative and geographical boundaries.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS1.5.1.1" class="ltx_text">III-A</span> </span><span id="S3.SS1.6.2" class="ltx_text ltx_font_italic">Multimodal Learning</span>
</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">Some common modalities in biomedicine include images (e.g., MRI, histology), tabular data (e.g., gene expression), and text (e.g., clinical data). Multimodal learning aims to utilize these different data modalities to provide the most informative predictions. Combining data from multiple sources enhances the information available beyond what any individual modality can provide, and integrating weak signals across modalities can help overcome noise present in a single modality.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">For example, integrating molecular, imaging, and clinical data can improve the quality and accuracy of biomarkers for cancer, offering a more comprehensive understanding of the disease, instead of any of these modalities individually. Single-modality data, such as radiology scans or gene expression data from bulk RNASeq, are often found to be insufficient for capturing the complex heterogeneity of cancer. While radiology scans provide macroscopic information with spatial context, bulk RNASeq gene expression data offers molecular-level insights without the spatial context. By integrating these orthogonal data sources, we can capture complementary aspects of tumor biology.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.1" class="ltx_p">Different data modalities—such as clinical notes, medical images, genomic data, and sensor readings—often contain complementary information and may vary in quality. When these diverse modalities are effectively integrated, they can provide a more comprehensive and informative view than any single data type alone, leading to more accurate prognoses, diagnoses, and treatment plans. However, directly combining such heterogeneous data is often impractical due to differences in data formats, structures, scales, and the complexities involved in processing them together.</p>
</div>
<div id="S3.SS1.p4" class="ltx_para">
<p id="S3.SS1.p4.1" class="ltx_p">To address this challenge, most multimodal models employ embeddings, transforming data from each modality into unified representations within a shared feature space. This approach facilitates the integration of different data types by encoding their essential features in a way that makes them compatible for joint analysis. The method of embedding generation is critical, as it significantly affects the level of inter-modal learning and, consequently, the overall performance of the model. Effective embedding strategies enhance the model’s ability to learn from the combined data, leading to more robust and insightful outcomes in biomedical research and healthcare applications.</p>
</div>
<div id="S3.SS1.p5" class="ltx_para">
<p id="S3.SS1.p5.1" class="ltx_p">Multimodal AI models generate joint representations of heterogeneous data modalities through data fusion, which can be broadly categorized into three types: early fusion, joint fusion, and late fusion <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>. In early fusion, the embeddings from the different modalities are generated independently and then combined to act as input to a downstream task-specific prediction model. In joint fusion, the embeddings from all the modalities are dynamically updated during training, allowing them to learn directly from the task objective as well as from the other modalities. In late fusion, instead of combining the embeddings from different modalities, the predictions from separate uni-modal submodels are combined into a final prediction. While joint fusion is theoretically the most informed way to learn the embeddings, it can be computationally expensive as it requires training the embedding generation models and the final prediction model simultaneously.</p>
</div>
<div id="S3.SS1.p6" class="ltx_para">
<p id="S3.SS1.p6.1" class="ltx_p">Integrating data from multiple sources and modalities to train a single AI model can be challenging due to varying information content and quality across modalities and sources. The embeddings must be context-specific and capable of capturing relevant features from their respective modalities. They should have sufficient dimensionality to represent the underlying characteristics of the modalities that are relevant for the task, but not so high as to become computationally expensive for model training. Such embedding generation methods can differ significantly among modalities, and are often strongly tied to the biological insights of the data they represent. For example, in histology whole slide images (WSI) or MRI scans, convolutional neural networks (CNNs) or vision transformer models can be used to generate embeddings after learning important features from a large number of training samples <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>. For bulk RNASeq data available in tabular form, variational autoencoders (VAEs) can be used to generate lower dimensional context-specific embeddings from the very high dimensional gene expression data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>. By carefully selecting embedding generation techniques tailored to each modality, it is possible to harmonize diverse data sources leading to improved model performance and more informative predictions.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS2.5.1.1" class="ltx_text">III-B</span> </span><span id="S3.SS2.6.2" class="ltx_text ltx_font_italic">Integration of Multimodal Learning in a Federated Setting</span>
</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">When training a multimodal model in a federated setting, there are three scenarios based on the distribution of the sample and multimodal feature spaces. In the first scenario, when all clients shared the same multimodal feature space, as depicted in Figure <a href="#S3.F2" title="Figure 2 ‣ III Federated Training of Multimodal Biomedical Models ‣ Advances in Privacy Preserving Federated Learning to Realize a Truly Learning Healthcare System" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>-a, a multimodal model can be trained directly using traditional FL algorithms, where each client trains an individual model with the same architecture and shares the locally trained model parameters for aggregation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>, <a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>. In the second scenario, the clients share the same sample space but possess different data modalities, as shown in Figure <a href="#S3.F2" title="Figure 2 ‣ III Federated Training of Multimodal Biomedical Models ‣ Advances in Privacy Preserving Federated Learning to Realize a Truly Learning Healthcare System" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>-b, making vertical FL (VFL) an appropriate solution. In VFL, each client trains a local model on its respective data modalities, generates latent representations, and sends these to the server to update the global model. The server then sends back gradients for the corresponding latent representations, allowing each client to update its local model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>, <a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>. However, VFL typically requires data identifiers to align distributed samples, which may not always be feasible in biomedical applications. In the third scenario, where clients have different sample and multimodal feature spaces and lack unique identifiers for aligning samples (Figure <a href="#S3.F2" title="Figure 2 ‣ III Federated Training of Multimodal Biomedical Models ‣ Advances in Privacy Preserving Federated Learning to Realize a Truly Learning Healthcare System" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>-c), training a multimodal model collaboratively becomes more challenging. One potential solution is for each client to train a sub-model on its local data modalities and share it with other clients to collectively build a larger multimodal model using intermediate or late fusion techniques. Another approach involves having each client train a local model on its private data modalities and transmit the latent representations of publicly available multimodal data to the server for sample alignment <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite>. Additionally, generative models could be used to create synthetic data that mimics the distribution of each client’s multimodal data, enabling alignment without compromising sensitive information. While promising, these approaches remain an open area of research, requiring further investigation to address the complexities of multimodal FL.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">Hierarchical FL for Collaborative Training Beyond the Trust Boundaries</span>
</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">In FL, while no data are directly exchanged between the server and clients, private and confidential training data can still be vulnerable to reconstruction from shared model gradients through gradient inversion techniques <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib39" title="" class="ltx_ref">39</a>, <a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>. As a result, some clients may be reluctant to share trained model parameters or gradients with an untrusted central server. For instance, small clinics within a geographic region might prefer to share model parameters exclusively with a trusted or affiliated local hospital. However, this limited trust boundary could result in biased localized datasets, restricting the model’s ability to generalize across diverse populations. Additionally, the need for diverse data becomes even more pressing in biomedical health applications involving rare diseases, where datasets are often small and fragmented across multiple institutions. Limiting data sharing with a single trusted entity may reduce the ability to capture complex patterns that are essential for understanding and diagnosing such conditions.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.1" class="ltx_p">Hierarchical federated learning (HierFL) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>, <a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite> offers a solution to this challenge by enabling broader participation while maintaining trust. As illustrated in Figure <a href="#S4.F3" title="Figure 3 ‣ IV Hierarchical FL for Collaborative Training Beyond the Trust Boundaries ‣ Advances in Privacy Preserving Federated Learning to Realize a Truly Learning Healthcare System" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, HierFL allows groups of clients, such as small clinics, to first share their local model parameters with an intermediate server trusted by the clients, such as a large local hospital. This intermediate server aggregates the local parameters, obscuring individual client information. Aggregated models from multiple intermediate servers, representing different trusted groups, are then sent to a central root server for further global aggregation. The resulting global model, now trained on a more diverse and representative dataset, is subsequently distributed back to the clients for further local training. HierFL enhances privacy by introducing an additional layer of aggregation with trusted intermediate servers, thus encouraging wider participation by clients beyond their immediate trust boundaries. This intermediate aggregation process safeguards individual model details while enabling the creation of a global model that generalizes better across varied populations, making it particularly valuable for biomedical health applications.</p>
</div>
<figure id="S4.F3" class="ltx_figure">
<p id="S4.F3.1" class="ltx_p ltx_align_center"><span id="S4.F3.1.1" class="ltx_text"><img src="/html/2409.19756/assets/x3.png" id="S4.F3.1.1.g1" class="ltx_graphics ltx_img_landscape" width="461" height="201" alt="Refer to caption"></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Hierarchical federated learning helps to connect several small trust group to a larger federation.</figcaption>
</figure>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">Federated Continuous Learning for Multimodal Biomedical Models</span>
</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">Continuous learning, the process by which models are continuously updated and improved as new data becomes available <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>, <a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite>, is essential in biomedical applications <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite>. It enables healthcare systems to remain adaptive and responsive, evolving to meet the ever-changing needs of patients across different settings. In a field where medical knowledge, treatments, and patient conditions are constantly evolving, continuous learning ensures that models stay relevant and resistant to performance degradation by incorporating real-time data. By continuously integrating new information from sources like patient records, clinical trials, and wearable devices, healthcare models can provide more accurate and robust predictions, diagnostics, and treatment recommendations. This dynamic approach allows healthcare systems to offer more personalized, timely care while improving outcomes for diverse patient populations. Ultimately, continuous learning helps reduce healthcare disparities and creates a more effective, data-driven healthcare ecosystem that can evolve in response to emerging challenges, thus enabling true learning healthcare systems (LHS).</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">Integrating continuous learning capabilities into a PPFL framework offers the framework the ability to timely adapt to new data from diverse medical institutions while maintaining data privacy. This integration allows models to stay up-to-date with the latest medical advancements, patient information, and social health trends, leading to improved predictive accuracy treatment recommendations. Additionally, continuous learning within a PPFL framework ensures that the models evolve to reflect the diversity of healthcare settings and populations, reducing biases and enabling better generalization. Ultimately, this combination enhances the capacity of healthcare systems to provide real-time, data-driven insights without compromising patient privacy. Additional capabilities need to be developed to calculate the optimal privacy budget for biomedical multimodal datasets to prevent model inversion attacks but allow for improved model performance.</p>
</div>
<div id="S5.p3" class="ltx_para">
<p id="S5.p3.1" class="ltx_p">Additionally, the PPFL framework can be extended with federated evaluation and monitoring capabilities to enable timely assessment and monitoring of the model’s performance across diverse and distributed client populations. As shown in Figure <a href="#S5.F4" title="Figure 4 ‣ V Federated Continuous Learning for Multimodal Biomedical Models ‣ Advances in Privacy Preserving Federated Learning to Realize a Truly Learning Healthcare System" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, whenever a biomedical AI model is trained via FL, the system will periodically and systematically evaluate its key performance metrics such as accuracy, precision, and recall in a federated setting to ensure the model remains effective under varying conditions and data distributions. Should the system detect any significant performance degradation, such as a decline in accuracy or a shift in data patterns, these insights can trigger an immediate, automated response via initiating a federated continuous learning process among the distributed clients to allow the model to adapt and retrain on new or evolving datasets without compromising data privacy. This dynamic feedback loop, when coupled with capabilities like AIDRIN, ensures that the model is regularly updated and optimized as needed, preventing performance degradation while addressing challenges such as data drift, population variance, or emerging trends in real-time. These capabilities significantly enhance the framework’s resilience and scalability, particularly in environments where data is continuously generated and needs to be rapidly incorporated into the model.</p>
</div>
<figure id="S5.F4" class="ltx_figure">
<p id="S5.F4.1" class="ltx_p ltx_align_center"><span id="S5.F4.1.1" class="ltx_text"><img src="/html/2409.19756/assets/x4.png" id="S5.F4.1.1.g1" class="ltx_graphics ltx_img_landscape" width="461" height="228" alt="Refer to caption"></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Federated continuous learning workflow with a federated evaluation feedback loop for timely performance degradation detection.</figcaption>
</figure>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VI </span><span id="S6.1.1" class="ltx_text ltx_font_smallcaps">Cost-Aware FL on the Cloud</span>
</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">Training AI models is often expensive, especially when relying on GPU virtual machine instances from cloud providers like AWS, Google Cloud Platform, and Azure. As many medical institutes lack sufficient on-premise computing and storage resources, they are highly dependent on cloud providers for AI model training tasks. This creates a crucial need to make FL experiments more cost-effective, speeding up the transition of FL from experimental prototyping to real-world applications. Popular cloud providers offer a cost-saving option called spot instances, which allow users to bid for unused virtual machines at significantly lower prices than on-demand instances (usually 70% to 90% cheaper). However, as a compromise for the low price, these spot instances can be terminated at any time with a short notice when the cloud provider needs them for on-demand users. As a consequence, clients should checkpoint their local training status and notify the server when termination is imminent. On the server side, inspired by work like <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite>, which uses a server-side computing-aware scheduler to enhance efficiency in heterogeneous environments, a cost-aware scheduler can be designed to make the FL experiments cost-effective, as shown in Figure <a href="#S6.F5" title="Figure 5 ‣ VI Cost-Aware FL on the Cloud ‣ Advances in Privacy Preserving Federated Learning to Realize a Truly Learning Healthcare System" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>. This scheduler would record the cost of training in real-time, manage the computing instances within a predefined training budget, reallocate resources for terminated instances, and perform aggregations even in the absence of offline clients. Implementing such cost-saving measures can significantly reduce financial barriers, making it more feasible to deploy FL more broadly within the healthcare ecosystems.</p>
</div>
<figure id="S6.F5" class="ltx_figure">
<p id="S6.F5.1" class="ltx_p ltx_align_center"><span id="S6.F5.1.1" class="ltx_text"><img src="/html/2409.19756/assets/x5.png" id="S6.F5.1.1.g1" class="ltx_graphics ltx_img_landscape" width="461" height="241" alt="Refer to caption"></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Using a server-side cost-aware scheduler to achieve cost-effective FL experiments among clients on the cloud.</figcaption>
</figure>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VII </span><span id="S7.1.1" class="ltx_text ltx_font_smallcaps">Conclusions</span>
</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">In this paper, we propose that privacy-preserving federated learning (PPFL) could offer a viable pathway toward realizing a truly learning healthcare system by facilitating the training of robust multimodal biomedical models while preserving patient data privacy. Our envisioned PPFL framework goes beyond traditional limitations by incorporating supports for hierarchical FL, which extends trust boundaries and enhances collaborative potential among diverse healthcare institutions. It also integrates federated evaluation and continuous learning mechanisms that allow for real-time updates and improvements to models based on new data and insights, ensuring that the models remain relevant and accurate over time. Moreover, the envisioned framework includes the development of cost-effective algorithms that make the adoption of FL feasible even for institutions with limited resources. Through these innovations, PPFL can drive forward the evolution of healthcare towards more automated, responsive, and efficient practices.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_font_smallcaps ltx_title_section">Acknowledgments</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">This work was supported by the U.S. Department of Energy, Office of Science, Advanced Scientific Computing Research, under Contract DE-AC02-06CH11357.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
V. Gulshan, L. Peng, M. Coram, M. C. Stumpe, D. Wu, A. Narayanaswamy, S. Venugopalan, K. Widner, T. Madams, J. Cuadros <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Development and validation of a deep learning algorithm for detection of diabetic retinopathy in retinal fundus photographs,” <em id="bib.bib1.2.2" class="ltx_emph ltx_font_italic">jama</em>, vol. 316, no. 22, pp. 2402–2410, 2016.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
A. Esteva, B. Kuprel, R. A. Novoa, J. Ko, S. M. Swetter, H. M. Blau, and S. Thrun, “Dermatologist-level classification of skin cancer with deep neural networks,” <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">nature</em>, vol. 542, no. 7639, pp. 115–118, 2017.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
R. Miotto, F. Wang, S. Wang, X. Jiang, and J. T. Dudley, “Deep learning for healthcare: review, opportunities and challenges,” <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">Briefings in bioinformatics</em>, vol. 19, no. 6, pp. 1236–1246, 2018.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
J. Kaplan, S. McCandlish, T. Henighan, T. B. Brown, B. Chess, R. Child, S. Gray, A. Radford, J. Wu, and D. Amodei, “Scaling laws for neural language models,” <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2001.08361</em>, 2020.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
U.S. Congress, “Health Insurance Portability and Accountability Act of 1996,” <a target="_blank" href="https://www.govinfo.gov/content/pkg/PLAW-104publ191/pdf/PLAW-104publ191.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.govinfo.gov/content/pkg/PLAW-104publ191/pdf/PLAW-104publ191.pdf</a>, 1996, public Law 104-191.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
European Parliament and Council of the European Union, “Regulation (EU) 2016/679 of the European Parliament and of the Council of 27 April 2016,” <a target="_blank" href="https://eur-lex.europa.eu/eli/reg/2016/679/oj" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://eur-lex.europa.eu/eli/reg/2016/679/oj</a>, 2016, general Data Protection Regulation.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
J. Konečnỳ, “Federated learning: Strategies for improving communication efficiency,” <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1610.05492</em>, 2016.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas, “Communication-efficient learning of deep networks from decentralized data,” in <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">Artificial intelligence and statistics</em>.   PMLR, 2017, pp. 1273–1282.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Q. Yang, Y. Liu, T. Chen, and Y. Tong, “Federated machine learning: Concept and applications,” <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">ACM Transactions on Intelligent Systems and Technology (TIST)</em>, vol. 10, no. 2, pp. 1–19, 2019.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
P. Kairouz, H. B. McMahan, B. Avent, A. Bellet, M. Bennis, A. N. Bhagoji, K. Bonawitz, Z. Charles, G. Cormode, R. Cummings <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Advances and open problems in federated learning,” <em id="bib.bib10.2.2" class="ltx_emph ltx_font_italic">Foundations and Trends® in Machine Learning</em>, vol. 14, no. 1–2, pp. 1–210, 2021.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
B. Zhao, K. R. Mopuri, and H. Bilen, “idlg: Improved deep leakage from gradients,” <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2001.02610</em>, 2020.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
J. Geiping, H. Bauermeister, H. Dröge, and M. Moeller, “Inverting gradients-how easy is it to break privacy in federated learning?” <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, vol. 33, pp. 16 937–16 947, 2020.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Executive Order No. 2023-24283, “Safe, secure, and trustworthy development and use of artificial intelligence,” Federal Register, November 2023, accessed: 2023-11-01. [Online]. Available: <a target="_blank" href="https://www.federalregister.gov/documents/2023/11/01/2023-24283/safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.federalregister.gov/documents/2023/11/01/2023-24283/safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence</a>

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
N. Ravi, P. Chaturvedi, E. Huerta, Z. Liu, R. Chard, A. Scourtas, K. Schmidt, K. Chard, B. Blaiszik, and I. Foster, “Fair principles for ai models with a practical application for accelerated high energy diffraction microscopy,” <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">Scientific Data</em>, vol. 9, no. 1, p. 657, 2022.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
E. Huerta, B. Blaiszik, L. C. Brinson, K. E. Bouchard, D. Diaz, C. Doglioni, J. M. Duarte, M. Emani, I. Foster, G. Fox <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Fair for ai: An interdisciplinary and international community building perspective,” <em id="bib.bib15.2.2" class="ltx_emph ltx_font_italic">Scientific data</em>, vol. 10, no. 1, p. 487, 2023.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
M. Ryu, Y. Kim, K. Kim, and R. K. Madduri, “APPFL: open-source software framework for privacy-preserving federated learning,” in <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">2022 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)</em>.   IEEE, 2022, pp. 1074–1083.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Z. Li, S. He, Z. Yang, M. Ryu, K. Kim, and R. Madduri, “Advances in appfl: A comprehensive and extensible federated learning framework,” 2024. [Online]. Available: <a target="_blank" href="https://arxiv.org/abs/2409.11585" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2409.11585</a>

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
C. Dwork, “Differential privacy,” in <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">International colloquium on automata, languages, and programming</em>.   Springer, 2006, pp. 1–12.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
D. J. Beutel, T. Topal, A. Mathur, X. Qiu, J. Fernandez-Marques, Y. Gao, L. Sani, K. H. Li, T. Parcollet, P. P. B. de Gusmão <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Flower: A friendly federated learning research framework,” <em id="bib.bib19.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2007.14390</em>, 2020.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
H. R. Roth, Y. Cheng, Y. Wen, I. Yang, Z. Xu, Y.-T. Hsieh, K. Kersten, A. Harouni, C. Zhao, K. Lu <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “NVIDIA FLARE: Federated learning from simulation to real-world,” <em id="bib.bib20.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2210.13291</em>, 2022.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Z. Li, S. He, P. Chaturvedi, T.-H. Hoang, M. Ryu, E. Huerta, V. Kindratenko, J. Fuhrman, M. Giger, R. Chard <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Appflx: Providing privacy-preserving cross-silo federated learning as a service,” in <em id="bib.bib21.2.2" class="ltx_emph ltx_font_italic">2023 IEEE 19th International Conference on e-Science (e-Science)</em>.   IEEE, 2023, pp. 1–4.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
S. Tuecke, R. Ananthakrishnan, K. Chard, M. Lidman, B. McCollam, S. Rosen, and I. Foster, “Globus auth: A research identity and access management platform,” in <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">2016 IEEE 12th International Conference on e-Science (e-Science)</em>.   IEEE, 2016, pp. 203–212.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
K. Hiniduma, S. Byna, J. L. Bez, and R. Madduri, “Ai data readiness inspector (aidrin) for quantitative assessment of data readiness for ai,” in <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 36th International Conference on Scientific and Statistical Database Management</em>, 2024, pp. 1–12.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
T.-H. Hoang, J. Fuhrman, R. Madduri, M. Li, P. Chaturvedi, Z. Li, K. Kim, M. Ryu, R. Chard, E. Huerta <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Enabling end-to-end secure federated learning in biomedical research on heterogeneous computing environments with appflx,” <em id="bib.bib24.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2312.08701</em>, 2023.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
S. R. Stahlschmidt, B. Ulfenborg, and J. Synnergren, “Multimodal deep learning for biomedical data fusion: a review,” <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">Briefings in Bioinformatics</em>, vol. 23, no. 2, p. bbab569, 2022.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
T. Tu, S. Azizi, D. Driess, M. Schaekermann, M. Amin, P.-C. Chang, A. Carroll, C. Lau, R. Tanno, I. Ktena <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Towards generalist biomedical ai,” <em id="bib.bib26.2.2" class="ltx_emph ltx_font_italic">NEJM AI</em>, vol. 1, no. 3, p. AIoa2300138, 2024.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
J. N. Acosta, G. J. Falcone, P. Rajpurkar, and E. J. Topol, “Multimodal biomedical ai,” <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">Nature Medicine</em>, vol. 28, no. 9, pp. 1773–1784, 2022.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
S. Pati, U. Baid, B. Edwards, M. Sheller, S.-H. Wang, G. A. Reina, P. Foley, A. Gruzdev, D. Karkada, C. Davatzikos <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Federated learning enables big data for rare cancer boundary detection,” <em id="bib.bib28.2.2" class="ltx_emph ltx_font_italic">Nature Communications</em>, vol. 13, no. 1, p. 7346, 2022.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
G. Kaissis, A. Ziller, J. Passerat-Palmbach, T. Ryffel, D. Usynin, A. Trask, I. Lima Jr, J. Mancuso, F. Jungmann, M.-M. Steinborn <em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “End-to-end privacy preserving deep learning on multi-institutional medical imaging,” <em id="bib.bib29.2.2" class="ltx_emph ltx_font_italic">Nature Machine Intelligence</em>, vol. 3, no. 6, pp. 473–484, 2021.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
J. Ogier du Terrail, S.-S. Ayed, E. Cyffers, F. Grimberg, C. He, R. Loeb, P. Mangold, T. Marchand, O. Marfoq, E. Mushtaq <em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “FLamby: Datasets and benchmarks for cross-silo federated learning in realistic healthcare settings,” <em id="bib.bib30.2.2" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, vol. 35, pp. 5315–5334, 2022.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
S. Steyaert, M. Pizurica, D. Nagaraj, P. Khandelwal, T. Hernandez-Boussard, A. J. Gentles, and O. Gevaert, “Multimodal data fusion for cancer biomarker discovery with deep learning,” <em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">Nature machine intelligence</em>, vol. 5, no. 4, pp. 351–362, 2023.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
M. Kang, H. Song, S. Park, D. Yoo, and S. Pereira, “Benchmarking self-supervised learning on diverse pathology datasets,” in <em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, 2023, pp. 3344–3354.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
F. Carrillo-Perez, M. Pizurica, Y. Zheng, T. N. Nandi, R. Madduri, J. Shen, and O. Gevaert, “Generation of synthetic whole-slide image tiles of tumours from rna-sequencing data via cascaded diffusion models,” <em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">Nature Biomedical Engineering</em>, pp. 1–13, 2024.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
B. Xiong, X. Yang, F. Qi, and C. Xu, “A unified framework for multi-modal federated learning,” <em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">Neurocomputing</em>, vol. 480, pp. 110–118, 2022.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
L. Che, J. Wang, Y. Zhou, and F. Ma, “Multimodal federated learning: A survey,” <em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">Sensors</em>, vol. 23, no. 15, p. 6986, 2023.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
F. Fu, Y. Shao, L. Yu, J. Jiang, H. Xue, Y. Tao, and B. Cui, “Vf2boost: Very fast vertical federated gradient boosting for cross-enterprise learning,” in <em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2021 International Conference on Management of Data</em>, 2021, pp. 563–576.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
Y. Liu, Y. Kang, T. Zou, Y. Pu, Y. He, X. Ye, Y. Ouyang, Y.-Q. Zhang, and Q. Yang, “Vertical federated learning: Concepts, advances, and challenges,” <em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Knowledge and Data Engineering</em>, 2024.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
Q. Yu, Y. Liu, Y. Wang, K. Xu, and J. Liu, “Multimodal federated learning via contrastive representation ensemble,” <em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2302.08888</em>, 2023.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
A. Hatamizadeh, H. Yin, P. Molchanov, A. Myronenko, W. Li, P. Dogra, A. Feng, M. G. Flores, J. Kautz, D. Xu <em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Do gradient inversion attacks make federated learning unsafe?” <em id="bib.bib39.2.2" class="ltx_emph ltx_font_italic">IEEE Transactions on Medical Imaging</em>, vol. 42, no. 7, pp. 2044–2056, 2023.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
M. S. H. Abad, E. Ozfatura, D. Gunduz, and O. Ercetin, “Hierarchical federated learning across heterogeneous cellular networks,” in <em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>.   IEEE, 2020, pp. 8866–8870.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
C. Briggs, Z. Fan, and P. Andras, “Federated learning with hierarchical clustering of local updates to improve training on non-iid data,” in <em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">2020 international joint conference on neural networks (IJCNN)</em>.   IEEE, 2020, pp. 1–9.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
S. Thrun and T. M. Mitchell, “Lifelong robot learning,” <em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">Robotics and autonomous systems</em>, vol. 15, no. 1-2, pp. 25–46, 1995.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
G. I. Parisi, R. Kemker, J. L. Part, C. Kanan, and S. Wermter, “Continual lifelong learning with neural networks: A review,” <em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">Neural networks</em>, vol. 113, pp. 54–71, 2019.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
C. S. Lee and A. Y. Lee, “Clinical applications of continual learning machine learning,” <em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">The Lancet Digital Health</em>, vol. 2, no. 6, pp. e279–e281, 2020.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
Z. Li, P. Chaturvedi, S. He, H. Chen, G. Singh, V. Kindratenko, E. A. Huerta, K. Kim, and R. Madduri, “Fedcompass: efficient cross-silo federated learning on heterogeneous client devices using a computing power aware scheduler,” <em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2309.14675</em>, 2023.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2409.19755" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2409.19756" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2409.19756">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2409.19756" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2409.19757" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sat Oct  5 21:27:28 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
