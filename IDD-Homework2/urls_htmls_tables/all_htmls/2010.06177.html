<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2010.06177] COVID-19 Imaging Data Privacy by Federated Learning Design: A Theoretical Framework</title><meta property="og:description" content="To address COVID-19 healthcare challenges, we need frequent sharing of health data, knowledge and resources at a global scale. However, in this digital age, data privacy is a big concern that requires the secure embedd…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="COVID-19 Imaging Data Privacy by Federated Learning Design: A Theoretical Framework">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="COVID-19 Imaging Data Privacy by Federated Learning Design: A Theoretical Framework">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2010.06177">

<!--Generated on Thu Mar  7 04:13:43 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">COVID-19 Imaging Data Privacy by Federated Learning Design: A Theoretical Framework </h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Anwaar Ulhaq 
<br class="ltx_break">Machine Vision and Digital Health Research Group,
<br class="ltx_break">Charles Sturt University, Port Macquarie, NSW, Australia
<br class="ltx_break"><span id="id1.1.id1" class="ltx_text ltx_font_typewriter">aulhaq@csu.edu.au</span>
<span id="id2.2.id2" class="ltx_ERROR undefined">\AND</span>Oliver Burmeister
<br class="ltx_break">Charles Sturt University, Bathurst, NSW, Australia
<br class="ltx_break"><span id="id3.3.id3" class="ltx_text ltx_font_typewriter">oburmeister@csu.edu.au</span>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id4.id1" class="ltx_p">To address COVID-19 healthcare challenges, we need frequent sharing of health data, knowledge and resources at a global scale. However, in this digital age, data privacy is a big concern that requires the secure embedding of privacy assurance into the design of all technological solutions that use health data. In this paper, we introduce differential privacy by design (dPbD) framework and discuss its embedding into the federated machine learning system. To limit the scope of our paper, we focus on the problem scenario of COVID-19 imaging data privacy for disease diagnosis by computer vision and deep learning approaches. We discuss the evaluation of the proposed design of federated machine learning systems and discuss how differential privacy by design (dPbD) framework can enhance data privacy in federated learning systems with scalability and robustness. We argue that scalable differentially private federated learning design is a promising solution for building a secure, private and collaborative machine learning model such as required to combat COVID19 challenge.</p>
</div>
<div id="p1" class="ltx_para ltx_noindent">
<p id="p1.1" class="ltx_p">Keywords: Differential privacy , COVID-19, Privacy by design (PbD), Federated learning systems</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para ltx_noindent">
<p id="S1.p1.1" class="ltx_p">COVID-19 pandemic has changed our world and its challenges <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. Today, more than ever, we require a centralised platform and collective approach to facilitate our collaborative research efforts in different scientific disciplines <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>. Artificial intelligence, especially computer vision, has responded strongly to this challenge <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>. Various imaging modalities are being processed and analysed for COVID-19 control <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>. These approaches vary from disease diagnosis and prognosis to disease prevention and management based on different imaging modalities like digital chest x-ray radiography (CXR), chest computed tomography (CT) and Lung ultrasound (LUS) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>. An ethical study of imaging data requires the privacy, confidentiality and integrity throughout data analysis. However, it seems a tremendous task due to the existing vulnerabilities of traditional machine learning systems that heavily rely on shared datasets for their training. Similarly, new data protection regulation like General Data Protection Regulation (GDPR) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> in the European Union puts restrictions on the move of data outside of their regional territories. This situation requires a fundamental change in the ways machine learning systems can work collaboratively.</p>
</div>
<div id="S1.p2" class="ltx_para ltx_noindent">
<p id="S1.p2.1" class="ltx_p">Privacy by design (PbD) approach <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> ensures that privacy assurance is embedded into a system design lifecycle by default from the beginning to the end. Therefore, any system built without including privacy considerations as a core part of their design process often behaves poor privacy control. A post (GDPR) world requires a focus on privacy by design with data privacy at the core of system design <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> . PbD has a special place in the design of machine learning systems, especially deep learning systems that are going to share our digital future. Google introduced a collaborative machine learning system <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> with embedded PbD named as federated learning in 2016 that nullified the need for a centralised training data. The fundamental idea is to use different clients or nodes to train local machine learning models on local data samples without any exchange, and sharing of model parameters (e.g. the weights and biases) between these local nodes at some frequency to generate a global model by a process called federated averaging. All clients or nodes then share this global model. As no data sharing takes place between the nodes, federated design simplicity ensures data privacy. These systems are ideally suited for taring machine learning algorithms for COVID-19 control as sensitive COVID-19 health data will not be shared and would remain in the custody of their subjects. Figure 1 illustrates privacy by design approach to machine learning with a federated model design for COVID-19 detection using CXR.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2010.06177/assets/FIG1.jpg" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="471" height="312" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>The proposed (dPbD) framework.</figcaption>
</figure>
<div id="S1.p3" class="ltx_para ltx_noindent">
<p id="S1.p3.1" class="ltx_p">However, this process does not guarantee data protection and system robustness. Attackers can figure out individual data based on the global model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>. Differential privacy adds random noise to an individual’s model, obscuring the results <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>. This random data can be added before the model is shared with the server, without revealing the actual data. This process preserves the individual’s privacy. However, this design approach has limited scalability and robustness. Additionally, this integration is hard to grasp for system designers due to its unreasonable complexity. Inspired from the preliminary empirical works on differentially-private federated learning, in this paper, we introduce a theoretical framework called differential privacy by design (dPbD) that can help to design scalable and robust federating learning systems for COVID-19data privacy. We address the following research questions in this paper:</p>
</div>
<div id="S1.p4" class="ltx_para ltx_noindent">
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">How can we devise a theoretical framework that underpins all saliant and impeding factors that impact the design of differentially-private federated learning systems with scalability and robustness?</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para ltx_noindent">
<p id="S1.I1.i2.p1.1" class="ltx_p">How can differentially-private federated learning systems ensure the privacy of COVID-19 imaging data without adversely harming the accuracy?</p>
</div>
</li>
</ul>
</div>
<div id="S1.p5" class="ltx_para ltx_noindent">
<p id="S1.p5.1" class="ltx_p">The contributions of this paper are as follows:
We extend privacy by design framework in the context of differential privacy and federated learning. We propose a theoretical framework called differential privacy by design (dPbD) that underpins saliant and impeding factors that impact the design of differentially-private federated learning systems with scalability and robustness. We discuss how the proposed framework can be used to model privacy of COVID-19 imaging data for training differentially-private federated learning systems.</p>
</div>
<div id="S1.p6" class="ltx_para ltx_noindent">
<p id="S1.p6.1" class="ltx_p">We have organised the paper as follow: Section 2 describes the related work. A brief introduction to preliminary techniques that have inspired the development of this theoretical framework is discussed in section 3. The proposed framework is presented in section 4. We discuss seven principles to implement this design in section 5. Embedding of the proposed principles into federated learning system design for COVID-19 data is discussed in section 6. It is followed by a discussion and concluding remarks.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<div id="S2.p1" class="ltx_para ltx_noindent">
<p id="S2.p1.1" class="ltx_p">At an early stage of COVID-19, authorities recognised the importance of privacy and public trust to fight against the pandemic. Some data privacy experts also dubbed it as an unusual scenario like the European Data Protection Board that highlighted article 9 of the General Data Protection Regulation. This article allows the processing of personal data “for reasons of public interest in the area of public health, such as protecting against serious cross-border threats to health <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>. However, careful data-management practices in our data-intensive world require giving critical consideration to data privacy aspects. COVID-19 poses various challenges to the Biomedical Imaging (BI), Artificial Intelligence (AI), Data Analytics (DA), Computer Vision (CV) and Machine learning (ML) as these disciplines require adequate access to big data to detect, diagnose, and predict the spread of the infection <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>. This article restricts its scope to data privacy of COVID-19 medical imaging data required by computer vision and machine learning approaches for COVID-19 control.</p>
</div>
<div id="S2.p2" class="ltx_para ltx_noindent">
<p id="S2.p2.1" class="ltx_p">Privacy by design is considered as an approach to embedding privacy directly into system design and introduced by Ann Cavoukian in 2009 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>. This design is incorporated into the European GDPR that shows its importance <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>. Privacy-preserving machine earning uses privacy by design approach in its framework <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>. Most recently, Google introduced a federated machine learning framework for preserving the privacy of the training data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>. Federated learning systems use distributed framework where model training is performed locally at the client-side, then the updated model parameters are sent to a central server for aggregation. Contray to the idea of data fusion <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>, a global model aggregation or fusion is used. Several works <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> discuss design, challenges and future direction in the field of federated learning. We refer the interested readers to these articles. Federated learning systems inherently support privacy by design.</p>
</div>
<div id="S2.p3" class="ltx_para ltx_noindent">
<p id="S2.p3.1" class="ltx_p">However, PbD is criticised for being unclear, complex to enforce its implementation, and difficult to adapt to certain disciplines <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>. Anotherline of work in the privacy domain takes a huge interest in leveraging differential privacy into machine learning design for privacy-preserving AI. We refer review articles <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> for the interested reader. With the increased popularity and enhanced performance of deep learning, difference privacy is proposed for deep learning models and federated learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>, <a href="#bib.bib24" title="" class="ltx_ref">24</a>, <a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>. The integration of differential privacy and federated learning leads future research directions in privacy preserving AI. However, this marriage is incredibly complex and lacks clarity in its design due to various competing factors. The complexity of the preliminary work in this direction inspired us to propose a theoretical framework called differential privacy by federated design. It is specially designed to provide differential privacy to COVID-19 imaging data using a federated machine learning system.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Preliminaries:</h2>

<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Federated Machine Learning Systems</h3>

<div id="S3.SS1.p1" class="ltx_para ltx_noindent">
<p id="S3.SS1.p1.1" class="ltx_p">Federated learning is a powerful framework that is devised for machine learning scientists to work collaboratively with decentralised data with privacy by default setting. Google generated the initial idea as part of the series of works in 2015 and 2016 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>. The initial focus of the federated design was on on-device federated learning tailored to distributed mobile-user interactions. A sample example is G-board app that Predicts the next word to make typing effortless based on typed text using a Federated Ruccerent neural network (RNN) model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para ltx_noindent">
<p id="S3.SS1.p2.6" class="ltx_p">Consider a scenario of n machine learning scientists <math id="S3.SS1.p2.1.m1.3" class="ltx_Math" alttext="\{s_{1},...,s_{n}\}" display="inline"><semantics id="S3.SS1.p2.1.m1.3a"><mrow id="S3.SS1.p2.1.m1.3.3.2" xref="S3.SS1.p2.1.m1.3.3.3.cmml"><mo stretchy="false" id="S3.SS1.p2.1.m1.3.3.2.3" xref="S3.SS1.p2.1.m1.3.3.3.cmml">{</mo><msub id="S3.SS1.p2.1.m1.2.2.1.1" xref="S3.SS1.p2.1.m1.2.2.1.1.cmml"><mi id="S3.SS1.p2.1.m1.2.2.1.1.2" xref="S3.SS1.p2.1.m1.2.2.1.1.2.cmml">s</mi><mn id="S3.SS1.p2.1.m1.2.2.1.1.3" xref="S3.SS1.p2.1.m1.2.2.1.1.3.cmml">1</mn></msub><mo id="S3.SS1.p2.1.m1.3.3.2.4" xref="S3.SS1.p2.1.m1.3.3.3.cmml">,</mo><mi mathvariant="normal" id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml">…</mi><mo id="S3.SS1.p2.1.m1.3.3.2.5" xref="S3.SS1.p2.1.m1.3.3.3.cmml">,</mo><msub id="S3.SS1.p2.1.m1.3.3.2.2" xref="S3.SS1.p2.1.m1.3.3.2.2.cmml"><mi id="S3.SS1.p2.1.m1.3.3.2.2.2" xref="S3.SS1.p2.1.m1.3.3.2.2.2.cmml">s</mi><mi id="S3.SS1.p2.1.m1.3.3.2.2.3" xref="S3.SS1.p2.1.m1.3.3.2.2.3.cmml">n</mi></msub><mo stretchy="false" id="S3.SS1.p2.1.m1.3.3.2.6" xref="S3.SS1.p2.1.m1.3.3.3.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.3b"><set id="S3.SS1.p2.1.m1.3.3.3.cmml" xref="S3.SS1.p2.1.m1.3.3.2"><apply id="S3.SS1.p2.1.m1.2.2.1.1.cmml" xref="S3.SS1.p2.1.m1.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.1.m1.2.2.1.1.1.cmml" xref="S3.SS1.p2.1.m1.2.2.1.1">subscript</csymbol><ci id="S3.SS1.p2.1.m1.2.2.1.1.2.cmml" xref="S3.SS1.p2.1.m1.2.2.1.1.2">𝑠</ci><cn type="integer" id="S3.SS1.p2.1.m1.2.2.1.1.3.cmml" xref="S3.SS1.p2.1.m1.2.2.1.1.3">1</cn></apply><ci id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1">…</ci><apply id="S3.SS1.p2.1.m1.3.3.2.2.cmml" xref="S3.SS1.p2.1.m1.3.3.2.2"><csymbol cd="ambiguous" id="S3.SS1.p2.1.m1.3.3.2.2.1.cmml" xref="S3.SS1.p2.1.m1.3.3.2.2">subscript</csymbol><ci id="S3.SS1.p2.1.m1.3.3.2.2.2.cmml" xref="S3.SS1.p2.1.m1.3.3.2.2.2">𝑠</ci><ci id="S3.SS1.p2.1.m1.3.3.2.2.3.cmml" xref="S3.SS1.p2.1.m1.3.3.2.2.3">𝑛</ci></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.3c">\{s_{1},...,s_{n}\}</annotation></semantics></math> working on COVID-19 imaging data, all of whom wish to collaborate to train a machine-learning model by sharing their respective imaging data <math id="S3.SS1.p2.2.m2.3" class="ltx_Math" alttext="\{d_{1},...,d_{n}\}" display="inline"><semantics id="S3.SS1.p2.2.m2.3a"><mrow id="S3.SS1.p2.2.m2.3.3.2" xref="S3.SS1.p2.2.m2.3.3.3.cmml"><mo stretchy="false" id="S3.SS1.p2.2.m2.3.3.2.3" xref="S3.SS1.p2.2.m2.3.3.3.cmml">{</mo><msub id="S3.SS1.p2.2.m2.2.2.1.1" xref="S3.SS1.p2.2.m2.2.2.1.1.cmml"><mi id="S3.SS1.p2.2.m2.2.2.1.1.2" xref="S3.SS1.p2.2.m2.2.2.1.1.2.cmml">d</mi><mn id="S3.SS1.p2.2.m2.2.2.1.1.3" xref="S3.SS1.p2.2.m2.2.2.1.1.3.cmml">1</mn></msub><mo id="S3.SS1.p2.2.m2.3.3.2.4" xref="S3.SS1.p2.2.m2.3.3.3.cmml">,</mo><mi mathvariant="normal" id="S3.SS1.p2.2.m2.1.1" xref="S3.SS1.p2.2.m2.1.1.cmml">…</mi><mo id="S3.SS1.p2.2.m2.3.3.2.5" xref="S3.SS1.p2.2.m2.3.3.3.cmml">,</mo><msub id="S3.SS1.p2.2.m2.3.3.2.2" xref="S3.SS1.p2.2.m2.3.3.2.2.cmml"><mi id="S3.SS1.p2.2.m2.3.3.2.2.2" xref="S3.SS1.p2.2.m2.3.3.2.2.2.cmml">d</mi><mi id="S3.SS1.p2.2.m2.3.3.2.2.3" xref="S3.SS1.p2.2.m2.3.3.2.2.3.cmml">n</mi></msub><mo stretchy="false" id="S3.SS1.p2.2.m2.3.3.2.6" xref="S3.SS1.p2.2.m2.3.3.3.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.3b"><set id="S3.SS1.p2.2.m2.3.3.3.cmml" xref="S3.SS1.p2.2.m2.3.3.2"><apply id="S3.SS1.p2.2.m2.2.2.1.1.cmml" xref="S3.SS1.p2.2.m2.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.2.m2.2.2.1.1.1.cmml" xref="S3.SS1.p2.2.m2.2.2.1.1">subscript</csymbol><ci id="S3.SS1.p2.2.m2.2.2.1.1.2.cmml" xref="S3.SS1.p2.2.m2.2.2.1.1.2">𝑑</ci><cn type="integer" id="S3.SS1.p2.2.m2.2.2.1.1.3.cmml" xref="S3.SS1.p2.2.m2.2.2.1.1.3">1</cn></apply><ci id="S3.SS1.p2.2.m2.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1">…</ci><apply id="S3.SS1.p2.2.m2.3.3.2.2.cmml" xref="S3.SS1.p2.2.m2.3.3.2.2"><csymbol cd="ambiguous" id="S3.SS1.p2.2.m2.3.3.2.2.1.cmml" xref="S3.SS1.p2.2.m2.3.3.2.2">subscript</csymbol><ci id="S3.SS1.p2.2.m2.3.3.2.2.2.cmml" xref="S3.SS1.p2.2.m2.3.3.2.2.2">𝑑</ci><ci id="S3.SS1.p2.2.m2.3.3.2.2.3.cmml" xref="S3.SS1.p2.2.m2.3.3.2.2.3">𝑛</ci></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.3c">\{d_{1},...,d_{n}\}</annotation></semantics></math>. A federated-learning system defines a distributed machine learning process in which the ML scientists collaboratively train a shared model Mf. However, this process ensures that any ML scientist <math id="S3.SS1.p2.3.m3.1" class="ltx_Math" alttext="s_{i}" display="inline"><semantics id="S3.SS1.p2.3.m3.1a"><msub id="S3.SS1.p2.3.m3.1.1" xref="S3.SS1.p2.3.m3.1.1.cmml"><mi id="S3.SS1.p2.3.m3.1.1.2" xref="S3.SS1.p2.3.m3.1.1.2.cmml">s</mi><mi id="S3.SS1.p2.3.m3.1.1.3" xref="S3.SS1.p2.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.3.m3.1b"><apply id="S3.SS1.p2.3.m3.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.3.m3.1.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.p2.3.m3.1.1.2.cmml" xref="S3.SS1.p2.3.m3.1.1.2">𝑠</ci><ci id="S3.SS1.p2.3.m3.1.1.3.cmml" xref="S3.SS1.p2.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.3.m3.1c">s_{i}</annotation></semantics></math> does not expose its data <math id="S3.SS1.p2.4.m4.1" class="ltx_Math" alttext="d_{i}" display="inline"><semantics id="S3.SS1.p2.4.m4.1a"><msub id="S3.SS1.p2.4.m4.1.1" xref="S3.SS1.p2.4.m4.1.1.cmml"><mi id="S3.SS1.p2.4.m4.1.1.2" xref="S3.SS1.p2.4.m4.1.1.2.cmml">d</mi><mi id="S3.SS1.p2.4.m4.1.1.3" xref="S3.SS1.p2.4.m4.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.4.m4.1b"><apply id="S3.SS1.p2.4.m4.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.4.m4.1.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1">subscript</csymbol><ci id="S3.SS1.p2.4.m4.1.1.2.cmml" xref="S3.SS1.p2.4.m4.1.1.2">𝑑</ci><ci id="S3.SS1.p2.4.m4.1.1.3.cmml" xref="S3.SS1.p2.4.m4.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.4.m4.1c">d_{i}</annotation></semantics></math> to any other scientist <math id="S3.SS1.p2.5.m5.1" class="ltx_Math" alttext="s_{j}" display="inline"><semantics id="S3.SS1.p2.5.m5.1a"><msub id="S3.SS1.p2.5.m5.1.1" xref="S3.SS1.p2.5.m5.1.1.cmml"><mi id="S3.SS1.p2.5.m5.1.1.2" xref="S3.SS1.p2.5.m5.1.1.2.cmml">s</mi><mi id="S3.SS1.p2.5.m5.1.1.3" xref="S3.SS1.p2.5.m5.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.5.m5.1b"><apply id="S3.SS1.p2.5.m5.1.1.cmml" xref="S3.SS1.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.5.m5.1.1.1.cmml" xref="S3.SS1.p2.5.m5.1.1">subscript</csymbol><ci id="S3.SS1.p2.5.m5.1.1.2.cmml" xref="S3.SS1.p2.5.m5.1.1.2">𝑠</ci><ci id="S3.SS1.p2.5.m5.1.1.3.cmml" xref="S3.SS1.p2.5.m5.1.1.3">𝑗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.5.m5.1c">s_{j}</annotation></semantics></math> during the local training process. Each of the data scientists, however, shares its local model <math id="S3.SS1.p2.6.m6.1" class="ltx_Math" alttext="m_{i}" display="inline"><semantics id="S3.SS1.p2.6.m6.1a"><msub id="S3.SS1.p2.6.m6.1.1" xref="S3.SS1.p2.6.m6.1.1.cmml"><mi id="S3.SS1.p2.6.m6.1.1.2" xref="S3.SS1.p2.6.m6.1.1.2.cmml">m</mi><mi id="S3.SS1.p2.6.m6.1.1.3" xref="S3.SS1.p2.6.m6.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.6.m6.1b"><apply id="S3.SS1.p2.6.m6.1.1.cmml" xref="S3.SS1.p2.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.6.m6.1.1.1.cmml" xref="S3.SS1.p2.6.m6.1.1">subscript</csymbol><ci id="S3.SS1.p2.6.m6.1.1.2.cmml" xref="S3.SS1.p2.6.m6.1.1.2">𝑚</ci><ci id="S3.SS1.p2.6.m6.1.1.3.cmml" xref="S3.SS1.p2.6.m6.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.6.m6.1c">m_{i}</annotation></semantics></math> to the server (centralised architecture) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> or on a blockchain ( decentralised architecture) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>. A federating averaging is used for model aggregation to get a shared model Mf that is then sent back to each ML scientist.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para ltx_noindent">
<p id="S3.SS1.p3.1" class="ltx_p">Various improvements are proposed in the literature after the initial design <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>. It includes horizontal and vertical federated learning architectures, federated transfer learning, federated domain adaptation, federated adversarial learning, improving communication protocols and security and making federated learning more personalisable. It is emerging as a promising research topic in machine learning. Interested readers, please refer to the topic reviews <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Differential Privacy in Machine Learning</h3>

<div id="S3.SS2.p1" class="ltx_para ltx_noindent">
<p id="S3.SS2.p1.9" class="ltx_p">Differential privacy (DF) defines a formal assurance of anonymity and indistinguishability in terms of a privacy budget (<math id="S3.SS2.p1.1.m1.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S3.SS2.p1.1.m1.1a"><mi id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><ci id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">\epsilon</annotation></semantics></math>)—the smaller the budget, the stronger the confidence on privacy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>. The topic has its roots in aggregate or adjacent databases. In the case of COVID-19 imaging datasets, each COVID-19 imaging training dataset is a set of image-label pairs for supervised learning. Any two of these datasets are adjacent if they vary in a single entry if one image-label pair is present in one image dataset and absent in the other. In other words, Two databases <math id="S3.SS2.p1.2.m2.1" class="ltx_Math" alttext="X" display="inline"><semantics id="S3.SS2.p1.2.m2.1a"><mi id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml">X</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><ci id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1">𝑋</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">X</annotation></semantics></math> and <math id="S3.SS2.p1.3.m3.1" class="ltx_Math" alttext="Y" display="inline"><semantics id="S3.SS2.p1.3.m3.1a"><mi id="S3.SS2.p1.3.m3.1.1" xref="S3.SS2.p1.3.m3.1.1.cmml">Y</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.3.m3.1b"><ci id="S3.SS2.p1.3.m3.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1">𝑌</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.3.m3.1c">Y</annotation></semantics></math> are neighbours or adjacent if <math id="S3.SS2.p1.4.m4.2" class="ltx_Math" alttext="A(X,Y)=1" display="inline"><semantics id="S3.SS2.p1.4.m4.2a"><mrow id="S3.SS2.p1.4.m4.2.3" xref="S3.SS2.p1.4.m4.2.3.cmml"><mrow id="S3.SS2.p1.4.m4.2.3.2" xref="S3.SS2.p1.4.m4.2.3.2.cmml"><mi id="S3.SS2.p1.4.m4.2.3.2.2" xref="S3.SS2.p1.4.m4.2.3.2.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p1.4.m4.2.3.2.1" xref="S3.SS2.p1.4.m4.2.3.2.1.cmml">​</mo><mrow id="S3.SS2.p1.4.m4.2.3.2.3.2" xref="S3.SS2.p1.4.m4.2.3.2.3.1.cmml"><mo stretchy="false" id="S3.SS2.p1.4.m4.2.3.2.3.2.1" xref="S3.SS2.p1.4.m4.2.3.2.3.1.cmml">(</mo><mi id="S3.SS2.p1.4.m4.1.1" xref="S3.SS2.p1.4.m4.1.1.cmml">X</mi><mo id="S3.SS2.p1.4.m4.2.3.2.3.2.2" xref="S3.SS2.p1.4.m4.2.3.2.3.1.cmml">,</mo><mi id="S3.SS2.p1.4.m4.2.2" xref="S3.SS2.p1.4.m4.2.2.cmml">Y</mi><mo stretchy="false" id="S3.SS2.p1.4.m4.2.3.2.3.2.3" xref="S3.SS2.p1.4.m4.2.3.2.3.1.cmml">)</mo></mrow></mrow><mo id="S3.SS2.p1.4.m4.2.3.1" xref="S3.SS2.p1.4.m4.2.3.1.cmml">=</mo><mn id="S3.SS2.p1.4.m4.2.3.3" xref="S3.SS2.p1.4.m4.2.3.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.4.m4.2b"><apply id="S3.SS2.p1.4.m4.2.3.cmml" xref="S3.SS2.p1.4.m4.2.3"><eq id="S3.SS2.p1.4.m4.2.3.1.cmml" xref="S3.SS2.p1.4.m4.2.3.1"></eq><apply id="S3.SS2.p1.4.m4.2.3.2.cmml" xref="S3.SS2.p1.4.m4.2.3.2"><times id="S3.SS2.p1.4.m4.2.3.2.1.cmml" xref="S3.SS2.p1.4.m4.2.3.2.1"></times><ci id="S3.SS2.p1.4.m4.2.3.2.2.cmml" xref="S3.SS2.p1.4.m4.2.3.2.2">𝐴</ci><interval closure="open" id="S3.SS2.p1.4.m4.2.3.2.3.1.cmml" xref="S3.SS2.p1.4.m4.2.3.2.3.2"><ci id="S3.SS2.p1.4.m4.1.1.cmml" xref="S3.SS2.p1.4.m4.1.1">𝑋</ci><ci id="S3.SS2.p1.4.m4.2.2.cmml" xref="S3.SS2.p1.4.m4.2.2">𝑌</ci></interval></apply><cn type="integer" id="S3.SS2.p1.4.m4.2.3.3.cmml" xref="S3.SS2.p1.4.m4.2.3.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.4.m4.2c">A(X,Y)=1</annotation></semantics></math> where A is the distance. A randomized mechanism <math id="S3.SS2.p1.5.m5.1" class="ltx_Math" alttext="K:D\rightarrow R" display="inline"><semantics id="S3.SS2.p1.5.m5.1a"><mrow id="S3.SS2.p1.5.m5.1.1" xref="S3.SS2.p1.5.m5.1.1.cmml"><mi id="S3.SS2.p1.5.m5.1.1.2" xref="S3.SS2.p1.5.m5.1.1.2.cmml">K</mi><mo lspace="0.278em" rspace="0.278em" id="S3.SS2.p1.5.m5.1.1.1" xref="S3.SS2.p1.5.m5.1.1.1.cmml">:</mo><mrow id="S3.SS2.p1.5.m5.1.1.3" xref="S3.SS2.p1.5.m5.1.1.3.cmml"><mi id="S3.SS2.p1.5.m5.1.1.3.2" xref="S3.SS2.p1.5.m5.1.1.3.2.cmml">D</mi><mo stretchy="false" id="S3.SS2.p1.5.m5.1.1.3.1" xref="S3.SS2.p1.5.m5.1.1.3.1.cmml">→</mo><mi id="S3.SS2.p1.5.m5.1.1.3.3" xref="S3.SS2.p1.5.m5.1.1.3.3.cmml">R</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.5.m5.1b"><apply id="S3.SS2.p1.5.m5.1.1.cmml" xref="S3.SS2.p1.5.m5.1.1"><ci id="S3.SS2.p1.5.m5.1.1.1.cmml" xref="S3.SS2.p1.5.m5.1.1.1">:</ci><ci id="S3.SS2.p1.5.m5.1.1.2.cmml" xref="S3.SS2.p1.5.m5.1.1.2">𝐾</ci><apply id="S3.SS2.p1.5.m5.1.1.3.cmml" xref="S3.SS2.p1.5.m5.1.1.3"><ci id="S3.SS2.p1.5.m5.1.1.3.1.cmml" xref="S3.SS2.p1.5.m5.1.1.3.1">→</ci><ci id="S3.SS2.p1.5.m5.1.1.3.2.cmml" xref="S3.SS2.p1.5.m5.1.1.3.2">𝐷</ci><ci id="S3.SS2.p1.5.m5.1.1.3.3.cmml" xref="S3.SS2.p1.5.m5.1.1.3.3">𝑅</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.5.m5.1c">K:D\rightarrow R</annotation></semantics></math> with
domain D and range R preserves (<math id="S3.SS2.p1.6.m6.2" class="ltx_Math" alttext="\epsilon,\delta" display="inline"><semantics id="S3.SS2.p1.6.m6.2a"><mrow id="S3.SS2.p1.6.m6.2.3.2" xref="S3.SS2.p1.6.m6.2.3.1.cmml"><mi id="S3.SS2.p1.6.m6.1.1" xref="S3.SS2.p1.6.m6.1.1.cmml">ϵ</mi><mo id="S3.SS2.p1.6.m6.2.3.2.1" xref="S3.SS2.p1.6.m6.2.3.1.cmml">,</mo><mi id="S3.SS2.p1.6.m6.2.2" xref="S3.SS2.p1.6.m6.2.2.cmml">δ</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.6.m6.2b"><list id="S3.SS2.p1.6.m6.2.3.1.cmml" xref="S3.SS2.p1.6.m6.2.3.2"><ci id="S3.SS2.p1.6.m6.1.1.cmml" xref="S3.SS2.p1.6.m6.1.1">italic-ϵ</ci><ci id="S3.SS2.p1.6.m6.2.2.cmml" xref="S3.SS2.p1.6.m6.2.2">𝛿</ci></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.6.m6.2c">\epsilon,\delta</annotation></semantics></math> differential privacy, if for any pair of adjacent databases <math id="S3.SS2.p1.7.m7.2" class="ltx_Math" alttext="(X,Y)" display="inline"><semantics id="S3.SS2.p1.7.m7.2a"><mrow id="S3.SS2.p1.7.m7.2.3.2" xref="S3.SS2.p1.7.m7.2.3.1.cmml"><mo stretchy="false" id="S3.SS2.p1.7.m7.2.3.2.1" xref="S3.SS2.p1.7.m7.2.3.1.cmml">(</mo><mi id="S3.SS2.p1.7.m7.1.1" xref="S3.SS2.p1.7.m7.1.1.cmml">X</mi><mo id="S3.SS2.p1.7.m7.2.3.2.2" xref="S3.SS2.p1.7.m7.2.3.1.cmml">,</mo><mi id="S3.SS2.p1.7.m7.2.2" xref="S3.SS2.p1.7.m7.2.2.cmml">Y</mi><mo stretchy="false" id="S3.SS2.p1.7.m7.2.3.2.3" xref="S3.SS2.p1.7.m7.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.7.m7.2b"><interval closure="open" id="S3.SS2.p1.7.m7.2.3.1.cmml" xref="S3.SS2.p1.7.m7.2.3.2"><ci id="S3.SS2.p1.7.m7.1.1.cmml" xref="S3.SS2.p1.7.m7.1.1">𝑋</ci><ci id="S3.SS2.p1.7.m7.2.2.cmml" xref="S3.SS2.p1.7.m7.2.2">𝑌</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.7.m7.2c">(X,Y)</annotation></semantics></math> belonging to <math id="S3.SS2.p1.8.m8.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S3.SS2.p1.8.m8.1a"><mi id="S3.SS2.p1.8.m8.1.1" xref="S3.SS2.p1.8.m8.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.8.m8.1b"><ci id="S3.SS2.p1.8.m8.1.1.cmml" xref="S3.SS2.p1.8.m8.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.8.m8.1c">D</annotation></semantics></math> and set S of possible outputs:<math id="S3.SS2.p1.9.m9.4" class="ltx_Math" alttext="Pr[K(X)\in S]\leq\epsilon Pr[K(Y)\in S]+\delta" display="inline"><semantics id="S3.SS2.p1.9.m9.4a"><mrow id="S3.SS2.p1.9.m9.4.4" xref="S3.SS2.p1.9.m9.4.4.cmml"><mrow id="S3.SS2.p1.9.m9.3.3.1" xref="S3.SS2.p1.9.m9.3.3.1.cmml"><mi id="S3.SS2.p1.9.m9.3.3.1.3" xref="S3.SS2.p1.9.m9.3.3.1.3.cmml">P</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p1.9.m9.3.3.1.2" xref="S3.SS2.p1.9.m9.3.3.1.2.cmml">​</mo><mi id="S3.SS2.p1.9.m9.3.3.1.4" xref="S3.SS2.p1.9.m9.3.3.1.4.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p1.9.m9.3.3.1.2a" xref="S3.SS2.p1.9.m9.3.3.1.2.cmml">​</mo><mrow id="S3.SS2.p1.9.m9.3.3.1.1.1" xref="S3.SS2.p1.9.m9.3.3.1.1.2.cmml"><mo stretchy="false" id="S3.SS2.p1.9.m9.3.3.1.1.1.2" xref="S3.SS2.p1.9.m9.3.3.1.1.2.1.cmml">[</mo><mrow id="S3.SS2.p1.9.m9.3.3.1.1.1.1" xref="S3.SS2.p1.9.m9.3.3.1.1.1.1.cmml"><mrow id="S3.SS2.p1.9.m9.3.3.1.1.1.1.2" xref="S3.SS2.p1.9.m9.3.3.1.1.1.1.2.cmml"><mi id="S3.SS2.p1.9.m9.3.3.1.1.1.1.2.2" xref="S3.SS2.p1.9.m9.3.3.1.1.1.1.2.2.cmml">K</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p1.9.m9.3.3.1.1.1.1.2.1" xref="S3.SS2.p1.9.m9.3.3.1.1.1.1.2.1.cmml">​</mo><mrow id="S3.SS2.p1.9.m9.3.3.1.1.1.1.2.3.2" xref="S3.SS2.p1.9.m9.3.3.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.SS2.p1.9.m9.3.3.1.1.1.1.2.3.2.1" xref="S3.SS2.p1.9.m9.3.3.1.1.1.1.2.cmml">(</mo><mi id="S3.SS2.p1.9.m9.1.1" xref="S3.SS2.p1.9.m9.1.1.cmml">X</mi><mo stretchy="false" id="S3.SS2.p1.9.m9.3.3.1.1.1.1.2.3.2.2" xref="S3.SS2.p1.9.m9.3.3.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S3.SS2.p1.9.m9.3.3.1.1.1.1.1" xref="S3.SS2.p1.9.m9.3.3.1.1.1.1.1.cmml">∈</mo><mi id="S3.SS2.p1.9.m9.3.3.1.1.1.1.3" xref="S3.SS2.p1.9.m9.3.3.1.1.1.1.3.cmml">S</mi></mrow><mo stretchy="false" id="S3.SS2.p1.9.m9.3.3.1.1.1.3" xref="S3.SS2.p1.9.m9.3.3.1.1.2.1.cmml">]</mo></mrow></mrow><mo id="S3.SS2.p1.9.m9.4.4.3" xref="S3.SS2.p1.9.m9.4.4.3.cmml">≤</mo><mrow id="S3.SS2.p1.9.m9.4.4.2" xref="S3.SS2.p1.9.m9.4.4.2.cmml"><mrow id="S3.SS2.p1.9.m9.4.4.2.1" xref="S3.SS2.p1.9.m9.4.4.2.1.cmml"><mi id="S3.SS2.p1.9.m9.4.4.2.1.3" xref="S3.SS2.p1.9.m9.4.4.2.1.3.cmml">ϵ</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p1.9.m9.4.4.2.1.2" xref="S3.SS2.p1.9.m9.4.4.2.1.2.cmml">​</mo><mi id="S3.SS2.p1.9.m9.4.4.2.1.4" xref="S3.SS2.p1.9.m9.4.4.2.1.4.cmml">P</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p1.9.m9.4.4.2.1.2a" xref="S3.SS2.p1.9.m9.4.4.2.1.2.cmml">​</mo><mi id="S3.SS2.p1.9.m9.4.4.2.1.5" xref="S3.SS2.p1.9.m9.4.4.2.1.5.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p1.9.m9.4.4.2.1.2b" xref="S3.SS2.p1.9.m9.4.4.2.1.2.cmml">​</mo><mrow id="S3.SS2.p1.9.m9.4.4.2.1.1.1" xref="S3.SS2.p1.9.m9.4.4.2.1.1.2.cmml"><mo stretchy="false" id="S3.SS2.p1.9.m9.4.4.2.1.1.1.2" xref="S3.SS2.p1.9.m9.4.4.2.1.1.2.1.cmml">[</mo><mrow id="S3.SS2.p1.9.m9.4.4.2.1.1.1.1" xref="S3.SS2.p1.9.m9.4.4.2.1.1.1.1.cmml"><mrow id="S3.SS2.p1.9.m9.4.4.2.1.1.1.1.2" xref="S3.SS2.p1.9.m9.4.4.2.1.1.1.1.2.cmml"><mi id="S3.SS2.p1.9.m9.4.4.2.1.1.1.1.2.2" xref="S3.SS2.p1.9.m9.4.4.2.1.1.1.1.2.2.cmml">K</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p1.9.m9.4.4.2.1.1.1.1.2.1" xref="S3.SS2.p1.9.m9.4.4.2.1.1.1.1.2.1.cmml">​</mo><mrow id="S3.SS2.p1.9.m9.4.4.2.1.1.1.1.2.3.2" xref="S3.SS2.p1.9.m9.4.4.2.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.SS2.p1.9.m9.4.4.2.1.1.1.1.2.3.2.1" xref="S3.SS2.p1.9.m9.4.4.2.1.1.1.1.2.cmml">(</mo><mi id="S3.SS2.p1.9.m9.2.2" xref="S3.SS2.p1.9.m9.2.2.cmml">Y</mi><mo stretchy="false" id="S3.SS2.p1.9.m9.4.4.2.1.1.1.1.2.3.2.2" xref="S3.SS2.p1.9.m9.4.4.2.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S3.SS2.p1.9.m9.4.4.2.1.1.1.1.1" xref="S3.SS2.p1.9.m9.4.4.2.1.1.1.1.1.cmml">∈</mo><mi id="S3.SS2.p1.9.m9.4.4.2.1.1.1.1.3" xref="S3.SS2.p1.9.m9.4.4.2.1.1.1.1.3.cmml">S</mi></mrow><mo stretchy="false" id="S3.SS2.p1.9.m9.4.4.2.1.1.1.3" xref="S3.SS2.p1.9.m9.4.4.2.1.1.2.1.cmml">]</mo></mrow></mrow><mo id="S3.SS2.p1.9.m9.4.4.2.2" xref="S3.SS2.p1.9.m9.4.4.2.2.cmml">+</mo><mi id="S3.SS2.p1.9.m9.4.4.2.3" xref="S3.SS2.p1.9.m9.4.4.2.3.cmml">δ</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.9.m9.4b"><apply id="S3.SS2.p1.9.m9.4.4.cmml" xref="S3.SS2.p1.9.m9.4.4"><leq id="S3.SS2.p1.9.m9.4.4.3.cmml" xref="S3.SS2.p1.9.m9.4.4.3"></leq><apply id="S3.SS2.p1.9.m9.3.3.1.cmml" xref="S3.SS2.p1.9.m9.3.3.1"><times id="S3.SS2.p1.9.m9.3.3.1.2.cmml" xref="S3.SS2.p1.9.m9.3.3.1.2"></times><ci id="S3.SS2.p1.9.m9.3.3.1.3.cmml" xref="S3.SS2.p1.9.m9.3.3.1.3">𝑃</ci><ci id="S3.SS2.p1.9.m9.3.3.1.4.cmml" xref="S3.SS2.p1.9.m9.3.3.1.4">𝑟</ci><apply id="S3.SS2.p1.9.m9.3.3.1.1.2.cmml" xref="S3.SS2.p1.9.m9.3.3.1.1.1"><csymbol cd="latexml" id="S3.SS2.p1.9.m9.3.3.1.1.2.1.cmml" xref="S3.SS2.p1.9.m9.3.3.1.1.1.2">delimited-[]</csymbol><apply id="S3.SS2.p1.9.m9.3.3.1.1.1.1.cmml" xref="S3.SS2.p1.9.m9.3.3.1.1.1.1"><in id="S3.SS2.p1.9.m9.3.3.1.1.1.1.1.cmml" xref="S3.SS2.p1.9.m9.3.3.1.1.1.1.1"></in><apply id="S3.SS2.p1.9.m9.3.3.1.1.1.1.2.cmml" xref="S3.SS2.p1.9.m9.3.3.1.1.1.1.2"><times id="S3.SS2.p1.9.m9.3.3.1.1.1.1.2.1.cmml" xref="S3.SS2.p1.9.m9.3.3.1.1.1.1.2.1"></times><ci id="S3.SS2.p1.9.m9.3.3.1.1.1.1.2.2.cmml" xref="S3.SS2.p1.9.m9.3.3.1.1.1.1.2.2">𝐾</ci><ci id="S3.SS2.p1.9.m9.1.1.cmml" xref="S3.SS2.p1.9.m9.1.1">𝑋</ci></apply><ci id="S3.SS2.p1.9.m9.3.3.1.1.1.1.3.cmml" xref="S3.SS2.p1.9.m9.3.3.1.1.1.1.3">𝑆</ci></apply></apply></apply><apply id="S3.SS2.p1.9.m9.4.4.2.cmml" xref="S3.SS2.p1.9.m9.4.4.2"><plus id="S3.SS2.p1.9.m9.4.4.2.2.cmml" xref="S3.SS2.p1.9.m9.4.4.2.2"></plus><apply id="S3.SS2.p1.9.m9.4.4.2.1.cmml" xref="S3.SS2.p1.9.m9.4.4.2.1"><times id="S3.SS2.p1.9.m9.4.4.2.1.2.cmml" xref="S3.SS2.p1.9.m9.4.4.2.1.2"></times><ci id="S3.SS2.p1.9.m9.4.4.2.1.3.cmml" xref="S3.SS2.p1.9.m9.4.4.2.1.3">italic-ϵ</ci><ci id="S3.SS2.p1.9.m9.4.4.2.1.4.cmml" xref="S3.SS2.p1.9.m9.4.4.2.1.4">𝑃</ci><ci id="S3.SS2.p1.9.m9.4.4.2.1.5.cmml" xref="S3.SS2.p1.9.m9.4.4.2.1.5">𝑟</ci><apply id="S3.SS2.p1.9.m9.4.4.2.1.1.2.cmml" xref="S3.SS2.p1.9.m9.4.4.2.1.1.1"><csymbol cd="latexml" id="S3.SS2.p1.9.m9.4.4.2.1.1.2.1.cmml" xref="S3.SS2.p1.9.m9.4.4.2.1.1.1.2">delimited-[]</csymbol><apply id="S3.SS2.p1.9.m9.4.4.2.1.1.1.1.cmml" xref="S3.SS2.p1.9.m9.4.4.2.1.1.1.1"><in id="S3.SS2.p1.9.m9.4.4.2.1.1.1.1.1.cmml" xref="S3.SS2.p1.9.m9.4.4.2.1.1.1.1.1"></in><apply id="S3.SS2.p1.9.m9.4.4.2.1.1.1.1.2.cmml" xref="S3.SS2.p1.9.m9.4.4.2.1.1.1.1.2"><times id="S3.SS2.p1.9.m9.4.4.2.1.1.1.1.2.1.cmml" xref="S3.SS2.p1.9.m9.4.4.2.1.1.1.1.2.1"></times><ci id="S3.SS2.p1.9.m9.4.4.2.1.1.1.1.2.2.cmml" xref="S3.SS2.p1.9.m9.4.4.2.1.1.1.1.2.2">𝐾</ci><ci id="S3.SS2.p1.9.m9.2.2.cmml" xref="S3.SS2.p1.9.m9.2.2">𝑌</ci></apply><ci id="S3.SS2.p1.9.m9.4.4.2.1.1.1.1.3.cmml" xref="S3.SS2.p1.9.m9.4.4.2.1.1.1.1.3">𝑆</ci></apply></apply></apply><ci id="S3.SS2.p1.9.m9.4.4.2.3.cmml" xref="S3.SS2.p1.9.m9.4.4.2.3">𝛿</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.9.m9.4c">Pr[K(X)\in S]\leq\epsilon Pr[K(Y)\in S]+\delta</annotation></semantics></math>.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para ltx_noindent">
<p id="S3.SS2.p2.5" class="ltx_p">A randomised mechanism like Gaussian mechanism(GM) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>approximates a real-valued function <math id="S3.SS2.p2.1.m1.1" class="ltx_Math" alttext="F" display="inline"><semantics id="S3.SS2.p2.1.m1.1a"><mi id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml">F</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><ci id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1">𝐹</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">F</annotation></semantics></math> for these neighbouring datasets, and differential privacy can be enforced by adding noise to the model to the scale depending on the sensitivity of this function function <math id="S3.SS2.p2.2.m2.1" class="ltx_Math" alttext="F" display="inline"><semantics id="S3.SS2.p2.2.m2.1a"><mi id="S3.SS2.p2.2.m2.1.1" xref="S3.SS2.p2.2.m2.1.1.cmml">F</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m2.1b"><ci id="S3.SS2.p2.2.m2.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1">𝐹</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.m2.1c">F</annotation></semantics></math>. The global sensitivity <math id="S3.SS2.p2.3.m3.1" class="ltx_Math" alttext="GS" display="inline"><semantics id="S3.SS2.p2.3.m3.1a"><mrow id="S3.SS2.p2.3.m3.1.1" xref="S3.SS2.p2.3.m3.1.1.cmml"><mi id="S3.SS2.p2.3.m3.1.1.2" xref="S3.SS2.p2.3.m3.1.1.2.cmml">G</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p2.3.m3.1.1.1" xref="S3.SS2.p2.3.m3.1.1.1.cmml">​</mo><mi id="S3.SS2.p2.3.m3.1.1.3" xref="S3.SS2.p2.3.m3.1.1.3.cmml">S</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.3.m3.1b"><apply id="S3.SS2.p2.3.m3.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1"><times id="S3.SS2.p2.3.m3.1.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1.1"></times><ci id="S3.SS2.p2.3.m3.1.1.2.cmml" xref="S3.SS2.p2.3.m3.1.1.2">𝐺</ci><ci id="S3.SS2.p2.3.m3.1.1.3.cmml" xref="S3.SS2.p2.3.m3.1.1.3">𝑆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.3.m3.1c">GS</annotation></semantics></math> of a function <math id="S3.SS2.p2.4.m4.1" class="ltx_Math" alttext="F" display="inline"><semantics id="S3.SS2.p2.4.m4.1a"><mi id="S3.SS2.p2.4.m4.1.1" xref="S3.SS2.p2.4.m4.1.1.cmml">F</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.4.m4.1b"><ci id="S3.SS2.p2.4.m4.1.1.cmml" xref="S3.SS2.p2.4.m4.1.1">𝐹</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.4.m4.1c">F</annotation></semantics></math> is defined as: <math id="S3.SS2.p2.5.m5.7" class="ltx_Math" alttext="GS_{F}=max_{X,Y:D(X,Y)=1}|F(X)-F(Y)|" display="inline"><semantics id="S3.SS2.p2.5.m5.7a"><mrow id="S3.SS2.p2.5.m5.7.7" xref="S3.SS2.p2.5.m5.7.7.cmml"><mrow id="S3.SS2.p2.5.m5.7.7.3" xref="S3.SS2.p2.5.m5.7.7.3.cmml"><mi id="S3.SS2.p2.5.m5.7.7.3.2" xref="S3.SS2.p2.5.m5.7.7.3.2.cmml">G</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p2.5.m5.7.7.3.1" xref="S3.SS2.p2.5.m5.7.7.3.1.cmml">​</mo><msub id="S3.SS2.p2.5.m5.7.7.3.3" xref="S3.SS2.p2.5.m5.7.7.3.3.cmml"><mi id="S3.SS2.p2.5.m5.7.7.3.3.2" xref="S3.SS2.p2.5.m5.7.7.3.3.2.cmml">S</mi><mi id="S3.SS2.p2.5.m5.7.7.3.3.3" xref="S3.SS2.p2.5.m5.7.7.3.3.3.cmml">F</mi></msub></mrow><mo id="S3.SS2.p2.5.m5.7.7.2" xref="S3.SS2.p2.5.m5.7.7.2.cmml">=</mo><mrow id="S3.SS2.p2.5.m5.7.7.1" xref="S3.SS2.p2.5.m5.7.7.1.cmml"><mi id="S3.SS2.p2.5.m5.7.7.1.3" xref="S3.SS2.p2.5.m5.7.7.1.3.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p2.5.m5.7.7.1.2" xref="S3.SS2.p2.5.m5.7.7.1.2.cmml">​</mo><mi id="S3.SS2.p2.5.m5.7.7.1.4" xref="S3.SS2.p2.5.m5.7.7.1.4.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p2.5.m5.7.7.1.2a" xref="S3.SS2.p2.5.m5.7.7.1.2.cmml">​</mo><msub id="S3.SS2.p2.5.m5.7.7.1.5" xref="S3.SS2.p2.5.m5.7.7.1.5.cmml"><mi id="S3.SS2.p2.5.m5.7.7.1.5.2" xref="S3.SS2.p2.5.m5.7.7.1.5.2.cmml">x</mi><mrow id="S3.SS2.p2.5.m5.4.4.4" xref="S3.SS2.p2.5.m5.4.4.4.cmml"><mrow id="S3.SS2.p2.5.m5.4.4.4.6.2" xref="S3.SS2.p2.5.m5.4.4.4.6.1.cmml"><mi id="S3.SS2.p2.5.m5.1.1.1.1" xref="S3.SS2.p2.5.m5.1.1.1.1.cmml">X</mi><mo id="S3.SS2.p2.5.m5.4.4.4.6.2.1" xref="S3.SS2.p2.5.m5.4.4.4.6.1.cmml">,</mo><mi id="S3.SS2.p2.5.m5.2.2.2.2" xref="S3.SS2.p2.5.m5.2.2.2.2.cmml">Y</mi></mrow><mo lspace="0.278em" rspace="0.278em" id="S3.SS2.p2.5.m5.4.4.4.5" xref="S3.SS2.p2.5.m5.4.4.4.5.cmml">:</mo><mrow id="S3.SS2.p2.5.m5.4.4.4.7" xref="S3.SS2.p2.5.m5.4.4.4.7.cmml"><mrow id="S3.SS2.p2.5.m5.4.4.4.7.2" xref="S3.SS2.p2.5.m5.4.4.4.7.2.cmml"><mi id="S3.SS2.p2.5.m5.4.4.4.7.2.2" xref="S3.SS2.p2.5.m5.4.4.4.7.2.2.cmml">D</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p2.5.m5.4.4.4.7.2.1" xref="S3.SS2.p2.5.m5.4.4.4.7.2.1.cmml">​</mo><mrow id="S3.SS2.p2.5.m5.4.4.4.7.2.3.2" xref="S3.SS2.p2.5.m5.4.4.4.7.2.3.1.cmml"><mo stretchy="false" id="S3.SS2.p2.5.m5.4.4.4.7.2.3.2.1" xref="S3.SS2.p2.5.m5.4.4.4.7.2.3.1.cmml">(</mo><mi id="S3.SS2.p2.5.m5.3.3.3.3" xref="S3.SS2.p2.5.m5.3.3.3.3.cmml">X</mi><mo id="S3.SS2.p2.5.m5.4.4.4.7.2.3.2.2" xref="S3.SS2.p2.5.m5.4.4.4.7.2.3.1.cmml">,</mo><mi id="S3.SS2.p2.5.m5.4.4.4.4" xref="S3.SS2.p2.5.m5.4.4.4.4.cmml">Y</mi><mo stretchy="false" id="S3.SS2.p2.5.m5.4.4.4.7.2.3.2.3" xref="S3.SS2.p2.5.m5.4.4.4.7.2.3.1.cmml">)</mo></mrow></mrow><mo id="S3.SS2.p2.5.m5.4.4.4.7.1" xref="S3.SS2.p2.5.m5.4.4.4.7.1.cmml">=</mo><mn id="S3.SS2.p2.5.m5.4.4.4.7.3" xref="S3.SS2.p2.5.m5.4.4.4.7.3.cmml">1</mn></mrow></mrow></msub><mo lspace="0em" rspace="0em" id="S3.SS2.p2.5.m5.7.7.1.2b" xref="S3.SS2.p2.5.m5.7.7.1.2.cmml">​</mo><mrow id="S3.SS2.p2.5.m5.7.7.1.1.1" xref="S3.SS2.p2.5.m5.7.7.1.1.2.cmml"><mo stretchy="false" id="S3.SS2.p2.5.m5.7.7.1.1.1.2" xref="S3.SS2.p2.5.m5.7.7.1.1.2.1.cmml">|</mo><mrow id="S3.SS2.p2.5.m5.7.7.1.1.1.1" xref="S3.SS2.p2.5.m5.7.7.1.1.1.1.cmml"><mrow id="S3.SS2.p2.5.m5.7.7.1.1.1.1.2" xref="S3.SS2.p2.5.m5.7.7.1.1.1.1.2.cmml"><mi id="S3.SS2.p2.5.m5.7.7.1.1.1.1.2.2" xref="S3.SS2.p2.5.m5.7.7.1.1.1.1.2.2.cmml">F</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p2.5.m5.7.7.1.1.1.1.2.1" xref="S3.SS2.p2.5.m5.7.7.1.1.1.1.2.1.cmml">​</mo><mrow id="S3.SS2.p2.5.m5.7.7.1.1.1.1.2.3.2" xref="S3.SS2.p2.5.m5.7.7.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.SS2.p2.5.m5.7.7.1.1.1.1.2.3.2.1" xref="S3.SS2.p2.5.m5.7.7.1.1.1.1.2.cmml">(</mo><mi id="S3.SS2.p2.5.m5.5.5" xref="S3.SS2.p2.5.m5.5.5.cmml">X</mi><mo stretchy="false" id="S3.SS2.p2.5.m5.7.7.1.1.1.1.2.3.2.2" xref="S3.SS2.p2.5.m5.7.7.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S3.SS2.p2.5.m5.7.7.1.1.1.1.1" xref="S3.SS2.p2.5.m5.7.7.1.1.1.1.1.cmml">−</mo><mrow id="S3.SS2.p2.5.m5.7.7.1.1.1.1.3" xref="S3.SS2.p2.5.m5.7.7.1.1.1.1.3.cmml"><mi id="S3.SS2.p2.5.m5.7.7.1.1.1.1.3.2" xref="S3.SS2.p2.5.m5.7.7.1.1.1.1.3.2.cmml">F</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p2.5.m5.7.7.1.1.1.1.3.1" xref="S3.SS2.p2.5.m5.7.7.1.1.1.1.3.1.cmml">​</mo><mrow id="S3.SS2.p2.5.m5.7.7.1.1.1.1.3.3.2" xref="S3.SS2.p2.5.m5.7.7.1.1.1.1.3.cmml"><mo stretchy="false" id="S3.SS2.p2.5.m5.7.7.1.1.1.1.3.3.2.1" xref="S3.SS2.p2.5.m5.7.7.1.1.1.1.3.cmml">(</mo><mi id="S3.SS2.p2.5.m5.6.6" xref="S3.SS2.p2.5.m5.6.6.cmml">Y</mi><mo stretchy="false" id="S3.SS2.p2.5.m5.7.7.1.1.1.1.3.3.2.2" xref="S3.SS2.p2.5.m5.7.7.1.1.1.1.3.cmml">)</mo></mrow></mrow></mrow><mo stretchy="false" id="S3.SS2.p2.5.m5.7.7.1.1.1.3" xref="S3.SS2.p2.5.m5.7.7.1.1.2.1.cmml">|</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.5.m5.7b"><apply id="S3.SS2.p2.5.m5.7.7.cmml" xref="S3.SS2.p2.5.m5.7.7"><eq id="S3.SS2.p2.5.m5.7.7.2.cmml" xref="S3.SS2.p2.5.m5.7.7.2"></eq><apply id="S3.SS2.p2.5.m5.7.7.3.cmml" xref="S3.SS2.p2.5.m5.7.7.3"><times id="S3.SS2.p2.5.m5.7.7.3.1.cmml" xref="S3.SS2.p2.5.m5.7.7.3.1"></times><ci id="S3.SS2.p2.5.m5.7.7.3.2.cmml" xref="S3.SS2.p2.5.m5.7.7.3.2">𝐺</ci><apply id="S3.SS2.p2.5.m5.7.7.3.3.cmml" xref="S3.SS2.p2.5.m5.7.7.3.3"><csymbol cd="ambiguous" id="S3.SS2.p2.5.m5.7.7.3.3.1.cmml" xref="S3.SS2.p2.5.m5.7.7.3.3">subscript</csymbol><ci id="S3.SS2.p2.5.m5.7.7.3.3.2.cmml" xref="S3.SS2.p2.5.m5.7.7.3.3.2">𝑆</ci><ci id="S3.SS2.p2.5.m5.7.7.3.3.3.cmml" xref="S3.SS2.p2.5.m5.7.7.3.3.3">𝐹</ci></apply></apply><apply id="S3.SS2.p2.5.m5.7.7.1.cmml" xref="S3.SS2.p2.5.m5.7.7.1"><times id="S3.SS2.p2.5.m5.7.7.1.2.cmml" xref="S3.SS2.p2.5.m5.7.7.1.2"></times><ci id="S3.SS2.p2.5.m5.7.7.1.3.cmml" xref="S3.SS2.p2.5.m5.7.7.1.3">𝑚</ci><ci id="S3.SS2.p2.5.m5.7.7.1.4.cmml" xref="S3.SS2.p2.5.m5.7.7.1.4">𝑎</ci><apply id="S3.SS2.p2.5.m5.7.7.1.5.cmml" xref="S3.SS2.p2.5.m5.7.7.1.5"><csymbol cd="ambiguous" id="S3.SS2.p2.5.m5.7.7.1.5.1.cmml" xref="S3.SS2.p2.5.m5.7.7.1.5">subscript</csymbol><ci id="S3.SS2.p2.5.m5.7.7.1.5.2.cmml" xref="S3.SS2.p2.5.m5.7.7.1.5.2">𝑥</ci><apply id="S3.SS2.p2.5.m5.4.4.4.cmml" xref="S3.SS2.p2.5.m5.4.4.4"><ci id="S3.SS2.p2.5.m5.4.4.4.5.cmml" xref="S3.SS2.p2.5.m5.4.4.4.5">:</ci><list id="S3.SS2.p2.5.m5.4.4.4.6.1.cmml" xref="S3.SS2.p2.5.m5.4.4.4.6.2"><ci id="S3.SS2.p2.5.m5.1.1.1.1.cmml" xref="S3.SS2.p2.5.m5.1.1.1.1">𝑋</ci><ci id="S3.SS2.p2.5.m5.2.2.2.2.cmml" xref="S3.SS2.p2.5.m5.2.2.2.2">𝑌</ci></list><apply id="S3.SS2.p2.5.m5.4.4.4.7.cmml" xref="S3.SS2.p2.5.m5.4.4.4.7"><eq id="S3.SS2.p2.5.m5.4.4.4.7.1.cmml" xref="S3.SS2.p2.5.m5.4.4.4.7.1"></eq><apply id="S3.SS2.p2.5.m5.4.4.4.7.2.cmml" xref="S3.SS2.p2.5.m5.4.4.4.7.2"><times id="S3.SS2.p2.5.m5.4.4.4.7.2.1.cmml" xref="S3.SS2.p2.5.m5.4.4.4.7.2.1"></times><ci id="S3.SS2.p2.5.m5.4.4.4.7.2.2.cmml" xref="S3.SS2.p2.5.m5.4.4.4.7.2.2">𝐷</ci><interval closure="open" id="S3.SS2.p2.5.m5.4.4.4.7.2.3.1.cmml" xref="S3.SS2.p2.5.m5.4.4.4.7.2.3.2"><ci id="S3.SS2.p2.5.m5.3.3.3.3.cmml" xref="S3.SS2.p2.5.m5.3.3.3.3">𝑋</ci><ci id="S3.SS2.p2.5.m5.4.4.4.4.cmml" xref="S3.SS2.p2.5.m5.4.4.4.4">𝑌</ci></interval></apply><cn type="integer" id="S3.SS2.p2.5.m5.4.4.4.7.3.cmml" xref="S3.SS2.p2.5.m5.4.4.4.7.3">1</cn></apply></apply></apply><apply id="S3.SS2.p2.5.m5.7.7.1.1.2.cmml" xref="S3.SS2.p2.5.m5.7.7.1.1.1"><abs id="S3.SS2.p2.5.m5.7.7.1.1.2.1.cmml" xref="S3.SS2.p2.5.m5.7.7.1.1.1.2"></abs><apply id="S3.SS2.p2.5.m5.7.7.1.1.1.1.cmml" xref="S3.SS2.p2.5.m5.7.7.1.1.1.1"><minus id="S3.SS2.p2.5.m5.7.7.1.1.1.1.1.cmml" xref="S3.SS2.p2.5.m5.7.7.1.1.1.1.1"></minus><apply id="S3.SS2.p2.5.m5.7.7.1.1.1.1.2.cmml" xref="S3.SS2.p2.5.m5.7.7.1.1.1.1.2"><times id="S3.SS2.p2.5.m5.7.7.1.1.1.1.2.1.cmml" xref="S3.SS2.p2.5.m5.7.7.1.1.1.1.2.1"></times><ci id="S3.SS2.p2.5.m5.7.7.1.1.1.1.2.2.cmml" xref="S3.SS2.p2.5.m5.7.7.1.1.1.1.2.2">𝐹</ci><ci id="S3.SS2.p2.5.m5.5.5.cmml" xref="S3.SS2.p2.5.m5.5.5">𝑋</ci></apply><apply id="S3.SS2.p2.5.m5.7.7.1.1.1.1.3.cmml" xref="S3.SS2.p2.5.m5.7.7.1.1.1.1.3"><times id="S3.SS2.p2.5.m5.7.7.1.1.1.1.3.1.cmml" xref="S3.SS2.p2.5.m5.7.7.1.1.1.1.3.1"></times><ci id="S3.SS2.p2.5.m5.7.7.1.1.1.1.3.2.cmml" xref="S3.SS2.p2.5.m5.7.7.1.1.1.1.3.2">𝐹</ci><ci id="S3.SS2.p2.5.m5.6.6.cmml" xref="S3.SS2.p2.5.m5.6.6">𝑌</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.5.m5.7c">GS_{F}=max_{X,Y:D(X,Y)=1}|F(X)-F(Y)|</annotation></semantics></math>.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para ltx_noindent">
<p id="S3.SS2.p3.2" class="ltx_p">DF provides a mathematically provable guarantee of privacy protection against a wide range of privacy attacks (include differencing attack, linkage attacks, and reconstruction attacks), Decreasing in epsilon leads to a decrease inaccuracy. <math id="S3.SS2.p3.1.m1.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S3.SS2.p3.1.m1.1a"><mi id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b"><ci id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">\epsilon</annotation></semantics></math> is a metric of privacy loss at a differentially change in data (adding, removing one entry). The smaller the value is, the better privacy protection while accuracy is defined to be the closeness of the output of DP algorithms to pure production. <math id="S3.SS2.p3.2.m2.1" class="ltx_Math" alttext="F(X)" display="inline"><semantics id="S3.SS2.p3.2.m2.1a"><mrow id="S3.SS2.p3.2.m2.1.2" xref="S3.SS2.p3.2.m2.1.2.cmml"><mi id="S3.SS2.p3.2.m2.1.2.2" xref="S3.SS2.p3.2.m2.1.2.2.cmml">F</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.2.m2.1.2.1" xref="S3.SS2.p3.2.m2.1.2.1.cmml">​</mo><mrow id="S3.SS2.p3.2.m2.1.2.3.2" xref="S3.SS2.p3.2.m2.1.2.cmml"><mo stretchy="false" id="S3.SS2.p3.2.m2.1.2.3.2.1" xref="S3.SS2.p3.2.m2.1.2.cmml">(</mo><mi id="S3.SS2.p3.2.m2.1.1" xref="S3.SS2.p3.2.m2.1.1.cmml">X</mi><mo stretchy="false" id="S3.SS2.p3.2.m2.1.2.3.2.2" xref="S3.SS2.p3.2.m2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.m2.1b"><apply id="S3.SS2.p3.2.m2.1.2.cmml" xref="S3.SS2.p3.2.m2.1.2"><times id="S3.SS2.p3.2.m2.1.2.1.cmml" xref="S3.SS2.p3.2.m2.1.2.1"></times><ci id="S3.SS2.p3.2.m2.1.2.2.cmml" xref="S3.SS2.p3.2.m2.1.2.2">𝐹</ci><ci id="S3.SS2.p3.2.m2.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1">𝑋</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.2.m2.1c">F(X)</annotation></semantics></math> can be released accurately when F is insensitive to individual models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>. Many natural functions have low GS like sample mean and covariance matrix. To achieve a small global sensitivity, the ideal condition is that all the clients use sufficient local datasets for training <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>The proposed Differential Privacy by Design (dPbD) framework </h2>

<div id="S4.p1" class="ltx_para ltx_noindent">
<p id="S4.p1.1" class="ltx_p">In privacy-preserving machine learning, we search for an algorithm that takes as input a dataset (sampled from some distribution), and then privately output a hypothesis h that with high probability has low error over the distribution.</p>
</div>
<div id="S4.p2" class="ltx_para ltx_noindent">
<p id="S4.p2.1" class="ltx_p">Our proposed theoretical framework is extending privacy by design framework <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> for federating machine learning design by using the notion of embedding differential privacy into its system design from end to end. Figure 2 provides a visual description of our proposed differential privacy by design (dPbD) framework.</p>
</div>
<div id="S4.p3" class="ltx_para ltx_noindent">
<p id="S4.p3.1" class="ltx_p">This framework is partially inspired by empirical studies <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>, <a href="#bib.bib24" title="" class="ltx_ref">24</a>, <a href="#bib.bib28" title="" class="ltx_ref">28</a>, <a href="#bib.bib25" title="" class="ltx_ref">25</a>, <a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> on the use of differential privacy for machine learning. From these empirical studies, two major dimensions consistently emerged. One dimension differentiates between privacy and utility and highlights their trade-off. Utility in machine learning can be taken as model accuracy or decrease in testing loss—the other dimensions design scalability and robustness. Here scalability means scalability of federated learning model and number of clients. Robustness indicates system performance against attacks.</p>
</div>
<div id="S4.p4" class="ltx_para ltx_noindent">
<p id="S4.p4.1" class="ltx_p">There are four quadrants and thus four important junctions of the proposed framework that define most important factors in defining differential privacy in federated learning design. These factors include level of privacy, level of randomised noise, global sensitivity and number of clients or nodes in a differentially private federated learning system.</p>
</div>
<div id="S4.p5" class="ltx_para ltx_noindent">
<p id="S4.p5.1" class="ltx_p">As differential privacy guarantees anonymity and indistinguishability in terms of a privacy budget (epsilon)—the smaller the budget, the stronger the confidence on privacy, and we call it a level of privacy. It is significant characteristics of differential privacy by design as it guarantees and provides a quantitative notion of privacy compared to the unclear concept of privacy in privacy by design framework. The level of privacy defines system robustness against attacks. Similarly adding more noise as part of differential privacy can reduce system utility and robustness. The amount of randomised noise is thus an important factor to balance the trade-off between privacy and utility.</p>
</div>
<div id="S4.p6" class="ltx_para ltx_noindent">
<p id="S4.p6.1" class="ltx_p">On the other hand, scalability requires an increase in the number of nodes and the effectiveness of robust aggregation. Robust aggregation depends on global sensitivity. A small value of global sensitivity requires that all the clients use sufficient local datasets for training, .and the type of aggregation function. Similarly, functions having low global sensitivity are preferred for better performance and utility like Sample mean and Covariance matrix.</p>
</div>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>The 7 Foundational Principles </h2>

<div id="S5.p1" class="ltx_para ltx_noindent">
<p id="S5.p1.1" class="ltx_p">We advise these seven principles to accomplish proposed differential privacy by design framework for system design.</p>
</div>
<div id="S5.p2" class="ltx_para ltx_noindent">
<ul id="S5.I1" class="ltx_itemize">
<li id="S5.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i1.p1" class="ltx_para ltx_noindent">
<p id="S5.I1.i1.p1.1" class="ltx_p">Privacy can be guaranteed in design: The system must ensure a meaningful privacy guarantee. For instance, choosing a smaller epsilon produces noisier results and better privacy guarantees in differential privacy. Privacy guarantee during system design will build trust.</p>
</div>
</li>
<li id="S5.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i2.p1" class="ltx_para ltx_noindent">
<p id="S5.I1.i2.p1.1" class="ltx_p">Privacy can be quantified in design: Differential privacy can be used to quantify privacy. The strategy of using budgets, expenses and losses in terms of privacy is known as privacy accounting. The maximum privacy loss is called the privacy budget. This quantification leads to better privacy-preserving design.</p>
</div>
</li>
<li id="S5.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i3.p1" class="ltx_para ltx_noindent">
<p id="S5.I1.i3.p1.1" class="ltx_p">Privacy by Modularity: Modularity is the Key to ensure privacy as it reduces complexity <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>. Modules can be removed, replaced, or upgraded without affecting other components. Privacy of the system should not be affected by removing, replacing, or upgrading any system component.</p>
</div>
</li>
<li id="S5.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i4.p1" class="ltx_para ltx_noindent">
<p id="S5.I1.i4.p1.1" class="ltx_p">Privacy Embedded into Federated Design : Privacy is preserved in model aggregation with low global sensitivity. The aggregated model should also be insensitive to local data at different nodes.</p>
</div>
</li>
<li id="S5.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i5.p1" class="ltx_para ltx_noindent">
<p id="S5.I1.i5.p1.1" class="ltx_p">Privacy with Scalability :Privacy notion is unaffected by scaling the system. Any change in scalability for Federated Learning system and asynchronous or synchronous training algorithms should not degrade privacy.</p>
</div>
</li>
<li id="S5.I1.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i6.p1" class="ltx_para ltx_noindent">
<p id="S5.I1.i6.p1.1" class="ltx_p">Anonymity in Design Lifecycle: Original data is never shared. Only modified function or model parameters are transmitted. Data anonymity must be ensured in complete Design Lifecycle.</p>
</div>
</li>
<li id="S5.I1.i7" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i7.p1" class="ltx_para ltx_noindent">
<p id="S5.I1.i7.p1.1" class="ltx_p">Optimising Privacy-Utility Trade-off in Design: we refer utility to certain system properties <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>. Increase in privacy often causes a decrease in utility. A design should optimise this trade-off by ensuring privacy without adversely harming system utility.</p>
</div>
</li>
</ul>
</div>
<figure id="S5.F2" class="ltx_figure"><img src="/html/2010.06177/assets/FIG2.png" id="S5.F2.g1" class="ltx_graphics ltx_centering ltx_img_square" width="628" height="537" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>The proposed differential privacy by design (dPbD) framework.</figcaption>
</figure>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>A Scenario of COVID-19 Imagaing Data Privacy By Design</h2>

<div id="S6.p1" class="ltx_para ltx_noindent">
<p id="S6.p1.1" class="ltx_p">The privacy of COVID-19 imaging data on a collaborative machine learning network (federated machine learning) can be taken as a case study of differential privacy by design framework. Its seven foundation principles can be applied to ensure privacy while designing collaborative machine learning systems. Here, we describe a brief view of the implementation of these seven principles in the scenario of the training machine learning model on federated learning systems.</p>
</div>
<div id="S6.p2" class="ltx_para ltx_noindent">
<ul id="S6.I1" class="ltx_itemize">
<li id="S6.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i1.p1" class="ltx_para ltx_noindent">
<p id="S6.I1.i1.p1.1" class="ltx_p">Privacy-preserving federated learning design must control the level of privacy to control perturbation and noise for robustness. However, the design must provide equate level of privacy to prevent patients personal information embedding or related to their COVID-19 imaging data.</p>
</div>
</li>
<li id="S6.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i2.p1" class="ltx_para ltx_noindent">
<p id="S6.I1.i2.p1.1" class="ltx_p">Privacy level must be quantified in federated design. There must be understanding and consensus between teams involved in federated learning setup about the minum and maximum level of privacy required for collaborative research.</p>
</div>
</li>
<li id="S6.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i3.p1" class="ltx_para ltx_noindent">
<p id="S6.I1.i3.p1.1" class="ltx_p">Adequate privacy must be enforced during design at all system components like clients, federated server and communication channels. Addition or removal of clients and change in client side learning model should not affect data privacy promised by the system.</p>
</div>
</li>
<li id="S6.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i4.p1" class="ltx_para ltx_noindent">
<p id="S6.I1.i4.p1.1" class="ltx_p">A robust model aggregation strategy must be adopted. A function with low global sensitivity be chosen while designing any federated system for COVID-19. The robust aggregation should be insensitive to local changes and changes in data on client nodes.</p>
</div>
</li>
<li id="S6.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i5.p1" class="ltx_para ltx_noindent">
<p id="S6.I1.i5.p1.1" class="ltx_p">COVID-19 imaging data is never shared throughout the training lifecycle. Model sharing is protected and maintain the anonymity of patients information through the model up-gradation and communication rounds.</p>
</div>
</li>
<li id="S6.I1.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i6.p1" class="ltx_para ltx_noindent">
<p id="S6.I1.i6.p1.1" class="ltx_p">The system design must be flexible, and adding and removing clients and teams or increasing or decreasing COVID-19 data size should not adversely harm patient data and shared model privacy. Horizontal and vertical scalability be supported during design with features of robustness and resilience.</p>
</div>
</li>
<li id="S6.I1.i7" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i7.p1" class="ltx_para ltx_noindent">
<p id="S6.I1.i7.p1.1" class="ltx_p">Accuracy is an important consideration in COVID diagnosis, and it should not be harmed. It is critical to reduce or sacrifice it for the sake of privacy as it can adversely affect system utility. An optimised trade-off be sought during the design.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Discussion and Concluding Remarks</h2>

<div id="S7.p1" class="ltx_para ltx_noindent">
<p id="S7.p1.1" class="ltx_p">The proposed differential privacy by design framework is focused on the design of privacy-preserving federated machine learnng systems. This theoretical framework is developed by inspiring from various empirical studies about the use of differential privacy in federated learning. However, we discovered that while the majority of the proposed systems emphasise on the trade-off between privacy and utility, they often ignore scalability and robustness of the system. Our proposed framework fills up that gap and proposes a comprehensive framework that covers the majority of the design concepts. We argue that following the footsteps of privacy by design framework, differential privacy must be embedded throughout the design lifecycle, and it should provide overall coverage of protection and privacy to any proposed federated machine learning system. To pave the way of this embedding in design lifecycle, we defined seven foundational principles similar to seven principles of privacy by design framework.</p>
</div>
<div id="S7.p2" class="ltx_para ltx_noindent">
<p id="S7.p2.1" class="ltx_p">We use a case study of COVID-19 imaging data. However, our proposed framework should be applicable to all types of data on a federated learning system. In our future work, we would implement and validate these principles for designing a computer vision-based COVID-19 diagnosis system based on pathological imaging data available from various teams around the world. We hope that the proposed framework with impact designing a privacy-preserving federated learning system with reduced complexity and sufficient data protection for collaborative research to combat COVID-19 challenge.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Urs Gasser, Marcello Ienca, James Scheibner, Joanna Sleigh, and Effy Vayena.

</span>
<span class="ltx_bibblock">Digital tools against covid-19: taxonomy, ethical challenges, and
navigation aid.

</span>
<span class="ltx_bibblock"><span id="bib.bib1.1.1" class="ltx_text ltx_font_italic">The Lancet Digital Health</span>, 2020.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Marcello Ienca and Effy Vayena.

</span>
<span class="ltx_bibblock">On the responsible use of digital data to tackle the covid-19
pandemic.

</span>
<span class="ltx_bibblock"><span id="bib.bib2.1.1" class="ltx_text ltx_font_italic">Nature medicine</span>, 26(4):463–464, 2020.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Sirina Keesara, Andrea Jonas, and Kevin Schulman.

</span>
<span class="ltx_bibblock">Covid-19 and health care’s digital revolution.

</span>
<span class="ltx_bibblock"><span id="bib.bib3.1.1" class="ltx_text ltx_font_italic">New England Journal of Medicine</span>, 382(23):e82, 2020.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Wim Naudé.

</span>
<span class="ltx_bibblock">Artificial intelligence vs covid-19: limitations, constraints and
pitfalls.

</span>
<span class="ltx_bibblock"><span id="bib.bib4.1.1" class="ltx_text ltx_font_italic">Ai &amp; Society</span>, page 1, 2020.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Anwaar Ulhaq, Asim Khan, Douglas Gomes, and Manoranjan Pau.

</span>
<span class="ltx_bibblock">Computer vision for covid-19 control: A survey.

</span>
<span class="ltx_bibblock"><span id="bib.bib5.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2004.09420</span>, 2020.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Michael J Horry, Manoranjan Paul, Anwaar Ulhaq, Biswajeet Pradhan, Manash Saha,
Nagesh Shukla, et al.

</span>
<span class="ltx_bibblock">X-ray image based covid-19 detection using pre-trained deep learning
models.

</span>
<span class="ltx_bibblock">2020.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Michael J Horry, Subrata Chakraborty, Manoranjan Paul, Anwaar Ulhaq, Biswajeet
Pradhan, Manas Saha, and Nagesh Shukla.

</span>
<span class="ltx_bibblock">Covid-19 detection through transfer learning using multimodal imaging
data.

</span>
<span class="ltx_bibblock"><span id="bib.bib7.1.1" class="ltx_text ltx_font_italic">IEEE Access</span>, 8:149808–149824, 2020.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Anwaar Ulhaq, Jannis Born, Asim Khan, Douglas Gomes, Subrata Chakraborty, and
Manoranjan Paul.

</span>
<span class="ltx_bibblock">Covid-19 control by computer vision approaches: A survey.

</span>
<span class="ltx_bibblock"><span id="bib.bib8.1.1" class="ltx_text ltx_font_italic">IEEE Access</span>, 2020.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Douglas PS Gomes, Anwaar Ulhaq, Manoranjan Paul, Michael J Horry, Subrata
Chakraborty, Manas Saha, Tanmoy Debnath, and DM Rahaman.

</span>
<span class="ltx_bibblock">Potential features of icu admission in x-ray images of covid-19
patients.

</span>
<span class="ltx_bibblock"><span id="bib.bib9.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2009.12597</span>, 2020.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Paul Voigt and Axel Von dem Bussche.

</span>
<span class="ltx_bibblock">The eu general data protection regulation (gdpr).

</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text ltx_font_italic">A Practical Guide, 1st Ed., Cham: Springer International
Publishing</span>, 2017.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Ann Cavoukian et al.

</span>
<span class="ltx_bibblock">Privacy by design: The 7 foundational principles.

</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text ltx_font_italic">Information and privacy commissioner of Ontario, Canada</span>, 5,
2009.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Ira S Rubinstein.

</span>
<span class="ltx_bibblock">Regulating privacy by design.

</span>
<span class="ltx_bibblock"><span id="bib.bib12.1.1" class="ltx_text ltx_font_italic">Berkeley Tech. LJ</span>, 26:1409, 2011.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Jakub Konečnỳ, Brendan McMahan, and Daniel Ramage.

</span>
<span class="ltx_bibblock">Federated optimization: Distributed optimization beyond the
datacenter.

</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1511.03575</span>, 2015.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Jakub Konečnỳ, H Brendan McMahan, Daniel Ramage, and Peter
Richtárik.

</span>
<span class="ltx_bibblock">Federated optimization: Distributed machine learning for on-device
intelligence.

</span>
<span class="ltx_bibblock"><span id="bib.bib14.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1610.02527</span>, 2016.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Qiang Yang, Yang Liu, Tianjian Chen, and Yongxin Tong.

</span>
<span class="ltx_bibblock">Federated machine learning: Concept and applications.

</span>
<span class="ltx_bibblock"><span id="bib.bib15.1.1" class="ltx_text ltx_font_italic">ACM Transactions on Intelligent Systems and Technology (TIST)</span>,
10(2):1–19, 2019.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Arjun Nitin Bhagoji, Supriyo Chakraborty, Prateek Mittal, and Seraphin Calo.

</span>
<span class="ltx_bibblock">Analyzing federated learning through an adversarial lens.

</span>
<span class="ltx_bibblock">In <span id="bib.bib16.1.1" class="ltx_text ltx_font_italic">International Conference on Machine Learning</span>, pages
634–643. PMLR, 2019.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Tian Li, Anit Kumar Sahu, Ameet Talwalkar, and Virginia Smith.

</span>
<span class="ltx_bibblock">Federated learning: Challenges, methods, and future directions.

</span>
<span class="ltx_bibblock"><span id="bib.bib17.1.1" class="ltx_text ltx_font_italic">IEEE Signal Processing Magazine</span>, 37(3):50–60, 2020.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Cynthia Dwork.

</span>
<span class="ltx_bibblock">Differential privacy: A survey of results.

</span>
<span class="ltx_bibblock">In <span id="bib.bib18.1.1" class="ltx_text ltx_font_italic">International conference on theory and applications of models
of computation</span>, pages 1–19. Springer, 2008.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Zhanglong Ji, Zachary C Lipton, and Charles Elkan.

</span>
<span class="ltx_bibblock">Differential privacy and machine learning: a survey and review.

</span>
<span class="ltx_bibblock"><span id="bib.bib19.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1412.7584</span>, 2014.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Kirsten Wahlstrom, Anwaar Ul-haq, Oliver Burmeister, et al.

</span>
<span class="ltx_bibblock">Privacy by design.

</span>
<span class="ltx_bibblock"><span id="bib.bib20.1.1" class="ltx_text ltx_font_italic">Australasian Journal of Information Systems</span>, 24, 2020.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Payman Mohassel and Yupeng Zhang.

</span>
<span class="ltx_bibblock">Secureml: A system for scalable privacy-preserving machine learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib21.1.1" class="ltx_text ltx_font_italic">2017 IEEE Symposium on Security and Privacy (SP)</span>, pages
19–38. IEEE, 2017.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
AM Mirza, Sajid Qamar, et al.

</span>
<span class="ltx_bibblock">An optimized image fusion algorithm for night-time surveillance and
navigation.

</span>
<span class="ltx_bibblock">In <span id="bib.bib22.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE Symposium on Emerging Technologies,
2005.</span>, pages 138–143. IEEE, 2005.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Martin Abadi, Andy Chu, Ian Goodfellow, H Brendan McMahan, Ilya Mironov, Kunal
Talwar, and Li Zhang.

</span>
<span class="ltx_bibblock">Deep learning with differential privacy.

</span>
<span class="ltx_bibblock">In <span id="bib.bib23.1.1" class="ltx_text ltx_font_italic">Proceedings of the 2016 ACM SIGSAC Conference on Computer and
Communications Security</span>, pages 308–318, 2016.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
Kang Wei, Jun Li, Ming Ding, Chuan Ma, Howard H Yang, Farhad Farokhi, Shi Jin,
Tony QS Quek, and H Vincent Poor.

</span>
<span class="ltx_bibblock">Federated learning with differential privacy: Algorithms and
performance analysis.

</span>
<span class="ltx_bibblock"><span id="bib.bib24.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Information Forensics and Security</span>, 2020.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
Rajesh Kumar, Abdullah Aman Khan, Sinmin Zhang, WenYong Wang, Yousif Abuidris,
Waqas Amin, and Jay Kumar.

</span>
<span class="ltx_bibblock">Blockchain-federated-learning and deep learning models for covid-19
detection using ct imaging.

</span>
<span class="ltx_bibblock"><span id="bib.bib25.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2007.06537</span>, 2020.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
Dianlei Xu, Tong Li, Yong Li, Xiang Su, Sasu Tarkoma, and Pan Hui.

</span>
<span class="ltx_bibblock">A survey on edge intelligence.

</span>
<span class="ltx_bibblock"><span id="bib.bib26.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2003.12172</span>, 2020.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
Boyi Liu, Bingjie Yan, Yize Zhou, Yifan Yang, and Yixian Zhang.

</span>
<span class="ltx_bibblock">Experiments of federated learning for covid-19 chest x-ray images.

</span>
<span class="ltx_bibblock"><span id="bib.bib27.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2007.05592</span>, 2020.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
Robin C Geyer, Tassilo Klein, and Moin Nabi.

</span>
<span class="ltx_bibblock">Differentially private federated learning: A client level
perspective.

</span>
<span class="ltx_bibblock"><span id="bib.bib28.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1712.07557</span>, 2017.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
Krishna Pillutla, Sham M Kakade, and Zaid Harchaoui.

</span>
<span class="ltx_bibblock">Robust aggregation for federated learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib29.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1912.13445</span>, 2019.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
Aleksei Triastcyn and Boi Faltings.

</span>
<span class="ltx_bibblock">Federated learning with bayesian differential privacy.

</span>
<span class="ltx_bibblock">In <span id="bib.bib30.1.1" class="ltx_text ltx_font_italic">2019 IEEE International Conference on Big Data (Big Data)</span>,
pages 2587–2596. IEEE, 2019.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
Joanna J Bryson and Lynn Andrea Stein.

</span>
<span class="ltx_bibblock">Modularity and design in reactive intelligence.

</span>
<span class="ltx_bibblock">In <span id="bib.bib31.1.1" class="ltx_text ltx_font_italic">International Joint Conference on Artificial Intelligence</span>,
volume 17, pages 1115–1120. LAWRENCE ERLBAUM ASSOCIATES LTD, 2001.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
Ali Makhdoumi and Nadia Fawaz.

</span>
<span class="ltx_bibblock">Privacy-utility tradeoff under statistical uncertainty.

</span>
<span class="ltx_bibblock">In <span id="bib.bib32.1.1" class="ltx_text ltx_font_italic">2013 51st Annual Allerton Conference on Communication,
Control, and Computing (Allerton)</span>, pages 1627–1634. IEEE, 2013.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2010.06176" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2010.06177" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2010.06177">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2010.06177" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2010.06178" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Mar  7 04:13:43 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
