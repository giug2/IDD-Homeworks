<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[1805.04247] Reciprocal Attention Fusion for Visual Question Answering</title><meta property="og:description" content="Existing attention mechanisms either attend to local image-grid or object level features for Visual Question Answering (VQA). Motivated by the observation that questions can relate to both object instances and their paâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Reciprocal Attention Fusion for Visual Question Answering">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Reciprocal Attention Fusion for Visual Question Answering">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/1805.04247">

<!--Generated on Tue Mar  5 11:41:24 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<div id="p1" class="ltx_para">
<span id="p1.3" class="ltx_ERROR undefined">\addauthor</span>
<p id="p1.2" class="ltx_p">Moshiur R Farazi<math id="p1.1.m1.1" class="ltx_Math" alttext="{}^{\text{1,}}" display="inline"><semantics id="p1.1.m1.1a"><msup id="p1.1.m1.1.1" xref="p1.1.m1.1.1.cmml"><mi id="p1.1.m1.1.1a" xref="p1.1.m1.1.1.cmml"></mi><mtext id="p1.1.m1.1.1.1" xref="p1.1.m1.1.1.1a.cmml">1,</mtext></msup><annotation-xml encoding="MathML-Content" id="p1.1.m1.1b"><apply id="p1.1.m1.1.1.cmml" xref="p1.1.m1.1.1"><ci id="p1.1.m1.1.1.1a.cmml" xref="p1.1.m1.1.1.1"><mtext mathsize="70%" id="p1.1.m1.1.1.1.cmml" xref="p1.1.m1.1.1.1">1,</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="p1.1.m1.1c">{}^{\text{1,}}</annotation></semantics></math>moshiur.farazi@anu.edu.au2
<span id="p1.2.1" class="ltx_ERROR undefined">\addauthor</span>Salman H Khan<math id="p1.2.m2.1" class="ltx_Math" alttext="{}^{\text{2,1,}}" display="inline"><semantics id="p1.2.m2.1a"><msup id="p1.2.m2.1.1" xref="p1.2.m2.1.1.cmml"><mi id="p1.2.m2.1.1a" xref="p1.2.m2.1.1.cmml"></mi><mtext id="p1.2.m2.1.1.1" xref="p1.2.m2.1.1.1a.cmml">2,1,</mtext></msup><annotation-xml encoding="MathML-Content" id="p1.2.m2.1b"><apply id="p1.2.m2.1.1.cmml" xref="p1.2.m2.1.1"><ci id="p1.2.m2.1.1.1a.cmml" xref="p1.2.m2.1.1.1"><mtext mathsize="70%" id="p1.2.m2.1.1.1.cmml" xref="p1.2.m2.1.1.1">2,1,</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="p1.2.m2.1c">{}^{\text{2,1,}}</annotation></semantics></math>salman.khan@anu.edu.au3
<span id="p1.2.2" class="ltx_ERROR undefined">\addinstitution</span>
Australian National University, 
<br class="ltx_break">Australia

<span id="p1.2.3" class="ltx_ERROR undefined">\addinstitution</span>
Data61 - CSIRO, Australia

<span id="p1.2.4" class="ltx_ERROR undefined">\addinstitution</span>
Inception Institute of AI, UAE

Reciprocal Attention Fusion for VQA</p>
</div>
<h1 class="ltx_title ltx_title_document">Reciprocal Attention Fusion for Visual Question Answering</h1>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">Existing attention mechanisms either attend to local image-grid or object level features for Visual Question Answering (VQA). Motivated by the observation that questions can relate to both object instances and their parts, we propose a novel attention mechanism that jointly considers reciprocal relationships between the two levels of visual details. The bottom-up attention thus generated is further coalesced with the top-down information to only focus on the scene elements that are most relevant to a given question. Our design hierarchically fuses multi-modal information i.e., language, object- and grid-level features, through an efficient tensor decomposition scheme. The proposed model improves the state-of-the-art single model performances from 67.9% to 68.2% on VQAv1 and from 65.7% to 67.4% on VQAv2, demonstrating a significant boost.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">An AI agent equipped with visual question answering ability can respond to intelligent questions about a complex scene. This task bridges the gap between visual and language understanding to realize the longstanding goal of highly intelligent machine vision systems. Recent advances in automatic feature learning with deep neural networks allow joint processing of both visual and language modalities in a unified framework, leading to significant improvements on the challenging VQA problem <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">Antol etÂ al. (2015)</span></a>, <a href="#bib.bib20" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">Krishna etÂ al. (2016)</span></a>, <a href="#bib.bib16" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">Johnson etÂ al. (2016)</span></a>, <a href="#bib.bib40" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">Zhu etÂ al. (2016)</span></a>, <a href="#bib.bib12" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">Goyal etÂ al. (2016)</span></a>]</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">To deduce the correct answer, an AI agent needs to correlate image and question information. A predominant focus in the existing efforts has remained on attending to local regions on the image-grid based on language input <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">Xu etÂ al. (2015)</span></a>, <a href="#bib.bib21" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">Lu etÂ al. (2016)</span></a>, <a href="#bib.bib35" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">Yang etÂ al. (2016)</span></a>, <a href="#bib.bib15" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">Jabri etÂ al. (2016)</span></a>, <a href="#bib.bib26" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">Shih etÂ al. (2016)</span></a>]</cite>. Since these regions do not necessarily correspond to representative scene elements (objects, attributes and actions), there exists a "semantic gap" in such attention mechanisms. To address this issue, Anderson <em id="S1.p2.1.1" class="ltx_emph ltx_font_italic">et al</em><span id="S1.p2.1.2" class="ltx_ERROR undefined">\bmvaOneDot</span><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">Anderson etÂ al. (2018)</span></a>]</cite> proposed to work at the object level, where model attention is spread over a set of possible object locations. However, the object proposal set considered in this way is non-exhaustive and can miss important aspects of a scene. Furthermore, language questions can pertain to local details about objects parts and attributes, which are not encompassed by the object-level scene decomposition.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/1805.04247/assets/x1.png" id="S1.F1.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="138" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Applying attention to reciprocal visual features allow a VQA model to obtain the most relevant informations required to answer a given visual question.</figcaption>
</figure>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">In this work, we propose to simultaneously attend to both low-level visual concepts as well as the high-level object based scene representation. Our intuition is based on the fact that the questions can be related to objects, object-parts and local attributes, therefore focusing on a single scene representation can degrade model capacity. To this end, we jointly attend to two reciprocal scene representations that encompass local information on the image-grid and the object-level features. The bottom-up attention thus generated is further combined with the top-down attention driven by the linguistic input. Our design draws inspiration from the human cognitive psychology, where attention mechanism is known to be a combination of both exogenous (bottom-up) and endogenous (top-down) factors <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">Desimone and Duncan (1995)</span></a>, <a href="#bib.bib6" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">Borji and Itti (2013)</span></a>]</cite>.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">Given the multi-modal inputs, a critical requirement is to effectively model complex interactions between the multi-level bottom-up and top-down factors. For this purpose, we propose a multi-branch CNN architecture that hierarchically fuses visual and linguistic features by leveraging an efficient tensor decomposition mechanism <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">Tucker (1966)</span></a>, <a href="#bib.bib5" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">Ben-Younes etÂ al. (2017)</span></a>]</cite>. Our experiments and extensive ablative study proves that a language driven attention on both image-grid and object level representation allows a deep network to model the complex interaction between vision and language as our model outperforms the state-of-the-art models in VQA tasks.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">In summary, this paper makes the following key contributions:</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">A hierarchical architecture incorporating both the bottom-up and top-down factors pertaining to meaningful scene elements and their parts.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">Co-attention mechanism enhancing scene understanding by combining local image-grid and object-level visual cues.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">Extensive evaluation and ablation on both balanced and imbalanced versions of the large-scale VQA dataset achieving single model state-of-the-art performance in both.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Works</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p"><span id="S2.p1.1.1" class="ltx_text ltx_font_bold">Deep Networks:</span>
Given the success of deep learning, one common approach to address the VQA problem is by generating image features using pretrained Convolutional Neural Networks (CNNs), e.g., VGGNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">Simonyan and Zisserman (2014)</span></a>]</cite>, ResNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">He etÂ al. (2016)</span></a>]</cite>, and language features using word-embeddings or Long Short-Term Memory (LSTM) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">Antol etÂ al. (2015)</span></a>]</cite>. After generating image and language features, some approaches train RNNs to generate top-K candidate answers and use a multi-class classifier to choose the best answer <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">Antol etÂ al. (2015)</span></a>, <a href="#bib.bib40" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">Zhu etÂ al. (2016)</span></a>, <a href="#bib.bib38" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">Zhou etÂ al. (2015)</span></a>]</cite>. A number of attention mechanisms have been incorporated within deep networks to automatically focus on specific details in an image based on the given question <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">Lu etÂ al. (2016)</span></a>, <a href="#bib.bib35" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">Yang etÂ al. (2016)</span></a>, <a href="#bib.bib15" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">Jabri etÂ al. (2016)</span></a>]</cite>. Memory networks have also been incorporated in many top performing models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">Xiong etÂ al. (2016)</span></a>, <a href="#bib.bib28" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">Sukhbaatar etÂ al. (2015)</span></a>, <a href="#bib.bib39" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">(39)</span></a>]</cite> where the questions required the system to compare attributes or use a long reasoning chain. While robust features and memory modules help capture some aspects of the semantics present in the scene, modeling the complex interplay between image-grid and objects level features can complement the understanding of the rich scene semantics.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p"><span id="S2.p2.1.1" class="ltx_text ltx_font_bold">Attention Models:</span>
The incorporation of spatial attention on the image and/or the text features has been investigated to capture the most important parts required to answer a given question <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">Xu etÂ al. (2015)</span></a>, <a href="#bib.bib35" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">Yang etÂ al. (2016)</span></a>, <a href="#bib.bib15" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">Jabri etÂ al. (2016)</span></a>, <a href="#bib.bib26" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">Shih etÂ al. (2016)</span></a>, <a href="#bib.bib21" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">Lu etÂ al. (2016)</span></a>]</cite>.
Different pooling methods have been used previously to compute the attention maps such as soft attention, bilinear pooling and tucker fusion <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">Xu etÂ al. (2015)</span></a>, <a href="#bib.bib11" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">Gao etÂ al. (2016)</span></a>, <a href="#bib.bib5" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">Ben-Younes etÂ al. (2017)</span></a>]</cite>. All these techniques explore top-down attention and only focus on the image-grid.
Different to these works, based on the observation that questions pertain to objects, their parts and attributes, we propose to work jointly at the spatial grid of image regions and the object-level. The closest to our work is <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">Anderson etÂ al. (2018)</span></a>]</cite>, which attends to salient objects in an image for improved VQA. However, they ignore two key aspects of visual reasoning i.e., the image level visual features and an effective fusion mechanism to combine the bimodal interaction between visual and language features. Another recent effort <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">Lu etÂ al. (2017)</span></a>]</cite> co-attends to both image regions and objects, but uses a simplistic fusion mechanism based on element-wise multiplication that is outperformed by our bilinear feature encoding. Besides, our multi-level attention mechanism effectively uses object features and scene context based on the natural language queries.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Methods</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">The VQA task requires an AI agent to generate a natural language response, given a visual (i.e. image, video) and natural language input (i.e.Â questions, parse). We formulate VQA task as a classification task, where the model predicts the correct answer (<math id="S3.p1.1.m1.1" class="ltx_Math" alttext="\hat{a}" display="inline"><semantics id="S3.p1.1.m1.1a"><mover accent="true" id="S3.p1.1.m1.1.1" xref="S3.p1.1.m1.1.1.cmml"><mi id="S3.p1.1.m1.1.1.2" xref="S3.p1.1.m1.1.1.2.cmml">a</mi><mo id="S3.p1.1.m1.1.1.1" xref="S3.p1.1.m1.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.p1.1.m1.1b"><apply id="S3.p1.1.m1.1.1.cmml" xref="S3.p1.1.m1.1.1"><ci id="S3.p1.1.m1.1.1.1.cmml" xref="S3.p1.1.m1.1.1.1">^</ci><ci id="S3.p1.1.m1.1.1.2.cmml" xref="S3.p1.1.m1.1.1.2">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.1.m1.1c">\hat{a}</annotation></semantics></math>) from all possible answers for a given image (<span id="S3.p1.1.1" class="ltx_text ltx_font_bold">v</span>) and question (<span id="S3.p1.1.2" class="ltx_text ltx_font_bold">q</span>) pair:</p>
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.4" class="ltx_Math" alttext="\hat{a}=\operatorname*{argmax}_{a\in A}p(a|\mathbf{v},\mathbf{q};\theta)," display="block"><semantics id="S3.E1.m1.4a"><mrow id="S3.E1.m1.4.4.1" xref="S3.E1.m1.4.4.1.1.cmml"><mrow id="S3.E1.m1.4.4.1.1" xref="S3.E1.m1.4.4.1.1.cmml"><mover accent="true" id="S3.E1.m1.4.4.1.1.3" xref="S3.E1.m1.4.4.1.1.3.cmml"><mi id="S3.E1.m1.4.4.1.1.3.2" xref="S3.E1.m1.4.4.1.1.3.2.cmml">a</mi><mo id="S3.E1.m1.4.4.1.1.3.1" xref="S3.E1.m1.4.4.1.1.3.1.cmml">^</mo></mover><mo rspace="0.1389em" id="S3.E1.m1.4.4.1.1.2" xref="S3.E1.m1.4.4.1.1.2.cmml">=</mo><mrow id="S3.E1.m1.4.4.1.1.1" xref="S3.E1.m1.4.4.1.1.1.cmml"><mrow id="S3.E1.m1.4.4.1.1.1.3" xref="S3.E1.m1.4.4.1.1.1.3.cmml"><munder id="S3.E1.m1.4.4.1.1.1.3.1" xref="S3.E1.m1.4.4.1.1.1.3.1.cmml"><mo lspace="0.1389em" rspace="0.167em" id="S3.E1.m1.4.4.1.1.1.3.1.2" xref="S3.E1.m1.4.4.1.1.1.3.1.2.cmml">argmax</mo><mrow id="S3.E1.m1.4.4.1.1.1.3.1.3" xref="S3.E1.m1.4.4.1.1.1.3.1.3.cmml"><mi id="S3.E1.m1.4.4.1.1.1.3.1.3.2" xref="S3.E1.m1.4.4.1.1.1.3.1.3.2.cmml">a</mi><mo id="S3.E1.m1.4.4.1.1.1.3.1.3.1" xref="S3.E1.m1.4.4.1.1.1.3.1.3.1.cmml">âˆˆ</mo><mi id="S3.E1.m1.4.4.1.1.1.3.1.3.3" xref="S3.E1.m1.4.4.1.1.1.3.1.3.3.cmml">A</mi></mrow></munder><mi id="S3.E1.m1.4.4.1.1.1.3.2" xref="S3.E1.m1.4.4.1.1.1.3.2.cmml">p</mi></mrow><mo lspace="0em" rspace="0em" id="S3.E1.m1.4.4.1.1.1.2" xref="S3.E1.m1.4.4.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E1.m1.4.4.1.1.1.1.1" xref="S3.E1.m1.4.4.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E1.m1.4.4.1.1.1.1.1.2" xref="S3.E1.m1.4.4.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E1.m1.4.4.1.1.1.1.1.1" xref="S3.E1.m1.4.4.1.1.1.1.1.1.cmml"><mi id="S3.E1.m1.4.4.1.1.1.1.1.1.2" xref="S3.E1.m1.4.4.1.1.1.1.1.1.2.cmml">a</mi><mo fence="false" id="S3.E1.m1.4.4.1.1.1.1.1.1.1" xref="S3.E1.m1.4.4.1.1.1.1.1.1.1.cmml">|</mo><mrow id="S3.E1.m1.4.4.1.1.1.1.1.1.3.2" xref="S3.E1.m1.4.4.1.1.1.1.1.1.3.1.cmml"><mi id="S3.E1.m1.1.1" xref="S3.E1.m1.1.1.cmml">ğ¯</mi><mo id="S3.E1.m1.4.4.1.1.1.1.1.1.3.2.1" xref="S3.E1.m1.4.4.1.1.1.1.1.1.3.1.cmml">,</mo><mi id="S3.E1.m1.2.2" xref="S3.E1.m1.2.2.cmml">ğª</mi><mo id="S3.E1.m1.4.4.1.1.1.1.1.1.3.2.2" xref="S3.E1.m1.4.4.1.1.1.1.1.1.3.1.cmml">;</mo><mi id="S3.E1.m1.3.3" xref="S3.E1.m1.3.3.cmml">Î¸</mi></mrow></mrow><mo stretchy="false" id="S3.E1.m1.4.4.1.1.1.1.1.3" xref="S3.E1.m1.4.4.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E1.m1.4.4.1.2" xref="S3.E1.m1.4.4.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.4b"><apply id="S3.E1.m1.4.4.1.1.cmml" xref="S3.E1.m1.4.4.1"><eq id="S3.E1.m1.4.4.1.1.2.cmml" xref="S3.E1.m1.4.4.1.1.2"></eq><apply id="S3.E1.m1.4.4.1.1.3.cmml" xref="S3.E1.m1.4.4.1.1.3"><ci id="S3.E1.m1.4.4.1.1.3.1.cmml" xref="S3.E1.m1.4.4.1.1.3.1">^</ci><ci id="S3.E1.m1.4.4.1.1.3.2.cmml" xref="S3.E1.m1.4.4.1.1.3.2">ğ‘</ci></apply><apply id="S3.E1.m1.4.4.1.1.1.cmml" xref="S3.E1.m1.4.4.1.1.1"><times id="S3.E1.m1.4.4.1.1.1.2.cmml" xref="S3.E1.m1.4.4.1.1.1.2"></times><apply id="S3.E1.m1.4.4.1.1.1.3.cmml" xref="S3.E1.m1.4.4.1.1.1.3"><apply id="S3.E1.m1.4.4.1.1.1.3.1.cmml" xref="S3.E1.m1.4.4.1.1.1.3.1"><csymbol cd="ambiguous" id="S3.E1.m1.4.4.1.1.1.3.1.1.cmml" xref="S3.E1.m1.4.4.1.1.1.3.1">subscript</csymbol><ci id="S3.E1.m1.4.4.1.1.1.3.1.2.cmml" xref="S3.E1.m1.4.4.1.1.1.3.1.2">argmax</ci><apply id="S3.E1.m1.4.4.1.1.1.3.1.3.cmml" xref="S3.E1.m1.4.4.1.1.1.3.1.3"><in id="S3.E1.m1.4.4.1.1.1.3.1.3.1.cmml" xref="S3.E1.m1.4.4.1.1.1.3.1.3.1"></in><ci id="S3.E1.m1.4.4.1.1.1.3.1.3.2.cmml" xref="S3.E1.m1.4.4.1.1.1.3.1.3.2">ğ‘</ci><ci id="S3.E1.m1.4.4.1.1.1.3.1.3.3.cmml" xref="S3.E1.m1.4.4.1.1.1.3.1.3.3">ğ´</ci></apply></apply><ci id="S3.E1.m1.4.4.1.1.1.3.2.cmml" xref="S3.E1.m1.4.4.1.1.1.3.2">ğ‘</ci></apply><apply id="S3.E1.m1.4.4.1.1.1.1.1.1.cmml" xref="S3.E1.m1.4.4.1.1.1.1.1"><csymbol cd="latexml" id="S3.E1.m1.4.4.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.4.4.1.1.1.1.1.1.1">conditional</csymbol><ci id="S3.E1.m1.4.4.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.4.4.1.1.1.1.1.1.2">ğ‘</ci><list id="S3.E1.m1.4.4.1.1.1.1.1.1.3.1.cmml" xref="S3.E1.m1.4.4.1.1.1.1.1.1.3.2"><ci id="S3.E1.m1.1.1.cmml" xref="S3.E1.m1.1.1">ğ¯</ci><ci id="S3.E1.m1.2.2.cmml" xref="S3.E1.m1.2.2">ğª</ci><ci id="S3.E1.m1.3.3.cmml" xref="S3.E1.m1.3.3">ğœƒ</ci></list></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.4c">\hat{a}=\operatorname*{argmax}_{a\in A}p(a|\mathbf{v},\mathbf{q};\theta),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S3.p1.3" class="ltx_p">where <math id="S3.p1.2.m1.1" class="ltx_Math" alttext="\theta" display="inline"><semantics id="S3.p1.2.m1.1a"><mi id="S3.p1.2.m1.1.1" xref="S3.p1.2.m1.1.1.cmml">Î¸</mi><annotation-xml encoding="MathML-Content" id="S3.p1.2.m1.1b"><ci id="S3.p1.2.m1.1.1.cmml" xref="S3.p1.2.m1.1.1">ğœƒ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.2.m1.1c">\theta</annotation></semantics></math> denotes the set of parameters used to predict the best answer from the set of all possible answers <math id="S3.p1.3.m2.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S3.p1.3.m2.1a"><mi id="S3.p1.3.m2.1.1" xref="S3.p1.3.m2.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S3.p1.3.m2.1b"><ci id="S3.p1.3.m2.1.1.cmml" xref="S3.p1.3.m2.1.1">ğ´</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.3.m2.1c">A</annotation></semantics></math>.</p>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.1" class="ltx_p">Our proposed architecture to perform VQA task is illustrated in Figure <a href="#S3.F2" title="Figure 2 â€£ 3 Methods â€£ Reciprocal Attention Fusion for Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. The key highlights of our proposed architecture include a hierarchical attention mechanism that focuses on complementary levels of scene details i.e., grid of image regions and object proposals. The relevant co-attended features are then fused together to perform final prediction. We name our model as the <em id="S3.p2.1.1" class="ltx_emph ltx_font_italic">â€˜Reciprocal Attention Fusionâ€™</em> because it simultaneously attends to two complementary scene representations i.e., image-grid and object proposals. Our experimental results demonstrate that both levels of scene details are reciprocal and reinforce each other to achieve the best single-model performance on challenging VQA task. Before elaborating on the hierarchical attention and feature fusion, we first discuss the joint feature embedding in Section <a href="#S3.SS1" title="3.1 Joint Feature Embedding â€£ 3 Methods â€£ Reciprocal Attention Fusion for Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a>.</p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/1805.04247/assets/x2.png" id="S3.F2.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="248" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Given an image-question pair, our model employs (1) Joint Feature Embedding (Sec.<a href="#S3.SS1" title="3.1 Joint Feature Embedding â€£ 3 Methods â€£ Reciprocal Attention Fusion for Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a>) to embed (a) Language Feature <math id="S3.F2.5.m1.1" class="ltx_Math" alttext="q" display="inline"><semantics id="S3.F2.5.m1.1b"><mi id="S3.F2.5.m1.1.1" xref="S3.F2.5.m1.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S3.F2.5.m1.1c"><ci id="S3.F2.5.m1.1.1.cmml" xref="S3.F2.5.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.5.m1.1d">q</annotation></semantics></math>, (b) Image-Level Feature <math id="S3.F2.6.m2.1" class="ltx_Math" alttext="v_{I}" display="inline"><semantics id="S3.F2.6.m2.1b"><msub id="S3.F2.6.m2.1.1" xref="S3.F2.6.m2.1.1.cmml"><mi id="S3.F2.6.m2.1.1.2" xref="S3.F2.6.m2.1.1.2.cmml">v</mi><mi id="S3.F2.6.m2.1.1.3" xref="S3.F2.6.m2.1.1.3.cmml">I</mi></msub><annotation-xml encoding="MathML-Content" id="S3.F2.6.m2.1c"><apply id="S3.F2.6.m2.1.1.cmml" xref="S3.F2.6.m2.1.1"><csymbol cd="ambiguous" id="S3.F2.6.m2.1.1.1.cmml" xref="S3.F2.6.m2.1.1">subscript</csymbol><ci id="S3.F2.6.m2.1.1.2.cmml" xref="S3.F2.6.m2.1.1.2">ğ‘£</ci><ci id="S3.F2.6.m2.1.1.3.cmml" xref="S3.F2.6.m2.1.1.3">ğ¼</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.6.m2.1d">v_{I}</annotation></semantics></math> and (c) Object-Level Feature <math id="S3.F2.7.m3.1" class="ltx_Math" alttext="v_{O}" display="inline"><semantics id="S3.F2.7.m3.1b"><msub id="S3.F2.7.m3.1.1" xref="S3.F2.7.m3.1.1.cmml"><mi id="S3.F2.7.m3.1.1.2" xref="S3.F2.7.m3.1.1.2.cmml">v</mi><mi id="S3.F2.7.m3.1.1.3" xref="S3.F2.7.m3.1.1.3.cmml">O</mi></msub><annotation-xml encoding="MathML-Content" id="S3.F2.7.m3.1c"><apply id="S3.F2.7.m3.1.1.cmml" xref="S3.F2.7.m3.1.1"><csymbol cd="ambiguous" id="S3.F2.7.m3.1.1.1.cmml" xref="S3.F2.7.m3.1.1">subscript</csymbol><ci id="S3.F2.7.m3.1.1.2.cmml" xref="S3.F2.7.m3.1.1.2">ğ‘£</ci><ci id="S3.F2.7.m3.1.1.3.cmml" xref="S3.F2.7.m3.1.1.3">ğ‘‚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.7.m3.1d">v_{O}</annotation></semantics></math>. Further, these embeddings undergo (2) Hierarchical Attention Fusion (Sec.<a href="#S3.SS2" title="3.2 Hierarchical Attention Fusion â€£ 3 Methods â€£ Reciprocal Attention Fusion for Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a>) which consists of (d) Image-Question and (e) Object-Question Fusion followed by top-down attention. These multi-modal representations are combined together by (3) Co-attention Fusion (Sec.<a href="#S3.SS3" title="3.3 Co-attention Fusion â€£ 3 Methods â€£ Reciprocal Attention Fusion for Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3</span></a>) that predicts an answer for the given Image-Question pair. Overall, the proposed model attends to complementary levels of scene details and fuses multi-modal information to predict highly accurate answers.</figcaption>
</figure>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Joint Feature Embedding</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.4" class="ltx_p">Let <math id="S3.SS1.p1.1.m1.1" class="ltx_Math" alttext="V" display="inline"><semantics id="S3.SS1.p1.1.m1.1a"><mi id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">V</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><ci id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">ğ‘‰</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">V</annotation></semantics></math> be the collection of all visual features extracted from an image and <math id="S3.SS1.p1.2.m2.1" class="ltx_Math" alttext="Q" display="inline"><semantics id="S3.SS1.p1.2.m2.1a"><mi id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><ci id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">ğ‘„</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">Q</annotation></semantics></math> be the language features extracted from the question. The objective of joint embedding is to learn the language feature representation <math id="S3.SS1.p1.3.m3.1" class="ltx_Math" alttext="q=\chi(Q)" display="inline"><semantics id="S3.SS1.p1.3.m3.1a"><mrow id="S3.SS1.p1.3.m3.1.2" xref="S3.SS1.p1.3.m3.1.2.cmml"><mi id="S3.SS1.p1.3.m3.1.2.2" xref="S3.SS1.p1.3.m3.1.2.2.cmml">q</mi><mo id="S3.SS1.p1.3.m3.1.2.1" xref="S3.SS1.p1.3.m3.1.2.1.cmml">=</mo><mrow id="S3.SS1.p1.3.m3.1.2.3" xref="S3.SS1.p1.3.m3.1.2.3.cmml"><mi id="S3.SS1.p1.3.m3.1.2.3.2" xref="S3.SS1.p1.3.m3.1.2.3.2.cmml">Ï‡</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p1.3.m3.1.2.3.1" xref="S3.SS1.p1.3.m3.1.2.3.1.cmml">â€‹</mo><mrow id="S3.SS1.p1.3.m3.1.2.3.3.2" xref="S3.SS1.p1.3.m3.1.2.3.cmml"><mo stretchy="false" id="S3.SS1.p1.3.m3.1.2.3.3.2.1" xref="S3.SS1.p1.3.m3.1.2.3.cmml">(</mo><mi id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml">Q</mi><mo stretchy="false" id="S3.SS1.p1.3.m3.1.2.3.3.2.2" xref="S3.SS1.p1.3.m3.1.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><apply id="S3.SS1.p1.3.m3.1.2.cmml" xref="S3.SS1.p1.3.m3.1.2"><eq id="S3.SS1.p1.3.m3.1.2.1.cmml" xref="S3.SS1.p1.3.m3.1.2.1"></eq><ci id="S3.SS1.p1.3.m3.1.2.2.cmml" xref="S3.SS1.p1.3.m3.1.2.2">ğ‘</ci><apply id="S3.SS1.p1.3.m3.1.2.3.cmml" xref="S3.SS1.p1.3.m3.1.2.3"><times id="S3.SS1.p1.3.m3.1.2.3.1.cmml" xref="S3.SS1.p1.3.m3.1.2.3.1"></times><ci id="S3.SS1.p1.3.m3.1.2.3.2.cmml" xref="S3.SS1.p1.3.m3.1.2.3.2">ğœ’</ci><ci id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">ğ‘„</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">q=\chi(Q)</annotation></semantics></math> and multilevel visual features <math id="S3.SS1.p1.4.m4.1" class="ltx_Math" alttext="v_{k}=\zeta(V)" display="inline"><semantics id="S3.SS1.p1.4.m4.1a"><mrow id="S3.SS1.p1.4.m4.1.2" xref="S3.SS1.p1.4.m4.1.2.cmml"><msub id="S3.SS1.p1.4.m4.1.2.2" xref="S3.SS1.p1.4.m4.1.2.2.cmml"><mi id="S3.SS1.p1.4.m4.1.2.2.2" xref="S3.SS1.p1.4.m4.1.2.2.2.cmml">v</mi><mi id="S3.SS1.p1.4.m4.1.2.2.3" xref="S3.SS1.p1.4.m4.1.2.2.3.cmml">k</mi></msub><mo id="S3.SS1.p1.4.m4.1.2.1" xref="S3.SS1.p1.4.m4.1.2.1.cmml">=</mo><mrow id="S3.SS1.p1.4.m4.1.2.3" xref="S3.SS1.p1.4.m4.1.2.3.cmml"><mi id="S3.SS1.p1.4.m4.1.2.3.2" xref="S3.SS1.p1.4.m4.1.2.3.2.cmml">Î¶</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p1.4.m4.1.2.3.1" xref="S3.SS1.p1.4.m4.1.2.3.1.cmml">â€‹</mo><mrow id="S3.SS1.p1.4.m4.1.2.3.3.2" xref="S3.SS1.p1.4.m4.1.2.3.cmml"><mo stretchy="false" id="S3.SS1.p1.4.m4.1.2.3.3.2.1" xref="S3.SS1.p1.4.m4.1.2.3.cmml">(</mo><mi id="S3.SS1.p1.4.m4.1.1" xref="S3.SS1.p1.4.m4.1.1.cmml">V</mi><mo stretchy="false" id="S3.SS1.p1.4.m4.1.2.3.3.2.2" xref="S3.SS1.p1.4.m4.1.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m4.1b"><apply id="S3.SS1.p1.4.m4.1.2.cmml" xref="S3.SS1.p1.4.m4.1.2"><eq id="S3.SS1.p1.4.m4.1.2.1.cmml" xref="S3.SS1.p1.4.m4.1.2.1"></eq><apply id="S3.SS1.p1.4.m4.1.2.2.cmml" xref="S3.SS1.p1.4.m4.1.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.4.m4.1.2.2.1.cmml" xref="S3.SS1.p1.4.m4.1.2.2">subscript</csymbol><ci id="S3.SS1.p1.4.m4.1.2.2.2.cmml" xref="S3.SS1.p1.4.m4.1.2.2.2">ğ‘£</ci><ci id="S3.SS1.p1.4.m4.1.2.2.3.cmml" xref="S3.SS1.p1.4.m4.1.2.2.3">ğ‘˜</ci></apply><apply id="S3.SS1.p1.4.m4.1.2.3.cmml" xref="S3.SS1.p1.4.m4.1.2.3"><times id="S3.SS1.p1.4.m4.1.2.3.1.cmml" xref="S3.SS1.p1.4.m4.1.2.3.1"></times><ci id="S3.SS1.p1.4.m4.1.2.3.2.cmml" xref="S3.SS1.p1.4.m4.1.2.3.2">ğœ</ci><ci id="S3.SS1.p1.4.m4.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1">ğ‘‰</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m4.1c">v_{k}=\zeta(V)</annotation></semantics></math>. These feature representations are used to encode the multilevel relationships between question and image which in turn is used to train the classifier to select the correct answer.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.8" class="ltx_p"><span id="S3.SS1.p2.8.1" class="ltx_text ltx_font_bold">Multilevel visual features:</span> The multilevel visual embedding <math id="S3.SS1.p2.1.m1.1" class="ltx_Math" alttext="v_{k}" display="inline"><semantics id="S3.SS1.p2.1.m1.1a"><msub id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml"><mi id="S3.SS1.p2.1.m1.1.1.2" xref="S3.SS1.p2.1.m1.1.1.2.cmml">v</mi><mi id="S3.SS1.p2.1.m1.1.1.3" xref="S3.SS1.p2.1.m1.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><apply id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.1.m1.1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.p2.1.m1.1.1.2.cmml" xref="S3.SS1.p2.1.m1.1.1.2">ğ‘£</ci><ci id="S3.SS1.p2.1.m1.1.1.3.cmml" xref="S3.SS1.p2.1.m1.1.1.3">ğ‘˜</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">v_{k}</annotation></semantics></math> consists of image level features <math id="S3.SS1.p2.2.m2.1" class="ltx_Math" alttext="v_{I}" display="inline"><semantics id="S3.SS1.p2.2.m2.1a"><msub id="S3.SS1.p2.2.m2.1.1" xref="S3.SS1.p2.2.m2.1.1.cmml"><mi id="S3.SS1.p2.2.m2.1.1.2" xref="S3.SS1.p2.2.m2.1.1.2.cmml">v</mi><mi id="S3.SS1.p2.2.m2.1.1.3" xref="S3.SS1.p2.2.m2.1.1.3.cmml">I</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.1b"><apply id="S3.SS1.p2.2.m2.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.2.m2.1.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.p2.2.m2.1.1.2.cmml" xref="S3.SS1.p2.2.m2.1.1.2">ğ‘£</ci><ci id="S3.SS1.p2.2.m2.1.1.3.cmml" xref="S3.SS1.p2.2.m2.1.1.3">ğ¼</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.1c">v_{I}</annotation></semantics></math> and object level features <math id="S3.SS1.p2.3.m3.1" class="ltx_Math" alttext="v_{O}" display="inline"><semantics id="S3.SS1.p2.3.m3.1a"><msub id="S3.SS1.p2.3.m3.1.1" xref="S3.SS1.p2.3.m3.1.1.cmml"><mi id="S3.SS1.p2.3.m3.1.1.2" xref="S3.SS1.p2.3.m3.1.1.2.cmml">v</mi><mi id="S3.SS1.p2.3.m3.1.1.3" xref="S3.SS1.p2.3.m3.1.1.3.cmml">O</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.3.m3.1b"><apply id="S3.SS1.p2.3.m3.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.3.m3.1.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.p2.3.m3.1.1.2.cmml" xref="S3.SS1.p2.3.m3.1.1.2">ğ‘£</ci><ci id="S3.SS1.p2.3.m3.1.1.3.cmml" xref="S3.SS1.p2.3.m3.1.1.3">ğ‘‚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.3.m3.1c">v_{O}</annotation></semantics></math>. Our model employs ResNeXt <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">Xie etÂ al. (2016)</span></a>]</cite> to obtain image level features, <math id="S3.SS1.p2.4.m4.1" class="ltx_Math" alttext="v_{I}\in\mathbb{R}^{n_{v}\times G}" display="inline"><semantics id="S3.SS1.p2.4.m4.1a"><mrow id="S3.SS1.p2.4.m4.1.1" xref="S3.SS1.p2.4.m4.1.1.cmml"><msub id="S3.SS1.p2.4.m4.1.1.2" xref="S3.SS1.p2.4.m4.1.1.2.cmml"><mi id="S3.SS1.p2.4.m4.1.1.2.2" xref="S3.SS1.p2.4.m4.1.1.2.2.cmml">v</mi><mi id="S3.SS1.p2.4.m4.1.1.2.3" xref="S3.SS1.p2.4.m4.1.1.2.3.cmml">I</mi></msub><mo id="S3.SS1.p2.4.m4.1.1.1" xref="S3.SS1.p2.4.m4.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS1.p2.4.m4.1.1.3" xref="S3.SS1.p2.4.m4.1.1.3.cmml"><mi id="S3.SS1.p2.4.m4.1.1.3.2" xref="S3.SS1.p2.4.m4.1.1.3.2.cmml">â„</mi><mrow id="S3.SS1.p2.4.m4.1.1.3.3" xref="S3.SS1.p2.4.m4.1.1.3.3.cmml"><msub id="S3.SS1.p2.4.m4.1.1.3.3.2" xref="S3.SS1.p2.4.m4.1.1.3.3.2.cmml"><mi id="S3.SS1.p2.4.m4.1.1.3.3.2.2" xref="S3.SS1.p2.4.m4.1.1.3.3.2.2.cmml">n</mi><mi id="S3.SS1.p2.4.m4.1.1.3.3.2.3" xref="S3.SS1.p2.4.m4.1.1.3.3.2.3.cmml">v</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p2.4.m4.1.1.3.3.1" xref="S3.SS1.p2.4.m4.1.1.3.3.1.cmml">Ã—</mo><mi id="S3.SS1.p2.4.m4.1.1.3.3.3" xref="S3.SS1.p2.4.m4.1.1.3.3.3.cmml">G</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.4.m4.1b"><apply id="S3.SS1.p2.4.m4.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1"><in id="S3.SS1.p2.4.m4.1.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1.1"></in><apply id="S3.SS1.p2.4.m4.1.1.2.cmml" xref="S3.SS1.p2.4.m4.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p2.4.m4.1.1.2.1.cmml" xref="S3.SS1.p2.4.m4.1.1.2">subscript</csymbol><ci id="S3.SS1.p2.4.m4.1.1.2.2.cmml" xref="S3.SS1.p2.4.m4.1.1.2.2">ğ‘£</ci><ci id="S3.SS1.p2.4.m4.1.1.2.3.cmml" xref="S3.SS1.p2.4.m4.1.1.2.3">ğ¼</ci></apply><apply id="S3.SS1.p2.4.m4.1.1.3.cmml" xref="S3.SS1.p2.4.m4.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p2.4.m4.1.1.3.1.cmml" xref="S3.SS1.p2.4.m4.1.1.3">superscript</csymbol><ci id="S3.SS1.p2.4.m4.1.1.3.2.cmml" xref="S3.SS1.p2.4.m4.1.1.3.2">â„</ci><apply id="S3.SS1.p2.4.m4.1.1.3.3.cmml" xref="S3.SS1.p2.4.m4.1.1.3.3"><times id="S3.SS1.p2.4.m4.1.1.3.3.1.cmml" xref="S3.SS1.p2.4.m4.1.1.3.3.1"></times><apply id="S3.SS1.p2.4.m4.1.1.3.3.2.cmml" xref="S3.SS1.p2.4.m4.1.1.3.3.2"><csymbol cd="ambiguous" id="S3.SS1.p2.4.m4.1.1.3.3.2.1.cmml" xref="S3.SS1.p2.4.m4.1.1.3.3.2">subscript</csymbol><ci id="S3.SS1.p2.4.m4.1.1.3.3.2.2.cmml" xref="S3.SS1.p2.4.m4.1.1.3.3.2.2">ğ‘›</ci><ci id="S3.SS1.p2.4.m4.1.1.3.3.2.3.cmml" xref="S3.SS1.p2.4.m4.1.1.3.3.2.3">ğ‘£</ci></apply><ci id="S3.SS1.p2.4.m4.1.1.3.3.3.cmml" xref="S3.SS1.p2.4.m4.1.1.3.3.3">ğº</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.4.m4.1c">v_{I}\in\mathbb{R}^{n_{v}\times G}</annotation></semantics></math> by taking the output of convolution layer before the final pooling layer, where <math id="S3.SS1.p2.5.m5.1" class="ltx_Math" alttext="G" display="inline"><semantics id="S3.SS1.p2.5.m5.1a"><mi id="S3.SS1.p2.5.m5.1.1" xref="S3.SS1.p2.5.m5.1.1.cmml">G</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.5.m5.1b"><ci id="S3.SS1.p2.5.m5.1.1.cmml" xref="S3.SS1.p2.5.m5.1.1">ğº</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.5.m5.1c">G</annotation></semantics></math> denotes the number of spatial grid locations of the extracted visual feature with <math id="S3.SS1.p2.6.m6.1" class="ltx_Math" alttext="n_{v}" display="inline"><semantics id="S3.SS1.p2.6.m6.1a"><msub id="S3.SS1.p2.6.m6.1.1" xref="S3.SS1.p2.6.m6.1.1.cmml"><mi id="S3.SS1.p2.6.m6.1.1.2" xref="S3.SS1.p2.6.m6.1.1.2.cmml">n</mi><mi id="S3.SS1.p2.6.m6.1.1.3" xref="S3.SS1.p2.6.m6.1.1.3.cmml">v</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.6.m6.1b"><apply id="S3.SS1.p2.6.m6.1.1.cmml" xref="S3.SS1.p2.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.6.m6.1.1.1.cmml" xref="S3.SS1.p2.6.m6.1.1">subscript</csymbol><ci id="S3.SS1.p2.6.m6.1.1.2.cmml" xref="S3.SS1.p2.6.m6.1.1.2">ğ‘›</ci><ci id="S3.SS1.p2.6.m6.1.1.3.cmml" xref="S3.SS1.p2.6.m6.1.1.3">ğ‘£</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.6.m6.1c">n_{v}</annotation></semantics></math> dimensions. This convolution layer retains the spatial information of the original image and enable the model to apply attention on the image-grid. On the other hand, our model employs object detectors to localize object instances and pass them through another deep CNN to generate object level features <math id="S3.SS1.p2.7.m7.1" class="ltx_Math" alttext="v_{O}\in\mathbb{R}^{n_{v}\times N}" display="inline"><semantics id="S3.SS1.p2.7.m7.1a"><mrow id="S3.SS1.p2.7.m7.1.1" xref="S3.SS1.p2.7.m7.1.1.cmml"><msub id="S3.SS1.p2.7.m7.1.1.2" xref="S3.SS1.p2.7.m7.1.1.2.cmml"><mi id="S3.SS1.p2.7.m7.1.1.2.2" xref="S3.SS1.p2.7.m7.1.1.2.2.cmml">v</mi><mi id="S3.SS1.p2.7.m7.1.1.2.3" xref="S3.SS1.p2.7.m7.1.1.2.3.cmml">O</mi></msub><mo id="S3.SS1.p2.7.m7.1.1.1" xref="S3.SS1.p2.7.m7.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS1.p2.7.m7.1.1.3" xref="S3.SS1.p2.7.m7.1.1.3.cmml"><mi id="S3.SS1.p2.7.m7.1.1.3.2" xref="S3.SS1.p2.7.m7.1.1.3.2.cmml">â„</mi><mrow id="S3.SS1.p2.7.m7.1.1.3.3" xref="S3.SS1.p2.7.m7.1.1.3.3.cmml"><msub id="S3.SS1.p2.7.m7.1.1.3.3.2" xref="S3.SS1.p2.7.m7.1.1.3.3.2.cmml"><mi id="S3.SS1.p2.7.m7.1.1.3.3.2.2" xref="S3.SS1.p2.7.m7.1.1.3.3.2.2.cmml">n</mi><mi id="S3.SS1.p2.7.m7.1.1.3.3.2.3" xref="S3.SS1.p2.7.m7.1.1.3.3.2.3.cmml">v</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p2.7.m7.1.1.3.3.1" xref="S3.SS1.p2.7.m7.1.1.3.3.1.cmml">Ã—</mo><mi id="S3.SS1.p2.7.m7.1.1.3.3.3" xref="S3.SS1.p2.7.m7.1.1.3.3.3.cmml">N</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.7.m7.1b"><apply id="S3.SS1.p2.7.m7.1.1.cmml" xref="S3.SS1.p2.7.m7.1.1"><in id="S3.SS1.p2.7.m7.1.1.1.cmml" xref="S3.SS1.p2.7.m7.1.1.1"></in><apply id="S3.SS1.p2.7.m7.1.1.2.cmml" xref="S3.SS1.p2.7.m7.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p2.7.m7.1.1.2.1.cmml" xref="S3.SS1.p2.7.m7.1.1.2">subscript</csymbol><ci id="S3.SS1.p2.7.m7.1.1.2.2.cmml" xref="S3.SS1.p2.7.m7.1.1.2.2">ğ‘£</ci><ci id="S3.SS1.p2.7.m7.1.1.2.3.cmml" xref="S3.SS1.p2.7.m7.1.1.2.3">ğ‘‚</ci></apply><apply id="S3.SS1.p2.7.m7.1.1.3.cmml" xref="S3.SS1.p2.7.m7.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p2.7.m7.1.1.3.1.cmml" xref="S3.SS1.p2.7.m7.1.1.3">superscript</csymbol><ci id="S3.SS1.p2.7.m7.1.1.3.2.cmml" xref="S3.SS1.p2.7.m7.1.1.3.2">â„</ci><apply id="S3.SS1.p2.7.m7.1.1.3.3.cmml" xref="S3.SS1.p2.7.m7.1.1.3.3"><times id="S3.SS1.p2.7.m7.1.1.3.3.1.cmml" xref="S3.SS1.p2.7.m7.1.1.3.3.1"></times><apply id="S3.SS1.p2.7.m7.1.1.3.3.2.cmml" xref="S3.SS1.p2.7.m7.1.1.3.3.2"><csymbol cd="ambiguous" id="S3.SS1.p2.7.m7.1.1.3.3.2.1.cmml" xref="S3.SS1.p2.7.m7.1.1.3.3.2">subscript</csymbol><ci id="S3.SS1.p2.7.m7.1.1.3.3.2.2.cmml" xref="S3.SS1.p2.7.m7.1.1.3.3.2.2">ğ‘›</ci><ci id="S3.SS1.p2.7.m7.1.1.3.3.2.3.cmml" xref="S3.SS1.p2.7.m7.1.1.3.3.2.3">ğ‘£</ci></apply><ci id="S3.SS1.p2.7.m7.1.1.3.3.3.cmml" xref="S3.SS1.p2.7.m7.1.1.3.3.3">ğ‘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.7.m7.1c">v_{O}\in\mathbb{R}^{n_{v}\times N}</annotation></semantics></math> for <math id="S3.SS1.p2.8.m8.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S3.SS1.p2.8.m8.1a"><mi id="S3.SS1.p2.8.m8.1.1" xref="S3.SS1.p2.8.m8.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.8.m8.1b"><ci id="S3.SS1.p2.8.m8.1.1.cmml" xref="S3.SS1.p2.8.m8.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.8.m8.1c">N</annotation></semantics></math> object proposals. We use Faster R-CNN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">Ren etÂ al. (2015)</span></a>]</cite> with ResNet-101 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">He etÂ al. (2016)</span></a>]</cite> backbone and pretrain the object detector on ImageNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">Deng etÂ al. (2009)</span></a>]</cite> and again retrain it on Visual Genome Dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">Krishna etÂ al. (2016)</span></a>]</cite> with class label and attribute features similar to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">Anderson etÂ al. (2018)</span></a>]</cite>.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.6" class="ltx_p"><span id="S3.SS1.p3.6.1" class="ltx_text ltx_font_bold">Bottom-up (BU) Attention:</span> In order to focus on the most relevant features, two bottom-up attention mechanisms are applied during multilevel feature extraction. The image-grid attention is generated using ResNeXt <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">Xie etÂ al. (2016)</span></a>]</cite> pretrained on ImageNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">Deng etÂ al. (2009)</span></a>]</cite> to obtain <math id="S3.SS1.p3.1.m1.1" class="ltx_Math" alttext="v_{I}\in\mathbb{R}^{2048\times 14\times 14}" display="inline"><semantics id="S3.SS1.p3.1.m1.1a"><mrow id="S3.SS1.p3.1.m1.1.1" xref="S3.SS1.p3.1.m1.1.1.cmml"><msub id="S3.SS1.p3.1.m1.1.1.2" xref="S3.SS1.p3.1.m1.1.1.2.cmml"><mi id="S3.SS1.p3.1.m1.1.1.2.2" xref="S3.SS1.p3.1.m1.1.1.2.2.cmml">v</mi><mi id="S3.SS1.p3.1.m1.1.1.2.3" xref="S3.SS1.p3.1.m1.1.1.2.3.cmml">I</mi></msub><mo id="S3.SS1.p3.1.m1.1.1.1" xref="S3.SS1.p3.1.m1.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS1.p3.1.m1.1.1.3" xref="S3.SS1.p3.1.m1.1.1.3.cmml"><mi id="S3.SS1.p3.1.m1.1.1.3.2" xref="S3.SS1.p3.1.m1.1.1.3.2.cmml">â„</mi><mrow id="S3.SS1.p3.1.m1.1.1.3.3" xref="S3.SS1.p3.1.m1.1.1.3.3.cmml"><mn id="S3.SS1.p3.1.m1.1.1.3.3.2" xref="S3.SS1.p3.1.m1.1.1.3.3.2.cmml">2048</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p3.1.m1.1.1.3.3.1" xref="S3.SS1.p3.1.m1.1.1.3.3.1.cmml">Ã—</mo><mn id="S3.SS1.p3.1.m1.1.1.3.3.3" xref="S3.SS1.p3.1.m1.1.1.3.3.3.cmml">14</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p3.1.m1.1.1.3.3.1a" xref="S3.SS1.p3.1.m1.1.1.3.3.1.cmml">Ã—</mo><mn id="S3.SS1.p3.1.m1.1.1.3.3.4" xref="S3.SS1.p3.1.m1.1.1.3.3.4.cmml">14</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.1.m1.1b"><apply id="S3.SS1.p3.1.m1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1"><in id="S3.SS1.p3.1.m1.1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1.1"></in><apply id="S3.SS1.p3.1.m1.1.1.2.cmml" xref="S3.SS1.p3.1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p3.1.m1.1.1.2.1.cmml" xref="S3.SS1.p3.1.m1.1.1.2">subscript</csymbol><ci id="S3.SS1.p3.1.m1.1.1.2.2.cmml" xref="S3.SS1.p3.1.m1.1.1.2.2">ğ‘£</ci><ci id="S3.SS1.p3.1.m1.1.1.2.3.cmml" xref="S3.SS1.p3.1.m1.1.1.2.3">ğ¼</ci></apply><apply id="S3.SS1.p3.1.m1.1.1.3.cmml" xref="S3.SS1.p3.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p3.1.m1.1.1.3.1.cmml" xref="S3.SS1.p3.1.m1.1.1.3">superscript</csymbol><ci id="S3.SS1.p3.1.m1.1.1.3.2.cmml" xref="S3.SS1.p3.1.m1.1.1.3.2">â„</ci><apply id="S3.SS1.p3.1.m1.1.1.3.3.cmml" xref="S3.SS1.p3.1.m1.1.1.3.3"><times id="S3.SS1.p3.1.m1.1.1.3.3.1.cmml" xref="S3.SS1.p3.1.m1.1.1.3.3.1"></times><cn type="integer" id="S3.SS1.p3.1.m1.1.1.3.3.2.cmml" xref="S3.SS1.p3.1.m1.1.1.3.3.2">2048</cn><cn type="integer" id="S3.SS1.p3.1.m1.1.1.3.3.3.cmml" xref="S3.SS1.p3.1.m1.1.1.3.3.3">14</cn><cn type="integer" id="S3.SS1.p3.1.m1.1.1.3.3.4.cmml" xref="S3.SS1.p3.1.m1.1.1.3.3.4">14</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.1.m1.1c">v_{I}\in\mathbb{R}^{2048\times 14\times 14}</annotation></semantics></math>, which represents <math id="S3.SS1.p3.2.m2.1" class="ltx_Math" alttext="2048" display="inline"><semantics id="S3.SS1.p3.2.m2.1a"><mn id="S3.SS1.p3.2.m2.1.1" xref="S3.SS1.p3.2.m2.1.1.cmml">2048</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.2.m2.1b"><cn type="integer" id="S3.SS1.p3.2.m2.1.1.cmml" xref="S3.SS1.p3.2.m2.1.1">2048</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.2.m2.1c">2048</annotation></semantics></math> dimensional features vectors for <math id="S3.SS1.p3.3.m3.1" class="ltx_Math" alttext="G=14\times 14" display="inline"><semantics id="S3.SS1.p3.3.m3.1a"><mrow id="S3.SS1.p3.3.m3.1.1" xref="S3.SS1.p3.3.m3.1.1.cmml"><mi id="S3.SS1.p3.3.m3.1.1.2" xref="S3.SS1.p3.3.m3.1.1.2.cmml">G</mi><mo id="S3.SS1.p3.3.m3.1.1.1" xref="S3.SS1.p3.3.m3.1.1.1.cmml">=</mo><mrow id="S3.SS1.p3.3.m3.1.1.3" xref="S3.SS1.p3.3.m3.1.1.3.cmml"><mn id="S3.SS1.p3.3.m3.1.1.3.2" xref="S3.SS1.p3.3.m3.1.1.3.2.cmml">14</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p3.3.m3.1.1.3.1" xref="S3.SS1.p3.3.m3.1.1.3.1.cmml">Ã—</mo><mn id="S3.SS1.p3.3.m3.1.1.3.3" xref="S3.SS1.p3.3.m3.1.1.3.3.cmml">14</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.3.m3.1b"><apply id="S3.SS1.p3.3.m3.1.1.cmml" xref="S3.SS1.p3.3.m3.1.1"><eq id="S3.SS1.p3.3.m3.1.1.1.cmml" xref="S3.SS1.p3.3.m3.1.1.1"></eq><ci id="S3.SS1.p3.3.m3.1.1.2.cmml" xref="S3.SS1.p3.3.m3.1.1.2">ğº</ci><apply id="S3.SS1.p3.3.m3.1.1.3.cmml" xref="S3.SS1.p3.3.m3.1.1.3"><times id="S3.SS1.p3.3.m3.1.1.3.1.cmml" xref="S3.SS1.p3.3.m3.1.1.3.1"></times><cn type="integer" id="S3.SS1.p3.3.m3.1.1.3.2.cmml" xref="S3.SS1.p3.3.m3.1.1.3.2">14</cn><cn type="integer" id="S3.SS1.p3.3.m3.1.1.3.3.cmml" xref="S3.SS1.p3.3.m3.1.1.3.3">14</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.3.m3.1c">G=14\times 14</annotation></semantics></math> image-grid over the visual input. The size and scale of the image-grid can be changed by using different CNN architecture or taking the output of a different convolutional layer to generate a different sized BU attention. Meanwhile, object proposals are generated in a bottom up fashion to encode object level visual features <math id="S3.SS1.p3.4.m4.1" class="ltx_Math" alttext="v_{O}" display="inline"><semantics id="S3.SS1.p3.4.m4.1a"><msub id="S3.SS1.p3.4.m4.1.1" xref="S3.SS1.p3.4.m4.1.1.cmml"><mi id="S3.SS1.p3.4.m4.1.1.2" xref="S3.SS1.p3.4.m4.1.1.2.cmml">v</mi><mi id="S3.SS1.p3.4.m4.1.1.3" xref="S3.SS1.p3.4.m4.1.1.3.cmml">O</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.4.m4.1b"><apply id="S3.SS1.p3.4.m4.1.1.cmml" xref="S3.SS1.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.4.m4.1.1.1.cmml" xref="S3.SS1.p3.4.m4.1.1">subscript</csymbol><ci id="S3.SS1.p3.4.m4.1.1.2.cmml" xref="S3.SS1.p3.4.m4.1.1.2">ğ‘£</ci><ci id="S3.SS1.p3.4.m4.1.1.3.cmml" xref="S3.SS1.p3.4.m4.1.1.3">ğ‘‚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.4.m4.1c">v_{O}</annotation></semantics></math>. We select a total of top <math id="S3.SS1.p3.5.m5.1" class="ltx_Math" alttext="N=36" display="inline"><semantics id="S3.SS1.p3.5.m5.1a"><mrow id="S3.SS1.p3.5.m5.1.1" xref="S3.SS1.p3.5.m5.1.1.cmml"><mi id="S3.SS1.p3.5.m5.1.1.2" xref="S3.SS1.p3.5.m5.1.1.2.cmml">N</mi><mo id="S3.SS1.p3.5.m5.1.1.1" xref="S3.SS1.p3.5.m5.1.1.1.cmml">=</mo><mn id="S3.SS1.p3.5.m5.1.1.3" xref="S3.SS1.p3.5.m5.1.1.3.cmml">36</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.5.m5.1b"><apply id="S3.SS1.p3.5.m5.1.1.cmml" xref="S3.SS1.p3.5.m5.1.1"><eq id="S3.SS1.p3.5.m5.1.1.1.cmml" xref="S3.SS1.p3.5.m5.1.1.1"></eq><ci id="S3.SS1.p3.5.m5.1.1.2.cmml" xref="S3.SS1.p3.5.m5.1.1.2">ğ‘</ci><cn type="integer" id="S3.SS1.p3.5.m5.1.1.3.cmml" xref="S3.SS1.p3.5.m5.1.1.3">36</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.5.m5.1c">N=36</annotation></semantics></math> object proposals whose <math id="S3.SS1.p3.6.m6.1" class="ltx_Math" alttext="n_{v}=2048" display="inline"><semantics id="S3.SS1.p3.6.m6.1a"><mrow id="S3.SS1.p3.6.m6.1.1" xref="S3.SS1.p3.6.m6.1.1.cmml"><msub id="S3.SS1.p3.6.m6.1.1.2" xref="S3.SS1.p3.6.m6.1.1.2.cmml"><mi id="S3.SS1.p3.6.m6.1.1.2.2" xref="S3.SS1.p3.6.m6.1.1.2.2.cmml">n</mi><mi id="S3.SS1.p3.6.m6.1.1.2.3" xref="S3.SS1.p3.6.m6.1.1.2.3.cmml">v</mi></msub><mo id="S3.SS1.p3.6.m6.1.1.1" xref="S3.SS1.p3.6.m6.1.1.1.cmml">=</mo><mn id="S3.SS1.p3.6.m6.1.1.3" xref="S3.SS1.p3.6.m6.1.1.3.cmml">2048</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.6.m6.1b"><apply id="S3.SS1.p3.6.m6.1.1.cmml" xref="S3.SS1.p3.6.m6.1.1"><eq id="S3.SS1.p3.6.m6.1.1.1.cmml" xref="S3.SS1.p3.6.m6.1.1.1"></eq><apply id="S3.SS1.p3.6.m6.1.1.2.cmml" xref="S3.SS1.p3.6.m6.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p3.6.m6.1.1.2.1.cmml" xref="S3.SS1.p3.6.m6.1.1.2">subscript</csymbol><ci id="S3.SS1.p3.6.m6.1.1.2.2.cmml" xref="S3.SS1.p3.6.m6.1.1.2.2">ğ‘›</ci><ci id="S3.SS1.p3.6.m6.1.1.2.3.cmml" xref="S3.SS1.p3.6.m6.1.1.2.3">ğ‘£</ci></apply><cn type="integer" id="S3.SS1.p3.6.m6.1.1.3.cmml" xref="S3.SS1.p3.6.m6.1.1.3">2048</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.6.m6.1c">n_{v}=2048</annotation></semantics></math> dimensional feature vectors are obtained from the ROI pooling layer in the Region Proposal Network.</p>
</div>
<div id="S3.SS1.p4" class="ltx_para">
<p id="S3.SS1.p4.3" class="ltx_p"><span id="S3.SS1.p4.3.1" class="ltx_text ltx_font_bold">Language features:</span> To represent the questions embedding in an end-to-end framework, GRUs <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">Cho etÂ al. (2014)</span></a>]</cite> are used in a manner similar to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">Fukui etÂ al. (2016)</span></a>, <a href="#bib.bib5" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">Ben-Younes etÂ al. (2017)</span></a>]</cite>. The words in questions are encoded using one-hot-vector representation and embedded into vector space by using a word embedding matrix. The embedded word vectors are fed to the GRU with <math id="S3.SS1.p4.1.m1.1" class="ltx_Math" alttext="n_{q}" display="inline"><semantics id="S3.SS1.p4.1.m1.1a"><msub id="S3.SS1.p4.1.m1.1.1" xref="S3.SS1.p4.1.m1.1.1.cmml"><mi id="S3.SS1.p4.1.m1.1.1.2" xref="S3.SS1.p4.1.m1.1.1.2.cmml">n</mi><mi id="S3.SS1.p4.1.m1.1.1.3" xref="S3.SS1.p4.1.m1.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.1.m1.1b"><apply id="S3.SS1.p4.1.m1.1.1.cmml" xref="S3.SS1.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.1.m1.1.1.1.cmml" xref="S3.SS1.p4.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.p4.1.m1.1.1.2.cmml" xref="S3.SS1.p4.1.m1.1.1.2">ğ‘›</ci><ci id="S3.SS1.p4.1.m1.1.1.3.cmml" xref="S3.SS1.p4.1.m1.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.1.m1.1c">n_{q}</annotation></semantics></math> units initialized with pretrained Skip-thought Vector model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">Kiros etÂ al. (2015)</span></a>]</cite>. The output of the GRU is fine-tuned to get the language feature embedding <math id="S3.SS1.p4.2.m2.3" class="ltx_Math" alttext="q=\{q_{i}\;:\,i\in[1,n_{q}]\}" display="inline"><semantics id="S3.SS1.p4.2.m2.3a"><mrow id="S3.SS1.p4.2.m2.3.3" xref="S3.SS1.p4.2.m2.3.3.cmml"><mi id="S3.SS1.p4.2.m2.3.3.4" xref="S3.SS1.p4.2.m2.3.3.4.cmml">q</mi><mo id="S3.SS1.p4.2.m2.3.3.3" xref="S3.SS1.p4.2.m2.3.3.3.cmml">=</mo><mrow id="S3.SS1.p4.2.m2.3.3.2.2" xref="S3.SS1.p4.2.m2.3.3.2.3.cmml"><mo stretchy="false" id="S3.SS1.p4.2.m2.3.3.2.2.3" xref="S3.SS1.p4.2.m2.3.3.2.3.1.cmml">{</mo><msub id="S3.SS1.p4.2.m2.2.2.1.1.1" xref="S3.SS1.p4.2.m2.2.2.1.1.1.cmml"><mi id="S3.SS1.p4.2.m2.2.2.1.1.1.2" xref="S3.SS1.p4.2.m2.2.2.1.1.1.2.cmml">q</mi><mi id="S3.SS1.p4.2.m2.2.2.1.1.1.3" xref="S3.SS1.p4.2.m2.2.2.1.1.1.3.cmml">i</mi></msub><mo lspace="0.278em" rspace="0.448em" id="S3.SS1.p4.2.m2.3.3.2.2.4" xref="S3.SS1.p4.2.m2.3.3.2.3.1.cmml">:</mo><mrow id="S3.SS1.p4.2.m2.3.3.2.2.2" xref="S3.SS1.p4.2.m2.3.3.2.2.2.cmml"><mi id="S3.SS1.p4.2.m2.3.3.2.2.2.3" xref="S3.SS1.p4.2.m2.3.3.2.2.2.3.cmml">i</mi><mo id="S3.SS1.p4.2.m2.3.3.2.2.2.2" xref="S3.SS1.p4.2.m2.3.3.2.2.2.2.cmml">âˆˆ</mo><mrow id="S3.SS1.p4.2.m2.3.3.2.2.2.1.1" xref="S3.SS1.p4.2.m2.3.3.2.2.2.1.2.cmml"><mo stretchy="false" id="S3.SS1.p4.2.m2.3.3.2.2.2.1.1.2" xref="S3.SS1.p4.2.m2.3.3.2.2.2.1.2.cmml">[</mo><mn id="S3.SS1.p4.2.m2.1.1" xref="S3.SS1.p4.2.m2.1.1.cmml">1</mn><mo id="S3.SS1.p4.2.m2.3.3.2.2.2.1.1.3" xref="S3.SS1.p4.2.m2.3.3.2.2.2.1.2.cmml">,</mo><msub id="S3.SS1.p4.2.m2.3.3.2.2.2.1.1.1" xref="S3.SS1.p4.2.m2.3.3.2.2.2.1.1.1.cmml"><mi id="S3.SS1.p4.2.m2.3.3.2.2.2.1.1.1.2" xref="S3.SS1.p4.2.m2.3.3.2.2.2.1.1.1.2.cmml">n</mi><mi id="S3.SS1.p4.2.m2.3.3.2.2.2.1.1.1.3" xref="S3.SS1.p4.2.m2.3.3.2.2.2.1.1.1.3.cmml">q</mi></msub><mo stretchy="false" id="S3.SS1.p4.2.m2.3.3.2.2.2.1.1.4" xref="S3.SS1.p4.2.m2.3.3.2.2.2.1.2.cmml">]</mo></mrow></mrow><mo stretchy="false" id="S3.SS1.p4.2.m2.3.3.2.2.5" xref="S3.SS1.p4.2.m2.3.3.2.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.2.m2.3b"><apply id="S3.SS1.p4.2.m2.3.3.cmml" xref="S3.SS1.p4.2.m2.3.3"><eq id="S3.SS1.p4.2.m2.3.3.3.cmml" xref="S3.SS1.p4.2.m2.3.3.3"></eq><ci id="S3.SS1.p4.2.m2.3.3.4.cmml" xref="S3.SS1.p4.2.m2.3.3.4">ğ‘</ci><apply id="S3.SS1.p4.2.m2.3.3.2.3.cmml" xref="S3.SS1.p4.2.m2.3.3.2.2"><csymbol cd="latexml" id="S3.SS1.p4.2.m2.3.3.2.3.1.cmml" xref="S3.SS1.p4.2.m2.3.3.2.2.3">conditional-set</csymbol><apply id="S3.SS1.p4.2.m2.2.2.1.1.1.cmml" xref="S3.SS1.p4.2.m2.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.2.m2.2.2.1.1.1.1.cmml" xref="S3.SS1.p4.2.m2.2.2.1.1.1">subscript</csymbol><ci id="S3.SS1.p4.2.m2.2.2.1.1.1.2.cmml" xref="S3.SS1.p4.2.m2.2.2.1.1.1.2">ğ‘</ci><ci id="S3.SS1.p4.2.m2.2.2.1.1.1.3.cmml" xref="S3.SS1.p4.2.m2.2.2.1.1.1.3">ğ‘–</ci></apply><apply id="S3.SS1.p4.2.m2.3.3.2.2.2.cmml" xref="S3.SS1.p4.2.m2.3.3.2.2.2"><in id="S3.SS1.p4.2.m2.3.3.2.2.2.2.cmml" xref="S3.SS1.p4.2.m2.3.3.2.2.2.2"></in><ci id="S3.SS1.p4.2.m2.3.3.2.2.2.3.cmml" xref="S3.SS1.p4.2.m2.3.3.2.2.2.3">ğ‘–</ci><interval closure="closed" id="S3.SS1.p4.2.m2.3.3.2.2.2.1.2.cmml" xref="S3.SS1.p4.2.m2.3.3.2.2.2.1.1"><cn type="integer" id="S3.SS1.p4.2.m2.1.1.cmml" xref="S3.SS1.p4.2.m2.1.1">1</cn><apply id="S3.SS1.p4.2.m2.3.3.2.2.2.1.1.1.cmml" xref="S3.SS1.p4.2.m2.3.3.2.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.2.m2.3.3.2.2.2.1.1.1.1.cmml" xref="S3.SS1.p4.2.m2.3.3.2.2.2.1.1.1">subscript</csymbol><ci id="S3.SS1.p4.2.m2.3.3.2.2.2.1.1.1.2.cmml" xref="S3.SS1.p4.2.m2.3.3.2.2.2.1.1.1.2">ğ‘›</ci><ci id="S3.SS1.p4.2.m2.3.3.2.2.2.1.1.1.3.cmml" xref="S3.SS1.p4.2.m2.3.3.2.2.2.1.1.1.3">ğ‘</ci></apply></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.2.m2.3c">q=\{q_{i}\;:\,i\in[1,n_{q}]\}</annotation></semantics></math> where <math id="S3.SS1.p4.3.m3.1" class="ltx_Math" alttext="n_{q}=2400" display="inline"><semantics id="S3.SS1.p4.3.m3.1a"><mrow id="S3.SS1.p4.3.m3.1.1" xref="S3.SS1.p4.3.m3.1.1.cmml"><msub id="S3.SS1.p4.3.m3.1.1.2" xref="S3.SS1.p4.3.m3.1.1.2.cmml"><mi id="S3.SS1.p4.3.m3.1.1.2.2" xref="S3.SS1.p4.3.m3.1.1.2.2.cmml">n</mi><mi id="S3.SS1.p4.3.m3.1.1.2.3" xref="S3.SS1.p4.3.m3.1.1.2.3.cmml">q</mi></msub><mo id="S3.SS1.p4.3.m3.1.1.1" xref="S3.SS1.p4.3.m3.1.1.1.cmml">=</mo><mn id="S3.SS1.p4.3.m3.1.1.3" xref="S3.SS1.p4.3.m3.1.1.3.cmml">2400</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.3.m3.1b"><apply id="S3.SS1.p4.3.m3.1.1.cmml" xref="S3.SS1.p4.3.m3.1.1"><eq id="S3.SS1.p4.3.m3.1.1.1.cmml" xref="S3.SS1.p4.3.m3.1.1.1"></eq><apply id="S3.SS1.p4.3.m3.1.1.2.cmml" xref="S3.SS1.p4.3.m3.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p4.3.m3.1.1.2.1.cmml" xref="S3.SS1.p4.3.m3.1.1.2">subscript</csymbol><ci id="S3.SS1.p4.3.m3.1.1.2.2.cmml" xref="S3.SS1.p4.3.m3.1.1.2.2">ğ‘›</ci><ci id="S3.SS1.p4.3.m3.1.1.2.3.cmml" xref="S3.SS1.p4.3.m3.1.1.2.3">ğ‘</ci></apply><cn type="integer" id="S3.SS1.p4.3.m3.1.1.3.cmml" xref="S3.SS1.p4.3.m3.1.1.3">2400</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.3.m3.1c">n_{q}=2400</annotation></semantics></math>. The language feature embedding is used to further refine the spatial visual features (i.e. image-grid and object level) by incorporating top-down attention discussed in Section <a href="#S3.SS2" title="3.2 Hierarchical Attention Fusion â€£ 3 Methods â€£ Reciprocal Attention Fusion for Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a>.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Hierarchical Attention Fusion</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.4" class="ltx_p">The hierarchical attention mechanism takes spatial visual features <math id="S3.SS2.p1.1.m1.2" class="ltx_Math" alttext="v_{I},v_{O}" display="inline"><semantics id="S3.SS2.p1.1.m1.2a"><mrow id="S3.SS2.p1.1.m1.2.2.2" xref="S3.SS2.p1.1.m1.2.2.3.cmml"><msub id="S3.SS2.p1.1.m1.1.1.1.1" xref="S3.SS2.p1.1.m1.1.1.1.1.cmml"><mi id="S3.SS2.p1.1.m1.1.1.1.1.2" xref="S3.SS2.p1.1.m1.1.1.1.1.2.cmml">v</mi><mi id="S3.SS2.p1.1.m1.1.1.1.1.3" xref="S3.SS2.p1.1.m1.1.1.1.1.3.cmml">I</mi></msub><mo id="S3.SS2.p1.1.m1.2.2.2.3" xref="S3.SS2.p1.1.m1.2.2.3.cmml">,</mo><msub id="S3.SS2.p1.1.m1.2.2.2.2" xref="S3.SS2.p1.1.m1.2.2.2.2.cmml"><mi id="S3.SS2.p1.1.m1.2.2.2.2.2" xref="S3.SS2.p1.1.m1.2.2.2.2.2.cmml">v</mi><mi id="S3.SS2.p1.1.m1.2.2.2.2.3" xref="S3.SS2.p1.1.m1.2.2.2.2.3.cmml">O</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.2b"><list id="S3.SS2.p1.1.m1.2.2.3.cmml" xref="S3.SS2.p1.1.m1.2.2.2"><apply id="S3.SS2.p1.1.m1.1.1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.1.m1.1.1.1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p1.1.m1.1.1.1.1.2.cmml" xref="S3.SS2.p1.1.m1.1.1.1.1.2">ğ‘£</ci><ci id="S3.SS2.p1.1.m1.1.1.1.1.3.cmml" xref="S3.SS2.p1.1.m1.1.1.1.1.3">ğ¼</ci></apply><apply id="S3.SS2.p1.1.m1.2.2.2.2.cmml" xref="S3.SS2.p1.1.m1.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p1.1.m1.2.2.2.2.1.cmml" xref="S3.SS2.p1.1.m1.2.2.2.2">subscript</csymbol><ci id="S3.SS2.p1.1.m1.2.2.2.2.2.cmml" xref="S3.SS2.p1.1.m1.2.2.2.2.2">ğ‘£</ci><ci id="S3.SS2.p1.1.m1.2.2.2.2.3.cmml" xref="S3.SS2.p1.1.m1.2.2.2.2.3">ğ‘‚</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.2c">v_{I},v_{O}</annotation></semantics></math> and language feature <math id="S3.SS2.p1.2.m2.1" class="ltx_Math" alttext="q" display="inline"><semantics id="S3.SS2.p1.2.m2.1a"><mi id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><ci id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">q</annotation></semantics></math> as input and a learns multi-modal representation <math id="S3.SS2.p1.3.m3.1" class="ltx_Math" alttext="W" display="inline"><semantics id="S3.SS2.p1.3.m3.1a"><mi id="S3.SS2.p1.3.m3.1.1" xref="S3.SS2.p1.3.m3.1.1.cmml">W</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.3.m3.1b"><ci id="S3.SS2.p1.3.m3.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1">ğ‘Š</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.3.m3.1c">W</annotation></semantics></math> to predict answer embedding <math id="S3.SS2.p1.4.m4.1" class="ltx_Math" alttext="\rho" display="inline"><semantics id="S3.SS2.p1.4.m4.1a"><mi id="S3.SS2.p1.4.m4.1.1" xref="S3.SS2.p1.4.m4.1.1.cmml">Ï</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.4.m4.1b"><ci id="S3.SS2.p1.4.m4.1.1.cmml" xref="S3.SS2.p1.4.m4.1.1">ğœŒ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.4.m4.1c">\rho</annotation></semantics></math>. This step can be formulated as an outer product of the multi-modal representation, visual and language embeddings as follows:</p>
<table id="S3.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E2.m1.1" class="ltx_Math" alttext="\rho=W\times_{1}\ q\ \times_{2}\ v," display="block"><semantics id="S3.E2.m1.1a"><mrow id="S3.E2.m1.1.1.1" xref="S3.E2.m1.1.1.1.1.cmml"><mrow id="S3.E2.m1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.cmml"><mi id="S3.E2.m1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.2.cmml">Ï</mi><mo id="S3.E2.m1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.cmml">=</mo><mrow id="S3.E2.m1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.3.cmml"><mrow id="S3.E2.m1.1.1.1.1.3.2" xref="S3.E2.m1.1.1.1.1.3.2.cmml"><mi id="S3.E2.m1.1.1.1.1.3.2.2" xref="S3.E2.m1.1.1.1.1.3.2.2.cmml">W</mi><msub id="S3.E2.m1.1.1.1.1.3.2.1" xref="S3.E2.m1.1.1.1.1.3.2.1.cmml"><mo lspace="0.222em" rspace="0.222em" id="S3.E2.m1.1.1.1.1.3.2.1.2" xref="S3.E2.m1.1.1.1.1.3.2.1.2.cmml">Ã—</mo><mn id="S3.E2.m1.1.1.1.1.3.2.1.3" xref="S3.E2.m1.1.1.1.1.3.2.1.3.cmml">1</mn></msub><mi id="S3.E2.m1.1.1.1.1.3.2.3" xref="S3.E2.m1.1.1.1.1.3.2.3.cmml">q</mi></mrow><msub id="S3.E2.m1.1.1.1.1.3.1" xref="S3.E2.m1.1.1.1.1.3.1.cmml"><mo lspace="0.722em" rspace="0.222em" id="S3.E2.m1.1.1.1.1.3.1.2" xref="S3.E2.m1.1.1.1.1.3.1.2.cmml">Ã—</mo><mn id="S3.E2.m1.1.1.1.1.3.1.3" xref="S3.E2.m1.1.1.1.1.3.1.3.cmml">2</mn></msub><mi id="S3.E2.m1.1.1.1.1.3.3" xref="S3.E2.m1.1.1.1.1.3.3.cmml">v</mi></mrow></mrow><mo id="S3.E2.m1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.1b"><apply id="S3.E2.m1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1"><eq id="S3.E2.m1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1"></eq><ci id="S3.E2.m1.1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.1.2">ğœŒ</ci><apply id="S3.E2.m1.1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.1.3"><apply id="S3.E2.m1.1.1.1.1.3.1.cmml" xref="S3.E2.m1.1.1.1.1.3.1"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.3.1.1.cmml" xref="S3.E2.m1.1.1.1.1.3.1">subscript</csymbol><times id="S3.E2.m1.1.1.1.1.3.1.2.cmml" xref="S3.E2.m1.1.1.1.1.3.1.2"></times><cn type="integer" id="S3.E2.m1.1.1.1.1.3.1.3.cmml" xref="S3.E2.m1.1.1.1.1.3.1.3">2</cn></apply><apply id="S3.E2.m1.1.1.1.1.3.2.cmml" xref="S3.E2.m1.1.1.1.1.3.2"><apply id="S3.E2.m1.1.1.1.1.3.2.1.cmml" xref="S3.E2.m1.1.1.1.1.3.2.1"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.3.2.1.1.cmml" xref="S3.E2.m1.1.1.1.1.3.2.1">subscript</csymbol><times id="S3.E2.m1.1.1.1.1.3.2.1.2.cmml" xref="S3.E2.m1.1.1.1.1.3.2.1.2"></times><cn type="integer" id="S3.E2.m1.1.1.1.1.3.2.1.3.cmml" xref="S3.E2.m1.1.1.1.1.3.2.1.3">1</cn></apply><ci id="S3.E2.m1.1.1.1.1.3.2.2.cmml" xref="S3.E2.m1.1.1.1.1.3.2.2">ğ‘Š</ci><ci id="S3.E2.m1.1.1.1.1.3.2.3.cmml" xref="S3.E2.m1.1.1.1.1.3.2.3">ğ‘</ci></apply><ci id="S3.E2.m1.1.1.1.1.3.3.cmml" xref="S3.E2.m1.1.1.1.1.3.3">ğ‘£</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.1c">\rho=W\times_{1}\ q\ \times_{2}\ v,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S3.SS2.p1.7" class="ltx_p">where, <math id="S3.SS2.p1.5.m1.1" class="ltx_Math" alttext="\times_{n}" display="inline"><semantics id="S3.SS2.p1.5.m1.1a"><msub id="S3.SS2.p1.5.m1.1.1" xref="S3.SS2.p1.5.m1.1.1.cmml"><mo id="S3.SS2.p1.5.m1.1.1.2" xref="S3.SS2.p1.5.m1.1.1.2.cmml">Ã—</mo><mi id="S3.SS2.p1.5.m1.1.1.3" xref="S3.SS2.p1.5.m1.1.1.3.cmml">n</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.5.m1.1b"><apply id="S3.SS2.p1.5.m1.1.1.cmml" xref="S3.SS2.p1.5.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.5.m1.1.1.1.cmml" xref="S3.SS2.p1.5.m1.1.1">subscript</csymbol><times id="S3.SS2.p1.5.m1.1.1.2.cmml" xref="S3.SS2.p1.5.m1.1.1.2"></times><ci id="S3.SS2.p1.5.m1.1.1.3.cmml" xref="S3.SS2.p1.5.m1.1.1.3">ğ‘›</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.5.m1.1c">\times_{n}</annotation></semantics></math> denotes n-mode tensor-matrix product. However, this approach has some serious practical limitations in terms of learnable parameters for <math id="S3.SS2.p1.6.m2.1" class="ltx_Math" alttext="W\in\mathbb{R}^{n_{v}\times n_{q}\times n_{\rho}}" display="inline"><semantics id="S3.SS2.p1.6.m2.1a"><mrow id="S3.SS2.p1.6.m2.1.1" xref="S3.SS2.p1.6.m2.1.1.cmml"><mi id="S3.SS2.p1.6.m2.1.1.2" xref="S3.SS2.p1.6.m2.1.1.2.cmml">W</mi><mo id="S3.SS2.p1.6.m2.1.1.1" xref="S3.SS2.p1.6.m2.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS2.p1.6.m2.1.1.3" xref="S3.SS2.p1.6.m2.1.1.3.cmml"><mi id="S3.SS2.p1.6.m2.1.1.3.2" xref="S3.SS2.p1.6.m2.1.1.3.2.cmml">â„</mi><mrow id="S3.SS2.p1.6.m2.1.1.3.3" xref="S3.SS2.p1.6.m2.1.1.3.3.cmml"><msub id="S3.SS2.p1.6.m2.1.1.3.3.2" xref="S3.SS2.p1.6.m2.1.1.3.3.2.cmml"><mi id="S3.SS2.p1.6.m2.1.1.3.3.2.2" xref="S3.SS2.p1.6.m2.1.1.3.3.2.2.cmml">n</mi><mi id="S3.SS2.p1.6.m2.1.1.3.3.2.3" xref="S3.SS2.p1.6.m2.1.1.3.3.2.3.cmml">v</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p1.6.m2.1.1.3.3.1" xref="S3.SS2.p1.6.m2.1.1.3.3.1.cmml">Ã—</mo><msub id="S3.SS2.p1.6.m2.1.1.3.3.3" xref="S3.SS2.p1.6.m2.1.1.3.3.3.cmml"><mi id="S3.SS2.p1.6.m2.1.1.3.3.3.2" xref="S3.SS2.p1.6.m2.1.1.3.3.3.2.cmml">n</mi><mi id="S3.SS2.p1.6.m2.1.1.3.3.3.3" xref="S3.SS2.p1.6.m2.1.1.3.3.3.3.cmml">q</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p1.6.m2.1.1.3.3.1a" xref="S3.SS2.p1.6.m2.1.1.3.3.1.cmml">Ã—</mo><msub id="S3.SS2.p1.6.m2.1.1.3.3.4" xref="S3.SS2.p1.6.m2.1.1.3.3.4.cmml"><mi id="S3.SS2.p1.6.m2.1.1.3.3.4.2" xref="S3.SS2.p1.6.m2.1.1.3.3.4.2.cmml">n</mi><mi id="S3.SS2.p1.6.m2.1.1.3.3.4.3" xref="S3.SS2.p1.6.m2.1.1.3.3.4.3.cmml">Ï</mi></msub></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.6.m2.1b"><apply id="S3.SS2.p1.6.m2.1.1.cmml" xref="S3.SS2.p1.6.m2.1.1"><in id="S3.SS2.p1.6.m2.1.1.1.cmml" xref="S3.SS2.p1.6.m2.1.1.1"></in><ci id="S3.SS2.p1.6.m2.1.1.2.cmml" xref="S3.SS2.p1.6.m2.1.1.2">ğ‘Š</ci><apply id="S3.SS2.p1.6.m2.1.1.3.cmml" xref="S3.SS2.p1.6.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p1.6.m2.1.1.3.1.cmml" xref="S3.SS2.p1.6.m2.1.1.3">superscript</csymbol><ci id="S3.SS2.p1.6.m2.1.1.3.2.cmml" xref="S3.SS2.p1.6.m2.1.1.3.2">â„</ci><apply id="S3.SS2.p1.6.m2.1.1.3.3.cmml" xref="S3.SS2.p1.6.m2.1.1.3.3"><times id="S3.SS2.p1.6.m2.1.1.3.3.1.cmml" xref="S3.SS2.p1.6.m2.1.1.3.3.1"></times><apply id="S3.SS2.p1.6.m2.1.1.3.3.2.cmml" xref="S3.SS2.p1.6.m2.1.1.3.3.2"><csymbol cd="ambiguous" id="S3.SS2.p1.6.m2.1.1.3.3.2.1.cmml" xref="S3.SS2.p1.6.m2.1.1.3.3.2">subscript</csymbol><ci id="S3.SS2.p1.6.m2.1.1.3.3.2.2.cmml" xref="S3.SS2.p1.6.m2.1.1.3.3.2.2">ğ‘›</ci><ci id="S3.SS2.p1.6.m2.1.1.3.3.2.3.cmml" xref="S3.SS2.p1.6.m2.1.1.3.3.2.3">ğ‘£</ci></apply><apply id="S3.SS2.p1.6.m2.1.1.3.3.3.cmml" xref="S3.SS2.p1.6.m2.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.SS2.p1.6.m2.1.1.3.3.3.1.cmml" xref="S3.SS2.p1.6.m2.1.1.3.3.3">subscript</csymbol><ci id="S3.SS2.p1.6.m2.1.1.3.3.3.2.cmml" xref="S3.SS2.p1.6.m2.1.1.3.3.3.2">ğ‘›</ci><ci id="S3.SS2.p1.6.m2.1.1.3.3.3.3.cmml" xref="S3.SS2.p1.6.m2.1.1.3.3.3.3">ğ‘</ci></apply><apply id="S3.SS2.p1.6.m2.1.1.3.3.4.cmml" xref="S3.SS2.p1.6.m2.1.1.3.3.4"><csymbol cd="ambiguous" id="S3.SS2.p1.6.m2.1.1.3.3.4.1.cmml" xref="S3.SS2.p1.6.m2.1.1.3.3.4">subscript</csymbol><ci id="S3.SS2.p1.6.m2.1.1.3.3.4.2.cmml" xref="S3.SS2.p1.6.m2.1.1.3.3.4.2">ğ‘›</ci><ci id="S3.SS2.p1.6.m2.1.1.3.3.4.3.cmml" xref="S3.SS2.p1.6.m2.1.1.3.3.4.3">ğœŒ</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.6.m2.1c">W\in\mathbb{R}^{n_{v}\times n_{q}\times n_{\rho}}</annotation></semantics></math> as the visual and language feature are very high dimensional, which results in huge computational and memory requirements. To counter this problem, our model employs a multi-modal fusion operation <math id="S3.SS2.p1.7.m3.2" class="ltx_Math" alttext="\tau(v,q)" display="inline"><semantics id="S3.SS2.p1.7.m3.2a"><mrow id="S3.SS2.p1.7.m3.2.3" xref="S3.SS2.p1.7.m3.2.3.cmml"><mi id="S3.SS2.p1.7.m3.2.3.2" xref="S3.SS2.p1.7.m3.2.3.2.cmml">Ï„</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p1.7.m3.2.3.1" xref="S3.SS2.p1.7.m3.2.3.1.cmml">â€‹</mo><mrow id="S3.SS2.p1.7.m3.2.3.3.2" xref="S3.SS2.p1.7.m3.2.3.3.1.cmml"><mo stretchy="false" id="S3.SS2.p1.7.m3.2.3.3.2.1" xref="S3.SS2.p1.7.m3.2.3.3.1.cmml">(</mo><mi id="S3.SS2.p1.7.m3.1.1" xref="S3.SS2.p1.7.m3.1.1.cmml">v</mi><mo id="S3.SS2.p1.7.m3.2.3.3.2.2" xref="S3.SS2.p1.7.m3.2.3.3.1.cmml">,</mo><mi id="S3.SS2.p1.7.m3.2.2" xref="S3.SS2.p1.7.m3.2.2.cmml">q</mi><mo stretchy="false" id="S3.SS2.p1.7.m3.2.3.3.2.3" xref="S3.SS2.p1.7.m3.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.7.m3.2b"><apply id="S3.SS2.p1.7.m3.2.3.cmml" xref="S3.SS2.p1.7.m3.2.3"><times id="S3.SS2.p1.7.m3.2.3.1.cmml" xref="S3.SS2.p1.7.m3.2.3.1"></times><ci id="S3.SS2.p1.7.m3.2.3.2.cmml" xref="S3.SS2.p1.7.m3.2.3.2">ğœ</ci><interval closure="open" id="S3.SS2.p1.7.m3.2.3.3.1.cmml" xref="S3.SS2.p1.7.m3.2.3.3.2"><ci id="S3.SS2.p1.7.m3.1.1.cmml" xref="S3.SS2.p1.7.m3.1.1">ğ‘£</ci><ci id="S3.SS2.p1.7.m3.2.2.cmml" xref="S3.SS2.p1.7.m3.2.2">ğ‘</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.7.m3.2c">\tau(v,q)</annotation></semantics></math> to encode the relationships between these two modalities, which is discussed next.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.4" class="ltx_p"><span id="S3.SS2.p2.4.1" class="ltx_text ltx_font_bold">Multi-modal Fusion:</span>
Multi-modal fusion aims to reduce the number of free parameters in tensor <math id="S3.SS2.p2.1.m1.1" class="ltx_Math" alttext="W\in\mathbb{R}^{n_{v}\times n_{q}\times n_{\rho}}" display="inline"><semantics id="S3.SS2.p2.1.m1.1a"><mrow id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml"><mi id="S3.SS2.p2.1.m1.1.1.2" xref="S3.SS2.p2.1.m1.1.1.2.cmml">W</mi><mo id="S3.SS2.p2.1.m1.1.1.1" xref="S3.SS2.p2.1.m1.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS2.p2.1.m1.1.1.3" xref="S3.SS2.p2.1.m1.1.1.3.cmml"><mi id="S3.SS2.p2.1.m1.1.1.3.2" xref="S3.SS2.p2.1.m1.1.1.3.2.cmml">â„</mi><mrow id="S3.SS2.p2.1.m1.1.1.3.3" xref="S3.SS2.p2.1.m1.1.1.3.3.cmml"><msub id="S3.SS2.p2.1.m1.1.1.3.3.2" xref="S3.SS2.p2.1.m1.1.1.3.3.2.cmml"><mi id="S3.SS2.p2.1.m1.1.1.3.3.2.2" xref="S3.SS2.p2.1.m1.1.1.3.3.2.2.cmml">n</mi><mi id="S3.SS2.p2.1.m1.1.1.3.3.2.3" xref="S3.SS2.p2.1.m1.1.1.3.3.2.3.cmml">v</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p2.1.m1.1.1.3.3.1" xref="S3.SS2.p2.1.m1.1.1.3.3.1.cmml">Ã—</mo><msub id="S3.SS2.p2.1.m1.1.1.3.3.3" xref="S3.SS2.p2.1.m1.1.1.3.3.3.cmml"><mi id="S3.SS2.p2.1.m1.1.1.3.3.3.2" xref="S3.SS2.p2.1.m1.1.1.3.3.3.2.cmml">n</mi><mi id="S3.SS2.p2.1.m1.1.1.3.3.3.3" xref="S3.SS2.p2.1.m1.1.1.3.3.3.3.cmml">q</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p2.1.m1.1.1.3.3.1a" xref="S3.SS2.p2.1.m1.1.1.3.3.1.cmml">Ã—</mo><msub id="S3.SS2.p2.1.m1.1.1.3.3.4" xref="S3.SS2.p2.1.m1.1.1.3.3.4.cmml"><mi id="S3.SS2.p2.1.m1.1.1.3.3.4.2" xref="S3.SS2.p2.1.m1.1.1.3.3.4.2.cmml">n</mi><mi id="S3.SS2.p2.1.m1.1.1.3.3.4.3" xref="S3.SS2.p2.1.m1.1.1.3.3.4.3.cmml">Ï</mi></msub></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><apply id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1"><in id="S3.SS2.p2.1.m1.1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1.1"></in><ci id="S3.SS2.p2.1.m1.1.1.2.cmml" xref="S3.SS2.p2.1.m1.1.1.2">ğ‘Š</ci><apply id="S3.SS2.p2.1.m1.1.1.3.cmml" xref="S3.SS2.p2.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p2.1.m1.1.1.3.1.cmml" xref="S3.SS2.p2.1.m1.1.1.3">superscript</csymbol><ci id="S3.SS2.p2.1.m1.1.1.3.2.cmml" xref="S3.SS2.p2.1.m1.1.1.3.2">â„</ci><apply id="S3.SS2.p2.1.m1.1.1.3.3.cmml" xref="S3.SS2.p2.1.m1.1.1.3.3"><times id="S3.SS2.p2.1.m1.1.1.3.3.1.cmml" xref="S3.SS2.p2.1.m1.1.1.3.3.1"></times><apply id="S3.SS2.p2.1.m1.1.1.3.3.2.cmml" xref="S3.SS2.p2.1.m1.1.1.3.3.2"><csymbol cd="ambiguous" id="S3.SS2.p2.1.m1.1.1.3.3.2.1.cmml" xref="S3.SS2.p2.1.m1.1.1.3.3.2">subscript</csymbol><ci id="S3.SS2.p2.1.m1.1.1.3.3.2.2.cmml" xref="S3.SS2.p2.1.m1.1.1.3.3.2.2">ğ‘›</ci><ci id="S3.SS2.p2.1.m1.1.1.3.3.2.3.cmml" xref="S3.SS2.p2.1.m1.1.1.3.3.2.3">ğ‘£</ci></apply><apply id="S3.SS2.p2.1.m1.1.1.3.3.3.cmml" xref="S3.SS2.p2.1.m1.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.SS2.p2.1.m1.1.1.3.3.3.1.cmml" xref="S3.SS2.p2.1.m1.1.1.3.3.3">subscript</csymbol><ci id="S3.SS2.p2.1.m1.1.1.3.3.3.2.cmml" xref="S3.SS2.p2.1.m1.1.1.3.3.3.2">ğ‘›</ci><ci id="S3.SS2.p2.1.m1.1.1.3.3.3.3.cmml" xref="S3.SS2.p2.1.m1.1.1.3.3.3.3">ğ‘</ci></apply><apply id="S3.SS2.p2.1.m1.1.1.3.3.4.cmml" xref="S3.SS2.p2.1.m1.1.1.3.3.4"><csymbol cd="ambiguous" id="S3.SS2.p2.1.m1.1.1.3.3.4.1.cmml" xref="S3.SS2.p2.1.m1.1.1.3.3.4">subscript</csymbol><ci id="S3.SS2.p2.1.m1.1.1.3.3.4.2.cmml" xref="S3.SS2.p2.1.m1.1.1.3.3.4.2">ğ‘›</ci><ci id="S3.SS2.p2.1.m1.1.1.3.3.4.3.cmml" xref="S3.SS2.p2.1.m1.1.1.3.3.4.3">ğœŒ</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">W\in\mathbb{R}^{n_{v}\times n_{q}\times n_{\rho}}</annotation></semantics></math> for a fully parameterized VQA bilinear model. Our model achieves this by using Tucker Decomposition <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">Tucker (1966)</span></a>]</cite> which is a special case of higher-order principal component analysis to express <math id="S3.SS2.p2.2.m2.1" class="ltx_Math" alttext="W" display="inline"><semantics id="S3.SS2.p2.2.m2.1a"><mi id="S3.SS2.p2.2.m2.1.1" xref="S3.SS2.p2.2.m2.1.1.cmml">W</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m2.1b"><ci id="S3.SS2.p2.2.m2.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1">ğ‘Š</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.m2.1c">W</annotation></semantics></math> as a core tensor <math id="S3.SS2.p2.3.m3.1" class="ltx_Math" alttext="T_{c}" display="inline"><semantics id="S3.SS2.p2.3.m3.1a"><msub id="S3.SS2.p2.3.m3.1.1" xref="S3.SS2.p2.3.m3.1.1.cmml"><mi id="S3.SS2.p2.3.m3.1.1.2" xref="S3.SS2.p2.3.m3.1.1.2.cmml">T</mi><mi id="S3.SS2.p2.3.m3.1.1.3" xref="S3.SS2.p2.3.m3.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.3.m3.1b"><apply id="S3.SS2.p2.3.m3.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.3.m3.1.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1">subscript</csymbol><ci id="S3.SS2.p2.3.m3.1.1.2.cmml" xref="S3.SS2.p2.3.m3.1.1.2">ğ‘‡</ci><ci id="S3.SS2.p2.3.m3.1.1.3.cmml" xref="S3.SS2.p2.3.m3.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.3.m3.1c">T_{c}</annotation></semantics></math> multiplied by a matrix along input mode. The decomposed tensors are fused in a manner similar to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">Ben-Younes etÂ al. (2017)</span></a>]</cite> that encompass the multi-modal relationship between language and vision domain. The tensor <math id="S3.SS2.p2.4.m4.1" class="ltx_Math" alttext="W" display="inline"><semantics id="S3.SS2.p2.4.m4.1a"><mi id="S3.SS2.p2.4.m4.1.1" xref="S3.SS2.p2.4.m4.1.1.cmml">W</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.4.m4.1b"><ci id="S3.SS2.p2.4.m4.1.1.cmml" xref="S3.SS2.p2.4.m4.1.1">ğ‘Š</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.4.m4.1c">W</annotation></semantics></math> can be approximated as:</p>
<table id="S3.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E3.m1.1" class="ltx_Math" alttext="W\approx T_{c}\times_{1}T_{q}\times_{2}T_{v}\times_{3}T_{\rho}=[\![T_{c};T_{q},T_{v},T_{\rho}]\!]" display="block"><semantics id="S3.E3.m1.1a"><mrow id="S3.E3.m1.1.1" xref="S3.E3.m1.1.1.cmml"><mi id="S3.E3.m1.1.1.3" xref="S3.E3.m1.1.1.3.cmml">W</mi><mo id="S3.E3.m1.1.1.4" xref="S3.E3.m1.1.1.4.cmml">â‰ˆ</mo><mrow id="S3.E3.m1.1.1.5" xref="S3.E3.m1.1.1.5.cmml"><mrow id="S3.E3.m1.1.1.5.2" xref="S3.E3.m1.1.1.5.2.cmml"><mrow id="S3.E3.m1.1.1.5.2.2" xref="S3.E3.m1.1.1.5.2.2.cmml"><msub id="S3.E3.m1.1.1.5.2.2.2" xref="S3.E3.m1.1.1.5.2.2.2.cmml"><mi id="S3.E3.m1.1.1.5.2.2.2.2" xref="S3.E3.m1.1.1.5.2.2.2.2.cmml">T</mi><mi id="S3.E3.m1.1.1.5.2.2.2.3" xref="S3.E3.m1.1.1.5.2.2.2.3.cmml">c</mi></msub><msub id="S3.E3.m1.1.1.5.2.2.1" xref="S3.E3.m1.1.1.5.2.2.1.cmml"><mo lspace="0.222em" rspace="0.222em" id="S3.E3.m1.1.1.5.2.2.1.2" xref="S3.E3.m1.1.1.5.2.2.1.2.cmml">Ã—</mo><mn id="S3.E3.m1.1.1.5.2.2.1.3" xref="S3.E3.m1.1.1.5.2.2.1.3.cmml">1</mn></msub><msub id="S3.E3.m1.1.1.5.2.2.3" xref="S3.E3.m1.1.1.5.2.2.3.cmml"><mi id="S3.E3.m1.1.1.5.2.2.3.2" xref="S3.E3.m1.1.1.5.2.2.3.2.cmml">T</mi><mi id="S3.E3.m1.1.1.5.2.2.3.3" xref="S3.E3.m1.1.1.5.2.2.3.3.cmml">q</mi></msub></mrow><msub id="S3.E3.m1.1.1.5.2.1" xref="S3.E3.m1.1.1.5.2.1.cmml"><mo lspace="0.222em" rspace="0.222em" id="S3.E3.m1.1.1.5.2.1.2" xref="S3.E3.m1.1.1.5.2.1.2.cmml">Ã—</mo><mn id="S3.E3.m1.1.1.5.2.1.3" xref="S3.E3.m1.1.1.5.2.1.3.cmml">2</mn></msub><msub id="S3.E3.m1.1.1.5.2.3" xref="S3.E3.m1.1.1.5.2.3.cmml"><mi id="S3.E3.m1.1.1.5.2.3.2" xref="S3.E3.m1.1.1.5.2.3.2.cmml">T</mi><mi id="S3.E3.m1.1.1.5.2.3.3" xref="S3.E3.m1.1.1.5.2.3.3.cmml">v</mi></msub></mrow><msub id="S3.E3.m1.1.1.5.1" xref="S3.E3.m1.1.1.5.1.cmml"><mo lspace="0.222em" rspace="0.222em" id="S3.E3.m1.1.1.5.1.2" xref="S3.E3.m1.1.1.5.1.2.cmml">Ã—</mo><mn id="S3.E3.m1.1.1.5.1.3" xref="S3.E3.m1.1.1.5.1.3.cmml">3</mn></msub><msub id="S3.E3.m1.1.1.5.3" xref="S3.E3.m1.1.1.5.3.cmml"><mi id="S3.E3.m1.1.1.5.3.2" xref="S3.E3.m1.1.1.5.3.2.cmml">T</mi><mi id="S3.E3.m1.1.1.5.3.3" xref="S3.E3.m1.1.1.5.3.3.cmml">Ï</mi></msub></mrow><mo id="S3.E3.m1.1.1.6" xref="S3.E3.m1.1.1.6.cmml">=</mo><mrow id="S3.E3.m1.1.1.1.1" xref="S3.E3.m1.1.1.1.2.cmml"><mpadded width="0.247em"><mo stretchy="false" id="S3.E3.m1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.2.1.cmml">[</mo></mpadded><mrow id="S3.E3.m1.1.1.1.1.1.4" xref="S3.E3.m1.1.1.1.1.1.5.cmml"><mo stretchy="false" id="S3.E3.m1.1.1.1.1.1.4.5" xref="S3.E3.m1.1.1.1.1.1.5.cmml">[</mo><msub id="S3.E3.m1.1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.1.cmml"><mi id="S3.E3.m1.1.1.1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.1.1.1.2.cmml">T</mi><mi id="S3.E3.m1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.1.1.3.cmml">c</mi></msub><mo id="S3.E3.m1.1.1.1.1.1.4.6" xref="S3.E3.m1.1.1.1.1.1.5.cmml">;</mo><msub id="S3.E3.m1.1.1.1.1.1.2.2" xref="S3.E3.m1.1.1.1.1.1.2.2.cmml"><mi id="S3.E3.m1.1.1.1.1.1.2.2.2" xref="S3.E3.m1.1.1.1.1.1.2.2.2.cmml">T</mi><mi id="S3.E3.m1.1.1.1.1.1.2.2.3" xref="S3.E3.m1.1.1.1.1.1.2.2.3.cmml">q</mi></msub><mo id="S3.E3.m1.1.1.1.1.1.4.7" xref="S3.E3.m1.1.1.1.1.1.5.cmml">,</mo><msub id="S3.E3.m1.1.1.1.1.1.3.3" xref="S3.E3.m1.1.1.1.1.1.3.3.cmml"><mi id="S3.E3.m1.1.1.1.1.1.3.3.2" xref="S3.E3.m1.1.1.1.1.1.3.3.2.cmml">T</mi><mi id="S3.E3.m1.1.1.1.1.1.3.3.3" xref="S3.E3.m1.1.1.1.1.1.3.3.3.cmml">v</mi></msub><mo id="S3.E3.m1.1.1.1.1.1.4.8" xref="S3.E3.m1.1.1.1.1.1.5.cmml">,</mo><msub id="S3.E3.m1.1.1.1.1.1.4.4" xref="S3.E3.m1.1.1.1.1.1.4.4.cmml"><mi id="S3.E3.m1.1.1.1.1.1.4.4.2" xref="S3.E3.m1.1.1.1.1.1.4.4.2.cmml">T</mi><mi id="S3.E3.m1.1.1.1.1.1.4.4.3" xref="S3.E3.m1.1.1.1.1.1.4.4.3.cmml">Ï</mi></msub><mpadded width="0.247em"><mo stretchy="false" id="S3.E3.m1.1.1.1.1.1.4.9" xref="S3.E3.m1.1.1.1.1.1.5.cmml">]</mo></mpadded></mrow><mo stretchy="false" id="S3.E3.m1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.2.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.1b"><apply id="S3.E3.m1.1.1.cmml" xref="S3.E3.m1.1.1"><and id="S3.E3.m1.1.1a.cmml" xref="S3.E3.m1.1.1"></and><apply id="S3.E3.m1.1.1b.cmml" xref="S3.E3.m1.1.1"><approx id="S3.E3.m1.1.1.4.cmml" xref="S3.E3.m1.1.1.4"></approx><ci id="S3.E3.m1.1.1.3.cmml" xref="S3.E3.m1.1.1.3">ğ‘Š</ci><apply id="S3.E3.m1.1.1.5.cmml" xref="S3.E3.m1.1.1.5"><apply id="S3.E3.m1.1.1.5.1.cmml" xref="S3.E3.m1.1.1.5.1"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.5.1.1.cmml" xref="S3.E3.m1.1.1.5.1">subscript</csymbol><times id="S3.E3.m1.1.1.5.1.2.cmml" xref="S3.E3.m1.1.1.5.1.2"></times><cn type="integer" id="S3.E3.m1.1.1.5.1.3.cmml" xref="S3.E3.m1.1.1.5.1.3">3</cn></apply><apply id="S3.E3.m1.1.1.5.2.cmml" xref="S3.E3.m1.1.1.5.2"><apply id="S3.E3.m1.1.1.5.2.1.cmml" xref="S3.E3.m1.1.1.5.2.1"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.5.2.1.1.cmml" xref="S3.E3.m1.1.1.5.2.1">subscript</csymbol><times id="S3.E3.m1.1.1.5.2.1.2.cmml" xref="S3.E3.m1.1.1.5.2.1.2"></times><cn type="integer" id="S3.E3.m1.1.1.5.2.1.3.cmml" xref="S3.E3.m1.1.1.5.2.1.3">2</cn></apply><apply id="S3.E3.m1.1.1.5.2.2.cmml" xref="S3.E3.m1.1.1.5.2.2"><apply id="S3.E3.m1.1.1.5.2.2.1.cmml" xref="S3.E3.m1.1.1.5.2.2.1"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.5.2.2.1.1.cmml" xref="S3.E3.m1.1.1.5.2.2.1">subscript</csymbol><times id="S3.E3.m1.1.1.5.2.2.1.2.cmml" xref="S3.E3.m1.1.1.5.2.2.1.2"></times><cn type="integer" id="S3.E3.m1.1.1.5.2.2.1.3.cmml" xref="S3.E3.m1.1.1.5.2.2.1.3">1</cn></apply><apply id="S3.E3.m1.1.1.5.2.2.2.cmml" xref="S3.E3.m1.1.1.5.2.2.2"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.5.2.2.2.1.cmml" xref="S3.E3.m1.1.1.5.2.2.2">subscript</csymbol><ci id="S3.E3.m1.1.1.5.2.2.2.2.cmml" xref="S3.E3.m1.1.1.5.2.2.2.2">ğ‘‡</ci><ci id="S3.E3.m1.1.1.5.2.2.2.3.cmml" xref="S3.E3.m1.1.1.5.2.2.2.3">ğ‘</ci></apply><apply id="S3.E3.m1.1.1.5.2.2.3.cmml" xref="S3.E3.m1.1.1.5.2.2.3"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.5.2.2.3.1.cmml" xref="S3.E3.m1.1.1.5.2.2.3">subscript</csymbol><ci id="S3.E3.m1.1.1.5.2.2.3.2.cmml" xref="S3.E3.m1.1.1.5.2.2.3.2">ğ‘‡</ci><ci id="S3.E3.m1.1.1.5.2.2.3.3.cmml" xref="S3.E3.m1.1.1.5.2.2.3.3">ğ‘</ci></apply></apply><apply id="S3.E3.m1.1.1.5.2.3.cmml" xref="S3.E3.m1.1.1.5.2.3"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.5.2.3.1.cmml" xref="S3.E3.m1.1.1.5.2.3">subscript</csymbol><ci id="S3.E3.m1.1.1.5.2.3.2.cmml" xref="S3.E3.m1.1.1.5.2.3.2">ğ‘‡</ci><ci id="S3.E3.m1.1.1.5.2.3.3.cmml" xref="S3.E3.m1.1.1.5.2.3.3">ğ‘£</ci></apply></apply><apply id="S3.E3.m1.1.1.5.3.cmml" xref="S3.E3.m1.1.1.5.3"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.5.3.1.cmml" xref="S3.E3.m1.1.1.5.3">subscript</csymbol><ci id="S3.E3.m1.1.1.5.3.2.cmml" xref="S3.E3.m1.1.1.5.3.2">ğ‘‡</ci><ci id="S3.E3.m1.1.1.5.3.3.cmml" xref="S3.E3.m1.1.1.5.3.3">ğœŒ</ci></apply></apply></apply><apply id="S3.E3.m1.1.1c.cmml" xref="S3.E3.m1.1.1"><eq id="S3.E3.m1.1.1.6.cmml" xref="S3.E3.m1.1.1.6"></eq><share href="#S3.E3.m1.1.1.5.cmml" id="S3.E3.m1.1.1d.cmml" xref="S3.E3.m1.1.1"></share><apply id="S3.E3.m1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1"><csymbol cd="latexml" id="S3.E3.m1.1.1.1.2.1.cmml" xref="S3.E3.m1.1.1.1.1.2">delimited-[]</csymbol><list id="S3.E3.m1.1.1.1.1.1.5.cmml" xref="S3.E3.m1.1.1.1.1.1.4"><apply id="S3.E3.m1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E3.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.2">ğ‘‡</ci><ci id="S3.E3.m1.1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.3">ğ‘</ci></apply><apply id="S3.E3.m1.1.1.1.1.1.2.2.cmml" xref="S3.E3.m1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.1.2.2.1.cmml" xref="S3.E3.m1.1.1.1.1.1.2.2">subscript</csymbol><ci id="S3.E3.m1.1.1.1.1.1.2.2.2.cmml" xref="S3.E3.m1.1.1.1.1.1.2.2.2">ğ‘‡</ci><ci id="S3.E3.m1.1.1.1.1.1.2.2.3.cmml" xref="S3.E3.m1.1.1.1.1.1.2.2.3">ğ‘</ci></apply><apply id="S3.E3.m1.1.1.1.1.1.3.3.cmml" xref="S3.E3.m1.1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.1.3.3.1.cmml" xref="S3.E3.m1.1.1.1.1.1.3.3">subscript</csymbol><ci id="S3.E3.m1.1.1.1.1.1.3.3.2.cmml" xref="S3.E3.m1.1.1.1.1.1.3.3.2">ğ‘‡</ci><ci id="S3.E3.m1.1.1.1.1.1.3.3.3.cmml" xref="S3.E3.m1.1.1.1.1.1.3.3.3">ğ‘£</ci></apply><apply id="S3.E3.m1.1.1.1.1.1.4.4.cmml" xref="S3.E3.m1.1.1.1.1.1.4.4"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.1.4.4.1.cmml" xref="S3.E3.m1.1.1.1.1.1.4.4">subscript</csymbol><ci id="S3.E3.m1.1.1.1.1.1.4.4.2.cmml" xref="S3.E3.m1.1.1.1.1.1.4.4.2">ğ‘‡</ci><ci id="S3.E3.m1.1.1.1.1.1.4.4.3.cmml" xref="S3.E3.m1.1.1.1.1.1.4.4.3">ğœŒ</ci></apply></list></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.1c">W\approx T_{c}\times_{1}T_{q}\times_{2}T_{v}\times_{3}T_{\rho}=[\![T_{c};T_{q},T_{v},T_{\rho}]\!]</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p id="S3.SS2.p2.10" class="ltx_p">where <math id="S3.SS2.p2.5.m1.1" class="ltx_Math" alttext="T_{v}\in\mathbb{R}^{n_{v}\times t_{v}}" display="inline"><semantics id="S3.SS2.p2.5.m1.1a"><mrow id="S3.SS2.p2.5.m1.1.1" xref="S3.SS2.p2.5.m1.1.1.cmml"><msub id="S3.SS2.p2.5.m1.1.1.2" xref="S3.SS2.p2.5.m1.1.1.2.cmml"><mi id="S3.SS2.p2.5.m1.1.1.2.2" xref="S3.SS2.p2.5.m1.1.1.2.2.cmml">T</mi><mi id="S3.SS2.p2.5.m1.1.1.2.3" xref="S3.SS2.p2.5.m1.1.1.2.3.cmml">v</mi></msub><mo id="S3.SS2.p2.5.m1.1.1.1" xref="S3.SS2.p2.5.m1.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS2.p2.5.m1.1.1.3" xref="S3.SS2.p2.5.m1.1.1.3.cmml"><mi id="S3.SS2.p2.5.m1.1.1.3.2" xref="S3.SS2.p2.5.m1.1.1.3.2.cmml">â„</mi><mrow id="S3.SS2.p2.5.m1.1.1.3.3" xref="S3.SS2.p2.5.m1.1.1.3.3.cmml"><msub id="S3.SS2.p2.5.m1.1.1.3.3.2" xref="S3.SS2.p2.5.m1.1.1.3.3.2.cmml"><mi id="S3.SS2.p2.5.m1.1.1.3.3.2.2" xref="S3.SS2.p2.5.m1.1.1.3.3.2.2.cmml">n</mi><mi id="S3.SS2.p2.5.m1.1.1.3.3.2.3" xref="S3.SS2.p2.5.m1.1.1.3.3.2.3.cmml">v</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p2.5.m1.1.1.3.3.1" xref="S3.SS2.p2.5.m1.1.1.3.3.1.cmml">Ã—</mo><msub id="S3.SS2.p2.5.m1.1.1.3.3.3" xref="S3.SS2.p2.5.m1.1.1.3.3.3.cmml"><mi id="S3.SS2.p2.5.m1.1.1.3.3.3.2" xref="S3.SS2.p2.5.m1.1.1.3.3.3.2.cmml">t</mi><mi id="S3.SS2.p2.5.m1.1.1.3.3.3.3" xref="S3.SS2.p2.5.m1.1.1.3.3.3.3.cmml">v</mi></msub></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.5.m1.1b"><apply id="S3.SS2.p2.5.m1.1.1.cmml" xref="S3.SS2.p2.5.m1.1.1"><in id="S3.SS2.p2.5.m1.1.1.1.cmml" xref="S3.SS2.p2.5.m1.1.1.1"></in><apply id="S3.SS2.p2.5.m1.1.1.2.cmml" xref="S3.SS2.p2.5.m1.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p2.5.m1.1.1.2.1.cmml" xref="S3.SS2.p2.5.m1.1.1.2">subscript</csymbol><ci id="S3.SS2.p2.5.m1.1.1.2.2.cmml" xref="S3.SS2.p2.5.m1.1.1.2.2">ğ‘‡</ci><ci id="S3.SS2.p2.5.m1.1.1.2.3.cmml" xref="S3.SS2.p2.5.m1.1.1.2.3">ğ‘£</ci></apply><apply id="S3.SS2.p2.5.m1.1.1.3.cmml" xref="S3.SS2.p2.5.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p2.5.m1.1.1.3.1.cmml" xref="S3.SS2.p2.5.m1.1.1.3">superscript</csymbol><ci id="S3.SS2.p2.5.m1.1.1.3.2.cmml" xref="S3.SS2.p2.5.m1.1.1.3.2">â„</ci><apply id="S3.SS2.p2.5.m1.1.1.3.3.cmml" xref="S3.SS2.p2.5.m1.1.1.3.3"><times id="S3.SS2.p2.5.m1.1.1.3.3.1.cmml" xref="S3.SS2.p2.5.m1.1.1.3.3.1"></times><apply id="S3.SS2.p2.5.m1.1.1.3.3.2.cmml" xref="S3.SS2.p2.5.m1.1.1.3.3.2"><csymbol cd="ambiguous" id="S3.SS2.p2.5.m1.1.1.3.3.2.1.cmml" xref="S3.SS2.p2.5.m1.1.1.3.3.2">subscript</csymbol><ci id="S3.SS2.p2.5.m1.1.1.3.3.2.2.cmml" xref="S3.SS2.p2.5.m1.1.1.3.3.2.2">ğ‘›</ci><ci id="S3.SS2.p2.5.m1.1.1.3.3.2.3.cmml" xref="S3.SS2.p2.5.m1.1.1.3.3.2.3">ğ‘£</ci></apply><apply id="S3.SS2.p2.5.m1.1.1.3.3.3.cmml" xref="S3.SS2.p2.5.m1.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.SS2.p2.5.m1.1.1.3.3.3.1.cmml" xref="S3.SS2.p2.5.m1.1.1.3.3.3">subscript</csymbol><ci id="S3.SS2.p2.5.m1.1.1.3.3.3.2.cmml" xref="S3.SS2.p2.5.m1.1.1.3.3.3.2">ğ‘¡</ci><ci id="S3.SS2.p2.5.m1.1.1.3.3.3.3.cmml" xref="S3.SS2.p2.5.m1.1.1.3.3.3.3">ğ‘£</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.5.m1.1c">T_{v}\in\mathbb{R}^{n_{v}\times t_{v}}</annotation></semantics></math>, <math id="S3.SS2.p2.6.m2.1" class="ltx_Math" alttext="T_{q}\in\mathbb{R}^{n_{q}\times t_{q}}" display="inline"><semantics id="S3.SS2.p2.6.m2.1a"><mrow id="S3.SS2.p2.6.m2.1.1" xref="S3.SS2.p2.6.m2.1.1.cmml"><msub id="S3.SS2.p2.6.m2.1.1.2" xref="S3.SS2.p2.6.m2.1.1.2.cmml"><mi id="S3.SS2.p2.6.m2.1.1.2.2" xref="S3.SS2.p2.6.m2.1.1.2.2.cmml">T</mi><mi id="S3.SS2.p2.6.m2.1.1.2.3" xref="S3.SS2.p2.6.m2.1.1.2.3.cmml">q</mi></msub><mo id="S3.SS2.p2.6.m2.1.1.1" xref="S3.SS2.p2.6.m2.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS2.p2.6.m2.1.1.3" xref="S3.SS2.p2.6.m2.1.1.3.cmml"><mi id="S3.SS2.p2.6.m2.1.1.3.2" xref="S3.SS2.p2.6.m2.1.1.3.2.cmml">â„</mi><mrow id="S3.SS2.p2.6.m2.1.1.3.3" xref="S3.SS2.p2.6.m2.1.1.3.3.cmml"><msub id="S3.SS2.p2.6.m2.1.1.3.3.2" xref="S3.SS2.p2.6.m2.1.1.3.3.2.cmml"><mi id="S3.SS2.p2.6.m2.1.1.3.3.2.2" xref="S3.SS2.p2.6.m2.1.1.3.3.2.2.cmml">n</mi><mi id="S3.SS2.p2.6.m2.1.1.3.3.2.3" xref="S3.SS2.p2.6.m2.1.1.3.3.2.3.cmml">q</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p2.6.m2.1.1.3.3.1" xref="S3.SS2.p2.6.m2.1.1.3.3.1.cmml">Ã—</mo><msub id="S3.SS2.p2.6.m2.1.1.3.3.3" xref="S3.SS2.p2.6.m2.1.1.3.3.3.cmml"><mi id="S3.SS2.p2.6.m2.1.1.3.3.3.2" xref="S3.SS2.p2.6.m2.1.1.3.3.3.2.cmml">t</mi><mi id="S3.SS2.p2.6.m2.1.1.3.3.3.3" xref="S3.SS2.p2.6.m2.1.1.3.3.3.3.cmml">q</mi></msub></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.6.m2.1b"><apply id="S3.SS2.p2.6.m2.1.1.cmml" xref="S3.SS2.p2.6.m2.1.1"><in id="S3.SS2.p2.6.m2.1.1.1.cmml" xref="S3.SS2.p2.6.m2.1.1.1"></in><apply id="S3.SS2.p2.6.m2.1.1.2.cmml" xref="S3.SS2.p2.6.m2.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p2.6.m2.1.1.2.1.cmml" xref="S3.SS2.p2.6.m2.1.1.2">subscript</csymbol><ci id="S3.SS2.p2.6.m2.1.1.2.2.cmml" xref="S3.SS2.p2.6.m2.1.1.2.2">ğ‘‡</ci><ci id="S3.SS2.p2.6.m2.1.1.2.3.cmml" xref="S3.SS2.p2.6.m2.1.1.2.3">ğ‘</ci></apply><apply id="S3.SS2.p2.6.m2.1.1.3.cmml" xref="S3.SS2.p2.6.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p2.6.m2.1.1.3.1.cmml" xref="S3.SS2.p2.6.m2.1.1.3">superscript</csymbol><ci id="S3.SS2.p2.6.m2.1.1.3.2.cmml" xref="S3.SS2.p2.6.m2.1.1.3.2">â„</ci><apply id="S3.SS2.p2.6.m2.1.1.3.3.cmml" xref="S3.SS2.p2.6.m2.1.1.3.3"><times id="S3.SS2.p2.6.m2.1.1.3.3.1.cmml" xref="S3.SS2.p2.6.m2.1.1.3.3.1"></times><apply id="S3.SS2.p2.6.m2.1.1.3.3.2.cmml" xref="S3.SS2.p2.6.m2.1.1.3.3.2"><csymbol cd="ambiguous" id="S3.SS2.p2.6.m2.1.1.3.3.2.1.cmml" xref="S3.SS2.p2.6.m2.1.1.3.3.2">subscript</csymbol><ci id="S3.SS2.p2.6.m2.1.1.3.3.2.2.cmml" xref="S3.SS2.p2.6.m2.1.1.3.3.2.2">ğ‘›</ci><ci id="S3.SS2.p2.6.m2.1.1.3.3.2.3.cmml" xref="S3.SS2.p2.6.m2.1.1.3.3.2.3">ğ‘</ci></apply><apply id="S3.SS2.p2.6.m2.1.1.3.3.3.cmml" xref="S3.SS2.p2.6.m2.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.SS2.p2.6.m2.1.1.3.3.3.1.cmml" xref="S3.SS2.p2.6.m2.1.1.3.3.3">subscript</csymbol><ci id="S3.SS2.p2.6.m2.1.1.3.3.3.2.cmml" xref="S3.SS2.p2.6.m2.1.1.3.3.3.2">ğ‘¡</ci><ci id="S3.SS2.p2.6.m2.1.1.3.3.3.3.cmml" xref="S3.SS2.p2.6.m2.1.1.3.3.3.3">ğ‘</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.6.m2.1c">T_{q}\in\mathbb{R}^{n_{q}\times t_{q}}</annotation></semantics></math> and <math id="S3.SS2.p2.7.m3.1" class="ltx_Math" alttext="T_{\rho}\in\mathbb{R}^{n_{\rho}\times t_{\rho}}" display="inline"><semantics id="S3.SS2.p2.7.m3.1a"><mrow id="S3.SS2.p2.7.m3.1.1" xref="S3.SS2.p2.7.m3.1.1.cmml"><msub id="S3.SS2.p2.7.m3.1.1.2" xref="S3.SS2.p2.7.m3.1.1.2.cmml"><mi id="S3.SS2.p2.7.m3.1.1.2.2" xref="S3.SS2.p2.7.m3.1.1.2.2.cmml">T</mi><mi id="S3.SS2.p2.7.m3.1.1.2.3" xref="S3.SS2.p2.7.m3.1.1.2.3.cmml">Ï</mi></msub><mo id="S3.SS2.p2.7.m3.1.1.1" xref="S3.SS2.p2.7.m3.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS2.p2.7.m3.1.1.3" xref="S3.SS2.p2.7.m3.1.1.3.cmml"><mi id="S3.SS2.p2.7.m3.1.1.3.2" xref="S3.SS2.p2.7.m3.1.1.3.2.cmml">â„</mi><mrow id="S3.SS2.p2.7.m3.1.1.3.3" xref="S3.SS2.p2.7.m3.1.1.3.3.cmml"><msub id="S3.SS2.p2.7.m3.1.1.3.3.2" xref="S3.SS2.p2.7.m3.1.1.3.3.2.cmml"><mi id="S3.SS2.p2.7.m3.1.1.3.3.2.2" xref="S3.SS2.p2.7.m3.1.1.3.3.2.2.cmml">n</mi><mi id="S3.SS2.p2.7.m3.1.1.3.3.2.3" xref="S3.SS2.p2.7.m3.1.1.3.3.2.3.cmml">Ï</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p2.7.m3.1.1.3.3.1" xref="S3.SS2.p2.7.m3.1.1.3.3.1.cmml">Ã—</mo><msub id="S3.SS2.p2.7.m3.1.1.3.3.3" xref="S3.SS2.p2.7.m3.1.1.3.3.3.cmml"><mi id="S3.SS2.p2.7.m3.1.1.3.3.3.2" xref="S3.SS2.p2.7.m3.1.1.3.3.3.2.cmml">t</mi><mi id="S3.SS2.p2.7.m3.1.1.3.3.3.3" xref="S3.SS2.p2.7.m3.1.1.3.3.3.3.cmml">Ï</mi></msub></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.7.m3.1b"><apply id="S3.SS2.p2.7.m3.1.1.cmml" xref="S3.SS2.p2.7.m3.1.1"><in id="S3.SS2.p2.7.m3.1.1.1.cmml" xref="S3.SS2.p2.7.m3.1.1.1"></in><apply id="S3.SS2.p2.7.m3.1.1.2.cmml" xref="S3.SS2.p2.7.m3.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p2.7.m3.1.1.2.1.cmml" xref="S3.SS2.p2.7.m3.1.1.2">subscript</csymbol><ci id="S3.SS2.p2.7.m3.1.1.2.2.cmml" xref="S3.SS2.p2.7.m3.1.1.2.2">ğ‘‡</ci><ci id="S3.SS2.p2.7.m3.1.1.2.3.cmml" xref="S3.SS2.p2.7.m3.1.1.2.3">ğœŒ</ci></apply><apply id="S3.SS2.p2.7.m3.1.1.3.cmml" xref="S3.SS2.p2.7.m3.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p2.7.m3.1.1.3.1.cmml" xref="S3.SS2.p2.7.m3.1.1.3">superscript</csymbol><ci id="S3.SS2.p2.7.m3.1.1.3.2.cmml" xref="S3.SS2.p2.7.m3.1.1.3.2">â„</ci><apply id="S3.SS2.p2.7.m3.1.1.3.3.cmml" xref="S3.SS2.p2.7.m3.1.1.3.3"><times id="S3.SS2.p2.7.m3.1.1.3.3.1.cmml" xref="S3.SS2.p2.7.m3.1.1.3.3.1"></times><apply id="S3.SS2.p2.7.m3.1.1.3.3.2.cmml" xref="S3.SS2.p2.7.m3.1.1.3.3.2"><csymbol cd="ambiguous" id="S3.SS2.p2.7.m3.1.1.3.3.2.1.cmml" xref="S3.SS2.p2.7.m3.1.1.3.3.2">subscript</csymbol><ci id="S3.SS2.p2.7.m3.1.1.3.3.2.2.cmml" xref="S3.SS2.p2.7.m3.1.1.3.3.2.2">ğ‘›</ci><ci id="S3.SS2.p2.7.m3.1.1.3.3.2.3.cmml" xref="S3.SS2.p2.7.m3.1.1.3.3.2.3">ğœŒ</ci></apply><apply id="S3.SS2.p2.7.m3.1.1.3.3.3.cmml" xref="S3.SS2.p2.7.m3.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.SS2.p2.7.m3.1.1.3.3.3.1.cmml" xref="S3.SS2.p2.7.m3.1.1.3.3.3">subscript</csymbol><ci id="S3.SS2.p2.7.m3.1.1.3.3.3.2.cmml" xref="S3.SS2.p2.7.m3.1.1.3.3.3.2">ğ‘¡</ci><ci id="S3.SS2.p2.7.m3.1.1.3.3.3.3.cmml" xref="S3.SS2.p2.7.m3.1.1.3.3.3.3">ğœŒ</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.7.m3.1c">T_{\rho}\in\mathbb{R}^{n_{\rho}\times t_{\rho}}</annotation></semantics></math> are factor matrices similar to principal components along each input and output embeddings and <math id="S3.SS2.p2.8.m4.1" class="ltx_Math" alttext="T_{c}\in\mathbb{R}^{t_{v}\times t_{q}\times t_{\rho}}" display="inline"><semantics id="S3.SS2.p2.8.m4.1a"><mrow id="S3.SS2.p2.8.m4.1.1" xref="S3.SS2.p2.8.m4.1.1.cmml"><msub id="S3.SS2.p2.8.m4.1.1.2" xref="S3.SS2.p2.8.m4.1.1.2.cmml"><mi id="S3.SS2.p2.8.m4.1.1.2.2" xref="S3.SS2.p2.8.m4.1.1.2.2.cmml">T</mi><mi id="S3.SS2.p2.8.m4.1.1.2.3" xref="S3.SS2.p2.8.m4.1.1.2.3.cmml">c</mi></msub><mo id="S3.SS2.p2.8.m4.1.1.1" xref="S3.SS2.p2.8.m4.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS2.p2.8.m4.1.1.3" xref="S3.SS2.p2.8.m4.1.1.3.cmml"><mi id="S3.SS2.p2.8.m4.1.1.3.2" xref="S3.SS2.p2.8.m4.1.1.3.2.cmml">â„</mi><mrow id="S3.SS2.p2.8.m4.1.1.3.3" xref="S3.SS2.p2.8.m4.1.1.3.3.cmml"><msub id="S3.SS2.p2.8.m4.1.1.3.3.2" xref="S3.SS2.p2.8.m4.1.1.3.3.2.cmml"><mi id="S3.SS2.p2.8.m4.1.1.3.3.2.2" xref="S3.SS2.p2.8.m4.1.1.3.3.2.2.cmml">t</mi><mi id="S3.SS2.p2.8.m4.1.1.3.3.2.3" xref="S3.SS2.p2.8.m4.1.1.3.3.2.3.cmml">v</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p2.8.m4.1.1.3.3.1" xref="S3.SS2.p2.8.m4.1.1.3.3.1.cmml">Ã—</mo><msub id="S3.SS2.p2.8.m4.1.1.3.3.3" xref="S3.SS2.p2.8.m4.1.1.3.3.3.cmml"><mi id="S3.SS2.p2.8.m4.1.1.3.3.3.2" xref="S3.SS2.p2.8.m4.1.1.3.3.3.2.cmml">t</mi><mi id="S3.SS2.p2.8.m4.1.1.3.3.3.3" xref="S3.SS2.p2.8.m4.1.1.3.3.3.3.cmml">q</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p2.8.m4.1.1.3.3.1a" xref="S3.SS2.p2.8.m4.1.1.3.3.1.cmml">Ã—</mo><msub id="S3.SS2.p2.8.m4.1.1.3.3.4" xref="S3.SS2.p2.8.m4.1.1.3.3.4.cmml"><mi id="S3.SS2.p2.8.m4.1.1.3.3.4.2" xref="S3.SS2.p2.8.m4.1.1.3.3.4.2.cmml">t</mi><mi id="S3.SS2.p2.8.m4.1.1.3.3.4.3" xref="S3.SS2.p2.8.m4.1.1.3.3.4.3.cmml">Ï</mi></msub></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.8.m4.1b"><apply id="S3.SS2.p2.8.m4.1.1.cmml" xref="S3.SS2.p2.8.m4.1.1"><in id="S3.SS2.p2.8.m4.1.1.1.cmml" xref="S3.SS2.p2.8.m4.1.1.1"></in><apply id="S3.SS2.p2.8.m4.1.1.2.cmml" xref="S3.SS2.p2.8.m4.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p2.8.m4.1.1.2.1.cmml" xref="S3.SS2.p2.8.m4.1.1.2">subscript</csymbol><ci id="S3.SS2.p2.8.m4.1.1.2.2.cmml" xref="S3.SS2.p2.8.m4.1.1.2.2">ğ‘‡</ci><ci id="S3.SS2.p2.8.m4.1.1.2.3.cmml" xref="S3.SS2.p2.8.m4.1.1.2.3">ğ‘</ci></apply><apply id="S3.SS2.p2.8.m4.1.1.3.cmml" xref="S3.SS2.p2.8.m4.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p2.8.m4.1.1.3.1.cmml" xref="S3.SS2.p2.8.m4.1.1.3">superscript</csymbol><ci id="S3.SS2.p2.8.m4.1.1.3.2.cmml" xref="S3.SS2.p2.8.m4.1.1.3.2">â„</ci><apply id="S3.SS2.p2.8.m4.1.1.3.3.cmml" xref="S3.SS2.p2.8.m4.1.1.3.3"><times id="S3.SS2.p2.8.m4.1.1.3.3.1.cmml" xref="S3.SS2.p2.8.m4.1.1.3.3.1"></times><apply id="S3.SS2.p2.8.m4.1.1.3.3.2.cmml" xref="S3.SS2.p2.8.m4.1.1.3.3.2"><csymbol cd="ambiguous" id="S3.SS2.p2.8.m4.1.1.3.3.2.1.cmml" xref="S3.SS2.p2.8.m4.1.1.3.3.2">subscript</csymbol><ci id="S3.SS2.p2.8.m4.1.1.3.3.2.2.cmml" xref="S3.SS2.p2.8.m4.1.1.3.3.2.2">ğ‘¡</ci><ci id="S3.SS2.p2.8.m4.1.1.3.3.2.3.cmml" xref="S3.SS2.p2.8.m4.1.1.3.3.2.3">ğ‘£</ci></apply><apply id="S3.SS2.p2.8.m4.1.1.3.3.3.cmml" xref="S3.SS2.p2.8.m4.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.SS2.p2.8.m4.1.1.3.3.3.1.cmml" xref="S3.SS2.p2.8.m4.1.1.3.3.3">subscript</csymbol><ci id="S3.SS2.p2.8.m4.1.1.3.3.3.2.cmml" xref="S3.SS2.p2.8.m4.1.1.3.3.3.2">ğ‘¡</ci><ci id="S3.SS2.p2.8.m4.1.1.3.3.3.3.cmml" xref="S3.SS2.p2.8.m4.1.1.3.3.3.3">ğ‘</ci></apply><apply id="S3.SS2.p2.8.m4.1.1.3.3.4.cmml" xref="S3.SS2.p2.8.m4.1.1.3.3.4"><csymbol cd="ambiguous" id="S3.SS2.p2.8.m4.1.1.3.3.4.1.cmml" xref="S3.SS2.p2.8.m4.1.1.3.3.4">subscript</csymbol><ci id="S3.SS2.p2.8.m4.1.1.3.3.4.2.cmml" xref="S3.SS2.p2.8.m4.1.1.3.3.4.2">ğ‘¡</ci><ci id="S3.SS2.p2.8.m4.1.1.3.3.4.3.cmml" xref="S3.SS2.p2.8.m4.1.1.3.3.4.3">ğœŒ</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.8.m4.1c">T_{c}\in\mathbb{R}^{t_{v}\times t_{q}\times t_{\rho}}</annotation></semantics></math> is the core tensor which encapsulates interactions between the factor matrices. The notation <math id="S3.SS2.p2.9.m5.2" class="ltx_Math" alttext="[\![\cdot]\!]" display="inline"><semantics id="S3.SS2.p2.9.m5.2a"><mrow id="S3.SS2.p2.9.m5.2.2.1" xref="S3.SS2.p2.9.m5.2.2.2.cmml"><mpadded width="0.247em"><mo stretchy="false" id="S3.SS2.p2.9.m5.2.2.1.2" xref="S3.SS2.p2.9.m5.2.2.2.1.cmml">[</mo></mpadded><mrow id="S3.SS2.p2.9.m5.2.2.1.1.2" xref="S3.SS2.p2.9.m5.2.2.1.1.1.cmml"><mo stretchy="false" id="S3.SS2.p2.9.m5.2.2.1.1.2.1" xref="S3.SS2.p2.9.m5.2.2.1.1.1.1.cmml">[</mo><mo lspace="0em" rspace="0em" id="S3.SS2.p2.9.m5.1.1" xref="S3.SS2.p2.9.m5.1.1.cmml">â‹…</mo><mpadded width="0.247em"><mo stretchy="false" id="S3.SS2.p2.9.m5.2.2.1.1.2.2" xref="S3.SS2.p2.9.m5.2.2.1.1.1.1.cmml">]</mo></mpadded></mrow><mo stretchy="false" id="S3.SS2.p2.9.m5.2.2.1.3" xref="S3.SS2.p2.9.m5.2.2.2.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.9.m5.2b"><apply id="S3.SS2.p2.9.m5.2.2.2.cmml" xref="S3.SS2.p2.9.m5.2.2.1"><csymbol cd="latexml" id="S3.SS2.p2.9.m5.2.2.2.1.cmml" xref="S3.SS2.p2.9.m5.2.2.1.2">delimited-[]</csymbol><apply id="S3.SS2.p2.9.m5.2.2.1.1.1.cmml" xref="S3.SS2.p2.9.m5.2.2.1.1.2"><csymbol cd="latexml" id="S3.SS2.p2.9.m5.2.2.1.1.1.1.cmml" xref="S3.SS2.p2.9.m5.2.2.1.1.2.1">delimited-[]</csymbol><ci id="S3.SS2.p2.9.m5.1.1.cmml" xref="S3.SS2.p2.9.m5.1.1">â‹…</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.9.m5.2c">[\![\cdot]\!]</annotation></semantics></math> represents the shorthand for Tucker decomposition. In practice, the decomposed version of <math id="S3.SS2.p2.10.m6.1" class="ltx_Math" alttext="W" display="inline"><semantics id="S3.SS2.p2.10.m6.1a"><mi id="S3.SS2.p2.10.m6.1.1" xref="S3.SS2.p2.10.m6.1.1.cmml">W</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.10.m6.1b"><ci id="S3.SS2.p2.10.m6.1.1.cmml" xref="S3.SS2.p2.10.m6.1.1">ğ‘Š</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.10.m6.1c">W</annotation></semantics></math> is significantly smaller number of parameters than the original tensor <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">Bader and Kolda (2007)</span></a>]</cite>.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.1" class="ltx_p">After reducing the parameter complexity of <math id="S3.SS2.p3.1.m1.1" class="ltx_Math" alttext="W" display="inline"><semantics id="S3.SS2.p3.1.m1.1a"><mi id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml">W</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b"><ci id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1">ğ‘Š</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">W</annotation></semantics></math> with tucker decomposition, the fully parametrized outer product representation in Eq. <a href="#S3.E2" title="In 3.2 Hierarchical Attention Fusion â€£ 3 Methods â€£ Reciprocal Attention Fusion for Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> can be rewritten as:</p>
<table id="S3.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E4.m1.1" class="ltx_Math" alttext="\rho=T_{c}\ \times_{1}\ \tilde{q}\ \times_{2}\ \tilde{v}\ \times_{3}\ T_{\rho}" display="block"><semantics id="S3.E4.m1.1a"><mrow id="S3.E4.m1.1.1" xref="S3.E4.m1.1.1.cmml"><mi id="S3.E4.m1.1.1.2" xref="S3.E4.m1.1.1.2.cmml">Ï</mi><mo id="S3.E4.m1.1.1.1" xref="S3.E4.m1.1.1.1.cmml">=</mo><mrow id="S3.E4.m1.1.1.3" xref="S3.E4.m1.1.1.3.cmml"><mrow id="S3.E4.m1.1.1.3.2" xref="S3.E4.m1.1.1.3.2.cmml"><mrow id="S3.E4.m1.1.1.3.2.2" xref="S3.E4.m1.1.1.3.2.2.cmml"><msub id="S3.E4.m1.1.1.3.2.2.2" xref="S3.E4.m1.1.1.3.2.2.2.cmml"><mi id="S3.E4.m1.1.1.3.2.2.2.2" xref="S3.E4.m1.1.1.3.2.2.2.2.cmml">T</mi><mi id="S3.E4.m1.1.1.3.2.2.2.3" xref="S3.E4.m1.1.1.3.2.2.2.3.cmml">c</mi></msub><msub id="S3.E4.m1.1.1.3.2.2.1" xref="S3.E4.m1.1.1.3.2.2.1.cmml"><mo lspace="0.222em" rspace="0.222em" id="S3.E4.m1.1.1.3.2.2.1.2" xref="S3.E4.m1.1.1.3.2.2.1.2.cmml">Ã—</mo><mn id="S3.E4.m1.1.1.3.2.2.1.3" xref="S3.E4.m1.1.1.3.2.2.1.3.cmml">1</mn></msub><mover accent="true" id="S3.E4.m1.1.1.3.2.2.3" xref="S3.E4.m1.1.1.3.2.2.3.cmml"><mi id="S3.E4.m1.1.1.3.2.2.3.2" xref="S3.E4.m1.1.1.3.2.2.3.2.cmml">q</mi><mo id="S3.E4.m1.1.1.3.2.2.3.1" xref="S3.E4.m1.1.1.3.2.2.3.1.cmml">~</mo></mover></mrow><msub id="S3.E4.m1.1.1.3.2.1" xref="S3.E4.m1.1.1.3.2.1.cmml"><mo lspace="0.222em" rspace="0.222em" id="S3.E4.m1.1.1.3.2.1.2" xref="S3.E4.m1.1.1.3.2.1.2.cmml">Ã—</mo><mn id="S3.E4.m1.1.1.3.2.1.3" xref="S3.E4.m1.1.1.3.2.1.3.cmml">2</mn></msub><mover accent="true" id="S3.E4.m1.1.1.3.2.3" xref="S3.E4.m1.1.1.3.2.3.cmml"><mi id="S3.E4.m1.1.1.3.2.3.2" xref="S3.E4.m1.1.1.3.2.3.2.cmml">v</mi><mo id="S3.E4.m1.1.1.3.2.3.1" xref="S3.E4.m1.1.1.3.2.3.1.cmml">~</mo></mover></mrow><msub id="S3.E4.m1.1.1.3.1" xref="S3.E4.m1.1.1.3.1.cmml"><mo lspace="0.222em" rspace="0.222em" id="S3.E4.m1.1.1.3.1.2" xref="S3.E4.m1.1.1.3.1.2.cmml">Ã—</mo><mn id="S3.E4.m1.1.1.3.1.3" xref="S3.E4.m1.1.1.3.1.3.cmml">3</mn></msub><msub id="S3.E4.m1.1.1.3.3" xref="S3.E4.m1.1.1.3.3.cmml"><mi id="S3.E4.m1.1.1.3.3.2" xref="S3.E4.m1.1.1.3.3.2.cmml">T</mi><mi id="S3.E4.m1.1.1.3.3.3" xref="S3.E4.m1.1.1.3.3.3.cmml">Ï</mi></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.1b"><apply id="S3.E4.m1.1.1.cmml" xref="S3.E4.m1.1.1"><eq id="S3.E4.m1.1.1.1.cmml" xref="S3.E4.m1.1.1.1"></eq><ci id="S3.E4.m1.1.1.2.cmml" xref="S3.E4.m1.1.1.2">ğœŒ</ci><apply id="S3.E4.m1.1.1.3.cmml" xref="S3.E4.m1.1.1.3"><apply id="S3.E4.m1.1.1.3.1.cmml" xref="S3.E4.m1.1.1.3.1"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.3.1.1.cmml" xref="S3.E4.m1.1.1.3.1">subscript</csymbol><times id="S3.E4.m1.1.1.3.1.2.cmml" xref="S3.E4.m1.1.1.3.1.2"></times><cn type="integer" id="S3.E4.m1.1.1.3.1.3.cmml" xref="S3.E4.m1.1.1.3.1.3">3</cn></apply><apply id="S3.E4.m1.1.1.3.2.cmml" xref="S3.E4.m1.1.1.3.2"><apply id="S3.E4.m1.1.1.3.2.1.cmml" xref="S3.E4.m1.1.1.3.2.1"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.3.2.1.1.cmml" xref="S3.E4.m1.1.1.3.2.1">subscript</csymbol><times id="S3.E4.m1.1.1.3.2.1.2.cmml" xref="S3.E4.m1.1.1.3.2.1.2"></times><cn type="integer" id="S3.E4.m1.1.1.3.2.1.3.cmml" xref="S3.E4.m1.1.1.3.2.1.3">2</cn></apply><apply id="S3.E4.m1.1.1.3.2.2.cmml" xref="S3.E4.m1.1.1.3.2.2"><apply id="S3.E4.m1.1.1.3.2.2.1.cmml" xref="S3.E4.m1.1.1.3.2.2.1"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.3.2.2.1.1.cmml" xref="S3.E4.m1.1.1.3.2.2.1">subscript</csymbol><times id="S3.E4.m1.1.1.3.2.2.1.2.cmml" xref="S3.E4.m1.1.1.3.2.2.1.2"></times><cn type="integer" id="S3.E4.m1.1.1.3.2.2.1.3.cmml" xref="S3.E4.m1.1.1.3.2.2.1.3">1</cn></apply><apply id="S3.E4.m1.1.1.3.2.2.2.cmml" xref="S3.E4.m1.1.1.3.2.2.2"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.3.2.2.2.1.cmml" xref="S3.E4.m1.1.1.3.2.2.2">subscript</csymbol><ci id="S3.E4.m1.1.1.3.2.2.2.2.cmml" xref="S3.E4.m1.1.1.3.2.2.2.2">ğ‘‡</ci><ci id="S3.E4.m1.1.1.3.2.2.2.3.cmml" xref="S3.E4.m1.1.1.3.2.2.2.3">ğ‘</ci></apply><apply id="S3.E4.m1.1.1.3.2.2.3.cmml" xref="S3.E4.m1.1.1.3.2.2.3"><ci id="S3.E4.m1.1.1.3.2.2.3.1.cmml" xref="S3.E4.m1.1.1.3.2.2.3.1">~</ci><ci id="S3.E4.m1.1.1.3.2.2.3.2.cmml" xref="S3.E4.m1.1.1.3.2.2.3.2">ğ‘</ci></apply></apply><apply id="S3.E4.m1.1.1.3.2.3.cmml" xref="S3.E4.m1.1.1.3.2.3"><ci id="S3.E4.m1.1.1.3.2.3.1.cmml" xref="S3.E4.m1.1.1.3.2.3.1">~</ci><ci id="S3.E4.m1.1.1.3.2.3.2.cmml" xref="S3.E4.m1.1.1.3.2.3.2">ğ‘£</ci></apply></apply><apply id="S3.E4.m1.1.1.3.3.cmml" xref="S3.E4.m1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.3.3.1.cmml" xref="S3.E4.m1.1.1.3.3">subscript</csymbol><ci id="S3.E4.m1.1.1.3.3.2.cmml" xref="S3.E4.m1.1.1.3.3.2">ğ‘‡</ci><ci id="S3.E4.m1.1.1.3.3.3.cmml" xref="S3.E4.m1.1.1.3.3.3">ğœŒ</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.1c">\rho=T_{c}\ \times_{1}\ \tilde{q}\ \times_{2}\ \tilde{v}\ \times_{3}\ T_{\rho}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p id="S3.SS2.p3.5" class="ltx_p">where <math id="S3.SS2.p3.2.m1.1" class="ltx_Math" alttext="\tilde{v}=v^{\intercal}\ T_{v}\in\mathbb{R}^{t_{v}}" display="inline"><semantics id="S3.SS2.p3.2.m1.1a"><mrow id="S3.SS2.p3.2.m1.1.1" xref="S3.SS2.p3.2.m1.1.1.cmml"><mover accent="true" id="S3.SS2.p3.2.m1.1.1.2" xref="S3.SS2.p3.2.m1.1.1.2.cmml"><mi id="S3.SS2.p3.2.m1.1.1.2.2" xref="S3.SS2.p3.2.m1.1.1.2.2.cmml">v</mi><mo id="S3.SS2.p3.2.m1.1.1.2.1" xref="S3.SS2.p3.2.m1.1.1.2.1.cmml">~</mo></mover><mo id="S3.SS2.p3.2.m1.1.1.3" xref="S3.SS2.p3.2.m1.1.1.3.cmml">=</mo><mrow id="S3.SS2.p3.2.m1.1.1.4" xref="S3.SS2.p3.2.m1.1.1.4.cmml"><msup id="S3.SS2.p3.2.m1.1.1.4.2" xref="S3.SS2.p3.2.m1.1.1.4.2.cmml"><mi id="S3.SS2.p3.2.m1.1.1.4.2.2" xref="S3.SS2.p3.2.m1.1.1.4.2.2.cmml">v</mi><mo id="S3.SS2.p3.2.m1.1.1.4.2.3" xref="S3.SS2.p3.2.m1.1.1.4.2.3.cmml">âŠº</mo></msup><mo lspace="0em" rspace="0em" id="S3.SS2.p3.2.m1.1.1.4.1" xref="S3.SS2.p3.2.m1.1.1.4.1.cmml">â€‹</mo><msub id="S3.SS2.p3.2.m1.1.1.4.3" xref="S3.SS2.p3.2.m1.1.1.4.3.cmml"><mi id="S3.SS2.p3.2.m1.1.1.4.3.2" xref="S3.SS2.p3.2.m1.1.1.4.3.2.cmml">T</mi><mi id="S3.SS2.p3.2.m1.1.1.4.3.3" xref="S3.SS2.p3.2.m1.1.1.4.3.3.cmml">v</mi></msub></mrow><mo id="S3.SS2.p3.2.m1.1.1.5" xref="S3.SS2.p3.2.m1.1.1.5.cmml">âˆˆ</mo><msup id="S3.SS2.p3.2.m1.1.1.6" xref="S3.SS2.p3.2.m1.1.1.6.cmml"><mi id="S3.SS2.p3.2.m1.1.1.6.2" xref="S3.SS2.p3.2.m1.1.1.6.2.cmml">â„</mi><msub id="S3.SS2.p3.2.m1.1.1.6.3" xref="S3.SS2.p3.2.m1.1.1.6.3.cmml"><mi id="S3.SS2.p3.2.m1.1.1.6.3.2" xref="S3.SS2.p3.2.m1.1.1.6.3.2.cmml">t</mi><mi id="S3.SS2.p3.2.m1.1.1.6.3.3" xref="S3.SS2.p3.2.m1.1.1.6.3.3.cmml">v</mi></msub></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.m1.1b"><apply id="S3.SS2.p3.2.m1.1.1.cmml" xref="S3.SS2.p3.2.m1.1.1"><and id="S3.SS2.p3.2.m1.1.1a.cmml" xref="S3.SS2.p3.2.m1.1.1"></and><apply id="S3.SS2.p3.2.m1.1.1b.cmml" xref="S3.SS2.p3.2.m1.1.1"><eq id="S3.SS2.p3.2.m1.1.1.3.cmml" xref="S3.SS2.p3.2.m1.1.1.3"></eq><apply id="S3.SS2.p3.2.m1.1.1.2.cmml" xref="S3.SS2.p3.2.m1.1.1.2"><ci id="S3.SS2.p3.2.m1.1.1.2.1.cmml" xref="S3.SS2.p3.2.m1.1.1.2.1">~</ci><ci id="S3.SS2.p3.2.m1.1.1.2.2.cmml" xref="S3.SS2.p3.2.m1.1.1.2.2">ğ‘£</ci></apply><apply id="S3.SS2.p3.2.m1.1.1.4.cmml" xref="S3.SS2.p3.2.m1.1.1.4"><times id="S3.SS2.p3.2.m1.1.1.4.1.cmml" xref="S3.SS2.p3.2.m1.1.1.4.1"></times><apply id="S3.SS2.p3.2.m1.1.1.4.2.cmml" xref="S3.SS2.p3.2.m1.1.1.4.2"><csymbol cd="ambiguous" id="S3.SS2.p3.2.m1.1.1.4.2.1.cmml" xref="S3.SS2.p3.2.m1.1.1.4.2">superscript</csymbol><ci id="S3.SS2.p3.2.m1.1.1.4.2.2.cmml" xref="S3.SS2.p3.2.m1.1.1.4.2.2">ğ‘£</ci><ci id="S3.SS2.p3.2.m1.1.1.4.2.3.cmml" xref="S3.SS2.p3.2.m1.1.1.4.2.3">âŠº</ci></apply><apply id="S3.SS2.p3.2.m1.1.1.4.3.cmml" xref="S3.SS2.p3.2.m1.1.1.4.3"><csymbol cd="ambiguous" id="S3.SS2.p3.2.m1.1.1.4.3.1.cmml" xref="S3.SS2.p3.2.m1.1.1.4.3">subscript</csymbol><ci id="S3.SS2.p3.2.m1.1.1.4.3.2.cmml" xref="S3.SS2.p3.2.m1.1.1.4.3.2">ğ‘‡</ci><ci id="S3.SS2.p3.2.m1.1.1.4.3.3.cmml" xref="S3.SS2.p3.2.m1.1.1.4.3.3">ğ‘£</ci></apply></apply></apply><apply id="S3.SS2.p3.2.m1.1.1c.cmml" xref="S3.SS2.p3.2.m1.1.1"><in id="S3.SS2.p3.2.m1.1.1.5.cmml" xref="S3.SS2.p3.2.m1.1.1.5"></in><share href="#S3.SS2.p3.2.m1.1.1.4.cmml" id="S3.SS2.p3.2.m1.1.1d.cmml" xref="S3.SS2.p3.2.m1.1.1"></share><apply id="S3.SS2.p3.2.m1.1.1.6.cmml" xref="S3.SS2.p3.2.m1.1.1.6"><csymbol cd="ambiguous" id="S3.SS2.p3.2.m1.1.1.6.1.cmml" xref="S3.SS2.p3.2.m1.1.1.6">superscript</csymbol><ci id="S3.SS2.p3.2.m1.1.1.6.2.cmml" xref="S3.SS2.p3.2.m1.1.1.6.2">â„</ci><apply id="S3.SS2.p3.2.m1.1.1.6.3.cmml" xref="S3.SS2.p3.2.m1.1.1.6.3"><csymbol cd="ambiguous" id="S3.SS2.p3.2.m1.1.1.6.3.1.cmml" xref="S3.SS2.p3.2.m1.1.1.6.3">subscript</csymbol><ci id="S3.SS2.p3.2.m1.1.1.6.3.2.cmml" xref="S3.SS2.p3.2.m1.1.1.6.3.2">ğ‘¡</ci><ci id="S3.SS2.p3.2.m1.1.1.6.3.3.cmml" xref="S3.SS2.p3.2.m1.1.1.6.3.3">ğ‘£</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.2.m1.1c">\tilde{v}=v^{\intercal}\ T_{v}\in\mathbb{R}^{t_{v}}</annotation></semantics></math> and <math id="S3.SS2.p3.3.m2.1" class="ltx_Math" alttext="\tilde{q}=q^{\intercal}\ T_{q}\in\mathbb{R}^{t_{q}}" display="inline"><semantics id="S3.SS2.p3.3.m2.1a"><mrow id="S3.SS2.p3.3.m2.1.1" xref="S3.SS2.p3.3.m2.1.1.cmml"><mover accent="true" id="S3.SS2.p3.3.m2.1.1.2" xref="S3.SS2.p3.3.m2.1.1.2.cmml"><mi id="S3.SS2.p3.3.m2.1.1.2.2" xref="S3.SS2.p3.3.m2.1.1.2.2.cmml">q</mi><mo id="S3.SS2.p3.3.m2.1.1.2.1" xref="S3.SS2.p3.3.m2.1.1.2.1.cmml">~</mo></mover><mo id="S3.SS2.p3.3.m2.1.1.3" xref="S3.SS2.p3.3.m2.1.1.3.cmml">=</mo><mrow id="S3.SS2.p3.3.m2.1.1.4" xref="S3.SS2.p3.3.m2.1.1.4.cmml"><msup id="S3.SS2.p3.3.m2.1.1.4.2" xref="S3.SS2.p3.3.m2.1.1.4.2.cmml"><mi id="S3.SS2.p3.3.m2.1.1.4.2.2" xref="S3.SS2.p3.3.m2.1.1.4.2.2.cmml">q</mi><mo id="S3.SS2.p3.3.m2.1.1.4.2.3" xref="S3.SS2.p3.3.m2.1.1.4.2.3.cmml">âŠº</mo></msup><mo lspace="0em" rspace="0em" id="S3.SS2.p3.3.m2.1.1.4.1" xref="S3.SS2.p3.3.m2.1.1.4.1.cmml">â€‹</mo><msub id="S3.SS2.p3.3.m2.1.1.4.3" xref="S3.SS2.p3.3.m2.1.1.4.3.cmml"><mi id="S3.SS2.p3.3.m2.1.1.4.3.2" xref="S3.SS2.p3.3.m2.1.1.4.3.2.cmml">T</mi><mi id="S3.SS2.p3.3.m2.1.1.4.3.3" xref="S3.SS2.p3.3.m2.1.1.4.3.3.cmml">q</mi></msub></mrow><mo id="S3.SS2.p3.3.m2.1.1.5" xref="S3.SS2.p3.3.m2.1.1.5.cmml">âˆˆ</mo><msup id="S3.SS2.p3.3.m2.1.1.6" xref="S3.SS2.p3.3.m2.1.1.6.cmml"><mi id="S3.SS2.p3.3.m2.1.1.6.2" xref="S3.SS2.p3.3.m2.1.1.6.2.cmml">â„</mi><msub id="S3.SS2.p3.3.m2.1.1.6.3" xref="S3.SS2.p3.3.m2.1.1.6.3.cmml"><mi id="S3.SS2.p3.3.m2.1.1.6.3.2" xref="S3.SS2.p3.3.m2.1.1.6.3.2.cmml">t</mi><mi id="S3.SS2.p3.3.m2.1.1.6.3.3" xref="S3.SS2.p3.3.m2.1.1.6.3.3.cmml">q</mi></msub></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.3.m2.1b"><apply id="S3.SS2.p3.3.m2.1.1.cmml" xref="S3.SS2.p3.3.m2.1.1"><and id="S3.SS2.p3.3.m2.1.1a.cmml" xref="S3.SS2.p3.3.m2.1.1"></and><apply id="S3.SS2.p3.3.m2.1.1b.cmml" xref="S3.SS2.p3.3.m2.1.1"><eq id="S3.SS2.p3.3.m2.1.1.3.cmml" xref="S3.SS2.p3.3.m2.1.1.3"></eq><apply id="S3.SS2.p3.3.m2.1.1.2.cmml" xref="S3.SS2.p3.3.m2.1.1.2"><ci id="S3.SS2.p3.3.m2.1.1.2.1.cmml" xref="S3.SS2.p3.3.m2.1.1.2.1">~</ci><ci id="S3.SS2.p3.3.m2.1.1.2.2.cmml" xref="S3.SS2.p3.3.m2.1.1.2.2">ğ‘</ci></apply><apply id="S3.SS2.p3.3.m2.1.1.4.cmml" xref="S3.SS2.p3.3.m2.1.1.4"><times id="S3.SS2.p3.3.m2.1.1.4.1.cmml" xref="S3.SS2.p3.3.m2.1.1.4.1"></times><apply id="S3.SS2.p3.3.m2.1.1.4.2.cmml" xref="S3.SS2.p3.3.m2.1.1.4.2"><csymbol cd="ambiguous" id="S3.SS2.p3.3.m2.1.1.4.2.1.cmml" xref="S3.SS2.p3.3.m2.1.1.4.2">superscript</csymbol><ci id="S3.SS2.p3.3.m2.1.1.4.2.2.cmml" xref="S3.SS2.p3.3.m2.1.1.4.2.2">ğ‘</ci><ci id="S3.SS2.p3.3.m2.1.1.4.2.3.cmml" xref="S3.SS2.p3.3.m2.1.1.4.2.3">âŠº</ci></apply><apply id="S3.SS2.p3.3.m2.1.1.4.3.cmml" xref="S3.SS2.p3.3.m2.1.1.4.3"><csymbol cd="ambiguous" id="S3.SS2.p3.3.m2.1.1.4.3.1.cmml" xref="S3.SS2.p3.3.m2.1.1.4.3">subscript</csymbol><ci id="S3.SS2.p3.3.m2.1.1.4.3.2.cmml" xref="S3.SS2.p3.3.m2.1.1.4.3.2">ğ‘‡</ci><ci id="S3.SS2.p3.3.m2.1.1.4.3.3.cmml" xref="S3.SS2.p3.3.m2.1.1.4.3.3">ğ‘</ci></apply></apply></apply><apply id="S3.SS2.p3.3.m2.1.1c.cmml" xref="S3.SS2.p3.3.m2.1.1"><in id="S3.SS2.p3.3.m2.1.1.5.cmml" xref="S3.SS2.p3.3.m2.1.1.5"></in><share href="#S3.SS2.p3.3.m2.1.1.4.cmml" id="S3.SS2.p3.3.m2.1.1d.cmml" xref="S3.SS2.p3.3.m2.1.1"></share><apply id="S3.SS2.p3.3.m2.1.1.6.cmml" xref="S3.SS2.p3.3.m2.1.1.6"><csymbol cd="ambiguous" id="S3.SS2.p3.3.m2.1.1.6.1.cmml" xref="S3.SS2.p3.3.m2.1.1.6">superscript</csymbol><ci id="S3.SS2.p3.3.m2.1.1.6.2.cmml" xref="S3.SS2.p3.3.m2.1.1.6.2">â„</ci><apply id="S3.SS2.p3.3.m2.1.1.6.3.cmml" xref="S3.SS2.p3.3.m2.1.1.6.3"><csymbol cd="ambiguous" id="S3.SS2.p3.3.m2.1.1.6.3.1.cmml" xref="S3.SS2.p3.3.m2.1.1.6.3">subscript</csymbol><ci id="S3.SS2.p3.3.m2.1.1.6.3.2.cmml" xref="S3.SS2.p3.3.m2.1.1.6.3.2">ğ‘¡</ci><ci id="S3.SS2.p3.3.m2.1.1.6.3.3.cmml" xref="S3.SS2.p3.3.m2.1.1.6.3.3">ğ‘</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.3.m2.1c">\tilde{q}=q^{\intercal}\ T_{q}\in\mathbb{R}^{t_{q}}</annotation></semantics></math>. We define a prediction space <math id="S3.SS2.p3.4.m3.1" class="ltx_Math" alttext="\rho=\tau^{\intercal}\ T_{\rho}\in\mathbb{R}^{n_{\rho}}" display="inline"><semantics id="S3.SS2.p3.4.m3.1a"><mrow id="S3.SS2.p3.4.m3.1.1" xref="S3.SS2.p3.4.m3.1.1.cmml"><mi id="S3.SS2.p3.4.m3.1.1.2" xref="S3.SS2.p3.4.m3.1.1.2.cmml">Ï</mi><mo id="S3.SS2.p3.4.m3.1.1.3" xref="S3.SS2.p3.4.m3.1.1.3.cmml">=</mo><mrow id="S3.SS2.p3.4.m3.1.1.4" xref="S3.SS2.p3.4.m3.1.1.4.cmml"><msup id="S3.SS2.p3.4.m3.1.1.4.2" xref="S3.SS2.p3.4.m3.1.1.4.2.cmml"><mi id="S3.SS2.p3.4.m3.1.1.4.2.2" xref="S3.SS2.p3.4.m3.1.1.4.2.2.cmml">Ï„</mi><mo id="S3.SS2.p3.4.m3.1.1.4.2.3" xref="S3.SS2.p3.4.m3.1.1.4.2.3.cmml">âŠº</mo></msup><mo lspace="0em" rspace="0em" id="S3.SS2.p3.4.m3.1.1.4.1" xref="S3.SS2.p3.4.m3.1.1.4.1.cmml">â€‹</mo><msub id="S3.SS2.p3.4.m3.1.1.4.3" xref="S3.SS2.p3.4.m3.1.1.4.3.cmml"><mi id="S3.SS2.p3.4.m3.1.1.4.3.2" xref="S3.SS2.p3.4.m3.1.1.4.3.2.cmml">T</mi><mi id="S3.SS2.p3.4.m3.1.1.4.3.3" xref="S3.SS2.p3.4.m3.1.1.4.3.3.cmml">Ï</mi></msub></mrow><mo id="S3.SS2.p3.4.m3.1.1.5" xref="S3.SS2.p3.4.m3.1.1.5.cmml">âˆˆ</mo><msup id="S3.SS2.p3.4.m3.1.1.6" xref="S3.SS2.p3.4.m3.1.1.6.cmml"><mi id="S3.SS2.p3.4.m3.1.1.6.2" xref="S3.SS2.p3.4.m3.1.1.6.2.cmml">â„</mi><msub id="S3.SS2.p3.4.m3.1.1.6.3" xref="S3.SS2.p3.4.m3.1.1.6.3.cmml"><mi id="S3.SS2.p3.4.m3.1.1.6.3.2" xref="S3.SS2.p3.4.m3.1.1.6.3.2.cmml">n</mi><mi id="S3.SS2.p3.4.m3.1.1.6.3.3" xref="S3.SS2.p3.4.m3.1.1.6.3.3.cmml">Ï</mi></msub></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.4.m3.1b"><apply id="S3.SS2.p3.4.m3.1.1.cmml" xref="S3.SS2.p3.4.m3.1.1"><and id="S3.SS2.p3.4.m3.1.1a.cmml" xref="S3.SS2.p3.4.m3.1.1"></and><apply id="S3.SS2.p3.4.m3.1.1b.cmml" xref="S3.SS2.p3.4.m3.1.1"><eq id="S3.SS2.p3.4.m3.1.1.3.cmml" xref="S3.SS2.p3.4.m3.1.1.3"></eq><ci id="S3.SS2.p3.4.m3.1.1.2.cmml" xref="S3.SS2.p3.4.m3.1.1.2">ğœŒ</ci><apply id="S3.SS2.p3.4.m3.1.1.4.cmml" xref="S3.SS2.p3.4.m3.1.1.4"><times id="S3.SS2.p3.4.m3.1.1.4.1.cmml" xref="S3.SS2.p3.4.m3.1.1.4.1"></times><apply id="S3.SS2.p3.4.m3.1.1.4.2.cmml" xref="S3.SS2.p3.4.m3.1.1.4.2"><csymbol cd="ambiguous" id="S3.SS2.p3.4.m3.1.1.4.2.1.cmml" xref="S3.SS2.p3.4.m3.1.1.4.2">superscript</csymbol><ci id="S3.SS2.p3.4.m3.1.1.4.2.2.cmml" xref="S3.SS2.p3.4.m3.1.1.4.2.2">ğœ</ci><ci id="S3.SS2.p3.4.m3.1.1.4.2.3.cmml" xref="S3.SS2.p3.4.m3.1.1.4.2.3">âŠº</ci></apply><apply id="S3.SS2.p3.4.m3.1.1.4.3.cmml" xref="S3.SS2.p3.4.m3.1.1.4.3"><csymbol cd="ambiguous" id="S3.SS2.p3.4.m3.1.1.4.3.1.cmml" xref="S3.SS2.p3.4.m3.1.1.4.3">subscript</csymbol><ci id="S3.SS2.p3.4.m3.1.1.4.3.2.cmml" xref="S3.SS2.p3.4.m3.1.1.4.3.2">ğ‘‡</ci><ci id="S3.SS2.p3.4.m3.1.1.4.3.3.cmml" xref="S3.SS2.p3.4.m3.1.1.4.3.3">ğœŒ</ci></apply></apply></apply><apply id="S3.SS2.p3.4.m3.1.1c.cmml" xref="S3.SS2.p3.4.m3.1.1"><in id="S3.SS2.p3.4.m3.1.1.5.cmml" xref="S3.SS2.p3.4.m3.1.1.5"></in><share href="#S3.SS2.p3.4.m3.1.1.4.cmml" id="S3.SS2.p3.4.m3.1.1d.cmml" xref="S3.SS2.p3.4.m3.1.1"></share><apply id="S3.SS2.p3.4.m3.1.1.6.cmml" xref="S3.SS2.p3.4.m3.1.1.6"><csymbol cd="ambiguous" id="S3.SS2.p3.4.m3.1.1.6.1.cmml" xref="S3.SS2.p3.4.m3.1.1.6">superscript</csymbol><ci id="S3.SS2.p3.4.m3.1.1.6.2.cmml" xref="S3.SS2.p3.4.m3.1.1.6.2">â„</ci><apply id="S3.SS2.p3.4.m3.1.1.6.3.cmml" xref="S3.SS2.p3.4.m3.1.1.6.3"><csymbol cd="ambiguous" id="S3.SS2.p3.4.m3.1.1.6.3.1.cmml" xref="S3.SS2.p3.4.m3.1.1.6.3">subscript</csymbol><ci id="S3.SS2.p3.4.m3.1.1.6.3.2.cmml" xref="S3.SS2.p3.4.m3.1.1.6.3.2">ğ‘›</ci><ci id="S3.SS2.p3.4.m3.1.1.6.3.3.cmml" xref="S3.SS2.p3.4.m3.1.1.6.3.3">ğœŒ</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.4.m3.1c">\rho=\tau^{\intercal}\ T_{\rho}\in\mathbb{R}^{n_{\rho}}</annotation></semantics></math> where the multi-modal fusion <math id="S3.SS2.p3.5.m4.1" class="ltx_Math" alttext="\tau" display="inline"><semantics id="S3.SS2.p3.5.m4.1a"><mi id="S3.SS2.p3.5.m4.1.1" xref="S3.SS2.p3.5.m4.1.1.cmml">Ï„</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.5.m4.1b"><ci id="S3.SS2.p3.5.m4.1.1.cmml" xref="S3.SS2.p3.5.m4.1.1">ğœ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.5.m4.1c">\tau</annotation></semantics></math> is:</p>
<table id="S3.E5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E5.m1.1" class="ltx_Math" alttext="\tau=T_{c}\ \times_{1}\ \tilde{q}\ \times_{2}\ \tilde{v}\ \in\mathbb{R}^{t_{\rho}}" display="block"><semantics id="S3.E5.m1.1a"><mrow id="S3.E5.m1.1.1" xref="S3.E5.m1.1.1.cmml"><mi id="S3.E5.m1.1.1.2" xref="S3.E5.m1.1.1.2.cmml">Ï„</mi><mo id="S3.E5.m1.1.1.3" xref="S3.E5.m1.1.1.3.cmml">=</mo><mrow id="S3.E5.m1.1.1.4" xref="S3.E5.m1.1.1.4.cmml"><mrow id="S3.E5.m1.1.1.4.2" xref="S3.E5.m1.1.1.4.2.cmml"><msub id="S3.E5.m1.1.1.4.2.2" xref="S3.E5.m1.1.1.4.2.2.cmml"><mi id="S3.E5.m1.1.1.4.2.2.2" xref="S3.E5.m1.1.1.4.2.2.2.cmml">T</mi><mi id="S3.E5.m1.1.1.4.2.2.3" xref="S3.E5.m1.1.1.4.2.2.3.cmml">c</mi></msub><msub id="S3.E5.m1.1.1.4.2.1" xref="S3.E5.m1.1.1.4.2.1.cmml"><mo lspace="0.222em" rspace="0.222em" id="S3.E5.m1.1.1.4.2.1.2" xref="S3.E5.m1.1.1.4.2.1.2.cmml">Ã—</mo><mn id="S3.E5.m1.1.1.4.2.1.3" xref="S3.E5.m1.1.1.4.2.1.3.cmml">1</mn></msub><mover accent="true" id="S3.E5.m1.1.1.4.2.3" xref="S3.E5.m1.1.1.4.2.3.cmml"><mi id="S3.E5.m1.1.1.4.2.3.2" xref="S3.E5.m1.1.1.4.2.3.2.cmml">q</mi><mo id="S3.E5.m1.1.1.4.2.3.1" xref="S3.E5.m1.1.1.4.2.3.1.cmml">~</mo></mover></mrow><msub id="S3.E5.m1.1.1.4.1" xref="S3.E5.m1.1.1.4.1.cmml"><mo lspace="0.222em" rspace="0.222em" id="S3.E5.m1.1.1.4.1.2" xref="S3.E5.m1.1.1.4.1.2.cmml">Ã—</mo><mn id="S3.E5.m1.1.1.4.1.3" xref="S3.E5.m1.1.1.4.1.3.cmml">2</mn></msub><mover accent="true" id="S3.E5.m1.1.1.4.3" xref="S3.E5.m1.1.1.4.3.cmml"><mi id="S3.E5.m1.1.1.4.3.2" xref="S3.E5.m1.1.1.4.3.2.cmml">v</mi><mo id="S3.E5.m1.1.1.4.3.1" xref="S3.E5.m1.1.1.4.3.1.cmml">~</mo></mover></mrow><mo id="S3.E5.m1.1.1.5" xref="S3.E5.m1.1.1.5.cmml">âˆˆ</mo><msup id="S3.E5.m1.1.1.6" xref="S3.E5.m1.1.1.6.cmml"><mi id="S3.E5.m1.1.1.6.2" xref="S3.E5.m1.1.1.6.2.cmml">â„</mi><msub id="S3.E5.m1.1.1.6.3" xref="S3.E5.m1.1.1.6.3.cmml"><mi id="S3.E5.m1.1.1.6.3.2" xref="S3.E5.m1.1.1.6.3.2.cmml">t</mi><mi id="S3.E5.m1.1.1.6.3.3" xref="S3.E5.m1.1.1.6.3.3.cmml">Ï</mi></msub></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.E5.m1.1b"><apply id="S3.E5.m1.1.1.cmml" xref="S3.E5.m1.1.1"><and id="S3.E5.m1.1.1a.cmml" xref="S3.E5.m1.1.1"></and><apply id="S3.E5.m1.1.1b.cmml" xref="S3.E5.m1.1.1"><eq id="S3.E5.m1.1.1.3.cmml" xref="S3.E5.m1.1.1.3"></eq><ci id="S3.E5.m1.1.1.2.cmml" xref="S3.E5.m1.1.1.2">ğœ</ci><apply id="S3.E5.m1.1.1.4.cmml" xref="S3.E5.m1.1.1.4"><apply id="S3.E5.m1.1.1.4.1.cmml" xref="S3.E5.m1.1.1.4.1"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.4.1.1.cmml" xref="S3.E5.m1.1.1.4.1">subscript</csymbol><times id="S3.E5.m1.1.1.4.1.2.cmml" xref="S3.E5.m1.1.1.4.1.2"></times><cn type="integer" id="S3.E5.m1.1.1.4.1.3.cmml" xref="S3.E5.m1.1.1.4.1.3">2</cn></apply><apply id="S3.E5.m1.1.1.4.2.cmml" xref="S3.E5.m1.1.1.4.2"><apply id="S3.E5.m1.1.1.4.2.1.cmml" xref="S3.E5.m1.1.1.4.2.1"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.4.2.1.1.cmml" xref="S3.E5.m1.1.1.4.2.1">subscript</csymbol><times id="S3.E5.m1.1.1.4.2.1.2.cmml" xref="S3.E5.m1.1.1.4.2.1.2"></times><cn type="integer" id="S3.E5.m1.1.1.4.2.1.3.cmml" xref="S3.E5.m1.1.1.4.2.1.3">1</cn></apply><apply id="S3.E5.m1.1.1.4.2.2.cmml" xref="S3.E5.m1.1.1.4.2.2"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.4.2.2.1.cmml" xref="S3.E5.m1.1.1.4.2.2">subscript</csymbol><ci id="S3.E5.m1.1.1.4.2.2.2.cmml" xref="S3.E5.m1.1.1.4.2.2.2">ğ‘‡</ci><ci id="S3.E5.m1.1.1.4.2.2.3.cmml" xref="S3.E5.m1.1.1.4.2.2.3">ğ‘</ci></apply><apply id="S3.E5.m1.1.1.4.2.3.cmml" xref="S3.E5.m1.1.1.4.2.3"><ci id="S3.E5.m1.1.1.4.2.3.1.cmml" xref="S3.E5.m1.1.1.4.2.3.1">~</ci><ci id="S3.E5.m1.1.1.4.2.3.2.cmml" xref="S3.E5.m1.1.1.4.2.3.2">ğ‘</ci></apply></apply><apply id="S3.E5.m1.1.1.4.3.cmml" xref="S3.E5.m1.1.1.4.3"><ci id="S3.E5.m1.1.1.4.3.1.cmml" xref="S3.E5.m1.1.1.4.3.1">~</ci><ci id="S3.E5.m1.1.1.4.3.2.cmml" xref="S3.E5.m1.1.1.4.3.2">ğ‘£</ci></apply></apply></apply><apply id="S3.E5.m1.1.1c.cmml" xref="S3.E5.m1.1.1"><in id="S3.E5.m1.1.1.5.cmml" xref="S3.E5.m1.1.1.5"></in><share href="#S3.E5.m1.1.1.4.cmml" id="S3.E5.m1.1.1d.cmml" xref="S3.E5.m1.1.1"></share><apply id="S3.E5.m1.1.1.6.cmml" xref="S3.E5.m1.1.1.6"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.6.1.cmml" xref="S3.E5.m1.1.1.6">superscript</csymbol><ci id="S3.E5.m1.1.1.6.2.cmml" xref="S3.E5.m1.1.1.6.2">â„</ci><apply id="S3.E5.m1.1.1.6.3.cmml" xref="S3.E5.m1.1.1.6.3"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.6.3.1.cmml" xref="S3.E5.m1.1.1.6.3">subscript</csymbol><ci id="S3.E5.m1.1.1.6.3.2.cmml" xref="S3.E5.m1.1.1.6.3.2">ğ‘¡</ci><ci id="S3.E5.m1.1.1.6.3.3.cmml" xref="S3.E5.m1.1.1.6.3.3">ğœŒ</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E5.m1.1c">\tau=T_{c}\ \times_{1}\ \tilde{q}\ \times_{2}\ \tilde{v}\ \in\mathbb{R}^{t_{\rho}}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS2.p4" class="ltx_para">
<p id="S3.SS2.p4.17" class="ltx_p">The Tucker decomposition allows our model to decompose <math id="S3.SS2.p4.1.m1.1" class="ltx_Math" alttext="W" display="inline"><semantics id="S3.SS2.p4.1.m1.1a"><mi id="S3.SS2.p4.1.m1.1.1" xref="S3.SS2.p4.1.m1.1.1.cmml">W</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.1.m1.1b"><ci id="S3.SS2.p4.1.m1.1.1.cmml" xref="S3.SS2.p4.1.m1.1.1">ğ‘Š</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.1.m1.1c">W</annotation></semantics></math> into a core tensor <math id="S3.SS2.p4.2.m2.1" class="ltx_Math" alttext="T_{c}" display="inline"><semantics id="S3.SS2.p4.2.m2.1a"><msub id="S3.SS2.p4.2.m2.1.1" xref="S3.SS2.p4.2.m2.1.1.cmml"><mi id="S3.SS2.p4.2.m2.1.1.2" xref="S3.SS2.p4.2.m2.1.1.2.cmml">T</mi><mi id="S3.SS2.p4.2.m2.1.1.3" xref="S3.SS2.p4.2.m2.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.2.m2.1b"><apply id="S3.SS2.p4.2.m2.1.1.cmml" xref="S3.SS2.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.2.m2.1.1.1.cmml" xref="S3.SS2.p4.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.p4.2.m2.1.1.2.cmml" xref="S3.SS2.p4.2.m2.1.1.2">ğ‘‡</ci><ci id="S3.SS2.p4.2.m2.1.1.3.cmml" xref="S3.SS2.p4.2.m2.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.2.m2.1c">T_{c}</annotation></semantics></math> and three matrices. The first two matrices, <math id="S3.SS2.p4.3.m3.1" class="ltx_Math" alttext="T_{q}" display="inline"><semantics id="S3.SS2.p4.3.m3.1a"><msub id="S3.SS2.p4.3.m3.1.1" xref="S3.SS2.p4.3.m3.1.1.cmml"><mi id="S3.SS2.p4.3.m3.1.1.2" xref="S3.SS2.p4.3.m3.1.1.2.cmml">T</mi><mi id="S3.SS2.p4.3.m3.1.1.3" xref="S3.SS2.p4.3.m3.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.3.m3.1b"><apply id="S3.SS2.p4.3.m3.1.1.cmml" xref="S3.SS2.p4.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.3.m3.1.1.1.cmml" xref="S3.SS2.p4.3.m3.1.1">subscript</csymbol><ci id="S3.SS2.p4.3.m3.1.1.2.cmml" xref="S3.SS2.p4.3.m3.1.1.2">ğ‘‡</ci><ci id="S3.SS2.p4.3.m3.1.1.3.cmml" xref="S3.SS2.p4.3.m3.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.3.m3.1c">T_{q}</annotation></semantics></math> and <math id="S3.SS2.p4.4.m4.1" class="ltx_Math" alttext="T_{v}" display="inline"><semantics id="S3.SS2.p4.4.m4.1a"><msub id="S3.SS2.p4.4.m4.1.1" xref="S3.SS2.p4.4.m4.1.1.cmml"><mi id="S3.SS2.p4.4.m4.1.1.2" xref="S3.SS2.p4.4.m4.1.1.2.cmml">T</mi><mi id="S3.SS2.p4.4.m4.1.1.3" xref="S3.SS2.p4.4.m4.1.1.3.cmml">v</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.4.m4.1b"><apply id="S3.SS2.p4.4.m4.1.1.cmml" xref="S3.SS2.p4.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.4.m4.1.1.1.cmml" xref="S3.SS2.p4.4.m4.1.1">subscript</csymbol><ci id="S3.SS2.p4.4.m4.1.1.2.cmml" xref="S3.SS2.p4.4.m4.1.1.2">ğ‘‡</ci><ci id="S3.SS2.p4.4.m4.1.1.3.cmml" xref="S3.SS2.p4.4.m4.1.1.3">ğ‘£</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.4.m4.1c">T_{v}</annotation></semantics></math> project the question and visual embeddings to lower <math id="S3.SS2.p4.5.m5.1" class="ltx_Math" alttext="t_{q}" display="inline"><semantics id="S3.SS2.p4.5.m5.1a"><msub id="S3.SS2.p4.5.m5.1.1" xref="S3.SS2.p4.5.m5.1.1.cmml"><mi id="S3.SS2.p4.5.m5.1.1.2" xref="S3.SS2.p4.5.m5.1.1.2.cmml">t</mi><mi id="S3.SS2.p4.5.m5.1.1.3" xref="S3.SS2.p4.5.m5.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.5.m5.1b"><apply id="S3.SS2.p4.5.m5.1.1.cmml" xref="S3.SS2.p4.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.5.m5.1.1.1.cmml" xref="S3.SS2.p4.5.m5.1.1">subscript</csymbol><ci id="S3.SS2.p4.5.m5.1.1.2.cmml" xref="S3.SS2.p4.5.m5.1.1.2">ğ‘¡</ci><ci id="S3.SS2.p4.5.m5.1.1.3.cmml" xref="S3.SS2.p4.5.m5.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.5.m5.1c">t_{q}</annotation></semantics></math> and <math id="S3.SS2.p4.6.m6.1" class="ltx_Math" alttext="t_{v}" display="inline"><semantics id="S3.SS2.p4.6.m6.1a"><msub id="S3.SS2.p4.6.m6.1.1" xref="S3.SS2.p4.6.m6.1.1.cmml"><mi id="S3.SS2.p4.6.m6.1.1.2" xref="S3.SS2.p4.6.m6.1.1.2.cmml">t</mi><mi id="S3.SS2.p4.6.m6.1.1.3" xref="S3.SS2.p4.6.m6.1.1.3.cmml">v</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.6.m6.1b"><apply id="S3.SS2.p4.6.m6.1.1.cmml" xref="S3.SS2.p4.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.6.m6.1.1.1.cmml" xref="S3.SS2.p4.6.m6.1.1">subscript</csymbol><ci id="S3.SS2.p4.6.m6.1.1.2.cmml" xref="S3.SS2.p4.6.m6.1.1.2">ğ‘¡</ci><ci id="S3.SS2.p4.6.m6.1.1.3.cmml" xref="S3.SS2.p4.6.m6.1.1.3">ğ‘£</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.6.m6.1c">t_{v}</annotation></semantics></math> dimensional space that learns to model the multi-modal interaction and projects the resulting output to <math id="S3.SS2.p4.7.m7.1" class="ltx_Math" alttext="t_{\rho}" display="inline"><semantics id="S3.SS2.p4.7.m7.1a"><msub id="S3.SS2.p4.7.m7.1.1" xref="S3.SS2.p4.7.m7.1.1.cmml"><mi id="S3.SS2.p4.7.m7.1.1.2" xref="S3.SS2.p4.7.m7.1.1.2.cmml">t</mi><mi id="S3.SS2.p4.7.m7.1.1.3" xref="S3.SS2.p4.7.m7.1.1.3.cmml">Ï</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.7.m7.1b"><apply id="S3.SS2.p4.7.m7.1.1.cmml" xref="S3.SS2.p4.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.7.m7.1.1.1.cmml" xref="S3.SS2.p4.7.m7.1.1">subscript</csymbol><ci id="S3.SS2.p4.7.m7.1.1.2.cmml" xref="S3.SS2.p4.7.m7.1.1.2">ğ‘¡</ci><ci id="S3.SS2.p4.7.m7.1.1.3.cmml" xref="S3.SS2.p4.7.m7.1.1.3">ğœŒ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.7.m7.1c">t_{\rho}</annotation></semantics></math> dimensional vector. We set the input projections dimension to <math id="S3.SS2.p4.8.m8.1" class="ltx_Math" alttext="t_{q}=t_{v}=310" display="inline"><semantics id="S3.SS2.p4.8.m8.1a"><mrow id="S3.SS2.p4.8.m8.1.1" xref="S3.SS2.p4.8.m8.1.1.cmml"><msub id="S3.SS2.p4.8.m8.1.1.2" xref="S3.SS2.p4.8.m8.1.1.2.cmml"><mi id="S3.SS2.p4.8.m8.1.1.2.2" xref="S3.SS2.p4.8.m8.1.1.2.2.cmml">t</mi><mi id="S3.SS2.p4.8.m8.1.1.2.3" xref="S3.SS2.p4.8.m8.1.1.2.3.cmml">q</mi></msub><mo id="S3.SS2.p4.8.m8.1.1.3" xref="S3.SS2.p4.8.m8.1.1.3.cmml">=</mo><msub id="S3.SS2.p4.8.m8.1.1.4" xref="S3.SS2.p4.8.m8.1.1.4.cmml"><mi id="S3.SS2.p4.8.m8.1.1.4.2" xref="S3.SS2.p4.8.m8.1.1.4.2.cmml">t</mi><mi id="S3.SS2.p4.8.m8.1.1.4.3" xref="S3.SS2.p4.8.m8.1.1.4.3.cmml">v</mi></msub><mo id="S3.SS2.p4.8.m8.1.1.5" xref="S3.SS2.p4.8.m8.1.1.5.cmml">=</mo><mn id="S3.SS2.p4.8.m8.1.1.6" xref="S3.SS2.p4.8.m8.1.1.6.cmml">310</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.8.m8.1b"><apply id="S3.SS2.p4.8.m8.1.1.cmml" xref="S3.SS2.p4.8.m8.1.1"><and id="S3.SS2.p4.8.m8.1.1a.cmml" xref="S3.SS2.p4.8.m8.1.1"></and><apply id="S3.SS2.p4.8.m8.1.1b.cmml" xref="S3.SS2.p4.8.m8.1.1"><eq id="S3.SS2.p4.8.m8.1.1.3.cmml" xref="S3.SS2.p4.8.m8.1.1.3"></eq><apply id="S3.SS2.p4.8.m8.1.1.2.cmml" xref="S3.SS2.p4.8.m8.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p4.8.m8.1.1.2.1.cmml" xref="S3.SS2.p4.8.m8.1.1.2">subscript</csymbol><ci id="S3.SS2.p4.8.m8.1.1.2.2.cmml" xref="S3.SS2.p4.8.m8.1.1.2.2">ğ‘¡</ci><ci id="S3.SS2.p4.8.m8.1.1.2.3.cmml" xref="S3.SS2.p4.8.m8.1.1.2.3">ğ‘</ci></apply><apply id="S3.SS2.p4.8.m8.1.1.4.cmml" xref="S3.SS2.p4.8.m8.1.1.4"><csymbol cd="ambiguous" id="S3.SS2.p4.8.m8.1.1.4.1.cmml" xref="S3.SS2.p4.8.m8.1.1.4">subscript</csymbol><ci id="S3.SS2.p4.8.m8.1.1.4.2.cmml" xref="S3.SS2.p4.8.m8.1.1.4.2">ğ‘¡</ci><ci id="S3.SS2.p4.8.m8.1.1.4.3.cmml" xref="S3.SS2.p4.8.m8.1.1.4.3">ğ‘£</ci></apply></apply><apply id="S3.SS2.p4.8.m8.1.1c.cmml" xref="S3.SS2.p4.8.m8.1.1"><eq id="S3.SS2.p4.8.m8.1.1.5.cmml" xref="S3.SS2.p4.8.m8.1.1.5"></eq><share href="#S3.SS2.p4.8.m8.1.1.4.cmml" id="S3.SS2.p4.8.m8.1.1d.cmml" xref="S3.SS2.p4.8.m8.1.1"></share><cn type="integer" id="S3.SS2.p4.8.m8.1.1.6.cmml" xref="S3.SS2.p4.8.m8.1.1.6">310</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.8.m8.1c">t_{q}=t_{v}=310</annotation></semantics></math> and output projection dimension as <math id="S3.SS2.p4.9.m9.1" class="ltx_Math" alttext="t_{\rho}=510" display="inline"><semantics id="S3.SS2.p4.9.m9.1a"><mrow id="S3.SS2.p4.9.m9.1.1" xref="S3.SS2.p4.9.m9.1.1.cmml"><msub id="S3.SS2.p4.9.m9.1.1.2" xref="S3.SS2.p4.9.m9.1.1.2.cmml"><mi id="S3.SS2.p4.9.m9.1.1.2.2" xref="S3.SS2.p4.9.m9.1.1.2.2.cmml">t</mi><mi id="S3.SS2.p4.9.m9.1.1.2.3" xref="S3.SS2.p4.9.m9.1.1.2.3.cmml">Ï</mi></msub><mo id="S3.SS2.p4.9.m9.1.1.1" xref="S3.SS2.p4.9.m9.1.1.1.cmml">=</mo><mn id="S3.SS2.p4.9.m9.1.1.3" xref="S3.SS2.p4.9.m9.1.1.3.cmml">510</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.9.m9.1b"><apply id="S3.SS2.p4.9.m9.1.1.cmml" xref="S3.SS2.p4.9.m9.1.1"><eq id="S3.SS2.p4.9.m9.1.1.1.cmml" xref="S3.SS2.p4.9.m9.1.1.1"></eq><apply id="S3.SS2.p4.9.m9.1.1.2.cmml" xref="S3.SS2.p4.9.m9.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p4.9.m9.1.1.2.1.cmml" xref="S3.SS2.p4.9.m9.1.1.2">subscript</csymbol><ci id="S3.SS2.p4.9.m9.1.1.2.2.cmml" xref="S3.SS2.p4.9.m9.1.1.2.2">ğ‘¡</ci><ci id="S3.SS2.p4.9.m9.1.1.2.3.cmml" xref="S3.SS2.p4.9.m9.1.1.2.3">ğœŒ</ci></apply><cn type="integer" id="S3.SS2.p4.9.m9.1.1.3.cmml" xref="S3.SS2.p4.9.m9.1.1.3">510</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.9.m9.1c">t_{\rho}=510</annotation></semantics></math>. The input and output tensor projection dimensions determine the complexity of the model and the degree of multi-modal interaction which in turn affects the performance of the model. These values are set empirically by testing them on VQAv1 validation dataset. It has been reported in the literature <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:70%;">Fukui etÂ al.</span>, <a href="#bib.bib10" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">2016</span></a>; <span class="ltx_text" style="font-size:70%;">Ben-Younes etÂ al.</span>, <a href="#bib.bib5" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">2017</span></a>)</cite> that applying nonlinearity to the input feature embeddings improve performance of multi-modal fusion. Therefore, we encode <math id="S3.SS2.p4.10.m10.1" class="ltx_Math" alttext="\tilde{v}" display="inline"><semantics id="S3.SS2.p4.10.m10.1a"><mover accent="true" id="S3.SS2.p4.10.m10.1.1" xref="S3.SS2.p4.10.m10.1.1.cmml"><mi id="S3.SS2.p4.10.m10.1.1.2" xref="S3.SS2.p4.10.m10.1.1.2.cmml">v</mi><mo id="S3.SS2.p4.10.m10.1.1.1" xref="S3.SS2.p4.10.m10.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.10.m10.1b"><apply id="S3.SS2.p4.10.m10.1.1.cmml" xref="S3.SS2.p4.10.m10.1.1"><ci id="S3.SS2.p4.10.m10.1.1.1.cmml" xref="S3.SS2.p4.10.m10.1.1.1">~</ci><ci id="S3.SS2.p4.10.m10.1.1.2.cmml" xref="S3.SS2.p4.10.m10.1.1.2">ğ‘£</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.10.m10.1c">\tilde{v}</annotation></semantics></math> and <math id="S3.SS2.p4.11.m11.1" class="ltx_Math" alttext="\tilde{q}" display="inline"><semantics id="S3.SS2.p4.11.m11.1a"><mover accent="true" id="S3.SS2.p4.11.m11.1.1" xref="S3.SS2.p4.11.m11.1.1.cmml"><mi id="S3.SS2.p4.11.m11.1.1.2" xref="S3.SS2.p4.11.m11.1.1.2.cmml">q</mi><mo id="S3.SS2.p4.11.m11.1.1.1" xref="S3.SS2.p4.11.m11.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.11.m11.1b"><apply id="S3.SS2.p4.11.m11.1.1.cmml" xref="S3.SS2.p4.11.m11.1.1"><ci id="S3.SS2.p4.11.m11.1.1.1.cmml" xref="S3.SS2.p4.11.m11.1.1.1">~</ci><ci id="S3.SS2.p4.11.m11.1.1.2.cmml" xref="S3.SS2.p4.11.m11.1.1.2">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.11.m11.1c">\tilde{q}</annotation></semantics></math> with <math id="S3.SS2.p4.12.m12.1" class="ltx_Math" alttext="\tanh" display="inline"><semantics id="S3.SS2.p4.12.m12.1a"><mi id="S3.SS2.p4.12.m12.1.1" xref="S3.SS2.p4.12.m12.1.1.cmml">tanh</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.12.m12.1b"><tanh id="S3.SS2.p4.12.m12.1.1.cmml" xref="S3.SS2.p4.12.m12.1.1"></tanh></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.12.m12.1c">\tanh</annotation></semantics></math> nonlinearity during fusion. The output of the multi-modal fusion <math id="S3.SS2.p4.13.m13.1" class="ltx_Math" alttext="\tau\in\mathbb{R}^{t_{\rho}}" display="inline"><semantics id="S3.SS2.p4.13.m13.1a"><mrow id="S3.SS2.p4.13.m13.1.1" xref="S3.SS2.p4.13.m13.1.1.cmml"><mi id="S3.SS2.p4.13.m13.1.1.2" xref="S3.SS2.p4.13.m13.1.1.2.cmml">Ï„</mi><mo id="S3.SS2.p4.13.m13.1.1.1" xref="S3.SS2.p4.13.m13.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS2.p4.13.m13.1.1.3" xref="S3.SS2.p4.13.m13.1.1.3.cmml"><mi id="S3.SS2.p4.13.m13.1.1.3.2" xref="S3.SS2.p4.13.m13.1.1.3.2.cmml">â„</mi><msub id="S3.SS2.p4.13.m13.1.1.3.3" xref="S3.SS2.p4.13.m13.1.1.3.3.cmml"><mi id="S3.SS2.p4.13.m13.1.1.3.3.2" xref="S3.SS2.p4.13.m13.1.1.3.3.2.cmml">t</mi><mi id="S3.SS2.p4.13.m13.1.1.3.3.3" xref="S3.SS2.p4.13.m13.1.1.3.3.3.cmml">Ï</mi></msub></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.13.m13.1b"><apply id="S3.SS2.p4.13.m13.1.1.cmml" xref="S3.SS2.p4.13.m13.1.1"><in id="S3.SS2.p4.13.m13.1.1.1.cmml" xref="S3.SS2.p4.13.m13.1.1.1"></in><ci id="S3.SS2.p4.13.m13.1.1.2.cmml" xref="S3.SS2.p4.13.m13.1.1.2">ğœ</ci><apply id="S3.SS2.p4.13.m13.1.1.3.cmml" xref="S3.SS2.p4.13.m13.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p4.13.m13.1.1.3.1.cmml" xref="S3.SS2.p4.13.m13.1.1.3">superscript</csymbol><ci id="S3.SS2.p4.13.m13.1.1.3.2.cmml" xref="S3.SS2.p4.13.m13.1.1.3.2">â„</ci><apply id="S3.SS2.p4.13.m13.1.1.3.3.cmml" xref="S3.SS2.p4.13.m13.1.1.3.3"><csymbol cd="ambiguous" id="S3.SS2.p4.13.m13.1.1.3.3.1.cmml" xref="S3.SS2.p4.13.m13.1.1.3.3">subscript</csymbol><ci id="S3.SS2.p4.13.m13.1.1.3.3.2.cmml" xref="S3.SS2.p4.13.m13.1.1.3.3.2">ğ‘¡</ci><ci id="S3.SS2.p4.13.m13.1.1.3.3.3.cmml" xref="S3.SS2.p4.13.m13.1.1.3.3.3">ğœŒ</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.13.m13.1c">\tau\in\mathbb{R}^{t_{\rho}}</annotation></semantics></math> passes through convolution and softmax layers to create <math id="S3.SS2.p4.14.m14.1" class="ltx_Math" alttext="1\times G" display="inline"><semantics id="S3.SS2.p4.14.m14.1a"><mrow id="S3.SS2.p4.14.m14.1.1" xref="S3.SS2.p4.14.m14.1.1.cmml"><mn id="S3.SS2.p4.14.m14.1.1.2" xref="S3.SS2.p4.14.m14.1.1.2.cmml">1</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p4.14.m14.1.1.1" xref="S3.SS2.p4.14.m14.1.1.1.cmml">Ã—</mo><mi id="S3.SS2.p4.14.m14.1.1.3" xref="S3.SS2.p4.14.m14.1.1.3.cmml">G</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.14.m14.1b"><apply id="S3.SS2.p4.14.m14.1.1.cmml" xref="S3.SS2.p4.14.m14.1.1"><times id="S3.SS2.p4.14.m14.1.1.1.cmml" xref="S3.SS2.p4.14.m14.1.1.1"></times><cn type="integer" id="S3.SS2.p4.14.m14.1.1.2.cmml" xref="S3.SS2.p4.14.m14.1.1.2">1</cn><ci id="S3.SS2.p4.14.m14.1.1.3.cmml" xref="S3.SS2.p4.14.m14.1.1.3">ğº</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.14.m14.1c">1\times G</annotation></semantics></math> and <math id="S3.SS2.p4.15.m15.1" class="ltx_Math" alttext="1\times N" display="inline"><semantics id="S3.SS2.p4.15.m15.1a"><mrow id="S3.SS2.p4.15.m15.1.1" xref="S3.SS2.p4.15.m15.1.1.cmml"><mn id="S3.SS2.p4.15.m15.1.1.2" xref="S3.SS2.p4.15.m15.1.1.2.cmml">1</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p4.15.m15.1.1.1" xref="S3.SS2.p4.15.m15.1.1.1.cmml">Ã—</mo><mi id="S3.SS2.p4.15.m15.1.1.3" xref="S3.SS2.p4.15.m15.1.1.3.cmml">N</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.15.m15.1b"><apply id="S3.SS2.p4.15.m15.1.1.cmml" xref="S3.SS2.p4.15.m15.1.1"><times id="S3.SS2.p4.15.m15.1.1.1.cmml" xref="S3.SS2.p4.15.m15.1.1.1"></times><cn type="integer" id="S3.SS2.p4.15.m15.1.1.2.cmml" xref="S3.SS2.p4.15.m15.1.1.2">1</cn><ci id="S3.SS2.p4.15.m15.1.1.3.cmml" xref="S3.SS2.p4.15.m15.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.15.m15.1c">1\times N</annotation></semantics></math> dimensional representation for image-question and object-question embedding respectively. Thus, by employing hierarchical attention fusion, we embed question with spatial visual features to generate image-question <math id="S3.SS2.p4.16.m16.2" class="ltx_Math" alttext="\tau_{v_{I},q}\in\mathbb{R}^{1\times G}" display="inline"><semantics id="S3.SS2.p4.16.m16.2a"><mrow id="S3.SS2.p4.16.m16.2.3" xref="S3.SS2.p4.16.m16.2.3.cmml"><msub id="S3.SS2.p4.16.m16.2.3.2" xref="S3.SS2.p4.16.m16.2.3.2.cmml"><mi id="S3.SS2.p4.16.m16.2.3.2.2" xref="S3.SS2.p4.16.m16.2.3.2.2.cmml">Ï„</mi><mrow id="S3.SS2.p4.16.m16.2.2.2.2" xref="S3.SS2.p4.16.m16.2.2.2.3.cmml"><msub id="S3.SS2.p4.16.m16.2.2.2.2.1" xref="S3.SS2.p4.16.m16.2.2.2.2.1.cmml"><mi id="S3.SS2.p4.16.m16.2.2.2.2.1.2" xref="S3.SS2.p4.16.m16.2.2.2.2.1.2.cmml">v</mi><mi id="S3.SS2.p4.16.m16.2.2.2.2.1.3" xref="S3.SS2.p4.16.m16.2.2.2.2.1.3.cmml">I</mi></msub><mo id="S3.SS2.p4.16.m16.2.2.2.2.2" xref="S3.SS2.p4.16.m16.2.2.2.3.cmml">,</mo><mi id="S3.SS2.p4.16.m16.1.1.1.1" xref="S3.SS2.p4.16.m16.1.1.1.1.cmml">q</mi></mrow></msub><mo id="S3.SS2.p4.16.m16.2.3.1" xref="S3.SS2.p4.16.m16.2.3.1.cmml">âˆˆ</mo><msup id="S3.SS2.p4.16.m16.2.3.3" xref="S3.SS2.p4.16.m16.2.3.3.cmml"><mi id="S3.SS2.p4.16.m16.2.3.3.2" xref="S3.SS2.p4.16.m16.2.3.3.2.cmml">â„</mi><mrow id="S3.SS2.p4.16.m16.2.3.3.3" xref="S3.SS2.p4.16.m16.2.3.3.3.cmml"><mn id="S3.SS2.p4.16.m16.2.3.3.3.2" xref="S3.SS2.p4.16.m16.2.3.3.3.2.cmml">1</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p4.16.m16.2.3.3.3.1" xref="S3.SS2.p4.16.m16.2.3.3.3.1.cmml">Ã—</mo><mi id="S3.SS2.p4.16.m16.2.3.3.3.3" xref="S3.SS2.p4.16.m16.2.3.3.3.3.cmml">G</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.16.m16.2b"><apply id="S3.SS2.p4.16.m16.2.3.cmml" xref="S3.SS2.p4.16.m16.2.3"><in id="S3.SS2.p4.16.m16.2.3.1.cmml" xref="S3.SS2.p4.16.m16.2.3.1"></in><apply id="S3.SS2.p4.16.m16.2.3.2.cmml" xref="S3.SS2.p4.16.m16.2.3.2"><csymbol cd="ambiguous" id="S3.SS2.p4.16.m16.2.3.2.1.cmml" xref="S3.SS2.p4.16.m16.2.3.2">subscript</csymbol><ci id="S3.SS2.p4.16.m16.2.3.2.2.cmml" xref="S3.SS2.p4.16.m16.2.3.2.2">ğœ</ci><list id="S3.SS2.p4.16.m16.2.2.2.3.cmml" xref="S3.SS2.p4.16.m16.2.2.2.2"><apply id="S3.SS2.p4.16.m16.2.2.2.2.1.cmml" xref="S3.SS2.p4.16.m16.2.2.2.2.1"><csymbol cd="ambiguous" id="S3.SS2.p4.16.m16.2.2.2.2.1.1.cmml" xref="S3.SS2.p4.16.m16.2.2.2.2.1">subscript</csymbol><ci id="S3.SS2.p4.16.m16.2.2.2.2.1.2.cmml" xref="S3.SS2.p4.16.m16.2.2.2.2.1.2">ğ‘£</ci><ci id="S3.SS2.p4.16.m16.2.2.2.2.1.3.cmml" xref="S3.SS2.p4.16.m16.2.2.2.2.1.3">ğ¼</ci></apply><ci id="S3.SS2.p4.16.m16.1.1.1.1.cmml" xref="S3.SS2.p4.16.m16.1.1.1.1">ğ‘</ci></list></apply><apply id="S3.SS2.p4.16.m16.2.3.3.cmml" xref="S3.SS2.p4.16.m16.2.3.3"><csymbol cd="ambiguous" id="S3.SS2.p4.16.m16.2.3.3.1.cmml" xref="S3.SS2.p4.16.m16.2.3.3">superscript</csymbol><ci id="S3.SS2.p4.16.m16.2.3.3.2.cmml" xref="S3.SS2.p4.16.m16.2.3.3.2">â„</ci><apply id="S3.SS2.p4.16.m16.2.3.3.3.cmml" xref="S3.SS2.p4.16.m16.2.3.3.3"><times id="S3.SS2.p4.16.m16.2.3.3.3.1.cmml" xref="S3.SS2.p4.16.m16.2.3.3.3.1"></times><cn type="integer" id="S3.SS2.p4.16.m16.2.3.3.3.2.cmml" xref="S3.SS2.p4.16.m16.2.3.3.3.2">1</cn><ci id="S3.SS2.p4.16.m16.2.3.3.3.3.cmml" xref="S3.SS2.p4.16.m16.2.3.3.3.3">ğº</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.16.m16.2c">\tau_{v_{I},q}\in\mathbb{R}^{1\times G}</annotation></semantics></math> and object-question <math id="S3.SS2.p4.17.m17.2" class="ltx_Math" alttext="\tau_{v_{O},q}\in\mathbb{R}^{1\times N}" display="inline"><semantics id="S3.SS2.p4.17.m17.2a"><mrow id="S3.SS2.p4.17.m17.2.3" xref="S3.SS2.p4.17.m17.2.3.cmml"><msub id="S3.SS2.p4.17.m17.2.3.2" xref="S3.SS2.p4.17.m17.2.3.2.cmml"><mi id="S3.SS2.p4.17.m17.2.3.2.2" xref="S3.SS2.p4.17.m17.2.3.2.2.cmml">Ï„</mi><mrow id="S3.SS2.p4.17.m17.2.2.2.2" xref="S3.SS2.p4.17.m17.2.2.2.3.cmml"><msub id="S3.SS2.p4.17.m17.2.2.2.2.1" xref="S3.SS2.p4.17.m17.2.2.2.2.1.cmml"><mi id="S3.SS2.p4.17.m17.2.2.2.2.1.2" xref="S3.SS2.p4.17.m17.2.2.2.2.1.2.cmml">v</mi><mi id="S3.SS2.p4.17.m17.2.2.2.2.1.3" xref="S3.SS2.p4.17.m17.2.2.2.2.1.3.cmml">O</mi></msub><mo id="S3.SS2.p4.17.m17.2.2.2.2.2" xref="S3.SS2.p4.17.m17.2.2.2.3.cmml">,</mo><mi id="S3.SS2.p4.17.m17.1.1.1.1" xref="S3.SS2.p4.17.m17.1.1.1.1.cmml">q</mi></mrow></msub><mo id="S3.SS2.p4.17.m17.2.3.1" xref="S3.SS2.p4.17.m17.2.3.1.cmml">âˆˆ</mo><msup id="S3.SS2.p4.17.m17.2.3.3" xref="S3.SS2.p4.17.m17.2.3.3.cmml"><mi id="S3.SS2.p4.17.m17.2.3.3.2" xref="S3.SS2.p4.17.m17.2.3.3.2.cmml">â„</mi><mrow id="S3.SS2.p4.17.m17.2.3.3.3" xref="S3.SS2.p4.17.m17.2.3.3.3.cmml"><mn id="S3.SS2.p4.17.m17.2.3.3.3.2" xref="S3.SS2.p4.17.m17.2.3.3.3.2.cmml">1</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p4.17.m17.2.3.3.3.1" xref="S3.SS2.p4.17.m17.2.3.3.3.1.cmml">Ã—</mo><mi id="S3.SS2.p4.17.m17.2.3.3.3.3" xref="S3.SS2.p4.17.m17.2.3.3.3.3.cmml">N</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.17.m17.2b"><apply id="S3.SS2.p4.17.m17.2.3.cmml" xref="S3.SS2.p4.17.m17.2.3"><in id="S3.SS2.p4.17.m17.2.3.1.cmml" xref="S3.SS2.p4.17.m17.2.3.1"></in><apply id="S3.SS2.p4.17.m17.2.3.2.cmml" xref="S3.SS2.p4.17.m17.2.3.2"><csymbol cd="ambiguous" id="S3.SS2.p4.17.m17.2.3.2.1.cmml" xref="S3.SS2.p4.17.m17.2.3.2">subscript</csymbol><ci id="S3.SS2.p4.17.m17.2.3.2.2.cmml" xref="S3.SS2.p4.17.m17.2.3.2.2">ğœ</ci><list id="S3.SS2.p4.17.m17.2.2.2.3.cmml" xref="S3.SS2.p4.17.m17.2.2.2.2"><apply id="S3.SS2.p4.17.m17.2.2.2.2.1.cmml" xref="S3.SS2.p4.17.m17.2.2.2.2.1"><csymbol cd="ambiguous" id="S3.SS2.p4.17.m17.2.2.2.2.1.1.cmml" xref="S3.SS2.p4.17.m17.2.2.2.2.1">subscript</csymbol><ci id="S3.SS2.p4.17.m17.2.2.2.2.1.2.cmml" xref="S3.SS2.p4.17.m17.2.2.2.2.1.2">ğ‘£</ci><ci id="S3.SS2.p4.17.m17.2.2.2.2.1.3.cmml" xref="S3.SS2.p4.17.m17.2.2.2.2.1.3">ğ‘‚</ci></apply><ci id="S3.SS2.p4.17.m17.1.1.1.1.cmml" xref="S3.SS2.p4.17.m17.1.1.1.1">ğ‘</ci></list></apply><apply id="S3.SS2.p4.17.m17.2.3.3.cmml" xref="S3.SS2.p4.17.m17.2.3.3"><csymbol cd="ambiguous" id="S3.SS2.p4.17.m17.2.3.3.1.cmml" xref="S3.SS2.p4.17.m17.2.3.3">superscript</csymbol><ci id="S3.SS2.p4.17.m17.2.3.3.2.cmml" xref="S3.SS2.p4.17.m17.2.3.3.2">â„</ci><apply id="S3.SS2.p4.17.m17.2.3.3.3.cmml" xref="S3.SS2.p4.17.m17.2.3.3.3"><times id="S3.SS2.p4.17.m17.2.3.3.3.1.cmml" xref="S3.SS2.p4.17.m17.2.3.3.3.1"></times><cn type="integer" id="S3.SS2.p4.17.m17.2.3.3.3.2.cmml" xref="S3.SS2.p4.17.m17.2.3.3.3.2">1</cn><ci id="S3.SS2.p4.17.m17.2.3.3.3.3.cmml" xref="S3.SS2.p4.17.m17.2.3.3.3.3">ğ‘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.17.m17.2c">\tau_{v_{O},q}\in\mathbb{R}^{1\times N}</annotation></semantics></math> embedding.</p>
</div>
<div id="S3.SS2.p5" class="ltx_para">
<p id="S3.SS2.p5.6" class="ltx_p"><span id="S3.SS2.p5.6.1" class="ltx_text ltx_font_bold">Top-down (TD) Attention</span> The image level and object level features are used alongside image-question and object-question embeddings to generate an attention distribution over spatial grid and object proposals respectively. We take weighted sum (WS) of the spatial visual features (i.e.Â <math id="S3.SS2.p5.1.m1.1" class="ltx_Math" alttext="v_{I}" display="inline"><semantics id="S3.SS2.p5.1.m1.1a"><msub id="S3.SS2.p5.1.m1.1.1" xref="S3.SS2.p5.1.m1.1.1.cmml"><mi id="S3.SS2.p5.1.m1.1.1.2" xref="S3.SS2.p5.1.m1.1.1.2.cmml">v</mi><mi id="S3.SS2.p5.1.m1.1.1.3" xref="S3.SS2.p5.1.m1.1.1.3.cmml">I</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.1.m1.1b"><apply id="S3.SS2.p5.1.m1.1.1.cmml" xref="S3.SS2.p5.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p5.1.m1.1.1.1.cmml" xref="S3.SS2.p5.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.p5.1.m1.1.1.2.cmml" xref="S3.SS2.p5.1.m1.1.1.2">ğ‘£</ci><ci id="S3.SS2.p5.1.m1.1.1.3.cmml" xref="S3.SS2.p5.1.m1.1.1.3">ğ¼</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.1.m1.1c">v_{I}</annotation></semantics></math> and <math id="S3.SS2.p5.2.m2.1" class="ltx_Math" alttext="v_{O}" display="inline"><semantics id="S3.SS2.p5.2.m2.1a"><msub id="S3.SS2.p5.2.m2.1.1" xref="S3.SS2.p5.2.m2.1.1.cmml"><mi id="S3.SS2.p5.2.m2.1.1.2" xref="S3.SS2.p5.2.m2.1.1.2.cmml">v</mi><mi id="S3.SS2.p5.2.m2.1.1.3" xref="S3.SS2.p5.2.m2.1.1.3.cmml">O</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.2.m2.1b"><apply id="S3.SS2.p5.2.m2.1.1.cmml" xref="S3.SS2.p5.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p5.2.m2.1.1.1.cmml" xref="S3.SS2.p5.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.p5.2.m2.1.1.2.cmml" xref="S3.SS2.p5.2.m2.1.1.2">ğ‘£</ci><ci id="S3.SS2.p5.2.m2.1.1.3.cmml" xref="S3.SS2.p5.2.m2.1.1.3">ğ‘‚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.2.m2.1c">v_{O}</annotation></semantics></math>) vectors using the attention weights (i.e.Â <math id="S3.SS2.p5.3.m3.2" class="ltx_Math" alttext="\tau_{v_{I},q}" display="inline"><semantics id="S3.SS2.p5.3.m3.2a"><msub id="S3.SS2.p5.3.m3.2.3" xref="S3.SS2.p5.3.m3.2.3.cmml"><mi id="S3.SS2.p5.3.m3.2.3.2" xref="S3.SS2.p5.3.m3.2.3.2.cmml">Ï„</mi><mrow id="S3.SS2.p5.3.m3.2.2.2.2" xref="S3.SS2.p5.3.m3.2.2.2.3.cmml"><msub id="S3.SS2.p5.3.m3.2.2.2.2.1" xref="S3.SS2.p5.3.m3.2.2.2.2.1.cmml"><mi id="S3.SS2.p5.3.m3.2.2.2.2.1.2" xref="S3.SS2.p5.3.m3.2.2.2.2.1.2.cmml">v</mi><mi id="S3.SS2.p5.3.m3.2.2.2.2.1.3" xref="S3.SS2.p5.3.m3.2.2.2.2.1.3.cmml">I</mi></msub><mo id="S3.SS2.p5.3.m3.2.2.2.2.2" xref="S3.SS2.p5.3.m3.2.2.2.3.cmml">,</mo><mi id="S3.SS2.p5.3.m3.1.1.1.1" xref="S3.SS2.p5.3.m3.1.1.1.1.cmml">q</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.3.m3.2b"><apply id="S3.SS2.p5.3.m3.2.3.cmml" xref="S3.SS2.p5.3.m3.2.3"><csymbol cd="ambiguous" id="S3.SS2.p5.3.m3.2.3.1.cmml" xref="S3.SS2.p5.3.m3.2.3">subscript</csymbol><ci id="S3.SS2.p5.3.m3.2.3.2.cmml" xref="S3.SS2.p5.3.m3.2.3.2">ğœ</ci><list id="S3.SS2.p5.3.m3.2.2.2.3.cmml" xref="S3.SS2.p5.3.m3.2.2.2.2"><apply id="S3.SS2.p5.3.m3.2.2.2.2.1.cmml" xref="S3.SS2.p5.3.m3.2.2.2.2.1"><csymbol cd="ambiguous" id="S3.SS2.p5.3.m3.2.2.2.2.1.1.cmml" xref="S3.SS2.p5.3.m3.2.2.2.2.1">subscript</csymbol><ci id="S3.SS2.p5.3.m3.2.2.2.2.1.2.cmml" xref="S3.SS2.p5.3.m3.2.2.2.2.1.2">ğ‘£</ci><ci id="S3.SS2.p5.3.m3.2.2.2.2.1.3.cmml" xref="S3.SS2.p5.3.m3.2.2.2.2.1.3">ğ¼</ci></apply><ci id="S3.SS2.p5.3.m3.1.1.1.1.cmml" xref="S3.SS2.p5.3.m3.1.1.1.1">ğ‘</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.3.m3.2c">\tau_{v_{I},q}</annotation></semantics></math> and <math id="S3.SS2.p5.4.m4.2" class="ltx_Math" alttext="\tau_{v_{O},q}" display="inline"><semantics id="S3.SS2.p5.4.m4.2a"><msub id="S3.SS2.p5.4.m4.2.3" xref="S3.SS2.p5.4.m4.2.3.cmml"><mi id="S3.SS2.p5.4.m4.2.3.2" xref="S3.SS2.p5.4.m4.2.3.2.cmml">Ï„</mi><mrow id="S3.SS2.p5.4.m4.2.2.2.2" xref="S3.SS2.p5.4.m4.2.2.2.3.cmml"><msub id="S3.SS2.p5.4.m4.2.2.2.2.1" xref="S3.SS2.p5.4.m4.2.2.2.2.1.cmml"><mi id="S3.SS2.p5.4.m4.2.2.2.2.1.2" xref="S3.SS2.p5.4.m4.2.2.2.2.1.2.cmml">v</mi><mi id="S3.SS2.p5.4.m4.2.2.2.2.1.3" xref="S3.SS2.p5.4.m4.2.2.2.2.1.3.cmml">O</mi></msub><mo id="S3.SS2.p5.4.m4.2.2.2.2.2" xref="S3.SS2.p5.4.m4.2.2.2.3.cmml">,</mo><mi id="S3.SS2.p5.4.m4.1.1.1.1" xref="S3.SS2.p5.4.m4.1.1.1.1.cmml">q</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.4.m4.2b"><apply id="S3.SS2.p5.4.m4.2.3.cmml" xref="S3.SS2.p5.4.m4.2.3"><csymbol cd="ambiguous" id="S3.SS2.p5.4.m4.2.3.1.cmml" xref="S3.SS2.p5.4.m4.2.3">subscript</csymbol><ci id="S3.SS2.p5.4.m4.2.3.2.cmml" xref="S3.SS2.p5.4.m4.2.3.2">ğœ</ci><list id="S3.SS2.p5.4.m4.2.2.2.3.cmml" xref="S3.SS2.p5.4.m4.2.2.2.2"><apply id="S3.SS2.p5.4.m4.2.2.2.2.1.cmml" xref="S3.SS2.p5.4.m4.2.2.2.2.1"><csymbol cd="ambiguous" id="S3.SS2.p5.4.m4.2.2.2.2.1.1.cmml" xref="S3.SS2.p5.4.m4.2.2.2.2.1">subscript</csymbol><ci id="S3.SS2.p5.4.m4.2.2.2.2.1.2.cmml" xref="S3.SS2.p5.4.m4.2.2.2.2.1.2">ğ‘£</ci><ci id="S3.SS2.p5.4.m4.2.2.2.2.1.3.cmml" xref="S3.SS2.p5.4.m4.2.2.2.2.1.3">ğ‘‚</ci></apply><ci id="S3.SS2.p5.4.m4.1.1.1.1.cmml" xref="S3.SS2.p5.4.m4.1.1.1.1">ğ‘</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.4.m4.2c">\tau_{v_{O},q}</annotation></semantics></math>) to generate <math id="S3.SS2.p5.5.m5.1" class="ltx_Math" alttext="\varphi_{I}" display="inline"><semantics id="S3.SS2.p5.5.m5.1a"><msub id="S3.SS2.p5.5.m5.1.1" xref="S3.SS2.p5.5.m5.1.1.cmml"><mi id="S3.SS2.p5.5.m5.1.1.2" xref="S3.SS2.p5.5.m5.1.1.2.cmml">Ï†</mi><mi id="S3.SS2.p5.5.m5.1.1.3" xref="S3.SS2.p5.5.m5.1.1.3.cmml">I</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.5.m5.1b"><apply id="S3.SS2.p5.5.m5.1.1.cmml" xref="S3.SS2.p5.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.p5.5.m5.1.1.1.cmml" xref="S3.SS2.p5.5.m5.1.1">subscript</csymbol><ci id="S3.SS2.p5.5.m5.1.1.2.cmml" xref="S3.SS2.p5.5.m5.1.1.2">ğœ‘</ci><ci id="S3.SS2.p5.5.m5.1.1.3.cmml" xref="S3.SS2.p5.5.m5.1.1.3">ğ¼</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.5.m5.1c">\varphi_{I}</annotation></semantics></math> and <math id="S3.SS2.p5.6.m6.1" class="ltx_Math" alttext="\varphi_{O}" display="inline"><semantics id="S3.SS2.p5.6.m6.1a"><msub id="S3.SS2.p5.6.m6.1.1" xref="S3.SS2.p5.6.m6.1.1.cmml"><mi id="S3.SS2.p5.6.m6.1.1.2" xref="S3.SS2.p5.6.m6.1.1.2.cmml">Ï†</mi><mi id="S3.SS2.p5.6.m6.1.1.3" xref="S3.SS2.p5.6.m6.1.1.3.cmml">O</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.6.m6.1b"><apply id="S3.SS2.p5.6.m6.1.1.cmml" xref="S3.SS2.p5.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS2.p5.6.m6.1.1.1.cmml" xref="S3.SS2.p5.6.m6.1.1">subscript</csymbol><ci id="S3.SS2.p5.6.m6.1.1.2.cmml" xref="S3.SS2.p5.6.m6.1.1.2">ğœ‘</ci><ci id="S3.SS2.p5.6.m6.1.1.3.cmml" xref="S3.SS2.p5.6.m6.1.1.3">ğ‘‚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.6.m6.1c">\varphi_{O}</annotation></semantics></math> which are top-down attended visual features,</p>
<table id="S3.E6" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E6.m1.6" class="ltx_Math" alttext="\varphi_{I}=\sum_{i}^{G}\tau_{v_{I},q}^{i}\ v_{I}^{i}\quad\textrm{and}\quad\varphi_{O}=\sum_{i}^{N}\tau_{v_{O},q}^{i}\ v_{O}^{i}." display="block"><semantics id="S3.E6.m1.6a"><mrow id="S3.E6.m1.6.6.1"><mrow id="S3.E6.m1.6.6.1.1.2" xref="S3.E6.m1.6.6.1.1.3.cmml"><mrow id="S3.E6.m1.6.6.1.1.1.1" xref="S3.E6.m1.6.6.1.1.1.1.cmml"><msub id="S3.E6.m1.6.6.1.1.1.1.3" xref="S3.E6.m1.6.6.1.1.1.1.3.cmml"><mi id="S3.E6.m1.6.6.1.1.1.1.3.2" xref="S3.E6.m1.6.6.1.1.1.1.3.2.cmml">Ï†</mi><mi id="S3.E6.m1.6.6.1.1.1.1.3.3" xref="S3.E6.m1.6.6.1.1.1.1.3.3.cmml">I</mi></msub><mo rspace="0.111em" id="S3.E6.m1.6.6.1.1.1.1.2" xref="S3.E6.m1.6.6.1.1.1.1.2.cmml">=</mo><mrow id="S3.E6.m1.6.6.1.1.1.1.1.1" xref="S3.E6.m1.6.6.1.1.1.1.1.2.cmml"><mrow id="S3.E6.m1.6.6.1.1.1.1.1.1.1" xref="S3.E6.m1.6.6.1.1.1.1.1.1.1.cmml"><munderover id="S3.E6.m1.6.6.1.1.1.1.1.1.1.1" xref="S3.E6.m1.6.6.1.1.1.1.1.1.1.1.cmml"><mo movablelimits="false" id="S3.E6.m1.6.6.1.1.1.1.1.1.1.1.2.2" xref="S3.E6.m1.6.6.1.1.1.1.1.1.1.1.2.2.cmml">âˆ‘</mo><mi id="S3.E6.m1.6.6.1.1.1.1.1.1.1.1.2.3" xref="S3.E6.m1.6.6.1.1.1.1.1.1.1.1.2.3.cmml">i</mi><mi id="S3.E6.m1.6.6.1.1.1.1.1.1.1.1.3" xref="S3.E6.m1.6.6.1.1.1.1.1.1.1.1.3.cmml">G</mi></munderover><mrow id="S3.E6.m1.6.6.1.1.1.1.1.1.1.2" xref="S3.E6.m1.6.6.1.1.1.1.1.1.1.2.cmml"><msubsup id="S3.E6.m1.6.6.1.1.1.1.1.1.1.2.2" xref="S3.E6.m1.6.6.1.1.1.1.1.1.1.2.2.cmml"><mi id="S3.E6.m1.6.6.1.1.1.1.1.1.1.2.2.2.2" xref="S3.E6.m1.6.6.1.1.1.1.1.1.1.2.2.2.2.cmml">Ï„</mi><mrow id="S3.E6.m1.2.2.2.2" xref="S3.E6.m1.2.2.2.3.cmml"><msub id="S3.E6.m1.2.2.2.2.1" xref="S3.E6.m1.2.2.2.2.1.cmml"><mi id="S3.E6.m1.2.2.2.2.1.2" xref="S3.E6.m1.2.2.2.2.1.2.cmml">v</mi><mi id="S3.E6.m1.2.2.2.2.1.3" xref="S3.E6.m1.2.2.2.2.1.3.cmml">I</mi></msub><mo id="S3.E6.m1.2.2.2.2.2" xref="S3.E6.m1.2.2.2.3.cmml">,</mo><mi id="S3.E6.m1.1.1.1.1" xref="S3.E6.m1.1.1.1.1.cmml">q</mi></mrow><mi id="S3.E6.m1.6.6.1.1.1.1.1.1.1.2.2.3" xref="S3.E6.m1.6.6.1.1.1.1.1.1.1.2.2.3.cmml">i</mi></msubsup><mo lspace="0em" rspace="0em" id="S3.E6.m1.6.6.1.1.1.1.1.1.1.2.1" xref="S3.E6.m1.6.6.1.1.1.1.1.1.1.2.1.cmml">â€‹</mo><msubsup id="S3.E6.m1.6.6.1.1.1.1.1.1.1.2.3" xref="S3.E6.m1.6.6.1.1.1.1.1.1.1.2.3.cmml"><mi id="S3.E6.m1.6.6.1.1.1.1.1.1.1.2.3.2.2" xref="S3.E6.m1.6.6.1.1.1.1.1.1.1.2.3.2.2.cmml">v</mi><mi id="S3.E6.m1.6.6.1.1.1.1.1.1.1.2.3.2.3" xref="S3.E6.m1.6.6.1.1.1.1.1.1.1.2.3.2.3.cmml">I</mi><mi id="S3.E6.m1.6.6.1.1.1.1.1.1.1.2.3.3" xref="S3.E6.m1.6.6.1.1.1.1.1.1.1.2.3.3.cmml">i</mi></msubsup></mrow></mrow><mspace width="1em" id="S3.E6.m1.6.6.1.1.1.1.1.1.2" xref="S3.E6.m1.6.6.1.1.1.1.1.2.cmml"></mspace><mtext id="S3.E6.m1.5.5" xref="S3.E6.m1.5.5a.cmml">and</mtext></mrow></mrow><mspace width="1em" id="S3.E6.m1.6.6.1.1.2.3" xref="S3.E6.m1.6.6.1.1.3a.cmml"></mspace><mrow id="S3.E6.m1.6.6.1.1.2.2" xref="S3.E6.m1.6.6.1.1.2.2.cmml"><msub id="S3.E6.m1.6.6.1.1.2.2.2" xref="S3.E6.m1.6.6.1.1.2.2.2.cmml"><mi id="S3.E6.m1.6.6.1.1.2.2.2.2" xref="S3.E6.m1.6.6.1.1.2.2.2.2.cmml">Ï†</mi><mi id="S3.E6.m1.6.6.1.1.2.2.2.3" xref="S3.E6.m1.6.6.1.1.2.2.2.3.cmml">O</mi></msub><mo rspace="0.111em" id="S3.E6.m1.6.6.1.1.2.2.1" xref="S3.E6.m1.6.6.1.1.2.2.1.cmml">=</mo><mrow id="S3.E6.m1.6.6.1.1.2.2.3" xref="S3.E6.m1.6.6.1.1.2.2.3.cmml"><munderover id="S3.E6.m1.6.6.1.1.2.2.3.1" xref="S3.E6.m1.6.6.1.1.2.2.3.1.cmml"><mo movablelimits="false" id="S3.E6.m1.6.6.1.1.2.2.3.1.2.2" xref="S3.E6.m1.6.6.1.1.2.2.3.1.2.2.cmml">âˆ‘</mo><mi id="S3.E6.m1.6.6.1.1.2.2.3.1.2.3" xref="S3.E6.m1.6.6.1.1.2.2.3.1.2.3.cmml">i</mi><mi id="S3.E6.m1.6.6.1.1.2.2.3.1.3" xref="S3.E6.m1.6.6.1.1.2.2.3.1.3.cmml">N</mi></munderover><mrow id="S3.E6.m1.6.6.1.1.2.2.3.2" xref="S3.E6.m1.6.6.1.1.2.2.3.2.cmml"><msubsup id="S3.E6.m1.6.6.1.1.2.2.3.2.2" xref="S3.E6.m1.6.6.1.1.2.2.3.2.2.cmml"><mi id="S3.E6.m1.6.6.1.1.2.2.3.2.2.2.2" xref="S3.E6.m1.6.6.1.1.2.2.3.2.2.2.2.cmml">Ï„</mi><mrow id="S3.E6.m1.4.4.2.2" xref="S3.E6.m1.4.4.2.3.cmml"><msub id="S3.E6.m1.4.4.2.2.1" xref="S3.E6.m1.4.4.2.2.1.cmml"><mi id="S3.E6.m1.4.4.2.2.1.2" xref="S3.E6.m1.4.4.2.2.1.2.cmml">v</mi><mi id="S3.E6.m1.4.4.2.2.1.3" xref="S3.E6.m1.4.4.2.2.1.3.cmml">O</mi></msub><mo id="S3.E6.m1.4.4.2.2.2" xref="S3.E6.m1.4.4.2.3.cmml">,</mo><mi id="S3.E6.m1.3.3.1.1" xref="S3.E6.m1.3.3.1.1.cmml">q</mi></mrow><mi id="S3.E6.m1.6.6.1.1.2.2.3.2.2.3" xref="S3.E6.m1.6.6.1.1.2.2.3.2.2.3.cmml">i</mi></msubsup><mo lspace="0em" rspace="0em" id="S3.E6.m1.6.6.1.1.2.2.3.2.1" xref="S3.E6.m1.6.6.1.1.2.2.3.2.1.cmml">â€‹</mo><msubsup id="S3.E6.m1.6.6.1.1.2.2.3.2.3" xref="S3.E6.m1.6.6.1.1.2.2.3.2.3.cmml"><mi id="S3.E6.m1.6.6.1.1.2.2.3.2.3.2.2" xref="S3.E6.m1.6.6.1.1.2.2.3.2.3.2.2.cmml">v</mi><mi id="S3.E6.m1.6.6.1.1.2.2.3.2.3.2.3" xref="S3.E6.m1.6.6.1.1.2.2.3.2.3.2.3.cmml">O</mi><mi id="S3.E6.m1.6.6.1.1.2.2.3.2.3.3" xref="S3.E6.m1.6.6.1.1.2.2.3.2.3.3.cmml">i</mi></msubsup></mrow></mrow></mrow></mrow><mo lspace="0em" id="S3.E6.m1.6.6.1.2">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E6.m1.6b"><apply id="S3.E6.m1.6.6.1.1.3.cmml" xref="S3.E6.m1.6.6.1.1.2"><csymbol cd="ambiguous" id="S3.E6.m1.6.6.1.1.3a.cmml" xref="S3.E6.m1.6.6.1.1.2.3">formulae-sequence</csymbol><apply id="S3.E6.m1.6.6.1.1.1.1.cmml" xref="S3.E6.m1.6.6.1.1.1.1"><eq id="S3.E6.m1.6.6.1.1.1.1.2.cmml" xref="S3.E6.m1.6.6.1.1.1.1.2"></eq><apply id="S3.E6.m1.6.6.1.1.1.1.3.cmml" xref="S3.E6.m1.6.6.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E6.m1.6.6.1.1.1.1.3.1.cmml" xref="S3.E6.m1.6.6.1.1.1.1.3">subscript</csymbol><ci id="S3.E6.m1.6.6.1.1.1.1.3.2.cmml" xref="S3.E6.m1.6.6.1.1.1.1.3.2">ğœ‘</ci><ci id="S3.E6.m1.6.6.1.1.1.1.3.3.cmml" xref="S3.E6.m1.6.6.1.1.1.1.3.3">ğ¼</ci></apply><list id="S3.E6.m1.6.6.1.1.1.1.1.2.cmml" xref="S3.E6.m1.6.6.1.1.1.1.1.1"><apply id="S3.E6.m1.6.6.1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.6.6.1.1.1.1.1.1.1"><apply id="S3.E6.m1.6.6.1.1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.6.6.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E6.m1.6.6.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.6.6.1.1.1.1.1.1.1.1">superscript</csymbol><apply id="S3.E6.m1.6.6.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E6.m1.6.6.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E6.m1.6.6.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E6.m1.6.6.1.1.1.1.1.1.1.1">subscript</csymbol><sum id="S3.E6.m1.6.6.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E6.m1.6.6.1.1.1.1.1.1.1.1.2.2"></sum><ci id="S3.E6.m1.6.6.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E6.m1.6.6.1.1.1.1.1.1.1.1.2.3">ğ‘–</ci></apply><ci id="S3.E6.m1.6.6.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E6.m1.6.6.1.1.1.1.1.1.1.1.3">ğº</ci></apply><apply id="S3.E6.m1.6.6.1.1.1.1.1.1.1.2.cmml" xref="S3.E6.m1.6.6.1.1.1.1.1.1.1.2"><times id="S3.E6.m1.6.6.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E6.m1.6.6.1.1.1.1.1.1.1.2.1"></times><apply id="S3.E6.m1.6.6.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E6.m1.6.6.1.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.E6.m1.6.6.1.1.1.1.1.1.1.2.2.1.cmml" xref="S3.E6.m1.6.6.1.1.1.1.1.1.1.2.2">superscript</csymbol><apply id="S3.E6.m1.6.6.1.1.1.1.1.1.1.2.2.2.cmml" xref="S3.E6.m1.6.6.1.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.E6.m1.6.6.1.1.1.1.1.1.1.2.2.2.1.cmml" xref="S3.E6.m1.6.6.1.1.1.1.1.1.1.2.2">subscript</csymbol><ci id="S3.E6.m1.6.6.1.1.1.1.1.1.1.2.2.2.2.cmml" xref="S3.E6.m1.6.6.1.1.1.1.1.1.1.2.2.2.2">ğœ</ci><list id="S3.E6.m1.2.2.2.3.cmml" xref="S3.E6.m1.2.2.2.2"><apply id="S3.E6.m1.2.2.2.2.1.cmml" xref="S3.E6.m1.2.2.2.2.1"><csymbol cd="ambiguous" id="S3.E6.m1.2.2.2.2.1.1.cmml" xref="S3.E6.m1.2.2.2.2.1">subscript</csymbol><ci id="S3.E6.m1.2.2.2.2.1.2.cmml" xref="S3.E6.m1.2.2.2.2.1.2">ğ‘£</ci><ci id="S3.E6.m1.2.2.2.2.1.3.cmml" xref="S3.E6.m1.2.2.2.2.1.3">ğ¼</ci></apply><ci id="S3.E6.m1.1.1.1.1.cmml" xref="S3.E6.m1.1.1.1.1">ğ‘</ci></list></apply><ci id="S3.E6.m1.6.6.1.1.1.1.1.1.1.2.2.3.cmml" xref="S3.E6.m1.6.6.1.1.1.1.1.1.1.2.2.3">ğ‘–</ci></apply><apply id="S3.E6.m1.6.6.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E6.m1.6.6.1.1.1.1.1.1.1.2.3"><csymbol cd="ambiguous" id="S3.E6.m1.6.6.1.1.1.1.1.1.1.2.3.1.cmml" xref="S3.E6.m1.6.6.1.1.1.1.1.1.1.2.3">superscript</csymbol><apply id="S3.E6.m1.6.6.1.1.1.1.1.1.1.2.3.2.cmml" xref="S3.E6.m1.6.6.1.1.1.1.1.1.1.2.3"><csymbol cd="ambiguous" id="S3.E6.m1.6.6.1.1.1.1.1.1.1.2.3.2.1.cmml" xref="S3.E6.m1.6.6.1.1.1.1.1.1.1.2.3">subscript</csymbol><ci id="S3.E6.m1.6.6.1.1.1.1.1.1.1.2.3.2.2.cmml" xref="S3.E6.m1.6.6.1.1.1.1.1.1.1.2.3.2.2">ğ‘£</ci><ci id="S3.E6.m1.6.6.1.1.1.1.1.1.1.2.3.2.3.cmml" xref="S3.E6.m1.6.6.1.1.1.1.1.1.1.2.3.2.3">ğ¼</ci></apply><ci id="S3.E6.m1.6.6.1.1.1.1.1.1.1.2.3.3.cmml" xref="S3.E6.m1.6.6.1.1.1.1.1.1.1.2.3.3">ğ‘–</ci></apply></apply></apply><ci id="S3.E6.m1.5.5a.cmml" xref="S3.E6.m1.5.5"><mtext id="S3.E6.m1.5.5.cmml" xref="S3.E6.m1.5.5">and</mtext></ci></list></apply><apply id="S3.E6.m1.6.6.1.1.2.2.cmml" xref="S3.E6.m1.6.6.1.1.2.2"><eq id="S3.E6.m1.6.6.1.1.2.2.1.cmml" xref="S3.E6.m1.6.6.1.1.2.2.1"></eq><apply id="S3.E6.m1.6.6.1.1.2.2.2.cmml" xref="S3.E6.m1.6.6.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.E6.m1.6.6.1.1.2.2.2.1.cmml" xref="S3.E6.m1.6.6.1.1.2.2.2">subscript</csymbol><ci id="S3.E6.m1.6.6.1.1.2.2.2.2.cmml" xref="S3.E6.m1.6.6.1.1.2.2.2.2">ğœ‘</ci><ci id="S3.E6.m1.6.6.1.1.2.2.2.3.cmml" xref="S3.E6.m1.6.6.1.1.2.2.2.3">ğ‘‚</ci></apply><apply id="S3.E6.m1.6.6.1.1.2.2.3.cmml" xref="S3.E6.m1.6.6.1.1.2.2.3"><apply id="S3.E6.m1.6.6.1.1.2.2.3.1.cmml" xref="S3.E6.m1.6.6.1.1.2.2.3.1"><csymbol cd="ambiguous" id="S3.E6.m1.6.6.1.1.2.2.3.1.1.cmml" xref="S3.E6.m1.6.6.1.1.2.2.3.1">superscript</csymbol><apply id="S3.E6.m1.6.6.1.1.2.2.3.1.2.cmml" xref="S3.E6.m1.6.6.1.1.2.2.3.1"><csymbol cd="ambiguous" id="S3.E6.m1.6.6.1.1.2.2.3.1.2.1.cmml" xref="S3.E6.m1.6.6.1.1.2.2.3.1">subscript</csymbol><sum id="S3.E6.m1.6.6.1.1.2.2.3.1.2.2.cmml" xref="S3.E6.m1.6.6.1.1.2.2.3.1.2.2"></sum><ci id="S3.E6.m1.6.6.1.1.2.2.3.1.2.3.cmml" xref="S3.E6.m1.6.6.1.1.2.2.3.1.2.3">ğ‘–</ci></apply><ci id="S3.E6.m1.6.6.1.1.2.2.3.1.3.cmml" xref="S3.E6.m1.6.6.1.1.2.2.3.1.3">ğ‘</ci></apply><apply id="S3.E6.m1.6.6.1.1.2.2.3.2.cmml" xref="S3.E6.m1.6.6.1.1.2.2.3.2"><times id="S3.E6.m1.6.6.1.1.2.2.3.2.1.cmml" xref="S3.E6.m1.6.6.1.1.2.2.3.2.1"></times><apply id="S3.E6.m1.6.6.1.1.2.2.3.2.2.cmml" xref="S3.E6.m1.6.6.1.1.2.2.3.2.2"><csymbol cd="ambiguous" id="S3.E6.m1.6.6.1.1.2.2.3.2.2.1.cmml" xref="S3.E6.m1.6.6.1.1.2.2.3.2.2">superscript</csymbol><apply id="S3.E6.m1.6.6.1.1.2.2.3.2.2.2.cmml" xref="S3.E6.m1.6.6.1.1.2.2.3.2.2"><csymbol cd="ambiguous" id="S3.E6.m1.6.6.1.1.2.2.3.2.2.2.1.cmml" xref="S3.E6.m1.6.6.1.1.2.2.3.2.2">subscript</csymbol><ci id="S3.E6.m1.6.6.1.1.2.2.3.2.2.2.2.cmml" xref="S3.E6.m1.6.6.1.1.2.2.3.2.2.2.2">ğœ</ci><list id="S3.E6.m1.4.4.2.3.cmml" xref="S3.E6.m1.4.4.2.2"><apply id="S3.E6.m1.4.4.2.2.1.cmml" xref="S3.E6.m1.4.4.2.2.1"><csymbol cd="ambiguous" id="S3.E6.m1.4.4.2.2.1.1.cmml" xref="S3.E6.m1.4.4.2.2.1">subscript</csymbol><ci id="S3.E6.m1.4.4.2.2.1.2.cmml" xref="S3.E6.m1.4.4.2.2.1.2">ğ‘£</ci><ci id="S3.E6.m1.4.4.2.2.1.3.cmml" xref="S3.E6.m1.4.4.2.2.1.3">ğ‘‚</ci></apply><ci id="S3.E6.m1.3.3.1.1.cmml" xref="S3.E6.m1.3.3.1.1">ğ‘</ci></list></apply><ci id="S3.E6.m1.6.6.1.1.2.2.3.2.2.3.cmml" xref="S3.E6.m1.6.6.1.1.2.2.3.2.2.3">ğ‘–</ci></apply><apply id="S3.E6.m1.6.6.1.1.2.2.3.2.3.cmml" xref="S3.E6.m1.6.6.1.1.2.2.3.2.3"><csymbol cd="ambiguous" id="S3.E6.m1.6.6.1.1.2.2.3.2.3.1.cmml" xref="S3.E6.m1.6.6.1.1.2.2.3.2.3">superscript</csymbol><apply id="S3.E6.m1.6.6.1.1.2.2.3.2.3.2.cmml" xref="S3.E6.m1.6.6.1.1.2.2.3.2.3"><csymbol cd="ambiguous" id="S3.E6.m1.6.6.1.1.2.2.3.2.3.2.1.cmml" xref="S3.E6.m1.6.6.1.1.2.2.3.2.3">subscript</csymbol><ci id="S3.E6.m1.6.6.1.1.2.2.3.2.3.2.2.cmml" xref="S3.E6.m1.6.6.1.1.2.2.3.2.3.2.2">ğ‘£</ci><ci id="S3.E6.m1.6.6.1.1.2.2.3.2.3.2.3.cmml" xref="S3.E6.m1.6.6.1.1.2.2.3.2.3.2.3">ğ‘‚</ci></apply><ci id="S3.E6.m1.6.6.1.1.2.2.3.2.3.3.cmml" xref="S3.E6.m1.6.6.1.1.2.2.3.2.3.3">ğ‘–</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E6.m1.6c">\varphi_{I}=\sum_{i}^{G}\tau_{v_{I},q}^{i}\ v_{I}^{i}\quad\textrm{and}\quad\varphi_{O}=\sum_{i}^{N}\tau_{v_{O},q}^{i}\ v_{O}^{i}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Co-attention Fusion</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.8" class="ltx_p">The attended image-question and object-question visual features represent a combination of visual and language features that are most important to generate an answer for a given question. We concatenate these two bimodal representations to create the final visual-question embedding <math id="S3.SS3.p1.1.m1.1" class="ltx_Math" alttext="\varphi=\varphi_{I}\oplus\varphi_{O}" display="inline"><semantics id="S3.SS3.p1.1.m1.1a"><mrow id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml"><mi id="S3.SS3.p1.1.m1.1.1.2" xref="S3.SS3.p1.1.m1.1.1.2.cmml">Ï†</mi><mo id="S3.SS3.p1.1.m1.1.1.1" xref="S3.SS3.p1.1.m1.1.1.1.cmml">=</mo><mrow id="S3.SS3.p1.1.m1.1.1.3" xref="S3.SS3.p1.1.m1.1.1.3.cmml"><msub id="S3.SS3.p1.1.m1.1.1.3.2" xref="S3.SS3.p1.1.m1.1.1.3.2.cmml"><mi id="S3.SS3.p1.1.m1.1.1.3.2.2" xref="S3.SS3.p1.1.m1.1.1.3.2.2.cmml">Ï†</mi><mi id="S3.SS3.p1.1.m1.1.1.3.2.3" xref="S3.SS3.p1.1.m1.1.1.3.2.3.cmml">I</mi></msub><mo id="S3.SS3.p1.1.m1.1.1.3.1" xref="S3.SS3.p1.1.m1.1.1.3.1.cmml">âŠ•</mo><msub id="S3.SS3.p1.1.m1.1.1.3.3" xref="S3.SS3.p1.1.m1.1.1.3.3.cmml"><mi id="S3.SS3.p1.1.m1.1.1.3.3.2" xref="S3.SS3.p1.1.m1.1.1.3.3.2.cmml">Ï†</mi><mi id="S3.SS3.p1.1.m1.1.1.3.3.3" xref="S3.SS3.p1.1.m1.1.1.3.3.3.cmml">O</mi></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><apply id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1"><eq id="S3.SS3.p1.1.m1.1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1.1"></eq><ci id="S3.SS3.p1.1.m1.1.1.2.cmml" xref="S3.SS3.p1.1.m1.1.1.2">ğœ‘</ci><apply id="S3.SS3.p1.1.m1.1.1.3.cmml" xref="S3.SS3.p1.1.m1.1.1.3"><csymbol cd="latexml" id="S3.SS3.p1.1.m1.1.1.3.1.cmml" xref="S3.SS3.p1.1.m1.1.1.3.1">direct-sum</csymbol><apply id="S3.SS3.p1.1.m1.1.1.3.2.cmml" xref="S3.SS3.p1.1.m1.1.1.3.2"><csymbol cd="ambiguous" id="S3.SS3.p1.1.m1.1.1.3.2.1.cmml" xref="S3.SS3.p1.1.m1.1.1.3.2">subscript</csymbol><ci id="S3.SS3.p1.1.m1.1.1.3.2.2.cmml" xref="S3.SS3.p1.1.m1.1.1.3.2.2">ğœ‘</ci><ci id="S3.SS3.p1.1.m1.1.1.3.2.3.cmml" xref="S3.SS3.p1.1.m1.1.1.3.2.3">ğ¼</ci></apply><apply id="S3.SS3.p1.1.m1.1.1.3.3.cmml" xref="S3.SS3.p1.1.m1.1.1.3.3"><csymbol cd="ambiguous" id="S3.SS3.p1.1.m1.1.1.3.3.1.cmml" xref="S3.SS3.p1.1.m1.1.1.3.3">subscript</csymbol><ci id="S3.SS3.p1.1.m1.1.1.3.3.2.cmml" xref="S3.SS3.p1.1.m1.1.1.3.3.2">ğœ‘</ci><ci id="S3.SS3.p1.1.m1.1.1.3.3.3.cmml" xref="S3.SS3.p1.1.m1.1.1.3.3.3">ğ‘‚</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">\varphi=\varphi_{I}\oplus\varphi_{O}</annotation></semantics></math>. The visual-question embedding, <math id="S3.SS3.p1.2.m2.1" class="ltx_Math" alttext="\varphi" display="inline"><semantics id="S3.SS3.p1.2.m2.1a"><mi id="S3.SS3.p1.2.m2.1.1" xref="S3.SS3.p1.2.m2.1.1.cmml">Ï†</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.2.m2.1b"><ci id="S3.SS3.p1.2.m2.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1">ğœ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.2.m2.1c">\varphi</annotation></semantics></math> and original question embedding <math id="S3.SS3.p1.3.m3.1" class="ltx_Math" alttext="q" display="inline"><semantics id="S3.SS3.p1.3.m3.1a"><mi id="S3.SS3.p1.3.m3.1.1" xref="S3.SS3.p1.3.m3.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.3.m3.1b"><ci id="S3.SS3.p1.3.m3.1.1.cmml" xref="S3.SS3.p1.3.m3.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.3.m3.1c">q</annotation></semantics></math> again undergo same multi-modal fusion as Eq. <a href="#S3.E5" title="In 3.2 Hierarchical Attention Fusion â€£ 3 Methods â€£ Reciprocal Attention Fusion for Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>. The only difference is now <math id="S3.SS3.p1.4.m4.1" class="ltx_Math" alttext="t_{\varphi}=2\times t_{v}" display="inline"><semantics id="S3.SS3.p1.4.m4.1a"><mrow id="S3.SS3.p1.4.m4.1.1" xref="S3.SS3.p1.4.m4.1.1.cmml"><msub id="S3.SS3.p1.4.m4.1.1.2" xref="S3.SS3.p1.4.m4.1.1.2.cmml"><mi id="S3.SS3.p1.4.m4.1.1.2.2" xref="S3.SS3.p1.4.m4.1.1.2.2.cmml">t</mi><mi id="S3.SS3.p1.4.m4.1.1.2.3" xref="S3.SS3.p1.4.m4.1.1.2.3.cmml">Ï†</mi></msub><mo id="S3.SS3.p1.4.m4.1.1.1" xref="S3.SS3.p1.4.m4.1.1.1.cmml">=</mo><mrow id="S3.SS3.p1.4.m4.1.1.3" xref="S3.SS3.p1.4.m4.1.1.3.cmml"><mn id="S3.SS3.p1.4.m4.1.1.3.2" xref="S3.SS3.p1.4.m4.1.1.3.2.cmml">2</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS3.p1.4.m4.1.1.3.1" xref="S3.SS3.p1.4.m4.1.1.3.1.cmml">Ã—</mo><msub id="S3.SS3.p1.4.m4.1.1.3.3" xref="S3.SS3.p1.4.m4.1.1.3.3.cmml"><mi id="S3.SS3.p1.4.m4.1.1.3.3.2" xref="S3.SS3.p1.4.m4.1.1.3.3.2.cmml">t</mi><mi id="S3.SS3.p1.4.m4.1.1.3.3.3" xref="S3.SS3.p1.4.m4.1.1.3.3.3.cmml">v</mi></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.4.m4.1b"><apply id="S3.SS3.p1.4.m4.1.1.cmml" xref="S3.SS3.p1.4.m4.1.1"><eq id="S3.SS3.p1.4.m4.1.1.1.cmml" xref="S3.SS3.p1.4.m4.1.1.1"></eq><apply id="S3.SS3.p1.4.m4.1.1.2.cmml" xref="S3.SS3.p1.4.m4.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p1.4.m4.1.1.2.1.cmml" xref="S3.SS3.p1.4.m4.1.1.2">subscript</csymbol><ci id="S3.SS3.p1.4.m4.1.1.2.2.cmml" xref="S3.SS3.p1.4.m4.1.1.2.2">ğ‘¡</ci><ci id="S3.SS3.p1.4.m4.1.1.2.3.cmml" xref="S3.SS3.p1.4.m4.1.1.2.3">ğœ‘</ci></apply><apply id="S3.SS3.p1.4.m4.1.1.3.cmml" xref="S3.SS3.p1.4.m4.1.1.3"><times id="S3.SS3.p1.4.m4.1.1.3.1.cmml" xref="S3.SS3.p1.4.m4.1.1.3.1"></times><cn type="integer" id="S3.SS3.p1.4.m4.1.1.3.2.cmml" xref="S3.SS3.p1.4.m4.1.1.3.2">2</cn><apply id="S3.SS3.p1.4.m4.1.1.3.3.cmml" xref="S3.SS3.p1.4.m4.1.1.3.3"><csymbol cd="ambiguous" id="S3.SS3.p1.4.m4.1.1.3.3.1.cmml" xref="S3.SS3.p1.4.m4.1.1.3.3">subscript</csymbol><ci id="S3.SS3.p1.4.m4.1.1.3.3.2.cmml" xref="S3.SS3.p1.4.m4.1.1.3.3.2">ğ‘¡</ci><ci id="S3.SS3.p1.4.m4.1.1.3.3.3.cmml" xref="S3.SS3.p1.4.m4.1.1.3.3.3">ğ‘£</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.4.m4.1c">t_{\varphi}=2\times t_{v}</annotation></semantics></math> as our model uses two glimpse attention which was found to yield better results <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:70%;">Fukui etÂ al.</span> (<a href="#bib.bib10" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">2016</span></a>); <span class="ltx_text" style="font-size:70%;">Ben-Younes etÂ al.</span> (<a href="#bib.bib5" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">2017</span></a>); <span class="ltx_text" style="font-size:70%;">Kim etÂ al.</span> (<a href="#bib.bib17" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">2016</span></a>)</cite>. The output of the final fusion is then passed on to the classifier that predicts the best answer <math id="S3.SS3.p1.5.m5.1" class="ltx_Math" alttext="\hat{a}" display="inline"><semantics id="S3.SS3.p1.5.m5.1a"><mover accent="true" id="S3.SS3.p1.5.m5.1.1" xref="S3.SS3.p1.5.m5.1.1.cmml"><mi id="S3.SS3.p1.5.m5.1.1.2" xref="S3.SS3.p1.5.m5.1.1.2.cmml">a</mi><mo id="S3.SS3.p1.5.m5.1.1.1" xref="S3.SS3.p1.5.m5.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.5.m5.1b"><apply id="S3.SS3.p1.5.m5.1.1.cmml" xref="S3.SS3.p1.5.m5.1.1"><ci id="S3.SS3.p1.5.m5.1.1.1.cmml" xref="S3.SS3.p1.5.m5.1.1.1">^</ci><ci id="S3.SS3.p1.5.m5.1.1.2.cmml" xref="S3.SS3.p1.5.m5.1.1.2">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.5.m5.1c">\hat{a}</annotation></semantics></math> from the answer dictionary <math id="S3.SS3.p1.6.m6.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S3.SS3.p1.6.m6.1a"><mi id="S3.SS3.p1.6.m6.1.1" xref="S3.SS3.p1.6.m6.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.6.m6.1b"><ci id="S3.SS3.p1.6.m6.1.1.cmml" xref="S3.SS3.p1.6.m6.1.1">ğ´</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.6.m6.1c">A</annotation></semantics></math> given question <math id="S3.SS3.p1.7.m7.1" class="ltx_Math" alttext="\bf{q}" display="inline"><semantics id="S3.SS3.p1.7.m7.1a"><mi id="S3.SS3.p1.7.m7.1.1" xref="S3.SS3.p1.7.m7.1.1.cmml">ğª</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.7.m7.1b"><ci id="S3.SS3.p1.7.m7.1.1.cmml" xref="S3.SS3.p1.7.m7.1.1">ğª</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.7.m7.1c">\bf{q}</annotation></semantics></math> and visual input <math id="S3.SS3.p1.8.m8.1" class="ltx_Math" alttext="\bf{v}" display="inline"><semantics id="S3.SS3.p1.8.m8.1a"><mi id="S3.SS3.p1.8.m8.1.1" xref="S3.SS3.p1.8.m8.1.1.cmml">ğ¯</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.8.m8.1b"><ci id="S3.SS3.p1.8.m8.1.1.cmml" xref="S3.SS3.p1.8.m8.1.1">ğ¯</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.8.m8.1c">\bf{v}</annotation></semantics></math>.</p>
</div>
<figure id="S3.T1" class="ltx_table">
<div id="S3.T1.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:541.2pt;height:307.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-30.1pt,17.1pt) scale(0.9,0.9) ;">
<table id="S3.T1.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T1.1.1.1.1" class="ltx_tr">
<th id="S3.T1.1.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt">Methods</th>
<th id="S3.T1.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="4">Test-dev</th>
<th id="S3.T1.1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_tt" colspan="4">Test-standard</th>
</tr>
<tr id="S3.T1.1.1.2.2" class="ltx_tr">
<th id="S3.T1.1.1.2.2.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r"></th>
<th id="S3.T1.1.1.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column">Y/N</th>
<th id="S3.T1.1.1.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column">No.</th>
<th id="S3.T1.1.1.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column">Other</th>
<th id="S3.T1.1.1.2.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r">All</th>
<th id="S3.T1.1.1.2.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column">Y/N</th>
<th id="S3.T1.1.1.2.2.7" class="ltx_td ltx_align_center ltx_th ltx_th_column">No.</th>
<th id="S3.T1.1.1.2.2.8" class="ltx_td ltx_align_center ltx_th ltx_th_column">Other</th>
<th id="S3.T1.1.1.2.2.9" class="ltx_td ltx_align_center ltx_th ltx_th_column">All</th>
</tr>
<tr id="S3.T1.1.1.3.3" class="ltx_tr">
<th id="S3.T1.1.1.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t">RAF (Ours)</th>
<th id="S3.T1.1.1.3.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S3.T1.1.1.3.3.2.1" class="ltx_text ltx_font_bold">85.9</span></th>
<th id="S3.T1.1.1.3.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S3.T1.1.1.3.3.3.1" class="ltx_text ltx_font_bold">41.3</span></th>
<th id="S3.T1.1.1.3.3.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S3.T1.1.1.3.3.4.1" class="ltx_text ltx_font_bold">58.7</span></th>
<th id="S3.T1.1.1.3.3.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S3.T1.1.1.3.3.5.1" class="ltx_text ltx_font_bold">68.0</span></th>
<th id="S3.T1.1.1.3.3.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S3.T1.1.1.3.3.6.1" class="ltx_text ltx_font_bold">85.8</span></th>
<th id="S3.T1.1.1.3.3.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">41.4</th>
<th id="S3.T1.1.1.3.3.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">58.9</th>
<th id="S3.T1.1.1.3.3.9" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S3.T1.1.1.3.3.9.1" class="ltx_text ltx_font_bold">68.2</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T1.1.1.4.1" class="ltx_tr">
<th id="S3.T1.1.1.4.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">ReasonNet<cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:70%;">Ilievski and Feng</span> (<a href="#bib.bib14" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">2017</span></a>)</cite>
</th>
<td id="S3.T1.1.1.4.1.2" class="ltx_td ltx_align_center ltx_border_t">-</td>
<td id="S3.T1.1.1.4.1.3" class="ltx_td ltx_align_center ltx_border_t">-</td>
<td id="S3.T1.1.1.4.1.4" class="ltx_td ltx_align_center ltx_border_t">-</td>
<td id="S3.T1.1.1.4.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">-</td>
<td id="S3.T1.1.1.4.1.6" class="ltx_td ltx_align_center ltx_border_t">84.0</td>
<td id="S3.T1.1.1.4.1.7" class="ltx_td ltx_align_center ltx_border_t">38.7</td>
<td id="S3.T1.1.1.4.1.8" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.1.1.4.1.8.1" class="ltx_text ltx_font_bold">60.4</span></td>
<td id="S3.T1.1.1.4.1.9" class="ltx_td ltx_align_center ltx_border_t">67.9</td>
</tr>
<tr id="S3.T1.1.1.5.2" class="ltx_tr">
<th id="S3.T1.1.1.5.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">MFB+CoAtt+Glove <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:70%;">Yu etÂ al.</span> (<a href="#bib.bib37" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">2018</span></a>)</cite>
</th>
<td id="S3.T1.1.1.5.2.2" class="ltx_td ltx_align_center">85.0</td>
<td id="S3.T1.1.1.5.2.3" class="ltx_td ltx_align_center">39.7</td>
<td id="S3.T1.1.1.5.2.4" class="ltx_td ltx_align_center">57.4</td>
<td id="S3.T1.1.1.5.2.5" class="ltx_td ltx_align_center ltx_border_r">66.8</td>
<td id="S3.T1.1.1.5.2.6" class="ltx_td ltx_align_center">85.0</td>
<td id="S3.T1.1.1.5.2.7" class="ltx_td ltx_align_center">39.5</td>
<td id="S3.T1.1.1.5.2.8" class="ltx_td ltx_align_center">57.4</td>
<td id="S3.T1.1.1.5.2.9" class="ltx_td ltx_align_center">66.9</td>
</tr>
<tr id="S3.T1.1.1.6.3" class="ltx_tr">
<th id="S3.T1.1.1.6.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Dual-MFA <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:70%;">Lu etÂ al.</span> (<a href="#bib.bib22" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">2017</span></a>)</cite>
</th>
<td id="S3.T1.1.1.6.3.2" class="ltx_td ltx_align_center">83.6</td>
<td id="S3.T1.1.1.6.3.3" class="ltx_td ltx_align_center">40.2</td>
<td id="S3.T1.1.1.6.3.4" class="ltx_td ltx_align_center">56.8</td>
<td id="S3.T1.1.1.6.3.5" class="ltx_td ltx_align_center ltx_border_r">66.0</td>
<td id="S3.T1.1.1.6.3.6" class="ltx_td ltx_align_center">83.4</td>
<td id="S3.T1.1.1.6.3.7" class="ltx_td ltx_align_center">40.4</td>
<td id="S3.T1.1.1.6.3.8" class="ltx_td ltx_align_center">56.9</td>
<td id="S3.T1.1.1.6.3.9" class="ltx_td ltx_align_center">66.1</td>
</tr>
<tr id="S3.T1.1.1.7.4" class="ltx_tr">
<th id="S3.T1.1.1.7.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">MLB+VG <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:70%;">Kim etÂ al.</span> (<a href="#bib.bib17" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">2016</span></a>)</cite>
</th>
<td id="S3.T1.1.1.7.4.2" class="ltx_td ltx_align_center">84.1</td>
<td id="S3.T1.1.1.7.4.3" class="ltx_td ltx_align_center">38.0</td>
<td id="S3.T1.1.1.7.4.4" class="ltx_td ltx_align_center">54.9</td>
<td id="S3.T1.1.1.7.4.5" class="ltx_td ltx_align_center ltx_border_r">65.8</td>
<td id="S3.T1.1.1.7.4.6" class="ltx_td ltx_align_center">-</td>
<td id="S3.T1.1.1.7.4.7" class="ltx_td ltx_align_center">-</td>
<td id="S3.T1.1.1.7.4.8" class="ltx_td ltx_align_center">-</td>
<td id="S3.T1.1.1.7.4.9" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S3.T1.1.1.8.5" class="ltx_tr">
<th id="S3.T1.1.1.8.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">MCB+Att+GloVe <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:70%;">Fukui etÂ al.</span> (<a href="#bib.bib10" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">2016</span></a>)</cite>
</th>
<td id="S3.T1.1.1.8.5.2" class="ltx_td ltx_align_center">82.3</td>
<td id="S3.T1.1.1.8.5.3" class="ltx_td ltx_align_center">37.2</td>
<td id="S3.T1.1.1.8.5.4" class="ltx_td ltx_align_center">57.4</td>
<td id="S3.T1.1.1.8.5.5" class="ltx_td ltx_align_center ltx_border_r">65.4</td>
<td id="S3.T1.1.1.8.5.6" class="ltx_td ltx_align_center">-</td>
<td id="S3.T1.1.1.8.5.7" class="ltx_td ltx_align_center">-</td>
<td id="S3.T1.1.1.8.5.8" class="ltx_td ltx_align_center">-</td>
<td id="S3.T1.1.1.8.5.9" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S3.T1.1.1.9.6" class="ltx_tr">
<th id="S3.T1.1.1.9.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">MLAN <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:70%;">Yu etÂ al.</span> (<a href="#bib.bib36" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">2017</span></a>)</cite>
</th>
<td id="S3.T1.1.1.9.6.2" class="ltx_td ltx_align_center">81.8</td>
<td id="S3.T1.1.1.9.6.3" class="ltx_td ltx_align_center">41.2</td>
<td id="S3.T1.1.1.9.6.4" class="ltx_td ltx_align_center">56.7</td>
<td id="S3.T1.1.1.9.6.5" class="ltx_td ltx_align_center ltx_border_r">65.3</td>
<td id="S3.T1.1.1.9.6.6" class="ltx_td ltx_align_center">81.3</td>
<td id="S3.T1.1.1.9.6.7" class="ltx_td ltx_align_center"><span id="S3.T1.1.1.9.6.7.1" class="ltx_text ltx_font_bold">41.9</span></td>
<td id="S3.T1.1.1.9.6.8" class="ltx_td ltx_align_center">56.5</td>
<td id="S3.T1.1.1.9.6.9" class="ltx_td ltx_align_center">65.2</td>
</tr>
<tr id="S3.T1.1.1.10.7" class="ltx_tr">
<th id="S3.T1.1.1.10.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">MUTAN <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:70%;">Ben-Younes etÂ al.</span> (<a href="#bib.bib5" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">2017</span></a>)</cite><span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Single model performance is evaluated using their publicly available code.</span></span></span>
</th>
<td id="S3.T1.1.1.10.7.2" class="ltx_td ltx_align_center">84.8</td>
<td id="S3.T1.1.1.10.7.3" class="ltx_td ltx_align_center">37.7</td>
<td id="S3.T1.1.1.10.7.4" class="ltx_td ltx_align_center">54.9</td>
<td id="S3.T1.1.1.10.7.5" class="ltx_td ltx_align_center ltx_border_r">65.2</td>
<td id="S3.T1.1.1.10.7.6" class="ltx_td ltx_align_center">-</td>
<td id="S3.T1.1.1.10.7.7" class="ltx_td ltx_align_center">-</td>
<td id="S3.T1.1.1.10.7.8" class="ltx_td ltx_align_center">-</td>
<td id="S3.T1.1.1.10.7.9" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S3.T1.1.1.11.8" class="ltx_tr">
<th id="S3.T1.1.1.11.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">DAN (ResNet) <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:70%;">Nam etÂ al.</span> (<a href="#bib.bib24" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">2016</span></a>)</cite>
</th>
<td id="S3.T1.1.1.11.8.2" class="ltx_td ltx_align_center">83.0</td>
<td id="S3.T1.1.1.11.8.3" class="ltx_td ltx_align_center">39.1</td>
<td id="S3.T1.1.1.11.8.4" class="ltx_td ltx_align_center">53.9</td>
<td id="S3.T1.1.1.11.8.5" class="ltx_td ltx_align_center ltx_border_r">64.3</td>
<td id="S3.T1.1.1.11.8.6" class="ltx_td ltx_align_center">82.8</td>
<td id="S3.T1.1.1.11.8.7" class="ltx_td ltx_align_center">38.1</td>
<td id="S3.T1.1.1.11.8.8" class="ltx_td ltx_align_center">54.0</td>
<td id="S3.T1.1.1.11.8.9" class="ltx_td ltx_align_center">64.2</td>
</tr>
<tr id="S3.T1.1.1.12.9" class="ltx_tr">
<th id="S3.T1.1.1.12.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">HieCoAtt <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:70%;">Lu etÂ al.</span> (<a href="#bib.bib21" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">2016</span></a>)</cite>
</th>
<td id="S3.T1.1.1.12.9.2" class="ltx_td ltx_align_center">79.7</td>
<td id="S3.T1.1.1.12.9.3" class="ltx_td ltx_align_center">38.7</td>
<td id="S3.T1.1.1.12.9.4" class="ltx_td ltx_align_center">51.7</td>
<td id="S3.T1.1.1.12.9.5" class="ltx_td ltx_align_center ltx_border_r">61.8</td>
<td id="S3.T1.1.1.12.9.6" class="ltx_td ltx_align_center">-</td>
<td id="S3.T1.1.1.12.9.7" class="ltx_td ltx_align_center">-</td>
<td id="S3.T1.1.1.12.9.8" class="ltx_td ltx_align_center">-</td>
<td id="S3.T1.1.1.12.9.9" class="ltx_td ltx_align_center">62.1</td>
</tr>
<tr id="S3.T1.1.1.13.10" class="ltx_tr">
<th id="S3.T1.1.1.13.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">A+C+K+LSTM<cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:70%;">Wu etÂ al.</span> (<a href="#bib.bib31" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">2016</span></a>)</cite>
</th>
<td id="S3.T1.1.1.13.10.2" class="ltx_td ltx_align_center">81.0</td>
<td id="S3.T1.1.1.13.10.3" class="ltx_td ltx_align_center">38.4</td>
<td id="S3.T1.1.1.13.10.4" class="ltx_td ltx_align_center">45.2</td>
<td id="S3.T1.1.1.13.10.5" class="ltx_td ltx_align_center ltx_border_r">59.2</td>
<td id="S3.T1.1.1.13.10.6" class="ltx_td ltx_align_center">81.1</td>
<td id="S3.T1.1.1.13.10.7" class="ltx_td ltx_align_center">37.1</td>
<td id="S3.T1.1.1.13.10.8" class="ltx_td ltx_align_center">45.8</td>
<td id="S3.T1.1.1.13.10.9" class="ltx_td ltx_align_center">59.4</td>
</tr>
<tr id="S3.T1.1.1.14.11" class="ltx_tr">
<th id="S3.T1.1.1.14.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">VQA LSTM Q+I <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:70%;">Antol etÂ al.</span> (<a href="#bib.bib3" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">2015</span></a>)</cite>
</th>
<td id="S3.T1.1.1.14.11.2" class="ltx_td ltx_align_center">80.5</td>
<td id="S3.T1.1.1.14.11.3" class="ltx_td ltx_align_center">36.8</td>
<td id="S3.T1.1.1.14.11.4" class="ltx_td ltx_align_center">43.1</td>
<td id="S3.T1.1.1.14.11.5" class="ltx_td ltx_align_center ltx_border_r">57.8</td>
<td id="S3.T1.1.1.14.11.6" class="ltx_td ltx_align_center">80.6</td>
<td id="S3.T1.1.1.14.11.7" class="ltx_td ltx_align_center">36.5</td>
<td id="S3.T1.1.1.14.11.8" class="ltx_td ltx_align_center">43.7</td>
<td id="S3.T1.1.1.14.11.9" class="ltx_td ltx_align_center">58.2</td>
</tr>
<tr id="S3.T1.1.1.15.12" class="ltx_tr">
<th id="S3.T1.1.1.15.12.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">SAN<cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:70%;">Yang etÂ al.</span> (<a href="#bib.bib35" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">2016</span></a>)</cite>
</th>
<td id="S3.T1.1.1.15.12.2" class="ltx_td ltx_align_center">79.3</td>
<td id="S3.T1.1.1.15.12.3" class="ltx_td ltx_align_center">36.6</td>
<td id="S3.T1.1.1.15.12.4" class="ltx_td ltx_align_center">46.1</td>
<td id="S3.T1.1.1.15.12.5" class="ltx_td ltx_align_center ltx_border_r">58.7</td>
<td id="S3.T1.1.1.15.12.6" class="ltx_td ltx_align_center">-</td>
<td id="S3.T1.1.1.15.12.7" class="ltx_td ltx_align_center">-</td>
<td id="S3.T1.1.1.15.12.8" class="ltx_td ltx_align_center">-</td>
<td id="S3.T1.1.1.15.12.9" class="ltx_td ltx_align_center">58.9</td>
</tr>
<tr id="S3.T1.1.1.16.13" class="ltx_tr">
<th id="S3.T1.1.1.16.13.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">AYN <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:70%;">Malinowski etÂ al.</span> (<a href="#bib.bib23" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">2017</span></a>)</cite>
</th>
<td id="S3.T1.1.1.16.13.2" class="ltx_td ltx_align_center">78.4</td>
<td id="S3.T1.1.1.16.13.3" class="ltx_td ltx_align_center">36.4</td>
<td id="S3.T1.1.1.16.13.4" class="ltx_td ltx_align_center">46.3</td>
<td id="S3.T1.1.1.16.13.5" class="ltx_td ltx_align_center ltx_border_r">58.4</td>
<td id="S3.T1.1.1.16.13.6" class="ltx_td ltx_align_center">78.2</td>
<td id="S3.T1.1.1.16.13.7" class="ltx_td ltx_align_center">37.1</td>
<td id="S3.T1.1.1.16.13.8" class="ltx_td ltx_align_center">45.8</td>
<td id="S3.T1.1.1.16.13.9" class="ltx_td ltx_align_center">59.4</td>
</tr>
<tr id="S3.T1.1.1.17.14" class="ltx_tr">
<th id="S3.T1.1.1.17.14.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">NMN <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:70%;">Andreas etÂ al.</span> (<a href="#bib.bib2" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">2016</span></a>)</cite>
</th>
<td id="S3.T1.1.1.17.14.2" class="ltx_td ltx_align_center">81.2</td>
<td id="S3.T1.1.1.17.14.3" class="ltx_td ltx_align_center">38.0</td>
<td id="S3.T1.1.1.17.14.4" class="ltx_td ltx_align_center">44.0</td>
<td id="S3.T1.1.1.17.14.5" class="ltx_td ltx_align_center ltx_border_r">58.6</td>
<td id="S3.T1.1.1.17.14.6" class="ltx_td ltx_align_center">-</td>
<td id="S3.T1.1.1.17.14.7" class="ltx_td ltx_align_center">-</td>
<td id="S3.T1.1.1.17.14.8" class="ltx_td ltx_align_center">-</td>
<td id="S3.T1.1.1.17.14.9" class="ltx_td ltx_align_center">58.7</td>
</tr>
<tr id="S3.T1.1.1.18.15" class="ltx_tr">
<th id="S3.T1.1.1.18.15.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">DMN+ <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:70%;">Xiong etÂ al.</span> (<a href="#bib.bib33" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">2016</span></a>)</cite>
</th>
<td id="S3.T1.1.1.18.15.2" class="ltx_td ltx_align_center">60.3</td>
<td id="S3.T1.1.1.18.15.3" class="ltx_td ltx_align_center">80.5</td>
<td id="S3.T1.1.1.18.15.4" class="ltx_td ltx_align_center">48.3</td>
<td id="S3.T1.1.1.18.15.5" class="ltx_td ltx_align_center ltx_border_r">56.8</td>
<td id="S3.T1.1.1.18.15.6" class="ltx_td ltx_align_center">-</td>
<td id="S3.T1.1.1.18.15.7" class="ltx_td ltx_align_center">-</td>
<td id="S3.T1.1.1.18.15.8" class="ltx_td ltx_align_center">-</td>
<td id="S3.T1.1.1.18.15.9" class="ltx_td ltx_align_center">60.4</td>
</tr>
<tr id="S3.T1.1.1.19.16" class="ltx_tr">
<th id="S3.T1.1.1.19.16.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r">iBowling <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:70%;">Zhou etÂ al.</span> (<a href="#bib.bib38" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">2015</span></a>)</cite>
</th>
<td id="S3.T1.1.1.19.16.2" class="ltx_td ltx_align_center ltx_border_bb">76.5</td>
<td id="S3.T1.1.1.19.16.3" class="ltx_td ltx_align_center ltx_border_bb">35.0</td>
<td id="S3.T1.1.1.19.16.4" class="ltx_td ltx_align_center ltx_border_bb">42.6</td>
<td id="S3.T1.1.1.19.16.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">55.7</td>
<td id="S3.T1.1.1.19.16.6" class="ltx_td ltx_align_center ltx_border_bb">76.8</td>
<td id="S3.T1.1.1.19.16.7" class="ltx_td ltx_align_center ltx_border_bb">35.0</td>
<td id="S3.T1.1.1.19.16.8" class="ltx_td ltx_align_center ltx_border_bb">42.6</td>
<td id="S3.T1.1.1.19.16.9" class="ltx_td ltx_align_center ltx_border_bb">55.9</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Comparison of the state-of-the-art methods with our single model performance on VQAv1.0 test-dev and test-standard server.</figcaption>
</figure>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>

<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Dataset</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">We perform experiments on <span id="S4.SS1.p1.1.1" class="ltx_text ltx_font_bold">VQAv1</span> <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:70%;">Antol etÂ al.</span> (<a href="#bib.bib3" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">2015</span></a>)</cite> and <span id="S4.SS1.p1.1.2" class="ltx_text ltx_font_bold">VQAv2</span> <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:70%;">Goyal etÂ al.</span> (<a href="#bib.bib12" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">2016</span></a>)</cite> both of which are large scale VQA datasets. VQAv1 contains over 200K images from the COCO dataset with 610K natural language open-ended questions. VQAv2 <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:70%;">Goyal etÂ al.</span> (<a href="#bib.bib12" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">2016</span></a>)</cite> contains almost twice as many question for the same number of images. VQAv2 has a balanced image-question pair to mitigate the language bias that allows a more realistic evaluation protocol. <span id="S4.SS1.p1.1.3" class="ltx_text ltx_font_bold">Visual Genome</span> is another larger scale dataset that has image question pair with dense annotation of objects, attributes <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:70%;">Krishna etÂ al.</span> (<a href="#bib.bib20" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">2016</span></a>)</cite>. We train a pretrained faster RCNN model (on ImageNet) again on Visual Genome dataset with class and attribute labels to extract object level features from the input image.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>VQA Model Architecture</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p"><span id="S4.SS2.p1.1.1" class="ltx_text ltx_font_bold">Question Feature Embedding:</span> Our model embeds the question features by first generating the questions and answer dictionary from training and validation set of the VQA datasets. We make the question and answers lower case, remove punctuation and perform other standard preprocessing steps before tokenizing the words, and representing them into one-hot vector representation. As mentioned in Section <a href="#S3.SS1" title="3.1 Joint Feature Embedding â€£ 3 Methods â€£ Reciprocal Attention Fusion for Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a>, these question embeddings are fed to GRUs pretrained with Skip-thoughts <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:70%;">Kiros etÂ al.</span> (<a href="#bib.bib19" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">2015</span></a>)</cite> model that generates <math id="S4.SS2.p1.1.m1.1" class="ltx_Math" alttext="2400" display="inline"><semantics id="S4.SS2.p1.1.m1.1a"><mn id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml">2400</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><cn type="integer" id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1">2400</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">2400</annotation></semantics></math>-d language feature embeddings for the given question. When experimenting with VQAv1 and VQAv2, we parse questions respectively from training and validation sets to create the question vocabulary.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.3" class="ltx_p"><span id="S4.SS2.p2.3.1" class="ltx_text ltx_font_bold">Answer Encoding:</span> We formulate the VQA task as a classification task. We create an answer dictionary from the training data and select the top <math id="S4.SS2.p2.1.m1.1" class="ltx_Math" alttext="2000" display="inline"><semantics id="S4.SS2.p2.1.m1.1a"><mn id="S4.SS2.p2.1.m1.1.1" xref="S4.SS2.p2.1.m1.1.1.cmml">2000</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.1.m1.1b"><cn type="integer" id="S4.SS2.p2.1.m1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1">2000</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.1.m1.1c">2000</annotation></semantics></math> answers as the different classes. We pass the output of the final fusion layer through a convolutional layer that outputs a <math id="S4.SS2.p2.2.m2.1" class="ltx_Math" alttext="2000" display="inline"><semantics id="S4.SS2.p2.2.m2.1a"><mn id="S4.SS2.p2.2.m2.1.1" xref="S4.SS2.p2.2.m2.1.1.cmml">2000</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.2.m2.1b"><cn type="integer" id="S4.SS2.p2.2.m2.1.1.cmml" xref="S4.SS2.p2.2.m2.1.1">2000</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.2.m2.1c">2000</annotation></semantics></math>d vector. This vector is passed through the classifier to predict <math id="S4.SS2.p2.3.m3.1" class="ltx_Math" alttext="\hat{a}" display="inline"><semantics id="S4.SS2.p2.3.m3.1a"><mover accent="true" id="S4.SS2.p2.3.m3.1.1" xref="S4.SS2.p2.3.m3.1.1.cmml"><mi id="S4.SS2.p2.3.m3.1.1.2" xref="S4.SS2.p2.3.m3.1.1.2.cmml">a</mi><mo id="S4.SS2.p2.3.m3.1.1.1" xref="S4.SS2.p2.3.m3.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.3.m3.1b"><apply id="S4.SS2.p2.3.m3.1.1.cmml" xref="S4.SS2.p2.3.m3.1.1"><ci id="S4.SS2.p2.3.m3.1.1.1.cmml" xref="S4.SS2.p2.3.m3.1.1.1">^</ci><ci id="S4.SS2.p2.3.m3.1.1.2.cmml" xref="S4.SS2.p2.3.m3.1.1.2">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.3.m3.1c">\hat{a}</annotation></semantics></math>.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.3" class="ltx_p">We use Adam solver <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:70%;">Kingma and Ba</span> (<a href="#bib.bib18" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">2014</span></a>)</cite> with base learning rate of <math id="S4.SS2.p3.1.m1.1" class="ltx_Math" alttext="10^{-4}" display="inline"><semantics id="S4.SS2.p3.1.m1.1a"><msup id="S4.SS2.p3.1.m1.1.1" xref="S4.SS2.p3.1.m1.1.1.cmml"><mn id="S4.SS2.p3.1.m1.1.1.2" xref="S4.SS2.p3.1.m1.1.1.2.cmml">10</mn><mrow id="S4.SS2.p3.1.m1.1.1.3" xref="S4.SS2.p3.1.m1.1.1.3.cmml"><mo id="S4.SS2.p3.1.m1.1.1.3a" xref="S4.SS2.p3.1.m1.1.1.3.cmml">âˆ’</mo><mn id="S4.SS2.p3.1.m1.1.1.3.2" xref="S4.SS2.p3.1.m1.1.1.3.2.cmml">4</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.1.m1.1b"><apply id="S4.SS2.p3.1.m1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p3.1.m1.1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1">superscript</csymbol><cn type="integer" id="S4.SS2.p3.1.m1.1.1.2.cmml" xref="S4.SS2.p3.1.m1.1.1.2">10</cn><apply id="S4.SS2.p3.1.m1.1.1.3.cmml" xref="S4.SS2.p3.1.m1.1.1.3"><minus id="S4.SS2.p3.1.m1.1.1.3.1.cmml" xref="S4.SS2.p3.1.m1.1.1.3"></minus><cn type="integer" id="S4.SS2.p3.1.m1.1.1.3.2.cmml" xref="S4.SS2.p3.1.m1.1.1.3.2">4</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.1.m1.1c">10^{-4}</annotation></semantics></math> and batch size of <math id="S4.SS2.p3.2.m2.1" class="ltx_Math" alttext="512" display="inline"><semantics id="S4.SS2.p3.2.m2.1a"><mn id="S4.SS2.p3.2.m2.1.1" xref="S4.SS2.p3.2.m2.1.1.cmml">512</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.2.m2.1b"><cn type="integer" id="S4.SS2.p3.2.m2.1.1.cmml" xref="S4.SS2.p3.2.m2.1.1">512</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.2.m2.1c">512</annotation></semantics></math> for our experiments. We keep the training parameters same for all our experiments. We use NVidia Tesla P100 (SXM2) GPUs to train our models and report our experimentation results on VQAv1 <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:70%;">Antol etÂ al.</span> (<a href="#bib.bib3" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">2015</span></a>)</cite> and VQAv2 <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:70%;">Goyal etÂ al.</span> (<a href="#bib.bib12" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">2016</span></a>)</cite> dataset representing <math id="S4.SS2.p3.3.m3.1" class="ltx_Math" alttext="1500" display="inline"><semantics id="S4.SS2.p3.3.m3.1a"><mn id="S4.SS2.p3.3.m3.1.1" xref="S4.SS2.p3.3.m3.1.1.cmml">1500</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.3.m3.1b"><cn type="integer" id="S4.SS2.p3.3.m3.1.1.cmml" xref="S4.SS2.p3.3.m3.1.1">1500</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.3.m3.1c">1500</annotation></semantics></math> GPU hours of computation.</p>
</div>
<figure id="S4.T2" class="ltx_table">
<div id="S4.T2.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:566.6pt;height:178.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-31.5pt,9.9pt) scale(0.9,0.9) ;">
<table id="S4.T2.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T2.1.1.1.1" class="ltx_tr">
<th id="S4.T2.1.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt">Methods</th>
<th id="S4.T2.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="4">Test-dev</th>
<th id="S4.T2.1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_tt" colspan="4">Test-standard</th>
</tr>
<tr id="S4.T2.1.1.2.2" class="ltx_tr">
<th id="S4.T2.1.1.2.2.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r"></th>
<th id="S4.T2.1.1.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column">Y/N</th>
<th id="S4.T2.1.1.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column">No.</th>
<th id="S4.T2.1.1.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column">Other</th>
<th id="S4.T2.1.1.2.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r">All</th>
<th id="S4.T2.1.1.2.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column">Y/N</th>
<th id="S4.T2.1.1.2.2.7" class="ltx_td ltx_align_center ltx_th ltx_th_column">No.</th>
<th id="S4.T2.1.1.2.2.8" class="ltx_td ltx_align_center ltx_th ltx_th_column">Other</th>
<th id="S4.T2.1.1.2.2.9" class="ltx_td ltx_align_center ltx_th ltx_th_column">All</th>
</tr>
<tr id="S4.T2.1.1.3.3" class="ltx_tr">
<th id="S4.T2.1.1.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t">RAF (Ours)</th>
<th id="S4.T2.1.1.3.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T2.1.1.3.3.2.1" class="ltx_text ltx_font_bold">84.1</span></th>
<th id="S4.T2.1.1.3.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T2.1.1.3.3.3.1" class="ltx_text ltx_font_bold">44.9</span></th>
<th id="S4.T2.1.1.3.3.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T2.1.1.3.3.4.1" class="ltx_text ltx_font_bold">57.8</span></th>
<th id="S4.T2.1.1.3.3.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T2.1.1.3.3.5.1" class="ltx_text ltx_font_bold">67.2</span></th>
<th id="S4.T2.1.1.3.3.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T2.1.1.3.3.6.1" class="ltx_text ltx_font_bold">84.2</span></th>
<th id="S4.T2.1.1.3.3.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T2.1.1.3.3.7.1" class="ltx_text ltx_font_bold">44.4</span></th>
<th id="S4.T2.1.1.3.3.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T2.1.1.3.3.8.1" class="ltx_text ltx_font_bold">58.0</span></th>
<th id="S4.T2.1.1.3.3.9" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T2.1.1.3.3.9.1" class="ltx_text ltx_font_bold">67.4</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T2.1.1.4.1" class="ltx_tr">
<th id="S4.T2.1.1.4.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">BU, adaptive K <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:70%;">Teney etÂ al.</span> (<a href="#bib.bib29" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">2017</span></a>)</cite>
</th>
<td id="S4.T2.1.1.4.1.2" class="ltx_td ltx_align_center ltx_border_t">81.8</td>
<td id="S4.T2.1.1.4.1.3" class="ltx_td ltx_align_center ltx_border_t">44.2</td>
<td id="S4.T2.1.1.4.1.4" class="ltx_td ltx_align_center ltx_border_t">56.1</td>
<td id="S4.T2.1.1.4.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">65.3</td>
<td id="S4.T2.1.1.4.1.6" class="ltx_td ltx_align_center ltx_border_t">82.2</td>
<td id="S4.T2.1.1.4.1.7" class="ltx_td ltx_align_center ltx_border_t">43.9</td>
<td id="S4.T2.1.1.4.1.8" class="ltx_td ltx_align_center ltx_border_t">56.3</td>
<td id="S4.T2.1.1.4.1.9" class="ltx_td ltx_align_center ltx_border_t">65.7</td>
</tr>
<tr id="S4.T2.1.1.5.2" class="ltx_tr">
<th id="S4.T2.1.1.5.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">MFB <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:70%;">Yu etÂ al.</span> (<a href="#bib.bib37" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">2018</span></a>)</cite>
</th>
<td id="S4.T2.1.1.5.2.2" class="ltx_td ltx_align_center">-</td>
<td id="S4.T2.1.1.5.2.3" class="ltx_td ltx_align_center">-</td>
<td id="S4.T2.1.1.5.2.4" class="ltx_td ltx_align_center">-</td>
<td id="S4.T2.1.1.5.2.5" class="ltx_td ltx_align_center ltx_border_r">64.9</td>
<td id="S4.T2.1.1.5.2.6" class="ltx_td ltx_align_center">-</td>
<td id="S4.T2.1.1.5.2.7" class="ltx_td ltx_align_center">-</td>
<td id="S4.T2.1.1.5.2.8" class="ltx_td ltx_align_center">-</td>
<td id="S4.T2.1.1.5.2.9" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S4.T2.1.1.6.3" class="ltx_tr">
<th id="S4.T2.1.1.6.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">ResonNet<cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:70%;">Ilievski and Feng</span> (<a href="#bib.bib14" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">2017</span></a>)</cite>
</th>
<td id="S4.T2.1.1.6.3.2" class="ltx_td ltx_align_center">-</td>
<td id="S4.T2.1.1.6.3.3" class="ltx_td ltx_align_center">-</td>
<td id="S4.T2.1.1.6.3.4" class="ltx_td ltx_align_center">-</td>
<td id="S4.T2.1.1.6.3.5" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S4.T2.1.1.6.3.6" class="ltx_td ltx_align_center">78.9</td>
<td id="S4.T2.1.1.6.3.7" class="ltx_td ltx_align_center">42.0</td>
<td id="S4.T2.1.1.6.3.8" class="ltx_td ltx_align_center">57.4</td>
<td id="S4.T2.1.1.6.3.9" class="ltx_td ltx_align_center">64.6</td>
</tr>
<tr id="S4.T2.1.1.7.4" class="ltx_tr">
<th id="S4.T2.1.1.7.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">MUTAN<cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:70%;">Ben-Younes etÂ al.</span> (<a href="#bib.bib5" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">2017</span></a>)</cite><span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>Performance on VQAv2 is evaluated from their publicly available repository.</span></span></span>
</th>
<td id="S4.T2.1.1.7.4.2" class="ltx_td ltx_align_center">80.7</td>
<td id="S4.T2.1.1.7.4.3" class="ltx_td ltx_align_center">39.4</td>
<td id="S4.T2.1.1.7.4.4" class="ltx_td ltx_align_center">53.7</td>
<td id="S4.T2.1.1.7.4.5" class="ltx_td ltx_align_center ltx_border_r">63.2</td>
<td id="S4.T2.1.1.7.4.6" class="ltx_td ltx_align_center">80.9</td>
<td id="S4.T2.1.1.7.4.7" class="ltx_td ltx_align_center">38.6</td>
<td id="S4.T2.1.1.7.4.8" class="ltx_td ltx_align_center">54.0</td>
<td id="S4.T2.1.1.7.4.9" class="ltx_td ltx_align_center">63.5</td>
</tr>
<tr id="S4.T2.1.1.8.5" class="ltx_tr">
<th id="S4.T2.1.1.8.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">MCB <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:70%;">Fukui etÂ al.</span> (<a href="#bib.bib10" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">2016</span></a>); <span class="ltx_text" style="font-size:70%;">Goyal etÂ al.</span> (<a href="#bib.bib12" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">2016</span></a>)</cite>
</th>
<td id="S4.T2.1.1.8.5.2" class="ltx_td ltx_align_center">-</td>
<td id="S4.T2.1.1.8.5.3" class="ltx_td ltx_align_center">-</td>
<td id="S4.T2.1.1.8.5.4" class="ltx_td ltx_align_center">-</td>
<td id="S4.T2.1.1.8.5.5" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S4.T2.1.1.8.5.6" class="ltx_td ltx_align_center">77.4</td>
<td id="S4.T2.1.1.8.5.7" class="ltx_td ltx_align_center">36.7</td>
<td id="S4.T2.1.1.8.5.8" class="ltx_td ltx_align_center">51.2</td>
<td id="S4.T2.1.1.8.5.9" class="ltx_td ltx_align_center">59.1</td>
</tr>
<tr id="S4.T2.1.1.9.6" class="ltx_tr">
<th id="S4.T2.1.1.9.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">HieCoAtt <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:70%;">Lu etÂ al.</span> (<a href="#bib.bib21" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">2016</span></a>); <span class="ltx_text" style="font-size:70%;">Goyal etÂ al.</span> (<a href="#bib.bib12" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">2016</span></a>)</cite>
</th>
<td id="S4.T2.1.1.9.6.2" class="ltx_td ltx_align_center">-</td>
<td id="S4.T2.1.1.9.6.3" class="ltx_td ltx_align_center">-</td>
<td id="S4.T2.1.1.9.6.4" class="ltx_td ltx_align_center">-</td>
<td id="S4.T2.1.1.9.6.5" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S4.T2.1.1.9.6.6" class="ltx_td ltx_align_center">71.8</td>
<td id="S4.T2.1.1.9.6.7" class="ltx_td ltx_align_center">36.5</td>
<td id="S4.T2.1.1.9.6.8" class="ltx_td ltx_align_center">46.3</td>
<td id="S4.T2.1.1.9.6.9" class="ltx_td ltx_align_center">54.6</td>
</tr>
<tr id="S4.T2.1.1.10.7" class="ltx_tr">
<th id="S4.T2.1.1.10.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Language only<cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:70%;">Goyal etÂ al.</span> (<a href="#bib.bib12" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">2016</span></a>)</cite>
</th>
<td id="S4.T2.1.1.10.7.2" class="ltx_td ltx_align_center">-</td>
<td id="S4.T2.1.1.10.7.3" class="ltx_td ltx_align_center">-</td>
<td id="S4.T2.1.1.10.7.4" class="ltx_td ltx_align_center">-</td>
<td id="S4.T2.1.1.10.7.5" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S4.T2.1.1.10.7.6" class="ltx_td ltx_align_center">67.1</td>
<td id="S4.T2.1.1.10.7.7" class="ltx_td ltx_align_center">31.6</td>
<td id="S4.T2.1.1.10.7.8" class="ltx_td ltx_align_center">27.4</td>
<td id="S4.T2.1.1.10.7.9" class="ltx_td ltx_align_center">44.3</td>
</tr>
<tr id="S4.T2.1.1.11.8" class="ltx_tr">
<th id="S4.T2.1.1.11.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r">Common answer<cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:70%;">Goyal etÂ al.</span> (<a href="#bib.bib12" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">2016</span></a>)</cite>
</th>
<td id="S4.T2.1.1.11.8.2" class="ltx_td ltx_align_center ltx_border_bb">-</td>
<td id="S4.T2.1.1.11.8.3" class="ltx_td ltx_align_center ltx_border_bb">-</td>
<td id="S4.T2.1.1.11.8.4" class="ltx_td ltx_align_center ltx_border_bb">-</td>
<td id="S4.T2.1.1.11.8.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">-</td>
<td id="S4.T2.1.1.11.8.6" class="ltx_td ltx_align_center ltx_border_bb">61.2</td>
<td id="S4.T2.1.1.11.8.7" class="ltx_td ltx_align_center ltx_border_bb">0.4</td>
<td id="S4.T2.1.1.11.8.8" class="ltx_td ltx_align_center ltx_border_bb">1.8</td>
<td id="S4.T2.1.1.11.8.9" class="ltx_td ltx_align_center ltx_border_bb">26.0</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Comparison of the state-of-the-art methods with our single model performance on VQAv2.0 test-dev and test-standard server.</figcaption>
</figure>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Results</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.2" class="ltx_p">We evaluate the proposed modelsâ€™ performance on the VQA test servers which ensures blind evaluation on the VQAv1 <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:70%;">Antol etÂ al.</span> (<a href="#bib.bib3" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">2015</span></a>)</cite> and v2 <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:70%;">Goyal etÂ al.</span> (<a href="#bib.bib12" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">2016</span></a>)</cite> test sets (i.e.Â test-dev, test-standard) following the VQA benchmark evaluation approach. The accuracy <math id="S5.p1.1.m1.1" class="ltx_Math" alttext="y" display="inline"><semantics id="S5.p1.1.m1.1a"><mi id="S5.p1.1.m1.1.1" xref="S5.p1.1.m1.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S5.p1.1.m1.1b"><ci id="S5.p1.1.m1.1.1.cmml" xref="S5.p1.1.m1.1.1">ğ‘¦</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.1.m1.1c">y</annotation></semantics></math> of the predicted answer <math id="S5.p1.2.m2.1" class="ltx_Math" alttext="\hat{a}" display="inline"><semantics id="S5.p1.2.m2.1a"><mover accent="true" id="S5.p1.2.m2.1.1" xref="S5.p1.2.m2.1.1.cmml"><mi id="S5.p1.2.m2.1.1.2" xref="S5.p1.2.m2.1.1.2.cmml">a</mi><mo id="S5.p1.2.m2.1.1.1" xref="S5.p1.2.m2.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S5.p1.2.m2.1b"><apply id="S5.p1.2.m2.1.1.cmml" xref="S5.p1.2.m2.1.1"><ci id="S5.p1.2.m2.1.1.1.cmml" xref="S5.p1.2.m2.1.1.1">^</ci><ci id="S5.p1.2.m2.1.1.2.cmml" xref="S5.p1.2.m2.1.1.2">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.2.m2.1c">\hat{a}</annotation></semantics></math> is calculated with the following formulation:</p>
<table id="S5.E7" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S5.E7.m1.2" class="ltx_Math" alttext="y=min\bigg{(}\frac{\#\;\text{of humans answered $\hat{a}$}}{3},1\bigg{)}" display="block"><semantics id="S5.E7.m1.2a"><mrow id="S5.E7.m1.2.3" xref="S5.E7.m1.2.3.cmml"><mi id="S5.E7.m1.2.3.2" xref="S5.E7.m1.2.3.2.cmml">y</mi><mo id="S5.E7.m1.2.3.1" xref="S5.E7.m1.2.3.1.cmml">=</mo><mrow id="S5.E7.m1.2.3.3" xref="S5.E7.m1.2.3.3.cmml"><mi id="S5.E7.m1.2.3.3.2" xref="S5.E7.m1.2.3.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S5.E7.m1.2.3.3.1" xref="S5.E7.m1.2.3.3.1.cmml">â€‹</mo><mi id="S5.E7.m1.2.3.3.3" xref="S5.E7.m1.2.3.3.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S5.E7.m1.2.3.3.1a" xref="S5.E7.m1.2.3.3.1.cmml">â€‹</mo><mi id="S5.E7.m1.2.3.3.4" xref="S5.E7.m1.2.3.3.4.cmml">n</mi><mo lspace="0em" rspace="0em" id="S5.E7.m1.2.3.3.1b" xref="S5.E7.m1.2.3.3.1.cmml">â€‹</mo><mrow id="S5.E7.m1.2.3.3.5.2" xref="S5.E7.m1.2.3.3.5.1.cmml"><mo maxsize="210%" minsize="210%" id="S5.E7.m1.2.3.3.5.2.1" xref="S5.E7.m1.2.3.3.5.1.cmml">(</mo><mfrac id="S5.E7.m1.1.1" xref="S5.E7.m1.1.1.cmml"><mrow id="S5.E7.m1.1.1.1" xref="S5.E7.m1.1.1.1.cmml"><mi mathvariant="normal" id="S5.E7.m1.1.1.1.3" xref="S5.E7.m1.1.1.1.3.cmml">#</mi><mo lspace="0.280em" rspace="0em" id="S5.E7.m1.1.1.1.2" xref="S5.E7.m1.1.1.1.2.cmml">â€‹</mo><mrow id="S5.E7.m1.1.1.1.1.1" xref="S5.E7.m1.1.1.1.1.1b.cmml"><mtext id="S5.E7.m1.1.1.1.1.1a" xref="S5.E7.m1.1.1.1.1.1b.cmml">of humans answeredÂ </mtext><mover accent="true" id="S5.E7.m1.1.1.1.1.1.m1.1.1" xref="S5.E7.m1.1.1.1.1.1.m1.1.1.cmml"><mi id="S5.E7.m1.1.1.1.1.1.m1.1.1.2" xref="S5.E7.m1.1.1.1.1.1.m1.1.1.2.cmml">a</mi><mo id="S5.E7.m1.1.1.1.1.1.m1.1.1.1" xref="S5.E7.m1.1.1.1.1.1.m1.1.1.1.cmml">^</mo></mover></mrow></mrow><mn id="S5.E7.m1.1.1.3" xref="S5.E7.m1.1.1.3.cmml">3</mn></mfrac><mo id="S5.E7.m1.2.3.3.5.2.2" xref="S5.E7.m1.2.3.3.5.1.cmml">,</mo><mn id="S5.E7.m1.2.2" xref="S5.E7.m1.2.2.cmml">1</mn><mo maxsize="210%" minsize="210%" id="S5.E7.m1.2.3.3.5.2.3" xref="S5.E7.m1.2.3.3.5.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.E7.m1.2b"><apply id="S5.E7.m1.2.3.cmml" xref="S5.E7.m1.2.3"><eq id="S5.E7.m1.2.3.1.cmml" xref="S5.E7.m1.2.3.1"></eq><ci id="S5.E7.m1.2.3.2.cmml" xref="S5.E7.m1.2.3.2">ğ‘¦</ci><apply id="S5.E7.m1.2.3.3.cmml" xref="S5.E7.m1.2.3.3"><times id="S5.E7.m1.2.3.3.1.cmml" xref="S5.E7.m1.2.3.3.1"></times><ci id="S5.E7.m1.2.3.3.2.cmml" xref="S5.E7.m1.2.3.3.2">ğ‘š</ci><ci id="S5.E7.m1.2.3.3.3.cmml" xref="S5.E7.m1.2.3.3.3">ğ‘–</ci><ci id="S5.E7.m1.2.3.3.4.cmml" xref="S5.E7.m1.2.3.3.4">ğ‘›</ci><interval closure="open" id="S5.E7.m1.2.3.3.5.1.cmml" xref="S5.E7.m1.2.3.3.5.2"><apply id="S5.E7.m1.1.1.cmml" xref="S5.E7.m1.1.1"><divide id="S5.E7.m1.1.1.2.cmml" xref="S5.E7.m1.1.1"></divide><apply id="S5.E7.m1.1.1.1.cmml" xref="S5.E7.m1.1.1.1"><times id="S5.E7.m1.1.1.1.2.cmml" xref="S5.E7.m1.1.1.1.2"></times><ci id="S5.E7.m1.1.1.1.3.cmml" xref="S5.E7.m1.1.1.1.3">#</ci><ci id="S5.E7.m1.1.1.1.1.1b.cmml" xref="S5.E7.m1.1.1.1.1.1"><mrow id="S5.E7.m1.1.1.1.1.1.cmml" xref="S5.E7.m1.1.1.1.1.1"><mtext id="S5.E7.m1.1.1.1.1.1a.cmml" xref="S5.E7.m1.1.1.1.1.1">of humans answeredÂ </mtext><mover accent="true" id="S5.E7.m1.1.1.1.1.1.m1.1.1.cmml" xref="S5.E7.m1.1.1.1.1.1.m1.1.1"><mi id="S5.E7.m1.1.1.1.1.1.m1.1.1.2.cmml" xref="S5.E7.m1.1.1.1.1.1.m1.1.1.2">a</mi><mo id="S5.E7.m1.1.1.1.1.1.m1.1.1.1.cmml" xref="S5.E7.m1.1.1.1.1.1.m1.1.1.1">^</mo></mover></mrow></ci></apply><cn type="integer" id="S5.E7.m1.1.1.3.cmml" xref="S5.E7.m1.1.1.3">3</cn></apply><cn type="integer" id="S5.E7.m1.2.2.cmml" xref="S5.E7.m1.2.2">1</cn></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.E7.m1.2c">y=min\bigg{(}\frac{\#\;\text{of humans answered $\hat{a}$}}{3},1\bigg{)}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(7)</span></td>
</tr></tbody>
</table>
<p id="S5.p1.3" class="ltx_p">which means that answer provided by the model is given 100% accuracy if at least 3 human annotators who helped create the VQA dataset gave the exact answer.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.7" class="ltx_p">In Table <a href="#S3.T1" title="Table 1 â€£ 3.3 Co-attention Fusion â€£ 3 Methods â€£ Reciprocal Attention Fusion for Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, we report VQAv1 test-dev and test-standard accuracies for our proposed RAF model and compare it with other single models found in literature. Remarkably, our model outperforms all other models in the overall accuracy. We report a significant performance boost of <math id="S5.p2.1.m1.1" class="ltx_Math" alttext="1.2\%" display="inline"><semantics id="S5.p2.1.m1.1a"><mrow id="S5.p2.1.m1.1.1" xref="S5.p2.1.m1.1.1.cmml"><mn id="S5.p2.1.m1.1.1.2" xref="S5.p2.1.m1.1.1.2.cmml">1.2</mn><mo id="S5.p2.1.m1.1.1.1" xref="S5.p2.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.p2.1.m1.1b"><apply id="S5.p2.1.m1.1.1.cmml" xref="S5.p2.1.m1.1.1"><csymbol cd="latexml" id="S5.p2.1.m1.1.1.1.cmml" xref="S5.p2.1.m1.1.1.1">percent</csymbol><cn type="float" id="S5.p2.1.m1.1.1.2.cmml" xref="S5.p2.1.m1.1.1.2">1.2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.1.m1.1c">1.2\%</annotation></semantics></math> on the test-dev set and <math id="S5.p2.2.m2.1" class="ltx_Math" alttext="0.3\%" display="inline"><semantics id="S5.p2.2.m2.1a"><mrow id="S5.p2.2.m2.1.1" xref="S5.p2.2.m2.1.1.cmml"><mn id="S5.p2.2.m2.1.1.2" xref="S5.p2.2.m2.1.1.2.cmml">0.3</mn><mo id="S5.p2.2.m2.1.1.1" xref="S5.p2.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.p2.2.m2.1b"><apply id="S5.p2.2.m2.1.1.cmml" xref="S5.p2.2.m2.1.1"><csymbol cd="latexml" id="S5.p2.2.m2.1.1.1.cmml" xref="S5.p2.2.m2.1.1.1">percent</csymbol><cn type="float" id="S5.p2.2.m2.1.1.2.cmml" xref="S5.p2.2.m2.1.1.2">0.3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.2.m2.1c">0.3\%</annotation></semantics></math> on the test-standard set. It is to be noted that using multiple ensembles and data augmentation with complementary training in Visual Genome QA pairs can increase the accuracy performance of the VQA models. For instance, MCB <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:70%;">Fukui etÂ al.</span> (<a href="#bib.bib10" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">2016</span></a>)</cite>, MLB <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:70%;">Kim etÂ al.</span> (<a href="#bib.bib17" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">2016</span></a>)</cite>, MUTAN <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:70%;">Ben-Younes etÂ al.</span> (<a href="#bib.bib5" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">2017</span></a>)</cite> and MFB <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:70%;">Yu etÂ al.</span> (<a href="#bib.bib37" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">2018</span></a>)</cite> employ similar model ensemble consisting of 7,7,5 and 7 models respectively, and report overall <math id="S5.p2.3.m3.1" class="ltx_Math" alttext="66.5" display="inline"><semantics id="S5.p2.3.m3.1a"><mn id="S5.p2.3.m3.1.1" xref="S5.p2.3.m3.1.1.cmml">66.5</mn><annotation-xml encoding="MathML-Content" id="S5.p2.3.m3.1b"><cn type="float" id="S5.p2.3.m3.1.1.cmml" xref="S5.p2.3.m3.1.1">66.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.3.m3.1c">66.5</annotation></semantics></math>, <math id="S5.p2.4.m4.1" class="ltx_Math" alttext="66.9" display="inline"><semantics id="S5.p2.4.m4.1a"><mn id="S5.p2.4.m4.1.1" xref="S5.p2.4.m4.1.1.cmml">66.9</mn><annotation-xml encoding="MathML-Content" id="S5.p2.4.m4.1b"><cn type="float" id="S5.p2.4.m4.1.1.cmml" xref="S5.p2.4.m4.1.1">66.9</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.4.m4.1c">66.9</annotation></semantics></math>, <math id="S5.p2.5.m5.1" class="ltx_Math" alttext="67.4" display="inline"><semantics id="S5.p2.5.m5.1a"><mn id="S5.p2.5.m5.1.1" xref="S5.p2.5.m5.1.1.cmml">67.4</mn><annotation-xml encoding="MathML-Content" id="S5.p2.5.m5.1b"><cn type="float" id="S5.p2.5.m5.1.1.cmml" xref="S5.p2.5.m5.1.1">67.4</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.5.m5.1c">67.4</annotation></semantics></math> and <math id="S5.p2.6.m6.1" class="ltx_Math" alttext="69.2" display="inline"><semantics id="S5.p2.6.m6.1a"><mn id="S5.p2.6.m6.1.1" xref="S5.p2.6.m6.1.1.cmml">69.2</mn><annotation-xml encoding="MathML-Content" id="S5.p2.6.m6.1b"><cn type="float" id="S5.p2.6.m6.1.1.cmml" xref="S5.p2.6.m6.1.1">69.2</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.6.m6.1c">69.2</annotation></semantics></math> on the test-standard set. It is interesting to note that except for MFB (7) all other ensemble models are <math id="S5.p2.7.m7.1" class="ltx_Math" alttext="\sim 1\%" display="inline"><semantics id="S5.p2.7.m7.1a"><mrow id="S5.p2.7.m7.1.1" xref="S5.p2.7.m7.1.1.cmml"><mi id="S5.p2.7.m7.1.1.2" xref="S5.p2.7.m7.1.1.2.cmml"></mi><mo id="S5.p2.7.m7.1.1.1" xref="S5.p2.7.m7.1.1.1.cmml">âˆ¼</mo><mrow id="S5.p2.7.m7.1.1.3" xref="S5.p2.7.m7.1.1.3.cmml"><mn id="S5.p2.7.m7.1.1.3.2" xref="S5.p2.7.m7.1.1.3.2.cmml">1</mn><mo id="S5.p2.7.m7.1.1.3.1" xref="S5.p2.7.m7.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.p2.7.m7.1b"><apply id="S5.p2.7.m7.1.1.cmml" xref="S5.p2.7.m7.1.1"><csymbol cd="latexml" id="S5.p2.7.m7.1.1.1.cmml" xref="S5.p2.7.m7.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="S5.p2.7.m7.1.1.2.cmml" xref="S5.p2.7.m7.1.1.2">absent</csymbol><apply id="S5.p2.7.m7.1.1.3.cmml" xref="S5.p2.7.m7.1.1.3"><csymbol cd="latexml" id="S5.p2.7.m7.1.1.3.1.cmml" xref="S5.p2.7.m7.1.1.3.1">percent</csymbol><cn type="integer" id="S5.p2.7.m7.1.1.3.2.cmml" xref="S5.p2.7.m7.1.1.3.2">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.7.m7.1c">\sim 1\%</annotation></semantics></math> less than our reported single model performance. We do not ensemble our model or use data augmentation with complementary dataset as it makes the best results irreproducible and most of the models in the literature do not adopt this strategy.</p>
</div>
<div id="S5.p3" class="ltx_para">
<p id="S5.p3.1" class="ltx_p">We also evaluate our model on VQAv2 test-standard dataset and compare it with state-of-the-art single model performance in Table <a href="#S4.T2" title="Table 2 â€£ 4.2 VQA Model Architecture â€£ 4 Experiments â€£ Reciprocal Attention Fusion for Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, illustrating that our model surpasses the closest method <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:70%;">Teney etÂ al.</span> (<a href="#bib.bib29" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">2017</span></a>)</cite> in all question categories and overall by a significant margin of <math id="S5.p3.1.m1.1" class="ltx_Math" alttext="1.7\%" display="inline"><semantics id="S5.p3.1.m1.1a"><mrow id="S5.p3.1.m1.1.1" xref="S5.p3.1.m1.1.1.cmml"><mn id="S5.p3.1.m1.1.1.2" xref="S5.p3.1.m1.1.1.2.cmml">1.7</mn><mo id="S5.p3.1.m1.1.1.1" xref="S5.p3.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.p3.1.m1.1b"><apply id="S5.p3.1.m1.1.1.cmml" xref="S5.p3.1.m1.1.1"><csymbol cd="latexml" id="S5.p3.1.m1.1.1.1.cmml" xref="S5.p3.1.m1.1.1.1">percent</csymbol><cn type="float" id="S5.p3.1.m1.1.1.2.cmml" xref="S5.p3.1.m1.1.1.2">1.7</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p3.1.m1.1c">1.7\%</annotation></semantics></math>. The bottom up, adaptive-k<cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:70%;">Teney etÂ al.</span> (<a href="#bib.bib29" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">2017</span></a>)</cite> is the same model whose 30-ensemble version <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:70%;">Anderson etÂ al.</span> (<a href="#bib.bib1" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">2018</span></a>)</cite> reports currently the best performance among on VQAv2 test-standard dataset. This indicates our models superior capability to interpret and incorporate multi-modal relationships for visual reasoning.</p>
</div>
<div id="S5.p4" class="ltx_para">
<p id="S5.p4.1" class="ltx_p">In summary, our model achieves state-of-the-art performance on both VQAv1 and VQAv2 dataset which affirms the robustness of our model against language bias without the need of data augmentation or the use of ensemble model. We also show qualitative results in Fig.Â <a href="#S5.F4" title="Figure 4 â€£ 5.1 Ablation Study â€£ 5 Results â€£ Reciprocal Attention Fusion for Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> to demonstrate the efficacy and complimentary nature of attention focused on image-grid and object proposals.</p>
</div>
<figure id="S5.T3" class="ltx_table">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S5.T3.fig1" class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" style="width:216.8pt;">
<div id="S5.T3.fig1.1" class="ltx_inline-block ltx_transformed_outer" style="width:396.8pt;height:162pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-22.0pt,9.0pt) scale(0.9,0.9) ;">
<table id="S5.T3.fig1.1.1" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S5.T3.fig1.1.1.1.1" class="ltx_tr">
<td id="S5.T3.fig1.1.1.1.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt">Cat.</td>
<td id="S5.T3.fig1.1.1.1.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt">Methods</td>
<td id="S5.T3.fig1.1.1.1.1.3" class="ltx_td ltx_align_center ltx_border_tt">Val-set</td>
</tr>
<tr id="S5.T3.fig1.1.1.2.2" class="ltx_tr">
<td id="S5.T3.fig1.1.1.2.2.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">I</td>
<td id="S5.T3.fig1.1.1.2.2.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">RAF-I(ResNet)</td>
<td id="S5.T3.fig1.1.1.2.2.3" class="ltx_td ltx_align_center ltx_border_t">53.9</td>
</tr>
<tr id="S5.T3.fig1.1.1.3.3" class="ltx_tr">
<td id="S5.T3.fig1.1.1.3.3.1" class="ltx_td ltx_border_r"></td>
<td id="S5.T3.fig1.1.1.3.3.2" class="ltx_td ltx_align_left ltx_border_r">HieCoAtt <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:70%;">Lu etÂ al.</span> (<a href="#bib.bib21" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">2016</span></a>); <span class="ltx_text" style="font-size:70%;">Goyal etÂ al.</span> (<a href="#bib.bib12" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">2016</span></a>)</cite>
</td>
<td id="S5.T3.fig1.1.1.3.3.3" class="ltx_td ltx_align_center">54.6</td>
</tr>
<tr id="S5.T3.fig1.1.1.4.4" class="ltx_tr">
<td id="S5.T3.fig1.1.1.4.4.1" class="ltx_td ltx_border_r"></td>
<td id="S5.T3.fig1.1.1.4.4.2" class="ltx_td ltx_align_left ltx_border_r">RAF-I(ResNeXt)</td>
<td id="S5.T3.fig1.1.1.4.4.3" class="ltx_td ltx_align_center">58.0</td>
</tr>
<tr id="S5.T3.fig1.1.1.5.5" class="ltx_tr">
<td id="S5.T3.fig1.1.1.5.5.1" class="ltx_td ltx_border_r"></td>
<td id="S5.T3.fig1.1.1.5.5.2" class="ltx_td ltx_align_left ltx_border_r">MCB <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:70%;">Fukui etÂ al.</span> (<a href="#bib.bib10" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">2016</span></a>); <span class="ltx_text" style="font-size:70%;">Goyal etÂ al.</span> (<a href="#bib.bib12" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">2016</span></a>)</cite>
</td>
<td id="S5.T3.fig1.1.1.5.5.3" class="ltx_td ltx_align_center">59.1</td>
</tr>
<tr id="S5.T3.fig1.1.1.6.6" class="ltx_tr">
<td id="S5.T3.fig1.1.1.6.6.1" class="ltx_td ltx_border_r"></td>
<td id="S5.T3.fig1.1.1.6.6.2" class="ltx_td ltx_align_left ltx_border_r">MUTAN <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:70%;">Ben-Younes etÂ al.</span> (<a href="#bib.bib5" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">2017</span></a>)</cite>
</td>
<td id="S5.T3.fig1.1.1.6.6.3" class="ltx_td ltx_align_center">60.1</td>
</tr>
<tr id="S5.T3.fig1.1.1.7.7" class="ltx_tr">
<td id="S5.T3.fig1.1.1.7.7.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">II</td>
<td id="S5.T3.fig1.1.1.7.7.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Up-Down<cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:70%;">Anderson etÂ al.</span> (<a href="#bib.bib1" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">2018</span></a>)</cite>
</td>
<td id="S5.T3.fig1.1.1.7.7.3" class="ltx_td ltx_align_center ltx_border_t">63.2</td>
</tr>
<tr id="S5.T3.fig1.1.1.8.8" class="ltx_tr">
<td id="S5.T3.fig1.1.1.8.8.1" class="ltx_td ltx_border_r"></td>
<td id="S5.T3.fig1.1.1.8.8.2" class="ltx_td ltx_align_left ltx_border_r">RAF-O(ResNet)</td>
<td id="S5.T3.fig1.1.1.8.8.3" class="ltx_td ltx_align_center">63.9</td>
</tr>
<tr id="S5.T3.fig1.1.1.9.9" class="ltx_tr">
<td id="S5.T3.fig1.1.1.9.9.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">III</td>
<td id="S5.T3.fig1.1.1.9.9.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">RAF-IO(ResNet-ResNet)</td>
<td id="S5.T3.fig1.1.1.9.9.3" class="ltx_td ltx_align_center ltx_border_t">64.0</td>
</tr>
<tr id="S5.T3.fig1.1.1.10.10" class="ltx_tr">
<td id="S5.T3.fig1.1.1.10.10.1" class="ltx_td ltx_border_bb ltx_border_r"></td>
<td id="S5.T3.fig1.1.1.10.10.2" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">RAF-IO(ResNeXt-ResNet)</td>
<td id="S5.T3.fig1.1.1.10.10.3" class="ltx_td ltx_align_center ltx_border_bb">64.2</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Table 3: </span>Ablation Study on VQAv2 val-set.</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S5.F3" class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" style="width:195.1pt;"><img src="/html/1805.04247/assets/x3.png" id="S5.F3.g1" class="ltx_graphics ltx_img_landscape" width="461" height="279" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Accuracy vs.Â Complexity (no. of parameters) comparison.</figcaption>
</figure>
</div>
</div>
</figure>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Ablation Study</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">We perform an extensive ablation study of the proposed model on VQAv2 <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:70%;">Goyal etÂ al.</span> (<a href="#bib.bib12" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">2016</span></a>)</cite> validation dataset and compare it with the best performing model in Table <a href="#S5.T3" title="Table 3 â€£ 5 Results â€£ Reciprocal Attention Fusion for Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. This ablation study helps to better understand the contribution of different components of our model towards the overall performance on the VQA task. The objective of this ablation study is to show that when the language features are combined with image- grid and object level visual features, the accuracy of the high level visual reasoning task (i.e.Â VQA) increases in contrast to only combining language with image or object level features. The models reported in Category I in Table <a href="#S5.T3" title="Table 3 â€£ 5 Results â€£ Reciprocal Attention Fusion for Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> use only image level features extracted with deep CNNs and we compare RAF-I which is a variant of our proposed RAF architecture only using image level features. We observe RAF-I achieve comparable performance in this category. In Category II, RAF-O model extracts only <math id="S5.SS1.p1.1.m1.1" class="ltx_Math" alttext="36" display="inline"><semantics id="S5.SS1.p1.1.m1.1a"><mn id="S5.SS1.p1.1.m1.1.1" xref="S5.SS1.p1.1.m1.1.1.cmml">36</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.1.m1.1b"><cn type="integer" id="S5.SS1.p1.1.m1.1.1.cmml" xref="S5.SS1.p1.1.m1.1.1">36</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.1.m1.1c">36</annotation></semantics></math> object level features but outperforms the models in Category I. <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:70%;">Anderson etÂ al.</span> (<a href="#bib.bib1" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">2018</span></a>)</cite> also used only object level features and this variant of our model achieves comparable performance to that model. When we combine image and object level features together in Category III, we observe that the best results are obtained. This proves our hypothesis that the questions relate to both objects, object parts and local attributes, which should be attended for jointly an improved VQA performance.</p>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<p id="S5.SS1.p2.1" class="ltx_p">The recent Dual-MFA <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:70%;">Lu etÂ al.</span> (<a href="#bib.bib22" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">2017</span></a>)</cite> model also uses complementary image and object-level features. In contrast, our model uses more efficient bimodal attention fusion mechanism and exhibit robustness on balanced VQAv2 <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:70%;">Goyal etÂ al.</span> (<a href="#bib.bib12" title="" class="ltx_ref"><span class="ltx_text" style="font-size:70%;">2016</span></a>)</cite> dataset. We also study the accuracy vs.Â complexity (no. of parameters) trade off in Fig. <a href="#S5.F3" title="Figure 3 â€£ Table 3 â€£ 5 Results â€£ Reciprocal Attention Fusion for Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> on VQAv1 test-dev set as most of the bilinear models do not report performance on VQAv2. Remarkably, our RAF model achieves significant performance boost over Dual-MFA (66% to 68%) with around half the complexity.</p>
</div>
<figure id="S5.F4" class="ltx_figure"><img src="/html/1805.04247/assets/x4.png" id="S5.F4.1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="437" height="458" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Qualitative results of the proposed Reciprocal Attention Fusion mechanism for Visual Question Answering. Given a question and an image (columns: <math id="S5.F4.7.m1.2" class="ltx_Math" alttext="1,4" display="inline"><semantics id="S5.F4.7.m1.2b"><mrow id="S5.F4.7.m1.2.3.2" xref="S5.F4.7.m1.2.3.1.cmml"><mn id="S5.F4.7.m1.1.1" xref="S5.F4.7.m1.1.1.cmml">1</mn><mo id="S5.F4.7.m1.2.3.2.1" xref="S5.F4.7.m1.2.3.1.cmml">,</mo><mn id="S5.F4.7.m1.2.2" xref="S5.F4.7.m1.2.2.cmml">4</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.F4.7.m1.2c"><list id="S5.F4.7.m1.2.3.1.cmml" xref="S5.F4.7.m1.2.3.2"><cn type="integer" id="S5.F4.7.m1.1.1.cmml" xref="S5.F4.7.m1.1.1">1</cn><cn type="integer" id="S5.F4.7.m1.2.2.cmml" xref="S5.F4.7.m1.2.2">4</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S5.F4.7.m1.2d">1,4</annotation></semantics></math>), attention based on image-grid (columns: <math id="S5.F4.8.m2.2" class="ltx_Math" alttext="2,5" display="inline"><semantics id="S5.F4.8.m2.2b"><mrow id="S5.F4.8.m2.2.3.2" xref="S5.F4.8.m2.2.3.1.cmml"><mn id="S5.F4.8.m2.1.1" xref="S5.F4.8.m2.1.1.cmml">2</mn><mo id="S5.F4.8.m2.2.3.2.1" xref="S5.F4.8.m2.2.3.1.cmml">,</mo><mn id="S5.F4.8.m2.2.2" xref="S5.F4.8.m2.2.2.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.F4.8.m2.2c"><list id="S5.F4.8.m2.2.3.1.cmml" xref="S5.F4.8.m2.2.3.2"><cn type="integer" id="S5.F4.8.m2.1.1.cmml" xref="S5.F4.8.m2.1.1">2</cn><cn type="integer" id="S5.F4.8.m2.2.2.cmml" xref="S5.F4.8.m2.2.2">5</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S5.F4.8.m2.2d">2,5</annotation></semantics></math>) and object proposals (columns: <math id="S5.F4.9.m3.2" class="ltx_Math" alttext="3,6" display="inline"><semantics id="S5.F4.9.m3.2b"><mrow id="S5.F4.9.m3.2.3.2" xref="S5.F4.9.m3.2.3.1.cmml"><mn id="S5.F4.9.m3.1.1" xref="S5.F4.9.m3.1.1.cmml">3</mn><mo id="S5.F4.9.m3.2.3.2.1" xref="S5.F4.9.m3.2.3.1.cmml">,</mo><mn id="S5.F4.9.m3.2.2" xref="S5.F4.9.m3.2.2.cmml">6</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.F4.9.m3.2c"><list id="S5.F4.9.m3.2.3.1.cmml" xref="S5.F4.9.m3.2.3.2"><cn type="integer" id="S5.F4.9.m3.1.1.cmml" xref="S5.F4.9.m3.1.1">3</cn><cn type="integer" id="S5.F4.9.m3.2.2.cmml" xref="S5.F4.9.m3.2.2">6</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S5.F4.9.m3.2d">3,6</annotation></semantics></math>) is shown above. Correct and incorrect answers are shown in <span id="S5.F4.14.1" class="ltx_text" style="color:#00FF00;">green</span> and <span id="S5.F4.15.2" class="ltx_text" style="color:#FF0000;">red</span>, respectively. Remarkably, the two attention levels provide complementary information about localized regions and objects that in turn help in obtaining the correct answer (rows: <math id="S5.F4.10.m4.4" class="ltx_Math" alttext="1,2,3,4" display="inline"><semantics id="S5.F4.10.m4.4b"><mrow id="S5.F4.10.m4.4.5.2" xref="S5.F4.10.m4.4.5.1.cmml"><mn id="S5.F4.10.m4.1.1" xref="S5.F4.10.m4.1.1.cmml">1</mn><mo id="S5.F4.10.m4.4.5.2.1" xref="S5.F4.10.m4.4.5.1.cmml">,</mo><mn id="S5.F4.10.m4.2.2" xref="S5.F4.10.m4.2.2.cmml">2</mn><mo id="S5.F4.10.m4.4.5.2.2" xref="S5.F4.10.m4.4.5.1.cmml">,</mo><mn id="S5.F4.10.m4.3.3" xref="S5.F4.10.m4.3.3.cmml">3</mn><mo id="S5.F4.10.m4.4.5.2.3" xref="S5.F4.10.m4.4.5.1.cmml">,</mo><mn id="S5.F4.10.m4.4.4" xref="S5.F4.10.m4.4.4.cmml">4</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.F4.10.m4.4c"><list id="S5.F4.10.m4.4.5.1.cmml" xref="S5.F4.10.m4.4.5.2"><cn type="integer" id="S5.F4.10.m4.1.1.cmml" xref="S5.F4.10.m4.1.1">1</cn><cn type="integer" id="S5.F4.10.m4.2.2.cmml" xref="S5.F4.10.m4.2.2">2</cn><cn type="integer" id="S5.F4.10.m4.3.3.cmml" xref="S5.F4.10.m4.3.3">3</cn><cn type="integer" id="S5.F4.10.m4.4.4.cmml" xref="S5.F4.10.m4.4.4">4</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S5.F4.10.m4.4d">1,2,3,4</annotation></semantics></math>). In some failure cases of our technique, ambiguous attention maps lead to incorrect predictions (row: <math id="S5.F4.11.m5.1" class="ltx_Math" alttext="5" display="inline"><semantics id="S5.F4.11.m5.1b"><mn id="S5.F4.11.m5.1.1" xref="S5.F4.11.m5.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="S5.F4.11.m5.1c"><cn type="integer" id="S5.F4.11.m5.1.1.cmml" xref="S5.F4.11.m5.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.F4.11.m5.1d">5</annotation></semantics></math>).</figcaption>
</figure>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">We build our proposed model based on the hypotheses that multi-level visual features and associated attention can provide an AI agent additional information pertinent for deep visual understanding. As VQA is a standard measure of image understanding and visual reasoning, we propose a VQA model that learns to capture the bimodal feature representation from visual and language domain. To this end, we employ state of the art CNN architectures to obtain visual features for local regions on the image-grid and object proposals. Based on these feature encodings, we develop a hierarchical co-attention scheme that learns the mutual relationships between objects, object-parts and given questions to predict the best response. We validate our hypotheses by evaluating the proposed model on two large scale VQA dataset servers followed by an extensive ablation study reporting state-of-the art performance.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgements</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">The authors would like to thank CSIRO Scientific Computing team, especially Peter Campbell and Ondrej Hlinka, for their assistance in optimizing the work-flow on GPU clusters.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:70%;">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib1.5.5.1" class="ltx_text" style="font-size:70%;">Anderson etÂ al. (2018)</span></span>
<span class="ltx_bibblock"><span id="bib.bib1.7.1" class="ltx_text" style="font-size:70%;">
Peter Anderson, Xiaodong He, Chris Buehler, Damien Teney, Mark Johnson, Stephen
Gould, and Lei Zhang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.8.1" class="ltx_text" style="font-size:70%;">Bottom-up and top-down attention for image captioning and visual
question answering.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.9.1" class="ltx_text" style="font-size:70%;">In </span><em id="bib.bib1.10.2" class="ltx_emph ltx_font_italic" style="font-size:70%;">CVPR</em><span id="bib.bib1.11.3" class="ltx_text" style="font-size:70%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib2.5.5.1" class="ltx_text" style="font-size:70%;">Andreas etÂ al. (2016)</span></span>
<span class="ltx_bibblock"><span id="bib.bib2.7.1" class="ltx_text" style="font-size:70%;">
Jacob Andreas, Marcus Rohrbach, Trevor Darrell, and Dan Klein.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.8.1" class="ltx_text" style="font-size:70%;">Neural module networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.9.1" class="ltx_text" style="font-size:70%;">In </span><em id="bib.bib2.10.2" class="ltx_emph ltx_font_italic" style="font-size:70%;">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition</em><span id="bib.bib2.11.3" class="ltx_text" style="font-size:70%;">, pages 39â€“48, 2016.
</span>
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib3.5.5.1" class="ltx_text" style="font-size:70%;">Antol etÂ al. (2015)</span></span>
<span class="ltx_bibblock"><span id="bib.bib3.7.1" class="ltx_text" style="font-size:70%;">
Stanislaw Antol, Aishwarya Agrawal, Jiasen Lu, Margaret Mitchell, Dhruv Batra,
CÂ LawrenceÂ Zitnick, and Devi Parikh.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.8.1" class="ltx_text" style="font-size:70%;">Vqa: Visual question answering.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.9.1" class="ltx_text" style="font-size:70%;">In </span><em id="bib.bib3.10.2" class="ltx_emph ltx_font_italic" style="font-size:70%;">Proceedings of the IEEE International Conference on Computer
Vision</em><span id="bib.bib3.11.3" class="ltx_text" style="font-size:70%;">, pages 2425â€“2433, 2015.
</span>
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib4.4.4.1" class="ltx_text" style="font-size:70%;">Bader and Kolda (2007)</span></span>
<span class="ltx_bibblock"><span id="bib.bib4.6.1" class="ltx_text" style="font-size:70%;">
BrettÂ W Bader and TamaraÂ G Kolda.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.7.1" class="ltx_text" style="font-size:70%;">Efficient matlab computations with sparse and factored tensors.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib4.8.1" class="ltx_emph ltx_font_italic" style="font-size:70%;">SIAM Journal on Scientific Computing</em><span id="bib.bib4.9.2" class="ltx_text" style="font-size:70%;">, 30(1):205â€“231, 2007.
</span>
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib5.5.5.1" class="ltx_text" style="font-size:70%;">Ben-Younes etÂ al. (2017)</span></span>
<span class="ltx_bibblock"><span id="bib.bib5.7.1" class="ltx_text" style="font-size:70%;">
Hedi Ben-Younes, RÃ©mi CadÃ¨ne, Nicolas Thome, and Matthieu Cord.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.8.1" class="ltx_text" style="font-size:70%;">Mutan: Multimodal tucker fusion for visual question answering.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib5.9.1" class="ltx_emph ltx_font_italic" style="font-size:70%;">ICCV</em><span id="bib.bib5.10.2" class="ltx_text" style="font-size:70%;">, 2017.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.11.1" class="ltx_text" style="font-size:70%;">URL </span><a target="_blank" href="http://arxiv.org/abs/1705.06676" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:70%;">http://arxiv.org/abs/1705.06676</a><span id="bib.bib5.12.2" class="ltx_text" style="font-size:70%;">.
</span>
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib6.4.4.1" class="ltx_text" style="font-size:70%;">Borji and Itti (2013)</span></span>
<span class="ltx_bibblock"><span id="bib.bib6.6.1" class="ltx_text" style="font-size:70%;">
Ali Borji and Laurent Itti.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.7.1" class="ltx_text" style="font-size:70%;">State-of-the-art in visual attention modeling.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib6.8.1" class="ltx_emph ltx_font_italic" style="font-size:70%;">IEEE transactions on pattern analysis and machine
intelligence</em><span id="bib.bib6.9.2" class="ltx_text" style="font-size:70%;">, 35(1):185â€“207, 2013.
</span>
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib7.5.5.1" class="ltx_text" style="font-size:70%;">Cho etÂ al. (2014)</span></span>
<span class="ltx_bibblock"><span id="bib.bib7.7.1" class="ltx_text" style="font-size:70%;">
Kyunghyun Cho, Bart VanÂ MerriÃ«nboer, Dzmitry Bahdanau, and Yoshua Bengio.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.8.1" class="ltx_text" style="font-size:70%;">On the properties of neural machine translation: Encoder-decoder
approaches.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib7.9.1" class="ltx_emph ltx_font_italic" style="font-size:70%;">arXiv preprint arXiv:1409.1259</em><span id="bib.bib7.10.2" class="ltx_text" style="font-size:70%;">, 2014.
</span>
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib8.5.5.1" class="ltx_text" style="font-size:70%;">Deng etÂ al. (2009)</span></span>
<span class="ltx_bibblock"><span id="bib.bib8.7.1" class="ltx_text" style="font-size:70%;">
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and LiÂ Fei-Fei.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.8.1" class="ltx_text" style="font-size:70%;">Imagenet: A large-scale hierarchical image database.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.9.1" class="ltx_text" style="font-size:70%;">In </span><em id="bib.bib8.10.2" class="ltx_emph ltx_font_italic" style="font-size:70%;">Computer Vision and Pattern Recognition, 2009. CVPR 2009.
IEEE Conference on</em><span id="bib.bib8.11.3" class="ltx_text" style="font-size:70%;">, pages 248â€“255. IEEE, 2009.
</span>
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib9.4.4.1" class="ltx_text" style="font-size:70%;">Desimone and Duncan (1995)</span></span>
<span class="ltx_bibblock"><span id="bib.bib9.6.1" class="ltx_text" style="font-size:70%;">
Robert Desimone and John Duncan.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.7.1" class="ltx_text" style="font-size:70%;">Neural mechanisms of selective visual attention.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib9.8.1" class="ltx_emph ltx_font_italic" style="font-size:70%;">Annual review of neuroscience</em><span id="bib.bib9.9.2" class="ltx_text" style="font-size:70%;">, 18(1):193â€“222, 1995.
</span>
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib10.5.5.1" class="ltx_text" style="font-size:70%;">Fukui etÂ al. (2016)</span></span>
<span class="ltx_bibblock"><span id="bib.bib10.7.1" class="ltx_text" style="font-size:70%;">
Akira Fukui, DongÂ Huk Park, Daylen Yang, Anna Rohrbach, Trevor Darrell, and
Marcus Rohrbach.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.8.1" class="ltx_text" style="font-size:70%;">Multimodal compact bilinear pooling for visual question answering and
visual grounding.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib10.9.1" class="ltx_emph ltx_font_italic" style="font-size:70%;">arXiv preprint arXiv:1606.01847</em><span id="bib.bib10.10.2" class="ltx_text" style="font-size:70%;">, 2016.
</span>
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib11.5.5.1" class="ltx_text" style="font-size:70%;">Gao etÂ al. (2016)</span></span>
<span class="ltx_bibblock"><span id="bib.bib11.7.1" class="ltx_text" style="font-size:70%;">
Yang Gao, Oscar Beijbom, Ning Zhang, and Trevor Darrell.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.8.1" class="ltx_text" style="font-size:70%;">Compact bilinear pooling.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.9.1" class="ltx_text" style="font-size:70%;">In </span><em id="bib.bib11.10.2" class="ltx_emph ltx_font_italic" style="font-size:70%;">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition</em><span id="bib.bib11.11.3" class="ltx_text" style="font-size:70%;">, pages 317â€“326, 2016.
</span>
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib12.5.5.1" class="ltx_text" style="font-size:70%;">Goyal etÂ al. (2016)</span></span>
<span class="ltx_bibblock"><span id="bib.bib12.7.1" class="ltx_text" style="font-size:70%;">
Yash Goyal, Tejas Khot, Douglas Summers-Stay, Dhruv Batra, and Devi Parikh.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.8.1" class="ltx_text" style="font-size:70%;">Making the v in vqa matter: Elevating the role of image understanding
in visual question answering.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib12.9.1" class="ltx_emph ltx_font_italic" style="font-size:70%;">arXiv preprint arXiv:1612.00837</em><span id="bib.bib12.10.2" class="ltx_text" style="font-size:70%;">, 2016.
</span>
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib13.5.5.1" class="ltx_text" style="font-size:70%;">He etÂ al. (2016)</span></span>
<span class="ltx_bibblock"><span id="bib.bib13.7.1" class="ltx_text" style="font-size:70%;">
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.8.1" class="ltx_text" style="font-size:70%;">Deep residual learning for image recognition.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.9.1" class="ltx_text" style="font-size:70%;">In </span><em id="bib.bib13.10.2" class="ltx_emph ltx_font_italic" style="font-size:70%;">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition</em><span id="bib.bib13.11.3" class="ltx_text" style="font-size:70%;">, pages 770â€“778, 2016.
</span>
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib14.4.4.1" class="ltx_text" style="font-size:70%;">Ilievski and Feng (2017)</span></span>
<span class="ltx_bibblock"><span id="bib.bib14.6.1" class="ltx_text" style="font-size:70%;">
Ilija Ilievski and Jiashi Feng.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.7.1" class="ltx_text" style="font-size:70%;">Multimodal learning and reasoning for visual question answering.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.8.1" class="ltx_text" style="font-size:70%;">In </span><em id="bib.bib14.9.2" class="ltx_emph ltx_font_italic" style="font-size:70%;">Advances in Neural Information Processing Systems</em><span id="bib.bib14.10.3" class="ltx_text" style="font-size:70%;">, pages
551â€“562, 2017.
</span>
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib15.5.5.1" class="ltx_text" style="font-size:70%;">Jabri etÂ al. (2016)</span></span>
<span class="ltx_bibblock"><span id="bib.bib15.7.1" class="ltx_text" style="font-size:70%;">
Allan Jabri, Armand Joulin, and Laurens vanÂ der Maaten.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.8.1" class="ltx_text" style="font-size:70%;">Revisiting visual question answering baselines.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.9.1" class="ltx_text" style="font-size:70%;">In </span><em id="bib.bib15.10.2" class="ltx_emph ltx_font_italic" style="font-size:70%;">European Conference on Computer Vision</em><span id="bib.bib15.11.3" class="ltx_text" style="font-size:70%;">, pages 727â€“739.
Springer, 2016.
</span>
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib16.5.5.1" class="ltx_text" style="font-size:70%;">Johnson etÂ al. (2016)</span></span>
<span class="ltx_bibblock"><span id="bib.bib16.7.1" class="ltx_text" style="font-size:70%;">
Justin Johnson, Bharath Hariharan, Laurens vanÂ der Maaten, LiÂ Fei-Fei,
CÂ Lawrence Zitnick, and Ross Girshick.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.8.1" class="ltx_text" style="font-size:70%;">Clevr: A diagnostic dataset for compositional language and elementary
visual reasoning.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib16.9.1" class="ltx_emph ltx_font_italic" style="font-size:70%;">arXiv preprint arXiv:1612.06890</em><span id="bib.bib16.10.2" class="ltx_text" style="font-size:70%;">, 2016.
</span>
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib17.5.5.1" class="ltx_text" style="font-size:70%;">Kim etÂ al. (2016)</span></span>
<span class="ltx_bibblock"><span id="bib.bib17.7.1" class="ltx_text" style="font-size:70%;">
Jin-Hwa Kim, Kyoung-Woon On, Jeonghee Kim, Jung-Woo Ha, and Byoung-Tak Zhang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.8.1" class="ltx_text" style="font-size:70%;">Hadamard product for low-rank bilinear pooling.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib17.9.1" class="ltx_emph ltx_font_italic" style="font-size:70%;">arXiv preprint arXiv:1610.04325</em><span id="bib.bib17.10.2" class="ltx_text" style="font-size:70%;">, 2016.
</span>
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib18.4.4.1" class="ltx_text" style="font-size:70%;">Kingma and Ba (2014)</span></span>
<span class="ltx_bibblock"><span id="bib.bib18.6.1" class="ltx_text" style="font-size:70%;">
Diederik Kingma and Jimmy Ba.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.7.1" class="ltx_text" style="font-size:70%;">Adam: A method for stochastic optimization.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib18.8.1" class="ltx_emph ltx_font_italic" style="font-size:70%;">arXiv preprint arXiv:1412.6980</em><span id="bib.bib18.9.2" class="ltx_text" style="font-size:70%;">, 2014.
</span>
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib19.5.5.1" class="ltx_text" style="font-size:70%;">Kiros etÂ al. (2015)</span></span>
<span class="ltx_bibblock"><span id="bib.bib19.7.1" class="ltx_text" style="font-size:70%;">
Ryan Kiros, Yukun Zhu, RuslanÂ R Salakhutdinov, Richard Zemel, Raquel Urtasun,
Antonio Torralba, and Sanja Fidler.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.8.1" class="ltx_text" style="font-size:70%;">Skip-thought vectors.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.9.1" class="ltx_text" style="font-size:70%;">In </span><em id="bib.bib19.10.2" class="ltx_emph ltx_font_italic" style="font-size:70%;">Advances in neural information processing systems</em><span id="bib.bib19.11.3" class="ltx_text" style="font-size:70%;">, pages
3294â€“3302, 2015.
</span>
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib20.5.5.1" class="ltx_text" style="font-size:70%;">Krishna etÂ al. (2016)</span></span>
<span class="ltx_bibblock"><span id="bib.bib20.7.1" class="ltx_text" style="font-size:70%;">
Ranjay Krishna, Yuke Zhu, Oliver Groth, Justin Johnson, Kenji Hata, Joshua
Kravitz, Stephanie Chen, Yannis Kalantidis, Li-Jia Li, DavidÂ A Shamma, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.8.1" class="ltx_text" style="font-size:70%;">Visual genome: Connecting language and vision using crowdsourced
dense image annotations.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib20.9.1" class="ltx_emph ltx_font_italic" style="font-size:70%;">arXiv preprint arXiv:1602.07332</em><span id="bib.bib20.10.2" class="ltx_text" style="font-size:70%;">, 2016.
</span>
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib21.5.5.1" class="ltx_text" style="font-size:70%;">Lu etÂ al. (2016)</span></span>
<span class="ltx_bibblock"><span id="bib.bib21.7.1" class="ltx_text" style="font-size:70%;">
Jiasen Lu, Jianwei Yang, Dhruv Batra, and Devi Parikh.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.8.1" class="ltx_text" style="font-size:70%;">Hierarchical question-image co-attention for visual question
answering.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.9.1" class="ltx_text" style="font-size:70%;">In </span><em id="bib.bib21.10.2" class="ltx_emph ltx_font_italic" style="font-size:70%;">Advances In Neural Information Processing Systems</em><span id="bib.bib21.11.3" class="ltx_text" style="font-size:70%;">, pages
289â€“297, 2016.
</span>
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib22.5.5.1" class="ltx_text" style="font-size:70%;">Lu etÂ al. (2017)</span></span>
<span class="ltx_bibblock"><span id="bib.bib22.7.1" class="ltx_text" style="font-size:70%;">
Pan Lu, Hongsheng Li, Wei Zhang, Jianyong Wang, and Xiaogang Wang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.8.1" class="ltx_text" style="font-size:70%;">Co-attending free-form regions and detections with multi-modal
multiplicative feature embedding for visual question answering.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib22.9.1" class="ltx_emph ltx_font_italic" style="font-size:70%;">arXiv preprint arXiv:1711.06794</em><span id="bib.bib22.10.2" class="ltx_text" style="font-size:70%;">, 2017.
</span>
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib23.5.5.1" class="ltx_text" style="font-size:70%;">Malinowski etÂ al. (2017)</span></span>
<span class="ltx_bibblock"><span id="bib.bib23.7.1" class="ltx_text" style="font-size:70%;">
Mateusz Malinowski, Marcus Rohrbach, and Mario Fritz.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.8.1" class="ltx_text" style="font-size:70%;">Ask your neurons: A deep learning approach to visual question
answering.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib23.9.1" class="ltx_emph ltx_font_italic" style="font-size:70%;">International Journal of Computer Vision</em><span id="bib.bib23.10.2" class="ltx_text" style="font-size:70%;">, 125(1-3):110â€“135, 2017.
</span>
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib24.5.5.1" class="ltx_text" style="font-size:70%;">Nam etÂ al. (2016)</span></span>
<span class="ltx_bibblock"><span id="bib.bib24.7.1" class="ltx_text" style="font-size:70%;">
Hyeonseob Nam, Jung-Woo Ha, and Jeonghee Kim.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.8.1" class="ltx_text" style="font-size:70%;">Dual attention networks for multimodal reasoning and matching.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib24.9.1" class="ltx_emph ltx_font_italic" style="font-size:70%;">arXiv preprint arXiv:1611.00471</em><span id="bib.bib24.10.2" class="ltx_text" style="font-size:70%;">, 2016.
</span>
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib25.5.5.1" class="ltx_text" style="font-size:70%;">Ren etÂ al. (2015)</span></span>
<span class="ltx_bibblock"><span id="bib.bib25.7.1" class="ltx_text" style="font-size:70%;">
Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.8.1" class="ltx_text" style="font-size:70%;">Faster r-cnn: Towards real-time object detection with region proposal
networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.9.1" class="ltx_text" style="font-size:70%;">In </span><em id="bib.bib25.10.2" class="ltx_emph ltx_font_italic" style="font-size:70%;">Advances in neural information processing systems</em><span id="bib.bib25.11.3" class="ltx_text" style="font-size:70%;">, pages
91â€“99, 2015.
</span>
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib26.5.5.1" class="ltx_text" style="font-size:70%;">Shih etÂ al. (2016)</span></span>
<span class="ltx_bibblock"><span id="bib.bib26.7.1" class="ltx_text" style="font-size:70%;">
KevinÂ J Shih, Saurabh Singh, and Derek Hoiem.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.8.1" class="ltx_text" style="font-size:70%;">Where to look: Focus regions for visual question answering.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.9.1" class="ltx_text" style="font-size:70%;">In </span><em id="bib.bib26.10.2" class="ltx_emph ltx_font_italic" style="font-size:70%;">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition</em><span id="bib.bib26.11.3" class="ltx_text" style="font-size:70%;">, pages 4613â€“4621, 2016.
</span>
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib27.4.4.1" class="ltx_text" style="font-size:70%;">Simonyan and Zisserman (2014)</span></span>
<span class="ltx_bibblock"><span id="bib.bib27.6.1" class="ltx_text" style="font-size:70%;">
Karen Simonyan and Andrew Zisserman.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.7.1" class="ltx_text" style="font-size:70%;">Very deep convolutional networks for large-scale image recognition.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib27.8.1" class="ltx_emph ltx_font_italic" style="font-size:70%;">arXiv preprint arXiv:1409.1556</em><span id="bib.bib27.9.2" class="ltx_text" style="font-size:70%;">, 2014.
</span>
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib28.5.5.1" class="ltx_text" style="font-size:70%;">Sukhbaatar etÂ al. (2015)</span></span>
<span class="ltx_bibblock"><span id="bib.bib28.7.1" class="ltx_text" style="font-size:70%;">
Sainbayar Sukhbaatar, Jason Weston, Rob Fergus, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.8.1" class="ltx_text" style="font-size:70%;">End-to-end memory networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.9.1" class="ltx_text" style="font-size:70%;">In </span><em id="bib.bib28.10.2" class="ltx_emph ltx_font_italic" style="font-size:70%;">Advances in neural information processing systems</em><span id="bib.bib28.11.3" class="ltx_text" style="font-size:70%;">, pages
2440â€“2448, 2015.
</span>
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib29.5.5.1" class="ltx_text" style="font-size:70%;">Teney etÂ al. (2017)</span></span>
<span class="ltx_bibblock"><span id="bib.bib29.7.1" class="ltx_text" style="font-size:70%;">
Damien Teney, Peter Anderson, Xiaodong He, and Anton vanÂ den Hengel.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.8.1" class="ltx_text" style="font-size:70%;">Tips and tricks for visual question answering: Learnings from the
2017 challenge.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib29.9.1" class="ltx_emph ltx_font_italic" style="font-size:70%;">arXiv preprint arXiv:1708.02711</em><span id="bib.bib29.10.2" class="ltx_text" style="font-size:70%;">, 2017.
</span>
</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib30.4.4.1" class="ltx_text" style="font-size:70%;">Tucker (1966)</span></span>
<span class="ltx_bibblock"><span id="bib.bib30.6.1" class="ltx_text" style="font-size:70%;">
LedyardÂ R Tucker.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.7.1" class="ltx_text" style="font-size:70%;">Some mathematical notes on three-mode factor analysis.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib30.8.1" class="ltx_emph ltx_font_italic" style="font-size:70%;">Psychometrika</em><span id="bib.bib30.9.2" class="ltx_text" style="font-size:70%;">, 31(3):279â€“311, 1966.
</span>
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib31.5.5.1" class="ltx_text" style="font-size:70%;">Wu etÂ al. (2016)</span></span>
<span class="ltx_bibblock"><span id="bib.bib31.7.1" class="ltx_text" style="font-size:70%;">
QiÂ Wu, Peng Wang, Chunhua Shen, Anthony Dick, and Anton vanÂ den Hengel.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.8.1" class="ltx_text" style="font-size:70%;">Ask me anything: Free-form visual question answering based on
knowledge from external sources.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.9.1" class="ltx_text" style="font-size:70%;">In </span><em id="bib.bib31.10.2" class="ltx_emph ltx_font_italic" style="font-size:70%;">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition</em><span id="bib.bib31.11.3" class="ltx_text" style="font-size:70%;">, pages 4622â€“4630, 2016.
</span>
</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib32.5.5.1" class="ltx_text" style="font-size:70%;">Xie etÂ al. (2016)</span></span>
<span class="ltx_bibblock"><span id="bib.bib32.7.1" class="ltx_text" style="font-size:70%;">
Saining Xie, Ross Girshick, Piotr DollÃ¡r, Zhuowen Tu, and Kaiming He.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.8.1" class="ltx_text" style="font-size:70%;">Aggregated residual transformations for deep neural networks.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib32.9.1" class="ltx_emph ltx_font_italic" style="font-size:70%;">arXiv preprint arXiv:1611.05431</em><span id="bib.bib32.10.2" class="ltx_text" style="font-size:70%;">, 2016.
</span>
</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib33.5.5.1" class="ltx_text" style="font-size:70%;">Xiong etÂ al. (2016)</span></span>
<span class="ltx_bibblock"><span id="bib.bib33.7.1" class="ltx_text" style="font-size:70%;">
Caiming Xiong, Stephen Merity, and Richard Socher.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.8.1" class="ltx_text" style="font-size:70%;">Dynamic memory networks for visual and textual question answering.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib33.9.1" class="ltx_emph ltx_font_italic" style="font-size:70%;">arXiv</em><span id="bib.bib33.10.2" class="ltx_text" style="font-size:70%;">, 1603, 2016.
</span>
</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib34.5.5.1" class="ltx_text" style="font-size:70%;">Xu etÂ al. (2015)</span></span>
<span class="ltx_bibblock"><span id="bib.bib34.7.1" class="ltx_text" style="font-size:70%;">
Kelvin Xu, Jimmy Ba, Ryan Kiros, Kyunghyun Cho, Aaron Courville, Ruslan
Salakhudinov, Rich Zemel, and Yoshua Bengio.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.8.1" class="ltx_text" style="font-size:70%;">Show, attend and tell: Neural image caption generation with visual
attention.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.9.1" class="ltx_text" style="font-size:70%;">In </span><em id="bib.bib34.10.2" class="ltx_emph ltx_font_italic" style="font-size:70%;">International Conference on Machine Learning</em><span id="bib.bib34.11.3" class="ltx_text" style="font-size:70%;">, pages
2048â€“2057, 2015.
</span>
</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib35.5.5.1" class="ltx_text" style="font-size:70%;">Yang etÂ al. (2016)</span></span>
<span class="ltx_bibblock"><span id="bib.bib35.7.1" class="ltx_text" style="font-size:70%;">
Zichao Yang, Xiaodong He, Jianfeng Gao, LiÂ Deng, and Alex Smola.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.8.1" class="ltx_text" style="font-size:70%;">Stacked attention networks for image question answering.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.9.1" class="ltx_text" style="font-size:70%;">In </span><em id="bib.bib35.10.2" class="ltx_emph ltx_font_italic" style="font-size:70%;">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition</em><span id="bib.bib35.11.3" class="ltx_text" style="font-size:70%;">, pages 21â€“29, 2016.
</span>
</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib36.5.5.1" class="ltx_text" style="font-size:70%;">Yu etÂ al. (2017)</span></span>
<span class="ltx_bibblock"><span id="bib.bib36.7.1" class="ltx_text" style="font-size:70%;">
Dongfei Yu, Jianlong Fu, Tao Mei, and Yong Rui.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.8.1" class="ltx_text" style="font-size:70%;">Multi-level attention networks for visual question answering.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.9.1" class="ltx_text" style="font-size:70%;">In </span><em id="bib.bib36.10.2" class="ltx_emph ltx_font_italic" style="font-size:70%;">Conf. on Computer Vision and Pattern Recognition</em><span id="bib.bib36.11.3" class="ltx_text" style="font-size:70%;">, 2017.
</span>
</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib37.5.5.1" class="ltx_text" style="font-size:70%;">Yu etÂ al. (2018)</span></span>
<span class="ltx_bibblock"><span id="bib.bib37.7.1" class="ltx_text" style="font-size:70%;">
Zhou Yu, Jun Yu, Chenchao Xiang, Jianping Fan, and Dacheng Tao.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.8.1" class="ltx_text" style="font-size:70%;">Beyond bilinear: Generalized multimodal factorized high-order pooling
for visual question answering.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib37.9.1" class="ltx_emph ltx_font_italic" style="font-size:70%;">IEEE Transactions on Neural Networks and Learning Systems</em><span id="bib.bib37.10.2" class="ltx_text" style="font-size:70%;">,
2018.
</span>
</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib38.5.5.1" class="ltx_text" style="font-size:70%;">Zhou etÂ al. (2015)</span></span>
<span class="ltx_bibblock"><span id="bib.bib38.7.1" class="ltx_text" style="font-size:70%;">
Bolei Zhou, Yuandong Tian, Sainbayar Sukhbaatar, Arthur Szlam, and Rob Fergus.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.8.1" class="ltx_text" style="font-size:70%;">Simple baseline for visual question answering.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib38.9.1" class="ltx_emph ltx_font_italic" style="font-size:70%;">arXiv preprint arXiv:1512.02167</em><span id="bib.bib38.10.2" class="ltx_text" style="font-size:70%;">, 2015.
</span>
</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib39.4.4.1" class="ltx_text" style="font-size:70%;">(39)</span></span>
<span class="ltx_bibblock"><span id="bib.bib39.6.1" class="ltx_text" style="font-size:70%;">
Yuke Zhu, JosephÂ J Lim, and LiÂ Fei-Fei.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.7.1" class="ltx_text" style="font-size:70%;">Knowledge acquisition for visual question answering via iterative
querying.
</span>
</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib40.5.5.1" class="ltx_text" style="font-size:70%;">Zhu etÂ al. (2016)</span></span>
<span class="ltx_bibblock"><span id="bib.bib40.7.1" class="ltx_text" style="font-size:70%;">
Yuke Zhu, Oliver Groth, Michael Bernstein, and LiÂ Fei-Fei.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.8.1" class="ltx_text" style="font-size:70%;">Visual7w: Grounded question answering in images.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.9.1" class="ltx_text" style="font-size:70%;">In </span><em id="bib.bib40.10.2" class="ltx_emph ltx_font_italic" style="font-size:70%;">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition</em><span id="bib.bib40.11.3" class="ltx_text" style="font-size:70%;">, pages 4995â€“5004, 2016.
</span>
</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/1805.04246" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/1805.04247" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+1805.04247">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/1805.04247" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/1805.04249" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Tue Mar  5 11:41:24 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
