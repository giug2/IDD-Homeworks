<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2206.04731] Leveraging Centric Data Federated Learning Using Blockchain For Integrity Assurance</title><meta property="og:description" content="Machine learning abilities have become a vital component for various solutions across industries, applications, and sectors. Many organizations seek to leverage AI-based solutions across their business services to unlo…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Leveraging Centric Data Federated Learning Using Blockchain For Integrity Assurance">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Leveraging Centric Data Federated Learning Using Blockchain For Integrity Assurance">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2206.04731">

<!--Generated on Mon Mar 11 17:16:45 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Leveraging Centric Data Federated Learning Using Blockchain For Integrity Assurance</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Riadh Ben Chaabene,<sup id="id1.1.id1" class="ltx_sup">1</sup>
Darine Amayed, <sup id="id2.2.id2" class="ltx_sup">1</sup>
Mohamed Cheriet <sup id="id3.3.id3" class="ltx_sup">1</sup>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id4.id1" class="ltx_p">Machine learning abilities have become a vital component for various solutions across industries, applications, and sectors. Many organizations seek to leverage AI-based solutions across their business services to unlock better efficiency and increase productivity. Problems, however, can arise if there is a lack of quality data for AI-model training, scalability, and maintenance.
We propose a data-centric federated learning architecture leveraged by a public blockchain and smart contracts to overcome this significant issue. Our proposed solution provides a virtual public marketplace where developers, data scientists, and AI-engineer can publish their models and collaboratively create and access quality data for training. We enhance data quality and integrity through an incentive mechanism that rewards contributors for data contribution and verification. Those combined with the proposed framework helped increase with only one user simulation the training dataset with an average of 100 input daily and the model accuracy by approximately 4%.</p>
</div>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Introduction</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">The machine learning market is witnessing tremendous growth. In 2020, the market saw an increase of 38.01%, leading to a compound annual growth rate growth of 39% and an investment intercepted at $11.16 Billion between the year 2020 and 2024 <cite class="ltx_cite ltx_citemacro_citep">(Technavio <a href="#bib.bib17" title="" class="ltx_ref">2020</a>)</cite>. This is due to the fragmentation of the market with large companies investing and contributing to the artificial intelligence field, such as Alphabet Inc, Amazon Inc, and many others. Moreover, in the last few years, machine learning research has augmented tremendously due to its contribution to numerous areas, making them more robust and systematic. Society and companies have benefited from this progress, leading to multiple investments to encourage this growth. Researchers and developers have been dedicated to providing more studies and contributions to this technology. Despite all of this, machine learning is still facing significant challenges; two of them consist of data accessibility and trustability.
Data <cite class="ltx_cite ltx_citemacro_citep">(Biderman and Scheirer <a href="#bib.bib4" title="" class="ltx_ref">2021</a>)</cite> is the key that is driving the majority of machine learning models. Acutely, the data is facing the following issues: high centralization, complex accessibility, insufficient security, and insufficient quality.
Companies and research centers are acting with the problem of acquiring the correct data for their research<cite class="ltx_cite ltx_citemacro_citep">(Biderman and Scheirer <a href="#bib.bib4" title="" class="ltx_ref">2021</a>)</cite>, since most of the data tends to be centralized and inaccessible, leading to either unavailability or high cost of acquirement. Also, data can easily be tampered with, which causes a lack of data quality. Even if the data is available, noisy information could affect the whole model. Results of a model could variety greatly from one dataset to another, and since the data commonly being used is variable, there is no guarantee that the data is equitable.
<br class="ltx_break">Additionally, creating the model relies on data collection, which consists of 60% of the overall machine learning work and that 25% of the time is allocated for data cleaning and data labeling<cite class="ltx_cite ltx_citemacro_citep">(Roh, Heo, and Whang <a href="#bib.bib15" title="" class="ltx_ref">2019</a>)</cite>. Despite the importance of data, 92% of it is owned and stored in the western world <cite class="ltx_cite ltx_citemacro_citep">(Amiot et al. <a href="#bib.bib1" title="" class="ltx_ref">2020</a>)</cite>, where most of the big companies lie.
On the other hand, machine learning model training is dependent on human interaction, causing the learning process to start or end in an insignificant time leading to the problem of automation.
<br class="ltx_break">It is therefore mandatory to provide alternative solutions to these problems. They will enhance the progress of machine learning, leading to the creation of a more efficient and sophisticated model to improve the development of this technology and our lives.
All of this leads to the categorization the problem into three areas:</p>
<ul id="Sx1.I1" class="ltx_itemize">
<li id="Sx1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx1.I1.i1.p1" class="ltx_para">
<p id="Sx1.I1.i1.p1.1" class="ltx_p">Model training issues: that consist of the insufficient data and resources for model training, leading to less accuracy.</p>
</div>
</li>
<li id="Sx1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx1.I1.i2.p1" class="ltx_para">
<p id="Sx1.I1.i2.p1.1" class="ltx_p">Data availability issues: that corresponds to the lack of data available for people to train machine learning models.</p>
</div>
</li>
<li id="Sx1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx1.I1.i3.p1" class="ltx_para">
<p id="Sx1.I1.i3.p1.1" class="ltx_p">Data Integrity issues: that refer to the insurance of the available data quality.</p>
</div>
</li>
</ul>
</div>
<div id="Sx1.p2" class="ltx_para">
<p id="Sx1.p2.1" class="ltx_p">In this paper, we propose a framework for publishing and contributing to the collaborative machine learning process. The idea is to present a public marketplace with free access to share a model on the one end and contribute to the continuous training of this model on the other. We encourage participants to share and verify the data to provide the needed data quality for the training to avoid manipulation. Also, we are looking for model diversity where this framework will function with any machine learning model type. To reach our objective, we will be using a collaborative learning approach such as federated learning. Furthermore, we will be using blockchain technology <cite class="ltx_cite ltx_citemacro_citep">(Nakamoto <a href="#bib.bib12" title="" class="ltx_ref">2008</a>)</cite> as an infrastructure for our framework and the InterPlanetary File System as a storage mechanism. Also, a monetary incentive mechanism will be developed to reward contributors and withhold malicious users.</p>
</div>
</section>
<section id="Sx2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Background</h2>

<div id="Sx2.p1" class="ltx_para">
<p id="Sx2.p1.1" class="ltx_p">Federated Learning <cite class="ltx_cite ltx_citemacro_citep">(Yang et al. <a href="#bib.bib21" title="" class="ltx_ref">2019</a>)</cite> conducts machine learning in a decentralized approach. It aims to provide the model to the data rather than the traditional way, where we create a model then provide the data. The data is distributed along with different users in their edge mobiles. Each provides his data to train the model, leading to multiple unique training datasets rather than one. Only the metadata is returned to the centralized model or the global model using encrypted communication. At the same time, this provides knowledge performance for the model and enhances data privacy since all the calculations happen inside the owner’s device without any exchange of their data to a centralized server. There exists two types of federated learning:
<br class="ltx_break"></p>
</div>
<div id="Sx2.p2" class="ltx_para">
<ul id="Sx2.I2" class="ltx_itemize">
<li id="Sx2.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I2.i1.p1" class="ltx_para">
<p id="Sx2.I2.i1.p1.1" class="ltx_p"><span id="Sx2.I2.i1.p1.1.1" class="ltx_text ltx_font_bold">Model-Centric Federated Learning</span> This is the most common of the two types.
In Model-Centric, the model is hosted in a cloud service, and its API is pre-configured (Layers, Weight, Etc ..). Each user downloads the model, enhances it and uploads a newer version. But this could happen over a long period of time, mostly weeks and months <cite class="ltx_cite ltx_citemacro_citep">(Yang et al. <a href="#bib.bib21" title="" class="ltx_ref">2019</a>)</cite>.
Figure <a href="#Sx2.F1" title="Figure 1 ‣ 1st item ‣ Background ‣ Leveraging Centric Data Federated Learning Using Blockchain For Integrity Assurance" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> describes its process. First, the model is sent to the edge device. Then, the metadata is sent to the global model, which resends an updated model.</p>
</div>
<div id="Sx2.I2.i1.p2" class="ltx_para">
<p id="Sx2.I2.i1.p2.1" class="ltx_p">A great example is Google’s GBoard mobile app. It learns users typing preferences over time without sending any private data.</p>
</div>
<figure id="Sx2.F1" class="ltx_figure"><img src="/html/2206.04731/assets/Figures/model_centric.png" id="Sx2.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="245" height="194" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Model-Centric Federated Learning</figcaption>
</figure>
</li>
<li id="Sx2.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I2.i2.p1" class="ltx_para">
<p id="Sx2.I2.i2.p1.1" class="ltx_p"><span id="Sx2.I2.i2.p1.1.1" class="ltx_text ltx_font_bold">Data-Centric Federated Learning</span> Less common than model-centric, but more suitable for experimentation science<cite class="ltx_cite ltx_citemacro_citep">(Majcherczyk, Srishankar, and
Pinciroli <a href="#bib.bib11" title="" class="ltx_ref">2020</a>)</cite>. It is hosted on a cloud server, not as a model but as a dataset whose API is also pre-configured (Schema, Attributes, etc …). Users can use those datasets to train their model locally in a specially appointed practical way <cite class="ltx_cite ltx_citemacro_citep">(Xie et al. <a href="#bib.bib20" title="" class="ltx_ref">2020</a>)</cite>. As described in figure <a href="#Sx2.F2" title="Figure 2 ‣ 2nd item ‣ Background ‣ Leveraging Centric Data Federated Learning Using Blockchain For Integrity Assurance" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, the model owner sends the model to a cloud server asking for a specific type of data to train it. As soon the data is available and accepted by its owner, the model starts to train and eventually is sent back to its owner.</p>
</div>
<div id="Sx2.I2.i2.p2" class="ltx_para">
<p id="Sx2.I2.i2.p2.1" class="ltx_p">For example, suppose an individual wants to train a model for a medical diagnosis. In that case, he needs to be part of a major hospital or constantly interact with a doctor. Otherwise, it may be highly troublesome or difficult to get a dataset that would be adequate for the model training. With data-centric, one could possess that data and add them to the cloud server for others to benefit from and train their model by submitting requests.</p>
</div>
<figure id="Sx2.F2" class="ltx_figure"><img src="/html/2206.04731/assets/Figures/Data_centric.png" id="Sx2.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="279" height="196" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Data-Centric Federated Learning </figcaption>
</figure>
</li>
</ul>
</div>
</section>
<section id="Sx3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Related Work</h2>

<div id="Sx3.p1" class="ltx_para">
<p id="Sx3.p1.1" class="ltx_p">This section discusses previous research papers related to the merging of blockchain technology, the machine learning process, and the integration of collaborative training. This idea is considered a new but promising one, considering the advantages it offers. Few works have been done in this area.
<br class="ltx_break">Generally, traditional Federated learning relies on a single central server to train a global model. If that server fails due to malicious behavior, all could be lost. Decentralization of the data and the training can provide a solution.</p>
</div>
<div id="Sx3.p2" class="ltx_para">
<p id="Sx3.p2.1" class="ltx_p">The research presented in the paper <cite class="ltx_cite ltx_citemacro_citep">(Harris and Waggoner <a href="#bib.bib6" title="" class="ltx_ref">2019</a>)</cite> focuses on improving machine learning model integrity and availability through decentralization. Their idea was to study the impact of blockchain technology over machine learning models, focusing on decentralization to mainly to provide sharing access to machine learning models. They used blockchain to establish a distributed build of large datasets accessible to all the network participants. Collaboration is a significant feature of their framework where they encourage contributors to improve and train a model constantly. Providing a continuously updated model, yet free, open and accessible is what this paper aims for.
<br class="ltx_break">The framework managed to create a distributed, collaborative environment where people could contribute effectively to a machine learning model using quality data. This helped improve the model’s accuracy, as it dealt with data manipulation thanks to a well designed incentive mechanism. The blockchain helped to create an open, secure, and with ownership datasets market where a participant could interact with to train models either on-chain or off-chain.
<br class="ltx_break">Unfortunately, it only manages to work with small models that can be efficiently updated with one sample. This approach of storing the entire dataset inside the blockchain is not very beneficial due the amount of data you can store. This is either because the amount is limited by the protocol, or because of the huge transaction fees you would have to pay. Therefore, the amount of data you store has to be held by every full node on the network. Everyone that downloads the blockchain is downloading your piece of data as well. Even keeping kilobytes can cost a fortune.
When storing data on the blockchain, we often pay a base price for the transaction itself plus an amount per byte we want to keep. If smart contracts are involved, we also pay for the execution time of the smart contract <cite class="ltx_cite ltx_citemacro_citep">(Hu <a href="#bib.bib7" title="" class="ltx_ref">2021</a>)</cite>. With that being said, this option is not used to provide a collaborative environment to train complex models that need a large amount of data.
<br class="ltx_break"></p>
</div>
<div id="Sx3.p3" class="ltx_para">
<p id="Sx3.p3.1" class="ltx_p">The work in the paper <cite class="ltx_cite ltx_citemacro_citep">(Ma et al. <a href="#bib.bib10" title="" class="ltx_ref">2021</a>)</cite> presents a secure and reliable federated learning framework. The idea is to ensure the model update process in a decentralized environment. Each client using the framework could train his machine learning model and mine blocks to publish aggregating results. The blockchain will track tasks related to collaborative learning, such as broadcasting learning models, publishing a task, or reviewing the aggregating learning results. Using decentralization accountability, they enable all miners to validate the uploaded model quality. This ensures misbehaving detection for low-quality contribution to the federated model. They start by integrating a local model into each training node, training and updating the model using a global model and its data. That leads to creating a training pool, conducting a decentralized aggregation process for the federated learning. Once the models are updated and collected, the clients calculate the global model update. Eventually, each block will record the local model update, data size, computation time, and aggregated parameters. Once registered, the model is published to the whole network. Once published and the hash value is found, miners need to verify the block contained aggregated results, either by comparing with the result found in the publishing block or by using a public dataset to justify the performance of the uploaded model. Reward allocation is available for the client to encourage them to mine and verify each block. Their study showed significant results for dealing with federated learning single server failure and avoiding unwanted distributed training behavior. However, the study shows that the data is available for the clients to train their model remotely and test its efficiency. This is not always the case.</p>
</div>
<div id="Sx3.p4" class="ltx_para">
<p id="Sx3.p4.1" class="ltx_p">Tao Wang <cite class="ltx_cite ltx_citemacro_citep">(Wang <a href="#bib.bib19" title="" class="ltx_ref">2018</a>)</cite> explored the establishment of a link between machine learning and blockchain technology to propose a unified framework aiming to deal with machine learning traceability and automation problems. It discussed the usage of multiple threads to translate core machine learning implementation instead of a single thread.
They used a three-layer architecture composed of a Server Layer, Streaming Layer, and a Smart Contract Layer. The server and streaming layers aim to achieve the seven machine learning steps (Initialization, Training, Validation, Testing, Evaluation, Serialization and Clean-up). Still, the first is using a static handle of data (data at rest) and the second a dynamic one (events on the fly). The Smart Contract layer is essential to deal with trustability and the automation of the process of training the model.
<br class="ltx_break">This work managed to achieve a stable framework to collect data using cloud technology and train machine learning models.
<br class="ltx_break">Nevertheless, the usage of smart contracts can cause runtime problems while running thousands of contracts on the blockchain, the response time can decrease tremendously.
<br class="ltx_break"></p>
</div>
<figure id="Sx3.F3" class="ltx_figure"><img src="/html/2206.04731/assets/Figures/federated-Page-8.png" id="Sx3.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="628" height="155" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Our contribution overview : Blockchain integration for data-centric federated learning</figcaption>
</figure>
<div id="Sx3.p5" class="ltx_para">
<p id="Sx3.p5.1" class="ltx_p">Each study has contributed to understanding the application of blockchain machine learning training, either in data availability or model training. As we mentioned previously, they provided the ability to conduct that contribution, such as automated model training, data availability, and verifying the quality and integrity of the data.
But with each work comes limitations. We are still facing some related to the usage of blockchain technology. One of the main problems is data storage. The biggest problem of storing data on a blockchain is the amount of data you can store, either because the amount is restricted by the convention or given the immense exchange expenses you would need to pay.
<br class="ltx_break">One other major limitation is the need for high computation power to train a machine learning model in an efficient time matter. When we are using on­chain training with smart contracts, this usage can cause runtime problems while running thousands of contracts; the response time can decrease tremendously and even causes network failure.
<br class="ltx_break">In our study, we consider not only supervised models but also unsupervised ones with a similar incentive mechanism <cite class="ltx_cite ltx_citemacro_citep">(Harris and Waggoner <a href="#bib.bib6" title="" class="ltx_ref">2019</a>)</cite>. In this matter, we address the Etherieum <cite class="ltx_cite ltx_citemacro_citep">(Vujicic, Jagodic, and Randic <a href="#bib.bib18" title="" class="ltx_ref">2018</a>)</cite> memory allocation problem. Our alternative solution is to use the InterPlanetary File System (IPFS) <cite class="ltx_cite ltx_citemacro_citep">(Benet <a href="#bib.bib3" title="" class="ltx_ref">2019</a>)</cite> where we will only store on the blockchain the links of the file; this will help reduce the cost of storing inside Etherieum and allow people to upload as much data as they want. This will provide the ability to use diverse models since it will provide the necessary data regarding its training. And we offer the ability to train a model in an off-chain manner. This will allow the possibility of training models faster by avoiding network latency and then re-uploading them into the blockchain.</p>
</div>
</section>
<section id="Sx4" class="ltx_section">
<h2 class="ltx_title ltx_title_section"> Proposed approach</h2>

<div id="Sx4.p1" class="ltx_para">
<p id="Sx4.p1.1" class="ltx_p">Distributed data is a critical element of our study since it provides a solution to data centralization. Data-centric Federated learning architecture was a reference approach in creating our architecture. While in federated learning, we distribute the model to the data in our study, we reverse it by spreading the data to the model.
We explain in the figure below <a href="#Sx3.F3" title="Figure 3 ‣ Related Work ‣ Leveraging Centric Data Federated Learning Using Blockchain For Integrity Assurance" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, the difference between two common types of learning, centralized learning and federated learning, and our framework contribution to model learning.</p>
</div>
<section id="Sx4.SSx1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">System Overview </h3>

<div id="Sx4.SSx1.p1" class="ltx_para">
<p id="Sx4.SSx1.p1.1" class="ltx_p">In classic centralized learning, we have data centralized in a server sent to a model for training. We spent decades using that technique until we were presented with federated learning. To be more specific, data-centric federated learning is the idea that a super or global oracle that is centralized in a server and contains multiple datasets added by contributors. Any model owner wanting to use this data could send their model and a request to use a specific dataset for its training. If accepted, the oracle searches for the requested dataset and starts the training of the model. As soon as the training is finished, the model is provided back to the model owner.
<br class="ltx_break">In the case of our framework, we have a model which is stored in a decentralized environment, being the public blockchain <cite class="ltx_cite ltx_citemacro_citep">(Kim et al. <a href="#bib.bib8" title="" class="ltx_ref">2020</a>)</cite>. It is therefore accessible by all the network participants. Those same participants provide the data to the model in a collaborative approach. With every input of data or IPFS hash, we have data aggregation <cite class="ltx_cite ltx_citemacro_citep">(Ramanan, Nakayama, and Sharma <a href="#bib.bib14" title="" class="ltx_ref">2019</a>)</cite>. But before any update to the model, the data needs to be verified to ensure its integrity. That function is provided using our incentive mechanism. The approved data is then sent to the model for training and the model is updated. For each beneficial deposit, a refund is made, and for each beneficial verification of the inputs, a reward is offered.
We are aiming more at data distribution rather than model distribution. Because that will help us create datasets for future usage. All of this is described in figure <a href="#Sx3.F3" title="Figure 3 ‣ Related Work ‣ Leveraging Centric Data Federated Learning Using Blockchain For Integrity Assurance" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.
Our system aims to apply blockchain advantages in machine learning; by merging The Ethereum Blockchain and the InterPlanetary File System, we will be able to create a safe and public market of collaborative training and sharing of machine learning models. Smart contracts are the core of our system, where users will be able to upload machine learning models and IPFS hashes that relate to datasets stored in a decentralized manner. Other users could reach those attributes for improving them. One other feature is the ability to make IPFS hashes available to create a data-sharing system. Our research concerns mainly two areas of work:</p>
<ul id="Sx4.I3" class="ltx_itemize">
<li id="Sx4.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx4.I3.i1.p1" class="ltx_para">
<p id="Sx4.I3.i1.p1.1" class="ltx_p">Collaborative Federated Data centric</p>
</div>
</li>
</ul>
<p id="Sx4.SSx1.p1.2" class="ltx_p">Where we present our strategy for reducing Blockchain storage costs so we could transform it into a data sharing and collection environment where people could have access to various data sets.</p>
<ul id="Sx4.I4" class="ltx_itemize">
<li id="Sx4.I4.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx4.I4.i1.p1" class="ltx_para">
<p id="Sx4.I4.i1.p1.1" class="ltx_p">Collaborative Training</p>
</div>
</li>
</ul>
<p id="Sx4.SSx1.p1.3" class="ltx_p">Aiming to encourage users to add their machine learning models inside Ethereum blockchain via a smart contract, where contributors could interact with it to train, either by adding data or retrieving it and train the model in an off-chain manner before re-uploading.</p>
</div>
</section>
<section id="Sx4.SSx2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">Data Collection</h3>

<div id="Sx4.SSx2.p1" class="ltx_para">
<p id="Sx4.SSx2.p1.1" class="ltx_p">Composed of the Data Handler and our Incentive Mechanism, those components aim to add and verify the integrity of the data added by the user to train the model.
<br class="ltx_break">The Data Handler collects and adds the data to the smart contract, which will be available to all participants of the network.
<br class="ltx_break">As for the incentive mechanism, it helps us ensure the quality of the data that is being distributed throw the blockchain by imposing a deposit when adding data and rewards for contributors when verifying it.
<br class="ltx_break">A smart contract is created and initialized to values of the incentive mechanism parameters. It then accepts actions from participants and triggers payments. Adding data requires validation from the incentive mechanism. The data will be stored in the smart contract either in the data handler or as an IPFS hash.
Figure <a href="#Sx4.F4" title="Figure 4 ‣ Data Collection ‣ Proposed approach ‣ Leveraging Centric Data Federated Learning Using Blockchain For Integrity Assurance" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> below describes the steps of the process of adding and collecting data to and from the smart contract in different scenarios. It consists of four users, a virtual wallet, the IPFS, the smart contract, and The Ethereum Blockchain.
<br class="ltx_break"></p>
<ul id="Sx4.I5" class="ltx_itemize">
<li id="Sx4.I5.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx4.I5.i1.p1" class="ltx_para">
<p id="Sx4.I5.i1.p1.1" class="ltx_p"><span id="Sx4.I5.i1.p1.1.1" class="ltx_text ltx_font_bold">Step 1:</span> User A which is the initial user add his data file to IPFS</p>
</div>
</li>
<li id="Sx4.I5.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx4.I5.i2.p1" class="ltx_para">
<p id="Sx4.I5.i2.p1.1" class="ltx_p"><span id="Sx4.I5.i2.p1.1.1" class="ltx_text ltx_font_bold">Step 2:</span> User A retrieves the hash of the file</p>
</div>
</li>
<li id="Sx4.I5.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx4.I5.i3.p1" class="ltx_para">
<p id="Sx4.I5.i3.p1.1" class="ltx_p"><span id="Sx4.I5.i3.p1.1.1" class="ltx_text ltx_font_bold">Step 3:</span> Start by providing the model, the data corresponding to the model, and the test data to the smart contract</p>
</div>
</li>
<li id="Sx4.I5.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx4.I5.i4.p1" class="ltx_para">
<p id="Sx4.I5.i4.p1.1" class="ltx_p"><span id="Sx4.I5.i4.p1.1.1" class="ltx_text ltx_font_bold">Step 4:</span> User A defines the reward fees for contributors</p>
</div>
</li>
<li id="Sx4.I5.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx4.I5.i5.p1" class="ltx_para">
<p id="Sx4.I5.i5.p1.1" class="ltx_p"><span id="Sx4.I5.i5.p1.1.1" class="ltx_text ltx_font_bold">Step 5:</span> The smart contract retrieves the amount and stores it</p>
</div>
</li>
<li id="Sx4.I5.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx4.I5.i6.p1" class="ltx_para">
<p id="Sx4.I5.i6.p1.1" class="ltx_p"><span id="Sx4.I5.i6.p1.1.1" class="ltx_text ltx_font_bold">Step 6:</span> The smart contract is stored in the blockchain
Those six steps represent ”The model initialization steps”</p>
</div>
</li>
<li id="Sx4.I5.i7" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx4.I5.i7.p1" class="ltx_para">
<p id="Sx4.I5.i7.p1.1" class="ltx_p"><span id="Sx4.I5.i7.p1.1.1" class="ltx_text ltx_font_bold">Step 7:</span> User B retrieves the IPFS hash</p>
</div>
</li>
<li id="Sx4.I5.i8" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx4.I5.i8.p1" class="ltx_para">
<p id="Sx4.I5.i8.p1.1" class="ltx_p"><span id="Sx4.I5.i8.p1.1.1" class="ltx_text ltx_font_bold">Step 8:</span> User B accesses IPFS platform and retrieves the file corresponding to the hash</p>
</div>
</li>
<li id="Sx4.I5.i9" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx4.I5.i9.p1" class="ltx_para">
<p id="Sx4.I5.i9.p1.1" class="ltx_p"><span id="Sx4.I5.i9.p1.1.1" class="ltx_text ltx_font_bold">Step 9:</span> User C makes a deposit</p>
</div>
</li>
<li id="Sx4.I5.i10" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx4.I5.i10.p1" class="ltx_para">
<p id="Sx4.I5.i10.p1.1" class="ltx_p"><span id="Sx4.I5.i10.p1.1.1" class="ltx_text ltx_font_bold">Step 10:</span> User C adds data to the smart contract</p>
</div>
</li>
<li id="Sx4.I5.i11" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx4.I5.i11.p1" class="ltx_para">
<p id="Sx4.I5.i11.p1.1" class="ltx_p"><span id="Sx4.I5.i11.p1.1.1" class="ltx_text ltx_font_bold">Step 11:</span> User D makes a deposit, verifies and fixes malicious data</p>
</div>
</li>
<li id="Sx4.I5.i12" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx4.I5.i12.p1" class="ltx_para">
<p id="Sx4.I5.i12.p1.1" class="ltx_p"><span id="Sx4.I5.i12.p1.1.1" class="ltx_text ltx_font_bold">Step 12:</span> User D retrieves a refund plus a reward fee</p>
</div>
</li>
</ul>
</div>
<figure id="Sx4.F4" class="ltx_figure"><img src="/html/2206.04731/assets/Figures/Collection_Dig.png" id="Sx4.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="384" height="198" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Data Collection Process</figcaption>
</figure>
<figure id="Sx4.F5" class="ltx_figure"><img src="/html/2206.04731/assets/Figures/Train_Diagram.png" id="Sx4.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="349" height="180" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Model training process</figcaption>
</figure>
</section>
<section id="Sx4.SSx3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">Model Training </h3>

<div id="Sx4.SSx3.p1" class="ltx_para">
<p id="Sx4.SSx3.p1.1" class="ltx_p">In order to automate the training process, users will generate a smart contract containing the machine learning model with all the specific details and its method of training. When data is received, it automatically starts the required action. When user A adds the model to the blockchain, it becomes public to other network users. When user B wants to contribute, there are two options; if the model isn’t complex and could be updated with one sample, the user could manually add the input after acquiring a deposit. Alternatively, they needs to add the data set to IPFS, then add that hash to the contract. For the training to occur, attributes of the dataset are required to be similar to the initial ones used to train the model.
<br class="ltx_break">Figure <a href="#Sx4.F5" title="Figure 5 ‣ Data Collection ‣ Proposed approach ‣ Leveraging Centric Data Federated Learning Using Blockchain For Integrity Assurance" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> above describes the steps of the process of training a model in different scenarios. It consists of three users, a virtual wallet, the IPFS, the smart contract, and the Ethereum Blockchain.
<br class="ltx_break"></p>
</div>
<div id="Sx4.SSx3.p2" class="ltx_para">
<p id="Sx4.SSx3.p2.1" class="ltx_p"><span id="Sx4.SSx3.p2.1.1" class="ltx_text ltx_font_bold">The model initialization steps</span></p>
<ul id="Sx4.I6" class="ltx_itemize">
<li id="Sx4.I6.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx4.I6.i1.p1" class="ltx_para">
<p id="Sx4.I6.i1.p1.1" class="ltx_p"><span id="Sx4.I6.i1.p1.1.1" class="ltx_text ltx_font_bold">Step 7:</span> User B downloads the model and the IPFS hash</p>
</div>
</li>
<li id="Sx4.I6.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx4.I6.i2.p1" class="ltx_para">
<p id="Sx4.I6.i2.p1.1" class="ltx_p"><span id="Sx4.I6.i2.p1.1.1" class="ltx_text ltx_font_bold">Step 8:</span> User B accesses IPFS platform and retrieves the file corresponding to the hash</p>
</div>
</li>
<li id="Sx4.I6.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx4.I6.i3.p1" class="ltx_para">
<p id="Sx4.I6.i3.p1.1" class="ltx_p"><span id="Sx4.I6.i3.p1.1.1" class="ltx_text ltx_font_bold">Step 9:</span> User B trains the model on his device</p>
</div>
</li>
<li id="Sx4.I6.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx4.I6.i4.p1" class="ltx_para">
<p id="Sx4.I6.i4.p1.1" class="ltx_p"><span id="Sx4.I6.i4.p1.1.1" class="ltx_text ltx_font_bold">Step 10:</span> User B uploads the model in a new smart contract with references to the previous one</p>
</div>
</li>
<li id="Sx4.I6.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx4.I6.i5.p1" class="ltx_para">
<p id="Sx4.I6.i5.p1.1" class="ltx_p"><span id="Sx4.I6.i5.p1.1.1" class="ltx_text ltx_font_bold">Step 11:</span> User C makes a deposit and adds data to the model that triggers and update function</p>
</div>
</li>
<li id="Sx4.I6.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx4.I6.i6.p1" class="ltx_para">
<p id="Sx4.I6.i6.p1.1" class="ltx_p"><span id="Sx4.I6.i6.p1.1.1" class="ltx_text ltx_font_bold">Step 12:</span> The smart contract starts the training of the model using the new input and tests it using the test data</p>
</div>
</li>
</ul>
</div>
</section>
<section id="Sx4.SSx4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">Implementation</h3>

<div id="Sx4.SSx4.p1" class="ltx_para">
<p id="Sx4.SSx4.p1.1" class="ltx_p">The whole system consists of three main components: back-end blockchain, IPFS storage, and front-end web UI. The client front-end will send a transaction to the blockchain to deploy a User contract for the current account. The user will be provided with an interface to upload the required files, machine learning model, and IPFS file. Previous research proved that blockchain could be suitable. We used Ethereum as our blockchain since it is public and supports smart contracts. On the other hand, IPFS is a distributed storage for our databases. The framework will store the hash of the IPFS file.</p>
</div>
<section id="Sx4.SSx4.SSSx1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Data Hashing</h4>

<div id="Sx4.SSx4.SSSx1.p1" class="ltx_para">
<p id="Sx4.SSx4.SSSx1.p1.1" class="ltx_p">The model owner breaks down the whole dataset into several data groups by using IPFS. It will create an IPFS object and generate a hash leading to the file address. This will allow us to benefit from large datasets without the need to store them inside the blockchain.
<br class="ltx_break">Moreover, the need to have a different hash to the test dataset is required in order to prevent it from being visible to the contributors. This help avoids overfitting problems. We used Sha-256 <cite class="ltx_cite ltx_citemacro_citep">(Appel <a href="#bib.bib2" title="" class="ltx_ref">2015</a>)</cite> as the hashing function for creating different hashed data groups for testing datasets. It is the same hashing algorithm used by IPFS.
<br class="ltx_break"></p>
</div>
<figure id="Sx4.F6" class="ltx_figure"><img src="/html/2206.04731/assets/Figures/Hash.png" id="Sx4.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="349" height="130" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Hashing Process</figcaption>
</figure>
<div id="Sx4.SSx4.SSSx1.p2" class="ltx_para">
<p id="Sx4.SSx4.SSSx1.p2.1" class="ltx_p">As mentioned in figure <a href="#Sx4.F6" title="Figure 6 ‣ Data Hashing ‣ Implementation ‣ Proposed approach ‣ Leveraging Centric Data Federated Learning Using Blockchain For Integrity Assurance" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>, the user needs to split the the data into two datasets, training and testing. Moreover, he needs to run the training dataset throw the IPFS to generate the hash and eventually store it into the smart contract. As for the testing dataset, when added to the framework, a hash function will be generated using the SHA-256 algorithm to obtain a hash value. This value will also be stored in the smart contract.</p>
</div>
</section>
<section id="Sx4.SSx4.SSSx2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Adding Data</h4>

<div id="Sx4.SSx4.SSSx2.p1" class="ltx_para">
<p id="Sx4.SSx4.SSSx2.p1.1" class="ltx_p">We call an add function that will allow the user to add data to the machine learning model either with simple input or as a hash of an IPFS file. This data will aim to train the model inside the blockchain. Those inputs will be later reviewed by contributors thanks to the incentive mechanism that will allow them to benefit from correcting and ensuring the data integrity. Other people could also download the data and use it to train their own machine models as described in figure <a href="#Sx4.F7" title="Figure 7 ‣ Adding Data ‣ Implementation ‣ Proposed approach ‣ Leveraging Centric Data Federated Learning Using Blockchain For Integrity Assurance" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>.</p>
</div>
<figure id="Sx4.F7" class="ltx_figure"><img src="/html/2206.04731/assets/Figures/Inceinteive_Mechanism-Page-1.png" id="Sx4.F7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="314" height="194" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Incentive Mechanism: Data Adding </figcaption>
</figure>
</section>
<section id="Sx4.SSx4.SSSx3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Data Integrity</h4>

<div id="Sx4.SSx4.SSSx3.p1" class="ltx_para">
<p id="Sx4.SSx4.SSSx3.p1.1" class="ltx_p">To ensure the integrity of the data, we implement an incentive mechanism to encourage contributors and oblige each user to insert a deposit to add data to the model to make it costly for malicious users to disturb the model efficiency. It starts with the model owner providing a deposit, reward, and time-out function. It creates the fundamental aspect of our incentive mechanism. The deposit corresponds to the monetary amount that a user needs to make to add data to the smart contract to train the model on-chain. The reward represents the amount that a user will receive when checking the integrity of the data and restoring it. The time-out function defines the time between a return of the deposit and the validation of the owner.
Figure <a href="#Sx4.F8" title="Figure 8 ‣ Data Integrity ‣ Implementation ‣ Proposed approach ‣ Leveraging Centric Data Federated Learning Using Blockchain For Integrity Assurance" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> describes the process of verification. Following a data input, a user has the opportunity to check it due to blockchain transparency.
An Interface shows all the contributors’ transactions, meaning that all added data is visible for the owner and other contributors. If a data is wrong or does not fit the process of learning of the concerned model, he will be allowed to change it and update the model.
<br class="ltx_break"></p>
</div>
<figure id="Sx4.F8" class="ltx_figure"><img src="/html/2206.04731/assets/Figures/Inceinteive_Mechanism-Page-2.png" id="Sx4.F8.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="349" height="214" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>Incentive Mechanism: Data Verification</figcaption>
</figure>
</section>
<section id="Sx4.SSx4.SSSx4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Training Process</h4>

<div id="Sx4.SSx4.SSSx4.p1" class="ltx_para">
<p id="Sx4.SSx4.SSSx4.p1.1" class="ltx_p">The user will be provided with an interface where he creates his customized smart contract. The model owner adds his dataset inside IPFS using a framework interface to store it and then retrieves its corresponding hash. Next, they provide the machine learning model with some description of the model, the data used, and the hash of the IPFS inside the smart contract. Then, they define an amount related to the data verification reward. The smart contract will retrieve that sum from the user’s virtual wallet and store it inside the Ethereum Blockchain. Network participants connect to the framework and access the smart contract to download the model and the IPFS hash to enhance the collaborative training. Using the hash, they obtain the dataset and start training the model off-chain. Finally, they add the updated model to a smart contract and store it in the Blockchain.</p>
</div>
</section>
</section>
</section>
<section id="Sx5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Results</h2>

<div id="Sx5.p1" class="ltx_para">
<p id="Sx5.p1.1" class="ltx_p">Each user will have one separate individual smart contract. They will be able to upload a machine learning model and IPFS file containing the data used to train the model. Meanwhile, contributors will be able to access the smart contract to retrieve the model and the IPFS file. After training and improving the model, they could re-upload it inside the smart contract and the data they used for its training as an IPFS file. The usage of a public blockchain will provide more frequency of contributors willing to validate the data integrity. 
<br class="ltx_break">The model will remain available inside the blockchain for future work with a view of its accuracy. This flow of interaction created an efficient environment for collaborative learning since it managed to make datasets available for all network users either with direct input inside the smart contract when we are dealing with simple inputs or with large ones when adding the file inside IPFS and sharing its hash in the blockchain. Their access will be at no cost. With the presence of the incentive mechanism, we managed to reduce the amount of ambiguous data that could be added to the model. The deposit function makes them costly and unworthy for malicious users. On the other hand, it encourages contributors since discovering those insufficient data benefits them with financial rewards. All of this improves the deployed model’s accuracy and provides usable datasets to test and train models.</p>
</div>
<section id="Sx5.SSx4.SSSx1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Results’ Validation</h4>

<div id="Sx5.SSx4.SSSx1.p1" class="ltx_para">
<p id="Sx5.SSx4.SSSx1.p1.1" class="ltx_p">Analyzing figure <a href="#Sx5.F9" title="Figure 9 ‣ Results’ Validation ‣ Results ‣ Leveraging Centric Data Federated Learning Using Blockchain For Integrity Assurance" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>, we notice that we managed to obtain multiple inputs to our initial dataset. At the beginning of the experiment, the dataset contained 25,000 inputs of data. After using the framework, we observed that the number kept increasing until reaching 25,500 data inputs. An additional 500 data inputs were obtained in just six days with an average of 83 new inputs every day with only two contributors. That proves that our framework could add the data inputted from the contributors into the initial training dataset.</p>
</div>
<figure id="Sx5.F9" class="ltx_figure"><img src="/html/2206.04731/assets/Figures/IMDB_growth.jpg" id="Sx5.F9.g1" class="ltx_graphics ltx_centering ltx_img_square" width="279" height="279" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9: </span>IMDB dataset growth</figcaption>
</figure>
<div id="Sx5.SSx4.SSSx1.p2" class="ltx_para">
<p id="Sx5.SSx4.SSSx1.p2.1" class="ltx_p">Same as the previous dataset, after analyzing figure <a href="#Sx5.F10" title="Figure 10 ‣ Results’ Validation ‣ Results ‣ Leveraging Centric Data Federated Learning Using Blockchain For Integrity Assurance" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a>, we notice that the amount of inputs in the training dataset had increased from 1000 in the initial state to 1100 input. That provides us with an additional 100 pictures in the dataset with their corresponding label.
<br class="ltx_break"></p>
</div>
<figure id="Sx5.F10" class="ltx_figure"><img src="/html/2206.04731/assets/Figures/Hot_dog.jpg" id="Sx5.F10.g1" class="ltx_graphics ltx_img_square" width="279" height="279" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 10: </span>Hotdog-not hotdog dataset growth</figcaption>
</figure>
<div id="Sx5.SSx4.SSSx1.p3" class="ltx_para">
<p id="Sx5.SSx4.SSSx1.p3.1" class="ltx_p">In our framework, any user can participate and train a public model after providing a deposit in cases that deposit contains false data and leads to a lack of quality.
<br class="ltx_break">Our Incentive Mechanism (IM) was created to deal with malicious users that aim to disturb the model accuracy by providing incorrect inputs into to training dataset. By requiring a deposit with each input and a reward mechanism with each verification, we aim to stop those disturbing inputs and encourage other contributors to verify them. Our simulation has yield the following graph <a href="#Sx5.F11" title="Figure 11 ‣ Results’ Validation ‣ Results ‣ Leveraging Centric Data Federated Learning Using Blockchain For Integrity Assurance" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a>.</p>
</div>
<figure id="Sx5.F11" class="ltx_figure"><img src="/html/2206.04731/assets/Figures/Agent_2.jpg" id="Sx5.F11.g1" class="ltx_graphics ltx_centering ltx_img_square" width="279" height="279" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 11: </span>Agents Balance</figcaption>
</figure>
<div id="Sx5.SSx4.SSSx1.p4" class="ltx_para">
<p id="Sx5.SSx4.SSSx1.p4.1" class="ltx_p">Figure <a href="#Sx5.F11" title="Figure 11 ‣ Results’ Validation ‣ Results ‣ Leveraging Centric Data Federated Learning Using Blockchain For Integrity Assurance" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a> represents each contributor’s ether balance, a good agent, and a malicious agent in their virtual wallet. We consider a malicious agent as a network participant who contributes to the model training with inadequate data. We can assume that there is a negative correlation between the two ratios. It is for the fact that after each deposit, the two agents add data to the contract, but while verifying the data, the good agent adjusts the incorrect data. Hence, he obtains a full refund plus a reward amount, while the other agent doesn’t get his deposit. Each time the malicious agent kept adding data, his balance reduced until almost reaching zero.
<br class="ltx_break">As for the accuracy, starting with the IMDB sentiment model, it was initially trained on 20,000 of the 25,000 training data samples, with a model accuracy of 78%.
<br class="ltx_break">We notice that despite the presence of the malicious agent, the presence of the IM, and a good agent, the model was able to train inside the smart contract improving from 78% to 82.9% level of accuracy. This proves that with this model, our framework was efficient in terms of improving the training of the model thanks to the constant contribution of data by the contributors.
<br class="ltx_break">As for the second model, The Hot Dog – Not Hot Dog Model, it was initially trained on the full dataset using the 1000 inputs. By constantly adding data and verifying its integrity, we managed to obtain the following result illustrated in figure <a href="#Sx5.F12" title="Figure 12 ‣ Results’ Validation ‣ Results ‣ Leveraging Centric Data Federated Learning Using Blockchain For Integrity Assurance" class="ltx_ref"><span class="ltx_text ltx_ref_tag">12</span></a>.</p>
</div>
<figure id="Sx5.F12" class="ltx_figure"><img src="/html/2206.04731/assets/Figures/Accuracy.jpg" id="Sx5.F12.g1" class="ltx_graphics ltx_centering ltx_img_square" width="279" height="279" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 12: </span>Accuracy evolution for the two models</figcaption>
</figure>
<div id="Sx5.SSx4.SSSx1.p5" class="ltx_para">
<p id="Sx5.SSx4.SSSx1.p5.1" class="ltx_p">We observed that those added data helped to improve the model accuracy from an initial 59% to 63%. Proving that our smart contract was capable of training the model and that the provided data were beneficial to the accuracy.
<br class="ltx_break"></p>
</div>
</section>
<section id="Sx5.SSx1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">Performance Evaluation</h3>

<div id="Sx5.SSx1.p1" class="ltx_para">
<p id="Sx5.SSx1.p1.1" class="ltx_p">Our framework is expected to deal with many users, so performance and scalability are major factors. However, at this moment, public blockchain throughput is very limited. We use the Ethereum blockchain, allowing around 15 transactions per second with 15-second blocktime. Also, <cite class="ltx_cite ltx_citemacro_citep">(Daniel and Tschorsch <a href="#bib.bib5" title="" class="ltx_ref">2022</a>)</cite> states that IPFS instances possess limited bandwidth leading to low critical scalability of IPFS. Plus, a quantitative analysis <cite class="ltx_cite ltx_citemacro_citep">(Shen et al. <a href="#bib.bib16" title="" class="ltx_ref">2019</a>)</cite> toward IPFS I/O performance from a client perspective showed that operations are performing resolving and downloading result a bottleneck while reading a remote node by an IPFS client. So, scalability still necessitates future improvement for a public blockchain and IPFS to ensure trouble-free for extensive usage.</p>
</div>
<div id="Sx5.SSx1.p2" class="ltx_para">
<p id="Sx5.SSx1.p2.1" class="ltx_p">Nonetheless, when we tested our framework locally running in a single wired LAN, the execution was smooth and rapid, as described in table <a href="#Sx5.T1" title="Table 1 ‣ Performance Evaluation ‣ Results ‣ Leveraging Centric Data Federated Learning Using Blockchain For Integrity Assurance" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. However, with a more significant number of nodes and a distributed wan approach, those results could tremendously alter time execution. In the current version, we use Ethereum as the basic framework; as we run the experimentation locally, we didn’t consider the influence of malicious node
behaviors on data quality. As for deploying the framework on the public Ethereum network, we recommend including machine learning-based detection of malicious Ethereum entities as described by Poursafaei et al <cite class="ltx_cite ltx_citemacro_citep">(Poursafaei, Hamad, and Zilic <a href="#bib.bib13" title="" class="ltx_ref">2020</a>)</cite>.</p>
</div>
<figure id="Sx5.T1" class="ltx_table">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_1">
<table id="Sx5.T1.1" class="ltx_tabular ltx_figure_panel ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="Sx5.T1.1.1.1" class="ltx_tr">
<th id="Sx5.T1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t">Operation</th>
<th id="Sx5.T1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Time of Execution in seconds</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="Sx5.T1.1.2.1" class="ltx_tr">
<th id="Sx5.T1.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">IPFS Node Creation</th>
<td id="Sx5.T1.1.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">2 - 3</td>
</tr>
<tr id="Sx5.T1.1.3.2" class="ltx_tr">
<th id="Sx5.T1.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">Smart Contract Creation</th>
<td id="Sx5.T1.1.3.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">15 - 20</td>
</tr>
<tr id="Sx5.T1.1.4.3" class="ltx_tr">
<th id="Sx5.T1.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">IPFS Hash Upload</th>
<td id="Sx5.T1.1.4.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">2 - 3</td>
</tr>
<tr id="Sx5.T1.1.5.4" class="ltx_tr">
<th id="Sx5.T1.1.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">
<table id="Sx5.T1.1.5.4.1.1" class="ltx_tabular ltx_align_middle">
<tr id="Sx5.T1.1.5.4.1.1.1" class="ltx_tr">
<td id="Sx5.T1.1.5.4.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Consensus &amp;</td>
</tr>
<tr id="Sx5.T1.1.5.4.1.1.2" class="ltx_tr">
<td id="Sx5.T1.1.5.4.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Ledger Update</td>
</tr>
</table>
</th>
<td id="Sx5.T1.1.5.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">2 - 3</td>
</tr>
<tr id="Sx5.T1.1.6.5" class="ltx_tr">
<th id="Sx5.T1.1.6.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">Data Adding</th>
<td id="Sx5.T1.1.6.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1 - 2</td>
</tr>
<tr id="Sx5.T1.1.7.6" class="ltx_tr">
<th id="Sx5.T1.1.7.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">
<table id="Sx5.T1.1.7.6.1.1" class="ltx_tabular ltx_align_middle">
<tr id="Sx5.T1.1.7.6.1.1.1" class="ltx_tr">
<td id="Sx5.T1.1.7.6.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Deposit Payment &amp;</td>
</tr>
<tr id="Sx5.T1.1.7.6.1.1.2" class="ltx_tr">
<td id="Sx5.T1.1.7.6.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Update</td>
</tr>
</table>
</th>
<td id="Sx5.T1.1.7.6.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">2 - 3</td>
</tr>
<tr id="Sx5.T1.1.8.7" class="ltx_tr">
<th id="Sx5.T1.1.8.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">
<table id="Sx5.T1.1.8.7.1.1" class="ltx_tabular ltx_align_middle">
<tr id="Sx5.T1.1.8.7.1.1.1" class="ltx_tr">
<td id="Sx5.T1.1.8.7.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Model Training</td>
</tr>
<tr id="Sx5.T1.1.8.7.1.1.2" class="ltx_tr">
<td id="Sx5.T1.1.8.7.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">With Single Input</td>
</tr>
</table>
</th>
<td id="Sx5.T1.1.8.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1 - 2</td>
</tr>
<tr id="Sx5.T1.1.9.8" class="ltx_tr">
<th id="Sx5.T1.1.9.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">
<table id="Sx5.T1.1.9.8.1.1" class="ltx_tabular ltx_align_middle">
<tr id="Sx5.T1.1.9.8.1.1.1" class="ltx_tr">
<td id="Sx5.T1.1.9.8.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Model Training</td>
</tr>
<tr id="Sx5.T1.1.9.8.1.1.2" class="ltx_tr">
<td id="Sx5.T1.1.9.8.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">With Multiple Input</td>
</tr>
</table>
</th>
<td id="Sx5.T1.1.9.8.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">60 - 80*</td>
</tr>
<tr id="Sx5.T1.1.10.9" class="ltx_tr">
<th id="Sx5.T1.1.10.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">Smart Contract Update</th>
<td id="Sx5.T1.1.10.9.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">2 - 3</td>
</tr>
<tr id="Sx5.T1.1.11.10" class="ltx_tr">
<th id="Sx5.T1.1.11.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">Reward Payment</th>
<td id="Sx5.T1.1.11.10.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1 - 2</td>
</tr>
<tr id="Sx5.T1.1.12.11" class="ltx_tr">
<th id="Sx5.T1.1.12.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">Model Download</th>
<td id="Sx5.T1.1.12.11.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1 - 2</td>
</tr>
<tr id="Sx5.T1.1.13.12" class="ltx_tr">
<th id="Sx5.T1.1.13.12.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t">Dataset Download</th>
<td id="Sx5.T1.1.13.12.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">10 - 15*</td>
</tr>
</tbody>
</table>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<ul id="Sx5.I7" class="ltx_itemize ltx_figure_panel">
<li id="Sx5.I7.ix1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">*</span> 
<div id="Sx5.I7.ix1.p1" class="ltx_para">
<p id="Sx5.I7.ix1.p1.1" class="ltx_p">Can vary tremendously depending the size</p>
</div>
</li>
</ul>
</div>
<div class="ltx_flex_break"></div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span>Framework process time consumption.</figcaption>
</figure>
</section>
</section>
<section id="Sx6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Discussion</h2>

<div id="Sx6.p1" class="ltx_para">
<p id="Sx6.p1.1" class="ltx_p">The study discussed here relates to creating a decentralized environment for collaborative learning of machine learning models. This research seeks to provide public access to datasets, share them, and automate the process of training models. The results acquired prove that leveraging Blockchain and IPFS offer a solid case to achieving our objectives.
<br class="ltx_break">The public blockchain makes such intuitively possible since it offers transparency access to stored data sets by storing their IPFS hashes and smart contracts. We were able to deploy our machine model, thus automating the training process. In addition, IPFS allows the shared files to be decentralized, and it provides a hash specific to that file to access it. Moreover, the results showed that it is non-beneficial and costly to add ambiguous data to the smart contract with the incentive mechanism since it keeps asking for a deposit with each iteration. Previous research demonstrated that blockchain and smart contracts are favorable for training non-complex machine learning models without a higher complex model since storing data in a public blockchain is very costly.
However, with the presence of IPFS, we could store those data without actually storing them and that by only storing the hash of the file, hence the training of more complex models.
<br class="ltx_break">Our framework manages to create a dissent-sharing environment of machine learning resources and an automated training ground for all models. This is considered one of the most considerable system contributions since we managed to train highly complex machine learning models while avoiding Ethereum storage’s high-cost.</p>
</div>
<section id="Sx6.SSx1.SSSx1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Limitations:</h4>

<div id="Sx6.SSx1.SSSx1.p1" class="ltx_para">
<p id="Sx6.SSx1.SSSx1.p1.1" class="ltx_p">Some limitations constrained the methodological choices; with the usage of IPFS, despite the multiple datasets, the incentive mechanism recognizes the file as only one data input, which will cost one date deposit and one data reward for the contributors. So despite the work put in the reward will not be significant.
<br class="ltx_break">Additionally, we didn’t manage to implement the DanKu protocol <cite class="ltx_cite ltx_citemacro_citep">(Kurtulmus and Daniel <a href="#bib.bib9" title="" class="ltx_ref">2018</a>)</cite> due to dependency issues, which cost our system not to evaluate all the updated models inside the same smart contract, leading to creating a new smart contract with each update of the model. Furthermore, it is beyond the scope of this study to acknowledge the required computation power for on-chain training of the model, which could lead to low training efficiency.</p>
</div>
</section>
</section>
<section id="Sx7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Conclusion</h2>

<div id="Sx7.p1" class="ltx_para">
<p id="Sx7.p1.1" class="ltx_p">Our research contributed to creating a decentralized public framework to enhance collaborative learning of the machine learning model on the Ethereum blockchain. The purpose is to provide specialists seeking contribution a network where they could find the right resources to accomplish their work. Data availability is crucial to the improvement of machine learning; hence, they aren’t accessible; thus, this framework could be beneficial for such situations. Training also is a crucial part of our objective. Having the opportunity to train a model publicly is helpful to obtain a higher efficiency and accuracy rate. With their anonymous and distributed nature, smart contracts create a marketplace of model and data sharing without the need for intermediaries. With the association of an Incentive mechanism, quality insurance could be met.
<br class="ltx_break">Future studies should consider improving audit mechanism to optimize the data verification process and eradicate any potential corruption in the network. Also, we will investigate sharing computation power inside the blockchain to enhance the training of highly complex models such as deep learning since GPU needs are becoming essential in training. Blockchain could provide a sharing computation power network where users could share their computation resources inside the blockchain via a smart contract to train on-chain models.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Amiot et al. (2020)</span>
<span class="ltx_bibblock">
Amiot, E.; Palencia, I.; Baena, A.; and de Pommerol, C. 2020.

</span>
<span class="ltx_bibblock">European Digital Sovereignty .

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Appel (2015)</span>
<span class="ltx_bibblock">
Appel, A. W. 2015.

</span>
<span class="ltx_bibblock">Veriﬁcation of a Cryptographic Primitive: SHA-256.

</span>
<span class="ltx_bibblock"><em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">ACM Transactions on Programming Languages and Systems</em>, 31.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Benet (2019)</span>
<span class="ltx_bibblock">
Benet, J. 2019.

</span>
<span class="ltx_bibblock">IPFS - Content Addressed, Versioned, P2P File System.

</span>
<span class="ltx_bibblock">11.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Biderman and Scheirer (2021)</span>
<span class="ltx_bibblock">
Biderman, S.; and Scheirer, W. J. 2021.

</span>
<span class="ltx_bibblock">Pitfalls in Machine Learning Research: Reexamining the
Development Cycle.

</span>
<span class="ltx_bibblock"><em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">arXiv:2011.02832 [cs, stat]</em>.

</span>
<span class="ltx_bibblock">ArXiv: 2011.02832.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Daniel and Tschorsch (2022)</span>
<span class="ltx_bibblock">
Daniel, E.; and Tschorsch, F. 2022.

</span>
<span class="ltx_bibblock">IPFS and Friends: A Qualitative Comparison of Next
Generation Peer-to-Peer Data Networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">arXiv:2102.12737 [cs]</em>.

</span>
<span class="ltx_bibblock">ArXiv: 2102.12737.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Harris and Waggoner (2019)</span>
<span class="ltx_bibblock">
Harris, J. D.; and Waggoner, B. 2019.

</span>
<span class="ltx_bibblock">Decentralized and Collaborative AI on Blockchain.

</span>
<span class="ltx_bibblock">In <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">2019 IEEE International Conference on Blockchain
(Blockchain)</em>, 368–375. Atlanta, GA, USA: IEEE.

</span>
<span class="ltx_bibblock">ISBN 978-1-72814-693-5.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu (2021)</span>
<span class="ltx_bibblock">
Hu, B. 2021.

</span>
<span class="ltx_bibblock">A comprehensive survey on smart contract construction and execution:
paradigms, tools, and systems.

</span>
<span class="ltx_bibblock"><em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">OPEN ACCESS</em>, 51.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim et al. (2020)</span>
<span class="ltx_bibblock">
Kim, H.; Park, J.; Bennis, M.; and Kim, S.-L. 2020.

</span>
<span class="ltx_bibblock">Blockchained On-Device Federated Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">IEEE Communications Letters</em>, 24(6): 1279–1283.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kurtulmus and Daniel (2018)</span>
<span class="ltx_bibblock">
Kurtulmus, A. B.; and Daniel, K. 2018.

</span>
<span class="ltx_bibblock">Trustless Machine Learning Contracts; Evaluating and
Exchanging Machine Learning Models on the Ethereum Blockchain.

</span>
<span class="ltx_bibblock"><em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">arXiv:1802.10185 [cs]</em>.

</span>
<span class="ltx_bibblock">ArXiv: 1802.10185.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ma et al. (2021)</span>
<span class="ltx_bibblock">
Ma, C.; Li, J.; Ding, M.; Shi, L.; Wang, T.; Han, Z.; and Poor, H. V. 2021.

</span>
<span class="ltx_bibblock">When Federated Learning Meets Blockchain: A New
Distributed Learning Paradigm.

</span>
<span class="ltx_bibblock"><em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">arXiv:2009.09338 [cs]</em>.

</span>
<span class="ltx_bibblock">ArXiv: 2009.09338.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Majcherczyk, Srishankar, and
Pinciroli (2020)</span>
<span class="ltx_bibblock">
Majcherczyk, N.; Srishankar, N.; and Pinciroli, C. 2020.

</span>
<span class="ltx_bibblock">Flow-FL: Data-Driven Federated Learning for
Spatio-Temporal Predictions in Multi-Robot Systems.

</span>
<span class="ltx_bibblock"><em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">arXiv:2010.08595 [cs]</em>.

</span>
<span class="ltx_bibblock">ArXiv: 2010.08595.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nakamoto (2008)</span>
<span class="ltx_bibblock">
Nakamoto, S. 2008.

</span>
<span class="ltx_bibblock">Bitcoin: A Peer-to-Peer Electronic Cash System.

</span>
<span class="ltx_bibblock">9.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Poursafaei, Hamad, and Zilic (2020)</span>
<span class="ltx_bibblock">
Poursafaei, F.; Hamad, G. B.; and Zilic, Z. 2020.

</span>
<span class="ltx_bibblock">Detecting Malicious Ethereum Entities via Application of
Machine Learning Classification.

</span>
<span class="ltx_bibblock">In <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">2020 2nd Conference on Blockchain Research &amp;
Applications for Innovative Networks and Services (BRAINS)</em>,
120–127. Paris, France: IEEE.

</span>
<span class="ltx_bibblock">ISBN 978-1-72817-091-6.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ramanan, Nakayama, and Sharma (2019)</span>
<span class="ltx_bibblock">
Ramanan, P.; Nakayama, K.; and Sharma, R. 2019.

</span>
<span class="ltx_bibblock"><em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">BAFFLE : Blockchain based Aggregator Free Federated
Learning</em>.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Roh, Heo, and Whang (2019)</span>
<span class="ltx_bibblock">
Roh, Y.; Heo, G.; and Whang, S. E. 2019.

</span>
<span class="ltx_bibblock">A Survey on Data Collection for Machine Learning: a Big
Data – AI Integration Perspective.

</span>
<span class="ltx_bibblock"><em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">arXiv:1811.03402 [cs, stat]</em>.

</span>
<span class="ltx_bibblock">ArXiv: 1811.03402.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shen et al. (2019)</span>
<span class="ltx_bibblock">
Shen, J.; Li, Y.; Zhou, Y.; and Wang, X. 2019.

</span>
<span class="ltx_bibblock">Understanding I/O performance of IPFS storage: a client’s
perspective.

</span>
<span class="ltx_bibblock">In <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">Proceedings of the International Symposium on Quality
of Service</em>, 1–10. Phoenix Arizona: ACM.

</span>
<span class="ltx_bibblock">ISBN 978-1-4503-6778-3.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Technavio (2020)</span>
<span class="ltx_bibblock">
Technavio. 2020.

</span>
<span class="ltx_bibblock">Machine to Machine Services Market by Technology, End-user, and
Geography - Forecast and Analysis 2020-2024 .

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vujicic, Jagodic, and Randic (2018)</span>
<span class="ltx_bibblock">
Vujicic, D.; Jagodic, D.; and Randic, S. 2018.

</span>
<span class="ltx_bibblock">Blockchain technology, bitcoin, and Ethereum: A brief overview.

</span>
<span class="ltx_bibblock">In <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">2018 17th International Symposium INFOTEH-JAHORINA
(INFOTEH)</em>, 1–6. East Sarajevo: IEEE.

</span>
<span class="ltx_bibblock">ISBN 978-1-5386-4907-7.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang (2018)</span>
<span class="ltx_bibblock">
Wang, T. 2018.

</span>
<span class="ltx_bibblock">A Unified Analytical Framework for Trustable Machine
Learning and Automation Running with Blockchain.

</span>
<span class="ltx_bibblock">In <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">2018 IEEE International Conference on Big Data
(Big Data)</em>, 4974–4983. Seattle, WA, USA: IEEE.

</span>
<span class="ltx_bibblock">ISBN 978-1-5386-5035-6.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xie et al. (2020)</span>
<span class="ltx_bibblock">
Xie, M.; Long, G.; Shen, T.; Zhou, T.; Wang, X.; and Jiang, J. 2020.

</span>
<span class="ltx_bibblock">Multi-Center Federated Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">arXiv:2005.01026 [cs, stat]</em>.

</span>
<span class="ltx_bibblock">ArXiv: 2005.01026.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al. (2019)</span>
<span class="ltx_bibblock">
Yang, Q.; Liu, Y.; Chen, T.; and Tong, Y. 2019.

</span>
<span class="ltx_bibblock">Federated Machine Learning: Concept and Applications.

</span>
<span class="ltx_bibblock"><em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">arXiv:1902.04885 [cs]</em>.

</span>
<span class="ltx_bibblock">ArXiv: 1902.04885.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2206.04730" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2206.04731" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2206.04731">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2206.04731" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2206.04732" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Mon Mar 11 17:16:45 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
