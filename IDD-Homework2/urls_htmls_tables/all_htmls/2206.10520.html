<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2206.10520] SFace: Privacy-friendly and Accurate Face Recognition using Synthetic Data</title><meta property="og:description" content="Recent deep face recognition models proposed in the literature utilized large-scale public datasets such as MS-Celeb-1M and VGGFace2 for training very deep neural networks, achieving state-of-the-art performance on maiâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="SFace: Privacy-friendly and Accurate Face Recognition using Synthetic Data">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="SFace: Privacy-friendly and Accurate Face Recognition using Synthetic Data">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2206.10520">

<!--Generated on Mon Mar 11 16:08:52 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">SFace: Privacy-friendly and Accurate Face Recognition using Synthetic Data</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Fadi Boutros<sup id="id7.7.id1" class="ltx_sup"><span id="id7.7.id1.1" class="ltx_text ltx_font_italic">1,2</span></sup>, Marco Huber<sup id="id8.8.id2" class="ltx_sup"><span id="id8.8.id2.1" class="ltx_text ltx_font_italic">1,2</span></sup>, Patrick Siebke<sup id="id9.9.id3" class="ltx_sup"><span id="id9.9.id3.1" class="ltx_text ltx_font_italic">1</span></sup>, Tim Rieber<sup id="id10.10.id4" class="ltx_sup"><span id="id10.10.id4.1" class="ltx_text ltx_font_italic">1</span></sup>,
Naser Damer<sup id="id11.11.id5" class="ltx_sup"><span id="id11.11.id5.1" class="ltx_text ltx_font_italic">1,2</span></sup> 
<br class="ltx_break">Fraunhofer Institute for Computer Graphics Research IGD,
Darmstadt, Germany
<br class="ltx_break"><sup id="id12.12.id6" class="ltx_sup"><span id="id12.12.id6.1" class="ltx_text ltx_font_italic">2</span></sup>Mathematical and Applied Visual Computing, TU Darmstadt,
Darmstadt, Germany
<br class="ltx_break">Email: fadi.boutros@igd.fraunhofer.de
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id13.id1" class="ltx_p">Recent deep face recognition models proposed in the literature utilized large-scale public datasets such as MS-Celeb-1M and VGGFace2 for training very deep neural networks, achieving state-of-the-art performance on mainstream benchmarks.
Recently, many of these datasets, e.g., MS-Celeb-1M and VGGFace2, are retracted due to credible privacy and ethical concerns. This motivates this work to propose and investigate the feasibility of using a privacy-friendly synthetically generated face dataset to train face recognition models.
Towards this end, we utilize a class-conditional generative adversarial network to generate class labeled synthetic face images, namely SFace.
To address the privacy aspect of using such data to train a face recognition model, we provide extensive evaluation experiments on the identity relation between the synthetic dataset and the original authentic dataset used to train the generative model.
Our reported evaluation proved that associating
an identity of the authentic dataset to one with the same class label in the synthetic dataset is hardly possible.
We also propose to train face recognition on our privacy-friendly dataset, SFace, using three different learning strategies, multi-class classification, label-free knowledge transfer, and combined learning of multi-class classification and knowledge transfer.
The reported evaluation results on five authentic face benchmarks demonstrated that the privacy-friendly synthetic dataset has high potential to be used for training face recognition models, achieving, for example, a verification accuracy of 91.87% on LFW using multi-class classification and 99.13% using the combined learning strategy.
The training code and the synthetic face image dataset are publicly released <span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a target="_blank" href="https://github.com/fdbtrs/SFace-Privacy-friendly-and-Accurate-Face-Recognition-using-Synthetic-Data" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/fdbtrs/SFace-Privacy-friendly-and-Accurate-Face-Recognition-using-Synthetic-Data</a></span></span></span>.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">The advances in deep face recognition (FR) are mainly driven by the architecture, the used loss function, and the availability of large-scale training datasets. In the FR community, a serious discussion has arisen regarding many of the datasets in use, as critical challenges regarding the ethical and legal aspects of creating, using, and sharing, these datasets are increasingly being discussed. Many of the recent face image datasets that are used in the literature have been collected from the web <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> which might conflict with some of the privacy regulations that control the use of personal data without clear consent <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Processing biometric data is governed by a set of legal restrictions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>, <a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>.
Taking the General Data Protection Regulation (GDPR) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite> as an example, it categories biometric data as a special category of personal data subjected to rigorous data protection rules <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>, requiring high protection in connection with fundamental rights and freedoms of individuals.
Dealing with such data requires the adherence to one of the exemptions of biometric data processing <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>, adherence to the related national laws <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite>, maintaining processing records <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>, and the preparation of data protection impact assessment <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>, <a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>, among other restrictions.
Depending on the purpose of the biometric data processing, this set of restrictions can be rigorously extended <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>, <a href="#bib.bib34" title="" class="ltx_ref">34</a>, <a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite>.
Besides the legal complications of using and sharing biometric data, ethical requirements are commonly necessary, such as the approval of an ethics committee or competent authorities.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">A theoretically possible solution to enable the protection of personal data while being able to share biometric data is the personal data anonoymization.
This is far from being a realistic solution given the high anonymization requirements set by authorities like the European Union <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>, in addition to the lack of data utility after anonoymization <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>.
To overcome this issue in conventional anonymization techniques <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>, a more effective and data-driven technique is the use of synthetic data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>, which aims at maintaining utility while permitting research continuation and the adherence to privacy requirements <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>.
Due to the legal privacy regulations briefly discussed above <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite>, collecting, using, sharing, and maintaining face image datasets for biometric processing may not be feasible currently and in the near future.
Some widely-used databases, such as VGGFace2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>,
MS-Celeb-1M <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>,
MegaFace <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> or DukeMTMC <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> are retracted by their creators based on increasing ethical and legal grounds.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">This calls for solutions that take into account the privacy of individuals and the reproducibility and continuity of FR research, which requires shareable face image datasets. With the on-going success of Generative Adversarial Networks (GANs) in creating synthetic data for computer vision tasks (e.g. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite>), a new area of biometric research is emerging to question how synthetic face images can be created and used to train FR models. In comparison to other synthetic data generation challenges, this research faces the challenge of assigning identity in the synthetically generated faces to be utilizable, while additionally insure variations within identity.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2206.10520/assets/overview_v6.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="538" height="379" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.4.2.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S1.F1.2.1" class="ltx_text" style="font-size:90%;">Overview of the proposed approach. On the left, a conditional StyleGAN2-ADA <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> is used in combination with the identity labels to create our synthetic dataset SFace. The identity labels are first embedded and concatenated to the latent variables and then passed to the generator and discriminator of the GAN architecture. The three proposed learning strategies are shown on the right. In the multi-class classification loss learning strategy, the FR Model S is only trained on the synthetic face dataset SFace utilizing CosFace loss <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite>. In the KT learning strategy, KT is utilized between the embedding layer of a pre-trained FR model P, trained on the authentic dataset, and the FR model S. In the combined learning strategy, both approaches are combined using a weighting factor <math id="S1.F1.2.1.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S1.F1.2.1.m1.1b"><mi id="S1.F1.2.1.m1.1.1" xref="S1.F1.2.1.m1.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S1.F1.2.1.m1.1c"><ci id="S1.F1.2.1.m1.1.1.cmml" xref="S1.F1.2.1.m1.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.F1.2.1.m1.1d">\alpha</annotation></semantics></math>. Note that all the three learning strategies do not require privacy-sensitive authentic data, the last two of the three require a pre-trained model, whose sharing does not require the share of personal data, along with the SFace data.</span></figcaption>
</figure>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">Motivated by the above-mentioned challenges, the use of synthetic data in biometrics has recently attracted attention. Zhang et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite> investigated the behavior of face image quality assessment methods on synthetic images created by StyleGAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> and StyleGAN2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> and compare the face image quality values with those of authentic face images. Another biometric use case based on synthetic data that has been studied so far is the creation of a morphing attack detection development dataset from synthetic data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>. Shen et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite> investigated how human individuals perceive synthetically generated faces and showed that humans can be fooled by state-of-the-art synthetic face images. In the field of FR, SynFace <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite> investigated the different behavior of FR models trained on authentic and synthetic images and proposed identity and domain mixup to reduce the performance gap of FR models trained on synthetic data in comparison to FR models trained on authentic data.
Zhai et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite> presented three approaches based on meta-learning, disentangling and filtering to reduce the modal difference between synthetic and authentic samples. Then, they combined synthetic with an authentic dataset to train a FR model.
Another approach in this direction was proposed by Trigueros et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>. They disentangled identity-relevant attributes and non-identity-relevant attributes by training a GAN based on an identity latent space created by an embedding network to perform generative image augmentation.
In contrast, Kortylewski et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> did not use GANs but 3D models to generate synthetic images. These images were then used to reduce dataset bias in real-world datasets.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">In this work, we contribute with a set of proposals towards training FR models without the need for authentic face data.
First, to enable our proposed learning strategies, we created a synthetic face dataset by training a class-conditional GAN using the identities as class labels
Second, we propose to train FR using three different learning strategies based on synthetic images.
The classification loss learning strategy is based on a multi-class classification loss and is trained only with our synthetic images. The knowledge transfer learning strategy is based on using our synthetic data to transfer the information from a pre-trained FR model to train a FR model from scratch without the need for authentic data.
In the combined learning strategy, the two mentioned learning strategies are combined to benefit from the classification optimization and the transferred knowledge, again, without the need for authentic data.
These contributions are accompanied by detailed novel analyses of the relation between the identities in the synthetic data and the authentic data used to train its generative model.
This work also provides an analysis of the effect of the synthetic data size, in terms of samples per identity, on the performance of the trained FR model under the different learning strategies.
Our presented synthetic data and learning strategy proved, by a thorough evaluation on a number of FR benchmarks, to be successful in training FR models in a privacy-friendly framework.
</p>
</div>
<figure id="S1.F2" class="ltx_figure"><img src="/html/2206.10520/assets/dataset_examples_v3_1.png" id="S1.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="419" height="121" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F2.4.2.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S1.F2.2.1" class="ltx_text" style="font-size:90%;">Examples from the authentic (CASIA-WebFace <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite>) and SFace datasets. The synthetic images also show a large variance in appearance and pose. The images from <math id="S1.F2.2.1.m1.1" class="ltx_Math" alttext="ID_{4206}" display="inline"><semantics id="S1.F2.2.1.m1.1b"><mrow id="S1.F2.2.1.m1.1.1" xref="S1.F2.2.1.m1.1.1.cmml"><mi id="S1.F2.2.1.m1.1.1.2" xref="S1.F2.2.1.m1.1.1.2.cmml">I</mi><mo lspace="0em" rspace="0em" id="S1.F2.2.1.m1.1.1.1" xref="S1.F2.2.1.m1.1.1.1.cmml">â€‹</mo><msub id="S1.F2.2.1.m1.1.1.3" xref="S1.F2.2.1.m1.1.1.3.cmml"><mi id="S1.F2.2.1.m1.1.1.3.2" xref="S1.F2.2.1.m1.1.1.3.2.cmml">D</mi><mn id="S1.F2.2.1.m1.1.1.3.3" xref="S1.F2.2.1.m1.1.1.3.3.cmml">4206</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S1.F2.2.1.m1.1c"><apply id="S1.F2.2.1.m1.1.1.cmml" xref="S1.F2.2.1.m1.1.1"><times id="S1.F2.2.1.m1.1.1.1.cmml" xref="S1.F2.2.1.m1.1.1.1"></times><ci id="S1.F2.2.1.m1.1.1.2.cmml" xref="S1.F2.2.1.m1.1.1.2">ğ¼</ci><apply id="S1.F2.2.1.m1.1.1.3.cmml" xref="S1.F2.2.1.m1.1.1.3"><csymbol cd="ambiguous" id="S1.F2.2.1.m1.1.1.3.1.cmml" xref="S1.F2.2.1.m1.1.1.3">subscript</csymbol><ci id="S1.F2.2.1.m1.1.1.3.2.cmml" xref="S1.F2.2.1.m1.1.1.3.2">ğ·</ci><cn type="integer" id="S1.F2.2.1.m1.1.1.3.3.cmml" xref="S1.F2.2.1.m1.1.1.3.3">4206</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F2.2.1.m1.1d">ID_{4206}</annotation></semantics></math> also show that the generated images do not strongly correspond to the identity present in the authentic images but rather to the class.</span></figcaption>
</figure>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Synthetic Face Recognition</span>
</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">In this section, we present our approach to generate and utilize synthetic face images to train a FR model that takes into account the privacy of the subjects depicted in authentic FR datasets. First, we train a conditional generative adversarial network (GAN) based on StyleGAN2-ADA <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> using the authentic dataset and setting the identity labels as class labels to create synthetic data. We then propose three learning strategies to train FR models based on the generated synthetic face images.
An overview of our approach is shown in Figure <a href="#S1.F1" title="Figure 1 â€£ I Introduction â€£ SFace: Privacy-friendly and Accurate Face Recognition using Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
In the first learning strategy, the classification loss learning, we solely train the FR model on the synthetic data. The second learning strategy, the knowledge transfer (KT), the infromation is transferred (on embedding level) from a FR model (pre-trained on authentic images) to train a new model (from scratch) with the support of the generated synthetic data. Last, in the third learning strategy, the combined learning, we successfully propose to combine these two learning strategies.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS1.5.1.1" class="ltx_text">II-A</span> </span><span id="S2.SS1.6.2" class="ltx_text ltx_font_italic">Synthetic Data Generation</span>
</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.2" class="ltx_p">This work utilizes a conditional GAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> to synthetically generate face images.
Specifically, we opt to use StyleGAN2-ADA for synthetic image generation. StyleGAN2-ADA <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> is built on style-based GAN (StyleGAN2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>) with adaptive discriminator augmentation (ADA) to increase the diversity of the training dataset, reducing the risk of overfitting the discriminator when the training data contains little samples. To generate class-conditional synthetic face images, we trained StyleGAN2-ADA <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> under conditional settings, where the class labels in our training setting are the identity labels. Once the model is trained, we construct our synthetic face dataset (noted as SFace) by generating k images from each class <math id="S2.SS1.p1.1.m1.1" class="ltx_Math" alttext="c\in C" display="inline"><semantics id="S2.SS1.p1.1.m1.1a"><mrow id="S2.SS1.p1.1.m1.1.1" xref="S2.SS1.p1.1.m1.1.1.cmml"><mi id="S2.SS1.p1.1.m1.1.1.2" xref="S2.SS1.p1.1.m1.1.1.2.cmml">c</mi><mo id="S2.SS1.p1.1.m1.1.1.1" xref="S2.SS1.p1.1.m1.1.1.1.cmml">âˆˆ</mo><mi id="S2.SS1.p1.1.m1.1.1.3" xref="S2.SS1.p1.1.m1.1.1.3.cmml">C</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.1.m1.1b"><apply id="S2.SS1.p1.1.m1.1.1.cmml" xref="S2.SS1.p1.1.m1.1.1"><in id="S2.SS1.p1.1.m1.1.1.1.cmml" xref="S2.SS1.p1.1.m1.1.1.1"></in><ci id="S2.SS1.p1.1.m1.1.1.2.cmml" xref="S2.SS1.p1.1.m1.1.1.2">ğ‘</ci><ci id="S2.SS1.p1.1.m1.1.1.3.cmml" xref="S2.SS1.p1.1.m1.1.1.3">ğ¶</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.1.m1.1c">c\in C</annotation></semantics></math> (<math id="S2.SS1.p1.2.m2.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S2.SS1.p1.2.m2.1a"><mi id="S2.SS1.p1.2.m2.1.1" xref="S2.SS1.p1.2.m2.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.2.m2.1b"><ci id="S2.SS1.p1.2.m2.1.1.cmml" xref="S2.SS1.p1.2.m2.1.1">ğ¶</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.2.m2.1c">C</annotation></semantics></math> is the number of classes). Examples of the data are shown in Figure <a href="#S1.F2" title="Figure 2 â€£ I Introduction â€£ SFace: Privacy-friendly and Accurate Face Recognition using Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
Besides using this synthetic data to train FR within our learning strategies, the relation between the identities in the synthetic data and the data used to train its generator is later analyzed in section <a href="#S4" title="IV Results â€£ SFace: Privacy-friendly and Accurate Face Recognition using Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV</span></a>.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS2.5.1.1" class="ltx_text">II-B</span> </span><span id="S2.SS2.6.2" class="ltx_text ltx_font_italic">Learning Strategies</span>
</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">To evaluate the feasibility of using synthetically generated face images for FR, we present three learning strategies to train FR models on a synthetically generated dataset. In the first learning strategy, we propose to train the FR model on the synthetic SFace dataset as a multi-class classification problem using conventional classification loss. In the second learning strategy, we propose to train the FR model on SFace with KT from a pre-trained FR model trained on real, authentic data. In the third learning strategy, we combine the first two approaches and propose to fuse the multi-class classification loss with KT into one loss function.</p>
</div>
<section id="S2.SS2.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Multi-class Classification (CLS)</h4>

<div id="S2.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="S2.SS2.SSS0.Px1.p1.6" class="ltx_p">In this learning strategy, we train the FR model solely on the synthetic SFace with the widely used CosFace loss <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite> as multi-class classification loss.
CosFace loss incorporates a margin penalty in the softmax loss to push its decision boundary and thus enhance intra-class compactness and inter-class discrepancy, aiming to improve FR accuracy.
This learning strategy aims to guide the model to learn multi-class classification and then use the obtained network as a feature extractor for FR.
Formally, the CosFace is given by:
</p>
<table id="S2.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center">
<div id="S2.E1.m1.1.1.1" class="ltx_inline-block ltx_markedasmath ltx_transformed_outer" style="width:433.6pt;height:54.5pt;vertical-align:-26.9pt;"><span class="ltx_transformed_inner" style="transform:translate(136.1pt,-8.7pt) scale(2.68684172060164,2.68684172060164) ;">
<p id="S2.E1.m1.1.1.1.1" class="ltx_p"><math id="S2.E1.m1.1.1.1.1.m1.6" class="ltx_Math" alttext="L_{CosFace}=\frac{1}{N}\sum\limits_{i\in N}-log\frac{e^{s(cos(\theta_{y_{i}})-m)}}{e^{s(cos(\theta_{y_{i}})-m)}+\sum\limits_{j=1,j\neq y_{i}}^{c}e^{s(cos(\theta_{j}))}}," display="inline"><semantics id="S2.E1.m1.1.1.1.1.m1.6a"><mrow id="S2.E1.m1.1.1.1.1.m1.6.6.1" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.cmml"><mrow id="S2.E1.m1.1.1.1.1.m1.6.6.1.1" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.cmml"><msub id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.2" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.2.cmml"><mi id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.2.2" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.2.2.cmml">L</mi><mrow id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.2.3" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.2.3.cmml"><mi id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.2.3.2" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.2.3.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.2.3.1" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.2.3.1.cmml">â€‹</mo><mi id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.2.3.3" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.2.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.2.3.1a" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.2.3.1.cmml">â€‹</mo><mi id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.2.3.4" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.2.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.2.3.1b" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.2.3.1.cmml">â€‹</mo><mi id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.2.3.5" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.2.3.5.cmml">F</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.2.3.1c" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.2.3.1.cmml">â€‹</mo><mi id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.2.3.6" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.2.3.6.cmml">a</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.2.3.1d" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.2.3.1.cmml">â€‹</mo><mi id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.2.3.7" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.2.3.7.cmml">c</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.2.3.1e" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.2.3.1.cmml">â€‹</mo><mi id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.2.3.8" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.2.3.8.cmml">e</mi></mrow></msub><mo id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.1" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.1.cmml">=</mo><mrow id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.cmml"><mrow id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.2" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.2.cmml"><mfrac id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.2.2" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.2.2.cmml"><mn id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.2.2.2" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.2.2.2.cmml">1</mn><mi id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.2.2.3" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.2.2.3.cmml">N</mi></mfrac><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.2.1" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.2.1.cmml">â€‹</mo><munder id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.2.3" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.2.3.cmml"><mo movablelimits="false" rspace="0em" id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.2.3.2" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.2.3.2.cmml">âˆ‘</mo><mrow id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.2.3.3" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.2.3.3.cmml"><mi id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.2.3.3.2" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.2.3.3.2.cmml">i</mi><mo id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.2.3.3.1" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.2.3.3.1.cmml">âˆˆ</mo><mi id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.2.3.3.3" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.2.3.3.3.cmml">N</mi></mrow></munder></mrow><mo lspace="0em" id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.1" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.1.cmml">âˆ’</mo><mrow id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.3" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.3.cmml"><mi id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.3.2" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.3.2.cmml">l</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.3.1" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.3.1.cmml">â€‹</mo><mi id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.3.3" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.3.1a" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.3.1.cmml">â€‹</mo><mi id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.3.4" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.3.4.cmml">g</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.3.1b" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.3.1.cmml">â€‹</mo><mfrac id="S2.E1.m1.1.1.1.1.m1.5.5" xref="S2.E1.m1.1.1.1.1.m1.5.5.cmml"><msup id="S2.E1.m1.1.1.1.1.m1.1.1.1" xref="S2.E1.m1.1.1.1.1.m1.1.1.1.cmml"><mi id="S2.E1.m1.1.1.1.1.m1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.m1.1.1.1.3.cmml">e</mi><mrow id="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.cmml"><mi id="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.3.cmml">s</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.cmml"><mrow id="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.1.3.cmml">c</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.1.2.cmml">â€‹</mo><mi id="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.1.4" xref="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.1.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.1.2a" xref="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.1.2.cmml">â€‹</mo><mi id="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.1.5" xref="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.1.5.cmml">s</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.1.2b" xref="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">Î¸</mi><msub id="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.2" xref="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml">y</mi><mi id="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.3" xref="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.3.cmml">i</mi></msub></msub><mo stretchy="false" id="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.2.cmml">âˆ’</mo><mi id="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.3.cmml">m</mi></mrow><mo stretchy="false" id="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></msup><mrow id="S2.E1.m1.1.1.1.1.m1.5.5.5" xref="S2.E1.m1.1.1.1.1.m1.5.5.5.cmml"><msup id="S2.E1.m1.1.1.1.1.m1.5.5.5.6" xref="S2.E1.m1.1.1.1.1.m1.5.5.5.6.cmml"><mi id="S2.E1.m1.1.1.1.1.m1.5.5.5.6.2" xref="S2.E1.m1.1.1.1.1.m1.5.5.5.6.2.cmml">e</mi><mrow id="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1" xref="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.cmml"><mi id="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.3" xref="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.3.cmml">s</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.2" xref="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.2.cmml">â€‹</mo><mrow id="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1" xref="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1.cmml">(</mo><mrow id="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1.cmml"><mrow id="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1.1.cmml"><mi id="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1.1.3.cmml">c</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1.1.2.cmml">â€‹</mo><mi id="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1.1.4" xref="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1.1.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1.1.2a" xref="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1.1.2.cmml">â€‹</mo><mi id="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1.1.5" xref="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1.1.5.cmml">s</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1.1.2b" xref="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1.1.1.1.1.2.cmml">Î¸</mi><msub id="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1.1.1.1.1.3.2" xref="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1.1.1.1.1.3.2.cmml">y</mi><mi id="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1.1.1.1.1.3.3" xref="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1.1.1.1.1.3.3.cmml">i</mi></msub></msub><mo stretchy="false" id="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1.2.cmml">âˆ’</mo><mi id="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1.3.cmml">m</mi></mrow><mo stretchy="false" id="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1.cmml">)</mo></mrow></mrow></msup><mo id="S2.E1.m1.1.1.1.1.m1.5.5.5.5" xref="S2.E1.m1.1.1.1.1.m1.5.5.5.5.cmml">+</mo><mrow id="S2.E1.m1.1.1.1.1.m1.5.5.5.7" xref="S2.E1.m1.1.1.1.1.m1.5.5.5.7.cmml"><mstyle displaystyle="false" id="S2.E1.m1.1.1.1.1.m1.5.5.5.7.1" xref="S2.E1.m1.1.1.1.1.m1.5.5.5.7.1.cmml"><munderover id="S2.E1.m1.1.1.1.1.m1.5.5.5.7.1a" xref="S2.E1.m1.1.1.1.1.m1.5.5.5.7.1.cmml"><mo movablelimits="false" id="S2.E1.m1.1.1.1.1.m1.5.5.5.7.1.2.2" xref="S2.E1.m1.1.1.1.1.m1.5.5.5.7.1.2.2.cmml">âˆ‘</mo><mrow id="S2.E1.m1.1.1.1.1.m1.4.4.4.3.2.2" xref="S2.E1.m1.1.1.1.1.m1.4.4.4.3.2.3.cmml"><mrow id="S2.E1.m1.1.1.1.1.m1.3.3.3.2.1.1.1" xref="S2.E1.m1.1.1.1.1.m1.3.3.3.2.1.1.1.cmml"><mi id="S2.E1.m1.1.1.1.1.m1.3.3.3.2.1.1.1.2" xref="S2.E1.m1.1.1.1.1.m1.3.3.3.2.1.1.1.2.cmml">j</mi><mo id="S2.E1.m1.1.1.1.1.m1.3.3.3.2.1.1.1.1" xref="S2.E1.m1.1.1.1.1.m1.3.3.3.2.1.1.1.1.cmml">=</mo><mn id="S2.E1.m1.1.1.1.1.m1.3.3.3.2.1.1.1.3" xref="S2.E1.m1.1.1.1.1.m1.3.3.3.2.1.1.1.3.cmml">1</mn></mrow><mo id="S2.E1.m1.1.1.1.1.m1.4.4.4.3.2.2.3" xref="S2.E1.m1.1.1.1.1.m1.4.4.4.3.2.3a.cmml">,</mo><mrow id="S2.E1.m1.1.1.1.1.m1.4.4.4.3.2.2.2" xref="S2.E1.m1.1.1.1.1.m1.4.4.4.3.2.2.2.cmml"><mi id="S2.E1.m1.1.1.1.1.m1.4.4.4.3.2.2.2.2" xref="S2.E1.m1.1.1.1.1.m1.4.4.4.3.2.2.2.2.cmml">j</mi><mo id="S2.E1.m1.1.1.1.1.m1.4.4.4.3.2.2.2.1" xref="S2.E1.m1.1.1.1.1.m1.4.4.4.3.2.2.2.1.cmml">â‰ </mo><msub id="S2.E1.m1.1.1.1.1.m1.4.4.4.3.2.2.2.3" xref="S2.E1.m1.1.1.1.1.m1.4.4.4.3.2.2.2.3.cmml"><mi id="S2.E1.m1.1.1.1.1.m1.4.4.4.3.2.2.2.3.2" xref="S2.E1.m1.1.1.1.1.m1.4.4.4.3.2.2.2.3.2.cmml">y</mi><mi id="S2.E1.m1.1.1.1.1.m1.4.4.4.3.2.2.2.3.3" xref="S2.E1.m1.1.1.1.1.m1.4.4.4.3.2.2.2.3.3.cmml">i</mi></msub></mrow></mrow><mi id="S2.E1.m1.1.1.1.1.m1.5.5.5.7.1.3" xref="S2.E1.m1.1.1.1.1.m1.5.5.5.7.1.3.cmml">c</mi></munderover></mstyle><msup id="S2.E1.m1.1.1.1.1.m1.5.5.5.7.2" xref="S2.E1.m1.1.1.1.1.m1.5.5.5.7.2.cmml"><mi id="S2.E1.m1.1.1.1.1.m1.5.5.5.7.2.2" xref="S2.E1.m1.1.1.1.1.m1.5.5.5.7.2.2.cmml">e</mi><mrow id="S2.E1.m1.1.1.1.1.m1.5.5.5.4.1" xref="S2.E1.m1.1.1.1.1.m1.5.5.5.4.1.cmml"><mi id="S2.E1.m1.1.1.1.1.m1.5.5.5.4.1.3" xref="S2.E1.m1.1.1.1.1.m1.5.5.5.4.1.3.cmml">s</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.m1.5.5.5.4.1.2" xref="S2.E1.m1.1.1.1.1.m1.5.5.5.4.1.2.cmml">â€‹</mo><mrow id="S2.E1.m1.1.1.1.1.m1.5.5.5.4.1.1.1" xref="S2.E1.m1.1.1.1.1.m1.5.5.5.4.1.1.1.1.cmml"><mo stretchy="false" id="S2.E1.m1.1.1.1.1.m1.5.5.5.4.1.1.1.2" xref="S2.E1.m1.1.1.1.1.m1.5.5.5.4.1.1.1.1.cmml">(</mo><mrow id="S2.E1.m1.1.1.1.1.m1.5.5.5.4.1.1.1.1" xref="S2.E1.m1.1.1.1.1.m1.5.5.5.4.1.1.1.1.cmml"><mi id="S2.E1.m1.1.1.1.1.m1.5.5.5.4.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.m1.5.5.5.4.1.1.1.1.3.cmml">c</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.m1.5.5.5.4.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.m1.5.5.5.4.1.1.1.1.2.cmml">â€‹</mo><mi id="S2.E1.m1.1.1.1.1.m1.5.5.5.4.1.1.1.1.4" xref="S2.E1.m1.1.1.1.1.m1.5.5.5.4.1.1.1.1.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.m1.5.5.5.4.1.1.1.1.2a" xref="S2.E1.m1.1.1.1.1.m1.5.5.5.4.1.1.1.1.2.cmml">â€‹</mo><mi id="S2.E1.m1.1.1.1.1.m1.5.5.5.4.1.1.1.1.5" xref="S2.E1.m1.1.1.1.1.m1.5.5.5.4.1.1.1.1.5.cmml">s</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.m1.5.5.5.4.1.1.1.1.2b" xref="S2.E1.m1.1.1.1.1.m1.5.5.5.4.1.1.1.1.2.cmml">â€‹</mo><mrow id="S2.E1.m1.1.1.1.1.m1.5.5.5.4.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.m1.5.5.5.4.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.E1.m1.1.1.1.1.m1.5.5.5.4.1.1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.m1.5.5.5.4.1.1.1.1.1.1.1.cmml">(</mo><msub id="S2.E1.m1.1.1.1.1.m1.5.5.5.4.1.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.m1.5.5.5.4.1.1.1.1.1.1.1.cmml"><mi id="S2.E1.m1.1.1.1.1.m1.5.5.5.4.1.1.1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.m1.5.5.5.4.1.1.1.1.1.1.1.2.cmml">Î¸</mi><mi id="S2.E1.m1.1.1.1.1.m1.5.5.5.4.1.1.1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.m1.5.5.5.4.1.1.1.1.1.1.1.3.cmml">j</mi></msub><mo stretchy="false" id="S2.E1.m1.1.1.1.1.m1.5.5.5.4.1.1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.m1.5.5.5.4.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S2.E1.m1.1.1.1.1.m1.5.5.5.4.1.1.1.3" xref="S2.E1.m1.1.1.1.1.m1.5.5.5.4.1.1.1.1.cmml">)</mo></mrow></mrow></msup></mrow></mrow></mfrac></mrow></mrow></mrow><mo id="S2.E1.m1.1.1.1.1.m1.6.6.1.2" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.1.1.1.1.m1.6b"><apply id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.cmml" xref="S2.E1.m1.1.1.1.1.m1.6.6.1"><eq id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.1"></eq><apply id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.2"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.2.1.cmml" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.2">subscript</csymbol><ci id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.2.2.cmml" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.2.2">ğ¿</ci><apply id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.2.3.cmml" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.2.3"><times id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.2.3.1.cmml" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.2.3.1"></times><ci id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.2.3.2.cmml" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.2.3.2">ğ¶</ci><ci id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.2.3.3.cmml" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.2.3.3">ğ‘œ</ci><ci id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.2.3.4.cmml" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.2.3.4">ğ‘ </ci><ci id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.2.3.5.cmml" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.2.3.5">ğ¹</ci><ci id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.2.3.6.cmml" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.2.3.6">ğ‘</ci><ci id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.2.3.7.cmml" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.2.3.7">ğ‘</ci><ci id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.2.3.8.cmml" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.2.3.8">ğ‘’</ci></apply></apply><apply id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.cmml" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3"><minus id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.1.cmml" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.1"></minus><apply id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.2.cmml" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.2"><times id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.2.1.cmml" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.2.1"></times><apply id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.2.2.cmml" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.2.2"><divide id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.2.2.1.cmml" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.2.2"></divide><cn type="integer" id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.2.2.2.cmml" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.2.2.2">1</cn><ci id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.2.2.3.cmml" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.2.2.3">ğ‘</ci></apply><apply id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.2.3.cmml" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.2.3"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.2.3.1.cmml" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.2.3">subscript</csymbol><sum id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.2.3.2.cmml" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.2.3.2"></sum><apply id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.2.3.3.cmml" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.2.3.3"><in id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.2.3.3.1.cmml" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.2.3.3.1"></in><ci id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.2.3.3.2.cmml" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.2.3.3.2">ğ‘–</ci><ci id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.2.3.3.3.cmml" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.2.3.3.3">ğ‘</ci></apply></apply></apply><apply id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.3.cmml" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.3"><times id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.3.1.cmml" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.3.1"></times><ci id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.3.2.cmml" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.3.2">ğ‘™</ci><ci id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.3.3.cmml" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.3.3">ğ‘œ</ci><ci id="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.3.4.cmml" xref="S2.E1.m1.1.1.1.1.m1.6.6.1.1.3.3.4">ğ‘”</ci><apply id="S2.E1.m1.1.1.1.1.m1.5.5.cmml" xref="S2.E1.m1.1.1.1.1.m1.5.5"><divide id="S2.E1.m1.1.1.1.1.m1.5.5.6.cmml" xref="S2.E1.m1.1.1.1.1.m1.5.5"></divide><apply id="S2.E1.m1.1.1.1.1.m1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.m1.1.1.1"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.m1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.m1.1.1.1">superscript</csymbol><ci id="S2.E1.m1.1.1.1.1.m1.1.1.1.3.cmml" xref="S2.E1.m1.1.1.1.1.m1.1.1.1.3">ğ‘’</ci><apply id="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1"><times id="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.2"></times><ci id="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.3.cmml" xref="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.3">ğ‘ </ci><apply id="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1"><minus id="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.2"></minus><apply id="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.1"><times id="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.1.2"></times><ci id="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.1.3">ğ‘</ci><ci id="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.1.4.cmml" xref="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.1.4">ğ‘œ</ci><ci id="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.1.5.cmml" xref="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.1.5">ğ‘ </ci><apply id="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2">ğœƒ</ci><apply id="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.2">ğ‘¦</ci><ci id="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.3">ğ‘–</ci></apply></apply></apply><ci id="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E1.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.3">ğ‘š</ci></apply></apply></apply><apply id="S2.E1.m1.1.1.1.1.m1.5.5.5.cmml" xref="S2.E1.m1.1.1.1.1.m1.5.5.5"><plus id="S2.E1.m1.1.1.1.1.m1.5.5.5.5.cmml" xref="S2.E1.m1.1.1.1.1.m1.5.5.5.5"></plus><apply id="S2.E1.m1.1.1.1.1.m1.5.5.5.6.cmml" xref="S2.E1.m1.1.1.1.1.m1.5.5.5.6"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.m1.5.5.5.6.1.cmml" xref="S2.E1.m1.1.1.1.1.m1.5.5.5.6">superscript</csymbol><ci id="S2.E1.m1.1.1.1.1.m1.5.5.5.6.2.cmml" xref="S2.E1.m1.1.1.1.1.m1.5.5.5.6.2">ğ‘’</ci><apply id="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.cmml" xref="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1"><times id="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.2"></times><ci id="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.3.cmml" xref="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.3">ğ‘ </ci><apply id="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1"><minus id="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1.2"></minus><apply id="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1.1"><times id="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1.1.2"></times><ci id="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1.1.3.cmml" xref="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1.1.3">ğ‘</ci><ci id="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1.1.4.cmml" xref="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1.1.4">ğ‘œ</ci><ci id="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1.1.5.cmml" xref="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1.1.5">ğ‘ </ci><apply id="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1.1.1.1.1.2">ğœƒ</ci><apply id="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1.1.1.1.1.3.2">ğ‘¦</ci><ci id="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1.1.1.1.1.3.3">ğ‘–</ci></apply></apply></apply><ci id="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1.3.cmml" xref="S2.E1.m1.1.1.1.1.m1.2.2.2.1.1.1.1.1.3">ğ‘š</ci></apply></apply></apply><apply id="S2.E1.m1.1.1.1.1.m1.5.5.5.7.cmml" xref="S2.E1.m1.1.1.1.1.m1.5.5.5.7"><apply id="S2.E1.m1.1.1.1.1.m1.5.5.5.7.1.cmml" xref="S2.E1.m1.1.1.1.1.m1.5.5.5.7.1"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.m1.5.5.5.7.1.1.cmml" xref="S2.E1.m1.1.1.1.1.m1.5.5.5.7.1">superscript</csymbol><apply id="S2.E1.m1.1.1.1.1.m1.5.5.5.7.1.2.cmml" xref="S2.E1.m1.1.1.1.1.m1.5.5.5.7.1"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.m1.5.5.5.7.1.2.1.cmml" xref="S2.E1.m1.1.1.1.1.m1.5.5.5.7.1">subscript</csymbol><sum id="S2.E1.m1.1.1.1.1.m1.5.5.5.7.1.2.2.cmml" xref="S2.E1.m1.1.1.1.1.m1.5.5.5.7.1.2.2"></sum><apply id="S2.E1.m1.1.1.1.1.m1.4.4.4.3.2.3.cmml" xref="S2.E1.m1.1.1.1.1.m1.4.4.4.3.2.2"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.m1.4.4.4.3.2.3a.cmml" xref="S2.E1.m1.1.1.1.1.m1.4.4.4.3.2.2.3">formulae-sequence</csymbol><apply id="S2.E1.m1.1.1.1.1.m1.3.3.3.2.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.m1.3.3.3.2.1.1.1"><eq id="S2.E1.m1.1.1.1.1.m1.3.3.3.2.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.m1.3.3.3.2.1.1.1.1"></eq><ci id="S2.E1.m1.1.1.1.1.m1.3.3.3.2.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.m1.3.3.3.2.1.1.1.2">ğ‘—</ci><cn type="integer" id="S2.E1.m1.1.1.1.1.m1.3.3.3.2.1.1.1.3.cmml" xref="S2.E1.m1.1.1.1.1.m1.3.3.3.2.1.1.1.3">1</cn></apply><apply id="S2.E1.m1.1.1.1.1.m1.4.4.4.3.2.2.2.cmml" xref="S2.E1.m1.1.1.1.1.m1.4.4.4.3.2.2.2"><neq id="S2.E1.m1.1.1.1.1.m1.4.4.4.3.2.2.2.1.cmml" xref="S2.E1.m1.1.1.1.1.m1.4.4.4.3.2.2.2.1"></neq><ci id="S2.E1.m1.1.1.1.1.m1.4.4.4.3.2.2.2.2.cmml" xref="S2.E1.m1.1.1.1.1.m1.4.4.4.3.2.2.2.2">ğ‘—</ci><apply id="S2.E1.m1.1.1.1.1.m1.4.4.4.3.2.2.2.3.cmml" xref="S2.E1.m1.1.1.1.1.m1.4.4.4.3.2.2.2.3"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.m1.4.4.4.3.2.2.2.3.1.cmml" xref="S2.E1.m1.1.1.1.1.m1.4.4.4.3.2.2.2.3">subscript</csymbol><ci id="S2.E1.m1.1.1.1.1.m1.4.4.4.3.2.2.2.3.2.cmml" xref="S2.E1.m1.1.1.1.1.m1.4.4.4.3.2.2.2.3.2">ğ‘¦</ci><ci id="S2.E1.m1.1.1.1.1.m1.4.4.4.3.2.2.2.3.3.cmml" xref="S2.E1.m1.1.1.1.1.m1.4.4.4.3.2.2.2.3.3">ğ‘–</ci></apply></apply></apply></apply><ci id="S2.E1.m1.1.1.1.1.m1.5.5.5.7.1.3.cmml" xref="S2.E1.m1.1.1.1.1.m1.5.5.5.7.1.3">ğ‘</ci></apply><apply id="S2.E1.m1.1.1.1.1.m1.5.5.5.7.2.cmml" xref="S2.E1.m1.1.1.1.1.m1.5.5.5.7.2"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.m1.5.5.5.7.2.1.cmml" xref="S2.E1.m1.1.1.1.1.m1.5.5.5.7.2">superscript</csymbol><ci id="S2.E1.m1.1.1.1.1.m1.5.5.5.7.2.2.cmml" xref="S2.E1.m1.1.1.1.1.m1.5.5.5.7.2.2">ğ‘’</ci><apply id="S2.E1.m1.1.1.1.1.m1.5.5.5.4.1.cmml" xref="S2.E1.m1.1.1.1.1.m1.5.5.5.4.1"><times id="S2.E1.m1.1.1.1.1.m1.5.5.5.4.1.2.cmml" xref="S2.E1.m1.1.1.1.1.m1.5.5.5.4.1.2"></times><ci id="S2.E1.m1.1.1.1.1.m1.5.5.5.4.1.3.cmml" xref="S2.E1.m1.1.1.1.1.m1.5.5.5.4.1.3">ğ‘ </ci><apply id="S2.E1.m1.1.1.1.1.m1.5.5.5.4.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.m1.5.5.5.4.1.1.1"><times id="S2.E1.m1.1.1.1.1.m1.5.5.5.4.1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.m1.5.5.5.4.1.1.1.1.2"></times><ci id="S2.E1.m1.1.1.1.1.m1.5.5.5.4.1.1.1.1.3.cmml" xref="S2.E1.m1.1.1.1.1.m1.5.5.5.4.1.1.1.1.3">ğ‘</ci><ci id="S2.E1.m1.1.1.1.1.m1.5.5.5.4.1.1.1.1.4.cmml" xref="S2.E1.m1.1.1.1.1.m1.5.5.5.4.1.1.1.1.4">ğ‘œ</ci><ci id="S2.E1.m1.1.1.1.1.m1.5.5.5.4.1.1.1.1.5.cmml" xref="S2.E1.m1.1.1.1.1.m1.5.5.5.4.1.1.1.1.5">ğ‘ </ci><apply id="S2.E1.m1.1.1.1.1.m1.5.5.5.4.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.m1.5.5.5.4.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.m1.5.5.5.4.1.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.m1.5.5.5.4.1.1.1.1.1.1">subscript</csymbol><ci id="S2.E1.m1.1.1.1.1.m1.5.5.5.4.1.1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.m1.5.5.5.4.1.1.1.1.1.1.1.2">ğœƒ</ci><ci id="S2.E1.m1.1.1.1.1.m1.5.5.5.4.1.1.1.1.1.1.1.3.cmml" xref="S2.E1.m1.1.1.1.1.m1.5.5.5.4.1.1.1.1.1.1.1.3">ğ‘—</ci></apply></apply></apply></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.1.1.1.1.m1.6c">L_{CosFace}=\frac{1}{N}\sum\limits_{i\in N}-log\frac{e^{s(cos(\theta_{y_{i}})-m)}}{e^{s(cos(\theta_{y_{i}})-m)}+\sum\limits_{j=1,j\neq y_{i}}^{c}e^{s(cos(\theta_{j}))}},</annotation></semantics></math></p>
</span></div>
</td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="0" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S2.SS2.SSS0.Px1.p1.5" class="ltx_p">where <math id="S2.SS2.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="m" display="inline"><semantics id="S2.SS2.SSS0.Px1.p1.1.m1.1a"><mi id="S2.SS2.SSS0.Px1.p1.1.m1.1.1" xref="S2.SS2.SSS0.Px1.p1.1.m1.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p1.1.m1.1b"><ci id="S2.SS2.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.1.m1.1.1">ğ‘š</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p1.1.m1.1c">m</annotation></semantics></math> is the margin penalty applied on the cosine angle <math id="S2.SS2.SSS0.Px1.p1.2.m2.1" class="ltx_Math" alttext="cos(\theta_{y_{i}})" display="inline"><semantics id="S2.SS2.SSS0.Px1.p1.2.m2.1a"><mrow id="S2.SS2.SSS0.Px1.p1.2.m2.1.1" xref="S2.SS2.SSS0.Px1.p1.2.m2.1.1.cmml"><mi id="S2.SS2.SSS0.Px1.p1.2.m2.1.1.3" xref="S2.SS2.SSS0.Px1.p1.2.m2.1.1.3.cmml">c</mi><mo lspace="0em" rspace="0em" id="S2.SS2.SSS0.Px1.p1.2.m2.1.1.2" xref="S2.SS2.SSS0.Px1.p1.2.m2.1.1.2.cmml">â€‹</mo><mi id="S2.SS2.SSS0.Px1.p1.2.m2.1.1.4" xref="S2.SS2.SSS0.Px1.p1.2.m2.1.1.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S2.SS2.SSS0.Px1.p1.2.m2.1.1.2a" xref="S2.SS2.SSS0.Px1.p1.2.m2.1.1.2.cmml">â€‹</mo><mi id="S2.SS2.SSS0.Px1.p1.2.m2.1.1.5" xref="S2.SS2.SSS0.Px1.p1.2.m2.1.1.5.cmml">s</mi><mo lspace="0em" rspace="0em" id="S2.SS2.SSS0.Px1.p1.2.m2.1.1.2b" xref="S2.SS2.SSS0.Px1.p1.2.m2.1.1.2.cmml">â€‹</mo><mrow id="S2.SS2.SSS0.Px1.p1.2.m2.1.1.1.1" xref="S2.SS2.SSS0.Px1.p1.2.m2.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.SS2.SSS0.Px1.p1.2.m2.1.1.1.1.2" xref="S2.SS2.SSS0.Px1.p1.2.m2.1.1.1.1.1.cmml">(</mo><msub id="S2.SS2.SSS0.Px1.p1.2.m2.1.1.1.1.1" xref="S2.SS2.SSS0.Px1.p1.2.m2.1.1.1.1.1.cmml"><mi id="S2.SS2.SSS0.Px1.p1.2.m2.1.1.1.1.1.2" xref="S2.SS2.SSS0.Px1.p1.2.m2.1.1.1.1.1.2.cmml">Î¸</mi><msub id="S2.SS2.SSS0.Px1.p1.2.m2.1.1.1.1.1.3" xref="S2.SS2.SSS0.Px1.p1.2.m2.1.1.1.1.1.3.cmml"><mi id="S2.SS2.SSS0.Px1.p1.2.m2.1.1.1.1.1.3.2" xref="S2.SS2.SSS0.Px1.p1.2.m2.1.1.1.1.1.3.2.cmml">y</mi><mi id="S2.SS2.SSS0.Px1.p1.2.m2.1.1.1.1.1.3.3" xref="S2.SS2.SSS0.Px1.p1.2.m2.1.1.1.1.1.3.3.cmml">i</mi></msub></msub><mo stretchy="false" id="S2.SS2.SSS0.Px1.p1.2.m2.1.1.1.1.3" xref="S2.SS2.SSS0.Px1.p1.2.m2.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p1.2.m2.1b"><apply id="S2.SS2.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.2.m2.1.1"><times id="S2.SS2.SSS0.Px1.p1.2.m2.1.1.2.cmml" xref="S2.SS2.SSS0.Px1.p1.2.m2.1.1.2"></times><ci id="S2.SS2.SSS0.Px1.p1.2.m2.1.1.3.cmml" xref="S2.SS2.SSS0.Px1.p1.2.m2.1.1.3">ğ‘</ci><ci id="S2.SS2.SSS0.Px1.p1.2.m2.1.1.4.cmml" xref="S2.SS2.SSS0.Px1.p1.2.m2.1.1.4">ğ‘œ</ci><ci id="S2.SS2.SSS0.Px1.p1.2.m2.1.1.5.cmml" xref="S2.SS2.SSS0.Px1.p1.2.m2.1.1.5">ğ‘ </ci><apply id="S2.SS2.SSS0.Px1.p1.2.m2.1.1.1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.2.m2.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.2.m2.1.1.1.1">subscript</csymbol><ci id="S2.SS2.SSS0.Px1.p1.2.m2.1.1.1.1.1.2.cmml" xref="S2.SS2.SSS0.Px1.p1.2.m2.1.1.1.1.1.2">ğœƒ</ci><apply id="S2.SS2.SSS0.Px1.p1.2.m2.1.1.1.1.1.3.cmml" xref="S2.SS2.SSS0.Px1.p1.2.m2.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px1.p1.2.m2.1.1.1.1.1.3.1.cmml" xref="S2.SS2.SSS0.Px1.p1.2.m2.1.1.1.1.1.3">subscript</csymbol><ci id="S2.SS2.SSS0.Px1.p1.2.m2.1.1.1.1.1.3.2.cmml" xref="S2.SS2.SSS0.Px1.p1.2.m2.1.1.1.1.1.3.2">ğ‘¦</ci><ci id="S2.SS2.SSS0.Px1.p1.2.m2.1.1.1.1.1.3.3.cmml" xref="S2.SS2.SSS0.Px1.p1.2.m2.1.1.1.1.1.3.3">ğ‘–</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p1.2.m2.1c">cos(\theta_{y_{i}})</annotation></semantics></math> between the feature embedding <math id="S2.SS2.SSS0.Px1.p1.3.m3.1" class="ltx_Math" alttext="x_{i}" display="inline"><semantics id="S2.SS2.SSS0.Px1.p1.3.m3.1a"><msub id="S2.SS2.SSS0.Px1.p1.3.m3.1.1" xref="S2.SS2.SSS0.Px1.p1.3.m3.1.1.cmml"><mi id="S2.SS2.SSS0.Px1.p1.3.m3.1.1.2" xref="S2.SS2.SSS0.Px1.p1.3.m3.1.1.2.cmml">x</mi><mi id="S2.SS2.SSS0.Px1.p1.3.m3.1.1.3" xref="S2.SS2.SSS0.Px1.p1.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p1.3.m3.1b"><apply id="S2.SS2.SSS0.Px1.p1.3.m3.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px1.p1.3.m3.1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.3.m3.1.1">subscript</csymbol><ci id="S2.SS2.SSS0.Px1.p1.3.m3.1.1.2.cmml" xref="S2.SS2.SSS0.Px1.p1.3.m3.1.1.2">ğ‘¥</ci><ci id="S2.SS2.SSS0.Px1.p1.3.m3.1.1.3.cmml" xref="S2.SS2.SSS0.Px1.p1.3.m3.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p1.3.m3.1c">x_{i}</annotation></semantics></math> of training sample <math id="S2.SS2.SSS0.Px1.p1.4.m4.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S2.SS2.SSS0.Px1.p1.4.m4.1a"><mi id="S2.SS2.SSS0.Px1.p1.4.m4.1.1" xref="S2.SS2.SSS0.Px1.p1.4.m4.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p1.4.m4.1b"><ci id="S2.SS2.SSS0.Px1.p1.4.m4.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.4.m4.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p1.4.m4.1c">i</annotation></semantics></math> and its class center <math id="S2.SS2.SSS0.Px1.p1.5.m5.1" class="ltx_Math" alttext="y_{i}" display="inline"><semantics id="S2.SS2.SSS0.Px1.p1.5.m5.1a"><msub id="S2.SS2.SSS0.Px1.p1.5.m5.1.1" xref="S2.SS2.SSS0.Px1.p1.5.m5.1.1.cmml"><mi id="S2.SS2.SSS0.Px1.p1.5.m5.1.1.2" xref="S2.SS2.SSS0.Px1.p1.5.m5.1.1.2.cmml">y</mi><mi id="S2.SS2.SSS0.Px1.p1.5.m5.1.1.3" xref="S2.SS2.SSS0.Px1.p1.5.m5.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p1.5.m5.1b"><apply id="S2.SS2.SSS0.Px1.p1.5.m5.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px1.p1.5.m5.1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.5.m5.1.1">subscript</csymbol><ci id="S2.SS2.SSS0.Px1.p1.5.m5.1.1.2.cmml" xref="S2.SS2.SSS0.Px1.p1.5.m5.1.1.2">ğ‘¦</ci><ci id="S2.SS2.SSS0.Px1.p1.5.m5.1.1.3.cmml" xref="S2.SS2.SSS0.Px1.p1.5.m5.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p1.5.m5.1c">y_{i}</annotation></semantics></math>.</p>
</div>
</section>
<section id="S2.SS2.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Knowledge transfer (KT)</h4>

<div id="S2.SS2.SSS0.Px2.p1" class="ltx_para">
<p id="S2.SS2.SSS0.Px2.p1.5" class="ltx_p">In the second learning strategy, we propose to train an FR model (noted as S) on the SFace dataset with KT from the pretrained FR model (noted as P) trained on the authentic dataset. Different than the first learning strategy that incorporates only SFace dataset, this learning strategy requires SFace dataset and access to the P model, which is less privacy-critical than accessing personal biometric data. The main idea is to guide the model S to learn to produce feature representations similar to the ones produced by the model trained on an authentic dataset.
Unlike the multi-class classification learning strategy, KT does not require class label supervision as the loss function is calculated between the feature representations of S and P models.
During the training phase, a batch of SFace dataset is sampled and fed into both models, S and P, to obtain <math id="S2.SS2.SSS0.Px2.p1.1.m1.1" class="ltx_Math" alttext="f^{S}" display="inline"><semantics id="S2.SS2.SSS0.Px2.p1.1.m1.1a"><msup id="S2.SS2.SSS0.Px2.p1.1.m1.1.1" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1.cmml"><mi id="S2.SS2.SSS0.Px2.p1.1.m1.1.1.2" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1.2.cmml">f</mi><mi id="S2.SS2.SSS0.Px2.p1.1.m1.1.1.3" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1.3.cmml">S</mi></msup><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px2.p1.1.m1.1b"><apply id="S2.SS2.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.cmml" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1">superscript</csymbol><ci id="S2.SS2.SSS0.Px2.p1.1.m1.1.1.2.cmml" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1.2">ğ‘“</ci><ci id="S2.SS2.SSS0.Px2.p1.1.m1.1.1.3.cmml" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1.3">ğ‘†</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px2.p1.1.m1.1c">f^{S}</annotation></semantics></math> and <math id="S2.SS2.SSS0.Px2.p1.2.m2.1" class="ltx_Math" alttext="f^{P}" display="inline"><semantics id="S2.SS2.SSS0.Px2.p1.2.m2.1a"><msup id="S2.SS2.SSS0.Px2.p1.2.m2.1.1" xref="S2.SS2.SSS0.Px2.p1.2.m2.1.1.cmml"><mi id="S2.SS2.SSS0.Px2.p1.2.m2.1.1.2" xref="S2.SS2.SSS0.Px2.p1.2.m2.1.1.2.cmml">f</mi><mi id="S2.SS2.SSS0.Px2.p1.2.m2.1.1.3" xref="S2.SS2.SSS0.Px2.p1.2.m2.1.1.3.cmml">P</mi></msup><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px2.p1.2.m2.1b"><apply id="S2.SS2.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S2.SS2.SSS0.Px2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px2.p1.2.m2.1.1.1.cmml" xref="S2.SS2.SSS0.Px2.p1.2.m2.1.1">superscript</csymbol><ci id="S2.SS2.SSS0.Px2.p1.2.m2.1.1.2.cmml" xref="S2.SS2.SSS0.Px2.p1.2.m2.1.1.2">ğ‘“</ci><ci id="S2.SS2.SSS0.Px2.p1.2.m2.1.1.3.cmml" xref="S2.SS2.SSS0.Px2.p1.2.m2.1.1.3">ğ‘ƒ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px2.p1.2.m2.1c">f^{P}</annotation></semantics></math>, respectively. Then, the mean squared error (noted as <math id="S2.SS2.SSS0.Px2.p1.3.m3.1" class="ltx_Math" alttext="L_{KT}" display="inline"><semantics id="S2.SS2.SSS0.Px2.p1.3.m3.1a"><msub id="S2.SS2.SSS0.Px2.p1.3.m3.1.1" xref="S2.SS2.SSS0.Px2.p1.3.m3.1.1.cmml"><mi id="S2.SS2.SSS0.Px2.p1.3.m3.1.1.2" xref="S2.SS2.SSS0.Px2.p1.3.m3.1.1.2.cmml">L</mi><mrow id="S2.SS2.SSS0.Px2.p1.3.m3.1.1.3" xref="S2.SS2.SSS0.Px2.p1.3.m3.1.1.3.cmml"><mi id="S2.SS2.SSS0.Px2.p1.3.m3.1.1.3.2" xref="S2.SS2.SSS0.Px2.p1.3.m3.1.1.3.2.cmml">K</mi><mo lspace="0em" rspace="0em" id="S2.SS2.SSS0.Px2.p1.3.m3.1.1.3.1" xref="S2.SS2.SSS0.Px2.p1.3.m3.1.1.3.1.cmml">â€‹</mo><mi id="S2.SS2.SSS0.Px2.p1.3.m3.1.1.3.3" xref="S2.SS2.SSS0.Px2.p1.3.m3.1.1.3.3.cmml">T</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px2.p1.3.m3.1b"><apply id="S2.SS2.SSS0.Px2.p1.3.m3.1.1.cmml" xref="S2.SS2.SSS0.Px2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px2.p1.3.m3.1.1.1.cmml" xref="S2.SS2.SSS0.Px2.p1.3.m3.1.1">subscript</csymbol><ci id="S2.SS2.SSS0.Px2.p1.3.m3.1.1.2.cmml" xref="S2.SS2.SSS0.Px2.p1.3.m3.1.1.2">ğ¿</ci><apply id="S2.SS2.SSS0.Px2.p1.3.m3.1.1.3.cmml" xref="S2.SS2.SSS0.Px2.p1.3.m3.1.1.3"><times id="S2.SS2.SSS0.Px2.p1.3.m3.1.1.3.1.cmml" xref="S2.SS2.SSS0.Px2.p1.3.m3.1.1.3.1"></times><ci id="S2.SS2.SSS0.Px2.p1.3.m3.1.1.3.2.cmml" xref="S2.SS2.SSS0.Px2.p1.3.m3.1.1.3.2">ğ¾</ci><ci id="S2.SS2.SSS0.Px2.p1.3.m3.1.1.3.3.cmml" xref="S2.SS2.SSS0.Px2.p1.3.m3.1.1.3.3">ğ‘‡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px2.p1.3.m3.1c">L_{KT}</annotation></semantics></math>) is calculated between <math id="S2.SS2.SSS0.Px2.p1.4.m4.1" class="ltx_Math" alttext="f^{S}" display="inline"><semantics id="S2.SS2.SSS0.Px2.p1.4.m4.1a"><msup id="S2.SS2.SSS0.Px2.p1.4.m4.1.1" xref="S2.SS2.SSS0.Px2.p1.4.m4.1.1.cmml"><mi id="S2.SS2.SSS0.Px2.p1.4.m4.1.1.2" xref="S2.SS2.SSS0.Px2.p1.4.m4.1.1.2.cmml">f</mi><mi id="S2.SS2.SSS0.Px2.p1.4.m4.1.1.3" xref="S2.SS2.SSS0.Px2.p1.4.m4.1.1.3.cmml">S</mi></msup><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px2.p1.4.m4.1b"><apply id="S2.SS2.SSS0.Px2.p1.4.m4.1.1.cmml" xref="S2.SS2.SSS0.Px2.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px2.p1.4.m4.1.1.1.cmml" xref="S2.SS2.SSS0.Px2.p1.4.m4.1.1">superscript</csymbol><ci id="S2.SS2.SSS0.Px2.p1.4.m4.1.1.2.cmml" xref="S2.SS2.SSS0.Px2.p1.4.m4.1.1.2">ğ‘“</ci><ci id="S2.SS2.SSS0.Px2.p1.4.m4.1.1.3.cmml" xref="S2.SS2.SSS0.Px2.p1.4.m4.1.1.3">ğ‘†</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px2.p1.4.m4.1c">f^{S}</annotation></semantics></math> and <math id="S2.SS2.SSS0.Px2.p1.5.m5.1" class="ltx_Math" alttext="f^{P}" display="inline"><semantics id="S2.SS2.SSS0.Px2.p1.5.m5.1a"><msup id="S2.SS2.SSS0.Px2.p1.5.m5.1.1" xref="S2.SS2.SSS0.Px2.p1.5.m5.1.1.cmml"><mi id="S2.SS2.SSS0.Px2.p1.5.m5.1.1.2" xref="S2.SS2.SSS0.Px2.p1.5.m5.1.1.2.cmml">f</mi><mi id="S2.SS2.SSS0.Px2.p1.5.m5.1.1.3" xref="S2.SS2.SSS0.Px2.p1.5.m5.1.1.3.cmml">P</mi></msup><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px2.p1.5.m5.1b"><apply id="S2.SS2.SSS0.Px2.p1.5.m5.1.1.cmml" xref="S2.SS2.SSS0.Px2.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px2.p1.5.m5.1.1.1.cmml" xref="S2.SS2.SSS0.Px2.p1.5.m5.1.1">superscript</csymbol><ci id="S2.SS2.SSS0.Px2.p1.5.m5.1.1.2.cmml" xref="S2.SS2.SSS0.Px2.p1.5.m5.1.1.2">ğ‘“</ci><ci id="S2.SS2.SSS0.Px2.p1.5.m5.1.1.3.cmml" xref="S2.SS2.SSS0.Px2.p1.5.m5.1.1.3">ğ‘ƒ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px2.p1.5.m5.1c">f^{P}</annotation></semantics></math> as follows:</p>
<table id="S2.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E2.m1.1" class="ltx_Math" alttext="L_{KT}=\frac{1}{N}\sum\limits_{i\in N}\Big{(}\frac{1}{d}\Sigma_{j=1}^{d}{\Big{(}F^{S}_{ij}-F^{P}_{ij}\Big{)}^{2}\Big{)}}," display="block"><semantics id="S2.E2.m1.1a"><mrow id="S2.E2.m1.1.1.1" xref="S2.E2.m1.1.1.1.1.cmml"><mrow id="S2.E2.m1.1.1.1.1" xref="S2.E2.m1.1.1.1.1.cmml"><msub id="S2.E2.m1.1.1.1.1.3" xref="S2.E2.m1.1.1.1.1.3.cmml"><mi id="S2.E2.m1.1.1.1.1.3.2" xref="S2.E2.m1.1.1.1.1.3.2.cmml">L</mi><mrow id="S2.E2.m1.1.1.1.1.3.3" xref="S2.E2.m1.1.1.1.1.3.3.cmml"><mi id="S2.E2.m1.1.1.1.1.3.3.2" xref="S2.E2.m1.1.1.1.1.3.3.2.cmml">K</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.1.1.1.1.3.3.1" xref="S2.E2.m1.1.1.1.1.3.3.1.cmml">â€‹</mo><mi id="S2.E2.m1.1.1.1.1.3.3.3" xref="S2.E2.m1.1.1.1.1.3.3.3.cmml">T</mi></mrow></msub><mo id="S2.E2.m1.1.1.1.1.2" xref="S2.E2.m1.1.1.1.1.2.cmml">=</mo><mrow id="S2.E2.m1.1.1.1.1.1" xref="S2.E2.m1.1.1.1.1.1.cmml"><mfrac id="S2.E2.m1.1.1.1.1.1.3" xref="S2.E2.m1.1.1.1.1.1.3.cmml"><mn id="S2.E2.m1.1.1.1.1.1.3.2" xref="S2.E2.m1.1.1.1.1.1.3.2.cmml">1</mn><mi id="S2.E2.m1.1.1.1.1.1.3.3" xref="S2.E2.m1.1.1.1.1.1.3.3.cmml">N</mi></mfrac><mo lspace="0em" rspace="0em" id="S2.E2.m1.1.1.1.1.1.2" xref="S2.E2.m1.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S2.E2.m1.1.1.1.1.1.1" xref="S2.E2.m1.1.1.1.1.1.1.cmml"><munder id="S2.E2.m1.1.1.1.1.1.1.2" xref="S2.E2.m1.1.1.1.1.1.1.2.cmml"><mo movablelimits="false" rspace="0em" id="S2.E2.m1.1.1.1.1.1.1.2.2" xref="S2.E2.m1.1.1.1.1.1.1.2.2.cmml">âˆ‘</mo><mrow id="S2.E2.m1.1.1.1.1.1.1.2.3" xref="S2.E2.m1.1.1.1.1.1.1.2.3.cmml"><mi id="S2.E2.m1.1.1.1.1.1.1.2.3.2" xref="S2.E2.m1.1.1.1.1.1.1.2.3.2.cmml">i</mi><mo id="S2.E2.m1.1.1.1.1.1.1.2.3.1" xref="S2.E2.m1.1.1.1.1.1.1.2.3.1.cmml">âˆˆ</mo><mi id="S2.E2.m1.1.1.1.1.1.1.2.3.3" xref="S2.E2.m1.1.1.1.1.1.1.2.3.3.cmml">N</mi></mrow></munder><mrow id="S2.E2.m1.1.1.1.1.1.1.1.1" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.cmml"><mo maxsize="160%" minsize="160%" id="S2.E2.m1.1.1.1.1.1.1.1.1.2" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.E2.m1.1.1.1.1.1.1.1.1.1" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.cmml"><mfrac id="S2.E2.m1.1.1.1.1.1.1.1.1.1.3" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.3.cmml"><mn id="S2.E2.m1.1.1.1.1.1.1.1.1.1.3.2" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.3.2.cmml">1</mn><mi id="S2.E2.m1.1.1.1.1.1.1.1.1.1.3.3" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.3.3.cmml">d</mi></mfrac><mo lspace="0em" rspace="0em" id="S2.E2.m1.1.1.1.1.1.1.1.1.1.2" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.2.cmml">â€‹</mo><msubsup id="S2.E2.m1.1.1.1.1.1.1.1.1.1.4" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.4.cmml"><mi mathvariant="normal" id="S2.E2.m1.1.1.1.1.1.1.1.1.1.4.2.2" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.4.2.2.cmml">Î£</mi><mrow id="S2.E2.m1.1.1.1.1.1.1.1.1.1.4.2.3" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.4.2.3.cmml"><mi id="S2.E2.m1.1.1.1.1.1.1.1.1.1.4.2.3.2" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.4.2.3.2.cmml">j</mi><mo id="S2.E2.m1.1.1.1.1.1.1.1.1.1.4.2.3.1" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.4.2.3.1.cmml">=</mo><mn id="S2.E2.m1.1.1.1.1.1.1.1.1.1.4.2.3.3" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.4.2.3.3.cmml">1</mn></mrow><mi id="S2.E2.m1.1.1.1.1.1.1.1.1.1.4.3" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.4.3.cmml">d</mi></msubsup><mo lspace="0em" rspace="0em" id="S2.E2.m1.1.1.1.1.1.1.1.1.1.2a" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.2.cmml">â€‹</mo><msup id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.cmml"><mrow id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo maxsize="160%" minsize="160%" id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><msubsup id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.2" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.cmml">F</mi><mrow id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.3" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.3.cmml"><mi id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.3.2" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.3.1" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.3.1.cmml">â€‹</mo><mi id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.3.3" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.3.3.cmml">j</mi></mrow><mi id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.3" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.3.cmml">S</mi></msubsup><mo id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">âˆ’</mo><msubsup id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.2.2" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.2.2.cmml">F</mi><mrow id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.3" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.3.cmml"><mi id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.3.2" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.3.1" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.3.1.cmml">â€‹</mo><mi id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.3.3" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.3.3.cmml">j</mi></mrow><mi id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.2.3" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.2.3.cmml">P</mi></msubsup></mrow><mo maxsize="160%" minsize="160%" id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mn id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.3" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.3.cmml">2</mn></msup></mrow><mo maxsize="160%" minsize="160%" id="S2.E2.m1.1.1.1.1.1.1.1.1.3" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S2.E2.m1.1.1.1.2" xref="S2.E2.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E2.m1.1b"><apply id="S2.E2.m1.1.1.1.1.cmml" xref="S2.E2.m1.1.1.1"><eq id="S2.E2.m1.1.1.1.1.2.cmml" xref="S2.E2.m1.1.1.1.1.2"></eq><apply id="S2.E2.m1.1.1.1.1.3.cmml" xref="S2.E2.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.1.1.3.1.cmml" xref="S2.E2.m1.1.1.1.1.3">subscript</csymbol><ci id="S2.E2.m1.1.1.1.1.3.2.cmml" xref="S2.E2.m1.1.1.1.1.3.2">ğ¿</ci><apply id="S2.E2.m1.1.1.1.1.3.3.cmml" xref="S2.E2.m1.1.1.1.1.3.3"><times id="S2.E2.m1.1.1.1.1.3.3.1.cmml" xref="S2.E2.m1.1.1.1.1.3.3.1"></times><ci id="S2.E2.m1.1.1.1.1.3.3.2.cmml" xref="S2.E2.m1.1.1.1.1.3.3.2">ğ¾</ci><ci id="S2.E2.m1.1.1.1.1.3.3.3.cmml" xref="S2.E2.m1.1.1.1.1.3.3.3">ğ‘‡</ci></apply></apply><apply id="S2.E2.m1.1.1.1.1.1.cmml" xref="S2.E2.m1.1.1.1.1.1"><times id="S2.E2.m1.1.1.1.1.1.2.cmml" xref="S2.E2.m1.1.1.1.1.1.2"></times><apply id="S2.E2.m1.1.1.1.1.1.3.cmml" xref="S2.E2.m1.1.1.1.1.1.3"><divide id="S2.E2.m1.1.1.1.1.1.3.1.cmml" xref="S2.E2.m1.1.1.1.1.1.3"></divide><cn type="integer" id="S2.E2.m1.1.1.1.1.1.3.2.cmml" xref="S2.E2.m1.1.1.1.1.1.3.2">1</cn><ci id="S2.E2.m1.1.1.1.1.1.3.3.cmml" xref="S2.E2.m1.1.1.1.1.1.3.3">ğ‘</ci></apply><apply id="S2.E2.m1.1.1.1.1.1.1.cmml" xref="S2.E2.m1.1.1.1.1.1.1"><apply id="S2.E2.m1.1.1.1.1.1.1.2.cmml" xref="S2.E2.m1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.1.1.1.1.2.1.cmml" xref="S2.E2.m1.1.1.1.1.1.1.2">subscript</csymbol><sum id="S2.E2.m1.1.1.1.1.1.1.2.2.cmml" xref="S2.E2.m1.1.1.1.1.1.1.2.2"></sum><apply id="S2.E2.m1.1.1.1.1.1.1.2.3.cmml" xref="S2.E2.m1.1.1.1.1.1.1.2.3"><in id="S2.E2.m1.1.1.1.1.1.1.2.3.1.cmml" xref="S2.E2.m1.1.1.1.1.1.1.2.3.1"></in><ci id="S2.E2.m1.1.1.1.1.1.1.2.3.2.cmml" xref="S2.E2.m1.1.1.1.1.1.1.2.3.2">ğ‘–</ci><ci id="S2.E2.m1.1.1.1.1.1.1.2.3.3.cmml" xref="S2.E2.m1.1.1.1.1.1.1.2.3.3">ğ‘</ci></apply></apply><apply id="S2.E2.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1"><times id="S2.E2.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.2"></times><apply id="S2.E2.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.3"><divide id="S2.E2.m1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.3"></divide><cn type="integer" id="S2.E2.m1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.3.2">1</cn><ci id="S2.E2.m1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.3.3">ğ‘‘</ci></apply><apply id="S2.E2.m1.1.1.1.1.1.1.1.1.1.4.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.4"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.1.1.1.1.1.1.1.4.1.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.4">superscript</csymbol><apply id="S2.E2.m1.1.1.1.1.1.1.1.1.1.4.2.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.4"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.1.1.1.1.1.1.1.4.2.1.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.4">subscript</csymbol><ci id="S2.E2.m1.1.1.1.1.1.1.1.1.1.4.2.2.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.4.2.2">Î£</ci><apply id="S2.E2.m1.1.1.1.1.1.1.1.1.1.4.2.3.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.4.2.3"><eq id="S2.E2.m1.1.1.1.1.1.1.1.1.1.4.2.3.1.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.4.2.3.1"></eq><ci id="S2.E2.m1.1.1.1.1.1.1.1.1.1.4.2.3.2.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.4.2.3.2">ğ‘—</ci><cn type="integer" id="S2.E2.m1.1.1.1.1.1.1.1.1.1.4.2.3.3.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.4.2.3.3">1</cn></apply></apply><ci id="S2.E2.m1.1.1.1.1.1.1.1.1.1.4.3.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.4.3">ğ‘‘</ci></apply><apply id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1">superscript</csymbol><apply id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1"><minus id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1"></minus><apply id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.2">subscript</csymbol><apply id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.1.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.2">superscript</csymbol><ci id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.2">ğ¹</ci><ci id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.3.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.3">ğ‘†</ci></apply><apply id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.3"><times id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.3.1.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.3.1"></times><ci id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.3.2.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.3.2">ğ‘–</ci><ci id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.3.3.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.3.3">ğ‘—</ci></apply></apply><apply id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.3">subscript</csymbol><apply id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.2.1.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.3">superscript</csymbol><ci id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.2.2.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.2.2">ğ¹</ci><ci id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.2.3.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.2.3">ğ‘ƒ</ci></apply><apply id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.3"><times id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.3.1.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.3.1"></times><ci id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.3.2.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.3.2">ğ‘–</ci><ci id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.3.3.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.3.3">ğ‘—</ci></apply></apply></apply><cn type="integer" id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.3">2</cn></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E2.m1.1c">L_{KT}=\frac{1}{N}\sum\limits_{i\in N}\Big{(}\frac{1}{d}\Sigma_{j=1}^{d}{\Big{(}F^{S}_{ij}-F^{P}_{ij}\Big{)}^{2}\Big{)}},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S2.SS2.SSS0.Px2.p1.7" class="ltx_p">where <math id="S2.SS2.SSS0.Px2.p1.6.m1.1" class="ltx_Math" alttext="d" display="inline"><semantics id="S2.SS2.SSS0.Px2.p1.6.m1.1a"><mi id="S2.SS2.SSS0.Px2.p1.6.m1.1.1" xref="S2.SS2.SSS0.Px2.p1.6.m1.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px2.p1.6.m1.1b"><ci id="S2.SS2.SSS0.Px2.p1.6.m1.1.1.cmml" xref="S2.SS2.SSS0.Px2.p1.6.m1.1.1">ğ‘‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px2.p1.6.m1.1c">d</annotation></semantics></math> is the embedding layer size (the last layer before the classification layer) and <math id="S2.SS2.SSS0.Px2.p1.7.m2.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S2.SS2.SSS0.Px2.p1.7.m2.1a"><mi id="S2.SS2.SSS0.Px2.p1.7.m2.1.1" xref="S2.SS2.SSS0.Px2.p1.7.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px2.p1.7.m2.1b"><ci id="S2.SS2.SSS0.Px2.p1.7.m2.1.1.cmml" xref="S2.SS2.SSS0.Px2.p1.7.m2.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px2.p1.7.m2.1c">N</annotation></semantics></math> is the batch size. As this learning strategy does not require class label supervision, it can be used to train FR on any synthetically generated data from unconditional face generative models.</p>
</div>
</section>
<section id="S2.SS2.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Combined learning (CL)</h4>

<div id="S2.SS2.SSS0.Px3.p1" class="ltx_para">
<p id="S2.SS2.SSS0.Px3.p1.2" class="ltx_p">In the third learning strategy, we train the model to learn from the multi-class classification learning (Eq. <a href="#S2.E1" title="In Multi-class Classification (CLS) â€£ II-B Learning Strategies â€£ II Synthetic Face Recognition â€£ SFace: Privacy-friendly and Accurate Face Recognition using Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>) and to produce a feature representation similar to one produced by the model trained on the authentic dataset, i.e. KT (Eq. <a href="#S2.E2" title="In Knowledge transfer (KT) â€£ II-B Learning Strategies â€£ II Synthetic Face Recognition â€£ SFace: Privacy-friendly and Accurate Face Recognition using Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>). The combined loss, in this case, is given by:</p>
<table id="S2.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E3.m1.1" class="ltx_Math" alttext="L_{CL}=\alpha L_{CosFace}+(1-\alpha)L_{KT}," display="block"><semantics id="S2.E3.m1.1a"><mrow id="S2.E3.m1.1.1.1" xref="S2.E3.m1.1.1.1.1.cmml"><mrow id="S2.E3.m1.1.1.1.1" xref="S2.E3.m1.1.1.1.1.cmml"><msub id="S2.E3.m1.1.1.1.1.3" xref="S2.E3.m1.1.1.1.1.3.cmml"><mi id="S2.E3.m1.1.1.1.1.3.2" xref="S2.E3.m1.1.1.1.1.3.2.cmml">L</mi><mrow id="S2.E3.m1.1.1.1.1.3.3" xref="S2.E3.m1.1.1.1.1.3.3.cmml"><mi id="S2.E3.m1.1.1.1.1.3.3.2" xref="S2.E3.m1.1.1.1.1.3.3.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S2.E3.m1.1.1.1.1.3.3.1" xref="S2.E3.m1.1.1.1.1.3.3.1.cmml">â€‹</mo><mi id="S2.E3.m1.1.1.1.1.3.3.3" xref="S2.E3.m1.1.1.1.1.3.3.3.cmml">L</mi></mrow></msub><mo id="S2.E3.m1.1.1.1.1.2" xref="S2.E3.m1.1.1.1.1.2.cmml">=</mo><mrow id="S2.E3.m1.1.1.1.1.1" xref="S2.E3.m1.1.1.1.1.1.cmml"><mrow id="S2.E3.m1.1.1.1.1.1.3" xref="S2.E3.m1.1.1.1.1.1.3.cmml"><mi id="S2.E3.m1.1.1.1.1.1.3.2" xref="S2.E3.m1.1.1.1.1.1.3.2.cmml">Î±</mi><mo lspace="0em" rspace="0em" id="S2.E3.m1.1.1.1.1.1.3.1" xref="S2.E3.m1.1.1.1.1.1.3.1.cmml">â€‹</mo><msub id="S2.E3.m1.1.1.1.1.1.3.3" xref="S2.E3.m1.1.1.1.1.1.3.3.cmml"><mi id="S2.E3.m1.1.1.1.1.1.3.3.2" xref="S2.E3.m1.1.1.1.1.1.3.3.2.cmml">L</mi><mrow id="S2.E3.m1.1.1.1.1.1.3.3.3" xref="S2.E3.m1.1.1.1.1.1.3.3.3.cmml"><mi id="S2.E3.m1.1.1.1.1.1.3.3.3.2" xref="S2.E3.m1.1.1.1.1.1.3.3.3.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S2.E3.m1.1.1.1.1.1.3.3.3.1" xref="S2.E3.m1.1.1.1.1.1.3.3.3.1.cmml">â€‹</mo><mi id="S2.E3.m1.1.1.1.1.1.3.3.3.3" xref="S2.E3.m1.1.1.1.1.1.3.3.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S2.E3.m1.1.1.1.1.1.3.3.3.1a" xref="S2.E3.m1.1.1.1.1.1.3.3.3.1.cmml">â€‹</mo><mi id="S2.E3.m1.1.1.1.1.1.3.3.3.4" xref="S2.E3.m1.1.1.1.1.1.3.3.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S2.E3.m1.1.1.1.1.1.3.3.3.1b" xref="S2.E3.m1.1.1.1.1.1.3.3.3.1.cmml">â€‹</mo><mi id="S2.E3.m1.1.1.1.1.1.3.3.3.5" xref="S2.E3.m1.1.1.1.1.1.3.3.3.5.cmml">F</mi><mo lspace="0em" rspace="0em" id="S2.E3.m1.1.1.1.1.1.3.3.3.1c" xref="S2.E3.m1.1.1.1.1.1.3.3.3.1.cmml">â€‹</mo><mi id="S2.E3.m1.1.1.1.1.1.3.3.3.6" xref="S2.E3.m1.1.1.1.1.1.3.3.3.6.cmml">a</mi><mo lspace="0em" rspace="0em" id="S2.E3.m1.1.1.1.1.1.3.3.3.1d" xref="S2.E3.m1.1.1.1.1.1.3.3.3.1.cmml">â€‹</mo><mi id="S2.E3.m1.1.1.1.1.1.3.3.3.7" xref="S2.E3.m1.1.1.1.1.1.3.3.3.7.cmml">c</mi><mo lspace="0em" rspace="0em" id="S2.E3.m1.1.1.1.1.1.3.3.3.1e" xref="S2.E3.m1.1.1.1.1.1.3.3.3.1.cmml">â€‹</mo><mi id="S2.E3.m1.1.1.1.1.1.3.3.3.8" xref="S2.E3.m1.1.1.1.1.1.3.3.3.8.cmml">e</mi></mrow></msub></mrow><mo id="S2.E3.m1.1.1.1.1.1.2" xref="S2.E3.m1.1.1.1.1.1.2.cmml">+</mo><mrow id="S2.E3.m1.1.1.1.1.1.1" xref="S2.E3.m1.1.1.1.1.1.1.cmml"><mrow id="S2.E3.m1.1.1.1.1.1.1.1.1" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.E3.m1.1.1.1.1.1.1.1.1.2" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.E3.m1.1.1.1.1.1.1.1.1.1" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.cmml"><mn id="S2.E3.m1.1.1.1.1.1.1.1.1.1.2" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.2.cmml">1</mn><mo id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.cmml">âˆ’</mo><mi id="S2.E3.m1.1.1.1.1.1.1.1.1.1.3" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.3.cmml">Î±</mi></mrow><mo stretchy="false" id="S2.E3.m1.1.1.1.1.1.1.1.1.3" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S2.E3.m1.1.1.1.1.1.1.2" xref="S2.E3.m1.1.1.1.1.1.1.2.cmml">â€‹</mo><msub id="S2.E3.m1.1.1.1.1.1.1.3" xref="S2.E3.m1.1.1.1.1.1.1.3.cmml"><mi id="S2.E3.m1.1.1.1.1.1.1.3.2" xref="S2.E3.m1.1.1.1.1.1.1.3.2.cmml">L</mi><mrow id="S2.E3.m1.1.1.1.1.1.1.3.3" xref="S2.E3.m1.1.1.1.1.1.1.3.3.cmml"><mi id="S2.E3.m1.1.1.1.1.1.1.3.3.2" xref="S2.E3.m1.1.1.1.1.1.1.3.3.2.cmml">K</mi><mo lspace="0em" rspace="0em" id="S2.E3.m1.1.1.1.1.1.1.3.3.1" xref="S2.E3.m1.1.1.1.1.1.1.3.3.1.cmml">â€‹</mo><mi id="S2.E3.m1.1.1.1.1.1.1.3.3.3" xref="S2.E3.m1.1.1.1.1.1.1.3.3.3.cmml">T</mi></mrow></msub></mrow></mrow></mrow><mo id="S2.E3.m1.1.1.1.2" xref="S2.E3.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E3.m1.1b"><apply id="S2.E3.m1.1.1.1.1.cmml" xref="S2.E3.m1.1.1.1"><eq id="S2.E3.m1.1.1.1.1.2.cmml" xref="S2.E3.m1.1.1.1.1.2"></eq><apply id="S2.E3.m1.1.1.1.1.3.cmml" xref="S2.E3.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E3.m1.1.1.1.1.3.1.cmml" xref="S2.E3.m1.1.1.1.1.3">subscript</csymbol><ci id="S2.E3.m1.1.1.1.1.3.2.cmml" xref="S2.E3.m1.1.1.1.1.3.2">ğ¿</ci><apply id="S2.E3.m1.1.1.1.1.3.3.cmml" xref="S2.E3.m1.1.1.1.1.3.3"><times id="S2.E3.m1.1.1.1.1.3.3.1.cmml" xref="S2.E3.m1.1.1.1.1.3.3.1"></times><ci id="S2.E3.m1.1.1.1.1.3.3.2.cmml" xref="S2.E3.m1.1.1.1.1.3.3.2">ğ¶</ci><ci id="S2.E3.m1.1.1.1.1.3.3.3.cmml" xref="S2.E3.m1.1.1.1.1.3.3.3">ğ¿</ci></apply></apply><apply id="S2.E3.m1.1.1.1.1.1.cmml" xref="S2.E3.m1.1.1.1.1.1"><plus id="S2.E3.m1.1.1.1.1.1.2.cmml" xref="S2.E3.m1.1.1.1.1.1.2"></plus><apply id="S2.E3.m1.1.1.1.1.1.3.cmml" xref="S2.E3.m1.1.1.1.1.1.3"><times id="S2.E3.m1.1.1.1.1.1.3.1.cmml" xref="S2.E3.m1.1.1.1.1.1.3.1"></times><ci id="S2.E3.m1.1.1.1.1.1.3.2.cmml" xref="S2.E3.m1.1.1.1.1.1.3.2">ğ›¼</ci><apply id="S2.E3.m1.1.1.1.1.1.3.3.cmml" xref="S2.E3.m1.1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S2.E3.m1.1.1.1.1.1.3.3.1.cmml" xref="S2.E3.m1.1.1.1.1.1.3.3">subscript</csymbol><ci id="S2.E3.m1.1.1.1.1.1.3.3.2.cmml" xref="S2.E3.m1.1.1.1.1.1.3.3.2">ğ¿</ci><apply id="S2.E3.m1.1.1.1.1.1.3.3.3.cmml" xref="S2.E3.m1.1.1.1.1.1.3.3.3"><times id="S2.E3.m1.1.1.1.1.1.3.3.3.1.cmml" xref="S2.E3.m1.1.1.1.1.1.3.3.3.1"></times><ci id="S2.E3.m1.1.1.1.1.1.3.3.3.2.cmml" xref="S2.E3.m1.1.1.1.1.1.3.3.3.2">ğ¶</ci><ci id="S2.E3.m1.1.1.1.1.1.3.3.3.3.cmml" xref="S2.E3.m1.1.1.1.1.1.3.3.3.3">ğ‘œ</ci><ci id="S2.E3.m1.1.1.1.1.1.3.3.3.4.cmml" xref="S2.E3.m1.1.1.1.1.1.3.3.3.4">ğ‘ </ci><ci id="S2.E3.m1.1.1.1.1.1.3.3.3.5.cmml" xref="S2.E3.m1.1.1.1.1.1.3.3.3.5">ğ¹</ci><ci id="S2.E3.m1.1.1.1.1.1.3.3.3.6.cmml" xref="S2.E3.m1.1.1.1.1.1.3.3.3.6">ğ‘</ci><ci id="S2.E3.m1.1.1.1.1.1.3.3.3.7.cmml" xref="S2.E3.m1.1.1.1.1.1.3.3.3.7">ğ‘</ci><ci id="S2.E3.m1.1.1.1.1.1.3.3.3.8.cmml" xref="S2.E3.m1.1.1.1.1.1.3.3.3.8">ğ‘’</ci></apply></apply></apply><apply id="S2.E3.m1.1.1.1.1.1.1.cmml" xref="S2.E3.m1.1.1.1.1.1.1"><times id="S2.E3.m1.1.1.1.1.1.1.2.cmml" xref="S2.E3.m1.1.1.1.1.1.1.2"></times><apply id="S2.E3.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1"><minus id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1"></minus><cn type="integer" id="S2.E3.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.2">1</cn><ci id="S2.E3.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.3">ğ›¼</ci></apply><apply id="S2.E3.m1.1.1.1.1.1.1.3.cmml" xref="S2.E3.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E3.m1.1.1.1.1.1.1.3.1.cmml" xref="S2.E3.m1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S2.E3.m1.1.1.1.1.1.1.3.2.cmml" xref="S2.E3.m1.1.1.1.1.1.1.3.2">ğ¿</ci><apply id="S2.E3.m1.1.1.1.1.1.1.3.3.cmml" xref="S2.E3.m1.1.1.1.1.1.1.3.3"><times id="S2.E3.m1.1.1.1.1.1.1.3.3.1.cmml" xref="S2.E3.m1.1.1.1.1.1.1.3.3.1"></times><ci id="S2.E3.m1.1.1.1.1.1.1.3.3.2.cmml" xref="S2.E3.m1.1.1.1.1.1.1.3.3.2">ğ¾</ci><ci id="S2.E3.m1.1.1.1.1.1.1.3.3.3.cmml" xref="S2.E3.m1.1.1.1.1.1.1.3.3.3">ğ‘‡</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E3.m1.1c">L_{CL}=\alpha L_{CosFace}+(1-\alpha)L_{KT},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p id="S2.SS2.SSS0.Px3.p1.1" class="ltx_p">where <math id="S2.SS2.SSS0.Px3.p1.1.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S2.SS2.SSS0.Px3.p1.1.m1.1a"><mi id="S2.SS2.SSS0.Px3.p1.1.m1.1.1" xref="S2.SS2.SSS0.Px3.p1.1.m1.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px3.p1.1.m1.1b"><ci id="S2.SS2.SSS0.Px3.p1.1.m1.1.1.cmml" xref="S2.SS2.SSS0.Px3.p1.1.m1.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px3.p1.1.m1.1c">\alpha</annotation></semantics></math> is a weighting parameter used to balance between the two training losses.</p>
</div>
<div id="S2.SS2.SSS0.Px3.p2" class="ltx_para">
<p id="S2.SS2.SSS0.Px3.p2.1" class="ltx_p">Later in Section <a href="#S4" title="IV Results â€£ SFace: Privacy-friendly and Accurate Face Recognition using Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV</span></a>, we analyze the identity relations between the authentic data and SFace, and the identifiability of the identities in the authentic data using the pre-trained model in comparison to their identifiability using our trained model, to point out the privacy-related enhancements induced by our solution.</p>
</div>
</section>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Experimental Setup</span>
</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">This section presents the experimental setups and implementation details used in this work.
</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS1.5.1.1" class="ltx_text">III-A</span> </span><span id="S3.SS1.6.2" class="ltx_text ltx_font_italic">Datasets and Benchmarks</span>
</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">We used CASIA-WebFace <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite> to train SyleGAN2-ADA and the base (pre-trained) FR model P, this data is noted as the â€authenticâ€ data.
The dataset contains 494,414 images of 10,575 different identities. The images are aligned and cropped to <math id="S3.SS1.p1.1.m1.1" class="ltx_Math" alttext="112\times 112" display="inline"><semantics id="S3.SS1.p1.1.m1.1a"><mrow id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml"><mn id="S3.SS1.p1.1.m1.1.1.2" xref="S3.SS1.p1.1.m1.1.1.2.cmml">112</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p1.1.m1.1.1.1" xref="S3.SS1.p1.1.m1.1.1.1.cmml">Ã—</mo><mn id="S3.SS1.p1.1.m1.1.1.3" xref="S3.SS1.p1.1.m1.1.1.3.cmml">112</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><apply id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1"><times id="S3.SS1.p1.1.m1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1.1"></times><cn type="integer" id="S3.SS1.p1.1.m1.1.1.2.cmml" xref="S3.SS1.p1.1.m1.1.1.2">112</cn><cn type="integer" id="S3.SS1.p1.1.m1.1.1.3.cmml" xref="S3.SS1.p1.1.m1.1.1.3">112</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">112\times 112</annotation></semantics></math> using landmarks obtained by the Multi-task Cascaded Convolutional Networks (MTCNN) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite>, as described in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>.
Our synthetic SFace dataset is constructed, as detailed in Section <a href="#S2" title="II Synthetic Face Recognition â€£ SFace: Privacy-friendly and Accurate Face Recognition using Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a>, using StyleGAN2-ADA conditionally trained on CASIA-WebFace to generate 634K synthetic images (60 images per class) equally distributed on 10,575 classes.
Then, we derived four subsets from SFace noted as SFace-N: SFace-10, SFace-20, SFace-40, and SFace-60, where N is the number of images per class (10,575 classes) in each of the subsets.
SFace-10, SFace-20, SFace-40, and SFace-60 are derived by selecting the first 10, 20, 40, and 60 images of each identity of SFace.
We used SFace-10 (105K images ) to evaluate the identity separability within SFace and the identity relations between SFace identities and those of the authentic data (Casia-WebFace). SFace-20, SFace-40, and SFace-60 are used to investigate the evaluation performance of FR trained on different dataset sizes, along with SFace-10.
The images in SFace are aligned and cropped using the same approach used to preprocess the authentic data.
The presented FR models in this work are evaluated on five benchmarks: Labeled Faces in the Wild (LFW) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>, Cross-age LFW (CALFW) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib50" title="" class="ltx_ref">50</a>]</cite>, Cross-Pose LFW (CPLFW) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite>, Celebrities in Frontal-Profile in the Wild (CFP-FP) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> and AgeDB-30 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>, each using the protocol defined by the benchmark and the respective performance metrics (verification accuracy in %) defined in the benchmark.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS2.5.1.1" class="ltx_text">III-B</span> </span><span id="S3.SS2.6.2" class="ltx_text ltx_font_italic">StyleGAN2-ADA Training Settings</span>
</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">We trained StyleGAN2-ADA <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> on the CASIA-WebFace dataset under conditional settings, i.e. generating images of specific classes. The number of classes is set to 10,575 (number of identities in CASIA-WebFace), which is embedded into a 512-D vector and then concatenated with the latent vector (512-D) to generate class-related synthetic images.
We kept most of the implementation settings of StyleGAN2-ADA unchanged (as set in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>), including the training setup, network architectures, optimizer, and training loss. We have only set the StyleGAN2-ADA model training epochs to 50, the batch-size to 128, and the learning rate to <math id="S3.SS2.p1.1.m1.1" class="ltx_Math" alttext="0.0025" display="inline"><semantics id="S3.SS2.p1.1.m1.1a"><mn id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml">0.0025</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><cn type="float" id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">0.0025</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">0.0025</annotation></semantics></math>.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS3.5.1.1" class="ltx_text">III-C</span> </span><span id="S3.SS3.6.2" class="ltx_text ltx_font_italic">Face Recognition Training Setups</span>
</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">The presented FR models in this paper utilize ResNet-50 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> as a backbone architecture.
We train five instances of ResNet-50. The first instance is trained with CosFace loss <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite> on the authentic CASIA-WebFace dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite> and is used for KT (model P). We followed the parameter selection in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite> for the CosFace loss margin value, and scale parameter to 0.35 and 64, respectively.
The other four instances are trained on the synthetic SFace dataset. The second instance is solely trained with CosFace loss, i.e. CLS, on the SFace dataset. The third instance is trained with only KT loss. The fourth and the fifth instances are trained with the CL loss with <math id="S3.SS3.p1.1.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S3.SS3.p1.1.m1.1a"><mi id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><ci id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">\alpha</annotation></semantics></math> in Equation <a href="#S2.E3" title="In Combined learning (CL) â€£ II-B Learning Strategies â€£ II Synthetic Face Recognition â€£ SFace: Privacy-friendly and Accurate Face Recognition using Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> of 1e-5 and 2e-5, respectively. The models trained on synthetic data are always noted with the training subset (SFace-10, SFace-20, SFace-40, or SFace-60) and the training strategy (CLS, KT, or CL).</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.1" class="ltx_p">The presented models in this paper are implemented using Pytorch <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>.
For all considered FR models, we set the mini-batch size to 512 and train the FR models with Stochastic Gradient Descent (SGD) optimizer.We set the momentum to 0.9 and the weight decay to 5e-4.
The FR models trained on the synthetic SFace required 64 epochs to converge and the one trained on authentic data required 32 epochs to converge.
The initial learning rate is set 1e-1 and divided by 10 at 40, 48, and 52 epochs for the models trained on SFace and divided by 10 at 20 and 28 epochs for the model trained on the authentic dataset.
During the training, we used random horizontal flipping with a probability of 0.5 for data augmentation. All training and testing images are normalized to have pixel values between -1 and 1.</p>
</div>
<figure id="S3.T1" class="ltx_table">
<div id="S3.T1.2" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:95.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(53.8pt,-11.9pt) scale(1.3302337617011,1.3302337617011) ;">
<table id="S3.T1.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T1.2.1.1" class="ltx_tr">
<td id="S3.T1.2.1.1.1" class="ltx_td ltx_border_t"></td>
<td id="S3.T1.2.1.1.2" class="ltx_td ltx_align_left ltx_border_t">EER (%)</td>
<td id="S3.T1.2.1.1.3" class="ltx_td ltx_align_left ltx_border_t">FMR100 (%)</td>
<td id="S3.T1.2.1.1.4" class="ltx_td ltx_align_left ltx_border_t">FMR1000 (%)</td>
</tr>
<tr id="S3.T1.2.1.2" class="ltx_tr">
<td id="S3.T1.2.1.2.1" class="ltx_td ltx_align_left ltx_border_t">SFace</td>
<td id="S3.T1.2.1.2.2" class="ltx_td ltx_align_left ltx_border_t">21.650</td>
<td id="S3.T1.2.1.2.3" class="ltx_td ltx_align_left ltx_border_t">62.275</td>
<td id="S3.T1.2.1.2.4" class="ltx_td ltx_align_left ltx_border_t">83.962</td>
</tr>
<tr id="S3.T1.2.1.3" class="ltx_tr">
<td id="S3.T1.2.1.3.1" class="ltx_td ltx_align_left">CASIA-WebFace</td>
<td id="S3.T1.2.1.3.2" class="ltx_td ltx_align_left">7.614</td>
<td id="S3.T1.2.1.3.3" class="ltx_td ltx_align_left">9.152</td>
<td id="S3.T1.2.1.3.4" class="ltx_td ltx_align_left">10.712</td>
</tr>
<tr id="S3.T1.2.1.4" class="ltx_tr">
<td id="S3.T1.2.1.4.1" class="ltx_td ltx_align_left ltx_border_b">CASIA-WebFace vs. SFace</td>
<td id="S3.T1.2.1.4.2" class="ltx_td ltx_align_left ltx_border_b">29.204</td>
<td id="S3.T1.2.1.4.3" class="ltx_td ltx_align_left ltx_border_b">74.662</td>
<td id="S3.T1.2.1.4.4" class="ltx_td ltx_align_left ltx_border_b">88.692</td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S3.T1.3.1.1" class="ltx_text" style="font-size:90%;">TABLE I</span>: </span><span id="S3.T1.4.2" class="ltx_text" style="font-size:90%;">Verification performances reported on three evaluation settings, SFace-10, CASIA-WebFace, and cross-dataset (reference images are taken from CASIA-WebFace and probe images are taken from SFace-10).
The low verification performance in the cross-dataset evaluation is observable, proving that SFace-10 and CASIA-WebFace identities are hardly associated.</span></figcaption>
</figure>
<figure id="S3.F3" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S3.F3.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2206.10520/assets/x1.png" id="S3.F3.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="346" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S3.F3.sf1.3.2" class="ltx_text" style="font-size:90%;">CASIA-WebFace

<br class="ltx_break"></span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S3.F3.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2206.10520/assets/x2.png" id="S3.F3.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="346" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S3.F3.sf2.3.2" class="ltx_text" style="font-size:90%;">SFace-10

<br class="ltx_break"></span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S3.F3.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2206.10520/assets/x3.png" id="S3.F3.sf3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="346" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="S3.F3.sf3.3.2" class="ltx_text" style="font-size:90%;">
CASIA-WebFace - SFace-10

<br class="ltx_break">Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S3.F3.sf4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2206.10520/assets/x4.png" id="S3.F3.sf4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="346" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.sf4.2.1.1" class="ltx_text" style="font-size:90%;">(d)</span> </span><span id="S3.F3.sf4.3.2" class="ltx_text" style="font-size:90%;">CASIA-WebFace - SFace-10 vs. Casia-WebFace </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.2.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S3.F3.3.2" class="ltx_text" style="font-size:90%;">
The genuine and imposter score distributions of different experimental settings. The genuine score distribution is overlapping with the imposter score distribution in the SFace-10 (Figure. <a href="#S3.F3.sf2" title="In Figure 3 â€£ III-C Face Recognition Training Setups â€£ III Experimental Setup â€£ SFace: Privacy-friendly and Accurate Face Recognition using Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3(b)</span></a>) in comparison to the authentic data in <a href="#S3.F3.sf1" title="In Figure 3 â€£ III-C Face Recognition Training Setups â€£ III Experimental Setup â€£ SFace: Privacy-friendly and Accurate Face Recognition using Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3(a)</span></a>. However, this overlap is lower than that in the cross-dataset evaluation (Figure. <a href="#S3.F3.sf3" title="In Figure 3 â€£ III-C Face Recognition Training Setups â€£ III Experimental Setup â€£ SFace: Privacy-friendly and Accurate Face Recognition using Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3(c)</span></a> and <a href="#S3.F3.sf4" title="In Figure 3 â€£ III-C Face Recognition Training Setups â€£ III Experimental Setup â€£ SFace: Privacy-friendly and Accurate Face Recognition using Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3(d)</span></a>), indicating weak identity link between the authentic data and the SFace data. The comparison scores are based on the cosine similarity calculated between the embeddings extracted by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> as described in Section <a href="#S3.SS4" title="III-D Evaluation Metrics â€£ III Experimental Setup â€£ SFace: Privacy-friendly and Accurate Face Recognition using Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">III-D</span></span></a>.
</span></figcaption>
</figure>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS4.5.1.1" class="ltx_text">III-D</span> </span><span id="S3.SS4.6.2" class="ltx_text ltx_font_italic">Evaluation Metrics</span>
</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.2" class="ltx_p">In this work, we investigate the identity-separability in the synthetic SFace dataset, and the identity-relation between SFace and the authentic CASIA-WebFace dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite> used to train the generative model. To achieve that, we report the verification performances of SFace, CASIA-WebFace, and cross-evaluation setting where the references are from Casia-WebFace and the probes are from SFace, using the conditional classes used for the StyleGan2-ADA as an identity label.
As SFace and Casia-WebFace, do not contain pre-defined comparison pairs, we considered the first two images of each identity in each dataset as a reference, and the rest are considered probes.
The verification performance is reported as
FMR100, and FMR1000, which are the lowest false non-match rate (FNMR) for a false match rate (FMR)<math id="S3.SS4.p1.1.m1.1" class="ltx_Math" alttext="\leq" display="inline"><semantics id="S3.SS4.p1.1.m1.1a"><mo id="S3.SS4.p1.1.m1.1.1" xref="S3.SS4.p1.1.m1.1.1.cmml">â‰¤</mo><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.1.m1.1b"><leq id="S3.SS4.p1.1.m1.1.1.cmml" xref="S3.SS4.p1.1.m1.1.1"></leq></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.1.m1.1c">\leq</annotation></semantics></math>1.0% and <math id="S3.SS4.p1.2.m2.1" class="ltx_Math" alttext="\leq" display="inline"><semantics id="S3.SS4.p1.2.m2.1a"><mo id="S3.SS4.p1.2.m2.1.1" xref="S3.SS4.p1.2.m2.1.1.cmml">â‰¤</mo><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.2.m2.1b"><leq id="S3.SS4.p1.2.m2.1.1.cmml" xref="S3.SS4.p1.2.m2.1.1"></leq></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.2.m2.1c">\leq</annotation></semantics></math>0.1%, respectively, along with the Equal Error Rate (EER) representing FMR or FNMR at the decision threshold where they are equal.
The verification performances are indicated by plotting the histogram of genuine and imposter score distribution plots. We used a pre-trained ElasticFace <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> model <span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>The network architecture of ElasticFace-Arc (CVPRW2022 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>) is ResNet100 trained on MS1MV2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> by ElasticFace authors (model publicly available).</span></span></span> to extract the feature embeddings of SFace and CASIA-WebFace for the investigations describe in this subsection.</p>
</div>
<div id="S3.SS4.p2" class="ltx_para">
<p id="S3.SS4.p2.1" class="ltx_p">The resulting FR models trained on our SFace dataset are evaluated on a set of widely used face recognition benchmarks and the reported performances follow the benchmarks defined evaluation protocols and metrics, all mentioned earlier in Section <a href="#S3.SS1" title="III-A Datasets and Benchmarks â€£ III Experimental Setup â€£ SFace: Privacy-friendly and Accurate Face Recognition using Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">III-A</span></span></a>.</p>
</div>
<figure id="S3.T2" class="ltx_table">
<table id="S3.T2.2" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S3.T2.2.2" class="ltx_tr">
<td id="S3.T2.2.2.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" colspan="2">Model / Training dataset</td>
<td id="S3.T2.2.2.4" class="ltx_td ltx_align_left ltx_border_t">
<table id="S3.T2.2.2.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T2.2.2.4.1.1" class="ltx_tr">
<td id="S3.T2.2.2.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">CLS/</td>
</tr>
<tr id="S3.T2.2.2.4.1.2" class="ltx_tr">
<td id="S3.T2.2.2.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">CASIA-WebFace</td>
</tr>
</table>
</td>
<td id="S3.T2.2.2.5" class="ltx_td ltx_align_left ltx_border_t">
<table id="S3.T2.2.2.5.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T2.2.2.5.1.1" class="ltx_tr">
<td id="S3.T2.2.2.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">CLS/</td>
</tr>
<tr id="S3.T2.2.2.5.1.2" class="ltx_tr">
<td id="S3.T2.2.2.5.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">SFace-10</td>
</tr>
</table>
</td>
<td id="S3.T2.1.1.1" class="ltx_td ltx_align_left ltx_border_t">
<table id="S3.T2.1.1.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T2.1.1.1.1.1" class="ltx_tr">
<td id="S3.T2.1.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">CL (<math id="S3.T2.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\alpha=2e-5" display="inline"><semantics id="S3.T2.1.1.1.1.1.1.m1.1a"><mrow id="S3.T2.1.1.1.1.1.1.m1.1.1" xref="S3.T2.1.1.1.1.1.1.m1.1.1.cmml"><mi id="S3.T2.1.1.1.1.1.1.m1.1.1.2" xref="S3.T2.1.1.1.1.1.1.m1.1.1.2.cmml">Î±</mi><mo id="S3.T2.1.1.1.1.1.1.m1.1.1.1" xref="S3.T2.1.1.1.1.1.1.m1.1.1.1.cmml">=</mo><mrow id="S3.T2.1.1.1.1.1.1.m1.1.1.3" xref="S3.T2.1.1.1.1.1.1.m1.1.1.3.cmml"><mrow id="S3.T2.1.1.1.1.1.1.m1.1.1.3.2" xref="S3.T2.1.1.1.1.1.1.m1.1.1.3.2.cmml"><mn id="S3.T2.1.1.1.1.1.1.m1.1.1.3.2.2" xref="S3.T2.1.1.1.1.1.1.m1.1.1.3.2.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S3.T2.1.1.1.1.1.1.m1.1.1.3.2.1" xref="S3.T2.1.1.1.1.1.1.m1.1.1.3.2.1.cmml">â€‹</mo><mi id="S3.T2.1.1.1.1.1.1.m1.1.1.3.2.3" xref="S3.T2.1.1.1.1.1.1.m1.1.1.3.2.3.cmml">e</mi></mrow><mo id="S3.T2.1.1.1.1.1.1.m1.1.1.3.1" xref="S3.T2.1.1.1.1.1.1.m1.1.1.3.1.cmml">âˆ’</mo><mn id="S3.T2.1.1.1.1.1.1.m1.1.1.3.3" xref="S3.T2.1.1.1.1.1.1.m1.1.1.3.3.cmml">5</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T2.1.1.1.1.1.1.m1.1b"><apply id="S3.T2.1.1.1.1.1.1.m1.1.1.cmml" xref="S3.T2.1.1.1.1.1.1.m1.1.1"><eq id="S3.T2.1.1.1.1.1.1.m1.1.1.1.cmml" xref="S3.T2.1.1.1.1.1.1.m1.1.1.1"></eq><ci id="S3.T2.1.1.1.1.1.1.m1.1.1.2.cmml" xref="S3.T2.1.1.1.1.1.1.m1.1.1.2">ğ›¼</ci><apply id="S3.T2.1.1.1.1.1.1.m1.1.1.3.cmml" xref="S3.T2.1.1.1.1.1.1.m1.1.1.3"><minus id="S3.T2.1.1.1.1.1.1.m1.1.1.3.1.cmml" xref="S3.T2.1.1.1.1.1.1.m1.1.1.3.1"></minus><apply id="S3.T2.1.1.1.1.1.1.m1.1.1.3.2.cmml" xref="S3.T2.1.1.1.1.1.1.m1.1.1.3.2"><times id="S3.T2.1.1.1.1.1.1.m1.1.1.3.2.1.cmml" xref="S3.T2.1.1.1.1.1.1.m1.1.1.3.2.1"></times><cn type="integer" id="S3.T2.1.1.1.1.1.1.m1.1.1.3.2.2.cmml" xref="S3.T2.1.1.1.1.1.1.m1.1.1.3.2.2">2</cn><ci id="S3.T2.1.1.1.1.1.1.m1.1.1.3.2.3.cmml" xref="S3.T2.1.1.1.1.1.1.m1.1.1.3.2.3">ğ‘’</ci></apply><cn type="integer" id="S3.T2.1.1.1.1.1.1.m1.1.1.3.3.cmml" xref="S3.T2.1.1.1.1.1.1.m1.1.1.3.3">5</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.1.1.1.1.1.1.m1.1c">\alpha=2e-5</annotation></semantics></math>)/</td>
</tr>
<tr id="S3.T2.1.1.1.1.2" class="ltx_tr">
<td id="S3.T2.1.1.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">SFace-10</td>
</tr>
</table>
</td>
<td id="S3.T2.2.2.2" class="ltx_td ltx_align_left ltx_border_t">
<table id="S3.T2.2.2.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T2.2.2.2.1.1" class="ltx_tr">
<td id="S3.T2.2.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">CL(<math id="S3.T2.2.2.2.1.1.1.m1.1" class="ltx_Math" alttext="\alpha=1e-5" display="inline"><semantics id="S3.T2.2.2.2.1.1.1.m1.1a"><mrow id="S3.T2.2.2.2.1.1.1.m1.1.1" xref="S3.T2.2.2.2.1.1.1.m1.1.1.cmml"><mi id="S3.T2.2.2.2.1.1.1.m1.1.1.2" xref="S3.T2.2.2.2.1.1.1.m1.1.1.2.cmml">Î±</mi><mo id="S3.T2.2.2.2.1.1.1.m1.1.1.1" xref="S3.T2.2.2.2.1.1.1.m1.1.1.1.cmml">=</mo><mrow id="S3.T2.2.2.2.1.1.1.m1.1.1.3" xref="S3.T2.2.2.2.1.1.1.m1.1.1.3.cmml"><mrow id="S3.T2.2.2.2.1.1.1.m1.1.1.3.2" xref="S3.T2.2.2.2.1.1.1.m1.1.1.3.2.cmml"><mn id="S3.T2.2.2.2.1.1.1.m1.1.1.3.2.2" xref="S3.T2.2.2.2.1.1.1.m1.1.1.3.2.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="S3.T2.2.2.2.1.1.1.m1.1.1.3.2.1" xref="S3.T2.2.2.2.1.1.1.m1.1.1.3.2.1.cmml">â€‹</mo><mi id="S3.T2.2.2.2.1.1.1.m1.1.1.3.2.3" xref="S3.T2.2.2.2.1.1.1.m1.1.1.3.2.3.cmml">e</mi></mrow><mo id="S3.T2.2.2.2.1.1.1.m1.1.1.3.1" xref="S3.T2.2.2.2.1.1.1.m1.1.1.3.1.cmml">âˆ’</mo><mn id="S3.T2.2.2.2.1.1.1.m1.1.1.3.3" xref="S3.T2.2.2.2.1.1.1.m1.1.1.3.3.cmml">5</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T2.2.2.2.1.1.1.m1.1b"><apply id="S3.T2.2.2.2.1.1.1.m1.1.1.cmml" xref="S3.T2.2.2.2.1.1.1.m1.1.1"><eq id="S3.T2.2.2.2.1.1.1.m1.1.1.1.cmml" xref="S3.T2.2.2.2.1.1.1.m1.1.1.1"></eq><ci id="S3.T2.2.2.2.1.1.1.m1.1.1.2.cmml" xref="S3.T2.2.2.2.1.1.1.m1.1.1.2">ğ›¼</ci><apply id="S3.T2.2.2.2.1.1.1.m1.1.1.3.cmml" xref="S3.T2.2.2.2.1.1.1.m1.1.1.3"><minus id="S3.T2.2.2.2.1.1.1.m1.1.1.3.1.cmml" xref="S3.T2.2.2.2.1.1.1.m1.1.1.3.1"></minus><apply id="S3.T2.2.2.2.1.1.1.m1.1.1.3.2.cmml" xref="S3.T2.2.2.2.1.1.1.m1.1.1.3.2"><times id="S3.T2.2.2.2.1.1.1.m1.1.1.3.2.1.cmml" xref="S3.T2.2.2.2.1.1.1.m1.1.1.3.2.1"></times><cn type="integer" id="S3.T2.2.2.2.1.1.1.m1.1.1.3.2.2.cmml" xref="S3.T2.2.2.2.1.1.1.m1.1.1.3.2.2">1</cn><ci id="S3.T2.2.2.2.1.1.1.m1.1.1.3.2.3.cmml" xref="S3.T2.2.2.2.1.1.1.m1.1.1.3.2.3">ğ‘’</ci></apply><cn type="integer" id="S3.T2.2.2.2.1.1.1.m1.1.1.3.3.cmml" xref="S3.T2.2.2.2.1.1.1.m1.1.1.3.3">5</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.2.2.2.1.1.1.m1.1c">\alpha=1e-5</annotation></semantics></math>)/</td>
</tr>
<tr id="S3.T2.2.2.2.1.2" class="ltx_tr">
<td id="S3.T2.2.2.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">SFace-10</td>
</tr>
</table>
</td>
</tr>
<tr id="S3.T2.2.3" class="ltx_tr">
<td id="S3.T2.2.3.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" rowspan="2"><span id="S3.T2.2.3.1.1" class="ltx_text">Testing dataset</span></td>
<td id="S3.T2.2.3.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">SFace-10</td>
<td id="S3.T2.2.3.3" class="ltx_td ltx_align_left ltx_border_t">0.06</td>
<td id="S3.T2.2.3.4" class="ltx_td ltx_align_left ltx_border_t">99.99</td>
<td id="S3.T2.2.3.5" class="ltx_td ltx_align_left ltx_border_t">99.28</td>
<td id="S3.T2.2.3.6" class="ltx_td ltx_align_left ltx_border_t">94.18</td>
</tr>
<tr id="S3.T2.2.4" class="ltx_tr">
<td id="S3.T2.2.4.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_r">CASIA-WebFace</td>
<td id="S3.T2.2.4.2" class="ltx_td ltx_align_left ltx_border_b">92.69</td>
<td id="S3.T2.2.4.3" class="ltx_td ltx_align_left ltx_border_b">0.04</td>
<td id="S3.T2.2.4.4" class="ltx_td ltx_align_left ltx_border_b">0.14</td>
<td id="S3.T2.2.4.5" class="ltx_td ltx_align_left ltx_border_b">0.22</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S3.T2.4.1.1" class="ltx_text" style="font-size:90%;">TABLE II</span>: </span><span id="S3.T2.5.2" class="ltx_text" style="font-size:90%;">Top-1 identification accuracy (%) of four FR models trained under different experimental settings.
The identification accuracy is very low when testing on a different dataset than the one used for training, pointing out that the authentic dataset and the synthetic dataset (SFace) do not strongly share identity information. </span></figcaption>
</figure>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">Results</span>
</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">In this section we present our findings under a set of research questions leading to the final FR performance using our SFace dataset and the presented learning strategies.</p>
</div>
<section id="S4.SS0.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Does a generative model trained under a class-conditional setting generate identity-separable face image classes?</h4>

<div id="S4.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS0.SSS0.Px1.p1.1" class="ltx_p">Figure <a href="#S3.F3.sf2" title="In Figure 3 â€£ III-C Face Recognition Training Setups â€£ III Experimental Setup â€£ SFace: Privacy-friendly and Accurate Face Recognition using Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3(b)</span></a> shows the genuine-imposter comparison score distributions on the synthetic SFace-10 dataset, where both references and probes images are from SFace. It can be observed that the genuine and imposter distributions are, to some degree, shifted from each other. The genuine score distribution in Figure <a href="#S3.F3.sf2" title="In Figure 3 â€£ III-C Face Recognition Training Setups â€£ III Experimental Setup â€£ SFace: Privacy-friendly and Accurate Face Recognition using Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3(b)</span></a> is shifted towards the imposter score distributions in comparison to the case where the references and probes images are from the authentic CASIA-WebFace dataset shown in Figure <a href="#S3.F3.sf1" title="In Figure 3 â€£ III-C Face Recognition Training Setups â€£ III Experimental Setup â€£ SFace: Privacy-friendly and Accurate Face Recognition using Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3(a)</span></a>.
Related to that, one can notice a degree of shared visual attributes in the SFace images from the same class in Figure <a href="#S1.F2" title="Figure 2 â€£ I Introduction â€£ SFace: Privacy-friendly and Accurate Face Recognition using Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
These observations are also confirmed quantitatively in Table <a href="#S3.T1" title="TABLE I â€£ III-C Face Recognition Training Setups â€£ III Experimental Setup â€£ SFace: Privacy-friendly and Accurate Face Recognition using Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a>, where in comparison to the relatively strong identity discrimination in the authentic data (EER=7.614%), the SFace data does maintain a certain degree of identity discrimination (EER=21.650%), however, to a lower degree than the authentic data.</p>
</div>
</section>
<section id="S4.SS0.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Does SFace share identity information with CASIA-WebFace?</h4>

<div id="S4.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS0.SSS0.Px2.p1.1" class="ltx_p">We answered this question by conducting a cross-dataset FR evaluation where authentic reference images from CASIA-WebFace are compared to synthetic probe images from SFace-10 using <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> as described in Section <a href="#S3.SS4" title="III-D Evaluation Metrics â€£ III Experimental Setup â€£ SFace: Privacy-friendly and Accurate Face Recognition using Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">III-D</span></span></a>. Figure <a href="#S3.F3.sf3" title="In Figure 3 â€£ III-C Face Recognition Training Setups â€£ III Experimental Setup â€£ SFace: Privacy-friendly and Accurate Face Recognition using Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3(c)</span></a> shows the genuine and imposter scores distributions of the cross-dataset evaluation.
One can clearly notice that the genuine score distribution is highly overlapping with the imposter score distribution (Figure <a href="#S3.F3.sf3" title="In Figure 3 â€£ III-C Face Recognition Training Setups â€£ III Experimental Setup â€£ SFace: Privacy-friendly and Accurate Face Recognition using Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3(c)</span></a>). This case is further illustrated by plotting the genuine and imposter score distributions of intra-data CASIA-WebFace and the cross-dataset settings in the same figure (Figure <a href="#S3.F3.sf4" title="In Figure 3 â€£ III-C Face Recognition Training Setups â€£ III Experimental Setup â€£ SFace: Privacy-friendly and Accurate Face Recognition using Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3(d)</span></a>), where the cross-data verification produces extremely lower genuine-imposter scores separability.
Also, the reported verification performance in Table <a href="#S3.T1" title="TABLE I â€£ III-C Face Recognition Training Setups â€£ III Experimental Setup â€£ SFace: Privacy-friendly and Accurate Face Recognition using Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a> showed that the verification performance is significantly decreased when the probe images are taken from SFace (29.204% EER ) compared to the case where both, reference and probe images, are from CASIA-WebFace (7.614% EER).
This also indicates that associating an identity of SFace to one of Casia-WebFace confidently is hardly possible (29.204% EER, 74.662% FMR100, and 88.692% FMR1000).
This practically means that, if operating at the FMR1000 threshold recommended by Frontex <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> for border control, an authentic image included in CASIA-WebFace, if compared to a 100 images of the same class in SFace using a top-performing FR solution <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>, will result in a (false) non-match decisions around 89 times, rendering the verification of the authentic identities in SFace extremely weak, which support the privacy motivation behind the SFace synthetic data.</p>
</div>
<div id="S4.SS0.SSS0.Px2.p2" class="ltx_para">
<p id="S4.SS0.SSS0.Px2.p2.2" class="ltx_p">To complement our conclusion, we empirically evaluated how well can the classes of SFace (SFace-10) be correctly classified as the corresponding identities in CASIA-WebFace.
We thus measure this correct classification ability as top-1 identification accuracy (%) by calculating the average prediction accuracy from the classification layer.
Towards that, as a baseline, we first trained an FR model on CASIA-WebFace (CLS/CASIA-WebFace setting in Table <a href="#S3.T2" title="TABLE II â€£ III-D Evaluation Metrics â€£ III Experimental Setup â€£ SFace: Privacy-friendly and Accurate Face Recognition using Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a>) and then reported the identification accuracies (%) on CASIA-WebFace and SFace.
Table <a href="#S3.T2" title="TABLE II â€£ III-D Evaluation Metrics â€£ III Experimental Setup â€£ SFace: Privacy-friendly and Accurate Face Recognition using Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a> proved that images in CASIA-WebFace can be strongly identified (92.69% accuracy). On the other hand, the identification accuracy of SFace in the model trained on Casia-WebFace is extremely low (0.06%), indicating that SFace classes have an extremely low association with the identities in Casia-WebFace.
This is expected based on, and supports, the results presented in Table <a href="#S3.T1" title="TABLE I â€£ III-C Face Recognition Training Setups â€£ III Experimental Setup â€£ SFace: Privacy-friendly and Accurate Face Recognition using Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a> and discussed above.
Similar observation can be made by training FR models on SFace under different learning strategies and evaluating the identification accuracies on SFace and CASIA-WebFace.
It can be noticed that the correct identification rate of the authentic data is extremely low in the models trained on SFace, even in the case where knowledge is transferred from the model trained on CASIA-WebFace (CL(<math id="S4.SS0.SSS0.Px2.p2.1.m1.1" class="ltx_Math" alttext="\alpha=2e-5" display="inline"><semantics id="S4.SS0.SSS0.Px2.p2.1.m1.1a"><mrow id="S4.SS0.SSS0.Px2.p2.1.m1.1.1" xref="S4.SS0.SSS0.Px2.p2.1.m1.1.1.cmml"><mi id="S4.SS0.SSS0.Px2.p2.1.m1.1.1.2" xref="S4.SS0.SSS0.Px2.p2.1.m1.1.1.2.cmml">Î±</mi><mo id="S4.SS0.SSS0.Px2.p2.1.m1.1.1.1" xref="S4.SS0.SSS0.Px2.p2.1.m1.1.1.1.cmml">=</mo><mrow id="S4.SS0.SSS0.Px2.p2.1.m1.1.1.3" xref="S4.SS0.SSS0.Px2.p2.1.m1.1.1.3.cmml"><mrow id="S4.SS0.SSS0.Px2.p2.1.m1.1.1.3.2" xref="S4.SS0.SSS0.Px2.p2.1.m1.1.1.3.2.cmml"><mn id="S4.SS0.SSS0.Px2.p2.1.m1.1.1.3.2.2" xref="S4.SS0.SSS0.Px2.p2.1.m1.1.1.3.2.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S4.SS0.SSS0.Px2.p2.1.m1.1.1.3.2.1" xref="S4.SS0.SSS0.Px2.p2.1.m1.1.1.3.2.1.cmml">â€‹</mo><mi id="S4.SS0.SSS0.Px2.p2.1.m1.1.1.3.2.3" xref="S4.SS0.SSS0.Px2.p2.1.m1.1.1.3.2.3.cmml">e</mi></mrow><mo id="S4.SS0.SSS0.Px2.p2.1.m1.1.1.3.1" xref="S4.SS0.SSS0.Px2.p2.1.m1.1.1.3.1.cmml">âˆ’</mo><mn id="S4.SS0.SSS0.Px2.p2.1.m1.1.1.3.3" xref="S4.SS0.SSS0.Px2.p2.1.m1.1.1.3.3.cmml">5</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px2.p2.1.m1.1b"><apply id="S4.SS0.SSS0.Px2.p2.1.m1.1.1.cmml" xref="S4.SS0.SSS0.Px2.p2.1.m1.1.1"><eq id="S4.SS0.SSS0.Px2.p2.1.m1.1.1.1.cmml" xref="S4.SS0.SSS0.Px2.p2.1.m1.1.1.1"></eq><ci id="S4.SS0.SSS0.Px2.p2.1.m1.1.1.2.cmml" xref="S4.SS0.SSS0.Px2.p2.1.m1.1.1.2">ğ›¼</ci><apply id="S4.SS0.SSS0.Px2.p2.1.m1.1.1.3.cmml" xref="S4.SS0.SSS0.Px2.p2.1.m1.1.1.3"><minus id="S4.SS0.SSS0.Px2.p2.1.m1.1.1.3.1.cmml" xref="S4.SS0.SSS0.Px2.p2.1.m1.1.1.3.1"></minus><apply id="S4.SS0.SSS0.Px2.p2.1.m1.1.1.3.2.cmml" xref="S4.SS0.SSS0.Px2.p2.1.m1.1.1.3.2"><times id="S4.SS0.SSS0.Px2.p2.1.m1.1.1.3.2.1.cmml" xref="S4.SS0.SSS0.Px2.p2.1.m1.1.1.3.2.1"></times><cn type="integer" id="S4.SS0.SSS0.Px2.p2.1.m1.1.1.3.2.2.cmml" xref="S4.SS0.SSS0.Px2.p2.1.m1.1.1.3.2.2">2</cn><ci id="S4.SS0.SSS0.Px2.p2.1.m1.1.1.3.2.3.cmml" xref="S4.SS0.SSS0.Px2.p2.1.m1.1.1.3.2.3">ğ‘’</ci></apply><cn type="integer" id="S4.SS0.SSS0.Px2.p2.1.m1.1.1.3.3.cmml" xref="S4.SS0.SSS0.Px2.p2.1.m1.1.1.3.3">5</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px2.p2.1.m1.1c">\alpha=2e-5</annotation></semantics></math>) / SFace-10 and CL(<math id="S4.SS0.SSS0.Px2.p2.2.m2.1" class="ltx_Math" alttext="\alpha=1e-5" display="inline"><semantics id="S4.SS0.SSS0.Px2.p2.2.m2.1a"><mrow id="S4.SS0.SSS0.Px2.p2.2.m2.1.1" xref="S4.SS0.SSS0.Px2.p2.2.m2.1.1.cmml"><mi id="S4.SS0.SSS0.Px2.p2.2.m2.1.1.2" xref="S4.SS0.SSS0.Px2.p2.2.m2.1.1.2.cmml">Î±</mi><mo id="S4.SS0.SSS0.Px2.p2.2.m2.1.1.1" xref="S4.SS0.SSS0.Px2.p2.2.m2.1.1.1.cmml">=</mo><mrow id="S4.SS0.SSS0.Px2.p2.2.m2.1.1.3" xref="S4.SS0.SSS0.Px2.p2.2.m2.1.1.3.cmml"><mrow id="S4.SS0.SSS0.Px2.p2.2.m2.1.1.3.2" xref="S4.SS0.SSS0.Px2.p2.2.m2.1.1.3.2.cmml"><mn id="S4.SS0.SSS0.Px2.p2.2.m2.1.1.3.2.2" xref="S4.SS0.SSS0.Px2.p2.2.m2.1.1.3.2.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="S4.SS0.SSS0.Px2.p2.2.m2.1.1.3.2.1" xref="S4.SS0.SSS0.Px2.p2.2.m2.1.1.3.2.1.cmml">â€‹</mo><mi id="S4.SS0.SSS0.Px2.p2.2.m2.1.1.3.2.3" xref="S4.SS0.SSS0.Px2.p2.2.m2.1.1.3.2.3.cmml">e</mi></mrow><mo id="S4.SS0.SSS0.Px2.p2.2.m2.1.1.3.1" xref="S4.SS0.SSS0.Px2.p2.2.m2.1.1.3.1.cmml">âˆ’</mo><mn id="S4.SS0.SSS0.Px2.p2.2.m2.1.1.3.3" xref="S4.SS0.SSS0.Px2.p2.2.m2.1.1.3.3.cmml">5</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px2.p2.2.m2.1b"><apply id="S4.SS0.SSS0.Px2.p2.2.m2.1.1.cmml" xref="S4.SS0.SSS0.Px2.p2.2.m2.1.1"><eq id="S4.SS0.SSS0.Px2.p2.2.m2.1.1.1.cmml" xref="S4.SS0.SSS0.Px2.p2.2.m2.1.1.1"></eq><ci id="S4.SS0.SSS0.Px2.p2.2.m2.1.1.2.cmml" xref="S4.SS0.SSS0.Px2.p2.2.m2.1.1.2">ğ›¼</ci><apply id="S4.SS0.SSS0.Px2.p2.2.m2.1.1.3.cmml" xref="S4.SS0.SSS0.Px2.p2.2.m2.1.1.3"><minus id="S4.SS0.SSS0.Px2.p2.2.m2.1.1.3.1.cmml" xref="S4.SS0.SSS0.Px2.p2.2.m2.1.1.3.1"></minus><apply id="S4.SS0.SSS0.Px2.p2.2.m2.1.1.3.2.cmml" xref="S4.SS0.SSS0.Px2.p2.2.m2.1.1.3.2"><times id="S4.SS0.SSS0.Px2.p2.2.m2.1.1.3.2.1.cmml" xref="S4.SS0.SSS0.Px2.p2.2.m2.1.1.3.2.1"></times><cn type="integer" id="S4.SS0.SSS0.Px2.p2.2.m2.1.1.3.2.2.cmml" xref="S4.SS0.SSS0.Px2.p2.2.m2.1.1.3.2.2">1</cn><ci id="S4.SS0.SSS0.Px2.p2.2.m2.1.1.3.2.3.cmml" xref="S4.SS0.SSS0.Px2.p2.2.m2.1.1.3.2.3">ğ‘’</ci></apply><cn type="integer" id="S4.SS0.SSS0.Px2.p2.2.m2.1.1.3.3.cmml" xref="S4.SS0.SSS0.Px2.p2.2.m2.1.1.3.3">5</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px2.p2.2.m2.1c">\alpha=1e-5</annotation></semantics></math>) / SFace-10).
This low identification accuracy in comparison to that in the model trained on the authentic data (0.04%, 0.14%, 0.22% in comparison to 92.69%) again points out the low class association between the authentic data and the synthetic SFace data.</p>
</div>
<figure id="S4.T3" class="ltx_table">
<table id="S4.T3.2" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S4.T3.2.3" class="ltx_tr">
<td id="S4.T3.2.3.1" class="ltx_td ltx_align_left ltx_border_t">Training dataset</td>
<td id="S4.T3.2.3.2" class="ltx_td ltx_align_left ltx_border_t">Training strategy</td>
<td id="S4.T3.2.3.3" class="ltx_td ltx_align_left ltx_border_t">LFW</td>
<td id="S4.T3.2.3.4" class="ltx_td ltx_align_left ltx_border_t">CFP-FP</td>
<td id="S4.T3.2.3.5" class="ltx_td ltx_align_left ltx_border_t">AgeDB-30</td>
<td id="S4.T3.2.3.6" class="ltx_td ltx_align_left ltx_border_t">CALFW</td>
<td id="S4.T3.2.3.7" class="ltx_td ltx_align_left ltx_border_t">CPLFW</td>
</tr>
<tr id="S4.T3.2.4" class="ltx_tr">
<td id="S4.T3.2.4.1" class="ltx_td ltx_align_left ltx_border_t">Authentic</td>
<td id="S4.T3.2.4.2" class="ltx_td ltx_align_left ltx_border_t">CLS</td>
<td id="S4.T3.2.4.3" class="ltx_td ltx_align_left ltx_border_t">99.55</td>
<td id="S4.T3.2.4.4" class="ltx_td ltx_align_left ltx_border_t">95.31</td>
<td id="S4.T3.2.4.5" class="ltx_td ltx_align_left ltx_border_t">94.55</td>
<td id="S4.T3.2.4.6" class="ltx_td ltx_align_left ltx_border_t">93.78</td>
<td id="S4.T3.2.4.7" class="ltx_td ltx_align_left ltx_border_t">89.95</td>
</tr>
<tr id="S4.T3.2.5" class="ltx_tr">
<td id="S4.T3.2.5.1" class="ltx_td ltx_align_left ltx_border_tt">SFace-10</td>
<td id="S4.T3.2.5.2" class="ltx_td ltx_align_left ltx_border_tt">CLS</td>
<td id="S4.T3.2.5.3" class="ltx_td ltx_align_left ltx_border_tt">87.13</td>
<td id="S4.T3.2.5.4" class="ltx_td ltx_align_left ltx_border_tt">68.84</td>
<td id="S4.T3.2.5.5" class="ltx_td ltx_align_left ltx_border_tt">63.30</td>
<td id="S4.T3.2.5.6" class="ltx_td ltx_align_left ltx_border_tt">73.47</td>
<td id="S4.T3.2.5.7" class="ltx_td ltx_align_left ltx_border_tt">66.82</td>
</tr>
<tr id="S4.T3.2.6" class="ltx_tr">
<td id="S4.T3.2.6.1" class="ltx_td ltx_align_left">SFace-10</td>
<td id="S4.T3.2.6.2" class="ltx_td ltx_align_left">KT</td>
<td id="S4.T3.2.6.3" class="ltx_td ltx_align_left">91.32</td>
<td id="S4.T3.2.6.4" class="ltx_td ltx_align_left">67.81</td>
<td id="S4.T3.2.6.5" class="ltx_td ltx_align_left">69.72</td>
<td id="S4.T3.2.6.6" class="ltx_td ltx_align_left">78.03</td>
<td id="S4.T3.2.6.7" class="ltx_td ltx_align_left">67.40</td>
</tr>
<tr id="S4.T3.1.1" class="ltx_tr">
<td id="S4.T3.1.1.2" class="ltx_td ltx_align_left">SFace-10</td>
<td id="S4.T3.1.1.1" class="ltx_td ltx_align_left">CL(<math id="S4.T3.1.1.1.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S4.T3.1.1.1.m1.1a"><mi id="S4.T3.1.1.1.m1.1.1" xref="S4.T3.1.1.1.m1.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S4.T3.1.1.1.m1.1b"><ci id="S4.T3.1.1.1.m1.1.1.cmml" xref="S4.T3.1.1.1.m1.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.1.1.1.m1.1c">\alpha</annotation></semantics></math>=2e-5)</td>
<td id="S4.T3.1.1.3" class="ltx_td ltx_align_left">94.75</td>
<td id="S4.T3.1.1.4" class="ltx_td ltx_align_left">75.20</td>
<td id="S4.T3.1.1.5" class="ltx_td ltx_align_left">77.28</td>
<td id="S4.T3.1.1.6" class="ltx_td ltx_align_left">84.15</td>
<td id="S4.T3.1.1.7" class="ltx_td ltx_align_left">73.32</td>
</tr>
<tr id="S4.T3.2.2" class="ltx_tr">
<td id="S4.T3.2.2.2" class="ltx_td ltx_align_left ltx_border_b">SFace-10</td>
<td id="S4.T3.2.2.1" class="ltx_td ltx_align_left ltx_border_b">CL(<math id="S4.T3.2.2.1.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S4.T3.2.2.1.m1.1a"><mi id="S4.T3.2.2.1.m1.1.1" xref="S4.T3.2.2.1.m1.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S4.T3.2.2.1.m1.1b"><ci id="S4.T3.2.2.1.m1.1.1.cmml" xref="S4.T3.2.2.1.m1.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.2.2.1.m1.1c">\alpha</annotation></semantics></math>=1e-5)</td>
<td id="S4.T3.2.2.3" class="ltx_td ltx_align_left ltx_border_b"><span id="S4.T3.2.2.3.1" class="ltx_text ltx_font_bold">96.63</span></td>
<td id="S4.T3.2.2.4" class="ltx_td ltx_align_left ltx_border_b"><span id="S4.T3.2.2.4.1" class="ltx_text ltx_font_bold">79.61</span></td>
<td id="S4.T3.2.2.5" class="ltx_td ltx_align_left ltx_border_b"><span id="S4.T3.2.2.5.1" class="ltx_text ltx_font_bold">82.08</span></td>
<td id="S4.T3.2.2.6" class="ltx_td ltx_align_left ltx_border_b"><span id="S4.T3.2.2.6.1" class="ltx_text ltx_font_bold">87.43</span></td>
<td id="S4.T3.2.2.7" class="ltx_td ltx_align_left ltx_border_b"><span id="S4.T3.2.2.7.1" class="ltx_text ltx_font_bold">76.23</span></td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T3.6.2.1" class="ltx_text" style="font-size:90%;">TABLE III</span>: </span><span id="S4.T3.4.1" class="ltx_text" style="font-size:90%;">
Verification accuracy in % of different learning strategies and different training datasets on five different FR benchmarks. The result in the first row is reported using the FR model trained on the authentic dataset to give an indication of the performance of an FR model trained on the authentic CASIA-WebFace <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite> dataset. The rest of the results are obtained using the different proposed learning strategies on SFace-10. KT achieved very close performance to CLS without class label supervision. CL achieved the best verification performances with <math id="S4.T3.4.1.m1.1" class="ltx_Math" alttext="\alpha=1e-5" display="inline"><semantics id="S4.T3.4.1.m1.1b"><mrow id="S4.T3.4.1.m1.1.1" xref="S4.T3.4.1.m1.1.1.cmml"><mi id="S4.T3.4.1.m1.1.1.2" xref="S4.T3.4.1.m1.1.1.2.cmml">Î±</mi><mo id="S4.T3.4.1.m1.1.1.1" xref="S4.T3.4.1.m1.1.1.1.cmml">=</mo><mrow id="S4.T3.4.1.m1.1.1.3" xref="S4.T3.4.1.m1.1.1.3.cmml"><mrow id="S4.T3.4.1.m1.1.1.3.2" xref="S4.T3.4.1.m1.1.1.3.2.cmml"><mn id="S4.T3.4.1.m1.1.1.3.2.2" xref="S4.T3.4.1.m1.1.1.3.2.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="S4.T3.4.1.m1.1.1.3.2.1" xref="S4.T3.4.1.m1.1.1.3.2.1.cmml">â€‹</mo><mi id="S4.T3.4.1.m1.1.1.3.2.3" xref="S4.T3.4.1.m1.1.1.3.2.3.cmml">e</mi></mrow><mo id="S4.T3.4.1.m1.1.1.3.1" xref="S4.T3.4.1.m1.1.1.3.1.cmml">âˆ’</mo><mn id="S4.T3.4.1.m1.1.1.3.3" xref="S4.T3.4.1.m1.1.1.3.3.cmml">5</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.4.1.m1.1c"><apply id="S4.T3.4.1.m1.1.1.cmml" xref="S4.T3.4.1.m1.1.1"><eq id="S4.T3.4.1.m1.1.1.1.cmml" xref="S4.T3.4.1.m1.1.1.1"></eq><ci id="S4.T3.4.1.m1.1.1.2.cmml" xref="S4.T3.4.1.m1.1.1.2">ğ›¼</ci><apply id="S4.T3.4.1.m1.1.1.3.cmml" xref="S4.T3.4.1.m1.1.1.3"><minus id="S4.T3.4.1.m1.1.1.3.1.cmml" xref="S4.T3.4.1.m1.1.1.3.1"></minus><apply id="S4.T3.4.1.m1.1.1.3.2.cmml" xref="S4.T3.4.1.m1.1.1.3.2"><times id="S4.T3.4.1.m1.1.1.3.2.1.cmml" xref="S4.T3.4.1.m1.1.1.3.2.1"></times><cn type="integer" id="S4.T3.4.1.m1.1.1.3.2.2.cmml" xref="S4.T3.4.1.m1.1.1.3.2.2">1</cn><ci id="S4.T3.4.1.m1.1.1.3.2.3.cmml" xref="S4.T3.4.1.m1.1.1.3.2.3">ğ‘’</ci></apply><cn type="integer" id="S4.T3.4.1.m1.1.1.3.3.cmml" xref="S4.T3.4.1.m1.1.1.3.3">5</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.4.1.m1.1d">\alpha=1e-5</annotation></semantics></math>.
</span></figcaption>
</figure>
</section>
<section id="S4.SS0.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Can the synthetic SFace dataset be used to train an FR model?</h4>

<div id="S4.SS0.SSS0.Px3.p1" class="ltx_para">
<p id="S4.SS0.SSS0.Px3.p1.1" class="ltx_p">Knowing that the identities are, to a certain degree, separable in SFace, we evaluated the feasibility of using this synthetic dataset to train an FR model under the three different learning strategies presented in Section <a href="#S2" title="II Synthetic Face Recognition â€£ SFace: Privacy-friendly and Accurate Face Recognition using Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a>.</p>
</div>
<div id="S4.SS0.SSS0.Px3.p2" class="ltx_para">
<p id="S4.SS0.SSS0.Px3.p2.1" class="ltx_p">In the first learning strategy, we trained an FR model to learn multi-class classification utilizing CosFace loss <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite> (i.e. CLS).
The achieved verification accuracies on the considered evaluation dataset, in this case (CLS with SFace-10), are LFW (86.98%), CFP-FP (68.51%), AgeDB-30 (62.40%), CALFW(73.10%) and CPLFW(66.55%), as shown in Table <a href="#S4.T3" title="TABLE III â€£ Does SFace share identity information with CASIA-WebFace? â€£ IV Results â€£ SFace: Privacy-friendly and Accurate Face Recognition using Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a>.
These verification accuracies improved when using SFace-20, SFace-40, or SFace-60 <a href="#S4.T4" title="TABLE IV â€£ Can the synthetic SFace dataset be used to train an FR model? â€£ IV Results â€£ SFace: Privacy-friendly and Accurate Face Recognition using Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV</span></a>. For example, the achieved accuracy on CALFW is improved from 73.47% (SFace-10) to 77.93% (SFace-60), as demonstrated in Table <a href="#S4.T4" title="TABLE IV â€£ Can the synthetic SFace dataset be used to train an FR model? â€£ IV Results â€£ SFace: Privacy-friendly and Accurate Face Recognition using Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV</span></a>.
Also, it can be noticed that the verification accuracies of models trained with CLS on SFace-20, SFace-40, and SFace-60 are, in general, very close, when compared to the performance leap achieved when moving from SFace-10 to SFace-20.
The results on all benchmarks are far away from being random, indicating the high potential of using synthetically generated data under class-conditional settings for FR.</p>
</div>
<div id="S4.SS0.SSS0.Px3.p3" class="ltx_para">
<p id="S4.SS0.SSS0.Px3.p3.1" class="ltx_p">In the second learning strategy, we trained FR models on the synthetic SFace dataset with KT.This learning strategy does not require class label supervision.
Using SFace-10, it achieved close performance to the case where the model was trained using the CLS strategy. However, the achieved verification accuracies are significantly improved in SFace-20, SFace-40, and SFace-60 settings as shown in Table <a href="#S4.T4" title="TABLE IV â€£ Can the synthetic SFace dataset be used to train an FR model? â€£ IV Results â€£ SFace: Privacy-friendly and Accurate Face Recognition using Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV</span></a>. The model trained with our SFace-60 under the KT strategy achieved an accuracy of 98.5% on the LFW benchmark.</p>
</div>
<div id="S4.SS0.SSS0.Px3.p4" class="ltx_para">
<p id="S4.SS0.SSS0.Px3.p4.4" class="ltx_p">As the next experiments showed, these results are significantly improved when both learning strategies are combined.
First, we set <math id="S4.SS0.SSS0.Px3.p4.1.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S4.SS0.SSS0.Px3.p4.1.m1.1a"><mi id="S4.SS0.SSS0.Px3.p4.1.m1.1.1" xref="S4.SS0.SSS0.Px3.p4.1.m1.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px3.p4.1.m1.1b"><ci id="S4.SS0.SSS0.Px3.p4.1.m1.1.1.cmml" xref="S4.SS0.SSS0.Px3.p4.1.m1.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px3.p4.1.m1.1c">\alpha</annotation></semantics></math> to a very small value, as the previous results on CLS and KT strategies showed the higher performance when using KT, and we trained an FR model on the SFace-10 dataset using CL. The achieved results, in this case, are presented in Table <a href="#S4.T3" title="TABLE III â€£ Does SFace share identity information with CASIA-WebFace? â€£ IV Results â€£ SFace: Privacy-friendly and Accurate Face Recognition using Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a>.
Then, we increased <math id="S4.SS0.SSS0.Px3.p4.2.m2.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S4.SS0.SSS0.Px3.p4.2.m2.1a"><mi id="S4.SS0.SSS0.Px3.p4.2.m2.1.1" xref="S4.SS0.SSS0.Px3.p4.2.m2.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px3.p4.2.m2.1b"><ci id="S4.SS0.SSS0.Px3.p4.2.m2.1.1.cmml" xref="S4.SS0.SSS0.Px3.p4.2.m2.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px3.p4.2.m2.1c">\alpha</annotation></semantics></math> by a factor of 2 (2e-5) and trained another FR instance. We observed, in this case, that using a smaller <math id="S4.SS0.SSS0.Px3.p4.3.m3.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S4.SS0.SSS0.Px3.p4.3.m3.1a"><mi id="S4.SS0.SSS0.Px3.p4.3.m3.1.1" xref="S4.SS0.SSS0.Px3.p4.3.m3.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px3.p4.3.m3.1b"><ci id="S4.SS0.SSS0.Px3.p4.3.m3.1.1.cmml" xref="S4.SS0.SSS0.Px3.p4.3.m3.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px3.p4.3.m3.1c">\alpha</annotation></semantics></math> value led to higher verification performance on the considered benchmarks, as shown in Table <a href="#S4.T3" title="TABLE III â€£ Does SFace share identity information with CASIA-WebFace? â€£ IV Results â€£ SFace: Privacy-friendly and Accurate Face Recognition using Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a>.
Thus, we set <math id="S4.SS0.SSS0.Px3.p4.4.m4.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S4.SS0.SSS0.Px3.p4.4.m4.1a"><mi id="S4.SS0.SSS0.Px3.p4.4.m4.1.1" xref="S4.SS0.SSS0.Px3.p4.4.m4.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px3.p4.4.m4.1b"><ci id="S4.SS0.SSS0.Px3.p4.4.m4.1.1.cmml" xref="S4.SS0.SSS0.Px3.p4.4.m4.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px3.p4.4.m4.1c">\alpha</annotation></semantics></math> to 1e-5 in the conduced experiments presented in Table <a href="#S4.T4" title="TABLE IV â€£ Can the synthetic SFace dataset be used to train an FR model? â€£ IV Results â€£ SFace: Privacy-friendly and Accurate Face Recognition using Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV</span></a>.
The achieved results of CL using different subsets of SFace are presented in Table <a href="#S4.T3" title="TABLE III â€£ Does SFace share identity information with CASIA-WebFace? â€£ IV Results â€£ SFace: Privacy-friendly and Accurate Face Recognition using Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a>.
It can be observed, from the results in TAble <a href="#S4.T4" title="TABLE IV â€£ Can the synthetic SFace dataset be used to train an FR model? â€£ IV Results â€£ SFace: Privacy-friendly and Accurate Face Recognition using Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV</span></a>, that combining CLS and KT (into CL) learning can improve the verification performance very significantly in comparison to the case where only CLS is used. For example, comparing the performance of the CLS strategy to that of the CL strategy when trained on SFace-60, the accuracy on LFW moved from 91.87% (CLS) to 99.13% (CL) and the accuracy on CALFW moved from 77.93% (CLS) to 92.47%. One can also notice that the achieved performance using the CL strategy is quite close to the performance of the model trained on the authentic data.</p>
</div>
<div id="S4.SS0.SSS0.Px3.p5" class="ltx_para">
<p id="S4.SS0.SSS0.Px3.p5.1" class="ltx_p">Two main previous works utilized synthetic data for FR training <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite> and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>. The presented solution (SynFace) by Qiu et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite> (ICCV2021) reported accuracy of 88.98% on LFW using a ResNet-50 model trained on synthetic dataset (500K images). The used synthetic dataset by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite> consists of 10K different identities with 50 images per identity.
The work by Kortylewski et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>(CVPRW2019) reported verification accuracy of 80.1% on LFW using FaceNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> trained on a synthetically generated dataset. Both previous works are outperformed by all of our three learning strategies achieving an LFW accuracy of 91.87%, 98.50%, and 99.13% for the CLS, KT, and CL strategies, respectively.</p>
</div>
<div id="S4.SS0.SSS0.Px3.p6" class="ltx_para">
<p id="S4.SS0.SSS0.Px3.p6.1" class="ltx_p">To conclude, this work is one of the earliest works proposing the use of a synthetically generated face dataset for FR training. This is performed with and without the support of a pre-trained model. Also, to the best of our knowledge, it is the first work to analyze the identity relation between the synthetically generated face dataset and the authentic data used to train its generative model.</p>
</div>
<figure id="S4.T4" class="ltx_table">
<table id="S4.T4.4" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S4.T4.4.1" class="ltx_tr">
<td id="S4.T4.4.1.1" class="ltx_td ltx_align_left ltx_border_t">Training dataset</td>
<td id="S4.T4.4.1.2" class="ltx_td ltx_align_left ltx_border_t">Training strategy</td>
<td id="S4.T4.4.1.3" class="ltx_td ltx_align_left ltx_border_t">LFW</td>
<td id="S4.T4.4.1.4" class="ltx_td ltx_align_left ltx_border_t">CFP-FP</td>
<td id="S4.T4.4.1.5" class="ltx_td ltx_align_left ltx_border_t">AgeDB-30</td>
<td id="S4.T4.4.1.6" class="ltx_td ltx_align_left ltx_border_t">CALFW</td>
<td id="S4.T4.4.1.7" class="ltx_td ltx_align_left ltx_border_t">CPLFW</td>
</tr>
<tr id="S4.T4.4.2" class="ltx_tr">
<td id="S4.T4.4.2.1" class="ltx_td ltx_align_left ltx_border_t">Authentic</td>
<td id="S4.T4.4.2.2" class="ltx_td ltx_align_left ltx_border_t">CLS</td>
<td id="S4.T4.4.2.3" class="ltx_td ltx_align_left ltx_border_t">99.55</td>
<td id="S4.T4.4.2.4" class="ltx_td ltx_align_left ltx_border_t">95.31</td>
<td id="S4.T4.4.2.5" class="ltx_td ltx_align_left ltx_border_t">94.55</td>
<td id="S4.T4.4.2.6" class="ltx_td ltx_align_left ltx_border_t">93.78</td>
<td id="S4.T4.4.2.7" class="ltx_td ltx_align_left ltx_border_t">89.95</td>
</tr>
<tr id="S4.T4.4.3" class="ltx_tr">
<td id="S4.T4.4.3.1" class="ltx_td ltx_align_left ltx_border_tt">SFace-10</td>
<td id="S4.T4.4.3.2" class="ltx_td ltx_align_left ltx_border_tt" rowspan="4"><span id="S4.T4.4.3.2.1" class="ltx_text">CLS</span></td>
<td id="S4.T4.4.3.3" class="ltx_td ltx_align_left ltx_border_tt">87.13</td>
<td id="S4.T4.4.3.4" class="ltx_td ltx_align_left ltx_border_tt">68.84</td>
<td id="S4.T4.4.3.5" class="ltx_td ltx_align_left ltx_border_tt">63.30</td>
<td id="S4.T4.4.3.6" class="ltx_td ltx_align_left ltx_border_tt">73.47</td>
<td id="S4.T4.4.3.7" class="ltx_td ltx_align_left ltx_border_tt">66.82</td>
</tr>
<tr id="S4.T4.4.4" class="ltx_tr">
<td id="S4.T4.4.4.1" class="ltx_td ltx_align_left">SFace-20</td>
<td id="S4.T4.4.4.2" class="ltx_td ltx_align_left">90.50</td>
<td id="S4.T4.4.4.3" class="ltx_td ltx_align_left">73.33</td>
<td id="S4.T4.4.4.4" class="ltx_td ltx_align_left">69.17</td>
<td id="S4.T4.4.4.5" class="ltx_td ltx_align_left">76.35</td>
<td id="S4.T4.4.4.6" class="ltx_td ltx_align_left">71.17</td>
</tr>
<tr id="S4.T4.4.5" class="ltx_tr">
<td id="S4.T4.4.5.1" class="ltx_td ltx_align_left">SFace-40</td>
<td id="S4.T4.4.5.2" class="ltx_td ltx_align_left">91.43</td>
<td id="S4.T4.4.5.3" class="ltx_td ltx_align_left">73.10</td>
<td id="S4.T4.4.5.4" class="ltx_td ltx_align_left">69.87</td>
<td id="S4.T4.4.5.5" class="ltx_td ltx_align_left">76.92</td>
<td id="S4.T4.4.5.6" class="ltx_td ltx_align_left">73.42</td>
</tr>
<tr id="S4.T4.4.6" class="ltx_tr">
<td id="S4.T4.4.6.1" class="ltx_td ltx_align_left">SFace-60</td>
<td id="S4.T4.4.6.2" class="ltx_td ltx_align_left">91.87</td>
<td id="S4.T4.4.6.3" class="ltx_td ltx_align_left">73.86</td>
<td id="S4.T4.4.6.4" class="ltx_td ltx_align_left">71.68</td>
<td id="S4.T4.4.6.5" class="ltx_td ltx_align_left">77.93</td>
<td id="S4.T4.4.6.6" class="ltx_td ltx_align_left">73.20</td>
</tr>
<tr id="S4.T4.4.7" class="ltx_tr">
<td id="S4.T4.4.7.1" class="ltx_td ltx_align_left ltx_border_tt">SFace-10</td>
<td id="S4.T4.4.7.2" class="ltx_td ltx_align_left ltx_border_tt" rowspan="4"><span id="S4.T4.4.7.2.1" class="ltx_text">KT</span></td>
<td id="S4.T4.4.7.3" class="ltx_td ltx_align_left ltx_border_tt">91.32</td>
<td id="S4.T4.4.7.4" class="ltx_td ltx_align_left ltx_border_tt">67.81</td>
<td id="S4.T4.4.7.5" class="ltx_td ltx_align_left ltx_border_tt">69.72</td>
<td id="S4.T4.4.7.6" class="ltx_td ltx_align_left ltx_border_tt">78.03</td>
<td id="S4.T4.4.7.7" class="ltx_td ltx_align_left ltx_border_tt">67.40</td>
</tr>
<tr id="S4.T4.4.8" class="ltx_tr">
<td id="S4.T4.4.8.1" class="ltx_td ltx_align_left">SFace-20</td>
<td id="S4.T4.4.8.2" class="ltx_td ltx_align_left">97.13</td>
<td id="S4.T4.4.8.3" class="ltx_td ltx_align_left">81.80</td>
<td id="S4.T4.4.8.4" class="ltx_td ltx_align_left">85.35</td>
<td id="S4.T4.4.8.5" class="ltx_td ltx_align_left">88.32</td>
<td id="S4.T4.4.8.6" class="ltx_td ltx_align_left">77.90</td>
</tr>
<tr id="S4.T4.4.9" class="ltx_tr">
<td id="S4.T4.4.9.1" class="ltx_td ltx_align_left">SFace-40</td>
<td id="S4.T4.4.9.2" class="ltx_td ltx_align_left">98.25</td>
<td id="S4.T4.4.9.3" class="ltx_td ltx_align_left">87.10</td>
<td id="S4.T4.4.9.4" class="ltx_td ltx_align_left">88.23</td>
<td id="S4.T4.4.9.5" class="ltx_td ltx_align_left">89.97</td>
<td id="S4.T4.4.9.6" class="ltx_td ltx_align_left">81.98</td>
</tr>
<tr id="S4.T4.4.10" class="ltx_tr">
<td id="S4.T4.4.10.1" class="ltx_td ltx_align_left">SFace-60</td>
<td id="S4.T4.4.10.2" class="ltx_td ltx_align_left">98.50</td>
<td id="S4.T4.4.10.3" class="ltx_td ltx_align_left">87.70</td>
<td id="S4.T4.4.10.4" class="ltx_td ltx_align_left">89.45</td>
<td id="S4.T4.4.10.5" class="ltx_td ltx_align_left">90.98</td>
<td id="S4.T4.4.10.6" class="ltx_td ltx_align_left">82.60</td>
</tr>
<tr id="S4.T4.4.11" class="ltx_tr">
<td id="S4.T4.4.11.1" class="ltx_td ltx_align_left ltx_border_tt">SFace-10</td>
<td id="S4.T4.4.11.2" class="ltx_td ltx_align_left ltx_border_b ltx_border_tt" rowspan="4"><span id="S4.T4.4.11.2.1" class="ltx_text">CL</span></td>
<td id="S4.T4.4.11.3" class="ltx_td ltx_align_left ltx_border_tt">96.63</td>
<td id="S4.T4.4.11.4" class="ltx_td ltx_align_left ltx_border_tt">79.61</td>
<td id="S4.T4.4.11.5" class="ltx_td ltx_align_left ltx_border_tt">82.08</td>
<td id="S4.T4.4.11.6" class="ltx_td ltx_align_left ltx_border_tt">87.43</td>
<td id="S4.T4.4.11.7" class="ltx_td ltx_align_left ltx_border_tt">76.23</td>
</tr>
<tr id="S4.T4.4.12" class="ltx_tr">
<td id="S4.T4.4.12.1" class="ltx_td ltx_align_left">SFace-20</td>
<td id="S4.T4.4.12.2" class="ltx_td ltx_align_left">98.70</td>
<td id="S4.T4.4.12.3" class="ltx_td ltx_align_left">88.00</td>
<td id="S4.T4.4.12.4" class="ltx_td ltx_align_left">87.87</td>
<td id="S4.T4.4.12.5" class="ltx_td ltx_align_left">90.62</td>
<td id="S4.T4.4.12.6" class="ltx_td ltx_align_left">83.38</td>
</tr>
<tr id="S4.T4.4.13" class="ltx_tr">
<td id="S4.T4.4.13.1" class="ltx_td ltx_align_left">SFace-40</td>
<td id="S4.T4.4.13.2" class="ltx_td ltx_align_left">99.10</td>
<td id="S4.T4.4.13.3" class="ltx_td ltx_align_left">90.41</td>
<td id="S4.T4.4.13.4" class="ltx_td ltx_align_left">90.27</td>
<td id="S4.T4.4.13.5" class="ltx_td ltx_align_left">92.05</td>
<td id="S4.T4.4.13.6" class="ltx_td ltx_align_left">86.35</td>
</tr>
<tr id="S4.T4.4.14" class="ltx_tr">
<td id="S4.T4.4.14.1" class="ltx_td ltx_align_left ltx_border_b">SFace-60</td>
<td id="S4.T4.4.14.2" class="ltx_td ltx_align_left ltx_border_b">99.13</td>
<td id="S4.T4.4.14.3" class="ltx_td ltx_align_left ltx_border_b">91.14</td>
<td id="S4.T4.4.14.4" class="ltx_td ltx_align_left ltx_border_b">91.03</td>
<td id="S4.T4.4.14.5" class="ltx_td ltx_align_left ltx_border_b">92.47</td>
<td id="S4.T4.4.14.6" class="ltx_td ltx_align_left ltx_border_b">87.03</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T4.5.2.1" class="ltx_text" style="font-size:90%;">TABLE IV</span>: </span><span id="S4.T4.2.1" class="ltx_text" style="font-size:90%;">Verification accuracies in % of different learning strategies and different subsets of SFace on the considered FR evaluation benchmarks. The <math id="S4.T4.2.1.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S4.T4.2.1.m1.1b"><mi id="S4.T4.2.1.m1.1.1" xref="S4.T4.2.1.m1.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S4.T4.2.1.m1.1c"><ci id="S4.T4.2.1.m1.1.1.cmml" xref="S4.T4.2.1.m1.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.2.1.m1.1d">\alpha</annotation></semantics></math> hyper-parameter is set to 1e-5 as it led to best performances (Table <a href="#S3.T1" title="TABLE I â€£ III-C Face Recognition Training Setups â€£ III Experimental Setup â€£ SFace: Privacy-friendly and Accurate Face Recognition using Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a>). One can notice that increasing the synthetic training data size in terms of samples per identity (going from SFace-10 to SFace-60) does generally increase the FR performance, however with some saturation behavior when moving to SFace-40 and SFace-60. </span></figcaption>
</figure>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">Conclusion</span>
</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">This work is motivated by the need for privacy-friendly biometric data to enable further development of FR, where many privacy, legal, and ethical concerns are raised regarding the collection, use, and sharing of authentic biometric data.
Towards that, we first created a synthetic face dataset, SFace, by training a StyleGAN2-ADA under class-conditional settings, and then, using the generative model to generate our synthetic data, the SFace.
Using SFace, we provided intensive evaluation experiments to address three main research questions posed in this paper regarding the identity separability in the synthetic SFace dataset, the identity-relation between the synthetic dataset and authentic dataset used to train its generator, and the feasibility of using synthetic data to train FR under different presented learning strategies.
Our investigation proved that SFace possesses, to a certain degree, the identity discriminant information, the identity-relation between SFace and the authentic datasets is extremely weak, and SFace achieved relatively high verification performances on a wide set of benchmarks using the presented learning strategies.
</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock"><span id="bib.bib1.1.1" class="ltx_text" style="font-size:90%;">
Privacy measures of biometrics businesses.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.2.1" class="ltx_text" style="font-size:90%;">Technical report, NEC Technical Journal, 2018.
</span>
</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock"><span id="bib.bib2.1.1" class="ltx_text" style="font-size:90%;">
740 ILCS/14.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.2.1" class="ltx_text" style="font-size:90%;">Biometric Information Privacy Act (BIPA).
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.3.1" class="ltx_text" style="font-size:90%;">Public act 095-994, Illinois General Assembly, 2008.
</span>
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock"><span id="bib.bib3.1.1" class="ltx_text" style="font-size:90%;">
F.Â Boutros, N.Â Damer, F.Â Kirchbuchner, and A.Â Kuijper.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.2.1" class="ltx_text" style="font-size:90%;">Elasticface: Elastic margin loss for deep face recognition.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib3.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Conference on Computer Vision and Pattern Recognition
Workshops, CVPR Workshops 2022, New Orleans, Louisiana, USA, June 19-24,
2022</span><span id="bib.bib3.5.3" class="ltx_text" style="font-size:90%;">. Computer Vision Foundation / IEEE, 2022.
</span>
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock"><span id="bib.bib4.1.1" class="ltx_text" style="font-size:90%;">
Q.Â Cao, L.Â Shen, W.Â Xie, O.Â M. Parkhi, and A.Â Zisserman.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.2.1" class="ltx_text" style="font-size:90%;">Vggface2: A dataset for recognising faces across pose and age.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib4.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">FG</span><span id="bib.bib4.5.3" class="ltx_text" style="font-size:90%;">, pages 67â€“74. IEEE Computer Society, 2018.
</span>
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock"><span id="bib.bib5.1.1" class="ltx_text" style="font-size:90%;">
N.Â Damer, C.Â A.Â F. LÃ³pez, M.Â Fang, N.Â Spiller, M.Â V. Pham, and
F.Â Boutros.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.2.1" class="ltx_text" style="font-size:90%;">Privacy-friendly synthetic data for the development of face morphing
attack detectors.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">CoRR</span><span id="bib.bib5.4.2" class="ltx_text" style="font-size:90%;">, abs/2203.06691, 2022.
</span>
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock"><span id="bib.bib6.1.1" class="ltx_text" style="font-size:90%;">
J.Â Deng, J.Â Guo, N.Â Xue, and S.Â Zafeiriou.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.2.1" class="ltx_text" style="font-size:90%;">Arcface: Additive angular margin loss for deep face recognition.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib6.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib6.5.3" class="ltx_text" style="font-size:90%;">, pages 4690â€“4699, 2019.
</span>
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock"><span id="bib.bib7.1.1" class="ltx_text" style="font-size:90%;">
C.Â Dowrk, M.Â Bugliese, B.Â Preneel, V.Â Sassone, and I.Â Wegener, editors.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.2.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Differential Privacy</span><span id="bib.bib7.3.2" class="ltx_text" style="font-size:90%;">, pages 1â€“12.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.4.1" class="ltx_text" style="font-size:90%;">Springer, Berlin, Heidelberg, 2006.
</span>
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock"><span id="bib.bib8.1.1" class="ltx_text" style="font-size:90%;">
K.Â ElÂ Emam.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.2.1" class="ltx_text" style="font-size:90%;">Seven ways to evaluate the utility of synthetic data.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Security Privacy</span><span id="bib.bib8.4.2" class="ltx_text" style="font-size:90%;">, 18(4):56â€“59, 2020.
</span>
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock"><span id="bib.bib9.1.1" class="ltx_text" style="font-size:90%;">
K.Â ElÂ Emam, L.Â Mosquera, and R.Â Hoptroff.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.2.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Practical Synthetic Data Generation: Balancing Privacy and the
Broad Availability of Data</span><span id="bib.bib9.3.2" class="ltx_text" style="font-size:90%;">.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.4.1" class="ltx_text" style="font-size:90%;">Oâ€™Reilly Media, Incorporated, 2020.
</span>
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text" style="font-size:90%;">
Frontex.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.2.1" class="ltx_text" style="font-size:90%;">Best practice technical guidelines for automated border control (abc)
systems, 2015.
</span>
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text" style="font-size:90%;">
Y.Â Guo, L.Â Zhang, Y.Â Hu, X.Â He, and J.Â Gao.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.2.1" class="ltx_text" style="font-size:90%;">Ms-celeb-1m: A dataset and benchmark for large-scale face
recognition.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib11.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Computer Vision - ECCV 2016 - 14th European Conference,
Amsterdam, The Netherlands, October 11-14, 2016, Proceedings, Part III</span><span id="bib.bib11.5.3" class="ltx_text" style="font-size:90%;">,
volume 9907 of </span><span id="bib.bib11.6.4" class="ltx_text ltx_font_italic" style="font-size:90%;">Lecture Notes in Computer Science</span><span id="bib.bib11.7.5" class="ltx_text" style="font-size:90%;">, pages 87â€“102.
Springer, 2016.
</span>
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock"><span id="bib.bib12.1.1" class="ltx_text" style="font-size:90%;">
K.Â He, X.Â Zhang, S.Â Ren, and J.Â Sun.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.2.1" class="ltx_text" style="font-size:90%;">Deep residual learning for image recognition.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib12.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib12.5.3" class="ltx_text" style="font-size:90%;">, pages 770â€“778. IEEE Computer Society, 2016.
</span>
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text" style="font-size:90%;">
G.Â B. Huang, M.Â Ramesh, T.Â Berg, and E.Â Learned-Miller.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.2.1" class="ltx_text" style="font-size:90%;">Labeled faces in the wild: A database for studying face recognition
in unconstrained environments.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.3.1" class="ltx_text" style="font-size:90%;">Technical Report 07-49, University of Massachusetts, Amherst, October
2007.
</span>
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock"><span id="bib.bib14.1.1" class="ltx_text" style="font-size:90%;">
T.Â Karras, M.Â Aittala, J.Â Hellsten, S.Â Laine, J.Â Lehtinen, and T.Â Aila.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.2.1" class="ltx_text" style="font-size:90%;">Training generative adversarial networks with limited data.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib14.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">NeurIPS</span><span id="bib.bib14.5.3" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock"><span id="bib.bib15.1.1" class="ltx_text" style="font-size:90%;">
T.Â Karras, S.Â Laine, and T.Â Aila.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.2.1" class="ltx_text" style="font-size:90%;">A style-based generator architecture for generative adversarial
networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib15.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib15.5.3" class="ltx_text" style="font-size:90%;">, pages 4401â€“4410. Computer Vision Foundation /
IEEE, 2019.
</span>
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock"><span id="bib.bib16.1.1" class="ltx_text" style="font-size:90%;">
T.Â Karras, S.Â Laine, M.Â Aittala, J.Â Hellsten, J.Â Lehtinen, and T.Â Aila.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.2.1" class="ltx_text" style="font-size:90%;">Analyzing and improving the image quality of stylegan.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib16.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib16.5.3" class="ltx_text" style="font-size:90%;">, pages 8107â€“8116. Computer Vision Foundation /
IEEE, 2020.
</span>
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock"><span id="bib.bib17.1.1" class="ltx_text" style="font-size:90%;">
I.Â Kemelmacher-Shlizerman, S.Â M. Seitz, D.Â Miller, and E.Â Brossard.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.2.1" class="ltx_text" style="font-size:90%;">The megaface benchmark: 1 million faces for recognition at scale.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib17.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib17.5.3" class="ltx_text" style="font-size:90%;">, pages 4873â€“4882, 2016.
</span>
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock"><span id="bib.bib18.1.1" class="ltx_text" style="font-size:90%;">
A.Â Kortylewski, B.Â Egger, A.Â Schneider, T.Â Gerig, A.Â Morel-Forster, and
T.Â Vetter.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.2.1" class="ltx_text" style="font-size:90%;">Analyzing and reducing the damage of dataset bias to face recognition
with synthetic data.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib18.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR Workshops</span><span id="bib.bib18.5.3" class="ltx_text" style="font-size:90%;">, pages 2261â€“2268. Computer Vision
Foundation / IEEE, 2019.
</span>
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock"><span id="bib.bib19.1.1" class="ltx_text" style="font-size:90%;">
Y.Â Lindell and B.Â Pinkas.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.2.1" class="ltx_text" style="font-size:90%;">Secure multiparty computation for privacy-preserving data mining.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Journal of Privacy and Confidentiality</span><span id="bib.bib19.4.2" class="ltx_text" style="font-size:90%;">, 1(1), Apr. 2009.
</span>
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock"><span id="bib.bib20.1.1" class="ltx_text" style="font-size:90%;">
A.Â Machanavajjhala, D.Â Kifer, J.Â Abowd, J.Â Gehrke, and L.Â Vilhuber.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.2.1" class="ltx_text" style="font-size:90%;">Privacy: Theory meets practice on the map.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib20.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2008 IEEE 24th International Conference on Data Engineering</span><span id="bib.bib20.5.3" class="ltx_text" style="font-size:90%;">,
pages 277â€“286, 2008.
</span>
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock"><span id="bib.bib21.1.1" class="ltx_text" style="font-size:90%;">
B.Â Meden, P.Â Rot, P.Â TerhÃ¶rst, N.Â Damer, A.Â Kuijper, W.Â J. Scheirer,
A.Â Ross, P.Â Peer, and V.Â Struc.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.2.1" class="ltx_text" style="font-size:90%;">Privacy-enhancing face biometrics: A comprehensive survey.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Trans. Inf. Forensics Secur.</span><span id="bib.bib21.4.2" class="ltx_text" style="font-size:90%;">, 16:4147â€“4183, 2021.
</span>
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock"><span id="bib.bib22.1.1" class="ltx_text" style="font-size:90%;">
T.Â Miyato and M.Â Koyama.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.2.1" class="ltx_text" style="font-size:90%;">cgans with projection discriminator.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib22.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">6th International Conference on Learning Representations,
ICLR 2018, Vancouver, BC, Canada, April 30 - May 3, 2018, Conference Track
Proceedings</span><span id="bib.bib22.5.3" class="ltx_text" style="font-size:90%;">. OpenReview.net, 2018.
</span>
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock"><span id="bib.bib23.1.1" class="ltx_text" style="font-size:90%;">
S.Â Moschoglou, A.Â Papaioannou, C.Â Sagonas, J.Â Deng, I.Â Kotsia, and
S.Â Zafeiriou.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.2.1" class="ltx_text" style="font-size:90%;">Agedb: The first manually collected, in-the-wild age database.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib23.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR Workshops</span><span id="bib.bib23.5.3" class="ltx_text" style="font-size:90%;">, pages 1997â€“2005. IEEE Computer Society,
2017.
</span>
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock"><span id="bib.bib24.1.1" class="ltx_text" style="font-size:90%;">
A.Â Paszke, S.Â Gross, F.Â Massa, A.Â Lerer, J.Â Bradbury, G.Â Chanan, T.Â Killeen,
Z.Â Lin, N.Â Gimelshein, L.Â Antiga, A.Â Desmaison, A.Â Kopf, E.Â Yang, Z.Â DeVito,
M.Â Raison, A.Â Tejani, S.Â Chilamkurthy, B.Â Steiner, L.Â Fang, J.Â Bai, and
S.Â Chintala.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.2.1" class="ltx_text" style="font-size:90%;">Pytorch: An imperative style, high-performance deep learning library.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.3.1" class="ltx_text" style="font-size:90%;">In H.Â Wallach, H.Â Larochelle, A.Â Beygelzimer, F.Â d'AlchÃ©-Buc, E.Â Fox, and R.Â Garnett, editors, </span><span id="bib.bib24.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Advances in Neural
Information Processing Systems 32</span><span id="bib.bib24.5.3" class="ltx_text" style="font-size:90%;">, pages 8024â€“8035. Curran Associates,
Inc., 2019.
</span>
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock"><span id="bib.bib25.1.1" class="ltx_text" style="font-size:90%;">
H.Â Qiu, B.Â Yu, D.Â Gong, Z.Â Li, W.Â Liu, and D.Â Tao.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.2.1" class="ltx_text" style="font-size:90%;">Synface: Face recognition with synthetic data.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib25.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICCV</span><span id="bib.bib25.5.3" class="ltx_text" style="font-size:90%;">, pages 10860â€“10870. IEEE, 2021.
</span>
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock"><span id="bib.bib26.1.1" class="ltx_text" style="font-size:90%;">
I.Â D. Raji and G.Â Fried.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.2.1" class="ltx_text" style="font-size:90%;">About face: A survey of facial recognition evaluation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">CoRR</span><span id="bib.bib26.4.2" class="ltx_text" style="font-size:90%;">, abs/2102.00813, 2021.
</span>
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock"><span id="bib.bib27.1.1" class="ltx_text" style="font-size:90%;">
E.Â Ristani, F.Â Solera, R.Â S. Zou, R.Â Cucchiara, and C.Â Tomasi.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.2.1" class="ltx_text" style="font-size:90%;">Performance measures and a data set for multi-target, multi-camera
tracking.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib27.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ECCV Workshops (2)</span><span id="bib.bib27.5.3" class="ltx_text" style="font-size:90%;">, volume 9914 of </span><span id="bib.bib27.6.4" class="ltx_text ltx_font_italic" style="font-size:90%;">Lecture Notes in
Computer Science</span><span id="bib.bib27.7.5" class="ltx_text" style="font-size:90%;">, pages 17â€“35, 2016.
</span>
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock"><span id="bib.bib28.1.1" class="ltx_text" style="font-size:90%;">
D.Â Saez-Trigueros, L.Â Meng, and M.Â Hartnett.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.2.1" class="ltx_text" style="font-size:90%;">Generating photo-realistic training data to improve face recognition
accuracy.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Neural Networks</span><span id="bib.bib28.4.2" class="ltx_text" style="font-size:90%;">, 134:86â€“94, 2021.
</span>
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock"><span id="bib.bib29.1.1" class="ltx_text" style="font-size:90%;">
F.Â Schroff, D.Â Kalenichenko, and J.Â Philbin.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.2.1" class="ltx_text" style="font-size:90%;">Facenet: A unified embedding for face recognition and clustering.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib29.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Conference on Computer Vision and Pattern Recognition,
CVPR 2015, Boston, MA, USA, June 7-12, 2015</span><span id="bib.bib29.5.3" class="ltx_text" style="font-size:90%;">, pages 815â€“823. IEEE
Computer Society, 2015.
</span>
</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock"><span id="bib.bib30.1.1" class="ltx_text" style="font-size:90%;">
S.Â Sengupta, J.Â Chen, C.Â D. Castillo, V.Â M. Patel, R.Â Chellappa, and D.Â W.
Jacobs.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.2.1" class="ltx_text" style="font-size:90%;">Frontal to profile face verification in the wild.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib30.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">WACV</span><span id="bib.bib30.5.3" class="ltx_text" style="font-size:90%;">, pages 1â€“9. IEEE Computer Society, 2016.
</span>
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock"><span id="bib.bib31.1.1" class="ltx_text" style="font-size:90%;">
B.Â Shen, B.Â RichardWebster, A.Â J. Oâ€™Toole, K.Â W. Bowyer, and W.Â J. Scheirer.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.2.1" class="ltx_text" style="font-size:90%;">A study of the human perception of synthetic faces.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib31.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">FG</span><span id="bib.bib31.5.3" class="ltx_text" style="font-size:90%;">, pages 1â€“8. IEEE, 2021.
</span>
</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock"><span id="bib.bib32.1.1" class="ltx_text" style="font-size:90%;">
The European Parliament and the Council of the European Union.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.2.1" class="ltx_text" style="font-size:90%;">Article 22(4) of the general data protection regulation, 2016.
</span>
</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock"><span id="bib.bib33.1.1" class="ltx_text" style="font-size:90%;">
The European Parliament and the Council of the European Union.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.2.1" class="ltx_text" style="font-size:90%;">Article 26 of the general data protection regulation, 2016.
</span>
</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock"><span id="bib.bib34.1.1" class="ltx_text" style="font-size:90%;">
The European Parliament and the Council of the European Union.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.2.1" class="ltx_text" style="font-size:90%;">Article 27(2) of the general data protection regulation, 2016.
</span>
</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock"><span id="bib.bib35.1.1" class="ltx_text" style="font-size:90%;">
The European Parliament and the Council of the European Union.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.2.1" class="ltx_text" style="font-size:90%;">Article 30 of the general data protection regulation, 2016.
</span>
</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock"><span id="bib.bib36.1.1" class="ltx_text" style="font-size:90%;">
The European Parliament and the Council of the European Union.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.2.1" class="ltx_text" style="font-size:90%;">Article 35(3) of the general data protection regulation, 2016.
</span>
</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock"><span id="bib.bib37.1.1" class="ltx_text" style="font-size:90%;">
The European Parliament and the Council of the European Union.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.2.1" class="ltx_text" style="font-size:90%;">Article 37(1) of the general data protection regulation, 2016.
</span>
</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock"><span id="bib.bib38.1.1" class="ltx_text" style="font-size:90%;">
The European Parliament and the Council of the European Union.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.2.1" class="ltx_text" style="font-size:90%;">Article 6(4) of the general data protection regulation, 2016.
</span>
</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock"><span id="bib.bib39.1.1" class="ltx_text" style="font-size:90%;">
The European Parliament and the Council of the European Union.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.2.1" class="ltx_text" style="font-size:90%;">Article 9 of the general data protection regulation, 2016.
</span>
</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock"><span id="bib.bib40.1.1" class="ltx_text" style="font-size:90%;">
The European Parliament and the Council of the European Union.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.2.1" class="ltx_text" style="font-size:90%;">Article 9(2) of the general data protection regulation, 2016.
</span>
</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock"><span id="bib.bib41.1.1" class="ltx_text" style="font-size:90%;">
The European Parliament and the Council of the European Union.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib41.2.1" class="ltx_text" style="font-size:90%;">Article 9(4) of the general data protection regulation, 2016.
</span>
</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock"><span id="bib.bib42.1.1" class="ltx_text" style="font-size:90%;">
The European Parliament and the Council of the European Union.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.2.1" class="ltx_text" style="font-size:90%;">Regulation (eu) 2016/679 of the european parliament and of the
council of 27 april 2016 on the protection of natural persons with regard to
the processing of personal data and on the free movement of such data, and
repealing directive 95/46/ec (General Data Protection Regulation), 2016.
</span>
</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock"><span id="bib.bib43.1.1" class="ltx_text" style="font-size:90%;">
H.Â Wang, Y.Â Wang, Z.Â Zhou, X.Â Ji, D.Â Gong, J.Â Zhou, Z.Â Li, and W.Â Liu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib43.2.1" class="ltx_text" style="font-size:90%;">Cosface: Large margin cosine loss for deep face recognition.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib43.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib43.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib43.5.3" class="ltx_text" style="font-size:90%;">, pages 5265â€“5274. Computer Vision Foundation /
IEEE Computer Society, 2018.
</span>
</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock"><span id="bib.bib44.1.1" class="ltx_text" style="font-size:90%;">
Q.Â Wang, J.Â Gao, W.Â Lin, and Y.Â Yuan.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib44.2.1" class="ltx_text" style="font-size:90%;">Learning from synthetic data for crowd counting in the wild.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib44.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib44.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib44.5.3" class="ltx_text" style="font-size:90%;">, pages 8198â€“8207. Computer Vision Foundation /
IEEE, 2019.
</span>
</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock"><span id="bib.bib45.1.1" class="ltx_text" style="font-size:90%;">
D.Â Yi, Z.Â Lei, S.Â Liao, and S.Â Z. Li.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib45.2.1" class="ltx_text" style="font-size:90%;">Learning face representation from scratch.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib45.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">CoRR</span><span id="bib.bib45.4.2" class="ltx_text" style="font-size:90%;">, abs/1411.7923, 2014.
</span>
</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock"><span id="bib.bib46.1.1" class="ltx_text" style="font-size:90%;">
Z.Â Zhai, P.Â Yang, X.Â Zhang, M.Â Huang, H.Â Cheng, X.Â Yan, C.Â Wang, and S.Â Pu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib46.2.1" class="ltx_text" style="font-size:90%;">Demodalizing face recognition with synthetic samples.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib46.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib46.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Thirty-Fifth AAAI Conference on Artificial Intelligence,
AAAI 2021, Thirty-Third Conference on Innovative Applications of Artificial
Intelligence, IAAI 2021, The Eleventh Symposium on Educational Advances in
Artificial Intelligence, EAAI 2021, Virtual Event, February 2-9, 2021</span><span id="bib.bib46.5.3" class="ltx_text" style="font-size:90%;">,
pages 3278â€“3286. AAAI Press, 2021.
</span>
</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock"><span id="bib.bib47.1.1" class="ltx_text" style="font-size:90%;">
H.Â Zhang, M.Â Grimmer, R.Â Ramachandra, K.Â B. Raja, and C.Â Busch.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib47.2.1" class="ltx_text" style="font-size:90%;">On the applicability of synthetic data for face recognition.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib47.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib47.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">IWBF</span><span id="bib.bib47.5.3" class="ltx_text" style="font-size:90%;">, pages 1â€“6. IEEE, 2021.
</span>
</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock"><span id="bib.bib48.1.1" class="ltx_text" style="font-size:90%;">
K.Â Zhang, Z.Â Zhang, Z.Â Li, and Y.Â Qiao.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib48.2.1" class="ltx_text" style="font-size:90%;">Joint face detection and alignment using multitask cascaded
convolutional networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib48.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Signal Processing Letters</span><span id="bib.bib48.4.2" class="ltx_text" style="font-size:90%;">, 23(10):1499â€“1503, 2016.
</span>
</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock"><span id="bib.bib49.1.1" class="ltx_text" style="font-size:90%;">
T.Â Zheng and W.Â Deng.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib49.2.1" class="ltx_text" style="font-size:90%;">Cross-pose lfw: A database for studying cross-pose face recognition
in unconstrained environments.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib49.3.1" class="ltx_text" style="font-size:90%;">Technical Report 18-01, Beijing University of Posts and
Telecommunications, February 2018.
</span>
</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock"><span id="bib.bib50.1.1" class="ltx_text" style="font-size:90%;">
T.Â Zheng, W.Â Deng, and J.Â Hu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib50.2.1" class="ltx_text" style="font-size:90%;">Cross-age LFW: A database for studying cross-age face recognition
in unconstrained environments.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib50.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">CoRR</span><span id="bib.bib50.4.2" class="ltx_text" style="font-size:90%;">, abs/1708.08197, 2017.
</span>
</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2206.10519" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2206.10520" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2206.10520">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2206.10520" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2206.10521" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Mon Mar 11 16:08:52 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
