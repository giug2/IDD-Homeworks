<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2302.08905] GraphLED: A graph-based approach to process and visualise linked engineering documents</title><meta property="og:description" content="The architecture, engineering and construction (AEC) sector extensively uses documents supporting product and process development. As part of this, organisations should handle big data of hundreds, or even thousands, o‚Ä¶">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="GraphLED: A graph-based approach to process and visualise linked engineering documents">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="GraphLED: A graph-based approach to process and visualise linked engineering documents">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2302.08905">

<!--Generated on Fri Mar  1 01:43:11 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">GraphLED: A graph-based approach to process and visualise linked engineering documents
</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Vanessa T. da Silva, Lucas de A. M. Ribeiro, Willian B. de Lemos, 
<br class="ltx_break"><span id="id1.1.id1" class="ltx_text ltx_font_bold">S√≠lvia S. da C. Botelho</span>, <span id="id2.2.id2" class="ltx_text ltx_font_bold">Nelson L. D. Filho</span>, <span id="id3.3.id3" class="ltx_text ltx_font_bold">Marcelo R. Pias</span> 
<br class="ltx_break">Universidade Feral do Rio Grande (FURG) 
<br class="ltx_break">Rio Grande, RS, Brazil
<br class="ltx_break"><span id="id4.4.id4" class="ltx_text ltx_font_typewriter">{vanessa.telles, lucasribeiro, willianlemos.b, silviacb, dmtnldf, mpias}@furg.br</span> 
<br class="ltx_break">
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id5.id1" class="ltx_p">The architecture, engineering and construction (AEC) sector extensively uses documents supporting product and process development. As part of this, organisations should handle big data of hundreds, or even thousands, of technical documents strongly linked together, including CAD design of industrial plants, equipment purchase orders, quality certificates, and part material analysis. However, analysing such records is daunting for users because it gets complicated to sift through hundreds of documents to establish valuable relationships. This paper addresses how knowledge extracted from linked engineering documents contributes to industrial digitalisation under IT/OT convergence. The proposed GraphLED is a system tasked with data processing, graph-based modelling, and colourful visualisation of related documents. The graph-based approach ensures an improved understanding of linked information because the graph structure offers a promising tool to model the underlying data properties of engineering documents. Preliminary system validation indicates quality improvements are possible in the OCR-based data (85.9% of ambiguous text data removed). This work has the potential to benefit the industry by improving the reliability and resilience of industrial production systems through automated summaries of large quantities of documents and their linkage.</p>
</div>
<div id="p1" class="ltx_para ltx_noindent">
<p id="p1.1" class="ltx_p"><em id="p1.1.1" class="ltx_emph ltx_font_bold ltx_font_italic">K</em><span id="p1.1.2" class="ltx_text ltx_font_bold">eywords</span>‚ÄÇgraph-based processing, document processing, industrial digital transformation, industrial IO, graph big data</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para ltx_noindent">
<p id="S1.p1.1" class="ltx_p">Ubiquitous data creation has grown at a rapid pace, with big data collection providing tangible digital transformation benefits in several industries <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. However, data remains document-centric in mixed analogue, and digital formats in more traditional sectors, including architecture, engineering and construction (AEC). Organisations often deal with hundreds, or even thousands, of technical documents such as CAD design of industrial factory plants, fleet design, equipment purchase orders, quality certificates, and material analysis <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para ltx_noindent">
<p id="S1.p2.1" class="ltx_p">The management of technical documents with efficient tools leads to efficient coordination of critical day-to-day activities throughout AEC process lifetime <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>.To this end, continuous data processing and visualisation bring considerable benefits to the AEC end-users: (i) support timely inspection of engineering projects, (ii) develop automated document compliance models with existing standards and societies‚Äô guidelines and (iii) promote information exchange among key stakeholders (suppliers, clients, standards societies). However, AEC documents are inherently complex because diverse unstructured topics usually link many documents to convey the information. Conventional state-of-the-art approaches that handle structured data (e.g. search by keywords in relational databases) are not feasible in this case <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>.</p>
</div>
<div id="S1.p3" class="ltx_para ltx_noindent">
<p id="S1.p3.1" class="ltx_p">The relationship between the tables is defined in advance, so users can only obtain limited relevant knowledge <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>. Paper-based documents further complicate the matter where scanned handwritten reports, technical specifications, engineering drawings, schematics, stamps, signatures and so on <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> make it challenging to retrieve information efficiently, even in its simplest form. For instance, a <span id="S1.p3.1.1" class="ltx_text ltx_font_italic">databook</span> ‚Äìa collection of engineering documents that specify project events ‚Äì comprises many pieces of data (i.e. topics) that coherently link with data present in other databooks. This interconnection creates a complex yet powerful <span id="S1.p3.1.2" class="ltx_text ltx_font_italic">network</span> of related engineering documents that offer several features. For instance, the end-users can visually inspect the material traceability of equipment parts and their compliance with current technical specifications (e.g. ASTM - American Society for Testing and Materials). Today the visualisation and inspection of a large dataset of documents become challenging and error-prone if the user is not assisted by big data tools.</p>
</div>
<div id="S1.p4" class="ltx_para ltx_noindent">
<p id="S1.p4.1" class="ltx_p">A key high-level question in this context is: <span id="S1.p4.1.1" class="ltx_text ltx_font_italic">how could knowledge, namely engineering document summaries and their relationships, extracted from noisy OCR processed engineering documents contribute to industrial digitalisation and resilience of production systems?</span></p>
</div>
<div id="S1.p5" class="ltx_para ltx_noindent">
<p id="S1.p5.1" class="ltx_p">The knowledge extraction is expected to be carried out efficiently and close to real-time. Equally important in this process is the exploitation of the cross-reference data between documents to obtain new information, a task that is inherently difficult for humans because of the document network depth and broadness <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>.</p>
</div>
<div id="S1.p6" class="ltx_para ltx_noindent">
<p id="S1.p6.1" class="ltx_p">This paper sheds some light to answer the question above. The proposed approach considers a simple yet promising mechanism to extract and structure the data for processing, knowledge extraction, and visualisation from diverse engineering databooks. The GraphLED is a system tasked with data processing, graph-based modelling, and visualisation of related documents. The graph-based approach ensures an improved understanding of linked information because the graph structure offers a first-hand tool to represent and model the underlying data properties <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>.</p>
</div>
<div id="S1.p7" class="ltx_para ltx_noindent">
<p id="S1.p7.1" class="ltx_p">The system assumes a moderate level of correctness in the close-to-real-time knowledge extraction from scanned documents, particularly cross-reference data. For instance, ambiguous data from OCR processing introduces errors that should be handled accordingly.</p>
</div>
<div id="S1.p8" class="ltx_para ltx_noindent">
<p id="S1.p8.1" class="ltx_p">This paper is structured as follows: Section 2 discusses related work. Section 3 explores user requirements and GraphLED design choices. The system architecture is discussed in Section 4. Finally, sections 5 and 6 present the validation results and draw the paper‚Äôs conclusions.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<div id="S2.p1" class="ltx_para ltx_noindent">
<p id="S2.p1.1" class="ltx_p">Engineering databooks are complex documents. The user‚Äôs acceptable level of data correctness associated with the knowledge extraction remains an open challenge, particularly considering the output quality obtained from the available OCR tools (e.g. Tesseract, Google OCR). The issue is beyond the OCR tools, where low-quality scanning of documents remains the norm in the industry. Conventional approaches that handle structured data are not very robust in this case, as noisy data in document table cells lead to limited relevant
knowledge <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>.</p>
</div>
<div id="S2.p2" class="ltx_para ltx_noindent">
<p id="S2.p2.1" class="ltx_p">Several applications use graph-based analysis to extract knowledge and visualise the results. For example, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> seeks to create public awareness of UN members voting patterns. The approach uses social knowledge graphs and similarity measures to analyse the publicly available information on the member votes. Because graphs lend themselves to intuitive visualisation, this work explored visual aids from the data. However, such an approach is less robust to data noise since stages of acquisition, treatment, and handling of the data require a prior pre-processed and ready-for-use dataset. Linked engineering AEC documents establish connections (e.g. purchase order number, quality certificate ID) that can be followed and analysed through automated software tools <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>.</p>
</div>
<div id="S2.p3" class="ltx_para ltx_noindent">
<p id="S2.p3.1" class="ltx_p">The graph-based analysis explores algorithms on graph data structures <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>. For instance, the graph-based document representation system (CGDR) provides classification reports intended for document forensic analysis <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>. A total of 1500 files were used in the study to classify 16 types of reports. The method structures the information as graph nodes and uses hierarchical text classification to set the reading order. However, the proposed model is not the ideal solution as it still depends on human experts to identify the useful features for each type of report.</p>
</div>
<div id="S2.p4" class="ltx_para ltx_noindent">
<p id="S2.p4.1" class="ltx_p">A more automated and adaptive approach could benefit the application in many ways. Also, the data should be inputted in an advanced processing stage (e.g. augmented, cleaned) for the system to work. The work in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> proposes a graph-based method for inductive text classification in documents.</p>
</div>
<div id="S2.p5" class="ltx_para ltx_noindent">
<p id="S2.p5.1" class="ltx_p">The system builds individual graphs for each document fed into a Graph Neural Network (GNN) that learns fine-grained word representations based on their local structures. The proposed approach can effectively produce embeddings for unseen words in new documents. However, the noisy data limit the robustness of the proposed work. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> introduces knowledge graphs and ontologies to cope with the complex network of decisions in construction documents. Other related work explores methods and algorithms in automated analysis of engineering drawings, commonly used in the oil and gas engineering industry.</p>
</div>
<div id="S2.p6" class="ltx_para ltx_noindent">
<p id="S2.p6.1" class="ltx_p">Authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> acknowledge the document quality as being the backbone of the problem, given that a poor-quality drawing (e.g. a paper that has been scanned numerous times) is virtually impossible to digitise unless a robust set of pre-processing methods are used.</p>
</div>
<div id="S2.p7" class="ltx_para ltx_noindent">
<p id="S2.p7.1" class="ltx_p">The proposed work addressed the problem using a deep neural network with satisfactory improvements. However, the approach remains model-centric (i.e. model hyperparameter tuning) with little effort in improving the raw data quality through pre-processing, cleaning, augmentation or re-shaping. Existing work explores to a great extent digitalisation of documents through OCR (Optical character recognition) based techniques <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>. The benefits of the links between documents to unveil very relevant patterns in knowledge extraction are not sufficiently explored in the previous work.</p>
</div>
<div id="S2.p8" class="ltx_para ltx_noindent">
<p id="S2.p8.1" class="ltx_p">The prior art acknowledges the challenge of achieving a satisfactory level of data correctness regarding close-to-real-time knowledge extraction from scanned documents, particularly cross-reference data. Data noise propagates throughout the knowledge extraction processing pipeline to visualisation and user engagement.</p>
</div>
<div id="S2.p9" class="ltx_para ltx_noindent">
<p id="S2.p9.1" class="ltx_p">The previous work primarily addresses the correctness problem using human-intensive correction <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> or, more recently, using model-centric deep neural networks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>, where the job is to fine-tune model hyperparameters as opposed to improve input data quality.
This paper advances the state-of-the-art as follows:</p>
<ul id="S2.I1" class="ltx_itemize">
<li id="S2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="S2.I1.i1.p1" class="ltx_para">
<p id="S2.I1.i1.p1.1" class="ltx_p">Proposes and validates data cleaning, and augmentation techniques (i.e. data-centric methodology) in noisy OCR scanned documents to overcome the so-called <span id="S2.I1.i1.p1.1.1" class="ltx_text ltx_font_italic">garbage in, garbage out</span> error propagation.</p>
</div>
</li>
<li id="S2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="S2.I1.i2.p1" class="ltx_para ltx_noindent">
<p id="S2.I1.i2.p1.1" class="ltx_p">Proposes a system architecture to provide a large scale graph-based tool for close-to-real-time knowledge extraction and representation, assisting users in the difficult task of sifting through hundreds to thousand of documents. The system validation focuses on the performance and scalability issues.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>System Design Choices</h2>

<div id="S3.p1" class="ltx_para ltx_noindent">
<p id="S3.p1.1" class="ltx_p">The proposed work is part of a larger technology-driven project that aims at digitalising industrial documents (OCR-based) grouped in databooks units. The work realises the vision of building digital twins tailored for the Oil&amp;Gas industry to benefit users whose roles include inspection of documentation of materials, equipment, construction processes and quality control as part of the IT/OT convergence trend. A series of meetings and workshops were held with AEC documentation inspectors in 2021 that elicited the following list of user requirements:</p>
</div>
<div id="S3.p2" class="ltx_para ltx_noindent">
<ul id="S3.I1" class="ltx_itemize">
<li id="S3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="S3.I1.i1.p1" class="ltx_para">
<p id="S3.I1.i1.p1.1" class="ltx_p">Ability to upload and extract key information from a large quantity of scanned databooks through OCR-based systems. The expected correctness level is minimal ambiguity in the knowledge-extracted data.</p>
</div>
</li>
<li id="S3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="S3.I1.i2.p1" class="ltx_para">
<p id="S3.I1.i2.p1.1" class="ltx_p">Capability to visualise, manipulate and analyse databooks through intuitive and easy-to-use interfaces.</p>
</div>
</li>
<li id="S3.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="S3.I1.i3.p1" class="ltx_para">
<p id="S3.I1.i3.p1.1" class="ltx_p">Carry out usual inspection tasks (Completeness and Conformance) in an automated fashion.</p>
</div>
</li>
<li id="S3.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="S3.I1.i4.p1" class="ltx_para">
<p id="S3.I1.i4.p1.1" class="ltx_p">Assert that specific information extracted from a databook complies with existing technical specifications and standards (e.g. ASTM B16).</p>
</div>
</li>
<li id="S3.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="S3.I1.i5.p1" class="ltx_para ltx_noindent">
<p id="S3.I1.i5.p1.1" class="ltx_p">Discover where and how the product and process were made (traceability, anomaly detection).</p>
</div>
</li>
</ul>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Databooks</h3>

<div id="S3.SS1.p1" class="ltx_para ltx_noindent">
<p id="S3.SS1.p1.1" class="ltx_p">The data space of interest comprises technical documents that make references to other documents. For instance, an equipment purchase order document can have relationships with complementary documents describing the chemical and physical properties of the materials used.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para ltx_noindent">
<p id="S3.SS1.p2.1" class="ltx_p">Another example is the collection of information that documents the construction process of offshore oil rigs and platforms. In this context, a databook is a group of related documents covering relevant aspects of a specific product or process cycle, from material production, batch production, product conformance validation and purchase order description.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para ltx_noindent">
<p id="S3.SS1.p3.1" class="ltx_p">For instance, the purchase of a bolt for a high-pressure gas pipe is described in a databook. A series of documents specify the bolt part‚Äôs key aspects, including the manufacturing process, material properties, ultra-sound testing, and visual, and dimensional characteristics.</p>
</div>
<figure id="S3.F1" class="ltx_figure"><img src="/html/2302.08905/assets/images/completo.png" id="S3.F1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="240" height="208" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Complete Graph: documents linked through topics (e.g. batch number OS_LOTE). </figcaption>
</figure>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2302.08905/assets/images/incompleto.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_square" width="240" height="208" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Incomplete Graph: databook with missing links. </figcaption>
</figure>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Design Choices</h3>

<div id="S3.SS2.p1" class="ltx_para ltx_noindent">
<p id="S3.SS2.p1.1" class="ltx_p">The system should check the completeness and compliance of databooks with relevant standards, databook traceability information and anomaly detection in case of data inconsistency and potential fraud. Non-functional requirements include low-latency operation, real-time performance, data coherence and integrity.</p>
</div>
<section id="S3.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.1 </span>Completeness and conformance</h4>

<div id="S3.SS2.SSS1.p1" class="ltx_para ltx_noindent">
<p id="S3.SS2.SSS1.p1.1" class="ltx_p">Inspecting completeness comprises checking whether all required documents are readily available in the databook. In addition, conformance to standards and guidelines is carried out to check several compliance rules such as material properties thresholds, dimensional specifications and visual inspection.</p>
</div>
</section>
<section id="S3.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.2 </span>Traceability</h4>

<div id="S3.SS2.SSS2.p1" class="ltx_para ltx_noindent">
<p id="S3.SS2.SSS2.p1.1" class="ltx_p">This system functionality ensures that a product or process has records that prove the manufacturing path to its inception. The traceability inspection searches all databook documents referenced in the dataset to analyse the linked and source data compatibility.
In addition, incomplete databooks or non-conformant documents should also be flagged as faults in the traceability verification.</p>
</div>
</section>
<section id="S3.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.3 </span>Data Coherence</h4>

<div id="S3.SS2.SSS3.p1" class="ltx_para ltx_noindent">
<p id="S3.SS2.SSS3.p1.1" class="ltx_p">Data inconsistency is inevitable as the documents are scanned, OCR (Optical Character Recognition) processed to extract relevant text, and structured in an automated way. For instance, word ambiguities, either because of language variability or OCR quality issues, challenge the proposed system where the same data element has different meanings. In this case, the system should strive to maintain consistency and coherence at all costs.</p>
</div>
</section>
<section id="S3.SS2.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.4 </span>Linked Documents</h4>

<div id="S3.SS2.SSS4.p1" class="ltx_para ltx_noindent">
<p id="S3.SS2.SSS4.p1.1" class="ltx_p">Graph-based structures and models provide a design choice to specify data elements and relationships of technical documents. Also, several graph algorithms can be explored to fulfil the document verification needs, including completeness, conformance and traceability. For instance, centrality techniques traverse a graph to compute such properties as popular elements and bottlenecks.</p>
</div>
<div id="S3.SS2.SSS4.p2" class="ltx_para ltx_noindent">
<p id="S3.SS2.SSS4.p2.3" class="ltx_p">The visual appeal of graph-based data representation offers a more intuitive data exploration to document inspectors. Figs. <a href="#S3.F1" title="Figure 1 ‚Ä£ 3.1 Databooks ‚Ä£ 3 System Design Choices ‚Ä£ GraphLED: A graph-based approach to process and visualise linked engineering documents" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> and <a href="#S3.F2" title="Figure 2 ‚Ä£ 3.1 Databooks ‚Ä£ 3 System Design Choices ‚Ä£ GraphLED: A graph-based approach to process and visualise linked engineering documents" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> shows an example of a databook sample, represented as a graph, extracted from a real-world dataset (Oil&amp;Gas industry, identifiers have been crossed-out). In this case, a graph <math id="S3.SS2.SSS4.p2.1.m1.2" class="ltx_Math" alttext="G(V,E)" display="inline"><semantics id="S3.SS2.SSS4.p2.1.m1.2a"><mrow id="S3.SS2.SSS4.p2.1.m1.2.3" xref="S3.SS2.SSS4.p2.1.m1.2.3.cmml"><mi id="S3.SS2.SSS4.p2.1.m1.2.3.2" xref="S3.SS2.SSS4.p2.1.m1.2.3.2.cmml">G</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS4.p2.1.m1.2.3.1" xref="S3.SS2.SSS4.p2.1.m1.2.3.1.cmml">‚Äã</mo><mrow id="S3.SS2.SSS4.p2.1.m1.2.3.3.2" xref="S3.SS2.SSS4.p2.1.m1.2.3.3.1.cmml"><mo stretchy="false" id="S3.SS2.SSS4.p2.1.m1.2.3.3.2.1" xref="S3.SS2.SSS4.p2.1.m1.2.3.3.1.cmml">(</mo><mi id="S3.SS2.SSS4.p2.1.m1.1.1" xref="S3.SS2.SSS4.p2.1.m1.1.1.cmml">V</mi><mo id="S3.SS2.SSS4.p2.1.m1.2.3.3.2.2" xref="S3.SS2.SSS4.p2.1.m1.2.3.3.1.cmml">,</mo><mi id="S3.SS2.SSS4.p2.1.m1.2.2" xref="S3.SS2.SSS4.p2.1.m1.2.2.cmml">E</mi><mo stretchy="false" id="S3.SS2.SSS4.p2.1.m1.2.3.3.2.3" xref="S3.SS2.SSS4.p2.1.m1.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS4.p2.1.m1.2b"><apply id="S3.SS2.SSS4.p2.1.m1.2.3.cmml" xref="S3.SS2.SSS4.p2.1.m1.2.3"><times id="S3.SS2.SSS4.p2.1.m1.2.3.1.cmml" xref="S3.SS2.SSS4.p2.1.m1.2.3.1"></times><ci id="S3.SS2.SSS4.p2.1.m1.2.3.2.cmml" xref="S3.SS2.SSS4.p2.1.m1.2.3.2">ùê∫</ci><interval closure="open" id="S3.SS2.SSS4.p2.1.m1.2.3.3.1.cmml" xref="S3.SS2.SSS4.p2.1.m1.2.3.3.2"><ci id="S3.SS2.SSS4.p2.1.m1.1.1.cmml" xref="S3.SS2.SSS4.p2.1.m1.1.1">ùëâ</ci><ci id="S3.SS2.SSS4.p2.1.m1.2.2.cmml" xref="S3.SS2.SSS4.p2.1.m1.2.2">ùê∏</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS4.p2.1.m1.2c">G(V,E)</annotation></semantics></math> comprises a set of vertices <math id="S3.SS2.SSS4.p2.2.m2.1" class="ltx_Math" alttext="V" display="inline"><semantics id="S3.SS2.SSS4.p2.2.m2.1a"><mi id="S3.SS2.SSS4.p2.2.m2.1.1" xref="S3.SS2.SSS4.p2.2.m2.1.1.cmml">V</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS4.p2.2.m2.1b"><ci id="S3.SS2.SSS4.p2.2.m2.1.1.cmml" xref="S3.SS2.SSS4.p2.2.m2.1.1">ùëâ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS4.p2.2.m2.1c">V</annotation></semantics></math> (databook individual documents) and a set of edges <math id="S3.SS2.SSS4.p2.3.m3.1" class="ltx_Math" alttext="E" display="inline"><semantics id="S3.SS2.SSS4.p2.3.m3.1a"><mi id="S3.SS2.SSS4.p2.3.m3.1.1" xref="S3.SS2.SSS4.p2.3.m3.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS4.p2.3.m3.1b"><ci id="S3.SS2.SSS4.p2.3.m3.1.1.cmml" xref="S3.SS2.SSS4.p2.3.m3.1.1">ùê∏</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS4.p2.3.m3.1c">E</annotation></semantics></math> that interconnects the vertices. Fig. <a href="#S3.F1" title="Figure 1 ‚Ä£ 3.1 Databooks ‚Ä£ 3 System Design Choices ‚Ä£ GraphLED: A graph-based approach to process and visualise linked engineering documents" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> shows an example of a graph with a complete databook, given that there is a path connecting all documents through the central node. In contrast, Fig. <a href="#S3.F2" title="Figure 2 ‚Ä£ 3.1 Databooks ‚Ä£ 3 System Design Choices ‚Ä£ GraphLED: A graph-based approach to process and visualise linked engineering documents" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> presents an incomplete graph where documents are missing, and two documents are isolated, thus compromising the intra-databook traceability. It is important to note that these documents relate to other documents through specific relationships (e.g. same quality assurance laboratory).</p>
</div>
</section>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>The GraphLED System</h2>

<div id="S4.p1" class="ltx_para ltx_noindent">
<p id="S4.p1.1" class="ltx_p">The GraphLED system architecture (as shown in Fig.¬†<a href="#S4.F3" title="Figure 3 ‚Ä£ 4 The GraphLED System ‚Ä£ GraphLED: A graph-based approach to process and visualise linked engineering documents" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>) is modularised to provide interoperability in the implementation of the pipeline functions from data insertion and knowledge extraction to graph visualisation and processing.</p>
</div>
<figure id="S4.F3" class="ltx_figure"><img src="/html/2302.08905/assets/images/Diagrama2.png" id="S4.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="419" height="195" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>System architecture modules. The GraphLED explores a colourful visual representation using bright colours (i.e. analogy to LEDs)</figcaption>
</figure>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Data Loading Module</h3>

<div id="S4.SS1.p1" class="ltx_para ltx_noindent">
<p id="S4.SS1.p1.1" class="ltx_p">OCR tools (e.g. Tesseract, Google image reader) convert scanned documents into raw text under a certain quality expectation. To minimise the OCR-related errors, GraphLED adopts the steps proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>, where the generated raw text data is pre-processed using noise reduction, binarisation and skew reduction.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para ltx_noindent">
<p id="S4.SS1.p2.1" class="ltx_p">The outputted document is fed into a <span id="S4.SS1.p2.1.1" class="ltx_text ltx_font_italic">form understanding</span> process that classifies documents using a form-based layout similarity scheme of document models previously defined. This module output is a JSON file containing each document represented as a set of blocks with the extracted words, their bounding boxes, and whether there is a link to a piece of data in another document.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Pre-Processing</h3>

<div id="S4.SS2.p1" class="ltx_para ltx_noindent">
<p id="S4.SS2.p1.1" class="ltx_p">Data is inherently noisy in this application scenario. This module handles the data cleaning and wrangling to improve data quality by transforming the input <span id="S4.SS2.p1.1.1" class="ltx_text ltx_font_italic">dataset</span> into an intermediate representation suitable for the graph generation. Pre-processing tasks are performed at coarse-grained (documents) and fine-grained (document words) levels. A summary of the challenges is as follows: (1) Data ambiguity: Data is represented differently, but it semantically represents the same information; (2) Irrelevant data: data with small intrinsic value for a graph-based analysis and (3) Over-relevant data: identifying the more likely data to become nodes or edges in the graph generation phase.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para ltx_noindent">
<p id="S4.SS2.p2.1" class="ltx_p">A sequence of operations is applied to the data to decrease noise levels. For instance, it is crucial to filter out <span id="S4.SS2.p2.1.1" class="ltx_text ltx_font_italic">Stopwords</span> prior to using disambiguation functions. Disambiguation works through similarity comparisons between data instances, using the following filters:</p>
<ul id="S4.I1" class="ltx_itemize">
<li id="S4.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="S4.I1.i1.p1" class="ltx_para">
<p id="S4.I1.i1.p1.1" class="ltx_p">Levenshtein filter <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> relies on the edit distance between two strings of comparable size (same proportion) to minimise false positives. A low acceptance threshold is also used to detect very similar instances.</p>
</div>
</li>
<li id="S4.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="S4.I1.i2.p1" class="ltx_para">
<p id="S4.I1.i2.p1.1" class="ltx_p">The Longest Common Subsequence (LCS) filter <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> detects similarity through the longest common subsequence (in the exact relative order) between any two strings.</p>
</div>
</li>
<li id="S4.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="S4.I1.i3.p1" class="ltx_para ltx_noindent">
<p id="S4.I1.i3.p1.1" class="ltx_p">Sequence Matcher filter (LCS variation) uses junk-free contiguous subsequences as a similarity metric.</p>
</div>
</li>
</ul>
</div>
<div id="S4.SS2.p3" class="ltx_para ltx_noindent">
<p id="S4.SS2.p3.1" class="ltx_p">Fig.<a href="#S4.F4" title="Figure 4 ‚Ä£ 4.2 Pre-Processing ‚Ä£ 4 The GraphLED System ‚Ä£ GraphLED: A graph-based approach to process and visualise linked engineering documents" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> presents the pipeline for the ambiguity correction sub-module, where filters are applied one after another, covering the primary forms of ambiguity found in the dataset. Another module maps the modifications performed in the filtering steps to instances of the original document for data provenance purposes. It is essential to keep track of input data, transformed data and processes, thus providing a historical record of the data and its origins.</p>
</div>
<figure id="S4.F4" class="ltx_figure"><img src="/html/2302.08905/assets/images/FiltrosDiagrama.png" id="S4.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="419" height="129" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Proposed ambiguity module architecture. </figcaption>
</figure>
<div id="S4.SS2.p4" class="ltx_para ltx_noindent">
<p id="S4.SS2.p4.1" class="ltx_p">With a large amount of data, exploiting helpful information can be daunting. Nevertheless, once we decrease the noise with filtered data, graph-based algorithms can attempt to spot patterns to detect relevant information based on past data behaviours. The detection of relevant data nodes exploits graph centrality algorithms for trend identification. Such algorithms enable the monitoring of a set of indicators: (a) the transitive influence of nodes (Eigenvector Centrality), (b) node influence on the flow of the graph (Betweenness Centrality) and (c) the number of incoming and outgoing relationships from a node (Degree Centrality).</p>
</div>
<div id="S4.SS2.p5" class="ltx_para ltx_noindent">
<p id="S4.SS2.p5.1" class="ltx_p">The criterion for defining the relevant features is the aggregate sum of the scores produced by the metrics above.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Management Module</h3>

<div id="S4.SS3.p1" class="ltx_para ltx_noindent">
<p id="S4.SS3.p1.1" class="ltx_p">This module deals with system integration and its proper operation. It exchanges information through RestFUL APIs (Fig.¬†<a href="#S4.F5" title="Figure 5 ‚Ä£ 4.3 Management Module ‚Ä£ 4 The GraphLED System ‚Ä£ GraphLED: A graph-based approach to process and visualise linked engineering documents" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>), namely <span id="S4.SS3.p1.1.1" class="ltx_text ltx_font_italic">graph-api</span>, that allows <span id="S4.SS3.p1.1.2" class="ltx_text ltx_font_italic">query</span> creation considering the user parameters informed via HTTP requests.</p>
</div>
<figure id="S4.F5" class="ltx_figure"><img src="/html/2302.08905/assets/images/Diagram1.png" id="S4.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="359" height="161" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Management Module. Data is exchanged with the Neo4j graph database through the Bolt protocol </figcaption>
</figure>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Storage Module</h3>

<div id="S4.SS4.p1" class="ltx_para ltx_noindent">
<p id="S4.SS4.p1.1" class="ltx_p">Graph-based storage and query engine are essential functions in the GraphLED system. The following criteria were used for the selection of a suitable graph database system:</p>
</div>
<div id="S4.SS4.p2" class="ltx_para ltx_noindent">
<ul id="S4.I2" class="ltx_itemize">
<li id="S4.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="S4.I2.i1.p1" class="ltx_para">
<p id="S4.I2.i1.p1.1" class="ltx_p">Maturity and availability of documentation and support from the developer team and community.</p>
</div>
</li>
<li id="S4.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="S4.I2.i2.p1" class="ltx_para">
<p id="S4.I2.i2.p1.1" class="ltx_p">Easy integration with other existing tools and provision of programming language integration (e.g. Python, Java and JavaScript).</p>
</div>
</li>
<li id="S4.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="S4.I2.i3.p1" class="ltx_para">
<p id="S4.I2.i3.p1.1" class="ltx_p">Satisfactory performance in moderate data volume.</p>
</div>
</li>
<li id="S4.I2.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="S4.I2.i4.p1" class="ltx_para">
<p id="S4.I2.i4.p1.1" class="ltx_p">Easy-to-use, understandable and maintainable graph query language.</p>
</div>
</li>
<li id="S4.I2.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="S4.I2.i5.p1" class="ltx_para ltx_noindent">
<p id="S4.I2.i5.p1.1" class="ltx_p">Schema-free: flexibility and agility in structuring graphs.</p>
</div>
</li>
</ul>
</div>
<div id="S4.SS4.p3" class="ltx_para ltx_noindent">
<p id="S4.SS4.p3.1" class="ltx_p">Unlike traditional databases (SQL-like), graph-oriented databases offer a few advantages, but the primary one is the optimisation of breadth-first searches, which is a highly recommended procedure to find non-obvious relationships between entities. A few choices were considered, including cloud-based Amazon Neptune, Azure CosmoDB and community-based Neo4j. The latter fulfilled the project requirements at the time. Also, the upcoming query language standards (Apache Gremlin and SparkQL) can soon make the GraphLED system graph database-agnostic.</p>
</div>
</section>
<section id="S4.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.5 </span>Data Visualisation</h3>

<div id="S4.SS5.p1" class="ltx_para ltx_noindent">
<p id="S4.SS5.p1.1" class="ltx_p">Graphs lend themselves to intuitive data visualisation. This module uses open-source toolkits, particularly the Neovis library, to render graph nodes and edges that model databooks, associated documents, and their relationships. In addition, the GraphLED visual tool interacts directly with the Bolt protocol‚Äôs graph database for improved performance. However, it has been noted that graph visualisation can be a bottleneck as the number of graph nodes increases.</p>
</div>
<div id="S4.SS5.p2" class="ltx_para ltx_noindent">
<p id="S4.SS5.p2.1" class="ltx_p">The designed user interfaces mitigate potential bottlenecks through <span id="S4.SS5.p2.1.1" class="ltx_text ltx_font_italic">(i)</span> simple searches aimed at node-edge-node traversals, in which the user can specify the nodes‚Äô classes.</p>
</div>
<div id="S4.SS5.p3" class="ltx_para ltx_noindent">
<p id="S4.SS5.p3.1" class="ltx_p">The system offers <span id="S4.SS5.p3.1.1" class="ltx_text ltx_font_italic">(ii)</span> advanced <span id="S4.SS5.p3.1.2" class="ltx_text ltx_font_italic">queries</span> in <span id="S4.SS5.p3.1.3" class="ltx_text ltx_font_italic">Cypher</span> language, returning to the user complex and elaborated results. Properties calculated <span id="S4.SS5.p3.1.4" class="ltx_text ltx_font_italic">(iii)</span>, such as degree centrality, are also presented in a table format at the bottom of the GUI.</p>
</div>
</section>
<section id="S4.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.6 </span>User Interface</h3>

<div id="S4.SS6.p1" class="ltx_para ltx_noindent">
<p id="S4.SS6.p1.1" class="ltx_p">The system <span id="S4.SS6.p1.1.1" class="ltx_text ltx_font_italic">beta</span> version (Fig. <a href="#S4.F6" title="Figure 6 ‚Ä£ 4.6 User Interface ‚Ä£ 4 The GraphLED System ‚Ä£ GraphLED: A graph-based approach to process and visualise linked engineering documents" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>) offers aesthetic and improved user experience. Customised GUI elements were added, allowing users to choose between the various types of engineering documents, and create, visualise and delete databook/document graphs.</p>
</div>
<div id="S4.SS6.p2" class="ltx_para ltx_noindent">
<p id="S4.SS6.p2.1" class="ltx_p">An exploration form field has been placed in the side menu so users can write complex graph traversal searches, choosing between nodes and connections types. In addition, a simple search box was added to complement node centrality information, where users can choose the following properties: <span id="S4.SS6.p2.1.1" class="ltx_text ltx_font_italic">Betweenness, Node Degree, Closeness and Eigenvector centrality.</span> The centrality provides hints to the user on structural anomalies, such as incomplete graphs, missing relationships, and others. Given that databook‚Äôs documents are modelled as graphs, the centrality properties answer the questions of completeness, conformance, and traceability.</p>
</div>
<figure id="S4.F6" class="ltx_figure"><img src="/html/2302.08905/assets/images/interface.png" id="S4.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="479" height="342" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Beta version. </figcaption>
</figure>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>System Validation Results</h2>

<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Data Quality</h3>

<div id="S5.SS1.p1" class="ltx_para ltx_noindent">
<p id="S5.SS1.p1.1" class="ltx_p">The validation is aimed at understanding and further improving the input data quality.</p>
</div>
<div id="S5.SS1.p2" class="ltx_para ltx_noindent">
<p id="S5.SS1.p2.1" class="ltx_p">The data pipeline implemented takes in a scanned document and passes it through an OCR stage. Then the OCR outputted file is classified and stored. The validation dataset used 81 PDF scanned databook files, totalling <span id="S5.SS1.p2.1.1" class="ltx_text ltx_font_italic">1.43 GB</span> of individual documents. It is important to note that a databook is a set of engineering-driven documents with various purposes ranging from purchase order specifications to material testing certificates.</p>
</div>
<div id="S5.SS1.p3" class="ltx_para ltx_noindent">
<p id="S5.SS1.p3.1" class="ltx_p">The benchmarking employed two document categories, labelled as <span id="S5.SS1.p3.1.1" class="ltx_text ltx_font_italic">easy document</span> and <span id="S5.SS1.p3.1.2" class="ltx_text ltx_font_italic">difficult document</span>. The labels indicate how difficult it is for the Tesseract OCR system to process scanned documents considering visual and document structural aspects such as page inclination, scrawls and complex internal elements (e.g. tables with few lines, few pages).</p>
</div>
<div id="S5.SS1.p4" class="ltx_para ltx_noindent">
<p id="S5.SS1.p4.1" class="ltx_p">Further validation experiments were undertaken on a small set of labelled data to analyze the performance of data noise filtering and disambiguation techniques (Pre-processing module). In addition, many recognized data entities in the graph have been used as a comparison metric because it conveys the amount of duplicate/ambiguous nodes in the dataset. The data comprises parts suppliers to oil platforms (the dataset has 226 rows). Specialists analyzed the dataset and found 17 distinct suppliers (out of 226). However, the graph generated where each supplier is a node contained 128 different suppliers.</p>
</div>
<div id="S5.SS1.p5" class="ltx_para ltx_noindent">
<p id="S5.SS1.p5.1" class="ltx_p">Further analysis found that such a discrepancy was due to ambiguous nodes in the graph, caused by 128 grammatical variations of the 17 suppliers. Some examples of variations include the terms: "supplier-A": "A-supplier", "supplier-A.inc", "group-A-supplier". The key idea for dealing with this issue is to identify variations of the same entity (a supplier) in the dataset and standardize them in a single form of writing. The ambiguity removal algorithm was developed to accomplish this task. The algorithm produced a list of 18 distinct suppliers, just one supplier off the specialist‚Äôs list, as is summarised in Figure <a href="#S5.F7" title="Figure 7 ‚Ä£ 5.1 Data Quality ‚Ä£ 5 System Validation Results ‚Ä£ GraphLED: A graph-based approach to process and visualise linked engineering documents" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>. As a result, the algorithm removed 110 ambiguous nodes in the graph - total removal of 99.09% of ambiguous nodes and an 85.93% reduction in the number of nodes from 128 to 18 suppliers.</p>
</div>
<figure id="S5.F7" class="ltx_figure"><img src="/html/2302.08905/assets/x1.jpg" id="S5.F7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="298" height="214" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Comparison between recognized entities by the OCR system, after the filter, and by specialists.</figcaption>
</figure>
<div id="S5.SS1.p6" class="ltx_para ltx_noindent">
<p id="S5.SS1.p6.1" class="ltx_p">The results were classified considering the similarity (OCR text versus ground-truth original text) into: <span id="S5.SS1.p6.1.1" class="ltx_text ltx_font_italic">100% Accuracy</span> (total hit), <span id="S5.SS1.p6.1.2" class="ltx_text ltx_font_italic">Partially accurate</span> (partial hit) and <span id="S5.SS1.p6.1.3" class="ltx_text ltx_font_italic">Inconsistency</span> for lack of any relation between the OCR and ground-truth text. In the <span id="S5.SS1.p6.1.4" class="ltx_text ltx_font_italic">easy document</span> context, as shown in Fig. <a href="#S5.F8" title="Figure 8 ‚Ä£ 5.1 Data Quality ‚Ä£ 5 System Validation Results ‚Ä£ GraphLED: A graph-based approach to process and visualise linked engineering documents" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>, the system managed to identify 85.9% of the data elements inside the document with total hits, 12.72% as partial hits and 1.58% as inconsistent (total error). However, the results for the <span id="S5.SS1.p6.1.5" class="ltx_text ltx_font_italic">difficult document</span> were not satisfactory: 25.67% of total hits, 24.32% of partial hits and 50.01% of inconsistencies.</p>
</div>
<div id="S5.SS1.p7" class="ltx_para ltx_noindent">
<p id="S5.SS1.p7.1" class="ltx_p">It is clear from these results that noise and ambiguity in the data propagate through the OCR-processed documents. Such errors are not helpful for graph construction from the OCR data.</p>
</div>
<figure id="S5.F8" class="ltx_figure"><img src="/html/2302.08905/assets/images/benchmark.png" id="S5.F8.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="281" height="168" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>OCR performance: easy and difficult documents. </figcaption>
</figure>
<div id="S5.SS1.p8" class="ltx_para ltx_noindent">
<p id="S5.SS1.p8.1" class="ltx_p">More complex forms of ambiguity, such as entity standardization and acronym identification, were handled manually and will be addressed in an automated way in the next release of the GraphLED system.</p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Scaling the GraphLED</h3>

<div id="S5.SS2.p1" class="ltx_para ltx_noindent">
<p id="S5.SS2.p1.1" class="ltx_p">As a quantitative reference, an analysis of the Read/Write rate of graph nodes, edges and properties was carried out in the Neo4j database. We chose the <span id="S5.SS2.p1.1.1" class="ltx_text ltx_font_italic">graph-workload</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>, an open-source tool for running loading tests, which is capable of generating random loads of data and Cypher queries to create graph nodes, edges and properties in a configurable and scalable way.</p>
</div>
<div id="S5.SS2.p2" class="ltx_para ltx_noindent">
<p id="S5.SS2.p2.1" class="ltx_p">Table¬†<a href="#S5.T1" title="Table 1 ‚Ä£ 5.2 Scaling the GraphLED ‚Ä£ 5 System Validation Results ‚Ä£ GraphLED: A graph-based approach to process and visualise linked engineering documents" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> lists the graph database setup parameters, including a Heap Initial Size value equal to 4GB of DDR4 RAM, limited by a Heap Max Size of 8GB.</p>
</div>
<div id="S5.SS2.p3" class="ltx_para ltx_noindent">
<p id="S5.SS2.p3.1" class="ltx_p">The experiment parameters used are: <span id="S5.SS2.p3.1.1" class="ltx_text ltx_font_italic">n = 1000</span>, where ‚Äún‚Äù is the target number of queries in the database, and <span id="S5.SS2.p3.1.2" class="ltx_text ltx_font_italic">concurrency = 10</span> is the number of queries executed in parallel. The data used are generated randomly (at runtime) or deterministically (hard coded), having no relation with an input dataset. The selected subgraph patterns, e.g. the Hub-Spoke (Figure¬†<a href="#S3.F1" title="Figure 1 ‚Ä£ 3.1 Databooks ‚Ä£ 3 System Design Choices ‚Ä£ GraphLED: A graph-based approach to process and visualise linked engineering documents" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>) and the N-Ary Tree pattern, are also observed in structures of operational industry documents.</p>
</div>
<figure id="S5.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span>Graph Database Setup Configuration.</figcaption>
<table id="S5.T1.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S5.T1.1.1.1" class="ltx_tr">
<th id="S5.T1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Setting</th>
<td id="S5.T1.1.1.1.2" class="ltx_td ltx_border_tt"></td>
</tr>
<tr id="S5.T1.1.2.2" class="ltx_tr">
<td id="S5.T1.1.2.2.1" class="ltx_td ltx_align_center ltx_border_t">Heap Initial Size</td>
<td id="S5.T1.1.2.2.2" class="ltx_td ltx_align_center ltx_border_t">4 GB</td>
</tr>
<tr id="S5.T1.1.3.3" class="ltx_tr">
<td id="S5.T1.1.3.3.1" class="ltx_td ltx_align_center">Heap Max Size</td>
<td id="S5.T1.1.3.3.2" class="ltx_td ltx_align_center">8 GB</td>
</tr>
<tr id="S5.T1.1.4.4" class="ltx_tr">
<td id="S5.T1.1.4.4.1" class="ltx_td ltx_align_center">Page Cache Size</td>
<td id="S5.T1.1.4.4.2" class="ltx_td ltx_align_center">4 GB</td>
</tr>
<tr id="S5.T1.1.5.5" class="ltx_tr">
<td id="S5.T1.1.5.5.1" class="ltx_td ltx_align_center ltx_border_bb">Neo4j Version</td>
<td id="S5.T1.1.5.5.2" class="ltx_td ltx_align_center ltx_border_bb">3.5.14</td>
</tr>
</tbody>
</table>
</figure>
<div id="S5.SS2.p4" class="ltx_para ltx_noindent">
<p id="S5.SS2.p4.1" class="ltx_p">The complete graph could be generated with 143,602 nodes and 87,427 edges, with an approximate execution time of 42286 ms (Table¬†<a href="#S5.T2" title="Table 2 ‚Ä£ 5.2 Scaling the GraphLED ‚Ä£ 5 System Validation Results ‚Ä£ GraphLED: A graph-based approach to process and visualise linked engineering documents" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>). Figure¬†<a href="#S5.F11" title="Figure 11 ‚Ä£ 5.2 Scaling the GraphLED ‚Ä£ 5 System Validation Results ‚Ä£ GraphLED: A graph-based approach to process and visualise linked engineering documents" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a> shows the rendering of a graph sample limited to 10,000 nodes. We observe the following graph patterns and operations:</p>
</div>
<div id="S5.SS2.p5" class="ltx_para ltx_noindent">
<ul id="S5.I1" class="ltx_itemize">
<li id="S5.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="S5.I1.i1.p1" class="ltx_para">
<p id="S5.I1.i1.p1.1" class="ltx_p">Hub-Spoke Structural Patterns can be spotted where a central node connects a "leaf" in a shape that resembles a dandelion. This type of node is represented in yellow (Figure¬†<a href="#S5.F9" title="Figure 9 ‚Ä£ 5.2 Scaling the GraphLED ‚Ä£ 5 System Validation Results ‚Ä£ GraphLED: A graph-based approach to process and visualise linked engineering documents" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>).</p>
</div>
</li>
<li id="S5.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="S5.I1.i2.p1" class="ltx_para">
<p id="S5.I1.i2.p1.1" class="ltx_p">N-Ary Tree Pattern, with nodes in red representing an unbalanced N-Ary tree structure, where the large level of the sub-graph gives the main characteristic, are shown in red (Figure¬†<a href="#S5.F10" title="Figure 10 ‚Ä£ 5.2 Scaling the GraphLED ‚Ä£ 5 System Validation Results ‚Ä£ GraphLED: A graph-based approach to process and visualise linked engineering documents" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a>).</p>
</div>
</li>
<li id="S5.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="S5.I1.i3.p1" class="ltx_para">
<p id="S5.I1.i3.p1.1" class="ltx_p">Large set of 1-on-1 single linked structures to populate the graph where nodes are depicted in blue, pink and green in Figures¬†<a href="#S5.F10" title="Figure 10 ‚Ä£ 5.2 Scaling the GraphLED ‚Ä£ 5 System Validation Results ‚Ä£ GraphLED: A graph-based approach to process and visualise linked engineering documents" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a> and¬†<a href="#S5.F11" title="Figure 11 ‚Ä£ 5.2 Scaling the GraphLED ‚Ä£ 5 System Validation Results ‚Ä£ GraphLED: A graph-based approach to process and visualise linked engineering documents" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a>). In addition, some of such sub-graphs could exhibit other properties: a large number of indexable attributes (Index Heavy), sub-graphs of nodes with a large number of characters (Fat Node Append), sub-graphs with nodes connected through random links (Random Linkage), sub-graphs with both random nodes and links (Raw Write) and sub-graphs created from a MERGE operation.</p>
</div>
</li>
<li id="S5.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="S5.I1.i4.p1" class="ltx_para ltx_noindent">
<p id="S5.I1.i4.p1.1" class="ltx_p">Other types of operations (Aggregate Read, Long Path Read and Random Access Read) are allowed as Read queries directly performed to the database. Such operations were included only to simulate a production environment with real-world users when both Write and Read operations can coincide.</p>
</div>
</li>
</ul>
</div>
<figure id="S5.F9" class="ltx_figure"><img src="/html/2302.08905/assets/images/FIgura2.png" id="S5.F9.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="269" height="133" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9: </span>Hub-Spoke Subgraph Pattern. </figcaption>
</figure>
<figure id="S5.F10" class="ltx_figure"><img src="/html/2302.08905/assets/images/Figura3.png" id="S5.F10.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="269" height="126" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 10: </span>N-Ary Tree Subgraph Pattern. </figcaption>
</figure>
<figure id="S5.F11" class="ltx_figure"><img src="/html/2302.08905/assets/images/Figura4.png" id="S5.F11.g1" class="ltx_graphics ltx_centering ltx_img_square" width="269" height="234" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 11: </span>Subgraph Sample with Ten Thousand Nodes. </figcaption>
</figure>
<figure id="S5.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Graph Database Running Results.</figcaption>
<table id="S5.T2.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T2.1.1.1" class="ltx_tr">
<th id="S5.T2.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Pattern</th>
<th id="S5.T2.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">RUNS</th>
<th id="S5.T2.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">AVG</th>
<th id="S5.T2.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">MIN</th>
<th id="S5.T2.1.1.1.5" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">MAX</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T2.1.2.1" class="ltx_tr">
<td id="S5.T2.1.2.1.1" class="ltx_td ltx_align_center ltx_border_t">Fat Node Append</td>
<td id="S5.T2.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t">1050</td>
<td id="S5.T2.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t">73.03</td>
<td id="S5.T2.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t">18</td>
<td id="S5.T2.1.2.1.5" class="ltx_td ltx_align_left ltx_border_t">1990</td>
</tr>
<tr id="S5.T2.1.3.2" class="ltx_tr">
<td id="S5.T2.1.3.2.1" class="ltx_td ltx_align_center">NAry Tree</td>
<td id="S5.T2.1.3.2.2" class="ltx_td ltx_align_center">1003</td>
<td id="S5.T2.1.3.2.3" class="ltx_td ltx_align_center">54.72</td>
<td id="S5.T2.1.3.2.4" class="ltx_td ltx_align_center">4</td>
<td id="S5.T2.1.3.2.5" class="ltx_td ltx_align_left">1993</td>
</tr>
<tr id="S5.T2.1.4.3" class="ltx_tr">
<td id="S5.T2.1.4.3.1" class="ltx_td ltx_align_center">Merge Write</td>
<td id="S5.T2.1.4.3.2" class="ltx_td ltx_align_center">985</td>
<td id="S5.T2.1.4.3.3" class="ltx_td ltx_align_center">38.24</td>
<td id="S5.T2.1.4.3.4" class="ltx_td ltx_align_center">4</td>
<td id="S5.T2.1.4.3.5" class="ltx_td ltx_align_left">1991</td>
</tr>
<tr id="S5.T2.1.5.4" class="ltx_tr">
<td id="S5.T2.1.5.4.1" class="ltx_td ltx_align_center">Random Linkage</td>
<td id="S5.T2.1.5.4.2" class="ltx_td ltx_align_center">1010</td>
<td id="S5.T2.1.5.4.3" class="ltx_td ltx_align_center">31.90</td>
<td id="S5.T2.1.5.4.4" class="ltx_td ltx_align_center">5</td>
<td id="S5.T2.1.5.4.5" class="ltx_td ltx_align_left">249</td>
</tr>
<tr id="S5.T2.1.6.5" class="ltx_tr">
<td id="S5.T2.1.6.5.1" class="ltx_td ltx_align_center">Hub-Spoke</td>
<td id="S5.T2.1.6.5.2" class="ltx_td ltx_align_center">481</td>
<td id="S5.T2.1.6.5.3" class="ltx_td ltx_align_center">60.74</td>
<td id="S5.T2.1.6.5.4" class="ltx_td ltx_align_center">20</td>
<td id="S5.T2.1.6.5.5" class="ltx_td ltx_align_left">719</td>
</tr>
<tr id="S5.T2.1.7.6" class="ltx_tr">
<td id="S5.T2.1.7.6.1" class="ltx_td ltx_align_center">RawWrite</td>
<td id="S5.T2.1.7.6.2" class="ltx_td ltx_align_center">2933</td>
<td id="S5.T2.1.7.6.3" class="ltx_td ltx_align_center">41.51</td>
<td id="S5.T2.1.7.6.4" class="ltx_td ltx_align_center">3</td>
<td id="S5.T2.1.7.6.5" class="ltx_td ltx_align_left">1754</td>
</tr>
<tr id="S5.T2.1.8.7" class="ltx_tr">
<td id="S5.T2.1.8.7.1" class="ltx_td ltx_align_center">Index Heavy</td>
<td id="S5.T2.1.8.7.2" class="ltx_td ltx_align_center">1002</td>
<td id="S5.T2.1.8.7.3" class="ltx_td ltx_align_center">41.10</td>
<td id="S5.T2.1.8.7.4" class="ltx_td ltx_align_center">4</td>
<td id="S5.T2.1.8.7.5" class="ltx_td ltx_align_left">1960</td>
</tr>
<tr id="S5.T2.1.9.8" class="ltx_tr">
<td id="S5.T2.1.9.8.1" class="ltx_td ltx_align_center">Aggregate Read</td>
<td id="S5.T2.1.9.8.2" class="ltx_td ltx_align_center">552</td>
<td id="S5.T2.1.9.8.3" class="ltx_td ltx_align_center">18.25</td>
<td id="S5.T2.1.9.8.4" class="ltx_td ltx_align_center">2</td>
<td id="S5.T2.1.9.8.5" class="ltx_td ltx_align_left">126</td>
</tr>
<tr id="S5.T2.1.10.9" class="ltx_tr">
<td id="S5.T2.1.10.9.1" class="ltx_td ltx_align_center">Random Access Read</td>
<td id="S5.T2.1.10.9.2" class="ltx_td ltx_align_center">952</td>
<td id="S5.T2.1.10.9.3" class="ltx_td ltx_align_center">37.44</td>
<td id="S5.T2.1.10.9.4" class="ltx_td ltx_align_center">7</td>
<td id="S5.T2.1.10.9.5" class="ltx_td ltx_align_left">114</td>
</tr>
<tr id="S5.T2.1.11.10" class="ltx_tr">
<td id="S5.T2.1.11.10.1" class="ltx_td ltx_align_center">Long Path Read</td>
<td id="S5.T2.1.11.10.2" class="ltx_td ltx_align_center">62</td>
<td id="S5.T2.1.11.10.3" class="ltx_td ltx_align_center">24.66</td>
<td id="S5.T2.1.11.10.4" class="ltx_td ltx_align_center">2</td>
<td id="S5.T2.1.11.10.5" class="ltx_td ltx_align_left">127</td>
</tr>
<tr id="S5.T2.1.12.11" class="ltx_tr">
<td id="S5.T2.1.12.11.1" class="ltx_td ltx_align_center"><span id="S5.T2.1.12.11.1.1" class="ltx_text ltx_font_bold">Total (units)</span></td>
<td id="S5.T2.1.12.11.2" class="ltx_td ltx_align_center"><span id="S5.T2.1.12.11.2.1" class="ltx_text ltx_font_bold">10030</span></td>
<td id="S5.T2.1.12.11.3" class="ltx_td ltx_align_center">-</td>
<td id="S5.T2.1.12.11.4" class="ltx_td ltx_align_center">-</td>
<td id="S5.T2.1.12.11.5" class="ltx_td ltx_align_left">-</td>
</tr>
<tr id="S5.T2.1.13.12" class="ltx_tr">
<td id="S5.T2.1.13.12.1" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T2.1.13.12.1.1" class="ltx_text ltx_font_bold">Average (ms)</span></td>
<td id="S5.T2.1.13.12.2" class="ltx_td ltx_align_center ltx_border_bb">-</td>
<td id="S5.T2.1.13.12.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T2.1.13.12.3.1" class="ltx_text ltx_font_bold">42.16</span></td>
<td id="S5.T2.1.13.12.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T2.1.13.12.4.1" class="ltx_text ltx_font_bold">6.9</span></td>
<td id="S5.T2.1.13.12.5" class="ltx_td ltx_align_left ltx_border_bb"><span id="S5.T2.1.13.12.5.1" class="ltx_text ltx_font_bold">1102.3</span></td>
</tr>
</tbody>
</table>
</figure>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusions</h2>

<div id="S6.p1" class="ltx_para ltx_noindent">
<p id="S6.p1.1" class="ltx_p">The GraphLED system addresses the needs of Oil<math id="S6.p1.1.m1.1" class="ltx_Math" alttext="\&amp;" display="inline"><semantics id="S6.p1.1.m1.1a"><mo id="S6.p1.1.m1.1.1" xref="S6.p1.1.m1.1.1.cmml">&amp;</mo><annotation-xml encoding="MathML-Content" id="S6.p1.1.m1.1b"><and id="S6.p1.1.m1.1.1.cmml" xref="S6.p1.1.m1.1.1"></and></annotation-xml><annotation encoding="application/x-tex" id="S6.p1.1.m1.1c">\&amp;</annotation></semantics></math>Gas inspection in <span id="S6.p1.1.1" class="ltx_text ltx_font_italic">big data</span> engineering contexts.</p>
</div>
<div id="S6.p2" class="ltx_para ltx_noindent">
<p id="S6.p2.1" class="ltx_p">This work contributes to a data-centric mechanism to address the correctness level in knowledge extracted from noisy OCR-based documents. The proposed data cleaning and augmentation achieved satisfactory results in removing ambiguity in the data.</p>
</div>
<div id="S6.p3" class="ltx_para ltx_noindent">
<p id="S6.p3.1" class="ltx_p">The GraphLED system offers a graph-based tool for close-to-real-time knowledge extraction and representation.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Martin Wollschlaeger, Thilo Sauter, and Juergen Jasperneite.

</span>
<span class="ltx_bibblock">The future of industrial communication: Automation networks in the
era of the internet of things and industry 4.0.

</span>
<span class="ltx_bibblock"><span id="bib.bib1.1.1" class="ltx_text ltx_font_italic">IEEE industrial electronics magazine</span>, 11(1):17‚Äì27, 2017.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Robert Amor and M¬†Clift.

</span>
<span class="ltx_bibblock">Documents as an enabling mechanism for concurrent engineering in the
construction industry.

</span>
<span class="ltx_bibblock">In <span id="bib.bib2.1.1" class="ltx_text ltx_font_italic">1st international conference on Concurrent Engineering in
Construction, CEC</span>, volume¬†97, 1997.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Pai Zheng, Chun-Hsien Chen, and Suiyue Shang.

</span>
<span class="ltx_bibblock">Towards an automatic engineering change management in smart
product-service systems‚Äìa dsm-based learning approach.

</span>
<span class="ltx_bibblock"><span id="bib.bib3.1.1" class="ltx_text ltx_font_italic">Advanced Engineering Informatics</span>, 39:203‚Äì213, 2019.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Kei Matsubayashi, Akihiro Yamashita, Hidetoshi Nonaka, and Yohko Konno.

</span>
<span class="ltx_bibblock">A research on document summarization and presentation system based on
feature word extraction from stored informations.

</span>
<span class="ltx_bibblock">In <span id="bib.bib4.1.1" class="ltx_text ltx_font_italic">2018 Conference on Technologies and Applications of
Artificial Intelligence (TAAI)</span>, pages 60‚Äì63. IEEE, 2018.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Qing Guan, Fuli Zhang, and Enli Zhang.

</span>
<span class="ltx_bibblock">Application prospect of knowledge graph technology in knowledge
management of oil and gas exploration and development.

</span>
<span class="ltx_bibblock">In <span id="bib.bib5.1.1" class="ltx_text ltx_font_italic">2019 2nd International Conference on Artificial Intelligence
and Big Data (ICAIBD)</span>, pages 161‚Äì166. IEEE, 2019.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Christian¬†M Dahl and Emil¬†N√∏rmark S√∏rensen.

</span>
<span class="ltx_bibblock">Document digitization and machine learning.

</span>
<span class="ltx_bibblock">2019.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Eduard Hovy, Roberto Navigli, and Simone¬†Paolo Ponzetto.

</span>
<span class="ltx_bibblock">Collaboratively built semi-structured content and artificial
intelligence: The story so far.

</span>
<span class="ltx_bibblock"><span id="bib.bib7.1.1" class="ltx_text ltx_font_italic">Artificial Intelligence</span>, 194:2‚Äì27, 2013.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Elena Simperl, Oscar Corcho, Marko Grobelnik, Dumitru Roman, Ahmet Soylu,
Mar√≠a Jes√∫s¬†Fern√°ndez Ru√≠z, Stefano Gatti, Chris Taggart,
Ur≈°ka¬†Skok Klima, Annie¬†Ferrari Uliana, Ian Makgill, and
Till¬†Christopher Lech.

</span>
<span class="ltx_bibblock">Towards a knowledge graph based platform for public procurement.

</span>
<span class="ltx_bibblock">In Emmanouel Garoufallou, Fabio Sartori, Rania Siatri, and Marios
Zervas, editors, <span id="bib.bib8.1.1" class="ltx_text ltx_font_italic">Metadata and Semantic Research</span>, pages 317‚Äì323, Cham,
2019. Springer International Publishing.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Manjai Lee and Byung-Won On.

</span>
<span class="ltx_bibblock">Social graph visualization techniques for public data.

</span>
<span class="ltx_bibblock"><span id="bib.bib9.1.1" class="ltx_text ltx_font_italic">Journal of the HCI Society of Korea</span>, 10(1):5‚Äì17, 2015.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Masaki Eto.

</span>
<span class="ltx_bibblock">Extended co-citation search: Graph-based document retrieval on a
co-citation network containing citation context information.

</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text ltx_font_italic">Information Processing &amp; Management</span>, 56(6):102046, 2019.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Trevor Strohman, W¬†Bruce Croft, and David Jensen.

</span>
<span class="ltx_bibblock">Recommending citations for academic papers.

</span>
<span class="ltx_bibblock">In <span id="bib.bib11.1.1" class="ltx_text ltx_font_italic">Proceedings of the 30th annual international ACM SIGIR
conference on Research and development in information retrieval</span>, pages
705‚Äì706, 2007.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Ghulam Mujtaba, Liyana Shuib, Ram¬†Gopal Raj, Retnagowri Rajandram, Khairunisa
Shaikh, and Mohammed¬†Ali Al-Garadi.

</span>
<span class="ltx_bibblock">Classification of forensic autopsy reports through conceptual
graph-based document representation model.

</span>
<span class="ltx_bibblock"><span id="bib.bib12.1.1" class="ltx_text ltx_font_italic">Journal of biomedical informatics</span>, 82:88‚Äì105, 2018.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Yufeng Zhang, Xueli Yu, Zeyu Cui, Shu Wu, Zhongzhen Wen, and Liang Wang.

</span>
<span class="ltx_bibblock">Every document owns its structure: Inductive text classification via
graph neural networks.

</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2004.13826</span>, 2020.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Mads¬†Holten Rasmussen, Maxime Lefran√ßois, Pieter Pauwels, Christian¬†Anker
Hviid, and Jan Karlsh√∏j.

</span>
<span class="ltx_bibblock">Managing interrelated project information in aec knowledge graphs.

</span>
<span class="ltx_bibblock"><span id="bib.bib14.1.1" class="ltx_text ltx_font_italic">Automation in Construction</span>, 108:102956, 2019.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Carlos¬†Francisco Moreno-Garcia and Eyad Elyan.

</span>
<span class="ltx_bibblock">Digitisation of assets from the oil and gas industry: Challenges and
opportunities.

</span>
<span class="ltx_bibblock">In <span id="bib.bib15.1.1" class="ltx_text ltx_font_italic">2019 International Conference on Document Analysis and
Recognition Workshops (ICDARW)</span>, volume¬†7, pages 2‚Äì5, 2019.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Carlos¬†Francisco Moreno-Garc√≠a, Eyad Elyan, and Chrisina Jayne.

</span>
<span class="ltx_bibblock">New trends on digitisation of complex engineering drawings.

</span>
<span class="ltx_bibblock"><span id="bib.bib16.1.1" class="ltx_text ltx_font_italic">Neural computing and applications</span>, 31(6):1695‚Äì1712, 2019.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Carlos¬†Francisco Moreno-Garc√≠a, Xavier Cort√©s, and Francesc Serratosa.

</span>
<span class="ltx_bibblock">A graph repository for learning error-tolerant graph matching.

</span>
<span class="ltx_bibblock">In <span id="bib.bib17.1.1" class="ltx_text ltx_font_italic">Joint IAPR International Workshops on Statistical Techniques
in Pattern Recognition (SPR) and Structural and Syntactic Pattern Recognition
(SSPR)</span>, pages 519‚Äì529. Springer, 2016.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Gabriel¬†L Santos, Vanessa¬†T Silva, Laura¬†A Dalmolin, Ricardo¬†N Rodrigues,
Paulo¬†LJ Drews, and Nelson¬†L Duarte¬†Filho.

</span>
<span class="ltx_bibblock">A form understanding approach to printed and structured engineering
documentation.

</span>
<span class="ltx_bibblock">In <span id="bib.bib18.1.1" class="ltx_text ltx_font_italic">2021 34th SIBGRAPI Conference on Graphics, Patterns and
Images (SIBGRAPI)</span>, pages 330‚Äì337. IEEE, 2021.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Rishin Haldar and Debajyoti Mukhopadhyay.

</span>
<span class="ltx_bibblock">Levenshtein distance technique in dictionary lookup methods: An
improved approach.

</span>
<span class="ltx_bibblock"><span id="bib.bib19.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1101.1232</span>, 2011.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
J√∂rg Tiedemann.

</span>
<span class="ltx_bibblock">Automatic construction of weighted string similarity measures.

</span>
<span class="ltx_bibblock">In <span id="bib.bib20.1.1" class="ltx_text ltx_font_italic">1999 Joint SIGDAT Conference on Empirical Methods in Natural
Language Processing and Very Large Corpora</span>, 1999.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
David Allen.

</span>
<span class="ltx_bibblock">Graph workload.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/moxious/graph-workload" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/moxious/graph-workload</a>, 2019.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2302.08904" class="ar5iv-nav-button ar5iv-nav-button-prev">‚óÑ</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2302.08905" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2302.08905">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2302.08905" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2302.08907" class="ar5iv-nav-button ar5iv-nav-button-next">‚ñ∫</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Fri Mar  1 01:43:11 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "√ó";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
