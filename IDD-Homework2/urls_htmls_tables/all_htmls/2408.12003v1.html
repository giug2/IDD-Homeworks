<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>RAG-Optimized Tibetan Tourism LLMs: Enhancing Accuracy and Personalization</title>
<!--Generated on Wed Aug 21 06:59:59 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="Retrieval-Augmented Generation,  Large Language Models,  Vector Databases,  Hallucination Problem" lang="en" name="keywords"/>
<base href="/html/2408.12003v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2408.12003v1#S1" title="In RAG-Optimized Tibetan Tourism LLMs: Enhancing Accuracy and Personalization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.12003v1#S1.SS1" title="In 1. Introduction ‣ RAG-Optimized Tibetan Tourism LLMs: Enhancing Accuracy and Personalization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1.1 </span>Current issues regarding Tibet’s cultural tourism and LLMs</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2408.12003v1#S2" title="In RAG-Optimized Tibetan Tourism LLMs: Enhancing Accuracy and Personalization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Methods and Models</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.12003v1#S2.SS1" title="In 2. Methods and Models ‣ RAG-Optimized Tibetan Tourism LLMs: Enhancing Accuracy and Personalization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Vectorization Methods: TF-IDF and BERT</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.12003v1#S2.SS2" title="In 2. Methods and Models ‣ RAG-Optimized Tibetan Tourism LLMs: Enhancing Accuracy and Personalization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Retrieval Construction Methods</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.12003v1#S2.SS3" title="In 2. Methods and Models ‣ RAG-Optimized Tibetan Tourism LLMs: Enhancing Accuracy and Personalization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>LLMS Function Calling and Retrieval-Augmented Generation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2408.12003v1#S3" title="In RAG-Optimized Tibetan Tourism LLMs: Enhancing Accuracy and Personalization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Theoretical Exposition of RAG’s Method for Optimizing Hallucination in Large Language Models</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.12003v1#S3.SS1" title="In 3. Theoretical Exposition of RAG’s Method for Optimizing Hallucination in Large Language Models ‣ RAG-Optimized Tibetan Tourism LLMs: Enhancing Accuracy and Personalization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Dataset construction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.12003v1#S3.SS2" title="In 3. Theoretical Exposition of RAG’s Method for Optimizing Hallucination in Large Language Models ‣ RAG-Optimized Tibetan Tourism LLMs: Enhancing Accuracy and Personalization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Database Vectorization and Indexing</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.12003v1#S3.SS3" title="In 3. Theoretical Exposition of RAG’s Method for Optimizing Hallucination in Large Language Models ‣ RAG-Optimized Tibetan Tourism LLMs: Enhancing Accuracy and Personalization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>RAG Optimization for Large Language Models</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.12003v1#S3.SS4" title="In 3. Theoretical Exposition of RAG’s Method for Optimizing Hallucination in Large Language Models ‣ RAG-Optimized Tibetan Tourism LLMs: Enhancing Accuracy and Personalization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4 </span>Evaluation Method</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2408.12003v1#S4" title="In RAG-Optimized Tibetan Tourism LLMs: Enhancing Accuracy and Personalization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Experiment</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.12003v1#S4.SS1" title="In 4. Experiment ‣ RAG-Optimized Tibetan Tourism LLMs: Enhancing Accuracy and Personalization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Database Vectorization and Indexing Experiment</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.12003v1#S4.SS2" title="In 4. Experiment ‣ RAG-Optimized Tibetan Tourism LLMs: Enhancing Accuracy and Personalization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Optimization of Large Language Models with RAG Technology</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2408.12003v1#S5" title="In RAG-Optimized Tibetan Tourism LLMs: Enhancing Accuracy and Personalization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2408.12003v1#S6" title="In RAG-Optimized Tibetan Tourism LLMs: Enhancing Accuracy and Personalization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Acknowledgments</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">RAG-Optimized Tibetan Tourism LLMs: Enhancing Accuracy and Personalization</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Jinhu Qi
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id1.1.id1">Chengdu Jincheng College</span><span class="ltx_text ltx_affiliation_city" id="id2.2.id2">Chengdu</span><span class="ltx_text ltx_affiliation_state" id="id3.3.id3">Sichuan</span><span class="ltx_text ltx_affiliation_country" id="id4.4.id4">China</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:qijinhu1218@gmail.com">qijinhu1218@gmail.com</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Shuai Yan
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id5.1.id1">Chengdu Jincheng College</span><span class="ltx_text ltx_affiliation_city" id="id6.2.id2">Chengdu</span><span class="ltx_text ltx_affiliation_state" id="id7.3.id3">Sichuan</span><span class="ltx_text ltx_affiliation_country" id="id8.4.id4">China</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:yanshuai1@cdjcc.edu.cn">yanshuai1@cdjcc.edu.cn</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yibo Zhang
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id9.1.id1">Chengdu Jincheng College</span><span class="ltx_text ltx_affiliation_city" id="id10.2.id2">Chengdu</span><span class="ltx_text ltx_affiliation_state" id="id11.3.id3">Sichuan</span><span class="ltx_text ltx_affiliation_country" id="id12.4.id4">China</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:z1575075389@gmail.com">z1575075389@gmail.com</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Wentao Zhang
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id13.1.id1">Chengdu Jincheng College</span><span class="ltx_text ltx_affiliation_city" id="id14.2.id2">Chengdu</span><span class="ltx_text ltx_affiliation_state" id="id15.3.id3">Sichuan</span><span class="ltx_text ltx_affiliation_country" id="id16.4.id4">China</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:vraniumzwt@gmail.com">vraniumzwt@gmail.com</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Rong Jin
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id17.1.id1">Chengdu Jincheng College</span><span class="ltx_text ltx_affiliation_city" id="id18.2.id2">Chengdu</span><span class="ltx_text ltx_affiliation_state" id="id19.3.id3">Sichuan</span><span class="ltx_text ltx_affiliation_country" id="id20.4.id4">China</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:kim.rong.king@gmail.com">kim.rong.king@gmail.com</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yuwei Hu
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id21.1.id1">Chengdu Jincheng College</span><span class="ltx_text ltx_affiliation_city" id="id22.2.id2">Chengdu</span><span class="ltx_text ltx_affiliation_state" id="id23.3.id3">Sichuan</span><span class="ltx_text ltx_affiliation_country" id="id24.4.id4">China</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:huy791745@gmail.com">huy791745@gmail.com</a>
</span></span></span>
<span class="ltx_author_before"> and </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Ke Wang
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id25.1.id1">Chengdu Jincheng College</span><span class="ltx_text ltx_affiliation_city" id="id26.2.id2">Chengdu</span><span class="ltx_text ltx_affiliation_state" id="id27.3.id3">Sichuan</span><span class="ltx_text ltx_affiliation_country" id="id28.4.id4">China</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:wangke@cdjcc.edu.cn">wangke@cdjcc.edu.cn</a>
</span></span></span>
</div>
<div class="ltx_dates">(2024)</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p class="ltx_p" id="id29.id1">With the development of the modern social economy, tourism has become an important way to meet people’s spiritual needs, bringing development opportunities to the tourism industry. However, existing large language models (LLMs) face challenges in personalized recommendation capabilities and the generation of content that can sometimes produce hallucinations. This study proposes an optimization scheme for Tibet tourism LLMs based on retrieval-augmented generation (RAG) technology. By constructing a database of tourist viewpoints and processing the data using vectorization techniques, we have significantly improved retrieval accuracy. The application of RAG technology effectively addresses the hallucination problem in content generation. The optimized model shows significant improvements in fluency, accuracy, and relevance of content generation. This research demonstrates the potential of RAG technology in the standardization of cultural tourism information and data analysis, providing theoretical and technical support for the development of intelligent cultural tourism service systems.</p>
</div>
<div class="ltx_keywords">Retrieval-Augmented Generation, Large Language Models, Vector Databases, Hallucination Problem
</div>
<span class="ltx_note ltx_note_frontmatter ltx_role_copyright" id="id1"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">copyright: </span>acmcopyright</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_journalyear" id="id2"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">journalyear: </span>2024</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_doi" id="id3"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">doi: </span>XXXXXXX.XXXXXXX</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_conference" id="id4"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">conference: </span>September 20-22, 2024; Xiamen, China; </span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_isbn" id="id5"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">isbn: </span>979-8-4007-1717-8</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_submissionid" id="id6"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">submissionid: </span>XA5000</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_ccs" id="id7"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Computing methodologies Natural language generation</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_ccs" id="id8"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Computing methodologies Artificial intelligence</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_ccs" id="id9"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Computing methodologies Natural language processing</span></span></span>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>
<section class="ltx_subsection" id="S1.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.1. </span>Current issues regarding Tibet’s cultural tourism and LLMs</h3>
<div class="ltx_para" id="S1.SS1.p1">
<p class="ltx_p" id="S1.SS1.p1.1">With the development of modern society’s economy, people’s desire for spiritual fulfillment is increasing. In terms of tourism, more and more people prefer to visit viewpoints that suit their preferences rather than popular ones. At this point, the abundance of information and inadequate viewpoint recommendations have become significant factors affecting the tourism experience. The Tibet region, with its rich tourism resources but substantial development challenges, urgently needs technological innovation to tap its cultural value and commercial potential.</p>
</div>
<div class="ltx_para" id="S1.SS1.p2">
<p class="ltx_p" id="S1.SS1.p2.1">To address these challenges, this study, under Project ID: XZ2024-01ZY0008, titled ”Research and Application of Intelligent Tourism Service System in Tibet Based on LLM,” aims to enhance tourists’ travel experiences and promote the development of Tibet’s tourism industry. The project focuses on the systematic organization and classification of viewpoints in the region. This includes detailed documentation of each viewpoint’s historical background, geographical location, cultural significance, and transportation information <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">Chen2020</span>)</cite>.</p>
</div>
<div class="ltx_para" id="S1.SS1.p3">
<p class="ltx_p" id="S1.SS1.p3.1">By constructing a comprehensive database and leveraging contemporary large language models (LLMs), we can offer personalized and precise attraction recommendations based on tourists’ needs. Specifically, this approach can guide tourists to less well-known but uniquely charming attractions, thereby alleviating the pressure on popular sites and promoting the rational utilization of tourism resources. Despite the significant technological advancements in LLMs, traditional models in the domain of personalized tourism recommendations still face two critical challenges: insufficient capability in personalized precise recommendations and issues related to the breadth, depth, timeliness, and accuracy of data.</p>
</div>
<div class="ltx_para" id="S1.SS1.p4">
<p class="ltx_p" id="S1.SS1.p4.1">Regarding the insufficiency in personalized recommendation capabilities, traditional models emphasize generalization but lack targeted fine-tuning, leading to suboptimal performance in personalized tourism contexts. Specifically, these models may exhibit ”hallucination” phenomena<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">Chen2023</span>)</cite>, where they fail to accurately understand user needs and recommend the most suitable attractions. This limitation is particularly evident in the context of Tibetan tourism, where the unique characteristics of many emerging attractions are not effectively captured, resulting in recommendations that lack accuracy and relevance.</p>
</div>
<div class="ltx_para" id="S1.SS1.p5">
<p class="ltx_p" id="S1.SS1.p5.1">Our research addresses these challenges by employing a vector database query method within the Retrieval-Augmented Generation (RAG) framework<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">meta_rag_2020</span>)</cite>. LLM extracts user requirements, which are then matched against a vector database to identify suitable attractions. These viewpoints are returned to the LLM for integration, resulting in accurate and contextually relevant recommendations tailored to the user’s preferences.</p>
</div>
<div class="ltx_para" id="S1.SS1.p6">
<p class="ltx_p" id="S1.SS1.p6.1">The breadth, depth, timeliness, and accuracy of data represent another major challenge affecting the personalized recommendation capabilities of LLMs. As Tibet’s tourism resources and infrastructure continue to evolve, LLMs require frequent updates to reflect the latest information. However, existing models often struggle to acquire and integrate the most recent tourism information and user feedback in real-time. This issue is particularly pronounced in remote areas or lesser-known attractions, where detailed data records and descriptions are often insufficient, leading to incomplete and inaccurate recommendations. Moreover, the unique cultural background of Tibet presents challenges for LLMs in handling relevant details with accuracy and depth. For instance, the understanding of Tibetan Buddhist rituals, festivals, and customs may be limited. Although LLMs possess multilingual processing capabilities, they may still face limitations when dealing with the Tibetan language and specialized terms related to Tibetan culture, potentially affecting the accuracy of information transmission.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Methods and Models</h2>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1. </span>Vectorization Methods: TF-IDF and BERT</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">TF-IDF (Term Frequency-Inverse Document Frequency) is used to evaluate the importance of a word in a document collection or corpus. By multiplying TF (term frequency) and IDF (inverse document frequency), the TF-IDF value is obtained, which measures the significance of a word to a particular document<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">Havrlant2017</span>)</cite>.</p>
</div>
<div class="ltx_para" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1">BERT (Bidirectional Encoder Representations from Transformers) handles unlabelled text data by pre-training deep bidirectional representations<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">Devlin2019</span>)</cite>. This pre-training process involves jointly conditioning on both left and right context in all layers, allowing the pre-trained BERT model to be fine-tuned for various tasks by simply adding an output layer. The advantage of this approach lies in its flexibility to adapt to the text data of this project and its capability to create state-of-the-art models for a wide range of NLP tasks.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2. </span>Retrieval Construction Methods</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">Retrieval techniques in vector databases can significantly impact the performance and efficiency of systems in large-scale data processing and querying. This project employs the following methods:</p>
</div>
<div class="ltx_para" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1">Flat (Brute Force Search): The system compares each vector in the database with the query vector, calculates their distance or similarity, and returns the closest vectors<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">Li2020</span>)</cite>.</p>
</div>
<div class="ltx_para" id="S2.SS2.p3">
<p class="ltx_p" id="S2.SS2.p3.1">HNSW (Hierarchical Navigable Small World): This method constructs a layered, small-world graph structure to accelerate query speed. HNSW supports multiple distance metrics, including l2 (Euclidean distance), l1 (Manhattan distance), and dot product<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">Lin2019</span>)</cite>.</p>
</div>
<div class="ltx_para" id="S2.SS2.p4">
<p class="ltx_p" id="S2.SS2.p4.1">IVFFlat (Inverted File Index with Flat Quantization): This technique clusters database vectors into multiple groups. During querying, it only searches the most relevant clusters to reduce computation.</p>
</div>
<div class="ltx_para" id="S2.SS2.p5">
<p class="ltx_p" id="S2.SS2.p5.1">SQ (Scalar Quantization): This method quantizes vector data to reduce storage and computation requirements<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">Johnson2017</span>)</cite>.</p>
</div>
<div class="ltx_para" id="S2.SS2.p6">
<p class="ltx_p" id="S2.SS2.p6.1">IVFSQ (Inverted File Index with Scalar Quantization): This combines the advantages of IVF and SQ by first clustering the data into multiple groups and then quantizing each cluster.</p>
</div>
<div class="ltx_para" id="S2.SS2.p7">
<p class="ltx_p" id="S2.SS2.p7.1">NSG (Navigable Small World Graph): Another graph-based Approximate Nearest Neighbor (ANN) search method, it constructs a navigable small-world graph for fast retrieval<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">Fu2019</span>)</cite>.</p>
</div>
<div class="ltx_para" id="S2.SS2.p8">
<p class="ltx_p" id="S2.SS2.p8.1">LSH (Locality-Sensitive Hashing): This technique accelerates similarity search by mapping similar data into the same hash buckets<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">Datar2004</span>)</cite>.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3. </span>LLMS Function Calling and Retrieval-Augmented Generation</h3>
<div class="ltx_para" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.1">LLM Function Calling enables large language models to interact with external functions, perform specific tasks, and generate more practical outputs<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">Gao2023</span>)</cite>. Function calling allows large language models to call external functions or services during the text generation process. By leveraging function calling, large language models can decide whether to invoke the corresponding functions based on instructions and return information in a structured format.</p>
</div>
<div class="ltx_para" id="S2.SS3.p2">
<p class="ltx_p" id="S2.SS3.p2.1">Retrieval-augmented generation (RAG) is a method that combines information retrieval and generation models to improve the performance of language models in handling complex queries and generation tasks. The core of the RAG method lies in its ability to combine pre-trained parametric memory with non-parametric external knowledge bases, accessing these external knowledge sources through a differentiable retrieval mechanism. This combination allows RAG models to rely not only on the internally learned knowledge during language generation but also to dynamically incorporate external information, thereby enhancing the relevance and accuracy of the generated content and eliminating model hallucinations<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">Lewis2020</span>)</cite>.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>Theoretical Exposition of RAG’s Method for Optimizing Hallucination in Large Language Models</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">The comprehensive methodology and procedural workflow of this study are depicted in Figure 1 and Figure 2. This figure provides a visual representation of the sequential steps and critical processes involved in the research, highlighting the key phases and their interconnections. Through this schematic, readers can gain a clearer understanding of the systematic approach adopted in this investigation.</p>
</div>
<figure class="ltx_figure" id="S3.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="391" id="S3.F1.g1" src="extracted/5804449/aipr1.jpg" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1. </span>RAG viewpoint information generation system flow chart</figcaption>
</figure>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1. </span>Dataset construction</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">To match the characteristics of each viewpoint when querying with an input prompt and identify the top three viewpoints that best meet the requirements, we integrated and processed existing viewpoint information to create a standardized database. After comparing the accuracy, standardization, and coverage of viewpoint data from various sources in the standardized database, we selected tourism information from Ctrip Travel as the primary data source and supplemented it with information from Wikipedia. For each viewpoint in the database, we recorded key information such as name, province, city, district, address, distance, popularity, ticket prices, brief description, and promotional policies. Through manual selection, we curated a total of 563 viewpoints, saving this information in CSV format as the basis for subsequent experiments.</p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1">Additionally, we needed a knowledge source database based on Retrieval-Augmented Generation (RAG) technology to mitigate hallucinations in large-scale language models while retaining crucial information. For this purpose, we employed the open-source large language model Mistral-7B-Instruct-v0.3<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">Mistral7BInstruct</span>)</cite>, which supports function calling. We designed precise prompts and detailed information extraction requirements for the model, embedding them into a function-calling framework. This enabled the large language model to automatically extract required geographic and historical information from Ctrip’s tourism information. Extracted information was formatted into a dictionary data structure, containing two primary key-value pairs: one for storing historical information and another for storing geographic information. Ultimately, we successfully extracted and organized the necessary geographic and historical information from the 563 viewpoints corresponding to our standardized database.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2. </span>Database Vectorization and Indexing</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">To achieve the task of matching viewpoints based on user preferences and needs while addressing the issue of insufficient retrieval accuracy caused by fuzzy searches, we adopted a method of vectorizing the database before indexing. The classic vectorization methods include TF-IDF and BERT, and the indexing methods for the vectorized data include Flat, HNSWFlat, SQ, LSH, etc. The distance calculation methods after indexing include Manhattan distance, Euclidean distance, and inner product. To explore which combination of ”vectorization method + indexing method + distance calculation” is most suitable for the content in the context of Tibet’s cultural tourism, we designed a total of 20 sets of control experiments across these three dimensions.</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1">The prompts for the control experiments were manually created. To ensure randomness in user searches and stability in feature quantity, each prompt randomly includes 1-4 features with an average total feature count of 3. These prompts were used as inputs for each group, and we used the SpaCy library to calculate the number of feature hits and feature hit rates to evaluate the performance of vectorized indexing.</p>
</div>
<div class="ltx_para" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.1">The formula presented below is the formula for TF-IDF<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">Jones1972</span>)</cite>.</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_left">(1)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="w_{x,y}=\text{tf}_{x,y}\times\log\left(\frac{N}{\text{df}_{x}}\right)" class="ltx_Math" display="block" id="S3.E1.m1.6"><semantics id="S3.E1.m1.6a"><mrow id="S3.E1.m1.6.7" xref="S3.E1.m1.6.7.cmml"><msub id="S3.E1.m1.6.7.2" xref="S3.E1.m1.6.7.2.cmml"><mi id="S3.E1.m1.6.7.2.2" xref="S3.E1.m1.6.7.2.2.cmml">w</mi><mrow id="S3.E1.m1.2.2.2.4" xref="S3.E1.m1.2.2.2.3.cmml"><mi id="S3.E1.m1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml">x</mi><mo id="S3.E1.m1.2.2.2.4.1" xref="S3.E1.m1.2.2.2.3.cmml">,</mo><mi id="S3.E1.m1.2.2.2.2" xref="S3.E1.m1.2.2.2.2.cmml">y</mi></mrow></msub><mo id="S3.E1.m1.6.7.1" xref="S3.E1.m1.6.7.1.cmml">=</mo><mrow id="S3.E1.m1.6.7.3" xref="S3.E1.m1.6.7.3.cmml"><msub id="S3.E1.m1.6.7.3.2" xref="S3.E1.m1.6.7.3.2.cmml"><mtext id="S3.E1.m1.6.7.3.2.2" xref="S3.E1.m1.6.7.3.2.2a.cmml">tf</mtext><mrow id="S3.E1.m1.4.4.2.4" xref="S3.E1.m1.4.4.2.3.cmml"><mi id="S3.E1.m1.3.3.1.1" xref="S3.E1.m1.3.3.1.1.cmml">x</mi><mo id="S3.E1.m1.4.4.2.4.1" xref="S3.E1.m1.4.4.2.3.cmml">,</mo><mi id="S3.E1.m1.4.4.2.2" xref="S3.E1.m1.4.4.2.2.cmml">y</mi></mrow></msub><mo id="S3.E1.m1.6.7.3.1" lspace="0.222em" rspace="0.222em" xref="S3.E1.m1.6.7.3.1.cmml">×</mo><mrow id="S3.E1.m1.6.7.3.3.2" xref="S3.E1.m1.6.7.3.3.1.cmml"><mi id="S3.E1.m1.5.5" xref="S3.E1.m1.5.5.cmml">log</mi><mo id="S3.E1.m1.6.7.3.3.2a" xref="S3.E1.m1.6.7.3.3.1.cmml">⁡</mo><mrow id="S3.E1.m1.6.7.3.3.2.1" xref="S3.E1.m1.6.7.3.3.1.cmml"><mo id="S3.E1.m1.6.7.3.3.2.1.1" xref="S3.E1.m1.6.7.3.3.1.cmml">(</mo><mfrac id="S3.E1.m1.6.6" xref="S3.E1.m1.6.6.cmml"><mi id="S3.E1.m1.6.6.2" xref="S3.E1.m1.6.6.2.cmml">N</mi><msub id="S3.E1.m1.6.6.3" xref="S3.E1.m1.6.6.3.cmml"><mtext id="S3.E1.m1.6.6.3.2" xref="S3.E1.m1.6.6.3.2a.cmml">df</mtext><mi id="S3.E1.m1.6.6.3.3" xref="S3.E1.m1.6.6.3.3.cmml">x</mi></msub></mfrac><mo id="S3.E1.m1.6.7.3.3.2.1.2" xref="S3.E1.m1.6.7.3.3.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.6b"><apply id="S3.E1.m1.6.7.cmml" xref="S3.E1.m1.6.7"><eq id="S3.E1.m1.6.7.1.cmml" xref="S3.E1.m1.6.7.1"></eq><apply id="S3.E1.m1.6.7.2.cmml" xref="S3.E1.m1.6.7.2"><csymbol cd="ambiguous" id="S3.E1.m1.6.7.2.1.cmml" xref="S3.E1.m1.6.7.2">subscript</csymbol><ci id="S3.E1.m1.6.7.2.2.cmml" xref="S3.E1.m1.6.7.2.2">𝑤</ci><list id="S3.E1.m1.2.2.2.3.cmml" xref="S3.E1.m1.2.2.2.4"><ci id="S3.E1.m1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1">𝑥</ci><ci id="S3.E1.m1.2.2.2.2.cmml" xref="S3.E1.m1.2.2.2.2">𝑦</ci></list></apply><apply id="S3.E1.m1.6.7.3.cmml" xref="S3.E1.m1.6.7.3"><times id="S3.E1.m1.6.7.3.1.cmml" xref="S3.E1.m1.6.7.3.1"></times><apply id="S3.E1.m1.6.7.3.2.cmml" xref="S3.E1.m1.6.7.3.2"><csymbol cd="ambiguous" id="S3.E1.m1.6.7.3.2.1.cmml" xref="S3.E1.m1.6.7.3.2">subscript</csymbol><ci id="S3.E1.m1.6.7.3.2.2a.cmml" xref="S3.E1.m1.6.7.3.2.2"><mtext id="S3.E1.m1.6.7.3.2.2.cmml" xref="S3.E1.m1.6.7.3.2.2">tf</mtext></ci><list id="S3.E1.m1.4.4.2.3.cmml" xref="S3.E1.m1.4.4.2.4"><ci id="S3.E1.m1.3.3.1.1.cmml" xref="S3.E1.m1.3.3.1.1">𝑥</ci><ci id="S3.E1.m1.4.4.2.2.cmml" xref="S3.E1.m1.4.4.2.2">𝑦</ci></list></apply><apply id="S3.E1.m1.6.7.3.3.1.cmml" xref="S3.E1.m1.6.7.3.3.2"><log id="S3.E1.m1.5.5.cmml" xref="S3.E1.m1.5.5"></log><apply id="S3.E1.m1.6.6.cmml" xref="S3.E1.m1.6.6"><divide id="S3.E1.m1.6.6.1.cmml" xref="S3.E1.m1.6.6"></divide><ci id="S3.E1.m1.6.6.2.cmml" xref="S3.E1.m1.6.6.2">𝑁</ci><apply id="S3.E1.m1.6.6.3.cmml" xref="S3.E1.m1.6.6.3"><csymbol cd="ambiguous" id="S3.E1.m1.6.6.3.1.cmml" xref="S3.E1.m1.6.6.3">subscript</csymbol><ci id="S3.E1.m1.6.6.3.2a.cmml" xref="S3.E1.m1.6.6.3.2"><mtext id="S3.E1.m1.6.6.3.2.cmml" xref="S3.E1.m1.6.6.3.2">df</mtext></ci><ci id="S3.E1.m1.6.6.3.3.cmml" xref="S3.E1.m1.6.6.3.3">𝑥</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.6c">w_{x,y}=\text{tf}_{x,y}\times\log\left(\frac{N}{\text{df}_{x}}\right)</annotation><annotation encoding="application/x-llamapun" id="S3.E1.m1.6d">italic_w start_POSTSUBSCRIPT italic_x , italic_y end_POSTSUBSCRIPT = tf start_POSTSUBSCRIPT italic_x , italic_y end_POSTSUBSCRIPT × roman_log ( divide start_ARG italic_N end_ARG start_ARG df start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT end_ARG )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p4">
<p class="ltx_p" id="S3.SS2.p4.6"><span class="ltx_text ltx_font_bold" id="S3.SS2.p4.1.1">TF-IDF
<br class="ltx_break"/><math alttext="\text{tf}_{x,y}" class="ltx_Math" display="inline" id="S3.SS2.p4.1.1.m1.2"><semantics id="S3.SS2.p4.1.1.m1.2a"><msub id="S3.SS2.p4.1.1.m1.2.3" xref="S3.SS2.p4.1.1.m1.2.3.cmml"><mtext id="S3.SS2.p4.1.1.m1.2.3.2" xref="S3.SS2.p4.1.1.m1.2.3.2a.cmml">tf</mtext><mrow id="S3.SS2.p4.1.1.m1.2.2.2.4" xref="S3.SS2.p4.1.1.m1.2.2.2.3.cmml"><mi id="S3.SS2.p4.1.1.m1.1.1.1.1" xref="S3.SS2.p4.1.1.m1.1.1.1.1.cmml">x</mi><mo id="S3.SS2.p4.1.1.m1.2.2.2.4.1" xref="S3.SS2.p4.1.1.m1.2.2.2.3.cmml">,</mo><mi id="S3.SS2.p4.1.1.m1.2.2.2.2" xref="S3.SS2.p4.1.1.m1.2.2.2.2.cmml">y</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.1.1.m1.2b"><apply id="S3.SS2.p4.1.1.m1.2.3.cmml" xref="S3.SS2.p4.1.1.m1.2.3"><csymbol cd="ambiguous" id="S3.SS2.p4.1.1.m1.2.3.1.cmml" xref="S3.SS2.p4.1.1.m1.2.3">subscript</csymbol><ci id="S3.SS2.p4.1.1.m1.2.3.2a.cmml" xref="S3.SS2.p4.1.1.m1.2.3.2"><mtext id="S3.SS2.p4.1.1.m1.2.3.2.cmml" xref="S3.SS2.p4.1.1.m1.2.3.2">tf</mtext></ci><list id="S3.SS2.p4.1.1.m1.2.2.2.3.cmml" xref="S3.SS2.p4.1.1.m1.2.2.2.4"><ci id="S3.SS2.p4.1.1.m1.1.1.1.1.cmml" xref="S3.SS2.p4.1.1.m1.1.1.1.1">𝑥</ci><ci id="S3.SS2.p4.1.1.m1.2.2.2.2.cmml" xref="S3.SS2.p4.1.1.m1.2.2.2.2">𝑦</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.1.1.m1.2c">\text{tf}_{x,y}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.1.1.m1.2d">tf start_POSTSUBSCRIPT italic_x , italic_y end_POSTSUBSCRIPT</annotation></semantics></math></span> = frequency of <math alttext="x" class="ltx_Math" display="inline" id="S3.SS2.p4.2.m1.1"><semantics id="S3.SS2.p4.2.m1.1a"><mi id="S3.SS2.p4.2.m1.1.1" xref="S3.SS2.p4.2.m1.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.2.m1.1b"><ci id="S3.SS2.p4.2.m1.1.1.cmml" xref="S3.SS2.p4.2.m1.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.2.m1.1c">x</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.2.m1.1d">italic_x</annotation></semantics></math> in <math alttext="y" class="ltx_Math" display="inline" id="S3.SS2.p4.3.m2.1"><semantics id="S3.SS2.p4.3.m2.1a"><mi id="S3.SS2.p4.3.m2.1.1" xref="S3.SS2.p4.3.m2.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.3.m2.1b"><ci id="S3.SS2.p4.3.m2.1.1.cmml" xref="S3.SS2.p4.3.m2.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.3.m2.1c">y</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.3.m2.1d">italic_y</annotation></semantics></math>
<br class="ltx_break"/><math alttext="\text{df}_{x}" class="ltx_Math" display="inline" id="S3.SS2.p4.4.m3.1"><semantics id="S3.SS2.p4.4.m3.1a"><msub id="S3.SS2.p4.4.m3.1.1" xref="S3.SS2.p4.4.m3.1.1.cmml"><mtext id="S3.SS2.p4.4.m3.1.1.2" xref="S3.SS2.p4.4.m3.1.1.2a.cmml">df</mtext><mi id="S3.SS2.p4.4.m3.1.1.3" xref="S3.SS2.p4.4.m3.1.1.3.cmml">x</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.4.m3.1b"><apply id="S3.SS2.p4.4.m3.1.1.cmml" xref="S3.SS2.p4.4.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.4.m3.1.1.1.cmml" xref="S3.SS2.p4.4.m3.1.1">subscript</csymbol><ci id="S3.SS2.p4.4.m3.1.1.2a.cmml" xref="S3.SS2.p4.4.m3.1.1.2"><mtext id="S3.SS2.p4.4.m3.1.1.2.cmml" xref="S3.SS2.p4.4.m3.1.1.2">df</mtext></ci><ci id="S3.SS2.p4.4.m3.1.1.3.cmml" xref="S3.SS2.p4.4.m3.1.1.3">𝑥</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.4.m3.1c">\text{df}_{x}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.4.m3.1d">df start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT</annotation></semantics></math> = number of documents containing <math alttext="x" class="ltx_Math" display="inline" id="S3.SS2.p4.5.m4.1"><semantics id="S3.SS2.p4.5.m4.1a"><mi id="S3.SS2.p4.5.m4.1.1" xref="S3.SS2.p4.5.m4.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.5.m4.1b"><ci id="S3.SS2.p4.5.m4.1.1.cmml" xref="S3.SS2.p4.5.m4.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.5.m4.1c">x</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.5.m4.1d">italic_x</annotation></semantics></math>
<br class="ltx_break"/><math alttext="N" class="ltx_Math" display="inline" id="S3.SS2.p4.6.m5.1"><semantics id="S3.SS2.p4.6.m5.1a"><mi id="S3.SS2.p4.6.m5.1.1" xref="S3.SS2.p4.6.m5.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.6.m5.1b"><ci id="S3.SS2.p4.6.m5.1.1.cmml" xref="S3.SS2.p4.6.m5.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.6.m5.1c">N</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.6.m5.1d">italic_N</annotation></semantics></math> = total number of documents</p>
<ul class="ltx_itemize" id="S3.I1">
<li class="ltx_item" id="S3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I1.i1.p1">
<p class="ltx_p" id="S3.I1.i1.p1.5"><math alttext="w_{x,y}" class="ltx_Math" display="inline" id="S3.I1.i1.p1.1.m1.2"><semantics id="S3.I1.i1.p1.1.m1.2a"><msub id="S3.I1.i1.p1.1.m1.2.3" xref="S3.I1.i1.p1.1.m1.2.3.cmml"><mi id="S3.I1.i1.p1.1.m1.2.3.2" xref="S3.I1.i1.p1.1.m1.2.3.2.cmml">w</mi><mrow id="S3.I1.i1.p1.1.m1.2.2.2.4" xref="S3.I1.i1.p1.1.m1.2.2.2.3.cmml"><mi id="S3.I1.i1.p1.1.m1.1.1.1.1" xref="S3.I1.i1.p1.1.m1.1.1.1.1.cmml">x</mi><mo id="S3.I1.i1.p1.1.m1.2.2.2.4.1" xref="S3.I1.i1.p1.1.m1.2.2.2.3.cmml">,</mo><mi id="S3.I1.i1.p1.1.m1.2.2.2.2" xref="S3.I1.i1.p1.1.m1.2.2.2.2.cmml">y</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.I1.i1.p1.1.m1.2b"><apply id="S3.I1.i1.p1.1.m1.2.3.cmml" xref="S3.I1.i1.p1.1.m1.2.3"><csymbol cd="ambiguous" id="S3.I1.i1.p1.1.m1.2.3.1.cmml" xref="S3.I1.i1.p1.1.m1.2.3">subscript</csymbol><ci id="S3.I1.i1.p1.1.m1.2.3.2.cmml" xref="S3.I1.i1.p1.1.m1.2.3.2">𝑤</ci><list id="S3.I1.i1.p1.1.m1.2.2.2.3.cmml" xref="S3.I1.i1.p1.1.m1.2.2.2.4"><ci id="S3.I1.i1.p1.1.m1.1.1.1.1.cmml" xref="S3.I1.i1.p1.1.m1.1.1.1.1">𝑥</ci><ci id="S3.I1.i1.p1.1.m1.2.2.2.2.cmml" xref="S3.I1.i1.p1.1.m1.2.2.2.2">𝑦</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i1.p1.1.m1.2c">w_{x,y}</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i1.p1.1.m1.2d">italic_w start_POSTSUBSCRIPT italic_x , italic_y end_POSTSUBSCRIPT</annotation></semantics></math>: This represents the TF-IDF weight of term <math alttext="x" class="ltx_Math" display="inline" id="S3.I1.i1.p1.2.m2.1"><semantics id="S3.I1.i1.p1.2.m2.1a"><mi id="S3.I1.i1.p1.2.m2.1.1" xref="S3.I1.i1.p1.2.m2.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.I1.i1.p1.2.m2.1b"><ci id="S3.I1.i1.p1.2.m2.1.1.cmml" xref="S3.I1.i1.p1.2.m2.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i1.p1.2.m2.1c">x</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i1.p1.2.m2.1d">italic_x</annotation></semantics></math> in document <math alttext="y" class="ltx_Math" display="inline" id="S3.I1.i1.p1.3.m3.1"><semantics id="S3.I1.i1.p1.3.m3.1a"><mi id="S3.I1.i1.p1.3.m3.1.1" xref="S3.I1.i1.p1.3.m3.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S3.I1.i1.p1.3.m3.1b"><ci id="S3.I1.i1.p1.3.m3.1.1.cmml" xref="S3.I1.i1.p1.3.m3.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i1.p1.3.m3.1c">y</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i1.p1.3.m3.1d">italic_y</annotation></semantics></math>. It is a measure of how important term <math alttext="x" class="ltx_Math" display="inline" id="S3.I1.i1.p1.4.m4.1"><semantics id="S3.I1.i1.p1.4.m4.1a"><mi id="S3.I1.i1.p1.4.m4.1.1" xref="S3.I1.i1.p1.4.m4.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.I1.i1.p1.4.m4.1b"><ci id="S3.I1.i1.p1.4.m4.1.1.cmml" xref="S3.I1.i1.p1.4.m4.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i1.p1.4.m4.1c">x</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i1.p1.4.m4.1d">italic_x</annotation></semantics></math> is in the specific document <math alttext="y" class="ltx_Math" display="inline" id="S3.I1.i1.p1.5.m5.1"><semantics id="S3.I1.i1.p1.5.m5.1a"><mi id="S3.I1.i1.p1.5.m5.1.1" xref="S3.I1.i1.p1.5.m5.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S3.I1.i1.p1.5.m5.1b"><ci id="S3.I1.i1.p1.5.m5.1.1.cmml" xref="S3.I1.i1.p1.5.m5.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i1.p1.5.m5.1c">y</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i1.p1.5.m5.1d">italic_y</annotation></semantics></math>.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I1.i2.p1">
<p class="ltx_p" id="S3.I1.i2.p1.3"><math alttext="\text{tf}_{x,y}" class="ltx_Math" display="inline" id="S3.I1.i2.p1.1.m1.2"><semantics id="S3.I1.i2.p1.1.m1.2a"><msub id="S3.I1.i2.p1.1.m1.2.3" xref="S3.I1.i2.p1.1.m1.2.3.cmml"><mtext id="S3.I1.i2.p1.1.m1.2.3.2" xref="S3.I1.i2.p1.1.m1.2.3.2a.cmml">tf</mtext><mrow id="S3.I1.i2.p1.1.m1.2.2.2.4" xref="S3.I1.i2.p1.1.m1.2.2.2.3.cmml"><mi id="S3.I1.i2.p1.1.m1.1.1.1.1" xref="S3.I1.i2.p1.1.m1.1.1.1.1.cmml">x</mi><mo id="S3.I1.i2.p1.1.m1.2.2.2.4.1" xref="S3.I1.i2.p1.1.m1.2.2.2.3.cmml">,</mo><mi id="S3.I1.i2.p1.1.m1.2.2.2.2" xref="S3.I1.i2.p1.1.m1.2.2.2.2.cmml">y</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.I1.i2.p1.1.m1.2b"><apply id="S3.I1.i2.p1.1.m1.2.3.cmml" xref="S3.I1.i2.p1.1.m1.2.3"><csymbol cd="ambiguous" id="S3.I1.i2.p1.1.m1.2.3.1.cmml" xref="S3.I1.i2.p1.1.m1.2.3">subscript</csymbol><ci id="S3.I1.i2.p1.1.m1.2.3.2a.cmml" xref="S3.I1.i2.p1.1.m1.2.3.2"><mtext id="S3.I1.i2.p1.1.m1.2.3.2.cmml" xref="S3.I1.i2.p1.1.m1.2.3.2">tf</mtext></ci><list id="S3.I1.i2.p1.1.m1.2.2.2.3.cmml" xref="S3.I1.i2.p1.1.m1.2.2.2.4"><ci id="S3.I1.i2.p1.1.m1.1.1.1.1.cmml" xref="S3.I1.i2.p1.1.m1.1.1.1.1">𝑥</ci><ci id="S3.I1.i2.p1.1.m1.2.2.2.2.cmml" xref="S3.I1.i2.p1.1.m1.2.2.2.2">𝑦</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i2.p1.1.m1.2c">\text{tf}_{x,y}</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i2.p1.1.m1.2d">tf start_POSTSUBSCRIPT italic_x , italic_y end_POSTSUBSCRIPT</annotation></semantics></math>: This is the Term Frequency (TF), which refers to the number of times term <math alttext="x" class="ltx_Math" display="inline" id="S3.I1.i2.p1.2.m2.1"><semantics id="S3.I1.i2.p1.2.m2.1a"><mi id="S3.I1.i2.p1.2.m2.1.1" xref="S3.I1.i2.p1.2.m2.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.I1.i2.p1.2.m2.1b"><ci id="S3.I1.i2.p1.2.m2.1.1.cmml" xref="S3.I1.i2.p1.2.m2.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i2.p1.2.m2.1c">x</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i2.p1.2.m2.1d">italic_x</annotation></semantics></math> appears in document <math alttext="y" class="ltx_Math" display="inline" id="S3.I1.i2.p1.3.m3.1"><semantics id="S3.I1.i2.p1.3.m3.1a"><mi id="S3.I1.i2.p1.3.m3.1.1" xref="S3.I1.i2.p1.3.m3.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S3.I1.i2.p1.3.m3.1b"><ci id="S3.I1.i2.p1.3.m3.1.1.cmml" xref="S3.I1.i2.p1.3.m3.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i2.p1.3.m3.1c">y</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i2.p1.3.m3.1d">italic_y</annotation></semantics></math>. It reflects how frequently a word occurs in a document.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I1.i3.p1">
<p class="ltx_p" id="S3.I1.i3.p1.1"><math alttext="\log\left(\frac{N}{\text{df}_{x}}\right)" class="ltx_Math" display="inline" id="S3.I1.i3.p1.1.m1.2"><semantics id="S3.I1.i3.p1.1.m1.2a"><mrow id="S3.I1.i3.p1.1.m1.2.3.2" xref="S3.I1.i3.p1.1.m1.2.3.1.cmml"><mi id="S3.I1.i3.p1.1.m1.1.1" xref="S3.I1.i3.p1.1.m1.1.1.cmml">log</mi><mo id="S3.I1.i3.p1.1.m1.2.3.2a" xref="S3.I1.i3.p1.1.m1.2.3.1.cmml">⁡</mo><mrow id="S3.I1.i3.p1.1.m1.2.3.2.1" xref="S3.I1.i3.p1.1.m1.2.3.1.cmml"><mo id="S3.I1.i3.p1.1.m1.2.3.2.1.1" xref="S3.I1.i3.p1.1.m1.2.3.1.cmml">(</mo><mfrac id="S3.I1.i3.p1.1.m1.2.2" xref="S3.I1.i3.p1.1.m1.2.2.cmml"><mi id="S3.I1.i3.p1.1.m1.2.2.2" xref="S3.I1.i3.p1.1.m1.2.2.2.cmml">N</mi><msub id="S3.I1.i3.p1.1.m1.2.2.3" xref="S3.I1.i3.p1.1.m1.2.2.3.cmml"><mtext id="S3.I1.i3.p1.1.m1.2.2.3.2" xref="S3.I1.i3.p1.1.m1.2.2.3.2a.cmml">df</mtext><mi id="S3.I1.i3.p1.1.m1.2.2.3.3" xref="S3.I1.i3.p1.1.m1.2.2.3.3.cmml">x</mi></msub></mfrac><mo id="S3.I1.i3.p1.1.m1.2.3.2.1.2" xref="S3.I1.i3.p1.1.m1.2.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.I1.i3.p1.1.m1.2b"><apply id="S3.I1.i3.p1.1.m1.2.3.1.cmml" xref="S3.I1.i3.p1.1.m1.2.3.2"><log id="S3.I1.i3.p1.1.m1.1.1.cmml" xref="S3.I1.i3.p1.1.m1.1.1"></log><apply id="S3.I1.i3.p1.1.m1.2.2.cmml" xref="S3.I1.i3.p1.1.m1.2.2"><divide id="S3.I1.i3.p1.1.m1.2.2.1.cmml" xref="S3.I1.i3.p1.1.m1.2.2"></divide><ci id="S3.I1.i3.p1.1.m1.2.2.2.cmml" xref="S3.I1.i3.p1.1.m1.2.2.2">𝑁</ci><apply id="S3.I1.i3.p1.1.m1.2.2.3.cmml" xref="S3.I1.i3.p1.1.m1.2.2.3"><csymbol cd="ambiguous" id="S3.I1.i3.p1.1.m1.2.2.3.1.cmml" xref="S3.I1.i3.p1.1.m1.2.2.3">subscript</csymbol><ci id="S3.I1.i3.p1.1.m1.2.2.3.2a.cmml" xref="S3.I1.i3.p1.1.m1.2.2.3.2"><mtext id="S3.I1.i3.p1.1.m1.2.2.3.2.cmml" mathsize="70%" xref="S3.I1.i3.p1.1.m1.2.2.3.2">df</mtext></ci><ci id="S3.I1.i3.p1.1.m1.2.2.3.3.cmml" xref="S3.I1.i3.p1.1.m1.2.2.3.3">𝑥</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i3.p1.1.m1.2c">\log\left(\frac{N}{\text{df}_{x}}\right)</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i3.p1.1.m1.2d">roman_log ( divide start_ARG italic_N end_ARG start_ARG df start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT end_ARG )</annotation></semantics></math>: This part is the Inverse Document Frequency (IDF):</p>
<ul class="ltx_itemize" id="S3.I1.i3.I1">
<li class="ltx_item" id="S3.I1.i3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="S3.I1.i3.I1.i1.1.1.1">–</span></span>
<div class="ltx_para" id="S3.I1.i3.I1.i1.p1">
<p class="ltx_p" id="S3.I1.i3.I1.i1.p1.1"><math alttext="N" class="ltx_Math" display="inline" id="S3.I1.i3.I1.i1.p1.1.m1.1"><semantics id="S3.I1.i3.I1.i1.p1.1.m1.1a"><mi id="S3.I1.i3.I1.i1.p1.1.m1.1.1" xref="S3.I1.i3.I1.i1.p1.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.I1.i3.I1.i1.p1.1.m1.1b"><ci id="S3.I1.i3.I1.i1.p1.1.m1.1.1.cmml" xref="S3.I1.i3.I1.i1.p1.1.m1.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i3.I1.i1.p1.1.m1.1c">N</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i3.I1.i1.p1.1.m1.1d">italic_N</annotation></semantics></math>: The total number of documents in the corpus.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="S3.I1.i3.I1.i2.1.1.1">–</span></span>
<div class="ltx_para" id="S3.I1.i3.I1.i2.p1">
<p class="ltx_p" id="S3.I1.i3.I1.i2.p1.2"><math alttext="\text{df}_{x}" class="ltx_Math" display="inline" id="S3.I1.i3.I1.i2.p1.1.m1.1"><semantics id="S3.I1.i3.I1.i2.p1.1.m1.1a"><msub id="S3.I1.i3.I1.i2.p1.1.m1.1.1" xref="S3.I1.i3.I1.i2.p1.1.m1.1.1.cmml"><mtext id="S3.I1.i3.I1.i2.p1.1.m1.1.1.2" xref="S3.I1.i3.I1.i2.p1.1.m1.1.1.2a.cmml">df</mtext><mi id="S3.I1.i3.I1.i2.p1.1.m1.1.1.3" xref="S3.I1.i3.I1.i2.p1.1.m1.1.1.3.cmml">x</mi></msub><annotation-xml encoding="MathML-Content" id="S3.I1.i3.I1.i2.p1.1.m1.1b"><apply id="S3.I1.i3.I1.i2.p1.1.m1.1.1.cmml" xref="S3.I1.i3.I1.i2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.I1.i3.I1.i2.p1.1.m1.1.1.1.cmml" xref="S3.I1.i3.I1.i2.p1.1.m1.1.1">subscript</csymbol><ci id="S3.I1.i3.I1.i2.p1.1.m1.1.1.2a.cmml" xref="S3.I1.i3.I1.i2.p1.1.m1.1.1.2"><mtext id="S3.I1.i3.I1.i2.p1.1.m1.1.1.2.cmml" xref="S3.I1.i3.I1.i2.p1.1.m1.1.1.2">df</mtext></ci><ci id="S3.I1.i3.I1.i2.p1.1.m1.1.1.3.cmml" xref="S3.I1.i3.I1.i2.p1.1.m1.1.1.3">𝑥</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i3.I1.i2.p1.1.m1.1c">\text{df}_{x}</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i3.I1.i2.p1.1.m1.1d">df start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT</annotation></semantics></math>: The number of documents that contain the term <math alttext="x" class="ltx_Math" display="inline" id="S3.I1.i3.I1.i2.p1.2.m2.1"><semantics id="S3.I1.i3.I1.i2.p1.2.m2.1a"><mi id="S3.I1.i3.I1.i2.p1.2.m2.1.1" xref="S3.I1.i3.I1.i2.p1.2.m2.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.I1.i3.I1.i2.p1.2.m2.1b"><ci id="S3.I1.i3.I1.i2.p1.2.m2.1.1.cmml" xref="S3.I1.i3.I1.i2.p1.2.m2.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i3.I1.i2.p1.2.m2.1c">x</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i3.I1.i2.p1.2.m2.1d">italic_x</annotation></semantics></math>.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i3.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="S3.I1.i3.I1.i3.1.1.1">–</span></span>
<div class="ltx_para" id="S3.I1.i3.I1.i3.p1">
<p class="ltx_p" id="S3.I1.i3.I1.i3.p1.2"><math alttext="\frac{N}{\text{df}_{x}}" class="ltx_Math" display="inline" id="S3.I1.i3.I1.i3.p1.1.m1.1"><semantics id="S3.I1.i3.I1.i3.p1.1.m1.1a"><mfrac id="S3.I1.i3.I1.i3.p1.1.m1.1.1" xref="S3.I1.i3.I1.i3.p1.1.m1.1.1.cmml"><mi id="S3.I1.i3.I1.i3.p1.1.m1.1.1.2" xref="S3.I1.i3.I1.i3.p1.1.m1.1.1.2.cmml">N</mi><msub id="S3.I1.i3.I1.i3.p1.1.m1.1.1.3" xref="S3.I1.i3.I1.i3.p1.1.m1.1.1.3.cmml"><mtext id="S3.I1.i3.I1.i3.p1.1.m1.1.1.3.2" xref="S3.I1.i3.I1.i3.p1.1.m1.1.1.3.2a.cmml">df</mtext><mi id="S3.I1.i3.I1.i3.p1.1.m1.1.1.3.3" xref="S3.I1.i3.I1.i3.p1.1.m1.1.1.3.3.cmml">x</mi></msub></mfrac><annotation-xml encoding="MathML-Content" id="S3.I1.i3.I1.i3.p1.1.m1.1b"><apply id="S3.I1.i3.I1.i3.p1.1.m1.1.1.cmml" xref="S3.I1.i3.I1.i3.p1.1.m1.1.1"><divide id="S3.I1.i3.I1.i3.p1.1.m1.1.1.1.cmml" xref="S3.I1.i3.I1.i3.p1.1.m1.1.1"></divide><ci id="S3.I1.i3.I1.i3.p1.1.m1.1.1.2.cmml" xref="S3.I1.i3.I1.i3.p1.1.m1.1.1.2">𝑁</ci><apply id="S3.I1.i3.I1.i3.p1.1.m1.1.1.3.cmml" xref="S3.I1.i3.I1.i3.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.I1.i3.I1.i3.p1.1.m1.1.1.3.1.cmml" xref="S3.I1.i3.I1.i3.p1.1.m1.1.1.3">subscript</csymbol><ci id="S3.I1.i3.I1.i3.p1.1.m1.1.1.3.2a.cmml" xref="S3.I1.i3.I1.i3.p1.1.m1.1.1.3.2"><mtext id="S3.I1.i3.I1.i3.p1.1.m1.1.1.3.2.cmml" mathsize="70%" xref="S3.I1.i3.I1.i3.p1.1.m1.1.1.3.2">df</mtext></ci><ci id="S3.I1.i3.I1.i3.p1.1.m1.1.1.3.3.cmml" xref="S3.I1.i3.I1.i3.p1.1.m1.1.1.3.3">𝑥</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i3.I1.i3.p1.1.m1.1c">\frac{N}{\text{df}_{x}}</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i3.I1.i3.p1.1.m1.1d">divide start_ARG italic_N end_ARG start_ARG df start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT end_ARG</annotation></semantics></math>: This ratio represents how common or rare the term <math alttext="x" class="ltx_Math" display="inline" id="S3.I1.i3.I1.i3.p1.2.m2.1"><semantics id="S3.I1.i3.I1.i3.p1.2.m2.1a"><mi id="S3.I1.i3.I1.i3.p1.2.m2.1.1" xref="S3.I1.i3.I1.i3.p1.2.m2.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.I1.i3.I1.i3.p1.2.m2.1b"><ci id="S3.I1.i3.I1.i3.p1.2.m2.1.1.cmml" xref="S3.I1.i3.I1.i3.p1.2.m2.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i3.I1.i3.p1.2.m2.1c">x</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i3.I1.i3.p1.2.m2.1d">italic_x</annotation></semantics></math> is across all documents in the corpus. The logarithm of this ratio dampens the effect of the term frequency, making sure that common terms (which appear in many documents) do not dominate the weighting.</p>
</div>
</li>
</ul>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3. </span>RAG Optimization for Large Language Models</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">We employed vector database retrieval to address the hallucination problem of large models. After identifying the viewpoints based on user needs, the geographical and historical information from the knowledge source database was returned to the large language model as an external knowledge base. Under this framework, the large language model no longer relies solely on its internal knowledge base to generate viewpoint introduction information. Instead, it understands and integrates the viewpoint introduction content through the external knowledge base. This method not only effectively optimize the hallucination problem of LLMs but also allows the model to fetch and generate comprehensive viewpoint introduction information, including geographical and historical details, even when certain knowledge is not included within the LLM itself. This research demonstrates the potential of RAG technology in enhancing the accuracy of information generated by large language models, providing new methods and tools for the standardization of tourism information and data analysis.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4. </span>Evaluation Method</h3>
<div class="ltx_para" id="S3.SS4.p1">
<p class="ltx_p" id="S3.SS4.p1.1">To evaluate the vector databases, we used the keyword-matching function of the SpaCy library along with a mature Chinese pre-trained model. After loading SpaCy’s<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">ExplosionAI</span>)</cite> pre-trained Chinese model, we applied it to the result text data from different retrieval methods. By calculating the number of keywords that match the features in the prompts, we can determine the relevance and accuracy of the retrieval results.</p>
</div>
<div class="ltx_para" id="S3.SS4.p2">
<p class="ltx_p" id="S3.SS4.p2.1">Since the dataset used in this experiment is unstructured, we utilized the ”calculate composite score” scoring system’s b formula to calculate the scores for various dataset metrics and derive a composite score. Detailed scoring criteria can be referenced from Qi’s scoring standards<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">Qi2024</span>)</cite>.</p>
</div>
<div class="ltx_para" id="S3.SS4.p3">
<p class="ltx_p" id="S3.SS4.p3.1"><span class="ltx_text" id="S3.SS4.p3.1.1">Comprehensive score (percentage system) </span> =</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_left">(2)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\begin{cases}b&amp;\sum\left(d_{1}\cdot\text{fluency }+d_{2}\cdot\log(\text{%
accurate rate}+1)+\right.\\
&amp;\left.d_{3}\cdot\exp(\text{relevance })\right)\end{cases}" class="ltx_math_unparsed" display="block" id="S3.E2.m1.3"><semantics id="S3.E2.m1.3a"><mrow id="S3.E2.m1.3.3"><mo id="S3.E2.m1.3.3.4">{</mo><mtable columnspacing="5pt" displaystyle="true" id="S3.E2.m1.3.3.3" rowspacing="0pt"><mtr id="S3.E2.m1.3.3.3a"><mtd class="ltx_align_left" columnalign="left" id="S3.E2.m1.3.3.3b"><mi id="S3.E2.m1.1.1.1.1.1.1">b</mi></mtd><mtd class="ltx_align_left" columnalign="left" id="S3.E2.m1.3.3.3c"><mrow id="S3.E2.m1.2.2.2.2.2.1"><mstyle displaystyle="false" id="S3.E2.m1.2.2.2.2.2.1.2"><mo id="S3.E2.m1.2.2.2.2.2.1.2a">∑</mo></mstyle><mrow id="S3.E2.m1.2.2.2.2.2.1.3"><mo id="S3.E2.m1.2.2.2.2.2.1.3.1">(</mo><msub id="S3.E2.m1.2.2.2.2.2.1.3.2"><mi id="S3.E2.m1.2.2.2.2.2.1.3.2.2">d</mi><mn id="S3.E2.m1.2.2.2.2.2.1.3.2.3">1</mn></msub><mo id="S3.E2.m1.2.2.2.2.2.1.3.3" lspace="0.222em" rspace="0.222em">⋅</mo><mtext id="S3.E2.m1.2.2.2.2.2.1.3.4">fluency </mtext><mo id="S3.E2.m1.2.2.2.2.2.1.3.5">+</mo><msub id="S3.E2.m1.2.2.2.2.2.1.3.6"><mi id="S3.E2.m1.2.2.2.2.2.1.3.6.2">d</mi><mn id="S3.E2.m1.2.2.2.2.2.1.3.6.3">2</mn></msub><mo id="S3.E2.m1.2.2.2.2.2.1.3.7" lspace="0.222em" rspace="0.222em">⋅</mo><mi id="S3.E2.m1.2.2.2.2.2.1.1">log</mi><mrow id="S3.E2.m1.2.2.2.2.2.1.3.8"><mo id="S3.E2.m1.2.2.2.2.2.1.3.8.1" stretchy="false">(</mo><mtext id="S3.E2.m1.2.2.2.2.2.1.3.8.2">accurate rate</mtext><mo id="S3.E2.m1.2.2.2.2.2.1.3.8.3">+</mo><mn id="S3.E2.m1.2.2.2.2.2.1.3.8.4">1</mn><mo id="S3.E2.m1.2.2.2.2.2.1.3.8.5" stretchy="false">)</mo></mrow><mo id="S3.E2.m1.2.2.2.2.2.1.3.9">+</mo></mrow></mrow></mtd></mtr><mtr id="S3.E2.m1.3.3.3d"><mtd id="S3.E2.m1.3.3.3e"></mtd><mtd class="ltx_align_left" columnalign="left" id="S3.E2.m1.3.3.3f"><mrow id="S3.E2.m1.3.3.3.3.1.1"><msub id="S3.E2.m1.3.3.3.3.1.1.3"><mi id="S3.E2.m1.3.3.3.3.1.1.3.2">d</mi><mn id="S3.E2.m1.3.3.3.3.1.1.3.3">3</mn></msub><mo id="S3.E2.m1.3.3.3.3.1.1.4" lspace="0.222em" rspace="0.222em">⋅</mo><mi id="S3.E2.m1.3.3.3.3.1.1.1">exp</mi><mrow id="S3.E2.m1.3.3.3.3.1.1.5"><mo id="S3.E2.m1.3.3.3.3.1.1.5.1" stretchy="false">(</mo><mtext id="S3.E2.m1.3.3.3.3.1.1.2">relevance </mtext><mo id="S3.E2.m1.3.3.3.3.1.1.5.2" stretchy="false">)</mo></mrow><mo id="S3.E2.m1.3.3.3.3.1.1.6">)</mo></mrow></mtd></mtr></mtable></mrow><annotation encoding="application/x-tex" id="S3.E2.m1.3b">\begin{cases}b&amp;\sum\left(d_{1}\cdot\text{fluency }+d_{2}\cdot\log(\text{%
accurate rate}+1)+\right.\\
&amp;\left.d_{3}\cdot\exp(\text{relevance })\right)\end{cases}</annotation><annotation encoding="application/x-llamapun" id="S3.E2.m1.3c">{ start_ROW start_CELL italic_b end_CELL start_CELL ∑ ( italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ⋅ fluency + italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ⋅ roman_log ( accurate rate + 1 ) + end_CELL end_ROW start_ROW start_CELL end_CELL start_CELL italic_d start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ⋅ roman_exp ( relevance ) ) end_CELL end_ROW</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.SS4.p4">
<p class="ltx_p" id="S3.SS4.p4.1">For the b formula, we rated the responses of the large language model from three aspects: fluency, accuracy rate, and relevance, and calculated the composite score. The weight coefficients for the different evaluation metrics, d1, d2, and d3, were set with a focus on solving the hallucination problem of the large model. We assigned relevance as the primary analysis metric, with weight parameters set to 0.3, 0.2, and 0.4, respectively. To ensure objectivity in scoring, we chose the fine-tuned Llama3-Chinese model<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">Wang2024</span>)</cite> based on Wang’s work to evaluate the data results of each model. By analyzing the fluency of the generated sentences and the relevance of the generated text to the corresponding knowledge source content, we obtained the scores for fluency and relevance. We used the BERTscore<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">Zhang2019</span>)</cite> evaluation tool developed by Zhang to score the generated text for the accuracy rate. By setting the prompt to control the scores within a range of 0 to 1, with 1 being the highest, we then applied the b formula to calculate the composite score for each model.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>Experiment</h2>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1. </span>Database Vectorization and Indexing Experiment</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">In constructing and retrieving the vector database, we utilized the widely used FAISS vector library and its associated algorithms (the rationale here may need further justification). For database vectorization, we compared mainstream methods TF-IDF and BERT. For indexing methods, we selected the most representative and characteristic methods: Flat, IVFFlat, NSGFlat, HNSWFlat, SQ, HNSWSQ, IVFSQ, and LSH (the dimension names used here and in Chapter 3 need to be consistent; if necessary, a brief explanation of these concepts should be included at an appropriate place in the text).</p>
</div>
<div class="ltx_para" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1">Since most of the indexing methods primarily support L2 (Euclidean distance), L1 (Manhattan distance), and Inner-Product (dot product) were only used as comparisons for HNSW in this experiment. Each of the two vectorization methods was tested with the 10 different indexing methods, using the standardized viewpoint dataset established in Section 3.1 for vectorization. We used the 180 prompts constructed following the randomness principle described in Section 3.2 as inputs. To ensure experimental generalization, each prompt randomly included 1 to 4 features, with an average of 3 features per prompt.</p>
</div>
<div class="ltx_para" id="S4.SS1.p3">
<p class="ltx_p" id="S4.SS1.p3.1">The following <span class="ltx_text ltx_font_bold" id="S4.SS1.p3.1.1">Algorithm 1</span> outlines a procedure for vectorizing text data (using either TF-IDF or BERT), defining distance metrics and index types, and then querying and saving the results as JSON files.</p>
</div>
<figure class="ltx_float ltx_float_algorithm ltx_framed ltx_framed_top" id="alg1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span class="ltx_text ltx_font_bold" id="alg1.2.1.1">Algorithm 1</span> </span> GenerateIndexResults</figcaption>
<div class="ltx_listing ltx_listing" id="alg1.3">
<div class="ltx_listingline" id="alg1.l0">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l0.1.1.1" style="font-size:80%;">0:</span></span>  <span class="ltx_text ltx_font_italic" id="alg1.l0.2">stop_words_file</span>, <span class="ltx_text ltx_font_italic" id="alg1.l0.3">attractions_csv_file</span>
</div>
<div class="ltx_listingline" id="alg1.l0a">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l0a.1.1.1" style="font-size:80%;">0:</span></span>  <span class="ltx_text ltx_font_italic" id="alg1.l0a.2">results_with_different_index_methods</span>
</div>
<div class="ltx_listingline" id="alg1.l1">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l1.1.1.1" style="font-size:80%;">1:</span></span>  <span class="ltx_text ltx_font_bold" id="alg1.l1.2">if</span> TF-IDF is chosen <span class="ltx_text ltx_font_bold" id="alg1.l1.3">then</span>
</div>
<div class="ltx_listingline" id="alg1.l2">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l2.1.1.1" style="font-size:80%;">2:</span></span>     vectorizer<math alttext="\leftarrow" class="ltx_Math" display="inline" id="alg1.l2.m1.1"><semantics id="alg1.l2.m1.1a"><mo id="alg1.l2.m1.1.1" stretchy="false" xref="alg1.l2.m1.1.1.cmml">←</mo><annotation-xml encoding="MathML-Content" id="alg1.l2.m1.1b"><ci id="alg1.l2.m1.1.1.cmml" xref="alg1.l2.m1.1.1">←</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l2.m1.1c">\leftarrow</annotation><annotation encoding="application/x-llamapun" id="alg1.l2.m1.1d">←</annotation></semantics></math><span class="ltx_text ltx_font_typewriter" id="alg1.l2.2">TfidfVectorizer(stop_words, ChineseTokenizer)</span>
</div>
<div class="ltx_listingline" id="alg1.l3">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l3.1.1.1" style="font-size:80%;">3:</span></span>     text_vectors <math alttext="\leftarrow" class="ltx_Math" display="inline" id="alg1.l3.m1.1"><semantics id="alg1.l3.m1.1a"><mo id="alg1.l3.m1.1.1" stretchy="false" xref="alg1.l3.m1.1.1.cmml">←</mo><annotation-xml encoding="MathML-Content" id="alg1.l3.m1.1b"><ci id="alg1.l3.m1.1.1.cmml" xref="alg1.l3.m1.1.1">←</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l3.m1.1c">\leftarrow</annotation><annotation encoding="application/x-llamapun" id="alg1.l3.m1.1d">←</annotation></semantics></math> vectorizer.fit_transform(texts).astype(float32)

</div>
<div class="ltx_listingline" id="alg1.l4">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l4.1.1.1" style="font-size:80%;">4:</span></span>     <math alttext="d\leftarrow" class="ltx_Math" display="inline" id="alg1.l4.m1.1"><semantics id="alg1.l4.m1.1a"><mrow id="alg1.l4.m1.1.1" xref="alg1.l4.m1.1.1.cmml"><mi id="alg1.l4.m1.1.1.2" xref="alg1.l4.m1.1.1.2.cmml">d</mi><mo id="alg1.l4.m1.1.1.1" stretchy="false" xref="alg1.l4.m1.1.1.1.cmml">←</mo><mi id="alg1.l4.m1.1.1.3" xref="alg1.l4.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.l4.m1.1b"><apply id="alg1.l4.m1.1.1.cmml" xref="alg1.l4.m1.1.1"><ci id="alg1.l4.m1.1.1.1.cmml" xref="alg1.l4.m1.1.1.1">←</ci><ci id="alg1.l4.m1.1.1.2.cmml" xref="alg1.l4.m1.1.1.2">𝑑</ci><csymbol cd="latexml" id="alg1.l4.m1.1.1.3.cmml" xref="alg1.l4.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l4.m1.1c">d\leftarrow</annotation><annotation encoding="application/x-llamapun" id="alg1.l4.m1.1d">italic_d ←</annotation></semantics></math> columns of text_vectors

</div>
<div class="ltx_listingline" id="alg1.l5">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l5.1.1.1" style="font-size:80%;">5:</span></span>  <span class="ltx_text ltx_font_bold" id="alg1.l5.2">else</span> <span class="ltx_text ltx_font_bold" id="alg1.l5.3">if</span> BERT is chosen <span class="ltx_text ltx_font_bold" id="alg1.l5.4">then</span>
</div>
<div class="ltx_listingline" id="alg1.l6">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l6.1.1.1" style="font-size:80%;">6:</span></span>     model, tokenizer <math alttext="\leftarrow" class="ltx_Math" display="inline" id="alg1.l6.m1.1"><semantics id="alg1.l6.m1.1a"><mo id="alg1.l6.m1.1.1" stretchy="false" xref="alg1.l6.m1.1.1.cmml">←</mo><annotation-xml encoding="MathML-Content" id="alg1.l6.m1.1b"><ci id="alg1.l6.m1.1.1.cmml" xref="alg1.l6.m1.1.1">←</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l6.m1.1c">\leftarrow</annotation><annotation encoding="application/x-llamapun" id="alg1.l6.m1.1d">←</annotation></semantics></math> <span class="ltx_text ltx_font_typewriter" id="alg1.l6.2">BERT(’bert-base-chinese’)</span>
</div>
<div class="ltx_listingline" id="alg1.l7">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l7.1.1.1" style="font-size:80%;">7:</span></span>     text_vectors <math alttext="\leftarrow" class="ltx_Math" display="inline" id="alg1.l7.m1.1"><semantics id="alg1.l7.m1.1a"><mo id="alg1.l7.m1.1.1" stretchy="false" xref="alg1.l7.m1.1.1.cmml">←</mo><annotation-xml encoding="MathML-Content" id="alg1.l7.m1.1b"><ci id="alg1.l7.m1.1.1.cmml" xref="alg1.l7.m1.1.1">←</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l7.m1.1c">\leftarrow</annotation><annotation encoding="application/x-llamapun" id="alg1.l7.m1.1d">←</annotation></semantics></math> <span class="ltx_text ltx_font_typewriter" id="alg1.l7.2">BERT_encode(texts)</span>.astype(float32)

</div>
<div class="ltx_listingline" id="alg1.l8">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l8.1.1.1" style="font-size:80%;">8:</span></span>     <math alttext="d\leftarrow" class="ltx_Math" display="inline" id="alg1.l8.m1.1"><semantics id="alg1.l8.m1.1a"><mrow id="alg1.l8.m1.1.1" xref="alg1.l8.m1.1.1.cmml"><mi id="alg1.l8.m1.1.1.2" xref="alg1.l8.m1.1.1.2.cmml">d</mi><mo id="alg1.l8.m1.1.1.1" stretchy="false" xref="alg1.l8.m1.1.1.1.cmml">←</mo><mi id="alg1.l8.m1.1.1.3" xref="alg1.l8.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.l8.m1.1b"><apply id="alg1.l8.m1.1.1.cmml" xref="alg1.l8.m1.1.1"><ci id="alg1.l8.m1.1.1.1.cmml" xref="alg1.l8.m1.1.1.1">←</ci><ci id="alg1.l8.m1.1.1.2.cmml" xref="alg1.l8.m1.1.1.2">𝑑</ci><csymbol cd="latexml" id="alg1.l8.m1.1.1.3.cmml" xref="alg1.l8.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l8.m1.1c">d\leftarrow</annotation><annotation encoding="application/x-llamapun" id="alg1.l8.m1.1d">italic_d ←</annotation></semantics></math> size of BERT embeddings

</div>
<div class="ltx_listingline" id="alg1.l9">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l9.1.1.1" style="font-size:80%;">9:</span></span>  <span class="ltx_text ltx_font_bold" id="alg1.l9.2">end</span> <span class="ltx_text ltx_font_bold" id="alg1.l9.3">if</span>
</div>
<div class="ltx_listingline" id="alg1.l10">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l10.1.1.1" style="font-size:80%;">10:</span></span>  distance_metrics<math alttext="\leftarrow" class="ltx_Math" display="inline" id="alg1.l10.m1.1"><semantics id="alg1.l10.m1.1a"><mo id="alg1.l10.m1.1.1" stretchy="false" xref="alg1.l10.m1.1.1.cmml">←</mo><annotation-xml encoding="MathML-Content" id="alg1.l10.m1.1b"><ci id="alg1.l10.m1.1.1.cmml" xref="alg1.l10.m1.1.1">←</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l10.m1.1c">\leftarrow</annotation><annotation encoding="application/x-llamapun" id="alg1.l10.m1.1d">←</annotation></semantics></math>{ ’L2’:<span class="ltx_text ltx_font_typewriter" id="alg1.l10.2">faiss.METRIC_L2</span>,’L1’:<span class="ltx_text ltx_font_typewriter" id="alg1.l10.3">faiss.METRIC_L1</span>, ’Inner Product’:<span class="ltx_text ltx_font_typewriter" id="alg1.l10.4">faiss.METRIC_INNER_PRODUCT</span>}

</div>
<div class="ltx_listingline" id="alg1.l11">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l11.1.1.1" style="font-size:80%;">11:</span></span>  index_types <math alttext="\leftarrow" class="ltx_Math" display="inline" id="alg1.l11.m1.1"><semantics id="alg1.l11.m1.1a"><mo id="alg1.l11.m1.1.1" stretchy="false" xref="alg1.l11.m1.1.1.cmml">←</mo><annotation-xml encoding="MathML-Content" id="alg1.l11.m1.1b"><ci id="alg1.l11.m1.1.1.cmml" xref="alg1.l11.m1.1.1">←</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l11.m1.1c">\leftarrow</annotation><annotation encoding="application/x-llamapun" id="alg1.l11.m1.1d">←</annotation></semantics></math> {}

</div>
<div class="ltx_listingline" id="alg1.l12">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l12.1.1.1" style="font-size:80%;">12:</span></span>  <span class="ltx_text ltx_font_bold" id="alg1.l12.2">Procedure</span> <span class="ltx_text ltx_font_typewriter" id="alg1.l12.3">QueryAndSaveAllAsJSON(index, method_name, query_texts, output_filename)</span>
</div>
<div class="ltx_listingline" id="alg1.l13">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l13.1.1.1" style="font-size:80%;">13:</span></span>  all_results <math alttext="\leftarrow" class="ltx_Math" display="inline" id="alg1.l13.m1.1"><semantics id="alg1.l13.m1.1a"><mo id="alg1.l13.m1.1.1" stretchy="false" xref="alg1.l13.m1.1.1.cmml">←</mo><annotation-xml encoding="MathML-Content" id="alg1.l13.m1.1b"><ci id="alg1.l13.m1.1.1.cmml" xref="alg1.l13.m1.1.1">←</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l13.m1.1c">\leftarrow</annotation><annotation encoding="application/x-llamapun" id="alg1.l13.m1.1d">←</annotation></semantics></math> {}

</div>
<div class="ltx_listingline" id="alg1.l14">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l14.1.1.1" style="font-size:80%;">14:</span></span>  <span class="ltx_text ltx_font_bold" id="alg1.l14.2">for</span> query_text <span class="ltx_text ltx_font_bold" id="alg1.l14.3">in</span> query_texts <span class="ltx_text ltx_font_bold" id="alg1.l14.4">do</span>
</div>
<div class="ltx_listingline" id="alg1.l15">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l15.1.1.1" style="font-size:80%;">15:</span></span>     query_vector<math alttext="\leftarrow" class="ltx_Math" display="inline" id="alg1.l15.m1.1"><semantics id="alg1.l15.m1.1a"><mo id="alg1.l15.m1.1.1" stretchy="false" xref="alg1.l15.m1.1.1.cmml">←</mo><annotation-xml encoding="MathML-Content" id="alg1.l15.m1.1b"><ci id="alg1.l15.m1.1.1.cmml" xref="alg1.l15.m1.1.1">←</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l15.m1.1c">\leftarrow</annotation><annotation encoding="application/x-llamapun" id="alg1.l15.m1.1d">←</annotation></semantics></math>
vectorizer.transform([query_text]).astype(float32)

</div>
<div class="ltx_listingline" id="alg1.l16">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l16.1.1.1" style="font-size:80%;">16:</span></span>     <math alttext="k\leftarrow 3" class="ltx_Math" display="inline" id="alg1.l16.m1.1"><semantics id="alg1.l16.m1.1a"><mrow id="alg1.l16.m1.1.1" xref="alg1.l16.m1.1.1.cmml"><mi id="alg1.l16.m1.1.1.2" xref="alg1.l16.m1.1.1.2.cmml">k</mi><mo id="alg1.l16.m1.1.1.1" stretchy="false" xref="alg1.l16.m1.1.1.1.cmml">←</mo><mn id="alg1.l16.m1.1.1.3" xref="alg1.l16.m1.1.1.3.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="alg1.l16.m1.1b"><apply id="alg1.l16.m1.1.1.cmml" xref="alg1.l16.m1.1.1"><ci id="alg1.l16.m1.1.1.1.cmml" xref="alg1.l16.m1.1.1.1">←</ci><ci id="alg1.l16.m1.1.1.2.cmml" xref="alg1.l16.m1.1.1.2">𝑘</ci><cn id="alg1.l16.m1.1.1.3.cmml" type="integer" xref="alg1.l16.m1.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l16.m1.1c">k\leftarrow 3</annotation><annotation encoding="application/x-llamapun" id="alg1.l16.m1.1d">italic_k ← 3</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg1.l17">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l17.1.1.1" style="font-size:80%;">17:</span></span>     distances, indices <math alttext="\leftarrow" class="ltx_Math" display="inline" id="alg1.l17.m1.1"><semantics id="alg1.l17.m1.1a"><mo id="alg1.l17.m1.1.1" stretchy="false" xref="alg1.l17.m1.1.1.cmml">←</mo><annotation-xml encoding="MathML-Content" id="alg1.l17.m1.1b"><ci id="alg1.l17.m1.1.1.cmml" xref="alg1.l17.m1.1.1">←</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l17.m1.1c">\leftarrow</annotation><annotation encoding="application/x-llamapun" id="alg1.l17.m1.1d">←</annotation></semantics></math> index.search(query_vector, <math alttext="k" class="ltx_Math" display="inline" id="alg1.l17.m2.1"><semantics id="alg1.l17.m2.1a"><mi id="alg1.l17.m2.1.1" xref="alg1.l17.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="alg1.l17.m2.1b"><ci id="alg1.l17.m2.1.1.cmml" xref="alg1.l17.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l17.m2.1c">k</annotation><annotation encoding="application/x-llamapun" id="alg1.l17.m2.1d">italic_k</annotation></semantics></math>)

</div>
<div class="ltx_listingline" id="alg1.l18">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l18.1.1.1" style="font-size:80%;">18:</span></span>     <span class="ltx_text ltx_font_bold" id="alg1.l18.2">for</span> <math alttext="i\leftarrow 0" class="ltx_Math" display="inline" id="alg1.l18.m1.1"><semantics id="alg1.l18.m1.1a"><mrow id="alg1.l18.m1.1.1" xref="alg1.l18.m1.1.1.cmml"><mi id="alg1.l18.m1.1.1.2" xref="alg1.l18.m1.1.1.2.cmml">i</mi><mo id="alg1.l18.m1.1.1.1" stretchy="false" xref="alg1.l18.m1.1.1.1.cmml">←</mo><mn id="alg1.l18.m1.1.1.3" xref="alg1.l18.m1.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="alg1.l18.m1.1b"><apply id="alg1.l18.m1.1.1.cmml" xref="alg1.l18.m1.1.1"><ci id="alg1.l18.m1.1.1.1.cmml" xref="alg1.l18.m1.1.1.1">←</ci><ci id="alg1.l18.m1.1.1.2.cmml" xref="alg1.l18.m1.1.1.2">𝑖</ci><cn id="alg1.l18.m1.1.1.3.cmml" type="integer" xref="alg1.l18.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l18.m1.1c">i\leftarrow 0</annotation><annotation encoding="application/x-llamapun" id="alg1.l18.m1.1d">italic_i ← 0</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="alg1.l18.3">to</span> <math alttext="k-1" class="ltx_Math" display="inline" id="alg1.l18.m2.1"><semantics id="alg1.l18.m2.1a"><mrow id="alg1.l18.m2.1.1" xref="alg1.l18.m2.1.1.cmml"><mi id="alg1.l18.m2.1.1.2" xref="alg1.l18.m2.1.1.2.cmml">k</mi><mo id="alg1.l18.m2.1.1.1" xref="alg1.l18.m2.1.1.1.cmml">−</mo><mn id="alg1.l18.m2.1.1.3" xref="alg1.l18.m2.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="alg1.l18.m2.1b"><apply id="alg1.l18.m2.1.1.cmml" xref="alg1.l18.m2.1.1"><minus id="alg1.l18.m2.1.1.1.cmml" xref="alg1.l18.m2.1.1.1"></minus><ci id="alg1.l18.m2.1.1.2.cmml" xref="alg1.l18.m2.1.1.2">𝑘</ci><cn id="alg1.l18.m2.1.1.3.cmml" type="integer" xref="alg1.l18.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l18.m2.1c">k-1</annotation><annotation encoding="application/x-llamapun" id="alg1.l18.m2.1d">italic_k - 1</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="alg1.l18.4">do</span>
</div>
<div class="ltx_listingline" id="alg1.l19">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l19.1.1.1" style="font-size:80%;">19:</span></span>        results_for_query.append({”description”: data.iloc[indices[0][i]][’description’] })

</div>
<div class="ltx_listingline" id="alg1.l20">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l20.1.1.1" style="font-size:80%;">20:</span></span>     <span class="ltx_text ltx_font_bold" id="alg1.l20.2">end</span> <span class="ltx_text ltx_font_bold" id="alg1.l20.3">for</span>
</div>
<div class="ltx_listingline" id="alg1.l21">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l21.1.1.1" style="font-size:80%;">21:</span></span>     all_results[query_text] <math alttext="\leftarrow" class="ltx_Math" display="inline" id="alg1.l21.m1.1"><semantics id="alg1.l21.m1.1a"><mo id="alg1.l21.m1.1.1" stretchy="false" xref="alg1.l21.m1.1.1.cmml">←</mo><annotation-xml encoding="MathML-Content" id="alg1.l21.m1.1b"><ci id="alg1.l21.m1.1.1.cmml" xref="alg1.l21.m1.1.1">←</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l21.m1.1c">\leftarrow</annotation><annotation encoding="application/x-llamapun" id="alg1.l21.m1.1d">←</annotation></semantics></math> { ”query”: query_text, ”results”: results_for_query }

</div>
<div class="ltx_listingline" id="alg1.l22">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l22.1.1.1" style="font-size:80%;">22:</span></span>  <span class="ltx_text ltx_font_bold" id="alg1.l22.2">end</span> <span class="ltx_text ltx_font_bold" id="alg1.l22.3">for</span>
</div>
<div class="ltx_listingline" id="alg1.l23">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l23.1.1.1" style="font-size:80%;">23:</span></span>  <span class="ltx_text ltx_font_bold" id="alg1.l23.2">return</span>  results_with_different_index_methods

</div>
</div>
</figure>
<figure class="ltx_float ltx_float_algorithm ltx_framed ltx_framed_top" id="alg2">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span class="ltx_text ltx_font_bold" id="alg2.2.1.1">Algorithm 2</span> </span> SpaCy_avg_hit_count</figcaption>
<div class="ltx_listing ltx_listing" id="alg2.3">
<div class="ltx_listingline" id="alg2.l0">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg2.l0.1.1.1" style="font-size:80%;">0:</span></span>  <span class="ltx_text ltx_font_italic" id="alg2.l0.2">json_files_directory</span>,
<span class="ltx_text ltx_font_italic" id="alg2.l0.3">json_results_with_different_index_methods</span>
</div>
<div class="ltx_listingline" id="alg2.l0a">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg2.l0a.1.1.1" style="font-size:80%;">0:</span></span>  <span class="ltx_text ltx_font_italic" id="alg2.l0a.2">average_scores</span>
</div>
<div class="ltx_listingline" id="alg2.l1">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg2.l1.1.1.1" style="font-size:80%;">1:</span></span>  <span class="ltx_text ltx_font_bold" id="alg2.l1.2">Function</span> <span class="ltx_text ltx_font_typewriter" id="alg2.l1.3">AssessAllQueries(json_path)</span>
</div>
<div class="ltx_listingline" id="alg2.l2">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg2.l2.1.1.1" style="font-size:80%;">2:</span></span>  queries_results <math alttext="\leftarrow" class="ltx_Math" display="inline" id="alg2.l2.m1.1"><semantics id="alg2.l2.m1.1a"><mo id="alg2.l2.m1.1.1" stretchy="false" xref="alg2.l2.m1.1.1.cmml">←</mo><annotation-xml encoding="MathML-Content" id="alg2.l2.m1.1b"><ci id="alg2.l2.m1.1.1.cmml" xref="alg2.l2.m1.1.1">←</ci></annotation-xml><annotation encoding="application/x-tex" id="alg2.l2.m1.1c">\leftarrow</annotation><annotation encoding="application/x-llamapun" id="alg2.l2.m1.1d">←</annotation></semantics></math> LoadQueriesResults(json_path)

</div>
<div class="ltx_listingline" id="alg2.l3">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg2.l3.1.1.1" style="font-size:80%;">3:</span></span>  total_score, total_results_count <math alttext="\leftarrow" class="ltx_Math" display="inline" id="alg2.l3.m1.1"><semantics id="alg2.l3.m1.1a"><mo id="alg2.l3.m1.1.1" stretchy="false" xref="alg2.l3.m1.1.1.cmml">←</mo><annotation-xml encoding="MathML-Content" id="alg2.l3.m1.1b"><ci id="alg2.l3.m1.1.1.cmml" xref="alg2.l3.m1.1.1">←</ci></annotation-xml><annotation encoding="application/x-tex" id="alg2.l3.m1.1c">\leftarrow</annotation><annotation encoding="application/x-llamapun" id="alg2.l3.m1.1d">←</annotation></semantics></math> 0, 0

</div>
<div class="ltx_listingline" id="alg2.l4">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg2.l4.1.1.1" style="font-size:80%;">4:</span></span>  <span class="ltx_text ltx_font_bold" id="alg2.l4.2">for</span> query_data <span class="ltx_text ltx_font_bold" id="alg2.l4.3">in</span> queries_results.values() <span class="ltx_text ltx_font_bold" id="alg2.l4.4">do</span>
</div>
<div class="ltx_listingline" id="alg2.l5">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg2.l5.1.1.1" style="font-size:80%;">5:</span></span>     query <math alttext="\leftarrow" class="ltx_Math" display="inline" id="alg2.l5.m1.1"><semantics id="alg2.l5.m1.1a"><mo id="alg2.l5.m1.1.1" stretchy="false" xref="alg2.l5.m1.1.1.cmml">←</mo><annotation-xml encoding="MathML-Content" id="alg2.l5.m1.1b"><ci id="alg2.l5.m1.1.1.cmml" xref="alg2.l5.m1.1.1">←</ci></annotation-xml><annotation encoding="application/x-tex" id="alg2.l5.m1.1c">\leftarrow</annotation><annotation encoding="application/x-llamapun" id="alg2.l5.m1.1d">←</annotation></semantics></math> query_data[”query”]

</div>
<div class="ltx_listingline" id="alg2.l6">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg2.l6.1.1.1" style="font-size:80%;">6:</span></span>     results <math alttext="\leftarrow" class="ltx_Math" display="inline" id="alg2.l6.m1.1"><semantics id="alg2.l6.m1.1a"><mo id="alg2.l6.m1.1.1" stretchy="false" xref="alg2.l6.m1.1.1.cmml">←</mo><annotation-xml encoding="MathML-Content" id="alg2.l6.m1.1b"><ci id="alg2.l6.m1.1.1.cmml" xref="alg2.l6.m1.1.1">←</ci></annotation-xml><annotation encoding="application/x-tex" id="alg2.l6.m1.1c">\leftarrow</annotation><annotation encoding="application/x-llamapun" id="alg2.l6.m1.1d">←</annotation></semantics></math> query_data[”results”]

</div>
<div class="ltx_listingline" id="alg2.l7">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg2.l7.1.1.1" style="font-size:80%;">7:</span></span>     query_keywords <math alttext="\leftarrow" class="ltx_Math" display="inline" id="alg2.l7.m1.1"><semantics id="alg2.l7.m1.1a"><mo id="alg2.l7.m1.1.1" stretchy="false" xref="alg2.l7.m1.1.1.cmml">←</mo><annotation-xml encoding="MathML-Content" id="alg2.l7.m1.1b"><ci id="alg2.l7.m1.1.1.cmml" xref="alg2.l7.m1.1.1">←</ci></annotation-xml><annotation encoding="application/x-tex" id="alg2.l7.m1.1c">\leftarrow</annotation><annotation encoding="application/x-llamapun" id="alg2.l7.m1.1d">←</annotation></semantics></math> ExtractKeywords(query)

</div>
<div class="ltx_listingline" id="alg2.l8">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg2.l8.1.1.1" style="font-size:80%;">8:</span></span>     <span class="ltx_text ltx_font_bold" id="alg2.l8.2">for</span> result <span class="ltx_text ltx_font_bold" id="alg2.l8.3">in</span> results <span class="ltx_text ltx_font_bold" id="alg2.l8.4">do</span>
</div>
<div class="ltx_listingline" id="alg2.l9">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg2.l9.1.1.1" style="font-size:80%;">9:</span></span>        result_text <math alttext="\leftarrow" class="ltx_Math" display="inline" id="alg2.l9.m1.1"><semantics id="alg2.l9.m1.1a"><mo id="alg2.l9.m1.1.1" stretchy="false" xref="alg2.l9.m1.1.1.cmml">←</mo><annotation-xml encoding="MathML-Content" id="alg2.l9.m1.1b"><ci id="alg2.l9.m1.1.1.cmml" xref="alg2.l9.m1.1.1">←</ci></annotation-xml><annotation encoding="application/x-tex" id="alg2.l9.m1.1c">\leftarrow</annotation><annotation encoding="application/x-llamapun" id="alg2.l9.m1.1d">←</annotation></semantics></math> Concatenate(result.get(”description”, ””), result.get(”name”, ””))

</div>
<div class="ltx_listingline" id="alg2.l10">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg2.l10.1.1.1" style="font-size:80%;">10:</span></span>        result_keywords <math alttext="\leftarrow" class="ltx_Math" display="inline" id="alg2.l10.m1.1"><semantics id="alg2.l10.m1.1a"><mo id="alg2.l10.m1.1.1" stretchy="false" xref="alg2.l10.m1.1.1.cmml">←</mo><annotation-xml encoding="MathML-Content" id="alg2.l10.m1.1b"><ci id="alg2.l10.m1.1.1.cmml" xref="alg2.l10.m1.1.1">←</ci></annotation-xml><annotation encoding="application/x-tex" id="alg2.l10.m1.1c">\leftarrow</annotation><annotation encoding="application/x-llamapun" id="alg2.l10.m1.1d">←</annotation></semantics></math> ExtractKeywords(result_text)

</div>
<div class="ltx_listingline" id="alg2.l11">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg2.l11.1.1.1" style="font-size:80%;">11:</span></span>        matched_keywords <math alttext="\leftarrow" class="ltx_Math" display="inline" id="alg2.l11.m1.1"><semantics id="alg2.l11.m1.1a"><mo id="alg2.l11.m1.1.1" stretchy="false" xref="alg2.l11.m1.1.1.cmml">←</mo><annotation-xml encoding="MathML-Content" id="alg2.l11.m1.1b"><ci id="alg2.l11.m1.1.1.cmml" xref="alg2.l11.m1.1.1">←</ci></annotation-xml><annotation encoding="application/x-tex" id="alg2.l11.m1.1c">\leftarrow</annotation><annotation encoding="application/x-llamapun" id="alg2.l11.m1.1d">←</annotation></semantics></math> Intersection(query_keywords, result_keywords)

</div>
<div class="ltx_listingline" id="alg2.l12">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg2.l12.1.1.1" style="font-size:80%;">12:</span></span>        total_score <math alttext="\leftarrow" class="ltx_Math" display="inline" id="alg2.l12.m1.1"><semantics id="alg2.l12.m1.1a"><mo id="alg2.l12.m1.1.1" stretchy="false" xref="alg2.l12.m1.1.1.cmml">←</mo><annotation-xml encoding="MathML-Content" id="alg2.l12.m1.1b"><ci id="alg2.l12.m1.1.1.cmml" xref="alg2.l12.m1.1.1">←</ci></annotation-xml><annotation encoding="application/x-tex" id="alg2.l12.m1.1c">\leftarrow</annotation><annotation encoding="application/x-llamapun" id="alg2.l12.m1.1d">←</annotation></semantics></math> total_score + Size(matched_keywords)

</div>
<div class="ltx_listingline" id="alg2.l13">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg2.l13.1.1.1" style="font-size:80%;">13:</span></span>        total_results_count <math alttext="\leftarrow" class="ltx_Math" display="inline" id="alg2.l13.m1.1"><semantics id="alg2.l13.m1.1a"><mo id="alg2.l13.m1.1.1" stretchy="false" xref="alg2.l13.m1.1.1.cmml">←</mo><annotation-xml encoding="MathML-Content" id="alg2.l13.m1.1b"><ci id="alg2.l13.m1.1.1.cmml" xref="alg2.l13.m1.1.1">←</ci></annotation-xml><annotation encoding="application/x-tex" id="alg2.l13.m1.1c">\leftarrow</annotation><annotation encoding="application/x-llamapun" id="alg2.l13.m1.1d">←</annotation></semantics></math> total_results_count + 1

</div>
<div class="ltx_listingline" id="alg2.l14">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg2.l14.1.1.1" style="font-size:80%;">14:</span></span>     <span class="ltx_text ltx_font_bold" id="alg2.l14.2">end</span> <span class="ltx_text ltx_font_bold" id="alg2.l14.3">for</span>
</div>
<div class="ltx_listingline" id="alg2.l15">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg2.l15.1.1.1" style="font-size:80%;">15:</span></span>  <span class="ltx_text ltx_font_bold" id="alg2.l15.2">end</span> <span class="ltx_text ltx_font_bold" id="alg2.l15.3">for</span>
</div>
<div class="ltx_listingline" id="alg2.l16">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg2.l16.1.1.1" style="font-size:80%;">16:</span></span>  <span class="ltx_text ltx_font_bold" id="alg2.l16.2">if</span> total_results_count ¿ 0 <span class="ltx_text ltx_font_bold" id="alg2.l16.3">then</span>
</div>
<div class="ltx_listingline" id="alg2.l17">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg2.l17.1.1.1" style="font-size:80%;">17:</span></span>     average_score <math alttext="\leftarrow" class="ltx_Math" display="inline" id="alg2.l17.m1.1"><semantics id="alg2.l17.m1.1a"><mo id="alg2.l17.m1.1.1" stretchy="false" xref="alg2.l17.m1.1.1.cmml">←</mo><annotation-xml encoding="MathML-Content" id="alg2.l17.m1.1b"><ci id="alg2.l17.m1.1.1.cmml" xref="alg2.l17.m1.1.1">←</ci></annotation-xml><annotation encoding="application/x-tex" id="alg2.l17.m1.1c">\leftarrow</annotation><annotation encoding="application/x-llamapun" id="alg2.l17.m1.1d">←</annotation></semantics></math> total_score / total_results_count

</div>
<div class="ltx_listingline" id="alg2.l18">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg2.l18.1.1.1" style="font-size:80%;">18:</span></span>  <span class="ltx_text ltx_font_bold" id="alg2.l18.2">else</span>
</div>
<div class="ltx_listingline" id="alg2.l19">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg2.l19.1.1.1" style="font-size:80%;">19:</span></span>     average_score <math alttext="\leftarrow" class="ltx_Math" display="inline" id="alg2.l19.m1.1"><semantics id="alg2.l19.m1.1a"><mo id="alg2.l19.m1.1.1" stretchy="false" xref="alg2.l19.m1.1.1.cmml">←</mo><annotation-xml encoding="MathML-Content" id="alg2.l19.m1.1b"><ci id="alg2.l19.m1.1.1.cmml" xref="alg2.l19.m1.1.1">←</ci></annotation-xml><annotation encoding="application/x-tex" id="alg2.l19.m1.1c">\leftarrow</annotation><annotation encoding="application/x-llamapun" id="alg2.l19.m1.1d">←</annotation></semantics></math> 0

</div>
<div class="ltx_listingline" id="alg2.l20">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg2.l20.1.1.1" style="font-size:80%;">20:</span></span>  <span class="ltx_text ltx_font_bold" id="alg2.l20.2">end</span> <span class="ltx_text ltx_font_bold" id="alg2.l20.3">if</span>
</div>
<div class="ltx_listingline" id="alg2.l21">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg2.l21.1.1.1" style="font-size:80%;">21:</span></span>  <span class="ltx_text ltx_font_bold" id="alg2.l21.2">return</span>  average_score

</div>
</div>
</figure>
<div class="ltx_para" id="S4.SS1.p4">
<p class="ltx_p" id="S4.SS1.p4.1">This formula represents the percentage improvement of TF-IDF relative to Bert.</p>
</div>
<div class="ltx_para" id="S4.SS1.p5">
<p class="ltx_p" id="S4.SS1.p5.1">Following the methodology outlined in Section 3.2, we retrieved the three closest results for each prompt and confirmed the number of keyword matches using the Chinese model loaded in SpaCy as <span class="ltx_text ltx_font_bold" id="S4.SS1.p5.1.1">Algorithm 2</span>. The final results are as follows Table 1.</p>
</div>
<div class="ltx_para" id="S4.SS1.p6">
<p class="ltx_p" id="S4.SS1.p6.1">Calculation of “avg gap”
The formula for calculating the “avg gap” is as follows:</p>
<table class="ltx_equation ltx_eqn_table" id="S4.Ex1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\text{avg gap}=\frac{\text{TF-IDF}-\text{Bert}}{\text{Bert}}" class="ltx_Math" display="block" id="S4.Ex1.m1.1"><semantics id="S4.Ex1.m1.1a"><mrow id="S4.Ex1.m1.1.1" xref="S4.Ex1.m1.1.1.cmml"><mtext id="S4.Ex1.m1.1.1.2" xref="S4.Ex1.m1.1.1.2a.cmml">avg gap</mtext><mo id="S4.Ex1.m1.1.1.1" xref="S4.Ex1.m1.1.1.1.cmml">=</mo><mfrac id="S4.Ex1.m1.1.1.3" xref="S4.Ex1.m1.1.1.3.cmml"><mrow id="S4.Ex1.m1.1.1.3.2" xref="S4.Ex1.m1.1.1.3.2.cmml"><mtext id="S4.Ex1.m1.1.1.3.2.2" xref="S4.Ex1.m1.1.1.3.2.2a.cmml">TF-IDF</mtext><mo id="S4.Ex1.m1.1.1.3.2.1" xref="S4.Ex1.m1.1.1.3.2.1.cmml">−</mo><mtext id="S4.Ex1.m1.1.1.3.2.3" xref="S4.Ex1.m1.1.1.3.2.3a.cmml">Bert</mtext></mrow><mtext id="S4.Ex1.m1.1.1.3.3" xref="S4.Ex1.m1.1.1.3.3a.cmml">Bert</mtext></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S4.Ex1.m1.1b"><apply id="S4.Ex1.m1.1.1.cmml" xref="S4.Ex1.m1.1.1"><eq id="S4.Ex1.m1.1.1.1.cmml" xref="S4.Ex1.m1.1.1.1"></eq><ci id="S4.Ex1.m1.1.1.2a.cmml" xref="S4.Ex1.m1.1.1.2"><mtext id="S4.Ex1.m1.1.1.2.cmml" xref="S4.Ex1.m1.1.1.2">avg gap</mtext></ci><apply id="S4.Ex1.m1.1.1.3.cmml" xref="S4.Ex1.m1.1.1.3"><divide id="S4.Ex1.m1.1.1.3.1.cmml" xref="S4.Ex1.m1.1.1.3"></divide><apply id="S4.Ex1.m1.1.1.3.2.cmml" xref="S4.Ex1.m1.1.1.3.2"><minus id="S4.Ex1.m1.1.1.3.2.1.cmml" xref="S4.Ex1.m1.1.1.3.2.1"></minus><ci id="S4.Ex1.m1.1.1.3.2.2a.cmml" xref="S4.Ex1.m1.1.1.3.2.2"><mtext id="S4.Ex1.m1.1.1.3.2.2.cmml" xref="S4.Ex1.m1.1.1.3.2.2">TF-IDF</mtext></ci><ci id="S4.Ex1.m1.1.1.3.2.3a.cmml" xref="S4.Ex1.m1.1.1.3.2.3"><mtext id="S4.Ex1.m1.1.1.3.2.3.cmml" xref="S4.Ex1.m1.1.1.3.2.3">Bert</mtext></ci></apply><ci id="S4.Ex1.m1.1.1.3.3a.cmml" xref="S4.Ex1.m1.1.1.3.3"><mtext id="S4.Ex1.m1.1.1.3.3.cmml" xref="S4.Ex1.m1.1.1.3.3">Bert</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.Ex1.m1.1c">\text{avg gap}=\frac{\text{TF-IDF}-\text{Bert}}{\text{Bert}}</annotation><annotation encoding="application/x-llamapun" id="S4.Ex1.m1.1d">avg gap = divide start_ARG TF-IDF - Bert end_ARG start_ARG Bert end_ARG</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S4.SS1.p7">
<p class="ltx_p" id="S4.SS1.p7.1">As shown in <span class="ltx_text ltx_font_bold" id="S4.SS1.p7.1.1">Table 1</span>, in terms of keyword hit rate, the TF-IDF vectorization method consistently outperformed the BERT vectorization method, with the maximum difference observed in the IVFSQ indexing method. Under the L2 space calculation method, the TF-IDF algorithm’s hit rate was 60.1770% higher than that of the BERT algorithm. The TF-IDF algorithm also had an average hit rate across various indexing methods that was 52.1495% higher than that of BERT. Additionally, due to differences in the principles of the two vectorization methods, the TF-IDF algorithm reduced vectorization time and performance requirements by approximately 60% and 47%, respectively (rough estimates).</p>
</div>
<div class="ltx_para" id="S4.SS1.p8">
<p class="ltx_p" id="S4.SS1.p8.1">Among the TF-IDF vectorization methods, the HNSWFlat method with inner product calculation showed the most outstanding performance, with an average keyword hit rate of 1.9556. However, because the Euclidean distance calculation method is more universal and the difference with the inner product calculation method is less than 1%, within the experimental error range, considering both universality and performance, we believe that vectorizing the database using the TF-IDF method, constructing the index using the HNSWFlat method, and using L2 Euclidean distance calculation for vector distance is most suitable for this study on Tibetan cultural tourism.</p>
</div>
<figure class="ltx_table" id="S4.T1">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t" id="S4.T1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.1.1.1">index</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="2" id="S4.T1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.1.2.1">TF-IDF</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="2" id="S4.T1.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.1.3.1">Bert</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.1.4.1">avg gap</span></th>
</tr>
<tr class="ltx_tr" id="S4.T1.1.2.2">
<th class="ltx_td ltx_th ltx_th_row" id="S4.T1.1.2.2.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T1.1.2.2.2"><span class="ltx_text ltx_font_bold" id="S4.T1.1.2.2.2.1">avg hit count</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T1.1.2.2.3"><span class="ltx_text ltx_font_bold" id="S4.T1.1.2.2.3.1">avg hit rate</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T1.1.2.2.4"><span class="ltx_text ltx_font_bold" id="S4.T1.1.2.2.4.1">avg hit count</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T1.1.2.2.5"><span class="ltx_text ltx_font_bold" id="S4.T1.1.2.2.5.1">avg hit rate</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T1.1.2.2.6"><span class="ltx_text ltx_font_bold" id="S4.T1.1.2.2.6.1">(bert base)</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T1.1.3.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T1.1.3.1.1">Flat</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.3.1.2">1.9481</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.3.1.3">64.9383%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.3.1.4">1.2981</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.3.1.5">43.2716%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.3.1.6">50.0713%</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.4.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.1.4.2.1">HNSW_L2</th>
<td class="ltx_td ltx_align_center" id="S4.T1.1.4.2.2"><span class="ltx_text ltx_font_bold" id="S4.T1.1.4.2.2.1">1.9519</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.4.2.3"><span class="ltx_text ltx_font_bold" id="S4.T1.1.4.2.3.1">65.0617%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.4.2.4">1.2815</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.4.2.5">42.7160%</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.4.2.6">52.3121%</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.5.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.1.5.3.1">HNSW_L1</th>
<td class="ltx_td ltx_align_center" id="S4.T1.1.5.3.2">1.9463</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.5.3.3">64.8765%</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.5.3.4">1.2796</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.5.3.5">42.6543%</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.5.3.6">52.0984%</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.6.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.1.6.4.1">HNSW_IP</th>
<td class="ltx_td ltx_align_center" id="S4.T1.1.6.4.2"><span class="ltx_text ltx_font_bold" id="S4.T1.1.6.4.2.1">1.9556</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.6.4.3"><span class="ltx_text ltx_font_bold" id="S4.T1.1.6.4.3.1">65.1852%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.6.4.4">1.2926</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.6.4.5">43.0864%</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.6.4.6">51.2894%</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.7.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.1.7.5.1">IVFFlat</th>
<td class="ltx_td ltx_align_center" id="S4.T1.1.7.5.2">1.3500</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.7.5.3">45.0000%</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.7.5.4">0.8370</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.7.5.5">27.9012%</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.7.5.6">61.2832%</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.8.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.1.8.6.1">SQ</th>
<td class="ltx_td ltx_align_center" id="S4.T1.1.8.6.2">1.9481</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.8.6.3">64.9383%</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.8.6.4">1.3037</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.8.6.5">43.4568%</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.8.6.6">49.4318%</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.9.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.1.9.7.1">IVFSQ</th>
<td class="ltx_td ltx_align_center" id="S4.T1.1.9.7.2">1.3407</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.9.7.3">44.6914%</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.9.7.4">0.8370</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.9.7.5">27.9012%</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.9.7.6">60.1770%</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.10.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.1.10.8.1">NSG</th>
<td class="ltx_td ltx_align_center" id="S4.T1.1.10.8.2">1.9500</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.10.8.3">65.0000%</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.10.8.4">1.2981</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.10.8.5">43.2716%</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.10.8.6">50.2140%</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.11.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.1.11.9.1">LSH</th>
<td class="ltx_td ltx_align_center" id="S4.T1.1.11.9.2">0.6833</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.11.9.3">22.7778%</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.11.9.4">0.4796</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.11.9.5">15.9877%</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.11.9.6">42.4710%</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.12.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b" id="S4.T1.1.12.10.1">AVG</th>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T1.1.12.10.2">1.6749</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T1.1.12.10.3">55.8299%</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T1.1.12.10.4">1.1008</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T1.1.12.10.5">36.6941%</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T1.1.12.10.6">52.1495%</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1. </span>Comparison of Vectorization and Indexing Methods</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2. </span>Optimization of Large Language Models with RAG Technology</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">In our RAG process, we utilized the LLaMA-Factory<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">Zheng2024</span>)</cite>, developed by hiyouga, as the tool for integrating knowledge and making inferences using large language models. We employed this tool with specific parameters to ensure the quality of the language model: a default temperature coefficient of 0.95, a maximum input length of 1024 tokens, and a maximum output length of 512 tokens. Below is the designed instruction for reference: ”Please use the provided viewpoint knowledge to introduce the viewpoint to the user. Always adhere strictly to the provided viewpoint information. Input: query of user, viewpoint information.”</p>
</div>
<div class="ltx_para" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1">In the research by Jinhu et al., methods such as Supervised Fine-Tuning (SFT) and Optimizing Model Weights (ORPO) were primarily used. These methods generated content about viewpoints under different computation precisions (including BF16, FP16, and FP32) and compared their optimal scores under various large language models, specific computation precisions, and fine-tuning methods. Additionally, these results were compared with the laboratory research on Retrieval-Augmented Generation (RAG) technology. This experiment was conducted using the same large language model, with identical parameter sizes, prompts, and evaluation methods, to scientifically compare the performance differences between RAG technology and different fine-tuning methods in generating viewpoint content while strictly controlling variables. The experimental results indicated significant differences in content quality generated by different fine-tuning methods and computation precisions, while RAG technology demonstrated unique advantages in specific scenarios.</p>
</div>
<div class="ltx_para" id="S4.SS2.p3">
<p class="ltx_p" id="S4.SS2.p3.1">The results of the models optimized with RAG technology are as Table 2.</p>
</div>
<div class="ltx_para" id="S4.SS2.p4">
<p class="ltx_p" id="S4.SS2.p4.1">From the table, we can see that the performance of most experimental models improved after optimization with RAG technology. Keeping the weight parameters consistent and setting the scores of each metric to 1, we obtained a full score of 1.5873 using the formula. The ChatGLM3-6b<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">huggingface_chatglm3_2023</span>)</cite> model achieved a total score of 1.2868 after fine-tuning, and a total score of 1.3228 after RAG optimization, with relevance increasing from 0.7885 to 0.7995, indicating improved model performance. The Baichuan2-7b<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">huggingface_baichuan2_2023</span>)</cite> model had a total score of 1.0012 after fine-tuning, and a total score of 0.9215 after RAG optimization, with relevance decreasing from 0.5485 to 0.4687, suggesting that the model did not perform well after RAG optimization. This issue is likely due to the model’s poor performance, making it unsuitable for complex optimization techniques like RAG. The QWEN7b-chat<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">qwen2_2024</span>)</cite> model achieved a total score of 1.1876 after fine-tuning and a total score of 1.3238 after RAG optimization, with relevance increasing from 0.6924 to 0.7966, showing a significant improvement and indicating that RAG technology effectively addresses the hallucination problem in this model. The Llama3-8b model<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">huggingface_meta_llama_2024</span>)</cite> showed the most significant improvement, with relevance increasing from 0.6743 to 0.9721, making the model’s performance nearly perfect after optimization. We speculate that the significant impact is due to Llama3-8b’s lack of Chinese corpus, preventing effective integration and linking of content from the external knowledge base, resulting in overfitting.</p>
</div>
<div class="ltx_para" id="S4.SS2.p5">
<p class="ltx_p" id="S4.SS2.p5.1">Based on the above experimental results, it is evident that most models perform better in terms of relevance when answering user questions after RAG optimization. Therefore, we believe that RAG technology greatly helps optimize the hallucination problem of large models. Additionally, it can also improve overall model performance metrics such as fluency and accuracy, thereby enhancing the model’s generation performance and robustness comprehensively.</p>
</div>
<figure class="ltx_table" id="S4.T2">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T2.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T2.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t" id="S4.T2.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.1.1">Model</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t" id="S4.T2.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.2.1">Group</span></th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t" id="S4.T2.1.1.1.3">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.1.1.3.1">
<span class="ltx_p" id="S4.T2.1.1.1.3.1.1" style="width:42.7pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.3.1.1.1">Fluency</span></span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t" id="S4.T2.1.1.1.4">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.1.1.4.1">
<span class="ltx_p" id="S4.T2.1.1.1.4.1.1" style="width:42.7pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.4.1.1.1">Accurate Rate</span></span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t" id="S4.T2.1.1.1.5">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.1.1.5.1">
<span class="ltx_p" id="S4.T2.1.1.1.5.1.1" style="width:42.7pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.5.1.1.1">Relevance</span></span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t" id="S4.T2.1.1.1.6">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.1.1.6.1">
<span class="ltx_p" id="S4.T2.1.1.1.6.1.1" style="width:56.9pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.6.1.1.1">Overall Score</span></span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t" id="S4.T2.1.1.1.7">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.1.1.7.1">
<span class="ltx_p" id="S4.T2.1.1.1.7.1.1" style="width:56.9pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.7.1.1.1">Overall Score%</span></span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t" id="S4.T2.1.1.1.8">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.1.1.8.1">
<span class="ltx_p" id="S4.T2.1.1.1.8.1.1" style="width:42.7pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.8.1.1.1">Improvement</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T2.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T2.1.2.1.1">ChatGLM 3-6b</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T2.1.2.1.2">RAG</th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S4.T2.1.2.1.3">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.2.1.3.1">
<span class="ltx_p" id="S4.T2.1.2.1.3.1.1" style="width:42.7pt;">0.8730</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S4.T2.1.2.1.4">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.2.1.4.1">
<span class="ltx_p" id="S4.T2.1.2.1.4.1.1" style="width:42.7pt;">0.8094</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S4.T2.1.2.1.5">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.2.1.5.1">
<span class="ltx_p" id="S4.T2.1.2.1.5.1.1" style="width:42.7pt;">0.7995</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S4.T2.1.2.1.6">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.2.1.6.1">
<span class="ltx_p" id="S4.T2.1.2.1.6.1.1" style="width:56.9pt;">1.3228</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S4.T2.1.2.1.7">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.2.1.7.1">
<span class="ltx_p" id="S4.T2.1.2.1.7.1.1" style="width:56.9pt;">83.33%</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S4.T2.1.2.1.8">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.2.1.8.1">
<span class="ltx_p" id="S4.T2.1.2.1.8.1.1" style="width:42.7pt;">0.0279</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.3.2">
<th class="ltx_td ltx_th ltx_th_row" id="S4.T2.1.3.2.1"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.1.3.2.2">Fine-tuning</th>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T2.1.3.2.3">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.3.2.3.1">
<span class="ltx_p" id="S4.T2.1.3.2.3.1.1" style="width:42.7pt;">0.8523</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T2.1.3.2.4">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.3.2.4.1">
<span class="ltx_p" id="S4.T2.1.3.2.4.1.1" style="width:42.7pt;">0.6879</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T2.1.3.2.5">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.3.2.5.1">
<span class="ltx_p" id="S4.T2.1.3.2.5.1.1" style="width:42.7pt;">0.7885</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T2.1.3.2.6">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.3.2.6.1">
<span class="ltx_p" id="S4.T2.1.3.2.6.1.1" style="width:56.9pt;">1.2868</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T2.1.3.2.7">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.3.2.7.1">
<span class="ltx_p" id="S4.T2.1.3.2.7.1.1" style="width:56.9pt;">81.07%</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T2.1.3.2.8">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.3.2.8.1">
<span class="ltx_p" id="S4.T2.1.3.2.8.1.1" style="width:42.7pt;"></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.1.4.3.1">Baichuan2-7b</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.1.4.3.2">RAG</th>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T2.1.4.3.3">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.4.3.3.1">
<span class="ltx_p" id="S4.T2.1.4.3.3.1.1" style="width:42.7pt;">0.4435</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T2.1.4.3.4">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.4.3.4.1">
<span class="ltx_p" id="S4.T2.1.4.3.4.1.1" style="width:42.7pt;">0.6774</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T2.1.4.3.5">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.4.3.5.1">
<span class="ltx_p" id="S4.T2.1.4.3.5.1.1" style="width:42.7pt;">0.4687</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T2.1.4.3.6">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.4.3.6.1">
<span class="ltx_p" id="S4.T2.1.4.3.6.1.1" style="width:56.9pt;">0.9215</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T2.1.4.3.7">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.4.3.7.1">
<span class="ltx_p" id="S4.T2.1.4.3.7.1.1" style="width:56.9pt;">58.05%</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T2.1.4.3.8">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.4.3.8.1">
<span class="ltx_p" id="S4.T2.1.4.3.8.1.1" style="width:42.7pt;">-0.0800</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.5.4">
<th class="ltx_td ltx_th ltx_th_row" id="S4.T2.1.5.4.1"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.1.5.4.2">Fine-tuning</th>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T2.1.5.4.3">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.5.4.3.1">
<span class="ltx_p" id="S4.T2.1.5.4.3.1.1" style="width:42.7pt;">0.5734</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T2.1.5.4.4">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.5.4.4.1">
<span class="ltx_p" id="S4.T2.1.5.4.4.1.1" style="width:42.7pt;">0.6074</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T2.1.5.4.5">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.5.4.5.1">
<span class="ltx_p" id="S4.T2.1.5.4.5.1.1" style="width:42.7pt;">0.5485</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T2.1.5.4.6">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.5.4.6.1">
<span class="ltx_p" id="S4.T2.1.5.4.6.1.1" style="width:56.9pt;">1.0012</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T2.1.5.4.7">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.5.4.7.1">
<span class="ltx_p" id="S4.T2.1.5.4.7.1.1" style="width:56.9pt;">63.08%</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T2.1.5.4.8">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.5.4.8.1">
<span class="ltx_p" id="S4.T2.1.5.4.8.1.1" style="width:42.7pt;"></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.1.6.5.1">Qwen-7b-chat</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.1.6.5.2">RAG</th>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T2.1.6.5.3">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.6.5.3.1">
<span class="ltx_p" id="S4.T2.1.6.5.3.1.1" style="width:42.7pt;">0.8876</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T2.1.6.5.4">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.6.5.4.1">
<span class="ltx_p" id="S4.T2.1.6.5.4.1.1" style="width:42.7pt;">0.8048</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T2.1.6.5.5">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.6.5.5.1">
<span class="ltx_p" id="S4.T2.1.6.5.5.1.1" style="width:42.7pt;">0.7966</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T2.1.6.5.6">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.6.5.6.1">
<span class="ltx_p" id="S4.T2.1.6.5.6.1.1" style="width:56.9pt;">1.3238</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T2.1.6.5.7">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.6.5.7.1">
<span class="ltx_p" id="S4.T2.1.6.5.7.1.1" style="width:56.9pt;">83.40%</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T2.1.6.5.8">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.6.5.8.1">
<span class="ltx_p" id="S4.T2.1.6.5.8.1.1" style="width:42.7pt;">0.1148</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.7.6">
<th class="ltx_td ltx_th ltx_th_row" id="S4.T2.1.7.6.1"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.1.7.6.2">Fine-tuning</th>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T2.1.7.6.3">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.7.6.3.1">
<span class="ltx_p" id="S4.T2.1.7.6.3.1.1" style="width:42.7pt;">0.8018</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T2.1.7.6.4">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.7.6.4.1">
<span class="ltx_p" id="S4.T2.1.7.6.4.1.1" style="width:42.7pt;">0.6681</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T2.1.7.6.5">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.7.6.5.1">
<span class="ltx_p" id="S4.T2.1.7.6.5.1.1" style="width:42.7pt;">0.6924</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T2.1.7.6.6">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.7.6.6.1">
<span class="ltx_p" id="S4.T2.1.7.6.6.1.1" style="width:56.9pt;">1.1876</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T2.1.7.6.7">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.7.6.7.1">
<span class="ltx_p" id="S4.T2.1.7.6.7.1.1" style="width:56.9pt;">74.82%</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T2.1.7.6.8">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.7.6.8.1">
<span class="ltx_p" id="S4.T2.1.7.6.8.1.1" style="width:42.7pt;"></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.8.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.1.8.7.1">Llama3-8b</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.1.8.7.2">RAG</th>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T2.1.8.7.3">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.8.7.3.1">
<span class="ltx_p" id="S4.T2.1.8.7.3.1.1" style="width:42.7pt;">0.7530</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T2.1.8.7.4">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.8.7.4.1">
<span class="ltx_p" id="S4.T2.1.8.7.4.1.1" style="width:42.7pt;">0.8724</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T2.1.8.7.5">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.8.7.5.1">
<span class="ltx_p" id="S4.T2.1.8.7.5.1.1" style="width:42.7pt;">0.9721</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T2.1.8.7.6">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.8.7.6.1">
<span class="ltx_p" id="S4.T2.1.8.7.6.1.1" style="width:56.9pt;">1.4643</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T2.1.8.7.7">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.8.7.7.1">
<span class="ltx_p" id="S4.T2.1.8.7.7.1.1" style="width:56.9pt;">92.25%</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T2.1.8.7.8">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.8.7.8.1">
<span class="ltx_p" id="S4.T2.1.8.7.8.1.1" style="width:42.7pt;">0.2418</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.9.8">
<th class="ltx_td ltx_th ltx_th_row ltx_border_b" id="S4.T2.1.9.8.1"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b" id="S4.T2.1.9.8.2">Fine-tuning</th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b" id="S4.T2.1.9.8.3">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.9.8.3.1">
<span class="ltx_p" id="S4.T2.1.9.8.3.1.1" style="width:42.7pt;">0.8150</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b" id="S4.T2.1.9.8.4">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.9.8.4.1">
<span class="ltx_p" id="S4.T2.1.9.8.4.1.1" style="width:42.7pt;">0.6795</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b" id="S4.T2.1.9.8.5">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.9.8.5.1">
<span class="ltx_p" id="S4.T2.1.9.8.5.1.1" style="width:42.7pt;">0.6743</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b" id="S4.T2.1.9.8.6">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.9.8.6.1">
<span class="ltx_p" id="S4.T2.1.9.8.6.1.1" style="width:56.9pt;">1.1792</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b" id="S4.T2.1.9.8.7">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.9.8.7.1">
<span class="ltx_p" id="S4.T2.1.9.8.7.1.1" style="width:56.9pt;">74.29%</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b" id="S4.T2.1.9.8.8">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.9.8.8.1">
<span class="ltx_p" id="S4.T2.1.9.8.8.1.1" style="width:42.7pt;"></span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2. </span>Comparison of Large Language Model Performance with RAG Optimization and Fine-Tuning</figcaption>
</figure>
<figure class="ltx_figure" id="S4.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="476" id="S4.F2.g1" src="extracted/5804449/aipr2.png" width="1196"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2. </span>Comparison of the models in RAG and Fine-tuning between Accurate Rate and Overall Score</figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5. </span>Conclusion</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">This study proposes an optimization scheme based on Retrieval-Augmented Generation (RAG) technology for large language models in the context of Tibet’s cultural tourism industry. By analyzing the deficiencies of existing large language models in the application of the cultural tourism field and combining experimental validation, we demonstrated the effectiveness of RAG technology in improving the accuracy of information generation and personalized recommendation capabilities.</p>
</div>
<div class="ltx_para" id="S5.p2">
<p class="ltx_p" id="S5.p2.1">First, we integrated existing tourism information resources to construct a detailed database of viewpoints and used vectorization techniques such as TF-IDF and BERT to process the data. Experimental results showed that TF-IDF performed excellently in keyword hit rate and vectorization efficiency. Particularly when combined with the HNSWFlat indexing method and L2 Euclidean distance calculation method, it significantly improved retrieval accuracy. This research provides guidance for the generation and debugging of similar databases in the future.</p>
</div>
<div class="ltx_para" id="S5.p3">
<p class="ltx_p" id="S5.p3.1">Second, we applied RAG technology to large language models, utilizing external knowledge bases to address the hallucination problem in content generation. The experimental results indicated that models optimized with RAG showed noticeable improvements in fluency, accuracy, and relevance of content generation. Among them, the Llama3-8b model exhibited the most significant improvement in overall score, increasing from 74.29.% to 92.25% after RAG optimization.</p>
</div>
<div class="ltx_para" id="S5.p4">
<p class="ltx_p" id="S5.p4.1">Finally, by comparing the performance of various models under different computation precisions and fine-tuning methods, we verified the unique advantages of RAG technology in specific scenarios. This research not only demonstrates the potential of RAG technology in the standardization of cultural tourism information and data analysis but also provides new methods and tools for further optimizing the application of large models in specialized fields.</p>
</div>
<div class="ltx_para" id="S5.p5">
<p class="ltx_p" id="S5.p5.1">In conclusion, the vector database construction and model optimization methods employed in this study effectively addressed the challenges of hallucinations and insufficient personalization capabilities in large models for Tibet tourism information recommendation. This provides a solid theoretical and technical foundation for future intelligent cultural tourism service systems. Future research can further explore the application of RAG technology in other fields and how to further enhance the personalized recommendation capabilities and information generation accuracy of large language models.</p>
</div>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6. </span>Acknowledgments</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">This work is supported by the project “Research and Application of Intelligent Tourism Service System in Tibet Based on LLM” under Grant No. XZ202401ZY0008.</p>
</div>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Wed Aug 21 06:59:59 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
