<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations</title>
<!--Generated on Wed May  1 18:53:36 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2404.08661v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#Sx1" title="In TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title">PERMISSION FOR USAGE</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#Sx2" title="In TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title">ABSTRACT</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#Sx3" title="In TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title">ABBREVIATIONS</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S1" title="In TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span><span class="ltx_text ltx_ulem_uline">Introduction</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S1.SS1" title="In 1 Introduction ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1.1 </span>Choice of NMT system and its human parity</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S1.SS2" title="In 1 Introduction ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1.2 </span>NMT translationese</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S1.SS3" title="In 1 Introduction ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1.3 </span>Translation relations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S1.SS4" title="In 1 Introduction ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1.4 </span>Summary</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S2" title="In TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span><span class="ltx_text ltx_ulem_uline">Related work</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S2.SS1" title="In 2 Related work ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Translationese</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S2.SS1.SSS1" title="In 2.1 Translationese ‣ 2 Related work ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1.1 </span>Translationese definition</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S2.SS1.SSS2" title="In 2.1 Translationese ‣ 2 Related work ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1.2 </span>Translationese features</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S2.SS1.SSS3" title="In 2.1 Translationese ‣ 2 Related work ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1.3 </span>Machine translation translationese</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S2.SS1.SSS4" title="In 2.1 Translationese ‣ 2 Related work ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1.4 </span>Machine tranlationese v.s. human translationese</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S2.SS2" title="In 2 Related work ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Metrics for translation quality</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S2.SS2.SSS1" title="In 2.2 Metrics for translation quality ‣ 2 Related work ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2.1 </span>Automatic evaluation of machine translation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S2.SS2.SSS2" title="In 2.2 Metrics for translation quality ‣ 2 Related work ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2.2 </span>Traditional metrics</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S2.SS3" title="In 2 Related work ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>Translation relations</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S2.SS3.SSS1" title="In 2.3 Translation relations ‣ 2 Related work ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3.1 </span>Translation relations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S2.SS3.SSS2" title="In 2.3 Translation relations ‣ 2 Related work ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3.2 </span>Non-literal translation in NMT</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S3" title="In TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span><span class="ltx_text ltx_ulem_uline">Methodology</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S3.SS1" title="In 3 Methodology ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Translationese comparison</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S3.SS1.SSS1" title="In 3.1 Translationese comparison ‣ 3 Methodology ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.1 </span>Data source</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S3.SS1.SSS2" title="In 3.1 Translationese comparison ‣ 3 Methodology ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.2 </span>MTionese v.s. HTionese</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S3.SS2" title="In 3 Methodology ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Translation relations</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S3.SS2.SSS1" title="In 3.2 Translation relations ‣ 3 Methodology ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.1 </span>Details of translation relations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S3.SS2.SSS2" title="In 3.2 Translation relations ‣ 3 Methodology ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.2 </span>Annotations of translation relations</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S3.SS3" title="In 3 Methodology ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Translation relations features</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S4" title="In TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span><span class="ltx_text ltx_ulem_uline">Discussions and findings</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S4.SS1" title="In 4 Discussions and findings ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Aligned Data</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S4.SS1.SSS1" title="In 4.1 Aligned Data ‣ 4 Discussions and findings ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1.1 </span>Comparison based on tokens in the source texts</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S4.SS1.SSS2" title="In 4.1 Aligned Data ‣ 4 Discussions and findings ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1.2 </span>Comparison of translation relations in genres</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S4.SS2" title="In 4 Discussions and findings ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Features of translation relations</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S4.SS2.SSS1" title="In 4.2 Features of translation relations ‣ 4 Discussions and findings ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.1 </span>Equivalence</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S4.SS2.SSS2" title="In 4.2 Features of translation relations ‣ 4 Discussions and findings ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.2 </span>Figurative translation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S4.SS2.SSS3" title="In 4.2 Features of translation relations ‣ 4 Discussions and findings ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.3 </span>Generalization</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S4.SS2.SSS4" title="In 4.2 Features of translation relations ‣ 4 Discussions and findings ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.4 </span>Lexical shift</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S4.SS2.SSS5" title="In 4.2 Features of translation relations ‣ 4 Discussions and findings ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.5 </span>Modulation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S4.SS2.SSS6" title="In 4.2 Features of translation relations ‣ 4 Discussions and findings ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.6 </span>Modulation + Transposition</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S4.SS2.SSS7" title="In 4.2 Features of translation relations ‣ 4 Discussions and findings ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.7 </span>Particularization</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S4.SS2.SSS8" title="In 4.2 Features of translation relations ‣ 4 Discussions and findings ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.8 </span>Transposition</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S4.SS2.SSS9" title="In 4.2 Features of translation relations ‣ 4 Discussions and findings ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.9 </span>Unaligned-explicitation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S4.SS2.SSS10" title="In 4.2 Features of translation relations ‣ 4 Discussions and findings ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.10 </span>Unaligned-reduction</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S5" title="In TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span><span class="ltx_text ltx_ulem_uline">Conclusions and future work</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S5.SS1" title="In 5 Conclusions and future work ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Research questions</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S5.SS2" title="In 5 Conclusions and future work ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Data</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S5.SS3" title="In 5 Conclusions and future work ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3 </span>Results</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S5.SS4" title="In 5 Conclusions and future work ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.4 </span>Shortcoming</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S5.SS5" title="In 5 Conclusions and future work ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.5 </span>Future work</span></a></li>
</ol>
</li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<h1 class="ltx_title ltx_title_document"><span class="ltx_text" id="id1.id1" style="color:#1E64C8;"> TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations</span></h1>
<div class="ltx_para" id="p1">
<p class="ltx_p" id="p1.1"><span class="ltx_text ltx_font_bold" id="p1.1.1" style="color:#1E64C8;">THE COMPARISON BETWEEN MACHINE TRANSLATION AND HUMAN TRANSLATION IN TERMS OF TRANSLATION RELATIONS 
<br class="ltx_break"/><span class="ltx_text ltx_font_medium" id="p1.1.1.1"> </span>
MASTER’S THESIS AT GHENT UNIVERSITY AND KU LEUVEN </span>
<span class="ltx_text" id="p1.1.2" style="color:#1E64C8;"> <span class="ltx_text ltx_font_bold" id="p1.1.2.1">
Faculty of Arts and Philosophy 
<br class="ltx_break"/></span></span></p>
</div>
<div class="ltx_para ltx_noindent" id="p2">
<p class="ltx_p" id="p2.3">Fan Zhou

<br class="ltx_break"/>Student number: 02016257 
<br class="ltx_break"/>Supervisor(s): Dr. Arda Tezcan
<br class="ltx_break"/>Co-supervisor(s): Prof. Linda Badan 
<br class="ltx_break"/>A thesis submitted to Ghent University in partial fulfilment of the requirements for the degree of Master of Arts in Linguistics: Natural Language Processing 
<br class="ltx_break"/>Ghent University and KU Leuven
<br class="ltx_break"/>Academic year: 2021 - 2022</p>
<div class="ltx_logical-block" id="p2.2">
<figure class="ltx_figure ltx_align_left" id="p2.1.1"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="3969" id="p2.1.1.g1" src="extracted/2404.08661v1/logo_UGent_NL_RGB_2400_kleur-op-wit.png" width="4961"/>
</figure>
<figure class="ltx_figure ltx_align_left" id="p2.2.2"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="47" id="p2.2.2.g1" src="extracted/2404.08661v1/kuleuven_logo.png" width="128"/>
</figure>
</div>
</div>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_ulem_uline ltx_title_section" style="color:#1E64C8;">PERMISSION FOR USAGE</h2>
<div class="ltx_para" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1">“The author(s) gives (give) permission to make this bachelor’s thesis available for consultation and to copy parts of this bachelor’s thesis for personal use. In the case of any other use, the copyright terms have to be respected, in particular with regard to the obligation to state expressly the source when quoting results from this bachelor’s thesis."</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx1.p2">
<p class="ltx_p" id="Sx1.p2.1"><span class="ltx_text ltx_font_bold" id="Sx1.p2.1.1" style="color:#1E64C8;">STUDENT’S NAME: Fan Zhou</span></p>
</div>
<div class="ltx_para ltx_noindent" id="Sx1.p3">
<p class="ltx_p" id="Sx1.p3.1"><span class="ltx_text ltx_font_bold" id="Sx1.p3.1.1" style="color:#1E64C8;">STUDENT’S SIGNATURE:</span></p>
</div>
<div class="ltx_para ltx_noindent" id="Sx1.p4">
<p class="ltx_p" id="Sx1.p4.1"><span class="ltx_text ltx_font_bold" id="Sx1.p4.1.1" style="color:#1E64C8;">DATE:</span>                   22-08-2022</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_section" id="Sx2">
<h2 class="ltx_title ltx_ulem_uline ltx_title_section" style="color:#1E64C8;">ABSTRACT</h2>
<div class="ltx_para" id="Sx2.p1">
<p class="ltx_p" id="Sx2.p1.1">The end result of the translation process is referred to as translationese (Gellerstam, 1986), also known as an interlanguage (Selinker, 1972) or the third language (Frawley, 1984). Its awkwardness, unnaturalness, and unidiomaticness set it apart from native-language texts in the target language since an extremely literal translation was utilized in an attempt to replicate the source texts’ qualities. There are studies and research on reducing translationese to increase translation quality, and one of these is on translation relations, which encompasses a variety of translation techniques. Along with literal translation methods, there exist non-literal translation techniques that can manage translation that is incomprehensible by literal translation techniques.</p>
</div>
<div class="ltx_para" id="Sx2.p2">
<br class="ltx_break"/>
</div>
<div class="ltx_para ltx_noindent" id="Sx2.p3">
<p class="ltx_p" id="Sx2.p3.1">This work identifies the distinctions between neural machine translation (NMT) and human translation (HT) based on translation relations. Seen as a type of metric for translation quality, the translation relation uses HT as a reference and assesses the translationese brought on by an NMT system, GoogleNMT (Wu et al., 2016). There are three research questions that need to be answered: how NMT and HT differ from one another in terms of the overall translation relations; how non-literal translation techniques are used differently by NMT and HT; and how NMT and HT differ from one another in terms of the factors that influence the use of specific non-literal translation techniques.</p>
</div>
<div class="ltx_para" id="Sx2.p4">
<br class="ltx_break"/>
</div>
<div class="ltx_para ltx_noindent" id="Sx2.p5">
<p class="ltx_p" id="Sx2.p5.1">Two parallel corpora are used: NMT-translated corpora as the experiment group and human-translated corpora as the reference one. Both parallel corpora have 9 genres with the shared source texts from the existing corpus (Zhai, 2020). Translation relations are manually annotated for aligned pairs with one side as the English token group and the other side as its corresponding translated Chinese token group. The use of translation relations in both parallel corpora is calculated for research comparisons, and in-depth linguistics-related knowledge which causes the use of translation techniques containing both semantics and syntax such as hyperonyms used by the translation technique of generalization and part-of-speech tagging alteration used by the technique of transposition is put to serve as a measurement for the application of translation relations.</p>
</div>
<div class="ltx_para" id="Sx2.p6">
<br class="ltx_break"/>
</div>
<div class="ltx_para ltx_noindent" id="Sx2.p7">
<p class="ltx_p" id="Sx2.p7.1">The final result shows that NMT uses more literal translation than HT by 17.41% on an overall basis, and such overweight exists in each genre though there are differences in excess between genres. For the use of non-literal translation techniques, NMT shows the nearly- equivalent good performance with HT at the syntactic level especially when using translation techniques of lexical shift, transposition, and unaligned-reduction; however, its performance is not ideal when the translation using the techniques of particularization, figuration, equivalence, and generalization on the semantic levels.</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx2.p8">
<p class="ltx_p" id="Sx2.p8.1"><span class="ltx_text ltx_font_bold" id="Sx2.p8.1.1">Keywords:</span> Translation Relation, Translation Techniques, Translationese, Neural Machine Translation, Translation Quality, English-Chinese Translation</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_section" id="Sx3">
<h2 class="ltx_title ltx_ulem_uline ltx_title_section" style="color:#1E64C8;">ABBREVIATIONS</h2>
<div class="ltx_para" id="Sx3.p1">
<p class="ltx_p" id="Sx3.p1.1"><span class="ltx_text ltx_font_bold" id="Sx3.p1.1.1">acl</span>                     clausal modifier of noun (adjectival clause)</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx3.p2">
<p class="ltx_p" id="Sx3.p2.1"><span class="ltx_text ltx_font_bold" id="Sx3.p2.1.1">ADJ</span>                   adjective</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx3.p3">
<p class="ltx_p" id="Sx3.p3.1"><span class="ltx_text ltx_font_bold" id="Sx3.p3.1.1">ADP</span>                   adposition</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx3.p4">
<p class="ltx_p" id="Sx3.p4.1"><span class="ltx_text ltx_font_bold" id="Sx3.p4.1.1">ADV</span>                   adverb</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx3.p5">
<p class="ltx_p" id="Sx3.p5.1"><span class="ltx_text ltx_font_bold" id="Sx3.p5.1.1">ADV</span>                   adverb</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx3.p6">
<p class="ltx_p" id="Sx3.p6.1"><span class="ltx_text ltx_font_bold" id="Sx3.p6.1.1">advmod</span>              adverbial modifier</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx3.p7">
<p class="ltx_p" id="Sx3.p7.1"><span class="ltx_text ltx_font_bold" id="Sx3.p7.1.1">amod</span>                  adjectival modifier</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx3.p8">
<p class="ltx_p" id="Sx3.p8.1"><span class="ltx_text ltx_font_bold" id="Sx3.p8.1.1">ASTrED</span>               aligned syntactic tree edit distance</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx3.p9">
<p class="ltx_p" id="Sx3.p9.1"><span class="ltx_text ltx_font_bold" id="Sx3.p9.1.1">aux</span>                    auxiliary</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx3.p10">
<p class="ltx_p" id="Sx3.p10.1"><span class="ltx_text ltx_font_bold" id="Sx3.p10.1.1">AUX</span>                   auxiliary</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx3.p11">
<p class="ltx_p" id="Sx3.p11.1"><span class="ltx_text ltx_font_bold" id="Sx3.p11.1.1">BLEU</span>                  bilingual evaluation understudy</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx3.p12">
<p class="ltx_p" id="Sx3.p12.1"><span class="ltx_text ltx_font_bold" id="Sx3.p12.1.1">case</span>                   case marking</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx3.p13">
<p class="ltx_p" id="Sx3.p13.1"><span class="ltx_text ltx_font_bold" id="Sx3.p13.1.1">cc</span>                      coordination</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx3.p14">
<p class="ltx_p" id="Sx3.p14.1"><span class="ltx_text ltx_font_bold" id="Sx3.p14.1.1">CCONJ</span>               coordinating conjunction</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx3.p15">
<p class="ltx_p" id="Sx3.p15.1"><span class="ltx_text ltx_font_bold" id="Sx3.p15.1.1">clf</span>                      classifier modifier</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx3.p16">
<p class="ltx_p" id="Sx3.p16.1"><span class="ltx_text ltx_font_bold" id="Sx3.p16.1.1">conj</span>                   conjunct</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx3.p17">
<p class="ltx_p" id="Sx3.p17.1"><span class="ltx_text ltx_font_bold" id="Sx3.p17.1.1">dep</span>                   dependent</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx3.p18">
<p class="ltx_p" id="Sx3.p18.1"><span class="ltx_text ltx_font_bold" id="Sx3.p18.1.1">DET</span>                   determiner</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx3.p19">
<p class="ltx_p" id="Sx3.p19.1"><span class="ltx_text ltx_font_bold" id="Sx3.p19.1.1">dobj</span>                   direct object</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx3.p20">
<p class="ltx_p" id="Sx3.p20.1"><span class="ltx_text ltx_font_bold" id="Sx3.p20.1.1">EBMT</span>                 example-based machine translation</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx3.p21">
<p class="ltx_p" id="Sx3.p21.1"><span class="ltx_text ltx_font_bold" id="Sx3.p21.1.1">GNMT/GoogleNMT</span>       Google neural machine translation</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx3.p22">
<p class="ltx_p" id="Sx3.p22.1"><span class="ltx_text ltx_font_bold" id="Sx3.p22.1.1">HT</span>                      human translation</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx3.p23">
<p class="ltx_p" id="Sx3.p23.1"><span class="ltx_text ltx_font_bold" id="Sx3.p23.1.1">HTionese</span>              human translationese</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx3.p24">
<p class="ltx_p" id="Sx3.p24.1"><span class="ltx_text ltx_font_bold" id="Sx3.p24.1.1">HUME</span>                   Human UCCA-Based MT Assessment</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx3.p25">
<p class="ltx_p" id="Sx3.p25.1"><span class="ltx_text ltx_font_bold" id="Sx3.p25.1.1">INTJ</span>                   interjection</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx3.p26">
<p class="ltx_p" id="Sx3.p26.1"><span class="ltx_text ltx_font_bold" id="Sx3.p26.1.1">LSTM</span>                   long short-term memory</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx3.p27">
<p class="ltx_p" id="Sx3.p27.1"><span class="ltx_text ltx_font_bold" id="Sx3.p27.1.1">mark</span>                    marker</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx3.p28">
<p class="ltx_p" id="Sx3.p28.1"><span class="ltx_text ltx_font_bold" id="Sx3.p28.1.1">MT</span>                       machine translation</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx3.p29">
<p class="ltx_p" id="Sx3.p29.1"><span class="ltx_text ltx_font_bold" id="Sx3.p29.1.1">MTionese</span>              machine translationese</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx3.p30">
<p class="ltx_p" id="Sx3.p30.1"><span class="ltx_text ltx_font_bold" id="Sx3.p30.1.1">nmod</span>                   noun compound modifier</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx3.p31">
<p class="ltx_p" id="Sx3.p31.1"><span class="ltx_text ltx_font_bold" id="Sx3.p31.1.1">NMT</span>                   neural machine translation</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx3.p32">
<p class="ltx_p" id="Sx3.p32.1"><span class="ltx_text ltx_font_bold" id="Sx3.p32.1.1">nn</span>                      noun compound modifier</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx3.p33">
<p class="ltx_p" id="Sx3.p33.1"><span class="ltx_text ltx_font_bold" id="Sx3.p33.1.1">nsubj</span>                  nominal subject</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx3.p34">
<p class="ltx_p" id="Sx3.p34.1"><span class="ltx_text ltx_font_bold" id="Sx3.p34.1.1">NUM</span>                   numeral</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx3.p35">
<p class="ltx_p" id="Sx3.p35.1"><span class="ltx_text ltx_font_bold" id="Sx3.p35.1.1">PART</span>                   particle</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx3.p36">
<p class="ltx_p" id="Sx3.p36.1"><span class="ltx_text ltx_font_bold" id="Sx3.p36.1.1">PB-SMT</span>              phrase-based statistical machine translation</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx3.p37">
<p class="ltx_p" id="Sx3.p37.1"><span class="ltx_text ltx_font_bold" id="Sx3.p37.1.1">pobj</span>                   object of a preposition</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx3.p38">
<p class="ltx_p" id="Sx3.p38.1"><span class="ltx_text ltx_font_bold" id="Sx3.p38.1.1">POS</span>                   part-of-speech</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx3.p39">
<p class="ltx_p" id="Sx3.p39.1"><span class="ltx_text ltx_font_bold" id="Sx3.p39.1.1">poss</span>                   possession modifier</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx3.p40">
<p class="ltx_p" id="Sx3.p40.1"><span class="ltx_text ltx_font_bold" id="Sx3.p40.1.1">prep</span>                   prepositional modifier</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx3.p41">
<p class="ltx_p" id="Sx3.p41.1"><span class="ltx_text ltx_font_bold" id="Sx3.p41.1.1">PRON</span>                  pronoun</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx3.p42">
<p class="ltx_p" id="Sx3.p42.1"><span class="ltx_text ltx_font_bold" id="Sx3.p42.1.1">PROPN</span>                proper noun</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx3.p43">
<p class="ltx_p" id="Sx3.p43.1"><span class="ltx_text ltx_font_bold" id="Sx3.p43.1.1">punct</span>                   punctuation</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx3.p44">
<p class="ltx_p" id="Sx3.p44.1"><span class="ltx_text ltx_font_bold" id="Sx3.p44.1.1">QE</span>                      quality estimation</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx3.p45">
<p class="ltx_p" id="Sx3.p45.1"><span class="ltx_text ltx_font_bold" id="Sx3.p45.1.1">RBMT</span>                   rule-based machine translation</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx3.p46">
<p class="ltx_p" id="Sx3.p46.1"><span class="ltx_text ltx_font_bold" id="Sx3.p46.1.1">SACr</span>                   syntactically aware cross</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx3.p47">
<p class="ltx_p" id="Sx3.p47.1"><span class="ltx_text ltx_font_bold" id="Sx3.p47.1.1">SCATE</span>                  Smart Computer-aided Translation Envrionment</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx3.p48">
<p class="ltx_p" id="Sx3.p48.1"><span class="ltx_text ltx_font_bold" id="Sx3.p48.1.1">SCONJ</span>                  subordinating conjunction</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx3.p49">
<p class="ltx_p" id="Sx3.p49.1"><span class="ltx_text ltx_font_bold" id="Sx3.p49.1.1">SMT</span>                    statistical machine translation</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx3.p50">
<p class="ltx_p" id="Sx3.p50.1"><span class="ltx_text ltx_font_bold" id="Sx3.p50.1.1">SVMs</span>                   support vector machines</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx3.p51">
<p class="ltx_p" id="Sx3.p51.1"><span class="ltx_text ltx_font_bold" id="Sx3.p51.1.1">TER</span>                     Translation Edit Rate</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx3.p52">
<p class="ltx_p" id="Sx3.p52.1"><span class="ltx_text ltx_font_bold" id="Sx3.p52.1.1">WER</span>                     word error rate</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx3.p53">
<p class="ltx_p" id="Sx3.p53.1"><span class="ltx_text ltx_font_bold" id="Sx3.p53.1.1">X</span>                         other</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx3.p54">
<p class="ltx_p" id="Sx3.p54.1"><span class="ltx_text ltx_font_bold" id="Sx3.p54.1.1">YAWAT</span>                 Yet Another Word Alignment Tool</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_pagination ltx_role_newpage"></div>
<nav class="ltx_TOC ltx_list_toc ltx_toc_toc"><h6 class="ltx_title ltx_title_contents">Contents</h6>
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#Sx1" title="In TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title">PERMISSION FOR USAGE</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#Sx2" title="In TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title">ABSTRACT</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#Sx3" title="In TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title">ABBREVIATIONS</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S1" title="In TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span><span class="ltx_text ltx_ulem_uline">Introduction</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S1.SS1" title="In 1 Introduction ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1.1 </span>Choice of NMT system and its human parity</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S1.SS2" title="In 1 Introduction ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1.2 </span>NMT translationese</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S1.SS3" title="In 1 Introduction ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1.3 </span>Translation relations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S1.SS4" title="In 1 Introduction ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1.4 </span>Summary</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S2" title="In TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span><span class="ltx_text ltx_ulem_uline">Related work</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S2.SS1" title="In 2 Related work ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Translationese</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S2.SS1.SSS1" title="In 2.1 Translationese ‣ 2 Related work ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1.1 </span>Translationese definition</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S2.SS1.SSS2" title="In 2.1 Translationese ‣ 2 Related work ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1.2 </span>Translationese features</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S2.SS1.SSS3" title="In 2.1 Translationese ‣ 2 Related work ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1.3 </span>Machine translation translationese</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S2.SS1.SSS4" title="In 2.1 Translationese ‣ 2 Related work ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1.4 </span>Machine tranlationese v.s. human translationese</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S2.SS2" title="In 2 Related work ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Metrics for translation quality</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S2.SS2.SSS1" title="In 2.2 Metrics for translation quality ‣ 2 Related work ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2.1 </span>Automatic evaluation of machine translation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S2.SS2.SSS2" title="In 2.2 Metrics for translation quality ‣ 2 Related work ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2.2 </span>Traditional metrics</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S2.SS3" title="In 2 Related work ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>Translation relations</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S2.SS3.SSS1" title="In 2.3 Translation relations ‣ 2 Related work ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3.1 </span>Translation relations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S2.SS3.SSS2" title="In 2.3 Translation relations ‣ 2 Related work ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3.2 </span>Non-literal translation in NMT</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S3" title="In TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span><span class="ltx_text ltx_ulem_uline">Methodology</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S3.SS1" title="In 3 Methodology ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Translationese comparison</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S3.SS1.SSS1" title="In 3.1 Translationese comparison ‣ 3 Methodology ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.1 </span>Data source</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S3.SS1.SSS2" title="In 3.1 Translationese comparison ‣ 3 Methodology ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.2 </span>MTionese v.s. HTionese</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S3.SS2" title="In 3 Methodology ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Translation relations</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S3.SS2.SSS1" title="In 3.2 Translation relations ‣ 3 Methodology ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.1 </span>Details of translation relations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S3.SS2.SSS2" title="In 3.2 Translation relations ‣ 3 Methodology ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.2 </span>Annotations of translation relations</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S3.SS3" title="In 3 Methodology ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Translation relations features</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S4" title="In TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span><span class="ltx_text ltx_ulem_uline">Discussions and findings</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S4.SS1" title="In 4 Discussions and findings ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Aligned Data</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S4.SS1.SSS1" title="In 4.1 Aligned Data ‣ 4 Discussions and findings ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1.1 </span>Comparison based on tokens in the source texts</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S4.SS1.SSS2" title="In 4.1 Aligned Data ‣ 4 Discussions and findings ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1.2 </span>Comparison of translation relations in genres</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S4.SS2" title="In 4 Discussions and findings ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Features of translation relations</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S4.SS2.SSS1" title="In 4.2 Features of translation relations ‣ 4 Discussions and findings ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.1 </span>Equivalence</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S4.SS2.SSS2" title="In 4.2 Features of translation relations ‣ 4 Discussions and findings ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.2 </span>Figurative translation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S4.SS2.SSS3" title="In 4.2 Features of translation relations ‣ 4 Discussions and findings ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.3 </span>Generalization</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S4.SS2.SSS4" title="In 4.2 Features of translation relations ‣ 4 Discussions and findings ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.4 </span>Lexical shift</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S4.SS2.SSS5" title="In 4.2 Features of translation relations ‣ 4 Discussions and findings ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.5 </span>Modulation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S4.SS2.SSS6" title="In 4.2 Features of translation relations ‣ 4 Discussions and findings ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.6 </span>Modulation + Transposition</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S4.SS2.SSS7" title="In 4.2 Features of translation relations ‣ 4 Discussions and findings ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.7 </span>Particularization</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S4.SS2.SSS8" title="In 4.2 Features of translation relations ‣ 4 Discussions and findings ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.8 </span>Transposition</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S4.SS2.SSS9" title="In 4.2 Features of translation relations ‣ 4 Discussions and findings ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.9 </span>Unaligned-explicitation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S4.SS2.SSS10" title="In 4.2 Features of translation relations ‣ 4 Discussions and findings ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.10 </span>Unaligned-reduction</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S5" title="In TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span><span class="ltx_text ltx_ulem_uline">Conclusions and future work</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S5.SS1" title="In 5 Conclusions and future work ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Research questions</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S5.SS2" title="In 5 Conclusions and future work ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Data</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S5.SS3" title="In 5 Conclusions and future work ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3 </span>Results</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S5.SS4" title="In 5 Conclusions and future work ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.4 </span>Shortcoming</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.08661v1#S5.SS5" title="In 5 Conclusions and future work ‣ TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.5 </span>Future work</span></a></li>
</ol>
</li>
</ol></nav>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section"><span class="ltx_text" id="S1.2.1.1" style="color:#1E64C8;">1</span> </span><span class="ltx_text ltx_ulem_uline" id="S1.3.2" style="color:#1E64C8;">Introduction</span>
</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Machine translation has been making significant progress in the past several decades, and one of the most important tasks is to achieve human parity which is defined by Hassan et al. (2018), which means the quality of machine translation reaches that of human translation, or even to reach the level of non-translated texts in target languages (Itamar, 1990; Toury, 2012; Baker, 1993, 1996, 2004; Dayrell, 2007). Although it is assumed unattainable at the current stage, there are various research and studies advancing the development in this direction. One research topic is about translationese reduction. In this dissertation, translationese in neural machine translation is detected with human translation as reference, measured by a metric named translation relations.</p>
</div>
<section class="ltx_subsection" id="S1.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.1 </span>Choice of NMT system and its human parity</h3>
<div class="ltx_para" id="S1.SS1.p1">
<p class="ltx_p" id="S1.SS1.p1.1">There are three types of machine translation systems guiding the current machine translation domain, and they are rule-based machine translation, statistical machine translation, and neural machine translation. More details are introduced in the following part. 
<br class="ltx_break"/>(1) Rule-based machine translation (RBMT) converts the source languages to target languages based on the linguistics-based rules specified by humans (Hutchins, 1995), featuring consistency and stability but low efficiency (Dove, 2012). Different languages have their own rules and contain oceans of text information; therefore, highly automation and efficiency are its two main problems. 
<br class="ltx_break"/>(2) A corpus-based system with statistical machine translation (SMT) or phrase-based machine translation (PB- SMT) as the primary method uses machine learning algorithms by using a large amount of parallel corpus as input, overcoming the problem of using labor work to boost efficiency automatically (Lopez, 2008); however, it has issues such as with translation for idiomatic expressions, compound words that have to be translated by more than one word, long dependencies, and ambiguous words with different meanings depending on contexts (Nießen, 2000). 
<br class="ltx_break"/>(3) The currently predominant neural machine translation (NMT) system has gained the most extensive popularity in machine translation domain. In contrast to more established system SMT, NMT makes use of its architecture and capacity to capture complex sentence dependencies, which suggests that it has a great deal of potential to become a new trend in machine translation. Following the development of a simple model, several NMT models have been put out, some of which have made significant advancements and produced cutting-edge outcomes. (Yang et al., 2020). Though much improvement has been made, there are still problems of quality, especially rare words, long sentences, and word alignment (Koehn et al., 2017). 
<br class="ltx_break"/>
<br class="ltx_break"/>Based on the previous rough analyses and comparisons for three machine translation systems, NMT has its advantages to be selected as the research target tool in this work, and its translation output is focused in this dissertation. Despite the advantages of the NMT system compared with other machine translation systems, how the translation quality by the NMT system is, and whether it achieve the human parity or the level of non-translated texts in target languages are questions discussed in this dissertation.

<br class="ltx_break"/>
<br class="ltx_break"/>A study assessing news translation from Chinese to English at the macro level claims that human parity has been reached (Hassan et al., 2018). However, the evaluation for translation quality at the document level shows a better preference for HT than for NMT (Laubli, 2018). Super-human translation performance by NMT between English and the other three languages, which are reassessed based on WMT 2019, is refuted (Toral, 2020). NMT shows worse performance when the sentences become shorter (Wan et al., 2022).</p>
</div>
</section>
<section class="ltx_subsection" id="S1.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.2 </span>NMT translationese</h3>
<div class="ltx_para" id="S1.SS2.p1">
<p class="ltx_p" id="S1.SS2.p1.1">Against the overall backdrop of relative feeble translation quality produced by NMT systems, much work has been done on the integration of semantics and syntax into the NMT system, and there are significant improvements on the NMT quality. In this dissertation, Google Translate<span class="ltx_note ltx_role_footnote" id="footnotex1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>https://translate.google.com/</span></span></span> is used for NMT tool. Google Translate, also known as Google Neural Machine Translation (GoogleNMT or GNMT) is published by Google in 2016, which applies the example-based (EBMT) machine translation approach and uses artificial neural networks to increase translation fluency and accuracy. Instead of learning translations phrase by phrase, the GNMT network may do interlingual machine translation by storing the semantics of the sentence (Wu et al., 2016). Although large progress has been made by Google Translate or GNMT, there are still unreadable or unnatural translation produced by it. According to the study by Rosaria and Riana (2021), the translation is still wordy and incomprehensible, since literal translation is much used and text contexts are ignored. 
<br class="ltx_break"/>
<br class="ltx_break"/>There are two examples to illustrate such problems:
<br class="ltx_break"/></p>
</div>
<div class="ltx_para" id="S1.SS2.p2">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S1.SS2.p2.1">
<tr class="ltx_tr" id="S1.SS2.p2.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S1.SS2.p2.1.1.1" style="padding-left:24.2pt;padding-right:24.2pt;">        Source sentence</td>
<td class="ltx_td ltx_nopad_r ltx_align_left ltx_border_tt" id="S1.SS2.p2.1.1.2" style="padding-left:24.2pt;padding-right:24.2pt;">        John can be relied on. He eats no fish and plays the game.</td>
</tr>
<tr class="ltx_tr" id="S1.SS2.p2.1.2">
<td class="ltx_td ltx_align_left" id="S1.SS2.p2.1.2.1" style="padding-left:24.2pt;padding-right:24.2pt;">        Reference translation</td>
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S1.SS2.p2.1.2.2" style="padding-left:24.2pt;padding-right:24.2pt;">        <span class="ltx_ERROR undefined" id="S1.SS2.p2.1.2.2.1">{CJK*}</span>UTF8gbsn约翰为人可靠，既忠诚又正直。</td>
</tr>
<tr class="ltx_tr" id="S1.SS2.p2.1.3">
<td class="ltx_td" id="S1.SS2.p2.1.3.1" style="padding-left:24.2pt;padding-right:24.2pt;"></td>
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S1.SS2.p2.1.3.2" style="padding-left:24.2pt;padding-right:24.2pt;">        (John can be relied on. He is loyal and trustworthy.)</td>
</tr>
<tr class="ltx_tr" id="S1.SS2.p2.1.4">
<td class="ltx_td ltx_align_left" id="S1.SS2.p2.1.4.1" style="padding-left:24.2pt;padding-right:24.2pt;">        Google Translate</td>
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S1.SS2.p2.1.4.2" style="padding-left:24.2pt;padding-right:24.2pt;">        <span class="ltx_ERROR undefined" id="S1.SS2.p2.1.4.2.1">{CJK*}</span>UTF8gbsn约翰为人可靠，他不吃鱼，玩游戏。</td>
</tr>
<tr class="ltx_tr" id="S1.SS2.p2.1.5">
<td class="ltx_td ltx_border_bb" id="S1.SS2.p2.1.5.1" style="padding-left:24.2pt;padding-right:24.2pt;"></td>
<td class="ltx_td ltx_nopad_r ltx_align_left ltx_border_bb" id="S1.SS2.p2.1.5.2" style="padding-left:24.2pt;padding-right:24.2pt;">        (John can be relied on. He doesn’t eat fish but plays the game.)</td>
</tr>
</table>
</div>
<div class="ltx_para" id="S1.SS2.p3">
<p class="ltx_p ltx_align_center" id="S1.SS2.p3.1">Table 1: Example-1 of machine translation</p>
</div>
<div class="ltx_logical-block" id="S1.SS2.1">
<div class="ltx_para" id="S1.SS2.1.p1">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S1.SS2.1.p1.1">
<tr class="ltx_tr" id="S1.SS2.1.p1.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S1.SS2.1.p1.1.1.1" style="padding-left:19.9pt;padding-right:19.9pt;">      Source sentence</td>
<td class="ltx_td ltx_nopad_r ltx_align_left ltx_border_tt" id="S1.SS2.1.p1.1.1.2" style="padding-left:19.9pt;padding-right:19.9pt;">      
<table class="ltx_tabular ltx_align_top" id="S1.SS2.1.p1.1.1.2.1">
<tr class="ltx_tr" id="S1.SS2.1.p1.1.1.2.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S1.SS2.1.p1.1.1.2.1.1.1" style="padding-left:19.9pt;padding-right:19.9pt;">      The track is aligned to industry-leading certifications,</td>
</tr>
<tr class="ltx_tr" id="S1.SS2.1.p1.1.1.2.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S1.SS2.1.p1.1.1.2.1.2.1" style="padding-left:19.9pt;padding-right:19.9pt;">      which employers look for as validation of your exceptional skill.</td>
</tr>
</table>
</td>
</tr>
<tr class="ltx_tr" id="S1.SS2.1.p1.1.2">
<td class="ltx_td ltx_align_left" id="S1.SS2.1.p1.1.2.1" style="padding-left:19.9pt;padding-right:19.9pt;">      Reference translation</td>
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S1.SS2.1.p1.1.2.2" style="padding-left:19.9pt;padding-right:19.9pt;">      
<table class="ltx_tabular ltx_align_top" id="S1.SS2.1.p1.1.2.2.1">
<tr class="ltx_tr" id="S1.SS2.1.p1.1.2.2.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S1.SS2.1.p1.1.2.2.1.1.1" style="padding-left:19.9pt;padding-right:19.9pt;">      <span class="ltx_ERROR undefined" id="S1.SS2.1.p1.1.2.2.1.1.1.1">{CJK*}</span>UTF8gbsn课程均与行业领先的认证直接挂钩，雇主会据此评判您是否具备卓越技能。</td>
</tr>
<tr class="ltx_tr" id="S1.SS2.1.p1.1.2.2.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S1.SS2.1.p1.1.2.2.1.2.1" style="padding-left:19.9pt;padding-right:19.9pt;">      (Each course is aligned to industry-leading certifications,</td>
</tr>
<tr class="ltx_tr" id="S1.SS2.1.p1.1.2.2.1.3">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S1.SS2.1.p1.1.2.2.1.3.1" style="padding-left:19.9pt;padding-right:19.9pt;">      according to which employers evaluate if you have exceptional skills.)</td>
</tr>
</table>
</td>
</tr>
<tr class="ltx_tr" id="S1.SS2.1.p1.1.3">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S1.SS2.1.p1.1.3.1" style="padding-left:19.9pt;padding-right:19.9pt;">      Google Translate</td>
<td class="ltx_td ltx_nopad_r ltx_align_left ltx_border_bb" id="S1.SS2.1.p1.1.3.2" style="padding-left:19.9pt;padding-right:19.9pt;">      
<table class="ltx_tabular ltx_align_top" id="S1.SS2.1.p1.1.3.2.1">
<tr class="ltx_tr" id="S1.SS2.1.p1.1.3.2.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S1.SS2.1.p1.1.3.2.1.1.1" style="padding-left:19.9pt;padding-right:19.9pt;">      <span class="ltx_ERROR undefined" id="S1.SS2.1.p1.1.3.2.1.1.1.1">{CJK*}</span>UTF8gbsn发展道路均与行业领先的认证保持一致，雇主将其视为卓越技能的验证。</td>
</tr>
<tr class="ltx_tr" id="S1.SS2.1.p1.1.3.2.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S1.SS2.1.p1.1.3.2.1.2.1" style="padding-left:19.9pt;padding-right:19.9pt;">      (Each track is aligned with industry-leading certifications,</td>
</tr>
<tr class="ltx_tr" id="S1.SS2.1.p1.1.3.2.1.3">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S1.SS2.1.p1.1.3.2.1.3.1" style="padding-left:19.9pt;padding-right:19.9pt;">      employers consider it as validation of exceptional skills.)</td>
</tr>
</table>
</td>
</tr>
</table>
</div>
</div>
<div class="ltx_para" id="S1.SS2.p4">
<p class="ltx_p ltx_align_center" id="S1.SS2.p4.1">Table 2 Example-2 of machine translation</p>
</div>
<div class="ltx_para" id="S1.SS2.p5">
<span class="ltx_ERROR undefined" id="S1.SS2.p5.1">{CJK}</span>
<p class="ltx_p" id="S1.SS2.p5.2">UTF8gbsnIn Example-1, “eats no fish and plays the game” is an idiom in English, should be paraphrased as “loyal and trustworthy” , and then translated into the corresponding target language Chinese as “既忠诚又正直” (loyal and trustworthy). However, Google Translate translates it literally without taking it as an idiom. While in Example-2: “track” is not necessarily translate into “道路” (road) but “课程” (course), and “look for as validation of” not translated but transposed and modulated into “据此评价是否” (according to which employers evaluate if).</p>
</div>
<div class="ltx_para" id="S1.SS2.p6">
<p class="ltx_p" id="S1.SS2.p6.1">From the two examples above, the translation produced by Google Translate is of unnaturalness and unreadabilty. According to Gellerstam (1986), if the translated texts sometimes do not accord with the manner of the target language, however, with the “footprints” or trances of the source language, the linguistic phenomenon is called “translationese,” which causes translation problems such as being unnatural and hard to understand and violating habitual use of target languages. 
<br class="ltx_break"/></p>
</div>
<div class="ltx_para" id="S1.SS2.p7">
<p class="ltx_p" id="S1.SS2.p7.1">Translation by Google Translate in the examples above can be seen as a kind of typical translationese of being replicating information from the source texts. Translationese is pervasive in the GNMT. In this dissertation, translationese is detected to assess the translation quality and performance by Google Translate.</p>
</div>
</section>
<section class="ltx_subsection" id="S1.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.3 </span>Translation relations</h3>
<div class="ltx_para" id="S1.SS3.p1">
<p class="ltx_p" id="S1.SS3.p1.1">Texts are prone to be literally translated through machine translation. In NMT, literal translation predominates, and Google Translate applies literal translation by 86.8% (Sipayung, 2021). However, literal translation, or word-for-word translation (Newmark, 1981), may cause awkwardness or ungrammaticality of translation, and even translation errors for idioms and some other language expression patterns, which can be seen as translationese. 
<br class="ltx_break"/>
<br class="ltx_break"/>In translation process by human translators, there are translation theories that guide the overall work of translation, and translation strategies and techniques are applied for specific translation process to ensure the translation quality. With these traditional guidelines, HT is thought to be more reliable than machine translations, and there is less translationese in HT than in MT. However, it is unclear that whether such a common sense is correct or not, and to what degree of these traditional translation guidelines are used in machine translations. Therefore, traditional translation guidelines are applied into this dissertation as one methodology for measuring translationese. For the convenience of calculation in this dissertation, only the translation relations, or translation techniques are used as one metric for translationese detection in GNMT. 
<br class="ltx_break"/>
<br class="ltx_break"/>For translation relations which proposed by Chuquet et al. (1989; Zhai et al., 2018), it refers to different types of translation techniques distinguished from literal translation. Based on the theory of translation relations, Vinay et al. (1958; Zhai et al., 2018) first established the taxonomy of translation relations. There are generally four types of translation techniques: literal translation, equivalence (semantic overlapping ranges of reference in translation), non-literal translation, and unaligned translation (translation reduction or explicitation). In the category of non-literal translation, there are sub-types of translation techniques, including modulation which means maintain naturalness but change forms, transposition which involves a shift from one grammatical category to another with meaning unchanged, generalization which refers to broader and more general term in translations, etc (Chuquet et al., 1989; Zhai et al., 2018). As total, there are 14 categories in translation relations, and more details can be seen in the part of Methodology in Section 3.</p>
</div>
</section>
<section class="ltx_subsection" id="S1.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.4 </span>Summary</h3>
<div class="ltx_para" id="S1.SS4.p1">
<p class="ltx_p" id="S1.SS4.p1.1">This dissertation analyzes translation obtained from an NMT system (GNMT) in comparison to human translations taking translation relation as the metric for translationese measurement. Specifically, this study examines how different HT and MT are from one another in terms of how translation relations are viewed; how much non-literal translation relations are used when translating using the NMT system; and what distinctions can be made between NMT and HT in terms of the variables that trigger the use of specific non-literal translation techniques. This dissertation is expected to serve as a basis for the further goal of optimizing NMT by reducing translationese from the perspective of translation relations to reach human parity or even the non-translated texts in target languages.
<br class="ltx_break"/>
<br class="ltx_break"/>To this end, source sentences in English obtained from the data set that was compiled by Zhai et al.(2018) are translated into Chinese through the GNMT system. In this way, there are two sets of parallel corpora of HT and MT with the source texts shared and target texts compared. In comparison, the aligned pairs which consists of token groups in English (the source language) and those their corresponding token groups in Chinese (the target language) are annotated with translation relations according to the translation relation annotation guidelines by Zhai et al. (2019). 
<br class="ltx_break"/>
<br class="ltx_break"/>After this section of induction, the following section collects related literature and work covering translationese, its features, translationese in machine translation, methods to optimize transationese, as well as translation relations in Section 2. Methodology and data sets are described in Section 3, and detailed data analyses are presented in Section 4. Finally, Section 5 will conclude. 
<br class="ltx_break"/></p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section"><span class="ltx_text" id="S2.2.1.1" style="color:#1E64C8;">2</span> </span><span class="ltx_text ltx_ulem_uline" id="S2.3.2" style="color:#1E64C8;">Related work</span>
</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">Some theories and previous work are applied into this work for theoretical basis, covering translationese’s definition and features, metrics for measuring translation quality, and translation relations.</p>
</div>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Translationese</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">Translationese refers to elements that are inherent in translations and may even be inescapable, as opposed to badly translated versions that emerge from a lack of translation expertise (Tirkkonen-Condit, 2002). Translationese in NMT and HT is compared, and is one main topic in this dissertation. In this section, translationese is discussed concerning its definition, features, its occurrence in machine translation and the its existence in HT and MT.</p>
</div>
<section class="ltx_subsubsection" id="S2.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.1.1 </span>Translationese definition</h4>
<div class="ltx_para" id="S2.SS1.SSS1.p1">
<p class="ltx_p" id="S2.SS1.SSS1.p1.1">There is a wealth of evidence from translation studies indicating works that have been translated are ontologically distinct from those non-translated texts in target languages. Any language that has been translated into another might be thought of as having its own dialect, or "translationese". The concept of translationese or its equivalence are developed in the following studies.
<br class="ltx_break"/></p>
</div>
<div class="ltx_para" id="S2.SS1.SSS1.p2">
<p class="ltx_p" id="S2.SS1.SSS1.p2.1">Selinker (1972) proposed the “interlanguage” which is defined as the utterances different from those by native speakers of the target language when second language learners attempted to utter the sentences of the target languages from their native languages. Interlanguage can be viewed as a distinct language when second-language learners have a grasp of the meaning of their mother tongue or source language, as opposed to the particular target language. 
<br class="ltx_break"/></p>
</div>
<div class="ltx_para" id="S2.SS1.SSS1.p3">
<p class="ltx_p" id="S2.SS1.SSS1.p3.1">Based on interlanguage theory, Frawley (1984) put forward the concept of the “third code”. He described the translation process as recodification from matrix code (source text) to target code (target text), and interlanguage is only a tiny part of the total information available in matrix code, called “semantic essence”. The conversion from the interlingual part from the matrix code to the target code needs the placement of semantic information of semiotic codes belonging to elements of the target matrix. Such semantic transfer is called the “third code", a totally new code derived from both matrix and target codes. The “third code” individuates itself with its logic. Frawley also argued that “fidelity” of the “third code” made translation unreadable, uninteresting, and unsuccessful.
<br class="ltx_break"/></p>
</div>
<div class="ltx_para" id="S2.SS1.SSS1.p4">
<p class="ltx_p" id="S2.SS1.SSS1.p4.1">The idea of a comparable corpus described by Baker (1995) as "two distinct collections of texts in the same language: one corpus consists of original texts in one language, while the other corpus consists of translations into that language from a particular source language or languages." The two corpora’s domains, languages, periods, and lengths should be comparable. Based on the concept of comparable corpus, Gellerstam (1986) compared the Swedish texts written by native speakers and translations from English to Swedish, and found that the source language leaves certain “fingerprints” from the source texts on the target language in the translation process. This phenomenon is termed as “translationese”. In addition, Gellerstam suggests that it might be caused by a difference in genre, such as a higher prevalence of detective novels in the translated corpus than in the original corpus (detective stories being often translated from English into Swedish) (Gellerstam, 1986, 1996).
<br class="ltx_break"/></p>
</div>
<div class="ltx_para" id="S2.SS1.SSS1.p5">
<p class="ltx_p" id="S2.SS1.SSS1.p5.1">Toury (2012) focused on the effects of interference, the process by which a specific source language leaves distinctive marks or fingerprints on the translation in the target language, so that translations from different source languages into the same target language may be regarded as other dialects of translationese.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S2.SS1.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.1.2 </span>Translationese features</h4>
<div class="ltx_para" id="S2.SS1.SSS2.p1">
<p class="ltx_p" id="S2.SS1.SSS2.p1.1">Translationese is pervasive in both HT and MT, and features of translationese are looked into for better understanding. 
<br class="ltx_break"/></p>
</div>
<div class="ltx_para" id="S2.SS1.SSS2.p2">
<p class="ltx_p" id="S2.SS1.SSS2.p2.1">(1) Overall features of translationese
<br class="ltx_break"/>Translationese is claimed to have some fixed linguistic features that tend to be shared in translation of different languages. Extralinguistic features in translational texts are excluded in the discussion of this dissertation. Translationese features are analyzed in several studies. Translationese features in translational English texts are identified with the reference of original English, and it shows that there are lower lexical density, fewer lemmas, and high repetition of high-frequency words (Laviosa, 1998). Baker (1993) proposed the universal features of translation or “translation universals” with more focus on the improvement of translations binding with more features on target language vis-à-vis source language. Specific translational features in translated texts have been contained in translation universal, including explicitness (Blum-Kulka, 1986), disambiguation and simplification (Vanderauwera, 1985), conventional ‘grammaticality’ (Shlesinger, 1991), repetition avoidance (Shlesinger, 1991; Toury, 1991), etc., which might be examined with similar corpora (Baker 1996). Consistent disparities between translated and original English’s lexical or syntactic structure without translators’ awareness were investigated. Olohan (2001) found that translations are more explicit than non-translations. The quantitative analysis experiment collects comments of intuitions on original writing texts, and concludes that lack of deviant or disturbing features was considered a mark of original writing and vice versa for translated language. Moreover, less unique items are another feature of translated texts (Tirkkonen-Condit, 2002). Santos (1995) sorted out several translationese features from the grammatical respect to syntax and tenses of Portuguese and English as research languages, and essential features are higher progressive, higher frequency of compact constructions, fewer tenses, and more locative details. Potential strategies have been used in translations such as explicitation and implications from Finish to English without ideological motivations (Puurtinen, 2003). 
<br class="ltx_break"/></p>
</div>
<div class="ltx_para" id="S2.SS1.SSS2.p3">
<p class="ltx_p" id="S2.SS1.SSS2.p3.1">Apart from traditional analyses, the methods of using machine learning and deep learning models also reveal some traits of translationese. Some potential factors include n-grams, word form, lemma, Part-of-Speech (POS) tagging, and elements mixed as features input into support vector machines (SVMs) (Baroni, 2006). The study shows that the distinctive contrast between the translated and original texts is primarily affected by function words and POS n-grams. Ilisei et al.’s (2010) study suggests that the most relevant features that distinguish translations from untranslated texts are lexical richness, the proportion of grammatical words to lexical words, sentence length, word length, and some morphological attributes like nouns, pronouns, finite verbs, conjunctions, and prepositions by using a supervised learning technique. Two lexical features, namely high-frequency words and function words are used to identify translationese (Nisioi et al., 2013). For the supervised classification of translationese, it has been demonstrated that lexical and structural aspects of the text, such as characters, POS, and contextual function words, are useful. (Volansky et al., 2015). The unsupervised learning approach is used for translationese classification by using domain-based properties over translationese-related characteristics including function words, character trigrams, POS trigrams, contextual function words, and cohesive markers (Rabinovich et al., 2015). The study demonstrates the dominance of domain-specific properties over the characteristics of translationese. By observations and analyses for Hebrew, features at the word and sub-word level are selected as input features for translationese classification including token-based features (word unigram and function words), morphological aspects (Hebrew verbal patterns, status, progressive and prefix), n-grams, features that approximate word structure, and features above combined (Avner et al., 2016). 
<br class="ltx_break"/></p>
</div>
<div class="ltx_para" id="S2.SS1.SSS2.p4">
<p class="ltx_p" id="S2.SS1.SSS2.p4.1">(2) Translationese features in translated Chinese texts
<br class="ltx_break"/><span class="ltx_ERROR undefined" id="S2.SS1.SSS2.p4.1.1">{CJK}</span>UTF8gbsnCharacteristics of translationese in Chinese translated from English are summarized and analyzed. Function words, as translationese, are examined between statistical machine-translated Chinese and original Chinese. Generally, translationese in the translated Chinese texts lies in tenses, sentence kinds (questions or assertions), passive voice, genitive cases, and normalization. More specific phenomenon for translationese are discussed in some work. Kuo (2019) suggested that in machine-translated Chinese, there are overuses of “de" (的, “of” in English) which can be omitted in the adjective-noun combination, and noun phrases, “he”(和, “and” in English), “shi”(是, “is” in English), etc.; also there is under-use of non-existence type such as lái (来, connecting two verb phrases), adverb and preposition categories like yě (也,“also” in English), and postpositions such as děng (等, “etc.” in English). The use of third-person pronouns which are not commonly seen in non-translated Chinese texts was also found with higher frequency in the SMT texts (Kuo, 2019). Lin (2019) made a summary of Chinese translationese from the differences between English and Chinese on vocabulary including the range of meaning of a word, POS, and the word order. Language styles are also discussed in the study that original Chinese texts tend to use more verbs compared to the weakening of verbs in English, and barely use less logical relations with connectives; English commonly employs the passive voice, but Chinese virtually ever does, and Chinese sentences often utilize a positive voice and follow the standard sentence structure. Hu et al. (2018) use syntactic characteristics alone to successfully identify translated from original Chinese with the features of various forms of constituent and dependency parses; In Hu’s study, the translated Chinese, for instance, uses additional determiners, subject-position pronouns, NP modifiers including "的" and numerous NPs or VPs connected by the "、" which is a punctuation mark in Chinese.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S2.SS1.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.1.3 </span>Machine translation translationese</h4>
<div class="ltx_para" id="S2.SS1.SSS3.p1">
<p class="ltx_p" id="S2.SS1.SSS3.p1.1">With the rise of machine translation, its translation quality is a topic and many studies have done to improve it. Although there has been continuous optimization for machine translation quality, the translationese still exists in machine translation caused by different machine translation systems. Therefore, translationese caused by machine translation systems can also be called machine translationese. There are basically three types of machine translation systems, namely rule-based machine translation (RBMT), statistical machine translation (SMT), and neural machine translation (NMT). Different type has its own features in translationese. There are some work related to translationese in these three different machine translation systems. 
<br class="ltx_break"/></p>
</div>
<div class="ltx_para" id="S2.SS1.SSS3.p2">
<p class="ltx_p" id="S2.SS1.SSS3.p2.1">(1) Rule-based machine translation
The traditional machine translation features rule-based machine translation (RBMT), also named the knowledge-based or linguistics-oriented approach (Hutchins, 1995), which converts the source languages to target languages based on the linguistics-based rules specified by humans. These rules are largely extracted from monolingual, bilingual, and multilingual dictionaries and grammars containing semantic, syntactic, and morphological regulations.</p>
</div>
<div class="ltx_para" id="S2.SS1.SSS3.p3">
<p class="ltx_p" id="S2.SS1.SSS3.p3.1">For the translation quality, RBMT generally produces the target language featuring consistency and stability without relying on a large bilingual corpus as the translation process strictly abides by the stipulated regulations. RBMT outperforms both NMT and SMT for verb tense, aspect, and mood, as well as ambiguity, according to Burchardt et al. (2017)’s comparison of NMT to both SMT and RBMT in German-to-English and English-to-German. Most post-editing or translationese is caused by the second person forms and the deletion of redundant personal pronouns as subjects or possessives in the RBMT output. Fluency is a known problem for RBMT, especially in the case of Finnish, excessive usage of redundant pronouns, for instance, may cause the language to sound stiff and unnecessarily literal (Koponen et al., 2019).</p>
</div>
<div class="ltx_para" id="S2.SS1.SSS3.p4">
<p class="ltx_p" id="S2.SS1.SSS3.p4.1">(2) Statistical machine translation
The fundamental concept behind statistical machine translation is to create a statistical translation model by statistically analyzing large amount of parallel corpora for training a model, and then to utilize this model for translation (Lopez, 2008). The phrase-based machine translation has replaced the earlier word-based translation, and has incorporates syntactic data to increase translation accuracy (Och et al., 2000).</p>
</div>
<div class="ltx_para" id="S2.SS1.SSS3.p5">
<p class="ltx_p" id="S2.SS1.SSS3.p5.1">However, several studies show that there are translation problems for SMT system. Nießen (2000) suggested that translation problems lies in idiomatic expressions, compound words that have to be translated by more than one word, long dependencies, and ambiguous words with different meanings depending on contexts. Compared to neural translations, phrase-based SMT has more translation errors in fluency and accuracy than NMT for English-Dutch parallel corpora according to Van Brussel et al. (2018). Besides, statistical engines provide clearer evidence of syntactic simplification produced by phrase-based SMT (Bizzoni et al., 2020).</p>
</div>
<div class="ltx_para" id="S2.SS1.SSS3.p6">
<p class="ltx_p" id="S2.SS1.SSS3.p6.1">(3) Neural machine translation
The state-of-the-art NMT approach is based on the transformer network (which is also an encoder-decoder approach). According to Wang et al.(2021), NMT has become the method of choice in the MT community as a result of these benefits. In the study of Aranberri (2020), the differences in translationese in the translation output produced by different MT systems (4 NMT systems and 1 RBMT system) are compared. Certain translationese features such as lexical variety, lexical density, length ratio, and POS sequence are analyzed, and the results show that NMT systems such as Google Translate and EJ-RBMT can render less translationese with these features as metrics compared with RBMT system. These features are called language-independent features; while Isabelle et al. (2017) made analyses of translationese on language-specific features, such as word concordance and insertion of words (De Clercq et al., 2021). In this study, machine translationese was examined by using the translation output produced by one SMT and three NMT systems. Five language-independent characteristics serve as the metrics for the differentiation between the original and machine-translated French, and the result shows that texts that have been machine translated frequently use the same word combination; the type-token ratios in machine translated texts are lower than reference non-translated texts (De Clercq et al., 2021). NMT performs best on a variety of features like coordination and ellipsis, multi-word expressions, long-distance dependencies, and named entities (Burchardt et al., 2017). The research by Toral et al. (2017) examined six languages from four different families (Germanic, Slavic, Romance, and Finno-Ugric), and they discovered that for all language directions outside English, the best NMT system outperformed the best phrase-based SMT system. Bizzoni et al. (2020) suggested that SMT produces over-simplified structures, while neural systems seem able to deal better with the complexity of their source. According to Jia et al. (2019), NMT delivers translations with greater quality than phrase-based SMT for both simple and complex texts.</p>
</div>
<div class="ltx_para" id="S2.SS1.SSS3.p7">
<p class="ltx_p" id="S2.SS1.SSS3.p7.1">Although their findings indicated that NMT systems have better performance than other machine translation systems, NMT performed badly when translating extremely long sentences (Toral et al., 2017). Recent error assessments reveal that NMT decreases many sorts of mistakes and generates more fluent output, particularly in morphologically rich languages like Czech, Finnish, Serbian, and Croatian (Klubička et al., 2017; Toral et al, 2017). When comparing the number of necessary edits, NMT can be shown to minimize word order mistakes compared to both the SMT and RBMT outputs (Koponen et al., 2019). However, some research (e.g. Castilho et al. 2017) has suggested that fewer word order and word form errors increase the fluency of NMT, but not necessarily the adequacy and that this improving fluency may produce more misleading translations because NMT may produce grammatically correct sentences that do not match the meaning of the source text. However, according to Koponen et al. (2019), such reductions are lower in NMT(2.2.%) than in RBMT (3.3%) or SMT (2.7%). In machine translationese feature analysis, transformer models perform better than phrase-based SMT (PB-SMT) and LSTM in terms of lexical and morphological diversity. The ratings for PB-SMT, LSTM, and transformer differ much less than those for original texts, demonstrating that the MT systems have a more detrimental effect on the morphologically richer languages (in terms of diversity and richness) (Vanmassenhove et al., 2021).</p>
</div>
</section>
<section class="ltx_subsubsection" id="S2.SS1.SSS4">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.1.4 </span>Machine tranlationese v.s. human translationese</h4>
<div class="ltx_para" id="S2.SS1.SSS4.p1">
<p class="ltx_p" id="S2.SS1.SSS4.p1.1">Translationese exists in both MT and HT. Therefore, the comparison between MT and HT can also be seen as that between machine translationese and human translationese. There are studies showing such comparisons. Popel et al. (2020) suggested that CUBBITT model which is deep-learning based fared noticeably better than professional agencies translating English to Czech news in terms of maintaining text meaning (translation adequacy) when translation adequacy, fluency, and overall translation quality of both MT and HT are inspected by evaluators. However, some other studies show that MT is overall worse than HT in terms of translationese comparison . Automatic classification between MT and HT based on lexical diversity was done by Fu et al. (2021) with the factor of accuracy above the chance level. Translationese across human and machine translations from text and speech is compared by using POS perplexity and dependency length to conclude that machine translation can over-correct translationese effects, not following the characteristics of training data. Also, the neural systems’ translations were found often more sophisticated yet near to the HTs, or to the originals, and machine translation usually exhibits higher degrees of structural interference from source languages and lower levels of adherence or over-adherence to the target language’s standards than human translation (Bizzoni et al., 2020). Vanmassenhove et al. (2019) found that compared to the text produced by humans, the MT process often results in a loss in lexical diversity and richness. Several observations on MT output compared to HT from English to Dutch are that a significant number of the MT translated sentences were flawed; there were less lexical variety and local coherence in NMT; NMT are more likely to mimic the source sentence’s grammatical structure; besides, the style of HT differs from that of MT (Webster et al., 2020).</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Metrics for translation quality</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">Translation metric is a kind of method to evaluate the translation quality. In the past decades, many metrics have been developed for translation evaluation. There are many translation metrics nowadays containing automated metrics and human metrics. Although Chatzikoumi (2020) claimed that two types of metrics are in practice not distinguishable as human labor work and machine calculation are interwoven, the pros and cons of each metric are analyzed in the following section.</p>
</div>
<section class="ltx_subsubsection" id="S2.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.2.1 </span>Automatic evaluation of machine translation</h4>
<div class="ltx_para" id="S2.SS2.SSS1.p1">
<p class="ltx_p" id="S2.SS2.SSS1.p1.1">Automated metrics for evaluating translation quality are convenient, relying on computational calculation to reduce labor work and improve efficiency. Reference-based translation metrics is one type which includes some measuring approaches based on the ideas of edit distance and precision and recall (Chatzikoumi, 2020). There is Levenshtein’s distance which focuses on the differences of sentences on the character level by calculating the sum of edit operations from one sentence to another (Levenshtein, 1966), and it is developed into concentrating on words rather than character (EuroMatrix, 2007). Based on the idea of Levenshtein’s distance, there are Word Error Rate (WER) (Nießen et al., 2000) and Translation Edit Rate (TER) (Snover et al., 2006) to calculate differences between translation and its reference sentences. The most often employed precision-based metric is the bilingual evaluation understudy (BLEU) (Papineni et al., 2002) which compares adequacy and fluency between reference sentences and translated output by using word n-gram with the score of from 0 to 1 as a measurement of closeness. However, there is no differentiation between translations with extremely low scores in low quality or highly free translations (Coughlin, 2003), and the failure to distinguish subtleties (Lavie, 2010). The use of lemmatization, synonymization, stemming, and paraphrasing is another kind of method that is different from the reference-based approach (Callison-Burch et al., 2006). Different from reference-based metrics, quality estimation (QE) metrics can classify translation into a good or bad translation without references. It mainly extracts features from source and target sentences from the perspective of complexity, fluency and adequacy, concerning the calculation of tokens, POS tagging, dependency relations, etc. (Specia et al., 2013). Besides, there are some other methods and metrics optimized and developed. CHRF (Popović, 2015) utilizes character-level n-gram to identify morphological differences. Lo (2019) determined semantic similarities of phrases in translation output with reference, namely YISI-1, and there is also its variant YISI-2. There are some other metrics involving more linguistic information. Popovic et al. (2011) calculate the similarity scores of source and target (translated) sentences based on the probabilities of morphemes, 4-gram POS, and lexicon. The bilingual phrase tables’ synonyms and the POS data from the matching task were used to create the TESLA assessment measures by Dahlmeier et al. (2011). Vanroy et al. (2021) combined dependency relations with word reordering to calculate word cross nodes, called SACr. They also proposed aligned syntactic tree edit distance (ASTrED) which aligns source and target dependency tree and calculate the edit distance between dependency parsed trees. Named entity knowledge is drawn from the literature on named-entity recognition, which seeks to recognize and categorize atomic elements in a text into distinct entity categories, to capture the semantic equivalence of sentences or text fragments (Marsh et al., 1998; Guo et al., 2009). Neural networks is used on translation quality assessment for pair-wise modeling to compare potential translations with a reference and select the best hypothetical translation by combining syntactic and semantic information into Neural networks (Guzmán et al., 2017). The BERTScore metric was proposed by Zhang et al. (2019) and is based on contextual embedding. It gets around the typical drawbacks of n-gram-based metrics (such as synonyms and paraphrases), allows translations that are different from the references, and can evaluate the accuracy of a translation model in a contextual embedding space.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S2.SS2.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.2.2 </span>Traditional metrics</h4>
<div class="ltx_para" id="S2.SS2.SSS2.p1">
<p class="ltx_p" id="S2.SS2.SSS2.p1.1">There are no absolute standards of translation excellence; there are only translations that are more or less appropriate for the context in which they are employed, according to Sager (1989). The establishment of such external criteria of translation quality is challenging, thus it is typical to choose a more constrained approach, focusing on the intrinsic features of translated texts and on translation errors as a means of measuring quality (Secară, 2005). Many ideas have been proposed to characterize translation assessment in the past century. According to Nida (1964), the translation should be “dynamic” to conform to the different target audiences, and good translations are those in which the reader’s response coincides with that of native speakers of the source language. Vermeer (2021) proposed the “skopos theory”, and he stressed that each text is created with a certain purpose, and when the purpose is fulfilled, the translation is a good translation. Peter Newmark (1981) distinguished between communicative translation (word-for-word) and semantic translation (sense-for-sense). According to him, communicative translation is biased toward the target language, free, and idiomatic, whereas semantic translation is biased toward the source language, literal, and loyal to the original material. The aim of a semantic translation is to preserve the exact contextual meaning of the original by adhering as closely as possible to the semantic and syntactic structures of the source language. The objective of a communicative translation is to have the same impact on the audience that the original had on its readers (Newmark, 1988). Lauscher (2000) proposed equivalence-based and function-based approaches for translation quality assessment. 
<br class="ltx_break"/></p>
</div>
<div class="ltx_para" id="S2.SS2.SSS2.p2">
<p class="ltx_p" id="S2.SS2.SSS2.p2.1">However, the theories above are elusive for translators, and specific and standard metrics are explored. 22 types of translation errors are stipulated by American Translators Association ranging from terminology and register to accents and diacritical marks (Secară, 2005). Point scale schema is designed to measure accuracy and fluency, and there are five-point scales (Callison-Burch et al., 2007) and seven-point ones (Przybocki et al., 2009). However, due to anomalies in the five-point scale, the adequacy and fluency metrics have been completely abandoned in the Workshop on Statistical Machine Translation assessments (Bojar et al., 2016). Human UCCA-Based MT Assessment (HUME), a semantic evaluation measure suggested by Birch et al. (2016), is another method of evaluating adequacy. Appraise (Federmann, 2010) is an open-source application that allows users to conduct MT assessment annotation activities concerning ranking. Direct Assessment involves the expression of a judgment of the quality of the MT output in a continuous rating scale (Graham et al., 2015), and it can capture the extent to which one translation is better than another rather than ranking interval-level scales (Graham et al., 2013). It is often used along with post-editing (Bentivogli et al., 2018). Tezcan et al. (2017) proposed a translation error identification guideline which specifies accuracy errors such as addition, omission and the untranslated and fluency errors like word form and word order in grammatical level and spelling in orthographic level. Based on it, an annotation tool named Smart Computer-aided Translation Environment (SCATE) where accuracy errors such as and fluency errors such as can be annotated is proposed.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Translation relations</h3>
<div class="ltx_para" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.1">No matter in MT or HT, there is always translationese in the translated texts which has discrepancies to original non-translated texts in target languages or human parity. To reach Human parity or even non-translated texts in target languages is the ultimate phrase in the translation process after the translationese reduction. The application of translation relation is one of good approaches to narrow such discrepancies and help reduce translationese in HT and may in MT. Before translation relation is applied to reduce translationese in MT, it can be checked and detected in MT to see how and how much it is used in MT.</p>
</div>
<section class="ltx_subsubsection" id="S2.SS3.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.3.1 </span>Translation relations</h4>
<div class="ltx_para" id="S2.SS3.SSS1.p1">
<p class="ltx_p" id="S2.SS3.SSS1.p1.1">According to Krings (1986), translation strategies were defined as a “potentially conscious plan for solving translation problems”. He built a tentative model of the translation process covering translation problems and translation strategies as solutions. For example, if the problem is not of “potential equivalence”, “retrieval strategy” would be used. Van Leuven-Zwart (1990) investigated translational norms, methods, and strategies adopted by translators, and concluded that “generalization” is less frequently used than “specification”, and source language oriented translation is more than target language oriented translation. The strategy of foreignization was explored and found in dominance in the translation of cultural texts (Kwieciñski, 1998). Translation strategies "involve the fundamental tasks of picking the foreign material to be translated and establishing a technique to translate it," according to Venuti (2000). He uses the terms "domesticating" and "foreignizing" to discuss translation techniques. Strategies are "a collection of skills, a set of activities or processes that favor the capture, storage, and/or exploitation of the information," according to Jääskeläinen (1999). According to him, strategies are "flexible and heuristic in character and their adoption indicates a decision affected by revisions in the translator’s aims.” Newmark (1998) summed several translation methods or strategies from the whole text or the macro level including word-for-word translation, literal translation, faithful translation, semantic translation, adaption, free translation, idiomatic translation, and communicative translation. 
<br class="ltx_break"/></p>
</div>
<div class="ltx_para" id="S2.SS3.SSS1.p2">
<p class="ltx_p" id="S2.SS3.SSS1.p2.1">When translation strategies and methods are applied to the translation process, translation tactics or techniques are worth mentioning. There are five features of translation techniques: “affecting translation output, classified by comparison with the original, affecting micro-level unit, discursive and contextual, and functional” (Molina et al., 2002). As Newmark (1998) mentioned that translation process or “procedure” is within “the sentence or the smaller units of language”. He classified different translation procedures covering transference, neutralization, cultural equivalent, functional equivalent, descriptive equivalent, componential analysis, synonymy, through-translation, shifts or transpositions, modulation, recognized translation, paraphrase, couplets, and notes. Molina et al. (2002) specified literal translation based on Newmark’s translation procedure, and they defined it into three sub-categories including borrowing, claque, and literal translation; transposition, modulation, equivalence, and adaption belong to the category of oblique translation which happens when the word-for-word translation is impossible. They also summed seven opposing pairs as Explicitation vs. Implicitation, Generalization vs. Particularization, and Reinforcement vs. Condensation. Based on all these translation techniques, translation relation, a kind of interlingual relation, was proposed to categorize translation techniques aside from literal translation (Vinay et al,, 1958; Chuquet et al., 1989; Zhai et al., 2018). Vinay et al. (1958; Zhai et al., 2018) were the ones who originally postulated and created a taxonomy of translation procedures. Based on theories that Chuquet et al.’s (1989; Zhai et al., 2018) work has clarified, there is a hierarchy of translation relations. This hierarchy of translation relations is used in this dissertation as a guideline, and more details are to be declared in Section 3.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S2.SS3.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.3.2 </span>Non-literal translation in NMT</h4>
<div class="ltx_para" id="S2.SS3.SSS2.p1">
<p class="ltx_p" id="S2.SS3.SSS2.p1.1">There are researches and studies into translation techniques that are displayed in the machine-translation output. Machine translation systems are prone to use more literal translation technique which may cause stiff, unnatural and even wrong translation. Machine translation with “literal” translation as the dominance in the 1990s for idioms was proposed as inappropriate (Volk, 1998). Literal translation by machine translation systems was thought to be notorious when they translated idioms (Hutchins, 1995). Literal translation mistakes are thought to represent a significant category of idiom-related translation problems (Manojlović et al., 2017; Shao et al., 2018). 
<br class="ltx_break"/></p>
</div>
<div class="ltx_para" id="S2.SS3.SSS2.p2">
<p class="ltx_p" id="S2.SS3.SSS2.p2.1">Therefore, non-literal translation techniques applied in machine translation or specifically in NMT are more focused in this dissertation. Non-literal translation exists because it is standard procedure in translation for the translator to select a non-literal translation in light of factors like naturalness, discourse coherence, and other factors (Deng et al., 2017). Non-literal translations produced by humans reflect the diversity of human languages and are occasionally necessary to maintain accuracy and fluency (Zhai, 2020). For translation relations used in NMT, most studies are on idiom translation problems caused by literal translation. The fact is that most of idioms are translated with non-literal translation techniques, but according to the evaluation for the language model of Transformer of NMT (Dankers et al., 2022), Transformer’s tendency to process idioms as compositional expressions contributes to literal translations of idioms. In order to make the idiom translated correctly, Fadaee et al. (2018) retrieved sentences containing idioms and mixed them with non-idiom phrases as a training data set to train the NMT. Apart from idioms, some other literal translation problem are studied. For example, Gamallo et al. (2021) suggested that the large amount used of literal translation causes transferring the constructions of the source language to the target language, and they proposed to use monolingual corpora instead of parallel ones with unsupervised translation can make the hybrid SMT plus NMT system produce more non-literal translation output on passive voice structured sentences. 
<br class="ltx_break"/></p>
</div>
<div class="ltx_para" id="S2.SS3.SSS2.p3">
<p class="ltx_p" id="S2.SS3.SSS2.p3.1">According to studies mentioned above, most studies only concentrate themselves on one translation problem (idiom translation) caused by using large amount of literal translation. However, there is few work involving the all translation techniques in NMT. Apart from literal translation, there are several non-literal translation techniques that can be analyzed and detected in NMT to see how these non-literal techniques are used in NMT. In this case, this dissertation focuses on the application of both literal translation and specific non-literal translation techniques in NMT.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section"><span class="ltx_text" id="S3.2.1.1" style="color:#1E64C8;">3</span> </span><span class="ltx_text ltx_ulem_uline" id="S3.3.2" style="color:#1E64C8;">Methodology</span>
</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">In this section, some methodologies<span class="ltx_note ltx_role_footnote" id="footnotex2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>Data and codes available at https://github.com/louisefz/translation_relations .</span></span></span> which applied into this dissertation are introduced, including translationese comparison, translation relations as an annotation guideline, and some language-independent and language-specific metrics for supplementary measurement.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Translationese comparison</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">This part introduces the used data, how the data is formed into machine translationese (MTionese) and human translationese (HTionese), and the comparison between MTionese and HTionese.</p>
</div>
<section class="ltx_subsubsection" id="S3.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.1 </span>Data source</h4>
<div class="ltx_para" id="S3.SS1.SSS1.p1">
<p class="ltx_p" id="S3.SS1.SSS1.p1.1">The experiment is based on the comparison between MT and HT, and therefore, there are two parallel corpora which consists of a set of texts in the source language and their translations in the target language: one is the source text and its translation by human translators which is defined as HT data, and the other is the source text which is shared with that of HT data and its translation created by Google Translate<span class="ltx_note ltx_role_footnote" id="footnotex3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>The translation in this study is produce in May, 2022 by Google Translate (https://translate.google.com/).</span></span></span>, which can be called MT data. For HT data, both source and target data are from Zhai et al. (2020). This existing data is from a new corpus of bilingual parallel texts they built, which covers eleven genres of texts including art, literature, law, material for education, microblog, news, official document, spoken, subtitles, science, and scientific article. The translation direction is all from English to Chinese for each genre except for the genre of scientific articles whose translation direction is from Chinese to English. However, for this kind of genre, I have changed the direction of the translation so as to ensure the target language is all Chinese, making it consistent for both parallel corpora. The source of the existing data from Zhai et al. is sampled from several different bilingual corpora which have their own features are employed covering UM-corpus (Tian et al., 2014), UT-corpus (Liu et al., 2015), UB-corpus (Chang, 2004), UnitedNations-corpus (Ziemski et al., 2016), and online bilingual journals (Zhai et al., 2020). For genres of news, literature, art, scientific article, and official documents, they are from the corpora of UT-corpus, UB-corpus, UB-corpus, own construction, and UnitedNations-corpus; as to the law, material for education, microblog, spoken, subtitles and science, they are collected from UM-corpus. The newly-built corpus has a total of 2200 pairs of bilingual sentences with high-quality human translation.</p>
</div>
<div class="ltx_para" id="S3.SS1.SSS1.p2">
<p class="ltx_p" id="S3.SS1.SSS1.p2.1">The work in this dissertation uses the data from the experiment of automatic classification for translation relations from English to Chinese by Zhai et al. (2020), and there are 9 genres covering education, law, scientific article, microblog, news, official document, science, spoken and subtitles. Each genre contains 50 sentences except for that of microblog which has 53 sentences, and there are 453 pairs of sentences in total. For MT data, the source texts in English are the same as the source data of HT data.</p>
</div>
<div class="ltx_para" id="S3.SS1.SSS1.p3">
<p class="ltx_p" id="S3.SS1.SSS1.p3.1">After HT and MT data is prepared, both its source sentences and translation are tokenized. As for HT data, both source and target sentences has been tokenized by Zhai et al. (2020). Standford Tokenizer is used for tokenization of source texts in English, and THULAC (Li et al., 2009) is for tokenization of translation in Chinese. Since the tokenizer is not 100% accurate, there are manual corrections by the annotator when checking and reviewing data. However, there are still some minute mistakes as the Chinese language, different from English, is more complicated for tokenization. Therefore, on the prerequisite of abiding by the tokenization principle of the Chinese language, there is some degree of intuition by the annotator.</p>
</div>
<div class="ltx_logical-block" id="S3.SS1.SSS1.1">
<div class="ltx_para" id="S3.SS1.SSS1.1.p1">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S3.SS1.SSS1.1.p1.1">
<tr class="ltx_tr" id="S3.SS1.SSS1.1.p1.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S3.SS1.SSS1.1.p1.1.1.1" style="padding-left:19.9pt;padding-right:19.9pt;">      <span class="ltx_text" id="S3.SS1.SSS1.1.p1.1.1.1.1"></span><span class="ltx_text" id="S3.SS1.SSS1.1.p1.1.1.1.2">
<span class="ltx_tabular ltx_align_middle" id="S3.SS1.SSS1.1.p1.1.1.1.2.1">
<span class="ltx_tr" id="S3.SS1.SSS1.1.p1.1.1.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S3.SS1.SSS1.1.p1.1.1.1.2.1.1.1" style="padding-left:19.9pt;padding-right:19.9pt;">      Genre</span></span>
</span></span><span class="ltx_text" id="S3.SS1.SSS1.1.p1.1.1.1.3"></span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.SS1.SSS1.1.p1.1.1.2" style="padding-left:19.9pt;padding-right:19.9pt;">      <span class="ltx_text" id="S3.SS1.SSS1.1.p1.1.1.2.1"></span> <span class="ltx_text" id="S3.SS1.SSS1.1.p1.1.1.2.2">
<span class="ltx_tabular ltx_align_middle" id="S3.SS1.SSS1.1.p1.1.1.2.2.1">
<span class="ltx_tr" id="S3.SS1.SSS1.1.p1.1.1.2.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.SS1.SSS1.1.p1.1.1.2.2.1.1.1" style="padding-left:19.9pt;padding-right:19.9pt;">      Source token number</span></span>
</span></span><span class="ltx_text" id="S3.SS1.SSS1.1.p1.1.1.2.3"></span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.SS1.SSS1.1.p1.1.1.3" style="padding-left:19.9pt;padding-right:19.9pt;">      <span class="ltx_text" id="S3.SS1.SSS1.1.p1.1.1.3.1"></span> <span class="ltx_text" id="S3.SS1.SSS1.1.p1.1.1.3.2">
<span class="ltx_tabular ltx_align_middle" id="S3.SS1.SSS1.1.p1.1.1.3.2.1">
<span class="ltx_tr" id="S3.SS1.SSS1.1.p1.1.1.3.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.SS1.SSS1.1.p1.1.1.3.2.1.1.1" style="padding-left:19.9pt;padding-right:19.9pt;">      MT token number</span></span>
</span></span><span class="ltx_text" id="S3.SS1.SSS1.1.p1.1.1.3.3"></span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt" id="S3.SS1.SSS1.1.p1.1.1.4" style="padding-left:19.9pt;padding-right:19.9pt;">      <span class="ltx_text" id="S3.SS1.SSS1.1.p1.1.1.4.1"></span> <span class="ltx_text" id="S3.SS1.SSS1.1.p1.1.1.4.2">
<span class="ltx_tabular ltx_align_middle" id="S3.SS1.SSS1.1.p1.1.1.4.2.1">
<span class="ltx_tr" id="S3.SS1.SSS1.1.p1.1.1.4.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.SS1.SSS1.1.p1.1.1.4.2.1.1.1" style="padding-left:19.9pt;padding-right:19.9pt;">      HT token number</span></span>
</span></span><span class="ltx_text" id="S3.SS1.SSS1.1.p1.1.1.4.3"></span></td>
</tr>
<tr class="ltx_tr" id="S3.SS1.SSS1.1.p1.1.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.SS1.SSS1.1.p1.1.2.1" style="padding-left:19.9pt;padding-right:19.9pt;">      education</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.SS1.SSS1.1.p1.1.2.2" style="padding-left:19.9pt;padding-right:19.9pt;">      1021</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.SS1.SSS1.1.p1.1.2.3" style="padding-left:19.9pt;padding-right:19.9pt;">      981</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S3.SS1.SSS1.1.p1.1.2.4" style="padding-left:19.9pt;padding-right:19.9pt;">      999</td>
</tr>
<tr class="ltx_tr" id="S3.SS1.SSS1.1.p1.1.3">
<td class="ltx_td ltx_align_left" id="S3.SS1.SSS1.1.p1.1.3.1" style="padding-left:19.9pt;padding-right:19.9pt;">      laws</td>
<td class="ltx_td ltx_align_center" id="S3.SS1.SSS1.1.p1.1.3.2" style="padding-left:19.9pt;padding-right:19.9pt;">      1857</td>
<td class="ltx_td ltx_align_center" id="S3.SS1.SSS1.1.p1.1.3.3" style="padding-left:19.9pt;padding-right:19.9pt;">      1681</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.SS1.SSS1.1.p1.1.3.4" style="padding-left:19.9pt;padding-right:19.9pt;">      1648</td>
</tr>
<tr class="ltx_tr" id="S3.SS1.SSS1.1.p1.1.4">
<td class="ltx_td ltx_align_left" id="S3.SS1.SSS1.1.p1.1.4.1" style="padding-left:19.9pt;padding-right:19.9pt;">      microblog</td>
<td class="ltx_td ltx_align_center" id="S3.SS1.SSS1.1.p1.1.4.2" style="padding-left:19.9pt;padding-right:19.9pt;">      1108</td>
<td class="ltx_td ltx_align_center" id="S3.SS1.SSS1.1.p1.1.4.3" style="padding-left:19.9pt;padding-right:19.9pt;">      1160</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.SS1.SSS1.1.p1.1.4.4" style="padding-left:19.9pt;padding-right:19.9pt;">      1139</td>
</tr>
<tr class="ltx_tr" id="S3.SS1.SSS1.1.p1.1.5">
<td class="ltx_td ltx_align_left" id="S3.SS1.SSS1.1.p1.1.5.1" style="padding-left:19.9pt;padding-right:19.9pt;">      news</td>
<td class="ltx_td ltx_align_center" id="S3.SS1.SSS1.1.p1.1.5.2" style="padding-left:19.9pt;padding-right:19.9pt;">      1573</td>
<td class="ltx_td ltx_align_center" id="S3.SS1.SSS1.1.p1.1.5.3" style="padding-left:19.9pt;padding-right:19.9pt;">      1424</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.SS1.SSS1.1.p1.1.5.4" style="padding-left:19.9pt;padding-right:19.9pt;">      1398</td>
</tr>
<tr class="ltx_tr" id="S3.SS1.SSS1.1.p1.1.6">
<td class="ltx_td ltx_align_left" id="S3.SS1.SSS1.1.p1.1.6.1" style="padding-left:19.9pt;padding-right:19.9pt;">      officialDoc</td>
<td class="ltx_td ltx_align_center" id="S3.SS1.SSS1.1.p1.1.6.2" style="padding-left:19.9pt;padding-right:19.9pt;">      1713</td>
<td class="ltx_td ltx_align_center" id="S3.SS1.SSS1.1.p1.1.6.3" style="padding-left:19.9pt;padding-right:19.9pt;">      1538</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.SS1.SSS1.1.p1.1.6.4" style="padding-left:19.9pt;padding-right:19.9pt;">      1485</td>
</tr>
<tr class="ltx_tr" id="S3.SS1.SSS1.1.p1.1.7">
<td class="ltx_td ltx_align_left" id="S3.SS1.SSS1.1.p1.1.7.1" style="padding-left:19.9pt;padding-right:19.9pt;">      science</td>
<td class="ltx_td ltx_align_center" id="S3.SS1.SSS1.1.p1.1.7.2" style="padding-left:19.9pt;padding-right:19.9pt;">      975</td>
<td class="ltx_td ltx_align_center" id="S3.SS1.SSS1.1.p1.1.7.3" style="padding-left:19.9pt;padding-right:19.9pt;">      914</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.SS1.SSS1.1.p1.1.7.4" style="padding-left:19.9pt;padding-right:19.9pt;">      880</td>
</tr>
<tr class="ltx_tr" id="S3.SS1.SSS1.1.p1.1.8">
<td class="ltx_td ltx_align_left" id="S3.SS1.SSS1.1.p1.1.8.1" style="padding-left:19.9pt;padding-right:19.9pt;">      scientificArticle</td>
<td class="ltx_td ltx_align_center" id="S3.SS1.SSS1.1.p1.1.8.2" style="padding-left:19.9pt;padding-right:19.9pt;">      1367</td>
<td class="ltx_td ltx_align_center" id="S3.SS1.SSS1.1.p1.1.8.3" style="padding-left:19.9pt;padding-right:19.9pt;">      1300</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.SS1.SSS1.1.p1.1.8.4" style="padding-left:19.9pt;padding-right:19.9pt;">      1288</td>
</tr>
<tr class="ltx_tr" id="S3.SS1.SSS1.1.p1.1.9">
<td class="ltx_td ltx_align_left" id="S3.SS1.SSS1.1.p1.1.9.1" style="padding-left:19.9pt;padding-right:19.9pt;">      spoken</td>
<td class="ltx_td ltx_align_center" id="S3.SS1.SSS1.1.p1.1.9.2" style="padding-left:19.9pt;padding-right:19.9pt;">      703</td>
<td class="ltx_td ltx_align_center" id="S3.SS1.SSS1.1.p1.1.9.3" style="padding-left:19.9pt;padding-right:19.9pt;">      666</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.SS1.SSS1.1.p1.1.9.4" style="padding-left:19.9pt;padding-right:19.9pt;">      691</td>
</tr>
<tr class="ltx_tr" id="S3.SS1.SSS1.1.p1.1.10">
<td class="ltx_td ltx_align_left" id="S3.SS1.SSS1.1.p1.1.10.1" style="padding-left:19.9pt;padding-right:19.9pt;">      subtitles</td>
<td class="ltx_td ltx_align_center" id="S3.SS1.SSS1.1.p1.1.10.2" style="padding-left:19.9pt;padding-right:19.9pt;">      599</td>
<td class="ltx_td ltx_align_center" id="S3.SS1.SSS1.1.p1.1.10.3" style="padding-left:19.9pt;padding-right:19.9pt;">      592</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.SS1.SSS1.1.p1.1.10.4" style="padding-left:19.9pt;padding-right:19.9pt;">      526</td>
</tr>
<tr class="ltx_tr" id="S3.SS1.SSS1.1.p1.1.11">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S3.SS1.SSS1.1.p1.1.11.1" style="padding-left:19.9pt;padding-right:19.9pt;">      Total</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.SS1.SSS1.1.p1.1.11.2" style="padding-left:19.9pt;padding-right:19.9pt;">      10916</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.SS1.SSS1.1.p1.1.11.3" style="padding-left:19.9pt;padding-right:19.9pt;">      10256</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb" id="S3.SS1.SSS1.1.p1.1.11.4" style="padding-left:19.9pt;padding-right:19.9pt;">      10054</td>
</tr>
</table>
</div>
</div>
<div class="ltx_para" id="S3.SS1.SSS1.p4">
<p class="ltx_p ltx_align_center" id="S3.SS1.SSS1.p4.1">Table 3 Token number of each genre in source texts, machine translated texts, and human translated texts</p>
</div>
<div class="ltx_para" id="S3.SS1.SSS1.p5">
<p class="ltx_p" id="S3.SS1.SSS1.p5.1">The source text in English has 10916 tokens, while HT Chinese and MT Chinese texts have 10054 and 10256 tokens respectively. More details of token number of each genre shows in Table 3. Overall, the number of English tokens is more than that of the rest two Chinese data sets, which is a regular phenomenon. However, the HT Chinese tokens are less than MT Chinese tokens except for the genres of education and spoken.</p>
</div>
<figure class="ltx_figure" id="S3.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="249" id="S3.F1.g1" src="extracted/2404.08661v1/1.png" width="476"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Figure 1: The number of tokens in each sentence of each genre in three corpora</figcaption>
</figure>
<div class="ltx_para" id="S3.SS1.SSS1.p6">
<p class="ltx_p" id="S3.SS1.SSS1.p6.1">The number of tokens in each sentence is calculated, and Figure 1 reflects the distribution of tokens in each sentence of different genres and data sets. Three data sets in all are evenly distributed in each genre. For genres of laws, news, officialDoc, and scientificArticle, the sentence lengths are not stable, and these genres contain more long sentences.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS1.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.2 </span>MTionese v.s. HTionese</h4>
<div class="ltx_para" id="S3.SS1.SSS2.p1">
<p class="ltx_p" id="S3.SS1.SSS2.p1.1">There are two sets of data, one is HT data, and the other is MT data. The translation in both HT data and MT data can be seen as translationese as both of them have discrepancies from the non-translated texts in the target language. Therefore, there are machine translationese (MTionese) and human translationese (HTionese). In this work, these two types of translationese are compared to find more if NMT reaches the human parity in terms of translation relations.</p>
</div>
<div class="ltx_para" id="S3.SS1.SSS2.p2">
<p class="ltx_p" id="S3.SS1.SSS2.p2.1">Translation relations which referes to the relations between different translation techniques can be equivalent to translation techniques. The application of translation relations into translation process can optimize the translation quality and reduce translationese. Concepts on translation relations and translation techniques are clarified in the following part. In this dissertation, the translation relation or technique is seen as a metric to measure translationese in both MT and HT data. The use of translation relations in the translation of HT and MT data is compared to see whether the performance of using translation relations in MT data is better, worse than, or equivalent to that in HT data.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Translation relations</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">Translation relations or translation techniques can help improve translation quality and reduce translationese in the process of translation. In this part, translation relations as a metric for measuring translationese in both HT and MT data and as a guideline of annotation will be specified.</p>
</div>
<section class="ltx_subsubsection" id="S3.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.1 </span>Details of translation relations</h4>
<div class="ltx_para" id="S3.SS2.SSS1.p1">
<p class="ltx_p" id="S3.SS2.SSS1.p1.1">Translation relation, a kind of interlingual relation, is defined to categorize translation techniques aside from literal translation (Vinay et al., 1958; Chuquet et al., 1989; Zhai et al., 2018). A taxonomy of translation processes was first proposed and built by Vinay et al. (1958; Zhai et al., 2018). The hierarchy of translation relations that is provided here is based on hypotheses that Chuquet et al.’s (1989; Zhai et al., 2018) work has elucidated.</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS1.p2">
<p class="ltx_p" id="S3.SS2.SSS1.p2.1">There is a hierarchical architecture of translation relations (see Figure 2) which has four types of translation techniques, namely literality, equivalence, non-literality, and unalignment. Beside, non-literal techniques have sub-categories of techniques, and the same for unalignment node.</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS1.p3">
<p class="ltx_p" id="S3.SS2.SSS1.p3.1">Nodes that are blue colored are translation techniques to be looked into in this dissertation. As for other white nodes, they are either more general to conclude some translation techniques or more specific to explain how their higher nodes work. The definition for each translation technique used in the dissertation will be given (Zhai et al., 2019) and exemplified.</p>
</div>
<figure class="ltx_figure" id="S3.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="249" id="S3.F2.g1" src="extracted/2404.08661v1/1.png" width="476"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Figure 2: Hierarchy of translation relations (Chuquet et al., 1989; Zhai et al., 2018)</figcaption>
</figure>
<div class="ltx_para" id="S3.SS2.SSS1.p4">
<p class="ltx_p" id="S3.SS2.SSS1.p4.1">(1) Literal translation is a type of direct translation or word-for-word translation that occasionally includes loan words or borrowing words from the source languages, the direct translation of idioms, the use of corresponding expressions when an absolutely literal translation is incomprehensible, the addition or deletion of determiners, the switching of singular and plural forms, etc.
<br class="ltx_break"/>Examples of literal translation:
<br class="ltx_break"/>literal a bronze ring <span class="ltx_ERROR undefined" id="S3.SS2.SSS1.p4.1.1">{CJK}</span>UTF8gbsn→ 一 个 青铜 戒指
<br class="ltx_break"/>As a husband, he is affectionate. <span class="ltx_ERROR undefined" id="S3.SS2.SSS1.p4.1.2">{CJK}</span>UTF8gbsn→ 作为 一个 丈夫 ，他 十分 地 深情 。</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS1.p5">
<p class="ltx_p" id="S3.SS2.SSS1.p5.1">(2) Equivalence is the non-literal translation of proverbs, idioms, or fixed phrases; it is also semantic equivalence at the supra-lexical level, translation of words, and there is no change in meaning or point of view, even though the translator has generated a different translation.
<br class="ltx_break"/>Examples of equivalence:
<br class="ltx_break"/>There is no use in crying over the split milk <span class="ltx_ERROR undefined" id="S3.SS2.SSS1.p5.1.1">{CJK}</span>UTF8gbsn→木已成舟 (The boat has been done. )
<br class="ltx_break"/>protect all locations <span class="ltx_text ltx_font_bold" id="S3.SS2.SSS1.p5.1.2">at all times</span> → <span class="ltx_ERROR undefined" id="S3.SS2.SSS1.p5.1.3">{CJK}</span><span class="ltx_text ltx_font_bold" id="S3.SS2.SSS1.p5.1.4">UTF8gbsn日夜</span> ("day and night") <span class="ltx_ERROR undefined" id="S3.SS2.SSS1.p5.1.5">{CJK}</span>UTF8gbsn保护 所有 的 地点</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS1.p6">
<p class="ltx_p" id="S3.SS2.SSS1.p6.1">(3) Modulation is a technique used by translators to keep the message as natural-sounding as possible by employing different forms and switching points of view. When literal translation would provide difficult or unnatural translation, this method is typically employed by translators. It involves shifting the viewpoint in order to get around a translation problem or to show how the target language speakers see the world. The semantic divergence between the source text and the target text may be caused by this category. All other phenomena, except its two sub-types of Particularization and Generalization, are represented by the sub-type. 
<br class="ltx_break"/>Examples of modulation:
<br class="ltx_break"/><span class="ltx_ERROR undefined" id="S3.SS2.SSS1.p6.1.1">{CJK}</span>UTF8gbsnIt is <span class="ltx_text ltx_font_bold" id="S3.SS2.SSS1.p6.1.2">difficult</span> . → 这 <span class="ltx_text ltx_font_bold" id="S3.SS2.SSS1.p6.1.3">不 简单 (not easy)</span>。
<br class="ltx_break"/>I like the dreams of the future <span class="ltx_text ltx_font_bold" id="S3.SS2.SSS1.p6.1.4">better</span> than the history of the past . → 我 <span class="ltx_text ltx_font_bold" id="S3.SS2.SSS1.p6.1.5">不 (not)</span>缅怀 过去 的 历史 ，<span class="ltx_text ltx_font_bold" id="S3.SS2.SSS1.p6.1.6">而 (instead)</span> 致力于 未来 的 梦想 。
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="S3.SS2.SSS1.p6.1.7">Maybe</span> we should postpone till the weekend . → <span class="ltx_text ltx_font_bold" id="S3.SS2.SSS1.p6.1.8">不如 (why not)</span> 我们 推迟 到 周末 吧 。</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS1.p7">
<p class="ltx_p" id="S3.SS2.SSS1.p7.1">(4) Particularization is to put the expression of translation in a clearer or more specific way. The translator would pick one of several target segments with a more precise meaning among those that may be created from the source segment. It occasionally explains a segment’s context-specific significance. A pronoun in one sentence can be translated into the items that it refers to. 
<br class="ltx_break"/>Examples of particularization:
<br class="ltx_break"/><span class="ltx_ERROR undefined" id="S3.SS2.SSS1.p7.1.1">{CJK}</span>UTF8gbsn" Yes , <span class="ltx_text ltx_font_bold" id="S3.SS2.SSS1.p7.1.2">put</span> you to bed , " she added lightly → " 是的 ， <span class="ltx_text ltx_font_bold" id="S3.SS2.SSS1.p7.1.3">服侍 (serve)</span>你 上床 睡觉 , " 她 小声 补充 说
<br class="ltx_break"/>He then requested <span class="ltx_text ltx_font_bold" id="S3.SS2.SSS1.p7.1.4">her</span> to stay where she was → 他 先 让 <span class="ltx_text ltx_font_bold" id="S3.SS2.SSS1.p7.1.5">苔丝 (Tess)</span> 在 外面 等 着</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS1.p8">
<p class="ltx_p" id="S3.SS2.SSS1.p8.1">(5)Generalization is the "conscious or unconscious semantic loss of one or more distinct senses" in translation (notional or pragmatic). The translator employed the more broad target term or phrase, which might be translated from a variety of source words or expressions. Sometimes non-fixed terms are used to refer to idioms, and the figurative picture is taken away from the source languages in the translation. 
<br class="ltx_break"/>Examples of generalization.
<br class="ltx_break"/><span class="ltx_ERROR undefined" id="S3.SS2.SSS1.p8.1.1">{CJK}</span>UTF8gbsna research that will be embraced by <span class="ltx_text ltx_font_bold" id="S3.SS2.SSS1.p8.1.2">millions of</span> bleary-eyed Britons → 一 项 即将 被 <span class="ltx_text ltx_font_bold" id="S3.SS2.SSS1.p8.1.3">广大 (many)</span> 睡眼惺忪 的 英国人 所 知道 的 研究
<br class="ltx_break"/>But should <span class="ltx_text ltx_font_bold" id="S3.SS2.SSS1.p8.1.4">tempers</span> rise in the Middle East, the price could jump again. → 如果 中东 <span class="ltx_text ltx_font_bold" id="S3.SS2.SSS1.p8.1.5">战火 (wars)</span> 重 燃 的 话，无疑，油价 会 再度 上涨 。</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS1.p9">
<p class="ltx_p" id="S3.SS2.SSS1.p9.1">(6) Transposition is the alteration of the order of grammatical categories or parts of speech without altering the meaning. 
<br class="ltx_break"/>Examples of transposition:
<br class="ltx_break"/><span class="ltx_ERROR undefined" id="S3.SS2.SSS1.p9.1.1">{CJK}</span>UTF8gbsnThose who are <span class="ltx_text ltx_font_bold" id="S3.SS2.SSS1.p9.1.2">experienced</span> have feeble imagination . → 有 <span class="ltx_text ltx_font_bold" id="S3.SS2.SSS1.p9.1.3">经验(experience, noun)</span>的 人 缺乏 (lack, verb) 想象力 。
<br class="ltx_break"/>people <span class="ltx_text ltx_font_bold" id="S3.SS2.SSS1.p9.1.4">of</span> Iran → 伊朗 <span class="ltx_text ltx_font_bold" id="S3.SS2.SSS1.p9.1.5">的 (’s, particle)</span>人们</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS1.p10">
<p class="ltx_p" id="S3.SS2.SSS1.p10.1">(7) Modulation plus Transposition contains any sub-categories of modulation plus transposition combined. 
<br class="ltx_break"/><span class="ltx_ERROR undefined" id="S3.SS2.SSS1.p10.1.1">{CJK}</span>UTF8gbsnExamples of modulation plus transposition:
<br class="ltx_break"/>Tobacco companies are barred from running cigarette ads in popular teenager magazines and <span class="ltx_text ltx_font_bold" id="S3.SS2.SSS1.p10.1.2">from targeting youth</span> . → 烟草 公司 不准 在 青少年 普遍 阅读 的 刊物 上 刊登 香烟 广告 ，不准 <span class="ltx_text ltx_font_bold" id="S3.SS2.SSS1.p10.1.3">以 青少年 为 拉拢 对象</span> 。</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS1.p11">
<p class="ltx_p" id="S3.SS2.SSS1.p11.1">(8) Figurative translation is to use an idiom or a metaphor to translate a non-metaphor or a non-fixed term, and it sometimes uses personification. 
<br class="ltx_break"/>Examples of figurative translation:
<br class="ltx_break"/><span class="ltx_ERROR undefined" id="S3.SS2.SSS1.p11.1.1">{CJK}</span>UTF8gbsnpressured the people a little bit about it → 刨根问底 ("inquire into the root of the matter”)
<br class="ltx_break"/>For Joanne, new opportunities are <span class="ltx_text ltx_font_bold" id="S3.SS2.SSS1.p11.1.2">opening</span> . → 对 乔安娜 而 言 ，新 的 机遇 现 已 向 她 <span class="ltx_text ltx_font_bold" id="S3.SS2.SSS1.p11.1.3">招手 (opportunities are waving hands to her)</span>。</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS1.p12">
<p class="ltx_p" id="S3.SS2.SSS1.p12.1">(9) Lexical shift is that the message remains unchanged despite the translation’s literal inaccuracy. They are only slight vocabulary modifications that don’t require any translation techniques.
<br class="ltx_break"/>Examples of lexical shift:
<br class="ltx_break"/><span class="ltx_ERROR undefined" id="S3.SS2.SSS1.p12.1.1">{CJK}</span>UTF8gbsninclude the following additional <span class="ltx_text ltx_font_bold" id="S3.SS2.SSS1.p12.1.2">responsibilities</span> → 包括 下列 新增 的 <span class="ltx_text ltx_font_bold" id="S3.SS2.SSS1.p12.1.3">职责 (plural noun to the singular)
<br class="ltx_break"/></span>He also <span class="ltx_text ltx_font_bold" id="S3.SS2.SSS1.p12.1.4">indicated</span> that the United States will hold negotiations with Cuba → 他 还 <span class="ltx_text ltx_font_bold" id="S3.SS2.SSS1.p12.1.5">表示 (past tense to present tense)</span>， 美国 将 与 古巴 举行 谈判</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS1.p13">
<p class="ltx_p" id="S3.SS2.SSS1.p13.1">(10) Translation error is errors that occur in translation. 
<br class="ltx_break"/>Examples of translation error:
<br class="ltx_break"/><span class="ltx_ERROR undefined" id="S3.SS2.SSS1.p13.1.1">{CJK}</span>UTF8gbsndatabase <span class="ltx_text ltx_font_bold" id="S3.SS2.SSS1.p13.1.2">connection</span> method → 数据库 <span class="ltx_text ltx_font_bold" id="S3.SS2.SSS1.p13.1.3">访问 (access, should be “连接”)</span>方式</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS1.p14">
<p class="ltx_p" id="S3.SS2.SSS1.p14.1">(11) Uncertainty is one category that no translation categories mentioned above can be assigned to the translation.</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS1.p15">
<p class="ltx_p" id="S3.SS2.SSS1.p15.1">(12) Other types: Apart from the eleven categories which can be alignment on both source and target languages sides, there are tokens that are not aligned on either side. If there are tokens unaligned from the source side, this case is ascribed to the category of “reduction”; the tokens which are not aligned on the target side are labeled with “explicitation”. There is also another type named “no type” which means the untranslatability of functions words and segments that were not translated but had no bearing on the message. 
<br class="ltx_break"/>Example of reduction:
<br class="ltx_break"/><span class="ltx_ERROR undefined" id="S3.SS2.SSS1.p15.1.1">{CJK}</span>UTF8gbsnPeter <span class="ltx_text ltx_font_bold" id="S3.SS2.SSS1.p15.1.2">is</span> six years old. → 彼得 六岁。
<br class="ltx_break"/>Example of explicitation:
<br class="ltx_break"/><span class="ltx_ERROR undefined" id="S3.SS2.SSS1.p15.1.3">{CJK}</span>UTF8gbsnthe knife → 这 <span class="ltx_text ltx_font_bold" id="S3.SS2.SSS1.p15.1.4">把 (Chinese measure word)</span>刀
<br class="ltx_break"/>Example of no type:
<br class="ltx_break"/><span class="ltx_ERROR undefined" id="S3.SS2.SSS1.p15.1.5">{CJK}</span>UTF8gbsnThe tragedy of the world is <span class="ltx_text ltx_font_bold" id="S3.SS2.SSS1.p15.1.6">that</span> those who are imaginative have but slight experience. → 世界 的 悲剧 就 在于 有 想象力 的 人 缺乏 经验。</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS1.p16">
<p class="ltx_p" id="S3.SS2.SSS1.p16.1">Definitions for each translation techniques and examples above are either from Zhai’ (2019) annotation guideline of Translation Techniques for English-Chinese or corpora data.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS2.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.2 </span>Annotations of translation relations</h4>
<div class="ltx_para" id="S3.SS2.SSS2.p1">
<p class="ltx_p" id="S3.SS2.SSS2.p1.1">When all sentences are tokenized, tokens of the source and target sentences are aligned, and Tsinghua Aligner is used for automatic token alignment so as to reduce the labor alignment. According to the user manual of Tsinghua Aligner (Liu, 2015), once the source and target texts are entered, there will be an alignment file with the token index aligned. For example, in Figure 3 there are two sentences in both source.txt (Chinese pinyin) and target.txt respectively. Line 2 is the source sentence, corresponding to line 6, the target sentence, and the same with line 3 to line 7. In Figure 4, Line 1 is the token index correspondence between line 2 and line 6 in Figure 3, and line 2 is for line 3 and line 7 in Figure 3; in “1-0”, “1” represents “he” (both) in line 2 of Figure 3, and “0” represents for “both” in line 6 of Figure 3. However, the automatic word alignment tool cannot ensure the alignment outcomes are all correct. Therefore, checking for alignment several times is needed when the annotator annotates the translation relations on the platform named YAWAT (Yet Another Word Alignment Tool) (Germann, 2008).</p>
</div>
<figure class="ltx_figure" id="S3.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="249" id="S3.F3.g1" src="extracted/2404.08661v1/1.png" width="476"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Figure 3: Input of source.txt file and target.txt file (Example from Liu (2015))</figcaption>
</figure>
<figure class="ltx_figure" id="S3.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="249" id="S3.F4.g1" src="extracted/2404.08661v1/1.png" width="476"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Figure 4: Output of token index alignment (Example from Liu (2015))</figcaption>
</figure>
<div class="ltx_para" id="S3.SS2.SSS2.p2">
<p class="ltx_p" id="S3.SS2.SSS2.p2.1">When tokens of parallel sentences are aligned and turned into token index matches, both index alignment files in the format of .aln and tokenized parallel sentences in the .crp files are uploaded onto YAWAT. YAWAT is a tool for manipulating and visualizing word- and phrase-level parallel text alignments (Germann, 2008). This tool is a webpage-based platform, enabling manual word alignment and labeling such as labeling for translation relations or translation techniques. On the YAWAT operation webpage (see Figure 5) with two parts divided, the left side contains source sentences while the right is for target sentences. For word alignment between source and target texts, there is a matrix for each alignment, in which the upright side represents the source sentences and the horizontal is for target ones; in a matrix, there are many small blocks that are matches between the source and the target (see Figure 6). Once the word alignment is done for one sentence, the annotation for translation relations can be handled. The default translation technique is literal translation highlighted by the color yellow. If some other non-literal translation techniques are used, the labeling can be changed, and so can the colors with right clicks. There is a drop list of translation techniques with different colors for annotators’ convenience (see Figure 7). In the drop list on the right mouse click, the color yellow represents for literal translation, orange for equivalence, green for transposition, light blue for modulation, green for modulation + transposition, brown for generalization, red for particularization, pink for figurative, purple for lexical shift, light red for uncertain, and deep blue for translation error.</p>
</div>
<figure class="ltx_figure" id="S3.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="229" id="S3.F5.g1" src="extracted/2404.08661v1/5.png" width="480"/>
<br class="ltx_break ltx_centering"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Figure 5: The operation web page of YAWAT</figcaption>
</figure>
<figure class="ltx_figure" id="S3.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="183" id="S3.F6.g1" src="extracted/2404.08661v1/6.png" width="467"/>
<br class="ltx_break ltx_centering"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Figure 6: A matrix for word alignment, and the black block used for matching source token groups and the target token groups</figcaption>
</figure>
<figure class="ltx_figure" id="S3.F7"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="93" id="S3.F7.g1" src="extracted/2404.08661v1/7.png" width="460"/>
<br class="ltx_break ltx_centering"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Figure 7: The drop list of labeling for translation relations contains 11 different translation techniques with different colors</figcaption>
</figure>
<div class="ltx_para" id="S3.SS2.SSS2.p3">
<p class="ltx_p" id="S3.SS2.SSS2.p3.1">Inconsistency of translation relation annotation was found in the HT data due to the fact that there are three annotators to annotate HT data. Therefore, HT data annotation was modified to make the whole labeling consistent.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Translation relations features</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">The discussion and comparison of linguistics-related traits and components that lead to the use of non-literal translation procedures between HT and MT data. Literal translation, translation mistake, uncertainty, and non-type are among the 14 categories in translation relations that are not covered. The remaining 10 non-literal translations will be analyzed in terms of in terms of semantics and syntax in linguistics. 
<br class="ltx_break"/></p>
</div>
<div class="ltx_para" id="S3.SS3.p2">
<p class="ltx_p" id="S3.SS3.p2.1">In general, the traits and factors that trigger the use of non-literal translations can be classified into semantics-related and syntax-related ones. For factors that involving semantic knowledge, there are equivalence which have 5 sub-types such as small changes of word meaning, fixed-expressions, etc., figurative translation, and generalization. The features are analyzed and classified through observations and some automatic semantic classification tools such as SpaCy’s named entity recognition. There are some non-literal translation techniques’ characteristics relates to syntactic knowledge, covering lexical shift, transposition, unaligned explicitation and reduction. The analyses for these traits are based on some language-independent metrics including POS and dependency relations. Besides, some techniques use a kind of hybrid method that combines semantic and syntactic knowledge for analyses and comparison, including modulation, modulation+transposition, and particularization. 
<br class="ltx_break"/></p>
</div>
<div class="ltx_para" id="S3.SS3.p3">
<p class="ltx_p" id="S3.SS3.p3.1">Based on these fine-grained classified factors or features, HT and MT data are compared on more subtle levels to find the occasions of causing the use of translation relations.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section"><span class="ltx_text" id="S4.2.1.1" style="color:#1E64C8;">4</span> </span><span class="ltx_text ltx_ulem_uline" id="S4.3.2" style="color:#1E64C8;">Discussions and findings</span>
</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">In this section, the use of translation relations in HT and MT data is analyzed and compared from various perspectives. Besides, there are linguistics-related factors that lead to the use of a certain translation technique, and the used of translation relations caused by these factors are also analyzed and compared between HT and MT data.</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Aligned Data</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">In aligned MT and HT corpora, there are 9314 and 9235 aligned pairs which constitute the smallest unit for alignment. These aligned pairs can continue to be annotated based on different translation techniques. Generally, pairs can be divided into the type of literal translation which is a kind of common translation technique, and the type of non-literal translation which contains some other translation techniques such as equivalence, modulation, etc. Among these aligned pairs, literal translation accounts for the largest part both for MT and HT corpora. In comparison of ratio of aligned pairs annotated with literal translation , MT data uses more literal translation than HT data by 24.23%, which verifies that machine translation systems are more inclined to use literal translation. However, It is noticeable that not all translation output delivered by machine translation systems is based on literal translation; around 23% of aligned pairs use other translation relations. Specific data on aligned pairs using literal and non-literal translation is shown in Table 4.</p>
</div>
<div class="ltx_para" id="S4.SS1.p2">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.SS1.p2.1">
<tr class="ltx_tr" id="S4.SS1.p2.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S4.SS1.p2.1.1.1" rowspan="2" style="padding-left:19.9pt;padding-right:19.9pt;">      <span class="ltx_text" id="S4.SS1.p2.1.1.1.1">Literal/non-literal</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S4.SS1.p2.1.1.2" style="padding-left:19.9pt;padding-right:19.9pt;">      No. of pairs aligned</td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S4.SS1.p2.1.1.3" style="padding-left:19.9pt;padding-right:19.9pt;">      Percentage</td>
</tr>
<tr class="ltx_tr" id="S4.SS1.p2.1.2">
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS1.p2.1.2.1" style="padding-left:19.9pt;padding-right:19.9pt;">      MT data</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS1.p2.1.2.2" style="padding-left:19.9pt;padding-right:19.9pt;">      HT data</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS1.p2.1.2.3" style="padding-left:19.9pt;padding-right:19.9pt;">      MT data</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S4.SS1.p2.1.2.4" style="padding-left:19.9pt;padding-right:19.9pt;">      HT data</td>
</tr>
<tr class="ltx_tr" id="S4.SS1.p2.1.3">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.SS1.p2.1.3.1" style="padding-left:19.9pt;padding-right:19.9pt;">      Literal</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS1.p2.1.3.2" style="padding-left:19.9pt;padding-right:19.9pt;">      6221</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS1.p2.1.3.3" style="padding-left:19.9pt;padding-right:19.9pt;">      5045</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS1.p2.1.3.4" style="padding-left:19.9pt;padding-right:19.9pt;">      76.895%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S4.SS1.p2.1.3.5" style="padding-left:19.9pt;padding-right:19.9pt;">      63.508%</td>
</tr>
<tr class="ltx_tr" id="S4.SS1.p2.1.4">
<td class="ltx_td ltx_align_left" id="S4.SS1.p2.1.4.1" style="padding-left:19.9pt;padding-right:19.9pt;">      Non-literal</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.p2.1.4.2" style="padding-left:19.9pt;padding-right:19.9pt;">      3093</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.p2.1.4.3" style="padding-left:19.9pt;padding-right:19.9pt;">      4190</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.p2.1.4.4" style="padding-left:19.9pt;padding-right:19.9pt;">      23.105%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS1.p2.1.4.5" style="padding-left:19.9pt;padding-right:19.9pt;">      36.492%</td>
</tr>
<tr class="ltx_tr" id="S4.SS1.p2.1.5">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S4.SS1.p2.1.5.1" style="padding-left:19.9pt;padding-right:19.9pt;">      Total</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.SS1.p2.1.5.2" style="padding-left:19.9pt;padding-right:19.9pt;">      9314</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.SS1.p2.1.5.3" style="padding-left:19.9pt;padding-right:19.9pt;">      9235</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.SS1.p2.1.5.4" style="padding-left:19.9pt;padding-right:19.9pt;">      100%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t" id="S4.SS1.p2.1.5.5" style="padding-left:19.9pt;padding-right:19.9pt;">      100%</td>
</tr>
</table>
</div>
<div class="ltx_para" id="S4.SS1.p3">
<p class="ltx_p ltx_align_center" id="S4.SS1.p3.1">Table 4 Token number of each genre in source texts, machine translated texts, and human translated texts</p>
</div>
<div class="ltx_para" id="S4.SS1.p4">
<p class="ltx_p" id="S4.SS1.p4.1">More details of aligned pairs annotated with different translation techniques can be seen in Table 5. Even though the total numbers of aligned pairs are different between MT and HT aligned corpora, which are caused by the different translations in the target language, there is no large difference between these two corpora, and the number of pairs can be seen as equivalent. However, on the basis of translation relations, there are distinct differences between these two aligned data sets. As the absolute total numbers are not the same, the percentage of relative numbers are compared. For the techniques of literal translation, lexical shift, and translation errors, MT data uses them more frequently than HT data, especially by using literal translation, 21% more than HT data. As to translation error, the discrepancy is large reaching 63%; however, the pair number of translation errors is small for evaluation. On the one hand, we can say that translation errors have more chances of occurring in MT data, while on the other hand, it is hard to evaluate what the real discrepancy is between MT and HT data on translation errors with small amount of data. There are some other types of non-literal translation techniques used more in HT data than in MT data, such as equivalence, particularization, explicitation, and reduction. For generalization, modulation, and transposition, there are smaller gap for techniques used between HT and MT data. Figurative techniques and modulation plus transposition are rarely employed in both HT and MT data, but they are still more used in HT data.</p>
</div>
<div class="ltx_logical-block" id="S4.SS1.1">
<div class="ltx_para" id="S4.SS1.1.p1">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.SS1.1.p1.1">
<tr class="ltx_tr" id="S4.SS1.1.p1.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S4.SS1.1.p1.1.1.1" rowspan="2" style="padding-left:11.4pt;padding-right:11.4pt;"><span class="ltx_text" id="S4.SS1.1.p1.1.1.1.1">Translation relations</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S4.SS1.1.p1.1.1.2" style="padding-left:11.4pt;padding-right:11.4pt;">No. of pairs aligned</td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S4.SS1.1.p1.1.1.3" style="padding-left:11.4pt;padding-right:11.4pt;">Percentage</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt" id="S4.SS1.1.p1.1.1.4" rowspan="2" style="padding-left:11.4pt;padding-right:11.4pt;"><span class="ltx_text" id="S4.SS1.1.p1.1.1.4.1">Discrepancy (MT data)</span></td>
</tr>
<tr class="ltx_tr" id="S4.SS1.1.p1.1.2">
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS1.1.p1.1.2.1" style="padding-left:11.4pt;padding-right:11.4pt;">MT data</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS1.1.p1.1.2.2" style="padding-left:11.4pt;padding-right:11.4pt;">HT data</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS1.1.p1.1.2.3" style="padding-left:11.4pt;padding-right:11.4pt;">MT data</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS1.1.p1.1.2.4" style="padding-left:11.4pt;padding-right:11.4pt;">HT data</td>
</tr>
<tr class="ltx_tr" id="S4.SS1.1.p1.1.3">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.SS1.1.p1.1.3.1" style="padding-left:11.4pt;padding-right:11.4pt;">equivalence</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS1.1.p1.1.3.2" style="padding-left:11.4pt;padding-right:11.4pt;">164</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS1.1.p1.1.3.3" style="padding-left:11.4pt;padding-right:11.4pt;">326</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS1.1.p1.1.3.4" style="padding-left:11.4pt;padding-right:11.4pt;">2.137%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS1.1.p1.1.3.5" style="padding-left:11.4pt;padding-right:11.4pt;">3.952%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S4.SS1.1.p1.1.3.6" style="padding-left:11.4pt;padding-right:11.4pt;">-45.926%</td>
</tr>
<tr class="ltx_tr" id="S4.SS1.1.p1.1.4">
<td class="ltx_td ltx_align_left" id="S4.SS1.1.p1.1.4.1" style="padding-left:11.4pt;padding-right:11.4pt;">figurative</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.1.p1.1.4.2" style="padding-left:11.4pt;padding-right:11.4pt;">1</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.1.p1.1.4.3" style="padding-left:11.4pt;padding-right:11.4pt;">3</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.1.p1.1.4.4" style="padding-left:11.4pt;padding-right:11.4pt;">0.011%</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.1.p1.1.4.5" style="padding-left:11.4pt;padding-right:11.4pt;">0.043%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS1.1.p1.1.4.6" style="padding-left:11.4pt;padding-right:11.4pt;">-74.419%</td>
</tr>
<tr class="ltx_tr" id="S4.SS1.1.p1.1.5">
<td class="ltx_td ltx_align_left" id="S4.SS1.1.p1.1.5.1" style="padding-left:11.4pt;padding-right:11.4pt;">generalization</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.1.p1.1.5.2" style="padding-left:11.4pt;padding-right:11.4pt;">32</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.1.p1.1.5.3" style="padding-left:11.4pt;padding-right:11.4pt;">49</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.1.p1.1.5.4" style="padding-left:11.4pt;padding-right:11.4pt;">0.376%</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.1.p1.1.5.5" style="padding-left:11.4pt;padding-right:11.4pt;">0.552%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS1.1.p1.1.5.6" style="padding-left:11.4pt;padding-right:11.4pt;">-31.884%</td>
</tr>
<tr class="ltx_tr" id="S4.SS1.1.p1.1.6">
<td class="ltx_td ltx_align_left" id="S4.SS1.1.p1.1.6.1" style="padding-left:11.4pt;padding-right:11.4pt;">lexical_shift</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.1.p1.1.6.2" style="padding-left:11.4pt;padding-right:11.4pt;">756</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.1.p1.1.6.3" style="padding-left:11.4pt;padding-right:11.4pt;">705</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.1.p1.1.6.4" style="padding-left:11.4pt;padding-right:11.4pt;">9.244%</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.1.p1.1.6.5" style="padding-left:11.4pt;padding-right:11.4pt;">8.652%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS1.1.p1.1.6.6" style="padding-left:11.4pt;padding-right:11.4pt;">6.842%</td>
</tr>
<tr class="ltx_tr" id="S4.SS1.1.p1.1.7">
<td class="ltx_td ltx_align_left" id="S4.SS1.1.p1.1.7.1" style="padding-left:11.4pt;padding-right:11.4pt;">literal</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.1.p1.1.7.2" style="padding-left:11.4pt;padding-right:11.4pt;">6221</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.1.p1.1.7.3" style="padding-left:11.4pt;padding-right:11.4pt;">5045</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.1.p1.1.7.4" style="padding-left:11.4pt;padding-right:11.4pt;">76.895%</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.1.p1.1.7.5" style="padding-left:11.4pt;padding-right:11.4pt;">63.508%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS1.1.p1.1.7.6" style="padding-left:11.4pt;padding-right:11.4pt;">21.079%</td>
</tr>
<tr class="ltx_tr" id="S4.SS1.1.p1.1.8">
<td class="ltx_td ltx_align_left" id="S4.SS1.1.p1.1.8.1" style="padding-left:11.4pt;padding-right:11.4pt;">modulation</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.1.p1.1.8.2" style="padding-left:11.4pt;padding-right:11.4pt;">95</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.1.p1.1.8.3" style="padding-left:11.4pt;padding-right:11.4pt;">128</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.1.p1.1.8.4" style="padding-left:11.4pt;padding-right:11.4pt;">1.299%</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.1.p1.1.8.5" style="padding-left:11.4pt;padding-right:11.4pt;">1.689%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS1.1.p1.1.8.6" style="padding-left:11.4pt;padding-right:11.4pt;">-23.091%</td>
</tr>
<tr class="ltx_tr" id="S4.SS1.1.p1.1.9">
<td class="ltx_td ltx_align_left" id="S4.SS1.1.p1.1.9.1" style="padding-left:11.4pt;padding-right:11.4pt;">modulation_transposition</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.1.p1.1.9.2" style="padding-left:11.4pt;padding-right:11.4pt;">18</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.1.p1.1.9.3" style="padding-left:11.4pt;padding-right:11.4pt;">22</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.1.p1.1.9.4" style="padding-left:11.4pt;padding-right:11.4pt;">0.204%</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.1.p1.1.9.5" style="padding-left:11.4pt;padding-right:11.4pt;">0.249%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS1.1.p1.1.9.6" style="padding-left:11.4pt;padding-right:11.4pt;">-18.072%</td>
</tr>
<tr class="ltx_tr" id="S4.SS1.1.p1.1.10">
<td class="ltx_td ltx_align_left" id="S4.SS1.1.p1.1.10.1" style="padding-left:11.4pt;padding-right:11.4pt;">particularization</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.1.p1.1.10.2" style="padding-left:11.4pt;padding-right:11.4pt;">102</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.1.p1.1.10.3" style="padding-left:11.4pt;padding-right:11.4pt;">224</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.1.p1.1.10.4" style="padding-left:11.4pt;padding-right:11.4pt;">1.310%</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.1.p1.1.10.5" style="padding-left:11.4pt;padding-right:11.4pt;">3.064%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS1.1.p1.1.10.6" style="padding-left:11.4pt;padding-right:11.4pt;">-57.245%</td>
</tr>
<tr class="ltx_tr" id="S4.SS1.1.p1.1.11">
<td class="ltx_td ltx_align_left" id="S4.SS1.1.p1.1.11.1" style="padding-left:11.4pt;padding-right:11.4pt;">translation_error</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.1.p1.1.11.2" style="padding-left:11.4pt;padding-right:11.4pt;">21</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.1.p1.1.11.3" style="padding-left:11.4pt;padding-right:11.4pt;">14</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.1.p1.1.11.4" style="padding-left:11.4pt;padding-right:11.4pt;">0.258%</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.1.p1.1.11.5" style="padding-left:11.4pt;padding-right:11.4pt;">0.162%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS1.1.p1.1.11.6" style="padding-left:11.4pt;padding-right:11.4pt;">59.259%</td>
</tr>
<tr class="ltx_tr" id="S4.SS1.1.p1.1.12">
<td class="ltx_td ltx_align_left" id="S4.SS1.1.p1.1.12.1" style="padding-left:11.4pt;padding-right:11.4pt;">transposition</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.1.p1.1.12.2" style="padding-left:11.4pt;padding-right:11.4pt;">500</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.1.p1.1.12.3" style="padding-left:11.4pt;padding-right:11.4pt;">545</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.1.p1.1.12.4" style="padding-left:11.4pt;padding-right:11.4pt;">6.206%</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.1.p1.1.12.5" style="padding-left:11.4pt;padding-right:11.4pt;">6.724%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS1.1.p1.1.12.6" style="padding-left:11.4pt;padding-right:11.4pt;">-7.704%</td>
</tr>
<tr class="ltx_tr" id="S4.SS1.1.p1.1.13">
<td class="ltx_td ltx_align_left" id="S4.SS1.1.p1.1.13.1" style="padding-left:11.4pt;padding-right:11.4pt;">no_type</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.1.p1.1.13.2" style="padding-left:11.4pt;padding-right:11.4pt;">30</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.1.p1.1.13.3" style="padding-left:11.4pt;padding-right:11.4pt;">62</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.1.p1.1.13.4" style="padding-left:11.4pt;padding-right:11.4pt;">0.344%</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.1.p1.1.13.5" style="padding-left:11.4pt;padding-right:11.4pt;">0.845%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS1.1.p1.1.13.6" style="padding-left:11.4pt;padding-right:11.4pt;">-59.290%</td>
</tr>
<tr class="ltx_tr" id="S4.SS1.1.p1.1.14">
<td class="ltx_td ltx_align_left" id="S4.SS1.1.p1.1.14.1" style="padding-left:11.4pt;padding-right:11.4pt;">unaligned_explicitation</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.1.p1.1.14.2" style="padding-left:11.4pt;padding-right:11.4pt;">736</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.1.p1.1.14.3" style="padding-left:11.4pt;padding-right:11.4pt;">1220</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.1.p1.1.14.4" style="padding-left:11.4pt;padding-right:11.4pt;">7.902%</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.1.p1.1.14.5" style="padding-left:11.4pt;padding-right:11.4pt;">13.211%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS1.1.p1.1.14.6" style="padding-left:11.4pt;padding-right:11.4pt;">-40.184%</td>
</tr>
<tr class="ltx_tr" id="S4.SS1.1.p1.1.15">
<td class="ltx_td ltx_align_left" id="S4.SS1.1.p1.1.15.1" style="padding-left:11.4pt;padding-right:11.4pt;">unaligned_reduction</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.1.p1.1.15.2" style="padding-left:11.4pt;padding-right:11.4pt;">636</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.1.p1.1.15.3" style="padding-left:11.4pt;padding-right:11.4pt;">870</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.1.p1.1.15.4" style="padding-left:11.4pt;padding-right:11.4pt;">6.828%</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.1.p1.1.15.5" style="padding-left:11.4pt;padding-right:11.4pt;">9.421%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS1.1.p1.1.15.6" style="padding-left:11.4pt;padding-right:11.4pt;">-27.517%</td>
</tr>
<tr class="ltx_tr" id="S4.SS1.1.p1.1.16">
<td class="ltx_td ltx_align_left" id="S4.SS1.1.p1.1.16.1" style="padding-left:11.4pt;padding-right:11.4pt;">uncertain</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.1.p1.1.16.2" style="padding-left:11.4pt;padding-right:11.4pt;">2</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.1.p1.1.16.3" style="padding-left:11.4pt;padding-right:11.4pt;">22</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.1.p1.1.16.4" style="padding-left:11.4pt;padding-right:11.4pt;">0.032%</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.1.p1.1.16.5" style="padding-left:11.4pt;padding-right:11.4pt;">0.282%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS1.1.p1.1.16.6" style="padding-left:11.4pt;padding-right:11.4pt;">-88.652%</td>
</tr>
<tr class="ltx_tr" id="S4.SS1.1.p1.1.17">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S4.SS1.1.p1.1.17.1" style="padding-left:11.4pt;padding-right:11.4pt;">Total</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.SS1.1.p1.1.17.2" style="padding-left:11.4pt;padding-right:11.4pt;">9314</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.SS1.1.p1.1.17.3" style="padding-left:11.4pt;padding-right:11.4pt;">9235</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.SS1.1.p1.1.17.4" style="padding-left:11.4pt;padding-right:11.4pt;">100%</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.SS1.1.p1.1.17.5" style="padding-left:11.4pt;padding-right:11.4pt;">100%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t" id="S4.SS1.1.p1.1.17.6" style="padding-left:11.4pt;padding-right:11.4pt;">0</td>
</tr>
</table>
</div>
</div>
<div class="ltx_para" id="S4.SS1.p5">
<p class="ltx_p ltx_align_center" id="S4.SS1.p5.1">Table 5 The number of aligned pairs using literal and non-literal translation</p>
</div>
<section class="ltx_subsubsection" id="S4.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.1 </span>Comparison based on tokens in the source texts</h4>
<div class="ltx_para" id="S4.SS1.SSS1.p1">
<p class="ltx_p" id="S4.SS1.SSS1.p1.1">The same source texts are shared by the aligned MT and HT corpora. For each token in the source texts, the application of translation relations is examined. In general, there are 10916 tokens in the source texts. 7623 and 6388 English tokens in MT and HT corpora are translated into Chinese using the literal translation approach respective. Table 6 provides more precise statistics.
<br class="ltx_break"/></p>
</div>
<div class="ltx_para" id="S4.SS1.SSS1.p2">
<p class="ltx_p" id="S4.SS1.SSS1.p2.1">The ratio of the number of literally translated tokens in a phrase is examined in accordance with various genres in order to compare the literally translated tokens in the source texts between the MT and HT data sets (see Figure 8). It is clear from the statistics that the ratio of literally translated tokens in the MT data is higher than that in the HT data. The education, microblog, scientific article, spoken language, and subtitles categories have the most disparities when utilizing literal translation.</p>
</div>
<div class="ltx_para" id="S4.SS1.SSS1.p3">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.SS1.SSS1.p3.1">
<tr class="ltx_tr" id="S4.SS1.SSS1.p3.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S4.SS1.SSS1.p3.1.1.1" style="padding-left:19.9pt;padding-right:19.9pt;">      English token number</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.SS1.SSS1.p3.1.1.2" style="padding-left:19.9pt;padding-right:19.9pt;">      MT data</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt" id="S4.SS1.SSS1.p3.1.1.3" style="padding-left:19.9pt;padding-right:19.9pt;">      HT data</td>
</tr>
<tr class="ltx_tr" id="S4.SS1.SSS1.p3.1.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.SS1.SSS1.p3.1.2.1" style="padding-left:19.9pt;padding-right:19.9pt;">      Literal token</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS1.SSS1.p3.1.2.2" style="padding-left:19.9pt;padding-right:19.9pt;">      7623</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S4.SS1.SSS1.p3.1.2.3" style="padding-left:19.9pt;padding-right:19.9pt;">      6388</td>
</tr>
<tr class="ltx_tr" id="S4.SS1.SSS1.p3.1.3">
<td class="ltx_td ltx_align_left" id="S4.SS1.SSS1.p3.1.3.1" style="padding-left:19.9pt;padding-right:19.9pt;">      Non-literal token</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.SSS1.p3.1.3.2" style="padding-left:19.9pt;padding-right:19.9pt;">      3293</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS1.SSS1.p3.1.3.3" style="padding-left:19.9pt;padding-right:19.9pt;">      4528</td>
</tr>
<tr class="ltx_tr" id="S4.SS1.SSS1.p3.1.4">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.SS1.SSS1.p3.1.4.1" style="padding-left:19.9pt;padding-right:19.9pt;">      Total</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS1.SSS1.p3.1.4.2" style="padding-left:19.9pt;padding-right:19.9pt;">      10916</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S4.SS1.SSS1.p3.1.4.3" style="padding-left:19.9pt;padding-right:19.9pt;">      10916</td>
</tr>
<tr class="ltx_tr" id="S4.SS1.SSS1.p3.1.5">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S4.SS1.SSS1.p3.1.5.1" style="padding-left:19.9pt;padding-right:19.9pt;">      Percentage (literal)</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.SS1.SSS1.p3.1.5.2" style="padding-left:19.9pt;padding-right:19.9pt;">      69.833%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb" id="S4.SS1.SSS1.p3.1.5.3" style="padding-left:19.9pt;padding-right:19.9pt;">      58.520%</td>
</tr>
</table>
</div>
<div class="ltx_para" id="S4.SS1.SSS1.p4">
<p class="ltx_p ltx_align_center" id="S4.SS1.SSS1.p4.1">Table 6 The number of literally and non-literally translated tokes used in source texts</p>
</div>
<figure class="ltx_figure" id="S4.F8"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="242" id="S4.F8.g1" src="extracted/2404.08661v1/8.png" width="484"/>
<br class="ltx_break ltx_centering"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>Figure 8: The proportion of literally translated token ratio in each sentence</figcaption>
</figure>
<div class="ltx_para" id="S4.SS1.SSS1.p5">
<span class="ltx_ERROR undefined" id="S4.SS1.SSS1.p5.1">{CJK}</span>
<p class="ltx_p" id="S4.SS1.SSS1.p5.2">UTF8gbsnThe utilization of translation relations in MT data and HT data are compared using the edit distance to determine how different they are. Since English tokens from the source texts are shared in both corpora, they each utilize a separate set of translation relations. For example, in the sentence “When my mother sees this rip in my new dress she will raise the roof .”, its translations are “当 我 母亲 看到 我 新 衣服 上 的 裂缝 ， 她 会 非常 生气 。” by human translators, and “当 我 母亲 看到 我 新 衣服 上 的 这 道 裂痕 时 ， 她 会 掀起 屋顶 。” by machine translation systems. As to “raise the roof” these three tokens, their translation in HT is “非常 生气” (very angry) by using generalization, while in MT data, they use literal translation with translation as “掀起 屋顶” (lift the roof). The difference of annotation can be seen in Figure 9 and Figure 10.</p>
</div>
<figure class="ltx_figure" id="S4.F9">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="138" id="S4.F9.g1" src="extracted/2404.08661v1/9.png" width="468"/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><span class="ltx_ERROR ltx_centering ltx_figure_panel undefined" id="S4.F9.1">{CJK}</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_align_center" id="S4.F9.2">UTF8gbsn</p>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9: </span>Figure 9: "raise the roof" is translated into "非常生气" (very angry) by using "generalization" (brown part in the annotation)</figcaption>
</figure>
<figure class="ltx_figure" id="S4.F10">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="126" id="S4.F10.g1" src="extracted/2404.08661v1/10.png" width="469"/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><span class="ltx_ERROR ltx_centering ltx_figure_panel undefined" id="S4.F10.1">{CJK}</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_align_center" id="S4.F10.2">UTF8gbsn</p>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 10: </span>Figure 10: "raise the roof" is literally translated into "掀起屋顶" (the roof)(yellow part in the annotation)</figcaption>
</figure>
<div class="ltx_para" id="S4.SS1.SSS1.p6">
<p class="ltx_p" id="S4.SS1.SSS1.p6.1">In this case, the core idea of Levenshtein distance is used to examine how different translations are used in HT and MT data, and there is an example for the calculation of edit distance. In this case, the edit distance of translation relations instead of characters is calculated in this example sentence, and the edit distance is 3 since "raise","the" and "roof" are translated with "generalization" respectively in HT data while they are literally translated in MT data (see Table 7). The collections of edit distances of sentences in each genre are shown in Figure 11. The edit distance of each sentence in subtitle is noticeably greater than that of sentences from other genres, demonstrating the similarity in how translation is used in spoken and scientific publications.</p>
</div>
<div class="ltx_para" id="S4.SS1.SSS1.p7">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.SS1.SSS1.p7.1">
<tr class="ltx_tr" id="S4.SS1.SSS1.p7.1.1">
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.SS1.SSS1.p7.1.1.1" style="padding-left:2.8pt;padding-right:2.8pt;">data</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.SS1.SSS1.p7.1.1.2" style="padding-left:2.8pt;padding-right:2.8pt;">When</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.SS1.SSS1.p7.1.1.3" style="padding-left:2.8pt;padding-right:2.8pt;">my</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.SS1.SSS1.p7.1.1.4" style="padding-left:2.8pt;padding-right:2.8pt;">mother</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.SS1.SSS1.p7.1.1.5" style="padding-left:2.8pt;padding-right:2.8pt;">sees</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.SS1.SSS1.p7.1.1.6" style="padding-left:2.8pt;padding-right:2.8pt;">this</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.SS1.SSS1.p7.1.1.7" style="padding-left:2.8pt;padding-right:2.8pt;">rip</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.SS1.SSS1.p7.1.1.8" style="padding-left:2.8pt;padding-right:2.8pt;">in</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.SS1.SSS1.p7.1.1.9" style="padding-left:2.8pt;padding-right:2.8pt;">my</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.SS1.SSS1.p7.1.1.10" style="padding-left:2.8pt;padding-right:2.8pt;">new</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.SS1.SSS1.p7.1.1.11" style="padding-left:2.8pt;padding-right:2.8pt;">dress</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.SS1.SSS1.p7.1.1.12" style="padding-left:2.8pt;padding-right:2.8pt;">she</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.SS1.SSS1.p7.1.1.13" style="padding-left:2.8pt;padding-right:2.8pt;">will</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.SS1.SSS1.p7.1.1.14" style="padding-left:2.8pt;padding-right:2.8pt;">raise</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.SS1.SSS1.p7.1.1.15" style="padding-left:2.8pt;padding-right:2.8pt;">the</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt" id="S4.SS1.SSS1.p7.1.1.16" style="padding-left:2.8pt;padding-right:2.8pt;">roof</td>
</tr>
<tr class="ltx_tr" id="S4.SS1.SSS1.p7.1.2">
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS1.SSS1.p7.1.2.1" style="padding-left:2.8pt;padding-right:2.8pt;">HT</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS1.SSS1.p7.1.2.2" style="padding-left:2.8pt;padding-right:2.8pt;">literal</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS1.SSS1.p7.1.2.3" style="padding-left:2.8pt;padding-right:2.8pt;">literal</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS1.SSS1.p7.1.2.4" style="padding-left:2.8pt;padding-right:2.8pt;">literal</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS1.SSS1.p7.1.2.5" style="padding-left:2.8pt;padding-right:2.8pt;">literal</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS1.SSS1.p7.1.2.6" style="padding-left:2.8pt;padding-right:2.8pt;">literal</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS1.SSS1.p7.1.2.7" style="padding-left:2.8pt;padding-right:2.8pt;">literal</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS1.SSS1.p7.1.2.8" style="padding-left:2.8pt;padding-right:2.8pt;">literal</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS1.SSS1.p7.1.2.9" style="padding-left:2.8pt;padding-right:2.8pt;">literal</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS1.SSS1.p7.1.2.10" style="padding-left:2.8pt;padding-right:2.8pt;">literal</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS1.SSS1.p7.1.2.11" style="padding-left:2.8pt;padding-right:2.8pt;">literal</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS1.SSS1.p7.1.2.12" style="padding-left:2.8pt;padding-right:2.8pt;">literal</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS1.SSS1.p7.1.2.13" style="padding-left:2.8pt;padding-right:2.8pt;">literal</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS1.SSS1.p7.1.2.14" style="padding-left:2.8pt;padding-right:2.8pt;">literal</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS1.SSS1.p7.1.2.15" style="padding-left:2.8pt;padding-right:2.8pt;">literal</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S4.SS1.SSS1.p7.1.2.16" style="padding-left:2.8pt;padding-right:2.8pt;">literal</td>
</tr>
<tr class="ltx_tr" id="S4.SS1.SSS1.p7.1.3">
<td class="ltx_td ltx_align_center" id="S4.SS1.SSS1.p7.1.3.1" style="padding-left:2.8pt;padding-right:2.8pt;">MT</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.SSS1.p7.1.3.2" style="padding-left:2.8pt;padding-right:2.8pt;">literal</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.SSS1.p7.1.3.3" style="padding-left:2.8pt;padding-right:2.8pt;">literal</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.SSS1.p7.1.3.4" style="padding-left:2.8pt;padding-right:2.8pt;">literal</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.SSS1.p7.1.3.5" style="padding-left:2.8pt;padding-right:2.8pt;">literal</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.SSS1.p7.1.3.6" style="padding-left:2.8pt;padding-right:2.8pt;">literal</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.SSS1.p7.1.3.7" style="padding-left:2.8pt;padding-right:2.8pt;">literal</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.SSS1.p7.1.3.8" style="padding-left:2.8pt;padding-right:2.8pt;">literal</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.SSS1.p7.1.3.9" style="padding-left:2.8pt;padding-right:2.8pt;">literal</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.SSS1.p7.1.3.10" style="padding-left:2.8pt;padding-right:2.8pt;">literal</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.SSS1.p7.1.3.11" style="padding-left:2.8pt;padding-right:2.8pt;">literal</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.SSS1.p7.1.3.12" style="padding-left:2.8pt;padding-right:2.8pt;">literal</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.SSS1.p7.1.3.13" style="padding-left:2.8pt;padding-right:2.8pt;">literal</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.SSS1.p7.1.3.14" style="padding-left:2.8pt;padding-right:2.8pt;">
<span class="ltx_text" id="S4.SS1.SSS1.p7.1.3.14.1"></span> <span class="ltx_text" id="S4.SS1.SSS1.p7.1.3.14.2">
<span class="ltx_tabular ltx_align_middle" id="S4.SS1.SSS1.p7.1.3.14.2.1">
<span class="ltx_tr" id="S4.SS1.SSS1.p7.1.3.14.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS1.SSS1.p7.1.3.14.2.1.1.1" style="padding-left:2.8pt;padding-right:2.8pt;">general-</span></span>
<span class="ltx_tr" id="S4.SS1.SSS1.p7.1.3.14.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS1.SSS1.p7.1.3.14.2.1.2.1" style="padding-left:2.8pt;padding-right:2.8pt;">ization</span></span>
</span></span><span class="ltx_text" id="S4.SS1.SSS1.p7.1.3.14.3"></span></td>
<td class="ltx_td ltx_align_center" id="S4.SS1.SSS1.p7.1.3.15" style="padding-left:2.8pt;padding-right:2.8pt;">
<span class="ltx_text" id="S4.SS1.SSS1.p7.1.3.15.1"></span> <span class="ltx_text" id="S4.SS1.SSS1.p7.1.3.15.2">
<span class="ltx_tabular ltx_align_middle" id="S4.SS1.SSS1.p7.1.3.15.2.1">
<span class="ltx_tr" id="S4.SS1.SSS1.p7.1.3.15.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS1.SSS1.p7.1.3.15.2.1.1.1" style="padding-left:2.8pt;padding-right:2.8pt;">general-</span></span>
<span class="ltx_tr" id="S4.SS1.SSS1.p7.1.3.15.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS1.SSS1.p7.1.3.15.2.1.2.1" style="padding-left:2.8pt;padding-right:2.8pt;">ization</span></span>
</span></span><span class="ltx_text" id="S4.SS1.SSS1.p7.1.3.15.3"></span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS1.SSS1.p7.1.3.16" style="padding-left:2.8pt;padding-right:2.8pt;">
<span class="ltx_text" id="S4.SS1.SSS1.p7.1.3.16.1"></span> <span class="ltx_text" id="S4.SS1.SSS1.p7.1.3.16.2">
<span class="ltx_tabular ltx_align_middle" id="S4.SS1.SSS1.p7.1.3.16.2.1">
<span class="ltx_tr" id="S4.SS1.SSS1.p7.1.3.16.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS1.SSS1.p7.1.3.16.2.1.1.1" style="padding-left:2.8pt;padding-right:2.8pt;">general-</span></span>
<span class="ltx_tr" id="S4.SS1.SSS1.p7.1.3.16.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS1.SSS1.p7.1.3.16.2.1.2.1" style="padding-left:2.8pt;padding-right:2.8pt;">ization</span></span>
</span></span><span class="ltx_text" id="S4.SS1.SSS1.p7.1.3.16.3"></span></td>
</tr>
<tr class="ltx_tr" id="S4.SS1.SSS1.p7.1.4">
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.SS1.SSS1.p7.1.4.1" style="padding-left:2.8pt;padding-right:2.8pt;">edit</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.SS1.SSS1.p7.1.4.2" style="padding-left:2.8pt;padding-right:2.8pt;">0</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.SS1.SSS1.p7.1.4.3" style="padding-left:2.8pt;padding-right:2.8pt;">0</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.SS1.SSS1.p7.1.4.4" style="padding-left:2.8pt;padding-right:2.8pt;">0</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.SS1.SSS1.p7.1.4.5" style="padding-left:2.8pt;padding-right:2.8pt;">0</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.SS1.SSS1.p7.1.4.6" style="padding-left:2.8pt;padding-right:2.8pt;">0</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.SS1.SSS1.p7.1.4.7" style="padding-left:2.8pt;padding-right:2.8pt;">0</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.SS1.SSS1.p7.1.4.8" style="padding-left:2.8pt;padding-right:2.8pt;">0</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.SS1.SSS1.p7.1.4.9" style="padding-left:2.8pt;padding-right:2.8pt;">0</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.SS1.SSS1.p7.1.4.10" style="padding-left:2.8pt;padding-right:2.8pt;">0</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.SS1.SSS1.p7.1.4.11" style="padding-left:2.8pt;padding-right:2.8pt;">0</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.SS1.SSS1.p7.1.4.12" style="padding-left:2.8pt;padding-right:2.8pt;">0</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.SS1.SSS1.p7.1.4.13" style="padding-left:2.8pt;padding-right:2.8pt;">0</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.SS1.SSS1.p7.1.4.14" style="padding-left:2.8pt;padding-right:2.8pt;">1</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.SS1.SSS1.p7.1.4.15" style="padding-left:2.8pt;padding-right:2.8pt;">1</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb" id="S4.SS1.SSS1.p7.1.4.16" style="padding-left:2.8pt;padding-right:2.8pt;">1</td>
</tr>
</table>
</div>
<div class="ltx_para" id="S4.SS1.SSS1.p8">
<p class="ltx_p ltx_align_center" id="S4.SS1.SSS1.p8.1">Table 7 the edit distance calculation of translation relations in an example sentence with the edit distance of 3</p>
</div>
<figure class="ltx_figure" id="S4.F11"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="283" id="S4.F11.g1" src="extracted/2404.08661v1/11.png" width="463"/>
<br class="ltx_break ltx_centering"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 11: </span>Figure 11: Edit distance of translation relations in each sentence in genres</figcaption>
</figure>
</section>
<section class="ltx_subsubsection" id="S4.SS1.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.2 </span>Comparison of translation relations in genres</h4>
<div class="ltx_para" id="S4.SS1.SSS2.p1">
<p class="ltx_p" id="S4.SS1.SSS2.p1.1">Literal and non-literal translation techniques are analyzed based on different genres in Table 8. It is clear that non-literal translation procedures are used more frequently in HT data than in MT data; in fact, over half of HT data have done so, compared to just one-third of MT data. The difference in subtitle is 98%, and it is also noticeable in spoken, microblog, and scientific articles. Besides, there is a significant disparity between the usage of non-literal translation in official documents, legislation, and science, which demonstrates that formal, rigid writings are more prone to employ literal translations.</p>
</div>
<div class="ltx_para" id="S4.SS1.SSS2.p2">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.SS1.SSS2.p2.1">
<tr class="ltx_tr" id="S4.SS1.SSS2.p2.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S4.SS1.SSS2.p2.1.1.1" rowspan="2" style="padding-left:11.4pt;padding-right:11.4pt;"><span class="ltx_text" id="S4.SS1.SSS2.p2.1.1.1.1">Genre</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S4.SS1.SSS2.p2.1.1.2" style="padding-left:11.4pt;padding-right:11.4pt;">MT data</td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S4.SS1.SSS2.p2.1.1.3" style="padding-left:11.4pt;padding-right:11.4pt;">HT data</td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="S4.SS1.SSS2.p2.1.1.4" style="padding-left:11.4pt;padding-right:11.4pt;">Percentage (non-literal)</td>
</tr>
<tr class="ltx_tr" id="S4.SS1.SSS2.p2.1.2">
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS1.SSS2.p2.1.2.1" style="padding-left:11.4pt;padding-right:11.4pt;">Literal</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS1.SSS2.p2.1.2.2" style="padding-left:11.4pt;padding-right:11.4pt;">Non-literal</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS1.SSS2.p2.1.2.3" style="padding-left:11.4pt;padding-right:11.4pt;">Literal</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS1.SSS2.p2.1.2.4" style="padding-left:11.4pt;padding-right:11.4pt;">Non-literal</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS1.SSS2.p2.1.2.5" style="padding-left:11.4pt;padding-right:11.4pt;">MT data</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS1.SSS2.p2.1.2.6" style="padding-left:11.4pt;padding-right:11.4pt;">HT data</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S4.SS1.SSS2.p2.1.2.7" style="padding-left:11.4pt;padding-right:11.4pt;">Discrepancy</td>
</tr>
<tr class="ltx_tr" id="S4.SS1.SSS2.p2.1.3">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.SS1.SSS2.p2.1.3.1" style="padding-left:11.4pt;padding-right:11.4pt;">education</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS1.SSS2.p2.1.3.2" style="padding-left:11.4pt;padding-right:11.4pt;">613</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS1.SSS2.p2.1.3.3" style="padding-left:11.4pt;padding-right:11.4pt;">273</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS1.SSS2.p2.1.3.4" style="padding-left:11.4pt;padding-right:11.4pt;">496</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS1.SSS2.p2.1.3.5" style="padding-left:11.4pt;padding-right:11.4pt;">382</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS1.SSS2.p2.1.3.6" style="padding-left:11.4pt;padding-right:11.4pt;">30.813%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS1.SSS2.p2.1.3.7" style="padding-left:11.4pt;padding-right:11.4pt;">43.508%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S4.SS1.SSS2.p2.1.3.8" style="padding-left:11.4pt;padding-right:11.4pt;">41.202%</td>
</tr>
<tr class="ltx_tr" id="S4.SS1.SSS2.p2.1.4">
<td class="ltx_td ltx_align_left" id="S4.SS1.SSS2.p2.1.4.1" style="padding-left:11.4pt;padding-right:11.4pt;">laws</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.SSS2.p2.1.4.2" style="padding-left:11.4pt;padding-right:11.4pt;">941</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.SSS2.p2.1.4.3" style="padding-left:11.4pt;padding-right:11.4pt;">563</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.SSS2.p2.1.4.4" style="padding-left:11.4pt;padding-right:11.4pt;">820</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.SSS2.p2.1.4.5" style="padding-left:11.4pt;padding-right:11.4pt;">636</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.SSS2.p2.1.4.6" style="padding-left:11.4pt;padding-right:11.4pt;">37.434%</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.SSS2.p2.1.4.7" style="padding-left:11.4pt;padding-right:11.4pt;">43.681%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS1.SSS2.p2.1.4.8" style="padding-left:11.4pt;padding-right:11.4pt;">16.690%</td>
</tr>
<tr class="ltx_tr" id="S4.SS1.SSS2.p2.1.5">
<td class="ltx_td ltx_align_left" id="S4.SS1.SSS2.p2.1.5.1" style="padding-left:11.4pt;padding-right:11.4pt;">microblog</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.SSS2.p2.1.5.2" style="padding-left:11.4pt;padding-right:11.4pt;">747</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.SSS2.p2.1.5.3" style="padding-left:11.4pt;padding-right:11.4pt;">282</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.SSS2.p2.1.5.4" style="padding-left:11.4pt;padding-right:11.4pt;">562</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.SSS2.p2.1.5.5" style="padding-left:11.4pt;padding-right:11.4pt;">464</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.SSS2.p2.1.5.6" style="padding-left:11.4pt;padding-right:11.4pt;">27.405%</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.SSS2.p2.1.5.7" style="padding-left:11.4pt;padding-right:11.4pt;">45.224%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS1.SSS2.p2.1.5.8" style="padding-left:11.4pt;padding-right:11.4pt;">65.020%</td>
</tr>
<tr class="ltx_tr" id="S4.SS1.SSS2.p2.1.6">
<td class="ltx_td ltx_align_left" id="S4.SS1.SSS2.p2.1.6.1" style="padding-left:11.4pt;padding-right:11.4pt;">news</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.SSS2.p2.1.6.2" style="padding-left:11.4pt;padding-right:11.4pt;">906</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.SSS2.p2.1.6.3" style="padding-left:11.4pt;padding-right:11.4pt;">411</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.SSS2.p2.1.6.4" style="padding-left:11.4pt;padding-right:11.4pt;">805</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.SSS2.p2.1.6.5" style="padding-left:11.4pt;padding-right:11.4pt;">528</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.SSS2.p2.1.6.6" style="padding-left:11.4pt;padding-right:11.4pt;">31.207%</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.SSS2.p2.1.6.7" style="padding-left:11.4pt;padding-right:11.4pt;">39.610%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS1.SSS2.p2.1.6.8" style="padding-left:11.4pt;padding-right:11.4pt;">26.925%</td>
</tr>
<tr class="ltx_tr" id="S4.SS1.SSS2.p2.1.7">
<td class="ltx_td ltx_align_left" id="S4.SS1.SSS2.p2.1.7.1" style="padding-left:11.4pt;padding-right:11.4pt;">officialDoc</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.SSS2.p2.1.7.2" style="padding-left:11.4pt;padding-right:11.4pt;">877</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.SSS2.p2.1.7.3" style="padding-left:11.4pt;padding-right:11.4pt;">620</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.SSS2.p2.1.7.4" style="padding-left:11.4pt;padding-right:11.4pt;">783</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.SSS2.p2.1.7.5" style="padding-left:11.4pt;padding-right:11.4pt;">654</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.SSS2.p2.1.7.6" style="padding-left:11.4pt;padding-right:11.4pt;">41.416%</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.SSS2.p2.1.7.7" style="padding-left:11.4pt;padding-right:11.4pt;">45.511%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS1.SSS2.p2.1.7.8" style="padding-left:11.4pt;padding-right:11.4pt;">9.888%</td>
</tr>
<tr class="ltx_tr" id="S4.SS1.SSS2.p2.1.8">
<td class="ltx_td ltx_align_left" id="S4.SS1.SSS2.p2.1.8.1" style="padding-left:11.4pt;padding-right:11.4pt;">science</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.SSS2.p2.1.8.2" style="padding-left:11.4pt;padding-right:11.4pt;">545</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.SSS2.p2.1.8.3" style="padding-left:11.4pt;padding-right:11.4pt;">288</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.SSS2.p2.1.8.4" style="padding-left:11.4pt;padding-right:11.4pt;">487</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.SSS2.p2.1.8.5" style="padding-left:11.4pt;padding-right:11.4pt;">353</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.SSS2.p2.1.8.6" style="padding-left:11.4pt;padding-right:11.4pt;">34.574%</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.SSS2.p2.1.8.7" style="padding-left:11.4pt;padding-right:11.4pt;">42.024%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS1.SSS2.p2.1.8.8" style="padding-left:11.4pt;padding-right:11.4pt;">21.548%</td>
</tr>
<tr class="ltx_tr" id="S4.SS1.SSS2.p2.1.9">
<td class="ltx_td ltx_align_left" id="S4.SS1.SSS2.p2.1.9.1" style="padding-left:11.4pt;padding-right:11.4pt;">scientificArticle</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.SSS2.p2.1.9.2" style="padding-left:11.4pt;padding-right:11.4pt;">748</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.SSS2.p2.1.9.3" style="padding-left:11.4pt;padding-right:11.4pt;">365</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.SSS2.p2.1.9.4" style="padding-left:11.4pt;padding-right:11.4pt;">475</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.SSS2.p2.1.9.5" style="padding-left:11.4pt;padding-right:11.4pt;">695</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.SSS2.p2.1.9.6" style="padding-left:11.4pt;padding-right:11.4pt;">32.794%</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.SSS2.p2.1.9.7" style="padding-left:11.4pt;padding-right:11.4pt;">59.402%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS1.SSS2.p2.1.9.8" style="padding-left:11.4pt;padding-right:11.4pt;">81.135%</td>
</tr>
<tr class="ltx_tr" id="S4.SS1.SSS2.p2.1.10">
<td class="ltx_td ltx_align_left" id="S4.SS1.SSS2.p2.1.10.1" style="padding-left:11.4pt;padding-right:11.4pt;">spoken</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.SSS2.p2.1.10.2" style="padding-left:11.4pt;padding-right:11.4pt;">421</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.SSS2.p2.1.10.3" style="padding-left:11.4pt;padding-right:11.4pt;">179</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.SSS2.p2.1.10.4" style="padding-left:11.4pt;padding-right:11.4pt;">341</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.SSS2.p2.1.10.5" style="padding-left:11.4pt;padding-right:11.4pt;">283</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.SSS2.p2.1.10.6" style="padding-left:11.4pt;padding-right:11.4pt;">29.833%</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.SSS2.p2.1.10.7" style="padding-left:11.4pt;padding-right:11.4pt;">45.353%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS1.SSS2.p2.1.10.8" style="padding-left:11.4pt;padding-right:11.4pt;">52.020%</td>
</tr>
<tr class="ltx_tr" id="S4.SS1.SSS2.p2.1.11">
<td class="ltx_td ltx_align_left" id="S4.SS1.SSS2.p2.1.11.1" style="padding-left:11.4pt;padding-right:11.4pt;">subtitles</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.SSS2.p2.1.11.2" style="padding-left:11.4pt;padding-right:11.4pt;">423</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.SSS2.p2.1.11.3" style="padding-left:11.4pt;padding-right:11.4pt;">112</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.SSS2.p2.1.11.4" style="padding-left:11.4pt;padding-right:11.4pt;">276</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.SSS2.p2.1.11.5" style="padding-left:11.4pt;padding-right:11.4pt;">195</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.SSS2.p2.1.11.6" style="padding-left:11.4pt;padding-right:11.4pt;">20.935%</td>
<td class="ltx_td ltx_align_center" id="S4.SS1.SSS2.p2.1.11.7" style="padding-left:11.4pt;padding-right:11.4pt;">41.401%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS1.SSS2.p2.1.11.8" style="padding-left:11.4pt;padding-right:11.4pt;">97.765%</td>
</tr>
<tr class="ltx_tr" id="S4.SS1.SSS2.p2.1.12">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S4.SS1.SSS2.p2.1.12.1" style="padding-left:11.4pt;padding-right:11.4pt;">Total</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.SS1.SSS2.p2.1.12.2" style="padding-left:11.4pt;padding-right:11.4pt;">6221</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.SS1.SSS2.p2.1.12.3" style="padding-left:11.4pt;padding-right:11.4pt;">3093</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.SS1.SSS2.p2.1.12.4" style="padding-left:11.4pt;padding-right:11.4pt;">5045</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.SS1.SSS2.p2.1.12.5" style="padding-left:11.4pt;padding-right:11.4pt;">4190</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.SS1.SSS2.p2.1.12.6" style="padding-left:11.4pt;padding-right:11.4pt;">33.208%</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.SS1.SSS2.p2.1.12.7" style="padding-left:11.4pt;padding-right:11.4pt;">45.371%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t" id="S4.SS1.SSS2.p2.1.12.8" style="padding-left:11.4pt;padding-right:11.4pt;">36.626%</td>
</tr>
</table>
</div>
<div class="ltx_para" id="S4.SS1.SSS2.p3">
<p class="ltx_p ltx_align_center" id="S4.SS1.SSS2.p3.1">Table 8 Literal and non-literal translation techniques used in different genres</p>
</div>
<div class="ltx_para" id="S4.SS1.SSS2.p4">
<p class="ltx_p" id="S4.SS1.SSS2.p4.1">Non-type and ambiguous translation relations, out of the 14 relations, won’t be explored in this study. Instead, more information and trends of genres employing the same translation techniques are evaluated (see Figure 12).</p>
</div>
<figure class="ltx_figure" id="S4.F12"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="672" id="S4.F12.g1" src="extracted/2404.08661v1/12.png" width="672"/>
<br class="ltx_break ltx_centering"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 12: </span>Figure 12: Percentages of use of translation relations in different genres</figcaption>
</figure>
<div class="ltx_para" id="S4.SS1.SSS2.p5">
<p class="ltx_p" id="S4.SS1.SSS2.p5.1">(1) Equivalence
<br class="ltx_break"/>The technique of equivalence is used in over 2% of all HT data, with scientific article texts using it the most frequently (at 7%), followed by subtitles at over 5%. In contrast, the total application of equivalence for MT data is between 1.5% and 2.3%, with the exception of microblogs, whose share is much lower than the flat trend of less than 1%.</p>
</div>
<div class="ltx_para" id="S4.SS1.SSS2.p6">
<p class="ltx_p" id="S4.SS1.SSS2.p6.1">(2) Figurative
<br class="ltx_break"/>Figuration contains metaphors and idioms, making it a challenging strategy for both human translators and machine translation systems. Personification is occasionally employed to cope with certain linguistic situations. Only 4 pairings of the metaphorical approach are used in the HT data in these two matched data sets, and only 1 pair is used in the MT data. Even though there is not a lot of data to analyze, it demonstrates that human translators are more mindful when using it.</p>
</div>
<div class="ltx_para" id="S4.SS1.SSS2.p7">
<p class="ltx_p" id="S4.SS1.SSS2.p7.1">(3) Generalization
<br class="ltx_break"/>In HT data, the education and subtitle genres employ generalization the most; the spoken and legal genres use it the least, much less than in MT data. Using the generalization approach, two sets of data exhibit the same level.</p>
</div>
<div class="ltx_para" id="S4.SS1.SSS2.p8">
<p class="ltx_p" id="S4.SS1.SSS2.p8.1">(4) Lexical shift
<br class="ltx_break"/>Lexical shift is utilized somewhat more in MT data than HT data. Two aligned corpora exhibit extremely comparable patterns, with spoken texts, subtitles, officialDoc, science, scientificArticle, and microblog employing lexical shift significantly more frequently than laws, education, microblog, and officialDoc.</p>
</div>
<div class="ltx_para" id="S4.SS1.SSS2.p9">
<p class="ltx_p" id="S4.SS1.SSS2.p9.1">(5) Literal translation
<br class="ltx_break"/>For all genres in the MT data set, the percentage of literal translation exceeds 60%, and for subtitles, it even approaches 80%. With the exception of scientificArticle, where the ratio is lower than 40% for HT-aligned corpora, the use of literal translation stabilizes between 55% and 60%.</p>
</div>
<div class="ltx_para" id="S4.SS1.SSS2.p10">
<p class="ltx_p" id="S4.SS1.SSS2.p10.1">(6) Modulation
<br class="ltx_break"/>In HT data, modulation is applied 1% more often to texts in the legal, scholarly, microblog, and subtitle genres than to texts in the other genres. In contrast to HT data, the usage of modulation in educational texts and subtitles is least for MT data.</p>
</div>
<div class="ltx_para" id="S4.SS1.SSS2.p11">
<p class="ltx_p" id="S4.SS1.SSS2.p11.1">(7) Modulation + transposition
<br class="ltx_break"/>Both in HT and MT corpora, this combination of translation methods is uncommon. With the exception of a scientific article, both sets of data show comparable tendencies, with HT data showing a higher adoption of the combining approach than MT data.</p>
</div>
<div class="ltx_para" id="S4.SS1.SSS2.p12">
<p class="ltx_p" id="S4.SS1.SSS2.p12.1">(8) Particularization
<br class="ltx_break"/>There is a distinct line that separates the MT and HT corpora: HT data is distributed on the upper line, while MT data is below it. In legal writings, microblogs, and scientific papers, particularization is employed more cautiously and conservatively in MT data.</p>
</div>
<div class="ltx_para" id="S4.SS1.SSS2.p13">
<p class="ltx_p" id="S4.SS1.SSS2.p13.1">(9) Transposition
<br class="ltx_break"/>The same trends and comparable data in many genres are shared by the MT and HT databases. However, there are two exceptions: the first is that MT utilizes transposition less frequently in official papers than HT, and the second is that HT uses it less frequently in spoken speech than MT.</p>
</div>
<div class="ltx_para" id="S4.SS1.SSS2.p14">
<p class="ltx_p" id="S4.SS1.SSS2.p14.1">(10) Translation error
<br class="ltx_break"/>Across all genres, the MT data set often contains more translation mistakes than the HT data. The proportion of translation mistakes in MT and HT datasets highest in scientific articles.</p>
</div>
<div class="ltx_para" id="S4.SS1.SSS2.p15">
<p class="ltx_p" id="S4.SS1.SSS2.p15.1">(11) Unaligned-explicitation 
<br class="ltx_break"/>Explicitation only occurs in the source materials, and certain additional details are given to the translation to make it seem more natural. More explicitation is used in the HT data set than the MT data. Less of this technique is used in the HT data set’s news, government papers, and science texts.</p>
</div>
<div class="ltx_para" id="S4.SS1.SSS2.p16">
<p class="ltx_p" id="S4.SS1.SSS2.p16.1">(12) Unaligned-reduction
<br class="ltx_break"/>Reduction is applied to tokens in the original texts that are not translated. Microblogs and scientific articles used reduction more frequently in aligned HT corpora, while MT data used it more frequently in legal and official texts.</p>
</div>
<div class="ltx_para" id="S4.SS1.SSS2.p17">
<p class="ltx_p" id="S4.SS1.SSS2.p17.1">Overall, HT data uses more non-literal translation techniques than MT data. Besides, the developing trends of two types of data in most of genres are similar except some slight points are out of steps. Two lines which are nearly in the same places when the translation techniques of lexical shift and transposition are used, which illustrates that GNMT has almost reached human parity when using these two translation techniques which are on syntactic levels.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Features of translation relations</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">Different translation techniques each have unique characteristics and linguistic causes that lead to the usage of a certain type of translation technique. This section compares this MT and HT data in terms of such characteristics and elements that lead to a certain translation technique.</p>
</div>
<section class="ltx_subsubsection" id="S4.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.1 </span>Equivalence</h4>
<div class="ltx_para" id="S4.SS2.SSS1.p1">
<p class="ltx_p" id="S4.SS2.SSS1.p1.1">Equivalence is generally applied twice as often in HT as it is in MT. However, not all matched pairings with equivalence annotations fall under the same linguistic classification. With observations and summarizing, there are five linguistic sub-categories covering slight semantic changes, named entities, phrase (fixed-expression), adjective translation, and refined translations which may be used to classify all aligned pairings using equivalence. As MT and HT share the same definitions, the examples chosen for these five kinds are taken from either MT or HT data. More numerical details can be seen in Table 9. More information about these five types are examplified.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS1.p2">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.SS2.SSS1.p2.1">
<tr class="ltx_tr" id="S4.SS2.SSS1.p2.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S4.SS2.SSS1.p2.1.1.1" style="padding-left:19.9pt;padding-right:19.9pt;">      Sub-categories of equivalence</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.SS2.SSS1.p2.1.1.2" style="padding-left:19.9pt;padding-right:19.9pt;">      MT data aligned pairs</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt" id="S4.SS2.SSS1.p2.1.1.3" style="padding-left:19.9pt;padding-right:19.9pt;">      HT data aligned pairs</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS1.p2.1.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.SS2.SSS1.p2.1.2.1" style="padding-left:19.9pt;padding-right:19.9pt;">      Slight semantic changes</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS2.SSS1.p2.1.2.2" style="padding-left:19.9pt;padding-right:19.9pt;">      78</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S4.SS2.SSS1.p2.1.2.3" style="padding-left:19.9pt;padding-right:19.9pt;">      113</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS1.p2.1.3">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS1.p2.1.3.1" style="padding-left:19.9pt;padding-right:19.9pt;">      Named entity</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS1.p2.1.3.2" style="padding-left:19.9pt;padding-right:19.9pt;">      40</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS1.p2.1.3.3" style="padding-left:19.9pt;padding-right:19.9pt;">      83</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS1.p2.1.4">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS1.p2.1.4.1" style="padding-left:19.9pt;padding-right:19.9pt;">      Adjective</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS1.p2.1.4.2" style="padding-left:19.9pt;padding-right:19.9pt;">      14</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS1.p2.1.4.3" style="padding-left:19.9pt;padding-right:19.9pt;">      14</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS1.p2.1.5">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS1.p2.1.5.1" style="padding-left:19.9pt;padding-right:19.9pt;">      Refined words</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS1.p2.1.5.2" style="padding-left:19.9pt;padding-right:19.9pt;">      4</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS1.p2.1.5.3" style="padding-left:19.9pt;padding-right:19.9pt;">      63</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS1.p2.1.6">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S4.SS2.SSS1.p2.1.6.1" style="padding-left:19.9pt;padding-right:19.9pt;">      Total</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.SS2.SSS1.p2.1.6.2" style="padding-left:19.9pt;padding-right:19.9pt;">      136</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t" id="S4.SS2.SSS1.p2.1.6.3" style="padding-left:19.9pt;padding-right:19.9pt;">      273</td>
</tr>
</table>
</div>
<div class="ltx_para" id="S4.SS2.SSS1.p3">
<p class="ltx_p ltx_align_center" id="S4.SS2.SSS1.p3.1">Table 9 Five types of equivalence used in aligned pairs</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS1.p4">
<p class="ltx_p" id="S4.SS2.SSS1.p4.1">(1) slight semantic changes: Unlike literal translation, aligned translations of source texts have somewhat different meanings in the destination texts. However, this semantic similarity between aligned pairings is less than that of synonyms and more than that of completely distinct terms.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS1.p5">
<p class="ltx_p" id="S4.SS2.SSS1.p5.1">Example 1: 
<br class="ltx_break"/>Source sentence: Experience is not interesting till it begins to repeat itself , in fact , till it does that , it hardly is experience.
<br class="ltx_break"/><span class="ltx_ERROR undefined" id="S4.SS2.SSS1.p5.1.1">{CJK}</span>UTF8gbsnTarget sentence: 经验 是 没有 意义 的 ， 直到 它 开始 重复 自己 ， 事实上 ， 直到 它 这样 做 ， 它 很 难 成为 经验 。</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS1.p6">
<span class="ltx_ERROR undefined" id="S4.SS2.SSS1.p6.1">{CJK}</span>
<p class="ltx_p" id="S4.SS2.SSS1.p6.2">UTF8gbsnThe translation of the word "interesting" from the original text is “有意义的” (meaningful, significant). Despite the discrepancies between the two terms, it is not considered a translation mistake because it makes sense for the entire statement. In both HT and MT data, the category of "slight changes in semantics" has the biggest proportion in the application of equivalence, as shown in Table 7. However, the amount of data in HT corpora that falls under this category is 1.5 times more than that in MT corpora.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS1.p7">
<p class="ltx_p" id="S4.SS2.SSS1.p7.1">(2) Named entities: Named entities can be identified by a proper name, such as a person, place, business, product, etc.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS1.p8">
<p class="ltx_p" id="S4.SS2.SSS1.p8.1">Example 2: 
<br class="ltx_break"/>Source sentence: ( afp , washington ) the world health organization said that in china and india , the two countries whose combined tb cases account for one third of the world ’s total , great progress has been made in the prevention and treatment of this infectious disease .
<br class="ltx_break"/><span class="ltx_ERROR undefined" id="S4.SS2.SSS1.p8.1.1">{CJK}</span>UTF8gbsnTarget sentence: （ 法新社 华盛顿 ） 世界 卫生 组织 说 ， 在 中国 和 印度 这 两 个 结核病 病例 合并 占 世界 总数 三分之一 的 国家 ， 在 防治 这 一 传染病 方面 取得 了 很 大 进展 。</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS1.p9">
<p class="ltx_p" id="S4.SS2.SSS1.p9.1">"TB" stands for tuberculosis in the original language. Equivalence is applied to deal with such named entities. Named entities which result in the application of equivalence The second most common scenario from Table 7. The fact that HT data recognizes and translates twice as many name entities as MT data shows that NMT is unable to recognize some name entities, such as "OO" (the acronym for "object-oriented") in MT data.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS1.p10">
<p class="ltx_p" id="S4.SS2.SSS1.p10.1">(3) phrase (fixed-expression): Some sentences have their own fixed translations that cannot make sense by a literal translation.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS1.p11">
<p class="ltx_p" id="S4.SS2.SSS1.p11.1">Example 3: 
<br class="ltx_break"/>Source sentence: But in one respect I have succeeded as gloriously as anyone who ’s ever lived : I ’ve loved another with all my heart and soul ;
<br class="ltx_break"/><span class="ltx_ERROR undefined" id="S4.SS2.SSS1.p11.1.1">{CJK}</span>UTF8gbsnTarget sentence: 但 在 某 一 方面 ， 我 的 成功 与 以往 任何人 一样 光荣 ： 我 全心全意 地 爱 着 另 一个 人 ；</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS1.p12">
<span class="ltx_ERROR undefined" id="S4.SS2.SSS1.p12.1">{CJK}</span>
<p class="ltx_p" id="S4.SS2.SSS1.p12.2">UTF8gbsnIf "with all my heart and soul" in the original text is translated literally, the result is “用我的真心和灵魂” which does not match the Chinese idiomatic expressions. Instead, the comparable statement in Chinese is represented by a four-character word “全心全意” (whole-heartedly). For fixed phrases, there are still twice as many translations in HT than there are in MT data.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS1.p13">
<p class="ltx_p" id="S4.SS2.SSS1.p13.1">(4) Adjective translation: In order to make adjectives seem more natural and catchy in Chinese, adjectives are frequently translated into "four-character" terms.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS1.p14">
<p class="ltx_p" id="S4.SS2.SSS1.p14.1">Example 4: 
<br class="ltx_break"/>Source sentence: he said : " she is just like the girl next door , extremely amiable and also with an inspiring life story . ”
<br class="ltx_break"/><span class="ltx_ERROR undefined" id="S4.SS2.SSS1.p14.1.1">{CJK}</span>UTF8gbsnTarget sentence: 他 说 ： “ 她 就 像 邻 家 女孩 一样 ， 非常 和蔼可亲 ， 也 有 励志 的 人生 故事 。 ”</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS1.p15">
<p class="ltx_p" id="S4.SS2.SSS1.p15.1">Example 5: 
<br class="ltx_break"/>Source sentence: Now , in research that will be embraced by millions of bleary - eyed Britons
<br class="ltx_break"/><span class="ltx_ERROR undefined" id="S4.SS2.SSS1.p15.1.1">{CJK}</span>UTF8gbsnTarget sentence: 现在 ， 在 一 项 将 被 数百万 睡眼惺忪 的 英国 人 所 接受 的 研究 中</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS1.p16">
<p class="ltx_p" id="S4.SS2.SSS1.p16.1">Translations of "amiable" and "bleary-eyed" into "four-character" terms make them more consistent with Chinese idioms and styles. The performance in HT data is equivalent to that of MT data.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS1.p17">
<p class="ltx_p" id="S4.SS2.SSS1.p17.1">(5) Refined translations: While it is permissible to translate words or texts exactly as they appear in the source language, the translators would improve the translation by taking the texts’ styles into account in order to make the translations better fit the target language’s contexts and expressions.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS1.p18">
<p class="ltx_p" id="S4.SS2.SSS1.p18.1">Example 6:
<br class="ltx_break"/>Source sentence: A wind had cleared the mist , the autumn leaves were rustling and the stars were shining .
<br class="ltx_break"/><span class="ltx_ERROR undefined" id="S4.SS2.SSS1.p18.1.1">{CJK}</span>UTF8gbsnTarget sentence: 一阵 风 吹 散 了 雾霭 ， 秋叶 沙沙 作响 ， 繁星 闪烁 。</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS1.p19">
<p class="ltx_p" id="S4.SS2.SSS1.p19.1">Example 6 employs literary terms to translate a text that portrays natural scenery and illustrates an aesthetic idea. The difference between the two sets of data on refined terms is enormous. Only four pairs in the MT data employ the revised translation, compared to 64 pairs in the HT data, which clearly shows how little capacity the GNMT system has to refine the translation based on contextual information.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS1.p20">
<p class="ltx_p" id="S4.SS2.SSS1.p20.1">To summarize, equivalence is a typical translation technique involves semantic knowledge on appropriate word selection to conform the context and styles in the target languages. It is evident that GNMT does perform well in this aspect.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS2.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.2 </span>Figurative translation</h4>
<div class="ltx_para" id="S4.SS2.SSS2.p1">
<span class="ltx_ERROR undefined" id="S4.SS2.SSS2.p1.1">{CJK}</span>
<p class="ltx_p" id="S4.SS2.SSS2.p1.2">UTF8gbsnThe goal of figurative translation is to explain a non-metaphor or non-fixed term using an idiom or metaphor; personification is also occasionally used. It occasionally takes contextual information into account. For instance, the word "simple" can be rendered as ‘柴米油盐’ (an idiom that means basic life necessities). In all aligned pairs, there are only four aligned pairs using figurative translation in HT and one in MT data, which reflects two issues: first, it is very difficult to be utilized in both human translation and machine translation, and second, the amount of data that is now available is extremely minimal, making it impossible to do analysis for this kind of technique.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS2.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.3 </span>Generalization</h4>
<div class="ltx_para" id="S4.SS2.SSS3.p1">
<span class="ltx_ERROR undefined" id="S4.SS2.SSS3.p1.1">{CJK}</span>
<p class="ltx_p" id="S4.SS2.SSS3.p1.2">UTF8gbsnWhen the technique of generation is examined, it mostly depends on two ways. The sentences in the brief names are chopped into multiple sections in the original materials, and the translation only uses one or a few of those portions. For example, in the phrase “anyone who is” is translated into “任何人” (anyone) instead of “任何人，他是”, and “refrain from” is translated into “不” (not) rather than “不让”. The second technique involves utilizing hyperonyms in the translated text, which implies that the phrase is used more general than in the original text. For example, “troops” is translated into “人” (people), and “travelling back” is translated into “返回” (returning back) rather than “旅行回来”.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS3.p2">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.SS2.SSS3.p2.1">
<tr class="ltx_tr" id="S4.SS2.SSS3.p2.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S4.SS2.SSS3.p2.1.1.1" style="padding-left:19.9pt;padding-right:19.9pt;">      Sub-categories of generalization</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.SS2.SSS3.p2.1.1.2" style="padding-left:19.9pt;padding-right:19.9pt;">      MT data</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt" id="S4.SS2.SSS3.p2.1.1.3" style="padding-left:19.9pt;padding-right:19.9pt;">      HT data</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS3.p2.1.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.SS2.SSS3.p2.1.2.1" style="padding-left:19.9pt;padding-right:19.9pt;">      Short names</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS2.SSS3.p2.1.2.2" style="padding-left:19.9pt;padding-right:19.9pt;">      13</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S4.SS2.SSS3.p2.1.2.3" style="padding-left:19.9pt;padding-right:19.9pt;">      4</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS3.p2.1.3">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS3.p2.1.3.1" style="padding-left:19.9pt;padding-right:19.9pt;">      Hyperonyms</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS3.p2.1.3.2" style="padding-left:19.9pt;padding-right:19.9pt;">      19</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS3.p2.1.3.3" style="padding-left:19.9pt;padding-right:19.9pt;">      45</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS3.p2.1.4">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S4.SS2.SSS3.p2.1.4.1" style="padding-left:19.9pt;padding-right:19.9pt;">      Total</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.SS2.SSS3.p2.1.4.2" style="padding-left:19.9pt;padding-right:19.9pt;">      32</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t" id="S4.SS2.SSS3.p2.1.4.3" style="padding-left:19.9pt;padding-right:19.9pt;">      49</td>
</tr>
</table>
</div>
<div class="ltx_para" id="S4.SS2.SSS3.p3">
<p class="ltx_p ltx_align_center" id="S4.SS2.SSS3.p3.1">Table 10 Two methods of generalization used in aligned pairs</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS3.p4">
<p class="ltx_p" id="S4.SS2.SSS3.p4.1">The application of short names and hyperonyms is calculated separately for HT and MT data; the particular data are shown in Table 10. Although the amount of data in both data sets is comparably small, the usage of hyperonyms in HT corpora is far higher than that in MT data, demonstrating that the NMT system does not have the same potential for generalization as human translators.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS2.SSS4">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.4 </span>Lexical shift</h4>
<div class="ltx_para" id="S4.SS2.SSS4.p1">
<p class="ltx_p" id="S4.SS2.SSS4.p1.1">In both aligned corpora, the lexical shift is a frequently used approach which has the typical attribute of syntax. When verbs in phrases include traces of the present tense or the past tense, or when nouns are plural, lexical shift is used. According to Table 11, the number of tense and plural nouns that trigger lexical shift in MT data is a little higher than it is in HT data.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS4.p2">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.SS2.SSS4.p2.1">
<tr class="ltx_tr" id="S4.SS2.SSS4.p2.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S4.SS2.SSS4.p2.1.1.1" style="padding-left:19.9pt;padding-right:19.9pt;">      Sub-categories of lexical_shift</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.SS2.SSS4.p2.1.1.2" style="padding-left:19.9pt;padding-right:19.9pt;">      MT data</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt" id="S4.SS2.SSS4.p2.1.1.3" style="padding-left:19.9pt;padding-right:19.9pt;">      HT data</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS4.p2.1.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.SS2.SSS4.p2.1.2.1" style="padding-left:19.9pt;padding-right:19.9pt;">      Plural nouns</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS2.SSS4.p2.1.2.2" style="padding-left:19.9pt;padding-right:19.9pt;">      455</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S4.SS2.SSS4.p2.1.2.3" style="padding-left:19.9pt;padding-right:19.9pt;">      432</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS4.p2.1.3">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS4.p2.1.3.1" style="padding-left:19.9pt;padding-right:19.9pt;">      Tense</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS4.p2.1.3.2" style="padding-left:19.9pt;padding-right:19.9pt;">      301</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS4.p2.1.3.3" style="padding-left:19.9pt;padding-right:19.9pt;">      273</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS4.p2.1.4">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S4.SS2.SSS4.p2.1.4.1" style="padding-left:19.9pt;padding-right:19.9pt;">      Total</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.SS2.SSS4.p2.1.4.2" style="padding-left:19.9pt;padding-right:19.9pt;">      756</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t" id="S4.SS2.SSS4.p2.1.4.3" style="padding-left:19.9pt;padding-right:19.9pt;">      705</td>
</tr>
</table>
</div>
<div class="ltx_para" id="S4.SS2.SSS4.p3">
<p class="ltx_p ltx_align_center" id="S4.SS2.SSS4.p3.1">Table 11 Two cases of lexical shift used in aligned pairs</p>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS2.SSS5">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.5 </span>Modulation</h4>
<div class="ltx_para" id="S4.SS2.SSS5.p1">
<span class="ltx_ERROR undefined" id="S4.SS2.SSS5.p1.1">{CJK}</span>
<p class="ltx_p" id="S4.SS2.SSS5.p1.2">UTF8gbsnIrony and the switch from passive to active voice are the two distinctive characteristics that cause modulation to be used. In English, the passive voice is widely employed to show objectivity by combining "be+past tense of verb". However, passive voice is uncommon in Chinese; instead, active voice is frequently used. The conversion of passive speech to active voice is therefore one characteristic of modulation. Irony is also a characteristic of this approach. It’s a figure of speech that emphasizes a point by saying the exact opposite of what is meant; the words’ intended meaning is the complete reverse of their usual meaning. For example. “difficult” is translated into “不容易” (not easy) by using irony of modulation. The conversion from passive to active voice is the most frequently used category in modulation, and GNMT system can achieve the same performance with that produced by human translators. In the meanwhile, irony is utilized less frequently in both HT and MT data, but HT data in this category is twice as common as MT data.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS5.p2">
<p class="ltx_p" id="S4.SS2.SSS5.p2.1">According to the sub-categories, modulation is a method that combining both syntactic and semantic knowledge since the voice conversion belongs to syntactic level while irony to semantic level. That GNMT’s performance is good on the former factor but bad on the latter once asserts that GNMT’s performance on syntax is better that on semantics.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS5.p3">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.SS2.SSS5.p3.1">
<tr class="ltx_tr" id="S4.SS2.SSS5.p3.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S4.SS2.SSS5.p3.1.1.1" style="padding-left:19.9pt;padding-right:19.9pt;">      Sub-categories of modulation</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.SS2.SSS5.p3.1.1.2" style="padding-left:19.9pt;padding-right:19.9pt;">      MT data</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt" id="S4.SS2.SSS5.p3.1.1.3" style="padding-left:19.9pt;padding-right:19.9pt;">      HT data</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS5.p3.1.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.SS2.SSS5.p3.1.2.1" style="padding-left:19.9pt;padding-right:19.9pt;">      Passive voice to active voice</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS2.SSS5.p3.1.2.2" style="padding-left:19.9pt;padding-right:19.9pt;">      72</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S4.SS2.SSS5.p3.1.2.3" style="padding-left:19.9pt;padding-right:19.9pt;">      70</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS5.p3.1.3">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS5.p3.1.3.1" style="padding-left:19.9pt;padding-right:19.9pt;">      Irony</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS5.p3.1.3.2" style="padding-left:19.9pt;padding-right:19.9pt;">      11</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS5.p3.1.3.3" style="padding-left:19.9pt;padding-right:19.9pt;">      23</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS5.p3.1.4">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS5.p3.1.4.1" style="padding-left:19.9pt;padding-right:19.9pt;">      Others</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS5.p3.1.4.2" style="padding-left:19.9pt;padding-right:19.9pt;">      12</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS5.p3.1.4.3" style="padding-left:19.9pt;padding-right:19.9pt;">      35</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS5.p3.1.5">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S4.SS2.SSS5.p3.1.5.1" style="padding-left:19.9pt;padding-right:19.9pt;">      Total</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.SS2.SSS5.p3.1.5.2" style="padding-left:19.9pt;padding-right:19.9pt;">      95</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t" id="S4.SS2.SSS5.p3.1.5.3" style="padding-left:19.9pt;padding-right:19.9pt;">      128</td>
</tr>
</table>
</div>
<div class="ltx_para" id="S4.SS2.SSS5.p4">
<p class="ltx_p ltx_align_center" id="S4.SS2.SSS5.p4.1">Table 12 Two cases of lexical shift used in aligned pairs</p>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS2.SSS6">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.6 </span>Modulation + Transposition</h4>
<div class="ltx_para" id="S4.SS2.SSS6.p1">
<span class="ltx_ERROR undefined" id="S4.SS2.SSS6.p1.1">{CJK}</span>
<p class="ltx_p" id="S4.SS2.SSS6.p1.2">UTF8gbsnThe most common use of “modulation+transposition” is the translation of propositional phrases. While the meaning remains the same, the manner of syntactic expressions changes, the proposition will be transferred to another POS labeling, something verbs. For example, “in” is translated into “用”(use), where both meaning and POS have changed. Such case in HT data is nearly twice than that in MT data according to Table 13.</p>
</div>
<div class="ltx_logical-block" id="S4.SS2.SSS6.1">
<div class="ltx_para" id="S4.SS2.SSS6.1.p1">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.SS2.SSS6.1.p1.1">
<tr class="ltx_tr" id="S4.SS2.SSS6.1.p1.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S4.SS2.SSS6.1.p1.1.1.1" style="padding-left:19.9pt;padding-right:19.9pt;">      Sub-categories of modulation + transposition</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.SS2.SSS6.1.p1.1.1.2" style="padding-left:19.9pt;padding-right:19.9pt;">      MT data</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt" id="S4.SS2.SSS6.1.p1.1.1.3" style="padding-left:19.9pt;padding-right:19.9pt;">      HT data</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS6.1.p1.1.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.SS2.SSS6.1.p1.1.2.1" style="padding-left:19.9pt;padding-right:19.9pt;">      Proposition</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS2.SSS6.1.p1.1.2.2" style="padding-left:19.9pt;padding-right:19.9pt;">      11</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S4.SS2.SSS6.1.p1.1.2.3" style="padding-left:19.9pt;padding-right:19.9pt;">      18</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS6.1.p1.1.3">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS6.1.p1.1.3.1" style="padding-left:19.9pt;padding-right:19.9pt;">      Others</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS6.1.p1.1.3.2" style="padding-left:19.9pt;padding-right:19.9pt;">      7</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS6.1.p1.1.3.3" style="padding-left:19.9pt;padding-right:19.9pt;">      4</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS6.1.p1.1.4">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S4.SS2.SSS6.1.p1.1.4.1" style="padding-left:19.9pt;padding-right:19.9pt;">      Total</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.SS2.SSS6.1.p1.1.4.2" style="padding-left:19.9pt;padding-right:19.9pt;">      18</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t" id="S4.SS2.SSS6.1.p1.1.4.3" style="padding-left:19.9pt;padding-right:19.9pt;">      22</td>
</tr>
</table>
</div>
</div>
<div class="ltx_para" id="S4.SS2.SSS6.p2">
<p class="ltx_p ltx_align_center" id="S4.SS2.SSS6.p2.1">Table 13 Two cases of lexical shift used in aligned pairs</p>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS2.SSS7">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.7 </span>Particularization</h4>
<div class="ltx_para" id="S4.SS2.SSS7.p1">
<span class="ltx_ERROR undefined" id="S4.SS2.SSS7.p1.1">{CJK}</span>
<p class="ltx_p" id="S4.SS2.SSS7.p1.2">UTF8gbsnTo determine how information from the original text is translated by applying particularization, part-of-speech tagging is employed. The computation of data processing shows that pronouns, nouns, verbs, adjectives, and adverbs are the five categories of POS terms that are most likely to be translated by using the technique of particularization. For example, several “it” are contained in one sentence, and if all “it” are translated into “它” (it), the translation into Chinese would be terrible since numerous instances of “它” (it) do not adhere to Chinese expressions. Each POS type in HT data typically employs twice as much method as it does in MT data. It requires contextual information to name a single pronoun or term from the source texts in the translation, demonstrating how inadequate GNMT’s understanding of contexts is.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS7.p2">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.SS2.SSS7.p2.1">
<tr class="ltx_tr" id="S4.SS2.SSS7.p2.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S4.SS2.SSS7.p2.1.1.1" style="padding-left:19.9pt;padding-right:19.9pt;">      POS-based sub-categories of particularization</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.SS2.SSS7.p2.1.1.2" style="padding-left:19.9pt;padding-right:19.9pt;">      MT data</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt" id="S4.SS2.SSS7.p2.1.1.3" style="padding-left:19.9pt;padding-right:19.9pt;">      HT data</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS7.p2.1.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.SS2.SSS7.p2.1.2.1" style="padding-left:19.9pt;padding-right:19.9pt;">      Pronoun</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS2.SSS7.p2.1.2.2" style="padding-left:19.9pt;padding-right:19.9pt;">      23</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S4.SS2.SSS7.p2.1.2.3" style="padding-left:19.9pt;padding-right:19.9pt;">      47</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS7.p2.1.3">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS7.p2.1.3.1" style="padding-left:19.9pt;padding-right:19.9pt;">      Noun</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS7.p2.1.3.2" style="padding-left:19.9pt;padding-right:19.9pt;">      41</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS7.p2.1.3.3" style="padding-left:19.9pt;padding-right:19.9pt;">      87</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS7.p2.1.4">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS7.p2.1.4.1" style="padding-left:19.9pt;padding-right:19.9pt;">      Verb</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS7.p2.1.4.2" style="padding-left:19.9pt;padding-right:19.9pt;">      23</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS7.p2.1.4.3" style="padding-left:19.9pt;padding-right:19.9pt;">      60</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS7.p2.1.5">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS7.p2.1.5.1" style="padding-left:19.9pt;padding-right:19.9pt;">      Adv., Adj.</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS7.p2.1.5.2" style="padding-left:19.9pt;padding-right:19.9pt;">      15</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS7.p2.1.5.3" style="padding-left:19.9pt;padding-right:19.9pt;">      30</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS7.p2.1.6">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S4.SS2.SSS7.p2.1.6.1" style="padding-left:19.9pt;padding-right:19.9pt;">      Total</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.SS2.SSS7.p2.1.6.2" style="padding-left:19.9pt;padding-right:19.9pt;">      102</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t" id="S4.SS2.SSS7.p2.1.6.3" style="padding-left:19.9pt;padding-right:19.9pt;">      224</td>
</tr>
</table>
</div>
<div class="ltx_para" id="S4.SS2.SSS7.p3">
<p class="ltx_p ltx_align_center" id="S4.SS2.SSS7.p3.1">Table 14 POS-categorized particularization</p>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS2.SSS8">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.8 </span>Transposition</h4>
<div class="ltx_para" id="S4.SS2.SSS8.p1">
<span class="ltx_ERROR undefined" id="S4.SS2.SSS8.p1.1">{CJK}</span>
<p class="ltx_p" id="S4.SS2.SSS8.p1.2">UTF8gbsnBetween the source and destination languages, POS labeling is mutually transferred during transposition. The most common POS transfers from the most recent MT and HT data sets are shown in Table 15. The most frequent POS transfers are ADP—PART, ADJ—NOUN, and NOUN—VERB. The most ADP—PART pairs are used because there are many instances of "of" in phrases and "that/which" in attributive clauses, both of which are translated into “的” (’s) in Chinese. For ADJ—NOUN, it is rare to see that “…的” in Chinese, and adjectives sometimes are converted into “generic verb” + “a noun”. For example, “homophonic”, an adjective is translated into “谐音”, a noun. Translation from nouns to verbs is also a common see, as the Chinese language uses more verbs than nouns (Choi et al., 1995; Kim et al., 2000; Ogura, 2001; Tardif, 1996; Imai et al., 2008).</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS8.p2">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.SS2.SSS8.p2.1">
<tr class="ltx_tr" id="S4.SS2.SSS8.p2.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S4.SS2.SSS8.p2.1.1.1" style="padding-left:19.9pt;padding-right:19.9pt;">      POS-transfer-based sub-categories of transposition</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.SS2.SSS8.p2.1.1.2" style="padding-left:19.9pt;padding-right:19.9pt;">      MT data</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt" id="S4.SS2.SSS8.p2.1.1.3" style="padding-left:19.9pt;padding-right:19.9pt;">      HT data</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS8.p2.1.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.SS2.SSS8.p2.1.2.1" style="padding-left:19.9pt;padding-right:19.9pt;">      ADP—PART</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS2.SSS8.p2.1.2.2" style="padding-left:19.9pt;padding-right:19.9pt;">      120</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S4.SS2.SSS8.p2.1.2.3" style="padding-left:19.9pt;padding-right:19.9pt;">      113</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS8.p2.1.3">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS8.p2.1.3.1" style="padding-left:19.9pt;padding-right:19.9pt;">      ADJ—NOUN</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS8.p2.1.3.2" style="padding-left:19.9pt;padding-right:19.9pt;">      69</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS8.p2.1.3.3" style="padding-left:19.9pt;padding-right:19.9pt;">      79</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS8.p2.1.4">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS8.p2.1.4.1" style="padding-left:19.9pt;padding-right:19.9pt;">      ADP—NOUN</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS8.p2.1.4.2" style="padding-left:19.9pt;padding-right:19.9pt;">      18</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS8.p2.1.4.3" style="padding-left:19.9pt;padding-right:19.9pt;">      31</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS8.p2.1.5">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS8.p2.1.5.1" style="padding-left:19.9pt;padding-right:19.9pt;">      ADJ—PROPN</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS8.p2.1.5.2" style="padding-left:19.9pt;padding-right:19.9pt;">      18</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS8.p2.1.5.3" style="padding-left:19.9pt;padding-right:19.9pt;">      11</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS8.p2.1.6">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS8.p2.1.6.1" style="padding-left:19.9pt;padding-right:19.9pt;">      PRON—PART</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS8.p2.1.6.2" style="padding-left:19.9pt;padding-right:19.9pt;">      17</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS8.p2.1.6.3" style="padding-left:19.9pt;padding-right:19.9pt;">      17</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS8.p2.1.7">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS8.p2.1.7.1" style="padding-left:19.9pt;padding-right:19.9pt;">      NOUN—VERB</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS8.p2.1.7.2" style="padding-left:19.9pt;padding-right:19.9pt;">      71</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS8.p2.1.7.3" style="padding-left:19.9pt;padding-right:19.9pt;">      76</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS8.p2.1.8">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS8.p2.1.8.1" style="padding-left:19.9pt;padding-right:19.9pt;">      ADJ—PART</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS8.p2.1.8.2" style="padding-left:19.9pt;padding-right:19.9pt;">      10</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS8.p2.1.8.3" style="padding-left:19.9pt;padding-right:19.9pt;">      6</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS8.p2.1.9">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS8.p2.1.9.1" style="padding-left:19.9pt;padding-right:19.9pt;">      ADP—VERB</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS8.p2.1.9.2" style="padding-left:19.9pt;padding-right:19.9pt;">      10</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS8.p2.1.9.3" style="padding-left:19.9pt;padding-right:19.9pt;">      18</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS8.p2.1.10">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS8.p2.1.10.1" style="padding-left:19.9pt;padding-right:19.9pt;">      ADJ—VERB</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS8.p2.1.10.2" style="padding-left:19.9pt;padding-right:19.9pt;">      11</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS8.p2.1.10.3" style="padding-left:19.9pt;padding-right:19.9pt;">      14</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS8.p2.1.11">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS8.p2.1.11.1" style="padding-left:19.9pt;padding-right:19.9pt;">      VERB—NOUN</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS8.p2.1.11.2" style="padding-left:19.9pt;padding-right:19.9pt;">      11</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS8.p2.1.11.3" style="padding-left:19.9pt;padding-right:19.9pt;">      8</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS8.p2.1.12">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS8.p2.1.12.1" style="padding-left:19.9pt;padding-right:19.9pt;">      ADJ—ADV</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS8.p2.1.12.2" style="padding-left:19.9pt;padding-right:19.9pt;">      7</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS8.p2.1.12.3" style="padding-left:19.9pt;padding-right:19.9pt;">      7</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS8.p2.1.13">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS8.p2.1.13.1" style="padding-left:19.9pt;padding-right:19.9pt;">      DET—PART</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS8.p2.1.13.2" style="padding-left:19.9pt;padding-right:19.9pt;">      6</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS8.p2.1.13.3" style="padding-left:19.9pt;padding-right:19.9pt;">      5</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS8.p2.1.14">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS8.p2.1.14.1" style="padding-left:19.9pt;padding-right:19.9pt;">      Other</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS8.p2.1.14.2" style="padding-left:19.9pt;padding-right:19.9pt;">      132</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS8.p2.1.14.3" style="padding-left:19.9pt;padding-right:19.9pt;">      160</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS8.p2.1.15">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S4.SS2.SSS8.p2.1.15.1" style="padding-left:19.9pt;padding-right:19.9pt;">      Total</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.SS2.SSS8.p2.1.15.2" style="padding-left:19.9pt;padding-right:19.9pt;">      500</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t" id="S4.SS2.SSS8.p2.1.15.3" style="padding-left:19.9pt;padding-right:19.9pt;">      545</td>
</tr>
</table>
</div>
<div class="ltx_para" id="S4.SS2.SSS8.p3">
<p class="ltx_p ltx_align_center" id="S4.SS2.SSS8.p3.1">Table 15 POS transfers in transposition</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS8.p4">
<p class="ltx_p" id="S4.SS2.SSS8.p4.1">The transfer of word POS is totally one pure aspect of syntax. HT data only performs slight better than MT data when transposition is used, demonstrating that GNMT can perform well when transposition is used.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS2.SSS9">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.9 </span>Unaligned-explicitation</h4>
<div class="ltx_para" id="S4.SS2.SSS9.p1">
<span class="ltx_ERROR undefined" id="S4.SS2.SSS9.p1.1">{CJK}</span>
<p class="ltx_p" id="S4.SS2.SSS9.p1.2">UTF8gbsnExplicitation or additional information added in translation to make the output more natural is used in the source texts, and the additional information in the translation cannot be found in its corresponding source texts. Overall, in human translation, there is more additional information than MT data, showing that more consciousness is put into translation processes. The translation additionally added in the target texts is analyzed through POS tagging (see Table 16), and the most frequent occurrences are PART, VERB, NOUN and NUM of Chinese tokens. They can represent function words such as “了” and “就”, and number words like “一 头”, “一 句” which are not used in English.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS9.p2">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.SS2.SSS9.p2.1">
<tr class="ltx_tr" id="S4.SS2.SSS9.p2.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S4.SS2.SSS9.p2.1.1.1" style="padding-left:19.9pt;padding-right:19.9pt;">      POS-transfer-based sub-categories of unaligned-explicitation</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.SS2.SSS9.p2.1.1.2" style="padding-left:19.9pt;padding-right:19.9pt;">      MT data</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt" id="S4.SS2.SSS9.p2.1.1.3" style="padding-left:19.9pt;padding-right:19.9pt;">      HT data</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS9.p2.1.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.SS2.SSS9.p2.1.2.1" style="padding-left:19.9pt;padding-right:19.9pt;">      ADV</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS2.SSS9.p2.1.2.2" style="padding-left:19.9pt;padding-right:19.9pt;">      71</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S4.SS2.SSS9.p2.1.2.3" style="padding-left:19.9pt;padding-right:19.9pt;">      148</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS9.p2.1.3">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS9.p2.1.3.1" style="padding-left:19.9pt;padding-right:19.9pt;">      PART</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS9.p2.1.3.2" style="padding-left:19.9pt;padding-right:19.9pt;">      253</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS9.p2.1.3.3" style="padding-left:19.9pt;padding-right:19.9pt;">      223</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS9.p2.1.4">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS9.p2.1.4.1" style="padding-left:19.9pt;padding-right:19.9pt;">      VERB</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS9.p2.1.4.2" style="padding-left:19.9pt;padding-right:19.9pt;">      112</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS9.p2.1.4.3" style="padding-left:19.9pt;padding-right:19.9pt;">      175</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS9.p2.1.5">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS9.p2.1.5.1" style="padding-left:19.9pt;padding-right:19.9pt;">      NUM</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS9.p2.1.5.2" style="padding-left:19.9pt;padding-right:19.9pt;">      97</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS9.p2.1.5.3" style="padding-left:19.9pt;padding-right:19.9pt;">      143</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS9.p2.1.6">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS9.p2.1.6.1" style="padding-left:19.9pt;padding-right:19.9pt;">      NOUN</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS9.p2.1.6.2" style="padding-left:19.9pt;padding-right:19.9pt;">      109</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS9.p2.1.6.3" style="padding-left:19.9pt;padding-right:19.9pt;">      262</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS9.p2.1.7">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS9.p2.1.7.1" style="padding-left:19.9pt;padding-right:19.9pt;">      PRON</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS9.p2.1.7.2" style="padding-left:19.9pt;padding-right:19.9pt;">      16</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS9.p2.1.7.3" style="padding-left:19.9pt;padding-right:19.9pt;">      17</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS9.p2.1.8">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS9.p2.1.8.1" style="padding-left:19.9pt;padding-right:19.9pt;">      X</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS9.p2.1.8.2" style="padding-left:19.9pt;padding-right:19.9pt;">      18</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS9.p2.1.8.3" style="padding-left:19.9pt;padding-right:19.9pt;">      11</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS9.p2.1.9">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS9.p2.1.9.1" style="padding-left:19.9pt;padding-right:19.9pt;">      CCONJ</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS9.p2.1.9.2" style="padding-left:19.9pt;padding-right:19.9pt;">      7</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS9.p2.1.9.3" style="padding-left:19.9pt;padding-right:19.9pt;">      17</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS9.p2.1.10">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS9.p2.1.10.1" style="padding-left:19.9pt;padding-right:19.9pt;">      ADP</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS9.p2.1.10.2" style="padding-left:19.9pt;padding-right:19.9pt;">      26</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS9.p2.1.10.3" style="padding-left:19.9pt;padding-right:19.9pt;">      46</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS9.p2.1.11">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS9.p2.1.11.1" style="padding-left:19.9pt;padding-right:19.9pt;">      PUNCT</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS9.p2.1.11.2" style="padding-left:19.9pt;padding-right:19.9pt;">      11</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS9.p2.1.11.3" style="padding-left:19.9pt;padding-right:19.9pt;">      53</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS9.p2.1.12">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS9.p2.1.12.1" style="padding-left:19.9pt;padding-right:19.9pt;">      ADJ</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS9.p2.1.12.2" style="padding-left:19.9pt;padding-right:19.9pt;">      7</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS9.p2.1.12.3" style="padding-left:19.9pt;padding-right:19.9pt;">      21</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS9.p2.1.13">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS9.p2.1.13.1" style="padding-left:19.9pt;padding-right:19.9pt;">      DET</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS9.p2.1.13.2" style="padding-left:19.9pt;padding-right:19.9pt;">      3</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS9.p2.1.13.3" style="padding-left:19.9pt;padding-right:19.9pt;">      23</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS9.p2.1.14">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS9.p2.1.14.1" style="padding-left:19.9pt;padding-right:19.9pt;">      PROPN</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS9.p2.1.14.2" style="padding-left:19.9pt;padding-right:19.9pt;">      6</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS9.p2.1.14.3" style="padding-left:19.9pt;padding-right:19.9pt;">      21</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS9.p2.1.15">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS9.p2.1.15.1" style="padding-left:19.9pt;padding-right:19.9pt;">      SCONJ</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS9.p2.1.15.2" style="padding-left:19.9pt;padding-right:19.9pt;">      0</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS9.p2.1.15.3" style="padding-left:19.9pt;padding-right:19.9pt;">      3</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS9.p2.1.16">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS9.p2.1.16.1" style="padding-left:19.9pt;padding-right:19.9pt;">      Others</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS9.p2.1.16.2" style="padding-left:19.9pt;padding-right:19.9pt;">      0</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS9.p2.1.16.3" style="padding-left:19.9pt;padding-right:19.9pt;">      37</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS9.p2.1.17">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S4.SS2.SSS9.p2.1.17.1" style="padding-left:19.9pt;padding-right:19.9pt;">      Total</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.SS2.SSS9.p2.1.17.2" style="padding-left:19.9pt;padding-right:19.9pt;">      736</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t" id="S4.SS2.SSS9.p2.1.17.3" style="padding-left:19.9pt;padding-right:19.9pt;">      1220</td>
</tr>
</table>
</div>
<div class="ltx_para" id="S4.SS2.SSS9.p3">
<p class="ltx_p ltx_align_center" id="S4.SS2.SSS9.p3.1">Table 16 Top added POS tagging in Unaligned-explicitation</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS9.p4">
<p class="ltx_p" id="S4.SS2.SSS9.p4.1">The tokens that do not have their counterpart in the sources texts are additionally translated in the target texts, and in this case, apart from analyzing POS of these additional tokens, it is similarly important to know what kind of dependency relations that these tokens are. Most dependency relations of explicitation in HT data are twice of those in MT data, among which punct, compound:nn, dobj, and nsubj in MT data are the worst. However, the dependency of mark in MT data is more than in HT data. It shows that GNMT is not apt to add additional words into translation which can make translation more natural. In this case, both POS and dependency relations are detected, which can give a direction for the follow-up work of optimizaing NMT systems on expliciation.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS9.p5">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.SS2.SSS9.p5.1">
<tr class="ltx_tr" id="S4.SS2.SSS9.p5.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S4.SS2.SSS9.p5.1.1.1" style="padding-left:19.9pt;padding-right:19.9pt;">      DEP-transfer-based sub-categories of unaligned-explicitation</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.SS2.SSS9.p5.1.1.2" style="padding-left:19.9pt;padding-right:19.9pt;">      MT data</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt" id="S4.SS2.SSS9.p5.1.1.3" style="padding-left:19.9pt;padding-right:19.9pt;">      HT data</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS9.p5.1.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.SS2.SSS9.p5.1.2.1" style="padding-left:19.9pt;padding-right:19.9pt;">      case</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS2.SSS9.p5.1.2.2" style="padding-left:19.9pt;padding-right:19.9pt;">      140</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S4.SS2.SSS9.p5.1.2.3" style="padding-left:19.9pt;padding-right:19.9pt;">      155</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS9.p5.1.3">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS9.p5.1.3.1" style="padding-left:19.9pt;padding-right:19.9pt;">      advmod</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS9.p5.1.3.2" style="padding-left:19.9pt;padding-right:19.9pt;">      69</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS9.p5.1.3.3" style="padding-left:19.9pt;padding-right:19.9pt;">      153</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS9.p5.1.4">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS9.p5.1.4.1" style="padding-left:19.9pt;padding-right:19.9pt;">      dep</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS9.p5.1.4.2" style="padding-left:19.9pt;padding-right:19.9pt;">      46</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS9.p5.1.4.3" style="padding-left:19.9pt;padding-right:19.9pt;">      95</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS9.p5.1.5">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS9.p5.1.5.1" style="padding-left:19.9pt;padding-right:19.9pt;">      compound:nn</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS9.p5.1.5.2" style="padding-left:19.9pt;padding-right:19.9pt;">      22</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS9.p5.1.5.3" style="padding-left:19.9pt;padding-right:19.9pt;">      94</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS9.p5.1.6">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS9.p5.1.6.1" style="padding-left:19.9pt;padding-right:19.9pt;">      mark:clf</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS9.p5.1.6.2" style="padding-left:19.9pt;padding-right:19.9pt;">      64</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS9.p5.1.6.3" style="padding-left:19.9pt;padding-right:19.9pt;">      89</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS9.p5.1.7">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS9.p5.1.7.1" style="padding-left:19.9pt;padding-right:19.9pt;">      dobj</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS9.p5.1.7.2" style="padding-left:19.9pt;padding-right:19.9pt;">      30</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS9.p5.1.7.3" style="padding-left:19.9pt;padding-right:19.9pt;">      77</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS9.p5.1.8">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS9.p5.1.8.1" style="padding-left:19.9pt;padding-right:19.9pt;">      mark</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS9.p5.1.8.2" style="padding-left:19.9pt;padding-right:19.9pt;">      97</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS9.p5.1.8.3" style="padding-left:19.9pt;padding-right:19.9pt;">      67</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS9.p5.1.9">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS9.p5.1.9.1" style="padding-left:19.9pt;padding-right:19.9pt;">      nsubj</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS9.p5.1.9.2" style="padding-left:19.9pt;padding-right:19.9pt;">      19</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS9.p5.1.9.3" style="padding-left:19.9pt;padding-right:19.9pt;">      56</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS9.p5.1.10">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS9.p5.1.10.1" style="padding-left:19.9pt;padding-right:19.9pt;">      punct</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS9.p5.1.10.2" style="padding-left:19.9pt;padding-right:19.9pt;">      9</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS9.p5.1.10.3" style="padding-left:19.9pt;padding-right:19.9pt;">      52</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS9.p5.1.11">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS9.p5.1.11.1" style="padding-left:19.9pt;padding-right:19.9pt;">      conj</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS9.p5.1.11.2" style="padding-left:19.9pt;padding-right:19.9pt;">      23</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS9.p5.1.11.3" style="padding-left:19.9pt;padding-right:19.9pt;">      48</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS9.p5.1.12">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS9.p5.1.12.1" style="padding-left:19.9pt;padding-right:19.9pt;">      nmod:prep</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS9.p5.1.12.2" style="padding-left:19.9pt;padding-right:19.9pt;">      22</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS9.p5.1.12.3" style="padding-left:19.9pt;padding-right:19.9pt;">      36</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS9.p5.1.13">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS9.p5.1.13.1" style="padding-left:19.9pt;padding-right:19.9pt;">      acl</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS9.p5.1.13.2" style="padding-left:19.9pt;padding-right:19.9pt;">      15</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS9.p5.1.13.3" style="padding-left:19.9pt;padding-right:19.9pt;">      32</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS9.p5.1.14">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS9.p5.1.14.1" style="padding-left:19.9pt;padding-right:19.9pt;">      amod</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS9.p5.1.14.2" style="padding-left:19.9pt;padding-right:19.9pt;">      6</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS9.p5.1.14.3" style="padding-left:19.9pt;padding-right:19.9pt;">      30</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS9.p5.1.15">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS9.p5.1.15.1" style="padding-left:19.9pt;padding-right:19.9pt;">      ROOT</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS9.p5.1.15.2" style="padding-left:19.9pt;padding-right:19.9pt;">      19</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS9.p5.1.15.3" style="padding-left:19.9pt;padding-right:19.9pt;">      29</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS9.p5.1.16">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS9.p5.1.16.1" style="padding-left:19.9pt;padding-right:19.9pt;">      others</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS9.p5.1.16.2" style="padding-left:19.9pt;padding-right:19.9pt;">      155</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS9.p5.1.16.3" style="padding-left:19.9pt;padding-right:19.9pt;">      207</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS9.p5.1.17">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S4.SS2.SSS9.p5.1.17.1" style="padding-left:19.9pt;padding-right:19.9pt;">      Total</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.SS2.SSS9.p5.1.17.2" style="padding-left:19.9pt;padding-right:19.9pt;">      736</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t" id="S4.SS2.SSS9.p5.1.17.3" style="padding-left:19.9pt;padding-right:19.9pt;">      1220</td>
</tr>
</table>
</div>
<div class="ltx_para" id="S4.SS2.SSS9.p6">
<p class="ltx_p ltx_align_center" id="S4.SS2.SSS9.p6.1">Table 17 Top added DEP tagging in Unaligned-explicitation</p>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS2.SSS10">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.10 </span>Unaligned-reduction</h4>
<div class="ltx_para" id="S4.SS2.SSS10.p1">
<p class="ltx_p" id="S4.SS2.SSS10.p1.1">Some words or phrases from the original texts are dropped in the translated texts. HT data drops more English words in the source texts than MT data. The POS of terms that are most unlikely to be translated include ADP, CCONJ, AUX, PART, and DET, which are function words in English but are not utilized in Chinese, according to Table 18. We can see that HT data removes both function terms and semantic words more than MT data when comparing MT and HT disparities in abandoning English words in Chinese translation.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS10.p2">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.SS2.SSS10.p2.1">
<tr class="ltx_tr" id="S4.SS2.SSS10.p2.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S4.SS2.SSS10.p2.1.1.1" style="padding-left:19.9pt;padding-right:19.9pt;">      POS-based sub-categories of unaligned-reduction</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.SS2.SSS10.p2.1.1.2" style="padding-left:19.9pt;padding-right:19.9pt;">      MT data</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt" id="S4.SS2.SSS10.p2.1.1.3" style="padding-left:19.9pt;padding-right:19.9pt;">      HT data</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS10.p2.1.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.SS2.SSS10.p2.1.2.1" style="padding-left:19.9pt;padding-right:19.9pt;">      AUX</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS2.SSS10.p2.1.2.2" style="padding-left:19.9pt;padding-right:19.9pt;">      60</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S4.SS2.SSS10.p2.1.2.3" style="padding-left:19.9pt;padding-right:19.9pt;">      72</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS10.p2.1.3">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS10.p2.1.3.1" style="padding-left:19.9pt;padding-right:19.9pt;">      PRON</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS10.p2.1.3.2" style="padding-left:19.9pt;padding-right:19.9pt;">      46</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS10.p2.1.3.3" style="padding-left:19.9pt;padding-right:19.9pt;">      108</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS10.p2.1.4">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS10.p2.1.4.1" style="padding-left:19.9pt;padding-right:19.9pt;">      ADP</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS10.p2.1.4.2" style="padding-left:19.9pt;padding-right:19.9pt;">      222</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS10.p2.1.4.3" style="padding-left:19.9pt;padding-right:19.9pt;">      244</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS10.p2.1.5">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS10.p2.1.5.1" style="padding-left:19.9pt;padding-right:19.9pt;">      VERB</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS10.p2.1.5.2" style="padding-left:19.9pt;padding-right:19.9pt;">      26</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS10.p2.1.5.3" style="padding-left:19.9pt;padding-right:19.9pt;">      40</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS10.p2.1.6">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS10.p2.1.6.1" style="padding-left:19.9pt;padding-right:19.9pt;">      PART</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS10.p2.1.6.2" style="padding-left:19.9pt;padding-right:19.9pt;">      78</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS10.p2.1.6.3" style="padding-left:19.9pt;padding-right:19.9pt;">      45</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS10.p2.1.7">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS10.p2.1.7.1" style="padding-left:19.9pt;padding-right:19.9pt;">      CCONJ</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS10.p2.1.7.2" style="padding-left:19.9pt;padding-right:19.9pt;">      56</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS10.p2.1.7.3" style="padding-left:19.9pt;padding-right:19.9pt;">      77</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS10.p2.1.8">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS10.p2.1.8.1" style="padding-left:19.9pt;padding-right:19.9pt;">      PUNCT</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS10.p2.1.8.2" style="padding-left:19.9pt;padding-right:19.9pt;">      16</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS10.p2.1.8.3" style="padding-left:19.9pt;padding-right:19.9pt;">      16</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS10.p2.1.9">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS10.p2.1.9.1" style="padding-left:19.9pt;padding-right:19.9pt;">      ADJ</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS10.p2.1.9.2" style="padding-left:19.9pt;padding-right:19.9pt;">      20</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS10.p2.1.9.3" style="padding-left:19.9pt;padding-right:19.9pt;">      36</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS10.p2.1.10">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS10.p2.1.10.1" style="padding-left:19.9pt;padding-right:19.9pt;">      NOUN</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS10.p2.1.10.2" style="padding-left:19.9pt;padding-right:19.9pt;">      37</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS10.p2.1.10.3" style="padding-left:19.9pt;padding-right:19.9pt;">      67</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS10.p2.1.11">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS10.p2.1.11.1" style="padding-left:19.9pt;padding-right:19.9pt;">      SCONJ</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS10.p2.1.11.2" style="padding-left:19.9pt;padding-right:19.9pt;">      9</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS10.p2.1.11.3" style="padding-left:19.9pt;padding-right:19.9pt;">      18</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS10.p2.1.12">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS10.p2.1.12.1" style="padding-left:19.9pt;padding-right:19.9pt;">      DET</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS10.p2.1.12.2" style="padding-left:19.9pt;padding-right:19.9pt;">      36</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS10.p2.1.12.3" style="padding-left:19.9pt;padding-right:19.9pt;">      40</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS10.p2.1.13">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS10.p2.1.13.1" style="padding-left:19.9pt;padding-right:19.9pt;">      PROPN</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS10.p2.1.13.2" style="padding-left:19.9pt;padding-right:19.9pt;">      14</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS10.p2.1.13.3" style="padding-left:19.9pt;padding-right:19.9pt;">      11</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS10.p2.1.14">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS10.p2.1.14.1" style="padding-left:19.9pt;padding-right:19.9pt;">      X</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS10.p2.1.14.2" style="padding-left:19.9pt;padding-right:19.9pt;">      0</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS10.p2.1.14.3" style="padding-left:19.9pt;padding-right:19.9pt;">      1</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS10.p2.1.15">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS10.p2.1.15.1" style="padding-left:19.9pt;padding-right:19.9pt;">      NUM</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS10.p2.1.15.2" style="padding-left:19.9pt;padding-right:19.9pt;">      2</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS10.p2.1.15.3" style="padding-left:19.9pt;padding-right:19.9pt;">      5</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS10.p2.1.16">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS10.p2.1.16.1" style="padding-left:19.9pt;padding-right:19.9pt;">      INTJ</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS10.p2.1.16.2" style="padding-left:19.9pt;padding-right:19.9pt;">      2</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS10.p2.1.16.3" style="padding-left:19.9pt;padding-right:19.9pt;">      2</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS10.p2.1.17">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS10.p2.1.17.1" style="padding-left:19.9pt;padding-right:19.9pt;">      More than one token</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS10.p2.1.17.2" style="padding-left:19.9pt;padding-right:19.9pt;">      0</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS10.p2.1.17.3" style="padding-left:19.9pt;padding-right:19.9pt;">      52</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS10.p2.1.18">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S4.SS2.SSS10.p2.1.18.1" style="padding-left:19.9pt;padding-right:19.9pt;">      Total</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.SS2.SSS10.p2.1.18.2" style="padding-left:19.9pt;padding-right:19.9pt;">      636</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t" id="S4.SS2.SSS10.p2.1.18.3" style="padding-left:19.9pt;padding-right:19.9pt;">      870</td>
</tr>
</table>
</div>
<div class="ltx_para" id="S4.SS2.SSS10.p3">
<p class="ltx_p ltx_align_center" id="S4.SS2.SSS10.p3.1">Table 18 Top dropped POS tagging in Unaligned-reduction</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS10.p4">
<p class="ltx_p" id="S4.SS2.SSS10.p4.1">Analysis is done on the dependency relations between English tokens that are not translated in the source texts. In general, HT data does not translate more of these tokens than MT data. In both MT and HT data, the dependency relation prep (prepositional modifiers) has the highest number of untranslated source tokens. However, in this dependence relation, the HT data has slightly more untranslated tokens than the MT data does. This little difference also affects cc, det, poss, ROOT, etc. In addition, several dependency relations, such as nsubj, advmod, pobj, and amod, demonstrate that the number of untranslated tokens in MT data is significantly lower than that of HT data. The smaller and greater disparities demonstrate that GNMT’s translation performance varies and has space for improvement. However, despite the fact that GNMT’s performance is generally inferior than that of human translators in many areas, the kind of aux in MT data is bigger than in HT data. The data can reach a conclusion that GNMT is more inclined to remain the target texts and make them translated into target language as much as possible. POS and dependencies of reduction in HT data are analyzed so as to make a guideline for the next step improvement for NMT system on the use of reduction.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS10.p5">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.SS2.SSS10.p5.1">
<tr class="ltx_tr" id="S4.SS2.SSS10.p5.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S4.SS2.SSS10.p5.1.1.1" style="padding-left:19.9pt;padding-right:19.9pt;">      DEP-transfer-based sub-categories of unaligned-reduction</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.SS2.SSS10.p5.1.1.2" style="padding-left:19.9pt;padding-right:19.9pt;">      MT data</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt" id="S4.SS2.SSS10.p5.1.1.3" style="padding-left:19.9pt;padding-right:19.9pt;">      HT data</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS10.p5.1.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.SS2.SSS10.p5.1.2.1" style="padding-left:19.9pt;padding-right:19.9pt;">      aux</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS2.SSS10.p5.1.2.2" style="padding-left:19.9pt;padding-right:19.9pt;">      97</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S4.SS2.SSS10.p5.1.2.3" style="padding-left:19.9pt;padding-right:19.9pt;">      75</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS10.p5.1.3">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS10.p5.1.3.1" style="padding-left:19.9pt;padding-right:19.9pt;">      nsubj</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS10.p5.1.3.2" style="padding-left:19.9pt;padding-right:19.9pt;">      19</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS10.p5.1.3.3" style="padding-left:19.9pt;padding-right:19.9pt;">      71</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS10.p5.1.4">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS10.p5.1.4.1" style="padding-left:19.9pt;padding-right:19.9pt;">      det</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS10.p5.1.4.2" style="padding-left:19.9pt;padding-right:19.9pt;">      35</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS10.p5.1.4.3" style="padding-left:19.9pt;padding-right:19.9pt;">      57</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS10.p5.1.5">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS10.p5.1.5.1" style="padding-left:19.9pt;padding-right:19.9pt;">      advmod</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS10.p5.1.5.2" style="padding-left:19.9pt;padding-right:19.9pt;">      13</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS10.p5.1.5.3" style="padding-left:19.9pt;padding-right:19.9pt;">      52</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS10.p5.1.6">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS10.p5.1.6.1" style="padding-left:19.9pt;padding-right:19.9pt;">      pobj</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS10.p5.1.6.2" style="padding-left:19.9pt;padding-right:19.9pt;">      21</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS10.p5.1.6.3" style="padding-left:19.9pt;padding-right:19.9pt;">      50</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS10.p5.1.7">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS10.p5.1.7.1" style="padding-left:19.9pt;padding-right:19.9pt;">      amod</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS10.p5.1.7.2" style="padding-left:19.9pt;padding-right:19.9pt;">      19</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS10.p5.1.7.3" style="padding-left:19.9pt;padding-right:19.9pt;">      40</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS10.p5.1.8">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS10.p5.1.8.1" style="padding-left:19.9pt;padding-right:19.9pt;">      poss</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS10.p5.1.8.2" style="padding-left:19.9pt;padding-right:19.9pt;">      22</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS10.p5.1.8.3" style="padding-left:19.9pt;padding-right:19.9pt;">      36</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS10.p5.1.9">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS10.p5.1.9.1" style="padding-left:19.9pt;padding-right:19.9pt;">      ROOT</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS10.p5.1.9.2" style="padding-left:19.9pt;padding-right:19.9pt;">      23</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS10.p5.1.9.3" style="padding-left:19.9pt;padding-right:19.9pt;">      33</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS10.p5.1.10">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS10.p5.1.10.1" style="padding-left:19.9pt;padding-right:19.9pt;">      punct</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS10.p5.1.10.2" style="padding-left:19.9pt;padding-right:19.9pt;">      15</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS10.p5.1.10.3" style="padding-left:19.9pt;padding-right:19.9pt;">      22</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS10.p5.1.11">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS10.p5.1.11.1" style="padding-left:19.9pt;padding-right:19.9pt;">      dobj</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS10.p5.1.11.2" style="padding-left:19.9pt;padding-right:19.9pt;">      13</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS10.p5.1.11.3" style="padding-left:19.9pt;padding-right:19.9pt;">      21</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS10.p5.1.12">
<td class="ltx_td ltx_align_left" id="S4.SS2.SSS10.p5.1.12.1" style="padding-left:19.9pt;padding-right:19.9pt;">      others</td>
<td class="ltx_td ltx_align_center" id="S4.SS2.SSS10.p5.1.12.2" style="padding-left:19.9pt;padding-right:19.9pt;">      112</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS2.SSS10.p5.1.12.3" style="padding-left:19.9pt;padding-right:19.9pt;">      80</td>
</tr>
<tr class="ltx_tr" id="S4.SS2.SSS10.p5.1.13">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S4.SS2.SSS10.p5.1.13.1" style="padding-left:19.9pt;padding-right:19.9pt;">      Total</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.SS2.SSS10.p5.1.13.2" style="padding-left:19.9pt;padding-right:19.9pt;">      636</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t" id="S4.SS2.SSS10.p5.1.13.3" style="padding-left:19.9pt;padding-right:19.9pt;">      870</td>
</tr>
</table>
</div>
<div class="ltx_para" id="S4.SS2.SSS10.p6">
<p class="ltx_p ltx_align_center" id="S4.SS2.SSS10.p6.1">Table 19 Top dropped DEP tagging in Unaligned-reduction</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section"><span class="ltx_text" id="S5.2.1.1" style="color:#1E64C8;">5</span> </span><span class="ltx_text ltx_ulem_uline" id="S5.3.2" style="color:#1E64C8;">Conclusions and future work</span>
</h2>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Research questions</h3>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">Translationese is pervasive in both human translation and machine translation. Studies and efforts are being made to quantify translationese using certain metrics, bring it down to human parity, and even to the level of non-translated texts in target languages. Translation relations, a technique for reducing translationese to make translation accurate, fluent, faithful, and natural, is employed in this dissertation’s work as a metric to quantify translationese in translations from English to Chinese generated by both human translators and Google Translate. Translation relations show the relationships between various translation techniques, including literal and non-literal translation techniques as well as a few additional types of translation phenomena. In this study, both MT and HT are annotated with various translation techniques for comparison. Specifically, the aligned MT and HT corpora are compared on three different levels: the general differences between translation relations used in HT and MT are the first set of comparisons; the comparison of non-literal translation techniques used in HT and MT data is also focused; the features and factors that lead to the use of one specific non-literal translation technique in the MT and HT parallel corpora are compared. Comparisons highlight the differences between MT and HT capacities for application of translation relations so as to close this gap and improve machine translation in terms of using translation relations in the follow-up work.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Data</h3>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">The study makes use of two parallel corpora. The first parallel corpus covers the English texts and its translation in Chinese is performed by human translators. The second parallel corpus covers the English texts shared with HT data as the source texts and its translation by GoogleNMT system (Google Translate). These two corpora are compared with HT data as a benchmark in order to identify the under-utilization of NMT translation from the standpoint of translation relations.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Results</h3>
<div class="ltx_para" id="S5.SS3.p1">
<p class="ltx_p" id="S5.SS3.p1.1">The overall conclusion is that HT data performs better than MT data in terms of translation relations since MT data relies more heavily on literal translation (77%) than HT data (64%), which can be seen as a hint to have more translationese. In particular, lexical shift, transposition, and unaligned-reduction translation procedures with absolute proportion disparities of 6.8%, 7.7%, and 28.63% respectively, indicate that MT data performs approximately identically to HT data on the syntactic level. However, the GoogleNMT system performs poorly when dealing with semantic level or issues with additional contextual knowledge, particularly when applying particularization, figuration, equivalence, and generalization with the gap of 57%, 75%, 46%, and 32% to HT data respectively. When translation relation disparities is analyzed from the perspective of genres, the ues of non-literal translation techniques varies. The usage of non-literal translation techniques between two data sets in official documents, legal texts, and the science sector has a lower gap of 9.8%, 16.7%, and 21.5% respectively, but significantly higher discrepancies exist in microblogs (65%), scientific papers (81%), and subtitles (98%).</p>
</div>
<div class="ltx_para" id="S5.SS3.p2">
<p class="ltx_p" id="S5.SS3.p2.1">In-depth linguistics-related characteristics and variables that influence the usage of non-literal translation techniques are explored in addition to broad comparisons. Elements on semantic and syntactic levels are detected and summarized to investigate 10 non-literal translation techniques. On a semantic level, the translation strategies of equivalence, figurative translation, and generalization are examined. These techniques continue to be broken down into much more granular semantic units. On the other hand, lexical shift, transposition, unaligned explicitation, and reduction need significantly greater syntactic understanding of individual tokens, and the use of automated metrics such POS tagging and dependence relation is the primary way for assessment. Modulation, modulation+transposition, and particularization are further components of a hybrid type that includes both semantic and syntactic aspects. Comparing the two corpora on a linguistic level that results in translation relationships reveals that GoogleNMT performs well at understanding syntactic relationships but poorly at capturing semantic relationships.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4 </span>Shortcoming</h3>
<div class="ltx_para" id="S5.SS4.p1">
<p class="ltx_p" id="S5.SS4.p1.1">However, there are two inevitable drawbacks in this study. The first problem is that the data distribution of different translation relations is uneven. There are just three aligned pairings for figurative translation, and less than 100 aligned pairs for modulation and modulation + transposition, despite the fact that each genre has 50 phrases. Additionally, the sorting of aligned pairings using semantic knowledge and the annotation of translation relations contain some manual operations, which to some extent adds to the incorrect classification and annotations.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.5 </span>Future work</h3>
<div class="ltx_para" id="S5.SS5.p1">
<p class="ltx_p" id="S5.SS5.p1.1">For future studies and work, there are several things that can be done and fulfilled. In this work, only one machine translation system (Google Translate) is used, and therefore this study lacks an overview of the whole current NMT systems as different NMT systems have their own preferences which lead to different translation outputs. The comparison across several types of NMT systems can render more general and universal conclusions. Besides, an automatic metric to measure the translation quality can be developed based on detecting and recognizing translation relations. Finally, based on the analyzed sub-categories of each translation technique, some directions for NMT system optimization can be provided, and more targeted improvement can be made by integrating certain linguistics-related knowledge into NMT systems.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Nora Aranberri.

</span>
<span class="ltx_bibblock">Can translationese features help users select an mt system for
post-editing?

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib1.1.1">Procesamiento del Lenguaje Natural</span>, 64:93–100, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Ehud Alexander Avner, Noam Ordan, and Shuly Wintner.

</span>
<span class="ltx_bibblock">Identifying translationese at the word and sub-word level.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib2.1.1">Digital Scholarship in the Humanities</span>, 31(1):30–54, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Mona Baker.

</span>
<span class="ltx_bibblock">Corpus linguistics and translation studies implications and
applications.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib3.1.1">Text and Technology: In honour of John Sinclair</span>, page 233,
1993.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Mona Baker.

</span>
<span class="ltx_bibblock">Corpora in translation studies: An overview and some suggestions for
future research.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib4.1.1">Target. International Journal of Translation Studies</span>,
7(2):223–243, 1995.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Mona Baker.

</span>
<span class="ltx_bibblock">Corpus-based translation studies: The challenges that lie ahead.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib5.1.1">Terminology, LSP and Translation</span>, page 175. John Benjamins,
1996.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Mona Baker.

</span>
<span class="ltx_bibblock">A corpus-based view of similarity and difference in translation.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib6.1.1">International journal of corpus linguistics</span>, 9(2):167–193,
2004.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Marco Baroni and Silvia Bernardini.

</span>
<span class="ltx_bibblock">A new approach to the study of translationese: Machine-learning the
difference between original and translated text.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib7.1.1">Literary and Linguistic Computing</span>, 21(3):259–274, 2006.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Luisa Bentivogli, Arianna Bisazza, Mauro Cettolo, and Marcello Federico.

</span>
<span class="ltx_bibblock">Neural versus phrase-based mt quality: An in-depth analysis on
english–german and english–french.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib8.1.1">Computer Speech &amp; Language</span>, 49:52–70, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Yuri Bizzoni, Tom S Juzek, Cristina Espana-Bonet, Koel Dutta Chowdhury, Josef
van Genabith, and Elke Teich.

</span>
<span class="ltx_bibblock">How human is machine translationese? comparing human and machine
translations of text and speech.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib9.1.1">Proceedings of the 17th International Conference on Spoken
Language Translation</span>, pages 280–290, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Ondřej Bojar, Rajen Chatterjee, Christian Federmann, Yvette Graham, Barry
Haddow, Matthias Huck, Antonio Jimeno Yepes, Philipp Koehn, Varvara
Logacheva, Christof Monz, et al.

</span>
<span class="ltx_bibblock">Findings of the 2016 conference on machine translation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib10.1.1">Proceedings of the First Conference on Machine Translation:
Volume 2, Shared Task Papers</span>, pages 131–198, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Aljoscha Burchardt, Vivien Macketanz, Jon Dehdari, Georg Heigold, Peter
Jan-Thorsten, and Philip Williams.

</span>
<span class="ltx_bibblock">A linguistic evaluation of rule-based, phrase-based, and neural mt
engines.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib11.1.1">The Prague Bulletin of Mathematical Linguistics</span>, 108(1):159,
2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Chris Callison-Burch, Cameron Shaw Fordyce, Philipp Koehn, Christof Monz, and
Josh Schroeder.

</span>
<span class="ltx_bibblock">(meta-) evaluation of machine translation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib12.1.1">Proceedings of the Second Workshop on Statistical Machine
Translation</span>, pages 136–158, 2007.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Chris Callison-Burch, Miles Osborne, and Philipp Koehn.

</span>
<span class="ltx_bibblock">Re-evaluating the role of bleu in machine translation research.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib13.1.1">11th conference of the european chapter of the association
for computational linguistics</span>, pages 249–256, 2006.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Sheila Castilho, Joss Moorkens, Federico Gaspari, Iacer Calixto, John Tinsley,
and Andy Way.

</span>
<span class="ltx_bibblock">Is neural machine translation the new state of the art?

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib14.1.1">The Prague Bulletin of Mathematical Linguistics</span>, (108), 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Baobao Chang.

</span>
<span class="ltx_bibblock">Chinese-english parallel corpus construction and its application.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib15.1.1">Proceedings of The 18th Pacific Asia Conference on Language,
Information and Computation</span>, pages 283–290, 2004.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Eirini Chatzikoumi.

</span>
<span class="ltx_bibblock">How to evaluate machine translation: A review of automated and human
metrics.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib16.1.1">Natural Language Engineering</span>, 26(2):137–161, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Soonja Choi and Alison Gopnik.

</span>
<span class="ltx_bibblock">Early acquisition of verbs in korean: A cross-linguistic study.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib17.1.1">Journal of child language</span>, 22(3):497–529, 1995.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Hélène Chuquet and Michel Paillard.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib18.1.1">Approche linguistique des problèmes de traduction
anglais-français</span>.

</span>
<span class="ltx_bibblock">Editions Ophrys, 1987.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Deborah Coughlin.

</span>
<span class="ltx_bibblock">Correlating automated and human assessments of machine translation
quality.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib19.1.1">Proceedings of Machine Translation Summit IX: Papers</span>, 2003.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Daniel Dahlmeier, Chang Liu, and Hwee Tou Ng.

</span>
<span class="ltx_bibblock">Tesla at wmt 2011: Translation evaluation and tunable metric.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib20.1.1">Proceedings of the Sixth Workshop on Statistical Machine
Translation</span>, pages 78–84, 2011.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Verna Dankers, Christopher G Lucas, and Ivan Titov.

</span>
<span class="ltx_bibblock">Can transformer be too compositional? analysing idiom processing in
neural machine translation.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib21.1.1">arXiv preprint arXiv:2205.15301</span>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Carmen Dayrell.

</span>
<span class="ltx_bibblock">A quantitative approach to compare collocational patterns in
translated and non-translated texts.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib22.1.1">International Journal of Corpus Linguistics</span>, 12(3):375–414,
2007.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Orphée De Clercq, Gert De Sutter, Rudy Loock, Bert Cappelle, and Koen
Plevoets.

</span>
<span class="ltx_bibblock">Uncovering machine translationese using corpus analysis techniques to
distinguish between original and machine-translated french.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib23.1.1">Translation Quarterly</span>, (101):21–45, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
Dun Deng and Nianwen Xue.

</span>
<span class="ltx_bibblock">Translation divergences in chinese–english machine translation: An
empirical investigation.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib24.1.1">Computational Linguistics</span>, 43(3):521–565, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
Catherine Dove, Olga Loskutova, and Ruben de la Fuente.

</span>
<span class="ltx_bibblock">What’s your pick: Rbmt, smt or hybrid?

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib25.1.1">Proceedings of the 10th Conference of the Association for
Machine Translation in the Americas: Commercial MT User Program</span>, 2012.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
P EuroMatrix.

</span>
<span class="ltx_bibblock">1.3: Survey of machine translation evaluation.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib26.1.1">EuroMatrix Project Report, Statistical and Hybrid MT between All
European Languages, co-ordinator: Prof. Hans Uszkoreit</span>, 2007.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
Marzieh Fadaee, Arianna Bisazza, and Christof Monz.

</span>
<span class="ltx_bibblock">Examining the tip of the iceberg: A data set for idiom translation.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib27.1.1">arXiv preprint arXiv:1802.04681</span>, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
Christian Federmann.

</span>
<span class="ltx_bibblock">Appraise: An open-source toolkit for manual phrase-based evaluation
of translations.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib28.1.1">Proceedings of the Seventh International Conference on
Language Resources and Evaluation (LREC’10)</span>, 2010.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
William Frawley.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib29.1.1">Translation: Literary, linguistic, and philosophical
perspectives</span>.

</span>
<span class="ltx_bibblock">Newark: University of Delaware Press; London: Associated University
Presses, 1984.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
Yingxue Fu and Mark-Jan Nederhof.

</span>
<span class="ltx_bibblock">Automatic classification of human translation and machine
translation: A study from the perspective of lexical diversity.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib30.1.1">arXiv preprint arXiv:2105.04616</span>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
Pablo Gamallo and Gorka Labaka.

</span>
<span class="ltx_bibblock">Using dependency-based contextualization for transferring passive
constructions from english to spanish.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib31.1.1">Procesamiento del Lenguaje Natural</span>, 66:53–64, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
Martin Gellerstam.

</span>
<span class="ltx_bibblock">Translationese in swedish novels translated from english.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib32.1.1">Translation studies in Scandinavia</span>, 1:88–95, 1986.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
Martin Gellerstam.

</span>
<span class="ltx_bibblock">Translations as a source for cross-linguistic studies.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib33.1.1">Lund studies in English</span>, 88:53–62, 1996.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
Ulrich Germann.

</span>
<span class="ltx_bibblock">Yawat: yet another word alignment tool.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib34.1.1">Proceedings of the ACL-08: HLT demo session</span>, pages 20–23,
2008.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
Yvette Graham, Timothy Baldwin, and Nitika Mathur.

</span>
<span class="ltx_bibblock">Accurate evaluation of segment-level machine translation metrics.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib35.1.1">Proceedings of the 2015 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Language
Technologies</span>, pages 1183–1191, 2015.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
Yvette Graham, Timothy Baldwin, Alistair Moffat, and Justin Zobel.

</span>
<span class="ltx_bibblock">Continuous measurement scales in human evaluation of machine
translation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib36.1.1">Proceedings of the 7th Linguistic Annotation Workshop and
Interoperability with Discourse</span>, pages 33–41, 2013.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
Honglei Guo, Huijia Zhu, Zhili Guo, Xiaoxun Zhang, Xian Wu, and Zhong Su.

</span>
<span class="ltx_bibblock">Domain adaptation with latent semantic association for named entity
recognition.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib37.1.1">Proceedings of Human Language Technologies: The 2009 Annual
Conference of the North American Chapter of the Association for Computational
Linguistics</span>, pages 281–289, 2009.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
Francisco Guzmán, Shafiq Joty, Lluís Màrquez, and Preslav Nakov.

</span>
<span class="ltx_bibblock">Machine translation evaluation with neural networks.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib38.1.1">Computer Speech &amp; Language</span>, 45:180–200, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
Hany Hassan, Anthony Aue, Chang Chen, Vishal Chowdhary, Jonathan Clark,
Christian Federmann, Xuedong Huang, Marcin Junczys-Dowmunt, William Lewis,
Mu Li, et al.

</span>
<span class="ltx_bibblock">Achieving human parity on automatic chinese to english news
translation.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib39.1.1">arXiv preprint arXiv:1803.05567</span>, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
Hai Hu, Wen Li, and Sandra Kübler.

</span>
<span class="ltx_bibblock">Detecting syntactic features of translated chinese.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib40.1.1">arXiv preprint arXiv:1804.08756</span>, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
W John Hutchins.

</span>
<span class="ltx_bibblock">Machine translation: A brief history.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib41.1.1">Concise history of the language sciences</span>, pages 431–445.
Elsevier, 1995.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
Iustina Ilisei, Diana Inkpen, Gloria Corpas Pastor, and Ruslan Mitkov.

</span>
<span class="ltx_bibblock">Identification of translationese: A machine learning approach.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib42.1.1">International conference on intelligent text processing and
computational linguistics</span>, pages 503–511. Springer, 2010.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
Mutsumi Imai, Lianjing Li, Etsuko Haryu, Hiroyuki Okada, Kathy Hirsh-Pasek,
Roberta Michnick Golinkoff, and Jun Shigematsu.

</span>
<span class="ltx_bibblock">Novel noun and verb learning in chinese-, english-, and
japanese-speaking children.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib43.1.1">Child development</span>, 79(4):979–1000, 2008.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
Pierre Isabelle, Colin Cherry, and George Foster.

</span>
<span class="ltx_bibblock">A challenge set approach to evaluating machine translation.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib44.1.1">arXiv preprint arXiv:1704.07431</span>, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
Even-Zohar Itamar.

</span>
<span class="ltx_bibblock">Polysystem studies.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib45.1.1">Poetics Today</span>, 11(1):1–268, 1990.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
R. Jääskeläinen.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib46.1.1">Tapping the Process: An Explorative Study of the Cognitive and
Affective Factors Involved in Translating</span>.

</span>
<span class="ltx_bibblock">Joensuun Yliopiston humanistisia julkaisuja: Joensuun Yliopisto.
Joensuun yliopisto, 1999.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
Yanfang Jia, Michael Carl, and Xiangling Wang.

</span>
<span class="ltx_bibblock">Post-editing neural machine translation versus phrase-based machine
translation for english–chinese.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib47.1.1">Machine Translation</span>, 33(1):9–29, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
Mikyong Kim, Karla K McGregor, and Cynthia K Thompson.

</span>
<span class="ltx_bibblock">Early lexical development in english-and korean-speaking children:
Language-general and language-specific patterns.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib48.1.1">Journal of child language</span>, 27(2):225–254, 2000.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
Filip Klubička, Antonio Toral, and Víctor M Sánchez-Cartagena.

</span>
<span class="ltx_bibblock">Fine-grained human evaluation of neural versus phrase-based machine
translation.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib49.1.1">The Prague Bulletin of Mathematical Linguistics</span>, 108(1):121,
2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
Philipp Koehn and Rebecca Knowles.

</span>
<span class="ltx_bibblock">Six challenges for neural machine translation.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib50.1.1">arXiv preprint arXiv:1706.03872</span>, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock">
Maarit Koponen, Leena Salmi, and Markku Nikulin.

</span>
<span class="ltx_bibblock">A product and process analysis of post-editor corrections on neural,
statistical and rule-based machine translation output.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib51.1.1">Machine Translation</span>, 33(1):61–90, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock">
Hans P Krings.

</span>
<span class="ltx_bibblock">Translation problems and translation strategies of advanced.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib52.1.1">Interlingual and intercultural communication: Discourse and
cognition in translation and second language acquisition studie</span>, pages
263–272, 1986.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock">
Chen-li Kuo.

</span>
<span class="ltx_bibblock">Function words in statistical machine-translated chinese and original
chinese: A study into the translationese of machine translation systems.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib53.1.1">Digital Scholarship in the Humanities</span>, 34(4):752–771, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock">
Piotr Kwieciñski.

</span>
<span class="ltx_bibblock">Translation strategies in a rapidly transforming culture: A central
european perspective.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib54.1.1">The translator</span>, 4(2):183–206, 1998.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock">
Samuel Läubli, Rico Sennrich, and Martin Volk.

</span>
<span class="ltx_bibblock">Has machine translation achieved human parity? a case for
document-level evaluation.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib55.1.1">arXiv preprint arXiv:1808.07048</span>, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock">
Susanne Lauscher.

</span>
<span class="ltx_bibblock">Translation quality assessment: Where can theory and practice meet?

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib56.1.1">The translator</span>, 6(2):149–168, 2000.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock">
Alon Lavie.

</span>
<span class="ltx_bibblock">Evaluating the output of machine translation systems.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib57.1.1">Proceedings of the 9th Conference of the Association for
Machine Translation in the Americas: Tutorials</span>, 2010.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock">
Sara Laviosa.

</span>
<span class="ltx_bibblock">Core patterns of lexical use in a comparable corpus of english
narrative prose.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib58.1.1">Meta: journal des traducteurs/Meta: Translators’ Journal</span>,
43(4):557–570, 1998.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib59">
<span class="ltx_tag ltx_tag_bibitem">[59]</span>
<span class="ltx_bibblock">
Vladimir I Levenshtein et al.

</span>
<span class="ltx_bibblock">Binary codes capable of correcting deletions, insertions, and
reversals.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib59.1.1">Soviet physics doklady</span>, volume 10, pages 707–710. Soviet
Union, 1966.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib60">
<span class="ltx_tag ltx_tag_bibitem">[60]</span>
<span class="ltx_bibblock">
Zhongguo Li and Maosong Sun.

</span>
<span class="ltx_bibblock">Punctuation as implicit annotations for chinese word segmentation.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib60.1.1">Computational Linguistics</span>, 35(4):505–512, 2009.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib61">
<span class="ltx_tag ltx_tag_bibitem">[61]</span>
<span class="ltx_bibblock">
Ken Lin.

</span>
<span class="ltx_bibblock">The elimination of translationese from the perspective of functional
equivalence.

</span>
<span class="ltx_bibblock">2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib62">
<span class="ltx_tag ltx_tag_bibitem">[62]</span>
<span class="ltx_bibblock">
Yang Liu.

</span>
<span class="ltx_bibblock">Tsinghuaaligner: A statistical bilingual word alignment system.

</span>
<span class="ltx_bibblock">2015.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib63">
<span class="ltx_tag ltx_tag_bibitem">[63]</span>
<span class="ltx_bibblock">
Yang Liu and Maosong Sun.

</span>
<span class="ltx_bibblock">Contrastive unsupervised word alignment with non-local features.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib63.1.1">Twenty-Ninth AAAI Conference on Artificial Intelligence</span>,
2015.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib64">
<span class="ltx_tag ltx_tag_bibitem">[64]</span>
<span class="ltx_bibblock">
Chi-kiu Lo.

</span>
<span class="ltx_bibblock">Yisi-a unified semantic mt quality evaluation and estimation metric
for languages with different levels of available resources.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib64.1.1">Proceedings of the Fourth Conference on Machine Translation
(Volume 2: Shared Task Papers, Day 1)</span>, pages 507–513, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib65">
<span class="ltx_tag ltx_tag_bibitem">[65]</span>
<span class="ltx_bibblock">
Adam Lopez.

</span>
<span class="ltx_bibblock">Statistical machine translation.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib65.1.1">ACM Computing Surveys (CSUR)</span>, 40(3):1–49, 2008.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib66">
<span class="ltx_tag ltx_tag_bibitem">[66]</span>
<span class="ltx_bibblock">
Maja Manojlović, Luka Dajak, and Marija Brkić Bakarić.

</span>
<span class="ltx_bibblock">Idioms in state-of-the-art croatian-english and english-croatian smt
systems.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib66.1.1">2017 40th International Convention on Information and
Communication Technology, Electronics and Microelectronics (MIPRO)</span>, pages
1546–1550. IEEE, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib67">
<span class="ltx_tag ltx_tag_bibitem">[67]</span>
<span class="ltx_bibblock">
Elaine Marsh and Dennis Perzanowski.

</span>
<span class="ltx_bibblock">Muc-7 evaluation of ie technology: Overview of results.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib67.1.1">Seventh Message Understanding Conference (MUC-7): Proceedings
of a Conference Held in Fairfax, Virginia, April 29-May 1, 1998</span>, 1998.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib68">
<span class="ltx_tag ltx_tag_bibitem">[68]</span>
<span class="ltx_bibblock">
Lucía Molina and Amparo Hurtado Albir.

</span>
<span class="ltx_bibblock">Translation techniques revisited: A dynamic and functionalist
approach.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib68.1.1">Meta: Journal des Traducteurs/Meta: Translators’ Journal</span>,
47(4):498–512, 2002.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib69">
<span class="ltx_tag ltx_tag_bibitem">[69]</span>
<span class="ltx_bibblock">
Peter Newmark.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib69.1.1">Approaches to translation (Language Teaching methodology
senes)</span>.

</span>
<span class="ltx_bibblock">Oxford: Pergamon Press, 1981.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib70">
<span class="ltx_tag ltx_tag_bibitem">[70]</span>
<span class="ltx_bibblock">
Peter Newmark.

</span>
<span class="ltx_bibblock">Pragmatic translation and literalism.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib70.1.1">TTR: traduction, terminologie, rédaction</span>, 1(2):133–145,
1988.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib71">
<span class="ltx_tag ltx_tag_bibitem">[71]</span>
<span class="ltx_bibblock">
Peter Newmark.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib71.1.1">More paragraphs on translation</span>.

</span>
<span class="ltx_bibblock">Multilingual matters, 1998.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib72">
<span class="ltx_tag ltx_tag_bibitem">[72]</span>
<span class="ltx_bibblock">
Binh Nguyen, Binh Le, Long Nguyen, Viet Pham, and Dien Dinh.

</span>
<span class="ltx_bibblock">Providing syntactic awareness to neural machine translation by
graph-based transformer.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib72.1.1">International Conference on Artificial Intelligence and Big
Data in Digital Era</span>, pages 73–83. Springer, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib73">
<span class="ltx_tag ltx_tag_bibitem">[73]</span>
<span class="ltx_bibblock">
Long HB Nguyen, Viet H Pham, and Dien Dinh.

</span>
<span class="ltx_bibblock">Improving neural machine translation with amr semantic graphs.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib73.1.1">Mathematical Problems in Engineering</span>, 2021, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib74">
<span class="ltx_tag ltx_tag_bibitem">[74]</span>
<span class="ltx_bibblock">
Eugene Albert Nida.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib74.1.1">Toward a science of translating: with special reference to
principles and procedures involved in Bible translating</span>.

</span>
<span class="ltx_bibblock">Brill Archive, 1964.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib75">
<span class="ltx_tag ltx_tag_bibitem">[75]</span>
<span class="ltx_bibblock">
Sonja Nießen and Hermann Ney.

</span>
<span class="ltx_bibblock">Improving smt quality with morpho-syntactic analysis.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib75.1.1">COLING 2000 Volume 2: The 18th International Conference on
Computational Linguistics</span>, 2000.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib76">
<span class="ltx_tag ltx_tag_bibitem">[76]</span>
<span class="ltx_bibblock">
Sergiu Nisioi and Liviu P Dinu.

</span>
<span class="ltx_bibblock">A clustering approach for translationese identification.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib76.1.1">Proceedings of the International Conference Recent Advances
in Natural Language Processing RANLP 2013</span>, pages 532–538, 2013.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib77">
<span class="ltx_tag ltx_tag_bibitem">[77]</span>
<span class="ltx_bibblock">
Franz Josef Och and Hermann Ney.

</span>
<span class="ltx_bibblock">Improved statistical alignment models.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib77.1.1">Proceedings of the 38th annual meeting of the association for
computational linguistics</span>, pages 440–447, 2000.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib78">
<span class="ltx_tag ltx_tag_bibitem">[78]</span>
<span class="ltx_bibblock">
Tamkiko Ogura.

</span>
<span class="ltx_bibblock">Meishi yuui, doushi yuui ni oyobosu hahaoya no gengo nyuryoku no
kentou.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib78.1.1">Influence of maternal input in the distribution of nouns and
verbs in early vocabulary.) Ministery of Education and Science grant report.
Kobe University</span>, 2001.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib79">
<span class="ltx_tag ltx_tag_bibitem">[79]</span>
<span class="ltx_bibblock">
Maeve Olohan.

</span>
<span class="ltx_bibblock">Spelling out the optionals in translation: a corpus study.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib79.1.1">UCREL technical papers</span>, 13:423–432, 2001.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib80">
<span class="ltx_tag ltx_tag_bibitem">[80]</span>
<span class="ltx_bibblock">
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.

</span>
<span class="ltx_bibblock">Bleu: a method for automatic evaluation of machine translation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib80.1.1">Proceedings of the 40th annual meeting of the Association for
Computational Linguistics</span>, pages 311–318, 2002.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib81">
<span class="ltx_tag ltx_tag_bibitem">[81]</span>
<span class="ltx_bibblock">
Martin Popel, Marketa Tomkova, Jakub Tomek, Łukasz Kaiser, Jakob Uszkoreit,
Ondřej Bojar, and Zdeněk Žabokrtskỳ.

</span>
<span class="ltx_bibblock">Transforming machine translation: a deep learning system reaches news
translation quality comparable to human professionals.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib81.1.1">Nature communications</span>, 11(1):1–15, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib82">
<span class="ltx_tag ltx_tag_bibitem">[82]</span>
<span class="ltx_bibblock">
Maja Popovic.

</span>
<span class="ltx_bibblock">Hjerson: An open source tool for automatic error classification of
machine translation output.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib82.1.1">Prague Bull. Math. Linguistics</span>, 96:59–68, 2011.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib83">
<span class="ltx_tag ltx_tag_bibitem">[83]</span>
<span class="ltx_bibblock">
Maja Popović.

</span>
<span class="ltx_bibblock">chrf: character n-gram f-score for automatic mt evaluation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib83.1.1">Proceedings of the Tenth Workshop on Statistical Machine
Translation</span>, pages 392–395, 2015.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib84">
<span class="ltx_tag ltx_tag_bibitem">[84]</span>
<span class="ltx_bibblock">
Mark Przybocki, Kay Peterson, Sébastien Bronsart, and Gregory Sanders.

</span>
<span class="ltx_bibblock">The nist 2008 metrics for machine translation challenge—overview,
methodology, metrics, and results.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib84.1.1">Machine Translation</span>, 23(2):71–103, 2009.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib85">
<span class="ltx_tag ltx_tag_bibitem">[85]</span>
<span class="ltx_bibblock">
Tiina Puurtinen.

</span>
<span class="ltx_bibblock">Explicitating and implicitating source text ideology.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib85.1.1">Across Languages and Cultures</span>, 4(1):53–62, 2003.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib86">
<span class="ltx_tag ltx_tag_bibitem">[86]</span>
<span class="ltx_bibblock">
Ella Rabinovich and Shuly Wintner.

</span>
<span class="ltx_bibblock">Unsupervised identification of translationese.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib86.1.1">Transactions of the Association for Computational Linguistics</span>,
3:419–432, 2015.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib87">
<span class="ltx_tag ltx_tag_bibitem">[87]</span>
<span class="ltx_bibblock">
Stefani Dewi Rosaria and Rati Riana.

</span>
<span class="ltx_bibblock">Weaknesses of translation result using google translate.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib87.1.1">STRUKTURAL 2020: Proceedings of the 2nd International Seminar
on Translation Studies, Applied Linguistics, Literature and Cultural Studies,
STRUKTURAL 2020, 30 December 2020, Semarang, Indonesia</span>, page 111. European
Alliance for Innovation, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib88">
<span class="ltx_tag ltx_tag_bibitem">[88]</span>
<span class="ltx_bibblock">
Juan C Sager.

</span>
<span class="ltx_bibblock">Quality and standards: The evaluation of translations.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib88.1.1">The translator’s handbook</span>, 2:91–102, 1989.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib89">
<span class="ltx_tag ltx_tag_bibitem">[89]</span>
<span class="ltx_bibblock">
Diana Santos.

</span>
<span class="ltx_bibblock">On grammatical translationese.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib89.1.1">Short papers presented at the Tenth Scandinavian Conference
on Computational Linguistics</span>, pages 59–66, 1995.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib90">
<span class="ltx_tag ltx_tag_bibitem">[90]</span>
<span class="ltx_bibblock">
Alina Secară.

</span>
<span class="ltx_bibblock">Translation evaluation-a state of the art survey.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib90.1.1">Proceedings of the eCoLoRe/MeLLANGE Workshop</span>, pages 39–44.
Citeseer, 2005.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib91">
<span class="ltx_tag ltx_tag_bibitem">[91]</span>
<span class="ltx_bibblock">
Larry Selinker.

</span>
<span class="ltx_bibblock">Interlanguage.

</span>
<span class="ltx_bibblock">1972.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib92">
<span class="ltx_tag ltx_tag_bibitem">[92]</span>
<span class="ltx_bibblock">
Blum-Kulka Sh.

</span>
<span class="ltx_bibblock">Shifts of cohesion and coherence in translation.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib92.1.1">Interlingual and Intercultural Communication. Discourse and
Cognition in Translation and Second Language Acquisition Studies</span>, pages
17–35, 1986.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib93">
<span class="ltx_tag ltx_tag_bibitem">[93]</span>
<span class="ltx_bibblock">
Yutong Shao, Rico Sennrich, Bonnie Webber, and Federico Fancellu.

</span>
<span class="ltx_bibblock">Evaluating machine translation performance on chinese idioms with a
blacklist method.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib93.1.1">arXiv preprint arXiv:1711.07646</span>, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib94">
<span class="ltx_tag ltx_tag_bibitem">[94]</span>
<span class="ltx_bibblock">
Miriam Shlesinger.

</span>
<span class="ltx_bibblock">Interpreter latitude vs. due process. simultaneous and consecutive
interpretation in multilingual trials.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib94.1.1">Empirical research in translation and intercultural studies</span>,
pages 147–155, 1991.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib95">
<span class="ltx_tag ltx_tag_bibitem">[95]</span>
<span class="ltx_bibblock">
Kammer Tuahman Sipayung, Novdin Manoktong Sianturi, I Made Dwipa Arta, Yeti
Rohayati, and Diani Indah.

</span>
<span class="ltx_bibblock">Comparison of translation techniques by google translate and
u-dictionary: How differently does both machine translation tools perform in
translating?

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib95.1.1">Elsya: Journal of English Language Studies</span>, 3(3):236–245,
2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib96">
<span class="ltx_tag ltx_tag_bibitem">[96]</span>
<span class="ltx_bibblock">
Matthew Snover, Bonnie Dorr, Richard Schwartz, Linnea Micciulla, and John
Makhoul.

</span>
<span class="ltx_bibblock">A study of translation edit rate with targeted human annotation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib96.1.1">Proceedings of the 7th Conference of the Association for
Machine Translation in the Americas: Technical Papers</span>, pages 223–231, 2006.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib97">
<span class="ltx_tag ltx_tag_bibitem">[97]</span>
<span class="ltx_bibblock">
Lucia Specia, Kashif Shah, José GC De Souza, and Trevor Cohn.

</span>
<span class="ltx_bibblock">Quest-a translation quality estimation framework.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib97.1.1">Proceedings of the 51st Annual Meeting of the Association for
Computational Linguistics: System Demonstrations</span>, pages 79–84, 2013.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib98">
<span class="ltx_tag ltx_tag_bibitem">[98]</span>
<span class="ltx_bibblock">
Twila Tardif.

</span>
<span class="ltx_bibblock">Nouns are not always learned before verbs: Evidence from mandarin
speakers’ early vocabularies.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib98.1.1">Developmental psychology</span>, 32(3):492, 1996.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib99">
<span class="ltx_tag ltx_tag_bibitem">[99]</span>
<span class="ltx_bibblock">
Arda Tezcan, Véronique Hoste, and Lieve Macken.

</span>
<span class="ltx_bibblock">Scate taxonomy and corpus of machine translation errors.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib99.1.1">Trends in E-tools and resources for translators and
interpreters</span>, pages 219–244, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib100">
<span class="ltx_tag ltx_tag_bibitem">[100]</span>
<span class="ltx_bibblock">
Liang Tian, Derek F Wong, Lidia S Chao, Paulo Quaresma, Francisco Oliveira,
Yi Lu, Shuo Li, Yiming Wang, and Longyue Wang.

</span>
<span class="ltx_bibblock">Um-corpus: A large english-chinese parallel corpus for statistical
machine translation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib100.1.1">Proceedings of the ninth international conference on language
resources and evaluation (LREC’14)</span>, pages 1837–1842, 2014.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib101">
<span class="ltx_tag ltx_tag_bibitem">[101]</span>
<span class="ltx_bibblock">
Sonja Tirkkonen-Condit.

</span>
<span class="ltx_bibblock">Translationese—a myth or an empirical fact?: A study into the
linguistic identifiability of translated language.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib101.1.1">Target. International Journal of Translation Studies</span>,
14(2):207–220, 2002.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib102">
<span class="ltx_tag ltx_tag_bibitem">[102]</span>
<span class="ltx_bibblock">
Antonio Toral.

</span>
<span class="ltx_bibblock">Reassessing claims of human parity and super-human performance in
machine translation at wmt 2019.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib102.1.1">arXiv preprint arXiv:2005.05738</span>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib103">
<span class="ltx_tag ltx_tag_bibitem">[103]</span>
<span class="ltx_bibblock">
Antonio Toral and Víctor M Sánchez-Cartagena.

</span>
<span class="ltx_bibblock">A multifaceted evaluation of neural versus phrase-based machine
translation for 9 language directions.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib103.1.1">arXiv preprint arXiv:1701.02901</span>, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib104">
<span class="ltx_tag ltx_tag_bibitem">[104]</span>
<span class="ltx_bibblock">
Gideon Toury.

</span>
<span class="ltx_bibblock">What are descriptive studies into translation likely to yield apart
from isolated descriptions.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib104.1.1">Translation studies: The state of the art</span>, pages 179–192.
Brill, 1991.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib105">
<span class="ltx_tag ltx_tag_bibitem">[105]</span>
<span class="ltx_bibblock">
Gideon Toury.

</span>
<span class="ltx_bibblock">Descriptive translation studies: And beyond.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib105.1.1">Descriptive Translation Studies</span>, pages 1–366, 2012.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib106">
<span class="ltx_tag ltx_tag_bibitem">[106]</span>
<span class="ltx_bibblock">
Laura Van Brussel, Arda Tezcan, and Lieve Macken.

</span>
<span class="ltx_bibblock">A fine-grained error analysis of nmt, pbmt and rbmt output for
english-to-dutch.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib106.1.1">Eleventh International Conference on Language Resources and
Evaluation</span>, pages 3799–3804. European Language Resources Association
(ELRA), 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib107">
<span class="ltx_tag ltx_tag_bibitem">[107]</span>
<span class="ltx_bibblock">
Kitty Van Leuven-Zwart.

</span>
<span class="ltx_bibblock">Translation and original: Similarities and dissimilarities, ii.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib107.1.1">Target. International Journal of Translation Studies</span>,
2(1):69–95, 1990.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib108">
<span class="ltx_tag ltx_tag_bibitem">[108]</span>
<span class="ltx_bibblock">
R. Vanderauwera.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib108.1.1">Dutch Novels Translated Into English: The Transformation of a
"Minority" Literature</span>.

</span>
<span class="ltx_bibblock">Approaches to translation studies. Rodopi, 1985.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib109">
<span class="ltx_tag ltx_tag_bibitem">[109]</span>
<span class="ltx_bibblock">
Eva Vanmassenhove, Dimitar Shterionov, and Matthew Gwilliam.

</span>
<span class="ltx_bibblock">Machine translationese: Effects of algorithmic bias on linguistic
complexity in machine translation.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib109.1.1">arXiv preprint arXiv:2102.00287</span>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib110">
<span class="ltx_tag ltx_tag_bibitem">[110]</span>
<span class="ltx_bibblock">
Eva Vanmassenhove, Dimitar Shterionov, and Andy Way.

</span>
<span class="ltx_bibblock">Lost in translation: Loss and decay of linguistic richness in machine
translation.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib110.1.1">arXiv preprint arXiv:1906.12068</span>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib111">
<span class="ltx_tag ltx_tag_bibitem">[111]</span>
<span class="ltx_bibblock">
Bram Vanroy, Orphée De Clercq, Arda Tezcan, Joke Daems, and Lieve Macken.

</span>
<span class="ltx_bibblock">Metrics of syntactic equivalence to assess translation difficulty.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib111.1.1">Explorations in empirical translation process research</span>,
pages 259–294. Springer, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib112">
<span class="ltx_tag ltx_tag_bibitem">[112]</span>
<span class="ltx_bibblock">
Lawrence Venuti and Mona Baker.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib112.1.1">The translation studies reader</span>, volume 216.

</span>
<span class="ltx_bibblock">Routledge London, 2000.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib113">
<span class="ltx_tag ltx_tag_bibitem">[113]</span>
<span class="ltx_bibblock">
Hans J Vermeer and Andrew Chesterman.

</span>
<span class="ltx_bibblock">Skopos and commission in translational action.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib113.1.1">The translation studies reader</span>, pages 219–230. Routledge,
2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib114">
<span class="ltx_tag ltx_tag_bibitem">[114]</span>
<span class="ltx_bibblock">
J.P. Vinay and J. Darbelnet.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib114.1.1">Stylistique comparée du français et de l’anglais:
méthode de traduction</span>.

</span>
<span class="ltx_bibblock">Bibliothèque de stylistique comparée. Didier, 1958.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib115">
<span class="ltx_tag ltx_tag_bibitem">[115]</span>
<span class="ltx_bibblock">
Vered Volansky, Noam Ordan, and Shuly Wintner.

</span>
<span class="ltx_bibblock">On the features of translationese.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib115.1.1">Digital Scholarship in the Humanities</span>, 30(1):98–118, 2015.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib116">
<span class="ltx_tag ltx_tag_bibitem">[116]</span>
<span class="ltx_bibblock">
Martin Volk and Nico Weber.

</span>
<span class="ltx_bibblock">The automatic translation of idioms. machine translation vs.
translation memory systems.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib116.1.1">Sprachwissenschaft, Computerlinguistik und neue Medien</span>,
(1):167–192, 1998.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib117">
<span class="ltx_tag ltx_tag_bibitem">[117]</span>
<span class="ltx_bibblock">
Yu Wan, Baosong Yang, Derek Fai Wong, Lidia Sam Chao, Liang Yao, Haibo Zhang,
and Boxing Chen.

</span>
<span class="ltx_bibblock">Challenges of neural machine translation for short texts.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib117.1.1">Computational Linguistics</span>, 48(2):321–342, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib118">
<span class="ltx_tag ltx_tag_bibitem">[118]</span>
<span class="ltx_bibblock">
Haifeng Wang, Hua Wu, Zhongjun He, Liang Huang, and Kenneth Ward Church.

</span>
<span class="ltx_bibblock">Progress in machine translation.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib118.1.1">Engineering</span>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib119">
<span class="ltx_tag ltx_tag_bibitem">[119]</span>
<span class="ltx_bibblock">
Rebecca Webster, Margot Fonteyne, Arda Tezcan, Lieve Macken, and Joke Daems.

</span>
<span class="ltx_bibblock">Gutenberg goes neural: Comparing features of dutch human translations
with raw neural machine translation outputs in a corpus of english literary
classics.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib119.1.1">Informatics</span>, volume 7, page 32. MDPI, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib120">
<span class="ltx_tag ltx_tag_bibitem">[120]</span>
<span class="ltx_bibblock">
Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V Le, Mohammad Norouzi, Wolfgang
Macherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, et al.

</span>
<span class="ltx_bibblock">Google’s neural machine translation system: Bridging the gap between
human and machine translation.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib120.1.1">arXiv preprint arXiv:1609.08144</span>, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib121">
<span class="ltx_tag ltx_tag_bibitem">[121]</span>
<span class="ltx_bibblock">
Shuoheng Yang, Yuxin Wang, and Xiaowen Chu.

</span>
<span class="ltx_bibblock">A survey of deep learning techniques for neural machine translation.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib121.1.1">arXiv preprint arXiv:2002.07526</span>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib122">
<span class="ltx_tag ltx_tag_bibitem">[122]</span>
<span class="ltx_bibblock">
Yuming Zhai, Lufei Liu, and Xinyi Zhong.

</span>
<span class="ltx_bibblock">Annotation guidelines of translation techniques for english-chinese.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib123">
<span class="ltx_tag ltx_tag_bibitem">[123]</span>
<span class="ltx_bibblock">
Yuming Zhai, Lufei Liu, Xinyi Zhong, Gbariel Illouz, and Anne Vilnat.

</span>
<span class="ltx_bibblock">Building an english-chinese parallel corpus annotated with
sub-sentential translation techniques.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib123.1.1">Proceedings of the 12th language resources and evaluation
conference</span>, pages 4024–4033, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib124">
<span class="ltx_tag ltx_tag_bibitem">[124]</span>
<span class="ltx_bibblock">
Yuming Zhai, Aurélien Max, and Anne Vilnat.

</span>
<span class="ltx_bibblock">Construction of a multilingual corpus annotated with translation
relations.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib124.1.1">First Workshop on Linguistic Resources for Natural Language
Processing</span>, pages 102–111, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib125">
<span class="ltx_tag ltx_tag_bibitem">[125]</span>
<span class="ltx_bibblock">
Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q Weinberger, and Yoav Artzi.

</span>
<span class="ltx_bibblock">Bertscore: Evaluating text generation with bert.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib125.1.1">arXiv preprint arXiv:1904.09675</span>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib126">
<span class="ltx_tag ltx_tag_bibitem">[126]</span>
<span class="ltx_bibblock">
Michał Ziemski, Marcin Junczys-Dowmunt, and Bruno Pouliquen.

</span>
<span class="ltx_bibblock">The united nations parallel corpus v1. 0.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib126.1.1">Proceedings of the Tenth International Conference on Language
Resources and Evaluation (LREC’16)</span>, pages 3530–3534, 2016.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_para" id="p3">
<p class="ltx_p" id="p3.1"></p>
</div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Wed May  1 18:53:36 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
