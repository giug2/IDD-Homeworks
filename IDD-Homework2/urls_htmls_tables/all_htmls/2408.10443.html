<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2408.10443] Federated Learning of Large ASR Models in the Real World</title><meta property="og:description" content="Federated learning (FL) has shown promising results on training machine learning models with privacy preservation. However, for large models with over 100 million parameters, the training resource requirement becomes a…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Federated Learning of Large ASR Models in the Real World">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Federated Learning of Large ASR Models in the Real World">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2408.10443">

<!--Generated on Thu Sep  5 13:53:09 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Federated Learning of Large ASR Models in the Real World</h1>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">Federated learning (FL) has shown promising results on training machine learning models with privacy preservation. However, for large models with over 100 million parameters, the training resource requirement becomes an obstacle for FL because common devices do not have enough memory and computation power to finish the FL tasks. Although efficient training methods have been proposed, it is still a challenge to train the large models like Conformer based ASR. This paper presents a systematic solution to train the full-size ASR models of 130M parameters with FL. To our knowledge, this is the first real-world FL application of the Conformer model, which is also the largest model ever trained with FL so far. And this is the first paper showing FL can improve the ASR model quality with a set of proposed methods to refine the quality of data and labels of clients. We demonstrate both the training efficiency and the model quality improvement in real-world experiments.</p>
</div>
<div id="p1" class="ltx_para">
<p id="p1.1" class="ltx_p"><span id="p1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Index Terms<span id="p1.1.1.1" class="ltx_text ltx_font_upright">— </span></span>
federated learning, speech recognition</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Federated learning (FL) has shown promising results on training machine learning (ML) models with privacy preservation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>. Because FL has access to the on-device data which is not available on centralized server-side training, it’s specially good at learning on-device related patterns, e.g. whether users have feedback to the on-device apps. Moreover, FL can also be combined with centralized server training under a joint training framework <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> to mitigate distribution shift of FL and further improve the model quality.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">With the above advantages, one of the drawbacks of FL is that the models have to be trained on users’ devices where only limited resources such as memory and computation power are available. The problem becomes worse given that recent models are getting larger and larger such as large language models (LLM) ChatGPT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> and PaLM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>. For end-to-end automatic speech recognition (ASR) models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>, the performance is also subject to the model size. Specifically, the Conformer-based ASR model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> usually requires 120<math id="S1.p2.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S1.p2.1.m1.1a"><mo id="S1.p2.1.m1.1.1" xref="S1.p2.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S1.p2.1.m1.1b"><csymbol cd="latexml" id="S1.p2.1.m1.1.1.cmml" xref="S1.p2.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S1.p2.1.m1.1c">\sim</annotation></semantics></math>150 million parameters to achieve the desired recognition quality. Models of this size requires several GB of training memory, e.g. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>, hence it is a big challenge for FL.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Efficient FL methods have been proposed to relieve the resource burden on FL devices. There are generally two categories of the related works. First, from the model perspective new training algorithms are proposed, including pruning technique <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> and dropout method <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> to reduce the model size, gradient checkpointing <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> to recompute the gradients in backward propagation and quantization method <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> to reduce the variables precision. Second, FL related algorithms are designed, including federated dropout<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> to train smaller models on clients, federated pruning<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> to reduce the overall model size, online model compression (OMC) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> to quantize the model to lower precision and partial variables training <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> to only compute partial gradients to save the memory usage.
However, the above works only focus on one aspect of the system and it’s unknown if the integration of different approach would enable the FL of ASR models.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2408.10443/assets/figures/fedspeech_overview.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="309" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.4.1.1" class="ltx_text ltx_font_bold">Fig. 1</span>: </span>The overview of the FL system. 1<math id="S1.F1.2.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S1.F1.2.m1.1b"><mo id="S1.F1.2.m1.1.1" xref="S1.F1.2.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S1.F1.2.m1.1c"><csymbol cd="latexml" id="S1.F1.2.m1.1.1.cmml" xref="S1.F1.2.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S1.F1.2.m1.1d">\sim</annotation></semantics></math>5 are the FL steps in a round. There are 3 types of data on clients: the input audio data, the original transcript from the incumbent ASR and the final transcript based on user edits.</figcaption>
</figure>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">In this paper we study the FL of Conformer based ASR model with 130M parameters, which is the largest model for FL so far. Our work potentially paves the road to train other large models like LLMs in the future. We first build different methods into one system and show how the consolidated system works together. Then we study the problem of how to improve the model quality with FL. Because FL is good at learning the on-device usage patterns, we design the FL algorithm as follows. For each user, there is an incumbent ASR on the device to generate the transcript from user audio. We observed that users might edit the original transcripts to correct the errors. For example, if a user said “covid” and the incumbent ASR outputs “covert”, then users may change the output to “covid” again. Therefore, we utilize user-correction actions on devices to improve the model performance on the ”corrected” words. Figure <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Federated Learning of Large ASR Models in the Real World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> highlights our approach. At the beginning of a FL round, the server selects the clients that have the correction actions. Then the server sends a “processed” (e.g. quantized/pruning/reduced) model to clients. Clients runs a data filtering method to only use the “correction” data as training examples, and partially train the model under the resource constraint. Then we design a weighted client aggregation (WCA) algorithm to update the trained model on server. Our contributions are summarized as follows.</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">To our knowledge, this is the first real-world FL application that successfully trains the production-grade ASR model of 130M parameters. We explain the FL system in Section <a href="#S2" title="2 Training Efficiency ‣ Federated Learning of Large ASR Models in the Real World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">This is also the first paper that shows the ASR quality can be improved by FL. We propose the WCA algorithm to refine the data and label quality of clients based on the user-corrections, described in Section <a href="#S3" title="3 Model Quality ‣ Federated Learning of Large ASR Models in the Real World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">We conducted real-world FL experiments to demonstrate the performance of our system in Section <a href="#S4" title="4 Experimental Results ‣ Federated Learning of Large ASR Models in the Real World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. We report that the training efficiency is greatly increased, which is measured by (1) the memory usage and (2) transportation size between server and clients, and the WER of FL models is effectively boosted.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Training Efficiency</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">In this section we describe how the FL system is built to train the ASR models. The bottleneck of the FL system consists of two constraints: (1) the on-device peak memory usage and (2) the transportation size between server and clients. The two constraints are also positively correlated as they can be optimized together.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">First we combine the existing algorithms together in our system as a baseline, meaning that all the following methods are applied by default unless explained further. We enable the gradient checkpointing method <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> in the Conformer model to reduce the memory usage. Moreover, we use the FedSGD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> algorithm to only take one batch of data as we observed that more examples lead to more memory usage with on-device CPU training <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>. To further reduce the memory consumption, we set a small batch size like 2. With this setting, it means the convergence speed might be slower compared to large batch size and FedAVG <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. But it can be compensated by more FL rounds and large report goal (the number of clients participating in one FL round). Between server and clients, transportation compression methods <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> are applied to reduce the network load. Next we add two methods on the baseline system including OMC and partial model training.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p"><span id="S2.p3.1.1" class="ltx_text ltx_font_bold">OMC.</span> We build the OMC <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> method in our system to reduce both the model size and the memory usage.
Specifically, the OMC method is the step <math id="S2.p3.1.m1.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S2.p3.1.m1.1a"><mn id="S2.p3.1.m1.1.1" xref="S2.p3.1.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S2.p3.1.m1.1b"><cn type="integer" id="S2.p3.1.m1.1.1.cmml" xref="S2.p3.1.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p3.1.m1.1c">2</annotation></semantics></math> in Figure <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Federated Learning of Large ASR Models in the Real World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. Before sending the model to clients, the server quantizes the variables to low-bit precision <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>. To balance the quality degradation and the training efficiency, we quantize the matrices variables to float16 and keep other variables in the original float32 format as the model quality is more sensitive to the biases and activations. Then the server sends the quantized models to clients and clients compute gradients with the same precision of the variables. In this way, both the download and upload sizes are reduced with the float16 format. The memory usage is also reduced because variable storage memory of float16 variables is smaller compared to float32 while the gradient computation is bounded by gradient checkpointing <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>. The results are reported in our experiments.</p>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.1" class="ltx_p"><span id="S2.p4.1.1" class="ltx_text ltx_font_bold">Partial model training.</span> We build an updated partial model training <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> corresponding to the step 4 in Figure <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Federated Learning of Large ASR Models in the Real World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> to reduce the memory usage and the upload size. It sets a subset of trainable variables and non-trainable variables in the model. In this way only a subset of gradients, i.e. for the trainable variables, needs to be computed and uploaded. And the non-trainable variables stay frozen during the training. Moreover, we freeze consecutive bottom encoder layers and only set the decoder and top encoder layers as trainable. When combining it with OMC, we observed that partial model training converges slower. To boost the convergence speed, we de-quantize the trainable variables to float32 again. To summarize, float32 variables consist of (1) all trainable variables from the decoder and top encoder layers and (2) the activations in non-trainable variables from the bottom encoder layers. And float16 includes matrices in non-trainable variables from the bottom encoder layers.
The performance is then shown in our experiments.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Model Quality</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">We explain our algorithm to boost the model quality of FL. The high level idea is to utilize the user-correction actions to refine the quality of data and labels with weighted client aggregation in FL.</p>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.1" class="ltx_p"><span id="S3.p2.1.1" class="ltx_text ltx_font_bold">Client selection.</span> To adopt the user-correction data, FL server selects the clients containing the corrections at the step 1 in Figure <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Federated Learning of Large ASR Models in the Real World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. At the beginning of an FL round, the server sends all clients an eligibility test designed to check if a client has the user-correction data. If a client passes the eligibility test, it will continue to participate the FL round. Otherwise, the client will drop out from the FL round. The server will keep sending the eligibility test until enough clients are collected to reach the expected report goal. In this way, all participating clients will have the correction data.</p>
</div>
<div id="S3.p3" class="ltx_para">
<p id="S3.p3.1" class="ltx_p"><span id="S3.p3.1.1" class="ltx_text ltx_font_bold">Data filtering on devices.</span> At the step 3 in Figure <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Federated Learning of Large ASR Models in the Real World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> when a client receives the model, the client needs to filter the data first. The purpose of the data filtering is to only take the user-correction data in the FL training. If the client batch size larger than 1, to make sure a client has enough data to form a batch of data after the filtering, we design the eligibility test to check if a client has enough (<math id="S3.p3.1.m1.1" class="ltx_Math" alttext="&gt;=" display="inline"><semantics id="S3.p3.1.m1.1a"><mo id="S3.p3.1.m1.1.1" xref="S3.p3.1.m1.1.1.cmml">&gt;=</mo><annotation-xml encoding="MathML-Content" id="S3.p3.1.m1.1b"><geq id="S3.p3.1.m1.1.1.cmml" xref="S3.p3.1.m1.1.1"></geq></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.1.m1.1c">&gt;=</annotation></semantics></math> the batch size) user-corrections. Another way is to duplicate the existing data to form a batch, which will change the training data distribution considered in the following WCA algorithm.</p>
</div>
<div id="S3.p4" class="ltx_para">
<p id="S3.p4.1" class="ltx_p">Another benefit of client selection and data filtering is to eliminate the “incorrect” corrections, e.g. a user said “covid” but got “covert” as transcript, then the user changed the transcript to “covertcovid” incorrectly. Because the true data is inaccessible in FL, such “incorrect” corrections also participate in the FL training and pollute the training data. Therefore, we need to filter out such “incorrected” examples. To do so, we use heuristics to estimate and quantify the quality of a correction in the eligibility test, e.g. the word length difference before and after a user edit should be smaller than a threshold. If the quality of correction is low by the hueristic, we eliminate the example.</p>
</div>
<div id="S3.p5" class="ltx_para">
<p id="S3.p5.1" class="ltx_p"><span id="S3.p5.1.1" class="ltx_text ltx_font_bold">Weighted Clients Aggregation.</span> At the step 5 in Figure <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Federated Learning of Large ASR Models in the Real World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, the server aggregates all the client uploads, i.e. the gradients from FedSGD computation, together to update the server model. At this time, we propose a WCA algorithm to compute the server model update. The motivation of WCA is to align the distribution of training data to the target distribution to boost the training quality. In particular, our target distribution is based on the list of corrected words denoted by <math id="S3.p5.1.m1.1" class="ltx_Math" alttext="\mathbb{W}" display="inline"><semantics id="S3.p5.1.m1.1a"><mi id="S3.p5.1.m1.1.1" xref="S3.p5.1.m1.1.1.cmml">𝕎</mi><annotation-xml encoding="MathML-Content" id="S3.p5.1.m1.1b"><ci id="S3.p5.1.m1.1.1.cmml" xref="S3.p5.1.m1.1.1">𝕎</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p5.1.m1.1c">\mathbb{W}</annotation></semantics></math>, i.e. a special distribution containing the incumbent model errors.</p>
</div>
<div id="S3.p6" class="ltx_para">
<p id="S3.p6.9" class="ltx_p">There are usually two aggregation methods in FL: (1) the simple averaging as <math id="S3.p6.1.m1.1" class="ltx_Math" alttext="\Sigma_{i=1}^{n}{G_{i}}/n" display="inline"><semantics id="S3.p6.1.m1.1a"><mrow id="S3.p6.1.m1.1.1" xref="S3.p6.1.m1.1.1.cmml"><mrow id="S3.p6.1.m1.1.1.2" xref="S3.p6.1.m1.1.1.2.cmml"><msubsup id="S3.p6.1.m1.1.1.2.2" xref="S3.p6.1.m1.1.1.2.2.cmml"><mi mathvariant="normal" id="S3.p6.1.m1.1.1.2.2.2.2" xref="S3.p6.1.m1.1.1.2.2.2.2.cmml">Σ</mi><mrow id="S3.p6.1.m1.1.1.2.2.2.3" xref="S3.p6.1.m1.1.1.2.2.2.3.cmml"><mi id="S3.p6.1.m1.1.1.2.2.2.3.2" xref="S3.p6.1.m1.1.1.2.2.2.3.2.cmml">i</mi><mo id="S3.p6.1.m1.1.1.2.2.2.3.1" xref="S3.p6.1.m1.1.1.2.2.2.3.1.cmml">=</mo><mn id="S3.p6.1.m1.1.1.2.2.2.3.3" xref="S3.p6.1.m1.1.1.2.2.2.3.3.cmml">1</mn></mrow><mi id="S3.p6.1.m1.1.1.2.2.3" xref="S3.p6.1.m1.1.1.2.2.3.cmml">n</mi></msubsup><mo lspace="0em" rspace="0em" id="S3.p6.1.m1.1.1.2.1" xref="S3.p6.1.m1.1.1.2.1.cmml">​</mo><msub id="S3.p6.1.m1.1.1.2.3" xref="S3.p6.1.m1.1.1.2.3.cmml"><mi id="S3.p6.1.m1.1.1.2.3.2" xref="S3.p6.1.m1.1.1.2.3.2.cmml">G</mi><mi id="S3.p6.1.m1.1.1.2.3.3" xref="S3.p6.1.m1.1.1.2.3.3.cmml">i</mi></msub></mrow><mo id="S3.p6.1.m1.1.1.1" xref="S3.p6.1.m1.1.1.1.cmml">/</mo><mi id="S3.p6.1.m1.1.1.3" xref="S3.p6.1.m1.1.1.3.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.p6.1.m1.1b"><apply id="S3.p6.1.m1.1.1.cmml" xref="S3.p6.1.m1.1.1"><divide id="S3.p6.1.m1.1.1.1.cmml" xref="S3.p6.1.m1.1.1.1"></divide><apply id="S3.p6.1.m1.1.1.2.cmml" xref="S3.p6.1.m1.1.1.2"><times id="S3.p6.1.m1.1.1.2.1.cmml" xref="S3.p6.1.m1.1.1.2.1"></times><apply id="S3.p6.1.m1.1.1.2.2.cmml" xref="S3.p6.1.m1.1.1.2.2"><csymbol cd="ambiguous" id="S3.p6.1.m1.1.1.2.2.1.cmml" xref="S3.p6.1.m1.1.1.2.2">superscript</csymbol><apply id="S3.p6.1.m1.1.1.2.2.2.cmml" xref="S3.p6.1.m1.1.1.2.2"><csymbol cd="ambiguous" id="S3.p6.1.m1.1.1.2.2.2.1.cmml" xref="S3.p6.1.m1.1.1.2.2">subscript</csymbol><ci id="S3.p6.1.m1.1.1.2.2.2.2.cmml" xref="S3.p6.1.m1.1.1.2.2.2.2">Σ</ci><apply id="S3.p6.1.m1.1.1.2.2.2.3.cmml" xref="S3.p6.1.m1.1.1.2.2.2.3"><eq id="S3.p6.1.m1.1.1.2.2.2.3.1.cmml" xref="S3.p6.1.m1.1.1.2.2.2.3.1"></eq><ci id="S3.p6.1.m1.1.1.2.2.2.3.2.cmml" xref="S3.p6.1.m1.1.1.2.2.2.3.2">𝑖</ci><cn type="integer" id="S3.p6.1.m1.1.1.2.2.2.3.3.cmml" xref="S3.p6.1.m1.1.1.2.2.2.3.3">1</cn></apply></apply><ci id="S3.p6.1.m1.1.1.2.2.3.cmml" xref="S3.p6.1.m1.1.1.2.2.3">𝑛</ci></apply><apply id="S3.p6.1.m1.1.1.2.3.cmml" xref="S3.p6.1.m1.1.1.2.3"><csymbol cd="ambiguous" id="S3.p6.1.m1.1.1.2.3.1.cmml" xref="S3.p6.1.m1.1.1.2.3">subscript</csymbol><ci id="S3.p6.1.m1.1.1.2.3.2.cmml" xref="S3.p6.1.m1.1.1.2.3.2">𝐺</ci><ci id="S3.p6.1.m1.1.1.2.3.3.cmml" xref="S3.p6.1.m1.1.1.2.3.3">𝑖</ci></apply></apply><ci id="S3.p6.1.m1.1.1.3.cmml" xref="S3.p6.1.m1.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p6.1.m1.1c">\Sigma_{i=1}^{n}{G_{i}}/n</annotation></semantics></math> where <math id="S3.p6.2.m2.1" class="ltx_Math" alttext="G_{i}" display="inline"><semantics id="S3.p6.2.m2.1a"><msub id="S3.p6.2.m2.1.1" xref="S3.p6.2.m2.1.1.cmml"><mi id="S3.p6.2.m2.1.1.2" xref="S3.p6.2.m2.1.1.2.cmml">G</mi><mi id="S3.p6.2.m2.1.1.3" xref="S3.p6.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p6.2.m2.1b"><apply id="S3.p6.2.m2.1.1.cmml" xref="S3.p6.2.m2.1.1"><csymbol cd="ambiguous" id="S3.p6.2.m2.1.1.1.cmml" xref="S3.p6.2.m2.1.1">subscript</csymbol><ci id="S3.p6.2.m2.1.1.2.cmml" xref="S3.p6.2.m2.1.1.2">𝐺</ci><ci id="S3.p6.2.m2.1.1.3.cmml" xref="S3.p6.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p6.2.m2.1c">G_{i}</annotation></semantics></math> is the model deltas of <math id="S3.p6.3.m3.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S3.p6.3.m3.1a"><mi id="S3.p6.3.m3.1.1" xref="S3.p6.3.m3.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.p6.3.m3.1b"><ci id="S3.p6.3.m3.1.1.cmml" xref="S3.p6.3.m3.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p6.3.m3.1c">n</annotation></semantics></math> clients; and (2) the <math id="S3.p6.4.m4.1" class="ltx_Math" alttext="\#" display="inline"><semantics id="S3.p6.4.m4.1a"><mi mathvariant="normal" id="S3.p6.4.m4.1.1" xref="S3.p6.4.m4.1.1.cmml">#</mi><annotation-xml encoding="MathML-Content" id="S3.p6.4.m4.1b"><ci id="S3.p6.4.m4.1.1.cmml" xref="S3.p6.4.m4.1.1">#</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p6.4.m4.1c">\#</annotation></semantics></math>example based aggregation as <math id="S3.p6.5.m5.1" class="ltx_Math" alttext="\Sigma_{i=1}^{n}{G_{i}}{E_{i}}/\Sigma_{i=1}^{n}{E_{i}}" display="inline"><semantics id="S3.p6.5.m5.1a"><mrow id="S3.p6.5.m5.1.1" xref="S3.p6.5.m5.1.1.cmml"><mrow id="S3.p6.5.m5.1.1.2" xref="S3.p6.5.m5.1.1.2.cmml"><mrow id="S3.p6.5.m5.1.1.2.2" xref="S3.p6.5.m5.1.1.2.2.cmml"><msubsup id="S3.p6.5.m5.1.1.2.2.2" xref="S3.p6.5.m5.1.1.2.2.2.cmml"><mi mathvariant="normal" id="S3.p6.5.m5.1.1.2.2.2.2.2" xref="S3.p6.5.m5.1.1.2.2.2.2.2.cmml">Σ</mi><mrow id="S3.p6.5.m5.1.1.2.2.2.2.3" xref="S3.p6.5.m5.1.1.2.2.2.2.3.cmml"><mi id="S3.p6.5.m5.1.1.2.2.2.2.3.2" xref="S3.p6.5.m5.1.1.2.2.2.2.3.2.cmml">i</mi><mo id="S3.p6.5.m5.1.1.2.2.2.2.3.1" xref="S3.p6.5.m5.1.1.2.2.2.2.3.1.cmml">=</mo><mn id="S3.p6.5.m5.1.1.2.2.2.2.3.3" xref="S3.p6.5.m5.1.1.2.2.2.2.3.3.cmml">1</mn></mrow><mi id="S3.p6.5.m5.1.1.2.2.2.3" xref="S3.p6.5.m5.1.1.2.2.2.3.cmml">n</mi></msubsup><mo lspace="0em" rspace="0em" id="S3.p6.5.m5.1.1.2.2.1" xref="S3.p6.5.m5.1.1.2.2.1.cmml">​</mo><msub id="S3.p6.5.m5.1.1.2.2.3" xref="S3.p6.5.m5.1.1.2.2.3.cmml"><mi id="S3.p6.5.m5.1.1.2.2.3.2" xref="S3.p6.5.m5.1.1.2.2.3.2.cmml">G</mi><mi id="S3.p6.5.m5.1.1.2.2.3.3" xref="S3.p6.5.m5.1.1.2.2.3.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S3.p6.5.m5.1.1.2.2.1a" xref="S3.p6.5.m5.1.1.2.2.1.cmml">​</mo><msub id="S3.p6.5.m5.1.1.2.2.4" xref="S3.p6.5.m5.1.1.2.2.4.cmml"><mi id="S3.p6.5.m5.1.1.2.2.4.2" xref="S3.p6.5.m5.1.1.2.2.4.2.cmml">E</mi><mi id="S3.p6.5.m5.1.1.2.2.4.3" xref="S3.p6.5.m5.1.1.2.2.4.3.cmml">i</mi></msub></mrow><mo id="S3.p6.5.m5.1.1.2.1" xref="S3.p6.5.m5.1.1.2.1.cmml">/</mo><msubsup id="S3.p6.5.m5.1.1.2.3" xref="S3.p6.5.m5.1.1.2.3.cmml"><mi mathvariant="normal" id="S3.p6.5.m5.1.1.2.3.2.2" xref="S3.p6.5.m5.1.1.2.3.2.2.cmml">Σ</mi><mrow id="S3.p6.5.m5.1.1.2.3.2.3" xref="S3.p6.5.m5.1.1.2.3.2.3.cmml"><mi id="S3.p6.5.m5.1.1.2.3.2.3.2" xref="S3.p6.5.m5.1.1.2.3.2.3.2.cmml">i</mi><mo id="S3.p6.5.m5.1.1.2.3.2.3.1" xref="S3.p6.5.m5.1.1.2.3.2.3.1.cmml">=</mo><mn id="S3.p6.5.m5.1.1.2.3.2.3.3" xref="S3.p6.5.m5.1.1.2.3.2.3.3.cmml">1</mn></mrow><mi id="S3.p6.5.m5.1.1.2.3.3" xref="S3.p6.5.m5.1.1.2.3.3.cmml">n</mi></msubsup></mrow><mo lspace="0em" rspace="0em" id="S3.p6.5.m5.1.1.1" xref="S3.p6.5.m5.1.1.1.cmml">​</mo><msub id="S3.p6.5.m5.1.1.3" xref="S3.p6.5.m5.1.1.3.cmml"><mi id="S3.p6.5.m5.1.1.3.2" xref="S3.p6.5.m5.1.1.3.2.cmml">E</mi><mi id="S3.p6.5.m5.1.1.3.3" xref="S3.p6.5.m5.1.1.3.3.cmml">i</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.p6.5.m5.1b"><apply id="S3.p6.5.m5.1.1.cmml" xref="S3.p6.5.m5.1.1"><times id="S3.p6.5.m5.1.1.1.cmml" xref="S3.p6.5.m5.1.1.1"></times><apply id="S3.p6.5.m5.1.1.2.cmml" xref="S3.p6.5.m5.1.1.2"><divide id="S3.p6.5.m5.1.1.2.1.cmml" xref="S3.p6.5.m5.1.1.2.1"></divide><apply id="S3.p6.5.m5.1.1.2.2.cmml" xref="S3.p6.5.m5.1.1.2.2"><times id="S3.p6.5.m5.1.1.2.2.1.cmml" xref="S3.p6.5.m5.1.1.2.2.1"></times><apply id="S3.p6.5.m5.1.1.2.2.2.cmml" xref="S3.p6.5.m5.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.p6.5.m5.1.1.2.2.2.1.cmml" xref="S3.p6.5.m5.1.1.2.2.2">superscript</csymbol><apply id="S3.p6.5.m5.1.1.2.2.2.2.cmml" xref="S3.p6.5.m5.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.p6.5.m5.1.1.2.2.2.2.1.cmml" xref="S3.p6.5.m5.1.1.2.2.2">subscript</csymbol><ci id="S3.p6.5.m5.1.1.2.2.2.2.2.cmml" xref="S3.p6.5.m5.1.1.2.2.2.2.2">Σ</ci><apply id="S3.p6.5.m5.1.1.2.2.2.2.3.cmml" xref="S3.p6.5.m5.1.1.2.2.2.2.3"><eq id="S3.p6.5.m5.1.1.2.2.2.2.3.1.cmml" xref="S3.p6.5.m5.1.1.2.2.2.2.3.1"></eq><ci id="S3.p6.5.m5.1.1.2.2.2.2.3.2.cmml" xref="S3.p6.5.m5.1.1.2.2.2.2.3.2">𝑖</ci><cn type="integer" id="S3.p6.5.m5.1.1.2.2.2.2.3.3.cmml" xref="S3.p6.5.m5.1.1.2.2.2.2.3.3">1</cn></apply></apply><ci id="S3.p6.5.m5.1.1.2.2.2.3.cmml" xref="S3.p6.5.m5.1.1.2.2.2.3">𝑛</ci></apply><apply id="S3.p6.5.m5.1.1.2.2.3.cmml" xref="S3.p6.5.m5.1.1.2.2.3"><csymbol cd="ambiguous" id="S3.p6.5.m5.1.1.2.2.3.1.cmml" xref="S3.p6.5.m5.1.1.2.2.3">subscript</csymbol><ci id="S3.p6.5.m5.1.1.2.2.3.2.cmml" xref="S3.p6.5.m5.1.1.2.2.3.2">𝐺</ci><ci id="S3.p6.5.m5.1.1.2.2.3.3.cmml" xref="S3.p6.5.m5.1.1.2.2.3.3">𝑖</ci></apply><apply id="S3.p6.5.m5.1.1.2.2.4.cmml" xref="S3.p6.5.m5.1.1.2.2.4"><csymbol cd="ambiguous" id="S3.p6.5.m5.1.1.2.2.4.1.cmml" xref="S3.p6.5.m5.1.1.2.2.4">subscript</csymbol><ci id="S3.p6.5.m5.1.1.2.2.4.2.cmml" xref="S3.p6.5.m5.1.1.2.2.4.2">𝐸</ci><ci id="S3.p6.5.m5.1.1.2.2.4.3.cmml" xref="S3.p6.5.m5.1.1.2.2.4.3">𝑖</ci></apply></apply><apply id="S3.p6.5.m5.1.1.2.3.cmml" xref="S3.p6.5.m5.1.1.2.3"><csymbol cd="ambiguous" id="S3.p6.5.m5.1.1.2.3.1.cmml" xref="S3.p6.5.m5.1.1.2.3">superscript</csymbol><apply id="S3.p6.5.m5.1.1.2.3.2.cmml" xref="S3.p6.5.m5.1.1.2.3"><csymbol cd="ambiguous" id="S3.p6.5.m5.1.1.2.3.2.1.cmml" xref="S3.p6.5.m5.1.1.2.3">subscript</csymbol><ci id="S3.p6.5.m5.1.1.2.3.2.2.cmml" xref="S3.p6.5.m5.1.1.2.3.2.2">Σ</ci><apply id="S3.p6.5.m5.1.1.2.3.2.3.cmml" xref="S3.p6.5.m5.1.1.2.3.2.3"><eq id="S3.p6.5.m5.1.1.2.3.2.3.1.cmml" xref="S3.p6.5.m5.1.1.2.3.2.3.1"></eq><ci id="S3.p6.5.m5.1.1.2.3.2.3.2.cmml" xref="S3.p6.5.m5.1.1.2.3.2.3.2">𝑖</ci><cn type="integer" id="S3.p6.5.m5.1.1.2.3.2.3.3.cmml" xref="S3.p6.5.m5.1.1.2.3.2.3.3">1</cn></apply></apply><ci id="S3.p6.5.m5.1.1.2.3.3.cmml" xref="S3.p6.5.m5.1.1.2.3.3">𝑛</ci></apply></apply><apply id="S3.p6.5.m5.1.1.3.cmml" xref="S3.p6.5.m5.1.1.3"><csymbol cd="ambiguous" id="S3.p6.5.m5.1.1.3.1.cmml" xref="S3.p6.5.m5.1.1.3">subscript</csymbol><ci id="S3.p6.5.m5.1.1.3.2.cmml" xref="S3.p6.5.m5.1.1.3.2">𝐸</ci><ci id="S3.p6.5.m5.1.1.3.3.cmml" xref="S3.p6.5.m5.1.1.3.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p6.5.m5.1c">\Sigma_{i=1}^{n}{G_{i}}{E_{i}}/\Sigma_{i=1}^{n}{E_{i}}</annotation></semantics></math> where <math id="S3.p6.6.m6.1" class="ltx_Math" alttext="E_{i}" display="inline"><semantics id="S3.p6.6.m6.1a"><msub id="S3.p6.6.m6.1.1" xref="S3.p6.6.m6.1.1.cmml"><mi id="S3.p6.6.m6.1.1.2" xref="S3.p6.6.m6.1.1.2.cmml">E</mi><mi id="S3.p6.6.m6.1.1.3" xref="S3.p6.6.m6.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p6.6.m6.1b"><apply id="S3.p6.6.m6.1.1.cmml" xref="S3.p6.6.m6.1.1"><csymbol cd="ambiguous" id="S3.p6.6.m6.1.1.1.cmml" xref="S3.p6.6.m6.1.1">subscript</csymbol><ci id="S3.p6.6.m6.1.1.2.cmml" xref="S3.p6.6.m6.1.1.2">𝐸</ci><ci id="S3.p6.6.m6.1.1.3.cmml" xref="S3.p6.6.m6.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p6.6.m6.1c">E_{i}</annotation></semantics></math> is the number of participating examples of the each client in FedAVG. However, these aggregation methods have not considered the quality of the clients data. Thus the model quality may be degraded due to unexpected data as discussed before. To fix this problem, we propose a WCA algorithm as <math id="S3.p6.7.m7.1" class="ltx_Math" alttext="\Sigma_{i=1}^{n}{G_{i}}{w_{i}}/\Sigma_{i=1}^{n}{w_{i}}" display="inline"><semantics id="S3.p6.7.m7.1a"><mrow id="S3.p6.7.m7.1.1" xref="S3.p6.7.m7.1.1.cmml"><mrow id="S3.p6.7.m7.1.1.2" xref="S3.p6.7.m7.1.1.2.cmml"><mrow id="S3.p6.7.m7.1.1.2.2" xref="S3.p6.7.m7.1.1.2.2.cmml"><msubsup id="S3.p6.7.m7.1.1.2.2.2" xref="S3.p6.7.m7.1.1.2.2.2.cmml"><mi mathvariant="normal" id="S3.p6.7.m7.1.1.2.2.2.2.2" xref="S3.p6.7.m7.1.1.2.2.2.2.2.cmml">Σ</mi><mrow id="S3.p6.7.m7.1.1.2.2.2.2.3" xref="S3.p6.7.m7.1.1.2.2.2.2.3.cmml"><mi id="S3.p6.7.m7.1.1.2.2.2.2.3.2" xref="S3.p6.7.m7.1.1.2.2.2.2.3.2.cmml">i</mi><mo id="S3.p6.7.m7.1.1.2.2.2.2.3.1" xref="S3.p6.7.m7.1.1.2.2.2.2.3.1.cmml">=</mo><mn id="S3.p6.7.m7.1.1.2.2.2.2.3.3" xref="S3.p6.7.m7.1.1.2.2.2.2.3.3.cmml">1</mn></mrow><mi id="S3.p6.7.m7.1.1.2.2.2.3" xref="S3.p6.7.m7.1.1.2.2.2.3.cmml">n</mi></msubsup><mo lspace="0em" rspace="0em" id="S3.p6.7.m7.1.1.2.2.1" xref="S3.p6.7.m7.1.1.2.2.1.cmml">​</mo><msub id="S3.p6.7.m7.1.1.2.2.3" xref="S3.p6.7.m7.1.1.2.2.3.cmml"><mi id="S3.p6.7.m7.1.1.2.2.3.2" xref="S3.p6.7.m7.1.1.2.2.3.2.cmml">G</mi><mi id="S3.p6.7.m7.1.1.2.2.3.3" xref="S3.p6.7.m7.1.1.2.2.3.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S3.p6.7.m7.1.1.2.2.1a" xref="S3.p6.7.m7.1.1.2.2.1.cmml">​</mo><msub id="S3.p6.7.m7.1.1.2.2.4" xref="S3.p6.7.m7.1.1.2.2.4.cmml"><mi id="S3.p6.7.m7.1.1.2.2.4.2" xref="S3.p6.7.m7.1.1.2.2.4.2.cmml">w</mi><mi id="S3.p6.7.m7.1.1.2.2.4.3" xref="S3.p6.7.m7.1.1.2.2.4.3.cmml">i</mi></msub></mrow><mo id="S3.p6.7.m7.1.1.2.1" xref="S3.p6.7.m7.1.1.2.1.cmml">/</mo><msubsup id="S3.p6.7.m7.1.1.2.3" xref="S3.p6.7.m7.1.1.2.3.cmml"><mi mathvariant="normal" id="S3.p6.7.m7.1.1.2.3.2.2" xref="S3.p6.7.m7.1.1.2.3.2.2.cmml">Σ</mi><mrow id="S3.p6.7.m7.1.1.2.3.2.3" xref="S3.p6.7.m7.1.1.2.3.2.3.cmml"><mi id="S3.p6.7.m7.1.1.2.3.2.3.2" xref="S3.p6.7.m7.1.1.2.3.2.3.2.cmml">i</mi><mo id="S3.p6.7.m7.1.1.2.3.2.3.1" xref="S3.p6.7.m7.1.1.2.3.2.3.1.cmml">=</mo><mn id="S3.p6.7.m7.1.1.2.3.2.3.3" xref="S3.p6.7.m7.1.1.2.3.2.3.3.cmml">1</mn></mrow><mi id="S3.p6.7.m7.1.1.2.3.3" xref="S3.p6.7.m7.1.1.2.3.3.cmml">n</mi></msubsup></mrow><mo lspace="0em" rspace="0em" id="S3.p6.7.m7.1.1.1" xref="S3.p6.7.m7.1.1.1.cmml">​</mo><msub id="S3.p6.7.m7.1.1.3" xref="S3.p6.7.m7.1.1.3.cmml"><mi id="S3.p6.7.m7.1.1.3.2" xref="S3.p6.7.m7.1.1.3.2.cmml">w</mi><mi id="S3.p6.7.m7.1.1.3.3" xref="S3.p6.7.m7.1.1.3.3.cmml">i</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.p6.7.m7.1b"><apply id="S3.p6.7.m7.1.1.cmml" xref="S3.p6.7.m7.1.1"><times id="S3.p6.7.m7.1.1.1.cmml" xref="S3.p6.7.m7.1.1.1"></times><apply id="S3.p6.7.m7.1.1.2.cmml" xref="S3.p6.7.m7.1.1.2"><divide id="S3.p6.7.m7.1.1.2.1.cmml" xref="S3.p6.7.m7.1.1.2.1"></divide><apply id="S3.p6.7.m7.1.1.2.2.cmml" xref="S3.p6.7.m7.1.1.2.2"><times id="S3.p6.7.m7.1.1.2.2.1.cmml" xref="S3.p6.7.m7.1.1.2.2.1"></times><apply id="S3.p6.7.m7.1.1.2.2.2.cmml" xref="S3.p6.7.m7.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.p6.7.m7.1.1.2.2.2.1.cmml" xref="S3.p6.7.m7.1.1.2.2.2">superscript</csymbol><apply id="S3.p6.7.m7.1.1.2.2.2.2.cmml" xref="S3.p6.7.m7.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.p6.7.m7.1.1.2.2.2.2.1.cmml" xref="S3.p6.7.m7.1.1.2.2.2">subscript</csymbol><ci id="S3.p6.7.m7.1.1.2.2.2.2.2.cmml" xref="S3.p6.7.m7.1.1.2.2.2.2.2">Σ</ci><apply id="S3.p6.7.m7.1.1.2.2.2.2.3.cmml" xref="S3.p6.7.m7.1.1.2.2.2.2.3"><eq id="S3.p6.7.m7.1.1.2.2.2.2.3.1.cmml" xref="S3.p6.7.m7.1.1.2.2.2.2.3.1"></eq><ci id="S3.p6.7.m7.1.1.2.2.2.2.3.2.cmml" xref="S3.p6.7.m7.1.1.2.2.2.2.3.2">𝑖</ci><cn type="integer" id="S3.p6.7.m7.1.1.2.2.2.2.3.3.cmml" xref="S3.p6.7.m7.1.1.2.2.2.2.3.3">1</cn></apply></apply><ci id="S3.p6.7.m7.1.1.2.2.2.3.cmml" xref="S3.p6.7.m7.1.1.2.2.2.3">𝑛</ci></apply><apply id="S3.p6.7.m7.1.1.2.2.3.cmml" xref="S3.p6.7.m7.1.1.2.2.3"><csymbol cd="ambiguous" id="S3.p6.7.m7.1.1.2.2.3.1.cmml" xref="S3.p6.7.m7.1.1.2.2.3">subscript</csymbol><ci id="S3.p6.7.m7.1.1.2.2.3.2.cmml" xref="S3.p6.7.m7.1.1.2.2.3.2">𝐺</ci><ci id="S3.p6.7.m7.1.1.2.2.3.3.cmml" xref="S3.p6.7.m7.1.1.2.2.3.3">𝑖</ci></apply><apply id="S3.p6.7.m7.1.1.2.2.4.cmml" xref="S3.p6.7.m7.1.1.2.2.4"><csymbol cd="ambiguous" id="S3.p6.7.m7.1.1.2.2.4.1.cmml" xref="S3.p6.7.m7.1.1.2.2.4">subscript</csymbol><ci id="S3.p6.7.m7.1.1.2.2.4.2.cmml" xref="S3.p6.7.m7.1.1.2.2.4.2">𝑤</ci><ci id="S3.p6.7.m7.1.1.2.2.4.3.cmml" xref="S3.p6.7.m7.1.1.2.2.4.3">𝑖</ci></apply></apply><apply id="S3.p6.7.m7.1.1.2.3.cmml" xref="S3.p6.7.m7.1.1.2.3"><csymbol cd="ambiguous" id="S3.p6.7.m7.1.1.2.3.1.cmml" xref="S3.p6.7.m7.1.1.2.3">superscript</csymbol><apply id="S3.p6.7.m7.1.1.2.3.2.cmml" xref="S3.p6.7.m7.1.1.2.3"><csymbol cd="ambiguous" id="S3.p6.7.m7.1.1.2.3.2.1.cmml" xref="S3.p6.7.m7.1.1.2.3">subscript</csymbol><ci id="S3.p6.7.m7.1.1.2.3.2.2.cmml" xref="S3.p6.7.m7.1.1.2.3.2.2">Σ</ci><apply id="S3.p6.7.m7.1.1.2.3.2.3.cmml" xref="S3.p6.7.m7.1.1.2.3.2.3"><eq id="S3.p6.7.m7.1.1.2.3.2.3.1.cmml" xref="S3.p6.7.m7.1.1.2.3.2.3.1"></eq><ci id="S3.p6.7.m7.1.1.2.3.2.3.2.cmml" xref="S3.p6.7.m7.1.1.2.3.2.3.2">𝑖</ci><cn type="integer" id="S3.p6.7.m7.1.1.2.3.2.3.3.cmml" xref="S3.p6.7.m7.1.1.2.3.2.3.3">1</cn></apply></apply><ci id="S3.p6.7.m7.1.1.2.3.3.cmml" xref="S3.p6.7.m7.1.1.2.3.3">𝑛</ci></apply></apply><apply id="S3.p6.7.m7.1.1.3.cmml" xref="S3.p6.7.m7.1.1.3"><csymbol cd="ambiguous" id="S3.p6.7.m7.1.1.3.1.cmml" xref="S3.p6.7.m7.1.1.3">subscript</csymbol><ci id="S3.p6.7.m7.1.1.3.2.cmml" xref="S3.p6.7.m7.1.1.3.2">𝑤</ci><ci id="S3.p6.7.m7.1.1.3.3.cmml" xref="S3.p6.7.m7.1.1.3.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p6.7.m7.1c">\Sigma_{i=1}^{n}{G_{i}}{w_{i}}/\Sigma_{i=1}^{n}{w_{i}}</annotation></semantics></math> where <math id="S3.p6.8.m8.1" class="ltx_Math" alttext="w_{i}" display="inline"><semantics id="S3.p6.8.m8.1a"><msub id="S3.p6.8.m8.1.1" xref="S3.p6.8.m8.1.1.cmml"><mi id="S3.p6.8.m8.1.1.2" xref="S3.p6.8.m8.1.1.2.cmml">w</mi><mi id="S3.p6.8.m8.1.1.3" xref="S3.p6.8.m8.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p6.8.m8.1b"><apply id="S3.p6.8.m8.1.1.cmml" xref="S3.p6.8.m8.1.1"><csymbol cd="ambiguous" id="S3.p6.8.m8.1.1.1.cmml" xref="S3.p6.8.m8.1.1">subscript</csymbol><ci id="S3.p6.8.m8.1.1.2.cmml" xref="S3.p6.8.m8.1.1.2">𝑤</ci><ci id="S3.p6.8.m8.1.1.3.cmml" xref="S3.p6.8.m8.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p6.8.m8.1c">w_{i}</annotation></semantics></math> is the designed weights of <math id="S3.p6.9.m9.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S3.p6.9.m9.1a"><mi id="S3.p6.9.m9.1.1" xref="S3.p6.9.m9.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.p6.9.m9.1b"><ci id="S3.p6.9.m9.1.1.cmml" xref="S3.p6.9.m9.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p6.9.m9.1c">n</annotation></semantics></math> clients as Algorithm <a href="#alg1" title="Algorithm 1 ‣ 3 Model Quality ‣ Federated Learning of Large ASR Models in the Real World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<figure id="alg1" class="ltx_float ltx_float_algorithm ltx_framed ltx_framed_top">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span id="alg1.11.1.1" class="ltx_text ltx_font_bold">Algorithm 1</span> </span> <em id="alg1.12.2" class="ltx_emph ltx_font_italic">Weighted client aggregation</em>. <math id="alg1.5.m1.1" class="ltx_Math" alttext="G" display="inline"><semantics id="alg1.5.m1.1b"><mi id="alg1.5.m1.1.1" xref="alg1.5.m1.1.1.cmml">G</mi><annotation-xml encoding="MathML-Content" id="alg1.5.m1.1c"><ci id="alg1.5.m1.1.1.cmml" xref="alg1.5.m1.1.1">𝐺</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.5.m1.1d">G</annotation></semantics></math> is the gradient computed from an example. <math id="alg1.6.m2.1" class="ltx_Math" alttext="w_{ij}" display="inline"><semantics id="alg1.6.m2.1b"><msub id="alg1.6.m2.1.1" xref="alg1.6.m2.1.1.cmml"><mi id="alg1.6.m2.1.1.2" xref="alg1.6.m2.1.1.2.cmml">w</mi><mrow id="alg1.6.m2.1.1.3" xref="alg1.6.m2.1.1.3.cmml"><mi id="alg1.6.m2.1.1.3.2" xref="alg1.6.m2.1.1.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="alg1.6.m2.1.1.3.1" xref="alg1.6.m2.1.1.3.1.cmml">​</mo><mi id="alg1.6.m2.1.1.3.3" xref="alg1.6.m2.1.1.3.3.cmml">j</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="alg1.6.m2.1c"><apply id="alg1.6.m2.1.1.cmml" xref="alg1.6.m2.1.1"><csymbol cd="ambiguous" id="alg1.6.m2.1.1.1.cmml" xref="alg1.6.m2.1.1">subscript</csymbol><ci id="alg1.6.m2.1.1.2.cmml" xref="alg1.6.m2.1.1.2">𝑤</ci><apply id="alg1.6.m2.1.1.3.cmml" xref="alg1.6.m2.1.1.3"><times id="alg1.6.m2.1.1.3.1.cmml" xref="alg1.6.m2.1.1.3.1"></times><ci id="alg1.6.m2.1.1.3.2.cmml" xref="alg1.6.m2.1.1.3.2">𝑖</ci><ci id="alg1.6.m2.1.1.3.3.cmml" xref="alg1.6.m2.1.1.3.3">𝑗</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.6.m2.1d">w_{ij}</annotation></semantics></math> is the designed weight of client <math id="alg1.7.m3.1" class="ltx_Math" alttext="i" display="inline"><semantics id="alg1.7.m3.1b"><mi id="alg1.7.m3.1.1" xref="alg1.7.m3.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="alg1.7.m3.1c"><ci id="alg1.7.m3.1.1.cmml" xref="alg1.7.m3.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.7.m3.1d">i</annotation></semantics></math> example <math id="alg1.8.m4.1" class="ltx_Math" alttext="j" display="inline"><semantics id="alg1.8.m4.1b"><mi id="alg1.8.m4.1.1" xref="alg1.8.m4.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="alg1.8.m4.1c"><ci id="alg1.8.m4.1.1.cmml" xref="alg1.8.m4.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.8.m4.1d">j</annotation></semantics></math>.</figcaption>
<div id="alg1.13" class="ltx_listing ltx_listing">
<div id="alg1.l1" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l1.1.1.1" class="ltx_text" style="font-size:80%;">1:</span></span><span id="alg1.l1.2" class="ltx_text ltx_font_bold">for</span> each round <math id="alg1.l1.m1.1" class="ltx_Math" alttext="r" display="inline"><semantics id="alg1.l1.m1.1a"><mi id="alg1.l1.m1.1.1" xref="alg1.l1.m1.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="alg1.l1.m1.1b"><ci id="alg1.l1.m1.1.1.cmml" xref="alg1.l1.m1.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m1.1c">r</annotation></semantics></math> = 1,2,… <span id="alg1.l1.3" class="ltx_text ltx_font_bold">do</span>

</div>
<div id="alg1.l2" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l2.1.1.1" class="ltx_text" style="font-size:80%;">2:</span></span>     Server selects participating clients.

</div>
<div id="alg1.l3" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l3.1.1.1" class="ltx_text" style="font-size:80%;">3:</span></span>     Server sends prepared models to selected clients.

</div>
<div id="alg1.l4" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l4.1.1.1" class="ltx_text" style="font-size:80%;">4:</span></span>     <span id="alg1.l4.2" class="ltx_text ltx_font_bold">for</span> each client <math id="alg1.l4.m1.1" class="ltx_Math" alttext="i\in n" display="inline"><semantics id="alg1.l4.m1.1a"><mrow id="alg1.l4.m1.1.1" xref="alg1.l4.m1.1.1.cmml"><mi id="alg1.l4.m1.1.1.2" xref="alg1.l4.m1.1.1.2.cmml">i</mi><mo id="alg1.l4.m1.1.1.1" xref="alg1.l4.m1.1.1.1.cmml">∈</mo><mi id="alg1.l4.m1.1.1.3" xref="alg1.l4.m1.1.1.3.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.l4.m1.1b"><apply id="alg1.l4.m1.1.1.cmml" xref="alg1.l4.m1.1.1"><in id="alg1.l4.m1.1.1.1.cmml" xref="alg1.l4.m1.1.1.1"></in><ci id="alg1.l4.m1.1.1.2.cmml" xref="alg1.l4.m1.1.1.2">𝑖</ci><ci id="alg1.l4.m1.1.1.3.cmml" xref="alg1.l4.m1.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l4.m1.1c">i\in n</annotation></semantics></math> <span id="alg1.l4.3" class="ltx_text ltx_font_bold">in parallel</span> <span id="alg1.l4.4" class="ltx_text ltx_font_bold">do</span>

</div>
<div id="alg1.l5" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l5.1.1.1" class="ltx_text" style="font-size:80%;">5:</span></span>         Filter examples to form a batch.

</div>
<div id="alg1.l6" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l6.1.1.1" class="ltx_text" style="font-size:80%;">6:</span></span>         <span id="alg1.l6.2" class="ltx_text ltx_font_bold">for</span> each example <math id="alg1.l6.m1.1" class="ltx_Math" alttext="E_{j}" display="inline"><semantics id="alg1.l6.m1.1a"><msub id="alg1.l6.m1.1.1" xref="alg1.l6.m1.1.1.cmml"><mi id="alg1.l6.m1.1.1.2" xref="alg1.l6.m1.1.1.2.cmml">E</mi><mi id="alg1.l6.m1.1.1.3" xref="alg1.l6.m1.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.l6.m1.1b"><apply id="alg1.l6.m1.1.1.cmml" xref="alg1.l6.m1.1.1"><csymbol cd="ambiguous" id="alg1.l6.m1.1.1.1.cmml" xref="alg1.l6.m1.1.1">subscript</csymbol><ci id="alg1.l6.m1.1.1.2.cmml" xref="alg1.l6.m1.1.1.2">𝐸</ci><ci id="alg1.l6.m1.1.1.3.cmml" xref="alg1.l6.m1.1.1.3">𝑗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l6.m1.1c">E_{j}</annotation></semantics></math> in the batch <span id="alg1.l6.3" class="ltx_text ltx_font_bold">do</span>

</div>
<div id="alg1.l7" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l7.1.1.1" class="ltx_text" style="font-size:80%;">7:</span></span>              Compute <math id="alg1.l7.m1.1" class="ltx_Math" alttext="w_{ij}" display="inline"><semantics id="alg1.l7.m1.1a"><msub id="alg1.l7.m1.1.1" xref="alg1.l7.m1.1.1.cmml"><mi id="alg1.l7.m1.1.1.2" xref="alg1.l7.m1.1.1.2.cmml">w</mi><mrow id="alg1.l7.m1.1.1.3" xref="alg1.l7.m1.1.1.3.cmml"><mi id="alg1.l7.m1.1.1.3.2" xref="alg1.l7.m1.1.1.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="alg1.l7.m1.1.1.3.1" xref="alg1.l7.m1.1.1.3.1.cmml">​</mo><mi id="alg1.l7.m1.1.1.3.3" xref="alg1.l7.m1.1.1.3.3.cmml">j</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="alg1.l7.m1.1b"><apply id="alg1.l7.m1.1.1.cmml" xref="alg1.l7.m1.1.1"><csymbol cd="ambiguous" id="alg1.l7.m1.1.1.1.cmml" xref="alg1.l7.m1.1.1">subscript</csymbol><ci id="alg1.l7.m1.1.1.2.cmml" xref="alg1.l7.m1.1.1.2">𝑤</ci><apply id="alg1.l7.m1.1.1.3.cmml" xref="alg1.l7.m1.1.1.3"><times id="alg1.l7.m1.1.1.3.1.cmml" xref="alg1.l7.m1.1.1.3.1"></times><ci id="alg1.l7.m1.1.1.3.2.cmml" xref="alg1.l7.m1.1.1.3.2">𝑖</ci><ci id="alg1.l7.m1.1.1.3.3.cmml" xref="alg1.l7.m1.1.1.3.3">𝑗</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l7.m1.1c">w_{ij}</annotation></semantics></math> for example <math id="alg1.l7.m2.1" class="ltx_Math" alttext="E_{j}" display="inline"><semantics id="alg1.l7.m2.1a"><msub id="alg1.l7.m2.1.1" xref="alg1.l7.m2.1.1.cmml"><mi id="alg1.l7.m2.1.1.2" xref="alg1.l7.m2.1.1.2.cmml">E</mi><mi id="alg1.l7.m2.1.1.3" xref="alg1.l7.m2.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.l7.m2.1b"><apply id="alg1.l7.m2.1.1.cmml" xref="alg1.l7.m2.1.1"><csymbol cd="ambiguous" id="alg1.l7.m2.1.1.1.cmml" xref="alg1.l7.m2.1.1">subscript</csymbol><ci id="alg1.l7.m2.1.1.2.cmml" xref="alg1.l7.m2.1.1.2">𝐸</ci><ci id="alg1.l7.m2.1.1.3.cmml" xref="alg1.l7.m2.1.1.3">𝑗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l7.m2.1c">E_{j}</annotation></semantics></math>


</div>
<div id="alg1.l8" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l8.1.1.1" class="ltx_text" style="font-size:80%;">8:</span></span>         <span id="alg1.l8.2" class="ltx_text ltx_font_bold">end</span> <span id="alg1.l8.3" class="ltx_text ltx_font_bold">for</span>
</div>
<div id="alg1.l9" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l9.1.1.1" class="ltx_text" style="font-size:80%;">9:</span></span>         <math id="alg1.l9.m1.1" class="ltx_Math" alttext="G_{i}\leftarrow\Sigma_{j}G_{ij}w_{ij}" display="inline"><semantics id="alg1.l9.m1.1a"><mrow id="alg1.l9.m1.1.1" xref="alg1.l9.m1.1.1.cmml"><msub id="alg1.l9.m1.1.1.2" xref="alg1.l9.m1.1.1.2.cmml"><mi id="alg1.l9.m1.1.1.2.2" xref="alg1.l9.m1.1.1.2.2.cmml">G</mi><mi id="alg1.l9.m1.1.1.2.3" xref="alg1.l9.m1.1.1.2.3.cmml">i</mi></msub><mo stretchy="false" id="alg1.l9.m1.1.1.1" xref="alg1.l9.m1.1.1.1.cmml">←</mo><mrow id="alg1.l9.m1.1.1.3" xref="alg1.l9.m1.1.1.3.cmml"><msub id="alg1.l9.m1.1.1.3.2" xref="alg1.l9.m1.1.1.3.2.cmml"><mi mathvariant="normal" id="alg1.l9.m1.1.1.3.2.2" xref="alg1.l9.m1.1.1.3.2.2.cmml">Σ</mi><mi id="alg1.l9.m1.1.1.3.2.3" xref="alg1.l9.m1.1.1.3.2.3.cmml">j</mi></msub><mo lspace="0em" rspace="0em" id="alg1.l9.m1.1.1.3.1" xref="alg1.l9.m1.1.1.3.1.cmml">​</mo><msub id="alg1.l9.m1.1.1.3.3" xref="alg1.l9.m1.1.1.3.3.cmml"><mi id="alg1.l9.m1.1.1.3.3.2" xref="alg1.l9.m1.1.1.3.3.2.cmml">G</mi><mrow id="alg1.l9.m1.1.1.3.3.3" xref="alg1.l9.m1.1.1.3.3.3.cmml"><mi id="alg1.l9.m1.1.1.3.3.3.2" xref="alg1.l9.m1.1.1.3.3.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="alg1.l9.m1.1.1.3.3.3.1" xref="alg1.l9.m1.1.1.3.3.3.1.cmml">​</mo><mi id="alg1.l9.m1.1.1.3.3.3.3" xref="alg1.l9.m1.1.1.3.3.3.3.cmml">j</mi></mrow></msub><mo lspace="0em" rspace="0em" id="alg1.l9.m1.1.1.3.1a" xref="alg1.l9.m1.1.1.3.1.cmml">​</mo><msub id="alg1.l9.m1.1.1.3.4" xref="alg1.l9.m1.1.1.3.4.cmml"><mi id="alg1.l9.m1.1.1.3.4.2" xref="alg1.l9.m1.1.1.3.4.2.cmml">w</mi><mrow id="alg1.l9.m1.1.1.3.4.3" xref="alg1.l9.m1.1.1.3.4.3.cmml"><mi id="alg1.l9.m1.1.1.3.4.3.2" xref="alg1.l9.m1.1.1.3.4.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="alg1.l9.m1.1.1.3.4.3.1" xref="alg1.l9.m1.1.1.3.4.3.1.cmml">​</mo><mi id="alg1.l9.m1.1.1.3.4.3.3" xref="alg1.l9.m1.1.1.3.4.3.3.cmml">j</mi></mrow></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l9.m1.1b"><apply id="alg1.l9.m1.1.1.cmml" xref="alg1.l9.m1.1.1"><ci id="alg1.l9.m1.1.1.1.cmml" xref="alg1.l9.m1.1.1.1">←</ci><apply id="alg1.l9.m1.1.1.2.cmml" xref="alg1.l9.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.l9.m1.1.1.2.1.cmml" xref="alg1.l9.m1.1.1.2">subscript</csymbol><ci id="alg1.l9.m1.1.1.2.2.cmml" xref="alg1.l9.m1.1.1.2.2">𝐺</ci><ci id="alg1.l9.m1.1.1.2.3.cmml" xref="alg1.l9.m1.1.1.2.3">𝑖</ci></apply><apply id="alg1.l9.m1.1.1.3.cmml" xref="alg1.l9.m1.1.1.3"><times id="alg1.l9.m1.1.1.3.1.cmml" xref="alg1.l9.m1.1.1.3.1"></times><apply id="alg1.l9.m1.1.1.3.2.cmml" xref="alg1.l9.m1.1.1.3.2"><csymbol cd="ambiguous" id="alg1.l9.m1.1.1.3.2.1.cmml" xref="alg1.l9.m1.1.1.3.2">subscript</csymbol><ci id="alg1.l9.m1.1.1.3.2.2.cmml" xref="alg1.l9.m1.1.1.3.2.2">Σ</ci><ci id="alg1.l9.m1.1.1.3.2.3.cmml" xref="alg1.l9.m1.1.1.3.2.3">𝑗</ci></apply><apply id="alg1.l9.m1.1.1.3.3.cmml" xref="alg1.l9.m1.1.1.3.3"><csymbol cd="ambiguous" id="alg1.l9.m1.1.1.3.3.1.cmml" xref="alg1.l9.m1.1.1.3.3">subscript</csymbol><ci id="alg1.l9.m1.1.1.3.3.2.cmml" xref="alg1.l9.m1.1.1.3.3.2">𝐺</ci><apply id="alg1.l9.m1.1.1.3.3.3.cmml" xref="alg1.l9.m1.1.1.3.3.3"><times id="alg1.l9.m1.1.1.3.3.3.1.cmml" xref="alg1.l9.m1.1.1.3.3.3.1"></times><ci id="alg1.l9.m1.1.1.3.3.3.2.cmml" xref="alg1.l9.m1.1.1.3.3.3.2">𝑖</ci><ci id="alg1.l9.m1.1.1.3.3.3.3.cmml" xref="alg1.l9.m1.1.1.3.3.3.3">𝑗</ci></apply></apply><apply id="alg1.l9.m1.1.1.3.4.cmml" xref="alg1.l9.m1.1.1.3.4"><csymbol cd="ambiguous" id="alg1.l9.m1.1.1.3.4.1.cmml" xref="alg1.l9.m1.1.1.3.4">subscript</csymbol><ci id="alg1.l9.m1.1.1.3.4.2.cmml" xref="alg1.l9.m1.1.1.3.4.2">𝑤</ci><apply id="alg1.l9.m1.1.1.3.4.3.cmml" xref="alg1.l9.m1.1.1.3.4.3"><times id="alg1.l9.m1.1.1.3.4.3.1.cmml" xref="alg1.l9.m1.1.1.3.4.3.1"></times><ci id="alg1.l9.m1.1.1.3.4.3.2.cmml" xref="alg1.l9.m1.1.1.3.4.3.2">𝑖</ci><ci id="alg1.l9.m1.1.1.3.4.3.3.cmml" xref="alg1.l9.m1.1.1.3.4.3.3">𝑗</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l9.m1.1c">G_{i}\leftarrow\Sigma_{j}G_{ij}w_{ij}</annotation></semantics></math>

</div>
<div id="alg1.l10" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l10.1.1.1" class="ltx_text" style="font-size:80%;">10:</span></span>         <math id="alg1.l10.m1.1" class="ltx_Math" alttext="w_{i}\leftarrow\Sigma_{j}w_{ij}" display="inline"><semantics id="alg1.l10.m1.1a"><mrow id="alg1.l10.m1.1.1" xref="alg1.l10.m1.1.1.cmml"><msub id="alg1.l10.m1.1.1.2" xref="alg1.l10.m1.1.1.2.cmml"><mi id="alg1.l10.m1.1.1.2.2" xref="alg1.l10.m1.1.1.2.2.cmml">w</mi><mi id="alg1.l10.m1.1.1.2.3" xref="alg1.l10.m1.1.1.2.3.cmml">i</mi></msub><mo stretchy="false" id="alg1.l10.m1.1.1.1" xref="alg1.l10.m1.1.1.1.cmml">←</mo><mrow id="alg1.l10.m1.1.1.3" xref="alg1.l10.m1.1.1.3.cmml"><msub id="alg1.l10.m1.1.1.3.2" xref="alg1.l10.m1.1.1.3.2.cmml"><mi mathvariant="normal" id="alg1.l10.m1.1.1.3.2.2" xref="alg1.l10.m1.1.1.3.2.2.cmml">Σ</mi><mi id="alg1.l10.m1.1.1.3.2.3" xref="alg1.l10.m1.1.1.3.2.3.cmml">j</mi></msub><mo lspace="0em" rspace="0em" id="alg1.l10.m1.1.1.3.1" xref="alg1.l10.m1.1.1.3.1.cmml">​</mo><msub id="alg1.l10.m1.1.1.3.3" xref="alg1.l10.m1.1.1.3.3.cmml"><mi id="alg1.l10.m1.1.1.3.3.2" xref="alg1.l10.m1.1.1.3.3.2.cmml">w</mi><mrow id="alg1.l10.m1.1.1.3.3.3" xref="alg1.l10.m1.1.1.3.3.3.cmml"><mi id="alg1.l10.m1.1.1.3.3.3.2" xref="alg1.l10.m1.1.1.3.3.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="alg1.l10.m1.1.1.3.3.3.1" xref="alg1.l10.m1.1.1.3.3.3.1.cmml">​</mo><mi id="alg1.l10.m1.1.1.3.3.3.3" xref="alg1.l10.m1.1.1.3.3.3.3.cmml">j</mi></mrow></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l10.m1.1b"><apply id="alg1.l10.m1.1.1.cmml" xref="alg1.l10.m1.1.1"><ci id="alg1.l10.m1.1.1.1.cmml" xref="alg1.l10.m1.1.1.1">←</ci><apply id="alg1.l10.m1.1.1.2.cmml" xref="alg1.l10.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.l10.m1.1.1.2.1.cmml" xref="alg1.l10.m1.1.1.2">subscript</csymbol><ci id="alg1.l10.m1.1.1.2.2.cmml" xref="alg1.l10.m1.1.1.2.2">𝑤</ci><ci id="alg1.l10.m1.1.1.2.3.cmml" xref="alg1.l10.m1.1.1.2.3">𝑖</ci></apply><apply id="alg1.l10.m1.1.1.3.cmml" xref="alg1.l10.m1.1.1.3"><times id="alg1.l10.m1.1.1.3.1.cmml" xref="alg1.l10.m1.1.1.3.1"></times><apply id="alg1.l10.m1.1.1.3.2.cmml" xref="alg1.l10.m1.1.1.3.2"><csymbol cd="ambiguous" id="alg1.l10.m1.1.1.3.2.1.cmml" xref="alg1.l10.m1.1.1.3.2">subscript</csymbol><ci id="alg1.l10.m1.1.1.3.2.2.cmml" xref="alg1.l10.m1.1.1.3.2.2">Σ</ci><ci id="alg1.l10.m1.1.1.3.2.3.cmml" xref="alg1.l10.m1.1.1.3.2.3">𝑗</ci></apply><apply id="alg1.l10.m1.1.1.3.3.cmml" xref="alg1.l10.m1.1.1.3.3"><csymbol cd="ambiguous" id="alg1.l10.m1.1.1.3.3.1.cmml" xref="alg1.l10.m1.1.1.3.3">subscript</csymbol><ci id="alg1.l10.m1.1.1.3.3.2.cmml" xref="alg1.l10.m1.1.1.3.3.2">𝑤</ci><apply id="alg1.l10.m1.1.1.3.3.3.cmml" xref="alg1.l10.m1.1.1.3.3.3"><times id="alg1.l10.m1.1.1.3.3.3.1.cmml" xref="alg1.l10.m1.1.1.3.3.3.1"></times><ci id="alg1.l10.m1.1.1.3.3.3.2.cmml" xref="alg1.l10.m1.1.1.3.3.3.2">𝑖</ci><ci id="alg1.l10.m1.1.1.3.3.3.3.cmml" xref="alg1.l10.m1.1.1.3.3.3.3">𝑗</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l10.m1.1c">w_{i}\leftarrow\Sigma_{j}w_{ij}</annotation></semantics></math>

</div>
<div id="alg1.l11" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l11.1.1.1" class="ltx_text" style="font-size:80%;">11:</span></span>     <span id="alg1.l11.2" class="ltx_text ltx_font_bold">end</span> <span id="alg1.l11.3" class="ltx_text ltx_font_bold">for</span>
</div>
<div id="alg1.l12" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l12.1.1.1" class="ltx_text" style="font-size:80%;">12:</span></span>     Update the server model by <math id="alg1.l12.m1.1" class="ltx_Math" alttext="\Sigma_{i=1}^{n}{G_{i}}{w_{i}}/\Sigma_{i=1}^{n}{w_{i}}" display="inline"><semantics id="alg1.l12.m1.1a"><mrow id="alg1.l12.m1.1.1" xref="alg1.l12.m1.1.1.cmml"><mrow id="alg1.l12.m1.1.1.2" xref="alg1.l12.m1.1.1.2.cmml"><mrow id="alg1.l12.m1.1.1.2.2" xref="alg1.l12.m1.1.1.2.2.cmml"><msubsup id="alg1.l12.m1.1.1.2.2.2" xref="alg1.l12.m1.1.1.2.2.2.cmml"><mi mathvariant="normal" id="alg1.l12.m1.1.1.2.2.2.2.2" xref="alg1.l12.m1.1.1.2.2.2.2.2.cmml">Σ</mi><mrow id="alg1.l12.m1.1.1.2.2.2.2.3" xref="alg1.l12.m1.1.1.2.2.2.2.3.cmml"><mi id="alg1.l12.m1.1.1.2.2.2.2.3.2" xref="alg1.l12.m1.1.1.2.2.2.2.3.2.cmml">i</mi><mo id="alg1.l12.m1.1.1.2.2.2.2.3.1" xref="alg1.l12.m1.1.1.2.2.2.2.3.1.cmml">=</mo><mn id="alg1.l12.m1.1.1.2.2.2.2.3.3" xref="alg1.l12.m1.1.1.2.2.2.2.3.3.cmml">1</mn></mrow><mi id="alg1.l12.m1.1.1.2.2.2.3" xref="alg1.l12.m1.1.1.2.2.2.3.cmml">n</mi></msubsup><mo lspace="0em" rspace="0em" id="alg1.l12.m1.1.1.2.2.1" xref="alg1.l12.m1.1.1.2.2.1.cmml">​</mo><msub id="alg1.l12.m1.1.1.2.2.3" xref="alg1.l12.m1.1.1.2.2.3.cmml"><mi id="alg1.l12.m1.1.1.2.2.3.2" xref="alg1.l12.m1.1.1.2.2.3.2.cmml">G</mi><mi id="alg1.l12.m1.1.1.2.2.3.3" xref="alg1.l12.m1.1.1.2.2.3.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="alg1.l12.m1.1.1.2.2.1a" xref="alg1.l12.m1.1.1.2.2.1.cmml">​</mo><msub id="alg1.l12.m1.1.1.2.2.4" xref="alg1.l12.m1.1.1.2.2.4.cmml"><mi id="alg1.l12.m1.1.1.2.2.4.2" xref="alg1.l12.m1.1.1.2.2.4.2.cmml">w</mi><mi id="alg1.l12.m1.1.1.2.2.4.3" xref="alg1.l12.m1.1.1.2.2.4.3.cmml">i</mi></msub></mrow><mo id="alg1.l12.m1.1.1.2.1" xref="alg1.l12.m1.1.1.2.1.cmml">/</mo><msubsup id="alg1.l12.m1.1.1.2.3" xref="alg1.l12.m1.1.1.2.3.cmml"><mi mathvariant="normal" id="alg1.l12.m1.1.1.2.3.2.2" xref="alg1.l12.m1.1.1.2.3.2.2.cmml">Σ</mi><mrow id="alg1.l12.m1.1.1.2.3.2.3" xref="alg1.l12.m1.1.1.2.3.2.3.cmml"><mi id="alg1.l12.m1.1.1.2.3.2.3.2" xref="alg1.l12.m1.1.1.2.3.2.3.2.cmml">i</mi><mo id="alg1.l12.m1.1.1.2.3.2.3.1" xref="alg1.l12.m1.1.1.2.3.2.3.1.cmml">=</mo><mn id="alg1.l12.m1.1.1.2.3.2.3.3" xref="alg1.l12.m1.1.1.2.3.2.3.3.cmml">1</mn></mrow><mi id="alg1.l12.m1.1.1.2.3.3" xref="alg1.l12.m1.1.1.2.3.3.cmml">n</mi></msubsup></mrow><mo lspace="0em" rspace="0em" id="alg1.l12.m1.1.1.1" xref="alg1.l12.m1.1.1.1.cmml">​</mo><msub id="alg1.l12.m1.1.1.3" xref="alg1.l12.m1.1.1.3.cmml"><mi id="alg1.l12.m1.1.1.3.2" xref="alg1.l12.m1.1.1.3.2.cmml">w</mi><mi id="alg1.l12.m1.1.1.3.3" xref="alg1.l12.m1.1.1.3.3.cmml">i</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="alg1.l12.m1.1b"><apply id="alg1.l12.m1.1.1.cmml" xref="alg1.l12.m1.1.1"><times id="alg1.l12.m1.1.1.1.cmml" xref="alg1.l12.m1.1.1.1"></times><apply id="alg1.l12.m1.1.1.2.cmml" xref="alg1.l12.m1.1.1.2"><divide id="alg1.l12.m1.1.1.2.1.cmml" xref="alg1.l12.m1.1.1.2.1"></divide><apply id="alg1.l12.m1.1.1.2.2.cmml" xref="alg1.l12.m1.1.1.2.2"><times id="alg1.l12.m1.1.1.2.2.1.cmml" xref="alg1.l12.m1.1.1.2.2.1"></times><apply id="alg1.l12.m1.1.1.2.2.2.cmml" xref="alg1.l12.m1.1.1.2.2.2"><csymbol cd="ambiguous" id="alg1.l12.m1.1.1.2.2.2.1.cmml" xref="alg1.l12.m1.1.1.2.2.2">superscript</csymbol><apply id="alg1.l12.m1.1.1.2.2.2.2.cmml" xref="alg1.l12.m1.1.1.2.2.2"><csymbol cd="ambiguous" id="alg1.l12.m1.1.1.2.2.2.2.1.cmml" xref="alg1.l12.m1.1.1.2.2.2">subscript</csymbol><ci id="alg1.l12.m1.1.1.2.2.2.2.2.cmml" xref="alg1.l12.m1.1.1.2.2.2.2.2">Σ</ci><apply id="alg1.l12.m1.1.1.2.2.2.2.3.cmml" xref="alg1.l12.m1.1.1.2.2.2.2.3"><eq id="alg1.l12.m1.1.1.2.2.2.2.3.1.cmml" xref="alg1.l12.m1.1.1.2.2.2.2.3.1"></eq><ci id="alg1.l12.m1.1.1.2.2.2.2.3.2.cmml" xref="alg1.l12.m1.1.1.2.2.2.2.3.2">𝑖</ci><cn type="integer" id="alg1.l12.m1.1.1.2.2.2.2.3.3.cmml" xref="alg1.l12.m1.1.1.2.2.2.2.3.3">1</cn></apply></apply><ci id="alg1.l12.m1.1.1.2.2.2.3.cmml" xref="alg1.l12.m1.1.1.2.2.2.3">𝑛</ci></apply><apply id="alg1.l12.m1.1.1.2.2.3.cmml" xref="alg1.l12.m1.1.1.2.2.3"><csymbol cd="ambiguous" id="alg1.l12.m1.1.1.2.2.3.1.cmml" xref="alg1.l12.m1.1.1.2.2.3">subscript</csymbol><ci id="alg1.l12.m1.1.1.2.2.3.2.cmml" xref="alg1.l12.m1.1.1.2.2.3.2">𝐺</ci><ci id="alg1.l12.m1.1.1.2.2.3.3.cmml" xref="alg1.l12.m1.1.1.2.2.3.3">𝑖</ci></apply><apply id="alg1.l12.m1.1.1.2.2.4.cmml" xref="alg1.l12.m1.1.1.2.2.4"><csymbol cd="ambiguous" id="alg1.l12.m1.1.1.2.2.4.1.cmml" xref="alg1.l12.m1.1.1.2.2.4">subscript</csymbol><ci id="alg1.l12.m1.1.1.2.2.4.2.cmml" xref="alg1.l12.m1.1.1.2.2.4.2">𝑤</ci><ci id="alg1.l12.m1.1.1.2.2.4.3.cmml" xref="alg1.l12.m1.1.1.2.2.4.3">𝑖</ci></apply></apply><apply id="alg1.l12.m1.1.1.2.3.cmml" xref="alg1.l12.m1.1.1.2.3"><csymbol cd="ambiguous" id="alg1.l12.m1.1.1.2.3.1.cmml" xref="alg1.l12.m1.1.1.2.3">superscript</csymbol><apply id="alg1.l12.m1.1.1.2.3.2.cmml" xref="alg1.l12.m1.1.1.2.3"><csymbol cd="ambiguous" id="alg1.l12.m1.1.1.2.3.2.1.cmml" xref="alg1.l12.m1.1.1.2.3">subscript</csymbol><ci id="alg1.l12.m1.1.1.2.3.2.2.cmml" xref="alg1.l12.m1.1.1.2.3.2.2">Σ</ci><apply id="alg1.l12.m1.1.1.2.3.2.3.cmml" xref="alg1.l12.m1.1.1.2.3.2.3"><eq id="alg1.l12.m1.1.1.2.3.2.3.1.cmml" xref="alg1.l12.m1.1.1.2.3.2.3.1"></eq><ci id="alg1.l12.m1.1.1.2.3.2.3.2.cmml" xref="alg1.l12.m1.1.1.2.3.2.3.2">𝑖</ci><cn type="integer" id="alg1.l12.m1.1.1.2.3.2.3.3.cmml" xref="alg1.l12.m1.1.1.2.3.2.3.3">1</cn></apply></apply><ci id="alg1.l12.m1.1.1.2.3.3.cmml" xref="alg1.l12.m1.1.1.2.3.3">𝑛</ci></apply></apply><apply id="alg1.l12.m1.1.1.3.cmml" xref="alg1.l12.m1.1.1.3"><csymbol cd="ambiguous" id="alg1.l12.m1.1.1.3.1.cmml" xref="alg1.l12.m1.1.1.3">subscript</csymbol><ci id="alg1.l12.m1.1.1.3.2.cmml" xref="alg1.l12.m1.1.1.3.2">𝑤</ci><ci id="alg1.l12.m1.1.1.3.3.cmml" xref="alg1.l12.m1.1.1.3.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l12.m1.1c">\Sigma_{i=1}^{n}{G_{i}}{w_{i}}/\Sigma_{i=1}^{n}{w_{i}}</annotation></semantics></math>

</div>
<div id="alg1.l13" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l13.1.1.1" class="ltx_text" style="font-size:80%;">13:</span></span><span id="alg1.l13.2" class="ltx_text ltx_font_bold">end</span> <span id="alg1.l13.3" class="ltx_text ltx_font_bold">for</span>
</div>
</div>
</figure>
<div id="S3.p7" class="ltx_para">
<p id="S3.p7.9" class="ltx_p">The key of WCA is how to design the weights <math id="S3.p7.1.m1.1" class="ltx_Math" alttext="w_{i}" display="inline"><semantics id="S3.p7.1.m1.1a"><msub id="S3.p7.1.m1.1.1" xref="S3.p7.1.m1.1.1.cmml"><mi id="S3.p7.1.m1.1.1.2" xref="S3.p7.1.m1.1.1.2.cmml">w</mi><mi id="S3.p7.1.m1.1.1.3" xref="S3.p7.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p7.1.m1.1b"><apply id="S3.p7.1.m1.1.1.cmml" xref="S3.p7.1.m1.1.1"><csymbol cd="ambiguous" id="S3.p7.1.m1.1.1.1.cmml" xref="S3.p7.1.m1.1.1">subscript</csymbol><ci id="S3.p7.1.m1.1.1.2.cmml" xref="S3.p7.1.m1.1.1.2">𝑤</ci><ci id="S3.p7.1.m1.1.1.3.cmml" xref="S3.p7.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p7.1.m1.1c">w_{i}</annotation></semantics></math>.
Because user-correction pattern may be different from the training data, we need to make the best of the corrections.
For example, if the correction from “pie torch” to “pytorch” is rare, we need to assign higher weight to it. Otherwise the gradient contribution of the example will be submerged in the aggregated gradients and vanish in the learned model.
To this end, we propose two methods (1) frequency based weights and (2) frequency and accuracy based weights. Given the set of corrected words <math id="S3.p7.2.m2.1" class="ltx_Math" alttext="\mathbb{W}" display="inline"><semantics id="S3.p7.2.m2.1a"><mi id="S3.p7.2.m2.1.1" xref="S3.p7.2.m2.1.1.cmml">𝕎</mi><annotation-xml encoding="MathML-Content" id="S3.p7.2.m2.1b"><ci id="S3.p7.2.m2.1.1.cmml" xref="S3.p7.2.m2.1.1">𝕎</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p7.2.m2.1c">\mathbb{W}</annotation></semantics></math>, the <span id="S3.p7.9.1" class="ltx_text ltx_font_bold">frequency based weights</span> compute the frequency of each word in <math id="S3.p7.3.m3.1" class="ltx_Math" alttext="\mathbb{W}" display="inline"><semantics id="S3.p7.3.m3.1a"><mi id="S3.p7.3.m3.1.1" xref="S3.p7.3.m3.1.1.cmml">𝕎</mi><annotation-xml encoding="MathML-Content" id="S3.p7.3.m3.1b"><ci id="S3.p7.3.m3.1.1.cmml" xref="S3.p7.3.m3.1.1">𝕎</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p7.3.m3.1c">\mathbb{W}</annotation></semantics></math> among all clients. Such frequency can be derived by computing the differentially private histogram <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> of words on the client pool, i.e. <math id="S3.p7.4.m4.1" class="ltx_Math" alttext="\mathbf{freq}_{w}" display="inline"><semantics id="S3.p7.4.m4.1a"><msub id="S3.p7.4.m4.1.1" xref="S3.p7.4.m4.1.1.cmml"><mi id="S3.p7.4.m4.1.1.2" xref="S3.p7.4.m4.1.1.2.cmml">𝐟𝐫𝐞𝐪</mi><mi id="S3.p7.4.m4.1.1.3" xref="S3.p7.4.m4.1.1.3.cmml">w</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p7.4.m4.1b"><apply id="S3.p7.4.m4.1.1.cmml" xref="S3.p7.4.m4.1.1"><csymbol cd="ambiguous" id="S3.p7.4.m4.1.1.1.cmml" xref="S3.p7.4.m4.1.1">subscript</csymbol><ci id="S3.p7.4.m4.1.1.2.cmml" xref="S3.p7.4.m4.1.1.2">𝐟𝐫𝐞𝐪</ci><ci id="S3.p7.4.m4.1.1.3.cmml" xref="S3.p7.4.m4.1.1.3">𝑤</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p7.4.m4.1c">\mathbf{freq}_{w}</annotation></semantics></math> is the differentially private frequency of word <math id="S3.p7.5.m5.1" class="ltx_Math" alttext="w" display="inline"><semantics id="S3.p7.5.m5.1a"><mi id="S3.p7.5.m5.1.1" xref="S3.p7.5.m5.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="S3.p7.5.m5.1b"><ci id="S3.p7.5.m5.1.1.cmml" xref="S3.p7.5.m5.1.1">𝑤</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p7.5.m5.1c">w</annotation></semantics></math>. Then for each word <math id="S3.p7.6.m6.1" class="ltx_Math" alttext="w" display="inline"><semantics id="S3.p7.6.m6.1a"><mi id="S3.p7.6.m6.1.1" xref="S3.p7.6.m6.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="S3.p7.6.m6.1b"><ci id="S3.p7.6.m6.1.1.cmml" xref="S3.p7.6.m6.1.1">𝑤</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p7.6.m6.1c">w</annotation></semantics></math> in the example <math id="S3.p7.7.m7.1" class="ltx_Math" alttext="j" display="inline"><semantics id="S3.p7.7.m7.1a"><mi id="S3.p7.7.m7.1.1" xref="S3.p7.7.m7.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S3.p7.7.m7.1b"><ci id="S3.p7.7.m7.1.1.cmml" xref="S3.p7.7.m7.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p7.7.m7.1c">j</annotation></semantics></math> containing the corrected transcript of client <math id="S3.p7.8.m8.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.p7.8.m8.1a"><mi id="S3.p7.8.m8.1.1" xref="S3.p7.8.m8.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.p7.8.m8.1b"><ci id="S3.p7.8.m8.1.1.cmml" xref="S3.p7.8.m8.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p7.8.m8.1c">i</annotation></semantics></math> at line <a href="#alg1.l7" title="In Algorithm 1 ‣ 3 Model Quality ‣ Federated Learning of Large ASR Models in the Real World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> in Algorithm <a href="#alg1" title="Algorithm 1 ‣ 3 Model Quality ‣ Federated Learning of Large ASR Models in the Real World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, the <math id="S3.p7.9.m9.1" class="ltx_Math" alttext="w_{ij}" display="inline"><semantics id="S3.p7.9.m9.1a"><msub id="S3.p7.9.m9.1.1" xref="S3.p7.9.m9.1.1.cmml"><mi id="S3.p7.9.m9.1.1.2" xref="S3.p7.9.m9.1.1.2.cmml">w</mi><mrow id="S3.p7.9.m9.1.1.3" xref="S3.p7.9.m9.1.1.3.cmml"><mi id="S3.p7.9.m9.1.1.3.2" xref="S3.p7.9.m9.1.1.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.p7.9.m9.1.1.3.1" xref="S3.p7.9.m9.1.1.3.1.cmml">​</mo><mi id="S3.p7.9.m9.1.1.3.3" xref="S3.p7.9.m9.1.1.3.3.cmml">j</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.p7.9.m9.1b"><apply id="S3.p7.9.m9.1.1.cmml" xref="S3.p7.9.m9.1.1"><csymbol cd="ambiguous" id="S3.p7.9.m9.1.1.1.cmml" xref="S3.p7.9.m9.1.1">subscript</csymbol><ci id="S3.p7.9.m9.1.1.2.cmml" xref="S3.p7.9.m9.1.1.2">𝑤</ci><apply id="S3.p7.9.m9.1.1.3.cmml" xref="S3.p7.9.m9.1.1.3"><times id="S3.p7.9.m9.1.1.3.1.cmml" xref="S3.p7.9.m9.1.1.3.1"></times><ci id="S3.p7.9.m9.1.1.3.2.cmml" xref="S3.p7.9.m9.1.1.3.2">𝑖</ci><ci id="S3.p7.9.m9.1.1.3.3.cmml" xref="S3.p7.9.m9.1.1.3.3">𝑗</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p7.9.m9.1c">w_{ij}</annotation></semantics></math> can be computed as follows.</p>
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.2" class="ltx_Math" alttext="\vspace{-2mm}w_{ij}=\Sigma\cfrac{1}{\mathbf{freq}_{w}},{w}\in\mathbf{correction}_{j}" display="block"><semantics id="S3.E1.m1.2a"><mrow id="S3.E1.m1.2.2.2" xref="S3.E1.m1.2.2.3.cmml"><mrow id="S3.E1.m1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml"><msub id="S3.E1.m1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.2.cmml"><mi id="S3.E1.m1.1.1.1.1.2.2" xref="S3.E1.m1.1.1.1.1.2.2.cmml">w</mi><mrow id="S3.E1.m1.1.1.1.1.2.3" xref="S3.E1.m1.1.1.1.1.2.3.cmml"><mi id="S3.E1.m1.1.1.1.1.2.3.2" xref="S3.E1.m1.1.1.1.1.2.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.1.1.2.3.1" xref="S3.E1.m1.1.1.1.1.2.3.1.cmml">​</mo><mi id="S3.E1.m1.1.1.1.1.2.3.3" xref="S3.E1.m1.1.1.1.1.2.3.3.cmml">j</mi></mrow></msub><mo id="S3.E1.m1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.cmml">=</mo><mrow id="S3.E1.m1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.3.cmml"><mi mathvariant="normal" id="S3.E1.m1.1.1.1.1.3.2" xref="S3.E1.m1.1.1.1.1.3.2.cmml">Σ</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.1.1.3.1" xref="S3.E1.m1.1.1.1.1.3.1.cmml">​</mo><mfrac id="S3.E1.m1.1.1.1.1.3.3" xref="S3.E1.m1.1.1.1.1.3.3.cmml"><mn id="S3.E1.m1.1.1.1.1.3.3.2" xref="S3.E1.m1.1.1.1.1.3.3.2.cmml">1</mn><msub id="S3.E1.m1.1.1.1.1.3.3.3" xref="S3.E1.m1.1.1.1.1.3.3.3.cmml"><mi id="S3.E1.m1.1.1.1.1.3.3.3.2" xref="S3.E1.m1.1.1.1.1.3.3.3.2.cmml">𝐟𝐫𝐞𝐪</mi><mi id="S3.E1.m1.1.1.1.1.3.3.3.3" xref="S3.E1.m1.1.1.1.1.3.3.3.3.cmml">w</mi></msub></mfrac></mrow></mrow><mo id="S3.E1.m1.2.2.2.3" xref="S3.E1.m1.2.2.3a.cmml">,</mo><mrow id="S3.E1.m1.2.2.2.2" xref="S3.E1.m1.2.2.2.2.cmml"><mi id="S3.E1.m1.2.2.2.2.2" xref="S3.E1.m1.2.2.2.2.2.cmml">w</mi><mo id="S3.E1.m1.2.2.2.2.1" xref="S3.E1.m1.2.2.2.2.1.cmml">∈</mo><msub id="S3.E1.m1.2.2.2.2.3" xref="S3.E1.m1.2.2.2.2.3.cmml"><mi id="S3.E1.m1.2.2.2.2.3.2" xref="S3.E1.m1.2.2.2.2.3.2.cmml">𝐜𝐨𝐫𝐫𝐞𝐜𝐭𝐢𝐨𝐧</mi><mi id="S3.E1.m1.2.2.2.2.3.3" xref="S3.E1.m1.2.2.2.2.3.3.cmml">j</mi></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.2b"><apply id="S3.E1.m1.2.2.3.cmml" xref="S3.E1.m1.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.3a.cmml" xref="S3.E1.m1.2.2.2.3">formulae-sequence</csymbol><apply id="S3.E1.m1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1"><eq id="S3.E1.m1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1"></eq><apply id="S3.E1.m1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.2.1.cmml" xref="S3.E1.m1.1.1.1.1.2">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.2.2.cmml" xref="S3.E1.m1.1.1.1.1.2.2">𝑤</ci><apply id="S3.E1.m1.1.1.1.1.2.3.cmml" xref="S3.E1.m1.1.1.1.1.2.3"><times id="S3.E1.m1.1.1.1.1.2.3.1.cmml" xref="S3.E1.m1.1.1.1.1.2.3.1"></times><ci id="S3.E1.m1.1.1.1.1.2.3.2.cmml" xref="S3.E1.m1.1.1.1.1.2.3.2">𝑖</ci><ci id="S3.E1.m1.1.1.1.1.2.3.3.cmml" xref="S3.E1.m1.1.1.1.1.2.3.3">𝑗</ci></apply></apply><apply id="S3.E1.m1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.3"><times id="S3.E1.m1.1.1.1.1.3.1.cmml" xref="S3.E1.m1.1.1.1.1.3.1"></times><ci id="S3.E1.m1.1.1.1.1.3.2.cmml" xref="S3.E1.m1.1.1.1.1.3.2">Σ</ci><apply id="S3.E1.m1.1.1.1.1.3.3.cmml" xref="S3.E1.m1.1.1.1.1.3.3"><csymbol cd="latexml" id="S3.E1.m1.1.1.1.1.3.3.1.cmml" xref="S3.E1.m1.1.1.1.1.3.3">continued-fraction</csymbol><cn type="integer" id="S3.E1.m1.1.1.1.1.3.3.2.cmml" xref="S3.E1.m1.1.1.1.1.3.3.2">1</cn><apply id="S3.E1.m1.1.1.1.1.3.3.3.cmml" xref="S3.E1.m1.1.1.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.3.3.3.1.cmml" xref="S3.E1.m1.1.1.1.1.3.3.3">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.3.3.3.2.cmml" xref="S3.E1.m1.1.1.1.1.3.3.3.2">𝐟𝐫𝐞𝐪</ci><ci id="S3.E1.m1.1.1.1.1.3.3.3.3.cmml" xref="S3.E1.m1.1.1.1.1.3.3.3.3">𝑤</ci></apply></apply></apply></apply><apply id="S3.E1.m1.2.2.2.2.cmml" xref="S3.E1.m1.2.2.2.2"><in id="S3.E1.m1.2.2.2.2.1.cmml" xref="S3.E1.m1.2.2.2.2.1"></in><ci id="S3.E1.m1.2.2.2.2.2.cmml" xref="S3.E1.m1.2.2.2.2.2">𝑤</ci><apply id="S3.E1.m1.2.2.2.2.3.cmml" xref="S3.E1.m1.2.2.2.2.3"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.2.2.3.1.cmml" xref="S3.E1.m1.2.2.2.2.3">subscript</csymbol><ci id="S3.E1.m1.2.2.2.2.3.2.cmml" xref="S3.E1.m1.2.2.2.2.3.2">𝐜𝐨𝐫𝐫𝐞𝐜𝐭𝐢𝐨𝐧</ci><ci id="S3.E1.m1.2.2.2.2.3.3.cmml" xref="S3.E1.m1.2.2.2.2.3.3">𝑗</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.2c">\vspace{-2mm}w_{ij}=\Sigma\cfrac{1}{\mathbf{freq}_{w}},{w}\in\mathbf{correction}_{j}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S3.p7.13" class="ltx_p">In this way, we have higher weights for rare words and less weights for frequent words in <math id="S3.p7.10.m1.1" class="ltx_Math" alttext="\mathbb{W}" display="inline"><semantics id="S3.p7.10.m1.1a"><mi id="S3.p7.10.m1.1.1" xref="S3.p7.10.m1.1.1.cmml">𝕎</mi><annotation-xml encoding="MathML-Content" id="S3.p7.10.m1.1b"><ci id="S3.p7.10.m1.1.1.cmml" xref="S3.p7.10.m1.1.1">𝕎</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p7.10.m1.1c">\mathbb{W}</annotation></semantics></math>. Based on this, the <span id="S3.p7.13.1" class="ltx_text ltx_font_bold">frequency and accuracy based weights</span> also incorporate the word accuracy of the incumbent ASR model that generates the transcripts in the first place. The accuracy <math id="S3.p7.11.m2.2" class="ltx_Math" alttext="\mathbf{acc}_{w}\in[0,1]" display="inline"><semantics id="S3.p7.11.m2.2a"><mrow id="S3.p7.11.m2.2.3" xref="S3.p7.11.m2.2.3.cmml"><msub id="S3.p7.11.m2.2.3.2" xref="S3.p7.11.m2.2.3.2.cmml"><mi id="S3.p7.11.m2.2.3.2.2" xref="S3.p7.11.m2.2.3.2.2.cmml">𝐚𝐜𝐜</mi><mi id="S3.p7.11.m2.2.3.2.3" xref="S3.p7.11.m2.2.3.2.3.cmml">w</mi></msub><mo id="S3.p7.11.m2.2.3.1" xref="S3.p7.11.m2.2.3.1.cmml">∈</mo><mrow id="S3.p7.11.m2.2.3.3.2" xref="S3.p7.11.m2.2.3.3.1.cmml"><mo stretchy="false" id="S3.p7.11.m2.2.3.3.2.1" xref="S3.p7.11.m2.2.3.3.1.cmml">[</mo><mn id="S3.p7.11.m2.1.1" xref="S3.p7.11.m2.1.1.cmml">0</mn><mo id="S3.p7.11.m2.2.3.3.2.2" xref="S3.p7.11.m2.2.3.3.1.cmml">,</mo><mn id="S3.p7.11.m2.2.2" xref="S3.p7.11.m2.2.2.cmml">1</mn><mo stretchy="false" id="S3.p7.11.m2.2.3.3.2.3" xref="S3.p7.11.m2.2.3.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p7.11.m2.2b"><apply id="S3.p7.11.m2.2.3.cmml" xref="S3.p7.11.m2.2.3"><in id="S3.p7.11.m2.2.3.1.cmml" xref="S3.p7.11.m2.2.3.1"></in><apply id="S3.p7.11.m2.2.3.2.cmml" xref="S3.p7.11.m2.2.3.2"><csymbol cd="ambiguous" id="S3.p7.11.m2.2.3.2.1.cmml" xref="S3.p7.11.m2.2.3.2">subscript</csymbol><ci id="S3.p7.11.m2.2.3.2.2.cmml" xref="S3.p7.11.m2.2.3.2.2">𝐚𝐜𝐜</ci><ci id="S3.p7.11.m2.2.3.2.3.cmml" xref="S3.p7.11.m2.2.3.2.3">𝑤</ci></apply><interval closure="closed" id="S3.p7.11.m2.2.3.3.1.cmml" xref="S3.p7.11.m2.2.3.3.2"><cn type="integer" id="S3.p7.11.m2.1.1.cmml" xref="S3.p7.11.m2.1.1">0</cn><cn type="integer" id="S3.p7.11.m2.2.2.cmml" xref="S3.p7.11.m2.2.2">1</cn></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p7.11.m2.2c">\mathbf{acc}_{w}\in[0,1]</annotation></semantics></math> denotes how well the incumbent model recognizes a word <math id="S3.p7.12.m3.1" class="ltx_Math" alttext="w" display="inline"><semantics id="S3.p7.12.m3.1a"><mi id="S3.p7.12.m3.1.1" xref="S3.p7.12.m3.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="S3.p7.12.m3.1b"><ci id="S3.p7.12.m3.1.1.cmml" xref="S3.p7.12.m3.1.1">𝑤</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p7.12.m3.1c">w</annotation></semantics></math>. The higher accuracy mean the word is recognized well and lower accuracy means the word is recognized poorly. Then the <math id="S3.p7.13.m4.1" class="ltx_Math" alttext="w_{ij}" display="inline"><semantics id="S3.p7.13.m4.1a"><msub id="S3.p7.13.m4.1.1" xref="S3.p7.13.m4.1.1.cmml"><mi id="S3.p7.13.m4.1.1.2" xref="S3.p7.13.m4.1.1.2.cmml">w</mi><mrow id="S3.p7.13.m4.1.1.3" xref="S3.p7.13.m4.1.1.3.cmml"><mi id="S3.p7.13.m4.1.1.3.2" xref="S3.p7.13.m4.1.1.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.p7.13.m4.1.1.3.1" xref="S3.p7.13.m4.1.1.3.1.cmml">​</mo><mi id="S3.p7.13.m4.1.1.3.3" xref="S3.p7.13.m4.1.1.3.3.cmml">j</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.p7.13.m4.1b"><apply id="S3.p7.13.m4.1.1.cmml" xref="S3.p7.13.m4.1.1"><csymbol cd="ambiguous" id="S3.p7.13.m4.1.1.1.cmml" xref="S3.p7.13.m4.1.1">subscript</csymbol><ci id="S3.p7.13.m4.1.1.2.cmml" xref="S3.p7.13.m4.1.1.2">𝑤</ci><apply id="S3.p7.13.m4.1.1.3.cmml" xref="S3.p7.13.m4.1.1.3"><times id="S3.p7.13.m4.1.1.3.1.cmml" xref="S3.p7.13.m4.1.1.3.1"></times><ci id="S3.p7.13.m4.1.1.3.2.cmml" xref="S3.p7.13.m4.1.1.3.2">𝑖</ci><ci id="S3.p7.13.m4.1.1.3.3.cmml" xref="S3.p7.13.m4.1.1.3.3">𝑗</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p7.13.m4.1c">w_{ij}</annotation></semantics></math> can be computed as Equation <a href="#S3.E2" title="In 3 Model Quality ‣ Federated Learning of Large ASR Models in the Real World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
<table id="S3.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E2.m1.2" class="ltx_Math" alttext="\vspace{-2mm}w_{ij}=\Sigma\cfrac{1-\mathbf{acc}_{w}}{\mathbf{freq}_{w}},{w}\in\mathbf{correction}_{j}" display="block"><semantics id="S3.E2.m1.2a"><mrow id="S3.E2.m1.2.2.2" xref="S3.E2.m1.2.2.3.cmml"><mrow id="S3.E2.m1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.cmml"><msub id="S3.E2.m1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.2.cmml"><mi id="S3.E2.m1.1.1.1.1.2.2" xref="S3.E2.m1.1.1.1.1.2.2.cmml">w</mi><mrow id="S3.E2.m1.1.1.1.1.2.3" xref="S3.E2.m1.1.1.1.1.2.3.cmml"><mi id="S3.E2.m1.1.1.1.1.2.3.2" xref="S3.E2.m1.1.1.1.1.2.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.1.1.1.2.3.1" xref="S3.E2.m1.1.1.1.1.2.3.1.cmml">​</mo><mi id="S3.E2.m1.1.1.1.1.2.3.3" xref="S3.E2.m1.1.1.1.1.2.3.3.cmml">j</mi></mrow></msub><mo id="S3.E2.m1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.cmml">=</mo><mrow id="S3.E2.m1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.3.cmml"><mi mathvariant="normal" id="S3.E2.m1.1.1.1.1.3.2" xref="S3.E2.m1.1.1.1.1.3.2.cmml">Σ</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.1.1.1.3.1" xref="S3.E2.m1.1.1.1.1.3.1.cmml">​</mo><mfrac id="S3.E2.m1.1.1.1.1.3.3" xref="S3.E2.m1.1.1.1.1.3.3.cmml"><mrow id="S3.E2.m1.1.1.1.1.3.3.2" xref="S3.E2.m1.1.1.1.1.3.3.2.cmml"><mn id="S3.E2.m1.1.1.1.1.3.3.2.2" xref="S3.E2.m1.1.1.1.1.3.3.2.2.cmml">1</mn><mo id="S3.E2.m1.1.1.1.1.3.3.2.1" xref="S3.E2.m1.1.1.1.1.3.3.2.1.cmml">−</mo><msub id="S3.E2.m1.1.1.1.1.3.3.2.3" xref="S3.E2.m1.1.1.1.1.3.3.2.3.cmml"><mi id="S3.E2.m1.1.1.1.1.3.3.2.3.2" xref="S3.E2.m1.1.1.1.1.3.3.2.3.2.cmml">𝐚𝐜𝐜</mi><mi id="S3.E2.m1.1.1.1.1.3.3.2.3.3" xref="S3.E2.m1.1.1.1.1.3.3.2.3.3.cmml">w</mi></msub></mrow><msub id="S3.E2.m1.1.1.1.1.3.3.3" xref="S3.E2.m1.1.1.1.1.3.3.3.cmml"><mi id="S3.E2.m1.1.1.1.1.3.3.3.2" xref="S3.E2.m1.1.1.1.1.3.3.3.2.cmml">𝐟𝐫𝐞𝐪</mi><mi id="S3.E2.m1.1.1.1.1.3.3.3.3" xref="S3.E2.m1.1.1.1.1.3.3.3.3.cmml">w</mi></msub></mfrac></mrow></mrow><mo id="S3.E2.m1.2.2.2.3" xref="S3.E2.m1.2.2.3a.cmml">,</mo><mrow id="S3.E2.m1.2.2.2.2" xref="S3.E2.m1.2.2.2.2.cmml"><mi id="S3.E2.m1.2.2.2.2.2" xref="S3.E2.m1.2.2.2.2.2.cmml">w</mi><mo id="S3.E2.m1.2.2.2.2.1" xref="S3.E2.m1.2.2.2.2.1.cmml">∈</mo><msub id="S3.E2.m1.2.2.2.2.3" xref="S3.E2.m1.2.2.2.2.3.cmml"><mi id="S3.E2.m1.2.2.2.2.3.2" xref="S3.E2.m1.2.2.2.2.3.2.cmml">𝐜𝐨𝐫𝐫𝐞𝐜𝐭𝐢𝐨𝐧</mi><mi id="S3.E2.m1.2.2.2.2.3.3" xref="S3.E2.m1.2.2.2.2.3.3.cmml">j</mi></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.2b"><apply id="S3.E2.m1.2.2.3.cmml" xref="S3.E2.m1.2.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.3a.cmml" xref="S3.E2.m1.2.2.2.3">formulae-sequence</csymbol><apply id="S3.E2.m1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1"><eq id="S3.E2.m1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1"></eq><apply id="S3.E2.m1.1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.2.1.cmml" xref="S3.E2.m1.1.1.1.1.2">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.2.2.cmml" xref="S3.E2.m1.1.1.1.1.2.2">𝑤</ci><apply id="S3.E2.m1.1.1.1.1.2.3.cmml" xref="S3.E2.m1.1.1.1.1.2.3"><times id="S3.E2.m1.1.1.1.1.2.3.1.cmml" xref="S3.E2.m1.1.1.1.1.2.3.1"></times><ci id="S3.E2.m1.1.1.1.1.2.3.2.cmml" xref="S3.E2.m1.1.1.1.1.2.3.2">𝑖</ci><ci id="S3.E2.m1.1.1.1.1.2.3.3.cmml" xref="S3.E2.m1.1.1.1.1.2.3.3">𝑗</ci></apply></apply><apply id="S3.E2.m1.1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.1.3"><times id="S3.E2.m1.1.1.1.1.3.1.cmml" xref="S3.E2.m1.1.1.1.1.3.1"></times><ci id="S3.E2.m1.1.1.1.1.3.2.cmml" xref="S3.E2.m1.1.1.1.1.3.2">Σ</ci><apply id="S3.E2.m1.1.1.1.1.3.3.cmml" xref="S3.E2.m1.1.1.1.1.3.3"><csymbol cd="latexml" id="S3.E2.m1.1.1.1.1.3.3.1.cmml" xref="S3.E2.m1.1.1.1.1.3.3">continued-fraction</csymbol><apply id="S3.E2.m1.1.1.1.1.3.3.2.cmml" xref="S3.E2.m1.1.1.1.1.3.3.2"><minus id="S3.E2.m1.1.1.1.1.3.3.2.1.cmml" xref="S3.E2.m1.1.1.1.1.3.3.2.1"></minus><cn type="integer" id="S3.E2.m1.1.1.1.1.3.3.2.2.cmml" xref="S3.E2.m1.1.1.1.1.3.3.2.2">1</cn><apply id="S3.E2.m1.1.1.1.1.3.3.2.3.cmml" xref="S3.E2.m1.1.1.1.1.3.3.2.3"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.3.3.2.3.1.cmml" xref="S3.E2.m1.1.1.1.1.3.3.2.3">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.3.3.2.3.2.cmml" xref="S3.E2.m1.1.1.1.1.3.3.2.3.2">𝐚𝐜𝐜</ci><ci id="S3.E2.m1.1.1.1.1.3.3.2.3.3.cmml" xref="S3.E2.m1.1.1.1.1.3.3.2.3.3">𝑤</ci></apply></apply><apply id="S3.E2.m1.1.1.1.1.3.3.3.cmml" xref="S3.E2.m1.1.1.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.3.3.3.1.cmml" xref="S3.E2.m1.1.1.1.1.3.3.3">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.3.3.3.2.cmml" xref="S3.E2.m1.1.1.1.1.3.3.3.2">𝐟𝐫𝐞𝐪</ci><ci id="S3.E2.m1.1.1.1.1.3.3.3.3.cmml" xref="S3.E2.m1.1.1.1.1.3.3.3.3">𝑤</ci></apply></apply></apply></apply><apply id="S3.E2.m1.2.2.2.2.cmml" xref="S3.E2.m1.2.2.2.2"><in id="S3.E2.m1.2.2.2.2.1.cmml" xref="S3.E2.m1.2.2.2.2.1"></in><ci id="S3.E2.m1.2.2.2.2.2.cmml" xref="S3.E2.m1.2.2.2.2.2">𝑤</ci><apply id="S3.E2.m1.2.2.2.2.3.cmml" xref="S3.E2.m1.2.2.2.2.3"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.2.2.3.1.cmml" xref="S3.E2.m1.2.2.2.2.3">subscript</csymbol><ci id="S3.E2.m1.2.2.2.2.3.2.cmml" xref="S3.E2.m1.2.2.2.2.3.2">𝐜𝐨𝐫𝐫𝐞𝐜𝐭𝐢𝐨𝐧</ci><ci id="S3.E2.m1.2.2.2.2.3.3.cmml" xref="S3.E2.m1.2.2.2.2.3.3">𝑗</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.2c">\vspace{-2mm}w_{ij}=\Sigma\cfrac{1-\mathbf{acc}_{w}}{\mathbf{freq}_{w}},{w}\in\mathbf{correction}_{j}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experimental Results</h2>

<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Experiment Settings</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p"><span id="S4.SS1.p1.1.1" class="ltx_text ltx_font_bold">Training settings.</span> We prepare a centrally pre-trained model at the server to warm start the FL training. The initial model was trained on a multi-domain datasets collected from domains of YouTube, farfield and telephony etc <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>. All datasets are anonymized and our work abides by Google AI Principles <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>. Our batch size is 2 and report goal is 128. All experiments were conducted on the real-world FL with users’ smartphones including Google Pixel phones.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p"><span id="S4.SS1.p2.1.1" class="ltx_text ltx_font_bold">Model Architecture.</span> Because our objective is to train the large ASR models, we chose the production-grade Conformer <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> model that has about 130M parameters. The model consists of a causal encoder for streaming case and another non-causal encoder for non-streaming case. We only train the causal encoder and the decoder for the streaming cases, although our method can be easily extended to the non-causal encoders.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p id="S4.SS1.p3.3" class="ltx_p"><span id="S4.SS1.p3.3.1" class="ltx_text ltx_font_bold">Metrics.</span> To evaluate the FL training efficiency, we measure the metrics of transportation size between server and client, and the averaged clients peak memory usage. For the model quality, we use two WERs: (1) the “general WER” refers to the WER on all evaluation datasets; and (2) “target WER” refers to the WER on the utterances containing only the corrected data in <math id="S4.SS1.p3.1.m1.1" class="ltx_Math" alttext="\mathbb{W}" display="inline"><semantics id="S4.SS1.p3.1.m1.1a"><mi id="S4.SS1.p3.1.m1.1.1" xref="S4.SS1.p3.1.m1.1.1.cmml">𝕎</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.1.m1.1b"><ci id="S4.SS1.p3.1.m1.1.1.cmml" xref="S4.SS1.p3.1.m1.1.1">𝕎</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.1.m1.1c">\mathbb{W}</annotation></semantics></math>. Because the objective is to improve the quality on the correction dataset, we mainly focus on the “target WER” while maintaining the general WER at the same level. The baseline WERs from the pre-trained model is “general WER” <span id="S4.SS1.p3.3.2" class="ltx_text ltx_markedasmath ltx_font_bold">4.4</span> and “target WER” <span id="S4.SS1.p3.3.3" class="ltx_text ltx_markedasmath ltx_font_bold">17.5</span>.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Training Efficiency</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">We first report the training efficiency metrics, which essentially are the bottleneck for training large ASR models in FL.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p"><span id="S4.SS2.p2.1.1" class="ltx_text ltx_font_bold">OMC.</span> To evaluate the benefit of OMC method, we performed experiments on a 6-layer encoder Conformer model (under a 250MB download size constraint) to compare the metrics with and without OMC. Table <a href="#S4.T1" title="Table 1 ‣ 4.2 Training Efficiency ‣ 4 Experimental Results ‣ Federated Learning of Large ASR Models in the Real World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> shows the result. The OMC method reduces the download and upload size by 40MB and 25MB. The peak memory usage is also reduced by about 150MB. Note that the transportation compression methods <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> are applied by default, and hence the transportation size is smaller than parameter memory size.</p>
</div>
<figure id="S4.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S4.T1.2.1.1" class="ltx_text ltx_font_bold">Table 1</span>: </span>Training efficiency vs OMC</figcaption>
<div id="S4.T1.3" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:229.4pt;height:54pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1.0,1.0) ;">
<table id="S4.T1.3.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T1.3.1.1.1" class="ltx_tr">
<th id="S4.T1.3.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt"><span id="S4.T1.3.1.1.1.1.1" class="ltx_text ltx_font_bold">Training setup</span></th>
<th id="S4.T1.3.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T1.3.1.1.1.2.1" class="ltx_text ltx_font_bold">Download</span></th>
<th id="S4.T1.3.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T1.3.1.1.1.3.1" class="ltx_text ltx_font_bold">Upload</span></th>
<th id="S4.T1.3.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T1.3.1.1.1.4.1" class="ltx_text ltx_font_bold">Memory</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T1.3.1.2.1" class="ltx_tr">
<th id="S4.T1.3.1.2.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">No OMC</th>
<td id="S4.T1.3.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t">131MB</td>
<td id="S4.T1.3.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t">31MB</td>
<td id="S4.T1.3.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t">965MB</td>
</tr>
<tr id="S4.T1.3.1.3.2" class="ltx_tr">
<th id="S4.T1.3.1.3.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r">with OMC</th>
<td id="S4.T1.3.1.3.2.2" class="ltx_td ltx_align_center ltx_border_bb">91MB</td>
<td id="S4.T1.3.1.3.2.3" class="ltx_td ltx_align_center ltx_border_bb">6MB</td>
<td id="S4.T1.3.1.3.2.4" class="ltx_td ltx_align_center ltx_border_bb">819MB</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.1" class="ltx_p"><span id="S4.SS2.p3.1.1" class="ltx_text ltx_font_bold">Partial model training.</span> Next we report the evaluation of partial model training in Table <a href="#S4.T2" title="Table 2 ‣ 4.2 Training Efficiency ‣ 4 Experimental Results ‣ Federated Learning of Large ASR Models in the Real World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. The upload size is reduced because only the gradients of trainable variables are uploaded. The peak memory usage is also reduced because the non-trainable layers are frozen without gradient computation. Because float16-OMC method is applied by default, partial model training actually increases the download size because the trainable parameters are extended to float32 precision.</p>
</div>
<figure id="S4.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S4.T2.2.1.1" class="ltx_text ltx_font_bold">Table 2</span>: </span>Training efficiency vs partial model training</figcaption>
<div id="S4.T2.3" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:229.4pt;height:72pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1.0,1.0) ;">
<table id="S4.T2.3.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T2.3.1.1.1" class="ltx_tr">
<th id="S4.T2.3.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt"><span id="S4.T2.3.1.1.1.1.1" class="ltx_text ltx_font_bold">Training setup</span></th>
<th id="S4.T2.3.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T2.3.1.1.1.2.1" class="ltx_text ltx_font_bold">Download</span></th>
<th id="S4.T2.3.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T2.3.1.1.1.3.1" class="ltx_text ltx_font_bold">Upload</span></th>
<th id="S4.T2.3.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T2.3.1.1.1.4.1" class="ltx_text ltx_font_bold">Memory</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T2.3.1.2.1" class="ltx_tr">
<th id="S4.T2.3.1.2.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">Full model</th>
<td id="S4.T2.3.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t">200MB</td>
<td id="S4.T2.3.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t">72MB</td>
<td id="S4.T2.3.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t">1.34GB</td>
</tr>
<tr id="S4.T2.3.1.3.2" class="ltx_tr">
<th id="S4.T2.3.1.3.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Dec + 1L Enc</th>
<td id="S4.T2.3.1.3.2.2" class="ltx_td ltx_align_center">231MB</td>
<td id="S4.T2.3.1.3.2.3" class="ltx_td ltx_align_center">29MB</td>
<td id="S4.T2.3.1.3.2.4" class="ltx_td ltx_align_center">727MB</td>
</tr>
<tr id="S4.T2.3.1.4.3" class="ltx_tr">
<th id="S4.T2.3.1.4.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r">Decoder only</th>
<td id="S4.T2.3.1.4.3.2" class="ltx_td ltx_align_center ltx_border_bb">247MB</td>
<td id="S4.T2.3.1.4.3.3" class="ltx_td ltx_align_center ltx_border_bb">16MB</td>
<td id="S4.T2.3.1.4.3.4" class="ltx_td ltx_align_center ltx_border_bb">677MB</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Model Quality</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">We report the quality of the trained model in this section. The model was trained with both OMC and partial model training methods. Specifically we train the top-1 encoder layer and decoder with the bottom encoder layers being frozen as non-trainable variables. The ablation studies w.r.t. OMC and partial model training were also conducted with no significant findings, i.e. float16-OMC is close to the float32 precision; and more trainable variables improve the model quality. Hence we skip the report of ablation studies.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.1" class="ltx_p"><span id="S4.SS3.p2.1.1" class="ltx_text ltx_font_bold">WER improvement.</span> The results are summarized in Table <a href="#S4.T3" title="Table 3 ‣ 4.3 Model Quality ‣ 4 Experimental Results ‣ Federated Learning of Large ASR Models in the Real World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> where each row adds a new method to the above row. The initial FL had general WER 4.4 and target WER 17.2. When the client selection method was added, the quality is not improved because clients might use unrelated examples. Thus we add the data filtering method to specify the training examples, and achieved general WER 4.4 and target WER 16.9. Next we added the two WCA methods, and the frequency and accuracy based WCA obtained the best result of general WER 4.4 and target WER 14.9.</p>
</div>
<figure id="S4.T3" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S4.T3.2.1.1" class="ltx_text ltx_font_bold">Table 3</span>: </span>WER of trained models</figcaption>
<div id="S4.T3.3" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:258.1pt;height:108pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1.0,1.0) ;">
<table id="S4.T3.3.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T3.3.1.1.1" class="ltx_tr">
<th id="S4.T3.3.1.1.1.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt"></th>
<th id="S4.T3.3.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T3.3.1.1.1.2.1" class="ltx_text ltx_font_bold">General WER</span></th>
<th id="S4.T3.3.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T3.3.1.1.1.3.1" class="ltx_text ltx_font_bold">Target WER</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T3.3.1.2.1" class="ltx_tr">
<th id="S4.T3.3.1.2.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">initial FL</th>
<td id="S4.T3.3.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t">4.4</td>
<td id="S4.T3.3.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t">17.2</td>
</tr>
<tr id="S4.T3.3.1.3.2" class="ltx_tr">
<th id="S4.T3.3.1.3.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">+ client selection</th>
<td id="S4.T3.3.1.3.2.2" class="ltx_td ltx_align_center">4.5</td>
<td id="S4.T3.3.1.3.2.3" class="ltx_td ltx_align_center">17.2</td>
</tr>
<tr id="S4.T3.3.1.4.3" class="ltx_tr">
<th id="S4.T3.3.1.4.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">+ data filtering</th>
<td id="S4.T3.3.1.4.3.2" class="ltx_td ltx_align_center">4.4</td>
<td id="S4.T3.3.1.4.3.3" class="ltx_td ltx_align_center">16.9</td>
</tr>
<tr id="S4.T3.3.1.5.4" class="ltx_tr">
<th id="S4.T3.3.1.5.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">+ frequency WCA</th>
<td id="S4.T3.3.1.5.4.2" class="ltx_td ltx_align_center">4.4</td>
<td id="S4.T3.3.1.5.4.3" class="ltx_td ltx_align_center">16.4</td>
</tr>
<tr id="S4.T3.3.1.6.5" class="ltx_tr">
<th id="S4.T3.3.1.6.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r">+ freq-accuracy WCA</th>
<td id="S4.T3.3.1.6.5.2" class="ltx_td ltx_align_center ltx_border_bb">4.4</td>
<td id="S4.T3.3.1.6.5.3" class="ltx_td ltx_align_center ltx_border_bb">14.9</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<figure id="S4.F2" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F2.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2408.10443/assets/figures/wer_general.png" id="S4.F2.sf1.g1" class="ltx_graphics ltx_img_landscape" width="281" height="174" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F2.sf1.2.1.1" class="ltx_text" style="font-size:80%;">(a)</span> </span><span id="S4.F2.sf1.3.2" class="ltx_text" style="font-size:80%;">General WER along FL rounds</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F2.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2408.10443/assets/figures/wer_target.png" id="S4.F2.sf2.g1" class="ltx_graphics ltx_img_landscape" width="281" height="174" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F2.sf2.2.1.1" class="ltx_text" style="font-size:80%;">(b)</span> </span><span id="S4.F2.sf2.3.2" class="ltx_text" style="font-size:80%;">Target WER along FL rounds</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F2.2.1.1" class="ltx_text ltx_font_bold">Fig. 2</span>: </span>WER trade-off between general WER and target wER.</figcaption>
</figure>
<div id="S4.SS3.p3" class="ltx_para">
<p id="S4.SS3.p3.1" class="ltx_p"><span id="S4.SS3.p3.1.1" class="ltx_text ltx_font_bold">WER trade-off.</span> Because our objective is to improve the target WER, we need to consider the WER trade-off between the general WER and target WER. Figure <a href="#S4.F2" title="Figure 2 ‣ 4.3 Model Quality ‣ 4 Experimental Results ‣ Federated Learning of Large ASR Models in the Real World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> shows the convergence curves of the two WCA methods. We can see that in Figure <a href="#S4.F2.sf1" title="In Figure 2 ‣ 4.3 Model Quality ‣ 4 Experimental Results ‣ Federated Learning of Large ASR Models in the Real World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2(a)</span></a> the general WER started to deteriorate after a FL round while the target WER keeps getting better in Figure <a href="#S4.F2.sf2" title="In Figure 2 ‣ 4.3 Model Quality ‣ 4 Experimental Results ‣ Federated Learning of Large ASR Models in the Real World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2(b)</span></a>. To balance the two WERs, we keep the general WER under the same level of 4.4 and take the corresponding target WER. Advanced trade-off can be designed in future works to further improve the performance.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusions</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this paper we reported the first real-world FL application to train the Conformer model of about 130 million parameters. And we proposed new algorithms to improve the FL model quality by utilizing the user corrections on devices. At last we demonstrated the performance of the FL system in real-world applications to verify that both the training efficiency and the model quality were improved.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock"><span id="bib.bib1.1.1" class="ltx_text" style="font-size:90%;">
H. Brendan McMahan, Eider Moore, Daniel Ramage, and Blaise Agüera y Arcas,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.2.1" class="ltx_text" style="font-size:90%;">“Federated learning of deep networks using model averaging,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">CoRR</span><span id="bib.bib1.4.2" class="ltx_text" style="font-size:90%;">, vol. abs/1602.05629, 2016.
</span>
</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock"><span id="bib.bib2.1.1" class="ltx_text" style="font-size:90%;">
Dhruv Guliani, Françoise Beaufays, and Giovanni Motta,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.2.1" class="ltx_text" style="font-size:90%;">“Training speech recognition models with federated learning: A quality/cost framework,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib2.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</span><span id="bib.bib2.5.3" class="ltx_text" style="font-size:90%;">. IEEE, 2021, pp. 3080–3084.
</span>
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock"><span id="bib.bib3.1.1" class="ltx_text" style="font-size:90%;">
Sean Augenstein, Andrew Hard, Kurt Partridge, and Rajiv Mathews,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.2.1" class="ltx_text" style="font-size:90%;">“Jointly learning from decentralized (federated) and centralized data to mitigate distribution shift,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">CoRR</span><span id="bib.bib3.4.2" class="ltx_text" style="font-size:90%;">, vol. abs/2111.12150, 2021.
</span>
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock"><span id="bib.bib4.1.1" class="ltx_text" style="font-size:90%;">
Yiheng Liu, Tianle Han, Siyuan Ma, Jiayue Zhang, Yuanyuan Yang, Jiaming Tian, Hao He, Antong Li, Mengshen He, Zhengliang Liu, Zihao Wu, Dajiang Zhu, Xiang Li, Ning Qiang, Dingang Shen, Tianming Liu, and Bao Ge,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.2.1" class="ltx_text" style="font-size:90%;">“Summary of chatgpt/gpt-4 research and perspective towards the future of large language models,” 2023.
</span>
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock"><span id="bib.bib5.1.1" class="ltx_text" style="font-size:90%;">
Rohan Anil et al,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.2.1" class="ltx_text" style="font-size:90%;">“Palm 2 technical report,” 2023.
</span>
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock"><span id="bib.bib6.1.1" class="ltx_text" style="font-size:90%;">
Dong Wang, Xiaodong Wang, and Shaohe Lv,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.2.1" class="ltx_text" style="font-size:90%;">“An overview of end-to-end automatic speech recognition,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Symmetry</span><span id="bib.bib6.4.2" class="ltx_text" style="font-size:90%;">, vol. 11, no. 8, pp. 1018, 2019.
</span>
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock"><span id="bib.bib7.1.1" class="ltx_text" style="font-size:90%;">
Bo Li, Anmol Gulati, Jiahui Yu, Tara N. Sainath, Chung-Cheng Chiu, Arun Narayanan, Shuo-Yiin Chang, Ruoming Pang, Yanzhang He, James Qin, Wei Han, Qiao Liang, Yu Zhang, Trevor Strohman, and Yonghui Wu,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.2.1" class="ltx_text" style="font-size:90%;">“A Better and Faster end-to-end Model for Streaming ASR,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">2021 ICASSP</span><span id="bib.bib7.4.2" class="ltx_text" style="font-size:90%;">, pp. 5634–5638.
</span>
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock"><span id="bib.bib8.1.1" class="ltx_text" style="font-size:90%;">
Anmol Gulati, James Qin, Chung-Cheng Chiu, Niki Parmar, Yu Zhang, Jiahui Yu, Wei Han, Shibo Wang, Zhengdong Zhang, Yonghui Wu, et al.,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.2.1" class="ltx_text" style="font-size:90%;">“Conformer: Convolution-augmented transformer for speech recognition,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2005.08100</span><span id="bib.bib8.4.2" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock"><span id="bib.bib9.1.1" class="ltx_text" style="font-size:90%;">
Arun Narayanan, Rohit Prabhavalkar, Chung-Cheng Chiu, David Rybach, Tara N. Sainath, and Trevor Strohman,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.2.1" class="ltx_text" style="font-size:90%;">“Recognizing Long-Form Speech Using Streaming End-to-End Models,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">2019 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)</span><span id="bib.bib9.4.2" class="ltx_text" style="font-size:90%;">, pp. 920–927, 2019.
</span>
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text" style="font-size:90%;">
Khe Chai Sim, Françoise Beaufays, Arnaud Benard, Dhruv Guliani, Andreas Kabel, Nikhil Khare, Tamar Lucassen, Petr Zadrazil, Harry Zhang, Leif Johnson, Giovanni Motta, and Lillian Zhou,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.2.1" class="ltx_text" style="font-size:90%;">“Personalization of end-to-end speech recognition on mobile devices for named entities,” 2019.
</span>
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text" style="font-size:90%;">
Shaojin Ding, Weiran Wang, Ding Zhao, Tara N. Sainath, Yanzhang He, Robert David, Rami Botros, Xin Wang, Rina Panigrahy, Qiao Liang, Dongseong Hwang, Ian McGraw, Rohit Prabhavalkar, and Trevor Strohman,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.2.1" class="ltx_text" style="font-size:90%;">“A unified cascaded encoder ASR model for dynamic model sizes,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib11.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Interspeech 2022, 23rd Annual Conference of the International Speech Communication Association, Incheon, Korea, 18-22 September 2022</span><span id="bib.bib11.5.3" class="ltx_text" style="font-size:90%;">, Hanseok Ko and John H. L. Hansen, Eds. 2022, pp. 1706–1710, ISCA.
</span>
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock"><span id="bib.bib12.1.1" class="ltx_text" style="font-size:90%;">
Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.2.1" class="ltx_text" style="font-size:90%;">“Dropout: A simple way to prevent neural networks from overfitting,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Journal of Machine Learning Research</span><span id="bib.bib12.4.2" class="ltx_text" style="font-size:90%;">, vol. 15, no. 56, pp. 1929–1958, 2014.
</span>
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text" style="font-size:90%;">
Tianqi Chen, Bing Xu, Chiyuan Zhang, and Carlos Guestrin,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.2.1" class="ltx_text" style="font-size:90%;">“Training deep nets with sublinear memory cost,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">CoRR</span><span id="bib.bib13.4.2" class="ltx_text" style="font-size:90%;">, vol. abs/1604.06174, 2016.
</span>
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock"><span id="bib.bib14.1.1" class="ltx_text" style="font-size:90%;">
Shaojin Ding, Phoenix Meadowlark, Yanzhang He, Lukasz Lew, Shivani Agrawal, and Oleg Rybakov,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.2.1" class="ltx_text" style="font-size:90%;">“4-bit conformer with native quantization aware training for speech recognition,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2203.15952</span><span id="bib.bib14.4.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock"><span id="bib.bib15.1.1" class="ltx_text" style="font-size:90%;">
Kai Zhen, Martin Radfar, Hieu Nguyen, Grant P Strimel, Nathan Susanj, and Athanasios Mouchtaris,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.2.1" class="ltx_text" style="font-size:90%;">“Sub-8-bit quantization for on-device speech recognition: a regularization-free approach,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib15.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2022 IEEE Spoken Language Technology Workshop (SLT)</span><span id="bib.bib15.5.3" class="ltx_text" style="font-size:90%;">. IEEE, 2023, pp. 15–22.
</span>
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock"><span id="bib.bib16.1.1" class="ltx_text" style="font-size:90%;">
Dhruv Guliani, Lillian Zhou, Changwan Ryu, Tien-Ju Yang, Harry Zhang, Yonghui Xiao, Françoise Beaufays, and Giovanni Motta,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.2.1" class="ltx_text" style="font-size:90%;">“Enabling on-device training of speech recognition models with federated dropout,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib16.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</span><span id="bib.bib16.5.3" class="ltx_text" style="font-size:90%;">. IEEE, 2022, pp. 8757–8761.
</span>
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock"><span id="bib.bib17.1.1" class="ltx_text" style="font-size:90%;">
Rongmei Lin, Yonghui Xiao, Tien-Ju Yang, Ding Zhao, Li Xiong, Giovanni Motta, and Françoise Beaufays,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.2.1" class="ltx_text" style="font-size:90%;">“Federated pruning: Improving neural network efficiency with federated learning,” 2022.
</span>
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock"><span id="bib.bib18.1.1" class="ltx_text" style="font-size:90%;">
Tien-Ju Yang, Yonghui Xiao, Giovanni Motta, Françoise Beaufays, Rajiv Mathews, and Mingqing Chen,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.2.1" class="ltx_text" style="font-size:90%;">“Online model compression for federated learning with large models,” 2022.
</span>
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock"><span id="bib.bib19.1.1" class="ltx_text" style="font-size:90%;">
Tien-Ju Yang, Dhruv Guliani, Françoise Beaufays, and Giovanni Motta,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.2.1" class="ltx_text" style="font-size:90%;">“Partial variable training for efficient on-device federated learning,” 2021.
</span>
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock"><span id="bib.bib20.1.1" class="ltx_text" style="font-size:90%;">
“TensorFlow Federated: Machine Learning on Decentralized Data,” </span><span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self" style="font-size:90%;">https://www.tensorflow.org/federated</span><span id="bib.bib20.2.2" class="ltx_text" style="font-size:90%;">.
</span>
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock"><span id="bib.bib21.1.1" class="ltx_text" style="font-size:90%;">
“TensorFlow Data Types,” </span><span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self" style="font-size:90%;">https://www.tensorflow.org/api_docs/python/tf/dtypes</span><span id="bib.bib21.2.2" class="ltx_text" style="font-size:90%;">.
</span>
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock"><span id="bib.bib22.1.1" class="ltx_text" style="font-size:90%;">
Yonghui Xiao, Li Xiong, Liyue Fan, and Slawomir Goryczka,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.2.1" class="ltx_text" style="font-size:90%;">“Dpcube: Differentially private histogram release through multidimensional partitioning,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">CoRR</span><span id="bib.bib22.4.2" class="ltx_text" style="font-size:90%;">, vol. abs/1202.5358, 2012.
</span>
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock"><span id="bib.bib23.1.1" class="ltx_text" style="font-size:90%;">
A. Misra, D. Hwang, Z. Huo, et al.,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.2.1" class="ltx_text" style="font-size:90%;">“A Comparison of Supervised and Unsupervised Pre-Training of End-to-End Models,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib23.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proc. Interspeech 2021</span><span id="bib.bib23.5.3" class="ltx_text" style="font-size:90%;">, 2021, pp. 731–735.
</span>
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock"><span id="bib.bib24.1.1" class="ltx_text" style="font-size:90%;">
Google,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.2.1" class="ltx_text" style="font-size:90%;">“Artificial intelligence at google: Our principles,” .
</span>
</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2408.10442" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2408.10443" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2408.10443">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2408.10443" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2408.10444" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Sep  5 13:53:09 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
