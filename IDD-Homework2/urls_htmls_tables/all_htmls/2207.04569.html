<!DOCTYPE html><html prefix="dcterms: http://purl.org/dc/terms/" lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2207.04569] 1 Background</title><meta property="og:description" content="Federated learning provides the ability to learn over heterogeneous user data in a distributed manner while preserving user privacy. However, its current client selection technique is a source of bias as it discriminat…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="1 Background">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="1 Background">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2207.04569">

<!--Generated on Wed Mar 13 13:30:32 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<div id="p1" class="ltx_para">
<p id="p1.1" class="ltx_p">marginparsep has been altered.
<br class="ltx_break">topmargin has been altered.
<br class="ltx_break">marginparwidth has been altered.
<br class="ltx_break">marginparpush has been altered.
<br class="ltx_break"><span id="p1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">The page layout violates the ICML style.</span>
Please do not change the page layout, or include packages like geometry,
savetrees, or fullpage, which change it for you.
We’re not able to reliably undo arbitrary changes to the style. Please remove
the offending package(s), or layout-changing commands and try again.</p>
</div>
<div id="p3" class="ltx_para ltx_align_center">
<p id="p3.1" class="ltx_p"><span class="ltx_rule" style="width:100%;height:2.0pt;background:black;display:inline-block;"> </span></p>
</div>
<div id="p4" class="ltx_para ltx_align_center">
<p id="p4.1" class="ltx_p"><span id="p4.1.1" class="ltx_text ltx_font_smallcaps">FedSS: Federated Learning with Smart Selection of Clients</span></p>
</div>
<div id="p5" class="ltx_para ltx_align_center">
<p id="p5.1" class="ltx_p"><span class="ltx_rule" style="width:100%;height:1.0pt;background:black;display:inline-block;"> </span></p>
</div>
<div id="p6" class="ltx_para">
<p id="p6.1" class="ltx_p ltx_align_center"><span id="p6.1.1" class="ltx_text ltx_font_bold">Anonymous Authors</span><sup id="p6.1.2" class="ltx_sup">1 </sup></p>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">Federated learning provides the ability to learn over heterogeneous user data in a distributed manner while preserving user privacy. However, its current client selection technique is a source of bias as it discriminates against slow clients. For starters, it selects clients that satisfy certain network and system-specific criteria, thus not selecting slow clients. Even when such clients are included in the training process, they either struggle with the training or are dropped altogether for being too slow. Our proposed idea looks to find a sweet spot between fast convergence and heterogeneity by looking at smart client selection and scheduling techniques.</p>
</div>
<span id="footnotex1" class="ltx_note ltx_role_footnotetext"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">footnotetext: </span>
<sup id="footnotex1.1" class="ltx_sup">1</sup>Anonymous Institution, Anonymous City, Anonymous Region, Anonymous Country.
Correspondence to: Anonymous Author &lt;anon.email@domain.com&gt;.
 
<br class="ltx_break">Preliminary work. Under review by the
Machine Learning and Systems (MLSys) Conference. Do not distribute.</span></span></span>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Background</h2>

<div id="S1.p1" class="ltx_para ltx_noindent">
<p id="S1.p1.1" class="ltx_p">The past decade has seen an explosion of data-driven and machine learning-based applications that solve different problems. This naturally leads to a lot of fruitful discussions about ownership and access control of these data. Users are concerned about the privacy of their sensitive data and do not prefer sharing it with third-party organizations. However, diverse and heterogeneous training data is of great importance to those models.
Thus, recently we have seen a lot of work on privacy-preserving designs of machine learning models, popularly known as federated learning.</p>
</div>
<div id="S1.p2" class="ltx_para ltx_noindent">
<p id="S1.p2.1" class="ltx_p">Federated learning is a privacy-preserving method of distributed learning over heterogeneous user data. Federated learning follows the philosophy of ”bringing the code to data, instead of bringing data to code” to address the above-mentioned privacy concerns <cite class="ltx_cite ltx_citemacro_cite">Bonawitz et al. (<a href="#bib.bib2" title="" class="ltx_ref">2019</a>); McMahan and Ramage (<a href="#bib.bib21" title="" class="ltx_ref">2017</a>)</cite>.
The architecture presented by Bonawitz et. al. <cite class="ltx_cite ltx_citemacro_cite">Bonawitz et al. (<a href="#bib.bib2" title="" class="ltx_ref">2019</a>)</cite> consists of a server responsible for selecting client devices for training from a pool of available devices in each round. The server maintains a copy of the global model, which is distributed to selected client devices at the start of each round. Each client trains the model with their local data and sends the gradients back to the server. The server calculates the average gradient using the FedAvg algorithm after collecting gradients. This average gradient is used to update the global model, which is then distributed in the next round.</p>
</div>
<div id="S1.p3" class="ltx_para ltx_noindent">
<p id="S1.p3.1" class="ltx_p">Since gradients can still reveal information about the data, gradient updates sent by clients are preserved with secure aggregation <cite class="ltx_cite ltx_citemacro_cite">Bonawitz et al. (<a href="#bib.bib3" title="" class="ltx_ref">2016</a>)</cite> to enforce privacy further. Secure aggregation prevents the server from learning individual clients’ gradients but learns the aggregate one once responses from all clients are received. This couples with the already synchronous nature of federated learning, and makes the performance of training susceptible to degradation due to stragglers. Thus, it is desirable from the angle of performance that the selected devices are almost homogeneous with respect to the network and computation power. However, mobile devices can have significantly different network conditions<cite class="ltx_cite ltx_citemacro_cite">Chen et al. (<a href="#bib.bib6" title="" class="ltx_ref">2023</a>)</cite> and compute capability. Most of the current designs select clients randomly from a pool of devices that satisfy certain criteria e.g. minimum 2 GB memory, unmetered network, etc <cite class="ltx_cite ltx_citemacro_cite">Bonawitz et al. (<a href="#bib.bib2" title="" class="ltx_ref">2019</a>); Li et al. (<a href="#bib.bib17" title="" class="ltx_ref">2020</a>)</cite>. This technique of client selection introduces explicit bias in the system since factors like device memory and quality of network are directly linked with socioeconomic status <cite class="ltx_cite ltx_citemacro_cite">Abay et al. (<a href="#bib.bib1" title="" class="ltx_ref">2020</a>); Kairouz et al. (<a href="#bib.bib15" title="" class="ltx_ref">2019</a>); Li et al. (<a href="#bib.bib17" title="" class="ltx_ref">2020</a>)</cite>. Thus, it’s critical to improve client selection mechanisms to build models that are void of this explicit bias.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<div id="S2.p1" class="ltx_para ltx_noindent">
<p id="S2.p1.1" class="ltx_p">A variety of solutions have been proposed for this problem, ranging from model compression to different strategies of client selection. Firstly, we discuss how existing work reduces the training time of slow clients, and still incorporates them to mitigate bias. Then, we discuss current smart client selection strategies.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Bias Mitigation Strategies</h3>

<div id="S2.SS1.p1" class="ltx_para ltx_noindent">
<p id="S2.SS1.p1.1" class="ltx_p">As we discussed, the existing design of federated learning introduces explicit bias since parameters based on which devices are selected are linked with socioeconomic factors<cite class="ltx_cite ltx_citemacro_cite">Abay et al. (<a href="#bib.bib1" title="" class="ltx_ref">2020</a>); Kairouz et al. (<a href="#bib.bib15" title="" class="ltx_ref">2019</a>); Li et al. (<a href="#bib.bib17" title="" class="ltx_ref">2020</a>)</cite>. Bias can also come because of the non-IID distribution of data. However, there are some techniques to circumvent it since it’s a deep learning optimization problem<cite class="ltx_cite ltx_citemacro_cite">Zhao et al. (<a href="#bib.bib33" title="" class="ltx_ref">2018</a>); Li et al. (<a href="#bib.bib18" title="" class="ltx_ref">2018</a>); Cho et al. (<a href="#bib.bib7" title="" class="ltx_ref">2020</a>)</cite>. To mitigate the explicit bias discussed above, we need to include slow devices in the training process. Clearly doing this comes at the cost of slow convergence, owing to the slow clients straggling the process. However, there has been some work on reducing computation and network costs for slow clients at the expense of the accuracy of the model <cite class="ltx_cite ltx_citemacro_cite">Xu et al. (<a href="#bib.bib31" title="" class="ltx_ref">2019</a>); Li et al. (<a href="#bib.bib18" title="" class="ltx_ref">2018</a>); Konečnỳ et al. (<a href="#bib.bib16" title="" class="ltx_ref">2016</a>)</cite>. For example Li et. al. <cite class="ltx_cite ltx_citemacro_cite">Li et al. (<a href="#bib.bib18" title="" class="ltx_ref">2018</a>)</cite> allows different devices to perform variable amount of workload depending on their resources. Slow clients can run fewer epochs or use lesser input data. Similarly, Konečnỳ et. al. <cite class="ltx_cite ltx_citemacro_cite">Konečnỳ et al. (<a href="#bib.bib16" title="" class="ltx_ref">2016</a>)</cite> compresses model updates in a lossy fashion to reduce communication costs at the expense of the accuracy of the sent parameters. Abay et al<cite class="ltx_cite ltx_citemacro_cite">Abay et al. (<a href="#bib.bib1" title="" class="ltx_ref">2020</a>)</cite> proposes a fairness-aware regularization in the loss function. However, we argue that such techniques do not truly address the bias problem because there is still discrimination in how slow clients are handled. An ideal design should give equal opportunity for all clients to contribute to the global model.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Clients Selection Strategies</h3>

<div id="S2.SS2.p1" class="ltx_para ltx_noindent">
<p id="S2.SS2.p1.1" class="ltx_p">It’s clear that the heterogeneous communication environments and computation resources at clients can hamper the overall training speed. To accelerate the convergence speed under this client heterogeneity, existing work has investigated to make smarter decisions about client selection to alleviate the communication overhead.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para ltx_noindent">
<p id="S2.SS2.p2.1" class="ltx_p">In the prevalent random client selection strategy, all clients participate in the client selection phase in every round. The server uniformly and randomly selects a subset of clients from the pool<cite class="ltx_cite ltx_citemacro_cite">McMahan et al. (<a href="#bib.bib22" title="" class="ltx_ref">2017</a>); Li et al. (<a href="#bib.bib19" title="" class="ltx_ref">2019</a>); Ruan et al. (<a href="#bib.bib25" title="" class="ltx_ref">2020</a>)</cite> for training. The chosen clients do multiple iterations of SGD on the local data, given the ML model and the latest parameters from the server. Finally, the server collects and aggregates the computed gradients to update the global parameters. Li et. al. <cite class="ltx_cite ltx_citemacro_cite">Li et al. (<a href="#bib.bib19" title="" class="ltx_ref">2019</a>)</cite> provides a necessary convergence condition for federated learning on non-iid data with partial client participation. Ruan et. al. <cite class="ltx_cite ltx_citemacro_cite">Ruan et al. (<a href="#bib.bib25" title="" class="ltx_ref">2020</a>)</cite> offer a selection scheme that converges even when devices can flexibly join or leave the training.</p>
</div>
<figure id="S2.F1" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S2.F1.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2207.04569/assets/x1.png" id="S2.F1.sf1.g1" class="ltx_graphics ltx_img_landscape" width="195" height="108" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>Random Selection</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S2.F1.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2207.04569/assets/x2.png" id="S2.F1.sf2.g1" class="ltx_graphics ltx_img_square" width="128" height="108" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>FedCS</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S2.F1.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2207.04569/assets/x3.png" id="S2.F1.sf3.g1" class="ltx_graphics ltx_img_landscape" width="148" height="108" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(c) </span>Ours</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>(a) The round time in the random selection scheme is determined by the straggler. (b) While the round time in FedCS is shortest, client3 and client4 are always excluded because of their long training time and transmission delay. (c) Our scheme reaches the best trade-off between training time and data heterogeneity. </figcaption>
</figure>
<div id="S2.SS2.p3" class="ltx_para ltx_noindent">
<p id="S2.SS2.p3.1" class="ltx_p">Some recent work looks into client selection based on different criteria like the higher potential for global model convergence or good network conditions. Cho et. al. <cite class="ltx_cite ltx_citemacro_cite">Cho et al. (<a href="#bib.bib7" title="" class="ltx_ref">2020</a>)</cite> reveal that a biased selection towards clients with higher local loss can increase the speed of convergence. This is because higher loss indicates a higher potential for model improvement. The proposed POWER-OF-CHOICE algorithm can yield up to 3X faster convergence and 10% higher test accuracy compared with conventional federated learning with random client selection. FedCS<cite class="ltx_cite ltx_citemacro_cite">Nishio and Yonetani (<a href="#bib.bib23" title="" class="ltx_ref">2019</a>)</cite> requests the resource information, such as wireless network bandwidth and compute capability, from selected clients before the distribution of parameters of the global model. It then only collects the gradients from clients which can update and upload the parameters within a deadline. Although these biased client selection models can facilitate quicker convergence, it sacrifices the original benefit of federated learning: the heterogeneity of data. TiFL<cite class="ltx_cite ltx_citemacro_cite">Chai et al. (<a href="#bib.bib5" title="" class="ltx_ref">2020</a>)</cite> is another recent work that explores tiering together clients with similar training times and prioritizing faster tiers to speed up training. It only temporarily prioritizes slower tiers when the accuracy of the global model is poor during testing on devices from slower tiers. In contrast, FedSS’s client selection does not lean toward any particular cluster during training and offers equal opportunities for every client to contribute to the training.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Training Policies</h3>

<div id="S2.SS3.p1" class="ltx_para ltx_noindent">
<p id="S2.SS3.p1.1" class="ltx_p">Recent work also shows that the straggler problem can be eliminated by using asynchronous training policies. For example, in FedAsync <cite class="ltx_cite ltx_citemacro_cite">Xie et al. (<a href="#bib.bib30" title="" class="ltx_ref">2019</a>)</cite>, the server does not wait for all clients to send their model updates before performing average. In fact, clients can request a central model whenever they complete their local training. This speeds up training but results in a higher degree of communication and complications due to the staleness of the model <cite class="ltx_cite ltx_citemacro_cite">Dai et al. (<a href="#bib.bib9" title="" class="ltx_ref">2018</a>); Stripelis et al. (<a href="#bib.bib27" title="" class="ltx_ref">2022</a>)</cite>. Semi-synchronous training <cite class="ltx_cite ltx_citemacro_cite">Stripelis et al. (<a href="#bib.bib27" title="" class="ltx_ref">2022</a>)</cite> tries to find the best of both worlds. It has a fixed point at which all clients must synchronize at the central server but avoids idling by letting faster clients continue training. However, this is orthogonal to our clustering strategy. Semi-synchronous training can still benefit from our clustering by dividing clients into clusters and having different synchronization deadlines for each cluster. Such clustering will help reduce bias by minimizing extra training that fast clients may do in any round.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Motivation</h2>

<div id="S3.p1" class="ltx_para ltx_noindent">
<p id="S3.p1.1" class="ltx_p">As evidenced by the related work, federated learning between clients with heterogeneous data, devices, and networks can result in prolonged convergence time. Appropriate client selection decisions can result in quick convergence. The convergence time is determined by two factors: <span id="S3.p1.1.1" class="ltx_text ltx_font_italic">i) number of rounds</span> until the model convergence condition is reached and <span id="S3.p1.1.2" class="ltx_text ltx_font_italic">ii) time duration of each round</span>. The number of rounds can be reduced by selecting clients that add more value to the learning e.g. high losses. Whereas the duration of each round is determined by stragglers, thus selecting devices based on hardware and network conditions can reduce the convergence time.</p>
</div>
<div id="S3.p2" class="ltx_para ltx_noindent">
<p id="S3.p2.1" class="ltx_p">To avoid the prolonged round duration time caused by stragglers, we can select clients with similar training times in each round. Meanwhile, we can randomly choose clients with different network/computation conditions across rounds to guarantee data heterogeneity. We understand that slow clients might be in the minority in some cases, where arranging separate rounds for them can jeopardize their privacy. To ensure privacy for such rounds we can fill up the round group with faster clients too. We visualize and compare this strategy with random selection in Bonawitz et, al. <cite class="ltx_cite ltx_citemacro_cite">Bonawitz et al. (<a href="#bib.bib2" title="" class="ltx_ref">2019</a>)</cite> and FedCS <cite class="ltx_cite ltx_citemacro_cite">Nishio and Yonetani (<a href="#bib.bib23" title="" class="ltx_ref">2019</a>)</cite> in Fig.<a href="#S2.F1" title="Figure 1 ‣ 2.2 Clients Selection Strategies ‣ 2 Related Work" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>System Design</h2>

<div id="S4.p1" class="ltx_para ltx_noindent">
<p id="S4.p1.1" class="ltx_p">To reduce bias and also ensure faster model convergence, we propose a smart approach of clients selection. We first collect the device’s compute capability captured by FLOPS (Floating point Operations per Second) along with network conditions such as uplink and downlink bandwidth <cite class="ltx_cite ltx_citemacro_cite">Choi et al. (<a href="#bib.bib8" title="" class="ltx_ref">1998</a>)</cite> of every connected client.</p>
</div>
<div id="S4.p2" class="ltx_para ltx_noindent">
<p id="S4.p2.2" class="ltx_p">Based on these collected parameters, we categorize clients into different equal sized clusters. Each cluster comprises clients with similar training time. We also determine optimal number of clusters, <math id="S4.p2.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S4.p2.1.m1.1a"><mi id="S4.p2.1.m1.1.1" xref="S4.p2.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.p2.1.m1.1b"><ci id="S4.p2.1.m1.1.1.cmml" xref="S4.p2.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.1.m1.1c">k</annotation></semantics></math>, for a given distribution. <math id="S4.p2.2.m2.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S4.p2.2.m2.1a"><mi id="S4.p2.2.m2.1.1" xref="S4.p2.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.p2.2.m2.1b"><ci id="S4.p2.2.m2.1.1.cmml" xref="S4.p2.2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.2.m2.1c">k</annotation></semantics></math> is optimized to minimize training time, while ensuring higher possible degree of anonymity (high cluster sizes). In every round, the FedSS server chooses a cluster in a round-robin way and selects clients within it randomly to ensure equal opportunity of every client.</p>
</div>
<div id="S4.p3" class="ltx_para ltx_noindent">
<p id="S4.p3.1" class="ltx_p">There are two basic intuitions behind the approach. 1) Reduce bias due to barriers to entry for low bandwidth/ low-end devices, which in turn minimizes socioeconomic bias. By giving a fair chance to all the clients, the model gets a better chance to learn from different data distributions. This also prevents against content farm attacks using uncompromised phones with high availability and bandwidth. 2) Have more coordinated training rounds with similar performing clients grouped together. We are less likely to run into a situation where the overall completion time of a round is longer due to a fraction of low-performing devices.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Dynamic Client Environment Tracking</h3>

<div id="S4.SS1.p1" class="ltx_para ltx_noindent">
<p id="S4.SS1.p1.1" class="ltx_p">From Fig.<a href="#S4.F2" title="Figure 2 ‣ 4.1 Dynamic Client Environment Tracking ‣ 4 System Design" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, the steps in one training round of FedSS comprise: the smart clients’ selection, the distribution of models, the parallel clients’ training procedure, the collection of updated models, and the aggregation. Except for the first and the last steps, the time it costs in all other steps is decided by the clients’ environments. The network conditions, such as bandwidth and propagation delay, determine the time taken to distribute the model and collect gradients. Meanwhile, the client’s local compute capability, reflected by available CPUs, GPUs, and memory, determines the time taken to finish the training procedure. Therefore, FedSS dynamically tracks and records those parameters of every connected client, and predicts the approximate time it takes to accomplish one round.</p>
</div>
<figure id="S4.F2" class="ltx_figure"><img src="/html/2207.04569/assets/x4.png" id="S4.F2.g1" class="ltx_graphics ltx_centering ltx_img_square" width="259" height="238" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>The workflow to finish one round of synchronous training in FedSS. The bottleneck includes model distribution, model collection, and parallel client training, which majorly depend on the client’s compute capability and network conditions.</figcaption>
</figure>
<div id="S4.SS1.p2" class="ltx_para ltx_noindent">
<p id="S4.SS1.p2.8" class="ltx_p">Let’s assume the model size is <math id="S4.SS1.p2.1.m1.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S4.SS1.p2.1.m1.1a"><mi id="S4.SS1.p2.1.m1.1.1" xref="S4.SS1.p2.1.m1.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.1.m1.1b"><ci id="S4.SS1.p2.1.m1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.1.m1.1c">M</annotation></semantics></math>, and the total number of floating point operations in the model is <math id="S4.SS1.p2.2.m2.1" class="ltx_Math" alttext="Flops" display="inline"><semantics id="S4.SS1.p2.2.m2.1a"><mrow id="S4.SS1.p2.2.m2.1.1" xref="S4.SS1.p2.2.m2.1.1.cmml"><mi id="S4.SS1.p2.2.m2.1.1.2" xref="S4.SS1.p2.2.m2.1.1.2.cmml">F</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p2.2.m2.1.1.1" xref="S4.SS1.p2.2.m2.1.1.1.cmml">​</mo><mi id="S4.SS1.p2.2.m2.1.1.3" xref="S4.SS1.p2.2.m2.1.1.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p2.2.m2.1.1.1a" xref="S4.SS1.p2.2.m2.1.1.1.cmml">​</mo><mi id="S4.SS1.p2.2.m2.1.1.4" xref="S4.SS1.p2.2.m2.1.1.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p2.2.m2.1.1.1b" xref="S4.SS1.p2.2.m2.1.1.1.cmml">​</mo><mi id="S4.SS1.p2.2.m2.1.1.5" xref="S4.SS1.p2.2.m2.1.1.5.cmml">p</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p2.2.m2.1.1.1c" xref="S4.SS1.p2.2.m2.1.1.1.cmml">​</mo><mi id="S4.SS1.p2.2.m2.1.1.6" xref="S4.SS1.p2.2.m2.1.1.6.cmml">s</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.2.m2.1b"><apply id="S4.SS1.p2.2.m2.1.1.cmml" xref="S4.SS1.p2.2.m2.1.1"><times id="S4.SS1.p2.2.m2.1.1.1.cmml" xref="S4.SS1.p2.2.m2.1.1.1"></times><ci id="S4.SS1.p2.2.m2.1.1.2.cmml" xref="S4.SS1.p2.2.m2.1.1.2">𝐹</ci><ci id="S4.SS1.p2.2.m2.1.1.3.cmml" xref="S4.SS1.p2.2.m2.1.1.3">𝑙</ci><ci id="S4.SS1.p2.2.m2.1.1.4.cmml" xref="S4.SS1.p2.2.m2.1.1.4">𝑜</ci><ci id="S4.SS1.p2.2.m2.1.1.5.cmml" xref="S4.SS1.p2.2.m2.1.1.5">𝑝</ci><ci id="S4.SS1.p2.2.m2.1.1.6.cmml" xref="S4.SS1.p2.2.m2.1.1.6">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.2.m2.1c">Flops</annotation></semantics></math>. Given the measured network uplink bandwidth <math id="S4.SS1.p2.3.m3.1" class="ltx_Math" alttext="UL_{i}" display="inline"><semantics id="S4.SS1.p2.3.m3.1a"><mrow id="S4.SS1.p2.3.m3.1.1" xref="S4.SS1.p2.3.m3.1.1.cmml"><mi id="S4.SS1.p2.3.m3.1.1.2" xref="S4.SS1.p2.3.m3.1.1.2.cmml">U</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p2.3.m3.1.1.1" xref="S4.SS1.p2.3.m3.1.1.1.cmml">​</mo><msub id="S4.SS1.p2.3.m3.1.1.3" xref="S4.SS1.p2.3.m3.1.1.3.cmml"><mi id="S4.SS1.p2.3.m3.1.1.3.2" xref="S4.SS1.p2.3.m3.1.1.3.2.cmml">L</mi><mi id="S4.SS1.p2.3.m3.1.1.3.3" xref="S4.SS1.p2.3.m3.1.1.3.3.cmml">i</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.3.m3.1b"><apply id="S4.SS1.p2.3.m3.1.1.cmml" xref="S4.SS1.p2.3.m3.1.1"><times id="S4.SS1.p2.3.m3.1.1.1.cmml" xref="S4.SS1.p2.3.m3.1.1.1"></times><ci id="S4.SS1.p2.3.m3.1.1.2.cmml" xref="S4.SS1.p2.3.m3.1.1.2">𝑈</ci><apply id="S4.SS1.p2.3.m3.1.1.3.cmml" xref="S4.SS1.p2.3.m3.1.1.3"><csymbol cd="ambiguous" id="S4.SS1.p2.3.m3.1.1.3.1.cmml" xref="S4.SS1.p2.3.m3.1.1.3">subscript</csymbol><ci id="S4.SS1.p2.3.m3.1.1.3.2.cmml" xref="S4.SS1.p2.3.m3.1.1.3.2">𝐿</ci><ci id="S4.SS1.p2.3.m3.1.1.3.3.cmml" xref="S4.SS1.p2.3.m3.1.1.3.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.3.m3.1c">UL_{i}</annotation></semantics></math>, downlink bandwidth <math id="S4.SS1.p2.4.m4.1" class="ltx_Math" alttext="DL_{i}" display="inline"><semantics id="S4.SS1.p2.4.m4.1a"><mrow id="S4.SS1.p2.4.m4.1.1" xref="S4.SS1.p2.4.m4.1.1.cmml"><mi id="S4.SS1.p2.4.m4.1.1.2" xref="S4.SS1.p2.4.m4.1.1.2.cmml">D</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p2.4.m4.1.1.1" xref="S4.SS1.p2.4.m4.1.1.1.cmml">​</mo><msub id="S4.SS1.p2.4.m4.1.1.3" xref="S4.SS1.p2.4.m4.1.1.3.cmml"><mi id="S4.SS1.p2.4.m4.1.1.3.2" xref="S4.SS1.p2.4.m4.1.1.3.2.cmml">L</mi><mi id="S4.SS1.p2.4.m4.1.1.3.3" xref="S4.SS1.p2.4.m4.1.1.3.3.cmml">i</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.4.m4.1b"><apply id="S4.SS1.p2.4.m4.1.1.cmml" xref="S4.SS1.p2.4.m4.1.1"><times id="S4.SS1.p2.4.m4.1.1.1.cmml" xref="S4.SS1.p2.4.m4.1.1.1"></times><ci id="S4.SS1.p2.4.m4.1.1.2.cmml" xref="S4.SS1.p2.4.m4.1.1.2">𝐷</ci><apply id="S4.SS1.p2.4.m4.1.1.3.cmml" xref="S4.SS1.p2.4.m4.1.1.3"><csymbol cd="ambiguous" id="S4.SS1.p2.4.m4.1.1.3.1.cmml" xref="S4.SS1.p2.4.m4.1.1.3">subscript</csymbol><ci id="S4.SS1.p2.4.m4.1.1.3.2.cmml" xref="S4.SS1.p2.4.m4.1.1.3.2">𝐿</ci><ci id="S4.SS1.p2.4.m4.1.1.3.3.cmml" xref="S4.SS1.p2.4.m4.1.1.3.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.4.m4.1c">DL_{i}</annotation></semantics></math>, client’s FLOPS rate <math id="S4.SS1.p2.5.m5.1" class="ltx_Math" alttext="FlopsRate_{i}" display="inline"><semantics id="S4.SS1.p2.5.m5.1a"><mrow id="S4.SS1.p2.5.m5.1.1" xref="S4.SS1.p2.5.m5.1.1.cmml"><mi id="S4.SS1.p2.5.m5.1.1.2" xref="S4.SS1.p2.5.m5.1.1.2.cmml">F</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p2.5.m5.1.1.1" xref="S4.SS1.p2.5.m5.1.1.1.cmml">​</mo><mi id="S4.SS1.p2.5.m5.1.1.3" xref="S4.SS1.p2.5.m5.1.1.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p2.5.m5.1.1.1a" xref="S4.SS1.p2.5.m5.1.1.1.cmml">​</mo><mi id="S4.SS1.p2.5.m5.1.1.4" xref="S4.SS1.p2.5.m5.1.1.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p2.5.m5.1.1.1b" xref="S4.SS1.p2.5.m5.1.1.1.cmml">​</mo><mi id="S4.SS1.p2.5.m5.1.1.5" xref="S4.SS1.p2.5.m5.1.1.5.cmml">p</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p2.5.m5.1.1.1c" xref="S4.SS1.p2.5.m5.1.1.1.cmml">​</mo><mi id="S4.SS1.p2.5.m5.1.1.6" xref="S4.SS1.p2.5.m5.1.1.6.cmml">s</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p2.5.m5.1.1.1d" xref="S4.SS1.p2.5.m5.1.1.1.cmml">​</mo><mi id="S4.SS1.p2.5.m5.1.1.7" xref="S4.SS1.p2.5.m5.1.1.7.cmml">R</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p2.5.m5.1.1.1e" xref="S4.SS1.p2.5.m5.1.1.1.cmml">​</mo><mi id="S4.SS1.p2.5.m5.1.1.8" xref="S4.SS1.p2.5.m5.1.1.8.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p2.5.m5.1.1.1f" xref="S4.SS1.p2.5.m5.1.1.1.cmml">​</mo><mi id="S4.SS1.p2.5.m5.1.1.9" xref="S4.SS1.p2.5.m5.1.1.9.cmml">t</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p2.5.m5.1.1.1g" xref="S4.SS1.p2.5.m5.1.1.1.cmml">​</mo><msub id="S4.SS1.p2.5.m5.1.1.10" xref="S4.SS1.p2.5.m5.1.1.10.cmml"><mi id="S4.SS1.p2.5.m5.1.1.10.2" xref="S4.SS1.p2.5.m5.1.1.10.2.cmml">e</mi><mi id="S4.SS1.p2.5.m5.1.1.10.3" xref="S4.SS1.p2.5.m5.1.1.10.3.cmml">i</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.5.m5.1b"><apply id="S4.SS1.p2.5.m5.1.1.cmml" xref="S4.SS1.p2.5.m5.1.1"><times id="S4.SS1.p2.5.m5.1.1.1.cmml" xref="S4.SS1.p2.5.m5.1.1.1"></times><ci id="S4.SS1.p2.5.m5.1.1.2.cmml" xref="S4.SS1.p2.5.m5.1.1.2">𝐹</ci><ci id="S4.SS1.p2.5.m5.1.1.3.cmml" xref="S4.SS1.p2.5.m5.1.1.3">𝑙</ci><ci id="S4.SS1.p2.5.m5.1.1.4.cmml" xref="S4.SS1.p2.5.m5.1.1.4">𝑜</ci><ci id="S4.SS1.p2.5.m5.1.1.5.cmml" xref="S4.SS1.p2.5.m5.1.1.5">𝑝</ci><ci id="S4.SS1.p2.5.m5.1.1.6.cmml" xref="S4.SS1.p2.5.m5.1.1.6">𝑠</ci><ci id="S4.SS1.p2.5.m5.1.1.7.cmml" xref="S4.SS1.p2.5.m5.1.1.7">𝑅</ci><ci id="S4.SS1.p2.5.m5.1.1.8.cmml" xref="S4.SS1.p2.5.m5.1.1.8">𝑎</ci><ci id="S4.SS1.p2.5.m5.1.1.9.cmml" xref="S4.SS1.p2.5.m5.1.1.9">𝑡</ci><apply id="S4.SS1.p2.5.m5.1.1.10.cmml" xref="S4.SS1.p2.5.m5.1.1.10"><csymbol cd="ambiguous" id="S4.SS1.p2.5.m5.1.1.10.1.cmml" xref="S4.SS1.p2.5.m5.1.1.10">subscript</csymbol><ci id="S4.SS1.p2.5.m5.1.1.10.2.cmml" xref="S4.SS1.p2.5.m5.1.1.10.2">𝑒</ci><ci id="S4.SS1.p2.5.m5.1.1.10.3.cmml" xref="S4.SS1.p2.5.m5.1.1.10.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.5.m5.1c">FlopsRate_{i}</annotation></semantics></math> and the number of samples at client <math id="S4.SS1.p2.6.m6.1" class="ltx_Math" alttext="S_{i}" display="inline"><semantics id="S4.SS1.p2.6.m6.1a"><msub id="S4.SS1.p2.6.m6.1.1" xref="S4.SS1.p2.6.m6.1.1.cmml"><mi id="S4.SS1.p2.6.m6.1.1.2" xref="S4.SS1.p2.6.m6.1.1.2.cmml">S</mi><mi id="S4.SS1.p2.6.m6.1.1.3" xref="S4.SS1.p2.6.m6.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.6.m6.1b"><apply id="S4.SS1.p2.6.m6.1.1.cmml" xref="S4.SS1.p2.6.m6.1.1"><csymbol cd="ambiguous" id="S4.SS1.p2.6.m6.1.1.1.cmml" xref="S4.SS1.p2.6.m6.1.1">subscript</csymbol><ci id="S4.SS1.p2.6.m6.1.1.2.cmml" xref="S4.SS1.p2.6.m6.1.1.2">𝑆</ci><ci id="S4.SS1.p2.6.m6.1.1.3.cmml" xref="S4.SS1.p2.6.m6.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.6.m6.1c">S_{i}</annotation></semantics></math> for client <math id="S4.SS1.p2.7.m7.1" class="ltx_Math" alttext="c_{i}" display="inline"><semantics id="S4.SS1.p2.7.m7.1a"><msub id="S4.SS1.p2.7.m7.1.1" xref="S4.SS1.p2.7.m7.1.1.cmml"><mi id="S4.SS1.p2.7.m7.1.1.2" xref="S4.SS1.p2.7.m7.1.1.2.cmml">c</mi><mi id="S4.SS1.p2.7.m7.1.1.3" xref="S4.SS1.p2.7.m7.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.7.m7.1b"><apply id="S4.SS1.p2.7.m7.1.1.cmml" xref="S4.SS1.p2.7.m7.1.1"><csymbol cd="ambiguous" id="S4.SS1.p2.7.m7.1.1.1.cmml" xref="S4.SS1.p2.7.m7.1.1">subscript</csymbol><ci id="S4.SS1.p2.7.m7.1.1.2.cmml" xref="S4.SS1.p2.7.m7.1.1.2">𝑐</ci><ci id="S4.SS1.p2.7.m7.1.1.3.cmml" xref="S4.SS1.p2.7.m7.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.7.m7.1c">c_{i}</annotation></semantics></math>, the overall round time <math id="S4.SS1.p2.8.m8.1" class="ltx_Math" alttext="T_{i}" display="inline"><semantics id="S4.SS1.p2.8.m8.1a"><msub id="S4.SS1.p2.8.m8.1.1" xref="S4.SS1.p2.8.m8.1.1.cmml"><mi id="S4.SS1.p2.8.m8.1.1.2" xref="S4.SS1.p2.8.m8.1.1.2.cmml">T</mi><mi id="S4.SS1.p2.8.m8.1.1.3" xref="S4.SS1.p2.8.m8.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.8.m8.1b"><apply id="S4.SS1.p2.8.m8.1.1.cmml" xref="S4.SS1.p2.8.m8.1.1"><csymbol cd="ambiguous" id="S4.SS1.p2.8.m8.1.1.1.cmml" xref="S4.SS1.p2.8.m8.1.1">subscript</csymbol><ci id="S4.SS1.p2.8.m8.1.1.2.cmml" xref="S4.SS1.p2.8.m8.1.1.2">𝑇</ci><ci id="S4.SS1.p2.8.m8.1.1.3.cmml" xref="S4.SS1.p2.8.m8.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.8.m8.1c">T_{i}</annotation></semantics></math> for that client is:</p>
</div>
<div id="S4.SS1.p3" class="ltx_para ltx_noindent">
<table id="S4.Ex1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.Ex1.m1.1" class="ltx_Math" alttext="T_{i}=M/UL_{i}+S_{i}\cdot Flops/FlopsRate_{i}+M/DL_{i}" display="block"><semantics id="S4.Ex1.m1.1a"><mrow id="S4.Ex1.m1.1.1" xref="S4.Ex1.m1.1.1.cmml"><msub id="S4.Ex1.m1.1.1.2" xref="S4.Ex1.m1.1.1.2.cmml"><mi id="S4.Ex1.m1.1.1.2.2" xref="S4.Ex1.m1.1.1.2.2.cmml">T</mi><mi id="S4.Ex1.m1.1.1.2.3" xref="S4.Ex1.m1.1.1.2.3.cmml">i</mi></msub><mo id="S4.Ex1.m1.1.1.1" xref="S4.Ex1.m1.1.1.1.cmml">=</mo><mrow id="S4.Ex1.m1.1.1.3" xref="S4.Ex1.m1.1.1.3.cmml"><mrow id="S4.Ex1.m1.1.1.3.2" xref="S4.Ex1.m1.1.1.3.2.cmml"><mrow id="S4.Ex1.m1.1.1.3.2.2" xref="S4.Ex1.m1.1.1.3.2.2.cmml"><mi id="S4.Ex1.m1.1.1.3.2.2.2" xref="S4.Ex1.m1.1.1.3.2.2.2.cmml">M</mi><mo id="S4.Ex1.m1.1.1.3.2.2.1" xref="S4.Ex1.m1.1.1.3.2.2.1.cmml">/</mo><mi id="S4.Ex1.m1.1.1.3.2.2.3" xref="S4.Ex1.m1.1.1.3.2.2.3.cmml">U</mi></mrow><mo lspace="0em" rspace="0em" id="S4.Ex1.m1.1.1.3.2.1" xref="S4.Ex1.m1.1.1.3.2.1.cmml">​</mo><msub id="S4.Ex1.m1.1.1.3.2.3" xref="S4.Ex1.m1.1.1.3.2.3.cmml"><mi id="S4.Ex1.m1.1.1.3.2.3.2" xref="S4.Ex1.m1.1.1.3.2.3.2.cmml">L</mi><mi id="S4.Ex1.m1.1.1.3.2.3.3" xref="S4.Ex1.m1.1.1.3.2.3.3.cmml">i</mi></msub></mrow><mo id="S4.Ex1.m1.1.1.3.1" xref="S4.Ex1.m1.1.1.3.1.cmml">+</mo><mrow id="S4.Ex1.m1.1.1.3.3" xref="S4.Ex1.m1.1.1.3.3.cmml"><mrow id="S4.Ex1.m1.1.1.3.3.2" xref="S4.Ex1.m1.1.1.3.3.2.cmml"><mrow id="S4.Ex1.m1.1.1.3.3.2.2" xref="S4.Ex1.m1.1.1.3.3.2.2.cmml"><mrow id="S4.Ex1.m1.1.1.3.3.2.2.2" xref="S4.Ex1.m1.1.1.3.3.2.2.2.cmml"><msub id="S4.Ex1.m1.1.1.3.3.2.2.2.2" xref="S4.Ex1.m1.1.1.3.3.2.2.2.2.cmml"><mi id="S4.Ex1.m1.1.1.3.3.2.2.2.2.2" xref="S4.Ex1.m1.1.1.3.3.2.2.2.2.2.cmml">S</mi><mi id="S4.Ex1.m1.1.1.3.3.2.2.2.2.3" xref="S4.Ex1.m1.1.1.3.3.2.2.2.2.3.cmml">i</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S4.Ex1.m1.1.1.3.3.2.2.2.1" xref="S4.Ex1.m1.1.1.3.3.2.2.2.1.cmml">⋅</mo><mi id="S4.Ex1.m1.1.1.3.3.2.2.2.3" xref="S4.Ex1.m1.1.1.3.3.2.2.2.3.cmml">F</mi></mrow><mo lspace="0em" rspace="0em" id="S4.Ex1.m1.1.1.3.3.2.2.1" xref="S4.Ex1.m1.1.1.3.3.2.2.1.cmml">​</mo><mi id="S4.Ex1.m1.1.1.3.3.2.2.3" xref="S4.Ex1.m1.1.1.3.3.2.2.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S4.Ex1.m1.1.1.3.3.2.2.1a" xref="S4.Ex1.m1.1.1.3.3.2.2.1.cmml">​</mo><mi id="S4.Ex1.m1.1.1.3.3.2.2.4" xref="S4.Ex1.m1.1.1.3.3.2.2.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.Ex1.m1.1.1.3.3.2.2.1b" xref="S4.Ex1.m1.1.1.3.3.2.2.1.cmml">​</mo><mi id="S4.Ex1.m1.1.1.3.3.2.2.5" xref="S4.Ex1.m1.1.1.3.3.2.2.5.cmml">p</mi><mo lspace="0em" rspace="0em" id="S4.Ex1.m1.1.1.3.3.2.2.1c" xref="S4.Ex1.m1.1.1.3.3.2.2.1.cmml">​</mo><mi id="S4.Ex1.m1.1.1.3.3.2.2.6" xref="S4.Ex1.m1.1.1.3.3.2.2.6.cmml">s</mi></mrow><mo id="S4.Ex1.m1.1.1.3.3.2.1" xref="S4.Ex1.m1.1.1.3.3.2.1.cmml">/</mo><mi id="S4.Ex1.m1.1.1.3.3.2.3" xref="S4.Ex1.m1.1.1.3.3.2.3.cmml">F</mi></mrow><mo lspace="0em" rspace="0em" id="S4.Ex1.m1.1.1.3.3.1" xref="S4.Ex1.m1.1.1.3.3.1.cmml">​</mo><mi id="S4.Ex1.m1.1.1.3.3.3" xref="S4.Ex1.m1.1.1.3.3.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S4.Ex1.m1.1.1.3.3.1a" xref="S4.Ex1.m1.1.1.3.3.1.cmml">​</mo><mi id="S4.Ex1.m1.1.1.3.3.4" xref="S4.Ex1.m1.1.1.3.3.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.Ex1.m1.1.1.3.3.1b" xref="S4.Ex1.m1.1.1.3.3.1.cmml">​</mo><mi id="S4.Ex1.m1.1.1.3.3.5" xref="S4.Ex1.m1.1.1.3.3.5.cmml">p</mi><mo lspace="0em" rspace="0em" id="S4.Ex1.m1.1.1.3.3.1c" xref="S4.Ex1.m1.1.1.3.3.1.cmml">​</mo><mi id="S4.Ex1.m1.1.1.3.3.6" xref="S4.Ex1.m1.1.1.3.3.6.cmml">s</mi><mo lspace="0em" rspace="0em" id="S4.Ex1.m1.1.1.3.3.1d" xref="S4.Ex1.m1.1.1.3.3.1.cmml">​</mo><mi id="S4.Ex1.m1.1.1.3.3.7" xref="S4.Ex1.m1.1.1.3.3.7.cmml">R</mi><mo lspace="0em" rspace="0em" id="S4.Ex1.m1.1.1.3.3.1e" xref="S4.Ex1.m1.1.1.3.3.1.cmml">​</mo><mi id="S4.Ex1.m1.1.1.3.3.8" xref="S4.Ex1.m1.1.1.3.3.8.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.Ex1.m1.1.1.3.3.1f" xref="S4.Ex1.m1.1.1.3.3.1.cmml">​</mo><mi id="S4.Ex1.m1.1.1.3.3.9" xref="S4.Ex1.m1.1.1.3.3.9.cmml">t</mi><mo lspace="0em" rspace="0em" id="S4.Ex1.m1.1.1.3.3.1g" xref="S4.Ex1.m1.1.1.3.3.1.cmml">​</mo><msub id="S4.Ex1.m1.1.1.3.3.10" xref="S4.Ex1.m1.1.1.3.3.10.cmml"><mi id="S4.Ex1.m1.1.1.3.3.10.2" xref="S4.Ex1.m1.1.1.3.3.10.2.cmml">e</mi><mi id="S4.Ex1.m1.1.1.3.3.10.3" xref="S4.Ex1.m1.1.1.3.3.10.3.cmml">i</mi></msub></mrow><mo id="S4.Ex1.m1.1.1.3.1a" xref="S4.Ex1.m1.1.1.3.1.cmml">+</mo><mrow id="S4.Ex1.m1.1.1.3.4" xref="S4.Ex1.m1.1.1.3.4.cmml"><mrow id="S4.Ex1.m1.1.1.3.4.2" xref="S4.Ex1.m1.1.1.3.4.2.cmml"><mi id="S4.Ex1.m1.1.1.3.4.2.2" xref="S4.Ex1.m1.1.1.3.4.2.2.cmml">M</mi><mo id="S4.Ex1.m1.1.1.3.4.2.1" xref="S4.Ex1.m1.1.1.3.4.2.1.cmml">/</mo><mi id="S4.Ex1.m1.1.1.3.4.2.3" xref="S4.Ex1.m1.1.1.3.4.2.3.cmml">D</mi></mrow><mo lspace="0em" rspace="0em" id="S4.Ex1.m1.1.1.3.4.1" xref="S4.Ex1.m1.1.1.3.4.1.cmml">​</mo><msub id="S4.Ex1.m1.1.1.3.4.3" xref="S4.Ex1.m1.1.1.3.4.3.cmml"><mi id="S4.Ex1.m1.1.1.3.4.3.2" xref="S4.Ex1.m1.1.1.3.4.3.2.cmml">L</mi><mi id="S4.Ex1.m1.1.1.3.4.3.3" xref="S4.Ex1.m1.1.1.3.4.3.3.cmml">i</mi></msub></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.Ex1.m1.1b"><apply id="S4.Ex1.m1.1.1.cmml" xref="S4.Ex1.m1.1.1"><eq id="S4.Ex1.m1.1.1.1.cmml" xref="S4.Ex1.m1.1.1.1"></eq><apply id="S4.Ex1.m1.1.1.2.cmml" xref="S4.Ex1.m1.1.1.2"><csymbol cd="ambiguous" id="S4.Ex1.m1.1.1.2.1.cmml" xref="S4.Ex1.m1.1.1.2">subscript</csymbol><ci id="S4.Ex1.m1.1.1.2.2.cmml" xref="S4.Ex1.m1.1.1.2.2">𝑇</ci><ci id="S4.Ex1.m1.1.1.2.3.cmml" xref="S4.Ex1.m1.1.1.2.3">𝑖</ci></apply><apply id="S4.Ex1.m1.1.1.3.cmml" xref="S4.Ex1.m1.1.1.3"><plus id="S4.Ex1.m1.1.1.3.1.cmml" xref="S4.Ex1.m1.1.1.3.1"></plus><apply id="S4.Ex1.m1.1.1.3.2.cmml" xref="S4.Ex1.m1.1.1.3.2"><times id="S4.Ex1.m1.1.1.3.2.1.cmml" xref="S4.Ex1.m1.1.1.3.2.1"></times><apply id="S4.Ex1.m1.1.1.3.2.2.cmml" xref="S4.Ex1.m1.1.1.3.2.2"><divide id="S4.Ex1.m1.1.1.3.2.2.1.cmml" xref="S4.Ex1.m1.1.1.3.2.2.1"></divide><ci id="S4.Ex1.m1.1.1.3.2.2.2.cmml" xref="S4.Ex1.m1.1.1.3.2.2.2">𝑀</ci><ci id="S4.Ex1.m1.1.1.3.2.2.3.cmml" xref="S4.Ex1.m1.1.1.3.2.2.3">𝑈</ci></apply><apply id="S4.Ex1.m1.1.1.3.2.3.cmml" xref="S4.Ex1.m1.1.1.3.2.3"><csymbol cd="ambiguous" id="S4.Ex1.m1.1.1.3.2.3.1.cmml" xref="S4.Ex1.m1.1.1.3.2.3">subscript</csymbol><ci id="S4.Ex1.m1.1.1.3.2.3.2.cmml" xref="S4.Ex1.m1.1.1.3.2.3.2">𝐿</ci><ci id="S4.Ex1.m1.1.1.3.2.3.3.cmml" xref="S4.Ex1.m1.1.1.3.2.3.3">𝑖</ci></apply></apply><apply id="S4.Ex1.m1.1.1.3.3.cmml" xref="S4.Ex1.m1.1.1.3.3"><times id="S4.Ex1.m1.1.1.3.3.1.cmml" xref="S4.Ex1.m1.1.1.3.3.1"></times><apply id="S4.Ex1.m1.1.1.3.3.2.cmml" xref="S4.Ex1.m1.1.1.3.3.2"><divide id="S4.Ex1.m1.1.1.3.3.2.1.cmml" xref="S4.Ex1.m1.1.1.3.3.2.1"></divide><apply id="S4.Ex1.m1.1.1.3.3.2.2.cmml" xref="S4.Ex1.m1.1.1.3.3.2.2"><times id="S4.Ex1.m1.1.1.3.3.2.2.1.cmml" xref="S4.Ex1.m1.1.1.3.3.2.2.1"></times><apply id="S4.Ex1.m1.1.1.3.3.2.2.2.cmml" xref="S4.Ex1.m1.1.1.3.3.2.2.2"><ci id="S4.Ex1.m1.1.1.3.3.2.2.2.1.cmml" xref="S4.Ex1.m1.1.1.3.3.2.2.2.1">⋅</ci><apply id="S4.Ex1.m1.1.1.3.3.2.2.2.2.cmml" xref="S4.Ex1.m1.1.1.3.3.2.2.2.2"><csymbol cd="ambiguous" id="S4.Ex1.m1.1.1.3.3.2.2.2.2.1.cmml" xref="S4.Ex1.m1.1.1.3.3.2.2.2.2">subscript</csymbol><ci id="S4.Ex1.m1.1.1.3.3.2.2.2.2.2.cmml" xref="S4.Ex1.m1.1.1.3.3.2.2.2.2.2">𝑆</ci><ci id="S4.Ex1.m1.1.1.3.3.2.2.2.2.3.cmml" xref="S4.Ex1.m1.1.1.3.3.2.2.2.2.3">𝑖</ci></apply><ci id="S4.Ex1.m1.1.1.3.3.2.2.2.3.cmml" xref="S4.Ex1.m1.1.1.3.3.2.2.2.3">𝐹</ci></apply><ci id="S4.Ex1.m1.1.1.3.3.2.2.3.cmml" xref="S4.Ex1.m1.1.1.3.3.2.2.3">𝑙</ci><ci id="S4.Ex1.m1.1.1.3.3.2.2.4.cmml" xref="S4.Ex1.m1.1.1.3.3.2.2.4">𝑜</ci><ci id="S4.Ex1.m1.1.1.3.3.2.2.5.cmml" xref="S4.Ex1.m1.1.1.3.3.2.2.5">𝑝</ci><ci id="S4.Ex1.m1.1.1.3.3.2.2.6.cmml" xref="S4.Ex1.m1.1.1.3.3.2.2.6">𝑠</ci></apply><ci id="S4.Ex1.m1.1.1.3.3.2.3.cmml" xref="S4.Ex1.m1.1.1.3.3.2.3">𝐹</ci></apply><ci id="S4.Ex1.m1.1.1.3.3.3.cmml" xref="S4.Ex1.m1.1.1.3.3.3">𝑙</ci><ci id="S4.Ex1.m1.1.1.3.3.4.cmml" xref="S4.Ex1.m1.1.1.3.3.4">𝑜</ci><ci id="S4.Ex1.m1.1.1.3.3.5.cmml" xref="S4.Ex1.m1.1.1.3.3.5">𝑝</ci><ci id="S4.Ex1.m1.1.1.3.3.6.cmml" xref="S4.Ex1.m1.1.1.3.3.6">𝑠</ci><ci id="S4.Ex1.m1.1.1.3.3.7.cmml" xref="S4.Ex1.m1.1.1.3.3.7">𝑅</ci><ci id="S4.Ex1.m1.1.1.3.3.8.cmml" xref="S4.Ex1.m1.1.1.3.3.8">𝑎</ci><ci id="S4.Ex1.m1.1.1.3.3.9.cmml" xref="S4.Ex1.m1.1.1.3.3.9">𝑡</ci><apply id="S4.Ex1.m1.1.1.3.3.10.cmml" xref="S4.Ex1.m1.1.1.3.3.10"><csymbol cd="ambiguous" id="S4.Ex1.m1.1.1.3.3.10.1.cmml" xref="S4.Ex1.m1.1.1.3.3.10">subscript</csymbol><ci id="S4.Ex1.m1.1.1.3.3.10.2.cmml" xref="S4.Ex1.m1.1.1.3.3.10.2">𝑒</ci><ci id="S4.Ex1.m1.1.1.3.3.10.3.cmml" xref="S4.Ex1.m1.1.1.3.3.10.3">𝑖</ci></apply></apply><apply id="S4.Ex1.m1.1.1.3.4.cmml" xref="S4.Ex1.m1.1.1.3.4"><times id="S4.Ex1.m1.1.1.3.4.1.cmml" xref="S4.Ex1.m1.1.1.3.4.1"></times><apply id="S4.Ex1.m1.1.1.3.4.2.cmml" xref="S4.Ex1.m1.1.1.3.4.2"><divide id="S4.Ex1.m1.1.1.3.4.2.1.cmml" xref="S4.Ex1.m1.1.1.3.4.2.1"></divide><ci id="S4.Ex1.m1.1.1.3.4.2.2.cmml" xref="S4.Ex1.m1.1.1.3.4.2.2">𝑀</ci><ci id="S4.Ex1.m1.1.1.3.4.2.3.cmml" xref="S4.Ex1.m1.1.1.3.4.2.3">𝐷</ci></apply><apply id="S4.Ex1.m1.1.1.3.4.3.cmml" xref="S4.Ex1.m1.1.1.3.4.3"><csymbol cd="ambiguous" id="S4.Ex1.m1.1.1.3.4.3.1.cmml" xref="S4.Ex1.m1.1.1.3.4.3">subscript</csymbol><ci id="S4.Ex1.m1.1.1.3.4.3.2.cmml" xref="S4.Ex1.m1.1.1.3.4.3.2">𝐿</ci><ci id="S4.Ex1.m1.1.1.3.4.3.3.cmml" xref="S4.Ex1.m1.1.1.3.4.3.3">𝑖</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.Ex1.m1.1c">T_{i}=M/UL_{i}+S_{i}\cdot Flops/FlopsRate_{i}+M/DL_{i}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div id="S4.SS1.p4" class="ltx_para ltx_noindent">
<p id="S4.SS1.p4.1" class="ltx_p">There are different faithful methods to measure network bandwidth and FLOPS. Measuring bandwidth has been an active research topic for a long time. There are active ways to measure bandwidth such as speed tests and probe trains <cite class="ltx_cite ltx_citemacro_cite">Choi et al. (<a href="#bib.bib8" title="" class="ltx_ref">1998</a>)</cite>. There are passive mechanisms as well that estimate bandwidth based on network usage, e.g. client hints <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib10" title="" class="ltx_ref">Google </a></cite>, CRAB <cite class="ltx_cite ltx_citemacro_cite">Tahir and Mittal (<a href="#bib.bib28" title="" class="ltx_ref">2023</a>)</cite>. Similarly, there are different benchmarks to measure FLOPS as a proxy of compute capability e.g. Linpack <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib20" title="" class="ltx_ref">LINPACK </a></cite> and HPL <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib12" title="" class="ltx_ref">HPL - A Portable Implementation of the High-Performance Linpack
Benchmark for Distributed-Memory Computers </a></cite>. Additionally, these estimates of compute capability can be improved with real-time observations of the time taken to run a training round. The mechanisms to track mentioned metrics are not the contribution of our work, and we rely on existing work for this.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Smart Client Selection</h3>

<div id="S4.SS2.p1" class="ltx_para ltx_noindent">
<p id="S4.SS2.p1.2" class="ltx_p">After getting the client round time estimate, <math id="S4.SS2.p1.1.m1.1" class="ltx_Math" alttext="T_{i}" display="inline"><semantics id="S4.SS2.p1.1.m1.1a"><msub id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml"><mi id="S4.SS2.p1.1.m1.1.1.2" xref="S4.SS2.p1.1.m1.1.1.2.cmml">T</mi><mi id="S4.SS2.p1.1.m1.1.1.3" xref="S4.SS2.p1.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><apply id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.1.m1.1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1">subscript</csymbol><ci id="S4.SS2.p1.1.m1.1.1.2.cmml" xref="S4.SS2.p1.1.m1.1.1.2">𝑇</ci><ci id="S4.SS2.p1.1.m1.1.1.3.cmml" xref="S4.SS2.p1.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">T_{i}</annotation></semantics></math> for most of the clients, we are ready to run our clustering algorithm. The clustering algorithm takes the number of clusters as an input, and based on it, decides the percentiles of the distribution. For example, if the number of clusters is 3, the selected percentiles would be 25, 50, and 75. Clients are sorted into these clusters based on their <math id="S4.SS2.p1.2.m2.1" class="ltx_Math" alttext="T_{i}" display="inline"><semantics id="S4.SS2.p1.2.m2.1a"><msub id="S4.SS2.p1.2.m2.1.1" xref="S4.SS2.p1.2.m2.1.1.cmml"><mi id="S4.SS2.p1.2.m2.1.1.2" xref="S4.SS2.p1.2.m2.1.1.2.cmml">T</mi><mi id="S4.SS2.p1.2.m2.1.1.3" xref="S4.SS2.p1.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.2.m2.1b"><apply id="S4.SS2.p1.2.m2.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.2.m2.1.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1">subscript</csymbol><ci id="S4.SS2.p1.2.m2.1.1.2.cmml" xref="S4.SS2.p1.2.m2.1.1.2">𝑇</ci><ci id="S4.SS2.p1.2.m2.1.1.3.cmml" xref="S4.SS2.p1.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.2.m2.1c">T_{i}</annotation></semantics></math>’s mean-squared distance from percentile values. Since the purpose of this clustering is to group together clients with almost similar training times, equidistant percentile-based centroids serve this purpose reasonably well.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para ltx_noindent">
<p id="S4.SS2.p2.1" class="ltx_p">The clusters constructed this way tend to have an uneven distribution of clients. The clusters with a shorter average training time tend to have the most number of clients compared to clusters with a higher average training time. This means if we have a round-robin pattern of switching between clusters for each training round, the clients in larger clusters have a smaller probability of selection. Our strawman solution to this problem was to construct a weighted round-robin scheduling where the weight is based on the cluster size. For example, assume the cluster sizes(out of the total number) are 50%, 25%, and 25% for clusters A, B, and C. The scheduling pattern would be (A, A, B, C), where cluster A is selected for two rounds compared to the others.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para ltx_noindent">
<p id="S4.SS2.p3.1" class="ltx_p">However, we realize that having different-sized clusters also means that clients have varying degrees of privacy. Assuming a malicious federated averaging server, it is easier to deanonymize a participating client in a smaller cluster than a larger one. Thus, another goal of our clustering algorithm is to build clusters of roughly the same size to ensure that the clustering algorithm does not impart any partiality when it comes to privacy.</p>
</div>
<div id="S4.SS2.p4" class="ltx_para ltx_noindent">
<p id="S4.SS2.p4.1" class="ltx_p">We leverage a simple insight to even out clusters created by our algorithm. As we observed that the slow client clusters tend to have fewer clients. We pick the slowest clients from the fast client cluster and migrate them to the slow cluster until sizes are almost evened out. The inverse of this can also be done if the fast client cluster is smaller, but we should be careful so that shifting clients from a slower cluster does not have a very drastic effect.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Optimal Number of Clusters</h3>

<div id="S4.SS3.p1" class="ltx_para ltx_noindent">
<p id="S4.SS3.p1.1" class="ltx_p">As we pointed out in <a href="#S4.SS2" title="4.2 Smart Client Selection ‣ 4 System Design" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>, the standalone client selection algorithm requires the number of clusters as an argument. However, it can be difficult for the operator to know this. Thus, we solve for the optimal value of it. Having fewer clusters is desirable from the perspective of privacy, whereas more clusters result in a shorter average round time. However, the average round time has diminishing returns as we keep increasing the number of clusters. The optimal number of clusters would be the point after which we see diminishing improvement in the average round time.</p>
</div>
<figure id="S4.F3" class="ltx_figure"><img src="/html/2207.04569/assets/x5.png" id="S4.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="259" height="165" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Visualization of the process behind finding the optimal number of clusters (6 in both cases). Also worth noticing is superior efficiency of FedSS’s clustering algorithm compared to KMeans.</figcaption>
</figure>
<div id="S4.SS3.p2" class="ltx_para ltx_noindent">
<p id="S4.SS3.p2.1" class="ltx_p">Thus, to find the optimal number of clusters, we simulate the training process given round-time estimates of clients with different values of clusters. This gives us the average round time for the given number of clusters. Then, we use Kneedle <cite class="ltx_cite ltx_citemacro_cite">Satopaa et al. (<a href="#bib.bib26" title="" class="ltx_ref">2011</a>)</cite> to find the optimal point on the curve of average round time vs. 1/cluster size. The Fig.<a href="#S4.F3" title="Figure 3 ‣ 4.3 Optimal Number of Clusters ‣ 4 System Design" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> shows the curve between average round time and 1/cluster size along with the knee point found by the Kneedle algorithm.</p>
</div>
<div id="S4.SS3.p3" class="ltx_para ltx_noindent">
<p id="S4.SS3.p3.1" class="ltx_p">Fig.<a href="#S4.F3" title="Figure 3 ‣ 4.3 Optimal Number of Clusters ‣ 4 System Design" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> also compares the effectiveness of our algorithm as compared to KMeans. This is the simulation of training with 10000 clients and 1000 rounds of training. We also compared it against DBScan and KDE clustering, which had almost similar curve as KMeans. The reason our clustering algorithm does better is that it is optimized to reduce round time. Whereas Kmeans and other clustering algorithms are specialized to just cluster data, these clusters may not be optimal with respect to reducing round time. Moreover, it is difficult for clustering algorithms to construct equal-sized clusters.</p>
</div>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Overhead</h3>

<div id="S4.SS4.p1" class="ltx_para ltx_noindent">
<p id="S4.SS4.p1.3" class="ltx_p">This grouping algorithm has a time complexity of <math id="S4.SS4.p1.1.m1.1" class="ltx_Math" alttext="NlogN" display="inline"><semantics id="S4.SS4.p1.1.m1.1a"><mrow id="S4.SS4.p1.1.m1.1.1" xref="S4.SS4.p1.1.m1.1.1.cmml"><mi id="S4.SS4.p1.1.m1.1.1.2" xref="S4.SS4.p1.1.m1.1.1.2.cmml">N</mi><mo lspace="0em" rspace="0em" id="S4.SS4.p1.1.m1.1.1.1" xref="S4.SS4.p1.1.m1.1.1.1.cmml">​</mo><mi id="S4.SS4.p1.1.m1.1.1.3" xref="S4.SS4.p1.1.m1.1.1.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S4.SS4.p1.1.m1.1.1.1a" xref="S4.SS4.p1.1.m1.1.1.1.cmml">​</mo><mi id="S4.SS4.p1.1.m1.1.1.4" xref="S4.SS4.p1.1.m1.1.1.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.SS4.p1.1.m1.1.1.1b" xref="S4.SS4.p1.1.m1.1.1.1.cmml">​</mo><mi id="S4.SS4.p1.1.m1.1.1.5" xref="S4.SS4.p1.1.m1.1.1.5.cmml">g</mi><mo lspace="0em" rspace="0em" id="S4.SS4.p1.1.m1.1.1.1c" xref="S4.SS4.p1.1.m1.1.1.1.cmml">​</mo><mi id="S4.SS4.p1.1.m1.1.1.6" xref="S4.SS4.p1.1.m1.1.1.6.cmml">N</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.1.m1.1b"><apply id="S4.SS4.p1.1.m1.1.1.cmml" xref="S4.SS4.p1.1.m1.1.1"><times id="S4.SS4.p1.1.m1.1.1.1.cmml" xref="S4.SS4.p1.1.m1.1.1.1"></times><ci id="S4.SS4.p1.1.m1.1.1.2.cmml" xref="S4.SS4.p1.1.m1.1.1.2">𝑁</ci><ci id="S4.SS4.p1.1.m1.1.1.3.cmml" xref="S4.SS4.p1.1.m1.1.1.3">𝑙</ci><ci id="S4.SS4.p1.1.m1.1.1.4.cmml" xref="S4.SS4.p1.1.m1.1.1.4">𝑜</ci><ci id="S4.SS4.p1.1.m1.1.1.5.cmml" xref="S4.SS4.p1.1.m1.1.1.5">𝑔</ci><ci id="S4.SS4.p1.1.m1.1.1.6.cmml" xref="S4.SS4.p1.1.m1.1.1.6">𝑁</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.1.m1.1c">NlogN</annotation></semantics></math>, where <math id="S4.SS4.p1.2.m2.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S4.SS4.p1.2.m2.1a"><mi id="S4.SS4.p1.2.m2.1.1" xref="S4.SS4.p1.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.2.m2.1b"><ci id="S4.SS4.p1.2.m2.1.1.cmml" xref="S4.SS4.p1.2.m2.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.2.m2.1c">N</annotation></semantics></math> is the total number of client devices. Finding the optimal number of clusters can be costly if the number of clients is quite high. But this computation can be bounded by limiting the maximum number of clusters to try. For example, it is not desirable to have tens of clusters for only 100 clients. Moreover, the whole algorithm can be run in parallel with model training and a new schedule can be used from the next round onwards. Network conditions as well as training time can vary over time depending on factors like competing traffic, memory, or compute back pressure. Therefore, it is desirable to run the grouping algorithm periodically on updated estimates of <math id="S4.SS4.p1.3.m3.1" class="ltx_Math" alttext="T_{i}" display="inline"><semantics id="S4.SS4.p1.3.m3.1a"><msub id="S4.SS4.p1.3.m3.1.1" xref="S4.SS4.p1.3.m3.1.1.cmml"><mi id="S4.SS4.p1.3.m3.1.1.2" xref="S4.SS4.p1.3.m3.1.1.2.cmml">T</mi><mi id="S4.SS4.p1.3.m3.1.1.3" xref="S4.SS4.p1.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.3.m3.1b"><apply id="S4.SS4.p1.3.m3.1.1.cmml" xref="S4.SS4.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS4.p1.3.m3.1.1.1.cmml" xref="S4.SS4.p1.3.m3.1.1">subscript</csymbol><ci id="S4.SS4.p1.3.m3.1.1.2.cmml" xref="S4.SS4.p1.3.m3.1.1.2">𝑇</ci><ci id="S4.SS4.p1.3.m3.1.1.3.cmml" xref="S4.SS4.p1.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.3.m3.1c">T_{i}</annotation></semantics></math>.</p>
</div>
<div id="S4.SS4.p2" class="ltx_para ltx_noindent">
<p id="S4.SS4.p2.1" class="ltx_p">In our experimental implementation, we did not implement mechanisms to measure bandwidth and profile FLOPS because our experiments are simulation-based. However, existing mechanisms to do so are very lightweight and do not have significant overhead. Similarly, the profiling of FLOPS can be done by measuring the time to train a round.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Implementation</h2>

<figure id="S5.F4" class="ltx_figure"><img src="/html/2207.04569/assets/x6.png" id="S5.F4.g1" class="ltx_graphics ltx_centering ltx_img_square" width="259" height="251" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>The RPC-based communication protocol</figcaption>
</figure>
<div id="S5.p1" class="ltx_para ltx_noindent">
<p id="S5.p1.1" class="ltx_p">Based on an open-source federated learning benchmark system leaf<cite class="ltx_cite ltx_citemacro_cite">Caldas et al. (<a href="#bib.bib4" title="" class="ltx_ref">2018</a>)</cite>, we implemented FedSS by writing a RPC-based communication protocol and scheduling logic. We emulate the real federated learning by doing distributed computations in multiple processes on a single machine.</p>
</div>
<div id="S5.p2" class="ltx_para ltx_noindent">
<p id="S5.p2.2" class="ltx_p">Fig.<a href="#S5.F4" title="Figure 4 ‣ 5 Implementation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> illustrates the communication protocol in detail. The coordinator thread in the server asynchronously sends RPC commands to <math id="S5.p2.1.m1.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S5.p2.1.m1.1a"><mi id="S5.p2.1.m1.1.1" xref="S5.p2.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S5.p2.1.m1.1b"><ci id="S5.p2.1.m1.1.1.cmml" xref="S5.p2.1.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.1.m1.1c">K</annotation></semantics></math> selected clients for training with its local data, while the server thread keeps listening to clients’ requests to upload the updated models. After the client finishes training, the server thread receives results and increments a shared variable <span id="S5.p2.2.1" class="ltx_text ltx_font_italic">acked</span> by one. The coordinator thread waits until <span id="S5.p2.2.2" class="ltx_text ltx_font_italic">acked</span> equals <math id="S5.p2.2.m2.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S5.p2.2.m2.1a"><mi id="S5.p2.2.m2.1.1" xref="S5.p2.2.m2.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S5.p2.2.m2.1b"><ci id="S5.p2.2.m2.1.1.cmml" xref="S5.p2.2.m2.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.2.m2.1c">K</annotation></semantics></math> to continue the aggregation step and finish this round.</p>
</div>
<div id="S5.p3" class="ltx_para ltx_noindent">
<p id="S5.p3.1" class="ltx_p">To simulate the variable network, we use Internet Speeds Data from World Population Review <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib29" title="" class="ltx_ref">World Population Review </a></cite>. We also simulated the computation time needed for training based on the benchmarked FLOPS <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib13" title="" class="ltx_ref">iconcharts </a></cite> of the top 20 most sold mobile phones in 2020 <cite class="ltx_cite ltx_citemacro_cite">Yordan (<a href="#bib.bib32" title="" class="ltx_ref">2020</a>)</cite>.</p>
</div>
<figure id="S5.F5" class="ltx_figure"><img src="/html/2207.04569/assets/Figures/latest/time.png" id="S5.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="337" height="253" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>The total time taken by FedSS, FedCS and Random Selection to train 2800 rounds.</figcaption>
</figure>
<figure id="S5.F6" class="ltx_figure"><img src="/html/2207.04569/assets/Figures/latest/time_cdf.png" id="S5.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="337" height="253" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>CDF of time taken per round for FedSS, FedCS and Random Selection.</figcaption>
</figure>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Evaluation</h2>

<div id="S6.p1" class="ltx_para ltx_noindent">
<p id="S6.p1.1" class="ltx_p">We evaluate FedSS against our implementation of FedCS and random client selection. We train a CNN model on the Femnist dataset, which is distributed in a Non-IID manner across 20 clients. Initially, we aimed to run our experiments with a much larger number of clients, but it’s not possible to run so many instances of concurrent CNN models with our limited computation resources. For FedSS and random client selection, we set the number of clients per round to 5. For FedCS, we select 8 clients per round but aggregate updates with the first 5 responses. To cover system and network heterogeneity, we simulate random delays for different clients. However, to ensure fairness between our system and benchmarks, the same delay configurations are used for clients across all our experiments. Similarly, the same distribution of datasets between clients is used across our experiments.</p>
</div>
<div id="S6.p2" class="ltx_para ltx_noindent">
<p id="S6.p2.1" class="ltx_p">We explored different metrics to evaluate our system. Since our trade-off is between training time and bias, we primarily focus on metrics to capture these two.</p>
</div>
<section id="S6.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1 </span>Training Time</h3>

<div id="S6.SS1.p1" class="ltx_para ltx_noindent">
<p id="S6.SS1.p1.1" class="ltx_p">Measuring training time is easy, we can individually measure the time taken to complete one round of training at the server. This time would include time taken to send the model to all clients concurrently, and time taken by the clients to train and send back the gradients. This process is bottlenecked by the slowest client accepted by the server for aggregation. Thus, time per each round is measured by the time taken by the slowest client to receive, train and send back the model.</p>
</div>
<div id="S6.SS1.p2" class="ltx_para ltx_noindent">
<p id="S6.SS1.p2.1" class="ltx_p">Fig.<a href="#S5.F5" title="Figure 5 ‣ 5 Implementation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> shows the total time taken by FedSS and benchmarks to run 2800 rounds of training. FedCS beats our system by approximately 26% because it only waits for the fastest clients to send back the gradients in every round.
On the other hand, Random Selection has the longest training time, since the time taken per round, in this case, is straggled by the slowest client. FedSS achieves 1.6<math id="S6.SS1.p2.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S6.SS1.p2.1.m1.1a"><mo id="S6.SS1.p2.1.m1.1.1" xref="S6.SS1.p2.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S6.SS1.p2.1.m1.1b"><times id="S6.SS1.p2.1.m1.1.1.cmml" xref="S6.SS1.p2.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p2.1.m1.1c">\times</annotation></semantics></math> shorter training time than Random Selection. This improvement is possible because of the optimal client clustering according to the training time.</p>
</div>
<div id="S6.SS1.p3" class="ltx_para ltx_noindent">
<p id="S6.SS1.p3.1" class="ltx_p">It seems that the training time of all systems is linear to the number of rounds in Fig.<a href="#S5.F5" title="Figure 5 ‣ 5 Implementation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>. This is due to too many data points and doesn’t indicate that the training time of every round is similar. Fig.<a href="#S5.F6" title="Figure 6 ‣ 5 Implementation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> shows the CDF of training time per round for all systems. Steps in the line for FedSS show different training times for different clusters (3 clusters in this particular case). FedSS, which selects clients with similar training time together, is able to finish 80% of the rounds faster than Random and save around 40 hours.</p>
</div>
<figure id="S6.F7" class="ltx_figure"><img src="/html/2207.04569/assets/Figures/latest/train_accuracy.png" id="S6.F7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="337" height="253" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>The average accuracy of the global model for FedSS, FedCS and Random Selection.</figcaption>
</figure>
<figure id="S6.F8" class="ltx_figure"><img src="/html/2207.04569/assets/Figures/latest/train_loss.png" id="S6.F8.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="337" height="253" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>The average loss of the global model for FedSS, FedCS and Random Selection.</figcaption>
</figure>
</section>
<section id="S6.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2 </span>Bias</h3>

<div id="S6.SS2.p1" class="ltx_para ltx_noindent">
<p id="S6.SS2.p1.1" class="ltx_p">Before measuring bias, let’s take a look at the performance of the global model after 2800 rounds for each of the selection strategies. There are many well-established evaluation metrics for classification models including precision, recall, accuracy, F1-score, etc. For our evaluation, we select accuracy and F1-score as the metrics.</p>
</div>
<section id="S6.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">6.2.1 </span>Accuracy</h4>

<div id="S6.SS2.SSS1.p1" class="ltx_para ltx_noindent">
<p id="S6.SS2.SSS1.p1.1" class="ltx_p">Accuracy is the metric to determine the correct prediction ratio for the given dataset. It is calculated as :</p>
<table id="S6.Ex2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S6.Ex2.m1.1" class="ltx_Math" alttext="\frac{TP+TN}{TP+TN+FP+FN}" display="block"><semantics id="S6.Ex2.m1.1a"><mfrac id="S6.Ex2.m1.1.1" xref="S6.Ex2.m1.1.1.cmml"><mrow id="S6.Ex2.m1.1.1.2" xref="S6.Ex2.m1.1.1.2.cmml"><mrow id="S6.Ex2.m1.1.1.2.2" xref="S6.Ex2.m1.1.1.2.2.cmml"><mi id="S6.Ex2.m1.1.1.2.2.2" xref="S6.Ex2.m1.1.1.2.2.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S6.Ex2.m1.1.1.2.2.1" xref="S6.Ex2.m1.1.1.2.2.1.cmml">​</mo><mi id="S6.Ex2.m1.1.1.2.2.3" xref="S6.Ex2.m1.1.1.2.2.3.cmml">P</mi></mrow><mo id="S6.Ex2.m1.1.1.2.1" xref="S6.Ex2.m1.1.1.2.1.cmml">+</mo><mrow id="S6.Ex2.m1.1.1.2.3" xref="S6.Ex2.m1.1.1.2.3.cmml"><mi id="S6.Ex2.m1.1.1.2.3.2" xref="S6.Ex2.m1.1.1.2.3.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S6.Ex2.m1.1.1.2.3.1" xref="S6.Ex2.m1.1.1.2.3.1.cmml">​</mo><mi id="S6.Ex2.m1.1.1.2.3.3" xref="S6.Ex2.m1.1.1.2.3.3.cmml">N</mi></mrow></mrow><mrow id="S6.Ex2.m1.1.1.3" xref="S6.Ex2.m1.1.1.3.cmml"><mrow id="S6.Ex2.m1.1.1.3.2" xref="S6.Ex2.m1.1.1.3.2.cmml"><mi id="S6.Ex2.m1.1.1.3.2.2" xref="S6.Ex2.m1.1.1.3.2.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S6.Ex2.m1.1.1.3.2.1" xref="S6.Ex2.m1.1.1.3.2.1.cmml">​</mo><mi id="S6.Ex2.m1.1.1.3.2.3" xref="S6.Ex2.m1.1.1.3.2.3.cmml">P</mi></mrow><mo id="S6.Ex2.m1.1.1.3.1" xref="S6.Ex2.m1.1.1.3.1.cmml">+</mo><mrow id="S6.Ex2.m1.1.1.3.3" xref="S6.Ex2.m1.1.1.3.3.cmml"><mi id="S6.Ex2.m1.1.1.3.3.2" xref="S6.Ex2.m1.1.1.3.3.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S6.Ex2.m1.1.1.3.3.1" xref="S6.Ex2.m1.1.1.3.3.1.cmml">​</mo><mi id="S6.Ex2.m1.1.1.3.3.3" xref="S6.Ex2.m1.1.1.3.3.3.cmml">N</mi></mrow><mo id="S6.Ex2.m1.1.1.3.1a" xref="S6.Ex2.m1.1.1.3.1.cmml">+</mo><mrow id="S6.Ex2.m1.1.1.3.4" xref="S6.Ex2.m1.1.1.3.4.cmml"><mi id="S6.Ex2.m1.1.1.3.4.2" xref="S6.Ex2.m1.1.1.3.4.2.cmml">F</mi><mo lspace="0em" rspace="0em" id="S6.Ex2.m1.1.1.3.4.1" xref="S6.Ex2.m1.1.1.3.4.1.cmml">​</mo><mi id="S6.Ex2.m1.1.1.3.4.3" xref="S6.Ex2.m1.1.1.3.4.3.cmml">P</mi></mrow><mo id="S6.Ex2.m1.1.1.3.1b" xref="S6.Ex2.m1.1.1.3.1.cmml">+</mo><mrow id="S6.Ex2.m1.1.1.3.5" xref="S6.Ex2.m1.1.1.3.5.cmml"><mi id="S6.Ex2.m1.1.1.3.5.2" xref="S6.Ex2.m1.1.1.3.5.2.cmml">F</mi><mo lspace="0em" rspace="0em" id="S6.Ex2.m1.1.1.3.5.1" xref="S6.Ex2.m1.1.1.3.5.1.cmml">​</mo><mi id="S6.Ex2.m1.1.1.3.5.3" xref="S6.Ex2.m1.1.1.3.5.3.cmml">N</mi></mrow></mrow></mfrac><annotation-xml encoding="MathML-Content" id="S6.Ex2.m1.1b"><apply id="S6.Ex2.m1.1.1.cmml" xref="S6.Ex2.m1.1.1"><divide id="S6.Ex2.m1.1.1.1.cmml" xref="S6.Ex2.m1.1.1"></divide><apply id="S6.Ex2.m1.1.1.2.cmml" xref="S6.Ex2.m1.1.1.2"><plus id="S6.Ex2.m1.1.1.2.1.cmml" xref="S6.Ex2.m1.1.1.2.1"></plus><apply id="S6.Ex2.m1.1.1.2.2.cmml" xref="S6.Ex2.m1.1.1.2.2"><times id="S6.Ex2.m1.1.1.2.2.1.cmml" xref="S6.Ex2.m1.1.1.2.2.1"></times><ci id="S6.Ex2.m1.1.1.2.2.2.cmml" xref="S6.Ex2.m1.1.1.2.2.2">𝑇</ci><ci id="S6.Ex2.m1.1.1.2.2.3.cmml" xref="S6.Ex2.m1.1.1.2.2.3">𝑃</ci></apply><apply id="S6.Ex2.m1.1.1.2.3.cmml" xref="S6.Ex2.m1.1.1.2.3"><times id="S6.Ex2.m1.1.1.2.3.1.cmml" xref="S6.Ex2.m1.1.1.2.3.1"></times><ci id="S6.Ex2.m1.1.1.2.3.2.cmml" xref="S6.Ex2.m1.1.1.2.3.2">𝑇</ci><ci id="S6.Ex2.m1.1.1.2.3.3.cmml" xref="S6.Ex2.m1.1.1.2.3.3">𝑁</ci></apply></apply><apply id="S6.Ex2.m1.1.1.3.cmml" xref="S6.Ex2.m1.1.1.3"><plus id="S6.Ex2.m1.1.1.3.1.cmml" xref="S6.Ex2.m1.1.1.3.1"></plus><apply id="S6.Ex2.m1.1.1.3.2.cmml" xref="S6.Ex2.m1.1.1.3.2"><times id="S6.Ex2.m1.1.1.3.2.1.cmml" xref="S6.Ex2.m1.1.1.3.2.1"></times><ci id="S6.Ex2.m1.1.1.3.2.2.cmml" xref="S6.Ex2.m1.1.1.3.2.2">𝑇</ci><ci id="S6.Ex2.m1.1.1.3.2.3.cmml" xref="S6.Ex2.m1.1.1.3.2.3">𝑃</ci></apply><apply id="S6.Ex2.m1.1.1.3.3.cmml" xref="S6.Ex2.m1.1.1.3.3"><times id="S6.Ex2.m1.1.1.3.3.1.cmml" xref="S6.Ex2.m1.1.1.3.3.1"></times><ci id="S6.Ex2.m1.1.1.3.3.2.cmml" xref="S6.Ex2.m1.1.1.3.3.2">𝑇</ci><ci id="S6.Ex2.m1.1.1.3.3.3.cmml" xref="S6.Ex2.m1.1.1.3.3.3">𝑁</ci></apply><apply id="S6.Ex2.m1.1.1.3.4.cmml" xref="S6.Ex2.m1.1.1.3.4"><times id="S6.Ex2.m1.1.1.3.4.1.cmml" xref="S6.Ex2.m1.1.1.3.4.1"></times><ci id="S6.Ex2.m1.1.1.3.4.2.cmml" xref="S6.Ex2.m1.1.1.3.4.2">𝐹</ci><ci id="S6.Ex2.m1.1.1.3.4.3.cmml" xref="S6.Ex2.m1.1.1.3.4.3">𝑃</ci></apply><apply id="S6.Ex2.m1.1.1.3.5.cmml" xref="S6.Ex2.m1.1.1.3.5"><times id="S6.Ex2.m1.1.1.3.5.1.cmml" xref="S6.Ex2.m1.1.1.3.5.1"></times><ci id="S6.Ex2.m1.1.1.3.5.2.cmml" xref="S6.Ex2.m1.1.1.3.5.2">𝐹</ci><ci id="S6.Ex2.m1.1.1.3.5.3.cmml" xref="S6.Ex2.m1.1.1.3.5.3">𝑁</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.Ex2.m1.1c">\frac{TP+TN}{TP+TN+FP+FN}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div id="S6.SS2.SSS1.p2" class="ltx_para ltx_noindent">
<p id="S6.SS2.SSS1.p2.1" class="ltx_p">Fig.<a href="#S6.F7" title="Figure 7 ‣ 6.1 Training Time ‣ 6 Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> &amp; <a href="#S6.F8" title="Figure 8 ‣ 6.1 Training Time ‣ 6 Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> respectively show the average accuracy and loss of the global model across all clients. From the first look, it seems as if all the strategies have similar performance with respect to model validity. However, a deeper look at the model’s metrics shows a clearer picture.</p>
</div>
<figure id="S6.T1" class="ltx_table">
<table id="S6.T1.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S6.T1.1.1.1" class="ltx_tr">
<th id="S6.T1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" colspan="4">Accuracy for 4 Slowest Clients</th>
<th id="S6.T1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" colspan="4">Accuracy for 4 Fastest Clients</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S6.T1.1.2.1" class="ltx_tr">
<th id="S6.T1.1.2.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">Client</th>
<td id="S6.T1.1.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">FedCS</td>
<td id="S6.T1.1.2.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<table id="S6.T1.1.2.1.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S6.T1.1.2.1.3.1.1" class="ltx_tr">
<td id="S6.T1.1.2.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Random</td>
</tr>
<tr id="S6.T1.1.2.1.3.1.2" class="ltx_tr">
<td id="S6.T1.1.2.1.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">Selection</td>
</tr>
</table>
</td>
<td id="S6.T1.1.2.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">FedSS</td>
<th id="S6.T1.1.2.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">Client</th>
<td id="S6.T1.1.2.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">FedCS</td>
<td id="S6.T1.1.2.1.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<table id="S6.T1.1.2.1.7.1" class="ltx_tabular ltx_align_middle">
<tr id="S6.T1.1.2.1.7.1.1" class="ltx_tr">
<td id="S6.T1.1.2.1.7.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Random</td>
</tr>
<tr id="S6.T1.1.2.1.7.1.2" class="ltx_tr">
<td id="S6.T1.1.2.1.7.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">Selection</td>
</tr>
</table>
</td>
<td id="S6.T1.1.2.1.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">FedSS</td>
</tr>
<tr id="S6.T1.1.3.2" class="ltx_tr">
<th id="S6.T1.1.3.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">1</th>
<td id="S6.T1.1.3.2.2" class="ltx_td ltx_align_center ltx_border_t">68.76</td>
<td id="S6.T1.1.3.2.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T1.1.3.2.3.1" class="ltx_text ltx_font_bold">80.12</span></td>
<td id="S6.T1.1.3.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">79.81</td>
<th id="S6.T1.1.3.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">1</th>
<td id="S6.T1.1.3.2.6" class="ltx_td ltx_align_center ltx_border_t">83.28</td>
<td id="S6.T1.1.3.2.7" class="ltx_td ltx_align_center ltx_border_t">85.92</td>
<td id="S6.T1.1.3.2.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S6.T1.1.3.2.8.1" class="ltx_text ltx_font_bold">86.80</span></td>
</tr>
<tr id="S6.T1.1.4.3" class="ltx_tr">
<th id="S6.T1.1.4.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r">2</th>
<td id="S6.T1.1.4.3.2" class="ltx_td ltx_align_center">72.34</td>
<td id="S6.T1.1.4.3.3" class="ltx_td ltx_align_center">76.17</td>
<td id="S6.T1.1.4.3.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S6.T1.1.4.3.4.1" class="ltx_text ltx_font_bold">76.59</span></td>
<th id="S6.T1.1.4.3.5" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">2</th>
<td id="S6.T1.1.4.3.6" class="ltx_td ltx_align_center">55.97</td>
<td id="S6.T1.1.4.3.7" class="ltx_td ltx_align_center">55.97</td>
<td id="S6.T1.1.4.3.8" class="ltx_td ltx_align_center ltx_border_r"><span id="S6.T1.1.4.3.8.1" class="ltx_text ltx_font_bold">60.37</span></td>
</tr>
<tr id="S6.T1.1.5.4" class="ltx_tr">
<th id="S6.T1.1.5.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r">3</th>
<td id="S6.T1.1.5.4.2" class="ltx_td ltx_align_center">56.68</td>
<td id="S6.T1.1.5.4.3" class="ltx_td ltx_align_center">67.51</td>
<td id="S6.T1.1.5.4.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S6.T1.1.5.4.4.1" class="ltx_text ltx_font_bold">71.33</span></td>
<th id="S6.T1.1.5.4.5" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">3</th>
<td id="S6.T1.1.5.4.6" class="ltx_td ltx_align_center"><span id="S6.T1.1.5.4.6.1" class="ltx_text ltx_font_bold">80.07</span></td>
<td id="S6.T1.1.5.4.7" class="ltx_td ltx_align_center">76.56</td>
<td id="S6.T1.1.5.4.8" class="ltx_td ltx_align_center ltx_border_r">78.90</td>
</tr>
<tr id="S6.T1.1.6.5" class="ltx_tr">
<th id="S6.T1.1.6.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r">4</th>
<td id="S6.T1.1.6.5.2" class="ltx_td ltx_align_center">67.32</td>
<td id="S6.T1.1.6.5.3" class="ltx_td ltx_align_center"><span id="S6.T1.1.6.5.3.1" class="ltx_text ltx_font_bold">71.25</span></td>
<td id="S6.T1.1.6.5.4" class="ltx_td ltx_align_center ltx_border_r">70.86</td>
<th id="S6.T1.1.6.5.5" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">4</th>
<td id="S6.T1.1.6.5.6" class="ltx_td ltx_align_center"><span id="S6.T1.1.6.5.6.1" class="ltx_text ltx_font_bold">84.88</span></td>
<td id="S6.T1.1.6.5.7" class="ltx_td ltx_align_center">79.42</td>
<td id="S6.T1.1.6.5.8" class="ltx_td ltx_align_center ltx_border_r">78.13</td>
</tr>
<tr id="S6.T1.1.7.6" class="ltx_tr">
<th id="S6.T1.1.7.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t">Average</th>
<td id="S6.T1.1.7.6.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">66.27</td>
<td id="S6.T1.1.7.6.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">73.76</td>
<td id="S6.T1.1.7.6.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S6.T1.1.7.6.4.1" class="ltx_text ltx_font_bold">74.65</span></td>
<th id="S6.T1.1.7.6.5" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t">Average</th>
<td id="S6.T1.1.7.6.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S6.T1.1.7.6.6.1" class="ltx_text ltx_font_bold">76.05</span></td>
<td id="S6.T1.1.7.6.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">74.47</td>
<td id="S6.T1.1.7.6.8" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S6.T1.1.7.6.8.1" class="ltx_text ltx_font_bold">76.05</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>A breakdown of the accuracy of the model across 4 slowest and 4 fastest clients for each of the selection strategies.</figcaption>
</figure>
<div id="S6.SS2.SSS1.p3" class="ltx_para ltx_noindent">
<p id="S6.SS2.SSS1.p3.1" class="ltx_p">Table<a href="#S6.T1" title="Table 1 ‣ 6.2.1 Accuracy ‣ 6.2 Bias ‣ 6 Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> shows the breakdown of the accuracy of the model across different kinds of clients. We notice that while FedCS has an average accuracy as good as Random Selection and FedSS, it has lower accuracy for slower clients. On the other hand, its accuracy for faster clients is similar to both Random Selection and FedSS. This difference in performance on slow clients captures the bias in FedCS’s client selection strategy. Fast clients end up getting a lot more training opportunities than slow clients.</p>
</div>
<div id="S6.SS2.SSS1.p4" class="ltx_para ltx_noindent">
<p id="S6.SS2.SSS1.p4.1" class="ltx_p">The 1.5% accuracy difference between FedSS and Random Selection, although negligible, can be explained from a data heterogeneity point of view. Recall that Random Selection by design does not have any explicit bias due to device heterogeneity. This is because Random Selection selects clients randomly and then waits for all of them to respond before aggregating. Thus, the 1% difference in its accuracy when compared to faster vs slower clients, can solely be attributed to data heterogeneity. The fact that FedSS does as good as Random Selection while reducing the training time by a huge margin shows promise that FedSS can reduce bias and amortize the cost of slow nodes.
</p>
</div>
</section>
<section id="S6.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">6.2.2 </span>F1 Score</h4>

<div id="S6.SS2.SSS2.p1" class="ltx_para ltx_noindent">
<p id="S6.SS2.SSS2.p1.1" class="ltx_p">F1-score is a metric to determine model performance by using both, precision and recall values. Precision is the metric to determine the percentage of correct results out of all the results for a given class. It is given as :</p>
<table id="S6.Ex3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S6.Ex3.m1.1" class="ltx_Math" alttext="TP/(TP+FP)" display="block"><semantics id="S6.Ex3.m1.1a"><mrow id="S6.Ex3.m1.1.1" xref="S6.Ex3.m1.1.1.cmml"><mrow id="S6.Ex3.m1.1.1.3" xref="S6.Ex3.m1.1.1.3.cmml"><mi id="S6.Ex3.m1.1.1.3.2" xref="S6.Ex3.m1.1.1.3.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S6.Ex3.m1.1.1.3.1" xref="S6.Ex3.m1.1.1.3.1.cmml">​</mo><mi id="S6.Ex3.m1.1.1.3.3" xref="S6.Ex3.m1.1.1.3.3.cmml">P</mi></mrow><mo id="S6.Ex3.m1.1.1.2" xref="S6.Ex3.m1.1.1.2.cmml">/</mo><mrow id="S6.Ex3.m1.1.1.1.1" xref="S6.Ex3.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="S6.Ex3.m1.1.1.1.1.2" xref="S6.Ex3.m1.1.1.1.1.1.cmml">(</mo><mrow id="S6.Ex3.m1.1.1.1.1.1" xref="S6.Ex3.m1.1.1.1.1.1.cmml"><mrow id="S6.Ex3.m1.1.1.1.1.1.2" xref="S6.Ex3.m1.1.1.1.1.1.2.cmml"><mi id="S6.Ex3.m1.1.1.1.1.1.2.2" xref="S6.Ex3.m1.1.1.1.1.1.2.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S6.Ex3.m1.1.1.1.1.1.2.1" xref="S6.Ex3.m1.1.1.1.1.1.2.1.cmml">​</mo><mi id="S6.Ex3.m1.1.1.1.1.1.2.3" xref="S6.Ex3.m1.1.1.1.1.1.2.3.cmml">P</mi></mrow><mo id="S6.Ex3.m1.1.1.1.1.1.1" xref="S6.Ex3.m1.1.1.1.1.1.1.cmml">+</mo><mrow id="S6.Ex3.m1.1.1.1.1.1.3" xref="S6.Ex3.m1.1.1.1.1.1.3.cmml"><mi id="S6.Ex3.m1.1.1.1.1.1.3.2" xref="S6.Ex3.m1.1.1.1.1.1.3.2.cmml">F</mi><mo lspace="0em" rspace="0em" id="S6.Ex3.m1.1.1.1.1.1.3.1" xref="S6.Ex3.m1.1.1.1.1.1.3.1.cmml">​</mo><mi id="S6.Ex3.m1.1.1.1.1.1.3.3" xref="S6.Ex3.m1.1.1.1.1.1.3.3.cmml">P</mi></mrow></mrow><mo stretchy="false" id="S6.Ex3.m1.1.1.1.1.3" xref="S6.Ex3.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S6.Ex3.m1.1b"><apply id="S6.Ex3.m1.1.1.cmml" xref="S6.Ex3.m1.1.1"><divide id="S6.Ex3.m1.1.1.2.cmml" xref="S6.Ex3.m1.1.1.2"></divide><apply id="S6.Ex3.m1.1.1.3.cmml" xref="S6.Ex3.m1.1.1.3"><times id="S6.Ex3.m1.1.1.3.1.cmml" xref="S6.Ex3.m1.1.1.3.1"></times><ci id="S6.Ex3.m1.1.1.3.2.cmml" xref="S6.Ex3.m1.1.1.3.2">𝑇</ci><ci id="S6.Ex3.m1.1.1.3.3.cmml" xref="S6.Ex3.m1.1.1.3.3">𝑃</ci></apply><apply id="S6.Ex3.m1.1.1.1.1.1.cmml" xref="S6.Ex3.m1.1.1.1.1"><plus id="S6.Ex3.m1.1.1.1.1.1.1.cmml" xref="S6.Ex3.m1.1.1.1.1.1.1"></plus><apply id="S6.Ex3.m1.1.1.1.1.1.2.cmml" xref="S6.Ex3.m1.1.1.1.1.1.2"><times id="S6.Ex3.m1.1.1.1.1.1.2.1.cmml" xref="S6.Ex3.m1.1.1.1.1.1.2.1"></times><ci id="S6.Ex3.m1.1.1.1.1.1.2.2.cmml" xref="S6.Ex3.m1.1.1.1.1.1.2.2">𝑇</ci><ci id="S6.Ex3.m1.1.1.1.1.1.2.3.cmml" xref="S6.Ex3.m1.1.1.1.1.1.2.3">𝑃</ci></apply><apply id="S6.Ex3.m1.1.1.1.1.1.3.cmml" xref="S6.Ex3.m1.1.1.1.1.1.3"><times id="S6.Ex3.m1.1.1.1.1.1.3.1.cmml" xref="S6.Ex3.m1.1.1.1.1.1.3.1"></times><ci id="S6.Ex3.m1.1.1.1.1.1.3.2.cmml" xref="S6.Ex3.m1.1.1.1.1.1.3.2">𝐹</ci><ci id="S6.Ex3.m1.1.1.1.1.1.3.3.cmml" xref="S6.Ex3.m1.1.1.1.1.1.3.3">𝑃</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.Ex3.m1.1c">TP/(TP+FP)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S6.SS2.SSS2.p1.2" class="ltx_p">Recall is the metric to determine the percentage of correct results out of all the true results for a given class. It is given as :</p>
<table id="S6.Ex4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S6.Ex4.m1.1" class="ltx_Math" alttext="TP/(TP+FN)" display="block"><semantics id="S6.Ex4.m1.1a"><mrow id="S6.Ex4.m1.1.1" xref="S6.Ex4.m1.1.1.cmml"><mrow id="S6.Ex4.m1.1.1.3" xref="S6.Ex4.m1.1.1.3.cmml"><mi id="S6.Ex4.m1.1.1.3.2" xref="S6.Ex4.m1.1.1.3.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S6.Ex4.m1.1.1.3.1" xref="S6.Ex4.m1.1.1.3.1.cmml">​</mo><mi id="S6.Ex4.m1.1.1.3.3" xref="S6.Ex4.m1.1.1.3.3.cmml">P</mi></mrow><mo id="S6.Ex4.m1.1.1.2" xref="S6.Ex4.m1.1.1.2.cmml">/</mo><mrow id="S6.Ex4.m1.1.1.1.1" xref="S6.Ex4.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="S6.Ex4.m1.1.1.1.1.2" xref="S6.Ex4.m1.1.1.1.1.1.cmml">(</mo><mrow id="S6.Ex4.m1.1.1.1.1.1" xref="S6.Ex4.m1.1.1.1.1.1.cmml"><mrow id="S6.Ex4.m1.1.1.1.1.1.2" xref="S6.Ex4.m1.1.1.1.1.1.2.cmml"><mi id="S6.Ex4.m1.1.1.1.1.1.2.2" xref="S6.Ex4.m1.1.1.1.1.1.2.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S6.Ex4.m1.1.1.1.1.1.2.1" xref="S6.Ex4.m1.1.1.1.1.1.2.1.cmml">​</mo><mi id="S6.Ex4.m1.1.1.1.1.1.2.3" xref="S6.Ex4.m1.1.1.1.1.1.2.3.cmml">P</mi></mrow><mo id="S6.Ex4.m1.1.1.1.1.1.1" xref="S6.Ex4.m1.1.1.1.1.1.1.cmml">+</mo><mrow id="S6.Ex4.m1.1.1.1.1.1.3" xref="S6.Ex4.m1.1.1.1.1.1.3.cmml"><mi id="S6.Ex4.m1.1.1.1.1.1.3.2" xref="S6.Ex4.m1.1.1.1.1.1.3.2.cmml">F</mi><mo lspace="0em" rspace="0em" id="S6.Ex4.m1.1.1.1.1.1.3.1" xref="S6.Ex4.m1.1.1.1.1.1.3.1.cmml">​</mo><mi id="S6.Ex4.m1.1.1.1.1.1.3.3" xref="S6.Ex4.m1.1.1.1.1.1.3.3.cmml">N</mi></mrow></mrow><mo stretchy="false" id="S6.Ex4.m1.1.1.1.1.3" xref="S6.Ex4.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S6.Ex4.m1.1b"><apply id="S6.Ex4.m1.1.1.cmml" xref="S6.Ex4.m1.1.1"><divide id="S6.Ex4.m1.1.1.2.cmml" xref="S6.Ex4.m1.1.1.2"></divide><apply id="S6.Ex4.m1.1.1.3.cmml" xref="S6.Ex4.m1.1.1.3"><times id="S6.Ex4.m1.1.1.3.1.cmml" xref="S6.Ex4.m1.1.1.3.1"></times><ci id="S6.Ex4.m1.1.1.3.2.cmml" xref="S6.Ex4.m1.1.1.3.2">𝑇</ci><ci id="S6.Ex4.m1.1.1.3.3.cmml" xref="S6.Ex4.m1.1.1.3.3">𝑃</ci></apply><apply id="S6.Ex4.m1.1.1.1.1.1.cmml" xref="S6.Ex4.m1.1.1.1.1"><plus id="S6.Ex4.m1.1.1.1.1.1.1.cmml" xref="S6.Ex4.m1.1.1.1.1.1.1"></plus><apply id="S6.Ex4.m1.1.1.1.1.1.2.cmml" xref="S6.Ex4.m1.1.1.1.1.1.2"><times id="S6.Ex4.m1.1.1.1.1.1.2.1.cmml" xref="S6.Ex4.m1.1.1.1.1.1.2.1"></times><ci id="S6.Ex4.m1.1.1.1.1.1.2.2.cmml" xref="S6.Ex4.m1.1.1.1.1.1.2.2">𝑇</ci><ci id="S6.Ex4.m1.1.1.1.1.1.2.3.cmml" xref="S6.Ex4.m1.1.1.1.1.1.2.3">𝑃</ci></apply><apply id="S6.Ex4.m1.1.1.1.1.1.3.cmml" xref="S6.Ex4.m1.1.1.1.1.1.3"><times id="S6.Ex4.m1.1.1.1.1.1.3.1.cmml" xref="S6.Ex4.m1.1.1.1.1.1.3.1"></times><ci id="S6.Ex4.m1.1.1.1.1.1.3.2.cmml" xref="S6.Ex4.m1.1.1.1.1.1.3.2">𝐹</ci><ci id="S6.Ex4.m1.1.1.1.1.1.3.3.cmml" xref="S6.Ex4.m1.1.1.1.1.1.3.3">𝑁</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.Ex4.m1.1c">TP/(TP+FN)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S6.SS2.SSS2.p1.3" class="ltx_p">F1 score, also known as the balanced F score, is the harmonic mean of precision and recall.</p>
<table id="S6.Ex5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S6.Ex5.m1.1" class="ltx_Math" alttext="2*\frac{precision*recall}{precision+recall}" display="block"><semantics id="S6.Ex5.m1.1a"><mrow id="S6.Ex5.m1.1.1" xref="S6.Ex5.m1.1.1.cmml"><mn id="S6.Ex5.m1.1.1.2" xref="S6.Ex5.m1.1.1.2.cmml">2</mn><mo lspace="0.222em" rspace="0.222em" id="S6.Ex5.m1.1.1.1" xref="S6.Ex5.m1.1.1.1.cmml">∗</mo><mfrac id="S6.Ex5.m1.1.1.3" xref="S6.Ex5.m1.1.1.3.cmml"><mrow id="S6.Ex5.m1.1.1.3.2" xref="S6.Ex5.m1.1.1.3.2.cmml"><mrow id="S6.Ex5.m1.1.1.3.2.2" xref="S6.Ex5.m1.1.1.3.2.2.cmml"><mrow id="S6.Ex5.m1.1.1.3.2.2.2" xref="S6.Ex5.m1.1.1.3.2.2.2.cmml"><mi id="S6.Ex5.m1.1.1.3.2.2.2.2" xref="S6.Ex5.m1.1.1.3.2.2.2.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S6.Ex5.m1.1.1.3.2.2.2.1" xref="S6.Ex5.m1.1.1.3.2.2.2.1.cmml">​</mo><mi id="S6.Ex5.m1.1.1.3.2.2.2.3" xref="S6.Ex5.m1.1.1.3.2.2.2.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S6.Ex5.m1.1.1.3.2.2.2.1a" xref="S6.Ex5.m1.1.1.3.2.2.2.1.cmml">​</mo><mi id="S6.Ex5.m1.1.1.3.2.2.2.4" xref="S6.Ex5.m1.1.1.3.2.2.2.4.cmml">e</mi><mo lspace="0em" rspace="0em" id="S6.Ex5.m1.1.1.3.2.2.2.1b" xref="S6.Ex5.m1.1.1.3.2.2.2.1.cmml">​</mo><mi id="S6.Ex5.m1.1.1.3.2.2.2.5" xref="S6.Ex5.m1.1.1.3.2.2.2.5.cmml">c</mi><mo lspace="0em" rspace="0em" id="S6.Ex5.m1.1.1.3.2.2.2.1c" xref="S6.Ex5.m1.1.1.3.2.2.2.1.cmml">​</mo><mi id="S6.Ex5.m1.1.1.3.2.2.2.6" xref="S6.Ex5.m1.1.1.3.2.2.2.6.cmml">i</mi><mo lspace="0em" rspace="0em" id="S6.Ex5.m1.1.1.3.2.2.2.1d" xref="S6.Ex5.m1.1.1.3.2.2.2.1.cmml">​</mo><mi id="S6.Ex5.m1.1.1.3.2.2.2.7" xref="S6.Ex5.m1.1.1.3.2.2.2.7.cmml">s</mi><mo lspace="0em" rspace="0em" id="S6.Ex5.m1.1.1.3.2.2.2.1e" xref="S6.Ex5.m1.1.1.3.2.2.2.1.cmml">​</mo><mi id="S6.Ex5.m1.1.1.3.2.2.2.8" xref="S6.Ex5.m1.1.1.3.2.2.2.8.cmml">i</mi><mo lspace="0em" rspace="0em" id="S6.Ex5.m1.1.1.3.2.2.2.1f" xref="S6.Ex5.m1.1.1.3.2.2.2.1.cmml">​</mo><mi id="S6.Ex5.m1.1.1.3.2.2.2.9" xref="S6.Ex5.m1.1.1.3.2.2.2.9.cmml">o</mi><mo lspace="0em" rspace="0em" id="S6.Ex5.m1.1.1.3.2.2.2.1g" xref="S6.Ex5.m1.1.1.3.2.2.2.1.cmml">​</mo><mi id="S6.Ex5.m1.1.1.3.2.2.2.10" xref="S6.Ex5.m1.1.1.3.2.2.2.10.cmml">n</mi></mrow><mo lspace="0.222em" rspace="0.222em" id="S6.Ex5.m1.1.1.3.2.2.1" xref="S6.Ex5.m1.1.1.3.2.2.1.cmml">∗</mo><mi id="S6.Ex5.m1.1.1.3.2.2.3" xref="S6.Ex5.m1.1.1.3.2.2.3.cmml">r</mi></mrow><mo lspace="0em" rspace="0em" id="S6.Ex5.m1.1.1.3.2.1" xref="S6.Ex5.m1.1.1.3.2.1.cmml">​</mo><mi id="S6.Ex5.m1.1.1.3.2.3" xref="S6.Ex5.m1.1.1.3.2.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S6.Ex5.m1.1.1.3.2.1a" xref="S6.Ex5.m1.1.1.3.2.1.cmml">​</mo><mi id="S6.Ex5.m1.1.1.3.2.4" xref="S6.Ex5.m1.1.1.3.2.4.cmml">c</mi><mo lspace="0em" rspace="0em" id="S6.Ex5.m1.1.1.3.2.1b" xref="S6.Ex5.m1.1.1.3.2.1.cmml">​</mo><mi id="S6.Ex5.m1.1.1.3.2.5" xref="S6.Ex5.m1.1.1.3.2.5.cmml">a</mi><mo lspace="0em" rspace="0em" id="S6.Ex5.m1.1.1.3.2.1c" xref="S6.Ex5.m1.1.1.3.2.1.cmml">​</mo><mi id="S6.Ex5.m1.1.1.3.2.6" xref="S6.Ex5.m1.1.1.3.2.6.cmml">l</mi><mo lspace="0em" rspace="0em" id="S6.Ex5.m1.1.1.3.2.1d" xref="S6.Ex5.m1.1.1.3.2.1.cmml">​</mo><mi id="S6.Ex5.m1.1.1.3.2.7" xref="S6.Ex5.m1.1.1.3.2.7.cmml">l</mi></mrow><mrow id="S6.Ex5.m1.1.1.3.3" xref="S6.Ex5.m1.1.1.3.3.cmml"><mrow id="S6.Ex5.m1.1.1.3.3.2" xref="S6.Ex5.m1.1.1.3.3.2.cmml"><mi id="S6.Ex5.m1.1.1.3.3.2.2" xref="S6.Ex5.m1.1.1.3.3.2.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S6.Ex5.m1.1.1.3.3.2.1" xref="S6.Ex5.m1.1.1.3.3.2.1.cmml">​</mo><mi id="S6.Ex5.m1.1.1.3.3.2.3" xref="S6.Ex5.m1.1.1.3.3.2.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S6.Ex5.m1.1.1.3.3.2.1a" xref="S6.Ex5.m1.1.1.3.3.2.1.cmml">​</mo><mi id="S6.Ex5.m1.1.1.3.3.2.4" xref="S6.Ex5.m1.1.1.3.3.2.4.cmml">e</mi><mo lspace="0em" rspace="0em" id="S6.Ex5.m1.1.1.3.3.2.1b" xref="S6.Ex5.m1.1.1.3.3.2.1.cmml">​</mo><mi id="S6.Ex5.m1.1.1.3.3.2.5" xref="S6.Ex5.m1.1.1.3.3.2.5.cmml">c</mi><mo lspace="0em" rspace="0em" id="S6.Ex5.m1.1.1.3.3.2.1c" xref="S6.Ex5.m1.1.1.3.3.2.1.cmml">​</mo><mi id="S6.Ex5.m1.1.1.3.3.2.6" xref="S6.Ex5.m1.1.1.3.3.2.6.cmml">i</mi><mo lspace="0em" rspace="0em" id="S6.Ex5.m1.1.1.3.3.2.1d" xref="S6.Ex5.m1.1.1.3.3.2.1.cmml">​</mo><mi id="S6.Ex5.m1.1.1.3.3.2.7" xref="S6.Ex5.m1.1.1.3.3.2.7.cmml">s</mi><mo lspace="0em" rspace="0em" id="S6.Ex5.m1.1.1.3.3.2.1e" xref="S6.Ex5.m1.1.1.3.3.2.1.cmml">​</mo><mi id="S6.Ex5.m1.1.1.3.3.2.8" xref="S6.Ex5.m1.1.1.3.3.2.8.cmml">i</mi><mo lspace="0em" rspace="0em" id="S6.Ex5.m1.1.1.3.3.2.1f" xref="S6.Ex5.m1.1.1.3.3.2.1.cmml">​</mo><mi id="S6.Ex5.m1.1.1.3.3.2.9" xref="S6.Ex5.m1.1.1.3.3.2.9.cmml">o</mi><mo lspace="0em" rspace="0em" id="S6.Ex5.m1.1.1.3.3.2.1g" xref="S6.Ex5.m1.1.1.3.3.2.1.cmml">​</mo><mi id="S6.Ex5.m1.1.1.3.3.2.10" xref="S6.Ex5.m1.1.1.3.3.2.10.cmml">n</mi></mrow><mo id="S6.Ex5.m1.1.1.3.3.1" xref="S6.Ex5.m1.1.1.3.3.1.cmml">+</mo><mrow id="S6.Ex5.m1.1.1.3.3.3" xref="S6.Ex5.m1.1.1.3.3.3.cmml"><mi id="S6.Ex5.m1.1.1.3.3.3.2" xref="S6.Ex5.m1.1.1.3.3.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S6.Ex5.m1.1.1.3.3.3.1" xref="S6.Ex5.m1.1.1.3.3.3.1.cmml">​</mo><mi id="S6.Ex5.m1.1.1.3.3.3.3" xref="S6.Ex5.m1.1.1.3.3.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S6.Ex5.m1.1.1.3.3.3.1a" xref="S6.Ex5.m1.1.1.3.3.3.1.cmml">​</mo><mi id="S6.Ex5.m1.1.1.3.3.3.4" xref="S6.Ex5.m1.1.1.3.3.3.4.cmml">c</mi><mo lspace="0em" rspace="0em" id="S6.Ex5.m1.1.1.3.3.3.1b" xref="S6.Ex5.m1.1.1.3.3.3.1.cmml">​</mo><mi id="S6.Ex5.m1.1.1.3.3.3.5" xref="S6.Ex5.m1.1.1.3.3.3.5.cmml">a</mi><mo lspace="0em" rspace="0em" id="S6.Ex5.m1.1.1.3.3.3.1c" xref="S6.Ex5.m1.1.1.3.3.3.1.cmml">​</mo><mi id="S6.Ex5.m1.1.1.3.3.3.6" xref="S6.Ex5.m1.1.1.3.3.3.6.cmml">l</mi><mo lspace="0em" rspace="0em" id="S6.Ex5.m1.1.1.3.3.3.1d" xref="S6.Ex5.m1.1.1.3.3.3.1.cmml">​</mo><mi id="S6.Ex5.m1.1.1.3.3.3.7" xref="S6.Ex5.m1.1.1.3.3.3.7.cmml">l</mi></mrow></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S6.Ex5.m1.1b"><apply id="S6.Ex5.m1.1.1.cmml" xref="S6.Ex5.m1.1.1"><times id="S6.Ex5.m1.1.1.1.cmml" xref="S6.Ex5.m1.1.1.1"></times><cn type="integer" id="S6.Ex5.m1.1.1.2.cmml" xref="S6.Ex5.m1.1.1.2">2</cn><apply id="S6.Ex5.m1.1.1.3.cmml" xref="S6.Ex5.m1.1.1.3"><divide id="S6.Ex5.m1.1.1.3.1.cmml" xref="S6.Ex5.m1.1.1.3"></divide><apply id="S6.Ex5.m1.1.1.3.2.cmml" xref="S6.Ex5.m1.1.1.3.2"><times id="S6.Ex5.m1.1.1.3.2.1.cmml" xref="S6.Ex5.m1.1.1.3.2.1"></times><apply id="S6.Ex5.m1.1.1.3.2.2.cmml" xref="S6.Ex5.m1.1.1.3.2.2"><times id="S6.Ex5.m1.1.1.3.2.2.1.cmml" xref="S6.Ex5.m1.1.1.3.2.2.1"></times><apply id="S6.Ex5.m1.1.1.3.2.2.2.cmml" xref="S6.Ex5.m1.1.1.3.2.2.2"><times id="S6.Ex5.m1.1.1.3.2.2.2.1.cmml" xref="S6.Ex5.m1.1.1.3.2.2.2.1"></times><ci id="S6.Ex5.m1.1.1.3.2.2.2.2.cmml" xref="S6.Ex5.m1.1.1.3.2.2.2.2">𝑝</ci><ci id="S6.Ex5.m1.1.1.3.2.2.2.3.cmml" xref="S6.Ex5.m1.1.1.3.2.2.2.3">𝑟</ci><ci id="S6.Ex5.m1.1.1.3.2.2.2.4.cmml" xref="S6.Ex5.m1.1.1.3.2.2.2.4">𝑒</ci><ci id="S6.Ex5.m1.1.1.3.2.2.2.5.cmml" xref="S6.Ex5.m1.1.1.3.2.2.2.5">𝑐</ci><ci id="S6.Ex5.m1.1.1.3.2.2.2.6.cmml" xref="S6.Ex5.m1.1.1.3.2.2.2.6">𝑖</ci><ci id="S6.Ex5.m1.1.1.3.2.2.2.7.cmml" xref="S6.Ex5.m1.1.1.3.2.2.2.7">𝑠</ci><ci id="S6.Ex5.m1.1.1.3.2.2.2.8.cmml" xref="S6.Ex5.m1.1.1.3.2.2.2.8">𝑖</ci><ci id="S6.Ex5.m1.1.1.3.2.2.2.9.cmml" xref="S6.Ex5.m1.1.1.3.2.2.2.9">𝑜</ci><ci id="S6.Ex5.m1.1.1.3.2.2.2.10.cmml" xref="S6.Ex5.m1.1.1.3.2.2.2.10">𝑛</ci></apply><ci id="S6.Ex5.m1.1.1.3.2.2.3.cmml" xref="S6.Ex5.m1.1.1.3.2.2.3">𝑟</ci></apply><ci id="S6.Ex5.m1.1.1.3.2.3.cmml" xref="S6.Ex5.m1.1.1.3.2.3">𝑒</ci><ci id="S6.Ex5.m1.1.1.3.2.4.cmml" xref="S6.Ex5.m1.1.1.3.2.4">𝑐</ci><ci id="S6.Ex5.m1.1.1.3.2.5.cmml" xref="S6.Ex5.m1.1.1.3.2.5">𝑎</ci><ci id="S6.Ex5.m1.1.1.3.2.6.cmml" xref="S6.Ex5.m1.1.1.3.2.6">𝑙</ci><ci id="S6.Ex5.m1.1.1.3.2.7.cmml" xref="S6.Ex5.m1.1.1.3.2.7">𝑙</ci></apply><apply id="S6.Ex5.m1.1.1.3.3.cmml" xref="S6.Ex5.m1.1.1.3.3"><plus id="S6.Ex5.m1.1.1.3.3.1.cmml" xref="S6.Ex5.m1.1.1.3.3.1"></plus><apply id="S6.Ex5.m1.1.1.3.3.2.cmml" xref="S6.Ex5.m1.1.1.3.3.2"><times id="S6.Ex5.m1.1.1.3.3.2.1.cmml" xref="S6.Ex5.m1.1.1.3.3.2.1"></times><ci id="S6.Ex5.m1.1.1.3.3.2.2.cmml" xref="S6.Ex5.m1.1.1.3.3.2.2">𝑝</ci><ci id="S6.Ex5.m1.1.1.3.3.2.3.cmml" xref="S6.Ex5.m1.1.1.3.3.2.3">𝑟</ci><ci id="S6.Ex5.m1.1.1.3.3.2.4.cmml" xref="S6.Ex5.m1.1.1.3.3.2.4">𝑒</ci><ci id="S6.Ex5.m1.1.1.3.3.2.5.cmml" xref="S6.Ex5.m1.1.1.3.3.2.5">𝑐</ci><ci id="S6.Ex5.m1.1.1.3.3.2.6.cmml" xref="S6.Ex5.m1.1.1.3.3.2.6">𝑖</ci><ci id="S6.Ex5.m1.1.1.3.3.2.7.cmml" xref="S6.Ex5.m1.1.1.3.3.2.7">𝑠</ci><ci id="S6.Ex5.m1.1.1.3.3.2.8.cmml" xref="S6.Ex5.m1.1.1.3.3.2.8">𝑖</ci><ci id="S6.Ex5.m1.1.1.3.3.2.9.cmml" xref="S6.Ex5.m1.1.1.3.3.2.9">𝑜</ci><ci id="S6.Ex5.m1.1.1.3.3.2.10.cmml" xref="S6.Ex5.m1.1.1.3.3.2.10">𝑛</ci></apply><apply id="S6.Ex5.m1.1.1.3.3.3.cmml" xref="S6.Ex5.m1.1.1.3.3.3"><times id="S6.Ex5.m1.1.1.3.3.3.1.cmml" xref="S6.Ex5.m1.1.1.3.3.3.1"></times><ci id="S6.Ex5.m1.1.1.3.3.3.2.cmml" xref="S6.Ex5.m1.1.1.3.3.3.2">𝑟</ci><ci id="S6.Ex5.m1.1.1.3.3.3.3.cmml" xref="S6.Ex5.m1.1.1.3.3.3.3">𝑒</ci><ci id="S6.Ex5.m1.1.1.3.3.3.4.cmml" xref="S6.Ex5.m1.1.1.3.3.3.4">𝑐</ci><ci id="S6.Ex5.m1.1.1.3.3.3.5.cmml" xref="S6.Ex5.m1.1.1.3.3.3.5">𝑎</ci><ci id="S6.Ex5.m1.1.1.3.3.3.6.cmml" xref="S6.Ex5.m1.1.1.3.3.3.6">𝑙</ci><ci id="S6.Ex5.m1.1.1.3.3.3.7.cmml" xref="S6.Ex5.m1.1.1.3.3.3.7">𝑙</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.Ex5.m1.1c">2*\frac{precision*recall}{precision+recall}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S6.SS2.SSS2.p1.4" class="ltx_p">For a multi-class classification, the F1 score is given as the average of the F1 score of each class based on averaging scheme. For our experiments, we have selected <span id="S6.SS2.SSS2.p1.4.1" class="ltx_text ltx_font_bold">weighted</span> averaging to deal with class imbalance issues due to the non-iid distribution of data across multiple clients.</p>
</div>
<figure id="S6.T2" class="ltx_table">
<table id="S6.T2.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S6.T2.1.1.1" class="ltx_tr">
<th id="S6.T2.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" colspan="4">F1 score for 4 Slowest Clients</th>
<th id="S6.T2.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" colspan="4">F1 score for 4 Fastest Clients</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S6.T2.1.2.1" class="ltx_tr">
<th id="S6.T2.1.2.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">Client</th>
<td id="S6.T2.1.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">FedCS</td>
<td id="S6.T2.1.2.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<table id="S6.T2.1.2.1.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S6.T2.1.2.1.3.1.1" class="ltx_tr">
<td id="S6.T2.1.2.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Random</td>
</tr>
<tr id="S6.T2.1.2.1.3.1.2" class="ltx_tr">
<td id="S6.T2.1.2.1.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">Selection</td>
</tr>
</table>
</td>
<td id="S6.T2.1.2.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">FedSS</td>
<th id="S6.T2.1.2.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">Client</th>
<td id="S6.T2.1.2.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">FedCS</td>
<td id="S6.T2.1.2.1.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<table id="S6.T2.1.2.1.7.1" class="ltx_tabular ltx_align_middle">
<tr id="S6.T2.1.2.1.7.1.1" class="ltx_tr">
<td id="S6.T2.1.2.1.7.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Random</td>
</tr>
<tr id="S6.T2.1.2.1.7.1.2" class="ltx_tr">
<td id="S6.T2.1.2.1.7.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">Selection</td>
</tr>
</table>
</td>
<td id="S6.T2.1.2.1.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">FedSS</td>
</tr>
<tr id="S6.T2.1.3.2" class="ltx_tr">
<th id="S6.T2.1.3.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">1</th>
<td id="S6.T2.1.3.2.2" class="ltx_td ltx_align_center ltx_border_t">67.10</td>
<td id="S6.T2.1.3.2.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T2.1.3.2.3.1" class="ltx_text ltx_font_bold">78.08</span></td>
<td id="S6.T2.1.3.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">77.22</td>
<th id="S6.T2.1.3.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">1</th>
<td id="S6.T2.1.3.2.6" class="ltx_td ltx_align_center ltx_border_t">81.48</td>
<td id="S6.T2.1.3.2.7" class="ltx_td ltx_align_center ltx_border_t">83.72</td>
<td id="S6.T2.1.3.2.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S6.T2.1.3.2.8.1" class="ltx_text ltx_font_bold">84.45</span></td>
</tr>
<tr id="S6.T2.1.4.3" class="ltx_tr">
<th id="S6.T2.1.4.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r">2</th>
<td id="S6.T2.1.4.3.2" class="ltx_td ltx_align_center">69.00</td>
<td id="S6.T2.1.4.3.3" class="ltx_td ltx_align_center">72.58</td>
<td id="S6.T2.1.4.3.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S6.T2.1.4.3.4.1" class="ltx_text ltx_font_bold">73.51</span></td>
<th id="S6.T2.1.4.3.5" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">2</th>
<td id="S6.T2.1.4.3.6" class="ltx_td ltx_align_center">56.34</td>
<td id="S6.T2.1.4.3.7" class="ltx_td ltx_align_center">56.86</td>
<td id="S6.T2.1.4.3.8" class="ltx_td ltx_align_center ltx_border_r"><span id="S6.T2.1.4.3.8.1" class="ltx_text ltx_font_bold">60.85</span></td>
</tr>
<tr id="S6.T2.1.5.4" class="ltx_tr">
<th id="S6.T2.1.5.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r">3</th>
<td id="S6.T2.1.5.4.2" class="ltx_td ltx_align_center">54.04</td>
<td id="S6.T2.1.5.4.3" class="ltx_td ltx_align_center">66.32</td>
<td id="S6.T2.1.5.4.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S6.T2.1.5.4.4.1" class="ltx_text ltx_font_bold">69.97</span></td>
<th id="S6.T2.1.5.4.5" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">3</th>
<td id="S6.T2.1.5.4.6" class="ltx_td ltx_align_center"><span id="S6.T2.1.5.4.6.1" class="ltx_text ltx_font_bold">77.50</span></td>
<td id="S6.T2.1.5.4.7" class="ltx_td ltx_align_center">73.60</td>
<td id="S6.T2.1.5.4.8" class="ltx_td ltx_align_center ltx_border_r">75.64</td>
</tr>
<tr id="S6.T2.1.6.5" class="ltx_tr">
<th id="S6.T2.1.6.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r">4</th>
<td id="S6.T2.1.6.5.2" class="ltx_td ltx_align_center">62.28</td>
<td id="S6.T2.1.6.5.3" class="ltx_td ltx_align_center"><span id="S6.T2.1.6.5.3.1" class="ltx_text ltx_font_bold">68.02</span></td>
<td id="S6.T2.1.6.5.4" class="ltx_td ltx_align_center ltx_border_r">67.69</td>
<th id="S6.T2.1.6.5.5" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">4</th>
<td id="S6.T2.1.6.5.6" class="ltx_td ltx_align_center"><span id="S6.T2.1.6.5.6.1" class="ltx_text ltx_font_bold">85.13</span></td>
<td id="S6.T2.1.6.5.7" class="ltx_td ltx_align_center">79.39</td>
<td id="S6.T2.1.6.5.8" class="ltx_td ltx_align_center ltx_border_r">78.14</td>
</tr>
<tr id="S6.T2.1.7.6" class="ltx_tr">
<th id="S6.T2.1.7.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t">Average</th>
<td id="S6.T2.1.7.6.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">62.60</td>
<td id="S6.T2.1.7.6.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">71.25</td>
<td id="S6.T2.1.7.6.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S6.T2.1.7.6.4.1" class="ltx_text ltx_font_bold">72.09</span></td>
<th id="S6.T2.1.7.6.5" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t">Average</th>
<td id="S6.T2.1.7.6.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S6.T2.1.7.6.6.1" class="ltx_text ltx_font_bold">75.11</span></td>
<td id="S6.T2.1.7.6.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">73.39</td>
<td id="S6.T2.1.7.6.8" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">74.77</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>A breakdown of F1 score of model across 4 slowest and 4 fastest clients for each of the selection strategies.</figcaption>
</figure>
<figure id="S6.F9" class="ltx_figure"><img src="/html/2207.04569/assets/Figures/latest/train_f1.png" id="S6.F9.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="337" height="253" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9: </span>The average F1 score of the global model for FedSS, FedCS and Random Selection.</figcaption>
</figure>
<div id="S6.SS2.SSS2.p2" class="ltx_para ltx_noindent">
<p id="S6.SS2.SSS2.p2.1" class="ltx_p">Table<a href="#S6.T2" title="Table 2 ‣ 6.2.2 F1 Score ‣ 6.2 Bias ‣ 6 Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> shows the breakdown of the F1-score for the slowest and the fastest clients trained in our experiment. The results are consistent with the accuracy scores. FedSS achieves results similar to FedCS for the fastest clients and improves the results by 16% for the slowest clients as compared to FedCS. Similar to accuracy, the results from FedSS match Random Selection while taking considerably less amount of time to train.</p>
</div>
</section>
</section>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Future work</h2>

<div id="S7.p1" class="ltx_para ltx_noindent">
<p id="S7.p1.1" class="ltx_p">We discuss the limitations of FedSS and the future work in this section. While FedSS achieves the best trade-off between training time and data heterogeneity in our testbed, we have some restrictions in experiments that need more work and real-world experimentation.</p>
</div>
<div id="S7.p2" class="ltx_para ltx_noindent">
<p id="S7.p2.1" class="ltx_p"><span id="S7.p2.1.1" class="ltx_text ltx_font_bold">Experimental Setup: </span>
Currently, we are bound to work on our local setup, which restricts us to be able to run experiments with only 20 clients. Running with more clients results in severe resource congestion(GPUs and memory). We expect better performance with more clients with our smart clustering and selection. Also, it would be really valuable to be able to run our setup with some real devices, along with implementations to track the client environment.</p>
</div>
<div id="S7.p3" class="ltx_para ltx_noindent">
<p id="S7.p3.1" class="ltx_p"><span id="S7.p3.1.1" class="ltx_text ltx_font_bold">Handling Churn: </span> Currently FedSS assumes that all clients join in the beginning and maintain available during the whole training procedure, which may not be true in real-world federated learning. Recalling that it takes a few rounds for FedSS to measure and profile the new client’s network condition and compute capability, it can be hard for FedSS to track this information accurately in the scenario where clients join and leave frequently.</p>
</div>
<div id="S7.p4" class="ltx_para ltx_noindent">
<p id="S7.p4.1" class="ltx_p">To mitigate the possible performance degradation due to the measurement and profiling delay of newly connected clients, we propose to collect the hardware specifications of clients, such as processor types and memory size, to initialize the grouping based on some regression models. The rationale behind it is that clients with similar hardware should have similar computation capability under most circumstances (unless many other background tasks compete for resources). Whenever a new client joins, FedSS takes one RTT to collect this information and determine its initial group based on the model, which is still better than random initialization.</p>
</div>
<div id="S7.p5" class="ltx_para ltx_noindent">
<p id="S7.p5.1" class="ltx_p"><span id="S7.p5.1.1" class="ltx_text ltx_font_bold">Data Heterogeneity: </span> FedSS treats all clients equally in every selection, which may not be the optimal solution. Although the selection is unbiased, the data heterogeneity itself among clients is another important source of bias<cite class="ltx_cite ltx_citemacro_cite">Kairouz et al. (<a href="#bib.bib15" title="" class="ltx_ref">2019</a>); Zhao et al. (<a href="#bib.bib33" title="" class="ltx_ref">2018</a>); Jeong et al. (<a href="#bib.bib14" title="" class="ltx_ref">2018</a>)</cite>. If a subset of clients with similar kinds of data is picked most of the time, the model will converge faster but can have a severe bias to the data distribution of that subset and may not be able to capture the true global data distribution.</p>
</div>
<div id="S7.p6" class="ltx_para ltx_noindent">
<p id="S7.p6.1" class="ltx_p">To overcome this issue, we want to explore the possibility to introduce the training loss of individual clients into the client selection process. Specifically in every round, if the training loss for a particular client is non-significant, we exclude it from selection for the next few rounds. This will improve the probability of other clients contributing towards the global model and also prevent model askew.</p>
</div>
<div id="S7.p7" class="ltx_para ltx_noindent">
<p id="S7.p7.1" class="ltx_p"><span id="S7.p7.1.1" class="ltx_text ltx_font_bold">Scalability and Fault-tolerance</span> FedSS applies only one server in the system, which induces a communication bottleneck and a single point of failure. We plan to leverage locality-aware multi-server architecture to enhance scalability, fault-tolerance, and even training performance in the future.</p>
</div>
<div id="S7.p8" class="ltx_para ltx_noindent">
<p id="S7.p8.1" class="ltx_p">Firstly, a locality-aware server tends to schedule and disseminate its model to local clients with better network service, which alleviates the communication bottleneck on the server side and reduces the ratio of stragglers resulting from the network. Secondly, multiple servers can apply a consensus algorithm to replicate the training state of each other to tolerate failure. Lastly, for geographically distributed applications such as next work prediction<cite class="ltx_cite ltx_citemacro_cite">Hard et al. (<a href="#bib.bib11" title="" class="ltx_ref">2018</a>)</cite> and geo-local language translation<cite class="ltx_cite ltx_citemacro_cite">Nord (<a href="#bib.bib24" title="" class="ltx_ref">2005</a>)</cite>, a locality-aware server can capture and preserve those geo-local characteristics better.</p>
</div>
</section>
<section id="S8" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8 </span>Conclusion</h2>

<div id="S8.p1" class="ltx_para ltx_noindent">
<p id="S8.p1.1" class="ltx_p">Federated learning due to its distributed nature of training machine learning model suffers from the issues of data and device heterogeneity. When we talk about device heterogeneity, there exists a trade-off between short training time and bias, as existing schemes end up dropping slower clients. We show this trade-off by comparing existing mechanisms of client selection. We then argue that to eliminate bias, it is necessary to make slow clients part of training. We present FedSS which finds a sweet spot between short training time and handling device heterogeneity by performing a smart selection of clients.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Abay et al. [2020]</span>
<span class="ltx_bibblock">
Annie Abay, Yi Zhou, Nathalie Baracaldo, Shashank Rajamoni, Ebube Chuba, and
Heiko Ludwig.

</span>
<span class="ltx_bibblock">Mitigating bias in federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2012.02447</em>, 2020.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bonawitz et al. [2019]</span>
<span class="ltx_bibblock">
K. A. Bonawitz, Hubert Eichner, Wolfgang Grieskamp, Dzmitry Huba, Alex
Ingerman, Vladimir Ivanov, Chloé M Kiddon, Jakub Konečný, Stefano
Mazzocchi, Brendan McMahan, Timon Van Overveldt, David Petrou, Daniel Ramage,
and Jason Roselander.

</span>
<span class="ltx_bibblock">Towards federated learning at scale: System design.

</span>
<span class="ltx_bibblock">In <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">SysML 2019</em>, 2019.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://arxiv.org/abs/1902.01046" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/1902.01046</a>.

</span>
<span class="ltx_bibblock">To appear.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bonawitz et al. [2016]</span>
<span class="ltx_bibblock">
Keith Bonawitz, Vladimir Ivanov, Ben Kreuter, Antonio Marcedone, H Brendan
McMahan, Sarvar Patel, Daniel Ramage, Aaron Segal, and Karn Seth.

</span>
<span class="ltx_bibblock">Practical secure aggregation for federated learning on user-held
data.

</span>
<span class="ltx_bibblock"><em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1611.04482</em>, 2016.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Caldas et al. [2018]</span>
<span class="ltx_bibblock">
S. Caldas, Peter Wu, Tian Li, Jakub Konecný, H. McMahan, Virginia Smith,
and Ameet Talwalkar.

</span>
<span class="ltx_bibblock">Leaf: A benchmark for federated settings.

</span>
<span class="ltx_bibblock"><em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/1812.01097, 2018.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chai et al. [2020]</span>
<span class="ltx_bibblock">
Zheng Chai, Ahsan Ali, Syed Zawad, Stacey Truex, Ali Anwar, Nathalie Baracaldo,
Yi Zhou, Heiko Ludwig, Feng Yan, and Yue Cheng.

</span>
<span class="ltx_bibblock">Tifl: A tier-based federated learning system.

</span>
<span class="ltx_bibblock">In <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 29th international symposium on
high-performance parallel and distributed computing</em>, pages 125–136, 2020.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. [2023]</span>
<span class="ltx_bibblock">
Yongzhou Chen, Ruihao Yao, Haitham Hassanieh, and Radhika Mittal.

</span>
<span class="ltx_bibblock">Channel-Aware 5g RAN slicing with customizable schedulers.

</span>
<span class="ltx_bibblock">In <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">20th USENIX Symposium on Networked Systems Design and
Implementation (NSDI 23)</em>, Boston, MA, 2023.

</span>
<span class="ltx_bibblock">ISBN 978-1-939133-33-5.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cho et al. [2020]</span>
<span class="ltx_bibblock">
Yae Jee Cho, Jianyu Wang, and Gauri Joshi.

</span>
<span class="ltx_bibblock">Client Selection in Federated Learning: Convergence Analysis and
Power-of-Choice Selection Strategies.

</span>
<span class="ltx_bibblock"><em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">arXiv e-prints</em>, art. arXiv:2010.01243, October 2020.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Choi et al. [1998]</span>
<span class="ltx_bibblock">
Bong Dae Choi, Doo Il Choi, Yoonju Lee, and Dan Keun Sung.

</span>
<span class="ltx_bibblock">Priority queueing system with fixed-length packet-train arrivals.

</span>
<span class="ltx_bibblock"><em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">IEE Proceedings-Communications</em>, 145(5):331–336, 1998.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dai et al. [2018]</span>
<span class="ltx_bibblock">
Wei Dai, Yi Zhou, Nanqing Dong, Hao Zhang, and Eric P Xing.

</span>
<span class="ltx_bibblock">Toward understanding the impact of staleness in distributed machine
learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1810.03264</em>, 2018.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Google.

</span>
<span class="ltx_bibblock">https://developers.google.com/web/funda-
mentals/performance/opt-imizing-content-effici- ency/client-hints.

</span>
<span class="ltx_bibblock">URL
<a target="_blank" href="https://developers.google.com/web/fundamentals/performance/optimizing-content-efficiency/client-hints" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://developers.google.com/web/fundamentals/performance/optimizing-content-efficiency/client-hints</a>.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hard et al. [2018]</span>
<span class="ltx_bibblock">
Andrew Hard, Kanishka Rao, Rajiv Mathews, Swaroop Ramaswamy, Françoise
Beaufays, Sean Augenstein, Hubert Eichner, Chloé Kiddon, and Daniel
Ramage.

</span>
<span class="ltx_bibblock">Federated learning for mobile keyboard prediction.

</span>
<span class="ltx_bibblock"><em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1811.03604</em>, 2018.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
HPL - A Portable Implementation of the High-Performance Linpack Benchmark for
Distributed-Memory Computers.

</span>
<span class="ltx_bibblock">http://www.netlib.org/benchmark/hpl/.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="http://www.netlib.org/benchmark/hpl/" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://www.netlib.org/benchmark/hpl/</a>.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
iconcharts.

</span>
<span class="ltx_bibblock">Passmark software - cpu benchmarks https://www.cpubenchmark.net/.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.cpubenchmark.net/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.cpubenchmark.net/</a>.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jeong et al. [2018]</span>
<span class="ltx_bibblock">
Eunjeong Jeong, Seungeun Oh, Hyesung Kim, Jihong Park, Mehdi Bennis, and
Seong-Lyun Kim.

</span>
<span class="ltx_bibblock">Communication-efficient on-device machine learning: Federated
distillation and augmentation under non-iid private data.

</span>
<span class="ltx_bibblock"><em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1811.11479</em>, 2018.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kairouz et al. [2019]</span>
<span class="ltx_bibblock">
Peter Kairouz, H Brendan McMahan, Brendan Avent, Aurélien Bellet, Mehdi
Bennis, Arjun Nitin Bhagoji, Keith Bonawitz, Zachary Charles, Graham Cormode,
Rachel Cummings, et al.

</span>
<span class="ltx_bibblock">Advances and open problems in federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1912.04977</em>, 2019.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Konečnỳ et al. [2016]</span>
<span class="ltx_bibblock">
Jakub Konečnỳ, H Brendan McMahan, Felix X Yu, Peter Richtárik,
Ananda Theertha Suresh, and Dave Bacon.

</span>
<span class="ltx_bibblock">Federated learning: Strategies for improving communication
efficiency.

</span>
<span class="ltx_bibblock"><em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1610.05492</em>, 2016.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. [2020]</span>
<span class="ltx_bibblock">
T. Li, A. K. Sahu, A. Talwalkar, and V. Smith.

</span>
<span class="ltx_bibblock">Federated learning: Challenges, methods, and future directions.

</span>
<span class="ltx_bibblock"><em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">IEEE Signal Processing Magazine</em>, 37(3):50–60, 2020.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1109/MSP.2020.2975749</span>.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. [2018]</span>
<span class="ltx_bibblock">
Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and
Virginia Smith.

</span>
<span class="ltx_bibblock">Federated optimization in heterogeneous networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1812.06127</em>, 2018.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. [2019]</span>
<span class="ltx_bibblock">
Xiang Li, Kaixuan Huang, Wenhao Yang, Shusen Wang, and Zhihua Zhang.

</span>
<span class="ltx_bibblock">On the Convergence of FedAvg on Non-IID Data.

</span>
<span class="ltx_bibblock"><em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">arXiv e-prints</em>, art. arXiv:1907.02189, July 2019.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
LINPACK.

</span>
<span class="ltx_bibblock">http://www.netlib.org/linpack/.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="http://www.netlib.org/linpack/" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://www.netlib.org/linpack/</a>.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McMahan and Ramage [2017]</span>
<span class="ltx_bibblock">
Brendan McMahan and Daniel Ramage.

</span>
<span class="ltx_bibblock">Federated learning: Collaborative machine learning without
centralized training data, Apr 2017.

</span>
<span class="ltx_bibblock">URL
<a target="_blank" href="https://ai.googleblog.com/2017/04/federated-learning-collaborative.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://ai.googleblog.com/2017/04/federated-learning-collaborative.html</a>.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McMahan et al. [2017]</span>
<span class="ltx_bibblock">
H. Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and
Blaise Agüera y Arcas.

</span>
<span class="ltx_bibblock">Communication-efficient learning of deep networks from decentralized
data, 2017.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nishio and Yonetani [2019]</span>
<span class="ltx_bibblock">
Takayuki Nishio and Ryo Yonetani.

</span>
<span class="ltx_bibblock">Client selection for federated learning with heterogeneous resources
in mobile edge.

</span>
<span class="ltx_bibblock"><em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">ICC 2019 - 2019 IEEE International Conference on Communications
(ICC)</em>, May 2019.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1109/icc.2019.8761315</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="http://dx.doi.org/10.1109/ICC.2019.8761315" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://dx.doi.org/10.1109/ICC.2019.8761315</a>.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nord [2005]</span>
<span class="ltx_bibblock">
Christiane Nord.

</span>
<span class="ltx_bibblock"><em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">Text analysis in translation: Theory, methodology, and didactic
application of a model for translation-oriented text analysis</em>.

</span>
<span class="ltx_bibblock">Rodopi, 2005.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ruan et al. [2020]</span>
<span class="ltx_bibblock">
Yichen Ruan, Xiaoxi Zhang, Shu-Che Liang, and Carlee Joe-Wong.

</span>
<span class="ltx_bibblock">Towards Flexible Device Participation in Federated Learning for
Non-IID Data.

</span>
<span class="ltx_bibblock"><em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">arXiv e-prints</em>, art. arXiv:2006.06954, June 2020.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Satopaa et al. [2011]</span>
<span class="ltx_bibblock">
Ville Satopaa, Jeannie Albrecht, David Irwin, and Barath Raghavan.

</span>
<span class="ltx_bibblock">Finding a” kneedle” in a haystack: Detecting knee points in system
behavior.

</span>
<span class="ltx_bibblock">In <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">2011 31st international conference on distributed computing
systems workshops</em>, pages 166–171. IEEE, 2011.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Stripelis et al. [2022]</span>
<span class="ltx_bibblock">
Dimitris Stripelis, Paul M Thompson, and José Luis Ambite.

</span>
<span class="ltx_bibblock">Semi-synchronous federated learning for energy-efficient training and
accelerated convergence in cross-silo settings.

</span>
<span class="ltx_bibblock"><em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">ACM Transactions on Intelligent Systems and Technology (TIST)</em>,
13(5):1–29, 2022.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tahir and Mittal [2023]</span>
<span class="ltx_bibblock">
Ammar Tahir and Radhika Mittal.

</span>
<span class="ltx_bibblock">Enabling users to control their internet.

</span>
<span class="ltx_bibblock">In <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">20th USENIX Symposium on Networked Systems Design and
Implementation (NSDI 23)</em>, pages 555–573, 2023.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
World Population Review.

</span>
<span class="ltx_bibblock">https://worldpopulationreview.com/country-rankings/internet-speeds-by-country.

</span>
<span class="ltx_bibblock">URL
<a target="_blank" href="https://worldpopulationreview.com/country-rankings/internet-speeds-by-country" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://worldpopulationreview.com/country-rankings/internet-speeds-by-country</a>.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xie et al. [2019]</span>
<span class="ltx_bibblock">
Cong Xie, Sanmi Koyejo, and Indranil Gupta.

</span>
<span class="ltx_bibblock">Asynchronous federated optimization.

</span>
<span class="ltx_bibblock"><em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1903.03934</em>, 2019.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al. [2019]</span>
<span class="ltx_bibblock">
Zirui Xu, Zhao Yang, Jinjun Xiong, Jianlei Yang, and Xiang Chen.

</span>
<span class="ltx_bibblock">Elfish: Resource-aware federated learning on heterogeneous edge
devices.

</span>
<span class="ltx_bibblock"><em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1912.01684</em>, 2019.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yordan [2020]</span>
<span class="ltx_bibblock">
Yordan.

</span>
<span class="ltx_bibblock">Top 20 most popular phones in 2020, Dec 2020.

</span>
<span class="ltx_bibblock">URL
<a target="_blank" href="https://www.gsmarena.com/top_20_most_popular_phones_in_2020-news-46737.php" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.gsmarena.com/top_20_most_popular_phones_in_2020-news-46737.php</a>.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al. [2018]</span>
<span class="ltx_bibblock">
Yue Zhao, Meng Li, Liangzhen Lai, Naveen Suda, Damon Civin, and Vikas Chandra.

</span>
<span class="ltx_bibblock">Federated learning with non-iid data.

</span>
<span class="ltx_bibblock"><em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1806.00582</em>, 2018.

</span>
</li>
</ul>
</section><div class="ltx_rdf" about="" property="dcterms:creator" content="Anonymous Authors"></div>
<div class="ltx_rdf" about="" property="dcterms:subject"></div>
<div class="ltx_rdf" about="" property="dcterms:subject" content="mlsys 2022"></div>
<div class="ltx_rdf" about="" property="dcterms:title" content="FedSS: Federated Learning with Smart Selection of Clients"></div>

</article>
</div>
<div class="ar5iv-footer"><a href="/html/2207.04568" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2207.04569" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2207.04569">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2207.04569" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2207.04570" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Wed Mar 13 13:30:32 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
