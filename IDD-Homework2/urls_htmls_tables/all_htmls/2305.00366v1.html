<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2305.00366] S2abEL: A Dataset for Entity Linking from Scientific Tables</title><meta property="og:description" content="Entity linking (EL) is the task of linking a textual mention to its corresponding entry in a knowledge base, and is critical for many knowledge-intensive NLP applications. When applied to tables in scientific papers, E…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="S2abEL: A Dataset for Entity Linking from Scientific Tables">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="S2abEL: A Dataset for Entity Linking from Scientific Tables">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2305.00366">

<!--Generated on Thu Feb 29 10:37:47 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">S2abEL: A Dataset for Entity Linking from Scientific Tables</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
<span id="id8.6.6" class="ltx_inline-block ltx_parbox ltx_align_middle" style="width:433.6pt;">
<span id="id5.3.3.3" class="ltx_p">Yuze Lou<sup id="id5.3.3.3.1" class="ltx_sup">‡</sup>,
Bailey Kuehl<sup id="id5.3.3.3.2" class="ltx_sup">†</sup>,
Erin Bransom<sup id="id5.3.3.3.3" class="ltx_sup">†</sup>,</span>
<span id="id8.6.6.6" class="ltx_p ltx_align_center">Sergey Feldman<sup id="id8.6.6.6.1" class="ltx_sup">†</sup>,
Aakanksha Naik<sup id="id8.6.6.6.2" class="ltx_sup">†</sup>,
Doug Downey<sup id="id8.6.6.6.3" class="ltx_sup">†</sup></span>
</span>
</span><span class="ltx_author_notes">This work was conducted during the internship at AI2.
<span class="ltx_contact ltx_role_affiliation"><sup id="id9.7.id1" class="ltx_sup">‡</sup>University of Michigan, <sup id="id10.8.id2" class="ltx_sup">†</sup> Allen Institute for AI
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id11.id1" class="ltx_p">Entity linking (EL) is the task of linking a textual mention to its corresponding entry in a knowledge base, and is critical for many knowledge-intensive NLP applications. When applied to tables in scientific papers, EL is a step toward large-scale scientific knowledge bases that could enable advanced scientific question answering and analytics.
We present the first dataset for EL in scientific tables.
EL for scientific tables is especially challenging because scientific knowledge bases can be very incomplete, and disambiguating table mentions typically requires understanding the paper’s text in addition to the table.
Our dataset, S2abEL<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a target="_blank" href="https://github.com/allenai/S2abEL/blob/main/data/release_data.tar.gz" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/allenai/S2abEL/blob/main/data/release_data.tar.gz</a></span></span></span>, focuses on EL in machine learning results tables and includes hand-labeled cell types, attributed sources, and entity links from the PaperswithCode taxonomy for 8,429 cells from 732 tables.
We introduce a neural baseline method designed for EL on scientific tables containing many out-of-knowledge-base mentions, and show that it significantly outperforms a state-of-the-art generic table EL method.
The best baselines fall below human performance, and our analysis highlights avenues for improvement.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Entity Linking (EL) is a longstanding problem in natural language processing and information extraction. The goal of the task is to link textual mentions to their corresponding entities in a knowledge base (KB) <cite class="ltx_cite ltx_citemacro_citep">(Cucerzan, <a href="#bib.bib7" title="" class="ltx_ref">2007</a>)</cite>, and it serves as a building block for various knowledge-intensive applications, including search engines <cite class="ltx_cite ltx_citemacro_citep">(Blanco et al., <a href="#bib.bib4" title="" class="ltx_ref">2015</a>)</cite>, question-answering systems <cite class="ltx_cite ltx_citemacro_citep">(Dubey et al., <a href="#bib.bib10" title="" class="ltx_ref">2018</a>)</cite>, and more. However, existing EL methods and datasets primarily focus on linking mentions from free-form natural language <cite class="ltx_cite ltx_citemacro_citep">(Gu et al., <a href="#bib.bib12" title="" class="ltx_ref">2021</a>; De Cao et al., <a href="#bib.bib8" title="" class="ltx_ref">2021</a>; Li et al., <a href="#bib.bib25" title="" class="ltx_ref">2020</a>; Yamada et al., <a href="#bib.bib43" title="" class="ltx_ref">2022</a>)</cite>. Some consider tabular data, but focus on tables from the general domain <cite class="ltx_cite ltx_citemacro_citep">(Deng et al., <a href="#bib.bib9" title="" class="ltx_ref">2020</a>; Tang et al., <a href="#bib.bib39" title="" class="ltx_ref">2021b</a>; Iida et al., <a href="#bib.bib19" title="" class="ltx_ref">2021</a>; Yu et al., <a href="#bib.bib44" title="" class="ltx_ref">2019</a>)</cite>.
Despite significant research in EL, there is a lack of datasets and methods for EL in <em id="S1.p1.1.1" class="ltx_emph ltx_font_italic">scientific tables</em>. Linking entities in scientific tables holds promise for accelerating science in multiple ways: from augmented reading applications that help users understand the meaning of table cells without diving into the document <cite class="ltx_cite ltx_citemacro_cite">Head et al. (<a href="#bib.bib13" title="" class="ltx_ref">2021</a>)</cite> to automated knowledge base construction that unifies disparate tables, enabling complex question answering or hypothesis generation <cite class="ltx_cite ltx_citemacro_cite">Hope et al. (<a href="#bib.bib16" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2305.00366/assets/figures/Running_example.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="1196" height="585" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Part of a table in <em id="S1.F1.2.1" class="ltx_emph ltx_font_italic">OPT: Open Pre-trained Transformer Language Models</em> <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al., <a href="#bib.bib47" title="" class="ltx_ref">2022</a>)</cite> showing relevant context needs to be found for entity mentions in the table and part of EL results to PapersWithCode KB.</figcaption>
</figure>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">EL in science is challenging because the set of scientific entities is vast and always growing, and existing knowledge bases are highly incomplete.
A traditional "closed world" assumption often made in EL systems, whereby all mentions have corresponding entities in the target KB, is not realistic in scientific domains. It is important to detect which mentions are entities not yet in the reference KB, referred to as <em id="S1.p2.1.1" class="ltx_emph ltx_font_italic">outKB</em> mentions.
Even for human annotators, accurately identifying whether a rarely-seen surface form actually refers to a rarely-mentioned long-tail inKB entity or an outKB entity requires domain expertise and a significant effort to investigate the document and the target KB.
A further challenge is that entity mentions in scientific tables are often abbreviated and opaque, and require examining other context in the caption and paper text for disambiguation.
An example is shown in Figure <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ S2abEL: A Dataset for Entity Linking from Scientific Tables" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">In this paper, we make three main contributions.
First,
we introduce <em id="S1.p3.1.1" class="ltx_emph ltx_font_italic">S2abEL</em>, a high-quality human-annotated dataset for EL in machine learning results tables. The dataset is sufficiently large for training and evaluating models on table EL and relevant sub-tasks, including 52,257 annotations of appropriate types for table cells (e.g. method, dataset), 9,565 annotations of attributed source papers and candidate entities for mentions, and 8,429 annotations for entity disambiguation including outKB mentions. To the best of our knowledge, this is the first dataset for table EL in the scientific domain.
Second,
we propose a model that serves as a strong baseline for each of the sub-tasks, as well as end-to-end table EL.
We conduct a comprehensive comparison between our approach and existing approaches, where applicable, for each sub-task. Our method significantly outperforms TURL <cite class="ltx_cite ltx_citemacro_citep">(Deng et al., <a href="#bib.bib9" title="" class="ltx_ref">2020</a>)</cite>, a state-of-the-art method closest to the table EL task, but only designed for general-domain tables. We also provide a detailed error analysis that emphasizes the need for improved methods to address the unique challenges of EL from scientific tables with outKB mentions.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Entity Linking</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">In recent years, various approaches have been proposed for entity linking from free-form text, leveraging large language models <cite class="ltx_cite ltx_citemacro_citep">(Gu et al., <a href="#bib.bib12" title="" class="ltx_ref">2021</a>; De Cao et al., <a href="#bib.bib8" title="" class="ltx_ref">2021</a>; Li et al., <a href="#bib.bib25" title="" class="ltx_ref">2020</a>; Yamada et al., <a href="#bib.bib42" title="" class="ltx_ref">2019</a>)</cite>. Researchers have also attempted to extend EL to structured Web tables,
but they solely rely on table contents and do not have rich surrounding text <cite class="ltx_cite ltx_citemacro_citep">(Deng et al., <a href="#bib.bib9" title="" class="ltx_ref">2020</a>; Zhang et al., <a href="#bib.bib46" title="" class="ltx_ref">2020</a>; Bhagavatula et al., <a href="#bib.bib3" title="" class="ltx_ref">2015</a>; Mulwad et al., <a href="#bib.bib29" title="" class="ltx_ref">2023</a>; Tang et al., <a href="#bib.bib38" title="" class="ltx_ref">2020</a>; Iida et al., <a href="#bib.bib19" title="" class="ltx_ref">2021</a>)</cite>.
Most of these works focus on general-purpose KBs such as Wikidata <cite class="ltx_cite ltx_citemacro_citep">(Vrandečić and Krötzsch, <a href="#bib.bib40" title="" class="ltx_ref">2014</a>)</cite> and DBPedia <cite class="ltx_cite ltx_citemacro_citep">(Auer et al., <a href="#bib.bib1" title="" class="ltx_ref">2007</a>)</cite>
and typically test their approaches with the assumption that the target KB is complete with respect to the mentions being linked (e.g., <cite class="ltx_cite ltx_citemacro_citep">De Cao et al., <a href="#bib.bib8" title="" class="ltx_ref">2021</a>; Deng et al., <a href="#bib.bib9" title="" class="ltx_ref">2020</a>; Hoffart et al., <a href="#bib.bib15" title="" class="ltx_ref">2011</a>; Tang et al., <a href="#bib.bib37" title="" class="ltx_ref">2021a</a>; Yamada et al., <a href="#bib.bib42" title="" class="ltx_ref">2019</a></cite>).</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">There is a lack of high-quality datasets for table EL in the scientific domain with abundant outKB mentions.
Recent work by <cite class="ltx_cite ltx_citemacro_citet">Ruas and Couto (<a href="#bib.bib34" title="" class="ltx_ref">2022</a>)</cite>
provides a dataset that artificially mimics an incomplete KB for biomedical text by removing actual referent entities but linking concepts to the direct ancestor of the referent entities. In contrast, our work provides human-annotated labels of realistic missing entities for scientific tables, without relying on the target KB to contain ancestor relations. Our dataset offers two distinct advantages: first, it provides context from documents in addition to original table mentions, and second, it explicitly identifies mentions referring to outKB entities.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Scientific IE</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">The field of scientific information extraction (IE) aims to extract structured information from scientific documents. Various extraction tasks have been studied in this area, such as detecting and classifying semantic relations <cite class="ltx_cite ltx_citemacro_citep">(Jain et al., <a href="#bib.bib20" title="" class="ltx_ref">2020</a>; Sahu et al., <a href="#bib.bib35" title="" class="ltx_ref">2016</a>)</cite>, concept extraction <cite class="ltx_cite ltx_citemacro_citep">(Fu et al., <a href="#bib.bib11" title="" class="ltx_ref">2020</a>)</cite>, automatic leaderboard construction <cite class="ltx_cite ltx_citemacro_citep">(Kardas et al., <a href="#bib.bib22" title="" class="ltx_ref">2020</a>; Hou et al., <a href="#bib.bib17" title="" class="ltx_ref">2019</a>)</cite>, and citation analysis <cite class="ltx_cite ltx_citemacro_citep">(Jurgens et al., <a href="#bib.bib21" title="" class="ltx_ref">2018</a>; Cohan et al., <a href="#bib.bib5" title="" class="ltx_ref">2019</a>)</cite>.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p">Among these, <cite class="ltx_cite ltx_citemacro_citep">Kardas et al., <a href="#bib.bib22" title="" class="ltx_ref">2020</a>; Hou et al., <a href="#bib.bib17" title="" class="ltx_ref">2019</a>; Yu et al., <a href="#bib.bib44" title="" class="ltx_ref">2019</a>, <a href="#bib.bib45" title="" class="ltx_ref">2020</a></cite> are the closest to ours. These works focus on identifying mentions that refer to tasks, datasets, and metrics in table cells to construct leaderboard records.
However, they only identify entities as raw strings extracted from the set of papers they examine, without canonicalization, clustering, or actual linking to an external KB. For instance, in the dataset from <cite class="ltx_cite ltx_citemacro_citep">Kardas et al., <a href="#bib.bib22" title="" class="ltx_ref">2020</a></cite>, the ambiguous string <span id="S2.SS2.p2.1.1" class="ltx_text ltx_font_typewriter">Best Learner</span> is identified as a model entity, and similarly <span id="S2.SS2.p2.1.2" class="ltx_text ltx_font_typewriter">Score</span> is identified as a metric entity. Such incomplete and ambiguous entity identification makes it difficult for users to interpret the results and limits the practical applicability of the extracted information.
In contrast, we propose a dataset and baselines for the end-to-end table EL task, beginning with a table in the context of a paper and ending with each cell linked to entities in the canonicalized ontology of the target KB (or classified as outKB).</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Entity Linking in Scientific Tables</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">Our entity linking task takes as input a reference KB (the <em id="S3.p1.1.1" class="ltx_emph ltx_font_italic">Papers with Code</em><span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a target="_blank" href="https://paperswithcode.com/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://paperswithcode.com/</a></span></span></span> taxonomy in our experiments), a table in a scientific paper, and the table’s surrounding context. The goal is to output an entity from the KB for each table cell (or "outKB" if none). We decompose the task into several subtasks, discussed below. We then present S2abEL, the dataset we construct for scientific table EL.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Task Definition</h3>

<div id="S3.SS1.p1" class="ltx_para ltx_noindent">
<p id="S3.SS1.p1.1" class="ltx_p"><span id="S3.SS1.p1.1.1" class="ltx_text ltx_font_bold">Cell Type Classification (CTC)</span>
is the task of identifying types of entities contained in a table cell, based on the document in which the cell appears.
This step is helpful to focus the later linking task on the correct type of entities from the target KB, and also excludes non-entity cells (e.g. those containing numeric values used to report experimental results) from later processing. Such exclusion removes a substantial fraction of table cells (74% in our dataset), reducing the computational cost.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">One approach to CTC is to view it as a multi-label classification task since a cell may contain multiple entities of different types. However, our initial investigation found that only mentions of datasets and metrics co-appear to a notable degree (e.g., "QNLI (acc)" indicates the <em id="S3.SS1.p2.1.1" class="ltx_emph ltx_font_italic">accuracy</em> of some method evaluated on the <em id="S3.SS1.p2.1.2" class="ltx_emph ltx_font_italic">Question-answering NLI</em> dataset <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a href="#bib.bib41" title="" class="ltx_ref">2018</a>)</cite>). Therefore, we introduce a separate class for these instances, reducing CTC to a <span id="S3.SS1.p2.1.3" class="ltx_text ltx_font_bold">single-label</span> classification task with four positive classes: <em id="S3.SS1.p2.1.4" class="ltx_emph ltx_font_italic">method</em>, <em id="S3.SS1.p2.1.5" class="ltx_emph ltx_font_italic">dataset</em>, <em id="S3.SS1.p2.1.6" class="ltx_emph ltx_font_italic">metric</em>, and <em id="S3.SS1.p2.1.7" class="ltx_emph ltx_font_italic">dataset&amp;metric</em>.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para ltx_noindent">
<p id="S3.SS1.p3.3" class="ltx_p"><span id="S3.SS1.p3.3.1" class="ltx_text ltx_font_bold">Attributed Source Matching (ASM)</span> is the task of identifying <em id="S3.SS1.p3.3.2" class="ltx_emph ltx_font_italic">attributed source(s)</em>
for a table cell within the context of the document. The <em id="S3.SS1.p3.3.3" class="ltx_emph ltx_font_italic">attributed source(s)</em> for a concept in a document <math id="S3.SS1.p3.1.m1.1" class="ltx_Math" alttext="p" display="inline"><semantics id="S3.SS1.p3.1.m1.1a"><mi id="S3.SS1.p3.1.m1.1.1" xref="S3.SS1.p3.1.m1.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.1.m1.1b"><ci id="S3.SS1.p3.1.m1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.1.m1.1c">p</annotation></semantics></math> is the reference paper mentioned in <math id="S3.SS1.p3.2.m2.1" class="ltx_Math" alttext="p" display="inline"><semantics id="S3.SS1.p3.2.m2.1a"><mi id="S3.SS1.p3.2.m2.1.1" xref="S3.SS1.p3.2.m2.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.2.m2.1b"><ci id="S3.SS1.p3.2.m2.1.1.cmml" xref="S3.SS1.p3.2.m2.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.2.m2.1c">p</annotation></semantics></math> to which the authors of <math id="S3.SS1.p3.3.m3.1" class="ltx_Math" alttext="p" display="inline"><semantics id="S3.SS1.p3.3.m3.1a"><mi id="S3.SS1.p3.3.m3.1.1" xref="S3.SS1.p3.3.m3.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.3.m3.1b"><ci id="S3.SS1.p3.3.m3.1.1.cmml" xref="S3.SS1.p3.3.m3.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.3.m3.1c">p</annotation></semantics></math> attribute the concept. ASM is a crucial step in distinguishing similar surface forms and finding the correct referent entities. For example in Figure <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ S2abEL: A Dataset for Entity Linking from Scientific Tables" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, ASM can help clarify which entities "BlenderBot 1" and "R2C2 BlenderBot" refer to, as the first mention is attributed to <cite class="ltx_cite ltx_citemacro_citep">Roller et al., <a href="#bib.bib33" title="" class="ltx_ref">2021</a></cite> while the second mention is attributed to <cite class="ltx_cite ltx_citemacro_citep">Shuster et al., <a href="#bib.bib36" title="" class="ltx_ref">2022</a></cite>. Identifying these attributions helps a system uniquely identify these two entities despite their very similar surface forms and the fact that their contexts in the document often overlap. In this work, we consider the
documents listed in the reference section and the document itself as potential sources for attribution. The inclusion of the document itself is necessary since concepts may be introduced in the current document for the first time.</p>
</div>
<div id="S3.SS1.p4" class="ltx_para ltx_noindent">
<p id="S3.SS1.p4.1" class="ltx_p"><span id="S3.SS1.p4.1.1" class="ltx_text ltx_font_bold">Candidate Entity Retrieval (CER)</span> is the process of identifying a small set of entities from the target KB that are most likely to be the referent entity for a table cell within the context of the document. The purpose of this step is to exclude unlikely candidates and pass only a limited number of candidates to the next step, to reduce computational cost.</p>
</div>
<div id="S3.SS1.p5" class="ltx_para ltx_noindent">
<p id="S3.SS1.p5.1" class="ltx_p"><span id="S3.SS1.p5.1.1" class="ltx_text ltx_font_bold">Entity Disambiguation (ED) with outKB Identification</span> is the final stage. The objective is to determine the referent entity (or report <em id="S3.SS1.p5.1.2" class="ltx_emph ltx_font_italic">outKB</em> if none), given a table cell and its candidate entity set.
The identification of outKB mentions significantly increases the complexity of the EL task, as it requires the method to differentiate between e.g. an unusual surface form of an inKB entity versus an outKB mention. However, distinguishing outKB mentions is a critical step in rapidly evolving domains like science, where existing KBs are highly incomplete.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Dataset Construction</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">Obtaining high-quality annotations for S2abEL is non-trivial. Identifying attributed sources and gold entities requires a global understanding of the text and tables in the full document. However, asking annotators to read every paper fully is prohibitively expensive. Presenting the full list of entities in the target KB to link from is also not feasible, while showing annotators short auto-populated candidate entity sets may introduce bias and miss gold entities. We address these challenges by designing a special-purpose annotation interface and pipeline, as detailed below.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">In the construction process, we used two in-house annotators with backgrounds in data analytics and data science, both having extensive experience in reading and annotating scientific papers. In addition, one author of the paper (author A) led and initial training phase with the annotators, and another author of the paper (author B) was responsible for evaluating the inter-annotator agreement (IAA) at the end of the annotation process.
</p>
</div>
<div id="S3.SS2.p3" class="ltx_para ltx_noindent">
<p id="S3.SS2.p3.1" class="ltx_p"><span id="S3.SS2.p3.1.1" class="ltx_text ltx_font_bold">Bootstrapping existing resources</span> — We began constructing our dataset by populating it with tables and cell type annotations from SegmentedTables<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a target="_blank" href="https://github.com/paperswithcode/axcell/releases" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/paperswithcode/axcell/releases</a></span></span></span> <cite class="ltx_cite ltx_citemacro_citep">(Kardas et al., <a href="#bib.bib22" title="" class="ltx_ref">2020</a>)</cite>, a CTC dataset where each cell is annotated according to whether it is a paper, metric, and so on.
To gather data for the ASM task, we fine-tuned a T5-small <cite class="ltx_cite ltx_citemacro_citep">(Raffel et al., <a href="#bib.bib30" title="" class="ltx_ref">2022</a>)</cite> model to extract the last name of the first author, year, and title for each paper that appears in the reference section of any papers in our dataset from the raw reference strings. We then used the extracted information to search for matching papers in Semantic Scholar <cite class="ltx_cite ltx_citemacro_citep">(Kinney et al., <a href="#bib.bib24" title="" class="ltx_ref">2023</a>)</cite>, to obtain their abstracts. Since the search APIs do not always return the matching paper at the top of the results, we manually verified the output for each query.</p>
</div>
<div id="S3.SS2.p4" class="ltx_para ltx_noindent">
<p id="S3.SS2.p4.1" class="ltx_p"><span id="S3.SS2.p4.1.1" class="ltx_text ltx_font_bold">Target KB</span> — Papers with Code (PwC)<span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>Our corpus is based on Papers with Code 2022/07 dump.</span></span></span><span id="footnote5" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span><a target="_blank" href="https://github.com/paperswithcode/paperswithcode-data" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/paperswithcode/paperswithcode-data</a></span></span></span> is a free and open knowledge base in the scientific domain with a total of 304,611 papers, 6,550 datasets, and 1,942 methods as of this writing. PwC includes basic relations between entities, such as relevant entities for a paper, the introducing paper for an entity, etc. Its data is collected from previously curated results and collaboratively edited by the community. While the KB has good precision, its coverage is not exhaustive — in our experiments, 42.8% of our entity mentions are outKB.</p>
</div>
<div id="S3.SS2.p5" class="ltx_para ltx_noindent">
<p id="S3.SS2.p5.1" class="ltx_p"><span id="S3.SS2.p5.1.1" class="ltx_text ltx_font_bold">Human Annotation</span> — We developed a web interface using the Flask<span id="footnote6" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span><a href="flask.palletsprojects.com" title="" class="ltx_ref ltx_url ltx_font_typewriter">flask.palletsprojects.com</a></span></span></span> library for the annotation process. It provides annotators with a link to the original paper, an indexed reference section, and annotation guidelines.</p>
</div>
<div id="S3.SS2.p6" class="ltx_para">
<p id="S3.SS2.p6.1" class="ltx_p">For the CTC sub-task,
we asked annotators to make necessary modifications to correct errors in SegmentedTables and accommodate the extra <em id="S3.SS2.p6.1.1" class="ltx_emph ltx_font_italic">dataset&amp;metric</em> class. During this phase, 15% of the original labels were changed. For the ASM sub-task, annotators were asked to read relevant document sections for each cell and identify attributed sources, if any. This step can require a global understanding of the document, but candidate lists are relatively small since reference sections usually contain just tens of papers. For the EL sub-task, the web interface populates each cell with entity candidates that are 1) returned from PwC with the cell content as the search string, and/or 2) associated with the identified attributed paper(s) for this cell via the <em id="S3.SS2.p6.1.2" class="ltx_emph ltx_font_italic">Paper-RelatesTo-Entity</em> relation in PwC.
Automatic candidate population is designed to be preliminary to prevent annotators from believing that gold entities should always come from the candidate set. Annotators were also asked to search against PwC using different surface forms of the cell content (e.g., full name, part of the cell content) before concluding that a cell refers to an outKB entity.</p>
</div>
<div id="S3.SS2.p7" class="ltx_para">
<p id="S3.SS2.p7.1" class="ltx_p">To ensure consistency and high quality, we conducted a training phase led by author A, where the two annotators were given four papers at a time to perform all annotation tasks. We then calculated the IAA between author A and each annotator for the four papers using Cohen’s Kappa  <cite class="ltx_cite ltx_citemacro_citep">(McHugh, <a href="#bib.bib28" title="" class="ltx_ref">2012</a>)</cite>, followed by disagreement discussion and guideline refinement. This process was repeated for three training rounds using different sets of papers until the IAA score was substantial (i.e., 100% for CTC, 82% for ASM, and 66% for EL). Afterward, the remaining set of papers was given to the annotators for annotation. The complete annotation instructions and web interface can be found in Appendix <a href="#A3" title="Appendix C Annotation Interface and Guidelines ‣ S2abEL: A Dataset for Entity Linking from Scientific Tables" class="ltx_ref"><span class="ltx_text ltx_ref_tag">C</span></a>.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Dataset and Annotation Statistics</h3>

<div id="S3.SS3.p1" class="ltx_para ltx_noindent">
<p id="S3.SS3.p1.1" class="ltx_p"><span id="S3.SS3.p1.1.1" class="ltx_text ltx_font_bold">Dataset Statistics</span> — Table <a href="#S3.T1" title="Table 1 ‣ 3.3 Dataset and Annotation Statistics ‣ 3 Entity Linking in Scientific Tables ‣ S2abEL: A Dataset for Entity Linking from Scientific Tables" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> provides a summary of the statistics for S2abEL, publicly available on GitHub<span id="footnote7" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span><a target="_blank" href="https://github.com/allenai/S2abEL/blob/main/data/release_data.tar.gz" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/allenai/S2abEL/blob/main/data/release_data.tar.gz</a></span></span></span>.
ASM and EL annotations are only available for cells labeled positively in CTC. Metrics only are not linked to entities due to the lack of a controlled metric ontology in PwC. It is worth noting that S2abEL contains 3,610 outKB mentions versus 4,819 inKB mentions, presenting a significantly different challenge from prior datasets that mostly handle inKB mentions.
More details are in Appendix <a href="#A1" title="Appendix A Detailed Dataset Statistics ‣ S2abEL: A Dataset for Entity Linking from Scientific Tables" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A</span></a>.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para ltx_noindent">
<p id="S3.SS3.p2.1" class="ltx_p"><span id="S3.SS3.p2.1.1" class="ltx_text ltx_font_bold">Post-hoc IAA Evaluation</span> —
We conducted a post-hoc evaluation to verify the quality of annotations, where author B, who is a researcher with a Ph.D. in Computer Science, independently annotated five random tables.
The Cohen’s Kappa scores show a substantial level of agreement <cite class="ltx_cite ltx_citemacro_citep">(McHugh, <a href="#bib.bib28" title="" class="ltx_ref">2012</a>)</cite> between author B and the annotations (100% for CTC, 85.5% for ASM, and 60.6% for EL). These results demonstrate the quality and reliability of the annotations in S2abEL.</p>
</div>
<figure id="S3.T1" class="ltx_table">
<div id="S3.T1.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:346.9pt;height:147.7pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(88.9pt,-37.9pt) scale(2.05196889354264,2.05196889354264) ;">
<table id="S3.T1.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T1.1.1.1" class="ltx_tr">
<td id="S3.T1.1.1.1.1" class="ltx_td ltx_border_tt" style="padding-top:-1.5pt;padding-bottom:-1.5pt;"></td>
<td id="S3.T1.1.1.1.2" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">CTC</td>
<td id="S3.T1.1.1.1.3" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">APM</td>
<td id="S3.T1.1.1.1.4" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">EL</td>
</tr>
<tr id="S3.T1.1.1.2" class="ltx_tr">
<td id="S3.T1.1.1.2.1" class="ltx_td ltx_align_left ltx_border_t" style="padding-top:-1.5pt;padding-bottom:-1.5pt;"># papers</td>
<td id="S3.T1.1.1.2.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">327</td>
<td id="S3.T1.1.1.2.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">316</td>
<td id="S3.T1.1.1.2.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">303</td>
</tr>
<tr id="S3.T1.1.1.3" class="ltx_tr">
<td id="S3.T1.1.1.3.1" class="ltx_td ltx_align_left" style="padding-top:-1.5pt;padding-bottom:-1.5pt;"># tables</td>
<td id="S3.T1.1.1.3.2" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">886</td>
<td id="S3.T1.1.1.3.3" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">790</td>
<td id="S3.T1.1.1.3.4" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">732</td>
</tr>
<tr id="S3.T1.1.1.4" class="ltx_tr">
<td id="S3.T1.1.1.4.1" class="ltx_td ltx_align_left ltx_border_bb" style="padding-top:-1.5pt;padding-bottom:-1.5pt;"># cells</td>
<td id="S3.T1.1.1.4.2" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">52,257</td>
<td id="S3.T1.1.1.4.3" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">9,564</td>
<td id="S3.T1.1.1.4.4" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">8,429</td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Overall statistics of S2abEL. It consists of 52,257 data points for cell types, 9,564 for attributed source matching, and 8,429 for entity linking, with ground truth.</figcaption>
</figure>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Method</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">In this section, we describe our approach for representing table cells, papers, and KB entities, as well as our model design for performing each of the sub-tasks defined in Section <a href="#S3.SS1" title="3.1 Task Definition ‣ 3 Entity Linking in Scientific Tables ‣ S2abEL: A Dataset for Entity Linking from Scientific Tables" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a></p>
</div>
<div id="S4.p2" class="ltx_para ltx_noindent">
<p id="S4.p2.1" class="ltx_p"><span id="S4.p2.1.1" class="ltx_text ltx_font_bold">Cell Representation</span> — For each table cell in a document,
we collect information from both document text and the surrounding table.
Top-ranked sentences were retrieved using BM25 <cite class="ltx_cite ltx_citemacro_citep">(Robertson and Zaragoza, <a href="#bib.bib32" title="" class="ltx_ref">2009</a>)</cite> as context sentences, which often include explanations and descriptions of the table cell. The surrounding table captures the row and column context of the cell, which can offer valuable hints, such as the fact that mentions in the same row and column usually refer to the same type of entities.
More details about cell representation features are in Appendix <a href="#A2.T9" title="Table 9 ‣ Appendix B Training Details ‣ S2abEL: A Dataset for Entity Linking from Scientific Tables" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>.</p>
</div>
<div id="S4.p3" class="ltx_para ltx_noindent">
<p id="S4.p3.1" class="ltx_p"><span id="S4.p3.1.1" class="ltx_text ltx_font_bold">Paper Representation</span> —
For each referenced paper, we extract its index in the reference section, the last name of the first author, year, title, and abstract. Index, author name, and year are helpful for identifying inline citations (which frequently take the form of the index in brackets or the author and year in parens). Additionally, the title and abstract provide a summary of a paper which may contain information on new concepts it proposes.
</p>
</div>
<div id="S4.p4" class="ltx_para ltx_noindent">
<p id="S4.p4.1" class="ltx_p"><span id="S4.p4.1.1" class="ltx_text ltx_font_bold">KB Entity Representation</span> —
To represent each entity in the target KB, we use its abbreviation, full name, and description from the KB, if available.
The abbreviation and full name of an entity are crucial for capturing exact mentions in the text, while the description provides additional context for the entity <cite class="ltx_cite ltx_citemacro_citep">(Logeswaran et al., <a href="#bib.bib26" title="" class="ltx_ref">2019</a>)</cite>.</p>
</div>
<div id="S4.p5" class="ltx_para ltx_noindent">
<p id="S4.p5.1" class="ltx_p"><span id="S4.p5.1.1" class="ltx_text ltx_font_bold">Cell Type Classification</span> —
We concatenate features of cell representation (separated by special tokens) and input the resulting sequence to the pre-trained language model SciBERT <cite class="ltx_cite ltx_citemacro_citep">(Beltagy et al., <a href="#bib.bib2" title="" class="ltx_ref">2019</a>)</cite>. For each token in the input sequence, we augment its word embedding vector with an additional trainable embedding vector from a separate embedding layer to differentiate whether a token is in the cell, from context sentences, etc. Subsequent mentions of SciBERT in the paper refers to this modified version.
We pass the average of the output token embeddings at the last layer to a linear output layer and optimize for Cross Entropy loss.
However, because the majority of cells in scientific tables pertain to experimental statistics, the distribution of cell types is highly imbalanced (as shown in Appendix <a href="#A1" title="Appendix A Detailed Dataset Statistics ‣ S2abEL: A Dataset for Entity Linking from Scientific Tables" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A</span></a>).
To address this issue, we oversample the minority class data by randomly shuffling the context sentences.</p>
</div>
<div id="S4.p6" class="ltx_para ltx_noindent">
<p id="S4.p6.1" class="ltx_p"><span id="S4.p6.1.1" class="ltx_text ltx_font_bold">Attributed Source Matching</span> —
To enable contextualization between cell context and a potential source, we combine the representations of each table cell and potential attributed source in the document as the input to a SciBERT followed by a linear output layer. We optimize for the Binary Cross Entropy loss, where all non-attributed sources in the document are used as negative examples for a cell. The model output measures the likelihood that a source should be attributed to given a table cell.</p>
</div>
<div id="S4.p7" class="ltx_para ltx_noindent">
<p id="S4.p7.1" class="ltx_p"><span id="S4.p7.1.1" class="ltx_text ltx_font_bold">Candidate Entity Retrieval</span> —
We design a method that combines candidates retrieved by two strategies: (i) <em id="S4.p7.1.2" class="ltx_emph ltx_font_italic">dense retrieval (DR)</em> <cite class="ltx_cite ltx_citemacro_cite">Karpukhin et al. (<a href="#bib.bib23" title="" class="ltx_ref">2020</a>)</cite> that leverages embeddings to represent latent semantics of table cells and entities, and (ii) <em id="S4.p7.1.3" class="ltx_emph ltx_font_italic">attributed source retrieval (ASR)</em> which uses the attributed source information to retrieve candidate entities.</p>
</div>
<div id="S4.p8" class="ltx_para">
<p id="S4.p8.2" class="ltx_p">For DR, we fine-tune a bi-encoder architecture <cite class="ltx_cite ltx_citemacro_citep">(Reimers and Gurevych, <a href="#bib.bib31" title="" class="ltx_ref">2019</a>)</cite> with two separate SciBERT to optimize a triplet objective function.
The model is only trained on cells whose gold referent entity exists in the KB. Top-ranked most similar entities based on the BM25F algorithm <cite class="ltx_cite ltx_citemacro_citep">(Robertson and Zaragoza, <a href="#bib.bib32" title="" class="ltx_ref">2009</a>)</cite><span id="footnote8" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span>We chose to use BM25F instead of BM25 because it can take into account entity data with several fields, including name, full name, and description.</span></span></span> in Elasticsearch, are used as negative examples.
For each table cell <math id="S4.p8.1.m1.1" class="ltx_Math" alttext="t_{i}" display="inline"><semantics id="S4.p8.1.m1.1a"><msub id="S4.p8.1.m1.1.1" xref="S4.p8.1.m1.1.1.cmml"><mi id="S4.p8.1.m1.1.1.2" xref="S4.p8.1.m1.1.1.2.cmml">t</mi><mi id="S4.p8.1.m1.1.1.3" xref="S4.p8.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.p8.1.m1.1b"><apply id="S4.p8.1.m1.1.1.cmml" xref="S4.p8.1.m1.1.1"><csymbol cd="ambiguous" id="S4.p8.1.m1.1.1.1.cmml" xref="S4.p8.1.m1.1.1">subscript</csymbol><ci id="S4.p8.1.m1.1.1.2.cmml" xref="S4.p8.1.m1.1.1.2">𝑡</ci><ci id="S4.p8.1.m1.1.1.3.cmml" xref="S4.p8.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p8.1.m1.1c">t_{i}</annotation></semantics></math>, the top-k nearest entities <math id="S4.p8.2.m2.1" class="ltx_Math" alttext="\mathcal{O}^{i}_{dr}" display="inline"><semantics id="S4.p8.2.m2.1a"><msubsup id="S4.p8.2.m2.1.1" xref="S4.p8.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.p8.2.m2.1.1.2.2" xref="S4.p8.2.m2.1.1.2.2.cmml">𝒪</mi><mrow id="S4.p8.2.m2.1.1.3" xref="S4.p8.2.m2.1.1.3.cmml"><mi id="S4.p8.2.m2.1.1.3.2" xref="S4.p8.2.m2.1.1.3.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="S4.p8.2.m2.1.1.3.1" xref="S4.p8.2.m2.1.1.3.1.cmml">​</mo><mi id="S4.p8.2.m2.1.1.3.3" xref="S4.p8.2.m2.1.1.3.3.cmml">r</mi></mrow><mi id="S4.p8.2.m2.1.1.2.3" xref="S4.p8.2.m2.1.1.2.3.cmml">i</mi></msubsup><annotation-xml encoding="MathML-Content" id="S4.p8.2.m2.1b"><apply id="S4.p8.2.m2.1.1.cmml" xref="S4.p8.2.m2.1.1"><csymbol cd="ambiguous" id="S4.p8.2.m2.1.1.1.cmml" xref="S4.p8.2.m2.1.1">subscript</csymbol><apply id="S4.p8.2.m2.1.1.2.cmml" xref="S4.p8.2.m2.1.1"><csymbol cd="ambiguous" id="S4.p8.2.m2.1.1.2.1.cmml" xref="S4.p8.2.m2.1.1">superscript</csymbol><ci id="S4.p8.2.m2.1.1.2.2.cmml" xref="S4.p8.2.m2.1.1.2.2">𝒪</ci><ci id="S4.p8.2.m2.1.1.2.3.cmml" xref="S4.p8.2.m2.1.1.2.3">𝑖</ci></apply><apply id="S4.p8.2.m2.1.1.3.cmml" xref="S4.p8.2.m2.1.1.3"><times id="S4.p8.2.m2.1.1.3.1.cmml" xref="S4.p8.2.m2.1.1.3.1"></times><ci id="S4.p8.2.m2.1.1.3.2.cmml" xref="S4.p8.2.m2.1.1.3.2">𝑑</ci><ci id="S4.p8.2.m2.1.1.3.3.cmml" xref="S4.p8.2.m2.1.1.3.3">𝑟</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p8.2.m2.1c">\mathcal{O}^{i}_{dr}</annotation></semantics></math> in the embedding space with ranks are returned as candidates.</p>
</div>
<div id="S4.p9" class="ltx_para">
<p id="S4.p9.1" class="ltx_p">For ASR, we use the trained ASM model to obtain a list of papers ranked by their probabilities of being the attributed source estimated by the model.
The candidate entity sequence <math id="S4.p9.1.m1.1" class="ltx_Math" alttext="\mathcal{O}^{i}_{asr}" display="inline"><semantics id="S4.p9.1.m1.1a"><msubsup id="S4.p9.1.m1.1.1" xref="S4.p9.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.p9.1.m1.1.1.2.2" xref="S4.p9.1.m1.1.1.2.2.cmml">𝒪</mi><mrow id="S4.p9.1.m1.1.1.3" xref="S4.p9.1.m1.1.1.3.cmml"><mi id="S4.p9.1.m1.1.1.3.2" xref="S4.p9.1.m1.1.1.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.p9.1.m1.1.1.3.1" xref="S4.p9.1.m1.1.1.3.1.cmml">​</mo><mi id="S4.p9.1.m1.1.1.3.3" xref="S4.p9.1.m1.1.1.3.3.cmml">s</mi><mo lspace="0em" rspace="0em" id="S4.p9.1.m1.1.1.3.1a" xref="S4.p9.1.m1.1.1.3.1.cmml">​</mo><mi id="S4.p9.1.m1.1.1.3.4" xref="S4.p9.1.m1.1.1.3.4.cmml">r</mi></mrow><mi id="S4.p9.1.m1.1.1.2.3" xref="S4.p9.1.m1.1.1.2.3.cmml">i</mi></msubsup><annotation-xml encoding="MathML-Content" id="S4.p9.1.m1.1b"><apply id="S4.p9.1.m1.1.1.cmml" xref="S4.p9.1.m1.1.1"><csymbol cd="ambiguous" id="S4.p9.1.m1.1.1.1.cmml" xref="S4.p9.1.m1.1.1">subscript</csymbol><apply id="S4.p9.1.m1.1.1.2.cmml" xref="S4.p9.1.m1.1.1"><csymbol cd="ambiguous" id="S4.p9.1.m1.1.1.2.1.cmml" xref="S4.p9.1.m1.1.1">superscript</csymbol><ci id="S4.p9.1.m1.1.1.2.2.cmml" xref="S4.p9.1.m1.1.1.2.2">𝒪</ci><ci id="S4.p9.1.m1.1.1.2.3.cmml" xref="S4.p9.1.m1.1.1.2.3">𝑖</ci></apply><apply id="S4.p9.1.m1.1.1.3.cmml" xref="S4.p9.1.m1.1.1.3"><times id="S4.p9.1.m1.1.1.3.1.cmml" xref="S4.p9.1.m1.1.1.3.1"></times><ci id="S4.p9.1.m1.1.1.3.2.cmml" xref="S4.p9.1.m1.1.1.3.2">𝑎</ci><ci id="S4.p9.1.m1.1.1.3.3.cmml" xref="S4.p9.1.m1.1.1.3.3">𝑠</ci><ci id="S4.p9.1.m1.1.1.3.4.cmml" xref="S4.p9.1.m1.1.1.3.4">𝑟</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p9.1.m1.1c">\mathcal{O}^{i}_{asr}</annotation></semantics></math> is constructed by fetching entities associated with each potentially attributed paper
in ranked order using the <em id="S4.p9.1.1" class="ltx_emph ltx_font_italic">Paper-RelatesTo-Entity</em> relations in PwC. Only entities of the same cell type as identified in CTC are retained.
Note that including entities associated with lower-ranked papers mitigates the errors propagated from the ASM model and the problem of imperfect entity and relation coverage that is common in real-world KBs.</p>
</div>
<div id="S4.p10" class="ltx_para">
<p id="S4.p10.3" class="ltx_p">We finally interleave <math id="S4.p10.1.m1.1" class="ltx_Math" alttext="\mathcal{O}^{i}_{dr}" display="inline"><semantics id="S4.p10.1.m1.1a"><msubsup id="S4.p10.1.m1.1.1" xref="S4.p10.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.p10.1.m1.1.1.2.2" xref="S4.p10.1.m1.1.1.2.2.cmml">𝒪</mi><mrow id="S4.p10.1.m1.1.1.3" xref="S4.p10.1.m1.1.1.3.cmml"><mi id="S4.p10.1.m1.1.1.3.2" xref="S4.p10.1.m1.1.1.3.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="S4.p10.1.m1.1.1.3.1" xref="S4.p10.1.m1.1.1.3.1.cmml">​</mo><mi id="S4.p10.1.m1.1.1.3.3" xref="S4.p10.1.m1.1.1.3.3.cmml">r</mi></mrow><mi id="S4.p10.1.m1.1.1.2.3" xref="S4.p10.1.m1.1.1.2.3.cmml">i</mi></msubsup><annotation-xml encoding="MathML-Content" id="S4.p10.1.m1.1b"><apply id="S4.p10.1.m1.1.1.cmml" xref="S4.p10.1.m1.1.1"><csymbol cd="ambiguous" id="S4.p10.1.m1.1.1.1.cmml" xref="S4.p10.1.m1.1.1">subscript</csymbol><apply id="S4.p10.1.m1.1.1.2.cmml" xref="S4.p10.1.m1.1.1"><csymbol cd="ambiguous" id="S4.p10.1.m1.1.1.2.1.cmml" xref="S4.p10.1.m1.1.1">superscript</csymbol><ci id="S4.p10.1.m1.1.1.2.2.cmml" xref="S4.p10.1.m1.1.1.2.2">𝒪</ci><ci id="S4.p10.1.m1.1.1.2.3.cmml" xref="S4.p10.1.m1.1.1.2.3">𝑖</ci></apply><apply id="S4.p10.1.m1.1.1.3.cmml" xref="S4.p10.1.m1.1.1.3"><times id="S4.p10.1.m1.1.1.3.1.cmml" xref="S4.p10.1.m1.1.1.3.1"></times><ci id="S4.p10.1.m1.1.1.3.2.cmml" xref="S4.p10.1.m1.1.1.3.2">𝑑</ci><ci id="S4.p10.1.m1.1.1.3.3.cmml" xref="S4.p10.1.m1.1.1.3.3">𝑟</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p10.1.m1.1c">\mathcal{O}^{i}_{dr}</annotation></semantics></math> and <math id="S4.p10.2.m2.1" class="ltx_Math" alttext="\mathcal{O}^{i}_{asr}" display="inline"><semantics id="S4.p10.2.m2.1a"><msubsup id="S4.p10.2.m2.1.1" xref="S4.p10.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.p10.2.m2.1.1.2.2" xref="S4.p10.2.m2.1.1.2.2.cmml">𝒪</mi><mrow id="S4.p10.2.m2.1.1.3" xref="S4.p10.2.m2.1.1.3.cmml"><mi id="S4.p10.2.m2.1.1.3.2" xref="S4.p10.2.m2.1.1.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.p10.2.m2.1.1.3.1" xref="S4.p10.2.m2.1.1.3.1.cmml">​</mo><mi id="S4.p10.2.m2.1.1.3.3" xref="S4.p10.2.m2.1.1.3.3.cmml">s</mi><mo lspace="0em" rspace="0em" id="S4.p10.2.m2.1.1.3.1a" xref="S4.p10.2.m2.1.1.3.1.cmml">​</mo><mi id="S4.p10.2.m2.1.1.3.4" xref="S4.p10.2.m2.1.1.3.4.cmml">r</mi></mrow><mi id="S4.p10.2.m2.1.1.2.3" xref="S4.p10.2.m2.1.1.2.3.cmml">i</mi></msubsup><annotation-xml encoding="MathML-Content" id="S4.p10.2.m2.1b"><apply id="S4.p10.2.m2.1.1.cmml" xref="S4.p10.2.m2.1.1"><csymbol cd="ambiguous" id="S4.p10.2.m2.1.1.1.cmml" xref="S4.p10.2.m2.1.1">subscript</csymbol><apply id="S4.p10.2.m2.1.1.2.cmml" xref="S4.p10.2.m2.1.1"><csymbol cd="ambiguous" id="S4.p10.2.m2.1.1.2.1.cmml" xref="S4.p10.2.m2.1.1">superscript</csymbol><ci id="S4.p10.2.m2.1.1.2.2.cmml" xref="S4.p10.2.m2.1.1.2.2">𝒪</ci><ci id="S4.p10.2.m2.1.1.2.3.cmml" xref="S4.p10.2.m2.1.1.2.3">𝑖</ci></apply><apply id="S4.p10.2.m2.1.1.3.cmml" xref="S4.p10.2.m2.1.1.3"><times id="S4.p10.2.m2.1.1.3.1.cmml" xref="S4.p10.2.m2.1.1.3.1"></times><ci id="S4.p10.2.m2.1.1.3.2.cmml" xref="S4.p10.2.m2.1.1.3.2">𝑎</ci><ci id="S4.p10.2.m2.1.1.3.3.cmml" xref="S4.p10.2.m2.1.1.3.3">𝑠</ci><ci id="S4.p10.2.m2.1.1.3.4.cmml" xref="S4.p10.2.m2.1.1.3.4">𝑟</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p10.2.m2.1c">\mathcal{O}^{i}_{asr}</annotation></semantics></math> until we reach a pre-defined entity set size <math id="S4.p10.3.m3.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S4.p10.3.m3.1a"><mi id="S4.p10.3.m3.1.1" xref="S4.p10.3.m3.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S4.p10.3.m3.1b"><ci id="S4.p10.3.m3.1.1.cmml" xref="S4.p10.3.m3.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p10.3.m3.1c">K</annotation></semantics></math>.</p>
</div>
<div id="S4.p11" class="ltx_para ltx_noindent">
<p id="S4.p11.1" class="ltx_p"><span id="S4.p11.1.1" class="ltx_text ltx_font_bold">Entity Disambiguation with outKB Identification</span> —
Given a table cell and its entity candidates, we fine-tune a cross-encoder architecture <cite class="ltx_cite ltx_citemacro_citep">(Reimers and Gurevych, <a href="#bib.bib31" title="" class="ltx_ref">2019</a>)</cite> with a SciBERT that takes as input the fused cell representation and entity representation, followed by a linear output layer. We optimize for BCE loss using the same negative examples used in CER training. The trained model is used to estimate the probability that a table cell matches an entity.
If the top-ranked entity for a cell has a matching likelihood lower than 0.5, which is a commonly used threshold for binary classification, then the cell is considered to be outKB.
</p>
</div>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Evaluations</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">As no existing baselines exist for the end-to-end table EL task with outKB mention identification, we compare our methods against appropriate recent work by evaluating their performance on sub-tasks of our dataset (Section <a href="#S5.SS1" title="5.1 Evaluating Sub-tasks ‣ 5 Evaluations ‣ S2abEL: A Dataset for Entity Linking from Scientific Tables" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.1</span></a>).
Additionally, we report the performance of the end-to-end system to provide baseline results for future work (Section <a href="#S5.SS2" title="5.2 End-to-end Evaluation ‣ 5 Evaluations ‣ S2abEL: A Dataset for Entity Linking from Scientific Tables" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.2</span></a>).
Finally, to understand the connection and impact of each sub-task on the final EL performance, we conducted a component-wise ablation study (Section <a href="#S5.SS3" title="5.3 Component-wise Ablation Study ‣ 5 Evaluations ‣ S2abEL: A Dataset for Entity Linking from Scientific Tables" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.3</span></a>). This study provides valuable insights into the difficulties and bottlenecks in model performance. The implementation is available on GitHub<span id="footnote9" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note">9</span><a target="_blank" href="https://github.com/allenai/S2abEL" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/allenai/S2abEL</a></span></span></span>.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">The experiments are designed to evaluate the performance of methods in a cross-domain setting (following the setup in <cite class="ltx_cite ltx_citemacro_citep">Kardas et al., <a href="#bib.bib22" title="" class="ltx_ref">2020</a></cite>), where training, validation, and test data come from different disjoint topics. This ensures that the methods are not overfitting to the particular characteristics of a topic and can generalize well to unseen data from different topics.</p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Evaluating Sub-tasks</h3>

<section id="S5.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.1 </span>Cell Type Classification</h4>

<figure id="S5.T2" class="ltx_table">
<table id="S5.T2.5" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S5.T2.5.6" class="ltx_tr">
<td id="S5.T2.5.6.1" class="ltx_td ltx_align_left ltx_border_tt" style="padding-top:-1.5pt;padding-bottom:-1.5pt;" rowspan="3"><span id="S5.T2.5.6.1.1" class="ltx_text">Class</span></td>
<td id="S5.T2.5.6.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-top:-1.5pt;padding-bottom:-1.5pt;" colspan="6">Validation</td>
<td id="S5.T2.5.6.3" class="ltx_td ltx_border_tt" style="padding-top:-1.5pt;padding-bottom:-1.5pt;"></td>
<td id="S5.T2.5.6.4" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:-1.5pt;padding-bottom:-1.5pt;" colspan="6">Test</td>
</tr>
<tr id="S5.T2.5.7" class="ltx_tr">
<td id="S5.T2.5.7.1" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;" colspan="3">AxCell</td>
<td id="S5.T2.5.7.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:-1.5pt;padding-bottom:-1.5pt;" colspan="3">Ours</td>
<td id="S5.T2.5.7.3" class="ltx_td" style="padding-top:-1.5pt;padding-bottom:-1.5pt;"></td>
<td id="S5.T2.5.7.4" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;" colspan="3">AxCell</td>
<td id="S5.T2.5.7.5" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;" colspan="3">Ours</td>
</tr>
<tr id="S5.T2.4.4" class="ltx_tr">
<td id="S5.T2.4.4.5" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">P</td>
<td id="S5.T2.4.4.6" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">R</td>
<td id="S5.T2.1.1.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:-1.5pt;padding-bottom:-1.5pt;"><math id="S5.T2.1.1.1.m1.1" class="ltx_Math" alttext="F_{1}" display="inline"><semantics id="S5.T2.1.1.1.m1.1a"><msub id="S5.T2.1.1.1.m1.1.1" xref="S5.T2.1.1.1.m1.1.1.cmml"><mi id="S5.T2.1.1.1.m1.1.1.2" xref="S5.T2.1.1.1.m1.1.1.2.cmml">F</mi><mn id="S5.T2.1.1.1.m1.1.1.3" xref="S5.T2.1.1.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S5.T2.1.1.1.m1.1b"><apply id="S5.T2.1.1.1.m1.1.1.cmml" xref="S5.T2.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T2.1.1.1.m1.1.1.1.cmml" xref="S5.T2.1.1.1.m1.1.1">subscript</csymbol><ci id="S5.T2.1.1.1.m1.1.1.2.cmml" xref="S5.T2.1.1.1.m1.1.1.2">𝐹</ci><cn type="integer" id="S5.T2.1.1.1.m1.1.1.3.cmml" xref="S5.T2.1.1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.1.1.1.m1.1c">F_{1}</annotation></semantics></math></td>
<td id="S5.T2.4.4.7" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">P</td>
<td id="S5.T2.4.4.8" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">R</td>
<td id="S5.T2.2.2.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:-1.5pt;padding-bottom:-1.5pt;"><math id="S5.T2.2.2.2.m1.1" class="ltx_Math" alttext="F_{1}" display="inline"><semantics id="S5.T2.2.2.2.m1.1a"><msub id="S5.T2.2.2.2.m1.1.1" xref="S5.T2.2.2.2.m1.1.1.cmml"><mi id="S5.T2.2.2.2.m1.1.1.2" xref="S5.T2.2.2.2.m1.1.1.2.cmml">F</mi><mn id="S5.T2.2.2.2.m1.1.1.3" xref="S5.T2.2.2.2.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S5.T2.2.2.2.m1.1b"><apply id="S5.T2.2.2.2.m1.1.1.cmml" xref="S5.T2.2.2.2.m1.1.1"><csymbol cd="ambiguous" id="S5.T2.2.2.2.m1.1.1.1.cmml" xref="S5.T2.2.2.2.m1.1.1">subscript</csymbol><ci id="S5.T2.2.2.2.m1.1.1.2.cmml" xref="S5.T2.2.2.2.m1.1.1.2">𝐹</ci><cn type="integer" id="S5.T2.2.2.2.m1.1.1.3.cmml" xref="S5.T2.2.2.2.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.2.2.2.m1.1c">F_{1}</annotation></semantics></math></td>
<td id="S5.T2.4.4.9" class="ltx_td" style="padding-top:-1.5pt;padding-bottom:-1.5pt;"></td>
<td id="S5.T2.4.4.10" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">P</td>
<td id="S5.T2.4.4.11" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">R</td>
<td id="S5.T2.3.3.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:-1.5pt;padding-bottom:-1.5pt;"><math id="S5.T2.3.3.3.m1.1" class="ltx_Math" alttext="F_{1}" display="inline"><semantics id="S5.T2.3.3.3.m1.1a"><msub id="S5.T2.3.3.3.m1.1.1" xref="S5.T2.3.3.3.m1.1.1.cmml"><mi id="S5.T2.3.3.3.m1.1.1.2" xref="S5.T2.3.3.3.m1.1.1.2.cmml">F</mi><mn id="S5.T2.3.3.3.m1.1.1.3" xref="S5.T2.3.3.3.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S5.T2.3.3.3.m1.1b"><apply id="S5.T2.3.3.3.m1.1.1.cmml" xref="S5.T2.3.3.3.m1.1.1"><csymbol cd="ambiguous" id="S5.T2.3.3.3.m1.1.1.1.cmml" xref="S5.T2.3.3.3.m1.1.1">subscript</csymbol><ci id="S5.T2.3.3.3.m1.1.1.2.cmml" xref="S5.T2.3.3.3.m1.1.1.2">𝐹</ci><cn type="integer" id="S5.T2.3.3.3.m1.1.1.3.cmml" xref="S5.T2.3.3.3.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.3.3.3.m1.1c">F_{1}</annotation></semantics></math></td>
<td id="S5.T2.4.4.12" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">P</td>
<td id="S5.T2.4.4.13" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">R</td>
<td id="S5.T2.4.4.4" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;"><math id="S5.T2.4.4.4.m1.1" class="ltx_Math" alttext="F_{1}" display="inline"><semantics id="S5.T2.4.4.4.m1.1a"><msub id="S5.T2.4.4.4.m1.1.1" xref="S5.T2.4.4.4.m1.1.1.cmml"><mi id="S5.T2.4.4.4.m1.1.1.2" xref="S5.T2.4.4.4.m1.1.1.2.cmml">F</mi><mn id="S5.T2.4.4.4.m1.1.1.3" xref="S5.T2.4.4.4.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S5.T2.4.4.4.m1.1b"><apply id="S5.T2.4.4.4.m1.1.1.cmml" xref="S5.T2.4.4.4.m1.1.1"><csymbol cd="ambiguous" id="S5.T2.4.4.4.m1.1.1.1.cmml" xref="S5.T2.4.4.4.m1.1.1">subscript</csymbol><ci id="S5.T2.4.4.4.m1.1.1.2.cmml" xref="S5.T2.4.4.4.m1.1.1.2">𝐹</ci><cn type="integer" id="S5.T2.4.4.4.m1.1.1.3.cmml" xref="S5.T2.4.4.4.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.4.4.4.m1.1c">F_{1}</annotation></semantics></math></td>
</tr>
<tr id="S5.T2.5.8" class="ltx_tr">
<td id="S5.T2.5.8.1" class="ltx_td ltx_align_left ltx_border_t" style="padding-top:-1.5pt;padding-bottom:-1.5pt;"><em id="S5.T2.5.8.1.1" class="ltx_emph ltx_font_italic">other</em></td>
<td id="S5.T2.5.8.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">97.4</td>
<td id="S5.T2.5.8.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">98.6</td>
<td id="S5.T2.5.8.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">98.0</td>
<td id="S5.T2.5.8.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">98.4</td>
<td id="S5.T2.5.8.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">98.4</td>
<td id="S5.T2.5.8.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">98.4</td>
<td id="S5.T2.5.8.8" class="ltx_td ltx_border_t" style="padding-top:-1.5pt;padding-bottom:-1.5pt;"></td>
<td id="S5.T2.5.8.9" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">97.3</td>
<td id="S5.T2.5.8.10" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">98.4</td>
<td id="S5.T2.5.8.11" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">97.8</td>
<td id="S5.T2.5.8.12" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">98.0</td>
<td id="S5.T2.5.8.13" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">98.4</td>
<td id="S5.T2.5.8.14" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">98.1</td>
</tr>
<tr id="S5.T2.5.9" class="ltx_tr">
<td id="S5.T2.5.9.1" class="ltx_td ltx_align_left" style="padding-top:-1.5pt;padding-bottom:-1.5pt;"><em id="S5.T2.5.9.1.1" class="ltx_emph ltx_font_italic">dataset</em></td>
<td id="S5.T2.5.9.2" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">83.1</td>
<td id="S5.T2.5.9.3" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">81.7</td>
<td id="S5.T2.5.9.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">82.2</td>
<td id="S5.T2.5.9.5" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">83.0</td>
<td id="S5.T2.5.9.6" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">88.7</td>
<td id="S5.T2.5.9.7" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">85.6</td>
<td id="S5.T2.5.9.8" class="ltx_td" style="padding-top:-1.5pt;padding-bottom:-1.5pt;"></td>
<td id="S5.T2.5.9.9" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">90.0</td>
<td id="S5.T2.5.9.10" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">84.0</td>
<td id="S5.T2.5.9.11" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">86.2</td>
<td id="S5.T2.5.9.12" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">90.1</td>
<td id="S5.T2.5.9.13" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">82.3</td>
<td id="S5.T2.5.9.14" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">85.4</td>
</tr>
<tr id="S5.T2.5.10" class="ltx_tr">
<td id="S5.T2.5.10.1" class="ltx_td ltx_align_left" style="padding-top:-1.5pt;padding-bottom:-1.5pt;"><em id="S5.T2.5.10.1.1" class="ltx_emph ltx_font_italic">method</em></td>
<td id="S5.T2.5.10.2" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">96.7</td>
<td id="S5.T2.5.10.3" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">96.4</td>
<td id="S5.T2.5.10.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">96.6</td>
<td id="S5.T2.5.10.5" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">97.2</td>
<td id="S5.T2.5.10.6" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">96.8</td>
<td id="S5.T2.5.10.7" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">97.0</td>
<td id="S5.T2.5.10.8" class="ltx_td" style="padding-top:-1.5pt;padding-bottom:-1.5pt;"></td>
<td id="S5.T2.5.10.9" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">95.3</td>
<td id="S5.T2.5.10.10" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">95.5</td>
<td id="S5.T2.5.10.11" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">95.4</td>
<td id="S5.T2.5.10.12" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">93.4</td>
<td id="S5.T2.5.10.13" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">96.9</td>
<td id="S5.T2.5.10.14" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">95.1</td>
</tr>
<tr id="S5.T2.5.11" class="ltx_tr">
<td id="S5.T2.5.11.1" class="ltx_td ltx_align_left" style="padding-top:-1.5pt;padding-bottom:-1.5pt;"><em id="S5.T2.5.11.1.1" class="ltx_emph ltx_font_italic">metric</em></td>
<td id="S5.T2.5.11.2" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">71.3</td>
<td id="S5.T2.5.11.3" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">72.8</td>
<td id="S5.T2.5.11.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">71.9</td>
<td id="S5.T2.5.11.5" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">88.6</td>
<td id="S5.T2.5.11.6" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">79.7</td>
<td id="S5.T2.5.11.7" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">83.7</td>
<td id="S5.T2.5.11.8" class="ltx_td" style="padding-top:-1.5pt;padding-bottom:-1.5pt;"></td>
<td id="S5.T2.5.11.9" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">86.6</td>
<td id="S5.T2.5.11.10" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">86.1</td>
<td id="S5.T2.5.11.11" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">85.0</td>
<td id="S5.T2.5.11.12" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">88.0</td>
<td id="S5.T2.5.11.13" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">87.4</td>
<td id="S5.T2.5.11.14" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">86.8</td>
</tr>
<tr id="S5.T2.5.12" class="ltx_tr">
<td id="S5.T2.5.12.1" class="ltx_td ltx_align_left" style="padding-top:-1.5pt;padding-bottom:-1.5pt;"><em id="S5.T2.5.12.1.1" class="ltx_emph ltx_font_italic">dataset&amp;metric</em></td>
<td id="S5.T2.5.12.2" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">97.1</td>
<td id="S5.T2.5.12.3" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">41.9</td>
<td id="S5.T2.5.12.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">58.0</td>
<td id="S5.T2.5.12.5" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">88.8</td>
<td id="S5.T2.5.12.6" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">77.6</td>
<td id="S5.T2.5.12.7" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">82.1</td>
<td id="S5.T2.5.12.8" class="ltx_td" style="padding-top:-1.5pt;padding-bottom:-1.5pt;"></td>
<td id="S5.T2.5.12.9" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">82.6</td>
<td id="S5.T2.5.12.10" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">63.4</td>
<td id="S5.T2.5.12.11" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">68.1</td>
<td id="S5.T2.5.12.12" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">75.3</td>
<td id="S5.T2.5.12.13" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">64.8</td>
<td id="S5.T2.5.12.14" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">61.9</td>
</tr>
<tr id="S5.T2.5.5" class="ltx_tr">
<td id="S5.T2.5.5.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">Micro <math id="S5.T2.5.5.1.m1.1" class="ltx_Math" alttext="F_{1}" display="inline"><semantics id="S5.T2.5.5.1.m1.1a"><msub id="S5.T2.5.5.1.m1.1.1" xref="S5.T2.5.5.1.m1.1.1.cmml"><mi id="S5.T2.5.5.1.m1.1.1.2" xref="S5.T2.5.5.1.m1.1.1.2.cmml">F</mi><mn id="S5.T2.5.5.1.m1.1.1.3" xref="S5.T2.5.5.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S5.T2.5.5.1.m1.1b"><apply id="S5.T2.5.5.1.m1.1.1.cmml" xref="S5.T2.5.5.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T2.5.5.1.m1.1.1.1.cmml" xref="S5.T2.5.5.1.m1.1.1">subscript</csymbol><ci id="S5.T2.5.5.1.m1.1.1.2.cmml" xref="S5.T2.5.5.1.m1.1.1.2">𝐹</ci><cn type="integer" id="S5.T2.5.5.1.m1.1.1.3.cmml" xref="S5.T2.5.5.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.5.5.1.m1.1c">F_{1}</annotation></semantics></math>
</td>
<td id="S5.T2.5.5.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-top:-1.5pt;padding-bottom:-1.5pt;" colspan="3">95.8</td>
<td id="S5.T2.5.5.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-top:-1.5pt;padding-bottom:-1.5pt;" colspan="3"><span id="S5.T2.5.5.3.1" class="ltx_text ltx_font_bold">96.8</span></td>
<td id="S5.T2.5.5.4" class="ltx_td ltx_border_bb ltx_border_t" style="padding-top:-1.5pt;padding-bottom:-1.5pt;"></td>
<td id="S5.T2.5.5.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-top:-1.5pt;padding-bottom:-1.5pt;" colspan="3">96.0</td>
<td id="S5.T2.5.5.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-top:-1.5pt;padding-bottom:-1.5pt;" colspan="3"><span id="S5.T2.5.5.6.1" class="ltx_text ltx_font_bold">96.2</span></td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Results of cell type classification on our method and AxCell, with image classification papers fixed as the validation set and papers from each remaining category as the test set in turn. Each fold is run five times with different random seeds, and the reported numbers are averaged over 10 folds and 5 runs.</figcaption>
</figure>
<div id="S5.SS1.SSS1.p1" class="ltx_para">
<p id="S5.SS1.SSS1.p1.1" class="ltx_p">We compare our method against AxCell’s cell type classification component <cite class="ltx_cite ltx_citemacro_citep">(Kardas et al., <a href="#bib.bib22" title="" class="ltx_ref">2020</a>)</cite>, which uses a ULMFiT architecture <cite class="ltx_cite ltx_citemacro_citep">(Howard and Ruder, <a href="#bib.bib18" title="" class="ltx_ref">2018</a>)</cite> with LSTM layers pre-trained on arXiv papers. It takes as input the contents of table cells with a set of hand-crafted features to provide the context of cells in the paper.
We use their publicly available implementation<span id="footnote10" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">10</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">10</sup><span class="ltx_tag ltx_tag_note">10</span><a target="_blank" href="https://github.com/paperswithcode/axcell" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/paperswithcode/axcell</a></span></span></span> with a slight modification to the output layer to suit our 5-class classification.</p>
</div>
<div id="S5.SS1.SSS1.p2" class="ltx_para">
<p id="S5.SS1.SSS1.p2.1" class="ltx_p">Table <a href="#S5.T2" title="Table 2 ‣ 5.1.1 Cell Type Classification ‣ 5.1 Evaluating Sub-tasks ‣ 5 Evaluations ‣ S2abEL: A Dataset for Entity Linking from Scientific Tables" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> shows that our method outperforms AxCell somewhat in terms of F1 scores. Although we do not claim our method on this particular sub-task is substantially better, we provide baseline results using state-of-the-art transformer models.</p>
</div>
</section>
<section id="S5.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.2 </span>Candidate Entity Retrieval</h4>

<div id="S5.SS1.SSS2.p1" class="ltx_para">
<p id="S5.SS1.SSS2.p1.1" class="ltx_p">Since the goal of CER is to generate a small list of potential entities for a table cell, we evaluate the performance of the CER method using <em id="S5.SS1.SSS2.p1.1.1" class="ltx_emph ltx_font_italic">recall@K</em>.</p>
</div>
<figure id="S5.F2" class="ltx_figure"><img src="/html/2305.00366/assets/x1.png" id="S5.F2.g1" class="ltx_graphics ltx_centering ltx_img_square" width="461" height="384" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Evaluation of different candidate entity retrieval methods. The method in the parenthesis indicates whether a fine-tuned SciBert or BM25F is used. </figcaption>
</figure>
<div id="S5.SS1.SSS2.p2" class="ltx_para">
<p id="S5.SS1.SSS2.p2.3" class="ltx_p">Figure <a href="#S5.F2" title="Figure 2 ‣ 5.1.2 Candidate Entity Retrieval ‣ 5.1 Evaluating Sub-tasks ‣ 5 Evaluations ‣ S2abEL: A Dataset for Entity Linking from Scientific Tables" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> shows the results of evaluating dense retrieval (DR), attributed source retrieval (ASR), and a combination of both methods, with different candidate size limits <math id="S5.SS1.SSS2.p2.1.m1.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S5.SS1.SSS2.p2.1.m1.1a"><mi id="S5.SS1.SSS2.p2.1.m1.1.1" xref="S5.SS1.SSS2.p2.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS2.p2.1.m1.1b"><ci id="S5.SS1.SSS2.p2.1.m1.1.1.cmml" xref="S5.SS1.SSS2.p2.1.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS2.p2.1.m1.1c">K</annotation></semantics></math>. We observe that seeding the candidate set with entities associated with
attributed papers significantly outperforms DR, while interleaving candidates from ASR and DR produces the most promising results. These results demonstrate the effectiveness of utilizing information on attributed sources to generate high-quality candidates.
It is worth noting that when <math id="S5.SS1.SSS2.p2.2.m2.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S5.SS1.SSS2.p2.2.m2.1a"><mi id="S5.SS1.SSS2.p2.2.m2.1.1" xref="S5.SS1.SSS2.p2.2.m2.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS2.p2.2.m2.1b"><ci id="S5.SS1.SSS2.p2.2.m2.1.1.cmml" xref="S5.SS1.SSS2.p2.2.m2.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS2.p2.2.m2.1c">K</annotation></semantics></math> is sufficiently large, ASR considers all sources as attributed sources for a given cell, thus returning entities that are associated with any source. However, if the gold entity is not related to any cited source in the paper, it will still be missing from the candidate set. Increasing <math id="S5.SS1.SSS2.p2.3.m3.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S5.SS1.SSS2.p2.3.m3.1a"><mi id="S5.SS1.SSS2.p2.3.m3.1.1" xref="S5.SS1.SSS2.p2.3.m3.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS2.p2.3.m3.1b"><ci id="S5.SS1.SSS2.p2.3.m3.1.1.cmml" xref="S5.SS1.SSS2.p2.3.m3.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS2.p2.3.m3.1c">K</annotation></semantics></math> further will not recover this missing entity, as indicated by the saturation observed in Figure <a href="#S5.F2" title="Figure 2 ‣ 5.1.2 Candidate Entity Retrieval ‣ 5.1 Evaluating Sub-tasks ‣ 5 Evaluations ‣ S2abEL: A Dataset for Entity Linking from Scientific Tables" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<div id="S5.SS1.SSS2.p3" class="ltx_para ltx_noindent">
<p id="S5.SS1.SSS2.p3.1" class="ltx_p"><span id="S5.SS1.SSS2.p3.1.1" class="ltx_text ltx_font_bold">Error Analysis</span> —
We examined the outputs of ASR and identified two main challenges.
First, we observed that in 22.8% of the error cases when <math id="S5.SS1.SSS2.p3.1.m1.1" class="ltx_Math" alttext="K=100" display="inline"><semantics id="S5.SS1.SSS2.p3.1.m1.1a"><mrow id="S5.SS1.SSS2.p3.1.m1.1.1" xref="S5.SS1.SSS2.p3.1.m1.1.1.cmml"><mi id="S5.SS1.SSS2.p3.1.m1.1.1.2" xref="S5.SS1.SSS2.p3.1.m1.1.1.2.cmml">K</mi><mo id="S5.SS1.SSS2.p3.1.m1.1.1.1" xref="S5.SS1.SSS2.p3.1.m1.1.1.1.cmml">=</mo><mn id="S5.SS1.SSS2.p3.1.m1.1.1.3" xref="S5.SS1.SSS2.p3.1.m1.1.1.3.cmml">100</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS2.p3.1.m1.1b"><apply id="S5.SS1.SSS2.p3.1.m1.1.1.cmml" xref="S5.SS1.SSS2.p3.1.m1.1.1"><eq id="S5.SS1.SSS2.p3.1.m1.1.1.1.cmml" xref="S5.SS1.SSS2.p3.1.m1.1.1.1"></eq><ci id="S5.SS1.SSS2.p3.1.m1.1.1.2.cmml" xref="S5.SS1.SSS2.p3.1.m1.1.1.2">𝐾</ci><cn type="integer" id="S5.SS1.SSS2.p3.1.m1.1.1.3.cmml" xref="S5.SS1.SSS2.p3.1.m1.1.1.3">100</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS2.p3.1.m1.1c">K=100</annotation></semantics></math>,
authors did not cite papers for referred concepts.
These cases typically involve well-known entities such as LSTM <cite class="ltx_cite ltx_citemacro_citep">(Hochreiter and Schmidhuber, <a href="#bib.bib14" title="" class="ltx_ref">1997</a>)</cite>.
In the remaining error cases, the authors did cite papers; however, the gold entity was not retrieved due to incomplete <em id="S5.SS1.SSS2.p3.1.2" class="ltx_emph ltx_font_italic">Paper-RelatesTo-Entity</em> relations in the target KB or because the authors cited the wrong paper.</p>
</div>
<div id="S5.SS1.SSS2.p4" class="ltx_para">
<p id="S5.SS1.SSS2.p4.1" class="ltx_p">We additionally investigated the error cases from DR and found that a considerable fraction was caused by the use of generic words to refer to a specific entity. For instance, the validation set of a specific dataset entity was referred to as "val" in the table, the method proposed in the paper was referred to as "ours", and a subset of a dataset that represents data belonging to one of the classification categories was referred to as "window". Resolving the ambiguity of such references requires the model to have an understanding of the unique meaning of those words in the context.</p>
</div>
<div id="S5.SS1.SSS2.p5" class="ltx_para">
<p id="S5.SS1.SSS2.p5.1" class="ltx_p">When using the combined candidate sets, missing gold entities were only observed when both DR and ASR failed, leading to superior performance compared to using either method alone.</p>
</div>
</section>
<section id="S5.SS1.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.3 </span>Entity Disambiguation with inKB Mentions</h4>

<div id="S5.SS1.SSS3.p1" class="ltx_para">
<p id="S5.SS1.SSS3.p1.1" class="ltx_p">The state-of-the-art method closest to our table EL task is TURL <cite class="ltx_cite ltx_citemacro_citep">(Deng et al., <a href="#bib.bib9" title="" class="ltx_ref">2020</a>)</cite>, designed for general-domain tables with inKB cells. It is a structure-aware Transformer encoder pre-trained on the general-purpose WikiTable corpus <cite class="ltx_cite ltx_citemacro_citep">(Bhagavatula et al., <a href="#bib.bib3" title="" class="ltx_ref">2015</a>)</cite>, which produces contextualized embeddings for table cells, rows, and columns that are suitable for a range of downstream applications, including table EL. We used TURL’s public code<span id="footnote11" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">11</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">11</sup><span class="ltx_tag ltx_tag_note">11</span><a target="_blank" href="https://github.com/sunlab-osu/TURL" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/sunlab-osu/TURL</a></span></span></span> and fine-tuned it on the inKB cells of our dataset and compared it with our method using the same entity candidate set of size 50.</p>
</div>
<figure id="S5.T3" class="ltx_table">
<table id="S5.T3.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S5.T3.1.1" class="ltx_tr">
<td id="S5.T3.1.1.1" class="ltx_td ltx_align_left ltx_border_tt" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">Test fold</td>
<td id="S5.T3.1.1.2" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">Support</td>
<td id="S5.T3.1.1.3" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">TURL</td>
<td id="S5.T3.1.1.4" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">Ours</td>
</tr>
<tr id="S5.T3.1.2" class="ltx_tr">
<td id="S5.T3.1.2.1" class="ltx_td ltx_align_left ltx_border_t" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">Question ans.</td>
<td id="S5.T3.1.2.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">381</td>
<td id="S5.T3.1.2.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">15.0</td>
<td id="S5.T3.1.2.4" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" style="padding-top:-1.5pt;padding-bottom:-1.5pt;"><span id="S5.T3.1.2.4.1" class="ltx_text ltx_font_bold">36.1</span></td>
</tr>
<tr id="S5.T3.1.3" class="ltx_tr">
<td id="S5.T3.1.3.1" class="ltx_td ltx_align_left" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">Object det.</td>
<td id="S5.T3.1.3.2" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">2040</td>
<td id="S5.T3.1.3.3" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">34.1</td>
<td id="S5.T3.1.3.4" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;"><span id="S5.T3.1.3.4.1" class="ltx_text ltx_font_bold">41.0</span></td>
</tr>
<tr id="S5.T3.1.4" class="ltx_tr">
<td id="S5.T3.1.4.1" class="ltx_td ltx_align_left" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">Speech rec.</td>
<td id="S5.T3.1.4.2" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">175</td>
<td id="S5.T3.1.4.3" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">34.3</td>
<td id="S5.T3.1.4.4" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;"><span id="S5.T3.1.4.4.1" class="ltx_text ltx_font_bold">54.3</span></td>
</tr>
<tr id="S5.T3.1.5" class="ltx_tr">
<td id="S5.T3.1.5.1" class="ltx_td ltx_align_left" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">Image gen.</td>
<td id="S5.T3.1.5.2" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">168</td>
<td id="S5.T3.1.5.3" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">7.7</td>
<td id="S5.T3.1.5.4" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;"><span id="S5.T3.1.5.4.1" class="ltx_text ltx_font_bold">35.1</span></td>
</tr>
<tr id="S5.T3.1.6" class="ltx_tr">
<td id="S5.T3.1.6.1" class="ltx_td ltx_align_left" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">Machine trans.</td>
<td id="S5.T3.1.6.2" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">234</td>
<td id="S5.T3.1.6.3" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">15.4</td>
<td id="S5.T3.1.6.4" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;"><span id="S5.T3.1.6.4.1" class="ltx_text ltx_font_bold">39.3</span></td>
</tr>
<tr id="S5.T3.1.7" class="ltx_tr">
<td id="S5.T3.1.7.1" class="ltx_td ltx_align_left" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">Text class.</td>
<td id="S5.T3.1.7.2" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">246</td>
<td id="S5.T3.1.7.3" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">52.4</td>
<td id="S5.T3.1.7.4" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;"><span id="S5.T3.1.7.4.1" class="ltx_text ltx_font_bold">68.7</span></td>
</tr>
<tr id="S5.T3.1.8" class="ltx_tr">
<td id="S5.T3.1.8.1" class="ltx_td ltx_align_left" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">Pose estim.</td>
<td id="S5.T3.1.8.2" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">108</td>
<td id="S5.T3.1.8.3" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">36.1</td>
<td id="S5.T3.1.8.4" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">36.1</td>
</tr>
<tr id="S5.T3.1.9" class="ltx_tr">
<td id="S5.T3.1.9.1" class="ltx_td ltx_align_left" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">Semantic seg.</td>
<td id="S5.T3.1.9.2" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">641</td>
<td id="S5.T3.1.9.3" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">44.8</td>
<td id="S5.T3.1.9.4" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;"><span id="S5.T3.1.9.4.1" class="ltx_text ltx_font_bold">50.9</span></td>
</tr>
<tr id="S5.T3.1.10" class="ltx_tr">
<td id="S5.T3.1.10.1" class="ltx_td ltx_align_left" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">NLI</td>
<td id="S5.T3.1.10.2" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">328</td>
<td id="S5.T3.1.10.3" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">30.8</td>
<td id="S5.T3.1.10.4" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;"><span id="S5.T3.1.10.4.1" class="ltx_text ltx_font_bold">58.8</span></td>
</tr>
<tr id="S5.T3.1.11" class="ltx_tr">
<td id="S5.T3.1.11.1" class="ltx_td ltx_align_left" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">Misc.</td>
<td id="S5.T3.1.11.2" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">81</td>
<td id="S5.T3.1.11.3" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">14.8</td>
<td id="S5.T3.1.11.4" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;"><span id="S5.T3.1.11.4.1" class="ltx_text ltx_font_bold">33.3</span></td>
</tr>
<tr id="S5.T3.1.12" class="ltx_tr">
<td id="S5.T3.1.12.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">Micro avg</td>
<td id="S5.T3.1.12.2" class="ltx_td ltx_border_bb ltx_border_t" style="padding-top:-1.5pt;padding-bottom:-1.5pt;"></td>
<td id="S5.T3.1.12.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">32.5</td>
<td id="S5.T3.1.12.4" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t" style="padding-top:-1.5pt;padding-bottom:-1.5pt;"><span id="S5.T3.1.12.4.1" class="ltx_text ltx_font_bold">44.8</span></td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Accuracy for end-to-end entity linking for cells that refer to an inKB entity with 10-fold-cross-domain evaluation using our approach and TURL. Our method is specialized for tables in scientific papers and outperforms the more general-purpose TURL method.</figcaption>
</figure>
<div id="S5.SS1.SSS3.p2" class="ltx_para">
<p id="S5.SS1.SSS3.p2.1" class="ltx_p">Table <a href="#S5.T3" title="Table 3 ‣ 5.1.3 Entity Disambiguation with inKB Mentions ‣ 5.1 Evaluating Sub-tasks ‣ 5 Evaluations ‣ S2abEL: A Dataset for Entity Linking from Scientific Tables" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> shows that our model achieves a substantial improvement in accuracy over TURL on nine out of ten paper folds. The examples in Table <a href="#A1.T6" title="Table 6 ‣ Appendix A Detailed Dataset Statistics ‣ S2abEL: A Dataset for Entity Linking from Scientific Tables" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> (appendix) demonstrate that our model is more effective at recognizing the referent entity when the cell mention is ambiguous and looks similar to other entities in the KB. This is because TURL as a generic table embedding method focuses on just cell content and position while our approach combines cell with the full document.
Our analysis further reveals that TURL made incorrect predictions for all cells whose mentions were shorter than four characters (likely an abbreviation or a pointer to a reference paper). Meanwhile, our method correctly linked 39% of these cells.
</p>
</div>
<figure id="S5.T4" class="ltx_table">
<div id="S5.T4.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:490.1pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(89.4pt,-101.0pt) scale(1.7015796920229,1.7015796920229) ;">
<table id="S5.T4.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T4.1.1.2" class="ltx_tr">
<td id="S5.T4.1.1.2.1" class="ltx_td ltx_align_left ltx_border_tt" style="padding-top:-1.5pt;padding-bottom:-1.5pt;" rowspan="2"><span id="S5.T4.1.1.2.1.1" class="ltx_text">Test fold</span></td>
<td id="S5.T4.1.1.2.2" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">O/I ratio</td>
<td id="S5.T4.1.1.2.3" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">OutKB</td>
<td id="S5.T4.1.1.2.4" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">InKB</td>
<td id="S5.T4.1.1.2.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">Overall</td>
</tr>
<tr id="S5.T4.1.1.1" class="ltx_tr">
<td id="S5.T4.1.1.1.2" class="ltx_td" style="padding-top:-1.5pt;padding-bottom:-1.5pt;"></td>
<td id="S5.T4.1.1.1.1" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;"><math id="S5.T4.1.1.1.1.m1.1" class="ltx_Math" alttext="F_{1}" display="inline"><semantics id="S5.T4.1.1.1.1.m1.1a"><msub id="S5.T4.1.1.1.1.m1.1.1" xref="S5.T4.1.1.1.1.m1.1.1.cmml"><mi id="S5.T4.1.1.1.1.m1.1.1.2" xref="S5.T4.1.1.1.1.m1.1.1.2.cmml">F</mi><mn id="S5.T4.1.1.1.1.m1.1.1.3" xref="S5.T4.1.1.1.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S5.T4.1.1.1.1.m1.1b"><apply id="S5.T4.1.1.1.1.m1.1.1.cmml" xref="S5.T4.1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T4.1.1.1.1.m1.1.1.1.cmml" xref="S5.T4.1.1.1.1.m1.1.1">subscript</csymbol><ci id="S5.T4.1.1.1.1.m1.1.1.2.cmml" xref="S5.T4.1.1.1.1.m1.1.1.2">𝐹</ci><cn type="integer" id="S5.T4.1.1.1.1.m1.1.1.3.cmml" xref="S5.T4.1.1.1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.1.1.1.1.m1.1c">F_{1}</annotation></semantics></math></td>
<td id="S5.T4.1.1.1.3" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">hit@1</td>
<td id="S5.T4.1.1.1.4" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">acc.</td>
</tr>
<tr id="S5.T4.1.1.3" class="ltx_tr">
<td id="S5.T4.1.1.3.1" class="ltx_td ltx_align_left ltx_border_t" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">Machine trans.</td>
<td id="S5.T4.1.1.3.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">0.60</td>
<td id="S5.T4.1.1.3.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">62.2</td>
<td id="S5.T4.1.1.3.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">23.7</td>
<td id="S5.T4.1.1.3.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">50.3</td>
</tr>
<tr id="S5.T4.1.1.4" class="ltx_tr">
<td id="S5.T4.1.1.4.1" class="ltx_td ltx_align_left" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">Image gen.</td>
<td id="S5.T4.1.1.4.2" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">0.48</td>
<td id="S5.T4.1.1.4.3" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">55.1</td>
<td id="S5.T4.1.1.4.4" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">20.0</td>
<td id="S5.T4.1.1.4.5" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">44.4</td>
</tr>
<tr id="S5.T4.1.1.5" class="ltx_tr">
<td id="S5.T4.1.1.5.1" class="ltx_td ltx_align_left" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">Misc.</td>
<td id="S5.T4.1.1.5.2" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">2.74</td>
<td id="S5.T4.1.1.5.3" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">85.1</td>
<td id="S5.T4.1.1.5.4" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">19.5</td>
<td id="S5.T4.1.1.5.5" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">74.9</td>
</tr>
<tr id="S5.T4.1.1.6" class="ltx_tr">
<td id="S5.T4.1.1.6.1" class="ltx_td ltx_align_left" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">Speech rec.</td>
<td id="S5.T4.1.1.6.2" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">1.46</td>
<td id="S5.T4.1.1.6.3" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">73.7</td>
<td id="S5.T4.1.1.6.4" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">33.3</td>
<td id="S5.T4.1.1.6.5" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">66.5</td>
</tr>
<tr id="S5.T4.1.1.7" class="ltx_tr">
<td id="S5.T4.1.1.7.1" class="ltx_td ltx_align_left" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">Question ans.</td>
<td id="S5.T4.1.1.7.2" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">2.33</td>
<td id="S5.T4.1.1.7.3" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">84.2</td>
<td id="S5.T4.1.1.7.4" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">14.0</td>
<td id="S5.T4.1.1.7.5" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">69.3</td>
</tr>
<tr id="S5.T4.1.1.8" class="ltx_tr">
<td id="S5.T4.1.1.8.1" class="ltx_td ltx_align_left" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">NLI</td>
<td id="S5.T4.1.1.8.2" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">1.11</td>
<td id="S5.T4.1.1.8.3" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">80.6</td>
<td id="S5.T4.1.1.8.4" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">47.4</td>
<td id="S5.T4.1.1.8.5" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">68.3</td>
</tr>
<tr id="S5.T4.1.1.9" class="ltx_tr">
<td id="S5.T4.1.1.9.1" class="ltx_td ltx_align_left" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">Text class.</td>
<td id="S5.T4.1.1.9.2" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">1.24</td>
<td id="S5.T4.1.1.9.3" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">77.1</td>
<td id="S5.T4.1.1.9.4" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">35.4</td>
<td id="S5.T4.1.1.9.5" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">66.8</td>
</tr>
<tr id="S5.T4.1.1.10" class="ltx_tr">
<td id="S5.T4.1.1.10.1" class="ltx_td ltx_align_left" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">Object det.</td>
<td id="S5.T4.1.1.10.2" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">0.23</td>
<td id="S5.T4.1.1.10.3" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">49.6</td>
<td id="S5.T4.1.1.10.4" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">35.2</td>
<td id="S5.T4.1.1.10.5" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">45.7</td>
</tr>
<tr id="S5.T4.1.1.11" class="ltx_tr">
<td id="S5.T4.1.1.11.1" class="ltx_td ltx_align_left" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">Semantic seg.</td>
<td id="S5.T4.1.1.11.2" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">0.42</td>
<td id="S5.T4.1.1.11.3" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">73.4</td>
<td id="S5.T4.1.1.11.4" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">39.7</td>
<td id="S5.T4.1.1.11.5" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">55.0</td>
</tr>
<tr id="S5.T4.1.1.12" class="ltx_tr">
<td id="S5.T4.1.1.12.1" class="ltx_td ltx_align_left" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">Pose estim.</td>
<td id="S5.T4.1.1.12.2" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">1.06</td>
<td id="S5.T4.1.1.12.3" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">72.2</td>
<td id="S5.T4.1.1.12.4" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">35.2</td>
<td id="S5.T4.1.1.12.5" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">59.9</td>
</tr>
<tr id="S5.T4.1.1.13" class="ltx_tr">
<td id="S5.T4.1.1.13.1" class="ltx_td ltx_align_left ltx_border_t" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">Micro avg</td>
<td id="S5.T4.1.1.13.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">0.75</td>
<td id="S5.T4.1.1.13.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">71.4</td>
<td id="S5.T4.1.1.13.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">33.3</td>
<td id="S5.T4.1.1.13.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">57.6</td>
</tr>
<tr id="S5.T4.1.1.14" class="ltx_tr">
<td id="S5.T4.1.1.14.1" class="ltx_td ltx_align_left" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">+ gold CTC</td>
<td id="S5.T4.1.1.14.2" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">0.75</td>
<td id="S5.T4.1.1.14.3" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">72.4</td>
<td id="S5.T4.1.1.14.4" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">33.4</td>
<td id="S5.T4.1.1.14.5" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">58.2</td>
</tr>
<tr id="S5.T4.1.1.15" class="ltx_tr">
<td id="S5.T4.1.1.15.1" class="ltx_td ltx_align_left" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">+ gold Can.</td>
<td id="S5.T4.1.1.15.2" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">0.75</td>
<td id="S5.T4.1.1.15.3" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">71.5</td>
<td id="S5.T4.1.1.15.4" class="ltx_td ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">33.4</td>
<td id="S5.T4.1.1.15.5" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">57.6</td>
</tr>
<tr id="S5.T4.1.1.16" class="ltx_tr">
<td id="S5.T4.1.1.16.1" class="ltx_td ltx_align_left ltx_border_bb" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">+ gold both</td>
<td id="S5.T4.1.1.16.2" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">0.75</td>
<td id="S5.T4.1.1.16.3" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">72.5</td>
<td id="S5.T4.1.1.16.4" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">33.4</td>
<td id="S5.T4.1.1.16.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-top:-1.5pt;padding-bottom:-1.5pt;">58.2</td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>End-to-end EL results with 10-fold-cross-domain evaluation of our method on learned DR + ASR candidate sets of size 50 with the inKB threshold set to 0.5.
Although our model achieved reasonable overall accuracy, it is still far from perfect, leaving ample room for future improvements in the end-to-end table EL task.
</figcaption>
</figure>
</section>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>End-to-end Evaluation</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">We now evaluate the end-to-end performance of our approach on the EL task with outKB identification. In addition to re-ranking candidate entities, the method needs to determine when cell mentions refer to entities that do not exist in the target KB. We report <math id="S5.SS2.p1.1.m1.1" class="ltx_Math" alttext="F_{1}" display="inline"><semantics id="S5.SS2.p1.1.m1.1a"><msub id="S5.SS2.p1.1.m1.1.1" xref="S5.SS2.p1.1.m1.1.1.cmml"><mi id="S5.SS2.p1.1.m1.1.1.2" xref="S5.SS2.p1.1.m1.1.1.2.cmml">F</mi><mn id="S5.SS2.p1.1.m1.1.1.3" xref="S5.SS2.p1.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.1.m1.1b"><apply id="S5.SS2.p1.1.m1.1.1.cmml" xref="S5.SS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS2.p1.1.m1.1.1.1.cmml" xref="S5.SS2.p1.1.m1.1.1">subscript</csymbol><ci id="S5.SS2.p1.1.m1.1.1.2.cmml" xref="S5.SS2.p1.1.m1.1.1.2">𝐹</ci><cn type="integer" id="S5.SS2.p1.1.m1.1.1.3.cmml" xref="S5.SS2.p1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.1.m1.1c">F_{1}</annotation></semantics></math> scores for outKB entities as the prediction is binary (precision and recall are reported in Appendix Table <a href="#A1.T8" title="Table 8 ‣ Appendix A Detailed Dataset Statistics ‣ S2abEL: A Dataset for Entity Linking from Scientific Tables" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>). For inKB mentions, we report the hit rate at top-1. Additionally, we evaluate overall performance using accuracy <span id="footnote12" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">12</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">12</sup><span class="ltx_tag ltx_tag_note">12</span>A cell is considered a correct prediction if it is an outKB mention and predicted as such, or if it is an inKB mention and predicted as inKB with the gold entity being ranked at top 1.</span></span></span>. For each topic of papers, we report the ratio of outKB mentions to inKB mentions.</p>
</div>
<figure id="S5.F3" class="ltx_figure"><img src="/html/2305.00366/assets/x2.png" id="S5.F3.g1" class="ltx_graphics ltx_centering ltx_img_square" width="461" height="384" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Entity linking results with varying inKB thresholds.
Note that the inKB hit rate is low (44.8%) even when all mentions are predicted with an entity (i.e., threshold is 0). </figcaption>
</figure>
<div id="S5.SS2.p2" class="ltx_para">
<p id="S5.SS2.p2.1" class="ltx_p">The top block of Table <a href="#S5.T4" title="Table 4 ‣ 5.1.3 Entity Disambiguation with inKB Mentions ‣ 5.1 Evaluating Sub-tasks ‣ 5 Evaluations ‣ S2abEL: A Dataset for Entity Linking from Scientific Tables" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> shows the end-to-end EL performance of our method. Our analysis shows a positive Pearson correlation <cite class="ltx_cite ltx_citemacro_citep">(Cohen et al., <a href="#bib.bib6" title="" class="ltx_ref">2009</a>)</cite> of 0.87 between O/I ratio and overall accuracy, indicating our method tends to predict a mention as outKB. Figure <a href="#S5.F3" title="Figure 3 ‣ 5.2 End-to-end Evaluation ‣ 5 Evaluations ‣ S2abEL: A Dataset for Entity Linking from Scientific Tables" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> shows the performance at various inKB thresholds.</p>
</div>
<div id="S5.SS2.p3" class="ltx_para ltx_noindent">
<p id="S5.SS2.p3.1" class="ltx_p"><span id="S5.SS2.p3.1.1" class="ltx_text ltx_font_bold">Error Analysis</span> <span class="ltx_rule" style="width:10.0pt;height:0.5pt;position:relative; bottom:2.0pt;background:black;display:inline-block;"> </span>
We sampled 100 examples of incorrect predictions for both outKB and inKB mentions and analyzed their causes of errors in Table <a href="#A1.T7" title="Table 7 ‣ Appendix A Detailed Dataset Statistics ‣ S2abEL: A Dataset for Entity Linking from Scientific Tables" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> (Appendix <a href="#A4" title="Appendix D Error Case Study ‣ S2abEL: A Dataset for Entity Linking from Scientific Tables" class="ltx_ref"><span class="ltx_text ltx_ref_tag">D</span></a>). Our analysis reveals that a majority of incorrect inKB predictions are due to the use of generic words. For outKB mentions, the model tends to get confused when they are similar to existing entities in the target KB.</p>
</div>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Component-wise Ablation Study</h3>

<div id="S5.SS3.p1" class="ltx_para">
<p id="S5.SS3.p1.1" class="ltx_p">To investigate how much of the error in our end-to-end three-step system was due to errors introduced in the first two stages (specifically, wrong cell type classifications from CTC or missing correct candidates from CER), we tried measuring system performance with these errors removed. Specifically, we tried replacing the CTC output with the gold cell labels, or adding the gold entity to the output CER candidate set, or both.</p>
</div>
<div id="S5.SS3.p2" class="ltx_para">
<p id="S5.SS3.p2.1" class="ltx_p">The results in the bottom block of Table <a href="#S5.T4" title="Table 4 ‣ 5.1.3 Entity Disambiguation with inKB Mentions ‣ 5.1 Evaluating Sub-tasks ‣ 5 Evaluations ‣ S2abEL: A Dataset for Entity Linking from Scientific Tables" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> show that there is no significant difference in performance with gold inputs.
This could be because CTC and CER are easier tasks compared to ED, and if the model fails those tasks, it is likely to still struggle to identify the correct referent entity, even if that is present in the candidate set or the correct cell type is given.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">We introduced a high-quality dataset for training and evaluating methods for the table EL task with a significant fraction of outKB mentions. To the best of our knowledge, it is the first table EL dataset in the scientific domain. We presented an end-to-end baseline model for the task. Performance analysis of our method indicated future opportunities to achieve human-level results.</p>
</div>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Limitations</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">In this section, we discuss some limitations of our work. First, our dataset only includes tables from English-language papers in the machine learning domain, linked to the Papers with Code KB, which may limit its generalizability to other domains, languages, and KBs. Second, we acknowledge that the creation of S2abEL required significant manual effort from domain experts, making it a resource-intensive process that may not be easily scalable. Third, our approach of using attributed papers to aid in identifying referent entities relies on the target KB containing relations that associate relevant papers and entities together. Fourth, we do not compare against GPT-series models due to budget limitations. Finally, while our experiments set one initial baseline for model performance on our task, substantially more exploration of different methods may improve performance on our task substantially.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Auer et al. (2007)</span>
<span class="ltx_bibblock">
Sören Auer, Christian Bizer, Georgi Kobilarov, Jens Lehmann, Richard
Cyganiak, and Zachary Ives. 2007.

</span>
<span class="ltx_bibblock">Dbpedia: A nucleus for a web of open data.

</span>
<span class="ltx_bibblock">In <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 6th International The Semantic Web and
2nd Asian Conference on Asian Semantic Web Conference</em>, ISWC’07/ASWC’07, page
722–735, Berlin, Heidelberg. Springer-Verlag.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Beltagy et al. (2019)</span>
<span class="ltx_bibblock">
Iz Beltagy, Kyle Lo, and Arman Cohan. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/D19-1371" title="" class="ltx_ref ltx_href">SciBERT: A
pretrained language model for scientific text</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 Conference on Empirical Methods in
Natural Language Processing and the 9th International Joint Conference on
Natural Language Processing (EMNLP-IJCNLP)</em>, pages 3615–3620, Hong Kong,
China. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bhagavatula et al. (2015)</span>
<span class="ltx_bibblock">
Chandra Sekhar Bhagavatula, Thanapon Noraset, and Doug Downey. 2015.

</span>
<span class="ltx_bibblock">Tabel: Entity linking in web tables.

</span>
<span class="ltx_bibblock">In <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">The Semantic Web-ISWC 2015: 14th International Semantic Web
Conference, Bethlehem, PA, USA, October 11-15, 2015, Proceedings, Part I</em>,
pages 425–441. Springer.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Blanco et al. (2015)</span>
<span class="ltx_bibblock">
Roi Blanco, Giuseppe Ottaviano, and Edgar Meij. 2015.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1145/2684822.2685317" title="" class="ltx_ref ltx_href">Fast and
space-efficient entity linking for queries</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Eighth ACM International Conference on
Web Search and Data Mining</em>, WSDM ’15, page 179–188, New York, NY, USA.
Association for Computing Machinery.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cohan et al. (2019)</span>
<span class="ltx_bibblock">
Arman Cohan, Waleed Ammar, Madeleine van Zuylen, and Field Cady. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/N19-1361" title="" class="ltx_ref ltx_href">Structural scaffolds
for citation intent classification in scientific publications</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Language
Technologies, Volume 1 (Long and Short Papers)</em>, pages 3586–3596,
Minneapolis, Minnesota. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cohen et al. (2009)</span>
<span class="ltx_bibblock">
Israel Cohen, Yiteng Huang, Jingdong Chen, Jacob Benesty, Jacob Benesty,
Jingdong Chen, Yiteng Huang, and Israel Cohen. 2009.

</span>
<span class="ltx_bibblock">Pearson correlation coefficient.

</span>
<span class="ltx_bibblock"><em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">Noise reduction in speech processing</em>, pages 1–4.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cucerzan (2007)</span>
<span class="ltx_bibblock">
Silviu Cucerzan. 2007.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://aclanthology.org/D07-1074" title="" class="ltx_ref ltx_href">Large-scale named entity
disambiguation based on Wikipedia data</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2007 Joint Conference on Empirical
Methods in Natural Language Processing and Computational Natural Language
Learning (EMNLP-CoNLL)</em>, pages 708–716, Prague, Czech Republic.
Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">De Cao et al. (2021)</span>
<span class="ltx_bibblock">
Nicola De Cao, Gautier Izacard, Sebastian Riedel, and Fabio Petroni. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://openreview.net/forum?id=5k8F6UU39V" title="" class="ltx_ref ltx_href">Autoregressive
entity retrieval</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">9th International Conference on Learning Representations,
ICLR 2021, Virtual Event, Austria, May 3-7, 2021</em>. OpenReview.net.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Deng et al. (2020)</span>
<span class="ltx_bibblock">
Xiang Deng, Huan Sun, Alyssa Lees, You Wu, and Cong Yu. 2020.

</span>
<span class="ltx_bibblock">Turl: table understanding through representation learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">Proceedings of the VLDB Endowment</em>, 14(3):307–319.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dubey et al. (2018)</span>
<span class="ltx_bibblock">
Mohnish Dubey, Debayan Banerjee, Debanjan Chaudhuri, and Jens Lehmann. 2018.

</span>
<span class="ltx_bibblock">Earl: joint entity and relation linking for question answering over
knowledge graphs.

</span>
<span class="ltx_bibblock">In <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">The Semantic Web–ISWC 2018: 17th International Semantic Web
Conference, Monterey, CA, USA, October 8–12, 2018, Proceedings, Part I 17</em>,
pages 108–126. Springer.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fu et al. (2020)</span>
<span class="ltx_bibblock">
Sunyang Fu, David Chen, Huan He, Sijia Liu, Sungrim Moon, Kevin J. Peterson,
Feichen Shen, Liwei Wang, Yanshan Wang, Andrew Wen, Yiqing Zhao, Sunghwan
Sohn, and Hongfang Liu. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/https://doi.org/10.1016/j.jbi.2020.103526" title="" class="ltx_ref ltx_href">Clinical concept extraction: A methodology review</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">Journal of Biomedical Informatics</em>, 109:103526.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gu et al. (2021)</span>
<span class="ltx_bibblock">
Yingjie Gu, Xiaoye Qu, Zhefeng Wang, Baoxing Huai, Nicholas Jing Yuan, and
Xiaolin Gui. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1609/aaai.v35i14.17528" title="" class="ltx_ref ltx_href">Read, retrospect,
select: An mrc framework to short text entity linking</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI Conference on Artificial Intelligence</em>,
35(14):12920–12928.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Head et al. (2021)</span>
<span class="ltx_bibblock">
Andrew Head, Kyle Lo, Dongyeop Kang, Raymond Fok, Sam Skjonsberg, Daniel S
Weld, and Marti A Hearst. 2021.

</span>
<span class="ltx_bibblock">Augmenting scientific papers with just-in-time, position-sensitive
definitions of terms and symbols.

</span>
<span class="ltx_bibblock">In <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2021 CHI Conference on Human Factors in
Computing Systems</em>, pages 1–18.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hochreiter and Schmidhuber (1997)</span>
<span class="ltx_bibblock">
Sepp Hochreiter and Jürgen Schmidhuber. 1997.

</span>
<span class="ltx_bibblock">Long short-term memory.

</span>
<span class="ltx_bibblock"><em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">Neural computation</em>, 9(8):1735–1780.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hoffart et al. (2011)</span>
<span class="ltx_bibblock">
Johannes Hoffart, Mohamed Amir Yosef, Ilaria Bordino, Hagen Fürstenau,
Manfred Pinkal, Marc Spaniol, Bilyana Taneva, Stefan Thater, and Gerhard
Weikum. 2011.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://aclanthology.org/D11-1072" title="" class="ltx_ref ltx_href">Robust disambiguation of
named entities in text</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2011 Conference on Empirical Methods in
Natural Language Processing</em>, pages 782–792, Edinburgh, Scotland, UK.
Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hope et al. (2022)</span>
<span class="ltx_bibblock">
Tom Hope, Doug Downey, Oren Etzioni, Daniel S Weld, and Eric Horvitz. 2022.

</span>
<span class="ltx_bibblock">A computational inflection for scientific discovery.

</span>
<span class="ltx_bibblock"><em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2205.02007</em>.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hou et al. (2019)</span>
<span class="ltx_bibblock">
Yufang Hou, Charles Jochim, Martin Gleize, Francesca Bonin, and Debasis
Ganguly. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/P19-1513" title="" class="ltx_ref ltx_href">Identification of
tasks, datasets, evaluation metrics, and numeric scores for scientific
leaderboards construction</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 57th Annual Meeting of the Association
for Computational Linguistics</em>, pages 5203–5213, Florence, Italy.
Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Howard and Ruder (2018)</span>
<span class="ltx_bibblock">
Jeremy Howard and Sebastian Ruder. 2018.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/P18-1031" title="" class="ltx_ref ltx_href">Universal language
model fine-tuning for text classification</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 56th Annual Meeting of the Association
for Computational Linguistics (Volume 1: Long Papers)</em>, pages 328–339,
Melbourne, Australia. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Iida et al. (2021)</span>
<span class="ltx_bibblock">
Hiroshi Iida, Dung Thai, Varun Manjunatha, and Mohit Iyyer. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2021.naacl-main.270" title="" class="ltx_ref ltx_href">TABBIE:
Pretrained representations of tabular data</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2021 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Language
Technologies</em>, pages 3446–3456, Online. Association for Computational
Linguistics.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jain et al. (2020)</span>
<span class="ltx_bibblock">
Sarthak Jain, Madeleine van Zuylen, Hannaneh Hajishirzi, and Iz Beltagy. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2020.acl-main.670" title="" class="ltx_ref ltx_href">SciREX:
A challenge dataset for document-level information extraction</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 58th Annual Meeting of the Association
for Computational Linguistics</em>, pages 7506–7516, Online. Association for
Computational Linguistics.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jurgens et al. (2018)</span>
<span class="ltx_bibblock">
David Jurgens, Srijan Kumar, Raine Hoover, Dan McFarland, and Dan Jurafsky.
2018.

</span>
<span class="ltx_bibblock">Measuring the evolution of a scientific field through citation
frames.

</span>
<span class="ltx_bibblock"><em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">Transactions of the Association for Computational Linguistics</em>,
6:391–406.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kardas et al. (2020)</span>
<span class="ltx_bibblock">
Marcin Kardas, Piotr Czapla, Pontus Stenetorp, Sebastian Ruder, Sebastian
Riedel, Ross Taylor, and Robert Stojnic. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2020.emnlp-main.692" title="" class="ltx_ref ltx_href">AxCell:
Automatic extraction of results from machine learning papers</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020 Conference on Empirical Methods in
Natural Language Processing (EMNLP)</em>, pages 8580–8594, Online. Association
for Computational Linguistics.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Karpukhin et al. (2020)</span>
<span class="ltx_bibblock">
Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey
Edunov, Danqi Chen, and Wen-tau Yih. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2020.emnlp-main.550" title="" class="ltx_ref ltx_href">Dense
passage retrieval for open-domain question answering</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020 Conference on Empirical Methods in
Natural Language Processing (EMNLP)</em>, pages 6769–6781, Online. Association
for Computational Linguistics.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kinney et al. (2023)</span>
<span class="ltx_bibblock">
Rodney Michael Kinney, Chloe Anastasiades, Russell Authur, Iz Beltagy, Jonathan
Bragg, Alexandra Buraczynski, Isabel Cachola, Stefan Candra, Yoganand
Chandrasekhar, Arman Cohan, Miles Crawford, Doug Downey, Jason Dunkelberger,
Oren Etzioni, Robert Evans, Sergey Feldman, Joseph Gorney, David W. Graham,
F.Q. Hu, Regan Huff, Daniel King, Sebastian Kohlmeier, Bailey Kuehl, Michael
Langan, Daniel Lin, Haokun Liu, Kyle Lo, Jaron Lochner, Kelsey MacMillan,
Tyler Murray, Christopher Newell, Smita Rao, Shaurya Rohatgi, Paul L Sayre,
Zejiang Shen, Amanpreet Singh, Luca Soldaini, Shivashankar Subramanian,
A. Tanaka, Alex D Wade, Linda M. Wagner, Lucy Lu Wang, Christopher Wilhelm,
Caroline Wu, Jiangjiang Yang, Angele Zamarron, Madeleine van Zuylen, and
Daniel S. Weld. 2023.

</span>
<span class="ltx_bibblock">The semantic scholar open data platform.

</span>
<span class="ltx_bibblock"><em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2301.10140.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2020)</span>
<span class="ltx_bibblock">
Belinda Z. Li, Sewon Min, Srinivasan Iyer, Yashar Mehdad, and Wen-tau Yih.
2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2020.emnlp-main.522" title="" class="ltx_ref ltx_href">Efficient
one-pass end-to-end entity linking for questions</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020 Conference on Empirical Methods in
Natural Language Processing (EMNLP)</em>, pages 6433–6441, Online. Association
for Computational Linguistics.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Logeswaran et al. (2019)</span>
<span class="ltx_bibblock">
Lajanugen Logeswaran, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, Jacob
Devlin, and Honglak Lee. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/P19-1335" title="" class="ltx_ref ltx_href">Zero-shot entity
linking by reading entity descriptions</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 57th Annual Meeting of the Association
for Computational Linguistics</em>, pages 3449–3460, Florence, Italy.
Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Loshchilov and Hutter (2019)</span>
<span class="ltx_bibblock">
Ilya Loshchilov and Frank Hutter. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://openreview.net/forum?id=Bkg6RiCqY7" title="" class="ltx_ref ltx_href">Decoupled weight
decay regularization</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations</em>.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McHugh (2012)</span>
<span class="ltx_bibblock">
Mary L McHugh. 2012.

</span>
<span class="ltx_bibblock">Interrater reliability: the kappa statistic.

</span>
<span class="ltx_bibblock"><em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">Biochemia medica</em>, 22(3):276–282.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mulwad et al. (2023)</span>
<span class="ltx_bibblock">
Varish Mulwad, Tim Finin, Vijay S Kumar, Jenny Weisenberg Williams, Sharad
Dixit, Anupam Joshi, et al. 2023.

</span>
<span class="ltx_bibblock">A practical entity linking system for tables in scientific
literature.

</span>
<span class="ltx_bibblock">In <em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">3rd Workshop on Scientific Document Understanding at
AAAI-2023</em>.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Raffel et al. (2022)</span>
<span class="ltx_bibblock">
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael
Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. 2022.

</span>
<span class="ltx_bibblock">Exploring the limits of transfer learning with a unified text-to-text
transformer.

</span>
<span class="ltx_bibblock"><em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">J. Mach. Learn. Res.</em>, 21(1).

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Reimers and Gurevych (2019)</span>
<span class="ltx_bibblock">
Nils Reimers and Iryna Gurevych. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/D19-1410" title="" class="ltx_ref ltx_href">Sentence-BERT:
Sentence embeddings using Siamese BERT-networks</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 Conference on Empirical Methods in
Natural Language Processing and the 9th International Joint Conference on
Natural Language Processing (EMNLP-IJCNLP)</em>, pages 3982–3992, Hong Kong,
China. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Robertson and Zaragoza (2009)</span>
<span class="ltx_bibblock">
Stephen Robertson and Hugo Zaragoza. 2009.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1561/1500000019" title="" class="ltx_ref ltx_href">The probabilistic
relevance framework: Bm25 and beyond</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">Found. Trends Inf. Retr.</em>, 3(4):333–389.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Roller et al. (2021)</span>
<span class="ltx_bibblock">
Stephen Roller, Emily Dinan, Naman Goyal, Da Ju, Mary Williamson, Yinhan Liu,
Jing Xu, Myle Ott, Eric Michael Smith, Y-Lan Boureau, and Jason Weston. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2021.eacl-main.24" title="" class="ltx_ref ltx_href">Recipes for
building an open-domain chatbot</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 16th Conference of the European Chapter
of the Association for Computational Linguistics: Main Volume</em>, pages
300–325, Online. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ruas and Couto (2022)</span>
<span class="ltx_bibblock">
Pedro Ruas and Francisco M. Couto. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/https://doi.org/10.1016/j.jbi.2022.104137" title="" class="ltx_ref ltx_href">Nilinker: Attention-based approach to nil entity linking</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">Journal of Biomedical Informatics</em>, 132:104137.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sahu et al. (2016)</span>
<span class="ltx_bibblock">
Sunil Sahu, Ashish Anand, Krishnadev Oruganty, and Mahanandeeshwar Gattu. 2016.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/W16-2928" title="" class="ltx_ref ltx_href">Relation extraction
from clinical texts using domain invariant convolutional neural network</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 15th Workshop on Biomedical Natural
Language Processing</em>, pages 206–215, Berlin, Germany. Association for
Computational Linguistics.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shuster et al. (2022)</span>
<span class="ltx_bibblock">
Kurt Shuster, Mojtaba Komeili, Leonard Adolphs, Stephen Roller, Arthur Szlam,
and Jason Weston. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2203.13224" title="" class="ltx_ref ltx_href">Language models
that seek for knowledge: Modular search &amp; generation for dialogue and prompt
completion</a>.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tang et al. (2021a)</span>
<span class="ltx_bibblock">
Hongyin Tang, Xingwu Sun, Beihong Jin, and Fuzheng Zhang. 2021a.

</span>
<span class="ltx_bibblock">A bidirectional multi-paragraph reading model for zero-shot entity
linking.

</span>
<span class="ltx_bibblock">In <em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI Conference on Artificial
Intelligence</em>, volume 35, pages 13889–13897.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tang et al. (2020)</span>
<span class="ltx_bibblock">
Nan Tang, Ju Fan, Fangyi Li, Jianhong Tu, Xiaoyong Du, Guoliang Li, Sam Madden,
and Mourad Ouzzani. 2020.

</span>
<span class="ltx_bibblock">Rpt: relational pre-trained transformer is almost all you need
towards democratizing data preparation.

</span>
<span class="ltx_bibblock"><em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2012.02469</em>.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tang et al. (2021b)</span>
<span class="ltx_bibblock">
Nan Tang, Ju Fan, Fangyi Li, Jianhong Tu, Xiaoyong Du, Guoliang Li, Sam Madden,
and Mourad Ouzzani. 2021b.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.14778/3457390.3457391" title="" class="ltx_ref ltx_href">Rpt: Relational
pre-trained transformer is almost all you need towards democratizing data
preparation</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">Proc. VLDB Endow.</em>, 14(8):1254–1261.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vrandečić and Krötzsch (2014)</span>
<span class="ltx_bibblock">
Denny Vrandečić and Markus Krötzsch. 2014.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1145/2629489" title="" class="ltx_ref ltx_href">Wikidata: A free
collaborative knowledgebase</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">Commun. ACM</em>, 57(10):78–85.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2018)</span>
<span class="ltx_bibblock">
Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel
Bowman. 2018.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/W18-5446" title="" class="ltx_ref ltx_href">GLUE: A multi-task
benchmark and analysis platform for natural language understanding</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 EMNLP Workshop BlackboxNLP:
Analyzing and Interpreting Neural Networks for NLP</em>, pages 353–355,
Brussels, Belgium. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yamada et al. (2019)</span>
<span class="ltx_bibblock">
Ikuya Yamada, Koki Washio, Hiroyuki Shindo, and Yuji Matsumoto. 2019.

</span>
<span class="ltx_bibblock">Global entity disambiguation with pretrained contextualized
embeddings of words and entities.

</span>
<span class="ltx_bibblock"><em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1909.00426</em>.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yamada et al. (2022)</span>
<span class="ltx_bibblock">
Ikuya Yamada, Koki Washio, Hiroyuki Shindo, and Yuji Matsumoto. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2022.naacl-main.238" title="" class="ltx_ref ltx_href">Global
entity disambiguation with BERT</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2022 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Language
Technologies</em>, pages 3264–3271, Seattle, United States. Association for
Computational Linguistics.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al. (2019)</span>
<span class="ltx_bibblock">
Wenhao Yu, Zongze Li, Qingkai Zeng, and Meng Jiang. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1145/3308558.3314118" title="" class="ltx_ref ltx_href">Tablepedia:
Automating pdf table reading in an experimental evidence exploration and
analytic system</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">The World Wide Web Conference</em>, WWW ’19, page 3615–3619,
New York, NY, USA. Association for Computing Machinery.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al. (2020)</span>
<span class="ltx_bibblock">
Wenhao Yu, Wei Peng, Yu Shu, Qingkai Zeng, and Meng Jiang. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1145/3366423.3380174" title="" class="ltx_ref ltx_href">Experimental
evidence extraction system in data science with hybrid table features and
ensemble learning</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">Proceedings of The Web Conference 2020</em>, WWW ’20, page
951–961, New York, NY, USA. Association for Computing Machinery.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2020)</span>
<span class="ltx_bibblock">
Shuo Zhang, Edgar Meij, Krisztian Balog, and Ridho Reinanda. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1145/3366423.3380205" title="" class="ltx_ref ltx_href">Novel entity
discovery from web tables</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">Proceedings of The Web Conference 2020</em>, WWW ’20, page
1298–1308, New York, NY, USA. Association for Computing Machinery.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2022)</span>
<span class="ltx_bibblock">
Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui
Chen, Christopher Dewan, Mona Diab, Xian Li, Xi Victoria Lin, et al. 2022.

</span>
<span class="ltx_bibblock">Opt: Open pre-trained transformer language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib47.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2205.01068</em>.

</span>
</li>
</ul>
</section>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Detailed Dataset Statistics</h2>

<div id="A1.p1" class="ltx_para">
<p id="A1.p1.1" class="ltx_p">S2abEL consists of 11 folds, each corresponding to a topic.
Table <a href="#A1.T5" title="Table 5 ‣ Appendix A Detailed Dataset Statistics ‣ S2abEL: A Dataset for Entity Linking from Scientific Tables" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> provides detailed statistics on the number of papers, tables, and cells for each sub-task and topic. The class distribution for CTC is as follows: <em id="A1.p1.1.1" class="ltx_emph ltx_font_italic">other</em> (74%), <em id="A1.p1.1.2" class="ltx_emph ltx_font_italic">dataset</em> (8%), <em id="A1.p1.1.3" class="ltx_emph ltx_font_italic">method</em> (14%), <em id="A1.p1.1.4" class="ltx_emph ltx_font_italic">metric</em> (3%), and <em id="A1.p1.1.5" class="ltx_emph ltx_font_italic">dataset&amp;metric</em> (0.4%). For APM, 1,532 (16.6%) cells have missing attributed paper, 1,095 (11.9%) cells attribute to the paper itself, 6,598 (71.5%) cells attribute to an entry in the reference section of the paper. For EL, 3,610 (42.8%) cells refer to outKB entities and (57.2%) cells refer to inKB entities.</p>
</div>
<figure id="A1.T5" class="ltx_table">
<table id="A1.T5.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="A1.T5.1.1" class="ltx_tr">
<td id="A1.T5.1.1.1" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2"><span id="A1.T5.1.1.1.1" class="ltx_text">Fold</span></td>
<td id="A1.T5.1.1.2" class="ltx_td ltx_align_center ltx_border_tt" colspan="3">CTC</td>
<td id="A1.T5.1.1.3" class="ltx_td ltx_border_tt"></td>
<td id="A1.T5.1.1.4" class="ltx_td ltx_align_center ltx_border_tt" colspan="3">APM</td>
<td id="A1.T5.1.1.5" class="ltx_td ltx_border_tt"></td>
<td id="A1.T5.1.1.6" class="ltx_td ltx_align_center ltx_border_tt" colspan="3">EL</td>
</tr>
<tr id="A1.T5.1.2" class="ltx_tr">
<td id="A1.T5.1.2.1" class="ltx_td ltx_align_center ltx_border_t"># paper</td>
<td id="A1.T5.1.2.2" class="ltx_td ltx_align_center ltx_border_t"># table</td>
<td id="A1.T5.1.2.3" class="ltx_td ltx_align_center ltx_border_t"># cell</td>
<td id="A1.T5.1.2.4" class="ltx_td"></td>
<td id="A1.T5.1.2.5" class="ltx_td ltx_align_center ltx_border_t"># paper</td>
<td id="A1.T5.1.2.6" class="ltx_td ltx_align_center ltx_border_t"># table</td>
<td id="A1.T5.1.2.7" class="ltx_td ltx_align_center ltx_border_t"># cell</td>
<td id="A1.T5.1.2.8" class="ltx_td"></td>
<td id="A1.T5.1.2.9" class="ltx_td ltx_align_center ltx_border_t"># paper</td>
<td id="A1.T5.1.2.10" class="ltx_td ltx_align_center ltx_border_t"># table</td>
<td id="A1.T5.1.2.11" class="ltx_td ltx_align_center ltx_border_t"># cell</td>
</tr>
<tr id="A1.T5.1.3" class="ltx_tr">
<td id="A1.T5.1.3.1" class="ltx_td ltx_align_center ltx_border_t">Question ans.</td>
<td id="A1.T5.1.3.2" class="ltx_td ltx_align_center ltx_border_t">58</td>
<td id="A1.T5.1.3.3" class="ltx_td ltx_align_center ltx_border_t">139</td>
<td id="A1.T5.1.3.4" class="ltx_td ltx_align_center ltx_border_t">6,422</td>
<td id="A1.T5.1.3.5" class="ltx_td ltx_border_t"></td>
<td id="A1.T5.1.3.6" class="ltx_td ltx_align_center ltx_border_t">57</td>
<td id="A1.T5.1.3.7" class="ltx_td ltx_align_center ltx_border_t">128</td>
<td id="A1.T5.1.3.8" class="ltx_td ltx_align_center ltx_border_t">1,320</td>
<td id="A1.T5.1.3.9" class="ltx_td ltx_border_t"></td>
<td id="A1.T5.1.3.10" class="ltx_td ltx_align_center ltx_border_t">57</td>
<td id="A1.T5.1.3.11" class="ltx_td ltx_align_center ltx_border_t">127</td>
<td id="A1.T5.1.3.12" class="ltx_td ltx_align_center ltx_border_t">1,282</td>
</tr>
<tr id="A1.T5.1.4" class="ltx_tr">
<td id="A1.T5.1.4.1" class="ltx_td ltx_align_center">Object det.</td>
<td id="A1.T5.1.4.2" class="ltx_td ltx_align_center">54</td>
<td id="A1.T5.1.4.3" class="ltx_td ltx_align_center">159</td>
<td id="A1.T5.1.4.4" class="ltx_td ltx_align_center">17,020</td>
<td id="A1.T5.1.4.5" class="ltx_td"></td>
<td id="A1.T5.1.4.6" class="ltx_td ltx_align_center">52</td>
<td id="A1.T5.1.4.7" class="ltx_td ltx_align_center">141</td>
<td id="A1.T5.1.4.8" class="ltx_td ltx_align_center">2,686</td>
<td id="A1.T5.1.4.9" class="ltx_td"></td>
<td id="A1.T5.1.4.10" class="ltx_td ltx_align_center">51</td>
<td id="A1.T5.1.4.11" class="ltx_td ltx_align_center">135</td>
<td id="A1.T5.1.4.12" class="ltx_td ltx_align_center">2,527</td>
</tr>
<tr id="A1.T5.1.5" class="ltx_tr">
<td id="A1.T5.1.5.1" class="ltx_td ltx_align_center">Image class.</td>
<td id="A1.T5.1.5.2" class="ltx_td ltx_align_center">27</td>
<td id="A1.T5.1.5.3" class="ltx_td ltx_align_center">94</td>
<td id="A1.T5.1.5.4" class="ltx_td ltx_align_center">2,681</td>
<td id="A1.T5.1.5.5" class="ltx_td"></td>
<td id="A1.T5.1.5.6" class="ltx_td ltx_align_center">27</td>
<td id="A1.T5.1.5.7" class="ltx_td ltx_align_center">82</td>
<td id="A1.T5.1.5.8" class="ltx_td ltx_align_center">608</td>
<td id="A1.T5.1.5.9" class="ltx_td"></td>
<td id="A1.T5.1.5.10" class="ltx_td ltx_align_center">27</td>
<td id="A1.T5.1.5.11" class="ltx_td ltx_align_center">81</td>
<td id="A1.T5.1.5.12" class="ltx_td ltx_align_center">597</td>
</tr>
<tr id="A1.T5.1.6" class="ltx_tr">
<td id="A1.T5.1.6.1" class="ltx_td ltx_align_center">Speech rec.</td>
<td id="A1.T5.1.6.2" class="ltx_td ltx_align_center">22</td>
<td id="A1.T5.1.6.3" class="ltx_td ltx_align_center">88</td>
<td id="A1.T5.1.6.4" class="ltx_td ltx_align_center">3,516</td>
<td id="A1.T5.1.6.5" class="ltx_td"></td>
<td id="A1.T5.1.6.6" class="ltx_td ltx_align_center">21</td>
<td id="A1.T5.1.6.7" class="ltx_td ltx_align_center">76</td>
<td id="A1.T5.1.6.8" class="ltx_td ltx_align_center">649</td>
<td id="A1.T5.1.6.9" class="ltx_td"></td>
<td id="A1.T5.1.6.10" class="ltx_td ltx_align_center">21</td>
<td id="A1.T5.1.6.11" class="ltx_td ltx_align_center">74</td>
<td id="A1.T5.1.6.12" class="ltx_td ltx_align_center">612</td>
</tr>
<tr id="A1.T5.1.7" class="ltx_tr">
<td id="A1.T5.1.7.1" class="ltx_td ltx_align_center">Image gen.</td>
<td id="A1.T5.1.7.2" class="ltx_td ltx_align_center">25</td>
<td id="A1.T5.1.7.3" class="ltx_td ltx_align_center">37</td>
<td id="A1.T5.1.7.4" class="ltx_td ltx_align_center">1,184</td>
<td id="A1.T5.1.7.5" class="ltx_td"></td>
<td id="A1.T5.1.7.6" class="ltx_td ltx_align_center">23</td>
<td id="A1.T5.1.7.7" class="ltx_td ltx_align_center">34</td>
<td id="A1.T5.1.7.8" class="ltx_td ltx_align_center">290</td>
<td id="A1.T5.1.7.9" class="ltx_td"></td>
<td id="A1.T5.1.7.10" class="ltx_td ltx_align_center">23</td>
<td id="A1.T5.1.7.11" class="ltx_td ltx_align_center">34</td>
<td id="A1.T5.1.7.12" class="ltx_td ltx_align_center">288</td>
</tr>
<tr id="A1.T5.1.8" class="ltx_tr">
<td id="A1.T5.1.8.1" class="ltx_td ltx_align_center">Machine trans.</td>
<td id="A1.T5.1.8.2" class="ltx_td ltx_align_center">28</td>
<td id="A1.T5.1.8.3" class="ltx_td ltx_align_center">48</td>
<td id="A1.T5.1.8.4" class="ltx_td ltx_align_center">2,199</td>
<td id="A1.T5.1.8.5" class="ltx_td"></td>
<td id="A1.T5.1.8.6" class="ltx_td ltx_align_center">25</td>
<td id="A1.T5.1.8.7" class="ltx_td ltx_align_center">42</td>
<td id="A1.T5.1.8.8" class="ltx_td ltx_align_center">412</td>
<td id="A1.T5.1.8.9" class="ltx_td"></td>
<td id="A1.T5.1.8.10" class="ltx_td ltx_align_center">25</td>
<td id="A1.T5.1.8.11" class="ltx_td ltx_align_center">41</td>
<td id="A1.T5.1.8.12" class="ltx_td ltx_align_center">378</td>
</tr>
<tr id="A1.T5.1.9" class="ltx_tr">
<td id="A1.T5.1.9.1" class="ltx_td ltx_align_center">Text class.</td>
<td id="A1.T5.1.9.2" class="ltx_td ltx_align_center">21</td>
<td id="A1.T5.1.9.3" class="ltx_td ltx_align_center">75</td>
<td id="A1.T5.1.9.4" class="ltx_td ltx_align_center">4,085</td>
<td id="A1.T5.1.9.5" class="ltx_td"></td>
<td id="A1.T5.1.9.6" class="ltx_td ltx_align_center">20</td>
<td id="A1.T5.1.9.7" class="ltx_td ltx_align_center">55</td>
<td id="A1.T5.1.9.8" class="ltx_td ltx_align_center">688</td>
<td id="A1.T5.1.9.9" class="ltx_td"></td>
<td id="A1.T5.1.9.10" class="ltx_td ltx_align_center">19</td>
<td id="A1.T5.1.9.11" class="ltx_td ltx_align_center">51</td>
<td id="A1.T5.1.9.12" class="ltx_td ltx_align_center">600</td>
</tr>
<tr id="A1.T5.1.10" class="ltx_tr">
<td id="A1.T5.1.10.1" class="ltx_td ltx_align_center">NLI</td>
<td id="A1.T5.1.10.2" class="ltx_td ltx_align_center">32</td>
<td id="A1.T5.1.10.3" class="ltx_td ltx_align_center">83</td>
<td id="A1.T5.1.10.4" class="ltx_td ltx_align_center">3,385</td>
<td id="A1.T5.1.10.5" class="ltx_td"></td>
<td id="A1.T5.1.10.6" class="ltx_td ltx_align_center">30</td>
<td id="A1.T5.1.10.7" class="ltx_td ltx_align_center">68</td>
<td id="A1.T5.1.10.8" class="ltx_td ltx_align_center">787</td>
<td id="A1.T5.1.10.9" class="ltx_td"></td>
<td id="A1.T5.1.10.10" class="ltx_td ltx_align_center">30</td>
<td id="A1.T5.1.10.11" class="ltx_td ltx_align_center">66</td>
<td id="A1.T5.1.10.12" class="ltx_td ltx_align_center">697</td>
</tr>
<tr id="A1.T5.1.11" class="ltx_tr">
<td id="A1.T5.1.11.1" class="ltx_td ltx_align_center">Pose estim.</td>
<td id="A1.T5.1.11.2" class="ltx_td ltx_align_center">13</td>
<td id="A1.T5.1.11.3" class="ltx_td ltx_align_center">47</td>
<td id="A1.T5.1.11.4" class="ltx_td ltx_align_center">4,447</td>
<td id="A1.T5.1.11.5" class="ltx_td"></td>
<td id="A1.T5.1.11.6" class="ltx_td ltx_align_center">11</td>
<td id="A1.T5.1.11.7" class="ltx_td ltx_align_center">31</td>
<td id="A1.T5.1.11.8" class="ltx_td ltx_align_center">550</td>
<td id="A1.T5.1.11.9" class="ltx_td"></td>
<td id="A1.T5.1.11.10" class="ltx_td ltx_align_center">7</td>
<td id="A1.T5.1.11.11" class="ltx_td ltx_align_center">18</td>
<td id="A1.T5.1.11.12" class="ltx_td ltx_align_center">222</td>
</tr>
<tr id="A1.T5.1.12" class="ltx_tr">
<td id="A1.T5.1.12.1" class="ltx_td ltx_align_center">Semantic seg,</td>
<td id="A1.T5.1.12.2" class="ltx_td ltx_align_center">32</td>
<td id="A1.T5.1.12.3" class="ltx_td ltx_align_center">82</td>
<td id="A1.T5.1.12.4" class="ltx_td ltx_align_center">5,733</td>
<td id="A1.T5.1.12.5" class="ltx_td"></td>
<td id="A1.T5.1.12.6" class="ltx_td ltx_align_center">30</td>
<td id="A1.T5.1.12.7" class="ltx_td ltx_align_center">75</td>
<td id="A1.T5.1.12.8" class="ltx_td ltx_align_center">927</td>
<td id="A1.T5.1.12.9" class="ltx_td"></td>
<td id="A1.T5.1.12.10" class="ltx_td ltx_align_center">30</td>
<td id="A1.T5.1.12.11" class="ltx_td ltx_align_center">75</td>
<td id="A1.T5.1.12.12" class="ltx_td ltx_align_center">919</td>
</tr>
<tr id="A1.T5.1.13" class="ltx_tr">
<td id="A1.T5.1.13.1" class="ltx_td ltx_align_center ltx_border_bb">Misc.</td>
<td id="A1.T5.1.13.2" class="ltx_td ltx_align_center ltx_border_bb">15</td>
<td id="A1.T5.1.13.3" class="ltx_td ltx_align_center ltx_border_bb">34</td>
<td id="A1.T5.1.13.4" class="ltx_td ltx_align_center ltx_border_bb">1,585</td>
<td id="A1.T5.1.13.5" class="ltx_td ltx_border_bb"></td>
<td id="A1.T5.1.13.6" class="ltx_td ltx_align_center ltx_border_bb">13</td>
<td id="A1.T5.1.13.7" class="ltx_td ltx_align_center ltx_border_bb">30</td>
<td id="A1.T5.1.13.8" class="ltx_td ltx_align_center ltx_border_bb">308</td>
<td id="A1.T5.1.13.9" class="ltx_td ltx_border_bb"></td>
<td id="A1.T5.1.13.10" class="ltx_td ltx_align_center ltx_border_bb">13</td>
<td id="A1.T5.1.13.11" class="ltx_td ltx_align_center ltx_border_bb">30</td>
<td id="A1.T5.1.13.12" class="ltx_td ltx_align_center ltx_border_bb">307</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>Detailed statistics of S2abEL.</figcaption>
</figure>
<figure id="A1.T6" class="ltx_table">
<table id="A1.T6.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="A1.T6.1.1" class="ltx_tr">
<td id="A1.T6.1.1.1" class="ltx_td ltx_align_center ltx_border_tt"><span id="A1.T6.1.1.1.1" class="ltx_text ltx_font_bold">Cell Content</span></td>
<td id="A1.T6.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span id="A1.T6.1.1.2.1" class="ltx_text ltx_font_bold">Column header</span></td>
<td id="A1.T6.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span id="A1.T6.1.1.3.1" class="ltx_text ltx_font_bold">TURL result</span></td>
<td id="A1.T6.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span id="A1.T6.1.1.4.1" class="ltx_text ltx_font_bold">Our result</span></td>
<td id="A1.T6.1.1.5" class="ltx_td ltx_align_center ltx_border_tt"><span id="A1.T6.1.1.5.1" class="ltx_text ltx_font_bold">Gold entity</span></td>
</tr>
<tr id="A1.T6.1.2" class="ltx_tr">
<td id="A1.T6.1.2.1" class="ltx_td ltx_align_center ltx_border_t" colspan="5">InKB</td>
</tr>
<tr id="A1.T6.1.3" class="ltx_tr">
<td id="A1.T6.1.3.1" class="ltx_td ltx_align_center ltx_border_t">"[33]"</td>
<td id="A1.T6.1.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">""</td>
<td id="A1.T6.1.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="A1.T6.1.3.3.1" class="ltx_text"></span> <span id="A1.T6.1.3.3.2" class="ltx_text">
<span id="A1.T6.1.3.3.2.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T6.1.3.3.2.1.1" class="ltx_tr">
<span id="A1.T6.1.3.3.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Cityscapes, PoseTrack,</span></span>
<span id="A1.T6.1.3.3.2.1.2" class="ltx_tr">
<span id="A1.T6.1.3.3.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">LAMBADA</span></span>
</span></span><span id="A1.T6.1.3.3.3" class="ltx_text"></span></td>
<td id="A1.T6.1.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">PointNet, GAN, CRF</td>
<td id="A1.T6.1.3.5" class="ltx_td ltx_align_center ltx_border_t"><a target="_blank" href="https://paperswithcode.com/method/pointnet" title="" class="ltx_ref ltx_href">PointNet</a></td>
</tr>
<tr id="A1.T6.1.4" class="ltx_tr">
<td id="A1.T6.1.4.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">"Text GCN"</td>
<td id="A1.T6.1.4.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t">"Model"</td>
<td id="A1.T6.1.4.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t">
<span id="A1.T6.1.4.3.1" class="ltx_text"></span> <span id="A1.T6.1.4.3.2" class="ltx_text">
<span id="A1.T6.1.4.3.2.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T6.1.4.3.2.1.1" class="ltx_tr">
<span id="A1.T6.1.4.3.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Global Conv. Net.,</span></span>
<span id="A1.T6.1.4.3.2.1.2" class="ltx_tr">
<span id="A1.T6.1.4.3.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">End-to-End Mem. Net.</span></span>
</span></span><span id="A1.T6.1.4.3.3" class="ltx_text"></span></td>
<td id="A1.T6.1.4.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t">
<span id="A1.T6.1.4.4.1" class="ltx_text"></span> <span id="A1.T6.1.4.4.2" class="ltx_text">
<span id="A1.T6.1.4.4.2.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T6.1.4.4.2.1.1" class="ltx_tr">
<span id="A1.T6.1.4.4.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Graph Conv. Net.,</span></span>
<span id="A1.T6.1.4.4.2.1.2" class="ltx_tr">
<span id="A1.T6.1.4.4.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">Global Conv. Net.</span></span>
</span></span><span id="A1.T6.1.4.4.3" class="ltx_text"></span></td>
<td id="A1.T6.1.4.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><a target="_blank" href="https://paperswithcode.com/method/gcn" title="" class="ltx_ref ltx_href">Graph Conv. Net.</a></td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6: </span>Incorrect examples for end-to-end EL from TURL. The table includes the cell content and the column header in the first two columns, the top-3 ranked results from TURL and our approach in the third and fourth columns, respectively, and the gold entity in the last column.</figcaption>
</figure>
<figure id="A1.T7" class="ltx_table">
<table id="A1.T7.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="A1.T7.1.1" class="ltx_tr">
<td id="A1.T7.1.1.1" class="ltx_td ltx_align_center ltx_border_tt"><span id="A1.T7.1.1.1.1" class="ltx_text ltx_font_bold">Cause</span></td>
<td id="A1.T7.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span id="A1.T7.1.1.2.1" class="ltx_text ltx_font_bold">Percent</span></td>
<td id="A1.T7.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span id="A1.T7.1.1.3.1" class="ltx_text ltx_font_bold">Example cell</span></td>
<td id="A1.T7.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span id="A1.T7.1.1.4.1" class="ltx_text ltx_font_bold">Our result</span></td>
<td id="A1.T7.1.1.5" class="ltx_td ltx_align_center ltx_border_tt"><span id="A1.T7.1.1.5.1" class="ltx_text ltx_font_bold">Gold entity</span></td>
</tr>
<tr id="A1.T7.1.2" class="ltx_tr">
<td id="A1.T7.1.2.1" class="ltx_td ltx_align_center ltx_border_t" colspan="5">InKB</td>
</tr>
<tr id="A1.T7.1.3" class="ltx_tr">
<td id="A1.T7.1.3.1" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="A1.T7.1.3.1.1" class="ltx_text">Variants</span></td>
<td id="A1.T7.1.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="2"><span id="A1.T7.1.3.2.1" class="ltx_text">21%</span></td>
<td id="A1.T7.1.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">"bottle"</td>
<td id="A1.T7.1.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="A1.T7.1.3.4.1" class="ltx_text"></span> <span id="A1.T7.1.3.4.2" class="ltx_text">
<span id="A1.T7.1.3.4.2.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T7.1.3.4.2.1.1" class="ltx_tr">
<span id="A1.T7.1.3.4.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">PASCAL VOC,</span></span>
<span id="A1.T7.1.3.4.2.1.2" class="ltx_tr">
<span id="A1.T7.1.3.4.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">PASCAL VOC 2007</span></span>
</span></span><span id="A1.T7.1.3.4.3" class="ltx_text"></span></td>
<td id="A1.T7.1.3.5" class="ltx_td ltx_align_center ltx_border_t"><a target="_blank" href="https://paperswithcode.com/datasets?q=PASCAL+VOC+2007" title="" class="ltx_ref ltx_href">PASCAL VOC 2007</a></td>
</tr>
<tr id="A1.T7.1.4" class="ltx_tr">
<td id="A1.T7.1.4.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">"BigGAN"</td>
<td id="A1.T7.1.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">BigGan-deep, BigGan</td>
<td id="A1.T7.1.4.3" class="ltx_td ltx_align_center ltx_border_t"><a target="_blank" href="https://paperswithcode.com/method/biggan" title="" class="ltx_ref ltx_href">BigGan</a></td>
</tr>
<tr id="A1.T7.1.5" class="ltx_tr">
<td id="A1.T7.1.5.1" class="ltx_td ltx_align_center ltx_border_t">Top below threshold</td>
<td id="A1.T7.1.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">16%</td>
<td id="A1.T7.1.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">"Car"</td>
<td id="A1.T7.1.5.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<em id="A1.T7.1.5.4.1" class="ltx_emph ltx_font_italic">outKB</em>, KITTI</td>
<td id="A1.T7.1.5.5" class="ltx_td ltx_align_center ltx_border_t"><a target="_blank" href="https://paperswithcode.com/dataset/kitti" title="" class="ltx_ref ltx_href">KITTI</a></td>
</tr>
<tr id="A1.T7.1.6" class="ltx_tr">
<td id="A1.T7.1.6.1" class="ltx_td ltx_align_center ltx_border_t">Abbreviations</td>
<td id="A1.T7.1.6.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">19%</td>
<td id="A1.T7.1.6.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">"FR-EN"</td>
<td id="A1.T7.1.6.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Arcade Learning Environment</td>
<td id="A1.T7.1.6.5" class="ltx_td ltx_align_center ltx_border_t"><a target="_blank" href="https://paperswithcode.com/datasets?q=WMT+2014" title="" class="ltx_ref ltx_href">WMT 2014</a></td>
</tr>
<tr id="A1.T7.1.7" class="ltx_tr">
<td id="A1.T7.1.7.1" class="ltx_td ltx_align_center ltx_border_t">Generic words</td>
<td id="A1.T7.1.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">39%</td>
<td id="A1.T7.1.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">"Ours"</td>
<td id="A1.T7.1.7.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Neural Turing Machine</td>
<td id="A1.T7.1.7.5" class="ltx_td ltx_align_center ltx_border_t"><a target="_blank" href="https://paperswithcode.com/method/ohem" title="" class="ltx_ref ltx_href">OHEM</a></td>
</tr>
<tr id="A1.T7.1.8" class="ltx_tr">
<td id="A1.T7.1.8.1" class="ltx_td ltx_align_center ltx_border_t" colspan="5">OutKB</td>
</tr>
<tr id="A1.T7.1.9" class="ltx_tr">
<td id="A1.T7.1.9.1" class="ltx_td ltx_align_center ltx_border_t">Similar names</td>
<td id="A1.T7.1.9.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">56%</td>
<td id="A1.T7.1.9.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">"DPN"</td>
<td id="A1.T7.1.9.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Dual Path Network</td>
<td id="A1.T7.1.9.5" class="ltx_td ltx_align_center ltx_border_t">Deep Parsing Network</td>
</tr>
<tr id="A1.T7.1.10" class="ltx_tr">
<td id="A1.T7.1.10.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">Generic words</td>
<td id="A1.T7.1.10.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t">22%</td>
<td id="A1.T7.1.10.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t">"12"</td>
<td id="A1.T7.1.10.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t">HUB5 English</td>
<td id="A1.T7.1.10.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">bAbi</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 7: </span>Representative examples of erroneous end-to-end EL cases. The table includes the cause and the percentage for that cause in the first two columns, an example of cell content for that cause and our incorrect prediction in the third and fourth columns, and the gold entity in the last column.</figcaption>
</figure>
<figure id="A1.T8" class="ltx_table">
<table id="A1.T8.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="A1.T8.1.1" class="ltx_tr">
<td id="A1.T8.1.1.1" class="ltx_td ltx_align_left ltx_border_tt">Test fold</td>
<td id="A1.T8.1.1.2" class="ltx_td ltx_align_center ltx_border_tt">Precision</td>
<td id="A1.T8.1.1.3" class="ltx_td ltx_align_center ltx_border_tt">Recall</td>
</tr>
<tr id="A1.T8.1.2" class="ltx_tr">
<td id="A1.T8.1.2.1" class="ltx_td ltx_align_left ltx_border_t">Machine trans.</td>
<td id="A1.T8.1.2.2" class="ltx_td ltx_align_center ltx_border_t">46.4</td>
<td id="A1.T8.1.2.3" class="ltx_td ltx_align_center ltx_border_t">94.4</td>
</tr>
<tr id="A1.T8.1.3" class="ltx_tr">
<td id="A1.T8.1.3.1" class="ltx_td ltx_align_left">Image gen.</td>
<td id="A1.T8.1.3.2" class="ltx_td ltx_align_center">38.7</td>
<td id="A1.T8.1.3.3" class="ltx_td ltx_align_center">95.7</td>
</tr>
<tr id="A1.T8.1.4" class="ltx_tr">
<td id="A1.T8.1.4.1" class="ltx_td ltx_align_left">Misc.</td>
<td id="A1.T8.1.4.2" class="ltx_td ltx_align_center">77.0</td>
<td id="A1.T8.1.4.3" class="ltx_td ltx_align_center">95.1</td>
</tr>
<tr id="A1.T8.1.5" class="ltx_tr">
<td id="A1.T8.1.5.1" class="ltx_td ltx_align_left">Speech rec.</td>
<td id="A1.T8.1.5.2" class="ltx_td ltx_align_center">62.8</td>
<td id="A1.T8.1.5.3" class="ltx_td ltx_align_center">89.3</td>
</tr>
<tr id="A1.T8.1.6" class="ltx_tr">
<td id="A1.T8.1.6.1" class="ltx_td ltx_align_left">Question ans.</td>
<td id="A1.T8.1.6.2" class="ltx_td ltx_align_center">76.9</td>
<td id="A1.T8.1.6.3" class="ltx_td ltx_align_center">93.1</td>
</tr>
<tr id="A1.T8.1.7" class="ltx_tr">
<td id="A1.T8.1.7.1" class="ltx_td ltx_align_left">NLI</td>
<td id="A1.T8.1.7.2" class="ltx_td ltx_align_center">74.9</td>
<td id="A1.T8.1.7.3" class="ltx_td ltx_align_center">87.2</td>
</tr>
<tr id="A1.T8.1.8" class="ltx_tr">
<td id="A1.T8.1.8.1" class="ltx_td ltx_align_left">Text class.</td>
<td id="A1.T8.1.8.2" class="ltx_td ltx_align_center">66.2</td>
<td id="A1.T8.1.8.3" class="ltx_td ltx_align_center">92.2</td>
</tr>
<tr id="A1.T8.1.9" class="ltx_tr">
<td id="A1.T8.1.9.1" class="ltx_td ltx_align_left">Object det.</td>
<td id="A1.T8.1.9.2" class="ltx_td ltx_align_center">34.0</td>
<td id="A1.T8.1.9.3" class="ltx_td ltx_align_center">91.1</td>
</tr>
<tr id="A1.T8.1.10" class="ltx_tr">
<td id="A1.T8.1.10.1" class="ltx_td ltx_align_left">Semantic seg.</td>
<td id="A1.T8.1.10.2" class="ltx_td ltx_align_center">61.4</td>
<td id="A1.T8.1.10.3" class="ltx_td ltx_align_center">91.2</td>
</tr>
<tr id="A1.T8.1.11" class="ltx_tr">
<td id="A1.T8.1.11.1" class="ltx_td ltx_align_left">Pose estim.</td>
<td id="A1.T8.1.11.2" class="ltx_td ltx_align_center">63.8</td>
<td id="A1.T8.1.11.3" class="ltx_td ltx_align_center">83.3</td>
</tr>
<tr id="A1.T8.1.12" class="ltx_tr">
<td id="A1.T8.1.12.1" class="ltx_td ltx_align_left ltx_border_t">Micro avg</td>
<td id="A1.T8.1.12.2" class="ltx_td ltx_align_center ltx_border_t">58.6</td>
<td id="A1.T8.1.12.3" class="ltx_td ltx_align_center ltx_border_t">91.4</td>
</tr>
<tr id="A1.T8.1.13" class="ltx_tr">
<td id="A1.T8.1.13.1" class="ltx_td ltx_align_left">+ gold CTC</td>
<td id="A1.T8.1.13.2" class="ltx_td ltx_align_center">59.5</td>
<td id="A1.T8.1.13.3" class="ltx_td ltx_align_center">92.7</td>
</tr>
<tr id="A1.T8.1.14" class="ltx_tr">
<td id="A1.T8.1.14.1" class="ltx_td ltx_align_left">+ gold Can.</td>
<td id="A1.T8.1.14.2" class="ltx_td ltx_align_center">58.7</td>
<td id="A1.T8.1.14.3" class="ltx_td ltx_align_center">91.4</td>
</tr>
<tr id="A1.T8.1.15" class="ltx_tr">
<td id="A1.T8.1.15.1" class="ltx_td ltx_align_left ltx_border_bb">+ gold both</td>
<td id="A1.T8.1.15.2" class="ltx_td ltx_align_center ltx_border_bb">59.5</td>
<td id="A1.T8.1.15.3" class="ltx_td ltx_align_center ltx_border_bb">92.7</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 8: </span>Additional end-to-end Entity linking results for outKB cells.</figcaption>
</figure>
</section>
<section id="A2" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Training Details</h2>

<div id="A2.p1" class="ltx_para">
<p id="A2.p1.1" class="ltx_p">We trained all our models for two epochs with a batch size of 32, using the AdamW optimizer <cite class="ltx_cite ltx_citemacro_citep">(Loshchilov and Hutter, <a href="#bib.bib27" title="" class="ltx_ref">2019</a>)</cite> with linear decay warm-up. The initial learning rate was 2e-5 and the warm-up ratio was 10%. All models were trained using a single 48Gb NVIDIA A6000 GPU. For the triplet loss function in DR, we used Euclidean as the distance function with a margin of 1. For the Candidate Entity Retrieval and Entity Disambiguation tasks, we used negative examples of size 50 at training time. Additionally for the ED task, we set candidate set size limitation as 50 when making predictions.</p>
</div>
<figure id="A2.T9" class="ltx_table">
<div id="A2.T9.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:338.3pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(43.8pt,-34.2pt) scale(1.25313463132396,1.25313463132396) ;">
<table id="A2.T9.1.1" class="ltx_tabular ltx_align_middle">
<tr id="A2.T9.1.1.1" class="ltx_tr">
<td id="A2.T9.1.1.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt">Feature</td>
<td id="A2.T9.1.1.1.2" class="ltx_td ltx_align_left ltx_border_tt">Description</td>
</tr>
<tr id="A2.T9.1.1.2" class="ltx_tr">
<td id="A2.T9.1.1.2.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">cell content</td>
<td id="A2.T9.1.1.2.2" class="ltx_td ltx_align_left ltx_border_t">cell’s raw text</td>
</tr>
<tr id="A2.T9.1.1.3" class="ltx_tr">
<td id="A2.T9.1.1.3.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">region</td>
<td id="A2.T9.1.1.3.2" class="ltx_td ltx_align_left ltx_border_t">cell’s relative location with reference to the top-left</td>
</tr>
<tr id="A2.T9.1.1.4" class="ltx_tr">
<td id="A2.T9.1.1.4.1" class="ltx_td ltx_border_r"></td>
<td id="A2.T9.1.1.4.2" class="ltx_td ltx_align_left">numeric cell in the table, i.e., top-left, top-right,</td>
</tr>
<tr id="A2.T9.1.1.5" class="ltx_tr">
<td id="A2.T9.1.1.5.1" class="ltx_td ltx_border_r"></td>
<td id="A2.T9.1.1.5.2" class="ltx_td ltx_align_left">bottom-left, and bottom-right</td>
</tr>
<tr id="A2.T9.1.1.6" class="ltx_tr">
<td id="A2.T9.1.1.6.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">context sentences</td>
<td id="A2.T9.1.1.6.2" class="ltx_td ltx_align_left ltx_border_t">top-ranked sentences in the full document</td>
</tr>
<tr id="A2.T9.1.1.7" class="ltx_tr">
<td id="A2.T9.1.1.7.1" class="ltx_td ltx_border_r"></td>
<td id="A2.T9.1.1.7.2" class="ltx_td ltx_align_left">(including table captions, section headers, etc.)</td>
</tr>
<tr id="A2.T9.1.1.8" class="ltx_tr">
<td id="A2.T9.1.1.8.1" class="ltx_td ltx_border_r"></td>
<td id="A2.T9.1.1.8.2" class="ltx_td ltx_align_left">regarding the cell content based on BM25</td>
</tr>
<tr id="A2.T9.1.1.9" class="ltx_tr">
<td id="A2.T9.1.1.9.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">row context</td>
<td id="A2.T9.1.1.9.2" class="ltx_td ltx_align_left ltx_border_t">concatenated cell’s row separated by special tokens</td>
</tr>
<tr id="A2.T9.1.1.10" class="ltx_tr">
<td id="A2.T9.1.1.10.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">column context</td>
<td id="A2.T9.1.1.10.2" class="ltx_td ltx_align_left ltx_border_t">concatenated cell’s column separated by special tokens</td>
</tr>
<tr id="A2.T9.1.1.11" class="ltx_tr">
<td id="A2.T9.1.1.11.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">position</td>
<td id="A2.T9.1.1.11.2" class="ltx_td ltx_align_left ltx_border_t">cell’s 2D position in the table in terms of distance</td>
</tr>
<tr id="A2.T9.1.1.12" class="ltx_tr">
<td id="A2.T9.1.1.12.1" class="ltx_td ltx_border_r"></td>
<td id="A2.T9.1.1.12.2" class="ltx_td ltx_align_left">from the top left corner</td>
</tr>
<tr id="A2.T9.1.1.13" class="ltx_tr">
<td id="A2.T9.1.1.13.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">reverse position</td>
<td id="A2.T9.1.1.13.2" class="ltx_td ltx_align_left ltx_border_t">cell’s 2D position in the table in terms of distance</td>
</tr>
<tr id="A2.T9.1.1.14" class="ltx_tr">
<td id="A2.T9.1.1.14.1" class="ltx_td ltx_border_r"></td>
<td id="A2.T9.1.1.14.2" class="ltx_td ltx_align_left">from the bottom right corner.</td>
</tr>
<tr id="A2.T9.1.1.15" class="ltx_tr">
<td id="A2.T9.1.1.15.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t">has reference</td>
<td id="A2.T9.1.1.15.2" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t">whether cell has a reference</td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 9: </span>Features for cell representation.</figcaption>
</figure>
</section>
<section id="A3" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Annotation Interface and Guidelines</h2>

<div id="A3.p1" class="ltx_para">
<p id="A3.p1.1" class="ltx_p">Our annotation interface with annotation guidelines is at <a target="_blank" href="https://github.com/allenai/s2abel/blob/main/common_utils/Annotation%20Interface.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/allenai/s2abel/blob/main/common_utils/Annotation%20Interface.pdf</a>. Note that there might be cells that contain a subentity mentions consisting of an entity mention and a non-entity mention string, e.g., "Bert-large", "Bert with 6 layers frozen". For these cells, we asked the annotators to focus on the primary entity and our current model considers these mentions as mentions of the main entity. Thus those two mentions are labeled as <em id="A3.p1.1.1" class="ltx_emph ltx_font_italic">method</em>, and linked to <a target="_blank" href="https:paperswithcode.com/method/bert" title="" class="ltx_ref ltx_url ltx_font_typewriter">https:paperswithcode.com/method/bert</a>. We also specifically asked the annotators to mark cells that contain mentions of more than one primary entity or are confusing to understand, which are excluded from the dataset. We leave the tasks of linking subentities explicitly and cells to multiple entities for future work.</p>
</div>
</section>
<section id="A4" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>Error Case Study</h2>

<div id="A4.p1" class="ltx_para">
<p id="A4.p1.1" class="ltx_p">Table <a href="#A1.T6" title="Table 6 ‣ Appendix A Detailed Dataset Statistics ‣ S2abEL: A Dataset for Entity Linking from Scientific Tables" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> presents examples where TURL made incorrect EL predictions while our approach made correct predictions.
Table <a href="#A1.T7" title="Table 7 ‣ Appendix A Detailed Dataset Statistics ‣ S2abEL: A Dataset for Entity Linking from Scientific Tables" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> summarizes the main causes of incorrect predictions made by our approach for both inKB and outKB mentions.</p>
</div>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2305.00365" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2305.00366" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2305.00366">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2305.00366" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2305.00367" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Feb 29 10:37:47 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
