<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>STORE: Streamlining Semantic Tokenization and Generative Recommendation with A Single LLM</title>
<!--Generated on Fri Sep 13 04:16:42 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="Semantic Tokenization,  Generative Recommendation,  Large Recommendation Model" lang="en" name="keywords"/>
<base href="/html/2409.07276v2/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#S1" title="In STORE: Streamlining Semantic Tokenization and Generative Recommendation with A Single LLM"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#S2" title="In STORE: Streamlining Semantic Tokenization and Generative Recommendation with A Single LLM"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Preliminaries</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#S2.SS1" title="In 2. Preliminaries ‣ STORE: Streamlining Semantic Tokenization and Generative Recommendation with A Single LLM"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Semantic Tokenization</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#S2.SS2" title="In 2. Preliminaries ‣ STORE: Streamlining Semantic Tokenization and Generative Recommendation with A Single LLM"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Downstream Recommenders</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#S3" title="In STORE: Streamlining Semantic Tokenization and Generative Recommendation with A Single LLM"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Proposed Approach: STORE</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#S3.SS1" title="In 3. Proposed Approach: STORE ‣ STORE: Streamlining Semantic Tokenization and Generative Recommendation with A Single LLM"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Dense Tokenizer</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#S3.SS2" title="In 3. Proposed Approach: STORE ‣ STORE: Streamlining Semantic Tokenization and Generative Recommendation with A Single LLM"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Simple Clusterer</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#S3.SS3" title="In 3. Proposed Approach: STORE ‣ STORE: Streamlining Semantic Tokenization and Generative Recommendation with A Single LLM"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Generative Recommender</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#S4" title="In STORE: Streamlining Semantic Tokenization and Generative Recommendation with A Single LLM"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#S4.SS1" title="In 4. Experiments ‣ STORE: Streamlining Semantic Tokenization and Generative Recommendation with A Single LLM"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Experimental Setup</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#S4.SS2" title="In 4. Experiments ‣ STORE: Streamlining Semantic Tokenization and Generative Recommendation with A Single LLM"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Generative Recommenders for Retrieval</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#S4.SS3" title="In 4. Experiments ‣ STORE: Streamlining Semantic Tokenization and Generative Recommendation with A Single LLM"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Ablation Study</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#S4.SS4" title="In 4. Experiments ‣ STORE: Streamlining Semantic Tokenization and Generative Recommendation with A Single LLM"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4 </span>Generative Recommenders for Scoring</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#S5" title="In STORE: Streamlining Semantic Tokenization and Generative Recommendation with A Single LLM"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Related Work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#S5.SS1" title="In 5. Related Work ‣ STORE: Streamlining Semantic Tokenization and Generative Recommendation with A Single LLM"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>LLMs for Recommendation</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#S5.SS1.SSS0.Px1" title="In 5.1. LLMs for Recommendation ‣ 5. Related Work ‣ STORE: Streamlining Semantic Tokenization and Generative Recommendation with A Single LLM"><span class="ltx_text ltx_ref_title">Pre-training.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#S5.SS1.SSS0.Px2" title="In 5.1. LLMs for Recommendation ‣ 5. Related Work ‣ STORE: Streamlining Semantic Tokenization and Generative Recommendation with A Single LLM"><span class="ltx_text ltx_ref_title">Prompting.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#S5.SS1.SSS0.Px3" title="In 5.1. LLMs for Recommendation ‣ 5. Related Work ‣ STORE: Streamlining Semantic Tokenization and Generative Recommendation with A Single LLM"><span class="ltx_text ltx_ref_title">Fine-tuning.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#S5.SS2" title="In 5. Related Work ‣ STORE: Streamlining Semantic Tokenization and Generative Recommendation with A Single LLM"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Generative Recommendation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#S6" title="In STORE: Streamlining Semantic Tokenization and Generative Recommendation with A Single LLM"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Conclusion</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">STORE: Streamlining Semantic Tokenization and Generative Recommendation with A Single LLM
</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Qijiong Liu
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id1.1.id1">The HK PolyU</span><span class="ltx_text ltx_affiliation_country" id="id2.2.id2">Hong Kong, China</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:liu@qijiong.work">liu@qijiong.work</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Jieming Zhu
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id3.1.id1">Huawei Noah’s Ark Lab</span><span class="ltx_text ltx_affiliation_city" id="id4.2.id2">Shenzhen</span><span class="ltx_text ltx_affiliation_country" id="id5.3.id3">China</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:jiemingzhu@ieee.org">jiemingzhu@ieee.org</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Lu Fan
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id6.1.id1">The HK PolyU</span><span class="ltx_text ltx_affiliation_country" id="id7.2.id2">Hong Kong, China</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:cslfan@comp.polyu.edu.hk">cslfan@comp.polyu.edu.hk</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Zhou Zhao
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id8.1.id1">Zhejiang University</span><span class="ltx_text ltx_affiliation_city" id="id9.2.id2">Hangzhou</span><span class="ltx_text ltx_affiliation_country" id="id10.3.id3">China</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:zhaozhou@zju.edu.cn">zhaozhou@zju.edu.cn</a>
</span></span></span>
<span class="ltx_author_before"> and </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Xiao-Ming Wu
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id11.1.id1">The HK PolyU</span><span class="ltx_text ltx_affiliation_country" id="id12.2.id2">Hong Kong, China</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:xiao-ming.wu@polyu.edu.hk">xiao-ming.wu@polyu.edu.hk</a>
</span></span></span>
</div>
<div class="ltx_dates">(2018)</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p class="ltx_p" id="id13.id1">Traditional recommendation models often rely on unique item identifiers (IDs) to distinguish between items, which can hinder their ability to effectively leverage item content information and generalize to long-tail or cold-start items. Recently, semantic tokenization has been proposed as a promising solution that aims to tokenize each item’s semantic representation into a sequence of discrete tokens. In this way, it preserves the item’s semantics within these tokens and ensures that semantically similar items are represented by similar tokens. These semantic tokens have become fundamental in training generative recommendation models. However, existing generative recommendation methods typically involve multiple sub-models for embedding, quantization, and recommendation, leading to an overly complex system. In this paper, we propose to streamline the semantic tokenization and generative recommendation process with a unified framework, dubbed STORE, which leverages a single large language model (LLM) for both tasks. Specifically, we formulate semantic tokenization as a text-to-token task and generative recommendation as a token-to-token task, supplemented by a token-to-text reconstruction task and a text-to-token auxiliary task. All these tasks are framed in a generative manner and trained using a single LLM backbone. Extensive experiments have been conducted to validate the effectiveness of our STORE framework across various recommendation tasks and datasets.
We will release the source code and configurations for reproducible research.</p>
</div>
<div class="ltx_keywords">Semantic Tokenization, Generative Recommendation, Large Recommendation Model
</div>
<span class="ltx_note ltx_note_frontmatter ltx_role_copyright" id="id1"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">copyright: </span>acmlicensed</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_journalyear" id="id2"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">journalyear: </span>2018</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_doi" id="id3"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">doi: </span>XXXXXXX.XXXXXXX</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_conference" id="id4"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">conference: </span>Make sure to enter the correct
conference title from your rights confirmation emai; June 03–05,
2018; Woodstock, NY</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_isbn" id="id5"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">isbn: </span>978-1-4503-XXXX-X/18/06</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_ccs" id="id6"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Information systems Recommender systems</span></span></span>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="302" id="S1.F1.g1" src="x1.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1. </span>Comparison between conventional unique identifiers (in light green) and semantic identifiers (in light purple). For simplicity, each semantic identifier in this illustration consists of only two tokens.</figcaption>
</figure>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Recommender systems are widely deployed in online applications, such as e-commerce websites, advertising networks, streaming services, and social media, to deliver personalized recommendations tailored to users’ interests. However, traditional recommendation models often rely on unique item identifiers (IDs) to represent items <cite class="ltx_cite ltx_citemacro_citep">(Yuan et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib42" title="">2023</a>; Liu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib23" title="">2024d</a>)</cite>, which presents several key limitations. First, ID-based item representation can suffer from overfitting due to the typically sparse and imbalanced nature of the training data. Second, it fails to fully leverage item content information, which is crucial for improving recommendations for long-tail and cold-start items. Third, ID embeddings are learned and updated independently, making it difficult to capture the semantic relationships among items. Finally, given the vast number of items, the item embedding table often consumes a significant amount of memory.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">To address these limitations, semantic tokenization has recently emerged as a promising solution and has gained rapid traction in the community <cite class="ltx_cite ltx_citemacro_citep">(Singh et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib32" title="">2024</a>; Rajput et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib29" title="">2024</a>; Liu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib20" title="">2024b</a>; Zhu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib46" title="">2024</a>)</cite>. As illustrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#S1.F1" title="Figure 1 ‣ 1. Introduction ‣ STORE: Streamlining Semantic Tokenization and Generative Recommendation with A Single LLM"><span class="ltx_text ltx_ref_tag">1</span></a>, instead of representing each item with a unique ID embedding, semantic tokenization encodes each item’s semantic representation into a compact sequence of discrete tokens. These tokens, also known as semantic identifiers or codes<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>In this paper, the terms <span class="ltx_text ltx_font_italic" id="footnote1.1">semantic identifiers</span>, <span class="ltx_text ltx_font_italic" id="footnote1.2">discrete tokens</span>, and <span class="ltx_text ltx_font_italic" id="footnote1.3">codes</span> may be used interchangeably.</span></span></span>, preserve the item’s semantics into the token space and ensure that semantically similar items are represented by similar tokens. For example, consider a scenario where each item is represented by a sequence of <span class="ltx_text ltx_font_italic" id="S1.p2.1.1">4</span> consecutive tokens, each capable of assuming one of <span class="ltx_text ltx_font_italic" id="S1.p2.1.2">256</span> possible values. This theoretically creates a representation space of approximately <math alttext="256^{4}\approx 4" class="ltx_Math" display="inline" id="S1.p2.1.m1.1"><semantics id="S1.p2.1.m1.1a"><mrow id="S1.p2.1.m1.1.1" xref="S1.p2.1.m1.1.1.cmml"><msup id="S1.p2.1.m1.1.1.2" xref="S1.p2.1.m1.1.1.2.cmml"><mn id="S1.p2.1.m1.1.1.2.2" xref="S1.p2.1.m1.1.1.2.2.cmml">256</mn><mn id="S1.p2.1.m1.1.1.2.3" xref="S1.p2.1.m1.1.1.2.3.cmml">4</mn></msup><mo id="S1.p2.1.m1.1.1.1" xref="S1.p2.1.m1.1.1.1.cmml">≈</mo><mn id="S1.p2.1.m1.1.1.3" xref="S1.p2.1.m1.1.1.3.cmml">4</mn></mrow><annotation-xml encoding="MathML-Content" id="S1.p2.1.m1.1b"><apply id="S1.p2.1.m1.1.1.cmml" xref="S1.p2.1.m1.1.1"><approx id="S1.p2.1.m1.1.1.1.cmml" xref="S1.p2.1.m1.1.1.1"></approx><apply id="S1.p2.1.m1.1.1.2.cmml" xref="S1.p2.1.m1.1.1.2"><csymbol cd="ambiguous" id="S1.p2.1.m1.1.1.2.1.cmml" xref="S1.p2.1.m1.1.1.2">superscript</csymbol><cn id="S1.p2.1.m1.1.1.2.2.cmml" type="integer" xref="S1.p2.1.m1.1.1.2.2">256</cn><cn id="S1.p2.1.m1.1.1.2.3.cmml" type="integer" xref="S1.p2.1.m1.1.1.2.3">4</cn></apply><cn id="S1.p2.1.m1.1.1.3.cmml" type="integer" xref="S1.p2.1.m1.1.1.3">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p2.1.m1.1c">256^{4}\approx 4</annotation><annotation encoding="application/x-llamapun" id="S1.p2.1.m1.1d">256 start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT ≈ 4</annotation></semantics></math> billion combinations, which is sufficient or easily expandable for industrial-scale systems. Additionally, tokens and their embeddings can be shared across items, allowing the similarity between two items to be roughly estimated by the Hamming distance between their token sequences. This information can be obtained without the need for training on subsequent recommendation tasks and is independent of token embeddings. As a result, semantic tokenization effectively addresses the aforementioned challenges and shows promise in semantic-enhanced modeling for recommendations <cite class="ltx_cite ltx_citemacro_citep">(Rajput et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib29" title="">2024</a>; Singh et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib32" title="">2024</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">With the recent success of generative AI, particularly large language models (LLMs) <cite class="ltx_cite ltx_citemacro_citep">(Touvron et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib34" title="">2023</a>; OpenAI, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib27" title="">2022</a>)</cite>, generative recommendation <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib18" title="">2024</a>; Rajput et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib29" title="">2024</a>)</cite> has emerged as a new paradigm for item recommendation, framing it as a token sequence generation task. Semantic tokenization is a crucial preliminary step in training these models. Directly generating item ID sequences, as seen in models like SASRec <cite class="ltx_cite ltx_citemacro_citep">(Kang and McAuley, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib13" title="">2018</a>)</cite> and Bert4Rec <cite class="ltx_cite ltx_citemacro_citep">(Sun et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib33" title="">2019</a>)</cite>, is challenging in practice due to the time-consuming process of decoding from the vast volume of item IDs. By tokenizing each item into a sequence of tokens, it becomes more efficient to generate over token sequences and subsequently map them back to items. This approach has significantly contributed to the success of recent generative recommendation models, such as TIGER <cite class="ltx_cite ltx_citemacro_citep">(Rajput et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib29" title="">2024</a>)</cite>, EAGER <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib37" title="">2024b</a>)</cite>, and LC-REC <cite class="ltx_cite ltx_citemacro_citep">(Zheng et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib45" title="">2024</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">However, existing generative recommendation methods (e.g., TIGER <cite class="ltx_cite ltx_citemacro_citep">(Rajput et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib29" title="">2024</a>)</cite>) typically follow a pipeline that involves multiple distinct models: an embedder, a quantizer, and a recommender. As illustrated in the upper panel of Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#S1.F2" title="Figure 2 ‣ 1. Introduction ‣ STORE: Streamlining Semantic Tokenization and Generative Recommendation with A Single LLM"><span class="ltx_text ltx_ref_tag">2</span></a>, the process begins with an embedder that extracts item semantic embeddings using a pre-trained text encoder. Next, a quantizer tokenizes these embeddings into discrete tokens, often using vector quantization techniques like RQ-VAE <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib37" title="">2024b</a>; Singh et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib32" title="">2024</a>)</cite>. These tokens are then used to train the recommender through token sequence generation tasks, resulting in a complex, multi-stage pipeline with several inherent limitations:
1) Current approaches rely on frozen general-domain text encoders (e.g., Sentence-T5 <cite class="ltx_cite ltx_citemacro_citep">(Ni et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib26" title="">2021</a>)</cite>) for item embedding, which fail to address the <span class="ltx_text ltx_font_bold" id="S1.p4.1.1">domain gap</span> between the general-domain corpus and item content in recommendation scenarios.
2) The commonly used RQ-VAE quantizer is <span class="ltx_text ltx_font_bold" id="S1.p4.1.2">challenging to train</span>, requiring additional efforts to prevent codebook collapse and manage collisions (i.e., different items being assigned the same token sequence) <cite class="ltx_cite ltx_citemacro_citep">(Rajput et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib29" title="">2024</a>)</cite>.
3) The pipeline involves the <span class="ltx_text ltx_font_bold" id="S1.p4.1.3">disjoint optimization</span> of multiple models, leading to information loss and hindering knowledge transfer between them.
4) The complex nature of the pipeline can incur <span class="ltx_text ltx_font_bold" id="S1.p4.1.4">additional costs</span> for model training, deployment, and management in practice.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">In this paper, we introduce a unified framework, <span class="ltx_text ltx_font_bold" id="S1.p5.1.1">STORE</span>, to streamline the processes of semantic tokenization and generative recommendation using a single LLM. Specifically, we formulate semantic tokenization as a text-to-token task and generative recommendation as a token-to-token task. To minimize information loss and enhance knowledge transfer, we incorporate a token-to-text reconstruction task for semantic tokenization and a text-to-token auxiliary task during generative recommendation. All tasks are framed in an instruction-based generative paradigm and trained on a domain-specific corpus using a single LLM backbone. Additionally, we utilize the classic non-parametric <math alttext="k" class="ltx_Math" display="inline" id="S1.p5.1.m1.1"><semantics id="S1.p5.1.m1.1a"><mi id="S1.p5.1.m1.1.1" xref="S1.p5.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S1.p5.1.m1.1b"><ci id="S1.p5.1.m1.1.1.cmml" xref="S1.p5.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p5.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S1.p5.1.m1.1d">italic_k</annotation></semantics></math>-means algorithm for token discretization, simplifying the overall training process. Our trained model can be applied to various downstream recommendation tasks, such as sequential recommendation and click-through rate (CTR) prediction.
In summary, our work makes the following main contributions:</p>
</div>
<figure class="ltx_figure" id="S1.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="511" id="S1.F2.g1" src="x2.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2. </span>Comparison of the existing semantic tokenization pipeline (embedder → quantizer → recommender) with our proposed pipeline (tokenizer → clusterer → recommender).
</figcaption>
</figure>
<div class="ltx_para" id="S1.p6">
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S1.I1.i1.p1.1.1">Unified Framework:</span> We introduce STORE, a novel framework that streamlines semantic tokenization and generative recommendation using a single LLM. This approach minimizes information loss, enhances knowledge transfer, and reduces the pipeline complexity by using a single LLM model.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S1.I1.i2.p1.1.1">Efficient Semantic Tokenization:</span> Our method employs a dense tokenizer to convert item content features into token embeddings, followed by k-means clustering to obtain discrete tokens. This design circumvents the challenges often encountered in training vector quantization models, such as codebook collapse <cite class="ltx_cite ltx_citemacro_citep">(Huh et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib10" title="">2023</a>; Baykal et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib3" title="">2023</a>)</cite>.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S1.I1.i3.p1.1.1">Empirical Evaluation:</span> Extensive experiments on two real-world datasets – MIND for news recommendation and Yelp for restaurant recommendation – demonstrate that the STORE framework achieves superior performance across multiple recommendation scenarios, highlighting its effectiveness and broad applicability.</p>
</div>
</li>
</ul>
</div>
<figure class="ltx_figure" id="S1.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="318" id="S1.F3.g1" src="x3.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3. </span>Detailed architecture for our designed dense tokenizer. Items are initially compressed into embeddings and subsequently clustered to generate semantic tokens, which are then incorporated into the downstream recommender system. Such “text-to-token” conversion will be achieved by cascaded attention mask mechanism and self-supervised tasks.</figcaption>
</figure>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Preliminaries</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">Traditional recommender systems use unique item identifiers mapped to learnable vectors (embeddings) to represent items during training, leading to the challenges mentioned earlier. Recent studies <cite class="ltx_cite ltx_citemacro_citep">(Rajput et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib29" title="">2024</a>; Zheng et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib45" title="">2024</a>; Liu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib20" title="">2024b</a>)</cite> have shown that semantic tokenization is becoming an increasingly popular approach for embedding item content into identifiers.<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>Recent works <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib37" title="">2024b</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib36" title="">a</a>; Qu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib28" title="">2024</a>)</cite> have extracted item embeddings from pretrained recommenders using collaborative knowledge. However, these collaborative embeddings are unstable and frequently change in real-world scenarios, unlike the stable nature of item content knowledge. Therefore, this paper focuses on generating semantic identifiers merely based on item content features.</span></span></span> In this section, we focus on two key aspects: i) generating semantic identifiers using standard approaches, and ii) utilizing these semantic identifiers in downstream recommendation models.</p>
</div>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1. </span>Semantic Tokenization</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">Semantic tokenization aims to generate shared sub-identifiers that can be linked across different items, based on item content or collaborative insights. As illustrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#S1.F2" title="Figure 2 ‣ 1. Introduction ‣ STORE: Streamlining Semantic Tokenization and Generative Recommendation with A Single LLM"><span class="ltx_text ltx_ref_tag">2</span></a>, the standard semantic tokenization pipeline <cite class="ltx_cite ltx_citemacro_citep">(Rajput et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib29" title="">2024</a>; Zheng et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib45" title="">2024</a>)</cite> consists of an embedder, a quantizer, and a recommender.</p>
</div>
<div class="ltx_para" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1">The embedder, typically a pretrained language model such as SentenceBERT <cite class="ltx_cite ltx_citemacro_citep">(Reimers and Gurevych, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib30" title="">2019</a>)</cite> or LLaMA <cite class="ltx_cite ltx_citemacro_citep">(Touvron et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib34" title="">2023</a>)</cite>, is often used because textual features are the primary modality in most recommendation scenarios. Leveraging the rich knowledge from pretrained corpora, these embedders generate robust item representations.</p>
</div>
<div class="ltx_para" id="S2.SS1.p3">
<p class="ltx_p" id="S2.SS1.p3.12">Next, a residual quantizer <cite class="ltx_cite ltx_citemacro_citep">(Lee et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib16" title="">2022</a>)</cite> is used to discretize each item embedding into structure-aware tokens, using multi-layer (<math alttext="L" class="ltx_Math" display="inline" id="S2.SS1.p3.1.m1.1"><semantics id="S2.SS1.p3.1.m1.1a"><mi id="S2.SS1.p3.1.m1.1.1" xref="S2.SS1.p3.1.m1.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.1.m1.1b"><ci id="S2.SS1.p3.1.m1.1.1.cmml" xref="S2.SS1.p3.1.m1.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.1.m1.1c">L</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p3.1.m1.1d">italic_L</annotation></semantics></math>) codebooks, with each codebook containing <math alttext="K" class="ltx_Math" display="inline" id="S2.SS1.p3.2.m2.1"><semantics id="S2.SS1.p3.2.m2.1a"><mi id="S2.SS1.p3.2.m2.1.1" xref="S2.SS1.p3.2.m2.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.2.m2.1b"><ci id="S2.SS1.p3.2.m2.1.1.cmml" xref="S2.SS1.p3.2.m2.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.2.m2.1c">K</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p3.2.m2.1d">italic_K</annotation></semantics></math> code vectors. Each item is (expected to be) mapped to a combination of codes with a length of <math alttext="L" class="ltx_Math" display="inline" id="S2.SS1.p3.3.m3.1"><semantics id="S2.SS1.p3.3.m3.1a"><mi id="S2.SS1.p3.3.m3.1.1" xref="S2.SS1.p3.3.m3.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.3.m3.1b"><ci id="S2.SS1.p3.3.m3.1.1.cmml" xref="S2.SS1.p3.3.m3.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.3.m3.1c">L</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p3.3.m3.1d">italic_L</annotation></semantics></math>, where each position is selected from the corresponding codebook. Theoretically, the representation space for <math alttext="L" class="ltx_Math" display="inline" id="S2.SS1.p3.4.m4.1"><semantics id="S2.SS1.p3.4.m4.1a"><mi id="S2.SS1.p3.4.m4.1.1" xref="S2.SS1.p3.4.m4.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.4.m4.1b"><ci id="S2.SS1.p3.4.m4.1.1.cmml" xref="S2.SS1.p3.4.m4.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.4.m4.1c">L</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p3.4.m4.1d">italic_L</annotation></semantics></math>-layer codebooks is <math alttext="K^{L}" class="ltx_Math" display="inline" id="S2.SS1.p3.5.m5.1"><semantics id="S2.SS1.p3.5.m5.1a"><msup id="S2.SS1.p3.5.m5.1.1" xref="S2.SS1.p3.5.m5.1.1.cmml"><mi id="S2.SS1.p3.5.m5.1.1.2" xref="S2.SS1.p3.5.m5.1.1.2.cmml">K</mi><mi id="S2.SS1.p3.5.m5.1.1.3" xref="S2.SS1.p3.5.m5.1.1.3.cmml">L</mi></msup><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.5.m5.1b"><apply id="S2.SS1.p3.5.m5.1.1.cmml" xref="S2.SS1.p3.5.m5.1.1"><csymbol cd="ambiguous" id="S2.SS1.p3.5.m5.1.1.1.cmml" xref="S2.SS1.p3.5.m5.1.1">superscript</csymbol><ci id="S2.SS1.p3.5.m5.1.1.2.cmml" xref="S2.SS1.p3.5.m5.1.1.2">𝐾</ci><ci id="S2.SS1.p3.5.m5.1.1.3.cmml" xref="S2.SS1.p3.5.m5.1.1.3">𝐿</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.5.m5.1c">K^{L}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p3.5.m5.1d">italic_K start_POSTSUPERSCRIPT italic_L end_POSTSUPERSCRIPT</annotation></semantics></math>, which means that even a much smaller <math alttext="K" class="ltx_Math" display="inline" id="S2.SS1.p3.6.m6.1"><semantics id="S2.SS1.p3.6.m6.1a"><mi id="S2.SS1.p3.6.m6.1.1" xref="S2.SS1.p3.6.m6.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.6.m6.1b"><ci id="S2.SS1.p3.6.m6.1.1.cmml" xref="S2.SS1.p3.6.m6.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.6.m6.1c">K</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p3.6.m6.1d">italic_K</annotation></semantics></math> and <math alttext="L" class="ltx_Math" display="inline" id="S2.SS1.p3.7.m7.1"><semantics id="S2.SS1.p3.7.m7.1a"><mi id="S2.SS1.p3.7.m7.1.1" xref="S2.SS1.p3.7.m7.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.7.m7.1b"><ci id="S2.SS1.p3.7.m7.1.1.cmml" xref="S2.SS1.p3.7.m7.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.7.m7.1c">L</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p3.7.m7.1d">italic_L</annotation></semantics></math> can effectively represent a total of <math alttext="N" class="ltx_Math" display="inline" id="S2.SS1.p3.8.m8.1"><semantics id="S2.SS1.p3.8.m8.1a"><mi id="S2.SS1.p3.8.m8.1.1" xref="S2.SS1.p3.8.m8.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.8.m8.1b"><ci id="S2.SS1.p3.8.m8.1.1.cmml" xref="S2.SS1.p3.8.m8.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.8.m8.1c">N</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p3.8.m8.1d">italic_N</annotation></semantics></math> items, even when <math alttext="N\gg K" class="ltx_Math" display="inline" id="S2.SS1.p3.9.m9.1"><semantics id="S2.SS1.p3.9.m9.1a"><mrow id="S2.SS1.p3.9.m9.1.1" xref="S2.SS1.p3.9.m9.1.1.cmml"><mi id="S2.SS1.p3.9.m9.1.1.2" xref="S2.SS1.p3.9.m9.1.1.2.cmml">N</mi><mo id="S2.SS1.p3.9.m9.1.1.1" xref="S2.SS1.p3.9.m9.1.1.1.cmml">≫</mo><mi id="S2.SS1.p3.9.m9.1.1.3" xref="S2.SS1.p3.9.m9.1.1.3.cmml">K</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.9.m9.1b"><apply id="S2.SS1.p3.9.m9.1.1.cmml" xref="S2.SS1.p3.9.m9.1.1"><csymbol cd="latexml" id="S2.SS1.p3.9.m9.1.1.1.cmml" xref="S2.SS1.p3.9.m9.1.1.1">much-greater-than</csymbol><ci id="S2.SS1.p3.9.m9.1.1.2.cmml" xref="S2.SS1.p3.9.m9.1.1.2">𝑁</ci><ci id="S2.SS1.p3.9.m9.1.1.3.cmml" xref="S2.SS1.p3.9.m9.1.1.3">𝐾</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.9.m9.1c">N\gg K</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p3.9.m9.1d">italic_N ≫ italic_K</annotation></semantics></math>. Consequently, the substantial memory required for item embeddings in traditional recommenders, i.e., <math alttext="N\times D" class="ltx_Math" display="inline" id="S2.SS1.p3.10.m10.1"><semantics id="S2.SS1.p3.10.m10.1a"><mrow id="S2.SS1.p3.10.m10.1.1" xref="S2.SS1.p3.10.m10.1.1.cmml"><mi id="S2.SS1.p3.10.m10.1.1.2" xref="S2.SS1.p3.10.m10.1.1.2.cmml">N</mi><mo id="S2.SS1.p3.10.m10.1.1.1" lspace="0.222em" rspace="0.222em" xref="S2.SS1.p3.10.m10.1.1.1.cmml">×</mo><mi id="S2.SS1.p3.10.m10.1.1.3" xref="S2.SS1.p3.10.m10.1.1.3.cmml">D</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.10.m10.1b"><apply id="S2.SS1.p3.10.m10.1.1.cmml" xref="S2.SS1.p3.10.m10.1.1"><times id="S2.SS1.p3.10.m10.1.1.1.cmml" xref="S2.SS1.p3.10.m10.1.1.1"></times><ci id="S2.SS1.p3.10.m10.1.1.2.cmml" xref="S2.SS1.p3.10.m10.1.1.2">𝑁</ci><ci id="S2.SS1.p3.10.m10.1.1.3.cmml" xref="S2.SS1.p3.10.m10.1.1.3">𝐷</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.10.m10.1c">N\times D</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p3.10.m10.1d">italic_N × italic_D</annotation></semantics></math> where <math alttext="D" class="ltx_Math" display="inline" id="S2.SS1.p3.11.m11.1"><semantics id="S2.SS1.p3.11.m11.1a"><mi id="S2.SS1.p3.11.m11.1.1" xref="S2.SS1.p3.11.m11.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.11.m11.1b"><ci id="S2.SS1.p3.11.m11.1.1.cmml" xref="S2.SS1.p3.11.m11.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.11.m11.1c">D</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p3.11.m11.1d">italic_D</annotation></semantics></math> is the embedding dimension, can be compressed into a significantly smaller, logarithmic space, i.e., <math alttext="K\times L\times D" class="ltx_Math" display="inline" id="S2.SS1.p3.12.m12.1"><semantics id="S2.SS1.p3.12.m12.1a"><mrow id="S2.SS1.p3.12.m12.1.1" xref="S2.SS1.p3.12.m12.1.1.cmml"><mi id="S2.SS1.p3.12.m12.1.1.2" xref="S2.SS1.p3.12.m12.1.1.2.cmml">K</mi><mo id="S2.SS1.p3.12.m12.1.1.1" lspace="0.222em" rspace="0.222em" xref="S2.SS1.p3.12.m12.1.1.1.cmml">×</mo><mi id="S2.SS1.p3.12.m12.1.1.3" xref="S2.SS1.p3.12.m12.1.1.3.cmml">L</mi><mo id="S2.SS1.p3.12.m12.1.1.1a" lspace="0.222em" rspace="0.222em" xref="S2.SS1.p3.12.m12.1.1.1.cmml">×</mo><mi id="S2.SS1.p3.12.m12.1.1.4" xref="S2.SS1.p3.12.m12.1.1.4.cmml">D</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.12.m12.1b"><apply id="S2.SS1.p3.12.m12.1.1.cmml" xref="S2.SS1.p3.12.m12.1.1"><times id="S2.SS1.p3.12.m12.1.1.1.cmml" xref="S2.SS1.p3.12.m12.1.1.1"></times><ci id="S2.SS1.p3.12.m12.1.1.2.cmml" xref="S2.SS1.p3.12.m12.1.1.2">𝐾</ci><ci id="S2.SS1.p3.12.m12.1.1.3.cmml" xref="S2.SS1.p3.12.m12.1.1.3">𝐿</ci><ci id="S2.SS1.p3.12.m12.1.1.4.cmml" xref="S2.SS1.p3.12.m12.1.1.4">𝐷</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.12.m12.1c">K\times L\times D</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p3.12.m12.1d">italic_K × italic_L × italic_D</annotation></semantics></math>.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2. </span>Downstream Recommenders</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">Once the semantic codes are obtained, they can be integrated into various recommendation models. In sequential recommendation <cite class="ltx_cite ltx_citemacro_citep">(Rajput et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib29" title="">2024</a>; Wang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib37" title="">2024b</a>)</cite>, the user sequence is replaced by a flattened sequence of semantic codes, shifting the task from next-item prediction to next-code prediction. Alternatively, these codes can enhance the recommendation ability of large language models by integrating collaborative knowledge <cite class="ltx_cite ltx_citemacro_citep">(Zheng et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib45" title="">2024</a>; Qu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib28" title="">2024</a>)</cite>.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>Proposed Approach: STORE</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">In this section, we introduce our STORE model, which includes a dense tokenizer, a simple clusterer, and a recommender. This design addresses the limitations of the standard paradigm.</p>
</div>
<figure class="ltx_figure" id="S3.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="420" id="S3.F4.g1" src="x4.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4. </span>Cascaded attention mask for dense tokenizer. “Ph. Block” represents the placeholder block.</figcaption>
</figure>
<div class="ltx_para" id="S3.p2">
<p class="ltx_p" id="S3.p2.1"><span class="ltx_text ltx_font_bold" id="S3.p2.1.1">Firstly</span>, our dense tokenizer compresses item content into several embeddings, enabling the reconstruction of the original content with minimal information loss. This is achieved by post-training a large language model on domain-specific data, which also reduces the distribution gap between the language model and the recommendation scenario. <span class="ltx_text ltx_font_bold" id="S3.p2.1.2">Secondly</span>, simple, training-free algorithms can be applied to cluster the positions of multiple dense embeddings. Unlike residual quantizers, which may suffer from codebook collapse, this simplicity ensures balanced distribution across clusters and a high utilization rate. <span class="ltx_text ltx_font_bold" id="S3.p2.1.3">Thirdly</span>, the downstream recommender shares the same backbone – a large language model – as the tokenizer, since the semantic tokens are generated based on the model’s textual comprehension. Therefore, item semantic knowledge will be transferred not only explicitly through the semantic tokens but also implicitly through the shared network parameters.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1. </span>Dense Tokenizer</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">To distill content into short tokens, we introduce a dense tokenizer compatible with any decoder-only large language model. This distillation leverages a block-wise input scheme, hierarchical attention masking scheme, and self-supervised post-pretraining tasks. The design of the dense tokenizer is inspired by the gisting framework <cite class="ltx_cite ltx_citemacro_citep">(Mu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib25" title="">2024</a>)</cite>, which compresses prompts into short tokens to enhance inference efficiency in the natural language processing domain.</p>
</div>
<figure class="ltx_figure" id="S3.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="804" id="S3.F5.g1" src="x5.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5. </span>Instruction tuning templates.</figcaption>
</figure>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.5"><span class="ltx_text ltx_font_bold" id="S3.SS1.p2.5.1">Block-wise Input Scheme.</span> The input sequence is organized into four distinct blocks: content, token, placeholder, and task.
Given an item <math alttext="\mathbf{x}" class="ltx_Math" display="inline" id="S3.SS1.p2.1.m1.1"><semantics id="S3.SS1.p2.1.m1.1a"><mi id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml">𝐱</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><ci id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1">𝐱</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">\mathbf{x}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.1.m1.1d">bold_x</annotation></semantics></math> – for example, a news article – with <math alttext="m" class="ltx_Math" display="inline" id="S3.SS1.p2.2.m2.1"><semantics id="S3.SS1.p2.2.m2.1a"><mi id="S3.SS1.p2.2.m2.1.1" xref="S3.SS1.p2.2.m2.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.1b"><ci id="S3.SS1.p2.2.m2.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.1c">m</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.2.m2.1d">italic_m</annotation></semantics></math> attributes <math alttext="\{\mathbf{a}_{1},\mathbf{a}_{2},\cdots,\mathbf{a}_{m}\}" class="ltx_Math" display="inline" id="S3.SS1.p2.3.m3.4"><semantics id="S3.SS1.p2.3.m3.4a"><mrow id="S3.SS1.p2.3.m3.4.4.3" xref="S3.SS1.p2.3.m3.4.4.4.cmml"><mo id="S3.SS1.p2.3.m3.4.4.3.4" stretchy="false" xref="S3.SS1.p2.3.m3.4.4.4.cmml">{</mo><msub id="S3.SS1.p2.3.m3.2.2.1.1" xref="S3.SS1.p2.3.m3.2.2.1.1.cmml"><mi id="S3.SS1.p2.3.m3.2.2.1.1.2" xref="S3.SS1.p2.3.m3.2.2.1.1.2.cmml">𝐚</mi><mn id="S3.SS1.p2.3.m3.2.2.1.1.3" xref="S3.SS1.p2.3.m3.2.2.1.1.3.cmml">1</mn></msub><mo id="S3.SS1.p2.3.m3.4.4.3.5" xref="S3.SS1.p2.3.m3.4.4.4.cmml">,</mo><msub id="S3.SS1.p2.3.m3.3.3.2.2" xref="S3.SS1.p2.3.m3.3.3.2.2.cmml"><mi id="S3.SS1.p2.3.m3.3.3.2.2.2" xref="S3.SS1.p2.3.m3.3.3.2.2.2.cmml">𝐚</mi><mn id="S3.SS1.p2.3.m3.3.3.2.2.3" xref="S3.SS1.p2.3.m3.3.3.2.2.3.cmml">2</mn></msub><mo id="S3.SS1.p2.3.m3.4.4.3.6" xref="S3.SS1.p2.3.m3.4.4.4.cmml">,</mo><mi id="S3.SS1.p2.3.m3.1.1" mathvariant="normal" xref="S3.SS1.p2.3.m3.1.1.cmml">⋯</mi><mo id="S3.SS1.p2.3.m3.4.4.3.7" xref="S3.SS1.p2.3.m3.4.4.4.cmml">,</mo><msub id="S3.SS1.p2.3.m3.4.4.3.3" xref="S3.SS1.p2.3.m3.4.4.3.3.cmml"><mi id="S3.SS1.p2.3.m3.4.4.3.3.2" xref="S3.SS1.p2.3.m3.4.4.3.3.2.cmml">𝐚</mi><mi id="S3.SS1.p2.3.m3.4.4.3.3.3" xref="S3.SS1.p2.3.m3.4.4.3.3.3.cmml">m</mi></msub><mo id="S3.SS1.p2.3.m3.4.4.3.8" stretchy="false" xref="S3.SS1.p2.3.m3.4.4.4.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.3.m3.4b"><set id="S3.SS1.p2.3.m3.4.4.4.cmml" xref="S3.SS1.p2.3.m3.4.4.3"><apply id="S3.SS1.p2.3.m3.2.2.1.1.cmml" xref="S3.SS1.p2.3.m3.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.3.m3.2.2.1.1.1.cmml" xref="S3.SS1.p2.3.m3.2.2.1.1">subscript</csymbol><ci id="S3.SS1.p2.3.m3.2.2.1.1.2.cmml" xref="S3.SS1.p2.3.m3.2.2.1.1.2">𝐚</ci><cn id="S3.SS1.p2.3.m3.2.2.1.1.3.cmml" type="integer" xref="S3.SS1.p2.3.m3.2.2.1.1.3">1</cn></apply><apply id="S3.SS1.p2.3.m3.3.3.2.2.cmml" xref="S3.SS1.p2.3.m3.3.3.2.2"><csymbol cd="ambiguous" id="S3.SS1.p2.3.m3.3.3.2.2.1.cmml" xref="S3.SS1.p2.3.m3.3.3.2.2">subscript</csymbol><ci id="S3.SS1.p2.3.m3.3.3.2.2.2.cmml" xref="S3.SS1.p2.3.m3.3.3.2.2.2">𝐚</ci><cn id="S3.SS1.p2.3.m3.3.3.2.2.3.cmml" type="integer" xref="S3.SS1.p2.3.m3.3.3.2.2.3">2</cn></apply><ci id="S3.SS1.p2.3.m3.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1">⋯</ci><apply id="S3.SS1.p2.3.m3.4.4.3.3.cmml" xref="S3.SS1.p2.3.m3.4.4.3.3"><csymbol cd="ambiguous" id="S3.SS1.p2.3.m3.4.4.3.3.1.cmml" xref="S3.SS1.p2.3.m3.4.4.3.3">subscript</csymbol><ci id="S3.SS1.p2.3.m3.4.4.3.3.2.cmml" xref="S3.SS1.p2.3.m3.4.4.3.3.2">𝐚</ci><ci id="S3.SS1.p2.3.m3.4.4.3.3.3.cmml" xref="S3.SS1.p2.3.m3.4.4.3.3.3">𝑚</ci></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.3.m3.4c">\{\mathbf{a}_{1},\mathbf{a}_{2},\cdots,\mathbf{a}_{m}\}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.3.m3.4d">{ bold_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , bold_a start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , ⋯ , bold_a start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT }</annotation></semantics></math>, where <math alttext="\mathbf{a}_{i}" class="ltx_Math" display="inline" id="S3.SS1.p2.4.m4.1"><semantics id="S3.SS1.p2.4.m4.1a"><msub id="S3.SS1.p2.4.m4.1.1" xref="S3.SS1.p2.4.m4.1.1.cmml"><mi id="S3.SS1.p2.4.m4.1.1.2" xref="S3.SS1.p2.4.m4.1.1.2.cmml">𝐚</mi><mi id="S3.SS1.p2.4.m4.1.1.3" xref="S3.SS1.p2.4.m4.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.4.m4.1b"><apply id="S3.SS1.p2.4.m4.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.4.m4.1.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1">subscript</csymbol><ci id="S3.SS1.p2.4.m4.1.1.2.cmml" xref="S3.SS1.p2.4.m4.1.1.2">𝐚</ci><ci id="S3.SS1.p2.4.m4.1.1.3.cmml" xref="S3.SS1.p2.4.m4.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.4.m4.1c">\mathbf{a}_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.4.m4.1d">bold_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> represents the <math alttext="i" class="ltx_Math" display="inline" id="S3.SS1.p2.5.m5.1"><semantics id="S3.SS1.p2.5.m5.1a"><mi id="S3.SS1.p2.5.m5.1.1" xref="S3.SS1.p2.5.m5.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.5.m5.1b"><ci id="S3.SS1.p2.5.m5.1.1.cmml" xref="S3.SS1.p2.5.m5.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.5.m5.1c">i</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.5.m5.1d">italic_i</annotation></semantics></math>-th attribute (e.g., title, abstract, category), the content block for the dense tokenizer is constructed as:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_left">(1)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\texttt{&lt;content&gt;}=[\mathbf{a}_{1};\mathbf{a}_{2};\cdots,\mathbf{a}_{r}]," class="ltx_Math" display="block" id="S3.E1.m1.2"><semantics id="S3.E1.m1.2a"><mrow id="S3.E1.m1.2.2.1" xref="S3.E1.m1.2.2.1.1.cmml"><mrow id="S3.E1.m1.2.2.1.1" xref="S3.E1.m1.2.2.1.1.cmml"><mtext class="ltx_mathvariant_monospace" id="S3.E1.m1.2.2.1.1.5" xref="S3.E1.m1.2.2.1.1.5a.cmml">&lt;content&gt;</mtext><mo id="S3.E1.m1.2.2.1.1.4" xref="S3.E1.m1.2.2.1.1.4.cmml">=</mo><mrow id="S3.E1.m1.2.2.1.1.3.3" xref="S3.E1.m1.2.2.1.1.3.4.cmml"><mo id="S3.E1.m1.2.2.1.1.3.3.4" stretchy="false" xref="S3.E1.m1.2.2.1.1.3.4.cmml">[</mo><msub id="S3.E1.m1.2.2.1.1.1.1.1" xref="S3.E1.m1.2.2.1.1.1.1.1.cmml"><mi id="S3.E1.m1.2.2.1.1.1.1.1.2" xref="S3.E1.m1.2.2.1.1.1.1.1.2.cmml">𝐚</mi><mn id="S3.E1.m1.2.2.1.1.1.1.1.3" xref="S3.E1.m1.2.2.1.1.1.1.1.3.cmml">1</mn></msub><mo id="S3.E1.m1.2.2.1.1.3.3.5" xref="S3.E1.m1.2.2.1.1.3.4.cmml">;</mo><msub id="S3.E1.m1.2.2.1.1.2.2.2" xref="S3.E1.m1.2.2.1.1.2.2.2.cmml"><mi id="S3.E1.m1.2.2.1.1.2.2.2.2" xref="S3.E1.m1.2.2.1.1.2.2.2.2.cmml">𝐚</mi><mn id="S3.E1.m1.2.2.1.1.2.2.2.3" xref="S3.E1.m1.2.2.1.1.2.2.2.3.cmml">2</mn></msub><mo id="S3.E1.m1.2.2.1.1.3.3.6" xref="S3.E1.m1.2.2.1.1.3.4.cmml">;</mo><mi id="S3.E1.m1.1.1" mathvariant="normal" xref="S3.E1.m1.1.1.cmml">⋯</mi><mo id="S3.E1.m1.2.2.1.1.3.3.7" xref="S3.E1.m1.2.2.1.1.3.4.cmml">,</mo><msub id="S3.E1.m1.2.2.1.1.3.3.3" xref="S3.E1.m1.2.2.1.1.3.3.3.cmml"><mi id="S3.E1.m1.2.2.1.1.3.3.3.2" xref="S3.E1.m1.2.2.1.1.3.3.3.2.cmml">𝐚</mi><mi id="S3.E1.m1.2.2.1.1.3.3.3.3" xref="S3.E1.m1.2.2.1.1.3.3.3.3.cmml">r</mi></msub><mo id="S3.E1.m1.2.2.1.1.3.3.8" stretchy="false" xref="S3.E1.m1.2.2.1.1.3.4.cmml">]</mo></mrow></mrow><mo id="S3.E1.m1.2.2.1.2" xref="S3.E1.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.2b"><apply id="S3.E1.m1.2.2.1.1.cmml" xref="S3.E1.m1.2.2.1"><eq id="S3.E1.m1.2.2.1.1.4.cmml" xref="S3.E1.m1.2.2.1.1.4"></eq><ci id="S3.E1.m1.2.2.1.1.5a.cmml" xref="S3.E1.m1.2.2.1.1.5"><mtext class="ltx_mathvariant_monospace" id="S3.E1.m1.2.2.1.1.5.cmml" xref="S3.E1.m1.2.2.1.1.5">&lt;content&gt;</mtext></ci><list id="S3.E1.m1.2.2.1.1.3.4.cmml" xref="S3.E1.m1.2.2.1.1.3.3"><apply id="S3.E1.m1.2.2.1.1.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.1.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1">subscript</csymbol><ci id="S3.E1.m1.2.2.1.1.1.1.1.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.2">𝐚</ci><cn id="S3.E1.m1.2.2.1.1.1.1.1.3.cmml" type="integer" xref="S3.E1.m1.2.2.1.1.1.1.1.3">1</cn></apply><apply id="S3.E1.m1.2.2.1.1.2.2.2.cmml" xref="S3.E1.m1.2.2.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.2.2.2.1.cmml" xref="S3.E1.m1.2.2.1.1.2.2.2">subscript</csymbol><ci id="S3.E1.m1.2.2.1.1.2.2.2.2.cmml" xref="S3.E1.m1.2.2.1.1.2.2.2.2">𝐚</ci><cn id="S3.E1.m1.2.2.1.1.2.2.2.3.cmml" type="integer" xref="S3.E1.m1.2.2.1.1.2.2.2.3">2</cn></apply><ci id="S3.E1.m1.1.1.cmml" xref="S3.E1.m1.1.1">⋯</ci><apply id="S3.E1.m1.2.2.1.1.3.3.3.cmml" xref="S3.E1.m1.2.2.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.3.3.3.1.cmml" xref="S3.E1.m1.2.2.1.1.3.3.3">subscript</csymbol><ci id="S3.E1.m1.2.2.1.1.3.3.3.2.cmml" xref="S3.E1.m1.2.2.1.1.3.3.3.2">𝐚</ci><ci id="S3.E1.m1.2.2.1.1.3.3.3.3.cmml" xref="S3.E1.m1.2.2.1.1.3.3.3.3">𝑟</ci></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.2c">\texttt{&lt;content&gt;}=[\mathbf{a}_{1};\mathbf{a}_{2};\cdots,\mathbf{a}_{r}],</annotation><annotation encoding="application/x-llamapun" id="S3.E1.m1.2d">&lt;content&gt; = [ bold_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ; bold_a start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ; ⋯ , bold_a start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ] ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS1.p2.7">where <math alttext="[;]" class="ltx_math_unparsed" display="inline" id="S3.SS1.p2.6.m1.1"><semantics id="S3.SS1.p2.6.m1.1a"><mrow id="S3.SS1.p2.6.m1.1b"><mo id="S3.SS1.p2.6.m1.1.1" stretchy="false">[</mo><mo id="S3.SS1.p2.6.m1.1.2">;</mo><mo id="S3.SS1.p2.6.m1.1.3" stretchy="false">]</mo></mrow><annotation encoding="application/x-tex" id="S3.SS1.p2.6.m1.1c">[;]</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.6.m1.1d">[ ; ]</annotation></semantics></math> denotes concatenation and <math alttext="r\leq m" class="ltx_Math" display="inline" id="S3.SS1.p2.7.m2.1"><semantics id="S3.SS1.p2.7.m2.1a"><mrow id="S3.SS1.p2.7.m2.1.1" xref="S3.SS1.p2.7.m2.1.1.cmml"><mi id="S3.SS1.p2.7.m2.1.1.2" xref="S3.SS1.p2.7.m2.1.1.2.cmml">r</mi><mo id="S3.SS1.p2.7.m2.1.1.1" xref="S3.SS1.p2.7.m2.1.1.1.cmml">≤</mo><mi id="S3.SS1.p2.7.m2.1.1.3" xref="S3.SS1.p2.7.m2.1.1.3.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.7.m2.1b"><apply id="S3.SS1.p2.7.m2.1.1.cmml" xref="S3.SS1.p2.7.m2.1.1"><leq id="S3.SS1.p2.7.m2.1.1.1.cmml" xref="S3.SS1.p2.7.m2.1.1.1"></leq><ci id="S3.SS1.p2.7.m2.1.1.2.cmml" xref="S3.SS1.p2.7.m2.1.1.2">𝑟</ci><ci id="S3.SS1.p2.7.m2.1.1.3.cmml" xref="S3.SS1.p2.7.m2.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.7.m2.1c">r\leq m</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.7.m2.1d">italic_r ≤ italic_m</annotation></semantics></math>. An example content block might be “<span class="ltx_text ltx_font_typewriter" id="S3.SS1.p2.7.1" style="color:#379349;">title:</span> <span class="ltx_text ltx_font_typewriter" id="S3.SS1.p2.7.2" style="color:#55AF7B;">Yellowstone tourist injured ...</span> <span class="ltx_text ltx_font_typewriter" id="S3.SS1.p2.7.3" style="color:#3D3283;">abstract:</span> <span class="ltx_text ltx_font_typewriter" id="S3.SS1.p2.7.4" style="color:#4286F3;">A tourist suffered severe burns ...</span>”.</p>
</div>
<div class="ltx_para" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.1">Next, the token block contains <math alttext="v" class="ltx_Math" display="inline" id="S3.SS1.p3.1.m1.1"><semantics id="S3.SS1.p3.1.m1.1a"><mi id="S3.SS1.p3.1.m1.1.1" xref="S3.SS1.p3.1.m1.1.1.cmml">v</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.1.m1.1b"><ci id="S3.SS1.p3.1.m1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1">𝑣</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.1.m1.1c">v</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.1.m1.1d">italic_v</annotation></semantics></math> fixed tokens:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_left">(2)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\texttt{&lt;token&gt;}=[\texttt{{\color[rgb]{0.5859375,0.44140625,0.21484375}%
\definecolor[named]{pgfstrokecolor}{rgb}{0.5859375,0.44140625,0.21484375}&lt;DT1&gt;%
}},\texttt{{\color[rgb]{0.1796875,0.36328125,0.52734375}\definecolor[named]{%
pgfstrokecolor}{rgb}{0.1796875,0.36328125,0.52734375}&lt;DT2&gt;}},\dots]," class="ltx_Math" display="block" id="S3.E2.m1.4"><semantics id="S3.E2.m1.4a"><mrow id="S3.E2.m1.4.4.1" xref="S3.E2.m1.4.4.1.1.cmml"><mrow id="S3.E2.m1.4.4.1.1" xref="S3.E2.m1.4.4.1.1.cmml"><mtext class="ltx_mathvariant_monospace" id="S3.E2.m1.4.4.1.1.2" xref="S3.E2.m1.4.4.1.1.2a.cmml">&lt;token&gt;</mtext><mo id="S3.E2.m1.4.4.1.1.1" xref="S3.E2.m1.4.4.1.1.1.cmml">=</mo><mrow id="S3.E2.m1.4.4.1.1.3.2" xref="S3.E2.m1.4.4.1.1.3.1.cmml"><mo id="S3.E2.m1.4.4.1.1.3.2.1" stretchy="false" xref="S3.E2.m1.4.4.1.1.3.1.cmml">[</mo><mtext class="ltx_mathvariant_monospace" id="S3.E2.m1.1.1" mathcolor="#957137" xref="S3.E2.m1.1.1a.cmml">&lt;DT1&gt;</mtext><mo id="S3.E2.m1.4.4.1.1.3.2.2" xref="S3.E2.m1.4.4.1.1.3.1.cmml">,</mo><mtext class="ltx_mathvariant_monospace" id="S3.E2.m1.2.2" mathcolor="#2E5D86" xref="S3.E2.m1.2.2a.cmml">&lt;DT2&gt;</mtext><mo id="S3.E2.m1.4.4.1.1.3.2.3" xref="S3.E2.m1.4.4.1.1.3.1.cmml">,</mo><mi id="S3.E2.m1.3.3" mathvariant="normal" xref="S3.E2.m1.3.3.cmml">…</mi><mo id="S3.E2.m1.4.4.1.1.3.2.4" stretchy="false" xref="S3.E2.m1.4.4.1.1.3.1.cmml">]</mo></mrow></mrow><mo id="S3.E2.m1.4.4.1.2" xref="S3.E2.m1.4.4.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.4b"><apply id="S3.E2.m1.4.4.1.1.cmml" xref="S3.E2.m1.4.4.1"><eq id="S3.E2.m1.4.4.1.1.1.cmml" xref="S3.E2.m1.4.4.1.1.1"></eq><ci id="S3.E2.m1.4.4.1.1.2a.cmml" xref="S3.E2.m1.4.4.1.1.2"><mtext class="ltx_mathvariant_monospace" id="S3.E2.m1.4.4.1.1.2.cmml" xref="S3.E2.m1.4.4.1.1.2">&lt;token&gt;</mtext></ci><list id="S3.E2.m1.4.4.1.1.3.1.cmml" xref="S3.E2.m1.4.4.1.1.3.2"><ci id="S3.E2.m1.1.1a.cmml" xref="S3.E2.m1.1.1"><mtext class="ltx_mathvariant_monospace" id="S3.E2.m1.1.1.cmml" mathcolor="#957137" xref="S3.E2.m1.1.1">&lt;DT1&gt;</mtext></ci><ci id="S3.E2.m1.2.2a.cmml" xref="S3.E2.m1.2.2"><mtext class="ltx_mathvariant_monospace" id="S3.E2.m1.2.2.cmml" mathcolor="#2E5D86" xref="S3.E2.m1.2.2">&lt;DT2&gt;</mtext></ci><ci id="S3.E2.m1.3.3.cmml" xref="S3.E2.m1.3.3">…</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.4c">\texttt{&lt;token&gt;}=[\texttt{{\color[rgb]{0.5859375,0.44140625,0.21484375}%
\definecolor[named]{pgfstrokecolor}{rgb}{0.5859375,0.44140625,0.21484375}&lt;DT1&gt;%
}},\texttt{{\color[rgb]{0.1796875,0.36328125,0.52734375}\definecolor[named]{%
pgfstrokecolor}{rgb}{0.1796875,0.36328125,0.52734375}&lt;DT2&gt;}},\dots],</annotation><annotation encoding="application/x-llamapun" id="S3.E2.m1.4d">&lt;token&gt; = [ &lt;DT1&gt; , &lt;DT2&gt; , … ] ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS1.p3.2">where <math alttext="v=2" class="ltx_Math" display="inline" id="S3.SS1.p3.2.m1.1"><semantics id="S3.SS1.p3.2.m1.1a"><mrow id="S3.SS1.p3.2.m1.1.1" xref="S3.SS1.p3.2.m1.1.1.cmml"><mi id="S3.SS1.p3.2.m1.1.1.2" xref="S3.SS1.p3.2.m1.1.1.2.cmml">v</mi><mo id="S3.SS1.p3.2.m1.1.1.1" xref="S3.SS1.p3.2.m1.1.1.1.cmml">=</mo><mn id="S3.SS1.p3.2.m1.1.1.3" xref="S3.SS1.p3.2.m1.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.2.m1.1b"><apply id="S3.SS1.p3.2.m1.1.1.cmml" xref="S3.SS1.p3.2.m1.1.1"><eq id="S3.SS1.p3.2.m1.1.1.1.cmml" xref="S3.SS1.p3.2.m1.1.1.1"></eq><ci id="S3.SS1.p3.2.m1.1.1.2.cmml" xref="S3.SS1.p3.2.m1.1.1.2">𝑣</ci><cn id="S3.SS1.p3.2.m1.1.1.3.cmml" type="integer" xref="S3.SS1.p3.2.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.2.m1.1c">v=2</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.2.m1.1d">italic_v = 2</annotation></semantics></math> in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#S1.F3" title="Figure 3 ‣ 1. Introduction ‣ STORE: Streamlining Semantic Tokenization and Generative Recommendation with A Single LLM"><span class="ltx_text ltx_ref_tag">3</span></a>. These tokens have learnable embeddings that absorb knowledge through a multi-layer transformer network, serving as a bridge between the original content and the task output.</p>
</div>
<div class="ltx_para" id="S3.SS1.p4">
<p class="ltx_p" id="S3.SS1.p4.1">Since the output embeddings of the token block are expected to encapsulate the knowledge of the item content, they must also reconstruct or generate the original item attributes. To achieve this, we append a placeholder block containing <math alttext="v" class="ltx_Math" display="inline" id="S3.SS1.p4.1.m1.1"><semantics id="S3.SS1.p4.1.m1.1a"><mi id="S3.SS1.p4.1.m1.1.1" xref="S3.SS1.p4.1.m1.1.1.cmml">v</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.1.m1.1b"><ci id="S3.SS1.p4.1.m1.1.1.cmml" xref="S3.SS1.p4.1.m1.1.1">𝑣</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.1.m1.1c">v</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.1.m1.1d">italic_v</annotation></semantics></math> placeholder tokens after the token block:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_left">(3)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\texttt{&lt;placeholder&gt;}=[\texttt{{\color[rgb]{0.5859375,0.44140625,0.21484375}%
\definecolor[named]{pgfstrokecolor}{rgb}{0.5859375,0.44140625,0.21484375}&lt;PH1&gt;%
}},\texttt{{\color[rgb]{0.1796875,0.36328125,0.52734375}\definecolor[named]{%
pgfstrokecolor}{rgb}{0.1796875,0.36328125,0.52734375}&lt;PH2&gt;}},\dots]." class="ltx_Math" display="block" id="S3.E3.m1.4"><semantics id="S3.E3.m1.4a"><mrow id="S3.E3.m1.4.4.1" xref="S3.E3.m1.4.4.1.1.cmml"><mrow id="S3.E3.m1.4.4.1.1" xref="S3.E3.m1.4.4.1.1.cmml"><mtext class="ltx_mathvariant_monospace" id="S3.E3.m1.4.4.1.1.2" xref="S3.E3.m1.4.4.1.1.2a.cmml">&lt;placeholder&gt;</mtext><mo id="S3.E3.m1.4.4.1.1.1" xref="S3.E3.m1.4.4.1.1.1.cmml">=</mo><mrow id="S3.E3.m1.4.4.1.1.3.2" xref="S3.E3.m1.4.4.1.1.3.1.cmml"><mo id="S3.E3.m1.4.4.1.1.3.2.1" stretchy="false" xref="S3.E3.m1.4.4.1.1.3.1.cmml">[</mo><mtext class="ltx_mathvariant_monospace" id="S3.E3.m1.1.1" mathcolor="#957137" xref="S3.E3.m1.1.1a.cmml">&lt;PH1&gt;</mtext><mo id="S3.E3.m1.4.4.1.1.3.2.2" xref="S3.E3.m1.4.4.1.1.3.1.cmml">,</mo><mtext class="ltx_mathvariant_monospace" id="S3.E3.m1.2.2" mathcolor="#2E5D86" xref="S3.E3.m1.2.2a.cmml">&lt;PH2&gt;</mtext><mo id="S3.E3.m1.4.4.1.1.3.2.3" xref="S3.E3.m1.4.4.1.1.3.1.cmml">,</mo><mi id="S3.E3.m1.3.3" mathvariant="normal" xref="S3.E3.m1.3.3.cmml">…</mi><mo id="S3.E3.m1.4.4.1.1.3.2.4" stretchy="false" xref="S3.E3.m1.4.4.1.1.3.1.cmml">]</mo></mrow></mrow><mo id="S3.E3.m1.4.4.1.2" lspace="0em" xref="S3.E3.m1.4.4.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.4b"><apply id="S3.E3.m1.4.4.1.1.cmml" xref="S3.E3.m1.4.4.1"><eq id="S3.E3.m1.4.4.1.1.1.cmml" xref="S3.E3.m1.4.4.1.1.1"></eq><ci id="S3.E3.m1.4.4.1.1.2a.cmml" xref="S3.E3.m1.4.4.1.1.2"><mtext class="ltx_mathvariant_monospace" id="S3.E3.m1.4.4.1.1.2.cmml" xref="S3.E3.m1.4.4.1.1.2">&lt;placeholder&gt;</mtext></ci><list id="S3.E3.m1.4.4.1.1.3.1.cmml" xref="S3.E3.m1.4.4.1.1.3.2"><ci id="S3.E3.m1.1.1a.cmml" xref="S3.E3.m1.1.1"><mtext class="ltx_mathvariant_monospace" id="S3.E3.m1.1.1.cmml" mathcolor="#957137" xref="S3.E3.m1.1.1">&lt;PH1&gt;</mtext></ci><ci id="S3.E3.m1.2.2a.cmml" xref="S3.E3.m1.2.2"><mtext class="ltx_mathvariant_monospace" id="S3.E3.m1.2.2.cmml" mathcolor="#2E5D86" xref="S3.E3.m1.2.2">&lt;PH2&gt;</mtext></ci><ci id="S3.E3.m1.3.3.cmml" xref="S3.E3.m1.3.3">…</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.4c">\texttt{&lt;placeholder&gt;}=[\texttt{{\color[rgb]{0.5859375,0.44140625,0.21484375}%
\definecolor[named]{pgfstrokecolor}{rgb}{0.5859375,0.44140625,0.21484375}&lt;PH1&gt;%
}},\texttt{{\color[rgb]{0.1796875,0.36328125,0.52734375}\definecolor[named]{%
pgfstrokecolor}{rgb}{0.1796875,0.36328125,0.52734375}&lt;PH2&gt;}},\dots].</annotation><annotation encoding="application/x-llamapun" id="S3.E3.m1.4d">&lt;placeholder&gt; = [ &lt;PH1&gt; , &lt;PH2&gt; , … ] .</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.SS1.p5">
<p class="ltx_p" id="S3.SS1.p5.1">Unlike other blocks, which have embedding tables to map tokens into embeddings as the final input to the large language model, the placeholder block is filled with the corresponding output embeddings of the token block. This ensures that the task block is guided to generate text from the first transformer layer based on these output embeddings.</p>
</div>
<div class="ltx_para" id="S3.SS1.p6">
<p class="ltx_p" id="S3.SS1.p6.5">Finally, the input sequence ends with the task block, which includes a task token and the answer sequence:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E4">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_left">(4)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\texttt{&lt;task&gt;}=[t_{i};\mathbf{a}_{i}]," class="ltx_Math" display="block" id="S3.E4.m1.1"><semantics id="S3.E4.m1.1a"><mrow id="S3.E4.m1.1.1.1" xref="S3.E4.m1.1.1.1.1.cmml"><mrow id="S3.E4.m1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.cmml"><mtext class="ltx_mathvariant_monospace" id="S3.E4.m1.1.1.1.1.4" xref="S3.E4.m1.1.1.1.1.4a.cmml">&lt;task&gt;</mtext><mo id="S3.E4.m1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.3.cmml">=</mo><mrow id="S3.E4.m1.1.1.1.1.2.2" xref="S3.E4.m1.1.1.1.1.2.3.cmml"><mo id="S3.E4.m1.1.1.1.1.2.2.3" stretchy="false" xref="S3.E4.m1.1.1.1.1.2.3.cmml">[</mo><msub id="S3.E4.m1.1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.1.cmml"><mi id="S3.E4.m1.1.1.1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.1.1.1.2.cmml">t</mi><mi id="S3.E4.m1.1.1.1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.E4.m1.1.1.1.1.2.2.4" xref="S3.E4.m1.1.1.1.1.2.3.cmml">;</mo><msub id="S3.E4.m1.1.1.1.1.2.2.2" xref="S3.E4.m1.1.1.1.1.2.2.2.cmml"><mi id="S3.E4.m1.1.1.1.1.2.2.2.2" xref="S3.E4.m1.1.1.1.1.2.2.2.2.cmml">𝐚</mi><mi id="S3.E4.m1.1.1.1.1.2.2.2.3" xref="S3.E4.m1.1.1.1.1.2.2.2.3.cmml">i</mi></msub><mo id="S3.E4.m1.1.1.1.1.2.2.5" stretchy="false" xref="S3.E4.m1.1.1.1.1.2.3.cmml">]</mo></mrow></mrow><mo id="S3.E4.m1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.1b"><apply id="S3.E4.m1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1"><eq id="S3.E4.m1.1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.3"></eq><ci id="S3.E4.m1.1.1.1.1.4a.cmml" xref="S3.E4.m1.1.1.1.1.4"><mtext class="ltx_mathvariant_monospace" id="S3.E4.m1.1.1.1.1.4.cmml" xref="S3.E4.m1.1.1.1.1.4">&lt;task&gt;</mtext></ci><list id="S3.E4.m1.1.1.1.1.2.3.cmml" xref="S3.E4.m1.1.1.1.1.2.2"><apply id="S3.E4.m1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E4.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.2">𝑡</ci><ci id="S3.E4.m1.1.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.3">𝑖</ci></apply><apply id="S3.E4.m1.1.1.1.1.2.2.2.cmml" xref="S3.E4.m1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.2.2.2.1.cmml" xref="S3.E4.m1.1.1.1.1.2.2.2">subscript</csymbol><ci id="S3.E4.m1.1.1.1.1.2.2.2.2.cmml" xref="S3.E4.m1.1.1.1.1.2.2.2.2">𝐚</ci><ci id="S3.E4.m1.1.1.1.1.2.2.2.3.cmml" xref="S3.E4.m1.1.1.1.1.2.2.2.3">𝑖</ci></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.1c">\texttt{&lt;task&gt;}=[t_{i};\mathbf{a}_{i}],</annotation><annotation encoding="application/x-llamapun" id="S3.E4.m1.1d">&lt;task&gt; = [ italic_t start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ; bold_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ] ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS1.p6.4">where <math alttext="t_{i}" class="ltx_Math" display="inline" id="S3.SS1.p6.1.m1.1"><semantics id="S3.SS1.p6.1.m1.1a"><msub id="S3.SS1.p6.1.m1.1.1" xref="S3.SS1.p6.1.m1.1.1.cmml"><mi id="S3.SS1.p6.1.m1.1.1.2" xref="S3.SS1.p6.1.m1.1.1.2.cmml">t</mi><mi id="S3.SS1.p6.1.m1.1.1.3" xref="S3.SS1.p6.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p6.1.m1.1b"><apply id="S3.SS1.p6.1.m1.1.1.cmml" xref="S3.SS1.p6.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p6.1.m1.1.1.1.cmml" xref="S3.SS1.p6.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.p6.1.m1.1.1.2.cmml" xref="S3.SS1.p6.1.m1.1.1.2">𝑡</ci><ci id="S3.SS1.p6.1.m1.1.1.3.cmml" xref="S3.SS1.p6.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p6.1.m1.1c">t_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p6.1.m1.1d">italic_t start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> is a special token representing the <math alttext="i" class="ltx_Math" display="inline" id="S3.SS1.p6.2.m2.1"><semantics id="S3.SS1.p6.2.m2.1a"><mi id="S3.SS1.p6.2.m2.1.1" xref="S3.SS1.p6.2.m2.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p6.2.m2.1b"><ci id="S3.SS1.p6.2.m2.1.1.cmml" xref="S3.SS1.p6.2.m2.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p6.2.m2.1c">i</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p6.2.m2.1d">italic_i</annotation></semantics></math>-th self-supervised task: it is a reconstruction task when <math alttext="0&lt;i\leq r" class="ltx_Math" display="inline" id="S3.SS1.p6.3.m3.1"><semantics id="S3.SS1.p6.3.m3.1a"><mrow id="S3.SS1.p6.3.m3.1.1" xref="S3.SS1.p6.3.m3.1.1.cmml"><mn id="S3.SS1.p6.3.m3.1.1.2" xref="S3.SS1.p6.3.m3.1.1.2.cmml">0</mn><mo id="S3.SS1.p6.3.m3.1.1.3" xref="S3.SS1.p6.3.m3.1.1.3.cmml">&lt;</mo><mi id="S3.SS1.p6.3.m3.1.1.4" xref="S3.SS1.p6.3.m3.1.1.4.cmml">i</mi><mo id="S3.SS1.p6.3.m3.1.1.5" xref="S3.SS1.p6.3.m3.1.1.5.cmml">≤</mo><mi id="S3.SS1.p6.3.m3.1.1.6" xref="S3.SS1.p6.3.m3.1.1.6.cmml">r</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p6.3.m3.1b"><apply id="S3.SS1.p6.3.m3.1.1.cmml" xref="S3.SS1.p6.3.m3.1.1"><and id="S3.SS1.p6.3.m3.1.1a.cmml" xref="S3.SS1.p6.3.m3.1.1"></and><apply id="S3.SS1.p6.3.m3.1.1b.cmml" xref="S3.SS1.p6.3.m3.1.1"><lt id="S3.SS1.p6.3.m3.1.1.3.cmml" xref="S3.SS1.p6.3.m3.1.1.3"></lt><cn id="S3.SS1.p6.3.m3.1.1.2.cmml" type="integer" xref="S3.SS1.p6.3.m3.1.1.2">0</cn><ci id="S3.SS1.p6.3.m3.1.1.4.cmml" xref="S3.SS1.p6.3.m3.1.1.4">𝑖</ci></apply><apply id="S3.SS1.p6.3.m3.1.1c.cmml" xref="S3.SS1.p6.3.m3.1.1"><leq id="S3.SS1.p6.3.m3.1.1.5.cmml" xref="S3.SS1.p6.3.m3.1.1.5"></leq><share href="https://arxiv.org/html/2409.07276v2#S3.SS1.p6.3.m3.1.1.4.cmml" id="S3.SS1.p6.3.m3.1.1d.cmml" xref="S3.SS1.p6.3.m3.1.1"></share><ci id="S3.SS1.p6.3.m3.1.1.6.cmml" xref="S3.SS1.p6.3.m3.1.1.6">𝑟</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p6.3.m3.1c">0&lt;i\leq r</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p6.3.m3.1d">0 &lt; italic_i ≤ italic_r</annotation></semantics></math> and a generation task when <math alttext="r&lt;i\leq m" class="ltx_Math" display="inline" id="S3.SS1.p6.4.m4.1"><semantics id="S3.SS1.p6.4.m4.1a"><mrow id="S3.SS1.p6.4.m4.1.1" xref="S3.SS1.p6.4.m4.1.1.cmml"><mi id="S3.SS1.p6.4.m4.1.1.2" xref="S3.SS1.p6.4.m4.1.1.2.cmml">r</mi><mo id="S3.SS1.p6.4.m4.1.1.3" xref="S3.SS1.p6.4.m4.1.1.3.cmml">&lt;</mo><mi id="S3.SS1.p6.4.m4.1.1.4" xref="S3.SS1.p6.4.m4.1.1.4.cmml">i</mi><mo id="S3.SS1.p6.4.m4.1.1.5" xref="S3.SS1.p6.4.m4.1.1.5.cmml">≤</mo><mi id="S3.SS1.p6.4.m4.1.1.6" xref="S3.SS1.p6.4.m4.1.1.6.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p6.4.m4.1b"><apply id="S3.SS1.p6.4.m4.1.1.cmml" xref="S3.SS1.p6.4.m4.1.1"><and id="S3.SS1.p6.4.m4.1.1a.cmml" xref="S3.SS1.p6.4.m4.1.1"></and><apply id="S3.SS1.p6.4.m4.1.1b.cmml" xref="S3.SS1.p6.4.m4.1.1"><lt id="S3.SS1.p6.4.m4.1.1.3.cmml" xref="S3.SS1.p6.4.m4.1.1.3"></lt><ci id="S3.SS1.p6.4.m4.1.1.2.cmml" xref="S3.SS1.p6.4.m4.1.1.2">𝑟</ci><ci id="S3.SS1.p6.4.m4.1.1.4.cmml" xref="S3.SS1.p6.4.m4.1.1.4">𝑖</ci></apply><apply id="S3.SS1.p6.4.m4.1.1c.cmml" xref="S3.SS1.p6.4.m4.1.1"><leq id="S3.SS1.p6.4.m4.1.1.5.cmml" xref="S3.SS1.p6.4.m4.1.1.5"></leq><share href="https://arxiv.org/html/2409.07276v2#S3.SS1.p6.4.m4.1.1.4.cmml" id="S3.SS1.p6.4.m4.1.1d.cmml" xref="S3.SS1.p6.4.m4.1.1"></share><ci id="S3.SS1.p6.4.m4.1.1.6.cmml" xref="S3.SS1.p6.4.m4.1.1.6">𝑚</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p6.4.m4.1c">r&lt;i\leq m</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p6.4.m4.1d">italic_r &lt; italic_i ≤ italic_m</annotation></semantics></math>. For example, this could be:
<span class="ltx_text ltx_font_typewriter" id="S3.SS1.p6.4.1">‘‘<span class="ltx_text" id="S3.SS1.p6.4.1.1" style="color:#83317C;">reconstruct_title:</span> <span class="ltx_text" id="S3.SS1.p6.4.1.2" style="color:#379349;">title:</span> <span class="ltx_text" id="S3.SS1.p6.4.1.3" style="color:#55AF7B;">Yellowstone tourist injured ...</span>’’</span></p>
</div>
<div class="ltx_para" id="S3.SS1.p7">
<p class="ltx_p" id="S3.SS1.p7.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p7.1.1">Cascaded Attention Mask.</span>
Decoder-only large language models typically employ a causal attention mask, ensuring that each token in a sequence can only attend to preceding tokens and itself, but not to future tokens. This conventional approach is unsuitable for our scenario where only the outputs of the token block (and subsequently the placeholder block) are permitted to generate the task output. Therefore, we introduce a cascaded attention masking scheme that includes both inner-block and inter-block masking.</p>
</div>
<div class="ltx_para" id="S3.SS1.p8">
<p class="ltx_p" id="S3.SS1.p8.1">As illustrated in the diagonal of Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#S3.F4" title="Figure 4 ‣ 3. Proposed Approach: STORE ‣ STORE: Streamlining Semantic Tokenization and Generative Recommendation with A Single LLM"><span class="ltx_text ltx_ref_tag">4</span></a>, <span class="ltx_text ltx_font_italic" id="S3.SS1.p8.1.1">inner-block masking</span> consistently enforces causal attention to preserve sequential knowledge comprehension. Conversely, <span class="ltx_text ltx_font_italic" id="S3.SS1.p8.1.2">inter-block masking</span> can be configured as either full or empty attention: the content block fully attends to the token block, and the placeholder block fully attends to the task block. Attention between other blocks is prohibited and set to empty.</p>
</div>
<div class="ltx_para" id="S3.SS1.p9">
<p class="ltx_p" id="S3.SS1.p9.3"><span class="ltx_text ltx_font_bold" id="S3.SS1.p9.3.1">Post-pretraining.</span>
As depicted in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#S1.F3" title="Figure 3 ‣ 1. Introduction ‣ STORE: Streamlining Semantic Tokenization and Generative Recommendation with A Single LLM"><span class="ltx_text ltx_ref_tag">3</span></a>, we replicate each item content <math alttext="m" class="ltx_Math" display="inline" id="S3.SS1.p9.1.m1.1"><semantics id="S3.SS1.p9.1.m1.1a"><mi id="S3.SS1.p9.1.m1.1.1" xref="S3.SS1.p9.1.m1.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p9.1.m1.1b"><ci id="S3.SS1.p9.1.m1.1.1.cmml" xref="S3.SS1.p9.1.m1.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p9.1.m1.1c">m</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p9.1.m1.1d">italic_m</annotation></semantics></math> times to create <math alttext="m" class="ltx_Math" display="inline" id="S3.SS1.p9.2.m2.1"><semantics id="S3.SS1.p9.2.m2.1a"><mi id="S3.SS1.p9.2.m2.1.1" xref="S3.SS1.p9.2.m2.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p9.2.m2.1b"><ci id="S3.SS1.p9.2.m2.1.1.cmml" xref="S3.SS1.p9.2.m2.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p9.2.m2.1c">m</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p9.2.m2.1d">italic_m</annotation></semantics></math> training samples. Each sample is tailored to a specific reconstruction or generation task <math alttext="t_{i}" class="ltx_Math" display="inline" id="S3.SS1.p9.3.m3.1"><semantics id="S3.SS1.p9.3.m3.1a"><msub id="S3.SS1.p9.3.m3.1.1" xref="S3.SS1.p9.3.m3.1.1.cmml"><mi id="S3.SS1.p9.3.m3.1.1.2" xref="S3.SS1.p9.3.m3.1.1.2.cmml">t</mi><mi id="S3.SS1.p9.3.m3.1.1.3" xref="S3.SS1.p9.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p9.3.m3.1b"><apply id="S3.SS1.p9.3.m3.1.1.cmml" xref="S3.SS1.p9.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p9.3.m3.1.1.1.cmml" xref="S3.SS1.p9.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.p9.3.m3.1.1.2.cmml" xref="S3.SS1.p9.3.m3.1.1.2">𝑡</ci><ci id="S3.SS1.p9.3.m3.1.1.3.cmml" xref="S3.SS1.p9.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p9.3.m3.1c">t_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p9.3.m3.1d">italic_t start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>.</p>
</div>
<div class="ltx_para" id="S3.SS1.p10">
<p class="ltx_p" id="S3.SS1.p10.1">We will employ low-rank adaptation (LoRA) <cite class="ltx_cite ltx_citemacro_citep">(Hu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib9" title="">2021</a>)</cite>, a parameter-efficient fine-tuning approach, to train the language model. Additionally, we will freeze the pretrained word embeddings while tuning the dense token embeddings and task embeddings.</p>
</div>
<div class="ltx_para" id="S3.SS1.p11">
<p class="ltx_p" id="S3.SS1.p11.5">To perform the filling operation on the placeholder block, we will conduct <span class="ltx_text ltx_font_italic" id="S3.SS1.p11.5.1">dual forward propagation</span>: first to capture the output from the token block to fill the placeholder, and then to tune the language model with the next token prediction task:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E5">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_left">(5)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\hat{a}_{i,j+1}=\text{argmax}_{w\in\mathbf{W}}P(w|a_{i,1},a_{i,2},\dots,a_{i,j%
})," class="ltx_Math" display="block" id="S3.E5.m1.10"><semantics id="S3.E5.m1.10a"><mrow id="S3.E5.m1.10.10.1" xref="S3.E5.m1.10.10.1.1.cmml"><mrow id="S3.E5.m1.10.10.1.1" xref="S3.E5.m1.10.10.1.1.cmml"><msub id="S3.E5.m1.10.10.1.1.3" xref="S3.E5.m1.10.10.1.1.3.cmml"><mover accent="true" id="S3.E5.m1.10.10.1.1.3.2" xref="S3.E5.m1.10.10.1.1.3.2.cmml"><mi id="S3.E5.m1.10.10.1.1.3.2.2" xref="S3.E5.m1.10.10.1.1.3.2.2.cmml">a</mi><mo id="S3.E5.m1.10.10.1.1.3.2.1" xref="S3.E5.m1.10.10.1.1.3.2.1.cmml">^</mo></mover><mrow id="S3.E5.m1.2.2.2.2" xref="S3.E5.m1.2.2.2.3.cmml"><mi id="S3.E5.m1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.cmml">i</mi><mo id="S3.E5.m1.2.2.2.2.2" xref="S3.E5.m1.2.2.2.3.cmml">,</mo><mrow id="S3.E5.m1.2.2.2.2.1" xref="S3.E5.m1.2.2.2.2.1.cmml"><mi id="S3.E5.m1.2.2.2.2.1.2" xref="S3.E5.m1.2.2.2.2.1.2.cmml">j</mi><mo id="S3.E5.m1.2.2.2.2.1.1" xref="S3.E5.m1.2.2.2.2.1.1.cmml">+</mo><mn id="S3.E5.m1.2.2.2.2.1.3" xref="S3.E5.m1.2.2.2.2.1.3.cmml">1</mn></mrow></mrow></msub><mo id="S3.E5.m1.10.10.1.1.2" xref="S3.E5.m1.10.10.1.1.2.cmml">=</mo><mrow id="S3.E5.m1.10.10.1.1.1" xref="S3.E5.m1.10.10.1.1.1.cmml"><msub id="S3.E5.m1.10.10.1.1.1.3" xref="S3.E5.m1.10.10.1.1.1.3.cmml"><mtext id="S3.E5.m1.10.10.1.1.1.3.2" xref="S3.E5.m1.10.10.1.1.1.3.2a.cmml">argmax</mtext><mrow id="S3.E5.m1.10.10.1.1.1.3.3" xref="S3.E5.m1.10.10.1.1.1.3.3.cmml"><mi id="S3.E5.m1.10.10.1.1.1.3.3.2" xref="S3.E5.m1.10.10.1.1.1.3.3.2.cmml">w</mi><mo id="S3.E5.m1.10.10.1.1.1.3.3.1" xref="S3.E5.m1.10.10.1.1.1.3.3.1.cmml">∈</mo><mi id="S3.E5.m1.10.10.1.1.1.3.3.3" xref="S3.E5.m1.10.10.1.1.1.3.3.3.cmml">𝐖</mi></mrow></msub><mo id="S3.E5.m1.10.10.1.1.1.2" xref="S3.E5.m1.10.10.1.1.1.2.cmml">⁢</mo><mi id="S3.E5.m1.10.10.1.1.1.4" xref="S3.E5.m1.10.10.1.1.1.4.cmml">P</mi><mo id="S3.E5.m1.10.10.1.1.1.2a" xref="S3.E5.m1.10.10.1.1.1.2.cmml">⁢</mo><mrow id="S3.E5.m1.10.10.1.1.1.1.1" xref="S3.E5.m1.10.10.1.1.1.1.1.1.cmml"><mo id="S3.E5.m1.10.10.1.1.1.1.1.2" stretchy="false" xref="S3.E5.m1.10.10.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E5.m1.10.10.1.1.1.1.1.1" xref="S3.E5.m1.10.10.1.1.1.1.1.1.cmml"><mi id="S3.E5.m1.10.10.1.1.1.1.1.1.5" xref="S3.E5.m1.10.10.1.1.1.1.1.1.5.cmml">w</mi><mo fence="false" id="S3.E5.m1.10.10.1.1.1.1.1.1.4" xref="S3.E5.m1.10.10.1.1.1.1.1.1.4.cmml">|</mo><mrow id="S3.E5.m1.10.10.1.1.1.1.1.1.3.3" xref="S3.E5.m1.10.10.1.1.1.1.1.1.3.4.cmml"><msub id="S3.E5.m1.10.10.1.1.1.1.1.1.1.1.1" xref="S3.E5.m1.10.10.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E5.m1.10.10.1.1.1.1.1.1.1.1.1.2" xref="S3.E5.m1.10.10.1.1.1.1.1.1.1.1.1.2.cmml">a</mi><mrow id="S3.E5.m1.4.4.2.4" xref="S3.E5.m1.4.4.2.3.cmml"><mi id="S3.E5.m1.3.3.1.1" xref="S3.E5.m1.3.3.1.1.cmml">i</mi><mo id="S3.E5.m1.4.4.2.4.1" xref="S3.E5.m1.4.4.2.3.cmml">,</mo><mn id="S3.E5.m1.4.4.2.2" xref="S3.E5.m1.4.4.2.2.cmml">1</mn></mrow></msub><mo id="S3.E5.m1.10.10.1.1.1.1.1.1.3.3.4" xref="S3.E5.m1.10.10.1.1.1.1.1.1.3.4.cmml">,</mo><msub id="S3.E5.m1.10.10.1.1.1.1.1.1.2.2.2" xref="S3.E5.m1.10.10.1.1.1.1.1.1.2.2.2.cmml"><mi id="S3.E5.m1.10.10.1.1.1.1.1.1.2.2.2.2" xref="S3.E5.m1.10.10.1.1.1.1.1.1.2.2.2.2.cmml">a</mi><mrow id="S3.E5.m1.6.6.2.4" xref="S3.E5.m1.6.6.2.3.cmml"><mi id="S3.E5.m1.5.5.1.1" xref="S3.E5.m1.5.5.1.1.cmml">i</mi><mo id="S3.E5.m1.6.6.2.4.1" xref="S3.E5.m1.6.6.2.3.cmml">,</mo><mn id="S3.E5.m1.6.6.2.2" xref="S3.E5.m1.6.6.2.2.cmml">2</mn></mrow></msub><mo id="S3.E5.m1.10.10.1.1.1.1.1.1.3.3.5" xref="S3.E5.m1.10.10.1.1.1.1.1.1.3.4.cmml">,</mo><mi id="S3.E5.m1.9.9" mathvariant="normal" xref="S3.E5.m1.9.9.cmml">…</mi><mo id="S3.E5.m1.10.10.1.1.1.1.1.1.3.3.6" xref="S3.E5.m1.10.10.1.1.1.1.1.1.3.4.cmml">,</mo><msub id="S3.E5.m1.10.10.1.1.1.1.1.1.3.3.3" xref="S3.E5.m1.10.10.1.1.1.1.1.1.3.3.3.cmml"><mi id="S3.E5.m1.10.10.1.1.1.1.1.1.3.3.3.2" xref="S3.E5.m1.10.10.1.1.1.1.1.1.3.3.3.2.cmml">a</mi><mrow id="S3.E5.m1.8.8.2.4" xref="S3.E5.m1.8.8.2.3.cmml"><mi id="S3.E5.m1.7.7.1.1" xref="S3.E5.m1.7.7.1.1.cmml">i</mi><mo id="S3.E5.m1.8.8.2.4.1" xref="S3.E5.m1.8.8.2.3.cmml">,</mo><mi id="S3.E5.m1.8.8.2.2" xref="S3.E5.m1.8.8.2.2.cmml">j</mi></mrow></msub></mrow></mrow><mo id="S3.E5.m1.10.10.1.1.1.1.1.3" stretchy="false" xref="S3.E5.m1.10.10.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E5.m1.10.10.1.2" xref="S3.E5.m1.10.10.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E5.m1.10b"><apply id="S3.E5.m1.10.10.1.1.cmml" xref="S3.E5.m1.10.10.1"><eq id="S3.E5.m1.10.10.1.1.2.cmml" xref="S3.E5.m1.10.10.1.1.2"></eq><apply id="S3.E5.m1.10.10.1.1.3.cmml" xref="S3.E5.m1.10.10.1.1.3"><csymbol cd="ambiguous" id="S3.E5.m1.10.10.1.1.3.1.cmml" xref="S3.E5.m1.10.10.1.1.3">subscript</csymbol><apply id="S3.E5.m1.10.10.1.1.3.2.cmml" xref="S3.E5.m1.10.10.1.1.3.2"><ci id="S3.E5.m1.10.10.1.1.3.2.1.cmml" xref="S3.E5.m1.10.10.1.1.3.2.1">^</ci><ci id="S3.E5.m1.10.10.1.1.3.2.2.cmml" xref="S3.E5.m1.10.10.1.1.3.2.2">𝑎</ci></apply><list id="S3.E5.m1.2.2.2.3.cmml" xref="S3.E5.m1.2.2.2.2"><ci id="S3.E5.m1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1">𝑖</ci><apply id="S3.E5.m1.2.2.2.2.1.cmml" xref="S3.E5.m1.2.2.2.2.1"><plus id="S3.E5.m1.2.2.2.2.1.1.cmml" xref="S3.E5.m1.2.2.2.2.1.1"></plus><ci id="S3.E5.m1.2.2.2.2.1.2.cmml" xref="S3.E5.m1.2.2.2.2.1.2">𝑗</ci><cn id="S3.E5.m1.2.2.2.2.1.3.cmml" type="integer" xref="S3.E5.m1.2.2.2.2.1.3">1</cn></apply></list></apply><apply id="S3.E5.m1.10.10.1.1.1.cmml" xref="S3.E5.m1.10.10.1.1.1"><times id="S3.E5.m1.10.10.1.1.1.2.cmml" xref="S3.E5.m1.10.10.1.1.1.2"></times><apply id="S3.E5.m1.10.10.1.1.1.3.cmml" xref="S3.E5.m1.10.10.1.1.1.3"><csymbol cd="ambiguous" id="S3.E5.m1.10.10.1.1.1.3.1.cmml" xref="S3.E5.m1.10.10.1.1.1.3">subscript</csymbol><ci id="S3.E5.m1.10.10.1.1.1.3.2a.cmml" xref="S3.E5.m1.10.10.1.1.1.3.2"><mtext id="S3.E5.m1.10.10.1.1.1.3.2.cmml" xref="S3.E5.m1.10.10.1.1.1.3.2">argmax</mtext></ci><apply id="S3.E5.m1.10.10.1.1.1.3.3.cmml" xref="S3.E5.m1.10.10.1.1.1.3.3"><in id="S3.E5.m1.10.10.1.1.1.3.3.1.cmml" xref="S3.E5.m1.10.10.1.1.1.3.3.1"></in><ci id="S3.E5.m1.10.10.1.1.1.3.3.2.cmml" xref="S3.E5.m1.10.10.1.1.1.3.3.2">𝑤</ci><ci id="S3.E5.m1.10.10.1.1.1.3.3.3.cmml" xref="S3.E5.m1.10.10.1.1.1.3.3.3">𝐖</ci></apply></apply><ci id="S3.E5.m1.10.10.1.1.1.4.cmml" xref="S3.E5.m1.10.10.1.1.1.4">𝑃</ci><apply id="S3.E5.m1.10.10.1.1.1.1.1.1.cmml" xref="S3.E5.m1.10.10.1.1.1.1.1"><csymbol cd="latexml" id="S3.E5.m1.10.10.1.1.1.1.1.1.4.cmml" xref="S3.E5.m1.10.10.1.1.1.1.1.1.4">conditional</csymbol><ci id="S3.E5.m1.10.10.1.1.1.1.1.1.5.cmml" xref="S3.E5.m1.10.10.1.1.1.1.1.1.5">𝑤</ci><list id="S3.E5.m1.10.10.1.1.1.1.1.1.3.4.cmml" xref="S3.E5.m1.10.10.1.1.1.1.1.1.3.3"><apply id="S3.E5.m1.10.10.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.10.10.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E5.m1.10.10.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.10.10.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E5.m1.10.10.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E5.m1.10.10.1.1.1.1.1.1.1.1.1.2">𝑎</ci><list id="S3.E5.m1.4.4.2.3.cmml" xref="S3.E5.m1.4.4.2.4"><ci id="S3.E5.m1.3.3.1.1.cmml" xref="S3.E5.m1.3.3.1.1">𝑖</ci><cn id="S3.E5.m1.4.4.2.2.cmml" type="integer" xref="S3.E5.m1.4.4.2.2">1</cn></list></apply><apply id="S3.E5.m1.10.10.1.1.1.1.1.1.2.2.2.cmml" xref="S3.E5.m1.10.10.1.1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.E5.m1.10.10.1.1.1.1.1.1.2.2.2.1.cmml" xref="S3.E5.m1.10.10.1.1.1.1.1.1.2.2.2">subscript</csymbol><ci id="S3.E5.m1.10.10.1.1.1.1.1.1.2.2.2.2.cmml" xref="S3.E5.m1.10.10.1.1.1.1.1.1.2.2.2.2">𝑎</ci><list id="S3.E5.m1.6.6.2.3.cmml" xref="S3.E5.m1.6.6.2.4"><ci id="S3.E5.m1.5.5.1.1.cmml" xref="S3.E5.m1.5.5.1.1">𝑖</ci><cn id="S3.E5.m1.6.6.2.2.cmml" type="integer" xref="S3.E5.m1.6.6.2.2">2</cn></list></apply><ci id="S3.E5.m1.9.9.cmml" xref="S3.E5.m1.9.9">…</ci><apply id="S3.E5.m1.10.10.1.1.1.1.1.1.3.3.3.cmml" xref="S3.E5.m1.10.10.1.1.1.1.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.E5.m1.10.10.1.1.1.1.1.1.3.3.3.1.cmml" xref="S3.E5.m1.10.10.1.1.1.1.1.1.3.3.3">subscript</csymbol><ci id="S3.E5.m1.10.10.1.1.1.1.1.1.3.3.3.2.cmml" xref="S3.E5.m1.10.10.1.1.1.1.1.1.3.3.3.2">𝑎</ci><list id="S3.E5.m1.8.8.2.3.cmml" xref="S3.E5.m1.8.8.2.4"><ci id="S3.E5.m1.7.7.1.1.cmml" xref="S3.E5.m1.7.7.1.1">𝑖</ci><ci id="S3.E5.m1.8.8.2.2.cmml" xref="S3.E5.m1.8.8.2.2">𝑗</ci></list></apply></list></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E5.m1.10c">\hat{a}_{i,j+1}=\text{argmax}_{w\in\mathbf{W}}P(w|a_{i,1},a_{i,2},\dots,a_{i,j%
}),</annotation><annotation encoding="application/x-llamapun" id="S3.E5.m1.10d">over^ start_ARG italic_a end_ARG start_POSTSUBSCRIPT italic_i , italic_j + 1 end_POSTSUBSCRIPT = argmax start_POSTSUBSCRIPT italic_w ∈ bold_W end_POSTSUBSCRIPT italic_P ( italic_w | italic_a start_POSTSUBSCRIPT italic_i , 1 end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_i , 2 end_POSTSUBSCRIPT , … , italic_a start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS1.p11.4">optimized using cross-entropy loss, where <math alttext="\mathbf{W}" class="ltx_Math" display="inline" id="S3.SS1.p11.1.m1.1"><semantics id="S3.SS1.p11.1.m1.1a"><mi id="S3.SS1.p11.1.m1.1.1" xref="S3.SS1.p11.1.m1.1.1.cmml">𝐖</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p11.1.m1.1b"><ci id="S3.SS1.p11.1.m1.1.1.cmml" xref="S3.SS1.p11.1.m1.1.1">𝐖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p11.1.m1.1c">\mathbf{W}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p11.1.m1.1d">bold_W</annotation></semantics></math> denotes the token vocabulary and <math alttext="a_{i,j}" class="ltx_Math" display="inline" id="S3.SS1.p11.2.m2.2"><semantics id="S3.SS1.p11.2.m2.2a"><msub id="S3.SS1.p11.2.m2.2.3" xref="S3.SS1.p11.2.m2.2.3.cmml"><mi id="S3.SS1.p11.2.m2.2.3.2" xref="S3.SS1.p11.2.m2.2.3.2.cmml">a</mi><mrow id="S3.SS1.p11.2.m2.2.2.2.4" xref="S3.SS1.p11.2.m2.2.2.2.3.cmml"><mi id="S3.SS1.p11.2.m2.1.1.1.1" xref="S3.SS1.p11.2.m2.1.1.1.1.cmml">i</mi><mo id="S3.SS1.p11.2.m2.2.2.2.4.1" xref="S3.SS1.p11.2.m2.2.2.2.3.cmml">,</mo><mi id="S3.SS1.p11.2.m2.2.2.2.2" xref="S3.SS1.p11.2.m2.2.2.2.2.cmml">j</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p11.2.m2.2b"><apply id="S3.SS1.p11.2.m2.2.3.cmml" xref="S3.SS1.p11.2.m2.2.3"><csymbol cd="ambiguous" id="S3.SS1.p11.2.m2.2.3.1.cmml" xref="S3.SS1.p11.2.m2.2.3">subscript</csymbol><ci id="S3.SS1.p11.2.m2.2.3.2.cmml" xref="S3.SS1.p11.2.m2.2.3.2">𝑎</ci><list id="S3.SS1.p11.2.m2.2.2.2.3.cmml" xref="S3.SS1.p11.2.m2.2.2.2.4"><ci id="S3.SS1.p11.2.m2.1.1.1.1.cmml" xref="S3.SS1.p11.2.m2.1.1.1.1">𝑖</ci><ci id="S3.SS1.p11.2.m2.2.2.2.2.cmml" xref="S3.SS1.p11.2.m2.2.2.2.2">𝑗</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p11.2.m2.2c">a_{i,j}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p11.2.m2.2d">italic_a start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT</annotation></semantics></math> denotes the <math alttext="j" class="ltx_Math" display="inline" id="S3.SS1.p11.3.m3.1"><semantics id="S3.SS1.p11.3.m3.1a"><mi id="S3.SS1.p11.3.m3.1.1" xref="S3.SS1.p11.3.m3.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p11.3.m3.1b"><ci id="S3.SS1.p11.3.m3.1.1.cmml" xref="S3.SS1.p11.3.m3.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p11.3.m3.1c">j</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p11.3.m3.1d">italic_j</annotation></semantics></math>-th token of the attribute <math alttext="\mathbf{a}_{i}" class="ltx_Math" display="inline" id="S3.SS1.p11.4.m4.1"><semantics id="S3.SS1.p11.4.m4.1a"><msub id="S3.SS1.p11.4.m4.1.1" xref="S3.SS1.p11.4.m4.1.1.cmml"><mi id="S3.SS1.p11.4.m4.1.1.2" xref="S3.SS1.p11.4.m4.1.1.2.cmml">𝐚</mi><mi id="S3.SS1.p11.4.m4.1.1.3" xref="S3.SS1.p11.4.m4.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p11.4.m4.1b"><apply id="S3.SS1.p11.4.m4.1.1.cmml" xref="S3.SS1.p11.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p11.4.m4.1.1.1.cmml" xref="S3.SS1.p11.4.m4.1.1">subscript</csymbol><ci id="S3.SS1.p11.4.m4.1.1.2.cmml" xref="S3.SS1.p11.4.m4.1.1.2">𝐚</ci><ci id="S3.SS1.p11.4.m4.1.1.3.cmml" xref="S3.SS1.p11.4.m4.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p11.4.m4.1c">\mathbf{a}_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p11.4.m4.1d">bold_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>.</p>
</div>
<div class="ltx_para" id="S3.SS1.p12">
<p class="ltx_p" id="S3.SS1.p12.1">Notably, our approach differs the gisting framework in several ways: i) our compression targets item content in recommendation scenarios; ii) we introduce a placeholder block adjacent to the token block to ensure the task block is guided by the output of the token block; iii) we design both reconstruction and generation tasks based on the dense tokens.</p>
</div>
<figure class="ltx_figure" id="S3.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="359" id="S3.F6.g1" src="x6.png" width="664"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6. </span>Code tree used in conditional beam search.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2. </span>Simple Clusterer</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.6">Unlike standard pipeline that employ complex, hard-to-train differentiable vector quantization techniques to segment item content embeddings into discrete tokens, our dense tokenizer efficiently maps item content features into reconstructable embeddings–termed dense tokens–that encapsulate domain-specific content. Hence, these dense vectors can be discretized into cluster indices using a training-free clustering approach. We first aggregate the output of the dense tokens for all items as follows:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E6">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_left">(6)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathbf{E}=\begin{bmatrix}\mathbf{{\color[rgb]{0.5859375,0.44140625,0.21484375%
}\definecolor[named]{pgfstrokecolor}{rgb}{0.5859375,0.44140625,0.21484375}e}}_%
{1,1}&amp;\mathbf{{\color[rgb]{0.5859375,0.44140625,0.21484375}\definecolor[named]%
{pgfstrokecolor}{rgb}{0.5859375,0.44140625,0.21484375}e}}_{1,2}&amp;\cdots&amp;\mathbf%
{{\color[rgb]{0.5859375,0.44140625,0.21484375}\definecolor[named]{%
pgfstrokecolor}{rgb}{0.5859375,0.44140625,0.21484375}e}}_{1,n}\\
\mathbf{{\color[rgb]{0.1796875,0.36328125,0.52734375}\definecolor[named]{%
pgfstrokecolor}{rgb}{0.1796875,0.36328125,0.52734375}e}}_{2,1}&amp;\mathbf{{\color%
[rgb]{0.1796875,0.36328125,0.52734375}\definecolor[named]{pgfstrokecolor}{rgb}%
{0.1796875,0.36328125,0.52734375}e}}_{2,2}&amp;\cdots&amp;\mathbf{{\color[rgb]{%
0.5859375,0.44140625,0.21484375}\definecolor[named]{pgfstrokecolor}{rgb}{%
0.5859375,0.44140625,0.21484375}e}}_{2,n}\\
\vdots&amp;\vdots&amp;\ddots&amp;\vdots\\
\mathbf{e}_{v,1}&amp;\mathbf{e}_{v,2}&amp;\cdots&amp;\mathbf{e}_{v,n}\end{bmatrix}," class="ltx_Math" display="block" id="S3.E6.m1.2"><semantics id="S3.E6.m1.2a"><mrow id="S3.E6.m1.2.2.1" xref="S3.E6.m1.2.2.1.1.cmml"><mrow id="S3.E6.m1.2.2.1.1" xref="S3.E6.m1.2.2.1.1.cmml"><mi id="S3.E6.m1.2.2.1.1.2" xref="S3.E6.m1.2.2.1.1.2.cmml">𝐄</mi><mo id="S3.E6.m1.2.2.1.1.1" xref="S3.E6.m1.2.2.1.1.1.cmml">=</mo><mrow id="S3.E6.m1.1.1.3" xref="S3.E6.m1.1.1.2.cmml"><mo id="S3.E6.m1.1.1.3.1" xref="S3.E6.m1.1.1.2.1.cmml">[</mo><mtable columnspacing="5pt" displaystyle="true" id="S3.E6.m1.1.1.1.1" rowspacing="0pt" xref="S3.E6.m1.1.1.1.1.cmml"><mtr id="S3.E6.m1.1.1.1.1a" xref="S3.E6.m1.1.1.1.1.cmml"><mtd id="S3.E6.m1.1.1.1.1b" xref="S3.E6.m1.1.1.1.1.cmml"><msub id="S3.E6.m1.1.1.1.1.2.2.2.2" xref="S3.E6.m1.1.1.1.1.2.2.2.2.cmml"><mi id="S3.E6.m1.1.1.1.1.2.2.2.2.4" mathcolor="#957137" xref="S3.E6.m1.1.1.1.1.2.2.2.2.4.cmml">𝐞</mi><mrow id="S3.E6.m1.1.1.1.1.2.2.2.2.2.2.4" xref="S3.E6.m1.1.1.1.1.2.2.2.2.2.2.3.cmml"><mn id="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.1.cmml">1</mn><mo id="S3.E6.m1.1.1.1.1.2.2.2.2.2.2.4.1" xref="S3.E6.m1.1.1.1.1.2.2.2.2.2.2.3.cmml">,</mo><mn id="S3.E6.m1.1.1.1.1.2.2.2.2.2.2.2" xref="S3.E6.m1.1.1.1.1.2.2.2.2.2.2.2.cmml">1</mn></mrow></msub></mtd><mtd id="S3.E6.m1.1.1.1.1c" xref="S3.E6.m1.1.1.1.1.cmml"><msub id="S3.E6.m1.1.1.1.1.4.4.4.2" xref="S3.E6.m1.1.1.1.1.4.4.4.2.cmml"><mi id="S3.E6.m1.1.1.1.1.4.4.4.2.4" mathcolor="#957137" xref="S3.E6.m1.1.1.1.1.4.4.4.2.4.cmml">𝐞</mi><mrow id="S3.E6.m1.1.1.1.1.4.4.4.2.2.2.4" xref="S3.E6.m1.1.1.1.1.4.4.4.2.2.2.3.cmml"><mn id="S3.E6.m1.1.1.1.1.3.3.3.1.1.1.1" xref="S3.E6.m1.1.1.1.1.3.3.3.1.1.1.1.cmml">1</mn><mo id="S3.E6.m1.1.1.1.1.4.4.4.2.2.2.4.1" xref="S3.E6.m1.1.1.1.1.4.4.4.2.2.2.3.cmml">,</mo><mn id="S3.E6.m1.1.1.1.1.4.4.4.2.2.2.2" xref="S3.E6.m1.1.1.1.1.4.4.4.2.2.2.2.cmml">2</mn></mrow></msub></mtd><mtd id="S3.E6.m1.1.1.1.1d" xref="S3.E6.m1.1.1.1.1.cmml"><mi id="S3.E6.m1.1.1.1.1.6.6.7.1" mathvariant="normal" xref="S3.E6.m1.1.1.1.1.6.6.7.1.cmml">⋯</mi></mtd><mtd id="S3.E6.m1.1.1.1.1e" xref="S3.E6.m1.1.1.1.1.cmml"><msub id="S3.E6.m1.1.1.1.1.6.6.6.2" xref="S3.E6.m1.1.1.1.1.6.6.6.2.cmml"><mi id="S3.E6.m1.1.1.1.1.6.6.6.2.4" mathcolor="#957137" xref="S3.E6.m1.1.1.1.1.6.6.6.2.4.cmml">𝐞</mi><mrow id="S3.E6.m1.1.1.1.1.6.6.6.2.2.2.4" xref="S3.E6.m1.1.1.1.1.6.6.6.2.2.2.3.cmml"><mn id="S3.E6.m1.1.1.1.1.5.5.5.1.1.1.1" xref="S3.E6.m1.1.1.1.1.5.5.5.1.1.1.1.cmml">1</mn><mo id="S3.E6.m1.1.1.1.1.6.6.6.2.2.2.4.1" xref="S3.E6.m1.1.1.1.1.6.6.6.2.2.2.3.cmml">,</mo><mi id="S3.E6.m1.1.1.1.1.6.6.6.2.2.2.2" xref="S3.E6.m1.1.1.1.1.6.6.6.2.2.2.2.cmml">n</mi></mrow></msub></mtd></mtr><mtr id="S3.E6.m1.1.1.1.1f" xref="S3.E6.m1.1.1.1.1.cmml"><mtd id="S3.E6.m1.1.1.1.1g" xref="S3.E6.m1.1.1.1.1.cmml"><msub id="S3.E6.m1.1.1.1.1.8.8.2.2" xref="S3.E6.m1.1.1.1.1.8.8.2.2.cmml"><mi id="S3.E6.m1.1.1.1.1.8.8.2.2.4" mathcolor="#2E5D86" xref="S3.E6.m1.1.1.1.1.8.8.2.2.4.cmml">𝐞</mi><mrow id="S3.E6.m1.1.1.1.1.8.8.2.2.2.2.4" xref="S3.E6.m1.1.1.1.1.8.8.2.2.2.2.3.cmml"><mn id="S3.E6.m1.1.1.1.1.7.7.1.1.1.1.1" xref="S3.E6.m1.1.1.1.1.7.7.1.1.1.1.1.cmml">2</mn><mo id="S3.E6.m1.1.1.1.1.8.8.2.2.2.2.4.1" xref="S3.E6.m1.1.1.1.1.8.8.2.2.2.2.3.cmml">,</mo><mn id="S3.E6.m1.1.1.1.1.8.8.2.2.2.2.2" xref="S3.E6.m1.1.1.1.1.8.8.2.2.2.2.2.cmml">1</mn></mrow></msub></mtd><mtd id="S3.E6.m1.1.1.1.1h" xref="S3.E6.m1.1.1.1.1.cmml"><msub id="S3.E6.m1.1.1.1.1.10.10.4.2" xref="S3.E6.m1.1.1.1.1.10.10.4.2.cmml"><mi id="S3.E6.m1.1.1.1.1.10.10.4.2.4" mathcolor="#2E5D86" xref="S3.E6.m1.1.1.1.1.10.10.4.2.4.cmml">𝐞</mi><mrow id="S3.E6.m1.1.1.1.1.10.10.4.2.2.2.4" xref="S3.E6.m1.1.1.1.1.10.10.4.2.2.2.3.cmml"><mn id="S3.E6.m1.1.1.1.1.9.9.3.1.1.1.1" xref="S3.E6.m1.1.1.1.1.9.9.3.1.1.1.1.cmml">2</mn><mo id="S3.E6.m1.1.1.1.1.10.10.4.2.2.2.4.1" xref="S3.E6.m1.1.1.1.1.10.10.4.2.2.2.3.cmml">,</mo><mn id="S3.E6.m1.1.1.1.1.10.10.4.2.2.2.2" xref="S3.E6.m1.1.1.1.1.10.10.4.2.2.2.2.cmml">2</mn></mrow></msub></mtd><mtd id="S3.E6.m1.1.1.1.1i" xref="S3.E6.m1.1.1.1.1.cmml"><mi id="S3.E6.m1.1.1.1.1.12.12.7.1" mathvariant="normal" xref="S3.E6.m1.1.1.1.1.12.12.7.1.cmml">⋯</mi></mtd><mtd id="S3.E6.m1.1.1.1.1j" xref="S3.E6.m1.1.1.1.1.cmml"><msub id="S3.E6.m1.1.1.1.1.12.12.6.2" xref="S3.E6.m1.1.1.1.1.12.12.6.2.cmml"><mi id="S3.E6.m1.1.1.1.1.12.12.6.2.4" mathcolor="#957137" xref="S3.E6.m1.1.1.1.1.12.12.6.2.4.cmml">𝐞</mi><mrow id="S3.E6.m1.1.1.1.1.12.12.6.2.2.2.4" xref="S3.E6.m1.1.1.1.1.12.12.6.2.2.2.3.cmml"><mn id="S3.E6.m1.1.1.1.1.11.11.5.1.1.1.1" xref="S3.E6.m1.1.1.1.1.11.11.5.1.1.1.1.cmml">2</mn><mo id="S3.E6.m1.1.1.1.1.12.12.6.2.2.2.4.1" xref="S3.E6.m1.1.1.1.1.12.12.6.2.2.2.3.cmml">,</mo><mi id="S3.E6.m1.1.1.1.1.12.12.6.2.2.2.2" xref="S3.E6.m1.1.1.1.1.12.12.6.2.2.2.2.cmml">n</mi></mrow></msub></mtd></mtr><mtr id="S3.E6.m1.1.1.1.1k" xref="S3.E6.m1.1.1.1.1.cmml"><mtd id="S3.E6.m1.1.1.1.1l" xref="S3.E6.m1.1.1.1.1.cmml"><mi id="S3.E6.m1.1.1.1.1.19.1.1" mathvariant="normal" xref="S3.E6.m1.1.1.1.1.19.1.1.cmml">⋮</mi></mtd><mtd id="S3.E6.m1.1.1.1.1m" xref="S3.E6.m1.1.1.1.1.cmml"><mi id="S3.E6.m1.1.1.1.1.19.2.1" mathvariant="normal" xref="S3.E6.m1.1.1.1.1.19.2.1.cmml">⋮</mi></mtd><mtd id="S3.E6.m1.1.1.1.1n" xref="S3.E6.m1.1.1.1.1.cmml"><mi id="S3.E6.m1.1.1.1.1.19.3.1" mathvariant="normal" xref="S3.E6.m1.1.1.1.1.19.3.1.cmml">⋱</mi></mtd><mtd id="S3.E6.m1.1.1.1.1o" xref="S3.E6.m1.1.1.1.1.cmml"><mi id="S3.E6.m1.1.1.1.1.19.4.1" mathvariant="normal" xref="S3.E6.m1.1.1.1.1.19.4.1.cmml">⋮</mi></mtd></mtr><mtr id="S3.E6.m1.1.1.1.1p" xref="S3.E6.m1.1.1.1.1.cmml"><mtd id="S3.E6.m1.1.1.1.1q" xref="S3.E6.m1.1.1.1.1.cmml"><msub id="S3.E6.m1.1.1.1.1.14.14.2.2" xref="S3.E6.m1.1.1.1.1.14.14.2.2.cmml"><mi id="S3.E6.m1.1.1.1.1.14.14.2.2.4" xref="S3.E6.m1.1.1.1.1.14.14.2.2.4.cmml">𝐞</mi><mrow id="S3.E6.m1.1.1.1.1.14.14.2.2.2.2.4" xref="S3.E6.m1.1.1.1.1.14.14.2.2.2.2.3.cmml"><mi id="S3.E6.m1.1.1.1.1.13.13.1.1.1.1.1" xref="S3.E6.m1.1.1.1.1.13.13.1.1.1.1.1.cmml">v</mi><mo id="S3.E6.m1.1.1.1.1.14.14.2.2.2.2.4.1" xref="S3.E6.m1.1.1.1.1.14.14.2.2.2.2.3.cmml">,</mo><mn id="S3.E6.m1.1.1.1.1.14.14.2.2.2.2.2" xref="S3.E6.m1.1.1.1.1.14.14.2.2.2.2.2.cmml">1</mn></mrow></msub></mtd><mtd id="S3.E6.m1.1.1.1.1r" xref="S3.E6.m1.1.1.1.1.cmml"><msub id="S3.E6.m1.1.1.1.1.16.16.4.2" xref="S3.E6.m1.1.1.1.1.16.16.4.2.cmml"><mi id="S3.E6.m1.1.1.1.1.16.16.4.2.4" xref="S3.E6.m1.1.1.1.1.16.16.4.2.4.cmml">𝐞</mi><mrow id="S3.E6.m1.1.1.1.1.16.16.4.2.2.2.4" xref="S3.E6.m1.1.1.1.1.16.16.4.2.2.2.3.cmml"><mi id="S3.E6.m1.1.1.1.1.15.15.3.1.1.1.1" xref="S3.E6.m1.1.1.1.1.15.15.3.1.1.1.1.cmml">v</mi><mo id="S3.E6.m1.1.1.1.1.16.16.4.2.2.2.4.1" xref="S3.E6.m1.1.1.1.1.16.16.4.2.2.2.3.cmml">,</mo><mn id="S3.E6.m1.1.1.1.1.16.16.4.2.2.2.2" xref="S3.E6.m1.1.1.1.1.16.16.4.2.2.2.2.cmml">2</mn></mrow></msub></mtd><mtd id="S3.E6.m1.1.1.1.1s" xref="S3.E6.m1.1.1.1.1.cmml"><mi id="S3.E6.m1.1.1.1.1.18.18.7.1" mathvariant="normal" xref="S3.E6.m1.1.1.1.1.18.18.7.1.cmml">⋯</mi></mtd><mtd id="S3.E6.m1.1.1.1.1t" xref="S3.E6.m1.1.1.1.1.cmml"><msub id="S3.E6.m1.1.1.1.1.18.18.6.2" xref="S3.E6.m1.1.1.1.1.18.18.6.2.cmml"><mi id="S3.E6.m1.1.1.1.1.18.18.6.2.4" xref="S3.E6.m1.1.1.1.1.18.18.6.2.4.cmml">𝐞</mi><mrow id="S3.E6.m1.1.1.1.1.18.18.6.2.2.2.4" xref="S3.E6.m1.1.1.1.1.18.18.6.2.2.2.3.cmml"><mi id="S3.E6.m1.1.1.1.1.17.17.5.1.1.1.1" xref="S3.E6.m1.1.1.1.1.17.17.5.1.1.1.1.cmml">v</mi><mo id="S3.E6.m1.1.1.1.1.18.18.6.2.2.2.4.1" xref="S3.E6.m1.1.1.1.1.18.18.6.2.2.2.3.cmml">,</mo><mi id="S3.E6.m1.1.1.1.1.18.18.6.2.2.2.2" xref="S3.E6.m1.1.1.1.1.18.18.6.2.2.2.2.cmml">n</mi></mrow></msub></mtd></mtr></mtable><mo id="S3.E6.m1.1.1.3.2" xref="S3.E6.m1.1.1.2.1.cmml">]</mo></mrow></mrow><mo id="S3.E6.m1.2.2.1.2" xref="S3.E6.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E6.m1.2b"><apply id="S3.E6.m1.2.2.1.1.cmml" xref="S3.E6.m1.2.2.1"><eq id="S3.E6.m1.2.2.1.1.1.cmml" xref="S3.E6.m1.2.2.1.1.1"></eq><ci id="S3.E6.m1.2.2.1.1.2.cmml" xref="S3.E6.m1.2.2.1.1.2">𝐄</ci><apply id="S3.E6.m1.1.1.2.cmml" xref="S3.E6.m1.1.1.3"><csymbol cd="latexml" id="S3.E6.m1.1.1.2.1.cmml" xref="S3.E6.m1.1.1.3.1">matrix</csymbol><matrix id="S3.E6.m1.1.1.1.1.cmml" xref="S3.E6.m1.1.1.1.1"><matrixrow id="S3.E6.m1.1.1.1.1a.cmml" xref="S3.E6.m1.1.1.1.1"><apply id="S3.E6.m1.1.1.1.1.2.2.2.2.cmml" xref="S3.E6.m1.1.1.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.2.2.2.2.3.cmml" xref="S3.E6.m1.1.1.1.1.2.2.2.2">subscript</csymbol><ci id="S3.E6.m1.1.1.1.1.2.2.2.2.4.cmml" xref="S3.E6.m1.1.1.1.1.2.2.2.2.4">𝐞</ci><list id="S3.E6.m1.1.1.1.1.2.2.2.2.2.2.3.cmml" xref="S3.E6.m1.1.1.1.1.2.2.2.2.2.2.4"><cn id="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.1.cmml" type="integer" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.1">1</cn><cn id="S3.E6.m1.1.1.1.1.2.2.2.2.2.2.2.cmml" type="integer" xref="S3.E6.m1.1.1.1.1.2.2.2.2.2.2.2">1</cn></list></apply><apply id="S3.E6.m1.1.1.1.1.4.4.4.2.cmml" xref="S3.E6.m1.1.1.1.1.4.4.4.2"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.4.4.4.2.3.cmml" xref="S3.E6.m1.1.1.1.1.4.4.4.2">subscript</csymbol><ci id="S3.E6.m1.1.1.1.1.4.4.4.2.4.cmml" xref="S3.E6.m1.1.1.1.1.4.4.4.2.4">𝐞</ci><list id="S3.E6.m1.1.1.1.1.4.4.4.2.2.2.3.cmml" xref="S3.E6.m1.1.1.1.1.4.4.4.2.2.2.4"><cn id="S3.E6.m1.1.1.1.1.3.3.3.1.1.1.1.cmml" type="integer" xref="S3.E6.m1.1.1.1.1.3.3.3.1.1.1.1">1</cn><cn id="S3.E6.m1.1.1.1.1.4.4.4.2.2.2.2.cmml" type="integer" xref="S3.E6.m1.1.1.1.1.4.4.4.2.2.2.2">2</cn></list></apply><ci id="S3.E6.m1.1.1.1.1.6.6.7.1.cmml" xref="S3.E6.m1.1.1.1.1.6.6.7.1">⋯</ci><apply id="S3.E6.m1.1.1.1.1.6.6.6.2.cmml" xref="S3.E6.m1.1.1.1.1.6.6.6.2"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.6.6.6.2.3.cmml" xref="S3.E6.m1.1.1.1.1.6.6.6.2">subscript</csymbol><ci id="S3.E6.m1.1.1.1.1.6.6.6.2.4.cmml" xref="S3.E6.m1.1.1.1.1.6.6.6.2.4">𝐞</ci><list id="S3.E6.m1.1.1.1.1.6.6.6.2.2.2.3.cmml" xref="S3.E6.m1.1.1.1.1.6.6.6.2.2.2.4"><cn id="S3.E6.m1.1.1.1.1.5.5.5.1.1.1.1.cmml" type="integer" xref="S3.E6.m1.1.1.1.1.5.5.5.1.1.1.1">1</cn><ci id="S3.E6.m1.1.1.1.1.6.6.6.2.2.2.2.cmml" xref="S3.E6.m1.1.1.1.1.6.6.6.2.2.2.2">𝑛</ci></list></apply></matrixrow><matrixrow id="S3.E6.m1.1.1.1.1b.cmml" xref="S3.E6.m1.1.1.1.1"><apply id="S3.E6.m1.1.1.1.1.8.8.2.2.cmml" xref="S3.E6.m1.1.1.1.1.8.8.2.2"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.8.8.2.2.3.cmml" xref="S3.E6.m1.1.1.1.1.8.8.2.2">subscript</csymbol><ci id="S3.E6.m1.1.1.1.1.8.8.2.2.4.cmml" xref="S3.E6.m1.1.1.1.1.8.8.2.2.4">𝐞</ci><list id="S3.E6.m1.1.1.1.1.8.8.2.2.2.2.3.cmml" xref="S3.E6.m1.1.1.1.1.8.8.2.2.2.2.4"><cn id="S3.E6.m1.1.1.1.1.7.7.1.1.1.1.1.cmml" type="integer" xref="S3.E6.m1.1.1.1.1.7.7.1.1.1.1.1">2</cn><cn id="S3.E6.m1.1.1.1.1.8.8.2.2.2.2.2.cmml" type="integer" xref="S3.E6.m1.1.1.1.1.8.8.2.2.2.2.2">1</cn></list></apply><apply id="S3.E6.m1.1.1.1.1.10.10.4.2.cmml" xref="S3.E6.m1.1.1.1.1.10.10.4.2"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.10.10.4.2.3.cmml" xref="S3.E6.m1.1.1.1.1.10.10.4.2">subscript</csymbol><ci id="S3.E6.m1.1.1.1.1.10.10.4.2.4.cmml" xref="S3.E6.m1.1.1.1.1.10.10.4.2.4">𝐞</ci><list id="S3.E6.m1.1.1.1.1.10.10.4.2.2.2.3.cmml" xref="S3.E6.m1.1.1.1.1.10.10.4.2.2.2.4"><cn id="S3.E6.m1.1.1.1.1.9.9.3.1.1.1.1.cmml" type="integer" xref="S3.E6.m1.1.1.1.1.9.9.3.1.1.1.1">2</cn><cn id="S3.E6.m1.1.1.1.1.10.10.4.2.2.2.2.cmml" type="integer" xref="S3.E6.m1.1.1.1.1.10.10.4.2.2.2.2">2</cn></list></apply><ci id="S3.E6.m1.1.1.1.1.12.12.7.1.cmml" xref="S3.E6.m1.1.1.1.1.12.12.7.1">⋯</ci><apply id="S3.E6.m1.1.1.1.1.12.12.6.2.cmml" xref="S3.E6.m1.1.1.1.1.12.12.6.2"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.12.12.6.2.3.cmml" xref="S3.E6.m1.1.1.1.1.12.12.6.2">subscript</csymbol><ci id="S3.E6.m1.1.1.1.1.12.12.6.2.4.cmml" xref="S3.E6.m1.1.1.1.1.12.12.6.2.4">𝐞</ci><list id="S3.E6.m1.1.1.1.1.12.12.6.2.2.2.3.cmml" xref="S3.E6.m1.1.1.1.1.12.12.6.2.2.2.4"><cn id="S3.E6.m1.1.1.1.1.11.11.5.1.1.1.1.cmml" type="integer" xref="S3.E6.m1.1.1.1.1.11.11.5.1.1.1.1">2</cn><ci id="S3.E6.m1.1.1.1.1.12.12.6.2.2.2.2.cmml" xref="S3.E6.m1.1.1.1.1.12.12.6.2.2.2.2">𝑛</ci></list></apply></matrixrow><matrixrow id="S3.E6.m1.1.1.1.1c.cmml" xref="S3.E6.m1.1.1.1.1"><ci id="S3.E6.m1.1.1.1.1.19.1.1.cmml" xref="S3.E6.m1.1.1.1.1.19.1.1">⋮</ci><ci id="S3.E6.m1.1.1.1.1.19.2.1.cmml" xref="S3.E6.m1.1.1.1.1.19.2.1">⋮</ci><ci id="S3.E6.m1.1.1.1.1.19.3.1.cmml" xref="S3.E6.m1.1.1.1.1.19.3.1">⋱</ci><ci id="S3.E6.m1.1.1.1.1.19.4.1.cmml" xref="S3.E6.m1.1.1.1.1.19.4.1">⋮</ci></matrixrow><matrixrow id="S3.E6.m1.1.1.1.1d.cmml" xref="S3.E6.m1.1.1.1.1"><apply id="S3.E6.m1.1.1.1.1.14.14.2.2.cmml" xref="S3.E6.m1.1.1.1.1.14.14.2.2"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.14.14.2.2.3.cmml" xref="S3.E6.m1.1.1.1.1.14.14.2.2">subscript</csymbol><ci id="S3.E6.m1.1.1.1.1.14.14.2.2.4.cmml" xref="S3.E6.m1.1.1.1.1.14.14.2.2.4">𝐞</ci><list id="S3.E6.m1.1.1.1.1.14.14.2.2.2.2.3.cmml" xref="S3.E6.m1.1.1.1.1.14.14.2.2.2.2.4"><ci id="S3.E6.m1.1.1.1.1.13.13.1.1.1.1.1.cmml" xref="S3.E6.m1.1.1.1.1.13.13.1.1.1.1.1">𝑣</ci><cn id="S3.E6.m1.1.1.1.1.14.14.2.2.2.2.2.cmml" type="integer" xref="S3.E6.m1.1.1.1.1.14.14.2.2.2.2.2">1</cn></list></apply><apply id="S3.E6.m1.1.1.1.1.16.16.4.2.cmml" xref="S3.E6.m1.1.1.1.1.16.16.4.2"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.16.16.4.2.3.cmml" xref="S3.E6.m1.1.1.1.1.16.16.4.2">subscript</csymbol><ci id="S3.E6.m1.1.1.1.1.16.16.4.2.4.cmml" xref="S3.E6.m1.1.1.1.1.16.16.4.2.4">𝐞</ci><list id="S3.E6.m1.1.1.1.1.16.16.4.2.2.2.3.cmml" xref="S3.E6.m1.1.1.1.1.16.16.4.2.2.2.4"><ci id="S3.E6.m1.1.1.1.1.15.15.3.1.1.1.1.cmml" xref="S3.E6.m1.1.1.1.1.15.15.3.1.1.1.1">𝑣</ci><cn id="S3.E6.m1.1.1.1.1.16.16.4.2.2.2.2.cmml" type="integer" xref="S3.E6.m1.1.1.1.1.16.16.4.2.2.2.2">2</cn></list></apply><ci id="S3.E6.m1.1.1.1.1.18.18.7.1.cmml" xref="S3.E6.m1.1.1.1.1.18.18.7.1">⋯</ci><apply id="S3.E6.m1.1.1.1.1.18.18.6.2.cmml" xref="S3.E6.m1.1.1.1.1.18.18.6.2"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.18.18.6.2.3.cmml" xref="S3.E6.m1.1.1.1.1.18.18.6.2">subscript</csymbol><ci id="S3.E6.m1.1.1.1.1.18.18.6.2.4.cmml" xref="S3.E6.m1.1.1.1.1.18.18.6.2.4">𝐞</ci><list id="S3.E6.m1.1.1.1.1.18.18.6.2.2.2.3.cmml" xref="S3.E6.m1.1.1.1.1.18.18.6.2.2.2.4"><ci id="S3.E6.m1.1.1.1.1.17.17.5.1.1.1.1.cmml" xref="S3.E6.m1.1.1.1.1.17.17.5.1.1.1.1">𝑣</ci><ci id="S3.E6.m1.1.1.1.1.18.18.6.2.2.2.2.cmml" xref="S3.E6.m1.1.1.1.1.18.18.6.2.2.2.2">𝑛</ci></list></apply></matrixrow></matrix></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E6.m1.2c">\mathbf{E}=\begin{bmatrix}\mathbf{{\color[rgb]{0.5859375,0.44140625,0.21484375%
}\definecolor[named]{pgfstrokecolor}{rgb}{0.5859375,0.44140625,0.21484375}e}}_%
{1,1}&amp;\mathbf{{\color[rgb]{0.5859375,0.44140625,0.21484375}\definecolor[named]%
{pgfstrokecolor}{rgb}{0.5859375,0.44140625,0.21484375}e}}_{1,2}&amp;\cdots&amp;\mathbf%
{{\color[rgb]{0.5859375,0.44140625,0.21484375}\definecolor[named]{%
pgfstrokecolor}{rgb}{0.5859375,0.44140625,0.21484375}e}}_{1,n}\\
\mathbf{{\color[rgb]{0.1796875,0.36328125,0.52734375}\definecolor[named]{%
pgfstrokecolor}{rgb}{0.1796875,0.36328125,0.52734375}e}}_{2,1}&amp;\mathbf{{\color%
[rgb]{0.1796875,0.36328125,0.52734375}\definecolor[named]{pgfstrokecolor}{rgb}%
{0.1796875,0.36328125,0.52734375}e}}_{2,2}&amp;\cdots&amp;\mathbf{{\color[rgb]{%
0.5859375,0.44140625,0.21484375}\definecolor[named]{pgfstrokecolor}{rgb}{%
0.5859375,0.44140625,0.21484375}e}}_{2,n}\\
\vdots&amp;\vdots&amp;\ddots&amp;\vdots\\
\mathbf{e}_{v,1}&amp;\mathbf{e}_{v,2}&amp;\cdots&amp;\mathbf{e}_{v,n}\end{bmatrix},</annotation><annotation encoding="application/x-llamapun" id="S3.E6.m1.2d">bold_E = [ start_ARG start_ROW start_CELL bold_e start_POSTSUBSCRIPT 1 , 1 end_POSTSUBSCRIPT end_CELL start_CELL bold_e start_POSTSUBSCRIPT 1 , 2 end_POSTSUBSCRIPT end_CELL start_CELL ⋯ end_CELL start_CELL bold_e start_POSTSUBSCRIPT 1 , italic_n end_POSTSUBSCRIPT end_CELL end_ROW start_ROW start_CELL bold_e start_POSTSUBSCRIPT 2 , 1 end_POSTSUBSCRIPT end_CELL start_CELL bold_e start_POSTSUBSCRIPT 2 , 2 end_POSTSUBSCRIPT end_CELL start_CELL ⋯ end_CELL start_CELL bold_e start_POSTSUBSCRIPT 2 , italic_n end_POSTSUBSCRIPT end_CELL end_ROW start_ROW start_CELL ⋮ end_CELL start_CELL ⋮ end_CELL start_CELL ⋱ end_CELL start_CELL ⋮ end_CELL end_ROW start_ROW start_CELL bold_e start_POSTSUBSCRIPT italic_v , 1 end_POSTSUBSCRIPT end_CELL start_CELL bold_e start_POSTSUBSCRIPT italic_v , 2 end_POSTSUBSCRIPT end_CELL start_CELL ⋯ end_CELL start_CELL bold_e start_POSTSUBSCRIPT italic_v , italic_n end_POSTSUBSCRIPT end_CELL end_ROW end_ARG ] ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS2.p1.5">where <math alttext="n" class="ltx_Math" display="inline" id="S3.SS2.p1.1.m1.1"><semantics id="S3.SS2.p1.1.m1.1a"><mi id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><ci id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">n</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.1.m1.1d">italic_n</annotation></semantics></math> denotes the number of items, and <math alttext="\mathbf{e}_{i,j}" class="ltx_Math" display="inline" id="S3.SS2.p1.2.m2.2"><semantics id="S3.SS2.p1.2.m2.2a"><msub id="S3.SS2.p1.2.m2.2.3" xref="S3.SS2.p1.2.m2.2.3.cmml"><mi id="S3.SS2.p1.2.m2.2.3.2" xref="S3.SS2.p1.2.m2.2.3.2.cmml">𝐞</mi><mrow id="S3.SS2.p1.2.m2.2.2.2.4" xref="S3.SS2.p1.2.m2.2.2.2.3.cmml"><mi id="S3.SS2.p1.2.m2.1.1.1.1" xref="S3.SS2.p1.2.m2.1.1.1.1.cmml">i</mi><mo id="S3.SS2.p1.2.m2.2.2.2.4.1" xref="S3.SS2.p1.2.m2.2.2.2.3.cmml">,</mo><mi id="S3.SS2.p1.2.m2.2.2.2.2" xref="S3.SS2.p1.2.m2.2.2.2.2.cmml">j</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.2b"><apply id="S3.SS2.p1.2.m2.2.3.cmml" xref="S3.SS2.p1.2.m2.2.3"><csymbol cd="ambiguous" id="S3.SS2.p1.2.m2.2.3.1.cmml" xref="S3.SS2.p1.2.m2.2.3">subscript</csymbol><ci id="S3.SS2.p1.2.m2.2.3.2.cmml" xref="S3.SS2.p1.2.m2.2.3.2">𝐞</ci><list id="S3.SS2.p1.2.m2.2.2.2.3.cmml" xref="S3.SS2.p1.2.m2.2.2.2.4"><ci id="S3.SS2.p1.2.m2.1.1.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1.1.1">𝑖</ci><ci id="S3.SS2.p1.2.m2.2.2.2.2.cmml" xref="S3.SS2.p1.2.m2.2.2.2.2">𝑗</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.2c">\mathbf{e}_{i,j}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.2.m2.2d">bold_e start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT</annotation></semantics></math> represents the <math alttext="i" class="ltx_Math" display="inline" id="S3.SS2.p1.3.m3.1"><semantics id="S3.SS2.p1.3.m3.1a"><mi id="S3.SS2.p1.3.m3.1.1" xref="S3.SS2.p1.3.m3.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.3.m3.1b"><ci id="S3.SS2.p1.3.m3.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.3.m3.1c">i</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.3.m3.1d">italic_i</annotation></semantics></math>-th output embedding of the dense tokens of the <math alttext="j" class="ltx_Math" display="inline" id="S3.SS2.p1.4.m4.1"><semantics id="S3.SS2.p1.4.m4.1a"><mi id="S3.SS2.p1.4.m4.1.1" xref="S3.SS2.p1.4.m4.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.4.m4.1b"><ci id="S3.SS2.p1.4.m4.1.1.cmml" xref="S3.SS2.p1.4.m4.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.4.m4.1c">j</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.4.m4.1d">italic_j</annotation></semantics></math>-th item with <math alttext="D" class="ltx_Math" display="inline" id="S3.SS2.p1.5.m5.1"><semantics id="S3.SS2.p1.5.m5.1a"><mi id="S3.SS2.p1.5.m5.1.1" xref="S3.SS2.p1.5.m5.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.5.m5.1b"><ci id="S3.SS2.p1.5.m5.1.1.cmml" xref="S3.SS2.p1.5.m5.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.5.m5.1c">D</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.5.m5.1d">italic_D</annotation></semantics></math> dimensions.</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.4">Next, we apply the principal component analysis (PCA) technique <cite class="ltx_cite ltx_citemacro_citep">(Maćkiewicz and Ratajczak, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib24" title="">1993</a>)</cite> to reduce the high-dimensional <math alttext="D" class="ltx_Math" display="inline" id="S3.SS2.p2.1.m1.1"><semantics id="S3.SS2.p2.1.m1.1a"><mi id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><ci id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">D</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.1.m1.1d">italic_D</annotation></semantics></math> vectors (over 1024 dimensions) to a lower dimension <math alttext="d" class="ltx_Math" display="inline" id="S3.SS2.p2.2.m2.1"><semantics id="S3.SS2.p2.2.m2.1a"><mi id="S3.SS2.p2.2.m2.1.1" xref="S3.SS2.p2.2.m2.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m2.1b"><ci id="S3.SS2.p2.2.m2.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1">𝑑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.m2.1c">d</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.2.m2.1d">italic_d</annotation></semantics></math>, such as 32. The principal components are denoted by <math alttext="\mathbf{\hat{e}}_{i,j}" class="ltx_Math" display="inline" id="S3.SS2.p2.3.m3.2"><semantics id="S3.SS2.p2.3.m3.2a"><msub id="S3.SS2.p2.3.m3.2.3" xref="S3.SS2.p2.3.m3.2.3.cmml"><mover accent="true" id="S3.SS2.p2.3.m3.2.3.2" xref="S3.SS2.p2.3.m3.2.3.2.cmml"><mi id="S3.SS2.p2.3.m3.2.3.2.2" xref="S3.SS2.p2.3.m3.2.3.2.2.cmml">𝐞</mi><mo id="S3.SS2.p2.3.m3.2.3.2.1" xref="S3.SS2.p2.3.m3.2.3.2.1.cmml">^</mo></mover><mrow id="S3.SS2.p2.3.m3.2.2.2.4" xref="S3.SS2.p2.3.m3.2.2.2.3.cmml"><mi id="S3.SS2.p2.3.m3.1.1.1.1" xref="S3.SS2.p2.3.m3.1.1.1.1.cmml">i</mi><mo id="S3.SS2.p2.3.m3.2.2.2.4.1" xref="S3.SS2.p2.3.m3.2.2.2.3.cmml">,</mo><mi id="S3.SS2.p2.3.m3.2.2.2.2" xref="S3.SS2.p2.3.m3.2.2.2.2.cmml">j</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.3.m3.2b"><apply id="S3.SS2.p2.3.m3.2.3.cmml" xref="S3.SS2.p2.3.m3.2.3"><csymbol cd="ambiguous" id="S3.SS2.p2.3.m3.2.3.1.cmml" xref="S3.SS2.p2.3.m3.2.3">subscript</csymbol><apply id="S3.SS2.p2.3.m3.2.3.2.cmml" xref="S3.SS2.p2.3.m3.2.3.2"><ci id="S3.SS2.p2.3.m3.2.3.2.1.cmml" xref="S3.SS2.p2.3.m3.2.3.2.1">^</ci><ci id="S3.SS2.p2.3.m3.2.3.2.2.cmml" xref="S3.SS2.p2.3.m3.2.3.2.2">𝐞</ci></apply><list id="S3.SS2.p2.3.m3.2.2.2.3.cmml" xref="S3.SS2.p2.3.m3.2.2.2.4"><ci id="S3.SS2.p2.3.m3.1.1.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1.1.1">𝑖</ci><ci id="S3.SS2.p2.3.m3.2.2.2.2.cmml" xref="S3.SS2.p2.3.m3.2.2.2.2">𝑗</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.3.m3.2c">\mathbf{\hat{e}}_{i,j}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.3.m3.2d">over^ start_ARG bold_e end_ARG start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT</annotation></semantics></math> for each reduced embedding of <math alttext="\mathbf{e}_{i,j}" class="ltx_Math" display="inline" id="S3.SS2.p2.4.m4.2"><semantics id="S3.SS2.p2.4.m4.2a"><msub id="S3.SS2.p2.4.m4.2.3" xref="S3.SS2.p2.4.m4.2.3.cmml"><mi id="S3.SS2.p2.4.m4.2.3.2" xref="S3.SS2.p2.4.m4.2.3.2.cmml">𝐞</mi><mrow id="S3.SS2.p2.4.m4.2.2.2.4" xref="S3.SS2.p2.4.m4.2.2.2.3.cmml"><mi id="S3.SS2.p2.4.m4.1.1.1.1" xref="S3.SS2.p2.4.m4.1.1.1.1.cmml">i</mi><mo id="S3.SS2.p2.4.m4.2.2.2.4.1" xref="S3.SS2.p2.4.m4.2.2.2.3.cmml">,</mo><mi id="S3.SS2.p2.4.m4.2.2.2.2" xref="S3.SS2.p2.4.m4.2.2.2.2.cmml">j</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.4.m4.2b"><apply id="S3.SS2.p2.4.m4.2.3.cmml" xref="S3.SS2.p2.4.m4.2.3"><csymbol cd="ambiguous" id="S3.SS2.p2.4.m4.2.3.1.cmml" xref="S3.SS2.p2.4.m4.2.3">subscript</csymbol><ci id="S3.SS2.p2.4.m4.2.3.2.cmml" xref="S3.SS2.p2.4.m4.2.3.2">𝐞</ci><list id="S3.SS2.p2.4.m4.2.2.2.3.cmml" xref="S3.SS2.p2.4.m4.2.2.2.4"><ci id="S3.SS2.p2.4.m4.1.1.1.1.cmml" xref="S3.SS2.p2.4.m4.1.1.1.1">𝑖</ci><ci id="S3.SS2.p2.4.m4.2.2.2.2.cmml" xref="S3.SS2.p2.4.m4.2.2.2.2">𝑗</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.4.m4.2c">\mathbf{e}_{i,j}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.4.m4.2d">bold_e start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT</annotation></semantics></math>.</p>
</div>
<div class="ltx_para" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.1">Finally, we apply a simple, training-free clustering algorithm, such as K-Means <cite class="ltx_cite ltx_citemacro_citep">(Krishna and Murty, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib15" title="">1999</a>)</cite>, to each row of the matrix, denoted as <math alttext="\mathbf{\hat{E}}[i,:]=[\mathbf{\hat{e}}_{i,1},\mathbf{\hat{e}}_{i,2},\cdots,%
\mathbf{\hat{e}}_{i,n}]" class="ltx_Math" display="inline" id="S3.SS2.p3.1.m1.12"><semantics id="S3.SS2.p3.1.m1.12a"><mrow id="S3.SS2.p3.1.m1.12.12" xref="S3.SS2.p3.1.m1.12.12.cmml"><mrow id="S3.SS2.p3.1.m1.12.12.5" xref="S3.SS2.p3.1.m1.12.12.5.cmml"><mover accent="true" id="S3.SS2.p3.1.m1.12.12.5.2" xref="S3.SS2.p3.1.m1.12.12.5.2.cmml"><mi id="S3.SS2.p3.1.m1.12.12.5.2.2" xref="S3.SS2.p3.1.m1.12.12.5.2.2.cmml">𝐄</mi><mo id="S3.SS2.p3.1.m1.12.12.5.2.1" xref="S3.SS2.p3.1.m1.12.12.5.2.1.cmml">^</mo></mover><mo id="S3.SS2.p3.1.m1.12.12.5.1" xref="S3.SS2.p3.1.m1.12.12.5.1.cmml">⁢</mo><mrow id="S3.SS2.p3.1.m1.12.12.5.3.2" xref="S3.SS2.p3.1.m1.12.12.5.3.1.cmml"><mo id="S3.SS2.p3.1.m1.12.12.5.3.2.1" stretchy="false" xref="S3.SS2.p3.1.m1.12.12.5.3.1.cmml">[</mo><mi id="S3.SS2.p3.1.m1.7.7" xref="S3.SS2.p3.1.m1.7.7.cmml">i</mi><mo id="S3.SS2.p3.1.m1.12.12.5.3.2.2" xref="S3.SS2.p3.1.m1.12.12.5.3.1.cmml">,</mo><mo id="S3.SS2.p3.1.m1.8.8" rspace="0em" xref="S3.SS2.p3.1.m1.8.8.cmml">:</mo><mo id="S3.SS2.p3.1.m1.12.12.5.3.2.3" stretchy="false" xref="S3.SS2.p3.1.m1.12.12.5.3.1.cmml">]</mo></mrow></mrow><mo id="S3.SS2.p3.1.m1.12.12.4" xref="S3.SS2.p3.1.m1.12.12.4.cmml">=</mo><mrow id="S3.SS2.p3.1.m1.12.12.3.3" xref="S3.SS2.p3.1.m1.12.12.3.4.cmml"><mo id="S3.SS2.p3.1.m1.12.12.3.3.4" stretchy="false" xref="S3.SS2.p3.1.m1.12.12.3.4.cmml">[</mo><msub id="S3.SS2.p3.1.m1.10.10.1.1.1" xref="S3.SS2.p3.1.m1.10.10.1.1.1.cmml"><mover accent="true" id="S3.SS2.p3.1.m1.10.10.1.1.1.2" xref="S3.SS2.p3.1.m1.10.10.1.1.1.2.cmml"><mi id="S3.SS2.p3.1.m1.10.10.1.1.1.2.2" xref="S3.SS2.p3.1.m1.10.10.1.1.1.2.2.cmml">𝐞</mi><mo id="S3.SS2.p3.1.m1.10.10.1.1.1.2.1" xref="S3.SS2.p3.1.m1.10.10.1.1.1.2.1.cmml">^</mo></mover><mrow id="S3.SS2.p3.1.m1.2.2.2.4" xref="S3.SS2.p3.1.m1.2.2.2.3.cmml"><mi id="S3.SS2.p3.1.m1.1.1.1.1" xref="S3.SS2.p3.1.m1.1.1.1.1.cmml">i</mi><mo id="S3.SS2.p3.1.m1.2.2.2.4.1" xref="S3.SS2.p3.1.m1.2.2.2.3.cmml">,</mo><mn id="S3.SS2.p3.1.m1.2.2.2.2" xref="S3.SS2.p3.1.m1.2.2.2.2.cmml">1</mn></mrow></msub><mo id="S3.SS2.p3.1.m1.12.12.3.3.5" xref="S3.SS2.p3.1.m1.12.12.3.4.cmml">,</mo><msub id="S3.SS2.p3.1.m1.11.11.2.2.2" xref="S3.SS2.p3.1.m1.11.11.2.2.2.cmml"><mover accent="true" id="S3.SS2.p3.1.m1.11.11.2.2.2.2" xref="S3.SS2.p3.1.m1.11.11.2.2.2.2.cmml"><mi id="S3.SS2.p3.1.m1.11.11.2.2.2.2.2" xref="S3.SS2.p3.1.m1.11.11.2.2.2.2.2.cmml">𝐞</mi><mo id="S3.SS2.p3.1.m1.11.11.2.2.2.2.1" xref="S3.SS2.p3.1.m1.11.11.2.2.2.2.1.cmml">^</mo></mover><mrow id="S3.SS2.p3.1.m1.4.4.2.4" xref="S3.SS2.p3.1.m1.4.4.2.3.cmml"><mi id="S3.SS2.p3.1.m1.3.3.1.1" xref="S3.SS2.p3.1.m1.3.3.1.1.cmml">i</mi><mo id="S3.SS2.p3.1.m1.4.4.2.4.1" xref="S3.SS2.p3.1.m1.4.4.2.3.cmml">,</mo><mn id="S3.SS2.p3.1.m1.4.4.2.2" xref="S3.SS2.p3.1.m1.4.4.2.2.cmml">2</mn></mrow></msub><mo id="S3.SS2.p3.1.m1.12.12.3.3.6" xref="S3.SS2.p3.1.m1.12.12.3.4.cmml">,</mo><mi id="S3.SS2.p3.1.m1.9.9" mathvariant="normal" xref="S3.SS2.p3.1.m1.9.9.cmml">⋯</mi><mo id="S3.SS2.p3.1.m1.12.12.3.3.7" xref="S3.SS2.p3.1.m1.12.12.3.4.cmml">,</mo><msub id="S3.SS2.p3.1.m1.12.12.3.3.3" xref="S3.SS2.p3.1.m1.12.12.3.3.3.cmml"><mover accent="true" id="S3.SS2.p3.1.m1.12.12.3.3.3.2" xref="S3.SS2.p3.1.m1.12.12.3.3.3.2.cmml"><mi id="S3.SS2.p3.1.m1.12.12.3.3.3.2.2" xref="S3.SS2.p3.1.m1.12.12.3.3.3.2.2.cmml">𝐞</mi><mo id="S3.SS2.p3.1.m1.12.12.3.3.3.2.1" xref="S3.SS2.p3.1.m1.12.12.3.3.3.2.1.cmml">^</mo></mover><mrow id="S3.SS2.p3.1.m1.6.6.2.4" xref="S3.SS2.p3.1.m1.6.6.2.3.cmml"><mi id="S3.SS2.p3.1.m1.5.5.1.1" xref="S3.SS2.p3.1.m1.5.5.1.1.cmml">i</mi><mo id="S3.SS2.p3.1.m1.6.6.2.4.1" xref="S3.SS2.p3.1.m1.6.6.2.3.cmml">,</mo><mi id="S3.SS2.p3.1.m1.6.6.2.2" xref="S3.SS2.p3.1.m1.6.6.2.2.cmml">n</mi></mrow></msub><mo id="S3.SS2.p3.1.m1.12.12.3.3.8" stretchy="false" xref="S3.SS2.p3.1.m1.12.12.3.4.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.12b"><apply id="S3.SS2.p3.1.m1.12.12.cmml" xref="S3.SS2.p3.1.m1.12.12"><eq id="S3.SS2.p3.1.m1.12.12.4.cmml" xref="S3.SS2.p3.1.m1.12.12.4"></eq><apply id="S3.SS2.p3.1.m1.12.12.5.cmml" xref="S3.SS2.p3.1.m1.12.12.5"><times id="S3.SS2.p3.1.m1.12.12.5.1.cmml" xref="S3.SS2.p3.1.m1.12.12.5.1"></times><apply id="S3.SS2.p3.1.m1.12.12.5.2.cmml" xref="S3.SS2.p3.1.m1.12.12.5.2"><ci id="S3.SS2.p3.1.m1.12.12.5.2.1.cmml" xref="S3.SS2.p3.1.m1.12.12.5.2.1">^</ci><ci id="S3.SS2.p3.1.m1.12.12.5.2.2.cmml" xref="S3.SS2.p3.1.m1.12.12.5.2.2">𝐄</ci></apply><interval closure="closed" id="S3.SS2.p3.1.m1.12.12.5.3.1.cmml" xref="S3.SS2.p3.1.m1.12.12.5.3.2"><ci id="S3.SS2.p3.1.m1.7.7.cmml" xref="S3.SS2.p3.1.m1.7.7">𝑖</ci><ci id="S3.SS2.p3.1.m1.8.8.cmml" xref="S3.SS2.p3.1.m1.8.8">:</ci></interval></apply><list id="S3.SS2.p3.1.m1.12.12.3.4.cmml" xref="S3.SS2.p3.1.m1.12.12.3.3"><apply id="S3.SS2.p3.1.m1.10.10.1.1.1.cmml" xref="S3.SS2.p3.1.m1.10.10.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.1.m1.10.10.1.1.1.1.cmml" xref="S3.SS2.p3.1.m1.10.10.1.1.1">subscript</csymbol><apply id="S3.SS2.p3.1.m1.10.10.1.1.1.2.cmml" xref="S3.SS2.p3.1.m1.10.10.1.1.1.2"><ci id="S3.SS2.p3.1.m1.10.10.1.1.1.2.1.cmml" xref="S3.SS2.p3.1.m1.10.10.1.1.1.2.1">^</ci><ci id="S3.SS2.p3.1.m1.10.10.1.1.1.2.2.cmml" xref="S3.SS2.p3.1.m1.10.10.1.1.1.2.2">𝐞</ci></apply><list id="S3.SS2.p3.1.m1.2.2.2.3.cmml" xref="S3.SS2.p3.1.m1.2.2.2.4"><ci id="S3.SS2.p3.1.m1.1.1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1">𝑖</ci><cn id="S3.SS2.p3.1.m1.2.2.2.2.cmml" type="integer" xref="S3.SS2.p3.1.m1.2.2.2.2">1</cn></list></apply><apply id="S3.SS2.p3.1.m1.11.11.2.2.2.cmml" xref="S3.SS2.p3.1.m1.11.11.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p3.1.m1.11.11.2.2.2.1.cmml" xref="S3.SS2.p3.1.m1.11.11.2.2.2">subscript</csymbol><apply id="S3.SS2.p3.1.m1.11.11.2.2.2.2.cmml" xref="S3.SS2.p3.1.m1.11.11.2.2.2.2"><ci id="S3.SS2.p3.1.m1.11.11.2.2.2.2.1.cmml" xref="S3.SS2.p3.1.m1.11.11.2.2.2.2.1">^</ci><ci id="S3.SS2.p3.1.m1.11.11.2.2.2.2.2.cmml" xref="S3.SS2.p3.1.m1.11.11.2.2.2.2.2">𝐞</ci></apply><list id="S3.SS2.p3.1.m1.4.4.2.3.cmml" xref="S3.SS2.p3.1.m1.4.4.2.4"><ci id="S3.SS2.p3.1.m1.3.3.1.1.cmml" xref="S3.SS2.p3.1.m1.3.3.1.1">𝑖</ci><cn id="S3.SS2.p3.1.m1.4.4.2.2.cmml" type="integer" xref="S3.SS2.p3.1.m1.4.4.2.2">2</cn></list></apply><ci id="S3.SS2.p3.1.m1.9.9.cmml" xref="S3.SS2.p3.1.m1.9.9">⋯</ci><apply id="S3.SS2.p3.1.m1.12.12.3.3.3.cmml" xref="S3.SS2.p3.1.m1.12.12.3.3.3"><csymbol cd="ambiguous" id="S3.SS2.p3.1.m1.12.12.3.3.3.1.cmml" xref="S3.SS2.p3.1.m1.12.12.3.3.3">subscript</csymbol><apply id="S3.SS2.p3.1.m1.12.12.3.3.3.2.cmml" xref="S3.SS2.p3.1.m1.12.12.3.3.3.2"><ci id="S3.SS2.p3.1.m1.12.12.3.3.3.2.1.cmml" xref="S3.SS2.p3.1.m1.12.12.3.3.3.2.1">^</ci><ci id="S3.SS2.p3.1.m1.12.12.3.3.3.2.2.cmml" xref="S3.SS2.p3.1.m1.12.12.3.3.3.2.2">𝐞</ci></apply><list id="S3.SS2.p3.1.m1.6.6.2.3.cmml" xref="S3.SS2.p3.1.m1.6.6.2.4"><ci id="S3.SS2.p3.1.m1.5.5.1.1.cmml" xref="S3.SS2.p3.1.m1.5.5.1.1">𝑖</ci><ci id="S3.SS2.p3.1.m1.6.6.2.2.cmml" xref="S3.SS2.p3.1.m1.6.6.2.2">𝑛</ci></list></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.12c">\mathbf{\hat{E}}[i,:]=[\mathbf{\hat{e}}_{i,1},\mathbf{\hat{e}}_{i,2},\cdots,%
\mathbf{\hat{e}}_{i,n}]</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.1.m1.12d">over^ start_ARG bold_E end_ARG [ italic_i , : ] = [ over^ start_ARG bold_e end_ARG start_POSTSUBSCRIPT italic_i , 1 end_POSTSUBSCRIPT , over^ start_ARG bold_e end_ARG start_POSTSUBSCRIPT italic_i , 2 end_POSTSUBSCRIPT , ⋯ , over^ start_ARG bold_e end_ARG start_POSTSUBSCRIPT italic_i , italic_n end_POSTSUBSCRIPT ]</annotation></semantics></math>. The resulting cluster indices are organized into a matrix:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E7">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_left">(7)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathbf{C}=\begin{bmatrix}c_{1,1}&amp;c_{1,2}&amp;\cdots&amp;c_{1,n}\\
c_{2,1}&amp;c_{2,2}&amp;\cdots&amp;c_{2,n}\\
\vdots&amp;\vdots&amp;\ddots&amp;\vdots\\
c_{v,1}&amp;c_{v,2}&amp;\cdots&amp;c_{v,n}\end{bmatrix}," class="ltx_Math" display="block" id="S3.E7.m1.2"><semantics id="S3.E7.m1.2a"><mrow id="S3.E7.m1.2.2.1" xref="S3.E7.m1.2.2.1.1.cmml"><mrow id="S3.E7.m1.2.2.1.1" xref="S3.E7.m1.2.2.1.1.cmml"><mi id="S3.E7.m1.2.2.1.1.2" xref="S3.E7.m1.2.2.1.1.2.cmml">𝐂</mi><mo id="S3.E7.m1.2.2.1.1.1" xref="S3.E7.m1.2.2.1.1.1.cmml">=</mo><mrow id="S3.E7.m1.1.1.3" xref="S3.E7.m1.1.1.2.cmml"><mo id="S3.E7.m1.1.1.3.1" xref="S3.E7.m1.1.1.2.1.cmml">[</mo><mtable columnspacing="5pt" displaystyle="true" id="S3.E7.m1.1.1.1.1" rowspacing="0pt" xref="S3.E7.m1.1.1.1.1.cmml"><mtr id="S3.E7.m1.1.1.1.1a" xref="S3.E7.m1.1.1.1.1.cmml"><mtd id="S3.E7.m1.1.1.1.1b" xref="S3.E7.m1.1.1.1.1.cmml"><msub id="S3.E7.m1.1.1.1.1.2.2.2.2" xref="S3.E7.m1.1.1.1.1.2.2.2.2.cmml"><mi id="S3.E7.m1.1.1.1.1.2.2.2.2.4" xref="S3.E7.m1.1.1.1.1.2.2.2.2.4.cmml">c</mi><mrow id="S3.E7.m1.1.1.1.1.2.2.2.2.2.2.4" xref="S3.E7.m1.1.1.1.1.2.2.2.2.2.2.3.cmml"><mn id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.cmml">1</mn><mo id="S3.E7.m1.1.1.1.1.2.2.2.2.2.2.4.1" xref="S3.E7.m1.1.1.1.1.2.2.2.2.2.2.3.cmml">,</mo><mn id="S3.E7.m1.1.1.1.1.2.2.2.2.2.2.2" xref="S3.E7.m1.1.1.1.1.2.2.2.2.2.2.2.cmml">1</mn></mrow></msub></mtd><mtd id="S3.E7.m1.1.1.1.1c" xref="S3.E7.m1.1.1.1.1.cmml"><msub id="S3.E7.m1.1.1.1.1.4.4.4.2" xref="S3.E7.m1.1.1.1.1.4.4.4.2.cmml"><mi id="S3.E7.m1.1.1.1.1.4.4.4.2.4" xref="S3.E7.m1.1.1.1.1.4.4.4.2.4.cmml">c</mi><mrow id="S3.E7.m1.1.1.1.1.4.4.4.2.2.2.4" xref="S3.E7.m1.1.1.1.1.4.4.4.2.2.2.3.cmml"><mn id="S3.E7.m1.1.1.1.1.3.3.3.1.1.1.1" xref="S3.E7.m1.1.1.1.1.3.3.3.1.1.1.1.cmml">1</mn><mo id="S3.E7.m1.1.1.1.1.4.4.4.2.2.2.4.1" xref="S3.E7.m1.1.1.1.1.4.4.4.2.2.2.3.cmml">,</mo><mn id="S3.E7.m1.1.1.1.1.4.4.4.2.2.2.2" xref="S3.E7.m1.1.1.1.1.4.4.4.2.2.2.2.cmml">2</mn></mrow></msub></mtd><mtd id="S3.E7.m1.1.1.1.1d" xref="S3.E7.m1.1.1.1.1.cmml"><mi id="S3.E7.m1.1.1.1.1.6.6.7.1" mathvariant="normal" xref="S3.E7.m1.1.1.1.1.6.6.7.1.cmml">⋯</mi></mtd><mtd id="S3.E7.m1.1.1.1.1e" xref="S3.E7.m1.1.1.1.1.cmml"><msub id="S3.E7.m1.1.1.1.1.6.6.6.2" xref="S3.E7.m1.1.1.1.1.6.6.6.2.cmml"><mi id="S3.E7.m1.1.1.1.1.6.6.6.2.4" xref="S3.E7.m1.1.1.1.1.6.6.6.2.4.cmml">c</mi><mrow id="S3.E7.m1.1.1.1.1.6.6.6.2.2.2.4" xref="S3.E7.m1.1.1.1.1.6.6.6.2.2.2.3.cmml"><mn id="S3.E7.m1.1.1.1.1.5.5.5.1.1.1.1" xref="S3.E7.m1.1.1.1.1.5.5.5.1.1.1.1.cmml">1</mn><mo id="S3.E7.m1.1.1.1.1.6.6.6.2.2.2.4.1" xref="S3.E7.m1.1.1.1.1.6.6.6.2.2.2.3.cmml">,</mo><mi id="S3.E7.m1.1.1.1.1.6.6.6.2.2.2.2" xref="S3.E7.m1.1.1.1.1.6.6.6.2.2.2.2.cmml">n</mi></mrow></msub></mtd></mtr><mtr id="S3.E7.m1.1.1.1.1f" xref="S3.E7.m1.1.1.1.1.cmml"><mtd id="S3.E7.m1.1.1.1.1g" xref="S3.E7.m1.1.1.1.1.cmml"><msub id="S3.E7.m1.1.1.1.1.8.8.2.2" xref="S3.E7.m1.1.1.1.1.8.8.2.2.cmml"><mi id="S3.E7.m1.1.1.1.1.8.8.2.2.4" xref="S3.E7.m1.1.1.1.1.8.8.2.2.4.cmml">c</mi><mrow id="S3.E7.m1.1.1.1.1.8.8.2.2.2.2.4" xref="S3.E7.m1.1.1.1.1.8.8.2.2.2.2.3.cmml"><mn id="S3.E7.m1.1.1.1.1.7.7.1.1.1.1.1" xref="S3.E7.m1.1.1.1.1.7.7.1.1.1.1.1.cmml">2</mn><mo id="S3.E7.m1.1.1.1.1.8.8.2.2.2.2.4.1" xref="S3.E7.m1.1.1.1.1.8.8.2.2.2.2.3.cmml">,</mo><mn id="S3.E7.m1.1.1.1.1.8.8.2.2.2.2.2" xref="S3.E7.m1.1.1.1.1.8.8.2.2.2.2.2.cmml">1</mn></mrow></msub></mtd><mtd id="S3.E7.m1.1.1.1.1h" xref="S3.E7.m1.1.1.1.1.cmml"><msub id="S3.E7.m1.1.1.1.1.10.10.4.2" xref="S3.E7.m1.1.1.1.1.10.10.4.2.cmml"><mi id="S3.E7.m1.1.1.1.1.10.10.4.2.4" xref="S3.E7.m1.1.1.1.1.10.10.4.2.4.cmml">c</mi><mrow id="S3.E7.m1.1.1.1.1.10.10.4.2.2.2.4" xref="S3.E7.m1.1.1.1.1.10.10.4.2.2.2.3.cmml"><mn id="S3.E7.m1.1.1.1.1.9.9.3.1.1.1.1" xref="S3.E7.m1.1.1.1.1.9.9.3.1.1.1.1.cmml">2</mn><mo id="S3.E7.m1.1.1.1.1.10.10.4.2.2.2.4.1" xref="S3.E7.m1.1.1.1.1.10.10.4.2.2.2.3.cmml">,</mo><mn id="S3.E7.m1.1.1.1.1.10.10.4.2.2.2.2" xref="S3.E7.m1.1.1.1.1.10.10.4.2.2.2.2.cmml">2</mn></mrow></msub></mtd><mtd id="S3.E7.m1.1.1.1.1i" xref="S3.E7.m1.1.1.1.1.cmml"><mi id="S3.E7.m1.1.1.1.1.12.12.7.1" mathvariant="normal" xref="S3.E7.m1.1.1.1.1.12.12.7.1.cmml">⋯</mi></mtd><mtd id="S3.E7.m1.1.1.1.1j" xref="S3.E7.m1.1.1.1.1.cmml"><msub id="S3.E7.m1.1.1.1.1.12.12.6.2" xref="S3.E7.m1.1.1.1.1.12.12.6.2.cmml"><mi id="S3.E7.m1.1.1.1.1.12.12.6.2.4" xref="S3.E7.m1.1.1.1.1.12.12.6.2.4.cmml">c</mi><mrow id="S3.E7.m1.1.1.1.1.12.12.6.2.2.2.4" xref="S3.E7.m1.1.1.1.1.12.12.6.2.2.2.3.cmml"><mn id="S3.E7.m1.1.1.1.1.11.11.5.1.1.1.1" xref="S3.E7.m1.1.1.1.1.11.11.5.1.1.1.1.cmml">2</mn><mo id="S3.E7.m1.1.1.1.1.12.12.6.2.2.2.4.1" xref="S3.E7.m1.1.1.1.1.12.12.6.2.2.2.3.cmml">,</mo><mi id="S3.E7.m1.1.1.1.1.12.12.6.2.2.2.2" xref="S3.E7.m1.1.1.1.1.12.12.6.2.2.2.2.cmml">n</mi></mrow></msub></mtd></mtr><mtr id="S3.E7.m1.1.1.1.1k" xref="S3.E7.m1.1.1.1.1.cmml"><mtd id="S3.E7.m1.1.1.1.1l" xref="S3.E7.m1.1.1.1.1.cmml"><mi id="S3.E7.m1.1.1.1.1.19.1.1" mathvariant="normal" xref="S3.E7.m1.1.1.1.1.19.1.1.cmml">⋮</mi></mtd><mtd id="S3.E7.m1.1.1.1.1m" xref="S3.E7.m1.1.1.1.1.cmml"><mi id="S3.E7.m1.1.1.1.1.19.2.1" mathvariant="normal" xref="S3.E7.m1.1.1.1.1.19.2.1.cmml">⋮</mi></mtd><mtd id="S3.E7.m1.1.1.1.1n" xref="S3.E7.m1.1.1.1.1.cmml"><mi id="S3.E7.m1.1.1.1.1.19.3.1" mathvariant="normal" xref="S3.E7.m1.1.1.1.1.19.3.1.cmml">⋱</mi></mtd><mtd id="S3.E7.m1.1.1.1.1o" xref="S3.E7.m1.1.1.1.1.cmml"><mi id="S3.E7.m1.1.1.1.1.19.4.1" mathvariant="normal" xref="S3.E7.m1.1.1.1.1.19.4.1.cmml">⋮</mi></mtd></mtr><mtr id="S3.E7.m1.1.1.1.1p" xref="S3.E7.m1.1.1.1.1.cmml"><mtd id="S3.E7.m1.1.1.1.1q" xref="S3.E7.m1.1.1.1.1.cmml"><msub id="S3.E7.m1.1.1.1.1.14.14.2.2" xref="S3.E7.m1.1.1.1.1.14.14.2.2.cmml"><mi id="S3.E7.m1.1.1.1.1.14.14.2.2.4" xref="S3.E7.m1.1.1.1.1.14.14.2.2.4.cmml">c</mi><mrow id="S3.E7.m1.1.1.1.1.14.14.2.2.2.2.4" xref="S3.E7.m1.1.1.1.1.14.14.2.2.2.2.3.cmml"><mi id="S3.E7.m1.1.1.1.1.13.13.1.1.1.1.1" xref="S3.E7.m1.1.1.1.1.13.13.1.1.1.1.1.cmml">v</mi><mo id="S3.E7.m1.1.1.1.1.14.14.2.2.2.2.4.1" xref="S3.E7.m1.1.1.1.1.14.14.2.2.2.2.3.cmml">,</mo><mn id="S3.E7.m1.1.1.1.1.14.14.2.2.2.2.2" xref="S3.E7.m1.1.1.1.1.14.14.2.2.2.2.2.cmml">1</mn></mrow></msub></mtd><mtd id="S3.E7.m1.1.1.1.1r" xref="S3.E7.m1.1.1.1.1.cmml"><msub id="S3.E7.m1.1.1.1.1.16.16.4.2" xref="S3.E7.m1.1.1.1.1.16.16.4.2.cmml"><mi id="S3.E7.m1.1.1.1.1.16.16.4.2.4" xref="S3.E7.m1.1.1.1.1.16.16.4.2.4.cmml">c</mi><mrow id="S3.E7.m1.1.1.1.1.16.16.4.2.2.2.4" xref="S3.E7.m1.1.1.1.1.16.16.4.2.2.2.3.cmml"><mi id="S3.E7.m1.1.1.1.1.15.15.3.1.1.1.1" xref="S3.E7.m1.1.1.1.1.15.15.3.1.1.1.1.cmml">v</mi><mo id="S3.E7.m1.1.1.1.1.16.16.4.2.2.2.4.1" xref="S3.E7.m1.1.1.1.1.16.16.4.2.2.2.3.cmml">,</mo><mn id="S3.E7.m1.1.1.1.1.16.16.4.2.2.2.2" xref="S3.E7.m1.1.1.1.1.16.16.4.2.2.2.2.cmml">2</mn></mrow></msub></mtd><mtd id="S3.E7.m1.1.1.1.1s" xref="S3.E7.m1.1.1.1.1.cmml"><mi id="S3.E7.m1.1.1.1.1.18.18.7.1" mathvariant="normal" xref="S3.E7.m1.1.1.1.1.18.18.7.1.cmml">⋯</mi></mtd><mtd id="S3.E7.m1.1.1.1.1t" xref="S3.E7.m1.1.1.1.1.cmml"><msub id="S3.E7.m1.1.1.1.1.18.18.6.2" xref="S3.E7.m1.1.1.1.1.18.18.6.2.cmml"><mi id="S3.E7.m1.1.1.1.1.18.18.6.2.4" xref="S3.E7.m1.1.1.1.1.18.18.6.2.4.cmml">c</mi><mrow id="S3.E7.m1.1.1.1.1.18.18.6.2.2.2.4" xref="S3.E7.m1.1.1.1.1.18.18.6.2.2.2.3.cmml"><mi id="S3.E7.m1.1.1.1.1.17.17.5.1.1.1.1" xref="S3.E7.m1.1.1.1.1.17.17.5.1.1.1.1.cmml">v</mi><mo id="S3.E7.m1.1.1.1.1.18.18.6.2.2.2.4.1" xref="S3.E7.m1.1.1.1.1.18.18.6.2.2.2.3.cmml">,</mo><mi id="S3.E7.m1.1.1.1.1.18.18.6.2.2.2.2" xref="S3.E7.m1.1.1.1.1.18.18.6.2.2.2.2.cmml">n</mi></mrow></msub></mtd></mtr></mtable><mo id="S3.E7.m1.1.1.3.2" xref="S3.E7.m1.1.1.2.1.cmml">]</mo></mrow></mrow><mo id="S3.E7.m1.2.2.1.2" xref="S3.E7.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E7.m1.2b"><apply id="S3.E7.m1.2.2.1.1.cmml" xref="S3.E7.m1.2.2.1"><eq id="S3.E7.m1.2.2.1.1.1.cmml" xref="S3.E7.m1.2.2.1.1.1"></eq><ci id="S3.E7.m1.2.2.1.1.2.cmml" xref="S3.E7.m1.2.2.1.1.2">𝐂</ci><apply id="S3.E7.m1.1.1.2.cmml" xref="S3.E7.m1.1.1.3"><csymbol cd="latexml" id="S3.E7.m1.1.1.2.1.cmml" xref="S3.E7.m1.1.1.3.1">matrix</csymbol><matrix id="S3.E7.m1.1.1.1.1.cmml" xref="S3.E7.m1.1.1.1.1"><matrixrow id="S3.E7.m1.1.1.1.1a.cmml" xref="S3.E7.m1.1.1.1.1"><apply id="S3.E7.m1.1.1.1.1.2.2.2.2.cmml" xref="S3.E7.m1.1.1.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.1.1.2.2.2.2.3.cmml" xref="S3.E7.m1.1.1.1.1.2.2.2.2">subscript</csymbol><ci id="S3.E7.m1.1.1.1.1.2.2.2.2.4.cmml" xref="S3.E7.m1.1.1.1.1.2.2.2.2.4">𝑐</ci><list id="S3.E7.m1.1.1.1.1.2.2.2.2.2.2.3.cmml" xref="S3.E7.m1.1.1.1.1.2.2.2.2.2.2.4"><cn id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.cmml" type="integer" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1">1</cn><cn id="S3.E7.m1.1.1.1.1.2.2.2.2.2.2.2.cmml" type="integer" xref="S3.E7.m1.1.1.1.1.2.2.2.2.2.2.2">1</cn></list></apply><apply id="S3.E7.m1.1.1.1.1.4.4.4.2.cmml" xref="S3.E7.m1.1.1.1.1.4.4.4.2"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.1.1.4.4.4.2.3.cmml" xref="S3.E7.m1.1.1.1.1.4.4.4.2">subscript</csymbol><ci id="S3.E7.m1.1.1.1.1.4.4.4.2.4.cmml" xref="S3.E7.m1.1.1.1.1.4.4.4.2.4">𝑐</ci><list id="S3.E7.m1.1.1.1.1.4.4.4.2.2.2.3.cmml" xref="S3.E7.m1.1.1.1.1.4.4.4.2.2.2.4"><cn id="S3.E7.m1.1.1.1.1.3.3.3.1.1.1.1.cmml" type="integer" xref="S3.E7.m1.1.1.1.1.3.3.3.1.1.1.1">1</cn><cn id="S3.E7.m1.1.1.1.1.4.4.4.2.2.2.2.cmml" type="integer" xref="S3.E7.m1.1.1.1.1.4.4.4.2.2.2.2">2</cn></list></apply><ci id="S3.E7.m1.1.1.1.1.6.6.7.1.cmml" xref="S3.E7.m1.1.1.1.1.6.6.7.1">⋯</ci><apply id="S3.E7.m1.1.1.1.1.6.6.6.2.cmml" xref="S3.E7.m1.1.1.1.1.6.6.6.2"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.1.1.6.6.6.2.3.cmml" xref="S3.E7.m1.1.1.1.1.6.6.6.2">subscript</csymbol><ci id="S3.E7.m1.1.1.1.1.6.6.6.2.4.cmml" xref="S3.E7.m1.1.1.1.1.6.6.6.2.4">𝑐</ci><list id="S3.E7.m1.1.1.1.1.6.6.6.2.2.2.3.cmml" xref="S3.E7.m1.1.1.1.1.6.6.6.2.2.2.4"><cn id="S3.E7.m1.1.1.1.1.5.5.5.1.1.1.1.cmml" type="integer" xref="S3.E7.m1.1.1.1.1.5.5.5.1.1.1.1">1</cn><ci id="S3.E7.m1.1.1.1.1.6.6.6.2.2.2.2.cmml" xref="S3.E7.m1.1.1.1.1.6.6.6.2.2.2.2">𝑛</ci></list></apply></matrixrow><matrixrow id="S3.E7.m1.1.1.1.1b.cmml" xref="S3.E7.m1.1.1.1.1"><apply id="S3.E7.m1.1.1.1.1.8.8.2.2.cmml" xref="S3.E7.m1.1.1.1.1.8.8.2.2"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.1.1.8.8.2.2.3.cmml" xref="S3.E7.m1.1.1.1.1.8.8.2.2">subscript</csymbol><ci id="S3.E7.m1.1.1.1.1.8.8.2.2.4.cmml" xref="S3.E7.m1.1.1.1.1.8.8.2.2.4">𝑐</ci><list id="S3.E7.m1.1.1.1.1.8.8.2.2.2.2.3.cmml" xref="S3.E7.m1.1.1.1.1.8.8.2.2.2.2.4"><cn id="S3.E7.m1.1.1.1.1.7.7.1.1.1.1.1.cmml" type="integer" xref="S3.E7.m1.1.1.1.1.7.7.1.1.1.1.1">2</cn><cn id="S3.E7.m1.1.1.1.1.8.8.2.2.2.2.2.cmml" type="integer" xref="S3.E7.m1.1.1.1.1.8.8.2.2.2.2.2">1</cn></list></apply><apply id="S3.E7.m1.1.1.1.1.10.10.4.2.cmml" xref="S3.E7.m1.1.1.1.1.10.10.4.2"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.1.1.10.10.4.2.3.cmml" xref="S3.E7.m1.1.1.1.1.10.10.4.2">subscript</csymbol><ci id="S3.E7.m1.1.1.1.1.10.10.4.2.4.cmml" xref="S3.E7.m1.1.1.1.1.10.10.4.2.4">𝑐</ci><list id="S3.E7.m1.1.1.1.1.10.10.4.2.2.2.3.cmml" xref="S3.E7.m1.1.1.1.1.10.10.4.2.2.2.4"><cn id="S3.E7.m1.1.1.1.1.9.9.3.1.1.1.1.cmml" type="integer" xref="S3.E7.m1.1.1.1.1.9.9.3.1.1.1.1">2</cn><cn id="S3.E7.m1.1.1.1.1.10.10.4.2.2.2.2.cmml" type="integer" xref="S3.E7.m1.1.1.1.1.10.10.4.2.2.2.2">2</cn></list></apply><ci id="S3.E7.m1.1.1.1.1.12.12.7.1.cmml" xref="S3.E7.m1.1.1.1.1.12.12.7.1">⋯</ci><apply id="S3.E7.m1.1.1.1.1.12.12.6.2.cmml" xref="S3.E7.m1.1.1.1.1.12.12.6.2"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.1.1.12.12.6.2.3.cmml" xref="S3.E7.m1.1.1.1.1.12.12.6.2">subscript</csymbol><ci id="S3.E7.m1.1.1.1.1.12.12.6.2.4.cmml" xref="S3.E7.m1.1.1.1.1.12.12.6.2.4">𝑐</ci><list id="S3.E7.m1.1.1.1.1.12.12.6.2.2.2.3.cmml" xref="S3.E7.m1.1.1.1.1.12.12.6.2.2.2.4"><cn id="S3.E7.m1.1.1.1.1.11.11.5.1.1.1.1.cmml" type="integer" xref="S3.E7.m1.1.1.1.1.11.11.5.1.1.1.1">2</cn><ci id="S3.E7.m1.1.1.1.1.12.12.6.2.2.2.2.cmml" xref="S3.E7.m1.1.1.1.1.12.12.6.2.2.2.2">𝑛</ci></list></apply></matrixrow><matrixrow id="S3.E7.m1.1.1.1.1c.cmml" xref="S3.E7.m1.1.1.1.1"><ci id="S3.E7.m1.1.1.1.1.19.1.1.cmml" xref="S3.E7.m1.1.1.1.1.19.1.1">⋮</ci><ci id="S3.E7.m1.1.1.1.1.19.2.1.cmml" xref="S3.E7.m1.1.1.1.1.19.2.1">⋮</ci><ci id="S3.E7.m1.1.1.1.1.19.3.1.cmml" xref="S3.E7.m1.1.1.1.1.19.3.1">⋱</ci><ci id="S3.E7.m1.1.1.1.1.19.4.1.cmml" xref="S3.E7.m1.1.1.1.1.19.4.1">⋮</ci></matrixrow><matrixrow id="S3.E7.m1.1.1.1.1d.cmml" xref="S3.E7.m1.1.1.1.1"><apply id="S3.E7.m1.1.1.1.1.14.14.2.2.cmml" xref="S3.E7.m1.1.1.1.1.14.14.2.2"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.1.1.14.14.2.2.3.cmml" xref="S3.E7.m1.1.1.1.1.14.14.2.2">subscript</csymbol><ci id="S3.E7.m1.1.1.1.1.14.14.2.2.4.cmml" xref="S3.E7.m1.1.1.1.1.14.14.2.2.4">𝑐</ci><list id="S3.E7.m1.1.1.1.1.14.14.2.2.2.2.3.cmml" xref="S3.E7.m1.1.1.1.1.14.14.2.2.2.2.4"><ci id="S3.E7.m1.1.1.1.1.13.13.1.1.1.1.1.cmml" xref="S3.E7.m1.1.1.1.1.13.13.1.1.1.1.1">𝑣</ci><cn id="S3.E7.m1.1.1.1.1.14.14.2.2.2.2.2.cmml" type="integer" xref="S3.E7.m1.1.1.1.1.14.14.2.2.2.2.2">1</cn></list></apply><apply id="S3.E7.m1.1.1.1.1.16.16.4.2.cmml" xref="S3.E7.m1.1.1.1.1.16.16.4.2"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.1.1.16.16.4.2.3.cmml" xref="S3.E7.m1.1.1.1.1.16.16.4.2">subscript</csymbol><ci id="S3.E7.m1.1.1.1.1.16.16.4.2.4.cmml" xref="S3.E7.m1.1.1.1.1.16.16.4.2.4">𝑐</ci><list id="S3.E7.m1.1.1.1.1.16.16.4.2.2.2.3.cmml" xref="S3.E7.m1.1.1.1.1.16.16.4.2.2.2.4"><ci id="S3.E7.m1.1.1.1.1.15.15.3.1.1.1.1.cmml" xref="S3.E7.m1.1.1.1.1.15.15.3.1.1.1.1">𝑣</ci><cn id="S3.E7.m1.1.1.1.1.16.16.4.2.2.2.2.cmml" type="integer" xref="S3.E7.m1.1.1.1.1.16.16.4.2.2.2.2">2</cn></list></apply><ci id="S3.E7.m1.1.1.1.1.18.18.7.1.cmml" xref="S3.E7.m1.1.1.1.1.18.18.7.1">⋯</ci><apply id="S3.E7.m1.1.1.1.1.18.18.6.2.cmml" xref="S3.E7.m1.1.1.1.1.18.18.6.2"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.1.1.18.18.6.2.3.cmml" xref="S3.E7.m1.1.1.1.1.18.18.6.2">subscript</csymbol><ci id="S3.E7.m1.1.1.1.1.18.18.6.2.4.cmml" xref="S3.E7.m1.1.1.1.1.18.18.6.2.4">𝑐</ci><list id="S3.E7.m1.1.1.1.1.18.18.6.2.2.2.3.cmml" xref="S3.E7.m1.1.1.1.1.18.18.6.2.2.2.4"><ci id="S3.E7.m1.1.1.1.1.17.17.5.1.1.1.1.cmml" xref="S3.E7.m1.1.1.1.1.17.17.5.1.1.1.1">𝑣</ci><ci id="S3.E7.m1.1.1.1.1.18.18.6.2.2.2.2.cmml" xref="S3.E7.m1.1.1.1.1.18.18.6.2.2.2.2">𝑛</ci></list></apply></matrixrow></matrix></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E7.m1.2c">\mathbf{C}=\begin{bmatrix}c_{1,1}&amp;c_{1,2}&amp;\cdots&amp;c_{1,n}\\
c_{2,1}&amp;c_{2,2}&amp;\cdots&amp;c_{2,n}\\
\vdots&amp;\vdots&amp;\ddots&amp;\vdots\\
c_{v,1}&amp;c_{v,2}&amp;\cdots&amp;c_{v,n}\end{bmatrix},</annotation><annotation encoding="application/x-llamapun" id="S3.E7.m1.2d">bold_C = [ start_ARG start_ROW start_CELL italic_c start_POSTSUBSCRIPT 1 , 1 end_POSTSUBSCRIPT end_CELL start_CELL italic_c start_POSTSUBSCRIPT 1 , 2 end_POSTSUBSCRIPT end_CELL start_CELL ⋯ end_CELL start_CELL italic_c start_POSTSUBSCRIPT 1 , italic_n end_POSTSUBSCRIPT end_CELL end_ROW start_ROW start_CELL italic_c start_POSTSUBSCRIPT 2 , 1 end_POSTSUBSCRIPT end_CELL start_CELL italic_c start_POSTSUBSCRIPT 2 , 2 end_POSTSUBSCRIPT end_CELL start_CELL ⋯ end_CELL start_CELL italic_c start_POSTSUBSCRIPT 2 , italic_n end_POSTSUBSCRIPT end_CELL end_ROW start_ROW start_CELL ⋮ end_CELL start_CELL ⋮ end_CELL start_CELL ⋱ end_CELL start_CELL ⋮ end_CELL end_ROW start_ROW start_CELL italic_c start_POSTSUBSCRIPT italic_v , 1 end_POSTSUBSCRIPT end_CELL start_CELL italic_c start_POSTSUBSCRIPT italic_v , 2 end_POSTSUBSCRIPT end_CELL start_CELL ⋯ end_CELL start_CELL italic_c start_POSTSUBSCRIPT italic_v , italic_n end_POSTSUBSCRIPT end_CELL end_ROW end_ARG ] ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS2.p3.5">where <math alttext="1\leq c_{i,j}\leq k" class="ltx_Math" display="inline" id="S3.SS2.p3.2.m1.2"><semantics id="S3.SS2.p3.2.m1.2a"><mrow id="S3.SS2.p3.2.m1.2.3" xref="S3.SS2.p3.2.m1.2.3.cmml"><mn id="S3.SS2.p3.2.m1.2.3.2" xref="S3.SS2.p3.2.m1.2.3.2.cmml">1</mn><mo id="S3.SS2.p3.2.m1.2.3.3" xref="S3.SS2.p3.2.m1.2.3.3.cmml">≤</mo><msub id="S3.SS2.p3.2.m1.2.3.4" xref="S3.SS2.p3.2.m1.2.3.4.cmml"><mi id="S3.SS2.p3.2.m1.2.3.4.2" xref="S3.SS2.p3.2.m1.2.3.4.2.cmml">c</mi><mrow id="S3.SS2.p3.2.m1.2.2.2.4" xref="S3.SS2.p3.2.m1.2.2.2.3.cmml"><mi id="S3.SS2.p3.2.m1.1.1.1.1" xref="S3.SS2.p3.2.m1.1.1.1.1.cmml">i</mi><mo id="S3.SS2.p3.2.m1.2.2.2.4.1" xref="S3.SS2.p3.2.m1.2.2.2.3.cmml">,</mo><mi id="S3.SS2.p3.2.m1.2.2.2.2" xref="S3.SS2.p3.2.m1.2.2.2.2.cmml">j</mi></mrow></msub><mo id="S3.SS2.p3.2.m1.2.3.5" xref="S3.SS2.p3.2.m1.2.3.5.cmml">≤</mo><mi id="S3.SS2.p3.2.m1.2.3.6" xref="S3.SS2.p3.2.m1.2.3.6.cmml">k</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.m1.2b"><apply id="S3.SS2.p3.2.m1.2.3.cmml" xref="S3.SS2.p3.2.m1.2.3"><and id="S3.SS2.p3.2.m1.2.3a.cmml" xref="S3.SS2.p3.2.m1.2.3"></and><apply id="S3.SS2.p3.2.m1.2.3b.cmml" xref="S3.SS2.p3.2.m1.2.3"><leq id="S3.SS2.p3.2.m1.2.3.3.cmml" xref="S3.SS2.p3.2.m1.2.3.3"></leq><cn id="S3.SS2.p3.2.m1.2.3.2.cmml" type="integer" xref="S3.SS2.p3.2.m1.2.3.2">1</cn><apply id="S3.SS2.p3.2.m1.2.3.4.cmml" xref="S3.SS2.p3.2.m1.2.3.4"><csymbol cd="ambiguous" id="S3.SS2.p3.2.m1.2.3.4.1.cmml" xref="S3.SS2.p3.2.m1.2.3.4">subscript</csymbol><ci id="S3.SS2.p3.2.m1.2.3.4.2.cmml" xref="S3.SS2.p3.2.m1.2.3.4.2">𝑐</ci><list id="S3.SS2.p3.2.m1.2.2.2.3.cmml" xref="S3.SS2.p3.2.m1.2.2.2.4"><ci id="S3.SS2.p3.2.m1.1.1.1.1.cmml" xref="S3.SS2.p3.2.m1.1.1.1.1">𝑖</ci><ci id="S3.SS2.p3.2.m1.2.2.2.2.cmml" xref="S3.SS2.p3.2.m1.2.2.2.2">𝑗</ci></list></apply></apply><apply id="S3.SS2.p3.2.m1.2.3c.cmml" xref="S3.SS2.p3.2.m1.2.3"><leq id="S3.SS2.p3.2.m1.2.3.5.cmml" xref="S3.SS2.p3.2.m1.2.3.5"></leq><share href="https://arxiv.org/html/2409.07276v2#S3.SS2.p3.2.m1.2.3.4.cmml" id="S3.SS2.p3.2.m1.2.3d.cmml" xref="S3.SS2.p3.2.m1.2.3"></share><ci id="S3.SS2.p3.2.m1.2.3.6.cmml" xref="S3.SS2.p3.2.m1.2.3.6">𝑘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.2.m1.2c">1\leq c_{i,j}\leq k</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.2.m1.2d">1 ≤ italic_c start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT ≤ italic_k</annotation></semantics></math> represents the cluster indices, and <math alttext="k" class="ltx_Math" display="inline" id="S3.SS2.p3.3.m2.1"><semantics id="S3.SS2.p3.3.m2.1a"><mi id="S3.SS2.p3.3.m2.1.1" xref="S3.SS2.p3.3.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.3.m2.1b"><ci id="S3.SS2.p3.3.m2.1.1.cmml" xref="S3.SS2.p3.3.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.3.m2.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.3.m2.1d">italic_k</annotation></semantics></math> is the number of clusters. Thus, each item can be represented by <math alttext="v" class="ltx_Math" display="inline" id="S3.SS2.p3.4.m3.1"><semantics id="S3.SS2.p3.4.m3.1a"><mi id="S3.SS2.p3.4.m3.1.1" xref="S3.SS2.p3.4.m3.1.1.cmml">v</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.4.m3.1b"><ci id="S3.SS2.p3.4.m3.1.1.cmml" xref="S3.SS2.p3.4.m3.1.1">𝑣</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.4.m3.1c">v</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.4.m3.1d">italic_v</annotation></semantics></math> discrete tokens: <math alttext="\mathbf{c}_{j}=[c_{1,j},c_{2,j},\ldots,c_{v,j}]" class="ltx_Math" display="inline" id="S3.SS2.p3.5.m4.10"><semantics id="S3.SS2.p3.5.m4.10a"><mrow id="S3.SS2.p3.5.m4.10.10" xref="S3.SS2.p3.5.m4.10.10.cmml"><msub id="S3.SS2.p3.5.m4.10.10.5" xref="S3.SS2.p3.5.m4.10.10.5.cmml"><mi id="S3.SS2.p3.5.m4.10.10.5.2" xref="S3.SS2.p3.5.m4.10.10.5.2.cmml">𝐜</mi><mi id="S3.SS2.p3.5.m4.10.10.5.3" xref="S3.SS2.p3.5.m4.10.10.5.3.cmml">j</mi></msub><mo id="S3.SS2.p3.5.m4.10.10.4" xref="S3.SS2.p3.5.m4.10.10.4.cmml">=</mo><mrow id="S3.SS2.p3.5.m4.10.10.3.3" xref="S3.SS2.p3.5.m4.10.10.3.4.cmml"><mo id="S3.SS2.p3.5.m4.10.10.3.3.4" stretchy="false" xref="S3.SS2.p3.5.m4.10.10.3.4.cmml">[</mo><msub id="S3.SS2.p3.5.m4.8.8.1.1.1" xref="S3.SS2.p3.5.m4.8.8.1.1.1.cmml"><mi id="S3.SS2.p3.5.m4.8.8.1.1.1.2" xref="S3.SS2.p3.5.m4.8.8.1.1.1.2.cmml">c</mi><mrow id="S3.SS2.p3.5.m4.2.2.2.4" xref="S3.SS2.p3.5.m4.2.2.2.3.cmml"><mn id="S3.SS2.p3.5.m4.1.1.1.1" xref="S3.SS2.p3.5.m4.1.1.1.1.cmml">1</mn><mo id="S3.SS2.p3.5.m4.2.2.2.4.1" xref="S3.SS2.p3.5.m4.2.2.2.3.cmml">,</mo><mi id="S3.SS2.p3.5.m4.2.2.2.2" xref="S3.SS2.p3.5.m4.2.2.2.2.cmml">j</mi></mrow></msub><mo id="S3.SS2.p3.5.m4.10.10.3.3.5" xref="S3.SS2.p3.5.m4.10.10.3.4.cmml">,</mo><msub id="S3.SS2.p3.5.m4.9.9.2.2.2" xref="S3.SS2.p3.5.m4.9.9.2.2.2.cmml"><mi id="S3.SS2.p3.5.m4.9.9.2.2.2.2" xref="S3.SS2.p3.5.m4.9.9.2.2.2.2.cmml">c</mi><mrow id="S3.SS2.p3.5.m4.4.4.2.4" xref="S3.SS2.p3.5.m4.4.4.2.3.cmml"><mn id="S3.SS2.p3.5.m4.3.3.1.1" xref="S3.SS2.p3.5.m4.3.3.1.1.cmml">2</mn><mo id="S3.SS2.p3.5.m4.4.4.2.4.1" xref="S3.SS2.p3.5.m4.4.4.2.3.cmml">,</mo><mi id="S3.SS2.p3.5.m4.4.4.2.2" xref="S3.SS2.p3.5.m4.4.4.2.2.cmml">j</mi></mrow></msub><mo id="S3.SS2.p3.5.m4.10.10.3.3.6" xref="S3.SS2.p3.5.m4.10.10.3.4.cmml">,</mo><mi id="S3.SS2.p3.5.m4.7.7" mathvariant="normal" xref="S3.SS2.p3.5.m4.7.7.cmml">…</mi><mo id="S3.SS2.p3.5.m4.10.10.3.3.7" xref="S3.SS2.p3.5.m4.10.10.3.4.cmml">,</mo><msub id="S3.SS2.p3.5.m4.10.10.3.3.3" xref="S3.SS2.p3.5.m4.10.10.3.3.3.cmml"><mi id="S3.SS2.p3.5.m4.10.10.3.3.3.2" xref="S3.SS2.p3.5.m4.10.10.3.3.3.2.cmml">c</mi><mrow id="S3.SS2.p3.5.m4.6.6.2.4" xref="S3.SS2.p3.5.m4.6.6.2.3.cmml"><mi id="S3.SS2.p3.5.m4.5.5.1.1" xref="S3.SS2.p3.5.m4.5.5.1.1.cmml">v</mi><mo id="S3.SS2.p3.5.m4.6.6.2.4.1" xref="S3.SS2.p3.5.m4.6.6.2.3.cmml">,</mo><mi id="S3.SS2.p3.5.m4.6.6.2.2" xref="S3.SS2.p3.5.m4.6.6.2.2.cmml">j</mi></mrow></msub><mo id="S3.SS2.p3.5.m4.10.10.3.3.8" stretchy="false" xref="S3.SS2.p3.5.m4.10.10.3.4.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.5.m4.10b"><apply id="S3.SS2.p3.5.m4.10.10.cmml" xref="S3.SS2.p3.5.m4.10.10"><eq id="S3.SS2.p3.5.m4.10.10.4.cmml" xref="S3.SS2.p3.5.m4.10.10.4"></eq><apply id="S3.SS2.p3.5.m4.10.10.5.cmml" xref="S3.SS2.p3.5.m4.10.10.5"><csymbol cd="ambiguous" id="S3.SS2.p3.5.m4.10.10.5.1.cmml" xref="S3.SS2.p3.5.m4.10.10.5">subscript</csymbol><ci id="S3.SS2.p3.5.m4.10.10.5.2.cmml" xref="S3.SS2.p3.5.m4.10.10.5.2">𝐜</ci><ci id="S3.SS2.p3.5.m4.10.10.5.3.cmml" xref="S3.SS2.p3.5.m4.10.10.5.3">𝑗</ci></apply><list id="S3.SS2.p3.5.m4.10.10.3.4.cmml" xref="S3.SS2.p3.5.m4.10.10.3.3"><apply id="S3.SS2.p3.5.m4.8.8.1.1.1.cmml" xref="S3.SS2.p3.5.m4.8.8.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.5.m4.8.8.1.1.1.1.cmml" xref="S3.SS2.p3.5.m4.8.8.1.1.1">subscript</csymbol><ci id="S3.SS2.p3.5.m4.8.8.1.1.1.2.cmml" xref="S3.SS2.p3.5.m4.8.8.1.1.1.2">𝑐</ci><list id="S3.SS2.p3.5.m4.2.2.2.3.cmml" xref="S3.SS2.p3.5.m4.2.2.2.4"><cn id="S3.SS2.p3.5.m4.1.1.1.1.cmml" type="integer" xref="S3.SS2.p3.5.m4.1.1.1.1">1</cn><ci id="S3.SS2.p3.5.m4.2.2.2.2.cmml" xref="S3.SS2.p3.5.m4.2.2.2.2">𝑗</ci></list></apply><apply id="S3.SS2.p3.5.m4.9.9.2.2.2.cmml" xref="S3.SS2.p3.5.m4.9.9.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p3.5.m4.9.9.2.2.2.1.cmml" xref="S3.SS2.p3.5.m4.9.9.2.2.2">subscript</csymbol><ci id="S3.SS2.p3.5.m4.9.9.2.2.2.2.cmml" xref="S3.SS2.p3.5.m4.9.9.2.2.2.2">𝑐</ci><list id="S3.SS2.p3.5.m4.4.4.2.3.cmml" xref="S3.SS2.p3.5.m4.4.4.2.4"><cn id="S3.SS2.p3.5.m4.3.3.1.1.cmml" type="integer" xref="S3.SS2.p3.5.m4.3.3.1.1">2</cn><ci id="S3.SS2.p3.5.m4.4.4.2.2.cmml" xref="S3.SS2.p3.5.m4.4.4.2.2">𝑗</ci></list></apply><ci id="S3.SS2.p3.5.m4.7.7.cmml" xref="S3.SS2.p3.5.m4.7.7">…</ci><apply id="S3.SS2.p3.5.m4.10.10.3.3.3.cmml" xref="S3.SS2.p3.5.m4.10.10.3.3.3"><csymbol cd="ambiguous" id="S3.SS2.p3.5.m4.10.10.3.3.3.1.cmml" xref="S3.SS2.p3.5.m4.10.10.3.3.3">subscript</csymbol><ci id="S3.SS2.p3.5.m4.10.10.3.3.3.2.cmml" xref="S3.SS2.p3.5.m4.10.10.3.3.3.2">𝑐</ci><list id="S3.SS2.p3.5.m4.6.6.2.3.cmml" xref="S3.SS2.p3.5.m4.6.6.2.4"><ci id="S3.SS2.p3.5.m4.5.5.1.1.cmml" xref="S3.SS2.p3.5.m4.5.5.1.1">𝑣</ci><ci id="S3.SS2.p3.5.m4.6.6.2.2.cmml" xref="S3.SS2.p3.5.m4.6.6.2.2">𝑗</ci></list></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.5.m4.10c">\mathbf{c}_{j}=[c_{1,j},c_{2,j},\ldots,c_{v,j}]</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.5.m4.10d">bold_c start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT = [ italic_c start_POSTSUBSCRIPT 1 , italic_j end_POSTSUBSCRIPT , italic_c start_POSTSUBSCRIPT 2 , italic_j end_POSTSUBSCRIPT , … , italic_c start_POSTSUBSCRIPT italic_v , italic_j end_POSTSUBSCRIPT ]</annotation></semantics></math>.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3. </span>Generative Recommender</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">Like other item tokenization approaches, the discrete tokens generated by the clusterer can be utilized in generative sequential recommendation. Since the dense tokens are derived from a large language model, we employ the same model as the backbone for both scenarios. Additionally, we have designed a text-token alignment task to enhance the token comprehension capabilities of large language models.</p>
</div>
<div class="ltx_para" id="S3.SS3.p2">
<p class="ltx_p" id="S3.SS3.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS3.p2.1.1">Training.</span> We construct a new vocabulary incorporating the semantic tokens. As illustrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#S3.F5" title="Figure 5 ‣ 3.1. Dense Tokenizer ‣ 3. Proposed Approach: STORE ‣ STORE: Streamlining Semantic Tokenization and Generative Recommendation with A Single LLM"><span class="ltx_text ltx_ref_tag">5</span></a>, the training involves the instruction tuning for both sequential recommendation and an additional text-token alignment tasks. The backbone model is also equipped with low-rank adaptation technique.</p>
</div>
<div class="ltx_para" id="S3.SS3.p3">
<p class="ltx_p" id="S3.SS3.p3.1"><span class="ltx_text ltx_font_bold" id="S3.SS3.p3.1.1">Inference.</span> We devise conditional beam search to generate the next item. Initially, we construct a code (i.e., token) tree, as illustrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#S3.F6" title="Figure 6 ‣ 3.1. Dense Tokenizer ‣ 3. Proposed Approach: STORE ‣ STORE: Streamlining Semantic Tokenization and Generative Recommendation with A Single LLM"><span class="ltx_text ltx_ref_tag">6</span></a>, which accommodates all possible code combinations. During the beam search, we set the code logits from the classification module to zero for any combinations that do not appear in the tree paths.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>Experiments</h2>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1. </span>Experimental Setup</h3>
<figure class="ltx_table" id="S4.T1">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1. </span>Dataset statistics.</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.T1.1">
<tr class="ltx_tr" id="S4.T1.1.1">
<td class="ltx_td ltx_border_r ltx_border_tt" id="S4.T1.1.1.1" style="padding-top:1pt;padding-bottom:1pt;"></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="S4.T1.1.1.2" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.2.1">MIND</span></td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="S4.T1.1.1.3" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.3.1">Yelp</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.2">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T1.1.2.1" style="padding-top:1pt;padding-bottom:1pt;">#Items</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T1.1.2.2" style="padding-top:1pt;padding-bottom:1pt;">25,634</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T1.1.2.3" style="padding-top:1pt;padding-bottom:1pt;">73,380</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.3">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.3.1" style="padding-top:1pt;padding-bottom:1pt;">#Users</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.3.2" style="padding-top:1pt;padding-bottom:1pt;">45,000</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.3.3" style="padding-top:1pt;padding-bottom:1pt;">45,000</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.4">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.4.1" style="padding-top:1pt;padding-bottom:1pt;">#Finetune</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.4.2" style="padding-top:1pt;padding-bottom:1pt;">40,000</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.4.3" style="padding-top:1pt;padding-bottom:1pt;">40,000</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.5">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.5.1" style="padding-top:1pt;padding-bottom:1pt;">#Test</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.5.2" style="padding-top:1pt;padding-bottom:1pt;">5,000</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.5.3" style="padding-top:1pt;padding-bottom:1pt;">5,000</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.6">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.6.1" style="padding-top:1pt;padding-bottom:1pt;">Avg. User Length</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.6.2" style="padding-top:1pt;padding-bottom:1pt;">11.78</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.6.3" style="padding-top:1pt;padding-bottom:1pt;">6.47</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.7">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" id="S4.T1.1.7.1" style="padding-top:1pt;padding-bottom:1pt;">Avg. Item Appearance</td>
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" id="S4.T1.1.7.2" style="padding-top:1pt;padding-bottom:1pt;">20.69</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T1.1.7.3" style="padding-top:1pt;padding-bottom:1pt;">3.97</td>
</tr>
</table>
</figure>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.p1.1.1">Datasets.</span>
We conduct experiments on two real-world content-based recommendation dataset, i.e., news recommendation dataset MIND <cite class="ltx_cite ltx_citemacro_citep">(Wu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib39" title="">2020a</a>)</cite> and restaurant recommendation dataset Yelp<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.yelp.com/dataset" title="">https://www.yelp.com/dataset</a></span></span></span>. The dataset statistics are summarized in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#S4.T1" title="Table 1 ‣ 4.1. Experimental Setup ‣ 4. Experiments ‣ STORE: Streamlining Semantic Tokenization and Generative Recommendation with A Single LLM"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<div class="ltx_para" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.p2.1.1">Baseline models.</span>
We benchmark our proposed STORE framework against unique id-based recommenders (SASRec <cite class="ltx_cite ltx_citemacro_citep">(Kang and McAuley, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib13" title="">2018</a>)</cite> and P5 <cite class="ltx_cite ltx_citemacro_citep">(Geng et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib7" title="">2022</a>)</cite>) and semantic code-based recommenders (TIGER <cite class="ltx_cite ltx_citemacro_citep">(Rajput et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib29" title="">2024</a>)</cite> and LC-Rec <cite class="ltx_cite ltx_citemacro_citep">(Zheng et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib45" title="">2024</a>)</cite>). Specifically, SASRec employs a multi-layer attention network with causal attention, utilizing unique identifiers and trained on a next-item prediction task. P5 integrates unique item identifiers into large language models. TIGER and LC-Rec use pretrained SentenceBERT <cite class="ltx_cite ltx_citemacro_citep">(Reimers and Gurevych, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib30" title="">2019</a>)</cite> and Llama-1 to extract item content embeddings, respectively. For a fair comparison, all code-based recommenders, i.e., TIGER, LC-Rec, and our STORE, represent each item using four codes, with a fixed code vocabulary of 256 at each position.</p>
</div>
<div class="ltx_para" id="S4.SS1.p3">
<p class="ltx_p" id="S4.SS1.p3.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.p3.1.1">Evaluation Metrics.</span> We follow the common practice <cite class="ltx_cite ltx_citemacro_citep">(Rajput et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib29" title="">2024</a>; Qu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib28" title="">2024</a>)</cite> to evaluate the effectiveness of sequential recommenders with the widely used metrics, i.e., Recall and NDCG <cite class="ltx_cite ltx_citemacro_citep">(Järvelin and Kekäläinen, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib11" title="">2002</a>)</cite>. In this work, we use Recall@1, Recall@5, Recall@10, Recall@20, NDCG@1, NDCG@5, NDCG@10, and NDCG@20 for evaluation.</p>
</div>
<div class="ltx_para" id="S4.SS1.p4">
<p class="ltx_p" id="S4.SS1.p4.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.p4.1.1">Implementation Details.</span> <span class="ltx_text ltx_font_italic" id="S4.SS1.p4.1.2">i) Tokenizer.</span> We utilize the pretrained OPT-base <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib43" title="">2022</a>)</cite> as the backbone large language model for dense tokenization. Optimization is performed using the Adam <cite class="ltx_cite ltx_citemacro_citep">(Kingma and Ba, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib14" title="">2015</a>)</cite> optimizer with a learning rate of 1e-4, a batch size of 512, a LoRA rank of 32, and a token block size <math alttext="v" class="ltx_Math" display="inline" id="S4.SS1.p4.1.m1.1"><semantics id="S4.SS1.p4.1.m1.1a"><mi id="S4.SS1.p4.1.m1.1.1" xref="S4.SS1.p4.1.m1.1.1.cmml">v</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p4.1.m1.1b"><ci id="S4.SS1.p4.1.m1.1.1.cmml" xref="S4.SS1.p4.1.m1.1.1">𝑣</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p4.1.m1.1c">v</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p4.1.m1.1d">italic_v</annotation></semantics></math> of 4. Self-supervised tasks are detailed in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#S4.T2" title="Table 2 ‣ 4.1. Experimental Setup ‣ 4. Experiments ‣ STORE: Streamlining Semantic Tokenization and Generative Recommendation with A Single LLM"><span class="ltx_text ltx_ref_tag">2</span></a>. <span class="ltx_text ltx_font_italic" id="S4.SS1.p4.1.3">ii) Clusterer.</span> We apply PCA <cite class="ltx_cite ltx_citemacro_citep">(Maćkiewicz and Ratajczak, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib24" title="">1993</a>)</cite> to reduce 1024-dimensional item embeddings to 32 components, subsequently clustering each position into 256 groups. <span class="ltx_text ltx_font_italic" id="S4.SS1.p4.1.4">iii) Recommender.</span> We set the maximum length of user history sequence to 20 and we use the last item in the sequence as the prediction target. We use the same pretrained OPT-base as the backbone with a learning rate of 5e-4, a batch size of 64 and a LoRA rank of 128. The training starts with the joint learning of generative recommendation task and text-token alignment task. After model convergence, the model will further be tuned by the single generative recommendation task. Early stopping mechanism is used with patience of 5. All the experiments are conducted on a single NVIDIA A100 device with 80GB memory. We release all our code and data here<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://anonymous.4open.science/r/STORE/" title="">https://anonymous.4open.science/r/STORE/</a></span></span></span> for other researches to reproduce our work. We employ <span class="ltx_text ltx_font_italic" id="S4.SS1.p4.1.5">Recability<span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_upright" id="footnote5.1.1.1">5</span></span><a class="ltx_ref ltx_url ltx_font_typewriter ltx_font_upright" href="https://github.com/Recability" title="">https://github.com/Recability</a></span></span></span></span>, a benchmark for evaluating the recommendation abilities of large language models, for most of our experiments.</p>
</div>
<figure class="ltx_table" id="S4.T2">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2. </span>Statistics of post-pretraining tasks.</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.T2.4">
<tr class="ltx_tr" id="S4.T2.4.5">
<td class="ltx_td ltx_border_r ltx_border_tt" id="S4.T2.4.5.1" style="padding-top:1pt;padding-bottom:1pt;"></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S4.T2.4.5.2" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.4.5.2.1">Content Block</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.4.5.3" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.4.5.3.1">Generation Target</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.2.2">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.2.2.2" rowspan="4" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text" id="S4.T2.2.2.2.2">
<span class="ltx_tabular ltx_align_middle" id="S4.T2.2.2.2.2.2">
<span class="ltx_tr" id="S4.T2.2.2.2.2.2.3">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T2.2.2.2.2.2.3.1" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.2.2.2.2.2.3.1.1">MIND</span></span></span>
<span class="ltx_tr" id="S4.T2.2.2.2.2.2.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T2.2.2.2.2.2.2.2" style="padding-top:1pt;padding-bottom:1pt;">(<math alttext="m" class="ltx_Math" display="inline" id="S4.T2.1.1.1.1.1.1.1.m1.1"><semantics id="S4.T2.1.1.1.1.1.1.1.m1.1a"><mi id="S4.T2.1.1.1.1.1.1.1.m1.1.1" xref="S4.T2.1.1.1.1.1.1.1.m1.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S4.T2.1.1.1.1.1.1.1.m1.1b"><ci id="S4.T2.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S4.T2.1.1.1.1.1.1.1.m1.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.1.1.1.1.1.1.1.m1.1c">m</annotation><annotation encoding="application/x-llamapun" id="S4.T2.1.1.1.1.1.1.1.m1.1d">italic_m</annotation></semantics></math>=4, <math alttext="k" class="ltx_Math" display="inline" id="S4.T2.2.2.2.2.2.2.2.m2.1"><semantics id="S4.T2.2.2.2.2.2.2.2.m2.1a"><mi id="S4.T2.2.2.2.2.2.2.2.m2.1.1" xref="S4.T2.2.2.2.2.2.2.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.T2.2.2.2.2.2.2.2.m2.1b"><ci id="S4.T2.2.2.2.2.2.2.2.m2.1.1.cmml" xref="S4.T2.2.2.2.2.2.2.2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.2.2.2.2.2.2.2.m2.1c">k</annotation><annotation encoding="application/x-llamapun" id="S4.T2.2.2.2.2.2.2.2.m2.1d">italic_k</annotation></semantics></math>=2)</span></span>
</span></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.2.2.3" style="padding-top:1pt;padding-bottom:1pt;">(title, abstract)</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.2.2.4" style="padding-top:1pt;padding-bottom:1pt;">title</td>
</tr>
<tr class="ltx_tr" id="S4.T2.4.6">
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.4.6.1" style="padding-top:1pt;padding-bottom:1pt;">(title, abstract)</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.6.2" style="padding-top:1pt;padding-bottom:1pt;">abstract</td>
</tr>
<tr class="ltx_tr" id="S4.T2.4.7">
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.4.7.1" style="padding-top:1pt;padding-bottom:1pt;">(title, abstract)</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.7.2" style="padding-top:1pt;padding-bottom:1pt;">category</td>
</tr>
<tr class="ltx_tr" id="S4.T2.4.8">
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.4.8.1" style="padding-top:1pt;padding-bottom:1pt;">(title, abstract)</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.8.2" style="padding-top:1pt;padding-bottom:1pt;">subcategory</td>
</tr>
<tr class="ltx_tr" id="S4.T2.4.4">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S4.T2.4.4.2" rowspan="4" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text" id="S4.T2.4.4.2.2">
<span class="ltx_tabular ltx_align_middle" id="S4.T2.4.4.2.2.2">
<span class="ltx_tr" id="S4.T2.4.4.2.2.2.3">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T2.4.4.2.2.2.3.1" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.4.4.2.2.2.3.1.1">Yelp</span></span></span>
<span class="ltx_tr" id="S4.T2.4.4.2.2.2.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T2.4.4.2.2.2.2.2" style="padding-top:1pt;padding-bottom:1pt;">(<math alttext="m" class="ltx_Math" display="inline" id="S4.T2.3.3.1.1.1.1.1.m1.1"><semantics id="S4.T2.3.3.1.1.1.1.1.m1.1a"><mi id="S4.T2.3.3.1.1.1.1.1.m1.1.1" xref="S4.T2.3.3.1.1.1.1.1.m1.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S4.T2.3.3.1.1.1.1.1.m1.1b"><ci id="S4.T2.3.3.1.1.1.1.1.m1.1.1.cmml" xref="S4.T2.3.3.1.1.1.1.1.m1.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.3.3.1.1.1.1.1.m1.1c">m</annotation><annotation encoding="application/x-llamapun" id="S4.T2.3.3.1.1.1.1.1.m1.1d">italic_m</annotation></semantics></math>=4, <math alttext="k" class="ltx_Math" display="inline" id="S4.T2.4.4.2.2.2.2.2.m2.1"><semantics id="S4.T2.4.4.2.2.2.2.2.m2.1a"><mi id="S4.T2.4.4.2.2.2.2.2.m2.1.1" xref="S4.T2.4.4.2.2.2.2.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.T2.4.4.2.2.2.2.2.m2.1b"><ci id="S4.T2.4.4.2.2.2.2.2.m2.1.1.cmml" xref="S4.T2.4.4.2.2.2.2.2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.4.4.2.2.2.2.2.m2.1c">k</annotation><annotation encoding="application/x-llamapun" id="S4.T2.4.4.2.2.2.2.2.m2.1d">italic_k</annotation></semantics></math>=3)</span></span>
</span></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.4.4.3" style="padding-top:1pt;padding-bottom:1pt;">(name, city, address)</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.4.4.4" style="padding-top:1pt;padding-bottom:1pt;">name</td>
</tr>
<tr class="ltx_tr" id="S4.T2.4.9">
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.4.9.1" style="padding-top:1pt;padding-bottom:1pt;">(name, city, address)</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.9.2" style="padding-top:1pt;padding-bottom:1pt;">city</td>
</tr>
<tr class="ltx_tr" id="S4.T2.4.10">
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.4.10.1" style="padding-top:1pt;padding-bottom:1pt;">(name, city, address)</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.10.2" style="padding-top:1pt;padding-bottom:1pt;">address</td>
</tr>
<tr class="ltx_tr" id="S4.T2.4.11">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T2.4.11.1" style="padding-top:1pt;padding-bottom:1pt;">(name, city, address)</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.4.11.2" style="padding-top:1pt;padding-bottom:1pt;">state</td>
</tr>
</table>
</figure>
<figure class="ltx_table" id="S4.T3">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 3. </span>Overall performance comparison in retrieval scenarios. We use R and N to represent the Recall and NDCG metrics, respectively.</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.T3.3">
<tr class="ltx_tr" id="S4.T3.3.1">
<td class="ltx_td ltx_border_tt" id="S4.T3.3.1.1" style="padding:0.9pt 5.0pt;"></td>
<td class="ltx_td ltx_border_r ltx_border_tt" id="S4.T3.3.1.2" style="padding:0.9pt 5.0pt;"></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="6" id="S4.T3.3.1.3" style="padding:0.9pt 5.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.3.1.3.1" style="font-size:90%;">MIND</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="6" id="S4.T3.3.1.4" style="padding:0.9pt 5.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.3.1.4.1" style="font-size:90%;">Yelp</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.3.2">
<td class="ltx_td ltx_align_center" id="S4.T3.3.2.1" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.2.1.1" style="font-size:90%;">Identifier</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.3.2.2" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.2.2.1" style="font-size:90%;">Backbone</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.3.2.3" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.2.3.1" style="font-size:90%;">R@5</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.3.2.4" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.2.4.1" style="font-size:90%;">R@10</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.3.2.5" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.2.5.1" style="font-size:90%;">R@20</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.3.2.6" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.2.6.1" style="font-size:90%;">N@5</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.3.2.7" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.2.7.1" style="font-size:90%;">N@10</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.3.2.8" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.2.8.1" style="font-size:90%;">N@20</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.3.2.9" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.2.9.1" style="font-size:90%;">R@5</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.3.2.10" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.2.10.1" style="font-size:90%;">R@10</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.3.2.11" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.2.11.1" style="font-size:90%;">R@20</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.3.2.12" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.2.12.1" style="font-size:90%;">N@5</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.3.2.13" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.2.13.1" style="font-size:90%;">N@10</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.3.2.14" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.2.14.1" style="font-size:90%;">N@20</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.3.3">
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.3.3.1" rowspan="2" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.3.1.1" style="font-size:90%;">Unique ID</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.3.3.2" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.3.2.1" style="font-size:90%;">SASRec</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.3.3.3" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.3.3.1" style="font-size:90%;">0.0076</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.3.3.4" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.3.4.1" style="font-size:90%;">0.0086</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.3.3.5" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.3.5.1" style="font-size:90%;">0.0096</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.3.3.6" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.3.6.1" style="font-size:90%;">0.0181</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.3.3.7" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.3.7.1" style="font-size:90%;">0.0242</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.3.3.8" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.3.8.1" style="font-size:90%;">0.0308</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.3.3.9" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.3.9.1" style="font-size:90%;">0.0000</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.3.3.10" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.3.10.1" style="font-size:90%;">0.0002</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.3.3.11" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.3.11.1" style="font-size:90%;">0.0002</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.3.3.12" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.3.12.1" style="font-size:90%;">0.0002</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.3.3.13" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.3.13.1" style="font-size:90%;">0.0002</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.3.3.14" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.3.14.1" style="font-size:90%;">0.0003</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.3.4">
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.3.4.1" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.4.1.1" style="font-size:90%;">P5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.3.4.2" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.4.2.1" style="font-size:90%;">0.0068</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.3.4.3" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.4.3.1" style="font-size:90%;">0.0082</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.3.4.4" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.4.4.1" style="font-size:90%;">0.0089</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.3.4.5" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.4.5.1" style="font-size:90%;">0.0158</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.3.4.6" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.4.6.1" style="font-size:90%;">0.0204</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.3.4.7" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.4.7.1" style="font-size:90%;">0.0249</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.3.4.8" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.4.8.1" style="font-size:90%;">0.0000</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.3.4.9" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.4.9.1" style="font-size:90%;">0.0002</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.3.4.10" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.4.10.1" style="font-size:90%;">0.0002</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.3.4.11" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.4.11.1" style="font-size:90%;">0.0002</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.3.4.12" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.4.12.1" style="font-size:90%;">0.0002</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.3.4.13" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.4.13.1" style="font-size:90%;">0.0003</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.3.5">
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.3.5.1" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.5.1.1" style="font-size:90%;">TIGER</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.3.5.2" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.5.2.1" style="font-size:90%;">Transformer</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.3.5.3" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.5.3.1" style="font-size:90%;">0.0168</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.3.5.4" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.5.4.1" style="font-size:90%;">0.0256</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.3.5.5" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.5.5.1" style="font-size:90%;">0.0370</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.3.5.6" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.5.6.1" style="font-size:90%;">0.0422</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.3.5.7" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.5.7.1" style="font-size:90%;">0.0565</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.3.5.8" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.5.8.1" style="font-size:90%;">0.0717</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.3.5.9" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.5.9.1" style="font-size:90%;">0.0044</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.3.5.10" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.5.10.1" style="font-size:90%;">0.0064</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.3.5.11" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.5.11.1" style="font-size:90%;">0.0082</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.3.5.12" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.5.12.1" style="font-size:90%;">0.0113</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.3.5.13" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.5.13.1" style="font-size:90%;">0.0152</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.3.5.14" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.5.14.1" style="font-size:90%;">0.0193</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.3.6">
<td class="ltx_td ltx_align_center" id="S4.T3.3.6.1" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.6.1.1" style="font-size:90%;">TIGER</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.3.6.2" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.6.2.1" style="font-size:90%;">OPT-base</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.3.6.3" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.6.3.1" style="font-size:90%;">0.0173</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.3.6.4" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.6.4.1" style="font-size:90%;">0.0272</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.3.6.5" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.6.5.1" style="font-size:90%;">0.0394</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.3.6.6" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.6.6.1" style="font-size:90%;">0.0424</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.3.6.7" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.6.7.1" style="font-size:90%;">0.0577</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.3.6.8" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.6.8.1" style="font-size:90%;">0.0720</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.3.6.9" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.6.9.1" style="font-size:90%;">0.0044</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.3.6.10" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.6.10.1" style="font-size:90%;">0.0062</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.3.6.11" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.6.11.1" style="font-size:90%;">0.0088</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.3.6.12" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.6.12.1" style="font-size:90%;">0.0114</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.3.6.13" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.6.13.1" style="font-size:90%;">0.0150</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.3.6.14" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.6.14.1" style="font-size:90%;">0.0198</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.3.7">
<td class="ltx_td ltx_align_center" id="S4.T3.3.7.1" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.7.1.1" style="font-size:90%;">LC-Rec</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.3.7.2" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.7.2.1" style="font-size:90%;">OPT-base</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.3.7.3" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.7.3.1" style="font-size:90%;">0.0288</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.3.7.4" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.7.4.1" style="font-size:90%;">0.0428</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.3.7.5" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.7.5.1" style="font-size:90%;">0.0594</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.3.7.6" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.7.6.1" style="font-size:90%;">0.0654</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.3.7.7" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.7.7.1" style="font-size:90%;">0.0875</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.3.7.8" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.7.8.1" style="font-size:90%;">0.1111</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.3.7.9" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.7.9.1" style="font-size:90%;">0.0082</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.3.7.10" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.7.10.1" style="font-size:90%;">0.0108</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.3.7.11" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.7.11.1" style="font-size:90%;">0.0140</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.3.7.12" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.7.12.1" style="font-size:90%;">0.0192</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.3.7.13" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.7.13.1" style="font-size:90%;">0.0257</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.3.7.14" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.7.14.1" style="font-size:90%;">0.0327</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.3.8">
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.3.8.1" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.8.1.1" style="font-size:90%;">STORE (ours)</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T3.3.8.2" style="padding:0.9pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.8.2.1" style="font-size:90%;">OPT-base</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.3.8.3" style="padding:0.9pt 5.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.3.8.3.1" style="font-size:90%;">0.0726</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.3.8.4" style="padding:0.9pt 5.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.3.8.4.1" style="font-size:90%;">0.0746</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.3.8.5" style="padding:0.9pt 5.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.3.8.5.1" style="font-size:90%;">0.0764</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.3.8.6" style="padding:0.9pt 5.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.3.8.6.1" style="font-size:90%;">0.1785</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.3.8.7" style="padding:0.9pt 5.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.3.8.7.1" style="font-size:90%;">0.2389</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T3.3.8.8" style="padding:0.9pt 5.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.3.8.8.1" style="font-size:90%;">0.3033</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.3.8.9" style="padding:0.9pt 5.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.3.8.9.1" style="font-size:90%;">0.0224</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.3.8.10" style="padding:0.9pt 5.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.3.8.10.1" style="font-size:90%;">0.0266</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.3.8.11" style="padding:0.9pt 5.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.3.8.11.1" style="font-size:90%;">0.0316</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.3.8.12" style="padding:0.9pt 5.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.3.8.12.1" style="font-size:90%;">0.0586</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.3.8.13" style="padding:0.9pt 5.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.3.8.13.1" style="font-size:90%;">0.0785</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.3.8.14" style="padding:0.9pt 5.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.3.8.14.1" style="font-size:90%;">0.0996</span></td>
</tr>
</table>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2. </span>Generative Recommenders for Retrieval</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#S4.T3" title="Table 3 ‣ 4.1. Experimental Setup ‣ 4. Experiments ‣ STORE: Streamlining Semantic Tokenization and Generative Recommendation with A Single LLM"><span class="ltx_text ltx_ref_tag">3</span></a> provides an overview of the performance across four baselines over two datasets. Drawing from the results, we can derive the following observations:</p>
</div>
<div class="ltx_para" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.p2.1.1">Firstly</span>, the semantic code group (i.e., TIGER, LC-Rec, and STORE) consistently outperforms the unique identifier group (i.e., SASRec and P5). This superiority stems from several factors: i) Learning unique identifiers for items depends heavily on rich interaction signals, whereas semantic codes can be learned from multiple items sharing common codes, enhancing learning efficiency. ii) Semantic codes incorporate content features into sequential recommenders, which is not the case with unique identifiers.</p>
</div>
<div class="ltx_para" id="S4.SS2.p3">
<p class="ltx_p" id="S4.SS2.p3.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.p3.1.1">Secondly</span>, the Yelp dataset exhibits worse performance compared to the MIND dataset, as indicated by shorter user sequence lengths and a higher number of distinct items, which results in a lower average item appearance as shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#S4.T1" title="Table 1 ‣ 4.1. Experimental Setup ‣ 4. Experiments ‣ STORE: Streamlining Semantic Tokenization and Generative Recommendation with A Single LLM"><span class="ltx_text ltx_ref_tag">1</span></a>. Additionally, using identical settings (4 tokens, each with a vocabulary size of 256) for tokenization, the MIND dataset, with fewer items, is more readily distinguishable. Furthermore, the item content in the MIND dataset, which includes news titles and abstracts, is more informative than that in the Yelp dataset, which consists of restaurant names, cities, and addresses.</p>
</div>
<div class="ltx_para" id="S4.SS2.p4">
<p class="ltx_p" id="S4.SS2.p4.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.p4.1.1">Thirdly</span>, compared to the Transformer backbone, the OPT-based backbone achieves better performance using the same TIGER code, due to its superior deep context comprehension ability.</p>
</div>
<div class="ltx_para" id="S4.SS2.p5">
<p class="ltx_p" id="S4.SS2.p5.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.p5.1.1">Fourthly</span>, despite Llama’s larger size and its superior performance over the OPT-base model in various NLP tasks, our STORE exceeds other baselines, including LC-Rec, which employs Llama for item embedding extraction. This underscores the effectiveness of STORE and the benefits of our post-pretraining strategy on dense tokens.</p>
</div>
<figure class="ltx_figure" id="S4.F7"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="493" id="S4.F7.g1" src="x7.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7. </span>Instruction tuning for scoring scenarios.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3. </span>Ablation Study</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">Here, we study the effectiveness of various components within our framework. Based on the results from Table <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#S4.T4" title="Table 4 ‣ 4.4. Generative Recommenders for Scoring ‣ 4. Experiments ‣ STORE: Streamlining Semantic Tokenization and Generative Recommendation with A Single LLM"><span class="ltx_text ltx_ref_tag">4</span></a>, we can make the following observations:</p>
</div>
<div class="ltx_para" id="S4.SS3.p2">
<p class="ltx_p" id="S4.SS3.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS3.p2.1.1">Firstly</span>, STORE<math alttext="{}_{\text{w/o dense tokenizer}}" class="ltx_Math" display="inline" id="S4.SS3.p2.1.m1.1"><semantics id="S4.SS3.p2.1.m1.1a"><msub id="S4.SS3.p2.1.m1.1.1" xref="S4.SS3.p2.1.m1.1.1.cmml"><mi id="S4.SS3.p2.1.m1.1.1a" xref="S4.SS3.p2.1.m1.1.1.cmml"></mi><mtext id="S4.SS3.p2.1.m1.1.1.1" xref="S4.SS3.p2.1.m1.1.1.1a.cmml">w/o dense tokenizer</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.1.m1.1b"><apply id="S4.SS3.p2.1.m1.1.1.cmml" xref="S4.SS3.p2.1.m1.1.1"><ci id="S4.SS3.p2.1.m1.1.1.1a.cmml" xref="S4.SS3.p2.1.m1.1.1.1"><mtext id="S4.SS3.p2.1.m1.1.1.1.cmml" mathsize="70%" xref="S4.SS3.p2.1.m1.1.1.1">w/o dense tokenizer</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.1.m1.1c">{}_{\text{w/o dense tokenizer}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p2.1.m1.1d">start_FLOATSUBSCRIPT w/o dense tokenizer end_FLOATSUBSCRIPT</annotation></semantics></math> follows the standard semantic tokenization pipeline: utilizing a pretrained OPT-base model to derive a single content embedding per item, which is then discretized into short tokens via RQ-VAE. Subsequently, these tokens are used to train the OPT-base model on a generative retrieval task. Our STORE surpasses this variant, demonstrating the superiority of our proposed paradigm.</p>
</div>
<div class="ltx_para" id="S4.SS3.p3">
<p class="ltx_p" id="S4.SS3.p3.1"><span class="ltx_text ltx_font_bold" id="S4.SS3.p3.1.1">Secondly</span>, STORE<math alttext="{}_{\text{w/o conditional beam search}}" class="ltx_Math" display="inline" id="S4.SS3.p3.1.m1.1"><semantics id="S4.SS3.p3.1.m1.1a"><msub id="S4.SS3.p3.1.m1.1.1" xref="S4.SS3.p3.1.m1.1.1.cmml"><mi id="S4.SS3.p3.1.m1.1.1a" xref="S4.SS3.p3.1.m1.1.1.cmml"></mi><mtext id="S4.SS3.p3.1.m1.1.1.1" xref="S4.SS3.p3.1.m1.1.1.1a.cmml">w/o conditional beam search</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.1.m1.1b"><apply id="S4.SS3.p3.1.m1.1.1.cmml" xref="S4.SS3.p3.1.m1.1.1"><ci id="S4.SS3.p3.1.m1.1.1.1a.cmml" xref="S4.SS3.p3.1.m1.1.1.1"><mtext id="S4.SS3.p3.1.m1.1.1.1.cmml" mathsize="70%" xref="S4.SS3.p3.1.m1.1.1.1">w/o conditional beam search</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.1.m1.1c">{}_{\text{w/o conditional beam search}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p3.1.m1.1d">start_FLOATSUBSCRIPT w/o conditional beam search end_FLOATSUBSCRIPT</annotation></semantics></math> employs soft beam search constraints as used by LC-Rec <cite class="ltx_cite ltx_citemacro_citep">(Zheng et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib45" title="">2024</a>)</cite>, where the classification at each position during next-code prediction is confined to the codebook size. While these soft constraints do enhance search performance, they cannot prevent the generation of token combinations that do not correspond to an actual item. For example, <span class="ltx_text ltx_font_typewriter" id="S4.SS3.p3.1.2" style="color:#957137;">2<span class="ltx_text" id="S4.SS3.p3.1.2.1" style="color:#000000;">-<span class="ltx_text" id="S4.SS3.p3.1.2.1.1" style="color:#2E5D86;">1</span></span></span> shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#S3.F6" title="Figure 6 ‣ 3.1. Dense Tokenizer ‣ 3. Proposed Approach: STORE ‣ STORE: Streamlining Semantic Tokenization and Generative Recommendation with A Single LLM"><span class="ltx_text ltx_ref_tag">6</span></a> is not a valid path (token combination), yet it can be generated as valid under soft constraints during the generation process. In contrast, our STORE achieves a significant improvement, thereby validating the effectiveness of conditional beam search.</p>
</div>
<div class="ltx_para" id="S4.SS3.p4">
<p class="ltx_p" id="S4.SS3.p4.1"><span class="ltx_text ltx_font_bold" id="S4.SS3.p4.1.1">Thirdly</span>, STORE<math alttext="{}_{\text{w/o text-token alignment task}}" class="ltx_Math" display="inline" id="S4.SS3.p4.1.m1.1"><semantics id="S4.SS3.p4.1.m1.1a"><msub id="S4.SS3.p4.1.m1.1.1" xref="S4.SS3.p4.1.m1.1.1.cmml"><mi id="S4.SS3.p4.1.m1.1.1a" xref="S4.SS3.p4.1.m1.1.1.cmml"></mi><mtext id="S4.SS3.p4.1.m1.1.1.1" xref="S4.SS3.p4.1.m1.1.1.1a.cmml">w/o text-token alignment task</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p4.1.m1.1b"><apply id="S4.SS3.p4.1.m1.1.1.cmml" xref="S4.SS3.p4.1.m1.1.1"><ci id="S4.SS3.p4.1.m1.1.1.1a.cmml" xref="S4.SS3.p4.1.m1.1.1.1"><mtext id="S4.SS3.p4.1.m1.1.1.1.cmml" mathsize="70%" xref="S4.SS3.p4.1.m1.1.1.1">w/o text-token alignment task</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p4.1.m1.1c">{}_{\text{w/o text-token alignment task}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p4.1.m1.1d">start_FLOATSUBSCRIPT w/o text-token alignment task end_FLOATSUBSCRIPT</annotation></semantics></math>, trained solely with the generative retrieval task (i.e., next-token prediction), performs less effectively compared to our STORE. This discrepancy likely arises because, despite using the same language model for both tokenization and recommendation, the model struggles to recognize randomly-initialized token embeddings. Introducing the text-token alignment task is crucial for bridging the gap between text and tokens, thereby enhancing the model’s semantic understanding of user sequences.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4. </span>Generative Recommenders for Scoring</h3>
<div class="ltx_para" id="S4.SS4.p1">
<p class="ltx_p" id="S4.SS4.p1.1">To illustrate the versatility of semantic codes, we examine their performance in a popular scenario using a large language model as a recommender: score prediction. As depicted in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#S4.F7" title="Figure 7 ‣ 4.2. Generative Recommenders for Retrieval ‣ 4. Experiments ‣ STORE: Streamlining Semantic Tokenization and Generative Recommendation with A Single LLM"><span class="ltx_text ltx_ref_tag">7</span></a>, the language model processes a user sequence and a candidate item, predicting the likelihood of a user clicking on the item. The logits for the “yes” and “no” tokens at the final output position are selected, and then normalized with a softmax function. The final score is represented by the “yes” score.<span class="ltx_note ltx_role_footnote" id="footnote6"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span>For GPT-3.5, we assign a score of 1 for a response of “YES” and 0 for “NO”.</span></span></span></p>
</div>
<div class="ltx_para" id="S4.SS4.p2">
<p class="ltx_p" id="S4.SS4.p2.1">Results for three groups are presented in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#S4.T5" title="Table 5 ‣ 4.4. Generative Recommenders for Scoring ‣ 4. Experiments ‣ STORE: Streamlining Semantic Tokenization and Generative Recommendation with A Single LLM"><span class="ltx_text ltx_ref_tag">5</span></a>. Zero-shot LLM recommenders such as BERT <cite class="ltx_cite ltx_citemacro_citep">(Devlin, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib5" title="">2018</a>)</cite>, OPT <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib43" title="">2022</a>)</cite>, Llama <cite class="ltx_cite ltx_citemacro_citep">(Touvron et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib34" title="">2023</a>)</cite>, and GPT-3.5 <cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib27" title="">2022</a>)</cite> are not fine-tuned on the recommendation dataset. However, finetuning with textual features is computationally expensive: lengthy item content leads to extended user sequences, and computational costs increase quadratically with the length of the input sequence. By utilizing semantic codes, large language models become more tunable: if the average item content length is 40 and the semantic code length is 4, this reduction of 10 times in length theoretically results in a 100-fold acceleration of the attention module. Based on the results, we have the following observations:</p>
</div>
<div class="ltx_para" id="S4.SS4.p3">
<p class="ltx_p" id="S4.SS4.p3.1"><span class="ltx_text ltx_font_bold" id="S4.SS4.p3.1.1">Firstly</span>, zero-shot large language models exhibit the poorest performance among the three groups. Despite their robust textual comprehension abilities, they lack exposure to collaborative corpora during pretraining, which hampers their recommendation ability. Notably, even advanced models like Llama and GPT-3.5, with their deeper networks and higher dimensionality, perform comparably to the zero-shot BERT-base model.</p>
</div>
<div class="ltx_para" id="S4.SS4.p4">
<p class="ltx_p" id="S4.SS4.p4.1"><span class="ltx_text ltx_font_bold" id="S4.SS4.p4.1.1">Secondly</span>, the fine-tuned LLM recommender, such as BERT-base, achieves over a 20% improvement compared to its zero-shot counterpart. This highlights the necessity of fine-tuning language models with recommendation tasks to enhance their efficacy as recommenders. Due to BERT’s limited maximum sequence length, we truncate the user sequence, making fine-tuning somewhat feasible given its relatively small network size. However, attempting to finetune larger language models in a similar manner is unacceptable as mentioned above.</p>
</div>
<div class="ltx_para" id="S4.SS4.p5">
<p class="ltx_p" id="S4.SS4.p5.1"><span class="ltx_text ltx_font_bold" id="S4.SS4.p5.1.1">Thirdly</span>, our generative recommender surpasses the performance of the other two groups. Although the semantic codes are new tokens for the language models, their advanced contextual comprehension capabilities enable the capture of both collaborative signals and content knowledge embedded within these codes. Crucially, replacing long item content with short semantic tokens significantly reduces computational demands, making the finetuning possible on larger language models like OPT-base, as opposed to BERT-base.</p>
</div>
<div class="ltx_para" id="S4.SS4.p6">
<p class="ltx_p" id="S4.SS4.p6.1"><span class="ltx_text ltx_font_bold" id="S4.SS4.p6.1.1">Fourthly</span>, our STORE surpasses TIGER and LC-Rec in the scoring scenario, underscoring the high quality of codes generated in our proposed paradigm.</p>
</div>
<figure class="ltx_table" id="S4.T4">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4. </span>Ablation studies. Experiments are conducted on the MIND dataset.</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.T4.3">
<tr class="ltx_tr" id="S4.T4.3.4">
<td class="ltx_td ltx_border_r ltx_border_tt" id="S4.T4.3.4.1" style="padding-top:1pt;padding-bottom:1pt;"></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T4.3.4.2" style="padding-top:1pt;padding-bottom:1pt;">R@5</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T4.3.4.3" style="padding-top:1pt;padding-bottom:1pt;">R@10</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T4.3.4.4" style="padding-top:1pt;padding-bottom:1pt;">R@20</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T4.3.4.5" style="padding-top:1pt;padding-bottom:1pt;">N@5</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T4.3.4.6" style="padding-top:1pt;padding-bottom:1pt;">N@10</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T4.3.4.7" style="padding-top:1pt;padding-bottom:1pt;">N@20</td>
</tr>
<tr class="ltx_tr" id="S4.T4.1.1">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.1.1.1" style="padding-top:1pt;padding-bottom:1pt;">STORE <math alttext="{}_{\text{w/o dense tokenizer}}" class="ltx_Math" display="inline" id="S4.T4.1.1.1.m1.1"><semantics id="S4.T4.1.1.1.m1.1a"><msub id="S4.T4.1.1.1.m1.1.1" xref="S4.T4.1.1.1.m1.1.1.cmml"><mi id="S4.T4.1.1.1.m1.1.1a" xref="S4.T4.1.1.1.m1.1.1.cmml"></mi><mtext id="S4.T4.1.1.1.m1.1.1.1" xref="S4.T4.1.1.1.m1.1.1.1a.cmml">w/o dense tokenizer</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.T4.1.1.1.m1.1b"><apply id="S4.T4.1.1.1.m1.1.1.cmml" xref="S4.T4.1.1.1.m1.1.1"><ci id="S4.T4.1.1.1.m1.1.1.1a.cmml" xref="S4.T4.1.1.1.m1.1.1.1"><mtext id="S4.T4.1.1.1.m1.1.1.1.cmml" mathsize="70%" xref="S4.T4.1.1.1.m1.1.1.1">w/o dense tokenizer</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.1.1.1.m1.1c">{}_{\text{w/o dense tokenizer}}</annotation><annotation encoding="application/x-llamapun" id="S4.T4.1.1.1.m1.1d">start_FLOATSUBSCRIPT w/o dense tokenizer end_FLOATSUBSCRIPT</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.1.1.2" style="padding-top:1pt;padding-bottom:1pt;">0.0664</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.1.1.3" style="padding-top:1pt;padding-bottom:1pt;">0.0670</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.1.1.4" style="padding-top:1pt;padding-bottom:1pt;">0.0676</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.1.1.5" style="padding-top:1pt;padding-bottom:1pt;">0.1685</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.1.1.6" style="padding-top:1pt;padding-bottom:1pt;">0.2255</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.1.1.7" style="padding-top:1pt;padding-bottom:1pt;">0.2863</td>
</tr>
<tr class="ltx_tr" id="S4.T4.2.2">
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.2.2.1" style="padding-top:1pt;padding-bottom:1pt;">STORE <math alttext="{}_{\text{w/o conditional beam search}}" class="ltx_Math" display="inline" id="S4.T4.2.2.1.m1.1"><semantics id="S4.T4.2.2.1.m1.1a"><msub id="S4.T4.2.2.1.m1.1.1" xref="S4.T4.2.2.1.m1.1.1.cmml"><mi id="S4.T4.2.2.1.m1.1.1a" xref="S4.T4.2.2.1.m1.1.1.cmml"></mi><mtext id="S4.T4.2.2.1.m1.1.1.1" xref="S4.T4.2.2.1.m1.1.1.1a.cmml">w/o conditional beam search</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.T4.2.2.1.m1.1b"><apply id="S4.T4.2.2.1.m1.1.1.cmml" xref="S4.T4.2.2.1.m1.1.1"><ci id="S4.T4.2.2.1.m1.1.1.1a.cmml" xref="S4.T4.2.2.1.m1.1.1.1"><mtext id="S4.T4.2.2.1.m1.1.1.1.cmml" mathsize="70%" xref="S4.T4.2.2.1.m1.1.1.1">w/o conditional beam search</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.2.2.1.m1.1c">{}_{\text{w/o conditional beam search}}</annotation><annotation encoding="application/x-llamapun" id="S4.T4.2.2.1.m1.1d">start_FLOATSUBSCRIPT w/o conditional beam search end_FLOATSUBSCRIPT</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="S4.T4.2.2.2" style="padding-top:1pt;padding-bottom:1pt;">0.0296</td>
<td class="ltx_td ltx_align_center" id="S4.T4.2.2.3" style="padding-top:1pt;padding-bottom:1pt;">0.0422</td>
<td class="ltx_td ltx_align_center" id="S4.T4.2.2.4" style="padding-top:1pt;padding-bottom:1pt;">0.0602</td>
<td class="ltx_td ltx_align_center" id="S4.T4.2.2.5" style="padding-top:1pt;padding-bottom:1pt;">0.0662</td>
<td class="ltx_td ltx_align_center" id="S4.T4.2.2.6" style="padding-top:1pt;padding-bottom:1pt;">0.0868</td>
<td class="ltx_td ltx_align_center" id="S4.T4.2.2.7" style="padding-top:1pt;padding-bottom:1pt;">0.1128</td>
</tr>
<tr class="ltx_tr" id="S4.T4.3.3">
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.3.3.1" style="padding-top:1pt;padding-bottom:1pt;">STORE <math alttext="{}_{\text{w/o text-token alignment task}}" class="ltx_Math" display="inline" id="S4.T4.3.3.1.m1.1"><semantics id="S4.T4.3.3.1.m1.1a"><msub id="S4.T4.3.3.1.m1.1.1" xref="S4.T4.3.3.1.m1.1.1.cmml"><mi id="S4.T4.3.3.1.m1.1.1a" xref="S4.T4.3.3.1.m1.1.1.cmml"></mi><mtext id="S4.T4.3.3.1.m1.1.1.1" xref="S4.T4.3.3.1.m1.1.1.1a.cmml">w/o text-token alignment task</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.T4.3.3.1.m1.1b"><apply id="S4.T4.3.3.1.m1.1.1.cmml" xref="S4.T4.3.3.1.m1.1.1"><ci id="S4.T4.3.3.1.m1.1.1.1a.cmml" xref="S4.T4.3.3.1.m1.1.1.1"><mtext id="S4.T4.3.3.1.m1.1.1.1.cmml" mathsize="70%" xref="S4.T4.3.3.1.m1.1.1.1">w/o text-token alignment task</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.3.3.1.m1.1c">{}_{\text{w/o text-token alignment task}}</annotation><annotation encoding="application/x-llamapun" id="S4.T4.3.3.1.m1.1d">start_FLOATSUBSCRIPT w/o text-token alignment task end_FLOATSUBSCRIPT</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.3.2" style="padding-top:1pt;padding-bottom:1pt;">0.0705</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.3.3" style="padding-top:1pt;padding-bottom:1pt;">0.0722</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.3.4" style="padding-top:1pt;padding-bottom:1pt;">0.0735</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.3.5" style="padding-top:1pt;padding-bottom:1pt;">0.1758</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.3.6" style="padding-top:1pt;padding-bottom:1pt;">0.2340</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.3.7" style="padding-top:1pt;padding-bottom:1pt;">0.2592</td>
</tr>
<tr class="ltx_tr" id="S4.T4.3.5">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T4.3.5.1" style="padding-top:1pt;padding-bottom:1pt;">STORE</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T4.3.5.2" style="padding-top:1pt;padding-bottom:1pt;">0.0726</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T4.3.5.3" style="padding-top:1pt;padding-bottom:1pt;">0.0746</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T4.3.5.4" style="padding-top:1pt;padding-bottom:1pt;">0.0764</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T4.3.5.5" style="padding-top:1pt;padding-bottom:1pt;">0.1785</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T4.3.5.6" style="padding-top:1pt;padding-bottom:1pt;">0.2389</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T4.3.5.7" style="padding-top:1pt;padding-bottom:1pt;">0.3033</td>
</tr>
</table>
</figure>
<figure class="ltx_table" id="S4.T5">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5. </span>Overall performance comparison in scoring scenarios. We use R and N to represent the Recall and NDCG metrics, respectively.</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.T5.1">
<tr class="ltx_tr" id="S4.T5.1.1">
<td class="ltx_td ltx_border_tt" id="S4.T5.1.1.1" style="padding-top:1pt;padding-bottom:1pt;"></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T5.1.1.2" style="padding-top:1pt;padding-bottom:1pt;">Identifier</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T5.1.1.3" style="padding-top:1pt;padding-bottom:1pt;">Backbone</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T5.1.1.4" style="padding-top:1pt;padding-bottom:1pt;">AUC</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T5.1.1.5" style="padding-top:1pt;padding-bottom:1pt;">MRR</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T5.1.1.6" style="padding-top:1pt;padding-bottom:1pt;">N@1</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T5.1.1.7" style="padding-top:1pt;padding-bottom:1pt;">N@5</td>
</tr>
<tr class="ltx_tr" id="S4.T5.1.2">
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.1.2.1" rowspan="4" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text" id="S4.T5.1.2.1.1"><span class="ltx_text" id="S4.T5.1.2.1.1.1"></span> <span class="ltx_text" id="S4.T5.1.2.1.1.2">
<span class="ltx_tabular ltx_align_middle" id="S4.T5.1.2.1.1.2.1">
<span class="ltx_tr" id="S4.T5.1.2.1.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T5.1.2.1.1.2.1.1.1" style="padding-top:1pt;padding-bottom:1pt;">Zero-shot</span></span>
<span class="ltx_tr" id="S4.T5.1.2.1.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T5.1.2.1.1.2.1.2.1" style="padding-top:1pt;padding-bottom:1pt;">LLM Recommender</span></span>
</span></span> <span class="ltx_text" id="S4.T5.1.2.1.1.3"></span></span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.1.2.2" style="padding-top:1pt;padding-bottom:1pt;">Text</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.1.2.3" style="padding-top:1pt;padding-bottom:1pt;">BERT-base</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.1.2.4" style="padding-top:1pt;padding-bottom:1pt;">0.4963</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.1.2.5" style="padding-top:1pt;padding-bottom:1pt;">0.4139</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.1.2.6" style="padding-top:1pt;padding-bottom:1pt;">0.2655</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.1.2.7" style="padding-top:1pt;padding-bottom:1pt;">0.3729</td>
</tr>
<tr class="ltx_tr" id="S4.T5.1.3">
<td class="ltx_td ltx_align_center" id="S4.T5.1.3.1" style="padding-top:1pt;padding-bottom:1pt;">Text</td>
<td class="ltx_td ltx_align_center" id="S4.T5.1.3.2" style="padding-top:1pt;padding-bottom:1pt;">OPT-base</td>
<td class="ltx_td ltx_align_center" id="S4.T5.1.3.3" style="padding-top:1pt;padding-bottom:1pt;">0.5490</td>
<td class="ltx_td ltx_align_center" id="S4.T5.1.3.4" style="padding-top:1pt;padding-bottom:1pt;">0.4658</td>
<td class="ltx_td ltx_align_center" id="S4.T5.1.3.5" style="padding-top:1pt;padding-bottom:1pt;">0.3715</td>
<td class="ltx_td ltx_align_center" id="S4.T5.1.3.6" style="padding-top:1pt;padding-bottom:1pt;">0.4362</td>
</tr>
<tr class="ltx_tr" id="S4.T5.1.4">
<td class="ltx_td ltx_align_center" id="S4.T5.1.4.1" style="padding-top:1pt;padding-bottom:1pt;">Text</td>
<td class="ltx_td ltx_align_center" id="S4.T5.1.4.2" style="padding-top:1pt;padding-bottom:1pt;">Llama-1</td>
<td class="ltx_td ltx_align_center" id="S4.T5.1.4.3" style="padding-top:1pt;padding-bottom:1pt;">0.4583</td>
<td class="ltx_td ltx_align_center" id="S4.T5.1.4.4" style="padding-top:1pt;padding-bottom:1pt;">0.3858</td>
<td class="ltx_td ltx_align_center" id="S4.T5.1.4.5" style="padding-top:1pt;padding-bottom:1pt;">0.2100</td>
<td class="ltx_td ltx_align_center" id="S4.T5.1.4.6" style="padding-top:1pt;padding-bottom:1pt;">0.3301</td>
</tr>
<tr class="ltx_tr" id="S4.T5.1.5">
<td class="ltx_td ltx_align_center" id="S4.T5.1.5.1" style="padding-top:1pt;padding-bottom:1pt;">Text</td>
<td class="ltx_td ltx_align_center" id="S4.T5.1.5.2" style="padding-top:1pt;padding-bottom:1pt;">GPT-3.5</td>
<td class="ltx_td ltx_align_center" id="S4.T5.1.5.3" style="padding-top:1pt;padding-bottom:1pt;">0.5057</td>
<td class="ltx_td ltx_align_center" id="S4.T5.1.5.4" style="padding-top:1pt;padding-bottom:1pt;">-</td>
<td class="ltx_td ltx_align_center" id="S4.T5.1.5.5" style="padding-top:1pt;padding-bottom:1pt;">-</td>
<td class="ltx_td ltx_align_center" id="S4.T5.1.5.6" style="padding-top:1pt;padding-bottom:1pt;">-</td>
</tr>
<tr class="ltx_tr" id="S4.T5.1.6">
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.1.6.1" style="padding-top:1pt;padding-bottom:1pt;">Fine-tuned LLM Recommender</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.1.6.2" style="padding-top:1pt;padding-bottom:1pt;">Text</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.1.6.3" style="padding-top:1pt;padding-bottom:1pt;">BERT-base</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.1.6.4" style="padding-top:1pt;padding-bottom:1pt;">0.6014</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.1.6.5" style="padding-top:1pt;padding-bottom:1pt;">0.5055</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.1.6.6" style="padding-top:1pt;padding-bottom:1pt;">0.4178</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.1.6.7" style="padding-top:1pt;padding-bottom:1pt;">0.4890</td>
</tr>
<tr class="ltx_tr" id="S4.T5.1.7">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T5.1.7.1" rowspan="3" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text" id="S4.T5.1.7.1.1"><span class="ltx_text" id="S4.T5.1.7.1.1.1"></span> <span class="ltx_text" id="S4.T5.1.7.1.1.2">
<span class="ltx_tabular ltx_align_middle" id="S4.T5.1.7.1.1.2.1">
<span class="ltx_tr" id="S4.T5.1.7.1.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T5.1.7.1.1.2.1.1.1" style="padding-top:1pt;padding-bottom:1pt;">Generative</span></span>
<span class="ltx_tr" id="S4.T5.1.7.1.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T5.1.7.1.1.2.1.2.1" style="padding-top:1pt;padding-bottom:1pt;">Recommender</span></span>
</span></span> <span class="ltx_text" id="S4.T5.1.7.1.1.3"></span></span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.1.7.2" style="padding-top:1pt;padding-bottom:1pt;">TIGER</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.1.7.3" style="padding-top:1pt;padding-bottom:1pt;">OPT-base</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.1.7.4" style="padding-top:1pt;padding-bottom:1pt;">0.6202</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.1.7.5" style="padding-top:1pt;padding-bottom:1pt;">0.5277</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.1.7.6" style="padding-top:1pt;padding-bottom:1pt;">0.4987</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.1.7.7" style="padding-top:1pt;padding-bottom:1pt;">0.5315</td>
</tr>
<tr class="ltx_tr" id="S4.T5.1.8">
<td class="ltx_td ltx_align_center" id="S4.T5.1.8.1" style="padding-top:1pt;padding-bottom:1pt;">LC-Rec</td>
<td class="ltx_td ltx_align_center" id="S4.T5.1.8.2" style="padding-top:1pt;padding-bottom:1pt;">OPT-base</td>
<td class="ltx_td ltx_align_center" id="S4.T5.1.8.3" style="padding-top:1pt;padding-bottom:1pt;">0.6043</td>
<td class="ltx_td ltx_align_center" id="S4.T5.1.8.4" style="padding-top:1pt;padding-bottom:1pt;">0.5052</td>
<td class="ltx_td ltx_align_center" id="S4.T5.1.8.5" style="padding-top:1pt;padding-bottom:1pt;">0.4543</td>
<td class="ltx_td ltx_align_center" id="S4.T5.1.8.6" style="padding-top:1pt;padding-bottom:1pt;">0.4988</td>
</tr>
<tr class="ltx_tr" id="S4.T5.1.9">
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T5.1.9.1" style="padding-top:1pt;padding-bottom:1pt;">STORE (ours)</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T5.1.9.2" style="padding-top:1pt;padding-bottom:1pt;">OPT-base</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T5.1.9.3" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text ltx_font_bold" id="S4.T5.1.9.3.1">0.6505</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T5.1.9.4" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text ltx_font_bold" id="S4.T5.1.9.4.1">0.5509</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T5.1.9.5" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text ltx_font_bold" id="S4.T5.1.9.5.1">0.5062</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T5.1.9.6" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text ltx_font_bold" id="S4.T5.1.9.6.1">0.5542</span></td>
</tr>
</table>
</figure>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5. </span>Related Work</h2>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1. </span>LLMs for Recommendation</h3>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">Generally, the emerging techniques of LLMs for enhancing recommender systems can be grouped into three paradigms, namely pre-training, prompting, and fine-tuning <cite class="ltx_cite ltx_citemacro_citep">(Zhao et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib44" title="">2024</a>)</cite>.</p>
</div>
<section class="ltx_paragraph" id="S5.SS1.SSS0.Px1">
<h4 class="ltx_title ltx_font_bold ltx_title_paragraph">Pre-training.</h4>
<div class="ltx_para" id="S5.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="S5.SS1.SSS0.Px1.p1.1"><cite class="ltx_cite ltx_citemacro_citep">(Liu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib21" title="">2022</a>; Wu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib38" title="">2020b</a>; Cui et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib4" title="">2022</a>; Geng et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib7" title="">2022</a>; Liu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib22" title="">2024c</a>)</cite> Research in this paradigm typically involves tasks designed to model diverse user behaviors and aims to develop a fundamental recommendation model. For instance, PTUM <cite class="ltx_cite ltx_citemacro_citep">(Wu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib38" title="">2020b</a>)</cite> employs two pre-training tasks: masked behavior prediction and next K behavior prediction. Similarly, Cui et al. <cite class="ltx_cite ltx_citemacro_citep">(Cui et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib4" title="">2022</a>)</cite> introduce M6, which utilizes an auto-regressive generation task and a text-infilling objective. Additionally, Geng et al. <cite class="ltx_cite ltx_citemacro_citep">(Geng et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib7" title="">2022</a>)</cite> propose P5, a model that integrates multiple recommendation tasks within a unified framework to pre-train a foundational recommendation model.</p>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS1.SSS0.Px2">
<h4 class="ltx_title ltx_font_bold ltx_title_paragraph">Prompting.</h4>
<div class="ltx_para" id="S5.SS1.SSS0.Px2.p1">
<p class="ltx_p" id="S5.SS1.SSS0.Px2.p1.1"><cite class="ltx_cite ltx_citemacro_citep">(Xi et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib41" title="">2023</a>; Wang and Lim, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib35" title="">2023</a>; Liu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib19" title="">2024a</a>)</cite> Instead of pre-training an LLM, some studies aim to directly integrate LLMs into the recommendation pipeline without parameter updates, typically through feature augmentation. For instance, Xi et al. <cite class="ltx_cite ltx_citemacro_citep">(Xi et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib41" title="">2023</a>)</cite> propose utilizing LLMs to infer user preferences and factual knowledge about items. Similarly, Wang et al. <cite class="ltx_cite ltx_citemacro_citep">(Wang and Lim, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib35" title="">2023</a>)</cite> employ LLMs to model user preferences.</p>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS1.SSS0.Px3">
<h4 class="ltx_title ltx_font_bold ltx_title_paragraph">Fine-tuning.</h4>
<div class="ltx_para" id="S5.SS1.SSS0.Px3.p1">
<p class="ltx_p" id="S5.SS1.SSS0.Px3.p1.1">This line of research seeks to leverage the capabilities of existing powerful LLMs with fine-tuning. Fine-tuning is a critical step in aligning LLMs with various downstream recommendation tasks. Related studies either adopt full-model fine-tuning <cite class="ltx_cite ltx_citemacro_citep">(Friedman et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib6" title="">2023</a>; Shen et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib31" title="">2023</a>)</cite> or employ parameter-efficient fine-tuning techniques <cite class="ltx_cite ltx_citemacro_citep">(Bao et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib2" title="">2023</a>; Wu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib40" title="">2024</a>)</cite>, such as LoRA <cite class="ltx_cite ltx_citemacro_citep">(Hu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib9" title="">2021</a>)</cite>, to reduce computational resource requirements.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2. </span>Generative Recommendation</h3>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">Generative recommenders learn from user interactions or sequential patterns to directly generate recommendations without the need for filtering or ranking <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib17" title="">2023</a>)</cite>. Traditional approaches such as SASRec <cite class="ltx_cite ltx_citemacro_citep">(Kang and McAuley, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib13" title="">2018</a>)</cite> and BERT4Rec <cite class="ltx_cite ltx_citemacro_citep">(Sun et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib33" title="">2019</a>)</cite>, along with language model-based recommenders like P5 <cite class="ltx_cite ltx_citemacro_citep">(Geng et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib7" title="">2022</a>)</cite> and VIP5 <cite class="ltx_cite ltx_citemacro_citep">(Geng et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib8" title="">2023</a>)</cite>, utilize unique identifiers to represent items and generate the next item by selecting the most probable item from the entire distribution.</p>
</div>
<div class="ltx_para" id="S5.SS2.p2">
<p class="ltx_p" id="S5.SS2.p2.1">To incorporate item content knowledge, TIGER <cite class="ltx_cite ltx_citemacro_citep">(Rajput et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib29" title="">2024</a>)</cite> introduced semantic identifiers that can be shared across different items, replacing the unique identifier. This approach has been further developed by other semantic tokenization efforts <cite class="ltx_cite ltx_citemacro_citep">(Zheng et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib45" title="">2024</a>; Jin et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib12" title="">2023</a>; Liu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib20" title="">2024b</a>)</cite>. Moreover, the effectiveness of integrating collaborative features learned from simple recommenders into identifiers has been demonstrated <cite class="ltx_cite ltx_citemacro_citep">(Qu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib28" title="">2024</a>; Wang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07276v2#bib.bib36" title="">2024a</a>)</cite>. However, this method heavily relies on rich interactions and tends to be unstable or change frequently in real-world scenarios. The learned tokens are used in generative recommenders, shifting the training focus from next-item prediction to next-code prediction. This shift narrows the search space for each position, thereby enhancing the inference performance.
Given the limitations discussed in the Preliminaries Section, this paper aims to reevaluate and refine the standard semantic tokenization pipeline.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6. </span>Conclusion</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">In this paper, we introduce the STORE framework, which streamlines semantic tokenization and generative recommendation using a single LLM. Unlike existing methods that rely on separate sub-models for embedding, quantization, and generation, our STORE framework unifies these tasks within a single generation framework, simplifying the overall process by reusing the LLM backbone. Our experimental results demonstrate that the STORE framework outperforms existing baselines across both retrieval and scoring tasks on real-world recommendation datasets. Additionally, the versatility of the STORE framework extends beyond purely text-based applications, showing promise in multimodal domains.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bao et al<span class="ltx_text" id="bib.bib2.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Keqin Bao, Jizhi Zhang, Yang Zhang, Wenjie Wang, Fuli Feng, and Xiangnan He. 2023.

</span>
<span class="ltx_bibblock">Tallrec: An effective and efficient tuning framework to align large language model with recommendation. In <em class="ltx_emph ltx_font_italic" id="bib.bib2.3.1">Proceedings of the 17th ACM Conference on Recommender Systems</em>. 1007–1014.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Baykal et al<span class="ltx_text" id="bib.bib3.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Gulcin Baykal, Melih Kandemir, and Gozde Unal. 2023.

</span>
<span class="ltx_bibblock">EdVAE: Mitigating Codebook Collapse with Evidential Discrete Variational Autoencoders.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib3.3.1">CoRR</em> abs/2310.05718 (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cui et al<span class="ltx_text" id="bib.bib4.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Zeyu Cui, Jianxin Ma, Chang Zhou, Jingren Zhou, and Hongxia Yang. 2022.

</span>
<span class="ltx_bibblock">M6-rec: Generative pretrained language models are open-ended recommender systems.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.3.1">arXiv preprint arXiv:2205.08084</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Devlin (2018)</span>
<span class="ltx_bibblock">
Jacob Devlin. 2018.

</span>
<span class="ltx_bibblock">Bert: Pre-training of deep bidirectional transformers for language understanding.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">arXiv preprint arXiv:1810.04805</em> (2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Friedman et al<span class="ltx_text" id="bib.bib6.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Luke Friedman, Sameer Ahuja, David Allen, Zhenning Tan, Hakim Sidahmed, Changbo Long, Jun Xie, Gabriel Schubiner, Ajay Patel, Harsh Lara, et al<span class="ltx_text" id="bib.bib6.3.1">.</span> 2023.

</span>
<span class="ltx_bibblock">Leveraging large language models in conversational recommender systems.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib6.4.1">arXiv preprint arXiv:2305.07961</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Geng et al<span class="ltx_text" id="bib.bib7.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Shijie Geng, Shuchang Liu, Zuohui Fu, Yingqiang Ge, and Yongfeng Zhang. 2022.

</span>
<span class="ltx_bibblock">Recommendation as language processing (rlp): A unified pretrain, personalized prompt &amp; predict paradigm (p5). In <em class="ltx_emph ltx_font_italic" id="bib.bib7.3.1">Proceedings of the 16th ACM Conference on Recommender Systems</em>. 299–315.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Geng et al<span class="ltx_text" id="bib.bib8.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Shijie Geng, Juntao Tan, Shuchang Liu, Zuohui Fu, and Yongfeng Zhang. 2023.

</span>
<span class="ltx_bibblock">Vip5: Towards multimodal foundation models for recommendation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.3.1">arXiv preprint arXiv:2305.14302</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et al<span class="ltx_text" id="bib.bib9.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. 2021.

</span>
<span class="ltx_bibblock">Lora: Low-rank adaptation of large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib9.3.1">arXiv preprint arXiv:2106.09685</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huh et al<span class="ltx_text" id="bib.bib10.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Minyoung Huh, Brian Cheung, Pulkit Agrawal, and Phillip Isola. 2023.

</span>
<span class="ltx_bibblock">Straightening Out the Straight-Through Estimator: Overcoming Optimization Challenges in Vector Quantized Networks. In <em class="ltx_emph ltx_font_italic" id="bib.bib10.3.1">International Conference on Machine Learning (ICML)</em>. 14096–14113.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Järvelin and Kekäläinen (2002)</span>
<span class="ltx_bibblock">
Kalervo Järvelin and Jaana Kekäläinen. 2002.

</span>
<span class="ltx_bibblock">Cumulated gain-based evaluation of IR techniques.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">ACM Transactions on Information Systems (TOIS)</em> 20, 4 (2002), 422–446.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jin et al<span class="ltx_text" id="bib.bib12.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Bowen Jin, Hansi Zeng, Guoyin Wang, Xiusi Chen, Tianxin Wei, Ruirui Li, Zhengyang Wang, Zheng Li, Yang Li, Hanqing Lu, et al<span class="ltx_text" id="bib.bib12.3.1">.</span> 2023.

</span>
<span class="ltx_bibblock">Language models as semantic indexers.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib12.4.1">arXiv preprint arXiv:2310.07815</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kang and McAuley (2018)</span>
<span class="ltx_bibblock">
Wang-Cheng Kang and Julian McAuley. 2018.

</span>
<span class="ltx_bibblock">Self-attentive sequential recommendation. In <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">2018 IEEE international conference on data mining (ICDM)</em>. IEEE, 197–206.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kingma and Ba (2015)</span>
<span class="ltx_bibblock">
Diederik P Kingma and Jimmy Ba. 2015.

</span>
<span class="ltx_bibblock">Adam: A Method for Stochastic Optimization.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">International Conference on Learning Representations</em> (2015).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Krishna and Murty (1999)</span>
<span class="ltx_bibblock">
K Krishna and M Narasimha Murty. 1999.

</span>
<span class="ltx_bibblock">Genetic K-means algorithm.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)</em> 29, 3 (1999), 433–439.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee et al<span class="ltx_text" id="bib.bib16.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Doyup Lee, Chiheon Kim, Saehoon Kim, Minsu Cho, and Wook-Shin Han. 2022.

</span>
<span class="ltx_bibblock">Autoregressive image generation using residual quantization. In <em class="ltx_emph ltx_font_italic" id="bib.bib16.3.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>. 11523–11532.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span class="ltx_text" id="bib.bib17.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Lei Li, Yongfeng Zhang, Dugang Liu, and Li Chen. 2023.

</span>
<span class="ltx_bibblock">Large language models for generative recommendation: A survey and visionary discussions.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib17.3.1">arXiv preprint arXiv:2309.01157</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span class="ltx_text" id="bib.bib18.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Yongqi Li, Xinyu Lin, Wenjie Wang, Fuli Feng, Liang Pang, Wenjie Li, Liqiang Nie, Xiangnan He, and Tat-Seng Chua. 2024.

</span>
<span class="ltx_bibblock">A Survey of Generative Search and Recommendation in the Era of Large Language Models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib18.3.1">CoRR</em> abs/2404.16924 (2024).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al<span class="ltx_text" id="bib.bib19.2.2.1">.</span> (2024a)</span>
<span class="ltx_bibblock">
Qijiong Liu, Nuo Chen, Tetsuya Sakai, and Xiao-Ming Wu. 2024a.

</span>
<span class="ltx_bibblock">Once: Boosting content-based recommendation with both open-and closed-source large language models. In <em class="ltx_emph ltx_font_italic" id="bib.bib19.3.1">Proceedings of the 17th ACM International Conference on Web Search and Data Mining</em>. 452–461.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al<span class="ltx_text" id="bib.bib20.2.2.1">.</span> (2024b)</span>
<span class="ltx_bibblock">
Qijiong Liu, Hengchang Hu, Jiahao Wu, Jieming Zhu, Min-Yen Kan, and Xiao-Ming Wu. 2024b.

</span>
<span class="ltx_bibblock">Discrete Semantic Tokenization for Deep CTR Prediction. In <em class="ltx_emph ltx_font_italic" id="bib.bib20.3.1">Companion Proceedings of the ACM on Web Conference 2024</em>. 919–922.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al<span class="ltx_text" id="bib.bib21.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Qijiong Liu, Jieming Zhu, Quanyu Dai, and Xiao-Ming Wu. 2022.

</span>
<span class="ltx_bibblock">Boosting deep CTR prediction with a plug-and-play pre-trainer for news recommendation. In <em class="ltx_emph ltx_font_italic" id="bib.bib21.3.1">Proceedings of the 29th International Conference on Computational Linguistics</em>. 2823–2833.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al<span class="ltx_text" id="bib.bib22.2.2.1">.</span> (2024c)</span>
<span class="ltx_bibblock">
Qijiong Liu, Jieming Zhu, Quanyu Dai, and Xiao-Ming Wu. 2024c.

</span>
<span class="ltx_bibblock">Benchmarking News Recommendation in the Era of Green AI. In <em class="ltx_emph ltx_font_italic" id="bib.bib22.3.1">Companion Proceedings of the ACM on Web Conference 2024</em>. 971–974.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al<span class="ltx_text" id="bib.bib23.2.2.1">.</span> (2024d)</span>
<span class="ltx_bibblock">
Qijiong Liu, Jieming Zhu, Yanting Yang, Quanyu Dai, Zhaocheng Du, Xiao-Ming Wu, Zhou Zhao, Rui Zhang, and Zhenhua Dong. 2024d.

</span>
<span class="ltx_bibblock">Multimodal Pretraining, Adaptation, and Generation for Recommendation: A Survey. In <em class="ltx_emph ltx_font_italic" id="bib.bib23.3.1">Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD)</em>. 6566–6576.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Maćkiewicz and Ratajczak (1993)</span>
<span class="ltx_bibblock">
Andrzej Maćkiewicz and Waldemar Ratajczak. 1993.

</span>
<span class="ltx_bibblock">Principal components analysis (PCA).

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">Computers &amp; Geosciences</em> 19, 3 (1993), 303–342.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mu et al<span class="ltx_text" id="bib.bib25.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Jesse Mu, Xiang Li, and Noah Goodman. 2024.

</span>
<span class="ltx_bibblock">Learning to compress prompts with gist tokens.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib25.3.1">Advances in Neural Information Processing Systems</em> 36 (2024).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ni et al<span class="ltx_text" id="bib.bib26.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Jianmo Ni, Gustavo Hernández Ábrego, Noah Constant, Ji Ma, Keith B Hall, Daniel Cer, and Yinfei Yang. 2021.

</span>
<span class="ltx_bibblock">Sentence-t5: Scalable sentence encoders from pre-trained text-to-text models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib26.3.1">arXiv preprint arXiv:2108.08877</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2022)</span>
<span class="ltx_bibblock">
OpenAI. 2022.

</span>
<span class="ltx_bibblock">ChatGPT.

</span>
<span class="ltx_bibblock">OpenAI website.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">Available at: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.openai.com/chatgpt" title="">https://www.openai.com/chatgpt</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qu et al<span class="ltx_text" id="bib.bib28.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Haohao Qu, Wenqi Fan, Zihuai Zhao, and Qing Li. 2024.

</span>
<span class="ltx_bibblock">TokenRec: Learning to Tokenize ID for LLM-based Generative Recommendation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib28.3.1">arXiv preprint arXiv:2406.10450</em> (2024).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rajput et al<span class="ltx_text" id="bib.bib29.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Shashank Rajput, Nikhil Mehta, Anima Singh, Raghunandan Hulikal Keshavan, Trung Vu, Lukasz Heldt, Lichan Hong, Yi Tay, Vinh Tran, Jonah Samost, et al<span class="ltx_text" id="bib.bib29.3.1">.</span> 2024.

</span>
<span class="ltx_bibblock">Recommender systems with generative retrieval.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib29.4.1">Advances in Neural Information Processing Systems</em> 36 (2024).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Reimers and Gurevych (2019)</span>
<span class="ltx_bibblock">
Nils Reimers and Iryna Gurevych. 2019.

</span>
<span class="ltx_bibblock">Sentence-bert: Sentence embeddings using siamese bert-networks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">arXiv preprint arXiv:1908.10084</em> (2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shen et al<span class="ltx_text" id="bib.bib31.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Tianshu Shen, Jiaru Li, Mohamed Reda Bouadjenek, Zheda Mai, and Scott Sanner. 2023.

</span>
<span class="ltx_bibblock">Towards understanding and mitigating unintended biases in language model-driven conversational recommendation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib31.3.1">Information Processing &amp; Management</em> 60, 1 (2023), 103139.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Singh et al<span class="ltx_text" id="bib.bib32.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Anima Singh, Trung Vu, Nikhil Mehta, Raghunandan Keshavan, Maheswaran Sathiamoorthy, Yilin Zheng, Lichan Hong, Lukasz Heldt, Li Wei, Devansh Tandon, Ed H. Chi, and Xinyang Yi. 2024.

</span>
<span class="ltx_bibblock">Better Generalization with Semantic IDs: A Case Study in Ranking for Recommendations.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2306.08121

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et al<span class="ltx_text" id="bib.bib33.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Fei Sun, Jun Liu, Jian Wu, Changhua Pei, Xiao Lin, Wenwu Ou, and Peng Jiang. 2019.

</span>
<span class="ltx_bibblock">BERT4Rec: Sequential recommendation with bidirectional encoder representations from transformer. In <em class="ltx_emph ltx_font_italic" id="bib.bib33.3.1">Proceedings of the 28th ACM international conference on information and knowledge management</em>. 1441–1450.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et al<span class="ltx_text" id="bib.bib34.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, et al<span class="ltx_text" id="bib.bib34.3.1">.</span> 2023.

</span>
<span class="ltx_bibblock">Llama: Open and efficient foundation language models. In <em class="ltx_emph ltx_font_italic" id="bib.bib34.4.1">arXiv</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang and Lim (2023)</span>
<span class="ltx_bibblock">
Lei Wang and Ee-Peng Lim. 2023.

</span>
<span class="ltx_bibblock">Zero-shot next-item recommendation using large pretrained language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">arXiv preprint arXiv:2304.03153</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span class="ltx_text" id="bib.bib36.2.2.1">.</span> (2024a)</span>
<span class="ltx_bibblock">
Wenjie Wang, Honghui Bao, Xinyu Lin, Jizhi Zhang, Yongqi Li, Fuli Feng, See-Kiong Ng, and Tat-Seng Chua. 2024a.

</span>
<span class="ltx_bibblock">Learnable Tokenizer for LLM-based Generative Recommendation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib36.3.1">arXiv preprint arXiv:2405.07314</em> (2024).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span class="ltx_text" id="bib.bib37.2.2.1">.</span> (2024b)</span>
<span class="ltx_bibblock">
Ye Wang, Jiahao Xun, Mingjie Hong, Jieming Zhu, Tao Jin, Wang Lin, Haoyuan Li, Linjun Li, Yan Xia, Zhou Zhao, et al<span class="ltx_text" id="bib.bib37.3.1">.</span> 2024b.

</span>
<span class="ltx_bibblock">EAGER: Two-Stream Generative Recommender with Behavior-Semantic Collaboration.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib37.4.1">arXiv preprint arXiv:2406.14017</em> (2024).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al<span class="ltx_text" id="bib.bib38.2.2.1">.</span> (2020b)</span>
<span class="ltx_bibblock">
Chuhan Wu, Fangzhao Wu, Tao Qi, Jianxun Lian, Yongfeng Huang, and Xing Xie. 2020b.

</span>
<span class="ltx_bibblock">PTUM: Pre-training user model from unlabeled user behaviors via self-supervision.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib38.3.1">arXiv preprint arXiv:2010.01494</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al<span class="ltx_text" id="bib.bib39.2.2.1">.</span> (2020a)</span>
<span class="ltx_bibblock">
Fangzhao Wu, Ying Qiao, Jiun-Hung Chen, Chuhan Wu, Tao Qi, Jianxun Lian, Danyang Liu, Xing Xie, Jianfeng Gao, Winnie Wu, et al<span class="ltx_text" id="bib.bib39.3.1">.</span> 2020a.

</span>
<span class="ltx_bibblock">Mind: A large-scale dataset for news recommendation. In <em class="ltx_emph ltx_font_italic" id="bib.bib39.4.1">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</em>. 3597–3606.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al<span class="ltx_text" id="bib.bib40.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Likang Wu, Zhaopeng Qiu, Zhi Zheng, Hengshu Zhu, and Enhong Chen. 2024.

</span>
<span class="ltx_bibblock">Exploring large language model for graph data understanding in online job recommendations. In <em class="ltx_emph ltx_font_italic" id="bib.bib40.3.1">Proceedings of the AAAI Conference on Artificial Intelligence</em>, Vol. 38. 9178–9186.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xi et al<span class="ltx_text" id="bib.bib41.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Yunjia Xi, Weiwen Liu, Jianghao Lin, Xiaoling Cai, Hong Zhu, Jieming Zhu, Bo Chen, Ruiming Tang, Weinan Zhang, Rui Zhang, et al<span class="ltx_text" id="bib.bib41.3.1">.</span> 2023.

</span>
<span class="ltx_bibblock">Towards open-world recommendation with knowledge augmentation from large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib41.4.1">arXiv preprint arXiv:2306.10933</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yuan et al<span class="ltx_text" id="bib.bib42.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Zheng Yuan, Fajie Yuan, Yu Song, Youhua Li, Junchen Fu, Fei Yang, Yunzhu Pan, and Yongxin Ni. 2023.

</span>
<span class="ltx_bibblock">Where to Go Next for Recommender Systems? ID- vs. Modality-based Recommender Models Revisited. In <em class="ltx_emph ltx_font_italic" id="bib.bib42.3.1">Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR)</em>. 2639–2649.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span class="ltx_text" id="bib.bib43.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen, Christopher Dewan, Mona Diab, Xian Li, Xi Victoria Lin, et al<span class="ltx_text" id="bib.bib43.3.1">.</span> 2022.

</span>
<span class="ltx_bibblock">Opt: Open pre-trained transformer language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib43.4.1">arXiv preprint arXiv:2205.01068</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al<span class="ltx_text" id="bib.bib44.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Zihuai Zhao, Wenqi Fan, Jiatong Li, Yunqing Liu, Xiaowei Mei, Yiqi Wang, Zhen Wen, Fei Wang, Xiangyu Zhao, Jiliang Tang, et al<span class="ltx_text" id="bib.bib44.3.1">.</span> 2024.

</span>
<span class="ltx_bibblock">Recommender systems in the era of large language models (llms).

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib44.4.1">IEEE Transactions on Knowledge and Data Engineering</em> (2024).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zheng et al<span class="ltx_text" id="bib.bib45.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Bowen Zheng, Yupeng Hou, Hongyu Lu, Yu Chen, Wayne Xin Zhao, Ming Chen, and Ji-Rong Wen. 2024.

</span>
<span class="ltx_bibblock">Adapting large language models by integrating collaborative semantics for recommendation. In <em class="ltx_emph ltx_font_italic" id="bib.bib45.3.1">2024 IEEE 40th International Conference on Data Engineering (ICDE)</em>. IEEE, 1435–1448.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu et al<span class="ltx_text" id="bib.bib46.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Jieming Zhu, Mengqun Jin, Qijiong Liu, Zexuan Qiu, Zhenhua Dong, and Xiu Li. 2024.

</span>
<span class="ltx_bibblock">CoST: Contrastive Quantization based Semantic Tokenization for Generative Recommendation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib46.3.1">CoRR</em> abs/2404.14774 (2024).

</span>
<span class="ltx_bibblock">
</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Fri Sep 13 04:16:42 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
