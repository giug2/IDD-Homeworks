<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Efficient course recommendations with T5-based ranking and summarization</title>
<!--Generated on Thu Jun 27 09:06:02 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2406.19018v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#S1" title="In Efficient course recommendations with T5-based ranking and summarization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#S2" title="In Efficient course recommendations with T5-based ranking and summarization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#S2.SS0.SSS0.Px1" title="In 2 Related work ‣ Efficient course recommendations with T5-based ranking and summarization"><span class="ltx_text ltx_ref_title">Course recommendations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#S2.SS0.SSS0.Px2" title="In 2 Related work ‣ Efficient course recommendations with T5-based ranking and summarization"><span class="ltx_text ltx_ref_title">Quantization of ranking models</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#S3" title="In Efficient course recommendations with T5-based ranking and summarization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Data collection</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#S3.SS1" title="In 3 Data collection ‣ Efficient course recommendations with T5-based ranking and summarization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Course data sources</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#S3.SS2" title="In 3 Data collection ‣ Efficient course recommendations with T5-based ranking and summarization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Pre-processing</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#S3.SS3" title="In 3 Data collection ‣ Efficient course recommendations with T5-based ranking and summarization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Queries</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#S3.SS4" title="In 3 Data collection ‣ Efficient course recommendations with T5-based ranking and summarization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4 </span>Evaluation data</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection">
<a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#S3.SS4.SSS1" title="In 3.4 Evaluation data ‣ 3 Data collection ‣ Efficient course recommendations with T5-based ranking and summarization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4.1 </span>BrightFit IT dataset</span></a>
<ol class="ltx_toclist ltx_toclist_subsubsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#S3.SS4.SSS1.Px1" title="In 3.4.1 BrightFit IT dataset ‣ 3.4 Evaluation data ‣ 3 Data collection ‣ Efficient course recommendations with T5-based ranking and summarization"><span class="ltx_text ltx_ref_title">Query generation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#S3.SS4.SSS1.Px2" title="In 3.4.1 BrightFit IT dataset ‣ 3.4 Evaluation data ‣ 3 Data collection ‣ Efficient course recommendations with T5-based ranking and summarization"><span class="ltx_text ltx_ref_title">Document pool creation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#S3.SS4.SSS1.Px3" title="In 3.4.1 BrightFit IT dataset ‣ 3.4 Evaluation data ‣ 3 Data collection ‣ Efficient course recommendations with T5-based ranking and summarization"><span class="ltx_text ltx_ref_title">Relevance assessment</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#S3.SS4.SSS2" title="In 3.4 Evaluation data ‣ 3 Data collection ‣ Efficient course recommendations with T5-based ranking and summarization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4.2 </span>BrightFit general skill dataset</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#S4" title="In Efficient course recommendations with T5-based ranking and summarization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Methods</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#S4.SS1" title="In 4 Methods ‣ Efficient course recommendations with T5-based ranking and summarization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>First-stage retrieval</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#S4.SS2" title="In 4 Methods ‣ Efficient course recommendations with T5-based ranking and summarization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Re-ranking</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#S4.SS3" title="In 4 Methods ‣ Efficient course recommendations with T5-based ranking and summarization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Summarization</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#S4.SS4" title="In 4 Methods ‣ Efficient course recommendations with T5-based ranking and summarization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4 </span>Quantization</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#S5" title="In Efficient course recommendations with T5-based ranking and summarization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Results</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#S5.SS1" title="In 5 Results ‣ Efficient course recommendations with T5-based ranking and summarization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Experiment 1: First-stage retrieval</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#S5.SS2" title="In 5 Results ‣ Efficient course recommendations with T5-based ranking and summarization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Experiment 2: Re-ranking</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#S5.SS3" title="In 5 Results ‣ Efficient course recommendations with T5-based ranking and summarization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3 </span>Experiment 3: Summarization</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#S5.SS4" title="In 5 Results ‣ Efficient course recommendations with T5-based ranking and summarization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.4 </span>Experiment 4: Quantization</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#S5.SS5" title="In 5 Results ‣ Efficient course recommendations with T5-based ranking and summarization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.5 </span>Experiment 5: User evaluation</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection">
<a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#S5.SS5.SSS1" title="In 5.5 Experiment 5: User evaluation ‣ 5 Results ‣ Efficient course recommendations with T5-based ranking and summarization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.5.1 </span>A/B test</span></a>
<ol class="ltx_toclist ltx_toclist_subsubsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#S5.SS5.SSS1.Px1" title="In 5.5.1 A/B test ‣ 5.5 Experiment 5: User evaluation ‣ 5 Results ‣ Efficient course recommendations with T5-based ranking and summarization"><span class="ltx_text ltx_ref_title">Ranking model selected for test</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#S5.SS5.SSS1.Px2" title="In 5.5.1 A/B test ‣ 5.5 Experiment 5: User evaluation ‣ 5 Results ‣ Efficient course recommendations with T5-based ranking and summarization"><span class="ltx_text ltx_ref_title">Experiment design</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#S5.SS5.SSS1.Px3" title="In 5.5.1 A/B test ‣ 5.5 Experiment 5: User evaluation ‣ 5 Results ‣ Efficient course recommendations with T5-based ranking and summarization"><span class="ltx_text ltx_ref_title">Results</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsubsection">
<a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#S5.SS5.SSS2" title="In 5.5 Experiment 5: User evaluation ‣ 5 Results ‣ Efficient course recommendations with T5-based ranking and summarization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.5.2 </span>User questionnaire</span></a>
<ol class="ltx_toclist ltx_toclist_subsubsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#S5.SS5.SSS2.Px1" title="In 5.5.2 User questionnaire ‣ 5.5 Experiment 5: User evaluation ‣ 5 Results ‣ Efficient course recommendations with T5-based ranking and summarization"><span class="ltx_text ltx_ref_title">Study design</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#S5.SS5.SSS2.Px2" title="In 5.5.2 User questionnaire ‣ 5.5 Experiment 5: User evaluation ‣ 5 Results ‣ Efficient course recommendations with T5-based ranking and summarization"><span class="ltx_text ltx_ref_title">Results</span></a></li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#S6" title="In Efficient course recommendations with T5-based ranking and summarization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Discussion</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#S6.SS0.SSS0.Px1" title="In 6 Discussion ‣ Efficient course recommendations with T5-based ranking and summarization"><span class="ltx_text ltx_ref_title">Comparing datasets</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#S6.SS0.SSS0.Px2" title="In 6 Discussion ‣ Efficient course recommendations with T5-based ranking and summarization"><span class="ltx_text ltx_ref_title">Quantization</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#S6.SS0.SSS0.Px3" title="In 6 Discussion ‣ Efficient course recommendations with T5-based ranking and summarization"><span class="ltx_text ltx_ref_title">User studies</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#S7" title="In Efficient course recommendations with T5-based ranking and summarization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Conclusion</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<div class="ltx_para" id="p1">
<span class="ltx_ERROR undefined" id="p1.1">\copyrightclause</span>
<p class="ltx_p" id="p1.2">Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).</p>
</div>
<div class="ltx_para" id="p2">
<span class="ltx_ERROR undefined" id="p2.1">\conference</span>
<p class="ltx_p" id="p2.2">ReNeuIR 2024 (at SIGIR 2024) – 3rd Workshop on Reaching Efficiency in Neural Information Retrieval, 18 July, 2024, Washington D.C, USA</p>
</div>
<div class="ltx_para" id="p3">
<p class="ltx_p" id="p3.1">[orcid=0009-0000-9550-2502,
]


</p>
</div>
<div class="ltx_para" id="p4">
<p class="ltx_p" id="p4.1">[]
[orcid=0000-0002-9609-9505,
email=s.verberne@liacs.leidenuniv.nl,
]
</p>
</div>
<h1 class="ltx_title ltx_title_document">Efficient course recommendations with T5-based ranking and summarization</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Thijmen Bijl
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_address">Randstad, the Netherlands
</span>
<span class="ltx_contact ltx_role_address">Leiden Institute of Advanced Computer Science, Leiden University, the Netherlands
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Niels van Weeren
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Suzan Verberne
</span></span>
</div>
<div class="ltx_dates">(2024)</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id1.id1">In this paper, we implement and evaluate a two-stage retrieval pipeline for a course recommender system that ranks courses for skill–occupation pairs.
The in-production recommender system BrightFit provides course recommendations from multiple sources. Some of the course descriptions are long and noisy, while retrieval and ranking in an online system have to be highly efficient.
We developed a two-step retrieval pipeline with RankT5 finetuned on MSMARCO as re-ranker. We compare two summarizers for course descriptions: a LongT5 model that we finetuned for the task, and a generative LLM (Vicuna) with in-context learning. We experiment with quantization to reduce the size of the ranking model and increase inference speed. We evaluate our rankers on two newly labelled datasets, with an A/B test, and with a user questionnaire.
On the two labelled datasets, our proposed two-stage ranking with automatic summarization achieves a substantial improvement over the in-production (BM25) ranker: nDCG@10 scores improve from 0.482 to 0.684 and from 0.447 to 0.844 on the two datasets. We also achieve a 40% speed-up by using a quantized version of RankT5. The improved quality of the ranking was confirmed by the questionnaire completed by 29 respondents, but not by the A/B test. In the A/B test, a higher clickthrough rate was observed for the BM25-ranking than for the proposed two-stage retrieval.
We conclude that T5-based re-ranking and summarization for online course recommendation can obtain much better effectiveness than single-step lexical retrieval, and that quantization has a large effect on RankT5. In the online evaluation, however, other factors than relevance play a role (such as speed and interpretability of the retrieval results), as well as individual preferences.
</p>
</div>
<div class="ltx_classification">
<h6 class="ltx_title ltx_title_classification">keywords: </h6>
Course recommendation <span class="ltx_ERROR undefined" id="id2.id1">\sep</span>Ranking models <span class="ltx_ERROR undefined" id="id3.id2">\sep</span>Summarization <span class="ltx_ERROR undefined" id="id4.id3">\sep</span>Evaluation <span class="ltx_ERROR undefined" id="id5.id4">\sep</span>Quantization

</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">With a rapidly changing labour market, it is becoming more important for people to adapt to these changing demands in order to remain relevant to employers. The topic of <span class="ltx_text ltx_font_italic" id="S1.p1.1.1">skilling</span> (learning new skills) plays an important role in the current labour market, both for employers and employees. For employers, it is in their best interest to let their employees learn new skills in order to remain competitive. For the employees, it is important to keep learning new skills in order to grow in their current job or get better career opportunities at other organizations.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">In the “Future of Jobs" report by the World Economic Forum (WEF) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#bib.bib1" title="">1</a>]</cite>, it is estimated that 44% of the in-demand skills will change between 2023 and 2028. Another survey among 2000 HR professionals and employees indicates that there is much interest in re- and up-skilling <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#bib.bib2" title="">2</a>]</cite>. However, the survey also finds that while both employees and employers see the benefits of learning new skills, they struggle with finding and identifying good skilling opportunities.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">The online recommender system <span class="ltx_text ltx_font_italic" id="S1.p3.1.1">BrightFit</span>, a system developed by Randstad Risesmart<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://go.randstadrisesmart.com/BrightFit" title="">https://go.randstadrisesmart.com/BrightFit</a></span></span></span>,
aims to help users explore future potential roles by looking at their current skill set and determining the skill gap to the next job or role they aspire to get. For this, BrightFit recommends online courses from several mainstream course providers to help a user learn a particular skill.
</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">In this paper, we approach the problem of recommending courses as an information retrieval (IR) problem. This alleviates the cold start problem that collaborative or content-based filtering approaches suffer from: both require historical user data to predict the users’ preferences. The users of BrightFit are typically short-term users for whom historical profile data is not available. Thus, we are not recommending courses based on previous user activities, but based on a combination of the user’s job profile and the skill they want to learn.
A query consisting of the skill and the job profile is automatically constructed and issued to the index with course descriptions.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">The current ranker in BrightFit’s backend is BM25-based. We propose a two-stage retrieval method that leverages the power of transformer-based models while keeping the time to generate recommendations reasonable. We first evaluate two first-stage retrievers (the dense retriever GTR and BM25), followed by the re-ranker RankT5 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#bib.bib3" title="">3</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">Since we do not have any human-labelled training data, the ranking is performed in a zero-shot setting. For evaluation, we compile and label 2 datasets with relevance assessments on three levels, for over 2500 query–document pairs.</p>
</div>
<div class="ltx_para" id="S1.p7">
<p class="ltx_p" id="S1.p7.1">Course retrieval comes with an additional challenge that the course descriptions are often long and contain irrelevant information, making it more difficult to efficiently retrieve the correct courses. We therefore evaluate summarization methods in our retrieval pipeline to both shorten and de-noise the course descriptions. We investigate if we can we improve the ranking by summarizing the course descriptions.
We compare two summarization models: LongT5 (an encoder-decoder model), which we finetune on pairs of long and short course descriptions, and Vicuna (a decoder-only LLM), with a zero-shot instruction prompt.</p>
</div>
<div class="ltx_para" id="S1.p8">
<p class="ltx_p" id="S1.p8.1">Since we are providing recommendations to real users in real-time, inference of the models has to be fast: BrightFit has a few seconds at most to provide the recommendations.
We therefore investigate model quantization (compressing the parameters of the RankT5 model) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#bib.bib4" title="">4</a>]</cite> as a way to increase inference speed and decrease storage/memory requirements. This can come at the cost of reduced model performance since we store the weights in lower precision. We evaluate quantization of our RankT5 model without compromising the quality of the recommendations too much.</p>
</div>
<div class="ltx_para" id="S1.p9">
<p class="ltx_p" id="S1.p9.1">Lastly, we evaluate how the improvements in offline datasets translate to the user’s perception of the recommendations. Prior work has indicated the importance of user studies for the evaluation of recommender systems <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#bib.bib5" title="">5</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#bib.bib6" title="">6</a>]</cite>.
We use an A/B test and a user questionnaire to evaluate whether our changes to the recommendations in BrightFit make a positive impact on the usage of the system.</p>
</div>
<div class="ltx_para" id="S1.p10">
<p class="ltx_p" id="S1.p10.1">In summary, we make the following contributions:</p>
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">We create two labelled datasets for evaluation of course retrieval for skills and occupations.<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>We released our data through <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/tbijl/course_ranking_data" title="">https://github.com/tbijl/course_ranking_data</a> Note that the documents are listed in the form of URLs in their course provider domain.</span></span></span></p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">We show that automatic summarization of the course descriptions improves the effectiveness of the course ranking.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">We show that quantization of RankT5 does not reduce the effectiveness, while substantially improving the inference speed of the ranker.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i4.p1">
<p class="ltx_p" id="S1.I1.i4.p1.1">With an online A/B test with real users and explicit user feedback in a questionnaire, we show that evaluation of course recommendation is challenging and that other factors than relevance play a role in user preferences.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related work</h2>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Course recommendations</h5>
<div class="ltx_para" id="S2.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px1.p1.1">The previous work on course recommendations is largely based on user profiles. Imran et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#bib.bib7" title="">7</a>]</cite> ask users about their prior knowledge to establish a user profile. This profile is extended based on user behaviour in the recommender system. In the context of MOOCs (Massive open online courses), Jing and Tang <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#bib.bib8" title="">8</a>]</cite> identify the challenges of user behavior modeling for course recommendation. They also argue that students might participate in courses for different reasons, and therefore collaborative filtering methods are not successful for course recommendation. They propose the use of historical user data to build an interest profile. For our use case, we do not have user behaviour history for the majority of the users, because BrightFit is used as a short-term tool and users have a large variety of occupations and skillsets. We therefore recommend courses for a specific skill, not based on a user profile.</p>
</div>
<div class="ltx_para" id="S2.SS0.SSS0.Px1.p2">
<p class="ltx_p" id="S2.SS0.SSS0.Px1.p2.1">Because skills can be organized in structured databases, ontology-based approaches are commonly used in prior work on course retrieval and recommendation <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#bib.bib9" title="">9</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#bib.bib10" title="">10</a>]</cite>. One approach is to map learners and learning materials to topics in an ontology, and then recommend courses for topics to the learners using the relations between items in the ontology <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#bib.bib11" title="">11</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#bib.bib12" title="">12</a>]</cite>.
The alternative is to start with a skills ontology and then collect publicly available resources as educational content for each skill in the ontology <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#bib.bib13" title="">13</a>]</cite>. Ontology-based approaches can be effective for finding and recommending courses that are related to a certain topic, however, they come with the drawback of knowledge engineering to map all courses to topics in the ontology. This makes these approaches unfeasible to use in contexts with a pre-defined large collection of unstructured course descriptions, like in BrightFit. In this setting, a text retrieval approach is more fit.</p>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">Quantization of ranking models</h5>
<div class="ltx_para" id="S2.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px2.p1.1">There is only limited prior work on the use of quantization methods to make ranking models more efficient. Quantization has been applied in prior work to the encoding of token embeddings  <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#bib.bib14" title="">14</a>]</cite> and to efficient storage of decision trees in learning-to-rank ensembles <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#bib.bib15" title="">15</a>]</cite>. Recent work has addressed quantization for the efficient coding of the document IDs in generative IR <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#bib.bib16" title="">16</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#bib.bib17" title="">17</a>]</cite>. In one prior work <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#bib.bib18" title="">18</a>]</cite>, quantization is mentioned as a suggestion to further improve the efficiency of SPLADE (sparse neural retrieval). To the best of our knowledge, our paper is the first to apply quantization to RankT5 or other transformer-encoder ranking models.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Data collection</h2>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Course data sources</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">BrightFit offers courses from four different online learning platforms. Table <a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#S3.T1" title="Table 1 ‣ 3.1 Course data sources ‣ 3 Data collection ‣ Efficient course recommendations with T5-based ranking and summarization"><span class="ltx_text ltx_ref_tag">1</span></a> shows an overview of the total number of courses per provider.
<span class="ltx_text ltx_font_italic" id="S3.SS1.p1.1.1">Udemy</span> is an online learning platform that offers video courses about a large variety of topics. Udemy is a marketplace where users can create and sell their own courses or buy and take courses created by other users. We retrieved course metadata from Udemy using the public Udemy affiliate API.<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.udemy.com/developers/affiliate/" title="">https://www.udemy.com/developers/affiliate/</a></span></span></span> This API returns general information about the courses that Udemy provides. In total, Udemy has over <math alttext="210,000" class="ltx_Math" display="inline" id="S3.SS1.p1.1.m1.2"><semantics id="S3.SS1.p1.1.m1.2a"><mrow id="S3.SS1.p1.1.m1.2.3.2" xref="S3.SS1.p1.1.m1.2.3.1.cmml"><mn id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">210</mn><mo id="S3.SS1.p1.1.m1.2.3.2.1" xref="S3.SS1.p1.1.m1.2.3.1.cmml">,</mo><mn id="S3.SS1.p1.1.m1.2.2" xref="S3.SS1.p1.1.m1.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.2b"><list id="S3.SS1.p1.1.m1.2.3.1.cmml" xref="S3.SS1.p1.1.m1.2.3.2"><cn id="S3.SS1.p1.1.m1.1.1.cmml" type="integer" xref="S3.SS1.p1.1.m1.1.1">210</cn><cn id="S3.SS1.p1.1.m1.2.2.cmml" type="integer" xref="S3.SS1.p1.1.m1.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.2c">210,000</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.1.m1.2d">210 , 000</annotation></semantics></math> courses available on its website. We only use English courses. <span class="ltx_text ltx_font_italic" id="S3.SS1.p1.1.2">Udemy Business</span> is similar to Udemy. It is a subscription service offered by Udemy to businesses that provides access to a curated subset of high-quality Udemy courses, via a separate Udemy Business API.<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://business-support.udemy.com/hc/en-us/articles/11965611508375-Udemy-Business-API-Best-Practices" title="">https://business-support.udemy.com/hc/en-us/articles/11965611508375-Udemy-Business-API-Best-Practices</a></span></span></span> <span class="ltx_text ltx_font_italic" id="S3.SS1.p1.1.3">edX</span> is a company that offers high-quality university-level courses. The data that we have available for the edX courses is limited compared to the data retrieved from the Udemy APIs. For the edX courses, we only have access to the course title, short course description and full course description. However, it is important to note that the short course descriptions of edX are of much better quality than the short course descriptions (headline) that we get from Udemy and Udemy Business. This makes them suitable for summarizer fine-tuning, as we will see later. <span class="ltx_text ltx_font_italic" id="S3.SS1.p1.1.4">GoodHabitz</span> provides online courses and training as a subscription service for businesses. The courses offered by GoodHabitz are largely focused on soft skills, like teamwork and collaboration. Similar to the edX courses the GoodHabitz courses only have a course title and course description to work with.</p>
</div>
<figure class="ltx_table" id="S3.T1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span>Overview of the number of courses per provider.</figcaption>
<table class="ltx_tabular ltx_align_middle" id="S3.T1.1">
<tr class="ltx_tr" id="S3.T1.1.1">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T1.1.1.1"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.1">Provider</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T1.1.1.2"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.2.1">Count</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.2">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T1.1.2.1">Udemy</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T1.1.2.2">54,348</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.3">
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T1.1.3.1">Udemy Business</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.3.2">10,414</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.4">
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T1.1.4.1">edX</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.4.2">2,077</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.5">
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T1.1.5.1">GoodHabitz</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.5.2">127</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.6">
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="S3.T1.1.6.1">Total</td>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_t" id="S3.T1.1.6.2">66,966</td>
</tr>
</table>
</figure>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Pre-processing</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">We convert all course descriptions from HTML to plain text, harmonize the encoding to Unicode, and standardize the names of the fields from the different course providers. Figure <a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#S3.F1" title="Figure 1 ‣ 3.2 Pre-processing ‣ 3 Data collection ‣ Efficient course recommendations with T5-based ranking and summarization"><span class="ltx_text ltx_ref_tag">1</span></a> shows a comparison of the lengths of the inputs for each course provider, consisting of the course titles concatenated with their full descriptions, tokenized with the Huggingface T5-base tokenizer <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#bib.bib19" title="">19</a>]</cite>. We see that a substantial proportion (18,467 / 66,966 = 27.6%) of courses are longer than the limit of 512 tokens. By default, inputs that go beyond this limit will be truncated. This motivates the use of summarization (see Section <a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#S4.SS3" title="4.3 Summarization ‣ 4 Methods ‣ Efficient course recommendations with T5-based ranking and summarization"><span class="ltx_text ltx_ref_tag">4.3</span></a>)</p>
</div>
<figure class="ltx_figure" id="S3.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="436" id="S3.F1.g1" src="x1.png" width="581"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Overview of the tokenized input size distribution of the course titles combined with the descriptions of all BrightFit courses per provider. The horizontal line marks the input size of 512 tokens which is the maximum for T5.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Queries</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">In BrightFit, users choose an occupation or job role they want to explore. They are asked to perform a self-assessment on how proficient they are in the most important skills for that role. After completing the self-assessment, users receive a report which includes the most important skills they need to develop, in order to have a more relevant skill set for the selected occupation or job role.
For providing course recommendations, the BrightFit system generates a query based on the skill that the user wants to learn and their job/role title. The query that the retrieval engine receives has the form <span class="ltx_text ltx_font_italic" id="S3.SS3.p1.1.1">“&lt;skill&gt; for &lt;occupation&gt;”</span>, e.g. <span class="ltx_text ltx_font_italic" id="S3.SS3.p1.1.2">“Python for Data Analyst”</span>. Both terms come from a lookup in the Burning Glass taxonomy <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#bib.bib20" title="">20</a>]</cite> based on the self assessment of the user.<span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span>Burning Glass was later merged into Lightcast. We still use the original Burning Glass taxonomy.</span></span></span> The occupation is used to provide more context for the course recommendations. </p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Evaluation data</h3>
<div class="ltx_para" id="S3.SS4.p1">
<p class="ltx_p" id="S3.SS4.p1.1">In this section, we present two datasets that we created for evaluating BrightFit: the BrightFit IT dataset and the BrightFit general skills dataset.</p>
</div>
<section class="ltx_subsubsection" id="S3.SS4.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.4.1 </span>BrightFit IT dataset</h4>
<div class="ltx_para" id="S3.SS4.SSS1.p1">
<p class="ltx_p" id="S3.SS4.SSS1.p1.1">The first dataset that we create is the BrightFit IT dataset, which is only focussed on IT skills. IT skills often have more courses available compared to other types of skills. This should give us a good dataset that can be used to see how the system behaves in cases where there are plenty of courses available for a skill.</p>
</div>
<section class="ltx_paragraph" id="S3.SS4.SSS1.Px1">
<h5 class="ltx_title ltx_title_paragraph">Query generation</h5>
<div class="ltx_para" id="S3.SS4.SSS1.Px1.p1">
<p class="ltx_p" id="S3.SS4.SSS1.Px1.p1.1">The first step in creating the dataset is to select the queries we will use to evaluate the model. The course catalogue of BrightFit has many courses related to IT skills (because IT skills are relatively easy to learn online).
In total we label data for 15 different skills. We combine each skill with 3 occupations that are common for that skill giving us a total of <math alttext="15*3=45" class="ltx_Math" display="inline" id="S3.SS4.SSS1.Px1.p1.1.m1.1"><semantics id="S3.SS4.SSS1.Px1.p1.1.m1.1a"><mrow id="S3.SS4.SSS1.Px1.p1.1.m1.1.1" xref="S3.SS4.SSS1.Px1.p1.1.m1.1.1.cmml"><mrow id="S3.SS4.SSS1.Px1.p1.1.m1.1.1.2" xref="S3.SS4.SSS1.Px1.p1.1.m1.1.1.2.cmml"><mn id="S3.SS4.SSS1.Px1.p1.1.m1.1.1.2.2" xref="S3.SS4.SSS1.Px1.p1.1.m1.1.1.2.2.cmml">15</mn><mo id="S3.SS4.SSS1.Px1.p1.1.m1.1.1.2.1" lspace="0.222em" rspace="0.222em" xref="S3.SS4.SSS1.Px1.p1.1.m1.1.1.2.1.cmml">∗</mo><mn id="S3.SS4.SSS1.Px1.p1.1.m1.1.1.2.3" xref="S3.SS4.SSS1.Px1.p1.1.m1.1.1.2.3.cmml">3</mn></mrow><mo id="S3.SS4.SSS1.Px1.p1.1.m1.1.1.1" xref="S3.SS4.SSS1.Px1.p1.1.m1.1.1.1.cmml">=</mo><mn id="S3.SS4.SSS1.Px1.p1.1.m1.1.1.3" xref="S3.SS4.SSS1.Px1.p1.1.m1.1.1.3.cmml">45</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS1.Px1.p1.1.m1.1b"><apply id="S3.SS4.SSS1.Px1.p1.1.m1.1.1.cmml" xref="S3.SS4.SSS1.Px1.p1.1.m1.1.1"><eq id="S3.SS4.SSS1.Px1.p1.1.m1.1.1.1.cmml" xref="S3.SS4.SSS1.Px1.p1.1.m1.1.1.1"></eq><apply id="S3.SS4.SSS1.Px1.p1.1.m1.1.1.2.cmml" xref="S3.SS4.SSS1.Px1.p1.1.m1.1.1.2"><times id="S3.SS4.SSS1.Px1.p1.1.m1.1.1.2.1.cmml" xref="S3.SS4.SSS1.Px1.p1.1.m1.1.1.2.1"></times><cn id="S3.SS4.SSS1.Px1.p1.1.m1.1.1.2.2.cmml" type="integer" xref="S3.SS4.SSS1.Px1.p1.1.m1.1.1.2.2">15</cn><cn id="S3.SS4.SSS1.Px1.p1.1.m1.1.1.2.3.cmml" type="integer" xref="S3.SS4.SSS1.Px1.p1.1.m1.1.1.2.3">3</cn></apply><cn id="S3.SS4.SSS1.Px1.p1.1.m1.1.1.3.cmml" type="integer" xref="S3.SS4.SSS1.Px1.p1.1.m1.1.1.3">45</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS1.Px1.p1.1.m1.1c">15*3=45</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.SSS1.Px1.p1.1.m1.1d">15 ∗ 3 = 45</annotation></semantics></math> queries for our dataset.
We select the IT occupations from the Burning Glass Occupation Taxonomy. We improve the diversity of our set by filtering out the senior versions of other occupations that are in the taxonomy, e.g. “Senior Java Developer/Engineer" when “Java Developer/Engineer" also exists, and we filter out the very general occupation “Software Developer/Engineer". The resulting set contains 148 IT occupations.
We then select for each of the 15 skills the 3 occupations that have the most mentions for the skill in the Burning Glass job posting data about skill occurrences in the United States <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#bib.bib21" title="">21</a>]</cite> in 2022. This way, we create 45 skill–occupation pairs.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS4.SSS1.Px2">
<h5 class="ltx_title ltx_title_paragraph">Document pool creation</h5>
<div class="ltx_para" id="S3.SS4.SSS1.Px2.p1">
<p class="ltx_p" id="S3.SS4.SSS1.Px2.p1.1">We manually label 50 documents for each query. Since one of the use cases for the annotated dataset is to compare the current BrightFit retriever with the newly proposed method, we need to create a fair dataset for both rankers. To accomplish this we obtain the top 25 from the two retrievers we discuss in Section <a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#S4.SS1" title="4.1 First-stage retrieval ‣ 4 Methods ‣ Efficient course recommendations with T5-based ranking and summarization"><span class="ltx_text ltx_ref_tag">4.1</span></a>. We interleave documents retrieved from the two retrievers to build a top 50 list. We remove duplicate documents for queries where both retrievers have retrieved the same document.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS4.SSS1.Px3">
<h5 class="ltx_title ltx_title_paragraph">Relevance assessment</h5>
<div class="ltx_para" id="S3.SS4.SSS1.Px3.p1">
<p class="ltx_p" id="S3.SS4.SSS1.Px3.p1.1">We label the query–document pairs on three relevance levels:</p>
<ul class="ltx_itemize" id="S3.I1">
<li class="ltx_item" id="S3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I1.i1.p1">
<p class="ltx_p" id="S3.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i1.p1.1.1">2</span>: Course is relevant for the skill–occupation combination and specific to the occupation. E.g. with the query “Python for ML Engineer" and a course “Learn Python for Machine Learning".</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I1.i2.p1">
<p class="ltx_p" id="S3.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i2.p1.1.1">1</span>: Course is relevant for the skill but it is generic. E.g. a course “Python for beginners" for the query “Python for ML Engineer".</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I1.i3.p1">
<p class="ltx_p" id="S3.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i3.p1.1.1">0</span>: Course is not relevant for the skill or the course is specific for the skill and a different occupation. E.g. When the query is “Python for Database Engineer" and the course is "Learn Python for Machine Learning".</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S3.SS4.SSS1.Px3.p2">
<p class="ltx_p" id="S3.SS4.SSS1.Px3.p2.1">The idea behind the labels is as follows: In the ideal case we want to recommend courses to users that teach a specific skill, but that are also relevant to the occupation they are trying to close their skill gap to. Therefore we want to prioritize courses that teach a skill in a context that is relevant for the user. However, it will often be the case that there is no perfect course that exactly teaches a certain skill in the context of the specific occupation we are looking for. In this case, we need alternatives to recommend that still teach the skill. We assign label 0 to courses that do not teach the skill we are searching for and courses that do teach the skill but in a context that is very different from the role the user is exploring. We do this as we believe that a generic course about a skill is more relevant than a course that teaches a skill in a context that is not relevant to the user. These labelling guidelines have also been discussed with a Learning and Development expert affiliated to BrightFit, to ensure that the guidelines align with what is expected from the recommender system.
</p>
</div>
</section>
</section>
<section class="ltx_subsubsection" id="S3.SS4.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.4.2 </span>BrightFit general skill dataset</h4>
<div class="ltx_para" id="S3.SS4.SSS2.p1">
<p class="ltx_p" id="S3.SS4.SSS2.p1.1">Similar to the BrightFit IT dataset we first create a set of queries. For this dataset, we randomly sample 10 occupations from the full taxonomy. We then select a random skill from the top 10 most common skills for each occupation based on the Burning Glass job posting data <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#bib.bib21" title="">21</a>]</cite>. We added as an additional constraint to the random skill/occupation pairs that the first-stage retriever should be able to at least retrieve 5 documents with a cosine similarity &gt;= 0.6. This additional constraint improves the quality of the queries and documents in the dataset, making the dataset more useful for evaluation. To obtain the documents to rate for each query we use the same method as for the BrightFit IT dataset. We also use the same relevance labelling rules.</p>
</div>
<div class="ltx_para" id="S3.SS4.SSS2.p2">
<p class="ltx_p" id="S3.SS4.SSS2.p2.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#S3.T2" title="Table 2 ‣ 3.4.2 BrightFit general skill dataset ‣ 3.4 Evaluation data ‣ 3 Data collection ‣ Efficient course recommendations with T5-based ranking and summarization"><span class="ltx_text ltx_ref_tag">2</span></a> shows the statistics for the two datasets. On average, the BrightFit IT skills dataset has more relevant courses for each query than the general skills dataset. This is because there exists a large amount of online courses for IT-related skills as they are easier to teach and learn online.</p>
</div>
<figure class="ltx_table" id="S3.T2">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Overview of the two labelled BrightFit datasets. The total number of indexed documents in BrightFit is 66,966.</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S3.T2.1">
<tr class="ltx_tr" id="S3.T2.1.1">
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T2.1.1.1">Dataset information</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T2.1.1.2">IT</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T2.1.1.3">general</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T2.1.2.1">Total number of unique documents with label</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T2.1.2.2">1,035</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T2.1.2.3">500</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.3">
<td class="ltx_td ltx_align_left" id="S3.T2.1.3.1">Total number of queries</td>
<td class="ltx_td ltx_align_right" id="S3.T2.1.3.2">45</td>
<td class="ltx_td ltx_align_right" id="S3.T2.1.3.3">10</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.4">
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T2.1.4.1">Query information</td>
<td class="ltx_td ltx_border_t" id="S3.T2.1.4.2"></td>
<td class="ltx_td ltx_border_t" id="S3.T2.1.4.3"></td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.5">
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T2.1.5.1">Lowest average relevance per query</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T2.1.5.2">0.20</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T2.1.5.3">0.26</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.6">
<td class="ltx_td ltx_align_left" id="S3.T2.1.6.1">Highest average relevance per query</td>
<td class="ltx_td ltx_align_right" id="S3.T2.1.6.2">1.68</td>
<td class="ltx_td ltx_align_right" id="S3.T2.1.6.3">1.20</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.7">
<td class="ltx_td ltx_align_left" id="S3.T2.1.7.1">Mean average relevance per query</td>
<td class="ltx_td ltx_align_right" id="S3.T2.1.7.2">0.84</td>
<td class="ltx_td ltx_align_right" id="S3.T2.1.7.3">0.74</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.8">
<td class="ltx_td ltx_align_left" id="S3.T2.1.8.1">Mean relevance count per query, label 0</td>
<td class="ltx_td ltx_align_right" id="S3.T2.1.8.2">19.3</td>
<td class="ltx_td ltx_align_right" id="S3.T2.1.8.3">24.0</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.9">
<td class="ltx_td ltx_align_left" id="S3.T2.1.9.1">Mean relevance count per query, label 1</td>
<td class="ltx_td ltx_align_right" id="S3.T2.1.9.2">19.3</td>
<td class="ltx_td ltx_align_right" id="S3.T2.1.9.3">14.9</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.10">
<td class="ltx_td ltx_align_left" id="S3.T2.1.10.1">Mean relevance count per query, label 2</td>
<td class="ltx_td ltx_align_right" id="S3.T2.1.10.2">11.4</td>
<td class="ltx_td ltx_align_right" id="S3.T2.1.10.3">11.1</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.11">
<td class="ltx_td ltx_align_left ltx_border_b" id="S3.T2.1.11.1">Average number of labels per query</td>
<td class="ltx_td ltx_align_right ltx_border_b" id="S3.T2.1.11.2">50</td>
<td class="ltx_td ltx_align_right ltx_border_b" id="S3.T2.1.11.3">50</td>
</tr>
</table>
</figure>
</section>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Methods</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">We follow a two-stage retrieval approach, with efficient first-stage retrievers (<a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#S4.SS1" title="4.1 First-stage retrieval ‣ 4 Methods ‣ Efficient course recommendations with T5-based ranking and summarization"><span class="ltx_text ltx_ref_tag">4.1</span></a>), and a more effective re-ranker (<a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#S4.SS2" title="4.2 Re-ranking ‣ 4 Methods ‣ Efficient course recommendations with T5-based ranking and summarization"><span class="ltx_text ltx_ref_tag">4.2</span></a>). We experiment with summarization of course descriptions (<a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#S4.SS3" title="4.3 Summarization ‣ 4 Methods ‣ Efficient course recommendations with T5-based ranking and summarization"><span class="ltx_text ltx_ref_tag">4.3</span></a>) and quantization of the re-ranker for more efficient real-time ranking (<a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#S4.SS4" title="4.4 Quantization ‣ 4 Methods ‣ Efficient course recommendations with T5-based ranking and summarization"><span class="ltx_text ltx_ref_tag">4.4</span></a>).</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>First-stage retrieval</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">The current in-production ranker in the BrightFit course recommendation system is BM25 with a weight of 2 for the title and 1 for the course description. Additionally, a score multiplier of 7 is applied when there is a perfect match with the skill text in the title. We compare this in-production ranker to a T5-based <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#bib.bib19" title="">19</a>]</cite> retriever called GTR <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#bib.bib22" title="">22</a>]</cite> which has shown good zero-shot performance on the BEIR benchmark. In this research, we use the <span class="ltx_text ltx_font_typewriter" id="S4.SS1.p1.1.1">GTR-Base<span class="ltx_note ltx_role_footnote" id="footnote6"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_serif" id="footnote6.1.1.1">6</span></span><a class="ltx_ref ltx_url" href="https://huggingface.co/sentence-transformers/gtr-t5-base" title="">https://huggingface.co/sentence-transformers/gtr-t5-base</a></span></span></span></span> version of the retriever as a zero-shot first-stage retriever. The query we use for first-stage retrieval is the same query format as described in Section <a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#S3.SS3" title="3.3 Queries ‣ 3 Data collection ‣ Efficient course recommendations with T5-based ranking and summarization"><span class="ltx_text ltx_ref_tag">3.3</span></a>: “<span class="ltx_text ltx_font_italic" id="S4.SS1.p1.1.2">&lt;skill&gt; for &lt;occupation&gt;</span>”. The documents are embedded using the format: <span class="ltx_text ltx_font_italic" id="S4.SS1.p1.1.3">“Title: &lt;course title&gt; Description: &lt;course description&gt;"</span>. For a given query we retrieve the top <math alttext="k" class="ltx_Math" display="inline" id="S4.SS1.p1.1.m1.1"><semantics id="S4.SS1.p1.1.m1.1a"><mi id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><ci id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.1.m1.1d">italic_k</annotation></semantics></math> courses based on cosine similarity.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Re-ranking</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">As our second stage re-ranker model, we use RankT5 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#bib.bib3" title="">3</a>]</cite>. We choose the RankT5-Enc architecture since this has half the number of parameters compared to the RankT5-EncDec architecture while achieving comparable performance <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#bib.bib3" title="">3</a>]</cite>. With fewer parameters, the model also uses less memory and has faster inference speed which is useful for the efficient deployment of the model in the BrightFit application.</p>
</div>
<div class="ltx_para" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1">We do not have access to labelled data that we can use for fine-tuning the RankT5 model to the BrightFit domain, but it was shown <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#bib.bib3" title="">3</a>]</cite> that the model is capable of achieving good zero-shot performance by training it on the MSMARCO passage ranking dataset <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#bib.bib23" title="">23</a>]</cite>. We use the version of the MSMARCO dataset in the BEIR benchmark <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#bib.bib24" title="">24</a>]</cite> to finetune our model. Finetuning RankT5 requires hard negatives. We sample these hard negatives for each query in the MSMARCO dataset using the GTR-Base retriever to obtain the top 1000 documents for each query and consider each document that does not have a positive relevance label for the query as a hard negative.</p>
</div>
<div class="ltx_para" id="S4.SS2.p3">
<p class="ltx_p" id="S4.SS2.p3.1">We use the listwise softmax loss function with a list size of 36 for the softmax loss, as higher list sizes have shown to result in better zero-shot performance <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#bib.bib3" title="">3</a>]</cite>. We train the model for 50,000 steps, similar to the RankT5 paper, and we evaluate the model every 5,000 steps and take the best-performing checkpoint. For training, we use the AdamW optimizer with a constant learning rate of <math alttext="10^{-4}" class="ltx_Math" display="inline" id="S4.SS2.p3.1.m1.1"><semantics id="S4.SS2.p3.1.m1.1a"><msup id="S4.SS2.p3.1.m1.1.1" xref="S4.SS2.p3.1.m1.1.1.cmml"><mn id="S4.SS2.p3.1.m1.1.1.2" xref="S4.SS2.p3.1.m1.1.1.2.cmml">10</mn><mrow id="S4.SS2.p3.1.m1.1.1.3" xref="S4.SS2.p3.1.m1.1.1.3.cmml"><mo id="S4.SS2.p3.1.m1.1.1.3a" xref="S4.SS2.p3.1.m1.1.1.3.cmml">−</mo><mn id="S4.SS2.p3.1.m1.1.1.3.2" xref="S4.SS2.p3.1.m1.1.1.3.2.cmml">4</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.1.m1.1b"><apply id="S4.SS2.p3.1.m1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p3.1.m1.1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1">superscript</csymbol><cn id="S4.SS2.p3.1.m1.1.1.2.cmml" type="integer" xref="S4.SS2.p3.1.m1.1.1.2">10</cn><apply id="S4.SS2.p3.1.m1.1.1.3.cmml" xref="S4.SS2.p3.1.m1.1.1.3"><minus id="S4.SS2.p3.1.m1.1.1.3.1.cmml" xref="S4.SS2.p3.1.m1.1.1.3"></minus><cn id="S4.SS2.p3.1.m1.1.1.3.2.cmml" type="integer" xref="S4.SS2.p3.1.m1.1.1.3.2">4</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.1.m1.1c">10^{-4}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p3.1.m1.1d">10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT</annotation></semantics></math>. Due to hardware limitations, we are not able to run a batch size of 32 like the RankT5 authors, but instead, we run a batch size of 2 with 16 steps of gradient accumulation to emulate the batch size of 32. We implement our model in the PyTorch framework and use the T5-base checkpoint from HuggingFace<span class="ltx_note ltx_role_footnote" id="footnote7"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/t5-base" title="">https://huggingface.co/t5-base</a></span></span></span> to initialize our encoder. We fine-tune our RankT5 model using an RTX 3090 GPU which takes up to 100 hours to fully train the model for 50,000 steps.</p>
</div>
<div class="ltx_para" id="S4.SS2.p4">
<p class="ltx_p" id="S4.SS2.p4.1">The input format for the re-ranker combines the query and document format that we use for the first-stage retriever and combines them using the format described by the RankT5 authors: <span class="ltx_text ltx_font_italic" id="S4.SS2.p4.1.1">“Query: &lt;skill&gt; for &lt;occupation&gt; Document: Title: &lt;course title&gt; Description: &lt;course description&gt;”</span>. If the input to the re-ranker is longer than the maximum input size (512 tokens by default) the input is truncated.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Summarization</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">Since a substantial proportion of the course descriptions in our collection are too long to fit the 512-token input length that T5 supports (see Figure <a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#S3.F1" title="Figure 1 ‣ 3.2 Pre-processing ‣ 3 Data collection ‣ Efficient course recommendations with T5-based ranking and summarization"><span class="ltx_text ltx_ref_tag">1</span></a>), we investigate automatic summarization of the course descriptions as an alternative to truncating. We hope that a side effect of summarization is that we dispose of irrelevant information in the course descriptions that provides noise to the ranker. Examples of this noise are positive user reviews included by course instructor to promote their course on the platform, information about which well-known companies are using the course, and information about the Udemy 30-day money guarantee. Although this information can be relevant to users, it is noise to the ranker. By using summarization we aim to give the re-ranker a cleaner input, which will hopefully improve the ranking performance. The users will be presented with the full course descriptions in BrightFit.
</p>
</div>
<div class="ltx_para" id="S4.SS3.p2">
<p class="ltx_p" id="S4.SS3.p2.1">We generate the summaries at index time, together with the embeddings used in first-stage retrieval. This means that we do not add any additional computation at query-time.</p>
</div>
<div class="ltx_para" id="S4.SS3.p3">
<p class="ltx_p" id="S4.SS3.p3.1">Transformer-based sequence-to-sequence models like T5 have shown strong performance on summarization tasks <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#bib.bib19" title="">19</a>]</cite> and summarization techniques based on the Longformer encoder-decoder model (LED) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#bib.bib25" title="">25</a>]</cite> have effectively been applied to long documents in the context of case law retrieval <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#bib.bib26" title="">26</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#bib.bib27" title="">27</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S4.SS3.p4">
<p class="ltx_p" id="S4.SS3.p4.1">We experiment with two models for summarization: LongT5 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#bib.bib28" title="">28</a>]</cite> and Vicuna <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#bib.bib29" title="">29</a>]</cite>. <span class="ltx_text ltx_font_bold" id="S4.SS3.p4.1.1">LongT5</span> is a T5 model that has been adapted to work efficiently for longer input sequences. The model has shown good performance on summarization of long documents compared to standard T5 models. We use the <span class="ltx_text ltx_font_typewriter" id="S4.SS3.p4.1.2">long-t5-tglobal-base<span class="ltx_note ltx_role_footnote" id="footnote8"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_serif" id="footnote8.1.1.1">8</span></span><a class="ltx_ref ltx_url" href="https://huggingface.co/google/long-t5-tglobal-base" title="">https://huggingface.co/google/long-t5-tglobal-base</a></span></span></span></span> checkpoint from HuggingFace as the base model. We fine-tune this model on 1,868 pairs of long and short course descriptions from the edX data. We chose the edX course descriptions since the short course descriptions from edX are of higher quality than the short descriptions from Udemy. We exclude from the training data the edX course descriptions that are part of our labelled test collection, to prevent data leakage from the train to the test set.
We fine-tune the model for 2 epochs on the pairs of full and short descriptions. We use a learning rate of <math alttext="10^{-4}" class="ltx_Math" display="inline" id="S4.SS3.p4.1.m1.1"><semantics id="S4.SS3.p4.1.m1.1a"><msup id="S4.SS3.p4.1.m1.1.1" xref="S4.SS3.p4.1.m1.1.1.cmml"><mn id="S4.SS3.p4.1.m1.1.1.2" xref="S4.SS3.p4.1.m1.1.1.2.cmml">10</mn><mrow id="S4.SS3.p4.1.m1.1.1.3" xref="S4.SS3.p4.1.m1.1.1.3.cmml"><mo id="S4.SS3.p4.1.m1.1.1.3a" xref="S4.SS3.p4.1.m1.1.1.3.cmml">−</mo><mn id="S4.SS3.p4.1.m1.1.1.3.2" xref="S4.SS3.p4.1.m1.1.1.3.2.cmml">4</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="S4.SS3.p4.1.m1.1b"><apply id="S4.SS3.p4.1.m1.1.1.cmml" xref="S4.SS3.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS3.p4.1.m1.1.1.1.cmml" xref="S4.SS3.p4.1.m1.1.1">superscript</csymbol><cn id="S4.SS3.p4.1.m1.1.1.2.cmml" type="integer" xref="S4.SS3.p4.1.m1.1.1.2">10</cn><apply id="S4.SS3.p4.1.m1.1.1.3.cmml" xref="S4.SS3.p4.1.m1.1.1.3"><minus id="S4.SS3.p4.1.m1.1.1.3.1.cmml" xref="S4.SS3.p4.1.m1.1.1.3"></minus><cn id="S4.SS3.p4.1.m1.1.1.3.2.cmml" type="integer" xref="S4.SS3.p4.1.m1.1.1.3.2">4</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p4.1.m1.1c">10^{-4}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p4.1.m1.1d">10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT</annotation></semantics></math> and a batch size of 1 with 16 gradient accumulation steps. We select the model with the highest <span class="ltx_text ltx_font_italic" id="S4.SS3.p4.1.3">ROUGE</span> score which we evaluate at the end of each epoch. We limit the maximum input length to 2048 to keep it comparable with the Vicuna summaries.</p>
</div>
<div class="ltx_para" id="S4.SS3.p5">
<p class="ltx_p" id="S4.SS3.p5.1">The <span class="ltx_text ltx_font_bold" id="S4.SS3.p5.1.1">Vicuna</span> models are a collection of LLMs that are adaptations of Llama <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#bib.bib30" title="">30</a>]</cite>, fine-tuned on ChatGPT conversations shared by users on the <a class="ltx_ref ltx_url ltx_font_typewriter" href="ShareGPT.com" title="">ShareGPT.com</a> website. The Vicuna maximum input context length is 2048 tokens, which is useful for our summarization use-case. The Vicuna model that we use is one of the Vicuna 7B checkpoints<span class="ltx_note ltx_role_footnote" id="footnote9"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note">9</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/lmsys/vicuna-7b-v1.3" title="">https://huggingface.co/lmsys/vicuna-7b-v1.3</a></span></span></span> based on the 7B parameter Llama model. The main reason for selecting the 7B model is that it is still possible to fit this model in 8-bit format on a single 16GB GPU and perform inference with it. We use the Vicuna model as a zero-shot summarizer by providing a fixed input prompt along with a course title and a course description for generating the summary. The prompt that we used is shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#S4.F2" title="Figure 2 ‣ 4.3 Summarization ‣ 4 Methods ‣ Efficient course recommendations with T5-based ranking and summarization"><span class="ltx_text ltx_ref_tag">2</span></a>. When the input is longer than the 2048 input window we truncate the input. We limit the number of generated tokens to 256 so that we are sure we are getting shorter course descriptions that easily fit into the input window of our re-ranker.</p>
</div>
<figure class="ltx_figure" id="S4.F2">
<table class="ltx_tabular ltx_align_middle" id="S4.F2.1">
<tr class="ltx_tr" id="S4.F2.1.1">
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.F2.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="S4.F2.1.1.1.1">
<span class="ltx_p" id="S4.F2.1.1.1.1.1" style="width:426.8pt;"><span class="ltx_text ltx_font_typewriter" id="S4.F2.1.1.1.1.1.1" style="font-size:90%;">I will provide you with a course title and description of an online course that I want you to summarize in 2 to 3 lines.</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.F2.1.2">
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.F2.1.2.1">
<span class="ltx_inline-block ltx_align_top" id="S4.F2.1.2.1.1">
<span class="ltx_p" id="S4.F2.1.2.1.1.1" style="width:426.8pt;"><span class="ltx_text ltx_font_typewriter" id="S4.F2.1.2.1.1.1.1" style="font-size:90%;">I want the summary to only include information about the content of the course.
You can leave out any information about the author, at which company the course is used and information about a 30 day money back guarantee.
You can also leave out any student reviews about the course. I want you to write the summary as if it were a new shortened course description.</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.F2.1.3">
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.F2.1.3.1">
<span class="ltx_inline-block ltx_align_top" id="S4.F2.1.3.1.1">
<span class="ltx_p" id="S4.F2.1.3.1.1.1" style="width:426.8pt;"><span class="ltx_text ltx_font_typewriter" id="S4.F2.1.3.1.1.1.1" style="font-size:90%;">Course title: [course_title]</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.F2.1.4">
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.F2.1.4.1">
<span class="ltx_inline-block ltx_align_top" id="S4.F2.1.4.1.1">
<span class="ltx_p" id="S4.F2.1.4.1.1.1" style="width:426.8pt;"><span class="ltx_text ltx_font_typewriter" id="S4.F2.1.4.1.1.1.1" style="font-size:90%;">Course description: [course_description]</span></span>
</span>
</td>
</tr>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Prompt used for Vicuna to summarize course descriptions</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Quantization</h3>
<div class="ltx_para" id="S4.SS4.p1">
<p class="ltx_p" id="S4.SS4.p1.1">The main bottleneck for inference speed in our approach is the re-ranker. To reduce this bottleneck, we experiment with 3 different quantization methods: dynamic quantization, static quantization <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#bib.bib31" title="">31</a>]</cite>, and SmoothQuant <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#bib.bib32" title="">32</a>]</cite>. We use the implementation of SmoothQuant in the Neural Compressor package by Intel.<span class="ltx_note ltx_role_footnote" id="footnote10"><sup class="ltx_note_mark">10</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">10</sup><span class="ltx_tag ltx_tag_note">10</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/intel/neural-compressor" title="">https://github.com/intel/neural-compressor</a></span></span></span> To perform the static quantization and quantization using the SmoothQuant algorithm we need to have a calibration dataset. To stay true to the zero-shot setting we use the <span class="ltx_text ltx_font_italic" id="S4.SS4.p1.1.1">dev</span> partition of the MSMARCO dataset to randomly select samples for calibration instead of using BrightFit data.
We use the version of SmoothQuant with the per-tensor dynamic quantization for the activations because the alternative versions have slower inference speed or lead to lower quality output according to the SmoothQuant paper <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#bib.bib32" title="">32</a>]</cite>.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Results</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">We use the BM25-based in-production ranker in the BrightFit course recommendation system as a baseline in our ranking evaluation.</p>
</div>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Experiment 1: First-stage retrieval</h3>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#S5.T3" title="Table 3 ‣ 5.1 Experiment 1: First-stage retrieval ‣ 5 Results ‣ Efficient course recommendations with T5-based ranking and summarization"><span class="ltx_text ltx_ref_tag">3</span></a> shows the results of the in-production BM25 baseline and the GTR first-stage retriever on the two BrightFit datasets. The table shows that GTR outperforms BM25 by a large margin. For the first-stage retrievers, the metric we are most interested in is recall, since we want the candidate list to have as many relevant documents as possible to obtain a better final ranking after re-ranking the candidate list using the second-stage re-ranker. The results for different levels of recall are shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#S5.T4" title="Table 4 ‣ 5.1 Experiment 1: First-stage retrieval ‣ 5 Results ‣ Efficient course recommendations with T5-based ranking and summarization"><span class="ltx_text ltx_ref_tag">4</span></a>. The table shows that the GTR retriever is consistently better than the BM25 retriever for all tested values of <math alttext="k" class="ltx_Math" display="inline" id="S5.SS1.p1.1.m1.1"><semantics id="S5.SS1.p1.1.m1.1a"><mi id="S5.SS1.p1.1.m1.1.1" xref="S5.SS1.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.1.m1.1b"><ci id="S5.SS1.p1.1.m1.1.1.cmml" xref="S5.SS1.p1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p1.1.m1.1d">italic_k</annotation></semantics></math>.</p>
</div>
<figure class="ltx_table" id="S5.T3">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Comparison between the BM25 and GTR-Base retriever on the two BrightFit datasets. BM25 is the current in-production ranker.</figcaption>
<p class="ltx_p ltx_align_center ltx_align_center" id="S5.T3.1"><span class="ltx_text" id="S5.T3.1.1">
<span class="ltx_tabular ltx_align_middle" id="S5.T3.1.1.1">
<span class="ltx_tr" id="S5.T3.1.1.1.1">
<span class="ltx_td ltx_align_left ltx_border_t" id="S5.T3.1.1.1.1.1"><span class="ltx_text" id="S5.T3.1.1.1.1.1.1" style="font-size:90%;">Ranker</span></span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.1.1.1.2"><span class="ltx_text" id="S5.T3.1.1.1.1.2.1" style="font-size:90%;">Dataset</span></span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.1.1.1.3"><span class="ltx_text" id="S5.T3.1.1.1.1.3.1" style="font-size:90%;">nDCG@10</span></span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.1.1.1.4"><span class="ltx_text" id="S5.T3.1.1.1.1.4.1" style="font-size:90%;">MRR@10</span></span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.1.1.1.5"><span class="ltx_text" id="S5.T3.1.1.1.1.5.1" style="font-size:90%;">MAP@10</span></span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.1.1.1.6"><span class="ltx_text" id="S5.T3.1.1.1.1.6.1" style="font-size:90%;">R@20</span></span></span>
<span class="ltx_tr" id="S5.T3.1.1.1.2">
<span class="ltx_td ltx_align_left ltx_border_t" id="S5.T3.1.1.1.2.1"><span class="ltx_text" id="S5.T3.1.1.1.2.1.1" style="font-size:90%;">BM25</span></span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.1.1.2.2"><span class="ltx_text" id="S5.T3.1.1.1.2.2.1" style="font-size:90%;">IT</span></span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.1.1.2.3"><span class="ltx_text" id="S5.T3.1.1.1.2.3.1" style="font-size:90%;">0.482</span></span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.1.1.2.4"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.1.2.4.1" style="font-size:90%;">0.931</span></span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.1.1.2.5"><span class="ltx_text" id="S5.T3.1.1.1.2.5.1" style="font-size:90%;">0.139</span></span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.1.1.2.6"><span class="ltx_text" id="S5.T3.1.1.1.2.6.1" style="font-size:90%;">0.380</span></span></span>
<span class="ltx_tr" id="S5.T3.1.1.1.3">
<span class="ltx_td" id="S5.T3.1.1.1.3.1"></span>
<span class="ltx_td ltx_align_center" id="S5.T3.1.1.1.3.2"><span class="ltx_text" id="S5.T3.1.1.1.3.2.1" style="font-size:90%;">General</span></span>
<span class="ltx_td ltx_align_center" id="S5.T3.1.1.1.3.3"><span class="ltx_text" id="S5.T3.1.1.1.3.3.1" style="font-size:90%;">0.447</span></span>
<span class="ltx_td ltx_align_center" id="S5.T3.1.1.1.3.4"><span class="ltx_text" id="S5.T3.1.1.1.3.4.1" style="font-size:90%;">0.778</span></span>
<span class="ltx_td ltx_align_center" id="S5.T3.1.1.1.3.5"><span class="ltx_text" id="S5.T3.1.1.1.3.5.1" style="font-size:90%;">0.150</span></span>
<span class="ltx_td ltx_align_center" id="S5.T3.1.1.1.3.6"><span class="ltx_text" id="S5.T3.1.1.1.3.6.1" style="font-size:90%;">0.400</span></span></span>
<span class="ltx_tr" id="S5.T3.1.1.1.4">
<span class="ltx_td ltx_align_left ltx_border_t" id="S5.T3.1.1.1.4.1"><span class="ltx_text" id="S5.T3.1.1.1.4.1.1" style="font-size:90%;">GTR</span></span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.1.1.4.2"><span class="ltx_text" id="S5.T3.1.1.1.4.2.1" style="font-size:90%;">IT</span></span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.1.1.4.3"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.1.4.3.1" style="font-size:90%;">0.648</span></span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.1.1.4.4"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.1.4.4.1" style="font-size:90%;">0.931</span></span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.1.1.4.5"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.1.4.5.1" style="font-size:90%;">0.221</span></span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.1.1.4.6"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.1.4.6.1" style="font-size:90%;">0.512</span></span></span>
<span class="ltx_tr" id="S5.T3.1.1.1.5">
<span class="ltx_td ltx_border_b" id="S5.T3.1.1.1.5.1"></span>
<span class="ltx_td ltx_align_center ltx_border_b" id="S5.T3.1.1.1.5.2"><span class="ltx_text" id="S5.T3.1.1.1.5.2.1" style="font-size:90%;">General</span></span>
<span class="ltx_td ltx_align_center ltx_border_b" id="S5.T3.1.1.1.5.3"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.1.5.3.1" style="font-size:90%;">0.705</span></span>
<span class="ltx_td ltx_align_center ltx_border_b" id="S5.T3.1.1.1.5.4"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.1.5.4.1" style="font-size:90%;">1.000</span></span>
<span class="ltx_td ltx_align_center ltx_border_b" id="S5.T3.1.1.1.5.5"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.1.5.5.1" style="font-size:90%;">0.311</span></span>
<span class="ltx_td ltx_align_center ltx_border_b" id="S5.T3.1.1.1.5.6"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.1.5.6.1" style="font-size:90%;">0.545</span></span></span>
</span></span></p>
<br class="ltx_break ltx_break"/>
</figure>
<figure class="ltx_table" id="S5.T4">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>Recall@K scores for the BM25 and GTR retrievers on both BrightFit datasets for different values of k.</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S5.T4.1">
<tr class="ltx_tr" id="S5.T4.1.1">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T4.1.1.1">Dataset</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T4.1.1.2">Ranker</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T4.1.1.3">k=20</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T4.1.1.4">k=30</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T4.1.1.5">k=50</td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T4.1.2.1">IT</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T4.1.2.2">BM25</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T4.1.2.3">0.380</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T4.1.2.4">0.504</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T4.1.2.5">0.555</td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.3">
<td class="ltx_td" id="S5.T4.1.3.1"></td>
<td class="ltx_td ltx_align_left" id="S5.T4.1.3.2">GTR</td>
<td class="ltx_td ltx_align_left" id="S5.T4.1.3.3"><span class="ltx_text ltx_font_bold" id="S5.T4.1.3.3.1">0.512</span></td>
<td class="ltx_td ltx_align_left" id="S5.T4.1.3.4"><span class="ltx_text ltx_font_bold" id="S5.T4.1.3.4.1">0.661</span></td>
<td class="ltx_td ltx_align_left" id="S5.T4.1.3.5"><span class="ltx_text ltx_font_bold" id="S5.T4.1.3.5.1">0.739</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.4">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T4.1.4.1">General</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T4.1.4.2">BM25</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T4.1.4.3">0.400</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T4.1.4.4">0.498</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T4.1.4.5">0.548</td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.5">
<td class="ltx_td ltx_border_b" id="S5.T4.1.5.1"></td>
<td class="ltx_td ltx_align_left ltx_border_b" id="S5.T4.1.5.2">GTR</td>
<td class="ltx_td ltx_align_left ltx_border_b" id="S5.T4.1.5.3"><span class="ltx_text ltx_font_bold" id="S5.T4.1.5.3.1">0.545</span></td>
<td class="ltx_td ltx_align_left ltx_border_b" id="S5.T4.1.5.4"><span class="ltx_text ltx_font_bold" id="S5.T4.1.5.4.1">0.651</span></td>
<td class="ltx_td ltx_align_left ltx_border_b" id="S5.T4.1.5.5"><span class="ltx_text ltx_font_bold" id="S5.T4.1.5.5.1">0.668</span></td>
</tr>
</table>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Experiment 2: Re-ranking</h3>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">We evaluate RankT5 with different configurations to see what variation gives us the best performance on both the BrightFit IT dataset and the BrightFit general skills dataset. The first aspect of the model that we experiment with is the maximum input length. We experiment with three different values: 128, 256 and 512 tokens. The input that goes past this maximum input length is truncated. The second aspect we vary is whether we do or do not include the short skill description from the Burning Glass taxonomy in the query for re-ranking. By adding the skill description to the query we can add more context, but it can also confuse the model since the input queries become much longer. This also means that we have less space for the document text in the limited input window of the encoder which can also hurt performance.</p>
</div>
<div class="ltx_para" id="S5.SS2.p2">
<p class="ltx_p" id="S5.SS2.p2.1">During the training process, we observe that the RankT5 model obtains its best zero-shot performance at 25k training steps, so for this experiment and the following, we use that checkpoint. The results of this experiment are shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#S5.T5" title="Table 5 ‣ 5.2 Experiment 2: Re-ranking ‣ 5 Results ‣ Efficient course recommendations with T5-based ranking and summarization"><span class="ltx_text ltx_ref_tag">5</span></a>. We observe that for both datasets the best-performing settings are the ones where we have a maximum input length of 128 and we do not include the skill descriptions. There is a substantial performance drop for all model lengths if we include the skill description in the query.</p>
</div>
<figure class="ltx_table" id="S5.T5">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>nDCG@10 scores of the second-stage re-ranker on both BrightFit datasets for different variations compared to the in-production BM25 ranker.</figcaption>
<p class="ltx_p ltx_align_center ltx_align_center" id="S5.T5.1"><span class="ltx_text" id="S5.T5.1.1">
<span class="ltx_tabular ltx_align_middle" id="S5.T5.1.1.1">
<span class="ltx_tr" id="S5.T5.1.1.1.1">
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T5.1.1.1.1.1"><span class="ltx_text" id="S5.T5.1.1.1.1.1.1" style="font-size:90%;">Dataset</span></span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t ltx_colspan ltx_colspan_3" id="S5.T5.1.1.1.1.2"><span class="ltx_text" id="S5.T5.1.1.1.1.2.1" style="font-size:90%;">BrightFit IT</span></span>
<span class="ltx_td ltx_align_center ltx_border_t ltx_colspan ltx_colspan_3" id="S5.T5.1.1.1.1.3"><span class="ltx_text" id="S5.T5.1.1.1.1.3.1" style="font-size:90%;">BrightFit General</span></span></span>
<span class="ltx_tr" id="S5.T5.1.1.1.2">
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T5.1.1.1.2.1"><span class="ltx_text" id="S5.T5.1.1.1.2.1.1" style="font-size:90%;">Max input length</span></span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.1.1.1.2.2"><span class="ltx_text" id="S5.T5.1.1.1.2.2.1" style="font-size:90%;">128</span></span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.1.1.1.2.3"><span class="ltx_text" id="S5.T5.1.1.1.2.3.1" style="font-size:90%;">256</span></span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T5.1.1.1.2.4"><span class="ltx_text" id="S5.T5.1.1.1.2.4.1" style="font-size:90%;">512</span></span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.1.1.1.2.5"><span class="ltx_text" id="S5.T5.1.1.1.2.5.1" style="font-size:90%;">128</span></span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.1.1.1.2.6"><span class="ltx_text" id="S5.T5.1.1.1.2.6.1" style="font-size:90%;">256</span></span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.1.1.1.2.7"><span class="ltx_text" id="S5.T5.1.1.1.2.7.1" style="font-size:90%;">512</span></span></span>
<span class="ltx_tr" id="S5.T5.1.1.1.3">
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T5.1.1.1.3.1"><span class="ltx_text" id="S5.T5.1.1.1.3.1.1" style="font-size:90%;">W/ skill description</span></span>
<span class="ltx_td ltx_align_left ltx_border_t" id="S5.T5.1.1.1.3.2"><span class="ltx_text" id="S5.T5.1.1.1.3.2.1" style="font-size:90%;">0.613</span></span>
<span class="ltx_td ltx_align_left ltx_border_t" id="S5.T5.1.1.1.3.3"><span class="ltx_text" id="S5.T5.1.1.1.3.3.1" style="font-size:90%;">0.628</span></span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T5.1.1.1.3.4"><span class="ltx_text" id="S5.T5.1.1.1.3.4.1" style="font-size:90%;">0.612</span></span>
<span class="ltx_td ltx_align_left ltx_border_t" id="S5.T5.1.1.1.3.5"><span class="ltx_text" id="S5.T5.1.1.1.3.5.1" style="font-size:90%;">0.627</span></span>
<span class="ltx_td ltx_align_left ltx_border_t" id="S5.T5.1.1.1.3.6"><span class="ltx_text" id="S5.T5.1.1.1.3.6.1" style="font-size:90%;">0.696</span></span>
<span class="ltx_td ltx_align_left ltx_border_t" id="S5.T5.1.1.1.3.7"><span class="ltx_text" id="S5.T5.1.1.1.3.7.1" style="font-size:90%;">0.646</span></span></span>
<span class="ltx_tr" id="S5.T5.1.1.1.4">
<span class="ltx_td ltx_align_left ltx_border_r" id="S5.T5.1.1.1.4.1"><span class="ltx_text" id="S5.T5.1.1.1.4.1.1" style="font-size:90%;">W/o skill description</span></span>
<span class="ltx_td ltx_align_left" id="S5.T5.1.1.1.4.2"><span class="ltx_text ltx_font_bold" id="S5.T5.1.1.1.4.2.1" style="font-size:90%;">0.682</span></span>
<span class="ltx_td ltx_align_left" id="S5.T5.1.1.1.4.3"><span class="ltx_text" id="S5.T5.1.1.1.4.3.1" style="font-size:90%;">0.660</span></span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S5.T5.1.1.1.4.4"><span class="ltx_text" id="S5.T5.1.1.1.4.4.1" style="font-size:90%;">0.626</span></span>
<span class="ltx_td ltx_align_left" id="S5.T5.1.1.1.4.5"><span class="ltx_text ltx_font_bold" id="S5.T5.1.1.1.4.5.1" style="font-size:90%;">0.798</span></span>
<span class="ltx_td ltx_align_left" id="S5.T5.1.1.1.4.6"><span class="ltx_text" id="S5.T5.1.1.1.4.6.1" style="font-size:90%;">0.758</span></span>
<span class="ltx_td ltx_align_left" id="S5.T5.1.1.1.4.7"><span class="ltx_text" id="S5.T5.1.1.1.4.7.1" style="font-size:90%;">0.729</span></span></span>
<span class="ltx_tr" id="S5.T5.1.1.1.5">
<span class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="S5.T5.1.1.1.5.1"><span class="ltx_text ltx_font_italic" id="S5.T5.1.1.1.5.1.1" style="font-size:90%;">BM25 (in-production)</span></span>
<span class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t ltx_colspan ltx_colspan_3" id="S5.T5.1.1.1.5.2"><span class="ltx_text ltx_font_italic" id="S5.T5.1.1.1.5.2.1" style="font-size:90%;">0.482</span></span>
<span class="ltx_td ltx_align_center ltx_border_b ltx_border_t ltx_colspan ltx_colspan_3" id="S5.T5.1.1.1.5.3"><span class="ltx_text ltx_font_italic" id="S5.T5.1.1.1.5.3.1" style="font-size:90%;">0.447</span></span></span>
</span></span></p>
</figure>
<div class="ltx_para" id="S5.SS2.p3">
<p class="ltx_p" id="S5.SS2.p3.1">We also analyzed the impact of changing the re-ranking depth on the final ranking performance. We experiment with the following re-ranking depths: 50, 30 and 20, and compare the NDCG@10 scores after re-ranking for both BrightFit datasets. The results are shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#S5.T6" title="Table 6 ‣ 5.2 Experiment 2: Re-ranking ‣ 5 Results ‣ Efficient course recommendations with T5-based ranking and summarization"><span class="ltx_text ltx_ref_tag">6</span></a>. For both datasets, we obtained the highest NDCG@10 score with a re-ranking depth of 30.</p>
</div>
<figure class="ltx_table" id="S5.T6">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6: </span>NDCG@10 scores after re-ranking the top-k documents with RankT5 retrieved on both BrightFit datasets for different values of k.</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S5.T6.1">
<tr class="ltx_tr" id="S5.T6.1.1">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T6.1.1.1">Dataset</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T6.1.1.2">k=20</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T6.1.1.3">k=30</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T6.1.1.4">k=50</td>
</tr>
<tr class="ltx_tr" id="S5.T6.1.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T6.1.2.1">IT</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T6.1.2.2">0.675</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T6.1.2.3"><span class="ltx_text ltx_font_bold" id="S5.T6.1.2.3.1">0.702</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T6.1.2.4">0.677</td>
</tr>
<tr class="ltx_tr" id="S5.T6.1.3">
<td class="ltx_td ltx_align_left ltx_border_b" id="S5.T6.1.3.1">General</td>
<td class="ltx_td ltx_align_left ltx_border_b" id="S5.T6.1.3.2">0.778</td>
<td class="ltx_td ltx_align_left ltx_border_b" id="S5.T6.1.3.3"><span class="ltx_text ltx_font_bold" id="S5.T6.1.3.3.1">0.881</span></td>
<td class="ltx_td ltx_align_left ltx_border_b" id="S5.T6.1.3.4">0.844</td>
</tr>
</table>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Experiment 3: Summarization</h3>
<div class="ltx_para" id="S5.SS3.p1">
<p class="ltx_p" id="S5.SS3.p1.1">We evaluate the effectiveness of ranking summarized versions of the course descriptions. We compare three settings: the default course description (truncated if needed), a summary generated by our fine-tuned LongT5 summarizer, and a summary generated by the zero-shot Vicuna model. We also explore how the effectiveness of the ranker with summarized descriptions changes when we vary the maximum input length of the ranker. We experiment with the values of 128, 256, and 512 for the maximum input length. The results of this experiment are shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#S5.T7" title="Table 7 ‣ 5.3 Experiment 3: Summarization ‣ 5 Results ‣ Efficient course recommendations with T5-based ranking and summarization"><span class="ltx_text ltx_ref_tag">7</span></a>.</p>
</div>
<figure class="ltx_table" id="S5.T7">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 7: </span>NDCG@10 scores of the RankT5 re-ranker on both BrightFit datasets for different summarization techniques.</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S5.T7.1">
<tr class="ltx_tr" id="S5.T7.1.1">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T7.1.1.1"><span class="ltx_text" id="S5.T7.1.1.1.1" style="font-size:90%;">Dataset</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3" id="S5.T7.1.1.2"><span class="ltx_text" id="S5.T7.1.1.2.1" style="font-size:90%;">BrightFit IT</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="3" id="S5.T7.1.1.3"><span class="ltx_text" id="S5.T7.1.1.3.1" style="font-size:90%;">BrightFit General</span></td>
</tr>
<tr class="ltx_tr" id="S5.T7.1.2">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T7.1.2.1"><span class="ltx_text" id="S5.T7.1.2.1.1" style="font-size:90%;">Max length</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T7.1.2.2"><span class="ltx_text" id="S5.T7.1.2.2.1" style="font-size:90%;">128</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T7.1.2.3"><span class="ltx_text" id="S5.T7.1.2.3.1" style="font-size:90%;">256</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T7.1.2.4"><span class="ltx_text" id="S5.T7.1.2.4.1" style="font-size:90%;">512</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T7.1.2.5"><span class="ltx_text" id="S5.T7.1.2.5.1" style="font-size:90%;">128</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T7.1.2.6"><span class="ltx_text" id="S5.T7.1.2.6.1" style="font-size:90%;">256</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T7.1.2.7"><span class="ltx_text" id="S5.T7.1.2.7.1" style="font-size:90%;">512</span></td>
</tr>
<tr class="ltx_tr" id="S5.T7.1.3">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T7.1.3.1"><span class="ltx_text" id="S5.T7.1.3.1.1" style="font-size:90%;">Original</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T7.1.3.2"><span class="ltx_text" id="S5.T7.1.3.2.1" style="font-size:90%;">0.682</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T7.1.3.3"><span class="ltx_text" id="S5.T7.1.3.3.1" style="font-size:90%;">0.660</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T7.1.3.4"><span class="ltx_text" id="S5.T7.1.3.4.1" style="font-size:90%;">0.626</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T7.1.3.5"><span class="ltx_text" id="S5.T7.1.3.5.1" style="font-size:90%;">0.798</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T7.1.3.6"><span class="ltx_text" id="S5.T7.1.3.6.1" style="font-size:90%;">0.758</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T7.1.3.7"><span class="ltx_text" id="S5.T7.1.3.7.1" style="font-size:90%;">0.729</span></td>
</tr>
<tr class="ltx_tr" id="S5.T7.1.4">
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T7.1.4.1"><span class="ltx_text" id="S5.T7.1.4.1.1" style="font-size:90%;">LongT5</span></td>
<td class="ltx_td ltx_align_left" id="S5.T7.1.4.2"><span class="ltx_text" id="S5.T7.1.4.2.1" style="font-size:90%;">0.680</span></td>
<td class="ltx_td ltx_align_left" id="S5.T7.1.4.3"><span class="ltx_text ltx_font_bold" id="S5.T7.1.4.3.1" style="font-size:90%;">0.684</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T7.1.4.4"><span class="ltx_text" id="S5.T7.1.4.4.1" style="font-size:90%;">0.683</span></td>
<td class="ltx_td ltx_align_left" id="S5.T7.1.4.5"><span class="ltx_text" id="S5.T7.1.4.5.1" style="font-size:90%;">0.814</span></td>
<td class="ltx_td ltx_align_left" id="S5.T7.1.4.6"><span class="ltx_text" id="S5.T7.1.4.6.1" style="font-size:90%;">0.801</span></td>
<td class="ltx_td ltx_align_left" id="S5.T7.1.4.7"><span class="ltx_text" id="S5.T7.1.4.7.1" style="font-size:90%;">0.798</span></td>
</tr>
<tr class="ltx_tr" id="S5.T7.1.5">
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S5.T7.1.5.1"><span class="ltx_text" id="S5.T7.1.5.1.1" style="font-size:90%;">Vicuna</span></td>
<td class="ltx_td ltx_align_left ltx_border_b" id="S5.T7.1.5.2"><span class="ltx_text" id="S5.T7.1.5.2.1" style="font-size:90%;">0.669</span></td>
<td class="ltx_td ltx_align_left ltx_border_b" id="S5.T7.1.5.3"><span class="ltx_text" id="S5.T7.1.5.3.1" style="font-size:90%;">0.676</span></td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S5.T7.1.5.4"><span class="ltx_text" id="S5.T7.1.5.4.1" style="font-size:90%;">0.677</span></td>
<td class="ltx_td ltx_align_left ltx_border_b" id="S5.T7.1.5.5"><span class="ltx_text" id="S5.T7.1.5.5.1" style="font-size:90%;">0.806</span></td>
<td class="ltx_td ltx_align_left ltx_border_b" id="S5.T7.1.5.6"><span class="ltx_text ltx_font_bold" id="S5.T7.1.5.6.1" style="font-size:90%;">0.844</span></td>
<td class="ltx_td ltx_align_left ltx_border_b" id="S5.T7.1.5.7"><span class="ltx_text ltx_font_bold" id="S5.T7.1.5.7.1" style="font-size:90%;">0.844</span></td>
</tr>
</table>
</figure>
<div class="ltx_para" id="S5.SS3.p2">
<p class="ltx_p" id="S5.SS3.p2.1">We find that on both BrightFit datasets the NDCG@10 score improves by summarizing the course descriptions. For the BrightFit IT dataset, we obtain the best results using the LongT5 summarizer for an input length of 256. Overall, we see that the improvement on the BrightFit IT dataset is very minimal compared to the default description with an input length of 128. Interestingly, we also observe that the Vicuna summaries on the BrightFit IT dataset do not directly outperform the 128 input length for the standard description. We do, however, notice that when the input lengths get longer the performance of the standard description starts to decrease, while the performance for the Vicuna summaries starts to increase. We think this is because Vicuna summaries are created to contain the essence of the course, leaving out irrelevant information; the ranker therefore benefits from including a longer summary. The original descriptions on the other hand are noisy and contain irrelevant information later in the text, so adding more of the description adds more irrelevant information.</p>
</div>
<div class="ltx_para" id="S5.SS3.p3">
<p class="ltx_p" id="S5.SS3.p3.1">We also see that the LongT5 summaries make an improvement over the standard description for this dataset but not as much as Vicuna. The improvement we get on the general skills dataset is much larger than the improvement we get on the IT dataset.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4 </span>Experiment 4: Quantization</h3>
<div class="ltx_para" id="S5.SS4.p1">
<p class="ltx_p" id="S5.SS4.p1.3">We evaluate the static, dynamic and SmoothQuant quantization methods on model size and inference speed. SmoothQuant has a single parameter <math alttext="\alpha" class="ltx_Math" display="inline" id="S5.SS4.p1.1.m1.1"><semantics id="S5.SS4.p1.1.m1.1a"><mi id="S5.SS4.p1.1.m1.1.1" xref="S5.SS4.p1.1.m1.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S5.SS4.p1.1.m1.1b"><ci id="S5.SS4.p1.1.m1.1.1.cmml" xref="S5.SS4.p1.1.m1.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p1.1.m1.1c">\alpha</annotation><annotation encoding="application/x-llamapun" id="S5.SS4.p1.1.m1.1d">italic_α</annotation></semantics></math>, which is the smoothing factor. We experiment with three values of <math alttext="\alpha\in\{0.25,0.50,0.75\}" class="ltx_Math" display="inline" id="S5.SS4.p1.2.m2.3"><semantics id="S5.SS4.p1.2.m2.3a"><mrow id="S5.SS4.p1.2.m2.3.4" xref="S5.SS4.p1.2.m2.3.4.cmml"><mi id="S5.SS4.p1.2.m2.3.4.2" xref="S5.SS4.p1.2.m2.3.4.2.cmml">α</mi><mo id="S5.SS4.p1.2.m2.3.4.1" xref="S5.SS4.p1.2.m2.3.4.1.cmml">∈</mo><mrow id="S5.SS4.p1.2.m2.3.4.3.2" xref="S5.SS4.p1.2.m2.3.4.3.1.cmml"><mo id="S5.SS4.p1.2.m2.3.4.3.2.1" stretchy="false" xref="S5.SS4.p1.2.m2.3.4.3.1.cmml">{</mo><mn id="S5.SS4.p1.2.m2.1.1" xref="S5.SS4.p1.2.m2.1.1.cmml">0.25</mn><mo id="S5.SS4.p1.2.m2.3.4.3.2.2" xref="S5.SS4.p1.2.m2.3.4.3.1.cmml">,</mo><mn id="S5.SS4.p1.2.m2.2.2" xref="S5.SS4.p1.2.m2.2.2.cmml">0.50</mn><mo id="S5.SS4.p1.2.m2.3.4.3.2.3" xref="S5.SS4.p1.2.m2.3.4.3.1.cmml">,</mo><mn id="S5.SS4.p1.2.m2.3.3" xref="S5.SS4.p1.2.m2.3.3.cmml">0.75</mn><mo id="S5.SS4.p1.2.m2.3.4.3.2.4" stretchy="false" xref="S5.SS4.p1.2.m2.3.4.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS4.p1.2.m2.3b"><apply id="S5.SS4.p1.2.m2.3.4.cmml" xref="S5.SS4.p1.2.m2.3.4"><in id="S5.SS4.p1.2.m2.3.4.1.cmml" xref="S5.SS4.p1.2.m2.3.4.1"></in><ci id="S5.SS4.p1.2.m2.3.4.2.cmml" xref="S5.SS4.p1.2.m2.3.4.2">𝛼</ci><set id="S5.SS4.p1.2.m2.3.4.3.1.cmml" xref="S5.SS4.p1.2.m2.3.4.3.2"><cn id="S5.SS4.p1.2.m2.1.1.cmml" type="float" xref="S5.SS4.p1.2.m2.1.1">0.25</cn><cn id="S5.SS4.p1.2.m2.2.2.cmml" type="float" xref="S5.SS4.p1.2.m2.2.2">0.50</cn><cn id="S5.SS4.p1.2.m2.3.3.cmml" type="float" xref="S5.SS4.p1.2.m2.3.3">0.75</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p1.2.m2.3c">\alpha\in\{0.25,0.50,0.75\}</annotation><annotation encoding="application/x-llamapun" id="S5.SS4.p1.2.m2.3d">italic_α ∈ { 0.25 , 0.50 , 0.75 }</annotation></semantics></math>, with 0.5 being recommended by the authors for most models. Since the results for the three values are very close to each other, we only report the results for <math alttext="\alpha=0.5" class="ltx_Math" display="inline" id="S5.SS4.p1.3.m3.1"><semantics id="S5.SS4.p1.3.m3.1a"><mrow id="S5.SS4.p1.3.m3.1.1" xref="S5.SS4.p1.3.m3.1.1.cmml"><mi id="S5.SS4.p1.3.m3.1.1.2" xref="S5.SS4.p1.3.m3.1.1.2.cmml">α</mi><mo id="S5.SS4.p1.3.m3.1.1.1" xref="S5.SS4.p1.3.m3.1.1.1.cmml">=</mo><mn id="S5.SS4.p1.3.m3.1.1.3" xref="S5.SS4.p1.3.m3.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS4.p1.3.m3.1b"><apply id="S5.SS4.p1.3.m3.1.1.cmml" xref="S5.SS4.p1.3.m3.1.1"><eq id="S5.SS4.p1.3.m3.1.1.1.cmml" xref="S5.SS4.p1.3.m3.1.1.1"></eq><ci id="S5.SS4.p1.3.m3.1.1.2.cmml" xref="S5.SS4.p1.3.m3.1.1.2">𝛼</ci><cn id="S5.SS4.p1.3.m3.1.1.3.cmml" type="float" xref="S5.SS4.p1.3.m3.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p1.3.m3.1c">\alpha=0.5</annotation><annotation encoding="application/x-llamapun" id="S5.SS4.p1.3.m3.1d">italic_α = 0.5</annotation></semantics></math>. The static and dynamic quantization algorithms do not have any parameters.</p>
</div>
<div class="ltx_para" id="S5.SS4.p2">
<p class="ltx_p" id="S5.SS4.p2.1">We look at how much space a model takes up after quantization compared to the full FP32 model and we look at how the inference speed is improved by measuring the throughput of the model. We use the built-in benchmarking tool from the Intel Neural Compressor package for this. We benchmark the models using 2 cores per model. For each quantization method, we run 8 repetitions. We use a batch size of 16. In each repetition, we use a warmup of 10 inference queries after which we run 200 inference query–document pairs from the BrightFit general skills dataset and measure the throughput of the model as the number of query–document pairs that are processed per second. Since measuring inference speed is very hardware- and sometimes even package-dependant we report all the used hardware and package versions in Table <a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#S5.T8" title="Table 8 ‣ 5.4 Experiment 4: Quantization ‣ 5 Results ‣ Efficient course recommendations with T5-based ranking and summarization"><span class="ltx_text ltx_ref_tag">8</span></a>.</p>
</div>
<figure class="ltx_table" id="S5.T8">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 8: </span>Hardware and package version overview for the quantization experiments.</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S5.T8.1">
<tr class="ltx_tr" id="S5.T8.1.1">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T8.1.1.1">Hardware</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T8.1.1.2">Version</td>
</tr>
<tr class="ltx_tr" id="S5.T8.1.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T8.1.2.1">Google Cloud Platform VM</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T8.1.2.2">
<table class="ltx_tabular ltx_align_middle" id="S5.T8.1.2.2.1">
<tr class="ltx_tr" id="S5.T8.1.2.2.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S5.T8.1.2.2.1.1.1">n1-standard-16 VM</td>
</tr>
<tr class="ltx_tr" id="S5.T8.1.2.2.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S5.T8.1.2.2.1.2.1">(16 vCpus, 60 GB RAM)</td>
</tr>
</table>
</td>
</tr>
<tr class="ltx_tr" id="S5.T8.1.3">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T8.1.3.1">Packages</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T8.1.3.2">Version</td>
</tr>
<tr class="ltx_tr" id="S5.T8.1.4">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T8.1.4.1">intel-neural-compressor</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T8.1.4.2">2.3</td>
</tr>
<tr class="ltx_tr" id="S5.T8.1.5">
<td class="ltx_td ltx_align_left" id="S5.T8.1.5.1">onnxruntime</td>
<td class="ltx_td ltx_align_left" id="S5.T8.1.5.2">1.16.0</td>
</tr>
<tr class="ltx_tr" id="S5.T8.1.6">
<td class="ltx_td ltx_align_left" id="S5.T8.1.6.1">onnx</td>
<td class="ltx_td ltx_align_left" id="S5.T8.1.6.2">1.14.1</td>
</tr>
<tr class="ltx_tr" id="S5.T8.1.7">
<td class="ltx_td ltx_align_left ltx_border_b" id="S5.T8.1.7.1">transformers</td>
<td class="ltx_td ltx_align_left ltx_border_b" id="S5.T8.1.7.2">4.30.2</td>
</tr>
</table>
</figure>
<div class="ltx_para" id="S5.SS4.p3">
<p class="ltx_p" id="S5.SS4.p3.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#S5.T9" title="Table 9 ‣ 5.4 Experiment 4: Quantization ‣ 5 Results ‣ Efficient course recommendations with T5-based ranking and summarization"><span class="ltx_text ltx_ref_tag">9</span></a> shows the inference speed and model sizes of the different quantization methods and the non-quantized FP32 model. We see that the dynamic quantization method obtains the best throughput for both the 256 and 512 input lengths. We observe over 40% speed-up of the dynamic quantization method compared to the default FP32 model. In terms of throughput the static and SmoothQuant quantized models are not far behind the dynamically quantized model. For the dynamic and SmoothQuant methods, we also observe a close to 4x reduction in model size which is as expected since we convert the model weights from 32-bit to 8-bit values.</p>
</div>
<figure class="ltx_table" id="S5.T9">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 9: </span>Throughput in queries per second for different input length sizes (256 and 512) and model size (in MB) comparisons for different quantization methods. The standard deviations are shown in brackets.</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S5.T9.8">
<tr class="ltx_tr" id="S5.T9.8.9">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T9.8.9.1">Quantization</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T9.8.9.2">Throughput (256)</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T9.8.9.3">Throughput (512)</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T9.8.9.4">Model size</td>
</tr>
<tr class="ltx_tr" id="S5.T9.2.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T9.2.2.3">None (FP32)</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T9.1.1.1">2.573 (<math alttext="\pm 0.035" class="ltx_Math" display="inline" id="S5.T9.1.1.1.m1.1"><semantics id="S5.T9.1.1.1.m1.1a"><mrow id="S5.T9.1.1.1.m1.1.1" xref="S5.T9.1.1.1.m1.1.1.cmml"><mo id="S5.T9.1.1.1.m1.1.1a" xref="S5.T9.1.1.1.m1.1.1.cmml">±</mo><mn id="S5.T9.1.1.1.m1.1.1.2" xref="S5.T9.1.1.1.m1.1.1.2.cmml">0.035</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T9.1.1.1.m1.1b"><apply id="S5.T9.1.1.1.m1.1.1.cmml" xref="S5.T9.1.1.1.m1.1.1"><csymbol cd="latexml" id="S5.T9.1.1.1.m1.1.1.1.cmml" xref="S5.T9.1.1.1.m1.1.1">plus-or-minus</csymbol><cn id="S5.T9.1.1.1.m1.1.1.2.cmml" type="float" xref="S5.T9.1.1.1.m1.1.1.2">0.035</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T9.1.1.1.m1.1c">\pm 0.035</annotation><annotation encoding="application/x-llamapun" id="S5.T9.1.1.1.m1.1d">± 0.035</annotation></semantics></math>)</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T9.2.2.2">1.226 (<math alttext="\pm 0.034" class="ltx_Math" display="inline" id="S5.T9.2.2.2.m1.1"><semantics id="S5.T9.2.2.2.m1.1a"><mrow id="S5.T9.2.2.2.m1.1.1" xref="S5.T9.2.2.2.m1.1.1.cmml"><mo id="S5.T9.2.2.2.m1.1.1a" xref="S5.T9.2.2.2.m1.1.1.cmml">±</mo><mn id="S5.T9.2.2.2.m1.1.1.2" xref="S5.T9.2.2.2.m1.1.1.2.cmml">0.034</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T9.2.2.2.m1.1b"><apply id="S5.T9.2.2.2.m1.1.1.cmml" xref="S5.T9.2.2.2.m1.1.1"><csymbol cd="latexml" id="S5.T9.2.2.2.m1.1.1.1.cmml" xref="S5.T9.2.2.2.m1.1.1">plus-or-minus</csymbol><cn id="S5.T9.2.2.2.m1.1.1.2.cmml" type="float" xref="S5.T9.2.2.2.m1.1.1.2">0.034</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T9.2.2.2.m1.1c">\pm 0.034</annotation><annotation encoding="application/x-llamapun" id="S5.T9.2.2.2.m1.1d">± 0.034</annotation></semantics></math>)</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T9.2.2.4">418.4</td>
</tr>
<tr class="ltx_tr" id="S5.T9.4.4">
<td class="ltx_td ltx_align_left" id="S5.T9.4.4.3"><span class="ltx_text ltx_font_italic" id="S5.T9.4.4.3.1">Static</span></td>
<td class="ltx_td ltx_align_center" id="S5.T9.3.3.1">2.875 (<math alttext="\pm 0.079" class="ltx_Math" display="inline" id="S5.T9.3.3.1.m1.1"><semantics id="S5.T9.3.3.1.m1.1a"><mrow id="S5.T9.3.3.1.m1.1.1" xref="S5.T9.3.3.1.m1.1.1.cmml"><mo id="S5.T9.3.3.1.m1.1.1a" xref="S5.T9.3.3.1.m1.1.1.cmml">±</mo><mn id="S5.T9.3.3.1.m1.1.1.2" xref="S5.T9.3.3.1.m1.1.1.2.cmml">0.079</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T9.3.3.1.m1.1b"><apply id="S5.T9.3.3.1.m1.1.1.cmml" xref="S5.T9.3.3.1.m1.1.1"><csymbol cd="latexml" id="S5.T9.3.3.1.m1.1.1.1.cmml" xref="S5.T9.3.3.1.m1.1.1">plus-or-minus</csymbol><cn id="S5.T9.3.3.1.m1.1.1.2.cmml" type="float" xref="S5.T9.3.3.1.m1.1.1.2">0.079</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T9.3.3.1.m1.1c">\pm 0.079</annotation><annotation encoding="application/x-llamapun" id="S5.T9.3.3.1.m1.1d">± 0.079</annotation></semantics></math>)</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.4.2">1.545 (<math alttext="\pm 0.043" class="ltx_Math" display="inline" id="S5.T9.4.4.2.m1.1"><semantics id="S5.T9.4.4.2.m1.1a"><mrow id="S5.T9.4.4.2.m1.1.1" xref="S5.T9.4.4.2.m1.1.1.cmml"><mo id="S5.T9.4.4.2.m1.1.1a" xref="S5.T9.4.4.2.m1.1.1.cmml">±</mo><mn id="S5.T9.4.4.2.m1.1.1.2" xref="S5.T9.4.4.2.m1.1.1.2.cmml">0.043</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T9.4.4.2.m1.1b"><apply id="S5.T9.4.4.2.m1.1.1.cmml" xref="S5.T9.4.4.2.m1.1.1"><csymbol cd="latexml" id="S5.T9.4.4.2.m1.1.1.1.cmml" xref="S5.T9.4.4.2.m1.1.1">plus-or-minus</csymbol><cn id="S5.T9.4.4.2.m1.1.1.2.cmml" type="float" xref="S5.T9.4.4.2.m1.1.1.2">0.043</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T9.4.4.2.m1.1c">\pm 0.043</annotation><annotation encoding="application/x-llamapun" id="S5.T9.4.4.2.m1.1d">± 0.043</annotation></semantics></math>)</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.4.4">128.8</td>
</tr>
<tr class="ltx_tr" id="S5.T9.6.6">
<td class="ltx_td ltx_align_left" id="S5.T9.6.6.3">Dynamic</td>
<td class="ltx_td ltx_align_center" id="S5.T9.5.5.1">
<span class="ltx_text ltx_font_bold" id="S5.T9.5.5.1.1">3.420</span> (<math alttext="\pm 0.046" class="ltx_Math" display="inline" id="S5.T9.5.5.1.m1.1"><semantics id="S5.T9.5.5.1.m1.1a"><mrow id="S5.T9.5.5.1.m1.1.1" xref="S5.T9.5.5.1.m1.1.1.cmml"><mo id="S5.T9.5.5.1.m1.1.1a" xref="S5.T9.5.5.1.m1.1.1.cmml">±</mo><mn id="S5.T9.5.5.1.m1.1.1.2" xref="S5.T9.5.5.1.m1.1.1.2.cmml">0.046</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T9.5.5.1.m1.1b"><apply id="S5.T9.5.5.1.m1.1.1.cmml" xref="S5.T9.5.5.1.m1.1.1"><csymbol cd="latexml" id="S5.T9.5.5.1.m1.1.1.1.cmml" xref="S5.T9.5.5.1.m1.1.1">plus-or-minus</csymbol><cn id="S5.T9.5.5.1.m1.1.1.2.cmml" type="float" xref="S5.T9.5.5.1.m1.1.1.2">0.046</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T9.5.5.1.m1.1c">\pm 0.046</annotation><annotation encoding="application/x-llamapun" id="S5.T9.5.5.1.m1.1d">± 0.046</annotation></semantics></math>)</td>
<td class="ltx_td ltx_align_center" id="S5.T9.6.6.2">
<span class="ltx_text ltx_font_bold" id="S5.T9.6.6.2.1">1.582</span> (<math alttext="\pm 0.029" class="ltx_Math" display="inline" id="S5.T9.6.6.2.m1.1"><semantics id="S5.T9.6.6.2.m1.1a"><mrow id="S5.T9.6.6.2.m1.1.1" xref="S5.T9.6.6.2.m1.1.1.cmml"><mo id="S5.T9.6.6.2.m1.1.1a" xref="S5.T9.6.6.2.m1.1.1.cmml">±</mo><mn id="S5.T9.6.6.2.m1.1.1.2" xref="S5.T9.6.6.2.m1.1.1.2.cmml">0.029</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T9.6.6.2.m1.1b"><apply id="S5.T9.6.6.2.m1.1.1.cmml" xref="S5.T9.6.6.2.m1.1.1"><csymbol cd="latexml" id="S5.T9.6.6.2.m1.1.1.1.cmml" xref="S5.T9.6.6.2.m1.1.1">plus-or-minus</csymbol><cn id="S5.T9.6.6.2.m1.1.1.2.cmml" type="float" xref="S5.T9.6.6.2.m1.1.1.2">0.029</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T9.6.6.2.m1.1c">\pm 0.029</annotation><annotation encoding="application/x-llamapun" id="S5.T9.6.6.2.m1.1d">± 0.029</annotation></semantics></math>)</td>
<td class="ltx_td ltx_align_center" id="S5.T9.6.6.4"><span class="ltx_text ltx_font_bold" id="S5.T9.6.6.4.1">105.2</span></td>
</tr>
<tr class="ltx_tr" id="S5.T9.8.8">
<td class="ltx_td ltx_align_left ltx_border_b" id="S5.T9.8.8.3">SmoothQuant</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T9.7.7.1">3.292 (<math alttext="\pm 0.050" class="ltx_Math" display="inline" id="S5.T9.7.7.1.m1.1"><semantics id="S5.T9.7.7.1.m1.1a"><mrow id="S5.T9.7.7.1.m1.1.1" xref="S5.T9.7.7.1.m1.1.1.cmml"><mo id="S5.T9.7.7.1.m1.1.1a" xref="S5.T9.7.7.1.m1.1.1.cmml">±</mo><mn id="S5.T9.7.7.1.m1.1.1.2" xref="S5.T9.7.7.1.m1.1.1.2.cmml">0.050</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T9.7.7.1.m1.1b"><apply id="S5.T9.7.7.1.m1.1.1.cmml" xref="S5.T9.7.7.1.m1.1.1"><csymbol cd="latexml" id="S5.T9.7.7.1.m1.1.1.1.cmml" xref="S5.T9.7.7.1.m1.1.1">plus-or-minus</csymbol><cn id="S5.T9.7.7.1.m1.1.1.2.cmml" type="float" xref="S5.T9.7.7.1.m1.1.1.2">0.050</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T9.7.7.1.m1.1c">\pm 0.050</annotation><annotation encoding="application/x-llamapun" id="S5.T9.7.7.1.m1.1d">± 0.050</annotation></semantics></math>)</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T9.8.8.2">1.528 (<math alttext="\pm 0.023" class="ltx_Math" display="inline" id="S5.T9.8.8.2.m1.1"><semantics id="S5.T9.8.8.2.m1.1a"><mrow id="S5.T9.8.8.2.m1.1.1" xref="S5.T9.8.8.2.m1.1.1.cmml"><mo id="S5.T9.8.8.2.m1.1.1a" xref="S5.T9.8.8.2.m1.1.1.cmml">±</mo><mn id="S5.T9.8.8.2.m1.1.1.2" xref="S5.T9.8.8.2.m1.1.1.2.cmml">0.023</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T9.8.8.2.m1.1b"><apply id="S5.T9.8.8.2.m1.1.1.cmml" xref="S5.T9.8.8.2.m1.1.1"><csymbol cd="latexml" id="S5.T9.8.8.2.m1.1.1.1.cmml" xref="S5.T9.8.8.2.m1.1.1">plus-or-minus</csymbol><cn id="S5.T9.8.8.2.m1.1.1.2.cmml" type="float" xref="S5.T9.8.8.2.m1.1.1.2">0.023</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T9.8.8.2.m1.1c">\pm 0.023</annotation><annotation encoding="application/x-llamapun" id="S5.T9.8.8.2.m1.1d">± 0.023</annotation></semantics></math>)</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T9.8.8.4">105.5</td>
</tr>
</table>
</figure>
<figure class="ltx_table" id="S5.T10">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 10: </span>NDCG@10 scores of various quantization methods on the BrightFit datasets compared to the standard, non-quantized FP32 model as a reference. * indicates that the difference with the FP32 model is statistically significant according to a paired t-test with <math alttext="\alpha=0.05" class="ltx_Math" display="inline" id="S5.T10.2.m1.1"><semantics id="S5.T10.2.m1.1b"><mrow id="S5.T10.2.m1.1.1" xref="S5.T10.2.m1.1.1.cmml"><mi id="S5.T10.2.m1.1.1.2" xref="S5.T10.2.m1.1.1.2.cmml">α</mi><mo id="S5.T10.2.m1.1.1.1" xref="S5.T10.2.m1.1.1.1.cmml">=</mo><mn id="S5.T10.2.m1.1.1.3" xref="S5.T10.2.m1.1.1.3.cmml">0.05</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T10.2.m1.1c"><apply id="S5.T10.2.m1.1.1.cmml" xref="S5.T10.2.m1.1.1"><eq id="S5.T10.2.m1.1.1.1.cmml" xref="S5.T10.2.m1.1.1.1"></eq><ci id="S5.T10.2.m1.1.1.2.cmml" xref="S5.T10.2.m1.1.1.2">𝛼</ci><cn id="S5.T10.2.m1.1.1.3.cmml" type="float" xref="S5.T10.2.m1.1.1.3">0.05</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T10.2.m1.1d">\alpha=0.05</annotation><annotation encoding="application/x-llamapun" id="S5.T10.2.m1.1e">italic_α = 0.05</annotation></semantics></math> and Bonferroni correction for multiple testing.</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S5.T10.3">
<tr class="ltx_tr" id="S5.T10.3.1">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T10.3.1.1">Dataset</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" colspan="2" id="S5.T10.3.1.2">BrightFit IT</td>
<td class="ltx_td ltx_align_left ltx_border_t" colspan="2" id="S5.T10.3.1.3">BrightFit General</td>
</tr>
<tr class="ltx_tr" id="S5.T10.3.2">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T10.3.2.1">Max input length</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T10.3.2.2">256</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T10.3.2.3">512</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T10.3.2.4">256</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T10.3.2.5">512</td>
</tr>
<tr class="ltx_tr" id="S5.T10.3.3">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T10.3.3.1"><span class="ltx_text ltx_font_italic" id="S5.T10.3.3.1.1">RankT5-FP32</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T10.3.3.2"><span class="ltx_text ltx_font_bold" id="S5.T10.3.3.2.1">0.659</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T10.3.3.3">0.623</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T10.3.3.4">0.754</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T10.3.3.5">0.725</td>
</tr>
<tr class="ltx_tr" id="S5.T10.3.4">
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T10.3.4.1">RankT5-Static</td>
<td class="ltx_td ltx_align_center" id="S5.T10.3.4.2">0.503*</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T10.3.4.3">0.511</td>
<td class="ltx_td ltx_align_center" id="S5.T10.3.4.4">0.444*</td>
<td class="ltx_td ltx_align_center" id="S5.T10.3.4.5">0.389</td>
</tr>
<tr class="ltx_tr" id="S5.T10.3.5">
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T10.3.5.1">RankT5-Dynamic</td>
<td class="ltx_td ltx_align_center" id="S5.T10.3.5.2">0.657</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T10.3.5.3">0.636</td>
<td class="ltx_td ltx_align_center" id="S5.T10.3.5.4"><span class="ltx_text ltx_font_bold" id="S5.T10.3.5.4.1">0.775</span></td>
<td class="ltx_td ltx_align_center" id="S5.T10.3.5.5">0.720</td>
</tr>
<tr class="ltx_tr" id="S5.T10.3.6">
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S5.T10.3.6.1">RankT5-SmoothQuant</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T10.3.6.2">0.626</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="S5.T10.3.6.3">0.597</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T10.3.6.4">0.737</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T10.3.6.5">0.691</td>
</tr>
</table>
</figure>
<div class="ltx_para" id="S5.SS4.p4">
<p class="ltx_p" id="S5.SS4.p4.1">To evaluate if the quantization of the models does not negatively impact the quality of the ranking we also evaluate the NDCG@10 scores of the quantized models on both BrightFit datasets by re-ranking the top 50 candidates with the default descriptions. The results for this are in Table <a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#S5.T10" title="Table 10 ‣ 5.4 Experiment 4: Quantization ‣ 5 Results ‣ Efficient course recommendations with T5-based ranking and summarization"><span class="ltx_text ltx_ref_tag">10</span></a>. The dynamic quantization method achieves the best scores of the quantization methods, and both SmoothQuant and dynamic quantization lead to results that are not significantly lower than the FP32 model. The static quantization method causes a notable and significant decrease in performance.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.5 </span>Experiment 5: User evaluation</h3>
<div class="ltx_para" id="S5.SS5.p1">
<p class="ltx_p" id="S5.SS5.p1.1">As per the recommendation by Knijenburg and Willemsen <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#bib.bib6" title="">6</a>]</cite> we perform both an A/B test and a questionnaire to effectively evaluate the user perception of our course ranking method.</p>
</div>
<section class="ltx_subsubsection" id="S5.SS5.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.5.1 </span>A/B test</h4>
<div class="ltx_para" id="S5.SS5.SSS1.p1">
<p class="ltx_p" id="S5.SS5.SSS1.p1.1">We implement an A/B test in the BrightFit production environment. We use this test to directly compare the in-production system (BM25-based) against our best ranking setup.</p>
</div>
<section class="ltx_paragraph" id="S5.SS5.SSS1.Px1">
<h5 class="ltx_title ltx_title_paragraph">Ranking model selected for test</h5>
<div class="ltx_para" id="S5.SS5.SSS1.Px1.p1">
<p class="ltx_p" id="S5.SS5.SSS1.Px1.p1.1">We select a version of our RankT5 model that balances speed and quality: course descriptions summarized by the LongT5 model; dynamic quantization; a maximum input length of 256; and a re-ranking depth of 20. In Section <a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#S5.SS2" title="5.2 Experiment 2: Re-ranking ‣ 5 Results ‣ Efficient course recommendations with T5-based ranking and summarization"><span class="ltx_text ltx_ref_tag">5.2</span></a> we have seen that a re-ranking depth of 30 achieves a higher NDCG@10 score. However, by reducing the number of processed documents from 30 to 20 we get close to a 150% speed-up. We are still happy with the quality of the recommendations at a depth of 20, which is why we decide to use a depth of 20 instead of 30.</p>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS5.SSS1.Px2">
<h5 class="ltx_title ltx_title_paragraph">Experiment design</h5>
<div class="ltx_para" id="S5.SS5.SSS1.Px2.p1">
<p class="ltx_p" id="S5.SS5.SSS1.Px2.p1.1">We use a between-subject randomization method as suggested by <cite class="ltx_cite ltx_citemacro_citet">Knijnenburg and Willemsen [<a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#bib.bib6" title="">6</a>]</cite>. If a user’s id is even-numbered, we use the in-production (BM25-based) ranker to select the presented recommendations and if the user’s id is an odd number we use our RankT5-based system described above. We deploy the A/B test in the United States and Australia. The United States is the largest market for BrightFit and Australia uses the exact same skills taxonomy and course catalogue as the United States version, allowing us to easily deploy it in Australia. </p>
</div>
<div class="ltx_para" id="S5.SS5.SSS1.Px2.p2">
<p class="ltx_p" id="S5.SS5.SSS1.Px2.p2.1">To track user behaviour during the experiment we use Google Analytics.<span class="ltx_note ltx_role_footnote" id="footnote11"><sup class="ltx_note_mark">11</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">11</sup><span class="ltx_tag ltx_tag_note">11</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://marketingplatform.google.com/about/analytics/" title="">https://marketingplatform.google.com/about/analytics/</a></span></span></span> We track the following three events related to the course recommendations in BrightFit:</p>
<ol class="ltx_enumerate" id="S5.I1">
<li class="ltx_item" id="S5.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S5.I1.i1.p1">
<p class="ltx_p" id="S5.I1.i1.p1.1"><span class="ltx_text ltx_font_italic" id="S5.I1.i1.p1.1.1">Open skill card</span>: A skill card is a small component presented to the user on the self-assessment report page (see Section <a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#S3.SS3" title="3.3 Queries ‣ 3 Data collection ‣ Efficient course recommendations with T5-based ranking and summarization"><span class="ltx_text ltx_ref_tag">3.3</span></a>), showing the recommended skills. The user can click a skill card to get more information on a skill. Opening a skill card will also show them the list of courses that are recommended for that skill. This is the starting point for the recommender.</p>
</div>
</li>
<li class="ltx_item" id="S5.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S5.I1.i2.p1">
<p class="ltx_p" id="S5.I1.i2.p1.1"><span class="ltx_text ltx_font_italic" id="S5.I1.i2.p1.1.1">Open course card</span>: Once a user has opened a skill card they will be presented with some information about the skill and a list of courses that are recommended to learn that skill. Each course is shown as a small card with some basic information like the title, the level, the rating and a thumbnail image. When a user is interested in a course they can open this course card to get more information about the course. For this event, we track if a user clicks on the course card to learn more about a course.</p>
</div>
</li>
<li class="ltx_item" id="S5.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S5.I1.i3.p1">
<p class="ltx_p" id="S5.I1.i3.p1.1"><span class="ltx_text ltx_font_italic" id="S5.I1.i3.p1.1.1">Go to course</span>: Once a user has opened a course card and they are presented with the full description of the course they will have the option to go to the actual course on the course provider’s website, which is what we track with this event.</p>
</div>
</li>
</ol>
</div>
<div class="ltx_para" id="S5.SS5.SSS1.Px2.p3">
<p class="ltx_p" id="S5.SS5.SSS1.Px2.p3.1">We ran the experiment for 66 days in the United States and for 46 days in Australia.</p>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS5.SSS1.Px3">
<h5 class="ltx_title ltx_title_paragraph">Results</h5>
<div class="ltx_para" id="S5.SS5.SSS1.Px3.p1">
<p class="ltx_p" id="S5.SS5.SSS1.Px3.p1.1">We show the combined results for both countries in Figure <a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#S5.F3" title="Figure 3 ‣ Results ‣ 5.5.1 A/B test ‣ 5.5 Experiment 5: User evaluation ‣ 5 Results ‣ Efficient course recommendations with T5-based ranking and summarization"><span class="ltx_text ltx_ref_tag">3</span></a>. Overall we find that the BM25-based recommender achieves higher click-through rates between the different parts of the BrightFit application. In Figure <a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#S5.F3" title="Figure 3 ‣ Results ‣ 5.5.1 A/B test ‣ 5.5 Experiment 5: User evaluation ‣ 5 Results ‣ Efficient course recommendations with T5-based ranking and summarization"><span class="ltx_text ltx_ref_tag">3</span></a> we can see that, after a user opened a skill card and was shown course recommendations by the BM25-based recommender, they open a course card in 50% of the cases, compared to only 29% for the RankT5-based recommendations. This contrasts our offline evaluation results in Table <a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#S5.T5" title="Table 5 ‣ 5.2 Experiment 2: Re-ranking ‣ 5 Results ‣ Efficient course recommendations with T5-based ranking and summarization"><span class="ltx_text ltx_ref_tag">5</span></a>. We discuss this contrast in Section <a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#S6" title="6 Discussion ‣ Efficient course recommendations with T5-based ranking and summarization"><span class="ltx_text ltx_ref_tag">6</span></a>.</p>
</div>
<figure class="ltx_figure" id="S5.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="151" id="S5.F3.g1" src="x2.png" width="418"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Funnel diagram for the events recorded during the BrightFit A/B test combined for the USA and Australia. The first value in each box indicates the total number of recorded events, the percentage indicates how many events of that type were recorded compared to the previous stage in the funnel.</figcaption>
</figure>
</section>
</section>
<section class="ltx_subsubsection" id="S5.SS5.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.5.2 </span>User questionnaire</h4>
<div class="ltx_para" id="S5.SS5.SSS2.p1">
<p class="ltx_p" id="S5.SS5.SSS2.p1.1">Again per the recommendation by <cite class="ltx_cite ltx_citemacro_citet">Knijnenburg and Willemsen [<a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#bib.bib6" title="">6</a>]</cite> we use an additional user questionnaire to get more insight into user preferences.</p>
</div>
<figure class="ltx_figure" id="S5.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="206" id="S5.F4.g1" src="extracted/5695284/survey-example.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>An example of the two lists a user is shown for the query <span class="ltx_text ltx_font_italic" id="S5.F4.2.1">Customer Service for Front Desk Employee</span> in the questionnaire.</figcaption>
</figure>
<section class="ltx_paragraph" id="S5.SS5.SSS2.Px1">
<h5 class="ltx_title ltx_title_paragraph">Study design</h5>
<div class="ltx_para" id="S5.SS5.SSS2.Px1.p1">
<p class="ltx_p" id="S5.SS5.SSS2.Px1.p1.1">We present users with the 10 queries from the BrightFit general skills dataset with their top recommended courses. We have to be careful about how we present the recommendations as this can have a significant influence on the user’s choices <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#bib.bib6" title="">6</a>]</cite>. We also do not want to overwhelm the users with choices to prevent so-called “choice overload" <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#bib.bib33" title="">33</a>]</cite>. After careful consideration and discussing options with test users, we opted for 5 courses per list. We show the two lists below each other for mobile-friendliness and we randomize which system’s recommendations are first <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#bib.bib34" title="">34</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S5.SS5.SSS2.Px1.p2">
<p class="ltx_p" id="S5.SS5.SSS2.Px1.p2.1">To make the questionnaire as representative as possible of the way recommendations are served to the user in BrightFit, we show them only information that is also available in BrightFit: the course title, course thumbnail, course rating, course provider, and the course level. An example of two lists we generate for a query in the questionnaire is shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#S5.F4" title="Figure 4 ‣ 5.5.2 User questionnaire ‣ 5.5 Experiment 5: User evaluation ‣ 5 Results ‣ Efficient course recommendations with T5-based ranking and summarization"><span class="ltx_text ltx_ref_tag">4</span></a>. Note that in this figure, the lists are laid out side by side while the lists in the survey are presented below each other.</p>
</div>
<div class="ltx_para" id="S5.SS5.SSS2.Px1.p3">
<p class="ltx_p" id="S5.SS5.SSS2.Px1.p3.1">For each of the 10 questions, we ask the user to indicate which list of recommendations they prefer or if they have no preference for one list over the other. We then ask them to elaborate on their reasoning for the choice they made to get an understanding of what users find important when getting recommendations. This has the additional benefit that it improves the accuracy of the responses given, as the users are forced to think more about their answer <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#bib.bib6" title="">6</a>]</cite>.</p>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS5.SSS2.Px2">
<h5 class="ltx_title ltx_title_paragraph">Results</h5>
<div class="ltx_para" id="S5.SS5.SSS2.Px2.p1">
<p class="ltx_p" id="S5.SS5.SSS2.Px2.p1.1">In total, we have collected responses from 29 different participants (M:19, F:9, X:1; mean age:28). Figure <a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#S5.F5" title="Figure 5 ‣ Results ‣ 5.5.2 User questionnaire ‣ 5.5 Experiment 5: User evaluation ‣ 5 Results ‣ Efficient course recommendations with T5-based ranking and summarization"><span class="ltx_text ltx_ref_tag">5</span></a> shows the user preferences for each question in the questionnaire. We can see that in 8 out of 10 cases, the results from the two-stage retrieval approach using GTR retrieval and RankT5 re-ranking are preferred over the BM25-based in-production ranker. This result is in contrast with the results we observed in the A/B test, but aligns with our offline evaluation results. We will discuss this in Section <a class="ltx_ref" href="https://arxiv.org/html/2406.19018v1#S6" title="6 Discussion ‣ Efficient course recommendations with T5-based ranking and summarization"><span class="ltx_text ltx_ref_tag">6</span></a>.</p>
</div>
<figure class="ltx_figure" id="S5.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="385" id="S5.F5.g1" src="x3.png" width="538"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Results of the conducted user questionnaire showing user preference for each of the 10 questions in the questionnaire. In total responses from 29 users were collected.</figcaption>
</figure>
<div class="ltx_para" id="S5.SS5.SSS2.Px2.p2">
<p class="ltx_p" id="S5.SS5.SSS2.Px2.p2.1">Even though the new recommendation system gets preferred over the old recommendation system in the questionnaire, we still have the case that for each query there is at least a handful of users that have no preference or prefer the other system. This shows that there is a difference between users’ perceptions of what makes a good recommendation. We looked at the motivations written by the users for the choices they made. As reasons were mentioned: higher course ratings, courses for different levels, diversity in course content, false positives, and courses taught within the job context.</p>
</div>
</section>
</section>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Discussion</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">In this section, we further discuss the results of the experiments, focussing on the unexpected findings.</p>
</div>
<section class="ltx_paragraph" id="S6.SS0.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Comparing datasets</h5>
<div class="ltx_para" id="S6.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S6.SS0.SSS0.Px1.p1.1">We found that the scores on the general skills dataset are generally higher than the scores on the BrightFit IT dataset. This shows us that the BrightFit IT dataset is a harder problem compared to the general skills many more courses for IT-related skills available, which can make it harder to get a good ranking of these courses. This is also supported by the fact that the BrightFit IT skills dataset has more relevant documents per query compared to the BrightFit general skills dataset.</p>
</div>
</section>
<section class="ltx_paragraph" id="S6.SS0.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">Quantization</h5>
<div class="ltx_para" id="S6.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S6.SS0.SSS0.Px2.p1.1">We found the dynamically quantized model performs very similarly to the FP32 movel, and in some settings even a bit better. This latter finding is surprising since quantization makes the model weights less precise, causing the model to have less information. We speculate that the model might be able to generalize better with the less specific weights after quantization, resulting in better scores.</p>
</div>
</section>
<section class="ltx_paragraph" id="S6.SS0.SSS0.Px3">
<h5 class="ltx_title ltx_title_paragraph">User studies</h5>
<div class="ltx_para" id="S6.SS0.SSS0.Px3.p1">
<p class="ltx_p" id="S6.SS0.SSS0.Px3.p1.1">In the user evaluation, the results from the A/B test and the questionnaire contradict each other. The result of the A/B test shows better user interaction with the BM25-based recommender, while the users who have taken the questionnaire have clearly shown a preference for the RankT5-based recommendations, the latter confirming our offline ranking experiments. One of the factors in the A/B test might be the interpretability of the results. If we have the query <span class="ltx_text ltx_font_italic" id="S6.SS0.SSS0.Px3.p1.1.1">“Information Security for Security Specialist”</span> the BM25-based re-ranker will retrieve course titles that contain the words “Information Security". On the other hand, we observe that in the RankT5-based recommendations there are many courses with the term <span class="ltx_text ltx_font_italic" id="S6.SS0.SSS0.Px3.p1.1.2">CISSP</span> which stands for “Certified Information Systems Security Professional". For someone who does not know <span class="ltx_text ltx_font_italic" id="S6.SS0.SSS0.Px3.p1.1.3">CISSP</span> stands for, the recognizable course descriptions retrieved by BM25 might be more appealing to click on.</p>
</div>
<div class="ltx_para" id="S6.SS0.SSS0.Px3.p2">
<p class="ltx_p" id="S6.SS0.SSS0.Px3.p2.1">Another factor that can be an issue is the time it takes to generate recommendations, which is a relevant aspect given that efficiency was one of the aims of our approach. The BM25-based recommendations are much faster to generate than the recommendations by RankT5. During our testing of the A/B test setup, we found that in almost all cases, the recommendations for the courses by RankT5 would be done by the time a normal user would get to the part of the page where the skills are shown, which is near the bottom. However, despite our efforts to improve the inference time using quantization and summarization, we cannot be sure that this longer time to generate the recommendations is impacting how the users interact with the system. This difference in time is not a factor in the questionnaire, which can explain the difference in results between the A/B test and the questionnaire results.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusion</h2>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p" id="S7.p1.1">In this paper, we addressed the problem of making good and efficient course recommendations for users who are looking to learn a certain skill. We evaluated a two-stage retrieval approach using GTR and RankT5 on two newly labelled datasets based on the commercial BrightFit course recommender. We experimented with improving the efficiency of the recommender by applying summarization and quantization techniques.</p>
</div>
<div class="ltx_para" id="S7.p2">
<p class="ltx_p" id="S7.p2.1">We found that the zero-shot GTR retriever outperforms the BM25-based retriever on both BrightFit datasets. We finetuned the RankT5 model on the MSMARCO dataset and showed that it can effectively perform course re-ranking despite not being trained on the course domain, and leads to a substantially better ranking for two labelled datasets than the in-production BM25 ranker.
We compared two summarization models for improving ranking of long course descriptions: a LongT5 model fine-tuned on edX data for summarizing courses and a Vicuna model that we prompted to generate summaries. We found that both models were able to get better performance than was achieved with the original course descriptions. We investigated the use of quantization to speed up model inference and we achieved a speed-up of up to 47% compared to inference with the original (FP32) model, while the performance was either very close or sometimes even better than the FP32 model. </p>
</div>
<div class="ltx_para" id="S7.p3">
<p class="ltx_p" id="S7.p3.1">Finally, we performed 2 user studies: an A/B test and a questionnaire. From the results of the A/B test, we saw that the BM25-based re-ranker had substantially higher click-through rates than our proposed two-step approach, which does not align with our findings that RankT5 was significantly better on both BrightFit benchmark datasets. Time to generate recommendations and transparency of relevance might be factors that play a role here. With the questionnaire, on the other hand, we found that in 8 out of 10 cases, the RankT5-based recommender was either equal to or preferred over the BM25-based recommender. Through the questionnaire, we gained insights into why users preferred one set of recommendations over another which is useful information when looking to extend the recommender in the future.
</p>
</div>
<div class="ltx_para" id="S7.p4">
<p class="ltx_p" id="S7.p4.1">Future work could focus on differences between the preferences of individual users. An extension incorporating user preferences might provide a better user experience by being able to serve personalized recommendations.
Another way to improve recommendations would be to construct a proper training dataset for BrightFit with enough ratings so that we can directly train on the task instead of using zero-shot methods.
</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">World Economic Forum [2023]</span>
<span class="ltx_bibblock">
World Economic Forum, The future of jobs report 2023, 2023. URL: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.weforum.org/reports/the-future-of-jobs-report-2023/" title="">https://www.weforum.org/reports/the-future-of-jobs-report-2023/</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Randstad Risesmart [2020]</span>
<span class="ltx_bibblock">
Randstad Risesmart, skilling today: a randstad risesmart global survey, 2020. URL: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.weforum.org/reports/the-future-of-jobs-report-2023/" title="">https://www.weforum.org/reports/the-future-of-jobs-report-2023/</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhuang et al. [2022]</span>
<span class="ltx_bibblock">
H. Zhuang, Z. Qin, R. Jagerman, K. Hui, J. Ma, J. Lu, J. Ni, X. Wang, M. Bendersky, Rankt5: Fine-tuning t5 for text ranking with ranking losses, 2022. <a class="ltx_ref ltx_href ltx_font_typewriter" href="http://arxiv.org/abs/2210.10634" title="">arXiv:2210.10634</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guo [2018]</span>
<span class="ltx_bibblock">
Y. Guo,

</span>
<span class="ltx_bibblock">A survey on methods and theories of quantized neural networks,

</span>
<span class="ltx_bibblock">CoRR abs/1808.04752 (2018). URL: <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/1808.04752" title="">http://arxiv.org/abs/1808.04752</a>. <a class="ltx_ref ltx_href ltx_font_typewriter" href="http://arxiv.org/abs/1808.04752" title="">arXiv:1808.04752</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Martin [2009]</span>
<span class="ltx_bibblock">
F. J. Martin,

</span>
<span class="ltx_bibblock">Recsys’09 industrial keynote: Top 10 lessons learned developing deploying and operating real-world recommender systems,

</span>
<span class="ltx_bibblock">in: Proceedings of the Third ACM Conference on Recommender Systems, RecSys ’09, Association for Computing Machinery, New York, NY, USA, 2009, p. 1–2. URL: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/1639714.1639715" title="">https://doi.org/10.1145/1639714.1639715</a>. doi:<a class="ltx_ref" href="https:/doi.org/10.1145/1639714.1639715" title="">10.1145/1639714.1639715</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Knijnenburg and Willemsen [2015]</span>
<span class="ltx_bibblock">
B. P. Knijnenburg, M. C. Willemsen, Evaluating Recommender Systems with User Experiments, Springer US, Boston, MA, 2015, pp. 309–352. URL: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1007/978-1-4899-7637-6_9" title="">https://doi.org/10.1007/978-1-4899-7637-6_9</a>. doi:<a class="ltx_ref" href="https:/doi.org/10.1007/978-1-4899-7637-6_9" title="">10.1007/978-1-4899-7637-6_9</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Imran et al. [2015]</span>
<span class="ltx_bibblock">
H. Imran, M. Belghis-Zadeh, T.-W. Chang, Kinshuk, S. Graf,

</span>
<span class="ltx_bibblock">PLORS: a personalized learning object recommender system,

</span>
<span class="ltx_bibblock">Vietnam Journal of Computer Science 3 (2015) 3–13. URL: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1007/s40595-015-0049-6" title="">https://doi.org/10.1007/s40595-015-0049-6</a>. doi:<a class="ltx_ref" href="https:/doi.org/10.1007/s40595-015-0049-6" title="">10.1007/s40595-015-0049-6</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jing and Tang [2017]</span>
<span class="ltx_bibblock">
X. Jing, J. Tang,

</span>
<span class="ltx_bibblock">Guess you like: course recommendation in moocs,

</span>
<span class="ltx_bibblock">in: Proceedings of the international conference on web intelligence, 2017, pp. 783–789.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ahmed-Ouamer and Hammache [2010]</span>
<span class="ltx_bibblock">
R. Ahmed-Ouamer, A. Hammache,

</span>
<span class="ltx_bibblock">Ontology-based information retrieval for e-learning of computer science,

</span>
<span class="ltx_bibblock">in: 2010 International Conference on Machine and Web Intelligence, IEEE, 2010, pp. 250–257.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">George and Lal [2019]</span>
<span class="ltx_bibblock">
G. George, A. M. Lal,

</span>
<span class="ltx_bibblock">Review of ontology-based recommender systems in e-learning,

</span>
<span class="ltx_bibblock">Computers &amp; Education 142 (2019) 103642. URL: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.sciencedirect.com/science/article/pii/S0360131519301952" title="">https://www.sciencedirect.com/science/article/pii/S0360131519301952</a>. doi:<a class="ltx_ref" href="https:/doi.org/https://doi.org/10.1016/j.compedu.2019.103642" title="">https://doi.org/10.1016/j.compedu.2019.103642</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shishehchi et al. [2012]</span>
<span class="ltx_bibblock">
S. Shishehchi, S. Banihashem, N. A. Mat Zin, S. A. Mohd Noah,

</span>
<span class="ltx_bibblock">Ontological approach in knowledge based recommender system to develop the quality of e-learning system,

</span>
<span class="ltx_bibblock">Australian Journal of Basic and Applied Sciences 6 (2012) 115–123.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bouihi and Bahaj [2017]</span>
<span class="ltx_bibblock">
B. Bouihi, M. Bahaj,

</span>
<span class="ltx_bibblock">An ontology-based architecture for context recommendation system in e-learning and mobile-learning applications,

</span>
<span class="ltx_bibblock">2017, pp. 1–6. doi:<a class="ltx_ref" href="https:/doi.org/10.1109/EITech.2017.8255278" title="">10.1109/EITech.2017.8255278</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tavakoli et al. [2022]</span>
<span class="ltx_bibblock">
M. Tavakoli, A. Faraji, J. Vrolijk, M. Molavi, S. T. Mol, G. Kismihók,

</span>
<span class="ltx_bibblock">An AI-based open recommender system for personalized labor market driven education,

</span>
<span class="ltx_bibblock">Advanced Engineering Informatics 52 (2022) 101508. URL: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1016/j.aei.2021.101508" title="">https://doi.org/10.1016/j.aei.2021.101508</a>. doi:<a class="ltx_ref" href="https:/doi.org/10.1016/j.aei.2021.101508" title="">10.1016/j.aei.2021.101508</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al. [2022]</span>
<span class="ltx_bibblock">
Y. Yang, Y. Qiao, T. Yang,

</span>
<span class="ltx_bibblock">Compact token representations with contextual quantization for efficient document re-ranking,

</span>
<span class="ltx_bibblock">in: Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 2022, pp. 695–707.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gil-Costa et al. [2022]</span>
<span class="ltx_bibblock">
V. Gil-Costa, F. Loor, R. Molina, F. M. Nardini, R. Perego, S. Trani,

</span>
<span class="ltx_bibblock">Ensemble model compression for fast and energy-efficient ranking on fpgas,

</span>
<span class="ltx_bibblock">in: European Conference on Information Retrieval, Springer, 2022, pp. 260–273.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zeng et al. [2023]</span>
<span class="ltx_bibblock">
H. Zeng, C. Luo, B. Jin, S. M. Sarwar, T. Wei, H. Zamani,

</span>
<span class="ltx_bibblock">Scalable and effective generative information retrieval,

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:2311.09134 (2023).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pradeep et al. [2023]</span>
<span class="ltx_bibblock">
R. Pradeep, K. Hui, J. Gupta, A. D. Lelkes, H. Zhuang, J. Lin, D. Metzler, V. Q. Tran,

</span>
<span class="ltx_bibblock">How does generative retrieval scale to millions of passages?,

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:2305.11841 (2023).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lassance et al. [2023]</span>
<span class="ltx_bibblock">
C. Lassance, S. Lupart, H. Dejean, S. Clinchant, N. Tonellotto,

</span>
<span class="ltx_bibblock">A static pruning study on sparse neural retrievers,

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:2304.12702 (2023).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Raffel et al. [2019]</span>
<span class="ltx_bibblock">
C. Raffel, N. Shazeer, A. Roberts, K. Lee, S. Narang, M. Matena, Y. Zhou, W. Li, P. J. Liu,

</span>
<span class="ltx_bibblock">Exploring the limits of transfer learning with a unified text-to-text transformer,

</span>
<span class="ltx_bibblock">CoRR (2019). URL: <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/1910.10683" title="">http://arxiv.org/abs/1910.10683</a>. <a class="ltx_ref ltx_href ltx_font_typewriter" href="http://arxiv.org/abs/1910.10683" title="">arXiv:1910.10683</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bonella [2020]</span>
<span class="ltx_bibblock">
H. Bonella, Burning glass occupational taxonomy (bgot), 2020. URL: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://economicmodeling.atlassian.net/wiki/spaces/KA/pages/2602501773/Burning+Glass+Occupational+Taxonomy+BGOT" title="">https://economicmodeling.atlassian.net/wiki/spaces/KA/pages/2602501773/Burning+Glass+Occupational+Taxonomy+BGOT</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lightcast<sup class="ltx_sup" id="bib.bib21.2.2.1">™</sup> [2023]</span>
<span class="ltx_bibblock">
Lightcast<sup class="ltx_sup" id="bib.bib21.3.1">™</sup>, 2023. URL: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://docs.lightcast.dev/apis/job-postings" title="">https://docs.lightcast.dev/apis/job-postings</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ni et al. [2021]</span>
<span class="ltx_bibblock">
J. Ni, C. Qu, J. Lu, Z. Dai, G. H. Ábrego, J. Ma, V. Y. Zhao, Y. Luan, K. B. Hall, M.-W. Chang, Y. Yang, Large dual encoders are generalizable retrievers, 2021. <a class="ltx_ref ltx_href ltx_font_typewriter" href="http://arxiv.org/abs/2112.07899" title="">arXiv:2112.07899</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bajaj et al. [2018]</span>
<span class="ltx_bibblock">
P. Bajaj, D. Campos, N. Craswell, L. Deng, J. Gao, X. Liu, R. Majumder, A. McNamara, B. Mitra, T. Nguyen, M. Rosenberg, X. Song, A. Stoica, S. Tiwary, T. Wang, Ms marco: A human generated machine reading comprehension dataset, 2018. <a class="ltx_ref ltx_href ltx_font_typewriter" href="http://arxiv.org/abs/1611.09268" title="">arXiv:1611.09268</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Thakur et al. [2021]</span>
<span class="ltx_bibblock">
N. Thakur, N. Reimers, A. Rücklé, A. Srivastava, I. Gurevych,

</span>
<span class="ltx_bibblock">BEIR: A heterogeneous benchmark for zero-shot evaluation of information retrieval models,

</span>
<span class="ltx_bibblock">in: Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2), 2021. URL: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openreview.net/forum?id=wCu6T5xFjeJ" title="">https://openreview.net/forum?id=wCu6T5xFjeJ</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Beltagy et al. [2020]</span>
<span class="ltx_bibblock">
I. Beltagy, M. E. Peters, A. Cohan, Longformer: The long-document transformer, 2020. <a class="ltx_ref ltx_href ltx_font_typewriter" href="http://arxiv.org/abs/2004.05150" title="">arXiv:2004.05150</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Althammer et al. [2021]</span>
<span class="ltx_bibblock">
S. Althammer, A. Askari, S. Verberne, A. Hanbury, Dossier@coliee 2021: Leveraging dense retrieval and summarization-based re-ranking for case law retrieval, 2021. <a class="ltx_ref ltx_href ltx_font_typewriter" href="http://arxiv.org/abs/2108.03937" title="">arXiv:2108.03937</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Askari and Verberne [2021]</span>
<span class="ltx_bibblock">
A. Askari, S. Verberne,

</span>
<span class="ltx_bibblock">Combining lexical and neural retrieval with longformer-based summarization for effective case law retrieval,

</span>
<span class="ltx_bibblock">in: Biennial Conference on Design of Experimental Search &amp; Information Retrieval Systems, 2021. URL: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://api.semanticscholar.org/CorpusID:238207602" title="">https://api.semanticscholar.org/CorpusID:238207602</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guo et al. [2022]</span>
<span class="ltx_bibblock">
M. Guo, J. Ainslie, D. Uthus, S. Ontanon, J. Ni, Y.-H. Sung, Y. Yang, Longt5: Efficient text-to-text transformer for long sequences, 2022. <a class="ltx_ref ltx_href ltx_font_typewriter" href="http://arxiv.org/abs/2112.07916" title="">arXiv:2112.07916</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chiang et al. [2023]</span>
<span class="ltx_bibblock">
W.-L. Chiang, Z. Li, Z. Lin, Y. Sheng, Z. Wu, H. Zhang, L. Zheng, S. Zhuang, Y. Zhuang, J. E. Gonzalez, I. Stoica, E. P. Xing, Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality, 2023. URL: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://lmsys.org/blog/2023-03-30-vicuna/" title="">https://lmsys.org/blog/2023-03-30-vicuna/</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et al. [2023]</span>
<span class="ltx_bibblock">
H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux, T. Lacroix, B. Rozière, N. Goyal, E. Hambro, F. Azhar, A. Rodriguez, A. Joulin, E. Grave, G. Lample, Llama: Open and efficient foundation language models, 2023. <a class="ltx_ref ltx_href ltx_font_typewriter" href="http://arxiv.org/abs/2302.13971" title="">arXiv:2302.13971</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gholami et al. [2021]</span>
<span class="ltx_bibblock">
A. Gholami, S. Kim, Z. Dong, Z. Yao, M. W. Mahoney, K. Keutzer,

</span>
<span class="ltx_bibblock">A survey of quantization methods for efficient neural network inference,

</span>
<span class="ltx_bibblock">CoRR abs/2103.13630 (2021). URL: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2103.13630" title="">https://arxiv.org/abs/2103.13630</a>. <a class="ltx_ref ltx_href ltx_font_typewriter" href="http://arxiv.org/abs/2103.13630" title="">arXiv:2103.13630</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xiao et al. [2023]</span>
<span class="ltx_bibblock">
G. Xiao, J. Lin, M. Seznec, H. Wu, J. Demouth, S. Han, Smoothquant: Accurate and efficient post-training quantization for large language models, 2023. <a class="ltx_ref ltx_href ltx_font_typewriter" href="http://arxiv.org/abs/2211.10438" title="">arXiv:2211.10438</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bollen et al. [2010]</span>
<span class="ltx_bibblock">
D. Bollen, B. P. Knijnenburg, M. C. Willemsen, M. Graus,

</span>
<span class="ltx_bibblock">Understanding choice overload in recommender systems,

</span>
<span class="ltx_bibblock">in: Proceedings of the Fourth ACM Conference on Recommender Systems, RecSys ’10, Association for Computing Machinery, New York, NY, USA, 2010, p. 63–70. URL: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/1864708.1864724" title="">https://doi.org/10.1145/1864708.1864724</a>. doi:<a class="ltx_ref" href="https:/doi.org/10.1145/1864708.1864724" title="">10.1145/1864708.1864724</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen and Tsoi [2011]</span>
<span class="ltx_bibblock">
L. Chen, H. Tsoi,

</span>
<span class="ltx_bibblock">Users’ decision behavior in recommender interfaces: Impact of layout design,

</span>
<span class="ltx_bibblock">CEUR Workshop Proceedings 811 (2011).

</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Thu Jun 27 09:06:02 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
