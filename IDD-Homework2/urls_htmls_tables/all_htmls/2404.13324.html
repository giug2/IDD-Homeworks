<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2404.13324] Collaborative Visual Place Recognition through Federated Learning</title><meta property="og:description" content="Visual Place Recognition (VPR) aims to estimate the location of an image by treating it as a retrieval problem. VPR uses a database of geo-tagged images and leverages deep neural networks to extract a global representaâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Collaborative Visual Place Recognition through Federated Learning">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Collaborative Visual Place Recognition through Federated Learning">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2404.13324">

<!--Generated on Sun May  5 20:28:37 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Collaborative Visual Place Recognition through Federated Learning</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Mattia Dutto<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Corresponding author</span></span></span>, Gabriele Berton, Debora Caldarola, Eros FanÃ¬, Gabriele Trivigno, Carlo Masone
<br class="ltx_break">Politecnico di Torino
<br class="ltx_break"><span id="id1.1.1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">name.surname@polito.it
<br class="ltx_break"><sup id="id1.1.1.1" class="ltx_sup"><span id="id1.1.1.1.1" class="ltx_text ltx_font_serif">âˆ—</span></sup><span id="id1.1.1.2" class="ltx_text ltx_font_serif">Corresponding Author: Mattia Dutto</span></span>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id2.id1" class="ltx_p">Visual Place Recognition (VPR) aims to estimate the location of an image by treating it as a retrieval problem. VPR uses a database of geo-tagged images and leverages deep neural networks to extract a global representation, called descriptor, from each image. While the training data for VPR models often originates from diverse, geographically scattered sources (geo-tagged images), the training process itself is typically assumed to be centralized. This research revisits the task of VPR through the lens of Federated Learning (FL), addressing several key challenges associated with this adaptation. VPR data inherently lacks well-defined classes, and models are typically trained using contrastive learning, which necessitates a data mining step on a centralized database. Additionally, client devices in federated systems can be highly heterogeneous in terms of their processing capabilities. The proposed FedVPR framework not only presents a novel approach for VPR but also introduces a new, challenging, and realistic task for FL research, paving the way to other image retrieval tasks in FL.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<figure id="S1.F1" class="ltx_figure"><img src="/html/2404.13324/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="230" height="163" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.5.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S1.F1.6.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Federated Visual Place Recognition<span id="S1.F1.6.2.1" class="ltx_text ltx_font_medium"> (FedVPR): we revisit the training of Visual Place Recognition models from the perspective of Federated Learning, with clients distributed across geographical areas, each possessing heterogeneous computational and communication resources and availability. Instead of relying on a central database for mining, each client builds its own database of geo-tagged images and uses it for local training based on contrastive learning (<span id="S1.F1.6.2.1.1" class="ltx_text" style="background-color:#000000;">step a.</span>). Subsequently, it communicates its model weights to the server, where they are aggregated into a new global model (<span id="S1.F1.6.2.1.2" class="ltx_text" style="background-color:#000000;">step b.</span>).</span></span></figcaption>
</figure>
<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">The ability to recognize the place depicted in a picture is of the utmost importance for many modern applications performed by camera-equipped mobile systems.
For example, in autonomous driving and mobile robotics, this ability is used for localization in instances where GPS measurement is unavailable or unreliableÂ <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib49" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">49</span></a>, <a href="#bib.bib64" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">64</span></a>]</cite>, or in facilitating loop closure within SLAM (Simultaneous Localization and Mapping) pipelinesÂ <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib38" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">38</span></a>]</cite>. Additionally, mobile phone applications heavily rely on this functionality for tasks like scene categorizationÂ <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib18" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">18</span></a>]</cite> and augmented reality supportÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib60" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">60</span></a>]</cite>. Likewise, wearable devices leverage this capability to provide useful information to the userÂ <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib19" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">19</span></a>]</cite>.
From a technical perspective, this task is referred to as <em id="S1.p1.1.1" class="ltx_emph ltx_font_italic">Visual Place Recognition</em> (VPR)Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">51</span></a>]</cite> and is naturally framed as an image retrieval problem. The query image to be localized is compared via features-space k-nearest neighbor (kNN) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">55</span></a>]</cite> to a database of images representing the known or already-visited places. Given that the database samples are usually labeled with geo-tags (such as GPS coordinates), the most similar images retrieved from the database serve as hypotheses of the queried location.
This approach entails representing each image with a single vector (<em id="S1.p1.1.2" class="ltx_emph ltx_font_italic">global feature descriptor</em>) so that the kNN can efficiently compute the similarity between two images, <em id="S1.p1.1.3" class="ltx_emph ltx_font_italic">e.g.</em>, as an Euclidean distance.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Recent research on VPR has been focusing predominantly on the development of deep neural networks capable of extracting global feature descriptors that are both compact and highly informative for place recognition while leveraging large collections of data from highly heterogeneous distributionsÂ <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib10" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">10</span></a>, <a href="#bib.bib2" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2</span></a>, <a href="#bib.bib12" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">12</span></a>, <a href="#bib.bib3" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">3</span></a>, <a href="#bib.bib39" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">39</span></a>, <a href="#bib.bib34" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">34</span></a>]</cite>.
However, this centralized formulation assumes the images are readily available on one computer or a central server, which does not suit the distributed nature of the VPR applications previously discussed well.
In an ideal scenario where mobile phones, wearable devices, and autonomous vehicles are deployed across numerous cities globally, it becomes crucial to leverage images collected by these diverse distributed devices without transferring their data to a central server, both for cost and privacy-related reasons. Furthermore, it would be beneficial to leverage the onboard computational capabilities of these devices to aid in model training.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">In light of these considerations, in this work we question <em id="S1.p3.1.1" class="ltx_emph ltx_font_italic">how to revisit the training of VPR models from the perspective of Federated Learning</em> (FL)Â <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib52" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">52</span></a>]</cite>, a distributed paradigm where multiple devices (<em id="S1.p3.1.2" class="ltx_emph ltx_font_italic">i.e.</em>, clients) exchange model parameters updates with a central server to learn a shared global model, without any transfer of local data (see <a href="#S1.F1" title="In 1 Introduction â€£ Collaborative Visual Place Recognition through Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">1</span></a>).
Some notable challenges make the adaptation of VPR to FL not trivial. Unlike the conventional FL literature that revolves around classification problems <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">17</span></a>, <a href="#bib.bib58" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">58</span></a>, <a href="#bib.bib16" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">16</span></a>]</cite>, VPR lacks a clear division of data into classes. Instead, the collected images are labeled with continuous space annotations (commonly in the form of GPS coordinates), and models are usually trained with contrastive learning techniquesÂ <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib5" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">5</span></a>]</cite>, which are often performed in conjunction with computationally heavy mining over a large centralized database <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">5</span></a>, <a href="#bib.bib37" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">37</span></a>, <a href="#bib.bib45" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">45</span></a>, <a href="#bib.bib27" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">27</span></a>]</cite>:
in a federated setting, this would be unfeasible due to (i) the low computational capacity of the clients and (ii) the privacy concerns that a centralized database would create.
By addressing these challenges, this paper introduces <span id="S1.p3.1.3" class="ltx_text ltx_font_bold">FedVPR</span>, the first formulation of VPR in a federated learning paradigm.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p"><span id="S1.p4.1.1" class="ltx_text ltx_font_bold">Contributions</span>:</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">We introduce the first formulation of the VPR task in a federated learning framework. The importance of this formulation is twofold: for the VPR field, it opens up a new research direction with important practical implications; for the FL field, it provides a new downstream task that can broaden the horizon of the research community.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">We propose a new splitting of the worldwide Mapillary Street-Level-Sequences (MSLS) datasetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib68" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">68</span></a>]</cite> into federated clients, designed to replicate realistic scenarios with varying degrees of statistical heterogeneity across them.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">We deal with clientsâ€™ data heterogeneity through critical design decisions such as client split, local iteration scheduling, and data augmentation, achieving centralized-level performances while accounting for power and computational requirements.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related work</h2>

<div id="S2.p1" class="ltx_para ltx_noindent">
<p id="S2.p1.1" class="ltx_p"><span id="S2.p1.1.1" class="ltx_text ltx_font_bold">Visual Place Recognition.</span> (VPR) aims to geolocate a given input photo, called <em id="S2.p1.1.2" class="ltx_emph ltx_font_italic">query</em>, by comparing it to a set of geo-tagged images (<em id="S2.p1.1.3" class="ltx_emph ltx_font_italic">i.e.</em>, with known GPS position), called <em id="S2.p1.1.4" class="ltx_emph ltx_font_italic">database</em>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">51</span></a>]</cite>.
Modern VPR methods leverage deep neural networks to extract global feature descriptors that provide a compact representation to perform a similarity search. An important milestone in this sense is the work by ArandjeloviÄ‡ et al. Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">5</span></a>]</cite>, which introduced a learnable aggregation layer called NetVLAD and a training protocol that leveraged street-view imagery through a triplet loss.
The triplet loss paradigm and NetVLAD layer have been used with slight modifications in a number of successive papers <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib37" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">37</span></a>, <a href="#bib.bib45" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">45</span></a>, <a href="#bib.bib27" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">27</span></a>, <a href="#bib.bib54" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">54</span></a>, <a href="#bib.bib53" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">53</span></a>, <a href="#bib.bib29" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">29</span></a>]</cite>.
Since then, various innovations have been proposed, <em id="S2.p1.1.5" class="ltx_emph ltx_font_italic">e.g.</em>, in the aggregation layers <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">7</span></a>, <a href="#bib.bib57" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">57</span></a>, <a href="#bib.bib3" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">3</span></a>, <a href="#bib.bib56" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">56</span></a>, <a href="#bib.bib65" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">65</span></a>, <a href="#bib.bib72" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">72</span></a>]</cite>, architecture <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib72" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">72</span></a>, <a href="#bib.bib37" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">37</span></a>, <a href="#bib.bib67" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">67</span></a>]</cite>, inference protocolÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib66" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">66</span></a>, <a href="#bib.bib6" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">6</span></a>]</cite>, training procedures <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">10</span></a>, <a href="#bib.bib39" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">39</span></a>, <a href="#bib.bib12" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">12</span></a>, <a href="#bib.bib2" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2</span></a>, <a href="#bib.bib33" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">33</span></a>, <a href="#bib.bib27" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">27</span></a>]</cite>, adaptation techniques <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib54" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">54</span></a>, <a href="#bib.bib4" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">4</span></a>]</cite>, post-processing strategies <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib72" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">72</span></a>, <a href="#bib.bib29" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">29</span></a>, <a href="#bib.bib9" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">9</span></a>, <a href="#bib.bib67" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">67</span></a>]</cite>, use of foundational models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">33</span></a>, <a href="#bib.bib36" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">36</span></a>]</cite>, as well as exploitation of temporal information <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib70" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">70</span></a>, <a href="#bib.bib25" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">25</span></a>, <a href="#bib.bib26" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">26</span></a>, <a href="#bib.bib53" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">53</span></a>, <a href="#bib.bib13" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">13</span></a>]</cite>.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">Recently, the release of increasingly large datasetsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib68" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">68</span></a>, <a href="#bib.bib10" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">10</span></a>, <a href="#bib.bib2" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2</span></a>]</cite> and the recognition that the expensive mining and large outputs of the traditional â€triplet-loss plus NetVLADâ€ paradigm hampers scalabilityÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">11</span></a>]</cite> has led to the emergence of solutions that can learn more efficiently from the data.
For example, CosPlace <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib10" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">10</span></a>]</cite> and its derivative works <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib12" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">12</span></a>, <a href="#bib.bib13" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">13</span></a>]</cite> use a mining-less classification proxy for training, whereas GCLÂ <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib39" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">39</span></a>]</cite> overcomes the expensive mining by leveraging graded similarity labels and integrate this with a generalized contrastive loss. Conv-AP <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib2" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2</span></a>]</cite> and MixVPR <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib3" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">3</span></a>]</cite> instead rely on a multi-similarity loss with more efficient online mining enabled by a curated dataset.
Despite their strong performance, these methods are unsuitable for federated learning because they either (i) require the full database to initialize training <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib10" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">10</span></a>, <a href="#bib.bib12" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">12</span></a>]</cite>, (ii) require batch sizes of hundreds of images from a curated dataset to converge <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib2" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2</span></a>, <a href="#bib.bib3" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">3</span></a>]</cite>, (iii) rely on large models and need additional similarity labels <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib39" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">39</span></a>]</cite>, or (iv) need a re-ranking step <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib29" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">29</span></a>, <a href="#bib.bib72" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">72</span></a>, <a href="#bib.bib8" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">8</span></a>, <a href="#bib.bib9" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">9</span></a>]</cite>, all too expensive to be performed on the clients.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">These factors make it challenging to apply federated learning to VPR. Indeed, there are a few works that <em id="S2.p3.1.1" class="ltx_emph ltx_font_italic">deploy</em> a single VPR model among multiple agents, which then localize collaboratively by fusing their descriptorsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">43</span></a>]</cite> or predictionsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">38</span></a>]</cite> in a consensus-like mechanism, but without any local or coordinated training. To the best of our knowledge, this is the first work that uses a federated learning approach to <em id="S2.p3.1.2" class="ltx_emph ltx_font_italic">learn</em> a global VPR model.</p>
</div>
<div id="S2.p4" class="ltx_para ltx_noindent">
<p id="S2.p4.1" class="ltx_p"><span id="S2.p4.1.1" class="ltx_text ltx_font_bold">Federated learning.</span> Federated Learning (FL) <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib52" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">52</span></a>]</cite> enables learning from private data at the edge and is based on the exchange of model parameters between multiple clients and a central server over several communication rounds. Each client trains a local copy of a common global model independently on its own private data and only sends back the updated parameters, which are then aggregated on the server side. The server remains unaware of any sensitive information, safeguarding privacy. The versatility of FL has led to its successful application in various domains, ranging from medical imaging <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib48" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">48</span></a>]</cite> to autonomous driving <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib24" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">24</span></a>, <a href="#bib.bib23" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">23</span></a>, <a href="#bib.bib62" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">62</span></a>]</cite> and natural language processing <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib47" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">47</span></a>, <a href="#bib.bib44" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">44</span></a>, <a href="#bib.bib73" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">73</span></a>]</cite>. Despite these accomplishments, the exploration of FLâ€™s potential in more complex vision applications remains incomplete <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib16" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">16</span></a>]</cite>.
This study marks a significant step in advancing FL, presenting the first reexamination of VPR within the federated setting. Adapting VPR to FL poses a major challenge due to the taskâ€™s reliance on mining large datasets. Furthermore, as VPR does not hinge on a discrete label space â€” unlike the majority of FL literature centered around classification methods <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">17</span></a>, <a href="#bib.bib16" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">16</span></a>]</cite> â€” this work introduces a novel case study, broadening the horizons of the FL research community. Aiming at studying real-world scenarios, we also take into consideration the challenges arising in realistic federated settings, namely <span id="S2.p4.1.2" class="ltx_text ltx_font_italic">statistical</span> and <span id="S2.p4.1.3" class="ltx_text ltx_font_italic">system heterogeneity</span> <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib41" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">41</span></a>, <a href="#bib.bib71" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">71</span></a>, <a href="#bib.bib58" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">58</span></a>]</cite>. Differently from standard distributed training scenarios, the clients are heterogeneous in terms of the distribution of the local data and computational capabilities and availability over time. This heterogeneity may arise from factors such as the usersâ€™ geographical locations or differences in internet access.
Due to such distribution shifts, the learning trend becomes inherently noisy and unstable <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib1" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">1</span></a>, <a href="#bib.bib58" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">58</span></a>, <a href="#bib.bib16" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">16</span></a>]</cite> and achieving a target performance necessitates more training rounds, impacting the communication network. Several approaches tackle this issue. Some focus on regularizing local training to prevent local objectives from deviating significantly from the global one <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib42" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">42</span></a>, <a href="#bib.bib35" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">35</span></a>, <a href="#bib.bib1" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">1</span></a>]</cite>. Others aim to virtually equalize the number of samples across clients (<em id="S2.p4.1.4" class="ltx_emph ltx_font_italic">e.g</em>.<span id="S2.p4.1.5" class="ltx_text"></span>, FedVC <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">32</span></a>]</cite>) or group similar clients together <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib61" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">61</span></a>, <a href="#bib.bib28" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">28</span></a>, <a href="#bib.bib22" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">22</span></a>, <a href="#bib.bib15" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">15</span></a>]</cite>.
Following the latter line of works, we further investigate hierarchical FL <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib14" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">14</span></a>, <a href="#bib.bib20" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">20</span></a>]</cite> for VPR. Clients found in close geographical locations are grouped together, with each cluster referring to a distinct server. All the servers communicate with a first-level additional server, orchestrating the overall training process. This approach facilitates a scalable VPR system that can adapt to regional preferences while maintaining a globally consistent framework.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Method</h2>

<figure id="S3.F2" class="ltx_figure"><img src="/html/2404.13324/assets/x2.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="66" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F2.22.5.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S3.F2.8.4" class="ltx_text ltx_font_bold" style="font-size:90%;">FedVPR training.<span id="S3.F2.8.4.4" class="ltx_text ltx_font_medium"> At each round <math id="S3.F2.5.1.1.m1.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S3.F2.5.1.1.m1.1b"><mi id="S3.F2.5.1.1.m1.1.1" xref="S3.F2.5.1.1.m1.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.F2.5.1.1.m1.1c"><ci id="S3.F2.5.1.1.m1.1.1.cmml" xref="S3.F2.5.1.1.m1.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.5.1.1.m1.1d">t</annotation></semantics></math>, the server <span id="S3.F2.8.4.4.1" class="ltx_text" style="color:#26FFCC;">sends the current global model</span> to a set of active clients, <em id="S3.F2.8.4.4.2" class="ltx_emph ltx_font_italic">e.g</em>.<span id="S3.F2.8.4.4.3" class="ltx_text"></span> <span id="S3.F2.8.4.4.4" class="ltx_text ltx_font_italic">client 1</span> and <span id="S3.F2.8.4.4.5" class="ltx_text ltx_font_italic">client 2</span> in the figure. Each client <math id="S3.F2.6.2.2.m2.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.F2.6.2.2.m2.1b"><mi id="S3.F2.6.2.2.m2.1.1" xref="S3.F2.6.2.2.m2.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.F2.6.2.2.m2.1c"><ci id="S3.F2.6.2.2.m2.1.1.cmml" xref="S3.F2.6.2.2.m2.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.6.2.2.m2.1d">i</annotation></semantics></math> has access to its own local dataset <math id="S3.F2.7.3.3.m3.1" class="ltx_Math" alttext="\mathcal{D}_{i}" display="inline"><semantics id="S3.F2.7.3.3.m3.1b"><msub id="S3.F2.7.3.3.m3.1.1" xref="S3.F2.7.3.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.F2.7.3.3.m3.1.1.2" xref="S3.F2.7.3.3.m3.1.1.2.cmml">ğ’Ÿ</mi><mi id="S3.F2.7.3.3.m3.1.1.3" xref="S3.F2.7.3.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.F2.7.3.3.m3.1c"><apply id="S3.F2.7.3.3.m3.1.1.cmml" xref="S3.F2.7.3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.F2.7.3.3.m3.1.1.1.cmml" xref="S3.F2.7.3.3.m3.1.1">subscript</csymbol><ci id="S3.F2.7.3.3.m3.1.1.2.cmml" xref="S3.F2.7.3.3.m3.1.1.2">ğ’Ÿ</ci><ci id="S3.F2.7.3.3.m3.1.1.3.cmml" xref="S3.F2.7.3.3.m3.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.7.3.3.m3.1d">\mathcal{D}_{i}</annotation></semantics></math>, whose distribution is highly influenced by the userâ€™s geographical positions (hence the country flags on the local datasets). Differently from centralized VPR, in FedVPR the mining happens exploiting the clientâ€™s previously collected images. Thus, given a <span id="S3.F2.8.4.4.6" class="ltx_text" style="color:#808080;">query image</span>, local optimization is based on a contrastive loss, which relies on a <span id="S3.F2.8.4.4.7" class="ltx_text" style="color:#00E000;">positive</span> and <span id="S3.F2.8.4.4.8" class="ltx_text" style="color:#B80000;">negative</span> images extracted from <math id="S3.F2.8.4.4.m4.1" class="ltx_Math" alttext="\mathcal{D}_{i}" display="inline"><semantics id="S3.F2.8.4.4.m4.1b"><msub id="S3.F2.8.4.4.m4.1.1" xref="S3.F2.8.4.4.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.F2.8.4.4.m4.1.1.2" xref="S3.F2.8.4.4.m4.1.1.2.cmml">ğ’Ÿ</mi><mi id="S3.F2.8.4.4.m4.1.1.3" xref="S3.F2.8.4.4.m4.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.F2.8.4.4.m4.1c"><apply id="S3.F2.8.4.4.m4.1.1.cmml" xref="S3.F2.8.4.4.m4.1.1"><csymbol cd="ambiguous" id="S3.F2.8.4.4.m4.1.1.1.cmml" xref="S3.F2.8.4.4.m4.1.1">subscript</csymbol><ci id="S3.F2.8.4.4.m4.1.1.2.cmml" xref="S3.F2.8.4.4.m4.1.1.2">ğ’Ÿ</ci><ci id="S3.F2.8.4.4.m4.1.1.3.cmml" xref="S3.F2.8.4.4.m4.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.8.4.4.m4.1d">\mathcal{D}_{i}</annotation></semantics></math>. Since each local dataset follows a different distribution, the resulting updated parameters vary from client to client (<span id="S3.F2.8.4.4.9" class="ltx_text ltx_font_italic" style="color:#FF804D;">orange</span> vs. <span id="S3.F2.8.4.4.10" class="ltx_text ltx_font_italic" style="color:#AD5CFF;">purple</span> updates). Lastly, the <span id="S3.F2.8.4.4.11" class="ltx_text" style="color:#FF2EFF;">local parameters are sent back to the server</span>, where they are aggregated with FedAvg.</span></span></figcaption>
</figure>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Centralized VPR</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.15" class="ltx_p">The task of VPR is commonly approached as an image retrieval problem. Given a query image, the goal is to find the most similar matches within a geo-tagged database to infer the queryâ€™s location.
When training a VPR model, we aim to learn a function <math id="S3.SS1.p1.1.m1.1" class="ltx_Math" alttext="F_{\theta}:\mathbb{X}\rightarrow\mathbb{D}" display="inline"><semantics id="S3.SS1.p1.1.m1.1a"><mrow id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml"><msub id="S3.SS1.p1.1.m1.1.1.2" xref="S3.SS1.p1.1.m1.1.1.2.cmml"><mi id="S3.SS1.p1.1.m1.1.1.2.2" xref="S3.SS1.p1.1.m1.1.1.2.2.cmml">F</mi><mi id="S3.SS1.p1.1.m1.1.1.2.3" xref="S3.SS1.p1.1.m1.1.1.2.3.cmml">Î¸</mi></msub><mo lspace="0.278em" rspace="0.278em" id="S3.SS1.p1.1.m1.1.1.1" xref="S3.SS1.p1.1.m1.1.1.1.cmml">:</mo><mrow id="S3.SS1.p1.1.m1.1.1.3" xref="S3.SS1.p1.1.m1.1.1.3.cmml"><mi id="S3.SS1.p1.1.m1.1.1.3.2" xref="S3.SS1.p1.1.m1.1.1.3.2.cmml">ğ•</mi><mo stretchy="false" id="S3.SS1.p1.1.m1.1.1.3.1" xref="S3.SS1.p1.1.m1.1.1.3.1.cmml">â†’</mo><mi id="S3.SS1.p1.1.m1.1.1.3.3" xref="S3.SS1.p1.1.m1.1.1.3.3.cmml">ğ”»</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><apply id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1"><ci id="S3.SS1.p1.1.m1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1.1">:</ci><apply id="S3.SS1.p1.1.m1.1.1.2.cmml" xref="S3.SS1.p1.1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.1.1.2.1.cmml" xref="S3.SS1.p1.1.m1.1.1.2">subscript</csymbol><ci id="S3.SS1.p1.1.m1.1.1.2.2.cmml" xref="S3.SS1.p1.1.m1.1.1.2.2">ğ¹</ci><ci id="S3.SS1.p1.1.m1.1.1.2.3.cmml" xref="S3.SS1.p1.1.m1.1.1.2.3">ğœƒ</ci></apply><apply id="S3.SS1.p1.1.m1.1.1.3.cmml" xref="S3.SS1.p1.1.m1.1.1.3"><ci id="S3.SS1.p1.1.m1.1.1.3.1.cmml" xref="S3.SS1.p1.1.m1.1.1.3.1">â†’</ci><ci id="S3.SS1.p1.1.m1.1.1.3.2.cmml" xref="S3.SS1.p1.1.m1.1.1.3.2">ğ•</ci><ci id="S3.SS1.p1.1.m1.1.1.3.3.cmml" xref="S3.SS1.p1.1.m1.1.1.3.3">ğ”»</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">F_{\theta}:\mathbb{X}\rightarrow\mathbb{D}</annotation></semantics></math> parameterized by <math id="S3.SS1.p1.2.m2.1" class="ltx_Math" alttext="\theta\in\mathbb{R}^{p}" display="inline"><semantics id="S3.SS1.p1.2.m2.1a"><mrow id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml"><mi id="S3.SS1.p1.2.m2.1.1.2" xref="S3.SS1.p1.2.m2.1.1.2.cmml">Î¸</mi><mo id="S3.SS1.p1.2.m2.1.1.1" xref="S3.SS1.p1.2.m2.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS1.p1.2.m2.1.1.3" xref="S3.SS1.p1.2.m2.1.1.3.cmml"><mi id="S3.SS1.p1.2.m2.1.1.3.2" xref="S3.SS1.p1.2.m2.1.1.3.2.cmml">â„</mi><mi id="S3.SS1.p1.2.m2.1.1.3.3" xref="S3.SS1.p1.2.m2.1.1.3.3.cmml">p</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><apply id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1"><in id="S3.SS1.p1.2.m2.1.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1.1"></in><ci id="S3.SS1.p1.2.m2.1.1.2.cmml" xref="S3.SS1.p1.2.m2.1.1.2">ğœƒ</ci><apply id="S3.SS1.p1.2.m2.1.1.3.cmml" xref="S3.SS1.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.1.1.3.1.cmml" xref="S3.SS1.p1.2.m2.1.1.3">superscript</csymbol><ci id="S3.SS1.p1.2.m2.1.1.3.2.cmml" xref="S3.SS1.p1.2.m2.1.1.3.2">â„</ci><ci id="S3.SS1.p1.2.m2.1.1.3.3.cmml" xref="S3.SS1.p1.2.m2.1.1.3.3">ğ‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">\theta\in\mathbb{R}^{p}</annotation></semantics></math> which projects each image sample <math id="S3.SS1.p1.3.m3.1" class="ltx_Math" alttext="x\in\mathbb{X}" display="inline"><semantics id="S3.SS1.p1.3.m3.1a"><mrow id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml"><mi id="S3.SS1.p1.3.m3.1.1.2" xref="S3.SS1.p1.3.m3.1.1.2.cmml">x</mi><mo id="S3.SS1.p1.3.m3.1.1.1" xref="S3.SS1.p1.3.m3.1.1.1.cmml">âˆˆ</mo><mi id="S3.SS1.p1.3.m3.1.1.3" xref="S3.SS1.p1.3.m3.1.1.3.cmml">ğ•</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><apply id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1"><in id="S3.SS1.p1.3.m3.1.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1.1"></in><ci id="S3.SS1.p1.3.m3.1.1.2.cmml" xref="S3.SS1.p1.3.m3.1.1.2">ğ‘¥</ci><ci id="S3.SS1.p1.3.m3.1.1.3.cmml" xref="S3.SS1.p1.3.m3.1.1.3">ğ•</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">x\in\mathbb{X}</annotation></semantics></math> into a common embedding space <math id="S3.SS1.p1.4.m4.1" class="ltx_Math" alttext="\mathbb{D}" display="inline"><semantics id="S3.SS1.p1.4.m4.1a"><mi id="S3.SS1.p1.4.m4.1.1" xref="S3.SS1.p1.4.m4.1.1.cmml">ğ”»</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m4.1b"><ci id="S3.SS1.p1.4.m4.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1">ğ”»</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m4.1c">\mathbb{D}</annotation></semantics></math> of dimensionality <math id="S3.SS1.p1.5.m5.1" class="ltx_Math" alttext="d" display="inline"><semantics id="S3.SS1.p1.5.m5.1a"><mi id="S3.SS1.p1.5.m5.1.1" xref="S3.SS1.p1.5.m5.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.5.m5.1b"><ci id="S3.SS1.p1.5.m5.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1">ğ‘‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.5.m5.1c">d</annotation></semantics></math>.
Intuitively, <math id="S3.SS1.p1.6.m6.1" class="ltx_Math" alttext="F_{\theta}" display="inline"><semantics id="S3.SS1.p1.6.m6.1a"><msub id="S3.SS1.p1.6.m6.1.1" xref="S3.SS1.p1.6.m6.1.1.cmml"><mi id="S3.SS1.p1.6.m6.1.1.2" xref="S3.SS1.p1.6.m6.1.1.2.cmml">F</mi><mi id="S3.SS1.p1.6.m6.1.1.3" xref="S3.SS1.p1.6.m6.1.1.3.cmml">Î¸</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.6.m6.1b"><apply id="S3.SS1.p1.6.m6.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.6.m6.1.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1">subscript</csymbol><ci id="S3.SS1.p1.6.m6.1.1.2.cmml" xref="S3.SS1.p1.6.m6.1.1.2">ğ¹</ci><ci id="S3.SS1.p1.6.m6.1.1.3.cmml" xref="S3.SS1.p1.6.m6.1.1.3">ğœƒ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.6.m6.1c">F_{\theta}</annotation></semantics></math> should provide an embedding space where different representations of the same place (<em id="S3.SS1.p1.15.1" class="ltx_emph ltx_font_italic">e.g.</em>, the same building seen with different perspectives or illuminations) should be close to each other while simultaneously being far from representations of other places.
VPR models are commonly trained with contrastive losses <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">5</span></a>, <a href="#bib.bib27" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">27</span></a>, <a href="#bib.bib69" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">69</span></a>, <a href="#bib.bib11" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">11</span></a>]</cite>, which rely on feeding the model with
samples from the same place (<span id="S3.SS1.p1.15.2" class="ltx_text ltx_font_italic">positives</span>) and samples from different, although potentially similar, locations (<span id="S3.SS1.p1.15.3" class="ltx_text ltx_font_italic">negative</span>).
The most common approach is to use a triplet loss <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">5</span></a>]</cite>, which takes a query (<span id="S3.SS1.p1.15.4" class="ltx_text ltx_font_italic">anchor</span>), a positive and a negative image, and aims at bringing the query and the positive sample closer in the features space, while pushing away the negative one.
However, when using such formulations of the loss, if the chosen negativeâ€™s embeddings are already far away from the queryâ€™s ones (a <span id="S3.SS1.p1.15.5" class="ltx_text ltx_font_italic">trivial negative</span>), the loss will be close to zero, thus leading to uninformative gradients.
To circumvent this issue, hard negatives (<em id="S3.SS1.p1.15.6" class="ltx_emph ltx_font_italic">i.e.</em>, negatives close to the query in features space, or visually similar)
must be selected, enabling the model to reach higher performances <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib11" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">11</span></a>]</cite>.
The hard negatives selection process takes the name of <span id="S3.SS1.p1.15.7" class="ltx_text ltx_font_bold">mining</span> and is a time-consuming technique performed throughout the training phase to select ever-increasing difficult negatives for each given query.
Formally, for a given training query <math id="S3.SS1.p1.7.m7.1" class="ltx_Math" alttext="q\in\mathbb{X}" display="inline"><semantics id="S3.SS1.p1.7.m7.1a"><mrow id="S3.SS1.p1.7.m7.1.1" xref="S3.SS1.p1.7.m7.1.1.cmml"><mi id="S3.SS1.p1.7.m7.1.1.2" xref="S3.SS1.p1.7.m7.1.1.2.cmml">q</mi><mo id="S3.SS1.p1.7.m7.1.1.1" xref="S3.SS1.p1.7.m7.1.1.1.cmml">âˆˆ</mo><mi id="S3.SS1.p1.7.m7.1.1.3" xref="S3.SS1.p1.7.m7.1.1.3.cmml">ğ•</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.7.m7.1b"><apply id="S3.SS1.p1.7.m7.1.1.cmml" xref="S3.SS1.p1.7.m7.1.1"><in id="S3.SS1.p1.7.m7.1.1.1.cmml" xref="S3.SS1.p1.7.m7.1.1.1"></in><ci id="S3.SS1.p1.7.m7.1.1.2.cmml" xref="S3.SS1.p1.7.m7.1.1.2">ğ‘</ci><ci id="S3.SS1.p1.7.m7.1.1.3.cmml" xref="S3.SS1.p1.7.m7.1.1.3">ğ•</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.7.m7.1c">q\in\mathbb{X}</annotation></semantics></math>, we want to obtain a training triplet <math id="S3.SS1.p1.8.m8.3" class="ltx_Math" alttext="(q,\tilde{p}^{q},\tilde{n}^{q})" display="inline"><semantics id="S3.SS1.p1.8.m8.3a"><mrow id="S3.SS1.p1.8.m8.3.3.2" xref="S3.SS1.p1.8.m8.3.3.3.cmml"><mo stretchy="false" id="S3.SS1.p1.8.m8.3.3.2.3" xref="S3.SS1.p1.8.m8.3.3.3.cmml">(</mo><mi id="S3.SS1.p1.8.m8.1.1" xref="S3.SS1.p1.8.m8.1.1.cmml">q</mi><mo id="S3.SS1.p1.8.m8.3.3.2.4" xref="S3.SS1.p1.8.m8.3.3.3.cmml">,</mo><msup id="S3.SS1.p1.8.m8.2.2.1.1" xref="S3.SS1.p1.8.m8.2.2.1.1.cmml"><mover accent="true" id="S3.SS1.p1.8.m8.2.2.1.1.2" xref="S3.SS1.p1.8.m8.2.2.1.1.2.cmml"><mi id="S3.SS1.p1.8.m8.2.2.1.1.2.2" xref="S3.SS1.p1.8.m8.2.2.1.1.2.2.cmml">p</mi><mo id="S3.SS1.p1.8.m8.2.2.1.1.2.1" xref="S3.SS1.p1.8.m8.2.2.1.1.2.1.cmml">~</mo></mover><mi id="S3.SS1.p1.8.m8.2.2.1.1.3" xref="S3.SS1.p1.8.m8.2.2.1.1.3.cmml">q</mi></msup><mo id="S3.SS1.p1.8.m8.3.3.2.5" xref="S3.SS1.p1.8.m8.3.3.3.cmml">,</mo><msup id="S3.SS1.p1.8.m8.3.3.2.2" xref="S3.SS1.p1.8.m8.3.3.2.2.cmml"><mover accent="true" id="S3.SS1.p1.8.m8.3.3.2.2.2" xref="S3.SS1.p1.8.m8.3.3.2.2.2.cmml"><mi id="S3.SS1.p1.8.m8.3.3.2.2.2.2" xref="S3.SS1.p1.8.m8.3.3.2.2.2.2.cmml">n</mi><mo id="S3.SS1.p1.8.m8.3.3.2.2.2.1" xref="S3.SS1.p1.8.m8.3.3.2.2.2.1.cmml">~</mo></mover><mi id="S3.SS1.p1.8.m8.3.3.2.2.3" xref="S3.SS1.p1.8.m8.3.3.2.2.3.cmml">q</mi></msup><mo stretchy="false" id="S3.SS1.p1.8.m8.3.3.2.6" xref="S3.SS1.p1.8.m8.3.3.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.8.m8.3b"><vector id="S3.SS1.p1.8.m8.3.3.3.cmml" xref="S3.SS1.p1.8.m8.3.3.2"><ci id="S3.SS1.p1.8.m8.1.1.cmml" xref="S3.SS1.p1.8.m8.1.1">ğ‘</ci><apply id="S3.SS1.p1.8.m8.2.2.1.1.cmml" xref="S3.SS1.p1.8.m8.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.8.m8.2.2.1.1.1.cmml" xref="S3.SS1.p1.8.m8.2.2.1.1">superscript</csymbol><apply id="S3.SS1.p1.8.m8.2.2.1.1.2.cmml" xref="S3.SS1.p1.8.m8.2.2.1.1.2"><ci id="S3.SS1.p1.8.m8.2.2.1.1.2.1.cmml" xref="S3.SS1.p1.8.m8.2.2.1.1.2.1">~</ci><ci id="S3.SS1.p1.8.m8.2.2.1.1.2.2.cmml" xref="S3.SS1.p1.8.m8.2.2.1.1.2.2">ğ‘</ci></apply><ci id="S3.SS1.p1.8.m8.2.2.1.1.3.cmml" xref="S3.SS1.p1.8.m8.2.2.1.1.3">ğ‘</ci></apply><apply id="S3.SS1.p1.8.m8.3.3.2.2.cmml" xref="S3.SS1.p1.8.m8.3.3.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.8.m8.3.3.2.2.1.cmml" xref="S3.SS1.p1.8.m8.3.3.2.2">superscript</csymbol><apply id="S3.SS1.p1.8.m8.3.3.2.2.2.cmml" xref="S3.SS1.p1.8.m8.3.3.2.2.2"><ci id="S3.SS1.p1.8.m8.3.3.2.2.2.1.cmml" xref="S3.SS1.p1.8.m8.3.3.2.2.2.1">~</ci><ci id="S3.SS1.p1.8.m8.3.3.2.2.2.2.cmml" xref="S3.SS1.p1.8.m8.3.3.2.2.2.2">ğ‘›</ci></apply><ci id="S3.SS1.p1.8.m8.3.3.2.2.3.cmml" xref="S3.SS1.p1.8.m8.3.3.2.2.3">ğ‘</ci></apply></vector></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.8.m8.3c">(q,\tilde{p}^{q},\tilde{n}^{q})</annotation></semantics></math>, where <math id="S3.SS1.p1.9.m9.1" class="ltx_Math" alttext="\tilde{p}^{q}" display="inline"><semantics id="S3.SS1.p1.9.m9.1a"><msup id="S3.SS1.p1.9.m9.1.1" xref="S3.SS1.p1.9.m9.1.1.cmml"><mover accent="true" id="S3.SS1.p1.9.m9.1.1.2" xref="S3.SS1.p1.9.m9.1.1.2.cmml"><mi id="S3.SS1.p1.9.m9.1.1.2.2" xref="S3.SS1.p1.9.m9.1.1.2.2.cmml">p</mi><mo id="S3.SS1.p1.9.m9.1.1.2.1" xref="S3.SS1.p1.9.m9.1.1.2.1.cmml">~</mo></mover><mi id="S3.SS1.p1.9.m9.1.1.3" xref="S3.SS1.p1.9.m9.1.1.3.cmml">q</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.9.m9.1b"><apply id="S3.SS1.p1.9.m9.1.1.cmml" xref="S3.SS1.p1.9.m9.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.9.m9.1.1.1.cmml" xref="S3.SS1.p1.9.m9.1.1">superscript</csymbol><apply id="S3.SS1.p1.9.m9.1.1.2.cmml" xref="S3.SS1.p1.9.m9.1.1.2"><ci id="S3.SS1.p1.9.m9.1.1.2.1.cmml" xref="S3.SS1.p1.9.m9.1.1.2.1">~</ci><ci id="S3.SS1.p1.9.m9.1.1.2.2.cmml" xref="S3.SS1.p1.9.m9.1.1.2.2">ğ‘</ci></apply><ci id="S3.SS1.p1.9.m9.1.1.3.cmml" xref="S3.SS1.p1.9.m9.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.9.m9.1c">\tilde{p}^{q}</annotation></semantics></math> is its positive image and <math id="S3.SS1.p1.10.m10.1" class="ltx_Math" alttext="\tilde{n}^{q}" display="inline"><semantics id="S3.SS1.p1.10.m10.1a"><msup id="S3.SS1.p1.10.m10.1.1" xref="S3.SS1.p1.10.m10.1.1.cmml"><mover accent="true" id="S3.SS1.p1.10.m10.1.1.2" xref="S3.SS1.p1.10.m10.1.1.2.cmml"><mi id="S3.SS1.p1.10.m10.1.1.2.2" xref="S3.SS1.p1.10.m10.1.1.2.2.cmml">n</mi><mo id="S3.SS1.p1.10.m10.1.1.2.1" xref="S3.SS1.p1.10.m10.1.1.2.1.cmml">~</mo></mover><mi id="S3.SS1.p1.10.m10.1.1.3" xref="S3.SS1.p1.10.m10.1.1.3.cmml">q</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.10.m10.1b"><apply id="S3.SS1.p1.10.m10.1.1.cmml" xref="S3.SS1.p1.10.m10.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.10.m10.1.1.1.cmml" xref="S3.SS1.p1.10.m10.1.1">superscript</csymbol><apply id="S3.SS1.p1.10.m10.1.1.2.cmml" xref="S3.SS1.p1.10.m10.1.1.2"><ci id="S3.SS1.p1.10.m10.1.1.2.1.cmml" xref="S3.SS1.p1.10.m10.1.1.2.1">~</ci><ci id="S3.SS1.p1.10.m10.1.1.2.2.cmml" xref="S3.SS1.p1.10.m10.1.1.2.2">ğ‘›</ci></apply><ci id="S3.SS1.p1.10.m10.1.1.3.cmml" xref="S3.SS1.p1.10.m10.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.10.m10.1c">\tilde{n}^{q}</annotation></semantics></math> the negative one. The set of potential positives <math id="S3.SS1.p1.11.m11.1" class="ltx_Math" alttext="\mathcal{P}:=\{p^{q}_{i}\}" display="inline"><semantics id="S3.SS1.p1.11.m11.1a"><mrow id="S3.SS1.p1.11.m11.1.1" xref="S3.SS1.p1.11.m11.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p1.11.m11.1.1.3" xref="S3.SS1.p1.11.m11.1.1.3.cmml">ğ’«</mi><mo lspace="0.278em" rspace="0.278em" id="S3.SS1.p1.11.m11.1.1.2" xref="S3.SS1.p1.11.m11.1.1.2.cmml">:=</mo><mrow id="S3.SS1.p1.11.m11.1.1.1.1" xref="S3.SS1.p1.11.m11.1.1.1.2.cmml"><mo stretchy="false" id="S3.SS1.p1.11.m11.1.1.1.1.2" xref="S3.SS1.p1.11.m11.1.1.1.2.cmml">{</mo><msubsup id="S3.SS1.p1.11.m11.1.1.1.1.1" xref="S3.SS1.p1.11.m11.1.1.1.1.1.cmml"><mi id="S3.SS1.p1.11.m11.1.1.1.1.1.2.2" xref="S3.SS1.p1.11.m11.1.1.1.1.1.2.2.cmml">p</mi><mi id="S3.SS1.p1.11.m11.1.1.1.1.1.3" xref="S3.SS1.p1.11.m11.1.1.1.1.1.3.cmml">i</mi><mi id="S3.SS1.p1.11.m11.1.1.1.1.1.2.3" xref="S3.SS1.p1.11.m11.1.1.1.1.1.2.3.cmml">q</mi></msubsup><mo stretchy="false" id="S3.SS1.p1.11.m11.1.1.1.1.3" xref="S3.SS1.p1.11.m11.1.1.1.2.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.11.m11.1b"><apply id="S3.SS1.p1.11.m11.1.1.cmml" xref="S3.SS1.p1.11.m11.1.1"><csymbol cd="latexml" id="S3.SS1.p1.11.m11.1.1.2.cmml" xref="S3.SS1.p1.11.m11.1.1.2">assign</csymbol><ci id="S3.SS1.p1.11.m11.1.1.3.cmml" xref="S3.SS1.p1.11.m11.1.1.3">ğ’«</ci><set id="S3.SS1.p1.11.m11.1.1.1.2.cmml" xref="S3.SS1.p1.11.m11.1.1.1.1"><apply id="S3.SS1.p1.11.m11.1.1.1.1.1.cmml" xref="S3.SS1.p1.11.m11.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.11.m11.1.1.1.1.1.1.cmml" xref="S3.SS1.p1.11.m11.1.1.1.1.1">subscript</csymbol><apply id="S3.SS1.p1.11.m11.1.1.1.1.1.2.cmml" xref="S3.SS1.p1.11.m11.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.11.m11.1.1.1.1.1.2.1.cmml" xref="S3.SS1.p1.11.m11.1.1.1.1.1">superscript</csymbol><ci id="S3.SS1.p1.11.m11.1.1.1.1.1.2.2.cmml" xref="S3.SS1.p1.11.m11.1.1.1.1.1.2.2">ğ‘</ci><ci id="S3.SS1.p1.11.m11.1.1.1.1.1.2.3.cmml" xref="S3.SS1.p1.11.m11.1.1.1.1.1.2.3">ğ‘</ci></apply><ci id="S3.SS1.p1.11.m11.1.1.1.1.1.3.cmml" xref="S3.SS1.p1.11.m11.1.1.1.1.1.3">ğ‘–</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.11.m11.1c">\mathcal{P}:=\{p^{q}_{i}\}</annotation></semantics></math>, commonly defined as the images within a threshold <math id="S3.SS1.p1.12.m12.1" class="ltx_Math" alttext="\tau=25" display="inline"><semantics id="S3.SS1.p1.12.m12.1a"><mrow id="S3.SS1.p1.12.m12.1.1" xref="S3.SS1.p1.12.m12.1.1.cmml"><mi id="S3.SS1.p1.12.m12.1.1.2" xref="S3.SS1.p1.12.m12.1.1.2.cmml">Ï„</mi><mo id="S3.SS1.p1.12.m12.1.1.1" xref="S3.SS1.p1.12.m12.1.1.1.cmml">=</mo><mn id="S3.SS1.p1.12.m12.1.1.3" xref="S3.SS1.p1.12.m12.1.1.3.cmml">25</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.12.m12.1b"><apply id="S3.SS1.p1.12.m12.1.1.cmml" xref="S3.SS1.p1.12.m12.1.1"><eq id="S3.SS1.p1.12.m12.1.1.1.cmml" xref="S3.SS1.p1.12.m12.1.1.1"></eq><ci id="S3.SS1.p1.12.m12.1.1.2.cmml" xref="S3.SS1.p1.12.m12.1.1.2">ğœ</ci><cn type="integer" id="S3.SS1.p1.12.m12.1.1.3.cmml" xref="S3.SS1.p1.12.m12.1.1.3">25</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.12.m12.1c">\tau=25</annotation></semantics></math> meters from the query <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">5</span></a>, <a href="#bib.bib37" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">37</span></a>, <a href="#bib.bib72" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">72</span></a>]</cite>, is retrieved using the GPS label.
The set of negatives <math id="S3.SS1.p1.13.m13.1" class="ltx_Math" alttext="\mathcal{N}:=\{n^{q}_{i}\}" display="inline"><semantics id="S3.SS1.p1.13.m13.1a"><mrow id="S3.SS1.p1.13.m13.1.1" xref="S3.SS1.p1.13.m13.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p1.13.m13.1.1.3" xref="S3.SS1.p1.13.m13.1.1.3.cmml">ğ’©</mi><mo lspace="0.278em" rspace="0.278em" id="S3.SS1.p1.13.m13.1.1.2" xref="S3.SS1.p1.13.m13.1.1.2.cmml">:=</mo><mrow id="S3.SS1.p1.13.m13.1.1.1.1" xref="S3.SS1.p1.13.m13.1.1.1.2.cmml"><mo stretchy="false" id="S3.SS1.p1.13.m13.1.1.1.1.2" xref="S3.SS1.p1.13.m13.1.1.1.2.cmml">{</mo><msubsup id="S3.SS1.p1.13.m13.1.1.1.1.1" xref="S3.SS1.p1.13.m13.1.1.1.1.1.cmml"><mi id="S3.SS1.p1.13.m13.1.1.1.1.1.2.2" xref="S3.SS1.p1.13.m13.1.1.1.1.1.2.2.cmml">n</mi><mi id="S3.SS1.p1.13.m13.1.1.1.1.1.3" xref="S3.SS1.p1.13.m13.1.1.1.1.1.3.cmml">i</mi><mi id="S3.SS1.p1.13.m13.1.1.1.1.1.2.3" xref="S3.SS1.p1.13.m13.1.1.1.1.1.2.3.cmml">q</mi></msubsup><mo stretchy="false" id="S3.SS1.p1.13.m13.1.1.1.1.3" xref="S3.SS1.p1.13.m13.1.1.1.2.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.13.m13.1b"><apply id="S3.SS1.p1.13.m13.1.1.cmml" xref="S3.SS1.p1.13.m13.1.1"><csymbol cd="latexml" id="S3.SS1.p1.13.m13.1.1.2.cmml" xref="S3.SS1.p1.13.m13.1.1.2">assign</csymbol><ci id="S3.SS1.p1.13.m13.1.1.3.cmml" xref="S3.SS1.p1.13.m13.1.1.3">ğ’©</ci><set id="S3.SS1.p1.13.m13.1.1.1.2.cmml" xref="S3.SS1.p1.13.m13.1.1.1.1"><apply id="S3.SS1.p1.13.m13.1.1.1.1.1.cmml" xref="S3.SS1.p1.13.m13.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.13.m13.1.1.1.1.1.1.cmml" xref="S3.SS1.p1.13.m13.1.1.1.1.1">subscript</csymbol><apply id="S3.SS1.p1.13.m13.1.1.1.1.1.2.cmml" xref="S3.SS1.p1.13.m13.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.13.m13.1.1.1.1.1.2.1.cmml" xref="S3.SS1.p1.13.m13.1.1.1.1.1">superscript</csymbol><ci id="S3.SS1.p1.13.m13.1.1.1.1.1.2.2.cmml" xref="S3.SS1.p1.13.m13.1.1.1.1.1.2.2">ğ‘›</ci><ci id="S3.SS1.p1.13.m13.1.1.1.1.1.2.3.cmml" xref="S3.SS1.p1.13.m13.1.1.1.1.1.2.3">ğ‘</ci></apply><ci id="S3.SS1.p1.13.m13.1.1.1.1.1.3.cmml" xref="S3.SS1.p1.13.m13.1.1.1.1.1.3">ğ‘–</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.13.m13.1c">\mathcal{N}:=\{n^{q}_{i}\}</annotation></semantics></math> instead contains all the images geographically far from the query and is obtained following the symmetrically opposite approach.
Since GPS labels alone are not enough to determine whether an image actually depicts the same visual content (<em id="S3.SS1.p1.15.8" class="ltx_emph ltx_font_italic">e.g.</em>, close-by images could point in opposite directions), the current estimate of <math id="S3.SS1.p1.14.m14.1" class="ltx_Math" alttext="F_{\theta}" display="inline"><semantics id="S3.SS1.p1.14.m14.1a"><msub id="S3.SS1.p1.14.m14.1.1" xref="S3.SS1.p1.14.m14.1.1.cmml"><mi id="S3.SS1.p1.14.m14.1.1.2" xref="S3.SS1.p1.14.m14.1.1.2.cmml">F</mi><mi id="S3.SS1.p1.14.m14.1.1.3" xref="S3.SS1.p1.14.m14.1.1.3.cmml">Î¸</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.14.m14.1b"><apply id="S3.SS1.p1.14.m14.1.1.cmml" xref="S3.SS1.p1.14.m14.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.14.m14.1.1.1.cmml" xref="S3.SS1.p1.14.m14.1.1">subscript</csymbol><ci id="S3.SS1.p1.14.m14.1.1.2.cmml" xref="S3.SS1.p1.14.m14.1.1.2">ğ¹</ci><ci id="S3.SS1.p1.14.m14.1.1.3.cmml" xref="S3.SS1.p1.14.m14.1.1.3">ğœƒ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.14.m14.1c">F_{\theta}</annotation></semantics></math> is used to compute the Euclidean distance <math id="S3.SS1.p1.15.m15.2" class="ltx_Math" alttext="D_{\theta}(q,p^{q}_{i})" display="inline"><semantics id="S3.SS1.p1.15.m15.2a"><mrow id="S3.SS1.p1.15.m15.2.2" xref="S3.SS1.p1.15.m15.2.2.cmml"><msub id="S3.SS1.p1.15.m15.2.2.3" xref="S3.SS1.p1.15.m15.2.2.3.cmml"><mi id="S3.SS1.p1.15.m15.2.2.3.2" xref="S3.SS1.p1.15.m15.2.2.3.2.cmml">D</mi><mi id="S3.SS1.p1.15.m15.2.2.3.3" xref="S3.SS1.p1.15.m15.2.2.3.3.cmml">Î¸</mi></msub><mo lspace="0em" rspace="0em" id="S3.SS1.p1.15.m15.2.2.2" xref="S3.SS1.p1.15.m15.2.2.2.cmml">â€‹</mo><mrow id="S3.SS1.p1.15.m15.2.2.1.1" xref="S3.SS1.p1.15.m15.2.2.1.2.cmml"><mo stretchy="false" id="S3.SS1.p1.15.m15.2.2.1.1.2" xref="S3.SS1.p1.15.m15.2.2.1.2.cmml">(</mo><mi id="S3.SS1.p1.15.m15.1.1" xref="S3.SS1.p1.15.m15.1.1.cmml">q</mi><mo id="S3.SS1.p1.15.m15.2.2.1.1.3" xref="S3.SS1.p1.15.m15.2.2.1.2.cmml">,</mo><msubsup id="S3.SS1.p1.15.m15.2.2.1.1.1" xref="S3.SS1.p1.15.m15.2.2.1.1.1.cmml"><mi id="S3.SS1.p1.15.m15.2.2.1.1.1.2.2" xref="S3.SS1.p1.15.m15.2.2.1.1.1.2.2.cmml">p</mi><mi id="S3.SS1.p1.15.m15.2.2.1.1.1.3" xref="S3.SS1.p1.15.m15.2.2.1.1.1.3.cmml">i</mi><mi id="S3.SS1.p1.15.m15.2.2.1.1.1.2.3" xref="S3.SS1.p1.15.m15.2.2.1.1.1.2.3.cmml">q</mi></msubsup><mo stretchy="false" id="S3.SS1.p1.15.m15.2.2.1.1.4" xref="S3.SS1.p1.15.m15.2.2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.15.m15.2b"><apply id="S3.SS1.p1.15.m15.2.2.cmml" xref="S3.SS1.p1.15.m15.2.2"><times id="S3.SS1.p1.15.m15.2.2.2.cmml" xref="S3.SS1.p1.15.m15.2.2.2"></times><apply id="S3.SS1.p1.15.m15.2.2.3.cmml" xref="S3.SS1.p1.15.m15.2.2.3"><csymbol cd="ambiguous" id="S3.SS1.p1.15.m15.2.2.3.1.cmml" xref="S3.SS1.p1.15.m15.2.2.3">subscript</csymbol><ci id="S3.SS1.p1.15.m15.2.2.3.2.cmml" xref="S3.SS1.p1.15.m15.2.2.3.2">ğ·</ci><ci id="S3.SS1.p1.15.m15.2.2.3.3.cmml" xref="S3.SS1.p1.15.m15.2.2.3.3">ğœƒ</ci></apply><interval closure="open" id="S3.SS1.p1.15.m15.2.2.1.2.cmml" xref="S3.SS1.p1.15.m15.2.2.1.1"><ci id="S3.SS1.p1.15.m15.1.1.cmml" xref="S3.SS1.p1.15.m15.1.1">ğ‘</ci><apply id="S3.SS1.p1.15.m15.2.2.1.1.1.cmml" xref="S3.SS1.p1.15.m15.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.15.m15.2.2.1.1.1.1.cmml" xref="S3.SS1.p1.15.m15.2.2.1.1.1">subscript</csymbol><apply id="S3.SS1.p1.15.m15.2.2.1.1.1.2.cmml" xref="S3.SS1.p1.15.m15.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.15.m15.2.2.1.1.1.2.1.cmml" xref="S3.SS1.p1.15.m15.2.2.1.1.1">superscript</csymbol><ci id="S3.SS1.p1.15.m15.2.2.1.1.1.2.2.cmml" xref="S3.SS1.p1.15.m15.2.2.1.1.1.2.2">ğ‘</ci><ci id="S3.SS1.p1.15.m15.2.2.1.1.1.2.3.cmml" xref="S3.SS1.p1.15.m15.2.2.1.1.1.2.3">ğ‘</ci></apply><ci id="S3.SS1.p1.15.m15.2.2.1.1.1.3.cmml" xref="S3.SS1.p1.15.m15.2.2.1.1.1.3">ğ‘–</ci></apply></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.15.m15.2c">D_{\theta}(q,p^{q}_{i})</annotation></semantics></math>.
Thus, the candidate with the highest probability of being a true positive is selected according to the criteria</p>
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.2" class="ltx_Math" alttext="\tilde{p}^{q}=\underset{p^{q}_{i}\in\,\mathcal{P}}{\text{argmin}}~{}D_{\theta}\left(q,p^{q}_{i}\right)." display="block"><semantics id="S3.E1.m1.2a"><mrow id="S3.E1.m1.2.2.1" xref="S3.E1.m1.2.2.1.1.cmml"><mrow id="S3.E1.m1.2.2.1.1" xref="S3.E1.m1.2.2.1.1.cmml"><msup id="S3.E1.m1.2.2.1.1.3" xref="S3.E1.m1.2.2.1.1.3.cmml"><mover accent="true" id="S3.E1.m1.2.2.1.1.3.2" xref="S3.E1.m1.2.2.1.1.3.2.cmml"><mi id="S3.E1.m1.2.2.1.1.3.2.2" xref="S3.E1.m1.2.2.1.1.3.2.2.cmml">p</mi><mo id="S3.E1.m1.2.2.1.1.3.2.1" xref="S3.E1.m1.2.2.1.1.3.2.1.cmml">~</mo></mover><mi id="S3.E1.m1.2.2.1.1.3.3" xref="S3.E1.m1.2.2.1.1.3.3.cmml">q</mi></msup><mo id="S3.E1.m1.2.2.1.1.2" xref="S3.E1.m1.2.2.1.1.2.cmml">=</mo><mrow id="S3.E1.m1.2.2.1.1.1" xref="S3.E1.m1.2.2.1.1.1.cmml"><munder accentunder="true" id="S3.E1.m1.2.2.1.1.1.3" xref="S3.E1.m1.2.2.1.1.1.3.cmml"><mtext id="S3.E1.m1.2.2.1.1.1.3.2" xref="S3.E1.m1.2.2.1.1.1.3.2a.cmml">argmin</mtext><mrow id="S3.E1.m1.2.2.1.1.1.3.1" xref="S3.E1.m1.2.2.1.1.1.3.1.cmml"><msubsup id="S3.E1.m1.2.2.1.1.1.3.1.2" xref="S3.E1.m1.2.2.1.1.1.3.1.2.cmml"><mi id="S3.E1.m1.2.2.1.1.1.3.1.2.2.2" xref="S3.E1.m1.2.2.1.1.1.3.1.2.2.2.cmml">p</mi><mi id="S3.E1.m1.2.2.1.1.1.3.1.2.3" xref="S3.E1.m1.2.2.1.1.1.3.1.2.3.cmml">i</mi><mi id="S3.E1.m1.2.2.1.1.1.3.1.2.2.3" xref="S3.E1.m1.2.2.1.1.1.3.1.2.2.3.cmml">q</mi></msubsup><mo rspace="0.448em" id="S3.E1.m1.2.2.1.1.1.3.1.1" xref="S3.E1.m1.2.2.1.1.1.3.1.1.cmml">âˆˆ</mo><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.2.2.1.1.1.3.1.3" xref="S3.E1.m1.2.2.1.1.1.3.1.3.cmml">ğ’«</mi></mrow></munder><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.1.1.1.2" xref="S3.E1.m1.2.2.1.1.1.2.cmml">â€‹</mo><msub id="S3.E1.m1.2.2.1.1.1.4" xref="S3.E1.m1.2.2.1.1.1.4.cmml"><mi id="S3.E1.m1.2.2.1.1.1.4.2" xref="S3.E1.m1.2.2.1.1.1.4.2.cmml">D</mi><mi id="S3.E1.m1.2.2.1.1.1.4.3" xref="S3.E1.m1.2.2.1.1.1.4.3.cmml">Î¸</mi></msub><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.1.1.1.2a" xref="S3.E1.m1.2.2.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E1.m1.2.2.1.1.1.1.1" xref="S3.E1.m1.2.2.1.1.1.1.2.cmml"><mo id="S3.E1.m1.2.2.1.1.1.1.1.2" xref="S3.E1.m1.2.2.1.1.1.1.2.cmml">(</mo><mi id="S3.E1.m1.1.1" xref="S3.E1.m1.1.1.cmml">q</mi><mo id="S3.E1.m1.2.2.1.1.1.1.1.3" xref="S3.E1.m1.2.2.1.1.1.1.2.cmml">,</mo><msubsup id="S3.E1.m1.2.2.1.1.1.1.1.1" xref="S3.E1.m1.2.2.1.1.1.1.1.1.cmml"><mi id="S3.E1.m1.2.2.1.1.1.1.1.1.2.2" xref="S3.E1.m1.2.2.1.1.1.1.1.1.2.2.cmml">p</mi><mi id="S3.E1.m1.2.2.1.1.1.1.1.1.3" xref="S3.E1.m1.2.2.1.1.1.1.1.1.3.cmml">i</mi><mi id="S3.E1.m1.2.2.1.1.1.1.1.1.2.3" xref="S3.E1.m1.2.2.1.1.1.1.1.1.2.3.cmml">q</mi></msubsup><mo id="S3.E1.m1.2.2.1.1.1.1.1.4" xref="S3.E1.m1.2.2.1.1.1.1.2.cmml">)</mo></mrow></mrow></mrow><mo lspace="0em" id="S3.E1.m1.2.2.1.2" xref="S3.E1.m1.2.2.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.2b"><apply id="S3.E1.m1.2.2.1.1.cmml" xref="S3.E1.m1.2.2.1"><eq id="S3.E1.m1.2.2.1.1.2.cmml" xref="S3.E1.m1.2.2.1.1.2"></eq><apply id="S3.E1.m1.2.2.1.1.3.cmml" xref="S3.E1.m1.2.2.1.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.3.1.cmml" xref="S3.E1.m1.2.2.1.1.3">superscript</csymbol><apply id="S3.E1.m1.2.2.1.1.3.2.cmml" xref="S3.E1.m1.2.2.1.1.3.2"><ci id="S3.E1.m1.2.2.1.1.3.2.1.cmml" xref="S3.E1.m1.2.2.1.1.3.2.1">~</ci><ci id="S3.E1.m1.2.2.1.1.3.2.2.cmml" xref="S3.E1.m1.2.2.1.1.3.2.2">ğ‘</ci></apply><ci id="S3.E1.m1.2.2.1.1.3.3.cmml" xref="S3.E1.m1.2.2.1.1.3.3">ğ‘</ci></apply><apply id="S3.E1.m1.2.2.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.1"><times id="S3.E1.m1.2.2.1.1.1.2.cmml" xref="S3.E1.m1.2.2.1.1.1.2"></times><apply id="S3.E1.m1.2.2.1.1.1.3.cmml" xref="S3.E1.m1.2.2.1.1.1.3"><apply id="S3.E1.m1.2.2.1.1.1.3.1.cmml" xref="S3.E1.m1.2.2.1.1.1.3.1"><in id="S3.E1.m1.2.2.1.1.1.3.1.1.cmml" xref="S3.E1.m1.2.2.1.1.1.3.1.1"></in><apply id="S3.E1.m1.2.2.1.1.1.3.1.2.cmml" xref="S3.E1.m1.2.2.1.1.1.3.1.2"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.1.3.1.2.1.cmml" xref="S3.E1.m1.2.2.1.1.1.3.1.2">subscript</csymbol><apply id="S3.E1.m1.2.2.1.1.1.3.1.2.2.cmml" xref="S3.E1.m1.2.2.1.1.1.3.1.2"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.1.3.1.2.2.1.cmml" xref="S3.E1.m1.2.2.1.1.1.3.1.2">superscript</csymbol><ci id="S3.E1.m1.2.2.1.1.1.3.1.2.2.2.cmml" xref="S3.E1.m1.2.2.1.1.1.3.1.2.2.2">ğ‘</ci><ci id="S3.E1.m1.2.2.1.1.1.3.1.2.2.3.cmml" xref="S3.E1.m1.2.2.1.1.1.3.1.2.2.3">ğ‘</ci></apply><ci id="S3.E1.m1.2.2.1.1.1.3.1.2.3.cmml" xref="S3.E1.m1.2.2.1.1.1.3.1.2.3">ğ‘–</ci></apply><ci id="S3.E1.m1.2.2.1.1.1.3.1.3.cmml" xref="S3.E1.m1.2.2.1.1.1.3.1.3">ğ’«</ci></apply><ci id="S3.E1.m1.2.2.1.1.1.3.2a.cmml" xref="S3.E1.m1.2.2.1.1.1.3.2"><mtext id="S3.E1.m1.2.2.1.1.1.3.2.cmml" xref="S3.E1.m1.2.2.1.1.1.3.2">argmin</mtext></ci></apply><apply id="S3.E1.m1.2.2.1.1.1.4.cmml" xref="S3.E1.m1.2.2.1.1.1.4"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.1.4.1.cmml" xref="S3.E1.m1.2.2.1.1.1.4">subscript</csymbol><ci id="S3.E1.m1.2.2.1.1.1.4.2.cmml" xref="S3.E1.m1.2.2.1.1.1.4.2">ğ·</ci><ci id="S3.E1.m1.2.2.1.1.1.4.3.cmml" xref="S3.E1.m1.2.2.1.1.1.4.3">ğœƒ</ci></apply><interval closure="open" id="S3.E1.m1.2.2.1.1.1.1.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1"><ci id="S3.E1.m1.1.1.cmml" xref="S3.E1.m1.1.1">ğ‘</ci><apply id="S3.E1.m1.2.2.1.1.1.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1">subscript</csymbol><apply id="S3.E1.m1.2.2.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.1.1.1.1.2.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1">superscript</csymbol><ci id="S3.E1.m1.2.2.1.1.1.1.1.1.2.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.2.2">ğ‘</ci><ci id="S3.E1.m1.2.2.1.1.1.1.1.1.2.3.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.2.3">ğ‘</ci></apply><ci id="S3.E1.m1.2.2.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.3">ğ‘–</ci></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.2c">\tilde{p}^{q}=\underset{p^{q}_{i}\in\,\mathcal{P}}{\text{argmin}}~{}D_{\theta}\left(q,p^{q}_{i}\right).</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.p1.18" class="ltx_p">On the other hand, hard negatives are selected as those who are closest to the query in the embedding space (therefore visually similar), while still being geographically far.</p>
<table id="S3.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E2.m1.2" class="ltx_Math" alttext="\tilde{n}^{q}=\underset{n^{q}_{i}\in\,\mathcal{N}}{\text{argmin}}~{}D_{\theta}\left(q,n^{q}_{i}\right)." display="block"><semantics id="S3.E2.m1.2a"><mrow id="S3.E2.m1.2.2.1" xref="S3.E2.m1.2.2.1.1.cmml"><mrow id="S3.E2.m1.2.2.1.1" xref="S3.E2.m1.2.2.1.1.cmml"><msup id="S3.E2.m1.2.2.1.1.3" xref="S3.E2.m1.2.2.1.1.3.cmml"><mover accent="true" id="S3.E2.m1.2.2.1.1.3.2" xref="S3.E2.m1.2.2.1.1.3.2.cmml"><mi id="S3.E2.m1.2.2.1.1.3.2.2" xref="S3.E2.m1.2.2.1.1.3.2.2.cmml">n</mi><mo id="S3.E2.m1.2.2.1.1.3.2.1" xref="S3.E2.m1.2.2.1.1.3.2.1.cmml">~</mo></mover><mi id="S3.E2.m1.2.2.1.1.3.3" xref="S3.E2.m1.2.2.1.1.3.3.cmml">q</mi></msup><mo id="S3.E2.m1.2.2.1.1.2" xref="S3.E2.m1.2.2.1.1.2.cmml">=</mo><mrow id="S3.E2.m1.2.2.1.1.1" xref="S3.E2.m1.2.2.1.1.1.cmml"><munder accentunder="true" id="S3.E2.m1.2.2.1.1.1.3" xref="S3.E2.m1.2.2.1.1.1.3.cmml"><mtext id="S3.E2.m1.2.2.1.1.1.3.2" xref="S3.E2.m1.2.2.1.1.1.3.2a.cmml">argmin</mtext><mrow id="S3.E2.m1.2.2.1.1.1.3.1" xref="S3.E2.m1.2.2.1.1.1.3.1.cmml"><msubsup id="S3.E2.m1.2.2.1.1.1.3.1.2" xref="S3.E2.m1.2.2.1.1.1.3.1.2.cmml"><mi id="S3.E2.m1.2.2.1.1.1.3.1.2.2.2" xref="S3.E2.m1.2.2.1.1.1.3.1.2.2.2.cmml">n</mi><mi id="S3.E2.m1.2.2.1.1.1.3.1.2.3" xref="S3.E2.m1.2.2.1.1.1.3.1.2.3.cmml">i</mi><mi id="S3.E2.m1.2.2.1.1.1.3.1.2.2.3" xref="S3.E2.m1.2.2.1.1.1.3.1.2.2.3.cmml">q</mi></msubsup><mo rspace="0.448em" id="S3.E2.m1.2.2.1.1.1.3.1.1" xref="S3.E2.m1.2.2.1.1.1.3.1.1.cmml">âˆˆ</mo><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.2.2.1.1.1.3.1.3" xref="S3.E2.m1.2.2.1.1.1.3.1.3.cmml">ğ’©</mi></mrow></munder><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.1.2" xref="S3.E2.m1.2.2.1.1.1.2.cmml">â€‹</mo><msub id="S3.E2.m1.2.2.1.1.1.4" xref="S3.E2.m1.2.2.1.1.1.4.cmml"><mi id="S3.E2.m1.2.2.1.1.1.4.2" xref="S3.E2.m1.2.2.1.1.1.4.2.cmml">D</mi><mi id="S3.E2.m1.2.2.1.1.1.4.3" xref="S3.E2.m1.2.2.1.1.1.4.3.cmml">Î¸</mi></msub><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.1.2a" xref="S3.E2.m1.2.2.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E2.m1.2.2.1.1.1.1.1" xref="S3.E2.m1.2.2.1.1.1.1.2.cmml"><mo id="S3.E2.m1.2.2.1.1.1.1.1.2" xref="S3.E2.m1.2.2.1.1.1.1.2.cmml">(</mo><mi id="S3.E2.m1.1.1" xref="S3.E2.m1.1.1.cmml">q</mi><mo id="S3.E2.m1.2.2.1.1.1.1.1.3" xref="S3.E2.m1.2.2.1.1.1.1.2.cmml">,</mo><msubsup id="S3.E2.m1.2.2.1.1.1.1.1.1" xref="S3.E2.m1.2.2.1.1.1.1.1.1.cmml"><mi id="S3.E2.m1.2.2.1.1.1.1.1.1.2.2" xref="S3.E2.m1.2.2.1.1.1.1.1.1.2.2.cmml">n</mi><mi id="S3.E2.m1.2.2.1.1.1.1.1.1.3" xref="S3.E2.m1.2.2.1.1.1.1.1.1.3.cmml">i</mi><mi id="S3.E2.m1.2.2.1.1.1.1.1.1.2.3" xref="S3.E2.m1.2.2.1.1.1.1.1.1.2.3.cmml">q</mi></msubsup><mo id="S3.E2.m1.2.2.1.1.1.1.1.4" xref="S3.E2.m1.2.2.1.1.1.1.2.cmml">)</mo></mrow></mrow></mrow><mo lspace="0em" id="S3.E2.m1.2.2.1.2" xref="S3.E2.m1.2.2.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.2b"><apply id="S3.E2.m1.2.2.1.1.cmml" xref="S3.E2.m1.2.2.1"><eq id="S3.E2.m1.2.2.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.2"></eq><apply id="S3.E2.m1.2.2.1.1.3.cmml" xref="S3.E2.m1.2.2.1.1.3"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.3.1.cmml" xref="S3.E2.m1.2.2.1.1.3">superscript</csymbol><apply id="S3.E2.m1.2.2.1.1.3.2.cmml" xref="S3.E2.m1.2.2.1.1.3.2"><ci id="S3.E2.m1.2.2.1.1.3.2.1.cmml" xref="S3.E2.m1.2.2.1.1.3.2.1">~</ci><ci id="S3.E2.m1.2.2.1.1.3.2.2.cmml" xref="S3.E2.m1.2.2.1.1.3.2.2">ğ‘›</ci></apply><ci id="S3.E2.m1.2.2.1.1.3.3.cmml" xref="S3.E2.m1.2.2.1.1.3.3">ğ‘</ci></apply><apply id="S3.E2.m1.2.2.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1"><times id="S3.E2.m1.2.2.1.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.1.2"></times><apply id="S3.E2.m1.2.2.1.1.1.3.cmml" xref="S3.E2.m1.2.2.1.1.1.3"><apply id="S3.E2.m1.2.2.1.1.1.3.1.cmml" xref="S3.E2.m1.2.2.1.1.1.3.1"><in id="S3.E2.m1.2.2.1.1.1.3.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1.3.1.1"></in><apply id="S3.E2.m1.2.2.1.1.1.3.1.2.cmml" xref="S3.E2.m1.2.2.1.1.1.3.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.1.3.1.2.1.cmml" xref="S3.E2.m1.2.2.1.1.1.3.1.2">subscript</csymbol><apply id="S3.E2.m1.2.2.1.1.1.3.1.2.2.cmml" xref="S3.E2.m1.2.2.1.1.1.3.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.1.3.1.2.2.1.cmml" xref="S3.E2.m1.2.2.1.1.1.3.1.2">superscript</csymbol><ci id="S3.E2.m1.2.2.1.1.1.3.1.2.2.2.cmml" xref="S3.E2.m1.2.2.1.1.1.3.1.2.2.2">ğ‘›</ci><ci id="S3.E2.m1.2.2.1.1.1.3.1.2.2.3.cmml" xref="S3.E2.m1.2.2.1.1.1.3.1.2.2.3">ğ‘</ci></apply><ci id="S3.E2.m1.2.2.1.1.1.3.1.2.3.cmml" xref="S3.E2.m1.2.2.1.1.1.3.1.2.3">ğ‘–</ci></apply><ci id="S3.E2.m1.2.2.1.1.1.3.1.3.cmml" xref="S3.E2.m1.2.2.1.1.1.3.1.3">ğ’©</ci></apply><ci id="S3.E2.m1.2.2.1.1.1.3.2a.cmml" xref="S3.E2.m1.2.2.1.1.1.3.2"><mtext id="S3.E2.m1.2.2.1.1.1.3.2.cmml" xref="S3.E2.m1.2.2.1.1.1.3.2">argmin</mtext></ci></apply><apply id="S3.E2.m1.2.2.1.1.1.4.cmml" xref="S3.E2.m1.2.2.1.1.1.4"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.1.4.1.cmml" xref="S3.E2.m1.2.2.1.1.1.4">subscript</csymbol><ci id="S3.E2.m1.2.2.1.1.1.4.2.cmml" xref="S3.E2.m1.2.2.1.1.1.4.2">ğ·</ci><ci id="S3.E2.m1.2.2.1.1.1.4.3.cmml" xref="S3.E2.m1.2.2.1.1.1.4.3">ğœƒ</ci></apply><interval closure="open" id="S3.E2.m1.2.2.1.1.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1"><ci id="S3.E2.m1.1.1.cmml" xref="S3.E2.m1.1.1">ğ‘</ci><apply id="S3.E2.m1.2.2.1.1.1.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1">subscript</csymbol><apply id="S3.E2.m1.2.2.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.1.1.1.1.2.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1">superscript</csymbol><ci id="S3.E2.m1.2.2.1.1.1.1.1.1.2.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.2.2">ğ‘›</ci><ci id="S3.E2.m1.2.2.1.1.1.1.1.1.2.3.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.2.3">ğ‘</ci></apply><ci id="S3.E2.m1.2.2.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.3">ğ‘–</ci></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.2c">\tilde{n}^{q}=\underset{n^{q}_{i}\in\,\mathcal{N}}{\text{argmin}}~{}D_{\theta}\left(q,n^{q}_{i}\right).</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.p1.16" class="ltx_p">Finally, the loss for the selected triplet <math id="S3.SS1.p1.16.m1.3" class="ltx_Math" alttext="(q,\tilde{p}^{q},\tilde{n}^{q})" display="inline"><semantics id="S3.SS1.p1.16.m1.3a"><mrow id="S3.SS1.p1.16.m1.3.3.2" xref="S3.SS1.p1.16.m1.3.3.3.cmml"><mo stretchy="false" id="S3.SS1.p1.16.m1.3.3.2.3" xref="S3.SS1.p1.16.m1.3.3.3.cmml">(</mo><mi id="S3.SS1.p1.16.m1.1.1" xref="S3.SS1.p1.16.m1.1.1.cmml">q</mi><mo id="S3.SS1.p1.16.m1.3.3.2.4" xref="S3.SS1.p1.16.m1.3.3.3.cmml">,</mo><msup id="S3.SS1.p1.16.m1.2.2.1.1" xref="S3.SS1.p1.16.m1.2.2.1.1.cmml"><mover accent="true" id="S3.SS1.p1.16.m1.2.2.1.1.2" xref="S3.SS1.p1.16.m1.2.2.1.1.2.cmml"><mi id="S3.SS1.p1.16.m1.2.2.1.1.2.2" xref="S3.SS1.p1.16.m1.2.2.1.1.2.2.cmml">p</mi><mo id="S3.SS1.p1.16.m1.2.2.1.1.2.1" xref="S3.SS1.p1.16.m1.2.2.1.1.2.1.cmml">~</mo></mover><mi id="S3.SS1.p1.16.m1.2.2.1.1.3" xref="S3.SS1.p1.16.m1.2.2.1.1.3.cmml">q</mi></msup><mo id="S3.SS1.p1.16.m1.3.3.2.5" xref="S3.SS1.p1.16.m1.3.3.3.cmml">,</mo><msup id="S3.SS1.p1.16.m1.3.3.2.2" xref="S3.SS1.p1.16.m1.3.3.2.2.cmml"><mover accent="true" id="S3.SS1.p1.16.m1.3.3.2.2.2" xref="S3.SS1.p1.16.m1.3.3.2.2.2.cmml"><mi id="S3.SS1.p1.16.m1.3.3.2.2.2.2" xref="S3.SS1.p1.16.m1.3.3.2.2.2.2.cmml">n</mi><mo id="S3.SS1.p1.16.m1.3.3.2.2.2.1" xref="S3.SS1.p1.16.m1.3.3.2.2.2.1.cmml">~</mo></mover><mi id="S3.SS1.p1.16.m1.3.3.2.2.3" xref="S3.SS1.p1.16.m1.3.3.2.2.3.cmml">q</mi></msup><mo stretchy="false" id="S3.SS1.p1.16.m1.3.3.2.6" xref="S3.SS1.p1.16.m1.3.3.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.16.m1.3b"><vector id="S3.SS1.p1.16.m1.3.3.3.cmml" xref="S3.SS1.p1.16.m1.3.3.2"><ci id="S3.SS1.p1.16.m1.1.1.cmml" xref="S3.SS1.p1.16.m1.1.1">ğ‘</ci><apply id="S3.SS1.p1.16.m1.2.2.1.1.cmml" xref="S3.SS1.p1.16.m1.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.16.m1.2.2.1.1.1.cmml" xref="S3.SS1.p1.16.m1.2.2.1.1">superscript</csymbol><apply id="S3.SS1.p1.16.m1.2.2.1.1.2.cmml" xref="S3.SS1.p1.16.m1.2.2.1.1.2"><ci id="S3.SS1.p1.16.m1.2.2.1.1.2.1.cmml" xref="S3.SS1.p1.16.m1.2.2.1.1.2.1">~</ci><ci id="S3.SS1.p1.16.m1.2.2.1.1.2.2.cmml" xref="S3.SS1.p1.16.m1.2.2.1.1.2.2">ğ‘</ci></apply><ci id="S3.SS1.p1.16.m1.2.2.1.1.3.cmml" xref="S3.SS1.p1.16.m1.2.2.1.1.3">ğ‘</ci></apply><apply id="S3.SS1.p1.16.m1.3.3.2.2.cmml" xref="S3.SS1.p1.16.m1.3.3.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.16.m1.3.3.2.2.1.cmml" xref="S3.SS1.p1.16.m1.3.3.2.2">superscript</csymbol><apply id="S3.SS1.p1.16.m1.3.3.2.2.2.cmml" xref="S3.SS1.p1.16.m1.3.3.2.2.2"><ci id="S3.SS1.p1.16.m1.3.3.2.2.2.1.cmml" xref="S3.SS1.p1.16.m1.3.3.2.2.2.1">~</ci><ci id="S3.SS1.p1.16.m1.3.3.2.2.2.2.cmml" xref="S3.SS1.p1.16.m1.3.3.2.2.2.2">ğ‘›</ci></apply><ci id="S3.SS1.p1.16.m1.3.3.2.2.3.cmml" xref="S3.SS1.p1.16.m1.3.3.2.2.3">ğ‘</ci></apply></vector></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.16.m1.3c">(q,\tilde{p}^{q},\tilde{n}^{q})</annotation></semantics></math> is</p>
<table id="S3.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E3.m1.5" class="ltx_Math" alttext="\mathcal{L}_{\theta}=\max\left(D^{2}_{\theta}\left(q,\tilde{p}^{q}\right)-D^{2}_{\theta}\left(q,\tilde{n}^{q}\right)+m,0\right)," display="block"><semantics id="S3.E3.m1.5a"><mrow id="S3.E3.m1.5.5.1" xref="S3.E3.m1.5.5.1.1.cmml"><mrow id="S3.E3.m1.5.5.1.1" xref="S3.E3.m1.5.5.1.1.cmml"><msub id="S3.E3.m1.5.5.1.1.3" xref="S3.E3.m1.5.5.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.5.5.1.1.3.2" xref="S3.E3.m1.5.5.1.1.3.2.cmml">â„’</mi><mi id="S3.E3.m1.5.5.1.1.3.3" xref="S3.E3.m1.5.5.1.1.3.3.cmml">Î¸</mi></msub><mo id="S3.E3.m1.5.5.1.1.2" xref="S3.E3.m1.5.5.1.1.2.cmml">=</mo><mrow id="S3.E3.m1.5.5.1.1.1.1" xref="S3.E3.m1.5.5.1.1.1.2.cmml"><mi id="S3.E3.m1.3.3" xref="S3.E3.m1.3.3.cmml">max</mi><mo id="S3.E3.m1.5.5.1.1.1.1a" xref="S3.E3.m1.5.5.1.1.1.2.cmml">â¡</mo><mrow id="S3.E3.m1.5.5.1.1.1.1.1" xref="S3.E3.m1.5.5.1.1.1.2.cmml"><mo id="S3.E3.m1.5.5.1.1.1.1.1.2" xref="S3.E3.m1.5.5.1.1.1.2.cmml">(</mo><mrow id="S3.E3.m1.5.5.1.1.1.1.1.1" xref="S3.E3.m1.5.5.1.1.1.1.1.1.cmml"><mrow id="S3.E3.m1.5.5.1.1.1.1.1.1.2" xref="S3.E3.m1.5.5.1.1.1.1.1.1.2.cmml"><mrow id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.cmml"><msubsup id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.3.2.2" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.3.2.2.cmml">D</mi><mi id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.3.3" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.3.3.cmml">Î¸</mi><mn id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.3.2.3" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.3.2.3.cmml">2</mn></msubsup><mo lspace="0em" rspace="0em" id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.2" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.2.cmml"><mo id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.2.cmml">(</mo><mi id="S3.E3.m1.1.1" xref="S3.E3.m1.1.1.cmml">q</mi><mo id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.2.cmml">,</mo><msup id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.cmml"><mover accent="true" id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.2.2" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml">p</mi><mo id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.2.1" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.2.1.cmml">~</mo></mover><mi id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.3.cmml">q</mi></msup><mo id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.4" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S3.E3.m1.5.5.1.1.1.1.1.1.2.3" xref="S3.E3.m1.5.5.1.1.1.1.1.1.2.3.cmml">âˆ’</mo><mrow id="S3.E3.m1.5.5.1.1.1.1.1.1.2.2" xref="S3.E3.m1.5.5.1.1.1.1.1.1.2.2.cmml"><msubsup id="S3.E3.m1.5.5.1.1.1.1.1.1.2.2.3" xref="S3.E3.m1.5.5.1.1.1.1.1.1.2.2.3.cmml"><mi id="S3.E3.m1.5.5.1.1.1.1.1.1.2.2.3.2.2" xref="S3.E3.m1.5.5.1.1.1.1.1.1.2.2.3.2.2.cmml">D</mi><mi id="S3.E3.m1.5.5.1.1.1.1.1.1.2.2.3.3" xref="S3.E3.m1.5.5.1.1.1.1.1.1.2.2.3.3.cmml">Î¸</mi><mn id="S3.E3.m1.5.5.1.1.1.1.1.1.2.2.3.2.3" xref="S3.E3.m1.5.5.1.1.1.1.1.1.2.2.3.2.3.cmml">2</mn></msubsup><mo lspace="0em" rspace="0em" id="S3.E3.m1.5.5.1.1.1.1.1.1.2.2.2" xref="S3.E3.m1.5.5.1.1.1.1.1.1.2.2.2.cmml">â€‹</mo><mrow id="S3.E3.m1.5.5.1.1.1.1.1.1.2.2.1.1" xref="S3.E3.m1.5.5.1.1.1.1.1.1.2.2.1.2.cmml"><mo id="S3.E3.m1.5.5.1.1.1.1.1.1.2.2.1.1.2" xref="S3.E3.m1.5.5.1.1.1.1.1.1.2.2.1.2.cmml">(</mo><mi id="S3.E3.m1.2.2" xref="S3.E3.m1.2.2.cmml">q</mi><mo id="S3.E3.m1.5.5.1.1.1.1.1.1.2.2.1.1.3" xref="S3.E3.m1.5.5.1.1.1.1.1.1.2.2.1.2.cmml">,</mo><msup id="S3.E3.m1.5.5.1.1.1.1.1.1.2.2.1.1.1" xref="S3.E3.m1.5.5.1.1.1.1.1.1.2.2.1.1.1.cmml"><mover accent="true" id="S3.E3.m1.5.5.1.1.1.1.1.1.2.2.1.1.1.2" xref="S3.E3.m1.5.5.1.1.1.1.1.1.2.2.1.1.1.2.cmml"><mi id="S3.E3.m1.5.5.1.1.1.1.1.1.2.2.1.1.1.2.2" xref="S3.E3.m1.5.5.1.1.1.1.1.1.2.2.1.1.1.2.2.cmml">n</mi><mo id="S3.E3.m1.5.5.1.1.1.1.1.1.2.2.1.1.1.2.1" xref="S3.E3.m1.5.5.1.1.1.1.1.1.2.2.1.1.1.2.1.cmml">~</mo></mover><mi id="S3.E3.m1.5.5.1.1.1.1.1.1.2.2.1.1.1.3" xref="S3.E3.m1.5.5.1.1.1.1.1.1.2.2.1.1.1.3.cmml">q</mi></msup><mo id="S3.E3.m1.5.5.1.1.1.1.1.1.2.2.1.1.4" xref="S3.E3.m1.5.5.1.1.1.1.1.1.2.2.1.2.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E3.m1.5.5.1.1.1.1.1.1.3" xref="S3.E3.m1.5.5.1.1.1.1.1.1.3.cmml">+</mo><mi id="S3.E3.m1.5.5.1.1.1.1.1.1.4" xref="S3.E3.m1.5.5.1.1.1.1.1.1.4.cmml">m</mi></mrow><mo id="S3.E3.m1.5.5.1.1.1.1.1.3" xref="S3.E3.m1.5.5.1.1.1.2.cmml">,</mo><mn id="S3.E3.m1.4.4" xref="S3.E3.m1.4.4.cmml">0</mn><mo id="S3.E3.m1.5.5.1.1.1.1.1.4" xref="S3.E3.m1.5.5.1.1.1.2.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E3.m1.5.5.1.2" xref="S3.E3.m1.5.5.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.5b"><apply id="S3.E3.m1.5.5.1.1.cmml" xref="S3.E3.m1.5.5.1"><eq id="S3.E3.m1.5.5.1.1.2.cmml" xref="S3.E3.m1.5.5.1.1.2"></eq><apply id="S3.E3.m1.5.5.1.1.3.cmml" xref="S3.E3.m1.5.5.1.1.3"><csymbol cd="ambiguous" id="S3.E3.m1.5.5.1.1.3.1.cmml" xref="S3.E3.m1.5.5.1.1.3">subscript</csymbol><ci id="S3.E3.m1.5.5.1.1.3.2.cmml" xref="S3.E3.m1.5.5.1.1.3.2">â„’</ci><ci id="S3.E3.m1.5.5.1.1.3.3.cmml" xref="S3.E3.m1.5.5.1.1.3.3">ğœƒ</ci></apply><apply id="S3.E3.m1.5.5.1.1.1.2.cmml" xref="S3.E3.m1.5.5.1.1.1.1"><max id="S3.E3.m1.3.3.cmml" xref="S3.E3.m1.3.3"></max><apply id="S3.E3.m1.5.5.1.1.1.1.1.1.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1"><plus id="S3.E3.m1.5.5.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.3"></plus><apply id="S3.E3.m1.5.5.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.2"><minus id="S3.E3.m1.5.5.1.1.1.1.1.1.2.3.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.2.3"></minus><apply id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1"><times id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.2"></times><apply id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.3">subscript</csymbol><apply id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.3.2.1.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.3">superscript</csymbol><ci id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.3.2.2.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.3.2.2">ğ·</ci><cn type="integer" id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.3.2.3.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.3.2.3">2</cn></apply><ci id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.3.3">ğœƒ</ci></apply><interval closure="open" id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1"><ci id="S3.E3.m1.1.1.cmml" xref="S3.E3.m1.1.1">ğ‘</ci><apply id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1">superscript</csymbol><apply id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.2"><ci id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.2.1">~</ci><ci id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.2.2">ğ‘</ci></apply><ci id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.3">ğ‘</ci></apply></interval></apply><apply id="S3.E3.m1.5.5.1.1.1.1.1.1.2.2.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.2.2"><times id="S3.E3.m1.5.5.1.1.1.1.1.1.2.2.2.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.2.2.2"></times><apply id="S3.E3.m1.5.5.1.1.1.1.1.1.2.2.3.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.2.2.3"><csymbol cd="ambiguous" id="S3.E3.m1.5.5.1.1.1.1.1.1.2.2.3.1.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.2.2.3">subscript</csymbol><apply id="S3.E3.m1.5.5.1.1.1.1.1.1.2.2.3.2.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.2.2.3"><csymbol cd="ambiguous" id="S3.E3.m1.5.5.1.1.1.1.1.1.2.2.3.2.1.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.2.2.3">superscript</csymbol><ci id="S3.E3.m1.5.5.1.1.1.1.1.1.2.2.3.2.2.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.2.2.3.2.2">ğ·</ci><cn type="integer" id="S3.E3.m1.5.5.1.1.1.1.1.1.2.2.3.2.3.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.2.2.3.2.3">2</cn></apply><ci id="S3.E3.m1.5.5.1.1.1.1.1.1.2.2.3.3.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.2.2.3.3">ğœƒ</ci></apply><interval closure="open" id="S3.E3.m1.5.5.1.1.1.1.1.1.2.2.1.2.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.2.2.1.1"><ci id="S3.E3.m1.2.2.cmml" xref="S3.E3.m1.2.2">ğ‘</ci><apply id="S3.E3.m1.5.5.1.1.1.1.1.1.2.2.1.1.1.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.5.5.1.1.1.1.1.1.2.2.1.1.1.1.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.2.2.1.1.1">superscript</csymbol><apply id="S3.E3.m1.5.5.1.1.1.1.1.1.2.2.1.1.1.2.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.2.2.1.1.1.2"><ci id="S3.E3.m1.5.5.1.1.1.1.1.1.2.2.1.1.1.2.1.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.2.2.1.1.1.2.1">~</ci><ci id="S3.E3.m1.5.5.1.1.1.1.1.1.2.2.1.1.1.2.2.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.2.2.1.1.1.2.2">ğ‘›</ci></apply><ci id="S3.E3.m1.5.5.1.1.1.1.1.1.2.2.1.1.1.3.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.2.2.1.1.1.3">ğ‘</ci></apply></interval></apply></apply><ci id="S3.E3.m1.5.5.1.1.1.1.1.1.4.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.4">ğ‘š</ci></apply><cn type="integer" id="S3.E3.m1.4.4.cmml" xref="S3.E3.m1.4.4">0</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.5c">\mathcal{L}_{\theta}=\max\left(D^{2}_{\theta}\left(q,\tilde{p}^{q}\right)-D^{2}_{\theta}\left(q,\tilde{n}^{q}\right)+m,0\right),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.p1.17" class="ltx_p">where <math id="S3.SS1.p1.17.m1.1" class="ltx_Math" alttext="m" display="inline"><semantics id="S3.SS1.p1.17.m1.1a"><mi id="S3.SS1.p1.17.m1.1.1" xref="S3.SS1.p1.17.m1.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.17.m1.1b"><ci id="S3.SS1.p1.17.m1.1.1.cmml" xref="S3.SS1.p1.17.m1.1.1">ğ‘š</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.17.m1.1c">m</annotation></semantics></math> is the margin hyperparameter. 
<br class="ltx_break"></p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">Finally, while the above procedure (triplet loss with negative mining) is not the only way to train VPR models, its computational affordability makes it suitable for a federated learning scenario. On the contrary, latest methods that skip mining altogether either require to know the entire database surface area before starting training <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib10" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">10</span></a>]</cite>, or are computationally expensive due to large batch sizes <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib2" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2</span></a>, <a href="#bib.bib3" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">3</span></a>]</cite> or large models <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib39" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">39</span></a>]</cite>, both of which are unsuitable options within a federated scenario.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Federated Visual Place Recognition (FedVPR)</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">In this work, we consider a realistic scenario in which the goal is to build a VPR system that will be deployed to a set of clients. While it is expected that some data will be available to pre-train a model in a centralized fashion, in general, it is not easy to obtain large-scale annotated datasets for place recognition. As an example, while large datasets exist available for research purposes, they are usually scraped from Google Street View, which does not allow commercial usage, and collecting a dataset that covers large geographical areas independently is highly expensive. On the other hand, the clients to which the model is deployed are a convenient source of heterogeneous and relevant data, which are fundamental for training a robust feature extractor for the task at hand. However, in the spirit of Federated Learning, the clientâ€™s privacy must not be violated. Possible examples of the described scenario can be a company deploying a fleet of self-driving vehicles, wanting to improve the performances of its localization-and-mapping pipeline, a swarm of drones, or even general-purpose content-based image retrieval. We frame our analysis in this realistic scenario, demonstrating the criticalities of developing a distributed learning framework. <a href="#S3.F2" title="In 3 Method â€£ Collaborative Visual Place Recognition through Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">2</span></a> summarizes FedVPR.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para ltx_noindent">
<p id="S3.SS2.p2.11" class="ltx_p"><span id="S3.SS2.p2.11.1" class="ltx_text ltx_font_bold">Federated framework.</span> In the standard federated framework, a central server communicates with a set of clients <math id="S3.SS2.p2.1.m1.1" class="ltx_Math" alttext="\mathcal{C}" display="inline"><semantics id="S3.SS2.p2.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml">ğ’</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><ci id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1">ğ’</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">\mathcal{C}</annotation></semantics></math> over <math id="S3.SS2.p2.2.m2.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S3.SS2.p2.2.m2.1a"><mi id="S3.SS2.p2.2.m2.1.1" xref="S3.SS2.p2.2.m2.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m2.1b"><ci id="S3.SS2.p2.2.m2.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.m2.1c">T</annotation></semantics></math> communication rounds. Clients commonly are edge devices, <em id="S3.SS2.p2.11.2" class="ltx_emph ltx_font_italic">e.g.</em>, smartphones, autonomous vehicles, and IoT sensors. In our setting, each client <math id="S3.SS2.p2.3.m3.1" class="ltx_Math" alttext="k\in\mathcal{K}" display="inline"><semantics id="S3.SS2.p2.3.m3.1a"><mrow id="S3.SS2.p2.3.m3.1.1" xref="S3.SS2.p2.3.m3.1.1.cmml"><mi id="S3.SS2.p2.3.m3.1.1.2" xref="S3.SS2.p2.3.m3.1.1.2.cmml">k</mi><mo id="S3.SS2.p2.3.m3.1.1.1" xref="S3.SS2.p2.3.m3.1.1.1.cmml">âˆˆ</mo><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p2.3.m3.1.1.3" xref="S3.SS2.p2.3.m3.1.1.3.cmml">ğ’¦</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.3.m3.1b"><apply id="S3.SS2.p2.3.m3.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1"><in id="S3.SS2.p2.3.m3.1.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1.1"></in><ci id="S3.SS2.p2.3.m3.1.1.2.cmml" xref="S3.SS2.p2.3.m3.1.1.2">ğ‘˜</ci><ci id="S3.SS2.p2.3.m3.1.1.3.cmml" xref="S3.SS2.p2.3.m3.1.1.3">ğ’¦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.3.m3.1c">k\in\mathcal{K}</annotation></semantics></math> has access to a privacy-protected dataset <math id="S3.SS2.p2.4.m4.1" class="ltx_Math" alttext="\mathcal{D}_{k}" display="inline"><semantics id="S3.SS2.p2.4.m4.1a"><msub id="S3.SS2.p2.4.m4.1.1" xref="S3.SS2.p2.4.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p2.4.m4.1.1.2" xref="S3.SS2.p2.4.m4.1.1.2.cmml">ğ’Ÿ</mi><mi id="S3.SS2.p2.4.m4.1.1.3" xref="S3.SS2.p2.4.m4.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.4.m4.1b"><apply id="S3.SS2.p2.4.m4.1.1.cmml" xref="S3.SS2.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.4.m4.1.1.1.cmml" xref="S3.SS2.p2.4.m4.1.1">subscript</csymbol><ci id="S3.SS2.p2.4.m4.1.1.2.cmml" xref="S3.SS2.p2.4.m4.1.1.2">ğ’Ÿ</ci><ci id="S3.SS2.p2.4.m4.1.1.3.cmml" xref="S3.SS2.p2.4.m4.1.1.3">ğ‘˜</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.4.m4.1c">\mathcal{D}_{k}</annotation></semantics></math> made of <math id="S3.SS2.p2.5.m5.1" class="ltx_Math" alttext="N_{k}" display="inline"><semantics id="S3.SS2.p2.5.m5.1a"><msub id="S3.SS2.p2.5.m5.1.1" xref="S3.SS2.p2.5.m5.1.1.cmml"><mi id="S3.SS2.p2.5.m5.1.1.2" xref="S3.SS2.p2.5.m5.1.1.2.cmml">N</mi><mi id="S3.SS2.p2.5.m5.1.1.3" xref="S3.SS2.p2.5.m5.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.5.m5.1b"><apply id="S3.SS2.p2.5.m5.1.1.cmml" xref="S3.SS2.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.5.m5.1.1.1.cmml" xref="S3.SS2.p2.5.m5.1.1">subscript</csymbol><ci id="S3.SS2.p2.5.m5.1.1.2.cmml" xref="S3.SS2.p2.5.m5.1.1.2">ğ‘</ci><ci id="S3.SS2.p2.5.m5.1.1.3.cmml" xref="S3.SS2.p2.5.m5.1.1.3">ğ‘˜</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.5.m5.1c">N_{k}</annotation></semantics></math> images <math id="S3.SS2.p2.6.m6.1" class="ltx_Math" alttext="x\in\mathbb{X}" display="inline"><semantics id="S3.SS2.p2.6.m6.1a"><mrow id="S3.SS2.p2.6.m6.1.1" xref="S3.SS2.p2.6.m6.1.1.cmml"><mi id="S3.SS2.p2.6.m6.1.1.2" xref="S3.SS2.p2.6.m6.1.1.2.cmml">x</mi><mo id="S3.SS2.p2.6.m6.1.1.1" xref="S3.SS2.p2.6.m6.1.1.1.cmml">âˆˆ</mo><mi id="S3.SS2.p2.6.m6.1.1.3" xref="S3.SS2.p2.6.m6.1.1.3.cmml">ğ•</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.6.m6.1b"><apply id="S3.SS2.p2.6.m6.1.1.cmml" xref="S3.SS2.p2.6.m6.1.1"><in id="S3.SS2.p2.6.m6.1.1.1.cmml" xref="S3.SS2.p2.6.m6.1.1.1"></in><ci id="S3.SS2.p2.6.m6.1.1.2.cmml" xref="S3.SS2.p2.6.m6.1.1.2">ğ‘¥</ci><ci id="S3.SS2.p2.6.m6.1.1.3.cmml" xref="S3.SS2.p2.6.m6.1.1.3">ğ•</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.6.m6.1c">x\in\mathbb{X}</annotation></semantics></math> associated with a GPS location. The training goal is to learn a global shared model <math id="S3.SS2.p2.7.m7.1" class="ltx_Math" alttext="F_{\theta}:\mathbb{X}\rightarrow\mathbb{D}" display="inline"><semantics id="S3.SS2.p2.7.m7.1a"><mrow id="S3.SS2.p2.7.m7.1.1" xref="S3.SS2.p2.7.m7.1.1.cmml"><msub id="S3.SS2.p2.7.m7.1.1.2" xref="S3.SS2.p2.7.m7.1.1.2.cmml"><mi id="S3.SS2.p2.7.m7.1.1.2.2" xref="S3.SS2.p2.7.m7.1.1.2.2.cmml">F</mi><mi id="S3.SS2.p2.7.m7.1.1.2.3" xref="S3.SS2.p2.7.m7.1.1.2.3.cmml">Î¸</mi></msub><mo lspace="0.278em" rspace="0.278em" id="S3.SS2.p2.7.m7.1.1.1" xref="S3.SS2.p2.7.m7.1.1.1.cmml">:</mo><mrow id="S3.SS2.p2.7.m7.1.1.3" xref="S3.SS2.p2.7.m7.1.1.3.cmml"><mi id="S3.SS2.p2.7.m7.1.1.3.2" xref="S3.SS2.p2.7.m7.1.1.3.2.cmml">ğ•</mi><mo stretchy="false" id="S3.SS2.p2.7.m7.1.1.3.1" xref="S3.SS2.p2.7.m7.1.1.3.1.cmml">â†’</mo><mi id="S3.SS2.p2.7.m7.1.1.3.3" xref="S3.SS2.p2.7.m7.1.1.3.3.cmml">ğ”»</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.7.m7.1b"><apply id="S3.SS2.p2.7.m7.1.1.cmml" xref="S3.SS2.p2.7.m7.1.1"><ci id="S3.SS2.p2.7.m7.1.1.1.cmml" xref="S3.SS2.p2.7.m7.1.1.1">:</ci><apply id="S3.SS2.p2.7.m7.1.1.2.cmml" xref="S3.SS2.p2.7.m7.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p2.7.m7.1.1.2.1.cmml" xref="S3.SS2.p2.7.m7.1.1.2">subscript</csymbol><ci id="S3.SS2.p2.7.m7.1.1.2.2.cmml" xref="S3.SS2.p2.7.m7.1.1.2.2">ğ¹</ci><ci id="S3.SS2.p2.7.m7.1.1.2.3.cmml" xref="S3.SS2.p2.7.m7.1.1.2.3">ğœƒ</ci></apply><apply id="S3.SS2.p2.7.m7.1.1.3.cmml" xref="S3.SS2.p2.7.m7.1.1.3"><ci id="S3.SS2.p2.7.m7.1.1.3.1.cmml" xref="S3.SS2.p2.7.m7.1.1.3.1">â†’</ci><ci id="S3.SS2.p2.7.m7.1.1.3.2.cmml" xref="S3.SS2.p2.7.m7.1.1.3.2">ğ•</ci><ci id="S3.SS2.p2.7.m7.1.1.3.3.cmml" xref="S3.SS2.p2.7.m7.1.1.3.3">ğ”»</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.7.m7.1c">F_{\theta}:\mathbb{X}\rightarrow\mathbb{D}</annotation></semantics></math> parameterized by <math id="S3.SS2.p2.8.m8.1" class="ltx_Math" alttext="\theta\in\mathbb{R}^{p}" display="inline"><semantics id="S3.SS2.p2.8.m8.1a"><mrow id="S3.SS2.p2.8.m8.1.1" xref="S3.SS2.p2.8.m8.1.1.cmml"><mi id="S3.SS2.p2.8.m8.1.1.2" xref="S3.SS2.p2.8.m8.1.1.2.cmml">Î¸</mi><mo id="S3.SS2.p2.8.m8.1.1.1" xref="S3.SS2.p2.8.m8.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS2.p2.8.m8.1.1.3" xref="S3.SS2.p2.8.m8.1.1.3.cmml"><mi id="S3.SS2.p2.8.m8.1.1.3.2" xref="S3.SS2.p2.8.m8.1.1.3.2.cmml">â„</mi><mi id="S3.SS2.p2.8.m8.1.1.3.3" xref="S3.SS2.p2.8.m8.1.1.3.3.cmml">p</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.8.m8.1b"><apply id="S3.SS2.p2.8.m8.1.1.cmml" xref="S3.SS2.p2.8.m8.1.1"><in id="S3.SS2.p2.8.m8.1.1.1.cmml" xref="S3.SS2.p2.8.m8.1.1.1"></in><ci id="S3.SS2.p2.8.m8.1.1.2.cmml" xref="S3.SS2.p2.8.m8.1.1.2">ğœƒ</ci><apply id="S3.SS2.p2.8.m8.1.1.3.cmml" xref="S3.SS2.p2.8.m8.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p2.8.m8.1.1.3.1.cmml" xref="S3.SS2.p2.8.m8.1.1.3">superscript</csymbol><ci id="S3.SS2.p2.8.m8.1.1.3.2.cmml" xref="S3.SS2.p2.8.m8.1.1.3.2">â„</ci><ci id="S3.SS2.p2.8.m8.1.1.3.3.cmml" xref="S3.SS2.p2.8.m8.1.1.3.3">ğ‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.8.m8.1c">\theta\in\mathbb{R}^{p}</annotation></semantics></math> without violating the usersâ€™ privacy. At each round <math id="S3.SS2.p2.9.m9.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S3.SS2.p2.9.m9.1a"><mi id="S3.SS2.p2.9.m9.1.1" xref="S3.SS2.p2.9.m9.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.9.m9.1b"><ci id="S3.SS2.p2.9.m9.1.1.cmml" xref="S3.SS2.p2.9.m9.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.9.m9.1c">t</annotation></semantics></math>, the server sends the current global model <math id="S3.SS2.p2.10.m10.1" class="ltx_Math" alttext="\theta^{t}" display="inline"><semantics id="S3.SS2.p2.10.m10.1a"><msup id="S3.SS2.p2.10.m10.1.1" xref="S3.SS2.p2.10.m10.1.1.cmml"><mi id="S3.SS2.p2.10.m10.1.1.2" xref="S3.SS2.p2.10.m10.1.1.2.cmml">Î¸</mi><mi id="S3.SS2.p2.10.m10.1.1.3" xref="S3.SS2.p2.10.m10.1.1.3.cmml">t</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.10.m10.1b"><apply id="S3.SS2.p2.10.m10.1.1.cmml" xref="S3.SS2.p2.10.m10.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.10.m10.1.1.1.cmml" xref="S3.SS2.p2.10.m10.1.1">superscript</csymbol><ci id="S3.SS2.p2.10.m10.1.1.2.cmml" xref="S3.SS2.p2.10.m10.1.1.2">ğœƒ</ci><ci id="S3.SS2.p2.10.m10.1.1.3.cmml" xref="S3.SS2.p2.10.m10.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.10.m10.1c">\theta^{t}</annotation></semantics></math> to a subset of selected clients <math id="S3.SS2.p2.11.m11.1" class="ltx_Math" alttext="\mathcal{C}^{t}\in\mathcal{C}" display="inline"><semantics id="S3.SS2.p2.11.m11.1a"><mrow id="S3.SS2.p2.11.m11.1.1" xref="S3.SS2.p2.11.m11.1.1.cmml"><msup id="S3.SS2.p2.11.m11.1.1.2" xref="S3.SS2.p2.11.m11.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p2.11.m11.1.1.2.2" xref="S3.SS2.p2.11.m11.1.1.2.2.cmml">ğ’</mi><mi id="S3.SS2.p2.11.m11.1.1.2.3" xref="S3.SS2.p2.11.m11.1.1.2.3.cmml">t</mi></msup><mo id="S3.SS2.p2.11.m11.1.1.1" xref="S3.SS2.p2.11.m11.1.1.1.cmml">âˆˆ</mo><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p2.11.m11.1.1.3" xref="S3.SS2.p2.11.m11.1.1.3.cmml">ğ’</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.11.m11.1b"><apply id="S3.SS2.p2.11.m11.1.1.cmml" xref="S3.SS2.p2.11.m11.1.1"><in id="S3.SS2.p2.11.m11.1.1.1.cmml" xref="S3.SS2.p2.11.m11.1.1.1"></in><apply id="S3.SS2.p2.11.m11.1.1.2.cmml" xref="S3.SS2.p2.11.m11.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p2.11.m11.1.1.2.1.cmml" xref="S3.SS2.p2.11.m11.1.1.2">superscript</csymbol><ci id="S3.SS2.p2.11.m11.1.1.2.2.cmml" xref="S3.SS2.p2.11.m11.1.1.2.2">ğ’</ci><ci id="S3.SS2.p2.11.m11.1.1.2.3.cmml" xref="S3.SS2.p2.11.m11.1.1.2.3">ğ‘¡</ci></apply><ci id="S3.SS2.p2.11.m11.1.1.3.cmml" xref="S3.SS2.p2.11.m11.1.1.3">ğ’</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.11.m11.1c">\mathcal{C}^{t}\in\mathcal{C}</annotation></semantics></math>, which trains it using their local data.
<span id="S3.SS2.p2.11.3" class="ltx_text ltx_font_bold">Local mining.</span> As detailed in <a href="#S3.SS1" title="3.1 Centralized VPR â€£ 3 Method â€£ Collaborative Visual Place Recognition through Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Sec.</span>Â <span class="ltx_text ltx_ref_tag">3.1</span></a>, the <span id="S3.SS2.p2.11.4" class="ltx_text ltx_font_bold">mining</span> process is crucial for learning as it ensures that the network is fed with informative samples during training.
Differently from the centralized scenario where the model has access to the whole dataset for training, here we encounter the challenge of performing mining without (<span id="S3.SS2.p2.11.5" class="ltx_text ltx_font_italic">i</span>) increasing the communication costs by exchanging continuous information between clients and server, <span id="S3.SS2.p2.11.6" class="ltx_text ltx_font_italic">ii</span>) downloading enormous quantities of data on resource-constrained devices and (<span id="S3.SS2.p2.11.7" class="ltx_text ltx_font_italic">iii</span>) exchanging data with other clients or the server, which could result in privacy leaks. In FedVPR, to avoid the aforementioned bottlenecks and any privacy concerns, the mining is limited to the database images previously collected by each client. The local data collection likely satisfies the requirement of having access to <span id="S3.SS2.p2.11.8" class="ltx_text ltx_font_italic">hard negative</span> samples (<em id="S3.SS2.p2.11.9" class="ltx_emph ltx_font_italic">i.e.</em>, visually similar images of different places) to successfully train the feature extractor. However, its limited variability is an important factor that can slow down convergence and ultimately affects performances. More details on this matter are presented in the experimental section.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.2" class="ltx_p">At the end of local training, each client <math id="S3.SS2.p3.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.SS2.p3.1.m1.1a"><mi id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b"><ci id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">k</annotation></semantics></math> sends the updated <math id="S3.SS2.p3.2.m2.1" class="ltx_Math" alttext="\theta_{k}^{t}" display="inline"><semantics id="S3.SS2.p3.2.m2.1a"><msubsup id="S3.SS2.p3.2.m2.1.1" xref="S3.SS2.p3.2.m2.1.1.cmml"><mi id="S3.SS2.p3.2.m2.1.1.2.2" xref="S3.SS2.p3.2.m2.1.1.2.2.cmml">Î¸</mi><mi id="S3.SS2.p3.2.m2.1.1.2.3" xref="S3.SS2.p3.2.m2.1.1.2.3.cmml">k</mi><mi id="S3.SS2.p3.2.m2.1.1.3" xref="S3.SS2.p3.2.m2.1.1.3.cmml">t</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.m2.1b"><apply id="S3.SS2.p3.2.m2.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.2.m2.1.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1">superscript</csymbol><apply id="S3.SS2.p3.2.m2.1.1.2.cmml" xref="S3.SS2.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.2.m2.1.1.2.1.cmml" xref="S3.SS2.p3.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.p3.2.m2.1.1.2.2.cmml" xref="S3.SS2.p3.2.m2.1.1.2.2">ğœƒ</ci><ci id="S3.SS2.p3.2.m2.1.1.2.3.cmml" xref="S3.SS2.p3.2.m2.1.1.2.3">ğ‘˜</ci></apply><ci id="S3.SS2.p3.2.m2.1.1.3.cmml" xref="S3.SS2.p3.2.m2.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.2.m2.1c">\theta_{k}^{t}</annotation></semantics></math> to the server.
The global training objective is solved by aggregating the received updates on the server side. The de-facto standard aggregation algorithm is FedAvg <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">52</span></a>]</cite>, which averages the clientsâ€™ parameters as</p>
<table id="S3.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E4.m1.1" class="ltx_Math" alttext="\theta^{t+1}\leftarrow\sum_{k\in\mathcal{C}^{t}}\frac{N_{k}}{N}\theta^{t}_{k}," display="block"><semantics id="S3.E4.m1.1a"><mrow id="S3.E4.m1.1.1.1" xref="S3.E4.m1.1.1.1.1.cmml"><mrow id="S3.E4.m1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.cmml"><msup id="S3.E4.m1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.2.cmml"><mi id="S3.E4.m1.1.1.1.1.2.2" xref="S3.E4.m1.1.1.1.1.2.2.cmml">Î¸</mi><mrow id="S3.E4.m1.1.1.1.1.2.3" xref="S3.E4.m1.1.1.1.1.2.3.cmml"><mi id="S3.E4.m1.1.1.1.1.2.3.2" xref="S3.E4.m1.1.1.1.1.2.3.2.cmml">t</mi><mo id="S3.E4.m1.1.1.1.1.2.3.1" xref="S3.E4.m1.1.1.1.1.2.3.1.cmml">+</mo><mn id="S3.E4.m1.1.1.1.1.2.3.3" xref="S3.E4.m1.1.1.1.1.2.3.3.cmml">1</mn></mrow></msup><mo rspace="0.111em" stretchy="false" id="S3.E4.m1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.cmml">â†</mo><mrow id="S3.E4.m1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.3.cmml"><munder id="S3.E4.m1.1.1.1.1.3.1" xref="S3.E4.m1.1.1.1.1.3.1.cmml"><mo movablelimits="false" id="S3.E4.m1.1.1.1.1.3.1.2" xref="S3.E4.m1.1.1.1.1.3.1.2.cmml">âˆ‘</mo><mrow id="S3.E4.m1.1.1.1.1.3.1.3" xref="S3.E4.m1.1.1.1.1.3.1.3.cmml"><mi id="S3.E4.m1.1.1.1.1.3.1.3.2" xref="S3.E4.m1.1.1.1.1.3.1.3.2.cmml">k</mi><mo id="S3.E4.m1.1.1.1.1.3.1.3.1" xref="S3.E4.m1.1.1.1.1.3.1.3.1.cmml">âˆˆ</mo><msup id="S3.E4.m1.1.1.1.1.3.1.3.3" xref="S3.E4.m1.1.1.1.1.3.1.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E4.m1.1.1.1.1.3.1.3.3.2" xref="S3.E4.m1.1.1.1.1.3.1.3.3.2.cmml">ğ’</mi><mi id="S3.E4.m1.1.1.1.1.3.1.3.3.3" xref="S3.E4.m1.1.1.1.1.3.1.3.3.3.cmml">t</mi></msup></mrow></munder><mrow id="S3.E4.m1.1.1.1.1.3.2" xref="S3.E4.m1.1.1.1.1.3.2.cmml"><mfrac id="S3.E4.m1.1.1.1.1.3.2.2" xref="S3.E4.m1.1.1.1.1.3.2.2.cmml"><msub id="S3.E4.m1.1.1.1.1.3.2.2.2" xref="S3.E4.m1.1.1.1.1.3.2.2.2.cmml"><mi id="S3.E4.m1.1.1.1.1.3.2.2.2.2" xref="S3.E4.m1.1.1.1.1.3.2.2.2.2.cmml">N</mi><mi id="S3.E4.m1.1.1.1.1.3.2.2.2.3" xref="S3.E4.m1.1.1.1.1.3.2.2.2.3.cmml">k</mi></msub><mi id="S3.E4.m1.1.1.1.1.3.2.2.3" xref="S3.E4.m1.1.1.1.1.3.2.2.3.cmml">N</mi></mfrac><mo lspace="0em" rspace="0em" id="S3.E4.m1.1.1.1.1.3.2.1" xref="S3.E4.m1.1.1.1.1.3.2.1.cmml">â€‹</mo><msubsup id="S3.E4.m1.1.1.1.1.3.2.3" xref="S3.E4.m1.1.1.1.1.3.2.3.cmml"><mi id="S3.E4.m1.1.1.1.1.3.2.3.2.2" xref="S3.E4.m1.1.1.1.1.3.2.3.2.2.cmml">Î¸</mi><mi id="S3.E4.m1.1.1.1.1.3.2.3.3" xref="S3.E4.m1.1.1.1.1.3.2.3.3.cmml">k</mi><mi id="S3.E4.m1.1.1.1.1.3.2.3.2.3" xref="S3.E4.m1.1.1.1.1.3.2.3.2.3.cmml">t</mi></msubsup></mrow></mrow></mrow><mo id="S3.E4.m1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.1b"><apply id="S3.E4.m1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1"><ci id="S3.E4.m1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1">â†</ci><apply id="S3.E4.m1.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.2.1.cmml" xref="S3.E4.m1.1.1.1.1.2">superscript</csymbol><ci id="S3.E4.m1.1.1.1.1.2.2.cmml" xref="S3.E4.m1.1.1.1.1.2.2">ğœƒ</ci><apply id="S3.E4.m1.1.1.1.1.2.3.cmml" xref="S3.E4.m1.1.1.1.1.2.3"><plus id="S3.E4.m1.1.1.1.1.2.3.1.cmml" xref="S3.E4.m1.1.1.1.1.2.3.1"></plus><ci id="S3.E4.m1.1.1.1.1.2.3.2.cmml" xref="S3.E4.m1.1.1.1.1.2.3.2">ğ‘¡</ci><cn type="integer" id="S3.E4.m1.1.1.1.1.2.3.3.cmml" xref="S3.E4.m1.1.1.1.1.2.3.3">1</cn></apply></apply><apply id="S3.E4.m1.1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.3"><apply id="S3.E4.m1.1.1.1.1.3.1.cmml" xref="S3.E4.m1.1.1.1.1.3.1"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.3.1.1.cmml" xref="S3.E4.m1.1.1.1.1.3.1">subscript</csymbol><sum id="S3.E4.m1.1.1.1.1.3.1.2.cmml" xref="S3.E4.m1.1.1.1.1.3.1.2"></sum><apply id="S3.E4.m1.1.1.1.1.3.1.3.cmml" xref="S3.E4.m1.1.1.1.1.3.1.3"><in id="S3.E4.m1.1.1.1.1.3.1.3.1.cmml" xref="S3.E4.m1.1.1.1.1.3.1.3.1"></in><ci id="S3.E4.m1.1.1.1.1.3.1.3.2.cmml" xref="S3.E4.m1.1.1.1.1.3.1.3.2">ğ‘˜</ci><apply id="S3.E4.m1.1.1.1.1.3.1.3.3.cmml" xref="S3.E4.m1.1.1.1.1.3.1.3.3"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.3.1.3.3.1.cmml" xref="S3.E4.m1.1.1.1.1.3.1.3.3">superscript</csymbol><ci id="S3.E4.m1.1.1.1.1.3.1.3.3.2.cmml" xref="S3.E4.m1.1.1.1.1.3.1.3.3.2">ğ’</ci><ci id="S3.E4.m1.1.1.1.1.3.1.3.3.3.cmml" xref="S3.E4.m1.1.1.1.1.3.1.3.3.3">ğ‘¡</ci></apply></apply></apply><apply id="S3.E4.m1.1.1.1.1.3.2.cmml" xref="S3.E4.m1.1.1.1.1.3.2"><times id="S3.E4.m1.1.1.1.1.3.2.1.cmml" xref="S3.E4.m1.1.1.1.1.3.2.1"></times><apply id="S3.E4.m1.1.1.1.1.3.2.2.cmml" xref="S3.E4.m1.1.1.1.1.3.2.2"><divide id="S3.E4.m1.1.1.1.1.3.2.2.1.cmml" xref="S3.E4.m1.1.1.1.1.3.2.2"></divide><apply id="S3.E4.m1.1.1.1.1.3.2.2.2.cmml" xref="S3.E4.m1.1.1.1.1.3.2.2.2"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.3.2.2.2.1.cmml" xref="S3.E4.m1.1.1.1.1.3.2.2.2">subscript</csymbol><ci id="S3.E4.m1.1.1.1.1.3.2.2.2.2.cmml" xref="S3.E4.m1.1.1.1.1.3.2.2.2.2">ğ‘</ci><ci id="S3.E4.m1.1.1.1.1.3.2.2.2.3.cmml" xref="S3.E4.m1.1.1.1.1.3.2.2.2.3">ğ‘˜</ci></apply><ci id="S3.E4.m1.1.1.1.1.3.2.2.3.cmml" xref="S3.E4.m1.1.1.1.1.3.2.2.3">ğ‘</ci></apply><apply id="S3.E4.m1.1.1.1.1.3.2.3.cmml" xref="S3.E4.m1.1.1.1.1.3.2.3"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.3.2.3.1.cmml" xref="S3.E4.m1.1.1.1.1.3.2.3">subscript</csymbol><apply id="S3.E4.m1.1.1.1.1.3.2.3.2.cmml" xref="S3.E4.m1.1.1.1.1.3.2.3"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.3.2.3.2.1.cmml" xref="S3.E4.m1.1.1.1.1.3.2.3">superscript</csymbol><ci id="S3.E4.m1.1.1.1.1.3.2.3.2.2.cmml" xref="S3.E4.m1.1.1.1.1.3.2.3.2.2">ğœƒ</ci><ci id="S3.E4.m1.1.1.1.1.3.2.3.2.3.cmml" xref="S3.E4.m1.1.1.1.1.3.2.3.2.3">ğ‘¡</ci></apply><ci id="S3.E4.m1.1.1.1.1.3.2.3.3.cmml" xref="S3.E4.m1.1.1.1.1.3.2.3.3">ğ‘˜</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.1c">\theta^{t+1}\leftarrow\sum_{k\in\mathcal{C}^{t}}\frac{N_{k}}{N}\theta^{t}_{k},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p id="S3.SS2.p3.6" class="ltx_p">where <math id="S3.SS2.p3.3.m1.1" class="ltx_Math" alttext="N=\sum_{k\in\mathcal{C}^{t}}N_{k}" display="inline"><semantics id="S3.SS2.p3.3.m1.1a"><mrow id="S3.SS2.p3.3.m1.1.1" xref="S3.SS2.p3.3.m1.1.1.cmml"><mi id="S3.SS2.p3.3.m1.1.1.2" xref="S3.SS2.p3.3.m1.1.1.2.cmml">N</mi><mo rspace="0.111em" id="S3.SS2.p3.3.m1.1.1.1" xref="S3.SS2.p3.3.m1.1.1.1.cmml">=</mo><mrow id="S3.SS2.p3.3.m1.1.1.3" xref="S3.SS2.p3.3.m1.1.1.3.cmml"><msub id="S3.SS2.p3.3.m1.1.1.3.1" xref="S3.SS2.p3.3.m1.1.1.3.1.cmml"><mo id="S3.SS2.p3.3.m1.1.1.3.1.2" xref="S3.SS2.p3.3.m1.1.1.3.1.2.cmml">âˆ‘</mo><mrow id="S3.SS2.p3.3.m1.1.1.3.1.3" xref="S3.SS2.p3.3.m1.1.1.3.1.3.cmml"><mi id="S3.SS2.p3.3.m1.1.1.3.1.3.2" xref="S3.SS2.p3.3.m1.1.1.3.1.3.2.cmml">k</mi><mo id="S3.SS2.p3.3.m1.1.1.3.1.3.1" xref="S3.SS2.p3.3.m1.1.1.3.1.3.1.cmml">âˆˆ</mo><msup id="S3.SS2.p3.3.m1.1.1.3.1.3.3" xref="S3.SS2.p3.3.m1.1.1.3.1.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p3.3.m1.1.1.3.1.3.3.2" xref="S3.SS2.p3.3.m1.1.1.3.1.3.3.2.cmml">ğ’</mi><mi id="S3.SS2.p3.3.m1.1.1.3.1.3.3.3" xref="S3.SS2.p3.3.m1.1.1.3.1.3.3.3.cmml">t</mi></msup></mrow></msub><msub id="S3.SS2.p3.3.m1.1.1.3.2" xref="S3.SS2.p3.3.m1.1.1.3.2.cmml"><mi id="S3.SS2.p3.3.m1.1.1.3.2.2" xref="S3.SS2.p3.3.m1.1.1.3.2.2.cmml">N</mi><mi id="S3.SS2.p3.3.m1.1.1.3.2.3" xref="S3.SS2.p3.3.m1.1.1.3.2.3.cmml">k</mi></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.3.m1.1b"><apply id="S3.SS2.p3.3.m1.1.1.cmml" xref="S3.SS2.p3.3.m1.1.1"><eq id="S3.SS2.p3.3.m1.1.1.1.cmml" xref="S3.SS2.p3.3.m1.1.1.1"></eq><ci id="S3.SS2.p3.3.m1.1.1.2.cmml" xref="S3.SS2.p3.3.m1.1.1.2">ğ‘</ci><apply id="S3.SS2.p3.3.m1.1.1.3.cmml" xref="S3.SS2.p3.3.m1.1.1.3"><apply id="S3.SS2.p3.3.m1.1.1.3.1.cmml" xref="S3.SS2.p3.3.m1.1.1.3.1"><csymbol cd="ambiguous" id="S3.SS2.p3.3.m1.1.1.3.1.1.cmml" xref="S3.SS2.p3.3.m1.1.1.3.1">subscript</csymbol><sum id="S3.SS2.p3.3.m1.1.1.3.1.2.cmml" xref="S3.SS2.p3.3.m1.1.1.3.1.2"></sum><apply id="S3.SS2.p3.3.m1.1.1.3.1.3.cmml" xref="S3.SS2.p3.3.m1.1.1.3.1.3"><in id="S3.SS2.p3.3.m1.1.1.3.1.3.1.cmml" xref="S3.SS2.p3.3.m1.1.1.3.1.3.1"></in><ci id="S3.SS2.p3.3.m1.1.1.3.1.3.2.cmml" xref="S3.SS2.p3.3.m1.1.1.3.1.3.2">ğ‘˜</ci><apply id="S3.SS2.p3.3.m1.1.1.3.1.3.3.cmml" xref="S3.SS2.p3.3.m1.1.1.3.1.3.3"><csymbol cd="ambiguous" id="S3.SS2.p3.3.m1.1.1.3.1.3.3.1.cmml" xref="S3.SS2.p3.3.m1.1.1.3.1.3.3">superscript</csymbol><ci id="S3.SS2.p3.3.m1.1.1.3.1.3.3.2.cmml" xref="S3.SS2.p3.3.m1.1.1.3.1.3.3.2">ğ’</ci><ci id="S3.SS2.p3.3.m1.1.1.3.1.3.3.3.cmml" xref="S3.SS2.p3.3.m1.1.1.3.1.3.3.3">ğ‘¡</ci></apply></apply></apply><apply id="S3.SS2.p3.3.m1.1.1.3.2.cmml" xref="S3.SS2.p3.3.m1.1.1.3.2"><csymbol cd="ambiguous" id="S3.SS2.p3.3.m1.1.1.3.2.1.cmml" xref="S3.SS2.p3.3.m1.1.1.3.2">subscript</csymbol><ci id="S3.SS2.p3.3.m1.1.1.3.2.2.cmml" xref="S3.SS2.p3.3.m1.1.1.3.2.2">ğ‘</ci><ci id="S3.SS2.p3.3.m1.1.1.3.2.3.cmml" xref="S3.SS2.p3.3.m1.1.1.3.2.3">ğ‘˜</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.3.m1.1c">N=\sum_{k\in\mathcal{C}^{t}}N_{k}</annotation></semantics></math>. As showed by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib58" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">58</span></a>]</cite>, <a href="#S3.E4" title="In 3.2 Federated Visual Place Recognition (FedVPR) â€£ 3 Method â€£ Collaborative Visual Place Recognition through Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Eq.</span>Â <span class="ltx_text ltx_ref_tag">4</span></a> is equivalent to apply SGD (Stochastic Gradient Descent) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib59" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">59</span></a>]</cite> with a pseudo-gradient <math id="S3.SS2.p3.4.m2.1" class="ltx_Math" alttext="\Delta\theta^{t}:=\sum_{k\in\mathcal{C}^{t}}\nicefrac{{N_{k}}}{{N}}(\theta^{t}-\theta_{k}^{t})" display="inline"><semantics id="S3.SS2.p3.4.m2.1a"><mrow id="S3.SS2.p3.4.m2.1.1" xref="S3.SS2.p3.4.m2.1.1.cmml"><mrow id="S3.SS2.p3.4.m2.1.1.3" xref="S3.SS2.p3.4.m2.1.1.3.cmml"><mi mathvariant="normal" id="S3.SS2.p3.4.m2.1.1.3.2" xref="S3.SS2.p3.4.m2.1.1.3.2.cmml">Î”</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.4.m2.1.1.3.1" xref="S3.SS2.p3.4.m2.1.1.3.1.cmml">â€‹</mo><msup id="S3.SS2.p3.4.m2.1.1.3.3" xref="S3.SS2.p3.4.m2.1.1.3.3.cmml"><mi id="S3.SS2.p3.4.m2.1.1.3.3.2" xref="S3.SS2.p3.4.m2.1.1.3.3.2.cmml">Î¸</mi><mi id="S3.SS2.p3.4.m2.1.1.3.3.3" xref="S3.SS2.p3.4.m2.1.1.3.3.3.cmml">t</mi></msup></mrow><mo lspace="0.278em" rspace="0.111em" id="S3.SS2.p3.4.m2.1.1.2" xref="S3.SS2.p3.4.m2.1.1.2.cmml">:=</mo><mrow id="S3.SS2.p3.4.m2.1.1.1" xref="S3.SS2.p3.4.m2.1.1.1.cmml"><msub id="S3.SS2.p3.4.m2.1.1.1.2" xref="S3.SS2.p3.4.m2.1.1.1.2.cmml"><mo id="S3.SS2.p3.4.m2.1.1.1.2.2" xref="S3.SS2.p3.4.m2.1.1.1.2.2.cmml">âˆ‘</mo><mrow id="S3.SS2.p3.4.m2.1.1.1.2.3" xref="S3.SS2.p3.4.m2.1.1.1.2.3.cmml"><mi id="S3.SS2.p3.4.m2.1.1.1.2.3.2" xref="S3.SS2.p3.4.m2.1.1.1.2.3.2.cmml">k</mi><mo id="S3.SS2.p3.4.m2.1.1.1.2.3.1" xref="S3.SS2.p3.4.m2.1.1.1.2.3.1.cmml">âˆˆ</mo><msup id="S3.SS2.p3.4.m2.1.1.1.2.3.3" xref="S3.SS2.p3.4.m2.1.1.1.2.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p3.4.m2.1.1.1.2.3.3.2" xref="S3.SS2.p3.4.m2.1.1.1.2.3.3.2.cmml">ğ’</mi><mi id="S3.SS2.p3.4.m2.1.1.1.2.3.3.3" xref="S3.SS2.p3.4.m2.1.1.1.2.3.3.3.cmml">t</mi></msup></mrow></msub><mrow id="S3.SS2.p3.4.m2.1.1.1.1" xref="S3.SS2.p3.4.m2.1.1.1.1.cmml"><mrow id="S3.SS2.p3.4.m2.1.1.1.1.3" xref="S3.SS2.p3.4.m2.1.1.1.1.3.cmml"><mpadded voffset="0.3em" id="S3.SS2.p3.4.m2.1.1.1.1.3.2" xref="S3.SS2.p3.4.m2.1.1.1.1.3.2.cmml"><msub id="S3.SS2.p3.4.m2.1.1.1.1.3.2a" xref="S3.SS2.p3.4.m2.1.1.1.1.3.2.cmml"><mi mathsize="70%" id="S3.SS2.p3.4.m2.1.1.1.1.3.2.2" xref="S3.SS2.p3.4.m2.1.1.1.1.3.2.2.cmml">N</mi><mi mathsize="71%" id="S3.SS2.p3.4.m2.1.1.1.1.3.2.3" xref="S3.SS2.p3.4.m2.1.1.1.1.3.2.3.cmml">k</mi></msub></mpadded><mpadded lspace="-0.1em" width="-0.15em" id="S3.SS2.p3.4.m2.1.1.1.1.3.1" xref="S3.SS2.p3.4.m2.1.1.1.1.3.1.cmml"><mo stretchy="true" symmetric="true" id="S3.SS2.p3.4.m2.1.1.1.1.3.1a" xref="S3.SS2.p3.4.m2.1.1.1.1.3.1.cmml">/</mo></mpadded><mi mathsize="70%" id="S3.SS2.p3.4.m2.1.1.1.1.3.3" xref="S3.SS2.p3.4.m2.1.1.1.1.3.3.cmml">N</mi></mrow><mo lspace="0em" rspace="0em" id="S3.SS2.p3.4.m2.1.1.1.1.2" xref="S3.SS2.p3.4.m2.1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.SS2.p3.4.m2.1.1.1.1.1.1" xref="S3.SS2.p3.4.m2.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS2.p3.4.m2.1.1.1.1.1.1.2" xref="S3.SS2.p3.4.m2.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS2.p3.4.m2.1.1.1.1.1.1.1" xref="S3.SS2.p3.4.m2.1.1.1.1.1.1.1.cmml"><msup id="S3.SS2.p3.4.m2.1.1.1.1.1.1.1.2" xref="S3.SS2.p3.4.m2.1.1.1.1.1.1.1.2.cmml"><mi id="S3.SS2.p3.4.m2.1.1.1.1.1.1.1.2.2" xref="S3.SS2.p3.4.m2.1.1.1.1.1.1.1.2.2.cmml">Î¸</mi><mi id="S3.SS2.p3.4.m2.1.1.1.1.1.1.1.2.3" xref="S3.SS2.p3.4.m2.1.1.1.1.1.1.1.2.3.cmml">t</mi></msup><mo id="S3.SS2.p3.4.m2.1.1.1.1.1.1.1.1" xref="S3.SS2.p3.4.m2.1.1.1.1.1.1.1.1.cmml">âˆ’</mo><msubsup id="S3.SS2.p3.4.m2.1.1.1.1.1.1.1.3" xref="S3.SS2.p3.4.m2.1.1.1.1.1.1.1.3.cmml"><mi id="S3.SS2.p3.4.m2.1.1.1.1.1.1.1.3.2.2" xref="S3.SS2.p3.4.m2.1.1.1.1.1.1.1.3.2.2.cmml">Î¸</mi><mi id="S3.SS2.p3.4.m2.1.1.1.1.1.1.1.3.2.3" xref="S3.SS2.p3.4.m2.1.1.1.1.1.1.1.3.2.3.cmml">k</mi><mi id="S3.SS2.p3.4.m2.1.1.1.1.1.1.1.3.3" xref="S3.SS2.p3.4.m2.1.1.1.1.1.1.1.3.3.cmml">t</mi></msubsup></mrow><mo stretchy="false" id="S3.SS2.p3.4.m2.1.1.1.1.1.1.3" xref="S3.SS2.p3.4.m2.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.4.m2.1b"><apply id="S3.SS2.p3.4.m2.1.1.cmml" xref="S3.SS2.p3.4.m2.1.1"><csymbol cd="latexml" id="S3.SS2.p3.4.m2.1.1.2.cmml" xref="S3.SS2.p3.4.m2.1.1.2">assign</csymbol><apply id="S3.SS2.p3.4.m2.1.1.3.cmml" xref="S3.SS2.p3.4.m2.1.1.3"><times id="S3.SS2.p3.4.m2.1.1.3.1.cmml" xref="S3.SS2.p3.4.m2.1.1.3.1"></times><ci id="S3.SS2.p3.4.m2.1.1.3.2.cmml" xref="S3.SS2.p3.4.m2.1.1.3.2">Î”</ci><apply id="S3.SS2.p3.4.m2.1.1.3.3.cmml" xref="S3.SS2.p3.4.m2.1.1.3.3"><csymbol cd="ambiguous" id="S3.SS2.p3.4.m2.1.1.3.3.1.cmml" xref="S3.SS2.p3.4.m2.1.1.3.3">superscript</csymbol><ci id="S3.SS2.p3.4.m2.1.1.3.3.2.cmml" xref="S3.SS2.p3.4.m2.1.1.3.3.2">ğœƒ</ci><ci id="S3.SS2.p3.4.m2.1.1.3.3.3.cmml" xref="S3.SS2.p3.4.m2.1.1.3.3.3">ğ‘¡</ci></apply></apply><apply id="S3.SS2.p3.4.m2.1.1.1.cmml" xref="S3.SS2.p3.4.m2.1.1.1"><apply id="S3.SS2.p3.4.m2.1.1.1.2.cmml" xref="S3.SS2.p3.4.m2.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p3.4.m2.1.1.1.2.1.cmml" xref="S3.SS2.p3.4.m2.1.1.1.2">subscript</csymbol><sum id="S3.SS2.p3.4.m2.1.1.1.2.2.cmml" xref="S3.SS2.p3.4.m2.1.1.1.2.2"></sum><apply id="S3.SS2.p3.4.m2.1.1.1.2.3.cmml" xref="S3.SS2.p3.4.m2.1.1.1.2.3"><in id="S3.SS2.p3.4.m2.1.1.1.2.3.1.cmml" xref="S3.SS2.p3.4.m2.1.1.1.2.3.1"></in><ci id="S3.SS2.p3.4.m2.1.1.1.2.3.2.cmml" xref="S3.SS2.p3.4.m2.1.1.1.2.3.2">ğ‘˜</ci><apply id="S3.SS2.p3.4.m2.1.1.1.2.3.3.cmml" xref="S3.SS2.p3.4.m2.1.1.1.2.3.3"><csymbol cd="ambiguous" id="S3.SS2.p3.4.m2.1.1.1.2.3.3.1.cmml" xref="S3.SS2.p3.4.m2.1.1.1.2.3.3">superscript</csymbol><ci id="S3.SS2.p3.4.m2.1.1.1.2.3.3.2.cmml" xref="S3.SS2.p3.4.m2.1.1.1.2.3.3.2">ğ’</ci><ci id="S3.SS2.p3.4.m2.1.1.1.2.3.3.3.cmml" xref="S3.SS2.p3.4.m2.1.1.1.2.3.3.3">ğ‘¡</ci></apply></apply></apply><apply id="S3.SS2.p3.4.m2.1.1.1.1.cmml" xref="S3.SS2.p3.4.m2.1.1.1.1"><times id="S3.SS2.p3.4.m2.1.1.1.1.2.cmml" xref="S3.SS2.p3.4.m2.1.1.1.1.2"></times><apply id="S3.SS2.p3.4.m2.1.1.1.1.3.cmml" xref="S3.SS2.p3.4.m2.1.1.1.1.3"><divide id="S3.SS2.p3.4.m2.1.1.1.1.3.1.cmml" xref="S3.SS2.p3.4.m2.1.1.1.1.3.1"></divide><apply id="S3.SS2.p3.4.m2.1.1.1.1.3.2.cmml" xref="S3.SS2.p3.4.m2.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S3.SS2.p3.4.m2.1.1.1.1.3.2.1.cmml" xref="S3.SS2.p3.4.m2.1.1.1.1.3.2">subscript</csymbol><ci id="S3.SS2.p3.4.m2.1.1.1.1.3.2.2.cmml" xref="S3.SS2.p3.4.m2.1.1.1.1.3.2.2">ğ‘</ci><ci id="S3.SS2.p3.4.m2.1.1.1.1.3.2.3.cmml" xref="S3.SS2.p3.4.m2.1.1.1.1.3.2.3">ğ‘˜</ci></apply><ci id="S3.SS2.p3.4.m2.1.1.1.1.3.3.cmml" xref="S3.SS2.p3.4.m2.1.1.1.1.3.3">ğ‘</ci></apply><apply id="S3.SS2.p3.4.m2.1.1.1.1.1.1.1.cmml" xref="S3.SS2.p3.4.m2.1.1.1.1.1.1"><minus id="S3.SS2.p3.4.m2.1.1.1.1.1.1.1.1.cmml" xref="S3.SS2.p3.4.m2.1.1.1.1.1.1.1.1"></minus><apply id="S3.SS2.p3.4.m2.1.1.1.1.1.1.1.2.cmml" xref="S3.SS2.p3.4.m2.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p3.4.m2.1.1.1.1.1.1.1.2.1.cmml" xref="S3.SS2.p3.4.m2.1.1.1.1.1.1.1.2">superscript</csymbol><ci id="S3.SS2.p3.4.m2.1.1.1.1.1.1.1.2.2.cmml" xref="S3.SS2.p3.4.m2.1.1.1.1.1.1.1.2.2">ğœƒ</ci><ci id="S3.SS2.p3.4.m2.1.1.1.1.1.1.1.2.3.cmml" xref="S3.SS2.p3.4.m2.1.1.1.1.1.1.1.2.3">ğ‘¡</ci></apply><apply id="S3.SS2.p3.4.m2.1.1.1.1.1.1.1.3.cmml" xref="S3.SS2.p3.4.m2.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p3.4.m2.1.1.1.1.1.1.1.3.1.cmml" xref="S3.SS2.p3.4.m2.1.1.1.1.1.1.1.3">superscript</csymbol><apply id="S3.SS2.p3.4.m2.1.1.1.1.1.1.1.3.2.cmml" xref="S3.SS2.p3.4.m2.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p3.4.m2.1.1.1.1.1.1.1.3.2.1.cmml" xref="S3.SS2.p3.4.m2.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.SS2.p3.4.m2.1.1.1.1.1.1.1.3.2.2.cmml" xref="S3.SS2.p3.4.m2.1.1.1.1.1.1.1.3.2.2">ğœƒ</ci><ci id="S3.SS2.p3.4.m2.1.1.1.1.1.1.1.3.2.3.cmml" xref="S3.SS2.p3.4.m2.1.1.1.1.1.1.1.3.2.3">ğ‘˜</ci></apply><ci id="S3.SS2.p3.4.m2.1.1.1.1.1.1.1.3.3.cmml" xref="S3.SS2.p3.4.m2.1.1.1.1.1.1.1.3.3">ğ‘¡</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.4.m2.1c">\Delta\theta^{t}:=\sum_{k\in\mathcal{C}^{t}}\nicefrac{{N_{k}}}{{N}}(\theta^{t}-\theta_{k}^{t})</annotation></semantics></math> and server learning rate <math id="S3.SS2.p3.5.m3.1" class="ltx_Math" alttext="\eta_{s}=1" display="inline"><semantics id="S3.SS2.p3.5.m3.1a"><mrow id="S3.SS2.p3.5.m3.1.1" xref="S3.SS2.p3.5.m3.1.1.cmml"><msub id="S3.SS2.p3.5.m3.1.1.2" xref="S3.SS2.p3.5.m3.1.1.2.cmml"><mi id="S3.SS2.p3.5.m3.1.1.2.2" xref="S3.SS2.p3.5.m3.1.1.2.2.cmml">Î·</mi><mi id="S3.SS2.p3.5.m3.1.1.2.3" xref="S3.SS2.p3.5.m3.1.1.2.3.cmml">s</mi></msub><mo id="S3.SS2.p3.5.m3.1.1.1" xref="S3.SS2.p3.5.m3.1.1.1.cmml">=</mo><mn id="S3.SS2.p3.5.m3.1.1.3" xref="S3.SS2.p3.5.m3.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.5.m3.1b"><apply id="S3.SS2.p3.5.m3.1.1.cmml" xref="S3.SS2.p3.5.m3.1.1"><eq id="S3.SS2.p3.5.m3.1.1.1.cmml" xref="S3.SS2.p3.5.m3.1.1.1"></eq><apply id="S3.SS2.p3.5.m3.1.1.2.cmml" xref="S3.SS2.p3.5.m3.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p3.5.m3.1.1.2.1.cmml" xref="S3.SS2.p3.5.m3.1.1.2">subscript</csymbol><ci id="S3.SS2.p3.5.m3.1.1.2.2.cmml" xref="S3.SS2.p3.5.m3.1.1.2.2">ğœ‚</ci><ci id="S3.SS2.p3.5.m3.1.1.2.3.cmml" xref="S3.SS2.p3.5.m3.1.1.2.3">ğ‘ </ci></apply><cn type="integer" id="S3.SS2.p3.5.m3.1.1.3.cmml" xref="S3.SS2.p3.5.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.5.m3.1c">\eta_{s}=1</annotation></semantics></math>, where each round is a different optimization step. Thus, <a href="#S3.E4" title="In 3.2 Federated Visual Place Recognition (FedVPR) â€£ 3 Method â€£ Collaborative Visual Place Recognition through Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Eq.</span>Â <span class="ltx_text ltx_ref_tag">4</span></a> can be generalized to <math id="S3.SS2.p3.6.m4.4" class="ltx_Math" alttext="\theta^{t+1}\leftarrow\theta^{t}-\textsc{ServerOpt}(\theta^{t},\Delta\theta^{t},\eta_{s},t)" display="inline"><semantics id="S3.SS2.p3.6.m4.4a"><mrow id="S3.SS2.p3.6.m4.4.4" xref="S3.SS2.p3.6.m4.4.4.cmml"><msup id="S3.SS2.p3.6.m4.4.4.5" xref="S3.SS2.p3.6.m4.4.4.5.cmml"><mi id="S3.SS2.p3.6.m4.4.4.5.2" xref="S3.SS2.p3.6.m4.4.4.5.2.cmml">Î¸</mi><mrow id="S3.SS2.p3.6.m4.4.4.5.3" xref="S3.SS2.p3.6.m4.4.4.5.3.cmml"><mi id="S3.SS2.p3.6.m4.4.4.5.3.2" xref="S3.SS2.p3.6.m4.4.4.5.3.2.cmml">t</mi><mo id="S3.SS2.p3.6.m4.4.4.5.3.1" xref="S3.SS2.p3.6.m4.4.4.5.3.1.cmml">+</mo><mn id="S3.SS2.p3.6.m4.4.4.5.3.3" xref="S3.SS2.p3.6.m4.4.4.5.3.3.cmml">1</mn></mrow></msup><mo stretchy="false" id="S3.SS2.p3.6.m4.4.4.4" xref="S3.SS2.p3.6.m4.4.4.4.cmml">â†</mo><mrow id="S3.SS2.p3.6.m4.4.4.3" xref="S3.SS2.p3.6.m4.4.4.3.cmml"><msup id="S3.SS2.p3.6.m4.4.4.3.5" xref="S3.SS2.p3.6.m4.4.4.3.5.cmml"><mi id="S3.SS2.p3.6.m4.4.4.3.5.2" xref="S3.SS2.p3.6.m4.4.4.3.5.2.cmml">Î¸</mi><mi id="S3.SS2.p3.6.m4.4.4.3.5.3" xref="S3.SS2.p3.6.m4.4.4.3.5.3.cmml">t</mi></msup><mo id="S3.SS2.p3.6.m4.4.4.3.4" xref="S3.SS2.p3.6.m4.4.4.3.4.cmml">âˆ’</mo><mrow id="S3.SS2.p3.6.m4.4.4.3.3" xref="S3.SS2.p3.6.m4.4.4.3.3.cmml"><mtext class="ltx_font_smallcaps" id="S3.SS2.p3.6.m4.4.4.3.3.5" xref="S3.SS2.p3.6.m4.4.4.3.3.5a.cmml">ServerOpt</mtext><mo lspace="0em" rspace="0em" id="S3.SS2.p3.6.m4.4.4.3.3.4" xref="S3.SS2.p3.6.m4.4.4.3.3.4.cmml">â€‹</mo><mrow id="S3.SS2.p3.6.m4.4.4.3.3.3.3" xref="S3.SS2.p3.6.m4.4.4.3.3.3.4.cmml"><mo stretchy="false" id="S3.SS2.p3.6.m4.4.4.3.3.3.3.4" xref="S3.SS2.p3.6.m4.4.4.3.3.3.4.cmml">(</mo><msup id="S3.SS2.p3.6.m4.2.2.1.1.1.1.1" xref="S3.SS2.p3.6.m4.2.2.1.1.1.1.1.cmml"><mi id="S3.SS2.p3.6.m4.2.2.1.1.1.1.1.2" xref="S3.SS2.p3.6.m4.2.2.1.1.1.1.1.2.cmml">Î¸</mi><mi id="S3.SS2.p3.6.m4.2.2.1.1.1.1.1.3" xref="S3.SS2.p3.6.m4.2.2.1.1.1.1.1.3.cmml">t</mi></msup><mo id="S3.SS2.p3.6.m4.4.4.3.3.3.3.5" xref="S3.SS2.p3.6.m4.4.4.3.3.3.4.cmml">,</mo><mrow id="S3.SS2.p3.6.m4.3.3.2.2.2.2.2" xref="S3.SS2.p3.6.m4.3.3.2.2.2.2.2.cmml"><mi mathvariant="normal" id="S3.SS2.p3.6.m4.3.3.2.2.2.2.2.2" xref="S3.SS2.p3.6.m4.3.3.2.2.2.2.2.2.cmml">Î”</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.6.m4.3.3.2.2.2.2.2.1" xref="S3.SS2.p3.6.m4.3.3.2.2.2.2.2.1.cmml">â€‹</mo><msup id="S3.SS2.p3.6.m4.3.3.2.2.2.2.2.3" xref="S3.SS2.p3.6.m4.3.3.2.2.2.2.2.3.cmml"><mi id="S3.SS2.p3.6.m4.3.3.2.2.2.2.2.3.2" xref="S3.SS2.p3.6.m4.3.3.2.2.2.2.2.3.2.cmml">Î¸</mi><mi id="S3.SS2.p3.6.m4.3.3.2.2.2.2.2.3.3" xref="S3.SS2.p3.6.m4.3.3.2.2.2.2.2.3.3.cmml">t</mi></msup></mrow><mo id="S3.SS2.p3.6.m4.4.4.3.3.3.3.6" xref="S3.SS2.p3.6.m4.4.4.3.3.3.4.cmml">,</mo><msub id="S3.SS2.p3.6.m4.4.4.3.3.3.3.3" xref="S3.SS2.p3.6.m4.4.4.3.3.3.3.3.cmml"><mi id="S3.SS2.p3.6.m4.4.4.3.3.3.3.3.2" xref="S3.SS2.p3.6.m4.4.4.3.3.3.3.3.2.cmml">Î·</mi><mi id="S3.SS2.p3.6.m4.4.4.3.3.3.3.3.3" xref="S3.SS2.p3.6.m4.4.4.3.3.3.3.3.3.cmml">s</mi></msub><mo id="S3.SS2.p3.6.m4.4.4.3.3.3.3.7" xref="S3.SS2.p3.6.m4.4.4.3.3.3.4.cmml">,</mo><mi id="S3.SS2.p3.6.m4.1.1" xref="S3.SS2.p3.6.m4.1.1.cmml">t</mi><mo stretchy="false" id="S3.SS2.p3.6.m4.4.4.3.3.3.3.8" xref="S3.SS2.p3.6.m4.4.4.3.3.3.4.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.6.m4.4b"><apply id="S3.SS2.p3.6.m4.4.4.cmml" xref="S3.SS2.p3.6.m4.4.4"><ci id="S3.SS2.p3.6.m4.4.4.4.cmml" xref="S3.SS2.p3.6.m4.4.4.4">â†</ci><apply id="S3.SS2.p3.6.m4.4.4.5.cmml" xref="S3.SS2.p3.6.m4.4.4.5"><csymbol cd="ambiguous" id="S3.SS2.p3.6.m4.4.4.5.1.cmml" xref="S3.SS2.p3.6.m4.4.4.5">superscript</csymbol><ci id="S3.SS2.p3.6.m4.4.4.5.2.cmml" xref="S3.SS2.p3.6.m4.4.4.5.2">ğœƒ</ci><apply id="S3.SS2.p3.6.m4.4.4.5.3.cmml" xref="S3.SS2.p3.6.m4.4.4.5.3"><plus id="S3.SS2.p3.6.m4.4.4.5.3.1.cmml" xref="S3.SS2.p3.6.m4.4.4.5.3.1"></plus><ci id="S3.SS2.p3.6.m4.4.4.5.3.2.cmml" xref="S3.SS2.p3.6.m4.4.4.5.3.2">ğ‘¡</ci><cn type="integer" id="S3.SS2.p3.6.m4.4.4.5.3.3.cmml" xref="S3.SS2.p3.6.m4.4.4.5.3.3">1</cn></apply></apply><apply id="S3.SS2.p3.6.m4.4.4.3.cmml" xref="S3.SS2.p3.6.m4.4.4.3"><minus id="S3.SS2.p3.6.m4.4.4.3.4.cmml" xref="S3.SS2.p3.6.m4.4.4.3.4"></minus><apply id="S3.SS2.p3.6.m4.4.4.3.5.cmml" xref="S3.SS2.p3.6.m4.4.4.3.5"><csymbol cd="ambiguous" id="S3.SS2.p3.6.m4.4.4.3.5.1.cmml" xref="S3.SS2.p3.6.m4.4.4.3.5">superscript</csymbol><ci id="S3.SS2.p3.6.m4.4.4.3.5.2.cmml" xref="S3.SS2.p3.6.m4.4.4.3.5.2">ğœƒ</ci><ci id="S3.SS2.p3.6.m4.4.4.3.5.3.cmml" xref="S3.SS2.p3.6.m4.4.4.3.5.3">ğ‘¡</ci></apply><apply id="S3.SS2.p3.6.m4.4.4.3.3.cmml" xref="S3.SS2.p3.6.m4.4.4.3.3"><times id="S3.SS2.p3.6.m4.4.4.3.3.4.cmml" xref="S3.SS2.p3.6.m4.4.4.3.3.4"></times><ci id="S3.SS2.p3.6.m4.4.4.3.3.5a.cmml" xref="S3.SS2.p3.6.m4.4.4.3.3.5"><mtext class="ltx_font_smallcaps" id="S3.SS2.p3.6.m4.4.4.3.3.5.cmml" xref="S3.SS2.p3.6.m4.4.4.3.3.5">ServerOpt</mtext></ci><vector id="S3.SS2.p3.6.m4.4.4.3.3.3.4.cmml" xref="S3.SS2.p3.6.m4.4.4.3.3.3.3"><apply id="S3.SS2.p3.6.m4.2.2.1.1.1.1.1.cmml" xref="S3.SS2.p3.6.m4.2.2.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.6.m4.2.2.1.1.1.1.1.1.cmml" xref="S3.SS2.p3.6.m4.2.2.1.1.1.1.1">superscript</csymbol><ci id="S3.SS2.p3.6.m4.2.2.1.1.1.1.1.2.cmml" xref="S3.SS2.p3.6.m4.2.2.1.1.1.1.1.2">ğœƒ</ci><ci id="S3.SS2.p3.6.m4.2.2.1.1.1.1.1.3.cmml" xref="S3.SS2.p3.6.m4.2.2.1.1.1.1.1.3">ğ‘¡</ci></apply><apply id="S3.SS2.p3.6.m4.3.3.2.2.2.2.2.cmml" xref="S3.SS2.p3.6.m4.3.3.2.2.2.2.2"><times id="S3.SS2.p3.6.m4.3.3.2.2.2.2.2.1.cmml" xref="S3.SS2.p3.6.m4.3.3.2.2.2.2.2.1"></times><ci id="S3.SS2.p3.6.m4.3.3.2.2.2.2.2.2.cmml" xref="S3.SS2.p3.6.m4.3.3.2.2.2.2.2.2">Î”</ci><apply id="S3.SS2.p3.6.m4.3.3.2.2.2.2.2.3.cmml" xref="S3.SS2.p3.6.m4.3.3.2.2.2.2.2.3"><csymbol cd="ambiguous" id="S3.SS2.p3.6.m4.3.3.2.2.2.2.2.3.1.cmml" xref="S3.SS2.p3.6.m4.3.3.2.2.2.2.2.3">superscript</csymbol><ci id="S3.SS2.p3.6.m4.3.3.2.2.2.2.2.3.2.cmml" xref="S3.SS2.p3.6.m4.3.3.2.2.2.2.2.3.2">ğœƒ</ci><ci id="S3.SS2.p3.6.m4.3.3.2.2.2.2.2.3.3.cmml" xref="S3.SS2.p3.6.m4.3.3.2.2.2.2.2.3.3">ğ‘¡</ci></apply></apply><apply id="S3.SS2.p3.6.m4.4.4.3.3.3.3.3.cmml" xref="S3.SS2.p3.6.m4.4.4.3.3.3.3.3"><csymbol cd="ambiguous" id="S3.SS2.p3.6.m4.4.4.3.3.3.3.3.1.cmml" xref="S3.SS2.p3.6.m4.4.4.3.3.3.3.3">subscript</csymbol><ci id="S3.SS2.p3.6.m4.4.4.3.3.3.3.3.2.cmml" xref="S3.SS2.p3.6.m4.4.4.3.3.3.3.3.2">ğœ‚</ci><ci id="S3.SS2.p3.6.m4.4.4.3.3.3.3.3.3.cmml" xref="S3.SS2.p3.6.m4.4.4.3.3.3.3.3.3">ğ‘ </ci></apply><ci id="S3.SS2.p3.6.m4.1.1.cmml" xref="S3.SS2.p3.6.m4.1.1">ğ‘¡</ci></vector></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.6.m4.4c">\theta^{t+1}\leftarrow\theta^{t}-\textsc{ServerOpt}(\theta^{t},\Delta\theta^{t},\eta_{s},t)</annotation></semantics></math>, with <span id="S3.SS2.p3.6.1" class="ltx_text ltx_font_smallcaps">ServerOpt</span> being any gradient-based optimizer.</p>
</div>
<div id="S3.SS2.p4" class="ltx_para">
<p id="S3.SS2.p4.4" class="ltx_p">The realistic scenario considered in this work gives us the opportunity to study not only the challenges linked with the VPR task but also those derived from the federated framework. In particular, in the experiments discussed in <a href="#S5" title="5 Experiments and Results â€£ Collaborative Visual Place Recognition through Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Sec.</span>Â <span class="ltx_text ltx_ref_tag">5</span></a>, we investigate the effect of <span id="S3.SS2.p4.4.1" class="ltx_text ltx_font_italic">statistical heterogeneity</span> on the task of VPR in real-world settings where clientsâ€™ data is usually non-<span id="S3.SS2.p4.4.2" class="ltx_text ltx_font_italic">i.i.d.</span> with respect to the overall data distribution. Namely, given two clients <math id="S3.SS2.p4.1.m1.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.SS2.p4.1.m1.1a"><mi id="S3.SS2.p4.1.m1.1.1" xref="S3.SS2.p4.1.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.1.m1.1b"><ci id="S3.SS2.p4.1.m1.1.1.cmml" xref="S3.SS2.p4.1.m1.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.1.m1.1c">i</annotation></semantics></math> and <math id="S3.SS2.p4.2.m2.1" class="ltx_Math" alttext="j" display="inline"><semantics id="S3.SS2.p4.2.m2.1a"><mi id="S3.SS2.p4.2.m2.1.1" xref="S3.SS2.p4.2.m2.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.2.m2.1b"><ci id="S3.SS2.p4.2.m2.1.1.cmml" xref="S3.SS2.p4.2.m2.1.1">ğ‘—</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.2.m2.1c">j</annotation></semantics></math>, their local datasets likely follow a different distribution <math id="S3.SS2.p4.3.m3.1" class="ltx_Math" alttext="P" display="inline"><semantics id="S3.SS2.p4.3.m3.1a"><mi id="S3.SS2.p4.3.m3.1.1" xref="S3.SS2.p4.3.m3.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.3.m3.1b"><ci id="S3.SS2.p4.3.m3.1.1.cmml" xref="S3.SS2.p4.3.m3.1.1">ğ‘ƒ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.3.m3.1c">P</annotation></semantics></math>, <em id="S3.SS2.p4.4.3" class="ltx_emph ltx_font_italic">i.e.</em>, <math id="S3.SS2.p4.4.m4.1" class="ltx_Math" alttext="P_{i}\neq P_{j}" display="inline"><semantics id="S3.SS2.p4.4.m4.1a"><mrow id="S3.SS2.p4.4.m4.1.1" xref="S3.SS2.p4.4.m4.1.1.cmml"><msub id="S3.SS2.p4.4.m4.1.1.2" xref="S3.SS2.p4.4.m4.1.1.2.cmml"><mi id="S3.SS2.p4.4.m4.1.1.2.2" xref="S3.SS2.p4.4.m4.1.1.2.2.cmml">P</mi><mi id="S3.SS2.p4.4.m4.1.1.2.3" xref="S3.SS2.p4.4.m4.1.1.2.3.cmml">i</mi></msub><mo id="S3.SS2.p4.4.m4.1.1.1" xref="S3.SS2.p4.4.m4.1.1.1.cmml">â‰ </mo><msub id="S3.SS2.p4.4.m4.1.1.3" xref="S3.SS2.p4.4.m4.1.1.3.cmml"><mi id="S3.SS2.p4.4.m4.1.1.3.2" xref="S3.SS2.p4.4.m4.1.1.3.2.cmml">P</mi><mi id="S3.SS2.p4.4.m4.1.1.3.3" xref="S3.SS2.p4.4.m4.1.1.3.3.cmml">j</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.4.m4.1b"><apply id="S3.SS2.p4.4.m4.1.1.cmml" xref="S3.SS2.p4.4.m4.1.1"><neq id="S3.SS2.p4.4.m4.1.1.1.cmml" xref="S3.SS2.p4.4.m4.1.1.1"></neq><apply id="S3.SS2.p4.4.m4.1.1.2.cmml" xref="S3.SS2.p4.4.m4.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p4.4.m4.1.1.2.1.cmml" xref="S3.SS2.p4.4.m4.1.1.2">subscript</csymbol><ci id="S3.SS2.p4.4.m4.1.1.2.2.cmml" xref="S3.SS2.p4.4.m4.1.1.2.2">ğ‘ƒ</ci><ci id="S3.SS2.p4.4.m4.1.1.2.3.cmml" xref="S3.SS2.p4.4.m4.1.1.2.3">ğ‘–</ci></apply><apply id="S3.SS2.p4.4.m4.1.1.3.cmml" xref="S3.SS2.p4.4.m4.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p4.4.m4.1.1.3.1.cmml" xref="S3.SS2.p4.4.m4.1.1.3">subscript</csymbol><ci id="S3.SS2.p4.4.m4.1.1.3.2.cmml" xref="S3.SS2.p4.4.m4.1.1.3.2">ğ‘ƒ</ci><ci id="S3.SS2.p4.4.m4.1.1.3.3.cmml" xref="S3.SS2.p4.4.m4.1.1.3.3">ğ‘—</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.4.m4.1c">P_{i}\neq P_{j}</annotation></semantics></math>. Consequently, local optimization paths usually lead towards distinct local minima, straying from the global one, a phenomenon referred to as <span id="S3.SS2.p4.4.4" class="ltx_text ltx_font_italic">client drift</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">35</span></a>]</cite>. The resulting learning trends are slowed down, unstable, and subject to catastrophic forgetting.</p>
</div>
<div id="S3.SS2.p5" class="ltx_para ltx_noindent">
<p id="S3.SS2.p5.4" class="ltx_p"><span id="S3.SS2.p5.4.1" class="ltx_text ltx_font_bold">Hierarchical FL.</span> Lastly, since in our setting, the clientsâ€™ data distributions are linked with the usersâ€™ geographical locations (<em id="S3.SS2.p5.4.2" class="ltx_emph ltx_font_italic">e.g.</em>, a device likely spends most time within a single region), we additionally explore the hierarchical FL (H-FL) setup <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">14</span></a>]</cite>. In H-FL, we group clients into <math id="S3.SS2.p5.1.m1.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S3.SS2.p5.1.m1.1a"><mi id="S3.SS2.p5.1.m1.1.1" xref="S3.SS2.p5.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.1.m1.1b"><ci id="S3.SS2.p5.1.m1.1.1.cmml" xref="S3.SS2.p5.1.m1.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.1.m1.1c">K</annotation></semantics></math> clusters according to their geographical proximity. A specialized model <math id="S3.SS2.p5.2.m2.1" class="ltx_Math" alttext="F_{\theta_{c}}" display="inline"><semantics id="S3.SS2.p5.2.m2.1a"><msub id="S3.SS2.p5.2.m2.1.1" xref="S3.SS2.p5.2.m2.1.1.cmml"><mi id="S3.SS2.p5.2.m2.1.1.2" xref="S3.SS2.p5.2.m2.1.1.2.cmml">F</mi><msub id="S3.SS2.p5.2.m2.1.1.3" xref="S3.SS2.p5.2.m2.1.1.3.cmml"><mi id="S3.SS2.p5.2.m2.1.1.3.2" xref="S3.SS2.p5.2.m2.1.1.3.2.cmml">Î¸</mi><mi id="S3.SS2.p5.2.m2.1.1.3.3" xref="S3.SS2.p5.2.m2.1.1.3.3.cmml">c</mi></msub></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.2.m2.1b"><apply id="S3.SS2.p5.2.m2.1.1.cmml" xref="S3.SS2.p5.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p5.2.m2.1.1.1.cmml" xref="S3.SS2.p5.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.p5.2.m2.1.1.2.cmml" xref="S3.SS2.p5.2.m2.1.1.2">ğ¹</ci><apply id="S3.SS2.p5.2.m2.1.1.3.cmml" xref="S3.SS2.p5.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p5.2.m2.1.1.3.1.cmml" xref="S3.SS2.p5.2.m2.1.1.3">subscript</csymbol><ci id="S3.SS2.p5.2.m2.1.1.3.2.cmml" xref="S3.SS2.p5.2.m2.1.1.3.2">ğœƒ</ci><ci id="S3.SS2.p5.2.m2.1.1.3.3.cmml" xref="S3.SS2.p5.2.m2.1.1.3.3">ğ‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.2.m2.1c">F_{\theta_{c}}</annotation></semantics></math> is assigned to each cluster <math id="S3.SS2.p5.3.m3.1" class="ltx_Math" alttext="c" display="inline"><semantics id="S3.SS2.p5.3.m3.1a"><mi id="S3.SS2.p5.3.m3.1.1" xref="S3.SS2.p5.3.m3.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.3.m3.1b"><ci id="S3.SS2.p5.3.m3.1.1.cmml" xref="S3.SS2.p5.3.m3.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.3.m3.1c">c</annotation></semantics></math>. Once every <math id="S3.SS2.p5.4.m4.1" class="ltx_Math" alttext="T_{c}" display="inline"><semantics id="S3.SS2.p5.4.m4.1a"><msub id="S3.SS2.p5.4.m4.1.1" xref="S3.SS2.p5.4.m4.1.1.cmml"><mi id="S3.SS2.p5.4.m4.1.1.2" xref="S3.SS2.p5.4.m4.1.1.2.cmml">T</mi><mi id="S3.SS2.p5.4.m4.1.1.3" xref="S3.SS2.p5.4.m4.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.4.m4.1b"><apply id="S3.SS2.p5.4.m4.1.1.cmml" xref="S3.SS2.p5.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.p5.4.m4.1.1.1.cmml" xref="S3.SS2.p5.4.m4.1.1">subscript</csymbol><ci id="S3.SS2.p5.4.m4.1.1.2.cmml" xref="S3.SS2.p5.4.m4.1.1.2">ğ‘‡</ci><ci id="S3.SS2.p5.4.m4.1.1.3.cmml" xref="S3.SS2.p5.4.m4.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.4.m4.1c">T_{c}</annotation></semantics></math> rounds, the cluster-specific models are aggregated. This implies the existence of multiple servers. We explore a dual-level framework: the first-tier servers handle inter-clusters interactions (<em id="S3.SS2.p5.4.3" class="ltx_emph ltx_font_italic">e.g.</em>, among cities or continents), while second-tier ones manage the intra-cluster exchanges (<em id="S3.SS2.p5.4.4" class="ltx_emph ltx_font_italic">e.g.</em>, between users living in the same city, or continent).</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Decentralizing the MSLS dataset for FL</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">Our experiments center on the Mapillary Street-Level-Sequences (MSLS) dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib68" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">68</span></a>]</cite>, geographically distributed across 30 cities worldwide, mimicking a FL scenario.
The dataset is split into non-overlapping train, validation, and test sets. Each set comprises distinct cities: Amsterdam and Manila for validation, San Francisco and Copenhagen for testing, and the remaining cities for training.
Similar to other VPR datasets, each subset is further divided into databases and queries. Queries represent images to be localized, while databases act as the systemâ€™s prior knowledge of the area. Notably, the dataset excels due to its rich diversity. It encompasses a vast number of cities captured by various users, resulting in a wide range of cameras, weather conditions, times of day, and scenarios across both urban and rural environments. These characteristics perfectly align with the demands of our use case.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Proposed FL datasets</h3>

<figure id="S4.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S4.T1.18.1.1" class="ltx_text" style="font-size:90%;">Table 1</span>: </span><span id="S4.T1.19.2" class="ltx_text" style="font-size:90%;">Characteristics of the proposed FL+VPR datasets and associated FedAvg performances.</span></figcaption>
<div id="S4.T1.16" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:377.0pt;height:149.4pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="S4.T1.16.16" class="ltx_p"><span id="S4.T1.16.16.16" class="ltx_text">
<span id="S4.T1.16.16.16.16" class="ltx_tabular ltx_align_middle">
<span id="S4.T1.16.16.16.16.17" class="ltx_tr">
<span id="S4.T1.16.16.16.16.17.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S4.T1.16.16.16.16.17.1.1" class="ltx_text ltx_font_bold">FL dataset</span></span>
<span id="S4.T1.16.16.16.16.17.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T1.16.16.16.16.17.2.1" class="ltx_text"></span> <span id="S4.T1.16.16.16.16.17.2.2" class="ltx_text">
<span id="S4.T1.16.16.16.16.17.2.2.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T1.16.16.16.16.17.2.2.1.1" class="ltx_tr">
<span id="S4.T1.16.16.16.16.17.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T1.16.16.16.16.17.2.2.1.1.1.1" class="ltx_text ltx_font_bold">Radius</span></span></span>
<span id="S4.T1.16.16.16.16.17.2.2.1.2" class="ltx_tr">
<span id="S4.T1.16.16.16.16.17.2.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T1.16.16.16.16.17.2.2.1.2.1.1" class="ltx_text ltx_font_bold">(m)</span></span></span>
</span></span><span id="S4.T1.16.16.16.16.17.2.3" class="ltx_text"></span></span>
<span id="S4.T1.16.16.16.16.17.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T1.16.16.16.16.17.3.1" class="ltx_text"></span> <span id="S4.T1.16.16.16.16.17.3.2" class="ltx_text">
<span id="S4.T1.16.16.16.16.17.3.2.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T1.16.16.16.16.17.3.2.1.1" class="ltx_tr">
<span id="S4.T1.16.16.16.16.17.3.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T1.16.16.16.16.17.3.2.1.1.1.1" class="ltx_text ltx_font_bold">Sequences</span></span></span>
<span id="S4.T1.16.16.16.16.17.3.2.1.2" class="ltx_tr">
<span id="S4.T1.16.16.16.16.17.3.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T1.16.16.16.16.17.3.2.1.2.1.1" class="ltx_text ltx_font_bold">per client</span></span></span>
</span></span><span id="S4.T1.16.16.16.16.17.3.3" class="ltx_text"></span></span>
<span id="S4.T1.16.16.16.16.17.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T1.16.16.16.16.17.4.1" class="ltx_text"></span> <span id="S4.T1.16.16.16.16.17.4.2" class="ltx_text">
<span id="S4.T1.16.16.16.16.17.4.2.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T1.16.16.16.16.17.4.2.1.1" class="ltx_tr">
<span id="S4.T1.16.16.16.16.17.4.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T1.16.16.16.16.17.4.2.1.1.1.1" class="ltx_text ltx_font_bold">Images</span></span></span>
<span id="S4.T1.16.16.16.16.17.4.2.1.2" class="ltx_tr">
<span id="S4.T1.16.16.16.16.17.4.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T1.16.16.16.16.17.4.2.1.2.1.1" class="ltx_text ltx_font_bold">per client</span></span></span>
</span></span><span id="S4.T1.16.16.16.16.17.4.3" class="ltx_text"></span></span>
<span id="S4.T1.16.16.16.16.17.5" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T1.16.16.16.16.17.5.1" class="ltx_text"></span> <span id="S4.T1.16.16.16.16.17.5.2" class="ltx_text">
<span id="S4.T1.16.16.16.16.17.5.2.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T1.16.16.16.16.17.5.2.1.1" class="ltx_tr">
<span id="S4.T1.16.16.16.16.17.5.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T1.16.16.16.16.17.5.2.1.1.1.1" class="ltx_text ltx_font_bold">Number of</span></span></span>
<span id="S4.T1.16.16.16.16.17.5.2.1.2" class="ltx_tr">
<span id="S4.T1.16.16.16.16.17.5.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T1.16.16.16.16.17.5.2.1.2.1.1" class="ltx_text ltx_font_bold">clients</span></span></span>
</span></span><span id="S4.T1.16.16.16.16.17.5.3" class="ltx_text"></span></span>
<span id="S4.T1.16.16.16.16.17.6" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T1.16.16.16.16.17.6.1" class="ltx_text ltx_font_bold">R@1 (%)</span></span></span>
<span id="S4.T1.1.1.1.1.1" class="ltx_tr" style="background-color:#EBEBEB;">
<span id="S4.T1.1.1.1.1.1.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T1.1.1.1.1.1.2.1" class="ltx_text" style="background-color:#EBEBEB;">Centralized</span></span>
<span id="S4.T1.1.1.1.1.1.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.1.1.1.1.1.3.1" class="ltx_text" style="background-color:#EBEBEB;">-</span></span>
<span id="S4.T1.1.1.1.1.1.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.1.1.1.1.1.4.1" class="ltx_text" style="background-color:#EBEBEB;">-</span></span>
<span id="S4.T1.1.1.1.1.1.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.1.1.1.1.1.5.1" class="ltx_text" style="background-color:#EBEBEB;">-</span></span>
<span id="S4.T1.1.1.1.1.1.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.1.1.1.1.1.6.1" class="ltx_text" style="background-color:#EBEBEB;">-</span></span>
<span id="S4.T1.1.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.1.1.1.1.1.1.1" class="ltx_text" style="background-color:#EBEBEB;">66.0 <math id="S4.T1.1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T1.1.1.1.1.1.1.1.m1.1a"><mo mathbackground="#EBEBEB" mathsize="70%" id="S4.T1.1.1.1.1.1.1.1.m1.1.1" xref="S4.T1.1.1.1.1.1.1.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S4.T1.1.1.1.1.1.1.1.m1.1b"><csymbol cd="latexml" id="S4.T1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S4.T1.1.1.1.1.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.1.1.1.1.1.1.1.m1.1c">\pm</annotation></semantics></math><span id="S4.T1.1.1.1.1.1.1.1.1" class="ltx_text" style="font-size:70%;background-color:#EBEBEB;"> 0.4</span></span></span></span>
<span id="S4.T1.4.4.4.4.4" class="ltx_tr">
<span id="S4.T1.4.4.4.4.4.4" class="ltx_td ltx_align_left ltx_border_t">Random</span>
<span id="S4.T1.4.4.4.4.4.5" class="ltx_td ltx_align_center ltx_border_t">-</span>
<span id="S4.T1.2.2.2.2.2.1" class="ltx_td ltx_align_center ltx_border_t">64 <math id="S4.T1.2.2.2.2.2.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T1.2.2.2.2.2.1.m1.1a"><mo mathsize="70%" id="S4.T1.2.2.2.2.2.1.m1.1.1" xref="S4.T1.2.2.2.2.2.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S4.T1.2.2.2.2.2.1.m1.1b"><csymbol cd="latexml" id="S4.T1.2.2.2.2.2.1.m1.1.1.cmml" xref="S4.T1.2.2.2.2.2.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.2.2.2.2.2.1.m1.1c">\pm</annotation></semantics></math><span id="S4.T1.2.2.2.2.2.1.1" class="ltx_text" style="font-size:70%;"> 1</span></span>
<span id="S4.T1.3.3.3.3.3.2" class="ltx_td ltx_align_center ltx_border_t">3655 <math id="S4.T1.3.3.3.3.3.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T1.3.3.3.3.3.2.m1.1a"><mo mathsize="70%" id="S4.T1.3.3.3.3.3.2.m1.1.1" xref="S4.T1.3.3.3.3.3.2.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S4.T1.3.3.3.3.3.2.m1.1b"><csymbol cd="latexml" id="S4.T1.3.3.3.3.3.2.m1.1.1.cmml" xref="S4.T1.3.3.3.3.3.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.3.3.3.3.3.2.m1.1c">\pm</annotation></semantics></math><span id="S4.T1.3.3.3.3.3.2.1" class="ltx_text" style="font-size:70%;"> 676</span></span>
<span id="S4.T1.4.4.4.4.4.6" class="ltx_td ltx_align_center ltx_border_t">700</span>
<span id="S4.T1.4.4.4.4.4.3" class="ltx_td ltx_align_center ltx_border_t">40.2 <math id="S4.T1.4.4.4.4.4.3.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T1.4.4.4.4.4.3.m1.1a"><mo mathsize="70%" id="S4.T1.4.4.4.4.4.3.m1.1.1" xref="S4.T1.4.4.4.4.4.3.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S4.T1.4.4.4.4.4.3.m1.1b"><csymbol cd="latexml" id="S4.T1.4.4.4.4.4.3.m1.1.1.cmml" xref="S4.T1.4.4.4.4.4.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.4.4.4.4.4.3.m1.1c">\pm</annotation></semantics></math><span id="S4.T1.4.4.4.4.4.3.1" class="ltx_text" style="font-size:70%;"> 0.0</span></span></span>
<span id="S4.T1.7.7.7.7.7" class="ltx_tr">
<span id="S4.T1.7.7.7.7.7.4" class="ltx_td ltx_align_left ltx_border_t">Clustering</span>
<span id="S4.T1.7.7.7.7.7.5" class="ltx_td ltx_align_center ltx_border_t">-</span>
<span id="S4.T1.5.5.5.5.5.1" class="ltx_td ltx_align_center ltx_border_t">36 <math id="S4.T1.5.5.5.5.5.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T1.5.5.5.5.5.1.m1.1a"><mo mathsize="70%" id="S4.T1.5.5.5.5.5.1.m1.1.1" xref="S4.T1.5.5.5.5.5.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S4.T1.5.5.5.5.5.1.m1.1b"><csymbol cd="latexml" id="S4.T1.5.5.5.5.5.1.m1.1.1.cmml" xref="S4.T1.5.5.5.5.5.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.5.5.5.5.5.1.m1.1c">\pm</annotation></semantics></math><span id="S4.T1.5.5.5.5.5.1.1" class="ltx_text" style="font-size:70%;"> 32</span></span>
<span id="S4.T1.6.6.6.6.6.2" class="ltx_td ltx_align_center ltx_border_t">2018 <math id="S4.T1.6.6.6.6.6.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T1.6.6.6.6.6.2.m1.1a"><mo mathsize="70%" id="S4.T1.6.6.6.6.6.2.m1.1.1" xref="S4.T1.6.6.6.6.6.2.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S4.T1.6.6.6.6.6.2.m1.1b"><csymbol cd="latexml" id="S4.T1.6.6.6.6.6.2.m1.1.1.cmml" xref="S4.T1.6.6.6.6.6.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.6.6.6.6.6.2.m1.1c">\pm</annotation></semantics></math><span id="S4.T1.6.6.6.6.6.2.1" class="ltx_text" style="font-size:70%;"> 1266</span></span>
<span id="S4.T1.7.7.7.7.7.6" class="ltx_td ltx_align_center ltx_border_t">678</span>
<span id="S4.T1.7.7.7.7.7.3" class="ltx_td ltx_align_center ltx_border_t">57.3 <math id="S4.T1.7.7.7.7.7.3.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T1.7.7.7.7.7.3.m1.1a"><mo mathsize="70%" id="S4.T1.7.7.7.7.7.3.m1.1.1" xref="S4.T1.7.7.7.7.7.3.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S4.T1.7.7.7.7.7.3.m1.1b"><csymbol cd="latexml" id="S4.T1.7.7.7.7.7.3.m1.1.1.cmml" xref="S4.T1.7.7.7.7.7.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.7.7.7.7.7.3.m1.1c">\pm</annotation></semantics></math><span id="S4.T1.7.7.7.7.7.3.1" class="ltx_text" style="font-size:70%;"> 1.2</span></span></span>
<span id="S4.T1.10.10.10.10.10" class="ltx_tr">
<span id="S4.T1.10.10.10.10.10.4" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t ltx_rowspan ltx_rowspan_3"><span id="S4.T1.10.10.10.10.10.4.1" class="ltx_text">Proximity</span></span>
<span id="S4.T1.10.10.10.10.10.5" class="ltx_td ltx_align_center ltx_border_t">1000</span>
<span id="S4.T1.8.8.8.8.8.1" class="ltx_td ltx_align_center ltx_border_t">17 <math id="S4.T1.8.8.8.8.8.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T1.8.8.8.8.8.1.m1.1a"><mo mathsize="70%" id="S4.T1.8.8.8.8.8.1.m1.1.1" xref="S4.T1.8.8.8.8.8.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S4.T1.8.8.8.8.8.1.m1.1b"><csymbol cd="latexml" id="S4.T1.8.8.8.8.8.1.m1.1.1.cmml" xref="S4.T1.8.8.8.8.8.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.8.8.8.8.8.1.m1.1c">\pm</annotation></semantics></math><span id="S4.T1.8.8.8.8.8.1.1" class="ltx_text" style="font-size:70%;"> 18</span></span>
<span id="S4.T1.9.9.9.9.9.2" class="ltx_td ltx_align_center ltx_border_t">897 <math id="S4.T1.9.9.9.9.9.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T1.9.9.9.9.9.2.m1.1a"><mo mathsize="70%" id="S4.T1.9.9.9.9.9.2.m1.1.1" xref="S4.T1.9.9.9.9.9.2.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S4.T1.9.9.9.9.9.2.m1.1b"><csymbol cd="latexml" id="S4.T1.9.9.9.9.9.2.m1.1.1.cmml" xref="S4.T1.9.9.9.9.9.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.9.9.9.9.9.2.m1.1c">\pm</annotation></semantics></math><span id="S4.T1.9.9.9.9.9.2.1" class="ltx_text" style="font-size:70%;"> 808</span></span>
<span id="S4.T1.10.10.10.10.10.6" class="ltx_td ltx_align_center ltx_border_t">1303</span>
<span id="S4.T1.10.10.10.10.10.3" class="ltx_td ltx_align_center ltx_border_t">51.7 <math id="S4.T1.10.10.10.10.10.3.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T1.10.10.10.10.10.3.m1.1a"><mo mathsize="70%" id="S4.T1.10.10.10.10.10.3.m1.1.1" xref="S4.T1.10.10.10.10.10.3.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S4.T1.10.10.10.10.10.3.m1.1b"><csymbol cd="latexml" id="S4.T1.10.10.10.10.10.3.m1.1.1.cmml" xref="S4.T1.10.10.10.10.10.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.10.10.10.10.10.3.m1.1c">\pm</annotation></semantics></math><span id="S4.T1.10.10.10.10.10.3.1" class="ltx_text" style="font-size:70%;"> 1.7</span></span></span>
<span id="S4.T1.13.13.13.13.13" class="ltx_tr">
<span id="S4.T1.13.13.13.13.13.4" class="ltx_td ltx_align_center">2000</span>
<span id="S4.T1.11.11.11.11.11.1" class="ltx_td ltx_align_center">33 <math id="S4.T1.11.11.11.11.11.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T1.11.11.11.11.11.1.m1.1a"><mo mathsize="70%" id="S4.T1.11.11.11.11.11.1.m1.1.1" xref="S4.T1.11.11.11.11.11.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S4.T1.11.11.11.11.11.1.m1.1b"><csymbol cd="latexml" id="S4.T1.11.11.11.11.11.1.m1.1.1.cmml" xref="S4.T1.11.11.11.11.11.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.11.11.11.11.11.1.m1.1c">\pm</annotation></semantics></math><span id="S4.T1.11.11.11.11.11.1.1" class="ltx_text" style="font-size:70%;"> 48</span></span>
<span id="S4.T1.12.12.12.12.12.2" class="ltx_td ltx_align_center">1834 <math id="S4.T1.12.12.12.12.12.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T1.12.12.12.12.12.2.m1.1a"><mo mathsize="70%" id="S4.T1.12.12.12.12.12.2.m1.1.1" xref="S4.T1.12.12.12.12.12.2.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S4.T1.12.12.12.12.12.2.m1.1b"><csymbol cd="latexml" id="S4.T1.12.12.12.12.12.2.m1.1.1.cmml" xref="S4.T1.12.12.12.12.12.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.12.12.12.12.12.2.m1.1c">\pm</annotation></semantics></math><span id="S4.T1.12.12.12.12.12.2.1" class="ltx_text" style="font-size:70%;"> 2050</span></span>
<span id="S4.T1.13.13.13.13.13.5" class="ltx_td ltx_align_center">713</span>
<span id="S4.T1.13.13.13.13.13.3" class="ltx_td ltx_align_center">61.0 <math id="S4.T1.13.13.13.13.13.3.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T1.13.13.13.13.13.3.m1.1a"><mo mathsize="70%" id="S4.T1.13.13.13.13.13.3.m1.1.1" xref="S4.T1.13.13.13.13.13.3.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S4.T1.13.13.13.13.13.3.m1.1b"><csymbol cd="latexml" id="S4.T1.13.13.13.13.13.3.m1.1.1.cmml" xref="S4.T1.13.13.13.13.13.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.13.13.13.13.13.3.m1.1c">\pm</annotation></semantics></math><span id="S4.T1.13.13.13.13.13.3.1" class="ltx_text" style="font-size:70%;"> 0.6</span></span></span>
<span id="S4.T1.16.16.16.16.16" class="ltx_tr">
<span id="S4.T1.16.16.16.16.16.4" class="ltx_td ltx_align_center ltx_border_bb">4000</span>
<span id="S4.T1.14.14.14.14.14.1" class="ltx_td ltx_align_center ltx_border_bb">75 <math id="S4.T1.14.14.14.14.14.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T1.14.14.14.14.14.1.m1.1a"><mo mathsize="70%" id="S4.T1.14.14.14.14.14.1.m1.1.1" xref="S4.T1.14.14.14.14.14.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S4.T1.14.14.14.14.14.1.m1.1b"><csymbol cd="latexml" id="S4.T1.14.14.14.14.14.1.m1.1.1.cmml" xref="S4.T1.14.14.14.14.14.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.14.14.14.14.14.1.m1.1c">\pm</annotation></semantics></math><span id="S4.T1.14.14.14.14.14.1.1" class="ltx_text" style="font-size:70%;"> 148</span></span>
<span id="S4.T1.15.15.15.15.15.2" class="ltx_td ltx_align_center ltx_border_bb">4270 <math id="S4.T1.15.15.15.15.15.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T1.15.15.15.15.15.2.m1.1a"><mo mathsize="70%" id="S4.T1.15.15.15.15.15.2.m1.1.1" xref="S4.T1.15.15.15.15.15.2.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S4.T1.15.15.15.15.15.2.m1.1b"><csymbol cd="latexml" id="S4.T1.15.15.15.15.15.2.m1.1.1.cmml" xref="S4.T1.15.15.15.15.15.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.15.15.15.15.15.2.m1.1c">\pm</annotation></semantics></math><span id="S4.T1.15.15.15.15.15.2.1" class="ltx_text" style="font-size:70%;"> 6515</span></span>
<span id="S4.T1.16.16.16.16.16.5" class="ltx_td ltx_align_center ltx_border_bb">316</span>
<span id="S4.T1.16.16.16.16.16.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T1.16.16.16.16.16.3.1" class="ltx_text ltx_font_bold">66.1 <math id="S4.T1.16.16.16.16.16.3.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T1.16.16.16.16.16.3.1.m1.1a"><mo mathsize="70%" id="S4.T1.16.16.16.16.16.3.1.m1.1.1" xref="S4.T1.16.16.16.16.16.3.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S4.T1.16.16.16.16.16.3.1.m1.1b"><csymbol cd="latexml" id="S4.T1.16.16.16.16.16.3.1.m1.1.1.cmml" xref="S4.T1.16.16.16.16.16.3.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.16.16.16.16.16.3.1.m1.1c">\pm</annotation></semantics></math><span id="S4.T1.16.16.16.16.16.3.1.1" class="ltx_text" style="font-size:70%;"> 0.3</span></span></span></span>
</span></span></p>
</span></div>
</figure>
<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">This workâ€™s first contribution lies in proposing three novel splits for the MSLS dataset. These splits mimic real-world scenarios with varying data distributions across devices. Users are grouped based on geographical <span id="S4.SS1.p1.1.1" class="ltx_text ltx_font_italic">proximity</span>, <span id="S4.SS1.p1.1.2" class="ltx_text ltx_font_italic">similarity</span> in city features (<em id="S4.SS1.p1.1.3" class="ltx_emph ltx_font_italic">e.g</em>.<span id="S4.SS1.p1.1.4" class="ltx_text"></span>, architecture), or <span id="S4.SS1.p1.1.5" class="ltx_text ltx_font_italic">randomness</span>. <a href="#S4.T1" title="In 4.1 Proposed FL datasets â€£ 4 Decentralizing the MSLS dataset for FL â€£ Collaborative Visual Place Recognition through Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">1</span></a> summarizes the datasetsâ€™ characteristics. Additional analyses can be found in <a href="#A3" title="Appendix C Distribution of clients in federated MSLS â€£ Collaborative Visual Place Recognition through Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Appendix</span>Â <span class="ltx_text ltx_ref_tag">C</span></a>.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para ltx_noindent">
<p id="S4.SS1.p2.1" class="ltx_p"><span id="S4.SS1.p2.1.1" class="ltx_text ltx_font_bold">Proximity.</span> This split emulates user movements within a neighborhood or a proximal geographical area. While clients in smaller towns may explore different localities, users in large cities like Tokyo or San Francisco are inclined to stay within their neighborhoods.
The MSLS dataset is first divided geographically, with each city representing a separate entity. Within each city, clients are formed iteratively. An initial query image is chosen from a sequence available in that city. All other geographically close sequences, <em id="S4.SS1.p2.1.2" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S4.SS1.p2.1.3" class="ltx_text"></span>, within a given radius from the coordinates of the selected image, are then grouped with the chosen query image. This group is considered a valid client only if it contains at least two queries and two database sequences.
The resulting number of training clients depends on the chosen radius, which we select in <math id="S4.SS1.p2.1.m1.3" class="ltx_Math" alttext="\{1000,2000,4000\}" display="inline"><semantics id="S4.SS1.p2.1.m1.3a"><mrow id="S4.SS1.p2.1.m1.3.4.2" xref="S4.SS1.p2.1.m1.3.4.1.cmml"><mo stretchy="false" id="S4.SS1.p2.1.m1.3.4.2.1" xref="S4.SS1.p2.1.m1.3.4.1.cmml">{</mo><mn id="S4.SS1.p2.1.m1.1.1" xref="S4.SS1.p2.1.m1.1.1.cmml">1000</mn><mo id="S4.SS1.p2.1.m1.3.4.2.2" xref="S4.SS1.p2.1.m1.3.4.1.cmml">,</mo><mn id="S4.SS1.p2.1.m1.2.2" xref="S4.SS1.p2.1.m1.2.2.cmml">2000</mn><mo id="S4.SS1.p2.1.m1.3.4.2.3" xref="S4.SS1.p2.1.m1.3.4.1.cmml">,</mo><mn id="S4.SS1.p2.1.m1.3.3" xref="S4.SS1.p2.1.m1.3.3.cmml">4000</mn><mo stretchy="false" id="S4.SS1.p2.1.m1.3.4.2.4" xref="S4.SS1.p2.1.m1.3.4.1.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.1.m1.3b"><set id="S4.SS1.p2.1.m1.3.4.1.cmml" xref="S4.SS1.p2.1.m1.3.4.2"><cn type="integer" id="S4.SS1.p2.1.m1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1">1000</cn><cn type="integer" id="S4.SS1.p2.1.m1.2.2.cmml" xref="S4.SS1.p2.1.m1.2.2">2000</cn><cn type="integer" id="S4.SS1.p2.1.m1.3.3.cmml" xref="S4.SS1.p2.1.m1.3.3">4000</cn></set></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.1.m1.3c">\{1000,2000,4000\}</annotation></semantics></math> meters. Twelve clients are randomly selected from the pool of validated training clients to serve as the validation set. The test set is kept on the server side.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para ltx_noindent">
<p id="S4.SS1.p3.3" class="ltx_p"><span id="S4.SS1.p3.3.1" class="ltx_text ltx_font_bold">Clustering.</span> The proximity split assumes similar features (<em id="S4.SS1.p3.3.2" class="ltx_emph ltx_font_italic">e.g</em>.<span id="S4.SS1.p3.3.3" class="ltx_text"></span>, architecture) in nearby areas. However, distant neighborhoods might share more similarities (<em id="S4.SS1.p3.3.4" class="ltx_emph ltx_font_italic">e.g</em>.<span id="S4.SS1.p3.3.5" class="ltx_text"></span>, busy streets, shops) than geographically close ones. To capture such nuances, the clustering split utilizes the <math id="S4.SS1.p3.1.m1.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S4.SS1.p3.1.m1.1a"><mi id="S4.SS1.p3.1.m1.1.1" xref="S4.SS1.p3.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.1.m1.1b"><ci id="S4.SS1.p3.1.m1.1.1.cmml" xref="S4.SS1.p3.1.m1.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.1.m1.1c">K</annotation></semantics></math>-means algorithm <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib50" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">50</span></a>]</cite> at the city level, grouping images based on their visual and environmental characteristics. To ensure a balanced number of clients while capturing similarities, we determine the value of <math id="S4.SS1.p3.2.m2.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S4.SS1.p3.2.m2.1a"><mi id="S4.SS1.p3.2.m2.1.1" xref="S4.SS1.p3.2.m2.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.2.m2.1b"><ci id="S4.SS1.p3.2.m2.1.1.cmml" xref="S4.SS1.p3.2.m2.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.2.m2.1c">K</annotation></semantics></math> (number of clusters) for each city individually. We use the number of clients obtained in the proximity split with a radius of 2000 meters as a reference point, <em id="S4.SS1.p3.3.6" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S4.SS1.p3.3.7" class="ltx_text"></span>, <math id="S4.SS1.p3.3.m3.1" class="ltx_Math" alttext="K=713" display="inline"><semantics id="S4.SS1.p3.3.m3.1a"><mrow id="S4.SS1.p3.3.m3.1.1" xref="S4.SS1.p3.3.m3.1.1.cmml"><mi id="S4.SS1.p3.3.m3.1.1.2" xref="S4.SS1.p3.3.m3.1.1.2.cmml">K</mi><mo id="S4.SS1.p3.3.m3.1.1.1" xref="S4.SS1.p3.3.m3.1.1.1.cmml">=</mo><mn id="S4.SS1.p3.3.m3.1.1.3" xref="S4.SS1.p3.3.m3.1.1.3.cmml">713</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.3.m3.1b"><apply id="S4.SS1.p3.3.m3.1.1.cmml" xref="S4.SS1.p3.3.m3.1.1"><eq id="S4.SS1.p3.3.m3.1.1.1.cmml" xref="S4.SS1.p3.3.m3.1.1.1"></eq><ci id="S4.SS1.p3.3.m3.1.1.2.cmml" xref="S4.SS1.p3.3.m3.1.1.2">ğ¾</ci><cn type="integer" id="S4.SS1.p3.3.m3.1.1.3.cmml" xref="S4.SS1.p3.3.m3.1.1.3">713</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.3.m3.1c">K=713</annotation></semantics></math>. The same selection criterion of the proximity split is then applied to define the valid clients. 12 clients are maintained for validation, and the test set is on the server.</p>
</div>
<div id="S4.SS1.p4" class="ltx_para ltx_noindent">
<p id="S4.SS1.p4.1" class="ltx_p"><span id="S4.SS1.p4.1.1" class="ltx_text ltx_font_bold">Random.</span> Following the approach of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">31</span></a>, <a href="#bib.bib24" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">24</span></a>, <a href="#bib.bib23" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">23</span></a>]</cite>, we introduce a <span id="S4.SS1.p4.1.2" class="ltx_text ltx_font_italic">random</span> split of MSLS to emulate a uniform distribution and facilitate the understanding of the effects of statistical heterogeneity induced by domain shift. Each datasetâ€™s client includes images from all cities, and validation is conducted on the same local dataset. If a city does not have enough data for all clients, we duplicate existing sequences until each client can access at least one sequence from each city. Any remaining sequences are redistributed among clients. The test set remains on the server side.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Experiments and Results</h2>

<figure id="S5.T2" class="ltx_table">

<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S5.T2.11.1.1" class="ltx_text" style="font-size:90%;">Table 2</span>: </span><span id="S5.T2.12.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Centralized baselines<span id="S5.T2.12.2.1" class="ltx_text ltx_font_medium">.
Comparison of different model architectures (<span id="S5.T2.12.2.1.1" class="ltx_text ltx_font_italic">left</span>) and pooling layers (<span id="S5.T2.12.2.1.2" class="ltx_text ltx_font_italic">right</span>) in terms of recall. The average pooling layer is used for the architecture comparison on the left, and ResNet18 truncated on the right. </span></span></figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S5.T2.3" class="ltx_table ltx_figure_panel ltx_align_center">
<div id="S5.T2.3.3" class="ltx_inline-block ltx_transformed_outer" style="width:229.1pt;height:72pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="S5.T2.3.3.3" class="ltx_p"><span id="S5.T2.3.3.3.3" class="ltx_text">
<span id="S5.T2.3.3.3.3.3" class="ltx_tabular ltx_align_middle">
<span id="S5.T2.3.3.3.3.3.4" class="ltx_tr">
<span id="S5.T2.3.3.3.3.3.4.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S5.T2.3.3.3.3.3.4.1.1" class="ltx_text ltx_font_bold">Backbone</span></span>
<span id="S5.T2.3.3.3.3.3.4.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S5.T2.3.3.3.3.3.4.2.1" class="ltx_text ltx_font_bold">R@1</span></span>
<span id="S5.T2.3.3.3.3.3.4.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S5.T2.3.3.3.3.3.4.3.1" class="ltx_text ltx_font_bold">Total</span></span>
<span id="S5.T2.3.3.3.3.3.4.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S5.T2.3.3.3.3.3.4.4.1" class="ltx_text ltx_font_bold">Trained</span></span></span>
<span id="S5.T2.1.1.1.1.1.1" class="ltx_tr">
<span id="S5.T2.1.1.1.1.1.1.2" class="ltx_td ltx_align_left ltx_border_t">ResNet18 trunc.</span>
<span id="S5.T2.1.1.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_t"><math id="S5.T2.1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="42.9\pm 2.5" display="inline"><semantics id="S5.T2.1.1.1.1.1.1.1.m1.1a"><mrow id="S5.T2.1.1.1.1.1.1.1.m1.1.1" xref="S5.T2.1.1.1.1.1.1.1.m1.1.1.cmml"><mn id="S5.T2.1.1.1.1.1.1.1.m1.1.1.2" xref="S5.T2.1.1.1.1.1.1.1.m1.1.1.2.cmml">42.9</mn><mo id="S5.T2.1.1.1.1.1.1.1.m1.1.1.1" xref="S5.T2.1.1.1.1.1.1.1.m1.1.1.1.cmml">Â±</mo><mn id="S5.T2.1.1.1.1.1.1.1.m1.1.1.3" xref="S5.T2.1.1.1.1.1.1.1.m1.1.1.3.cmml">2.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.1.1.1.1.1.1.1.m1.1b"><apply id="S5.T2.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S5.T2.1.1.1.1.1.1.1.m1.1.1"><csymbol cd="latexml" id="S5.T2.1.1.1.1.1.1.1.m1.1.1.1.cmml" xref="S5.T2.1.1.1.1.1.1.1.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S5.T2.1.1.1.1.1.1.1.m1.1.1.2.cmml" xref="S5.T2.1.1.1.1.1.1.1.m1.1.1.2">42.9</cn><cn type="float" id="S5.T2.1.1.1.1.1.1.1.m1.1.1.3.cmml" xref="S5.T2.1.1.1.1.1.1.1.m1.1.1.3">2.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.1.1.1.1.1.1.1.m1.1c">42.9\pm 2.5</annotation></semantics></math></span>
<span id="S5.T2.1.1.1.1.1.1.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T2.1.1.1.1.1.1.3.1" class="ltx_text ltx_font_bold">2.8M</span></span>
<span id="S5.T2.1.1.1.1.1.1.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T2.1.1.1.1.1.1.4.1" class="ltx_text ltx_font_bold">2.1M</span></span></span>
<span id="S5.T2.2.2.2.2.2.2" class="ltx_tr">
<span id="S5.T2.2.2.2.2.2.2.2" class="ltx_td ltx_align_left">ResNet18</span>
<span id="S5.T2.2.2.2.2.2.2.1" class="ltx_td ltx_align_center"><math id="S5.T2.2.2.2.2.2.2.1.m1.1" class="ltx_Math" alttext="\textbf{60.1}\pm\textbf{0.3}" display="inline"><semantics id="S5.T2.2.2.2.2.2.2.1.m1.1a"><mrow id="S5.T2.2.2.2.2.2.2.1.m1.1.1" xref="S5.T2.2.2.2.2.2.2.1.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S5.T2.2.2.2.2.2.2.1.m1.1.1.2" xref="S5.T2.2.2.2.2.2.2.1.m1.1.1.2a.cmml">60.1</mtext><mo id="S5.T2.2.2.2.2.2.2.1.m1.1.1.1" xref="S5.T2.2.2.2.2.2.2.1.m1.1.1.1.cmml">Â±</mo><mtext class="ltx_mathvariant_bold" id="S5.T2.2.2.2.2.2.2.1.m1.1.1.3" xref="S5.T2.2.2.2.2.2.2.1.m1.1.1.3a.cmml">0.3</mtext></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.2.2.2.2.2.2.1.m1.1b"><apply id="S5.T2.2.2.2.2.2.2.1.m1.1.1.cmml" xref="S5.T2.2.2.2.2.2.2.1.m1.1.1"><csymbol cd="latexml" id="S5.T2.2.2.2.2.2.2.1.m1.1.1.1.cmml" xref="S5.T2.2.2.2.2.2.2.1.m1.1.1.1">plus-or-minus</csymbol><ci id="S5.T2.2.2.2.2.2.2.1.m1.1.1.2a.cmml" xref="S5.T2.2.2.2.2.2.2.1.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S5.T2.2.2.2.2.2.2.1.m1.1.1.2.cmml" xref="S5.T2.2.2.2.2.2.2.1.m1.1.1.2">60.1</mtext></ci><ci id="S5.T2.2.2.2.2.2.2.1.m1.1.1.3a.cmml" xref="S5.T2.2.2.2.2.2.2.1.m1.1.1.3"><mtext class="ltx_mathvariant_bold" id="S5.T2.2.2.2.2.2.2.1.m1.1.1.3.cmml" xref="S5.T2.2.2.2.2.2.2.1.m1.1.1.3">0.3</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.2.2.2.2.2.2.1.m1.1c">\textbf{60.1}\pm\textbf{0.3}</annotation></semantics></math></span>
<span id="S5.T2.2.2.2.2.2.2.3" class="ltx_td ltx_align_center">11.2M</span>
<span id="S5.T2.2.2.2.2.2.2.4" class="ltx_td ltx_align_center">10M</span></span>
<span id="S5.T2.3.3.3.3.3.3" class="ltx_tr">
<span id="S5.T2.3.3.3.3.3.3.2" class="ltx_td ltx_align_left ltx_border_bb">VGG16</span>
<span id="S5.T2.3.3.3.3.3.3.1" class="ltx_td ltx_align_center ltx_border_bb"><math id="S5.T2.3.3.3.3.3.3.1.m1.1" class="ltx_Math" alttext="46.3\pm 0.5" display="inline"><semantics id="S5.T2.3.3.3.3.3.3.1.m1.1a"><mrow id="S5.T2.3.3.3.3.3.3.1.m1.1.1" xref="S5.T2.3.3.3.3.3.3.1.m1.1.1.cmml"><mn id="S5.T2.3.3.3.3.3.3.1.m1.1.1.2" xref="S5.T2.3.3.3.3.3.3.1.m1.1.1.2.cmml">46.3</mn><mo id="S5.T2.3.3.3.3.3.3.1.m1.1.1.1" xref="S5.T2.3.3.3.3.3.3.1.m1.1.1.1.cmml">Â±</mo><mn id="S5.T2.3.3.3.3.3.3.1.m1.1.1.3" xref="S5.T2.3.3.3.3.3.3.1.m1.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.3.3.3.3.3.3.1.m1.1b"><apply id="S5.T2.3.3.3.3.3.3.1.m1.1.1.cmml" xref="S5.T2.3.3.3.3.3.3.1.m1.1.1"><csymbol cd="latexml" id="S5.T2.3.3.3.3.3.3.1.m1.1.1.1.cmml" xref="S5.T2.3.3.3.3.3.3.1.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S5.T2.3.3.3.3.3.3.1.m1.1.1.2.cmml" xref="S5.T2.3.3.3.3.3.3.1.m1.1.1.2">46.3</cn><cn type="float" id="S5.T2.3.3.3.3.3.3.1.m1.1.1.3.cmml" xref="S5.T2.3.3.3.3.3.3.1.m1.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.3.3.3.3.3.3.1.m1.1c">46.3\pm 0.5</annotation></semantics></math></span>
<span id="S5.T2.3.3.3.3.3.3.3" class="ltx_td ltx_align_center ltx_border_bb">14.7M</span>
<span id="S5.T2.3.3.3.3.3.3.4" class="ltx_td ltx_align_center ltx_border_bb">7M</span></span>
</span></span></p>
</span></div>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S5.T2.6" class="ltx_table ltx_figure_panel ltx_align_center">
<div id="S5.T2.6.3" class="ltx_inline-block ltx_transformed_outer" style="width:267.5pt;height:72pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="S5.T2.6.3.3" class="ltx_p"><span id="S5.T2.6.3.3.3" class="ltx_text">
<span id="S5.T2.6.3.3.3.3" class="ltx_tabular ltx_align_middle">
<span id="S5.T2.6.3.3.3.3.4" class="ltx_tr">
<span id="S5.T2.6.3.3.3.3.4.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S5.T2.6.3.3.3.3.4.1.1" class="ltx_text ltx_font_bold">Pooling</span></span>
<span id="S5.T2.6.3.3.3.3.4.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S5.T2.6.3.3.3.3.4.2.1" class="ltx_text ltx_font_bold">R@1</span></span></span>
<span id="S5.T2.4.1.1.1.1.1" class="ltx_tr">
<span id="S5.T2.4.1.1.1.1.1.2" class="ltx_td ltx_align_left ltx_border_t">SPOC <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">7</span></a>]</cite></span>
<span id="S5.T2.4.1.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_t"><math id="S5.T2.4.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="42.9\pm 2.5" display="inline"><semantics id="S5.T2.4.1.1.1.1.1.1.m1.1a"><mrow id="S5.T2.4.1.1.1.1.1.1.m1.1.1" xref="S5.T2.4.1.1.1.1.1.1.m1.1.1.cmml"><mn id="S5.T2.4.1.1.1.1.1.1.m1.1.1.2" xref="S5.T2.4.1.1.1.1.1.1.m1.1.1.2.cmml">42.9</mn><mo id="S5.T2.4.1.1.1.1.1.1.m1.1.1.1" xref="S5.T2.4.1.1.1.1.1.1.m1.1.1.1.cmml">Â±</mo><mn id="S5.T2.4.1.1.1.1.1.1.m1.1.1.3" xref="S5.T2.4.1.1.1.1.1.1.m1.1.1.3.cmml">2.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.4.1.1.1.1.1.1.m1.1b"><apply id="S5.T2.4.1.1.1.1.1.1.m1.1.1.cmml" xref="S5.T2.4.1.1.1.1.1.1.m1.1.1"><csymbol cd="latexml" id="S5.T2.4.1.1.1.1.1.1.m1.1.1.1.cmml" xref="S5.T2.4.1.1.1.1.1.1.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S5.T2.4.1.1.1.1.1.1.m1.1.1.2.cmml" xref="S5.T2.4.1.1.1.1.1.1.m1.1.1.2">42.9</cn><cn type="float" id="S5.T2.4.1.1.1.1.1.1.m1.1.1.3.cmml" xref="S5.T2.4.1.1.1.1.1.1.m1.1.1.3">2.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.4.1.1.1.1.1.1.m1.1c">42.9\pm 2.5</annotation></semantics></math></span></span>
<span id="S5.T2.5.2.2.2.2.2" class="ltx_tr">
<span id="S5.T2.5.2.2.2.2.2.2" class="ltx_td ltx_align_left">MAC <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">57</span></a>]</cite></span>
<span id="S5.T2.5.2.2.2.2.2.1" class="ltx_td ltx_align_center"><math id="S5.T2.5.2.2.2.2.2.1.m1.1" class="ltx_Math" alttext="59.4\pm 0.6" display="inline"><semantics id="S5.T2.5.2.2.2.2.2.1.m1.1a"><mrow id="S5.T2.5.2.2.2.2.2.1.m1.1.1" xref="S5.T2.5.2.2.2.2.2.1.m1.1.1.cmml"><mn id="S5.T2.5.2.2.2.2.2.1.m1.1.1.2" xref="S5.T2.5.2.2.2.2.2.1.m1.1.1.2.cmml">59.4</mn><mo id="S5.T2.5.2.2.2.2.2.1.m1.1.1.1" xref="S5.T2.5.2.2.2.2.2.1.m1.1.1.1.cmml">Â±</mo><mn id="S5.T2.5.2.2.2.2.2.1.m1.1.1.3" xref="S5.T2.5.2.2.2.2.2.1.m1.1.1.3.cmml">0.6</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.5.2.2.2.2.2.1.m1.1b"><apply id="S5.T2.5.2.2.2.2.2.1.m1.1.1.cmml" xref="S5.T2.5.2.2.2.2.2.1.m1.1.1"><csymbol cd="latexml" id="S5.T2.5.2.2.2.2.2.1.m1.1.1.1.cmml" xref="S5.T2.5.2.2.2.2.2.1.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S5.T2.5.2.2.2.2.2.1.m1.1.1.2.cmml" xref="S5.T2.5.2.2.2.2.2.1.m1.1.1.2">59.4</cn><cn type="float" id="S5.T2.5.2.2.2.2.2.1.m1.1.1.3.cmml" xref="S5.T2.5.2.2.2.2.2.1.m1.1.1.3">0.6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.5.2.2.2.2.2.1.m1.1c">59.4\pm 0.6</annotation></semantics></math></span></span>
<span id="S5.T2.6.3.3.3.3.3" class="ltx_tr">
<span id="S5.T2.6.3.3.3.3.3.2" class="ltx_td ltx_align_left ltx_border_bb">GeM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib56" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">56</span></a>]</cite></span>
<span id="S5.T2.6.3.3.3.3.3.1" class="ltx_td ltx_align_center ltx_border_bb"><math id="S5.T2.6.3.3.3.3.3.1.m1.1" class="ltx_Math" alttext="\textbf{68.0}\pm\textbf{0.3}" display="inline"><semantics id="S5.T2.6.3.3.3.3.3.1.m1.1a"><mrow id="S5.T2.6.3.3.3.3.3.1.m1.1.1" xref="S5.T2.6.3.3.3.3.3.1.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S5.T2.6.3.3.3.3.3.1.m1.1.1.2" xref="S5.T2.6.3.3.3.3.3.1.m1.1.1.2a.cmml">68.0</mtext><mo id="S5.T2.6.3.3.3.3.3.1.m1.1.1.1" xref="S5.T2.6.3.3.3.3.3.1.m1.1.1.1.cmml">Â±</mo><mtext class="ltx_mathvariant_bold" id="S5.T2.6.3.3.3.3.3.1.m1.1.1.3" xref="S5.T2.6.3.3.3.3.3.1.m1.1.1.3a.cmml">0.3</mtext></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.6.3.3.3.3.3.1.m1.1b"><apply id="S5.T2.6.3.3.3.3.3.1.m1.1.1.cmml" xref="S5.T2.6.3.3.3.3.3.1.m1.1.1"><csymbol cd="latexml" id="S5.T2.6.3.3.3.3.3.1.m1.1.1.1.cmml" xref="S5.T2.6.3.3.3.3.3.1.m1.1.1.1">plus-or-minus</csymbol><ci id="S5.T2.6.3.3.3.3.3.1.m1.1.1.2a.cmml" xref="S5.T2.6.3.3.3.3.3.1.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S5.T2.6.3.3.3.3.3.1.m1.1.1.2.cmml" xref="S5.T2.6.3.3.3.3.3.1.m1.1.1.2">68.0</mtext></ci><ci id="S5.T2.6.3.3.3.3.3.1.m1.1.1.3a.cmml" xref="S5.T2.6.3.3.3.3.3.1.m1.1.1.3"><mtext class="ltx_mathvariant_bold" id="S5.T2.6.3.3.3.3.3.1.m1.1.1.3.cmml" xref="S5.T2.6.3.3.3.3.3.1.m1.1.1.3">0.3</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.6.3.3.3.3.3.1.m1.1c">\textbf{68.0}\pm\textbf{0.3}</annotation></semantics></math></span></span>
</span></span></p>
</span></div>
</figure>
</div>
</div>
</figure>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Implementation details</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.2" class="ltx_p">This section provides the main implementation details used in our experiments. Additional information can be found in <a href="#A2" title="Appendix B Implementation details â€£ Collaborative Visual Place Recognition through Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Appendix</span>Â <span class="ltx_text ltx_ref_tag">B</span></a>.
The used model architecture, unless specified otherwise, is a ResNet18 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">30</span></a>]</cite> truncated at the third convolutional layer, with GeM pooling <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib56" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">56</span></a>]</cite>.
In local training, we use a batch size of 2 triplets per iteration, with each triplet comprising 5 negative examples for each query alongside its positive counterpart. The learning rate is <math id="S5.SS1.p1.1.m1.1" class="ltx_Math" alttext="1\times 10^{-5}" display="inline"><semantics id="S5.SS1.p1.1.m1.1a"><mrow id="S5.SS1.p1.1.m1.1.1" xref="S5.SS1.p1.1.m1.1.1.cmml"><mn id="S5.SS1.p1.1.m1.1.1.2" xref="S5.SS1.p1.1.m1.1.1.2.cmml">1</mn><mo lspace="0.222em" rspace="0.222em" id="S5.SS1.p1.1.m1.1.1.1" xref="S5.SS1.p1.1.m1.1.1.1.cmml">Ã—</mo><msup id="S5.SS1.p1.1.m1.1.1.3" xref="S5.SS1.p1.1.m1.1.1.3.cmml"><mn id="S5.SS1.p1.1.m1.1.1.3.2" xref="S5.SS1.p1.1.m1.1.1.3.2.cmml">10</mn><mrow id="S5.SS1.p1.1.m1.1.1.3.3" xref="S5.SS1.p1.1.m1.1.1.3.3.cmml"><mo id="S5.SS1.p1.1.m1.1.1.3.3a" xref="S5.SS1.p1.1.m1.1.1.3.3.cmml">âˆ’</mo><mn id="S5.SS1.p1.1.m1.1.1.3.3.2" xref="S5.SS1.p1.1.m1.1.1.3.3.2.cmml">5</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.1.m1.1b"><apply id="S5.SS1.p1.1.m1.1.1.cmml" xref="S5.SS1.p1.1.m1.1.1"><times id="S5.SS1.p1.1.m1.1.1.1.cmml" xref="S5.SS1.p1.1.m1.1.1.1"></times><cn type="integer" id="S5.SS1.p1.1.m1.1.1.2.cmml" xref="S5.SS1.p1.1.m1.1.1.2">1</cn><apply id="S5.SS1.p1.1.m1.1.1.3.cmml" xref="S5.SS1.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S5.SS1.p1.1.m1.1.1.3.1.cmml" xref="S5.SS1.p1.1.m1.1.1.3">superscript</csymbol><cn type="integer" id="S5.SS1.p1.1.m1.1.1.3.2.cmml" xref="S5.SS1.p1.1.m1.1.1.3.2">10</cn><apply id="S5.SS1.p1.1.m1.1.1.3.3.cmml" xref="S5.SS1.p1.1.m1.1.1.3.3"><minus id="S5.SS1.p1.1.m1.1.1.3.3.1.cmml" xref="S5.SS1.p1.1.m1.1.1.3.3"></minus><cn type="integer" id="S5.SS1.p1.1.m1.1.1.3.3.2.cmml" xref="S5.SS1.p1.1.m1.1.1.3.3.2">5</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.1.m1.1c">1\times 10^{-5}</annotation></semantics></math> with Adam as both local optimizer and optimizer in the centralized runs. On the server side, unless otherwise specified, FedAvg <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">52</span></a>]</cite> is used for model aggregation.
In the centralized experiments, the training continues until the model converges, incorporating an early-stopping mechanism based on validation accuracy. In contrast, in the FL framework, each round engages 5 clients, with each client running a single local epoch. This process is repeated across a total of <math id="S5.SS1.p1.2.m2.1" class="ltx_Math" alttext="T=300" display="inline"><semantics id="S5.SS1.p1.2.m2.1a"><mrow id="S5.SS1.p1.2.m2.1.1" xref="S5.SS1.p1.2.m2.1.1.cmml"><mi id="S5.SS1.p1.2.m2.1.1.2" xref="S5.SS1.p1.2.m2.1.1.2.cmml">T</mi><mo id="S5.SS1.p1.2.m2.1.1.1" xref="S5.SS1.p1.2.m2.1.1.1.cmml">=</mo><mn id="S5.SS1.p1.2.m2.1.1.3" xref="S5.SS1.p1.2.m2.1.1.3.cmml">300</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.2.m2.1b"><apply id="S5.SS1.p1.2.m2.1.1.cmml" xref="S5.SS1.p1.2.m2.1.1"><eq id="S5.SS1.p1.2.m2.1.1.1.cmml" xref="S5.SS1.p1.2.m2.1.1.1"></eq><ci id="S5.SS1.p1.2.m2.1.1.2.cmml" xref="S5.SS1.p1.2.m2.1.1.2">ğ‘‡</ci><cn type="integer" id="S5.SS1.p1.2.m2.1.1.3.cmml" xref="S5.SS1.p1.2.m2.1.1.3">300</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.2.m2.1c">T=300</annotation></semantics></math> rounds. Validation is conducted using a subset of 12 clients that do not participate in the training phase. Lastly, testing is directly handled by the server.</p>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<p id="S5.SS1.p2.1" class="ltx_p">The Hierarchical Federated Learning (H-FL) <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib46" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">46</span></a>, <a href="#bib.bib20" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">20</span></a>]</cite> experiments propose two hierarchy types, delineated by geographical proximity: <span id="S5.SS1.p2.1.1" class="ltx_text ltx_font_italic">City</span> and <span id="S5.SS1.p2.1.2" class="ltx_text ltx_font_italic">Continental</span> levels, where clients within the same city or continent respectively are aggregated to form the cluster-specific models. This results in 21 clusters in the former case and 4 in the latter. We employ the classical SGD server optimizer in our hierarchical experiments and select 5 clients from each cluster per round.</p>
</div>
<div id="S5.SS1.p3" class="ltx_para">
<p id="S5.SS1.p3.1" class="ltx_p">All experiments are conducted using an image resolution of <math id="S5.SS1.p3.1.m1.1" class="ltx_Math" alttext="288\times 384" display="inline"><semantics id="S5.SS1.p3.1.m1.1a"><mrow id="S5.SS1.p3.1.m1.1.1" xref="S5.SS1.p3.1.m1.1.1.cmml"><mn id="S5.SS1.p3.1.m1.1.1.2" xref="S5.SS1.p3.1.m1.1.1.2.cmml">288</mn><mo lspace="0.222em" rspace="0.222em" id="S5.SS1.p3.1.m1.1.1.1" xref="S5.SS1.p3.1.m1.1.1.1.cmml">Ã—</mo><mn id="S5.SS1.p3.1.m1.1.1.3" xref="S5.SS1.p3.1.m1.1.1.3.cmml">384</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p3.1.m1.1b"><apply id="S5.SS1.p3.1.m1.1.1.cmml" xref="S5.SS1.p3.1.m1.1.1"><times id="S5.SS1.p3.1.m1.1.1.1.cmml" xref="S5.SS1.p3.1.m1.1.1.1"></times><cn type="integer" id="S5.SS1.p3.1.m1.1.1.2.cmml" xref="S5.SS1.p3.1.m1.1.1.2">288</cn><cn type="integer" id="S5.SS1.p3.1.m1.1.1.3.cmml" xref="S5.SS1.p3.1.m1.1.1.3">384</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p3.1.m1.1c">288\times 384</annotation></semantics></math> pixels, which provides a good trade-off between speed and results. Notably, we refrain from employing any form of data augmentation in our methodology.
To ensure the robustness and reliability of the results, all experimental outcomes are averaged over 3 distinct runs.</p>
</div>
<figure id="S5.F3" class="ltx_figure"><img src="/html/2404.13324/assets/x3.png" id="S5.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="346" height="159" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F3.5.2.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S5.F3.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Centralized setting<span id="S5.F3.2.1.1" class="ltx_text ltx_font_medium">. Comparison of R<math id="S5.F3.2.1.1.m1.1" class="ltx_Math" alttext="@1" display="inline"><semantics id="S5.F3.2.1.1.m1.1b"><mrow id="S5.F3.2.1.1.m1.1.1" xref="S5.F3.2.1.1.m1.1.1.cmml"><mi mathvariant="normal" id="S5.F3.2.1.1.m1.1.1.2" xref="S5.F3.2.1.1.m1.1.1.2.cmml">@</mi><mo lspace="0em" rspace="0em" id="S5.F3.2.1.1.m1.1.1.1" xref="S5.F3.2.1.1.m1.1.1.1.cmml">â€‹</mo><mn id="S5.F3.2.1.1.m1.1.1.3" xref="S5.F3.2.1.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.F3.2.1.1.m1.1c"><apply id="S5.F3.2.1.1.m1.1.1.cmml" xref="S5.F3.2.1.1.m1.1.1"><times id="S5.F3.2.1.1.m1.1.1.1.cmml" xref="S5.F3.2.1.1.m1.1.1.1"></times><ci id="S5.F3.2.1.1.m1.1.1.2.cmml" xref="S5.F3.2.1.1.m1.1.1.2">@</ci><cn type="integer" id="S5.F3.2.1.1.m1.1.1.3.cmml" xref="S5.F3.2.1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F3.2.1.1.m1.1d">@1</annotation></semantics></math> (%) and computational time (hours) when varying the image resolution. Resolution greatly affects training time, and an optimal trade-off can be attained with minimal performance drops.
</span></span></figcaption>
</figure>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Centralized baselines</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">In FL, the choice of network architectures is restricted by the communication bottleneck and the constrained computational capabilities of individual clients. Consequently, lightweight backbones with fewer parameters are preferred to alleviate communication and computation burdens.
<a href="#S5.T2.6" title="In 5 Experiments and Results â€£ Collaborative Visual Place Recognition through Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span>Â <span class="ltx_text ltx_ref_tag">2</span></a> presents a comparison of backbone architectures and aggregation layers in a centralized setting, which serve as a baseline for the FL experiments. We consider three networks pre-trained on ImageNetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">21</span></a>]</cite>: ResNet18 <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib30" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">30</span></a>]</cite> truncated at the third layer, ResNet18 with fine-tuning limited to the last block, and VGG16 <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib63" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">63</span></a>]</cite>.
Regarding aggregation layers, we test different pooling strategies, namely SPOC <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib7" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">7</span></a>]</cite>, MAC <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib57" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">57</span></a>]</cite>, and GeM <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib56" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">56</span></a>]</cite>. These methods apply a pooling operation on the feature maps provided by the backbone, obtaining a single embedding for each image, whose dimensions are determined by the number of channels of the chosen backbone. NetVLAD <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib5" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">5</span></a>]</cite> is another popular aggregation layer for VPR, which usually grants robust performances <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">11</span></a>]</cite>. Nevertheless, some drawbacks make its adoption impractical in a federated scenario. Firstly, it outputs large descriptors (ranging from 16k to 64k dimensionality, depending on the backbone), which clients would have to store and use for nearest neighbor search. Moreover, it requires to initialize a set of centroids (<span id="S5.SS2.p1.1.1" class="ltx_text ltx_font_italic">visual words</span>) using a diverse set of images <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">11</span></a>]</cite>, which would have to be provided by the server, increasing the communication costs and eventually raising privacy concerns. Thus, in our analysis, we consider simpler pooling layers to be viable alternatives.</p>
</div>
<div id="S5.SS2.p2" class="ltx_para">
<p id="S5.SS2.p2.2" class="ltx_p">Based on the results in <a href="#S5.T2.6" title="In 5 Experiments and Results â€£ Collaborative Visual Place Recognition through Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">2</span></a>, we select ResNet18 truncated as our architecture, capitalizing on the benefits of a reduced parameter count. The adoption of GeM as the pooling layer is justified by the observed performance improvements. However, GeM increases the computational time, which is a restriction in FL settings, where edge devices have access to limited resources. To mitigate this, we compare various image resolutions, considering both training time and performance metrics in <a href="#S5.F3" title="In 5.1 Implementation details â€£ 5 Experiments and Results â€£ Collaborative Visual Place Recognition through Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">3</span></a>. We settle on the 288<math id="S5.SS2.p2.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.SS2.p2.1.m1.1a"><mo id="S5.SS2.p2.1.m1.1.1" xref="S5.SS2.p2.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.1.m1.1b"><times id="S5.SS2.p2.1.m1.1.1.cmml" xref="S5.SS2.p2.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.1.m1.1c">\times</annotation></semantics></math>384 resolution as the optimal choice, striking the best balance between recall and training time. With this resolution, we get a final centralized recall of <math id="S5.SS2.p2.2.m2.1" class="ltx_Math" alttext="66.0\pm 0.4" display="inline"><semantics id="S5.SS2.p2.2.m2.1a"><mrow id="S5.SS2.p2.2.m2.1.1" xref="S5.SS2.p2.2.m2.1.1.cmml"><mn id="S5.SS2.p2.2.m2.1.1.2" xref="S5.SS2.p2.2.m2.1.1.2.cmml">66.0</mn><mo id="S5.SS2.p2.2.m2.1.1.1" xref="S5.SS2.p2.2.m2.1.1.1.cmml">Â±</mo><mn id="S5.SS2.p2.2.m2.1.1.3" xref="S5.SS2.p2.2.m2.1.1.3.cmml">0.4</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.2.m2.1b"><apply id="S5.SS2.p2.2.m2.1.1.cmml" xref="S5.SS2.p2.2.m2.1.1"><csymbol cd="latexml" id="S5.SS2.p2.2.m2.1.1.1.cmml" xref="S5.SS2.p2.2.m2.1.1.1">plus-or-minus</csymbol><cn type="float" id="S5.SS2.p2.2.m2.1.1.2.cmml" xref="S5.SS2.p2.2.m2.1.1.2">66.0</cn><cn type="float" id="S5.SS2.p2.2.m2.1.1.3.cmml" xref="S5.SS2.p2.2.m2.1.1.3">0.4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.2.m2.1c">66.0\pm 0.4</annotation></semantics></math>.</p>
</div>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>FL baselines</h3>

<div id="S5.SS3.p1" class="ltx_para ltx_noindent">
<p id="S5.SS3.p1.1" class="ltx_p"><span id="S5.SS3.p1.1.1" class="ltx_text ltx_font_bold">Splits comparison.</span> With the centralized baselines established, we conduct an analysis of the vanilla FedAvg algorithm across the different introduced datasets, as illustrated in <a href="#S4.T1" title="In 4.1 Proposed FL datasets â€£ 4 Decentralizing the MSLS dataset for FL â€£ Collaborative Visual Place Recognition through Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">1</span></a>.
Interestingly, the performance of FedAvg on the Random FL dataset significantly lags behind that of other ones, despite the scenario closely resembling uniform splits as seen in prior works <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib31" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">31</span></a>, <a href="#bib.bib24" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">24</span></a>, <a href="#bib.bib23" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">23</span></a>]</cite>. However, as highlighted in <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib11" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">11</span></a>]</cite>, optimal performance necessitates hard negatives to be situated within a distance range of 25 meters to a few kilometers from the query, a condition not met in this dataset where images within the same client can belong to various locations worldwide.
Our experiments on the Proximity and Clustering FL datasets yielded comparable performance. Interestingly, the Proximity split achieved slightly better results on average. This difference is likely because images within clients of the Proximity split have closer GPS coordinates compared to those in the Clustering split. Additionally, clients in the Proximity FL datasets with radii of 2000m and 4000m also contain a larger number of images compared to their counterparts in the Clustering datasets.
The proximity experiment employing a radius of 4000m demonstrates performance levels roughly akin to the centralized baseline. However, opting for a larger radius results in fewer clients, each possessing a greater number of images and sequences, thereby resembling a cross-silo scenario <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">40</span></a>]</cite>. Conversely, reducing the radius yields a larger number of clients but with a markedly limited quantity of images and sequences per client.
Given all these considerations, we shift our focus solely to the <span id="S5.SS3.p1.1.2" class="ltx_text ltx_font_bold">proximity</span> FL dataset with a <span id="S5.SS3.p1.1.3" class="ltx_text ltx_font_bold">2000m radius</span> in the upcoming experiments. This choice strikes a balance between the number of clients and the volume of data per client.</p>
</div>
<figure id="S5.T3" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S5.T3.10.3.1" class="ltx_text" style="font-size:90%;">Table 3</span>: </span><span id="S5.T3.4.2" class="ltx_text" style="font-size:90%;">Comparison of the vanilla baseline FedAvg with Hierarchical FL methods and various server optimizers. Notation: <span id="S5.T3.4.2.1" class="ltx_text ltx_font_bold">CC</span> for continent-level middle servers in H-FL, <span id="S5.T3.4.2.2" class="ltx_text ltx_font_bold">C</span> for city-level middle servers, SGDm for SGD with server-side momentum, <math id="S5.T3.3.1.m1.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S5.T3.3.1.m1.1b"><mi id="S5.T3.3.1.m1.1.1" xref="S5.T3.3.1.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S5.T3.3.1.m1.1c"><ci id="S5.T3.3.1.m1.1.1.cmml" xref="S5.T3.3.1.m1.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.3.1.m1.1d">T</annotation></semantics></math> rounds, <math id="S5.T3.4.2.m2.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S5.T3.4.2.m2.1b"><mi id="S5.T3.4.2.m2.1.1" xref="S5.T3.4.2.m2.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S5.T3.4.2.m2.1c"><ci id="S5.T3.4.2.m2.1.1.cmml" xref="S5.T3.4.2.m2.1.1">ğ¶</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.4.2.m2.1d">C</annotation></semantics></math> clients participating at each round.</span></figcaption>
<div id="S5.T3.6" class="ltx_logical-block ltx_pruned_first">
<div id="S5.T3.6.p2" class="ltx_para ltx_noindent ltx_align_center">
<div id="S5.T3.6.p2.12" class="ltx_inline-block ltx_transformed_outer" style="width:278.1pt;height:162pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="S5.T3.6.p2.12.12" class="ltx_p"><span id="S5.T3.6.p2.12.12.12" class="ltx_text">

<span id="S5.T3.6.p2.12.12.12.12" class="ltx_tabular ltx_align_middle">
<span id="S5.T3.6.p2.12.12.12.12.13" class="ltx_tr">
<span id="S5.T3.6.p2.12.12.12.12.13.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S5.T3.6.p2.12.12.12.12.13.1.1" class="ltx_text ltx_font_bold">Algorithm</span></span>
<span id="S5.T3.6.p2.12.12.12.12.13.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S5.T3.6.p2.12.12.12.12.13.2.1" class="ltx_text ltx_font_bold">Server Optimizer</span></span>
<span id="S5.T3.6.p2.12.12.12.12.13.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S5.T3.6.p2.12.12.12.12.13.3.1" class="ltx_text ltx_font_bold">R@1 (%)</span></span></span>
<span id="S5.T3.6.p2.1.1.1.1.1" class="ltx_tr">
<span id="S5.T3.6.p2.1.1.1.1.1.2" class="ltx_td ltx_align_left ltx_border_t ltx_rowspan ltx_rowspan_4"><span id="S5.T3.6.p2.1.1.1.1.1.2.1" class="ltx_text">FedAvg</span></span>
<span id="S5.T3.6.p2.1.1.1.1.1.3" class="ltx_td ltx_align_center ltx_border_t">SGD</span>
<span id="S5.T3.6.p2.1.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_t">61.0 <math id="S5.T3.6.p2.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T3.6.p2.1.1.1.1.1.1.m1.1a"><mo mathsize="70%" id="S5.T3.6.p2.1.1.1.1.1.1.m1.1.1" xref="S5.T3.6.p2.1.1.1.1.1.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S5.T3.6.p2.1.1.1.1.1.1.m1.1b"><csymbol cd="latexml" id="S5.T3.6.p2.1.1.1.1.1.1.m1.1.1.cmml" xref="S5.T3.6.p2.1.1.1.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.6.p2.1.1.1.1.1.1.m1.1c">\pm</annotation></semantics></math><span id="S5.T3.6.p2.1.1.1.1.1.1.1" class="ltx_text" style="font-size:70%;"> 0.6</span></span></span>
<span id="S5.T3.6.p2.2.2.2.2.2" class="ltx_tr">
<span id="S5.T3.6.p2.2.2.2.2.2.2" class="ltx_td ltx_align_center">SGDm</span>
<span id="S5.T3.6.p2.2.2.2.2.2.1" class="ltx_td ltx_align_center">61.2 <math id="S5.T3.6.p2.2.2.2.2.2.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T3.6.p2.2.2.2.2.2.1.m1.1a"><mo mathsize="70%" id="S5.T3.6.p2.2.2.2.2.2.1.m1.1.1" xref="S5.T3.6.p2.2.2.2.2.2.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S5.T3.6.p2.2.2.2.2.2.1.m1.1b"><csymbol cd="latexml" id="S5.T3.6.p2.2.2.2.2.2.1.m1.1.1.cmml" xref="S5.T3.6.p2.2.2.2.2.2.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.6.p2.2.2.2.2.2.1.m1.1c">\pm</annotation></semantics></math><span id="S5.T3.6.p2.2.2.2.2.2.1.1" class="ltx_text" style="font-size:70%;"> 1.4</span></span></span>
<span id="S5.T3.6.p2.3.3.3.3.3" class="ltx_tr">
<span id="S5.T3.6.p2.3.3.3.3.3.2" class="ltx_td ltx_align_center">Adam</span>
<span id="S5.T3.6.p2.3.3.3.3.3.1" class="ltx_td ltx_align_center">61.1 <math id="S5.T3.6.p2.3.3.3.3.3.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T3.6.p2.3.3.3.3.3.1.m1.1a"><mo mathsize="70%" id="S5.T3.6.p2.3.3.3.3.3.1.m1.1.1" xref="S5.T3.6.p2.3.3.3.3.3.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S5.T3.6.p2.3.3.3.3.3.1.m1.1b"><csymbol cd="latexml" id="S5.T3.6.p2.3.3.3.3.3.1.m1.1.1.cmml" xref="S5.T3.6.p2.3.3.3.3.3.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.6.p2.3.3.3.3.3.1.m1.1c">\pm</annotation></semantics></math><span id="S5.T3.6.p2.3.3.3.3.3.1.1" class="ltx_text" style="font-size:70%;"> 1.2</span></span></span>
<span id="S5.T3.6.p2.4.4.4.4.4" class="ltx_tr">
<span id="S5.T3.6.p2.4.4.4.4.4.2" class="ltx_td ltx_align_center">AdaGrad</span>
<span id="S5.T3.6.p2.4.4.4.4.4.1" class="ltx_td ltx_align_center">61.6 <math id="S5.T3.6.p2.4.4.4.4.4.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T3.6.p2.4.4.4.4.4.1.m1.1a"><mo mathsize="70%" id="S5.T3.6.p2.4.4.4.4.4.1.m1.1.1" xref="S5.T3.6.p2.4.4.4.4.4.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S5.T3.6.p2.4.4.4.4.4.1.m1.1b"><csymbol cd="latexml" id="S5.T3.6.p2.4.4.4.4.4.1.m1.1.1.cmml" xref="S5.T3.6.p2.4.4.4.4.4.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.6.p2.4.4.4.4.4.1.m1.1c">\pm</annotation></semantics></math><span id="S5.T3.6.p2.4.4.4.4.4.1.1" class="ltx_text" style="font-size:70%;"> 0.3</span></span></span>
<span id="S5.T3.6.p2.5.5.5.5.5" class="ltx_tr">
<span id="S5.T3.6.p2.5.5.5.5.5.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T3.6.p2.5.5.5.5.5.2.1" class="ltx_text">H-FL (<span id="S5.T3.6.p2.5.5.5.5.5.2.1.1" class="ltx_text ltx_font_bold">CC</span>)</span></span>
<span id="S5.T3.6.p2.5.5.5.5.5.3" class="ltx_td ltx_align_center ltx_border_t">SGD</span>
<span id="S5.T3.6.p2.5.5.5.5.5.1" class="ltx_td ltx_align_center ltx_border_t">46.9 <math id="S5.T3.6.p2.5.5.5.5.5.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T3.6.p2.5.5.5.5.5.1.m1.1a"><mo mathsize="70%" id="S5.T3.6.p2.5.5.5.5.5.1.m1.1.1" xref="S5.T3.6.p2.5.5.5.5.5.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S5.T3.6.p2.5.5.5.5.5.1.m1.1b"><csymbol cd="latexml" id="S5.T3.6.p2.5.5.5.5.5.1.m1.1.1.cmml" xref="S5.T3.6.p2.5.5.5.5.5.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.6.p2.5.5.5.5.5.1.m1.1c">\pm</annotation></semantics></math><span id="S5.T3.6.p2.5.5.5.5.5.1.1" class="ltx_text" style="font-size:70%;"> 1.3</span></span></span>
<span id="S5.T3.6.p2.8.8.8.8.8" class="ltx_tr">
<span id="S5.T3.6.p2.7.7.7.7.7.2" class="ltx_td ltx_align_left"><span id="S5.T3.6.p2.7.7.7.7.7.2.1" class="ltx_ERROR undefined">\hdashline</span>FedAvg <math id="S5.T3.6.p2.6.6.6.6.6.1.m1.1" class="ltx_Math" alttext="T=75" display="inline"><semantics id="S5.T3.6.p2.6.6.6.6.6.1.m1.1a"><mrow id="S5.T3.6.p2.6.6.6.6.6.1.m1.1.1" xref="S5.T3.6.p2.6.6.6.6.6.1.m1.1.1.cmml"><mi id="S5.T3.6.p2.6.6.6.6.6.1.m1.1.1.2" xref="S5.T3.6.p2.6.6.6.6.6.1.m1.1.1.2.cmml">T</mi><mo id="S5.T3.6.p2.6.6.6.6.6.1.m1.1.1.1" xref="S5.T3.6.p2.6.6.6.6.6.1.m1.1.1.1.cmml">=</mo><mn id="S5.T3.6.p2.6.6.6.6.6.1.m1.1.1.3" xref="S5.T3.6.p2.6.6.6.6.6.1.m1.1.1.3.cmml">75</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T3.6.p2.6.6.6.6.6.1.m1.1b"><apply id="S5.T3.6.p2.6.6.6.6.6.1.m1.1.1.cmml" xref="S5.T3.6.p2.6.6.6.6.6.1.m1.1.1"><eq id="S5.T3.6.p2.6.6.6.6.6.1.m1.1.1.1.cmml" xref="S5.T3.6.p2.6.6.6.6.6.1.m1.1.1.1"></eq><ci id="S5.T3.6.p2.6.6.6.6.6.1.m1.1.1.2.cmml" xref="S5.T3.6.p2.6.6.6.6.6.1.m1.1.1.2">ğ‘‡</ci><cn type="integer" id="S5.T3.6.p2.6.6.6.6.6.1.m1.1.1.3.cmml" xref="S5.T3.6.p2.6.6.6.6.6.1.m1.1.1.3">75</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.6.p2.6.6.6.6.6.1.m1.1c">T=75</annotation></semantics></math>, <math id="S5.T3.6.p2.7.7.7.7.7.2.m2.1" class="ltx_Math" alttext="C=20" display="inline"><semantics id="S5.T3.6.p2.7.7.7.7.7.2.m2.1a"><mrow id="S5.T3.6.p2.7.7.7.7.7.2.m2.1.1" xref="S5.T3.6.p2.7.7.7.7.7.2.m2.1.1.cmml"><mi id="S5.T3.6.p2.7.7.7.7.7.2.m2.1.1.2" xref="S5.T3.6.p2.7.7.7.7.7.2.m2.1.1.2.cmml">C</mi><mo id="S5.T3.6.p2.7.7.7.7.7.2.m2.1.1.1" xref="S5.T3.6.p2.7.7.7.7.7.2.m2.1.1.1.cmml">=</mo><mn id="S5.T3.6.p2.7.7.7.7.7.2.m2.1.1.3" xref="S5.T3.6.p2.7.7.7.7.7.2.m2.1.1.3.cmml">20</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T3.6.p2.7.7.7.7.7.2.m2.1b"><apply id="S5.T3.6.p2.7.7.7.7.7.2.m2.1.1.cmml" xref="S5.T3.6.p2.7.7.7.7.7.2.m2.1.1"><eq id="S5.T3.6.p2.7.7.7.7.7.2.m2.1.1.1.cmml" xref="S5.T3.6.p2.7.7.7.7.7.2.m2.1.1.1"></eq><ci id="S5.T3.6.p2.7.7.7.7.7.2.m2.1.1.2.cmml" xref="S5.T3.6.p2.7.7.7.7.7.2.m2.1.1.2">ğ¶</ci><cn type="integer" id="S5.T3.6.p2.7.7.7.7.7.2.m2.1.1.3.cmml" xref="S5.T3.6.p2.7.7.7.7.7.2.m2.1.1.3">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.6.p2.7.7.7.7.7.2.m2.1c">C=20</annotation></semantics></math></span>
<span id="S5.T3.6.p2.8.8.8.8.8.4" class="ltx_td ltx_align_center">SGD</span>
<span id="S5.T3.6.p2.8.8.8.8.8.3" class="ltx_td ltx_align_center">55.6 <math id="S5.T3.6.p2.8.8.8.8.8.3.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T3.6.p2.8.8.8.8.8.3.m1.1a"><mo mathsize="70%" id="S5.T3.6.p2.8.8.8.8.8.3.m1.1.1" xref="S5.T3.6.p2.8.8.8.8.8.3.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S5.T3.6.p2.8.8.8.8.8.3.m1.1b"><csymbol cd="latexml" id="S5.T3.6.p2.8.8.8.8.8.3.m1.1.1.cmml" xref="S5.T3.6.p2.8.8.8.8.8.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.6.p2.8.8.8.8.8.3.m1.1c">\pm</annotation></semantics></math><span id="S5.T3.6.p2.8.8.8.8.8.3.1" class="ltx_text" style="font-size:70%;"> 0.8</span></span></span>
<span id="S5.T3.6.p2.9.9.9.9.9" class="ltx_tr">
<span id="S5.T3.6.p2.9.9.9.9.9.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T3.6.p2.9.9.9.9.9.2.1" class="ltx_text">H-FL (<span id="S5.T3.6.p2.9.9.9.9.9.2.1.1" class="ltx_text ltx_font_bold">C</span>)</span></span>
<span id="S5.T3.6.p2.9.9.9.9.9.3" class="ltx_td ltx_align_center ltx_border_t">SGD</span>
<span id="S5.T3.6.p2.9.9.9.9.9.1" class="ltx_td ltx_align_center ltx_border_t">33.3 <math id="S5.T3.6.p2.9.9.9.9.9.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T3.6.p2.9.9.9.9.9.1.m1.1a"><mo mathsize="70%" id="S5.T3.6.p2.9.9.9.9.9.1.m1.1.1" xref="S5.T3.6.p2.9.9.9.9.9.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S5.T3.6.p2.9.9.9.9.9.1.m1.1b"><csymbol cd="latexml" id="S5.T3.6.p2.9.9.9.9.9.1.m1.1.1.cmml" xref="S5.T3.6.p2.9.9.9.9.9.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.6.p2.9.9.9.9.9.1.m1.1c">\pm</annotation></semantics></math><span id="S5.T3.6.p2.9.9.9.9.9.1.1" class="ltx_text" style="font-size:70%;"> 0.1</span></span></span>
<span id="S5.T3.6.p2.12.12.12.12.12" class="ltx_tr">
<span id="S5.T3.6.p2.11.11.11.11.11.2" class="ltx_td ltx_align_left ltx_border_bb"><span id="S5.T3.6.p2.11.11.11.11.11.2.1" class="ltx_ERROR undefined">\hdashline</span>FedAvg <math id="S5.T3.6.p2.10.10.10.10.10.1.m1.1" class="ltx_Math" alttext="T=15" display="inline"><semantics id="S5.T3.6.p2.10.10.10.10.10.1.m1.1a"><mrow id="S5.T3.6.p2.10.10.10.10.10.1.m1.1.1" xref="S5.T3.6.p2.10.10.10.10.10.1.m1.1.1.cmml"><mi id="S5.T3.6.p2.10.10.10.10.10.1.m1.1.1.2" xref="S5.T3.6.p2.10.10.10.10.10.1.m1.1.1.2.cmml">T</mi><mo id="S5.T3.6.p2.10.10.10.10.10.1.m1.1.1.1" xref="S5.T3.6.p2.10.10.10.10.10.1.m1.1.1.1.cmml">=</mo><mn id="S5.T3.6.p2.10.10.10.10.10.1.m1.1.1.3" xref="S5.T3.6.p2.10.10.10.10.10.1.m1.1.1.3.cmml">15</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T3.6.p2.10.10.10.10.10.1.m1.1b"><apply id="S5.T3.6.p2.10.10.10.10.10.1.m1.1.1.cmml" xref="S5.T3.6.p2.10.10.10.10.10.1.m1.1.1"><eq id="S5.T3.6.p2.10.10.10.10.10.1.m1.1.1.1.cmml" xref="S5.T3.6.p2.10.10.10.10.10.1.m1.1.1.1"></eq><ci id="S5.T3.6.p2.10.10.10.10.10.1.m1.1.1.2.cmml" xref="S5.T3.6.p2.10.10.10.10.10.1.m1.1.1.2">ğ‘‡</ci><cn type="integer" id="S5.T3.6.p2.10.10.10.10.10.1.m1.1.1.3.cmml" xref="S5.T3.6.p2.10.10.10.10.10.1.m1.1.1.3">15</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.6.p2.10.10.10.10.10.1.m1.1c">T=15</annotation></semantics></math>, <math id="S5.T3.6.p2.11.11.11.11.11.2.m2.1" class="ltx_Math" alttext="C=105" display="inline"><semantics id="S5.T3.6.p2.11.11.11.11.11.2.m2.1a"><mrow id="S5.T3.6.p2.11.11.11.11.11.2.m2.1.1" xref="S5.T3.6.p2.11.11.11.11.11.2.m2.1.1.cmml"><mi id="S5.T3.6.p2.11.11.11.11.11.2.m2.1.1.2" xref="S5.T3.6.p2.11.11.11.11.11.2.m2.1.1.2.cmml">C</mi><mo id="S5.T3.6.p2.11.11.11.11.11.2.m2.1.1.1" xref="S5.T3.6.p2.11.11.11.11.11.2.m2.1.1.1.cmml">=</mo><mn id="S5.T3.6.p2.11.11.11.11.11.2.m2.1.1.3" xref="S5.T3.6.p2.11.11.11.11.11.2.m2.1.1.3.cmml">105</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T3.6.p2.11.11.11.11.11.2.m2.1b"><apply id="S5.T3.6.p2.11.11.11.11.11.2.m2.1.1.cmml" xref="S5.T3.6.p2.11.11.11.11.11.2.m2.1.1"><eq id="S5.T3.6.p2.11.11.11.11.11.2.m2.1.1.1.cmml" xref="S5.T3.6.p2.11.11.11.11.11.2.m2.1.1.1"></eq><ci id="S5.T3.6.p2.11.11.11.11.11.2.m2.1.1.2.cmml" xref="S5.T3.6.p2.11.11.11.11.11.2.m2.1.1.2">ğ¶</ci><cn type="integer" id="S5.T3.6.p2.11.11.11.11.11.2.m2.1.1.3.cmml" xref="S5.T3.6.p2.11.11.11.11.11.2.m2.1.1.3">105</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.6.p2.11.11.11.11.11.2.m2.1c">C=105</annotation></semantics></math></span>
<span id="S5.T3.6.p2.12.12.12.12.12.4" class="ltx_td ltx_align_center ltx_border_bb">SGD</span>
<span id="S5.T3.6.p2.12.12.12.12.12.3" class="ltx_td ltx_align_center ltx_border_bb">44.2 <math id="S5.T3.6.p2.12.12.12.12.12.3.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T3.6.p2.12.12.12.12.12.3.m1.1a"><mo mathsize="70%" id="S5.T3.6.p2.12.12.12.12.12.3.m1.1.1" xref="S5.T3.6.p2.12.12.12.12.12.3.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S5.T3.6.p2.12.12.12.12.12.3.m1.1b"><csymbol cd="latexml" id="S5.T3.6.p2.12.12.12.12.12.3.m1.1.1.cmml" xref="S5.T3.6.p2.12.12.12.12.12.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.6.p2.12.12.12.12.12.3.m1.1c">\pm</annotation></semantics></math><span id="S5.T3.6.p2.12.12.12.12.12.3.1" class="ltx_text" style="font-size:70%;"> 0.4</span></span></span>
</span></span></p>
</span></div>
</div>
</div>
</figure>
<div id="S5.SS3.p2" class="ltx_para ltx_noindent">
<p id="S5.SS3.p2.2" class="ltx_p"><span id="S5.SS3.p2.2.1" class="ltx_text ltx_font_bold">Baselines.</span> <a href="#S5.T3" title="In 5.3 FL baselines â€£ 5 Experiments and Results â€£ Collaborative Visual Place Recognition through Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span>Â <span class="ltx_text ltx_ref_tag">3</span></a> presents a comparative analysis between FedAvg with various server-side optimizers and baselines sourced from the Hierarchical Federated Learning (H-FL) literature <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib46" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">46</span></a>, <a href="#bib.bib20" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">20</span></a>]</cite>. As described in <a href="#S5.SS1" title="5.1 Implementation details â€£ 5 Experiments and Results â€£ Collaborative Visual Place Recognition through Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Sec.</span>Â <span class="ltx_text ltx_ref_tag">5.1</span></a>, we distinguish between H-FL at city (C) and continent level (CC). To ensure a fair comparison with H-FL, which selects 5 clients from each cluster per round, we additionally run FedAvg with 20 clients per round and <math id="S5.SS3.p2.1.m1.1" class="ltx_Math" alttext="T=75" display="inline"><semantics id="S5.SS3.p2.1.m1.1a"><mrow id="S5.SS3.p2.1.m1.1.1" xref="S5.SS3.p2.1.m1.1.1.cmml"><mi id="S5.SS3.p2.1.m1.1.1.2" xref="S5.SS3.p2.1.m1.1.1.2.cmml">T</mi><mo id="S5.SS3.p2.1.m1.1.1.1" xref="S5.SS3.p2.1.m1.1.1.1.cmml">=</mo><mn id="S5.SS3.p2.1.m1.1.1.3" xref="S5.SS3.p2.1.m1.1.1.3.cmml">75</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.1.m1.1b"><apply id="S5.SS3.p2.1.m1.1.1.cmml" xref="S5.SS3.p2.1.m1.1.1"><eq id="S5.SS3.p2.1.m1.1.1.1.cmml" xref="S5.SS3.p2.1.m1.1.1.1"></eq><ci id="S5.SS3.p2.1.m1.1.1.2.cmml" xref="S5.SS3.p2.1.m1.1.1.2">ğ‘‡</ci><cn type="integer" id="S5.SS3.p2.1.m1.1.1.3.cmml" xref="S5.SS3.p2.1.m1.1.1.3">75</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.1.m1.1c">T=75</annotation></semantics></math>, and 105 participating clients for <math id="S5.SS3.p2.2.m2.1" class="ltx_Math" alttext="T=15" display="inline"><semantics id="S5.SS3.p2.2.m2.1a"><mrow id="S5.SS3.p2.2.m2.1.1" xref="S5.SS3.p2.2.m2.1.1.cmml"><mi id="S5.SS3.p2.2.m2.1.1.2" xref="S5.SS3.p2.2.m2.1.1.2.cmml">T</mi><mo id="S5.SS3.p2.2.m2.1.1.1" xref="S5.SS3.p2.2.m2.1.1.1.cmml">=</mo><mn id="S5.SS3.p2.2.m2.1.1.3" xref="S5.SS3.p2.2.m2.1.1.3.cmml">15</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.2.m2.1b"><apply id="S5.SS3.p2.2.m2.1.1.cmml" xref="S5.SS3.p2.2.m2.1.1"><eq id="S5.SS3.p2.2.m2.1.1.1.cmml" xref="S5.SS3.p2.2.m2.1.1.1"></eq><ci id="S5.SS3.p2.2.m2.1.1.2.cmml" xref="S5.SS3.p2.2.m2.1.1.2">ğ‘‡</ci><cn type="integer" id="S5.SS3.p2.2.m2.1.1.3.cmml" xref="S5.SS3.p2.2.m2.1.1.3">15</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.2.m2.1c">T=15</annotation></semantics></math> rounds.
Both H-FL experiments exhibit a reduction in recall by approximately 10%. We posit that this substantial decline in performance stems from clusters tending to overfit the local distributions, thereby diminishing the meaningfulness of aggregation compared to training with all clients collectively.
Concerning the server optimizers, AdaGrad demonstrates slightly superior performance compared to others. As a result, we opt to employ the standard SGD without momentum for the other baselines.</p>
</div>
</section>
<section id="S5.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4 </span>Data Quantity Skewness in FedVPR</h3>

<figure id="S5.T4" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S5.T4.18.2.1" class="ltx_text" style="font-size:90%;">Table 4</span>: </span><span id="S5.T4.2.1" class="ltx_text" style="font-size:90%;">Addressing the clientsâ€™ quantity heterogeneity. We compare the R@1 (%) of the FedAvg baseline (grey background) with the ones of FedAvg and FedVC <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib32" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">32</span></a>]</cite> with a fixed number of iterations per client per round. <math id="S5.T4.2.1.m1.1" class="ltx_Math" alttext="B" display="inline"><semantics id="S5.T4.2.1.m1.1b"><mi id="S5.T4.2.1.m1.1.1" xref="S5.T4.2.1.m1.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="S5.T4.2.1.m1.1c"><ci id="S5.T4.2.1.m1.1.1.cmml" xref="S5.T4.2.1.m1.1.1">ğµ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.2.1.m1.1d">B</annotation></semantics></math> is the local mini-batch size.</span></figcaption>
<div id="S5.T4.16" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:208.5pt;height:144pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="S5.T4.16.14" class="ltx_p"><span id="S5.T4.16.14.14" class="ltx_text">
<span id="S5.T4.16.14.14.14" class="ltx_tabular ltx_align_middle">
<span id="S5.T4.16.14.14.14.15" class="ltx_tr">
<span id="S5.T4.16.14.14.14.15.1" class="ltx_td ltx_align_center ltx_border_tt"><span id="S5.T4.16.14.14.14.15.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Local Iterations</span></span>
<span id="S5.T4.16.14.14.14.15.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S5.T4.16.14.14.14.15.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Rounds</span></span>
<span id="S5.T4.16.14.14.14.15.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S5.T4.16.14.14.14.15.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">FedAvg</span></span>
<span id="S5.T4.16.14.14.14.15.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S5.T4.16.14.14.14.15.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">FedVC</span></span></span>
<span id="S5.T4.4.2.2.2.2" class="ltx_tr" style="background-color:#EBEBEB;">
<span id="S5.T4.3.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_t"><math id="S5.T4.3.1.1.1.1.1.m1.4" class="ltx_Math" style="background-color:#EBEBEB;" alttext="\min\left(\left\lfloor\nicefrac{{|\mathcal{D}_{k}|}}{{B}}\right\rfloor,2500\right)" display="inline"><semantics id="S5.T4.3.1.1.1.1.1.m1.4a"><mrow id="S5.T4.3.1.1.1.1.1.m1.4.4.1" xref="S5.T4.3.1.1.1.1.1.m1.4.4.2.cmml"><mi mathbackground="#EBEBEB" mathsize="80%" id="S5.T4.3.1.1.1.1.1.m1.2.2" xref="S5.T4.3.1.1.1.1.1.m1.2.2.cmml">min</mi><mo id="S5.T4.3.1.1.1.1.1.m1.4.4.1a" xref="S5.T4.3.1.1.1.1.1.m1.4.4.2.cmml">â¡</mo><mrow id="S5.T4.3.1.1.1.1.1.m1.4.4.1.1" xref="S5.T4.3.1.1.1.1.1.m1.4.4.2.cmml"><mo mathbackground="#EBEBEB" id="S5.T4.3.1.1.1.1.1.m1.4.4.1.1.2" xref="S5.T4.3.1.1.1.1.1.m1.4.4.2.cmml">(</mo><mrow id="S5.T4.3.1.1.1.1.1.m1.4.4.1.1.1.2" xref="S5.T4.3.1.1.1.1.1.m1.4.4.1.1.1.1.cmml"><mo mathbackground="#EBEBEB" id="S5.T4.3.1.1.1.1.1.m1.4.4.1.1.1.2.1" xref="S5.T4.3.1.1.1.1.1.m1.4.4.1.1.1.1.1.cmml">âŒŠ</mo><mrow id="S5.T4.3.1.1.1.1.1.m1.1.1" xref="S5.T4.3.1.1.1.1.1.m1.1.1.cmml"><mpadded voffset="0.3em" id="S5.T4.3.1.1.1.1.1.m1.1.1.1.1" xref="S5.T4.3.1.1.1.1.1.m1.1.1.1.2.cmml"><mo mathbackground="#EBEBEB" maxsize="56%" minsize="56%" id="S5.T4.3.1.1.1.1.1.m1.1.1.1.1.2" xref="S5.T4.3.1.1.1.1.1.m1.1.1.1.2.1.cmml">|</mo><msub id="S5.T4.3.1.1.1.1.1.m1.1.1.1.1.1" xref="S5.T4.3.1.1.1.1.1.m1.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" mathbackground="#EBEBEB" mathsize="56%" id="S5.T4.3.1.1.1.1.1.m1.1.1.1.1.1.2" xref="S5.T4.3.1.1.1.1.1.m1.1.1.1.1.1.2.cmml">ğ’Ÿ</mi><mi mathbackground="#EBEBEB" mathsize="57%" id="S5.T4.3.1.1.1.1.1.m1.1.1.1.1.1.3" xref="S5.T4.3.1.1.1.1.1.m1.1.1.1.1.1.3.cmml">k</mi></msub><mo mathbackground="#EBEBEB" maxsize="56%" minsize="56%" id="S5.T4.3.1.1.1.1.1.m1.1.1.1.1.3" xref="S5.T4.3.1.1.1.1.1.m1.1.1.1.2.1.cmml">|</mo></mpadded><mpadded lspace="-0.1em" width="-0.15em" id="S5.T4.3.1.1.1.1.1.m1.1.1.2" xref="S5.T4.3.1.1.1.1.1.m1.1.1.2.cmml"><mo mathbackground="#EBEBEB" stretchy="true" symmetric="true" id="S5.T4.3.1.1.1.1.1.m1.1.1.2a" xref="S5.T4.3.1.1.1.1.1.m1.1.1.2.cmml">/</mo></mpadded><mi mathbackground="#EBEBEB" mathsize="56%" id="S5.T4.3.1.1.1.1.1.m1.1.1.3" xref="S5.T4.3.1.1.1.1.1.m1.1.1.3.cmml">B</mi></mrow><mo mathbackground="#EBEBEB" id="S5.T4.3.1.1.1.1.1.m1.4.4.1.1.1.2.2" xref="S5.T4.3.1.1.1.1.1.m1.4.4.1.1.1.1.1.cmml">âŒ‹</mo></mrow><mo mathbackground="#EBEBEB" mathsize="80%" id="S5.T4.3.1.1.1.1.1.m1.4.4.1.1.3" xref="S5.T4.3.1.1.1.1.1.m1.4.4.2.cmml">,</mo><mn mathbackground="#EBEBEB" mathsize="80%" id="S5.T4.3.1.1.1.1.1.m1.3.3" xref="S5.T4.3.1.1.1.1.1.m1.3.3.cmml">2500</mn><mo mathbackground="#EBEBEB" id="S5.T4.3.1.1.1.1.1.m1.4.4.1.1.4" xref="S5.T4.3.1.1.1.1.1.m1.4.4.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.T4.3.1.1.1.1.1.m1.4b"><apply id="S5.T4.3.1.1.1.1.1.m1.4.4.2.cmml" xref="S5.T4.3.1.1.1.1.1.m1.4.4.1"><min id="S5.T4.3.1.1.1.1.1.m1.2.2.cmml" xref="S5.T4.3.1.1.1.1.1.m1.2.2"></min><apply id="S5.T4.3.1.1.1.1.1.m1.4.4.1.1.1.1.cmml" xref="S5.T4.3.1.1.1.1.1.m1.4.4.1.1.1.2"><floor id="S5.T4.3.1.1.1.1.1.m1.4.4.1.1.1.1.1.cmml" xref="S5.T4.3.1.1.1.1.1.m1.4.4.1.1.1.2.1"></floor><apply id="S5.T4.3.1.1.1.1.1.m1.1.1.cmml" xref="S5.T4.3.1.1.1.1.1.m1.1.1"><divide id="S5.T4.3.1.1.1.1.1.m1.1.1.2.cmml" xref="S5.T4.3.1.1.1.1.1.m1.1.1.2"></divide><apply id="S5.T4.3.1.1.1.1.1.m1.1.1.1.2.cmml" xref="S5.T4.3.1.1.1.1.1.m1.1.1.1.1"><abs id="S5.T4.3.1.1.1.1.1.m1.1.1.1.2.1.cmml" xref="S5.T4.3.1.1.1.1.1.m1.1.1.1.1.2"></abs><apply id="S5.T4.3.1.1.1.1.1.m1.1.1.1.1.1.cmml" xref="S5.T4.3.1.1.1.1.1.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S5.T4.3.1.1.1.1.1.m1.1.1.1.1.1.1.cmml" xref="S5.T4.3.1.1.1.1.1.m1.1.1.1.1.1">subscript</csymbol><ci id="S5.T4.3.1.1.1.1.1.m1.1.1.1.1.1.2.cmml" xref="S5.T4.3.1.1.1.1.1.m1.1.1.1.1.1.2">ğ’Ÿ</ci><ci id="S5.T4.3.1.1.1.1.1.m1.1.1.1.1.1.3.cmml" xref="S5.T4.3.1.1.1.1.1.m1.1.1.1.1.1.3">ğ‘˜</ci></apply></apply><ci id="S5.T4.3.1.1.1.1.1.m1.1.1.3.cmml" xref="S5.T4.3.1.1.1.1.1.m1.1.1.3">ğµ</ci></apply></apply><cn type="integer" id="S5.T4.3.1.1.1.1.1.m1.3.3.cmml" xref="S5.T4.3.1.1.1.1.1.m1.3.3">2500</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.3.1.1.1.1.1.m1.4c">\min\left(\left\lfloor\nicefrac{{|\mathcal{D}_{k}|}}{{B}}\right\rfloor,2500\right)</annotation></semantics></math></span>
<span id="S5.T4.4.2.2.2.2.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T4.4.2.2.2.2.3.1" class="ltx_text" style="font-size:80%;background-color:#EBEBEB;">300</span></span>
<span id="S5.T4.4.2.2.2.2.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T4.4.2.2.2.2.2.1" class="ltx_text" style="font-size:80%;background-color:#EBEBEB;">61.0 <math id="S5.T4.4.2.2.2.2.2.1.m1.1" class="ltx_Math" style="background-color:#EBEBEB;" alttext="\pm" display="inline"><semantics id="S5.T4.4.2.2.2.2.2.1.m1.1a"><mo mathbackground="#EBEBEB" mathsize="88%" id="S5.T4.4.2.2.2.2.2.1.m1.1.1" xref="S5.T4.4.2.2.2.2.2.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S5.T4.4.2.2.2.2.2.1.m1.1b"><csymbol cd="latexml" id="S5.T4.4.2.2.2.2.2.1.m1.1.1.cmml" xref="S5.T4.4.2.2.2.2.2.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.4.2.2.2.2.2.1.m1.1c">\pm</annotation></semantics></math><span id="S5.T4.4.2.2.2.2.2.1.1" class="ltx_text" style="font-size:88%;background-color:#EBEBEB;"> 0.6</span></span></span>
<span id="S5.T4.4.2.2.2.2.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T4.4.2.2.2.2.4.1" class="ltx_text" style="font-size:80%;background-color:#EBEBEB;">-</span></span></span>
<span id="S5.T4.6.4.4.4.4" class="ltx_tr">
<span id="S5.T4.6.4.4.4.4.3" class="ltx_td ltx_align_center"><span id="S5.T4.6.4.4.4.4.3.1" class="ltx_text" style="font-size:80%;">125</span></span>
<span id="S5.T4.6.4.4.4.4.4" class="ltx_td ltx_align_center"><span id="S5.T4.6.4.4.4.4.4.1" class="ltx_text" style="font-size:80%;">3200</span></span>
<span id="S5.T4.5.3.3.3.3.1" class="ltx_td ltx_align_center"><span id="S5.T4.5.3.3.3.3.1.1" class="ltx_text" style="font-size:80%;">66.6 </span><math id="S5.T4.5.3.3.3.3.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T4.5.3.3.3.3.1.m1.1a"><mo mathsize="70%" id="S5.T4.5.3.3.3.3.1.m1.1.1" xref="S5.T4.5.3.3.3.3.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S5.T4.5.3.3.3.3.1.m1.1b"><csymbol cd="latexml" id="S5.T4.5.3.3.3.3.1.m1.1.1.cmml" xref="S5.T4.5.3.3.3.3.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.5.3.3.3.3.1.m1.1c">\pm</annotation></semantics></math><span id="S5.T4.5.3.3.3.3.1.2" class="ltx_text" style="font-size:70%;"> 0.8</span></span>
<span id="S5.T4.6.4.4.4.4.2" class="ltx_td ltx_align_center"><span id="S5.T4.6.4.4.4.4.2.1" class="ltx_text" style="font-size:80%;">62.3 </span><math id="S5.T4.6.4.4.4.4.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T4.6.4.4.4.4.2.m1.1a"><mo mathsize="70%" id="S5.T4.6.4.4.4.4.2.m1.1.1" xref="S5.T4.6.4.4.4.4.2.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S5.T4.6.4.4.4.4.2.m1.1b"><csymbol cd="latexml" id="S5.T4.6.4.4.4.4.2.m1.1.1.cmml" xref="S5.T4.6.4.4.4.4.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.6.4.4.4.4.2.m1.1c">\pm</annotation></semantics></math><span id="S5.T4.6.4.4.4.4.2.2" class="ltx_text" style="font-size:70%;"> 1.1</span></span></span>
<span id="S5.T4.8.6.6.6.6" class="ltx_tr">
<span id="S5.T4.8.6.6.6.6.3" class="ltx_td ltx_align_center"><span id="S5.T4.8.6.6.6.6.3.1" class="ltx_text" style="font-size:80%;">250</span></span>
<span id="S5.T4.8.6.6.6.6.4" class="ltx_td ltx_align_center"><span id="S5.T4.8.6.6.6.6.4.1" class="ltx_text" style="font-size:80%;">1600</span></span>
<span id="S5.T4.7.5.5.5.5.1" class="ltx_td ltx_align_center"><span id="S5.T4.7.5.5.5.5.1.1" class="ltx_text" style="font-size:80%;">66.0 </span><math id="S5.T4.7.5.5.5.5.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T4.7.5.5.5.5.1.m1.1a"><mo mathsize="70%" id="S5.T4.7.5.5.5.5.1.m1.1.1" xref="S5.T4.7.5.5.5.5.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S5.T4.7.5.5.5.5.1.m1.1b"><csymbol cd="latexml" id="S5.T4.7.5.5.5.5.1.m1.1.1.cmml" xref="S5.T4.7.5.5.5.5.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.7.5.5.5.5.1.m1.1c">\pm</annotation></semantics></math><span id="S5.T4.7.5.5.5.5.1.2" class="ltx_text" style="font-size:70%;"> 1.7</span></span>
<span id="S5.T4.8.6.6.6.6.2" class="ltx_td ltx_align_center"><span id="S5.T4.8.6.6.6.6.2.1" class="ltx_text" style="font-size:80%;">65.9 </span><math id="S5.T4.8.6.6.6.6.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T4.8.6.6.6.6.2.m1.1a"><mo mathsize="70%" id="S5.T4.8.6.6.6.6.2.m1.1.1" xref="S5.T4.8.6.6.6.6.2.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S5.T4.8.6.6.6.6.2.m1.1b"><csymbol cd="latexml" id="S5.T4.8.6.6.6.6.2.m1.1.1.cmml" xref="S5.T4.8.6.6.6.6.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.8.6.6.6.6.2.m1.1c">\pm</annotation></semantics></math><span id="S5.T4.8.6.6.6.6.2.2" class="ltx_text" style="font-size:70%;"> 1.0</span></span></span>
<span id="S5.T4.10.8.8.8.8" class="ltx_tr">
<span id="S5.T4.10.8.8.8.8.3" class="ltx_td ltx_align_center"><span id="S5.T4.10.8.8.8.8.3.1" class="ltx_text" style="font-size:80%;">500</span></span>
<span id="S5.T4.10.8.8.8.8.4" class="ltx_td ltx_align_center"><span id="S5.T4.10.8.8.8.8.4.1" class="ltx_text" style="font-size:80%;">800</span></span>
<span id="S5.T4.9.7.7.7.7.1" class="ltx_td ltx_align_center"><span id="S5.T4.9.7.7.7.7.1.1" class="ltx_text" style="font-size:80%;">66.4 </span><math id="S5.T4.9.7.7.7.7.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T4.9.7.7.7.7.1.m1.1a"><mo mathsize="70%" id="S5.T4.9.7.7.7.7.1.m1.1.1" xref="S5.T4.9.7.7.7.7.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S5.T4.9.7.7.7.7.1.m1.1b"><csymbol cd="latexml" id="S5.T4.9.7.7.7.7.1.m1.1.1.cmml" xref="S5.T4.9.7.7.7.7.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.9.7.7.7.7.1.m1.1c">\pm</annotation></semantics></math><span id="S5.T4.9.7.7.7.7.1.2" class="ltx_text" style="font-size:70%;"> 1.6</span></span>
<span id="S5.T4.10.8.8.8.8.2" class="ltx_td ltx_align_center"><span id="S5.T4.10.8.8.8.8.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">67.7 <math id="S5.T4.10.8.8.8.8.2.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T4.10.8.8.8.8.2.1.m1.1a"><mo mathsize="88%" id="S5.T4.10.8.8.8.8.2.1.m1.1.1" xref="S5.T4.10.8.8.8.8.2.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S5.T4.10.8.8.8.8.2.1.m1.1b"><csymbol cd="latexml" id="S5.T4.10.8.8.8.8.2.1.m1.1.1.cmml" xref="S5.T4.10.8.8.8.8.2.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.10.8.8.8.8.2.1.m1.1c">\pm</annotation></semantics></math><span id="S5.T4.10.8.8.8.8.2.1.1" class="ltx_text" style="font-size:88%;"> 0.4</span></span></span></span>
<span id="S5.T4.12.10.10.10.10" class="ltx_tr">
<span id="S5.T4.12.10.10.10.10.3" class="ltx_td ltx_align_center"><span id="S5.T4.12.10.10.10.10.3.1" class="ltx_text" style="font-size:80%;">1000</span></span>
<span id="S5.T4.12.10.10.10.10.4" class="ltx_td ltx_align_center"><span id="S5.T4.12.10.10.10.10.4.1" class="ltx_text" style="font-size:80%;">400</span></span>
<span id="S5.T4.11.9.9.9.9.1" class="ltx_td ltx_align_center"><span id="S5.T4.11.9.9.9.9.1.1" class="ltx_text" style="font-size:80%;">61.7 </span><math id="S5.T4.11.9.9.9.9.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T4.11.9.9.9.9.1.m1.1a"><mo mathsize="70%" id="S5.T4.11.9.9.9.9.1.m1.1.1" xref="S5.T4.11.9.9.9.9.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S5.T4.11.9.9.9.9.1.m1.1b"><csymbol cd="latexml" id="S5.T4.11.9.9.9.9.1.m1.1.1.cmml" xref="S5.T4.11.9.9.9.9.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.11.9.9.9.9.1.m1.1c">\pm</annotation></semantics></math><span id="S5.T4.11.9.9.9.9.1.2" class="ltx_text" style="font-size:70%;"> 2.4</span></span>
<span id="S5.T4.12.10.10.10.10.2" class="ltx_td ltx_align_center"><span id="S5.T4.12.10.10.10.10.2.1" class="ltx_text" style="font-size:80%;">66.8 </span><math id="S5.T4.12.10.10.10.10.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T4.12.10.10.10.10.2.m1.1a"><mo mathsize="70%" id="S5.T4.12.10.10.10.10.2.m1.1.1" xref="S5.T4.12.10.10.10.10.2.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S5.T4.12.10.10.10.10.2.m1.1b"><csymbol cd="latexml" id="S5.T4.12.10.10.10.10.2.m1.1.1.cmml" xref="S5.T4.12.10.10.10.10.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.12.10.10.10.10.2.m1.1c">\pm</annotation></semantics></math><span id="S5.T4.12.10.10.10.10.2.2" class="ltx_text" style="font-size:70%;"> 0.5</span></span></span>
<span id="S5.T4.14.12.12.12.12" class="ltx_tr">
<span id="S5.T4.14.12.12.12.12.3" class="ltx_td ltx_align_center"><span id="S5.T4.14.12.12.12.12.3.1" class="ltx_text" style="font-size:80%;">2000</span></span>
<span id="S5.T4.14.12.12.12.12.4" class="ltx_td ltx_align_center"><span id="S5.T4.14.12.12.12.12.4.1" class="ltx_text" style="font-size:80%;">200</span></span>
<span id="S5.T4.13.11.11.11.11.1" class="ltx_td ltx_align_center"><span id="S5.T4.13.11.11.11.11.1.1" class="ltx_text" style="font-size:80%;">58.8 </span><math id="S5.T4.13.11.11.11.11.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T4.13.11.11.11.11.1.m1.1a"><mo mathsize="70%" id="S5.T4.13.11.11.11.11.1.m1.1.1" xref="S5.T4.13.11.11.11.11.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S5.T4.13.11.11.11.11.1.m1.1b"><csymbol cd="latexml" id="S5.T4.13.11.11.11.11.1.m1.1.1.cmml" xref="S5.T4.13.11.11.11.11.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.13.11.11.11.11.1.m1.1c">\pm</annotation></semantics></math><span id="S5.T4.13.11.11.11.11.1.2" class="ltx_text" style="font-size:70%;"> 1.8</span></span>
<span id="S5.T4.14.12.12.12.12.2" class="ltx_td ltx_align_center"><span id="S5.T4.14.12.12.12.12.2.1" class="ltx_text" style="font-size:80%;">65.2 </span><math id="S5.T4.14.12.12.12.12.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T4.14.12.12.12.12.2.m1.1a"><mo mathsize="70%" id="S5.T4.14.12.12.12.12.2.m1.1.1" xref="S5.T4.14.12.12.12.12.2.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S5.T4.14.12.12.12.12.2.m1.1b"><csymbol cd="latexml" id="S5.T4.14.12.12.12.12.2.m1.1.1.cmml" xref="S5.T4.14.12.12.12.12.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.14.12.12.12.12.2.m1.1c">\pm</annotation></semantics></math><span id="S5.T4.14.12.12.12.12.2.2" class="ltx_text" style="font-size:70%;"> 0.9</span></span></span>
<span id="S5.T4.16.14.14.14.14" class="ltx_tr">
<span id="S5.T4.16.14.14.14.14.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T4.16.14.14.14.14.3.1" class="ltx_text" style="font-size:80%;">4000</span></span>
<span id="S5.T4.16.14.14.14.14.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T4.16.14.14.14.14.4.1" class="ltx_text" style="font-size:80%;">100</span></span>
<span id="S5.T4.15.13.13.13.13.1" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T4.15.13.13.13.13.1.1" class="ltx_text" style="font-size:80%;">57.3 </span><math id="S5.T4.15.13.13.13.13.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T4.15.13.13.13.13.1.m1.1a"><mo mathsize="70%" id="S5.T4.15.13.13.13.13.1.m1.1.1" xref="S5.T4.15.13.13.13.13.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S5.T4.15.13.13.13.13.1.m1.1b"><csymbol cd="latexml" id="S5.T4.15.13.13.13.13.1.m1.1.1.cmml" xref="S5.T4.15.13.13.13.13.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.15.13.13.13.13.1.m1.1c">\pm</annotation></semantics></math><span id="S5.T4.15.13.13.13.13.1.2" class="ltx_text" style="font-size:70%;"> 2.5</span></span>
<span id="S5.T4.16.14.14.14.14.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T4.16.14.14.14.14.2.1" class="ltx_text" style="font-size:80%;">60.6 </span><math id="S5.T4.16.14.14.14.14.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T4.16.14.14.14.14.2.m1.1a"><mo mathsize="70%" id="S5.T4.16.14.14.14.14.2.m1.1.1" xref="S5.T4.16.14.14.14.14.2.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S5.T4.16.14.14.14.14.2.m1.1b"><csymbol cd="latexml" id="S5.T4.16.14.14.14.14.2.m1.1.1.cmml" xref="S5.T4.16.14.14.14.14.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.16.14.14.14.14.2.m1.1c">\pm</annotation></semantics></math><span id="S5.T4.16.14.14.14.14.2.2" class="ltx_text" style="font-size:70%;"> 1.0</span></span></span>
</span><span id="S5.T4.16.14.14.15" class="ltx_text" style="font-size:80%;"></span></span></p>
</span></div>
</figure>
<div id="S5.SS4.p1" class="ltx_para">
<p id="S5.SS4.p1.1" class="ltx_p"><a href="#S4.T1" title="In 4.1 Proposed FL datasets â€£ 4 Decentralizing the MSLS dataset for FL â€£ Collaborative Visual Place Recognition through Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span>Â <span class="ltx_text ltx_ref_tag">1</span></a> highlights significant variations in the number of sequences or images among clients (<em id="S5.SS4.p1.1.1" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S5.SS4.p1.1.2" class="ltx_text"></span>, <span id="S5.SS4.p1.1.3" class="ltx_text ltx_font_italic">quantity heterogeneity</span>), particularly evident in the Proximity split with a radius of 2000m - our reference federated dataset. This section analyzes how this phenomenon affects the final performance.</p>
</div>
<div id="S5.SS4.p2" class="ltx_para">
<p id="S5.SS4.p2.1" class="ltx_p">In heterogeneous settings, an increased number of local training steps (updates within a client over a batch of data) fosters client drift and destructive interference during aggregation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">35</span></a>, <a href="#bib.bib16" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">16</span></a>]</cite>. Thus, a larger local dataset leads to more updates and potentially negatively impacts the training process. Motivated by these insights, <a href="#S5.T4" title="In 5.4 Data Quantity Skewness in FedVPR â€£ 5 Experiments and Results â€£ Collaborative Visual Place Recognition through Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">4</span></a> investigates how the data quantity skewness and the number of local training iterations affect performances of algorithms trained within the FedVPR framework, focusing on FedAvg and the state-of-the-art algorithm FedVC (Federated Virtual Clients) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">32</span></a>]</cite>. FedVC specifically addresses variations in client data sizes by splitting large datasets into smaller clients and replicating smaller ones. This ensures all participating <span id="S5.SS4.p2.1.1" class="ltx_text ltx_font_italic">virtual</span> clients contribute roughly the same amount of data during each training round. To prevent knowledge loss, larger clients are resampled with higher probability.</p>
</div>
<div id="S5.SS4.p3" class="ltx_para">
<p id="S5.SS4.p3.9" class="ltx_p">Given a fixed amount of total iterations <math id="S5.SS4.p3.1.m1.1" class="ltx_Math" alttext="I_{tot}" display="inline"><semantics id="S5.SS4.p3.1.m1.1a"><msub id="S5.SS4.p3.1.m1.1.1" xref="S5.SS4.p3.1.m1.1.1.cmml"><mi id="S5.SS4.p3.1.m1.1.1.2" xref="S5.SS4.p3.1.m1.1.1.2.cmml">I</mi><mrow id="S5.SS4.p3.1.m1.1.1.3" xref="S5.SS4.p3.1.m1.1.1.3.cmml"><mi id="S5.SS4.p3.1.m1.1.1.3.2" xref="S5.SS4.p3.1.m1.1.1.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S5.SS4.p3.1.m1.1.1.3.1" xref="S5.SS4.p3.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S5.SS4.p3.1.m1.1.1.3.3" xref="S5.SS4.p3.1.m1.1.1.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S5.SS4.p3.1.m1.1.1.3.1a" xref="S5.SS4.p3.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S5.SS4.p3.1.m1.1.1.3.4" xref="S5.SS4.p3.1.m1.1.1.3.4.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S5.SS4.p3.1.m1.1b"><apply id="S5.SS4.p3.1.m1.1.1.cmml" xref="S5.SS4.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS4.p3.1.m1.1.1.1.cmml" xref="S5.SS4.p3.1.m1.1.1">subscript</csymbol><ci id="S5.SS4.p3.1.m1.1.1.2.cmml" xref="S5.SS4.p3.1.m1.1.1.2">ğ¼</ci><apply id="S5.SS4.p3.1.m1.1.1.3.cmml" xref="S5.SS4.p3.1.m1.1.1.3"><times id="S5.SS4.p3.1.m1.1.1.3.1.cmml" xref="S5.SS4.p3.1.m1.1.1.3.1"></times><ci id="S5.SS4.p3.1.m1.1.1.3.2.cmml" xref="S5.SS4.p3.1.m1.1.1.3.2">ğ‘¡</ci><ci id="S5.SS4.p3.1.m1.1.1.3.3.cmml" xref="S5.SS4.p3.1.m1.1.1.3.3">ğ‘œ</ci><ci id="S5.SS4.p3.1.m1.1.1.3.4.cmml" xref="S5.SS4.p3.1.m1.1.1.3.4">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p3.1.m1.1c">I_{tot}</annotation></semantics></math>, we either vary the local iterations <math id="S5.SS4.p3.2.m2.1" class="ltx_Math" alttext="I_{loc}" display="inline"><semantics id="S5.SS4.p3.2.m2.1a"><msub id="S5.SS4.p3.2.m2.1.1" xref="S5.SS4.p3.2.m2.1.1.cmml"><mi id="S5.SS4.p3.2.m2.1.1.2" xref="S5.SS4.p3.2.m2.1.1.2.cmml">I</mi><mrow id="S5.SS4.p3.2.m2.1.1.3" xref="S5.SS4.p3.2.m2.1.1.3.cmml"><mi id="S5.SS4.p3.2.m2.1.1.3.2" xref="S5.SS4.p3.2.m2.1.1.3.2.cmml">l</mi><mo lspace="0em" rspace="0em" id="S5.SS4.p3.2.m2.1.1.3.1" xref="S5.SS4.p3.2.m2.1.1.3.1.cmml">â€‹</mo><mi id="S5.SS4.p3.2.m2.1.1.3.3" xref="S5.SS4.p3.2.m2.1.1.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S5.SS4.p3.2.m2.1.1.3.1a" xref="S5.SS4.p3.2.m2.1.1.3.1.cmml">â€‹</mo><mi id="S5.SS4.p3.2.m2.1.1.3.4" xref="S5.SS4.p3.2.m2.1.1.3.4.cmml">c</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S5.SS4.p3.2.m2.1b"><apply id="S5.SS4.p3.2.m2.1.1.cmml" xref="S5.SS4.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS4.p3.2.m2.1.1.1.cmml" xref="S5.SS4.p3.2.m2.1.1">subscript</csymbol><ci id="S5.SS4.p3.2.m2.1.1.2.cmml" xref="S5.SS4.p3.2.m2.1.1.2">ğ¼</ci><apply id="S5.SS4.p3.2.m2.1.1.3.cmml" xref="S5.SS4.p3.2.m2.1.1.3"><times id="S5.SS4.p3.2.m2.1.1.3.1.cmml" xref="S5.SS4.p3.2.m2.1.1.3.1"></times><ci id="S5.SS4.p3.2.m2.1.1.3.2.cmml" xref="S5.SS4.p3.2.m2.1.1.3.2">ğ‘™</ci><ci id="S5.SS4.p3.2.m2.1.1.3.3.cmml" xref="S5.SS4.p3.2.m2.1.1.3.3">ğ‘œ</ci><ci id="S5.SS4.p3.2.m2.1.1.3.4.cmml" xref="S5.SS4.p3.2.m2.1.1.3.4">ğ‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p3.2.m2.1c">I_{loc}</annotation></semantics></math>, or the training rounds <math id="S5.SS4.p3.3.m3.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S5.SS4.p3.3.m3.1a"><mi id="S5.SS4.p3.3.m3.1.1" xref="S5.SS4.p3.3.m3.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S5.SS4.p3.3.m3.1b"><ci id="S5.SS4.p3.3.m3.1.1.cmml" xref="S5.SS4.p3.3.m3.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p3.3.m3.1c">T</annotation></semantics></math> such that <math id="S5.SS4.p3.4.m4.1" class="ltx_Math" alttext="I_{loc}\times T\times|\mathcal{C}^{t}|=I_{tot}" display="inline"><semantics id="S5.SS4.p3.4.m4.1a"><mrow id="S5.SS4.p3.4.m4.1.1" xref="S5.SS4.p3.4.m4.1.1.cmml"><mrow id="S5.SS4.p3.4.m4.1.1.1" xref="S5.SS4.p3.4.m4.1.1.1.cmml"><msub id="S5.SS4.p3.4.m4.1.1.1.3" xref="S5.SS4.p3.4.m4.1.1.1.3.cmml"><mi id="S5.SS4.p3.4.m4.1.1.1.3.2" xref="S5.SS4.p3.4.m4.1.1.1.3.2.cmml">I</mi><mrow id="S5.SS4.p3.4.m4.1.1.1.3.3" xref="S5.SS4.p3.4.m4.1.1.1.3.3.cmml"><mi id="S5.SS4.p3.4.m4.1.1.1.3.3.2" xref="S5.SS4.p3.4.m4.1.1.1.3.3.2.cmml">l</mi><mo lspace="0em" rspace="0em" id="S5.SS4.p3.4.m4.1.1.1.3.3.1" xref="S5.SS4.p3.4.m4.1.1.1.3.3.1.cmml">â€‹</mo><mi id="S5.SS4.p3.4.m4.1.1.1.3.3.3" xref="S5.SS4.p3.4.m4.1.1.1.3.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S5.SS4.p3.4.m4.1.1.1.3.3.1a" xref="S5.SS4.p3.4.m4.1.1.1.3.3.1.cmml">â€‹</mo><mi id="S5.SS4.p3.4.m4.1.1.1.3.3.4" xref="S5.SS4.p3.4.m4.1.1.1.3.3.4.cmml">c</mi></mrow></msub><mo lspace="0.222em" rspace="0.222em" id="S5.SS4.p3.4.m4.1.1.1.2" xref="S5.SS4.p3.4.m4.1.1.1.2.cmml">Ã—</mo><mi id="S5.SS4.p3.4.m4.1.1.1.4" xref="S5.SS4.p3.4.m4.1.1.1.4.cmml">T</mi><mo lspace="0.222em" rspace="0.222em" id="S5.SS4.p3.4.m4.1.1.1.2a" xref="S5.SS4.p3.4.m4.1.1.1.2.cmml">Ã—</mo><mrow id="S5.SS4.p3.4.m4.1.1.1.1.1" xref="S5.SS4.p3.4.m4.1.1.1.1.2.cmml"><mo stretchy="false" id="S5.SS4.p3.4.m4.1.1.1.1.1.2" xref="S5.SS4.p3.4.m4.1.1.1.1.2.1.cmml">|</mo><msup id="S5.SS4.p3.4.m4.1.1.1.1.1.1" xref="S5.SS4.p3.4.m4.1.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.SS4.p3.4.m4.1.1.1.1.1.1.2" xref="S5.SS4.p3.4.m4.1.1.1.1.1.1.2.cmml">ğ’</mi><mi id="S5.SS4.p3.4.m4.1.1.1.1.1.1.3" xref="S5.SS4.p3.4.m4.1.1.1.1.1.1.3.cmml">t</mi></msup><mo stretchy="false" id="S5.SS4.p3.4.m4.1.1.1.1.1.3" xref="S5.SS4.p3.4.m4.1.1.1.1.2.1.cmml">|</mo></mrow></mrow><mo id="S5.SS4.p3.4.m4.1.1.2" xref="S5.SS4.p3.4.m4.1.1.2.cmml">=</mo><msub id="S5.SS4.p3.4.m4.1.1.3" xref="S5.SS4.p3.4.m4.1.1.3.cmml"><mi id="S5.SS4.p3.4.m4.1.1.3.2" xref="S5.SS4.p3.4.m4.1.1.3.2.cmml">I</mi><mrow id="S5.SS4.p3.4.m4.1.1.3.3" xref="S5.SS4.p3.4.m4.1.1.3.3.cmml"><mi id="S5.SS4.p3.4.m4.1.1.3.3.2" xref="S5.SS4.p3.4.m4.1.1.3.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S5.SS4.p3.4.m4.1.1.3.3.1" xref="S5.SS4.p3.4.m4.1.1.3.3.1.cmml">â€‹</mo><mi id="S5.SS4.p3.4.m4.1.1.3.3.3" xref="S5.SS4.p3.4.m4.1.1.3.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S5.SS4.p3.4.m4.1.1.3.3.1a" xref="S5.SS4.p3.4.m4.1.1.3.3.1.cmml">â€‹</mo><mi id="S5.SS4.p3.4.m4.1.1.3.3.4" xref="S5.SS4.p3.4.m4.1.1.3.3.4.cmml">t</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S5.SS4.p3.4.m4.1b"><apply id="S5.SS4.p3.4.m4.1.1.cmml" xref="S5.SS4.p3.4.m4.1.1"><eq id="S5.SS4.p3.4.m4.1.1.2.cmml" xref="S5.SS4.p3.4.m4.1.1.2"></eq><apply id="S5.SS4.p3.4.m4.1.1.1.cmml" xref="S5.SS4.p3.4.m4.1.1.1"><times id="S5.SS4.p3.4.m4.1.1.1.2.cmml" xref="S5.SS4.p3.4.m4.1.1.1.2"></times><apply id="S5.SS4.p3.4.m4.1.1.1.3.cmml" xref="S5.SS4.p3.4.m4.1.1.1.3"><csymbol cd="ambiguous" id="S5.SS4.p3.4.m4.1.1.1.3.1.cmml" xref="S5.SS4.p3.4.m4.1.1.1.3">subscript</csymbol><ci id="S5.SS4.p3.4.m4.1.1.1.3.2.cmml" xref="S5.SS4.p3.4.m4.1.1.1.3.2">ğ¼</ci><apply id="S5.SS4.p3.4.m4.1.1.1.3.3.cmml" xref="S5.SS4.p3.4.m4.1.1.1.3.3"><times id="S5.SS4.p3.4.m4.1.1.1.3.3.1.cmml" xref="S5.SS4.p3.4.m4.1.1.1.3.3.1"></times><ci id="S5.SS4.p3.4.m4.1.1.1.3.3.2.cmml" xref="S5.SS4.p3.4.m4.1.1.1.3.3.2">ğ‘™</ci><ci id="S5.SS4.p3.4.m4.1.1.1.3.3.3.cmml" xref="S5.SS4.p3.4.m4.1.1.1.3.3.3">ğ‘œ</ci><ci id="S5.SS4.p3.4.m4.1.1.1.3.3.4.cmml" xref="S5.SS4.p3.4.m4.1.1.1.3.3.4">ğ‘</ci></apply></apply><ci id="S5.SS4.p3.4.m4.1.1.1.4.cmml" xref="S5.SS4.p3.4.m4.1.1.1.4">ğ‘‡</ci><apply id="S5.SS4.p3.4.m4.1.1.1.1.2.cmml" xref="S5.SS4.p3.4.m4.1.1.1.1.1"><abs id="S5.SS4.p3.4.m4.1.1.1.1.2.1.cmml" xref="S5.SS4.p3.4.m4.1.1.1.1.1.2"></abs><apply id="S5.SS4.p3.4.m4.1.1.1.1.1.1.cmml" xref="S5.SS4.p3.4.m4.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S5.SS4.p3.4.m4.1.1.1.1.1.1.1.cmml" xref="S5.SS4.p3.4.m4.1.1.1.1.1.1">superscript</csymbol><ci id="S5.SS4.p3.4.m4.1.1.1.1.1.1.2.cmml" xref="S5.SS4.p3.4.m4.1.1.1.1.1.1.2">ğ’</ci><ci id="S5.SS4.p3.4.m4.1.1.1.1.1.1.3.cmml" xref="S5.SS4.p3.4.m4.1.1.1.1.1.1.3">ğ‘¡</ci></apply></apply></apply><apply id="S5.SS4.p3.4.m4.1.1.3.cmml" xref="S5.SS4.p3.4.m4.1.1.3"><csymbol cd="ambiguous" id="S5.SS4.p3.4.m4.1.1.3.1.cmml" xref="S5.SS4.p3.4.m4.1.1.3">subscript</csymbol><ci id="S5.SS4.p3.4.m4.1.1.3.2.cmml" xref="S5.SS4.p3.4.m4.1.1.3.2">ğ¼</ci><apply id="S5.SS4.p3.4.m4.1.1.3.3.cmml" xref="S5.SS4.p3.4.m4.1.1.3.3"><times id="S5.SS4.p3.4.m4.1.1.3.3.1.cmml" xref="S5.SS4.p3.4.m4.1.1.3.3.1"></times><ci id="S5.SS4.p3.4.m4.1.1.3.3.2.cmml" xref="S5.SS4.p3.4.m4.1.1.3.3.2">ğ‘¡</ci><ci id="S5.SS4.p3.4.m4.1.1.3.3.3.cmml" xref="S5.SS4.p3.4.m4.1.1.3.3.3">ğ‘œ</ci><ci id="S5.SS4.p3.4.m4.1.1.3.3.4.cmml" xref="S5.SS4.p3.4.m4.1.1.3.3.4">ğ‘¡</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p3.4.m4.1c">I_{loc}\times T\times|\mathcal{C}^{t}|=I_{tot}</annotation></semantics></math>. With larger <math id="S5.SS4.p3.5.m5.1" class="ltx_Math" alttext="I_{loc}" display="inline"><semantics id="S5.SS4.p3.5.m5.1a"><msub id="S5.SS4.p3.5.m5.1.1" xref="S5.SS4.p3.5.m5.1.1.cmml"><mi id="S5.SS4.p3.5.m5.1.1.2" xref="S5.SS4.p3.5.m5.1.1.2.cmml">I</mi><mrow id="S5.SS4.p3.5.m5.1.1.3" xref="S5.SS4.p3.5.m5.1.1.3.cmml"><mi id="S5.SS4.p3.5.m5.1.1.3.2" xref="S5.SS4.p3.5.m5.1.1.3.2.cmml">l</mi><mo lspace="0em" rspace="0em" id="S5.SS4.p3.5.m5.1.1.3.1" xref="S5.SS4.p3.5.m5.1.1.3.1.cmml">â€‹</mo><mi id="S5.SS4.p3.5.m5.1.1.3.3" xref="S5.SS4.p3.5.m5.1.1.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S5.SS4.p3.5.m5.1.1.3.1a" xref="S5.SS4.p3.5.m5.1.1.3.1.cmml">â€‹</mo><mi id="S5.SS4.p3.5.m5.1.1.3.4" xref="S5.SS4.p3.5.m5.1.1.3.4.cmml">c</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S5.SS4.p3.5.m5.1b"><apply id="S5.SS4.p3.5.m5.1.1.cmml" xref="S5.SS4.p3.5.m5.1.1"><csymbol cd="ambiguous" id="S5.SS4.p3.5.m5.1.1.1.cmml" xref="S5.SS4.p3.5.m5.1.1">subscript</csymbol><ci id="S5.SS4.p3.5.m5.1.1.2.cmml" xref="S5.SS4.p3.5.m5.1.1.2">ğ¼</ci><apply id="S5.SS4.p3.5.m5.1.1.3.cmml" xref="S5.SS4.p3.5.m5.1.1.3"><times id="S5.SS4.p3.5.m5.1.1.3.1.cmml" xref="S5.SS4.p3.5.m5.1.1.3.1"></times><ci id="S5.SS4.p3.5.m5.1.1.3.2.cmml" xref="S5.SS4.p3.5.m5.1.1.3.2">ğ‘™</ci><ci id="S5.SS4.p3.5.m5.1.1.3.3.cmml" xref="S5.SS4.p3.5.m5.1.1.3.3">ğ‘œ</ci><ci id="S5.SS4.p3.5.m5.1.1.3.4.cmml" xref="S5.SS4.p3.5.m5.1.1.3.4">ğ‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p3.5.m5.1c">I_{loc}</annotation></semantics></math>, smaller datasets are used multiple times within a client, while fewer iterations might lead to an incomplete view of larger datasets. We set <math id="S5.SS4.p3.6.m6.3" class="ltx_Math" alttext="I_{tot}=2,000,000" display="inline"><semantics id="S5.SS4.p3.6.m6.3a"><mrow id="S5.SS4.p3.6.m6.3.4" xref="S5.SS4.p3.6.m6.3.4.cmml"><msub id="S5.SS4.p3.6.m6.3.4.2" xref="S5.SS4.p3.6.m6.3.4.2.cmml"><mi id="S5.SS4.p3.6.m6.3.4.2.2" xref="S5.SS4.p3.6.m6.3.4.2.2.cmml">I</mi><mrow id="S5.SS4.p3.6.m6.3.4.2.3" xref="S5.SS4.p3.6.m6.3.4.2.3.cmml"><mi id="S5.SS4.p3.6.m6.3.4.2.3.2" xref="S5.SS4.p3.6.m6.3.4.2.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S5.SS4.p3.6.m6.3.4.2.3.1" xref="S5.SS4.p3.6.m6.3.4.2.3.1.cmml">â€‹</mo><mi id="S5.SS4.p3.6.m6.3.4.2.3.3" xref="S5.SS4.p3.6.m6.3.4.2.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S5.SS4.p3.6.m6.3.4.2.3.1a" xref="S5.SS4.p3.6.m6.3.4.2.3.1.cmml">â€‹</mo><mi id="S5.SS4.p3.6.m6.3.4.2.3.4" xref="S5.SS4.p3.6.m6.3.4.2.3.4.cmml">t</mi></mrow></msub><mo id="S5.SS4.p3.6.m6.3.4.1" xref="S5.SS4.p3.6.m6.3.4.1.cmml">=</mo><mrow id="S5.SS4.p3.6.m6.3.4.3.2" xref="S5.SS4.p3.6.m6.3.4.3.1.cmml"><mn id="S5.SS4.p3.6.m6.1.1" xref="S5.SS4.p3.6.m6.1.1.cmml">2</mn><mo id="S5.SS4.p3.6.m6.3.4.3.2.1" xref="S5.SS4.p3.6.m6.3.4.3.1.cmml">,</mo><mn id="S5.SS4.p3.6.m6.2.2" xref="S5.SS4.p3.6.m6.2.2.cmml">000</mn><mo id="S5.SS4.p3.6.m6.3.4.3.2.2" xref="S5.SS4.p3.6.m6.3.4.3.1.cmml">,</mo><mn id="S5.SS4.p3.6.m6.3.3" xref="S5.SS4.p3.6.m6.3.3.cmml">000</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS4.p3.6.m6.3b"><apply id="S5.SS4.p3.6.m6.3.4.cmml" xref="S5.SS4.p3.6.m6.3.4"><eq id="S5.SS4.p3.6.m6.3.4.1.cmml" xref="S5.SS4.p3.6.m6.3.4.1"></eq><apply id="S5.SS4.p3.6.m6.3.4.2.cmml" xref="S5.SS4.p3.6.m6.3.4.2"><csymbol cd="ambiguous" id="S5.SS4.p3.6.m6.3.4.2.1.cmml" xref="S5.SS4.p3.6.m6.3.4.2">subscript</csymbol><ci id="S5.SS4.p3.6.m6.3.4.2.2.cmml" xref="S5.SS4.p3.6.m6.3.4.2.2">ğ¼</ci><apply id="S5.SS4.p3.6.m6.3.4.2.3.cmml" xref="S5.SS4.p3.6.m6.3.4.2.3"><times id="S5.SS4.p3.6.m6.3.4.2.3.1.cmml" xref="S5.SS4.p3.6.m6.3.4.2.3.1"></times><ci id="S5.SS4.p3.6.m6.3.4.2.3.2.cmml" xref="S5.SS4.p3.6.m6.3.4.2.3.2">ğ‘¡</ci><ci id="S5.SS4.p3.6.m6.3.4.2.3.3.cmml" xref="S5.SS4.p3.6.m6.3.4.2.3.3">ğ‘œ</ci><ci id="S5.SS4.p3.6.m6.3.4.2.3.4.cmml" xref="S5.SS4.p3.6.m6.3.4.2.3.4">ğ‘¡</ci></apply></apply><list id="S5.SS4.p3.6.m6.3.4.3.1.cmml" xref="S5.SS4.p3.6.m6.3.4.3.2"><cn type="integer" id="S5.SS4.p3.6.m6.1.1.cmml" xref="S5.SS4.p3.6.m6.1.1">2</cn><cn type="integer" id="S5.SS4.p3.6.m6.2.2.cmml" xref="S5.SS4.p3.6.m6.2.2">000</cn><cn type="integer" id="S5.SS4.p3.6.m6.3.3.cmml" xref="S5.SS4.p3.6.m6.3.3">000</cn></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p3.6.m6.3c">I_{tot}=2,000,000</annotation></semantics></math>, <math id="S5.SS4.p3.7.m7.1" class="ltx_Math" alttext="|\mathcal{C}|^{t}=5" display="inline"><semantics id="S5.SS4.p3.7.m7.1a"><mrow id="S5.SS4.p3.7.m7.1.2" xref="S5.SS4.p3.7.m7.1.2.cmml"><msup id="S5.SS4.p3.7.m7.1.2.2" xref="S5.SS4.p3.7.m7.1.2.2.cmml"><mrow id="S5.SS4.p3.7.m7.1.2.2.2.2" xref="S5.SS4.p3.7.m7.1.2.2.2.1.cmml"><mo stretchy="false" id="S5.SS4.p3.7.m7.1.2.2.2.2.1" xref="S5.SS4.p3.7.m7.1.2.2.2.1.1.cmml">|</mo><mi class="ltx_font_mathcaligraphic" id="S5.SS4.p3.7.m7.1.1" xref="S5.SS4.p3.7.m7.1.1.cmml">ğ’</mi><mo stretchy="false" id="S5.SS4.p3.7.m7.1.2.2.2.2.2" xref="S5.SS4.p3.7.m7.1.2.2.2.1.1.cmml">|</mo></mrow><mi id="S5.SS4.p3.7.m7.1.2.2.3" xref="S5.SS4.p3.7.m7.1.2.2.3.cmml">t</mi></msup><mo id="S5.SS4.p3.7.m7.1.2.1" xref="S5.SS4.p3.7.m7.1.2.1.cmml">=</mo><mn id="S5.SS4.p3.7.m7.1.2.3" xref="S5.SS4.p3.7.m7.1.2.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS4.p3.7.m7.1b"><apply id="S5.SS4.p3.7.m7.1.2.cmml" xref="S5.SS4.p3.7.m7.1.2"><eq id="S5.SS4.p3.7.m7.1.2.1.cmml" xref="S5.SS4.p3.7.m7.1.2.1"></eq><apply id="S5.SS4.p3.7.m7.1.2.2.cmml" xref="S5.SS4.p3.7.m7.1.2.2"><csymbol cd="ambiguous" id="S5.SS4.p3.7.m7.1.2.2.1.cmml" xref="S5.SS4.p3.7.m7.1.2.2">superscript</csymbol><apply id="S5.SS4.p3.7.m7.1.2.2.2.1.cmml" xref="S5.SS4.p3.7.m7.1.2.2.2.2"><abs id="S5.SS4.p3.7.m7.1.2.2.2.1.1.cmml" xref="S5.SS4.p3.7.m7.1.2.2.2.2.1"></abs><ci id="S5.SS4.p3.7.m7.1.1.cmml" xref="S5.SS4.p3.7.m7.1.1">ğ’</ci></apply><ci id="S5.SS4.p3.7.m7.1.2.2.3.cmml" xref="S5.SS4.p3.7.m7.1.2.2.3">ğ‘¡</ci></apply><cn type="integer" id="S5.SS4.p3.7.m7.1.2.3.cmml" xref="S5.SS4.p3.7.m7.1.2.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p3.7.m7.1c">|\mathcal{C}|^{t}=5</annotation></semantics></math> and vary <math id="S5.SS4.p3.8.m8.1" class="ltx_Math" alttext="I_{loc}" display="inline"><semantics id="S5.SS4.p3.8.m8.1a"><msub id="S5.SS4.p3.8.m8.1.1" xref="S5.SS4.p3.8.m8.1.1.cmml"><mi id="S5.SS4.p3.8.m8.1.1.2" xref="S5.SS4.p3.8.m8.1.1.2.cmml">I</mi><mrow id="S5.SS4.p3.8.m8.1.1.3" xref="S5.SS4.p3.8.m8.1.1.3.cmml"><mi id="S5.SS4.p3.8.m8.1.1.3.2" xref="S5.SS4.p3.8.m8.1.1.3.2.cmml">l</mi><mo lspace="0em" rspace="0em" id="S5.SS4.p3.8.m8.1.1.3.1" xref="S5.SS4.p3.8.m8.1.1.3.1.cmml">â€‹</mo><mi id="S5.SS4.p3.8.m8.1.1.3.3" xref="S5.SS4.p3.8.m8.1.1.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S5.SS4.p3.8.m8.1.1.3.1a" xref="S5.SS4.p3.8.m8.1.1.3.1.cmml">â€‹</mo><mi id="S5.SS4.p3.8.m8.1.1.3.4" xref="S5.SS4.p3.8.m8.1.1.3.4.cmml">c</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S5.SS4.p3.8.m8.1b"><apply id="S5.SS4.p3.8.m8.1.1.cmml" xref="S5.SS4.p3.8.m8.1.1"><csymbol cd="ambiguous" id="S5.SS4.p3.8.m8.1.1.1.cmml" xref="S5.SS4.p3.8.m8.1.1">subscript</csymbol><ci id="S5.SS4.p3.8.m8.1.1.2.cmml" xref="S5.SS4.p3.8.m8.1.1.2">ğ¼</ci><apply id="S5.SS4.p3.8.m8.1.1.3.cmml" xref="S5.SS4.p3.8.m8.1.1.3"><times id="S5.SS4.p3.8.m8.1.1.3.1.cmml" xref="S5.SS4.p3.8.m8.1.1.3.1"></times><ci id="S5.SS4.p3.8.m8.1.1.3.2.cmml" xref="S5.SS4.p3.8.m8.1.1.3.2">ğ‘™</ci><ci id="S5.SS4.p3.8.m8.1.1.3.3.cmml" xref="S5.SS4.p3.8.m8.1.1.3.3">ğ‘œ</ci><ci id="S5.SS4.p3.8.m8.1.1.3.4.cmml" xref="S5.SS4.p3.8.m8.1.1.3.4">ğ‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p3.8.m8.1c">I_{loc}</annotation></semantics></math> and <math id="S5.SS4.p3.9.m9.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S5.SS4.p3.9.m9.1a"><mi id="S5.SS4.p3.9.m9.1.1" xref="S5.SS4.p3.9.m9.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S5.SS4.p3.9.m9.1b"><ci id="S5.SS4.p3.9.m9.1.1.cmml" xref="S5.SS4.p3.9.m9.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p3.9.m9.1c">T</annotation></semantics></math>.</p>
</div>
<div id="S5.SS4.p4" class="ltx_para">
<p id="S5.SS4.p4.1" class="ltx_p">This analysis reveals that reducing the influence of data imbalances can improve performance by up to 5%. However, there exists a trade-off between communication rounds and final accuracy. As shown in <a href="#S5.T4" title="In 5.4 Data Quantity Skewness in FedVPR â€£ 5 Experiments and Results â€£ Collaborative Visual Place Recognition through Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">4</span></a>, increasing <math id="S5.SS4.p4.1.m1.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S5.SS4.p4.1.m1.1a"><mi id="S5.SS4.p4.1.m1.1.1" xref="S5.SS4.p4.1.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S5.SS4.p4.1.m1.1b"><ci id="S5.SS4.p4.1.m1.1.1.cmml" xref="S5.SS4.p4.1.m1.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p4.1.m1.1c">T</annotation></semantics></math> (more communication) while reducing the local steps leads to performance improvement. Conversely, excessively increasing local computation at the expense of the number of rounds deteriorates the final performance. Finally, FedVCâ€™s sampling strategy, which favors larger clients, consistently improves performance when each device performs more than 500 local updates per round. However, for fewer local updates (125 and 250), FedVC shows a decrease in accuracy.</p>
</div>
</section>
<section id="S5.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.5 </span>Heterogeneity of Local Augmentations</h3>

<figure id="S5.T5" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S5.T5.7.1.1" class="ltx_text" style="font-size:90%;">Table 5</span>: </span><span id="S5.T5.8.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Augmentation<span id="S5.T5.8.2.1" class="ltx_text ltx_font_medium">. Comparison of data augmentation strategies. The baseline represents training without augmentation, while the Client-specific color jitter strategy aims at simulating the system heterogeneity typical of FL <a href="#S5.SS5" title="5.5 Heterogeneity of Local Augmentations â€£ 5 Experiments and Results â€£ Collaborative Visual Place Recognition through Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Sec.</span>Â <span class="ltx_text ltx_ref_tag">5.5</span></a>.</span></span></figcaption>
<table id="S5.T5.4" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S5.T5.4.5" class="ltx_tr">
<td id="S5.T5.4.5.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S5.T5.4.5.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Augmentation</span></td>
<td id="S5.T5.4.5.2" class="ltx_td ltx_align_left ltx_border_tt"><span id="S5.T5.4.5.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">R@1 (%)</span></td>
</tr>
<tr id="S5.T5.1.1" class="ltx_tr" style="background-color:#EBEBEB;">
<td id="S5.T5.1.1.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T5.1.1.2.1" class="ltx_text" style="font-size:80%;background-color:#EBEBEB;">Baseline</span></td>
<td id="S5.T5.1.1.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T5.1.1.1.1" class="ltx_text" style="font-size:80%;background-color:#EBEBEB;">61.0 <math id="S5.T5.1.1.1.1.m1.1" class="ltx_Math" style="background-color:#EBEBEB;" alttext="\pm 0.6" display="inline"><semantics id="S5.T5.1.1.1.1.m1.1a"><mrow id="S5.T5.1.1.1.1.m1.1.1" xref="S5.T5.1.1.1.1.m1.1.1.cmml"><mo mathbackground="#EBEBEB" mathsize="88%" id="S5.T5.1.1.1.1.m1.1.1a" xref="S5.T5.1.1.1.1.m1.1.1.cmml">Â±</mo><mn mathbackground="#EBEBEB" mathsize="88%" id="S5.T5.1.1.1.1.m1.1.1.2" xref="S5.T5.1.1.1.1.m1.1.1.2.cmml">0.6</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T5.1.1.1.1.m1.1b"><apply id="S5.T5.1.1.1.1.m1.1.1.cmml" xref="S5.T5.1.1.1.1.m1.1.1"><csymbol cd="latexml" id="S5.T5.1.1.1.1.m1.1.1.1.cmml" xref="S5.T5.1.1.1.1.m1.1.1">plus-or-minus</csymbol><cn type="float" id="S5.T5.1.1.1.1.m1.1.1.2.cmml" xref="S5.T5.1.1.1.1.m1.1.1.2">0.6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.1.1.1.1.m1.1c">\pm 0.6</annotation></semantics></math></span></td>
</tr>
<tr id="S5.T5.2.2" class="ltx_tr">
<td id="S5.T5.2.2.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T5.2.2.2.1" class="ltx_text" style="font-size:80%;">Client-specific color jitter</span></td>
<td id="S5.T5.2.2.1" class="ltx_td ltx_align_left ltx_border_t">
<span id="S5.T5.2.2.1.1" class="ltx_text" style="font-size:80%;">53.5 </span><math id="S5.T5.2.2.1.m1.1" class="ltx_Math" alttext="\pm 2.5" display="inline"><semantics id="S5.T5.2.2.1.m1.1a"><mrow id="S5.T5.2.2.1.m1.1.1" xref="S5.T5.2.2.1.m1.1.1.cmml"><mo mathsize="70%" id="S5.T5.2.2.1.m1.1.1a" xref="S5.T5.2.2.1.m1.1.1.cmml">Â±</mo><mn mathsize="70%" id="S5.T5.2.2.1.m1.1.1.2" xref="S5.T5.2.2.1.m1.1.1.2.cmml">2.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T5.2.2.1.m1.1b"><apply id="S5.T5.2.2.1.m1.1.1.cmml" xref="S5.T5.2.2.1.m1.1.1"><csymbol cd="latexml" id="S5.T5.2.2.1.m1.1.1.1.cmml" xref="S5.T5.2.2.1.m1.1.1">plus-or-minus</csymbol><cn type="float" id="S5.T5.2.2.1.m1.1.1.2.cmml" xref="S5.T5.2.2.1.m1.1.1.2">2.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.2.2.1.m1.1c">\pm 2.5</annotation></semantics></math>
</td>
</tr>
<tr id="S5.T5.3.3" class="ltx_tr">
<td id="S5.T5.3.3.2" class="ltx_td ltx_align_left"><span id="S5.T5.3.3.2.1" class="ltx_text" style="font-size:80%;">Color jitter</span></td>
<td id="S5.T5.3.3.1" class="ltx_td ltx_align_left">
<span id="S5.T5.3.3.1.1" class="ltx_text" style="font-size:80%;">64.7 </span><math id="S5.T5.3.3.1.m1.1" class="ltx_Math" alttext="\pm 0.9" display="inline"><semantics id="S5.T5.3.3.1.m1.1a"><mrow id="S5.T5.3.3.1.m1.1.1" xref="S5.T5.3.3.1.m1.1.1.cmml"><mo mathsize="70%" id="S5.T5.3.3.1.m1.1.1a" xref="S5.T5.3.3.1.m1.1.1.cmml">Â±</mo><mn mathsize="70%" id="S5.T5.3.3.1.m1.1.1.2" xref="S5.T5.3.3.1.m1.1.1.2.cmml">0.9</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T5.3.3.1.m1.1b"><apply id="S5.T5.3.3.1.m1.1.1.cmml" xref="S5.T5.3.3.1.m1.1.1"><csymbol cd="latexml" id="S5.T5.3.3.1.m1.1.1.1.cmml" xref="S5.T5.3.3.1.m1.1.1">plus-or-minus</csymbol><cn type="float" id="S5.T5.3.3.1.m1.1.1.2.cmml" xref="S5.T5.3.3.1.m1.1.1.2">0.9</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.3.3.1.m1.1c">\pm 0.9</annotation></semantics></math>
</td>
</tr>
<tr id="S5.T5.4.4" class="ltx_tr">
<td id="S5.T5.4.4.2" class="ltx_td ltx_align_left ltx_border_bb"><span id="S5.T5.4.4.2.1" class="ltx_text" style="font-size:80%;">Color jitter + random resize crop</span></td>
<td id="S5.T5.4.4.1" class="ltx_td ltx_align_left ltx_border_bb">
<span id="S5.T5.4.4.1.1" class="ltx_text" style="font-size:80%;">65.7 </span><math id="S5.T5.4.4.1.m1.1" class="ltx_Math" alttext="\pm 0.6" display="inline"><semantics id="S5.T5.4.4.1.m1.1a"><mrow id="S5.T5.4.4.1.m1.1.1" xref="S5.T5.4.4.1.m1.1.1.cmml"><mo mathsize="70%" id="S5.T5.4.4.1.m1.1.1a" xref="S5.T5.4.4.1.m1.1.1.cmml">Â±</mo><mn mathsize="70%" id="S5.T5.4.4.1.m1.1.1.2" xref="S5.T5.4.4.1.m1.1.1.2.cmml">0.6</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T5.4.4.1.m1.1b"><apply id="S5.T5.4.4.1.m1.1.1.cmml" xref="S5.T5.4.4.1.m1.1.1"><csymbol cd="latexml" id="S5.T5.4.4.1.m1.1.1.1.cmml" xref="S5.T5.4.4.1.m1.1.1">plus-or-minus</csymbol><cn type="float" id="S5.T5.4.4.1.m1.1.1.2.cmml" xref="S5.T5.4.4.1.m1.1.1.2">0.6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.4.4.1.m1.1c">\pm 0.6</annotation></semantics></math>
</td>
</tr>
</table>
</figure>
<div id="S5.SS5.p1" class="ltx_para">
<p id="S5.SS5.p1.1" class="ltx_p"><a href="#S5.T5" title="In 5.5 Heterogeneity of Local Augmentations â€£ 5 Experiments and Results â€£ Collaborative Visual Place Recognition through Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span>Â <span class="ltx_text ltx_ref_tag">5</span></a> illustrates the performance variations with different levels of data augmentation during training using FedAvg.
Varying levels of color jitter among clients (<span id="S5.SS5.p1.1.1" class="ltx_text ltx_font_italic">client-specific color jitter</span>) simulate significant statistical heterogeneity. This heterogeneity could arise from various sources, as client devices capture data with varying camera qualities and under diverse environmental conditions (lighting, weather).
As expected, this experiment results in a severe performance degradation (<math id="S5.SS5.p1.1.m1.1" class="ltx_Math" alttext="-7.5" display="inline"><semantics id="S5.SS5.p1.1.m1.1a"><mrow id="S5.SS5.p1.1.m1.1.1" xref="S5.SS5.p1.1.m1.1.1.cmml"><mo id="S5.SS5.p1.1.m1.1.1a" xref="S5.SS5.p1.1.m1.1.1.cmml">âˆ’</mo><mn id="S5.SS5.p1.1.m1.1.1.2" xref="S5.SS5.p1.1.m1.1.1.2.cmml">7.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS5.p1.1.m1.1b"><apply id="S5.SS5.p1.1.m1.1.1.cmml" xref="S5.SS5.p1.1.m1.1.1"><minus id="S5.SS5.p1.1.m1.1.1.1.cmml" xref="S5.SS5.p1.1.m1.1.1"></minus><cn type="float" id="S5.SS5.p1.1.m1.1.1.2.cmml" xref="S5.SS5.p1.1.m1.1.1.2">7.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS5.p1.1.m1.1c">-7.5</annotation></semantics></math> points w.r.t. the baseline). To isolate the effects of color jitter augmentation from statistical heterogeneity, we apply the same color jitter augmentation uniformly across all clients, revealing an improvement of nearly 4 percentage points in R@1 w.r.t. the baseline.
An additional random resized crop yields an increase in performance of 1 percentage point. We posit that the substantial benefits observed with stronger data augmentation primarily stem from the relatively small local datasets. Without robust augmentation, clients tend to overfit on local data, culminating in a meaninglessly aggregated model at the end of each round.</p>
</div>
</section>
<section id="S5.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.6 </span>Impact of Data Distribution on Local Mining</h3>

<div id="S5.SS6.p1" class="ltx_para">
<p id="S5.SS6.p1.1" class="ltx_p">As discussed in <a href="#S3.SS1" title="3.1 Centralized VPR â€£ 3 Method â€£ Collaborative Visual Place Recognition through Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Sec.</span>Â <span class="ltx_text ltx_ref_tag">3.1</span></a>, the mining algorithm is a crucial factor affecting performances in VPR.
In centralized training, the model can access the entire database to select negative examples. On the other hand, in FL, clients can only rely on their local collection of images, which come from a limited geographical area, thus limiting the negative sampling distribution.
To study the extent to which this limitation represents an issue for FL, we run centralized experiments with limited available images during mining (<a href="#S5.T6" title="In 5.6 Impact of Data Distribution on Local Mining â€£ 5 Experiments and Results â€£ Collaborative Visual Place Recognition through Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">6</span></a>).
For each query, the server accesses negative images only within the closest <math id="S5.SS6.p1.1.m1.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S5.SS6.p1.1.m1.1a"><mi id="S5.SS6.p1.1.m1.1.1" xref="S5.SS6.p1.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S5.SS6.p1.1.m1.1b"><ci id="S5.SS6.p1.1.m1.1.1.cmml" xref="S5.SS6.p1.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS6.p1.1.m1.1c">N</annotation></semantics></math> database sequences.</p>
</div>
<figure id="S5.T6" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S5.T6.5.1.1" class="ltx_text" style="font-size:90%;">Table 6</span>: </span><span id="S5.T6.6.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Local mining<span id="S5.T6.6.2.1" class="ltx_text ltx_font_medium">. In a centralized scenario, we constrain the mining procedure to select negatives within the closest database sequences, rather than the global database, to study its effect. This setting emulates a federated scenario.</span></span></figcaption>
<div id="S5.T6.2" class="ltx_logical-block ltx_pruned_first">
<div id="S5.T6.2.p2" class="ltx_para ltx_noindent ltx_align_center">
<div id="S5.T6.2.p2.3" class="ltx_inline-block ltx_transformed_outer" style="width:215.8pt;height:72pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="S5.T6.2.p2.3.3" class="ltx_p"><span id="S5.T6.2.p2.3.3.3" class="ltx_text">
<span id="S5.T6.2.p2.3.3.3.3" class="ltx_tabular ltx_align_middle">
<span id="S5.T6.2.p2.3.3.3.3.4" class="ltx_tr">
<span id="S5.T6.2.p2.3.3.3.3.4.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S5.T6.2.p2.3.3.3.3.4.1.1" class="ltx_text ltx_font_bold">Mining</span></span>
<span id="S5.T6.2.p2.3.3.3.3.4.2" class="ltx_td ltx_align_left ltx_border_tt"><span id="S5.T6.2.p2.3.3.3.3.4.2.1" class="ltx_text ltx_font_bold"># Sequences</span></span>
<span id="S5.T6.2.p2.3.3.3.3.4.3" class="ltx_td ltx_align_left ltx_border_tt"><span id="S5.T6.2.p2.3.3.3.3.4.3.1" class="ltx_text ltx_font_bold">DB size</span></span>
<span id="S5.T6.2.p2.3.3.3.3.4.4" class="ltx_td ltx_align_left ltx_border_tt"><span id="S5.T6.2.p2.3.3.3.3.4.4.1" class="ltx_text ltx_font_bold">R@1</span></span></span>
<span id="S5.T6.2.p2.1.1.1.1.1" class="ltx_tr" style="background-color:#EBEBEB;">
<span id="S5.T6.2.p2.1.1.1.1.1.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T6.2.p2.1.1.1.1.1.2.1" class="ltx_text" style="background-color:#EBEBEB;">Baseline</span></span>
<span id="S5.T6.2.p2.1.1.1.1.1.3" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T6.2.p2.1.1.1.1.1.3.1" class="ltx_text" style="background-color:#EBEBEB;">-</span></span>
<span id="S5.T6.2.p2.1.1.1.1.1.4" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T6.2.p2.1.1.1.1.1.4.1" class="ltx_text" style="background-color:#EBEBEB;">1k</span></span>
<span id="S5.T6.2.p2.1.1.1.1.1.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T6.2.p2.1.1.1.1.1.1.1" class="ltx_text" style="background-color:#EBEBEB;">66.0 <math id="S5.T6.2.p2.1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\pm 0.4" display="inline"><semantics id="S5.T6.2.p2.1.1.1.1.1.1.1.m1.1a"><mrow id="S5.T6.2.p2.1.1.1.1.1.1.1.m1.1.1" xref="S5.T6.2.p2.1.1.1.1.1.1.1.m1.1.1.cmml"><mo mathbackground="#EBEBEB" mathsize="70%" id="S5.T6.2.p2.1.1.1.1.1.1.1.m1.1.1a" xref="S5.T6.2.p2.1.1.1.1.1.1.1.m1.1.1.cmml">Â±</mo><mn mathbackground="#EBEBEB" mathsize="70%" id="S5.T6.2.p2.1.1.1.1.1.1.1.m1.1.1.2" xref="S5.T6.2.p2.1.1.1.1.1.1.1.m1.1.1.2.cmml">0.4</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T6.2.p2.1.1.1.1.1.1.1.m1.1b"><apply id="S5.T6.2.p2.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S5.T6.2.p2.1.1.1.1.1.1.1.m1.1.1"><csymbol cd="latexml" id="S5.T6.2.p2.1.1.1.1.1.1.1.m1.1.1.1.cmml" xref="S5.T6.2.p2.1.1.1.1.1.1.1.m1.1.1">plus-or-minus</csymbol><cn type="float" id="S5.T6.2.p2.1.1.1.1.1.1.1.m1.1.1.2.cmml" xref="S5.T6.2.p2.1.1.1.1.1.1.1.m1.1.1.2">0.4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.2.p2.1.1.1.1.1.1.1.m1.1c">\pm 0.4</annotation></semantics></math></span></span></span>
<span id="S5.T6.2.p2.2.2.2.2.2" class="ltx_tr">
<span id="S5.T6.2.p2.2.2.2.2.2.2" class="ltx_td ltx_align_left ltx_border_t">Local</span>
<span id="S5.T6.2.p2.2.2.2.2.2.3" class="ltx_td ltx_align_left ltx_border_t">333</span>
<span id="S5.T6.2.p2.2.2.2.2.2.4" class="ltx_td ltx_align_left ltx_border_t">28k</span>
<span id="S5.T6.2.p2.2.2.2.2.2.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T6.2.p2.2.2.2.2.2.1.1" class="ltx_text ltx_font_bold">68.8</span> <math id="S5.T6.2.p2.2.2.2.2.2.1.m1.1" class="ltx_Math" alttext="\pm\textbf{0.2}" display="inline"><semantics id="S5.T6.2.p2.2.2.2.2.2.1.m1.1a"><mrow id="S5.T6.2.p2.2.2.2.2.2.1.m1.1.1" xref="S5.T6.2.p2.2.2.2.2.2.1.m1.1.1.cmml"><mo mathsize="70%" id="S5.T6.2.p2.2.2.2.2.2.1.m1.1.1a" xref="S5.T6.2.p2.2.2.2.2.2.1.m1.1.1.cmml">Â±</mo><mtext class="ltx_mathvariant_bold" mathsize="70%" id="S5.T6.2.p2.2.2.2.2.2.1.m1.1.1.2" xref="S5.T6.2.p2.2.2.2.2.2.1.m1.1.1.2a.cmml">0.2</mtext></mrow><annotation-xml encoding="MathML-Content" id="S5.T6.2.p2.2.2.2.2.2.1.m1.1b"><apply id="S5.T6.2.p2.2.2.2.2.2.1.m1.1.1.cmml" xref="S5.T6.2.p2.2.2.2.2.2.1.m1.1.1"><csymbol cd="latexml" id="S5.T6.2.p2.2.2.2.2.2.1.m1.1.1.1.cmml" xref="S5.T6.2.p2.2.2.2.2.2.1.m1.1.1">plus-or-minus</csymbol><ci id="S5.T6.2.p2.2.2.2.2.2.1.m1.1.1.2a.cmml" xref="S5.T6.2.p2.2.2.2.2.2.1.m1.1.1.2"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="S5.T6.2.p2.2.2.2.2.2.1.m1.1.1.2.cmml" xref="S5.T6.2.p2.2.2.2.2.2.1.m1.1.1.2">0.2</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.2.p2.2.2.2.2.2.1.m1.1c">\pm\textbf{0.2}</annotation></semantics></math></span></span>
<span id="S5.T6.2.p2.3.3.3.3.3" class="ltx_tr">
<span id="S5.T6.2.p2.3.3.3.3.3.2" class="ltx_td ltx_align_left ltx_border_bb">Local</span>
<span id="S5.T6.2.p2.3.3.3.3.3.3" class="ltx_td ltx_align_left ltx_border_bb">20</span>
<span id="S5.T6.2.p2.3.3.3.3.3.4" class="ltx_td ltx_align_left ltx_border_bb">3k</span>
<span id="S5.T6.2.p2.3.3.3.3.3.1" class="ltx_td ltx_align_left ltx_border_bb">58.0 <math id="S5.T6.2.p2.3.3.3.3.3.1.m1.1" class="ltx_Math" alttext="\pm 0.9" display="inline"><semantics id="S5.T6.2.p2.3.3.3.3.3.1.m1.1a"><mrow id="S5.T6.2.p2.3.3.3.3.3.1.m1.1.1" xref="S5.T6.2.p2.3.3.3.3.3.1.m1.1.1.cmml"><mo mathsize="70%" id="S5.T6.2.p2.3.3.3.3.3.1.m1.1.1a" xref="S5.T6.2.p2.3.3.3.3.3.1.m1.1.1.cmml">Â±</mo><mn mathsize="70%" id="S5.T6.2.p2.3.3.3.3.3.1.m1.1.1.2" xref="S5.T6.2.p2.3.3.3.3.3.1.m1.1.1.2.cmml">0.9</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T6.2.p2.3.3.3.3.3.1.m1.1b"><apply id="S5.T6.2.p2.3.3.3.3.3.1.m1.1.1.cmml" xref="S5.T6.2.p2.3.3.3.3.3.1.m1.1.1"><csymbol cd="latexml" id="S5.T6.2.p2.3.3.3.3.3.1.m1.1.1.1.cmml" xref="S5.T6.2.p2.3.3.3.3.3.1.m1.1.1">plus-or-minus</csymbol><cn type="float" id="S5.T6.2.p2.3.3.3.3.3.1.m1.1.1.2.cmml" xref="S5.T6.2.p2.3.3.3.3.3.1.m1.1.1.2">0.9</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.2.p2.3.3.3.3.3.1.m1.1c">\pm 0.9</annotation></semantics></math></span></span>
</span></span></p>
</span></div>
</div>
</div>
</figure>
<div id="S5.SS6.p2" class="ltx_para">
<p id="S5.SS6.p2.1" class="ltx_p">The results confirm our expectation that focusing on an overly restricted geographical range of images can hinder performance in VPR. Interestingly, having an extremely wide geographical spread of images doesnâ€™t necessarily lead to better learning either.
Limiting the image range to a moderate level (<math id="S5.SS6.p2.1.m1.1" class="ltx_Math" alttext="\approx 333" display="inline"><semantics id="S5.SS6.p2.1.m1.1a"><mrow id="S5.SS6.p2.1.m1.1.1" xref="S5.SS6.p2.1.m1.1.1.cmml"><mi id="S5.SS6.p2.1.m1.1.1.2" xref="S5.SS6.p2.1.m1.1.1.2.cmml"></mi><mo id="S5.SS6.p2.1.m1.1.1.1" xref="S5.SS6.p2.1.m1.1.1.1.cmml">â‰ˆ</mo><mn id="S5.SS6.p2.1.m1.1.1.3" xref="S5.SS6.p2.1.m1.1.1.3.cmml">333</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS6.p2.1.m1.1b"><apply id="S5.SS6.p2.1.m1.1.1.cmml" xref="S5.SS6.p2.1.m1.1.1"><approx id="S5.SS6.p2.1.m1.1.1.1.cmml" xref="S5.SS6.p2.1.m1.1.1.1"></approx><csymbol cd="latexml" id="S5.SS6.p2.1.m1.1.1.2.cmml" xref="S5.SS6.p2.1.m1.1.1.2">absent</csymbol><cn type="integer" id="S5.SS6.p2.1.m1.1.1.3.cmml" xref="S5.SS6.p2.1.m1.1.1.3">333</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS6.p2.1.m1.1c">\approx 333</annotation></semantics></math> sequences, <em id="S5.SS6.p2.1.1" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S5.SS6.p2.1.2" class="ltx_text"></span>, neighborhood to city scale) leads to a slight performance improvement. This suggests that focusing on a localized area can be beneficial for VPR, motivating FedVPR. However, excessively restricting the range to a very local level (20 sequences) proves detrimental, resulting in performance even lower than a FL approach (cf. <a href="#S5.T3" title="In 5.3 FL baselines â€£ 5 Experiments and Results â€£ Collaborative Visual Place Recognition through Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">3</span></a>). This is likely because most clients in the federated setting have access to a wider variety of images.</p>
</div>
<div id="S5.SS6.p3" class="ltx_para">
<p id="S5.SS6.p3.1" class="ltx_p">These findings challenge the traditional assumption that geographical diversity is essential for VPR and suggest that a balance might exist between geographical scope and training data diversity for optimal VPR results.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">In this work, we introduced <span id="S6.p1.1.1" class="ltx_text ltx_font_bold">FedVPR</span>, a novel Federated Learning framework specifically designed for Visual Place Recognition (VPR) tasks. This approach addresses the growing need for distributed VPR solutions in applications like autonomous vehicles and mobile augmented reality. We analyzed the unique challenges of federated VPR compared to classification tasks and demonstrated that FedVPR can achieve performance comparable to a centralized model while minimizing resource consumption on individual devices. Our exploration identified key design choices impacting the performance-cost trade-off, including the number of local iterations, data augmentation strategies, and image resolution. These simple yet effective tools effectively mitigate statistical heterogeneity, validating the feasibility of the FedVPR setting. We believe this work opens a new avenue for VPR research while offering a realistic and valuable task for federated learning research.</p>
</div>
<section id="S6.SS0.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Acknowledgments.</h4>

<div id="S6.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S6.SS0.SSS0.Px1.p1.1" class="ltx_p">This project was supported by CINI (Consorzio Interuniversitario Nazionale per lâ€™Informatica). Computational resources were provided by HPC@POLITO.</p>
</div>
</section>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib1.5.5.1" class="ltx_text" style="font-size:90%;">Acar etÂ al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib1.7.1" class="ltx_text" style="font-size:90%;">
Durmus AlpÂ Emre Acar, Yue Zhao, RamonÂ Matas Navarro, Matthew Mattina, PaulÂ N. Whatmough, and Venkatesh Saligrama.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.8.1" class="ltx_text" style="font-size:90%;">Federated learning based on dynamic regularization, 2021.
</span>
</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib2.5.5.1" class="ltx_text" style="font-size:90%;">Ali-bey etÂ al. [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib2.7.1" class="ltx_text" style="font-size:90%;">
Amar Ali-bey, Brahim Chaib-draa, and Philippe GiguÃ¨re.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.8.1" class="ltx_text" style="font-size:90%;">Gsv-cities: Toward appropriate supervised visual place recognition.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib2.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Neurocomputing</em><span id="bib.bib2.10.2" class="ltx_text" style="font-size:90%;">, 513:194â€“203, 2022.
</span>
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib3.5.5.1" class="ltx_text" style="font-size:90%;">Ali-bey etÂ al. [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib3.7.1" class="ltx_text" style="font-size:90%;">
Amar Ali-bey, Brahim Chaib-draa, and Philippe GiguÃ¨re.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.8.1" class="ltx_text" style="font-size:90%;">Mixvpr: Feature mixing for visual place recognition.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib3.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision</em><span id="bib.bib3.11.3" class="ltx_text" style="font-size:90%;">, pages 2998â€“3007, 2023.
</span>
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib4.5.5.1" class="ltx_text" style="font-size:90%;">Anoosheh etÂ al. [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib4.7.1" class="ltx_text" style="font-size:90%;">
Asha Anoosheh, Torsten Sattler, Radu Timofte, Marc Pollefeys, and Luc VanÂ Gool.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.8.1" class="ltx_text" style="font-size:90%;">Night-to-day image translation for retrieval-based localization.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib4.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2019 International Conference on Robotics and Automation (ICRA)</em><span id="bib.bib4.11.3" class="ltx_text" style="font-size:90%;">, pages 5958â€“5964. IEEE, 2019.
</span>
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib5.5.5.1" class="ltx_text" style="font-size:90%;">ArandjeloviÄ‡ etÂ al. [2018]</span></span>
<span class="ltx_bibblock"><span id="bib.bib5.7.1" class="ltx_text" style="font-size:90%;">
Relja ArandjeloviÄ‡, Petr Gronat, Akihiko Torii, Tomas Pajdla, and Josef Sivic.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.8.1" class="ltx_text" style="font-size:90%;">NetVLAD: CNN architecture for weakly supervised place recognition.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib5.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Transactions on Pattern Analysis and Machine Intelligence</em><span id="bib.bib5.10.2" class="ltx_text" style="font-size:90%;">, 40(6):1437â€“1451, 2018.
</span>
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib6.5.5.1" class="ltx_text" style="font-size:90%;">Arcanjo etÂ al. [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib6.7.1" class="ltx_text" style="font-size:90%;">
Bruno Arcanjo, Bruno Ferrarini, Michael Milford, KlausÂ D McDonald-Maier, and Shoaib Ehsan.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.8.1" class="ltx_text" style="font-size:90%;">An efficient and scalable collection of fly-inspired voting units for visual place recognition in changing environments.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib6.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Robotics and Automation Letters</em><span id="bib.bib6.10.2" class="ltx_text" style="font-size:90%;">, 7(2):2527â€“2534, 2022.
</span>
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib7.4.4.1" class="ltx_text" style="font-size:90%;">Babenko and Lempitsky [2015]</span></span>
<span class="ltx_bibblock"><span id="bib.bib7.6.1" class="ltx_text" style="font-size:90%;">
Artem Babenko and Victor Lempitsky.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.7.1" class="ltx_text" style="font-size:90%;">Aggregating deep convolutional features for image retrieval.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib7.8.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1510.07493</em><span id="bib.bib7.9.2" class="ltx_text" style="font-size:90%;">, 2015.
</span>
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib8.5.5.1" class="ltx_text" style="font-size:90%;">Barbarani etÂ al. [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib8.7.1" class="ltx_text" style="font-size:90%;">
Giovanni Barbarani, Mohamad Mostafa, Hajali Bayramov, Gabriele Trivigno, Gabriele Berton, Carlo Masone, and Barbara Caputo.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.8.1" class="ltx_text" style="font-size:90%;">Are local features all you need for cross-domain visual place recognition?, 2023.
</span>
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib9.5.5.1" class="ltx_text" style="font-size:90%;">Berton etÂ al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib9.7.1" class="ltx_text" style="font-size:90%;">
Gabriele Berton, Carlo Masone, Valerio Paolicelli, and Barbara Caputo.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.8.1" class="ltx_text" style="font-size:90%;">Viewpoint invariant dense matching for visual geolocalization.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib9.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE International Conference on Computer Vision</em><span id="bib.bib9.11.3" class="ltx_text" style="font-size:90%;">, pages 12169â€“12178, 2021.
</span>
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib10.5.5.1" class="ltx_text" style="font-size:90%;">Berton etÂ al. [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib10.7.1" class="ltx_text" style="font-size:90%;">
Gabriele Berton, Carlo Masone, and Barbara Caputo.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.8.1" class="ltx_text" style="font-size:90%;">Rethinking visual geo-localization for large-scale applications.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib10.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em><span id="bib.bib10.11.3" class="ltx_text" style="font-size:90%;">, pages 4878â€“4888, 2022.
</span>
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib11.5.5.1" class="ltx_text" style="font-size:90%;">Berton etÂ al. [2023a]</span></span>
<span class="ltx_bibblock"><span id="bib.bib11.7.1" class="ltx_text" style="font-size:90%;">
Gabriele Berton, Riccardo Mereu, Gabriele Trivigno, Carlo Masone, Gabriela Csurka, Torsten Sattler, and Barbara Caputo.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.8.1" class="ltx_text" style="font-size:90%;">Deep visual geo-localization benchmark, 2023a.
</span>
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib12.5.5.1" class="ltx_text" style="font-size:90%;">Berton etÂ al. [2023b]</span></span>
<span class="ltx_bibblock"><span id="bib.bib12.7.1" class="ltx_text" style="font-size:90%;">
Gabriele Berton, Gabriele Trivigno, Barbara Caputo, and Carlo Masone.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.8.1" class="ltx_text" style="font-size:90%;">Eigenplaces: Training viewpoint robust models for visual place recognition.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib12.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</em><span id="bib.bib12.11.3" class="ltx_text" style="font-size:90%;">, pages 11080â€“11090, 2023b.
</span>
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib13.5.5.1" class="ltx_text" style="font-size:90%;">Berton etÂ al. [2024]</span></span>
<span class="ltx_bibblock"><span id="bib.bib13.7.1" class="ltx_text" style="font-size:90%;">
Gabriele Berton, Gabriele Trivigno, Barbara Caputo, and Carlo Masone.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.8.1" class="ltx_text" style="font-size:90%;">Jist: Joint image and sequence training for sequential visual place recognition.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib13.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Robotics and Automation Letters</em><span id="bib.bib13.10.2" class="ltx_text" style="font-size:90%;">, 9(2):1310â€“1317, 2024.
</span>
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib14.5.5.1" class="ltx_text" style="font-size:90%;">Briggs etÂ al. [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib14.7.1" class="ltx_text" style="font-size:90%;">
Christopher Briggs, Zhong Fan, and Peter Andras.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.8.1" class="ltx_text" style="font-size:90%;">Federated learning with hierarchical clustering of local updates to improve training on non-iid data.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib14.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2020 International Joint Conference on Neural Networks (IJCNN)</em><span id="bib.bib14.11.3" class="ltx_text" style="font-size:90%;">, pages 1â€“9. IEEE, 2020.
</span>
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib15.5.5.1" class="ltx_text" style="font-size:90%;">Caldarola etÂ al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib15.7.1" class="ltx_text" style="font-size:90%;">
Debora Caldarola, Massimiliano Mancini, Fabio Galasso, Marco Ciccone, Emanuele RodolÃ , and Barbara Caputo.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.8.1" class="ltx_text" style="font-size:90%;">Cluster-driven graph federated learning over multiple domains.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib15.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em><span id="bib.bib15.11.3" class="ltx_text" style="font-size:90%;">, pages 2749â€“2758, 2021.
</span>
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib16.5.5.1" class="ltx_text" style="font-size:90%;">Caldarola etÂ al. [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib16.7.1" class="ltx_text" style="font-size:90%;">
Debora Caldarola, Barbara Caputo, and Marco Ciccone.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.8.1" class="ltx_text" style="font-size:90%;">Improving generalization in federated learning by seeking flat minima.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib16.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">European Conference on Computer Vision</em><span id="bib.bib16.11.3" class="ltx_text" style="font-size:90%;">, pages 654â€“672. Springer, 2022.
</span>
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib17.5.5.1" class="ltx_text" style="font-size:90%;">Caldas etÂ al. [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib17.7.1" class="ltx_text" style="font-size:90%;">
Sebastian Caldas, Sai MeherÂ Karthik Duddu, Peter Wu, Tian Li, Jakub KoneÄná»³, HÂ Brendan McMahan, Virginia Smith, and Ameet Talwalkar.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.8.1" class="ltx_text" style="font-size:90%;">Leaf: A benchmark for federated settings.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib17.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Workshop on Federated Learning for Data Privacy and Confidentiality</em><span id="bib.bib17.10.2" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib18.5.5.1" class="ltx_text" style="font-size:90%;">Chatzidakis etÂ al. [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib18.7.1" class="ltx_text" style="font-size:90%;">
Mike Chatzidakis, Junye Chen, Oliver Chick, Eric Circlaeays, Sowmya Gopalan, Yusuf Goren, Kristine Guo, Michael Hesse, Omid Javidbakht, Vojta Jina, Kalu Kalu, Anil Katti, Albert Liu, Richard Low, Audra McMillan, Joey Meyer, Steve Myers, Alex Palmer, David Park, Gianni Parsa, Paul Pelzl, Rehan Rishi, Michael Scaria, Chiraag Sumanth, Kunal Talwar, Karl Tarbe, Shan Wang, and Mayank Yadav.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.8.1" class="ltx_text" style="font-size:90%;">Learning iconic scenes with differential privacy.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib18.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Expo Talk at International Conference on Machine Learning</em><span id="bib.bib18.10.2" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib19.5.5.1" class="ltx_text" style="font-size:90%;">Cheng etÂ al. [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib19.7.1" class="ltx_text" style="font-size:90%;">
Ruiqi Cheng, Kaiwei Wang, Jian Bai, and Zhijie Xu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.8.1" class="ltx_text" style="font-size:90%;">Unifying visual localization and scene recognition for people with visual impairment.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib19.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Access</em><span id="bib.bib19.10.2" class="ltx_text" style="font-size:90%;">, 8:64284â€“64296, 2020.
</span>
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib20.5.5.1" class="ltx_text" style="font-size:90%;">Chu etÂ al. [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib20.7.1" class="ltx_text" style="font-size:90%;">
Shunfeng Chu, Jun Li, Kang Wei, Yuwen Qian, Kunlun Wang, Feng Shu, and Wen Chen.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.8.1" class="ltx_text" style="font-size:90%;">Design of two-level incentive mechanisms for hierarchical federated learning, 2023.
</span>
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib21.5.5.1" class="ltx_text" style="font-size:90%;">Deng etÂ al. [2009]</span></span>
<span class="ltx_bibblock"><span id="bib.bib21.7.1" class="ltx_text" style="font-size:90%;">
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.8.1" class="ltx_text" style="font-size:90%;">Imagenet: A large-scale hierarchical image database.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib21.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2009 IEEE Conference on Computer Vision and Pattern Recognition</em><span id="bib.bib21.11.3" class="ltx_text" style="font-size:90%;">, pages 248â€“255, 2009.
</span>
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib22.5.5.1" class="ltx_text" style="font-size:90%;">Duan etÂ al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib22.7.1" class="ltx_text" style="font-size:90%;">
Moming Duan, Duo Liu, Xinyuan Ji, Yu Wu, Liang Liang, Xianzhang Chen, Yujuan Tan, and Ao Ren.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.8.1" class="ltx_text" style="font-size:90%;">Flexible clustered federated learning for client-level data distribution shift.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib22.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Transactions on Parallel and Distributed Systems</em><span id="bib.bib22.10.2" class="ltx_text" style="font-size:90%;">, 33(11):2661â€“2674, 2021.
</span>
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib23.5.5.1" class="ltx_text" style="font-size:90%;">FanÃ¬ etÂ al. [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib23.7.1" class="ltx_text" style="font-size:90%;">
Eros FanÃ¬, Marco Ciccone, and Barbara Caputo.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.8.1" class="ltx_text" style="font-size:90%;">Feddrive v2: an analysis of the impact of label skewness in federated semantic segmentation for autonomous driving.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib23.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2309.13336</em><span id="bib.bib23.10.2" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib24.5.5.1" class="ltx_text" style="font-size:90%;">Fantauzzo etÂ al. [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib24.7.1" class="ltx_text" style="font-size:90%;">
Lidia Fantauzzo, Eros FanÃ¬, Debora Caldarola, Antonio Tavera, Fabio Cermelli, Marco Ciccone, and Barbara Caputo.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.8.1" class="ltx_text" style="font-size:90%;">Feddrive: Generalizing federated learning to semantic segmentation in autonomous driving.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib24.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</em><span id="bib.bib24.11.3" class="ltx_text" style="font-size:90%;">, pages 11504â€“11511. IEEE, 2022.
</span>
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib25.4.4.1" class="ltx_text" style="font-size:90%;">Garg and Milford [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib25.6.1" class="ltx_text" style="font-size:90%;">
Sourav Garg and Michael Milford.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.7.1" class="ltx_text" style="font-size:90%;">Seqnet: Learning descriptors for sequence-based hierarchical place recognition.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib25.8.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Robotics and Automation Letters</em><span id="bib.bib25.9.2" class="ltx_text" style="font-size:90%;">, 6(3):4305â€“4312, 2021.
</span>
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib26.5.5.1" class="ltx_text" style="font-size:90%;">Garg etÂ al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib26.7.1" class="ltx_text" style="font-size:90%;">
Sourav Garg, Madhu Vankadari, and Michael Milford.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.8.1" class="ltx_text" style="font-size:90%;">Seqmatchnet: Contrastive learning with sequence matching for place recognition &amp; relocalization.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib26.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">5th Annual Conference on Robot Learning</em><span id="bib.bib26.11.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib27.5.5.1" class="ltx_text" style="font-size:90%;">Ge etÂ al. [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib27.7.1" class="ltx_text" style="font-size:90%;">
Yixiao Ge, Haibo Wang, Feng Zhu, Rui Zhao, and Hongsheng Li.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.8.1" class="ltx_text" style="font-size:90%;">Self-supervising fine-grained region similarities for large-scale image localization.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib27.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Computer Vision â€“ ECCV 2020</em><span id="bib.bib27.11.3" class="ltx_text" style="font-size:90%;">, pages 369â€“386, Cham, 2020. Springer International Publishing.
</span>
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib28.5.5.1" class="ltx_text" style="font-size:90%;">Ghosh etÂ al. [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib28.7.1" class="ltx_text" style="font-size:90%;">
Avishek Ghosh, Jichan Chung, Dong Yin, and Kannan Ramchandran.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.8.1" class="ltx_text" style="font-size:90%;">An efficient framework for clustered federated learning.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib28.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Advances in Neural Information Processing Systems</em><span id="bib.bib28.10.2" class="ltx_text" style="font-size:90%;">, 33:19586â€“19597, 2020.
</span>
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib29.5.5.1" class="ltx_text" style="font-size:90%;">Hausler etÂ al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib29.7.1" class="ltx_text" style="font-size:90%;">
Stephen Hausler, Sourav Garg, Ming Xu, Michael Milford, and Tobias Fischer.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.8.1" class="ltx_text" style="font-size:90%;">Patch-netvlad: Multi-scale fusion of locally-global descriptors for place recognition.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib29.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Conference on Computer Vision and Pattern Recognition</em><span id="bib.bib29.11.3" class="ltx_text" style="font-size:90%;">, pages 14141â€“14152, 2021.
</span>
</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib30.5.5.1" class="ltx_text" style="font-size:90%;">He etÂ al. [2016]</span></span>
<span class="ltx_bibblock"><span id="bib.bib30.7.1" class="ltx_text" style="font-size:90%;">
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.8.1" class="ltx_text" style="font-size:90%;">Deep residual learning for image recognition.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib30.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE conference on computer vision and pattern recognition</em><span id="bib.bib30.11.3" class="ltx_text" style="font-size:90%;">, pages 770â€“778, 2016.
</span>
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib31.5.5.1" class="ltx_text" style="font-size:90%;">Hsu etÂ al. [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib31.7.1" class="ltx_text" style="font-size:90%;">
Tzu-MingÂ Harry Hsu, Hang Qi, and Matthew Brown.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.8.1" class="ltx_text" style="font-size:90%;">Measuring the effects of non-identical data distribution for federated visual classification.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib31.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1909.06335</em><span id="bib.bib31.10.2" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib32.5.5.1" class="ltx_text" style="font-size:90%;">Hsu etÂ al. [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib32.7.1" class="ltx_text" style="font-size:90%;">
Tzu-MingÂ Harry Hsu, Hang Qi, and Matthew Brown.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.8.1" class="ltx_text" style="font-size:90%;">Federated visual classification with real-world data distribution, 2020.
</span>
</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib33.4.4.1" class="ltx_text" style="font-size:90%;">Izquierdo and Civera [2023a]</span></span>
<span class="ltx_bibblock"><span id="bib.bib33.6.1" class="ltx_text" style="font-size:90%;">
Sergio Izquierdo and Javier Civera.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.7.1" class="ltx_text" style="font-size:90%;">Optimal transport aggregation for visual place recognition.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib33.8.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2311.15937</em><span id="bib.bib33.9.2" class="ltx_text" style="font-size:90%;">, 2023a.
</span>
</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib34.4.4.1" class="ltx_text" style="font-size:90%;">Izquierdo and Civera [2023b]</span></span>
<span class="ltx_bibblock"><span id="bib.bib34.6.1" class="ltx_text" style="font-size:90%;">
Sergio Izquierdo and Javier Civera.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.7.1" class="ltx_text" style="font-size:90%;">Optimal transport aggregation for visual place recognition, 2023b.
</span>
</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib35.5.5.1" class="ltx_text" style="font-size:90%;">Karimireddy etÂ al. [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib35.7.1" class="ltx_text" style="font-size:90%;">
SaiÂ Praneeth Karimireddy, Satyen Kale, Mehryar Mohri, Sashank Reddi, Sebastian Stich, and AnandaÂ Theertha Suresh.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.8.1" class="ltx_text" style="font-size:90%;">Scaffold: Stochastic controlled averaging for federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib35.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">International conference on machine learning</em><span id="bib.bib35.11.3" class="ltx_text" style="font-size:90%;">, pages 5132â€“5143. PMLR, 2020.
</span>
</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib36.5.5.1" class="ltx_text" style="font-size:90%;">Keetha etÂ al. [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib36.7.1" class="ltx_text" style="font-size:90%;">
Nikhil Keetha, Avneesh Mishra, Jay Karhade, KrishnaÂ Murthy Jatavallabhula, Sebastian Scherer, Madhava Krishna, and Sourav Garg.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.8.1" class="ltx_text" style="font-size:90%;">Anyloc: Towards universal visual place recognition.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib36.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Robotics and Automation Letters</em><span id="bib.bib36.10.2" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib37.5.5.1" class="ltx_text" style="font-size:90%;">Kim etÂ al. [2017]</span></span>
<span class="ltx_bibblock"><span id="bib.bib37.7.1" class="ltx_text" style="font-size:90%;">
HyoÂ Jin Kim, Enrique Dunn, and Jan-Michael Frahm.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.8.1" class="ltx_text" style="font-size:90%;">Learned contextual feature reweighting for image geo-localization.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib37.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Conference on Computer Vision and Pattern Recognition</em><span id="bib.bib37.11.3" class="ltx_text" style="font-size:90%;">, pages 3251â€“3260, 2017.
</span>
</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib38.4.4.1" class="ltx_text" style="font-size:90%;">Lajoie and Beltrame [2024]</span></span>
<span class="ltx_bibblock"><span id="bib.bib38.6.1" class="ltx_text" style="font-size:90%;">
Pierre-Yves Lajoie and Giovanni Beltrame.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.7.1" class="ltx_text" style="font-size:90%;">Swarm-slam: Sparse decentralized collaborative simultaneous localization and mapping framework for multi-robot systems.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib38.8.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Robotics and Automation Letters</em><span id="bib.bib38.9.2" class="ltx_text" style="font-size:90%;">, 9(1):475â€“482, 2024.
</span>
</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib39.5.5.1" class="ltx_text" style="font-size:90%;">Leyva-Vallina etÂ al. [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib39.7.1" class="ltx_text" style="font-size:90%;">
MarÃ­a Leyva-Vallina, Nicola Strisciuglio, and Nicolai Petkov.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.8.1" class="ltx_text" style="font-size:90%;">Data-efficient large scale place recognition with graded similarity supervision.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib39.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Conference on Computer Vision and Pattern Recognition</em><span id="bib.bib39.11.3" class="ltx_text" style="font-size:90%;">, pages 23487â€“23496, 2023.
</span>
</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib40.5.5.1" class="ltx_text" style="font-size:90%;">Li etÂ al. [2020a]</span></span>
<span class="ltx_bibblock"><span id="bib.bib40.7.1" class="ltx_text" style="font-size:90%;">
Li Li, Yuxi Fan, Mike Tse, and Kuo-Yi Lin.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.8.1" class="ltx_text" style="font-size:90%;">A review of applications in federated learning.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib40.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Computers &amp; Industrial Engineering</em><span id="bib.bib40.10.2" class="ltx_text" style="font-size:90%;">, 149:106854, 2020a.
</span>
</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib41.5.5.1" class="ltx_text" style="font-size:90%;">Li etÂ al. [2020b]</span></span>
<span class="ltx_bibblock"><span id="bib.bib41.7.1" class="ltx_text" style="font-size:90%;">
Tian Li, AnitÂ Kumar Sahu, Ameet Talwalkar, and Virginia Smith.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib41.8.1" class="ltx_text" style="font-size:90%;">Federated learning: Challenges, methods, and future directions.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib41.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Signal Processing Magazine</em><span id="bib.bib41.10.2" class="ltx_text" style="font-size:90%;">, 37(3):50â€“60, 2020b.
</span>
</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib42.5.5.1" class="ltx_text" style="font-size:90%;">Li etÂ al. [2020c]</span></span>
<span class="ltx_bibblock"><span id="bib.bib42.7.1" class="ltx_text" style="font-size:90%;">
Tian Li, AnitÂ Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and Virginia Smith.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.8.1" class="ltx_text" style="font-size:90%;">Federated optimization in heterogeneous networks.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib42.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of Machine learning and systems</em><span id="bib.bib42.10.2" class="ltx_text" style="font-size:90%;">, 2:429â€“450, 2020c.
</span>
</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib43.5.5.1" class="ltx_text" style="font-size:90%;">Li etÂ al. [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib43.7.1" class="ltx_text" style="font-size:90%;">
Yiming Li, Zonglin Lyu, Mingxuan Lu, Chao Chen, Michael Milford, and Chen Feng.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib43.8.1" class="ltx_text" style="font-size:90%;">Collaborative visual place recognition, 2023.
</span>
</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib44.5.5.1" class="ltx_text" style="font-size:90%;">Lin etÂ al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib44.7.1" class="ltx_text" style="font-size:90%;">
BillÂ Yuchen Lin, Chaoyang He, Zihang Zeng, Hulin Wang, Yufen Huang, Christophe Dupuy, Rahul Gupta, Mahdi Soltanolkotabi, Xiang Ren, and Salman Avestimehr.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib44.8.1" class="ltx_text" style="font-size:90%;">Fednlp: Benchmarking federated learning methods for natural language processing tasks.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib44.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2104.08815</em><span id="bib.bib44.10.2" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib45.5.5.1" class="ltx_text" style="font-size:90%;">Liu etÂ al. [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib45.7.1" class="ltx_text" style="font-size:90%;">
Liu Liu, Hongdong Li, and Yuchao Dai.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib45.8.1" class="ltx_text" style="font-size:90%;">Stochastic attraction-repulsion embedding for large scale image localization, 2019.
</span>
</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib46.5.5.1" class="ltx_text" style="font-size:90%;">Liu etÂ al. [2023a]</span></span>
<span class="ltx_bibblock"><span id="bib.bib46.7.1" class="ltx_text" style="font-size:90%;">
Lumin Liu, Jun Zhang, Shenghui Song, and KhaledÂ B. Letaief.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib46.8.1" class="ltx_text" style="font-size:90%;">Hierarchical federated learning with quantization: Convergence analysis and system design.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib46.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Transactions on Wireless Communications</em><span id="bib.bib46.10.2" class="ltx_text" style="font-size:90%;">, 22(1):2â€“18, 2023a.
</span>
</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib47.5.5.1" class="ltx_text" style="font-size:90%;">Liu etÂ al. [2021a]</span></span>
<span class="ltx_bibblock"><span id="bib.bib47.7.1" class="ltx_text" style="font-size:90%;">
Ming Liu, Stella Ho, Mengqi Wang, Longxiang Gao, Yuan Jin, and He Zhang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib47.8.1" class="ltx_text" style="font-size:90%;">Federated learning meets natural language processing: A survey.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib47.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2107.12603</em><span id="bib.bib47.10.2" class="ltx_text" style="font-size:90%;">, 2021a.
</span>
</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib48.5.5.1" class="ltx_text" style="font-size:90%;">Liu etÂ al. [2021b]</span></span>
<span class="ltx_bibblock"><span id="bib.bib48.7.1" class="ltx_text" style="font-size:90%;">
Quande Liu, Cheng Chen, Jing Qin, Qi Dou, and Pheng-Ann Heng.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib48.8.1" class="ltx_text" style="font-size:90%;">Feddg: Federated domain generalization on medical image segmentation via episodic learning in continuous frequency space.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib48.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib48.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em><span id="bib.bib48.11.3" class="ltx_text" style="font-size:90%;">, pages 1013â€“1023, 2021b.
</span>
</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib49.5.5.1" class="ltx_text" style="font-size:90%;">Liu etÂ al. [2023b]</span></span>
<span class="ltx_bibblock"><span id="bib.bib49.7.1" class="ltx_text" style="font-size:90%;">
Zhuoqun Liu, Fan Guo, Heng Liu, Xiaoyue Xiao, and Jin Tang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib49.8.1" class="ltx_text" style="font-size:90%;">CMLocate: A cross-modal automatic visual geo-localization framework for a natural environment without gnss information.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib49.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">IET Image Processing</em><span id="bib.bib49.10.2" class="ltx_text" style="font-size:90%;">, 17(12):3524â€“3540, 2023b.
</span>
</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib50.4.4.1" class="ltx_text" style="font-size:90%;">Lloyd [1982]</span></span>
<span class="ltx_bibblock"><span id="bib.bib50.6.1" class="ltx_text" style="font-size:90%;">
Stuart Lloyd.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib50.7.1" class="ltx_text" style="font-size:90%;">Least squares quantization in pcm.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib50.8.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE transactions on information theory</em><span id="bib.bib50.9.2" class="ltx_text" style="font-size:90%;">, 28(2):129â€“137, 1982.
</span>
</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib51.4.4.1" class="ltx_text" style="font-size:90%;">Masone and Caputo [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib51.6.1" class="ltx_text" style="font-size:90%;">
Carlo Masone and Barbara Caputo.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib51.7.1" class="ltx_text" style="font-size:90%;">A survey on deep visual place recognition.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib51.8.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Access</em><span id="bib.bib51.9.2" class="ltx_text" style="font-size:90%;">, 9:19516â€“19547, 2021.
</span>
</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib52.5.5.1" class="ltx_text" style="font-size:90%;">McMahan etÂ al. [2017]</span></span>
<span class="ltx_bibblock"><span id="bib.bib52.7.1" class="ltx_text" style="font-size:90%;">
Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and BlaiseÂ Aguera y Arcas.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib52.8.1" class="ltx_text" style="font-size:90%;">Communication-efficient learning of deep networks from decentralized data.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib52.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib52.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Artificial intelligence and statistics</em><span id="bib.bib52.11.3" class="ltx_text" style="font-size:90%;">, pages 1273â€“1282. PMLR, 2017.
</span>
</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib53.5.5.1" class="ltx_text" style="font-size:90%;">Mereu etÂ al. [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib53.7.1" class="ltx_text" style="font-size:90%;">
Riccardo Mereu, Gabriele Trivigno, Gabriele Berton, Carlo Masone, and Barbara Caputo.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib53.8.1" class="ltx_text" style="font-size:90%;">Learning sequential descriptors for sequence-based visual place recognition.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib53.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Robotics and Automation Letters</em><span id="bib.bib53.10.2" class="ltx_text" style="font-size:90%;">, 7(4):10383â€“10390, 2022.
</span>
</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib54.5.5.1" class="ltx_text" style="font-size:90%;">MorenoÂ Berton etÂ al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib54.7.1" class="ltx_text" style="font-size:90%;">
Gabriele MorenoÂ Berton, Valerio Paolicelli, Carlo Masone, and Barbara Caputo.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib54.8.1" class="ltx_text" style="font-size:90%;">Adaptive-attentive geolocalization from few queries: a hybrid approach.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib54.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib54.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2021 IEEE Winter Conference on Applications of Computer Vision (WACV)</em><span id="bib.bib54.11.3" class="ltx_text" style="font-size:90%;">, pages 2917â€“2926, 2021.
</span>
</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib55.4.4.1" class="ltx_text" style="font-size:90%;">Peterson [2009]</span></span>
<span class="ltx_bibblock"><span id="bib.bib55.6.1" class="ltx_text" style="font-size:90%;">
LeifÂ E Peterson.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib55.7.1" class="ltx_text" style="font-size:90%;">K-nearest neighbor.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib55.8.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Scholarpedia</em><span id="bib.bib55.9.2" class="ltx_text" style="font-size:90%;">, 4(2):1883, 2009.
</span>
</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib56.5.5.1" class="ltx_text" style="font-size:90%;">RadenoviÄ‡ etÂ al. [2018]</span></span>
<span class="ltx_bibblock"><span id="bib.bib56.7.1" class="ltx_text" style="font-size:90%;">
F. RadenoviÄ‡, G. Tolias, and O. Chum.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib56.8.1" class="ltx_text" style="font-size:90%;">Fine-tuning CNN Image Retrieval with No Human Annotation.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib56.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Transactions on Pattern Analysis and Machine Intelligence</em><span id="bib.bib56.10.2" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib57.5.5.1" class="ltx_text" style="font-size:90%;">Razavian etÂ al. [2016]</span></span>
<span class="ltx_bibblock"><span id="bib.bib57.7.1" class="ltx_text" style="font-size:90%;">
AliÂ S Razavian, Josephine Sullivan, Stefan Carlsson, and Atsuto Maki.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib57.8.1" class="ltx_text" style="font-size:90%;">Visual instance retrieval with deep convolutional networks.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib57.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">ITE Transactions on Media Technology and Applications</em><span id="bib.bib57.10.2" class="ltx_text" style="font-size:90%;">, 4(3):251â€“258, 2016.
</span>
</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib58.5.5.1" class="ltx_text" style="font-size:90%;">Reddi etÂ al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib58.7.1" class="ltx_text" style="font-size:90%;">
Sashank Reddi, Zachary Charles, Manzil Zaheer, Zachary Garrett, Keith Rush, Jakub KoneÄná»³, Sanjiv Kumar, and HÂ Brendan McMahan.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib58.8.1" class="ltx_text" style="font-size:90%;">Adaptive federated optimization.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib58.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">International Conference on Learning Representations</em><span id="bib.bib58.10.2" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib59.4.4.1" class="ltx_text" style="font-size:90%;">Ruder [2016]</span></span>
<span class="ltx_bibblock"><span id="bib.bib59.6.1" class="ltx_text" style="font-size:90%;">
Sebastian Ruder.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib59.7.1" class="ltx_text" style="font-size:90%;">An overview of gradient descent optimization algorithms.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib59.8.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1609.04747</em><span id="bib.bib59.9.2" class="ltx_text" style="font-size:90%;">, 2016.
</span>
</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib60.5.5.1" class="ltx_text" style="font-size:90%;">Sarlin etÂ al. [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib60.7.1" class="ltx_text" style="font-size:90%;">
Paul-Edouard Sarlin, Mihai Dusmanu, JohannesÂ L. SchÃ¶nberger, Pablo Speciale, Lukas Gruber, Viktor Larsson, Ondrej Miksik, and Marc Pollefeys.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib60.8.1" class="ltx_text" style="font-size:90%;">LaMAR: Benchmarking localization and mapping for augmented reality.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib60.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib60.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">European Conference on Computer Vision</em><span id="bib.bib60.11.3" class="ltx_text" style="font-size:90%;">, pages 686â€“704, Cham, 2022. Springer Nature Switzerland.
</span>
</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib61.5.5.1" class="ltx_text" style="font-size:90%;">Sattler etÂ al. [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib61.7.1" class="ltx_text" style="font-size:90%;">
Felix Sattler, Klaus-Robert MÃ¼ller, and Wojciech Samek.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib61.8.1" class="ltx_text" style="font-size:90%;">Clustered federated learning: Model-agnostic distributed multitask optimization under privacy constraints.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib61.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE transactions on neural networks and learning systems</em><span id="bib.bib61.10.2" class="ltx_text" style="font-size:90%;">, 32(8):3710â€“3722, 2020.
</span>
</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib62.5.5.1" class="ltx_text" style="font-size:90%;">Shenaj etÂ al. [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib62.7.1" class="ltx_text" style="font-size:90%;">
Donald Shenaj, Eros FanÃ¬, Marco Toldo, Debora Caldarola, Antonio Tavera, Umberto Michieli, Marco Ciccone, Pietro Zanuttigh, and Barbara Caputo.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib62.8.1" class="ltx_text" style="font-size:90%;">Learning across domains and devices: Style-driven source-free domain adaptation in clustered federated learning, 2022.
</span>
</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib63.4.4.1" class="ltx_text" style="font-size:90%;">Simonyan and Zisserman [2015]</span></span>
<span class="ltx_bibblock"><span id="bib.bib63.6.1" class="ltx_text" style="font-size:90%;">
Karen Simonyan and Andrew Zisserman.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib63.7.1" class="ltx_text" style="font-size:90%;">Very deep convolutional networks for large-scale image recognition, 2015.
</span>
</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib64.5.5.1" class="ltx_text" style="font-size:90%;">Suomela etÂ al. [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib64.7.1" class="ltx_text" style="font-size:90%;">
Lauri Suomela, Jussi Kalliola, Harry Edelman, and Joni-Kristian KÃ¤mÃ¤rÃ¤inen.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib64.8.1" class="ltx_text" style="font-size:90%;">Placenav: Topological navigation through place recognition.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib64.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2309.17260</em><span id="bib.bib64.10.2" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib65.5.5.1" class="ltx_text" style="font-size:90%;">Tolias etÂ al. [2016]</span></span>
<span class="ltx_bibblock"><span id="bib.bib65.7.1" class="ltx_text" style="font-size:90%;">
Giorgos Tolias, R. Sicre, and H. JÃ©gou.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib65.8.1" class="ltx_text" style="font-size:90%;">Particular object retrieval with integral max-pooling of CNN activations.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib65.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">CoRR</em><span id="bib.bib65.10.2" class="ltx_text" style="font-size:90%;">, abs/1511.05879, 2016.
</span>
</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib66.5.5.1" class="ltx_text" style="font-size:90%;">Trivigno etÂ al. [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib66.7.1" class="ltx_text" style="font-size:90%;">
Gabriele Trivigno, Gabriele Berton, Juan Aragon, Barbara Caputo, and Carlo Masone.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib66.8.1" class="ltx_text" style="font-size:90%;">Divide&amp;classify: Fine-grained classification for city-wide visual geo-localization.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib66.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib66.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on Computer Vision</em><span id="bib.bib66.11.3" class="ltx_text" style="font-size:90%;">, pages 11142â€“11152, 2023.
</span>
</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib67.5.5.1" class="ltx_text" style="font-size:90%;">Wang etÂ al. [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib67.7.1" class="ltx_text" style="font-size:90%;">
Ruotong Wang, Yanqing Shen, Weiliang Zuo, Sanping Zhou, and Nanning Zheng.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib67.8.1" class="ltx_text" style="font-size:90%;">Transvpr: Transformer-based place recognition with multi-level attention aggregation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib67.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib67.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em><span id="bib.bib67.11.3" class="ltx_text" style="font-size:90%;">, pages 13648â€“13657, 2022.
</span>
</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib68.5.5.1" class="ltx_text" style="font-size:90%;">Warburg etÂ al. [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib68.7.1" class="ltx_text" style="font-size:90%;">
Frederik Warburg, SÃ¸ren Hauberg, Manuel LÃ³pez-Antequera, Pau Gargallo, Yubin Kuang, and Javier Civera.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib68.8.1" class="ltx_text" style="font-size:90%;">Mapillary street-level sequences: A dataset for lifelong place recognition.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib68.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib68.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em><span id="bib.bib68.11.3" class="ltx_text" style="font-size:90%;">, pages 2623â€“2632, 2020.
</span>
</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib69.5.5.1" class="ltx_text" style="font-size:90%;">Zaffar etÂ al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib69.7.1" class="ltx_text" style="font-size:90%;">
Mubariz Zaffar, Sourav Garg, Michael Milford, Julian Kooij, David Flynn, Klaus McDonald-Maier, and Shoaib Ehsan.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib69.8.1" class="ltx_text" style="font-size:90%;">VPR-Bench: An open-source visual place recognition evaluation framework with quantifiable viewpoint and appearance change.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib69.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">International Journal of Computer Vision</em><span id="bib.bib69.10.2" class="ltx_text" style="font-size:90%;">, 129(7):2136â€“2174, 2021.
</span>
</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib70.5.5.1" class="ltx_text" style="font-size:90%;">Zhao etÂ al. [2024]</span></span>
<span class="ltx_bibblock"><span id="bib.bib70.7.1" class="ltx_text" style="font-size:90%;">
Junqiao Zhao, Fenglin Zhang, Yingfeng Cai, Gengxuan Tian, Wenjie Mu, Chen Ye, and Tiantian Feng.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib70.8.1" class="ltx_text" style="font-size:90%;">Learning sequence descriptor based on spatio-temporal attention for visual place recognition.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib70.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Robotics and Automation Letters</em><span id="bib.bib70.10.2" class="ltx_text" style="font-size:90%;">, 9(3):2351â€“2358, 2024.
</span>
</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib71.5.5.1" class="ltx_text" style="font-size:90%;">Zhu etÂ al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib71.7.1" class="ltx_text" style="font-size:90%;">
Hangyu Zhu, Jinjin Xu, Shiqing Liu, and Yaochu Jin.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib71.8.1" class="ltx_text" style="font-size:90%;">Federated learning on non-iid data: A survey.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib71.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Neurocomputing</em><span id="bib.bib71.10.2" class="ltx_text" style="font-size:90%;">, 465:371â€“390, 2021.
</span>
</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib72.5.5.1" class="ltx_text" style="font-size:90%;">Zhu etÂ al. [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib72.7.1" class="ltx_text" style="font-size:90%;">
Sijie Zhu, Linjie Yang, Chen Chen, Mubarak Shah, Xiaohui Shen, and Heng Wang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib72.8.1" class="ltx_text" style="font-size:90%;">R2former: Unified retrieval and reranking transformer for place recognition.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib72.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib72.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em><span id="bib.bib72.11.3" class="ltx_text" style="font-size:90%;">, pages 19370â€“19380, 2023.
</span>
</span>
</li>
<li id="bib.bib73" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib73.5.5.1" class="ltx_text" style="font-size:90%;">Zhu etÂ al. [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib73.7.1" class="ltx_text" style="font-size:90%;">
Xinghua Zhu, Jianzong Wang, Zhenhou Hong, and Jing Xiao.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib73.8.1" class="ltx_text" style="font-size:90%;">Empirical studies of institutional federated learning for natural language processing.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib73.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib73.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Findings of the Association for Computational Linguistics: EMNLP 2020</em><span id="bib.bib73.11.3" class="ltx_text" style="font-size:90%;">, pages 625â€“634, 2020.
</span>
</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="Ax1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">Appendix</h2>

<div id="Ax1.p1" class="ltx_para">
<p id="Ax1.p1.1" class="ltx_p">The Appendix is organized as follows:</p>
<ul id="Ax1.I1" class="ltx_itemize">
<li id="Ax1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="Ax1.I1.i1.p1" class="ltx_para">
<p id="Ax1.I1.i1.p1.1" class="ltx_p"><a href="#A1" title="Appendix A Centralized runs â€£ Collaborative Visual Place Recognition through Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Appendix</span>Â <span class="ltx_text ltx_ref_tag">A</span></a>: additional details on centralized runs.</p>
</div>
</li>
<li id="Ax1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="Ax1.I1.i2.p1" class="ltx_para">
<p id="Ax1.I1.i2.p1.1" class="ltx_p"><a href="#A2" title="Appendix B Implementation details â€£ Collaborative Visual Place Recognition through Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Appendix</span>Â <span class="ltx_text ltx_ref_tag">B</span></a>: implementation details.</p>
</div>
</li>
<li id="Ax1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="Ax1.I1.i3.p1" class="ltx_para">
<p id="Ax1.I1.i3.p1.1" class="ltx_p"><a href="#A3" title="Appendix C Distribution of clients in federated MSLS â€£ Collaborative Visual Place Recognition through Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Appendix</span>Â <span class="ltx_text ltx_ref_tag">C</span></a>: additional analyses on MSLS Proximity split.</p>
</div>
</li>
<li id="Ax1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="Ax1.I1.i4.p1" class="ltx_para">
<p id="Ax1.I1.i4.p1.1" class="ltx_p"><a href="#A4" title="Appendix D Ablation studies on H-FL â€£ Collaborative Visual Place Recognition through Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Appendix</span>Â <span class="ltx_text ltx_ref_tag">D</span></a>: ablation studies on Hierarchical Federated Learning.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Centralized runs</h2>

<div id="A1.p1" class="ltx_para">
<p id="A1.p1.1" class="ltx_p">This section introduces additional details on the centralized experiments presented in <a href="#S5.SS2" title="5.2 Centralized baselines â€£ 5 Experiments and Results â€£ Collaborative Visual Place Recognition through Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Sec.</span>Â <span class="ltx_text ltx_ref_tag">5.2</span></a>.
Centralized training continues until the network performance plateaus for five consecutive epochs. This approach results in training different networks for a varying number of epochs depending on their convergence speed.
<a href="#A1.T7" title="In Appendix A Centralized runs â€£ Collaborative Visual Place Recognition through Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">7</span></a> compares the selected model architectures in terms of number of epochs, recall and training time. Based on these results and on the number of parameters (<a href="#S5.T2.6" title="In 5 Experiments and Results â€£ Collaborative Visual Place Recognition through Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">2</span></a>), we select ResNet18 truncated as our network.</p>
</div>
<figure id="A1.T7" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="A1.T7.6.1.1" class="ltx_text" style="font-size:90%;">Table 7</span>: </span><span id="A1.T7.7.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Centralized baselines<span id="A1.T7.7.2.1" class="ltx_text ltx_font_medium">: model architectures compared in terms of number of epochs, recall (R@1) and training time in the centralized scenario.
</span></span></figcaption>
<table id="A1.T7.3" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="A1.T7.3.4" class="ltx_tr">
<td id="A1.T7.3.4.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="A1.T7.3.4.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Backbone</span></td>
<td id="A1.T7.3.4.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="A1.T7.3.4.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Epochs</span></td>
<td id="A1.T7.3.4.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="A1.T7.3.4.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">R@1</span></td>
<td id="A1.T7.3.4.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="A1.T7.3.4.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Time</span></td>
</tr>
<tr id="A1.T7.1.1" class="ltx_tr">
<td id="A1.T7.1.1.2" class="ltx_td ltx_align_left ltx_border_t"><span id="A1.T7.1.1.2.1" class="ltx_text" style="font-size:80%;">ResNet18 truncated</span></td>
<td id="A1.T7.1.1.3" class="ltx_td ltx_align_center ltx_border_t"><span id="A1.T7.1.1.3.1" class="ltx_text" style="font-size:80%;">40</span></td>
<td id="A1.T7.1.1.1" class="ltx_td ltx_align_center ltx_border_t">
<span id="A1.T7.1.1.1.1" class="ltx_text" style="font-size:80%;">42.9 </span><math id="A1.T7.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="A1.T7.1.1.1.m1.1a"><mo mathsize="80%" id="A1.T7.1.1.1.m1.1.1" xref="A1.T7.1.1.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="A1.T7.1.1.1.m1.1b"><csymbol cd="latexml" id="A1.T7.1.1.1.m1.1.1.cmml" xref="A1.T7.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T7.1.1.1.m1.1c">\pm</annotation></semantics></math><span id="A1.T7.1.1.1.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T7.1.1.1.3" class="ltx_text" style="font-size:70%;">2.5</span>
</td>
<td id="A1.T7.1.1.4" class="ltx_td ltx_align_center ltx_border_t"><span id="A1.T7.1.1.4.1" class="ltx_text" style="font-size:80%;">15h30</span></td>
</tr>
<tr id="A1.T7.2.2" class="ltx_tr">
<td id="A1.T7.2.2.2" class="ltx_td ltx_align_left"><span id="A1.T7.2.2.2.1" class="ltx_text" style="font-size:80%;">ResNet18</span></td>
<td id="A1.T7.2.2.3" class="ltx_td ltx_align_center"><span id="A1.T7.2.2.3.1" class="ltx_text" style="font-size:80%;">31</span></td>
<td id="A1.T7.2.2.1" class="ltx_td ltx_align_center">
<span id="A1.T7.2.2.1.1" class="ltx_text" style="font-size:80%;">60.1 </span><math id="A1.T7.2.2.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="A1.T7.2.2.1.m1.1a"><mo mathsize="80%" id="A1.T7.2.2.1.m1.1.1" xref="A1.T7.2.2.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="A1.T7.2.2.1.m1.1b"><csymbol cd="latexml" id="A1.T7.2.2.1.m1.1.1.cmml" xref="A1.T7.2.2.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T7.2.2.1.m1.1c">\pm</annotation></semantics></math><span id="A1.T7.2.2.1.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T7.2.2.1.3" class="ltx_text" style="font-size:70%;">0.3</span>
</td>
<td id="A1.T7.2.2.4" class="ltx_td ltx_align_center"><span id="A1.T7.2.2.4.1" class="ltx_text" style="font-size:80%;">10h15</span></td>
</tr>
<tr id="A1.T7.3.3" class="ltx_tr">
<td id="A1.T7.3.3.2" class="ltx_td ltx_align_left ltx_border_bb"><span id="A1.T7.3.3.2.1" class="ltx_text" style="font-size:80%;">VGG16</span></td>
<td id="A1.T7.3.3.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="A1.T7.3.3.3.1" class="ltx_text" style="font-size:80%;">30</span></td>
<td id="A1.T7.3.3.1" class="ltx_td ltx_align_center ltx_border_bb">
<span id="A1.T7.3.3.1.1" class="ltx_text" style="font-size:80%;">46.3 </span><math id="A1.T7.3.3.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="A1.T7.3.3.1.m1.1a"><mo mathsize="80%" id="A1.T7.3.3.1.m1.1.1" xref="A1.T7.3.3.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="A1.T7.3.3.1.m1.1b"><csymbol cd="latexml" id="A1.T7.3.3.1.m1.1.1.cmml" xref="A1.T7.3.3.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T7.3.3.1.m1.1c">\pm</annotation></semantics></math><span id="A1.T7.3.3.1.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T7.3.3.1.3" class="ltx_text" style="font-size:70%;">0.5</span>
</td>
<td id="A1.T7.3.3.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="A1.T7.3.3.4.1" class="ltx_text" style="font-size:80%;">28h30</span></td>
</tr>
</table>
</figure>
</section>
<section id="A2" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Implementation details</h2>

<div id="A2.p1" class="ltx_para">
<p id="A2.p1.1" class="ltx_p">This section extends <a href="#S5.SS1" title="5.1 Implementation details â€£ 5 Experiments and Results â€£ Collaborative Visual Place Recognition through Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Sec.</span>Â <span class="ltx_text ltx_ref_tag">5.1</span></a> with additional implementation details on our experiments. The codebase is written in Python with PyTorch for neural networks optimization. The experiments are run on the Nvidia Titan X GPU with 12GB of VRAM. All runs are averaged across 3 different seeds.</p>
</div>
<div id="A2.p2" class="ltx_para ltx_noindent">
<p id="A2.p2.1" class="ltx_p"><span id="A2.p2.1.1" class="ltx_text ltx_font_bold">Model.</span> The experiments are run using a ResNet18 truncated after the third convolutional layer. The pooling layer is GeM except for the baseline experiments available in <a href="#S5.T2.6" title="In 5 Experiments and Results â€£ Collaborative Visual Place Recognition through Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">2</span></a> where we tested SPOC and MAC as well. The image resolution is always 288x384 pixels except for the cases in <a href="#S5.T2.6" title="In 5 Experiments and Results â€£ Collaborative Visual Place Recognition through Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">2</span></a> and <a href="#S5.F3" title="In 5.1 Implementation details â€£ 5 Experiments and Results â€£ Collaborative Visual Place Recognition through Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">3</span></a> where we tried different values: 96x128, 192x256, 384x512, and 480x640 pixels.</p>
</div>
<div id="A2.p3" class="ltx_para ltx_noindent">
<p id="A2.p3.4" class="ltx_p"><span id="A2.p3.4.1" class="ltx_text ltx_font_bold">FL baselines.</span> The number of rounds <math id="A2.p3.1.m1.1" class="ltx_Math" alttext="T" display="inline"><semantics id="A2.p3.1.m1.1a"><mi id="A2.p3.1.m1.1.1" xref="A2.p3.1.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="A2.p3.1.m1.1b"><ci id="A2.p3.1.m1.1.1.cmml" xref="A2.p3.1.m1.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.p3.1.m1.1c">T</annotation></semantics></math> in the FL experiments is set to 300, with 5 clients per round. The server optimizer is always SGD with learning rate 1, <em id="A2.p3.4.2" class="ltx_emph ltx_font_italic">i.e</em>.<span id="A2.p3.4.3" class="ltx_text"></span>, FedAvg. <a href="#A2.T8" title="In Appendix B Implementation details â€£ Collaborative Visual Place Recognition through Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">8</span></a> reports the hyperparameters used for the ablation on the server-side optimizers (<span id="A2.p3.4.4" class="ltx_text ltx_font_smallcaps">ServerOpt</span> in <a href="#S3.SS2" title="3.2 Federated Visual Place Recognition (FedVPR) â€£ 3 Method â€£ Collaborative Visual Place Recognition through Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Sec.</span>Â <span class="ltx_text ltx_ref_tag">3.2</span></a>) from <a href="#S5.T3" title="In 5.3 FL baselines â€£ 5 Experiments and Results â€£ Collaborative Visual Place Recognition through Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">3</span></a>.
In local training, the optimizer is Adam with learning rate is always set to <math id="A2.p3.2.m2.1" class="ltx_Math" alttext="1e-5" display="inline"><semantics id="A2.p3.2.m2.1a"><mrow id="A2.p3.2.m2.1.1" xref="A2.p3.2.m2.1.1.cmml"><mrow id="A2.p3.2.m2.1.1.2" xref="A2.p3.2.m2.1.1.2.cmml"><mn id="A2.p3.2.m2.1.1.2.2" xref="A2.p3.2.m2.1.1.2.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="A2.p3.2.m2.1.1.2.1" xref="A2.p3.2.m2.1.1.2.1.cmml">â€‹</mo><mi id="A2.p3.2.m2.1.1.2.3" xref="A2.p3.2.m2.1.1.2.3.cmml">e</mi></mrow><mo id="A2.p3.2.m2.1.1.1" xref="A2.p3.2.m2.1.1.1.cmml">âˆ’</mo><mn id="A2.p3.2.m2.1.1.3" xref="A2.p3.2.m2.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="A2.p3.2.m2.1b"><apply id="A2.p3.2.m2.1.1.cmml" xref="A2.p3.2.m2.1.1"><minus id="A2.p3.2.m2.1.1.1.cmml" xref="A2.p3.2.m2.1.1.1"></minus><apply id="A2.p3.2.m2.1.1.2.cmml" xref="A2.p3.2.m2.1.1.2"><times id="A2.p3.2.m2.1.1.2.1.cmml" xref="A2.p3.2.m2.1.1.2.1"></times><cn type="integer" id="A2.p3.2.m2.1.1.2.2.cmml" xref="A2.p3.2.m2.1.1.2.2">1</cn><ci id="A2.p3.2.m2.1.1.2.3.cmml" xref="A2.p3.2.m2.1.1.2.3">ğ‘’</ci></apply><cn type="integer" id="A2.p3.2.m2.1.1.3.cmml" xref="A2.p3.2.m2.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.p3.2.m2.1c">1e-5</annotation></semantics></math> and momentum 0. Each client runs one epoch. Unless otherwise specified, the maximum number of local iterations is set to 2500. When comparing H-FL with FedAvg (<a href="#S5.T3" title="In 5.3 FL baselines â€£ 5 Experiments and Results â€£ Collaborative Visual Place Recognition through Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">3</span></a>), we modify the number of rounds <math id="A2.p3.3.m3.1" class="ltx_Math" alttext="T" display="inline"><semantics id="A2.p3.3.m3.1a"><mi id="A2.p3.3.m3.1.1" xref="A2.p3.3.m3.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="A2.p3.3.m3.1b"><ci id="A2.p3.3.m3.1.1.cmml" xref="A2.p3.3.m3.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.p3.3.m3.1c">T</annotation></semantics></math> and participating clients <math id="A2.p3.4.m4.1" class="ltx_Math" alttext="C" display="inline"><semantics id="A2.p3.4.m4.1a"><mi id="A2.p3.4.m4.1.1" xref="A2.p3.4.m4.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="A2.p3.4.m4.1b"><ci id="A2.p3.4.m4.1.1.cmml" xref="A2.p3.4.m4.1.1">ğ¶</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.p3.4.m4.1c">C</annotation></semantics></math> accordingly, as summarized in <a href="#A2.T9" title="In Appendix B Implementation details â€£ Collaborative Visual Place Recognition through Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">9</span></a>.</p>
</div>
<figure id="A2.T8" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="A2.T8.8.3.1" class="ltx_text" style="font-size:90%;">Table 8</span>: </span><span id="A2.T8.4.2" class="ltx_text" style="font-size:90%;">Server-side optimizers hyperparameters (learning rate <math id="A2.T8.3.1.m1.1" class="ltx_Math" alttext="\eta_{s}" display="inline"><semantics id="A2.T8.3.1.m1.1b"><msub id="A2.T8.3.1.m1.1.1" xref="A2.T8.3.1.m1.1.1.cmml"><mi id="A2.T8.3.1.m1.1.1.2" xref="A2.T8.3.1.m1.1.1.2.cmml">Î·</mi><mi id="A2.T8.3.1.m1.1.1.3" xref="A2.T8.3.1.m1.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="A2.T8.3.1.m1.1c"><apply id="A2.T8.3.1.m1.1.1.cmml" xref="A2.T8.3.1.m1.1.1"><csymbol cd="ambiguous" id="A2.T8.3.1.m1.1.1.1.cmml" xref="A2.T8.3.1.m1.1.1">subscript</csymbol><ci id="A2.T8.3.1.m1.1.1.2.cmml" xref="A2.T8.3.1.m1.1.1.2">ğœ‚</ci><ci id="A2.T8.3.1.m1.1.1.3.cmml" xref="A2.T8.3.1.m1.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T8.3.1.m1.1d">\eta_{s}</annotation></semantics></math> and momentum <math id="A2.T8.4.2.m2.1" class="ltx_Math" alttext="\beta_{s}" display="inline"><semantics id="A2.T8.4.2.m2.1b"><msub id="A2.T8.4.2.m2.1.1" xref="A2.T8.4.2.m2.1.1.cmml"><mi id="A2.T8.4.2.m2.1.1.2" xref="A2.T8.4.2.m2.1.1.2.cmml">Î²</mi><mi id="A2.T8.4.2.m2.1.1.3" xref="A2.T8.4.2.m2.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="A2.T8.4.2.m2.1c"><apply id="A2.T8.4.2.m2.1.1.cmml" xref="A2.T8.4.2.m2.1.1"><csymbol cd="ambiguous" id="A2.T8.4.2.m2.1.1.1.cmml" xref="A2.T8.4.2.m2.1.1">subscript</csymbol><ci id="A2.T8.4.2.m2.1.1.2.cmml" xref="A2.T8.4.2.m2.1.1.2">ğ›½</ci><ci id="A2.T8.4.2.m2.1.1.3.cmml" xref="A2.T8.4.2.m2.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T8.4.2.m2.1d">\beta_{s}</annotation></semantics></math>).</span></figcaption>
<table id="A2.T8.6" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="A2.T8.6.2" class="ltx_tr">
<td id="A2.T8.6.2.3" class="ltx_td ltx_align_left ltx_border_tt"><span id="A2.T8.6.2.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Method</span></td>
<td id="A2.T8.5.1.1" class="ltx_td ltx_align_center ltx_border_tt"><math id="A2.T8.5.1.1.m1.1" class="ltx_Math" alttext="\eta_{s}" display="inline"><semantics id="A2.T8.5.1.1.m1.1a"><msub id="A2.T8.5.1.1.m1.1.1" xref="A2.T8.5.1.1.m1.1.1.cmml"><mi mathsize="80%" id="A2.T8.5.1.1.m1.1.1.2" xref="A2.T8.5.1.1.m1.1.1.2.cmml">ğœ¼</mi><mi mathsize="80%" id="A2.T8.5.1.1.m1.1.1.3" xref="A2.T8.5.1.1.m1.1.1.3.cmml">ğ’”</mi></msub><annotation-xml encoding="MathML-Content" id="A2.T8.5.1.1.m1.1b"><apply id="A2.T8.5.1.1.m1.1.1.cmml" xref="A2.T8.5.1.1.m1.1.1"><csymbol cd="ambiguous" id="A2.T8.5.1.1.m1.1.1.1.cmml" xref="A2.T8.5.1.1.m1.1.1">subscript</csymbol><ci id="A2.T8.5.1.1.m1.1.1.2.cmml" xref="A2.T8.5.1.1.m1.1.1.2">ğœ¼</ci><ci id="A2.T8.5.1.1.m1.1.1.3.cmml" xref="A2.T8.5.1.1.m1.1.1.3">ğ’”</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T8.5.1.1.m1.1c">\eta_{s}</annotation></semantics></math></td>
<td id="A2.T8.6.2.2" class="ltx_td ltx_align_center ltx_border_tt"><math id="A2.T8.6.2.2.m1.1" class="ltx_Math" alttext="\beta_{s}" display="inline"><semantics id="A2.T8.6.2.2.m1.1a"><msub id="A2.T8.6.2.2.m1.1.1" xref="A2.T8.6.2.2.m1.1.1.cmml"><mi mathsize="80%" id="A2.T8.6.2.2.m1.1.1.2" xref="A2.T8.6.2.2.m1.1.1.2.cmml">ğœ·</mi><mi mathsize="80%" id="A2.T8.6.2.2.m1.1.1.3" xref="A2.T8.6.2.2.m1.1.1.3.cmml">ğ’”</mi></msub><annotation-xml encoding="MathML-Content" id="A2.T8.6.2.2.m1.1b"><apply id="A2.T8.6.2.2.m1.1.1.cmml" xref="A2.T8.6.2.2.m1.1.1"><csymbol cd="ambiguous" id="A2.T8.6.2.2.m1.1.1.1.cmml" xref="A2.T8.6.2.2.m1.1.1">subscript</csymbol><ci id="A2.T8.6.2.2.m1.1.1.2.cmml" xref="A2.T8.6.2.2.m1.1.1.2">ğœ·</ci><ci id="A2.T8.6.2.2.m1.1.1.3.cmml" xref="A2.T8.6.2.2.m1.1.1.3">ğ’”</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T8.6.2.2.m1.1c">\beta_{s}</annotation></semantics></math></td>
</tr>
<tr id="A2.T8.6.3" class="ltx_tr">
<td id="A2.T8.6.3.1" class="ltx_td ltx_align_left ltx_border_t"><span id="A2.T8.6.3.1.1" class="ltx_text" style="font-size:80%;">FedAvg</span></td>
<td id="A2.T8.6.3.2" class="ltx_td ltx_align_center ltx_border_t"><span id="A2.T8.6.3.2.1" class="ltx_text" style="font-size:80%;">1</span></td>
<td id="A2.T8.6.3.3" class="ltx_td ltx_align_center ltx_border_t"><span id="A2.T8.6.3.3.1" class="ltx_text" style="font-size:80%;">0</span></td>
</tr>
<tr id="A2.T8.6.4" class="ltx_tr">
<td id="A2.T8.6.4.1" class="ltx_td ltx_align_left"><span id="A2.T8.6.4.1.1" class="ltx_text" style="font-size:80%;">FedSGD</span></td>
<td id="A2.T8.6.4.2" class="ltx_td ltx_align_center"><span id="A2.T8.6.4.2.1" class="ltx_text" style="font-size:80%;">0.1</span></td>
<td id="A2.T8.6.4.3" class="ltx_td ltx_align_center"><span id="A2.T8.6.4.3.1" class="ltx_text" style="font-size:80%;">0.9</span></td>
</tr>
<tr id="A2.T8.6.5" class="ltx_tr">
<td id="A2.T8.6.5.1" class="ltx_td ltx_align_left"><span id="A2.T8.6.5.1.1" class="ltx_text" style="font-size:80%;">FedAdam</span></td>
<td id="A2.T8.6.5.2" class="ltx_td ltx_align_center"><span id="A2.T8.6.5.2.1" class="ltx_text" style="font-size:80%;">0.1</span></td>
<td id="A2.T8.6.5.3" class="ltx_td ltx_align_center"><span id="A2.T8.6.5.3.1" class="ltx_text" style="font-size:80%;">0.9</span></td>
</tr>
<tr id="A2.T8.6.6" class="ltx_tr">
<td id="A2.T8.6.6.1" class="ltx_td ltx_align_left ltx_border_bb"><span id="A2.T8.6.6.1.1" class="ltx_text" style="font-size:80%;">FedAdaGrad</span></td>
<td id="A2.T8.6.6.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="A2.T8.6.6.2.1" class="ltx_text" style="font-size:80%;">0.01</span></td>
<td id="A2.T8.6.6.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="A2.T8.6.6.3.1" class="ltx_text" style="font-size:80%;">0.9</span></td>
</tr>
</table>
</figure>
<figure id="A2.T9" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="A2.T9.8.3.1" class="ltx_text" style="font-size:90%;">Table 9</span>: </span><span id="A2.T9.4.2" class="ltx_text" style="font-size:90%;">Number of rounds <math id="A2.T9.3.1.m1.1" class="ltx_Math" alttext="T" display="inline"><semantics id="A2.T9.3.1.m1.1b"><mi id="A2.T9.3.1.m1.1.1" xref="A2.T9.3.1.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="A2.T9.3.1.m1.1c"><ci id="A2.T9.3.1.m1.1.1.cmml" xref="A2.T9.3.1.m1.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.T9.3.1.m1.1d">T</annotation></semantics></math> and selected clients per round <math id="A2.T9.4.2.m2.1" class="ltx_Math" alttext="C" display="inline"><semantics id="A2.T9.4.2.m2.1b"><mi id="A2.T9.4.2.m2.1.1" xref="A2.T9.4.2.m2.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="A2.T9.4.2.m2.1c"><ci id="A2.T9.4.2.m2.1.1.cmml" xref="A2.T9.4.2.m2.1.1">ğ¶</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.T9.4.2.m2.1d">C</annotation></semantics></math> when comparing FedAvg with H-FL.</span></figcaption>
<table id="A2.T9.6" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="A2.T9.6.2" class="ltx_tr">
<td id="A2.T9.6.2.3" class="ltx_td ltx_align_left ltx_border_tt"><span id="A2.T9.6.2.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Method</span></td>
<td id="A2.T9.5.1.1" class="ltx_td ltx_align_center ltx_border_tt"><math id="A2.T9.5.1.1.m1.1" class="ltx_Math" alttext="T" display="inline"><semantics id="A2.T9.5.1.1.m1.1a"><mi mathsize="80%" id="A2.T9.5.1.1.m1.1.1" xref="A2.T9.5.1.1.m1.1.1.cmml">ğ‘»</mi><annotation-xml encoding="MathML-Content" id="A2.T9.5.1.1.m1.1b"><ci id="A2.T9.5.1.1.m1.1.1.cmml" xref="A2.T9.5.1.1.m1.1.1">ğ‘»</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.T9.5.1.1.m1.1c">T</annotation></semantics></math></td>
<td id="A2.T9.6.2.2" class="ltx_td ltx_align_center ltx_border_tt"><math id="A2.T9.6.2.2.m1.1" class="ltx_Math" alttext="C" display="inline"><semantics id="A2.T9.6.2.2.m1.1a"><mi mathsize="80%" id="A2.T9.6.2.2.m1.1.1" xref="A2.T9.6.2.2.m1.1.1.cmml">ğ‘ª</mi><annotation-xml encoding="MathML-Content" id="A2.T9.6.2.2.m1.1b"><ci id="A2.T9.6.2.2.m1.1.1.cmml" xref="A2.T9.6.2.2.m1.1.1">ğ‘ª</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.T9.6.2.2.m1.1c">C</annotation></semantics></math></td>
</tr>
<tr id="A2.T9.6.3" class="ltx_tr">
<td id="A2.T9.6.3.1" class="ltx_td ltx_align_left ltx_border_t"><span id="A2.T9.6.3.1.1" class="ltx_text" style="font-size:80%;">FedAvg</span></td>
<td id="A2.T9.6.3.2" class="ltx_td ltx_align_center ltx_border_t"><span id="A2.T9.6.3.2.1" class="ltx_text" style="font-size:80%;">75</span></td>
<td id="A2.T9.6.3.3" class="ltx_td ltx_align_center ltx_border_t"><span id="A2.T9.6.3.3.1" class="ltx_text" style="font-size:80%;">20</span></td>
</tr>
<tr id="A2.T9.6.4" class="ltx_tr">
<td id="A2.T9.6.4.1" class="ltx_td ltx_align_left"><span id="A2.T9.6.4.1.1" class="ltx_text" style="font-size:80%;">H-FL Continent</span></td>
<td id="A2.T9.6.4.2" class="ltx_td ltx_align_center"><span id="A2.T9.6.4.2.1" class="ltx_text" style="font-size:80%;">75</span></td>
<td id="A2.T9.6.4.3" class="ltx_td ltx_align_center"><span id="A2.T9.6.4.3.1" class="ltx_text" style="font-size:80%;">20 (4 continents by 5 clients per continent)</span></td>
</tr>
<tr id="A2.T9.6.5" class="ltx_tr">
<td id="A2.T9.6.5.1" class="ltx_td ltx_align_left ltx_border_t"><span id="A2.T9.6.5.1.1" class="ltx_text" style="font-size:80%;">FedAvg</span></td>
<td id="A2.T9.6.5.2" class="ltx_td ltx_align_center ltx_border_t"><span id="A2.T9.6.5.2.1" class="ltx_text" style="font-size:80%;">15</span></td>
<td id="A2.T9.6.5.3" class="ltx_td ltx_align_center ltx_border_t"><span id="A2.T9.6.5.3.1" class="ltx_text" style="font-size:80%;">105</span></td>
</tr>
<tr id="A2.T9.6.6" class="ltx_tr">
<td id="A2.T9.6.6.1" class="ltx_td ltx_align_left ltx_border_bb"><span id="A2.T9.6.6.1.1" class="ltx_text" style="font-size:80%;">H-FL City</span></td>
<td id="A2.T9.6.6.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="A2.T9.6.6.2.1" class="ltx_text" style="font-size:80%;">15</span></td>
<td id="A2.T9.6.6.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="A2.T9.6.6.3.1" class="ltx_text" style="font-size:80%;">105 (21 cities by 5 clients per city)</span></td>
</tr>
</table>
</figure>
<div id="A2.p4" class="ltx_para ltx_noindent">
<p id="A2.p4.1" class="ltx_p"><span id="A2.p4.1.1" class="ltx_text ltx_font_bold">Data augmentation.</span> We study the effect of data augmentation techniques in <a href="#S5.SS5" title="5.5 Heterogeneity of Local Augmentations â€£ 5 Experiments and Results â€£ Collaborative Visual Place Recognition through Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Sec.</span>Â <span class="ltx_text ltx_ref_tag">5.5</span></a>. Due to the required increased time, data augmentation is not used by default in the other experiments. In <a href="#S5.SS5" title="5.5 Heterogeneity of Local Augmentations â€£ 5 Experiments and Results â€£ Collaborative Visual Place Recognition through Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Sec.</span>Â <span class="ltx_text ltx_ref_tag">5.5</span></a>, data augmentation is applied with 50% probability. We apply color jitter (hue, saturation, brightness, and contrast) and random resize crop.
Normalization instead is always applied with standard ImageNet values.</p>
</div>
<div id="A2.p5" class="ltx_para ltx_noindent">
<p id="A2.p5.1" class="ltx_p"><span id="A2.p5.1.1" class="ltx_text ltx_font_bold">Local mining.</span> We set the number of sequences for computing the mining dataset to 333 and 20 and the number of images selected per sequence to 3 and 50 respectively.</p>
</div>
</section>
<section id="A3" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Distribution of clients in federated MSLS</h2>

<div id="A3.p1" class="ltx_para">
<p id="A3.p1.1" class="ltx_p">In this section, we present additional analyses on the MSLS federated splits described in <a href="#S4" title="4 Decentralizing the MSLS dataset for FL â€£ Collaborative Visual Place Recognition through Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Sec.</span>Â <span class="ltx_text ltx_ref_tag">4</span></a>.
Focusing on the <span id="A3.p1.1.1" class="ltx_text ltx_font_italic">Proximity</span> split, <a href="#A3.F4.sf1" title="In Figure 4 â€£ Appendix C Distribution of clients in federated MSLS â€£ Collaborative Visual Place Recognition through Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">4(a)</span></a> shows the distribution of clients across cities. We note that Budapest, Bangkok, Phoenix and Melbourne are the most populated. <a href="#A3.F5.sf1" title="In Figure 5 â€£ Appendix C Distribution of clients in federated MSLS â€£ Collaborative Visual Place Recognition through Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">5(a)</span></a> shows that those same cities are also the ones containing most images. <a href="#A3.F4.sf2" title="In Figure 4 â€£ Appendix C Distribution of clients in federated MSLS â€£ Collaborative Visual Place Recognition through Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figs.</span>Â <span class="ltx_text ltx_ref_tag">4(b)</span></a> andÂ <a href="#A3.F5.sf2" title="Figure 5(b) â€£ Figure 5 â€£ Appendix C Distribution of clients in federated MSLS â€£ Collaborative Visual Place Recognition through Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5(b)</span></a> repeat the same analyses per continent: even if most of the clients are found in America, Europe has most of the images, while the least populated continent is Oceania but Asian clients have in total less images.</p>
</div>
<figure id="A3.F4" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="A3.F4.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2404.13324/assets/images/number_of_client_per_city.png" id="A3.F4.sf1.g1" class="ltx_graphics ltx_img_square" width="309" height="277" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A3.F4.sf1.3.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="A3.F4.sf1.4.2" class="ltx_text" style="font-size:90%;">Distribution of clients per <span id="A3.F4.sf1.4.2.1" class="ltx_text ltx_font_bold">city</span></span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="A3.F4.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2404.13324/assets/images/number_of_client_per_continent.png" id="A3.F4.sf2.g1" class="ltx_graphics ltx_img_landscape" width="343" height="257" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A3.F4.sf2.3.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="A3.F4.sf2.4.2" class="ltx_text" style="font-size:90%;">Distribution of clients per <span id="A3.F4.sf2.4.2.1" class="ltx_text ltx_font_bold">continent</span></span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A3.F4.2.1.1" class="ltx_text" style="font-size:90%;">Figure 4</span>: </span><span id="A3.F4.3.2" class="ltx_text" style="font-size:90%;">Clients distribution in the MSLS Proximity split.</span></figcaption>
</figure>
<figure id="A3.F5" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="A3.F5.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2404.13324/assets/images/number_of_total_images_per_city.png" id="A3.F5.sf1.g1" class="ltx_graphics ltx_img_square" width="309" height="260" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A3.F5.sf1.3.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="A3.F5.sf1.4.2" class="ltx_text" style="font-size:90%;">Distribution of images per <span id="A3.F5.sf1.4.2.1" class="ltx_text ltx_font_bold">city</span></span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="A3.F5.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2404.13324/assets/images/number_of_total_images_per_continent.png" id="A3.F5.sf2.g1" class="ltx_graphics ltx_img_landscape" width="343" height="257" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A3.F5.sf2.3.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="A3.F5.sf2.4.2" class="ltx_text" style="font-size:90%;">Distribution of images per <span id="A3.F5.sf2.4.2.1" class="ltx_text ltx_font_bold">continent</span></span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A3.F5.2.1.1" class="ltx_text" style="font-size:90%;">Figure 5</span>: </span><span id="A3.F5.3.2" class="ltx_text" style="font-size:90%;">Images distribution in the MSLS Proximity split.</span></figcaption>
</figure>
</section>
<section id="A4" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>Ablation studies on H-FL</h2>

<div id="A4.p1" class="ltx_para">
<p id="A4.p1.5" class="ltx_p"><a href="#A4.T10" title="In Appendix D Ablation studies on H-FL â€£ Collaborative Visual Place Recognition through Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">10</span></a> investigates the effect of the round interval (<math id="A4.p1.1.m1.1" class="ltx_Math" alttext="T_{s}" display="inline"><semantics id="A4.p1.1.m1.1a"><msub id="A4.p1.1.m1.1.1" xref="A4.p1.1.m1.1.1.cmml"><mi id="A4.p1.1.m1.1.1.2" xref="A4.p1.1.m1.1.1.2.cmml">T</mi><mi id="A4.p1.1.m1.1.1.3" xref="A4.p1.1.m1.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="A4.p1.1.m1.1b"><apply id="A4.p1.1.m1.1.1.cmml" xref="A4.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A4.p1.1.m1.1.1.1.cmml" xref="A4.p1.1.m1.1.1">subscript</csymbol><ci id="A4.p1.1.m1.1.1.2.cmml" xref="A4.p1.1.m1.1.1.2">ğ‘‡</ci><ci id="A4.p1.1.m1.1.1.3.cmml" xref="A4.p1.1.m1.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.p1.1.m1.1c">T_{s}</annotation></semantics></math>) between aggregation steps in H-FL for continent-based clustering. The results show that an optimal value exists for <math id="A4.p1.2.m2.1" class="ltx_Math" alttext="T_{s}" display="inline"><semantics id="A4.p1.2.m2.1a"><msub id="A4.p1.2.m2.1.1" xref="A4.p1.2.m2.1.1.cmml"><mi id="A4.p1.2.m2.1.1.2" xref="A4.p1.2.m2.1.1.2.cmml">T</mi><mi id="A4.p1.2.m2.1.1.3" xref="A4.p1.2.m2.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="A4.p1.2.m2.1b"><apply id="A4.p1.2.m2.1.1.cmml" xref="A4.p1.2.m2.1.1"><csymbol cd="ambiguous" id="A4.p1.2.m2.1.1.1.cmml" xref="A4.p1.2.m2.1.1">subscript</csymbol><ci id="A4.p1.2.m2.1.1.2.cmml" xref="A4.p1.2.m2.1.1.2">ğ‘‡</ci><ci id="A4.p1.2.m2.1.1.3.cmml" xref="A4.p1.2.m2.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.p1.2.m2.1c">T_{s}</annotation></semantics></math>. Setting <math id="A4.p1.3.m3.1" class="ltx_Math" alttext="T_{s}" display="inline"><semantics id="A4.p1.3.m3.1a"><msub id="A4.p1.3.m3.1.1" xref="A4.p1.3.m3.1.1.cmml"><mi id="A4.p1.3.m3.1.1.2" xref="A4.p1.3.m3.1.1.2.cmml">T</mi><mi id="A4.p1.3.m3.1.1.3" xref="A4.p1.3.m3.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="A4.p1.3.m3.1b"><apply id="A4.p1.3.m3.1.1.cmml" xref="A4.p1.3.m3.1.1"><csymbol cd="ambiguous" id="A4.p1.3.m3.1.1.1.cmml" xref="A4.p1.3.m3.1.1">subscript</csymbol><ci id="A4.p1.3.m3.1.1.2.cmml" xref="A4.p1.3.m3.1.1.2">ğ‘‡</ci><ci id="A4.p1.3.m3.1.1.3.cmml" xref="A4.p1.3.m3.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.p1.3.m3.1c">T_{s}</annotation></semantics></math> too low hinders the cluster-specific models from learning generalizable information, while a very high <math id="A4.p1.4.m4.1" class="ltx_Math" alttext="T_{s}" display="inline"><semantics id="A4.p1.4.m4.1a"><msub id="A4.p1.4.m4.1.1" xref="A4.p1.4.m4.1.1.cmml"><mi id="A4.p1.4.m4.1.1.2" xref="A4.p1.4.m4.1.1.2.cmml">T</mi><mi id="A4.p1.4.m4.1.1.3" xref="A4.p1.4.m4.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="A4.p1.4.m4.1b"><apply id="A4.p1.4.m4.1.1.cmml" xref="A4.p1.4.m4.1.1"><csymbol cd="ambiguous" id="A4.p1.4.m4.1.1.1.cmml" xref="A4.p1.4.m4.1.1">subscript</csymbol><ci id="A4.p1.4.m4.1.1.2.cmml" xref="A4.p1.4.m4.1.1.2">ğ‘‡</ci><ci id="A4.p1.4.m4.1.1.3.cmml" xref="A4.p1.4.m4.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.p1.4.m4.1c">T_{s}</annotation></semantics></math> leads to reliance on outdated updates. The best performance is achieved with <math id="A4.p1.5.m5.1" class="ltx_Math" alttext="T_{s}=15" display="inline"><semantics id="A4.p1.5.m5.1a"><mrow id="A4.p1.5.m5.1.1" xref="A4.p1.5.m5.1.1.cmml"><msub id="A4.p1.5.m5.1.1.2" xref="A4.p1.5.m5.1.1.2.cmml"><mi id="A4.p1.5.m5.1.1.2.2" xref="A4.p1.5.m5.1.1.2.2.cmml">T</mi><mi id="A4.p1.5.m5.1.1.2.3" xref="A4.p1.5.m5.1.1.2.3.cmml">s</mi></msub><mo id="A4.p1.5.m5.1.1.1" xref="A4.p1.5.m5.1.1.1.cmml">=</mo><mn id="A4.p1.5.m5.1.1.3" xref="A4.p1.5.m5.1.1.3.cmml">15</mn></mrow><annotation-xml encoding="MathML-Content" id="A4.p1.5.m5.1b"><apply id="A4.p1.5.m5.1.1.cmml" xref="A4.p1.5.m5.1.1"><eq id="A4.p1.5.m5.1.1.1.cmml" xref="A4.p1.5.m5.1.1.1"></eq><apply id="A4.p1.5.m5.1.1.2.cmml" xref="A4.p1.5.m5.1.1.2"><csymbol cd="ambiguous" id="A4.p1.5.m5.1.1.2.1.cmml" xref="A4.p1.5.m5.1.1.2">subscript</csymbol><ci id="A4.p1.5.m5.1.1.2.2.cmml" xref="A4.p1.5.m5.1.1.2.2">ğ‘‡</ci><ci id="A4.p1.5.m5.1.1.2.3.cmml" xref="A4.p1.5.m5.1.1.2.3">ğ‘ </ci></apply><cn type="integer" id="A4.p1.5.m5.1.1.3.cmml" xref="A4.p1.5.m5.1.1.3">15</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.p1.5.m5.1c">T_{s}=15</annotation></semantics></math>.</p>
</div>
<figure id="A4.T10" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="A4.T10.10.2.1" class="ltx_text" style="font-size:90%;">Table 10</span>: </span><span id="A4.T10.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Comparison of different aggregation interval <math id="A4.T10.2.1.m1.1" class="ltx_Math" alttext="T_{s}" display="inline"><semantics id="A4.T10.2.1.m1.1b"><msub id="A4.T10.2.1.m1.1.1" xref="A4.T10.2.1.m1.1.1.cmml"><mi id="A4.T10.2.1.m1.1.1.2" xref="A4.T10.2.1.m1.1.1.2.cmml">T</mi><mi id="A4.T10.2.1.m1.1.1.3" xref="A4.T10.2.1.m1.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="A4.T10.2.1.m1.1c"><apply id="A4.T10.2.1.m1.1.1.cmml" xref="A4.T10.2.1.m1.1.1"><csymbol cd="ambiguous" id="A4.T10.2.1.m1.1.1.1.cmml" xref="A4.T10.2.1.m1.1.1">subscript</csymbol><ci id="A4.T10.2.1.m1.1.1.2.cmml" xref="A4.T10.2.1.m1.1.1.2">ğ‘‡</ci><ci id="A4.T10.2.1.m1.1.1.3.cmml" xref="A4.T10.2.1.m1.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.T10.2.1.m1.1d">T_{s}</annotation></semantics></math> in h-FL.<span id="A4.T10.2.1.1" class="ltx_text ltx_font_medium"> The experiments are run with the continental aggregation with 5 clients per continent at each round and carried on for 300 rounds.</span></span></figcaption>
<table id="A4.T10.8" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="A4.T10.3.1" class="ltx_tr">
<td id="A4.T10.3.1.1" class="ltx_td ltx_align_center ltx_border_tt"><math id="A4.T10.3.1.1.m1.1" class="ltx_Math" alttext="T_{s}" display="inline"><semantics id="A4.T10.3.1.1.m1.1a"><msub id="A4.T10.3.1.1.m1.1.1" xref="A4.T10.3.1.1.m1.1.1.cmml"><mi mathsize="80%" id="A4.T10.3.1.1.m1.1.1.2" xref="A4.T10.3.1.1.m1.1.1.2.cmml">ğ‘»</mi><mi mathsize="80%" id="A4.T10.3.1.1.m1.1.1.3" xref="A4.T10.3.1.1.m1.1.1.3.cmml">ğ’”</mi></msub><annotation-xml encoding="MathML-Content" id="A4.T10.3.1.1.m1.1b"><apply id="A4.T10.3.1.1.m1.1.1.cmml" xref="A4.T10.3.1.1.m1.1.1"><csymbol cd="ambiguous" id="A4.T10.3.1.1.m1.1.1.1.cmml" xref="A4.T10.3.1.1.m1.1.1">subscript</csymbol><ci id="A4.T10.3.1.1.m1.1.1.2.cmml" xref="A4.T10.3.1.1.m1.1.1.2">ğ‘»</ci><ci id="A4.T10.3.1.1.m1.1.1.3.cmml" xref="A4.T10.3.1.1.m1.1.1.3">ğ’”</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.T10.3.1.1.m1.1c">T_{s}</annotation></semantics></math></td>
<td id="A4.T10.3.1.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="A4.T10.3.1.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">R@1</span></td>
</tr>
<tr id="A4.T10.4.2" class="ltx_tr">
<td id="A4.T10.4.2.2" class="ltx_td ltx_align_center ltx_border_t"><span id="A4.T10.4.2.2.1" class="ltx_text" style="font-size:80%;">5</span></td>
<td id="A4.T10.4.2.1" class="ltx_td ltx_align_center ltx_border_t">
<span id="A4.T10.4.2.1.1" class="ltx_text" style="font-size:80%;">60.1 </span><math id="A4.T10.4.2.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="A4.T10.4.2.1.m1.1a"><mo mathsize="70%" id="A4.T10.4.2.1.m1.1.1" xref="A4.T10.4.2.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="A4.T10.4.2.1.m1.1b"><csymbol cd="latexml" id="A4.T10.4.2.1.m1.1.1.cmml" xref="A4.T10.4.2.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A4.T10.4.2.1.m1.1c">\pm</annotation></semantics></math><span id="A4.T10.4.2.1.2" class="ltx_text" style="font-size:70%;"> 0.8</span>
</td>
</tr>
<tr id="A4.T10.5.3" class="ltx_tr">
<td id="A4.T10.5.3.2" class="ltx_td ltx_align_center"><span id="A4.T10.5.3.2.1" class="ltx_text" style="font-size:80%;">10</span></td>
<td id="A4.T10.5.3.1" class="ltx_td ltx_align_center">
<span id="A4.T10.5.3.1.1" class="ltx_text" style="font-size:80%;">60.4 </span><math id="A4.T10.5.3.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="A4.T10.5.3.1.m1.1a"><mo mathsize="70%" id="A4.T10.5.3.1.m1.1.1" xref="A4.T10.5.3.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="A4.T10.5.3.1.m1.1b"><csymbol cd="latexml" id="A4.T10.5.3.1.m1.1.1.cmml" xref="A4.T10.5.3.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A4.T10.5.3.1.m1.1c">\pm</annotation></semantics></math><span id="A4.T10.5.3.1.2" class="ltx_text" style="font-size:70%;"> 0.9</span>
</td>
</tr>
<tr id="A4.T10.6.4" class="ltx_tr">
<td id="A4.T10.6.4.2" class="ltx_td ltx_align_center"><span id="A4.T10.6.4.2.1" class="ltx_text" style="font-size:80%;">15</span></td>
<td id="A4.T10.6.4.1" class="ltx_td ltx_align_center">
<span id="A4.T10.6.4.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">61.1</span><span id="A4.T10.6.4.1.2" class="ltx_text" style="font-size:80%;"> </span><math id="A4.T10.6.4.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="A4.T10.6.4.1.m1.1a"><mo mathsize="70%" id="A4.T10.6.4.1.m1.1.1" xref="A4.T10.6.4.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="A4.T10.6.4.1.m1.1b"><csymbol cd="latexml" id="A4.T10.6.4.1.m1.1.1.cmml" xref="A4.T10.6.4.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A4.T10.6.4.1.m1.1c">\pm</annotation></semantics></math><span id="A4.T10.6.4.1.3" class="ltx_text" style="font-size:70%;"> <span id="A4.T10.6.4.1.3.1" class="ltx_text ltx_font_bold">0.6</span></span>
</td>
</tr>
<tr id="A4.T10.7.5" class="ltx_tr">
<td id="A4.T10.7.5.2" class="ltx_td ltx_align_center"><span id="A4.T10.7.5.2.1" class="ltx_text" style="font-size:80%;">20</span></td>
<td id="A4.T10.7.5.1" class="ltx_td ltx_align_center">
<span id="A4.T10.7.5.1.1" class="ltx_text" style="font-size:80%;">60.0 </span><math id="A4.T10.7.5.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="A4.T10.7.5.1.m1.1a"><mo mathsize="70%" id="A4.T10.7.5.1.m1.1.1" xref="A4.T10.7.5.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="A4.T10.7.5.1.m1.1b"><csymbol cd="latexml" id="A4.T10.7.5.1.m1.1.1.cmml" xref="A4.T10.7.5.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A4.T10.7.5.1.m1.1c">\pm</annotation></semantics></math><span id="A4.T10.7.5.1.2" class="ltx_text" style="font-size:70%;"> 0.9</span>
</td>
</tr>
<tr id="A4.T10.8.6" class="ltx_tr">
<td id="A4.T10.8.6.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="A4.T10.8.6.2.1" class="ltx_text" style="font-size:80%;">25</span></td>
<td id="A4.T10.8.6.1" class="ltx_td ltx_align_center ltx_border_bb">
<span id="A4.T10.8.6.1.1" class="ltx_text" style="font-size:80%;">60.3 </span><math id="A4.T10.8.6.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="A4.T10.8.6.1.m1.1a"><mo mathsize="70%" id="A4.T10.8.6.1.m1.1.1" xref="A4.T10.8.6.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="A4.T10.8.6.1.m1.1b"><csymbol cd="latexml" id="A4.T10.8.6.1.m1.1.1.cmml" xref="A4.T10.8.6.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A4.T10.8.6.1.m1.1c">\pm</annotation></semantics></math><span id="A4.T10.8.6.1.2" class="ltx_text" style="font-size:70%;"> 0.4</span>
</td>
</tr>
</table>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2404.13323" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2404.13324" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2404.13324">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2404.13324" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2404.13325" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sun May  5 20:28:37 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
