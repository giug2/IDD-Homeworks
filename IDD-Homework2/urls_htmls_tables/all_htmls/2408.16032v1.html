<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>An Extremely Data-efficient and Generative LLM-based Reinforcement Learning Agent for Recommenders</title>
<!--Generated on Wed Aug 28 10:29:26 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="LLM,  Reinforcement Learning,  Recommender,  Contrast Learning,  Generative AI,  RLHF,  Human Preference,  E-commerce" lang="en" name="keywords"/>
<base href="/html/2408.16032v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2408.16032v1#S1" title="In An Extremely Data-efficient and Generative LLM-based Reinforcement Learning Agent for Recommenders"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2408.16032v1#S2" title="In An Extremely Data-efficient and Generative LLM-based Reinforcement Learning Agent for Recommenders"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.16032v1#S2.SS1" title="In 2. Related Work ‣ An Extremely Data-efficient and Generative LLM-based Reinforcement Learning Agent for Recommenders"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>The WebShop Environment</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.16032v1#S2.SS2" title="In 2. Related Work ‣ An Extremely Data-efficient and Generative LLM-based Reinforcement Learning Agent for Recommenders"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Reinforcement Learning with Human Preference - RLHF</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.16032v1#S2.SS3" title="In 2. Related Work ‣ An Extremely Data-efficient and Generative LLM-based Reinforcement Learning Agent for Recommenders"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>PPO for Regularized Policy Gradient</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.16032v1#S2.SS4" title="In 2. Related Work ‣ An Extremely Data-efficient and Generative LLM-based Reinforcement Learning Agent for Recommenders"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.4 </span>Learning with Human Preference - DPO</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2408.16032v1#S3" title="In An Extremely Data-efficient and Generative LLM-based Reinforcement Learning Agent for Recommenders"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Approach</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.16032v1#S3.SS1" title="In 3. Approach ‣ An Extremely Data-efficient and Generative LLM-based Reinforcement Learning Agent for Recommenders"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Semi-generative Reinforcement Learning Using Human Trajectories</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.16032v1#S3.SS2" title="In 3. Approach ‣ An Extremely Data-efficient and Generative LLM-based Reinforcement Learning Agent for Recommenders"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Self-learning - Training with Generated Trajectories</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2408.16032v1#S4" title="In An Extremely Data-efficient and Generative LLM-based Reinforcement Learning Agent for Recommenders"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Experimental Results</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.16032v1#S4.SS1" title="In 4. Experimental Results ‣ An Extremely Data-efficient and Generative LLM-based Reinforcement Learning Agent for Recommenders"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>DPO vs. PPO Task Performance</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2408.16032v1#S5" title="In An Extremely Data-efficient and Generative LLM-based Reinforcement Learning Agent for Recommenders"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2408.16032v1#S6" title="In An Extremely Data-efficient and Generative LLM-based Reinforcement Learning Agent for Recommenders"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Potential Usage: Using Trained Agents as a Recommender</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">An Extremely Data-efficient and Generative LLM-based Reinforcement Learning Agent for Recommenders</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Shuang Feng
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:fengshuang@gmail.com">fengshuang@gmail.com</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id1.1.id1">Stanford University SCPD</span><span class="ltx_text ltx_affiliation_city" id="id2.2.id2">Palo Alto</span><span class="ltx_text ltx_affiliation_state" id="id3.3.id3">California</span><span class="ltx_text ltx_affiliation_country" id="id4.4.id4">USA</span>
</span></span></span>
<span class="ltx_author_before"> and </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Grace Feng
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:gracefeng@ucsb.eud">gracefeng@ucsb.eud</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id5.1.id1">University of California Santa Barbara</span><span class="ltx_text ltx_affiliation_city" id="id6.2.id2">Santa Barbara</span><span class="ltx_text ltx_affiliation_state" id="id7.3.id3">California</span><span class="ltx_text ltx_affiliation_country" id="id8.4.id4">USA</span>
</span></span></span>
</div>
<div class="ltx_dates">(2024)</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p class="ltx_p" id="id9.id1">Recent advancements in large language models (LLMs) have enabled understanding webpage contexts, product details, and human instructions. Utilizing LLMs as the foundational architecture for either reward models or policies in reinforcement learning has gained popularity - a notable achievement is the success of InstructGPT <cite class="ltx_cite ltx_citemacro_citep">(Ouyang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.16032v1#bib.bib12" title="">2022</a>)</cite>. RL algorithms have been instrumental in maximizing long-term customer satisfaction and avoiding short-term, myopic goals in industrial recommender systems, which often rely on deep learning models to predict immediate clicks or purchases.</p>
<p class="ltx_p" id="id10.id2">In this project, several RL methods are implemented and evaluated using the WebShop <cite class="ltx_cite ltx_citemacro_citep">(Yao et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.16032v1#bib.bib18" title="">2023</a>)</cite> benchmark environment, data, simulator, and pre-trained model checkpoints. The goal is to train an RL agent to maximize the purchase reward given a detailed human instruction describing a desired product.</p>
<p class="ltx_p" id="id11.id3">The RL agents are developed by fine-tuning a pre-trained BERT model with various objectives, learning from preferences without a reward model, and employing contemporary training techniques such as Proximal Policy Optimization (PPO) as used in InstructGPT <cite class="ltx_cite ltx_citemacro_citep">(Ouyang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.16032v1#bib.bib12" title="">2022</a>)</cite>, and Direct Preference Optimization (DPO) <cite class="ltx_cite ltx_citemacro_citep">(Rafailov et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.16032v1#bib.bib13" title="">2023</a>)</cite>. This report also evaluates the RL agents trained using generative trajectories. Evaluations were conducted using Thompson sampling in the WebShop simulator environment.</p>
<p class="ltx_p" id="id12.id4">The simulated online experiments demonstrate that DPO outperforms PPO in data efficiency and task performance, especially in success rate, using the same amount of training time. However, longer training time is necessary for fair comparison between the two. Specifically, without utilizing any image, a DPO agent achieved a 19% success rate after approximately 3000 steps or 30 minutes of training on T4 GPUs, compared to a PPO agent, which reached a 15% success rate after 2 hours of training. Results also indicate that agents trained on generated trajectories exhibited comparable task performance to those trained using human trajectories. This has demonstrated an example of an extremely low-cost data-efficient way of training reinforcement learning agents.</p>
</div>
<div class="ltx_keywords">LLM, Reinforcement Learning, Recommender, Contrast Learning, Generative AI, RLHF, Human Preference, E-commerce
</div>
<span class="ltx_note ltx_note_frontmatter ltx_role_copyright" id="id1"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">copyright: </span>acmlicensed</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_journalyear" id="id2"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">journalyear: </span>2024</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_conference" id="id3"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">conference: </span>fengshuang@gmail.com; August 25-29; Barcelona, Spain</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_isbn" id="id4"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">isbn: </span>978-1-4503-XXXX-X/18/06</span></span></span><span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>This paper was originally part of the class project for CS234 Spring 2024 in Stanford University and was submitted to KDD’24 on 6/30/2024 for RelKD Workshop. It was accepted in July 2024. See https://github.com/fengshuang-coding/KDD2024 for updates.</span></span></span>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Recent advances in Large Language Models (LLMs) have significantly enhanced research and applications in understanding human instructions on the web, processing webpage text, and grasping context. These advancements have provided valuable tools for training reinforcement learning (RL) agents to navigate web environments, particularly in e-commerce and various recommender systems such as YouTube and Netflix. Leveraging LLMs in RL agent training is relatively new but has proven successful. A notable example is InstructGPT <cite class="ltx_cite ltx_citemacro_citep">(Ouyang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.16032v1#bib.bib12" title="">2022</a>)</cite>, where an RL agent was trained using human preferences by fine-tuning GPT-3 models with human instructions. Combining LLMs with RL techniques enables the creation of intelligent web agents that can understand human instructions and complete tasks in web or app environments, thereby maximizing desired rewards.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Recommender systems have evolved from collaborative filtering <cite class="ltx_cite ltx_citemacro_citep">(Koren et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.16032v1#bib.bib7" title="">2009</a>)</cite> to the recent surge in deep supervised learning, which predicts immediate user responses such as clicks <cite class="ltx_cite ltx_citemacro_citep">(Covington et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.16032v1#bib.bib5" title="">2016</a>; Zhang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.16032v1#bib.bib19" title="">2017</a>)</cite>. This approach has seen tremendous success in personalized user engagement. However, after several years in production, deep supervised learning algorithms have shown limitations, including: 1) a focus on optimizing short-term gains at the expense of long-term user satisfaction and retention, and 2) strong feedback loops caused by training data generated from these algorithms, which exacerbate these effects. Conversely, RL algorithms are designed to optimize long-term gains by learning policies that maximize long-term user satisfaction. RL agents are also well-known for their ability to perform sequential planning and make decisions based on the Markov Decision Process (MDP) properties <cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.16032v1#bib.bib3" title="">2018</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">The training of RL agents for recommenders in web environments has been actively studied, with several benchmark datasets and trained agents available. For example, WikiNav <cite class="ltx_cite ltx_citemacro_citep">(Nogueira and Cho, <a class="ltx_ref" href="https://arxiv.org/html/2408.16032v1#bib.bib11" title="">2017</a>)</cite> provides a benchmark for web-based navigation RL agents. RecoGym <cite class="ltx_cite ltx_citemacro_citep">(Rohde et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.16032v1#bib.bib14" title="">2018</a>)</cite> offers a benchmark for RL agents in production recommendations for online advertising. Virtual-Taobao <cite class="ltx_cite ltx_citemacro_citep">(Shi et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.16032v1#bib.bib16" title="">2019</a>)</cite> includes a virtual online shopping environment derived from Taobao, hosting several RL algorithms for product recommendations. WebShop <cite class="ltx_cite ltx_citemacro_citep">(Yao et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.16032v1#bib.bib18" title="">2023</a>)</cite> presents a simulated e-commerce web environment with over 1,600 human demonstrations for web shopping tasks based on human text instructions. This environment includes 1.18 million products with text and image descriptions, along with 12,087 crowd-sourced text instructions. The authors of WebShop also explored several imitation and RL agents trained using real-world human trajectories.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">Previous explorations in RL for web-based recommenders are extensive. Query reformulation, as published in <cite class="ltx_cite ltx_citemacro_citep">(Nogueira and Cho, <a class="ltx_ref" href="https://arxiv.org/html/2408.16032v1#bib.bib11" title="">2017</a>)</cite>, is part of an RL problem aimed at optimizing outcomes. In this context, search engines are considered black boxes, and the RL agent (or reformulator) learns to generate queries that maximize the expected return through actions in the state space. This paper, published in 2017, predates the widespread use of BERT <cite class="ltx_cite ltx_citemacro_citep">(Devlin et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.16032v1#bib.bib6" title="">2019</a>)</cite>. The authors proposed a PRF framework, with CNN/RNN serving as the contextual learner and query generator. A more recent work proposed the concept of ”learning to search” <cite class="ltx_cite ltx_citemacro_citep">(Adolphs et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.16032v1#bib.bib2" title="">2021</a>)</cite>, where a search agent mimics the interactive process by generating interactive search queries based on previous queries and saving the best queries along the way. The authors used the T5 model with fine-tuning as a query generator to interact with the search engine iteratively, producing a set of fine-grained queries that yield better outcomes. Another related work, WebGPT <cite class="ltx_cite ltx_citemacro_citep">(Nakano et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.16032v1#bib.bib10" title="">2021</a>)</cite>, utilizes a web interface and a search engine to train RL agents to answer questions.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Related Work</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">The work presented in this paper is built and evaluated within the WebShop <cite class="ltx_cite ltx_citemacro_citep">(Yao et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.16032v1#bib.bib18" title="">2023</a>)</cite> environment, a simulator of online web shopping recommender system.</p>
</div>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1. </span>The WebShop Environment</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">WebShop is a benchmark project designed to train reinforcement learning algorithms in a large-scale, interactive, web-based environment. It includes over 12,000 crowdsourced human instructions, over 1.1 million products scraped from amazon.com. A total of 670 attributes were derived from concatenated product titles and descriptions using bi-gram representations and assigned to each product through TF-IDF scoring.</p>
</div>
<div class="ltx_para" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1">Figure 1 and Figure 2 below provide an example WebShop interface and a sequence of actions.</p>
</div>
<figure class="ltx_figure" id="S2.F1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 1. </span>WebShop Environment <cite class="ltx_cite ltx_citemacro_citep">(Yao et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.16032v1#bib.bib18" title="">2023</a>)</cite></figcaption><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="131" id="S2.F1.g1" src="extracted/5817589/webship_flow.png" width="189"/>
</figure>
<figure class="ltx_figure" id="S2.F2">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 2. </span>WebShop Human Instructions and Human Trajectories <cite class="ltx_cite ltx_citemacro_citep">(Yao et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.16032v1#bib.bib18" title="">2023</a>)</cite></figcaption><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="143" id="S2.F2.g1" src="extracted/5817589/shopping_agent.png" width="196"/>
</figure>
<div class="ltx_para" id="S2.SS1.p3">
<p class="ltx_p" id="S2.SS1.p3.1">The original paper tackles the problem into two sets of reinforcement learning models for search and choice (or clicks). The search model is an imitation learning model (search-IL) mimicking human search queries from instructions. It is a human instruction and query pair fine-tuned BART <cite class="ltx_cite ltx_citemacro_citep">(Lewis et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.16032v1#bib.bib8" title="">2020</a>)</cite> model in root. For choice (clicks) learning, the authors present a few reinforcement learning models to optimize choice of clicks navigating the recommender simulator to optimize the end rewards (purchase). The reward is calculated by a scoring function to quantify the relevance between a purchased product and the human instruction, based on attributes of the product. The imitation learning algorithm (choice-IL) presented by the original authors is a human trajectory fine-tuned BERT <cite class="ltx_cite ltx_citemacro_citep">(Devlin et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.16032v1#bib.bib6" title="">2019</a>)</cite> model in root. The reinforcement learning algorithm for choice iterates the imitation learned (choice-IL-RL), fine-tuned BERT model as the baseline and iterates the optimization using a mixed objectives of policy gradients and cross entropy. 
<br class="ltx_break"/></p>
</div>
<div class="ltx_para" id="S2.SS1.p4">
<p class="ltx_p" id="S2.SS1.p4.1">The state space in this problem consists abstraction of four types of webpages: search page, product recommendation page, product page, and product detail page. The search page features only a search bar for entering instructions, which are used to take a search query either generated by human or a search agent, serving as input for a search engine. Actions include searching, clicking buttons, and choosing from a drop-down menu. Clicking the purchase button marks the end of a trajectory. State transitions are initiated by clicks and other actions that deterministically redirect from one webpage (state) to another. Observations, which includes state and instruction at a specific time snapshot, together form the input for the reinforcement learning agent to make subsequent actions. 
<br class="ltx_break"/></p>
</div>
<div class="ltx_para" id="S2.SS1.p5">
<p class="ltx_p" id="S2.SS1.p5.1">The search engine used by the WebShop project is self-built and self-indexed offline using Pyserini <cite class="ltx_cite ltx_citemacro_citep">(Lin et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.16032v1#bib.bib9" title="">2021</a>)</cite>, which is built upon the open-source Lucene search library. Product retrieval is based on BM25 between search queries and product information text. Top 50 results are shown in 5 pages ranked by BM25. 
<br class="ltx_break"/></p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2. </span>Reinforcement Learning with Human Preference - RLHF</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">RLHF <cite class="ltx_cite ltx_citemacro_citep">(Christiano et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.16032v1#bib.bib4" title="">2023</a>)</cite> together with PPO <cite class="ltx_cite ltx_citemacro_citep">(Schulman et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.16032v1#bib.bib15" title="">2017</a>)</cite> were successfully used to train a few well-known GPT related product, such as instructGPT <cite class="ltx_cite ltx_citemacro_citep">(Ouyang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.16032v1#bib.bib12" title="">2022</a>)</cite>. RLHF leverages the Bradley-Terry model, which defines the preference using rewards of preferred and dispreferred data labeled by human labelers:
<br class="ltx_break"/></p>
<table class="ltx_equation ltx_eqn_table" id="S2.Ex1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="P(y_{l}\succ y_{w}|x)=\frac{exp(r(x,y_{l}))}{exp(r(x,y_{l}))+exp(r(x,y_{w}))}." class="ltx_Math" display="block" id="S2.Ex1.m1.7"><semantics id="S2.Ex1.m1.7a"><mrow id="S2.Ex1.m1.7.7.1" xref="S2.Ex1.m1.7.7.1.1.cmml"><mrow id="S2.Ex1.m1.7.7.1.1" xref="S2.Ex1.m1.7.7.1.1.cmml"><mrow id="S2.Ex1.m1.7.7.1.1.1" xref="S2.Ex1.m1.7.7.1.1.1.cmml"><mi id="S2.Ex1.m1.7.7.1.1.1.3" xref="S2.Ex1.m1.7.7.1.1.1.3.cmml">P</mi><mo id="S2.Ex1.m1.7.7.1.1.1.2" xref="S2.Ex1.m1.7.7.1.1.1.2.cmml">⁢</mo><mrow id="S2.Ex1.m1.7.7.1.1.1.1.1" xref="S2.Ex1.m1.7.7.1.1.1.1.1.1.cmml"><mo id="S2.Ex1.m1.7.7.1.1.1.1.1.2" stretchy="false" xref="S2.Ex1.m1.7.7.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.Ex1.m1.7.7.1.1.1.1.1.1" xref="S2.Ex1.m1.7.7.1.1.1.1.1.1.cmml"><msub id="S2.Ex1.m1.7.7.1.1.1.1.1.1.2" xref="S2.Ex1.m1.7.7.1.1.1.1.1.1.2.cmml"><mi id="S2.Ex1.m1.7.7.1.1.1.1.1.1.2.2" xref="S2.Ex1.m1.7.7.1.1.1.1.1.1.2.2.cmml">y</mi><mi id="S2.Ex1.m1.7.7.1.1.1.1.1.1.2.3" xref="S2.Ex1.m1.7.7.1.1.1.1.1.1.2.3.cmml">l</mi></msub><mo id="S2.Ex1.m1.7.7.1.1.1.1.1.1.1" xref="S2.Ex1.m1.7.7.1.1.1.1.1.1.1.cmml">≻</mo><mrow id="S2.Ex1.m1.7.7.1.1.1.1.1.1.3" xref="S2.Ex1.m1.7.7.1.1.1.1.1.1.3.cmml"><msub id="S2.Ex1.m1.7.7.1.1.1.1.1.1.3.2" xref="S2.Ex1.m1.7.7.1.1.1.1.1.1.3.2.cmml"><mi id="S2.Ex1.m1.7.7.1.1.1.1.1.1.3.2.2" xref="S2.Ex1.m1.7.7.1.1.1.1.1.1.3.2.2.cmml">y</mi><mi id="S2.Ex1.m1.7.7.1.1.1.1.1.1.3.2.3" xref="S2.Ex1.m1.7.7.1.1.1.1.1.1.3.2.3.cmml">w</mi></msub><mo fence="false" id="S2.Ex1.m1.7.7.1.1.1.1.1.1.3.1" xref="S2.Ex1.m1.7.7.1.1.1.1.1.1.3.1.cmml">|</mo><mi id="S2.Ex1.m1.7.7.1.1.1.1.1.1.3.3" xref="S2.Ex1.m1.7.7.1.1.1.1.1.1.3.3.cmml">x</mi></mrow></mrow><mo id="S2.Ex1.m1.7.7.1.1.1.1.1.3" stretchy="false" xref="S2.Ex1.m1.7.7.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.Ex1.m1.7.7.1.1.2" xref="S2.Ex1.m1.7.7.1.1.2.cmml">=</mo><mfrac id="S2.Ex1.m1.6.6" xref="S2.Ex1.m1.6.6.cmml"><mrow id="S2.Ex1.m1.2.2.2" xref="S2.Ex1.m1.2.2.2.cmml"><mi id="S2.Ex1.m1.2.2.2.4" xref="S2.Ex1.m1.2.2.2.4.cmml">e</mi><mo id="S2.Ex1.m1.2.2.2.3" xref="S2.Ex1.m1.2.2.2.3.cmml">⁢</mo><mi id="S2.Ex1.m1.2.2.2.5" xref="S2.Ex1.m1.2.2.2.5.cmml">x</mi><mo id="S2.Ex1.m1.2.2.2.3a" xref="S2.Ex1.m1.2.2.2.3.cmml">⁢</mo><mi id="S2.Ex1.m1.2.2.2.6" xref="S2.Ex1.m1.2.2.2.6.cmml">p</mi><mo id="S2.Ex1.m1.2.2.2.3b" xref="S2.Ex1.m1.2.2.2.3.cmml">⁢</mo><mrow id="S2.Ex1.m1.2.2.2.2.1" xref="S2.Ex1.m1.2.2.2.2.1.1.cmml"><mo id="S2.Ex1.m1.2.2.2.2.1.2" stretchy="false" xref="S2.Ex1.m1.2.2.2.2.1.1.cmml">(</mo><mrow id="S2.Ex1.m1.2.2.2.2.1.1" xref="S2.Ex1.m1.2.2.2.2.1.1.cmml"><mi id="S2.Ex1.m1.2.2.2.2.1.1.3" xref="S2.Ex1.m1.2.2.2.2.1.1.3.cmml">r</mi><mo id="S2.Ex1.m1.2.2.2.2.1.1.2" xref="S2.Ex1.m1.2.2.2.2.1.1.2.cmml">⁢</mo><mrow id="S2.Ex1.m1.2.2.2.2.1.1.1.1" xref="S2.Ex1.m1.2.2.2.2.1.1.1.2.cmml"><mo id="S2.Ex1.m1.2.2.2.2.1.1.1.1.2" stretchy="false" xref="S2.Ex1.m1.2.2.2.2.1.1.1.2.cmml">(</mo><mi id="S2.Ex1.m1.1.1.1.1" xref="S2.Ex1.m1.1.1.1.1.cmml">x</mi><mo id="S2.Ex1.m1.2.2.2.2.1.1.1.1.3" xref="S2.Ex1.m1.2.2.2.2.1.1.1.2.cmml">,</mo><msub id="S2.Ex1.m1.2.2.2.2.1.1.1.1.1" xref="S2.Ex1.m1.2.2.2.2.1.1.1.1.1.cmml"><mi id="S2.Ex1.m1.2.2.2.2.1.1.1.1.1.2" xref="S2.Ex1.m1.2.2.2.2.1.1.1.1.1.2.cmml">y</mi><mi id="S2.Ex1.m1.2.2.2.2.1.1.1.1.1.3" xref="S2.Ex1.m1.2.2.2.2.1.1.1.1.1.3.cmml">l</mi></msub><mo id="S2.Ex1.m1.2.2.2.2.1.1.1.1.4" stretchy="false" xref="S2.Ex1.m1.2.2.2.2.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S2.Ex1.m1.2.2.2.2.1.3" stretchy="false" xref="S2.Ex1.m1.2.2.2.2.1.1.cmml">)</mo></mrow></mrow><mrow id="S2.Ex1.m1.6.6.6" xref="S2.Ex1.m1.6.6.6.cmml"><mrow id="S2.Ex1.m1.5.5.5.3" xref="S2.Ex1.m1.5.5.5.3.cmml"><mi id="S2.Ex1.m1.5.5.5.3.3" xref="S2.Ex1.m1.5.5.5.3.3.cmml">e</mi><mo id="S2.Ex1.m1.5.5.5.3.2" xref="S2.Ex1.m1.5.5.5.3.2.cmml">⁢</mo><mi id="S2.Ex1.m1.5.5.5.3.4" xref="S2.Ex1.m1.5.5.5.3.4.cmml">x</mi><mo id="S2.Ex1.m1.5.5.5.3.2a" xref="S2.Ex1.m1.5.5.5.3.2.cmml">⁢</mo><mi id="S2.Ex1.m1.5.5.5.3.5" xref="S2.Ex1.m1.5.5.5.3.5.cmml">p</mi><mo id="S2.Ex1.m1.5.5.5.3.2b" xref="S2.Ex1.m1.5.5.5.3.2.cmml">⁢</mo><mrow id="S2.Ex1.m1.5.5.5.3.1.1" xref="S2.Ex1.m1.5.5.5.3.1.1.1.cmml"><mo id="S2.Ex1.m1.5.5.5.3.1.1.2" stretchy="false" xref="S2.Ex1.m1.5.5.5.3.1.1.1.cmml">(</mo><mrow id="S2.Ex1.m1.5.5.5.3.1.1.1" xref="S2.Ex1.m1.5.5.5.3.1.1.1.cmml"><mi id="S2.Ex1.m1.5.5.5.3.1.1.1.3" xref="S2.Ex1.m1.5.5.5.3.1.1.1.3.cmml">r</mi><mo id="S2.Ex1.m1.5.5.5.3.1.1.1.2" xref="S2.Ex1.m1.5.5.5.3.1.1.1.2.cmml">⁢</mo><mrow id="S2.Ex1.m1.5.5.5.3.1.1.1.1.1" xref="S2.Ex1.m1.5.5.5.3.1.1.1.1.2.cmml"><mo id="S2.Ex1.m1.5.5.5.3.1.1.1.1.1.2" stretchy="false" xref="S2.Ex1.m1.5.5.5.3.1.1.1.1.2.cmml">(</mo><mi id="S2.Ex1.m1.3.3.3.1" xref="S2.Ex1.m1.3.3.3.1.cmml">x</mi><mo id="S2.Ex1.m1.5.5.5.3.1.1.1.1.1.3" xref="S2.Ex1.m1.5.5.5.3.1.1.1.1.2.cmml">,</mo><msub id="S2.Ex1.m1.5.5.5.3.1.1.1.1.1.1" xref="S2.Ex1.m1.5.5.5.3.1.1.1.1.1.1.cmml"><mi id="S2.Ex1.m1.5.5.5.3.1.1.1.1.1.1.2" xref="S2.Ex1.m1.5.5.5.3.1.1.1.1.1.1.2.cmml">y</mi><mi id="S2.Ex1.m1.5.5.5.3.1.1.1.1.1.1.3" xref="S2.Ex1.m1.5.5.5.3.1.1.1.1.1.1.3.cmml">l</mi></msub><mo id="S2.Ex1.m1.5.5.5.3.1.1.1.1.1.4" stretchy="false" xref="S2.Ex1.m1.5.5.5.3.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S2.Ex1.m1.5.5.5.3.1.1.3" stretchy="false" xref="S2.Ex1.m1.5.5.5.3.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.Ex1.m1.6.6.6.5" xref="S2.Ex1.m1.6.6.6.5.cmml">+</mo><mrow id="S2.Ex1.m1.6.6.6.4" xref="S2.Ex1.m1.6.6.6.4.cmml"><mi id="S2.Ex1.m1.6.6.6.4.3" xref="S2.Ex1.m1.6.6.6.4.3.cmml">e</mi><mo id="S2.Ex1.m1.6.6.6.4.2" xref="S2.Ex1.m1.6.6.6.4.2.cmml">⁢</mo><mi id="S2.Ex1.m1.6.6.6.4.4" xref="S2.Ex1.m1.6.6.6.4.4.cmml">x</mi><mo id="S2.Ex1.m1.6.6.6.4.2a" xref="S2.Ex1.m1.6.6.6.4.2.cmml">⁢</mo><mi id="S2.Ex1.m1.6.6.6.4.5" xref="S2.Ex1.m1.6.6.6.4.5.cmml">p</mi><mo id="S2.Ex1.m1.6.6.6.4.2b" xref="S2.Ex1.m1.6.6.6.4.2.cmml">⁢</mo><mrow id="S2.Ex1.m1.6.6.6.4.1.1" xref="S2.Ex1.m1.6.6.6.4.1.1.1.cmml"><mo id="S2.Ex1.m1.6.6.6.4.1.1.2" stretchy="false" xref="S2.Ex1.m1.6.6.6.4.1.1.1.cmml">(</mo><mrow id="S2.Ex1.m1.6.6.6.4.1.1.1" xref="S2.Ex1.m1.6.6.6.4.1.1.1.cmml"><mi id="S2.Ex1.m1.6.6.6.4.1.1.1.3" xref="S2.Ex1.m1.6.6.6.4.1.1.1.3.cmml">r</mi><mo id="S2.Ex1.m1.6.6.6.4.1.1.1.2" xref="S2.Ex1.m1.6.6.6.4.1.1.1.2.cmml">⁢</mo><mrow id="S2.Ex1.m1.6.6.6.4.1.1.1.1.1" xref="S2.Ex1.m1.6.6.6.4.1.1.1.1.2.cmml"><mo id="S2.Ex1.m1.6.6.6.4.1.1.1.1.1.2" stretchy="false" xref="S2.Ex1.m1.6.6.6.4.1.1.1.1.2.cmml">(</mo><mi id="S2.Ex1.m1.4.4.4.2" xref="S2.Ex1.m1.4.4.4.2.cmml">x</mi><mo id="S2.Ex1.m1.6.6.6.4.1.1.1.1.1.3" xref="S2.Ex1.m1.6.6.6.4.1.1.1.1.2.cmml">,</mo><msub id="S2.Ex1.m1.6.6.6.4.1.1.1.1.1.1" xref="S2.Ex1.m1.6.6.6.4.1.1.1.1.1.1.cmml"><mi id="S2.Ex1.m1.6.6.6.4.1.1.1.1.1.1.2" xref="S2.Ex1.m1.6.6.6.4.1.1.1.1.1.1.2.cmml">y</mi><mi id="S2.Ex1.m1.6.6.6.4.1.1.1.1.1.1.3" xref="S2.Ex1.m1.6.6.6.4.1.1.1.1.1.1.3.cmml">w</mi></msub><mo id="S2.Ex1.m1.6.6.6.4.1.1.1.1.1.4" stretchy="false" xref="S2.Ex1.m1.6.6.6.4.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S2.Ex1.m1.6.6.6.4.1.1.3" stretchy="false" xref="S2.Ex1.m1.6.6.6.4.1.1.1.cmml">)</mo></mrow></mrow></mrow></mfrac></mrow><mo id="S2.Ex1.m1.7.7.1.2" lspace="0em" xref="S2.Ex1.m1.7.7.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.Ex1.m1.7b"><apply id="S2.Ex1.m1.7.7.1.1.cmml" xref="S2.Ex1.m1.7.7.1"><eq id="S2.Ex1.m1.7.7.1.1.2.cmml" xref="S2.Ex1.m1.7.7.1.1.2"></eq><apply id="S2.Ex1.m1.7.7.1.1.1.cmml" xref="S2.Ex1.m1.7.7.1.1.1"><times id="S2.Ex1.m1.7.7.1.1.1.2.cmml" xref="S2.Ex1.m1.7.7.1.1.1.2"></times><ci id="S2.Ex1.m1.7.7.1.1.1.3.cmml" xref="S2.Ex1.m1.7.7.1.1.1.3">𝑃</ci><apply id="S2.Ex1.m1.7.7.1.1.1.1.1.1.cmml" xref="S2.Ex1.m1.7.7.1.1.1.1.1"><csymbol cd="latexml" id="S2.Ex1.m1.7.7.1.1.1.1.1.1.1.cmml" xref="S2.Ex1.m1.7.7.1.1.1.1.1.1.1">succeeds</csymbol><apply id="S2.Ex1.m1.7.7.1.1.1.1.1.1.2.cmml" xref="S2.Ex1.m1.7.7.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.Ex1.m1.7.7.1.1.1.1.1.1.2.1.cmml" xref="S2.Ex1.m1.7.7.1.1.1.1.1.1.2">subscript</csymbol><ci id="S2.Ex1.m1.7.7.1.1.1.1.1.1.2.2.cmml" xref="S2.Ex1.m1.7.7.1.1.1.1.1.1.2.2">𝑦</ci><ci id="S2.Ex1.m1.7.7.1.1.1.1.1.1.2.3.cmml" xref="S2.Ex1.m1.7.7.1.1.1.1.1.1.2.3">𝑙</ci></apply><apply id="S2.Ex1.m1.7.7.1.1.1.1.1.1.3.cmml" xref="S2.Ex1.m1.7.7.1.1.1.1.1.1.3"><csymbol cd="latexml" id="S2.Ex1.m1.7.7.1.1.1.1.1.1.3.1.cmml" xref="S2.Ex1.m1.7.7.1.1.1.1.1.1.3.1">conditional</csymbol><apply id="S2.Ex1.m1.7.7.1.1.1.1.1.1.3.2.cmml" xref="S2.Ex1.m1.7.7.1.1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S2.Ex1.m1.7.7.1.1.1.1.1.1.3.2.1.cmml" xref="S2.Ex1.m1.7.7.1.1.1.1.1.1.3.2">subscript</csymbol><ci id="S2.Ex1.m1.7.7.1.1.1.1.1.1.3.2.2.cmml" xref="S2.Ex1.m1.7.7.1.1.1.1.1.1.3.2.2">𝑦</ci><ci id="S2.Ex1.m1.7.7.1.1.1.1.1.1.3.2.3.cmml" xref="S2.Ex1.m1.7.7.1.1.1.1.1.1.3.2.3">𝑤</ci></apply><ci id="S2.Ex1.m1.7.7.1.1.1.1.1.1.3.3.cmml" xref="S2.Ex1.m1.7.7.1.1.1.1.1.1.3.3">𝑥</ci></apply></apply></apply><apply id="S2.Ex1.m1.6.6.cmml" xref="S2.Ex1.m1.6.6"><divide id="S2.Ex1.m1.6.6.7.cmml" xref="S2.Ex1.m1.6.6"></divide><apply id="S2.Ex1.m1.2.2.2.cmml" xref="S2.Ex1.m1.2.2.2"><times id="S2.Ex1.m1.2.2.2.3.cmml" xref="S2.Ex1.m1.2.2.2.3"></times><ci id="S2.Ex1.m1.2.2.2.4.cmml" xref="S2.Ex1.m1.2.2.2.4">𝑒</ci><ci id="S2.Ex1.m1.2.2.2.5.cmml" xref="S2.Ex1.m1.2.2.2.5">𝑥</ci><ci id="S2.Ex1.m1.2.2.2.6.cmml" xref="S2.Ex1.m1.2.2.2.6">𝑝</ci><apply id="S2.Ex1.m1.2.2.2.2.1.1.cmml" xref="S2.Ex1.m1.2.2.2.2.1"><times id="S2.Ex1.m1.2.2.2.2.1.1.2.cmml" xref="S2.Ex1.m1.2.2.2.2.1.1.2"></times><ci id="S2.Ex1.m1.2.2.2.2.1.1.3.cmml" xref="S2.Ex1.m1.2.2.2.2.1.1.3">𝑟</ci><interval closure="open" id="S2.Ex1.m1.2.2.2.2.1.1.1.2.cmml" xref="S2.Ex1.m1.2.2.2.2.1.1.1.1"><ci id="S2.Ex1.m1.1.1.1.1.cmml" xref="S2.Ex1.m1.1.1.1.1">𝑥</ci><apply id="S2.Ex1.m1.2.2.2.2.1.1.1.1.1.cmml" xref="S2.Ex1.m1.2.2.2.2.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.Ex1.m1.2.2.2.2.1.1.1.1.1.1.cmml" xref="S2.Ex1.m1.2.2.2.2.1.1.1.1.1">subscript</csymbol><ci id="S2.Ex1.m1.2.2.2.2.1.1.1.1.1.2.cmml" xref="S2.Ex1.m1.2.2.2.2.1.1.1.1.1.2">𝑦</ci><ci id="S2.Ex1.m1.2.2.2.2.1.1.1.1.1.3.cmml" xref="S2.Ex1.m1.2.2.2.2.1.1.1.1.1.3">𝑙</ci></apply></interval></apply></apply><apply id="S2.Ex1.m1.6.6.6.cmml" xref="S2.Ex1.m1.6.6.6"><plus id="S2.Ex1.m1.6.6.6.5.cmml" xref="S2.Ex1.m1.6.6.6.5"></plus><apply id="S2.Ex1.m1.5.5.5.3.cmml" xref="S2.Ex1.m1.5.5.5.3"><times id="S2.Ex1.m1.5.5.5.3.2.cmml" xref="S2.Ex1.m1.5.5.5.3.2"></times><ci id="S2.Ex1.m1.5.5.5.3.3.cmml" xref="S2.Ex1.m1.5.5.5.3.3">𝑒</ci><ci id="S2.Ex1.m1.5.5.5.3.4.cmml" xref="S2.Ex1.m1.5.5.5.3.4">𝑥</ci><ci id="S2.Ex1.m1.5.5.5.3.5.cmml" xref="S2.Ex1.m1.5.5.5.3.5">𝑝</ci><apply id="S2.Ex1.m1.5.5.5.3.1.1.1.cmml" xref="S2.Ex1.m1.5.5.5.3.1.1"><times id="S2.Ex1.m1.5.5.5.3.1.1.1.2.cmml" xref="S2.Ex1.m1.5.5.5.3.1.1.1.2"></times><ci id="S2.Ex1.m1.5.5.5.3.1.1.1.3.cmml" xref="S2.Ex1.m1.5.5.5.3.1.1.1.3">𝑟</ci><interval closure="open" id="S2.Ex1.m1.5.5.5.3.1.1.1.1.2.cmml" xref="S2.Ex1.m1.5.5.5.3.1.1.1.1.1"><ci id="S2.Ex1.m1.3.3.3.1.cmml" xref="S2.Ex1.m1.3.3.3.1">𝑥</ci><apply id="S2.Ex1.m1.5.5.5.3.1.1.1.1.1.1.cmml" xref="S2.Ex1.m1.5.5.5.3.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.Ex1.m1.5.5.5.3.1.1.1.1.1.1.1.cmml" xref="S2.Ex1.m1.5.5.5.3.1.1.1.1.1.1">subscript</csymbol><ci id="S2.Ex1.m1.5.5.5.3.1.1.1.1.1.1.2.cmml" xref="S2.Ex1.m1.5.5.5.3.1.1.1.1.1.1.2">𝑦</ci><ci id="S2.Ex1.m1.5.5.5.3.1.1.1.1.1.1.3.cmml" xref="S2.Ex1.m1.5.5.5.3.1.1.1.1.1.1.3">𝑙</ci></apply></interval></apply></apply><apply id="S2.Ex1.m1.6.6.6.4.cmml" xref="S2.Ex1.m1.6.6.6.4"><times id="S2.Ex1.m1.6.6.6.4.2.cmml" xref="S2.Ex1.m1.6.6.6.4.2"></times><ci id="S2.Ex1.m1.6.6.6.4.3.cmml" xref="S2.Ex1.m1.6.6.6.4.3">𝑒</ci><ci id="S2.Ex1.m1.6.6.6.4.4.cmml" xref="S2.Ex1.m1.6.6.6.4.4">𝑥</ci><ci id="S2.Ex1.m1.6.6.6.4.5.cmml" xref="S2.Ex1.m1.6.6.6.4.5">𝑝</ci><apply id="S2.Ex1.m1.6.6.6.4.1.1.1.cmml" xref="S2.Ex1.m1.6.6.6.4.1.1"><times id="S2.Ex1.m1.6.6.6.4.1.1.1.2.cmml" xref="S2.Ex1.m1.6.6.6.4.1.1.1.2"></times><ci id="S2.Ex1.m1.6.6.6.4.1.1.1.3.cmml" xref="S2.Ex1.m1.6.6.6.4.1.1.1.3">𝑟</ci><interval closure="open" id="S2.Ex1.m1.6.6.6.4.1.1.1.1.2.cmml" xref="S2.Ex1.m1.6.6.6.4.1.1.1.1.1"><ci id="S2.Ex1.m1.4.4.4.2.cmml" xref="S2.Ex1.m1.4.4.4.2">𝑥</ci><apply id="S2.Ex1.m1.6.6.6.4.1.1.1.1.1.1.cmml" xref="S2.Ex1.m1.6.6.6.4.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.Ex1.m1.6.6.6.4.1.1.1.1.1.1.1.cmml" xref="S2.Ex1.m1.6.6.6.4.1.1.1.1.1.1">subscript</csymbol><ci id="S2.Ex1.m1.6.6.6.4.1.1.1.1.1.1.2.cmml" xref="S2.Ex1.m1.6.6.6.4.1.1.1.1.1.1.2">𝑦</ci><ci id="S2.Ex1.m1.6.6.6.4.1.1.1.1.1.1.3.cmml" xref="S2.Ex1.m1.6.6.6.4.1.1.1.1.1.1.3">𝑤</ci></apply></interval></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex1.m1.7c">P(y_{l}\succ y_{w}|x)=\frac{exp(r(x,y_{l}))}{exp(r(x,y_{l}))+exp(r(x,y_{w}))}.</annotation><annotation encoding="application/x-llamapun" id="S2.Ex1.m1.7d">italic_P ( italic_y start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT ≻ italic_y start_POSTSUBSCRIPT italic_w end_POSTSUBSCRIPT | italic_x ) = divide start_ARG italic_e italic_x italic_p ( italic_r ( italic_x , italic_y start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT ) ) end_ARG start_ARG italic_e italic_x italic_p ( italic_r ( italic_x , italic_y start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT ) ) + italic_e italic_x italic_p ( italic_r ( italic_x , italic_y start_POSTSUBSCRIPT italic_w end_POSTSUBSCRIPT ) ) end_ARG .</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S2.SS2.p1.2">RLHF objectives then can be defined similarly to entropy loss. 
<br class="ltx_break"/></p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3. </span>PPO for Regularized Policy Gradient</h3>
<div class="ltx_para" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.1">Proximal Policy Optimization (PPO) <cite class="ltx_cite ltx_citemacro_citep">(Schulman et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.16032v1#bib.bib15" title="">2017</a>)</cite> has been demonstrated to be effective in fine-tuning GPT models with human instructions and labeled preferences <cite class="ltx_cite ltx_citemacro_citep">(Ouyang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.16032v1#bib.bib12" title="">2022</a>)</cite>. PPO uses clipping or KL divergence constraints to minimize the likelihood of large updates between steps, approximately providing guarantees for monotonic improvement. This approach converges in probability to local optima and, in practice, results in more stable training outcomes. The clipped loss function for policy gradient in PPO can be expressed as:</p>
<table class="ltx_equation ltx_eqn_table" id="S2.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_left">(1)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="L_{\theta_{k}}^{PPO}=-E_{\tau\sim\pi_{k}}\left[min(z_{t}(\theta)\hat{A}_{t}^{%
\pi_{k}},clip(z_{t}(\theta),1-\epsilon,1+\epsilon)\hat{A}_{t}^{\pi_{k}}\right]" class="ltx_math_unparsed" display="block" id="S2.E1.m1.2"><semantics id="S2.E1.m1.2a"><mrow id="S2.E1.m1.2b"><msubsup id="S2.E1.m1.2.3"><mi id="S2.E1.m1.2.3.2.2">L</mi><msub id="S2.E1.m1.2.3.2.3"><mi id="S2.E1.m1.2.3.2.3.2">θ</mi><mi id="S2.E1.m1.2.3.2.3.3">k</mi></msub><mrow id="S2.E1.m1.2.3.3"><mi id="S2.E1.m1.2.3.3.2">P</mi><mo id="S2.E1.m1.2.3.3.1">⁢</mo><mi id="S2.E1.m1.2.3.3.3">P</mi><mo id="S2.E1.m1.2.3.3.1a">⁢</mo><mi id="S2.E1.m1.2.3.3.4">O</mi></mrow></msubsup><mo id="S2.E1.m1.2.4" rspace="0em">=</mo><mo id="S2.E1.m1.2.5" lspace="0em">−</mo><msub id="S2.E1.m1.2.6"><mi id="S2.E1.m1.2.6.2">E</mi><mrow id="S2.E1.m1.2.6.3"><mi id="S2.E1.m1.2.6.3.2">τ</mi><mo id="S2.E1.m1.2.6.3.1">∼</mo><msub id="S2.E1.m1.2.6.3.3"><mi id="S2.E1.m1.2.6.3.3.2">π</mi><mi id="S2.E1.m1.2.6.3.3.3">k</mi></msub></mrow></msub><mrow id="S2.E1.m1.2.7"><mo id="S2.E1.m1.2.7.1">[</mo><mi id="S2.E1.m1.2.7.2">m</mi><mi id="S2.E1.m1.2.7.3">i</mi><mi id="S2.E1.m1.2.7.4">n</mi><mrow id="S2.E1.m1.2.7.5"><mo id="S2.E1.m1.2.7.5.1" stretchy="false">(</mo><msub id="S2.E1.m1.2.7.5.2"><mi id="S2.E1.m1.2.7.5.2.2">z</mi><mi id="S2.E1.m1.2.7.5.2.3">t</mi></msub><mrow id="S2.E1.m1.2.7.5.3"><mo id="S2.E1.m1.2.7.5.3.1" stretchy="false">(</mo><mi id="S2.E1.m1.1.1">θ</mi><mo id="S2.E1.m1.2.7.5.3.2" stretchy="false">)</mo></mrow><msubsup id="S2.E1.m1.2.7.5.4"><mover accent="true" id="S2.E1.m1.2.7.5.4.2.2"><mi id="S2.E1.m1.2.7.5.4.2.2.2">A</mi><mo id="S2.E1.m1.2.7.5.4.2.2.1">^</mo></mover><mi id="S2.E1.m1.2.7.5.4.2.3">t</mi><msub id="S2.E1.m1.2.7.5.4.3"><mi id="S2.E1.m1.2.7.5.4.3.2">π</mi><mi id="S2.E1.m1.2.7.5.4.3.3">k</mi></msub></msubsup><mo id="S2.E1.m1.2.7.5.5">,</mo><mi id="S2.E1.m1.2.7.5.6">c</mi><mi id="S2.E1.m1.2.7.5.7">l</mi><mi id="S2.E1.m1.2.7.5.8">i</mi><mi id="S2.E1.m1.2.7.5.9">p</mi><mrow id="S2.E1.m1.2.7.5.10"><mo id="S2.E1.m1.2.7.5.10.1" stretchy="false">(</mo><msub id="S2.E1.m1.2.7.5.10.2"><mi id="S2.E1.m1.2.7.5.10.2.2">z</mi><mi id="S2.E1.m1.2.7.5.10.2.3">t</mi></msub><mrow id="S2.E1.m1.2.7.5.10.3"><mo id="S2.E1.m1.2.7.5.10.3.1" stretchy="false">(</mo><mi id="S2.E1.m1.2.2">θ</mi><mo id="S2.E1.m1.2.7.5.10.3.2" stretchy="false">)</mo></mrow><mo id="S2.E1.m1.2.7.5.10.4">,</mo><mn id="S2.E1.m1.2.7.5.10.5">1</mn><mo id="S2.E1.m1.2.7.5.10.6">−</mo><mi id="S2.E1.m1.2.7.5.10.7">ϵ</mi><mo id="S2.E1.m1.2.7.5.10.8">,</mo><mn id="S2.E1.m1.2.7.5.10.9">1</mn><mo id="S2.E1.m1.2.7.5.10.10">+</mo><mi id="S2.E1.m1.2.7.5.10.11">ϵ</mi><mo id="S2.E1.m1.2.7.5.10.12" stretchy="false">)</mo></mrow><msubsup id="S2.E1.m1.2.7.5.11"><mover accent="true" id="S2.E1.m1.2.7.5.11.2.2"><mi id="S2.E1.m1.2.7.5.11.2.2.2">A</mi><mo id="S2.E1.m1.2.7.5.11.2.2.1">^</mo></mover><mi id="S2.E1.m1.2.7.5.11.2.3">t</mi><msub id="S2.E1.m1.2.7.5.11.3"><mi id="S2.E1.m1.2.7.5.11.3.2">π</mi><mi id="S2.E1.m1.2.7.5.11.3.3">k</mi></msub></msubsup><mo id="S2.E1.m1.2.7.5.12">]</mo></mrow></mrow></mrow><annotation encoding="application/x-tex" id="S2.E1.m1.2c">L_{\theta_{k}}^{PPO}=-E_{\tau\sim\pi_{k}}\left[min(z_{t}(\theta)\hat{A}_{t}^{%
\pi_{k}},clip(z_{t}(\theta),1-\epsilon,1+\epsilon)\hat{A}_{t}^{\pi_{k}}\right]</annotation><annotation encoding="application/x-llamapun" id="S2.E1.m1.2d">italic_L start_POSTSUBSCRIPT italic_θ start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_P italic_P italic_O end_POSTSUPERSCRIPT = - italic_E start_POSTSUBSCRIPT italic_τ ∼ italic_π start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT end_POSTSUBSCRIPT [ italic_m italic_i italic_n ( italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_θ ) over^ start_ARG italic_A end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_π start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT end_POSTSUPERSCRIPT , italic_c italic_l italic_i italic_p ( italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_θ ) , 1 - italic_ϵ , 1 + italic_ϵ ) over^ start_ARG italic_A end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_π start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ]</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S2.SS3.p1.2">, where 
<br class="ltx_break"/></p>
<table class="ltx_equation ltx_eqn_table" id="S2.Ex2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="z_{t}(\theta)=\frac{\pi_{\theta}(a_{t}|o_{t})}{\pi_{\theta_{k}}(a_{t}|o_{t})}," class="ltx_Math" display="block" id="S2.Ex2.m1.4"><semantics id="S2.Ex2.m1.4a"><mrow id="S2.Ex2.m1.4.4.1" xref="S2.Ex2.m1.4.4.1.1.cmml"><mrow id="S2.Ex2.m1.4.4.1.1" xref="S2.Ex2.m1.4.4.1.1.cmml"><mrow id="S2.Ex2.m1.4.4.1.1.2" xref="S2.Ex2.m1.4.4.1.1.2.cmml"><msub id="S2.Ex2.m1.4.4.1.1.2.2" xref="S2.Ex2.m1.4.4.1.1.2.2.cmml"><mi id="S2.Ex2.m1.4.4.1.1.2.2.2" xref="S2.Ex2.m1.4.4.1.1.2.2.2.cmml">z</mi><mi id="S2.Ex2.m1.4.4.1.1.2.2.3" xref="S2.Ex2.m1.4.4.1.1.2.2.3.cmml">t</mi></msub><mo id="S2.Ex2.m1.4.4.1.1.2.1" xref="S2.Ex2.m1.4.4.1.1.2.1.cmml">⁢</mo><mrow id="S2.Ex2.m1.4.4.1.1.2.3.2" xref="S2.Ex2.m1.4.4.1.1.2.cmml"><mo id="S2.Ex2.m1.4.4.1.1.2.3.2.1" stretchy="false" xref="S2.Ex2.m1.4.4.1.1.2.cmml">(</mo><mi id="S2.Ex2.m1.3.3" xref="S2.Ex2.m1.3.3.cmml">θ</mi><mo id="S2.Ex2.m1.4.4.1.1.2.3.2.2" stretchy="false" xref="S2.Ex2.m1.4.4.1.1.2.cmml">)</mo></mrow></mrow><mo id="S2.Ex2.m1.4.4.1.1.1" xref="S2.Ex2.m1.4.4.1.1.1.cmml">=</mo><mfrac id="S2.Ex2.m1.2.2" xref="S2.Ex2.m1.2.2.cmml"><mrow id="S2.Ex2.m1.1.1.1" xref="S2.Ex2.m1.1.1.1.cmml"><msub id="S2.Ex2.m1.1.1.1.3" xref="S2.Ex2.m1.1.1.1.3.cmml"><mi id="S2.Ex2.m1.1.1.1.3.2" xref="S2.Ex2.m1.1.1.1.3.2.cmml">π</mi><mi id="S2.Ex2.m1.1.1.1.3.3" xref="S2.Ex2.m1.1.1.1.3.3.cmml">θ</mi></msub><mo id="S2.Ex2.m1.1.1.1.2" xref="S2.Ex2.m1.1.1.1.2.cmml">⁢</mo><mrow id="S2.Ex2.m1.1.1.1.1.1" xref="S2.Ex2.m1.1.1.1.1.1.1.cmml"><mo id="S2.Ex2.m1.1.1.1.1.1.2" stretchy="false" xref="S2.Ex2.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.Ex2.m1.1.1.1.1.1.1" xref="S2.Ex2.m1.1.1.1.1.1.1.cmml"><msub id="S2.Ex2.m1.1.1.1.1.1.1.2" xref="S2.Ex2.m1.1.1.1.1.1.1.2.cmml"><mi id="S2.Ex2.m1.1.1.1.1.1.1.2.2" xref="S2.Ex2.m1.1.1.1.1.1.1.2.2.cmml">a</mi><mi id="S2.Ex2.m1.1.1.1.1.1.1.2.3" xref="S2.Ex2.m1.1.1.1.1.1.1.2.3.cmml">t</mi></msub><mo fence="false" id="S2.Ex2.m1.1.1.1.1.1.1.1" xref="S2.Ex2.m1.1.1.1.1.1.1.1.cmml">|</mo><msub id="S2.Ex2.m1.1.1.1.1.1.1.3" xref="S2.Ex2.m1.1.1.1.1.1.1.3.cmml"><mi id="S2.Ex2.m1.1.1.1.1.1.1.3.2" xref="S2.Ex2.m1.1.1.1.1.1.1.3.2.cmml">o</mi><mi id="S2.Ex2.m1.1.1.1.1.1.1.3.3" xref="S2.Ex2.m1.1.1.1.1.1.1.3.3.cmml">t</mi></msub></mrow><mo id="S2.Ex2.m1.1.1.1.1.1.3" stretchy="false" xref="S2.Ex2.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mrow id="S2.Ex2.m1.2.2.2" xref="S2.Ex2.m1.2.2.2.cmml"><msub id="S2.Ex2.m1.2.2.2.3" xref="S2.Ex2.m1.2.2.2.3.cmml"><mi id="S2.Ex2.m1.2.2.2.3.2" xref="S2.Ex2.m1.2.2.2.3.2.cmml">π</mi><msub id="S2.Ex2.m1.2.2.2.3.3" xref="S2.Ex2.m1.2.2.2.3.3.cmml"><mi id="S2.Ex2.m1.2.2.2.3.3.2" xref="S2.Ex2.m1.2.2.2.3.3.2.cmml">θ</mi><mi id="S2.Ex2.m1.2.2.2.3.3.3" xref="S2.Ex2.m1.2.2.2.3.3.3.cmml">k</mi></msub></msub><mo id="S2.Ex2.m1.2.2.2.2" xref="S2.Ex2.m1.2.2.2.2.cmml">⁢</mo><mrow id="S2.Ex2.m1.2.2.2.1.1" xref="S2.Ex2.m1.2.2.2.1.1.1.cmml"><mo id="S2.Ex2.m1.2.2.2.1.1.2" stretchy="false" xref="S2.Ex2.m1.2.2.2.1.1.1.cmml">(</mo><mrow id="S2.Ex2.m1.2.2.2.1.1.1" xref="S2.Ex2.m1.2.2.2.1.1.1.cmml"><msub id="S2.Ex2.m1.2.2.2.1.1.1.2" xref="S2.Ex2.m1.2.2.2.1.1.1.2.cmml"><mi id="S2.Ex2.m1.2.2.2.1.1.1.2.2" xref="S2.Ex2.m1.2.2.2.1.1.1.2.2.cmml">a</mi><mi id="S2.Ex2.m1.2.2.2.1.1.1.2.3" xref="S2.Ex2.m1.2.2.2.1.1.1.2.3.cmml">t</mi></msub><mo fence="false" id="S2.Ex2.m1.2.2.2.1.1.1.1" xref="S2.Ex2.m1.2.2.2.1.1.1.1.cmml">|</mo><msub id="S2.Ex2.m1.2.2.2.1.1.1.3" xref="S2.Ex2.m1.2.2.2.1.1.1.3.cmml"><mi id="S2.Ex2.m1.2.2.2.1.1.1.3.2" xref="S2.Ex2.m1.2.2.2.1.1.1.3.2.cmml">o</mi><mi id="S2.Ex2.m1.2.2.2.1.1.1.3.3" xref="S2.Ex2.m1.2.2.2.1.1.1.3.3.cmml">t</mi></msub></mrow><mo id="S2.Ex2.m1.2.2.2.1.1.3" stretchy="false" xref="S2.Ex2.m1.2.2.2.1.1.1.cmml">)</mo></mrow></mrow></mfrac></mrow><mo id="S2.Ex2.m1.4.4.1.2" xref="S2.Ex2.m1.4.4.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.Ex2.m1.4b"><apply id="S2.Ex2.m1.4.4.1.1.cmml" xref="S2.Ex2.m1.4.4.1"><eq id="S2.Ex2.m1.4.4.1.1.1.cmml" xref="S2.Ex2.m1.4.4.1.1.1"></eq><apply id="S2.Ex2.m1.4.4.1.1.2.cmml" xref="S2.Ex2.m1.4.4.1.1.2"><times id="S2.Ex2.m1.4.4.1.1.2.1.cmml" xref="S2.Ex2.m1.4.4.1.1.2.1"></times><apply id="S2.Ex2.m1.4.4.1.1.2.2.cmml" xref="S2.Ex2.m1.4.4.1.1.2.2"><csymbol cd="ambiguous" id="S2.Ex2.m1.4.4.1.1.2.2.1.cmml" xref="S2.Ex2.m1.4.4.1.1.2.2">subscript</csymbol><ci id="S2.Ex2.m1.4.4.1.1.2.2.2.cmml" xref="S2.Ex2.m1.4.4.1.1.2.2.2">𝑧</ci><ci id="S2.Ex2.m1.4.4.1.1.2.2.3.cmml" xref="S2.Ex2.m1.4.4.1.1.2.2.3">𝑡</ci></apply><ci id="S2.Ex2.m1.3.3.cmml" xref="S2.Ex2.m1.3.3">𝜃</ci></apply><apply id="S2.Ex2.m1.2.2.cmml" xref="S2.Ex2.m1.2.2"><divide id="S2.Ex2.m1.2.2.3.cmml" xref="S2.Ex2.m1.2.2"></divide><apply id="S2.Ex2.m1.1.1.1.cmml" xref="S2.Ex2.m1.1.1.1"><times id="S2.Ex2.m1.1.1.1.2.cmml" xref="S2.Ex2.m1.1.1.1.2"></times><apply id="S2.Ex2.m1.1.1.1.3.cmml" xref="S2.Ex2.m1.1.1.1.3"><csymbol cd="ambiguous" id="S2.Ex2.m1.1.1.1.3.1.cmml" xref="S2.Ex2.m1.1.1.1.3">subscript</csymbol><ci id="S2.Ex2.m1.1.1.1.3.2.cmml" xref="S2.Ex2.m1.1.1.1.3.2">𝜋</ci><ci id="S2.Ex2.m1.1.1.1.3.3.cmml" xref="S2.Ex2.m1.1.1.1.3.3">𝜃</ci></apply><apply id="S2.Ex2.m1.1.1.1.1.1.1.cmml" xref="S2.Ex2.m1.1.1.1.1.1"><csymbol cd="latexml" id="S2.Ex2.m1.1.1.1.1.1.1.1.cmml" xref="S2.Ex2.m1.1.1.1.1.1.1.1">conditional</csymbol><apply id="S2.Ex2.m1.1.1.1.1.1.1.2.cmml" xref="S2.Ex2.m1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.Ex2.m1.1.1.1.1.1.1.2.1.cmml" xref="S2.Ex2.m1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S2.Ex2.m1.1.1.1.1.1.1.2.2.cmml" xref="S2.Ex2.m1.1.1.1.1.1.1.2.2">𝑎</ci><ci id="S2.Ex2.m1.1.1.1.1.1.1.2.3.cmml" xref="S2.Ex2.m1.1.1.1.1.1.1.2.3">𝑡</ci></apply><apply id="S2.Ex2.m1.1.1.1.1.1.1.3.cmml" xref="S2.Ex2.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.Ex2.m1.1.1.1.1.1.1.3.1.cmml" xref="S2.Ex2.m1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S2.Ex2.m1.1.1.1.1.1.1.3.2.cmml" xref="S2.Ex2.m1.1.1.1.1.1.1.3.2">𝑜</ci><ci id="S2.Ex2.m1.1.1.1.1.1.1.3.3.cmml" xref="S2.Ex2.m1.1.1.1.1.1.1.3.3">𝑡</ci></apply></apply></apply><apply id="S2.Ex2.m1.2.2.2.cmml" xref="S2.Ex2.m1.2.2.2"><times id="S2.Ex2.m1.2.2.2.2.cmml" xref="S2.Ex2.m1.2.2.2.2"></times><apply id="S2.Ex2.m1.2.2.2.3.cmml" xref="S2.Ex2.m1.2.2.2.3"><csymbol cd="ambiguous" id="S2.Ex2.m1.2.2.2.3.1.cmml" xref="S2.Ex2.m1.2.2.2.3">subscript</csymbol><ci id="S2.Ex2.m1.2.2.2.3.2.cmml" xref="S2.Ex2.m1.2.2.2.3.2">𝜋</ci><apply id="S2.Ex2.m1.2.2.2.3.3.cmml" xref="S2.Ex2.m1.2.2.2.3.3"><csymbol cd="ambiguous" id="S2.Ex2.m1.2.2.2.3.3.1.cmml" xref="S2.Ex2.m1.2.2.2.3.3">subscript</csymbol><ci id="S2.Ex2.m1.2.2.2.3.3.2.cmml" xref="S2.Ex2.m1.2.2.2.3.3.2">𝜃</ci><ci id="S2.Ex2.m1.2.2.2.3.3.3.cmml" xref="S2.Ex2.m1.2.2.2.3.3.3">𝑘</ci></apply></apply><apply id="S2.Ex2.m1.2.2.2.1.1.1.cmml" xref="S2.Ex2.m1.2.2.2.1.1"><csymbol cd="latexml" id="S2.Ex2.m1.2.2.2.1.1.1.1.cmml" xref="S2.Ex2.m1.2.2.2.1.1.1.1">conditional</csymbol><apply id="S2.Ex2.m1.2.2.2.1.1.1.2.cmml" xref="S2.Ex2.m1.2.2.2.1.1.1.2"><csymbol cd="ambiguous" id="S2.Ex2.m1.2.2.2.1.1.1.2.1.cmml" xref="S2.Ex2.m1.2.2.2.1.1.1.2">subscript</csymbol><ci id="S2.Ex2.m1.2.2.2.1.1.1.2.2.cmml" xref="S2.Ex2.m1.2.2.2.1.1.1.2.2">𝑎</ci><ci id="S2.Ex2.m1.2.2.2.1.1.1.2.3.cmml" xref="S2.Ex2.m1.2.2.2.1.1.1.2.3">𝑡</ci></apply><apply id="S2.Ex2.m1.2.2.2.1.1.1.3.cmml" xref="S2.Ex2.m1.2.2.2.1.1.1.3"><csymbol cd="ambiguous" id="S2.Ex2.m1.2.2.2.1.1.1.3.1.cmml" xref="S2.Ex2.m1.2.2.2.1.1.1.3">subscript</csymbol><ci id="S2.Ex2.m1.2.2.2.1.1.1.3.2.cmml" xref="S2.Ex2.m1.2.2.2.1.1.1.3.2">𝑜</ci><ci id="S2.Ex2.m1.2.2.2.1.1.1.3.3.cmml" xref="S2.Ex2.m1.2.2.2.1.1.1.3.3">𝑡</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex2.m1.4c">z_{t}(\theta)=\frac{\pi_{\theta}(a_{t}|o_{t})}{\pi_{\theta_{k}}(a_{t}|o_{t})},</annotation><annotation encoding="application/x-llamapun" id="S2.Ex2.m1.4d">italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_θ ) = divide start_ARG italic_π start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | italic_o start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) end_ARG start_ARG italic_π start_POSTSUBSCRIPT italic_θ start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | italic_o start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) end_ARG ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<table class="ltx_equation ltx_eqn_table" id="S2.Ex3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\hat{A}_{t}^{\pi_{k}}=R_{t}-V^{\pi_{k}}(o_{t})." class="ltx_Math" display="block" id="S2.Ex3.m1.1"><semantics id="S2.Ex3.m1.1a"><mrow id="S2.Ex3.m1.1.1.1" xref="S2.Ex3.m1.1.1.1.1.cmml"><mrow id="S2.Ex3.m1.1.1.1.1" xref="S2.Ex3.m1.1.1.1.1.cmml"><msubsup id="S2.Ex3.m1.1.1.1.1.3" xref="S2.Ex3.m1.1.1.1.1.3.cmml"><mover accent="true" id="S2.Ex3.m1.1.1.1.1.3.2.2" xref="S2.Ex3.m1.1.1.1.1.3.2.2.cmml"><mi id="S2.Ex3.m1.1.1.1.1.3.2.2.2" xref="S2.Ex3.m1.1.1.1.1.3.2.2.2.cmml">A</mi><mo id="S2.Ex3.m1.1.1.1.1.3.2.2.1" xref="S2.Ex3.m1.1.1.1.1.3.2.2.1.cmml">^</mo></mover><mi id="S2.Ex3.m1.1.1.1.1.3.2.3" xref="S2.Ex3.m1.1.1.1.1.3.2.3.cmml">t</mi><msub id="S2.Ex3.m1.1.1.1.1.3.3" xref="S2.Ex3.m1.1.1.1.1.3.3.cmml"><mi id="S2.Ex3.m1.1.1.1.1.3.3.2" xref="S2.Ex3.m1.1.1.1.1.3.3.2.cmml">π</mi><mi id="S2.Ex3.m1.1.1.1.1.3.3.3" xref="S2.Ex3.m1.1.1.1.1.3.3.3.cmml">k</mi></msub></msubsup><mo id="S2.Ex3.m1.1.1.1.1.2" xref="S2.Ex3.m1.1.1.1.1.2.cmml">=</mo><mrow id="S2.Ex3.m1.1.1.1.1.1" xref="S2.Ex3.m1.1.1.1.1.1.cmml"><msub id="S2.Ex3.m1.1.1.1.1.1.3" xref="S2.Ex3.m1.1.1.1.1.1.3.cmml"><mi id="S2.Ex3.m1.1.1.1.1.1.3.2" xref="S2.Ex3.m1.1.1.1.1.1.3.2.cmml">R</mi><mi id="S2.Ex3.m1.1.1.1.1.1.3.3" xref="S2.Ex3.m1.1.1.1.1.1.3.3.cmml">t</mi></msub><mo id="S2.Ex3.m1.1.1.1.1.1.2" xref="S2.Ex3.m1.1.1.1.1.1.2.cmml">−</mo><mrow id="S2.Ex3.m1.1.1.1.1.1.1" xref="S2.Ex3.m1.1.1.1.1.1.1.cmml"><msup id="S2.Ex3.m1.1.1.1.1.1.1.3" xref="S2.Ex3.m1.1.1.1.1.1.1.3.cmml"><mi id="S2.Ex3.m1.1.1.1.1.1.1.3.2" xref="S2.Ex3.m1.1.1.1.1.1.1.3.2.cmml">V</mi><msub id="S2.Ex3.m1.1.1.1.1.1.1.3.3" xref="S2.Ex3.m1.1.1.1.1.1.1.3.3.cmml"><mi id="S2.Ex3.m1.1.1.1.1.1.1.3.3.2" xref="S2.Ex3.m1.1.1.1.1.1.1.3.3.2.cmml">π</mi><mi id="S2.Ex3.m1.1.1.1.1.1.1.3.3.3" xref="S2.Ex3.m1.1.1.1.1.1.1.3.3.3.cmml">k</mi></msub></msup><mo id="S2.Ex3.m1.1.1.1.1.1.1.2" xref="S2.Ex3.m1.1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S2.Ex3.m1.1.1.1.1.1.1.1.1" xref="S2.Ex3.m1.1.1.1.1.1.1.1.1.1.cmml"><mo id="S2.Ex3.m1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S2.Ex3.m1.1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S2.Ex3.m1.1.1.1.1.1.1.1.1.1" xref="S2.Ex3.m1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.Ex3.m1.1.1.1.1.1.1.1.1.1.2" xref="S2.Ex3.m1.1.1.1.1.1.1.1.1.1.2.cmml">o</mi><mi id="S2.Ex3.m1.1.1.1.1.1.1.1.1.1.3" xref="S2.Ex3.m1.1.1.1.1.1.1.1.1.1.3.cmml">t</mi></msub><mo id="S2.Ex3.m1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S2.Ex3.m1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S2.Ex3.m1.1.1.1.2" lspace="0em" xref="S2.Ex3.m1.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.Ex3.m1.1b"><apply id="S2.Ex3.m1.1.1.1.1.cmml" xref="S2.Ex3.m1.1.1.1"><eq id="S2.Ex3.m1.1.1.1.1.2.cmml" xref="S2.Ex3.m1.1.1.1.1.2"></eq><apply id="S2.Ex3.m1.1.1.1.1.3.cmml" xref="S2.Ex3.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.Ex3.m1.1.1.1.1.3.1.cmml" xref="S2.Ex3.m1.1.1.1.1.3">superscript</csymbol><apply id="S2.Ex3.m1.1.1.1.1.3.2.cmml" xref="S2.Ex3.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.Ex3.m1.1.1.1.1.3.2.1.cmml" xref="S2.Ex3.m1.1.1.1.1.3">subscript</csymbol><apply id="S2.Ex3.m1.1.1.1.1.3.2.2.cmml" xref="S2.Ex3.m1.1.1.1.1.3.2.2"><ci id="S2.Ex3.m1.1.1.1.1.3.2.2.1.cmml" xref="S2.Ex3.m1.1.1.1.1.3.2.2.1">^</ci><ci id="S2.Ex3.m1.1.1.1.1.3.2.2.2.cmml" xref="S2.Ex3.m1.1.1.1.1.3.2.2.2">𝐴</ci></apply><ci id="S2.Ex3.m1.1.1.1.1.3.2.3.cmml" xref="S2.Ex3.m1.1.1.1.1.3.2.3">𝑡</ci></apply><apply id="S2.Ex3.m1.1.1.1.1.3.3.cmml" xref="S2.Ex3.m1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S2.Ex3.m1.1.1.1.1.3.3.1.cmml" xref="S2.Ex3.m1.1.1.1.1.3.3">subscript</csymbol><ci id="S2.Ex3.m1.1.1.1.1.3.3.2.cmml" xref="S2.Ex3.m1.1.1.1.1.3.3.2">𝜋</ci><ci id="S2.Ex3.m1.1.1.1.1.3.3.3.cmml" xref="S2.Ex3.m1.1.1.1.1.3.3.3">𝑘</ci></apply></apply><apply id="S2.Ex3.m1.1.1.1.1.1.cmml" xref="S2.Ex3.m1.1.1.1.1.1"><minus id="S2.Ex3.m1.1.1.1.1.1.2.cmml" xref="S2.Ex3.m1.1.1.1.1.1.2"></minus><apply id="S2.Ex3.m1.1.1.1.1.1.3.cmml" xref="S2.Ex3.m1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.Ex3.m1.1.1.1.1.1.3.1.cmml" xref="S2.Ex3.m1.1.1.1.1.1.3">subscript</csymbol><ci id="S2.Ex3.m1.1.1.1.1.1.3.2.cmml" xref="S2.Ex3.m1.1.1.1.1.1.3.2">𝑅</ci><ci id="S2.Ex3.m1.1.1.1.1.1.3.3.cmml" xref="S2.Ex3.m1.1.1.1.1.1.3.3">𝑡</ci></apply><apply id="S2.Ex3.m1.1.1.1.1.1.1.cmml" xref="S2.Ex3.m1.1.1.1.1.1.1"><times id="S2.Ex3.m1.1.1.1.1.1.1.2.cmml" xref="S2.Ex3.m1.1.1.1.1.1.1.2"></times><apply id="S2.Ex3.m1.1.1.1.1.1.1.3.cmml" xref="S2.Ex3.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.Ex3.m1.1.1.1.1.1.1.3.1.cmml" xref="S2.Ex3.m1.1.1.1.1.1.1.3">superscript</csymbol><ci id="S2.Ex3.m1.1.1.1.1.1.1.3.2.cmml" xref="S2.Ex3.m1.1.1.1.1.1.1.3.2">𝑉</ci><apply id="S2.Ex3.m1.1.1.1.1.1.1.3.3.cmml" xref="S2.Ex3.m1.1.1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S2.Ex3.m1.1.1.1.1.1.1.3.3.1.cmml" xref="S2.Ex3.m1.1.1.1.1.1.1.3.3">subscript</csymbol><ci id="S2.Ex3.m1.1.1.1.1.1.1.3.3.2.cmml" xref="S2.Ex3.m1.1.1.1.1.1.1.3.3.2">𝜋</ci><ci id="S2.Ex3.m1.1.1.1.1.1.1.3.3.3.cmml" xref="S2.Ex3.m1.1.1.1.1.1.1.3.3.3">𝑘</ci></apply></apply><apply id="S2.Ex3.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.Ex3.m1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.Ex3.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.Ex3.m1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.Ex3.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.Ex3.m1.1.1.1.1.1.1.1.1.1.2">𝑜</ci><ci id="S2.Ex3.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.Ex3.m1.1.1.1.1.1.1.1.1.1.3">𝑡</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex3.m1.1c">\hat{A}_{t}^{\pi_{k}}=R_{t}-V^{\pi_{k}}(o_{t}).</annotation><annotation encoding="application/x-llamapun" id="S2.Ex3.m1.1d">over^ start_ARG italic_A end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_π start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT end_POSTSUPERSCRIPT = italic_R start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT - italic_V start_POSTSUPERSCRIPT italic_π start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ( italic_o start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) .</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
</section>
<section class="ltx_subsection" id="S2.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.4. </span>Learning with Human Preference - DPO</h3>
<div class="ltx_para" id="S2.SS4.p1">
<p class="ltx_p" id="S2.SS4.p1.1">The development of Direct Preference Optimization (DPO) <cite class="ltx_cite ltx_citemacro_citep">(Rafailov et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.16032v1#bib.bib13" title="">2023</a>)</cite> is revolutionary. It eliminates the need for explicit reward functions for preferences and instead relies solely on paired preference trajectories as training data. DPO is derived from joining the Bradley-Terry objective
<br class="ltx_break"/></p>
<table class="ltx_equation ltx_eqn_table" id="S2.Ex4">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="L_{BT}(r,D)=-E_{(x,y_{w},y_{l})\sim D}\left[log\ \sigma\left(r(x,y_{w})-r(x,y_%
{l})\right)\right]" class="ltx_Math" display="block" id="S2.Ex4.m1.8"><semantics id="S2.Ex4.m1.8a"><mrow id="S2.Ex4.m1.8.8" xref="S2.Ex4.m1.8.8.cmml"><mrow id="S2.Ex4.m1.8.8.3" xref="S2.Ex4.m1.8.8.3.cmml"><msub id="S2.Ex4.m1.8.8.3.2" xref="S2.Ex4.m1.8.8.3.2.cmml"><mi id="S2.Ex4.m1.8.8.3.2.2" xref="S2.Ex4.m1.8.8.3.2.2.cmml">L</mi><mrow id="S2.Ex4.m1.8.8.3.2.3" xref="S2.Ex4.m1.8.8.3.2.3.cmml"><mi id="S2.Ex4.m1.8.8.3.2.3.2" xref="S2.Ex4.m1.8.8.3.2.3.2.cmml">B</mi><mo id="S2.Ex4.m1.8.8.3.2.3.1" xref="S2.Ex4.m1.8.8.3.2.3.1.cmml">⁢</mo><mi id="S2.Ex4.m1.8.8.3.2.3.3" xref="S2.Ex4.m1.8.8.3.2.3.3.cmml">T</mi></mrow></msub><mo id="S2.Ex4.m1.8.8.3.1" xref="S2.Ex4.m1.8.8.3.1.cmml">⁢</mo><mrow id="S2.Ex4.m1.8.8.3.3.2" xref="S2.Ex4.m1.8.8.3.3.1.cmml"><mo id="S2.Ex4.m1.8.8.3.3.2.1" stretchy="false" xref="S2.Ex4.m1.8.8.3.3.1.cmml">(</mo><mi id="S2.Ex4.m1.4.4" xref="S2.Ex4.m1.4.4.cmml">r</mi><mo id="S2.Ex4.m1.8.8.3.3.2.2" xref="S2.Ex4.m1.8.8.3.3.1.cmml">,</mo><mi id="S2.Ex4.m1.5.5" xref="S2.Ex4.m1.5.5.cmml">D</mi><mo id="S2.Ex4.m1.8.8.3.3.2.3" stretchy="false" xref="S2.Ex4.m1.8.8.3.3.1.cmml">)</mo></mrow></mrow><mo id="S2.Ex4.m1.8.8.2" xref="S2.Ex4.m1.8.8.2.cmml">=</mo><mrow id="S2.Ex4.m1.8.8.1" xref="S2.Ex4.m1.8.8.1.cmml"><mo id="S2.Ex4.m1.8.8.1a" xref="S2.Ex4.m1.8.8.1.cmml">−</mo><mrow id="S2.Ex4.m1.8.8.1.1" xref="S2.Ex4.m1.8.8.1.1.cmml"><msub id="S2.Ex4.m1.8.8.1.1.3" xref="S2.Ex4.m1.8.8.1.1.3.cmml"><mi id="S2.Ex4.m1.8.8.1.1.3.2" xref="S2.Ex4.m1.8.8.1.1.3.2.cmml">E</mi><mrow id="S2.Ex4.m1.3.3.3" xref="S2.Ex4.m1.3.3.3.cmml"><mrow id="S2.Ex4.m1.3.3.3.3.2" xref="S2.Ex4.m1.3.3.3.3.3.cmml"><mo id="S2.Ex4.m1.3.3.3.3.2.3" stretchy="false" xref="S2.Ex4.m1.3.3.3.3.3.cmml">(</mo><mi id="S2.Ex4.m1.1.1.1.1" xref="S2.Ex4.m1.1.1.1.1.cmml">x</mi><mo id="S2.Ex4.m1.3.3.3.3.2.4" xref="S2.Ex4.m1.3.3.3.3.3.cmml">,</mo><msub id="S2.Ex4.m1.2.2.2.2.1.1" xref="S2.Ex4.m1.2.2.2.2.1.1.cmml"><mi id="S2.Ex4.m1.2.2.2.2.1.1.2" xref="S2.Ex4.m1.2.2.2.2.1.1.2.cmml">y</mi><mi id="S2.Ex4.m1.2.2.2.2.1.1.3" xref="S2.Ex4.m1.2.2.2.2.1.1.3.cmml">w</mi></msub><mo id="S2.Ex4.m1.3.3.3.3.2.5" xref="S2.Ex4.m1.3.3.3.3.3.cmml">,</mo><msub id="S2.Ex4.m1.3.3.3.3.2.2" xref="S2.Ex4.m1.3.3.3.3.2.2.cmml"><mi id="S2.Ex4.m1.3.3.3.3.2.2.2" xref="S2.Ex4.m1.3.3.3.3.2.2.2.cmml">y</mi><mi id="S2.Ex4.m1.3.3.3.3.2.2.3" xref="S2.Ex4.m1.3.3.3.3.2.2.3.cmml">l</mi></msub><mo id="S2.Ex4.m1.3.3.3.3.2.6" stretchy="false" xref="S2.Ex4.m1.3.3.3.3.3.cmml">)</mo></mrow><mo id="S2.Ex4.m1.3.3.3.4" xref="S2.Ex4.m1.3.3.3.4.cmml">∼</mo><mi id="S2.Ex4.m1.3.3.3.5" xref="S2.Ex4.m1.3.3.3.5.cmml">D</mi></mrow></msub><mo id="S2.Ex4.m1.8.8.1.1.2" xref="S2.Ex4.m1.8.8.1.1.2.cmml">⁢</mo><mrow id="S2.Ex4.m1.8.8.1.1.1.1" xref="S2.Ex4.m1.8.8.1.1.1.2.cmml"><mo id="S2.Ex4.m1.8.8.1.1.1.1.2" xref="S2.Ex4.m1.8.8.1.1.1.2.1.cmml">[</mo><mrow id="S2.Ex4.m1.8.8.1.1.1.1.1" xref="S2.Ex4.m1.8.8.1.1.1.1.1.cmml"><mi id="S2.Ex4.m1.8.8.1.1.1.1.1.3" xref="S2.Ex4.m1.8.8.1.1.1.1.1.3.cmml">l</mi><mo id="S2.Ex4.m1.8.8.1.1.1.1.1.2" xref="S2.Ex4.m1.8.8.1.1.1.1.1.2.cmml">⁢</mo><mi id="S2.Ex4.m1.8.8.1.1.1.1.1.4" xref="S2.Ex4.m1.8.8.1.1.1.1.1.4.cmml">o</mi><mo id="S2.Ex4.m1.8.8.1.1.1.1.1.2a" xref="S2.Ex4.m1.8.8.1.1.1.1.1.2.cmml">⁢</mo><mi id="S2.Ex4.m1.8.8.1.1.1.1.1.5" xref="S2.Ex4.m1.8.8.1.1.1.1.1.5.cmml">g</mi><mo id="S2.Ex4.m1.8.8.1.1.1.1.1.2b" lspace="0.500em" xref="S2.Ex4.m1.8.8.1.1.1.1.1.2.cmml">⁢</mo><mi id="S2.Ex4.m1.8.8.1.1.1.1.1.6" xref="S2.Ex4.m1.8.8.1.1.1.1.1.6.cmml">σ</mi><mo id="S2.Ex4.m1.8.8.1.1.1.1.1.2c" xref="S2.Ex4.m1.8.8.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S2.Ex4.m1.8.8.1.1.1.1.1.1.1" xref="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.cmml"><mo id="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.2" xref="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1" xref="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.cmml"><mrow id="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.1" xref="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.1.3" xref="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.1.3.cmml">r</mi><mo id="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.1.2" xref="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.1.1.1" xref="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.1.1.2.cmml"><mo id="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.1.1.2.cmml">(</mo><mi id="S2.Ex4.m1.6.6" xref="S2.Ex4.m1.6.6.cmml">x</mi><mo id="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.1.1.1.3" xref="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.1.1.2.cmml">,</mo><msub id="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.1.1.1.1" xref="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">y</mi><mi id="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">w</mi></msub><mo id="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.1.1.1.4" stretchy="false" xref="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.3" xref="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.3.cmml">−</mo><mrow id="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.2" xref="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.2.cmml"><mi id="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.2.3" xref="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.2.3.cmml">r</mi><mo id="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.2.2" xref="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.2.2.cmml">⁢</mo><mrow id="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.2.1.1" xref="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.2.1.2.cmml"><mo id="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.2.1.1.2" stretchy="false" xref="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.2.1.2.cmml">(</mo><mi id="S2.Ex4.m1.7.7" xref="S2.Ex4.m1.7.7.cmml">x</mi><mo id="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.2.1.1.3" xref="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.2.1.2.cmml">,</mo><msub id="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.2.1.1.1" xref="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.2.1.1.1.cmml"><mi id="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.2.1.1.1.2" xref="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.2.1.1.1.2.cmml">y</mi><mi id="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.2.1.1.1.3" xref="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.2.1.1.1.3.cmml">l</mi></msub><mo id="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.2.1.1.4" stretchy="false" xref="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.2.1.2.cmml">)</mo></mrow></mrow></mrow><mo id="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.3" xref="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.Ex4.m1.8.8.1.1.1.1.3" xref="S2.Ex4.m1.8.8.1.1.1.2.1.cmml">]</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.Ex4.m1.8b"><apply id="S2.Ex4.m1.8.8.cmml" xref="S2.Ex4.m1.8.8"><eq id="S2.Ex4.m1.8.8.2.cmml" xref="S2.Ex4.m1.8.8.2"></eq><apply id="S2.Ex4.m1.8.8.3.cmml" xref="S2.Ex4.m1.8.8.3"><times id="S2.Ex4.m1.8.8.3.1.cmml" xref="S2.Ex4.m1.8.8.3.1"></times><apply id="S2.Ex4.m1.8.8.3.2.cmml" xref="S2.Ex4.m1.8.8.3.2"><csymbol cd="ambiguous" id="S2.Ex4.m1.8.8.3.2.1.cmml" xref="S2.Ex4.m1.8.8.3.2">subscript</csymbol><ci id="S2.Ex4.m1.8.8.3.2.2.cmml" xref="S2.Ex4.m1.8.8.3.2.2">𝐿</ci><apply id="S2.Ex4.m1.8.8.3.2.3.cmml" xref="S2.Ex4.m1.8.8.3.2.3"><times id="S2.Ex4.m1.8.8.3.2.3.1.cmml" xref="S2.Ex4.m1.8.8.3.2.3.1"></times><ci id="S2.Ex4.m1.8.8.3.2.3.2.cmml" xref="S2.Ex4.m1.8.8.3.2.3.2">𝐵</ci><ci id="S2.Ex4.m1.8.8.3.2.3.3.cmml" xref="S2.Ex4.m1.8.8.3.2.3.3">𝑇</ci></apply></apply><interval closure="open" id="S2.Ex4.m1.8.8.3.3.1.cmml" xref="S2.Ex4.m1.8.8.3.3.2"><ci id="S2.Ex4.m1.4.4.cmml" xref="S2.Ex4.m1.4.4">𝑟</ci><ci id="S2.Ex4.m1.5.5.cmml" xref="S2.Ex4.m1.5.5">𝐷</ci></interval></apply><apply id="S2.Ex4.m1.8.8.1.cmml" xref="S2.Ex4.m1.8.8.1"><minus id="S2.Ex4.m1.8.8.1.2.cmml" xref="S2.Ex4.m1.8.8.1"></minus><apply id="S2.Ex4.m1.8.8.1.1.cmml" xref="S2.Ex4.m1.8.8.1.1"><times id="S2.Ex4.m1.8.8.1.1.2.cmml" xref="S2.Ex4.m1.8.8.1.1.2"></times><apply id="S2.Ex4.m1.8.8.1.1.3.cmml" xref="S2.Ex4.m1.8.8.1.1.3"><csymbol cd="ambiguous" id="S2.Ex4.m1.8.8.1.1.3.1.cmml" xref="S2.Ex4.m1.8.8.1.1.3">subscript</csymbol><ci id="S2.Ex4.m1.8.8.1.1.3.2.cmml" xref="S2.Ex4.m1.8.8.1.1.3.2">𝐸</ci><apply id="S2.Ex4.m1.3.3.3.cmml" xref="S2.Ex4.m1.3.3.3"><csymbol cd="latexml" id="S2.Ex4.m1.3.3.3.4.cmml" xref="S2.Ex4.m1.3.3.3.4">similar-to</csymbol><vector id="S2.Ex4.m1.3.3.3.3.3.cmml" xref="S2.Ex4.m1.3.3.3.3.2"><ci id="S2.Ex4.m1.1.1.1.1.cmml" xref="S2.Ex4.m1.1.1.1.1">𝑥</ci><apply id="S2.Ex4.m1.2.2.2.2.1.1.cmml" xref="S2.Ex4.m1.2.2.2.2.1.1"><csymbol cd="ambiguous" id="S2.Ex4.m1.2.2.2.2.1.1.1.cmml" xref="S2.Ex4.m1.2.2.2.2.1.1">subscript</csymbol><ci id="S2.Ex4.m1.2.2.2.2.1.1.2.cmml" xref="S2.Ex4.m1.2.2.2.2.1.1.2">𝑦</ci><ci id="S2.Ex4.m1.2.2.2.2.1.1.3.cmml" xref="S2.Ex4.m1.2.2.2.2.1.1.3">𝑤</ci></apply><apply id="S2.Ex4.m1.3.3.3.3.2.2.cmml" xref="S2.Ex4.m1.3.3.3.3.2.2"><csymbol cd="ambiguous" id="S2.Ex4.m1.3.3.3.3.2.2.1.cmml" xref="S2.Ex4.m1.3.3.3.3.2.2">subscript</csymbol><ci id="S2.Ex4.m1.3.3.3.3.2.2.2.cmml" xref="S2.Ex4.m1.3.3.3.3.2.2.2">𝑦</ci><ci id="S2.Ex4.m1.3.3.3.3.2.2.3.cmml" xref="S2.Ex4.m1.3.3.3.3.2.2.3">𝑙</ci></apply></vector><ci id="S2.Ex4.m1.3.3.3.5.cmml" xref="S2.Ex4.m1.3.3.3.5">𝐷</ci></apply></apply><apply id="S2.Ex4.m1.8.8.1.1.1.2.cmml" xref="S2.Ex4.m1.8.8.1.1.1.1"><csymbol cd="latexml" id="S2.Ex4.m1.8.8.1.1.1.2.1.cmml" xref="S2.Ex4.m1.8.8.1.1.1.1.2">delimited-[]</csymbol><apply id="S2.Ex4.m1.8.8.1.1.1.1.1.cmml" xref="S2.Ex4.m1.8.8.1.1.1.1.1"><times id="S2.Ex4.m1.8.8.1.1.1.1.1.2.cmml" xref="S2.Ex4.m1.8.8.1.1.1.1.1.2"></times><ci id="S2.Ex4.m1.8.8.1.1.1.1.1.3.cmml" xref="S2.Ex4.m1.8.8.1.1.1.1.1.3">𝑙</ci><ci id="S2.Ex4.m1.8.8.1.1.1.1.1.4.cmml" xref="S2.Ex4.m1.8.8.1.1.1.1.1.4">𝑜</ci><ci id="S2.Ex4.m1.8.8.1.1.1.1.1.5.cmml" xref="S2.Ex4.m1.8.8.1.1.1.1.1.5">𝑔</ci><ci id="S2.Ex4.m1.8.8.1.1.1.1.1.6.cmml" xref="S2.Ex4.m1.8.8.1.1.1.1.1.6">𝜎</ci><apply id="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.cmml" xref="S2.Ex4.m1.8.8.1.1.1.1.1.1.1"><minus id="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.3.cmml" xref="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.3"></minus><apply id="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.1.cmml" xref="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.1"><times id="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.1.2"></times><ci id="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.1.3">𝑟</ci><interval closure="open" id="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.1.1.1"><ci id="S2.Ex4.m1.6.6.cmml" xref="S2.Ex4.m1.6.6">𝑥</ci><apply id="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.1.1.1.1.2">𝑦</ci><ci id="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.1.1.1.1.3">𝑤</ci></apply></interval></apply><apply id="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.2.cmml" xref="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.2"><times id="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.2.2.cmml" xref="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.2.2"></times><ci id="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.2.3.cmml" xref="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.2.3">𝑟</ci><interval closure="open" id="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.2.1.2.cmml" xref="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.2.1.1"><ci id="S2.Ex4.m1.7.7.cmml" xref="S2.Ex4.m1.7.7">𝑥</ci><apply id="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.2.1.1.1.cmml" xref="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.2.1.1.1"><csymbol cd="ambiguous" id="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.2.1.1.1.1.cmml" xref="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.2.1.1.1">subscript</csymbol><ci id="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.2.1.1.1.2.cmml" xref="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.2.1.1.1.2">𝑦</ci><ci id="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.2.1.1.1.3.cmml" xref="S2.Ex4.m1.8.8.1.1.1.1.1.1.1.1.2.1.1.1.3">𝑙</ci></apply></interval></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex4.m1.8c">L_{BT}(r,D)=-E_{(x,y_{w},y_{l})\sim D}\left[log\ \sigma\left(r(x,y_{w})-r(x,y_%
{l})\right)\right]</annotation><annotation encoding="application/x-llamapun" id="S2.Ex4.m1.8d">italic_L start_POSTSUBSCRIPT italic_B italic_T end_POSTSUBSCRIPT ( italic_r , italic_D ) = - italic_E start_POSTSUBSCRIPT ( italic_x , italic_y start_POSTSUBSCRIPT italic_w end_POSTSUBSCRIPT , italic_y start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT ) ∼ italic_D end_POSTSUBSCRIPT [ italic_l italic_o italic_g italic_σ ( italic_r ( italic_x , italic_y start_POSTSUBSCRIPT italic_w end_POSTSUBSCRIPT ) - italic_r ( italic_x , italic_y start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT ) ) ]</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S2.SS4.p1.2">, and the RLHF objective: 
<br class="ltx_break"/></p>
<table class="ltx_equation ltx_eqn_table" id="S2.Ex5">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\smash{\displaystyle\max_{\pi}}\ E_{x\sim D,y\sim\pi}[r(x,y)]-\beta D_{KL}[\pi%
(y|x)||\pi_{ref}(y|x)]." class="ltx_math_unparsed" display="block" id="S2.Ex5.m1.4"><semantics id="S2.Ex5.m1.4a"><mrow id="S2.Ex5.m1.4b"><munder id="S2.Ex5.m1.4.5"><mi id="S2.Ex5.m1.4.5.2">max</mi><mi id="S2.Ex5.m1.4.5.3">π</mi></munder><msub id="S2.Ex5.m1.4.6"><mi id="S2.Ex5.m1.4.6.2">E</mi><mrow id="S2.Ex5.m1.2.2.2.2"><mrow id="S2.Ex5.m1.1.1.1.1.1"><mi id="S2.Ex5.m1.1.1.1.1.1.2">x</mi><mo id="S2.Ex5.m1.1.1.1.1.1.1">∼</mo><mi id="S2.Ex5.m1.1.1.1.1.1.3">D</mi></mrow><mo id="S2.Ex5.m1.2.2.2.2.3">,</mo><mrow id="S2.Ex5.m1.2.2.2.2.2"><mi id="S2.Ex5.m1.2.2.2.2.2.2">y</mi><mo id="S2.Ex5.m1.2.2.2.2.2.1">∼</mo><mi id="S2.Ex5.m1.2.2.2.2.2.3">π</mi></mrow></mrow></msub><mrow id="S2.Ex5.m1.4.7"><mo id="S2.Ex5.m1.4.7.1" stretchy="false">[</mo><mi id="S2.Ex5.m1.4.7.2">r</mi><mrow id="S2.Ex5.m1.4.7.3"><mo id="S2.Ex5.m1.4.7.3.1" stretchy="false">(</mo><mi id="S2.Ex5.m1.3.3">x</mi><mo id="S2.Ex5.m1.4.7.3.2">,</mo><mi id="S2.Ex5.m1.4.4">y</mi><mo id="S2.Ex5.m1.4.7.3.3" stretchy="false">)</mo></mrow><mo id="S2.Ex5.m1.4.7.4" stretchy="false">]</mo></mrow><mo id="S2.Ex5.m1.4.8">−</mo><mi id="S2.Ex5.m1.4.9">β</mi><msub id="S2.Ex5.m1.4.10"><mi id="S2.Ex5.m1.4.10.2">D</mi><mrow id="S2.Ex5.m1.4.10.3"><mi id="S2.Ex5.m1.4.10.3.2">K</mi><mo id="S2.Ex5.m1.4.10.3.1">⁢</mo><mi id="S2.Ex5.m1.4.10.3.3">L</mi></mrow></msub><mrow id="S2.Ex5.m1.4.11"><mo id="S2.Ex5.m1.4.11.1" stretchy="false">[</mo><mi id="S2.Ex5.m1.4.11.2">π</mi><mrow id="S2.Ex5.m1.4.11.3"><mo id="S2.Ex5.m1.4.11.3.1" stretchy="false">(</mo><mi id="S2.Ex5.m1.4.11.3.2">y</mi><mo fence="false" id="S2.Ex5.m1.4.11.3.3" rspace="0.167em" stretchy="false">|</mo><mi id="S2.Ex5.m1.4.11.3.4">x</mi><mo id="S2.Ex5.m1.4.11.3.5" stretchy="false">)</mo></mrow><mo fence="false" id="S2.Ex5.m1.4.11.4" rspace="0.167em" stretchy="false">|</mo><mo fence="false" id="S2.Ex5.m1.4.11.5" rspace="0.167em" stretchy="false">|</mo><msub id="S2.Ex5.m1.4.11.6"><mi id="S2.Ex5.m1.4.11.6.2">π</mi><mrow id="S2.Ex5.m1.4.11.6.3"><mi id="S2.Ex5.m1.4.11.6.3.2">r</mi><mo id="S2.Ex5.m1.4.11.6.3.1">⁢</mo><mi id="S2.Ex5.m1.4.11.6.3.3">e</mi><mo id="S2.Ex5.m1.4.11.6.3.1a">⁢</mo><mi id="S2.Ex5.m1.4.11.6.3.4">f</mi></mrow></msub><mrow id="S2.Ex5.m1.4.11.7"><mo id="S2.Ex5.m1.4.11.7.1" stretchy="false">(</mo><mi id="S2.Ex5.m1.4.11.7.2">y</mi><mo fence="false" id="S2.Ex5.m1.4.11.7.3" rspace="0.167em" stretchy="false">|</mo><mi id="S2.Ex5.m1.4.11.7.4">x</mi><mo id="S2.Ex5.m1.4.11.7.5" stretchy="false">)</mo></mrow><mo id="S2.Ex5.m1.4.11.8" stretchy="false">]</mo></mrow><mo id="S2.Ex5.m1.4.12" lspace="0em">.</mo></mrow><annotation encoding="application/x-tex" id="S2.Ex5.m1.4c">\smash{\displaystyle\max_{\pi}}\ E_{x\sim D,y\sim\pi}[r(x,y)]-\beta D_{KL}[\pi%
(y|x)||\pi_{ref}(y|x)].</annotation><annotation encoding="application/x-llamapun" id="S2.Ex5.m1.4d">roman_max start_POSTSUBSCRIPT italic_π end_POSTSUBSCRIPT italic_E start_POSTSUBSCRIPT italic_x ∼ italic_D , italic_y ∼ italic_π end_POSTSUBSCRIPT [ italic_r ( italic_x , italic_y ) ] - italic_β italic_D start_POSTSUBSCRIPT italic_K italic_L end_POSTSUBSCRIPT [ italic_π ( italic_y | italic_x ) | | italic_π start_POSTSUBSCRIPT italic_r italic_e italic_f end_POSTSUBSCRIPT ( italic_y | italic_x ) ] .</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S2.SS4.p2">
<p class="ltx_p" id="S2.SS4.p2.3">The DPO loss function is:
<br class="ltx_break"/></p>
<table class="ltx_equation ltx_eqn_table" id="S2.Ex6">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\begin{split}L_{DPO}(\pi_{\theta},\pi_{ref})&amp;=-E_{(x,y_{w},y_{l})\sim D}[log\ %
\sigma(\beta log\frac{\pi_{\theta}(y_{w}|x)}{\pi_{ref}(y_{w}|x)}\\
&amp;-\beta log\frac{\pi_{\theta}(y_{l}|x)}{\pi_{ref}(y_{l}|x)})].\end{split}" class="ltx_Math" display="block" id="S2.Ex6.m1.36"><semantics id="S2.Ex6.m1.36a"><mtable columnspacing="0pt" displaystyle="true" id="S2.Ex6.m1.36.36.3" rowspacing="0pt"><mtr id="S2.Ex6.m1.36.36.3a"><mtd class="ltx_align_right" columnalign="right" id="S2.Ex6.m1.36.36.3b"><mrow id="S2.Ex6.m1.36.36.3.35.26.11"><msub id="S2.Ex6.m1.36.36.3.35.26.11.13"><mi id="S2.Ex6.m1.1.1.1.1.1.1" xref="S2.Ex6.m1.1.1.1.1.1.1.cmml">L</mi><mrow id="S2.Ex6.m1.2.2.2.2.2.2.1" xref="S2.Ex6.m1.2.2.2.2.2.2.1.cmml"><mi id="S2.Ex6.m1.2.2.2.2.2.2.1.2" xref="S2.Ex6.m1.2.2.2.2.2.2.1.2.cmml">D</mi><mo id="S2.Ex6.m1.2.2.2.2.2.2.1.1" xref="S2.Ex6.m1.2.2.2.2.2.2.1.1.cmml">⁢</mo><mi id="S2.Ex6.m1.2.2.2.2.2.2.1.3" xref="S2.Ex6.m1.2.2.2.2.2.2.1.3.cmml">P</mi><mo id="S2.Ex6.m1.2.2.2.2.2.2.1.1a" xref="S2.Ex6.m1.2.2.2.2.2.2.1.1.cmml">⁢</mo><mi id="S2.Ex6.m1.2.2.2.2.2.2.1.4" xref="S2.Ex6.m1.2.2.2.2.2.2.1.4.cmml">O</mi></mrow></msub><mo id="S2.Ex6.m1.36.36.3.35.26.11.12" xref="S2.Ex6.m1.34.34.1.1.1.cmml">⁢</mo><mrow id="S2.Ex6.m1.36.36.3.35.26.11.11.2"><mo id="S2.Ex6.m1.3.3.3.3.3.3" stretchy="false" xref="S2.Ex6.m1.34.34.1.1.1.cmml">(</mo><msub id="S2.Ex6.m1.35.35.2.34.25.10.10.1.1"><mi id="S2.Ex6.m1.4.4.4.4.4.4" xref="S2.Ex6.m1.4.4.4.4.4.4.cmml">π</mi><mi id="S2.Ex6.m1.5.5.5.5.5.5.1" xref="S2.Ex6.m1.5.5.5.5.5.5.1.cmml">θ</mi></msub><mo id="S2.Ex6.m1.6.6.6.6.6.6" xref="S2.Ex6.m1.34.34.1.1.1.cmml">,</mo><msub id="S2.Ex6.m1.36.36.3.35.26.11.11.2.2"><mi id="S2.Ex6.m1.7.7.7.7.7.7" xref="S2.Ex6.m1.7.7.7.7.7.7.cmml">π</mi><mrow id="S2.Ex6.m1.8.8.8.8.8.8.1" xref="S2.Ex6.m1.8.8.8.8.8.8.1.cmml"><mi id="S2.Ex6.m1.8.8.8.8.8.8.1.2" xref="S2.Ex6.m1.8.8.8.8.8.8.1.2.cmml">r</mi><mo id="S2.Ex6.m1.8.8.8.8.8.8.1.1" xref="S2.Ex6.m1.8.8.8.8.8.8.1.1.cmml">⁢</mo><mi id="S2.Ex6.m1.8.8.8.8.8.8.1.3" xref="S2.Ex6.m1.8.8.8.8.8.8.1.3.cmml">e</mi><mo id="S2.Ex6.m1.8.8.8.8.8.8.1.1a" xref="S2.Ex6.m1.8.8.8.8.8.8.1.1.cmml">⁢</mo><mi id="S2.Ex6.m1.8.8.8.8.8.8.1.4" xref="S2.Ex6.m1.8.8.8.8.8.8.1.4.cmml">f</mi></mrow></msub><mo id="S2.Ex6.m1.9.9.9.9.9.9" stretchy="false" xref="S2.Ex6.m1.34.34.1.1.1.cmml">)</mo></mrow></mrow></mtd><mtd class="ltx_align_left" columnalign="left" id="S2.Ex6.m1.36.36.3c"><mrow id="S2.Ex6.m1.24.24.24.24.15"><mo id="S2.Ex6.m1.10.10.10.10.1.1" rspace="0em" xref="S2.Ex6.m1.10.10.10.10.1.1.cmml">=</mo><mo id="S2.Ex6.m1.11.11.11.11.2.2" lspace="0em" xref="S2.Ex6.m1.11.11.11.11.2.2.cmml">−</mo><msub id="S2.Ex6.m1.24.24.24.24.15.16"><mi id="S2.Ex6.m1.12.12.12.12.3.3" xref="S2.Ex6.m1.12.12.12.12.3.3.cmml">E</mi><mrow id="S2.Ex6.m1.13.13.13.13.4.4.1" xref="S2.Ex6.m1.13.13.13.13.4.4.1.cmml"><mrow id="S2.Ex6.m1.13.13.13.13.4.4.1.3.2" xref="S2.Ex6.m1.13.13.13.13.4.4.1.3.3.cmml"><mo id="S2.Ex6.m1.13.13.13.13.4.4.1.3.2.3" stretchy="false" xref="S2.Ex6.m1.13.13.13.13.4.4.1.3.3.cmml">(</mo><mi id="S2.Ex6.m1.13.13.13.13.4.4.1.1" xref="S2.Ex6.m1.13.13.13.13.4.4.1.1.cmml">x</mi><mo id="S2.Ex6.m1.13.13.13.13.4.4.1.3.2.4" xref="S2.Ex6.m1.13.13.13.13.4.4.1.3.3.cmml">,</mo><msub id="S2.Ex6.m1.13.13.13.13.4.4.1.2.1.1" xref="S2.Ex6.m1.13.13.13.13.4.4.1.2.1.1.cmml"><mi id="S2.Ex6.m1.13.13.13.13.4.4.1.2.1.1.2" xref="S2.Ex6.m1.13.13.13.13.4.4.1.2.1.1.2.cmml">y</mi><mi id="S2.Ex6.m1.13.13.13.13.4.4.1.2.1.1.3" xref="S2.Ex6.m1.13.13.13.13.4.4.1.2.1.1.3.cmml">w</mi></msub><mo id="S2.Ex6.m1.13.13.13.13.4.4.1.3.2.5" xref="S2.Ex6.m1.13.13.13.13.4.4.1.3.3.cmml">,</mo><msub id="S2.Ex6.m1.13.13.13.13.4.4.1.3.2.2" xref="S2.Ex6.m1.13.13.13.13.4.4.1.3.2.2.cmml"><mi id="S2.Ex6.m1.13.13.13.13.4.4.1.3.2.2.2" xref="S2.Ex6.m1.13.13.13.13.4.4.1.3.2.2.2.cmml">y</mi><mi id="S2.Ex6.m1.13.13.13.13.4.4.1.3.2.2.3" xref="S2.Ex6.m1.13.13.13.13.4.4.1.3.2.2.3.cmml">l</mi></msub><mo id="S2.Ex6.m1.13.13.13.13.4.4.1.3.2.6" stretchy="false" xref="S2.Ex6.m1.13.13.13.13.4.4.1.3.3.cmml">)</mo></mrow><mo id="S2.Ex6.m1.13.13.13.13.4.4.1.4" xref="S2.Ex6.m1.13.13.13.13.4.4.1.4.cmml">∼</mo><mi id="S2.Ex6.m1.13.13.13.13.4.4.1.5" xref="S2.Ex6.m1.13.13.13.13.4.4.1.5.cmml">D</mi></mrow></msub><mrow id="S2.Ex6.m1.24.24.24.24.15.17"><mo id="S2.Ex6.m1.14.14.14.14.5.5" stretchy="false" xref="S2.Ex6.m1.34.34.1.1.1.cmml">[</mo><mi id="S2.Ex6.m1.15.15.15.15.6.6" xref="S2.Ex6.m1.15.15.15.15.6.6.cmml">l</mi><mi id="S2.Ex6.m1.16.16.16.16.7.7" xref="S2.Ex6.m1.16.16.16.16.7.7.cmml">o</mi><mi id="S2.Ex6.m1.17.17.17.17.8.8" xref="S2.Ex6.m1.17.17.17.17.8.8.cmml">g</mi><mi id="S2.Ex6.m1.18.18.18.18.9.9" xref="S2.Ex6.m1.18.18.18.18.9.9.cmml">σ</mi><mrow id="S2.Ex6.m1.24.24.24.24.15.17.1"><mo id="S2.Ex6.m1.19.19.19.19.10.10" stretchy="false" xref="S2.Ex6.m1.34.34.1.1.1.cmml">(</mo><mi id="S2.Ex6.m1.20.20.20.20.11.11" xref="S2.Ex6.m1.20.20.20.20.11.11.cmml">β</mi><mi id="S2.Ex6.m1.21.21.21.21.12.12" xref="S2.Ex6.m1.21.21.21.21.12.12.cmml">l</mi><mi id="S2.Ex6.m1.22.22.22.22.13.13" xref="S2.Ex6.m1.22.22.22.22.13.13.cmml">o</mi><mi id="S2.Ex6.m1.23.23.23.23.14.14" xref="S2.Ex6.m1.23.23.23.23.14.14.cmml">g</mi><mfrac id="S2.Ex6.m1.24.24.24.24.15.15" xref="S2.Ex6.m1.24.24.24.24.15.15.cmml"><mrow id="S2.Ex6.m1.24.24.24.24.15.15.1" xref="S2.Ex6.m1.24.24.24.24.15.15.1.cmml"><msub id="S2.Ex6.m1.24.24.24.24.15.15.1.3" xref="S2.Ex6.m1.24.24.24.24.15.15.1.3.cmml"><mi id="S2.Ex6.m1.24.24.24.24.15.15.1.3.2" xref="S2.Ex6.m1.24.24.24.24.15.15.1.3.2.cmml">π</mi><mi id="S2.Ex6.m1.24.24.24.24.15.15.1.3.3" xref="S2.Ex6.m1.24.24.24.24.15.15.1.3.3.cmml">θ</mi></msub><mo id="S2.Ex6.m1.24.24.24.24.15.15.1.2" xref="S2.Ex6.m1.24.24.24.24.15.15.1.2.cmml">⁢</mo><mrow id="S2.Ex6.m1.24.24.24.24.15.15.1.1.1" xref="S2.Ex6.m1.24.24.24.24.15.15.1.1.1.1.cmml"><mo id="S2.Ex6.m1.24.24.24.24.15.15.1.1.1.2" stretchy="false" xref="S2.Ex6.m1.24.24.24.24.15.15.1.1.1.1.cmml">(</mo><mrow id="S2.Ex6.m1.24.24.24.24.15.15.1.1.1.1" xref="S2.Ex6.m1.24.24.24.24.15.15.1.1.1.1.cmml"><msub id="S2.Ex6.m1.24.24.24.24.15.15.1.1.1.1.2" xref="S2.Ex6.m1.24.24.24.24.15.15.1.1.1.1.2.cmml"><mi id="S2.Ex6.m1.24.24.24.24.15.15.1.1.1.1.2.2" xref="S2.Ex6.m1.24.24.24.24.15.15.1.1.1.1.2.2.cmml">y</mi><mi id="S2.Ex6.m1.24.24.24.24.15.15.1.1.1.1.2.3" xref="S2.Ex6.m1.24.24.24.24.15.15.1.1.1.1.2.3.cmml">w</mi></msub><mo fence="false" id="S2.Ex6.m1.24.24.24.24.15.15.1.1.1.1.1" xref="S2.Ex6.m1.24.24.24.24.15.15.1.1.1.1.1.cmml">|</mo><mi id="S2.Ex6.m1.24.24.24.24.15.15.1.1.1.1.3" xref="S2.Ex6.m1.24.24.24.24.15.15.1.1.1.1.3.cmml">x</mi></mrow><mo id="S2.Ex6.m1.24.24.24.24.15.15.1.1.1.3" stretchy="false" xref="S2.Ex6.m1.24.24.24.24.15.15.1.1.1.1.cmml">)</mo></mrow></mrow><mrow id="S2.Ex6.m1.24.24.24.24.15.15.2" xref="S2.Ex6.m1.24.24.24.24.15.15.2.cmml"><msub id="S2.Ex6.m1.24.24.24.24.15.15.2.3" xref="S2.Ex6.m1.24.24.24.24.15.15.2.3.cmml"><mi id="S2.Ex6.m1.24.24.24.24.15.15.2.3.2" xref="S2.Ex6.m1.24.24.24.24.15.15.2.3.2.cmml">π</mi><mrow id="S2.Ex6.m1.24.24.24.24.15.15.2.3.3" xref="S2.Ex6.m1.24.24.24.24.15.15.2.3.3.cmml"><mi id="S2.Ex6.m1.24.24.24.24.15.15.2.3.3.2" xref="S2.Ex6.m1.24.24.24.24.15.15.2.3.3.2.cmml">r</mi><mo id="S2.Ex6.m1.24.24.24.24.15.15.2.3.3.1" xref="S2.Ex6.m1.24.24.24.24.15.15.2.3.3.1.cmml">⁢</mo><mi id="S2.Ex6.m1.24.24.24.24.15.15.2.3.3.3" xref="S2.Ex6.m1.24.24.24.24.15.15.2.3.3.3.cmml">e</mi><mo id="S2.Ex6.m1.24.24.24.24.15.15.2.3.3.1a" xref="S2.Ex6.m1.24.24.24.24.15.15.2.3.3.1.cmml">⁢</mo><mi id="S2.Ex6.m1.24.24.24.24.15.15.2.3.3.4" xref="S2.Ex6.m1.24.24.24.24.15.15.2.3.3.4.cmml">f</mi></mrow></msub><mo id="S2.Ex6.m1.24.24.24.24.15.15.2.2" xref="S2.Ex6.m1.24.24.24.24.15.15.2.2.cmml">⁢</mo><mrow id="S2.Ex6.m1.24.24.24.24.15.15.2.1.1" xref="S2.Ex6.m1.24.24.24.24.15.15.2.1.1.1.cmml"><mo id="S2.Ex6.m1.24.24.24.24.15.15.2.1.1.2" stretchy="false" xref="S2.Ex6.m1.24.24.24.24.15.15.2.1.1.1.cmml">(</mo><mrow id="S2.Ex6.m1.24.24.24.24.15.15.2.1.1.1" xref="S2.Ex6.m1.24.24.24.24.15.15.2.1.1.1.cmml"><msub id="S2.Ex6.m1.24.24.24.24.15.15.2.1.1.1.2" xref="S2.Ex6.m1.24.24.24.24.15.15.2.1.1.1.2.cmml"><mi id="S2.Ex6.m1.24.24.24.24.15.15.2.1.1.1.2.2" xref="S2.Ex6.m1.24.24.24.24.15.15.2.1.1.1.2.2.cmml">y</mi><mi id="S2.Ex6.m1.24.24.24.24.15.15.2.1.1.1.2.3" xref="S2.Ex6.m1.24.24.24.24.15.15.2.1.1.1.2.3.cmml">w</mi></msub><mo fence="false" id="S2.Ex6.m1.24.24.24.24.15.15.2.1.1.1.1" xref="S2.Ex6.m1.24.24.24.24.15.15.2.1.1.1.1.cmml">|</mo><mi id="S2.Ex6.m1.24.24.24.24.15.15.2.1.1.1.3" xref="S2.Ex6.m1.24.24.24.24.15.15.2.1.1.1.3.cmml">x</mi></mrow><mo id="S2.Ex6.m1.24.24.24.24.15.15.2.1.1.3" stretchy="false" xref="S2.Ex6.m1.24.24.24.24.15.15.2.1.1.1.cmml">)</mo></mrow></mrow></mfrac></mrow></mrow></mrow></mtd></mtr><mtr id="S2.Ex6.m1.36.36.3d"><mtd id="S2.Ex6.m1.36.36.3e" xref="S2.Ex6.m1.34.34.1.1.1.cmml"></mtd><mtd class="ltx_align_left" columnalign="left" id="S2.Ex6.m1.36.36.3f"><mrow id="S2.Ex6.m1.33.33.33.9.9"><mrow id="S2.Ex6.m1.33.33.33.9.9.10"><mo id="S2.Ex6.m1.25.25.25.1.1.1" xref="S2.Ex6.m1.25.25.25.1.1.1.cmml">−</mo><mi id="S2.Ex6.m1.26.26.26.2.2.2" xref="S2.Ex6.m1.26.26.26.2.2.2.cmml">β</mi><mi id="S2.Ex6.m1.27.27.27.3.3.3" xref="S2.Ex6.m1.27.27.27.3.3.3.cmml">l</mi><mi id="S2.Ex6.m1.28.28.28.4.4.4" xref="S2.Ex6.m1.28.28.28.4.4.4.cmml">o</mi><mi id="S2.Ex6.m1.29.29.29.5.5.5" xref="S2.Ex6.m1.29.29.29.5.5.5.cmml">g</mi><mfrac id="S2.Ex6.m1.30.30.30.6.6.6" xref="S2.Ex6.m1.30.30.30.6.6.6.cmml"><mrow id="S2.Ex6.m1.30.30.30.6.6.6.1" xref="S2.Ex6.m1.30.30.30.6.6.6.1.cmml"><msub id="S2.Ex6.m1.30.30.30.6.6.6.1.3" xref="S2.Ex6.m1.30.30.30.6.6.6.1.3.cmml"><mi id="S2.Ex6.m1.30.30.30.6.6.6.1.3.2" xref="S2.Ex6.m1.30.30.30.6.6.6.1.3.2.cmml">π</mi><mi id="S2.Ex6.m1.30.30.30.6.6.6.1.3.3" xref="S2.Ex6.m1.30.30.30.6.6.6.1.3.3.cmml">θ</mi></msub><mo id="S2.Ex6.m1.30.30.30.6.6.6.1.2" xref="S2.Ex6.m1.30.30.30.6.6.6.1.2.cmml">⁢</mo><mrow id="S2.Ex6.m1.30.30.30.6.6.6.1.1.1" xref="S2.Ex6.m1.30.30.30.6.6.6.1.1.1.1.cmml"><mo id="S2.Ex6.m1.30.30.30.6.6.6.1.1.1.2" stretchy="false" xref="S2.Ex6.m1.30.30.30.6.6.6.1.1.1.1.cmml">(</mo><mrow id="S2.Ex6.m1.30.30.30.6.6.6.1.1.1.1" xref="S2.Ex6.m1.30.30.30.6.6.6.1.1.1.1.cmml"><msub id="S2.Ex6.m1.30.30.30.6.6.6.1.1.1.1.2" xref="S2.Ex6.m1.30.30.30.6.6.6.1.1.1.1.2.cmml"><mi id="S2.Ex6.m1.30.30.30.6.6.6.1.1.1.1.2.2" xref="S2.Ex6.m1.30.30.30.6.6.6.1.1.1.1.2.2.cmml">y</mi><mi id="S2.Ex6.m1.30.30.30.6.6.6.1.1.1.1.2.3" xref="S2.Ex6.m1.30.30.30.6.6.6.1.1.1.1.2.3.cmml">l</mi></msub><mo fence="false" id="S2.Ex6.m1.30.30.30.6.6.6.1.1.1.1.1" xref="S2.Ex6.m1.30.30.30.6.6.6.1.1.1.1.1.cmml">|</mo><mi id="S2.Ex6.m1.30.30.30.6.6.6.1.1.1.1.3" xref="S2.Ex6.m1.30.30.30.6.6.6.1.1.1.1.3.cmml">x</mi></mrow><mo id="S2.Ex6.m1.30.30.30.6.6.6.1.1.1.3" stretchy="false" xref="S2.Ex6.m1.30.30.30.6.6.6.1.1.1.1.cmml">)</mo></mrow></mrow><mrow id="S2.Ex6.m1.30.30.30.6.6.6.2" xref="S2.Ex6.m1.30.30.30.6.6.6.2.cmml"><msub id="S2.Ex6.m1.30.30.30.6.6.6.2.3" xref="S2.Ex6.m1.30.30.30.6.6.6.2.3.cmml"><mi id="S2.Ex6.m1.30.30.30.6.6.6.2.3.2" xref="S2.Ex6.m1.30.30.30.6.6.6.2.3.2.cmml">π</mi><mrow id="S2.Ex6.m1.30.30.30.6.6.6.2.3.3" xref="S2.Ex6.m1.30.30.30.6.6.6.2.3.3.cmml"><mi id="S2.Ex6.m1.30.30.30.6.6.6.2.3.3.2" xref="S2.Ex6.m1.30.30.30.6.6.6.2.3.3.2.cmml">r</mi><mo id="S2.Ex6.m1.30.30.30.6.6.6.2.3.3.1" xref="S2.Ex6.m1.30.30.30.6.6.6.2.3.3.1.cmml">⁢</mo><mi id="S2.Ex6.m1.30.30.30.6.6.6.2.3.3.3" xref="S2.Ex6.m1.30.30.30.6.6.6.2.3.3.3.cmml">e</mi><mo id="S2.Ex6.m1.30.30.30.6.6.6.2.3.3.1a" xref="S2.Ex6.m1.30.30.30.6.6.6.2.3.3.1.cmml">⁢</mo><mi id="S2.Ex6.m1.30.30.30.6.6.6.2.3.3.4" xref="S2.Ex6.m1.30.30.30.6.6.6.2.3.3.4.cmml">f</mi></mrow></msub><mo id="S2.Ex6.m1.30.30.30.6.6.6.2.2" xref="S2.Ex6.m1.30.30.30.6.6.6.2.2.cmml">⁢</mo><mrow id="S2.Ex6.m1.30.30.30.6.6.6.2.1.1" xref="S2.Ex6.m1.30.30.30.6.6.6.2.1.1.1.cmml"><mo id="S2.Ex6.m1.30.30.30.6.6.6.2.1.1.2" stretchy="false" xref="S2.Ex6.m1.30.30.30.6.6.6.2.1.1.1.cmml">(</mo><mrow id="S2.Ex6.m1.30.30.30.6.6.6.2.1.1.1" xref="S2.Ex6.m1.30.30.30.6.6.6.2.1.1.1.cmml"><msub id="S2.Ex6.m1.30.30.30.6.6.6.2.1.1.1.2" xref="S2.Ex6.m1.30.30.30.6.6.6.2.1.1.1.2.cmml"><mi id="S2.Ex6.m1.30.30.30.6.6.6.2.1.1.1.2.2" xref="S2.Ex6.m1.30.30.30.6.6.6.2.1.1.1.2.2.cmml">y</mi><mi id="S2.Ex6.m1.30.30.30.6.6.6.2.1.1.1.2.3" xref="S2.Ex6.m1.30.30.30.6.6.6.2.1.1.1.2.3.cmml">l</mi></msub><mo fence="false" id="S2.Ex6.m1.30.30.30.6.6.6.2.1.1.1.1" xref="S2.Ex6.m1.30.30.30.6.6.6.2.1.1.1.1.cmml">|</mo><mi id="S2.Ex6.m1.30.30.30.6.6.6.2.1.1.1.3" xref="S2.Ex6.m1.30.30.30.6.6.6.2.1.1.1.3.cmml">x</mi></mrow><mo id="S2.Ex6.m1.30.30.30.6.6.6.2.1.1.3" stretchy="false" xref="S2.Ex6.m1.30.30.30.6.6.6.2.1.1.1.cmml">)</mo></mrow></mrow></mfrac><mo id="S2.Ex6.m1.31.31.31.7.7.7" stretchy="false" xref="S2.Ex6.m1.34.34.1.1.1.cmml">)</mo></mrow><mo id="S2.Ex6.m1.32.32.32.8.8.8" stretchy="false" xref="S2.Ex6.m1.34.34.1.1.1.cmml">]</mo><mo id="S2.Ex6.m1.33.33.33.9.9.9" lspace="0em" xref="S2.Ex6.m1.34.34.1.1.1.cmml">.</mo></mrow></mtd></mtr></mtable><annotation-xml encoding="MathML-Content" id="S2.Ex6.m1.36b"><apply id="S2.Ex6.m1.34.34.1.1.1.cmml" xref="S2.Ex6.m1.36.36.3.35.26.11.12"><eq id="S2.Ex6.m1.10.10.10.10.1.1.cmml" xref="S2.Ex6.m1.10.10.10.10.1.1"></eq><apply id="S2.Ex6.m1.34.34.1.1.1.2.cmml" xref="S2.Ex6.m1.36.36.3.35.26.11.12"><times id="S2.Ex6.m1.34.34.1.1.1.2.3.cmml" xref="S2.Ex6.m1.36.36.3.35.26.11.12"></times><apply id="S2.Ex6.m1.34.34.1.1.1.2.4.cmml" xref="S2.Ex6.m1.36.36.3.35.26.11.12"><csymbol cd="ambiguous" id="S2.Ex6.m1.34.34.1.1.1.2.4.1.cmml" xref="S2.Ex6.m1.36.36.3.35.26.11.12">subscript</csymbol><ci id="S2.Ex6.m1.1.1.1.1.1.1.cmml" xref="S2.Ex6.m1.1.1.1.1.1.1">𝐿</ci><apply id="S2.Ex6.m1.2.2.2.2.2.2.1.cmml" xref="S2.Ex6.m1.2.2.2.2.2.2.1"><times id="S2.Ex6.m1.2.2.2.2.2.2.1.1.cmml" xref="S2.Ex6.m1.2.2.2.2.2.2.1.1"></times><ci id="S2.Ex6.m1.2.2.2.2.2.2.1.2.cmml" xref="S2.Ex6.m1.2.2.2.2.2.2.1.2">𝐷</ci><ci id="S2.Ex6.m1.2.2.2.2.2.2.1.3.cmml" xref="S2.Ex6.m1.2.2.2.2.2.2.1.3">𝑃</ci><ci id="S2.Ex6.m1.2.2.2.2.2.2.1.4.cmml" xref="S2.Ex6.m1.2.2.2.2.2.2.1.4">𝑂</ci></apply></apply><interval closure="open" id="S2.Ex6.m1.34.34.1.1.1.2.2.3.cmml" xref="S2.Ex6.m1.36.36.3.35.26.11.12"><apply id="S2.Ex6.m1.34.34.1.1.1.1.1.1.1.cmml" xref="S2.Ex6.m1.36.36.3.35.26.11.12"><csymbol cd="ambiguous" id="S2.Ex6.m1.34.34.1.1.1.1.1.1.1.1.cmml" xref="S2.Ex6.m1.36.36.3.35.26.11.12">subscript</csymbol><ci id="S2.Ex6.m1.4.4.4.4.4.4.cmml" xref="S2.Ex6.m1.4.4.4.4.4.4">𝜋</ci><ci id="S2.Ex6.m1.5.5.5.5.5.5.1.cmml" xref="S2.Ex6.m1.5.5.5.5.5.5.1">𝜃</ci></apply><apply id="S2.Ex6.m1.34.34.1.1.1.2.2.2.2.cmml" xref="S2.Ex6.m1.36.36.3.35.26.11.12"><csymbol cd="ambiguous" id="S2.Ex6.m1.34.34.1.1.1.2.2.2.2.1.cmml" xref="S2.Ex6.m1.36.36.3.35.26.11.12">subscript</csymbol><ci id="S2.Ex6.m1.7.7.7.7.7.7.cmml" xref="S2.Ex6.m1.7.7.7.7.7.7">𝜋</ci><apply id="S2.Ex6.m1.8.8.8.8.8.8.1.cmml" xref="S2.Ex6.m1.8.8.8.8.8.8.1"><times id="S2.Ex6.m1.8.8.8.8.8.8.1.1.cmml" xref="S2.Ex6.m1.8.8.8.8.8.8.1.1"></times><ci id="S2.Ex6.m1.8.8.8.8.8.8.1.2.cmml" xref="S2.Ex6.m1.8.8.8.8.8.8.1.2">𝑟</ci><ci id="S2.Ex6.m1.8.8.8.8.8.8.1.3.cmml" xref="S2.Ex6.m1.8.8.8.8.8.8.1.3">𝑒</ci><ci id="S2.Ex6.m1.8.8.8.8.8.8.1.4.cmml" xref="S2.Ex6.m1.8.8.8.8.8.8.1.4">𝑓</ci></apply></apply></interval></apply><apply id="S2.Ex6.m1.34.34.1.1.1.3.cmml" xref="S2.Ex6.m1.36.36.3.35.26.11.12"><minus id="S2.Ex6.m1.11.11.11.11.2.2.cmml" xref="S2.Ex6.m1.11.11.11.11.2.2"></minus><apply id="S2.Ex6.m1.34.34.1.1.1.3.1.cmml" xref="S2.Ex6.m1.36.36.3.35.26.11.12"><times id="S2.Ex6.m1.34.34.1.1.1.3.1.2.cmml" xref="S2.Ex6.m1.36.36.3.35.26.11.12"></times><apply id="S2.Ex6.m1.34.34.1.1.1.3.1.3.cmml" xref="S2.Ex6.m1.36.36.3.35.26.11.12"><csymbol cd="ambiguous" id="S2.Ex6.m1.34.34.1.1.1.3.1.3.1.cmml" xref="S2.Ex6.m1.36.36.3.35.26.11.12">subscript</csymbol><ci id="S2.Ex6.m1.12.12.12.12.3.3.cmml" xref="S2.Ex6.m1.12.12.12.12.3.3">𝐸</ci><apply id="S2.Ex6.m1.13.13.13.13.4.4.1.cmml" xref="S2.Ex6.m1.13.13.13.13.4.4.1"><csymbol cd="latexml" id="S2.Ex6.m1.13.13.13.13.4.4.1.4.cmml" xref="S2.Ex6.m1.13.13.13.13.4.4.1.4">similar-to</csymbol><vector id="S2.Ex6.m1.13.13.13.13.4.4.1.3.3.cmml" xref="S2.Ex6.m1.13.13.13.13.4.4.1.3.2"><ci id="S2.Ex6.m1.13.13.13.13.4.4.1.1.cmml" xref="S2.Ex6.m1.13.13.13.13.4.4.1.1">𝑥</ci><apply id="S2.Ex6.m1.13.13.13.13.4.4.1.2.1.1.cmml" xref="S2.Ex6.m1.13.13.13.13.4.4.1.2.1.1"><csymbol cd="ambiguous" id="S2.Ex6.m1.13.13.13.13.4.4.1.2.1.1.1.cmml" xref="S2.Ex6.m1.13.13.13.13.4.4.1.2.1.1">subscript</csymbol><ci id="S2.Ex6.m1.13.13.13.13.4.4.1.2.1.1.2.cmml" xref="S2.Ex6.m1.13.13.13.13.4.4.1.2.1.1.2">𝑦</ci><ci id="S2.Ex6.m1.13.13.13.13.4.4.1.2.1.1.3.cmml" xref="S2.Ex6.m1.13.13.13.13.4.4.1.2.1.1.3">𝑤</ci></apply><apply id="S2.Ex6.m1.13.13.13.13.4.4.1.3.2.2.cmml" xref="S2.Ex6.m1.13.13.13.13.4.4.1.3.2.2"><csymbol cd="ambiguous" id="S2.Ex6.m1.13.13.13.13.4.4.1.3.2.2.1.cmml" xref="S2.Ex6.m1.13.13.13.13.4.4.1.3.2.2">subscript</csymbol><ci id="S2.Ex6.m1.13.13.13.13.4.4.1.3.2.2.2.cmml" xref="S2.Ex6.m1.13.13.13.13.4.4.1.3.2.2.2">𝑦</ci><ci id="S2.Ex6.m1.13.13.13.13.4.4.1.3.2.2.3.cmml" xref="S2.Ex6.m1.13.13.13.13.4.4.1.3.2.2.3">𝑙</ci></apply></vector><ci id="S2.Ex6.m1.13.13.13.13.4.4.1.5.cmml" xref="S2.Ex6.m1.13.13.13.13.4.4.1.5">𝐷</ci></apply></apply><apply id="S2.Ex6.m1.34.34.1.1.1.3.1.1.2.cmml" xref="S2.Ex6.m1.36.36.3.35.26.11.12"><csymbol cd="latexml" id="S2.Ex6.m1.34.34.1.1.1.3.1.1.2.1.cmml" xref="S2.Ex6.m1.36.36.3.35.26.11.12">delimited-[]</csymbol><apply id="S2.Ex6.m1.34.34.1.1.1.3.1.1.1.1.cmml" xref="S2.Ex6.m1.36.36.3.35.26.11.12"><times id="S2.Ex6.m1.34.34.1.1.1.3.1.1.1.1.2.cmml" xref="S2.Ex6.m1.36.36.3.35.26.11.12"></times><ci id="S2.Ex6.m1.15.15.15.15.6.6.cmml" xref="S2.Ex6.m1.15.15.15.15.6.6">𝑙</ci><ci id="S2.Ex6.m1.16.16.16.16.7.7.cmml" xref="S2.Ex6.m1.16.16.16.16.7.7">𝑜</ci><ci id="S2.Ex6.m1.17.17.17.17.8.8.cmml" xref="S2.Ex6.m1.17.17.17.17.8.8">𝑔</ci><ci id="S2.Ex6.m1.18.18.18.18.9.9.cmml" xref="S2.Ex6.m1.18.18.18.18.9.9">𝜎</ci><apply id="S2.Ex6.m1.34.34.1.1.1.3.1.1.1.1.1.1.1.cmml" xref="S2.Ex6.m1.36.36.3.35.26.11.12"><minus id="S2.Ex6.m1.25.25.25.1.1.1.cmml" xref="S2.Ex6.m1.25.25.25.1.1.1"></minus><apply id="S2.Ex6.m1.34.34.1.1.1.3.1.1.1.1.1.1.1.2.cmml" xref="S2.Ex6.m1.36.36.3.35.26.11.12"><times id="S2.Ex6.m1.34.34.1.1.1.3.1.1.1.1.1.1.1.2.1.cmml" xref="S2.Ex6.m1.36.36.3.35.26.11.12"></times><ci id="S2.Ex6.m1.20.20.20.20.11.11.cmml" xref="S2.Ex6.m1.20.20.20.20.11.11">𝛽</ci><ci id="S2.Ex6.m1.21.21.21.21.12.12.cmml" xref="S2.Ex6.m1.21.21.21.21.12.12">𝑙</ci><ci id="S2.Ex6.m1.22.22.22.22.13.13.cmml" xref="S2.Ex6.m1.22.22.22.22.13.13">𝑜</ci><ci id="S2.Ex6.m1.23.23.23.23.14.14.cmml" xref="S2.Ex6.m1.23.23.23.23.14.14">𝑔</ci><apply id="S2.Ex6.m1.24.24.24.24.15.15.cmml" xref="S2.Ex6.m1.24.24.24.24.15.15"><divide id="S2.Ex6.m1.24.24.24.24.15.15.3.cmml" xref="S2.Ex6.m1.24.24.24.24.15.15"></divide><apply id="S2.Ex6.m1.24.24.24.24.15.15.1.cmml" xref="S2.Ex6.m1.24.24.24.24.15.15.1"><times id="S2.Ex6.m1.24.24.24.24.15.15.1.2.cmml" xref="S2.Ex6.m1.24.24.24.24.15.15.1.2"></times><apply id="S2.Ex6.m1.24.24.24.24.15.15.1.3.cmml" xref="S2.Ex6.m1.24.24.24.24.15.15.1.3"><csymbol cd="ambiguous" id="S2.Ex6.m1.24.24.24.24.15.15.1.3.1.cmml" xref="S2.Ex6.m1.24.24.24.24.15.15.1.3">subscript</csymbol><ci id="S2.Ex6.m1.24.24.24.24.15.15.1.3.2.cmml" xref="S2.Ex6.m1.24.24.24.24.15.15.1.3.2">𝜋</ci><ci id="S2.Ex6.m1.24.24.24.24.15.15.1.3.3.cmml" xref="S2.Ex6.m1.24.24.24.24.15.15.1.3.3">𝜃</ci></apply><apply id="S2.Ex6.m1.24.24.24.24.15.15.1.1.1.1.cmml" xref="S2.Ex6.m1.24.24.24.24.15.15.1.1.1"><csymbol cd="latexml" id="S2.Ex6.m1.24.24.24.24.15.15.1.1.1.1.1.cmml" xref="S2.Ex6.m1.24.24.24.24.15.15.1.1.1.1.1">conditional</csymbol><apply id="S2.Ex6.m1.24.24.24.24.15.15.1.1.1.1.2.cmml" xref="S2.Ex6.m1.24.24.24.24.15.15.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.Ex6.m1.24.24.24.24.15.15.1.1.1.1.2.1.cmml" xref="S2.Ex6.m1.24.24.24.24.15.15.1.1.1.1.2">subscript</csymbol><ci id="S2.Ex6.m1.24.24.24.24.15.15.1.1.1.1.2.2.cmml" xref="S2.Ex6.m1.24.24.24.24.15.15.1.1.1.1.2.2">𝑦</ci><ci id="S2.Ex6.m1.24.24.24.24.15.15.1.1.1.1.2.3.cmml" xref="S2.Ex6.m1.24.24.24.24.15.15.1.1.1.1.2.3">𝑤</ci></apply><ci id="S2.Ex6.m1.24.24.24.24.15.15.1.1.1.1.3.cmml" xref="S2.Ex6.m1.24.24.24.24.15.15.1.1.1.1.3">𝑥</ci></apply></apply><apply id="S2.Ex6.m1.24.24.24.24.15.15.2.cmml" xref="S2.Ex6.m1.24.24.24.24.15.15.2"><times id="S2.Ex6.m1.24.24.24.24.15.15.2.2.cmml" xref="S2.Ex6.m1.24.24.24.24.15.15.2.2"></times><apply id="S2.Ex6.m1.24.24.24.24.15.15.2.3.cmml" xref="S2.Ex6.m1.24.24.24.24.15.15.2.3"><csymbol cd="ambiguous" id="S2.Ex6.m1.24.24.24.24.15.15.2.3.1.cmml" xref="S2.Ex6.m1.24.24.24.24.15.15.2.3">subscript</csymbol><ci id="S2.Ex6.m1.24.24.24.24.15.15.2.3.2.cmml" xref="S2.Ex6.m1.24.24.24.24.15.15.2.3.2">𝜋</ci><apply id="S2.Ex6.m1.24.24.24.24.15.15.2.3.3.cmml" xref="S2.Ex6.m1.24.24.24.24.15.15.2.3.3"><times id="S2.Ex6.m1.24.24.24.24.15.15.2.3.3.1.cmml" xref="S2.Ex6.m1.24.24.24.24.15.15.2.3.3.1"></times><ci id="S2.Ex6.m1.24.24.24.24.15.15.2.3.3.2.cmml" xref="S2.Ex6.m1.24.24.24.24.15.15.2.3.3.2">𝑟</ci><ci id="S2.Ex6.m1.24.24.24.24.15.15.2.3.3.3.cmml" xref="S2.Ex6.m1.24.24.24.24.15.15.2.3.3.3">𝑒</ci><ci id="S2.Ex6.m1.24.24.24.24.15.15.2.3.3.4.cmml" xref="S2.Ex6.m1.24.24.24.24.15.15.2.3.3.4">𝑓</ci></apply></apply><apply id="S2.Ex6.m1.24.24.24.24.15.15.2.1.1.1.cmml" xref="S2.Ex6.m1.24.24.24.24.15.15.2.1.1"><csymbol cd="latexml" id="S2.Ex6.m1.24.24.24.24.15.15.2.1.1.1.1.cmml" xref="S2.Ex6.m1.24.24.24.24.15.15.2.1.1.1.1">conditional</csymbol><apply id="S2.Ex6.m1.24.24.24.24.15.15.2.1.1.1.2.cmml" xref="S2.Ex6.m1.24.24.24.24.15.15.2.1.1.1.2"><csymbol cd="ambiguous" id="S2.Ex6.m1.24.24.24.24.15.15.2.1.1.1.2.1.cmml" xref="S2.Ex6.m1.24.24.24.24.15.15.2.1.1.1.2">subscript</csymbol><ci id="S2.Ex6.m1.24.24.24.24.15.15.2.1.1.1.2.2.cmml" xref="S2.Ex6.m1.24.24.24.24.15.15.2.1.1.1.2.2">𝑦</ci><ci id="S2.Ex6.m1.24.24.24.24.15.15.2.1.1.1.2.3.cmml" xref="S2.Ex6.m1.24.24.24.24.15.15.2.1.1.1.2.3">𝑤</ci></apply><ci id="S2.Ex6.m1.24.24.24.24.15.15.2.1.1.1.3.cmml" xref="S2.Ex6.m1.24.24.24.24.15.15.2.1.1.1.3">𝑥</ci></apply></apply></apply></apply><apply id="S2.Ex6.m1.34.34.1.1.1.3.1.1.1.1.1.1.1.3.cmml" xref="S2.Ex6.m1.36.36.3.35.26.11.12"><times id="S2.Ex6.m1.34.34.1.1.1.3.1.1.1.1.1.1.1.3.1.cmml" xref="S2.Ex6.m1.36.36.3.35.26.11.12"></times><ci id="S2.Ex6.m1.26.26.26.2.2.2.cmml" xref="S2.Ex6.m1.26.26.26.2.2.2">𝛽</ci><ci id="S2.Ex6.m1.27.27.27.3.3.3.cmml" xref="S2.Ex6.m1.27.27.27.3.3.3">𝑙</ci><ci id="S2.Ex6.m1.28.28.28.4.4.4.cmml" xref="S2.Ex6.m1.28.28.28.4.4.4">𝑜</ci><ci id="S2.Ex6.m1.29.29.29.5.5.5.cmml" xref="S2.Ex6.m1.29.29.29.5.5.5">𝑔</ci><apply id="S2.Ex6.m1.30.30.30.6.6.6.cmml" xref="S2.Ex6.m1.30.30.30.6.6.6"><divide id="S2.Ex6.m1.30.30.30.6.6.6.3.cmml" xref="S2.Ex6.m1.30.30.30.6.6.6"></divide><apply id="S2.Ex6.m1.30.30.30.6.6.6.1.cmml" xref="S2.Ex6.m1.30.30.30.6.6.6.1"><times id="S2.Ex6.m1.30.30.30.6.6.6.1.2.cmml" xref="S2.Ex6.m1.30.30.30.6.6.6.1.2"></times><apply id="S2.Ex6.m1.30.30.30.6.6.6.1.3.cmml" xref="S2.Ex6.m1.30.30.30.6.6.6.1.3"><csymbol cd="ambiguous" id="S2.Ex6.m1.30.30.30.6.6.6.1.3.1.cmml" xref="S2.Ex6.m1.30.30.30.6.6.6.1.3">subscript</csymbol><ci id="S2.Ex6.m1.30.30.30.6.6.6.1.3.2.cmml" xref="S2.Ex6.m1.30.30.30.6.6.6.1.3.2">𝜋</ci><ci id="S2.Ex6.m1.30.30.30.6.6.6.1.3.3.cmml" xref="S2.Ex6.m1.30.30.30.6.6.6.1.3.3">𝜃</ci></apply><apply id="S2.Ex6.m1.30.30.30.6.6.6.1.1.1.1.cmml" xref="S2.Ex6.m1.30.30.30.6.6.6.1.1.1"><csymbol cd="latexml" id="S2.Ex6.m1.30.30.30.6.6.6.1.1.1.1.1.cmml" xref="S2.Ex6.m1.30.30.30.6.6.6.1.1.1.1.1">conditional</csymbol><apply id="S2.Ex6.m1.30.30.30.6.6.6.1.1.1.1.2.cmml" xref="S2.Ex6.m1.30.30.30.6.6.6.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.Ex6.m1.30.30.30.6.6.6.1.1.1.1.2.1.cmml" xref="S2.Ex6.m1.30.30.30.6.6.6.1.1.1.1.2">subscript</csymbol><ci id="S2.Ex6.m1.30.30.30.6.6.6.1.1.1.1.2.2.cmml" xref="S2.Ex6.m1.30.30.30.6.6.6.1.1.1.1.2.2">𝑦</ci><ci id="S2.Ex6.m1.30.30.30.6.6.6.1.1.1.1.2.3.cmml" xref="S2.Ex6.m1.30.30.30.6.6.6.1.1.1.1.2.3">𝑙</ci></apply><ci id="S2.Ex6.m1.30.30.30.6.6.6.1.1.1.1.3.cmml" xref="S2.Ex6.m1.30.30.30.6.6.6.1.1.1.1.3">𝑥</ci></apply></apply><apply id="S2.Ex6.m1.30.30.30.6.6.6.2.cmml" xref="S2.Ex6.m1.30.30.30.6.6.6.2"><times id="S2.Ex6.m1.30.30.30.6.6.6.2.2.cmml" xref="S2.Ex6.m1.30.30.30.6.6.6.2.2"></times><apply id="S2.Ex6.m1.30.30.30.6.6.6.2.3.cmml" xref="S2.Ex6.m1.30.30.30.6.6.6.2.3"><csymbol cd="ambiguous" id="S2.Ex6.m1.30.30.30.6.6.6.2.3.1.cmml" xref="S2.Ex6.m1.30.30.30.6.6.6.2.3">subscript</csymbol><ci id="S2.Ex6.m1.30.30.30.6.6.6.2.3.2.cmml" xref="S2.Ex6.m1.30.30.30.6.6.6.2.3.2">𝜋</ci><apply id="S2.Ex6.m1.30.30.30.6.6.6.2.3.3.cmml" xref="S2.Ex6.m1.30.30.30.6.6.6.2.3.3"><times id="S2.Ex6.m1.30.30.30.6.6.6.2.3.3.1.cmml" xref="S2.Ex6.m1.30.30.30.6.6.6.2.3.3.1"></times><ci id="S2.Ex6.m1.30.30.30.6.6.6.2.3.3.2.cmml" xref="S2.Ex6.m1.30.30.30.6.6.6.2.3.3.2">𝑟</ci><ci id="S2.Ex6.m1.30.30.30.6.6.6.2.3.3.3.cmml" xref="S2.Ex6.m1.30.30.30.6.6.6.2.3.3.3">𝑒</ci><ci id="S2.Ex6.m1.30.30.30.6.6.6.2.3.3.4.cmml" xref="S2.Ex6.m1.30.30.30.6.6.6.2.3.3.4">𝑓</ci></apply></apply><apply id="S2.Ex6.m1.30.30.30.6.6.6.2.1.1.1.cmml" xref="S2.Ex6.m1.30.30.30.6.6.6.2.1.1"><csymbol cd="latexml" id="S2.Ex6.m1.30.30.30.6.6.6.2.1.1.1.1.cmml" xref="S2.Ex6.m1.30.30.30.6.6.6.2.1.1.1.1">conditional</csymbol><apply id="S2.Ex6.m1.30.30.30.6.6.6.2.1.1.1.2.cmml" xref="S2.Ex6.m1.30.30.30.6.6.6.2.1.1.1.2"><csymbol cd="ambiguous" id="S2.Ex6.m1.30.30.30.6.6.6.2.1.1.1.2.1.cmml" xref="S2.Ex6.m1.30.30.30.6.6.6.2.1.1.1.2">subscript</csymbol><ci id="S2.Ex6.m1.30.30.30.6.6.6.2.1.1.1.2.2.cmml" xref="S2.Ex6.m1.30.30.30.6.6.6.2.1.1.1.2.2">𝑦</ci><ci id="S2.Ex6.m1.30.30.30.6.6.6.2.1.1.1.2.3.cmml" xref="S2.Ex6.m1.30.30.30.6.6.6.2.1.1.1.2.3">𝑙</ci></apply><ci id="S2.Ex6.m1.30.30.30.6.6.6.2.1.1.1.3.cmml" xref="S2.Ex6.m1.30.30.30.6.6.6.2.1.1.1.3">𝑥</ci></apply></apply></apply></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex6.m1.36c">\begin{split}L_{DPO}(\pi_{\theta},\pi_{ref})&amp;=-E_{(x,y_{w},y_{l})\sim D}[log\ %
\sigma(\beta log\frac{\pi_{\theta}(y_{w}|x)}{\pi_{ref}(y_{w}|x)}\\
&amp;-\beta log\frac{\pi_{\theta}(y_{l}|x)}{\pi_{ref}(y_{l}|x)})].\end{split}</annotation><annotation encoding="application/x-llamapun" id="S2.Ex6.m1.36d">start_ROW start_CELL italic_L start_POSTSUBSCRIPT italic_D italic_P italic_O end_POSTSUBSCRIPT ( italic_π start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT , italic_π start_POSTSUBSCRIPT italic_r italic_e italic_f end_POSTSUBSCRIPT ) end_CELL start_CELL = - italic_E start_POSTSUBSCRIPT ( italic_x , italic_y start_POSTSUBSCRIPT italic_w end_POSTSUBSCRIPT , italic_y start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT ) ∼ italic_D end_POSTSUBSCRIPT [ italic_l italic_o italic_g italic_σ ( italic_β italic_l italic_o italic_g divide start_ARG italic_π start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( italic_y start_POSTSUBSCRIPT italic_w end_POSTSUBSCRIPT | italic_x ) end_ARG start_ARG italic_π start_POSTSUBSCRIPT italic_r italic_e italic_f end_POSTSUBSCRIPT ( italic_y start_POSTSUBSCRIPT italic_w end_POSTSUBSCRIPT | italic_x ) end_ARG end_CELL end_ROW start_ROW start_CELL end_CELL start_CELL - italic_β italic_l italic_o italic_g divide start_ARG italic_π start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( italic_y start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT | italic_x ) end_ARG start_ARG italic_π start_POSTSUBSCRIPT italic_r italic_e italic_f end_POSTSUBSCRIPT ( italic_y start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT | italic_x ) end_ARG ) ] . end_CELL end_ROW</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S2.SS4.p2.2">, where <math alttext="\pi_{\theta}" class="ltx_Math" display="inline" id="S2.SS4.p2.1.m1.1"><semantics id="S2.SS4.p2.1.m1.1a"><msub id="S2.SS4.p2.1.m1.1.1" xref="S2.SS4.p2.1.m1.1.1.cmml"><mi id="S2.SS4.p2.1.m1.1.1.2" xref="S2.SS4.p2.1.m1.1.1.2.cmml">π</mi><mi id="S2.SS4.p2.1.m1.1.1.3" xref="S2.SS4.p2.1.m1.1.1.3.cmml">θ</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS4.p2.1.m1.1b"><apply id="S2.SS4.p2.1.m1.1.1.cmml" xref="S2.SS4.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS4.p2.1.m1.1.1.1.cmml" xref="S2.SS4.p2.1.m1.1.1">subscript</csymbol><ci id="S2.SS4.p2.1.m1.1.1.2.cmml" xref="S2.SS4.p2.1.m1.1.1.2">𝜋</ci><ci id="S2.SS4.p2.1.m1.1.1.3.cmml" xref="S2.SS4.p2.1.m1.1.1.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p2.1.m1.1c">\pi_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p2.1.m1.1d">italic_π start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math> is the DPO policy to learn and <math alttext="\pi_{ref}" class="ltx_Math" display="inline" id="S2.SS4.p2.2.m2.1"><semantics id="S2.SS4.p2.2.m2.1a"><msub id="S2.SS4.p2.2.m2.1.1" xref="S2.SS4.p2.2.m2.1.1.cmml"><mi id="S2.SS4.p2.2.m2.1.1.2" xref="S2.SS4.p2.2.m2.1.1.2.cmml">π</mi><mrow id="S2.SS4.p2.2.m2.1.1.3" xref="S2.SS4.p2.2.m2.1.1.3.cmml"><mi id="S2.SS4.p2.2.m2.1.1.3.2" xref="S2.SS4.p2.2.m2.1.1.3.2.cmml">r</mi><mo id="S2.SS4.p2.2.m2.1.1.3.1" xref="S2.SS4.p2.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S2.SS4.p2.2.m2.1.1.3.3" xref="S2.SS4.p2.2.m2.1.1.3.3.cmml">e</mi><mo id="S2.SS4.p2.2.m2.1.1.3.1a" xref="S2.SS4.p2.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S2.SS4.p2.2.m2.1.1.3.4" xref="S2.SS4.p2.2.m2.1.1.3.4.cmml">f</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SS4.p2.2.m2.1b"><apply id="S2.SS4.p2.2.m2.1.1.cmml" xref="S2.SS4.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS4.p2.2.m2.1.1.1.cmml" xref="S2.SS4.p2.2.m2.1.1">subscript</csymbol><ci id="S2.SS4.p2.2.m2.1.1.2.cmml" xref="S2.SS4.p2.2.m2.1.1.2">𝜋</ci><apply id="S2.SS4.p2.2.m2.1.1.3.cmml" xref="S2.SS4.p2.2.m2.1.1.3"><times id="S2.SS4.p2.2.m2.1.1.3.1.cmml" xref="S2.SS4.p2.2.m2.1.1.3.1"></times><ci id="S2.SS4.p2.2.m2.1.1.3.2.cmml" xref="S2.SS4.p2.2.m2.1.1.3.2">𝑟</ci><ci id="S2.SS4.p2.2.m2.1.1.3.3.cmml" xref="S2.SS4.p2.2.m2.1.1.3.3">𝑒</ci><ci id="S2.SS4.p2.2.m2.1.1.3.4.cmml" xref="S2.SS4.p2.2.m2.1.1.3.4">𝑓</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p2.2.m2.1c">\pi_{ref}</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p2.2.m2.1d">italic_π start_POSTSUBSCRIPT italic_r italic_e italic_f end_POSTSUBSCRIPT</annotation></semantics></math> is the pre-selected reference policy. From the form of the loss function, although DPO does not need a reward model to be trained explicitly, it does require a pre-defined reference policy to iterate upon.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>Approach</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">This report summarizes a few efforts implementing and evaluating PPO
vs. contrast learning using DPO using human trajectories and generated unpreferred trajectories. Then it demonstrates the contrast learning effort using all generative trajectories. 
<br class="ltx_break"/></p>
</div>
<div class="ltx_para" id="S3.p2">
<p class="ltx_p" id="S3.p2.1">We branched and implemented DPO and PPO using the original WebShop code package, together with a new generative module for the self-generative learning experiments, and a Thompson sampling module to roll out online experiments and collect results. 
<br class="ltx_break"/></p>
</div>
<div class="ltx_para" id="S3.p3">
<p class="ltx_p" id="S3.p3.1">For PPO training, the policy gradient objective from the original paper <cite class="ltx_cite ltx_citemacro_citep">(Yao et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.16032v1#bib.bib18" title="">2023</a>)</cite> is modified into a PPO objective as shown in equation (1). The overall objective components, which is the total loss from policy gradient (PG), entropy loss, and imitation learning loss remain the same as in the original paper, except PG component is replaced with PPO loss.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1. </span>Semi-generative Reinforcement Learning Using Human Trajectories</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">For this project, we utilize a pre-trained imitation learning agent checkpoint as the reference policy to generate unpreferred trajectories. Preferred trajectories are obtained from human data provided by the WebShop benchmark. During training, a human trajectory is randomly sampled, including states and available actions from the log. At each state where an action decision is needed, an unpreferred action is generated using the reference policy. This unpreferred action is paired with the preferred action generated by the human. The DPO update is applied after each episode based on the human trajectory.</p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1">This approach is considered both generative and semi-self-learning. It is generative because we use a predefined unpreferred policy to generate actions for pair-wise training. It is semi-self-learning because it pairs these generated actions with previously collected human trajectories, which serve as the gold standard.
<br class="ltx_break"/></p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2. </span>Self-learning - Training with Generated Trajectories</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">In classic reinforcement learning, self-play or learning through simulation plays a crucial role, particularly when data collection is costly, such as the collection of human trajectories in this problem. Self-play has proven to be effective, with the most notable example being AlphaGo <cite class="ltx_cite ltx_citemacro_citep">(Silver et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.16032v1#bib.bib17" title="">2016</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1">To evaluate the idea of self-play or self-learning in navigating the WebShop recommendation systems, we generated 100 preferred trajectories using a straightforward method of sampling trajectories with perfect reward (score = 1). This sampling was done using the agent checkpoint from imitation learning provided by the authors of the WebShop paper, but with real-world human instructions.</p>
</div>
<div class="ltx_para" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.1">Ideally, these sampled trajectories are pruned to eliminate looped sub-trajectories. A DPO agent is then trained from the same checkpoint used for DPO evaluation in the previous section, with 3000 steps. Task performance between these two DPO agents — one trained using semi-learning with human trajectories and the other using self-learning with generated trajectories — is compared using Thompson sampling ran in the WebShop simulator environment.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>Experimental Results</h2>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1. </span>DPO vs. PPO Task Performance</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">In this project, leveraging the WebShop environment and simulator, we conduct extensive simulated online experiments using Thompson sampling to analyze the performance differences across trained agents. The goal of Thompson sampling is to select the optimal action (or ”arm”) that minimizes overall regret. However, when sampling over a small number of steps, it may not be ideal for estimating rewards from arms that are perceived as less optimal due to insufficient exploration. To address this, we use multiple parallel runs of Thompson sampling, each with 1000 rollouts, to capture variability across runs. Careful experimental design and calculated rollouts of online experiments are necessary for accurately estimating the rewards and success rates of each agent. The aim of this project is to implement and understand the performance trends across different approaches.</p>
</div>
<div class="ltx_para" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1">The results indicate that Direct Preference Optimization (DPO) agents achieve significantly higher scores and success rates compared to Proximal Policy Optimization (PPO) agents, even though all agents start from the same imitation learning BERT model checkpoint provided by the original paper. It is important to note that all agents in this comparison are trained without image data, so the scores and success rates collected are not directly comparable to the original paper, which includes image data in training and experiments.</p>
</div>
<div class="ltx_para" id="S4.SS1.p3">
<p class="ltx_p" id="S4.SS1.p3.1">An interesting finding is that DPO agents trained using human trajectories perform similarly to DPO agents trained using generated trajectories, albeit with larger variance in success rate across runs. The smaller variance observed in self-learning agents can be attributed to the fact that only 100 generated trajectories were used to train the DPO self-learning agent, compared to 1200 human trajectories used for training the DPO agent with human data.</p>
</div>
<div class="ltx_para" id="S4.SS1.p4">
<p class="ltx_p" id="S4.SS1.p4.1">The fact that DPO agents are trained using only 3000 steps also suggests the possibility of underestimating data inefficiency or bottleneck when training over long period of times using the same set of data. When training an agent for production systems, the limited number of available trajectories can result in decreased task performance due to insufficient information learned from the limited data. In reality, collecting human data is expensive and time-consuming. This issue can be mitigated by generating preferred and unpreferred trajectories to serve as a continuous, low-cost source of training data.</p>
</div>
<figure class="ltx_figure" id="S4.F3">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 3. </span>DPO vs. PPO — Human Trajectories and Generated Trajectories — Scores</figcaption><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="152" id="S4.F3.g1" src="extracted/5817589/TS_scores.png" width="201"/>
</figure>
<figure class="ltx_figure" id="S4.F4">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 4. </span>DPO vs. PPO — Human Trajectories and Generated Trajectories — Success Rate</figcaption><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="153" id="S4.F4.g1" src="extracted/5817589/TS_sr.png" width="204"/>
</figure>
<div class="ltx_para" id="S4.SS1.p5">
<p class="ltx_p" id="S4.SS1.p5.1">It is important to note that the results of this project are not directly comparable to those of the original paper due to two key differences: 1) no image data were used for training or experiments for any of the agents evaluated in this project, and 2) each agent was trained with minimal steps (3000) and within a timeframe of less than one hour. The purpose of this project is not to benchmark results but to investigate variations in reinforcement learning algorithms.</p>
</div>
<div class="ltx_para" id="S4.SS1.p6">
<p class="ltx_p" id="S4.SS1.p6.1">Training using fully generated preferences on top of the DPO agent achieved much higher scores than DPO agents using human trajectories, while the success rate remained similar (<span class="ltx_text ltx_font_italic" id="S4.SS1.p6.1.1">Figure 5</span>, <span class="ltx_text ltx_font_italic" id="S4.SS1.p6.1.2">Figure 6</span>). The magnitude of this difference needs to be justified using variance across runs, but this finding demonstrates the potential of using generative data to enhance training on top of existing agents initially trained with human trajectories.</p>
</div>
<figure class="ltx_figure" id="S4.F5">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 5. </span>Self-learning Using Generated Trajectories — Scores</figcaption><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="154" id="S4.F5.g1" src="extracted/5817589/TS_generated_traj_scores.png" width="205"/>
</figure>
<figure class="ltx_figure" id="S4.F6">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 6. </span>Self-learning Using Generated Trajectories — Success Rate</figcaption><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="154" id="S4.F6.g1" src="extracted/5817589/TS_generated_traj_sr.png" width="211"/>
</figure>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5. </span>Conclusion</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">With very limited training time (¡1 hour), Direct Preference Optimization (DPO) outperforms Proximal Policy Optimization (PPO), offering better task performance and higher success rates with less training time. However, more evaluations with longer training time are necessary to draw a conclusion. Using a DPO agent trained within one hour and without image data, we achieved a success rate of approximately 19%. This is higher than the success rate of an RL agent trained with an RNN network (without pre-trained models for search or choice imitation learning), which has an 18% success rate from the original paper.
<br class="ltx_break"/></p>
</div>
<div class="ltx_para" id="S5.p2">
<p class="ltx_p" id="S5.p2.1">PPO is known to be able to provide less volatile training and approximately monotonic guarantees for RL objectives. By nature, PPO’s regularization and clipping of objectives prevent rapid policy changes, making it suitable for problems with smaller state and action spaces where large policy changes are not expected. However, in the context of online product recommenders, where the state-action space can expand to millions of dimensions, and rapid policy changes are essential for fast learning, PPO can need longer time to train. 
<br class="ltx_break"/></p>
</div>
<div class="ltx_para" id="S5.p3">
<p class="ltx_p" id="S5.p3.1">Training DPO agents with generated trajectories has shown great potential. With only 100 generated human trajectories and the same amount of computational resources, the task performance was comparable to a DPO agent trained using 1200 human trajectories. This approach addresses data inefficiency and the high costs of human data collection. As training requires more time and data, the limited availability of human data can hinder continuous improvement. This exercise demonstrates that generated trajectories can be nearly as effective as human trajectories and can even serve as a continuous, low-cost source of training data. Additionally, generated trajectories allow exploration of successful paths not seen by humans, similar to the approach that contributed to the success of AlphaGo<cite class="ltx_cite ltx_citemacro_citep">(Silver et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.16032v1#bib.bib17" title="">2016</a>)</cite> and AlphaZero, which were trained using self-play rather than past human games.
<br class="ltx_break"/></p>
</div>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6. </span>Potential Usage: Using Trained Agents as a Recommender</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">Using reinforcement learning agent in recommenders is not new - it is known to be used in online recommenders such as Youtube. The trained optimal policy can become an ideal ranking algorithm for recommender systems. Starting from a human instruction, the agent simulates navigating through a provided list of product following the trained optimal policy and provides a ”purchased” product from each run. When using in recommenders, multiple runs of the agent provide a list of recommended product to user and the order to present in a user interface, such as on web or in an app can be rank-ordered by scores or success for each recommended product from each run of the RL agent.</p>
</div>
<div class="ltx_acknowledgements">
<h6 class="ltx_title ltx_title_acknowledgements">Acknowledgements.</h6>
To the WebShop authors Shunyu Yao, Howard Chen, John Yang and Karthik Narasimhan from Princeton University who published <cite class="ltx_cite ltx_citemacro_citep">(Yao et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.16032v1#bib.bib18" title="">2023</a>)</cite>, which inspired this project report. 
<br class="ltx_break"/>To Professor Chris Potts who has introduced WebShop [17] to the
author of this report, and for his excellent teaching CS224U in
Stanford University. 
<br class="ltx_break"/>To Professor Emma Brunskill for her excellent teaching CS234 in
Stanford University. 
<br class="ltx_break"/>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Adolphs et al<span class="ltx_text" id="bib.bib2.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Leonard Adolphs, Benjamin Börschinger, Christian Buck, Michelle Chen Huebscher, Massimiliano Ciaramita, Lasse Espeholt, Thomas Hofmann, and Yannic Kilcher. 2021.

</span>
<span class="ltx_bibblock">Boosting Search Engines with Interactive Agents.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib2.3.1">CoRR</em> abs/2109.00527 (2021).

</span>
<span class="ltx_bibblock">arXiv:2109.00527

<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2109.00527" title="">https://arxiv.org/abs/2109.00527</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al<span class="ltx_text" id="bib.bib3.2.2.1">.</span> (2018)</span>
<span class="ltx_bibblock">
Minmin Chen, Alex Beutel, Paul Covington, Sagar Jain, Francois Belletti, and Ed H. Chi. 2018.

</span>
<span class="ltx_bibblock">Top-K Off-Policy Correction for a REINFORCE Recommender System.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib3.3.1">CoRR</em> abs/1812.02353 (2018).

</span>
<span class="ltx_bibblock">arXiv:1812.02353

<a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/1812.02353" title="">http://arxiv.org/abs/1812.02353</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Christiano et al<span class="ltx_text" id="bib.bib4.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Paul Christiano, Jan Leike, Tom B. Brown, Miljan Martic, Shane Legg, and Dario Amodei. 2023.

</span>
<span class="ltx_bibblock">Deep reinforcement learning from human preferences.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:1706.03741 [stat.ML]

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Covington et al<span class="ltx_text" id="bib.bib5.2.2.1">.</span> (2016)</span>
<span class="ltx_bibblock">
Paul Covington, Jay Adams, and Emre Sargin. 2016.

</span>
<span class="ltx_bibblock">Deep Neural Networks for YouTube Recommendations. In <em class="ltx_emph ltx_font_italic" id="bib.bib5.3.1">Proceedings of the 10th ACM Conference on Recommender Systems</em> (Boston, Massachusetts, USA) <em class="ltx_emph ltx_font_italic" id="bib.bib5.4.2">(RecSys ’16)</em>. Association for Computing Machinery, New York, NY, USA, 191–198.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/2959100.2959190" title="">https://doi.org/10.1145/2959100.2959190</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Devlin et al<span class="ltx_text" id="bib.bib6.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019.

</span>
<span class="ltx_bibblock">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.

</span>
<span class="ltx_bibblock">(2019).

</span>
<span class="ltx_bibblock">arXiv:1810.04805 [cs.CL]

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Koren et al<span class="ltx_text" id="bib.bib7.2.2.1">.</span> (2009)</span>
<span class="ltx_bibblock">
Yehuda Koren, Robert Bell, and Chris Volinsky. 2009.

</span>
<span class="ltx_bibblock">Matrix Factorization Techniques for Recommender Systems.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib7.3.1">Computer</em> 42, 8 (2009), 30–37.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/MC.2009.263" title="">https://doi.org/10.1109/MC.2009.263</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lewis et al<span class="ltx_text" id="bib.bib8.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, and Luke Zettlemoyer. 2020.

</span>
<span class="ltx_bibblock">BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension. In <em class="ltx_emph ltx_font_italic" id="bib.bib8.3.1">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</em>. Association for Computational Linguistics, Online, 7871–7880.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/v1/2020.acl-main.703" title="">https://doi.org/10.18653/v1/2020.acl-main.703</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin et al<span class="ltx_text" id="bib.bib9.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Jimmy Lin, Xueguang Ma, Sheng-Chieh Lin, Jheng-Hong Yang, Ronak Pradeep, and Rodrigo Frassetto Nogueira. 2021.

</span>
<span class="ltx_bibblock">Pyserini: An Easy-to-Use Python Toolkit to Support Replicable IR Research with Sparse and Dense Representations.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib9.3.1">CoRR</em> abs/2102.10073 (2021).

</span>
<span class="ltx_bibblock">arXiv:2102.10073

<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2102.10073" title="">https://arxiv.org/abs/2102.10073</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nakano et al<span class="ltx_text" id="bib.bib10.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William Saunders, Xu Jiang, Karl Cobbe, Tyna Eloundou, Gretchen Krueger, Kevin Button, Matthew Knight, Benjamin Chess, and John Schulman. 2021.

</span>
<span class="ltx_bibblock">WebGPT: Browser-assisted question-answering with human feedback.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.3.1">CoRR</em> abs/2112.09332 (2021).

</span>
<span class="ltx_bibblock">arXiv:2112.09332

<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2112.09332" title="">https://arxiv.org/abs/2112.09332</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nogueira and Cho (2017)</span>
<span class="ltx_bibblock">
Rodrigo Frassetto Nogueira and Kyunghyun Cho. 2017.

</span>
<span class="ltx_bibblock">Task-Oriented Query Reformulation with Reinforcement Learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">CoRR</em> abs/1704.04572 (2017).

</span>
<span class="ltx_bibblock">arXiv:1704.04572

<a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/1704.04572" title="">http://arxiv.org/abs/1704.04572</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ouyang et al<span class="ltx_text" id="bib.bib12.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul F Christiano, Jan Leike, and Ryan Lowe. 2022.

</span>
<span class="ltx_bibblock">Training language models to follow instructions with human feedback. In <em class="ltx_emph ltx_font_italic" id="bib.bib12.3.1">Advances in Neural Information Processing Systems</em>, S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh (Eds.), Vol. 35. Curran Associates, Inc., 27730–27744.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://proceedings.neurips.cc/paper_files/paper/2022/file/b1efde53be364a73914f58805a001731-Paper-Conference.pdf" title="">https://proceedings.neurips.cc/paper_files/paper/2022/file/b1efde53be364a73914f58805a001731-Paper-Conference.pdf</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rafailov et al<span class="ltx_text" id="bib.bib13.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Rafael Rafailov, Archit Sharma, Eric Mitchell, Stefano Ermon, Christopher D. Manning, and Chelsea Finn. 2023.

</span>
<span class="ltx_bibblock">Direct Preference Optimization: Your Language Model is Secretly a Reward Model.

</span>
<span class="ltx_bibblock">(2023).

</span>
<span class="ltx_bibblock">arXiv:2305.18290 [cs.LG]

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rohde et al<span class="ltx_text" id="bib.bib14.2.2.1">.</span> (2018)</span>
<span class="ltx_bibblock">
David Rohde, Stephen Bonner, Travis Dunlop, Flavian Vasile, and Alexandros Karatzoglou. 2018.

</span>
<span class="ltx_bibblock">RecoGym: A Reinforcement Learning Environment for the problem of Product Recommendation in Online Advertising.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib14.3.1">CoRR</em> abs/1808.00720 (2018).

</span>
<span class="ltx_bibblock">arXiv:1808.00720

<a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/1808.00720" title="">http://arxiv.org/abs/1808.00720</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schulman et al<span class="ltx_text" id="bib.bib15.2.2.1">.</span> (2017)</span>
<span class="ltx_bibblock">
John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov. 2017.

</span>
<span class="ltx_bibblock">Proximal Policy Optimization Algorithms.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib15.3.1">CoRR</em> abs/1707.06347 (2017).

</span>
<span class="ltx_bibblock">arXiv:1707.06347

<a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/1707.06347" title="">http://arxiv.org/abs/1707.06347</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shi et al<span class="ltx_text" id="bib.bib16.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Jing-Cheng Shi, Yang Yu, Qing Da, Shi-Yong Chen, and An-Xiang Zeng. 2019.

</span>
<span class="ltx_bibblock">Virtual-Taobao: Virtualizing Real-World Online Retail Environment for Reinforcement Learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib16.3.1">Proceedings of the AAAI Conference on Artificial Intelligence</em> 33, 01 (Jul. 2019), 4902–4909.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1609/aaai.v33i01.33014902" title="">https://doi.org/10.1609/aaai.v33i01.33014902</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Silver et al<span class="ltx_text" id="bib.bib17.2.2.1">.</span> (2016)</span>
<span class="ltx_bibblock">
David Silver, Aja Huang, Christopher J. Maddison, Arthur Guez, Laurent Sifre, George van den Driessche, Julian Schrittwieser, Ioannis Antonoglou, Veda Panneershelvam, Marc Lanctot, Sander Dieleman, Dominik Grewe, John Nham, Nal Kalchbrenner, Ilya Sutskever, Timothy Lillicrap, Madeleine Leach, Koray Kavukcuoglu, Thore Graepel, and Demis Hassabis. 2016.

</span>
<span class="ltx_bibblock">Mastering the game of Go with deep neural networks and tree search.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib17.3.1">Nature</em> 529 (2016), 484–503.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="http://www.nature.com/nature/journal/v529/n7587/full/nature16961.html" title="">http://www.nature.com/nature/journal/v529/n7587/full/nature16961.html</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yao et al<span class="ltx_text" id="bib.bib18.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Shunyu Yao, Howard Chen, John Yang, and Karthik Narasimhan. 2023.

</span>
<span class="ltx_bibblock">WebShop: Towards Scalable Real-World Web Interaction with Grounded Language Agents.

</span>
<span class="ltx_bibblock">(2023).

</span>
<span class="ltx_bibblock">arXiv:2207.01206 [cs.CL]

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span class="ltx_text" id="bib.bib19.2.2.1">.</span> (2017)</span>
<span class="ltx_bibblock">
Shuai Zhang, Lina Yao, and Aixin Sun. 2017.

</span>
<span class="ltx_bibblock">Deep Learning based Recommender System: A Survey and New Perspectives.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.3.1">CoRR</em> abs/1707.07435 (2017).

</span>
<span class="ltx_bibblock">arXiv:1707.07435

<a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/1707.07435" title="">http://arxiv.org/abs/1707.07435</a>
</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Wed Aug 28 10:29:26 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
