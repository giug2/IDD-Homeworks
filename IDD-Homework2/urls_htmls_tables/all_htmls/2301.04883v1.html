<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2301.04883] SlideVQA: A Dataset for Document Visual Question Answering on Multiple Images</title><meta property="og:description" content="Visual question answering on document images that contain textual, visual, and layout information, called document VQA, has received much attention recently. Although many datasets have been proposed for developing doc…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="SlideVQA: A Dataset for Document Visual Question Answering on Multiple Images">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="SlideVQA: A Dataset for Document Visual Question Answering on Multiple Images">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2301.04883">

<!--Generated on Fri Mar  1 07:29:03 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">SlideVQA: A Dataset for Document Visual Question Answering on Multiple Images</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Anonymous Submission
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Ryota Tanaka,
Kyosuke Nishida,
Kosuke Nishida,
Taku Hasegawa,
Itsumi Saito,
Kuniko Saito
<br class="ltx_break">
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">Visual question answering on document images that contain textual, visual, and layout information, called document VQA, has received much attention recently. Although many datasets have been proposed for developing document VQA systems, most of the existing datasets focus on understanding the content relationships within a single image and not across multiple images. In this study, we propose a new multi-image document VQA dataset, SlideVQA, containing 2.6k+ slide decks composed of 52k+ slide images and 14.5k questions about a slide deck. SlideVQA requires complex reasoning, including single-hop, multi-hop, and numerical reasoning, and also provides annotated arithmetic expressions of numerical answers for enhancing the ability of numerical reasoning. Moreover, we developed a new end-to-end document VQA model that treats evidence selection and question answering in a unified sequence-to-sequence format. Experiments on SlideVQA show that our model outperformed existing state-of-the-art QA models, but that it still has a large gap behind human performance. We believe that our dataset will facilitate research on document VQA.</p>
</div>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Introduction</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">Building intelligent agents that can read and comprehend real-world documents, such as webpages, office documents, lecture slides, etc., has been a long-standing goal of artificial intelligence. To achieve this goal, machine reading comprehension (MRC), a central task in natural language understanding, has been intensively studied.
The typical definition of the MRC task is quite simple, wherein given a short natural language text as a context and a question about it, a machine reads the text and then answers the question by extracting a span from the text <cite class="ltx_cite ltx_citemacro_citep">(Rajpurkar et al. <a href="#bib.bib26" title="" class="ltx_ref">2016</a>; Rajpurkar, Jia, and Liang <a href="#bib.bib25" title="" class="ltx_ref">2018</a>)</cite>. However, this definition is far from real-world applications, such as customer service chatbots on e-commerce websites <cite class="ltx_cite ltx_citemacro_citep">(Cui et al. <a href="#bib.bib4" title="" class="ltx_ref">2017</a>)</cite> and assistant systems for reading professional literature <cite class="ltx_cite ltx_citemacro_citep">(Hong et al. <a href="#bib.bib11" title="" class="ltx_ref">2019</a>)</cite>,
in that the context is composed entirely of text, with no graphical elements.</p>
</div>
<div id="Sx1.p2" class="ltx_para">
<p id="Sx1.p2.1" class="ltx_p">To this end, visual question answering on document images (document VQA) has received much attention. It is a challenging vision and language task that requires methods to reason about document layout, textual content, and visual elements <cite class="ltx_cite ltx_citemacro_citep">(Mathew, Karatzas, and Jawahar <a href="#bib.bib20" title="" class="ltx_ref">2021</a>; Tanaka, Nishida, and Yoshida <a href="#bib.bib35" title="" class="ltx_ref">2021</a>; Mathew et al. <a href="#bib.bib19" title="" class="ltx_ref">2022</a>)</cite>. When the primary content in a document is text (e.g., e-mails and forms)
and the task is to understand it on the basis of its layout information, state-of-the-art models have already achieved
nearly human-level performance <cite class="ltx_cite ltx_citemacro_citep">(Xu et al. <a href="#bib.bib42" title="" class="ltx_ref">2021</a>; Powalski et al. <a href="#bib.bib22" title="" class="ltx_ref">2021</a>)</cite>.
On the other hand, challenges remain when it comes to handling diverse real-world documents.
First and foremost is that current models are not capable of performing reasoning across
multiple images since the existing datasets focus on testing reasoning ability on a single image.
Moreover, compared with humans, document VQA models still have trouble understanding documents that contain visual elements and understanding questions that require numerical reasoning <cite class="ltx_cite ltx_citemacro_citep">(Mathew et al. <a href="#bib.bib19" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
<div id="Sx1.p3" class="ltx_para">
<p id="Sx1.p3.1" class="ltx_p">To address the above challenges, we introduce a new document VQA dataset<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Our dataset and codes are publicly available at <span class="ltx_ref ltx_nolink ltx_url ltx_ref_self">https://github.com/nttmdlab-nlp/SlideVQA</span></span></span></span>, SlideVQA, for tasks wherein given a slide deck composed of multiple
slide images
and a corresponding question, a system selects a set of evidence images and answers the question. Slide decks are one of the most efficient document types that arrange visual and textual elements for communication. As shown in Figure <a href="#Sx1.F1" title="Figure 1 ‣ Introduction ‣ SlideVQA: A Dataset for Document Visual Question Answering on Multiple Images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, SlideVQA requires complex reasoning over slide images, including single-hop, multi-hop, and numerical reasoning. These reasoning skills play essential roles in MRC tasks <cite class="ltx_cite ltx_citemacro_citep">(Yang et al. <a href="#bib.bib43" title="" class="ltx_ref">2018</a>; Dua et al. <a href="#bib.bib6" title="" class="ltx_ref">2019</a>)</cite>.</p>
</div>
<figure id="Sx1.F1" class="ltx_figure"><img src="/html/2301.04883/assets/x1.png" id="Sx1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="532" height="199" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Examples from our SlideVQA dataset. Some questions can be answered through single-hop, multi-hop, and numerical reasoning. The colors of the words match the image borders with the same colors. (<math id="Sx1.F1.2.m1.1" class="ltx_Math" alttext="\cdot" display="inline"><semantics id="Sx1.F1.2.m1.1b"><mo id="Sx1.F1.2.m1.1.1" xref="Sx1.F1.2.m1.1.1.cmml">⋅</mo><annotation-xml encoding="MathML-Content" id="Sx1.F1.2.m1.1c"><ci id="Sx1.F1.2.m1.1.1.cmml" xref="Sx1.F1.2.m1.1.1">⋅</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx1.F1.2.m1.1d">\cdot</annotation></semantics></math>) of the right example in the answer denotes an annotated arithmetic expression to derive the final answer. The slide deck can be viewed at <span class="ltx_ref ltx_nolink ltx_url ltx_ref_self">https://www.slideshare.net/mslgroup/mediainsights-evolving-sources-of-news-for-media</span>.</figcaption>
</figure>
<div id="Sx1.p4" class="ltx_para">
<p id="Sx1.p4.1" class="ltx_p">Our main contributions are summarized as follows:</p>
<ul id="Sx1.I1" class="ltx_itemize">
<li id="Sx1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx1.I1.i1.p1" class="ltx_para">
<p id="Sx1.I1.i1.p1.1" class="ltx_p">We introduce a novel task and dataset,
SlideVQA, wherein to answer its questions, a machine has to read and comprehend a slide deck.
It is the largest multi-image document VQA dataset containing 2.6k+ slide decks (each consisting of 20 slides) and 14.5k questions. It also provides bounding boxes around textual and visual elements for understanding document layout and arithmetic expressions for numerical reasoning.</p>
</div>
</li>
<li id="Sx1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx1.I1.i2.p1" class="ltx_para">
<p id="Sx1.I1.i2.p1.1" class="ltx_p">We developed a
<span id="Sx1.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">M</span>ulti-<span id="Sx1.I1.i2.p1.1.2" class="ltx_text ltx_font_bold">M</span>odal <span id="Sx1.I1.i2.p1.1.3" class="ltx_text ltx_font_bold">M</span>ulti-image <span id="Sx1.I1.i2.p1.1.4" class="ltx_text ltx_font_bold">D</span>ocument VQA model, M3D, to jointly
perform evidence selection and question answering tasks
and to enhance numerical reasoning by generating arithmetic expressions.</p>
</div>
</li>
<li id="Sx1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx1.I1.i3.p1" class="ltx_para">
<p id="Sx1.I1.i3.p1.1" class="ltx_p">Our model outperformed existing state-of-the-art QA models on SlideVQA, but its performance is still below that of humans by a large margin.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="Sx2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Related Work</h2>

<section id="Sx2.SS0.SSSx1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Datasets for VQA on document images.</h4>

<div id="Sx2.SS0.SSSx1.p1" class="ltx_para">
<p id="Sx2.SS0.SSSx1.p1.1" class="ltx_p">Document VQA is the task of answering questions about document images, and
some useful
datasets have been published, such as DocVQA <cite class="ltx_cite ltx_citemacro_citep">(Mathew, Karatzas, and Jawahar <a href="#bib.bib20" title="" class="ltx_ref">2021</a>)</cite>,
VisualMRC <cite class="ltx_cite ltx_citemacro_citep">(Tanaka, Nishida, and Yoshida <a href="#bib.bib35" title="" class="ltx_ref">2021</a>)</cite>,
WebSRC <cite class="ltx_cite ltx_citemacro_citep">(Chen et al. <a href="#bib.bib3" title="" class="ltx_ref">2021</a>)</cite>, and
InfographicVQA <cite class="ltx_cite ltx_citemacro_citep">(Mathew et al. <a href="#bib.bib19" title="" class="ltx_ref">2022</a>)</cite>.
The task assumes that the datasets have a single relevant image, containing all the facts required to answer.</p>
</div>
<div id="Sx2.SS0.SSSx1.p2" class="ltx_para">
<p id="Sx2.SS0.SSSx1.p2.1" class="ltx_p">The work most related to ours is DocCVQA <cite class="ltx_cite ltx_citemacro_citep">(Tito, Karatzas, and Valveny <a href="#bib.bib37" title="" class="ltx_ref">2021</a>)</cite>, wherein a large collection of document images is used to answer a given question. Our dataset differs from DocCVQA, as follows. First, SlideVQA
consists
of 14.5k questions,
wheres DocCVQA provides only 20 questions. Second, SlideVQA requires multi-hop reasoning over multiple slides
to find the answer, while DocCVQA requires only single-hop reasoning on individual images to find the answer.
Besides these differences, SlideVQA provides questions that require numerical reasoning and arithmetic expression annotations to answer numerical questions (e.g., “30 - 28” for the answer “2”): no other VQA dataset, including InfographicVQA that requires numerical reasoning, provides such annotations. Furthermore, SlideVQA provides the largest number of bounding boxes on all of the collected images among the related datasets. </p>
</div>
<figure id="Sx2.T1" class="ltx_table">
<div id="Sx2.T1.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:568.1pt;height:119.6pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-60.3pt,12.6pt) scale(0.825,0.825) ;">
<table id="Sx2.T1.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="Sx2.T1.1.1.1.1" class="ltx_tr">
<th id="Sx2.T1.1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;" rowspan="2"><span id="Sx2.T1.1.1.1.1.1.1" class="ltx_text">Dataset</span></th>
<th id="Sx2.T1.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;">Document</th>
<th id="Sx2.T1.1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;">Multi-images</th>
<th id="Sx2.T1.1.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;">Multi-hop</th>
<th id="Sx2.T1.1.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;">Numerical</th>
<th id="Sx2.T1.1.1.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;">Answer</th>
<th id="Sx2.T1.1.1.1.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;">Document images</th>
<th id="Sx2.T1.1.1.1.1.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;" rowspan="2"><span id="Sx2.T1.1.1.1.1.8.1" class="ltx_text">#QAs</span></th>
<th id="Sx2.T1.1.1.1.1.9" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;" rowspan="2"><span id="Sx2.T1.1.1.1.1.9.1" class="ltx_text">#Images</span></th>
<th id="Sx2.T1.1.1.1.1.10" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;" rowspan="2"><span id="Sx2.T1.1.1.1.1.10.1" class="ltx_text">#BBoxes</span></th>
<th id="Sx2.T1.1.1.1.1.11" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;">#Arithmetic</th>
<th id="Sx2.T1.1.1.1.1.12" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;">#Evidence</th>
</tr>
<tr id="Sx2.T1.1.1.2.2" class="ltx_tr">
<th id="Sx2.T1.1.1.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column" style="padding-left:3.0pt;padding-right:3.0pt;">source</th>
<th id="Sx2.T1.1.1.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column" style="padding-left:3.0pt;padding-right:3.0pt;">input</th>
<th id="Sx2.T1.1.1.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column" style="padding-left:3.0pt;padding-right:3.0pt;">reasoning</th>
<th id="Sx2.T1.1.1.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column" style="padding-left:3.0pt;padding-right:3.0pt;">reasoning</th>
<th id="Sx2.T1.1.1.2.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column" style="padding-left:3.0pt;padding-right:3.0pt;">type</th>
<th id="Sx2.T1.1.1.2.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column" style="padding-left:3.0pt;padding-right:3.0pt;">modal type</th>
<th id="Sx2.T1.1.1.2.2.7" class="ltx_td ltx_align_center ltx_th ltx_th_column" style="padding-left:3.0pt;padding-right:3.0pt;">annotations</th>
<th id="Sx2.T1.1.1.2.2.8" class="ltx_td ltx_align_center ltx_th ltx_th_column" style="padding-left:3.0pt;padding-right:3.0pt;">candidates</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="Sx2.T1.1.1.3.1" class="ltx_tr">
<td id="Sx2.T1.1.1.3.1.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">DocVQA</td>
<td id="Sx2.T1.1.1.3.1.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">industry</td>
<td id="Sx2.T1.1.1.3.1.3" class="ltx_td ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"></td>
<td id="Sx2.T1.1.1.3.1.4" class="ltx_td ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"></td>
<td id="Sx2.T1.1.1.3.1.5" class="ltx_td ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"></td>
<td id="Sx2.T1.1.1.3.1.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">SS</td>
<td id="Sx2.T1.1.1.3.1.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">TL</td>
<td id="Sx2.T1.1.1.3.1.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">50k</td>
<td id="Sx2.T1.1.1.3.1.9" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">12k</td>
<td id="Sx2.T1.1.1.3.1.10" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">–</td>
<td id="Sx2.T1.1.1.3.1.11" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">–</td>
<td id="Sx2.T1.1.1.3.1.12" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">1</td>
</tr>
<tr id="Sx2.T1.1.1.4.2" class="ltx_tr">
<td id="Sx2.T1.1.1.4.2.1" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">VisualMRC</td>
<td id="Sx2.T1.1.1.4.2.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">web-pages</td>
<td id="Sx2.T1.1.1.4.2.3" class="ltx_td" style="padding-left:3.0pt;padding-right:3.0pt;"></td>
<td id="Sx2.T1.1.1.4.2.4" class="ltx_td" style="padding-left:3.0pt;padding-right:3.0pt;"></td>
<td id="Sx2.T1.1.1.4.2.5" class="ltx_td" style="padding-left:3.0pt;padding-right:3.0pt;"></td>
<td id="Sx2.T1.1.1.4.2.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">Ab</td>
<td id="Sx2.T1.1.1.4.2.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">TLV</td>
<td id="Sx2.T1.1.1.4.2.8" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">30k</td>
<td id="Sx2.T1.1.1.4.2.9" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">10k</td>
<td id="Sx2.T1.1.1.4.2.10" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">64k</td>
<td id="Sx2.T1.1.1.4.2.11" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">–</td>
<td id="Sx2.T1.1.1.4.2.12" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">1</td>
</tr>
<tr id="Sx2.T1.1.1.5.3" class="ltx_tr">
<td id="Sx2.T1.1.1.5.3.1" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">WebSRC</td>
<td id="Sx2.T1.1.1.5.3.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">web-pages</td>
<td id="Sx2.T1.1.1.5.3.3" class="ltx_td" style="padding-left:3.0pt;padding-right:3.0pt;"></td>
<td id="Sx2.T1.1.1.5.3.4" class="ltx_td" style="padding-left:3.0pt;padding-right:3.0pt;"></td>
<td id="Sx2.T1.1.1.5.3.5" class="ltx_td" style="padding-left:3.0pt;padding-right:3.0pt;"></td>
<td id="Sx2.T1.1.1.5.3.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">SS</td>
<td id="Sx2.T1.1.1.5.3.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">TLV</td>
<td id="Sx2.T1.1.1.5.3.8" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">400k</td>
<td id="Sx2.T1.1.1.5.3.9" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">6.4k</td>
<td id="Sx2.T1.1.1.5.3.10" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">–</td>
<td id="Sx2.T1.1.1.5.3.11" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">–</td>
<td id="Sx2.T1.1.1.5.3.12" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">1</td>
</tr>
<tr id="Sx2.T1.1.1.6.4" class="ltx_tr">
<td id="Sx2.T1.1.1.6.4.1" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">InfographicVQA</td>
<td id="Sx2.T1.1.1.6.4.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">infographics</td>
<td id="Sx2.T1.1.1.6.4.3" class="ltx_td" style="padding-left:3.0pt;padding-right:3.0pt;"></td>
<td id="Sx2.T1.1.1.6.4.4" class="ltx_td" style="padding-left:3.0pt;padding-right:3.0pt;"></td>
<td id="Sx2.T1.1.1.6.4.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">✓</td>
<td id="Sx2.T1.1.1.6.4.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">SS, MS, NS</td>
<td id="Sx2.T1.1.1.6.4.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">TLV</td>
<td id="Sx2.T1.1.1.6.4.8" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">30k</td>
<td id="Sx2.T1.1.1.6.4.9" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">5k</td>
<td id="Sx2.T1.1.1.6.4.10" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">–</td>
<td id="Sx2.T1.1.1.6.4.11" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">–</td>
<td id="Sx2.T1.1.1.6.4.12" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">1</td>
</tr>
<tr id="Sx2.T1.1.1.7.5" class="ltx_tr">
<td id="Sx2.T1.1.1.7.5.1" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">DocCVQA</td>
<td id="Sx2.T1.1.1.7.5.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">industry</td>
<td id="Sx2.T1.1.1.7.5.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">✓</td>
<td id="Sx2.T1.1.1.7.5.4" class="ltx_td" style="padding-left:3.0pt;padding-right:3.0pt;"></td>
<td id="Sx2.T1.1.1.7.5.5" class="ltx_td" style="padding-left:3.0pt;padding-right:3.0pt;"></td>
<td id="Sx2.T1.1.1.7.5.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">MS</td>
<td id="Sx2.T1.1.1.7.5.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">TL</td>
<td id="Sx2.T1.1.1.7.5.8" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">0.02k</td>
<td id="Sx2.T1.1.1.7.5.9" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">14k</td>
<td id="Sx2.T1.1.1.7.5.10" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">–</td>
<td id="Sx2.T1.1.1.7.5.11" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">–</td>
<td id="Sx2.T1.1.1.7.5.12" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">14k</td>
</tr>
<tr id="Sx2.T1.1.1.8.6" class="ltx_tr">
<td id="Sx2.T1.1.1.8.6.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">SlideVQA (Ours)</td>
<td id="Sx2.T1.1.1.8.6.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">slide decks</td>
<td id="Sx2.T1.1.1.8.6.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">✓</td>
<td id="Sx2.T1.1.1.8.6.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">✓</td>
<td id="Sx2.T1.1.1.8.6.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">✓</td>
<td id="Sx2.T1.1.1.8.6.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">SS, MS, NS</td>
<td id="Sx2.T1.1.1.8.6.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">TLV</td>
<td id="Sx2.T1.1.1.8.6.8" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">14.5k</td>
<td id="Sx2.T1.1.1.8.6.9" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">52k</td>
<td id="Sx2.T1.1.1.8.6.10" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">890k</td>
<td id="Sx2.T1.1.1.8.6.11" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">1.7k</td>
<td id="Sx2.T1.1.1.8.6.12" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">20</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Comparison of question answering datasets on document images. Answer types can be broken down into abstractive (Ab), single-span (SS), multi-span (MS), and non-span (NS). “T/L/V” denotes the “text/layout/visual” modality of images.</figcaption>
</figure>
</section>
<section id="Sx2.SS0.SSSx2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Document VQA Models.</h4>

<div id="Sx2.SS0.SSSx2.p1" class="ltx_para">
<p id="Sx2.SS0.SSSx2.p1.1" class="ltx_p">In parallel with the development of datasets, Transformer <cite class="ltx_cite ltx_citemacro_citep">(Vaswani et al. <a href="#bib.bib39" title="" class="ltx_ref">2017</a>)</cite> has come to be used for understanding unstructured text in document images. LayoutLM <cite class="ltx_cite ltx_citemacro_citep">(Xu et al. <a href="#bib.bib41" title="" class="ltx_ref">2020</a>)</cite>, LayoutLMv2 <cite class="ltx_cite ltx_citemacro_citep">(Xu et al. <a href="#bib.bib42" title="" class="ltx_ref">2021</a>)</cite>, LayoutT5 <cite class="ltx_cite ltx_citemacro_citep">(Tanaka, Nishida, and Yoshida <a href="#bib.bib35" title="" class="ltx_ref">2021</a>)</cite>, and TILT <cite class="ltx_cite ltx_citemacro_citep">(Powalski et al. <a href="#bib.bib22" title="" class="ltx_ref">2021</a>)</cite> have achieved impressive results in single-image document
VQA tasks by combining textual, layout, and visual features. By contrast, we focus on endowing models with the ability to reason and comprehend
multiple images.
Moreover, while <cite class="ltx_cite ltx_citemacro_citet">Tito, Karatzas, and Valveny (<a href="#bib.bib37" title="" class="ltx_ref">2021</a>)</cite> used a pipeline of retrieval and reading models for DocCVQA, we use multi-task learning that jointly performs evidence selection and question answering.</p>
</div>
</section>
<section id="Sx2.SS0.SSSx3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Multi-modal question answering.</h4>

<div id="Sx2.SS0.SSSx3.p1" class="ltx_para">
<p id="Sx2.SS0.SSSx3.p1.1" class="ltx_p">This type takes textual and visual information as input contexts, which is different from document VQA that takes only a document image as the input context.
TQA <cite class="ltx_cite ltx_citemacro_citep">(Kembhavi et al. <a href="#bib.bib13" title="" class="ltx_ref">2017</a>)</cite> is comprised of middle-school science lessons containing diagrams and text.
MultiModalQA <cite class="ltx_cite ltx_citemacro_citep">(Talmor et al. <a href="#bib.bib34" title="" class="ltx_ref">2021</a>)</cite> requires joint reasoning over text, tables, and images in Wikipedia.</p>
</div>
</section>
<section id="Sx2.SS0.SSSx4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">VQA on videos or image sets.</h4>

<div id="Sx2.SS0.SSSx4.p1" class="ltx_para">
<p id="Sx2.SS0.SSSx4.p1.1" class="ltx_p">VideoQA focuses on answering questions about video frames of TV shows <cite class="ltx_cite ltx_citemacro_citep">(Lei et al. <a href="#bib.bib15" title="" class="ltx_ref">2018</a>, <a href="#bib.bib16" title="" class="ltx_ref">2020</a>)</cite> and movies <cite class="ltx_cite ltx_citemacro_citep">(Tapaswi et al. <a href="#bib.bib36" title="" class="ltx_ref">2016</a>)</cite>. A similar task is VQA on image sets (ISVQA), which involves handling photos taken from different viewpoint indoors <cite class="ltx_cite ltx_citemacro_citep">(Bansal, Zhang, and Chellappa <a href="#bib.bib2" title="" class="ltx_ref">2020</a>)</cite>. By contrast, our dataset also requires a model to understand the text in images.</p>
</div>
</section>
<section id="Sx2.SS0.SSSx5" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Slide images understanding.</h4>

<div id="Sx2.SS0.SSSx5.p1" class="ltx_para">
<p id="Sx2.SS0.SSSx5.p1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citet">Monica Haurilet and Stiefelhagen (<a href="#bib.bib21" title="" class="ltx_ref">2019</a>); Haurilet et al. (<a href="#bib.bib9" title="" class="ltx_ref">2019</a>)</cite> introduced a benchmark for object segmentation on slide-pages.
<cite class="ltx_cite ltx_citemacro_citet">Sun et al. (<a href="#bib.bib32" title="" class="ltx_ref">2021</a>); Fu et al. (<a href="#bib.bib7" title="" class="ltx_ref">2022</a>)</cite> tackled the task of generating slides from research papers.
Our work is the first to focus on answering questions on sets of slide images.</p>
</div>
</section>
<section id="Sx2.SS0.SSSx6" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Reasoning over textual documents.</h4>

<div id="Sx2.SS0.SSSx6.p1" class="ltx_para">
<p id="Sx2.SS0.SSSx6.p1.1" class="ltx_p">Numerical reasoning plays an important role in NLP tasks <cite class="ltx_cite ltx_citemacro_citep">(Dua et al. <a href="#bib.bib6" title="" class="ltx_ref">2019</a>; Zhang et al. <a href="#bib.bib46" title="" class="ltx_ref">2020</a>, <a href="#bib.bib45" title="" class="ltx_ref">2021</a>)</cite>. Moreover, multi-hop reasoning has taken the spotlight as it aligns with the multi-hop nature of how humans reason to acquire knowledge, and has led to a proliferation of benchmarks <cite class="ltx_cite ltx_citemacro_citep">(Talmor and Berant <a href="#bib.bib33" title="" class="ltx_ref">2018</a>; Yang et al. <a href="#bib.bib43" title="" class="ltx_ref">2018</a>)</cite>. However, there is as yet no dataset for developing models to perform both multi-hop and numerical reasoning on document images.</p>
</div>
</section>
</section>
<section id="Sx3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">The SlideVQA Task and Dataset</h2>

<section id="Sx3.SSx1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">Task Overview and Formulation</h3>

<div id="Sx3.SSx1.p1" class="ltx_para">
<p id="Sx3.SSx1.p1.5" class="ltx_p">The SlideVQA task, requires a system to answer a question about a slide deck, which is composed of an ordered set of slide images and to select evidence slide images. We formulate the end-to-end SlideVQA task as follows:

<br class="ltx_break"><span id="Sx3.SSx1.p1.5.1" class="ltx_text ltx_font_smallcaps">MainTask</span> (SlideVQA).

Given a question <math id="Sx3.SSx1.p1.1.m1.1" class="ltx_Math" alttext="q" display="inline"><semantics id="Sx3.SSx1.p1.1.m1.1a"><mi id="Sx3.SSx1.p1.1.m1.1.1" xref="Sx3.SSx1.p1.1.m1.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="Sx3.SSx1.p1.1.m1.1b"><ci id="Sx3.SSx1.p1.1.m1.1.1.cmml" xref="Sx3.SSx1.p1.1.m1.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx3.SSx1.p1.1.m1.1c">q</annotation></semantics></math> and a slide deck <math id="Sx3.SSx1.p1.2.m2.3" class="ltx_Math" alttext="\mathbf{I}=\{I_{1},\ldots,I_{K}\}" display="inline"><semantics id="Sx3.SSx1.p1.2.m2.3a"><mrow id="Sx3.SSx1.p1.2.m2.3.3" xref="Sx3.SSx1.p1.2.m2.3.3.cmml"><mi id="Sx3.SSx1.p1.2.m2.3.3.4" xref="Sx3.SSx1.p1.2.m2.3.3.4.cmml">𝐈</mi><mo id="Sx3.SSx1.p1.2.m2.3.3.3" xref="Sx3.SSx1.p1.2.m2.3.3.3.cmml">=</mo><mrow id="Sx3.SSx1.p1.2.m2.3.3.2.2" xref="Sx3.SSx1.p1.2.m2.3.3.2.3.cmml"><mo stretchy="false" id="Sx3.SSx1.p1.2.m2.3.3.2.2.3" xref="Sx3.SSx1.p1.2.m2.3.3.2.3.cmml">{</mo><msub id="Sx3.SSx1.p1.2.m2.2.2.1.1.1" xref="Sx3.SSx1.p1.2.m2.2.2.1.1.1.cmml"><mi id="Sx3.SSx1.p1.2.m2.2.2.1.1.1.2" xref="Sx3.SSx1.p1.2.m2.2.2.1.1.1.2.cmml">I</mi><mn id="Sx3.SSx1.p1.2.m2.2.2.1.1.1.3" xref="Sx3.SSx1.p1.2.m2.2.2.1.1.1.3.cmml">1</mn></msub><mo id="Sx3.SSx1.p1.2.m2.3.3.2.2.4" xref="Sx3.SSx1.p1.2.m2.3.3.2.3.cmml">,</mo><mi mathvariant="normal" id="Sx3.SSx1.p1.2.m2.1.1" xref="Sx3.SSx1.p1.2.m2.1.1.cmml">…</mi><mo id="Sx3.SSx1.p1.2.m2.3.3.2.2.5" xref="Sx3.SSx1.p1.2.m2.3.3.2.3.cmml">,</mo><msub id="Sx3.SSx1.p1.2.m2.3.3.2.2.2" xref="Sx3.SSx1.p1.2.m2.3.3.2.2.2.cmml"><mi id="Sx3.SSx1.p1.2.m2.3.3.2.2.2.2" xref="Sx3.SSx1.p1.2.m2.3.3.2.2.2.2.cmml">I</mi><mi id="Sx3.SSx1.p1.2.m2.3.3.2.2.2.3" xref="Sx3.SSx1.p1.2.m2.3.3.2.2.2.3.cmml">K</mi></msub><mo stretchy="false" id="Sx3.SSx1.p1.2.m2.3.3.2.2.6" xref="Sx3.SSx1.p1.2.m2.3.3.2.3.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="Sx3.SSx1.p1.2.m2.3b"><apply id="Sx3.SSx1.p1.2.m2.3.3.cmml" xref="Sx3.SSx1.p1.2.m2.3.3"><eq id="Sx3.SSx1.p1.2.m2.3.3.3.cmml" xref="Sx3.SSx1.p1.2.m2.3.3.3"></eq><ci id="Sx3.SSx1.p1.2.m2.3.3.4.cmml" xref="Sx3.SSx1.p1.2.m2.3.3.4">𝐈</ci><set id="Sx3.SSx1.p1.2.m2.3.3.2.3.cmml" xref="Sx3.SSx1.p1.2.m2.3.3.2.2"><apply id="Sx3.SSx1.p1.2.m2.2.2.1.1.1.cmml" xref="Sx3.SSx1.p1.2.m2.2.2.1.1.1"><csymbol cd="ambiguous" id="Sx3.SSx1.p1.2.m2.2.2.1.1.1.1.cmml" xref="Sx3.SSx1.p1.2.m2.2.2.1.1.1">subscript</csymbol><ci id="Sx3.SSx1.p1.2.m2.2.2.1.1.1.2.cmml" xref="Sx3.SSx1.p1.2.m2.2.2.1.1.1.2">𝐼</ci><cn type="integer" id="Sx3.SSx1.p1.2.m2.2.2.1.1.1.3.cmml" xref="Sx3.SSx1.p1.2.m2.2.2.1.1.1.3">1</cn></apply><ci id="Sx3.SSx1.p1.2.m2.1.1.cmml" xref="Sx3.SSx1.p1.2.m2.1.1">…</ci><apply id="Sx3.SSx1.p1.2.m2.3.3.2.2.2.cmml" xref="Sx3.SSx1.p1.2.m2.3.3.2.2.2"><csymbol cd="ambiguous" id="Sx3.SSx1.p1.2.m2.3.3.2.2.2.1.cmml" xref="Sx3.SSx1.p1.2.m2.3.3.2.2.2">subscript</csymbol><ci id="Sx3.SSx1.p1.2.m2.3.3.2.2.2.2.cmml" xref="Sx3.SSx1.p1.2.m2.3.3.2.2.2.2">𝐼</ci><ci id="Sx3.SSx1.p1.2.m2.3.3.2.2.2.3.cmml" xref="Sx3.SSx1.p1.2.m2.3.3.2.2.2.3">𝐾</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx3.SSx1.p1.2.m2.3c">\mathbf{I}=\{I_{1},\ldots,I_{K}\}</annotation></semantics></math> (<math id="Sx3.SSx1.p1.3.m3.1" class="ltx_Math" alttext="K=20" display="inline"><semantics id="Sx3.SSx1.p1.3.m3.1a"><mrow id="Sx3.SSx1.p1.3.m3.1.1" xref="Sx3.SSx1.p1.3.m3.1.1.cmml"><mi id="Sx3.SSx1.p1.3.m3.1.1.2" xref="Sx3.SSx1.p1.3.m3.1.1.2.cmml">K</mi><mo id="Sx3.SSx1.p1.3.m3.1.1.1" xref="Sx3.SSx1.p1.3.m3.1.1.1.cmml">=</mo><mn id="Sx3.SSx1.p1.3.m3.1.1.3" xref="Sx3.SSx1.p1.3.m3.1.1.3.cmml">20</mn></mrow><annotation-xml encoding="MathML-Content" id="Sx3.SSx1.p1.3.m3.1b"><apply id="Sx3.SSx1.p1.3.m3.1.1.cmml" xref="Sx3.SSx1.p1.3.m3.1.1"><eq id="Sx3.SSx1.p1.3.m3.1.1.1.cmml" xref="Sx3.SSx1.p1.3.m3.1.1.1"></eq><ci id="Sx3.SSx1.p1.3.m3.1.1.2.cmml" xref="Sx3.SSx1.p1.3.m3.1.1.2">𝐾</ci><cn type="integer" id="Sx3.SSx1.p1.3.m3.1.1.3.cmml" xref="Sx3.SSx1.p1.3.m3.1.1.3">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx3.SSx1.p1.3.m3.1c">K=20</annotation></semantics></math>),
a model outputs an answer <math id="Sx3.SSx1.p1.4.m4.1" class="ltx_Math" alttext="y" display="inline"><semantics id="Sx3.SSx1.p1.4.m4.1a"><mi id="Sx3.SSx1.p1.4.m4.1.1" xref="Sx3.SSx1.p1.4.m4.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="Sx3.SSx1.p1.4.m4.1b"><ci id="Sx3.SSx1.p1.4.m4.1.1.cmml" xref="Sx3.SSx1.p1.4.m4.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx3.SSx1.p1.4.m4.1c">y</annotation></semantics></math> and selects relevant slides <math id="Sx3.SSx1.p1.5.m5.3" class="ltx_Math" alttext="\mathbf{\hat{I}}=\{\hat{I}_{1},\ldots,\hat{I}_{K^{\prime}}\}" display="inline"><semantics id="Sx3.SSx1.p1.5.m5.3a"><mrow id="Sx3.SSx1.p1.5.m5.3.3" xref="Sx3.SSx1.p1.5.m5.3.3.cmml"><mover accent="true" id="Sx3.SSx1.p1.5.m5.3.3.4" xref="Sx3.SSx1.p1.5.m5.3.3.4.cmml"><mi id="Sx3.SSx1.p1.5.m5.3.3.4.2" xref="Sx3.SSx1.p1.5.m5.3.3.4.2.cmml">𝐈</mi><mo id="Sx3.SSx1.p1.5.m5.3.3.4.1" xref="Sx3.SSx1.p1.5.m5.3.3.4.1.cmml">^</mo></mover><mo id="Sx3.SSx1.p1.5.m5.3.3.3" xref="Sx3.SSx1.p1.5.m5.3.3.3.cmml">=</mo><mrow id="Sx3.SSx1.p1.5.m5.3.3.2.2" xref="Sx3.SSx1.p1.5.m5.3.3.2.3.cmml"><mo stretchy="false" id="Sx3.SSx1.p1.5.m5.3.3.2.2.3" xref="Sx3.SSx1.p1.5.m5.3.3.2.3.cmml">{</mo><msub id="Sx3.SSx1.p1.5.m5.2.2.1.1.1" xref="Sx3.SSx1.p1.5.m5.2.2.1.1.1.cmml"><mover accent="true" id="Sx3.SSx1.p1.5.m5.2.2.1.1.1.2" xref="Sx3.SSx1.p1.5.m5.2.2.1.1.1.2.cmml"><mi id="Sx3.SSx1.p1.5.m5.2.2.1.1.1.2.2" xref="Sx3.SSx1.p1.5.m5.2.2.1.1.1.2.2.cmml">I</mi><mo id="Sx3.SSx1.p1.5.m5.2.2.1.1.1.2.1" xref="Sx3.SSx1.p1.5.m5.2.2.1.1.1.2.1.cmml">^</mo></mover><mn id="Sx3.SSx1.p1.5.m5.2.2.1.1.1.3" xref="Sx3.SSx1.p1.5.m5.2.2.1.1.1.3.cmml">1</mn></msub><mo id="Sx3.SSx1.p1.5.m5.3.3.2.2.4" xref="Sx3.SSx1.p1.5.m5.3.3.2.3.cmml">,</mo><mi mathvariant="normal" id="Sx3.SSx1.p1.5.m5.1.1" xref="Sx3.SSx1.p1.5.m5.1.1.cmml">…</mi><mo id="Sx3.SSx1.p1.5.m5.3.3.2.2.5" xref="Sx3.SSx1.p1.5.m5.3.3.2.3.cmml">,</mo><msub id="Sx3.SSx1.p1.5.m5.3.3.2.2.2" xref="Sx3.SSx1.p1.5.m5.3.3.2.2.2.cmml"><mover accent="true" id="Sx3.SSx1.p1.5.m5.3.3.2.2.2.2" xref="Sx3.SSx1.p1.5.m5.3.3.2.2.2.2.cmml"><mi id="Sx3.SSx1.p1.5.m5.3.3.2.2.2.2.2" xref="Sx3.SSx1.p1.5.m5.3.3.2.2.2.2.2.cmml">I</mi><mo id="Sx3.SSx1.p1.5.m5.3.3.2.2.2.2.1" xref="Sx3.SSx1.p1.5.m5.3.3.2.2.2.2.1.cmml">^</mo></mover><msup id="Sx3.SSx1.p1.5.m5.3.3.2.2.2.3" xref="Sx3.SSx1.p1.5.m5.3.3.2.2.2.3.cmml"><mi id="Sx3.SSx1.p1.5.m5.3.3.2.2.2.3.2" xref="Sx3.SSx1.p1.5.m5.3.3.2.2.2.3.2.cmml">K</mi><mo id="Sx3.SSx1.p1.5.m5.3.3.2.2.2.3.3" xref="Sx3.SSx1.p1.5.m5.3.3.2.2.2.3.3.cmml">′</mo></msup></msub><mo stretchy="false" id="Sx3.SSx1.p1.5.m5.3.3.2.2.6" xref="Sx3.SSx1.p1.5.m5.3.3.2.3.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="Sx3.SSx1.p1.5.m5.3b"><apply id="Sx3.SSx1.p1.5.m5.3.3.cmml" xref="Sx3.SSx1.p1.5.m5.3.3"><eq id="Sx3.SSx1.p1.5.m5.3.3.3.cmml" xref="Sx3.SSx1.p1.5.m5.3.3.3"></eq><apply id="Sx3.SSx1.p1.5.m5.3.3.4.cmml" xref="Sx3.SSx1.p1.5.m5.3.3.4"><ci id="Sx3.SSx1.p1.5.m5.3.3.4.1.cmml" xref="Sx3.SSx1.p1.5.m5.3.3.4.1">^</ci><ci id="Sx3.SSx1.p1.5.m5.3.3.4.2.cmml" xref="Sx3.SSx1.p1.5.m5.3.3.4.2">𝐈</ci></apply><set id="Sx3.SSx1.p1.5.m5.3.3.2.3.cmml" xref="Sx3.SSx1.p1.5.m5.3.3.2.2"><apply id="Sx3.SSx1.p1.5.m5.2.2.1.1.1.cmml" xref="Sx3.SSx1.p1.5.m5.2.2.1.1.1"><csymbol cd="ambiguous" id="Sx3.SSx1.p1.5.m5.2.2.1.1.1.1.cmml" xref="Sx3.SSx1.p1.5.m5.2.2.1.1.1">subscript</csymbol><apply id="Sx3.SSx1.p1.5.m5.2.2.1.1.1.2.cmml" xref="Sx3.SSx1.p1.5.m5.2.2.1.1.1.2"><ci id="Sx3.SSx1.p1.5.m5.2.2.1.1.1.2.1.cmml" xref="Sx3.SSx1.p1.5.m5.2.2.1.1.1.2.1">^</ci><ci id="Sx3.SSx1.p1.5.m5.2.2.1.1.1.2.2.cmml" xref="Sx3.SSx1.p1.5.m5.2.2.1.1.1.2.2">𝐼</ci></apply><cn type="integer" id="Sx3.SSx1.p1.5.m5.2.2.1.1.1.3.cmml" xref="Sx3.SSx1.p1.5.m5.2.2.1.1.1.3">1</cn></apply><ci id="Sx3.SSx1.p1.5.m5.1.1.cmml" xref="Sx3.SSx1.p1.5.m5.1.1">…</ci><apply id="Sx3.SSx1.p1.5.m5.3.3.2.2.2.cmml" xref="Sx3.SSx1.p1.5.m5.3.3.2.2.2"><csymbol cd="ambiguous" id="Sx3.SSx1.p1.5.m5.3.3.2.2.2.1.cmml" xref="Sx3.SSx1.p1.5.m5.3.3.2.2.2">subscript</csymbol><apply id="Sx3.SSx1.p1.5.m5.3.3.2.2.2.2.cmml" xref="Sx3.SSx1.p1.5.m5.3.3.2.2.2.2"><ci id="Sx3.SSx1.p1.5.m5.3.3.2.2.2.2.1.cmml" xref="Sx3.SSx1.p1.5.m5.3.3.2.2.2.2.1">^</ci><ci id="Sx3.SSx1.p1.5.m5.3.3.2.2.2.2.2.cmml" xref="Sx3.SSx1.p1.5.m5.3.3.2.2.2.2.2">𝐼</ci></apply><apply id="Sx3.SSx1.p1.5.m5.3.3.2.2.2.3.cmml" xref="Sx3.SSx1.p1.5.m5.3.3.2.2.2.3"><csymbol cd="ambiguous" id="Sx3.SSx1.p1.5.m5.3.3.2.2.2.3.1.cmml" xref="Sx3.SSx1.p1.5.m5.3.3.2.2.2.3">superscript</csymbol><ci id="Sx3.SSx1.p1.5.m5.3.3.2.2.2.3.2.cmml" xref="Sx3.SSx1.p1.5.m5.3.3.2.2.2.3.2">𝐾</ci><ci id="Sx3.SSx1.p1.5.m5.3.3.2.2.2.3.3.cmml" xref="Sx3.SSx1.p1.5.m5.3.3.2.2.2.3.3">′</ci></apply></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx3.SSx1.p1.5.m5.3c">\mathbf{\hat{I}}=\{\hat{I}_{1},\ldots,\hat{I}_{K^{\prime}}\}</annotation></semantics></math>.</p>
</div>
<div id="Sx3.SSx1.p2" class="ltx_para">
<p id="Sx3.SSx1.p2.1" class="ltx_p">The task can be decomposed into two subtasks:</p>
</div>
<div id="Thmsubtask1" class="ltx_theorem ltx_theorem_subtask">
<h6 class="ltx_title ltx_runin ltx_title_theorem">
<span class="ltx_tag ltx_tag_theorem"><span id="Thmsubtask1.1.1.1" class="ltx_text ltx_font_smallcaps">Subtask 1</span></span><span id="Thmsubtask1.2.2" class="ltx_text ltx_font_smallcaps"> </span>(Evidence Selection)<span id="Thmsubtask1.3.3" class="ltx_text ltx_font_smallcaps">. </span>
</h6>
<div id="Thmsubtask1.p1" class="ltx_para">
<p id="Thmsubtask1.p1.4" class="ltx_p">Given a question <math id="Thmsubtask1.p1.1.m1.1" class="ltx_Math" alttext="q" display="inline"><semantics id="Thmsubtask1.p1.1.m1.1a"><mi id="Thmsubtask1.p1.1.m1.1.1" xref="Thmsubtask1.p1.1.m1.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="Thmsubtask1.p1.1.m1.1b"><ci id="Thmsubtask1.p1.1.m1.1.1.cmml" xref="Thmsubtask1.p1.1.m1.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="Thmsubtask1.p1.1.m1.1c">q</annotation></semantics></math> and a slide deck <math id="Thmsubtask1.p1.2.m2.1" class="ltx_Math" alttext="\mathbf{I}" display="inline"><semantics id="Thmsubtask1.p1.2.m2.1a"><mi id="Thmsubtask1.p1.2.m2.1.1" xref="Thmsubtask1.p1.2.m2.1.1.cmml">𝐈</mi><annotation-xml encoding="MathML-Content" id="Thmsubtask1.p1.2.m2.1b"><ci id="Thmsubtask1.p1.2.m2.1.1.cmml" xref="Thmsubtask1.p1.2.m2.1.1">𝐈</ci></annotation-xml><annotation encoding="application/x-tex" id="Thmsubtask1.p1.2.m2.1c">\mathbf{I}</annotation></semantics></math>, a model identifies the images <math id="Thmsubtask1.p1.3.m3.1" class="ltx_Math" alttext="\mathbf{\hat{I}}" display="inline"><semantics id="Thmsubtask1.p1.3.m3.1a"><mover accent="true" id="Thmsubtask1.p1.3.m3.1.1" xref="Thmsubtask1.p1.3.m3.1.1.cmml"><mi id="Thmsubtask1.p1.3.m3.1.1.2" xref="Thmsubtask1.p1.3.m3.1.1.2.cmml">𝐈</mi><mo id="Thmsubtask1.p1.3.m3.1.1.1" xref="Thmsubtask1.p1.3.m3.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="Thmsubtask1.p1.3.m3.1b"><apply id="Thmsubtask1.p1.3.m3.1.1.cmml" xref="Thmsubtask1.p1.3.m3.1.1"><ci id="Thmsubtask1.p1.3.m3.1.1.1.cmml" xref="Thmsubtask1.p1.3.m3.1.1.1">^</ci><ci id="Thmsubtask1.p1.3.m3.1.1.2.cmml" xref="Thmsubtask1.p1.3.m3.1.1.2">𝐈</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Thmsubtask1.p1.3.m3.1c">\mathbf{\hat{I}}</annotation></semantics></math> from which to derive the answer <math id="Thmsubtask1.p1.4.m4.1" class="ltx_Math" alttext="y" display="inline"><semantics id="Thmsubtask1.p1.4.m4.1a"><mi id="Thmsubtask1.p1.4.m4.1.1" xref="Thmsubtask1.p1.4.m4.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="Thmsubtask1.p1.4.m4.1b"><ci id="Thmsubtask1.p1.4.m4.1.1.cmml" xref="Thmsubtask1.p1.4.m4.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="Thmsubtask1.p1.4.m4.1c">y</annotation></semantics></math>.</p>
</div>
</div>
<div id="Thmsubtask2" class="ltx_theorem ltx_theorem_subtask">
<h6 class="ltx_title ltx_runin ltx_title_theorem">
<span class="ltx_tag ltx_tag_theorem"><span id="Thmsubtask2.1.1.1" class="ltx_text ltx_font_smallcaps">Subtask 2</span></span><span id="Thmsubtask2.2.2" class="ltx_text ltx_font_smallcaps"> </span>(Question Answering)<span id="Thmsubtask2.3.3" class="ltx_text ltx_font_smallcaps">. </span>
</h6>
<div id="Thmsubtask2.p1" class="ltx_para">
<p id="Thmsubtask2.p1.4" class="ltx_p">Given a question <math id="Thmsubtask2.p1.1.m1.1" class="ltx_Math" alttext="q" display="inline"><semantics id="Thmsubtask2.p1.1.m1.1a"><mi id="Thmsubtask2.p1.1.m1.1.1" xref="Thmsubtask2.p1.1.m1.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="Thmsubtask2.p1.1.m1.1b"><ci id="Thmsubtask2.p1.1.m1.1.1.cmml" xref="Thmsubtask2.p1.1.m1.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="Thmsubtask2.p1.1.m1.1c">q</annotation></semantics></math> and
the slide images (<math id="Thmsubtask2.p1.2.m2.1" class="ltx_Math" alttext="\mathbf{I}" display="inline"><semantics id="Thmsubtask2.p1.2.m2.1a"><mi id="Thmsubtask2.p1.2.m2.1.1" xref="Thmsubtask2.p1.2.m2.1.1.cmml">𝐈</mi><annotation-xml encoding="MathML-Content" id="Thmsubtask2.p1.2.m2.1b"><ci id="Thmsubtask2.p1.2.m2.1.1.cmml" xref="Thmsubtask2.p1.2.m2.1.1">𝐈</ci></annotation-xml><annotation encoding="application/x-tex" id="Thmsubtask2.p1.2.m2.1c">\mathbf{I}</annotation></semantics></math> or <math id="Thmsubtask2.p1.3.m3.1" class="ltx_Math" alttext="\mathbf{\hat{I}}" display="inline"><semantics id="Thmsubtask2.p1.3.m3.1a"><mover accent="true" id="Thmsubtask2.p1.3.m3.1.1" xref="Thmsubtask2.p1.3.m3.1.1.cmml"><mi id="Thmsubtask2.p1.3.m3.1.1.2" xref="Thmsubtask2.p1.3.m3.1.1.2.cmml">𝐈</mi><mo id="Thmsubtask2.p1.3.m3.1.1.1" xref="Thmsubtask2.p1.3.m3.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="Thmsubtask2.p1.3.m3.1b"><apply id="Thmsubtask2.p1.3.m3.1.1.cmml" xref="Thmsubtask2.p1.3.m3.1.1"><ci id="Thmsubtask2.p1.3.m3.1.1.1.cmml" xref="Thmsubtask2.p1.3.m3.1.1.1">^</ci><ci id="Thmsubtask2.p1.3.m3.1.1.2.cmml" xref="Thmsubtask2.p1.3.m3.1.1.2">𝐈</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Thmsubtask2.p1.3.m3.1c">\mathbf{\hat{I}}</annotation></semantics></math>),
a model outputs an answer <math id="Thmsubtask2.p1.4.m4.1" class="ltx_Math" alttext="y" display="inline"><semantics id="Thmsubtask2.p1.4.m4.1a"><mi id="Thmsubtask2.p1.4.m4.1.1" xref="Thmsubtask2.p1.4.m4.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="Thmsubtask2.p1.4.m4.1b"><ci id="Thmsubtask2.p1.4.m4.1.1.cmml" xref="Thmsubtask2.p1.4.m4.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="Thmsubtask2.p1.4.m4.1c">y</annotation></semantics></math>.</p>
</div>
</div>
<div id="Sx3.SSx1.p3" class="ltx_para">
<p id="Sx3.SSx1.p3.1" class="ltx_p">SlideVQA has three answer types (see the examples in Figure <a href="#Sx1.F1" title="Figure 1 ‣ Introduction ‣ SlideVQA: A Dataset for Document Visual Question Answering on Multiple Images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>). A single-span answer is a contiguous sequence of tokens in the reading order extracted from the image, and a multi-span answer is formed from multiple spans from the image. A non-span answer is not extracted and is composed of numerical values and visual appearances.</p>
</div>
<div id="Sx3.SSx1.p4" class="ltx_para">
<p id="Sx3.SSx1.p4.1" class="ltx_p">We can also use annotations of bounding boxes around the objects (and their categories) to understand the semantic structure of images and annotations of arithmetic expressions to understand numerical reasoning as additional input at training. These annotations are not given at inference.</p>
</div>
</section>
<section id="Sx3.SSx2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">Dataset Collection</h3>

<div id="Sx3.SSx2.p1" class="ltx_para">
<p id="Sx3.SSx2.p1.1" class="ltx_p">In this section, we describe the collection process of the SlideVQA dataset. To control the annotation quality, we recruited crowd workers located in English-speaking countries and who had passed a rigorous qualification procedure. Additionally, we asked other workers to assess the quality of the annotated samples after each collection step.</p>
</div>
<section id="Sx3.SSx2.SSSx1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Slide decks collection.</h4>

<div id="Sx3.SSx2.SSSx1.p1" class="ltx_para">
<p id="Sx3.SSx2.SSSx1.p1.1" class="ltx_p">First, we selected and downloaded
25,327 slide decks composed of more than 20 slides from slideshare<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><span class="ltx_ref ltx_nolink ltx_url ltx_ref_self">https://www.slideshare.net/</span></span></span></span>
and covering 39 topics. We kept the first 20 slides and truncated the rest of the pages. Then, the workers filtered the collected decks that did not meet the following criteria: (i) the main language is English; (ii) the content is easy for workers to understand; (iii) the decks must contain one or more graphs, tables, figures, or numerical data to avoid creating questions requiring only text-level understanding.</p>
</div>
</section>
<section id="Sx3.SSx2.SSSx2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Bounding boxes and categories annotation.</h4>

<figure id="Sx3.F2" class="ltx_figure"><img src="/html/2301.04883/assets/x2.png" id="Sx3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="183" height="137" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Example of collected bounding boxes. Colored boxes and words were annotated by workers. The image can be viewed at <span class="ltx_ref ltx_nolink ltx_url ltx_ref_self">https://www.slideshare.net/andrybrewok/big-data-analytics-a-social-network-approach</span>.</figcaption>
</figure>
<div id="Sx3.SSx2.SSSx2.p1" class="ltx_para">
<p id="Sx3.SSx2.SSSx2.p1.1" class="ltx_p">To facilitate understanding of the semantic components of images, we annotated all images with bounding boxes and their categories. The workers indicated specific objects in each image by annotating bounding boxes around the objects and classifying them into nine classes that were based on SPaSe <cite class="ltx_cite ltx_citemacro_citep">(Monica Haurilet and Stiefelhagen <a href="#bib.bib21" title="" class="ltx_ref">2019</a>)</cite> as follows:</p>
</div>
<div id="Sx3.SSx2.SSSx2.p2" class="ltx_para">
<ul id="Sx3.I2" class="ltx_itemize">
<li id="Sx3.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx3.I2.i1.p1" class="ltx_para">
<p id="Sx3.I2.i1.p1.1" class="ltx_p"><span id="Sx3.I2.i1.p1.1.1" class="ltx_text ltx_font_bold">Title</span>: presentation title, slide title</p>
</div>
</li>
<li id="Sx3.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx3.I2.i2.p1" class="ltx_para">
<p id="Sx3.I2.i2.p1.1" class="ltx_p"><span id="Sx3.I2.i2.p1.1.1" class="ltx_text ltx_font_bold">Page-text</span>: text in slide, bullet-point text list, text list</p>
</div>
</li>
<li id="Sx3.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx3.I2.i3.p1" class="ltx_para">
<p id="Sx3.I2.i3.p1.1" class="ltx_p"><span id="Sx3.I2.i3.p1.1.1" class="ltx_text ltx_font_bold">Obj-text</span>: text in a figure, image, diagram or table</p>
</div>
</li>
<li id="Sx3.I2.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx3.I2.i4.p1" class="ltx_para">
<p id="Sx3.I2.i4.p1.1" class="ltx_p"><span id="Sx3.I2.i4.p1.1.1" class="ltx_text ltx_font_bold">Caption</span>: description of figure, image, diagram, or table</p>
</div>
</li>
<li id="Sx3.I2.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx3.I2.i5.p1" class="ltx_para">
<p id="Sx3.I2.i5.p1.1" class="ltx_p"><span id="Sx3.I2.i5.p1.1.1" class="ltx_text ltx_font_bold">Other-text</span>: footnote, date, affiliation, code, URL</p>
</div>
</li>
<li id="Sx3.I2.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx3.I2.i6.p1" class="ltx_para">
<p id="Sx3.I2.i6.p1.1" class="ltx_p"><span id="Sx3.I2.i6.p1.1.1" class="ltx_text ltx_font_bold">Diagram</span>: a graphical representation of data, a process</p>
</div>
</li>
<li id="Sx3.I2.i7" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx3.I2.i7.p1" class="ltx_para">
<p id="Sx3.I2.i7.p1.1" class="ltx_p"><span id="Sx3.I2.i7.p1.1.1" class="ltx_text ltx_font_bold">Table</span>: data arranged in rows and columns</p>
</div>
</li>
<li id="Sx3.I2.i8" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx3.I2.i8.p1" class="ltx_para">
<p id="Sx3.I2.i8.p1.1" class="ltx_p"><span id="Sx3.I2.i8.p1.1.1" class="ltx_text ltx_font_bold">Image</span>: drawing, logo, map, screenshot, realistic image</p>
</div>
</li>
<li id="Sx3.I2.i9" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx3.I2.i9.p1" class="ltx_para">
<p id="Sx3.I2.i9.p1.1" class="ltx_p"><span id="Sx3.I2.i9.p1.1.1" class="ltx_text ltx_font_bold">Figure</span>: graph with data points and coordinates</p>
</div>
</li>
</ul>
<p id="Sx3.SSx2.SSSx2.p2.1" class="ltx_p">As shown in Figure <a href="#Sx3.F2" title="Figure 2 ‣ Bounding boxes and categories annotation. ‣ Dataset Collection ‣ The SlideVQA Task and Dataset ‣ SlideVQA: A Dataset for Document Visual Question Answering on Multiple Images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, SlideVQA provides densely annotated bounding boxes in images.</p>
</div>
<figure id="Sx3.F3" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="Sx3.F3.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2301.04883/assets/x3.png" id="Sx3.F3.sf1.g1" class="ltx_graphics ltx_img_square" width="118" height="98" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>Bounding box categories.</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="Sx3.F3.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2301.04883/assets/x4.png" id="Sx3.F3.sf2.g1" class="ltx_graphics ltx_img_square" width="118" height="98" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>Reasoning types.</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="Sx3.F3.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2301.04883/assets/x5.png" id="Sx3.F3.sf3.g1" class="ltx_graphics ltx_img_square" width="118" height="98" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(c) </span>Numerical operation types.</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="Sx3.F3.sf4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2301.04883/assets/x6.png" id="Sx3.F3.sf4.g1" class="ltx_graphics ltx_img_square" width="118" height="98" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(d) </span>Answer types.</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Distribution of bounding box categories, reasoning types, numerical operations, and answer types in the test set.</figcaption>
</figure>
</section>
<section id="Sx3.SSx2.SSSx3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Single-hop QA creation.</h4>

<div id="Sx3.SSx2.SSSx3.p1" class="ltx_para">
<p id="Sx3.SSx2.SSSx3.p1.1" class="ltx_p">We asked the workers to create 12,466 QA pairs by selecting a single slide
image from a slide deck. The selected slide can be used as evidence to tell whether a system arrived at the right answer for the right reasons.
We encouraged questions that needed numerical reasoning, including operations of arithmetic expressions with <math id="Sx3.SSx2.SSSx3.p1.1.m1.4" class="ltx_Math" alttext="\{+,-,/,*\}" display="inline"><semantics id="Sx3.SSx2.SSSx3.p1.1.m1.4a"><mrow id="Sx3.SSx2.SSSx3.p1.1.m1.4.5.2" xref="Sx3.SSx2.SSSx3.p1.1.m1.4.5.1.cmml"><mo stretchy="false" id="Sx3.SSx2.SSSx3.p1.1.m1.4.5.2.1" xref="Sx3.SSx2.SSSx3.p1.1.m1.4.5.1.cmml">{</mo><mo lspace="0em" rspace="0em" id="Sx3.SSx2.SSSx3.p1.1.m1.1.1" xref="Sx3.SSx2.SSSx3.p1.1.m1.1.1.cmml">+</mo><mo rspace="0em" id="Sx3.SSx2.SSSx3.p1.1.m1.4.5.2.2" xref="Sx3.SSx2.SSSx3.p1.1.m1.4.5.1.cmml">,</mo><mo lspace="0em" rspace="0em" id="Sx3.SSx2.SSSx3.p1.1.m1.2.2" xref="Sx3.SSx2.SSSx3.p1.1.m1.2.2.cmml">−</mo><mo rspace="0em" id="Sx3.SSx2.SSSx3.p1.1.m1.4.5.2.3" xref="Sx3.SSx2.SSSx3.p1.1.m1.4.5.1.cmml">,</mo><mo lspace="0em" rspace="0em" id="Sx3.SSx2.SSSx3.p1.1.m1.3.3" xref="Sx3.SSx2.SSSx3.p1.1.m1.3.3.cmml">/</mo><mo rspace="0em" id="Sx3.SSx2.SSSx3.p1.1.m1.4.5.2.4" xref="Sx3.SSx2.SSSx3.p1.1.m1.4.5.1.cmml">,</mo><mo lspace="0em" rspace="0em" id="Sx3.SSx2.SSSx3.p1.1.m1.4.4" xref="Sx3.SSx2.SSSx3.p1.1.m1.4.4.cmml">∗</mo><mo stretchy="false" id="Sx3.SSx2.SSSx3.p1.1.m1.4.5.2.5" xref="Sx3.SSx2.SSSx3.p1.1.m1.4.5.1.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="Sx3.SSx2.SSSx3.p1.1.m1.4b"><set id="Sx3.SSx2.SSSx3.p1.1.m1.4.5.1.cmml" xref="Sx3.SSx2.SSSx3.p1.1.m1.4.5.2"><plus id="Sx3.SSx2.SSSx3.p1.1.m1.1.1.cmml" xref="Sx3.SSx2.SSSx3.p1.1.m1.1.1"></plus><minus id="Sx3.SSx2.SSSx3.p1.1.m1.2.2.cmml" xref="Sx3.SSx2.SSSx3.p1.1.m1.2.2"></minus><divide id="Sx3.SSx2.SSSx3.p1.1.m1.3.3.cmml" xref="Sx3.SSx2.SSSx3.p1.1.m1.3.3"></divide><times id="Sx3.SSx2.SSSx3.p1.1.m1.4.4.cmml" xref="Sx3.SSx2.SSSx3.p1.1.m1.4.4"></times></set></annotation-xml><annotation encoding="application/x-tex" id="Sx3.SSx2.SSSx3.p1.1.m1.4c">\{+,-,/,*\}</annotation></semantics></math>, counting, and comparisons. Additionally, the workers avoided creating questions that (i) contained selected page numbers; (ii) required external knowledge; (iii) were common to all of the slides (e.g., “What is the title?”).</p>
</div>
</section>
<section id="Sx3.SSx2.SSSx4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Multi-hop questions creation.</h4>

<div id="Sx3.SSx2.SSSx4.p1" class="ltx_para">
<p id="Sx3.SSx2.SSSx4.p1.1" class="ltx_p">We created 2,018 QA pairs for multi-hop reasoning by editing the single-hop questions created in the previous step.
For example at the left of Figure <a href="#Sx1.F1" title="Figure 1 ‣ Introduction ‣ SlideVQA: A Dataset for Document Visual Question Answering on Multiple Images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, “North” is replaced by the phrase “the region with 70% of journals”. To this end, we first identified one or two bridge entities
in the created questions, and the workers selected related slides as evidence that mentioned the identified ones. Then, the content of the selected slides was utilized to replace the entities in the created questions. The process of creating multi-hop questions by editing may produce unnatural questions, as mentioned in the “Limitations” section, but is easily scalable. A similar approach was taken with MultiModalQA <cite class="ltx_cite ltx_citemacro_citep">(Talmor et al. <a href="#bib.bib34" title="" class="ltx_ref">2021</a>)</cite>, which requires multi-hop reasoning over text, tables, and images in Wikipedia.</p>
</div>
</section>
<section id="Sx3.SSx2.SSSx5" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Arithmetic expression annotation.</h4>

<div id="Sx3.SSx2.SSSx5.p1" class="ltx_para">
<p id="Sx3.SSx2.SSSx5.p1.1" class="ltx_p">We provided arithmetic expressions
like “30 - 28” in which the final numerical answer can be arrived at with the four arithmetic operations. The interpretation of the answer generation process is important for creating explainable QA models.</p>
</div>
</section>
</section>
<section id="Sx3.SSx3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">Statistics and Analysis</h3>

<div id="Sx3.SSx3.p1" class="ltx_para">
<p id="Sx3.SSx3.p1.1" class="ltx_p">SlideVQA contains 14,484 QA pairs from 2,619
slide decks, consisting of 52,480 slide images annotated with 890,945 bounding boxes. We split the dataset into 10,617 questions for training, 1,652 (2,215) questions for development (test), making sure that each deck appears in the same split.</p>
</div>
<section id="Sx3.SSx3.SSSx1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Images.</h4>

<div id="Sx3.SSx3.SSSx1.p1" class="ltx_para">
<p id="Sx3.SSx3.SSSx1.p1.1" class="ltx_p">SlideVQA provides the largest number of images covering broad range of topics among the datasets shown in Table <a href="#Sx2.T1" title="Table 1 ‣ Datasets for VQA on document images. ‣ Related Work ‣ SlideVQA: A Dataset for Document Visual Question Answering on Multiple Images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
Moreover, SlideVQA provides the largest number of bounding box annotations, where the number of the annotations in SlideVQA is 14.7 times that of VisualMRC. Figure <a href="#Sx3.F3" title="Figure 3 ‣ Bounding boxes and categories annotation. ‣ Dataset Collection ‣ The SlideVQA Task and Dataset ‣ SlideVQA: A Dataset for Document Visual Question Answering on Multiple Images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>a shows the distribution of bounding boxes broken down into nine categories, which cover all classes, including visually related ones (Image and Figure), unlike DocVQA and DocCVQA. To analyze the OCR tokens, we extracted the text shown in the images by using the Google Cloud
Vision API<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>https://cloud.google.com/vision</span></span></span>.
As a result,
the number of OCR tokens the system should consider simultaneously is larger (1488.88 tokens) than those of single-image document VQA datasets; the largest dataset (InfographicVQA) has 217.89 tokens.</p>
</div>
<figure id="Sx3.F4" class="ltx_figure"><img src="/html/2301.04883/assets/x7.png" id="Sx3.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="269" height="192" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Distribution of the first three words of the questions.</figcaption>
</figure>
<figure id="Sx3.F5" class="ltx_figure"><img src="/html/2301.04883/assets/x8.png" id="Sx3.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="484" height="168" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>(a) Our encoder-decoder model architecture and (b) input representations. Given a question with a task prefix and a slide deck, the model outputs a corresponding answer/arithmetic-expression and evidence pages. The calculator outputs the final answer to calculate the generated arithmetic expression.</figcaption>
</figure>
</section>
<section id="Sx3.SSx3.SSSx2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Questions and answers.</h4>

<div id="Sx3.SSx3.SSSx2.p1" class="ltx_para">
<p id="Sx3.SSx3.SSSx2.p1.1" class="ltx_p">As shown in Table <a href="#Sx2.T1" title="Table 1 ‣ Datasets for VQA on document images. ‣ Related Work ‣ SlideVQA: A Dataset for Document Visual Question Answering on Multiple Images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, SlideVQA
requires complex reasoning including single/multi-hop, and numerical reasoning.
Figure <a href="#Sx3.F3" title="Figure 3 ‣ Bounding boxes and categories annotation. ‣ Dataset Collection ‣ The SlideVQA Task and Dataset ‣ SlideVQA: A Dataset for Document Visual Question Answering on Multiple Images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>b shows the diverse distribution of questions related to reasoning types. 49.3% of the questions require multi-hop or numerical reasoning.
Moreover, SlideVQA
provides annotations of arithmetic expressions to improve numerical reasoning. Figure <a href="#Sx3.F3" title="Figure 3 ‣ Bounding boxes and categories annotation. ‣ Dataset Collection ‣ The SlideVQA Task and Dataset ‣ SlideVQA: A Dataset for Document Visual Question Answering on Multiple Images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>c shows the distribution of numerical operations. 25.5% of the numerical questions require arithmetic operations, which current systems have particular difficulty answering. Figure <a href="#Sx3.F3" title="Figure 3 ‣ Bounding boxes and categories annotation. ‣ Dataset Collection ‣ The SlideVQA Task and Dataset ‣ SlideVQA: A Dataset for Document Visual Question Answering on Multiple Images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>d shows that multi-span and non-span account for 32.4% of the answers, indicating systems also need to generate answers as well as extract multiple spans.</p>
</div>
<div id="Sx3.SSx3.SSSx2.p2" class="ltx_para">
<p id="Sx3.SSx3.SSSx2.p2.1" class="ltx_p">Figure <a href="#Sx3.F4" title="Figure 4 ‣ Images. ‣ Statistics and Analysis ‣ The SlideVQA Task and Dataset ‣ SlideVQA: A Dataset for Document Visual Question Answering on Multiple Images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> shows the sunburst pattern of the first three words of the questions. “In” and “Regarding” are frequent first words because SlideVQA needs to search for evidence images from a slide deck, which is a special pattern in multi-text document QA <cite class="ltx_cite ltx_citemacro_citep">(Yang et al. <a href="#bib.bib43" title="" class="ltx_ref">2018</a>)</cite>.</p>
</div>
</section>
</section>
</section>
<section id="Sx4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Our Model</h2>

<div id="Sx4.p1" class="ltx_para">
<p id="Sx4.p1.1" class="ltx_p">Figure <a href="#Sx3.F5" title="Figure 5 ‣ Images. ‣ Statistics and Analysis ‣ The SlideVQA Task and Dataset ‣ SlideVQA: A Dataset for Document Visual Question Answering on Multiple Images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> shows an overview of our model, called M3D
(<span id="Sx4.p1.1.1" class="ltx_text ltx_font_bold">M</span>ulti-<span id="Sx4.p1.1.2" class="ltx_text ltx_font_bold">M</span>odal <span id="Sx4.p1.1.3" class="ltx_text ltx_font_bold">M</span>ulti-image <span id="Sx4.p1.1.4" class="ltx_text ltx_font_bold">D</span>ocument VQA model).
We use Fusion-in-Decoder (FiD) <cite class="ltx_cite ltx_citemacro_citep">(Izacard and Grave <a href="#bib.bib12" title="" class="ltx_ref">2021</a>)</cite>, which is a state-of-the-art multi-text encoder-decoder model, as our base model and initialize FiD with a pre-trained T5 <cite class="ltx_cite ltx_citemacro_citep">(Raffel et al. <a href="#bib.bib24" title="" class="ltx_ref">2020</a>)</cite>.
We extend FiD to perform the end-to-end SlideVQA task (defined in <span id="Sx4.p1.1.5" class="ltx_text ltx_font_smallcaps">MainTask</span>) by (i) performing evidence selection and question answering tasks as a unified sequence-to-sequence format using multi-task learning, (ii) predicting arithmetic expressions as intermediate reasoning steps instead of generating answers directly to enhance numerical reasoning, and (iii) modifying the input sequence to learn the visual layout and content of the image.</p>
</div>
<section id="Sx4.SSx1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">Multi-modal Task-Specific Input</h3>

<section id="Sx4.SSx1.SSSx1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Input token sequence.</h4>

<div id="Sx4.SSx1.SSSx1.p1" class="ltx_para">
<p id="Sx4.SSx1.SSSx1.p1.5" class="ltx_p">For each image <math id="Sx4.SSx1.SSSx1.p1.1.m1.1" class="ltx_Math" alttext="I_{k}" display="inline"><semantics id="Sx4.SSx1.SSSx1.p1.1.m1.1a"><msub id="Sx4.SSx1.SSSx1.p1.1.m1.1.1" xref="Sx4.SSx1.SSSx1.p1.1.m1.1.1.cmml"><mi id="Sx4.SSx1.SSSx1.p1.1.m1.1.1.2" xref="Sx4.SSx1.SSSx1.p1.1.m1.1.1.2.cmml">I</mi><mi id="Sx4.SSx1.SSSx1.p1.1.m1.1.1.3" xref="Sx4.SSx1.SSSx1.p1.1.m1.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="Sx4.SSx1.SSSx1.p1.1.m1.1b"><apply id="Sx4.SSx1.SSSx1.p1.1.m1.1.1.cmml" xref="Sx4.SSx1.SSSx1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="Sx4.SSx1.SSSx1.p1.1.m1.1.1.1.cmml" xref="Sx4.SSx1.SSSx1.p1.1.m1.1.1">subscript</csymbol><ci id="Sx4.SSx1.SSSx1.p1.1.m1.1.1.2.cmml" xref="Sx4.SSx1.SSSx1.p1.1.m1.1.1.2">𝐼</ci><ci id="Sx4.SSx1.SSSx1.p1.1.m1.1.1.3.cmml" xref="Sx4.SSx1.SSSx1.p1.1.m1.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx4.SSx1.SSSx1.p1.1.m1.1c">I_{k}</annotation></semantics></math>, we first use Faster-RCNN  <cite class="ltx_cite ltx_citemacro_citep">(Ren et al. <a href="#bib.bib27" title="" class="ltx_ref">2015</a>)</cite>, which was trained on SlideVQA, to extract <math id="Sx4.SSx1.SSSx1.p1.2.m2.1" class="ltx_Math" alttext="N" display="inline"><semantics id="Sx4.SSx1.SSSx1.p1.2.m2.1a"><mi id="Sx4.SSx1.SSSx1.p1.2.m2.1.1" xref="Sx4.SSx1.SSSx1.p1.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="Sx4.SSx1.SSSx1.p1.2.m2.1b"><ci id="Sx4.SSx1.SSSx1.p1.2.m2.1.1.cmml" xref="Sx4.SSx1.SSSx1.p1.2.m2.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx4.SSx1.SSSx1.p1.2.m2.1c">N</annotation></semantics></math> semantic regions (bounding boxes) and their labels
(e.g., Title and Image). We parse the slide image for each extracted region <math id="Sx4.SSx1.SSSx1.p1.3.m3.1" class="ltx_Math" alttext="r" display="inline"><semantics id="Sx4.SSx1.SSSx1.p1.3.m3.1a"><mi id="Sx4.SSx1.SSSx1.p1.3.m3.1.1" xref="Sx4.SSx1.SSSx1.p1.3.m3.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="Sx4.SSx1.SSSx1.p1.3.m3.1b"><ci id="Sx4.SSx1.SSSx1.p1.3.m3.1.1.cmml" xref="Sx4.SSx1.SSSx1.p1.3.m3.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx4.SSx1.SSSx1.p1.3.m3.1c">r</annotation></semantics></math> by using an OCR engine and apply a sub-word tokenizer to obtain OCR tokens <math id="Sx4.SSx1.SSSx1.p1.4.m4.7" class="ltx_Math" alttext="\mathbf{W}^{r}_{k}=\{w^{r}_{k,1},\ldots,w^{r}_{k,n}\}" display="inline"><semantics id="Sx4.SSx1.SSSx1.p1.4.m4.7a"><mrow id="Sx4.SSx1.SSSx1.p1.4.m4.7.7" xref="Sx4.SSx1.SSSx1.p1.4.m4.7.7.cmml"><msubsup id="Sx4.SSx1.SSSx1.p1.4.m4.7.7.4" xref="Sx4.SSx1.SSSx1.p1.4.m4.7.7.4.cmml"><mi id="Sx4.SSx1.SSSx1.p1.4.m4.7.7.4.2.2" xref="Sx4.SSx1.SSSx1.p1.4.m4.7.7.4.2.2.cmml">𝐖</mi><mi id="Sx4.SSx1.SSSx1.p1.4.m4.7.7.4.3" xref="Sx4.SSx1.SSSx1.p1.4.m4.7.7.4.3.cmml">k</mi><mi id="Sx4.SSx1.SSSx1.p1.4.m4.7.7.4.2.3" xref="Sx4.SSx1.SSSx1.p1.4.m4.7.7.4.2.3.cmml">r</mi></msubsup><mo id="Sx4.SSx1.SSSx1.p1.4.m4.7.7.3" xref="Sx4.SSx1.SSSx1.p1.4.m4.7.7.3.cmml">=</mo><mrow id="Sx4.SSx1.SSSx1.p1.4.m4.7.7.2.2" xref="Sx4.SSx1.SSSx1.p1.4.m4.7.7.2.3.cmml"><mo stretchy="false" id="Sx4.SSx1.SSSx1.p1.4.m4.7.7.2.2.3" xref="Sx4.SSx1.SSSx1.p1.4.m4.7.7.2.3.cmml">{</mo><msubsup id="Sx4.SSx1.SSSx1.p1.4.m4.6.6.1.1.1" xref="Sx4.SSx1.SSSx1.p1.4.m4.6.6.1.1.1.cmml"><mi id="Sx4.SSx1.SSSx1.p1.4.m4.6.6.1.1.1.2.2" xref="Sx4.SSx1.SSSx1.p1.4.m4.6.6.1.1.1.2.2.cmml">w</mi><mrow id="Sx4.SSx1.SSSx1.p1.4.m4.2.2.2.4" xref="Sx4.SSx1.SSSx1.p1.4.m4.2.2.2.3.cmml"><mi id="Sx4.SSx1.SSSx1.p1.4.m4.1.1.1.1" xref="Sx4.SSx1.SSSx1.p1.4.m4.1.1.1.1.cmml">k</mi><mo id="Sx4.SSx1.SSSx1.p1.4.m4.2.2.2.4.1" xref="Sx4.SSx1.SSSx1.p1.4.m4.2.2.2.3.cmml">,</mo><mn id="Sx4.SSx1.SSSx1.p1.4.m4.2.2.2.2" xref="Sx4.SSx1.SSSx1.p1.4.m4.2.2.2.2.cmml">1</mn></mrow><mi id="Sx4.SSx1.SSSx1.p1.4.m4.6.6.1.1.1.2.3" xref="Sx4.SSx1.SSSx1.p1.4.m4.6.6.1.1.1.2.3.cmml">r</mi></msubsup><mo id="Sx4.SSx1.SSSx1.p1.4.m4.7.7.2.2.4" xref="Sx4.SSx1.SSSx1.p1.4.m4.7.7.2.3.cmml">,</mo><mi mathvariant="normal" id="Sx4.SSx1.SSSx1.p1.4.m4.5.5" xref="Sx4.SSx1.SSSx1.p1.4.m4.5.5.cmml">…</mi><mo id="Sx4.SSx1.SSSx1.p1.4.m4.7.7.2.2.5" xref="Sx4.SSx1.SSSx1.p1.4.m4.7.7.2.3.cmml">,</mo><msubsup id="Sx4.SSx1.SSSx1.p1.4.m4.7.7.2.2.2" xref="Sx4.SSx1.SSSx1.p1.4.m4.7.7.2.2.2.cmml"><mi id="Sx4.SSx1.SSSx1.p1.4.m4.7.7.2.2.2.2.2" xref="Sx4.SSx1.SSSx1.p1.4.m4.7.7.2.2.2.2.2.cmml">w</mi><mrow id="Sx4.SSx1.SSSx1.p1.4.m4.4.4.2.4" xref="Sx4.SSx1.SSSx1.p1.4.m4.4.4.2.3.cmml"><mi id="Sx4.SSx1.SSSx1.p1.4.m4.3.3.1.1" xref="Sx4.SSx1.SSSx1.p1.4.m4.3.3.1.1.cmml">k</mi><mo id="Sx4.SSx1.SSSx1.p1.4.m4.4.4.2.4.1" xref="Sx4.SSx1.SSSx1.p1.4.m4.4.4.2.3.cmml">,</mo><mi id="Sx4.SSx1.SSSx1.p1.4.m4.4.4.2.2" xref="Sx4.SSx1.SSSx1.p1.4.m4.4.4.2.2.cmml">n</mi></mrow><mi id="Sx4.SSx1.SSSx1.p1.4.m4.7.7.2.2.2.2.3" xref="Sx4.SSx1.SSSx1.p1.4.m4.7.7.2.2.2.2.3.cmml">r</mi></msubsup><mo stretchy="false" id="Sx4.SSx1.SSSx1.p1.4.m4.7.7.2.2.6" xref="Sx4.SSx1.SSSx1.p1.4.m4.7.7.2.3.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="Sx4.SSx1.SSSx1.p1.4.m4.7b"><apply id="Sx4.SSx1.SSSx1.p1.4.m4.7.7.cmml" xref="Sx4.SSx1.SSSx1.p1.4.m4.7.7"><eq id="Sx4.SSx1.SSSx1.p1.4.m4.7.7.3.cmml" xref="Sx4.SSx1.SSSx1.p1.4.m4.7.7.3"></eq><apply id="Sx4.SSx1.SSSx1.p1.4.m4.7.7.4.cmml" xref="Sx4.SSx1.SSSx1.p1.4.m4.7.7.4"><csymbol cd="ambiguous" id="Sx4.SSx1.SSSx1.p1.4.m4.7.7.4.1.cmml" xref="Sx4.SSx1.SSSx1.p1.4.m4.7.7.4">subscript</csymbol><apply id="Sx4.SSx1.SSSx1.p1.4.m4.7.7.4.2.cmml" xref="Sx4.SSx1.SSSx1.p1.4.m4.7.7.4"><csymbol cd="ambiguous" id="Sx4.SSx1.SSSx1.p1.4.m4.7.7.4.2.1.cmml" xref="Sx4.SSx1.SSSx1.p1.4.m4.7.7.4">superscript</csymbol><ci id="Sx4.SSx1.SSSx1.p1.4.m4.7.7.4.2.2.cmml" xref="Sx4.SSx1.SSSx1.p1.4.m4.7.7.4.2.2">𝐖</ci><ci id="Sx4.SSx1.SSSx1.p1.4.m4.7.7.4.2.3.cmml" xref="Sx4.SSx1.SSSx1.p1.4.m4.7.7.4.2.3">𝑟</ci></apply><ci id="Sx4.SSx1.SSSx1.p1.4.m4.7.7.4.3.cmml" xref="Sx4.SSx1.SSSx1.p1.4.m4.7.7.4.3">𝑘</ci></apply><set id="Sx4.SSx1.SSSx1.p1.4.m4.7.7.2.3.cmml" xref="Sx4.SSx1.SSSx1.p1.4.m4.7.7.2.2"><apply id="Sx4.SSx1.SSSx1.p1.4.m4.6.6.1.1.1.cmml" xref="Sx4.SSx1.SSSx1.p1.4.m4.6.6.1.1.1"><csymbol cd="ambiguous" id="Sx4.SSx1.SSSx1.p1.4.m4.6.6.1.1.1.1.cmml" xref="Sx4.SSx1.SSSx1.p1.4.m4.6.6.1.1.1">subscript</csymbol><apply id="Sx4.SSx1.SSSx1.p1.4.m4.6.6.1.1.1.2.cmml" xref="Sx4.SSx1.SSSx1.p1.4.m4.6.6.1.1.1"><csymbol cd="ambiguous" id="Sx4.SSx1.SSSx1.p1.4.m4.6.6.1.1.1.2.1.cmml" xref="Sx4.SSx1.SSSx1.p1.4.m4.6.6.1.1.1">superscript</csymbol><ci id="Sx4.SSx1.SSSx1.p1.4.m4.6.6.1.1.1.2.2.cmml" xref="Sx4.SSx1.SSSx1.p1.4.m4.6.6.1.1.1.2.2">𝑤</ci><ci id="Sx4.SSx1.SSSx1.p1.4.m4.6.6.1.1.1.2.3.cmml" xref="Sx4.SSx1.SSSx1.p1.4.m4.6.6.1.1.1.2.3">𝑟</ci></apply><list id="Sx4.SSx1.SSSx1.p1.4.m4.2.2.2.3.cmml" xref="Sx4.SSx1.SSSx1.p1.4.m4.2.2.2.4"><ci id="Sx4.SSx1.SSSx1.p1.4.m4.1.1.1.1.cmml" xref="Sx4.SSx1.SSSx1.p1.4.m4.1.1.1.1">𝑘</ci><cn type="integer" id="Sx4.SSx1.SSSx1.p1.4.m4.2.2.2.2.cmml" xref="Sx4.SSx1.SSSx1.p1.4.m4.2.2.2.2">1</cn></list></apply><ci id="Sx4.SSx1.SSSx1.p1.4.m4.5.5.cmml" xref="Sx4.SSx1.SSSx1.p1.4.m4.5.5">…</ci><apply id="Sx4.SSx1.SSSx1.p1.4.m4.7.7.2.2.2.cmml" xref="Sx4.SSx1.SSSx1.p1.4.m4.7.7.2.2.2"><csymbol cd="ambiguous" id="Sx4.SSx1.SSSx1.p1.4.m4.7.7.2.2.2.1.cmml" xref="Sx4.SSx1.SSSx1.p1.4.m4.7.7.2.2.2">subscript</csymbol><apply id="Sx4.SSx1.SSSx1.p1.4.m4.7.7.2.2.2.2.cmml" xref="Sx4.SSx1.SSSx1.p1.4.m4.7.7.2.2.2"><csymbol cd="ambiguous" id="Sx4.SSx1.SSSx1.p1.4.m4.7.7.2.2.2.2.1.cmml" xref="Sx4.SSx1.SSSx1.p1.4.m4.7.7.2.2.2">superscript</csymbol><ci id="Sx4.SSx1.SSSx1.p1.4.m4.7.7.2.2.2.2.2.cmml" xref="Sx4.SSx1.SSSx1.p1.4.m4.7.7.2.2.2.2.2">𝑤</ci><ci id="Sx4.SSx1.SSSx1.p1.4.m4.7.7.2.2.2.2.3.cmml" xref="Sx4.SSx1.SSSx1.p1.4.m4.7.7.2.2.2.2.3">𝑟</ci></apply><list id="Sx4.SSx1.SSSx1.p1.4.m4.4.4.2.3.cmml" xref="Sx4.SSx1.SSSx1.p1.4.m4.4.4.2.4"><ci id="Sx4.SSx1.SSSx1.p1.4.m4.3.3.1.1.cmml" xref="Sx4.SSx1.SSSx1.p1.4.m4.3.3.1.1">𝑘</ci><ci id="Sx4.SSx1.SSSx1.p1.4.m4.4.4.2.2.cmml" xref="Sx4.SSx1.SSSx1.p1.4.m4.4.4.2.2">𝑛</ci></list></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx4.SSx1.SSSx1.p1.4.m4.7c">\mathbf{W}^{r}_{k}=\{w^{r}_{k,1},\ldots,w^{r}_{k,n}\}</annotation></semantics></math> and corresponding OCR bounding boxes. To jointly train the evidence selection and question answering tasks, we add different task prefixes <math id="Sx4.SSx1.SSSx1.p1.5.m5.1" class="ltx_Math" alttext="t\in" display="inline"><semantics id="Sx4.SSx1.SSSx1.p1.5.m5.1a"><mrow id="Sx4.SSx1.SSSx1.p1.5.m5.1.1" xref="Sx4.SSx1.SSSx1.p1.5.m5.1.1.cmml"><mi id="Sx4.SSx1.SSSx1.p1.5.m5.1.1.2" xref="Sx4.SSx1.SSSx1.p1.5.m5.1.1.2.cmml">t</mi><mo id="Sx4.SSx1.SSSx1.p1.5.m5.1.1.1" xref="Sx4.SSx1.SSSx1.p1.5.m5.1.1.1.cmml">∈</mo><mi id="Sx4.SSx1.SSSx1.p1.5.m5.1.1.3" xref="Sx4.SSx1.SSSx1.p1.5.m5.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="Sx4.SSx1.SSSx1.p1.5.m5.1b"><apply id="Sx4.SSx1.SSSx1.p1.5.m5.1.1.cmml" xref="Sx4.SSx1.SSSx1.p1.5.m5.1.1"><in id="Sx4.SSx1.SSSx1.p1.5.m5.1.1.1.cmml" xref="Sx4.SSx1.SSSx1.p1.5.m5.1.1.1"></in><ci id="Sx4.SSx1.SSSx1.p1.5.m5.1.1.2.cmml" xref="Sx4.SSx1.SSSx1.p1.5.m5.1.1.2">𝑡</ci><csymbol cd="latexml" id="Sx4.SSx1.SSSx1.p1.5.m5.1.1.3.cmml" xref="Sx4.SSx1.SSSx1.p1.5.m5.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx4.SSx1.SSSx1.p1.5.m5.1c">t\in</annotation></semantics></math> {<span id="Sx4.SSx1.SSSx1.p1.5.1" class="ltx_text ltx_font_typewriter">Evidence Selection</span>, <span id="Sx4.SSx1.SSSx1.p1.5.2" class="ltx_text ltx_font_typewriter">Question Answering</span>} to the encoder input. Specifically, the input sequence is as follows:</p>
<table id="Sx4.Ex1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="Sx4.Ex1.m1.1" class="ltx_Math" alttext="x_{k}=(\texttt{task:}t\texttt{ question:}q\texttt{ page:}e_{k}\texttt{ context:}c_{k})," display="block"><semantics id="Sx4.Ex1.m1.1a"><mrow id="Sx4.Ex1.m1.1.1.1" xref="Sx4.Ex1.m1.1.1.1.1.cmml"><mrow id="Sx4.Ex1.m1.1.1.1.1" xref="Sx4.Ex1.m1.1.1.1.1.cmml"><msub id="Sx4.Ex1.m1.1.1.1.1.3" xref="Sx4.Ex1.m1.1.1.1.1.3.cmml"><mi id="Sx4.Ex1.m1.1.1.1.1.3.2" xref="Sx4.Ex1.m1.1.1.1.1.3.2.cmml">x</mi><mi id="Sx4.Ex1.m1.1.1.1.1.3.3" xref="Sx4.Ex1.m1.1.1.1.1.3.3.cmml">k</mi></msub><mo id="Sx4.Ex1.m1.1.1.1.1.2" xref="Sx4.Ex1.m1.1.1.1.1.2.cmml">=</mo><mrow id="Sx4.Ex1.m1.1.1.1.1.1.1" xref="Sx4.Ex1.m1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="Sx4.Ex1.m1.1.1.1.1.1.1.2" xref="Sx4.Ex1.m1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="Sx4.Ex1.m1.1.1.1.1.1.1.1" xref="Sx4.Ex1.m1.1.1.1.1.1.1.1.cmml"><mtext class="ltx_mathvariant_monospace" id="Sx4.Ex1.m1.1.1.1.1.1.1.1.2" xref="Sx4.Ex1.m1.1.1.1.1.1.1.1.2a.cmml">task:</mtext><mo lspace="0em" rspace="0em" id="Sx4.Ex1.m1.1.1.1.1.1.1.1.1" xref="Sx4.Ex1.m1.1.1.1.1.1.1.1.1.cmml">​</mo><mi id="Sx4.Ex1.m1.1.1.1.1.1.1.1.3" xref="Sx4.Ex1.m1.1.1.1.1.1.1.1.3.cmml">t</mi><mo lspace="0em" rspace="0em" id="Sx4.Ex1.m1.1.1.1.1.1.1.1.1a" xref="Sx4.Ex1.m1.1.1.1.1.1.1.1.1.cmml">​</mo><mtext class="ltx_mathvariant_monospace" id="Sx4.Ex1.m1.1.1.1.1.1.1.1.4" xref="Sx4.Ex1.m1.1.1.1.1.1.1.1.4a.cmml"> question:</mtext><mo lspace="0em" rspace="0em" id="Sx4.Ex1.m1.1.1.1.1.1.1.1.1b" xref="Sx4.Ex1.m1.1.1.1.1.1.1.1.1.cmml">​</mo><mi id="Sx4.Ex1.m1.1.1.1.1.1.1.1.5" xref="Sx4.Ex1.m1.1.1.1.1.1.1.1.5.cmml">q</mi><mo lspace="0em" rspace="0em" id="Sx4.Ex1.m1.1.1.1.1.1.1.1.1c" xref="Sx4.Ex1.m1.1.1.1.1.1.1.1.1.cmml">​</mo><mtext class="ltx_mathvariant_monospace" id="Sx4.Ex1.m1.1.1.1.1.1.1.1.6" xref="Sx4.Ex1.m1.1.1.1.1.1.1.1.6a.cmml"> page:</mtext><mo lspace="0em" rspace="0em" id="Sx4.Ex1.m1.1.1.1.1.1.1.1.1d" xref="Sx4.Ex1.m1.1.1.1.1.1.1.1.1.cmml">​</mo><msub id="Sx4.Ex1.m1.1.1.1.1.1.1.1.7" xref="Sx4.Ex1.m1.1.1.1.1.1.1.1.7.cmml"><mi id="Sx4.Ex1.m1.1.1.1.1.1.1.1.7.2" xref="Sx4.Ex1.m1.1.1.1.1.1.1.1.7.2.cmml">e</mi><mi id="Sx4.Ex1.m1.1.1.1.1.1.1.1.7.3" xref="Sx4.Ex1.m1.1.1.1.1.1.1.1.7.3.cmml">k</mi></msub><mo lspace="0em" rspace="0em" id="Sx4.Ex1.m1.1.1.1.1.1.1.1.1e" xref="Sx4.Ex1.m1.1.1.1.1.1.1.1.1.cmml">​</mo><mtext class="ltx_mathvariant_monospace" id="Sx4.Ex1.m1.1.1.1.1.1.1.1.8" xref="Sx4.Ex1.m1.1.1.1.1.1.1.1.8a.cmml"> context:</mtext><mo lspace="0em" rspace="0em" id="Sx4.Ex1.m1.1.1.1.1.1.1.1.1f" xref="Sx4.Ex1.m1.1.1.1.1.1.1.1.1.cmml">​</mo><msub id="Sx4.Ex1.m1.1.1.1.1.1.1.1.9" xref="Sx4.Ex1.m1.1.1.1.1.1.1.1.9.cmml"><mi id="Sx4.Ex1.m1.1.1.1.1.1.1.1.9.2" xref="Sx4.Ex1.m1.1.1.1.1.1.1.1.9.2.cmml">c</mi><mi id="Sx4.Ex1.m1.1.1.1.1.1.1.1.9.3" xref="Sx4.Ex1.m1.1.1.1.1.1.1.1.9.3.cmml">k</mi></msub></mrow><mo stretchy="false" id="Sx4.Ex1.m1.1.1.1.1.1.1.3" xref="Sx4.Ex1.m1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="Sx4.Ex1.m1.1.1.1.2" xref="Sx4.Ex1.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="Sx4.Ex1.m1.1b"><apply id="Sx4.Ex1.m1.1.1.1.1.cmml" xref="Sx4.Ex1.m1.1.1.1"><eq id="Sx4.Ex1.m1.1.1.1.1.2.cmml" xref="Sx4.Ex1.m1.1.1.1.1.2"></eq><apply id="Sx4.Ex1.m1.1.1.1.1.3.cmml" xref="Sx4.Ex1.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="Sx4.Ex1.m1.1.1.1.1.3.1.cmml" xref="Sx4.Ex1.m1.1.1.1.1.3">subscript</csymbol><ci id="Sx4.Ex1.m1.1.1.1.1.3.2.cmml" xref="Sx4.Ex1.m1.1.1.1.1.3.2">𝑥</ci><ci id="Sx4.Ex1.m1.1.1.1.1.3.3.cmml" xref="Sx4.Ex1.m1.1.1.1.1.3.3">𝑘</ci></apply><apply id="Sx4.Ex1.m1.1.1.1.1.1.1.1.cmml" xref="Sx4.Ex1.m1.1.1.1.1.1.1"><times id="Sx4.Ex1.m1.1.1.1.1.1.1.1.1.cmml" xref="Sx4.Ex1.m1.1.1.1.1.1.1.1.1"></times><ci id="Sx4.Ex1.m1.1.1.1.1.1.1.1.2a.cmml" xref="Sx4.Ex1.m1.1.1.1.1.1.1.1.2"><mtext class="ltx_mathvariant_monospace" id="Sx4.Ex1.m1.1.1.1.1.1.1.1.2.cmml" xref="Sx4.Ex1.m1.1.1.1.1.1.1.1.2">task:</mtext></ci><ci id="Sx4.Ex1.m1.1.1.1.1.1.1.1.3.cmml" xref="Sx4.Ex1.m1.1.1.1.1.1.1.1.3">𝑡</ci><ci id="Sx4.Ex1.m1.1.1.1.1.1.1.1.4a.cmml" xref="Sx4.Ex1.m1.1.1.1.1.1.1.1.4"><mtext class="ltx_mathvariant_monospace" id="Sx4.Ex1.m1.1.1.1.1.1.1.1.4.cmml" xref="Sx4.Ex1.m1.1.1.1.1.1.1.1.4"> question:</mtext></ci><ci id="Sx4.Ex1.m1.1.1.1.1.1.1.1.5.cmml" xref="Sx4.Ex1.m1.1.1.1.1.1.1.1.5">𝑞</ci><ci id="Sx4.Ex1.m1.1.1.1.1.1.1.1.6a.cmml" xref="Sx4.Ex1.m1.1.1.1.1.1.1.1.6"><mtext class="ltx_mathvariant_monospace" id="Sx4.Ex1.m1.1.1.1.1.1.1.1.6.cmml" xref="Sx4.Ex1.m1.1.1.1.1.1.1.1.6"> page:</mtext></ci><apply id="Sx4.Ex1.m1.1.1.1.1.1.1.1.7.cmml" xref="Sx4.Ex1.m1.1.1.1.1.1.1.1.7"><csymbol cd="ambiguous" id="Sx4.Ex1.m1.1.1.1.1.1.1.1.7.1.cmml" xref="Sx4.Ex1.m1.1.1.1.1.1.1.1.7">subscript</csymbol><ci id="Sx4.Ex1.m1.1.1.1.1.1.1.1.7.2.cmml" xref="Sx4.Ex1.m1.1.1.1.1.1.1.1.7.2">𝑒</ci><ci id="Sx4.Ex1.m1.1.1.1.1.1.1.1.7.3.cmml" xref="Sx4.Ex1.m1.1.1.1.1.1.1.1.7.3">𝑘</ci></apply><ci id="Sx4.Ex1.m1.1.1.1.1.1.1.1.8a.cmml" xref="Sx4.Ex1.m1.1.1.1.1.1.1.1.8"><mtext class="ltx_mathvariant_monospace" id="Sx4.Ex1.m1.1.1.1.1.1.1.1.8.cmml" xref="Sx4.Ex1.m1.1.1.1.1.1.1.1.8"> context:</mtext></ci><apply id="Sx4.Ex1.m1.1.1.1.1.1.1.1.9.cmml" xref="Sx4.Ex1.m1.1.1.1.1.1.1.1.9"><csymbol cd="ambiguous" id="Sx4.Ex1.m1.1.1.1.1.1.1.1.9.1.cmml" xref="Sx4.Ex1.m1.1.1.1.1.1.1.1.9">subscript</csymbol><ci id="Sx4.Ex1.m1.1.1.1.1.1.1.1.9.2.cmml" xref="Sx4.Ex1.m1.1.1.1.1.1.1.1.9.2">𝑐</ci><ci id="Sx4.Ex1.m1.1.1.1.1.1.1.1.9.3.cmml" xref="Sx4.Ex1.m1.1.1.1.1.1.1.1.9.3">𝑘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx4.Ex1.m1.1c">x_{k}=(\texttt{task:}t\texttt{ question:}q\texttt{ page:}e_{k}\texttt{ context:}c_{k}),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="Sx4.SSx1.SSSx1.p1.15" class="ltx_p">where the sequence concatenates each slide and page number pair (<math id="Sx4.SSx1.SSSx1.p1.6.m1.1" class="ltx_Math" alttext="c_{k}" display="inline"><semantics id="Sx4.SSx1.SSSx1.p1.6.m1.1a"><msub id="Sx4.SSx1.SSSx1.p1.6.m1.1.1" xref="Sx4.SSx1.SSSx1.p1.6.m1.1.1.cmml"><mi id="Sx4.SSx1.SSSx1.p1.6.m1.1.1.2" xref="Sx4.SSx1.SSSx1.p1.6.m1.1.1.2.cmml">c</mi><mi id="Sx4.SSx1.SSSx1.p1.6.m1.1.1.3" xref="Sx4.SSx1.SSSx1.p1.6.m1.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="Sx4.SSx1.SSSx1.p1.6.m1.1b"><apply id="Sx4.SSx1.SSSx1.p1.6.m1.1.1.cmml" xref="Sx4.SSx1.SSSx1.p1.6.m1.1.1"><csymbol cd="ambiguous" id="Sx4.SSx1.SSSx1.p1.6.m1.1.1.1.cmml" xref="Sx4.SSx1.SSSx1.p1.6.m1.1.1">subscript</csymbol><ci id="Sx4.SSx1.SSSx1.p1.6.m1.1.1.2.cmml" xref="Sx4.SSx1.SSSx1.p1.6.m1.1.1.2">𝑐</ci><ci id="Sx4.SSx1.SSSx1.p1.6.m1.1.1.3.cmml" xref="Sx4.SSx1.SSSx1.p1.6.m1.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx4.SSx1.SSSx1.p1.6.m1.1c">c_{k}</annotation></semantics></math>, <math id="Sx4.SSx1.SSSx1.p1.7.m2.1" class="ltx_Math" alttext="e_{k}" display="inline"><semantics id="Sx4.SSx1.SSSx1.p1.7.m2.1a"><msub id="Sx4.SSx1.SSSx1.p1.7.m2.1.1" xref="Sx4.SSx1.SSSx1.p1.7.m2.1.1.cmml"><mi id="Sx4.SSx1.SSSx1.p1.7.m2.1.1.2" xref="Sx4.SSx1.SSSx1.p1.7.m2.1.1.2.cmml">e</mi><mi id="Sx4.SSx1.SSSx1.p1.7.m2.1.1.3" xref="Sx4.SSx1.SSSx1.p1.7.m2.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="Sx4.SSx1.SSSx1.p1.7.m2.1b"><apply id="Sx4.SSx1.SSSx1.p1.7.m2.1.1.cmml" xref="Sx4.SSx1.SSSx1.p1.7.m2.1.1"><csymbol cd="ambiguous" id="Sx4.SSx1.SSSx1.p1.7.m2.1.1.1.cmml" xref="Sx4.SSx1.SSSx1.p1.7.m2.1.1">subscript</csymbol><ci id="Sx4.SSx1.SSSx1.p1.7.m2.1.1.2.cmml" xref="Sx4.SSx1.SSSx1.p1.7.m2.1.1.2">𝑒</ci><ci id="Sx4.SSx1.SSSx1.p1.7.m2.1.1.3.cmml" xref="Sx4.SSx1.SSSx1.p1.7.m2.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx4.SSx1.SSSx1.p1.7.m2.1c">e_{k}</annotation></semantics></math>) with the question <math id="Sx4.SSx1.SSSx1.p1.8.m3.1" class="ltx_Math" alttext="q" display="inline"><semantics id="Sx4.SSx1.SSSx1.p1.8.m3.1a"><mi id="Sx4.SSx1.SSSx1.p1.8.m3.1.1" xref="Sx4.SSx1.SSSx1.p1.8.m3.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="Sx4.SSx1.SSSx1.p1.8.m3.1b"><ci id="Sx4.SSx1.SSSx1.p1.8.m3.1.1.cmml" xref="Sx4.SSx1.SSSx1.p1.8.m3.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx4.SSx1.SSSx1.p1.8.m3.1c">q</annotation></semantics></math> and task prefix <math id="Sx4.SSx1.SSSx1.p1.9.m4.1" class="ltx_Math" alttext="t" display="inline"><semantics id="Sx4.SSx1.SSSx1.p1.9.m4.1a"><mi id="Sx4.SSx1.SSSx1.p1.9.m4.1.1" xref="Sx4.SSx1.SSSx1.p1.9.m4.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="Sx4.SSx1.SSSx1.p1.9.m4.1b"><ci id="Sx4.SSx1.SSSx1.p1.9.m4.1.1.cmml" xref="Sx4.SSx1.SSSx1.p1.9.m4.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx4.SSx1.SSSx1.p1.9.m4.1c">t</annotation></semantics></math>. To tell the role of each region, we insert region labels <span id="Sx4.SSx1.SSSx1.p1.10.1" class="ltx_text ltx_font_typewriter">[R<math id="Sx4.SSx1.SSSx1.p1.10.1.m1.1" class="ltx_Math" alttext="{}^{r_{i}}_{k}" display="inline"><semantics id="Sx4.SSx1.SSSx1.p1.10.1.m1.1a"><mmultiscripts id="Sx4.SSx1.SSSx1.p1.10.1.m1.1.1" xref="Sx4.SSx1.SSSx1.p1.10.1.m1.1.1.cmml"><mi id="Sx4.SSx1.SSSx1.p1.10.1.m1.1.1.2.2" xref="Sx4.SSx1.SSSx1.p1.10.1.m1.1.1.2.2.cmml"></mi><mprescripts id="Sx4.SSx1.SSSx1.p1.10.1.m1.1.1a" xref="Sx4.SSx1.SSSx1.p1.10.1.m1.1.1.cmml"></mprescripts><mi id="Sx4.SSx1.SSSx1.p1.10.1.m1.1.1.3" xref="Sx4.SSx1.SSSx1.p1.10.1.m1.1.1.3.cmml">k</mi><mrow id="Sx4.SSx1.SSSx1.p1.10.1.m1.1.1b" xref="Sx4.SSx1.SSSx1.p1.10.1.m1.1.1.cmml"></mrow><mrow id="Sx4.SSx1.SSSx1.p1.10.1.m1.1.1c" xref="Sx4.SSx1.SSSx1.p1.10.1.m1.1.1.cmml"></mrow><msub id="Sx4.SSx1.SSSx1.p1.10.1.m1.1.1.2.3" xref="Sx4.SSx1.SSSx1.p1.10.1.m1.1.1.2.3.cmml"><mi id="Sx4.SSx1.SSSx1.p1.10.1.m1.1.1.2.3.2" xref="Sx4.SSx1.SSSx1.p1.10.1.m1.1.1.2.3.2.cmml">r</mi><mi id="Sx4.SSx1.SSSx1.p1.10.1.m1.1.1.2.3.3" xref="Sx4.SSx1.SSSx1.p1.10.1.m1.1.1.2.3.3.cmml">i</mi></msub></mmultiscripts><annotation-xml encoding="MathML-Content" id="Sx4.SSx1.SSSx1.p1.10.1.m1.1b"><apply id="Sx4.SSx1.SSSx1.p1.10.1.m1.1.1.cmml" xref="Sx4.SSx1.SSSx1.p1.10.1.m1.1.1"><csymbol cd="ambiguous" id="Sx4.SSx1.SSSx1.p1.10.1.m1.1.1.1.cmml" xref="Sx4.SSx1.SSSx1.p1.10.1.m1.1.1">subscript</csymbol><apply id="Sx4.SSx1.SSSx1.p1.10.1.m1.1.1.2.cmml" xref="Sx4.SSx1.SSSx1.p1.10.1.m1.1.1"><csymbol cd="ambiguous" id="Sx4.SSx1.SSSx1.p1.10.1.m1.1.1.2.1.cmml" xref="Sx4.SSx1.SSSx1.p1.10.1.m1.1.1">superscript</csymbol><csymbol cd="latexml" id="Sx4.SSx1.SSSx1.p1.10.1.m1.1.1.2.2.cmml" xref="Sx4.SSx1.SSSx1.p1.10.1.m1.1.1.2.2">absent</csymbol><apply id="Sx4.SSx1.SSSx1.p1.10.1.m1.1.1.2.3.cmml" xref="Sx4.SSx1.SSSx1.p1.10.1.m1.1.1.2.3"><csymbol cd="ambiguous" id="Sx4.SSx1.SSSx1.p1.10.1.m1.1.1.2.3.1.cmml" xref="Sx4.SSx1.SSSx1.p1.10.1.m1.1.1.2.3">subscript</csymbol><ci id="Sx4.SSx1.SSSx1.p1.10.1.m1.1.1.2.3.2.cmml" xref="Sx4.SSx1.SSSx1.p1.10.1.m1.1.1.2.3.2">𝑟</ci><ci id="Sx4.SSx1.SSSx1.p1.10.1.m1.1.1.2.3.3.cmml" xref="Sx4.SSx1.SSSx1.p1.10.1.m1.1.1.2.3.3">𝑖</ci></apply></apply><ci id="Sx4.SSx1.SSSx1.p1.10.1.m1.1.1.3.cmml" xref="Sx4.SSx1.SSSx1.p1.10.1.m1.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx4.SSx1.SSSx1.p1.10.1.m1.1c">{}^{r_{i}}_{k}</annotation></semantics></math>]</span>, corresponding to the region label of the <math id="Sx4.SSx1.SSSx1.p1.11.m5.1" class="ltx_Math" alttext="i" display="inline"><semantics id="Sx4.SSx1.SSSx1.p1.11.m5.1a"><mi id="Sx4.SSx1.SSSx1.p1.11.m5.1.1" xref="Sx4.SSx1.SSSx1.p1.11.m5.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="Sx4.SSx1.SSSx1.p1.11.m5.1b"><ci id="Sx4.SSx1.SSSx1.p1.11.m5.1.1.cmml" xref="Sx4.SSx1.SSSx1.p1.11.m5.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx4.SSx1.SSSx1.p1.11.m5.1c">i</annotation></semantics></math>-th region <math id="Sx4.SSx1.SSSx1.p1.12.m6.1" class="ltx_Math" alttext="r_{i}" display="inline"><semantics id="Sx4.SSx1.SSSx1.p1.12.m6.1a"><msub id="Sx4.SSx1.SSSx1.p1.12.m6.1.1" xref="Sx4.SSx1.SSSx1.p1.12.m6.1.1.cmml"><mi id="Sx4.SSx1.SSSx1.p1.12.m6.1.1.2" xref="Sx4.SSx1.SSSx1.p1.12.m6.1.1.2.cmml">r</mi><mi id="Sx4.SSx1.SSSx1.p1.12.m6.1.1.3" xref="Sx4.SSx1.SSSx1.p1.12.m6.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="Sx4.SSx1.SSSx1.p1.12.m6.1b"><apply id="Sx4.SSx1.SSSx1.p1.12.m6.1.1.cmml" xref="Sx4.SSx1.SSSx1.p1.12.m6.1.1"><csymbol cd="ambiguous" id="Sx4.SSx1.SSSx1.p1.12.m6.1.1.1.cmml" xref="Sx4.SSx1.SSSx1.p1.12.m6.1.1">subscript</csymbol><ci id="Sx4.SSx1.SSSx1.p1.12.m6.1.1.2.cmml" xref="Sx4.SSx1.SSSx1.p1.12.m6.1.1.2">𝑟</ci><ci id="Sx4.SSx1.SSSx1.p1.12.m6.1.1.3.cmml" xref="Sx4.SSx1.SSSx1.p1.12.m6.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx4.SSx1.SSSx1.p1.12.m6.1c">r_{i}</annotation></semantics></math> in <math id="Sx4.SSx1.SSSx1.p1.13.m7.1" class="ltx_Math" alttext="k" display="inline"><semantics id="Sx4.SSx1.SSSx1.p1.13.m7.1a"><mi id="Sx4.SSx1.SSSx1.p1.13.m7.1.1" xref="Sx4.SSx1.SSSx1.p1.13.m7.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="Sx4.SSx1.SSSx1.p1.13.m7.1b"><ci id="Sx4.SSx1.SSSx1.p1.13.m7.1.1.cmml" xref="Sx4.SSx1.SSSx1.p1.13.m7.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx4.SSx1.SSSx1.p1.13.m7.1c">k</annotation></semantics></math>-th page, before the OCR tokens <math id="Sx4.SSx1.SSSx1.p1.14.m8.1" class="ltx_Math" alttext="\mathbf{W}^{r_{i}}_{k}" display="inline"><semantics id="Sx4.SSx1.SSSx1.p1.14.m8.1a"><msubsup id="Sx4.SSx1.SSSx1.p1.14.m8.1.1" xref="Sx4.SSx1.SSSx1.p1.14.m8.1.1.cmml"><mi id="Sx4.SSx1.SSSx1.p1.14.m8.1.1.2.2" xref="Sx4.SSx1.SSSx1.p1.14.m8.1.1.2.2.cmml">𝐖</mi><mi id="Sx4.SSx1.SSSx1.p1.14.m8.1.1.3" xref="Sx4.SSx1.SSSx1.p1.14.m8.1.1.3.cmml">k</mi><msub id="Sx4.SSx1.SSSx1.p1.14.m8.1.1.2.3" xref="Sx4.SSx1.SSSx1.p1.14.m8.1.1.2.3.cmml"><mi id="Sx4.SSx1.SSSx1.p1.14.m8.1.1.2.3.2" xref="Sx4.SSx1.SSSx1.p1.14.m8.1.1.2.3.2.cmml">r</mi><mi id="Sx4.SSx1.SSSx1.p1.14.m8.1.1.2.3.3" xref="Sx4.SSx1.SSSx1.p1.14.m8.1.1.2.3.3.cmml">i</mi></msub></msubsup><annotation-xml encoding="MathML-Content" id="Sx4.SSx1.SSSx1.p1.14.m8.1b"><apply id="Sx4.SSx1.SSSx1.p1.14.m8.1.1.cmml" xref="Sx4.SSx1.SSSx1.p1.14.m8.1.1"><csymbol cd="ambiguous" id="Sx4.SSx1.SSSx1.p1.14.m8.1.1.1.cmml" xref="Sx4.SSx1.SSSx1.p1.14.m8.1.1">subscript</csymbol><apply id="Sx4.SSx1.SSSx1.p1.14.m8.1.1.2.cmml" xref="Sx4.SSx1.SSSx1.p1.14.m8.1.1"><csymbol cd="ambiguous" id="Sx4.SSx1.SSSx1.p1.14.m8.1.1.2.1.cmml" xref="Sx4.SSx1.SSSx1.p1.14.m8.1.1">superscript</csymbol><ci id="Sx4.SSx1.SSSx1.p1.14.m8.1.1.2.2.cmml" xref="Sx4.SSx1.SSSx1.p1.14.m8.1.1.2.2">𝐖</ci><apply id="Sx4.SSx1.SSSx1.p1.14.m8.1.1.2.3.cmml" xref="Sx4.SSx1.SSSx1.p1.14.m8.1.1.2.3"><csymbol cd="ambiguous" id="Sx4.SSx1.SSSx1.p1.14.m8.1.1.2.3.1.cmml" xref="Sx4.SSx1.SSSx1.p1.14.m8.1.1.2.3">subscript</csymbol><ci id="Sx4.SSx1.SSSx1.p1.14.m8.1.1.2.3.2.cmml" xref="Sx4.SSx1.SSSx1.p1.14.m8.1.1.2.3.2">𝑟</ci><ci id="Sx4.SSx1.SSSx1.p1.14.m8.1.1.2.3.3.cmml" xref="Sx4.SSx1.SSSx1.p1.14.m8.1.1.2.3.3">𝑖</ci></apply></apply><ci id="Sx4.SSx1.SSSx1.p1.14.m8.1.1.3.cmml" xref="Sx4.SSx1.SSSx1.p1.14.m8.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx4.SSx1.SSSx1.p1.14.m8.1c">\mathbf{W}^{r_{i}}_{k}</annotation></semantics></math> extracted in <math id="Sx4.SSx1.SSSx1.p1.15.m9.1" class="ltx_Math" alttext="r_{i}" display="inline"><semantics id="Sx4.SSx1.SSSx1.p1.15.m9.1a"><msub id="Sx4.SSx1.SSSx1.p1.15.m9.1.1" xref="Sx4.SSx1.SSSx1.p1.15.m9.1.1.cmml"><mi id="Sx4.SSx1.SSSx1.p1.15.m9.1.1.2" xref="Sx4.SSx1.SSSx1.p1.15.m9.1.1.2.cmml">r</mi><mi id="Sx4.SSx1.SSSx1.p1.15.m9.1.1.3" xref="Sx4.SSx1.SSSx1.p1.15.m9.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="Sx4.SSx1.SSSx1.p1.15.m9.1b"><apply id="Sx4.SSx1.SSSx1.p1.15.m9.1.1.cmml" xref="Sx4.SSx1.SSSx1.p1.15.m9.1.1"><csymbol cd="ambiguous" id="Sx4.SSx1.SSSx1.p1.15.m9.1.1.1.cmml" xref="Sx4.SSx1.SSSx1.p1.15.m9.1.1">subscript</csymbol><ci id="Sx4.SSx1.SSSx1.p1.15.m9.1.1.2.cmml" xref="Sx4.SSx1.SSSx1.p1.15.m9.1.1.2">𝑟</ci><ci id="Sx4.SSx1.SSSx1.p1.15.m9.1.1.3.cmml" xref="Sx4.SSx1.SSSx1.p1.15.m9.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx4.SSx1.SSSx1.p1.15.m9.1c">r_{i}</annotation></semantics></math>:</p>
<table id="Sx4.Ex2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="Sx4.Ex2.m1.7" class="ltx_Math" alttext="c_{k}=([{\rm\texttt{R}}^{r_{1}}_{k}],\mathbf{W}^{r_{1}}_{k},[{\rm\texttt{R}}^{r_{2}}_{k}],\mathbf{W}^{r_{2}}_{k},\dots,[{\rm\texttt{R}}^{r_{N}}_{k}],\mathbf{W}^{r_{N}}_{k})" display="block"><semantics id="Sx4.Ex2.m1.7a"><mrow id="Sx4.Ex2.m1.7.7" xref="Sx4.Ex2.m1.7.7.cmml"><msub id="Sx4.Ex2.m1.7.7.8" xref="Sx4.Ex2.m1.7.7.8.cmml"><mi id="Sx4.Ex2.m1.7.7.8.2" xref="Sx4.Ex2.m1.7.7.8.2.cmml">c</mi><mi id="Sx4.Ex2.m1.7.7.8.3" xref="Sx4.Ex2.m1.7.7.8.3.cmml">k</mi></msub><mo id="Sx4.Ex2.m1.7.7.7" xref="Sx4.Ex2.m1.7.7.7.cmml">=</mo><mrow id="Sx4.Ex2.m1.7.7.6.6" xref="Sx4.Ex2.m1.7.7.6.7.cmml"><mo stretchy="false" id="Sx4.Ex2.m1.7.7.6.6.7" xref="Sx4.Ex2.m1.7.7.6.7.cmml">(</mo><mrow id="Sx4.Ex2.m1.2.2.1.1.1.1" xref="Sx4.Ex2.m1.2.2.1.1.1.2.cmml"><mo stretchy="false" id="Sx4.Ex2.m1.2.2.1.1.1.1.2" xref="Sx4.Ex2.m1.2.2.1.1.1.2.1.cmml">[</mo><msubsup id="Sx4.Ex2.m1.2.2.1.1.1.1.1" xref="Sx4.Ex2.m1.2.2.1.1.1.1.1.cmml"><mtext class="ltx_mathvariant_monospace" id="Sx4.Ex2.m1.2.2.1.1.1.1.1.2.2" xref="Sx4.Ex2.m1.2.2.1.1.1.1.1.2.2a.cmml">R</mtext><mi id="Sx4.Ex2.m1.2.2.1.1.1.1.1.3" xref="Sx4.Ex2.m1.2.2.1.1.1.1.1.3.cmml">k</mi><msub id="Sx4.Ex2.m1.2.2.1.1.1.1.1.2.3" xref="Sx4.Ex2.m1.2.2.1.1.1.1.1.2.3.cmml"><mi id="Sx4.Ex2.m1.2.2.1.1.1.1.1.2.3.2" xref="Sx4.Ex2.m1.2.2.1.1.1.1.1.2.3.2.cmml">r</mi><mn id="Sx4.Ex2.m1.2.2.1.1.1.1.1.2.3.3" xref="Sx4.Ex2.m1.2.2.1.1.1.1.1.2.3.3.cmml">1</mn></msub></msubsup><mo stretchy="false" id="Sx4.Ex2.m1.2.2.1.1.1.1.3" xref="Sx4.Ex2.m1.2.2.1.1.1.2.1.cmml">]</mo></mrow><mo id="Sx4.Ex2.m1.7.7.6.6.8" xref="Sx4.Ex2.m1.7.7.6.7.cmml">,</mo><msubsup id="Sx4.Ex2.m1.3.3.2.2.2" xref="Sx4.Ex2.m1.3.3.2.2.2.cmml"><mi id="Sx4.Ex2.m1.3.3.2.2.2.2.2" xref="Sx4.Ex2.m1.3.3.2.2.2.2.2.cmml">𝐖</mi><mi id="Sx4.Ex2.m1.3.3.2.2.2.3" xref="Sx4.Ex2.m1.3.3.2.2.2.3.cmml">k</mi><msub id="Sx4.Ex2.m1.3.3.2.2.2.2.3" xref="Sx4.Ex2.m1.3.3.2.2.2.2.3.cmml"><mi id="Sx4.Ex2.m1.3.3.2.2.2.2.3.2" xref="Sx4.Ex2.m1.3.3.2.2.2.2.3.2.cmml">r</mi><mn id="Sx4.Ex2.m1.3.3.2.2.2.2.3.3" xref="Sx4.Ex2.m1.3.3.2.2.2.2.3.3.cmml">1</mn></msub></msubsup><mo id="Sx4.Ex2.m1.7.7.6.6.9" xref="Sx4.Ex2.m1.7.7.6.7.cmml">,</mo><mrow id="Sx4.Ex2.m1.4.4.3.3.3.1" xref="Sx4.Ex2.m1.4.4.3.3.3.2.cmml"><mo stretchy="false" id="Sx4.Ex2.m1.4.4.3.3.3.1.2" xref="Sx4.Ex2.m1.4.4.3.3.3.2.1.cmml">[</mo><msubsup id="Sx4.Ex2.m1.4.4.3.3.3.1.1" xref="Sx4.Ex2.m1.4.4.3.3.3.1.1.cmml"><mtext class="ltx_mathvariant_monospace" id="Sx4.Ex2.m1.4.4.3.3.3.1.1.2.2" xref="Sx4.Ex2.m1.4.4.3.3.3.1.1.2.2a.cmml">R</mtext><mi id="Sx4.Ex2.m1.4.4.3.3.3.1.1.3" xref="Sx4.Ex2.m1.4.4.3.3.3.1.1.3.cmml">k</mi><msub id="Sx4.Ex2.m1.4.4.3.3.3.1.1.2.3" xref="Sx4.Ex2.m1.4.4.3.3.3.1.1.2.3.cmml"><mi id="Sx4.Ex2.m1.4.4.3.3.3.1.1.2.3.2" xref="Sx4.Ex2.m1.4.4.3.3.3.1.1.2.3.2.cmml">r</mi><mn id="Sx4.Ex2.m1.4.4.3.3.3.1.1.2.3.3" xref="Sx4.Ex2.m1.4.4.3.3.3.1.1.2.3.3.cmml">2</mn></msub></msubsup><mo stretchy="false" id="Sx4.Ex2.m1.4.4.3.3.3.1.3" xref="Sx4.Ex2.m1.4.4.3.3.3.2.1.cmml">]</mo></mrow><mo id="Sx4.Ex2.m1.7.7.6.6.10" xref="Sx4.Ex2.m1.7.7.6.7.cmml">,</mo><msubsup id="Sx4.Ex2.m1.5.5.4.4.4" xref="Sx4.Ex2.m1.5.5.4.4.4.cmml"><mi id="Sx4.Ex2.m1.5.5.4.4.4.2.2" xref="Sx4.Ex2.m1.5.5.4.4.4.2.2.cmml">𝐖</mi><mi id="Sx4.Ex2.m1.5.5.4.4.4.3" xref="Sx4.Ex2.m1.5.5.4.4.4.3.cmml">k</mi><msub id="Sx4.Ex2.m1.5.5.4.4.4.2.3" xref="Sx4.Ex2.m1.5.5.4.4.4.2.3.cmml"><mi id="Sx4.Ex2.m1.5.5.4.4.4.2.3.2" xref="Sx4.Ex2.m1.5.5.4.4.4.2.3.2.cmml">r</mi><mn id="Sx4.Ex2.m1.5.5.4.4.4.2.3.3" xref="Sx4.Ex2.m1.5.5.4.4.4.2.3.3.cmml">2</mn></msub></msubsup><mo id="Sx4.Ex2.m1.7.7.6.6.11" xref="Sx4.Ex2.m1.7.7.6.7.cmml">,</mo><mi mathvariant="normal" id="Sx4.Ex2.m1.1.1" xref="Sx4.Ex2.m1.1.1.cmml">…</mi><mo id="Sx4.Ex2.m1.7.7.6.6.12" xref="Sx4.Ex2.m1.7.7.6.7.cmml">,</mo><mrow id="Sx4.Ex2.m1.6.6.5.5.5.1" xref="Sx4.Ex2.m1.6.6.5.5.5.2.cmml"><mo stretchy="false" id="Sx4.Ex2.m1.6.6.5.5.5.1.2" xref="Sx4.Ex2.m1.6.6.5.5.5.2.1.cmml">[</mo><msubsup id="Sx4.Ex2.m1.6.6.5.5.5.1.1" xref="Sx4.Ex2.m1.6.6.5.5.5.1.1.cmml"><mtext class="ltx_mathvariant_monospace" id="Sx4.Ex2.m1.6.6.5.5.5.1.1.2.2" xref="Sx4.Ex2.m1.6.6.5.5.5.1.1.2.2a.cmml">R</mtext><mi id="Sx4.Ex2.m1.6.6.5.5.5.1.1.3" xref="Sx4.Ex2.m1.6.6.5.5.5.1.1.3.cmml">k</mi><msub id="Sx4.Ex2.m1.6.6.5.5.5.1.1.2.3" xref="Sx4.Ex2.m1.6.6.5.5.5.1.1.2.3.cmml"><mi id="Sx4.Ex2.m1.6.6.5.5.5.1.1.2.3.2" xref="Sx4.Ex2.m1.6.6.5.5.5.1.1.2.3.2.cmml">r</mi><mi id="Sx4.Ex2.m1.6.6.5.5.5.1.1.2.3.3" xref="Sx4.Ex2.m1.6.6.5.5.5.1.1.2.3.3.cmml">N</mi></msub></msubsup><mo stretchy="false" id="Sx4.Ex2.m1.6.6.5.5.5.1.3" xref="Sx4.Ex2.m1.6.6.5.5.5.2.1.cmml">]</mo></mrow><mo id="Sx4.Ex2.m1.7.7.6.6.13" xref="Sx4.Ex2.m1.7.7.6.7.cmml">,</mo><msubsup id="Sx4.Ex2.m1.7.7.6.6.6" xref="Sx4.Ex2.m1.7.7.6.6.6.cmml"><mi id="Sx4.Ex2.m1.7.7.6.6.6.2.2" xref="Sx4.Ex2.m1.7.7.6.6.6.2.2.cmml">𝐖</mi><mi id="Sx4.Ex2.m1.7.7.6.6.6.3" xref="Sx4.Ex2.m1.7.7.6.6.6.3.cmml">k</mi><msub id="Sx4.Ex2.m1.7.7.6.6.6.2.3" xref="Sx4.Ex2.m1.7.7.6.6.6.2.3.cmml"><mi id="Sx4.Ex2.m1.7.7.6.6.6.2.3.2" xref="Sx4.Ex2.m1.7.7.6.6.6.2.3.2.cmml">r</mi><mi id="Sx4.Ex2.m1.7.7.6.6.6.2.3.3" xref="Sx4.Ex2.m1.7.7.6.6.6.2.3.3.cmml">N</mi></msub></msubsup><mo stretchy="false" id="Sx4.Ex2.m1.7.7.6.6.14" xref="Sx4.Ex2.m1.7.7.6.7.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="Sx4.Ex2.m1.7b"><apply id="Sx4.Ex2.m1.7.7.cmml" xref="Sx4.Ex2.m1.7.7"><eq id="Sx4.Ex2.m1.7.7.7.cmml" xref="Sx4.Ex2.m1.7.7.7"></eq><apply id="Sx4.Ex2.m1.7.7.8.cmml" xref="Sx4.Ex2.m1.7.7.8"><csymbol cd="ambiguous" id="Sx4.Ex2.m1.7.7.8.1.cmml" xref="Sx4.Ex2.m1.7.7.8">subscript</csymbol><ci id="Sx4.Ex2.m1.7.7.8.2.cmml" xref="Sx4.Ex2.m1.7.7.8.2">𝑐</ci><ci id="Sx4.Ex2.m1.7.7.8.3.cmml" xref="Sx4.Ex2.m1.7.7.8.3">𝑘</ci></apply><vector id="Sx4.Ex2.m1.7.7.6.7.cmml" xref="Sx4.Ex2.m1.7.7.6.6"><apply id="Sx4.Ex2.m1.2.2.1.1.1.2.cmml" xref="Sx4.Ex2.m1.2.2.1.1.1.1"><csymbol cd="latexml" id="Sx4.Ex2.m1.2.2.1.1.1.2.1.cmml" xref="Sx4.Ex2.m1.2.2.1.1.1.1.2">delimited-[]</csymbol><apply id="Sx4.Ex2.m1.2.2.1.1.1.1.1.cmml" xref="Sx4.Ex2.m1.2.2.1.1.1.1.1"><csymbol cd="ambiguous" id="Sx4.Ex2.m1.2.2.1.1.1.1.1.1.cmml" xref="Sx4.Ex2.m1.2.2.1.1.1.1.1">subscript</csymbol><apply id="Sx4.Ex2.m1.2.2.1.1.1.1.1.2.cmml" xref="Sx4.Ex2.m1.2.2.1.1.1.1.1"><csymbol cd="ambiguous" id="Sx4.Ex2.m1.2.2.1.1.1.1.1.2.1.cmml" xref="Sx4.Ex2.m1.2.2.1.1.1.1.1">superscript</csymbol><ci id="Sx4.Ex2.m1.2.2.1.1.1.1.1.2.2a.cmml" xref="Sx4.Ex2.m1.2.2.1.1.1.1.1.2.2"><mtext class="ltx_mathvariant_monospace" id="Sx4.Ex2.m1.2.2.1.1.1.1.1.2.2.cmml" xref="Sx4.Ex2.m1.2.2.1.1.1.1.1.2.2">R</mtext></ci><apply id="Sx4.Ex2.m1.2.2.1.1.1.1.1.2.3.cmml" xref="Sx4.Ex2.m1.2.2.1.1.1.1.1.2.3"><csymbol cd="ambiguous" id="Sx4.Ex2.m1.2.2.1.1.1.1.1.2.3.1.cmml" xref="Sx4.Ex2.m1.2.2.1.1.1.1.1.2.3">subscript</csymbol><ci id="Sx4.Ex2.m1.2.2.1.1.1.1.1.2.3.2.cmml" xref="Sx4.Ex2.m1.2.2.1.1.1.1.1.2.3.2">𝑟</ci><cn type="integer" id="Sx4.Ex2.m1.2.2.1.1.1.1.1.2.3.3.cmml" xref="Sx4.Ex2.m1.2.2.1.1.1.1.1.2.3.3">1</cn></apply></apply><ci id="Sx4.Ex2.m1.2.2.1.1.1.1.1.3.cmml" xref="Sx4.Ex2.m1.2.2.1.1.1.1.1.3">𝑘</ci></apply></apply><apply id="Sx4.Ex2.m1.3.3.2.2.2.cmml" xref="Sx4.Ex2.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="Sx4.Ex2.m1.3.3.2.2.2.1.cmml" xref="Sx4.Ex2.m1.3.3.2.2.2">subscript</csymbol><apply id="Sx4.Ex2.m1.3.3.2.2.2.2.cmml" xref="Sx4.Ex2.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="Sx4.Ex2.m1.3.3.2.2.2.2.1.cmml" xref="Sx4.Ex2.m1.3.3.2.2.2">superscript</csymbol><ci id="Sx4.Ex2.m1.3.3.2.2.2.2.2.cmml" xref="Sx4.Ex2.m1.3.3.2.2.2.2.2">𝐖</ci><apply id="Sx4.Ex2.m1.3.3.2.2.2.2.3.cmml" xref="Sx4.Ex2.m1.3.3.2.2.2.2.3"><csymbol cd="ambiguous" id="Sx4.Ex2.m1.3.3.2.2.2.2.3.1.cmml" xref="Sx4.Ex2.m1.3.3.2.2.2.2.3">subscript</csymbol><ci id="Sx4.Ex2.m1.3.3.2.2.2.2.3.2.cmml" xref="Sx4.Ex2.m1.3.3.2.2.2.2.3.2">𝑟</ci><cn type="integer" id="Sx4.Ex2.m1.3.3.2.2.2.2.3.3.cmml" xref="Sx4.Ex2.m1.3.3.2.2.2.2.3.3">1</cn></apply></apply><ci id="Sx4.Ex2.m1.3.3.2.2.2.3.cmml" xref="Sx4.Ex2.m1.3.3.2.2.2.3">𝑘</ci></apply><apply id="Sx4.Ex2.m1.4.4.3.3.3.2.cmml" xref="Sx4.Ex2.m1.4.4.3.3.3.1"><csymbol cd="latexml" id="Sx4.Ex2.m1.4.4.3.3.3.2.1.cmml" xref="Sx4.Ex2.m1.4.4.3.3.3.1.2">delimited-[]</csymbol><apply id="Sx4.Ex2.m1.4.4.3.3.3.1.1.cmml" xref="Sx4.Ex2.m1.4.4.3.3.3.1.1"><csymbol cd="ambiguous" id="Sx4.Ex2.m1.4.4.3.3.3.1.1.1.cmml" xref="Sx4.Ex2.m1.4.4.3.3.3.1.1">subscript</csymbol><apply id="Sx4.Ex2.m1.4.4.3.3.3.1.1.2.cmml" xref="Sx4.Ex2.m1.4.4.3.3.3.1.1"><csymbol cd="ambiguous" id="Sx4.Ex2.m1.4.4.3.3.3.1.1.2.1.cmml" xref="Sx4.Ex2.m1.4.4.3.3.3.1.1">superscript</csymbol><ci id="Sx4.Ex2.m1.4.4.3.3.3.1.1.2.2a.cmml" xref="Sx4.Ex2.m1.4.4.3.3.3.1.1.2.2"><mtext class="ltx_mathvariant_monospace" id="Sx4.Ex2.m1.4.4.3.3.3.1.1.2.2.cmml" xref="Sx4.Ex2.m1.4.4.3.3.3.1.1.2.2">R</mtext></ci><apply id="Sx4.Ex2.m1.4.4.3.3.3.1.1.2.3.cmml" xref="Sx4.Ex2.m1.4.4.3.3.3.1.1.2.3"><csymbol cd="ambiguous" id="Sx4.Ex2.m1.4.4.3.3.3.1.1.2.3.1.cmml" xref="Sx4.Ex2.m1.4.4.3.3.3.1.1.2.3">subscript</csymbol><ci id="Sx4.Ex2.m1.4.4.3.3.3.1.1.2.3.2.cmml" xref="Sx4.Ex2.m1.4.4.3.3.3.1.1.2.3.2">𝑟</ci><cn type="integer" id="Sx4.Ex2.m1.4.4.3.3.3.1.1.2.3.3.cmml" xref="Sx4.Ex2.m1.4.4.3.3.3.1.1.2.3.3">2</cn></apply></apply><ci id="Sx4.Ex2.m1.4.4.3.3.3.1.1.3.cmml" xref="Sx4.Ex2.m1.4.4.3.3.3.1.1.3">𝑘</ci></apply></apply><apply id="Sx4.Ex2.m1.5.5.4.4.4.cmml" xref="Sx4.Ex2.m1.5.5.4.4.4"><csymbol cd="ambiguous" id="Sx4.Ex2.m1.5.5.4.4.4.1.cmml" xref="Sx4.Ex2.m1.5.5.4.4.4">subscript</csymbol><apply id="Sx4.Ex2.m1.5.5.4.4.4.2.cmml" xref="Sx4.Ex2.m1.5.5.4.4.4"><csymbol cd="ambiguous" id="Sx4.Ex2.m1.5.5.4.4.4.2.1.cmml" xref="Sx4.Ex2.m1.5.5.4.4.4">superscript</csymbol><ci id="Sx4.Ex2.m1.5.5.4.4.4.2.2.cmml" xref="Sx4.Ex2.m1.5.5.4.4.4.2.2">𝐖</ci><apply id="Sx4.Ex2.m1.5.5.4.4.4.2.3.cmml" xref="Sx4.Ex2.m1.5.5.4.4.4.2.3"><csymbol cd="ambiguous" id="Sx4.Ex2.m1.5.5.4.4.4.2.3.1.cmml" xref="Sx4.Ex2.m1.5.5.4.4.4.2.3">subscript</csymbol><ci id="Sx4.Ex2.m1.5.5.4.4.4.2.3.2.cmml" xref="Sx4.Ex2.m1.5.5.4.4.4.2.3.2">𝑟</ci><cn type="integer" id="Sx4.Ex2.m1.5.5.4.4.4.2.3.3.cmml" xref="Sx4.Ex2.m1.5.5.4.4.4.2.3.3">2</cn></apply></apply><ci id="Sx4.Ex2.m1.5.5.4.4.4.3.cmml" xref="Sx4.Ex2.m1.5.5.4.4.4.3">𝑘</ci></apply><ci id="Sx4.Ex2.m1.1.1.cmml" xref="Sx4.Ex2.m1.1.1">…</ci><apply id="Sx4.Ex2.m1.6.6.5.5.5.2.cmml" xref="Sx4.Ex2.m1.6.6.5.5.5.1"><csymbol cd="latexml" id="Sx4.Ex2.m1.6.6.5.5.5.2.1.cmml" xref="Sx4.Ex2.m1.6.6.5.5.5.1.2">delimited-[]</csymbol><apply id="Sx4.Ex2.m1.6.6.5.5.5.1.1.cmml" xref="Sx4.Ex2.m1.6.6.5.5.5.1.1"><csymbol cd="ambiguous" id="Sx4.Ex2.m1.6.6.5.5.5.1.1.1.cmml" xref="Sx4.Ex2.m1.6.6.5.5.5.1.1">subscript</csymbol><apply id="Sx4.Ex2.m1.6.6.5.5.5.1.1.2.cmml" xref="Sx4.Ex2.m1.6.6.5.5.5.1.1"><csymbol cd="ambiguous" id="Sx4.Ex2.m1.6.6.5.5.5.1.1.2.1.cmml" xref="Sx4.Ex2.m1.6.6.5.5.5.1.1">superscript</csymbol><ci id="Sx4.Ex2.m1.6.6.5.5.5.1.1.2.2a.cmml" xref="Sx4.Ex2.m1.6.6.5.5.5.1.1.2.2"><mtext class="ltx_mathvariant_monospace" id="Sx4.Ex2.m1.6.6.5.5.5.1.1.2.2.cmml" xref="Sx4.Ex2.m1.6.6.5.5.5.1.1.2.2">R</mtext></ci><apply id="Sx4.Ex2.m1.6.6.5.5.5.1.1.2.3.cmml" xref="Sx4.Ex2.m1.6.6.5.5.5.1.1.2.3"><csymbol cd="ambiguous" id="Sx4.Ex2.m1.6.6.5.5.5.1.1.2.3.1.cmml" xref="Sx4.Ex2.m1.6.6.5.5.5.1.1.2.3">subscript</csymbol><ci id="Sx4.Ex2.m1.6.6.5.5.5.1.1.2.3.2.cmml" xref="Sx4.Ex2.m1.6.6.5.5.5.1.1.2.3.2">𝑟</ci><ci id="Sx4.Ex2.m1.6.6.5.5.5.1.1.2.3.3.cmml" xref="Sx4.Ex2.m1.6.6.5.5.5.1.1.2.3.3">𝑁</ci></apply></apply><ci id="Sx4.Ex2.m1.6.6.5.5.5.1.1.3.cmml" xref="Sx4.Ex2.m1.6.6.5.5.5.1.1.3">𝑘</ci></apply></apply><apply id="Sx4.Ex2.m1.7.7.6.6.6.cmml" xref="Sx4.Ex2.m1.7.7.6.6.6"><csymbol cd="ambiguous" id="Sx4.Ex2.m1.7.7.6.6.6.1.cmml" xref="Sx4.Ex2.m1.7.7.6.6.6">subscript</csymbol><apply id="Sx4.Ex2.m1.7.7.6.6.6.2.cmml" xref="Sx4.Ex2.m1.7.7.6.6.6"><csymbol cd="ambiguous" id="Sx4.Ex2.m1.7.7.6.6.6.2.1.cmml" xref="Sx4.Ex2.m1.7.7.6.6.6">superscript</csymbol><ci id="Sx4.Ex2.m1.7.7.6.6.6.2.2.cmml" xref="Sx4.Ex2.m1.7.7.6.6.6.2.2">𝐖</ci><apply id="Sx4.Ex2.m1.7.7.6.6.6.2.3.cmml" xref="Sx4.Ex2.m1.7.7.6.6.6.2.3"><csymbol cd="ambiguous" id="Sx4.Ex2.m1.7.7.6.6.6.2.3.1.cmml" xref="Sx4.Ex2.m1.7.7.6.6.6.2.3">subscript</csymbol><ci id="Sx4.Ex2.m1.7.7.6.6.6.2.3.2.cmml" xref="Sx4.Ex2.m1.7.7.6.6.6.2.3.2">𝑟</ci><ci id="Sx4.Ex2.m1.7.7.6.6.6.2.3.3.cmml" xref="Sx4.Ex2.m1.7.7.6.6.6.2.3.3">𝑁</ci></apply></apply><ci id="Sx4.Ex2.m1.7.7.6.6.6.3.cmml" xref="Sx4.Ex2.m1.7.7.6.6.6.3">𝑘</ci></apply></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx4.Ex2.m1.7c">c_{k}=([{\rm\texttt{R}}^{r_{1}}_{k}],\mathbf{W}^{r_{1}}_{k},[{\rm\texttt{R}}^{r_{2}}_{k}],\mathbf{W}^{r_{2}}_{k},\dots,[{\rm\texttt{R}}^{r_{N}}_{k}],\mathbf{W}^{r_{N}}_{k})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
</section>
<section id="Sx4.SSx1.SSSx2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Input embedding.</h4>

<div id="Sx4.SSx1.SSSx2.p1" class="ltx_para">
<p id="Sx4.SSx1.SSSx2.p1.5" class="ltx_p">Following LayoutT5 <cite class="ltx_cite ltx_citemacro_citep">(Tanaka, Nishida, and Yoshida <a href="#bib.bib35" title="" class="ltx_ref">2021</a>)</cite>, the input embeddings <math id="Sx4.SSx1.SSSx2.p1.1.m1.1" class="ltx_Math" alttext="\mathbf{z}" display="inline"><semantics id="Sx4.SSx1.SSSx2.p1.1.m1.1a"><mi id="Sx4.SSx1.SSSx2.p1.1.m1.1.1" xref="Sx4.SSx1.SSSx2.p1.1.m1.1.1.cmml">𝐳</mi><annotation-xml encoding="MathML-Content" id="Sx4.SSx1.SSSx2.p1.1.m1.1b"><ci id="Sx4.SSx1.SSSx2.p1.1.m1.1.1.cmml" xref="Sx4.SSx1.SSSx2.p1.1.m1.1.1">𝐳</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx4.SSx1.SSSx2.p1.1.m1.1c">\mathbf{z}</annotation></semantics></math> of the encoder are defined by utilizing multi-modal information, including token <math id="Sx4.SSx1.SSSx2.p1.2.m2.1" class="ltx_Math" alttext="\mathbf{z}^{{\rm token}}" display="inline"><semantics id="Sx4.SSx1.SSSx2.p1.2.m2.1a"><msup id="Sx4.SSx1.SSSx2.p1.2.m2.1.1" xref="Sx4.SSx1.SSSx2.p1.2.m2.1.1.cmml"><mi id="Sx4.SSx1.SSSx2.p1.2.m2.1.1.2" xref="Sx4.SSx1.SSSx2.p1.2.m2.1.1.2.cmml">𝐳</mi><mi id="Sx4.SSx1.SSSx2.p1.2.m2.1.1.3" xref="Sx4.SSx1.SSSx2.p1.2.m2.1.1.3.cmml">token</mi></msup><annotation-xml encoding="MathML-Content" id="Sx4.SSx1.SSSx2.p1.2.m2.1b"><apply id="Sx4.SSx1.SSSx2.p1.2.m2.1.1.cmml" xref="Sx4.SSx1.SSSx2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="Sx4.SSx1.SSSx2.p1.2.m2.1.1.1.cmml" xref="Sx4.SSx1.SSSx2.p1.2.m2.1.1">superscript</csymbol><ci id="Sx4.SSx1.SSSx2.p1.2.m2.1.1.2.cmml" xref="Sx4.SSx1.SSSx2.p1.2.m2.1.1.2">𝐳</ci><ci id="Sx4.SSx1.SSSx2.p1.2.m2.1.1.3.cmml" xref="Sx4.SSx1.SSSx2.p1.2.m2.1.1.3">token</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx4.SSx1.SSSx2.p1.2.m2.1c">\mathbf{z}^{{\rm token}}</annotation></semantics></math>, segment <math id="Sx4.SSx1.SSSx2.p1.3.m3.1" class="ltx_Math" alttext="\mathbf{z}^{{\rm seg}}" display="inline"><semantics id="Sx4.SSx1.SSSx2.p1.3.m3.1a"><msup id="Sx4.SSx1.SSSx2.p1.3.m3.1.1" xref="Sx4.SSx1.SSSx2.p1.3.m3.1.1.cmml"><mi id="Sx4.SSx1.SSSx2.p1.3.m3.1.1.2" xref="Sx4.SSx1.SSSx2.p1.3.m3.1.1.2.cmml">𝐳</mi><mi id="Sx4.SSx1.SSSx2.p1.3.m3.1.1.3" xref="Sx4.SSx1.SSSx2.p1.3.m3.1.1.3.cmml">seg</mi></msup><annotation-xml encoding="MathML-Content" id="Sx4.SSx1.SSSx2.p1.3.m3.1b"><apply id="Sx4.SSx1.SSSx2.p1.3.m3.1.1.cmml" xref="Sx4.SSx1.SSSx2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="Sx4.SSx1.SSSx2.p1.3.m3.1.1.1.cmml" xref="Sx4.SSx1.SSSx2.p1.3.m3.1.1">superscript</csymbol><ci id="Sx4.SSx1.SSSx2.p1.3.m3.1.1.2.cmml" xref="Sx4.SSx1.SSSx2.p1.3.m3.1.1.2">𝐳</ci><ci id="Sx4.SSx1.SSSx2.p1.3.m3.1.1.3.cmml" xref="Sx4.SSx1.SSSx2.p1.3.m3.1.1.3">seg</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx4.SSx1.SSSx2.p1.3.m3.1c">\mathbf{z}^{{\rm seg}}</annotation></semantics></math>, layout <math id="Sx4.SSx1.SSSx2.p1.4.m4.1" class="ltx_Math" alttext="\mathbf{z}^{{\rm lay}}" display="inline"><semantics id="Sx4.SSx1.SSSx2.p1.4.m4.1a"><msup id="Sx4.SSx1.SSSx2.p1.4.m4.1.1" xref="Sx4.SSx1.SSSx2.p1.4.m4.1.1.cmml"><mi id="Sx4.SSx1.SSSx2.p1.4.m4.1.1.2" xref="Sx4.SSx1.SSSx2.p1.4.m4.1.1.2.cmml">𝐳</mi><mi id="Sx4.SSx1.SSSx2.p1.4.m4.1.1.3" xref="Sx4.SSx1.SSSx2.p1.4.m4.1.1.3.cmml">lay</mi></msup><annotation-xml encoding="MathML-Content" id="Sx4.SSx1.SSSx2.p1.4.m4.1b"><apply id="Sx4.SSx1.SSSx2.p1.4.m4.1.1.cmml" xref="Sx4.SSx1.SSSx2.p1.4.m4.1.1"><csymbol cd="ambiguous" id="Sx4.SSx1.SSSx2.p1.4.m4.1.1.1.cmml" xref="Sx4.SSx1.SSSx2.p1.4.m4.1.1">superscript</csymbol><ci id="Sx4.SSx1.SSSx2.p1.4.m4.1.1.2.cmml" xref="Sx4.SSx1.SSSx2.p1.4.m4.1.1.2">𝐳</ci><ci id="Sx4.SSx1.SSSx2.p1.4.m4.1.1.3.cmml" xref="Sx4.SSx1.SSSx2.p1.4.m4.1.1.3">lay</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx4.SSx1.SSSx2.p1.4.m4.1c">\mathbf{z}^{{\rm lay}}</annotation></semantics></math>, and visual embeddings <math id="Sx4.SSx1.SSSx2.p1.5.m5.1" class="ltx_Math" alttext="\mathbf{z}^{{\rm vis}}" display="inline"><semantics id="Sx4.SSx1.SSSx2.p1.5.m5.1a"><msup id="Sx4.SSx1.SSSx2.p1.5.m5.1.1" xref="Sx4.SSx1.SSSx2.p1.5.m5.1.1.cmml"><mi id="Sx4.SSx1.SSSx2.p1.5.m5.1.1.2" xref="Sx4.SSx1.SSSx2.p1.5.m5.1.1.2.cmml">𝐳</mi><mi id="Sx4.SSx1.SSSx2.p1.5.m5.1.1.3" xref="Sx4.SSx1.SSSx2.p1.5.m5.1.1.3.cmml">vis</mi></msup><annotation-xml encoding="MathML-Content" id="Sx4.SSx1.SSSx2.p1.5.m5.1b"><apply id="Sx4.SSx1.SSSx2.p1.5.m5.1.1.cmml" xref="Sx4.SSx1.SSSx2.p1.5.m5.1.1"><csymbol cd="ambiguous" id="Sx4.SSx1.SSSx2.p1.5.m5.1.1.1.cmml" xref="Sx4.SSx1.SSSx2.p1.5.m5.1.1">superscript</csymbol><ci id="Sx4.SSx1.SSSx2.p1.5.m5.1.1.2.cmml" xref="Sx4.SSx1.SSSx2.p1.5.m5.1.1.2">𝐳</ci><ci id="Sx4.SSx1.SSSx2.p1.5.m5.1.1.3.cmml" xref="Sx4.SSx1.SSSx2.p1.5.m5.1.1.3">vis</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx4.SSx1.SSSx2.p1.5.m5.1c">\mathbf{z}^{{\rm vis}}</annotation></semantics></math> as follows:</p>
<table id="Sx4.Ex3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="Sx4.Ex3.m1.1" class="ltx_Math" alttext="\mathbf{z}={\rm LN}(\mathbf{z}^{{\rm token}}+\mathbf{z}^{{\rm seg}}+\mathbf{z}^{{\rm lay}}+\mathbf{z}^{{\rm vis}})\in\mathbb{R}^{L\times d}," display="block"><semantics id="Sx4.Ex3.m1.1a"><mrow id="Sx4.Ex3.m1.1.1.1" xref="Sx4.Ex3.m1.1.1.1.1.cmml"><mrow id="Sx4.Ex3.m1.1.1.1.1" xref="Sx4.Ex3.m1.1.1.1.1.cmml"><mi id="Sx4.Ex3.m1.1.1.1.1.3" xref="Sx4.Ex3.m1.1.1.1.1.3.cmml">𝐳</mi><mo id="Sx4.Ex3.m1.1.1.1.1.4" xref="Sx4.Ex3.m1.1.1.1.1.4.cmml">=</mo><mrow id="Sx4.Ex3.m1.1.1.1.1.1" xref="Sx4.Ex3.m1.1.1.1.1.1.cmml"><mi id="Sx4.Ex3.m1.1.1.1.1.1.3" xref="Sx4.Ex3.m1.1.1.1.1.1.3.cmml">LN</mi><mo lspace="0em" rspace="0em" id="Sx4.Ex3.m1.1.1.1.1.1.2" xref="Sx4.Ex3.m1.1.1.1.1.1.2.cmml">​</mo><mrow id="Sx4.Ex3.m1.1.1.1.1.1.1.1" xref="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="Sx4.Ex3.m1.1.1.1.1.1.1.1.2" xref="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="Sx4.Ex3.m1.1.1.1.1.1.1.1.1" xref="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.cmml"><msup id="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.2" xref="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.2.cmml"><mi id="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.2.2" xref="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.2.2.cmml">𝐳</mi><mi id="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.2.3" xref="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.2.3.cmml">token</mi></msup><mo id="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.1" xref="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.1.cmml">+</mo><msup id="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.3" xref="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.3.cmml"><mi id="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.3.2" xref="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.3.2.cmml">𝐳</mi><mi id="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.3.3" xref="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.3.3.cmml">seg</mi></msup><mo id="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.1a" xref="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.1.cmml">+</mo><msup id="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.4" xref="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.4.cmml"><mi id="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.4.2" xref="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.4.2.cmml">𝐳</mi><mi id="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.4.3" xref="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.4.3.cmml">lay</mi></msup><mo id="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.1b" xref="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.1.cmml">+</mo><msup id="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.5" xref="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.5.cmml"><mi id="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.5.2" xref="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.5.2.cmml">𝐳</mi><mi id="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.5.3" xref="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.5.3.cmml">vis</mi></msup></mrow><mo stretchy="false" id="Sx4.Ex3.m1.1.1.1.1.1.1.1.3" xref="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="Sx4.Ex3.m1.1.1.1.1.5" xref="Sx4.Ex3.m1.1.1.1.1.5.cmml">∈</mo><msup id="Sx4.Ex3.m1.1.1.1.1.6" xref="Sx4.Ex3.m1.1.1.1.1.6.cmml"><mi id="Sx4.Ex3.m1.1.1.1.1.6.2" xref="Sx4.Ex3.m1.1.1.1.1.6.2.cmml">ℝ</mi><mrow id="Sx4.Ex3.m1.1.1.1.1.6.3" xref="Sx4.Ex3.m1.1.1.1.1.6.3.cmml"><mi id="Sx4.Ex3.m1.1.1.1.1.6.3.2" xref="Sx4.Ex3.m1.1.1.1.1.6.3.2.cmml">L</mi><mo lspace="0.222em" rspace="0.222em" id="Sx4.Ex3.m1.1.1.1.1.6.3.1" xref="Sx4.Ex3.m1.1.1.1.1.6.3.1.cmml">×</mo><mi id="Sx4.Ex3.m1.1.1.1.1.6.3.3" xref="Sx4.Ex3.m1.1.1.1.1.6.3.3.cmml">d</mi></mrow></msup></mrow><mo id="Sx4.Ex3.m1.1.1.1.2" xref="Sx4.Ex3.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="Sx4.Ex3.m1.1b"><apply id="Sx4.Ex3.m1.1.1.1.1.cmml" xref="Sx4.Ex3.m1.1.1.1"><and id="Sx4.Ex3.m1.1.1.1.1a.cmml" xref="Sx4.Ex3.m1.1.1.1"></and><apply id="Sx4.Ex3.m1.1.1.1.1b.cmml" xref="Sx4.Ex3.m1.1.1.1"><eq id="Sx4.Ex3.m1.1.1.1.1.4.cmml" xref="Sx4.Ex3.m1.1.1.1.1.4"></eq><ci id="Sx4.Ex3.m1.1.1.1.1.3.cmml" xref="Sx4.Ex3.m1.1.1.1.1.3">𝐳</ci><apply id="Sx4.Ex3.m1.1.1.1.1.1.cmml" xref="Sx4.Ex3.m1.1.1.1.1.1"><times id="Sx4.Ex3.m1.1.1.1.1.1.2.cmml" xref="Sx4.Ex3.m1.1.1.1.1.1.2"></times><ci id="Sx4.Ex3.m1.1.1.1.1.1.3.cmml" xref="Sx4.Ex3.m1.1.1.1.1.1.3">LN</ci><apply id="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.cmml" xref="Sx4.Ex3.m1.1.1.1.1.1.1.1"><plus id="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.1.cmml" xref="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.1"></plus><apply id="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.2.cmml" xref="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.2.1.cmml" xref="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.2">superscript</csymbol><ci id="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.2.2.cmml" xref="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.2.2">𝐳</ci><ci id="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.2.3.cmml" xref="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.2.3">token</ci></apply><apply id="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.3.cmml" xref="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.3.1.cmml" xref="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.3">superscript</csymbol><ci id="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.3.2.cmml" xref="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.3.2">𝐳</ci><ci id="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.3.3.cmml" xref="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.3.3">seg</ci></apply><apply id="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.4.cmml" xref="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.4"><csymbol cd="ambiguous" id="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.4.1.cmml" xref="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.4">superscript</csymbol><ci id="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.4.2.cmml" xref="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.4.2">𝐳</ci><ci id="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.4.3.cmml" xref="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.4.3">lay</ci></apply><apply id="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.5.cmml" xref="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.5"><csymbol cd="ambiguous" id="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.5.1.cmml" xref="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.5">superscript</csymbol><ci id="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.5.2.cmml" xref="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.5.2">𝐳</ci><ci id="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.5.3.cmml" xref="Sx4.Ex3.m1.1.1.1.1.1.1.1.1.5.3">vis</ci></apply></apply></apply></apply><apply id="Sx4.Ex3.m1.1.1.1.1c.cmml" xref="Sx4.Ex3.m1.1.1.1"><in id="Sx4.Ex3.m1.1.1.1.1.5.cmml" xref="Sx4.Ex3.m1.1.1.1.1.5"></in><share href="#Sx4.Ex3.m1.1.1.1.1.1.cmml" id="Sx4.Ex3.m1.1.1.1.1d.cmml" xref="Sx4.Ex3.m1.1.1.1"></share><apply id="Sx4.Ex3.m1.1.1.1.1.6.cmml" xref="Sx4.Ex3.m1.1.1.1.1.6"><csymbol cd="ambiguous" id="Sx4.Ex3.m1.1.1.1.1.6.1.cmml" xref="Sx4.Ex3.m1.1.1.1.1.6">superscript</csymbol><ci id="Sx4.Ex3.m1.1.1.1.1.6.2.cmml" xref="Sx4.Ex3.m1.1.1.1.1.6.2">ℝ</ci><apply id="Sx4.Ex3.m1.1.1.1.1.6.3.cmml" xref="Sx4.Ex3.m1.1.1.1.1.6.3"><times id="Sx4.Ex3.m1.1.1.1.1.6.3.1.cmml" xref="Sx4.Ex3.m1.1.1.1.1.6.3.1"></times><ci id="Sx4.Ex3.m1.1.1.1.1.6.3.2.cmml" xref="Sx4.Ex3.m1.1.1.1.1.6.3.2">𝐿</ci><ci id="Sx4.Ex3.m1.1.1.1.1.6.3.3.cmml" xref="Sx4.Ex3.m1.1.1.1.1.6.3.3">𝑑</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx4.Ex3.m1.1c">\mathbf{z}={\rm LN}(\mathbf{z}^{{\rm token}}+\mathbf{z}^{{\rm seg}}+\mathbf{z}^{{\rm lay}}+\mathbf{z}^{{\rm vis}})\in\mathbb{R}^{L\times d},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="Sx4.SSx1.SSSx2.p1.7" class="ltx_p">where LN is a layer normalization <cite class="ltx_cite ltx_citemacro_citep">(Ba, Kiros, and Hinton <a href="#bib.bib1" title="" class="ltx_ref">2016</a>)</cite>, and <math id="Sx4.SSx1.SSSx2.p1.6.m1.1" class="ltx_Math" alttext="L" display="inline"><semantics id="Sx4.SSx1.SSSx2.p1.6.m1.1a"><mi id="Sx4.SSx1.SSSx2.p1.6.m1.1.1" xref="Sx4.SSx1.SSSx2.p1.6.m1.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="Sx4.SSx1.SSSx2.p1.6.m1.1b"><ci id="Sx4.SSx1.SSSx2.p1.6.m1.1.1.cmml" xref="Sx4.SSx1.SSSx2.p1.6.m1.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx4.SSx1.SSSx2.p1.6.m1.1c">L</annotation></semantics></math> and <math id="Sx4.SSx1.SSSx2.p1.7.m2.1" class="ltx_Math" alttext="d" display="inline"><semantics id="Sx4.SSx1.SSSx2.p1.7.m2.1a"><mi id="Sx4.SSx1.SSSx2.p1.7.m2.1.1" xref="Sx4.SSx1.SSSx2.p1.7.m2.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="Sx4.SSx1.SSSx2.p1.7.m2.1b"><ci id="Sx4.SSx1.SSSx2.p1.7.m2.1.1.cmml" xref="Sx4.SSx1.SSSx2.p1.7.m2.1.1">𝑑</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx4.SSx1.SSSx2.p1.7.m2.1c">d</annotation></semantics></math> are the length of the input sequence and a hidden vector size, respectively. The segment embedding indicates which regions are included in the input sequence. The layout embedding denotes the encoded bounding box coordinates of the token within the image. We normalize all coordinates by the size of images and use embedding layers to embed x-axis and y-axis features separately. The visual embedding is the appearance feature of each region and the OCR bounding boxes, which were obtained from Faster-RCNN. Note that the layout and visual embeddings are set to zero vectors for the task prefix, question, and page number.</p>
</div>
</section>
</section>
<section id="Sx4.SSx2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">Multi-modal Encoder-Decoder</h3>

<section id="Sx4.SSx2.SSSx1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Multi-modal encoder.</h4>

<div id="Sx4.SSx2.SSSx1.p1" class="ltx_para">
<p id="Sx4.SSx2.SSSx1.p1.5" class="ltx_p">Our encoder is a stack of <math id="Sx4.SSx2.SSSx1.p1.1.m1.1" class="ltx_Math" alttext="m" display="inline"><semantics id="Sx4.SSx2.SSSx1.p1.1.m1.1a"><mi id="Sx4.SSx2.SSSx1.p1.1.m1.1.1" xref="Sx4.SSx2.SSSx1.p1.1.m1.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="Sx4.SSx2.SSSx1.p1.1.m1.1b"><ci id="Sx4.SSx2.SSSx1.p1.1.m1.1.1.cmml" xref="Sx4.SSx2.SSSx1.p1.1.m1.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx4.SSx2.SSSx1.p1.1.m1.1c">m</annotation></semantics></math> Transformer blocks, consisting of a self-attention layer and a fully-connected layer with residual connections.
Following FiD <cite class="ltx_cite ltx_citemacro_citep">(Izacard and Grave <a href="#bib.bib12" title="" class="ltx_ref">2021</a>)</cite>, all <math id="Sx4.SSx2.SSSx1.p1.2.m2.1" class="ltx_Math" alttext="K" display="inline"><semantics id="Sx4.SSx2.SSSx1.p1.2.m2.1a"><mi id="Sx4.SSx2.SSSx1.p1.2.m2.1.1" xref="Sx4.SSx2.SSSx1.p1.2.m2.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="Sx4.SSx2.SSSx1.p1.2.m2.1b"><ci id="Sx4.SSx2.SSSx1.p1.2.m2.1.1.cmml" xref="Sx4.SSx2.SSSx1.p1.2.m2.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx4.SSx2.SSSx1.p1.2.m2.1c">K</annotation></semantics></math> input sequences are encoded independently and then
concatenated to form a unified input representation. Formally, we transform each input sequence <math id="Sx4.SSx2.SSSx1.p1.3.m3.1" class="ltx_Math" alttext="x_{k}" display="inline"><semantics id="Sx4.SSx2.SSSx1.p1.3.m3.1a"><msub id="Sx4.SSx2.SSSx1.p1.3.m3.1.1" xref="Sx4.SSx2.SSSx1.p1.3.m3.1.1.cmml"><mi id="Sx4.SSx2.SSSx1.p1.3.m3.1.1.2" xref="Sx4.SSx2.SSSx1.p1.3.m3.1.1.2.cmml">x</mi><mi id="Sx4.SSx2.SSSx1.p1.3.m3.1.1.3" xref="Sx4.SSx2.SSSx1.p1.3.m3.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="Sx4.SSx2.SSSx1.p1.3.m3.1b"><apply id="Sx4.SSx2.SSSx1.p1.3.m3.1.1.cmml" xref="Sx4.SSx2.SSSx1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="Sx4.SSx2.SSSx1.p1.3.m3.1.1.1.cmml" xref="Sx4.SSx2.SSSx1.p1.3.m3.1.1">subscript</csymbol><ci id="Sx4.SSx2.SSSx1.p1.3.m3.1.1.2.cmml" xref="Sx4.SSx2.SSSx1.p1.3.m3.1.1.2">𝑥</ci><ci id="Sx4.SSx2.SSSx1.p1.3.m3.1.1.3.cmml" xref="Sx4.SSx2.SSSx1.p1.3.m3.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx4.SSx2.SSSx1.p1.3.m3.1c">x_{k}</annotation></semantics></math> into <math id="Sx4.SSx2.SSSx1.p1.4.m4.1" class="ltx_Math" alttext="\mathbf{x}_{k}\in\mathbb{R}^{L\times d}" display="inline"><semantics id="Sx4.SSx2.SSSx1.p1.4.m4.1a"><mrow id="Sx4.SSx2.SSSx1.p1.4.m4.1.1" xref="Sx4.SSx2.SSSx1.p1.4.m4.1.1.cmml"><msub id="Sx4.SSx2.SSSx1.p1.4.m4.1.1.2" xref="Sx4.SSx2.SSSx1.p1.4.m4.1.1.2.cmml"><mi id="Sx4.SSx2.SSSx1.p1.4.m4.1.1.2.2" xref="Sx4.SSx2.SSSx1.p1.4.m4.1.1.2.2.cmml">𝐱</mi><mi id="Sx4.SSx2.SSSx1.p1.4.m4.1.1.2.3" xref="Sx4.SSx2.SSSx1.p1.4.m4.1.1.2.3.cmml">k</mi></msub><mo id="Sx4.SSx2.SSSx1.p1.4.m4.1.1.1" xref="Sx4.SSx2.SSSx1.p1.4.m4.1.1.1.cmml">∈</mo><msup id="Sx4.SSx2.SSSx1.p1.4.m4.1.1.3" xref="Sx4.SSx2.SSSx1.p1.4.m4.1.1.3.cmml"><mi id="Sx4.SSx2.SSSx1.p1.4.m4.1.1.3.2" xref="Sx4.SSx2.SSSx1.p1.4.m4.1.1.3.2.cmml">ℝ</mi><mrow id="Sx4.SSx2.SSSx1.p1.4.m4.1.1.3.3" xref="Sx4.SSx2.SSSx1.p1.4.m4.1.1.3.3.cmml"><mi id="Sx4.SSx2.SSSx1.p1.4.m4.1.1.3.3.2" xref="Sx4.SSx2.SSSx1.p1.4.m4.1.1.3.3.2.cmml">L</mi><mo lspace="0.222em" rspace="0.222em" id="Sx4.SSx2.SSSx1.p1.4.m4.1.1.3.3.1" xref="Sx4.SSx2.SSSx1.p1.4.m4.1.1.3.3.1.cmml">×</mo><mi id="Sx4.SSx2.SSSx1.p1.4.m4.1.1.3.3.3" xref="Sx4.SSx2.SSSx1.p1.4.m4.1.1.3.3.3.cmml">d</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="Sx4.SSx2.SSSx1.p1.4.m4.1b"><apply id="Sx4.SSx2.SSSx1.p1.4.m4.1.1.cmml" xref="Sx4.SSx2.SSSx1.p1.4.m4.1.1"><in id="Sx4.SSx2.SSSx1.p1.4.m4.1.1.1.cmml" xref="Sx4.SSx2.SSSx1.p1.4.m4.1.1.1"></in><apply id="Sx4.SSx2.SSSx1.p1.4.m4.1.1.2.cmml" xref="Sx4.SSx2.SSSx1.p1.4.m4.1.1.2"><csymbol cd="ambiguous" id="Sx4.SSx2.SSSx1.p1.4.m4.1.1.2.1.cmml" xref="Sx4.SSx2.SSSx1.p1.4.m4.1.1.2">subscript</csymbol><ci id="Sx4.SSx2.SSSx1.p1.4.m4.1.1.2.2.cmml" xref="Sx4.SSx2.SSSx1.p1.4.m4.1.1.2.2">𝐱</ci><ci id="Sx4.SSx2.SSSx1.p1.4.m4.1.1.2.3.cmml" xref="Sx4.SSx2.SSSx1.p1.4.m4.1.1.2.3">𝑘</ci></apply><apply id="Sx4.SSx2.SSSx1.p1.4.m4.1.1.3.cmml" xref="Sx4.SSx2.SSSx1.p1.4.m4.1.1.3"><csymbol cd="ambiguous" id="Sx4.SSx2.SSSx1.p1.4.m4.1.1.3.1.cmml" xref="Sx4.SSx2.SSSx1.p1.4.m4.1.1.3">superscript</csymbol><ci id="Sx4.SSx2.SSSx1.p1.4.m4.1.1.3.2.cmml" xref="Sx4.SSx2.SSSx1.p1.4.m4.1.1.3.2">ℝ</ci><apply id="Sx4.SSx2.SSSx1.p1.4.m4.1.1.3.3.cmml" xref="Sx4.SSx2.SSSx1.p1.4.m4.1.1.3.3"><times id="Sx4.SSx2.SSSx1.p1.4.m4.1.1.3.3.1.cmml" xref="Sx4.SSx2.SSSx1.p1.4.m4.1.1.3.3.1"></times><ci id="Sx4.SSx2.SSSx1.p1.4.m4.1.1.3.3.2.cmml" xref="Sx4.SSx2.SSSx1.p1.4.m4.1.1.3.3.2">𝐿</ci><ci id="Sx4.SSx2.SSSx1.p1.4.m4.1.1.3.3.3.cmml" xref="Sx4.SSx2.SSSx1.p1.4.m4.1.1.3.3.3">𝑑</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx4.SSx2.SSSx1.p1.4.m4.1c">\mathbf{x}_{k}\in\mathbb{R}^{L\times d}</annotation></semantics></math> and concatenate them into <math id="Sx4.SSx2.SSSx1.p1.5.m5.1" class="ltx_Math" alttext="\mathbf{X}\in\mathbb{R}^{K\times L\times d}" display="inline"><semantics id="Sx4.SSx2.SSSx1.p1.5.m5.1a"><mrow id="Sx4.SSx2.SSSx1.p1.5.m5.1.1" xref="Sx4.SSx2.SSSx1.p1.5.m5.1.1.cmml"><mi id="Sx4.SSx2.SSSx1.p1.5.m5.1.1.2" xref="Sx4.SSx2.SSSx1.p1.5.m5.1.1.2.cmml">𝐗</mi><mo id="Sx4.SSx2.SSSx1.p1.5.m5.1.1.1" xref="Sx4.SSx2.SSSx1.p1.5.m5.1.1.1.cmml">∈</mo><msup id="Sx4.SSx2.SSSx1.p1.5.m5.1.1.3" xref="Sx4.SSx2.SSSx1.p1.5.m5.1.1.3.cmml"><mi id="Sx4.SSx2.SSSx1.p1.5.m5.1.1.3.2" xref="Sx4.SSx2.SSSx1.p1.5.m5.1.1.3.2.cmml">ℝ</mi><mrow id="Sx4.SSx2.SSSx1.p1.5.m5.1.1.3.3" xref="Sx4.SSx2.SSSx1.p1.5.m5.1.1.3.3.cmml"><mi id="Sx4.SSx2.SSSx1.p1.5.m5.1.1.3.3.2" xref="Sx4.SSx2.SSSx1.p1.5.m5.1.1.3.3.2.cmml">K</mi><mo lspace="0.222em" rspace="0.222em" id="Sx4.SSx2.SSSx1.p1.5.m5.1.1.3.3.1" xref="Sx4.SSx2.SSSx1.p1.5.m5.1.1.3.3.1.cmml">×</mo><mi id="Sx4.SSx2.SSSx1.p1.5.m5.1.1.3.3.3" xref="Sx4.SSx2.SSSx1.p1.5.m5.1.1.3.3.3.cmml">L</mi><mo lspace="0.222em" rspace="0.222em" id="Sx4.SSx2.SSSx1.p1.5.m5.1.1.3.3.1a" xref="Sx4.SSx2.SSSx1.p1.5.m5.1.1.3.3.1.cmml">×</mo><mi id="Sx4.SSx2.SSSx1.p1.5.m5.1.1.3.3.4" xref="Sx4.SSx2.SSSx1.p1.5.m5.1.1.3.3.4.cmml">d</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="Sx4.SSx2.SSSx1.p1.5.m5.1b"><apply id="Sx4.SSx2.SSSx1.p1.5.m5.1.1.cmml" xref="Sx4.SSx2.SSSx1.p1.5.m5.1.1"><in id="Sx4.SSx2.SSSx1.p1.5.m5.1.1.1.cmml" xref="Sx4.SSx2.SSSx1.p1.5.m5.1.1.1"></in><ci id="Sx4.SSx2.SSSx1.p1.5.m5.1.1.2.cmml" xref="Sx4.SSx2.SSSx1.p1.5.m5.1.1.2">𝐗</ci><apply id="Sx4.SSx2.SSSx1.p1.5.m5.1.1.3.cmml" xref="Sx4.SSx2.SSSx1.p1.5.m5.1.1.3"><csymbol cd="ambiguous" id="Sx4.SSx2.SSSx1.p1.5.m5.1.1.3.1.cmml" xref="Sx4.SSx2.SSSx1.p1.5.m5.1.1.3">superscript</csymbol><ci id="Sx4.SSx2.SSSx1.p1.5.m5.1.1.3.2.cmml" xref="Sx4.SSx2.SSSx1.p1.5.m5.1.1.3.2">ℝ</ci><apply id="Sx4.SSx2.SSSx1.p1.5.m5.1.1.3.3.cmml" xref="Sx4.SSx2.SSSx1.p1.5.m5.1.1.3.3"><times id="Sx4.SSx2.SSSx1.p1.5.m5.1.1.3.3.1.cmml" xref="Sx4.SSx2.SSSx1.p1.5.m5.1.1.3.3.1"></times><ci id="Sx4.SSx2.SSSx1.p1.5.m5.1.1.3.3.2.cmml" xref="Sx4.SSx2.SSSx1.p1.5.m5.1.1.3.3.2">𝐾</ci><ci id="Sx4.SSx2.SSSx1.p1.5.m5.1.1.3.3.3.cmml" xref="Sx4.SSx2.SSSx1.p1.5.m5.1.1.3.3.3">𝐿</ci><ci id="Sx4.SSx2.SSSx1.p1.5.m5.1.1.3.3.4.cmml" xref="Sx4.SSx2.SSSx1.p1.5.m5.1.1.3.3.4">𝑑</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx4.SSx2.SSSx1.p1.5.m5.1c">\mathbf{X}\in\mathbb{R}^{K\times L\times d}</annotation></semantics></math>.</p>
</div>
</section>
<section id="Sx4.SSx2.SSSx2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Answer/Arithmetic-expression decoder.</h4>

<div id="Sx4.SSx2.SSSx2.p1" class="ltx_para">
<p id="Sx4.SSx2.SSSx2.p1.9" class="ltx_p">Our decoder is another stack of <math id="Sx4.SSx2.SSSx2.p1.1.m1.1" class="ltx_Math" alttext="m" display="inline"><semantics id="Sx4.SSx2.SSSx2.p1.1.m1.1a"><mi id="Sx4.SSx2.SSSx2.p1.1.m1.1.1" xref="Sx4.SSx2.SSSx2.p1.1.m1.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="Sx4.SSx2.SSSx2.p1.1.m1.1b"><ci id="Sx4.SSx2.SSSx2.p1.1.m1.1.1.cmml" xref="Sx4.SSx2.SSSx2.p1.1.m1.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx4.SSx2.SSSx2.p1.1.m1.1c">m</annotation></semantics></math> Transformer blocks similar to the multi-modal encoder, where each block has an additional layer of cross-attention between the output sequence and <math id="Sx4.SSx2.SSSx2.p1.2.m2.1" class="ltx_Math" alttext="\mathbf{X}" display="inline"><semantics id="Sx4.SSx2.SSSx2.p1.2.m2.1a"><mi id="Sx4.SSx2.SSSx2.p1.2.m2.1.1" xref="Sx4.SSx2.SSSx2.p1.2.m2.1.1.cmml">𝐗</mi><annotation-xml encoding="MathML-Content" id="Sx4.SSx2.SSSx2.p1.2.m2.1b"><ci id="Sx4.SSx2.SSSx2.p1.2.m2.1.1.cmml" xref="Sx4.SSx2.SSSx2.p1.2.m2.1.1">𝐗</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx4.SSx2.SSSx2.p1.2.m2.1c">\mathbf{X}</annotation></semantics></math>. The answer decoder is modeled
as a conditional generation <math id="Sx4.SSx2.SSSx2.p1.3.m3.1" class="ltx_Math" alttext="p_{\theta}(y|\mathbf{X})" display="inline"><semantics id="Sx4.SSx2.SSSx2.p1.3.m3.1a"><mrow id="Sx4.SSx2.SSSx2.p1.3.m3.1.1" xref="Sx4.SSx2.SSSx2.p1.3.m3.1.1.cmml"><msub id="Sx4.SSx2.SSSx2.p1.3.m3.1.1.3" xref="Sx4.SSx2.SSSx2.p1.3.m3.1.1.3.cmml"><mi id="Sx4.SSx2.SSSx2.p1.3.m3.1.1.3.2" xref="Sx4.SSx2.SSSx2.p1.3.m3.1.1.3.2.cmml">p</mi><mi id="Sx4.SSx2.SSSx2.p1.3.m3.1.1.3.3" xref="Sx4.SSx2.SSSx2.p1.3.m3.1.1.3.3.cmml">θ</mi></msub><mo lspace="0em" rspace="0em" id="Sx4.SSx2.SSSx2.p1.3.m3.1.1.2" xref="Sx4.SSx2.SSSx2.p1.3.m3.1.1.2.cmml">​</mo><mrow id="Sx4.SSx2.SSSx2.p1.3.m3.1.1.1.1" xref="Sx4.SSx2.SSSx2.p1.3.m3.1.1.1.1.1.cmml"><mo stretchy="false" id="Sx4.SSx2.SSSx2.p1.3.m3.1.1.1.1.2" xref="Sx4.SSx2.SSSx2.p1.3.m3.1.1.1.1.1.cmml">(</mo><mrow id="Sx4.SSx2.SSSx2.p1.3.m3.1.1.1.1.1" xref="Sx4.SSx2.SSSx2.p1.3.m3.1.1.1.1.1.cmml"><mi id="Sx4.SSx2.SSSx2.p1.3.m3.1.1.1.1.1.2" xref="Sx4.SSx2.SSSx2.p1.3.m3.1.1.1.1.1.2.cmml">y</mi><mo fence="false" id="Sx4.SSx2.SSSx2.p1.3.m3.1.1.1.1.1.1" xref="Sx4.SSx2.SSSx2.p1.3.m3.1.1.1.1.1.1.cmml">|</mo><mi id="Sx4.SSx2.SSSx2.p1.3.m3.1.1.1.1.1.3" xref="Sx4.SSx2.SSSx2.p1.3.m3.1.1.1.1.1.3.cmml">𝐗</mi></mrow><mo stretchy="false" id="Sx4.SSx2.SSSx2.p1.3.m3.1.1.1.1.3" xref="Sx4.SSx2.SSSx2.p1.3.m3.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="Sx4.SSx2.SSSx2.p1.3.m3.1b"><apply id="Sx4.SSx2.SSSx2.p1.3.m3.1.1.cmml" xref="Sx4.SSx2.SSSx2.p1.3.m3.1.1"><times id="Sx4.SSx2.SSSx2.p1.3.m3.1.1.2.cmml" xref="Sx4.SSx2.SSSx2.p1.3.m3.1.1.2"></times><apply id="Sx4.SSx2.SSSx2.p1.3.m3.1.1.3.cmml" xref="Sx4.SSx2.SSSx2.p1.3.m3.1.1.3"><csymbol cd="ambiguous" id="Sx4.SSx2.SSSx2.p1.3.m3.1.1.3.1.cmml" xref="Sx4.SSx2.SSSx2.p1.3.m3.1.1.3">subscript</csymbol><ci id="Sx4.SSx2.SSSx2.p1.3.m3.1.1.3.2.cmml" xref="Sx4.SSx2.SSSx2.p1.3.m3.1.1.3.2">𝑝</ci><ci id="Sx4.SSx2.SSSx2.p1.3.m3.1.1.3.3.cmml" xref="Sx4.SSx2.SSSx2.p1.3.m3.1.1.3.3">𝜃</ci></apply><apply id="Sx4.SSx2.SSSx2.p1.3.m3.1.1.1.1.1.cmml" xref="Sx4.SSx2.SSSx2.p1.3.m3.1.1.1.1"><csymbol cd="latexml" id="Sx4.SSx2.SSSx2.p1.3.m3.1.1.1.1.1.1.cmml" xref="Sx4.SSx2.SSSx2.p1.3.m3.1.1.1.1.1.1">conditional</csymbol><ci id="Sx4.SSx2.SSSx2.p1.3.m3.1.1.1.1.1.2.cmml" xref="Sx4.SSx2.SSSx2.p1.3.m3.1.1.1.1.1.2">𝑦</ci><ci id="Sx4.SSx2.SSSx2.p1.3.m3.1.1.1.1.1.3.cmml" xref="Sx4.SSx2.SSSx2.p1.3.m3.1.1.1.1.1.3">𝐗</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx4.SSx2.SSSx2.p1.3.m3.1c">p_{\theta}(y|\mathbf{X})</annotation></semantics></math>, where <math id="Sx4.SSx2.SSSx2.p1.4.m4.1" class="ltx_Math" alttext="\theta" display="inline"><semantics id="Sx4.SSx2.SSSx2.p1.4.m4.1a"><mi id="Sx4.SSx2.SSSx2.p1.4.m4.1.1" xref="Sx4.SSx2.SSSx2.p1.4.m4.1.1.cmml">θ</mi><annotation-xml encoding="MathML-Content" id="Sx4.SSx2.SSSx2.p1.4.m4.1b"><ci id="Sx4.SSx2.SSSx2.p1.4.m4.1.1.cmml" xref="Sx4.SSx2.SSSx2.p1.4.m4.1.1">𝜃</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx4.SSx2.SSSx2.p1.4.m4.1c">\theta</annotation></semantics></math> represents the set of all model parameters. To allow the model to perform numerical reasoning, we train the system to predict annotated arithmetic expressions <math id="Sx4.SSx2.SSSx2.p1.5.m5.1" class="ltx_Math" alttext="y^{\prime}" display="inline"><semantics id="Sx4.SSx2.SSSx2.p1.5.m5.1a"><msup id="Sx4.SSx2.SSSx2.p1.5.m5.1.1" xref="Sx4.SSx2.SSSx2.p1.5.m5.1.1.cmml"><mi id="Sx4.SSx2.SSSx2.p1.5.m5.1.1.2" xref="Sx4.SSx2.SSSx2.p1.5.m5.1.1.2.cmml">y</mi><mo id="Sx4.SSx2.SSSx2.p1.5.m5.1.1.3" xref="Sx4.SSx2.SSSx2.p1.5.m5.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="Sx4.SSx2.SSSx2.p1.5.m5.1b"><apply id="Sx4.SSx2.SSSx2.p1.5.m5.1.1.cmml" xref="Sx4.SSx2.SSSx2.p1.5.m5.1.1"><csymbol cd="ambiguous" id="Sx4.SSx2.SSSx2.p1.5.m5.1.1.1.cmml" xref="Sx4.SSx2.SSSx2.p1.5.m5.1.1">superscript</csymbol><ci id="Sx4.SSx2.SSSx2.p1.5.m5.1.1.2.cmml" xref="Sx4.SSx2.SSSx2.p1.5.m5.1.1.2">𝑦</ci><ci id="Sx4.SSx2.SSSx2.p1.5.m5.1.1.3.cmml" xref="Sx4.SSx2.SSSx2.p1.5.m5.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx4.SSx2.SSSx2.p1.5.m5.1c">y^{\prime}</annotation></semantics></math> (e.g., “<math id="Sx4.SSx2.SSSx2.p1.6.m6.1" class="ltx_Math" alttext="30-28" display="inline"><semantics id="Sx4.SSx2.SSSx2.p1.6.m6.1a"><mrow id="Sx4.SSx2.SSSx2.p1.6.m6.1.1" xref="Sx4.SSx2.SSSx2.p1.6.m6.1.1.cmml"><mn id="Sx4.SSx2.SSSx2.p1.6.m6.1.1.2" xref="Sx4.SSx2.SSSx2.p1.6.m6.1.1.2.cmml">30</mn><mo id="Sx4.SSx2.SSSx2.p1.6.m6.1.1.1" xref="Sx4.SSx2.SSSx2.p1.6.m6.1.1.1.cmml">−</mo><mn id="Sx4.SSx2.SSSx2.p1.6.m6.1.1.3" xref="Sx4.SSx2.SSSx2.p1.6.m6.1.1.3.cmml">28</mn></mrow><annotation-xml encoding="MathML-Content" id="Sx4.SSx2.SSSx2.p1.6.m6.1b"><apply id="Sx4.SSx2.SSSx2.p1.6.m6.1.1.cmml" xref="Sx4.SSx2.SSSx2.p1.6.m6.1.1"><minus id="Sx4.SSx2.SSSx2.p1.6.m6.1.1.1.cmml" xref="Sx4.SSx2.SSSx2.p1.6.m6.1.1.1"></minus><cn type="integer" id="Sx4.SSx2.SSSx2.p1.6.m6.1.1.2.cmml" xref="Sx4.SSx2.SSSx2.p1.6.m6.1.1.2">30</cn><cn type="integer" id="Sx4.SSx2.SSSx2.p1.6.m6.1.1.3.cmml" xref="Sx4.SSx2.SSSx2.p1.6.m6.1.1.3">28</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx4.SSx2.SSSx2.p1.6.m6.1c">30-28</annotation></semantics></math>”) instead of numeric values <math id="Sx4.SSx2.SSSx2.p1.7.m7.1" class="ltx_Math" alttext="y" display="inline"><semantics id="Sx4.SSx2.SSSx2.p1.7.m7.1a"><mi id="Sx4.SSx2.SSSx2.p1.7.m7.1.1" xref="Sx4.SSx2.SSSx2.p1.7.m7.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="Sx4.SSx2.SSSx2.p1.7.m7.1b"><ci id="Sx4.SSx2.SSSx2.p1.7.m7.1.1.cmml" xref="Sx4.SSx2.SSSx2.p1.7.m7.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx4.SSx2.SSSx2.p1.7.m7.1c">y</annotation></semantics></math> (e.g., “<math id="Sx4.SSx2.SSSx2.p1.8.m8.1" class="ltx_Math" alttext="2" display="inline"><semantics id="Sx4.SSx2.SSSx2.p1.8.m8.1a"><mn id="Sx4.SSx2.SSSx2.p1.8.m8.1.1" xref="Sx4.SSx2.SSSx2.p1.8.m8.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="Sx4.SSx2.SSSx2.p1.8.m8.1b"><cn type="integer" id="Sx4.SSx2.SSSx2.p1.8.m8.1.1.cmml" xref="Sx4.SSx2.SSSx2.p1.8.m8.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="Sx4.SSx2.SSSx2.p1.8.m8.1c">2</annotation></semantics></math>”) by modeling <math id="Sx4.SSx2.SSSx2.p1.9.m9.1" class="ltx_Math" alttext="p_{\theta}(y^{\prime}|\mathbf{X})" display="inline"><semantics id="Sx4.SSx2.SSSx2.p1.9.m9.1a"><mrow id="Sx4.SSx2.SSSx2.p1.9.m9.1.1" xref="Sx4.SSx2.SSSx2.p1.9.m9.1.1.cmml"><msub id="Sx4.SSx2.SSSx2.p1.9.m9.1.1.3" xref="Sx4.SSx2.SSSx2.p1.9.m9.1.1.3.cmml"><mi id="Sx4.SSx2.SSSx2.p1.9.m9.1.1.3.2" xref="Sx4.SSx2.SSSx2.p1.9.m9.1.1.3.2.cmml">p</mi><mi id="Sx4.SSx2.SSSx2.p1.9.m9.1.1.3.3" xref="Sx4.SSx2.SSSx2.p1.9.m9.1.1.3.3.cmml">θ</mi></msub><mo lspace="0em" rspace="0em" id="Sx4.SSx2.SSSx2.p1.9.m9.1.1.2" xref="Sx4.SSx2.SSSx2.p1.9.m9.1.1.2.cmml">​</mo><mrow id="Sx4.SSx2.SSSx2.p1.9.m9.1.1.1.1" xref="Sx4.SSx2.SSSx2.p1.9.m9.1.1.1.1.1.cmml"><mo stretchy="false" id="Sx4.SSx2.SSSx2.p1.9.m9.1.1.1.1.2" xref="Sx4.SSx2.SSSx2.p1.9.m9.1.1.1.1.1.cmml">(</mo><mrow id="Sx4.SSx2.SSSx2.p1.9.m9.1.1.1.1.1" xref="Sx4.SSx2.SSSx2.p1.9.m9.1.1.1.1.1.cmml"><msup id="Sx4.SSx2.SSSx2.p1.9.m9.1.1.1.1.1.2" xref="Sx4.SSx2.SSSx2.p1.9.m9.1.1.1.1.1.2.cmml"><mi id="Sx4.SSx2.SSSx2.p1.9.m9.1.1.1.1.1.2.2" xref="Sx4.SSx2.SSSx2.p1.9.m9.1.1.1.1.1.2.2.cmml">y</mi><mo id="Sx4.SSx2.SSSx2.p1.9.m9.1.1.1.1.1.2.3" xref="Sx4.SSx2.SSSx2.p1.9.m9.1.1.1.1.1.2.3.cmml">′</mo></msup><mo fence="false" id="Sx4.SSx2.SSSx2.p1.9.m9.1.1.1.1.1.1" xref="Sx4.SSx2.SSSx2.p1.9.m9.1.1.1.1.1.1.cmml">|</mo><mi id="Sx4.SSx2.SSSx2.p1.9.m9.1.1.1.1.1.3" xref="Sx4.SSx2.SSSx2.p1.9.m9.1.1.1.1.1.3.cmml">𝐗</mi></mrow><mo stretchy="false" id="Sx4.SSx2.SSSx2.p1.9.m9.1.1.1.1.3" xref="Sx4.SSx2.SSSx2.p1.9.m9.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="Sx4.SSx2.SSSx2.p1.9.m9.1b"><apply id="Sx4.SSx2.SSSx2.p1.9.m9.1.1.cmml" xref="Sx4.SSx2.SSSx2.p1.9.m9.1.1"><times id="Sx4.SSx2.SSSx2.p1.9.m9.1.1.2.cmml" xref="Sx4.SSx2.SSSx2.p1.9.m9.1.1.2"></times><apply id="Sx4.SSx2.SSSx2.p1.9.m9.1.1.3.cmml" xref="Sx4.SSx2.SSSx2.p1.9.m9.1.1.3"><csymbol cd="ambiguous" id="Sx4.SSx2.SSSx2.p1.9.m9.1.1.3.1.cmml" xref="Sx4.SSx2.SSSx2.p1.9.m9.1.1.3">subscript</csymbol><ci id="Sx4.SSx2.SSSx2.p1.9.m9.1.1.3.2.cmml" xref="Sx4.SSx2.SSSx2.p1.9.m9.1.1.3.2">𝑝</ci><ci id="Sx4.SSx2.SSSx2.p1.9.m9.1.1.3.3.cmml" xref="Sx4.SSx2.SSSx2.p1.9.m9.1.1.3.3">𝜃</ci></apply><apply id="Sx4.SSx2.SSSx2.p1.9.m9.1.1.1.1.1.cmml" xref="Sx4.SSx2.SSSx2.p1.9.m9.1.1.1.1"><csymbol cd="latexml" id="Sx4.SSx2.SSSx2.p1.9.m9.1.1.1.1.1.1.cmml" xref="Sx4.SSx2.SSSx2.p1.9.m9.1.1.1.1.1.1">conditional</csymbol><apply id="Sx4.SSx2.SSSx2.p1.9.m9.1.1.1.1.1.2.cmml" xref="Sx4.SSx2.SSSx2.p1.9.m9.1.1.1.1.1.2"><csymbol cd="ambiguous" id="Sx4.SSx2.SSSx2.p1.9.m9.1.1.1.1.1.2.1.cmml" xref="Sx4.SSx2.SSSx2.p1.9.m9.1.1.1.1.1.2">superscript</csymbol><ci id="Sx4.SSx2.SSSx2.p1.9.m9.1.1.1.1.1.2.2.cmml" xref="Sx4.SSx2.SSSx2.p1.9.m9.1.1.1.1.1.2.2">𝑦</ci><ci id="Sx4.SSx2.SSSx2.p1.9.m9.1.1.1.1.1.2.3.cmml" xref="Sx4.SSx2.SSSx2.p1.9.m9.1.1.1.1.1.2.3">′</ci></apply><ci id="Sx4.SSx2.SSSx2.p1.9.m9.1.1.1.1.1.3.cmml" xref="Sx4.SSx2.SSSx2.p1.9.m9.1.1.1.1.1.3">𝐗</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx4.SSx2.SSSx2.p1.9.m9.1c">p_{\theta}(y^{\prime}|\mathbf{X})</annotation></semantics></math>.
During inference, the model itself decides whether numerical reasoning is required or not for each question by predicting an indicator token <span id="Sx4.SSx2.SSSx2.p1.9.1" class="ltx_text ltx_font_typewriter">Answer:</span> or <span id="Sx4.SSx2.SSSx2.p1.9.2" class="ltx_text ltx_font_typewriter">Expression:</span> at the beginning of the output sequence.</p>
</div>
</section>
<section id="Sx4.SSx2.SSSx3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Evidence selector.</h4>

<div id="Sx4.SSx2.SSSx3.p1" class="ltx_para">
<p id="Sx4.SSx2.SSSx3.p1.6" class="ltx_p">The selector shares the weights and the architecture of the answer/arithmetic-expression decoder. Instead of only modeling answer generation, we devise a simple method to train evidence selection in a unified sequence. Specifically, we define the output sequence as <math id="Sx4.SSx2.SSSx3.p1.1.m1.1" class="ltx_Math" alttext="\hat{\mathbf{I}}_{\text{pages}}" display="inline"><semantics id="Sx4.SSx2.SSSx3.p1.1.m1.1a"><msub id="Sx4.SSx2.SSSx3.p1.1.m1.1.1" xref="Sx4.SSx2.SSSx3.p1.1.m1.1.1.cmml"><mover accent="true" id="Sx4.SSx2.SSSx3.p1.1.m1.1.1.2" xref="Sx4.SSx2.SSSx3.p1.1.m1.1.1.2.cmml"><mi id="Sx4.SSx2.SSSx3.p1.1.m1.1.1.2.2" xref="Sx4.SSx2.SSSx3.p1.1.m1.1.1.2.2.cmml">𝐈</mi><mo id="Sx4.SSx2.SSSx3.p1.1.m1.1.1.2.1" xref="Sx4.SSx2.SSSx3.p1.1.m1.1.1.2.1.cmml">^</mo></mover><mtext id="Sx4.SSx2.SSSx3.p1.1.m1.1.1.3" xref="Sx4.SSx2.SSSx3.p1.1.m1.1.1.3a.cmml">pages</mtext></msub><annotation-xml encoding="MathML-Content" id="Sx4.SSx2.SSSx3.p1.1.m1.1b"><apply id="Sx4.SSx2.SSSx3.p1.1.m1.1.1.cmml" xref="Sx4.SSx2.SSSx3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="Sx4.SSx2.SSSx3.p1.1.m1.1.1.1.cmml" xref="Sx4.SSx2.SSSx3.p1.1.m1.1.1">subscript</csymbol><apply id="Sx4.SSx2.SSSx3.p1.1.m1.1.1.2.cmml" xref="Sx4.SSx2.SSSx3.p1.1.m1.1.1.2"><ci id="Sx4.SSx2.SSSx3.p1.1.m1.1.1.2.1.cmml" xref="Sx4.SSx2.SSSx3.p1.1.m1.1.1.2.1">^</ci><ci id="Sx4.SSx2.SSSx3.p1.1.m1.1.1.2.2.cmml" xref="Sx4.SSx2.SSSx3.p1.1.m1.1.1.2.2">𝐈</ci></apply><ci id="Sx4.SSx2.SSSx3.p1.1.m1.1.1.3a.cmml" xref="Sx4.SSx2.SSSx3.p1.1.m1.1.1.3"><mtext mathsize="70%" id="Sx4.SSx2.SSSx3.p1.1.m1.1.1.3.cmml" xref="Sx4.SSx2.SSSx3.p1.1.m1.1.1.3">pages</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx4.SSx2.SSSx3.p1.1.m1.1c">\hat{\mathbf{I}}_{\text{pages}}</annotation></semantics></math> <math id="Sx4.SSx2.SSSx3.p1.2.m2.1" class="ltx_Math" alttext="=" display="inline"><semantics id="Sx4.SSx2.SSSx3.p1.2.m2.1a"><mo id="Sx4.SSx2.SSSx3.p1.2.m2.1.1" xref="Sx4.SSx2.SSSx3.p1.2.m2.1.1.cmml">=</mo><annotation-xml encoding="MathML-Content" id="Sx4.SSx2.SSSx3.p1.2.m2.1b"><eq id="Sx4.SSx2.SSSx3.p1.2.m2.1.1.cmml" xref="Sx4.SSx2.SSSx3.p1.2.m2.1.1"></eq></annotation-xml><annotation encoding="application/x-tex" id="Sx4.SSx2.SSSx3.p1.2.m2.1c">=</annotation></semantics></math> (<span id="Sx4.SSx2.SSSx3.p1.6.1" class="ltx_text ltx_font_typewriter">Evidence pages:</span> <math id="Sx4.SSx2.SSSx3.p1.3.m3.1" class="ltx_Math" alttext="\hat{e}_{1}" display="inline"><semantics id="Sx4.SSx2.SSSx3.p1.3.m3.1a"><msub id="Sx4.SSx2.SSSx3.p1.3.m3.1.1" xref="Sx4.SSx2.SSSx3.p1.3.m3.1.1.cmml"><mover accent="true" id="Sx4.SSx2.SSSx3.p1.3.m3.1.1.2" xref="Sx4.SSx2.SSSx3.p1.3.m3.1.1.2.cmml"><mi id="Sx4.SSx2.SSSx3.p1.3.m3.1.1.2.2" xref="Sx4.SSx2.SSSx3.p1.3.m3.1.1.2.2.cmml">e</mi><mo id="Sx4.SSx2.SSSx3.p1.3.m3.1.1.2.1" xref="Sx4.SSx2.SSSx3.p1.3.m3.1.1.2.1.cmml">^</mo></mover><mn id="Sx4.SSx2.SSSx3.p1.3.m3.1.1.3" xref="Sx4.SSx2.SSSx3.p1.3.m3.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="Sx4.SSx2.SSSx3.p1.3.m3.1b"><apply id="Sx4.SSx2.SSSx3.p1.3.m3.1.1.cmml" xref="Sx4.SSx2.SSSx3.p1.3.m3.1.1"><csymbol cd="ambiguous" id="Sx4.SSx2.SSSx3.p1.3.m3.1.1.1.cmml" xref="Sx4.SSx2.SSSx3.p1.3.m3.1.1">subscript</csymbol><apply id="Sx4.SSx2.SSSx3.p1.3.m3.1.1.2.cmml" xref="Sx4.SSx2.SSSx3.p1.3.m3.1.1.2"><ci id="Sx4.SSx2.SSSx3.p1.3.m3.1.1.2.1.cmml" xref="Sx4.SSx2.SSSx3.p1.3.m3.1.1.2.1">^</ci><ci id="Sx4.SSx2.SSSx3.p1.3.m3.1.1.2.2.cmml" xref="Sx4.SSx2.SSSx3.p1.3.m3.1.1.2.2">𝑒</ci></apply><cn type="integer" id="Sx4.SSx2.SSSx3.p1.3.m3.1.1.3.cmml" xref="Sx4.SSx2.SSSx3.p1.3.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx4.SSx2.SSSx3.p1.3.m3.1c">\hat{e}_{1}</annotation></semantics></math>, <math id="Sx4.SSx2.SSSx3.p1.4.m4.1" class="ltx_Math" alttext="\ldots" display="inline"><semantics id="Sx4.SSx2.SSSx3.p1.4.m4.1a"><mi mathvariant="normal" id="Sx4.SSx2.SSSx3.p1.4.m4.1.1" xref="Sx4.SSx2.SSSx3.p1.4.m4.1.1.cmml">…</mi><annotation-xml encoding="MathML-Content" id="Sx4.SSx2.SSSx3.p1.4.m4.1b"><ci id="Sx4.SSx2.SSSx3.p1.4.m4.1.1.cmml" xref="Sx4.SSx2.SSSx3.p1.4.m4.1.1">…</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx4.SSx2.SSSx3.p1.4.m4.1c">\ldots</annotation></semantics></math>, <math id="Sx4.SSx2.SSSx3.p1.5.m5.1" class="ltx_Math" alttext="\hat{e}_{K^{\prime}}" display="inline"><semantics id="Sx4.SSx2.SSSx3.p1.5.m5.1a"><msub id="Sx4.SSx2.SSSx3.p1.5.m5.1.1" xref="Sx4.SSx2.SSSx3.p1.5.m5.1.1.cmml"><mover accent="true" id="Sx4.SSx2.SSSx3.p1.5.m5.1.1.2" xref="Sx4.SSx2.SSSx3.p1.5.m5.1.1.2.cmml"><mi id="Sx4.SSx2.SSSx3.p1.5.m5.1.1.2.2" xref="Sx4.SSx2.SSSx3.p1.5.m5.1.1.2.2.cmml">e</mi><mo id="Sx4.SSx2.SSSx3.p1.5.m5.1.1.2.1" xref="Sx4.SSx2.SSSx3.p1.5.m5.1.1.2.1.cmml">^</mo></mover><msup id="Sx4.SSx2.SSSx3.p1.5.m5.1.1.3" xref="Sx4.SSx2.SSSx3.p1.5.m5.1.1.3.cmml"><mi id="Sx4.SSx2.SSSx3.p1.5.m5.1.1.3.2" xref="Sx4.SSx2.SSSx3.p1.5.m5.1.1.3.2.cmml">K</mi><mo id="Sx4.SSx2.SSSx3.p1.5.m5.1.1.3.3" xref="Sx4.SSx2.SSSx3.p1.5.m5.1.1.3.3.cmml">′</mo></msup></msub><annotation-xml encoding="MathML-Content" id="Sx4.SSx2.SSSx3.p1.5.m5.1b"><apply id="Sx4.SSx2.SSSx3.p1.5.m5.1.1.cmml" xref="Sx4.SSx2.SSSx3.p1.5.m5.1.1"><csymbol cd="ambiguous" id="Sx4.SSx2.SSSx3.p1.5.m5.1.1.1.cmml" xref="Sx4.SSx2.SSSx3.p1.5.m5.1.1">subscript</csymbol><apply id="Sx4.SSx2.SSSx3.p1.5.m5.1.1.2.cmml" xref="Sx4.SSx2.SSSx3.p1.5.m5.1.1.2"><ci id="Sx4.SSx2.SSSx3.p1.5.m5.1.1.2.1.cmml" xref="Sx4.SSx2.SSSx3.p1.5.m5.1.1.2.1">^</ci><ci id="Sx4.SSx2.SSSx3.p1.5.m5.1.1.2.2.cmml" xref="Sx4.SSx2.SSSx3.p1.5.m5.1.1.2.2">𝑒</ci></apply><apply id="Sx4.SSx2.SSSx3.p1.5.m5.1.1.3.cmml" xref="Sx4.SSx2.SSSx3.p1.5.m5.1.1.3"><csymbol cd="ambiguous" id="Sx4.SSx2.SSSx3.p1.5.m5.1.1.3.1.cmml" xref="Sx4.SSx2.SSSx3.p1.5.m5.1.1.3">superscript</csymbol><ci id="Sx4.SSx2.SSSx3.p1.5.m5.1.1.3.2.cmml" xref="Sx4.SSx2.SSSx3.p1.5.m5.1.1.3.2">𝐾</ci><ci id="Sx4.SSx2.SSSx3.p1.5.m5.1.1.3.3.cmml" xref="Sx4.SSx2.SSSx3.p1.5.m5.1.1.3.3">′</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx4.SSx2.SSSx3.p1.5.m5.1c">\hat{e}_{K^{\prime}}</annotation></semantics></math>), where each <math id="Sx4.SSx2.SSSx3.p1.6.m6.1" class="ltx_Math" alttext="\hat{e}" display="inline"><semantics id="Sx4.SSx2.SSSx3.p1.6.m6.1a"><mover accent="true" id="Sx4.SSx2.SSSx3.p1.6.m6.1.1" xref="Sx4.SSx2.SSSx3.p1.6.m6.1.1.cmml"><mi id="Sx4.SSx2.SSSx3.p1.6.m6.1.1.2" xref="Sx4.SSx2.SSSx3.p1.6.m6.1.1.2.cmml">e</mi><mo id="Sx4.SSx2.SSSx3.p1.6.m6.1.1.1" xref="Sx4.SSx2.SSSx3.p1.6.m6.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="Sx4.SSx2.SSSx3.p1.6.m6.1b"><apply id="Sx4.SSx2.SSSx3.p1.6.m6.1.1.cmml" xref="Sx4.SSx2.SSSx3.p1.6.m6.1.1"><ci id="Sx4.SSx2.SSSx3.p1.6.m6.1.1.1.cmml" xref="Sx4.SSx2.SSSx3.p1.6.m6.1.1.1">^</ci><ci id="Sx4.SSx2.SSSx3.p1.6.m6.1.1.2.cmml" xref="Sx4.SSx2.SSSx3.p1.6.m6.1.1.2">𝑒</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx4.SSx2.SSSx3.p1.6.m6.1c">\hat{e}</annotation></semantics></math> is the page number of the selected slide.</p>
</div>
</section>
<section id="Sx4.SSx2.SSSx4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Training and inference.</h4>

<div id="Sx4.SSx2.SSSx4.p1" class="ltx_para">
<p id="Sx4.SSx2.SSSx4.p1.3" class="ltx_p">Our model is trained by minimizing the weighted sum of two losses <math id="Sx4.SSx2.SSSx4.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{L}=\mathcal{L}_{\text{dec}}+\mathcal{L}_{\text{sel}}" display="inline"><semantics id="Sx4.SSx2.SSSx4.p1.1.m1.1a"><mrow id="Sx4.SSx2.SSSx4.p1.1.m1.1.1" xref="Sx4.SSx2.SSSx4.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="Sx4.SSx2.SSSx4.p1.1.m1.1.1.2" xref="Sx4.SSx2.SSSx4.p1.1.m1.1.1.2.cmml">ℒ</mi><mo id="Sx4.SSx2.SSSx4.p1.1.m1.1.1.1" xref="Sx4.SSx2.SSSx4.p1.1.m1.1.1.1.cmml">=</mo><mrow id="Sx4.SSx2.SSSx4.p1.1.m1.1.1.3" xref="Sx4.SSx2.SSSx4.p1.1.m1.1.1.3.cmml"><msub id="Sx4.SSx2.SSSx4.p1.1.m1.1.1.3.2" xref="Sx4.SSx2.SSSx4.p1.1.m1.1.1.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="Sx4.SSx2.SSSx4.p1.1.m1.1.1.3.2.2" xref="Sx4.SSx2.SSSx4.p1.1.m1.1.1.3.2.2.cmml">ℒ</mi><mtext id="Sx4.SSx2.SSSx4.p1.1.m1.1.1.3.2.3" xref="Sx4.SSx2.SSSx4.p1.1.m1.1.1.3.2.3a.cmml">dec</mtext></msub><mo id="Sx4.SSx2.SSSx4.p1.1.m1.1.1.3.1" xref="Sx4.SSx2.SSSx4.p1.1.m1.1.1.3.1.cmml">+</mo><msub id="Sx4.SSx2.SSSx4.p1.1.m1.1.1.3.3" xref="Sx4.SSx2.SSSx4.p1.1.m1.1.1.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="Sx4.SSx2.SSSx4.p1.1.m1.1.1.3.3.2" xref="Sx4.SSx2.SSSx4.p1.1.m1.1.1.3.3.2.cmml">ℒ</mi><mtext id="Sx4.SSx2.SSSx4.p1.1.m1.1.1.3.3.3" xref="Sx4.SSx2.SSSx4.p1.1.m1.1.1.3.3.3a.cmml">sel</mtext></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="Sx4.SSx2.SSSx4.p1.1.m1.1b"><apply id="Sx4.SSx2.SSSx4.p1.1.m1.1.1.cmml" xref="Sx4.SSx2.SSSx4.p1.1.m1.1.1"><eq id="Sx4.SSx2.SSSx4.p1.1.m1.1.1.1.cmml" xref="Sx4.SSx2.SSSx4.p1.1.m1.1.1.1"></eq><ci id="Sx4.SSx2.SSSx4.p1.1.m1.1.1.2.cmml" xref="Sx4.SSx2.SSSx4.p1.1.m1.1.1.2">ℒ</ci><apply id="Sx4.SSx2.SSSx4.p1.1.m1.1.1.3.cmml" xref="Sx4.SSx2.SSSx4.p1.1.m1.1.1.3"><plus id="Sx4.SSx2.SSSx4.p1.1.m1.1.1.3.1.cmml" xref="Sx4.SSx2.SSSx4.p1.1.m1.1.1.3.1"></plus><apply id="Sx4.SSx2.SSSx4.p1.1.m1.1.1.3.2.cmml" xref="Sx4.SSx2.SSSx4.p1.1.m1.1.1.3.2"><csymbol cd="ambiguous" id="Sx4.SSx2.SSSx4.p1.1.m1.1.1.3.2.1.cmml" xref="Sx4.SSx2.SSSx4.p1.1.m1.1.1.3.2">subscript</csymbol><ci id="Sx4.SSx2.SSSx4.p1.1.m1.1.1.3.2.2.cmml" xref="Sx4.SSx2.SSSx4.p1.1.m1.1.1.3.2.2">ℒ</ci><ci id="Sx4.SSx2.SSSx4.p1.1.m1.1.1.3.2.3a.cmml" xref="Sx4.SSx2.SSSx4.p1.1.m1.1.1.3.2.3"><mtext mathsize="70%" id="Sx4.SSx2.SSSx4.p1.1.m1.1.1.3.2.3.cmml" xref="Sx4.SSx2.SSSx4.p1.1.m1.1.1.3.2.3">dec</mtext></ci></apply><apply id="Sx4.SSx2.SSSx4.p1.1.m1.1.1.3.3.cmml" xref="Sx4.SSx2.SSSx4.p1.1.m1.1.1.3.3"><csymbol cd="ambiguous" id="Sx4.SSx2.SSSx4.p1.1.m1.1.1.3.3.1.cmml" xref="Sx4.SSx2.SSSx4.p1.1.m1.1.1.3.3">subscript</csymbol><ci id="Sx4.SSx2.SSSx4.p1.1.m1.1.1.3.3.2.cmml" xref="Sx4.SSx2.SSSx4.p1.1.m1.1.1.3.3.2">ℒ</ci><ci id="Sx4.SSx2.SSSx4.p1.1.m1.1.1.3.3.3a.cmml" xref="Sx4.SSx2.SSSx4.p1.1.m1.1.1.3.3.3"><mtext mathsize="70%" id="Sx4.SSx2.SSSx4.p1.1.m1.1.1.3.3.3.cmml" xref="Sx4.SSx2.SSSx4.p1.1.m1.1.1.3.3.3">sel</mtext></ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx4.SSx2.SSSx4.p1.1.m1.1c">\mathcal{L}=\mathcal{L}_{\text{dec}}+\mathcal{L}_{\text{sel}}</annotation></semantics></math>, where <math id="Sx4.SSx2.SSSx4.p1.2.m2.1" class="ltx_Math" alttext="\mathcal{L}_{\text{dec}}" display="inline"><semantics id="Sx4.SSx2.SSSx4.p1.2.m2.1a"><msub id="Sx4.SSx2.SSSx4.p1.2.m2.1.1" xref="Sx4.SSx2.SSSx4.p1.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="Sx4.SSx2.SSSx4.p1.2.m2.1.1.2" xref="Sx4.SSx2.SSSx4.p1.2.m2.1.1.2.cmml">ℒ</mi><mtext id="Sx4.SSx2.SSSx4.p1.2.m2.1.1.3" xref="Sx4.SSx2.SSSx4.p1.2.m2.1.1.3a.cmml">dec</mtext></msub><annotation-xml encoding="MathML-Content" id="Sx4.SSx2.SSSx4.p1.2.m2.1b"><apply id="Sx4.SSx2.SSSx4.p1.2.m2.1.1.cmml" xref="Sx4.SSx2.SSSx4.p1.2.m2.1.1"><csymbol cd="ambiguous" id="Sx4.SSx2.SSSx4.p1.2.m2.1.1.1.cmml" xref="Sx4.SSx2.SSSx4.p1.2.m2.1.1">subscript</csymbol><ci id="Sx4.SSx2.SSSx4.p1.2.m2.1.1.2.cmml" xref="Sx4.SSx2.SSSx4.p1.2.m2.1.1.2">ℒ</ci><ci id="Sx4.SSx2.SSSx4.p1.2.m2.1.1.3a.cmml" xref="Sx4.SSx2.SSSx4.p1.2.m2.1.1.3"><mtext mathsize="70%" id="Sx4.SSx2.SSSx4.p1.2.m2.1.1.3.cmml" xref="Sx4.SSx2.SSSx4.p1.2.m2.1.1.3">dec</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx4.SSx2.SSSx4.p1.2.m2.1c">\mathcal{L}_{\text{dec}}</annotation></semantics></math> and <math id="Sx4.SSx2.SSSx4.p1.3.m3.1" class="ltx_Math" alttext="\mathcal{L}_{\text{sel}}" display="inline"><semantics id="Sx4.SSx2.SSSx4.p1.3.m3.1a"><msub id="Sx4.SSx2.SSSx4.p1.3.m3.1.1" xref="Sx4.SSx2.SSSx4.p1.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="Sx4.SSx2.SSSx4.p1.3.m3.1.1.2" xref="Sx4.SSx2.SSSx4.p1.3.m3.1.1.2.cmml">ℒ</mi><mtext id="Sx4.SSx2.SSSx4.p1.3.m3.1.1.3" xref="Sx4.SSx2.SSSx4.p1.3.m3.1.1.3a.cmml">sel</mtext></msub><annotation-xml encoding="MathML-Content" id="Sx4.SSx2.SSSx4.p1.3.m3.1b"><apply id="Sx4.SSx2.SSSx4.p1.3.m3.1.1.cmml" xref="Sx4.SSx2.SSSx4.p1.3.m3.1.1"><csymbol cd="ambiguous" id="Sx4.SSx2.SSSx4.p1.3.m3.1.1.1.cmml" xref="Sx4.SSx2.SSSx4.p1.3.m3.1.1">subscript</csymbol><ci id="Sx4.SSx2.SSSx4.p1.3.m3.1.1.2.cmml" xref="Sx4.SSx2.SSSx4.p1.3.m3.1.1.2">ℒ</ci><ci id="Sx4.SSx2.SSSx4.p1.3.m3.1.1.3a.cmml" xref="Sx4.SSx2.SSSx4.p1.3.m3.1.1.3"><mtext mathsize="70%" id="Sx4.SSx2.SSSx4.p1.3.m3.1.1.3.cmml" xref="Sx4.SSx2.SSSx4.p1.3.m3.1.1.3">sel</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx4.SSx2.SSSx4.p1.3.m3.1c">\mathcal{L}_{\text{sel}}</annotation></semantics></math> are the negative log-likelihood between the ground-truth and the prediction regarding the decoder and selector, respectively. During inference, we obtain the final prediction to post-process the decoded sequence by removing the task indicator. If an arithmetic expression is generated (i.e., <span id="Sx4.SSx2.SSSx4.p1.3.1" class="ltx_text ltx_font_typewriter">Expression:</span> is generated), we use a calculator to obtain the final results.</p>
</div>
</section>
</section>
</section>
<section id="Sx5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Experiments</h2>

<figure id="Sx5.T2" class="ltx_table">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_3">
<div id="Sx5.T2.2" class="ltx_block ltx_figure_panel ltx_minipage ltx_align_middle" style="width:161.9pt;">
<div id="Sx5.T2.2.2.2" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:187.9pt;height:162pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-10.4pt,9.0pt) scale(0.9,0.9) ;">
<table id="Sx5.T2.2.2.2.2" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="Sx5.T2.2.2.2.2.3.1" class="ltx_tr">
<th id="Sx5.T2.2.2.2.2.3.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_r ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;"></th>
<th id="Sx5.T2.2.2.2.2.3.1.2" class="ltx_td ltx_th ltx_th_row ltx_border_r ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;"></th>
<td id="Sx5.T2.2.2.2.2.3.1.3" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;" colspan="2">Dev</td>
<td id="Sx5.T2.2.2.2.2.3.1.4" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;" colspan="2">Test</td>
</tr>
<tr id="Sx5.T2.2.2.2.2.4.2" class="ltx_tr">
<th id="Sx5.T2.2.2.2.2.4.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">Model</th>
<th id="Sx5.T2.2.2.2.2.4.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">Modal</th>
<td id="Sx5.T2.2.2.2.2.4.2.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">JEM</td>
<td id="Sx5.T2.2.2.2.2.4.2.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">JF1</td>
<td id="Sx5.T2.2.2.2.2.4.2.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">JEM</td>
<td id="Sx5.T2.2.2.2.2.4.2.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">JF1</td>
</tr>
<tr id="Sx5.T2.2.2.2.2.5.3" class="ltx_tr">
<th id="Sx5.T2.2.2.2.2.5.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">PreasM</th>
<th id="Sx5.T2.2.2.2.2.5.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">T</th>
<td id="Sx5.T2.2.2.2.2.5.3.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">30.2</td>
<td id="Sx5.T2.2.2.2.2.5.3.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">38.2</td>
<td id="Sx5.T2.2.2.2.2.5.3.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">23.4</td>
<td id="Sx5.T2.2.2.2.2.5.3.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">34.7</td>
</tr>
<tr id="Sx5.T2.2.2.2.2.6.4" class="ltx_tr">
<th id="Sx5.T2.2.2.2.2.6.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">T5</th>
<th id="Sx5.T2.2.2.2.2.6.4.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">T</th>
<td id="Sx5.T2.2.2.2.2.6.4.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">30.0</td>
<td id="Sx5.T2.2.2.2.2.6.4.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">38.0</td>
<td id="Sx5.T2.2.2.2.2.6.4.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">22.6</td>
<td id="Sx5.T2.2.2.2.2.6.4.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">34.2</td>
</tr>
<tr id="Sx5.T2.1.1.1.1.1" class="ltx_tr">
<th id="Sx5.T2.1.1.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">T5 + <math id="Sx5.T2.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\mathbf{z}^{{\rm lay}}" display="inline"><semantics id="Sx5.T2.1.1.1.1.1.1.m1.1a"><msup id="Sx5.T2.1.1.1.1.1.1.m1.1.1" xref="Sx5.T2.1.1.1.1.1.1.m1.1.1.cmml"><mi id="Sx5.T2.1.1.1.1.1.1.m1.1.1.2" xref="Sx5.T2.1.1.1.1.1.1.m1.1.1.2.cmml">𝐳</mi><mi id="Sx5.T2.1.1.1.1.1.1.m1.1.1.3" xref="Sx5.T2.1.1.1.1.1.1.m1.1.1.3.cmml">lay</mi></msup><annotation-xml encoding="MathML-Content" id="Sx5.T2.1.1.1.1.1.1.m1.1b"><apply id="Sx5.T2.1.1.1.1.1.1.m1.1.1.cmml" xref="Sx5.T2.1.1.1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="Sx5.T2.1.1.1.1.1.1.m1.1.1.1.cmml" xref="Sx5.T2.1.1.1.1.1.1.m1.1.1">superscript</csymbol><ci id="Sx5.T2.1.1.1.1.1.1.m1.1.1.2.cmml" xref="Sx5.T2.1.1.1.1.1.1.m1.1.1.2">𝐳</ci><ci id="Sx5.T2.1.1.1.1.1.1.m1.1.1.3.cmml" xref="Sx5.T2.1.1.1.1.1.1.m1.1.1.3">lay</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx5.T2.1.1.1.1.1.1.m1.1c">\mathbf{z}^{{\rm lay}}</annotation></semantics></math>
</th>
<th id="Sx5.T2.1.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">TL</th>
<td id="Sx5.T2.1.1.1.1.1.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">30.9</td>
<td id="Sx5.T2.1.1.1.1.1.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">39.5</td>
<td id="Sx5.T2.1.1.1.1.1.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">23.6</td>
<td id="Sx5.T2.1.1.1.1.1.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">35.7</td>
</tr>
<tr id="Sx5.T2.2.2.2.2.7.5" class="ltx_tr">
<th id="Sx5.T2.2.2.2.2.7.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">LayoutT5</th>
<th id="Sx5.T2.2.2.2.2.7.5.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">TLV</th>
<td id="Sx5.T2.2.2.2.2.7.5.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">31.7</td>
<td id="Sx5.T2.2.2.2.2.7.5.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">39.9</td>
<td id="Sx5.T2.2.2.2.2.7.5.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">24.3</td>
<td id="Sx5.T2.2.2.2.2.7.5.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">36.1</td>
</tr>
<tr id="Sx5.T2.2.2.2.2.8.6" class="ltx_tr">
<th id="Sx5.T2.2.2.2.2.8.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">LayoutLMv2†</th>
<th id="Sx5.T2.2.2.2.2.8.6.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">TLV</th>
<td id="Sx5.T2.2.2.2.2.8.6.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">22.8</td>
<td id="Sx5.T2.2.2.2.2.8.6.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">30.8</td>
<td id="Sx5.T2.2.2.2.2.8.6.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">16.5</td>
<td id="Sx5.T2.2.2.2.2.8.6.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">26.5</td>
</tr>
<tr id="Sx5.T2.2.2.2.2.9.7" class="ltx_tr">
<th id="Sx5.T2.2.2.2.2.9.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">M3D</th>
<th id="Sx5.T2.2.2.2.2.9.7.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">TLV</th>
<td id="Sx5.T2.2.2.2.2.9.7.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="Sx5.T2.2.2.2.2.9.7.3.1" class="ltx_text ltx_font_bold">36.2</span></td>
<td id="Sx5.T2.2.2.2.2.9.7.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="Sx5.T2.2.2.2.2.9.7.4.1" class="ltx_text ltx_font_bold">42.8</span></td>
<td id="Sx5.T2.2.2.2.2.9.7.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="Sx5.T2.2.2.2.2.9.7.5.1" class="ltx_text ltx_font_bold">28.0</span></td>
<td id="Sx5.T2.2.2.2.2.9.7.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="Sx5.T2.2.2.2.2.9.7.6.1" class="ltx_text ltx_font_bold">37.3</span></td>
</tr>
<tr id="Sx5.T2.2.2.2.2.2" class="ltx_tr">
<th id="Sx5.T2.2.2.2.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">M3D<math id="Sx5.T2.2.2.2.2.2.1.m1.1" class="ltx_Math" alttext="{}_{\texttt{GT}}" display="inline"><semantics id="Sx5.T2.2.2.2.2.2.1.m1.1a"><msub id="Sx5.T2.2.2.2.2.2.1.m1.1.1" xref="Sx5.T2.2.2.2.2.2.1.m1.1.1.cmml"><mi id="Sx5.T2.2.2.2.2.2.1.m1.1.1a" xref="Sx5.T2.2.2.2.2.2.1.m1.1.1.cmml"></mi><mtext class="ltx_mathvariant_monospace" id="Sx5.T2.2.2.2.2.2.1.m1.1.1.1" xref="Sx5.T2.2.2.2.2.2.1.m1.1.1.1a.cmml">GT</mtext></msub><annotation-xml encoding="MathML-Content" id="Sx5.T2.2.2.2.2.2.1.m1.1b"><apply id="Sx5.T2.2.2.2.2.2.1.m1.1.1.cmml" xref="Sx5.T2.2.2.2.2.2.1.m1.1.1"><ci id="Sx5.T2.2.2.2.2.2.1.m1.1.1.1a.cmml" xref="Sx5.T2.2.2.2.2.2.1.m1.1.1.1"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="Sx5.T2.2.2.2.2.2.1.m1.1.1.1.cmml" xref="Sx5.T2.2.2.2.2.2.1.m1.1.1.1">GT</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx5.T2.2.2.2.2.2.1.m1.1c">{}_{\texttt{GT}}</annotation></semantics></math>
</th>
<th id="Sx5.T2.2.2.2.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">TLV</th>
<td id="Sx5.T2.2.2.2.2.2.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">44.6</td>
<td id="Sx5.T2.2.2.2.2.2.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">50.4</td>
<td id="Sx5.T2.2.2.2.2.2.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">35.4</td>
<td id="Sx5.T2.2.2.2.2.2.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">44.7</td>
</tr>
<tr id="Sx5.T2.2.2.2.2.10.8" class="ltx_tr">
<th id="Sx5.T2.2.2.2.2.10.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">Human</th>
<th id="Sx5.T2.2.2.2.2.10.8.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">–</th>
<td id="Sx5.T2.2.2.2.2.10.8.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">–</td>
<td id="Sx5.T2.2.2.2.2.10.8.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">–</td>
<td id="Sx5.T2.2.2.2.2.10.8.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">88.6</td>
<td id="Sx5.T2.2.2.2.2.10.8.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">91.9</td>
</tr>
</tbody>
</table>
</span></div>
<p id="Sx5.T2.2.3" class="ltx_p ltx_align_center"><span id="Sx5.T2.2.3.1" class="ltx_text">(a) Performance of main task.</span></p>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<div id="Sx5.T2.4" class="ltx_block ltx_figure_panel ltx_minipage ltx_align_middle" style="width:172.0pt;">
<div id="Sx5.T2.4.2.2" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:187.7pt;height:194.4pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-10.4pt,10.8pt) scale(0.9,0.9) ;">
<table id="Sx5.T2.4.2.2.2" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="Sx5.T2.4.2.2.2.3.1" class="ltx_tr">
<th id="Sx5.T2.4.2.2.2.3.1.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;"></th>
<th id="Sx5.T2.4.2.2.2.3.1.2" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;"></th>
<th id="Sx5.T2.4.2.2.2.3.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;" colspan="2">Dev</th>
<th id="Sx5.T2.4.2.2.2.3.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;" colspan="2">Test</th>
</tr>
<tr id="Sx5.T2.4.2.2.2.4.2" class="ltx_tr">
<th id="Sx5.T2.4.2.2.2.4.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">Model</th>
<th id="Sx5.T2.4.2.2.2.4.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">Modal</th>
<th id="Sx5.T2.4.2.2.2.4.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column" style="padding-left:3.0pt;padding-right:3.0pt;">EM</th>
<th id="Sx5.T2.4.2.2.2.4.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column" style="padding-left:3.0pt;padding-right:3.0pt;">F1</th>
<th id="Sx5.T2.4.2.2.2.4.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column" style="padding-left:3.0pt;padding-right:3.0pt;">EM</th>
<th id="Sx5.T2.4.2.2.2.4.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column" style="padding-left:3.0pt;padding-right:3.0pt;">F1</th>
</tr>
<tr id="Sx5.T2.4.2.2.2.5.3" class="ltx_tr">
<th id="Sx5.T2.4.2.2.2.5.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">BM25</th>
<th id="Sx5.T2.4.2.2.2.5.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">T</th>
<th id="Sx5.T2.4.2.2.2.5.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">40.1</th>
<th id="Sx5.T2.4.2.2.2.5.3.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">46.0</th>
<th id="Sx5.T2.4.2.2.2.5.3.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">35.9</th>
<th id="Sx5.T2.4.2.2.2.5.3.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">47.5</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="Sx5.T2.3.1.1.1.1" class="ltx_tr">
<th id="Sx5.T2.3.1.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">CLIP<math id="Sx5.T2.3.1.1.1.1.1.m1.1" class="ltx_Math" alttext="{}_{\texttt{zero}}" display="inline"><semantics id="Sx5.T2.3.1.1.1.1.1.m1.1a"><msub id="Sx5.T2.3.1.1.1.1.1.m1.1.1" xref="Sx5.T2.3.1.1.1.1.1.m1.1.1.cmml"><mi id="Sx5.T2.3.1.1.1.1.1.m1.1.1a" xref="Sx5.T2.3.1.1.1.1.1.m1.1.1.cmml"></mi><mtext class="ltx_mathvariant_monospace" id="Sx5.T2.3.1.1.1.1.1.m1.1.1.1" xref="Sx5.T2.3.1.1.1.1.1.m1.1.1.1a.cmml">zero</mtext></msub><annotation-xml encoding="MathML-Content" id="Sx5.T2.3.1.1.1.1.1.m1.1b"><apply id="Sx5.T2.3.1.1.1.1.1.m1.1.1.cmml" xref="Sx5.T2.3.1.1.1.1.1.m1.1.1"><ci id="Sx5.T2.3.1.1.1.1.1.m1.1.1.1a.cmml" xref="Sx5.T2.3.1.1.1.1.1.m1.1.1.1"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="Sx5.T2.3.1.1.1.1.1.m1.1.1.1.cmml" xref="Sx5.T2.3.1.1.1.1.1.m1.1.1.1">zero</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx5.T2.3.1.1.1.1.1.m1.1c">{}_{\texttt{zero}}</annotation></semantics></math>
</th>
<th id="Sx5.T2.3.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">V</th>
<td id="Sx5.T2.3.1.1.1.1.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">33.0</td>
<td id="Sx5.T2.3.1.1.1.1.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">34.8</td>
<td id="Sx5.T2.3.1.1.1.1.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">30.6</td>
<td id="Sx5.T2.3.1.1.1.1.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">34.4</td>
</tr>
<tr id="Sx5.T2.4.2.2.2.6.1" class="ltx_tr">
<th id="Sx5.T2.4.2.2.2.6.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">CLIP</th>
<th id="Sx5.T2.4.2.2.2.6.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">V</th>
<td id="Sx5.T2.4.2.2.2.6.1.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">40.6</td>
<td id="Sx5.T2.4.2.2.2.6.1.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">43.0</td>
<td id="Sx5.T2.4.2.2.2.6.1.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">39.3</td>
<td id="Sx5.T2.4.2.2.2.6.1.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">43.5</td>
</tr>
<tr id="Sx5.T2.4.2.2.2.7.2" class="ltx_tr">
<th id="Sx5.T2.4.2.2.2.7.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">BERT</th>
<th id="Sx5.T2.4.2.2.2.7.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">T</th>
<td id="Sx5.T2.4.2.2.2.7.2.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">60.9</td>
<td id="Sx5.T2.4.2.2.2.7.2.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">74.4</td>
<td id="Sx5.T2.4.2.2.2.7.2.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">50.3</td>
<td id="Sx5.T2.4.2.2.2.7.2.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">69.2</td>
</tr>
<tr id="Sx5.T2.4.2.2.2.2" class="ltx_tr">
<th id="Sx5.T2.4.2.2.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">BERT + <math id="Sx5.T2.4.2.2.2.2.1.m1.1" class="ltx_Math" alttext="\mathbf{z}^{{\rm lay}}" display="inline"><semantics id="Sx5.T2.4.2.2.2.2.1.m1.1a"><msup id="Sx5.T2.4.2.2.2.2.1.m1.1.1" xref="Sx5.T2.4.2.2.2.2.1.m1.1.1.cmml"><mi id="Sx5.T2.4.2.2.2.2.1.m1.1.1.2" xref="Sx5.T2.4.2.2.2.2.1.m1.1.1.2.cmml">𝐳</mi><mi id="Sx5.T2.4.2.2.2.2.1.m1.1.1.3" xref="Sx5.T2.4.2.2.2.2.1.m1.1.1.3.cmml">lay</mi></msup><annotation-xml encoding="MathML-Content" id="Sx5.T2.4.2.2.2.2.1.m1.1b"><apply id="Sx5.T2.4.2.2.2.2.1.m1.1.1.cmml" xref="Sx5.T2.4.2.2.2.2.1.m1.1.1"><csymbol cd="ambiguous" id="Sx5.T2.4.2.2.2.2.1.m1.1.1.1.cmml" xref="Sx5.T2.4.2.2.2.2.1.m1.1.1">superscript</csymbol><ci id="Sx5.T2.4.2.2.2.2.1.m1.1.1.2.cmml" xref="Sx5.T2.4.2.2.2.2.1.m1.1.1.2">𝐳</ci><ci id="Sx5.T2.4.2.2.2.2.1.m1.1.1.3.cmml" xref="Sx5.T2.4.2.2.2.2.1.m1.1.1.3">lay</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx5.T2.4.2.2.2.2.1.m1.1c">\mathbf{z}^{{\rm lay}}</annotation></semantics></math>
</th>
<th id="Sx5.T2.4.2.2.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">TL</th>
<td id="Sx5.T2.4.2.2.2.2.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">61.4</td>
<td id="Sx5.T2.4.2.2.2.2.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">75.2</td>
<td id="Sx5.T2.4.2.2.2.2.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">52.7</td>
<td id="Sx5.T2.4.2.2.2.2.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">71.0</td>
</tr>
<tr id="Sx5.T2.4.2.2.2.8.3" class="ltx_tr">
<th id="Sx5.T2.4.2.2.2.8.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">LayoutLM</th>
<th id="Sx5.T2.4.2.2.2.8.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">TL</th>
<td id="Sx5.T2.4.2.2.2.8.3.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">51.0</td>
<td id="Sx5.T2.4.2.2.2.8.3.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">63.7</td>
<td id="Sx5.T2.4.2.2.2.8.3.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">42.0</td>
<td id="Sx5.T2.4.2.2.2.8.3.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">59.9</td>
</tr>
<tr id="Sx5.T2.4.2.2.2.9.4" class="ltx_tr">
<th id="Sx5.T2.4.2.2.2.9.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">LayoutLMv2</th>
<th id="Sx5.T2.4.2.2.2.9.4.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">TLV</th>
<td id="Sx5.T2.4.2.2.2.9.4.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">63.3</td>
<td id="Sx5.T2.4.2.2.2.9.4.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">77.1</td>
<td id="Sx5.T2.4.2.2.2.9.4.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">51.7</td>
<td id="Sx5.T2.4.2.2.2.9.4.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">71.5</td>
</tr>
<tr id="Sx5.T2.4.2.2.2.10.5" class="ltx_tr">
<th id="Sx5.T2.4.2.2.2.10.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">H-LayoutLMv2</th>
<th id="Sx5.T2.4.2.2.2.10.5.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">TLV</th>
<td id="Sx5.T2.4.2.2.2.10.5.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">81.1</td>
<td id="Sx5.T2.4.2.2.2.10.5.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="Sx5.T2.4.2.2.2.10.5.4.1" class="ltx_text ltx_font_bold">89.5</span></td>
<td id="Sx5.T2.4.2.2.2.10.5.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">69.8</td>
<td id="Sx5.T2.4.2.2.2.10.5.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="Sx5.T2.4.2.2.2.10.5.6.1" class="ltx_text ltx_font_bold">85.6</span></td>
</tr>
<tr id="Sx5.T2.4.2.2.2.11.6" class="ltx_tr">
<th id="Sx5.T2.4.2.2.2.11.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">M3D</th>
<th id="Sx5.T2.4.2.2.2.11.6.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">TLV</th>
<td id="Sx5.T2.4.2.2.2.11.6.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="Sx5.T2.4.2.2.2.11.6.3.1" class="ltx_text ltx_font_bold">83.1</span></td>
<td id="Sx5.T2.4.2.2.2.11.6.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">87.7</td>
<td id="Sx5.T2.4.2.2.2.11.6.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="Sx5.T2.4.2.2.2.11.6.5.1" class="ltx_text ltx_font_bold">75.0</span></td>
<td id="Sx5.T2.4.2.2.2.11.6.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">83.8</td>
</tr>
<tr id="Sx5.T2.4.2.2.2.12.7" class="ltx_tr">
<th id="Sx5.T2.4.2.2.2.12.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">Human</th>
<th id="Sx5.T2.4.2.2.2.12.7.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">–</th>
<td id="Sx5.T2.4.2.2.2.12.7.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">–</td>
<td id="Sx5.T2.4.2.2.2.12.7.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">–</td>
<td id="Sx5.T2.4.2.2.2.12.7.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">97.7</td>
<td id="Sx5.T2.4.2.2.2.12.7.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">98.0</td>
</tr>
</tbody>
</table>
</span></div>
<p id="Sx5.T2.4.3" class="ltx_p ltx_align_center"><span id="Sx5.T2.4.3.1" class="ltx_text">(b) Performance of evidence selection task.</span></p>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<div id="Sx5.T2.6" class="ltx_block ltx_figure_panel ltx_minipage ltx_align_middle" style="width:151.8pt;">
<div id="Sx5.T2.6.2.2" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:181.9pt;height:210.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-10.1pt,11.7pt) scale(0.9,0.9) ;">
<table id="Sx5.T2.6.2.2.2" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="Sx5.T2.6.2.2.2.3.1" class="ltx_tr">
<th id="Sx5.T2.6.2.2.2.3.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_r ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;"></th>
<th id="Sx5.T2.6.2.2.2.3.1.2" class="ltx_td ltx_th ltx_th_row ltx_border_r ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;"></th>
<td id="Sx5.T2.6.2.2.2.3.1.3" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;" colspan="2">Dev</td>
<td id="Sx5.T2.6.2.2.2.3.1.4" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;" colspan="2">Test</td>
</tr>
<tr id="Sx5.T2.6.2.2.2.4.2" class="ltx_tr">
<th id="Sx5.T2.6.2.2.2.4.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">Model</th>
<th id="Sx5.T2.6.2.2.2.4.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">Modal</th>
<td id="Sx5.T2.6.2.2.2.4.2.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">EM</td>
<td id="Sx5.T2.6.2.2.2.4.2.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">F1</td>
<td id="Sx5.T2.6.2.2.2.4.2.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">EM</td>
<td id="Sx5.T2.6.2.2.2.4.2.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">F1</td>
</tr>
<tr id="Sx5.T2.6.2.2.2.5.3" class="ltx_tr">
<th id="Sx5.T2.6.2.2.2.5.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">Q-only</th>
<th id="Sx5.T2.6.2.2.2.5.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">–</th>
<td id="Sx5.T2.6.2.2.2.5.3.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">9.4</td>
<td id="Sx5.T2.6.2.2.2.5.3.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">11.4</td>
<td id="Sx5.T2.6.2.2.2.5.3.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">10.7</td>
<td id="Sx5.T2.6.2.2.2.5.3.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">13.5</td>
</tr>
<tr id="Sx5.T2.6.2.2.2.6.4" class="ltx_tr">
<th id="Sx5.T2.6.2.2.2.6.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">UniVL</th>
<th id="Sx5.T2.6.2.2.2.6.4.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">V</th>
<td id="Sx5.T2.6.2.2.2.6.4.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">8.8</td>
<td id="Sx5.T2.6.2.2.2.6.4.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">12.1</td>
<td id="Sx5.T2.6.2.2.2.6.4.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">10.6</td>
<td id="Sx5.T2.6.2.2.2.6.4.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">14.1</td>
</tr>
<tr id="Sx5.T2.6.2.2.2.7.5" class="ltx_tr">
<th id="Sx5.T2.6.2.2.2.7.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">PreasM</th>
<th id="Sx5.T2.6.2.2.2.7.5.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">T</th>
<td id="Sx5.T2.6.2.2.2.7.5.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">36.3</td>
<td id="Sx5.T2.6.2.2.2.7.5.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">41.9</td>
<td id="Sx5.T2.6.2.2.2.7.5.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">30.7</td>
<td id="Sx5.T2.6.2.2.2.7.5.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">38.2</td>
</tr>
<tr id="Sx5.T2.6.2.2.2.8.6" class="ltx_tr">
<th id="Sx5.T2.6.2.2.2.8.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">T5</th>
<th id="Sx5.T2.6.2.2.2.8.6.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">T</th>
<td id="Sx5.T2.6.2.2.2.8.6.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">35.2</td>
<td id="Sx5.T2.6.2.2.2.8.6.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">41.3</td>
<td id="Sx5.T2.6.2.2.2.8.6.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">29.3</td>
<td id="Sx5.T2.6.2.2.2.8.6.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">37.9</td>
</tr>
<tr id="Sx5.T2.5.1.1.1.1" class="ltx_tr">
<th id="Sx5.T2.5.1.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">T5 + <math id="Sx5.T2.5.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\mathbf{z}^{{\rm lay}}" display="inline"><semantics id="Sx5.T2.5.1.1.1.1.1.m1.1a"><msup id="Sx5.T2.5.1.1.1.1.1.m1.1.1" xref="Sx5.T2.5.1.1.1.1.1.m1.1.1.cmml"><mi id="Sx5.T2.5.1.1.1.1.1.m1.1.1.2" xref="Sx5.T2.5.1.1.1.1.1.m1.1.1.2.cmml">𝐳</mi><mi id="Sx5.T2.5.1.1.1.1.1.m1.1.1.3" xref="Sx5.T2.5.1.1.1.1.1.m1.1.1.3.cmml">lay</mi></msup><annotation-xml encoding="MathML-Content" id="Sx5.T2.5.1.1.1.1.1.m1.1b"><apply id="Sx5.T2.5.1.1.1.1.1.m1.1.1.cmml" xref="Sx5.T2.5.1.1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="Sx5.T2.5.1.1.1.1.1.m1.1.1.1.cmml" xref="Sx5.T2.5.1.1.1.1.1.m1.1.1">superscript</csymbol><ci id="Sx5.T2.5.1.1.1.1.1.m1.1.1.2.cmml" xref="Sx5.T2.5.1.1.1.1.1.m1.1.1.2">𝐳</ci><ci id="Sx5.T2.5.1.1.1.1.1.m1.1.1.3.cmml" xref="Sx5.T2.5.1.1.1.1.1.m1.1.1.3">lay</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx5.T2.5.1.1.1.1.1.m1.1c">\mathbf{z}^{{\rm lay}}</annotation></semantics></math>
</th>
<th id="Sx5.T2.5.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">TL</th>
<td id="Sx5.T2.5.1.1.1.1.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">36.9</td>
<td id="Sx5.T2.5.1.1.1.1.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">43.2</td>
<td id="Sx5.T2.5.1.1.1.1.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">31.0</td>
<td id="Sx5.T2.5.1.1.1.1.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">39.7</td>
</tr>
<tr id="Sx5.T2.6.2.2.2.9.7" class="ltx_tr">
<th id="Sx5.T2.6.2.2.2.9.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">LayoutT5</th>
<th id="Sx5.T2.6.2.2.2.9.7.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">TLV</th>
<td id="Sx5.T2.6.2.2.2.9.7.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">38.9</td>
<td id="Sx5.T2.6.2.2.2.9.7.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">44.8</td>
<td id="Sx5.T2.6.2.2.2.9.7.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">31.7</td>
<td id="Sx5.T2.6.2.2.2.9.7.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">39.9</td>
</tr>
<tr id="Sx5.T2.6.2.2.2.10.8" class="ltx_tr">
<th id="Sx5.T2.6.2.2.2.10.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">LayoutLMv2†</th>
<th id="Sx5.T2.6.2.2.2.10.8.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">TLV</th>
<td id="Sx5.T2.6.2.2.2.10.8.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">26.5</td>
<td id="Sx5.T2.6.2.2.2.10.8.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">33.4</td>
<td id="Sx5.T2.6.2.2.2.10.8.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">21.4</td>
<td id="Sx5.T2.6.2.2.2.10.8.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">29.3</td>
</tr>
<tr id="Sx5.T2.6.2.2.2.11.9" class="ltx_tr">
<th id="Sx5.T2.6.2.2.2.11.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">FiD</th>
<th id="Sx5.T2.6.2.2.2.11.9.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">T</th>
<td id="Sx5.T2.6.2.2.2.11.9.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">37.6</td>
<td id="Sx5.T2.6.2.2.2.11.9.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">42.9</td>
<td id="Sx5.T2.6.2.2.2.11.9.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">30.4</td>
<td id="Sx5.T2.6.2.2.2.11.9.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">38.9</td>
</tr>
<tr id="Sx5.T2.6.2.2.2.2" class="ltx_tr">
<th id="Sx5.T2.6.2.2.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">FiD + <math id="Sx5.T2.6.2.2.2.2.1.m1.1" class="ltx_Math" alttext="\mathbf{z}^{{\rm lay}}" display="inline"><semantics id="Sx5.T2.6.2.2.2.2.1.m1.1a"><msup id="Sx5.T2.6.2.2.2.2.1.m1.1.1" xref="Sx5.T2.6.2.2.2.2.1.m1.1.1.cmml"><mi id="Sx5.T2.6.2.2.2.2.1.m1.1.1.2" xref="Sx5.T2.6.2.2.2.2.1.m1.1.1.2.cmml">𝐳</mi><mi id="Sx5.T2.6.2.2.2.2.1.m1.1.1.3" xref="Sx5.T2.6.2.2.2.2.1.m1.1.1.3.cmml">lay</mi></msup><annotation-xml encoding="MathML-Content" id="Sx5.T2.6.2.2.2.2.1.m1.1b"><apply id="Sx5.T2.6.2.2.2.2.1.m1.1.1.cmml" xref="Sx5.T2.6.2.2.2.2.1.m1.1.1"><csymbol cd="ambiguous" id="Sx5.T2.6.2.2.2.2.1.m1.1.1.1.cmml" xref="Sx5.T2.6.2.2.2.2.1.m1.1.1">superscript</csymbol><ci id="Sx5.T2.6.2.2.2.2.1.m1.1.1.2.cmml" xref="Sx5.T2.6.2.2.2.2.1.m1.1.1.2">𝐳</ci><ci id="Sx5.T2.6.2.2.2.2.1.m1.1.1.3.cmml" xref="Sx5.T2.6.2.2.2.2.1.m1.1.1.3">lay</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx5.T2.6.2.2.2.2.1.m1.1c">\mathbf{z}^{{\rm lay}}</annotation></semantics></math>
</th>
<th id="Sx5.T2.6.2.2.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">TL</th>
<td id="Sx5.T2.6.2.2.2.2.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">38.1</td>
<td id="Sx5.T2.6.2.2.2.2.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">43.3</td>
<td id="Sx5.T2.6.2.2.2.2.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">30.6</td>
<td id="Sx5.T2.6.2.2.2.2.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">38.9</td>
</tr>
<tr id="Sx5.T2.6.2.2.2.12.10" class="ltx_tr">
<th id="Sx5.T2.6.2.2.2.12.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">M3D</th>
<th id="Sx5.T2.6.2.2.2.12.10.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">TLV</th>
<td id="Sx5.T2.6.2.2.2.12.10.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="Sx5.T2.6.2.2.2.12.10.3.1" class="ltx_text ltx_font_bold">41.3</span></td>
<td id="Sx5.T2.6.2.2.2.12.10.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="Sx5.T2.6.2.2.2.12.10.4.1" class="ltx_text ltx_font_bold">47.1</span></td>
<td id="Sx5.T2.6.2.2.2.12.10.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="Sx5.T2.6.2.2.2.12.10.5.1" class="ltx_text ltx_font_bold">33.5</span></td>
<td id="Sx5.T2.6.2.2.2.12.10.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="Sx5.T2.6.2.2.2.12.10.6.1" class="ltx_text ltx_font_bold">41.7</span></td>
</tr>
<tr id="Sx5.T2.6.2.2.2.13.11" class="ltx_tr">
<th id="Sx5.T2.6.2.2.2.13.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">Human</th>
<th id="Sx5.T2.6.2.2.2.13.11.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">–</th>
<td id="Sx5.T2.6.2.2.2.13.11.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">–</td>
<td id="Sx5.T2.6.2.2.2.13.11.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">–</td>
<td id="Sx5.T2.6.2.2.2.13.11.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">89.8</td>
<td id="Sx5.T2.6.2.2.2.13.11.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">93.0</td>
</tr>
</tbody>
</table>
</span></div>
<p id="Sx5.T2.6.3" class="ltx_p ltx_align_center"><span id="Sx5.T2.6.3.1" class="ltx_text">(c) Performance of question answering task.</span></p>
</div>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span>Performance of SlideVQA tasks. “T/L/V” denotes the “text/layout/visual” modality of images. †denotes the extractive approach. The pipeline models answer the question based on the top-3 evidences obtained by H-LayoutLMv2. M3D<math id="Sx5.T2.10.m1.1" class="ltx_Math" alttext="{}_{\texttt{GT}}" display="inline"><semantics id="Sx5.T2.10.m1.1b"><msub id="Sx5.T2.10.m1.1.1" xref="Sx5.T2.10.m1.1.1.cmml"><mi id="Sx5.T2.10.m1.1.1b" xref="Sx5.T2.10.m1.1.1.cmml"></mi><mtext class="ltx_mathvariant_monospace" id="Sx5.T2.10.m1.1.1.1" xref="Sx5.T2.10.m1.1.1.1a.cmml">GT</mtext></msub><annotation-xml encoding="MathML-Content" id="Sx5.T2.10.m1.1c"><apply id="Sx5.T2.10.m1.1.1.cmml" xref="Sx5.T2.10.m1.1.1"><ci id="Sx5.T2.10.m1.1.1.1a.cmml" xref="Sx5.T2.10.m1.1.1.1"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="Sx5.T2.10.m1.1.1.1.cmml" xref="Sx5.T2.10.m1.1.1.1">GT</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx5.T2.10.m1.1d">{}_{\texttt{GT}}</annotation></semantics></math> knows the ground-truth evidence.
+ <math id="Sx5.T2.11.m2.1" class="ltx_Math" alttext="\mathbf{z}^{{\rm lay}}" display="inline"><semantics id="Sx5.T2.11.m2.1b"><msup id="Sx5.T2.11.m2.1.1" xref="Sx5.T2.11.m2.1.1.cmml"><mi id="Sx5.T2.11.m2.1.1.2" xref="Sx5.T2.11.m2.1.1.2.cmml">𝐳</mi><mi id="Sx5.T2.11.m2.1.1.3" xref="Sx5.T2.11.m2.1.1.3.cmml">lay</mi></msup><annotation-xml encoding="MathML-Content" id="Sx5.T2.11.m2.1c"><apply id="Sx5.T2.11.m2.1.1.cmml" xref="Sx5.T2.11.m2.1.1"><csymbol cd="ambiguous" id="Sx5.T2.11.m2.1.1.1.cmml" xref="Sx5.T2.11.m2.1.1">superscript</csymbol><ci id="Sx5.T2.11.m2.1.1.2.cmml" xref="Sx5.T2.11.m2.1.1.2">𝐳</ci><ci id="Sx5.T2.11.m2.1.1.3.cmml" xref="Sx5.T2.11.m2.1.1.3">lay</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx5.T2.11.m2.1d">\mathbf{z}^{{\rm lay}}</annotation></semantics></math> denotes addition of the layout embedding to the input embeddings. LayoutLM was not pre-trained in any matching task (e.g., text-image matching). CLIP<math id="Sx5.T2.12.m3.1" class="ltx_Math" alttext="{}_{\texttt{zero}}" display="inline"><semantics id="Sx5.T2.12.m3.1b"><msub id="Sx5.T2.12.m3.1.1" xref="Sx5.T2.12.m3.1.1.cmml"><mi id="Sx5.T2.12.m3.1.1b" xref="Sx5.T2.12.m3.1.1.cmml"></mi><mtext class="ltx_mathvariant_monospace" id="Sx5.T2.12.m3.1.1.1" xref="Sx5.T2.12.m3.1.1.1a.cmml">zero</mtext></msub><annotation-xml encoding="MathML-Content" id="Sx5.T2.12.m3.1c"><apply id="Sx5.T2.12.m3.1.1.cmml" xref="Sx5.T2.12.m3.1.1"><ci id="Sx5.T2.12.m3.1.1.1a.cmml" xref="Sx5.T2.12.m3.1.1.1"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="Sx5.T2.12.m3.1.1.1.cmml" xref="Sx5.T2.12.m3.1.1.1">zero</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx5.T2.12.m3.1d">{}_{\texttt{zero}}</annotation></semantics></math> denotes CLIP without fine-tuning.
</figcaption>
</figure>
<section id="Sx5.SSx1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">Experimental Setup</h3>

<div id="Sx5.SSx1.p1" class="ltx_para">
<p id="Sx5.SSx1.p1.1" class="ltx_p">We conducted experiments on the SlideVQA task, evidence selection task, and question answering task respectively defined in <span id="Sx5.SSx1.p1.1.1" class="ltx_text ltx_font_smallcaps">MainTask</span>, <span id="Sx5.SSx1.p1.1.2" class="ltx_text ltx_font_smallcaps">Subtasks</span> <a href="#Thmsubtask1" title="Subtask 1 (Evidence Selection). ‣ Task Overview and Formulation ‣ The SlideVQA Task and Dataset ‣ SlideVQA: A Dataset for Document Visual Question Answering on Multiple Images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> and <a href="#Thmsubtask2" title="Subtask 2 (Question Answering). ‣ Task Overview and Formulation ‣ The SlideVQA Task and Dataset ‣ SlideVQA: A Dataset for Document Visual Question Answering on Multiple Images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<section id="Sx5.SSx1.SSSx1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Main task baselines.</h4>

<div id="Sx5.SSx1.SSSx1.p1" class="ltx_para">
<p id="Sx5.SSx1.SSSx1.p1.1" class="ltx_p">We mainly evaluated pipeline models as baselines, consisting of evidence selection that produces top-3 evidences and question answering that takes the selection results as input. Here, we introduced a hierarchical LayoutLMv2 (H-LayoutLMv2) inspired by <cite class="ltx_cite ltx_citemacro_citep">(Tu et al. <a href="#bib.bib38" title="" class="ltx_ref">2020</a>; Xu et al. <a href="#bib.bib42" title="" class="ltx_ref">2021</a>)</cite>, which encodes all slides simultaneously by using another Transformer layer, as the evidence selector. It achieved 96.0% on Recall@3 on the test set.
We used three generative QA models: a textual model <span id="Sx5.SSx1.SSSx1.p1.1.1" class="ltx_text ltx_font_bold">T5</span> <cite class="ltx_cite ltx_citemacro_citep">(Raffel et al. <a href="#bib.bib24" title="" class="ltx_ref">2020</a>)</cite>, a numerical and multi-hop model <span id="Sx5.SSx1.SSSx1.p1.1.2" class="ltx_text ltx_font_bold">PreasM</span> <cite class="ltx_cite ltx_citemacro_citep">(Yoran, Talmor, and Berant <a href="#bib.bib44" title="" class="ltx_ref">2022</a>)</cite>, and a document VQA model <span id="Sx5.SSx1.SSSx1.p1.1.3" class="ltx_text ltx_font_bold">LayoutT5</span> <cite class="ltx_cite ltx_citemacro_citep">(Tanaka, Nishida, and Yoshida <a href="#bib.bib35" title="" class="ltx_ref">2021</a>)</cite>.
We also used an extractive document VQA model <span id="Sx5.SSx1.SSSx1.p1.1.4" class="ltx_text ltx_font_bold">LayoutLMv2</span> to predict the single span.</p>
</div>
</section>
<section id="Sx5.SSx1.SSSx2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Evidence selection baselines.</h4>

<div id="Sx5.SSx1.SSSx2.p1" class="ltx_para">
<p id="Sx5.SSx1.SSSx2.p1.1" class="ltx_p">We also evaluated the evidence selection task alone.
<span id="Sx5.SSx1.SSSx2.p1.1.1" class="ltx_text ltx_font_bold">BM25</span> <cite class="ltx_cite ltx_citemacro_citep">(Robertson, Zaragoza et al. <a href="#bib.bib28" title="" class="ltx_ref">2009</a>)</cite> is a non-neural retrieval framework to estimate the relevance of texts to a search query.
For the neural models,
<span id="Sx5.SSx1.SSSx2.p1.1.2" class="ltx_text ltx_font_bold">CLIP</span> <cite class="ltx_cite ltx_citemacro_citep">(Radford et al. <a href="#bib.bib23" title="" class="ltx_ref">2021</a>)</cite> encodes the question and each image to predict the highest similar pair. BM25 and CLIP used the top-1 slide as the prediction.
<span id="Sx5.SSx1.SSSx2.p1.1.3" class="ltx_text ltx_font_bold">BERT</span> <cite class="ltx_cite ltx_citemacro_citep">(Devlin et al. <a href="#bib.bib5" title="" class="ltx_ref">2019</a>)</cite> is a pre-trained language model which only uses text information with the Transformer architecture. <span id="Sx5.SSx1.SSSx2.p1.1.4" class="ltx_text ltx_font_bold">LayoutLM</span> <cite class="ltx_cite ltx_citemacro_citep">(Xu et al. <a href="#bib.bib41" title="" class="ltx_ref">2020</a>)</cite> incorporates layout information into the input embeddings of BERT. <span id="Sx5.SSx1.SSSx2.p1.1.5" class="ltx_text ltx_font_bold">LayoutLMv2</span> includes image features produced by a CNN backbone in input embeddings. To model the interactions between the slides,
we used <span id="Sx5.SSx1.SSSx2.p1.1.6" class="ltx_text ltx_font_bold">H-LayoutLMv2</span> described in the previous section. For neural evidence selection baselines (except for CLIP), we use a hidden state of <span id="Sx5.SSx1.SSSx2.p1.1.7" class="ltx_text ltx_font_typewriter">[CLS]</span> in the last layer to feed into an MLP classifier with a sigmoid activation. Evidence is selected if its confidence of binary classification is above the optimal value on the development set.</p>
</div>
<div id="Sx5.SSx1.SSSx2.p2" class="ltx_para">
<p id="Sx5.SSx1.SSSx2.p2.1" class="ltx_p">To evaluate the effectiveness of our generative evidence selection module, we introduced <span id="Sx5.SSx1.SSSx2.p2.1.1" class="ltx_text ltx_font_bold">BinaryClass</span> as a classification baseline, which uses a two-layer MLP classifier with a sigmoid activation on top of each encoder representation at the start-of-sequence. We also introduced a generative baseline, <span id="Sx5.SSx1.SSSx2.p2.1.2" class="ltx_text ltx_font_bold">ChainGen</span>, which generates a sequence of selected slide page numbers before the answer <cite class="ltx_cite ltx_citemacro_citep">(Wei et al. <a href="#bib.bib40" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
</section>
<section id="Sx5.SSx1.SSSx3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Question answering baselines.</h4>

<div id="Sx5.SSx1.SSSx3.p1" class="ltx_para">
<p id="Sx5.SSx1.SSSx3.p1.1" class="ltx_p">In addition to the pipeline models,
we developed <span id="Sx5.SSx1.SSSx3.p1.1.1" class="ltx_text ltx_font_bold">Q-only</span>, which takes only the question into T5. We also used
a VideoQA model <span id="Sx5.SSx1.SSSx3.p1.1.2" class="ltx_text ltx_font_bold">UniVL</span> <cite class="ltx_cite ltx_citemacro_citep">(Luo et al. <a href="#bib.bib18" title="" class="ltx_ref">2020</a>)</cite>
that can take all of the slide images as input.
Furthermore, we evaluated our base model <span id="Sx5.SSx1.SSSx3.p1.1.3" class="ltx_text ltx_font_bold">FiD</span> <cite class="ltx_cite ltx_citemacro_citep">(Izacard and Grave <a href="#bib.bib12" title="" class="ltx_ref">2021</a>)</cite>.</p>
</div>
</section>
<section id="Sx5.SSx1.SSSx4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Human performance.</h4>

<div id="Sx5.SSx1.SSSx4.p1" class="ltx_para">
<p id="Sx5.SSx1.SSSx4.p1.1" class="ltx_p">We asked six crowdworkers (not among those recruited to collect our dataset) to select slide images relevant to the question and answer the question.</p>
</div>
</section>
<section id="Sx5.SSx1.SSSx5" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Evaluation metrics.</h4>

<div id="Sx5.SSx1.SSSx5.p1" class="ltx_para">
<p id="Sx5.SSx1.SSSx5.p1.1" class="ltx_p">Following HotpotQA <cite class="ltx_cite ltx_citemacro_citep">(Yang et al. <a href="#bib.bib43" title="" class="ltx_ref">2018</a>)</cite>, we used exact match (EM) and F1 on each question answering and evidence selection task and also used Joint EM (JEM) and Joint F1 (JF1) to evaluate both tasks. These joint metrics penalize models that perform poorly on either task and assess the accuracy and explainability of the question answering models.</p>
</div>
</section>
</section>
<section id="Sx5.SSx2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">Implementation Details</h3>

<div id="Sx5.SSx2.p1" class="ltx_para">
<p id="Sx5.SSx2.p1.1" class="ltx_p">We implemented all of the models in PyTorch and experimented on eight Tesla V100 32GB GPUs. The size of CLIP was <span id="Sx5.SSx2.p1.1.1" class="ltx_text ltx_font_typewriter">Large</span> and the size of the other models was <span id="Sx5.SSx2.p1.1.2" class="ltx_text ltx_font_typewriter">Base</span>. We fine-tuned the models using AdamW <cite class="ltx_cite ltx_citemacro_citep">(Loshchilov and Hutter <a href="#bib.bib17" title="" class="ltx_ref">2017</a>)</cite> with a learning rate of 5e-5 and a dropout rate of 10%, and we linearly warmed up the learning rate over 1000 steps. The batch size was set to 32. We evaluated models every 500 steps and selected the best one on the development set on the basis of the loss. We used a maximum length of 200 tokens for each input sequence of M3D, and set the maximum target sequence length to 50. We trained Faster-RCNN <cite class="ltx_cite ltx_citemacro_citep">(Ren et al. <a href="#bib.bib27" title="" class="ltx_ref">2015</a>)</cite> with a ResNet-101 <cite class="ltx_cite ltx_citemacro_citep">(He et al. <a href="#bib.bib10" title="" class="ltx_ref">2016</a>)</cite> backbone by using stochastic gradient descent (SGD) <cite class="ltx_cite ltx_citemacro_citep">(Ruder <a href="#bib.bib29" title="" class="ltx_ref">2016</a>)</cite> with a learning rate of 1e-3 and batch size of one. Standard anchor scales of [8, 16, 32] and anchor ratios of [0.5, 1.0, 2.0] were used. For the VideoQA baseline, we created a new video at a rate of five frames per second. We used the Google Cloud Vision API to extract text and bounding boxes from images. When the OCR word is tokenized into sub-word tokens, the bounding box coordinates of a sub-word token are the same as those of its whole word.</p>
</div>
</section>
<section id="Sx5.SSx3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">Experimental Results and Analysis</h3>

<section id="Sx5.SSx3.SSSx1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Does our model outperform the baselines?</h4>

<div id="Sx5.SSx3.SSSx1.p1" class="ltx_para">
<p id="Sx5.SSx3.SSSx1.p1.1" class="ltx_p">Table <a href="#Sx5.T2" title="Table 2 ‣ Experiments ‣ SlideVQA: A Dataset for Document Visual Question Answering on Multiple Images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> summarizes the results of the main tasks. As shown in Table <a href="#Sx5.T2" title="Table 2 ‣ Experiments ‣ SlideVQA: A Dataset for Document Visual Question Answering on Multiple Images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>a, M3D outperformed the baselines on joint EM/F1, where the metrics evaluate the consistency between the predicted evidence and answers. For the evidence selection task, Table <a href="#Sx5.T2" title="Table 2 ‣ Experiments ‣ SlideVQA: A Dataset for Document Visual Question Answering on Multiple Images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>b shows that H-LayoutLMv2 and M3D performed better than the baselines. This indicates that modeling the interaction between multiple slides
simultaneously is needed to improve performance. For the QA task, Table <a href="#Sx5.T2" title="Table 2 ‣ Experiments ‣ SlideVQA: A Dataset for Document Visual Question Answering on Multiple Images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>c shows that M3D outperformed the pipeline methods
in all metrics.
Our end-to-end M3D model is better at ignoring the slides irrelevant to the question than
the answer generator in the pipeline methods that strongly depend on the slides narrowed down by the evidence selector.
However, M3D<math id="Sx5.SSx3.SSSx1.p1.1.m1.1" class="ltx_Math" alttext="{}_{\texttt{GT}}" display="inline"><semantics id="Sx5.SSx3.SSSx1.p1.1.m1.1a"><msub id="Sx5.SSx3.SSSx1.p1.1.m1.1.1" xref="Sx5.SSx3.SSSx1.p1.1.m1.1.1.cmml"><mi id="Sx5.SSx3.SSSx1.p1.1.m1.1.1a" xref="Sx5.SSx3.SSSx1.p1.1.m1.1.1.cmml"></mi><mtext class="ltx_mathvariant_monospace" id="Sx5.SSx3.SSSx1.p1.1.m1.1.1.1" xref="Sx5.SSx3.SSSx1.p1.1.m1.1.1.1a.cmml">GT</mtext></msub><annotation-xml encoding="MathML-Content" id="Sx5.SSx3.SSSx1.p1.1.m1.1b"><apply id="Sx5.SSx3.SSSx1.p1.1.m1.1.1.cmml" xref="Sx5.SSx3.SSSx1.p1.1.m1.1.1"><ci id="Sx5.SSx3.SSSx1.p1.1.m1.1.1.1a.cmml" xref="Sx5.SSx3.SSSx1.p1.1.m1.1.1.1"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="Sx5.SSx3.SSSx1.p1.1.m1.1.1.1.cmml" xref="Sx5.SSx3.SSSx1.p1.1.m1.1.1.1">GT</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx5.SSx3.SSSx1.p1.1.m1.1c">{}_{\texttt{GT}}</annotation></semantics></math> in Table <a href="#Sx5.T2" title="Table 2 ‣ Experiments ‣ SlideVQA: A Dataset for Document Visual Question Answering on Multiple Images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>a achieved a significant improvement by knowing the ground-truth slides. There is room for improving the correctness of evidence selection.</p>
</div>
<figure id="Sx5.F6" class="ltx_figure"><img src="/html/2301.04883/assets/x9.png" id="Sx5.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="252" height="126" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Performance of models and humans on the answer types, reasoning types and numerical operation types in the test set. AE stands for “arithmetic expression”.</figcaption>
</figure>
</section>
<section id="Sx5.SSx3.SSSx2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">What are the characteristics of our dataset?</h4>

<div id="Sx5.SSx3.SSSx2.p1" class="ltx_para">
<p id="Sx5.SSx3.SSSx2.p1.1" class="ltx_p">Table <a href="#Sx5.T2" title="Table 2 ‣ Experiments ‣ SlideVQA: A Dataset for Document Visual Question Answering on Multiple Images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> shows that adding modality information tended to improve performance in all tasks. This demonstrates that SlideVQA requires methods to have the ability to jointly understand the text, layout, and visual modalities of documents. As shown in Table <a href="#Sx5.T2" title="Table 2 ‣ Experiments ‣ SlideVQA: A Dataset for Document Visual Question Answering on Multiple Images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>c, Q-only had the lowest performance, showing that the systems could not answer the question without reading documents in the SlideVQA task.
Additionally, UniVL has a comparative result to Q-only,
indicating that SlideVQA requires different abilities from VideoQA <cite class="ltx_cite ltx_citemacro_citep">(Le and Hoi <a href="#bib.bib14" title="" class="ltx_ref">2020</a>)</cite>, especially the ability to read texts in images.
Tables <a href="#Sx5.T2" title="Table 2 ‣ Experiments ‣ SlideVQA: A Dataset for Document Visual Question Answering on Multiple Images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>a and <a href="#Sx5.T2" title="Table 2 ‣ Experiments ‣ SlideVQA: A Dataset for Document Visual Question Answering on Multiple Images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>c show that LayoutT5, a generative model, significantly outperformed LayoutLMv2, an extractive approach. This result is inline with observations on the DROP dataset <cite class="ltx_cite ltx_citemacro_citep">(Dua et al. <a href="#bib.bib6" title="" class="ltx_ref">2019</a>)</cite>, which also has non-span answers <cite class="ltx_cite ltx_citemacro_citep">(Geva, Gupta, and Berant <a href="#bib.bib8" title="" class="ltx_ref">2020</a>)</cite>. Additionally, all of the models performed all of the tasks significantly worse than humans. To be specific, Figure <a href="#Sx5.F6" title="Figure 6 ‣ Does our model outperform the baselines? ‣ Experimental Results and Analysis ‣ Experiments ‣ SlideVQA: A Dataset for Document Visual Question Answering on Multiple Images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> illustrates that (i) better multi-hop reasoning over multiple images is needed and (ii) non-span answers to questions involving arithmetic operations have to be improved.</p>
</div>
<figure id="Sx5.T3" class="ltx_table">
<div id="Sx5.T3.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:249.9pt;height:119.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-25.6pt,12.2pt) scale(0.83,0.83) ;">
<table id="Sx5.T3.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="Sx5.T3.1.1.1.1" class="ltx_tr">
<th id="Sx5.T3.1.1.1.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_tt"></th>
<th id="Sx5.T3.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2">Main</th>
<th id="Sx5.T3.1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2">Select</th>
<th id="Sx5.T3.1.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2">QA</th>
</tr>
<tr id="Sx5.T3.1.1.2.2" class="ltx_tr">
<th id="Sx5.T3.1.1.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row">Model</th>
<th id="Sx5.T3.1.1.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column">JEM</th>
<th id="Sx5.T3.1.1.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column">JF1</th>
<th id="Sx5.T3.1.1.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column">EM</th>
<th id="Sx5.T3.1.1.2.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column">F1</th>
<th id="Sx5.T3.1.1.2.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column">EM</th>
<th id="Sx5.T3.1.1.2.2.7" class="ltx_td ltx_align_center ltx_th ltx_th_column">F1</th>
</tr>
<tr id="Sx5.T3.1.1.3.3" class="ltx_tr">
<th id="Sx5.T3.1.1.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t">M3D</th>
<th id="Sx5.T3.1.1.3.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="Sx5.T3.1.1.3.3.2.1" class="ltx_text ltx_font_bold">36.2</span></th>
<th id="Sx5.T3.1.1.3.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="Sx5.T3.1.1.3.3.3.1" class="ltx_text ltx_font_bold">42.8</span></th>
<th id="Sx5.T3.1.1.3.3.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="Sx5.T3.1.1.3.3.4.1" class="ltx_text ltx_font_bold">83.1</span></th>
<th id="Sx5.T3.1.1.3.3.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="Sx5.T3.1.1.3.3.5.1" class="ltx_text ltx_font_bold">87.7</span></th>
<th id="Sx5.T3.1.1.3.3.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="Sx5.T3.1.1.3.3.6.1" class="ltx_text ltx_font_bold">41.3</span></th>
<th id="Sx5.T3.1.1.3.3.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="Sx5.T3.1.1.3.3.7.1" class="ltx_text ltx_font_bold">47.1</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="Sx5.T3.1.1.4.1" class="ltx_tr">
<th id="Sx5.T3.1.1.4.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">w/o AE generation</th>
<td id="Sx5.T3.1.1.4.1.2" class="ltx_td ltx_align_center ltx_border_t">35.7</td>
<td id="Sx5.T3.1.1.4.1.3" class="ltx_td ltx_align_center ltx_border_t">42.3</td>
<td id="Sx5.T3.1.1.4.1.4" class="ltx_td ltx_align_center ltx_border_t">82.9</td>
<td id="Sx5.T3.1.1.4.1.5" class="ltx_td ltx_align_center ltx_border_t">87.7</td>
<td id="Sx5.T3.1.1.4.1.6" class="ltx_td ltx_align_center ltx_border_t">40.5</td>
<td id="Sx5.T3.1.1.4.1.7" class="ltx_td ltx_align_center ltx_border_t">46.3</td>
</tr>
<tr id="Sx5.T3.1.1.5.2" class="ltx_tr">
<th id="Sx5.T3.1.1.5.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">w/o Evidence selection</th>
<td id="Sx5.T3.1.1.5.2.2" class="ltx_td ltx_align_center">–</td>
<td id="Sx5.T3.1.1.5.2.3" class="ltx_td ltx_align_center">–</td>
<td id="Sx5.T3.1.1.5.2.4" class="ltx_td ltx_align_center">–</td>
<td id="Sx5.T3.1.1.5.2.5" class="ltx_td ltx_align_center">–</td>
<td id="Sx5.T3.1.1.5.2.6" class="ltx_td ltx_align_center">40.6</td>
<td id="Sx5.T3.1.1.5.2.7" class="ltx_td ltx_align_center">46.4</td>
</tr>
<tr id="Sx5.T3.1.1.6.3" class="ltx_tr">
<th id="Sx5.T3.1.1.6.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">w/o Layout features</th>
<td id="Sx5.T3.1.1.6.3.2" class="ltx_td ltx_align_center">35.1</td>
<td id="Sx5.T3.1.1.6.3.3" class="ltx_td ltx_align_center">42.0</td>
<td id="Sx5.T3.1.1.6.3.4" class="ltx_td ltx_align_center">82.4</td>
<td id="Sx5.T3.1.1.6.3.5" class="ltx_td ltx_align_center">87.1</td>
<td id="Sx5.T3.1.1.6.3.6" class="ltx_td ltx_align_center">40.3</td>
<td id="Sx5.T3.1.1.6.3.7" class="ltx_td ltx_align_center">46.3</td>
</tr>
<tr id="Sx5.T3.1.1.7.4" class="ltx_tr">
<th id="Sx5.T3.1.1.7.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">w/o Visual features</th>
<td id="Sx5.T3.1.1.7.4.2" class="ltx_td ltx_align_center">34.2</td>
<td id="Sx5.T3.1.1.7.4.3" class="ltx_td ltx_align_center">40.9</td>
<td id="Sx5.T3.1.1.7.4.4" class="ltx_td ltx_align_center">81.5</td>
<td id="Sx5.T3.1.1.7.4.5" class="ltx_td ltx_align_center">86.3</td>
<td id="Sx5.T3.1.1.7.4.6" class="ltx_td ltx_align_center">39.0</td>
<td id="Sx5.T3.1.1.7.4.7" class="ltx_td ltx_align_center">44.9</td>
</tr>
<tr id="Sx5.T3.1.1.8.5" class="ltx_tr">
<th id="Sx5.T3.1.1.8.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">w/o Text features</th>
<td id="Sx5.T3.1.1.8.5.2" class="ltx_td ltx_align_center ltx_border_bb">1.0</td>
<td id="Sx5.T3.1.1.8.5.3" class="ltx_td ltx_align_center ltx_border_bb">1.5</td>
<td id="Sx5.T3.1.1.8.5.4" class="ltx_td ltx_align_center ltx_border_bb">8.4</td>
<td id="Sx5.T3.1.1.8.5.5" class="ltx_td ltx_align_center ltx_border_bb">9.8</td>
<td id="Sx5.T3.1.1.8.5.6" class="ltx_td ltx_align_center ltx_border_bb">9.8</td>
<td id="Sx5.T3.1.1.8.5.7" class="ltx_td ltx_align_center ltx_border_bb">12.0</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Ablation study of M3D on dev set.</figcaption>
</figure>
<figure id="Sx5.T4" class="ltx_table">
<div id="Sx5.T4.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:237.5pt;height:89.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-24.3pt,9.2pt) scale(0.83,0.83) ;">
<table id="Sx5.T4.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="Sx5.T4.1.1.1.1" class="ltx_tr">
<th id="Sx5.T4.1.1.1.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_tt"></th>
<th id="Sx5.T4.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2">Main</th>
<th id="Sx5.T4.1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2">Select</th>
<th id="Sx5.T4.1.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2">QA</th>
</tr>
<tr id="Sx5.T4.1.1.2.2" class="ltx_tr">
<th id="Sx5.T4.1.1.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row">Model</th>
<th id="Sx5.T4.1.1.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column">JEM</th>
<th id="Sx5.T4.1.1.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column">JF1</th>
<th id="Sx5.T4.1.1.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column">EM</th>
<th id="Sx5.T4.1.1.2.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column">F1</th>
<th id="Sx5.T4.1.1.2.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column">EM</th>
<th id="Sx5.T4.1.1.2.2.7" class="ltx_td ltx_align_center ltx_th ltx_th_column">F1</th>
</tr>
<tr id="Sx5.T4.1.1.3.3" class="ltx_tr">
<th id="Sx5.T4.1.1.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t">M3D backbone</th>
<th id="Sx5.T4.1.1.3.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">–</th>
<th id="Sx5.T4.1.1.3.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">–</th>
<th id="Sx5.T4.1.1.3.3.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">–</th>
<th id="Sx5.T4.1.1.3.3.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">–</th>
<th id="Sx5.T4.1.1.3.3.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">39.0</th>
<th id="Sx5.T4.1.1.3.3.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">44.8</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="Sx5.T4.1.1.4.1" class="ltx_tr">
<th id="Sx5.T4.1.1.4.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">+ BinaryClass</th>
<td id="Sx5.T4.1.1.4.1.2" class="ltx_td ltx_align_center ltx_border_t">24.7</td>
<td id="Sx5.T4.1.1.4.1.3" class="ltx_td ltx_align_center ltx_border_t">34.8</td>
<td id="Sx5.T4.1.1.4.1.4" class="ltx_td ltx_align_center ltx_border_t">54.5</td>
<td id="Sx5.T4.1.1.4.1.5" class="ltx_td ltx_align_center ltx_border_t">68.5</td>
<td id="Sx5.T4.1.1.4.1.6" class="ltx_td ltx_align_center ltx_border_t">38.8</td>
<td id="Sx5.T4.1.1.4.1.7" class="ltx_td ltx_align_center ltx_border_t">44.8</td>
</tr>
<tr id="Sx5.T4.1.1.5.2" class="ltx_tr">
<th id="Sx5.T4.1.1.5.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">+ ChainGen</th>
<td id="Sx5.T4.1.1.5.2.2" class="ltx_td ltx_align_center">34.0</td>
<td id="Sx5.T4.1.1.5.2.3" class="ltx_td ltx_align_center">40.8</td>
<td id="Sx5.T4.1.1.5.2.4" class="ltx_td ltx_align_center">81.1</td>
<td id="Sx5.T4.1.1.5.2.5" class="ltx_td ltx_align_center">86.1</td>
<td id="Sx5.T4.1.1.5.2.6" class="ltx_td ltx_align_center">39.8</td>
<td id="Sx5.T4.1.1.5.2.7" class="ltx_td ltx_align_center">45.4</td>
</tr>
<tr id="Sx5.T4.1.1.6.3" class="ltx_tr">
<th id="Sx5.T4.1.1.6.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">+ MultiGen (<span id="Sx5.T4.1.1.6.3.1.1" class="ltx_text ltx_font_bold">Ours</span>)</th>
<td id="Sx5.T4.1.1.6.3.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="Sx5.T4.1.1.6.3.2.1" class="ltx_text ltx_font_bold">35.7</span></td>
<td id="Sx5.T4.1.1.6.3.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="Sx5.T4.1.1.6.3.3.1" class="ltx_text ltx_font_bold">42.3</span></td>
<td id="Sx5.T4.1.1.6.3.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="Sx5.T4.1.1.6.3.4.1" class="ltx_text ltx_font_bold">82.9</span></td>
<td id="Sx5.T4.1.1.6.3.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="Sx5.T4.1.1.6.3.5.1" class="ltx_text ltx_font_bold">87.7</span></td>
<td id="Sx5.T4.1.1.6.3.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="Sx5.T4.1.1.6.3.6.1" class="ltx_text ltx_font_bold">40.5</span></td>
<td id="Sx5.T4.1.1.6.3.7" class="ltx_td ltx_align_center ltx_border_bb"><span id="Sx5.T4.1.1.6.3.7.1" class="ltx_text ltx_font_bold">46.3</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>Performance comparison of different evidence selection methods on dev set.</figcaption>
</figure>
</section>
<section id="Sx5.SSx3.SSSx3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Do our sub-modules improve performance?</h4>

<div id="Sx5.SSx3.SSSx3.p1" class="ltx_para">
<p id="Sx5.SSx3.SSSx3.p1.1" class="ltx_p">Table <a href="#Sx5.T3" title="Table 3 ‣ What are the characteristics of our dataset? ‣ Experimental Results and Analysis ‣ Experiments ‣ SlideVQA: A Dataset for Document Visual Question Answering on Multiple Images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> lists the results of an ablation study. Here, performance consistently decreased as individual modules were removed from M3D. This indicates that each of the modules is effective. More precisely, the arithmetic expression (AE) generation was influential on the QA and Joint performance, meaning that predicting the arithmetic expression instead of the numerical value enhances the ability to generate answers with numerical reasoning. As shown in Figure <a href="#Sx5.F6" title="Figure 6 ‣ Does our model outperform the baselines? ‣ Experimental Results and Analysis ‣ Experiments ‣ SlideVQA: A Dataset for Document Visual Question Answering on Multiple Images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>, applying AE prediction increased F1 by a large margin (+10.4%) in the arithmetic type.</p>
</div>
</section>
<section id="Sx5.SSx3.SSSx4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">What are the effective evidence selection methods?</h4>

<div id="Sx5.SSx3.SSSx4.p1" class="ltx_para">
<p id="Sx5.SSx3.SSSx4.p1.1" class="ltx_p">Table <a href="#Sx5.T4" title="Table 4 ‣ What are the characteristics of our dataset? ‣ Experimental Results and Analysis ‣ Experiments ‣ SlideVQA: A Dataset for Document Visual Question Answering on Multiple Images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> shows that our method, which generates the evidence selection and question answering results separately, obtained the highest performance.
It seems that the generative methods (MultiGen and ChainGen) benefited from the text-to-text pre-training of T5 more than the classification-based method (BinaryClass). Our MultiGen decoder that separately trains evidence selection and question answering had the advantage of being easier to train than the ChainGen baseline decoder that trains the two tasks as a single sequence generation task.
</p>
</div>
</section>
<section id="Sx5.SSx3.SSSx5" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">On which categories does the object detection model not work well?</h4>

<figure id="Sx5.T5" class="ltx_table">
<div id="Sx5.T5.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:136.3pt;height:153pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-12.0pt,13.5pt) scale(0.85,0.85) ;">
<table id="Sx5.T5.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="Sx5.T5.1.1.1.1" class="ltx_tr">
<th id="Sx5.T5.1.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt">Class</th>
<th id="Sx5.T5.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Dev AP</th>
<th id="Sx5.T5.1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Test AP</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="Sx5.T5.1.1.2.1" class="ltx_tr">
<th id="Sx5.T5.1.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Title</th>
<td id="Sx5.T5.1.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t">86.8</td>
<td id="Sx5.T5.1.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t">87.5</td>
</tr>
<tr id="Sx5.T5.1.1.3.2" class="ltx_tr">
<th id="Sx5.T5.1.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Page-text</th>
<td id="Sx5.T5.1.1.3.2.2" class="ltx_td ltx_align_center">76.9</td>
<td id="Sx5.T5.1.1.3.2.3" class="ltx_td ltx_align_center">76.9</td>
</tr>
<tr id="Sx5.T5.1.1.4.3" class="ltx_tr">
<th id="Sx5.T5.1.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Obj-text</th>
<td id="Sx5.T5.1.1.4.3.2" class="ltx_td ltx_align_center">29.5</td>
<td id="Sx5.T5.1.1.4.3.3" class="ltx_td ltx_align_center">33.4</td>
</tr>
<tr id="Sx5.T5.1.1.5.4" class="ltx_tr">
<th id="Sx5.T5.1.1.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Caption</th>
<td id="Sx5.T5.1.1.5.4.2" class="ltx_td ltx_align_center">25.6</td>
<td id="Sx5.T5.1.1.5.4.3" class="ltx_td ltx_align_center">24.9</td>
</tr>
<tr id="Sx5.T5.1.1.6.5" class="ltx_tr">
<th id="Sx5.T5.1.1.6.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Other-text</th>
<td id="Sx5.T5.1.1.6.5.2" class="ltx_td ltx_align_center">40.5</td>
<td id="Sx5.T5.1.1.6.5.3" class="ltx_td ltx_align_center">39.4</td>
</tr>
<tr id="Sx5.T5.1.1.7.6" class="ltx_tr">
<th id="Sx5.T5.1.1.7.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Image</th>
<td id="Sx5.T5.1.1.7.6.2" class="ltx_td ltx_align_center">60.4</td>
<td id="Sx5.T5.1.1.7.6.3" class="ltx_td ltx_align_center">62.2</td>
</tr>
<tr id="Sx5.T5.1.1.8.7" class="ltx_tr">
<th id="Sx5.T5.1.1.8.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Diagram</th>
<td id="Sx5.T5.1.1.8.7.2" class="ltx_td ltx_align_center">65.4</td>
<td id="Sx5.T5.1.1.8.7.3" class="ltx_td ltx_align_center">64.0</td>
</tr>
<tr id="Sx5.T5.1.1.9.8" class="ltx_tr">
<th id="Sx5.T5.1.1.9.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Figure</th>
<td id="Sx5.T5.1.1.9.8.2" class="ltx_td ltx_align_center">74.1</td>
<td id="Sx5.T5.1.1.9.8.3" class="ltx_td ltx_align_center">68.8</td>
</tr>
<tr id="Sx5.T5.1.1.10.9" class="ltx_tr">
<th id="Sx5.T5.1.1.10.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">Table</th>
<td id="Sx5.T5.1.1.10.9.2" class="ltx_td ltx_align_center ltx_border_bb">67.0</td>
<td id="Sx5.T5.1.1.10.9.3" class="ltx_td ltx_align_center ltx_border_bb">65.6</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>Object detection performance of Faster-RCNN broken down by bounding box categories. We set an intersection-over union (IoU) threshold to 0.5.</figcaption>
</figure>
<div id="Sx5.SSx3.SSSx5.p1" class="ltx_para">
<p id="Sx5.SSx3.SSSx5.p1.1" class="ltx_p">Table <a href="#Sx5.T5" title="Table 5 ‣ On which categories does the object detection model not work well? ‣ Experimental Results and Analysis ‣ Experiments ‣ SlideVQA: A Dataset for Document Visual Question Answering on Multiple Images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> lists the object detection performance of Faster-RCNN broken down by bounding box categories. These results show that detecting randomly placed and small boxes, such as Obj-text, is more difficult than mostly fixed and large boxes, such as Title.</p>
</div>
<figure id="Sx5.F7" class="ltx_figure"><img src="/html/2301.04883/assets/x10.png" id="Sx5.F7.g1" class="ltx_graphics ltx_centering ltx_img_square" width="266" height="315" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Qualitative example. GT denotes the ground-truth. (<math id="Sx5.F7.2.m1.1" class="ltx_Math" alttext="\cdot" display="inline"><semantics id="Sx5.F7.2.m1.1b"><mo id="Sx5.F7.2.m1.1.1" xref="Sx5.F7.2.m1.1.1.cmml">⋅</mo><annotation-xml encoding="MathML-Content" id="Sx5.F7.2.m1.1c"><ci id="Sx5.F7.2.m1.1.1.cmml" xref="Sx5.F7.2.m1.1.1">⋅</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx5.F7.2.m1.1d">\cdot</annotation></semantics></math>) means the generated arithmetic expression. The slide deck can be viewed at <span class="ltx_ref ltx_nolink ltx_url ltx_ref_self">https://www.slideshare.net/musicbizassoc/nielsen-2015-music-biz-presentation-final</span>.</figcaption>
</figure>
</section>
<section id="Sx5.SSx3.SSSx6" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Qualitative examples.</h4>

<div id="Sx5.SSx3.SSSx6.p1" class="ltx_para">
<p id="Sx5.SSx3.SSSx6.p1.1" class="ltx_p">Figure <a href="#Sx5.F7" title="Figure 7 ‣ On which categories does the object detection model not work well? ‣ Experimental Results and Analysis ‣ Experiments ‣ SlideVQA: A Dataset for Document Visual Question Answering on Multiple Images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> demonstrates our model’s performance by visualizing a qualitative example. This example needs multi-hop reasoning and an answer involving an arithmetic operation. FiD gave an incorrect answer because it did not consider the visual layout of the slides.
Moreover, while LayoutT5 could not understand the process of getting numerical answers, M3D successfully extracted information (“11%” and “12%”) and generated the same answer as the ground-truth.
</p>
</div>
</section>
</section>
</section>
<section id="Sx6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Discussion and Limitations</h2>

<div id="Sx6.p1" class="ltx_para">
<p id="Sx6.p1.1" class="ltx_p">SlideVQA is the largest document VQA benchmark that uses multiple images as input and requires multi-hop reasoning; its limitation is that
the multi-hop questions created by editing are different from the questions humans might actually ask the system. We argue that developing models that
can reason over multiple images is an important research direction, and therefore, we employed an editing method that guarantees multi-hop questions and easily extends the dataset size.
Also, our model uses cross-attention on all evidence candidates, which may cause a computational problem when there are a lot of input images (e.g., as in the open-domain QA setting like DocCVQA). To remedy this problem,
we consider that models that train a two-stage selector that roughly narrows down candidates to a small number of images and then accurately selects evidence images and an answer generator in an end-to-end manner are promising <cite class="ltx_cite ltx_citemacro_citep">(Sachan et al. <a href="#bib.bib30" title="" class="ltx_ref">2021a</a>, <a href="#bib.bib31" title="" class="ltx_ref">b</a>)</cite>.</p>
</div>
</section>
<section id="Sx7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Conclusion</h2>

<div id="Sx7.p1" class="ltx_para">
<p id="Sx7.p1.1" class="ltx_p">We introduced a new document VQA dataset, SlideVQA, focused on the task of understanding slide decks composed of multiple images. We also introduced a unified end-to-end model, M3D, that can perform evidence selection and question answering tasks and enhance numerical reasoning by generating arithmetic expressions. While our evaluation highlighted the promise of this approach, it also revealed a huge gap compared with human performance, and several challenges emerge from multi-hop reasoning
on multiple images and generating answers with arithmetic operations.
We believe that our dataset will contribute to the development of intelligent assistant agents that can comprehend diverse real-world documents.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ba, Kiros, and Hinton (2016)</span>
<span class="ltx_bibblock">
Ba, L. J.; Kiros, R.; and Hinton, G. E. 2016.

</span>
<span class="ltx_bibblock">Layer Normalization.

</span>
<span class="ltx_bibblock"><em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">arXiv:1607.06450</em>.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bansal, Zhang, and Chellappa (2020)</span>
<span class="ltx_bibblock">
Bansal, A.; Zhang, Y.; and Chellappa, R. 2020.

</span>
<span class="ltx_bibblock">Visual question answering on image sets.

</span>
<span class="ltx_bibblock">In <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">ECCV</em>, 51–67.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2021)</span>
<span class="ltx_bibblock">
Chen, X.; Zhao, Z.; Chen, L.; Ji, J.; Zhang, D.; Luo, A.; Xiong, Y.; and Yu, K.
2021.

</span>
<span class="ltx_bibblock">WebSRC: A Dataset for Web-Based Structural Reading Comprehension.

</span>
<span class="ltx_bibblock">In <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">EMNLP</em>, 4173–4185.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cui et al. (2017)</span>
<span class="ltx_bibblock">
Cui, L.; Huang, S.; Wei, F.; Tan, C.; Duan, C.; and Zhou, M. 2017.

</span>
<span class="ltx_bibblock">SuperAgent: A Customer Service Chatbot for E-commerce Websites.

</span>
<span class="ltx_bibblock">In <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">ACL</em>, 97–102.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Devlin et al. (2019)</span>
<span class="ltx_bibblock">
Devlin, J.; Chang, M.; Lee, K.; and Toutanova, K. 2019.

</span>
<span class="ltx_bibblock">BERT: Pre-training of Deep Bidirectional Transformers for Language
Understanding.

</span>
<span class="ltx_bibblock">In <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">NAACL-HLT</em>, 4171–4186.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dua et al. (2019)</span>
<span class="ltx_bibblock">
Dua, D.; Wang, Y.; Dasigi, P.; Stanovsky, G.; Singh, S.; and Gardner, M. 2019.

</span>
<span class="ltx_bibblock">DROP: A Reading Comprehension Benchmark Requiring Discrete
Reasoning Over Paragraphs.

</span>
<span class="ltx_bibblock">In <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">ACL</em>, 2368–2378.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fu et al. (2022)</span>
<span class="ltx_bibblock">
Fu, T.; Wang, W. Y.; McDuff, D.; and Song, Y. 2022.

</span>
<span class="ltx_bibblock">DOC2PPT: Automatic Presentation Slides Generation from Scientific
Documents.

</span>
<span class="ltx_bibblock">In <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">AAAI</em>, 634–642.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Geva, Gupta, and Berant (2020)</span>
<span class="ltx_bibblock">
Geva, M.; Gupta, A.; and Berant, J. 2020.

</span>
<span class="ltx_bibblock">Injecting Numerical Reasoning Skills into Language Models.

</span>
<span class="ltx_bibblock">In <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">ACL</em>, 946–958.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Haurilet et al. (2019)</span>
<span class="ltx_bibblock">
Haurilet, M.; Roitberg, A.; Martinez, M.; and Stiefelhagen, R. 2019.

</span>
<span class="ltx_bibblock">Wise—slide segmentation in the wild.

</span>
<span class="ltx_bibblock">In <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">ICDAR</em>, 343–348.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et al. (2016)</span>
<span class="ltx_bibblock">
He, K.; Zhang, X.; Ren, S.; and Sun, J. 2016.

</span>
<span class="ltx_bibblock">Deep Residual Learning for Image Recognition.

</span>
<span class="ltx_bibblock">In <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">CVPR</em>, 770–778.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hong et al. (2019)</span>
<span class="ltx_bibblock">
Hong, Y.; Wang, J.; Jia, Y.; Zhang, W.; and Wang, X. 2019.

</span>
<span class="ltx_bibblock">Academic Reader: An Interactive Question Answering System on Academic
Literatures.

</span>
<span class="ltx_bibblock">In <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">AAAI</em>, 9855–9856.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Izacard and Grave (2021)</span>
<span class="ltx_bibblock">
Izacard, G.; and Grave, E. 2021.

</span>
<span class="ltx_bibblock">Leveraging Passage Retrieval with Generative Models for Open Domain
Question Answering.

</span>
<span class="ltx_bibblock">In <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">EACL</em>, 874–880.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kembhavi et al. (2017)</span>
<span class="ltx_bibblock">
Kembhavi, A.; Seo, M. J.; Schwenk, D.; Choi, J.; Farhadi, A.; and Hajishirzi,
H. 2017.

</span>
<span class="ltx_bibblock">Are You Smarter Than a Sixth Grader? Textbook Question Answering for
Multimodal Machine Comprehension.

</span>
<span class="ltx_bibblock">In <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">CVPR</em>, 5376–5384.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Le and Hoi (2020)</span>
<span class="ltx_bibblock">
Le, H.; and Hoi, S. C. H. 2020.

</span>
<span class="ltx_bibblock">Video-Grounded Dialogues with Pretrained Generation Language Models.

</span>
<span class="ltx_bibblock">In <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">ACL</em>, 5842–5848.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lei et al. (2018)</span>
<span class="ltx_bibblock">
Lei, J.; Yu, L.; Bansal, M.; and Berg, T. 2018.

</span>
<span class="ltx_bibblock">TVQA: Localized, Compositional Video Question Answering.

</span>
<span class="ltx_bibblock">In <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">EMNLP</em>, 1369–1379.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lei et al. (2020)</span>
<span class="ltx_bibblock">
Lei, J.; Yu, L.; Berg, T.; and Bansal, M. 2020.

</span>
<span class="ltx_bibblock">TVQA+: Spatio-Temporal Grounding for Video Question Answering.

</span>
<span class="ltx_bibblock">In <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">ACL</em>, 8211–8225.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Loshchilov and Hutter (2017)</span>
<span class="ltx_bibblock">
Loshchilov, I.; and Hutter, F. 2017.

</span>
<span class="ltx_bibblock">Decoupled weight decay regularization.

</span>
<span class="ltx_bibblock"><em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">arXiv:1711.05101</em>.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Luo et al. (2020)</span>
<span class="ltx_bibblock">
Luo, H.; Ji, L.; Shi, B.; Huang, H.; Duan, N.; Li, T.; Li, J.; Bharti, T.; and
Zhou, M. 2020.

</span>
<span class="ltx_bibblock">UniVL: A Unified Video and Language Pre-Training Model for Multimodal
Understanding and Generation.

</span>
<span class="ltx_bibblock"><em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">arXiv:2002.06353</em>.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mathew et al. (2022)</span>
<span class="ltx_bibblock">
Mathew, M.; Bagal, V.; Tito, R.; Karatzas, D.; Valveny, E.; and Jawahar, C.
2022.

</span>
<span class="ltx_bibblock">InfographicVQA.

</span>
<span class="ltx_bibblock">In <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">WACV</em>, 1697–1706.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mathew, Karatzas, and Jawahar (2021)</span>
<span class="ltx_bibblock">
Mathew, M.; Karatzas, D.; and Jawahar, C. V. 2021.

</span>
<span class="ltx_bibblock">DocVQA: A Dataset for VQA on Document Images.

</span>
<span class="ltx_bibblock">In <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">WACV</em>, 2200–2209.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Monica Haurilet and Stiefelhagen (2019)</span>
<span class="ltx_bibblock">
Monica Haurilet, Z. A.-H.; and Stiefelhagen, R. 2019.

</span>
<span class="ltx_bibblock">SPaSe - Multi-Label Page Segmentation for Presentation Slides.

</span>
<span class="ltx_bibblock">In <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">WACV</em>, 726–734.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Powalski et al. (2021)</span>
<span class="ltx_bibblock">
Powalski, R.; Borchmann, Ł.; Jurkiewicz, D.; Dwojak, T.; Pietruszka, M.; and
Pałka, G. 2021.

</span>
<span class="ltx_bibblock">Going full-tilt boogie on document understanding with
text-image-layout transformer.

</span>
<span class="ltx_bibblock">In <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">ICDAR</em>, 732–747.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford et al. (2021)</span>
<span class="ltx_bibblock">
Radford, A.; Kim, J. W.; Hallacy, C.; Ramesh, A.; Goh, G.; Agarwal, S.; Sastry,
G.; Askell, A.; Mishkin, P.; Clark, J.; et al. 2021.

</span>
<span class="ltx_bibblock">Learning transferable visual models from natural language
supervision.

</span>
<span class="ltx_bibblock">In <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">ICML</em>, 8748–8763.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Raffel et al. (2020)</span>
<span class="ltx_bibblock">
Raffel, C.; Shazeer, N.; Roberts, A.; Lee, K.; Narang, S.; Matena, M.; Zhou,
Y.; Li, W.; and Liu, P. J. 2020.

</span>
<span class="ltx_bibblock">Exploring the Limits of Transfer Learning with a Unified Text-to-Text
Transformer.

</span>
<span class="ltx_bibblock"><em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">JMLR</em>, 21(140): 1–67.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rajpurkar, Jia, and Liang (2018)</span>
<span class="ltx_bibblock">
Rajpurkar, P.; Jia, R.; and Liang, P. 2018.

</span>
<span class="ltx_bibblock">Know What You Don’t Know: Unanswerable Questions for SQuAD.

</span>
<span class="ltx_bibblock">In <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">ACL</em>, 784–789.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rajpurkar et al. (2016)</span>
<span class="ltx_bibblock">
Rajpurkar, P.; Zhang, J.; Lopyrev, K.; and Liang, P. 2016.

</span>
<span class="ltx_bibblock">SQuAD: 100,000+ Questions for Machine Comprehension of Text.

</span>
<span class="ltx_bibblock">In <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">EMNLP</em>, 2383–2392.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ren et al. (2015)</span>
<span class="ltx_bibblock">
Ren; Shaoqing; He; Kaiming; Girshicka; Ross; Sun; and Jian. 2015.

</span>
<span class="ltx_bibblock">Faster r-cnn: Towards real-time object detection with region proposal
networks.

</span>
<span class="ltx_bibblock">In <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">NIPS</em>, 91–99.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Robertson, Zaragoza et al. (2009)</span>
<span class="ltx_bibblock">
Robertson, S.; Zaragoza, H.; et al. 2009.

</span>
<span class="ltx_bibblock">The probabilistic relevance framework: BM25 and beyond.

</span>
<span class="ltx_bibblock"><em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">Foundations and Trends® in Information
Retrieval</em>, 3(4): 333–389.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ruder (2016)</span>
<span class="ltx_bibblock">
Ruder, S. 2016.

</span>
<span class="ltx_bibblock">An overview of gradient descent optimization algorithms.

</span>
<span class="ltx_bibblock"><em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">arXiv:1609.04747</em>.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sachan et al. (2021a)</span>
<span class="ltx_bibblock">
Sachan, D.; Patwary, M.; Shoeybi, M.; Kant, N.; Ping, W.; Hamilton, W. L.; and
Catanzaro, B. 2021a.

</span>
<span class="ltx_bibblock">End-to-End Training of Neural Retrievers for Open-Domain Question
Answering.

</span>
<span class="ltx_bibblock">In <em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">ACL</em>, 6648–6662.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sachan et al. (2021b)</span>
<span class="ltx_bibblock">
Sachan, D. S.; Reddy, S.; Hamilton, W. L.; Dyer, C.; and Yogatama, D.
2021b.

</span>
<span class="ltx_bibblock">End-to-End Training of Multi-Document Reader and Retriever for
Open-Domain Question Answering.

</span>
<span class="ltx_bibblock">In <em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">NeurIPS</em>, 25968–25981.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et al. (2021)</span>
<span class="ltx_bibblock">
Sun, E.; Hou, Y.; Wang, D.; Zhang, Y.; and Wang, N. X. R. 2021.

</span>
<span class="ltx_bibblock">D2S: Document-to-Slide Generation Via Query-Based Text
Summarization.

</span>
<span class="ltx_bibblock">In <em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">NAACL-HLT</em>, 1405–1418.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Talmor and Berant (2018)</span>
<span class="ltx_bibblock">
Talmor, A.; and Berant, J. 2018.

</span>
<span class="ltx_bibblock">The Web as a Knowledge-Base for Answering Complex Questions.

</span>
<span class="ltx_bibblock">In <em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">NAACL-HLT</em>, 641–651.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Talmor et al. (2021)</span>
<span class="ltx_bibblock">
Talmor, A.; Yoran, O.; Catav, A.; Lahav, D.; Wang, Y.; Asai, A.; Ilharco, G.;
Hajishirzi, H.; and Berant, J. 2021.

</span>
<span class="ltx_bibblock">MultiModalQA: complex question answering over text, tables and
images.

</span>
<span class="ltx_bibblock">In <em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">ICLR</em>.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tanaka, Nishida, and Yoshida (2021)</span>
<span class="ltx_bibblock">
Tanaka, R.; Nishida, K.; and Yoshida, S. 2021.

</span>
<span class="ltx_bibblock">VisualMRC: Machine Reading Comprehension on Document Images.

</span>
<span class="ltx_bibblock">In <em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">AAAI</em>, 13878–13888.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tapaswi et al. (2016)</span>
<span class="ltx_bibblock">
Tapaswi, M.; Zhu, Y.; Stiefelhagen, R.; Torralba, A.; Urtasun, R.; and Fidler,
S. 2016.

</span>
<span class="ltx_bibblock">Movieqa: Understanding stories in movies through question-answering.

</span>
<span class="ltx_bibblock">In <em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">CVPR</em>, 4631–4640.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tito, Karatzas, and Valveny (2021)</span>
<span class="ltx_bibblock">
Tito, R.; Karatzas, D.; and Valveny, E. 2021.

</span>
<span class="ltx_bibblock">Document Collection Visual Question Answering.

</span>
<span class="ltx_bibblock">In <em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">ICADR</em>, 778–792.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tu et al. (2020)</span>
<span class="ltx_bibblock">
Tu, M.; Huang, K.; Wang, G.; Huang, J.; He, X.; and Zhou, B. 2020.

</span>
<span class="ltx_bibblock">Select, answer and explain: Interpretable multi-hop reading
comprehension over multiple documents.

</span>
<span class="ltx_bibblock">In <em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">AAAI</em>, 9073–9080.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vaswani et al. (2017)</span>
<span class="ltx_bibblock">
Vaswani, A.; Shazeer, N.; Parmar, N.; Uszkoreit, J.; Jones, L.; Gomez, A. N.;
Kaiser, L.; and Polosukhin, I. 2017.

</span>
<span class="ltx_bibblock">Attention is All you Need.

</span>
<span class="ltx_bibblock">In <em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">NIPS</em>, 6000–6010.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et al. (2022)</span>
<span class="ltx_bibblock">
Wei, J.; Wang, X.; Schuurmans, D.; Bosma, M.; Chi, E.; Le, Q.; and Zhou, D.
2022.

</span>
<span class="ltx_bibblock">Chain of thought prompting elicits reasoning in large language
models.

</span>
<span class="ltx_bibblock"><em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">arXiv:2201.11903</em>.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al. (2020)</span>
<span class="ltx_bibblock">
Xu, Y.; Li, M.; Cui, L.; Huang, S.; Wei, F.; and Zhou, M. 2020.

</span>
<span class="ltx_bibblock">LayoutLM: Pre-training of Text and Layout for Document Image
Understanding.

</span>
<span class="ltx_bibblock">In <em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">KDD</em>, 1192–1200.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al. (2021)</span>
<span class="ltx_bibblock">
Xu, Y.; Xu, Y.; Lv, T.; Cui, L.; Wei, F.; Wang, G.; Lu, Y.; Florêncio, D.
A. F.; Zhang, C.; Che, W.; Zhang, M.; and Zhou, L. 2021.

</span>
<span class="ltx_bibblock">LayoutLMv2: Multi-modal Pre-training for Visually-rich Document
Understanding.

</span>
<span class="ltx_bibblock">In <em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">ACL/IJCNLP</em>, 2579–2591.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al. (2018)</span>
<span class="ltx_bibblock">
Yang, Z.; Qi, P.; Zhang, S.; Bengio, Y.; Cohen, W. W.; Salakhutdinov, R.; and
Manning, C. D. 2018.

</span>
<span class="ltx_bibblock">HotpotQA: A Dataset for Diverse, Explainable Multi-hop Question
Answering.

</span>
<span class="ltx_bibblock">In <em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">EMNLP</em>, 2369–2380.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yoran, Talmor, and Berant (2022)</span>
<span class="ltx_bibblock">
Yoran, O.; Talmor, A.; and Berant, J. 2022.

</span>
<span class="ltx_bibblock">Turning Tables: Generating Examples from Semi-structured Tables for
Endowing Language Models with Reasoning Skills.

</span>
<span class="ltx_bibblock">In <em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">ACL</em>, 6016–6031.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2021)</span>
<span class="ltx_bibblock">
Zhang, Q.; Wang, L.; Yu, S.; Wang, S.; Wang, Y.; Jiang, J.; and Lim, E.-P.
2021.

</span>
<span class="ltx_bibblock">NOAHQA: Numerical Reasoning with Interpretable Graph Question
Answering Dataset.

</span>
<span class="ltx_bibblock">In <em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">Findings of EMNLP</em>, 4147–4161.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2020)</span>
<span class="ltx_bibblock">
Zhang, X.; Ramachandran, D.; Tenney, I.; Elazar, Y.; and Roth, D. 2020.

</span>
<span class="ltx_bibblock">Do Language Embeddings capture Scales?

</span>
<span class="ltx_bibblock">In <em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">BlackboxNLP Workshop</em>.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2301.04882" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2301.04883" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2301.04883">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2301.04883" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2301.04884" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Fri Mar  1 07:29:03 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
