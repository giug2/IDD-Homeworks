<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2402.12271] Secure Federated Learning Across Heterogeneous Cloud and High-Performance Computing Resources - A Case Study on Federated Fine-tuning of LLaMA 2</title><meta property="og:description" content="Federated learning enables multiple data owners to collaboratively train robust machine learning models without transferring large or sensitive local datasets by only sharing the parameters of the locally trained model…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Secure Federated Learning Across Heterogeneous Cloud and High-Performance Computing Resources - A Case Study on Federated Fine-tuning of LLaMA 2">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Secure Federated Learning Across Heterogeneous Cloud and High-Performance Computing Resources - A Case Study on Federated Fine-tuning of LLaMA 2">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2402.12271">

<!--Generated on Tue Mar  5 16:46:20 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<div id="p1" class="ltx_para">
<span id="p1.1" class="ltx_ERROR undefined">\jvol</span>
<p id="p1.2" class="ltx_p">XX
<span id="p1.2.1" class="ltx_ERROR undefined">\jnum</span>XX
<span id="p1.2.2" class="ltx_ERROR undefined">\paper</span>8
<span id="p1.2.3" class="ltx_ERROR undefined">\jmonth</span>Month

<span id="p1.2.4" class="ltx_ERROR undefined">\jtitle</span>Computing in Science &amp; Engineering


</p>
</div>
<div id="p2" class="ltx_para">
<span id="p2.1" class="ltx_ERROR undefined">\sptitle</span>
<p id="p2.2" class="ltx_p">THEME ARTICLE: CONVERGED COMPUTING: A BEST-OF-BOTH WORLDS OF HPC AND CLOUD</p>
</div>
<h1 class="ltx_title ltx_title_document">Secure Federated Learning Across Heterogeneous Cloud and High-Performance Computing Resources - A Case Study on Federated Fine-tuning of LLaMA 2</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Zilinghan Li
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">University of Illinois at Urbana-Champaign, Urbana, IL, 61820, USA
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Shilan He
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">University of Illinois at Urbana-Champaign, Urbana, IL, 61820, USA
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Pranshu Chaturvedi
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Argonne National Laboratory, Lemont, IL, 60439, USA
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Volodymyr Kindratenko
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">University of Illinois at Urbana-Champaign, Urbana, IL, 61820, USA
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Eliu A Huerta
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Argonne National Laboratory, Lemont, IL, 60439, USA
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Kibaek Kim
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Argonne National Laboratory, Lemont, IL, 60439, USA
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Ravi Madduri
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Argonne National Laboratory, Lemont, IL, 60439, USA
</span></span></span>
</div>
<div class="ltx_dates">(2024)</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">Federated learning enables multiple data owners to collaboratively train robust machine learning models without transferring large or sensitive local datasets by only sharing the parameters of the locally trained models. In this paper, we elaborate on the design of our Advanced Privacy-Preserving Federated Learning (APPFL) framework, which streamlines end-to-end secure and reliable federated learning experiments across cloud computing facilities and high-performance computing resources by leveraging Globus Compute, a distributed function as a service platform, and Amazon Web Services. We further demonstrate the use case of APPFL in fine-tuning a LLaMA 2 7B model using several cloud resources and supercomputers.</p>
</div>
<span id="id1" class="ltx_note ltx_note_frontmatter ltx_role_journal"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">journal: </span>Computing in Science &amp; Engineering</span></span></span>
<div id="p3" class="ltx_para">
<span id="p3.4" class="ltx_ERROR undefined">\chapteri</span>
<p id="p3.3" class="ltx_p">Federated learning (FL) is a distributed machine learning paradigm where multiple data owners, referred to as clients, jointly train a machine learning model.<sup id="p3.3.1" class="ltx_sup"><span id="p3.3.1.1" class="ltx_text ltx_font_italic">1-2</span></sup> The process is orchestrated by a central server that only requires the transfer of locally trained model parameters and not the entire datasets. The server aggregates these model parameters and redistributes the updated parameters to the clients for further local training iterations. As FL does not require collecting and storing distributed client datasets together as a centralized dataset, it is becoming an increasingly promising approach to train a more robust machine learning model and alleviate the domain shift problem without compromising the privacy of local training datasets.<sup id="p3.3.2" class="ltx_sup">3</sup> FL is broadly categorized into two types, cross-device FL and cross-silo FL.<sup id="p3.3.3" class="ltx_sup">2</sup> Cross-device FL involves a large number of unreliable devices, such as IoT or mobile devices, with only a small subset participating in each FL training round. On the other hand, cross-silo FL only has a few reliable clients, typically institutions or organizations equipped with powerful computing resources, including high-performance computing (HPC) systems or cloud computing facilities. This paper specifically focuses on the cross-silo FL settings.</p>
</div>
<div id="p4" class="ltx_para">
<p id="p4.2" class="ltx_p">The deployment and launch of cross-silo FL experiments face several key challenges, including the establishment of trust relationships among FL clients, inherent heterogeneity of client computing resources, and tedious coordination of the collaboration efforts. First, trust is paramount in FL to avoid data or model attacks, where a client might maliciously train the model using invalid data or send corrupted model parameters to the server. Second, the computing resources of clients in a federation can vary widely in architecture, operating systems, computing power, and job scheduling systems. Third, as cross-silo FL requires the participation of all clients in each training round, indicating the need for the simultaneous start of client training jobs to avoid resource wastage, it becomes more complex to coordinate the collaboration among multiple clients. To overcome these challenges, we introduce the Advanced Privacy-Preserving Federated Learning (APPFL) framework which enables easy and streamlined setup of secure end-to-end cross-silo FL experiments. APPFL employs <span id="p4.2.1" class="ltx_text ltx_font_italic">Globus Compute</span> as its primary communication backbone for the distributed training process. <span id="p4.2.2" class="ltx_text ltx_font_italic">Globus Compute</span> is a distributed function-as-a-service platform that supports a wide array of target computing systems and converts each FL client’s computing machine into an endpoint,<sup id="p4.2.3" class="ltx_sup">4</sup> primed for local training executions. This simplifies the process of coordinating the collaborators to initiate the FL training. Moreover, <span id="p4.2.4" class="ltx_text ltx_font_italic">Globus Compute</span> is integrated with the Globus authentication service,<sup id="p4.2.5" class="ltx_sup">5</sup> linking each FL client with an institutional or organizational Identity and Access Management services for identification. This facilitates building trust relationships among the clients. The APPFL framework is aimed at enabling a wide array of domain experts to easily engage in creating secure federations and running FL experiments for various scientific applications.</p>
</div>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">APPFL FRAMEWORK</h2>

<figure id="Sx1.F1" class="ltx_figure">
<p id="Sx1.F1.1" class="ltx_p ltx_align_center"><span id="Sx1.F1.1.1" class="ltx_text"><img src="/html/2402.12271/assets/x1.png" id="Sx1.F1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="236" height="76" alt="Refer to caption"></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Overview of the federated learning process using the APPFL framework.</figcaption>
</figure>
<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">Figure 1 illustrates the process of federated learning using the APPFL framework. In this process, the FL server plays a pivotal role, orchestrating the training by iteratively dispatching training tasks to all FL clients and subsequently gathering results via the <span id="Sx1.p1.1.1" class="ltx_text ltx_font_italic">Globus Compute</span> cloud server. The large model parameters are reliably exchanged via the Amazon Simple Storage Service (S3). The combination of <span id="Sx1.p1.1.2" class="ltx_text ltx_font_italic">Globus Compute</span> and Amazon S3 ensures a secure, robust, and smooth flow of tasks, information, and models between the server and clients. Computing machines, ranging from personal laptops to HPC clusters with varied job schedulers, as well as cloud virtual machines, are all capable of participating as FL clients. These heterogeneous resources act as <span id="Sx1.p1.1.3" class="ltx_text ltx_font_italic">Globus Compute</span> endpoints to execute the dispatched training tasks using the private local datasets. Each client computing resource installs the APPFL software package, containing auxiliary codes for local training tasks. This setup highlights the versatility and adaptability of the framework to various computing environments, making it suitable for a wide range of FL applications.</p>
</div>
<div id="Sx1.p2" class="ltx_para">
<p id="Sx1.p2.1" class="ltx_p">Launching an FL experiment among various data owners using the APPFL framework involves a structured and secure process. The first step requires one participant to establish a Globus group, inviting other collaborating data owners through their institutional or organizational emails. This step is crucial for ensuring reliable identity and access management between the desired collaborators and FL clients, laying the foundation for an end-to-end trusted relationship. The created Globus group further provides an additional layer of authorization for FL experiments. For the actual conducting of the FL experiment, any collaborator can volunteer to take on the role of the server. This involves gathering essential information from each client, such as the <span id="Sx1.p2.1.1" class="ltx_text ltx_font_italic">Globus Compute</span> endpoint ID and a dataloader file. The dataloader file is particularly important as it is used for loading each client’s local datasets during the remote task execution and performing the required pre-processing. Once these elements are collected, the server utilizes the training script from the APPFL framework software package to initiate the training process by providing the information collected from clients, alongside the specified model architecture and training hyperparameters. As long as all client <span id="Sx1.p2.1.2" class="ltx_text ltx_font_italic">Globus Compute</span> endpoints are started before the experiment initiation, <span id="Sx1.p2.1.3" class="ltx_text ltx_font_italic">Globus Compute</span> will automatically allocate required computing resources to execute the local training tasks, thus minimizing the complexity for coordinating the distributed training. All data owners gain access to the final model parameters at the end of the FL experiment to ensure that every participant benefits from the collaborative effort. Optionally, the experiment can be connected to the resources on Amazon Web Services that can be used to store training logs and results from various experiments along with training visualizations.</p>
</div>
<figure id="Sx1.F2" class="ltx_figure">
<p id="Sx1.F2.1" class="ltx_p ltx_align_center"><span id="Sx1.F2.1.1" class="ltx_text"><img src="/html/2402.12271/assets/x2.png" id="Sx1.F2.1.1.g1" class="ltx_graphics ltx_img_portrait" width="415" height="531" alt="Refer to caption"></span></p>
<br class="ltx_break ltx_break">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Modular design of the APPFL framework.</figcaption>
</figure>
<div id="Sx1.p3" class="ltx_para">
<p id="Sx1.p3.3" class="ltx_p">Figure 2 presents the modular design of the APPFL framework. The APPFL server consists of four parts, federated learning algorithms, machine learning model architectures for training, training loss functions and metrics, and training configurations. The APPFL server supports a range of FL algorithms, including widely-used synchronous algorithms like <span id="Sx1.p3.3.1" class="ltx_text ltx_font_typewriter">FedAvg</span>,<sup id="Sx1.p3.3.2" class="ltx_sup">1</sup> advanced asynchronous algorithms such as <span id="Sx1.p3.3.3" class="ltx_text ltx_font_typewriter">FedCompass</span>,<sup id="Sx1.p3.3.4" class="ltx_sup">6</sup> and privacy-preserving algorithms such as <span id="Sx1.p3.3.5" class="ltx_text ltx_font_typewriter">IIADMM</span>.<sup id="Sx1.p3.3.6" class="ltx_sup">7</sup> This versatility allows the APPFL framework to adapt to various FL scenarios and requirements. The framework incorporates several standard machine learning model architectures, including convolutional neural networks (CNN), residual neural networks (ResNet), long short-term memory networks (LSTM), and transformers. It also provides the flexibility for users to utilize custom model architectures for specific tasks. Similarly, for training loss functions and evaluation metrics, the APPFL server also offers both popular default options and the ability to use custom choices to accommodate a wide range of training scenarios. The training configuration component is for setting up necessary hyperparameters for the central aggregation and local training. On the client side, the APPFL client includes auxiliary trainers that facilitate model training on private local datasets using the provided dataloader. Multiple trainers are provided to support a variety of training tasks, from common training procedures to more specialized approaches such as parameter-efficient fine-tuning (PEFT) and personalized federated learning. The APPFL communicator lies in between the FL server and FL clients, ensuring secure and seamless communication using <span id="Sx1.p3.3.7" class="ltx_text ltx_font_italic">Globus Compute</span> and AWS S3 buckets.</p>
</div>
</section>
<section id="Sx2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">EXPERIMENTS</h2>

<div id="Sx2.p1" class="ltx_para">
<p id="Sx2.p1.5" class="ltx_p">To demonstrate the effectiveness of the APPFL framework in streamlining FL experiments, we present a case study focusing on the application of APPFL in federated fine-tuning the LLaMA 2 7B,<sup id="Sx2.p1.5.1" class="ltx_sup">8</sup> a popular open-source pre-trained large language model (LLM), on the SuperGLUE natural language understanding benchmark.<sup id="Sx2.p1.5.2" class="ltx_sup">9</sup> Figure 3 illustrates the overview of the experiment. Each FL client operates on an individual computing machine and accesses its local datasets. Each SuperGLUE dataset is partitioned into four client chunks in a non-independent and identically distributed manner following the <span id="Sx2.p1.5.3" class="ltx_text ltx_font_italic">dual-Dirichlet partition</span> strategy introduced in <span id="Sx2.p1.5.4" class="ltx_text ltx_font_typewriter">FedCompass</span>.<sup id="Sx2.p1.5.5" class="ltx_sup">6</sup> The strategy employs two Dirichlet distributions to simulate the distribution of sample classes within one client (with a concentration parameter <math id="Sx2.p1.4.m4.1" class="ltx_Math" alttext="\alpha_{1}=2" display="inline"><semantics id="Sx2.p1.4.m4.1a"><mrow id="Sx2.p1.4.m4.1.1" xref="Sx2.p1.4.m4.1.1.cmml"><msub id="Sx2.p1.4.m4.1.1.2" xref="Sx2.p1.4.m4.1.1.2.cmml"><mi id="Sx2.p1.4.m4.1.1.2.2" xref="Sx2.p1.4.m4.1.1.2.2.cmml">α</mi><mn id="Sx2.p1.4.m4.1.1.2.3" xref="Sx2.p1.4.m4.1.1.2.3.cmml">1</mn></msub><mo id="Sx2.p1.4.m4.1.1.1" xref="Sx2.p1.4.m4.1.1.1.cmml">=</mo><mn id="Sx2.p1.4.m4.1.1.3" xref="Sx2.p1.4.m4.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="Sx2.p1.4.m4.1b"><apply id="Sx2.p1.4.m4.1.1.cmml" xref="Sx2.p1.4.m4.1.1"><eq id="Sx2.p1.4.m4.1.1.1.cmml" xref="Sx2.p1.4.m4.1.1.1"></eq><apply id="Sx2.p1.4.m4.1.1.2.cmml" xref="Sx2.p1.4.m4.1.1.2"><csymbol cd="ambiguous" id="Sx2.p1.4.m4.1.1.2.1.cmml" xref="Sx2.p1.4.m4.1.1.2">subscript</csymbol><ci id="Sx2.p1.4.m4.1.1.2.2.cmml" xref="Sx2.p1.4.m4.1.1.2.2">𝛼</ci><cn type="integer" id="Sx2.p1.4.m4.1.1.2.3.cmml" xref="Sx2.p1.4.m4.1.1.2.3">1</cn></apply><cn type="integer" id="Sx2.p1.4.m4.1.1.3.cmml" xref="Sx2.p1.4.m4.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx2.p1.4.m4.1c">\alpha_{1}=2</annotation></semantics></math>) and the distribution of sample sizes across clients (with a concentration parameter <math id="Sx2.p1.5.m5.1" class="ltx_Math" alttext="\alpha_{2}=8" display="inline"><semantics id="Sx2.p1.5.m5.1a"><mrow id="Sx2.p1.5.m5.1.1" xref="Sx2.p1.5.m5.1.1.cmml"><msub id="Sx2.p1.5.m5.1.1.2" xref="Sx2.p1.5.m5.1.1.2.cmml"><mi id="Sx2.p1.5.m5.1.1.2.2" xref="Sx2.p1.5.m5.1.1.2.2.cmml">α</mi><mn id="Sx2.p1.5.m5.1.1.2.3" xref="Sx2.p1.5.m5.1.1.2.3.cmml">2</mn></msub><mo id="Sx2.p1.5.m5.1.1.1" xref="Sx2.p1.5.m5.1.1.1.cmml">=</mo><mn id="Sx2.p1.5.m5.1.1.3" xref="Sx2.p1.5.m5.1.1.3.cmml">8</mn></mrow><annotation-xml encoding="MathML-Content" id="Sx2.p1.5.m5.1b"><apply id="Sx2.p1.5.m5.1.1.cmml" xref="Sx2.p1.5.m5.1.1"><eq id="Sx2.p1.5.m5.1.1.1.cmml" xref="Sx2.p1.5.m5.1.1.1"></eq><apply id="Sx2.p1.5.m5.1.1.2.cmml" xref="Sx2.p1.5.m5.1.1.2"><csymbol cd="ambiguous" id="Sx2.p1.5.m5.1.1.2.1.cmml" xref="Sx2.p1.5.m5.1.1.2">subscript</csymbol><ci id="Sx2.p1.5.m5.1.1.2.2.cmml" xref="Sx2.p1.5.m5.1.1.2.2">𝛼</ci><cn type="integer" id="Sx2.p1.5.m5.1.1.2.3.cmml" xref="Sx2.p1.5.m5.1.1.2.3">2</cn></apply><cn type="integer" id="Sx2.p1.5.m5.1.1.3.cmml" xref="Sx2.p1.5.m5.1.1.3">8</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx2.p1.5.m5.1c">\alpha_{2}=8</annotation></semantics></math>), respectively. Figure 4 illustrates how local data is distributed among the four clients for various datasets within the SuperGLUE benchmark.</p>
</div>
<div id="Sx2.p2" class="ltx_para">
<p id="Sx2.p2.1" class="ltx_p">To circumvent the transfer of extensive parameters of LLM, a parameter-efficient fine-tuning (PEFT) method, low-rank adaptation (LoRA),<sup id="Sx2.p2.1.1" class="ltx_sup"><span id="Sx2.p2.1.1.1" class="ltx_text ltx_font_italic">10</span></sup> is employed. LoRA freezes all parameters of the pre-trained LLM and only trains an additional set of rank decomposition matrices injected into each transformer layer, which substantially reduces the number of trainable parameters. Specifically, for LLaMA 2 7B, with decomposition matrices applied to all query and value matrices, a rank of 8, and a scaling factor of 32, LoRA results in a total of 16.0 MB trainable parameters being exchanged between the FL server and clients.</p>
</div>
<figure id="Sx2.F3" class="ltx_figure">
<p id="Sx2.F3.1" class="ltx_p ltx_align_center"><span id="Sx2.F3.1.1" class="ltx_text"><img src="/html/2402.12271/assets/x3.png" id="Sx2.F3.1.1.g1" class="ltx_graphics ltx_img_landscape" width="461" height="277" alt="Refer to caption"></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Overview of the federated large language model fine-tuning experiments among four heterogeneous clients on HPC nodes and cloud.</figcaption>
</figure>
<figure id="Sx2.F4" class="ltx_figure"><img src="/html/2402.12271/assets/x4.png" id="Sx2.F4.g1" class="ltx_graphics ltx_img_landscape" width="461" height="48" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Local data distributions among four clients for the SuperGLUE datasets, where different colors indicate samples with different labels.</figcaption>
</figure>
<figure id="Sx2.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Detailed Stanford Alpaca prompt instructions and inputs for the SuperGLUE datasets.</figcaption>
<table id="Sx2.T1.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="Sx2.T1.1.1.1" class="ltx_tr">
<th id="Sx2.T1.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t">Dataset</th>
<th id="Sx2.T1.1.1.1.2" class="ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_r ltx_border_t">
<span id="Sx2.T1.1.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx2.T1.1.1.1.2.1.1" class="ltx_p">Instruction</span>
</span>
</th>
<th id="Sx2.T1.1.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t">
<span id="Sx2.T1.1.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="Sx2.T1.1.1.1.3.1.1" class="ltx_p" style="width:113.8pt;">Input</span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="Sx2.T1.1.2.1" class="ltx_tr">
<th id="Sx2.T1.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="Sx2.T1.1.2.1.1.1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">BoolQ</span></th>
<td id="Sx2.T1.1.2.1.2" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t">
<span id="Sx2.T1.1.2.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx2.T1.1.2.1.2.1.1" class="ltx_p"><span id="Sx2.T1.1.2.1.2.1.1.1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">The following reading comprehension question requires you to understand the following passage and answer a question related to the passage. Please answer with only "True" or "False" to the question: {sample[’question’]}?</span></span>
</span>
</td>
<td id="Sx2.T1.1.2.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="Sx2.T1.1.2.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="Sx2.T1.1.2.1.3.1.1" class="ltx_p" style="width:113.8pt;"><span id="Sx2.T1.1.2.1.3.1.1.1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">sample[’passage’]</span></span>
</span>
</td>
</tr>
<tr id="Sx2.T1.1.3.2" class="ltx_tr">
<th id="Sx2.T1.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="Sx2.T1.1.3.2.1.1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">CB</span></th>
<td id="Sx2.T1.1.3.2.2" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t">
<span id="Sx2.T1.1.3.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx2.T1.1.3.2.2.1.1" class="ltx_p"><span id="Sx2.T1.1.3.2.2.1.1.1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">Please determine whether the hypothesis "{sample[’hypothesis’]}" entails, contradicts, or is unrelated to the following premise: "{sample[’premise’]}". Please respond with either "Entailment", "Contradiction", or "Neutral".</span></span>
</span>
</td>
<td id="Sx2.T1.1.3.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="Sx2.T1.1.3.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="Sx2.T1.1.3.2.3.1.1" class="ltx_p" style="width:113.8pt;"><span id="Sx2.T1.1.3.2.3.1.1.1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">N/A</span></span>
</span>
</td>
</tr>
<tr id="Sx2.T1.1.4.3" class="ltx_tr">
<th id="Sx2.T1.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="Sx2.T1.1.4.3.1.1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">COPA</span></th>
<td id="Sx2.T1.1.4.3.2" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t">
<span id="Sx2.T1.1.4.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx2.T1.1.4.3.2.1.1" class="ltx_p"><span id="Sx2.T1.1.4.3.2.1.1.1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">Given the following premise, please determine whether Choice One, {sample[’choice1’]}, or Choice Two, {sample[’choice2’]}, is the {sample[’question’]} of the premise. Please respond with either "One" or "Two".</span></span>
</span>
</td>
<td id="Sx2.T1.1.4.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="Sx2.T1.1.4.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="Sx2.T1.1.4.3.3.1.1" class="ltx_p" style="width:113.8pt;"><span id="Sx2.T1.1.4.3.3.1.1.1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">sample[’premise’]</span></span>
</span>
</td>
</tr>
<tr id="Sx2.T1.1.5.4" class="ltx_tr">
<th id="Sx2.T1.1.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="Sx2.T1.1.5.4.1.1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">MultiRC</span></th>
<td id="Sx2.T1.1.5.4.2" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t">
<span id="Sx2.T1.1.5.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx2.T1.1.5.4.2.1.1" class="ltx_p"><span id="Sx2.T1.1.5.4.2.1.1.1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">Given the following paragraph, please determine whether "{sample[’answer’]}" is a correct answer to the question "{sample[’question’]}". Please respond with either "Yes" or "No".</span></span>
</span>
</td>
<td id="Sx2.T1.1.5.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="Sx2.T1.1.5.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="Sx2.T1.1.5.4.3.1.1" class="ltx_p" style="width:113.8pt;"><span id="Sx2.T1.1.5.4.3.1.1.1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">sample[’paragraph’]</span></span>
</span>
</td>
</tr>
<tr id="Sx2.T1.1.6.5" class="ltx_tr">
<th id="Sx2.T1.1.6.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="Sx2.T1.1.6.5.1.1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">RTE</span></th>
<td id="Sx2.T1.1.6.5.2" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t">
<span id="Sx2.T1.1.6.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx2.T1.1.6.5.2.1.1" class="ltx_p"><span id="Sx2.T1.1.6.5.2.1.1.1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">Please determine whether the sentence "{sample[’premise’]}" entails the hypothesis "{sample[’hypothesis’]}" or not. Please respond with either "Yes" or "No".</span></span>
</span>
</td>
<td id="Sx2.T1.1.6.5.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="Sx2.T1.1.6.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="Sx2.T1.1.6.5.3.1.1" class="ltx_p" style="width:113.8pt;"><span id="Sx2.T1.1.6.5.3.1.1.1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">N/A</span></span>
</span>
</td>
</tr>
<tr id="Sx2.T1.1.7.6" class="ltx_tr">
<th id="Sx2.T1.1.7.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="Sx2.T1.1.7.6.1.1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">WiC</span></th>
<td id="Sx2.T1.1.7.6.2" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t">
<span id="Sx2.T1.1.7.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx2.T1.1.7.6.2.1.1" class="ltx_p"><span id="Sx2.T1.1.7.6.2.1.1.1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">Please determine whether the word "{sample[’word’]}" is used in the same way in the following two sentences: "{sample[’sentence1’]}" and "{sample[’sentence2’]}" Please respond with either "Yes" or "No".</span></span>
</span>
</td>
<td id="Sx2.T1.1.7.6.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="Sx2.T1.1.7.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="Sx2.T1.1.7.6.3.1.1" class="ltx_p" style="width:113.8pt;"><span id="Sx2.T1.1.7.6.3.1.1.1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">N/A</span></span>
</span>
</td>
</tr>
<tr id="Sx2.T1.1.8.7" class="ltx_tr">
<th id="Sx2.T1.1.8.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t"><span id="Sx2.T1.1.8.7.1.1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">WSC</span></th>
<td id="Sx2.T1.1.8.7.2" class="ltx_td ltx_align_justify ltx_border_b ltx_border_r ltx_border_t">
<span id="Sx2.T1.1.8.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx2.T1.1.8.7.2.1.1" class="ltx_p"><span id="Sx2.T1.1.8.7.2.1.1.1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">Please carefully read the following passages. For each passage, you must identify whether the pronoun marked in *bold* refers to the "quoted" noun.</span></span>
</span>
</td>
<td id="Sx2.T1.1.8.7.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t">
<span id="Sx2.T1.1.8.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="Sx2.T1.1.8.7.3.1.1" class="ltx_p" style="width:113.8pt;"><span id="Sx2.T1.1.8.7.3.1.1.1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">sample[’text’]. \n Question: In the passage above, does the pronoun sample[’span2_text’] refer to sample[’span1_text’]</span></span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
<figure id="Sx2.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Number of training batches per local round and maximum token lengths for different datasets in the SuperGLUE benchmark.</figcaption>
<table id="Sx2.T2.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="Sx2.T2.1.1.1" class="ltx_tr">
<th id="Sx2.T2.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t">Dataset</th>
<th id="Sx2.T2.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Batch number</th>
<th id="Sx2.T2.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Max token length</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="Sx2.T2.1.2.1" class="ltx_tr">
<th id="Sx2.T2.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><span id="Sx2.T2.1.2.1.1.1" class="ltx_text ltx_font_typewriter">BoolQ</span></th>
<td id="Sx2.T2.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t">200</td>
<td id="Sx2.T2.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t">350</td>
</tr>
<tr id="Sx2.T2.1.3.2" class="ltx_tr">
<th id="Sx2.T2.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="Sx2.T2.1.3.2.1.1" class="ltx_text ltx_font_typewriter">CB</span></th>
<td id="Sx2.T2.1.3.2.2" class="ltx_td ltx_align_center">All</td>
<td id="Sx2.T2.1.3.2.3" class="ltx_td ltx_align_center">350</td>
</tr>
<tr id="Sx2.T2.1.4.3" class="ltx_tr">
<th id="Sx2.T2.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="Sx2.T2.1.4.3.1.1" class="ltx_text ltx_font_typewriter">COPA</span></th>
<td id="Sx2.T2.1.4.3.2" class="ltx_td ltx_align_center">All</td>
<td id="Sx2.T2.1.4.3.3" class="ltx_td ltx_align_center">300</td>
</tr>
<tr id="Sx2.T2.1.5.4" class="ltx_tr">
<th id="Sx2.T2.1.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="Sx2.T2.1.5.4.1.1" class="ltx_text ltx_font_typewriter">MultiRC</span></th>
<td id="Sx2.T2.1.5.4.2" class="ltx_td ltx_align_center">200</td>
<td id="Sx2.T2.1.5.4.3" class="ltx_td ltx_align_center">600</td>
</tr>
<tr id="Sx2.T2.1.6.5" class="ltx_tr">
<th id="Sx2.T2.1.6.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="Sx2.T2.1.6.5.1.1" class="ltx_text ltx_font_typewriter">RTE</span></th>
<td id="Sx2.T2.1.6.5.2" class="ltx_td ltx_align_center">200</td>
<td id="Sx2.T2.1.6.5.3" class="ltx_td ltx_align_center">200</td>
</tr>
<tr id="Sx2.T2.1.7.6" class="ltx_tr">
<th id="Sx2.T2.1.7.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="Sx2.T2.1.7.6.1.1" class="ltx_text ltx_font_typewriter">WiC</span></th>
<td id="Sx2.T2.1.7.6.2" class="ltx_td ltx_align_center">200</td>
<td id="Sx2.T2.1.7.6.3" class="ltx_td ltx_align_center">200</td>
</tr>
<tr id="Sx2.T2.1.8.7" class="ltx_tr">
<th id="Sx2.T2.1.8.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b"><span id="Sx2.T2.1.8.7.1.1" class="ltx_text ltx_font_typewriter">WSC</span></th>
<td id="Sx2.T2.1.8.7.2" class="ltx_td ltx_align_center ltx_border_b">All</td>
<td id="Sx2.T2.1.8.7.3" class="ltx_td ltx_align_center ltx_border_b">220</td>
</tr>
</tbody>
</table>
</figure>
<figure id="Sx2.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Performance of the fine-tuned LLaMA 2 7B using federated learning (FL), global training, and local training.</figcaption>
<table id="Sx2.T3.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="Sx2.T3.1.1.1" class="ltx_tr">
<th id="Sx2.T3.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t">Dataset</th>
<th id="Sx2.T3.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_t"># Val. Samples</th>
<th id="Sx2.T3.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">
<span id="Sx2.T3.1.1.1.3.1" class="ltx_text ltx_font_typewriter">FL</span> (%)</th>
<th id="Sx2.T3.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">
<span id="Sx2.T3.1.1.1.4.1" class="ltx_text ltx_font_typewriter">Global</span> (%)</th>
<th id="Sx2.T3.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">
<span id="Sx2.T3.1.1.1.5.1" class="ltx_text ltx_font_typewriter">Local</span> Avg (%)</th>
<th id="Sx2.T3.1.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">
<span id="Sx2.T3.1.1.1.6.1" class="ltx_text ltx_font_typewriter">Local</span> (%)</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="Sx2.T3.1.2.1" class="ltx_tr">
<th id="Sx2.T3.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><span id="Sx2.T3.1.2.1.1.1" class="ltx_text ltx_font_typewriter">BoolQ</span></th>
<th id="Sx2.T3.1.2.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">3270</th>
<td id="Sx2.T3.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t">80.34</td>
<td id="Sx2.T3.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t">81.01</td>
<td id="Sx2.T3.1.2.1.5" class="ltx_td ltx_align_center ltx_border_t">72.73</td>
<td id="Sx2.T3.1.2.1.6" class="ltx_td ltx_align_center ltx_border_t">[69.72, 69.45, 77.80, 73.94]</td>
</tr>
<tr id="Sx2.T3.1.3.2" class="ltx_tr">
<th id="Sx2.T3.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="Sx2.T3.1.3.2.1.1" class="ltx_text ltx_font_typewriter">CB</span></th>
<th id="Sx2.T3.1.3.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">56</th>
<td id="Sx2.T3.1.3.2.3" class="ltx_td ltx_align_center">78.57</td>
<td id="Sx2.T3.1.3.2.4" class="ltx_td ltx_align_center">82.14</td>
<td id="Sx2.T3.1.3.2.5" class="ltx_td ltx_align_center">62.95</td>
<td id="Sx2.T3.1.3.2.6" class="ltx_td ltx_align_center">[46.43, 76.79, 67.86, 60.71]</td>
</tr>
<tr id="Sx2.T3.1.4.3" class="ltx_tr">
<th id="Sx2.T3.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="Sx2.T3.1.4.3.1.1" class="ltx_text ltx_font_typewriter">BOPA</span></th>
<th id="Sx2.T3.1.4.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">100</th>
<td id="Sx2.T3.1.4.3.3" class="ltx_td ltx_align_center">83.00</td>
<td id="Sx2.T3.1.4.3.4" class="ltx_td ltx_align_center">89.00</td>
<td id="Sx2.T3.1.4.3.5" class="ltx_td ltx_align_center">74.00</td>
<td id="Sx2.T3.1.4.3.6" class="ltx_td ltx_align_center">[76.00, 68.00, 70.00, 82.00]</td>
</tr>
<tr id="Sx2.T3.1.5.4" class="ltx_tr">
<th id="Sx2.T3.1.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="Sx2.T3.1.5.4.1.1" class="ltx_text ltx_font_typewriter">MultiRC</span></th>
<th id="Sx2.T3.1.5.4.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">4850</th>
<td id="Sx2.T3.1.5.4.3" class="ltx_td ltx_align_center">68.38</td>
<td id="Sx2.T3.1.5.4.4" class="ltx_td ltx_align_center">71.62</td>
<td id="Sx2.T3.1.5.4.5" class="ltx_td ltx_align_center">65.22</td>
<td id="Sx2.T3.1.5.4.6" class="ltx_td ltx_align_center">[70.54, 63.72, 61.80, 64.81]</td>
</tr>
<tr id="Sx2.T3.1.6.5" class="ltx_tr">
<th id="Sx2.T3.1.6.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="Sx2.T3.1.6.5.1.1" class="ltx_text ltx_font_typewriter">RTE</span></th>
<th id="Sx2.T3.1.6.5.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">227</th>
<td id="Sx2.T3.1.6.5.3" class="ltx_td ltx_align_center">87.36</td>
<td id="Sx2.T3.1.6.5.4" class="ltx_td ltx_align_center">85.28</td>
<td id="Sx2.T3.1.6.5.5" class="ltx_td ltx_align_center">84.66</td>
<td id="Sx2.T3.1.6.5.6" class="ltx_td ltx_align_center">[86.28, 85.20, 84.48, 82.67]</td>
</tr>
<tr id="Sx2.T3.1.7.6" class="ltx_tr">
<th id="Sx2.T3.1.7.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="Sx2.T3.1.7.6.1.1" class="ltx_text ltx_font_typewriter">WiC</span></th>
<th id="Sx2.T3.1.7.6.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">638</th>
<td id="Sx2.T3.1.7.6.3" class="ltx_td ltx_align_center">64.11</td>
<td id="Sx2.T3.1.7.6.4" class="ltx_td ltx_align_center">66.14</td>
<td id="Sx2.T3.1.7.6.5" class="ltx_td ltx_align_center">53.76</td>
<td id="Sx2.T3.1.7.6.6" class="ltx_td ltx_align_center">[59.87, 50.00, 55.64, 49.53]</td>
</tr>
<tr id="Sx2.T3.1.8.7" class="ltx_tr">
<th id="Sx2.T3.1.8.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b"><span id="Sx2.T3.1.8.7.1.1" class="ltx_text ltx_font_typewriter">WSC</span></th>
<th id="Sx2.T3.1.8.7.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b">104</th>
<td id="Sx2.T3.1.8.7.3" class="ltx_td ltx_align_center ltx_border_b">72.12</td>
<td id="Sx2.T3.1.8.7.4" class="ltx_td ltx_align_center ltx_border_b">75.96</td>
<td id="Sx2.T3.1.8.7.5" class="ltx_td ltx_align_center ltx_border_b">64.36</td>
<td id="Sx2.T3.1.8.7.6" class="ltx_td ltx_align_center ltx_border_b">[64.42, 68.27, 57.69, 63.46]</td>
</tr>
</tbody>
</table>
</figure>
<div id="Sx2.p3" class="ltx_para">
<p id="Sx2.p3.4" class="ltx_p">For all datasets in the SuperGLUE benchmark, each sample is transformed into the Stanford Alpaca prompt format.<sup id="Sx2.p3.4.1" class="ltx_sup"><span id="Sx2.p3.4.1.1" class="ltx_text ltx_font_italic">11</span></sup> Table 1 shows the detailed prompt instructions and inputs for each SuperGLUE dataset. The APPFL PEFT local trainer minimizes the cross-entropy loss for the labeled prompt outputs using the AdamW optimizer with a learning rate of <math id="Sx2.p3.2.m2.1" class="ltx_Math" alttext="10^{-4}" display="inline"><semantics id="Sx2.p3.2.m2.1a"><msup id="Sx2.p3.2.m2.1.1" xref="Sx2.p3.2.m2.1.1.cmml"><mn id="Sx2.p3.2.m2.1.1.2" xref="Sx2.p3.2.m2.1.1.2.cmml">10</mn><mrow id="Sx2.p3.2.m2.1.1.3" xref="Sx2.p3.2.m2.1.1.3.cmml"><mo id="Sx2.p3.2.m2.1.1.3a" xref="Sx2.p3.2.m2.1.1.3.cmml">−</mo><mn id="Sx2.p3.2.m2.1.1.3.2" xref="Sx2.p3.2.m2.1.1.3.2.cmml">4</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="Sx2.p3.2.m2.1b"><apply id="Sx2.p3.2.m2.1.1.cmml" xref="Sx2.p3.2.m2.1.1"><csymbol cd="ambiguous" id="Sx2.p3.2.m2.1.1.1.cmml" xref="Sx2.p3.2.m2.1.1">superscript</csymbol><cn type="integer" id="Sx2.p3.2.m2.1.1.2.cmml" xref="Sx2.p3.2.m2.1.1.2">10</cn><apply id="Sx2.p3.2.m2.1.1.3.cmml" xref="Sx2.p3.2.m2.1.1.3"><minus id="Sx2.p3.2.m2.1.1.3.1.cmml" xref="Sx2.p3.2.m2.1.1.3"></minus><cn type="integer" id="Sx2.p3.2.m2.1.1.3.2.cmml" xref="Sx2.p3.2.m2.1.1.3.2">4</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx2.p3.2.m2.1c">10^{-4}</annotation></semantics></math> and a decay factor of <math id="Sx2.p3.3.m3.1" class="ltx_Math" alttext="0.85" display="inline"><semantics id="Sx2.p3.3.m3.1a"><mn id="Sx2.p3.3.m3.1.1" xref="Sx2.p3.3.m3.1.1.cmml">0.85</mn><annotation-xml encoding="MathML-Content" id="Sx2.p3.3.m3.1b"><cn type="float" id="Sx2.p3.3.m3.1.1.cmml" xref="Sx2.p3.3.m3.1.1">0.85</cn></annotation-xml><annotation encoding="application/x-tex" id="Sx2.p3.3.m3.1c">0.85</annotation></semantics></math>.<sup id="Sx2.p3.4.2" class="ltx_sup"><span id="Sx2.p3.4.2.1" class="ltx_text ltx_font_italic">12</span></sup> <span id="Sx2.p3.4.3" class="ltx_text ltx_font_typewriter">FedAvg</span> is used as the FL algorithm. The number of global communication rounds is set to 5 and the training batch size is set to 4 for all datasets. Given the varying characteristics of the datasets in the SuperGLUE benchmark, we have tailored the number of training batches of each training round and the maximum token length for each dataset in the training configurations, as detailed in Table 2. Notably, the term “All” for the batch number indicates that each client utilizes the entirety of available local training samples in every local training round.</p>
</div>
<div id="Sx2.p4" class="ltx_para">
<p id="Sx2.p4.1" class="ltx_p">To reflect real-world variability in computing resources, the four clients are operating on four heterogeneous computing machines. Specifically, two of these clients are deployed on HPC setups within the Delta supercomputer at the National Center for Supercomputing Applications (NCSA), using the Slurm job scheduler. These two differ in their GPU capabilities: one uses an NVIDIA A40 GPU, while the other employs an NVIDIA A100 Tensor Core GPU. The remaining two clients leverage Amazon Web Services (AWS) Elastic Compute Cloud (EC2) virtual machines with different specifications: one runs on a <span id="Sx2.p4.1.1" class="ltx_text ltx_font_typewriter">g4ad.xlarge</span> instance and the other on a <span id="Sx2.p4.1.2" class="ltx_text ltx_font_typewriter">g4ad.4xlarge</span> instance. This diverse computational setup provides a realistic testbed for the APPFL framework, demonstrating its applicability and adaptability in heterogeneous computing environments.</p>
</div>
<div id="Sx2.p5" class="ltx_para">
<p id="Sx2.p5.1" class="ltx_p">Table 3 presents a comparative analysis of the performance achieved by the LLaMA 2 7B model when fine-tuned under different settings: federated learning (<span id="Sx2.p5.1.1" class="ltx_text ltx_font_typewriter">FL</span>), global training using centralized data (<span id="Sx2.p5.1.2" class="ltx_text ltx_font_typewriter">Global</span>), and local training with client local corpus (<span id="Sx2.p5.1.3" class="ltx_text ltx_font_typewriter">Local</span>). Since the labels for the SuperGLUE test datasets are not publicly available, the evaluation is based on the validation datasets from this benchmark. The results highlighted in the table reveal a notable pattern: models fine-tuned through FL outperform those fine-tuned locally on individual client data. This finding underscores the effectiveness of FL in enhancing model robustness. By leveraging the diverse local training corpora of various clients, FL manages to train more comprehensive models without the need for explicit data sharing. However, there remains a slight performance discrepancy when compared to models trained with centralized data, which likely arises from the inherent data heterogeneity across different clients. Additionally, the experiment showcases the versatility and capability of the APPFL framework in facilitating FL experiments across a wide range of computing environments, from HPC nodes to cloud computing facilities. This adaptability makes the APPFL framework a valuable tool for conducting FL experiments in real-world settings, where computing resources and desired training tasks can vary greatly.</p>
</div>
</section>
<section id="Sx3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">CONCLUSION</h2>

<div id="Sx3.p1" class="ltx_para">
<p id="Sx3.p1.1" class="ltx_p">In this paper, we introduce the design of the APPFL framework, a sophisticated software package to streamline the initiation and execution of secure and reliable end-to-end federated learning experiments across a diverse range of applications. This framework is adept at handling heterogeneous computing environments, from HPC systems to cloud-based resources. We showcase the framework’s capabilities through a comprehensive case study, illustrating how APPFL can be seamlessly applied to the federated fine-tuning of large language models using parameter-efficient fine-tuning methods. Looking to the future, there is potential for further enhancement via improving the quality and accessibility of FL-as-a-Service provided by APPFL. Our ultimate goal is to empower a broader range of domain experts from large institutions, universities, and national laboratories, to effortlessly conduct FL experiments in various AI applications, thus expanding the horizons of collaborative, privacy-preserving AI research and development.</p>
</div>
</section>
<section id="Sx4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">ACKNOWLEDGMENTS</h2>

<div id="Sx4.p1" class="ltx_para">
<p id="Sx4.p1.1" class="ltx_p">This material is based upon work supported by the U.S. Department of Energy, Office of Science, under contract number DE-AC02-06CH11357. This research is also part of the Delta research computing project, which is supported by the National Science Foundation (award OCI 2005572), and the State of Illinois. Delta is a joint effort of the University of Illinois at Urbana-Champaign and the National Center for Supercomputing Applications.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">REFERENCES</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
B. McMahan, E. Moore, D. Ramage, S. Hampson, B. A. y Arcas, “Communication-efficient learning of deep networks from decentralized data,” in <span id="bib.bib1.1.1" class="ltx_text ltx_font_italic">Artificial Intelligence and Statistics</span>, PMLR, 2017, pp. 1273–1282.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
P. Kairouz, <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">et al</em>., “Advances and open problems in federated learning,” <span id="bib.bib2.2.2" class="ltx_text ltx_font_italic">Foundations and Trends in Machine Learning</span>, vol. 14, no. 1-2, pp. 1–210, 2021, doi:10.1561/2200000083

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
T.-H. Hoang, <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">et al</em>., “Enabling end-to-end secure federated learning in biomedical research on heterogeneous computing environments with APPFLx,” <span id="bib.bib3.2.2" class="ltx_text ltx_font_italic">arXiv preprint</span>, 2023, doi:10.48550/arXiv.2312.08701.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
R. Chard, <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">et al</em>., “FuncX: A federated function serving fabric for science,” in <span id="bib.bib4.2.2" class="ltx_text ltx_font_italic">Proceedings of the 29th International Symposium on High-Performance Parallel and Distributed Computing</span>, 2020, pp. 65–76, doi:10.1145/3369583.3392683.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
S. Tuecke, <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">et al</em>., “Globus auth: A research identity and access management platform,” in <span id="bib.bib5.2.2" class="ltx_text ltx_font_italic">2016 IEEE 12th International Conference on e-Science (e-Science)</span>, IEEE, 2016, pp. 203–212, doi:10.1109/eScience.2016.7870901.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Z. Li, <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">et al</em>., “FedCompass: efficient cross-silo federated learning on heterogeneous client devices using a computing power aware scheduler,” <span id="bib.bib6.2.2" class="ltx_text ltx_font_italic">arXiv preprint</span>, 2023, doi:10.48550/arXiv.2309.14675.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
M. Ryu, Y. Kim, K. Kim, and R. K. Madduri, “APPFL: Open-source software framework for privacy-preserving federated learning,” in <span id="bib.bib7.1.1" class="ltx_text ltx_font_italic">2022 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)</span>, IEEE, 2022, pp. 1074–1083, doi:10.1109/IPDPSW55747.2022.00175.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
H. Touvron, <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">et al</em>., “Llama 2: Open foundation and fine-tuned chat models,” <span id="bib.bib8.2.2" class="ltx_text ltx_font_italic">arXiv preprint</span>, 2023,
doi:10.48550/arXiv.2307.09288.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
A. Wang, <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">et al</em>., “Superglue: A stickier benchmark for general-purpose language understanding systems,” in <span id="bib.bib9.2.2" class="ltx_text ltx_font_italic">Advances in Neural Information Processing Systems</span>, vol. 32, 2019.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
E. J. Hu, <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">et al</em>., “LoRA: Low-rank adaptation of large language models,” in <span id="bib.bib10.2.2" class="ltx_text ltx_font_italic">International Conference on Learning Representations</span>, 2022.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
R. Taori, <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">et al</em>., “Stanford Alpaca: An Instruction-following LLaMA model,” 2023. [Online]. Available: https://github.com/tatsu-lab/stanford_alpaca

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
I. Loshchilov and F. Hutter, “Decoupled Weight Decay Regularization,” in <span id="bib.bib12.1.1" class="ltx_text ltx_font_italic">International Conference on Learning Representations</span>, 2019.

</span>
</li>
</ul>
</section>
<div id="p5" class="ltx_para">
<span id="p5.1" class="ltx_ERROR undefined">{IEEEbiography}</span>
<p id="p5.2" class="ltx_p">Zilinghan Li  is a Master of Science student in Computer Science at the University of Illinois at Urbana-Champaign and a research assistant at Argonne National Laboratory. His research interests include federated learning, distributed computing, and natural language processing. He received dual Bachelor’s degrees from the University of Illinois at Urbana-Champaign and Zhejiang University. Contact him at zl52@illinois.edu.</p>
</div>
<div id="p6" class="ltx_para">
<span id="p6.1" class="ltx_ERROR undefined">{IEEEbiography}</span>
<p id="p6.2" class="ltx_p">Shilan He  is a Master of Science student in Electrical and Computer Engineering at the University of Illinois at Urbana-Champaign. Her research interests include reinforcement learning, federated learning, and communication networks. She received dual Bachelor’s degrees from the University of Illinois at Urbana-Champaign and Zhejiang University. Contact her at shilanh2@illinois.edu.</p>
</div>
<div id="p7" class="ltx_para">
<span id="p7.1" class="ltx_ERROR undefined">{IEEEbiography}</span>
<p id="p7.2" class="ltx_p">Pranshu Chaturvedi  is a research engineer in the Data Science and Learning Division at Argonne National Laboratory. He is interested in trustworthy AI, federated learning, and privacy preserving machine learning. He obtained his Bachelor’s degree in Computer Science and Statistics from the University of Illinois at Urbana-Champaign. Contact him at pranshu.01.c@gmail.com.</p>
</div>
<div id="p8" class="ltx_para">
<span id="p8.1" class="ltx_ERROR undefined">{IEEEbiography}</span>
<p id="p8.2" class="ltx_p">Volodymyr Kindratenko   is an Assistant Director at the National Center for Supercomputing Applications (NCSA) at the University of Illinois at Urbana-Champaign where he serves as the Director for the Center for Artificial Intelligence Innovation (CAII). He holds an Adjunct Associate Professor appointment in the Departments of Electrical and Computer Engineering (ECE) and a Research Associate Professor appointment in the Department of Computer Science (CS). Dr. Kindratenko received a D.Sc. degree from the University of Antwerp, Belgium. His research interests include high-performance computing, special-purpose computing architectures, and machine learning systems and applications. He is an IEEE senior member. Contact him at kindrtnk@illinois.edu.</p>
</div>
<div id="p9" class="ltx_para">
<span id="p9.1" class="ltx_ERROR undefined">{IEEEbiography}</span>
<p id="p9.2" class="ltx_p">Eliu A Huerta   is the Lead for Translational AI and Computational Scientist in the Data Science and Learning Division at Argonne National Laboratory, and CASE Senior Scientist at the Department of Computer Science at the University of Chicago. He received a Master of Advanced Study in Applied Mathematics and Theoretical Physics and a Ph.D. in Theoretical Astrophysics from the University of Cambridge, United Kingdom. His research interests are at the interface of artificial intelligence, theoretical astrophysics, extreme scale computing, scientific visualization and mathematics. Contact him at elihu@anl.gov.</p>
</div>
<div id="p10" class="ltx_para">
<span id="p10.1" class="ltx_ERROR undefined">{IEEEbiography}</span>
<p id="p10.2" class="ltx_p">Kibaek Kim   is a Computational Mathematician in the Mathematics and Computer Science Division at Argonne National Laboratory, and a Senior Scientist at-Large at the University of Chicago Consortium for Advanced Science and Engineering. His research focuses primarily on computational optimization, including stochastic programming and integer programming, with applications to complex systems. Dr. Kim obtained a Ph.D. degree in Industrial Engineering and Management Sciences from Northwestern University. He is an IEEE senior member. Contact him at kimk@anl.gov.</p>
</div>
<div id="p11" class="ltx_para">
<span id="p11.1" class="ltx_ERROR undefined">{IEEEbiography}</span>
<p id="p11.2" class="ltx_p">Ravi Madduri   is a Computer Scientist in the Data Science and Learning Division at Argonne National Laboratory, and a Senior Scientist at-Large at the University of Chicago Consortium for Advanced Science and Engineering. His research interests are in AI for science, large-scale computation, and biomedical informatics. He received a Master’s degree in Computer Science from Illinois Institute of Technology. Contact him at madduri@anl.gov.</p>
</div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2402.12270" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2402.12271" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2402.12271">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2402.12271" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2402.12273" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Tue Mar  5 16:46:20 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
