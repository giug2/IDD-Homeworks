<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2310.19250] Abstract</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Abstract">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Abstract">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2310.19250">

<!--Generated on Tue Feb 27 21:40:18 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<div id="id1" class="ltx_logical-block">
<div id="id1.p1" class="ltx_para">
<br class="ltx_break ltx_align_left">
<p id="id1.p1.1" class="ltx_p ltx_align_left"><span id="id1.p1.1.1" class="ltx_text" style="font-size:144%;">Assessment of Differentially Private Synthetic Data for Utility and Fairness in End-to-End Machine Learning Pipelines for Tabular Data </span>

<br class="ltx_break"></p>
<p id="id1.p1.2" class="ltx_p ltx_align_left">Mayana Pereira<sup id="id1.p1.2.1" class="ltx_sup">1,2,*</sup>,
Meghana Kshirsagar<sup id="id1.p1.2.2" class="ltx_sup">1</sup>,
Sumit Mukherjee<sup id="id1.p1.2.3" class="ltx_sup">3</sup>,
Rahul Dodhia<sup id="id1.p1.2.4" class="ltx_sup">1</sup>,
Juan Lavista Ferres<sup id="id1.p1.2.5" class="ltx_sup">1</sup>,
Rafael de Sousa<sup id="id1.p1.2.6" class="ltx_sup">2</sup></p>
<br class="ltx_break ltx_align_left">
<p id="id1.p1.3" class="ltx_p ltx_align_left"><span id="id1.p1.3.1" class="ltx_text ltx_font_bold">1</span> AI for Good Research Lab, Microsoft, Redmond, Washington, U.S.A.</p>
<p id="id1.p1.4" class="ltx_p ltx_align_left"><span id="id1.p1.4.1" class="ltx_text ltx_font_bold">2</span> Department of Electrical Engineering, University of Brasilia, Brasilia, Brazil</p>
<p id="id1.p1.5" class="ltx_p ltx_align_left"><span id="id1.p1.5.1" class="ltx_text ltx_font_bold">3</span> INSITRO, San Francisco, CA, U.S.A.</p>
<br class="ltx_break ltx_align_left">
<p id="id1.p1.6" class="ltx_p ltx_align_left">* mayana.wanderley@microsoft.com</p>
</div>
</div>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Abstract</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">Differentially private (DP) synthetic data sets are a solution for sharing data while preserving the privacy of individual data providers. Understanding the effects of utilizing DP synthetic data in end-to-end machine learning pipelines impacts areas such as health care and humanitarian action, where data is scarce and regulated by restrictive privacy laws. In this work, we investigate the extent to which synthetic data can replace real, tabular data in machine learning pipelines and identify the most effective synthetic data generation techniques for training and evaluating machine learning models. We systematically investigate the impacts of differentially private synthetic data on downstream classification tasks from the point of view of utility as well as fairness. Our analysis is comprehensive and includes representatives of the two main types of synthetic data generation algorithms: marginal-based and GAN-based.</p>
</div>
<div id="Sx1.p2" class="ltx_para">
<p id="Sx1.p2.1" class="ltx_p">To the best of our knowledge, our work is the first that: (i) proposes a training and evaluation framework that does not assume that real data is available for testing the utility and fairness of machine learning models trained on synthetic data; (ii) presents the most extensive analysis of synthetic data set generation algorithms in terms of utility and fairness when used for training machine learning models; and (iii) encompasses several different definitions of fairness.</p>
</div>
<div id="Sx1.p3" class="ltx_para">
<p id="Sx1.p3.1" class="ltx_p">Our findings demonstrate that marginal-based synthetic data generators surpass GAN-based ones regarding model training utility for tabular data. Indeed, we show that models trained using data generated by marginal-based algorithms can exhibit similar utility to models trained using real data. Our analysis also reveals that the marginal-based synthetic data generator MWEM PGM can train models that simultaneously achieve utility and fairness characteristics close to those obtained by models trained with real data.</p>
</div>
</section>
<section id="Sx2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Introduction</h2>

<div id="Sx2.p1" class="ltx_para">
<p id="Sx2.p1.1" class="ltx_p">Differential privacy (DP) is the standard for privacy-preserving statistical summaries <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. Companies such as Microsoft <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>, Google <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>, Apple <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>, and government organizations such as the US Census <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>, have successfully applied DP in machine learning and data sharing scenarios. The popularity of DP is due to its strong mathematical guarantees. Differential Privacy guarantees privacy by ensuring that the inclusion or exclusion of any particular individual does not significantly change the output distribution of an algorithm.</p>
</div>
<div id="Sx2.p2" class="ltx_para">
<p id="Sx2.p2.1" class="ltx_p">In areas ranging from health care, humanitarian action, education, and socioeconomic studies, the publication and sharing of data is crucial for informing society and scientific collaboration. However, the disclosure of such data sets can often reveal private, sensitive information. Privacy-preserving data publishing aims at enabling such collaborations while preserving the privacy of individual entries in the data set. Tabular/categorical data about individuals are relevant in many applications, from health care to humanitarian action. Privacy-preserving data publishing for such data can be done in the form of a synthetic data table that has the same schema and similar distributional properties as the real data. The aim here is to release a perturbed version of the original information, so that it can still be used for statistical analysis, but the privacy of individuals in the database is preserved.</p>
</div>
<div id="Sx2.p3" class="ltx_para">
<p id="Sx2.p3.1" class="ltx_p">The biggest advantage of synthetic data sets is that, once released, all data analysis and machine learning tasks are performed in the same way it is done with real data. As noted by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>, the switch between real and synthetic data in data analysis and machine learning pipelines is seamless - the same analysis tools, libraries and algorithms are applied in the same manner in both data sets. Other privacy-preserving technologies, such as federated learning, requires expertise and appropriate tools to perform data analysis and model training.</p>
</div>
<div id="Sx2.p4" class="ltx_para">
<p id="Sx2.p4.1" class="ltx_p">Due to the all the potential benefits of synthetic data, understanding the impacts of synthetic data in downstream classification tasks have become of extreme importance. A trend observed in recent studies is to evaluate performance of synthetic data generators of two types: marginal-based synthesizers <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> and generative adversarial networks (GAN) based synthesizers <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>. Marginal-based synthetic data generators are suitable for tabular data only, and have gained increased popularity after the algorithm MST won the NIST competition in 2018 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>. Marginal-based synthesizers are named as such due to the fact that they learn approximate data distributions by querying noisy marginals from the real data. Notable marginal-based algorithms are MWEM PGM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> and PrivBayes <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>. GAN-based synthesizers, on the other hand, are flexible algorithms, and are suitable for tabular, image and other data formats. GANs learn patterns and relationships from the input data based on a game, in the sense of game theory, between two machine learning models, a discriminator model and the generator model. Among popular differentially private GAN architectures we list DP-GAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>, DP-CTGAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> , PATE-GAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> and PATE-CTGAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>.</p>
</div>
<div id="Sx2.p5" class="ltx_para">
<p id="Sx2.p5.1" class="ltx_p">One of the major applications of synthetic data is for training machine learning models. Therefore, it is paramount to understand how exchanging real data for synthetic data impacts the performance of the trained machine learning models. By performance, we mean not only the utility of the model (its accuracy, for example) but also how well the model performs for different subgroups of the data set - the fairness of the model. The impact of machine learning models on minorities subgroups is an active area of research, and several works have investigated the trade-offs among model accuracy, bias, and privacy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>. However, only recently bias caused by the use of synthetic data in downstream classification received attention <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>.
This problem becomes particularly relevant in the context of synthetic data sets generated with differential privacy guarantees. It is known that differential privacy can affect fairness in machine learning models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>. Despite recent work investigating the impact of synthetic data in downstream model fairness <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>, there are important questions that remain unanswered.</p>
</div>
<div id="Sx2.p6" class="ltx_para">
<ul id="Sx2.I1" class="ltx_itemize">
<li id="Sx2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="Sx2.I1.i1.p1" class="ltx_para">
<p id="Sx2.I1.i1.p1.1" class="ltx_p">There is no published work that systematically studies the utility and fairness of machine learning models trained on several GAN based and marginal-based synthetic tabular data set generation algorithms.</p>
</div>
</li>
<li id="Sx2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="Sx2.I1.i2.p1" class="ltx_para">
<p id="Sx2.I1.i2.p1.1" class="ltx_p">Previous studies have not evaluated machine learning models trained on synthetic data set generation algorithms for multiple definitions of fairness.</p>
</div>
</li>
<li id="Sx2.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="Sx2.I1.i3.p1" class="ltx_para">
<p id="Sx2.I1.i3.p1.1" class="ltx_p">In previous studies, it was always assumed that real data was available for evaluating the fairness of models trained on synthetic data. Here, we propose and evaluate a pipeline where no such assumption is necessary.</p>
</div>
</li>
</ul>
</div>
<div id="Sx2.p7" class="ltx_para">
<p id="Sx2.p7.1" class="ltx_p"><span id="Sx2.p7.1.1" class="ltx_text ltx_font_bold">Contributions</span> In this work, we investigate the impacts of differentially private synthetic data on downstream classification, where we focus on understanding the impacts on model utility and fairness. Our investigation focus on two aspects of such impact:</p>
</div>
<div id="Sx2.p8" class="ltx_para">
<ul id="Sx2.I2" class="ltx_itemize">
<li id="Sx2.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="Sx2.I2.i1.p1" class="ltx_para">
<p id="Sx2.I2.i1.p1.1" class="ltx_p">What is the impact in model utility when utilizing synthetic data for training machine learning models? Can synthetic data also be used to evaluate utility of machine learning models?</p>
</div>
</li>
<li id="Sx2.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="Sx2.I2.i2.p1" class="ltx_para">
<p id="Sx2.I2.i2.p1.1" class="ltx_p">What is the impact in model fairness when utilizing synthetic data for training machine learning models? Can synthetic data be used to evaluate fairness of machine learning models?</p>
</div>
</li>
</ul>
</div>
<div id="Sx2.p9" class="ltx_para">
<p id="Sx2.p9.1" class="ltx_p">In our investigations we also evaluate if there are clear differences in performance between marginal-based and GAN-based synthetic data, and if there is a synthesizer algorithm that produces data that clearly outperform others.</p>
</div>
<figure id="Sx2.F1" class="ltx_figure"><img src="/html/2310.19250/assets/Fig_intro.png" id="Sx2.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="510" height="249" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Fig 1: </span>Pipeline for model training and evaluation using synthetic data (1) We generate Synthetic data sets for model training and model testing utilizing differentially private synthesizers. (2) We train models utilizing synthetic data and evaluate on a synthetic test data. Model selection is made during this phase. (3) Based on the previous phase results, model is trained using synthetic data and deployed. Model is applied to real (test) data in production phase.</figcaption>
</figure>
<div id="Sx2.p10" class="ltx_para">
<p id="Sx2.p10.1" class="ltx_p">Our research work evaluates the impact of utilizing synthetic data sets for both training and testing in machine learning pipelines. We empirically compare the performance of marginal-based synthesizers and GAN-based synthesizers within the context of a machine learning pipeline. Our experiments yield a comprehensive analysis, encompassing utility and fairness metrics.
Our main contributions are:</p>
</div>
<div id="Sx2.p11" class="ltx_para">
<ul id="Sx2.I3" class="ltx_itemize">
<li id="Sx2.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="Sx2.I3.i1.p1" class="ltx_para">
<p id="Sx2.I3.i1.p1.1" class="ltx_p">We propose a training and evaluation framework that does not assume that real data is available for testing the utility and fairness of machine learning models trained on synthetic data.</p>
</div>
</li>
<li id="Sx2.I3.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="Sx2.I3.i2.p1" class="ltx_para">
<p id="Sx2.I3.i2.p1.1" class="ltx_p">We present an extensive analysis of synthetic data set generation algorithms in terms of utility and fairness when used for training machine learning models. In particular, this is the first systematic comparison of several marginal-based and GAN-based algorithms for fairness and utility of the resulting machine learning models.</p>
</div>
</li>
<li id="Sx2.I3.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="Sx2.I3.i3.p1" class="ltx_para">
<p id="Sx2.I3.i3.p1.1" class="ltx_p">This is the first of such studies that includes several different definitions of fairness.</p>
</div>
</li>
</ul>
</div>
<div id="Sx2.p12" class="ltx_para">
<p id="Sx2.p12.1" class="ltx_p"><span id="Sx2.p12.1.1" class="ltx_text ltx_font_bold">Main Findings:</span></p>
</div>
<div id="Sx2.p13" class="ltx_para">
<ul id="Sx2.I4" class="ltx_itemize">
<li id="Sx2.I4.ix1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1</span> 
<div id="Sx2.I4.ix1.p1" class="ltx_para">
<p id="Sx2.I4.ix1.p1.1" class="ltx_p"><span id="Sx2.I4.ix1.p1.1.1" class="ltx_text ltx_font_bold">Marginal-based synthetic data can accurately train machine learning models for tabular data.</span> Marginal-based synthetic data can train models with similar utility to models trained on real data. Our experiments show that for a privacy-loss parameter <math id="Sx2.I4.ix1.p1.1.m1.1" class="ltx_Math" alttext="\epsilon&gt;5.0" display="inline"><semantics id="Sx2.I4.ix1.p1.1.m1.1a"><mrow id="Sx2.I4.ix1.p1.1.m1.1.1" xref="Sx2.I4.ix1.p1.1.m1.1.1.cmml"><mi id="Sx2.I4.ix1.p1.1.m1.1.1.2" xref="Sx2.I4.ix1.p1.1.m1.1.1.2.cmml">Ïµ</mi><mo id="Sx2.I4.ix1.p1.1.m1.1.1.1" xref="Sx2.I4.ix1.p1.1.m1.1.1.1.cmml">&gt;</mo><mn id="Sx2.I4.ix1.p1.1.m1.1.1.3" xref="Sx2.I4.ix1.p1.1.m1.1.1.3.cmml">5.0</mn></mrow><annotation-xml encoding="MathML-Content" id="Sx2.I4.ix1.p1.1.m1.1b"><apply id="Sx2.I4.ix1.p1.1.m1.1.1.cmml" xref="Sx2.I4.ix1.p1.1.m1.1.1"><gt id="Sx2.I4.ix1.p1.1.m1.1.1.1.cmml" xref="Sx2.I4.ix1.p1.1.m1.1.1.1"></gt><ci id="Sx2.I4.ix1.p1.1.m1.1.1.2.cmml" xref="Sx2.I4.ix1.p1.1.m1.1.1.2">italic-Ïµ</ci><cn type="float" id="Sx2.I4.ix1.p1.1.m1.1.1.3.cmml" xref="Sx2.I4.ix1.p1.1.m1.1.1.3">5.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx2.I4.ix1.p1.1.m1.1c">\epsilon&gt;5.0</annotation></semantics></math>, models trained with MWEM PGM (AUC = 0.684), MST (AUC = 0.662) and Privbayes (AUC = 0.668) provides utility very similar to models trained on real data (AUC = 0.684). Additionally, we evaluated models using synthetic data, and found that marginal-based synthetic provides a good evaluation, with synthetic data providing an AUC = 0.671 versus AUC = 0.684 (measured using real data).</p>
</div>
</li>
<li id="Sx2.I4.ix2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2</span> 
<div id="Sx2.I4.ix2.p1" class="ltx_para">
<p id="Sx2.I4.ix2.p1.1" class="ltx_p"><span id="Sx2.I4.ix2.p1.1.1" class="ltx_text ltx_font_bold">Synthetic data sets trained with MWEM PGM can be used for accurate model training and fairness evaluation in the case of tabular data.</span> We found that MWEM PGM synthetic data can train models that achieves very similar utility and fairness characteristics of models trained with real data. Additionally, the synthetic data generated by MWEM PGM algorithm showed very similar behavior to real data when used to evaluate utility an fairness of machine learning models. This is the first study that (first time that it is showing that synthetic data can actually present reliable behavior and a potential substitute for real data sets in end-to-end machine learning pipelines)</p>
</div>
</li>
</ul>
</div>
<div id="Sx2.p14" class="ltx_para">
<p id="Sx2.p14.1" class="ltx_p">This work significantly extends and sub sums a previous version, presented at the <em id="Sx2.p14.1.1" class="ltx_emph ltx_font_italic">Machine Learning for Data: Automated Creation, Privacy, Bias Workshop</em> at the <em id="Sx2.p14.1.2" class="ltx_emph ltx_font_italic">International Conference on Machine Learning (ICML)</em> (workshop without proceedings) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>.</p>
</div>
</section>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Related Works</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">As synthetic data generation becomes standard practice for data sharing and publishing, understanding the impacts of utilizing synthetic data in machine learning pipelines is of significant importance. Although previous works have advised against using synthetic data to train and evaluate any final tools deployed in the real world <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>, in very sensitive scenarios, such as human trafficking data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>, synthetic data might be the only available data for training and testing models.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">The promises synthetic data brings generated an interest in understanding impacts of utilizing synthetic in data analysis and machine learning. Some of these works include analysing the utility of differentially private synthetic data in different tasks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>, investigating if training models with differentially private synthetic images can increase subgroup disparities <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>, the impacts different types of synthetic data can have in model fairness <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>, utility of synthetic data in downstream health care classification systems <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>, and whether feature importance can be accurately analyzed using differentially private synthetic data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>. All these works are ultimately trying to answer a same question: to which extent can we substitute real data with synthetic data, and which are the best synthetic data generation techniques for model training?</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">However these works still left questions unanswered. First of all, there hasnâ€™t been a systematic study of impacts of using synthetic data sets in end-to-end machine learning pipelines, which means evaluating the use of synthetic data for model training and model evaluation. Additionally, there has been a lot of focus on image classification tasks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> where the disparity in accuracy are largely attributable to the class imbalance in these data sets: i.e disadvantaged classes are also rare classes in the data set thereby leading to worse performance on these. In contrast, our work studies these issues in the context of tabular data sets and in settings where the data has an intrinsic bias against sub-populations that are not necessarily rare in the data set. Moreover, our work focus on comparing two types of data synthetization algorithm families: marginal-based and GAN-based data synthesizers. While, these two type of data synthetization algorithms have been previously compared for utility <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>, no such extensive comparative analysis exists for fairness.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">We are the first to extensively study the differences of applying data generated by these two families types of data synthetization algorithms in end-to-end machine learning pipelines for utility and multiple fairness metrics.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Preliminaries</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">In this section we introduce the concepts of differential privacy and algorithmic fairness. We refer the reader to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite> for detailed explanation of these concepts. Additionally, we describe the synthetic data generation techniques and the data sets used in our experiments.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Differential privacy</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Differential privacy is a rigorous privacy notion used to protect an individualâ€™s data in a data set disclosure. We present in this section notation and definitions that we will use to describe our privatization approach. We refer the reader to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite> for detailed explanations of these definitions and theorems.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.8" class="ltx_p"><span id="S2.SS1.p2.8.1" class="ltx_text ltx_font_smallcaps">Pure Differential Privacy.</span> A randomized mechanism <math id="S2.SS1.p2.1.m1.1" class="ltx_Math" alttext="\mathcal{M}:\mathcal{D}\rightarrow\mathcal{A}" display="inline"><semantics id="S2.SS1.p2.1.m1.1a"><mrow id="S2.SS1.p2.1.m1.1.1" xref="S2.SS1.p2.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p2.1.m1.1.1.2" xref="S2.SS1.p2.1.m1.1.1.2.cmml">â„³</mi><mo lspace="0.278em" rspace="0.278em" id="S2.SS1.p2.1.m1.1.1.1" xref="S2.SS1.p2.1.m1.1.1.1.cmml">:</mo><mrow id="S2.SS1.p2.1.m1.1.1.3" xref="S2.SS1.p2.1.m1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p2.1.m1.1.1.3.2" xref="S2.SS1.p2.1.m1.1.1.3.2.cmml">ğ’Ÿ</mi><mo stretchy="false" id="S2.SS1.p2.1.m1.1.1.3.1" xref="S2.SS1.p2.1.m1.1.1.3.1.cmml">â†’</mo><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p2.1.m1.1.1.3.3" xref="S2.SS1.p2.1.m1.1.1.3.3.cmml">ğ’œ</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.1.m1.1b"><apply id="S2.SS1.p2.1.m1.1.1.cmml" xref="S2.SS1.p2.1.m1.1.1"><ci id="S2.SS1.p2.1.m1.1.1.1.cmml" xref="S2.SS1.p2.1.m1.1.1.1">:</ci><ci id="S2.SS1.p2.1.m1.1.1.2.cmml" xref="S2.SS1.p2.1.m1.1.1.2">â„³</ci><apply id="S2.SS1.p2.1.m1.1.1.3.cmml" xref="S2.SS1.p2.1.m1.1.1.3"><ci id="S2.SS1.p2.1.m1.1.1.3.1.cmml" xref="S2.SS1.p2.1.m1.1.1.3.1">â†’</ci><ci id="S2.SS1.p2.1.m1.1.1.3.2.cmml" xref="S2.SS1.p2.1.m1.1.1.3.2">ğ’Ÿ</ci><ci id="S2.SS1.p2.1.m1.1.1.3.3.cmml" xref="S2.SS1.p2.1.m1.1.1.3.3">ğ’œ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.1.m1.1c">\mathcal{M}:\mathcal{D}\rightarrow\mathcal{A}</annotation></semantics></math> with data base domain <math id="S2.SS1.p2.2.m2.1" class="ltx_Math" alttext="\mathcal{D}" display="inline"><semantics id="S2.SS1.p2.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p2.2.m2.1.1" xref="S2.SS1.p2.2.m2.1.1.cmml">ğ’Ÿ</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.2.m2.1b"><ci id="S2.SS1.p2.2.m2.1.1.cmml" xref="S2.SS1.p2.2.m2.1.1">ğ’Ÿ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.2.m2.1c">\mathcal{D}</annotation></semantics></math> and output set <math id="S2.SS1.p2.3.m3.1" class="ltx_Math" alttext="\mathcal{A}" display="inline"><semantics id="S2.SS1.p2.3.m3.1a"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p2.3.m3.1.1" xref="S2.SS1.p2.3.m3.1.1.cmml">ğ’œ</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.3.m3.1b"><ci id="S2.SS1.p2.3.m3.1.1.cmml" xref="S2.SS1.p2.3.m3.1.1">ğ’œ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.3.m3.1c">\mathcal{A}</annotation></semantics></math> is <math id="S2.SS1.p2.4.m4.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S2.SS1.p2.4.m4.1a"><mi id="S2.SS1.p2.4.m4.1.1" xref="S2.SS1.p2.4.m4.1.1.cmml">Ïµ</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.4.m4.1b"><ci id="S2.SS1.p2.4.m4.1.1.cmml" xref="S2.SS1.p2.4.m4.1.1">italic-Ïµ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.4.m4.1c">\epsilon</annotation></semantics></math>-differentially private if, for any output <math id="S2.SS1.p2.5.m5.1" class="ltx_Math" alttext="A\subseteq\mathcal{Y}" display="inline"><semantics id="S2.SS1.p2.5.m5.1a"><mrow id="S2.SS1.p2.5.m5.1.1" xref="S2.SS1.p2.5.m5.1.1.cmml"><mi id="S2.SS1.p2.5.m5.1.1.2" xref="S2.SS1.p2.5.m5.1.1.2.cmml">A</mi><mo id="S2.SS1.p2.5.m5.1.1.1" xref="S2.SS1.p2.5.m5.1.1.1.cmml">âŠ†</mo><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p2.5.m5.1.1.3" xref="S2.SS1.p2.5.m5.1.1.3.cmml">ğ’´</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.5.m5.1b"><apply id="S2.SS1.p2.5.m5.1.1.cmml" xref="S2.SS1.p2.5.m5.1.1"><subset id="S2.SS1.p2.5.m5.1.1.1.cmml" xref="S2.SS1.p2.5.m5.1.1.1"></subset><ci id="S2.SS1.p2.5.m5.1.1.2.cmml" xref="S2.SS1.p2.5.m5.1.1.2">ğ´</ci><ci id="S2.SS1.p2.5.m5.1.1.3.cmml" xref="S2.SS1.p2.5.m5.1.1.3">ğ’´</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.5.m5.1c">A\subseteq\mathcal{Y}</annotation></semantics></math> and neighboring databases <math id="S2.SS1.p2.6.m6.2" class="ltx_Math" alttext="D,D^{\prime}\in\mathcal{D}" display="inline"><semantics id="S2.SS1.p2.6.m6.2a"><mrow id="S2.SS1.p2.6.m6.2.2" xref="S2.SS1.p2.6.m6.2.2.cmml"><mrow id="S2.SS1.p2.6.m6.2.2.1.1" xref="S2.SS1.p2.6.m6.2.2.1.2.cmml"><mi id="S2.SS1.p2.6.m6.1.1" xref="S2.SS1.p2.6.m6.1.1.cmml">D</mi><mo id="S2.SS1.p2.6.m6.2.2.1.1.2" xref="S2.SS1.p2.6.m6.2.2.1.2.cmml">,</mo><msup id="S2.SS1.p2.6.m6.2.2.1.1.1" xref="S2.SS1.p2.6.m6.2.2.1.1.1.cmml"><mi id="S2.SS1.p2.6.m6.2.2.1.1.1.2" xref="S2.SS1.p2.6.m6.2.2.1.1.1.2.cmml">D</mi><mo id="S2.SS1.p2.6.m6.2.2.1.1.1.3" xref="S2.SS1.p2.6.m6.2.2.1.1.1.3.cmml">â€²</mo></msup></mrow><mo id="S2.SS1.p2.6.m6.2.2.2" xref="S2.SS1.p2.6.m6.2.2.2.cmml">âˆˆ</mo><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p2.6.m6.2.2.3" xref="S2.SS1.p2.6.m6.2.2.3.cmml">ğ’Ÿ</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.6.m6.2b"><apply id="S2.SS1.p2.6.m6.2.2.cmml" xref="S2.SS1.p2.6.m6.2.2"><in id="S2.SS1.p2.6.m6.2.2.2.cmml" xref="S2.SS1.p2.6.m6.2.2.2"></in><list id="S2.SS1.p2.6.m6.2.2.1.2.cmml" xref="S2.SS1.p2.6.m6.2.2.1.1"><ci id="S2.SS1.p2.6.m6.1.1.cmml" xref="S2.SS1.p2.6.m6.1.1">ğ·</ci><apply id="S2.SS1.p2.6.m6.2.2.1.1.1.cmml" xref="S2.SS1.p2.6.m6.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.6.m6.2.2.1.1.1.1.cmml" xref="S2.SS1.p2.6.m6.2.2.1.1.1">superscript</csymbol><ci id="S2.SS1.p2.6.m6.2.2.1.1.1.2.cmml" xref="S2.SS1.p2.6.m6.2.2.1.1.1.2">ğ·</ci><ci id="S2.SS1.p2.6.m6.2.2.1.1.1.3.cmml" xref="S2.SS1.p2.6.m6.2.2.1.1.1.3">â€²</ci></apply></list><ci id="S2.SS1.p2.6.m6.2.2.3.cmml" xref="S2.SS1.p2.6.m6.2.2.3">ğ’Ÿ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.6.m6.2c">D,D^{\prime}\in\mathcal{D}</annotation></semantics></math> (i.e., <math id="S2.SS1.p2.7.m7.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S2.SS1.p2.7.m7.1a"><mi id="S2.SS1.p2.7.m7.1.1" xref="S2.SS1.p2.7.m7.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.7.m7.1b"><ci id="S2.SS1.p2.7.m7.1.1.cmml" xref="S2.SS1.p2.7.m7.1.1">ğ·</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.7.m7.1c">D</annotation></semantics></math> and <math id="S2.SS1.p2.8.m8.1" class="ltx_Math" alttext="D^{\prime}" display="inline"><semantics id="S2.SS1.p2.8.m8.1a"><msup id="S2.SS1.p2.8.m8.1.1" xref="S2.SS1.p2.8.m8.1.1.cmml"><mi id="S2.SS1.p2.8.m8.1.1.2" xref="S2.SS1.p2.8.m8.1.1.2.cmml">D</mi><mo id="S2.SS1.p2.8.m8.1.1.3" xref="S2.SS1.p2.8.m8.1.1.3.cmml">â€²</mo></msup><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.8.m8.1b"><apply id="S2.SS1.p2.8.m8.1.1.cmml" xref="S2.SS1.p2.8.m8.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.8.m8.1.1.1.cmml" xref="S2.SS1.p2.8.m8.1.1">superscript</csymbol><ci id="S2.SS1.p2.8.m8.1.1.2.cmml" xref="S2.SS1.p2.8.m8.1.1.2">ğ·</ci><ci id="S2.SS1.p2.8.m8.1.1.3.cmml" xref="S2.SS1.p2.8.m8.1.1.3">â€²</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.8.m8.1c">D^{\prime}</annotation></semantics></math> differ in at most one entry), we have</p>
<table id="S2.Ex1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.Ex1.m1.3" class="ltx_Math" alttext="\textnormal{Pr}[\mathcal{M}(D)\in A]\leq e^{\epsilon}\textnormal{Pr}[\mathcal{M}(D^{\prime})\in A]" display="block"><semantics id="S2.Ex1.m1.3a"><mrow id="S2.Ex1.m1.3.3" xref="S2.Ex1.m1.3.3.cmml"><mrow id="S2.Ex1.m1.2.2.1" xref="S2.Ex1.m1.2.2.1.cmml"><mtext id="S2.Ex1.m1.2.2.1.3" xref="S2.Ex1.m1.2.2.1.3a.cmml">Pr</mtext><mo lspace="0em" rspace="0em" id="S2.Ex1.m1.2.2.1.2" xref="S2.Ex1.m1.2.2.1.2.cmml">â€‹</mo><mrow id="S2.Ex1.m1.2.2.1.1.1" xref="S2.Ex1.m1.2.2.1.1.2.cmml"><mo stretchy="false" id="S2.Ex1.m1.2.2.1.1.1.2" xref="S2.Ex1.m1.2.2.1.1.2.1.cmml">[</mo><mrow id="S2.Ex1.m1.2.2.1.1.1.1" xref="S2.Ex1.m1.2.2.1.1.1.1.cmml"><mrow id="S2.Ex1.m1.2.2.1.1.1.1.2" xref="S2.Ex1.m1.2.2.1.1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.Ex1.m1.2.2.1.1.1.1.2.2" xref="S2.Ex1.m1.2.2.1.1.1.1.2.2.cmml">â„³</mi><mo lspace="0em" rspace="0em" id="S2.Ex1.m1.2.2.1.1.1.1.2.1" xref="S2.Ex1.m1.2.2.1.1.1.1.2.1.cmml">â€‹</mo><mrow id="S2.Ex1.m1.2.2.1.1.1.1.2.3.2" xref="S2.Ex1.m1.2.2.1.1.1.1.2.cmml"><mo stretchy="false" id="S2.Ex1.m1.2.2.1.1.1.1.2.3.2.1" xref="S2.Ex1.m1.2.2.1.1.1.1.2.cmml">(</mo><mi id="S2.Ex1.m1.1.1" xref="S2.Ex1.m1.1.1.cmml">D</mi><mo stretchy="false" id="S2.Ex1.m1.2.2.1.1.1.1.2.3.2.2" xref="S2.Ex1.m1.2.2.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S2.Ex1.m1.2.2.1.1.1.1.1" xref="S2.Ex1.m1.2.2.1.1.1.1.1.cmml">âˆˆ</mo><mi id="S2.Ex1.m1.2.2.1.1.1.1.3" xref="S2.Ex1.m1.2.2.1.1.1.1.3.cmml">A</mi></mrow><mo stretchy="false" id="S2.Ex1.m1.2.2.1.1.1.3" xref="S2.Ex1.m1.2.2.1.1.2.1.cmml">]</mo></mrow></mrow><mo id="S2.Ex1.m1.3.3.3" xref="S2.Ex1.m1.3.3.3.cmml">â‰¤</mo><mrow id="S2.Ex1.m1.3.3.2" xref="S2.Ex1.m1.3.3.2.cmml"><msup id="S2.Ex1.m1.3.3.2.3" xref="S2.Ex1.m1.3.3.2.3.cmml"><mi id="S2.Ex1.m1.3.3.2.3.2" xref="S2.Ex1.m1.3.3.2.3.2.cmml">e</mi><mi id="S2.Ex1.m1.3.3.2.3.3" xref="S2.Ex1.m1.3.3.2.3.3.cmml">Ïµ</mi></msup><mo lspace="0em" rspace="0em" id="S2.Ex1.m1.3.3.2.2" xref="S2.Ex1.m1.3.3.2.2.cmml">â€‹</mo><mtext id="S2.Ex1.m1.3.3.2.4" xref="S2.Ex1.m1.3.3.2.4a.cmml">Pr</mtext><mo lspace="0em" rspace="0em" id="S2.Ex1.m1.3.3.2.2a" xref="S2.Ex1.m1.3.3.2.2.cmml">â€‹</mo><mrow id="S2.Ex1.m1.3.3.2.1.1" xref="S2.Ex1.m1.3.3.2.1.2.cmml"><mo stretchy="false" id="S2.Ex1.m1.3.3.2.1.1.2" xref="S2.Ex1.m1.3.3.2.1.2.1.cmml">[</mo><mrow id="S2.Ex1.m1.3.3.2.1.1.1" xref="S2.Ex1.m1.3.3.2.1.1.1.cmml"><mrow id="S2.Ex1.m1.3.3.2.1.1.1.1" xref="S2.Ex1.m1.3.3.2.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.Ex1.m1.3.3.2.1.1.1.1.3" xref="S2.Ex1.m1.3.3.2.1.1.1.1.3.cmml">â„³</mi><mo lspace="0em" rspace="0em" id="S2.Ex1.m1.3.3.2.1.1.1.1.2" xref="S2.Ex1.m1.3.3.2.1.1.1.1.2.cmml">â€‹</mo><mrow id="S2.Ex1.m1.3.3.2.1.1.1.1.1.1" xref="S2.Ex1.m1.3.3.2.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.Ex1.m1.3.3.2.1.1.1.1.1.1.2" xref="S2.Ex1.m1.3.3.2.1.1.1.1.1.1.1.cmml">(</mo><msup id="S2.Ex1.m1.3.3.2.1.1.1.1.1.1.1" xref="S2.Ex1.m1.3.3.2.1.1.1.1.1.1.1.cmml"><mi id="S2.Ex1.m1.3.3.2.1.1.1.1.1.1.1.2" xref="S2.Ex1.m1.3.3.2.1.1.1.1.1.1.1.2.cmml">D</mi><mo id="S2.Ex1.m1.3.3.2.1.1.1.1.1.1.1.3" xref="S2.Ex1.m1.3.3.2.1.1.1.1.1.1.1.3.cmml">â€²</mo></msup><mo stretchy="false" id="S2.Ex1.m1.3.3.2.1.1.1.1.1.1.3" xref="S2.Ex1.m1.3.3.2.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.Ex1.m1.3.3.2.1.1.1.2" xref="S2.Ex1.m1.3.3.2.1.1.1.2.cmml">âˆˆ</mo><mi id="S2.Ex1.m1.3.3.2.1.1.1.3" xref="S2.Ex1.m1.3.3.2.1.1.1.3.cmml">A</mi></mrow><mo stretchy="false" id="S2.Ex1.m1.3.3.2.1.1.3" xref="S2.Ex1.m1.3.3.2.1.2.1.cmml">]</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.Ex1.m1.3b"><apply id="S2.Ex1.m1.3.3.cmml" xref="S2.Ex1.m1.3.3"><leq id="S2.Ex1.m1.3.3.3.cmml" xref="S2.Ex1.m1.3.3.3"></leq><apply id="S2.Ex1.m1.2.2.1.cmml" xref="S2.Ex1.m1.2.2.1"><times id="S2.Ex1.m1.2.2.1.2.cmml" xref="S2.Ex1.m1.2.2.1.2"></times><ci id="S2.Ex1.m1.2.2.1.3a.cmml" xref="S2.Ex1.m1.2.2.1.3"><mtext id="S2.Ex1.m1.2.2.1.3.cmml" xref="S2.Ex1.m1.2.2.1.3">Pr</mtext></ci><apply id="S2.Ex1.m1.2.2.1.1.2.cmml" xref="S2.Ex1.m1.2.2.1.1.1"><csymbol cd="latexml" id="S2.Ex1.m1.2.2.1.1.2.1.cmml" xref="S2.Ex1.m1.2.2.1.1.1.2">delimited-[]</csymbol><apply id="S2.Ex1.m1.2.2.1.1.1.1.cmml" xref="S2.Ex1.m1.2.2.1.1.1.1"><in id="S2.Ex1.m1.2.2.1.1.1.1.1.cmml" xref="S2.Ex1.m1.2.2.1.1.1.1.1"></in><apply id="S2.Ex1.m1.2.2.1.1.1.1.2.cmml" xref="S2.Ex1.m1.2.2.1.1.1.1.2"><times id="S2.Ex1.m1.2.2.1.1.1.1.2.1.cmml" xref="S2.Ex1.m1.2.2.1.1.1.1.2.1"></times><ci id="S2.Ex1.m1.2.2.1.1.1.1.2.2.cmml" xref="S2.Ex1.m1.2.2.1.1.1.1.2.2">â„³</ci><ci id="S2.Ex1.m1.1.1.cmml" xref="S2.Ex1.m1.1.1">ğ·</ci></apply><ci id="S2.Ex1.m1.2.2.1.1.1.1.3.cmml" xref="S2.Ex1.m1.2.2.1.1.1.1.3">ğ´</ci></apply></apply></apply><apply id="S2.Ex1.m1.3.3.2.cmml" xref="S2.Ex1.m1.3.3.2"><times id="S2.Ex1.m1.3.3.2.2.cmml" xref="S2.Ex1.m1.3.3.2.2"></times><apply id="S2.Ex1.m1.3.3.2.3.cmml" xref="S2.Ex1.m1.3.3.2.3"><csymbol cd="ambiguous" id="S2.Ex1.m1.3.3.2.3.1.cmml" xref="S2.Ex1.m1.3.3.2.3">superscript</csymbol><ci id="S2.Ex1.m1.3.3.2.3.2.cmml" xref="S2.Ex1.m1.3.3.2.3.2">ğ‘’</ci><ci id="S2.Ex1.m1.3.3.2.3.3.cmml" xref="S2.Ex1.m1.3.3.2.3.3">italic-Ïµ</ci></apply><ci id="S2.Ex1.m1.3.3.2.4a.cmml" xref="S2.Ex1.m1.3.3.2.4"><mtext id="S2.Ex1.m1.3.3.2.4.cmml" xref="S2.Ex1.m1.3.3.2.4">Pr</mtext></ci><apply id="S2.Ex1.m1.3.3.2.1.2.cmml" xref="S2.Ex1.m1.3.3.2.1.1"><csymbol cd="latexml" id="S2.Ex1.m1.3.3.2.1.2.1.cmml" xref="S2.Ex1.m1.3.3.2.1.1.2">delimited-[]</csymbol><apply id="S2.Ex1.m1.3.3.2.1.1.1.cmml" xref="S2.Ex1.m1.3.3.2.1.1.1"><in id="S2.Ex1.m1.3.3.2.1.1.1.2.cmml" xref="S2.Ex1.m1.3.3.2.1.1.1.2"></in><apply id="S2.Ex1.m1.3.3.2.1.1.1.1.cmml" xref="S2.Ex1.m1.3.3.2.1.1.1.1"><times id="S2.Ex1.m1.3.3.2.1.1.1.1.2.cmml" xref="S2.Ex1.m1.3.3.2.1.1.1.1.2"></times><ci id="S2.Ex1.m1.3.3.2.1.1.1.1.3.cmml" xref="S2.Ex1.m1.3.3.2.1.1.1.1.3">â„³</ci><apply id="S2.Ex1.m1.3.3.2.1.1.1.1.1.1.1.cmml" xref="S2.Ex1.m1.3.3.2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.Ex1.m1.3.3.2.1.1.1.1.1.1.1.1.cmml" xref="S2.Ex1.m1.3.3.2.1.1.1.1.1.1">superscript</csymbol><ci id="S2.Ex1.m1.3.3.2.1.1.1.1.1.1.1.2.cmml" xref="S2.Ex1.m1.3.3.2.1.1.1.1.1.1.1.2">ğ·</ci><ci id="S2.Ex1.m1.3.3.2.1.1.1.1.1.1.1.3.cmml" xref="S2.Ex1.m1.3.3.2.1.1.1.1.1.1.1.3">â€²</ci></apply></apply><ci id="S2.Ex1.m1.3.3.2.1.1.1.3.cmml" xref="S2.Ex1.m1.3.3.2.1.1.1.3">ğ´</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex1.m1.3c">\textnormal{Pr}[\mathcal{M}(D)\in A]\leq e^{\epsilon}\textnormal{Pr}[\mathcal{M}(D^{\prime})\in A]</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div id="S2.SS1.p3" class="ltx_para">
<p id="S2.SS1.p3.8" class="ltx_p"><span id="S2.SS1.p3.8.1" class="ltx_text ltx_font_smallcaps">Approximate Differential Privacy.</span> A randomized mechanism <math id="S2.SS1.p3.1.m1.1" class="ltx_Math" alttext="\mathcal{M}:\mathcal{D}\rightarrow\mathcal{A}" display="inline"><semantics id="S2.SS1.p3.1.m1.1a"><mrow id="S2.SS1.p3.1.m1.1.1" xref="S2.SS1.p3.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p3.1.m1.1.1.2" xref="S2.SS1.p3.1.m1.1.1.2.cmml">â„³</mi><mo lspace="0.278em" rspace="0.278em" id="S2.SS1.p3.1.m1.1.1.1" xref="S2.SS1.p3.1.m1.1.1.1.cmml">:</mo><mrow id="S2.SS1.p3.1.m1.1.1.3" xref="S2.SS1.p3.1.m1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p3.1.m1.1.1.3.2" xref="S2.SS1.p3.1.m1.1.1.3.2.cmml">ğ’Ÿ</mi><mo stretchy="false" id="S2.SS1.p3.1.m1.1.1.3.1" xref="S2.SS1.p3.1.m1.1.1.3.1.cmml">â†’</mo><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p3.1.m1.1.1.3.3" xref="S2.SS1.p3.1.m1.1.1.3.3.cmml">ğ’œ</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.1.m1.1b"><apply id="S2.SS1.p3.1.m1.1.1.cmml" xref="S2.SS1.p3.1.m1.1.1"><ci id="S2.SS1.p3.1.m1.1.1.1.cmml" xref="S2.SS1.p3.1.m1.1.1.1">:</ci><ci id="S2.SS1.p3.1.m1.1.1.2.cmml" xref="S2.SS1.p3.1.m1.1.1.2">â„³</ci><apply id="S2.SS1.p3.1.m1.1.1.3.cmml" xref="S2.SS1.p3.1.m1.1.1.3"><ci id="S2.SS1.p3.1.m1.1.1.3.1.cmml" xref="S2.SS1.p3.1.m1.1.1.3.1">â†’</ci><ci id="S2.SS1.p3.1.m1.1.1.3.2.cmml" xref="S2.SS1.p3.1.m1.1.1.3.2">ğ’Ÿ</ci><ci id="S2.SS1.p3.1.m1.1.1.3.3.cmml" xref="S2.SS1.p3.1.m1.1.1.3.3">ğ’œ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.1.m1.1c">\mathcal{M}:\mathcal{D}\rightarrow\mathcal{A}</annotation></semantics></math> with data base domain <math id="S2.SS1.p3.2.m2.1" class="ltx_Math" alttext="\mathcal{D}" display="inline"><semantics id="S2.SS1.p3.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p3.2.m2.1.1" xref="S2.SS1.p3.2.m2.1.1.cmml">ğ’Ÿ</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.2.m2.1b"><ci id="S2.SS1.p3.2.m2.1.1.cmml" xref="S2.SS1.p3.2.m2.1.1">ğ’Ÿ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.2.m2.1c">\mathcal{D}</annotation></semantics></math> and output set <math id="S2.SS1.p3.3.m3.1" class="ltx_Math" alttext="\mathcal{A}" display="inline"><semantics id="S2.SS1.p3.3.m3.1a"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p3.3.m3.1.1" xref="S2.SS1.p3.3.m3.1.1.cmml">ğ’œ</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.3.m3.1b"><ci id="S2.SS1.p3.3.m3.1.1.cmml" xref="S2.SS1.p3.3.m3.1.1">ğ’œ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.3.m3.1c">\mathcal{A}</annotation></semantics></math> is <math id="S2.SS1.p3.4.m4.2" class="ltx_Math" alttext="(\epsilon,\delta)" display="inline"><semantics id="S2.SS1.p3.4.m4.2a"><mrow id="S2.SS1.p3.4.m4.2.3.2" xref="S2.SS1.p3.4.m4.2.3.1.cmml"><mo stretchy="false" id="S2.SS1.p3.4.m4.2.3.2.1" xref="S2.SS1.p3.4.m4.2.3.1.cmml">(</mo><mi id="S2.SS1.p3.4.m4.1.1" xref="S2.SS1.p3.4.m4.1.1.cmml">Ïµ</mi><mo id="S2.SS1.p3.4.m4.2.3.2.2" xref="S2.SS1.p3.4.m4.2.3.1.cmml">,</mo><mi id="S2.SS1.p3.4.m4.2.2" xref="S2.SS1.p3.4.m4.2.2.cmml">Î´</mi><mo stretchy="false" id="S2.SS1.p3.4.m4.2.3.2.3" xref="S2.SS1.p3.4.m4.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.4.m4.2b"><interval closure="open" id="S2.SS1.p3.4.m4.2.3.1.cmml" xref="S2.SS1.p3.4.m4.2.3.2"><ci id="S2.SS1.p3.4.m4.1.1.cmml" xref="S2.SS1.p3.4.m4.1.1">italic-Ïµ</ci><ci id="S2.SS1.p3.4.m4.2.2.cmml" xref="S2.SS1.p3.4.m4.2.2">ğ›¿</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.4.m4.2c">(\epsilon,\delta)</annotation></semantics></math>-differentially private if, for any output <math id="S2.SS1.p3.5.m5.1" class="ltx_Math" alttext="A\subseteq\mathcal{Y}" display="inline"><semantics id="S2.SS1.p3.5.m5.1a"><mrow id="S2.SS1.p3.5.m5.1.1" xref="S2.SS1.p3.5.m5.1.1.cmml"><mi id="S2.SS1.p3.5.m5.1.1.2" xref="S2.SS1.p3.5.m5.1.1.2.cmml">A</mi><mo id="S2.SS1.p3.5.m5.1.1.1" xref="S2.SS1.p3.5.m5.1.1.1.cmml">âŠ†</mo><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p3.5.m5.1.1.3" xref="S2.SS1.p3.5.m5.1.1.3.cmml">ğ’´</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.5.m5.1b"><apply id="S2.SS1.p3.5.m5.1.1.cmml" xref="S2.SS1.p3.5.m5.1.1"><subset id="S2.SS1.p3.5.m5.1.1.1.cmml" xref="S2.SS1.p3.5.m5.1.1.1"></subset><ci id="S2.SS1.p3.5.m5.1.1.2.cmml" xref="S2.SS1.p3.5.m5.1.1.2">ğ´</ci><ci id="S2.SS1.p3.5.m5.1.1.3.cmml" xref="S2.SS1.p3.5.m5.1.1.3">ğ’´</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.5.m5.1c">A\subseteq\mathcal{Y}</annotation></semantics></math> and neighboring databases <math id="S2.SS1.p3.6.m6.2" class="ltx_Math" alttext="D,D^{\prime}\in\mathcal{D}" display="inline"><semantics id="S2.SS1.p3.6.m6.2a"><mrow id="S2.SS1.p3.6.m6.2.2" xref="S2.SS1.p3.6.m6.2.2.cmml"><mrow id="S2.SS1.p3.6.m6.2.2.1.1" xref="S2.SS1.p3.6.m6.2.2.1.2.cmml"><mi id="S2.SS1.p3.6.m6.1.1" xref="S2.SS1.p3.6.m6.1.1.cmml">D</mi><mo id="S2.SS1.p3.6.m6.2.2.1.1.2" xref="S2.SS1.p3.6.m6.2.2.1.2.cmml">,</mo><msup id="S2.SS1.p3.6.m6.2.2.1.1.1" xref="S2.SS1.p3.6.m6.2.2.1.1.1.cmml"><mi id="S2.SS1.p3.6.m6.2.2.1.1.1.2" xref="S2.SS1.p3.6.m6.2.2.1.1.1.2.cmml">D</mi><mo id="S2.SS1.p3.6.m6.2.2.1.1.1.3" xref="S2.SS1.p3.6.m6.2.2.1.1.1.3.cmml">â€²</mo></msup></mrow><mo id="S2.SS1.p3.6.m6.2.2.2" xref="S2.SS1.p3.6.m6.2.2.2.cmml">âˆˆ</mo><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p3.6.m6.2.2.3" xref="S2.SS1.p3.6.m6.2.2.3.cmml">ğ’Ÿ</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.6.m6.2b"><apply id="S2.SS1.p3.6.m6.2.2.cmml" xref="S2.SS1.p3.6.m6.2.2"><in id="S2.SS1.p3.6.m6.2.2.2.cmml" xref="S2.SS1.p3.6.m6.2.2.2"></in><list id="S2.SS1.p3.6.m6.2.2.1.2.cmml" xref="S2.SS1.p3.6.m6.2.2.1.1"><ci id="S2.SS1.p3.6.m6.1.1.cmml" xref="S2.SS1.p3.6.m6.1.1">ğ·</ci><apply id="S2.SS1.p3.6.m6.2.2.1.1.1.cmml" xref="S2.SS1.p3.6.m6.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p3.6.m6.2.2.1.1.1.1.cmml" xref="S2.SS1.p3.6.m6.2.2.1.1.1">superscript</csymbol><ci id="S2.SS1.p3.6.m6.2.2.1.1.1.2.cmml" xref="S2.SS1.p3.6.m6.2.2.1.1.1.2">ğ·</ci><ci id="S2.SS1.p3.6.m6.2.2.1.1.1.3.cmml" xref="S2.SS1.p3.6.m6.2.2.1.1.1.3">â€²</ci></apply></list><ci id="S2.SS1.p3.6.m6.2.2.3.cmml" xref="S2.SS1.p3.6.m6.2.2.3">ğ’Ÿ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.6.m6.2c">D,D^{\prime}\in\mathcal{D}</annotation></semantics></math> (i.e., <math id="S2.SS1.p3.7.m7.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S2.SS1.p3.7.m7.1a"><mi id="S2.SS1.p3.7.m7.1.1" xref="S2.SS1.p3.7.m7.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.7.m7.1b"><ci id="S2.SS1.p3.7.m7.1.1.cmml" xref="S2.SS1.p3.7.m7.1.1">ğ·</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.7.m7.1c">D</annotation></semantics></math> and <math id="S2.SS1.p3.8.m8.1" class="ltx_Math" alttext="D^{\prime}" display="inline"><semantics id="S2.SS1.p3.8.m8.1a"><msup id="S2.SS1.p3.8.m8.1.1" xref="S2.SS1.p3.8.m8.1.1.cmml"><mi id="S2.SS1.p3.8.m8.1.1.2" xref="S2.SS1.p3.8.m8.1.1.2.cmml">D</mi><mo id="S2.SS1.p3.8.m8.1.1.3" xref="S2.SS1.p3.8.m8.1.1.3.cmml">â€²</mo></msup><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.8.m8.1b"><apply id="S2.SS1.p3.8.m8.1.1.cmml" xref="S2.SS1.p3.8.m8.1.1"><csymbol cd="ambiguous" id="S2.SS1.p3.8.m8.1.1.1.cmml" xref="S2.SS1.p3.8.m8.1.1">superscript</csymbol><ci id="S2.SS1.p3.8.m8.1.1.2.cmml" xref="S2.SS1.p3.8.m8.1.1.2">ğ·</ci><ci id="S2.SS1.p3.8.m8.1.1.3.cmml" xref="S2.SS1.p3.8.m8.1.1.3">â€²</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.8.m8.1c">D^{\prime}</annotation></semantics></math> differ in at most one entry), we have</p>
<table id="S2.Ex2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.Ex2.m1.3" class="ltx_Math" alttext="\textnormal{Pr}[\mathcal{M}(D)\in A]\leq e^{\epsilon}\textnormal{Pr}[\mathcal{M}(D^{\prime})\in A]+\delta" display="block"><semantics id="S2.Ex2.m1.3a"><mrow id="S2.Ex2.m1.3.3" xref="S2.Ex2.m1.3.3.cmml"><mrow id="S2.Ex2.m1.2.2.1" xref="S2.Ex2.m1.2.2.1.cmml"><mtext id="S2.Ex2.m1.2.2.1.3" xref="S2.Ex2.m1.2.2.1.3a.cmml">Pr</mtext><mo lspace="0em" rspace="0em" id="S2.Ex2.m1.2.2.1.2" xref="S2.Ex2.m1.2.2.1.2.cmml">â€‹</mo><mrow id="S2.Ex2.m1.2.2.1.1.1" xref="S2.Ex2.m1.2.2.1.1.2.cmml"><mo stretchy="false" id="S2.Ex2.m1.2.2.1.1.1.2" xref="S2.Ex2.m1.2.2.1.1.2.1.cmml">[</mo><mrow id="S2.Ex2.m1.2.2.1.1.1.1" xref="S2.Ex2.m1.2.2.1.1.1.1.cmml"><mrow id="S2.Ex2.m1.2.2.1.1.1.1.2" xref="S2.Ex2.m1.2.2.1.1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.Ex2.m1.2.2.1.1.1.1.2.2" xref="S2.Ex2.m1.2.2.1.1.1.1.2.2.cmml">â„³</mi><mo lspace="0em" rspace="0em" id="S2.Ex2.m1.2.2.1.1.1.1.2.1" xref="S2.Ex2.m1.2.2.1.1.1.1.2.1.cmml">â€‹</mo><mrow id="S2.Ex2.m1.2.2.1.1.1.1.2.3.2" xref="S2.Ex2.m1.2.2.1.1.1.1.2.cmml"><mo stretchy="false" id="S2.Ex2.m1.2.2.1.1.1.1.2.3.2.1" xref="S2.Ex2.m1.2.2.1.1.1.1.2.cmml">(</mo><mi id="S2.Ex2.m1.1.1" xref="S2.Ex2.m1.1.1.cmml">D</mi><mo stretchy="false" id="S2.Ex2.m1.2.2.1.1.1.1.2.3.2.2" xref="S2.Ex2.m1.2.2.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S2.Ex2.m1.2.2.1.1.1.1.1" xref="S2.Ex2.m1.2.2.1.1.1.1.1.cmml">âˆˆ</mo><mi id="S2.Ex2.m1.2.2.1.1.1.1.3" xref="S2.Ex2.m1.2.2.1.1.1.1.3.cmml">A</mi></mrow><mo stretchy="false" id="S2.Ex2.m1.2.2.1.1.1.3" xref="S2.Ex2.m1.2.2.1.1.2.1.cmml">]</mo></mrow></mrow><mo id="S2.Ex2.m1.3.3.3" xref="S2.Ex2.m1.3.3.3.cmml">â‰¤</mo><mrow id="S2.Ex2.m1.3.3.2" xref="S2.Ex2.m1.3.3.2.cmml"><mrow id="S2.Ex2.m1.3.3.2.1" xref="S2.Ex2.m1.3.3.2.1.cmml"><msup id="S2.Ex2.m1.3.3.2.1.3" xref="S2.Ex2.m1.3.3.2.1.3.cmml"><mi id="S2.Ex2.m1.3.3.2.1.3.2" xref="S2.Ex2.m1.3.3.2.1.3.2.cmml">e</mi><mi id="S2.Ex2.m1.3.3.2.1.3.3" xref="S2.Ex2.m1.3.3.2.1.3.3.cmml">Ïµ</mi></msup><mo lspace="0em" rspace="0em" id="S2.Ex2.m1.3.3.2.1.2" xref="S2.Ex2.m1.3.3.2.1.2.cmml">â€‹</mo><mtext id="S2.Ex2.m1.3.3.2.1.4" xref="S2.Ex2.m1.3.3.2.1.4a.cmml">Pr</mtext><mo lspace="0em" rspace="0em" id="S2.Ex2.m1.3.3.2.1.2a" xref="S2.Ex2.m1.3.3.2.1.2.cmml">â€‹</mo><mrow id="S2.Ex2.m1.3.3.2.1.1.1" xref="S2.Ex2.m1.3.3.2.1.1.2.cmml"><mo stretchy="false" id="S2.Ex2.m1.3.3.2.1.1.1.2" xref="S2.Ex2.m1.3.3.2.1.1.2.1.cmml">[</mo><mrow id="S2.Ex2.m1.3.3.2.1.1.1.1" xref="S2.Ex2.m1.3.3.2.1.1.1.1.cmml"><mrow id="S2.Ex2.m1.3.3.2.1.1.1.1.1" xref="S2.Ex2.m1.3.3.2.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.Ex2.m1.3.3.2.1.1.1.1.1.3" xref="S2.Ex2.m1.3.3.2.1.1.1.1.1.3.cmml">â„³</mi><mo lspace="0em" rspace="0em" id="S2.Ex2.m1.3.3.2.1.1.1.1.1.2" xref="S2.Ex2.m1.3.3.2.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S2.Ex2.m1.3.3.2.1.1.1.1.1.1.1" xref="S2.Ex2.m1.3.3.2.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.Ex2.m1.3.3.2.1.1.1.1.1.1.1.2" xref="S2.Ex2.m1.3.3.2.1.1.1.1.1.1.1.1.cmml">(</mo><msup id="S2.Ex2.m1.3.3.2.1.1.1.1.1.1.1.1" xref="S2.Ex2.m1.3.3.2.1.1.1.1.1.1.1.1.cmml"><mi id="S2.Ex2.m1.3.3.2.1.1.1.1.1.1.1.1.2" xref="S2.Ex2.m1.3.3.2.1.1.1.1.1.1.1.1.2.cmml">D</mi><mo id="S2.Ex2.m1.3.3.2.1.1.1.1.1.1.1.1.3" xref="S2.Ex2.m1.3.3.2.1.1.1.1.1.1.1.1.3.cmml">â€²</mo></msup><mo stretchy="false" id="S2.Ex2.m1.3.3.2.1.1.1.1.1.1.1.3" xref="S2.Ex2.m1.3.3.2.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.Ex2.m1.3.3.2.1.1.1.1.2" xref="S2.Ex2.m1.3.3.2.1.1.1.1.2.cmml">âˆˆ</mo><mi id="S2.Ex2.m1.3.3.2.1.1.1.1.3" xref="S2.Ex2.m1.3.3.2.1.1.1.1.3.cmml">A</mi></mrow><mo stretchy="false" id="S2.Ex2.m1.3.3.2.1.1.1.3" xref="S2.Ex2.m1.3.3.2.1.1.2.1.cmml">]</mo></mrow></mrow><mo id="S2.Ex2.m1.3.3.2.2" xref="S2.Ex2.m1.3.3.2.2.cmml">+</mo><mi id="S2.Ex2.m1.3.3.2.3" xref="S2.Ex2.m1.3.3.2.3.cmml">Î´</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.Ex2.m1.3b"><apply id="S2.Ex2.m1.3.3.cmml" xref="S2.Ex2.m1.3.3"><leq id="S2.Ex2.m1.3.3.3.cmml" xref="S2.Ex2.m1.3.3.3"></leq><apply id="S2.Ex2.m1.2.2.1.cmml" xref="S2.Ex2.m1.2.2.1"><times id="S2.Ex2.m1.2.2.1.2.cmml" xref="S2.Ex2.m1.2.2.1.2"></times><ci id="S2.Ex2.m1.2.2.1.3a.cmml" xref="S2.Ex2.m1.2.2.1.3"><mtext id="S2.Ex2.m1.2.2.1.3.cmml" xref="S2.Ex2.m1.2.2.1.3">Pr</mtext></ci><apply id="S2.Ex2.m1.2.2.1.1.2.cmml" xref="S2.Ex2.m1.2.2.1.1.1"><csymbol cd="latexml" id="S2.Ex2.m1.2.2.1.1.2.1.cmml" xref="S2.Ex2.m1.2.2.1.1.1.2">delimited-[]</csymbol><apply id="S2.Ex2.m1.2.2.1.1.1.1.cmml" xref="S2.Ex2.m1.2.2.1.1.1.1"><in id="S2.Ex2.m1.2.2.1.1.1.1.1.cmml" xref="S2.Ex2.m1.2.2.1.1.1.1.1"></in><apply id="S2.Ex2.m1.2.2.1.1.1.1.2.cmml" xref="S2.Ex2.m1.2.2.1.1.1.1.2"><times id="S2.Ex2.m1.2.2.1.1.1.1.2.1.cmml" xref="S2.Ex2.m1.2.2.1.1.1.1.2.1"></times><ci id="S2.Ex2.m1.2.2.1.1.1.1.2.2.cmml" xref="S2.Ex2.m1.2.2.1.1.1.1.2.2">â„³</ci><ci id="S2.Ex2.m1.1.1.cmml" xref="S2.Ex2.m1.1.1">ğ·</ci></apply><ci id="S2.Ex2.m1.2.2.1.1.1.1.3.cmml" xref="S2.Ex2.m1.2.2.1.1.1.1.3">ğ´</ci></apply></apply></apply><apply id="S2.Ex2.m1.3.3.2.cmml" xref="S2.Ex2.m1.3.3.2"><plus id="S2.Ex2.m1.3.3.2.2.cmml" xref="S2.Ex2.m1.3.3.2.2"></plus><apply id="S2.Ex2.m1.3.3.2.1.cmml" xref="S2.Ex2.m1.3.3.2.1"><times id="S2.Ex2.m1.3.3.2.1.2.cmml" xref="S2.Ex2.m1.3.3.2.1.2"></times><apply id="S2.Ex2.m1.3.3.2.1.3.cmml" xref="S2.Ex2.m1.3.3.2.1.3"><csymbol cd="ambiguous" id="S2.Ex2.m1.3.3.2.1.3.1.cmml" xref="S2.Ex2.m1.3.3.2.1.3">superscript</csymbol><ci id="S2.Ex2.m1.3.3.2.1.3.2.cmml" xref="S2.Ex2.m1.3.3.2.1.3.2">ğ‘’</ci><ci id="S2.Ex2.m1.3.3.2.1.3.3.cmml" xref="S2.Ex2.m1.3.3.2.1.3.3">italic-Ïµ</ci></apply><ci id="S2.Ex2.m1.3.3.2.1.4a.cmml" xref="S2.Ex2.m1.3.3.2.1.4"><mtext id="S2.Ex2.m1.3.3.2.1.4.cmml" xref="S2.Ex2.m1.3.3.2.1.4">Pr</mtext></ci><apply id="S2.Ex2.m1.3.3.2.1.1.2.cmml" xref="S2.Ex2.m1.3.3.2.1.1.1"><csymbol cd="latexml" id="S2.Ex2.m1.3.3.2.1.1.2.1.cmml" xref="S2.Ex2.m1.3.3.2.1.1.1.2">delimited-[]</csymbol><apply id="S2.Ex2.m1.3.3.2.1.1.1.1.cmml" xref="S2.Ex2.m1.3.3.2.1.1.1.1"><in id="S2.Ex2.m1.3.3.2.1.1.1.1.2.cmml" xref="S2.Ex2.m1.3.3.2.1.1.1.1.2"></in><apply id="S2.Ex2.m1.3.3.2.1.1.1.1.1.cmml" xref="S2.Ex2.m1.3.3.2.1.1.1.1.1"><times id="S2.Ex2.m1.3.3.2.1.1.1.1.1.2.cmml" xref="S2.Ex2.m1.3.3.2.1.1.1.1.1.2"></times><ci id="S2.Ex2.m1.3.3.2.1.1.1.1.1.3.cmml" xref="S2.Ex2.m1.3.3.2.1.1.1.1.1.3">â„³</ci><apply id="S2.Ex2.m1.3.3.2.1.1.1.1.1.1.1.1.cmml" xref="S2.Ex2.m1.3.3.2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.Ex2.m1.3.3.2.1.1.1.1.1.1.1.1.1.cmml" xref="S2.Ex2.m1.3.3.2.1.1.1.1.1.1.1">superscript</csymbol><ci id="S2.Ex2.m1.3.3.2.1.1.1.1.1.1.1.1.2.cmml" xref="S2.Ex2.m1.3.3.2.1.1.1.1.1.1.1.1.2">ğ·</ci><ci id="S2.Ex2.m1.3.3.2.1.1.1.1.1.1.1.1.3.cmml" xref="S2.Ex2.m1.3.3.2.1.1.1.1.1.1.1.1.3">â€²</ci></apply></apply><ci id="S2.Ex2.m1.3.3.2.1.1.1.1.3.cmml" xref="S2.Ex2.m1.3.3.2.1.1.1.1.3">ğ´</ci></apply></apply></apply><ci id="S2.Ex2.m1.3.3.2.3.cmml" xref="S2.Ex2.m1.3.3.2.3">ğ›¿</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex2.m1.3c">\textnormal{Pr}[\mathcal{M}(D)\in A]\leq e^{\epsilon}\textnormal{Pr}[\mathcal{M}(D^{\prime})\in A]+\delta</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div id="S2.SS1.p4" class="ltx_para">
<p id="S2.SS1.p4.2" class="ltx_p">The privacy loss of the mechanism is defined by the parameter <math id="S2.SS1.p4.1.m1.1" class="ltx_Math" alttext="\epsilon\geq 0" display="inline"><semantics id="S2.SS1.p4.1.m1.1a"><mrow id="S2.SS1.p4.1.m1.1.1" xref="S2.SS1.p4.1.m1.1.1.cmml"><mi id="S2.SS1.p4.1.m1.1.1.2" xref="S2.SS1.p4.1.m1.1.1.2.cmml">Ïµ</mi><mo id="S2.SS1.p4.1.m1.1.1.1" xref="S2.SS1.p4.1.m1.1.1.1.cmml">â‰¥</mo><mn id="S2.SS1.p4.1.m1.1.1.3" xref="S2.SS1.p4.1.m1.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p4.1.m1.1b"><apply id="S2.SS1.p4.1.m1.1.1.cmml" xref="S2.SS1.p4.1.m1.1.1"><geq id="S2.SS1.p4.1.m1.1.1.1.cmml" xref="S2.SS1.p4.1.m1.1.1.1"></geq><ci id="S2.SS1.p4.1.m1.1.1.2.cmml" xref="S2.SS1.p4.1.m1.1.1.2">italic-Ïµ</ci><cn type="integer" id="S2.SS1.p4.1.m1.1.1.3.cmml" xref="S2.SS1.p4.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p4.1.m1.1c">\epsilon\geq 0</annotation></semantics></math> in the case of â€™pureâ€™ differential privacy and parameters <math id="S2.SS1.p4.2.m2.2" class="ltx_Math" alttext="\epsilon,\delta\geq 0" display="inline"><semantics id="S2.SS1.p4.2.m2.2a"><mrow id="S2.SS1.p4.2.m2.2.3" xref="S2.SS1.p4.2.m2.2.3.cmml"><mrow id="S2.SS1.p4.2.m2.2.3.2.2" xref="S2.SS1.p4.2.m2.2.3.2.1.cmml"><mi id="S2.SS1.p4.2.m2.1.1" xref="S2.SS1.p4.2.m2.1.1.cmml">Ïµ</mi><mo id="S2.SS1.p4.2.m2.2.3.2.2.1" xref="S2.SS1.p4.2.m2.2.3.2.1.cmml">,</mo><mi id="S2.SS1.p4.2.m2.2.2" xref="S2.SS1.p4.2.m2.2.2.cmml">Î´</mi></mrow><mo id="S2.SS1.p4.2.m2.2.3.1" xref="S2.SS1.p4.2.m2.2.3.1.cmml">â‰¥</mo><mn id="S2.SS1.p4.2.m2.2.3.3" xref="S2.SS1.p4.2.m2.2.3.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p4.2.m2.2b"><apply id="S2.SS1.p4.2.m2.2.3.cmml" xref="S2.SS1.p4.2.m2.2.3"><geq id="S2.SS1.p4.2.m2.2.3.1.cmml" xref="S2.SS1.p4.2.m2.2.3.1"></geq><list id="S2.SS1.p4.2.m2.2.3.2.1.cmml" xref="S2.SS1.p4.2.m2.2.3.2.2"><ci id="S2.SS1.p4.2.m2.1.1.cmml" xref="S2.SS1.p4.2.m2.1.1">italic-Ïµ</ci><ci id="S2.SS1.p4.2.m2.2.2.cmml" xref="S2.SS1.p4.2.m2.2.2">ğ›¿</ci></list><cn type="integer" id="S2.SS1.p4.2.m2.2.3.3.cmml" xref="S2.SS1.p4.2.m2.2.3.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p4.2.m2.2c">\epsilon,\delta\geq 0</annotation></semantics></math> in the case of â€™approximateâ€™ differential privacy.</p>
</div>
<div id="S2.SS1.p5" class="ltx_para">
<p id="S2.SS1.p5.1" class="ltx_p">The definition of neighboring databases used in this paper is user-level privacy. User-level privacy defines neighboring to be the addition or deletion of a single user in the data and all possible records of that user. Informally, the definition above states that the addition or removal of a single individual in the database does not provoke significant changes in the probability of any differentially private output. Therefore, differential privacy limits the amount of information that the output reveals about any individual.</p>
</div>
<div id="S2.SS1.p6" class="ltx_para">
<p id="S2.SS1.p6.3" class="ltx_p">A function <math id="S2.SS1.p6.1.m1.1" class="ltx_Math" alttext="f" display="inline"><semantics id="S2.SS1.p6.1.m1.1a"><mi id="S2.SS1.p6.1.m1.1.1" xref="S2.SS1.p6.1.m1.1.1.cmml">f</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p6.1.m1.1b"><ci id="S2.SS1.p6.1.m1.1.1.cmml" xref="S2.SS1.p6.1.m1.1.1">ğ‘“</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p6.1.m1.1c">f</annotation></semantics></math> (also called query) from a data set <math id="S2.SS1.p6.2.m2.1" class="ltx_Math" alttext="D\in\mathcal{D}" display="inline"><semantics id="S2.SS1.p6.2.m2.1a"><mrow id="S2.SS1.p6.2.m2.1.1" xref="S2.SS1.p6.2.m2.1.1.cmml"><mi id="S2.SS1.p6.2.m2.1.1.2" xref="S2.SS1.p6.2.m2.1.1.2.cmml">D</mi><mo id="S2.SS1.p6.2.m2.1.1.1" xref="S2.SS1.p6.2.m2.1.1.1.cmml">âˆˆ</mo><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p6.2.m2.1.1.3" xref="S2.SS1.p6.2.m2.1.1.3.cmml">ğ’Ÿ</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p6.2.m2.1b"><apply id="S2.SS1.p6.2.m2.1.1.cmml" xref="S2.SS1.p6.2.m2.1.1"><in id="S2.SS1.p6.2.m2.1.1.1.cmml" xref="S2.SS1.p6.2.m2.1.1.1"></in><ci id="S2.SS1.p6.2.m2.1.1.2.cmml" xref="S2.SS1.p6.2.m2.1.1.2">ğ·</ci><ci id="S2.SS1.p6.2.m2.1.1.3.cmml" xref="S2.SS1.p6.2.m2.1.1.3">ğ’Ÿ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p6.2.m2.1c">D\in\mathcal{D}</annotation></semantics></math> to a result set <math id="S2.SS1.p6.3.m3.1" class="ltx_Math" alttext="A\subseteq\mathcal{A}" display="inline"><semantics id="S2.SS1.p6.3.m3.1a"><mrow id="S2.SS1.p6.3.m3.1.1" xref="S2.SS1.p6.3.m3.1.1.cmml"><mi id="S2.SS1.p6.3.m3.1.1.2" xref="S2.SS1.p6.3.m3.1.1.2.cmml">A</mi><mo id="S2.SS1.p6.3.m3.1.1.1" xref="S2.SS1.p6.3.m3.1.1.1.cmml">âŠ†</mo><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p6.3.m3.1.1.3" xref="S2.SS1.p6.3.m3.1.1.3.cmml">ğ’œ</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p6.3.m3.1b"><apply id="S2.SS1.p6.3.m3.1.1.cmml" xref="S2.SS1.p6.3.m3.1.1"><subset id="S2.SS1.p6.3.m3.1.1.1.cmml" xref="S2.SS1.p6.3.m3.1.1.1"></subset><ci id="S2.SS1.p6.3.m3.1.1.2.cmml" xref="S2.SS1.p6.3.m3.1.1.2">ğ´</ci><ci id="S2.SS1.p6.3.m3.1.1.3.cmml" xref="S2.SS1.p6.3.m3.1.1.3">ğ’œ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p6.3.m3.1c">A\subseteq\mathcal{A}</annotation></semantics></math> can be made differentially private by injecting random noise to its output. The amount of noise depends on the sensitivity of the query.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Fairness Metrics</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.4" class="ltx_p">In this section we present the definition of two different fairness metrics: Equal Opportunity <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> and Statistical Disparity<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>. Given a data set <math id="S2.SS2.p1.1.m1.3" class="ltx_Math" alttext="W=(X,Y^{\prime},C)" display="inline"><semantics id="S2.SS2.p1.1.m1.3a"><mrow id="S2.SS2.p1.1.m1.3.3" xref="S2.SS2.p1.1.m1.3.3.cmml"><mi id="S2.SS2.p1.1.m1.3.3.3" xref="S2.SS2.p1.1.m1.3.3.3.cmml">W</mi><mo id="S2.SS2.p1.1.m1.3.3.2" xref="S2.SS2.p1.1.m1.3.3.2.cmml">=</mo><mrow id="S2.SS2.p1.1.m1.3.3.1.1" xref="S2.SS2.p1.1.m1.3.3.1.2.cmml"><mo stretchy="false" id="S2.SS2.p1.1.m1.3.3.1.1.2" xref="S2.SS2.p1.1.m1.3.3.1.2.cmml">(</mo><mi id="S2.SS2.p1.1.m1.1.1" xref="S2.SS2.p1.1.m1.1.1.cmml">X</mi><mo id="S2.SS2.p1.1.m1.3.3.1.1.3" xref="S2.SS2.p1.1.m1.3.3.1.2.cmml">,</mo><msup id="S2.SS2.p1.1.m1.3.3.1.1.1" xref="S2.SS2.p1.1.m1.3.3.1.1.1.cmml"><mi id="S2.SS2.p1.1.m1.3.3.1.1.1.2" xref="S2.SS2.p1.1.m1.3.3.1.1.1.2.cmml">Y</mi><mo id="S2.SS2.p1.1.m1.3.3.1.1.1.3" xref="S2.SS2.p1.1.m1.3.3.1.1.1.3.cmml">â€²</mo></msup><mo id="S2.SS2.p1.1.m1.3.3.1.1.4" xref="S2.SS2.p1.1.m1.3.3.1.2.cmml">,</mo><mi id="S2.SS2.p1.1.m1.2.2" xref="S2.SS2.p1.1.m1.2.2.cmml">C</mi><mo stretchy="false" id="S2.SS2.p1.1.m1.3.3.1.1.5" xref="S2.SS2.p1.1.m1.3.3.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.1.m1.3b"><apply id="S2.SS2.p1.1.m1.3.3.cmml" xref="S2.SS2.p1.1.m1.3.3"><eq id="S2.SS2.p1.1.m1.3.3.2.cmml" xref="S2.SS2.p1.1.m1.3.3.2"></eq><ci id="S2.SS2.p1.1.m1.3.3.3.cmml" xref="S2.SS2.p1.1.m1.3.3.3">ğ‘Š</ci><vector id="S2.SS2.p1.1.m1.3.3.1.2.cmml" xref="S2.SS2.p1.1.m1.3.3.1.1"><ci id="S2.SS2.p1.1.m1.1.1.cmml" xref="S2.SS2.p1.1.m1.1.1">ğ‘‹</ci><apply id="S2.SS2.p1.1.m1.3.3.1.1.1.cmml" xref="S2.SS2.p1.1.m1.3.3.1.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.1.m1.3.3.1.1.1.1.cmml" xref="S2.SS2.p1.1.m1.3.3.1.1.1">superscript</csymbol><ci id="S2.SS2.p1.1.m1.3.3.1.1.1.2.cmml" xref="S2.SS2.p1.1.m1.3.3.1.1.1.2">ğ‘Œ</ci><ci id="S2.SS2.p1.1.m1.3.3.1.1.1.3.cmml" xref="S2.SS2.p1.1.m1.3.3.1.1.1.3">â€²</ci></apply><ci id="S2.SS2.p1.1.m1.2.2.cmml" xref="S2.SS2.p1.1.m1.2.2">ğ¶</ci></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.1.m1.3c">W=(X,Y^{\prime},C)</annotation></semantics></math> with binary protected attribute <math id="S2.SS2.p1.2.m2.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S2.SS2.p1.2.m2.1a"><mi id="S2.SS2.p1.2.m2.1.1" xref="S2.SS2.p1.2.m2.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.2.m2.1b"><ci id="S2.SS2.p1.2.m2.1.1.cmml" xref="S2.SS2.p1.2.m2.1.1">ğ¶</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.2.m2.1c">C</annotation></semantics></math> (e.g. race, sex, religion, etc), remaining decision variables <math id="S2.SS2.p1.3.m3.1" class="ltx_Math" alttext="X" display="inline"><semantics id="S2.SS2.p1.3.m3.1a"><mi id="S2.SS2.p1.3.m3.1.1" xref="S2.SS2.p1.3.m3.1.1.cmml">X</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.3.m3.1b"><ci id="S2.SS2.p1.3.m3.1.1.cmml" xref="S2.SS2.p1.3.m3.1.1">ğ‘‹</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.3.m3.1c">X</annotation></semantics></math> and predicted outcome <math id="S2.SS2.p1.4.m4.1" class="ltx_Math" alttext="Y^{\prime}" display="inline"><semantics id="S2.SS2.p1.4.m4.1a"><msup id="S2.SS2.p1.4.m4.1.1" xref="S2.SS2.p1.4.m4.1.1.cmml"><mi id="S2.SS2.p1.4.m4.1.1.2" xref="S2.SS2.p1.4.m4.1.1.2.cmml">Y</mi><mo id="S2.SS2.p1.4.m4.1.1.3" xref="S2.SS2.p1.4.m4.1.1.3.cmml">â€²</mo></msup><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.4.m4.1b"><apply id="S2.SS2.p1.4.m4.1.1.cmml" xref="S2.SS2.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.4.m4.1.1.1.cmml" xref="S2.SS2.p1.4.m4.1.1">superscript</csymbol><ci id="S2.SS2.p1.4.m4.1.1.2.cmml" xref="S2.SS2.p1.4.m4.1.1.2">ğ‘Œ</ci><ci id="S2.SS2.p1.4.m4.1.1.3.cmml" xref="S2.SS2.p1.4.m4.1.1.3">â€²</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.4.m4.1c">Y^{\prime}</annotation></semantics></math>, we define Equal Opportunity and Statistical Disparity as follows.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p"><span id="S2.SS2.p2.1.1" class="ltx_text ltx_font_smallcaps">Equal Opportunity/ Equality of Odds</span> requires equal True Positive Rate (TPR) across subgroups:</p>
<table id="S2.Ex3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.Ex3.m1.1" class="ltx_math_unparsed" alttext="\textnormal{Pr}(Y^{\prime}=1|Y=1,C=0)=\textnormal{Pr}(Y^{\prime}=1|Y=1,C=1)" display="block"><semantics id="S2.Ex3.m1.1a"><mrow id="S2.Ex3.m1.1b"><mtext id="S2.Ex3.m1.1.1">Pr</mtext><mrow id="S2.Ex3.m1.1.2"><mo stretchy="false" id="S2.Ex3.m1.1.2.1">(</mo><msup id="S2.Ex3.m1.1.2.2"><mi id="S2.Ex3.m1.1.2.2.2">Y</mi><mo id="S2.Ex3.m1.1.2.2.3">â€²</mo></msup><mo id="S2.Ex3.m1.1.2.3">=</mo><mn id="S2.Ex3.m1.1.2.4">1</mn><mo fence="false" rspace="0.167em" stretchy="false" id="S2.Ex3.m1.1.2.5">|</mo><mi id="S2.Ex3.m1.1.2.6">Y</mi><mo id="S2.Ex3.m1.1.2.7">=</mo><mn id="S2.Ex3.m1.1.2.8">1</mn><mo id="S2.Ex3.m1.1.2.9">,</mo><mi id="S2.Ex3.m1.1.2.10">C</mi><mo id="S2.Ex3.m1.1.2.11">=</mo><mn id="S2.Ex3.m1.1.2.12">0</mn><mo stretchy="false" id="S2.Ex3.m1.1.2.13">)</mo></mrow><mo id="S2.Ex3.m1.1.3">=</mo><mtext id="S2.Ex3.m1.1.4">Pr</mtext><mrow id="S2.Ex3.m1.1.5"><mo stretchy="false" id="S2.Ex3.m1.1.5.1">(</mo><msup id="S2.Ex3.m1.1.5.2"><mi id="S2.Ex3.m1.1.5.2.2">Y</mi><mo id="S2.Ex3.m1.1.5.2.3">â€²</mo></msup><mo id="S2.Ex3.m1.1.5.3">=</mo><mn id="S2.Ex3.m1.1.5.4">1</mn><mo fence="false" rspace="0.167em" stretchy="false" id="S2.Ex3.m1.1.5.5">|</mo><mi id="S2.Ex3.m1.1.5.6">Y</mi><mo id="S2.Ex3.m1.1.5.7">=</mo><mn id="S2.Ex3.m1.1.5.8">1</mn><mo id="S2.Ex3.m1.1.5.9">,</mo><mi id="S2.Ex3.m1.1.5.10">C</mi><mo id="S2.Ex3.m1.1.5.11">=</mo><mn id="S2.Ex3.m1.1.5.12">1</mn><mo stretchy="false" id="S2.Ex3.m1.1.5.13">)</mo></mrow></mrow><annotation encoding="application/x-tex" id="S2.Ex3.m1.1c">\textnormal{Pr}(Y^{\prime}=1|Y=1,C=0)=\textnormal{Pr}(Y^{\prime}=1|Y=1,C=1)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div id="S2.SS2.p3" class="ltx_para">
<p id="S2.SS2.p3.1" class="ltx_p">where Yâ€™ is the model output.</p>
</div>
<div id="S2.SS2.p4" class="ltx_para">
<p id="S2.SS2.p4.1" class="ltx_p"><span id="S2.SS2.p4.1.1" class="ltx_text ltx_font_smallcaps">Statistical Parity</span> requires positive predictions to be unaffected by the value of the protected attribute, regardless of true label</p>
<table id="S2.Ex4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.Ex4.m1.2" class="ltx_Math" alttext="\textnormal{Pr}(Y^{\prime}=1|C=0)=\textnormal{Pr}(Y^{\prime}=1|C=1)" display="block"><semantics id="S2.Ex4.m1.2a"><mrow id="S2.Ex4.m1.2.2" xref="S2.Ex4.m1.2.2.cmml"><mrow id="S2.Ex4.m1.1.1.1" xref="S2.Ex4.m1.1.1.1.cmml"><mtext id="S2.Ex4.m1.1.1.1.3" xref="S2.Ex4.m1.1.1.1.3a.cmml">Pr</mtext><mo lspace="0em" rspace="0em" id="S2.Ex4.m1.1.1.1.2" xref="S2.Ex4.m1.1.1.1.2.cmml">â€‹</mo><mrow id="S2.Ex4.m1.1.1.1.1.1" xref="S2.Ex4.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.Ex4.m1.1.1.1.1.1.2" xref="S2.Ex4.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.Ex4.m1.1.1.1.1.1.1" xref="S2.Ex4.m1.1.1.1.1.1.1.cmml"><msup id="S2.Ex4.m1.1.1.1.1.1.1.2" xref="S2.Ex4.m1.1.1.1.1.1.1.2.cmml"><mi id="S2.Ex4.m1.1.1.1.1.1.1.2.2" xref="S2.Ex4.m1.1.1.1.1.1.1.2.2.cmml">Y</mi><mo id="S2.Ex4.m1.1.1.1.1.1.1.2.3" xref="S2.Ex4.m1.1.1.1.1.1.1.2.3.cmml">â€²</mo></msup><mo id="S2.Ex4.m1.1.1.1.1.1.1.3" xref="S2.Ex4.m1.1.1.1.1.1.1.3.cmml">=</mo><mrow id="S2.Ex4.m1.1.1.1.1.1.1.4" xref="S2.Ex4.m1.1.1.1.1.1.1.4.cmml"><mn id="S2.Ex4.m1.1.1.1.1.1.1.4.2" xref="S2.Ex4.m1.1.1.1.1.1.1.4.2.cmml">1</mn><mo fence="false" id="S2.Ex4.m1.1.1.1.1.1.1.4.1" xref="S2.Ex4.m1.1.1.1.1.1.1.4.1.cmml">|</mo><mi id="S2.Ex4.m1.1.1.1.1.1.1.4.3" xref="S2.Ex4.m1.1.1.1.1.1.1.4.3.cmml">C</mi></mrow><mo id="S2.Ex4.m1.1.1.1.1.1.1.5" xref="S2.Ex4.m1.1.1.1.1.1.1.5.cmml">=</mo><mn id="S2.Ex4.m1.1.1.1.1.1.1.6" xref="S2.Ex4.m1.1.1.1.1.1.1.6.cmml">0</mn></mrow><mo stretchy="false" id="S2.Ex4.m1.1.1.1.1.1.3" xref="S2.Ex4.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.Ex4.m1.2.2.3" xref="S2.Ex4.m1.2.2.3.cmml">=</mo><mrow id="S2.Ex4.m1.2.2.2" xref="S2.Ex4.m1.2.2.2.cmml"><mtext id="S2.Ex4.m1.2.2.2.3" xref="S2.Ex4.m1.2.2.2.3a.cmml">Pr</mtext><mo lspace="0em" rspace="0em" id="S2.Ex4.m1.2.2.2.2" xref="S2.Ex4.m1.2.2.2.2.cmml">â€‹</mo><mrow id="S2.Ex4.m1.2.2.2.1.1" xref="S2.Ex4.m1.2.2.2.1.1.1.cmml"><mo stretchy="false" id="S2.Ex4.m1.2.2.2.1.1.2" xref="S2.Ex4.m1.2.2.2.1.1.1.cmml">(</mo><mrow id="S2.Ex4.m1.2.2.2.1.1.1" xref="S2.Ex4.m1.2.2.2.1.1.1.cmml"><msup id="S2.Ex4.m1.2.2.2.1.1.1.2" xref="S2.Ex4.m1.2.2.2.1.1.1.2.cmml"><mi id="S2.Ex4.m1.2.2.2.1.1.1.2.2" xref="S2.Ex4.m1.2.2.2.1.1.1.2.2.cmml">Y</mi><mo id="S2.Ex4.m1.2.2.2.1.1.1.2.3" xref="S2.Ex4.m1.2.2.2.1.1.1.2.3.cmml">â€²</mo></msup><mo id="S2.Ex4.m1.2.2.2.1.1.1.3" xref="S2.Ex4.m1.2.2.2.1.1.1.3.cmml">=</mo><mrow id="S2.Ex4.m1.2.2.2.1.1.1.4" xref="S2.Ex4.m1.2.2.2.1.1.1.4.cmml"><mn id="S2.Ex4.m1.2.2.2.1.1.1.4.2" xref="S2.Ex4.m1.2.2.2.1.1.1.4.2.cmml">1</mn><mo fence="false" id="S2.Ex4.m1.2.2.2.1.1.1.4.1" xref="S2.Ex4.m1.2.2.2.1.1.1.4.1.cmml">|</mo><mi id="S2.Ex4.m1.2.2.2.1.1.1.4.3" xref="S2.Ex4.m1.2.2.2.1.1.1.4.3.cmml">C</mi></mrow><mo id="S2.Ex4.m1.2.2.2.1.1.1.5" xref="S2.Ex4.m1.2.2.2.1.1.1.5.cmml">=</mo><mn id="S2.Ex4.m1.2.2.2.1.1.1.6" xref="S2.Ex4.m1.2.2.2.1.1.1.6.cmml">1</mn></mrow><mo stretchy="false" id="S2.Ex4.m1.2.2.2.1.1.3" xref="S2.Ex4.m1.2.2.2.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.Ex4.m1.2b"><apply id="S2.Ex4.m1.2.2.cmml" xref="S2.Ex4.m1.2.2"><eq id="S2.Ex4.m1.2.2.3.cmml" xref="S2.Ex4.m1.2.2.3"></eq><apply id="S2.Ex4.m1.1.1.1.cmml" xref="S2.Ex4.m1.1.1.1"><times id="S2.Ex4.m1.1.1.1.2.cmml" xref="S2.Ex4.m1.1.1.1.2"></times><ci id="S2.Ex4.m1.1.1.1.3a.cmml" xref="S2.Ex4.m1.1.1.1.3"><mtext id="S2.Ex4.m1.1.1.1.3.cmml" xref="S2.Ex4.m1.1.1.1.3">Pr</mtext></ci><apply id="S2.Ex4.m1.1.1.1.1.1.1.cmml" xref="S2.Ex4.m1.1.1.1.1.1"><and id="S2.Ex4.m1.1.1.1.1.1.1a.cmml" xref="S2.Ex4.m1.1.1.1.1.1"></and><apply id="S2.Ex4.m1.1.1.1.1.1.1b.cmml" xref="S2.Ex4.m1.1.1.1.1.1"><eq id="S2.Ex4.m1.1.1.1.1.1.1.3.cmml" xref="S2.Ex4.m1.1.1.1.1.1.1.3"></eq><apply id="S2.Ex4.m1.1.1.1.1.1.1.2.cmml" xref="S2.Ex4.m1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.Ex4.m1.1.1.1.1.1.1.2.1.cmml" xref="S2.Ex4.m1.1.1.1.1.1.1.2">superscript</csymbol><ci id="S2.Ex4.m1.1.1.1.1.1.1.2.2.cmml" xref="S2.Ex4.m1.1.1.1.1.1.1.2.2">ğ‘Œ</ci><ci id="S2.Ex4.m1.1.1.1.1.1.1.2.3.cmml" xref="S2.Ex4.m1.1.1.1.1.1.1.2.3">â€²</ci></apply><apply id="S2.Ex4.m1.1.1.1.1.1.1.4.cmml" xref="S2.Ex4.m1.1.1.1.1.1.1.4"><csymbol cd="latexml" id="S2.Ex4.m1.1.1.1.1.1.1.4.1.cmml" xref="S2.Ex4.m1.1.1.1.1.1.1.4.1">conditional</csymbol><cn type="integer" id="S2.Ex4.m1.1.1.1.1.1.1.4.2.cmml" xref="S2.Ex4.m1.1.1.1.1.1.1.4.2">1</cn><ci id="S2.Ex4.m1.1.1.1.1.1.1.4.3.cmml" xref="S2.Ex4.m1.1.1.1.1.1.1.4.3">ğ¶</ci></apply></apply><apply id="S2.Ex4.m1.1.1.1.1.1.1c.cmml" xref="S2.Ex4.m1.1.1.1.1.1"><eq id="S2.Ex4.m1.1.1.1.1.1.1.5.cmml" xref="S2.Ex4.m1.1.1.1.1.1.1.5"></eq><share href="#S2.Ex4.m1.1.1.1.1.1.1.4.cmml" id="S2.Ex4.m1.1.1.1.1.1.1d.cmml" xref="S2.Ex4.m1.1.1.1.1.1"></share><cn type="integer" id="S2.Ex4.m1.1.1.1.1.1.1.6.cmml" xref="S2.Ex4.m1.1.1.1.1.1.1.6">0</cn></apply></apply></apply><apply id="S2.Ex4.m1.2.2.2.cmml" xref="S2.Ex4.m1.2.2.2"><times id="S2.Ex4.m1.2.2.2.2.cmml" xref="S2.Ex4.m1.2.2.2.2"></times><ci id="S2.Ex4.m1.2.2.2.3a.cmml" xref="S2.Ex4.m1.2.2.2.3"><mtext id="S2.Ex4.m1.2.2.2.3.cmml" xref="S2.Ex4.m1.2.2.2.3">Pr</mtext></ci><apply id="S2.Ex4.m1.2.2.2.1.1.1.cmml" xref="S2.Ex4.m1.2.2.2.1.1"><and id="S2.Ex4.m1.2.2.2.1.1.1a.cmml" xref="S2.Ex4.m1.2.2.2.1.1"></and><apply id="S2.Ex4.m1.2.2.2.1.1.1b.cmml" xref="S2.Ex4.m1.2.2.2.1.1"><eq id="S2.Ex4.m1.2.2.2.1.1.1.3.cmml" xref="S2.Ex4.m1.2.2.2.1.1.1.3"></eq><apply id="S2.Ex4.m1.2.2.2.1.1.1.2.cmml" xref="S2.Ex4.m1.2.2.2.1.1.1.2"><csymbol cd="ambiguous" id="S2.Ex4.m1.2.2.2.1.1.1.2.1.cmml" xref="S2.Ex4.m1.2.2.2.1.1.1.2">superscript</csymbol><ci id="S2.Ex4.m1.2.2.2.1.1.1.2.2.cmml" xref="S2.Ex4.m1.2.2.2.1.1.1.2.2">ğ‘Œ</ci><ci id="S2.Ex4.m1.2.2.2.1.1.1.2.3.cmml" xref="S2.Ex4.m1.2.2.2.1.1.1.2.3">â€²</ci></apply><apply id="S2.Ex4.m1.2.2.2.1.1.1.4.cmml" xref="S2.Ex4.m1.2.2.2.1.1.1.4"><csymbol cd="latexml" id="S2.Ex4.m1.2.2.2.1.1.1.4.1.cmml" xref="S2.Ex4.m1.2.2.2.1.1.1.4.1">conditional</csymbol><cn type="integer" id="S2.Ex4.m1.2.2.2.1.1.1.4.2.cmml" xref="S2.Ex4.m1.2.2.2.1.1.1.4.2">1</cn><ci id="S2.Ex4.m1.2.2.2.1.1.1.4.3.cmml" xref="S2.Ex4.m1.2.2.2.1.1.1.4.3">ğ¶</ci></apply></apply><apply id="S2.Ex4.m1.2.2.2.1.1.1c.cmml" xref="S2.Ex4.m1.2.2.2.1.1"><eq id="S2.Ex4.m1.2.2.2.1.1.1.5.cmml" xref="S2.Ex4.m1.2.2.2.1.1.1.5"></eq><share href="#S2.Ex4.m1.2.2.2.1.1.1.4.cmml" id="S2.Ex4.m1.2.2.2.1.1.1d.cmml" xref="S2.Ex4.m1.2.2.2.1.1"></share><cn type="integer" id="S2.Ex4.m1.2.2.2.1.1.1.6.cmml" xref="S2.Ex4.m1.2.2.2.1.1.1.6">1</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex4.m1.2c">\textnormal{Pr}(Y^{\prime}=1|C=0)=\textnormal{Pr}(Y^{\prime}=1|C=1)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div id="S2.SS2.p5" class="ltx_para">
<p id="S2.SS2.p5.2" class="ltx_p">We follow the approach of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>, <a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite> and utilize difference in Equal Oportunity (DEO) = <math id="S2.SS2.p5.1.m1.1" class="ltx_math_unparsed" alttext="|\textnormal{Pr}(Y^{\prime}=1|Y=1,C=0)-\textnormal{Pr}(Y^{\prime}=1|Y=1,C=1)|" display="inline"><semantics id="S2.SS2.p5.1.m1.1a"><mrow id="S2.SS2.p5.1.m1.1b"><mo fence="false" rspace="0.167em" stretchy="false" id="S2.SS2.p5.1.m1.1.1">|</mo><mtext id="S2.SS2.p5.1.m1.1.2">Pr</mtext><mrow id="S2.SS2.p5.1.m1.1.3"><mo stretchy="false" id="S2.SS2.p5.1.m1.1.3.1">(</mo><msup id="S2.SS2.p5.1.m1.1.3.2"><mi id="S2.SS2.p5.1.m1.1.3.2.2">Y</mi><mo id="S2.SS2.p5.1.m1.1.3.2.3">â€²</mo></msup><mo id="S2.SS2.p5.1.m1.1.3.3">=</mo><mn id="S2.SS2.p5.1.m1.1.3.4">1</mn><mo fence="false" rspace="0.167em" stretchy="false" id="S2.SS2.p5.1.m1.1.3.5">|</mo><mi id="S2.SS2.p5.1.m1.1.3.6">Y</mi><mo id="S2.SS2.p5.1.m1.1.3.7">=</mo><mn id="S2.SS2.p5.1.m1.1.3.8">1</mn><mo id="S2.SS2.p5.1.m1.1.3.9">,</mo><mi id="S2.SS2.p5.1.m1.1.3.10">C</mi><mo id="S2.SS2.p5.1.m1.1.3.11">=</mo><mn id="S2.SS2.p5.1.m1.1.3.12">0</mn><mo stretchy="false" id="S2.SS2.p5.1.m1.1.3.13">)</mo></mrow><mo id="S2.SS2.p5.1.m1.1.4">âˆ’</mo><mtext id="S2.SS2.p5.1.m1.1.5">Pr</mtext><mrow id="S2.SS2.p5.1.m1.1.6"><mo stretchy="false" id="S2.SS2.p5.1.m1.1.6.1">(</mo><msup id="S2.SS2.p5.1.m1.1.6.2"><mi id="S2.SS2.p5.1.m1.1.6.2.2">Y</mi><mo id="S2.SS2.p5.1.m1.1.6.2.3">â€²</mo></msup><mo id="S2.SS2.p5.1.m1.1.6.3">=</mo><mn id="S2.SS2.p5.1.m1.1.6.4">1</mn><mo fence="false" rspace="0.167em" stretchy="false" id="S2.SS2.p5.1.m1.1.6.5">|</mo><mi id="S2.SS2.p5.1.m1.1.6.6">Y</mi><mo id="S2.SS2.p5.1.m1.1.6.7">=</mo><mn id="S2.SS2.p5.1.m1.1.6.8">1</mn><mo id="S2.SS2.p5.1.m1.1.6.9">,</mo><mi id="S2.SS2.p5.1.m1.1.6.10">C</mi><mo id="S2.SS2.p5.1.m1.1.6.11">=</mo><mn id="S2.SS2.p5.1.m1.1.6.12">1</mn><mo stretchy="false" id="S2.SS2.p5.1.m1.1.6.13">)</mo></mrow><mo fence="false" stretchy="false" id="S2.SS2.p5.1.m1.1.7">|</mo></mrow><annotation encoding="application/x-tex" id="S2.SS2.p5.1.m1.1c">|\textnormal{Pr}(Y^{\prime}=1|Y=1,C=0)-\textnormal{Pr}(Y^{\prime}=1|Y=1,C=1)|</annotation></semantics></math> and difference in Statistical Parity (DSP) = <math id="S2.SS2.p5.2.m2.1" class="ltx_math_unparsed" alttext="|\textnormal{Pr}(Y^{\prime}=1|C=0)-\textnormal{Pr}(Y^{\prime}=1|C=1)|" display="inline"><semantics id="S2.SS2.p5.2.m2.1a"><mrow id="S2.SS2.p5.2.m2.1b"><mo fence="false" rspace="0.167em" stretchy="false" id="S2.SS2.p5.2.m2.1.1">|</mo><mtext id="S2.SS2.p5.2.m2.1.2">Pr</mtext><mrow id="S2.SS2.p5.2.m2.1.3"><mo stretchy="false" id="S2.SS2.p5.2.m2.1.3.1">(</mo><msup id="S2.SS2.p5.2.m2.1.3.2"><mi id="S2.SS2.p5.2.m2.1.3.2.2">Y</mi><mo id="S2.SS2.p5.2.m2.1.3.2.3">â€²</mo></msup><mo id="S2.SS2.p5.2.m2.1.3.3">=</mo><mn id="S2.SS2.p5.2.m2.1.3.4">1</mn><mo fence="false" rspace="0.167em" stretchy="false" id="S2.SS2.p5.2.m2.1.3.5">|</mo><mi id="S2.SS2.p5.2.m2.1.3.6">C</mi><mo id="S2.SS2.p5.2.m2.1.3.7">=</mo><mn id="S2.SS2.p5.2.m2.1.3.8">0</mn><mo stretchy="false" id="S2.SS2.p5.2.m2.1.3.9">)</mo></mrow><mo id="S2.SS2.p5.2.m2.1.4">âˆ’</mo><mtext id="S2.SS2.p5.2.m2.1.5">Pr</mtext><mrow id="S2.SS2.p5.2.m2.1.6"><mo stretchy="false" id="S2.SS2.p5.2.m2.1.6.1">(</mo><msup id="S2.SS2.p5.2.m2.1.6.2"><mi id="S2.SS2.p5.2.m2.1.6.2.2">Y</mi><mo id="S2.SS2.p5.2.m2.1.6.2.3">â€²</mo></msup><mo id="S2.SS2.p5.2.m2.1.6.3">=</mo><mn id="S2.SS2.p5.2.m2.1.6.4">1</mn><mo fence="false" rspace="0.167em" stretchy="false" id="S2.SS2.p5.2.m2.1.6.5">|</mo><mi id="S2.SS2.p5.2.m2.1.6.6">C</mi><mo id="S2.SS2.p5.2.m2.1.6.7">=</mo><mn id="S2.SS2.p5.2.m2.1.6.8">1</mn><mo stretchy="false" id="S2.SS2.p5.2.m2.1.6.9">)</mo></mrow><mo fence="false" stretchy="false" id="S2.SS2.p5.2.m2.1.7">|</mo></mrow><annotation encoding="application/x-tex" id="S2.SS2.p5.2.m2.1c">|\textnormal{Pr}(Y^{\prime}=1|C=0)-\textnormal{Pr}(Y^{\prime}=1|C=1)|</annotation></semantics></math> to measure model fairness.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Differentially Private Synthetic Data Generators.</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">We use several differentially private (DP) synthetic data generators that have been specifically tailored for generating tabular data with the goal of enhancing their utility for learning tasks. We consider two broad categories of approaches: i) marginal-based methods, ii) and Generative Adversarial Network (GAN) based models.</p>
</div>
<section id="S2.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.3.1 </span>Marginal-based methods</h4>

<section id="S2.SS3.SSS1.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">MWEM PGM</h5>

<div id="S2.SS3.SSS1.Px1.p1" class="ltx_para">
<p id="S2.SS3.SSS1.Px1.p1.1" class="ltx_p">Is a variation of the multiplicative weights with exponential mechanism algorithm (MWEM), which is an algorithm that generated synthetic data based on linear queries. The algorithm aims to produce a data distribution that produces query answers similar answers resulted when querying the real data set. The MWEM PGM variation combines probabilistic graphical models with the MWEM algorithm. The structure of the graphical model is determined by the measurements, such that no information is lost relative to a full contingency table representation.</p>
</div>
</section>
<section id="S2.SS3.SSS1.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">MST</h5>

<div id="S2.SS3.SSS1.Px2.p1" class="ltx_para">
<p id="S2.SS3.SSS1.Px2.p1.1" class="ltx_p">Is a synthetic data generation algorithm that acts selecting 2- and 3-way marginals for measurement. It combines one principled step, which is to find the maximum spanning tree (MST) on the graph where edge weights correspond to mutual information between two attributes, with some additional heuristics to ensure that certain important attribute pairs are selected, and a final step to select triples while keeping the graph tree-like.</p>
</div>
</section>
<section id="S2.SS3.SSS1.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">PrivBayes</h5>

<div id="S2.SS3.SSS1.Px3.p1" class="ltx_para">
<p id="S2.SS3.SSS1.Px3.p1.1" class="ltx_p">In order to improve the utility of the generated synthetic data, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> approximates the actual distribution of the data by constructing a Bayesian network using the correlations between the data attributes. This allows them to factorize the joint distribution of the data into marginal distributions. Next, to ensure differential privacy, noise is injected into each of the marginal distributions and the simulated data is sampled from the approximate joint distribution constructed from these noisy marginals.</p>
</div>
</section>
</section>
<section id="S2.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.3.2 </span>GAN-based methods</h4>

<div id="S2.SS3.SSS2.p1" class="ltx_para">
<p id="S2.SS3.SSS2.p1.2" class="ltx_p">Generative neural networks (GANs) are a type of artificial neural network used in machine learning for generating new data samples similar to a given training data set.
Generative adversarial networks are based on a game, in the sense of game theory, between two machine learning models, a discriminator model <math id="S2.SS3.SSS2.p1.1.m1.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S2.SS3.SSS2.p1.1.m1.1a"><mi id="S2.SS3.SSS2.p1.1.m1.1.1" xref="S2.SS3.SSS2.p1.1.m1.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS2.p1.1.m1.1b"><ci id="S2.SS3.SSS2.p1.1.m1.1.1.cmml" xref="S2.SS3.SSS2.p1.1.m1.1.1">ğ·</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS2.p1.1.m1.1c">D</annotation></semantics></math> and the generator <math id="S2.SS3.SSS2.p1.2.m2.1" class="ltx_Math" alttext="G" display="inline"><semantics id="S2.SS3.SSS2.p1.2.m2.1a"><mi id="S2.SS3.SSS2.p1.2.m2.1.1" xref="S2.SS3.SSS2.p1.2.m2.1.1.cmml">G</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS2.p1.2.m2.1b"><ci id="S2.SS3.SSS2.p1.2.m2.1.1.cmml" xref="S2.SS3.SSS2.p1.2.m2.1.1">ğº</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS2.p1.2.m2.1c">G</annotation></semantics></math> model. The goal of the generator is to learn realistic samples that can fool the discriminator, while the goal of the discriminator is to be able to tell generator generated samples from real ones <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>.</p>
</div>
<div id="S2.SS3.SSS2.p2" class="ltx_para">
<p id="S2.SS3.SSS2.p2.1" class="ltx_p"><span id="S2.SS3.SSS2.p2.1.1" class="ltx_text ltx_font_bold">Conditional Tabular GAN (CTGAN)</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite> is an approach for generating tabular data. CTGAN adapts GANs by addressing issues that are unique to tabular data that conventional GANs cannot handle, such as the modeling of multivariate discrete and mixed discrete and continuous distributions. It achieves these challenges by augmenting the training procedure with mode-specific normalization, and by employing a conditional generator and training-by-sampling that allows it to explore discrete values more evenly. When applying differentially private SGD (DP-SGD) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> in combination with CTGAN the result is a DP approach for generating tabular data.</p>
</div>
<div id="S2.SS3.SSS2.p3" class="ltx_para">
<p id="S2.SS3.SSS2.p3.2" class="ltx_p">The <span id="S2.SS3.SSS2.p3.2.1" class="ltx_text ltx_font_bold">PATE (Private Aggregation of Teacher Ensembles)</span> framework <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite> protects the privacy of sensitive data during training, by transferring knowledge from an ensemble of teacher models trained on partitions of the data to a student model. To achieve DP guarantees, only the student model is published while keeping the teachers private. The framework adds Laplacian noise to the aggregated answers from the teachers that are used to train the student models. CTGAN can provide differential privacy by applying the PATE framework. We call this combination PATE-CTGAN, which is similar to PATE-GAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>, for images. The original data set is partitioned into <math id="S2.SS3.SSS2.p3.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S2.SS3.SSS2.p3.1.m1.1a"><mi id="S2.SS3.SSS2.p3.1.m1.1.1" xref="S2.SS3.SSS2.p3.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS2.p3.1.m1.1b"><ci id="S2.SS3.SSS2.p3.1.m1.1.1.cmml" xref="S2.SS3.SSS2.p3.1.m1.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS2.p3.1.m1.1c">k</annotation></semantics></math> subsets and a DP teacher discriminator is trained on each subset. Further, instead of using one generator to generate samples, <math id="S2.SS3.SSS2.p3.2.m2.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S2.SS3.SSS2.p3.2.m2.1a"><mi id="S2.SS3.SSS2.p3.2.m2.1.1" xref="S2.SS3.SSS2.p3.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS2.p3.2.m2.1b"><ci id="S2.SS3.SSS2.p3.2.m2.1.1.cmml" xref="S2.SS3.SSS2.p3.2.m2.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS2.p3.2.m2.1c">k</annotation></semantics></math> conditional generators are used for each subset of the data.</p>
</div>
</section>
</section>
<section id="S2.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.4 </span>Data sets</h3>

<section id="S2.SS4.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Adult data set</h5>

<div id="S2.SS4.SSS0.Px1.p1" class="ltx_para">
<p id="S2.SS4.SSS0.Px1.p1.1" class="ltx_p">In the Adult data set (32561 instances), the features were categorized as protected variable (C): gender (male, female); and response variable (Y): income (binary); decision variables (X): the remaining variables in the data set. We map into categorical variables all continuous variables.</p>
</div>
</section>
<section id="S2.SS4.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Prison Recidivism data set</h5>

<div id="S2.SS4.SSS0.Px2.p1" class="ltx_para">
<p id="S2.SS4.SSS0.Px2.p1.1" class="ltx_p">From the COMPAS data set (7214 instances), we select severity of charge, number of prior crimes, and age category to be the decision variables (X). The outcome variable (Y) is a binary indicator of whether the individual recidivated (re-offended), and race is set to be the protected variable (C). We utilize a reduced set of features as proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>.</p>
</div>
</section>
<section id="S2.SS4.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Fair Prison Recidivism data set</h5>

<div id="S2.SS4.SSS0.Px3.p1" class="ltx_para">
<p id="S2.SS4.SSS0.Px3.p1.1" class="ltx_p">We construct a â€fairâ€ data set based on the COMPAS recidivism data set by employing a data preprocessing technique for learning non-discriminating classifiers from <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>, which involves changing the class labels in order to remove discrimination from the data set. This approach selects examples close to the decision boundary to be either â€™promotedâ€™, i.e label flipped to the desirable class, or â€˜demotedâ€™, i.e label flipped to the undesirable class (ex: the â€™recidivateâ€™ label in the COMPAS data set is the undesirable class). By flipping an equal number of positive and negative class examples, the class skew in the data set is maintained.</p>
</div>
</section>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Experimental Evaluation</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">One potential outcome of synthetic data sharing is the utilization of synthetic data for training and evaluating an ML model. The trained model could be deployed without assessing its performance on real data, due to lack of data access. However, it is important to acknowledge that these trained models are ultimately applied to real data. This scenario is illustrated in Figure <a href="#Sx2.F1" title="Fig 1 â€£ Introduction" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. In our experiments, we address the concern that there may be substantial disparities in performance between the evaluation phase (employing synthetic data) and the deployment phase (utilizing real data).
We compare the performance of logistic regression models trained with differentially private synthesizers, focusing on two performance dimensions: utility and fairness. The follow the approach of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> and use logistic regression for downstream classification evaluation to avoid another layer of stochasticity.</p>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.1" class="ltx_p">To assess the utility performance, we employ the AUC-ROC metric, which quantifies trade-off between the recall and false positive rate. We examine fairness performance through three different perspectives.
Previous research <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> has indicated that differentially private machine learning models tend to perform worse on minority groups. To this point we evaluate the decay in accuracy for the different subgroups in the protected attribute. We also measure the difference in equality of odds (DEO) and the difference in statistical parity (DSP). These metrics allow us to assess any disparities or bias in the modelâ€™s predictions across different groups. Furthermore, we also investigate the extent to which one can accurately assess a model utilizing synthetic data sets. Again, we evaluate two performance dimensions: utility and fairness.</p>
</div>
<div id="S3.p3" class="ltx_para">
<p id="S3.p3.1" class="ltx_p">Our experiments include two types of synthesizers: marginal-based and GAN-based synthesizers.
We generate synthetic data using three differentially private marginal-based synthesizers: MST <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>, MWEM-PGM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> and PrivBayes <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite>; and four GAN-based synthesizers: DP-GAN, DP-CTGAN, PATE-GAN and PATE-CTGAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>. For each synthetic data generation technique, we generate data sets utilizing different four privacy-loss budgets <math id="S3.p3.1.m1.4" class="ltx_Math" alttext="\epsilon=\{0.5,1.0,5.0,10.0\}" display="inline"><semantics id="S3.p3.1.m1.4a"><mrow id="S3.p3.1.m1.4.5" xref="S3.p3.1.m1.4.5.cmml"><mi id="S3.p3.1.m1.4.5.2" xref="S3.p3.1.m1.4.5.2.cmml">Ïµ</mi><mo id="S3.p3.1.m1.4.5.1" xref="S3.p3.1.m1.4.5.1.cmml">=</mo><mrow id="S3.p3.1.m1.4.5.3.2" xref="S3.p3.1.m1.4.5.3.1.cmml"><mo stretchy="false" id="S3.p3.1.m1.4.5.3.2.1" xref="S3.p3.1.m1.4.5.3.1.cmml">{</mo><mn id="S3.p3.1.m1.1.1" xref="S3.p3.1.m1.1.1.cmml">0.5</mn><mo id="S3.p3.1.m1.4.5.3.2.2" xref="S3.p3.1.m1.4.5.3.1.cmml">,</mo><mn id="S3.p3.1.m1.2.2" xref="S3.p3.1.m1.2.2.cmml">1.0</mn><mo id="S3.p3.1.m1.4.5.3.2.3" xref="S3.p3.1.m1.4.5.3.1.cmml">,</mo><mn id="S3.p3.1.m1.3.3" xref="S3.p3.1.m1.3.3.cmml">5.0</mn><mo id="S3.p3.1.m1.4.5.3.2.4" xref="S3.p3.1.m1.4.5.3.1.cmml">,</mo><mn id="S3.p3.1.m1.4.4" xref="S3.p3.1.m1.4.4.cmml">10.0</mn><mo stretchy="false" id="S3.p3.1.m1.4.5.3.2.5" xref="S3.p3.1.m1.4.5.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p3.1.m1.4b"><apply id="S3.p3.1.m1.4.5.cmml" xref="S3.p3.1.m1.4.5"><eq id="S3.p3.1.m1.4.5.1.cmml" xref="S3.p3.1.m1.4.5.1"></eq><ci id="S3.p3.1.m1.4.5.2.cmml" xref="S3.p3.1.m1.4.5.2">italic-Ïµ</ci><set id="S3.p3.1.m1.4.5.3.1.cmml" xref="S3.p3.1.m1.4.5.3.2"><cn type="float" id="S3.p3.1.m1.1.1.cmml" xref="S3.p3.1.m1.1.1">0.5</cn><cn type="float" id="S3.p3.1.m1.2.2.cmml" xref="S3.p3.1.m1.2.2">1.0</cn><cn type="float" id="S3.p3.1.m1.3.3.cmml" xref="S3.p3.1.m1.3.3">5.0</cn><cn type="float" id="S3.p3.1.m1.4.4.cmml" xref="S3.p3.1.m1.4.4">10.0</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.1.m1.4c">\epsilon=\{0.5,1.0,5.0,10.0\}</annotation></semantics></math>.</p>
</div>
<div id="S3.p4" class="ltx_para">
<p id="S3.p4.1" class="ltx_p">We randomly divide the real data set into an 80/20 split, separating the data into generator and test data sets. We run 10 rounds of synthetic DP data generation on the 80% split (generator data), where we generate synthetic train and synthetic test data sets. We utilize the SmartNoise Library<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>https://smartnoise.org</span></span></span> implementation of the synthesizers, and approximate-DP approaches use the libraryâ€™s default value of <math id="S3.p4.1.m1.1" class="ltx_Math" alttext="\delta" display="inline"><semantics id="S3.p4.1.m1.1a"><mi id="S3.p4.1.m1.1.1" xref="S3.p4.1.m1.1.1.cmml">Î´</mi><annotation-xml encoding="MathML-Content" id="S3.p4.1.m1.1b"><ci id="S3.p4.1.m1.1.1.cmml" xref="S3.p4.1.m1.1.1">ğ›¿</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.1.m1.1c">\delta</annotation></semantics></math>. For experiments using PrivBayes Synthesizers, we use the DiffPrivLib implementation <span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>https://github.com/IBM/differential-privacy-library</span></span></span>.</p>
</div>
<div id="S3.p5" class="ltx_para">
<p id="S3.p5.1" class="ltx_p">We train Logistic Regression models using the generated DP synthetic data sets. In experiments where we test the trained models on real data, model performance is evaluated on the real test data (the 20% test split from the real data). In experiments where we test the trained models on synthetic data, models are evaluated using the synthetic test data sets.</p>
</div>
<div id="S3.p6" class="ltx_para">
<p id="S3.p6.1" class="ltx_p">We report, for each technique and each value of privacy loss parameter, the mean across 10 rounds. Our experiments use three data sets: the UCI Adult data set <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite> and ProPublicaâ€™s COMPAS recidivism data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>, and a fair COMPAS data set as defined in Section <a href="#S2.SS4.SSS0.Px3" title="Fair Prison Recidivism data set â€£ 2.4 Data sets â€£ 2 Preliminaries" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.4</span></a>. The fair COMPAS data set provides a way to evaluate synthetic data generation performance in fair and biased versions of the same data set.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Utility analysis of synthetic data in machine learning pipelines</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">We evaluate the quality of models trained with synthetic data sets by measuring AUC and accuracy of the protected class. We consider privacy-loss budgets of 0.5, 1.0, 5.0 and 10.0 . We compare the AUC obtained in our experiments with the AUC measured by training models with the real (non-synthetic) Adult, COMPAS, and fair COMPAS data sets.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.5" class="ltx_p">Figure <a href="#S3.F2" title="Fig 2 â€£ 3.1 Utility analysis of synthetic data in machine learning pipelines â€£ 3 Experimental Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> (a) shows AUC for different privacy losses and different synthesizers. The plots show the variation of AUC as a function of <math id="S3.SS1.p2.1.m1.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S3.SS1.p2.1.m1.1a"><mi id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml">Ïµ</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><ci id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1">italic-Ïµ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">\epsilon</annotation></semantics></math> for marginal-based and GAN-based synhtesizers. The top row refers to marginal-based synthesizers. Overall, the performance of the models trained on marginal-based synthetic data is very close to the baseline model, trained on real data. For all three synthesizers, we see an increase in AUC as we increase <math id="S3.SS1.p2.2.m2.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S3.SS1.p2.2.m2.1a"><mi id="S3.SS1.p2.2.m2.1.1" xref="S3.SS1.p2.2.m2.1.1.cmml">Ïµ</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.1b"><ci id="S3.SS1.p2.2.m2.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1">italic-Ïµ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.1c">\epsilon</annotation></semantics></math>. For all data sets, Adult, COMPAS and fair COMPAS, the perfomance of MST and MWEM-PGM are similar across all values of <math id="S3.SS1.p2.3.m3.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S3.SS1.p2.3.m3.1a"><mi id="S3.SS1.p2.3.m3.1.1" xref="S3.SS1.p2.3.m3.1.1.cmml">Ïµ</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.3.m3.1b"><ci id="S3.SS1.p2.3.m3.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1">italic-Ïµ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.3.m3.1c">\epsilon</annotation></semantics></math>. PrivBayes has a slightly lower performance. For <math id="S3.SS1.p2.4.m4.1" class="ltx_Math" alttext="\epsilon&gt;5.0" display="inline"><semantics id="S3.SS1.p2.4.m4.1a"><mrow id="S3.SS1.p2.4.m4.1.1" xref="S3.SS1.p2.4.m4.1.1.cmml"><mi id="S3.SS1.p2.4.m4.1.1.2" xref="S3.SS1.p2.4.m4.1.1.2.cmml">Ïµ</mi><mo id="S3.SS1.p2.4.m4.1.1.1" xref="S3.SS1.p2.4.m4.1.1.1.cmml">&gt;</mo><mn id="S3.SS1.p2.4.m4.1.1.3" xref="S3.SS1.p2.4.m4.1.1.3.cmml">5.0</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.4.m4.1b"><apply id="S3.SS1.p2.4.m4.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1"><gt id="S3.SS1.p2.4.m4.1.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1.1"></gt><ci id="S3.SS1.p2.4.m4.1.1.2.cmml" xref="S3.SS1.p2.4.m4.1.1.2">italic-Ïµ</ci><cn type="float" id="S3.SS1.p2.4.m4.1.1.3.cmml" xref="S3.SS1.p2.4.m4.1.1.3">5.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.4.m4.1c">\epsilon&gt;5.0</annotation></semantics></math>, all three synthesizer presented very similar performance. For COMPAS data set (which has a small dimension) the performance of synthetic data sets as training data is very close to the performance of the real data. The bottom row of figure <a href="#S3.F2" title="Fig 2 â€£ 3.1 Utility analysis of synthetic data in machine learning pipelines â€£ 3 Experimental Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> (a) presents the perfomance of GAN-based synthetic data. The overall performance of this type of synthesizer is worse and the performance of the marginal-based synthesizer. As noted by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>, models trained on GAN-based synthetic data perform worse than models trained on marginal-based synthetic data. With AUC <math id="S3.SS1.p2.5.m5.1" class="ltx_Math" alttext="\approx 0.5" display="inline"><semantics id="S3.SS1.p2.5.m5.1a"><mrow id="S3.SS1.p2.5.m5.1.1" xref="S3.SS1.p2.5.m5.1.1.cmml"><mi id="S3.SS1.p2.5.m5.1.1.2" xref="S3.SS1.p2.5.m5.1.1.2.cmml"></mi><mo id="S3.SS1.p2.5.m5.1.1.1" xref="S3.SS1.p2.5.m5.1.1.1.cmml">â‰ˆ</mo><mn id="S3.SS1.p2.5.m5.1.1.3" xref="S3.SS1.p2.5.m5.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.5.m5.1b"><apply id="S3.SS1.p2.5.m5.1.1.cmml" xref="S3.SS1.p2.5.m5.1.1"><approx id="S3.SS1.p2.5.m5.1.1.1.cmml" xref="S3.SS1.p2.5.m5.1.1.1"></approx><csymbol cd="latexml" id="S3.SS1.p2.5.m5.1.1.2.cmml" xref="S3.SS1.p2.5.m5.1.1.2">absent</csymbol><cn type="float" id="S3.SS1.p2.5.m5.1.1.3.cmml" xref="S3.SS1.p2.5.m5.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.5.m5.1c">\approx 0.5</annotation></semantics></math>, we can say that they do not do much better than random guessing. Additionally, we see a much greater variance in results for a same privacy-loss budget, which is observed by the large error bars. Finally, as the privacy-loss budget increases, the utility does not necessarily increase.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.1" class="ltx_p">Although several works have assessed the performance of machine learning models trained with synthetic data sets <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>, this is the first study to analyze if synthetic data sets can be used for model assessment, and how close to reality such assessment is. In Figure <a href="#S3.F2" title="Fig 2 â€£ 3.1 Utility analysis of synthetic data in machine learning pipelines â€£ 3 Experimental Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> (b) we present the plots of variation of AUC for different values of epsilon. The plots in the first line refer to performance of models trained on marginal-based synthesizers, the the plots in the second line refer to GAN-based synthesizers. By comparing the evaluation of models trained with marginal-based data in Figure <a href="#S3.F2" title="Fig 2 â€£ 3.1 Utility analysis of synthetic data in machine learning pipelines â€£ 3 Experimental Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> (a) - assessment with real data, and in Figure <a href="#S3.F2" title="Fig 2 â€£ 3.1 Utility analysis of synthetic data in machine learning pipelines â€£ 3 Experimental Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> (b) - assessment with synthetic data, we see that the assessment is very similar in both cases when the synthesizers are MST and MWEM PGM. When assessing with synthetic data, we notice that PrivBayes present a large difference in assessment results when assessing model trained on Adult and fair COMPAS synthetic data. GAN-based synthetic data present inconsistent behavior when used for model assessment. When comparing the assessments in Figure <a href="#S3.F2" title="Fig 2 â€£ 3.1 Utility analysis of synthetic data in machine learning pipelines â€£ 3 Experimental Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> (a) - assessment with real data, and (b) - assessment with synthetic data, we notice that using DP-GAN sythetic data for model assessment can over estimate model AUC. Overall, GAN-based synthetic data will make assessments that are as good as random guessing.</p>
</div>
<figure id="S3.F2" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S3.F2.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2310.19250/assets/x1.png" id="S3.F2.sf1.g1" class="ltx_graphics ltx_img_landscape" width="403" height="242" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F2.sf1.2.1.1" class="ltx_text" style="font-size:80%;">(a)</span> </span><span id="S3.F2.sf1.3.2" class="ltx_text" style="font-size:80%;">AUC variation of models trained on synthetic data and evaluated using real data.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S3.F2.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2310.19250/assets/x2.png" id="S3.F2.sf2.g1" class="ltx_graphics ltx_img_landscape" width="403" height="243" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F2.sf2.2.1.1" class="ltx_text" style="font-size:80%;">(b)</span> </span><span id="S3.F2.sf2.3.2" class="ltx_text" style="font-size:80%;">AUC variation of models trained on synthetic data and evaluated using synthetic data.</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Fig 2: </span>Impact in utility caused by the use of differentially private synthetic data in model training and testing. In (a) we show the decay in model utility when utilizing marginal-based and GAN-based synthetic data sets for model training. In (b) we show what is the measured model utility when the instrument for measuring model performance is a synthetic data set.</figcaption>
</figure>
<section id="S3.SS1.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Marginal-based synthetic data does better at training and assessing utility of models.</h5>

<div id="S3.SS1.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS1.SSS0.Px1.p1.1" class="ltx_p">We ranked the utility performance of all synthesizers taking based on two criteria: ability to generate synthetic data for model training and ability to generate synthetic data for model assessment. Table <a href="#S3.T1" title="Table 1 â€£ Marginal-based synthetic data does better at training and assessing utility of models. â€£ 3.1 Utility analysis of synthetic data in machine learning pipelines â€£ 3 Experimental Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> shows the ranking of synthesizers when generating training ans assessment data for the Adult data and the COMPAS data. The table also shows model AUC metrics when measured with real data - AUC(R), and model AUC when measured with synthetic data - AUC(S). All table results accounts for synthetic data generated with privacy-loss parameter <math id="S3.SS1.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="\epsilon=5.0" display="inline"><semantics id="S3.SS1.SSS0.Px1.p1.1.m1.1a"><mrow id="S3.SS1.SSS0.Px1.p1.1.m1.1.1" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1.cmml"><mi id="S3.SS1.SSS0.Px1.p1.1.m1.1.1.2" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1.2.cmml">Ïµ</mi><mo id="S3.SS1.SSS0.Px1.p1.1.m1.1.1.1" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1.1.cmml">=</mo><mn id="S3.SS1.SSS0.Px1.p1.1.m1.1.1.3" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1.3.cmml">5.0</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.1.m1.1b"><apply id="S3.SS1.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1"><eq id="S3.SS1.SSS0.Px1.p1.1.m1.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1.1"></eq><ci id="S3.SS1.SSS0.Px1.p1.1.m1.1.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1.2">italic-Ïµ</ci><cn type="float" id="S3.SS1.SSS0.Px1.p1.1.m1.1.1.3.cmml" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1.3">5.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.1.m1.1c">\epsilon=5.0</annotation></semantics></math>.</p>
</div>
<figure id="S3.T1" class="ltx_table">
<table id="S3.T1.3" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T1.3.1.1" class="ltx_tr">
<th id="S3.T1.3.1.1.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T1.3.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column" colspan="2"><span id="S3.T1.3.1.1.2.1" class="ltx_text ltx_font_smallcaps">Rank</span></th>
<th id="S3.T1.3.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column" colspan="2"><span id="S3.T1.3.1.1.3.1" class="ltx_text ltx_font_smallcaps">Adult</span>
</th>
<th id="S3.T1.3.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column" colspan="2"><span id="S3.T1.3.1.1.4.1" class="ltx_text ltx_font_smallcaps">COMPAS</span>
</th>
</tr>
<tr id="S3.T1.3.2.2" class="ltx_tr">
<th id="S3.T1.3.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row"><span id="S3.T1.3.2.2.1.1" class="ltx_text ltx_font_smallcaps">Synthesizer</span></th>
<th id="S3.T1.3.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S3.T1.3.2.2.2.1" class="ltx_text ltx_font_smallcaps">Adult</span></th>
<th id="S3.T1.3.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S3.T1.3.2.2.3.1" class="ltx_text ltx_font_smallcaps">COMPAS</span></th>
<th id="S3.T1.3.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column">AUC (R)</th>
<th id="S3.T1.3.2.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column">AUC (S)</th>
<th id="S3.T1.3.2.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column">AUC (R)</th>
<th id="S3.T1.3.2.2.7" class="ltx_td ltx_align_center ltx_th ltx_th_column">AUC (S)</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T1.3.3.1" class="ltx_tr">
<th id="S3.T1.3.3.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt">MWEM PGM</th>
<td id="S3.T1.3.3.1.2" class="ltx_td ltx_align_center ltx_border_tt">1st</td>
<td id="S3.T1.3.3.1.3" class="ltx_td ltx_align_center ltx_border_tt">1st</td>
<td id="S3.T1.3.3.1.4" class="ltx_td ltx_align_center ltx_border_tt">0.850</td>
<td id="S3.T1.3.3.1.5" class="ltx_td ltx_align_center ltx_border_tt">0.820</td>
<td id="S3.T1.3.3.1.6" class="ltx_td ltx_align_center ltx_border_tt">0.684</td>
<td id="S3.T1.3.3.1.7" class="ltx_td ltx_align_center ltx_border_tt">0.671</td>
</tr>
<tr id="S3.T1.3.4.2" class="ltx_tr">
<th id="S3.T1.3.4.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">MST</th>
<td id="S3.T1.3.4.2.2" class="ltx_td ltx_align_center">2nd</td>
<td id="S3.T1.3.4.2.3" class="ltx_td ltx_align_center">2nd</td>
<td id="S3.T1.3.4.2.4" class="ltx_td ltx_align_center">0.836</td>
<td id="S3.T1.3.4.2.5" class="ltx_td ltx_align_center">0.804</td>
<td id="S3.T1.3.4.2.6" class="ltx_td ltx_align_center">0.662</td>
<td id="S3.T1.3.4.2.7" class="ltx_td ltx_align_center">0.643</td>
</tr>
<tr id="S3.T1.3.5.3" class="ltx_tr">
<th id="S3.T1.3.5.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">PrivBayes</th>
<td id="S3.T1.3.5.3.2" class="ltx_td ltx_align_center">3rd</td>
<td id="S3.T1.3.5.3.3" class="ltx_td ltx_align_center">3rd</td>
<td id="S3.T1.3.5.3.4" class="ltx_td ltx_align_center">0.846</td>
<td id="S3.T1.3.5.3.5" class="ltx_td ltx_align_center">0.544</td>
<td id="S3.T1.3.5.3.6" class="ltx_td ltx_align_center">0.668</td>
<td id="S3.T1.3.5.3.7" class="ltx_td ltx_align_center">0.629</td>
</tr>
<tr id="S3.T1.3.6.4" class="ltx_tr">
<th id="S3.T1.3.6.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">DP-GAN</th>
<td id="S3.T1.3.6.4.2" class="ltx_td ltx_align_center">4th</td>
<td id="S3.T1.3.6.4.3" class="ltx_td ltx_align_center">6th</td>
<td id="S3.T1.3.6.4.4" class="ltx_td ltx_align_center">0.667</td>
<td id="S3.T1.3.6.4.5" class="ltx_td ltx_align_center">0.880</td>
<td id="S3.T1.3.6.4.6" class="ltx_td ltx_align_center">0.503</td>
<td id="S3.T1.3.6.4.7" class="ltx_td ltx_align_center">0.568</td>
</tr>
<tr id="S3.T1.3.7.5" class="ltx_tr">
<th id="S3.T1.3.7.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">PATE-CTGAN</th>
<td id="S3.T1.3.7.5.2" class="ltx_td ltx_align_center">5th</td>
<td id="S3.T1.3.7.5.3" class="ltx_td ltx_align_center">4th</td>
<td id="S3.T1.3.7.5.4" class="ltx_td ltx_align_center">0.343</td>
<td id="S3.T1.3.7.5.5" class="ltx_td ltx_align_center">0.504</td>
<td id="S3.T1.3.7.5.6" class="ltx_td ltx_align_center">0.552</td>
<td id="S3.T1.3.7.5.7" class="ltx_td ltx_align_center">0.492</td>
</tr>
<tr id="S3.T1.3.8.6" class="ltx_tr">
<th id="S3.T1.3.8.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">DP-CTGAN</th>
<td id="S3.T1.3.8.6.2" class="ltx_td ltx_align_center">6th</td>
<td id="S3.T1.3.8.6.3" class="ltx_td ltx_align_center">5th</td>
<td id="S3.T1.3.8.6.4" class="ltx_td ltx_align_center">0.284</td>
<td id="S3.T1.3.8.6.5" class="ltx_td ltx_align_center">0.485</td>
<td id="S3.T1.3.8.6.6" class="ltx_td ltx_align_center">0.504</td>
<td id="S3.T1.3.8.6.7" class="ltx_td ltx_align_center">0.502</td>
</tr>
<tr id="S3.T1.3.9.7" class="ltx_tr">
<th id="S3.T1.3.9.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">PATE-GAN</th>
<td id="S3.T1.3.9.7.2" class="ltx_td ltx_align_center">7th</td>
<td id="S3.T1.3.9.7.3" class="ltx_td ltx_align_center">7th</td>
<td id="S3.T1.3.9.7.4" class="ltx_td ltx_align_center">0.210</td>
<td id="S3.T1.3.9.7.5" class="ltx_td ltx_align_center">0.597</td>
<td id="S3.T1.3.9.7.6" class="ltx_td ltx_align_center">0.362</td>
<td id="S3.T1.3.9.7.7" class="ltx_td ltx_align_center">0.587</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span>Synthesizer utility comparison. We compare and rank all synthesizers by their ability to generate quality training data and evaluation data for machine learning pipelines. The comparison presented accounts for synthetic data generated with privacy-loss parameter <math id="S3.T1.2.m1.1" class="ltx_Math" alttext="\epsilon=5.0" display="inline"><semantics id="S3.T1.2.m1.1b"><mrow id="S3.T1.2.m1.1.1" xref="S3.T1.2.m1.1.1.cmml"><mi id="S3.T1.2.m1.1.1.2" xref="S3.T1.2.m1.1.1.2.cmml">Ïµ</mi><mo id="S3.T1.2.m1.1.1.1" xref="S3.T1.2.m1.1.1.1.cmml">=</mo><mn id="S3.T1.2.m1.1.1.3" xref="S3.T1.2.m1.1.1.3.cmml">5.0</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.2.m1.1c"><apply id="S3.T1.2.m1.1.1.cmml" xref="S3.T1.2.m1.1.1"><eq id="S3.T1.2.m1.1.1.1.cmml" xref="S3.T1.2.m1.1.1.1"></eq><ci id="S3.T1.2.m1.1.1.2.cmml" xref="S3.T1.2.m1.1.1.2">italic-Ïµ</ci><cn type="float" id="S3.T1.2.m1.1.1.3.cmml" xref="S3.T1.2.m1.1.1.3">5.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.2.m1.1d">\epsilon=5.0</annotation></semantics></math>. In addition to present a performance ranking for Adult and COMPAS data, we show a comparison of model AUC measured with real data - AUC(R), and model AUC measured with synthetic data - AUC(S).</figcaption>
</figure>
<div id="S3.SS1.SSS0.Px1.p2" class="ltx_para">
<p id="S3.SS1.SSS0.Px1.p2.1" class="ltx_p">MWEM PGM synthetic data outperforms all other synthetic data for both tasks: utility as training data for machine learning models and utility as evaluation data for machine learning models. The performance of synthetic data sets generated with MWEM PGM and MST perform well and with a small performance decay when compared to real data, both when using the synthetic data for model training and model assessment. For model training, when comparing the AUC achieved by model trained with the real data set (AUC = 0.892 ) to the metrics achieved by models trained with MWEM PGM data (AUC = 0.850 ) and MST (AUC = 0.836), the decrease in performance is small. The synthetic data sets also present a good performance as assessment data. The model assessment resulted when using MST data (AUC = 0.804) and MWEM PGM data (AUC = 0.820) presents consistent results with a small decay. Although PrivBayes data presents good performance in model training (AUC = 0.846), there is a significant discrepancy between assessment utilizing real data and assessment utilizing synthetic data. We reach similar conclusions when analysing results for COMPAS data. Using GAN-based data as training data resulted in models with utility very close to random guess, as already observed in previous analysis, with DP-GAN synthetic data performing slightly better than the rest of GAN-based data sets.</p>
</div>
</section>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Fairness analysis of synthetic data in machine learning pipelines</h3>

<section id="S3.SS2.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Impacts on subgroup accuracy</h5>

<div id="S3.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS2.SSS0.Px1.p1.1" class="ltx_p">In the previous section, we showed that adding privacy by utilizing synthetic data sets in machine learning pipelines results in a utility decrease. We now proceed to perform a fairness analysis. In this experiment, presented in Table <a href="#S3.T2" title="Table 2 â€£ Impacts on subgroup accuracy â€£ 3.2 Fairness analysis of synthetic data in machine learning pipelines â€£ 3 Experimental Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> we analyze model accuracy for different groups in the protected class to understand whether the addition of privacy to the data pipeline harms model utility more for the minority class than it does for the privileged class. Results in Table <a href="#S3.T2" title="Table 2 â€£ Impacts on subgroup accuracy â€£ 3.2 Fairness analysis of synthetic data in machine learning pipelines â€£ 3 Experimental Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> refer to the Adult data set.</p>
</div>
<figure id="S3.T2" class="ltx_table">
<table id="S3.T2.3" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T2.3.1.1" class="ltx_tr">
<th id="S3.T2.3.1.1.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T2.3.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column" colspan="4"><span id="S3.T2.3.1.1.2.1" class="ltx_text ltx_font_smallcaps">Accuracy of different subgroups - Adult data</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T2.3.2.1" class="ltx_tr">
<th id="S3.T2.3.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T2.3.2.1.1.1" class="ltx_text ltx_font_smallcaps">Synthesizer</span></th>
<td id="S3.T2.3.2.1.2" class="ltx_td ltx_align_center">minority (R)</td>
<td id="S3.T2.3.2.1.3" class="ltx_td ltx_align_center">minority (S)</td>
<td id="S3.T2.3.2.1.4" class="ltx_td ltx_align_center">privileged (R)</td>
<td id="S3.T2.3.2.1.5" class="ltx_td ltx_align_center">privileged (S)</td>
</tr>
<tr id="S3.T2.3.3.2" class="ltx_tr">
<th id="S3.T2.3.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt">Real</th>
<th id="S3.T2.3.3.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">0.924</th>
<th id="S3.T2.3.3.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">â€“</th>
<th id="S3.T2.3.3.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">0.804</th>
<th id="S3.T2.3.3.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">â€“</th>
</tr>
<tr id="S3.T2.3.4.3" class="ltx_tr">
<th id="S3.T2.3.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">MWEM PGM</th>
<td id="S3.T2.3.4.3.2" class="ltx_td ltx_align_center">0.909</td>
<td id="S3.T2.3.4.3.3" class="ltx_td ltx_align_center">0.898</td>
<td id="S3.T2.3.4.3.4" class="ltx_td ltx_align_center">0.779</td>
<td id="S3.T2.3.4.3.5" class="ltx_td ltx_align_center">0.770</td>
</tr>
<tr id="S3.T2.3.5.4" class="ltx_tr">
<th id="S3.T2.3.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row">MST</th>
<th id="S3.T2.3.5.4.2" class="ltx_td ltx_align_center ltx_th ltx_th_column">0.914</th>
<th id="S3.T2.3.5.4.3" class="ltx_td ltx_align_center ltx_th ltx_th_column">0.895</th>
<th id="S3.T2.3.5.4.4" class="ltx_td ltx_align_center ltx_th ltx_th_column">0.756</th>
<th id="S3.T2.3.5.4.5" class="ltx_td ltx_align_center ltx_th ltx_th_column">0.765</th>
</tr>
<tr id="S3.T2.3.6.5" class="ltx_tr">
<th id="S3.T2.3.6.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">PrivBayes</th>
<td id="S3.T2.3.6.5.2" class="ltx_td ltx_align_center">0.892</td>
<td id="S3.T2.3.6.5.3" class="ltx_td ltx_align_center">0.596</td>
<td id="S3.T2.3.6.5.4" class="ltx_td ltx_align_center">0.709</td>
<td id="S3.T2.3.6.5.5" class="ltx_td ltx_align_center">0.575</td>
</tr>
<tr id="S3.T2.3.7.6" class="ltx_tr">
<th id="S3.T2.3.7.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row">DP-GAN</th>
<th id="S3.T2.3.7.6.2" class="ltx_td ltx_align_center ltx_th ltx_th_column">0.733</th>
<th id="S3.T2.3.7.6.3" class="ltx_td ltx_align_center ltx_th ltx_th_column">0.929</th>
<th id="S3.T2.3.7.6.4" class="ltx_td ltx_align_center ltx_th ltx_th_column">0.585</th>
<th id="S3.T2.3.7.6.5" class="ltx_td ltx_align_center ltx_th ltx_th_column">0.855</th>
</tr>
<tr id="S3.T2.3.8.7" class="ltx_tr">
<th id="S3.T2.3.8.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">PATE-CTGAN</th>
<td id="S3.T2.3.8.7.2" class="ltx_td ltx_align_center">0.892</td>
<td id="S3.T2.3.8.7.3" class="ltx_td ltx_align_center">0.938</td>
<td id="S3.T2.3.8.7.4" class="ltx_td ltx_align_center">0.695</td>
<td id="S3.T2.3.8.7.5" class="ltx_td ltx_align_center">0.942</td>
</tr>
<tr id="S3.T2.3.9.8" class="ltx_tr">
<th id="S3.T2.3.9.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row">DP-CTGAN</th>
<th id="S3.T2.3.9.8.2" class="ltx_td ltx_align_center ltx_th ltx_th_column">0.889</th>
<th id="S3.T2.3.9.8.3" class="ltx_td ltx_align_center ltx_th ltx_th_column">0.999</th>
<th id="S3.T2.3.9.8.4" class="ltx_td ltx_align_center ltx_th ltx_th_column">0.693</th>
<th id="S3.T2.3.9.8.5" class="ltx_td ltx_align_center ltx_th ltx_th_column">0.999</th>
</tr>
<tr id="S3.T2.3.10.9" class="ltx_tr">
<th id="S3.T2.3.10.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">PATE-GAN</th>
<td id="S3.T2.3.10.9.2" class="ltx_td ltx_align_center">0.892</td>
<td id="S3.T2.3.10.9.3" class="ltx_td ltx_align_center">0.874</td>
<td id="S3.T2.3.10.9.4" class="ltx_td ltx_align_center">0.695</td>
<td id="S3.T2.3.10.9.5" class="ltx_td ltx_align_center">0.854</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span>Accuracy comparison for different groups. The comparison presented accounts for synthetic data generated with privacy-loss parameter <math id="S3.T2.2.m1.1" class="ltx_Math" alttext="\epsilon=5.0" display="inline"><semantics id="S3.T2.2.m1.1b"><mrow id="S3.T2.2.m1.1.1" xref="S3.T2.2.m1.1.1.cmml"><mi id="S3.T2.2.m1.1.1.2" xref="S3.T2.2.m1.1.1.2.cmml">Ïµ</mi><mo id="S3.T2.2.m1.1.1.1" xref="S3.T2.2.m1.1.1.1.cmml">=</mo><mn id="S3.T2.2.m1.1.1.3" xref="S3.T2.2.m1.1.1.3.cmml">5.0</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T2.2.m1.1c"><apply id="S3.T2.2.m1.1.1.cmml" xref="S3.T2.2.m1.1.1"><eq id="S3.T2.2.m1.1.1.1.cmml" xref="S3.T2.2.m1.1.1.1"></eq><ci id="S3.T2.2.m1.1.1.2.cmml" xref="S3.T2.2.m1.1.1.2">italic-Ïµ</ci><cn type="float" id="S3.T2.2.m1.1.1.3.cmml" xref="S3.T2.2.m1.1.1.3">5.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.2.m1.1d">\epsilon=5.0</annotation></semantics></math>. We show a comparison of model accuracy for the different groups measured with real data (R), and model accuracy measured with synthetic data (S).</figcaption>
</figure>
<div id="S3.SS2.SSS0.Px1.p2" class="ltx_para">
<p id="S3.SS2.SSS0.Px1.p2.1" class="ltx_p">From a fairness perspective, the overall behavior of all synthesizers is to have less accuracy decay for the protected class than it does for the privileged class. As observed on the utility experiments, MWEM PGM and MST are the best performing synthetic data sets for both pipeline tasks: training and evaluation. Although MWEM PGM presents good results for minority and privileged classes, where the model accuracy is very close to the baseline model - captured by accuracy minority(R) and accuracy privileged(R) in Table <a href="#S3.T2" title="Table 2 â€£ Impacts on subgroup accuracy â€£ 3.2 Fairness analysis of synthetic data in machine learning pipelines â€£ 3 Experimental Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. Additionally, evaluation with MWEM PGM synthetic data sets captured accuracy metric for both classes - captured by accuracy minority(S) and accuracy privileged(S) - that are very close to model evaluation done with real data.</p>
</div>
</section>
<section id="S3.SS2.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Impacts on statistical parity</h5>

<div id="S3.SS2.SSS0.Px2.p1" class="ltx_para">
<p id="S3.SS2.SSS0.Px2.p1.1" class="ltx_p">A model presents statistical parity if the percentage of positive predictions are the same for all subgroups. The goal of the experiments in this section is to measure whether models trained with synthetic data preserve the characteristics of models trained on real data.</p>
</div>
<div id="S3.SS2.SSS0.Px2.p2" class="ltx_para">
<p id="S3.SS2.SSS0.Px2.p2.1" class="ltx_p">Our experiments measure the difference in statistical parity (DSP) of models. We measure DSP of models using real data - DSP(R), and using synthetic data - DSP(S). We present a detailed comparison of DSP for all three data sets and all synthesizers on Table <a href="#S3.T3" title="Table 3 â€£ Impacts on statistical parity â€£ 3.2 Fairness analysis of synthetic data in machine learning pipelines â€£ 3 Experimental Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. We notice from our experiments that several models trained on synthetic data seem to be less biased than the model trained on real data. MWEM PGM synthesizer presented the best utility overall, based on the results present in the previous experiments. PATE-CTGAN, however, was ranked in 5th place in utility.</p>
</div>
<figure id="S3.T3" class="ltx_table">
<table id="S3.T3.3" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T3.3.1.1" class="ltx_tr">
<th id="S3.T3.3.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row"><span id="S3.T3.3.1.1.1.1" class="ltx_text ltx_font_smallcaps">Data</span></th>
<th id="S3.T3.3.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row"><span id="S3.T3.3.1.1.2.1" class="ltx_text ltx_font_smallcaps">Synthesizer</span></th>
<th id="S3.T3.3.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column">DSP(R)</th>
<th id="S3.T3.3.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column">DSP(S)</th>
<th id="S3.T3.3.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column">DSP delta</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T3.3.2.1" class="ltx_tr">
<th id="S3.T3.3.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt">Adult</th>
<th id="S3.T3.3.2.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt">MST</th>
<td id="S3.T3.3.2.1.3" class="ltx_td ltx_align_center ltx_border_tt">0.083</td>
<td id="S3.T3.3.2.1.4" class="ltx_td ltx_align_center ltx_border_tt">0.072</td>
<td id="S3.T3.3.2.1.5" class="ltx_td ltx_align_center ltx_border_tt">0.011</td>
</tr>
<tr id="S3.T3.3.3.2" class="ltx_tr">
<th id="S3.T3.3.3.2.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T3.3.3.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">MWEM PGM</th>
<td id="S3.T3.3.3.2.3" class="ltx_td ltx_align_center">0.168</td>
<td id="S3.T3.3.3.2.4" class="ltx_td ltx_align_center">0.159</td>
<td id="S3.T3.3.3.2.5" class="ltx_td ltx_align_center">0.009</td>
</tr>
<tr id="S3.T3.3.4.3" class="ltx_tr">
<th id="S3.T3.3.4.3.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T3.3.4.3.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">PrivBayes</th>
<td id="S3.T3.3.4.3.3" class="ltx_td ltx_align_center">0.051</td>
<td id="S3.T3.3.4.3.4" class="ltx_td ltx_align_center">0.035</td>
<td id="S3.T3.3.4.3.5" class="ltx_td ltx_align_center">0.016</td>
</tr>
<tr id="S3.T3.3.5.4" class="ltx_tr">
<th id="S3.T3.3.5.4.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T3.3.5.4.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">DP-CTGAN</th>
<td id="S3.T3.3.5.4.3" class="ltx_td ltx_align_center">-0.001</td>
<td id="S3.T3.3.5.4.4" class="ltx_td ltx_align_center">0.000</td>
<td id="S3.T3.3.5.4.5" class="ltx_td ltx_align_center">-0.001</td>
</tr>
<tr id="S3.T3.3.6.5" class="ltx_tr">
<th id="S3.T3.3.6.5.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T3.3.6.5.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">DP-GAN</th>
<td id="S3.T3.3.6.5.3" class="ltx_td ltx_align_center">0.346</td>
<td id="S3.T3.3.6.5.4" class="ltx_td ltx_align_center">0.253</td>
<td id="S3.T3.3.6.5.5" class="ltx_td ltx_align_center">-0.093</td>
</tr>
<tr id="S3.T3.3.7.6" class="ltx_tr">
<th id="S3.T3.3.7.6.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T3.3.7.6.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">PATE-CTGAN</th>
<td id="S3.T3.3.7.6.3" class="ltx_td ltx_align_center">0.000</td>
<td id="S3.T3.3.7.6.4" class="ltx_td ltx_align_center">0.000</td>
<td id="S3.T3.3.7.6.5" class="ltx_td ltx_align_center">0.000</td>
</tr>
<tr id="S3.T3.3.8.7" class="ltx_tr">
<th id="S3.T3.3.8.7.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T3.3.8.7.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">PATE-GAN</th>
<td id="S3.T3.3.8.7.3" class="ltx_td ltx_align_center">0.000</td>
<td id="S3.T3.3.8.7.4" class="ltx_td ltx_align_center">0.000</td>
<td id="S3.T3.3.8.7.5" class="ltx_td ltx_align_center">0.000</td>
</tr>
<tr id="S3.T3.3.9.8" class="ltx_tr">
<th id="S3.T3.3.9.8.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T3.3.9.8.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">Real</th>
<td id="S3.T3.3.9.8.3" class="ltx_td ltx_align_center"><span id="S3.T3.3.9.8.3.1" class="ltx_text ltx_font_bold">0.189</span></td>
<td id="S3.T3.3.9.8.4" class="ltx_td"></td>
<td id="S3.T3.3.9.8.5" class="ltx_td"></td>
</tr>
<tr id="S3.T3.3.10.9" class="ltx_tr">
<th id="S3.T3.3.10.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">COMPAS</th>
<th id="S3.T3.3.10.9.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">MST</th>
<td id="S3.T3.3.10.9.3" class="ltx_td ltx_align_center">-0.182</td>
<td id="S3.T3.3.10.9.4" class="ltx_td ltx_align_center">-0.101</td>
<td id="S3.T3.3.10.9.5" class="ltx_td ltx_align_center">-0.082</td>
</tr>
<tr id="S3.T3.3.11.10" class="ltx_tr">
<th id="S3.T3.3.11.10.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T3.3.11.10.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">MWEM PGM</th>
<td id="S3.T3.3.11.10.3" class="ltx_td ltx_align_center">-0.218</td>
<td id="S3.T3.3.11.10.4" class="ltx_td ltx_align_center">-0.190</td>
<td id="S3.T3.3.11.10.5" class="ltx_td ltx_align_center">-0.028</td>
</tr>
<tr id="S3.T3.3.12.11" class="ltx_tr">
<th id="S3.T3.3.12.11.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T3.3.12.11.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">PrivBaeys</th>
<td id="S3.T3.3.12.11.3" class="ltx_td ltx_align_center">-0.211</td>
<td id="S3.T3.3.12.11.4" class="ltx_td ltx_align_center">-0.166</td>
<td id="S3.T3.3.12.11.5" class="ltx_td ltx_align_center">-0.046</td>
</tr>
<tr id="S3.T3.3.13.12" class="ltx_tr">
<th id="S3.T3.3.13.12.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T3.3.13.12.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">DP-CTGAN</th>
<td id="S3.T3.3.13.12.3" class="ltx_td ltx_align_center">-0.034</td>
<td id="S3.T3.3.13.12.4" class="ltx_td ltx_align_center">0.001</td>
<td id="S3.T3.3.13.12.5" class="ltx_td ltx_align_center">-0.034</td>
</tr>
<tr id="S3.T3.3.14.13" class="ltx_tr">
<th id="S3.T3.3.14.13.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T3.3.14.13.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">DP-GAN</th>
<td id="S3.T3.3.14.13.3" class="ltx_td ltx_align_center">0.072</td>
<td id="S3.T3.3.14.13.4" class="ltx_td ltx_align_center">-0.089</td>
<td id="S3.T3.3.14.13.5" class="ltx_td ltx_align_center">0.161</td>
</tr>
<tr id="S3.T3.3.15.14" class="ltx_tr">
<th id="S3.T3.3.15.14.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T3.3.15.14.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">PATE-CTGAN</th>
<td id="S3.T3.3.15.14.3" class="ltx_td ltx_align_center">-0.008</td>
<td id="S3.T3.3.15.14.4" class="ltx_td ltx_align_center">-0.009</td>
<td id="S3.T3.3.15.14.5" class="ltx_td ltx_align_center">0.001</td>
</tr>
<tr id="S3.T3.3.16.15" class="ltx_tr">
<th id="S3.T3.3.16.15.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T3.3.16.15.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">PATE-GAN</th>
<td id="S3.T3.3.16.15.3" class="ltx_td ltx_align_center">0.000</td>
<td id="S3.T3.3.16.15.4" class="ltx_td ltx_align_center">-0.001</td>
<td id="S3.T3.3.16.15.5" class="ltx_td ltx_align_center">0.001</td>
</tr>
<tr id="S3.T3.3.17.16" class="ltx_tr">
<th id="S3.T3.3.17.16.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T3.3.17.16.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">Real</th>
<td id="S3.T3.3.17.16.3" class="ltx_td ltx_align_center"><span id="S3.T3.3.17.16.3.1" class="ltx_text ltx_font_bold">-0.205</span></td>
<td id="S3.T3.3.17.16.4" class="ltx_td"></td>
<td id="S3.T3.3.17.16.5" class="ltx_td"></td>
</tr>
<tr id="S3.T3.3.18.17" class="ltx_tr">
<th id="S3.T3.3.18.17.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">COMPAS</th>
<th id="S3.T3.3.18.17.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">MST</th>
<td id="S3.T3.3.18.17.3" class="ltx_td ltx_align_center">-0.185</td>
<td id="S3.T3.3.18.17.4" class="ltx_td ltx_align_center">-0.090</td>
<td id="S3.T3.3.18.17.5" class="ltx_td ltx_align_center">-0.095</td>
</tr>
<tr id="S3.T3.3.19.18" class="ltx_tr">
<th id="S3.T3.3.19.18.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">(fair)</th>
<th id="S3.T3.3.19.18.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">MWEM PGM</th>
<td id="S3.T3.3.19.18.3" class="ltx_td ltx_align_center">-0.018</td>
<td id="S3.T3.3.19.18.4" class="ltx_td ltx_align_center">0.015</td>
<td id="S3.T3.3.19.18.5" class="ltx_td ltx_align_center">-0.032</td>
</tr>
<tr id="S3.T3.3.20.19" class="ltx_tr">
<th id="S3.T3.3.20.19.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T3.3.20.19.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">PrivBayes</th>
<td id="S3.T3.3.20.19.3" class="ltx_td ltx_align_center">-0.065</td>
<td id="S3.T3.3.20.19.4" class="ltx_td ltx_align_center">0.037</td>
<td id="S3.T3.3.20.19.5" class="ltx_td ltx_align_center">-0.027</td>
</tr>
<tr id="S3.T3.3.21.20" class="ltx_tr">
<th id="S3.T3.3.21.20.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T3.3.21.20.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">DP-CTGAN</th>
<td id="S3.T3.3.21.20.3" class="ltx_td ltx_align_center">-0.034</td>
<td id="S3.T3.3.21.20.4" class="ltx_td ltx_align_center">-0.004</td>
<td id="S3.T3.3.21.20.5" class="ltx_td ltx_align_center">-0.030</td>
</tr>
<tr id="S3.T3.3.22.21" class="ltx_tr">
<th id="S3.T3.3.22.21.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T3.3.22.21.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">DP-GAN</th>
<td id="S3.T3.3.22.21.3" class="ltx_td ltx_align_center">0.066</td>
<td id="S3.T3.3.22.21.4" class="ltx_td ltx_align_center">0.096</td>
<td id="S3.T3.3.22.21.5" class="ltx_td ltx_align_center">-0.030</td>
</tr>
<tr id="S3.T3.3.23.22" class="ltx_tr">
<th id="S3.T3.3.23.22.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T3.3.23.22.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">PATE-CTGAN</th>
<td id="S3.T3.3.23.22.3" class="ltx_td ltx_align_center">0.000</td>
<td id="S3.T3.3.23.22.4" class="ltx_td ltx_align_center">0.000</td>
<td id="S3.T3.3.23.22.5" class="ltx_td ltx_align_center">0.000</td>
</tr>
<tr id="S3.T3.3.24.23" class="ltx_tr">
<th id="S3.T3.3.24.23.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T3.3.24.23.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">PATE-GAN</th>
<td id="S3.T3.3.24.23.3" class="ltx_td ltx_align_center">0.000</td>
<td id="S3.T3.3.24.23.4" class="ltx_td ltx_align_center">0.000</td>
<td id="S3.T3.3.24.23.5" class="ltx_td ltx_align_center">0.000</td>
</tr>
<tr id="S3.T3.3.25.24" class="ltx_tr">
<th id="S3.T3.3.25.24.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T3.3.25.24.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">Real</th>
<td id="S3.T3.3.25.24.3" class="ltx_td ltx_align_center"><span id="S3.T3.3.25.24.3.1" class="ltx_text ltx_font_bold">-0.025</span></td>
<td id="S3.T3.3.25.24.4" class="ltx_td"></td>
<td id="S3.T3.3.25.24.5" class="ltx_td"></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Difference in statistical parity (DSP) of models trained with synthetic data. We measure the DSP of models using real test data - DSP(R) and synthetic test data DSP(S). DEO delta quantifies the difference between DSP(R) and DSP(S). All synthetic data where generated using privacy-loss parameter <math id="S3.T3.2.m1.1" class="ltx_Math" alttext="\epsilon=5.0" display="inline"><semantics id="S3.T3.2.m1.1b"><mrow id="S3.T3.2.m1.1.1" xref="S3.T3.2.m1.1.1.cmml"><mi id="S3.T3.2.m1.1.1.2" xref="S3.T3.2.m1.1.1.2.cmml">Ïµ</mi><mo id="S3.T3.2.m1.1.1.1" xref="S3.T3.2.m1.1.1.1.cmml">=</mo><mn id="S3.T3.2.m1.1.1.3" xref="S3.T3.2.m1.1.1.3.cmml">5.0</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T3.2.m1.1c"><apply id="S3.T3.2.m1.1.1.cmml" xref="S3.T3.2.m1.1.1"><eq id="S3.T3.2.m1.1.1.1.cmml" xref="S3.T3.2.m1.1.1.1"></eq><ci id="S3.T3.2.m1.1.1.2.cmml" xref="S3.T3.2.m1.1.1.2">italic-Ïµ</ci><cn type="float" id="S3.T3.2.m1.1.1.3.cmml" xref="S3.T3.2.m1.1.1.3">5.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.2.m1.1d">\epsilon=5.0</annotation></semantics></math>.</figcaption>
</figure>
<div id="S3.SS2.SSS0.Px2.p3" class="ltx_para">
<p id="S3.SS2.SSS0.Px2.p3.1" class="ltx_p">To understand better what is behind this apparent fairness provided by PAET-CTGAN, we investigate the percentage of positive labelled samples in the training data, evaluation data and predictions. We present percentages for minority and privileged classes for adult data in Table <a href="#S3.T4" title="Table 4 â€£ Impacts on statistical parity â€£ 3.2 Fairness analysis of synthetic data in machine learning pipelines â€£ 3 Experimental Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
<figure id="S3.T4" class="ltx_table">
<table id="S3.T4.11" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T4.11.12.1" class="ltx_tr">
<th id="S3.T4.11.12.1.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T4.11.12.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column" colspan="6"><span id="S3.T4.11.12.1.2.1" class="ltx_text ltx_font_smallcaps">Ratio of positive labels - Adult data</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T4.11.13.1" class="ltx_tr">
<th id="S3.T4.11.13.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T4.11.13.1.1.1" class="ltx_text ltx_font_smallcaps">Generation</span></th>
<td id="S3.T4.11.13.1.2" class="ltx_td ltx_align_center" colspan="2"><span id="S3.T4.11.13.1.2.1" class="ltx_text ltx_font_smallcaps">Generated data</span></td>
<td id="S3.T4.11.13.1.3" class="ltx_td ltx_align_center" colspan="2"><span id="S3.T4.11.13.1.3.1" class="ltx_text ltx_font_smallcaps">Predictions(R)</span></td>
<td id="S3.T4.11.13.1.4" class="ltx_td ltx_align_center" colspan="2"><span id="S3.T4.11.13.1.4.1" class="ltx_text ltx_font_smallcaps">Predictions(S)</span></td>
</tr>
<tr id="S3.T4.11.14.2" class="ltx_tr">
<th id="S3.T4.11.14.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T4.11.14.2.1.1" class="ltx_text ltx_font_smallcaps">algorithm</span></th>
<td id="S3.T4.11.14.2.2" class="ltx_td ltx_align_center"><span id="S3.T4.11.14.2.2.1" class="ltx_text ltx_font_smallcaps">Female</span></td>
<td id="S3.T4.11.14.2.3" class="ltx_td ltx_align_center"><span id="S3.T4.11.14.2.3.1" class="ltx_text ltx_font_smallcaps">Male</span></td>
<td id="S3.T4.11.14.2.4" class="ltx_td ltx_align_center"><span id="S3.T4.11.14.2.4.1" class="ltx_text ltx_font_smallcaps">Female</span></td>
<td id="S3.T4.11.14.2.5" class="ltx_td ltx_align_center"><span id="S3.T4.11.14.2.5.1" class="ltx_text ltx_font_smallcaps">Male</span></td>
<td id="S3.T4.11.14.2.6" class="ltx_td ltx_align_center"><span id="S3.T4.11.14.2.6.1" class="ltx_text ltx_font_smallcaps">Female</span></td>
<td id="S3.T4.11.14.2.7" class="ltx_td ltx_align_center"><span id="S3.T4.11.14.2.7.1" class="ltx_text ltx_font_smallcaps">Male</span></td>
</tr>
<tr id="S3.T4.11.15.3" class="ltx_tr">
<th id="S3.T4.11.15.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt">Real</th>
<td id="S3.T4.11.15.3.2" class="ltx_td ltx_align_center ltx_border_tt">0.109</td>
<td id="S3.T4.11.15.3.3" class="ltx_td ltx_align_center ltx_border_tt">0.303</td>
<td id="S3.T4.11.15.3.4" class="ltx_td ltx_align_center ltx_border_tt">0.055</td>
<td id="S3.T4.11.15.3.5" class="ltx_td ltx_align_center ltx_border_tt">0.244</td>
<td id="S3.T4.11.15.3.6" class="ltx_td ltx_border_tt"></td>
<td id="S3.T4.11.15.3.7" class="ltx_td ltx_border_tt"></td>
</tr>
<tr id="S3.T4.11.16.4" class="ltx_tr">
<th id="S3.T4.11.16.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">MWEM PGM</th>
<td id="S3.T4.11.16.4.2" class="ltx_td ltx_align_center">0.120</td>
<td id="S3.T4.11.16.4.3" class="ltx_td ltx_align_center">0.307</td>
<td id="S3.T4.11.16.4.4" class="ltx_td ltx_align_center">0.042</td>
<td id="S3.T4.11.16.4.5" class="ltx_td ltx_align_center">0.209</td>
<td id="S3.T4.11.16.4.6" class="ltx_td ltx_align_center">0.043</td>
<td id="S3.T4.11.16.4.7" class="ltx_td ltx_align_center">0.202</td>
</tr>
<tr id="S3.T4.11.17.5" class="ltx_tr">
<th id="S3.T4.11.17.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">MST</th>
<td id="S3.T4.11.17.5.2" class="ltx_td ltx_align_center">0.123</td>
<td id="S3.T4.11.17.5.3" class="ltx_td ltx_align_center">0.297</td>
<td id="S3.T4.11.17.5.4" class="ltx_td ltx_align_center">0.032</td>
<td id="S3.T4.11.17.5.5" class="ltx_td ltx_align_center">0.115</td>
<td id="S3.T4.11.17.5.6" class="ltx_td ltx_align_center">0.031</td>
<td id="S3.T4.11.17.5.7" class="ltx_td ltx_align_center">0.102</td>
</tr>
<tr id="S3.T4.11.18.6" class="ltx_tr">
<th id="S3.T4.11.18.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">PrivBayes</th>
<td id="S3.T4.11.18.6.2" class="ltx_td ltx_align_center">0.265</td>
<td id="S3.T4.11.18.6.3" class="ltx_td ltx_align_center">0.342</td>
<td id="S3.T4.11.18.6.4" class="ltx_td ltx_align_center">0.004</td>
<td id="S3.T4.11.18.6.5" class="ltx_td ltx_align_center">0.055</td>
<td id="S3.T4.11.18.6.6" class="ltx_td ltx_align_center">0.056</td>
<td id="S3.T4.11.18.6.7" class="ltx_td ltx_align_center">0.091</td>
</tr>
<tr id="S3.T4.4.4" class="ltx_tr">
<th id="S3.T4.4.4.5" class="ltx_td ltx_align_left ltx_th ltx_th_row">PATE-GAN</th>
<td id="S3.T4.4.4.6" class="ltx_td ltx_align_center">0.125</td>
<td id="S3.T4.4.4.7" class="ltx_td ltx_align_center">0.144</td>
<td id="S3.T4.1.1.1" class="ltx_td ltx_align_center">
<math id="S3.T4.1.1.1.m1.1" class="ltx_Math" alttext="\approx" display="inline"><semantics id="S3.T4.1.1.1.m1.1a"><mo id="S3.T4.1.1.1.m1.1.1" xref="S3.T4.1.1.1.m1.1.1.cmml">â‰ˆ</mo><annotation-xml encoding="MathML-Content" id="S3.T4.1.1.1.m1.1b"><approx id="S3.T4.1.1.1.m1.1.1.cmml" xref="S3.T4.1.1.1.m1.1.1"></approx></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.1.1.1.m1.1c">\approx</annotation></semantics></math> 0</td>
<td id="S3.T4.2.2.2" class="ltx_td ltx_align_center">
<math id="S3.T4.2.2.2.m1.1" class="ltx_Math" alttext="\approx" display="inline"><semantics id="S3.T4.2.2.2.m1.1a"><mo id="S3.T4.2.2.2.m1.1.1" xref="S3.T4.2.2.2.m1.1.1.cmml">â‰ˆ</mo><annotation-xml encoding="MathML-Content" id="S3.T4.2.2.2.m1.1b"><approx id="S3.T4.2.2.2.m1.1.1.cmml" xref="S3.T4.2.2.2.m1.1.1"></approx></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.2.2.2.m1.1c">\approx</annotation></semantics></math> 0</td>
<td id="S3.T4.3.3.3" class="ltx_td ltx_align_center">
<math id="S3.T4.3.3.3.m1.1" class="ltx_Math" alttext="\approx" display="inline"><semantics id="S3.T4.3.3.3.m1.1a"><mo id="S3.T4.3.3.3.m1.1.1" xref="S3.T4.3.3.3.m1.1.1.cmml">â‰ˆ</mo><annotation-xml encoding="MathML-Content" id="S3.T4.3.3.3.m1.1b"><approx id="S3.T4.3.3.3.m1.1.1.cmml" xref="S3.T4.3.3.3.m1.1.1"></approx></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.3.3.3.m1.1c">\approx</annotation></semantics></math> 0</td>
<td id="S3.T4.4.4.4" class="ltx_td ltx_align_center">
<math id="S3.T4.4.4.4.m1.1" class="ltx_Math" alttext="\approx" display="inline"><semantics id="S3.T4.4.4.4.m1.1a"><mo id="S3.T4.4.4.4.m1.1.1" xref="S3.T4.4.4.4.m1.1.1.cmml">â‰ˆ</mo><annotation-xml encoding="MathML-Content" id="S3.T4.4.4.4.m1.1b"><approx id="S3.T4.4.4.4.m1.1.1.cmml" xref="S3.T4.4.4.4.m1.1.1"></approx></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.4.4.4.m1.1c">\approx</annotation></semantics></math> 0</td>
</tr>
<tr id="S3.T4.8.8" class="ltx_tr">
<th id="S3.T4.8.8.5" class="ltx_td ltx_align_left ltx_th ltx_th_row">PATE-CTGAN</th>
<td id="S3.T4.8.8.6" class="ltx_td ltx_align_center">0.056</td>
<td id="S3.T4.8.8.7" class="ltx_td ltx_align_center">0.058</td>
<td id="S3.T4.5.5.1" class="ltx_td ltx_align_center">
<math id="S3.T4.5.5.1.m1.1" class="ltx_Math" alttext="\approx" display="inline"><semantics id="S3.T4.5.5.1.m1.1a"><mo id="S3.T4.5.5.1.m1.1.1" xref="S3.T4.5.5.1.m1.1.1.cmml">â‰ˆ</mo><annotation-xml encoding="MathML-Content" id="S3.T4.5.5.1.m1.1b"><approx id="S3.T4.5.5.1.m1.1.1.cmml" xref="S3.T4.5.5.1.m1.1.1"></approx></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.5.5.1.m1.1c">\approx</annotation></semantics></math> 0</td>
<td id="S3.T4.6.6.2" class="ltx_td ltx_align_center">
<math id="S3.T4.6.6.2.m1.1" class="ltx_Math" alttext="\approx" display="inline"><semantics id="S3.T4.6.6.2.m1.1a"><mo id="S3.T4.6.6.2.m1.1.1" xref="S3.T4.6.6.2.m1.1.1.cmml">â‰ˆ</mo><annotation-xml encoding="MathML-Content" id="S3.T4.6.6.2.m1.1b"><approx id="S3.T4.6.6.2.m1.1.1.cmml" xref="S3.T4.6.6.2.m1.1.1"></approx></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.6.6.2.m1.1c">\approx</annotation></semantics></math> 0</td>
<td id="S3.T4.7.7.3" class="ltx_td ltx_align_center">
<math id="S3.T4.7.7.3.m1.1" class="ltx_Math" alttext="\approx" display="inline"><semantics id="S3.T4.7.7.3.m1.1a"><mo id="S3.T4.7.7.3.m1.1.1" xref="S3.T4.7.7.3.m1.1.1.cmml">â‰ˆ</mo><annotation-xml encoding="MathML-Content" id="S3.T4.7.7.3.m1.1b"><approx id="S3.T4.7.7.3.m1.1.1.cmml" xref="S3.T4.7.7.3.m1.1.1"></approx></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.7.7.3.m1.1c">\approx</annotation></semantics></math> 0</td>
<td id="S3.T4.8.8.4" class="ltx_td ltx_align_center">
<math id="S3.T4.8.8.4.m1.1" class="ltx_Math" alttext="\approx" display="inline"><semantics id="S3.T4.8.8.4.m1.1a"><mo id="S3.T4.8.8.4.m1.1.1" xref="S3.T4.8.8.4.m1.1.1.cmml">â‰ˆ</mo><annotation-xml encoding="MathML-Content" id="S3.T4.8.8.4.m1.1b"><approx id="S3.T4.8.8.4.m1.1.1.cmml" xref="S3.T4.8.8.4.m1.1.1"></approx></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.8.8.4.m1.1c">\approx</annotation></semantics></math> 0</td>
</tr>
<tr id="S3.T4.11.19.7" class="ltx_tr">
<th id="S3.T4.11.19.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">DP-GAN</th>
<td id="S3.T4.11.19.7.2" class="ltx_td ltx_align_center">0.061</td>
<td id="S3.T4.11.19.7.3" class="ltx_td ltx_align_center">0.307</td>
<td id="S3.T4.11.19.7.4" class="ltx_td ltx_align_center">0.199</td>
<td id="S3.T4.11.19.7.5" class="ltx_td ltx_align_center">0.545</td>
<td id="S3.T4.11.19.7.6" class="ltx_td ltx_align_center">0.016</td>
<td id="S3.T4.11.19.7.7" class="ltx_td ltx_align_center">0.269</td>
</tr>
<tr id="S3.T4.11.11" class="ltx_tr">
<th id="S3.T4.11.11.4" class="ltx_td ltx_align_left ltx_th ltx_th_row">DP-CTGAN</th>
<td id="S3.T4.9.9.1" class="ltx_td ltx_align_center">
<math id="S3.T4.9.9.1.m1.1" class="ltx_Math" alttext="\approx" display="inline"><semantics id="S3.T4.9.9.1.m1.1a"><mo id="S3.T4.9.9.1.m1.1.1" xref="S3.T4.9.9.1.m1.1.1.cmml">â‰ˆ</mo><annotation-xml encoding="MathML-Content" id="S3.T4.9.9.1.m1.1b"><approx id="S3.T4.9.9.1.m1.1.1.cmml" xref="S3.T4.9.9.1.m1.1.1"></approx></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.9.9.1.m1.1c">\approx</annotation></semantics></math> 0</td>
<td id="S3.T4.11.11.5" class="ltx_td ltx_align_center">0.002</td>
<td id="S3.T4.11.11.6" class="ltx_td ltx_align_center">0.227</td>
<td id="S3.T4.11.11.7" class="ltx_td ltx_align_center">0.130</td>
<td id="S3.T4.10.10.2" class="ltx_td ltx_align_center">
<math id="S3.T4.10.10.2.m1.1" class="ltx_Math" alttext="\approx" display="inline"><semantics id="S3.T4.10.10.2.m1.1a"><mo id="S3.T4.10.10.2.m1.1.1" xref="S3.T4.10.10.2.m1.1.1.cmml">â‰ˆ</mo><annotation-xml encoding="MathML-Content" id="S3.T4.10.10.2.m1.1b"><approx id="S3.T4.10.10.2.m1.1.1.cmml" xref="S3.T4.10.10.2.m1.1.1"></approx></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.10.10.2.m1.1c">\approx</annotation></semantics></math> 0</td>
<td id="S3.T4.11.11.3" class="ltx_td ltx_align_center">
<math id="S3.T4.11.11.3.m1.1" class="ltx_Math" alttext="\approx" display="inline"><semantics id="S3.T4.11.11.3.m1.1a"><mo id="S3.T4.11.11.3.m1.1.1" xref="S3.T4.11.11.3.m1.1.1.cmml">â‰ˆ</mo><annotation-xml encoding="MathML-Content" id="S3.T4.11.11.3.m1.1b"><approx id="S3.T4.11.11.3.m1.1.1.cmml" xref="S3.T4.11.11.3.m1.1.1"></approx></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.11.11.3.m1.1c">\approx</annotation></semantics></math> 0</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 4: </span>Ratio of samples with positive labels for each subgroup in the protect class in the Adult data. We compare percentages present in the true labels of the real data and the predicted labels. Analogously, we measure the percentage of samples with positive present in the training, testing and predicted labels for data sets generated from three distinct synthesizer techniques: MWEM PGM, PATE-CTGAN and DP-GAN. Predictions(data1/data2) represents prediction labels of an experiment where model was trained with data1, and predictions were performed on data2.</figcaption>
</figure>
<div id="S3.SS2.SSS0.Px2.p4" class="ltx_para">
<p id="S3.SS2.SSS0.Px2.p4.2" class="ltx_p">We observe in Table <a href="#S3.T4" title="Table 4 â€£ Impacts on statistical parity â€£ 3.2 Fairness analysis of synthetic data in machine learning pipelines â€£ 3 Experimental Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> that synthetic data generated with PATE-CTGAN presents a very similar percentages of samples with positive labels, of <math id="S3.SS2.SSS0.Px2.p4.1.m1.1" class="ltx_Math" alttext="\approx 5\%" display="inline"><semantics id="S3.SS2.SSS0.Px2.p4.1.m1.1a"><mrow id="S3.SS2.SSS0.Px2.p4.1.m1.1.1" xref="S3.SS2.SSS0.Px2.p4.1.m1.1.1.cmml"><mi id="S3.SS2.SSS0.Px2.p4.1.m1.1.1.2" xref="S3.SS2.SSS0.Px2.p4.1.m1.1.1.2.cmml"></mi><mo id="S3.SS2.SSS0.Px2.p4.1.m1.1.1.1" xref="S3.SS2.SSS0.Px2.p4.1.m1.1.1.1.cmml">â‰ˆ</mo><mrow id="S3.SS2.SSS0.Px2.p4.1.m1.1.1.3" xref="S3.SS2.SSS0.Px2.p4.1.m1.1.1.3.cmml"><mn id="S3.SS2.SSS0.Px2.p4.1.m1.1.1.3.2" xref="S3.SS2.SSS0.Px2.p4.1.m1.1.1.3.2.cmml">5</mn><mo id="S3.SS2.SSS0.Px2.p4.1.m1.1.1.3.1" xref="S3.SS2.SSS0.Px2.p4.1.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p4.1.m1.1b"><apply id="S3.SS2.SSS0.Px2.p4.1.m1.1.1.cmml" xref="S3.SS2.SSS0.Px2.p4.1.m1.1.1"><approx id="S3.SS2.SSS0.Px2.p4.1.m1.1.1.1.cmml" xref="S3.SS2.SSS0.Px2.p4.1.m1.1.1.1"></approx><csymbol cd="latexml" id="S3.SS2.SSS0.Px2.p4.1.m1.1.1.2.cmml" xref="S3.SS2.SSS0.Px2.p4.1.m1.1.1.2">absent</csymbol><apply id="S3.SS2.SSS0.Px2.p4.1.m1.1.1.3.cmml" xref="S3.SS2.SSS0.Px2.p4.1.m1.1.1.3"><csymbol cd="latexml" id="S3.SS2.SSS0.Px2.p4.1.m1.1.1.3.1.cmml" xref="S3.SS2.SSS0.Px2.p4.1.m1.1.1.3.1">percent</csymbol><cn type="integer" id="S3.SS2.SSS0.Px2.p4.1.m1.1.1.3.2.cmml" xref="S3.SS2.SSS0.Px2.p4.1.m1.1.1.3.2">5</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p4.1.m1.1c">\approx 5\%</annotation></semantics></math> for each group that belongs to the protected attribute. At a first sight, this seems like a data set with promising fairness capabilities. However, when training models with such data, there are no positive predictions resulting from the model scoring. The model trained with PATE-CTGAN data acts like a majority baseline classifier for all groups. The data sets generated with DP-CTGAN presented an accentuated disparity in positive labels percentages between minority and privileged classes. In the real data 30% of privileged class contains positive labels, while only 10% of minority class contains positive labels. Although DP-GAN synthesizer generates data where 31% of privileged class with positive labels (a value similar to the one presented in the real data - 30%), there is a significant decrease in the percentage of positive class in the minority class, which is <math id="S3.SS2.SSS0.Px2.p4.2.m2.1" class="ltx_Math" alttext="\approx 6\%" display="inline"><semantics id="S3.SS2.SSS0.Px2.p4.2.m2.1a"><mrow id="S3.SS2.SSS0.Px2.p4.2.m2.1.1" xref="S3.SS2.SSS0.Px2.p4.2.m2.1.1.cmml"><mi id="S3.SS2.SSS0.Px2.p4.2.m2.1.1.2" xref="S3.SS2.SSS0.Px2.p4.2.m2.1.1.2.cmml"></mi><mo id="S3.SS2.SSS0.Px2.p4.2.m2.1.1.1" xref="S3.SS2.SSS0.Px2.p4.2.m2.1.1.1.cmml">â‰ˆ</mo><mrow id="S3.SS2.SSS0.Px2.p4.2.m2.1.1.3" xref="S3.SS2.SSS0.Px2.p4.2.m2.1.1.3.cmml"><mn id="S3.SS2.SSS0.Px2.p4.2.m2.1.1.3.2" xref="S3.SS2.SSS0.Px2.p4.2.m2.1.1.3.2.cmml">6</mn><mo id="S3.SS2.SSS0.Px2.p4.2.m2.1.1.3.1" xref="S3.SS2.SSS0.Px2.p4.2.m2.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p4.2.m2.1b"><apply id="S3.SS2.SSS0.Px2.p4.2.m2.1.1.cmml" xref="S3.SS2.SSS0.Px2.p4.2.m2.1.1"><approx id="S3.SS2.SSS0.Px2.p4.2.m2.1.1.1.cmml" xref="S3.SS2.SSS0.Px2.p4.2.m2.1.1.1"></approx><csymbol cd="latexml" id="S3.SS2.SSS0.Px2.p4.2.m2.1.1.2.cmml" xref="S3.SS2.SSS0.Px2.p4.2.m2.1.1.2">absent</csymbol><apply id="S3.SS2.SSS0.Px2.p4.2.m2.1.1.3.cmml" xref="S3.SS2.SSS0.Px2.p4.2.m2.1.1.3"><csymbol cd="latexml" id="S3.SS2.SSS0.Px2.p4.2.m2.1.1.3.1.cmml" xref="S3.SS2.SSS0.Px2.p4.2.m2.1.1.3.1">percent</csymbol><cn type="integer" id="S3.SS2.SSS0.Px2.p4.2.m2.1.1.3.2.cmml" xref="S3.SS2.SSS0.Px2.p4.2.m2.1.1.3.2">6</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p4.2.m2.1c">\approx 6\%</annotation></semantics></math>. This imbalance is even further accentuated by the models trained with DP-GAN synthetic data. Model predictions resulted in over half of samples from the privileged class being classified with positive labels (versus 20% of minority class).</p>
</div>
<div id="S3.SS2.SSS0.Px2.p5" class="ltx_para">
<p id="S3.SS2.SSS0.Px2.p5.1" class="ltx_p">MWEM PGM once again was the best overall performing model, as it preserves similar percentages of positive labels for all groups, 11% and 30% (compared to 11% and 30% in real data). Models trained with MWEM PGM also presented similar metric to models trained with real data, and even presenting slightly improvement in fairness.</p>
</div>
<div id="S3.SS2.SSS0.Px2.p6" class="ltx_para">
<p id="S3.SS2.SSS0.Px2.p6.1" class="ltx_p">The DSP delta presented in Table <a href="#S3.T3" title="Table 3 â€£ Impacts on statistical parity â€£ 3.2 Fairness analysis of synthetic data in machine learning pipelines â€£ 3 Experimental Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> quantifies the difference in DSP observed during model evalution with real data and model evaluation with synthetic data. For Adult data set, a positive DSP delta means that evaluation with synthetic data observed fairer
results than evaluation with real data. For COMPAS and fair COMPAS data, a negative DSP delta means that evaluation with synthetic data observed fairer
results than evaluation with real data.</p>
</div>
<div id="S3.SS2.SSS0.Px2.p7" class="ltx_para">
<p id="S3.SS2.SSS0.Px2.p7.1" class="ltx_p">Across all data sets, models trained with MWEM PGM presented DSP metrics very similar to models trained with real data, this is captured by the DSP(R) metric.</p>
</div>
</section>
<section id="S3.SS2.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Impacts on equal opportunity</h5>

<div id="S3.SS2.SSS0.Px3.p1" class="ltx_para">
<p id="S3.SS2.SSS0.Px3.p1.1" class="ltx_p">Equal Opportunity requires equal True Positive Rate
(TPR) across subgroups. Difference in equal opportunity (DEO) measures the difference of privileged group TPR and minority group TPR.</p>
</div>
<div id="S3.SS2.SSS0.Px3.p2" class="ltx_para">
<p id="S3.SS2.SSS0.Px3.p2.1" class="ltx_p">We perform a thorough analysis to understand two points.First, what is the DEO of models trained with synthetic data sets, and how does it compare with models trained with real data? Second, we investigate whether synthetic data preserves similar true positive rates across all subgroups.</p>
</div>
<div id="S3.SS2.SSS0.Px3.p3" class="ltx_para">
<p id="S3.SS2.SSS0.Px3.p3.1" class="ltx_p">We present in Table <a href="#S3.T5" title="Table 5 â€£ Impacts on equal opportunity â€£ 3.2 Fairness analysis of synthetic data in machine learning pipelines â€£ 3 Experimental Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> experiment results comparing DEO of models trained with differentially private synthetic data sets (<math id="S3.SS2.SSS0.Px3.p3.1.m1.1" class="ltx_Math" alttext="\epsilon=5.0" display="inline"><semantics id="S3.SS2.SSS0.Px3.p3.1.m1.1a"><mrow id="S3.SS2.SSS0.Px3.p3.1.m1.1.1" xref="S3.SS2.SSS0.Px3.p3.1.m1.1.1.cmml"><mi id="S3.SS2.SSS0.Px3.p3.1.m1.1.1.2" xref="S3.SS2.SSS0.Px3.p3.1.m1.1.1.2.cmml">Ïµ</mi><mo id="S3.SS2.SSS0.Px3.p3.1.m1.1.1.1" xref="S3.SS2.SSS0.Px3.p3.1.m1.1.1.1.cmml">=</mo><mn id="S3.SS2.SSS0.Px3.p3.1.m1.1.1.3" xref="S3.SS2.SSS0.Px3.p3.1.m1.1.1.3.cmml">5.0</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px3.p3.1.m1.1b"><apply id="S3.SS2.SSS0.Px3.p3.1.m1.1.1.cmml" xref="S3.SS2.SSS0.Px3.p3.1.m1.1.1"><eq id="S3.SS2.SSS0.Px3.p3.1.m1.1.1.1.cmml" xref="S3.SS2.SSS0.Px3.p3.1.m1.1.1.1"></eq><ci id="S3.SS2.SSS0.Px3.p3.1.m1.1.1.2.cmml" xref="S3.SS2.SSS0.Px3.p3.1.m1.1.1.2">italic-Ïµ</ci><cn type="float" id="S3.SS2.SSS0.Px3.p3.1.m1.1.1.3.cmml" xref="S3.SS2.SSS0.Px3.p3.1.m1.1.1.3">5.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px3.p3.1.m1.1c">\epsilon=5.0</annotation></semantics></math>). These experiment are similar to the statistical parity experiments, we use real data - DEO(R) - to measure DEO of models trained on synthetic data, as well as synthetic data - DEO(S).</p>
</div>
<figure id="S3.T5" class="ltx_table">
<table id="S3.T5.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T5.1.2.1" class="ltx_tr">
<th id="S3.T5.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row"><span id="S3.T5.1.2.1.1.1" class="ltx_text ltx_font_smallcaps">Data</span></th>
<th id="S3.T5.1.2.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row"><span id="S3.T5.1.2.1.2.1" class="ltx_text ltx_font_smallcaps">Synthesizer</span></th>
<th id="S3.T5.1.2.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column">DEO (R)</th>
<th id="S3.T5.1.2.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column">DEO (S)</th>
<th id="S3.T5.1.2.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column">DEO Delta</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T5.1.3.1" class="ltx_tr">
<th id="S3.T5.1.3.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt">Adult</th>
<th id="S3.T5.1.3.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt">MST</th>
<td id="S3.T5.1.3.1.3" class="ltx_td ltx_align_center ltx_border_tt">0.038</td>
<td id="S3.T5.1.3.1.4" class="ltx_td ltx_align_center ltx_border_tt">0.076</td>
<td id="S3.T5.1.3.1.5" class="ltx_td ltx_align_center ltx_border_tt">-0.037</td>
</tr>
<tr id="S3.T5.1.4.2" class="ltx_tr">
<th id="S3.T5.1.4.2.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T5.1.4.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">MWEM PGM</th>
<td id="S3.T5.1.4.2.3" class="ltx_td ltx_align_center">0.206</td>
<td id="S3.T5.1.4.2.4" class="ltx_td ltx_align_center">0.200</td>
<td id="S3.T5.1.4.2.5" class="ltx_td ltx_align_center">0.006</td>
</tr>
<tr id="S3.T5.1.5.3" class="ltx_tr">
<th id="S3.T5.1.5.3.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T5.1.5.3.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">PrivBayes</th>
<td id="S3.T5.1.5.3.3" class="ltx_td ltx_align_center">0.094</td>
<td id="S3.T5.1.5.3.4" class="ltx_td ltx_align_center">0.030</td>
<td id="S3.T5.1.5.3.5" class="ltx_td ltx_align_center">0.063</td>
</tr>
<tr id="S3.T5.1.1" class="ltx_tr">
<th id="S3.T5.1.1.2" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T5.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_row">DP-CTGAN</th>
<td id="S3.T5.1.1.4" class="ltx_td ltx_align_center">-0.002</td>
<td id="S3.T5.1.1.1" class="ltx_td ltx_align_center">
<math id="S3.T5.1.1.1.m1.1" class="ltx_Math" alttext="\approx" display="inline"><semantics id="S3.T5.1.1.1.m1.1a"><mo id="S3.T5.1.1.1.m1.1.1" xref="S3.T5.1.1.1.m1.1.1.cmml">â‰ˆ</mo><annotation-xml encoding="MathML-Content" id="S3.T5.1.1.1.m1.1b"><approx id="S3.T5.1.1.1.m1.1.1.cmml" xref="S3.T5.1.1.1.m1.1.1"></approx></annotation-xml><annotation encoding="application/x-tex" id="S3.T5.1.1.1.m1.1c">\approx</annotation></semantics></math>0.00</td>
<td id="S3.T5.1.1.5" class="ltx_td ltx_align_center">-0.002</td>
</tr>
<tr id="S3.T5.1.6.4" class="ltx_tr">
<th id="S3.T5.1.6.4.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T5.1.6.4.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">DP-GAN</th>
<td id="S3.T5.1.6.4.3" class="ltx_td ltx_align_center">0.527</td>
<td id="S3.T5.1.6.4.4" class="ltx_td ltx_align_center">0.641</td>
<td id="S3.T5.1.6.4.5" class="ltx_td ltx_align_center">-0.116</td>
</tr>
<tr id="S3.T5.1.7.5" class="ltx_tr">
<th id="S3.T5.1.7.5.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T5.1.7.5.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">PATE-CTGAN</th>
<td id="S3.T5.1.7.5.3" class="ltx_td ltx_align_center">0.000</td>
<td id="S3.T5.1.7.5.4" class="ltx_td ltx_align_center">0.000</td>
<td id="S3.T5.1.7.5.5" class="ltx_td ltx_align_center">0.000</td>
</tr>
<tr id="S3.T5.1.8.6" class="ltx_tr">
<th id="S3.T5.1.8.6.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T5.1.8.6.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">PATE-GAN</th>
<td id="S3.T5.1.8.6.3" class="ltx_td ltx_align_center">0.000</td>
<td id="S3.T5.1.8.6.4" class="ltx_td ltx_align_center">0.000</td>
<td id="S3.T5.1.8.6.5" class="ltx_td ltx_align_center">0.000</td>
</tr>
<tr id="S3.T5.1.9.7" class="ltx_tr">
<th id="S3.T5.1.9.7.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T5.1.9.7.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">Real</th>
<td id="S3.T5.1.9.7.3" class="ltx_td ltx_align_center"><span id="S3.T5.1.9.7.3.1" class="ltx_text ltx_font_bold">0.173</span></td>
<td id="S3.T5.1.9.7.4" class="ltx_td"></td>
<td id="S3.T5.1.9.7.5" class="ltx_td"></td>
</tr>
<tr id="S3.T5.1.10.8" class="ltx_tr">
<th id="S3.T5.1.10.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">COMPAS</th>
<th id="S3.T5.1.10.8.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">MST</th>
<td id="S3.T5.1.10.8.3" class="ltx_td ltx_align_center">-0.150</td>
<td id="S3.T5.1.10.8.4" class="ltx_td ltx_align_center">-0.089</td>
<td id="S3.T5.1.10.8.5" class="ltx_td ltx_align_center">-0.061</td>
</tr>
<tr id="S3.T5.1.11.9" class="ltx_tr">
<th id="S3.T5.1.11.9.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T5.1.11.9.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">MWEM PGM</th>
<td id="S3.T5.1.11.9.3" class="ltx_td ltx_align_center">-0.215</td>
<td id="S3.T5.1.11.9.4" class="ltx_td ltx_align_center">-0.224</td>
<td id="S3.T5.1.11.9.5" class="ltx_td ltx_align_center">0.009</td>
</tr>
<tr id="S3.T5.1.12.10" class="ltx_tr">
<th id="S3.T5.1.12.10.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T5.1.12.10.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">PrivBayes</th>
<td id="S3.T5.1.12.10.3" class="ltx_td ltx_align_center">-0.177</td>
<td id="S3.T5.1.12.10.4" class="ltx_td ltx_align_center">-0.158</td>
<td id="S3.T5.1.12.10.5" class="ltx_td ltx_align_center">-0.020</td>
</tr>
<tr id="S3.T5.1.13.11" class="ltx_tr">
<th id="S3.T5.1.13.11.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T5.1.13.11.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">DP-CTGAN</th>
<td id="S3.T5.1.13.11.3" class="ltx_td ltx_align_center">-0.031</td>
<td id="S3.T5.1.13.11.4" class="ltx_td ltx_align_center">-0.000</td>
<td id="S3.T5.1.13.11.5" class="ltx_td ltx_align_center">-0.031</td>
</tr>
<tr id="S3.T5.1.14.12" class="ltx_tr">
<th id="S3.T5.1.14.12.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T5.1.14.12.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">DP-GAN</th>
<td id="S3.T5.1.14.12.3" class="ltx_td ltx_align_center">-0.075</td>
<td id="S3.T5.1.14.12.4" class="ltx_td ltx_align_center">0.020</td>
<td id="S3.T5.1.14.12.5" class="ltx_td ltx_align_center">0.055</td>
</tr>
<tr id="S3.T5.1.15.13" class="ltx_tr">
<th id="S3.T5.1.15.13.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T5.1.15.13.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">PATE-CTGAN</th>
<td id="S3.T5.1.15.13.3" class="ltx_td ltx_align_center">-0.011</td>
<td id="S3.T5.1.15.13.4" class="ltx_td ltx_align_center">-0.009</td>
<td id="S3.T5.1.15.13.5" class="ltx_td ltx_align_center">-0.002</td>
</tr>
<tr id="S3.T5.1.16.14" class="ltx_tr">
<th id="S3.T5.1.16.14.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T5.1.16.14.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">PATE-GAN</th>
<td id="S3.T5.1.16.14.3" class="ltx_td ltx_align_center">0.000</td>
<td id="S3.T5.1.16.14.4" class="ltx_td ltx_align_center">-0.001</td>
<td id="S3.T5.1.16.14.5" class="ltx_td ltx_align_center">0.001</td>
</tr>
<tr id="S3.T5.1.17.15" class="ltx_tr">
<th id="S3.T5.1.17.15.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T5.1.17.15.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">Real</th>
<td id="S3.T5.1.17.15.3" class="ltx_td ltx_align_center"><span id="S3.T5.1.17.15.3.1" class="ltx_text ltx_font_bold">-0.204</span></td>
<td id="S3.T5.1.17.15.4" class="ltx_td"></td>
<td id="S3.T5.1.17.15.5" class="ltx_td"></td>
</tr>
<tr id="S3.T5.1.18.16" class="ltx_tr">
<th id="S3.T5.1.18.16.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">COMPAS</th>
<th id="S3.T5.1.18.16.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">MST</th>
<td id="S3.T5.1.18.16.3" class="ltx_td ltx_align_center">-0.181</td>
<td id="S3.T5.1.18.16.4" class="ltx_td ltx_align_center">-0.073</td>
<td id="S3.T5.1.18.16.5" class="ltx_td ltx_align_center">-0.107</td>
</tr>
<tr id="S3.T5.1.19.17" class="ltx_tr">
<th id="S3.T5.1.19.17.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">(fair)</th>
<th id="S3.T5.1.19.17.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">MWEM PGM</th>
<td id="S3.T5.1.19.17.3" class="ltx_td ltx_align_center">-0.019</td>
<td id="S3.T5.1.19.17.4" class="ltx_td ltx_align_center">0.037</td>
<td id="S3.T5.1.19.17.5" class="ltx_td ltx_align_center">-0.056</td>
</tr>
<tr id="S3.T5.1.20.18" class="ltx_tr">
<th id="S3.T5.1.20.18.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T5.1.20.18.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">PrivBayes</th>
<td id="S3.T5.1.20.18.3" class="ltx_td ltx_align_center">-0.057</td>
<td id="S3.T5.1.20.18.4" class="ltx_td ltx_align_center">0.003</td>
<td id="S3.T5.1.20.18.5" class="ltx_td ltx_align_center">-0.054</td>
</tr>
<tr id="S3.T5.1.21.19" class="ltx_tr">
<th id="S3.T5.1.21.19.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T5.1.21.19.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">DP-CTGAN</th>
<td id="S3.T5.1.21.19.3" class="ltx_td ltx_align_center">-0.030</td>
<td id="S3.T5.1.21.19.4" class="ltx_td ltx_align_center">-0.005</td>
<td id="S3.T5.1.21.19.5" class="ltx_td ltx_align_center">-0.026</td>
</tr>
<tr id="S3.T5.1.22.20" class="ltx_tr">
<th id="S3.T5.1.22.20.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T5.1.22.20.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">DP-GAN</th>
<td id="S3.T5.1.22.20.3" class="ltx_td ltx_align_center">0.097</td>
<td id="S3.T5.1.22.20.4" class="ltx_td ltx_align_center">0.087</td>
<td id="S3.T5.1.22.20.5" class="ltx_td ltx_align_center">0.010</td>
</tr>
<tr id="S3.T5.1.23.21" class="ltx_tr">
<th id="S3.T5.1.23.21.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T5.1.23.21.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">PATE-CTGAN</th>
<td id="S3.T5.1.23.21.3" class="ltx_td ltx_align_center">0.000</td>
<td id="S3.T5.1.23.21.4" class="ltx_td ltx_align_center">0.000</td>
<td id="S3.T5.1.23.21.5" class="ltx_td ltx_align_center">0.000</td>
</tr>
<tr id="S3.T5.1.24.22" class="ltx_tr">
<th id="S3.T5.1.24.22.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T5.1.24.22.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">PATE-GAN</th>
<td id="S3.T5.1.24.22.3" class="ltx_td ltx_align_center">0.000</td>
<td id="S3.T5.1.24.22.4" class="ltx_td ltx_align_center">-0.001</td>
<td id="S3.T5.1.24.22.5" class="ltx_td ltx_align_center">-0.000</td>
</tr>
<tr id="S3.T5.1.25.23" class="ltx_tr">
<th id="S3.T5.1.25.23.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T5.1.25.23.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">Real</th>
<td id="S3.T5.1.25.23.3" class="ltx_td ltx_align_center"><span id="S3.T5.1.25.23.3.1" class="ltx_text ltx_font_bold">-0.027</span></td>
<td id="S3.T5.1.25.23.4" class="ltx_td"></td>
<td id="S3.T5.1.25.23.5" class="ltx_td"></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 5: </span>Difference in equal opportunity (DEO) of models trained with synthetic data. We measure the DEO of models using real test data - DEO(R) and synthetic test data DEO(S). DEO delta quantifies the difference between DEO(R) and DEO(S). All synthetic data where generated using privacy-loss parameter <math id="S3.T5.3.m1.1" class="ltx_Math" alttext="\epsilon=5.0" display="inline"><semantics id="S3.T5.3.m1.1b"><mrow id="S3.T5.3.m1.1.1" xref="S3.T5.3.m1.1.1.cmml"><mi id="S3.T5.3.m1.1.1.2" xref="S3.T5.3.m1.1.1.2.cmml">Ïµ</mi><mo id="S3.T5.3.m1.1.1.1" xref="S3.T5.3.m1.1.1.1.cmml">=</mo><mn id="S3.T5.3.m1.1.1.3" xref="S3.T5.3.m1.1.1.3.cmml">5.0</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T5.3.m1.1c"><apply id="S3.T5.3.m1.1.1.cmml" xref="S3.T5.3.m1.1.1"><eq id="S3.T5.3.m1.1.1.1.cmml" xref="S3.T5.3.m1.1.1.1"></eq><ci id="S3.T5.3.m1.1.1.2.cmml" xref="S3.T5.3.m1.1.1.2">italic-Ïµ</ci><cn type="float" id="S3.T5.3.m1.1.1.3.cmml" xref="S3.T5.3.m1.1.1.3">5.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T5.3.m1.1d">\epsilon=5.0</annotation></semantics></math>.</figcaption>
</figure>
<div id="S3.SS2.SSS0.Px3.p4" class="ltx_para">
<p id="S3.SS2.SSS0.Px3.p4.1" class="ltx_p">The model trained with MWEM PGM synthetic data was the only one that presented a similar DEO to the baseline model, outperforming all other models trained with synthetic data. Note that our comparison, as in the DSP case, focus on understanding which synthetic data sets can train model that behave as close as possible to models trained with real data. Models trained with MST, which presented promising utility metrics and subgroup accuracy, did not capture as well the difference in equality on odds in experiments with the Adult data. For experiments with COMPAS and fair COMPAS data, MST performs better, but still worse than MWEM PGM, as we can see on Table <a href="#S3.T5" title="Table 5 â€£ Impacts on equal opportunity â€£ 3.2 Fairness analysis of synthetic data in machine learning pipelines â€£ 3 Experimental Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>.</p>
</div>
<div id="S3.SS2.SSS0.Px3.p5" class="ltx_para">
<p id="S3.SS2.SSS0.Px3.p5.1" class="ltx_p">As we investigate the details of variation in TPR it becomes clear MWEM PGM is the the best technique for training models that preserve fairness characteristics of models trained with real data. Experiments with Adult data (Figure <a href="#S3.F3" title="Fig 3 â€£ Impacts on equal opportunity â€£ 3.2 Fairness analysis of synthetic data in machine learning pipelines â€£ 3 Experimental Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>) show that the difference between the privileged group TPR and the minority group TPR of models trained with MWEM PGM data is very similar to the difference between subgroups TPR of models trained with real data. Experiments with COMPAS data (Figure <a href="#S3.F4" title="Fig 4 â€£ Impacts on equal opportunity â€£ 3.2 Fairness analysis of synthetic data in machine learning pipelines â€£ 3 Experimental Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>) are even more compelling. Not only the difference between the subgroup TPR of the model trained with MWEM PGM data is close to that of the model trained with real data, but the true positive rates of the subgroups are also very similar to the TPR of the model trained with real data. Figures <a href="#S3.F3" title="Fig 3 â€£ Impacts on equal opportunity â€£ 3.2 Fairness analysis of synthetic data in machine learning pipelines â€£ 3 Experimental Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> and <a href="#S3.F4" title="Fig 4 â€£ Impacts on equal opportunity â€£ 3.2 Fairness analysis of synthetic data in machine learning pipelines â€£ 3 Experimental Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> show that models trained with marginal-based synthetic data outperforms models trained with GAN-based synthetic data for our tested data sets.</p>
</div>
<figure id="S3.F3" class="ltx_figure"><img src="/html/2310.19250/assets/x3.png" id="S3.F3.g1" class="ltx_graphics ltx_centering ltx_img_square" width="403" height="356" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Fig 3: </span>True positive rate (TPR) variation of different subgroups of the protected attribute of the Adult data. The top two rows shows TPR variation for different values of privacy-loss parameter <math id="S3.F3.3.m1.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S3.F3.3.m1.1b"><mi id="S3.F3.3.m1.1.1" xref="S3.F3.3.m1.1.1.cmml">Ïµ</mi><annotation-xml encoding="MathML-Content" id="S3.F3.3.m1.1c"><ci id="S3.F3.3.m1.1.1.cmml" xref="S3.F3.3.m1.1.1">italic-Ïµ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.3.m1.1d">\epsilon</annotation></semantics></math>, of models trained with synthetic data and evaluated with real data. The bottom two rows shows TPR variation for different values of privacy-loss parameter <math id="S3.F3.4.m2.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S3.F3.4.m2.1b"><mi id="S3.F3.4.m2.1.1" xref="S3.F3.4.m2.1.1.cmml">Ïµ</mi><annotation-xml encoding="MathML-Content" id="S3.F3.4.m2.1c"><ci id="S3.F3.4.m2.1.1.cmml" xref="S3.F3.4.m2.1.1">italic-Ïµ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.4.m2.1d">\epsilon</annotation></semantics></math>, of models trained with synthetic data and evaluated with synthetic data.</figcaption>
</figure>
<div id="S3.SS2.SSS0.Px3.p6" class="ltx_para">
<p id="S3.SS2.SSS0.Px3.p6.1" class="ltx_p">We make a similar analysis when evaluating how good synthetic data sets are for assessing TPRs. Figures <a href="#S3.F3" title="Fig 3 â€£ Impacts on equal opportunity â€£ 3.2 Fairness analysis of synthetic data in machine learning pipelines â€£ 3 Experimental Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> and <a href="#S3.F4" title="Fig 4 â€£ Impacts on equal opportunity â€£ 3.2 Fairness analysis of synthetic data in machine learning pipelines â€£ 3 Experimental Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> also present plots of TPR when synthetic data is used during model assessment. Models trained with MWEM PGM data present very similar assessment when using both real and synthetic data as test data. Models trained on MST and PrivBayes present greater discrepancies. Models trained on GAN-based data present even greater discrepancies between assessments made with real and synthetic data as test data.</p>
</div>
<figure id="S3.F4" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S3.F4.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2310.19250/assets/x4.png" id="S3.F4.1.g1" class="ltx_graphics ltx_img_square" width="371" height="311" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S3.F4.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2310.19250/assets/x5.png" id="S3.F4.2.g1" class="ltx_graphics ltx_img_square" width="371" height="324" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Fig 4: </span>TPR variation: COMPAS and <math id="S3.F4.5.m1.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S3.F4.5.m1.1b"><mi id="S3.F4.5.m1.1.1" xref="S3.F4.5.m1.1.1.cmml">Ïµ</mi><annotation-xml encoding="MathML-Content" id="S3.F4.5.m1.1c"><ci id="S3.F4.5.m1.1.1.cmml" xref="S3.F4.5.m1.1.1">italic-Ïµ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F4.5.m1.1d">\epsilon</annotation></semantics></math>, of models trained with synthetic data and evaluated with real data.We also present TPR variation for different values of <math id="S3.F4.6.m2.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S3.F4.6.m2.1b"><mi id="S3.F4.6.m2.1.1" xref="S3.F4.6.m2.1.1.cmml">Ïµ</mi><annotation-xml encoding="MathML-Content" id="S3.F4.6.m2.1c"><ci id="S3.F4.6.m2.1.1.cmml" xref="S3.F4.6.m2.1.1">italic-Ïµ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F4.6.m2.1d">\epsilon</annotation></semantics></math>, of models trained with synthetic data and evaluated with synthetic data.</figcaption>
</figure>
</section>
<section id="S3.SS2.SSS0.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Marginal-based synthetic data preserves and better assess model fairness</h5>

<div id="S3.SS2.SSS0.Px4.p1" class="ltx_para">
<p id="S3.SS2.SSS0.Px4.p1.1" class="ltx_p">We evaluated the performance of the synthetic data sets based on two key model fairness tasks: the ability to mirror the behavior of actual data in downstream model fairness, and the ability to produce synthetic data for assessing model fairness. Our analysis includes a rigorous assessment of model fairness, which includes measuring subgroup accuracy, the difference in statistical parity(DSP) and the difference in equal opportunity (DEO). Beyond measuring the classical fairness metrics, we also assess the Positive Predictive Value (PPV) and True Positive Rate (TPR) for each subgroup within the protected class. The significance of evaluating PPV and TPR lies in understanding if the model upholds fairness because it accurately represents PPV and TPR for all subgroups, or if it does so merely by acting as a random classifier.</p>
</div>
<div id="S3.SS2.SSS0.Px4.p2" class="ltx_para">
<p id="S3.SS2.SSS0.Px4.p2.1" class="ltx_p">Table <a href="#S3.T6" title="Table 6 â€£ Marginal-based synthetic data preserves and better assess model fairness â€£ 3.2 Fairness analysis of synthetic data in machine learning pipelines â€£ 3 Experimental Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> shows the best synthesizers in end-to-end machine learning pipelines when evaluating for fairness metrics. All table results accounts for synthetic data generated with privacy-loss parameter <math id="S3.SS2.SSS0.Px4.p2.1.m1.1" class="ltx_Math" alttext="\epsilon=5.0" display="inline"><semantics id="S3.SS2.SSS0.Px4.p2.1.m1.1a"><mrow id="S3.SS2.SSS0.Px4.p2.1.m1.1.1" xref="S3.SS2.SSS0.Px4.p2.1.m1.1.1.cmml"><mi id="S3.SS2.SSS0.Px4.p2.1.m1.1.1.2" xref="S3.SS2.SSS0.Px4.p2.1.m1.1.1.2.cmml">Ïµ</mi><mo id="S3.SS2.SSS0.Px4.p2.1.m1.1.1.1" xref="S3.SS2.SSS0.Px4.p2.1.m1.1.1.1.cmml">=</mo><mn id="S3.SS2.SSS0.Px4.p2.1.m1.1.1.3" xref="S3.SS2.SSS0.Px4.p2.1.m1.1.1.3.cmml">5.0</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px4.p2.1.m1.1b"><apply id="S3.SS2.SSS0.Px4.p2.1.m1.1.1.cmml" xref="S3.SS2.SSS0.Px4.p2.1.m1.1.1"><eq id="S3.SS2.SSS0.Px4.p2.1.m1.1.1.1.cmml" xref="S3.SS2.SSS0.Px4.p2.1.m1.1.1.1"></eq><ci id="S3.SS2.SSS0.Px4.p2.1.m1.1.1.2.cmml" xref="S3.SS2.SSS0.Px4.p2.1.m1.1.1.2">italic-Ïµ</ci><cn type="float" id="S3.SS2.SSS0.Px4.p2.1.m1.1.1.3.cmml" xref="S3.SS2.SSS0.Px4.p2.1.m1.1.1.3">5.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px4.p2.1.m1.1c">\epsilon=5.0</annotation></semantics></math>.</p>
</div>
<div id="S3.SS2.SSS0.Px4.p3" class="ltx_para">
<p id="S3.SS2.SSS0.Px4.p3.1" class="ltx_p">MWEM PGM synthetic data, once more, outperforms all other synthetic data in the three fairness metrics. This advanatge is observed when MWEM PGM synthetic data is used as a training data set as well as when used as a testing data set.</p>
</div>
<div id="S3.SS2.SSS0.Px4.p4" class="ltx_para">
<p id="S3.SS2.SSS0.Px4.p4.1" class="ltx_p">As we investigate subgroup PPV and TPR metrics to get insights into model fairness performances. We note that MWEM PGM synthetic data presents a ratio of positive labels comparable to that obtained with real data (Table <a href="#S3.T4" title="Table 4 â€£ Impacts on statistical parity â€£ 3.2 Fairness analysis of synthetic data in machine learning pipelines â€£ 3 Experimental Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>), for all subgroups. When evaluating the ratio of positive labels in prediction for all subgroups (female and male) in Table <a href="#S3.T4" title="Table 4 â€£ Impacts on statistical parity â€£ 3.2 Fairness analysis of synthetic data in machine learning pipelines â€£ 3 Experimental Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, we see that MWEM PGM also results is metrics that are the closest to real data.</p>
</div>
<div id="S3.SS2.SSS0.Px4.p5" class="ltx_para">
<p id="S3.SS2.SSS0.Px4.p5.2" class="ltx_p">The evaluation of true positive rate provides more insights into the bias introduced by synthetic data set in end-to-end machine learning pipelines. Figures <a href="#S3.F3" title="Fig 3 â€£ Impacts on equal opportunity â€£ 3.2 Fairness analysis of synthetic data in machine learning pipelines â€£ 3 Experimental Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> and <a href="#S3.F4" title="Fig 4 â€£ Impacts on equal opportunity â€£ 3.2 Fairness analysis of synthetic data in machine learning pipelines â€£ 3 Experimental Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> shows the variation of TPR for different values of <math id="S3.SS2.SSS0.Px4.p5.1.m1.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S3.SS2.SSS0.Px4.p5.1.m1.1a"><mi id="S3.SS2.SSS0.Px4.p5.1.m1.1.1" xref="S3.SS2.SSS0.Px4.p5.1.m1.1.1.cmml">Ïµ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px4.p5.1.m1.1b"><ci id="S3.SS2.SSS0.Px4.p5.1.m1.1.1.cmml" xref="S3.SS2.SSS0.Px4.p5.1.m1.1.1">italic-Ïµ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px4.p5.1.m1.1c">\epsilon</annotation></semantics></math>, in experiments with Adult, COMPAS ans fair COMPAS, respectively. For COMPAS data set, MWEM PGM provides performance comparable the real data set in an end-to-end analysis. For Adult data, <math id="S3.SS2.SSS0.Px4.p5.2.m2.1" class="ltx_Math" alttext="\epsilon&gt;5" display="inline"><semantics id="S3.SS2.SSS0.Px4.p5.2.m2.1a"><mrow id="S3.SS2.SSS0.Px4.p5.2.m2.1.1" xref="S3.SS2.SSS0.Px4.p5.2.m2.1.1.cmml"><mi id="S3.SS2.SSS0.Px4.p5.2.m2.1.1.2" xref="S3.SS2.SSS0.Px4.p5.2.m2.1.1.2.cmml">Ïµ</mi><mo id="S3.SS2.SSS0.Px4.p5.2.m2.1.1.1" xref="S3.SS2.SSS0.Px4.p5.2.m2.1.1.1.cmml">&gt;</mo><mn id="S3.SS2.SSS0.Px4.p5.2.m2.1.1.3" xref="S3.SS2.SSS0.Px4.p5.2.m2.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px4.p5.2.m2.1b"><apply id="S3.SS2.SSS0.Px4.p5.2.m2.1.1.cmml" xref="S3.SS2.SSS0.Px4.p5.2.m2.1.1"><gt id="S3.SS2.SSS0.Px4.p5.2.m2.1.1.1.cmml" xref="S3.SS2.SSS0.Px4.p5.2.m2.1.1.1"></gt><ci id="S3.SS2.SSS0.Px4.p5.2.m2.1.1.2.cmml" xref="S3.SS2.SSS0.Px4.p5.2.m2.1.1.2">italic-Ïµ</ci><cn type="integer" id="S3.SS2.SSS0.Px4.p5.2.m2.1.1.3.cmml" xref="S3.SS2.SSS0.Px4.p5.2.m2.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px4.p5.2.m2.1c">\epsilon&gt;5</annotation></semantics></math> provides comparable metrics. Other algorithms, such as PrivBayes, that presented utility results (AUC metric) comparable to real data, showed low performance in terms of TPR. Finally, marginal-based synthesizers presented similar performance from the point of view of utility and fairness for both biased and fair versions of the COMPAS data set.</p>
</div>
<figure id="S3.T6" class="ltx_table">
<table id="S3.T6.3" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T6.3.1.1" class="ltx_tr">
<th id="S3.T6.3.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row"><span id="S3.T6.3.1.1.1.1" class="ltx_text ltx_font_smallcaps">Metric</span></th>
<th id="S3.T6.3.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S3.T6.3.1.1.2.1" class="ltx_text ltx_font_smallcaps">Best Synthesizer</span></th>
<th id="S3.T6.3.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S3.T6.3.1.1.3.1" class="ltx_text ltx_font_smallcaps">Runner up</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T6.3.2.1" class="ltx_tr">
<th id="S3.T6.3.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt">Subgroup accuracy</th>
<td id="S3.T6.3.2.1.2" class="ltx_td ltx_align_center ltx_border_tt">MWEM PGM</td>
<td id="S3.T6.3.2.1.3" class="ltx_td ltx_align_center ltx_border_tt">MST</td>
</tr>
<tr id="S3.T6.3.3.2" class="ltx_tr">
<th id="S3.T6.3.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Difference in statistical parity</th>
<td id="S3.T6.3.3.2.2" class="ltx_td ltx_align_center">MWEM PGM</td>
<td id="S3.T6.3.3.2.3" class="ltx_td ltx_align_center">MST</td>
</tr>
<tr id="S3.T6.3.4.3" class="ltx_tr">
<th id="S3.T6.3.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Difference in equality of odds</th>
<td id="S3.T6.3.4.3.2" class="ltx_td ltx_align_center">MWEM PGM</td>
<td id="S3.T6.3.4.3.3" class="ltx_td ltx_align_center">MST</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6: </span>Difference in equal opportunity (DEO) of models trained with synthetic data. We measure the DEO of models using real test data - DEO(R) and synthetic test data DEO(S). DEO delta quantifies the difference between DEO(R) and DEO(S). All synthetic data where generated using privacy-loss parameter <math id="S3.T6.2.m1.1" class="ltx_Math" alttext="\epsilon=5.0" display="inline"><semantics id="S3.T6.2.m1.1b"><mrow id="S3.T6.2.m1.1.1" xref="S3.T6.2.m1.1.1.cmml"><mi id="S3.T6.2.m1.1.1.2" xref="S3.T6.2.m1.1.1.2.cmml">Ïµ</mi><mo id="S3.T6.2.m1.1.1.1" xref="S3.T6.2.m1.1.1.1.cmml">=</mo><mn id="S3.T6.2.m1.1.1.3" xref="S3.T6.2.m1.1.1.3.cmml">5.0</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T6.2.m1.1c"><apply id="S3.T6.2.m1.1.1.cmml" xref="S3.T6.2.m1.1.1"><eq id="S3.T6.2.m1.1.1.1.cmml" xref="S3.T6.2.m1.1.1.1"></eq><ci id="S3.T6.2.m1.1.1.2.cmml" xref="S3.T6.2.m1.1.1.2">italic-Ïµ</ci><cn type="float" id="S3.T6.2.m1.1.1.3.cmml" xref="S3.T6.2.m1.1.1.3">5.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T6.2.m1.1d">\epsilon=5.0</annotation></semantics></math>.</figcaption>
</figure>
</section>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Limitations and Future Works</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">Although the data sets utilized in our analysis are commonly employed in fairness literature, extending the validity of our findings to larger-scale data sets would provide a more comprehensive understanding of the generalizability and robustness of marginal-based synthetic data approaches. Future research should focus on exploring the performance of these frameworks in real-world scenarios with diverse and extensive data sets. This would contribute to the broader applicability and reliability of synthetic data methods in various domains and facilitate a more nuanced understanding of their limitations and capabilities. Finally, extending our analysis to non-tabular data would be an interestign sequel to this work.</p>
</div>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">Our research comprehensively evaluates the impact of synthetic data sets for training and testing in machine learning pipelines in the case of tabular data sets. Specifically, we compare the performance of marginal-based and GAN-based synthesizers within a machine-learning pipeline and analyze various utility and fairness metrics for tabular data sets.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">Our main findings are as follows:
Marginal-based synthetic data demonstrated comparable utility to real data in end-to-end machine-learning pipelines. MWEM PGM (AUC = 0.684) provides utility very close to models trained on real data (AUC = 0.684). Furthermore, we show that model evaluation using synthetic data also provides similar results to evaluation using real data, for tabular data. The metrics obtained when utilizing marginal-based synthetic data (AUC=0.671) are comparable to real data (AUC = 0.684).
Synthetic data sets trained with MWEM PGM do not increase model bias and can provide a realistic fairness evaluation. Our study reveals that MWEM PGM synthetic data can train models that achieve similar utility and fairness characteristics as models trained with real data. Additionally, when used to evaluate the utility and fairness of machine learning models, the synthetic data generated by the MWEM PGM algorithm exhibits behavior very similar to real data.</p>
</div>
<div id="S5.p3" class="ltx_para">
<p id="S5.p3.1" class="ltx_p">These findings highlight synthetic dataâ€™s potential reliability and viability as a substitute for real data sets in end-to-end machine learning pipelines for tabular data. Furthermore, our research sheds light on the implications of model fairness when utilizing differentially private synthetic data for model training.</p>
</div>
<div id="S5.p4" class="ltx_para">
<p id="S5.p4.1" class="ltx_p">One crucial observation is that synthetic data that does well in model training might perform differently when used as evaluation data. This was the case with Privbayes and some of the GAN-based synthetic data. This observation is important as synthetic data techniques gain acceptance as the standard data publishing approach in domains such as healthcare, humanitarian action, education, and population studies.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ1.</span>
<span class="ltx_bibblock">
Dwork C, McSherry F, Nissim K, Smith A.

</span>
<span class="ltx_bibblock">Calibrating noise to sensitivity in private data analysis.

</span>
<span class="ltx_bibblock">In: Theory of cryptography conference. Springer; 2006. p. 265â€“284.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ2.</span>
<span class="ltx_bibblock">
Pereira M, Kim A, Allen J, White K, Ferres JL, Dodhia R.

</span>
<span class="ltx_bibblock">US Broadband Coverage Data Set: A Differentially Private Data
Release.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:210314035. 2021;.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ3.</span>
<span class="ltx_bibblock">
Aktay A, Bavadekar S, Cossoul G, Davis J, Desfontaines D, Fabrikant A, etÂ al.

</span>
<span class="ltx_bibblock">Google COVID-19 community mobility reports: Anonymization process
description (version 1.0).

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:200404145. 2020;.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ4.</span>
<span class="ltx_bibblock">
Tang J, Korolova A, Bai X, Wang X, Wang X.

</span>
<span class="ltx_bibblock">Privacy loss in appleâ€™s implementation of differential privacy on
macos 10.12.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:170902753. 2017;.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ5.</span>
<span class="ltx_bibblock">
Abowd JM.

</span>
<span class="ltx_bibblock">The US Census Bureau adopts differential privacy.

</span>
<span class="ltx_bibblock">In: Proceedings of the 24th ACM SIGKDD International Conference on
Knowledge Discovery &amp; Data Mining; 2018. p. 2867â€“2867.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ6.</span>
<span class="ltx_bibblock">
Qian Z, Callender T, Cebere B, Janes SM, Navani N, vanÂ der Schaar M.

</span>
<span class="ltx_bibblock">Synthetic data for privacy-preserving clinical risk prediction.

</span>
<span class="ltx_bibblock">medRxiv. 2023; p. 2023â€“05.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ7.</span>
<span class="ltx_bibblock">
Movahedi P, Nieminen V, Perez IM, Pahikkala T, Airola A.

</span>
<span class="ltx_bibblock">Evaluating Classifiers Trained on Differentially Private Synthetic
Health Data.

</span>
<span class="ltx_bibblock">In: 2023 IEEE 36th International Symposium on Computer-Based Medical
Systems (CBMS). IEEE; 2023. p. 748â€“753.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ8.</span>
<span class="ltx_bibblock">
Cheng V, Suriyakumar VM, Dullerud N, Joshi S, Ghassemi M.

</span>
<span class="ltx_bibblock">Can You Fake It Until You Make It? Impacts of Differentially Private
Synthetic Data on Downstream Classification Fairness.

</span>
<span class="ltx_bibblock">In: Proceedings of the 2021 ACM Conference on Fairness,
Accountability, and Transparency; 2021. p. 149â€“160.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ9.</span>
<span class="ltx_bibblock">
Ganev G.

</span>
<span class="ltx_bibblock">DP-SGD vs PATE: Which Has Less Disparate Impact on GANs?

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:211113617. 2021;.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ10.</span>
<span class="ltx_bibblock">
McKenna R, Miklau G, Sheldon D.

</span>
<span class="ltx_bibblock">Winning the NIST Contest: A scalable and general approach to
differentially private synthetic data.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:210804978. 2021;.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ11.</span>
<span class="ltx_bibblock">
McKenna R, Sheldon D, Miklau G.

</span>
<span class="ltx_bibblock">Graphical-model based estimation and inference for differential
privacy.

</span>
<span class="ltx_bibblock">In: International Conference on Machine Learning. PMLR; 2019. p.
4435â€“4444.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ12.</span>
<span class="ltx_bibblock">
Zhang J, Cormode G, Procopiuc CM, Srivastava D, Xiao X.

</span>
<span class="ltx_bibblock">Privbayes: Private data release via bayesian networks.

</span>
<span class="ltx_bibblock">ACM Transactions on Database Systems (TODS). 2017;42(4):1â€“41.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ13.</span>
<span class="ltx_bibblock">
Xie L, Lin K, Wang S, Wang F, Zhou J.

</span>
<span class="ltx_bibblock">Differentially private generative adversarial network.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:180206739. 2018;.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ14.</span>
<span class="ltx_bibblock">
Rosenblatt L, Liu X, Pouyanfar S, deÂ Leon E, Desai A, Allen J.

</span>
<span class="ltx_bibblock">Differentially Private Synthetic Data: Applied Evaluations and
Enhancements.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:201105537. 2020;.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ15.</span>
<span class="ltx_bibblock">
Jordon J, Yoon J, Van DerÂ Schaar M.

</span>
<span class="ltx_bibblock">PATE-GAN: Generating synthetic data with differential privacy
guarantees.

</span>
<span class="ltx_bibblock">International Conference on Learning Representations. 2018;.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ16.</span>
<span class="ltx_bibblock">
Wiens J, Saria S, Sendak M, Ghassemi M, Liu VX, Doshi-Velez F, etÂ al.

</span>
<span class="ltx_bibblock">Do no harm: a roadmap for responsible machine learning for health
care.

</span>
<span class="ltx_bibblock">Nature medicine. 2019;25(9):1337â€“1340.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ17.</span>
<span class="ltx_bibblock">
Bagdasaryan E, Poursaeed O, Shmatikov V.

</span>
<span class="ltx_bibblock">Differential privacy has disparate impact on model accuracy.

</span>
<span class="ltx_bibblock">Advances in Neural Information Processing Systems.
2019;32:15479â€“15488.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ18.</span>
<span class="ltx_bibblock">
Calmon FP, Wei D, Vinzamuri B, Ramamurthy KN, Varshney KR.

</span>
<span class="ltx_bibblock">Optimized pre-processing for discrimination prevention.

</span>
<span class="ltx_bibblock">In: Proceedings of the 31st International Conference on Neural
Information Processing Systems; 2017. p. 3995â€“4004.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ19.</span>
<span class="ltx_bibblock">
Rajotte JF, Mukherjee S, Robinson C, Ortiz A, West C, Ferres JL, etÂ al.

</span>
<span class="ltx_bibblock">Reducing bias and increasing utility by federated generative modeling
of medical images using a centralized adversary.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:210107235. 2021;.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ20.</span>
<span class="ltx_bibblock">
Ganev G, Oprisanu B, DeÂ Cristofaro E.

</span>
<span class="ltx_bibblock">Robin hood and matthew effects: Differential privacy has disparate
impact on synthetic data.

</span>
<span class="ltx_bibblock">In: International Conference on Machine Learning. PMLR; 2022. p.
6944â€“6959.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ21.</span>
<span class="ltx_bibblock">
Giles O, Hosseini K, Mingas G, Strickson O, Bowler L, Smith CR, etÂ al.

</span>
<span class="ltx_bibblock">Faking feature importance: A cautionary tale on the use of
differentially-private synthetic data.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:220301363. 2022;.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ22.</span>
<span class="ltx_bibblock">
Pereira M, Kshirsagar M, Mukherjee S, Dodhia R, Ferres JL.

</span>
<span class="ltx_bibblock">An analysis of the deployment of models trained on private tabular
synthetic data: Unexpected surprises.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:210610241. 2021;.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ23.</span>
<span class="ltx_bibblock">
Jordon J, Szpruch L, Houssiau F, Bottarelli M, Cherubin G, Maple C, etÂ al.

</span>
<span class="ltx_bibblock">Synthetic Dataâ€“what, why and how?

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:220503257. 2022;.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ24.</span>
<span class="ltx_bibblock">
Research M. The global victim-perpetrator synthetic dataset; 2022.

</span>
<span class="ltx_bibblock">Available from:
<a target="_blank" href="https://www.ctdatacollaborative.org/global-victim-perpetrator-synthetic-dataset" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.ctdatacollaborative.org/global-victim-perpetrator-synthetic-dataset</a>.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ25.</span>
<span class="ltx_bibblock">
Tao Y, McKenna R, Hay M, Machanavajjhala A, Miklau G.

</span>
<span class="ltx_bibblock">Benchmarking differentially private synthetic data generation
algorithms.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:211209238. 2021;.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ26.</span>
<span class="ltx_bibblock">
Bullwinkel B, Grabarz K, Ke L, Gong S, Tanner C, Allen J.

</span>
<span class="ltx_bibblock">Evaluating the Fairness Impact of Differentially Private Synthetic
Data.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:220504321. 2022;.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ27.</span>
<span class="ltx_bibblock">
Heidari H, Loi M, Gummadi KP, Krause A.

</span>
<span class="ltx_bibblock">A moral framework for understanding fair ML through economic models
of equality of opportunity.

</span>
<span class="ltx_bibblock">In: Proceedings of the Conference on Fairness, Accountability, and
Transparency; 2019. p. 181â€“190.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ28.</span>
<span class="ltx_bibblock">
Barocas S, Hardt M, Narayanan A.

</span>
<span class="ltx_bibblock">Fairness in machine learning.

</span>
<span class="ltx_bibblock">Nips tutorial. 2017;1:2.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ29.</span>
<span class="ltx_bibblock">
Dwork C, Roth A, etÂ al.

</span>
<span class="ltx_bibblock">The algorithmic foundations of differential privacy.

</span>
<span class="ltx_bibblock">Foundations and Trends in Theoretical Computer Science.
2014;9(3-4):211â€“407.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ30.</span>
<span class="ltx_bibblock">
McSherry FD.

</span>
<span class="ltx_bibblock">Privacy integrated queries: an extensible platform for
privacy-preserving data analysis.

</span>
<span class="ltx_bibblock">In: Proceedings of the 2009 ACM SIGMOD International Conference on
Management of data; 2009. p. 19â€“30.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ31.</span>
<span class="ltx_bibblock">
Dwork C, McSherry F, Nissim K, Smith A.

</span>
<span class="ltx_bibblock">Calibrating noise to sensitivity in private data analysis.

</span>
<span class="ltx_bibblock">In: Theory of cryptography conference. Springer; 2006. p. 265â€“284.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ32.</span>
<span class="ltx_bibblock">
Xu W, Zhao J, Iannacci F, Wang B.

</span>
<span class="ltx_bibblock">FFPDG: Fast, Fair and Private Data Generation.

</span>
<span class="ltx_bibblock">online preprint. 2021;.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ33.</span>
<span class="ltx_bibblock">
Perrone V, Donini M, Zafar MB, Schmucker R, Kenthapadi K, Archambeau C.

</span>
<span class="ltx_bibblock">Fair bayesian optimization.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:200605109. 2020;.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ34.</span>
<span class="ltx_bibblock">
Xu L, Skoularidou M, Cuesta-Infante A, Veeramachaneni K.

</span>
<span class="ltx_bibblock">Modeling tabular data using conditional gan.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:190700503. 2019;.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ35.</span>
<span class="ltx_bibblock">
Abadi M, Chu A, Goodfellow I, McMahan HB, Mironov I, Talwar K, etÂ al.

</span>
<span class="ltx_bibblock">Deep learning with differential privacy.

</span>
<span class="ltx_bibblock">In: Proceedings of the 2016 ACM SIGSAC conference on computer and
communications security; 2016. p. 308â€“318.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ36.</span>
<span class="ltx_bibblock">
Papernot N, Abadi M, Erlingsson U, Goodfellow I, Talwar K.

</span>
<span class="ltx_bibblock">Semi-supervised knowledge transfer for deep learning from private
training data.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:161005755. 2016;.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ37.</span>
<span class="ltx_bibblock">
Kamiran F, Calders T.

</span>
<span class="ltx_bibblock">Data preprocessing techniques for classification without
discrimination.

</span>
<span class="ltx_bibblock">Knowledge and Information Systems. 2012;33(1):1â€“33.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ38.</span>
<span class="ltx_bibblock">
Zhang J, Cormode G, Procopiuc CM, Srivastava D, Xiao X.

</span>
<span class="ltx_bibblock">Privbayes: Private data release via bayesian networks.

</span>
<span class="ltx_bibblock">ACM Transactions on Database Systems (TODS). 2017;42(4):1â€“41.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ39.</span>
<span class="ltx_bibblock">
Dua D, Graff C. UCI Machine Learning Repository; 2017.

</span>
<span class="ltx_bibblock">Available from: <a target="_blank" href="http://archive.ics.uci.edu/ml" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://archive.ics.uci.edu/ml</a>.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ40.</span>
<span class="ltx_bibblock">
Barenstein M.

</span>
<span class="ltx_bibblock">ProPublicaâ€™s COMPAS Data Revisited.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:190604711. 2019;.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2310.19249" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2310.19250" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2310.19250">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2310.19250" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2310.19251" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Tue Feb 27 21:40:18 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
