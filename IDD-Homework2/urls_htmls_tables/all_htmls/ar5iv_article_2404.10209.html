<article class="ltx_document ltx_authors_1line ltx_leqno">
 <h1 class="ltx_title ltx_title_document">
  Demonstration of DB-GPT: Next Generation Data Interaction System Empowered by Large Language Models
 </h1>
 <div class="ltx_authors">
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Siqiao Xue
    <sup class="ltx_sup" id="id22.22.id1">
     <span class="ltx_text ltx_font_italic" id="id22.22.id1.1">
      ♢
     </span>
    </sup>
    , Danrui Qi
    <sup class="ltx_sup" id="id23.23.id2">
     <span class="ltx_text ltx_font_italic" id="id23.23.id2.1">
      ♣
     </span>
    </sup>
    , Caigao Jiang
    <sup class="ltx_sup" id="id24.24.id3">
     <span class="ltx_text ltx_font_italic" id="id24.24.id3.1">
      ♢
     </span>
    </sup>
    , Wenhui Shi
    <sup class="ltx_sup" id="id25.25.id4">
     <span class="ltx_text ltx_font_italic" id="id25.25.id4.1">
      ♢
     </span>
    </sup>
    , Fangyin Cheng
    <sup class="ltx_sup" id="id26.26.id5">
     <span class="ltx_text ltx_font_italic" id="id26.26.id5.1">
      ♥
     </span>
    </sup>
    , Keting Chen
    <sup class="ltx_sup" id="id27.27.id6">
     <span class="ltx_text ltx_font_italic" id="id27.27.id6.1">
      ♢
     </span>
    </sup>
    ,
    <br class="ltx_break"/>
    Hongjun Yang
    <sup class="ltx_sup" id="id28.28.id7">
     <span class="ltx_text ltx_font_italic" id="id28.28.id7.1">
      ♢
     </span>
    </sup>
    ,
Zhiping Zhang
    <sup class="ltx_sup" id="id29.29.id8">
     <span class="ltx_text ltx_font_italic" id="id29.29.id8.1">
      ♡
     </span>
    </sup>
    , Jianshan He
    <sup class="ltx_sup" id="id30.30.id9">
     <span class="ltx_text ltx_font_italic" id="id30.30.id9.1">
      ♢
     </span>
    </sup>
    , Hongyang Zhang
    <sup class="ltx_sup" id="id31.31.id10">
     <span class="ltx_text ltx_font_italic" id="id31.31.id10.1">
      ♦
     </span>
    </sup>
    , Ganglin Wei
    <sup class="ltx_sup" id="id32.32.id11">
     <span class="ltx_text ltx_font_italic" id="id32.32.id11.1">
      ♢
     </span>
    </sup>
    ,
    <br class="ltx_break"/>
    Wang Zhao,
Fan Zhou
    <sup class="ltx_sup" id="id33.33.id12">
     <span class="ltx_text ltx_font_italic" id="id33.33.id12.1">
      ♢
     </span>
    </sup>
    , Hong Yi, Shaodong Liu
    <sup class="ltx_sup" id="id34.34.id13">
     <span class="ltx_text ltx_font_italic" id="id34.34.id13.1">
      ♠
     </span>
    </sup>
    , Hongjun Yang
    <sup class="ltx_sup" id="id35.35.id14">
     <span class="ltx_text ltx_font_italic" id="id35.35.id14.1">
      ♢
     </span>
    </sup>
    , Faqiang Chen
    <sup class="ltx_sup" id="id36.36.id15">
     <span class="ltx_text ltx_font_italic" id="id36.36.id15.1">
      ♢,∗
     </span>
    </sup>
   </span>
   <span class="ltx_author_notes">
    <span class="ltx_contact ltx_role_affiliation">
     <span class="ltx_text ltx_affiliation_institution" id="id21.21.6">
      <sup class="ltx_sup" id="id21.21.6.1">
       <span class="ltx_text ltx_font_italic" id="id21.21.6.1.1">
        ♢
       </span>
      </sup>
      Ant Group,
      <sup class="ltx_sup" id="id21.21.6.2">
       <span class="ltx_text ltx_font_italic" id="id21.21.6.2.1">
        ♡
       </span>
      </sup>
      Alibaba Group,
      <sup class="ltx_sup" id="id21.21.6.3">
       <span class="ltx_text ltx_font_italic" id="id21.21.6.3.1">
        ♥
       </span>
      </sup>
      JD Group,
      <sup class="ltx_sup" id="id21.21.6.4">
       <span class="ltx_text ltx_font_italic" id="id21.21.6.4.1">
        ♠
       </span>
      </sup>
      Meituan,
      <br class="ltx_break"/>
      <sup class="ltx_sup" id="id21.21.6.5">
       <span class="ltx_text ltx_font_italic" id="id21.21.6.5.1">
        ♦
       </span>
      </sup>
      Southwestern University of Finance and Economics, China,
      <br class="ltx_break"/>
      <sup class="ltx_sup" id="id21.21.6.6">
       <span class="ltx_text ltx_font_italic" id="id21.21.6.6.1">
        ♣
       </span>
      </sup>
      Simon Fraser University, Canada
     </span>
    </span>
   </span>
  </span>
 </div>
 <div class="ltx_abstract">
  <h6 class="ltx_title ltx_title_abstract">
   Abstract.
  </h6>
  <p class="ltx_p" id="id37.id1">
   The recent breakthroughs in large language models (LLMs) are positioned to transition many areas of software. The technologies of interacting with data particularly have an important entanglement with LLMs as efficient and intuitive data interactions are paramount. In this paper, we present DB-GPT, a revolutionary and product-ready Python library that integrates LLMs into traditional data interaction tasks to enhance user experience and accessibility.
DB-GPT is designed to understand data interaction tasks described by natural language and provide context-aware responses powered by LLMs, making it an indispensable tool for users ranging from novice to expert.
Its system design supports deployment across local, distributed, and cloud environments. Beyond handling basic data interaction tasks like Text-to-SQL with LLMs, it can handle complex tasks like generative data analysis through a Multi-Agents framework and the Agentic Workflow Expression Language (AWEL). The Service-oriented Multi-model Management Framework (SMMF) ensures data privacy and security, enabling users to employ DB-GPT with private LLMs. Additionally, DB-GPT offers a series of product-ready features designed to enable users to integrate DB-GPT within their product environments easily. The code of DB-GPT is available at
Github
   <span class="ltx_note ltx_role_footnote" id="footnote1">
    <sup class="ltx_note_mark">
     1
    </sup>
    <span class="ltx_note_outer">
     <span class="ltx_note_content">
      <sup class="ltx_note_mark">
       1
      </sup>
      <span class="ltx_tag ltx_tag_note">
       1
      </span>
      https://github.com/eosphoros-ai/DB-GPT
     </span>
    </span>
   </span>
   which already has
   <span class="ltx_text ltx_font_bold" id="id37.id1.1">
    over 10.7k stars
   </span>
   . Please install DB-GPT for your own usage with the instructions
   <span class="ltx_note ltx_role_footnote" id="footnote2">
    <sup class="ltx_note_mark">
     2
    </sup>
    <span class="ltx_note_outer">
     <span class="ltx_note_content">
      <sup class="ltx_note_mark">
       2
      </sup>
      <span class="ltx_tag ltx_tag_note">
       2
      </span>
      https://github.com/eosphoros-ai/DB-GPT#install
     </span>
    </span>
   </span>
   and watch a 5-minute introduction video on Youtube
   <span class="ltx_note ltx_role_footnote" id="footnote3">
    <sup class="ltx_note_mark">
     3
    </sup>
    <span class="ltx_note_outer">
     <span class="ltx_note_content">
      <sup class="ltx_note_mark">
       3
      </sup>
      <span class="ltx_tag ltx_tag_note">
       3
      </span>
      https://youtu.be/n_8RI1ENyl4
     </span>
    </span>
   </span>
   to further investigate DB-GPT.
  </p>
 </div>
 <section class="ltx_section" id="S1">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    1.
   </span>
   Introduction
  </h2>
  <div class="ltx_para" id="S1.p1">
   <p class="ltx_p" id="S1.p1.1">
    Large language models (LLMs) such as ChatGPT and GPT-4 have showcased their remarkable capabilities in engaging in human-like communication and understanding complex queries, bringing a trend of incorporating LLMs in various fields.
Data interaction, which aims to let users engage with and understand their data, enabling the retrieval, analysis, manipulation, and visualization of data to derive insights or make decisions. In the realm of interacting with data, LLMs pave the way for natural language interfaces, enabling users to express their data interaction tasks through natural language and leading to more natural and intuitive data interactions.
   </p>
  </div>
  <div class="ltx_para" id="S1.p2">
   <p class="ltx_p" id="S1.p2.1">
    Nonetheless, how to enhance the data interaction tasks with LLMs to provide users reliable understanding and insights to their data still remains an open question. One straightforward approach is to directly provide commonly used LLMs, such as GPT-4, with instructions on how to interact via few-shot prompting or in-context learning. Moreover, to further facilitate the intelligent interactions with data, many works
    <cite class="ltx_cite ltx_citemacro_citep">
     (Chase,
     <a class="ltx_ref" href="#bib.bib2" title="">
      2022
     </a>
     ; Liu,
     <a class="ltx_ref" href="#bib.bib9" title="">
      2022
     </a>
     ; Richards,
     <a class="ltx_ref" href="#bib.bib15" title="">
      2022
     </a>
     )
    </cite>
    have incorporated the LLM-powered automated reasoning and decision process (a.k.a., multi-agents frameworks) into the data interaction process. However, these multi-agents frameworks are usually task-specific instead of task-agnostic, limiting their usage to a broad range of tasks. Meanwhile, the interaction with data includes a variety of tasks in practice. For example, it includes the Text-to-SQL / SQL-to-Text tasks, the generation of data analytics, the generation of enterprise report analysis and business insights, etc. It is necessary for users to arrange the workflow of multi-agents according to their own needs. The existing effort
    <cite class="ltx_cite ltx_citemacro_citep">
     (Chase,
     <a class="ltx_ref" href="#bib.bib2" title="">
      2022
     </a>
     )
    </cite>
    does not consider abundant data interaction needs. Finally, though being important, the privacy-sensitive setup for LLM-empowered data interaction is under-investigated. The previous efforts
    <cite class="ltx_cite ltx_citemacro_citep">
     (Martínez et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib10" title="">
      2023
     </a>
     ; H2O.ai,
     <a class="ltx_ref" href="#bib.bib4" title="">
      2023
     </a>
     )
    </cite>
    are not designed for data interaction tasks.
   </p>
  </div>
  <div class="ltx_para" id="S1.p3">
   <p class="ltx_p" id="S1.p3.1">
    To overcome these limitations, our key idea is to propose an open-sourced Python library
    <span class="ltx_text ltx_font_italic" id="S1.p3.1.1">
     DB-GPT
    </span>
    supporting data interaction by using multi-agents with flexible arrangement and privacy-sensitive setup.
This idea, however, introduces three main challenges, the first challenge (
    <span class="ltx_text ltx_font_bold ltx_font_italic" id="S1.p3.1.2">
     C1
    </span>
    ) is the design of multi-agents framework for supporting database interaction.
The second challenge (
    <span class="ltx_text ltx_font_bold ltx_font_italic" id="S1.p3.1.3">
     C2
    </span>
    ) is the declarative expression supporting arrange multi-agents flexibly. The third challenge (
    <span class="ltx_text ltx_font_bold ltx_font_italic" id="S1.p3.1.4">
     C3
    </span>
    ) focuses on the design of private LLM-empowered data interaction.
   </p>
  </div>
  <div class="ltx_para" id="S1.p4">
   <p class="ltx_p" id="S1.p4.1">
    <span class="ltx_text ltx_font_bold ltx_font_italic" id="S1.p4.1.1">
     To solve C1
    </span>
    , we propose the Multi-Agents framework in
    <span class="ltx_text ltx_font_italic" id="S1.p4.1.2">
     DB-GPT
    </span>
    which automates the database interaction tasks. Once users have entered their final goals, the Multi-Agents framework can free their hands, autonomously generate the planning of tasks and execute particular tasks.
    <span class="ltx_text ltx_font_bold ltx_font_italic" id="S1.p4.1.3">
     To solve C2
    </span>
    , we proposes a declarative language called
    <span class="ltx_text ltx_font_italic" id="S1.p4.1.4">
     Agentic Workflow Expression Language (AWEL)
    </span>
    in
    <span class="ltx_text ltx_font_italic" id="S1.p4.1.5">
     DB-GPT
    </span>
    . With AWEL, users can implement their execution plan for multi-agents with simple expression (i.e. few lines of code). Furthermore, to make users more code-free,
    <span class="ltx_text ltx_font_italic" id="S1.p4.1.6">
     DB-GPT
    </span>
    also provides an interface for users constructing their Agentic Workflow with only drag and drop.
    <span class="ltx_text ltx_font_bold ltx_font_italic" id="S1.p4.1.7">
     To solve C3
    </span>
    , we propose
    <span class="ltx_text ltx_font_italic" id="S1.p4.1.8">
     Service-oriented Multi-model Management Framework (SMMF)
    </span>
    in
    <span class="ltx_text ltx_font_italic" id="S1.p4.1.9">
     DB-GPT
    </span>
    to support users to run
    <span class="ltx_text ltx_font_italic" id="S1.p4.1.10">
     DB-GPT
    </span>
    with their private LLMs in their own execution environment. All the interactions among users, LLMs and data are performed locally, which definitely promises users’ privacy.
   </p>
  </div>
  <figure class="ltx_table" id="S1.T1">
   <figcaption class="ltx_caption" style="font-size:90%;">
    <span class="ltx_tag ltx_tag_table">
     Table 1.
    </span>
    Comparasion between DB-GPT and other tools.
   </figcaption>
   <table class="ltx_tabular ltx_align_middle" id="S1.T1.3">
    <tr class="ltx_tr" id="S1.T1.3.1">
     <td class="ltx_td ltx_border_r ltx_border_t" id="S1.T1.3.1.1">
     </td>
     <td class="ltx_td ltx_border_t" id="S1.T1.3.1.2">
     </td>
     <td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.3.1.3">
      <span class="ltx_text ltx_font_bold" id="S1.T1.3.1.3.1" style="font-size:90%;">
       LangChain
       <cite class="ltx_cite ltx_citemacro_citep">
        (Chase,
        <a class="ltx_ref" href="#bib.bib2" title="">
         2022
        </a>
        )
       </cite>
      </span>
     </td>
     <td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.3.1.4">
      <span class="ltx_text ltx_font_bold" id="S1.T1.3.1.4.1" style="font-size:90%;">
       LlamaIndex
       <cite class="ltx_cite ltx_citemacro_citep">
        (Liu,
        <a class="ltx_ref" href="#bib.bib9" title="">
         2022
        </a>
        )
       </cite>
      </span>
     </td>
     <td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.3.1.5">
      <span class="ltx_text ltx_font_bold" id="S1.T1.3.1.5.1" style="font-size:90%;">
       PrivateGPT
       <cite class="ltx_cite ltx_citemacro_citep">
        (Martínez et al
        <span class="ltx_text">
         .
        </span>
        ,
        <a class="ltx_ref" href="#bib.bib10" title="">
         2023
        </a>
        )
       </cite>
      </span>
     </td>
     <td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.3.1.6">
      <span class="ltx_text ltx_font_bold" id="S1.T1.3.1.6.1" style="font-size:90%;">
       ChatDB
       <cite class="ltx_cite ltx_citemacro_citep">
        (Hu et al
        <span class="ltx_text">
         .
        </span>
        ,
        <a class="ltx_ref" href="#bib.bib5" title="">
         2023
        </a>
        )
       </cite>
      </span>
     </td>
     <td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.3.1.7">
      <span class="ltx_text ltx_font_bold" id="S1.T1.3.1.7.1" style="font-size:90%;">
       DB-GPT
      </span>
     </td>
    </tr>
    <tr class="ltx_tr" id="S1.T1.3.2">
     <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.3.2.1" rowspan="5">
      <span class="ltx_text ltx_font_bold" id="S1.T1.3.2.1.1" style="font-size:90%;">
       System Components
      </span>
     </td>
     <td class="ltx_td ltx_align_left ltx_border_t" id="S1.T1.3.2.2">
      <span class="ltx_text" id="S1.T1.3.2.2.1" style="font-size:90%;">
       Multi-Agents Framework
      </span>
     </td>
     <td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.3.2.3">
      <span class="ltx_text" id="S1.T1.3.2.3.1" style="font-size:90%;color:#00FF00;">
       ✓
      </span>
     </td>
     <td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.3.2.4">
      <span class="ltx_text" id="S1.T1.3.2.4.1" style="font-size:90%;color:#00FF00;">
       ✓
      </span>
     </td>
     <td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.3.2.5">
      <span class="ltx_text" id="S1.T1.3.2.5.1" style="font-size:90%;color:#FF0000;">
       ✗
      </span>
     </td>
     <td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.3.2.6">
      <span class="ltx_text" id="S1.T1.3.2.6.1" style="font-size:90%;color:#FF0000;">
       ✗
      </span>
     </td>
     <td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.3.2.7">
      <span class="ltx_text" id="S1.T1.3.2.7.1" style="font-size:90%;color:#00FF00;">
       ✓
      </span>
     </td>
    </tr>
    <tr class="ltx_tr" id="S1.T1.3.3">
     <td class="ltx_td ltx_align_left" id="S1.T1.3.3.1">
      <span class="ltx_text" id="S1.T1.3.3.1.1" style="font-size:90%;">
       Multi-LLMs Support
      </span>
     </td>
     <td class="ltx_td ltx_align_center" id="S1.T1.3.3.2">
      <span class="ltx_text" id="S1.T1.3.3.2.1" style="font-size:90%;color:#00FF00;">
       ✓
      </span>
     </td>
     <td class="ltx_td ltx_align_center" id="S1.T1.3.3.3">
      <span class="ltx_text" id="S1.T1.3.3.3.1" style="font-size:90%;color:#00FF00;">
       ✓
      </span>
     </td>
     <td class="ltx_td ltx_align_center" id="S1.T1.3.3.4">
      <span class="ltx_text" id="S1.T1.3.3.4.1" style="font-size:90%;color:#FF0000;">
       ✗
      </span>
     </td>
     <td class="ltx_td ltx_align_center" id="S1.T1.3.3.5">
      <span class="ltx_text" id="S1.T1.3.3.5.1" style="font-size:90%;color:#00FF00;">
       ✓
      </span>
     </td>
     <td class="ltx_td ltx_align_center" id="S1.T1.3.3.6">
      <span class="ltx_text" id="S1.T1.3.3.6.1" style="font-size:90%;color:#00FF00;">
       ✓
      </span>
     </td>
    </tr>
    <tr class="ltx_tr" id="S1.T1.3.4">
     <td class="ltx_td ltx_align_left" id="S1.T1.3.4.1">
      <span class="ltx_text" id="S1.T1.3.4.1.1" style="font-size:90%;">
       RAG from Multiple Data Sources
      </span>
     </td>
     <td class="ltx_td ltx_align_center" id="S1.T1.3.4.2">
      <span class="ltx_text" id="S1.T1.3.4.2.1" style="font-size:90%;color:#00FF00;">
       ✓
      </span>
     </td>
     <td class="ltx_td ltx_align_center" id="S1.T1.3.4.3">
      <span class="ltx_text" id="S1.T1.3.4.3.1" style="font-size:90%;color:#00FF00;">
       ✓
      </span>
     </td>
     <td class="ltx_td ltx_align_center" id="S1.T1.3.4.4">
      <span class="ltx_text" id="S1.T1.3.4.4.1" style="font-size:90%;color:#FF0000;">
       ✗
      </span>
     </td>
     <td class="ltx_td ltx_align_center" id="S1.T1.3.4.5">
      <span class="ltx_text" id="S1.T1.3.4.5.1" style="font-size:90%;color:#FF0000;">
       ✗
      </span>
     </td>
     <td class="ltx_td ltx_align_center" id="S1.T1.3.4.6">
      <span class="ltx_text" id="S1.T1.3.4.6.1" style="font-size:90%;color:#00FF00;">
       ✓
      </span>
     </td>
    </tr>
    <tr class="ltx_tr" id="S1.T1.3.5">
     <td class="ltx_td ltx_align_left" id="S1.T1.3.5.1">
      <span class="ltx_text" id="S1.T1.3.5.1.1" style="font-size:90%;">
       Agent Workflow Expression Language
      </span>
     </td>
     <td class="ltx_td ltx_align_center" id="S1.T1.3.5.2">
      <span class="ltx_text" id="S1.T1.3.5.2.1" style="font-size:90%;color:#FF0000;">
       ✗
      </span>
     </td>
     <td class="ltx_td ltx_align_center" id="S1.T1.3.5.3">
      <span class="ltx_text" id="S1.T1.3.5.3.1" style="font-size:90%;color:#FF0000;">
       ✗
      </span>
     </td>
     <td class="ltx_td ltx_align_center" id="S1.T1.3.5.4">
      <span class="ltx_text" id="S1.T1.3.5.4.1" style="font-size:90%;color:#FF0000;">
       ✗
      </span>
     </td>
     <td class="ltx_td ltx_align_center" id="S1.T1.3.5.5">
      <span class="ltx_text" id="S1.T1.3.5.5.1" style="font-size:90%;color:#FF0000;">
       ✗
      </span>
     </td>
     <td class="ltx_td ltx_align_center" id="S1.T1.3.5.6">
      <span class="ltx_text" id="S1.T1.3.5.6.1" style="font-size:90%;color:#00FF00;">
       ✓
      </span>
     </td>
    </tr>
    <tr class="ltx_tr" id="S1.T1.3.6">
     <td class="ltx_td ltx_align_left" id="S1.T1.3.6.1">
      <span class="ltx_text" id="S1.T1.3.6.1.1" style="font-size:90%;">
       Fine-tuned Text-to-SQL Model
      </span>
     </td>
     <td class="ltx_td ltx_align_center" id="S1.T1.3.6.2">
      <span class="ltx_text" id="S1.T1.3.6.2.1" style="font-size:90%;color:#FF0000;">
       ✗
      </span>
     </td>
     <td class="ltx_td ltx_align_center" id="S1.T1.3.6.3">
      <span class="ltx_text" id="S1.T1.3.6.3.1" style="font-size:90%;color:#00FF00;">
       ✓
      </span>
     </td>
     <td class="ltx_td ltx_align_center" id="S1.T1.3.6.4">
      <span class="ltx_text" id="S1.T1.3.6.4.1" style="font-size:90%;color:#FF0000;">
       ✗
      </span>
     </td>
     <td class="ltx_td ltx_align_center" id="S1.T1.3.6.5">
      <span class="ltx_text" id="S1.T1.3.6.5.1" style="font-size:90%;color:#FF0000;">
       ✗
      </span>
     </td>
     <td class="ltx_td ltx_align_center" id="S1.T1.3.6.6">
      <span class="ltx_text" id="S1.T1.3.6.6.1" style="font-size:90%;color:#00FF00;">
       ✓
      </span>
     </td>
    </tr>
    <tr class="ltx_tr" id="S1.T1.3.7">
     <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.3.7.1" rowspan="4">
      <span class="ltx_text" id="S1.T1.3.7.1.1" style="font-size:90%;">
       <span class="ltx_tabular ltx_align_middle" id="S1.T1.3.7.1.1.1">
        <span class="ltx_tr" id="S1.T1.3.7.1.1.1.1">
         <span class="ltx_td ltx_nopad_r ltx_align_center" id="S1.T1.3.7.1.1.1.1.1">
          <span class="ltx_text ltx_font_bold" id="S1.T1.3.7.1.1.1.1.1.1">
           Data Interaction
          </span>
         </span>
        </span>
        <span class="ltx_tr" id="S1.T1.3.7.1.1.1.2">
         <span class="ltx_td ltx_nopad_r ltx_align_center" id="S1.T1.3.7.1.1.1.2.1">
          <span class="ltx_text ltx_font_bold" id="S1.T1.3.7.1.1.1.2.1.1">
           Functionalities
          </span>
         </span>
        </span>
       </span>
      </span>
     </td>
     <td class="ltx_td ltx_align_left ltx_border_t" id="S1.T1.3.7.2">
      <span class="ltx_text" id="S1.T1.3.7.2.1" style="font-size:90%;">
       Text-to-SQL / SQL-to-Text
      </span>
     </td>
     <td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.3.7.3">
      <span class="ltx_text" id="S1.T1.3.7.3.1" style="font-size:90%;color:#00FF00;">
       ✓
      </span>
     </td>
     <td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.3.7.4">
      <span class="ltx_text" id="S1.T1.3.7.4.1" style="font-size:90%;color:#00FF00;">
       ✓
      </span>
     </td>
     <td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.3.7.5">
      <span class="ltx_text" id="S1.T1.3.7.5.1" style="font-size:90%;color:#FF0000;">
       ✗
      </span>
     </td>
     <td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.3.7.6">
      <span class="ltx_text" id="S1.T1.3.7.6.1" style="font-size:90%;color:#00FF00;">
       ✓
      </span>
     </td>
     <td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.3.7.7">
      <span class="ltx_text" id="S1.T1.3.7.7.1" style="font-size:90%;color:#00FF00;">
       ✓
      </span>
     </td>
    </tr>
    <tr class="ltx_tr" id="S1.T1.3.8">
     <td class="ltx_td ltx_align_left" id="S1.T1.3.8.1">
      <span class="ltx_text" id="S1.T1.3.8.1.1" style="font-size:90%;">
       Chat2DB / Chat2Data / Chat2Excel
      </span>
     </td>
     <td class="ltx_td ltx_align_center" id="S1.T1.3.8.2">
      <span class="ltx_text" id="S1.T1.3.8.2.1" style="font-size:90%;color:#00FF00;">
       ✓
      </span>
     </td>
     <td class="ltx_td ltx_align_center" id="S1.T1.3.8.3">
      <span class="ltx_text" id="S1.T1.3.8.3.1" style="font-size:90%;color:#00FF00;">
       ✓
      </span>
     </td>
     <td class="ltx_td ltx_align_center" id="S1.T1.3.8.4">
      <span class="ltx_text" id="S1.T1.3.8.4.1" style="font-size:90%;color:#FF0000;">
       ✗
      </span>
     </td>
     <td class="ltx_td ltx_align_center" id="S1.T1.3.8.5">
      <span class="ltx_text" id="S1.T1.3.8.5.1" style="font-size:90%;color:#00FF00;">
       ✓
      </span>
     </td>
     <td class="ltx_td ltx_align_center" id="S1.T1.3.8.6">
      <span class="ltx_text" id="S1.T1.3.8.6.1" style="font-size:90%;color:#00FF00;">
       ✓
      </span>
     </td>
    </tr>
    <tr class="ltx_tr" id="S1.T1.3.9">
     <td class="ltx_td ltx_align_left" id="S1.T1.3.9.1">
      <span class="ltx_text" id="S1.T1.3.9.1.1" style="font-size:90%;">
       Data Privacy and Security
      </span>
     </td>
     <td class="ltx_td ltx_align_center" id="S1.T1.3.9.2">
      <span class="ltx_text" id="S1.T1.3.9.2.1" style="font-size:90%;color:#FF0000;">
       ✗
      </span>
     </td>
     <td class="ltx_td ltx_align_center" id="S1.T1.3.9.3">
      <span class="ltx_text" id="S1.T1.3.9.3.1" style="font-size:90%;color:#FF0000;">
       ✗
      </span>
     </td>
     <td class="ltx_td ltx_align_center" id="S1.T1.3.9.4">
      <span class="ltx_text" id="S1.T1.3.9.4.1" style="font-size:90%;color:#00FF00;">
       ✓
      </span>
     </td>
     <td class="ltx_td ltx_align_center" id="S1.T1.3.9.5">
      <span class="ltx_text" id="S1.T1.3.9.5.1" style="font-size:90%;color:#FF0000;">
       ✗
      </span>
     </td>
     <td class="ltx_td ltx_align_center" id="S1.T1.3.9.6">
      <span class="ltx_text" id="S1.T1.3.9.6.1" style="font-size:90%;color:#00FF00;">
       ✓
      </span>
     </td>
    </tr>
    <tr class="ltx_tr" id="S1.T1.3.10">
     <td class="ltx_td ltx_align_left" id="S1.T1.3.10.1">
      <span class="ltx_text" id="S1.T1.3.10.1.1" style="font-size:90%;">
       Multilingual Interactions
      </span>
     </td>
     <td class="ltx_td ltx_align_center" id="S1.T1.3.10.2">
      <span class="ltx_text" id="S1.T1.3.10.2.1" style="font-size:90%;color:#FF0000;">
       ✗
      </span>
     </td>
     <td class="ltx_td ltx_align_center" id="S1.T1.3.10.3">
      <span class="ltx_text" id="S1.T1.3.10.3.1" style="font-size:90%;color:#FF0000;">
       ✗
      </span>
     </td>
     <td class="ltx_td ltx_align_center" id="S1.T1.3.10.4">
      <span class="ltx_text" id="S1.T1.3.10.4.1" style="font-size:90%;color:#FF0000;">
       ✗
      </span>
     </td>
     <td class="ltx_td ltx_align_center" id="S1.T1.3.10.5">
      <span class="ltx_text" id="S1.T1.3.10.5.1" style="font-size:90%;color:#00FF00;">
       ✓
      </span>
     </td>
     <td class="ltx_td ltx_align_center" id="S1.T1.3.10.6">
      <span class="ltx_text" id="S1.T1.3.10.6.1" style="font-size:90%;color:#00FF00;">
       ✓
      </span>
     </td>
    </tr>
    <tr class="ltx_tr" id="S1.T1.3.11">
     <td class="ltx_td ltx_border_b ltx_border_r" id="S1.T1.3.11.1">
     </td>
     <td class="ltx_td ltx_align_left ltx_border_b" id="S1.T1.3.11.2">
      <span class="ltx_text" id="S1.T1.3.11.2.1" style="font-size:90%;">
       Generative Data Analysis
      </span>
     </td>
     <td class="ltx_td ltx_align_center ltx_border_b" id="S1.T1.3.11.3">
      <span class="ltx_text" id="S1.T1.3.11.3.1" style="font-size:90%;color:#FF0000;">
       ✗
      </span>
     </td>
     <td class="ltx_td ltx_align_center ltx_border_b" id="S1.T1.3.11.4">
      <span class="ltx_text" id="S1.T1.3.11.4.1" style="font-size:90%;color:#FF0000;">
       ✗
      </span>
     </td>
     <td class="ltx_td ltx_align_center ltx_border_b" id="S1.T1.3.11.5">
      <span class="ltx_text" id="S1.T1.3.11.5.1" style="font-size:90%;color:#FF0000;">
       ✗
      </span>
     </td>
     <td class="ltx_td ltx_align_center ltx_border_b" id="S1.T1.3.11.6">
      <span class="ltx_text" id="S1.T1.3.11.6.1" style="font-size:90%;color:#FF0000;">
       ✗
      </span>
     </td>
     <td class="ltx_td ltx_align_center ltx_border_b" id="S1.T1.3.11.7">
      <span class="ltx_text" id="S1.T1.3.11.7.1" style="font-size:90%;color:#00FF00;">
       ✓
      </span>
     </td>
    </tr>
   </table>
  </figure>
  <div class="ltx_para" id="S1.p5">
   <p class="ltx_p" id="S1.p5.1">
    Additionally, the
    <span class="ltx_text ltx_font_italic" id="S1.p5.1.1">
     DB-GPT
    </span>
    community extends its support beyond basic functionalities, offering a suite of product-ready features designed to enhance data interaction capabilities. These include advanced knowledge extraction from diverse data sources for more accurate answers to users’ queries, specialized fine-tuning of Text-to-SQL Large Language Models (LLMs) to facilitate seamless database queries, and a user-friendly front-end interface for more convenient interaction. Furthermore,
    <span class="ltx_text ltx_font_italic" id="S1.p5.1.2">
     DB-GPT
    </span>
    supports multilingual functionality, accommodating both English and Chinese, thereby broadening its applicability and ease of use across different linguistic contexts. With these comprehensive, product-ready considerations,
    <span class="ltx_text ltx_font_italic" id="S1.p5.1.3">
     DB-GPT
    </span>
    is equipped to handle intricate data interaction tasks, such as generative data analysis, enabling users to seamlessly integrate and leverage its powerful functionalities within their product environments. This holistic approach ensures that
    <span class="ltx_text ltx_font_italic" id="S1.p5.1.4">
     DB-GPT
    </span>
    is not just a library, but a complete solution for developers and businesses aiming to harness the full potential of AI in the process of interacting with data. Table
    <a class="ltx_ref" href="#S1.T1" title="Table 1 ‣ 1. Introduction ‣ Demonstration of DB-GPT: Next Generation Data Interaction System Empowered by Large Language Models">
     <span class="ltx_text ltx_ref_tag">
      1
     </span>
    </a>
    shows the comparison between
    <span class="ltx_text ltx_font_italic" id="S1.p5.1.5">
     DB-GPT
    </span>
    and other popular tools from two main perspectives: system components and data interaction functionalities, showing the superiority of
    <span class="ltx_text ltx_font_italic" id="S1.p5.1.6">
     DB-GPT
    </span>
    .
   </p>
  </div>
  <figure class="ltx_figure" id="S1.F1">
   <p class="ltx_p ltx_align_center ltx_align_center" id="S1.F1.1.1">
    <span class="ltx_text" id="S1.F1.1.1.1">
     <img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="427" id="S1.F1.1.1.1.g1" src="/html/2404.10209/assets/x1.png" width="553"/>
    </span>
   </p>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     Figure 1.
    </span>
    System Design of DB-GPT
   </figcaption>
  </figure>
  <div class="ltx_para" id="S1.p6">
   <p class="ltx_p" id="S1.p6.1">
    To summarize, we make the following contributions:
1) we propose
    <span class="ltx_text ltx_font_italic" id="S1.p6.1.1">
     DB-GPT
    </span>
    , an open-sourced and product-ready library supporting an end-to-end interaction with data.
2) we propose Multi-Agents Framework in
    <span class="ltx_text ltx_font_italic" id="S1.p6.1.2">
     DB-GPT
    </span>
    for solving complex data interaction tasks like generative data analysis.
3) we propose
    <span class="ltx_text ltx_font_italic" id="S1.p6.1.3">
     Agentic Workflow Expression Language (AWEL)
    </span>
    to enhance the practicability and flexibility of Multi-Agents in
    <span class="ltx_text ltx_font_italic" id="S1.p6.1.4">
     DB-GPT
    </span>
    .
4) we propose
    <span class="ltx_text ltx_font_italic" id="S1.p6.1.5">
     Service-oriented Multi-model Management Framework (SMMF)
    </span>
    to promise the users’ privacy from the model perspective in
    <span class="ltx_text ltx_font_italic" id="S1.p6.1.6">
     DB-GPT
    </span>
    .
5) we deploy
    <span class="ltx_text ltx_font_italic" id="S1.p6.1.7">
     DB-GPT
    </span>
    as an application with user-friendly interface and demonstrate its utility. We also open-sourced the implementation of
    <span class="ltx_text ltx_font_italic" id="S1.p6.1.8">
     DB-GPT
    </span>
    on
    <a class="ltx_ref ltx_href" href="https://github.com/eosphoros-ai/DB-GPT" style="color:#0000FF;" target="_blank" title="">
     Github
    </a>
    , which already has
    <span class="ltx_text ltx_font_bold" id="S1.p6.1.9">
     over 10.7k stars
    </span>
    .
   </p>
  </div>
 </section>
 <section class="ltx_section" id="S2">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    2.
   </span>
   System Design
  </h2>
  <div class="ltx_para" id="S2.p1">
   <p class="ltx_p" id="S2.p1.1">
    The overall system design of
    <span class="ltx_text ltx_font_italic" id="S2.p1.1.1">
     DB-GPT
    </span>
    is depicted in Figure
    <a class="ltx_ref" href="#S1.F1" title="Figure 1 ‣ 1. Introduction ‣ Demonstration of DB-GPT: Next Generation Data Interaction System Empowered by Large Language Models">
     <span class="ltx_text ltx_ref_tag">
      1
     </span>
    </a>
    .
    <span class="ltx_text ltx_font_italic" id="S2.p1.1.2">
     DB-GPT
    </span>
    includes four layers, i.e. the protocol layer, the module layer, the server layer and the application layer. In this section, we delineate the design of each phase with a top-down manner. There are also other layers making
    <span class="ltx_text ltx_font_italic" id="S2.p1.1.3">
     DB-GPT
    </span>
    product-ready. We also introduce the design of these layers in this section.
   </p>
  </div>
  <section class="ltx_subsection" id="S2.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     2.1.
    </span>
    The Application Layer
   </h3>
   <div class="ltx_para" id="S2.SS1.p1">
    <p class="ltx_p" id="S2.SS1.p1.1">
     The application layer encompasses the array of data interaction functionalities supported by DB-GPT. These include, but are not limited to, Text-to-SQL/SQL-to-Text, chat-to-database interactions (chat2db), chat-to-data queries (chat2data), chat-to-Excel operations (chat2excel), chat-to-visualization commands (chat2visualization), generative data analysis, and question answering based on knowledge bases. These functionalities include the majority of foundational tasks associated with data interaction, illustrating the comprehensive capabilities of the DB-GPT framework.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S2.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     2.2.
    </span>
    The Server Layer
   </h3>
   <div class="ltx_para" id="S2.SS2.p1">
    <p class="ltx_p" id="S2.SS2.p1.1">
     The server layer in
     <span class="ltx_text ltx_font_italic" id="S2.SS2.p1.1.1">
      DB-GPT
     </span>
     is an optional component that manages external inputs, such as HTTP requests, by integrating them with domain knowledge to guide lower-tier layers, i.e. the Module Layer. This layer’s optional status allows for direct communication between the application layer and the module layer in simple scenarios. In contexts that necessitate external inputs, the server layer acts as a supplementary intermediary, underscoring its utility in supporting a wider range of applications.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S2.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     2.3.
    </span>
    The Module Layer
   </h3>
   <div class="ltx_para" id="S2.SS3.p1">
    <p class="ltx_p" id="S2.SS3.p1.1">
     The module layer of
     <span class="ltx_text ltx_font_italic" id="S2.SS3.p1.1.1">
      DB-GPT
     </span>
     is composed by
     <span class="ltx_text ltx_font_italic" id="S2.SS3.p1.1.2">
      Service-oriented Multi-model Management Framework (SMMF), Retrieval-Augmented Generation (RAG) from Multiple Data Source
     </span>
     and
     <span class="ltx_text ltx_font_italic" id="S2.SS3.p1.1.3">
      Multi-Agents Framework
     </span>
     . The three parts of the module layer are most important to support users’ interaction with their data, which is shown in the Application Layer.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S2.SS3.p2">
    <p class="ltx_p" id="S2.SS3.p2.1">
     <span class="ltx_text ltx_font_bold" id="S2.SS3.p2.1.1">
      Service-oriented Multi-model Management Framework (SMMF).
     </span>
     The Service-oriented Multi-model Framework (SMMF) in the context of DB-GPT aims at facilitating model adaptation, enhancing deployment efficiency, and optimizing performance. SMMF offers a streamlined platform for the deployment and inference of Multi-Large Language Models (Multi-LLMs), enabling local execution of users’ own LLMs to ensure data privacy and security.
    </p>
   </div>
   <figure class="ltx_figure" id="S2.F2">
    <p class="ltx_p ltx_align_center ltx_align_center" id="S2.F2.1.1">
     <span class="ltx_text" id="S2.F2.1.1.1">
      <img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="69" id="S2.F2.1.1.1.g1" src="/html/2404.10209/assets/x2.png" width="392"/>
     </span>
    </p>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      Figure 2.
     </span>
     The RAG architecture in DB-GPT
    </figcaption>
   </figure>
   <div class="ltx_para" id="S2.SS3.p3">
    <p class="ltx_p" id="S2.SS3.p3.1">
     SMMF is underpinned by two core components: the model inference layer and the model deployment layer. The inference layer supports various LLM inference frameworks, enhancing the framework’s flexibility. The deployment layer connects inference mechanisms with model serving capabilities, incorporating an API server and a model handler for robust functionality. At its core, the model controller manages metadata, integrating the deployment process, while the model worker establishes connectivity with inference and infrastructure, ensuring efficient model operation. Through SMMF, DB-GPT provides an efficient approach to deploying machine learning models in a cloud environment, highlighting the framework’s potential in improving adaptability, performance, and data security in MaaS applications.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S2.SS3.p4">
    <p class="ltx_p" id="S2.SS3.p4.1">
     <span class="ltx_text ltx_font_bold" id="S2.SS3.p4.1.1">
      Retrieval-Augmented Generation (RAG) from Multiple Data Source.
     </span>
     While LLMs are usually trained on enormous bodies of open sourced or other parties’ proprietary data, RAG
     <cite class="ltx_cite ltx_citemacro_citep">
      (Lewis et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib8" title="">
       2020
      </a>
      )
     </cite>
     is a technique for augmenting LLMs’ knowledge with additional and often private data. Shown in Figure
     <a class="ltx_ref" href="#S2.F2" title="Figure 2 ‣ 2.3. The Module Layer ‣ 2. System Design ‣ Demonstration of DB-GPT: Next Generation Data Interaction System Empowered by Large Language Models">
      <span class="ltx_text ltx_ref_tag">
       2
      </span>
     </a>
     , our RAG pipeline consists of three stages: knowledge construction, knowledge retrieval and adaptive In-Contextual Learning (ICL)
     <cite class="ltx_cite ltx_citemacro_citep">
      (Dong et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib3" title="">
       2022
      </a>
      )
     </cite>
     strategies.
    </p>
   </div>
   <div class="ltx_para" id="S2.SS3.p5">
    <p class="ltx_p" id="S2.SS3.p5.4">
     For knowledge construction, DB-GPT constructs a knowledge base according to multiple data sources provided by users. Contents in each data source are segmented into paragraphs, with each paragraph encoded into a multidimensional vector using a neural encoder. Notably, DB-GPT enhances traditional vector-based knowledge representation by integrating inverted index and graph index methods, facilitating precise context-relevant data retrieval.
For knowledge retrieval, upon receiving a query
     <math alttext="x" class="ltx_Math" display="inline" id="S2.SS3.p5.1.m1.1">
      <semantics id="S2.SS3.p5.1.m1.1a">
       <mi id="S2.SS3.p5.1.m1.1.1" xref="S2.SS3.p5.1.m1.1.1.cmml">
        x
       </mi>
       <annotation-xml encoding="MathML-Content" id="S2.SS3.p5.1.m1.1b">
        <ci id="S2.SS3.p5.1.m1.1.1.cmml" xref="S2.SS3.p5.1.m1.1.1">
         𝑥
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.SS3.p5.1.m1.1c">
        x
       </annotation>
      </semantics>
     </math>
     , it is transformed into a query vector
     <math alttext="q" class="ltx_Math" display="inline" id="S2.SS3.p5.2.m2.1">
      <semantics id="S2.SS3.p5.2.m2.1a">
       <mi id="S2.SS3.p5.2.m2.1.1" xref="S2.SS3.p5.2.m2.1.1.cmml">
        q
       </mi>
       <annotation-xml encoding="MathML-Content" id="S2.SS3.p5.2.m2.1b">
        <ci id="S2.SS3.p5.2.m2.1.1.cmml" xref="S2.SS3.p5.2.m2.1.1">
         𝑞
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.SS3.p5.2.m2.1c">
        q
       </annotation>
      </semantics>
     </math>
     . DB-GPT then identifies the top-
     <math alttext="k" class="ltx_Math" display="inline" id="S2.SS3.p5.3.m3.1">
      <semantics id="S2.SS3.p5.3.m3.1a">
       <mi id="S2.SS3.p5.3.m3.1.1" xref="S2.SS3.p5.3.m3.1.1.cmml">
        k
       </mi>
       <annotation-xml encoding="MathML-Content" id="S2.SS3.p5.3.m3.1b">
        <ci id="S2.SS3.p5.3.m3.1.1.cmml" xref="S2.SS3.p5.3.m3.1.1">
         𝑘
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.SS3.p5.3.m3.1c">
        k
       </annotation>
      </semantics>
     </math>
     paragraphs within the knowledge base that are most relevant to
     <math alttext="q" class="ltx_Math" display="inline" id="S2.SS3.p5.4.m4.1">
      <semantics id="S2.SS3.p5.4.m4.1a">
       <mi id="S2.SS3.p5.4.m4.1.1" xref="S2.SS3.p5.4.m4.1.1.cmml">
        q
       </mi>
       <annotation-xml encoding="MathML-Content" id="S2.SS3.p5.4.m4.1b">
        <ci id="S2.SS3.p5.4.m4.1.1.cmml" xref="S2.SS3.p5.4.m4.1.1">
         𝑞
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.SS3.p5.4.m4.1c">
        q
       </annotation>
      </semantics>
     </math>
     . DB-GPT employs diverse retrieval strategies for prioritizing relevant documents, including ordering based on the cosine similarity of their embedded vectors, as well as categorization according to keyword similarity.
In the adaptive iterative contextualization phase, DB-GPT employs Interactive Contextual Learning (ICL) for generating responses. ICL enhances DB-GPT’s response by integrating knowledge retrieval results during LLMs’ inference. It incorporates them into a predefined prompt template to get response from LLM. The efficacy of ICL depends on specific configurations such as prompt templates. Our DB-GPT system provides various strategies for prompt formulation and incorporates privacy measures to protect private information. Due to the page limit, please see
     <cite class="ltx_cite ltx_citemacro_citep">
      (Xue et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib18" title="">
       2023a
      </a>
      )
     </cite>
     for the full details.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S2.SS3.p6">
    <p class="ltx_p" id="S2.SS3.p6.1">
     <span class="ltx_text ltx_font_bold" id="S2.SS3.p6.1.1">
      Multi-Agents Framework.
     </span>
     Inspired by
     <a class="ltx_ref ltx_href" href="https://github.com/geekan/MetaGPT" style="color:#0000FF;" target="_blank" title="">
      MetaGPT
     </a>
     and
     <a class="ltx_ref ltx_href" href="https://microsoft.github.io/autogen/" style="color:#0000FF;" target="_blank" title="">
      AutoGen
     </a>
     , when dealing with challenging data interaction tasks such as generative data analysis, DB-GPT proposes its own Multi-Agent framework. The proposed framework leverages the specialized capabilities and communicative interactions of multiple agents to effectively address multifaceted challenges. For example, consider the task of constructing detailed sales reports from at least three distinct dimensions. The Multi-Agent framework initiates this process by deploying a planning agent to devise a comprehensive strategy, which includes the creation of: 1) a donut chart for the analysis of total sales by product category, 2) a bar chart for examining sales data from the perspective of user demographics, and 3) an area chart for evaluating monthly sales trends. Subsequent to the planning phase, dedicated chart-generating agents are tasked with the production of these visual representations, which are then aggregated by the planner and presented to users.
    </p>
   </div>
   <div class="ltx_para" id="S2.SS3.p7">
    <p class="ltx_p" id="S2.SS3.p7.1">
     Compared to MetaGPT and AutoGen, DB-GPT’s Multi-Agent framework archives the entire communication history among its agents within a local storage system, thereby significantly enhancing the reliability of the generated content of agents. Furthermore, in contrast to the LlamaIndex framework, which prescribes a set of constrained behaviours tailored to specific use cases, DB-GPT’s framework offers flexibility which allows users to custom-define agents tailored to their specific data interaction tasks, thus affording a broader applicability across various domains.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S2.SS4">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     2.4.
    </span>
    The Protocol Layer
   </h3>
   <div class="ltx_para" id="S2.SS4.p1">
    <p class="ltx_p" id="S2.SS4.p1.1">
     The protocol layer in
     <span class="ltx_text ltx_font_italic" id="S2.SS4.p1.1.1">
      DB-GPT
     </span>
     mainly includes
     <span class="ltx_text ltx_font_italic" id="S2.SS4.p1.1.2">
      Agentic Workflow Expression Language (AWEL)
     </span>
     ,
which adopts the big data processing concepts of
     <a class="ltx_ref ltx_href" href="https://airflow.apache.org/" style="color:#0000FF;" target="_blank" title="">
      Apache Airflow
     </a>
     . By leveraging Directed Acyclic Graphs (DAGs), AWEL orchestrates workflows, aligning with Apache Airflow’s mission to efficiently define, schedule, and oversee complex data pipelines and workflows.
    </p>
   </div>
   <div class="ltx_para" id="S2.SS4.p2">
    <p class="ltx_p" id="S2.SS4.p2.1">
     In Apache Airflow, the core components of these workflows are operators, where each operator represents a discrete task or operation capable of executing defined actions. Reflecting this approach,
     <span class="ltx_text ltx_font_italic" id="S2.SS4.p2.1.1">
      DB-GPT
     </span>
     ’s AWEL models each agent as a distinct operator, thus enabling users to intricately design their agent-based workflows. This is achieved by interconnecting multiple agents to construct a DAG. Such a design grants users the flexibility to manipulate the flow of information between agents. Consequently, users can seamlessly integrate their comprehension of specific data interaction tasks with the actionable insights generated by LLM-based agents.
    </p>
   </div>
   <div class="ltx_para" id="S2.SS4.p3">
    <p class="ltx_p" id="S2.SS4.p3.1">
     Employing AWEL within
     <span class="ltx_text ltx_font_italic" id="S2.SS4.p3.1.1">
      DB-GPT
     </span>
     empowers it to support a variety of tasks including stream processing, batch processing, and asynchronous operations. This capability significantly bolsters
     <span class="ltx_text ltx_font_italic" id="S2.SS4.p3.1.2">
      DB-GPT
     </span>
     ’s effectiveness and applicability in navigating the complexities of real-world production environments.
    </p>
   </div>
   <figure class="ltx_figure" id="S2.F3">
    <p class="ltx_p ltx_align_center ltx_align_center" id="S2.F3.1.1">
     <span class="ltx_text" id="S2.F3.1.1.1">
      <img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="284" id="S2.F3.1.1.1.g1" src="/html/2404.10209/assets/x3.png" width="461"/>
     </span>
    </p>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      Figure 3.
     </span>
     Demonstration of DB-GPT
    </figcaption>
   </figure>
  </section>
  <section class="ltx_subsection" id="S2.SS5">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     2.5.
    </span>
    Other Layers
   </h3>
   <div class="ltx_para ltx_noindent" id="S2.SS5.p1">
    <p class="ltx_p" id="S2.SS5.p1.1">
     <span class="ltx_text ltx_font_bold" id="S2.SS5.p1.1.1">
      Visualization Layer.
     </span>
     The visualization layer aims to display the answers returned by DB-GPT to the users with elegance. For scenarios involving purely textual question-and-answer formats, this layer exhibits the textual outputs generated by DB-GPT. When the tasks necessitate the generation of charts, DB-GPT renders these charts within its front-end, facilitating user interaction with the displayed charts. The significance of possessing a sophisticated visualization layer within DB-GPT cannot be overstated, as practical applications demand that users engage in multiple interactions with their data to successfully complete their data interaction tasks. Superior visualization capabilities significantly expedite users’ comprehension of their data, thereby enhancing the overall effectiveness and user experience of the system.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S2.SS5.p2">
    <p class="ltx_p" id="S2.SS5.p2.1">
     <span class="ltx_text ltx_font_bold" id="S2.SS5.p2.1.1">
      Text-to-SQL Fine-Tuning.
     </span>
     Although LLMs,.e.g., CodeX and ChatGPT, have shown successful results for Text-to-SQL, they still have a gap with the fine-tuned alternatives in specific application scenarios. Consequently, tailoring LLMs to domain-specific Text-to-SQL datasets emerges as a crucial step towards enhancing their comprehension of prompts and facilitating superior outcomes.
Within DB-GPT, we have introduced a component, termed DB-GPT-Hub, which serves to encapsulate the Text-to-SQL fine-tuning process. This module enables users to refine their Text-to-SQL LLMs using publicly available LLMs hosted on Huggingface in conjunction with their own Text-to-SQL data pairs. Moreover, our SMMF framework accords users the flexibility to employ their fine-tuned LLMs in a localized manner, which underscores our commitment to data privacy and security.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S2.SS5.p3">
    <p class="ltx_p" id="S2.SS5.p3.1">
     <span class="ltx_text ltx_font_bold" id="S2.SS5.p3.1.1">
      Execution Environments.
     </span>
     DB-GPT is capable of operating within distributed environments through the employment of the distributed framework Ray, as well as within cloud ecosystems such as AWS Cloud, Alibaba Cloud, and private cloud configurations maintained by users. This operational flexibility underscores DB-GPT’s adeptness at accommodating a variety of data storage contexts. Furthermore, it exemplifies the wide applicability of DB-GPT across diverse operational requirements and environments.
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="S3">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    3.
   </span>
   Demonstration
  </h2>
  <div class="ltx_para" id="S3.p1">
   <p class="ltx_p" id="S3.p1.1">
    The demonstration setup includes a table need to be standardized and a laptop. The laptop must connect to the Internet for visitors can use DB-GPT smoothly with OpenAI’s GPT service. Visitors can also choose local models such as Qwen and GLM. If the conference Internet fails, a mobile hotspot (established via cell phone) can also be used for running DB-GPT.
   </p>
  </div>
  <div class="ltx_para" id="S3.p2">
   <p class="ltx_p" id="S3.p2.1">
    Figure
    <a class="ltx_ref" href="#S2.F3" title="Figure 3 ‣ 2.4. The Protocol Layer ‣ 2. System Design ‣ Demonstration of DB-GPT: Next Generation Data Interaction System Empowered by Large Language Models">
     <span class="ltx_text ltx_ref_tag">
      3
     </span>
    </a>
    illustrates the capability of DB-GPT to perform generative data analysis. When users are faced with a data interaction task, they initiate the process by starting a new chat session (area ①) and entering a command such as "Build sales reports and analyze user orders from at least three distinct dimensions" (area ②). DB-GPT undertakes this task utilizing its Multi-Agent framework, which begins with invoking a planner to generate a four-step strategy tailored to the task (area ③). Then, three specialized agents, designated for the creation of data analytics charts, proceed to generate sales reports (area ④). These report takes into account various dimensions, including product category, user name and month. Another agent, dedicated to aggregating these charts, collects, organizes, and presents them on the front-end interface (area ⑤). The interface allows users to interact with the displayed charts, offering the flexibility to alter chart types according to their preferences (area ⑥). If users need further data interaction tasks to be performed, they can continue to engage with their data through natural language inputs (area ⑦).
   </p>
  </div>
 </section>
 <section class="ltx_section" id="S4">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    4.
   </span>
   Conclusion
  </h2>
  <div class="ltx_para" id="S4.p1">
   <p class="ltx_p" id="S4.p1.1">
    In this paper, we proposed DB-GPT, a revolutionary and product-ready Python library that understands data interaction tasks described by natural language and provides responses powered by LLMs. With the four-layer system design, DB-GPT can handle complex data interaction tasks with privacy consideration. In the future, DB-GPT will adapt more data interaction needs with its code-free agentic workflow.
   </p>
  </div>
  <div class="ltx_para" id="S4.p2">
   <p class="ltx_p" id="S4.p2.1">
    Future research directions include: 1) introducing powerful agents providing more powerful abilities, such as time series predictions
    <cite class="ltx_cite ltx_citemacro_citep">
     (Jin et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib7" title="">
      2023
     </a>
     ; Xue et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib21" title="">
      2021
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib22" title="">
      2022b
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib20" title="">
      2023b
     </a>
     ; Shi et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib16" title="">
      2023
     </a>
     )
    </cite>
    based on historical data and predictive decision abilities
    <cite class="ltx_cite ltx_citemacro_citep">
     (Xue et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib19" title="">
      2022a
     </a>
     ; Qu et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib14" title="">
      2023
     </a>
     )
    </cite>
    and automatic data preparation
    <cite class="ltx_cite ltx_citemacro_citep">
     (Qi et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib11" title="">
      2023
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib13" title="">
      2024
     </a>
     ; Qi and Wang,
     <a class="ltx_ref" href="#bib.bib12" title="">
      2024
     </a>
     )
    </cite>
    ; 2) the integration of more model training techniques. In addition to pre-training, the community is also interested in continual learning techniques for language models, such as continual pre-training
    <cite class="ltx_cite ltx_citemacro_citep">
     (Jiang et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib6" title="">
      2023
     </a>
     )
    </cite>
    , prompt learning
    <cite class="ltx_cite ltx_citemacro_citep">
     (Wang et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib17" title="">
      2022
     </a>
     ; Xue et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib23" title="">
      2023c
     </a>
     )
    </cite>
    .
   </p>
  </div>
 </section>
 <section class="ltx_bibliography" id="bib">
  <h2 class="ltx_title ltx_title_bibliography">
   References
  </h2>
  <ul class="ltx_biblist">
   <li class="ltx_bibitem" id="bib.bib1">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     (1)
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib2">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chase (2022)
    </span>
    <span class="ltx_bibblock">
     Harrison Chase. 2022.
    </span>
    <span class="ltx_bibblock">
     LangChain.
    </span>
    <span class="ltx_bibblock">
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/hwchase17/langchain" target="_blank" title="">
      https://github.com/hwchase17/langchain
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib3">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Dong et al
     <span class="ltx_text" id="bib.bib3.2.2.1">
      .
     </span>
     (2022)
    </span>
    <span class="ltx_bibblock">
     Qingxiu Dong, Lei Li, Damai Dai, Ce Zheng, Zhiyong Wu, Baobao Chang, Xu Sun, Jingjing Xu, and Zhifang Sui. 2022.
    </span>
    <span class="ltx_bibblock">
     A Survey on In-context Learning.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://api.semanticscholar.org/CorpusID:255372865" target="_blank" title="">
      https://api.semanticscholar.org/CorpusID:255372865
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib4">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     H2O.ai (2023)
    </span>
    <span class="ltx_bibblock">
     H2O.ai. 2023.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">
      H2OGPT
     </em>
     .
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/h2oai/h2ogpt" target="_blank" title="">
      https://github.com/h2oai/h2ogpt
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib5">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Hu et al
     <span class="ltx_text" id="bib.bib5.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Chenxu Hu, Jie Fu, Chenzhuang Du, Simian Luo, Junbo Zhao, and Hang Zhao. 2023.
    </span>
    <span class="ltx_bibblock">
     ChatDB: Augmenting LLMs with Databases as Their Symbolic Memory.
    </span>
    <span class="ltx_bibblock">
    </span>
    <span class="ltx_bibblock">
     arXiv:2306.03901 [cs.AI]
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib6">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Jiang et al
     <span class="ltx_text" id="bib.bib6.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Gangwei Jiang, Caigao Jiang, Siqiao Xue, James Y. Zhang, Jun Zhou, Defu Lian, and Ying Wei. 2023.
    </span>
    <span class="ltx_bibblock">
     Towards Anytime Fine-tuning: Continually Pre-trained Language Models with Hypernetwork Prompt. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib6.3.1">
      Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing (EMNLP)
     </em>
     .
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib7">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Jin et al
     <span class="ltx_text" id="bib.bib7.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Ming Jin, Qingsong Wen, Yuxuan Liang, Chaoli Zhang, Siqiao Xue, Xue Wang, James Zhang, Yi Wang, Haifeng Chen, Xiaoli Li, Shirui Pan, Vincent S. Tseng, Yu Zheng, Lei Chen, and Hui Xiong. 2023.
    </span>
    <span class="ltx_bibblock">
     Large Models for Time Series and Spatio-Temporal Data: A Survey and Outlook.
    </span>
    <span class="ltx_bibblock">
    </span>
    <span class="ltx_bibblock">
     arXiv:2310.10196 [cs.LG]
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib8">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Lewis et al
     <span class="ltx_text" id="bib.bib8.2.2.1">
      .
     </span>
     (2020)
    </span>
    <span class="ltx_bibblock">
     Patrick Lewis, Ethan Perez, Aleksandara Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Kuttler, Mike Lewis, Wen tau Yih, Tim Rocktäschel, Sebastian Riedel, and Douwe Kiela. 2020.
    </span>
    <span class="ltx_bibblock">
     Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib8.3.1">
      ArXiv
     </em>
     abs/2005.11401 (2020).
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://api.semanticscholar.org/CorpusID:218869575" target="_blank" title="">
      https://api.semanticscholar.org/CorpusID:218869575
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib9">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Liu (2022)
    </span>
    <span class="ltx_bibblock">
     Jerry Liu. 2022.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">
      LlamaIndex
     </em>
     .
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.5281/zenodo.1234" target="_blank" title="">
      https://doi.org/10.5281/zenodo.1234
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib10">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Martínez et al
     <span class="ltx_text" id="bib.bib10.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Iván Martínez, Daniel Gallego Vico, and Pablo Orgaz. 2023.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib10.3.1">
      PrivateGPT
     </em>
     .
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/imartinez/privateGPT" target="_blank" title="">
      https://github.com/imartinez/privateGPT
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib11">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Qi et al
     <span class="ltx_text" id="bib.bib11.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Danrui Qi, Jinglin Peng, Yongjun He, and Jiannan Wang. 2023.
    </span>
    <span class="ltx_bibblock">
     Auto-FP: An Experimental Study of Automated Feature Preprocessing for Tabular Data.
    </span>
    <span class="ltx_bibblock">
    </span>
    <span class="ltx_bibblock">
     arXiv:2310.02540 [cs.LG]
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib12">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Qi and Wang (2024)
    </span>
    <span class="ltx_bibblock">
     Danrui Qi and Jiannan Wang. 2024.
    </span>
    <span class="ltx_bibblock">
     CleanAgent: Automating Data Standardization with LLM-based Agents.
    </span>
    <span class="ltx_bibblock">
    </span>
    <span class="ltx_bibblock">
     arXiv:2403.08291 [cs.LG]
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib13">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Qi et al
     <span class="ltx_text" id="bib.bib13.2.2.1">
      .
     </span>
     (2024)
    </span>
    <span class="ltx_bibblock">
     Danrui Qi, Weiling Zheng, and Jiannan Wang. 2024.
    </span>
    <span class="ltx_bibblock">
     FeatAug: Automatic Feature Augmentation From One-to-Many Relationship Tables.
    </span>
    <span class="ltx_bibblock">
    </span>
    <span class="ltx_bibblock">
     arXiv:2403.06367 [cs.LG]
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib14">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Qu et al
     <span class="ltx_text" id="bib.bib14.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Chao Qu, Xiaoyu Tan, Siqiao Xue, Xiaoming Shi, James Zhang, and Hongyuan Mei. 2023.
    </span>
    <span class="ltx_bibblock">
     Bellman Meets Hawkes: Model-Based Reinforcement Learning via Temporal Point Processes.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2201.12569" target="_blank" title="">
      https://arxiv.org/abs/2201.12569
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib15">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Richards (2022)
    </span>
    <span class="ltx_bibblock">
     Toran Bruce Richards. 2022.
    </span>
    <span class="ltx_bibblock">
     AutoGPT.
    </span>
    <span class="ltx_bibblock">
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/Significant-Gravitas/AutoGPT" target="_blank" title="">
      https://github.com/Significant-Gravitas/AutoGPT
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib16">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Shi et al
     <span class="ltx_text" id="bib.bib16.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Xiaoming Shi, Siqiao Xue, Kangrui Wang, Fan Zhou, James Y. Zhang, Jun Zhou, Chenhao Tan, and Hongyuan Mei. 2023.
    </span>
    <span class="ltx_bibblock">
     Language Models Can Improve Event Prediction by Few-Shot Abductive Reasoning. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib16.3.1">
      Advances in Neural Information Processing Systems
     </em>
     .
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2305.16646" target="_blank" title="">
      https://arxiv.org/abs/2305.16646
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib17">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang et al
     <span class="ltx_text" id="bib.bib17.2.2.1">
      .
     </span>
     (2022)
    </span>
    <span class="ltx_bibblock">
     Zifeng Wang, Zizhao Zhang, Chen-Yu Lee, Han Zhang, Ruoxi Sun, Xiaoqi Ren, Guolong Su, Vincent Perot, Jennifer Dy, and Tomas Pfister. 2022.
    </span>
    <span class="ltx_bibblock">
     Learning to prompt for continual learning. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib17.3.1">
      Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition
     </em>
     . 139–149.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib18">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Xue et al
     <span class="ltx_text" id="bib.bib18.2.2.1">
      .
     </span>
     (2023a)
    </span>
    <span class="ltx_bibblock">
     Siqiao Xue, Caigao Jiang, Wenhui Shi, Fangyin Cheng, Keting Chen, Hongjun Yang, Zhiping Zhang, Jianshan He, Hongyang Zhang, Ganglin Wei, Wang Zhao, Fan Zhou, Danrui Qi, Hong Yi, Shaodong Liu, and Faqiang Chen. 2023a.
    </span>
    <span class="ltx_bibblock">
     DB-GPT: Empowering Database Interactions with Private Large Language Models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib18.3.1">
      arXiv preprint arXiv:2312.17449
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2312.17449" target="_blank" title="">
      https://arxiv.org/abs/2312.17449
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib19">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Xue et al
     <span class="ltx_text" id="bib.bib19.2.2.1">
      .
     </span>
     (2022a)
    </span>
    <span class="ltx_bibblock">
     Siqiao Xue, Chao Qu, Xiaoming Shi, Cong Liao, Shiyi Zhu, Xiaoyu Tan, Lintao Ma, Shiyu Wang, Shijun Wang, Yun Hu, Lei Lei, Yangfei Zheng, Jianguo Li, and James Zhang. 2022a.
    </span>
    <span class="ltx_bibblock">
     A Meta Reinforcement Learning Approach for Predictive Autoscaling in the Cloud. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib19.3.1">
      KDD ’22: The 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, Washington, DC, USA, August 14 - 18, 2022
     </em>
     , Aidong Zhang and Huzefa Rangwala (Eds.). ACM, 4290–4299.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3534678.3539063" target="_blank" title="">
      https://doi.org/10.1145/3534678.3539063
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib20">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Xue et al
     <span class="ltx_text" id="bib.bib20.2.2.1">
      .
     </span>
     (2023b)
    </span>
    <span class="ltx_bibblock">
     Siqiao Xue, Xiaoming Shi, Zhixuan Chu, Yan Wang, Fan Zhou, Hongyan Hao, Caigao Jiang, Chen Pan, Yi Xu, James Y. Zhang, Qingsong Wen, Jun Zhou, and Hongyuan Mei. 2023b.
    </span>
    <span class="ltx_bibblock">
     EasyTPP: Towards Open Benchmarking the Temporal Point Processes.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib20.3.1">
      arXiv preprint arXiv:2307.08097
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2307.08097" target="_blank" title="">
      https://arxiv.org/abs/2307.08097
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib21">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Xue et al
     <span class="ltx_text" id="bib.bib21.2.2.1">
      .
     </span>
     (2021)
    </span>
    <span class="ltx_bibblock">
     Siqiao Xue, Xiaoming Shi, Hongyan Hao, Lintao Ma, James Zhang, Shiyu Wang, and Shijun Wang. 2021.
    </span>
    <span class="ltx_bibblock">
     A Graph Regularized Point Process Model For Event Propagation Sequence. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib21.3.1">
      IJCNN
     </em>
     . 1–7.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib22">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Xue et al
     <span class="ltx_text" id="bib.bib22.2.2.1">
      .
     </span>
     (2022b)
    </span>
    <span class="ltx_bibblock">
     Siqiao Xue, Xiaoming Shi, Y James Zhang, and Hongyuan Mei. 2022b.
    </span>
    <span class="ltx_bibblock">
     HYPRO: A Hybridly Normalized Probabilistic Model for Long-Horizon Prediction of Event Sequences. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib22.3.1">
      Advances in Neural Information Processing Systems
     </em>
     .
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2210.01753" target="_blank" title="">
      https://arxiv.org/abs/2210.01753
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib23">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Xue et al
     <span class="ltx_text" id="bib.bib23.2.2.1">
      .
     </span>
     (2023c)
    </span>
    <span class="ltx_bibblock">
     Siqiao Xue, Yan Wang, Zhixuan Chu, Xiaoming Shi, Caigao Jiang, Hongyan Hao, Gangwei Jiang, Xiaoyun Feng, James Zhang, and Jun Zhou. 2023c.
    </span>
    <span class="ltx_bibblock">
     Prompt-augmented Temporal Point Process for Streaming Event Sequence. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib23.3.1">
      NeurIPS
     </em>
     .
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
  </ul>
 </section>
 <div class="ltx_pagination ltx_role_newpage">
 </div>
</article>
