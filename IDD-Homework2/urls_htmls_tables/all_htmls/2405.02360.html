<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2405.02360] Holistic Evaluation Metrics: Use Case Sensitive Evaluation Metrics for Federated Learning</title><meta property="og:description" content="A large number of federated learning (FL) algorithms have been proposed for different applications and from varying perspectives. However, the evaluation of such approaches often relies on a single metric (e.g., accura…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Holistic Evaluation Metrics: Use Case Sensitive Evaluation Metrics for Federated Learning">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Holistic Evaluation Metrics: Use Case Sensitive Evaluation Metrics for Federated Learning">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2405.02360">

<!--Generated on Wed Jun  5 17:37:33 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="
Federated Learning (FL),  Decentralized Machine Learning (DML),  Evaluation Metrics,  Collaboration Application
">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Holistic Evaluation Metrics: Use Case Sensitive Evaluation Metrics for Federated Learning</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yanli Li1, Jehad Ibrahim1, Huaming Chen2, , Dong Yuan and Kim-Kwang Raymond Choo2
</span><span class="ltx_author_notes">Yanli Li, Jehad Ibrahim, Huaming Chen and Dong Yuan are with the School of Electrical and Computer Engineering, The University of Sydney (e-mail: {yanli.li, huaming.chen, dong.yuan}@sydney.edu.au, jibr7656@uni.sydney.edu.au).Kim-Kwang Raymond Choo is with the Department of Information Systems and Cyber Security, University of Texas at San Antonio, San Antonio, TX 78249, USA. (e-mail:raymond.choo@fulbrightmail.org).1Equal contribution.2Corresponding author.
<span class="ltx_contact ltx_role_orcid"><a target="_blank" href="https://orcid.org/0000-0001-9842-2209" title="ORCID identifier" class="ltx_ref">0000-0001-9842-2209</a></span>

<span class="ltx_contact ltx_role_orcid"><a target="_blank" href="https://orcid.org/0009-0005-1256-1010%0A" title="ORCID identifier" class="ltx_ref">0009-0005-1256-1010
</a></span>

<span class="ltx_contact ltx_role_orcid"><a target="_blank" href="https://orcid.org/0000-0001-5678-472X" title="ORCID identifier" class="ltx_ref">0000-0001-5678-472X</a></span>

<span class="ltx_contact ltx_role_orcid"><a target="_blank" href="https://orcid.org/0000-0003-1130-0888" title="ORCID identifier" class="ltx_ref">0000-0003-1130-0888</a></span>

<span class="ltx_contact ltx_role_orcid"><a target="_blank" href="https://orcid.org/0000-0001-9208-5336" title="ORCID identifier" class="ltx_ref">0000-0001-9208-5336</a></span>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">A large number of federated learning (FL) algorithms have been proposed for different applications and from varying perspectives. However, the evaluation of such approaches often relies on a single metric (e.g., accuracy). Such a practice fails to account for the unique demands and diverse requirements of different use cases. Thus, how to comprehensively evaluate an FL algorithm and determine the most suitable candidate for a designated use case remains an open question. To mitigate this research gap, we introduce the Holistic Evaluation Metrics (HEM) for FL in this work. Specifically, we collectively focus on three primary use cases, which are Internet of Things (IoT), smart devices, and institutions. The evaluation metric encompasses various aspects including accuracy, convergence, computational efficiency, fairness, and personalization. We then assign a respective importance vector for each use case, reflecting their distinct performance requirements and priorities. The HEM index is finally generated by integrating these metric components with their respective importance vectors. Through evaluating different FL algorithms in these three prevalent use cases, our experimental results demonstrate that HEM can effectively assess and identify the FL algorithms best suited to particular scenarios. We anticipate this work sheds light on the evaluation process for pragmatic FL algorithms in real-world applications.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
Federated Learning (FL), Decentralized Machine Learning (DML), Evaluation Metrics, Collaboration Application

</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Federated learning (FL) is a trending distributed learning paradigm that enables many clients to train a machine learning model collaboratively while keeping the training data decentralized <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. The underpinning privacy protection nature partly resulted in its application in various real-world scenarios, including <span id="S1.p1.1.1" class="ltx_text ltx_font_italic">smartphones</span> (smart devices <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>), <span id="S1.p1.1.2" class="ltx_text ltx_font_italic">institutional</span> settings <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>, and <span id="S1.p1.1.3" class="ltx_text ltx_font_italic">Internet of Things</span> (IoT) environment <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>. For instance, Google implements the intelligent keyboard “Gboard” on its Pixel smartphones <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>, and Apple has developed its virtual assistant “Siri” for smart i-devices <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. Studies such as <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> have explored the deployment of FL in health and medical institutions for achieving intelligent diagnosis and treatment. Furthermore, the research in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> demonstrates FL’s significant potential in IoT scenarios, including vehicular traffic planning, unmanned aerial vehicles, and the smart city.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Different FL algorithms have been developed for various real-world applications <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> with different requirements, ranging from reduced communication costs (e.g., FedAvg <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>) to non-independent identical distribution (non-IID) settings (e.g., FedDyn <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>, SCAFFOLD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>) to and personalized local model (e.g., MAML, ProtoNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>), etc. Given the diversity of FL algorithms, it is no surprise that selecting an appropriate candidate for a specific use case is an important research trend <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>. To inform the selection, existing studies typically assess and compare FL algorithms based on a single metric, such as accuracy or loss value. While such evaluation indexes can partially reflect the performance of FL algorithms from particular perspectives, they fall short in providing a comprehensive assessment of the overall model performance <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>. Furthermore, the evaluations based on a single metric fail to consider the unique requirements and priorities of different FL use cases, further undermining the reliability of the evaluation outcome. To mitigate the research gap, we introduce holistic evaluation metrics (HEM) and a corresponding evaluation pipeline to thoroughly assess FL algorithms and select the most appropriate FL candidate for the targeted use cases.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Given the unique performance requirements of each FL use case, we start by highlighting the three most representative contexts, namely smartphones (smart devices), institutions, and IoT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>. Our proposed evaluation framework, the HEM index, goes beyond a singular metric by encompasses multiple key components, including Client Accuracy, Convergence, Computational Efficiency, Fairness, and Personalization (for personalized FL-PFL algorithms), ensuring a comprehensive assessment. The HEM for any FL algorithm is generated by a weighted average of these component performance indices, where the weights assigned are proportional to the particular needs identified (referred to as importance vectors) for the target application. Specifically, we identify that accuracy and fairness are the primary performance requirements for FL applications in IoT and institutional contexts. In contrast, convergence and computational efficiency are the main focus in smartphone related applications.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">In this study, we evaluate a range of FL algorithms and personalization methods across these identified cases using our proposed HEM and the corresponding evaluation pipeline. The experimental results demonstrate that the HEM can effectively evaluate and differentiate FL algorithms, aiding in the algorithm selection for target use cases. While we currently focuses on three FL use cases in this paper, our HEM could be easily extended to other application scenarios through further investigation into the importance of different metrics components.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">The main contributions of our work are:</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">We establish a comprehensive set of metrics, including accuracy, convergence, computational efficiency, fairness, and personalization for organizing the evaluation metrics.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">We identify the specific needs of different use cases and assess the importance of each corresponding component accordingly.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">We propose the HEM index based on the evaluation components and importance identified, achieving comprehensive and effective evaluation for an FL algorithm in the designated use cases.</p>
</div>
</li>
</ul>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">This work has substantially extended our previous study <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>. Specifically, we extend Section <a href="#S2.SS1" title="II-A Federated Learning Applications ‣ II Related Works ‣ Holistic Evaluation Metrics: Use Case Sensitive Evaluation Metrics for Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">II-A</span></span></a> for a more comprehensive survey on the FL application, Section <a href="#S3.SS4" title="III-D Evaluation Process ‣ III Holistic Evaluation Metrics ‣ Holistic Evaluation Metrics: Use Case Sensitive Evaluation Metrics for Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">III-D</span></span></a> about the detailed HEM evaluation process, and Section <a href="#S4.SS4" title="IV-D Discussion ‣ IV FL Algorithms Evaluation through HEM ‣ Holistic Evaluation Metrics: Use Case Sensitive Evaluation Metrics for Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">IV-D</span></span></a> with the insight of the performance trade-off by introducing personalization.</p>
</div>
<div id="S1.p7" class="ltx_para">
<p id="S1.p7.1" class="ltx_p">The rest of this paper is organized as follows. The next section provides related works surveying existing federated learning applications, algorithms, and evaluation metrics. Section <a href="#S3" title="III Holistic Evaluation Metrics ‣ Holistic Evaluation Metrics: Use Case Sensitive Evaluation Metrics for Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a> describes the proposed HEM, followed by the experimental results and related discussions in Section <a href="#S4" title="IV FL Algorithms Evaluation through HEM ‣ Holistic Evaluation Metrics: Use Case Sensitive Evaluation Metrics for Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV</span></a>. The last section concludes the paper.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Related Works</span>
</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS1.4.1.1" class="ltx_text">II-A</span> </span><span id="S2.SS1.5.2" class="ltx_text ltx_font_italic">Federated Learning Applications</span>
</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">To utilize data isolated at client locations without compromising privacy, numerous applications have been deployed employing FL architecture. These applications typically fall into three categories, depending on the use cases. They include applications for smart phones (smart devices) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>, institutions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>, and IoT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>, <a href="#bib.bib23" title="" class="ltx_ref">23</a>, <a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">Firstly, Google’s successful deployment of its FL-based user input prediction keyboard (Gboard) has sparked significant interest in developing FL applications for smart devices. This application category of smart devices now includes not only text prediction of user input <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> but also emoji prediction <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>, monitoring health condition (such as depression detection) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>, and offering energy efficiency plan recommendations to users <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>. Secondly, FL’s capabilities in preserving privacy have led to its adoption in data-sensitive institutional settings. A recent study <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> introduces a para-medicine application designed to predict the histological response to neoadjuvant chemotherapy (NACT) in early-stage breast cancer patients. FL has facilitated the utilization of clinical information while ensuring data is securely maintained behind hospital firewalls. To support the treatment for patients with COVID-19, another study <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite> proposes an FL-based prediction model, named EXAM, which successfully uses the data from 20 institutes across the globe without compromising privacy. Thirdly, FL is being applied in the IoT sector to address the limitations of high storage costs, together with privacy concerns associated with the traditional ecosystem of centralized over-the-cloud learning and IoT platforms. To offer diversified electricity services, the study <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> introduces an FL application that identifies electricity consumer characteristics. Specifically, privacy-preserving principal component analysis (PCA) is utilized to extract features from smart meter data, while an artificial neural network is trained in a federated setting with various weighted averaging strategies.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS2.4.1.1" class="ltx_text">II-B</span> </span><span id="S2.SS2.5.2" class="ltx_text ltx_font_italic">Federated Learning Algorithms</span>
</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">FL allows multiple participants to collaboratively train a shared model without sharing their raw data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>. Typically, a FL training round includes three steps: the server first broadcasts the current global model to all participants. Subsequently, each participant locally updates the global model using their own private data, sending the updated model back to the server once the established training criteria are satisfied. Finally, the server aggregates the models received using a designated FL algorithm and finalizes the current training round <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p">As a key FL algorithm, FedAvg <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> efficiently aggregates the client gradients while minimising the communication costs. In the FedAvg approach, the server computes a weighted average of the clients’ models, where the weights are proportional to the size of the training data each client possesses. Despite reducing the communication bottleneck in FL, FedAvg stuggles with handling non-IID data and heterogeneous data, limiting its deployment in real-world scenarios. To address these shortcomings and further improve FL performance, FedDyn <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> and SCAFFOLD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> have been developed. The algorithm FedDyn builds on the concept of adding a penalty term to the objective function introduced by FedProx but dynamically changes the value of the penalty term by using a novel dynamic regularization method to ensure that the minima of the global and local objective functions are consistent <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>. SCAFFOLD is an algorithm that builds on FedAvg by attempting to improve its convergence limitation when trained on non-IID data. It corrects the “client drift” issue by leveraging variant reduction.</p>
</div>
<div id="S2.SS2.p3" class="ltx_para">
<p id="S2.SS2.p3.1" class="ltx_p">In addition to ensuring identical model functions for all participants, there is a growing research focus on developing personalized FL algorithms and providing customised learning performances. The study <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> proposes two algorithms, PFLDyn and PFLScaf, which apply the gradient correction methods (FedDyn and SCAFFOLD) to correct bias in a meta-model and tailor personalised client models. Two meta-learning approaches are used to implement the algorithms: MAML and ProtoNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>. The algorithms present convergence guarantees for convex and nonconvex meta objectives. Further, the research <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> proposes a personalized version of the FedAvg algorithm, namely Per-FedAvg, which trains an initial shared model using the MAML framework. The experimental findings indicate that the solution derived from Per-FedAvg can facilitate a more personalized outcome.</p>
</div>
<figure id="S2.T1" class="ltx_table">
<table id="S2.T1.17" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S2.T1.17.18.1" class="ltx_tr">
<td id="S2.T1.17.18.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt ltx_border_t" rowspan="2"><span id="S2.T1.17.18.1.1.1" class="ltx_text ltx_font_bold">FL/PFL Algorithms</span></td>
<td id="S2.T1.17.18.1.2" class="ltx_td ltx_align_center ltx_border_tt ltx_border_t" colspan="4"><span id="S2.T1.17.18.1.2.1" class="ltx_text ltx_font_bold">Evaluation Criteria</span></td>
</tr>
<tr id="S2.T1.17.19.2" class="ltx_tr">
<td id="S2.T1.17.19.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S2.T1.17.19.2.1.1" class="ltx_text ltx_font_bold">Accuracy</span></td>
<td id="S2.T1.17.19.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S2.T1.17.19.2.2.1" class="ltx_text ltx_font_bold">Convergence</span></td>
<td id="S2.T1.17.19.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S2.T1.17.19.2.3.1" class="ltx_text ltx_font_bold">Complexity</span></td>
<td id="S2.T1.17.19.2.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T1.17.19.2.4.1" class="ltx_text ltx_font_bold">Fairness</span></td>
</tr>
<tr id="S2.T1.2.2" class="ltx_tr">
<td id="S2.T1.2.2.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">FedAvg</td>
<td id="S2.T1.2.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">✓</td>
<td id="S2.T1.2.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">✓</td>
<td id="S2.T1.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S2.T1.1.1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T1.1.1.1.m1.1a"><mo id="S2.T1.1.1.1.m1.1.1" xref="S2.T1.1.1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.T1.1.1.1.m1.1b"><times id="S2.T1.1.1.1.m1.1.1.cmml" xref="S2.T1.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.1.1.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S2.T1.2.2.2" class="ltx_td ltx_align_center ltx_border_t"><math id="S2.T1.2.2.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T1.2.2.2.m1.1a"><mo id="S2.T1.2.2.2.m1.1.1" xref="S2.T1.2.2.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.T1.2.2.2.m1.1b"><times id="S2.T1.2.2.2.m1.1.1.cmml" xref="S2.T1.2.2.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.2.2.2.m1.1c">\times</annotation></semantics></math></td>
</tr>
<tr id="S2.T1.5.5" class="ltx_tr">
<td id="S2.T1.5.5.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">FedAvg (MAML)</td>
<td id="S2.T1.3.3.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S2.T1.3.3.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T1.3.3.1.m1.1a"><mo id="S2.T1.3.3.1.m1.1.1" xref="S2.T1.3.3.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.T1.3.3.1.m1.1b"><times id="S2.T1.3.3.1.m1.1.1.cmml" xref="S2.T1.3.3.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.3.3.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S2.T1.5.5.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">✓</td>
<td id="S2.T1.4.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S2.T1.4.4.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T1.4.4.2.m1.1a"><mo id="S2.T1.4.4.2.m1.1.1" xref="S2.T1.4.4.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.T1.4.4.2.m1.1b"><times id="S2.T1.4.4.2.m1.1.1.cmml" xref="S2.T1.4.4.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.4.4.2.m1.1c">\times</annotation></semantics></math></td>
<td id="S2.T1.5.5.3" class="ltx_td ltx_align_center ltx_border_t"><math id="S2.T1.5.5.3.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T1.5.5.3.m1.1a"><mo id="S2.T1.5.5.3.m1.1.1" xref="S2.T1.5.5.3.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.T1.5.5.3.m1.1b"><times id="S2.T1.5.5.3.m1.1.1.cmml" xref="S2.T1.5.5.3.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.5.5.3.m1.1c">\times</annotation></semantics></math></td>
</tr>
<tr id="S2.T1.7.7" class="ltx_tr">
<td id="S2.T1.7.7.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">FedAvg (Proto)</td>
<td id="S2.T1.7.7.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">✓</td>
<td id="S2.T1.7.7.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">✓</td>
<td id="S2.T1.6.6.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S2.T1.6.6.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T1.6.6.1.m1.1a"><mo id="S2.T1.6.6.1.m1.1.1" xref="S2.T1.6.6.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.T1.6.6.1.m1.1b"><times id="S2.T1.6.6.1.m1.1.1.cmml" xref="S2.T1.6.6.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.6.6.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S2.T1.7.7.2" class="ltx_td ltx_align_center ltx_border_t"><math id="S2.T1.7.7.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T1.7.7.2.m1.1a"><mo id="S2.T1.7.7.2.m1.1.1" xref="S2.T1.7.7.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.T1.7.7.2.m1.1b"><times id="S2.T1.7.7.2.m1.1.1.cmml" xref="S2.T1.7.7.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.7.7.2.m1.1c">\times</annotation></semantics></math></td>
</tr>
<tr id="S2.T1.8.8" class="ltx_tr">
<td id="S2.T1.8.8.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">FedDyn</td>
<td id="S2.T1.8.8.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">✓</td>
<td id="S2.T1.8.8.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">✓</td>
<td id="S2.T1.8.8.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">✓</td>
<td id="S2.T1.8.8.1" class="ltx_td ltx_align_center ltx_border_t"><math id="S2.T1.8.8.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T1.8.8.1.m1.1a"><mo id="S2.T1.8.8.1.m1.1.1" xref="S2.T1.8.8.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.T1.8.8.1.m1.1b"><times id="S2.T1.8.8.1.m1.1.1.cmml" xref="S2.T1.8.8.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.8.8.1.m1.1c">\times</annotation></semantics></math></td>
</tr>
<tr id="S2.T1.10.10" class="ltx_tr">
<td id="S2.T1.10.10.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">FedDyn (MAML)</td>
<td id="S2.T1.10.10.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">✓</td>
<td id="S2.T1.10.10.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">✓</td>
<td id="S2.T1.9.9.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S2.T1.9.9.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T1.9.9.1.m1.1a"><mo id="S2.T1.9.9.1.m1.1.1" xref="S2.T1.9.9.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.T1.9.9.1.m1.1b"><times id="S2.T1.9.9.1.m1.1.1.cmml" xref="S2.T1.9.9.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.9.9.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S2.T1.10.10.2" class="ltx_td ltx_align_center ltx_border_t"><math id="S2.T1.10.10.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T1.10.10.2.m1.1a"><mo id="S2.T1.10.10.2.m1.1.1" xref="S2.T1.10.10.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.T1.10.10.2.m1.1b"><times id="S2.T1.10.10.2.m1.1.1.cmml" xref="S2.T1.10.10.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.10.10.2.m1.1c">\times</annotation></semantics></math></td>
</tr>
<tr id="S2.T1.12.12" class="ltx_tr">
<td id="S2.T1.12.12.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">FedDyn (Proto)</td>
<td id="S2.T1.12.12.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">✓</td>
<td id="S2.T1.12.12.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">✓</td>
<td id="S2.T1.11.11.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S2.T1.11.11.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T1.11.11.1.m1.1a"><mo id="S2.T1.11.11.1.m1.1.1" xref="S2.T1.11.11.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.T1.11.11.1.m1.1b"><times id="S2.T1.11.11.1.m1.1.1.cmml" xref="S2.T1.11.11.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.11.11.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S2.T1.12.12.2" class="ltx_td ltx_align_center ltx_border_t"><math id="S2.T1.12.12.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T1.12.12.2.m1.1a"><mo id="S2.T1.12.12.2.m1.1.1" xref="S2.T1.12.12.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.T1.12.12.2.m1.1b"><times id="S2.T1.12.12.2.m1.1.1.cmml" xref="S2.T1.12.12.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.12.12.2.m1.1c">\times</annotation></semantics></math></td>
</tr>
<tr id="S2.T1.13.13" class="ltx_tr">
<td id="S2.T1.13.13.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">SCAFFOLD</td>
<td id="S2.T1.13.13.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">✓</td>
<td id="S2.T1.13.13.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">✓</td>
<td id="S2.T1.13.13.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">✓</td>
<td id="S2.T1.13.13.1" class="ltx_td ltx_align_center ltx_border_t"><math id="S2.T1.13.13.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T1.13.13.1.m1.1a"><mo id="S2.T1.13.13.1.m1.1.1" xref="S2.T1.13.13.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.T1.13.13.1.m1.1b"><times id="S2.T1.13.13.1.m1.1.1.cmml" xref="S2.T1.13.13.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.13.13.1.m1.1c">\times</annotation></semantics></math></td>
</tr>
<tr id="S2.T1.15.15" class="ltx_tr">
<td id="S2.T1.15.15.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">SCAFFOLD (MAML)</td>
<td id="S2.T1.15.15.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">✓</td>
<td id="S2.T1.15.15.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">✓</td>
<td id="S2.T1.14.14.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S2.T1.14.14.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T1.14.14.1.m1.1a"><mo id="S2.T1.14.14.1.m1.1.1" xref="S2.T1.14.14.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.T1.14.14.1.m1.1b"><times id="S2.T1.14.14.1.m1.1.1.cmml" xref="S2.T1.14.14.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.14.14.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S2.T1.15.15.2" class="ltx_td ltx_align_center ltx_border_t"><math id="S2.T1.15.15.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T1.15.15.2.m1.1a"><mo id="S2.T1.15.15.2.m1.1.1" xref="S2.T1.15.15.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.T1.15.15.2.m1.1b"><times id="S2.T1.15.15.2.m1.1.1.cmml" xref="S2.T1.15.15.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.15.15.2.m1.1c">\times</annotation></semantics></math></td>
</tr>
<tr id="S2.T1.17.17" class="ltx_tr">
<td id="S2.T1.17.17.3" class="ltx_td ltx_align_left ltx_border_bb ltx_border_b ltx_border_r ltx_border_t">SCAFFOLD (Proto)</td>
<td id="S2.T1.17.17.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_b ltx_border_r ltx_border_t">✓</td>
<td id="S2.T1.17.17.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_b ltx_border_r ltx_border_t">✓</td>
<td id="S2.T1.16.16.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_b ltx_border_r ltx_border_t"><math id="S2.T1.16.16.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T1.16.16.1.m1.1a"><mo id="S2.T1.16.16.1.m1.1.1" xref="S2.T1.16.16.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.T1.16.16.1.m1.1b"><times id="S2.T1.16.16.1.m1.1.1.cmml" xref="S2.T1.16.16.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.16.16.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S2.T1.17.17.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_b ltx_border_t"><math id="S2.T1.17.17.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T1.17.17.2.m1.1a"><mo id="S2.T1.17.17.2.m1.1.1" xref="S2.T1.17.17.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.T1.17.17.2.m1.1b"><times id="S2.T1.17.17.2.m1.1.1.cmml" xref="S2.T1.17.17.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.17.17.2.m1.1c">\times</annotation></semantics></math></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE I: </span>Criteria used for different FL algorithms evaluations.</figcaption>
</figure>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS3.4.1.1" class="ltx_text">II-C</span> </span><span id="S2.SS3.5.2" class="ltx_text ltx_font_italic">Federated Learning Evaluation Metrics</span>
</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">Currently, the evaluation metrics used in FL generally derive from those established in traditional centralized machine learning (CML) concepts. The development of specific metrics tailored for FL is still in its nascent stages. Commonly, metrics like accuracy or loss value, which measure the percentage of correct prediction on the testing data or quantify the difference between predictions and actual results, are used to evaluate both FL and CML algorithms <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>. In addition, since FL training relies on regular communication between the server and clients, some research evaluates algorithm performance based on communication efficiency <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>, considering the factors such as the number of communication rounds, parameters, and message sizes required to train an FL model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>. From a system performance perspective, the evaluation of an FL algorithm could be conducted based on its network and hardware requirements <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>. Furthermore, several studies <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> employ metrics that assess local model fairness and robustness against adversarial attacks, thereby assessing the trustworthiness of their frameworks.</p>
</div>
<div id="S2.SS3.p2" class="ltx_para">
<p id="S2.SS3.p2.1" class="ltx_p">We broadly review the key FL algorithms (i.e., FedAvg, FedDyn, and SCAFFOLD) and delve into two meta-learning techniques (i.e., MAML and Proto) that can adapt these FL algorithms into personalized FL (PFL) algorithms. We note that, although these algorithms could effectively address specific weaknesses of the original algorithm, the researchers used to evaluate and demonstrate improvements using a single metric. This approach often make the trade-offs involved with each algorithm unclear.</p>
</div>
<div id="S2.SS3.p3" class="ltx_para">
<p id="S2.SS3.p3.1" class="ltx_p">Thus, in this work, we propose the Holistic Evaluation Metric (HEM), aiming to provide an effective and comprehensive evaluation of FL algorithms and aid in selecting the most appropriate FL algorithm for diverse real-world use cases. Table <a href="#S2.T1" title="TABLE I ‣ II-B Federated Learning Algorithms ‣ II Related Works ‣ Holistic Evaluation Metrics: Use Case Sensitive Evaluation Metrics for Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a> illustrates the criteria used for different FL algorithm evaluations.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Holistic Evaluation Metrics</span>
</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">In this section, we present Holistic Evaluation Metrics (HEM) to mitigate the research gap carried by current simplistic evaluation metric and provide an effective evaluation method for FL algorithms in various real-world use cases. Recognising that different use cases may prioritize different performance aspects, we start by identifying the most representative FL use cases. We then determine the principal evaluation perspectives, and finally organize the HEM by developing the formula for the HEM index.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS1.4.1.1" class="ltx_text">III-A</span> </span><span id="S3.SS1.5.2" class="ltx_text ltx_font_italic">Federated Learning Use Cases</span>
</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">FL has revolutionzed traditional ML by facilitating training on decentralized data while addressing crucial privacy concerns in privacy-sensitive applications where training data is distributed across multiple edge devices <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>. Currently, a large number of service providers have adopted the FL method, which has found a significant role in different domains, ranging from smart devices to institutions and IoT. Herein, we explore the three representative real-world application use cases of FL, drawing on insights from the applications and characteristics outlined in recent studies <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>, <a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>.</p>
</div>
<section id="S3.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS1.SSS1.4.1.1" class="ltx_text">III-A</span>1 </span>Smartphones (Smart Devices)</h4>

<div id="S3.SS1.SSS1.p1" class="ltx_para">
<p id="S3.SS1.SSS1.p1.1" class="ltx_p">Smart devices, including smartphones and laptops, significantly benefit humans and have become integral to our daily lives. While providing information to users, these devices also collect user information and usage patterns. Applications such as next-word prediction, face detection, and voice recognition <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>, <a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> could greatly benefit from these collected and recorded data from users. However, data gathering in a centralized location to support traditional centralized ML poses challenges due to user privacy concerns and legal restrictions. FL addresses these issues by facilitating the collaborative learning of ML models across a wide array of mobile devices. The smartphone participants can retain the data locally, only sharing the model update with the server via the cellular or wireless network. By leveraging FL, on the one hand, the vast amounts of user data ensure both high learning performance and satisfactory service provision; on the other hand, clients benefit from personalized functions through their participation. For instance, providers of next-word predictor applications can employ FL to train model with the historical text data from users across a broad network of smart devices. In return, clients benefit from more accurate prediction results that are customized to their individual user habits <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>.</p>
</div>
</section>
<section id="S3.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS1.SSS2.4.1.1" class="ltx_text">III-A</span>2 </span>Institutions</h4>

<div id="S3.SS1.SSS2.p1" class="ltx_para">
<p id="S3.SS1.SSS2.p1.1" class="ltx_p">Existing institutions maintain large amounts of records and information on their clients to deliver services <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>. For example, healthcare institutions store diagnostic logs of patients to inform treatment strategies, while financial institutions keep records of clients’ bank statements to make lending decisions. While such data could greatly improve training datasets and boost model performance, these institutions are frequently subject to strict privacy regulations and ethical considerations, necessitating that data remains localized <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>. This limitation hinders institutions’ ability to utilize data from other organizations or even from their client data, ultimately constraining their potential to offer enhanced intelligent services. FL presents an innovative solution for these use cases by ensuring privacy and enabling institutions to participate in secure collaborations. Within an FL system, institutions acts as “client” nodes sharing only the model updates during each learning iteration, thus maintaining data privacy within their boundaries <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>. Furthermore, vertical FL technology allows the deployment of an FL model in scenarios where participants share the same sample ID space but possess different feature sets, effectively accommodating collaboration between institutions even from different domains.</p>
</div>
</section>
<section id="S3.SS1.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS1.SSS3.4.1.1" class="ltx_text">III-A</span>3 </span>Internet of Things (IoT)</h4>

<div id="S3.SS1.SSS3.p1" class="ltx_para">
<p id="S3.SS1.SSS3.p1.1" class="ltx_p">The IoT ecosystem consists of a network of interconnected devices, such as wearable devices<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite>, autonomous vehicles <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>, and smart homes <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>, all equipped with sensors to collect, process, and act on real-time data. For example, autonomous vehicles rely on continually updated models for safe navigation, taking into account traffic conditions, construction sites, and pedestrian movements. However, building accurate and up-to-date models can be challenging due to the privacy concerns associated with data and the limited connectivity of each device <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite>. Moreover, the large volume of data generated by IoT devices every second further brings difficulty to the traditional centralized ML. To this end, FL algorithms are considered a viable alternative, which adapt IoT devices to dynamic environments, enabling efficient model training while preserving user privacy. When deploying FL in an IoT use case, each interconnected device can act as a client contributing partially or fully to the model training, depending on its computing resources <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite>. A trustworthy cloud node serves as the server, orchestrating the entire training process.</p>
</div>
<figure id="S3.T2" class="ltx_table">
<table id="S3.T2.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T2.1.1.1" class="ltx_tr">
<th id="S3.T2.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt ltx_border_tt" style="padding-left:12.0pt;padding-right:12.0pt;"><span id="S3.T2.1.1.1.1.1" class="ltx_text ltx_font_bold">Use Cases</span></th>
<th id="S3.T2.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt ltx_border_tt" style="padding-left:12.0pt;padding-right:12.0pt;"><span id="S3.T2.1.1.1.2.1" class="ltx_text ltx_font_bold">IoT</span></th>
<th id="S3.T2.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt ltx_border_tt" style="padding-left:12.0pt;padding-right:12.0pt;"><span id="S3.T2.1.1.1.3.1" class="ltx_text ltx_font_bold">Smart devices (Smartphone)</span></th>
<th id="S3.T2.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt ltx_border_tt" style="padding-left:12.0pt;padding-right:12.0pt;"><span id="S3.T2.1.1.1.4.1" class="ltx_text ltx_font_bold">Institution</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T2.1.2.1" class="ltx_tr">
<td id="S3.T2.1.2.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:12.0pt;padding-right:12.0pt;">Accuracy</td>
<td id="S3.T2.1.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:12.0pt;padding-right:12.0pt;">High</td>
<td id="S3.T2.1.2.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:12.0pt;padding-right:12.0pt;">Moderate</td>
<td id="S3.T2.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:12.0pt;padding-right:12.0pt;">High</td>
</tr>
<tr id="S3.T2.1.3.2" class="ltx_tr">
<td id="S3.T2.1.3.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:12.0pt;padding-right:12.0pt;">Convergence</td>
<td id="S3.T2.1.3.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:12.0pt;padding-right:12.0pt;">Low</td>
<td id="S3.T2.1.3.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:12.0pt;padding-right:12.0pt;">High</td>
<td id="S3.T2.1.3.2.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:12.0pt;padding-right:12.0pt;">Low</td>
</tr>
<tr id="S3.T2.1.4.3" class="ltx_tr">
<td id="S3.T2.1.4.3.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:12.0pt;padding-right:12.0pt;">Computational Efficiency</td>
<td id="S3.T2.1.4.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:12.0pt;padding-right:12.0pt;">High</td>
<td id="S3.T2.1.4.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:12.0pt;padding-right:12.0pt;">High</td>
<td id="S3.T2.1.4.3.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:12.0pt;padding-right:12.0pt;">Low</td>
</tr>
<tr id="S3.T2.1.5.4" class="ltx_tr">
<td id="S3.T2.1.5.4.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_b ltx_border_r ltx_border_t" style="padding-left:12.0pt;padding-right:12.0pt;">Fairness</td>
<td id="S3.T2.1.5.4.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_b ltx_border_r ltx_border_t" style="padding-left:12.0pt;padding-right:12.0pt;">High</td>
<td id="S3.T2.1.5.4.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_b ltx_border_r ltx_border_t" style="padding-left:12.0pt;padding-right:12.0pt;">Moderate</td>
<td id="S3.T2.1.5.4.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_b ltx_border_t" style="padding-left:12.0pt;padding-right:12.0pt;">High</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE II: </span>Holistic evaluation metric component importance for IoT, smartphone, and institution.</figcaption>
</figure>
</section>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS2.4.1.1" class="ltx_text">III-B</span> </span><span id="S3.SS2.5.2" class="ltx_text ltx_font_italic">Evaluation Metric Components</span>
</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">Rather than relying solely on a single performance metric, such as accuracy or loss value, we organize the HEM through multiple components to provide a more comprehensive evaluation. Specifically, these evaluation metric components encompass client accuracy, convergence, computation efficiency, fairness, and personalization for PFL.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p"><span id="S3.SS2.p2.1.1" class="ltx_text ltx_font_bold">Evaluation Metric Component 1: Client Accuracy
<br class="ltx_break"></span>Accuracy, as the most intuitive indicator, is widely used in the evaluation of existing ML and FL algorithms to assess model learning performance. Within the FL context, the global model used to be evaluated using testing data after each iteration’s aggregation. The percentage of accurate predictions is then calculated as accuracy, serving as a measure to demonstrate the overall learning performance. However, due to the heterogeneity of participants’ data and devices, their learning performance can vary significantly. Therefore, in the proposed HEM, we leverage client accuracy over global model accuracy, calculating it as the mean accuracy across clients per round. Client Accuracy reflects the utility and learning performance of the FL algorithm for individual clients under the given learning task and data distribution. Specifically, a higher Client Accuracy indicates greater satisfaction among clients regarding the predictions generated by their models. It essentially provides a clear measure of the FL algorithm’s effectiveness and ability to meet the varied needs and expectations of participating clients.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.1" class="ltx_p"><span id="S3.SS2.p3.1.1" class="ltx_text ltx_font_bold">Evaluation Metric Component 2: Convergence
<br class="ltx_break"></span>The FL training heavily relies on the regular models (or gradients) exchange between clients and the server to perform the learning process. An algorithm that requires numerous learning rounds to achieve convergence may introduce high communication costs and exacerbate the bottleneck. To this end, we introduce the Convergence component in the HEM. The Convergence component reflects the time and computational resources an FL algorithm consumes by measuring the number of communication rounds an FL algorithm requires to achieve a predetermined target accuracy for clients. A higher convergence score indicates a heavier demand for communication computational and temporal resources, potentially taxing the devices involved. In our study, we set the target accuracy at 80%, a benchmark deemed satisfactory for model performance across all investigated use cases. Additionally, we normalize the Convergence value on a scale from 0 to 1000, where 0 represents optimal performance and 1000 indicates the worst outcome.</p>
</div>
<div id="S3.SS2.p4" class="ltx_para">
<p id="S3.SS2.p4.1" class="ltx_p"><span id="S3.SS2.p4.1.1" class="ltx_text ltx_font_bold">Evaluation Metric Component 3: Computation Efficiency
<br class="ltx_break"></span>While HEM utilizes the Convergence component to represent the time cost by counting the communication rounds, the training time per round can vary across different FL algorithms and finally drives impact on the learning efficiency. To this end, we further include Computational Efficiency in HEM to introduce clock time cost evaluation. Specifically, the Computational Efficiency component reflects the amount of time or memory required for a given threshold but emphasizes the wall-clock time. In the HEM, the Computational Efficiency is measured using a metric called Time to Accuracy (TTA). TTA merges the concepts of Convergence and Simulation Time, providing a view of the duration necessary for an algorithm to meet the set target accuracy or threshold. Besides, This component evaluates the balance between computational resource demand and time investment and demonstrates an algorithm’s efficiency in resource utilization.</p>
</div>
<div id="S3.SS2.p5" class="ltx_para">
<p id="S3.SS2.p5.6" class="ltx_p"><span id="S3.SS2.p5.6.1" class="ltx_text ltx_font_bold">Evaluation Metric Component 4: Fairness
<br class="ltx_break"></span>The Fairness reflects the level of the learning performance (model accuracy) difference that exists in the FL system across all participants. In HEM, the Fairness component is assessed by calculating (inversely proportional to) the entropy (<math id="S3.SS2.p5.1.m1.1" class="ltx_Math" alttext="H" display="inline"><semantics id="S3.SS2.p5.1.m1.1a"><mi id="S3.SS2.p5.1.m1.1.1" xref="S3.SS2.p5.1.m1.1.1.cmml">H</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.1.m1.1b"><ci id="S3.SS2.p5.1.m1.1.1.cmml" xref="S3.SS2.p5.1.m1.1.1">𝐻</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.1.m1.1c">H</annotation></semantics></math>) of the Client Accuracy list. Formally, for a given accuracy list <math id="S3.SS2.p5.2.m2.4" class="ltx_Math" alttext="L={\{a_{1},...,a_{i}}\},|L|=I" display="inline"><semantics id="S3.SS2.p5.2.m2.4a"><mrow id="S3.SS2.p5.2.m2.4.4.2" xref="S3.SS2.p5.2.m2.4.4.3.cmml"><mrow id="S3.SS2.p5.2.m2.3.3.1.1" xref="S3.SS2.p5.2.m2.3.3.1.1.cmml"><mi id="S3.SS2.p5.2.m2.3.3.1.1.4" xref="S3.SS2.p5.2.m2.3.3.1.1.4.cmml">L</mi><mo id="S3.SS2.p5.2.m2.3.3.1.1.3" xref="S3.SS2.p5.2.m2.3.3.1.1.3.cmml">=</mo><mrow id="S3.SS2.p5.2.m2.3.3.1.1.2.2" xref="S3.SS2.p5.2.m2.3.3.1.1.2.3.cmml"><mo stretchy="false" id="S3.SS2.p5.2.m2.3.3.1.1.2.2.3" xref="S3.SS2.p5.2.m2.3.3.1.1.2.3.cmml">{</mo><msub id="S3.SS2.p5.2.m2.3.3.1.1.1.1.1" xref="S3.SS2.p5.2.m2.3.3.1.1.1.1.1.cmml"><mi id="S3.SS2.p5.2.m2.3.3.1.1.1.1.1.2" xref="S3.SS2.p5.2.m2.3.3.1.1.1.1.1.2.cmml">a</mi><mn id="S3.SS2.p5.2.m2.3.3.1.1.1.1.1.3" xref="S3.SS2.p5.2.m2.3.3.1.1.1.1.1.3.cmml">1</mn></msub><mo id="S3.SS2.p5.2.m2.3.3.1.1.2.2.4" xref="S3.SS2.p5.2.m2.3.3.1.1.2.3.cmml">,</mo><mi mathvariant="normal" id="S3.SS2.p5.2.m2.1.1" xref="S3.SS2.p5.2.m2.1.1.cmml">…</mi><mo id="S3.SS2.p5.2.m2.3.3.1.1.2.2.5" xref="S3.SS2.p5.2.m2.3.3.1.1.2.3.cmml">,</mo><msub id="S3.SS2.p5.2.m2.3.3.1.1.2.2.2" xref="S3.SS2.p5.2.m2.3.3.1.1.2.2.2.cmml"><mi id="S3.SS2.p5.2.m2.3.3.1.1.2.2.2.2" xref="S3.SS2.p5.2.m2.3.3.1.1.2.2.2.2.cmml">a</mi><mi id="S3.SS2.p5.2.m2.3.3.1.1.2.2.2.3" xref="S3.SS2.p5.2.m2.3.3.1.1.2.2.2.3.cmml">i</mi></msub><mo stretchy="false" id="S3.SS2.p5.2.m2.3.3.1.1.2.2.6" xref="S3.SS2.p5.2.m2.3.3.1.1.2.3.cmml">}</mo></mrow></mrow><mo id="S3.SS2.p5.2.m2.4.4.2.3" xref="S3.SS2.p5.2.m2.4.4.3a.cmml">,</mo><mrow id="S3.SS2.p5.2.m2.4.4.2.2" xref="S3.SS2.p5.2.m2.4.4.2.2.cmml"><mrow id="S3.SS2.p5.2.m2.4.4.2.2.2.2" xref="S3.SS2.p5.2.m2.4.4.2.2.2.1.cmml"><mo stretchy="false" id="S3.SS2.p5.2.m2.4.4.2.2.2.2.1" xref="S3.SS2.p5.2.m2.4.4.2.2.2.1.1.cmml">|</mo><mi id="S3.SS2.p5.2.m2.2.2" xref="S3.SS2.p5.2.m2.2.2.cmml">L</mi><mo stretchy="false" id="S3.SS2.p5.2.m2.4.4.2.2.2.2.2" xref="S3.SS2.p5.2.m2.4.4.2.2.2.1.1.cmml">|</mo></mrow><mo id="S3.SS2.p5.2.m2.4.4.2.2.1" xref="S3.SS2.p5.2.m2.4.4.2.2.1.cmml">=</mo><mi id="S3.SS2.p5.2.m2.4.4.2.2.3" xref="S3.SS2.p5.2.m2.4.4.2.2.3.cmml">I</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.2.m2.4b"><apply id="S3.SS2.p5.2.m2.4.4.3.cmml" xref="S3.SS2.p5.2.m2.4.4.2"><csymbol cd="ambiguous" id="S3.SS2.p5.2.m2.4.4.3a.cmml" xref="S3.SS2.p5.2.m2.4.4.2.3">formulae-sequence</csymbol><apply id="S3.SS2.p5.2.m2.3.3.1.1.cmml" xref="S3.SS2.p5.2.m2.3.3.1.1"><eq id="S3.SS2.p5.2.m2.3.3.1.1.3.cmml" xref="S3.SS2.p5.2.m2.3.3.1.1.3"></eq><ci id="S3.SS2.p5.2.m2.3.3.1.1.4.cmml" xref="S3.SS2.p5.2.m2.3.3.1.1.4">𝐿</ci><set id="S3.SS2.p5.2.m2.3.3.1.1.2.3.cmml" xref="S3.SS2.p5.2.m2.3.3.1.1.2.2"><apply id="S3.SS2.p5.2.m2.3.3.1.1.1.1.1.cmml" xref="S3.SS2.p5.2.m2.3.3.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p5.2.m2.3.3.1.1.1.1.1.1.cmml" xref="S3.SS2.p5.2.m2.3.3.1.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p5.2.m2.3.3.1.1.1.1.1.2.cmml" xref="S3.SS2.p5.2.m2.3.3.1.1.1.1.1.2">𝑎</ci><cn type="integer" id="S3.SS2.p5.2.m2.3.3.1.1.1.1.1.3.cmml" xref="S3.SS2.p5.2.m2.3.3.1.1.1.1.1.3">1</cn></apply><ci id="S3.SS2.p5.2.m2.1.1.cmml" xref="S3.SS2.p5.2.m2.1.1">…</ci><apply id="S3.SS2.p5.2.m2.3.3.1.1.2.2.2.cmml" xref="S3.SS2.p5.2.m2.3.3.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p5.2.m2.3.3.1.1.2.2.2.1.cmml" xref="S3.SS2.p5.2.m2.3.3.1.1.2.2.2">subscript</csymbol><ci id="S3.SS2.p5.2.m2.3.3.1.1.2.2.2.2.cmml" xref="S3.SS2.p5.2.m2.3.3.1.1.2.2.2.2">𝑎</ci><ci id="S3.SS2.p5.2.m2.3.3.1.1.2.2.2.3.cmml" xref="S3.SS2.p5.2.m2.3.3.1.1.2.2.2.3">𝑖</ci></apply></set></apply><apply id="S3.SS2.p5.2.m2.4.4.2.2.cmml" xref="S3.SS2.p5.2.m2.4.4.2.2"><eq id="S3.SS2.p5.2.m2.4.4.2.2.1.cmml" xref="S3.SS2.p5.2.m2.4.4.2.2.1"></eq><apply id="S3.SS2.p5.2.m2.4.4.2.2.2.1.cmml" xref="S3.SS2.p5.2.m2.4.4.2.2.2.2"><abs id="S3.SS2.p5.2.m2.4.4.2.2.2.1.1.cmml" xref="S3.SS2.p5.2.m2.4.4.2.2.2.2.1"></abs><ci id="S3.SS2.p5.2.m2.2.2.cmml" xref="S3.SS2.p5.2.m2.2.2">𝐿</ci></apply><ci id="S3.SS2.p5.2.m2.4.4.2.2.3.cmml" xref="S3.SS2.p5.2.m2.4.4.2.2.3">𝐼</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.2.m2.4c">L={\{a_{1},...,a_{i}}\},|L|=I</annotation></semantics></math> , where <math id="S3.SS2.p5.3.m3.1" class="ltx_Math" alttext="a_{i}" display="inline"><semantics id="S3.SS2.p5.3.m3.1a"><msub id="S3.SS2.p5.3.m3.1.1" xref="S3.SS2.p5.3.m3.1.1.cmml"><mi id="S3.SS2.p5.3.m3.1.1.2" xref="S3.SS2.p5.3.m3.1.1.2.cmml">a</mi><mi id="S3.SS2.p5.3.m3.1.1.3" xref="S3.SS2.p5.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.3.m3.1b"><apply id="S3.SS2.p5.3.m3.1.1.cmml" xref="S3.SS2.p5.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p5.3.m3.1.1.1.cmml" xref="S3.SS2.p5.3.m3.1.1">subscript</csymbol><ci id="S3.SS2.p5.3.m3.1.1.2.cmml" xref="S3.SS2.p5.3.m3.1.1.2">𝑎</ci><ci id="S3.SS2.p5.3.m3.1.1.3.cmml" xref="S3.SS2.p5.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.3.m3.1c">a_{i}</annotation></semantics></math> denotes the accuracy of the <math id="S3.SS2.p5.4.m4.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.SS2.p5.4.m4.1a"><mi id="S3.SS2.p5.4.m4.1.1" xref="S3.SS2.p5.4.m4.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.4.m4.1b"><ci id="S3.SS2.p5.4.m4.1.1.cmml" xref="S3.SS2.p5.4.m4.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.4.m4.1c">i</annotation></semantics></math>th client. The Fairness (<math id="S3.SS2.p5.5.m5.1" class="ltx_Math" alttext="F" display="inline"><semantics id="S3.SS2.p5.5.m5.1a"><mi id="S3.SS2.p5.5.m5.1.1" xref="S3.SS2.p5.5.m5.1.1.cmml">F</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.5.m5.1b"><ci id="S3.SS2.p5.5.m5.1.1.cmml" xref="S3.SS2.p5.5.m5.1.1">𝐹</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.5.m5.1c">F</annotation></semantics></math>) of <math id="S3.SS2.p5.6.m6.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S3.SS2.p5.6.m6.1a"><mi id="S3.SS2.p5.6.m6.1.1" xref="S3.SS2.p5.6.m6.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.6.m6.1b"><ci id="S3.SS2.p5.6.m6.1.1.cmml" xref="S3.SS2.p5.6.m6.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.6.m6.1c">L</annotation></semantics></math> is:</p>
</div>
<div id="S3.SS2.p6" class="ltx_para">
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.2" class="ltx_Math" alttext="1/F(L)\propto H(L)=-\sum_{i=0}^{I}a_{i}log_{e}a_{i}" display="block"><semantics id="S3.E1.m1.2a"><mrow id="S3.E1.m1.2.3" xref="S3.E1.m1.2.3.cmml"><mrow id="S3.E1.m1.2.3.2" xref="S3.E1.m1.2.3.2.cmml"><mrow id="S3.E1.m1.2.3.2.2" xref="S3.E1.m1.2.3.2.2.cmml"><mn id="S3.E1.m1.2.3.2.2.2" xref="S3.E1.m1.2.3.2.2.2.cmml">1</mn><mo id="S3.E1.m1.2.3.2.2.1" xref="S3.E1.m1.2.3.2.2.1.cmml">/</mo><mi id="S3.E1.m1.2.3.2.2.3" xref="S3.E1.m1.2.3.2.2.3.cmml">F</mi></mrow><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.3.2.1" xref="S3.E1.m1.2.3.2.1.cmml">​</mo><mrow id="S3.E1.m1.2.3.2.3.2" xref="S3.E1.m1.2.3.2.cmml"><mo stretchy="false" id="S3.E1.m1.2.3.2.3.2.1" xref="S3.E1.m1.2.3.2.cmml">(</mo><mi id="S3.E1.m1.1.1" xref="S3.E1.m1.1.1.cmml">L</mi><mo stretchy="false" id="S3.E1.m1.2.3.2.3.2.2" xref="S3.E1.m1.2.3.2.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.2.3.3" xref="S3.E1.m1.2.3.3.cmml">∝</mo><mrow id="S3.E1.m1.2.3.4" xref="S3.E1.m1.2.3.4.cmml"><mi id="S3.E1.m1.2.3.4.2" xref="S3.E1.m1.2.3.4.2.cmml">H</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.3.4.1" xref="S3.E1.m1.2.3.4.1.cmml">​</mo><mrow id="S3.E1.m1.2.3.4.3.2" xref="S3.E1.m1.2.3.4.cmml"><mo stretchy="false" id="S3.E1.m1.2.3.4.3.2.1" xref="S3.E1.m1.2.3.4.cmml">(</mo><mi id="S3.E1.m1.2.2" xref="S3.E1.m1.2.2.cmml">L</mi><mo stretchy="false" id="S3.E1.m1.2.3.4.3.2.2" xref="S3.E1.m1.2.3.4.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.2.3.5" xref="S3.E1.m1.2.3.5.cmml">=</mo><mrow id="S3.E1.m1.2.3.6" xref="S3.E1.m1.2.3.6.cmml"><mo id="S3.E1.m1.2.3.6a" xref="S3.E1.m1.2.3.6.cmml">−</mo><mrow id="S3.E1.m1.2.3.6.2" xref="S3.E1.m1.2.3.6.2.cmml"><munderover id="S3.E1.m1.2.3.6.2.1" xref="S3.E1.m1.2.3.6.2.1.cmml"><mo movablelimits="false" id="S3.E1.m1.2.3.6.2.1.2.2" xref="S3.E1.m1.2.3.6.2.1.2.2.cmml">∑</mo><mrow id="S3.E1.m1.2.3.6.2.1.2.3" xref="S3.E1.m1.2.3.6.2.1.2.3.cmml"><mi id="S3.E1.m1.2.3.6.2.1.2.3.2" xref="S3.E1.m1.2.3.6.2.1.2.3.2.cmml">i</mi><mo id="S3.E1.m1.2.3.6.2.1.2.3.1" xref="S3.E1.m1.2.3.6.2.1.2.3.1.cmml">=</mo><mn id="S3.E1.m1.2.3.6.2.1.2.3.3" xref="S3.E1.m1.2.3.6.2.1.2.3.3.cmml">0</mn></mrow><mi id="S3.E1.m1.2.3.6.2.1.3" xref="S3.E1.m1.2.3.6.2.1.3.cmml">I</mi></munderover><mrow id="S3.E1.m1.2.3.6.2.2" xref="S3.E1.m1.2.3.6.2.2.cmml"><msub id="S3.E1.m1.2.3.6.2.2.2" xref="S3.E1.m1.2.3.6.2.2.2.cmml"><mi id="S3.E1.m1.2.3.6.2.2.2.2" xref="S3.E1.m1.2.3.6.2.2.2.2.cmml">a</mi><mi id="S3.E1.m1.2.3.6.2.2.2.3" xref="S3.E1.m1.2.3.6.2.2.2.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.3.6.2.2.1" xref="S3.E1.m1.2.3.6.2.2.1.cmml">​</mo><mi id="S3.E1.m1.2.3.6.2.2.3" xref="S3.E1.m1.2.3.6.2.2.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.3.6.2.2.1a" xref="S3.E1.m1.2.3.6.2.2.1.cmml">​</mo><mi id="S3.E1.m1.2.3.6.2.2.4" xref="S3.E1.m1.2.3.6.2.2.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.3.6.2.2.1b" xref="S3.E1.m1.2.3.6.2.2.1.cmml">​</mo><msub id="S3.E1.m1.2.3.6.2.2.5" xref="S3.E1.m1.2.3.6.2.2.5.cmml"><mi id="S3.E1.m1.2.3.6.2.2.5.2" xref="S3.E1.m1.2.3.6.2.2.5.2.cmml">g</mi><mi id="S3.E1.m1.2.3.6.2.2.5.3" xref="S3.E1.m1.2.3.6.2.2.5.3.cmml">e</mi></msub><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.3.6.2.2.1c" xref="S3.E1.m1.2.3.6.2.2.1.cmml">​</mo><msub id="S3.E1.m1.2.3.6.2.2.6" xref="S3.E1.m1.2.3.6.2.2.6.cmml"><mi id="S3.E1.m1.2.3.6.2.2.6.2" xref="S3.E1.m1.2.3.6.2.2.6.2.cmml">a</mi><mi id="S3.E1.m1.2.3.6.2.2.6.3" xref="S3.E1.m1.2.3.6.2.2.6.3.cmml">i</mi></msub></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.2b"><apply id="S3.E1.m1.2.3.cmml" xref="S3.E1.m1.2.3"><and id="S3.E1.m1.2.3a.cmml" xref="S3.E1.m1.2.3"></and><apply id="S3.E1.m1.2.3b.cmml" xref="S3.E1.m1.2.3"><csymbol cd="latexml" id="S3.E1.m1.2.3.3.cmml" xref="S3.E1.m1.2.3.3">proportional-to</csymbol><apply id="S3.E1.m1.2.3.2.cmml" xref="S3.E1.m1.2.3.2"><times id="S3.E1.m1.2.3.2.1.cmml" xref="S3.E1.m1.2.3.2.1"></times><apply id="S3.E1.m1.2.3.2.2.cmml" xref="S3.E1.m1.2.3.2.2"><divide id="S3.E1.m1.2.3.2.2.1.cmml" xref="S3.E1.m1.2.3.2.2.1"></divide><cn type="integer" id="S3.E1.m1.2.3.2.2.2.cmml" xref="S3.E1.m1.2.3.2.2.2">1</cn><ci id="S3.E1.m1.2.3.2.2.3.cmml" xref="S3.E1.m1.2.3.2.2.3">𝐹</ci></apply><ci id="S3.E1.m1.1.1.cmml" xref="S3.E1.m1.1.1">𝐿</ci></apply><apply id="S3.E1.m1.2.3.4.cmml" xref="S3.E1.m1.2.3.4"><times id="S3.E1.m1.2.3.4.1.cmml" xref="S3.E1.m1.2.3.4.1"></times><ci id="S3.E1.m1.2.3.4.2.cmml" xref="S3.E1.m1.2.3.4.2">𝐻</ci><ci id="S3.E1.m1.2.2.cmml" xref="S3.E1.m1.2.2">𝐿</ci></apply></apply><apply id="S3.E1.m1.2.3c.cmml" xref="S3.E1.m1.2.3"><eq id="S3.E1.m1.2.3.5.cmml" xref="S3.E1.m1.2.3.5"></eq><share href="#S3.E1.m1.2.3.4.cmml" id="S3.E1.m1.2.3d.cmml" xref="S3.E1.m1.2.3"></share><apply id="S3.E1.m1.2.3.6.cmml" xref="S3.E1.m1.2.3.6"><minus id="S3.E1.m1.2.3.6.1.cmml" xref="S3.E1.m1.2.3.6"></minus><apply id="S3.E1.m1.2.3.6.2.cmml" xref="S3.E1.m1.2.3.6.2"><apply id="S3.E1.m1.2.3.6.2.1.cmml" xref="S3.E1.m1.2.3.6.2.1"><csymbol cd="ambiguous" id="S3.E1.m1.2.3.6.2.1.1.cmml" xref="S3.E1.m1.2.3.6.2.1">superscript</csymbol><apply id="S3.E1.m1.2.3.6.2.1.2.cmml" xref="S3.E1.m1.2.3.6.2.1"><csymbol cd="ambiguous" id="S3.E1.m1.2.3.6.2.1.2.1.cmml" xref="S3.E1.m1.2.3.6.2.1">subscript</csymbol><sum id="S3.E1.m1.2.3.6.2.1.2.2.cmml" xref="S3.E1.m1.2.3.6.2.1.2.2"></sum><apply id="S3.E1.m1.2.3.6.2.1.2.3.cmml" xref="S3.E1.m1.2.3.6.2.1.2.3"><eq id="S3.E1.m1.2.3.6.2.1.2.3.1.cmml" xref="S3.E1.m1.2.3.6.2.1.2.3.1"></eq><ci id="S3.E1.m1.2.3.6.2.1.2.3.2.cmml" xref="S3.E1.m1.2.3.6.2.1.2.3.2">𝑖</ci><cn type="integer" id="S3.E1.m1.2.3.6.2.1.2.3.3.cmml" xref="S3.E1.m1.2.3.6.2.1.2.3.3">0</cn></apply></apply><ci id="S3.E1.m1.2.3.6.2.1.3.cmml" xref="S3.E1.m1.2.3.6.2.1.3">𝐼</ci></apply><apply id="S3.E1.m1.2.3.6.2.2.cmml" xref="S3.E1.m1.2.3.6.2.2"><times id="S3.E1.m1.2.3.6.2.2.1.cmml" xref="S3.E1.m1.2.3.6.2.2.1"></times><apply id="S3.E1.m1.2.3.6.2.2.2.cmml" xref="S3.E1.m1.2.3.6.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.2.3.6.2.2.2.1.cmml" xref="S3.E1.m1.2.3.6.2.2.2">subscript</csymbol><ci id="S3.E1.m1.2.3.6.2.2.2.2.cmml" xref="S3.E1.m1.2.3.6.2.2.2.2">𝑎</ci><ci id="S3.E1.m1.2.3.6.2.2.2.3.cmml" xref="S3.E1.m1.2.3.6.2.2.2.3">𝑖</ci></apply><ci id="S3.E1.m1.2.3.6.2.2.3.cmml" xref="S3.E1.m1.2.3.6.2.2.3">𝑙</ci><ci id="S3.E1.m1.2.3.6.2.2.4.cmml" xref="S3.E1.m1.2.3.6.2.2.4">𝑜</ci><apply id="S3.E1.m1.2.3.6.2.2.5.cmml" xref="S3.E1.m1.2.3.6.2.2.5"><csymbol cd="ambiguous" id="S3.E1.m1.2.3.6.2.2.5.1.cmml" xref="S3.E1.m1.2.3.6.2.2.5">subscript</csymbol><ci id="S3.E1.m1.2.3.6.2.2.5.2.cmml" xref="S3.E1.m1.2.3.6.2.2.5.2">𝑔</ci><ci id="S3.E1.m1.2.3.6.2.2.5.3.cmml" xref="S3.E1.m1.2.3.6.2.2.5.3">𝑒</ci></apply><apply id="S3.E1.m1.2.3.6.2.2.6.cmml" xref="S3.E1.m1.2.3.6.2.2.6"><csymbol cd="ambiguous" id="S3.E1.m1.2.3.6.2.2.6.1.cmml" xref="S3.E1.m1.2.3.6.2.2.6">subscript</csymbol><ci id="S3.E1.m1.2.3.6.2.2.6.2.cmml" xref="S3.E1.m1.2.3.6.2.2.6.2">𝑎</ci><ci id="S3.E1.m1.2.3.6.2.2.6.3.cmml" xref="S3.E1.m1.2.3.6.2.2.6.3">𝑖</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.2c">1/F(L)\propto H(L)=-\sum_{i=0}^{I}a_{i}log_{e}a_{i}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS2.p7" class="ltx_para">
<p id="S3.SS2.p7.1" class="ltx_p">A lower entropy signifies a more equitable distribution of accuracy, while a higher entropy points to disparities in performance among clients. Due to the data and device heterogeneity, clients usually achieve different learning performances in FL systems. Introducing Fairness in the evaluation metric avoids overemphasizing the overall global model and ignores the participant’s disadvantage. It illustrates the balance of accuracy among the clients, indicating the algorithm’s ability to address the diverse capabilities and characteristics of participating devices, so-called fairness.</p>
</div>
<div id="S3.SS2.p8" class="ltx_para">
<p id="S3.SS2.p8.1" class="ltx_p"><span id="S3.SS2.p8.1.1" class="ltx_text ltx_font_bold">Evaluation Metric Component 5: Personalization (PFL)
<br class="ltx_break"></span>In FL systems, clients may have various exceptions for the global model due to their different interests and use patterns. To evaluate the effectiveness of customization achieved through personalization methods, we introduce the Personalization component into the HEM for PFL algorithms. This component is calculated by comparing the Client Accuracy list with and without introducing personalization methods. Within HEM, Personalization is represented as the median percentage improvement in accuracy across all clients when using the PFL algorithm compared to the original FL algorithm. A higher personalization index indicates the method’s capability to enhance performance for individual clients’ specific data distribution, demonstrating strong potential for delivering personalized functions in real-world applications.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS3.4.1.1" class="ltx_text">III-C</span> </span><span id="S3.SS3.5.2" class="ltx_text ltx_font_italic">Holistic Evaluation Metrics (HEM)</span>
</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">Now, we construct the HEM using the identified components of the evaluation metric. This subsection presents the organization of HEM across the three most representative use cases—IoT, smartphone, and institution; however, the HEM is versatile and can be applied to any other use case.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.1" class="ltx_p">The HEM is generated through a linear combination of each evaluation metric component value and represented as an index ranging from 0 to 1, with 1 denoting the ideal algorithm for a specific use case. Specifically, each evaluation metric component is assigned an importance level (namely Importance Vector) between 0 and 1, considering the specific requirements of the use case. Then, the holistic index is computed as a weighted average of the evaluation metric component indexes, taking into account the significance of each component within the given use case.</p>
</div>
<div id="S3.SS3.p3" class="ltx_para">
<p id="S3.SS3.p3.6" class="ltx_p">Formally, the HEM is generated followed Equation. (2):</p>
<table id="S3.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E2.m1.1" class="ltx_math_unparsed" alttext="HEM=\sum_{i=1}^{N}Index_{i}\cdot\stackrel{{\scriptstyle UseC}}{{ImporV_{i}}}" display="block"><semantics id="S3.E2.m1.1a"><mrow id="S3.E2.m1.1b"><mi id="S3.E2.m1.1.1">H</mi><mi id="S3.E2.m1.1.2">E</mi><mi id="S3.E2.m1.1.3">M</mi><mo rspace="0.111em" id="S3.E2.m1.1.4">=</mo><munderover id="S3.E2.m1.1.5"><mo movablelimits="false" id="S3.E2.m1.1.5.2.2">∑</mo><mrow id="S3.E2.m1.1.5.2.3"><mi id="S3.E2.m1.1.5.2.3.2">i</mi><mo id="S3.E2.m1.1.5.2.3.1">=</mo><mn id="S3.E2.m1.1.5.2.3.3">1</mn></mrow><mi id="S3.E2.m1.1.5.3">N</mi></munderover><mi id="S3.E2.m1.1.6">I</mi><mi id="S3.E2.m1.1.7">n</mi><mi id="S3.E2.m1.1.8">d</mi><mi id="S3.E2.m1.1.9">e</mi><msub id="S3.E2.m1.1.10"><mi id="S3.E2.m1.1.10.2">x</mi><mi id="S3.E2.m1.1.10.3">i</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.E2.m1.1.11">⋅</mo><mover id="S3.E2.m1.1.12"><mrow id="S3.E2.m1.1.12.2"><mi id="S3.E2.m1.1.12.2.2">I</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.12.2.1">​</mo><mi id="S3.E2.m1.1.12.2.3">m</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.12.2.1a">​</mo><mi id="S3.E2.m1.1.12.2.4">p</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.12.2.1b">​</mo><mi id="S3.E2.m1.1.12.2.5">o</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.12.2.1c">​</mo><mi id="S3.E2.m1.1.12.2.6">r</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.12.2.1d">​</mo><msub id="S3.E2.m1.1.12.2.7"><mi id="S3.E2.m1.1.12.2.7.2">V</mi><mi id="S3.E2.m1.1.12.2.7.3">i</mi></msub></mrow><mrow id="S3.E2.m1.1.12.3"><mi id="S3.E2.m1.1.12.3.2">U</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.12.3.1">​</mo><mi id="S3.E2.m1.1.12.3.3">s</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.12.3.1a">​</mo><mi id="S3.E2.m1.1.12.3.4">e</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.12.3.1b">​</mo><mi id="S3.E2.m1.1.12.3.5">C</mi></mrow></mover></mrow><annotation encoding="application/x-tex" id="S3.E2.m1.1c">HEM=\sum_{i=1}^{N}Index_{i}\cdot\stackrel{{\scriptstyle UseC}}{{ImporV_{i}}}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S3.SS3.p3.5" class="ltx_p">where <math id="S3.SS3.p3.1.m1.1" class="ltx_Math" alttext="{Index}_{i}" display="inline"><semantics id="S3.SS3.p3.1.m1.1a"><mrow id="S3.SS3.p3.1.m1.1.1" xref="S3.SS3.p3.1.m1.1.1.cmml"><mi id="S3.SS3.p3.1.m1.1.1.2" xref="S3.SS3.p3.1.m1.1.1.2.cmml">I</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p3.1.m1.1.1.1" xref="S3.SS3.p3.1.m1.1.1.1.cmml">​</mo><mi id="S3.SS3.p3.1.m1.1.1.3" xref="S3.SS3.p3.1.m1.1.1.3.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p3.1.m1.1.1.1a" xref="S3.SS3.p3.1.m1.1.1.1.cmml">​</mo><mi id="S3.SS3.p3.1.m1.1.1.4" xref="S3.SS3.p3.1.m1.1.1.4.cmml">d</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p3.1.m1.1.1.1b" xref="S3.SS3.p3.1.m1.1.1.1.cmml">​</mo><mi id="S3.SS3.p3.1.m1.1.1.5" xref="S3.SS3.p3.1.m1.1.1.5.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p3.1.m1.1.1.1c" xref="S3.SS3.p3.1.m1.1.1.1.cmml">​</mo><msub id="S3.SS3.p3.1.m1.1.1.6" xref="S3.SS3.p3.1.m1.1.1.6.cmml"><mi id="S3.SS3.p3.1.m1.1.1.6.2" xref="S3.SS3.p3.1.m1.1.1.6.2.cmml">x</mi><mi id="S3.SS3.p3.1.m1.1.1.6.3" xref="S3.SS3.p3.1.m1.1.1.6.3.cmml">i</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.1.m1.1b"><apply id="S3.SS3.p3.1.m1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1"><times id="S3.SS3.p3.1.m1.1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1.1"></times><ci id="S3.SS3.p3.1.m1.1.1.2.cmml" xref="S3.SS3.p3.1.m1.1.1.2">𝐼</ci><ci id="S3.SS3.p3.1.m1.1.1.3.cmml" xref="S3.SS3.p3.1.m1.1.1.3">𝑛</ci><ci id="S3.SS3.p3.1.m1.1.1.4.cmml" xref="S3.SS3.p3.1.m1.1.1.4">𝑑</ci><ci id="S3.SS3.p3.1.m1.1.1.5.cmml" xref="S3.SS3.p3.1.m1.1.1.5">𝑒</ci><apply id="S3.SS3.p3.1.m1.1.1.6.cmml" xref="S3.SS3.p3.1.m1.1.1.6"><csymbol cd="ambiguous" id="S3.SS3.p3.1.m1.1.1.6.1.cmml" xref="S3.SS3.p3.1.m1.1.1.6">subscript</csymbol><ci id="S3.SS3.p3.1.m1.1.1.6.2.cmml" xref="S3.SS3.p3.1.m1.1.1.6.2">𝑥</ci><ci id="S3.SS3.p3.1.m1.1.1.6.3.cmml" xref="S3.SS3.p3.1.m1.1.1.6.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.1.m1.1c">{Index}_{i}</annotation></semantics></math> and <math id="S3.SS3.p3.2.m2.1" class="ltx_Math" alttext="ImporV_{i}" display="inline"><semantics id="S3.SS3.p3.2.m2.1a"><mrow id="S3.SS3.p3.2.m2.1.1" xref="S3.SS3.p3.2.m2.1.1.cmml"><mi id="S3.SS3.p3.2.m2.1.1.2" xref="S3.SS3.p3.2.m2.1.1.2.cmml">I</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p3.2.m2.1.1.1" xref="S3.SS3.p3.2.m2.1.1.1.cmml">​</mo><mi id="S3.SS3.p3.2.m2.1.1.3" xref="S3.SS3.p3.2.m2.1.1.3.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p3.2.m2.1.1.1a" xref="S3.SS3.p3.2.m2.1.1.1.cmml">​</mo><mi id="S3.SS3.p3.2.m2.1.1.4" xref="S3.SS3.p3.2.m2.1.1.4.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p3.2.m2.1.1.1b" xref="S3.SS3.p3.2.m2.1.1.1.cmml">​</mo><mi id="S3.SS3.p3.2.m2.1.1.5" xref="S3.SS3.p3.2.m2.1.1.5.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p3.2.m2.1.1.1c" xref="S3.SS3.p3.2.m2.1.1.1.cmml">​</mo><mi id="S3.SS3.p3.2.m2.1.1.6" xref="S3.SS3.p3.2.m2.1.1.6.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p3.2.m2.1.1.1d" xref="S3.SS3.p3.2.m2.1.1.1.cmml">​</mo><msub id="S3.SS3.p3.2.m2.1.1.7" xref="S3.SS3.p3.2.m2.1.1.7.cmml"><mi id="S3.SS3.p3.2.m2.1.1.7.2" xref="S3.SS3.p3.2.m2.1.1.7.2.cmml">V</mi><mi id="S3.SS3.p3.2.m2.1.1.7.3" xref="S3.SS3.p3.2.m2.1.1.7.3.cmml">i</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.2.m2.1b"><apply id="S3.SS3.p3.2.m2.1.1.cmml" xref="S3.SS3.p3.2.m2.1.1"><times id="S3.SS3.p3.2.m2.1.1.1.cmml" xref="S3.SS3.p3.2.m2.1.1.1"></times><ci id="S3.SS3.p3.2.m2.1.1.2.cmml" xref="S3.SS3.p3.2.m2.1.1.2">𝐼</ci><ci id="S3.SS3.p3.2.m2.1.1.3.cmml" xref="S3.SS3.p3.2.m2.1.1.3">𝑚</ci><ci id="S3.SS3.p3.2.m2.1.1.4.cmml" xref="S3.SS3.p3.2.m2.1.1.4">𝑝</ci><ci id="S3.SS3.p3.2.m2.1.1.5.cmml" xref="S3.SS3.p3.2.m2.1.1.5">𝑜</ci><ci id="S3.SS3.p3.2.m2.1.1.6.cmml" xref="S3.SS3.p3.2.m2.1.1.6">𝑟</ci><apply id="S3.SS3.p3.2.m2.1.1.7.cmml" xref="S3.SS3.p3.2.m2.1.1.7"><csymbol cd="ambiguous" id="S3.SS3.p3.2.m2.1.1.7.1.cmml" xref="S3.SS3.p3.2.m2.1.1.7">subscript</csymbol><ci id="S3.SS3.p3.2.m2.1.1.7.2.cmml" xref="S3.SS3.p3.2.m2.1.1.7.2">𝑉</ci><ci id="S3.SS3.p3.2.m2.1.1.7.3.cmml" xref="S3.SS3.p3.2.m2.1.1.7.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.2.m2.1c">ImporV_{i}</annotation></semantics></math> indicate the value (Index) of each evaluation metric component and its associated Importance Vector, respectively. <math id="S3.SS3.p3.3.m3.1" class="ltx_Math" alttext="UseC" display="inline"><semantics id="S3.SS3.p3.3.m3.1a"><mrow id="S3.SS3.p3.3.m3.1.1" xref="S3.SS3.p3.3.m3.1.1.cmml"><mi id="S3.SS3.p3.3.m3.1.1.2" xref="S3.SS3.p3.3.m3.1.1.2.cmml">U</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p3.3.m3.1.1.1" xref="S3.SS3.p3.3.m3.1.1.1.cmml">​</mo><mi id="S3.SS3.p3.3.m3.1.1.3" xref="S3.SS3.p3.3.m3.1.1.3.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p3.3.m3.1.1.1a" xref="S3.SS3.p3.3.m3.1.1.1.cmml">​</mo><mi id="S3.SS3.p3.3.m3.1.1.4" xref="S3.SS3.p3.3.m3.1.1.4.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p3.3.m3.1.1.1b" xref="S3.SS3.p3.3.m3.1.1.1.cmml">​</mo><mi id="S3.SS3.p3.3.m3.1.1.5" xref="S3.SS3.p3.3.m3.1.1.5.cmml">C</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.3.m3.1b"><apply id="S3.SS3.p3.3.m3.1.1.cmml" xref="S3.SS3.p3.3.m3.1.1"><times id="S3.SS3.p3.3.m3.1.1.1.cmml" xref="S3.SS3.p3.3.m3.1.1.1"></times><ci id="S3.SS3.p3.3.m3.1.1.2.cmml" xref="S3.SS3.p3.3.m3.1.1.2">𝑈</ci><ci id="S3.SS3.p3.3.m3.1.1.3.cmml" xref="S3.SS3.p3.3.m3.1.1.3">𝑠</ci><ci id="S3.SS3.p3.3.m3.1.1.4.cmml" xref="S3.SS3.p3.3.m3.1.1.4">𝑒</ci><ci id="S3.SS3.p3.3.m3.1.1.5.cmml" xref="S3.SS3.p3.3.m3.1.1.5">𝐶</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.3.m3.1c">UseC</annotation></semantics></math> demonstrates the target use case, and <math id="S3.SS3.p3.4.m4.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S3.SS3.p3.4.m4.1a"><mi id="S3.SS3.p3.4.m4.1.1" xref="S3.SS3.p3.4.m4.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.4.m4.1b"><ci id="S3.SS3.p3.4.m4.1.1.cmml" xref="S3.SS3.p3.4.m4.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.4.m4.1c">N</annotation></semantics></math> indicates the amount of evaluation metric component. Due to the unique characteristic of each use case, the <math id="S3.SS3.p3.5.m5.1" class="ltx_Math" alttext="\stackrel{{\scriptstyle UseC}}{{ImporV_{i}}}" display="inline"><semantics id="S3.SS3.p3.5.m5.1a"><mover id="S3.SS3.p3.5.m5.1.1" xref="S3.SS3.p3.5.m5.1.1.cmml"><mrow id="S3.SS3.p3.5.m5.1.1.2" xref="S3.SS3.p3.5.m5.1.1.2.cmml"><mi id="S3.SS3.p3.5.m5.1.1.2.2" xref="S3.SS3.p3.5.m5.1.1.2.2.cmml">I</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p3.5.m5.1.1.2.1" xref="S3.SS3.p3.5.m5.1.1.2.1.cmml">​</mo><mi id="S3.SS3.p3.5.m5.1.1.2.3" xref="S3.SS3.p3.5.m5.1.1.2.3.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p3.5.m5.1.1.2.1a" xref="S3.SS3.p3.5.m5.1.1.2.1.cmml">​</mo><mi id="S3.SS3.p3.5.m5.1.1.2.4" xref="S3.SS3.p3.5.m5.1.1.2.4.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p3.5.m5.1.1.2.1b" xref="S3.SS3.p3.5.m5.1.1.2.1.cmml">​</mo><mi id="S3.SS3.p3.5.m5.1.1.2.5" xref="S3.SS3.p3.5.m5.1.1.2.5.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p3.5.m5.1.1.2.1c" xref="S3.SS3.p3.5.m5.1.1.2.1.cmml">​</mo><mi id="S3.SS3.p3.5.m5.1.1.2.6" xref="S3.SS3.p3.5.m5.1.1.2.6.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p3.5.m5.1.1.2.1d" xref="S3.SS3.p3.5.m5.1.1.2.1.cmml">​</mo><msub id="S3.SS3.p3.5.m5.1.1.2.7" xref="S3.SS3.p3.5.m5.1.1.2.7.cmml"><mi id="S3.SS3.p3.5.m5.1.1.2.7.2" xref="S3.SS3.p3.5.m5.1.1.2.7.2.cmml">V</mi><mi id="S3.SS3.p3.5.m5.1.1.2.7.3" xref="S3.SS3.p3.5.m5.1.1.2.7.3.cmml">i</mi></msub></mrow><mrow id="S3.SS3.p3.5.m5.1.1.3" xref="S3.SS3.p3.5.m5.1.1.3.cmml"><mi id="S3.SS3.p3.5.m5.1.1.3.2" xref="S3.SS3.p3.5.m5.1.1.3.2.cmml">U</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p3.5.m5.1.1.3.1" xref="S3.SS3.p3.5.m5.1.1.3.1.cmml">​</mo><mi id="S3.SS3.p3.5.m5.1.1.3.3" xref="S3.SS3.p3.5.m5.1.1.3.3.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p3.5.m5.1.1.3.1a" xref="S3.SS3.p3.5.m5.1.1.3.1.cmml">​</mo><mi id="S3.SS3.p3.5.m5.1.1.3.4" xref="S3.SS3.p3.5.m5.1.1.3.4.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p3.5.m5.1.1.3.1b" xref="S3.SS3.p3.5.m5.1.1.3.1.cmml">​</mo><mi id="S3.SS3.p3.5.m5.1.1.3.5" xref="S3.SS3.p3.5.m5.1.1.3.5.cmml">C</mi></mrow></mover><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.5.m5.1b"><apply id="S3.SS3.p3.5.m5.1.1.cmml" xref="S3.SS3.p3.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.5.m5.1.1.1.cmml" xref="S3.SS3.p3.5.m5.1.1">superscript</csymbol><apply id="S3.SS3.p3.5.m5.1.1.2.cmml" xref="S3.SS3.p3.5.m5.1.1.2"><times id="S3.SS3.p3.5.m5.1.1.2.1.cmml" xref="S3.SS3.p3.5.m5.1.1.2.1"></times><ci id="S3.SS3.p3.5.m5.1.1.2.2.cmml" xref="S3.SS3.p3.5.m5.1.1.2.2">𝐼</ci><ci id="S3.SS3.p3.5.m5.1.1.2.3.cmml" xref="S3.SS3.p3.5.m5.1.1.2.3">𝑚</ci><ci id="S3.SS3.p3.5.m5.1.1.2.4.cmml" xref="S3.SS3.p3.5.m5.1.1.2.4">𝑝</ci><ci id="S3.SS3.p3.5.m5.1.1.2.5.cmml" xref="S3.SS3.p3.5.m5.1.1.2.5">𝑜</ci><ci id="S3.SS3.p3.5.m5.1.1.2.6.cmml" xref="S3.SS3.p3.5.m5.1.1.2.6">𝑟</ci><apply id="S3.SS3.p3.5.m5.1.1.2.7.cmml" xref="S3.SS3.p3.5.m5.1.1.2.7"><csymbol cd="ambiguous" id="S3.SS3.p3.5.m5.1.1.2.7.1.cmml" xref="S3.SS3.p3.5.m5.1.1.2.7">subscript</csymbol><ci id="S3.SS3.p3.5.m5.1.1.2.7.2.cmml" xref="S3.SS3.p3.5.m5.1.1.2.7.2">𝑉</ci><ci id="S3.SS3.p3.5.m5.1.1.2.7.3.cmml" xref="S3.SS3.p3.5.m5.1.1.2.7.3">𝑖</ci></apply></apply><apply id="S3.SS3.p3.5.m5.1.1.3.cmml" xref="S3.SS3.p3.5.m5.1.1.3"><times id="S3.SS3.p3.5.m5.1.1.3.1.cmml" xref="S3.SS3.p3.5.m5.1.1.3.1"></times><ci id="S3.SS3.p3.5.m5.1.1.3.2.cmml" xref="S3.SS3.p3.5.m5.1.1.3.2">𝑈</ci><ci id="S3.SS3.p3.5.m5.1.1.3.3.cmml" xref="S3.SS3.p3.5.m5.1.1.3.3">𝑠</ci><ci id="S3.SS3.p3.5.m5.1.1.3.4.cmml" xref="S3.SS3.p3.5.m5.1.1.3.4">𝑒</ci><ci id="S3.SS3.p3.5.m5.1.1.3.5.cmml" xref="S3.SS3.p3.5.m5.1.1.3.5">𝐶</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.5.m5.1c">\stackrel{{\scriptstyle UseC}}{{ImporV_{i}}}</annotation></semantics></math> should be different. TABLE. <a href="#S3.T2" title="TABLE II ‣ III-A3 Internet of Things (IoT) ‣ III-A Federated Learning Use Cases ‣ III Holistic Evaluation Metrics ‣ Holistic Evaluation Metrics: Use Case Sensitive Evaluation Metrics for Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a> illustrates the HEM component importance for IoT, smartphone and institution use cases, and we will provide detailed information and discussion in the following subsections.</p>
</div>
<figure id="S3.F1" class="ltx_figure"><img src="/html/2405.02360/assets/overview.jpg" id="S3.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="334" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>The overall evaluation process with HEM for PFL in different use cases.</figcaption>
</figure>
<section id="S3.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS3.SSS1.4.1.1" class="ltx_text">III-C</span>1 </span>HEM for IoT Use Cases</h4>

<div id="S3.SS3.SSS1.p1" class="ltx_para">
<p id="S3.SS3.SSS1.p1.1" class="ltx_p">Given the advancements in FL and IoT technologies, heavy machinery (including autonomous vehicles and cranes) can now operate autonomously, significantly reducing the human workload <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>, <a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite>. However, given their considerable volume, weight, and strength, any inaccuracies in the decisions made by these machines could lead to life-threatening outcomes. Therefore, maintaining a high level of accuracy for every single participant in IoT scenarios is crucial, justifying the High importance of the evaluation components - Client Accuracy and Fairness. Similarly, the Computational Efficiency component is also deemed as High important due to the limited computational resources of most IoT devices. We note that although some of these devices are allowed to train FL models in the background without impacting their primary functions, their reduced CPU power and memory capacity restrict the effectiveness of such background processes, which emphasizes the priority of Computational Efficiency. On the contrary, due to the IoT devices typically remaining idle for an extended duration, which could make the execution of numerous FL communication rounds <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite>, the importance of the model Convergence is considered as Low level.</p>
</div>
</section>
<section id="S3.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS3.SSS2.4.1.1" class="ltx_text">III-C</span>2 </span>HEM for Smartphone Use Cases</h4>

<div id="S3.SS3.SSS2.p1" class="ltx_para">
<p id="S3.SS3.SSS2.p1.1" class="ltx_p">Today, smartphones (as well as smart devices) provide numerous applications to the user based on their platform. To derive the importance of each metric component for the smartphone use case, we take the “next word prediction” as an example <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>. Through literature review, we note that most next-word prediction applications do not reach very high accuracy (over 90%) and only support general prediction services <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>, <a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite>. On the other hand, while service providers aim to deliver customized predictions, creating a personalized model for each individual client within a network is impractical due to the vast number of users. Thus, in the use case of “next word prediction,” we rank the importance of Client Accuracy and Fairness as Moderate. As the environment changes dynamically with the user, smartphones usually suffer from fluctuating bandwidth and network. This unstable connection between client nodes and the server emphasizes the requirement of effectiveness Convergence of the FL model, with the importance level as High <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite>. Furthermore, as most smartphones are designed with limited computational resources to facilitate portability, we classify the importance of Computational Efficiency as High level.</p>
</div>
</section>
<section id="S3.SS3.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS3.SSS3.4.1.1" class="ltx_text">III-C</span>3 </span>HEM for Institution Use Cases</h4>

<div id="S3.SS3.SSS3.p1" class="ltx_para">
<p id="S3.SS3.SSS3.p1.1" class="ltx_p">The institutional use cases include all organizations or institutions that are sensitive to data privacy and seek to benefit from FL systems.
Here, we take healthcare institutions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite> as the example to derive and investigate the importance level for each component of HEM. Given that medical diagnoses contain highly sensitive patient information, individuals may not be willing to participate in the FL task and contribute their data if the algorithm does not offer a satisfactory service. Thus, Client Accuracy and Fairness achieve a High importance level in institutional use cases. On the other hand, institutions usually have stable networking, high bandwidth, and sufficient computational resources. They can afford computing-intensive learning tasks and achieve regular communication between the server and end nodes. Thus, the Convergence and Computational Efficiency are rated as Low importance.
<br class="ltx_break"></p>
</div>
<div id="S3.SS3.SSS3.p2" class="ltx_para">
<p id="S3.SS3.SSS3.p2.1" class="ltx_p">While we emphasize the importance of each component covering the most applications in three use cases, we acknowledge that certain specific applications within these categories may have unique requirements. Therefore, the importance levels indicated in Table <a href="#S3.T2" title="TABLE II ‣ III-A3 Internet of Things (IoT) ‣ III-A Federated Learning Use Cases ‣ III Holistic Evaluation Metrics ‣ Holistic Evaluation Metrics: Use Case Sensitive Evaluation Metrics for Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a> are intended as general guidelines, subject to further alignment based on the particular demands of individual applications.</p>
</div>
</section>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS4.4.1.1" class="ltx_text">III-D</span> </span><span id="S3.SS4.5.2" class="ltx_text ltx_font_italic">Evaluation Process</span>
</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.1" class="ltx_p">In this section, we discuss the evaluation process from preparation through to the generation of HEM.</p>
</div>
<div id="S3.SS4.p2" class="ltx_para">
<p id="S3.SS4.p2.1" class="ltx_p">During the HEM evaluation procedure, the evaluator starts by selecting candidates FL algorithms, identifying the learning tasks that fit the specific use case, and establishing the termination criteria for local and global model training. These criteria include the target accuracy and a preset training round. The testing datasets should be collected to facilitate both global and local model testing, ensuring that the selection of testing data reflects the non-IID data distribution of FL and the given use case.</p>
</div>
<div id="S3.SS4.p3" class="ltx_para">
<p id="S3.SS4.p3.1" class="ltx_p">When performing the evaluation, each selected FL algorithm undergoes normal training within the specified scenario, during which both the training duration and the number of learning rounds are recorded until the predefined end conditions are satisfied. To derive all evaluation components, the delivered model under selected FL algorithms may be initialized and undergo multiple training times, concluding upon meeting various predefined thresholds. Following training, the models are assessed using testing datasets to generate index values from various perspectives. Considering the Importance Vector specific to the use case, these index values are then converted into HEM scores. While Table <a href="#S3.T2" title="TABLE II ‣ III-A3 Internet of Things (IoT) ‣ III-A Federated Learning Use Cases ‣ III Holistic Evaluation Metrics ‣ Holistic Evaluation Metrics: Use Case Sensitive Evaluation Metrics for Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a> provides a guideline about the components’ importance in different use cases, these importance levels could be further updated based on the requirements of the given scenario and applications. These HEM scores finally facilitate the informed selection of FL algorithms for subsequent use. The evaluation process through HEM is shown in Figure <a href="#S3.F1" title="Figure 1 ‣ III-C Holistic Evaluation Metrics (HEM) ‣ III Holistic Evaluation Metrics ‣ Holistic Evaluation Metrics: Use Case Sensitive Evaluation Metrics for Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">FL Algorithms Evaluation through HEM</span>
</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">In this section, we evaluate the most prominent FL algorithms and personalization methods using the proposed HEM index and the corresponding evaluation process. Initially, the evaluation focuses on each individual component of the metric. We then integrate these components into the HEM framework using the formula referenced in Equation (2). THis section concludes with a discussion of the findings.</p>
</div>
<figure id="S4.T3" class="ltx_table">
<table id="S4.T3.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T3.1.1.1" class="ltx_tr">
<td id="S4.T3.1.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_t"><span id="S4.T3.1.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">FL Algorithm</span></td>
<td id="S4.T3.1.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_t"><span id="S4.T3.1.1.1.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Client Accuracy</span></td>
<td id="S4.T3.1.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_t"><span id="S4.T3.1.1.1.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Convergence</span></td>
<td id="S4.T3.1.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_t"><span id="S4.T3.1.1.1.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Computation Efficiency</span></td>
<td id="S4.T3.1.1.1.5" class="ltx_td ltx_align_center ltx_border_tt ltx_border_t"><span id="S4.T3.1.1.1.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Fairness</span></td>
</tr>
<tr id="S4.T3.1.2.2" class="ltx_tr">
<td id="S4.T3.1.2.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.1.2.2.1.1" class="ltx_text" style="font-size:90%;">FedAvg</span></td>
<td id="S4.T3.1.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.1.2.2.2.1" class="ltx_text" style="font-size:90%;">0.84</span></td>
<td id="S4.T3.1.2.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.1.2.2.3.1" class="ltx_text" style="font-size:90%;">0.67</span></td>
<td id="S4.T3.1.2.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.1.2.2.4.1" class="ltx_text" style="font-size:90%;">0.12</span></td>
<td id="S4.T3.1.2.2.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.1.2.2.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">1.00</span></td>
</tr>
<tr id="S4.T3.1.3.3" class="ltx_tr">
<td id="S4.T3.1.3.3.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.1.3.3.1.1" class="ltx_text" style="font-size:90%;">FedAvg_MAML</span></td>
<td id="S4.T3.1.3.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.1.3.3.2.1" class="ltx_text" style="font-size:90%;">0.88</span></td>
<td id="S4.T3.1.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.1.3.3.3.1" class="ltx_text" style="font-size:90%;">0.90</span></td>
<td id="S4.T3.1.3.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.1.3.3.4.1" class="ltx_text" style="font-size:90%;">0.00</span></td>
<td id="S4.T3.1.3.3.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.1.3.3.5.1" class="ltx_text" style="font-size:90%;">0.55</span></td>
</tr>
<tr id="S4.T3.1.4.4" class="ltx_tr">
<td id="S4.T3.1.4.4.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.1.4.4.1.1" class="ltx_text" style="font-size:90%;">FedAvg_Proto</span></td>
<td id="S4.T3.1.4.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.1.4.4.2.1" class="ltx_text" style="font-size:90%;">0.88</span></td>
<td id="S4.T3.1.4.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.1.4.4.3.1" class="ltx_text" style="font-size:90%;">0.85</span></td>
<td id="S4.T3.1.4.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.1.4.4.4.1" class="ltx_text" style="font-size:90%;">0.78</span></td>
<td id="S4.T3.1.4.4.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.1.4.4.5.1" class="ltx_text" style="font-size:90%;">0.36</span></td>
</tr>
<tr id="S4.T3.1.5.5" class="ltx_tr">
<td id="S4.T3.1.5.5.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.1.5.5.1.1" class="ltx_text" style="font-size:90%;">FedDyn</span></td>
<td id="S4.T3.1.5.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.1.5.5.2.1" class="ltx_text" style="font-size:90%;">0.85</span></td>
<td id="S4.T3.1.5.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.1.5.5.3.1" class="ltx_text" style="font-size:90%;">0.69</span></td>
<td id="S4.T3.1.5.5.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.1.5.5.4.1" class="ltx_text" style="font-size:90%;">0.21</span></td>
<td id="S4.T3.1.5.5.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.1.5.5.5.1" class="ltx_text" style="font-size:90%;">0.41</span></td>
</tr>
<tr id="S4.T3.1.6.6" class="ltx_tr">
<td id="S4.T3.1.6.6.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.1.6.6.1.1" class="ltx_text" style="font-size:90%;">FedDyn_MAML</span></td>
<td id="S4.T3.1.6.6.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.1.6.6.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.89</span></td>
<td id="S4.T3.1.6.6.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.1.6.6.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.94</span></td>
<td id="S4.T3.1.6.6.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.1.6.6.4.1" class="ltx_text" style="font-size:90%;">0.56</span></td>
<td id="S4.T3.1.6.6.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.1.6.6.5.1" class="ltx_text" style="font-size:90%;">0.00</span></td>
</tr>
<tr id="S4.T3.1.7.7" class="ltx_tr">
<td id="S4.T3.1.7.7.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.1.7.7.1.1" class="ltx_text" style="font-size:90%;">FedDyn_Proto</span></td>
<td id="S4.T3.1.7.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.1.7.7.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.89</span></td>
<td id="S4.T3.1.7.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.1.7.7.3.1" class="ltx_text" style="font-size:90%;">0.92</span></td>
<td id="S4.T3.1.7.7.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.1.7.7.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.89</span></td>
<td id="S4.T3.1.7.7.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.1.7.7.5.1" class="ltx_text" style="font-size:90%;">0.27</span></td>
</tr>
<tr id="S4.T3.1.8.8" class="ltx_tr">
<td id="S4.T3.1.8.8.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.1.8.8.1.1" class="ltx_text" style="font-size:90%;">SCAFFOLD</span></td>
<td id="S4.T3.1.8.8.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.1.8.8.2.1" class="ltx_text" style="font-size:90%;">0.86</span></td>
<td id="S4.T3.1.8.8.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.1.8.8.3.1" class="ltx_text" style="font-size:90%;">0.86</span></td>
<td id="S4.T3.1.8.8.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.1.8.8.4.1" class="ltx_text" style="font-size:90%;">0.44</span></td>
<td id="S4.T3.1.8.8.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.1.8.8.5.1" class="ltx_text" style="font-size:90%;">0.59</span></td>
</tr>
<tr id="S4.T3.1.9.9" class="ltx_tr">
<td id="S4.T3.1.9.9.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.1.9.9.1.1" class="ltx_text" style="font-size:90%;">SCAFFOLD_MAML</span></td>
<td id="S4.T3.1.9.9.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.1.9.9.2.1" class="ltx_text" style="font-size:90%;">0.87</span></td>
<td id="S4.T3.1.9.9.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.1.9.9.3.1" class="ltx_text" style="font-size:90%;">0.86</span></td>
<td id="S4.T3.1.9.9.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.1.9.9.4.1" class="ltx_text" style="font-size:90%;">0.67</span></td>
<td id="S4.T3.1.9.9.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.1.9.9.5.1" class="ltx_text" style="font-size:90%;">0.23</span></td>
</tr>
<tr id="S4.T3.1.10.10" class="ltx_tr">
<td id="S4.T3.1.10.10.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T3.1.10.10.1.1" class="ltx_text" style="font-size:90%;">SCAFFOLD_Proto</span></td>
<td id="S4.T3.1.10.10.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T3.1.10.10.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.89</span></td>
<td id="S4.T3.1.10.10.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T3.1.10.10.3.1" class="ltx_text" style="font-size:90%;">0.91</span></td>
<td id="S4.T3.1.10.10.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T3.1.10.10.4.1" class="ltx_text" style="font-size:90%;">0.87</span></td>
<td id="S4.T3.1.10.10.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_b ltx_border_t"><span id="S4.T3.1.10.10.5.1" class="ltx_text" style="font-size:90%;">0.05</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">TABLE III: </span>The accuracy, convergence, computation efficiency, fairness index (performances) of different FL algorithms.</figcaption>
</figure>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS1.4.1.1" class="ltx_text">IV-A</span> </span><span id="S4.SS1.5.2" class="ltx_text ltx_font_italic">Experiments Setup</span>
</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">We consider 100 clients participating in the FL tasks; each client trains the model with data on only 5 out of 10 classes in the chosen dataset. We set the end conditions as “1000 communication rounds” to generate the Client Accuracy index and “80% accuracy” to generate the Convergence index. We use The Cifar-10 as the training dataset, which consists of 60000, 32x32 pixels color images in 10 classes, including airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.3" class="ltx_p">As the overall data distribution in FL is considered non-IID, we introduce a custom dataset configuration to tailor the dataset to the requirements of our FL simulations.
Specifically, we distribute 5 classes of training and test data to each end node based on its class list. The <math id="S4.SS1.p2.1.m1.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S4.SS1.p2.1.m1.1a"><mi id="S4.SS1.p2.1.m1.1.1" xref="S4.SS1.p2.1.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.1.m1.1b"><ci id="S4.SS1.p2.1.m1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.1.m1.1c">i</annotation></semantics></math>th client is assigned the class list shown as follows, where <math id="S4.SS1.p2.2.m2.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S4.SS1.p2.2.m2.1a"><mo id="S4.SS1.p2.2.m2.1.1" xref="S4.SS1.p2.2.m2.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.2.m2.1b"><csymbol cd="latexml" id="S4.SS1.p2.2.m2.1.1.cmml" xref="S4.SS1.p2.2.m2.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.2.m2.1c">\%</annotation></semantics></math> denotes operation <math id="S4.SS1.p2.3.m3.1" class="ltx_Math" alttext="MOD" display="inline"><semantics id="S4.SS1.p2.3.m3.1a"><mrow id="S4.SS1.p2.3.m3.1.1" xref="S4.SS1.p2.3.m3.1.1.cmml"><mi id="S4.SS1.p2.3.m3.1.1.2" xref="S4.SS1.p2.3.m3.1.1.2.cmml">M</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p2.3.m3.1.1.1" xref="S4.SS1.p2.3.m3.1.1.1.cmml">​</mo><mi id="S4.SS1.p2.3.m3.1.1.3" xref="S4.SS1.p2.3.m3.1.1.3.cmml">O</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p2.3.m3.1.1.1a" xref="S4.SS1.p2.3.m3.1.1.1.cmml">​</mo><mi id="S4.SS1.p2.3.m3.1.1.4" xref="S4.SS1.p2.3.m3.1.1.4.cmml">D</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.3.m3.1b"><apply id="S4.SS1.p2.3.m3.1.1.cmml" xref="S4.SS1.p2.3.m3.1.1"><times id="S4.SS1.p2.3.m3.1.1.1.cmml" xref="S4.SS1.p2.3.m3.1.1.1"></times><ci id="S4.SS1.p2.3.m3.1.1.2.cmml" xref="S4.SS1.p2.3.m3.1.1.2">𝑀</ci><ci id="S4.SS1.p2.3.m3.1.1.3.cmml" xref="S4.SS1.p2.3.m3.1.1.3">𝑂</ci><ci id="S4.SS1.p2.3.m3.1.1.4.cmml" xref="S4.SS1.p2.3.m3.1.1.4">𝐷</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.3.m3.1c">MOD</annotation></semantics></math>:</p>
<table id="S4.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E3.m1.7" class="ltx_Math" alttext="(i+n)\%10,n\in[0,1,2,3,4]" display="block"><semantics id="S4.E3.m1.7a"><mrow id="S4.E3.m1.7.7" xref="S4.E3.m1.7.7.cmml"><mrow id="S4.E3.m1.7.7.1.1" xref="S4.E3.m1.7.7.1.2.cmml"><mrow id="S4.E3.m1.7.7.1.1.1" xref="S4.E3.m1.7.7.1.1.1.cmml"><mrow id="S4.E3.m1.7.7.1.1.1.1" xref="S4.E3.m1.7.7.1.1.1.1.cmml"><mrow id="S4.E3.m1.7.7.1.1.1.1.1.1" xref="S4.E3.m1.7.7.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.E3.m1.7.7.1.1.1.1.1.1.2" xref="S4.E3.m1.7.7.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.E3.m1.7.7.1.1.1.1.1.1.1" xref="S4.E3.m1.7.7.1.1.1.1.1.1.1.cmml"><mi id="S4.E3.m1.7.7.1.1.1.1.1.1.1.2" xref="S4.E3.m1.7.7.1.1.1.1.1.1.1.2.cmml">i</mi><mo id="S4.E3.m1.7.7.1.1.1.1.1.1.1.1" xref="S4.E3.m1.7.7.1.1.1.1.1.1.1.1.cmml">+</mo><mi id="S4.E3.m1.7.7.1.1.1.1.1.1.1.3" xref="S4.E3.m1.7.7.1.1.1.1.1.1.1.3.cmml">n</mi></mrow><mo stretchy="false" id="S4.E3.m1.7.7.1.1.1.1.1.1.3" xref="S4.E3.m1.7.7.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="S4.E3.m1.7.7.1.1.1.1.2" xref="S4.E3.m1.7.7.1.1.1.1.2.cmml">%</mo></mrow><mo lspace="0em" rspace="0em" id="S4.E3.m1.7.7.1.1.1.2" xref="S4.E3.m1.7.7.1.1.1.2.cmml">​</mo><mn id="S4.E3.m1.7.7.1.1.1.3" xref="S4.E3.m1.7.7.1.1.1.3.cmml">10</mn></mrow><mo id="S4.E3.m1.7.7.1.1.2" xref="S4.E3.m1.7.7.1.2.cmml">,</mo><mi id="S4.E3.m1.6.6" xref="S4.E3.m1.6.6.cmml">n</mi></mrow><mo id="S4.E3.m1.7.7.2" xref="S4.E3.m1.7.7.2.cmml">∈</mo><mrow id="S4.E3.m1.7.7.3.2" xref="S4.E3.m1.7.7.3.1.cmml"><mo stretchy="false" id="S4.E3.m1.7.7.3.2.1" xref="S4.E3.m1.7.7.3.1.cmml">[</mo><mn id="S4.E3.m1.1.1" xref="S4.E3.m1.1.1.cmml">0</mn><mo id="S4.E3.m1.7.7.3.2.2" xref="S4.E3.m1.7.7.3.1.cmml">,</mo><mn id="S4.E3.m1.2.2" xref="S4.E3.m1.2.2.cmml">1</mn><mo id="S4.E3.m1.7.7.3.2.3" xref="S4.E3.m1.7.7.3.1.cmml">,</mo><mn id="S4.E3.m1.3.3" xref="S4.E3.m1.3.3.cmml">2</mn><mo id="S4.E3.m1.7.7.3.2.4" xref="S4.E3.m1.7.7.3.1.cmml">,</mo><mn id="S4.E3.m1.4.4" xref="S4.E3.m1.4.4.cmml">3</mn><mo id="S4.E3.m1.7.7.3.2.5" xref="S4.E3.m1.7.7.3.1.cmml">,</mo><mn id="S4.E3.m1.5.5" xref="S4.E3.m1.5.5.cmml">4</mn><mo stretchy="false" id="S4.E3.m1.7.7.3.2.6" xref="S4.E3.m1.7.7.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E3.m1.7b"><apply id="S4.E3.m1.7.7.cmml" xref="S4.E3.m1.7.7"><in id="S4.E3.m1.7.7.2.cmml" xref="S4.E3.m1.7.7.2"></in><list id="S4.E3.m1.7.7.1.2.cmml" xref="S4.E3.m1.7.7.1.1"><apply id="S4.E3.m1.7.7.1.1.1.cmml" xref="S4.E3.m1.7.7.1.1.1"><times id="S4.E3.m1.7.7.1.1.1.2.cmml" xref="S4.E3.m1.7.7.1.1.1.2"></times><apply id="S4.E3.m1.7.7.1.1.1.1.cmml" xref="S4.E3.m1.7.7.1.1.1.1"><csymbol cd="latexml" id="S4.E3.m1.7.7.1.1.1.1.2.cmml" xref="S4.E3.m1.7.7.1.1.1.1.2">percent</csymbol><apply id="S4.E3.m1.7.7.1.1.1.1.1.1.1.cmml" xref="S4.E3.m1.7.7.1.1.1.1.1.1"><plus id="S4.E3.m1.7.7.1.1.1.1.1.1.1.1.cmml" xref="S4.E3.m1.7.7.1.1.1.1.1.1.1.1"></plus><ci id="S4.E3.m1.7.7.1.1.1.1.1.1.1.2.cmml" xref="S4.E3.m1.7.7.1.1.1.1.1.1.1.2">𝑖</ci><ci id="S4.E3.m1.7.7.1.1.1.1.1.1.1.3.cmml" xref="S4.E3.m1.7.7.1.1.1.1.1.1.1.3">𝑛</ci></apply></apply><cn type="integer" id="S4.E3.m1.7.7.1.1.1.3.cmml" xref="S4.E3.m1.7.7.1.1.1.3">10</cn></apply><ci id="S4.E3.m1.6.6.cmml" xref="S4.E3.m1.6.6">𝑛</ci></list><list id="S4.E3.m1.7.7.3.1.cmml" xref="S4.E3.m1.7.7.3.2"><cn type="integer" id="S4.E3.m1.1.1.cmml" xref="S4.E3.m1.1.1">0</cn><cn type="integer" id="S4.E3.m1.2.2.cmml" xref="S4.E3.m1.2.2">1</cn><cn type="integer" id="S4.E3.m1.3.3.cmml" xref="S4.E3.m1.3.3">2</cn><cn type="integer" id="S4.E3.m1.4.4.cmml" xref="S4.E3.m1.4.4">3</cn><cn type="integer" id="S4.E3.m1.5.5.cmml" xref="S4.E3.m1.5.5">4</cn></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E3.m1.7c">(i+n)\%10,n\in[0,1,2,3,4]</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p id="S4.SS1.p3.1" class="ltx_p">We select the 5 most representative Fl algorithms for experiments, including FedAvg, FedDyn, SCAFFOLD, MAML (for personalized), and ProtoNet (for personalized). We use a CNN in our experiments, which has two convolutional layers (64× and 5×5 kernels), a max pooling layer, two fully connected layers (384×, 192×) with ReLU activation, and a softmax layer.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS2.4.1.1" class="ltx_text">IV-B</span> </span><span id="S4.SS2.5.2" class="ltx_text ltx_font_italic">Evaluation Metric Component Indexes</span>
</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">Table <a href="#S4.T3" title="TABLE III ‣ IV FL Algorithms Evaluation through HEM ‣ Holistic Evaluation Metrics: Use Case Sensitive Evaluation Metrics for Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a> illustrates the Client Accuracy, Convergence, Computation Efficiency, and Fairness index (evaluation outcomes) of different FL algorithms and their personalized implementation.</p>
</div>
<section id="S4.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS2.SSS1.4.1.1" class="ltx_text">IV-B</span>1 </span>Client Accuracy Index</h4>

<div id="S4.SS2.SSS1.p1" class="ltx_para">
<p id="S4.SS2.SSS1.p1.1" class="ltx_p">The experimental results show that all FL algorithms achieve a high client model testing accuracy, with a variance in the accuracy index among them of less than 0.05. FedDyn, utilizing both MAML and Proto personalization methods, and SCAFFOLD, with Proto personalization, attain the highest performance, each achieving an accuracy of 0.89. In contrast, FedAvg witnesses the lowest testing accuracy at 0.84. The accuracy gap can be attributed to FedAvg’s performance degradation when facing heterogeneous and non-IID data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>. Furthermore, personalization methods such as MAML and Proto allow individual clients to receive FL models that are better fitted to their unique data distributions. Consequently, algorithms personalized through these methods show approximately 3% higher accuracy compared to their original algorithms.</p>
</div>
</section>
<section id="S4.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS2.SSS2.4.1.1" class="ltx_text">IV-B</span>2 </span>Convergence Index</h4>

<div id="S4.SS2.SSS2.p1" class="ltx_para">
<p id="S4.SS2.SSS2.p1.1" class="ltx_p">The Convergence Index across all simulated FL algorithms exhibits a wider range than the Client Accuracy, with the lowest performing algorithm, FedAvg, demonstrating a difference of approximately 0.17 when compared to the highest performing algorithm, FedDyn_MAML. Specifically, FedDyn_MAML, FedAvg_MAML, FedDyn_Proto, and SCAFFOLD_Proto show a higher performance, achieving a Convergence Index of over 0.90. In contrast, the lowest Convergence Index is observed in FedAvg and FedDyn, both falling below 0.7. This convergence performance difference is attributed to the accuracy gains in PFL algorithms achieved through the effectiveness of meta-learning techniques. Such techniques enable FL algorithms to transfer knowledge across clients, facilitating faster convergence <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>. In contrast, non-personalized FL algorithms may not consistently converge in limited communication rounds, particularly when trained on clients with strong non-IID data distribution (as simulated).</p>
</div>
</section>
<section id="S4.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS2.SSS3.4.1.1" class="ltx_text">IV-B</span>3 </span>Computational Efficiency Index</h4>

<div id="S4.SS2.SSS3.p1" class="ltx_para">
<p id="S4.SS2.SSS3.p1.1" class="ltx_p">The Computational Efficiency index is a comparative index across the simulated algorithms. As achieving the longest TTA, FedAvg_MAML is assigned to the lowest Computational Efficiency Index with 0. The experimental results indicate a strong correlation between the Computational Efficiency of FL algorithms and the personalization methods employed. Specifically, for each base FL algorithm, the incorporation of Proto personalization results in better computational efficiency compared to the integration of MAML. Besides, while recent computational efficiency research indicates FedAvg outperformed SCAFFOLD when the client datasets were IID <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>, we note SCAFFOLD heavily outperformed FedAvg in non-IID scenarios. For instance, FedAvg, MAML, and Proto achieve 0.12, 0.00, and 0.78 Computation Efficiency Index, while SCAFFOLD, MAML, and Proto achieve 0.44, 0.67, and 0.87, respectively.</p>
</div>
</section>
<section id="S4.SS2.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS2.SSS4.4.1.1" class="ltx_text">IV-B</span>4 </span>Fairness Index</h4>

<div id="S4.SS2.SSS4.p1" class="ltx_para">
<p id="S4.SS2.SSS4.p1.1" class="ltx_p">The Fairness index serves as a comparative measure across the simulated algorithms, scaling from 0 to 1. Among the three non-personalized FL algorithms, FedAvg achieves the highest Fairness Index (indicating the lowest entropy) with a score of 1.00. It is followed by SCAFFOLD with a score of 0.59, FedAvg_MALA at 0.55, and FedDyn at 0.41. In contrast, FedDyn_MAML exhibits the highest entropy in its accuracy list, resulting in the lowest Fairness index of 0. Besides, the experimental results indicate that incorporating personalization methods into these FL algorithms increases the variance in clients’ accuracy and leads to a reduction in the Fairness Index. Specifically, FedAvg, FedDyn, and SCAFFOLD exhibit reductions in their Fairness Index ranging from 0.45 to 0.64, 0.14 to 0.41, and 0.36 to 0.54, respectively.</p>
</div>
</section>
<section id="S4.SS2.SSS5" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS2.SSS5.4.1.1" class="ltx_text">IV-B</span>5 </span>Personalization of PFL Algorithms</h4>

<div id="S4.SS2.SSS5.p1" class="ltx_para">
<p id="S4.SS2.SSS5.p1.1" class="ltx_p">The experimental results demonstrate that two personalization methods, Proto and MAML, effectively enhance model learning performance based on the client’s specific data distribution, resulting in positive personalization indices for all evaluated algorithms. Specifically, FedAvg_Proto emerged as the most personalized FL algorithm, achieving a Median Percentage of Client Accuracy Improvement (MPI) of 10.46, closely followed by FedAvg_MAML. The FedDyn class of PFL algorithms demonstrates moderate levels of personalization, receiving MPI values of 9.2 and 8.11 for the Proto and MAML methods, respectively. Conversely, SCAFFOLD PFL algorithms show the lowest degree of personalization, with an average MPI value of around 8.</p>
</div>
<div id="S4.SS2.SSS5.p2" class="ltx_para">
<p id="S4.SS2.SSS5.p2.1" class="ltx_p">Figure <a href="#S4.F2" title="Figure 2 ‣ IV-B5 Personalization of PFL Algorithms ‣ IV-B Evaluation Metric Component Indexes ‣ IV FL Algorithms Evaluation through HEM ‣ Holistic Evaluation Metrics: Use Case Sensitive Evaluation Metrics for Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> illustrates the personalization capabilities of PFL algorithms.</p>
</div>
<figure id="S4.F2" class="ltx_figure"><img src="/html/2405.02360/assets/Personalization.png" id="S4.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="399" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Personalization of PFL algorithms</figcaption>
</figure>
</section>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS3.4.1.1" class="ltx_text">IV-C</span> </span><span id="S4.SS3.5.2" class="ltx_text ltx_font_italic">Holistic Evaluation for the Three Use Cases</span>
</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">In this section, we conduct the HEM evaluation of the FL algorithms across the identified use cases (IoT, institution, and smartphone) based on the experimental results presented in Section <a href="#S4.SS2" title="IV-B Evaluation Metric Component Indexes ‣ IV FL Algorithms Evaluation through HEM ‣ Holistic Evaluation Metrics: Use Case Sensitive Evaluation Metrics for Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">IV-B</span></span></a> and Equation <a href="#S3.E2" title="In III-C Holistic Evaluation Metrics (HEM) ‣ III Holistic Evaluation Metrics ‣ Holistic Evaluation Metrics: Use Case Sensitive Evaluation Metrics for Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. The importance levels are quantified as follows: High is assigned an index of 3, Moderate is an index of 2, and Low is an index of 1 for organizing HEMs. Under this simulation, an FL algorithm exhibits Excellent overall performance if its HEM index is greater than 0.8. Performance is classified as Good for HEM indices ranging from 0.7 to 0.8, Acceptable for indices between 0.5 and 0.7, and Low for indices below 0.5. These quantification and standards set here could be further updated according to the special requirements of target use cases.</p>
</div>
<section id="S4.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS3.SSS1.4.1.1" class="ltx_text">IV-C</span>1 </span>IoT Use Case</h4>

<figure id="S4.F3" class="ltx_figure"><img src="/html/2405.02360/assets/IoT_final.png" id="S4.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="403" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>HEM index of various FL algorithms in IoT use case.</figcaption>
</figure>
<div id="S4.SS3.SSS1.p1" class="ltx_para">
<p id="S4.SS3.SSS1.p1.1" class="ltx_p">In the IoT use case, the HEM index indicates that the FL algorithms’ performance ranges from Good to Low. Specifically, FedAvg_Proto and FedDyn_Proto achieve the highest performance, with a HEM index of 0.76 and 0.70, respectively. FL algorithms based on SCAFFOLD receive the middle level with an average HEM index of around 0.60. In contrast, FedAvg_MAML and FedDyn_MAML receive the lowest HEM index, approximately 0.50. This variation in HEM performance is attributed to the High importance of Accuracy, Computational Efficiency, and Fairness in IoT use cases. Thus, FL algorithms that demonstrate high performance in these components (e.g., FedAvg_Proto) maintain an advantage in the HEM evaluation, whereas those with lower scores in these aspects (e.g., FedAvg_MAML) are at a disadvantage. Figure <a href="#S4.F3" title="Figure 3 ‣ IV-C1 IoT Use Case ‣ IV-C Holistic Evaluation for the Three Use Cases ‣ IV FL Algorithms Evaluation through HEM ‣ Holistic Evaluation Metrics: Use Case Sensitive Evaluation Metrics for Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> illustrates the HEM index of various FL algorithms in IoT use cases.</p>
</div>
<div id="S4.SS3.SSS1.p2" class="ltx_para">
<p id="S4.SS3.SSS1.p2.1" class="ltx_p">Recall the individual competent performance evaluated shown in Table <a href="#S4.T3" title="TABLE III ‣ IV FL Algorithms Evaluation through HEM ‣ Holistic Evaluation Metrics: Use Case Sensitive Evaluation Metrics for Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a>, FedAvg_Proto algorithm does not reach any highest performance on each single perspective. As a result, a user seeking an FL algorithm for IoT use cases through traditional evaluation metrics may overlook the FedAvg_Proto, while it emerges as the most suitable algorithm when considering the IoT requirements. However, our proposed HEM reveals a different insight and shows the benefits of the FedAvg_Proto algorithm in the target scenarios. This comprehensive evaluation underscores the importance of considering the collective strengths of FedAvg_Proto rather than focusing on isolated metrics.</p>
</div>
</section>
<section id="S4.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS3.SSS2.4.1.1" class="ltx_text">IV-C</span>2 </span>Smartphone Use Case</h4>

<figure id="S4.F4" class="ltx_figure"><img src="/html/2405.02360/assets/Smart_final.png" id="S4.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="394" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>HEM index of various FL algorithms in the Smartphone use case.</figcaption>
</figure>
<div id="S4.SS3.SSS2.p1" class="ltx_para">
<p id="S4.SS3.SSS2.p1.1" class="ltx_p">The HEM index shows that the performance of FL algorithms in the Smartphone use case ranges from Acceptable to Excellent. On the one hand, all three PFL algorithms that use the Proto meta-learning framework score in the Excellent Performance, achieving a HEM index of over 0.80. On the other hand, the original algorithms generally receive a low HEM index, with FedAvg at 0.56, FedDyn at 0.55, and SCAFFOLD at 0.64. From an average performance perspective, the SCAFFOLD class achieves the highest mean value at 0.72, followed by FedDyn at 0.69 and FedAvg at 0.63, indicating its advantages in Smartphone use cases. Figure <a href="#S4.F4" title="Figure 4 ‣ IV-C2 Smartphone Use Case ‣ IV-C Holistic Evaluation for the Three Use Cases ‣ IV FL Algorithms Evaluation through HEM ‣ Holistic Evaluation Metrics: Use Case Sensitive Evaluation Metrics for Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> illustrates the HEM index of various FL algorithms in the Smartphone use case.</p>
</div>
<figure id="S4.F5" class="ltx_figure"><img src="/html/2405.02360/assets/Ins_Final.png" id="S4.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="395" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>HEM index of various FL algorithms in Institution use case.</figcaption>
</figure>
<div id="S4.SS3.SSS2.p2" class="ltx_para">
<p id="S4.SS3.SSS2.p2.1" class="ltx_p">Given that Convergence and Computational Efficiency are highly valued in the HEM evaluation for the smartphone use case, an FL algorithm that excels in these areas can compensate for deficiencies in other components. Thus, although FedDyn_Proto may not consistently achieve the highest performance in existing evaluations, it could be identified through the HEM as the most suitable algorithm for Smartphone users.</p>
</div>
</section>
<section id="S4.SS3.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS3.SSS3.4.1.1" class="ltx_text">IV-C</span>3 </span>Institution Use Case</h4>

<figure id="S4.F6" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3"><img src="/html/2405.02360/assets/davg.png" id="S4.F6.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="197" height="132" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_3"><img src="/html/2405.02360/assets/ddyn.png" id="S4.F6.g2" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="197" height="132" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_3"><img src="/html/2405.02360/assets/dsca.png" id="S4.F6.g3" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="197" height="132" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Illustration of the index fluctuation in various evaluation components upon introducing personalization methods to the FedDyn, SCAFFOLD, and FedAvg algorithms.</figcaption>
</figure>
<div id="S4.SS3.SSS3.p1" class="ltx_para">
<p id="S4.SS3.SSS3.p1.1" class="ltx_p">In the institution use case, the algorithms show performance from Good to Acceptable. Specifically, FedAvg scores the highest with a HEM index of 0.79, followed by FedAvg_Proto at 0.76 and FedDyn_Proto at 0.67. In contrast, FedDyn_MAML and SCAFFOLD achieve the lowest performance, which receives a 0.52 HEM index. As the Institution use cases prioritize Client Accuracy and Fairness, the HEM index for FedDyn_MAML is adversely impacted by its lower performance in fairness despite achieving high model accuracy. Additionally, it is observed that most FL algorithms experience a decrease in their HEM index upon integrating MAML personalization, whereas the Proto method tends to maintain or even enhance performance. Figure <a href="#S4.F5" title="Figure 5 ‣ IV-C2 Smartphone Use Case ‣ IV-C Holistic Evaluation for the Three Use Cases ‣ IV FL Algorithms Evaluation through HEM ‣ Holistic Evaluation Metrics: Use Case Sensitive Evaluation Metrics for Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> illustrates the HEM index of various FL algorithms in the simulated institution use case.</p>
</div>
<div id="S4.SS3.SSS3.p2" class="ltx_para">
<p id="S4.SS3.SSS3.p2.1" class="ltx_p">Based on the HEM evaluation results, a user seeking an FL algorithm to support model training and delivery services in institutional use cases might consider selecting FedAvg_Proto and FedDyn_Proto. Both algorithms deliver Good overall performance and satisfactory Fairness, which could continuously encourage clients to participate in the learning task.</p>
</div>
</section>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS4.4.1.1" class="ltx_text">IV-D</span> </span><span id="S4.SS4.5.2" class="ltx_text ltx_font_italic">Discussion</span>
</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.1" class="ltx_p">The previous experimental results demonstrate that personalization methods enhance the Client Accuracy and Computation Efficiency of original FL algorithms by effectively converging on heterogeneous or non-IID data during the training process (see Table <a href="#S4.T3" title="TABLE III ‣ IV FL Algorithms Evaluation through HEM ‣ Holistic Evaluation Metrics: Use Case Sensitive Evaluation Metrics for Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a>). However, it remains unclear whether these improvement carried by personalization methods implicitly brings trade-offs that could negatively affect other components and the overall HEM.</p>
</div>
<div id="S4.SS4.p2" class="ltx_para">
<p id="S4.SS4.p2.1" class="ltx_p">Thus, in this subsection, we seek to answer the following three research questions:</p>
</div>
<div id="S4.SS4.p3" class="ltx_para">
<p id="S4.SS4.p3.1" class="ltx_p"><span id="S4.SS4.p3.1.1" class="ltx_text ltx_font_bold">RQ1:</span> What kind of trade-offs are carried by personalization methods?</p>
</div>
<div id="S4.SS4.p4" class="ltx_para">
<p id="S4.SS4.p4.1" class="ltx_p"><span id="S4.SS4.p4.1.1" class="ltx_text ltx_font_bold">RQ2:</span> Whether the PFL algorithms with high personalization performed better?</p>
</div>
<div id="S4.SS4.p5" class="ltx_para">
<p id="S4.SS4.p5.1" class="ltx_p"><span id="S4.SS4.p5.1.1" class="ltx_text ltx_font_bold">RQ3:</span> Whether the FL algorithms in each simulated use case are benefited from the implementation of personalization methods?</p>
</div>
<div id="S4.SS4.p6" class="ltx_para">
<p id="S4.SS4.p6.1" class="ltx_p">Figure <a href="#S4.F6" title="Figure 6 ‣ IV-C3 Institution Use Case ‣ IV-C Holistic Evaluation for the Three Use Cases ‣ IV FL Algorithms Evaluation through HEM ‣ Holistic Evaluation Metrics: Use Case Sensitive Evaluation Metrics for Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> illustrates the index fluctuation of various evaluation components by introducing personalization methods (MAML, Proto) to the FedDyn, SCAFFOLD, and FedAvg algorithms. One can observe that almost all components experience an increase following the introduction of personalization methods. Specifically, through introducing personalization, the Computational Efficiency achieves the largest improvement, with gains of up to approximately 0.7. Convergence and Accuracy experience slighter improvements, approximately around 0.03 and 0.2, respectively. However, all Fairness indexes witnessed a significant decrease when the FL algorithm was personalized, with reductions of up to 0.64. We attribute this to the fact that PFL can achieve performance improvements for only a subset of clients and shows limited effectiveness for others with disadvantaged data distributions. The unbalance performance improvement across clients enlarges the accuracy difference and subsequently decreases the Fairness. Thus, while personalization methods can enhance the performance of FL algorithms, particularly in terms of Computational Efficiency, they sacrifice Fairness among participants, leading to significant accuracy disparities in non-IID scenarios. When introducing personalization methods, such a trade-off should be considered. A PFL method may be more suitable for use cases where Fairness is of low importance, and Computational Efficiency is highly valued.</p>
</div>
<div id="S4.SS4.p7" class="ltx_para">
<p id="S4.SS4.p7.1" class="ltx_p">On the other hand, the Proto method is observed to impart a higher degree of personalization to the FL algorithm compared to the MAML method. As shown in Figure <a href="#S4.F2" title="Figure 2 ‣ IV-B5 Personalization of PFL Algorithms ‣ IV-B Evaluation Metric Component Indexes ‣ IV FL Algorithms Evaluation through HEM ‣ Holistic Evaluation Metrics: Use Case Sensitive Evaluation Metrics for Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, Proto personalization yields a 0.01, 1.11, and 0.78 higher MPI than MALA for FedAvg, FedDyn, and SCAFFOLD, respectively. The enhanced personalization results in higher performance improvements in Computational Efficiency, which is larger than those achieved through the MAML method by approximately 0.3. Conversely, the Proto method introduces a reduction in Fairness, exacerbating the accuracy disparity among clients by about 0.2, while Accuracy and Convergence keep a similar performance. Hence, although greater personalization can enhance Computational Efficiency performance in non-IID scenarios, the trade-offs, particularly in terms of fairness degradation, are also larger.</p>
</div>
<div id="S4.SS4.p8" class="ltx_para">
<p id="S4.SS4.p8.1" class="ltx_p">From the perspective of use cases, we note that only two algorithms, FedAvg_Proto and FedDyn_Proto, both PFL algorithms, are rated as Good levels within the IoT scenario. Similarly, in both smartphone and institutional scenarios, algorithms achieving High and Good performance ratings are generally PFL, including FedAvg_Proto, FedDyn_Proto, and FedDyn_MAML. This observation indicates that despite the trade-offs associated with personalization methods, the overall HEM performance is enhanced, benefiting the application of FL algorithms across all three scenarios. As a result, PFL algorithms should be prioritized for selection within these simulated use cases.</p>
</div>
<div id="S4.SS4.p9" class="ltx_para">
<p id="S4.SS4.p9.1" class="ltx_p">However, since the generation of HEM is closely tied to the Importance Vector and its corresponding quantification, further discussion is warranted on whether improvements in convergence can offset decreases in fairness, ultimately contributing to a high HEM for a specific application. This consideration should be explored in conjunction with an investigation into the performance requirements of the deployment use case.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">Conclusion and Future work</span>
</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this paper, we outline our proposed HEM index and use three typical use cases to provide a comprehensive evaluation of given FL algorithms in the respective scenario. Specifically, the application scenarios of IoT, Smartphone, and Institution are included as the representative FL use cases. For each scenario, we identify the evaluation metric components and their corresponding importance vectors. The HEM index is generated through a combination of the evaluation metric components and importance vectors. We experimentally assess various FL and PFL algorithms through HEM proposed in different use cases. The experimental results demonstrate that the HEM index can effectively and efficiently evaluate and select the appropriate FL algorithms for diverse scenarios. Currently, we determine the importance of each metric component for each use case based on the findings of literature review and scenario investigation. Moving forward, one future work will be to create a pragmatic benchmarking for the identification of the importance of each metric component for each use case, thereby refining our HEM approach.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
J. Wen, Z. Zhang, Y. Lan, Z. Cui, J. Cai, and W. Zhang, “A survey on federated learning: challenges and applications,” <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">International Journal of Machine Learning and Cybernetics</em>, vol. 14, no. 2, pp. 513–535, 2023.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
D. Gufran and S. Pasricha, “Fedhil: Heterogeneity resilient federated learning for robust indoor localization with mobile devices,” <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">ACM Transactions on Embedded Computing Systems</em>, vol. 22, no. 5s, pp. 1–24, 2023.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
T. Wang, Y. Du, Y. Gong, K.-K. R. Choo, and Y. Guo, “Applications of federated learning in mobile health: Scoping review,” <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">Journal of Medical Internet Research</em>, vol. 25, pp. 1–26, 2023.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
P. Guo, P. Wang, J. Zhou, S. Jiang, and V. M. Patel, “Multi-institutional collaborations for improving deep learning-based magnetic resonance image reconstruction using federated learning,” in <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2021, pp. 2423–2432.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
M. J. Sheller, B. Edwards, G. A. Reina, J. Martin, S. Pati, A. Kotrotsou, M. Milchenko, W. Xu, D. Marcus, R. R. Colen <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Federated learning in medicine: facilitating multi-institutional collaborations without sharing patient data,” <em id="bib.bib5.2.2" class="ltx_emph ltx_font_italic">Scientific reports</em>, vol. 10, no. 1, pp. 1–12, 2020.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
T. Yang, G. Andrew, H. Eichner, H. Sun, W. Li, N. Kong, D. Ramage, and F. Beaufays, “Applied federated learning: Improving google keyboard query suggestions,” <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1812.02903</em>, 2018.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
K. Hao, “How apple personalizes siri without hoovering up your data,” <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">Technology Review</em>, 2020.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
N. Rieke, J. Hancox, W. Li, F. Milletari, H. R. Roth, S. Albarqouni, S. Bakas, M. N. Galtier, B. A. Landman, K. Maier-Hein <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “The future of digital health with federated learning,” <em id="bib.bib8.2.2" class="ltx_emph ltx_font_italic">NPJ digital medicine</em>, vol. 3, no. 1, pp. 119–206, 2020.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
J. Bian and J. Xu, “Client clustering for energy-efficient clustered federated learning in wireless networks,” in <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">Adjunct Proceedings of the ACM International Joint Conference on Pervasive and Ubiquitous Computing (UbiComp) &amp; the ACM International Symposium on Wearable Computing (ISWC)</em>, 2023, pp. 718–723.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
D. Chai, L. Wang, L. Yang, J. Zhang, K. Chen, and Q. Yang, “Fedeval: A holistic evaluation framework for federated learning,” <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2011.09655</em>, 2020.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
P. Kairouz, H. B. McMahan, B. Avent, A. Bellet, M. Bennis, A. N. Bhagoji, K. Bonawitz, Z. Charles, G. Cormode, R. Cummings <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Advances and open problems in federated learning,” <em id="bib.bib11.2.2" class="ltx_emph ltx_font_italic">Foundations and Trends® in Machine Learning</em>, vol. 14, no. 1–2, pp. 1–210, 2021.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
D. A. E. Acar, Y. Zhao, R. Matas, M. Mattina, P. Whatmough, and V. Saligrama, “Federated learning based on dynamic regularization,” in <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations (ICLR)</em>, 2021, pp. 1–36.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
S. P. Karimireddy, S. Kale, M. Mohri, S. Reddi, S. Stich, and A. T. Suresh, “Scaffold: Stochastic controlled averaging for federated learning,” in <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning (ICML)</em>, 2020, pp. 5132–5143.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
A. Fallah, A. Mokhtari, and A. Ozdaglar, “Personalized federated learning: A meta-learning approach,” <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2002.07948</em>, 2020.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
L. Li, Y. Fan, M. Tse, and K.-Y. Lin, “A review of applications in federated learning,” <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">Computers &amp; Industrial Engineering</em>, vol. 149, pp. 1–15, 2020.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
J. Mills, J. Hu, and G. Min, “Multi-task federated learning for personalised deep neural networks in edge computing,” <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Parallel and Distributed Systems</em>, vol. 33, no. 3, pp. 630–641, 2021.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
J. Ibrahim, Y. Li, H. Chen, and D. Yuan, “Holistic evaluation metrics for federated learning,” in <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">International Conference on Computer Supported Cooperative Work in Design (CSCWD)</em>, 2024, pp. 1–6.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
N. Tabassum, M. Ahmed, N. J. Shorna, U. R. Sowad, M. Mejbah, and H. Haque, “Depression detection through smartphone sensing: A federated learning approach.” <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">International Journal of Interactive Mobile Technologies</em>, vol. 17, no. 1, pp. 1–17, 2023.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
I. Varlamis, C. Sardianos, C. Chronis, G. Dimitrakopoulos, Y. Himeur, A. Alsalemi, F. Bensaali, and A. Amira, “Using big data and federated learning for generating energy efficiency recommendations,” <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">International Journal of Data Science and Analytics</em>, vol. 16, no. 3, pp. 353–369, 2023.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
J. Ogier du Terrail, A. Leopold, C. Joly, C. Béguier, M. Andreux, C. Maussion, B. Schmauch, E. W. Tramel, E. Bendjebbar, M. Zaslavskiy <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Federated learning for predicting histological response to neoadjuvant chemotherapy in triple-negative breast cancer,” <em id="bib.bib20.2.2" class="ltx_emph ltx_font_italic">Nature medicine</em>, vol. 29, no. 1, pp. 135–146, 2023.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
S. K. Lo, Y. Liu, Q. Lu, C. Wang, X. Xu, H.-Y. Paik, and L. Zhu, “Toward trustworthy ai: Blockchain-based architecture design for accountability and fairness of federated learning systems,” <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">IEEE Internet of Things Journal</em>, vol. 10, no. 4, pp. 3276–3284, 2022.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Y. Wang, I. L. Bennani, X. Liu, M. Sun, and Y. Zhou, “Electricity consumer characteristics identification: A federated learning approach,” <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Smart Grid</em>, vol. 12, no. 4, pp. 3637–3647, 2021.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
T. Zhang, L. Gao, C. He, M. Zhang, B. Krishnamachari, and A. S. Avestimehr, “Federated learning for the internet of things: Applications, challenges, and opportunities,” <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">IEEE Internet of Things Magazine</em>, vol. 5, no. 1, pp. 24–29, 2022.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
D. Wu, R. Ullah, P. Harvey, P. Kilpatrick, I. Spence, and B. Varghese, “Fedadapt: Adaptive offloading for iot devices in federated learning,” <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">IEEE Internet of Things Journal</em>, vol. 9, no. 21, pp. 20 889–20 901, 2022.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
S. Ramaswamy, R. Mathews, K. Rao, and F. Beaufays, “Federated learning for emoji prediction in a mobile keyboard,” <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1906.04329</em>, 2019.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
I. Dayan, H. R. Roth, A. Zhong, A. Harouni, A. Gentili, A. Z. Abidin, A. Liu, A. B. Costa, B. J. Wood, C.-S. Tsai <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Federated learning for predicting clinical outcomes in patients with covid-19,” <em id="bib.bib26.2.2" class="ltx_emph ltx_font_italic">Nature medicine</em>, vol. 27, no. 10, pp. 1735–1743, 2021.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas, “Communication-efficient learning of deep networks from decentralized data,” in <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">International Conference on Artificial Intelligence and Statistics (AISTATS)</em>, 2017, pp. 1273–1282.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
J. Konečnỳ, H. B. McMahan, F. X. Yu, P. Richtárik, A. T. Suresh, and D. Bacon, “Federated learning: Strategies for improving communication efficiency,” <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1610.05492</em>, 2016.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
D. A. E. Acar, Y. Zhao, R. Zhu, R. Matas, M. Mattina, P. Whatmough, and V. Saligrama, “Debiasing model updates for improving personalized federated training,” in <em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning (ICML)</em>, 2021, pp. 21–31.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
M. Shayan, C. Fung, C. J. Yoon, and I. Beschastnikh, “Biscotti: A blockchain system for private and secure federated learning,” <em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Parallel and Distributed Systems</em>, vol. 32, no. 7, pp. 1513–1525, 2020.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
A. Imteaj, U. Thakker, S. Wang, J. Li, and M. H. Amini, “A survey on federated learning for resource-constrained iot devices,” <em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">IEEE Internet of Things Journal</em>, vol. 9, no. 1, pp. 1–24, 2021.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
M. Ye, X. Fang, B. Du, P. C. Yuen, and D. Tao, “Heterogeneous federated learning: State-of-the-art and research challenges,” <em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">ACM Computing Surveys</em>, vol. 56, no. 3, pp. 1–44, 2023.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
S. Pandya, G. Srivastava, R. Jhaveri, M. R. Babu, S. Bhattacharya, P. K. R. Maddikunta, S. Mastorakis, M. J. Piran, and T. R. Gadekallu, “Federated learning for smart cities: A comprehensive survey,” <em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">Sustainable Energy Technologies and Assessments</em>, vol. 55, pp. 1–13, 2023.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
A. Hard, K. Rao, R. Mathews, S. Ramaswamy, F. Beaufays, S. Augenstein, H. Eichner, C. Kiddon, and D. Ramage, “Federated learning for mobile keyboard prediction,” <em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1811.03604</em>, 2018.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
C. Yang, Q. Wang, M. Xu, Z. Chen, K. Bian, Y. Liu, and X. Liu, “Characterizing impacts of heterogeneity in federated learning upon large-scale smartphone data,” in <em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Web Conference (WWW)</em>, 2021, pp. 935–946.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
T. Li, A. K. Sahu, A. Talwalkar, and V. Smith, “Federated learning: Challenges, methods, and future directions,” <em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">IEEE signal processing magazine</em>, vol. 37, no. 3, pp. 50–60, 2020.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
M. Joshi, A. Pal, and M. Sankarasubbu, “Federated learning for healthcare domain-pipeline, applications and challenges,” <em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">ACM Transactions on Computing for Healthcare</em>, vol. 3, no. 4, pp. 1–36, 2022.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
Y. Chen, X. Qin, J. Wang, C. Yu, and W. Gao, “Fedhealth: A federated transfer learning framework for wearable healthcare,” <em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">IEEE Intelligent Systems</em>, vol. 35, no. 4, pp. 83–93, 2020.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
Y. Li, X. Tao, X. Zhang, J. Liu, and J. Xu, “Privacy-preserved federated learning for autonomous driving,” <em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Intelligent Transportation Systems</em>, vol. 23, no. 7, pp. 8423–8434, 2021.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
D. C. Nguyen, Q.-V. Pham, P. N. Pathirana, M. Ding, A. Seneviratne, Z. Lin, O. Dobre, and W.-J. Hwang, “Federated learning for smart healthcare: A survey,” <em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">ACM Computing Surveys</em>, vol. 55, no. 3, pp. 1–37, 2022.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
X. Wang, W. Liu, H. Lin, J. Hu, K. Kaur, and M. S. Hossain, “Ai-empowered trajectory anomaly detection for intelligent transportation systems: A hierarchical federated learning approach,” <em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Intelligent Transportation Systems</em>, vol. 24, no. 4, pp. 4631–4640, 2022.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
W. Zhang, D. Yang, W. Wu, H. Peng, N. Zhang, H. Zhang, and X. Shen, “Optimizing federated learning in distributed industrial iot: A multi-agent approach,” <em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">IEEE Journal on Selected Areas in Communications</em>, vol. 39, no. 12, pp. 3688–3703, 2021.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
L. U. Khan, W. Saad, Z. Han, E. Hossain, and C. S. Hong, “Federated learning for internet of things: Recent advances, taxonomy, and open challenges,” <em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">IEEE Communications Surveys &amp; Tutorials</em>, vol. 23, no. 3, pp. 1759–1799, 2021.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
J. Mills, J. Hu, and G. Min, “Communication-efficient federated learning for wireless edge intelligence in iot,” <em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">IEEE Internet of Things Journal</em>, vol. 7, no. 7, pp. 5986–5994, 2019.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
D. Khurana, A. Koli, K. Khatter, and S. Singh, “Natural language processing: State of the art, current trends and challenges,” <em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">Multimedia tools and applications</em>, vol. 82, no. 3, pp. 3713–3744, 2023.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
B. Min, H. Ross, E. Sulem, A. P. B. Veyseh, T. H. Nguyen, O. Sainz, E. Agirre, I. Heintz, and D. Roth, “Recent advances in natural language processing via large pre-trained language models: A survey,” <em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">ACM Computing Surveys</em>, vol. 56, no. 2, pp. 1–40, 2023.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2405.02359" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2405.02360" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2405.02360">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2405.02360" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2405.02361" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Wed Jun  5 17:37:33 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
