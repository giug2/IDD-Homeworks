<article class="ltx_document ltx_authors_1line">
 <h1 class="ltx_title ltx_title_document">
  Urban Generative Intelligence (UGI): A Foundational Platform for Agents in Embodied City Environment
 </h1>
 <div class="ltx_authors">
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Fengli Xu  Jun Zhang
    <span class="ltx_note ltx_role_footnotemark" id="footnotex1">
     <sup class="ltx_note_mark">
      1
     </sup>
     <span class="ltx_note_outer">
      <span class="ltx_note_content">
       <sup class="ltx_note_mark">
        1
       </sup>
       <span class="ltx_note_type">
        footnotemark:
       </span>
       <span class="ltx_tag ltx_tag_note">
        1
       </span>
      </span>
     </span>
    </span>
    Chen Gao
    <span class="ltx_note ltx_role_footnotemark" id="footnotex2">
     <sup class="ltx_note_mark">
      1
     </sup>
     <span class="ltx_note_outer">
      <span class="ltx_note_content">
       <sup class="ltx_note_mark">
        1
       </sup>
       <span class="ltx_note_type">
        footnotemark:
       </span>
       <span class="ltx_tag ltx_tag_note">
        1
       </span>
      </span>
     </span>
    </span>
    Jie Feng  Yong Li
    <br class="ltx_break"/>
    Tsinghua University, Beijing, China
    <br class="ltx_break"/>
    <span class="ltx_text ltx_font_typewriter" id="id1.1.id1">
     {fenglixu, chgao96, liyong07}@tsinghua.edu.cn
    </span>
   </span>
   <span class="ltx_author_notes">
    The first three authors contribute to this work equally.
   </span>
  </span>
 </div>
 <div class="ltx_abstract">
  <h6 class="ltx_title ltx_title_abstract">
   Abstract
  </h6>
  <p class="ltx_p" id="id2.id1">
   Urban environments, characterized by their complex, multi-layered networks encompassing physical, social, economic, and environmental dimensions, face significant challenges in the face of rapid urbanization. These challenges, ranging from traffic congestion and pollution to social inequality, call for advanced technological interventions. Recent developments in big data, artificial intelligence, urban computing, and digital twins have laid the groundwork for sophisticated city modeling and simulation. However, a gap persists between these technological capabilities and their practical implementation in addressing urban challenges in an systemic-intelligent way. This paper proposes Urban Generative Intelligence (UGI), a novel foundational platform integrating Large Language Models (LLMs) into urban systems to foster a new paradigm of urban intelligence. UGI leverages CityGPT, a foundation model trained on city-specific multi-source data, to create embodied agents for various urban tasks. These agents, operating within a textual urban environment emulated by city simulator and urban knowledge graph, interact through a natural language interface, offering an open platform for diverse intelligent and embodied agent development. This platform not only addresses specific urban issues but also simulates complex urban systems, providing a multidisciplinary approach to understand and manage urban complexity. This work signifies a transformative step in city science and urban intelligence, harnessing the power of LLMs to unravel and address the intricate dynamics of urban systems.
The code repository with demonstrations will soon be released here
   <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">
    https://github.com/tsinghua-fib-lab/UGI
   </span>
   .
  </p>
 </div>
 <section class="ltx_section" id="S1">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    1
   </span>
   Introduction
  </h2>
  <div class="ltx_para ltx_noindent" id="S1.p1">
   <p class="ltx_p" id="S1.p1.1">
    Urban are complex systems with dynamic and multi-layered networks encompassing physical elements (buildings, roads, infrastructure), social structures (population distribution, organizations, culture), economic activities (industry, services, commerce), and environmental factors (natural resources, ecosystems, climate change)
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib10" title="">
      10
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib15" title="">
      15
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib17" title="">
      17
     </a>
     ]
    </cite>
    . This intricate interplay creates uncertainty and dynamism, reflecting the complex interactions between human activities and the urban environment
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib17" title="">
      17
     </a>
     ]
    </cite>
    . Each individual, community, and organization within these systems is interconnected, influencing the city’s overall characters and functionality
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib99" title="">
      99
     </a>
     ]
    </cite>
    . The primary challenge in urban complex systems is balancing economic growth, social welfare, and environmental sustainability amid rapid urbanization, and it faces critical challenges including traffic congestion, environmental pollution, resource scarcity, and infrastructure strain, all exacerbated by rapid urbanization
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib184" title="">
      184
     </a>
     ]
    </cite>
    . Besides, social inequality and housing issues further impact residents’ quality of life. The growing threats of climate change, such as extreme weather and rising sea levels, add to these challenges, highlighting the urgent need for solutions. Addressing these prominent urban issues is essential to ensure sustainable, equitable urban development and maintain the vitality of cities in a rapidly evolving global context
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib2" title="">
      2
     </a>
     ]
    </cite>
    .
   </p>
  </div>
  <div class="ltx_para ltx_noindent" id="S1.p2">
   <p class="ltx_p" id="S1.p2.1">
    In order to address above problems, the recent technological evolution began with big data, which provided rich and variety urban information
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib178" title="">
      178
     </a>
     ]
    </cite>
    . The complexity of this data necessitated the development of artificial intelligence (AI) for effective description, prediction and management
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib186" title="">
      186
     </a>
     ]
    </cite>
    . This synergy led to urban computing
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib184" title="">
      184
     </a>
     ]
    </cite>
    , which applies AI to big data for urban problem-solving. Building on this, digital twins
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib11" title="">
      11
     </a>
     ]
    </cite>
    and city simulations
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib176" title="">
      176
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib175" title="">
      175
     </a>
     ]
    </cite>
    emerged, creating virtual models of cities using real-time data and AI analysis. These technologies represent a progression from data collection (big data), to data analysis (AI), to application (urban computing), and finally to advanced simulation and modeling (digital twins and city simulations). Each stage builds upon the last, offering increasingly sophisticated tools for tackling urban complexities. However, despite these advancements, the ability of these technologies to systematically address the complexity of urban issues lies in the gap between technological capabilities and practical implementation. This shortfall implies that while these technologies are invaluable tools, they cannot yet comprehend and address the intricate and systemic challenges cities face, necessitating further advancements in AI and computational models to achieve more intelligent system-wide urban solutions.
   </p>
  </div>
  <div class="ltx_para ltx_noindent" id="S1.p3">
   <p class="ltx_p" id="S1.p3.1">
    The advent of artificial general intelligence, particularly large language models (LLMs), as a form of human-like intelligence presents a transformative opportunity in addressing urban challenges
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib48" title="">
      48
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib151" title="">
      151
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib25" title="">
      25
     </a>
     ]
    </cite>
    . LLMs demonstrate emergent intelligence capabilities, mimicking human cognitive process to analyze and reason vast datasets. The human-like intelligence of LLMs can significantly contribute to the intelligence of urban systems by providing deep and context-aware insights. They can identify patterns, sentiments, and trends within urban discourse, offering a more nuanced understanding of the complex social and economic dynamics at play in urban environments, which further supports smart decision-making in urban planning and policy formulation. Thus, the integration of LLMs into urban systems holds great promise for finding comprehensive solutions to the multifaceted challenges in cities, which will push the urban technology to the next stage of urban intelligence.
   </p>
  </div>
  <div class="ltx_para ltx_noindent" id="S1.p4">
   <p class="ltx_p" id="S1.p4.1">
    In this paper, we propose Urban Generative Intelligence (UGI), a foundational platform that fosters the emergence, evolution, and application of generative intelligence in urban space and fuels the transition to smart future city.
The UGI platform is built on top of an open digital infrastructure that consists of the UrbanKG knowledge graph
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib95" title="">
      95
     </a>
     ]
    </cite>
    and a city simulator engine
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib176" title="">
      176
     </a>
     ]
    </cite>
    .
This infrastructure is capable of simulating realistic urban interactions based on multi-source urban data and providing embodied feedback to intelligent agents, setting it apart from existing sandboxes
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib112" title="">
      112
     </a>
     ]
    </cite>
    or virtual environments
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib41" title="">
      41
     </a>
     ]
    </cite>
    .
We design a standard language interface to expose the access to this digital infrastructure, facilitating the easy plugin of language models and the development of generative and embodied agents.
To create a foundation model for urban problems, we pre-train a LLM called CityGPT on general text corpus and high-quality city-specific data, including general text corpus, including domain-specific urban knowledge, task-solving process data and so on. Using CityGPT as a generative intelligence core, we propose a general framework of creating embodied agents for various urban tasks, such as planning transportation system, assisting policy-making, and simulating urban life and socioeconomic interactions
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib50" title="">
      50
     </a>
     ]
    </cite>
    .
Moreover, this general framework can be easily adapted to build customized agents, fostering the emergence of diverse intelligent agents supporting various aspects of urban intelligence.
Through the realistic embodied feedback provided by digital infrastructure and the interactions with other agents, the LLM-empowered agents are able to learn from the environment, develop their own understanding, and further evolve their intelligence to deal with complicate urban tasks. Leveraging the CityGPT and various embodied agents, the UGI platform can help solve urban issues, support a wide range of urban applications, and explore new urban forms. These components collectively form the Foundation Platform of UGI, facilitating the emergence and advancement of generative intelligence in urban space.
   </p>
  </div>
  <div class="ltx_para ltx_noindent" id="S1.p5">
   <p class="ltx_p" id="S1.p5.1">
    The contributions of this paper can be summarized as the following aspects.
   </p>
  </div>
  <div class="ltx_para ltx_noindent" id="S1.p6">
   <ul class="ltx_itemize" id="S1.I1">
    <li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para ltx_noindent" id="S1.I1.i1.p1">
      <p class="ltx_p" id="S1.I1.i1.p1.1">
       We are the first to propose an open digital infrastructure for embodied urban environment simulation, which provides realistic feedback of urban experience via a natural language interface. It leverages UrbanKG knowledge graph and city simulator to provide textual feedback that can enable generative intelligence in urban space.
      </p>
     </div>
    </li>
    <li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para ltx_noindent" id="S1.I1.i2.p1">
      <p class="ltx_p" id="S1.I1.i2.p1.1">
       We design and implement a foundation model for city problems, called
       <em class="ltx_emph ltx_font_italic" id="S1.I1.i2.p1.1.1">
        CityGPT
       </em>
       . It is continuously pre-trained from general foundation model to incorporate urban knowledge extracted from text corpus, and then supervised fine-tuned to induce urban intelligence ability with domain-specific data.
      </p>
     </div>
    </li>
    <li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para ltx_noindent" id="S1.I1.i3.p1">
      <p class="ltx_p" id="S1.I1.i3.p1.1">
       We propose a general framework for generative city agents, which releases the generative intelligence of CityGPT in various urban tasks. We also propose several successful design cases for: a) simulation agents of physical mobility, economy activity, and social interaction in city; b) decision making agents that can serve as personal assistance of location recommendation and schedule planning.
      </p>
     </div>
    </li>
    <li class="ltx_item" id="S1.I1.i4" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para ltx_noindent" id="S1.I1.i4.p1">
      <p class="ltx_p" id="S1.I1.i4.p1.1">
       We introduce an evaluation framework to validate the performance of foundation model and generative city agents, quantifying urban generative intelligence as the levels of mastering knowledge, simple reasoning, and planing and decision making. It provides a standard and reference for the development of urban intelligence.
      </p>
     </div>
    </li>
   </ul>
  </div>
 </section>
 <section class="ltx_section" id="S2">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    2
   </span>
   Related Work
  </h2>
  <section class="ltx_subsection" id="S2.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     2.1
    </span>
    Complex Urban System
   </h3>
   <div class="ltx_para ltx_noindent" id="S2.SS1.p1">
    <p class="ltx_p" id="S2.SS1.p1.1">
     Cities have long been viewed as a complex system of interconnected humans, things and space
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib10" title="">
       10
      </a>
      ]
     </cite>
     .
Extensive research attentions are devoted to review the universal patterns of various statistics in complex urban system, such as city size and morphology shape
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib9" title="">
       9
      </a>
      ]
     </cite>
     . Specifically, previous works find cities exhibit typical fractal morphology
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib12" title="">
       12
      </a>
      ]
     </cite>
     , contradicting the common practice in urban planing, but is a symbolic feature of complex system. Besides, a large body of literature is devoted to reveal the scaling laws in urban space
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib18" title="">
       18
      </a>
      ]
     </cite>
     . They find universal patterns of super-linear growth of economy, innovation and crimes, and sub-linear growth of infrastructure investment as city size increases. Previous works build theoretical framework to explain these scaling laws from the interaction mechanisms of urban agents
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib16" title="">
       16
      </a>
      ]
     </cite>
     , which root in the increased interaction frequency in the compact urban space of large cities
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib128" title="">
       128
      </a>
      ]
     </cite>
     .
In recent years, increasing research attention is drawn to the complex challenges faced by modern cities, ranging from climate change to economic inequality, especially as the detailed data of social fabric is increasingly available
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib164" title="">
       164
      </a>
      ]
     </cite>
     . Researchers are dedicated to understanding the complex and concerning phenomena of experienced segregation
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib108" title="">
       108
      </a>
      ]
     </cite>
     , widening socioeconomic gaps
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib22" title="">
       22
      </a>
      ]
     </cite>
     , and prevalence of slums
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib23" title="">
       23
      </a>
      ]
     </cite>
     .
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S2.SS1.p2">
    <p class="ltx_p" id="S2.SS1.p2.1">
     Motivated by these empirical studies, extensive previous works aim to design agent-based model to explain complex urban system from a bottom up perspective. For example, researchers propose to use diffusion limited aggregation model to reproduce fractal urban morphology as the process of physical particles
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib13" title="">
       13
      </a>
      ]
     </cite>
     . A later study uses correlated percolation model on spatial lattice to explain urban morphology
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib101" title="">
       101
      </a>
      ]
     </cite>
     . Recent study finds the scaling laws of urban growth and fractal urban morphology can naturally emerge from agent-based model of human mobility
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib156" title="">
       156
      </a>
      ]
     </cite>
     . In terms of complex urban challenges, agent-based model has been leveraged to reproduce and explain the ubiquitous segregation in urban space
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib127" title="">
       127
      </a>
      ]
     </cite>
     .
Researchers have also developed bottom up model to explain the emergence of varying levels of socioeconomic inequality as the provision of universal basic urban service change
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib22" title="">
       22
      </a>
      ]
     </cite>
     .
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S2.SS1.p3">
    <p class="ltx_p" id="S2.SS1.p3.1">
     However, previous studies mainly use agents guided by simple rules. The recent advance of large language models provides unique opportunity to design generative agents with much more sophisticated intelligence. Such agents have been proved feasible in simulating virtue village
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib112" title="">
       112
      </a>
      ]
     </cite>
     and company
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib66" title="">
       66
      </a>
      ]
     </cite>
     .
By leveraging the human like intelligence and bias encoded in large language model, these generative agents have the potential to explain more complex social phenomena. For example, recent studies show large language model-driven agents exhibit similar content bias in transmission chain
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib1" title="">
       1
      </a>
      ]
     </cite>
     , and can reproduce the typical social processes like
     <em class="ltx_emph ltx_font_italic" id="S2.SS1.p3.1.1">
      wisdom of crowd
     </em>
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib3" title="">
       3
      </a>
      ]
     </cite>
     and
     <em class="ltx_emph ltx_font_italic" id="S2.SS1.p3.1.2">
      social conformity
     </em>
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib190" title="">
       190
      </a>
      ]
     </cite>
     . However, these agents are all simulated in simple and virtual environment. It is still unclear if they are sophisticated enough to interact with complex urban environment. Hence, it is an important research direction to expose language model-driven agents to the rich information collected from urban systems or generated by realistic simulators.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S2.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     2.2
    </span>
    Urban Computing and Intelligence
   </h3>
   <div class="ltx_para ltx_noindent" id="S2.SS2.p1">
    <p class="ltx_p" id="S2.SS2.p1.1">
     As a core concept of urban intelligence, urban computing
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib184" title="">
       184
      </a>
      ]
     </cite>
     is to solve the urban issues like traffic congestion, energy consumption, and air pollution with the help of computer science algorithms. In the early years, the research focused on the spatial-temporal data analytics and management
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib90" title="">
       90
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib185" title="">
       185
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib189" title="">
       189
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib188" title="">
       188
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib167" title="">
       167
      </a>
      ]
     </cite>
     and its application on urban planing
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib187" title="">
       187
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib166" title="">
       166
      </a>
      ]
     </cite>
     , transportation
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib167" title="">
       167
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib97" title="">
       97
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib147" title="">
       147
      </a>
      ]
     </cite>
     and environment
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib118" title="">
       118
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib37" title="">
       37
      </a>
      ]
     </cite>
     . With careful designed data processing and fusion technics in different fields, these works achieved pretty good results. In the recent five years, with the application of deep learning methods, urban computing achieved significant process on various prediction problems in the urban space, e.g., traffic prediction
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib142" title="">
       142
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib61" title="">
       61
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib86" title="">
       86
      </a>
      ]
     </cite>
     and mobility prediction
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib177" title="">
       177
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib46" title="">
       46
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib162" title="">
       162
      </a>
      ]
     </cite>
     which are widely used in transportation, epidemic modeling and environment. STResNet
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib177" title="">
       177
      </a>
      ]
     </cite>
     first introduces the convolution neural network into the crowd flow prediction problem to better model the spatial correlation between regions. DeepMove
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib46" title="">
       46
      </a>
      ]
     </cite>
     proposes to utilize the power of recurrent neural network and attention mechanism to capture the periodic pattern of individual mobility. ASTGCN
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib61" title="">
       61
      </a>
      ]
     </cite>
     applies graph neural network to the traffic network to capture the spatial-temporal correlations between road segments.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S2.SS2.p2">
    <p class="ltx_p" id="S2.SS2.p2.1">
     While these data analytics and prediction methods of urban computing helped us better understand the urban space from different aspects, they are limited for tackling many real-life issues which require counterfactual inference and decision making ability. Thus, recent works further extend the concept of urban intelligence into the new fields like behavior simulation
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib47" title="">
       47
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib168" title="">
       168
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib170" title="">
       170
      </a>
      ]
     </cite>
     and decision making
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib150" title="">
       150
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib149" title="">
       149
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib186" title="">
       186
      </a>
      ]
     </cite>
     . MoveSim
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib47" title="">
       47
      </a>
      ]
     </cite>
     simulates the human movement behaviors and is applied in the epidemic modeling. Further, SAND
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib170" title="">
       170
      </a>
      ]
     </cite>
     develops a knowledge-driven framework to simulate the human activities with Maslow’s need. Intellilight
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib150" title="">
       150
      </a>
      ]
     </cite>
     first utilizes deep reinforcement learning to enable the intelligent traffic light control. Zheng et. al.
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib186" title="">
       186
      </a>
      ]
     </cite>
     propose an artificial intelligence urban-planning model to generate spatial plans for urban communities with the help of graph neural network and deep reinforcement learning.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S2.SS2.p3">
    <p class="ltx_p" id="S2.SS2.p3.1">
     However, despite the above advancements, these methods usually simplify the assumptions of specific real-life problems and fail to solve the complex urban system issues in practice. Recently, the rapid development of LLMs with incredible human-like cognitive abilities provide us new opportunities to solve these issues. The integration of LLMs into the urban intelligence will enable the more real-world applicable methods and frameworks for pattern discovery, dynamics prediction and decision making in the urban space from a systematic view.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S2.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     2.3
    </span>
    Digital Twin City
   </h3>
   <div class="ltx_para ltx_noindent" id="S2.SS3.p1">
    <p class="ltx_p" id="S2.SS3.p1.1">
     Digital Twin City (DTC) refers to the emulation of a city in a digital environment, enabling real-time sensing, analysis, and optimization of urban systems through the use of data-driven models
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib191" title="">
       191
      </a>
      ]
     </cite>
     . DTC stands as a significant trend in smart city research, finding applications in urban planning, traffic management, environmental protection and disaster response. Recent years have witnessed substantial progress in various information technologies, significantly accelerating the development pace of DTC. On one hand, advancements in sensor devices have facilitated the collection of vast amounts of data from multiple sources, including aerospace satellites
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib161" title="">
       161
      </a>
      ]
     </cite>
     , aircraft and drones
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib106" title="">
       106
      </a>
      ]
     </cite>
     , smartphones and mobile terminals
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib28" title="">
       28
      </a>
      ]
     </cite>
     , smart wearable devices
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib126" title="">
       126
      </a>
      ]
     </cite>
     , industrial and household monitoring equipment
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib76" title="">
       76
      </a>
      ]
     </cite>
     , and wireless sensing devices
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib119" title="">
       119
      </a>
      ]
     </cite>
     . A recent focus has been on crowd-sensing methods that leverage distributed smart devices within a crowd, exhibiting distinctive characteristics
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib30" title="">
       30
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib60" title="">
       60
      </a>
      ]
     </cite>
     , focusing on integrating and analyzing digital footprints left by large-scale crowds to establish reliable and semantic-rich representations of group behavior across spatial domains. On the other hand, the analysis and optimization of urban data heavily rely on machine learning algorithms. The complex spatio-temporal data of DTC present challenges for forecasting and decision-making, and the advent of AI
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib53" title="">
       53
      </a>
      ]
     </cite>
     has significantly improved data processing efficiency. Advancements like differentiable decision trees
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib131" title="">
       131
      </a>
      ]
     </cite>
     or knowledge graphs
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib19" title="">
       19
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib165" title="">
       165
      </a>
      ]
     </cite>
     can yield more informed and contextually sound outcomes through utilizing inherent comprehension of domain intricacies. Deep reinforcement learning provides a direct path to model spatio-temporal data through trial-and-error learning with agents
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib169" title="">
       169
      </a>
      ]
     </cite>
     for urban decision-making tasks including traffic signal
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib102" title="">
       102
      </a>
      ]
     </cite>
     or navigation
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib92" title="">
       92
      </a>
      ]
     </cite>
     .
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S2.SS3.p2">
    <p class="ltx_p" id="S2.SS3.p2.1">
     It is important to acknowledge that the digital twin city technology to solve urban problems still faces several challenges and problems. Firstly, there is a strong need to enhance the capability to process the multi-source urban data to improve credibility and realism. Secondly, the processing and computation of large-scale data pose challenges for real-time updates and evolution, and how to process complex instructions and provide human-friendly outputs, making DTC more accessible to policymakers and urban planners, is crucial for scenario testing and decision-making processes. Our proposed LLM-empowered fundamental city platform aims to solve these problems to upgrades DTC into the practice of urban problem solving.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S2.SS4">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     2.4
    </span>
    Large Language Models and Agents
   </h3>
   <div class="ltx_para ltx_noindent" id="S2.SS4.p1">
    <p class="ltx_p" id="S2.SS4.p1.1">
     Large language models
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib182" title="">
       182
      </a>
      ]
     </cite>
     such as ChatGPT
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib110" title="">
       110
      </a>
      ]
     </cite>
     , LLaMA
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib139" title="">
       139
      </a>
      ]
     </cite>
     , Alphca
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib136" title="">
       136
      </a>
      ]
     </cite>
     , and GLM
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib172" title="">
       172
      </a>
      ]
     </cite>
     , are the recent advances of artificial intelligence, which learns from the large corpus, with emergent abilities in understanding and generating language texts.
Since language is the most basic tool for humans interacting with the world
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib62" title="">
       62
      </a>
      ]
     </cite>
     , the human-like language ability endows large language models with high-level capacity, including reasoning and decision-making. Therefore, large language models are considered a promising approach for artificial general intelligence
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib26" title="">
       26
      </a>
      ]
     </cite>
     .
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S2.SS4.p2">
    <p class="ltx_p" id="S2.SS4.p2.1">
     To achieve urban generative intelligence, it is required to endow the existing large language with essential abilities for urban scenarios.
It is worth mentioning that there are some recent attempts to build city-related large language models.
Deng
     <span class="ltx_text ltx_font_italic" id="S2.SS4.p2.1.1">
      et al.
     </span>
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib36" title="">
       36
      </a>
      ]
     </cite>
     proposed to fine-tune Llama-7B with Geoscience Academic Knowledge Graph and relevant research papers in the geoscience field. The fine-tuned model obtained the ability to understand these professional concepts, and support the basic QA tasks.
Similar solutions with fine-tuned large language models with geo-related corpus include GeoLM
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib91" title="">
       91
      </a>
      ]
     </cite>
     and GeoLLM
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib103" title="">
       103
      </a>
      ]
     </cite>
     .
Zhang
     <span class="ltx_text ltx_font_italic" id="S2.SS4.p2.1.2">
      et al.
     </span>
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib179" title="">
       179
      </a>
      ]
     </cite>
     utilize the large language model to help process the user query in traffic-related tools.
GeoGPT
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib181" title="">
       181
      </a>
      ]
     </cite>
     took advantage of the ability in tool usage, considering large language model a bridge in connecting the practitioners with GIS software.
Despite these efforts, they are still limiting in only understanding some city-related concepts, without fully considering what abilities a real human has in the urban scenarios,
     <span class="ltx_text ltx_font_italic" id="S2.SS4.p2.1.3">
      i.e.
     </span>
     , urban generative intelligence, limiting these works’ application.
In this paper, we pay attention to the construct the foundational model, simulation environment, and embodied agents for the urban context.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S2.SS4.p3">
    <p class="ltx_p" id="S2.SS4.p3.1">
     Despite the astonishing performance in various tasks of natural language processing, the large language models can also be used as an agent
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib145" title="">
       145
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib154" title="">
       154
      </a>
      ]
     </cite>
     , which can act and behave like a real human, serving as a virtual agent for personalized purposes.
That is, the agent can be a digital twin in various scenarios, such as representing a real human to interact with other humans in social networks in Metaverse applications
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib84" title="">
       84
      </a>
      ]
     </cite>
     .
One of the most critical challenges is to extend the language ability to more dimensions of models, from environment perception and action execution.
On the one hand, the environment can be represented as textual descriptions
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib112" title="">
       112
      </a>
      ]
     </cite>
     , which can be naturally perceived by the large language models; on the other hand, recent advances build the multi-modal ability by the alignment among different modals
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib67" title="">
       67
      </a>
      ]
     </cite>
     , including textual, visual, etc.
As for action execution, it is widely acknowledged that the agent can leverage various tools well, which extend the action space to language into real-world actions, supporting various interactions between the large language model agent and the environment. That is, it endows the large language models with the ability of embodied perception, reasoning, and action, which is also known as embodied agent
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib143" title="">
       143
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib40" title="">
       40
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib107" title="">
       107
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib174" title="">
       174
      </a>
      ]
     </cite>
     .
Specifically, these works approach the embodied tasks in the real-world environment, such as navigating and controlling robots, and take advantage of the reasoning and decision-making abilities of large language models. Moreover, to ensure the agents can take embodied actions, these works connect the textual output with a tool or another action-execution module.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S2.SS4.p4">
    <p class="ltx_p" id="S2.SS4.p4.1">
     However, these works only consider simple environments such as a room or virtual game environment. In addition, the tasks are relatively simple.
Unlike these works, in this paper, we present a far more complex problem in building fundamentally embodied agents in the city environment, and the agents can have almost all kinds of embodied behaviors of real humankind.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S2.SS5">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     2.5
    </span>
    Agent-based Modeling and Simulation
   </h3>
   <div class="ltx_para ltx_noindent" id="S2.SS5.p1">
    <p class="ltx_p" id="S2.SS5.p1.1">
     Agent-based modeling and simulation is an important and powerful approach to modeling complex systems, such as the city system, understanding, analyzing, explaining, and even predicting the dynamics of the systems
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib14" title="">
       14
      </a>
      ]
     </cite>
     .
Generally speaking, simulation can be divided into macrosimulation and microsimulation.
Macrosimulation refers to simulating the system from an aggregate or high level, which focuses on the trends and behaviors within a system or a population without focusing on the individual-level characteristics. Specifically, macrosimulation may deploy several equations to describe how the critical variables in the system affect each other.
However, it is quite challenging to formulate the equations since real-world systems are always very complex, which motivates the microsimulation, which is also known as agent-based simulation. On the other hand, microsimulation focuses on individual entities within a system.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S2.SS5.p2">
    <p class="ltx_p" id="S2.SS5.p2.1">
     In general, agent-based simulation aims to model the behavior of individual components or agents to understand their interactions and how they collectively contribute to the overall system. For example, the famous Cellular Automata
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib153" title="">
       153
      </a>
      ]
     </cite>
     is comprised of discrete cells, each following a set of rules based on their neighboring cells.
The simulations based on setting rules for each individual can often showcase emergent behaviors, where complex patterns arise from simple interactions between individual components.
Since it is general, agent-based simulation is extensively used in various fields, such as biology
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib5" title="">
       5
      </a>
      ]
     </cite>
     , ecology
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib104" title="">
       104
      </a>
      ]
     </cite>
     , sociology
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib100" title="">
       100
      </a>
      ]
     </cite>
     , etc., to model systems where individual entities influence collective behavior.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S2.SS5.p3">
    <p class="ltx_p" id="S2.SS5.p3.1">
     The early attempts at agent-based simulation
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib24" title="">
       24
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib138" title="">
       138
      </a>
      ]
     </cite>
     used some simple rules or formulas to guide how each individual behaved when faced with environmental change, which is easy to implement but makes it hard to capture complex individual behaviors accurately. After that, with the development of neural networks, for those individual decision factors that the simple rules cannot well capture, the neural networks are leveraged
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib44" title="">
       44
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib52" title="">
       52
      </a>
      ]
     </cite>
     .
Furthermore, recent works tend to deploy reinforcement learning-based agents
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib183" title="">
       183
      </a>
      ]
     </cite>
     , for which each individual’s goal in the simulation is to maximize the reward.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S2.SS5.p4">
    <p class="ltx_p" id="S2.SS5.p4.1">
     However, these agents are limited since they are not autonomous and require human-defined goals or rules, which motivates the large language model-driven agents.
In this paper, we present the UGI system, one of the main goals of which is to deploy large language model-based agents to simulate the complex dynamics of the city and further support various applications such as decision-making, etc.
The large language model agents are the up-to-date solution for agent-based modeling and simulation for the complex city system.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S2.SS6">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     2.6
    </span>
    Metaverse
   </h3>
   <div class="ltx_para ltx_noindent" id="S2.SS6.p1">
    <p class="ltx_p" id="S2.SS6.p1.1">
     The Metaverse epitomizes a collective virtual shared space, formed from the fusion of physical and digital realities, typically accessed through immersive technologies such as virtual reality (VR)
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib84" title="">
       84
      </a>
      ]
     </cite>
     and augmented reality (AR)
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib109" title="">
       109
      </a>
      ]
     </cite>
     . This digital universe offers an array of interactive experiences, social interactions, and economic activities, presenting various research questions and avenues for advancement. At its philosophical core, the Metaverse is entwined with the reality-virtuality continuum
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib31" title="">
       31
      </a>
      ]
     </cite>
     . On the reality aspect, it draws inspiration from the concept of the digital twin, meticulously replicating the physical world within the virtual sphere. This comprehensive replication captures physical objects, interactions, and dynamics, integrating reality into the digital landscape
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib45" title="">
       45
      </a>
      ]
     </cite>
     . Conversely, the virtuality facet of the Metaverse revolves around generating entities within the digital realm
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib20" title="">
       20
      </a>
      ]
     </cite>
     . These virtual creations, born from human imagination and innovation, surpass physical limitations and showcase human ingenuity in the virtual domain. Recent strides in Artificial Intelligence Generated Content (AIGC) notably advance this field
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib98" title="">
       98
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib116" title="">
       116
      </a>
      ]
     </cite>
     .
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S2.SS6.p2">
    <p class="ltx_p" id="S2.SS6.p2.1">
     Therefore, it comes as no surprise that research in this field is currently focused on two primary directions, one of which involves progress related to devices closely associated with the physical world. In contemporary times, Metaverse applications vary based on execution devices, such as tabletops, projectors, hand-held touchscreen devices, and headsets
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib56" title="">
       56
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib105" title="">
       105
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib6" title="">
       6
      </a>
      ]
     </cite>
     . These devices play a pivotal role in creating seamless, immersive experiences. Recent studies have delved into innovative solutions aiming to prevent information overload
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib38" title="">
       38
      </a>
      ]
     </cite>
     , alleviate cognitive load
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib77" title="">
       77
      </a>
      ]
     </cite>
     , explore eye-tracking technologies
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib122" title="">
       122
      </a>
      ]
     </cite>
     , synchronize visual-motor responses
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib79" title="">
       79
      </a>
      ]
     </cite>
     , or leverage natural finger positioning
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib158" title="">
       158
      </a>
      ]
     </cite>
     . These efforts aim to create more accessible and intuitive entry points into the physical world. In the virtual realm, advancements in Artificial Intelligence (AI) have revolutionized artistic creation. With the success of diffusion models
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib123" title="">
       123
      </a>
      ]
     </cite>
     and applications like Midjourney, demonstrating high-quality, real-life image generation capabilities, creators within the Metaverse can now generate diverse types, contents, and styles of artworks through simple textual prompts. Similarly, generative works in film
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib43" title="">
       43
      </a>
      ]
     </cite>
     , audio
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib72" title="">
       72
      </a>
      ]
     </cite>
     , or poetry
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib93" title="">
       93
      </a>
      ]
     </cite>
     have produced impressive content, ultimately providing users with experiences derived from reality but elevated beyond it. This revolution extends further to architectural designs
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib68" title="">
       68
      </a>
      ]
     </cite>
     , landscape design
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib7" title="">
       7
      </a>
      ]
     </cite>
     , and urban planning
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib186" title="">
       186
      </a>
      ]
     </cite>
     , offering exciting possibilities to create a metaverse city.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S2.SS6.p3">
    <p class="ltx_p" id="S2.SS6.p3.1">
     Looking ahead, the Metaverse is poised for rapid evolution and expansion, particularly in encompassing entire cities and creating an equitably accessible City Metaverse. Future developments may involve enhanced interoperability between diverse virtual environments, integration of AI for personalized experiences, advancements in haptic feedback systems
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib34" title="">
       34
      </a>
      ]
     </cite>
     , and exploration of blockchain
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib80" title="">
       80
      </a>
      ]
     </cite>
     for decentralized virtual economies. Our proposed foundational platform aims to build the future city metaverse with embodied agent to achieve urban generative intelligence.
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="S3">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    3
   </span>
   Architecture
  </h2>
  <figure class="ltx_figure" id="S3.F1">
   <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="413" id="S3.F1.g1" src="/html/2312.11813/assets/Figures/Architecture.png" width="449"/>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     Figure 1:
    </span>
    Architecture of the foundational platform for urban generative intelligence.
   </figcaption>
  </figure>
  <div class="ltx_para ltx_noindent" id="S3.p1">
   <p class="ltx_p" id="S3.p1.1">
    Here, we present the overall architecture of our proposed Urban Generative Intelligence (UGI) platform (see Figure
    <a class="ltx_ref" href="#S3.F1" title="Figure 1 ‣ 3 Architecture ‣ Urban Generative Intelligence (UGI): A Foundational Platform for Agents in Embodied City Environment">
     <span class="ltx_text ltx_ref_tag">
      1
     </span>
    </a>
    ). The key idea is to assemble the powerful city simulator, urban knowledge graphs (Urban KG) and various data streams as an open digital infrastructure. More importantly, the infrastructure will provide a standard language interface that enables the easy plugin of large language models and generative agents. It allows the generative intelligent models to conveniently access the computation power and factual knowledge in digital infrastructure, test strategies in various simulated scenarios and learn to evolve based on the feedback. Consequently, these empowered generative models will facilitate various downstream urban applications.
The key components of the presented architecture are elaborated as follows:
   </p>
  </div>
  <div class="ltx_para ltx_noindent" id="S3.p2">
   <p class="ltx_p" id="S3.p2.1">
    <span class="ltx_text ltx_font_bold" id="S3.p2.1.1">
     Open Digital Infrastructure
    </span>
    : This component aims to provide a backbone system that integrates the data science resources and computational tools designed for urban problems. Specifically, it accesses various data streams in urban systems to collect massive spatial-temporal data of empirical urban activities, covering the aspects of spatial layout (e.g. points-of-interest and areas-of-interest), infrastructure distribution (e.g. road network and subway network), human behaviour (e.g. individual movements and collective mobility flows) and urban dynamics (e.g. traffic jams). These rich datasets are fed into a powerful city simulator,
    <em class="ltx_emph ltx_font_italic" id="S3.p2.1.2">
     Mirage
    </em>
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib176" title="">
      176
     </a>
     ]
    </cite>
    , which can simulate the complex interactions between human, thing and space in an efficient and extensible manner. On top of the empirical observational data, this module can simulate various hypothetical scenarios efficiently, providing diverse environment to host intelligent agents. Besides,
    <em class="ltx_emph ltx_font_italic" id="S3.p2.1.3">
     UrbanKG
    </em>
    module
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib95" title="">
      95
     </a>
     ]
    </cite>
    fuses various data streams and extracts factual knowledge, such as the spatial relation like “border by” and semantic relation like “category of”.
Urban KG provides the functions of construction, storage, and basic operations and algorithms of factual knowledge, which can facilitate easy access in generative intelligence models.
   </p>
  </div>
  <div class="ltx_para ltx_noindent" id="S3.p3">
   <p class="ltx_p" id="S3.p3.1">
    <span class="ltx_text ltx_font_bold" id="S3.p3.1.1">
     Language Interface
    </span>
    : We design a standardized language interface to fully release the power of open digital infrastructure. City simulator, Urban KG and diverse data sources used to be difficult to access. They often require customized algorithms to configure city simulator, retrieve factual knowledge from Urban KG and integrate various data sources. Such obstacles limit their application in downstream tasks, and make their power inaccessible to advanced AI models. In our architecture, we design a user-friendly language interface to fully unleash the potential of the open digital infrastructure. It uses predefined natural language protocol to allow large language models and generative agents to conveniently leverage the computation power of city simulator and access factual knowledge from Urban KG. The standardized language interface reduces the barrier of developing language model-driven agents on top of the open digital infrastructure, which hopefully will foster the proliferation of generative urban agents.
   </p>
  </div>
  <div class="ltx_para ltx_noindent" id="S3.p4">
   <p class="ltx_p" id="S3.p4.1">
    <span class="ltx_text ltx_font_bold" id="S3.p4.1.1">
     Generative Intelligence
    </span>
    : On top of the language interface, we propose to train a foundation model customized for urban problems,
    <em class="ltx_emph ltx_font_italic" id="S3.p4.1.2">
     CityGPT
    </em>
    . Specifically, CityGPT is a pre-trained large language model that encodes local urban knowledge via the language interface. It effectively leverages the reasoning capability and common sense in large language model, and greatly reinforced for specialized local urban problems. Empowered by this powerful city foundation model, we will design a series of generative agents in the dimensions of urban mobility, economy, community and society. These agents not only are capable of high quality decision making in various scenarios, but also can enable realistic agent-based simulations. Such agents combined with
    <em class="ltx_emph ltx_font_italic" id="S3.p4.1.3">
     CityGPT
    </em>
    will release the power of generative intelligence to solve various important urban problems, such as urban planning, climate adaptation, inequality reduction, etc.
   </p>
  </div>
 </section>
 <section class="ltx_section" id="S4">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    4
   </span>
   Open Digital Infrastructure
  </h2>
  <div class="ltx_para ltx_noindent" id="S4.p1">
   <p class="ltx_p" id="S4.p1.1">
    One question that must be answered on the road to building urban generative intelligence is how to create a real urban digital environment.
With a real urban digital environment, agents can use LLMs’ capabilities to perform realistic interaction behaviors in this environment.
Therefore, they can address specific urban issues, simulate complex urban systems, and even assess the level of urban intelligence.
To build open digital infrastructure that satisfy the interaction requirements of agents, we start with urban modeling in Section
    <a class="ltx_ref" href="#S4.SS1" title="4.1 Urban Modeling ‣ 4 Open Digital Infrastructure ‣ Urban Generative Intelligence (UGI): A Foundational Platform for Agents in Embodied City Environment">
     <span class="ltx_text ltx_ref_tag">
      4.1
     </span>
    </a>
    , build data streams of real urban data based on multiple sources in Section
    <a class="ltx_ref" href="#S4.SS2" title="4.2 Data Streams ‣ 4 Open Digital Infrastructure ‣ Urban Generative Intelligence (UGI): A Foundational Platform for Agents in Embodied City Environment">
     <span class="ltx_text ltx_ref_tag">
      4.2
     </span>
    </a>
    , implement a computational engine (i.e. city simulator) that supports mobility, social, and economic simulations in Section
    <a class="ltx_ref" href="#S4.SS3" title="4.3 City Simulator ‣ 4 Open Digital Infrastructure ‣ Urban Generative Intelligence (UGI): A Foundational Platform for Agents in Embodied City Environment">
     <span class="ltx_text ltx_ref_tag">
      4.3
     </span>
    </a>
    , and finally provide open application programming interface (API) and natural language interface for agents and human users in Section
    <a class="ltx_ref" href="#S4.SS4" title="4.4 Open Interfaces ‣ 4 Open Digital Infrastructure ‣ Urban Generative Intelligence (UGI): A Foundational Platform for Agents in Embodied City Environment">
     <span class="ltx_text ltx_ref_tag">
      4.4
     </span>
    </a>
    .
The whole framework of the open digital infrastructure is shown in Figure
    <a class="ltx_ref" href="#S4.F2" title="Figure 2 ‣ 4 Open Digital Infrastructure ‣ Urban Generative Intelligence (UGI): A Foundational Platform for Agents in Embodied City Environment">
     <span class="ltx_text ltx_ref_tag">
      2
     </span>
    </a>
    .
   </p>
  </div>
  <figure class="ltx_figure" id="S4.F2">
   <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="316" id="S4.F2.g1" src="/html/2312.11813/assets/x1.png" width="461"/>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     Figure 2:
    </span>
    The framework of the open digital infrastructure.
   </figcaption>
  </figure>
  <section class="ltx_subsection" id="S4.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     4.1
    </span>
    Urban Modeling
   </h3>
   <div class="ltx_para ltx_noindent" id="S4.SS1.p1">
    <p class="ltx_p" id="S4.SS1.p1.1">
     From the perspective of urban spatial structure, cities can be considered to be made up of many areas and a road network connecting each area.
These areas include commercial land such as shopping centers, industrial land such as factories, residential land such as neighborhoods, and public service land such as parks and sport fields.
In the work, we define these areas as areas-of-interest (AOIs).
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S4.SS1.p2">
    <p class="ltx_p" id="S4.SS1.p2.1">
     From the perspective of urban functions, cities are represented as a collection of points-of-interest (POIs).
Restaurants cater to the dietary needs of the public, hotels provide temporary accommodation for travelers, and auto repair stores help people with vehicle problems.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S4.SS1.p3">
    <p class="ltx_p" id="S4.SS1.p3.1">
     To model the external and internal characteristics of the city at the same time, our urban modeling takes into account both the urban spatial structure and urban functions, including the urban road network, AOIs, and POIs.
In more detail, the urban road network contains two types of elements, roads and junctions.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S4.SS1.p4">
    <p class="ltx_p" id="S4.SS1.p4.1">
     After modeling the spatial structure and function of the city, we then consider the most critical element that makes up the city, human.
Under such modeling, human activity in the city is in terms of spatial structure moving between the urban road network and AOIs, while in the functional sense it is expressed as visiting different POIs at different times.
Human social behavior is then viewed as peer-to-peer and peer-to-cluster messaging.
Relationships in pairs or groups can be predefined through social networks (i.e. online socialization) or obtained based on spatial proximity (i.e. offline socialization).
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S4.SS1.p5">
    <p class="ltx_p" id="S4.SS1.p5.1">
     To model the necessities that people need to live in cities, we also need to model infrastructure networks and economic systems.
Infrastructure networks, including power grids, water supply networks, communication networks, etc., are modeled as a topology with AOIs as vertices, and edges represent infrastructure conduits like electrical wiring, water pipes, etc.
Modeling of economic systems includes companies, individuals, governments, banks.
Between these entities, we model the basic economic behaviors of consumption, wages, taxes, and interest.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S4.SS1.p6">
    <p class="ltx_p" id="S4.SS1.p6.1">
     Through the above modeling, we are able to obtain a comprehensive description of people’s lives in the city, including people’s mobility, people’s socialization, people’s economic behavior, etc.
This will guide us in refining the construction of real data streams and the implementation of the city simulator.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S4.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     4.2
    </span>
    Data Streams
   </h3>
   <section class="ltx_subsubsection" id="S4.SS2.SSS1">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      4.2.1
     </span>
     Databases
    </h4>
    <div class="ltx_para ltx_noindent" id="S4.SS2.SSS1.p1">
     <p class="ltx_p" id="S4.SS2.SSS1.p1.1">
      To model cities realistically, it is important to continuously collect real-world data and enrich the attributes of urban elements based on the data and the data preprocessing processes.
To achieve this, we build a pipeline that incorporates multiple data sources such as open source crowd-sourced data, research results
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib58" title="">
        58
       </a>
       ,
       <a class="ltx_ref" href="#bib.bib137" title="">
        137
       </a>
       ]
      </cite>
      , and Internet application services to profile a city.
After preprocessing is complete, the city modeling data is stored in multiple databases to be used as input to the city simulator or available for call by the agent via the API.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S4.SS2.SSS1.p2">
     <p class="ltx_p" id="S4.SS2.SSS1.p2.1">
      For the urban spatial structure, i.e., the urban road network and AOIs, we first obtain the original urban road vertex-edge topology and AOI polygon boundaries from OpenStreetMap
      <span class="ltx_note ltx_role_footnote" id="footnote1">
       <sup class="ltx_note_mark">
        1
       </sup>
       <span class="ltx_note_outer">
        <span class="ltx_note_content">
         <sup class="ltx_note_mark">
          1
         </sup>
         <span class="ltx_tag ltx_tag_note">
          1
         </span>
         <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">
          https://www.openstreetmap.org/
         </span>
        </span>
       </span>
      </span>
      .
To improve the quality of the OpenStreetMap data to meet the needs of the city simulator, we perform a series of processes on the raw geometric data.
For the urban road vertex-edge topology, we first aggregate redundant vertices and edges so that each vertex corresponds to a real-world junction and an edge corresponds to a real-world road.
For the edges, we assign the number of lanes and the speed limit to them based on the road class provided by OpenStreetMap.
Then, we identify the junction morphology based on the topology and the geometry of the edges, distinguishing between ramps, crossroads, T-intersections, etc.
Based on the junction morphology, we establish the road to road connectivity at the junction and assign their turn types and signal phases.
Finally, we can obtain an urban road network with the following elements and attributes:
     </p>
     <ul class="ltx_itemize" id="S4.I1">
      <li class="ltx_item" id="S4.I1.i1" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S4.I1.i1.p1">
        <p class="ltx_p" id="S4.I1.i1.p1.1">
         <span class="ltx_text ltx_font_bold" id="S4.I1.i1.p1.1.1">
          Road:
         </span>
         ID, road’s geometry, number of lanes and speed limit.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S4.I1.i2" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para ltx_noindent" id="S4.I1.i2.p1">
        <p class="ltx_p" id="S4.I1.i2.p1.1">
         <span class="ltx_text ltx_font_bold" id="S4.I1.i2.p1.1.1">
          Junction:
         </span>
         ID, list of road IDs connected to the junction, connectivity between roads with the number of lanes and the turn types, and signal phases.
        </p>
       </div>
      </li>
     </ul>
     <p class="ltx_p" id="S4.SS2.SSS1.p2.2">
      For the AOI data, we use only the polygon boundary data provided by OpenStreetMap.
To enrich the attributes of AOIs, land use
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib58" title="">
        58
       </a>
       ]
      </cite>
      and population data
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib137" title="">
        137
       </a>
       ]
      </cite>
      are matched to AOI polygons and used to add the type attribute and the population size attribute to the AOI.
Besides, we also match the AOI polygons with close roads to get the spatial locations of the connection points between the AOI and the neighboring roads, and establish the topological association between the AOI and the urban road network.
Thus, we can obtain AOIs with the following attributes:
     </p>
     <ul class="ltx_itemize" id="S4.I2">
      <li class="ltx_item" id="S4.I2.i1" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para ltx_noindent" id="S4.I2.i1.p1">
        <p class="ltx_p" id="S4.I2.i1.p1.1">
         <span class="ltx_text ltx_font_bold" id="S4.I2.i1.p1.1.1">
          AOI:
         </span>
         ID, boundary geometry, land use type, population, and road connection points.
        </p>
       </div>
      </li>
     </ul>
    </div>
    <div class="ltx_para ltx_noindent" id="S4.SS2.SSS1.p3">
     <p class="ltx_p" id="S4.SS2.SSS1.p3.1">
      For POI data representing urban functions, we use UrbanKG’s data sources to benefit from the spatio-temporal correlation knowledge and data fusion of urban domains provided by UrbanKG.
We match the POI data to the AOI containing it based on its latitude and longitude coordinates.
In this way, elements describing urban functions are linked to the spatial structure of the city through spatial subordination, which helps to understand and control the intentions (e.g. go for leisure) and actions (e.g. drive to the park) of human activities in cities.
We can obtain POIs with the following attributes:
     </p>
     <ul class="ltx_itemize" id="S4.I3">
      <li class="ltx_item" id="S4.I3.i1" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para ltx_noindent" id="S4.I3.i1.p1">
        <p class="ltx_p" id="S4.I3.i1.p1.1">
         <span class="ltx_text ltx_font_bold" id="S4.I3.i1.p1.1.1">
          POI:
         </span>
         ID, coordinate, name, category, and belonging AOI ID.
        </p>
       </div>
      </li>
     </ul>
    </div>
    <div class="ltx_para ltx_noindent" id="S4.SS2.SSS1.p4">
     <p class="ltx_p" id="S4.SS2.SSS1.p4.6">
      It is very hard to get direct access to the activities of all people in the city.
However, through data analysis and model training on sampled human travel records (e.g., check-in sequences, GPS tracks, etc.), deep learning models
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib124" title="">
        124
       </a>
       ,
       <a class="ltx_ref" href="#bib.bib125" title="">
        125
       </a>
       ,
       <a class="ltx_ref" href="#bib.bib169" title="">
        169
       </a>
       ,
       <a class="ltx_ref" href="#bib.bib171" title="">
        171
       </a>
       ]
      </cite>
      can help us generate and restore the full amount of human mobility behavior in the city that conforms to the real pattern.
The generated human activity contains the following attributes:
     </p>
     <ul class="ltx_itemize" id="S4.I4">
      <li class="ltx_item" id="S4.I4.i1" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para ltx_noindent" id="S4.I4.i1.p1">
        <p class="ltx_p" id="S4.I4.i1.p1.1">
         <span class="ltx_text ltx_font_bold" id="S4.I4.i1.p1.1.1">
          Person:
         </span>
         ID, home position, list of trips.
        </p>
       </div>
      </li>
     </ul>
     <p class="ltx_p" id="S4.SS2.SSS1.p4.5">
      A trip is characterized by a tuple
      <math alttext="(P_{s},P_{e},t_{s},mode)" class="ltx_Math" display="inline" id="S4.SS2.SSS1.p4.1.m1.4">
       <semantics id="S4.SS2.SSS1.p4.1.m1.4a">
        <mrow id="S4.SS2.SSS1.p4.1.m1.4.4.4" xref="S4.SS2.SSS1.p4.1.m1.4.4.5.cmml">
         <mo id="S4.SS2.SSS1.p4.1.m1.4.4.4.5" stretchy="false" xref="S4.SS2.SSS1.p4.1.m1.4.4.5.cmml">
          (
         </mo>
         <msub id="S4.SS2.SSS1.p4.1.m1.1.1.1.1" xref="S4.SS2.SSS1.p4.1.m1.1.1.1.1.cmml">
          <mi id="S4.SS2.SSS1.p4.1.m1.1.1.1.1.2" xref="S4.SS2.SSS1.p4.1.m1.1.1.1.1.2.cmml">
           P
          </mi>
          <mi id="S4.SS2.SSS1.p4.1.m1.1.1.1.1.3" xref="S4.SS2.SSS1.p4.1.m1.1.1.1.1.3.cmml">
           s
          </mi>
         </msub>
         <mo id="S4.SS2.SSS1.p4.1.m1.4.4.4.6" xref="S4.SS2.SSS1.p4.1.m1.4.4.5.cmml">
          ,
         </mo>
         <msub id="S4.SS2.SSS1.p4.1.m1.2.2.2.2" xref="S4.SS2.SSS1.p4.1.m1.2.2.2.2.cmml">
          <mi id="S4.SS2.SSS1.p4.1.m1.2.2.2.2.2" xref="S4.SS2.SSS1.p4.1.m1.2.2.2.2.2.cmml">
           P
          </mi>
          <mi id="S4.SS2.SSS1.p4.1.m1.2.2.2.2.3" xref="S4.SS2.SSS1.p4.1.m1.2.2.2.2.3.cmml">
           e
          </mi>
         </msub>
         <mo id="S4.SS2.SSS1.p4.1.m1.4.4.4.7" xref="S4.SS2.SSS1.p4.1.m1.4.4.5.cmml">
          ,
         </mo>
         <msub id="S4.SS2.SSS1.p4.1.m1.3.3.3.3" xref="S4.SS2.SSS1.p4.1.m1.3.3.3.3.cmml">
          <mi id="S4.SS2.SSS1.p4.1.m1.3.3.3.3.2" xref="S4.SS2.SSS1.p4.1.m1.3.3.3.3.2.cmml">
           t
          </mi>
          <mi id="S4.SS2.SSS1.p4.1.m1.3.3.3.3.3" xref="S4.SS2.SSS1.p4.1.m1.3.3.3.3.3.cmml">
           s
          </mi>
         </msub>
         <mo id="S4.SS2.SSS1.p4.1.m1.4.4.4.8" xref="S4.SS2.SSS1.p4.1.m1.4.4.5.cmml">
          ,
         </mo>
         <mrow id="S4.SS2.SSS1.p4.1.m1.4.4.4.4" xref="S4.SS2.SSS1.p4.1.m1.4.4.4.4.cmml">
          <mi id="S4.SS2.SSS1.p4.1.m1.4.4.4.4.2" xref="S4.SS2.SSS1.p4.1.m1.4.4.4.4.2.cmml">
           m
          </mi>
          <mo id="S4.SS2.SSS1.p4.1.m1.4.4.4.4.1" lspace="0em" rspace="0em" xref="S4.SS2.SSS1.p4.1.m1.4.4.4.4.1.cmml">
           ​
          </mo>
          <mi id="S4.SS2.SSS1.p4.1.m1.4.4.4.4.3" xref="S4.SS2.SSS1.p4.1.m1.4.4.4.4.3.cmml">
           o
          </mi>
          <mo id="S4.SS2.SSS1.p4.1.m1.4.4.4.4.1a" lspace="0em" rspace="0em" xref="S4.SS2.SSS1.p4.1.m1.4.4.4.4.1.cmml">
           ​
          </mo>
          <mi id="S4.SS2.SSS1.p4.1.m1.4.4.4.4.4" xref="S4.SS2.SSS1.p4.1.m1.4.4.4.4.4.cmml">
           d
          </mi>
          <mo id="S4.SS2.SSS1.p4.1.m1.4.4.4.4.1b" lspace="0em" rspace="0em" xref="S4.SS2.SSS1.p4.1.m1.4.4.4.4.1.cmml">
           ​
          </mo>
          <mi id="S4.SS2.SSS1.p4.1.m1.4.4.4.4.5" xref="S4.SS2.SSS1.p4.1.m1.4.4.4.4.5.cmml">
           e
          </mi>
         </mrow>
         <mo id="S4.SS2.SSS1.p4.1.m1.4.4.4.9" stretchy="false" xref="S4.SS2.SSS1.p4.1.m1.4.4.5.cmml">
          )
         </mo>
        </mrow>
        <annotation-xml encoding="MathML-Content" id="S4.SS2.SSS1.p4.1.m1.4b">
         <vector id="S4.SS2.SSS1.p4.1.m1.4.4.5.cmml" xref="S4.SS2.SSS1.p4.1.m1.4.4.4">
          <apply id="S4.SS2.SSS1.p4.1.m1.1.1.1.1.cmml" xref="S4.SS2.SSS1.p4.1.m1.1.1.1.1">
           <csymbol cd="ambiguous" id="S4.SS2.SSS1.p4.1.m1.1.1.1.1.1.cmml" xref="S4.SS2.SSS1.p4.1.m1.1.1.1.1">
            subscript
           </csymbol>
           <ci id="S4.SS2.SSS1.p4.1.m1.1.1.1.1.2.cmml" xref="S4.SS2.SSS1.p4.1.m1.1.1.1.1.2">
            𝑃
           </ci>
           <ci id="S4.SS2.SSS1.p4.1.m1.1.1.1.1.3.cmml" xref="S4.SS2.SSS1.p4.1.m1.1.1.1.1.3">
            𝑠
           </ci>
          </apply>
          <apply id="S4.SS2.SSS1.p4.1.m1.2.2.2.2.cmml" xref="S4.SS2.SSS1.p4.1.m1.2.2.2.2">
           <csymbol cd="ambiguous" id="S4.SS2.SSS1.p4.1.m1.2.2.2.2.1.cmml" xref="S4.SS2.SSS1.p4.1.m1.2.2.2.2">
            subscript
           </csymbol>
           <ci id="S4.SS2.SSS1.p4.1.m1.2.2.2.2.2.cmml" xref="S4.SS2.SSS1.p4.1.m1.2.2.2.2.2">
            𝑃
           </ci>
           <ci id="S4.SS2.SSS1.p4.1.m1.2.2.2.2.3.cmml" xref="S4.SS2.SSS1.p4.1.m1.2.2.2.2.3">
            𝑒
           </ci>
          </apply>
          <apply id="S4.SS2.SSS1.p4.1.m1.3.3.3.3.cmml" xref="S4.SS2.SSS1.p4.1.m1.3.3.3.3">
           <csymbol cd="ambiguous" id="S4.SS2.SSS1.p4.1.m1.3.3.3.3.1.cmml" xref="S4.SS2.SSS1.p4.1.m1.3.3.3.3">
            subscript
           </csymbol>
           <ci id="S4.SS2.SSS1.p4.1.m1.3.3.3.3.2.cmml" xref="S4.SS2.SSS1.p4.1.m1.3.3.3.3.2">
            𝑡
           </ci>
           <ci id="S4.SS2.SSS1.p4.1.m1.3.3.3.3.3.cmml" xref="S4.SS2.SSS1.p4.1.m1.3.3.3.3.3">
            𝑠
           </ci>
          </apply>
          <apply id="S4.SS2.SSS1.p4.1.m1.4.4.4.4.cmml" xref="S4.SS2.SSS1.p4.1.m1.4.4.4.4">
           <times id="S4.SS2.SSS1.p4.1.m1.4.4.4.4.1.cmml" xref="S4.SS2.SSS1.p4.1.m1.4.4.4.4.1">
           </times>
           <ci id="S4.SS2.SSS1.p4.1.m1.4.4.4.4.2.cmml" xref="S4.SS2.SSS1.p4.1.m1.4.4.4.4.2">
            𝑚
           </ci>
           <ci id="S4.SS2.SSS1.p4.1.m1.4.4.4.4.3.cmml" xref="S4.SS2.SSS1.p4.1.m1.4.4.4.4.3">
            𝑜
           </ci>
           <ci id="S4.SS2.SSS1.p4.1.m1.4.4.4.4.4.cmml" xref="S4.SS2.SSS1.p4.1.m1.4.4.4.4.4">
            𝑑
           </ci>
           <ci id="S4.SS2.SSS1.p4.1.m1.4.4.4.4.5.cmml" xref="S4.SS2.SSS1.p4.1.m1.4.4.4.4.5">
            𝑒
           </ci>
          </apply>
         </vector>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S4.SS2.SSS1.p4.1.m1.4c">
         (P_{s},P_{e},t_{s},mode)
        </annotation>
       </semantics>
      </math>
      , where
      <math alttext="P_{s}" class="ltx_Math" display="inline" id="S4.SS2.SSS1.p4.2.m2.1">
       <semantics id="S4.SS2.SSS1.p4.2.m2.1a">
        <msub id="S4.SS2.SSS1.p4.2.m2.1.1" xref="S4.SS2.SSS1.p4.2.m2.1.1.cmml">
         <mi id="S4.SS2.SSS1.p4.2.m2.1.1.2" xref="S4.SS2.SSS1.p4.2.m2.1.1.2.cmml">
          P
         </mi>
         <mi id="S4.SS2.SSS1.p4.2.m2.1.1.3" xref="S4.SS2.SSS1.p4.2.m2.1.1.3.cmml">
          s
         </mi>
        </msub>
        <annotation-xml encoding="MathML-Content" id="S4.SS2.SSS1.p4.2.m2.1b">
         <apply id="S4.SS2.SSS1.p4.2.m2.1.1.cmml" xref="S4.SS2.SSS1.p4.2.m2.1.1">
          <csymbol cd="ambiguous" id="S4.SS2.SSS1.p4.2.m2.1.1.1.cmml" xref="S4.SS2.SSS1.p4.2.m2.1.1">
           subscript
          </csymbol>
          <ci id="S4.SS2.SSS1.p4.2.m2.1.1.2.cmml" xref="S4.SS2.SSS1.p4.2.m2.1.1.2">
           𝑃
          </ci>
          <ci id="S4.SS2.SSS1.p4.2.m2.1.1.3.cmml" xref="S4.SS2.SSS1.p4.2.m2.1.1.3">
           𝑠
          </ci>
         </apply>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S4.SS2.SSS1.p4.2.m2.1c">
         P_{s}
        </annotation>
       </semantics>
      </math>
      and
      <math alttext="P_{e}" class="ltx_Math" display="inline" id="S4.SS2.SSS1.p4.3.m3.1">
       <semantics id="S4.SS2.SSS1.p4.3.m3.1a">
        <msub id="S4.SS2.SSS1.p4.3.m3.1.1" xref="S4.SS2.SSS1.p4.3.m3.1.1.cmml">
         <mi id="S4.SS2.SSS1.p4.3.m3.1.1.2" xref="S4.SS2.SSS1.p4.3.m3.1.1.2.cmml">
          P
         </mi>
         <mi id="S4.SS2.SSS1.p4.3.m3.1.1.3" xref="S4.SS2.SSS1.p4.3.m3.1.1.3.cmml">
          e
         </mi>
        </msub>
        <annotation-xml encoding="MathML-Content" id="S4.SS2.SSS1.p4.3.m3.1b">
         <apply id="S4.SS2.SSS1.p4.3.m3.1.1.cmml" xref="S4.SS2.SSS1.p4.3.m3.1.1">
          <csymbol cd="ambiguous" id="S4.SS2.SSS1.p4.3.m3.1.1.1.cmml" xref="S4.SS2.SSS1.p4.3.m3.1.1">
           subscript
          </csymbol>
          <ci id="S4.SS2.SSS1.p4.3.m3.1.1.2.cmml" xref="S4.SS2.SSS1.p4.3.m3.1.1.2">
           𝑃
          </ci>
          <ci id="S4.SS2.SSS1.p4.3.m3.1.1.3.cmml" xref="S4.SS2.SSS1.p4.3.m3.1.1.3">
           𝑒
          </ci>
         </apply>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S4.SS2.SSS1.p4.3.m3.1c">
         P_{e}
        </annotation>
       </semantics>
      </math>
      denote the starting and ending positions of the trip,
      <math alttext="t_{s}" class="ltx_Math" display="inline" id="S4.SS2.SSS1.p4.4.m4.1">
       <semantics id="S4.SS2.SSS1.p4.4.m4.1a">
        <msub id="S4.SS2.SSS1.p4.4.m4.1.1" xref="S4.SS2.SSS1.p4.4.m4.1.1.cmml">
         <mi id="S4.SS2.SSS1.p4.4.m4.1.1.2" xref="S4.SS2.SSS1.p4.4.m4.1.1.2.cmml">
          t
         </mi>
         <mi id="S4.SS2.SSS1.p4.4.m4.1.1.3" xref="S4.SS2.SSS1.p4.4.m4.1.1.3.cmml">
          s
         </mi>
        </msub>
        <annotation-xml encoding="MathML-Content" id="S4.SS2.SSS1.p4.4.m4.1b">
         <apply id="S4.SS2.SSS1.p4.4.m4.1.1.cmml" xref="S4.SS2.SSS1.p4.4.m4.1.1">
          <csymbol cd="ambiguous" id="S4.SS2.SSS1.p4.4.m4.1.1.1.cmml" xref="S4.SS2.SSS1.p4.4.m4.1.1">
           subscript
          </csymbol>
          <ci id="S4.SS2.SSS1.p4.4.m4.1.1.2.cmml" xref="S4.SS2.SSS1.p4.4.m4.1.1.2">
           𝑡
          </ci>
          <ci id="S4.SS2.SSS1.p4.4.m4.1.1.3.cmml" xref="S4.SS2.SSS1.p4.4.m4.1.1.3">
           𝑠
          </ci>
         </apply>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S4.SS2.SSS1.p4.4.m4.1c">
         t_{s}
        </annotation>
       </semantics>
      </math>
      represents the starting time of the trip, and
      <math alttext="mode" class="ltx_Math" display="inline" id="S4.SS2.SSS1.p4.5.m5.1">
       <semantics id="S4.SS2.SSS1.p4.5.m5.1a">
        <mrow id="S4.SS2.SSS1.p4.5.m5.1.1" xref="S4.SS2.SSS1.p4.5.m5.1.1.cmml">
         <mi id="S4.SS2.SSS1.p4.5.m5.1.1.2" xref="S4.SS2.SSS1.p4.5.m5.1.1.2.cmml">
          m
         </mi>
         <mo id="S4.SS2.SSS1.p4.5.m5.1.1.1" lspace="0em" rspace="0em" xref="S4.SS2.SSS1.p4.5.m5.1.1.1.cmml">
          ​
         </mo>
         <mi id="S4.SS2.SSS1.p4.5.m5.1.1.3" xref="S4.SS2.SSS1.p4.5.m5.1.1.3.cmml">
          o
         </mi>
         <mo id="S4.SS2.SSS1.p4.5.m5.1.1.1a" lspace="0em" rspace="0em" xref="S4.SS2.SSS1.p4.5.m5.1.1.1.cmml">
          ​
         </mo>
         <mi id="S4.SS2.SSS1.p4.5.m5.1.1.4" xref="S4.SS2.SSS1.p4.5.m5.1.1.4.cmml">
          d
         </mi>
         <mo id="S4.SS2.SSS1.p4.5.m5.1.1.1b" lspace="0em" rspace="0em" xref="S4.SS2.SSS1.p4.5.m5.1.1.1.cmml">
          ​
         </mo>
         <mi id="S4.SS2.SSS1.p4.5.m5.1.1.5" xref="S4.SS2.SSS1.p4.5.m5.1.1.5.cmml">
          e
         </mi>
        </mrow>
        <annotation-xml encoding="MathML-Content" id="S4.SS2.SSS1.p4.5.m5.1b">
         <apply id="S4.SS2.SSS1.p4.5.m5.1.1.cmml" xref="S4.SS2.SSS1.p4.5.m5.1.1">
          <times id="S4.SS2.SSS1.p4.5.m5.1.1.1.cmml" xref="S4.SS2.SSS1.p4.5.m5.1.1.1">
          </times>
          <ci id="S4.SS2.SSS1.p4.5.m5.1.1.2.cmml" xref="S4.SS2.SSS1.p4.5.m5.1.1.2">
           𝑚
          </ci>
          <ci id="S4.SS2.SSS1.p4.5.m5.1.1.3.cmml" xref="S4.SS2.SSS1.p4.5.m5.1.1.3">
           𝑜
          </ci>
          <ci id="S4.SS2.SSS1.p4.5.m5.1.1.4.cmml" xref="S4.SS2.SSS1.p4.5.m5.1.1.4">
           𝑑
          </ci>
          <ci id="S4.SS2.SSS1.p4.5.m5.1.1.5.cmml" xref="S4.SS2.SSS1.p4.5.m5.1.1.5">
           𝑒
          </ci>
         </apply>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S4.SS2.SSS1.p4.5.m5.1c">
         mode
        </annotation>
       </semantics>
      </math>
      indicates the mobility mode used during the trip, such as walking, driving, or biking.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S4.SS2.SSS1.p5">
     <p class="ltx_p" id="S4.SS2.SSS1.p5.1">
      For the infrastructure network, we use heuristics for construction.
The methods consider each AOI as a vertex, calculate the resource demand based on the regional population and land use type, and then obtain the higher-level vertices and the edges based on the aggregation of the resource demand.
Finally, we can obtain an infrastructure network topology with a hierarchical structure and use it for infrastructure network simulation.
In general, infrastructure networks have the following attributes:
     </p>
     <ul class="ltx_itemize" id="S4.I5">
      <li class="ltx_item" id="S4.I5.i1" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S4.I5.i1.p1">
        <p class="ltx_p" id="S4.I5.i1.p1.1">
         <span class="ltx_text ltx_font_bold" id="S4.I5.i1.p1.1.1">
          Vertex:
         </span>
         ID, coordinate, level and belonging AOI ID.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S4.I5.i2" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para ltx_noindent" id="S4.I5.i2.p1">
        <p class="ltx_p" id="S4.I5.i2.p1.1">
         <span class="ltx_text ltx_font_bold" id="S4.I5.i2.p1.1.1">
          Edge:
         </span>
         vertex pair, line geometry and level.
        </p>
       </div>
      </li>
     </ul>
     <p class="ltx_p" id="S4.SS2.SSS1.p5.2">
      For different infrastructure networks, specific fields are also added to match the corresponding simulation program inputs.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S4.SS2.SSS1.p6">
     <p class="ltx_p" id="S4.SS2.SSS1.p6.1">
      The city’s economic performance data are better publicized.
By crawling the public information from internet platforms such as enterprise information disclosure platforms, recruitment platforms and real estate agency platforms, we get the information of enterprises in the city as well as the main industries, wage levels, consumption levels and rent levels in different areas.
This data is eventually matched to the AOI by adding the following fields to the AOI:
     </p>
     <ul class="ltx_itemize" id="S4.I6">
      <li class="ltx_item" id="S4.I6.i1" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S4.I6.i1.p1">
        <p class="ltx_p" id="S4.I6.i1.p1.1">
         <span class="ltx_text ltx_font_bold" id="S4.I6.i1.p1.1.1">
          Enterprises
         </span>
         : name, category, registered capital, number of employees and average wage.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S4.I6.i2" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S4.I6.i2.p1">
        <p class="ltx_p" id="S4.I6.i2.p1.1">
         <span class="ltx_text ltx_font_bold" id="S4.I6.i2.p1.1.1">
          Consumption
         </span>
         : per capita consumption of different POI categories.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S4.I6.i3" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para ltx_noindent" id="S4.I6.i3.p1">
        <p class="ltx_p" id="S4.I6.i3.p1.1">
         <span class="ltx_text ltx_font_bold" id="S4.I6.i3.p1.1.1">
          Rent
         </span>
         : average rent.
        </p>
       </div>
      </li>
     </ul>
    </div>
    <div class="ltx_para ltx_noindent" id="S4.SS2.SSS1.p7">
     <p class="ltx_p" id="S4.SS2.SSS1.p7.1">
      In order to add more real city information and build a multimodal data base, we finally introduced images as an additional data source.
These images include satellite images and street view data.
Satellite image data is organized in tiles and the data source is from Mapbox
      <span class="ltx_note ltx_role_footnote" id="footnote2">
       <sup class="ltx_note_mark">
        2
       </sup>
       <span class="ltx_note_outer">
        <span class="ltx_note_content">
         <sup class="ltx_note_mark">
          2
         </sup>
         <span class="ltx_tag ltx_tag_note">
          2
         </span>
         <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">
          https://docs.mapbox.com/api/maps/raster-tiles/
         </span>
        </span>
       </span>
      </span>
      .
Street view data is obtained from Baidu Maps
      <span class="ltx_note ltx_role_footnote" id="footnote3">
       <sup class="ltx_note_mark">
        3
       </sup>
       <span class="ltx_note_outer">
        <span class="ltx_note_content">
         <sup class="ltx_note_mark">
          3
         </sup>
         <span class="ltx_tag ltx_tag_note">
          3
         </span>
         <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">
          https://map.baidu.com/
         </span>
        </span>
       </span>
      </span>
      , and the spatial coordinates where the images are located are spaced at intervals of 100 meters from each other.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S4.SS2.SSS2">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      4.2.2
     </span>
     Knowledge Graphs
    </h4>
    <div class="ltx_para ltx_noindent" id="S4.SS2.SSS2.p1">
     <p class="ltx_p" id="S4.SS2.SSS2.p1.1">
      At the urban functional level, the complex relationships between POIs further constitute the uniqueness of the city.
However, it is difficult to process and mine the correlation between POIs and aggregate and distill massive data based solely on the attributes of POIs.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S4.SS2.SSS2.p2">
     <p class="ltx_p" id="S4.SS2.SSS2.p2.1">
      In the field of data mining, knowledge graphs
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib146" title="">
        146
       </a>
       ,
       <a class="ltx_ref" href="#bib.bib65" title="">
        65
       </a>
       ]
      </cite>
      are a means of effectively organizing massive data and knowledge, which can help users quickly retrieve other entities that are related to a given entity.
Inspired by the idea, UrbanKG
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib96" title="">
        96
       </a>
       ]
      </cite>
      is proposed to build the relationship network of entities within the city.
UrbanKG builds a variety of relations for urban entities.
Of these, the relations on the urban spatial structure include
      <code class="ltx_verbatim ltx_font_typewriter" id="S4.SS2.SSS2.p2.1.1">
       borderBy
      </code>
      ,
      <code class="ltx_verbatim ltx_font_typewriter" id="S4.SS2.SSS2.p2.1.2">
       nearBy
      </code>
      and
      <code class="ltx_verbatim ltx_font_typewriter" id="S4.SS2.SSS2.p2.1.3">
       locateAt
      </code>
      ,
      <code class="ltx_verbatim ltx_font_typewriter" id="S4.SS2.SSS2.p2.1.4">
       belongTo
      </code>
      .
The relations regarding urban functions include
      <code class="ltx_verbatim ltx_font_typewriter" id="S4.SS2.SSS2.p2.1.5">
       brandOf
      </code>
      ,
      <code class="ltx_verbatim ltx_font_typewriter" id="S4.SS2.SSS2.p2.1.6">
       cate1Of
      </code>
      ,
      <code class="ltx_verbatim ltx_font_typewriter" id="S4.SS2.SSS2.p2.1.7">
       cate2Of
      </code>
      ,
      <code class="ltx_verbatim ltx_font_typewriter" id="S4.SS2.SSS2.p2.1.8">
       cate3Of
      </code>
      ,
      <code class="ltx_verbatim ltx_font_typewriter" id="S4.SS2.SSS2.p2.1.9">
       competitive
      </code>
      ,
      <code class="ltx_verbatim ltx_font_typewriter" id="S4.SS2.SSS2.p2.1.10">
       coCheckin
      </code>
      ,
      <code class="ltx_verbatim ltx_font_typewriter" id="S4.SS2.SSS2.p2.1.11">
       similarFunc
      </code>
      ,
      <code class="ltx_verbatim ltx_font_typewriter" id="S4.SS2.SSS2.p2.1.12">
       provideService
      </code>
      , etc.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S4.SS2.SSS2.p3">
     <p class="ltx_p" id="S4.SS2.SSS2.p3.1">
      Besides, for multi-modal data, UrbanKG establishes two relationships
      <code class="ltx_verbatim ltx_font_typewriter" id="S4.SS2.SSS2.p3.1.1">
       satelliteImageOf
      </code>
      and
      <code class="ltx_verbatim ltx_font_typewriter" id="S4.SS2.SSS2.p3.1.2">
       streetViewOf
      </code>
      .
These relational categories designed by expert knowledge and the data-driven fact set provided by UrbanKG enhance the understanding of urban spatial structure and urban functions and also provide more effective information input to agents.
     </p>
    </div>
   </section>
  </section>
  <section class="ltx_subsection" id="S4.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     4.3
    </span>
    City Simulator
   </h3>
   <div class="ltx_para ltx_noindent" id="S4.SS3.p1">
    <p class="ltx_p" id="S4.SS3.p1.1">
     The open digital infrastructure computational engine is called the city simulator.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S4.SS3.p2">
    <p class="ltx_p" id="S4.SS3.p2.1">
     Firstly, the city simulator
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib175" title="">
       175
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib176" title="">
       176
      </a>
      ]
     </cite>
     can efficiently simulate the interactions between human and urban space in large-scale cities.
In detail, it simulate the movement of agents in the urban space between roads and AOIs using multiple mobility modes (e.g. driving, walking, etc.), and provide agents with the ability to sense the environment like obtaining its current road or querying specific AOIs’ and POIs’ information by IDs.
The agent’s mobility task in the simulator is described as a list of trips.
Therefore, the agent’s behavior can be controlled by modifying its trip list.
Overall, city simulators provide agents with sense and control.
For example, the agent can use the city simulator’s interface to obtain the current road, query the AOI and POI information on the road, and then control the agent to walk to the AOI where a restaurant type POI is located.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S4.SS3.p3">
    <p class="ltx_p" id="S4.SS3.p3.1">
     As the most important part of open digital infrastructure, the city simulator need to be able to host the access of a variety of generative agents and provide excellent computing efficiency to ensure the speed of city-level simulations.
To this end, the city simulator has implemented numerous software design and optimization for urban simulation, and achieves the following features:
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S4.SS3.p4">
    <ul class="ltx_itemize" id="S4.I7">
     <li class="ltx_item" id="S4.I7.i1" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S4.I7.i1.p1">
       <p class="ltx_p" id="S4.I7.i1.p1.1">
        <span class="ltx_text ltx_font_bold" id="S4.I7.i1.p1.1.1">
         Multiple Modes Simulation:
        </span>
        The city simulator supports the simulation of multiple mobility modes, including driving, walking, biking and public transportation.
This comprehensively models how people commonly move through space in cities.
In order to realistically simulate human mobility behavior, we adopt the widely used IDM car-following model
        <cite class="ltx_cite ltx_citemacro_cite">
         [
         <a class="ltx_ref" href="#bib.bib140" title="">
          140
         </a>
         ]
        </cite>
        and MOBIL lane-changing model
        <cite class="ltx_cite ltx_citemacro_cite">
         [
         <a class="ltx_ref" href="#bib.bib75" title="">
          75
         </a>
         ]
        </cite>
        to simulate driving, and the PCS
        <cite class="ltx_cite ltx_citemacro_cite">
         [
         <a class="ltx_ref" href="#bib.bib173" title="">
          173
         </a>
         ]
        </cite>
        model to simulate walking.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S4.I7.i2" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S4.I7.i2.p1">
       <p class="ltx_p" id="S4.I7.i2.p1.1">
        <span class="ltx_text ltx_font_bold" id="S4.I7.i2.p1.1.1">
         Clock Synchronization:
        </span>
        During the simulation, the city simulator and the accessed agents must be able to keep the simulation time synchronized.
In order to achieve this goal, the clock synchronization mechanism introduced in the Mirage framework
        <cite class="ltx_cite ltx_citemacro_cite">
         [
         <a class="ltx_ref" href="#bib.bib176" title="">
          176
         </a>
         ]
        </cite>
        is embedded in the city simulator, and the communication interface is opened as a necessary link for agent access.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S4.I7.i3" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S4.I7.i3.p1">
       <p class="ltx_p" id="S4.I7.i3.p1.1">
        <span class="ltx_text ltx_font_bold" id="S4.I7.i3.p1.1.1">
         Computing Acceleration:
        </span>
        Through reasonable design of control flow and data flow, and the introduction of an efficient indexing subsystem
        <cite class="ltx_cite ltx_citemacro_cite">
         [
         <a class="ltx_ref" href="#bib.bib175" title="">
          175
         </a>
         ]
        </cite>
        , the city simulator achieves computing acceleration of more than 10 times compared to wall clock time for nearly one million agents at the urban scale.
This can help the agent quickly explore, learn and evolve.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S4.I7.i4" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S4.I7.i4.p1">
       <p class="ltx_p" id="S4.I7.i4.p1.1">
        <span class="ltx_text ltx_font_bold" id="S4.I7.i4.p1.1.1">
         Various Data Retrieval Interfaces:
        </span>
        The city simulator models the spatial structure of the city.
Therefore, it also provides a rich data retrieval interfaces about the spatial structure and the agents running in the spatial structure.
These retrieval interfaces include retrieval of urban spatial topological structures (e.g. which roads the specified AOI is connected to) and runtime status (e.g. how many people are in the specified AOI now).
These retrieval interfaces provide two access forms: pull and push.
The specific details will be introduced in Section
        <a class="ltx_ref" href="#S4.SS4.SSS1" title="4.4.1 Application Programming Interface ‣ 4.4 Open Interfaces ‣ 4 Open Digital Infrastructure ‣ Urban Generative Intelligence (UGI): A Foundational Platform for Agents in Embodied City Environment">
         <span class="ltx_text ltx_ref_tag">
          4.4.1
         </span>
        </a>
        .
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S4.I7.i5" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para ltx_noindent" id="S4.I7.i5.p1">
       <p class="ltx_p" id="S4.I7.i5.p1.1">
        <span class="ltx_text ltx_font_bold" id="S4.I7.i5.p1.1.1">
         Unified Control Interface:
        </span>
        In order to simplify the control of the agent, the control interface of the agent is unified into modifying the agent’s trip list.
By modifying the trip list, the caller can control the agent’s attributes such as stay time, departure time, destination, and mobility mode.
       </p>
      </div>
     </li>
    </ul>
    <p class="ltx_p" id="S4.SS3.p4.1">
     On top of the mobility simulation, we also add the ability to social message propagation and financial flow mechanism based on the extended friendliness of the city simulator.
The social message propagation mechanism allows a person to send a message to a specific list of people or broadcast it to the surrounding crowd, which enables online and offline socialization, respectively.
Financial flows are triggered primarily based on a person’s visit to a POI.
Depending on the POI category, the city simulator models consumption, income and taxes.
The simulation of interest is triggered periodically.
Through these features, the city simulator can realistically model the life activities of agents in urban space, orderly access a large number of generative agents, and provide rich sense capabilities and a simple and unified control method.
This provides an environment for exploration, learning and evaluation for agents.
Agents can use the city simulator to enhance their understanding of the city, and even deduce the future evolution of the city and find optimal decisions.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S4.SS3.p5">
    <p class="ltx_p" id="S4.SS3.p5.1">
     Using the distributed architecture described in Mirage
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib176" title="">
       176
      </a>
      ]
     </cite>
     , the simulation of the infrastructure networks is implemented as multiple independent extensions in the city simulator.
We support to integrate PYPOWER
     <span class="ltx_note ltx_role_footnote" id="footnote4">
      <sup class="ltx_note_mark">
       4
      </sup>
      <span class="ltx_note_outer">
       <span class="ltx_note_content">
        <sup class="ltx_note_mark">
         4
        </sup>
        <span class="ltx_tag ltx_tag_note">
         4
        </span>
        <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">
         https://github.com/rwl/PYPOWER/
        </span>
       </span>
      </span>
     </span>
     as grid simulation, WNTR
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib78" title="">
       78
      </a>
      ]
     </cite>
     and SWMM
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib55" title="">
       55
      </a>
      ]
     </cite>
     as water supply and drainage simulation, and the digital twin system for mobile networks
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib57" title="">
       57
      </a>
      ]
     </cite>
     as communication simulation.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S4.SS4">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     4.4
    </span>
    Open Interfaces
   </h3>
   <section class="ltx_subsubsection" id="S4.SS4.SSS1">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      4.4.1
     </span>
     Application Programming Interface
    </h4>
    <div class="ltx_para ltx_noindent" id="S4.SS4.SSS1.p1">
     <p class="ltx_p" id="S4.SS4.SSS1.p1.1">
      As the open digital infrastructure in UGI, its capabilities need to be exported through open interfaces.
For experienced developers, we provide two layers of application programming interface (API).
The first layer is based on Protobuf
      <span class="ltx_note ltx_role_footnote" id="footnote5">
       <sup class="ltx_note_mark">
        5
       </sup>
       <span class="ltx_note_outer">
        <span class="ltx_note_content">
         <sup class="ltx_note_mark">
          5
         </sup>
         <span class="ltx_tag ltx_tag_note">
          5
         </span>
         <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">
          https://protobuf.dev/programming-guides/proto3/
         </span>
        </span>
       </span>
      </span>
      and gRPC
      <span class="ltx_note ltx_role_footnote" id="footnote6">
       <sup class="ltx_note_mark">
        6
       </sup>
       <span class="ltx_note_outer">
        <span class="ltx_note_content">
         <sup class="ltx_note_mark">
          6
         </sup>
         <span class="ltx_tag ltx_tag_note">
          6
         </span>
         <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">
          https://grpc.io/
         </span>
        </span>
       </span>
      </span>
      .
We use Protobuf to standardize data structures including roads, junctions, AOIs, and POIs.
gRPC is used to implement communication between the caller and the city simulator to achieve clock synchronization, data retrieval, and control.
Actually, the gRPC implementation we use is Connect
      <span class="ltx_note ltx_role_footnote" id="footnote7">
       <sup class="ltx_note_mark">
        7
       </sup>
       <span class="ltx_note_outer">
        <span class="ltx_note_content">
         <sup class="ltx_note_mark">
          7
         </sup>
         <span class="ltx_tag ltx_tag_note">
          7
         </span>
         <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">
          https://connectrpc.com/
         </span>
        </span>
       </span>
      </span>
      , which is a simple, reliable and interoperable library to provide both browser (i.e. JSON format message on HTTP) and gRPC-compatible APIs.
For users who do not want to see the underlying communication implementation, we provide a higher-level Python API.
Through the Python API, users can interact with the open infrastructure in the form of Python function calls and receive responses in Python’s basic data format (e.g. dict and list), which is more familiar to researchers.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S4.SS4.SSS1.p2">
     <p class="ltx_p" id="S4.SS4.SSS1.p2.1">
      For the original data from the data streams, encapsulation of database access is provided in the Python API.
Relation queries and reasoning to UrbanKG are also included in it.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S4.SS4.SSS1.p3">
     <p class="ltx_p" id="S4.SS4.SSS1.p3.1">
      Through these APIs, users can not only access the original data provided by the data streams, but also can
      <span class="ltx_text ltx_font_bold" id="S4.SS4.SSS1.p3.1.1">
       sense
      </span>
      the environment and
      <span class="ltx_text ltx_font_bold" id="S4.SS4.SSS1.p3.1.2">
       control
      </span>
      agents in the city simulator.
The main sense APIs are as follows:
     </p>
     <ul class="ltx_itemize" id="S4.I8">
      <li class="ltx_item" id="S4.I8.i1" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S4.I8.i1.p1">
        <p class="ltx_p" id="S4.I8.i1.p1.1">
         <span class="ltx_text ltx_font_bold" id="S4.I8.i1.p1.1.1">
          GetAoi
         </span>
         : get the runtime status of the specific AOI.
        </p>
        <ul class="ltx_itemize" id="S4.I8.i1.I1">
         <li class="ltx_item" id="S4.I8.i1.I1.i1" style="list-style-type:none;">
          <span class="ltx_tag ltx_tag_item">
           <span class="ltx_text ltx_font_bold" id="S4.I8.i1.I1.i1.1.1.1">
            –
           </span>
          </span>
          <div class="ltx_para" id="S4.I8.i1.I1.i1.p1">
           <p class="ltx_p" id="S4.I8.i1.I1.i1.p1.1">
            <span class="ltx_text ltx_font_bold" id="S4.I8.i1.I1.i1.p1.1.1">
             Input:
            </span>
            AOI ID.
           </p>
          </div>
         </li>
         <li class="ltx_item" id="S4.I8.i1.I1.i2" style="list-style-type:none;">
          <span class="ltx_tag ltx_tag_item">
           <span class="ltx_text ltx_font_bold" id="S4.I8.i1.I1.i2.1.1.1">
            –
           </span>
          </span>
          <div class="ltx_para ltx_noindent" id="S4.I8.i1.I1.i2.p1">
           <p class="ltx_p" id="S4.I8.i1.I1.i2.p1.1">
            <span class="ltx_text ltx_font_bold" id="S4.I8.i1.I1.i2.p1.1.1">
             Output:
            </span>
            list of people IDs, number of recent entries and departures.
           </p>
          </div>
         </li>
        </ul>
       </div>
      </li>
      <li class="ltx_item" id="S4.I8.i2" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S4.I8.i2.p1">
        <p class="ltx_p" id="S4.I8.i2.p1.1">
         <span class="ltx_text ltx_font_bold" id="S4.I8.i2.p1.1.1">
          GetRoad
         </span>
         : get the runtime status of the specific road.
        </p>
        <ul class="ltx_itemize" id="S4.I8.i2.I1">
         <li class="ltx_item" id="S4.I8.i2.I1.i1" style="list-style-type:none;">
          <span class="ltx_tag ltx_tag_item">
           <span class="ltx_text ltx_font_bold" id="S4.I8.i2.I1.i1.1.1.1">
            –
           </span>
          </span>
          <div class="ltx_para" id="S4.I8.i2.I1.i1.p1">
           <p class="ltx_p" id="S4.I8.i2.I1.i1.p1.1">
            <span class="ltx_text ltx_font_bold" id="S4.I8.i2.I1.i1.p1.1.1">
             Input:
            </span>
            road ID.
           </p>
          </div>
         </li>
         <li class="ltx_item" id="S4.I8.i2.I1.i2" style="list-style-type:none;">
          <span class="ltx_tag ltx_tag_item">
           <span class="ltx_text ltx_font_bold" id="S4.I8.i2.I1.i2.1.1.1">
            –
           </span>
          </span>
          <div class="ltx_para ltx_noindent" id="S4.I8.i2.I1.i2.p1">
           <p class="ltx_p" id="S4.I8.i2.I1.i2.p1.1">
            <span class="ltx_text ltx_font_bold" id="S4.I8.i2.I1.i2.p1.1.1">
             Output:
            </span>
            list of vehicle IDs and pedestrian IDs, average speed and congestion level.
           </p>
          </div>
         </li>
        </ul>
       </div>
      </li>
      <li class="ltx_item" id="S4.I8.i3" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para ltx_noindent" id="S4.I8.i3.p1">
        <p class="ltx_p" id="S4.I8.i3.p1.1">
         <span class="ltx_text ltx_font_bold" id="S4.I8.i3.p1.1.1">
          GetPerson
         </span>
         : get the runtime status of the specific person.
        </p>
        <ul class="ltx_itemize" id="S4.I8.i3.I1">
         <li class="ltx_item" id="S4.I8.i3.I1.i1" style="list-style-type:none;">
          <span class="ltx_tag ltx_tag_item">
           <span class="ltx_text ltx_font_bold" id="S4.I8.i3.I1.i1.1.1.1">
            –
           </span>
          </span>
          <div class="ltx_para" id="S4.I8.i3.I1.i1.p1">
           <p class="ltx_p" id="S4.I8.i3.I1.i1.p1.1">
            <span class="ltx_text ltx_font_bold" id="S4.I8.i3.I1.i1.p1.1.1">
             Input:
            </span>
            person ID.
           </p>
          </div>
         </li>
         <li class="ltx_item" id="S4.I8.i3.I1.i2" style="list-style-type:none;">
          <span class="ltx_tag ltx_tag_item">
           <span class="ltx_text ltx_font_bold" id="S4.I8.i3.I1.i2.1.1.1">
            –
           </span>
          </span>
          <div class="ltx_para ltx_noindent" id="S4.I8.i3.I1.i2.p1">
           <p class="ltx_p" id="S4.I8.i3.I1.i2.p1.1">
            <span class="ltx_text ltx_font_bold" id="S4.I8.i3.I1.i2.p1.1.1">
             Output:
            </span>
            coordinate, speed, direction, trip currently in progress.
           </p>
          </div>
         </li>
        </ul>
       </div>
      </li>
     </ul>
     <p class="ltx_p" id="S4.SS4.SSS1.p3.2">
      The unique control API is as follows:
     </p>
     <ul class="ltx_itemize" id="S4.I9">
      <li class="ltx_item" id="S4.I9.i1" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para ltx_noindent" id="S4.I9.i1.p1">
        <p class="ltx_p" id="S4.I9.i1.p1.1">
         <span class="ltx_text ltx_font_bold" id="S4.I9.i1.p1.1.1">
          SetTrips
         </span>
         : modify a person’s trip list to change the person’s moving target, departure time, and mobility mode.
        </p>
        <ul class="ltx_itemize" id="S4.I9.i1.I1">
         <li class="ltx_item" id="S4.I9.i1.I1.i1" style="list-style-type:none;">
          <span class="ltx_tag ltx_tag_item">
           <span class="ltx_text ltx_font_bold" id="S4.I9.i1.I1.i1.1.1.1">
            –
           </span>
          </span>
          <div class="ltx_para" id="S4.I9.i1.I1.i1.p1">
           <p class="ltx_p" id="S4.I9.i1.I1.i1.p1.1">
            <span class="ltx_text ltx_font_bold" id="S4.I9.i1.I1.i1.p1.1.1">
             Input:
            </span>
            person ID and new list of trips.
           </p>
          </div>
         </li>
         <li class="ltx_item" id="S4.I9.i1.I1.i2" style="list-style-type:none;">
          <span class="ltx_tag ltx_tag_item">
           <span class="ltx_text ltx_font_bold" id="S4.I9.i1.I1.i2.1.1.1">
            –
           </span>
          </span>
          <div class="ltx_para ltx_noindent" id="S4.I9.i1.I1.i2.p1">
           <p class="ltx_p" id="S4.I9.i1.I1.i2.p1.1">
            <span class="ltx_text ltx_font_bold" id="S4.I9.i1.I1.i2.p1.1.1">
             Output:
            </span>
            None.
           </p>
          </div>
         </li>
        </ul>
       </div>
      </li>
     </ul>
    </div>
    <div class="ltx_para ltx_noindent" id="S4.SS4.SSS1.p4">
     <p class="ltx_p" id="S4.SS4.SSS1.p4.1">
      In particular, in order to avoid excessive processing pressure caused by polling, the city simulator provides a push mechanism for the retrieval of runtime environmental information.
The client can specify to monitor the changes of a certain element through the API.
When the element changes, the city simulator will push a message to the client to trigger the corresponding processing logic.
The list of triggers that support the push mechanism includes, but is not limited to, the following scenarios:
     </p>
     <ul class="ltx_itemize" id="S4.I10">
      <li class="ltx_item" id="S4.I10.i1" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S4.I10.i1.p1">
        <p class="ltx_p" id="S4.I10.i1.p1.1">
         Someone enters the specific AOI.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S4.I10.i2" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S4.I10.i2.p1">
        <p class="ltx_p" id="S4.I10.i2.p1.1">
         Someone leaves the specific AOI.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S4.I10.i3" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S4.I10.i3.p1">
        <p class="ltx_p" id="S4.I10.i3.p1.1">
         Someone enters the specific road.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S4.I10.i4" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S4.I10.i4.p1">
        <p class="ltx_p" id="S4.I10.i4.p1.1">
         Someone leaves the specific road.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S4.I10.i5" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S4.I10.i5.p1">
        <p class="ltx_p" id="S4.I10.i5.p1.1">
         The specific person starts a trip.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S4.I10.i6" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para ltx_noindent" id="S4.I10.i6.p1">
        <p class="ltx_p" id="S4.I10.i6.p1.1">
         The specific person finishes a trip.
        </p>
       </div>
      </li>
     </ul>
     <p class="ltx_p" id="S4.SS4.SSS1.p4.2">
      For example, the client can monitor the entry of a person into the specified AOI.
When someone enters the AOI, the client will receive the information about the person who enters the AOI, so that it can control the future behavior of the person.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S4.SS4.SSS2">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      4.4.2
     </span>
     Natural Language Interface
    </h4>
    <div class="ltx_para ltx_noindent" id="S4.SS4.SSS2.p1">
     <p class="ltx_p" id="S4.SS4.SSS2.p1.1">
      For users without programming skills, we also provide a natural language interface.
The natural language interface is a further encapsulation of the API.
Users can use some standardized natural language instructions to complete functions such as data retrieval and agent control like ALFWorld
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib130" title="">
        130
       </a>
       ]
      </cite>
      .
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S4.SS4.SSS2.p2">
     <p class="ltx_p" id="S4.SS4.SSS2.p2.1">
      For instance, in the natural language interface, the information to retrieve AOI is expressed in the following form:
     </p>
     <ul class="ltx_itemize" id="S4.I11">
      <li class="ltx_item" id="S4.I11.i1" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S4.I11.i1.p1">
        <p class="ltx_p" id="S4.I11.i1.p1.1">
         <span class="ltx_text ltx_font_bold" id="S4.I11.i1.p1.1.1">
          Request:
         </span>
         Get AOI with ID 500000000.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S4.I11.i2" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para ltx_noindent" id="S4.I11.i2.p1">
        <p class="ltx_p" id="S4.I11.i2.p1.1">
         <span class="ltx_text ltx_font_bold" id="S4.I11.i2.p1.1.1">
          Response:
         </span>
         The AOI with ID 500000000 has an area of 26059 square meters, a population of 1219, the land use type is commercial land, contains 51 POIs, and is connected to roads 10, 11 and 23.
        </p>
       </div>
      </li>
     </ul>
     <p class="ltx_p" id="S4.SS4.SSS2.p2.2">
      The control of the agent is expressed in the following form:
     </p>
     <ul class="ltx_itemize" id="S4.I12">
      <li class="ltx_item" id="S4.I12.i1" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S4.I12.i1.p1">
        <p class="ltx_p" id="S4.I12.i1.p1.1">
         <span class="ltx_text ltx_font_bold" id="S4.I12.i1.p1.1.1">
          Request:
         </span>
         Set agent with ID 1000 to drive to AOI 500000001 at 09:20, and then walk to AOI 500000010 at 11:00.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S4.I12.i2" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para ltx_noindent" id="S4.I12.i2.p1">
        <p class="ltx_p" id="S4.I12.i2.p1.1">
         <span class="ltx_text ltx_font_bold" id="S4.I12.i2.p1.1.1">
          Response:
         </span>
         OK.
        </p>
       </div>
      </li>
     </ul>
    </div>
   </section>
  </section>
 </section>
 <section class="ltx_section" id="S5">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    5
   </span>
   Foundation Model and Agent
  </h2>
  <section class="ltx_subsection" id="S5.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     5.1
    </span>
    CityGPT: Large Language Model for Urban Generative Intelligence
   </h3>
   <figure class="ltx_figure" id="S5.F3">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="157" id="S5.F3.g1" src="/html/2312.11813/assets/Figures/citygpt-framework.png" width="538"/>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      Figure 3:
     </span>
     Training procedure of CityGPT.
    </figcaption>
   </figure>
   <div class="ltx_para ltx_noindent" id="S5.SS1.p1">
    <p class="ltx_p" id="S5.SS1.p1.1">
     As the fundamental component of platform, the large language model plays the critical role of empowering the city agents with general and specific skills in the urban generative intelligence. In other words, the ability of the large language model determines the upper limit of whole system. There exists many open source large language model
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib159" title="">
       159
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib139" title="">
       139
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib8" title="">
       8
      </a>
      ]
     </cite>
     , which are build for general purpose. While these models perform well on common tasks like daily chat and text generation, they perform inefficiently even fail to support the generative city agent in the urban space in many cases due to the lack of domain-specific background knowledge
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib144" title="">
       144
      </a>
      ]
     </cite>
     and related skills. Thus, we need to enhance the general large language model to meet the requirements of city agents modelling in the urban space. The whole enhancement procedure is presented in the Figure
     <a class="ltx_ref" href="#S5.F3" title="Figure 3 ‣ 5.1 CityGPT: Large Language Model for Urban Generative Intelligence ‣ 5 Foundation Model and Agent ‣ Urban Generative Intelligence (UGI): A Foundational Platform for Agents in Embodied City Environment">
      <span class="ltx_text ltx_ref_tag">
       3
      </span>
     </a>
     . We introduce two steps to refine the general large language model to obtain the CityGPT. Firstly, we aim to incorporating the multi-source urban knowledge into the general large language model. Then, based on the output of the first step, we design sufficient methods and training datasets to induce the related skills of it for urban intelligence.
    </p>
   </div>
   <figure class="ltx_figure" id="S5.F4">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="344" id="S5.F4.g1" src="/html/2312.11813/assets/Figures/data-v2.png" width="598"/>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      Figure 4:
     </span>
     Training data of CityGPT.
    </figcaption>
   </figure>
   <div class="ltx_para ltx_noindent" id="S5.SS1.p2">
    <p class="ltx_p" id="S5.SS1.p2.1">
     <span class="ltx_text ltx_font_bold" id="S5.SS1.p2.1.1">
      Stage 1: incorporating the urban knowledge.
     </span>
     As claimed in open source models
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib159" title="">
       159
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib139" title="">
       139
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib8" title="">
       8
      </a>
      ]
     </cite>
     , most of the training corpus are from the public web text like common crawl project and only limited common data processing methods are applied due to the high-cost of handling the large volume various data. However, domain specific data like urban knowledge data are usually not open and specific data processing method is fundamentally necessary for utilizing them. Thus, incorporating the carefully processed urban knowledge into the general large language model becomes an essential step. There are several methods for incorporating knowledge into the large language model, including retrieval based methods
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib85" title="">
       85
      </a>
      ]
     </cite>
     , fine-tuning based methods
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib49" title="">
       49
      </a>
      ]
     </cite>
     , and continue pre-training methods
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib74" title="">
       74
      </a>
      ]
     </cite>
     . The retrieval based methods rely on the effective retrieval mechanisms and only limited knowledge can be utilized for each single use. While fine-tuning methods can introduce more knowledge than the first one, their capacity are still limited and may amplify the hallucination of large language model when requiring model to output things which not learned during its pre-training. Thus, we apply continue pre-training methods to incorporating urban knowledge into the general large language model.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S5.SS1.p3">
    <p class="ltx_p" id="S5.SS1.p3.1">
     As shown in the left part in the Figure
     <a class="ltx_ref" href="#S5.F4" title="Figure 4 ‣ 5.1 CityGPT: Large Language Model for Urban Generative Intelligence ‣ 5 Foundation Model and Agent ‣ Urban Generative Intelligence (UGI): A Foundational Platform for Agents in Embodied City Environment">
      <span class="ltx_text ltx_ref_tag">
       4
      </span>
     </a>
     , we collect general text corpus (e.g., domain-specific research papers, high-quality codes and online web text) and domain-specific data (e.g., urban knowledge graph
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib95" title="">
       95
      </a>
      ]
     </cite>
     , geographic data, human behavior data
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib46" title="">
       46
      </a>
      ]
     </cite>
     ) to conduct the continue pre-training process. We follow the data cleaning rules in open source LLMs
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib159" title="">
       159
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib8" title="">
       8
      </a>
      ]
     </cite>
     to process the general text corpus data. As for the domain-specific data, we process them case by case. For knowledge graph data, we apply the universal knowledge-text prediction task
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib135" title="">
       135
      </a>
      ]
     </cite>
     to integrate knowledge into model. Given a pair of tuple from urban knowledge graph, we use ChatGPT to generate a related text sentence. Different from the original paper, we combine the tuple and the related text as a training instance in the pre-training. For geographic data, we directly use the widely-used geojson
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib27" title="">
       27
      </a>
      ]
     </cite>
     format in the GIS community to organize each object as a single training instance. For human behavior data, we alignment their elements with the aforementioned two data source and regard each behavior session as a single training instance. We choose the open source Baichuan2-7B
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib159" title="">
       159
      </a>
      ]
     </cite>
     as the base model and utilize deepspeed
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib120" title="">
       120
      </a>
      ]
     </cite>
     to continue pre-train the model on a single machine with eight A100 GPUs for about one week. Other general large language model can also be selected and we take Baichuan2-7B as an experimental example. The continue pre-trained model is called as CityGPT-base model.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S5.SS1.p4">
    <p class="ltx_p" id="S5.SS1.p4.1">
     <span class="ltx_text ltx_font_bold" id="S5.SS1.p4.1.1">
      Stage 2: inducing the urban intelligence ability.
     </span>
     After the continue pre-training procedure, the based model acquires various urban knowledge. While we can directly extract information from the base model via in-context learning method, it requires few-shot demonstrations during the use which are not easy to construct. Besides, we want CityGPT learn to response based on the injected factual urban knowledge and follow the instruction from agents with standard output formats, e.g., JSON. Thus, we need the alignment procedure
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib111" title="">
       111
      </a>
      ]
     </cite>
     to induce the these general and specific ability of model. Follow the common practice of large language model
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib159" title="">
       159
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib139" title="">
       139
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib8" title="">
       8
      </a>
      ]
     </cite>
     , we apply supervised fine-tuning and DPO
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib117" title="">
       117
      </a>
      ]
     </cite>
     to achieve this goal. The dataset used in the supervised fine-tuning stage is shown in the right part of Figure
     <a class="ltx_ref" href="#S5.F4" title="Figure 4 ‣ 5.1 CityGPT: Large Language Model for Urban Generative Intelligence ‣ 5 Foundation Model and Agent ‣ Urban Generative Intelligence (UGI): A Foundational Platform for Agents in Embodied City Environment">
      <span class="ltx_text ltx_ref_tag">
       4
      </span>
     </a>
     . Specifically, we build a domain-specific alignment dataset with three kinds of data: general purpose chat datasets
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib83" title="">
       83
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib155" title="">
       155
      </a>
      ]
     </cite>
     , domain-specific chat datasets and task-solving (e.g., schedule planning, and navigation task in urban space) chat dataset. The open source general purpose chat datasets aim to teach model how to chat with people fluently. Similar to the self-instruct framework
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib148" title="">
       148
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib39" title="">
       39
      </a>
      ]
     </cite>
     , we build the domain-specific chat dataset by generating question-answer pair with ChatGPT on the domain specific text corpus. Task-solving dataset is built by solving classic urban tasks with the assistance of ChatGPT and external tools. It is noted that while urban knowledge data like UrbanKG are directly added in the continue pre-training stage, we also use the UrbanKG as an external knowledge source when solving the specific tasks. Details about the task-solving process of different urban tasks can refer to the following sections. After supervised fine-tuning CityGPT on above datasets, we use UltraFeedback
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib35" title="">
       35
      </a>
      ]
     </cite>
     with DPO to align it with human preferences. We use trl
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib141" title="">
       141
      </a>
      ]
     </cite>
     with packing strategy to accelerate the training procedure.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S5.SS1.p5">
    <p class="ltx_p" id="S5.SS1.p5.1">
     After the above two-stage training procedure, we obtain the CityGPT, an urban knowledge enhanced foundation model for urban generative intelligence. In the following sections, with sufficient prompts as inputs, CityGPT will follow the instructions to complete different tasks.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S5.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     5.2
    </span>
    General Framework for Generative City Agents
   </h3>
   <figure class="ltx_figure" id="S5.F5">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="309" id="S5.F5.g1" src="/html/2312.11813/assets/Figures/Framework.png" width="449"/>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      Figure 5:
     </span>
     A general framework for embodied generative agents in urban space.
    </figcaption>
   </figure>
   <div class="ltx_para ltx_noindent" id="S5.SS2.p1">
    <p class="ltx_p" id="S5.SS2.p1.1">
     Here, we present a general framework for embodied generative agents in urban space (see Figure
     <a class="ltx_ref" href="#S5.F5" title="Figure 5 ‣ 5.2 General Framework for Generative City Agents ‣ 5 Foundation Model and Agent ‣ Urban Generative Intelligence (UGI): A Foundational Platform for Agents in Embodied City Environment">
      <span class="ltx_text ltx_ref_tag">
       5
      </span>
     </a>
     ). This framework leverages generative foundation model as intelligence core, and it is built upon the open digital infrastructure of city simulator and UrbanKG knowledge graph. Following embodied cognition hypothesis
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib152" title="">
       152
      </a>
      ]
     </cite>
     , this framework allows generative agents to harness the realistic embodied feedback provided by the digital infrastructure and evolve its intelligence in simulated urban environment.
The proposed framework aims to extract a unified conceptual abstract for most generative city agents, and provide enough flexibility for customization in various applications. Specifically, the autonomous agents under this framework have the
     <em class="ltx_emph ltx_font_italic" id="S5.SS2.p1.1.1">
      Mental States
     </em>
     components of
     <em class="ltx_emph ltx_font_italic" id="S5.SS2.p1.1.2">
      memory
     </em>
     ,
     <em class="ltx_emph ltx_font_italic" id="S5.SS2.p1.1.3">
      persona
     </em>
     and
     <em class="ltx_emph ltx_font_italic" id="S5.SS2.p1.1.4">
      preference
     </em>
     . The
     <em class="ltx_emph ltx_font_italic" id="S5.SS2.p1.1.5">
      memory
     </em>
     component stores the history of past behaivour and interactions,
     <em class="ltx_emph ltx_font_italic" id="S5.SS2.p1.1.6">
      persona
     </em>
     component assign the agents a specific profile to leverage the role play capability of language model, and
     <em class="ltx_emph ltx_font_italic" id="S5.SS2.p1.1.7">
      preference
     </em>
     component allows personalizing the agents with high-level language description. Besides, the
     <em class="ltx_emph ltx_font_italic" id="S5.SS2.p1.1.8">
      Interaction
     </em>
     components include:
     <em class="ltx_emph ltx_font_italic" id="S5.SS2.p1.1.9">
      perceive
     </em>
     module that senses the simulated urban environment;
     <em class="ltx_emph ltx_font_italic" id="S5.SS2.p1.1.10">
      act
     </em>
     module that registers behaviours or status changes in city simulator; and
     <em class="ltx_emph ltx_font_italic" id="S5.SS2.p1.1.11">
      communicate
     </em>
     module to exchange information with other agents. Finally, these agents use city foundation model as its generative intelligence core, which can comprehensively model the internal
     <em class="ltx_emph ltx_font_italic" id="S5.SS2.p1.1.12">
      Mental States
     </em>
     and external
     <em class="ltx_emph ltx_font_italic" id="S5.SS2.p1.1.13">
      Interactions
     </em>
     to generate appropriate behaviours. To better illustrate our framework, we provide several concrete agent designs as below, focusing on two major categories of urban problems,
     <em class="ltx_emph ltx_font_italic" id="S5.SS2.p1.1.14">
      i.e.
     </em>
     , simulating urban phenomena and informing complex decision making.
    </p>
   </div>
   <section class="ltx_subsubsection" id="S5.SS2.SSS1">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      5.2.1
     </span>
     Simulation Agent: Generating Individual and Collective Behaviour
    </h4>
    <div class="ltx_para ltx_noindent" id="S5.SS2.SSS1.p1">
     <p class="ltx_p" id="S5.SS2.SSS1.p1.1">
      Complex urban phenomena are driven by the spatiotemporal agglomeration of micro activities in physical, economic and social domains. Understanding the underlying micro mechanisms and the emergence process plays an important role in modeling and managing urban systems, necessitating the simulation of complex urban phenomena with micro autonomous agents. Here, we present three design examples of embodied agents under the proposed general framework, which are customized for the simulation of the basic urban activities in physical, economic and social domains, respectively.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S5.SS2.SSS1.p2">
     <p class="ltx_p" id="S5.SS2.SSS1.p2.1">
      <span class="ltx_text ltx_font_bold" id="S5.SS2.SSS1.p2.1.1">
       Physical mobility
      </span>
      :
This agent aims to simulate individual activities and movements within urban environments, with the objective of creating trajectories that mirror real-life patterns. In addition to generate logical individual mobility behavior, we also want to reproduce the statistical distribution of collective movements by simulating a population of these agents, such as reproducing the daily number of commuters between two locations. Traditional simulation models often use simplified rules to guide agent’s mobility behaviour, but they lack depth in understanding the rich semantic in urban mobility, such as the function of a specific place and characteristics of diverse demographic profile. The generative intelligence in city foundation model offers a promising alternative. It excels in common sense reasoning and has deep knowledge of the local environment. These features equip simulation agents with accurate prior of social norms and human behaviour patterns, contributing to more plausible simulation outcomes. Besides, the flexibility of language models, particularly through their prompt-based mechanism, enables more logical and realistic reasoning in behavior simulation.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S5.SS2.SSS1.p3">
     <p class="ltx_p" id="S5.SS2.SSS1.p3.1">
      We propose a generative agent that involves the
      <em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS1.p3.1.1">
       memory
      </em>
      ,
      <em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS1.p3.1.2">
       persona
      </em>
      ,
      <em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS1.p3.1.3">
       perceive
      </em>
      and
      <em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS1.p3.1.4">
       act
      </em>
      modules in the proposed general framework, combined with reasoning core driven by CityGPT. The
      <em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS1.p3.1.5">
       memory
      </em>
      module serves as the knowledge base of historical mobility patterns, and
      <em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS1.p3.1.6">
       persona
      </em>
      module holds demographic profiles of the simulated agents. The designed agent will generate mobility behaviour step by step based on its historic movements and the preference inferred from demographic profiles. Besides, it will also jointly consider the contextual information
      <em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS1.p3.1.7">
       perceived
      </em>
      from simulated urban environment, such as current time and road traffic. After generating a mobility behaviour, it will register its new locations in simulator via
      <em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS1.p3.1.8">
       act
      </em>
      module. We also design an anchor detection mechanism that will generate a routine for each agent based on its profile, such as the work schedule, serving as the anchor points of its daily life. The reasoning core is prompted to avoid violation with these anchor points during generation. Such agent designs allow the simulation of realistic, personalized and coherent urban mobility behaivours, which are the most essential micro urban activities in physical domains, reflecting the interactions between urban dwellers and the access of various urban resources.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S5.SS2.SSS1.p4">
     <p class="ltx_p" id="S5.SS2.SSS1.p4.1">
      <span class="ltx_text ltx_font_bold" id="S5.SS2.SSS1.p4.1.1">
       Economy activity
      </span>
      :
For the economy, agent-based modeling and simulation is a promising solution for understanding and predicting the dynamics of economic systems
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib44" title="">
        44
       </a>
       ]
      </cite>
      .
Specifically, when predicting economic indicators such as GDP, unemployment rate, etc.,
Traditional methods, such as econometrics
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib132" title="">
        132
       </a>
       ]
      </cite>
      , cannot handle some complex real-world scenarios.
For example, for one of the most famous econometrics methods, Dynamic Stochastic General Equilibrium (DGSE)
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib63" title="">
        63
       </a>
       ]
      </cite>
      , sometimes there is no feasible solution for the equilibrium.
That is, the agent-based simulation can construct multiple heterogeneous agents to describe each user in the ecosystem and then define what kind of economic behaviors the agents can have. The major objective of the agent-based simulation in the economy is to observe both the emerging phenomenon from the perspective of macroeconomics and behavioral economics, which can regarded as an environment to support theory validation and decision-making.
To construct the economic agents, our previous work
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib88" title="">
        88
       </a>
       ]
      </cite>
      follows the well-acknowledged simulation mechanism illustrated in Figure
      <a class="ltx_ref" href="#S5.F6" title="Figure 6 ‣ 5.2.1 Simulation Agent: Generating Individual and Collective Behaviour ‣ 5.2 General Framework for Generative City Agents ‣ 5 Foundation Model and Agent ‣ Urban Generative Intelligence (UGI): A Foundational Platform for Agents in Embodied City Environment">
       <span class="ltx_text ltx_ref_tag">
        6
       </span>
      </a>
      .
     </p>
    </div>
    <figure class="ltx_figure" id="S5.F6">
     <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="135" id="S5.F6.g1" src="/html/2312.11813/assets/x2.png" width="368"/>
     <figcaption class="ltx_caption ltx_centering">
      <span class="ltx_tag ltx_tag_figure">
       Figure 6:
      </span>
      The illustration of LLM-driven agents for economic simulation
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib88" title="">
        88
       </a>
       ]
      </cite>
      .
     </figcaption>
    </figure>
    <div class="ltx_para ltx_noindent" id="S5.SS2.SSS1.p5">
     <p class="ltx_p" id="S5.SS2.SSS1.p5.1">
      Specifically, there are four components: labor, consumption, financial markets, and government taxation, covering the primary components of existing macroeconomic simulations.
Specifically, the agent is deployed to simulate the two most critical decisions the real human will make in real life: going to work (earning money) and consumption (spending money).
The government agents decide the tax policy, and the bank agents adjust interest rates based on market inflation or deflation.
From the macroscopic perspective, the system can observe the dynamics of overall labor and consumption markets.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S5.SS2.SSS1.p6">
     <p class="ltx_p" id="S5.SS2.SSS1.p6.1">
      <span class="ltx_text ltx_font_bold" id="S5.SS2.SSS1.p6.1.1">
       Social interaction
      </span>
      :
Human social behaviors can also be simulated with large language model-empowered agents. Specifically, the social agents require human-like abilities in social behaviors,
      <span class="ltx_text ltx_font_italic" id="S5.SS2.SSS1.p6.1.2">
       i.e.
      </span>
      , interacting with other individuals in the city system.
For social activities, there are both online and offline social networks,
      <span class="ltx_text ltx_font_italic" id="S5.SS2.SSS1.p6.1.3">
       i.e.
      </span>
      , the communication can occur in both online social networks or just via chatting in a room.
The social agent simulation mainly focuses on how information propagates on the social network and its further impact on the individuals.
That is, the LLM-driven agent can first shape their social awareness,
      <span class="ltx_text ltx_font_italic" id="S5.SS2.SSS1.p6.1.4">
       i.e.,
      </span>
      distinguishing the friends and other individuals and distinguishing different social-tie strengths.
The agents can further make their own daily schedule autonomously in the city environment, which further leads to social activities, yielding interaction between different agents, including chatting, cooperation, or even conflicts.
Last, the online social network, which is not restricted by the physical space, also provides the environment for social activities.
The agents can post new content or propagate content of the other users.
Despite the behavior itself, the internal characteristics, including the emotion and attitude of the agent, are also contained in the memory and mechanism of the large language model-based social agents.
Overall speaking, the simulation can be evaluated from both individual-level and population-level perspectives.
Regarding individual-level simulation, the aim is to generate social behaviors, attitudes, and emotions by leveraging user characteristics and the informational context within social networks.
In the social simulation system S
      <sup class="ltx_sup" id="S5.SS2.SSS1.p6.1.5">
       3
      </sup>
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib51" title="">
        51
       </a>
       ]
      </cite>
      built based on the UGI system, the social agents can accurately simulate the propagation process of information, attitude, and emotion on two representative events about nuclear energy and gender discrimination.
To summarize, the UGI system provides a good platform to support understanding and simulate social behaviors, including the emerged social phenomenon.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S5.SS2.SSS2">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      5.2.2
     </span>
     Decision Making Agent: Task Solving and Personal Assistance
    </h4>
    <div class="ltx_para ltx_noindent" id="S5.SS2.SSS2.p1">
     <p class="ltx_p" id="S5.SS2.SSS2.p1.1">
      We present the design cases of decision-making agents in the following two scenarios.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S5.SS2.SSS2.p2">
     <p class="ltx_p" id="S5.SS2.SSS2.p2.1">
      <span class="ltx_text ltx_font_bold" id="S5.SS2.SSS2.p2.1.1">
       Location recommendation
      </span>
      :
Location recommendation is one kind of new infrastructure in the area of information overload.
That is, there are too many points of interest (locations) in the city environment, and the individual living there finds it hard to determine where to visit to meet the demands. Furthermore, each individual may have his/her own preferences and interests, which motivates the construction of personalized assistants based on large language model-empowered agents.
In our system, we design an LLM-driven agent for location recommendation based on the LLM’s strong ability to understand both user preferences and decision-making. First, the agent can extract critical information from the profile, attributes, and other basic information for a given user. In other words, the LLM agent can be a personal assistant with essential information about the user. Second, the agent is good at planning and scheduling based on the city environment’s feedback. Specifically, it is always challenging for a human to directly query or search for locations for visitation since the searching or filtering process will be faced with abundant data and information. To address it, the agent can organize the output of the traditional search and recommendation engines well and even adjust the engine if the results cannot meet the requirements. Last, the agent can communicate well with the user, understand the user’s new and instant feedback, and provide textual explanations for recommendation results based on the users’ historical behaviors, personal demands, or spatial-temporal context.
In UGI, the large language model-based agents have three major abilities, including 1) understanding the mixed and complex user intents, 2) detecting the user profiles and interests based on historical data and then adjusting recommendations, and 3) identifying the improper user demands given the real-world city environment.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S5.SS2.SSS2.p3">
     <p class="ltx_p" id="S5.SS2.SSS2.p3.1">
      <span class="ltx_text ltx_font_bold" id="S5.SS2.SSS2.p3.1.1">
       Schedule planning
      </span>
      : Effective schedule planning is crucial for efficient daily activity management. Traditional methods, often relying on shortest path algorithms
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib42" title="">
        42
       </a>
       ]
      </cite>
      , provide time-saving solutions but lack personalization and flexibility. They fail to account for user-specific preferences and cannot dynamically adapt to evolving or abstract requirements, potentially leading to suboptimal scheduling and conflicts. To overcome these limitations, we design a foundation model-driven agent to help users make high quality decisions for nuanced schedule planning. This agent leverages
      <em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS2.p3.1.2">
       CityGPT
      </em>
      capabilities, integrating common-sense knowledge to contextualize tasks and offering logical, user-centric planning solutions. Its natural language interface ensures a seamless, intuitive human-computer interaction, significantly enhancing the user experience.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S5.SS2.SSS2.p4">
     <p class="ltx_p" id="S5.SS2.SSS2.p4.1">
      The proposed agent comprises several key components. Upon receiving user’s schedule input, the agent will use the comprehension and reasoning skills of its generative intelligence core to formulate optimal schedule. It will respect the fixed commitments specified by users while accommodating preferences and time constraints. The
      <em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS2.p4.1.1">
       memory
      </em>
      module continuously integrates new information, facilitating dynamic adjustments. Through its interfaces for
      <em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS2.p4.1.2">
       perceive
      </em>
      and
      <em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS2.p4.1.3">
       communicate
      </em>
      , the agent evaluates the feasibility of plans, considering travel time and proximity. It finalizes the schedule with the user preference inferred from
      <em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS2.p4.1.4">
       persona
      </em>
      module, ensuring logical coherence and user satisfaction. This approach represents a significant advancement in personalized schedule planning, harnessing foundation model’s deep understanding and reasoning for more tailored and efficient daily organization.
The design of schedule planning agent represents the basic decision making capability in urban daily life, which can also serve as a useful personal assistance that continuously learns user preference and evolves with urban environment.
     </p>
    </div>
   </section>
  </section>
 </section>
 <section class="ltx_section" id="S6">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    6
   </span>
   Evaluation
  </h2>
  <div class="ltx_para ltx_noindent" id="S6.p1">
   <p class="ltx_p" id="S6.p1.1">
    Here, we introduce a systematic evaluation framework to validate the performance of foundation model and LLM empowered agents for urban generative intelligence. As shown in Figure
    <a class="ltx_ref" href="#S6.F7" title="Figure 7 ‣ 6 Evaluation ‣ Urban Generative Intelligence (UGI): A Foundational Platform for Agents in Embodied City Environment">
     <span class="ltx_text ltx_ref_tag">
      7
     </span>
    </a>
    , the whole evaluation framework contains three levels,
   </p>
   <ul class="ltx_itemize" id="S6.I1">
    <li class="ltx_item" id="S6.I1.i1" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para" id="S6.I1.i1.p1">
      <p class="ltx_p" id="S6.I1.i1.p1.1">
       <span class="ltx_text ltx_font_italic" id="S6.I1.i1.p1.1.1">
        Level 1: evaluating the urban knowledge of CityGPT by automated domain-specific question answering
       </span>
      </p>
     </div>
    </li>
    <li class="ltx_item" id="S6.I1.i2" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para" id="S6.I1.i2.p1">
      <p class="ltx_p" id="S6.I1.i2.p1.1">
       <span class="ltx_text ltx_font_italic" id="S6.I1.i2.p1.1.1">
        Level 2: evaluating the simple reasoning ability of CityGPT via human labeled domain-specific question answering
       </span>
      </p>
     </div>
    </li>
    <li class="ltx_item" id="S6.I1.i3" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para ltx_noindent" id="S6.I1.i3.p1">
      <p class="ltx_p" id="S6.I1.i3.p1.1">
       <span class="ltx_text ltx_font_italic" id="S6.I1.i3.p1.1.1">
        Level 3: evaluating the planning and decision making ability of generative city agents by solving specific tasks in urban space
       </span>
      </p>
     </div>
    </li>
   </ul>
  </div>
  <figure class="ltx_figure" id="S6.F7">
   <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="216" id="S6.F7.g1" src="/html/2312.11813/assets/Figures/evaluation-v2.png" width="598"/>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     Figure 7:
    </span>
    Systematic evaluation framework for urban generative intelligence.
   </figcaption>
  </figure>
  <div class="ltx_para ltx_noindent" id="S6.p2">
   <p class="ltx_p" id="S6.p2.1">
    <span class="ltx_text ltx_font_bold ltx_font_italic" id="S6.p2.1.1">
     Level 1
     <span class="ltx_text ltx_font_upright" id="S6.p2.1.1.1">
      : Automated domain-specific question answer evaluation.
     </span>
    </span>
    Evaluation in
    <span class="ltx_text ltx_font_italic" id="S6.p2.1.2">
     Level 1
    </span>
    aims to validate whether the CityGPT really learn and understand the domain-knowledge injected in the training. To do this, we first extract related domain-specific question answer pairs from various general evaluation datasets including Gaokao
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib180" title="">
      180
     </a>
     ]
    </cite>
    , CEval
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib69" title="">
      69
     </a>
     ]
    </cite>
    and CMMLU
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib87" title="">
      87
     </a>
     ]
    </cite>
    as the first part of evaluation. Besides, we also construct domain-specific question answer pairs based on the pre-training corpus with the help of ChatGPT. Specifically, we first random sample instance from the training corpus. Then, with carefully designed prompts, we require ChatGPT to generate question and answer pairs based on the input context. Finally, we design another prompt to require ChatGPT validate the quality of generated QA and filter the low quality ones. In this way, we can collect questions span diverse topics in the city including transportation, civil engineering, environment, geography and so on. To enable the automated evaluation, all the question answer pairs are formatted as the multiple-choice questions and we use accuracy as the metric.
   </p>
  </div>
  <div class="ltx_para ltx_noindent" id="S6.p3">
   <p class="ltx_p" id="S6.p3.1">
    <span class="ltx_text ltx_font_bold ltx_font_italic" id="S6.p3.1.1">
     Level 2
     <span class="ltx_text ltx_font_upright" id="S6.p3.1.1.1">
      : Human labeled domain-specific question answer evaluation.
     </span>
    </span>
    We build
    <span class="ltx_text ltx_font_italic" id="S6.p3.1.2">
     Level 2
    </span>
    evaluation to validate the reasoning ability of CityGPT in the simple scenarios of city. Different from the
    <span class="ltx_text ltx_font_italic" id="S6.p3.1.3">
     Level 1
    </span>
    evaluation, we hope the
    <span class="ltx_text ltx_font_italic" id="S6.p3.1.4">
     Level 2
    </span>
    evaluation can take a step further by answering the questions which can not be directly extracted from the training corpus. Thus, we recruit volunteers with various backgrounds to write new expert problems related to urban intelligence and corresponding answers. To guarantee the coverage of problems on urban space, we predefine a question taxonomy of various domain to lead the topic selection of volunteers. One example of question on common knowledge is shown in Figure
    <a class="ltx_ref" href="#S6.F8" title="Figure 8 ‣ 6 Evaluation ‣ Urban Generative Intelligence (UGI): A Foundational Platform for Agents in Embodied City Environment">
     <span class="ltx_text ltx_ref_tag">
      8
     </span>
    </a>
    and another example on route planning is presented in Figure
    <a class="ltx_ref" href="#S6.F9" title="Figure 9 ‣ 6 Evaluation ‣ Urban Generative Intelligence (UGI): A Foundational Platform for Agents in Embodied City Environment">
     <span class="ltx_text ltx_ref_tag">
      9
     </span>
    </a>
    . We can find that due to the lack of domain knowledge on urban space, advanced LLMs like ChatGPT cannot solve these simple urban problems. At the same time, CityGPT with domain-knowledge enhancement solve them easily.
   </p>
  </div>
  <figure class="ltx_figure" id="S6.F8">
   <div class="ltx_flex_figure">
    <div class="ltx_flex_cell ltx_flex_size_2">
     <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_portrait" height="319" id="S6.F8.g1" src="/html/2312.11813/assets/Figures/Rohm-ChatGPT.png" width="252"/>
    </div>
    <div class="ltx_flex_cell ltx_flex_size_2">
     <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" height="317" id="S6.F8.g2" src="/html/2312.11813/assets/Figures/Rohm-CityGPT.png" width="293"/>
    </div>
   </div>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     Figure 8:
    </span>
    Human labeled domain-specific question answer example on commonsense knowledge. The left is the answer from ChatGPT, the right is the answer from CityGPT.
   </figcaption>
  </figure>
  <figure class="ltx_figure" id="S6.F9">
   <div class="ltx_flex_figure">
    <div class="ltx_flex_cell ltx_flex_size_2">
     <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="221" id="S6.F9.g1" src="/html/2312.11813/assets/Figures/Route-ChatGPT.png" width="281"/>
    </div>
    <div class="ltx_flex_cell ltx_flex_size_2">
     <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" height="234" id="S6.F9.g2" src="/html/2312.11813/assets/Figures/Route-CityGPT.png" width="269"/>
    </div>
   </div>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     Figure 9:
    </span>
    Human labeled domain-specific question answer example on route planning. The left is the answer from ChatGPT, the right is the answer from CityGPT.
   </figcaption>
  </figure>
  <div class="ltx_para ltx_noindent" id="S6.p4">
   <p class="ltx_p" id="S6.p4.1">
    <span class="ltx_text ltx_font_bold ltx_font_italic" id="S6.p4.1.1">
     Level 3
     <span class="ltx_text ltx_font_upright" id="S6.p4.1.1.1">
      : Problem solving of various urban tasks.
     </span>
    </span>
    Finally, we introduce several complicated real-life urban task as
    <span class="ltx_text ltx_font_italic" id="S6.p4.1.2">
     Level 3
    </span>
    evaluation to validate the capability of generative city agents on long term planning and decision making. We use next location prediction, PoI navigation without map, daily schedule planning, and society simulation as four representative tasks. To complete these tasks, beyond the basic ability evaluated before, agents have to master several high-level skills like spatial-temporal reasoning, multi-step goal decomposition, external tool using and so on. During the evaluation, agent is only allowed to access the API and dataset provided by City Simulator. The agents empowered by different foundation models should follow the same structure in the specific task. In each task, we provide hundreds of samples for agents to complete and the overall success rate on these samples are calculated as the final metric of it. It is noted that the definition of success rate various depending on the task. For simulation based tasks, we define the task is successfully completed when its results meet the general law in the field and various pre-defined metrics.
   </p>
  </div>
 </section>
 <section class="ltx_section" id="S7">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    7
   </span>
   Enabled Urban Applications
  </h2>
  <div class="ltx_para ltx_noindent" id="S7.p1">
   <p class="ltx_p" id="S7.p1.1">
    In this Section, we take several typical examples to discuss how our proposed UGI foundation platform enables to deal with complicated urban tasks and issues from four important urban systems of transportation, business, economy, and society.
   </p>
  </div>
  <section class="ltx_subsection" id="S7.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     7.1
    </span>
    Transportation System
   </h3>
   <div class="ltx_para ltx_noindent" id="S7.SS1.p1">
    <p class="ltx_p" id="S7.SS1.p1.1">
     Travel surveys have long been a cornerstone in transportation research, providing indispensable insights into travel behaviors and patterns. These surveys inform urban planning, infrastructure development, and transportation policy, aiding in the creation of more efficient and user-centric transport systems. However, traditional travel surveys, such as household travel surveys and on-board transit surveys, come with significant challenges. They are often expensive and time-consuming to conduct, involving face-to-face interviews, manual data collection, and extensive processing
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib134" title="">
       134
      </a>
      ]
     </cite>
     . Additionally, the data collected may not adequately capture rapid shifts in travel behavior due to its infrequent nature
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib121" title="">
       121
      </a>
      ]
     </cite>
     . Recent advancements in technology have led to the exploration of data science research in human mobility
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib59" title="">
       59
      </a>
      ]
     </cite>
     . Researchers leverage the increasingly available mobility data to identify the universal rules in human mobility
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib133" title="">
       133
      </a>
      ]
     </cite>
     , and design rule-based generator of urban mobility behaviour
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib71" title="">
       71
      </a>
      ]
     </cite>
     . This shift is significant as it promises to overcome the limitations of traditional surveys, offering real-time data collection and analysis capabilities.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S7.SS1.p2">
    <p class="ltx_p" id="S7.SS1.p2.1">
     However, the classic rule-based mobility generator model, such as TimeGeo
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib71" title="">
       71
      </a>
      ]
     </cite>
     , leverages simplified statistics rules to simulate individual movements between several frequent locations like home, work, and other. However, they lack a in-depth understanding of mobility intent and user profiles, and hence the travel behaviour they generate are not realistic. Foundation model-driven generative agents bring about important opportunities. The reasoning core of language model possesses not only robust comprehension capabilities for commonsense, but also could make high quality reasoning based on contextual information. In this paper, we describe a generative agent for physical mobility behaviour, which can generate realistic and intention-aware travel behaviour. Such generative model will provide an important opportunity for high-quality and efficient alternative for travel survey.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S7.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     7.2
    </span>
    Business Intelligence
   </h3>
   <div class="ltx_para ltx_noindent" id="S7.SS2.p1">
    <p class="ltx_p" id="S7.SS2.p1.1">
     Business site selection plays a key role in the interdisciplinary areas of urban planning, economic growth, and social development. Traditional site selection methods, often reliant on expert consultants and manual surveys, are resource-intensive and time expensive
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib21" title="">
       21
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib81" title="">
       81
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib114" title="">
       114
      </a>
      ]
     </cite>
     . In contrast, research interests have shifted towards a data-driven paradigm, employing machine learning models fed with diverse urban data to evaluate potential sites
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib73" title="">
       73
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib89" title="">
       89
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib94" title="">
       94
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib157" title="">
       157
      </a>
      ]
     </cite>
     . These models, however, often lack comprehensive feature representation and logical reasoning in their analysis
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib163" title="">
       163
      </a>
      ]
     </cite>
     . Recent advancements have introduced knowledge graphs in business site selection, integrating multifaceted data into a graph structure for enhanced knowledge representation without complex feature engineering
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib70" title="">
       70
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib96" title="">
       96
      </a>
      ]
     </cite>
     . Despite their potential, knowledge graphs face challenges in assimilating varied urban data, refining knowledge for different factors, and ensuring interpretability in decision-making.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S7.SS2.p2">
    <p class="ltx_p" id="S7.SS2.p2.1">
     Foundation models have emerged as a promising tool, capable of automating text-related tasks with extensive domain knowledge, advanced language generation abilities, and efficient data processing
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib151" title="">
       151
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib26" title="">
       26
      </a>
      ]
     </cite>
     . Their application in business site selection offers capabilities like comprehensive information retrieval and real-time decision support. However, foundation models often struggle with accurately recalling facts in knowledge-based content generation
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib160" title="">
       160
      </a>
      ]
     </cite>
     . Here, we propose to address these gaps with an integrated intelligent site selection model. It combines the structured knowledge of knowledge graphs with the reasoning and common-sense prowess of language foundation model, which is particularly enhanced for urban problems in
     <em class="ltx_emph ltx_font_italic" id="S7.SS2.p2.1.1">
      CityGPT
     </em>
     . Utilizing algorithms of reasoning on knowledge graph, this model is designed to deliver precise site selection results with enhanced decision-making quality, clear interpretations and improved efficiency and breadth. Therefore, we can leverage city foundation model to unleash the power in urban knowledge graph and various empirical data to transform business site selection.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S7.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     7.3
    </span>
    Urban Economy System
   </h3>
   <div class="ltx_para ltx_noindent" id="S7.SS3.p1">
    <p class="ltx_p" id="S7.SS3.p1.1">
     Agent-based modeling and simulation are of great importance for the research of the economy due to the limitations of other approaches.
Early empirical statistical models, such as the Phelps Model
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib113" title="">
       113
      </a>
      ]
     </cite>
     highlighted in the pioneering works of Hendry
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib64" title="">
       64
      </a>
      ]
     </cite>
     , delved into data-driven analyses of macroeconomic phenomena. These models unraveled relationships among pivotal variables. Kydland and Prescott
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib82" title="">
       82
      </a>
      ]
     </cite>
     crafted a computational model geared toward predicting policy outcomes. Later, the advent of Dynamic Stochastic General Equilibrium (DSGE) models
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib33" title="">
       33
      </a>
      ]
     </cite>
     aimed to encapsulate the dynamics of diverse economic variables like output, inflation, consumption, and investment, while accommodating the inherent uncertainty and randomness within economic processes. However, as pointed out by Farmer
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib44" title="">
       44
      </a>
      ]
     </cite>
     , these models operate under the assumption of a perfect world, which motivates agent-based modeling and simulation for the economy.
That is, the large language model-based economic simulation based on our system can be an environment to deploy various relevant applications.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S7.SS3.p2">
    <p class="ltx_p" id="S7.SS3.p2.1">
     <span class="ltx_text ltx_font_bold" id="S7.SS3.p2.1.1">
      Macroeconomic behavior.
     </span>
     This simulation offers an ideal platform to scrutinize and emulate complex macroeconomic behaviors. By leveraging the interplay of diverse agents and institutions, the model can elucidate emergent behaviors, market dynamics, and the ripple effects of economic decisions. Understanding these behaviors is crucial for forecasting economic trends and devising resilient strategies in response to varying scenarios.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S7.SS3.p3">
    <p class="ltx_p" id="S7.SS3.p3.1">
     <span class="ltx_text ltx_font_bold" id="S7.SS3.p3.1.1">
      Macroeconomic activities.
     </span>
     Through this simulation framework, the intricate landscape of macroeconomic activities can be explored comprehensively. From trade dynamics and investment patterns to consumption trends and labor market behaviors, the model provides a simulated environment to examine and evaluate diverse economic activities.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S7.SS3.p4">
    <p class="ltx_p" id="S7.SS3.p4.1">
     <span class="ltx_text ltx_font_bold" id="S7.SS3.p4.1.1">
      Policy making.
     </span>
     This simulation serves as an invaluable tool for policymakers to test and assess the efficacy of different policy interventions in a controlled environment. By simulating policy scenarios and their potential impacts on various economic indicators, policymakers can fine-tune strategies, evaluate trade-offs, and anticipate unintended consequences before implementation. This proactive approach to policymaking helps in devising robust, adaptive policies conducive to sustainable economic growth.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S7.SS3.p5">
    <p class="ltx_p" id="S7.SS3.p5.1">
     In essence, our system’s large language model-based economic simulation platform offers a versatile and robust framework for investigating, understanding, and shaping macroeconomic behavior, activities, and policy outcomes.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S7.SS4">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     7.4
    </span>
    Urban Society
   </h3>
   <div class="ltx_para ltx_noindent" id="S7.SS4.p1">
    <p class="ltx_p" id="S7.SS4.p1.1">
     Understanding our society is the core of social sciences, for which the proposal and validation of theory highly relies on social experiments. Due to the high cost of real-world social experiments, the simulation is a very promising approach.
There are two key perspectives in social simulation, as outlined by Gilbert
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib54" title="">
       54
      </a>
      ]
     </cite>
     : 1) the dynamic interaction among individuals, and 2) the status evolving of the population. By simulating social activities, both researchers and practitioners gain the ability to forecast the future progression of individual behaviors and the overall status of populations. Moreover, these simulations provide experimental arenas where interventions can be implemented and their effects observed.
The applications supported by our system and agents can be summarized as follows.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S7.SS4.p2">
    <p class="ltx_p" id="S7.SS4.p2.1">
     <span class="ltx_text ltx_font_bold" id="S7.SS4.p2.1.1">
      Understanding individual behaviors in society.
     </span>
     The simulation system, along with the LLM-driven agents, enables a deep dive into individual behaviors within social contexts. By emulating these behaviors, researchers and practitioners can forecast and comprehend how individual actions are driven by internal mechanisms and external contexts or factors.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S7.SS4.p3">
    <p class="ltx_p" id="S7.SS4.p3.1">
     <span class="ltx_text ltx_font_bold" id="S7.SS4.p3.1.1">
      Predicting population-level dynamics.
     </span>
     Beyond individual behaviors, the system facilitates the prediction of broader population dynamics. It offers insights into how collective behaviors, trends, and group interactions evolve over time, aiding in anticipating societal shifts and trends.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S7.SS4.p4">
    <p class="ltx_p" id="S7.SS4.p4.1">
     <span class="ltx_text ltx_font_bold" id="S7.SS4.p4.1.1">
      Experimenting with interventions and policy evaluation.
     </span>
     The simulation serves as an experimental ground for testing interventions in simulated social environments. Researchers and practitioners can implement and study the impact of various interventions, policies, or changes within these controlled settings, providing crucial insights into potential real-world outcomes. Thus, policymakers can develop and evaluate policies in a simulated societal landscape. By testing proposed policies virtually, they can assess their potential effects and fine-tune strategies before real-world deployment.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S7.SS4.p5">
    <p class="ltx_p" id="S7.SS4.p5.1">
     <span class="ltx_text ltx_font_bold" id="S7.SS4.p5.1.1">
      Emergency and risk management.
     </span>
     In the real-world scenario, emergency-related data is always sparse, which leads to the challenge of risk prevention.
By exploring different potential outcomes based on varying parameters, the government can prepare strategies to mitigate risks and adapt to changing circumstances, supported by the simulation system and LLM-driven agents in simulated society.
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="S8">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    8
   </span>
   Discussion
  </h2>
  <div class="ltx_para ltx_noindent" id="S8.p1">
   <p class="ltx_p" id="S8.p1.1">
    We discuss the open challenges and important future research directions of urban generative intelligence platform from the following aspects.
   </p>
  </div>
  <section class="ltx_subsection" id="S8.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     8.1
    </span>
    Dive into Complicated Urban Issues
   </h3>
   <div class="ltx_para ltx_noindent" id="S8.SS1.p1">
    <p class="ltx_p" id="S8.SS1.p1.1">
     Urban environments are dynamic and multifaceted, which are increasingly confronted with a myriad of complex issues stemming from their intricate networks encompassing physical, social, economic, and environmental factors. As mentioned in the Introduction, the rapid urbanization exacerbates challenges like traffic congestion, environmental pollution, resource scarcity, and infrastructure strain, alongside socio-economic issues like social inequality and housing crises. Addressing these issues is crucial for sustainable, equitable urban development and maintaining the vitality of cities in a global context.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S8.SS1.p2">
    <p class="ltx_p" id="S8.SS1.p2.1">
     To navigate these complexities, our proposed foudation platform of Urban Generative Intelligence (UGI) can foster emergent and sophisticated urban solutions. By leveraging the multi-source urban data and creating a real urban environment for interaction beyond traditional sandboxes or virtual simulations, with the LLM-empowered embodied agents, UGI enables deep, context-aware insights, offering nuanced understandings of urban dynamics. Morevoer, UGI allows for the emergence of intelligent solutions, which is able to address complex urban issues through advanced cognitive capabilities similar to human intelligence, while with the power of computational intelligence.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S8.SS1.p3">
    <p class="ltx_p" id="S8.SS1.p3.1">
     While UGI holds promise in tackling urban complexities, several challenges necessitate further exploration. Bridging the gap between advanced technological capabilities and practical, real-world urban applications remains a crucial hurdle. This includes adapting UGI to rapidly evolving urban dynamics and policy landscapes. Moreover, there is a pressing need to develop advanced embodied agent for a more nuanced, systematic understanding of urban complexities, integrating the diverse social, economic, and environmental aspects of urban life. Additionally, adapting these solutions to the escalating challenges of rapid urbanization and climate change is vital for ensuring sustainable and resilient urban development. Addressing these problems is critical for the successful implementation and evolution of UGI, making it a truly transformative tool for urban problem-solving.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S8.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     8.2
    </span>
    Scale Up to Large City
   </h3>
   <div class="ltx_para ltx_noindent" id="S8.SS2.p1">
    <p class="ltx_p" id="S8.SS2.p1.1">
     Recent advancements in LLMs have opened new frontiers in simulating complex urban systems. Studies reveal that LLM agents, when personalized with diverse roles such as executives, engineers, and designers, can synergistically solve complex tasks like software development, making significant strides in designing, coding, testing, and documentation processes
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib115" title="">
       115
      </a>
      ]
     </cite>
     . The scalability of these simulations, introducing more varied personas, has been shown to be beneficial across various domains
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib193" title="">
       193
      </a>
      ]
     </cite>
     , which are particularly of simulating large urban systems.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S8.SS2.p2">
    <p class="ltx_p" id="S8.SS2.p2.1">
     However, simulating societies of large-scale LLM agent, reflecting the complex constraints in urban environments, faces substantial computational challenges. Research efforts are geared towards optimizing the memory footprint and operational efficiencies of these models
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib129" title="">
       129
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib4" title="">
       4
      </a>
      ]
     </cite>
     . Techniques like model compression through knowledge distillation and quantization have been proposed
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib192" title="">
       192
      </a>
      ]
     </cite>
     . Specifically, in urban simulations, batch prompting has emerged as a crucial technique, enhancing efficiency by simulating multiple agents concurrently, showing up to a 5x improvement in inference time and cost
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib32" title="">
       32
      </a>
      ]
     </cite>
     . Moreover, the MetaGPT framework, initially applied in virtual software companies, presents a promising approach for efficient multi-agent collaboration in urban simulations
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib66" title="">
       66
      </a>
      ]
     </cite>
     . Its shared message pool and subscription mechanism offer significant reductions in resource consumption. Despite these advancements, simulating expansive urban societies with LLM agents remains a formidable challenge, limiting the full potential of these simulations. Successfully simulating large-scale urban environments with LLM agents could not only enhance performance in specific tasks but also mimic emergent properties of human societies, offering insights into complex urban dynamics
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib29" title="">
       29
      </a>
      ]
     </cite>
     . Thus, achieving full-process acceleration in LLM agent simulations remains a critical, yet unresolved, task in urban science.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S8.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     8.3
    </span>
    Openness of the Environment
   </h3>
   <div class="ltx_para ltx_noindent" id="S8.SS3.p1">
    <p class="ltx_p" id="S8.SS3.p1.1">
     As a foundational platform that integrates advanced technologies such as big data, simulation, and LLMs, UGI’s capabilities are not limited to providing realistic urban environments.
With UGI’s open capabilities, users can transform their environments at will based on real cities, or even create a new city.
Specifically, users can adjust AOI, POI and other data to change the urban spatial structure, land use type, so as to change the spatial distribution of urban functions.
Based on the new urban spatial structure and functional distribution, users can use existing algorithms
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib124" title="">
       124
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib125" title="">
       125
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib169" title="">
       169
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib171" title="">
       171
      </a>
      ]
     </cite>
     to generate urban human activities under new conditions.
Users are also allowed to create human activities using their own algorithms or data sources.
Besides, the city’s road network, infrastructure networks, and even the image data, are all open and allow users to make any modifications on the copy that belongs to them.
Through the openness of the environment, we hope that UGI will not only be used to build LLM-based agents in the city, but also that it will be able to provide a full range of intelligence for the planning, design, and governance of future cities, and promote multidisciplinary paradigm innovation in the urban field.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S8.SS4">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     8.4
    </span>
    Developer Community
   </h3>
   <div class="ltx_para ltx_noindent" id="S8.SS4.p1">
    <p class="ltx_p" id="S8.SS4.p1.1">
     As a topic that integrates the latest achievements in big data, urban simulation, LLMs and other fields, the development of UGI requires the collaboration of researchers and developers in multiple fields.
This requires the establishment of a multi-disciplinary collaborative UGI developer community.
In the community, researchers in the field of big data can share their data sets, data processing methods, and data generation methods to provide high-quality data streams for UGI.
People interested in urban simulation can add new functions to the open infrastructure, improve its computing performance, and design more reasonable interfaces.
Large language model researchers can provide insights for the training of
     <span class="ltx_text ltx_font_italic" id="S8.SS4.p1.1.1">
      CityGPT
     </span>
     .
Researchers in urban-related fields, such as urban planning, traffic management, economics, etc., can build their own agents that solve domain-specific problems through programming or natural language interface.
The community will be a highly interdisciplinary community that will inspire many interesting ideas and research questions, help solve urban problems, and achieve smart and sustainable urban development.
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="S9">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    9
   </span>
   Conclusion
  </h2>
  <div class="ltx_para ltx_noindent" id="S9.p1">
   <p class="ltx_p" id="S9.p1.1">
    In conclusion, Urban Generative Intelligence (UGI) marks a significant advancement in the field of city science and urban computing, bridging the gap between cutting-edge technological capabilities and practical urban system applications. By innovatively integrating Large Language Models (LLMs) with urban data and digital twins, UGI provides a nuanced, dynamic platform for the development and deployment of embodied agents with human-level intelligence. These agents, empowered by CityGPT, are adept at addressing diverse urban challenges, offering insights and solutions across social, economic, and environmental dimensions. This foundational platform not only propels forward the field of urban science but also sets new paradigm of generative intelligence in urban space. UGI’s comprehensive approach to modeling complex urban systems heralds a new era of intelligent, sustainable, and resilient urban development, paving the way for future cities that are more adaptive and responsive to the evolving needs of their inhabitants.
   </p>
  </div>
 </section>
 <section class="ltx_bibliography" id="bib">
  <h2 class="ltx_title ltx_title_bibliography">
   References
  </h2>
  <ul class="ltx_biblist">
   <li class="ltx_bibitem" id="bib.bib1">
    <span class="ltx_tag ltx_tag_bibitem">
     [1]
    </span>
    <span class="ltx_bibblock">
     Alberto Acerbi and Joseph M Stubbersfield.
    </span>
    <span class="ltx_bibblock">
     Large language models show human-like content biases in transmission chain experiments.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib1.1.1">
      Proceedings of the National Academy of Sciences
     </span>
     , 120(44):e2313790120, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib2">
    <span class="ltx_tag ltx_tag_bibitem">
     [2]
    </span>
    <span class="ltx_bibblock">
     Michele Acuto, Susan Parnell, and Karen C Seto.
    </span>
    <span class="ltx_bibblock">
     Building a global urban science.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib2.1.1">
      Nature Sustainability
     </span>
     , 1(1):2–4, 2018.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib3">
    <span class="ltx_tag ltx_tag_bibitem">
     [3]
    </span>
    <span class="ltx_bibblock">
     Gati V Aher, Rosa I Arriaga, and Adam Tauman Kalai.
    </span>
    <span class="ltx_bibblock">
     Using large language models to simulate multiple humans and replicate human subject studies.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib3.1.1">
      International Conference on Machine Learning
     </span>
     , pages 337–371. PMLR, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib4">
    <span class="ltx_tag ltx_tag_bibitem">
     [4]
    </span>
    <span class="ltx_bibblock">
     Reza Yazdani Aminabadi, Samyam Rajbhandari, Ammar Ahmad Awan, Cheng Li, Du Li, Elton Zheng, Olatunji Ruwase, Shaden Smith, Minjia Zhang, Jeff Rasley, et al.
    </span>
    <span class="ltx_bibblock">
     Deepspeed-inference: enabling efficient inference of transformer models at unprecedented scale.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib4.1.1">
      SC22: International Conference for High Performance Computing, Networking, Storage and Analysis
     </span>
     , pages 1–15. IEEE, 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib5">
    <span class="ltx_tag ltx_tag_bibitem">
     [5]
    </span>
    <span class="ltx_bibblock">
     Gary An, Qi Mi, Joyeeta Dutta-Moscato, and Yoram Vodovotz.
    </span>
    <span class="ltx_bibblock">
     Agent-based models in translational systems biology.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib5.1.1">
      Wiley Interdisciplinary Reviews: Systems Biology and Medicine
     </span>
     , 1(2):159–171, 2009.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib6">
    <span class="ltx_tag ltx_tag_bibitem">
     [6]
    </span>
    <span class="ltx_bibblock">
     Apple.
    </span>
    <span class="ltx_bibblock">
     Apple vision, 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib7">
    <span class="ltx_tag ltx_tag_bibitem">
     [7]
    </span>
    <span class="ltx_bibblock">
     Peter Ardhianto, Yonathan Purbo Santosa, Christian Moniaga, Maya Putri Utami, Christine Dewi, Henoch Juli Christanto, Abbott Po Shun Chen, et al.
    </span>
    <span class="ltx_bibblock">
     Generative deep learning for visual animation in landscapes design.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib7.1.1">
      Scientific Programming
     </span>
     , 2023, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib8">
    <span class="ltx_tag ltx_tag_bibitem">
     [8]
    </span>
    <span class="ltx_bibblock">
     Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong Deng, Yang Fan, Wenbin Ge, Yu Han, Fei Huang, et al.
    </span>
    <span class="ltx_bibblock">
     Qwen technical report.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib8.1.1">
      arXiv preprint arXiv:2309.16609
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib9">
    <span class="ltx_tag ltx_tag_bibitem">
     [9]
    </span>
    <span class="ltx_bibblock">
     Michael Batty.
    </span>
    <span class="ltx_bibblock">
     The size, scale, and shape of cities.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib9.1.1">
      science
     </span>
     , 319(5864):769–771, 2008.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib10">
    <span class="ltx_tag ltx_tag_bibitem">
     [10]
    </span>
    <span class="ltx_bibblock">
     Michael Batty.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib10.1.1">
      The new science of cities
     </span>
     .
    </span>
    <span class="ltx_bibblock">
     MIT press, 2013.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib11">
    <span class="ltx_tag ltx_tag_bibitem">
     [11]
    </span>
    <span class="ltx_bibblock">
     Michael Batty.
    </span>
    <span class="ltx_bibblock">
     Digital twins, 2018.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib12">
    <span class="ltx_tag ltx_tag_bibitem">
     [12]
    </span>
    <span class="ltx_bibblock">
     Michael Batty and Paul A Longley.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib12.1.1">
      Fractal cities: a geometry of form and function
     </span>
     .
    </span>
    <span class="ltx_bibblock">
     Academic press, 1994.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib13">
    <span class="ltx_tag ltx_tag_bibitem">
     [13]
    </span>
    <span class="ltx_bibblock">
     Mike Batty, Paul Longley, and Stewart Fotheringham.
    </span>
    <span class="ltx_bibblock">
     Urban growth and form: scaling, fractal geometry, and diffusion-limited aggregation.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib13.1.1">
      Environment and planning A
     </span>
     , 21(11):1447–1472, 1989.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib14">
    <span class="ltx_tag ltx_tag_bibitem">
     [14]
    </span>
    <span class="ltx_bibblock">
     Jean Baudrillard.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib14.1.1">
      Simulacra and simulation
     </span>
     .
    </span>
    <span class="ltx_bibblock">
     University of Michigan press, 1994.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib15">
    <span class="ltx_tag ltx_tag_bibitem">
     [15]
    </span>
    <span class="ltx_bibblock">
     Alan R Berkowitz, Charles H Nilon, and Karen S Hollweg.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib15.1.1">
      Understanding urban ecosystems: a new frontier for science and education
     </span>
     .
    </span>
    <span class="ltx_bibblock">
     Springer Science &amp; Business Media, 2003.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib16">
    <span class="ltx_tag ltx_tag_bibitem">
     [16]
    </span>
    <span class="ltx_bibblock">
     Luís MA Bettencourt.
    </span>
    <span class="ltx_bibblock">
     The origins of scaling in cities.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib16.1.1">
      science
     </span>
     , 340(6139):1438–1441, 2013.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib17">
    <span class="ltx_tag ltx_tag_bibitem">
     [17]
    </span>
    <span class="ltx_bibblock">
     Luís MA Bettencourt.
    </span>
    <span class="ltx_bibblock">
     Introduction to urban science: evidence and theory of cities as complex systems.
    </span>
    <span class="ltx_bibblock">
     2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib18">
    <span class="ltx_tag ltx_tag_bibitem">
     [18]
    </span>
    <span class="ltx_bibblock">
     Luís MA Bettencourt, José Lobo, Dirk Helbing, Christian Kühnert, and Geoffrey B West.
    </span>
    <span class="ltx_bibblock">
     Growth, innovation, scaling, and the pace of life in cities.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib18.1.1">
      Proceedings of the national academy of sciences
     </span>
     , 104(17):7301–7306, 2007.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib19">
    <span class="ltx_tag ltx_tag_bibitem">
     [19]
    </span>
    <span class="ltx_bibblock">
     Wendong Bi, Xueqi Cheng, Bingbing Xu, Xiaoqian Sun, Li Xu, and Huawei Shen.
    </span>
    <span class="ltx_bibblock">
     Bridged-gnn: Knowledge bridge learning for effective knowledge transfer.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib19.1.1">
      arXiv preprint arXiv:2308.09499
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib20">
    <span class="ltx_tag ltx_tag_bibitem">
     [20]
    </span>
    <span class="ltx_bibblock">
     Timothy Binkley.
    </span>
    <span class="ltx_bibblock">
     The vitality of digital creation.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib20.1.1">
      The journal of aesthetics and art criticism
     </span>
     , 55(2):107–116, 1997.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib21">
    <span class="ltx_tag ltx_tag_bibitem">
     [21]
    </span>
    <span class="ltx_bibblock">
     Michael J Breheny.
    </span>
    <span class="ltx_bibblock">
     Practical methods of retail location analysis: a review.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib21.1.1">
      Store choice, store location and market analysis
     </span>
     , pages 39–86, 1988.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib22">
    <span class="ltx_tag ltx_tag_bibitem">
     [22]
    </span>
    <span class="ltx_bibblock">
     Christa Brelsford, José Lobo, Joe Hand, and Luís MA Bettencourt.
    </span>
    <span class="ltx_bibblock">
     Heterogeneity and scale of sustainable development in cities.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib22.1.1">
      Proceedings of the National Academy of Sciences
     </span>
     , 114(34):8963–8968, 2017.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib23">
    <span class="ltx_tag ltx_tag_bibitem">
     [23]
    </span>
    <span class="ltx_bibblock">
     Christa Brelsford, Taylor Martin, Joe Hand, and Luís MA Bettencourt.
    </span>
    <span class="ltx_bibblock">
     Toward cities without slums: Topology and the spatial evolution of neighborhoods.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib23.1.1">
      Science advances
     </span>
     , 4(8):eaar4644, 2018.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib24">
    <span class="ltx_tag ltx_tag_bibitem">
     [24]
    </span>
    <span class="ltx_bibblock">
     William A Brock and Cars H Hommes.
    </span>
    <span class="ltx_bibblock">
     Heterogeneous beliefs and routes to chaos in a simple asset pricing model.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib24.1.1">
      Journal of Economic dynamics and Control
     </span>
     , 22(8-9):1235–1274, 1998.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib25">
    <span class="ltx_tag ltx_tag_bibitem">
     [25]
    </span>
    <span class="ltx_bibblock">
     Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al.
    </span>
    <span class="ltx_bibblock">
     Language models are few-shot learners.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib25.1.1">
      Advances in neural information processing systems
     </span>
     , 33:1877–1901, 2020.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib26">
    <span class="ltx_tag ltx_tag_bibitem">
     [26]
    </span>
    <span class="ltx_bibblock">
     Sébastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg, et al.
    </span>
    <span class="ltx_bibblock">
     Sparks of artificial general intelligence: Early experiments with gpt-4.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib26.1.1">
      arXiv preprint arXiv:2303.12712
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib27">
    <span class="ltx_tag ltx_tag_bibitem">
     [27]
    </span>
    <span class="ltx_bibblock">
     Howard Butler, Martin Daly, Allan Doyle, Sean Gillies, Stefan Hagen, and Tim Schaub.
    </span>
    <span class="ltx_bibblock">
     The geojson format.
    </span>
    <span class="ltx_bibblock">
     Technical report, 2016.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib28">
    <span class="ltx_tag ltx_tag_bibitem">
     [28]
    </span>
    <span class="ltx_bibblock">
     Francesco Calabrese, Laura Ferrari, and Vincent D Blondel.
    </span>
    <span class="ltx_bibblock">
     Urban sensing using mobile phone network data: a survey of research.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib28.1.1">
      Acm computing surveys (csur)
     </span>
     , 47(2):1–20, 2014.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib29">
    <span class="ltx_tag ltx_tag_bibitem">
     [29]
    </span>
    <span class="ltx_bibblock">
     G Caldarelli, E Arcaute, M Barthelemy, M Batty, C Gershenson, D Helbing, S Mancuso, Y Moreno, JJ Ramasco, C Rozenblat, et al.
    </span>
    <span class="ltx_bibblock">
     The role of complexity for digital twins of cities.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib29.1.1">
      Nature Computational Science
     </span>
     , pages 1–8, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib30">
    <span class="ltx_tag ltx_tag_bibitem">
     [30]
    </span>
    <span class="ltx_bibblock">
     Andrea Capponi, Claudio Fiandrino, Burak Kantarci, Luca Foschini, Dzmitry Kliazovich, and Pascal Bouvry.
    </span>
    <span class="ltx_bibblock">
     A survey on mobile crowdsensing systems: Challenges, solutions, and opportunities.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib30.1.1">
      IEEE communications surveys &amp; tutorials
     </span>
     , 21(3):2419–2465, 2019.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib31">
    <span class="ltx_tag ltx_tag_bibitem">
     [31]
    </span>
    <span class="ltx_bibblock">
     Melvin Chen.
    </span>
    <span class="ltx_bibblock">
     The philosophy of the metaverse.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib31.1.1">
      Ethics and Information Technology
     </span>
     , 25(3):41, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib32">
    <span class="ltx_tag ltx_tag_bibitem">
     [32]
    </span>
    <span class="ltx_bibblock">
     Zhoujun Cheng, Jungo Kasai, and Tao Yu.
    </span>
    <span class="ltx_bibblock">
     Batch prompting: Efficient inference with large language model apis.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib32.1.1">
      arXiv preprint arXiv:2301.08721
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib33">
    <span class="ltx_tag ltx_tag_bibitem">
     [33]
    </span>
    <span class="ltx_bibblock">
     Lawrence J Christiano, Martin Eichenbaum, and Charles L Evans.
    </span>
    <span class="ltx_bibblock">
     Nominal rigidities and the dynamic effects of a shock to monetary policy.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib33.1.1">
      Journal of political Economy
     </span>
     , 113(1):1–45, 2005.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib34">
    <span class="ltx_tag ltx_tag_bibitem">
     [34]
    </span>
    <span class="ltx_bibblock">
     Dixuan Cui and Christos Mousas.
    </span>
    <span class="ltx_bibblock">
     Evaluating the sense of embodiment through out-of-body experience and tactile feedback.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib34.1.1">
      Proceedings of the 18th ACM SIGGRAPH International Conference on Virtual-Reality Continuum and its Applications in Industry
     </span>
     , pages 1–7, 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib35">
    <span class="ltx_tag ltx_tag_bibitem">
     [35]
    </span>
    <span class="ltx_bibblock">
     Ganqu Cui, Lifan Yuan, Ning Ding, Guanming Yao, Wei Zhu, Yuan Ni, Guotong Xie, Zhiyuan Liu, and Maosong Sun.
    </span>
    <span class="ltx_bibblock">
     Ultrafeedback: Boosting language models with high-quality feedback.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib35.1.1">
      arXiv preprint arXiv:2310.01377
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib36">
    <span class="ltx_tag ltx_tag_bibitem">
     [36]
    </span>
    <span class="ltx_bibblock">
     Cheng Deng, Tianhang Zhang, Zhongmou He, Qiyuan Chen, Yuanyuan Shi, Le Zhou, Luoyi Fu, Weinan Zhang, Xinbing Wang, Chenghu Zhou, et al.
    </span>
    <span class="ltx_bibblock">
     Learning a foundation language model for geoscience knowledge understanding and utilization.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib36.1.1">
      arXiv preprint arXiv:2306.05064
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib37">
    <span class="ltx_tag ltx_tag_bibitem">
     [37]
    </span>
    <span class="ltx_bibblock">
     Srinivas Devarakonda, Parveen Sevusu, Hongzhang Liu, Ruilin Liu, Liviu Iftode, and Badri Nath.
    </span>
    <span class="ltx_bibblock">
     Real-time air quality monitoring through mobile sensing in metropolitan areas.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib37.1.1">
      Proceedings of the 2nd ACM SIGKDD international workshop on urban computing
     </span>
     , pages 1–8, 2013.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib38">
    <span class="ltx_tag ltx_tag_bibitem">
     [38]
    </span>
    <span class="ltx_bibblock">
     Ersin Dincelli and Alper Yayla.
    </span>
    <span class="ltx_bibblock">
     Immersive virtual reality in the age of the metaverse: A hybrid-narrative review based on the technology affordance perspective.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib38.1.1">
      The Journal of Strategic Information Systems
     </span>
     , 31(2):101717, 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib39">
    <span class="ltx_tag ltx_tag_bibitem">
     [39]
    </span>
    <span class="ltx_bibblock">
     Ning Ding, Yulin Chen, Bokai Xu, Yujia Qin, Zhi Zheng, Shengding Hu, Zhiyuan Liu, Maosong Sun, and Bowen Zhou.
    </span>
    <span class="ltx_bibblock">
     Enhancing chat language models by scaling high-quality instructional conversations.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib39.1.1">
      arXiv preprint arXiv:2305.14233
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib40">
    <span class="ltx_tag ltx_tag_bibitem">
     [40]
    </span>
    <span class="ltx_bibblock">
     Danny Driess, Fei Xia, Mehdi SM Sajjadi, Corey Lynch, Aakanksha Chowdhery, Brian Ichter, Ayzaan Wahid, Jonathan Tompson, Quan Vuong, Tianhe Yu, et al.
    </span>
    <span class="ltx_bibblock">
     Palm-e: An embodied multimodal language model.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib40.1.1">
      arXiv preprint arXiv:2303.03378
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib41">
    <span class="ltx_tag ltx_tag_bibitem">
     [41]
    </span>
    <span class="ltx_bibblock">
     Sean C Duncan.
    </span>
    <span class="ltx_bibblock">
     Minecraft, beyond construction and survival.
    </span>
    <span class="ltx_bibblock">
     2011.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib42">
    <span class="ltx_tag ltx_tag_bibitem">
     [42]
    </span>
    <span class="ltx_bibblock">
     David Eppstein.
    </span>
    <span class="ltx_bibblock">
     Finding the k shortest paths.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib42.1.1">
      SIAM Journal on computing
     </span>
     , 28(2):652–673, 1998.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib43">
    <span class="ltx_tag ltx_tag_bibitem">
     [43]
    </span>
    <span class="ltx_bibblock">
     Patrick Esser, Johnathan Chiu, Parmida Atighehchian, Jonathan Granskog, and Anastasis Germanidis.
    </span>
    <span class="ltx_bibblock">
     Structure and content-guided video synthesis with diffusion models.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib43.1.1">
      Proceedings of the IEEE/CVF International Conference on Computer Vision
     </span>
     , pages 7346–7356, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib44">
    <span class="ltx_tag ltx_tag_bibitem">
     [44]
    </span>
    <span class="ltx_bibblock">
     J Doyne Farmer and Duncan Foley.
    </span>
    <span class="ltx_bibblock">
     The economy needs agent-based modelling.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib44.1.1">
      Nature
     </span>
     , 460(7256):685–686, 2009.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib45">
    <span class="ltx_tag ltx_tag_bibitem">
     [45]
    </span>
    <span class="ltx_bibblock">
     Tao Fei, Zhang Chenyuan, Qi Qinglin, and Zhang He.
    </span>
    <span class="ltx_bibblock">
     Digital twin maturity model.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib45.1.1">
      Computer Integrated Manufacturing Systems
     </span>
     , 28(5):1–20, 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib46">
    <span class="ltx_tag ltx_tag_bibitem">
     [46]
    </span>
    <span class="ltx_bibblock">
     Jie Feng, Yong Li, Chao Zhang, Funing Sun, Fanchao Meng, Ang Guo, and Depeng Jin.
    </span>
    <span class="ltx_bibblock">
     Deepmove: Predicting human mobility with attentional recurrent networks.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib46.1.1">
      Proceedings of the 2018 world wide web conference
     </span>
     , pages 1459–1468, 2018.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib47">
    <span class="ltx_tag ltx_tag_bibitem">
     [47]
    </span>
    <span class="ltx_bibblock">
     Jie Feng, Zeyu Yang, Fengli Xu, Haisu Yu, Mudan Wang, and Yong Li.
    </span>
    <span class="ltx_bibblock">
     Learning to simulate human mobility.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib47.1.1">
      Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining
     </span>
     , pages 3426–3433, 2020.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib48">
    <span class="ltx_tag ltx_tag_bibitem">
     [48]
    </span>
    <span class="ltx_bibblock">
     Ragnar Fjelland.
    </span>
    <span class="ltx_bibblock">
     Why general artificial intelligence will not be realized.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib48.1.1">
      Humanities and Social Sciences Communications
     </span>
     , 7(1):1–9, 2020.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib49">
    <span class="ltx_tag ltx_tag_bibitem">
     [49]
    </span>
    <span class="ltx_bibblock">
     Peng Fu, Yiming Zhang, Haobo Wang, Weikang Qiu, and Junbo Zhao.
    </span>
    <span class="ltx_bibblock">
     Revisiting the knowledge injection frameworks.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib49.1.1">
      arXiv preprint arXiv:2311.01150
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib50">
    <span class="ltx_tag ltx_tag_bibitem">
     [50]
    </span>
    <span class="ltx_bibblock">
     Chen Gao, Xiaochong Lan, Nian Li, Jingtao Ding, Yuan Yuan, Zhilun Zhou, Fengli Xu, and Yong Li.
    </span>
    <span class="ltx_bibblock">
     Large language models empowered agent-based modeling and simulation: A survey and prospective.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib50.1.1">
      arXiv preprint
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib51">
    <span class="ltx_tag ltx_tag_bibitem">
     [51]
    </span>
    <span class="ltx_bibblock">
     Chen Gao, Xiaochong Lan, Zhihong Lu, Jinzhu Mao, Jinghua Piao, Huandong Wang, Depeng Jin, and Yong Li.
    </span>
    <span class="ltx_bibblock">
     S3: Social-network simulation system with large language model-empowered agents.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib51.1.1">
      arXiv preprint arXiv:2307.14984
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib52">
    <span class="ltx_tag ltx_tag_bibitem">
     [52]
    </span>
    <span class="ltx_bibblock">
     John Geanakoplos.
    </span>
    <span class="ltx_bibblock">
     The leverage cycle.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib52.1.1">
      NBER macroeconomics annual
     </span>
     , 24(1):1–66, 2010.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib53">
    <span class="ltx_tag ltx_tag_bibitem">
     [53]
    </span>
    <span class="ltx_bibblock">
     Amir Ghaderi, Borhan M Sanandaji, and Faezeh Ghaderi.
    </span>
    <span class="ltx_bibblock">
     Deep forecast: Deep learning-based spatio-temporal forecasting.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib53.1.1">
      arXiv preprint arXiv:1707.08110
     </span>
     , 2017.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib54">
    <span class="ltx_tag ltx_tag_bibitem">
     [54]
    </span>
    <span class="ltx_bibblock">
     Nigel Gilbert and Klaus Troitzsch.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib54.1.1">
      Simulation for the social scientist
     </span>
     .
    </span>
    <span class="ltx_bibblock">
     McGraw-Hill Education (UK), 2005.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib55">
    <span class="ltx_tag ltx_tag_bibitem">
     [55]
    </span>
    <span class="ltx_bibblock">
     Jorge Gironás, Larry A Roesner, Lewis A Rossman, and Jennifer Davis.
    </span>
    <span class="ltx_bibblock">
     A new applications manual for the storm water management model(swmm).
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib55.1.1">
      Environmental Modelling &amp; Software
     </span>
     , 25(6):813–814, 2010.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib56">
    <span class="ltx_tag ltx_tag_bibitem">
     [56]
    </span>
    <span class="ltx_bibblock">
     Eg Su Goh, Mohd Shahrizal Sunar, and Ajune Wanis Ismail.
    </span>
    <span class="ltx_bibblock">
     3d object manipulation techniques in handheld mobile augmented reality interface: A review.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib56.1.1">
      IEEE Access
     </span>
     , 7:40581–40601, 2019.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib57">
    <span class="ltx_tag ltx_tag_bibitem">
     [57]
    </span>
    <span class="ltx_bibblock">
     Jiahui Gong, Qiaohong Yu, Tong Li, Haoqiang Liu, Jun Zhang, Hangyu Fan, Depeng Jin, and Yong Li.
    </span>
    <span class="ltx_bibblock">
     Scalable digital twin system for mobile networks with generative ai.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib57.1.1">
      Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services
     </span>
     , pages 610–611, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib58">
    <span class="ltx_tag ltx_tag_bibitem">
     [58]
    </span>
    <span class="ltx_bibblock">
     Peng Gong, Bin Chen, Xuecao Li, Han Liu, Jie Wang, Yuqi Bai, Jingming Chen, Xi Chen, Lei Fang, Shuailong Feng, et al.
    </span>
    <span class="ltx_bibblock">
     Mapping essential urban land use categories in china (euluc-china): Preliminary results for 2018.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib58.1.1">
      Science Bulletin
     </span>
     , 65(3):182–187, 2020.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib59">
    <span class="ltx_tag ltx_tag_bibitem">
     [59]
    </span>
    <span class="ltx_bibblock">
     Marta C Gonzalez, Cesar A Hidalgo, and Albert-Laszlo Barabasi.
    </span>
    <span class="ltx_bibblock">
     Understanding individual human mobility patterns.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib59.1.1">
      nature
     </span>
     , 453(7196):779–782, 2008.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib60">
    <span class="ltx_tag ltx_tag_bibitem">
     [60]
    </span>
    <span class="ltx_bibblock">
     Bin Guo, Yan Liu, Sicong Liu, Zhiwen Yu, and Xingshe Zhou.
    </span>
    <span class="ltx_bibblock">
     Crowdhmt: Crowd intelligence with the deep fusion of human, machine, and iot.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib60.1.1">
      IEEE Internet of Things Journal
     </span>
     , 9(24):24822–24842, 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib61">
    <span class="ltx_tag ltx_tag_bibitem">
     [61]
    </span>
    <span class="ltx_bibblock">
     Shengnan Guo, Youfang Lin, Ning Feng, Chao Song, and Huaiyu Wan.
    </span>
    <span class="ltx_bibblock">
     Attention based spatial-temporal graph convolutional networks for traffic flow forecasting.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib61.1.1">
      Proceedings of the AAAI conference on artificial intelligence
     </span>
     , volume 33, pages 922–929, 2019.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib62">
    <span class="ltx_tag ltx_tag_bibitem">
     [62]
    </span>
    <span class="ltx_bibblock">
     Marc D Hauser, Noam Chomsky, and W Tecumseh Fitch.
    </span>
    <span class="ltx_bibblock">
     The faculty of language: what is it, who has it, and how did it evolve?
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib62.1.1">
      science
     </span>
     , 298(5598):1569–1579, 2002.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib63">
    <span class="ltx_tag ltx_tag_bibitem">
     [63]
    </span>
    <span class="ltx_bibblock">
     Fumio Hayashi.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib63.1.1">
      Econometrics
     </span>
     .
    </span>
    <span class="ltx_bibblock">
     Princeton University Press, 2011.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib64">
    <span class="ltx_tag ltx_tag_bibitem">
     [64]
    </span>
    <span class="ltx_bibblock">
     David F Hendry and Jean-Francois Richard.
    </span>
    <span class="ltx_bibblock">
     On the formulation of empirical models in dynamic econometrics.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib64.1.1">
      Journal of Econometrics
     </span>
     , 20(1):3–33, 1982.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib65">
    <span class="ltx_tag ltx_tag_bibitem">
     [65]
    </span>
    <span class="ltx_bibblock">
     Aidan Hogan, Eva Blomqvist, Michael Cochez, Claudia d’Amato, Gerard De Melo, Claudio Gutierrez, Sabrina Kirrane, José Emilio Labra Gayo, Roberto Navigli, Sebastian Neumaier, et al.
    </span>
    <span class="ltx_bibblock">
     Knowledge graphs.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib65.1.1">
      ACM Computing Surveys (Csur)
     </span>
     , 54(4):1–37, 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib66">
    <span class="ltx_tag ltx_tag_bibitem">
     [66]
    </span>
    <span class="ltx_bibblock">
     Sirui Hong, Xiawu Zheng, Jonathan Chen, Yuheng Cheng, Ceyao Zhang, Zili Wang, Steven Ka Shing Yau, Zijuan Lin, Liyang Zhou, Chenyu Ran, et al.
    </span>
    <span class="ltx_bibblock">
     Metagpt: Meta programming for multi-agent collaborative framework.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib66.1.1">
      arXiv preprint arXiv:2308.00352
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib67">
    <span class="ltx_tag ltx_tag_bibitem">
     [67]
    </span>
    <span class="ltx_bibblock">
     Hanyao Huang, Ou Zheng, Dongdong Wang, Jiayi Yin, Zijin Wang, Shengxuan Ding, Heng Yin, Chuan Xu, Renjie Yang, Qian Zheng, et al.
    </span>
    <span class="ltx_bibblock">
     Chatgpt for shaping the future of dentistry: the potential of multi-modal large language model.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib67.1.1">
      International Journal of Oral Science
     </span>
     , 15(1):29, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib68">
    <span class="ltx_tag ltx_tag_bibitem">
     [68]
    </span>
    <span class="ltx_bibblock">
     Weixin Huang and Hao Zheng.
    </span>
    <span class="ltx_bibblock">
     Architectural drawings recognition and generation through machine learning.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib68.1.1">
      Proceedings of the 38th annual conference of the association for computer aided design in architecture, Mexico City, Mexico
     </span>
     , pages 18–20, 2018.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib69">
    <span class="ltx_tag ltx_tag_bibitem">
     [69]
    </span>
    <span class="ltx_bibblock">
     Yuzhen Huang, Yuzhuo Bai, Zhihao Zhu, Junlei Zhang, Jinghan Zhang, Tangjun Su, Junteng Liu, Chuancheng Lv, Yikai Zhang, Jiayi Lei, et al.
    </span>
    <span class="ltx_bibblock">
     C-eval: A multi-level multi-discipline chinese evaluation suite for foundation models.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib69.1.1">
      arXiv preprint arXiv:2305.08322
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib70">
    <span class="ltx_tag ltx_tag_bibitem">
     [70]
    </span>
    <span class="ltx_bibblock">
     Shaoxiong Ji, Shirui Pan, Erik Cambria, Pekka Marttinen, and S Yu Philip.
    </span>
    <span class="ltx_bibblock">
     A survey on knowledge graphs: Representation, acquisition, and applications.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib70.1.1">
      IEEE transactions on neural networks and learning systems
     </span>
     , 33(2):494–514, 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib71">
    <span class="ltx_tag ltx_tag_bibitem">
     [71]
    </span>
    <span class="ltx_bibblock">
     Shan Jiang, Yingxiang Yang, Siddharth Gupta, Daniele Veneziano, Shounak Athavale, and Marta C González.
    </span>
    <span class="ltx_bibblock">
     The timegeo modeling framework for urban mobility without travel surveys.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib71.1.1">
      Proceedings of the National Academy of Sciences
     </span>
     , 113(37):E5370–E5378, 2016.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib72">
    <span class="ltx_tag ltx_tag_bibitem">
     [72]
    </span>
    <span class="ltx_bibblock">
     Cong Jin, Fengjuan Wu, Jing Wang, Yang Liu, Zixuan Guan, and Zhe Han.
    </span>
    <span class="ltx_bibblock">
     Metamgc: a music generation framework for concerts in metaverse.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib72.1.1">
      EURASIP Journal on Audio, Speech, and Music Processing
     </span>
     , 2022(1):31, 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib73">
    <span class="ltx_tag ltx_tag_bibitem">
     [73]
    </span>
    <span class="ltx_bibblock">
     Dmytro Karamshuk, Anastasios Noulas, Salvatore Scellato, Vincenzo Nicosia, and Cecilia Mascolo.
    </span>
    <span class="ltx_bibblock">
     Geo-spotting: mining online location-based services for optimal retail store placement.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib73.1.1">
      Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining
     </span>
     , pages 793–801, 2013.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib74">
    <span class="ltx_tag ltx_tag_bibitem">
     [74]
    </span>
    <span class="ltx_bibblock">
     Zixuan Ke, Yijia Shao, Haowei Lin, Tatsuya Konishi, Gyuhak Kim, and Bing Liu.
    </span>
    <span class="ltx_bibblock">
     Continual pre-training of language models.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib74.1.1">
      The Eleventh International Conference on Learning Representations
     </span>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib75">
    <span class="ltx_tag ltx_tag_bibitem">
     [75]
    </span>
    <span class="ltx_bibblock">
     Arne Kesting, Martin Treiber, and Dirk Helbing.
    </span>
    <span class="ltx_bibblock">
     General lane-changing model mobil for car-following models.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib75.1.1">
      Transportation Research Record
     </span>
     , 1999(1):86–94, 2007.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib76">
    <span class="ltx_tag ltx_tag_bibitem">
     [76]
    </span>
    <span class="ltx_bibblock">
     Hakpyeong Kim, Heeju Choi, Hyuna Kang, Jongbaek An, Seungkeun Yeom, and Taehoon Hong.
    </span>
    <span class="ltx_bibblock">
     A systematic review of the smart energy conservation system: From smart homes to sustainable smart cities.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib76.1.1">
      Renewable and sustainable energy reviews
     </span>
     , 140:110755, 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib77">
    <span class="ltx_tag ltx_tag_bibitem">
     [77]
    </span>
    <span class="ltx_bibblock">
     Jonghyun Kim, Youngmo Jeong, Michael Stengel, Kaan Aksit, Rachel A Albert, Ben Boudaoud, Trey Greer, Joohwan Kim, Ward Lopes, Zander Majercik, et al.
    </span>
    <span class="ltx_bibblock">
     Foveated ar: dynamically-foveated augmented reality display.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib77.1.1">
      ACM Trans. Graph.
     </span>
     , 38(4):99–1, 2019.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib78">
    <span class="ltx_tag ltx_tag_bibitem">
     [78]
    </span>
    <span class="ltx_bibblock">
     Katherine A Klise, Regan Murray, and Terra Haxton.
    </span>
    <span class="ltx_bibblock">
     An overview of the water network tool for resilience (wntr).
    </span>
    <span class="ltx_bibblock">
     2018.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib79">
    <span class="ltx_tag ltx_tag_bibitem">
     [79]
    </span>
    <span class="ltx_bibblock">
     Ryota Kondo, Maki Sugimoto, Kouta Minamizawa, Takayuki Hoshi, Masahiko Inami, and Michiteru Kitazaki.
    </span>
    <span class="ltx_bibblock">
     Illusory body ownership of an invisible body interpolated between virtual hands and feet via visual-motor synchronicity.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib79.1.1">
      Scientific reports
     </span>
     , 8(1):7541, 2018.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib80">
    <span class="ltx_tag ltx_tag_bibitem">
     [80]
    </span>
    <span class="ltx_bibblock">
     Logan Kugler.
    </span>
    <span class="ltx_bibblock">
     Non-fungible tokens and the future of art.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib80.1.1">
      Commun. ACM
     </span>
     , 64(9):19–20, aug 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib81">
    <span class="ltx_tag ltx_tag_bibitem">
     [81]
    </span>
    <span class="ltx_bibblock">
     Vipin Kumar and Kiran Karande.
    </span>
    <span class="ltx_bibblock">
     The effect of retail store environment on retailer performance.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib81.1.1">
      Journal of business research
     </span>
     , 49(2):167–181, 2000.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib82">
    <span class="ltx_tag ltx_tag_bibitem">
     [82]
    </span>
    <span class="ltx_bibblock">
     Finn E Kydland and Edward C Prescott.
    </span>
    <span class="ltx_bibblock">
     Time to build and aggregate fluctuations.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib82.1.1">
      Econometrica: Journal of the Econometric Society
     </span>
     , pages 1345–1370, 1982.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib83">
    <span class="ltx_tag ltx_tag_bibitem">
     [83]
    </span>
    <span class="ltx_bibblock">
     Ariel N. Lee, Cole J. Hunter, and Nataniel Ruiz.
    </span>
    <span class="ltx_bibblock">
     Platypus: Quick, cheap, and powerful refinement of llms.
    </span>
    <span class="ltx_bibblock">
     2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib84">
    <span class="ltx_tag ltx_tag_bibitem">
     [84]
    </span>
    <span class="ltx_bibblock">
     Lik-Hang Lee, Tristan Braud, Pengyuan Zhou, Lin Wang, Dianlei Xu, Zijun Lin, Abhishek Kumar, Carlos Bermejo, and Pan Hui.
    </span>
    <span class="ltx_bibblock">
     All one needs to know about metaverse: A complete survey on technological singularity, virtual ecosystem, and research agenda.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib84.1.1">
      arXiv preprint arXiv:2110.05352
     </span>
     , 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib85">
    <span class="ltx_tag ltx_tag_bibitem">
     [85]
    </span>
    <span class="ltx_bibblock">
     Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, et al.
    </span>
    <span class="ltx_bibblock">
     Retrieval-augmented generation for knowledge-intensive nlp tasks.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib85.1.1">
      Advances in Neural Information Processing Systems
     </span>
     , 33:9459–9474, 2020.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib86">
    <span class="ltx_tag ltx_tag_bibitem">
     [86]
    </span>
    <span class="ltx_bibblock">
     Fuxian Li, Jie Feng, Huan Yan, Guangyin Jin, Fan Yang, Funing Sun, Depeng Jin, and Yong Li.
    </span>
    <span class="ltx_bibblock">
     Dynamic graph convolutional recurrent network for traffic prediction: Benchmark and solution.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib86.1.1">
      ACM Transactions on Knowledge Discovery from Data
     </span>
     , 17(1):1–21, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib87">
    <span class="ltx_tag ltx_tag_bibitem">
     [87]
    </span>
    <span class="ltx_bibblock">
     Haonan Li, Yixuan Zhang, Fajri Koto, Yifei Yang, Hai Zhao, Yeyun Gong, Nan Duan, and Timothy Baldwin.
    </span>
    <span class="ltx_bibblock">
     Cmmlu: Measuring massive multitask language understanding in chinese.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib87.1.1">
      arXiv preprint arXiv:2306.09212
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib88">
    <span class="ltx_tag ltx_tag_bibitem">
     [88]
    </span>
    <span class="ltx_bibblock">
     Nian Li, Chen Gao, Yong Li, and Qingmin Liao.
    </span>
    <span class="ltx_bibblock">
     Large language model-empowered agents for simulating macroeconomic activities.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib88.1.1">
      arXiv preprint arXiv:2310.10436
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib89">
    <span class="ltx_tag ltx_tag_bibitem">
     [89]
    </span>
    <span class="ltx_bibblock">
     Nuo Li, Bin Guo, Yan Liu, Yao Jing, Yi Ouyang, and Zhiwen Yu.
    </span>
    <span class="ltx_bibblock">
     Commercial site recommendation based on neural collaborative filtering.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib89.1.1">
      Proceedings of the 2018 ACM International Joint Conference and 2018 International Symposium on Pervasive and Ubiquitous Computing and Wearable Computers
     </span>
     , pages 138–141, 2018.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib90">
    <span class="ltx_tag ltx_tag_bibitem">
     [90]
    </span>
    <span class="ltx_bibblock">
     Quannan Li, Yu Zheng, Xing Xie, Yukun Chen, Wenyu Liu, and Wei-Ying Ma.
    </span>
    <span class="ltx_bibblock">
     Mining user similarity based on location history.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib90.1.1">
      Proceedings of the 16th ACM SIGSPATIAL international conference on Advances in geographic information systems
     </span>
     , pages 1–10, 2008.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib91">
    <span class="ltx_tag ltx_tag_bibitem">
     [91]
    </span>
    <span class="ltx_bibblock">
     Zekun Li, Wenxuan Zhou, Yao-Yi Chiang, and Muhao Chen.
    </span>
    <span class="ltx_bibblock">
     Geolm: Empowering language models for geospatially grounded language understanding.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib91.1.1">
      arXiv preprint arXiv:2310.14478
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib92">
    <span class="ltx_tag ltx_tag_bibitem">
     [92]
    </span>
    <span class="ltx_bibblock">
     Lucia Liu, Daniel Dugas, Gianluca Cesari, Roland Siegwart, and Renaud Dubé.
    </span>
    <span class="ltx_bibblock">
     Robot navigation in crowded environments using deep reinforcement learning.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib92.1.1">
      2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
     </span>
     , pages 5671–5677. IEEE, 2020.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib93">
    <span class="ltx_tag ltx_tag_bibitem">
     [93]
    </span>
    <span class="ltx_bibblock">
     Qing Liu, Cheng Chang, Hao Shen, Shasha Cheng, Xiaoyu Li, and Ran Zheng.
    </span>
    <span class="ltx_bibblock">
     Research on artificial intelligence generated audio.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib93.1.1">
      Sixth International Conference on Computer Information Science and Application Technology (CISAT 2023)
     </span>
     , volume 12800, pages 1206–1212. SPIE, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib94">
    <span class="ltx_tag ltx_tag_bibitem">
     [94]
    </span>
    <span class="ltx_bibblock">
     Yan Liu, Bin Guo, Nuo Li, Jing Zhang, Jingmin Chen, Daqing Zhang, Yinxiao Liu, Zhiwen Yu, Sizhe Zhang, and Lina Yao.
    </span>
    <span class="ltx_bibblock">
     Deepstore: An interaction-aware wide&amp;deep model for store site recommendation with attentional spatial embeddings.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib94.1.1">
      IEEE Internet of Things Journal
     </span>
     , 6(4):7319–7333, 2019.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib95">
    <span class="ltx_tag ltx_tag_bibitem">
     [95]
    </span>
    <span class="ltx_bibblock">
     Yu Liu, Jingtao Ding, Yanjie Fu, and Yong Li.
    </span>
    <span class="ltx_bibblock">
     Urbankg: An urban knowledge graph system.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib95.1.1">
      ACM Transactions on Intelligent Systems and Technology
     </span>
     , 14(4):1–25, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib96">
    <span class="ltx_tag ltx_tag_bibitem">
     [96]
    </span>
    <span class="ltx_bibblock">
     Yu Liu, Jingtao Ding, and Yong Li.
    </span>
    <span class="ltx_bibblock">
     Knowledge-driven site selection via urban knowledge graph.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib96.1.1">
      arXiv preprint arXiv:2111.00787
     </span>
     , 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib97">
    <span class="ltx_tag ltx_tag_bibitem">
     [97]
    </span>
    <span class="ltx_bibblock">
     Yin Lou, Chengyang Zhang, Yu Zheng, Xing Xie, Wei Wang, and Yan Huang.
    </span>
    <span class="ltx_bibblock">
     Map-matching for low-sampling-rate gps trajectories.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib97.1.1">
      Proceedings of the 17th ACM SIGSPATIAL international conference on advances in geographic information systems
     </span>
     , pages 352–361, 2009.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib98">
    <span class="ltx_tag ltx_tag_bibitem">
     [98]
    </span>
    <span class="ltx_bibblock">
     Zhihan Lv.
    </span>
    <span class="ltx_bibblock">
     Generative artificial intelligence in the metaverse era.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib98.1.1">
      Cognitive Robotics
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib99">
    <span class="ltx_tag ltx_tag_bibitem">
     [99]
    </span>
    <span class="ltx_bibblock">
     Larry Lyon and Robyn Driskell.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib99.1.1">
      The community in urban society
     </span>
     .
    </span>
    <span class="ltx_bibblock">
     Waveland Press, 2011.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib100">
    <span class="ltx_tag ltx_tag_bibitem">
     [100]
    </span>
    <span class="ltx_bibblock">
     Michael W Macy and Robert Willer.
    </span>
    <span class="ltx_bibblock">
     From factors to actors: Computational sociology and agent-based modeling.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib100.1.1">
      Annual review of sociology
     </span>
     , 28(1):143–166, 2002.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib101">
    <span class="ltx_tag ltx_tag_bibitem">
     [101]
    </span>
    <span class="ltx_bibblock">
     Hernán A Makse, Shlomo Havlin, and H Eugene Stanley.
    </span>
    <span class="ltx_bibblock">
     Modelling urban growth patterns.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib101.1.1">
      Nature
     </span>
     , 377(6550):608–612, 1995.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib102">
    <span class="ltx_tag ltx_tag_bibitem">
     [102]
    </span>
    <span class="ltx_bibblock">
     Patrick Mannion, Jim Duggan, and Enda Howley.
    </span>
    <span class="ltx_bibblock">
     An experimental review of reinforcement learning algorithms for adaptive traffic signal control.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib102.1.1">
      Autonomic road transport support systems
     </span>
     , pages 47–66, 2016.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib103">
    <span class="ltx_tag ltx_tag_bibitem">
     [103]
    </span>
    <span class="ltx_bibblock">
     Rohin Manvi, Samar Khanna, Gengchen Mai, Marshall Burke, David Lobell, and Stefano Ermon.
    </span>
    <span class="ltx_bibblock">
     Geollm: Extracting geospatial knowledge from large language models.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib103.1.1">
      arXiv preprint arXiv:2310.06213
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib104">
    <span class="ltx_tag ltx_tag_bibitem">
     [104]
    </span>
    <span class="ltx_bibblock">
     Adam J McLane, Christina Semeniuk, Gregory J McDermid, and Danielle J Marceau.
    </span>
    <span class="ltx_bibblock">
     The role of agent-based models in wildlife ecology and management.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib104.1.1">
      Ecological modelling
     </span>
     , 222(8):1544–1556, 2011.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib105">
    <span class="ltx_tag ltx_tag_bibitem">
     [105]
    </span>
    <span class="ltx_bibblock">
     Meta.
    </span>
    <span class="ltx_bibblock">
     Meta quest, 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib106">
    <span class="ltx_tag ltx_tag_bibitem">
     [106]
    </span>
    <span class="ltx_bibblock">
     Norzailawati Mohd Noor, Alias Abdullah, and Mazlan Hashim.
    </span>
    <span class="ltx_bibblock">
     Remote sensing uav/drones and its applications for urban areas: A review.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib106.1.1">
      IOP conference series: Earth and environmental science
     </span>
     , volume 169, page 012003. IOP Publishing, 2018.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib107">
    <span class="ltx_tag ltx_tag_bibitem">
     [107]
    </span>
    <span class="ltx_bibblock">
     Yao Mu, Qinglong Zhang, Mengkang Hu, Wenhai Wang, Mingyu Ding, Jun Jin, Bin Wang, Jifeng Dai, Yu Qiao, and Ping Luo.
    </span>
    <span class="ltx_bibblock">
     Embodiedgpt: Vision-language pre-training via embodied chain of thought.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib107.1.1">
      arXiv preprint arXiv:2305.15021
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib108">
    <span class="ltx_tag ltx_tag_bibitem">
     [108]
    </span>
    <span class="ltx_bibblock">
     Hamed Nilforoshan, Wenli Looi, Emma Pierson, Blanca Villanueva, Nic Fishman, Yiling Chen, John Sholar, Beth Redbird, David Grusky, and Jure Leskovec.
    </span>
    <span class="ltx_bibblock">
     Human mobility networks reveal increased segregation in large cities.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib108.1.1">
      Nature
     </span>
     , pages 1–7, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib109">
    <span class="ltx_tag ltx_tag_bibitem">
     [109]
    </span>
    <span class="ltx_bibblock">
     Huansheng Ning, Hang Wang, Yujia Lin, Wenxi Wang, Sahraoui Dhelim, Fadi Farha, Jianguo Ding, and Mahmoud Daneshmand.
    </span>
    <span class="ltx_bibblock">
     A survey on the metaverse: The state-of-the-art, technologies, applications, and challenges.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib109.1.1">
      IEEE Internet of Things Journal
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib110">
    <span class="ltx_tag ltx_tag_bibitem">
     [110]
    </span>
    <span class="ltx_bibblock">
     OpenAI.
    </span>
    <span class="ltx_bibblock">
     Introducing chatgpt.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">
      https://openai.com/blog/chatgpt
     </span>
     , 2022.
    </span>
    <span class="ltx_bibblock">
     (Accessed on 01/10/2023).
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib111">
    <span class="ltx_tag ltx_tag_bibitem">
     [111]
    </span>
    <span class="ltx_bibblock">
     Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al.
    </span>
    <span class="ltx_bibblock">
     Training language models to follow instructions with human feedback.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib111.1.1">
      Advances in Neural Information Processing Systems
     </span>
     , 35:27730–27744, 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib112">
    <span class="ltx_tag ltx_tag_bibitem">
     [112]
    </span>
    <span class="ltx_bibblock">
     Joon Sung Park, Joseph O’Brien, Carrie Jun Cai, Meredith Ringel Morris, Percy Liang, and Michael S Bernstein.
    </span>
    <span class="ltx_bibblock">
     Generative agents: Interactive simulacra of human behavior.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib112.1.1">
      Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology
     </span>
     , pages 1–22, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib113">
    <span class="ltx_tag ltx_tag_bibitem">
     [113]
    </span>
    <span class="ltx_bibblock">
     Edmund S Phelps.
    </span>
    <span class="ltx_bibblock">
     Phillips curves, expectations of inflation and optimal unemployment over time.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib113.1.1">
      Economica
     </span>
     , pages 254–281, 1967.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib114">
    <span class="ltx_tag ltx_tag_bibitem">
     [114]
    </span>
    <span class="ltx_bibblock">
     Nicholas A Phelps and Andrew M Wood.
    </span>
    <span class="ltx_bibblock">
     The business of location: site selection consultants and the mobilisation of knowledge in the location decision.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib114.1.1">
      Journal of Economic Geography
     </span>
     , 18(5):1023–1044, 2018.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib115">
    <span class="ltx_tag ltx_tag_bibitem">
     [115]
    </span>
    <span class="ltx_bibblock">
     Chen Qian, Xin Cong, Cheng Yang, Weize Chen, Yusheng Su, Juyuan Xu, Zhiyuan Liu, and Maosong Sun.
    </span>
    <span class="ltx_bibblock">
     Communicative agents for software development.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib115.1.1">
      arXiv preprint arXiv:2307.07924
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib116">
    <span class="ltx_tag ltx_tag_bibitem">
     [116]
    </span>
    <span class="ltx_bibblock">
     Hua Xuan Qin and Pan Hui.
    </span>
    <span class="ltx_bibblock">
     Empowering the metaverse with generative ai: Survey and future directions.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib116.1.1">
      2023 IEEE 43rd International Conference on Distributed Computing Systems Workshops (ICDCSW)
     </span>
     , pages 85–90. IEEE, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib117">
    <span class="ltx_tag ltx_tag_bibitem">
     [117]
    </span>
    <span class="ltx_bibblock">
     Rafael Rafailov, Archit Sharma, Eric Mitchell, Stefano Ermon, Christopher D Manning, and Chelsea Finn.
    </span>
    <span class="ltx_bibblock">
     Direct preference optimization: Your language model is secretly a reward model.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib117.1.1">
      arXiv preprint arXiv:2305.18290
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib118">
    <span class="ltx_tag ltx_tag_bibitem">
     [118]
    </span>
    <span class="ltx_bibblock">
     Rajib Kumar Rana, Chun Tung Chou, Salil S Kanhere, Nirupama Bulusu, and Wen Hu.
    </span>
    <span class="ltx_bibblock">
     Ear-phone: an end-to-end participatory urban noise mapping system.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib118.1.1">
      Proceedings of the 9th ACM/IEEE international conference on information processing in sensor networks
     </span>
     , pages 105–116, 2010.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib119">
    <span class="ltx_tag ltx_tag_bibitem">
     [119]
    </span>
    <span class="ltx_bibblock">
     Bushra Rashid and Mubashir Husain Rehmani.
    </span>
    <span class="ltx_bibblock">
     Applications of wireless sensor networks for urban areas: A survey.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib119.1.1">
      Journal of network and computer applications
     </span>
     , 60:192–219, 2016.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib120">
    <span class="ltx_tag ltx_tag_bibitem">
     [120]
    </span>
    <span class="ltx_bibblock">
     Jeff Rasley, Samyam Rajbhandari, Olatunji Ruwase, and Yuxiong He.
    </span>
    <span class="ltx_bibblock">
     Deepspeed: System optimizations enable training deep learning models with over 100 billion parameters.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib120.1.1">
      Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining
     </span>
     , pages 3505–3506, 2020.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib121">
    <span class="ltx_tag ltx_tag_bibitem">
     [121]
    </span>
    <span class="ltx_bibblock">
     Anthony J Richardson, Elizabeth S Ampt, and Arnim H Meyburg.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib121.1.1">
      Survey methods for transport planning
     </span>
     .
    </span>
    <span class="ltx_bibblock">
     Eucalyptus Press Melbourne, 1995.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib122">
    <span class="ltx_tag ltx_tag_bibitem">
     [122]
    </span>
    <span class="ltx_bibblock">
     Florent Robert.
    </span>
    <span class="ltx_bibblock">
     Analysing and understanding embodied interactions in virtual reality systems.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib122.1.1">
      Proceedings of the 2023 ACM International Conference on Interactive Media Experiences
     </span>
     , pages 386–389, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib123">
    <span class="ltx_tag ltx_tag_bibitem">
     [123]
    </span>
    <span class="ltx_bibblock">
     Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Björn Ommer.
    </span>
    <span class="ltx_bibblock">
     High-resolution image synthesis with latent diffusion models.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib123.1.1">
      Proceedings of the IEEE/CVF conference on computer vision and pattern recognition
     </span>
     , pages 10684–10695, 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib124">
    <span class="ltx_tag ltx_tag_bibitem">
     [124]
    </span>
    <span class="ltx_bibblock">
     Can Rong, Jingtao Ding, and Yong Li.
    </span>
    <span class="ltx_bibblock">
     An interdisciplinary survey on origin-destination flows modeling: Theory and techniques.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib124.1.1">
      arXiv preprint arXiv:2306.10048
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib125">
    <span class="ltx_tag ltx_tag_bibitem">
     [125]
    </span>
    <span class="ltx_bibblock">
     Can Rong, Jingtao Ding, Zhicheng Liu, and Yong Li.
    </span>
    <span class="ltx_bibblock">
     Complexity-aware large scale origin-destination network generation via diffusion model.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib125.1.1">
      arXiv preprint arXiv:2306.04873
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib126">
    <span class="ltx_tag ltx_tag_bibitem">
     [126]
    </span>
    <span class="ltx_bibblock">
     Francesco Salamone, Massimiliano Masullo, and Sergio Sibilio.
    </span>
    <span class="ltx_bibblock">
     Wearable devices for environmental monitoring in the built environment: a systematic review.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib126.1.1">
      Sensors
     </span>
     , 21(14):4727, 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib127">
    <span class="ltx_tag ltx_tag_bibitem">
     [127]
    </span>
    <span class="ltx_bibblock">
     Thomas C Schelling.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib127.1.1">
      Micromotives and macrobehavior
     </span>
     .
    </span>
    <span class="ltx_bibblock">
     WW Norton &amp; Company, 2006.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib128">
    <span class="ltx_tag ltx_tag_bibitem">
     [128]
    </span>
    <span class="ltx_bibblock">
     Markus Schläpfer, Luís MA Bettencourt, Sébastian Grauwin, Mathias Raschke, Rob Claxton, Zbigniew Smoreda, Geoffrey B West, and Carlo Ratti.
    </span>
    <span class="ltx_bibblock">
     The scaling of human interactions with city size.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib128.1.1">
      Journal of the Royal Society Interface
     </span>
     , 11(98):20130789, 2014.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib129">
    <span class="ltx_tag ltx_tag_bibitem">
     [129]
    </span>
    <span class="ltx_bibblock">
     Ying Sheng, Lianmin Zheng, Binhang Yuan, Zhuohan Li, Max Ryabinin, Daniel Y Fu, Zhiqiang Xie, Beidi Chen, Clark Barrett, Joseph E Gonzalez, et al.
    </span>
    <span class="ltx_bibblock">
     High-throughput generative inference of large language models with a single gpu.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib129.1.1">
      arXiv preprint arXiv:2303.06865
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib130">
    <span class="ltx_tag ltx_tag_bibitem">
     [130]
    </span>
    <span class="ltx_bibblock">
     Mohit Shridhar, Xingdi Yuan, Marc-Alexandre Côté, Yonatan Bisk, Adam Trischler, and Matthew Hausknecht.
    </span>
    <span class="ltx_bibblock">
     ALFWorld: Aligning Text and Embodied Environments for Interactive Learning.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib130.1.1">
      Proceedings of the International Conference on Learning Representations (ICLR)
     </span>
     , 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib131">
    <span class="ltx_tag ltx_tag_bibitem">
     [131]
    </span>
    <span class="ltx_bibblock">
     Andrew Silva, Matthew Gombolay, Taylor Killian, Ivan Jimenez, and Sung-Hyun Son.
    </span>
    <span class="ltx_bibblock">
     Optimization methods for interpretable differentiable decision trees applied to reinforcement learning.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib131.1.1">
      International conference on artificial intelligence and statistics
     </span>
     , pages 1855–1865. PMLR, 2020.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib132">
    <span class="ltx_tag ltx_tag_bibitem">
     [132]
    </span>
    <span class="ltx_bibblock">
     Frank Smets and Raf Wouters.
    </span>
    <span class="ltx_bibblock">
     An estimated dynamic stochastic general equilibrium model of the euro area.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib132.1.1">
      Journal of the European economic association
     </span>
     , 1(5):1123–1175, 2003.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib133">
    <span class="ltx_tag ltx_tag_bibitem">
     [133]
    </span>
    <span class="ltx_bibblock">
     Chaoming Song, Tal Koren, Pu Wang, and Albert-László Barabási.
    </span>
    <span class="ltx_bibblock">
     Modelling the scaling properties of human mobility.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib133.1.1">
      Nature physics
     </span>
     , 6(10):818–823, 2010.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib134">
    <span class="ltx_tag ltx_tag_bibitem">
     [134]
    </span>
    <span class="ltx_bibblock">
     Peter Stopher.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib134.1.1">
      Collecting, managing, and assessing data using sample surveys
     </span>
     .
    </span>
    <span class="ltx_bibblock">
     Cambridge University Press, 2012.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib135">
    <span class="ltx_tag ltx_tag_bibitem">
     [135]
    </span>
    <span class="ltx_bibblock">
     Yu Sun, Shuohuan Wang, Shikun Feng, Siyu Ding, Chao Pang, Junyuan Shang, Jiaxiang Liu, Xuyi Chen, Yanbin Zhao, Yuxiang Lu, et al.
    </span>
    <span class="ltx_bibblock">
     Ernie 3.0: Large-scale knowledge enhanced pre-training for language understanding and generation.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib135.1.1">
      arXiv preprint arXiv:2107.02137
     </span>
     , 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib136">
    <span class="ltx_tag ltx_tag_bibitem">
     [136]
    </span>
    <span class="ltx_bibblock">
     Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, and Tatsunori B. Hashimoto.
    </span>
    <span class="ltx_bibblock">
     Stanford alpaca: An instruction-following llama model.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">
      https://github.com/tatsu-lab/stanford_alpaca
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib137">
    <span class="ltx_tag ltx_tag_bibitem">
     [137]
    </span>
    <span class="ltx_bibblock">
     Andrew J Tatem.
    </span>
    <span class="ltx_bibblock">
     Worldpop, open data for spatial demography.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib137.1.1">
      Scientific data
     </span>
     , 4(1):1–4, 2017.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib138">
    <span class="ltx_tag ltx_tag_bibitem">
     [138]
    </span>
    <span class="ltx_bibblock">
     Leigh Tesfatsion and Kenneth L Judd.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib138.1.1">
      Handbook of computational economics: agent-based computational economics
     </span>
     .
    </span>
    <span class="ltx_bibblock">
     Elsevier, 2006.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib139">
    <span class="ltx_tag ltx_tag_bibitem">
     [139]
    </span>
    <span class="ltx_bibblock">
     Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al.
    </span>
    <span class="ltx_bibblock">
     Llama 2: Open foundation and fine-tuned chat models.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib139.1.1">
      arXiv preprint arXiv:2307.09288
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib140">
    <span class="ltx_tag ltx_tag_bibitem">
     [140]
    </span>
    <span class="ltx_bibblock">
     Martin Treiber, Ansgar Hennecke, and Dirk Helbing.
    </span>
    <span class="ltx_bibblock">
     Congested traffic states in empirical observations and microscopic simulations.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib140.1.1">
      Physical review E
     </span>
     , 62(2):1805, 2000.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib141">
    <span class="ltx_tag ltx_tag_bibitem">
     [141]
    </span>
    <span class="ltx_bibblock">
     Leandro von Werra, Younes Belkada, Lewis Tunstall, Edward Beeching, Tristan Thrush, Nathan Lambert, and Shengyi Huang.
    </span>
    <span class="ltx_bibblock">
     Trl: Transformer reinforcement learning.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">
      https://github.com/huggingface/trl
     </span>
     , 2020.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib142">
    <span class="ltx_tag ltx_tag_bibitem">
     [142]
    </span>
    <span class="ltx_bibblock">
     Dong Wang, Junbo Zhang, Wei Cao, Jian Li, and Yu Zheng.
    </span>
    <span class="ltx_bibblock">
     When will you arrive? estimating travel time based on deep neural networks.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib142.1.1">
      Proceedings of the AAAI Conference on Artificial Intelligence
     </span>
     , volume 32, 2018.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib143">
    <span class="ltx_tag ltx_tag_bibitem">
     [143]
    </span>
    <span class="ltx_bibblock">
     Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu, Linxi Fan, and Anima Anandkumar.
    </span>
    <span class="ltx_bibblock">
     Voyager: An open-ended embodied agent with large language models.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib143.1.1">
      arXiv preprint arXiv:2305.16291
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib144">
    <span class="ltx_tag ltx_tag_bibitem">
     [144]
    </span>
    <span class="ltx_bibblock">
     Jindong Wang, Xixu Hu, Wenxin Hou, Hao Chen, Runkai Zheng, Yidong Wang, Linyi Yang, Haojun Huang, Wei Ye, Xiubo Geng, et al.
    </span>
    <span class="ltx_bibblock">
     On the robustness of chatgpt: An adversarial and out-of-distribution perspective.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib144.1.1">
      arXiv preprint arXiv:2302.12095
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib145">
    <span class="ltx_tag ltx_tag_bibitem">
     [145]
    </span>
    <span class="ltx_bibblock">
     Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, et al.
    </span>
    <span class="ltx_bibblock">
     A survey on large language model based autonomous agents.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib145.1.1">
      arXiv preprint arXiv:2308.11432
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib146">
    <span class="ltx_tag ltx_tag_bibitem">
     [146]
    </span>
    <span class="ltx_bibblock">
     Quan Wang, Zhendong Mao, Bin Wang, and Li Guo.
    </span>
    <span class="ltx_bibblock">
     Knowledge graph embedding: A survey of approaches and applications.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib146.1.1">
      IEEE Transactions on Knowledge and Data Engineering
     </span>
     , 29(12):2724–2743, 2017.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib147">
    <span class="ltx_tag ltx_tag_bibitem">
     [147]
    </span>
    <span class="ltx_bibblock">
     Yilun Wang, Yu Zheng, and Yexiang Xue.
    </span>
    <span class="ltx_bibblock">
     Travel time estimation of a path using sparse trajectories.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib147.1.1">
      Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining
     </span>
     , pages 25–34, 2014.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib148">
    <span class="ltx_tag ltx_tag_bibitem">
     [148]
    </span>
    <span class="ltx_bibblock">
     Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A Smith, Daniel Khashabi, and Hannaneh Hajishirzi.
    </span>
    <span class="ltx_bibblock">
     Self-instruct: Aligning language model with self generated instructions.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib148.1.1">
      arXiv preprint arXiv:2212.10560
     </span>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib149">
    <span class="ltx_tag ltx_tag_bibitem">
     [149]
    </span>
    <span class="ltx_bibblock">
     Hua Wei, Nan Xu, Huichu Zhang, Guanjie Zheng, Xinshi Zang, Chacha Chen, Weinan Zhang, Yanmin Zhu, Kai Xu, and Zhenhui Li.
    </span>
    <span class="ltx_bibblock">
     Colight: Learning network-level cooperation for traffic signal control.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib149.1.1">
      Proceedings of the 28th ACM International Conference on Information and Knowledge Management
     </span>
     , pages 1913–1922, 2019.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib150">
    <span class="ltx_tag ltx_tag_bibitem">
     [150]
    </span>
    <span class="ltx_bibblock">
     Hua Wei, Guanjie Zheng, Huaxiu Yao, and Zhenhui Li.
    </span>
    <span class="ltx_bibblock">
     Intellilight: A reinforcement learning approach for intelligent traffic light control.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib150.1.1">
      Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining
     </span>
     , pages 2496–2505, 2018.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib151">
    <span class="ltx_tag ltx_tag_bibitem">
     [151]
    </span>
    <span class="ltx_bibblock">
     Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, et al.
    </span>
    <span class="ltx_bibblock">
     Emergent abilities of large language models.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib151.1.1">
      arXiv preprint arXiv:2206.07682
     </span>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib152">
    <span class="ltx_tag ltx_tag_bibitem">
     [152]
    </span>
    <span class="ltx_bibblock">
     Margaret Wilson.
    </span>
    <span class="ltx_bibblock">
     Six views of embodied cognition.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib152.1.1">
      Psychonomic bulletin &amp; review
     </span>
     , 9:625–636, 2002.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib153">
    <span class="ltx_tag ltx_tag_bibitem">
     [153]
    </span>
    <span class="ltx_bibblock">
     Stephen Wolfram.
    </span>
    <span class="ltx_bibblock">
     Statistical mechanics of cellular automata.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib153.1.1">
      Reviews of modern physics
     </span>
     , 55(3):601, 1983.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib154">
    <span class="ltx_tag ltx_tag_bibitem">
     [154]
    </span>
    <span class="ltx_bibblock">
     Zhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding, Boyang Hong, Ming Zhang, Junzhe Wang, Senjie Jin, Enyu Zhou, et al.
    </span>
    <span class="ltx_bibblock">
     The rise and potential of large language model based agents: A survey.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib154.1.1">
      arXiv preprint arXiv:2309.07864
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib155">
    <span class="ltx_tag ltx_tag_bibitem">
     [155]
    </span>
    <span class="ltx_bibblock">
     Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Pu Zhao, Jiazhan Feng, Chongyang Tao, and Daxin Jiang.
    </span>
    <span class="ltx_bibblock">
     Wizardlm: Empowering large language models to follow complex instructions.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib155.1.1">
      arXiv preprint arXiv:2304.12244
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib156">
    <span class="ltx_tag ltx_tag_bibitem">
     [156]
    </span>
    <span class="ltx_bibblock">
     Fengli Xu, Yong Li, Depeng Jin, Jianhua Lu, and Chaoming Song.
    </span>
    <span class="ltx_bibblock">
     Emergence of urban growth patterns from human mobility behavior.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib156.1.1">
      Nature Computational Science
     </span>
     , 1(12):791–800, 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib157">
    <span class="ltx_tag ltx_tag_bibitem">
     [157]
    </span>
    <span class="ltx_bibblock">
     Mengwen Xu, Tianyi Wang, Zhengwei Wu, Jingbo Zhou, Jian Li, and Haishan Wu.
    </span>
    <span class="ltx_bibblock">
     Demand driven store site selection via multiple spatial-temporal data.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib157.1.1">
      Proceedings of the 24th acm sigspatial international conference on advances in geographic information systems
     </span>
     , pages 1–10, 2016.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib158">
    <span class="ltx_tag ltx_tag_bibitem">
     [158]
    </span>
    <span class="ltx_bibblock">
     Takahiro Yamada, Toshimitsu Tanaka, and Yuji Sagawa.
    </span>
    <span class="ltx_bibblock">
     One-handed character input method without screen cover for smart glasses that does not require visual confirmation of fingertip position.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib158.1.1">
      International Conference on Human-Computer Interaction
     </span>
     , pages 603–614. Springer, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib159">
    <span class="ltx_tag ltx_tag_bibitem">
     [159]
    </span>
    <span class="ltx_bibblock">
     Aiyuan Yang, Bin Xiao, Bingning Wang, Borong Zhang, Chao Yin, Chenxu Lv, Da Pan, Dian Wang, Dong Yan, Fan Yang, et al.
    </span>
    <span class="ltx_bibblock">
     Baichuan 2: Open large-scale language models.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib159.1.1">
      arXiv preprint arXiv:2309.10305
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib160">
    <span class="ltx_tag ltx_tag_bibitem">
     [160]
    </span>
    <span class="ltx_bibblock">
     Linyao Yang, Hongyang Chen, Zhao Li, Xiao Ding, and Xindong Wu.
    </span>
    <span class="ltx_bibblock">
     Chatgpt is not enough: Enhancing large language models with knowledge graphs for fact-aware language modeling.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib160.1.1">
      arXiv preprint arXiv:2306.11489
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib161">
    <span class="ltx_tag ltx_tag_bibitem">
     [161]
    </span>
    <span class="ltx_bibblock">
     Xiaojun X Yang.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib161.1.1">
      Urban remote sensing: monitoring, synthesis and modeling in the urban environment
     </span>
     .
    </span>
    <span class="ltx_bibblock">
     John Wiley &amp; Sons, 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib162">
    <span class="ltx_tag ltx_tag_bibitem">
     [162]
    </span>
    <span class="ltx_bibblock">
     Huaxiu Yao, Fei Wu, Jintao Ke, Xianfeng Tang, Yitian Jia, Siyu Lu, Pinghua Gong, Jieping Ye, and Zhenhui Li.
    </span>
    <span class="ltx_bibblock">
     Deep multi-view spatial-temporal network for taxi demand prediction.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib162.1.1">
      Proceedings of the AAAI conference on artificial intelligence
     </span>
     , volume 32, 2018.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib163">
    <span class="ltx_tag ltx_tag_bibitem">
     [163]
    </span>
    <span class="ltx_bibblock">
     Jeremy YL Yap, Chiung Ching Ho, and Choo-Yee Ting.
    </span>
    <span class="ltx_bibblock">
     Analytic hierarchy process (ahp) for business site selection.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib163.1.1">
      AIP Conference Proceedings
     </span>
     , volume 2016. AIP Publishing, 2018.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib164">
    <span class="ltx_tag ltx_tag_bibitem">
     [164]
    </span>
    <span class="ltx_bibblock">
     Hyejin Youn, Luís MA Bettencourt, José Lobo, Deborah Strumsky, Horacio Samaniego, and Geoffrey B West.
    </span>
    <span class="ltx_bibblock">
     Scaling and universality in urban economic diversification.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib164.1.1">
      Journal of The Royal Society Interface
     </span>
     , 13(114):20150937, 2016.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib165">
    <span class="ltx_tag ltx_tag_bibitem">
     [165]
    </span>
    <span class="ltx_bibblock">
     Biao Yuan, Zengde Deng, Na Geng, Yujie Chen, and Haoyuan Hu.
    </span>
    <span class="ltx_bibblock">
     Practice summary: Cainiao optimizes the fulfillment routes of parcels.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib165.1.1">
      INFORMS Journal on Applied Analytics
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib166">
    <span class="ltx_tag ltx_tag_bibitem">
     [166]
    </span>
    <span class="ltx_bibblock">
     Jing Yuan, Yu Zheng, and Xing Xie.
    </span>
    <span class="ltx_bibblock">
     Discovering regions of different functions in a city using human mobility and pois.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib166.1.1">
      Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining
     </span>
     , pages 186–194, 2012.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib167">
    <span class="ltx_tag ltx_tag_bibitem">
     [167]
    </span>
    <span class="ltx_bibblock">
     Jing Yuan, Yu Zheng, Chengyang Zhang, Wenlei Xie, Xing Xie, Guangzhong Sun, and Yan Huang.
    </span>
    <span class="ltx_bibblock">
     T-drive: driving directions based on taxi trajectories.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib167.1.1">
      Proceedings of the 18th SIGSPATIAL International conference on advances in geographic information systems
     </span>
     , pages 99–108, 2010.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib168">
    <span class="ltx_tag ltx_tag_bibitem">
     [168]
    </span>
    <span class="ltx_bibblock">
     Yuan Yuan, Jingtao Ding, Huandong Wang, Depeng Jin, and Yong Li.
    </span>
    <span class="ltx_bibblock">
     Activity trajectory generation via modeling spatiotemporal dynamics.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib168.1.1">
      Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining
     </span>
     , pages 4752–4762, 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib169">
    <span class="ltx_tag ltx_tag_bibitem">
     [169]
    </span>
    <span class="ltx_bibblock">
     Yuan Yuan, Jingtao Ding, Huandong Wang, Depeng Jin, and Yong Li.
    </span>
    <span class="ltx_bibblock">
     Activity trajectory generation via modeling spatiotemporal dynamics.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib169.1.1">
      Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining
     </span>
     , pages 4752–4762, 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib170">
    <span class="ltx_tag ltx_tag_bibitem">
     [170]
    </span>
    <span class="ltx_bibblock">
     Yuan Yuan, Huandong Wang, Jingtao Ding, Depeng Jin, and Yong Li.
    </span>
    <span class="ltx_bibblock">
     Learning to simulate daily activities via modeling dynamic human needs.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib170.1.1">
      arXiv preprint arXiv:2302.10897
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib171">
    <span class="ltx_tag ltx_tag_bibitem">
     [171]
    </span>
    <span class="ltx_bibblock">
     Yuan Yuan, Huandong Wang, Jingtao Ding, Depeng Jin, and Yong Li.
    </span>
    <span class="ltx_bibblock">
     Learning to simulate daily activities via modeling dynamic human needs.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib171.1.1">
      Proceedings of the ACM Web Conference 2023
     </span>
     , WWW ’23, page 906–916, New York, NY, USA, 2023. Association for Computing Machinery.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib172">
    <span class="ltx_tag ltx_tag_bibitem">
     [172]
    </span>
    <span class="ltx_bibblock">
     Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang, Hanyu Lai, Ming Ding, Zhuoyi Yang, Yifan Xu, Wendi Zheng, Xiao Xia, et al.
    </span>
    <span class="ltx_bibblock">
     Glm-130b: An open bilingual pre-trained model.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib172.1.1">
      The Eleventh International Conference on Learning Representations
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib173">
    <span class="ltx_tag ltx_tag_bibitem">
     [173]
    </span>
    <span class="ltx_bibblock">
     Guozhen Zhang, Zihan Yu, Depeng Jin, and Yong Li.
    </span>
    <span class="ltx_bibblock">
     Physics-infused machine learning for crowd simulation.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib173.1.1">
      Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining
     </span>
     , pages 2439–2449, 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib174">
    <span class="ltx_tag ltx_tag_bibitem">
     [174]
    </span>
    <span class="ltx_bibblock">
     Hongxin Zhang, Weihua Du, Jiaming Shan, Qinhong Zhou, Yilun Du, Joshua B Tenenbaum, Tianmin Shu, and Chuang Gan.
    </span>
    <span class="ltx_bibblock">
     Building cooperative embodied agents modularly with large language models.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib174.1.1">
      arXiv preprint arXiv:2307.02485
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib175">
    <span class="ltx_tag ltx_tag_bibitem">
     [175]
    </span>
    <span class="ltx_bibblock">
     Jun Zhang, Wenxuan Ao, Depeng Jin, Li Liu, and Yong Li.
    </span>
    <span class="ltx_bibblock">
     A city-level high-performance spatio-temporal mobility simulation system.
    </span>
    <span class="ltx_bibblock">
     2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib176">
    <span class="ltx_tag ltx_tag_bibitem">
     [176]
    </span>
    <span class="ltx_bibblock">
     Jun Zhang, Depeng Jin, and Yong Li.
    </span>
    <span class="ltx_bibblock">
     Mirage: an efficient and extensible city simulation framework (systems paper).
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib176.1.1">
      Proceedings of the 30th International Conference on Advances in Geographic Information Systems
     </span>
     , pages 1–4, 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib177">
    <span class="ltx_tag ltx_tag_bibitem">
     [177]
    </span>
    <span class="ltx_bibblock">
     Junbo Zhang, Yu Zheng, and Dekang Qi.
    </span>
    <span class="ltx_bibblock">
     Deep spatio-temporal residual networks for citywide crowd flows prediction.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib177.1.1">
      Proceedings of the AAAI conference on artificial intelligence
     </span>
     , volume 31, 2017.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib178">
    <span class="ltx_tag ltx_tag_bibitem">
     [178]
    </span>
    <span class="ltx_bibblock">
     Mingyang Zhang, Haohao Fu, Yong Li, and Sheng Chen.
    </span>
    <span class="ltx_bibblock">
     Understanding urban dynamics from massive mobile traffic data.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib178.1.1">
      IEEE Transactions on Big Data
     </span>
     , 5(2):266–278, 2017.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib179">
    <span class="ltx_tag ltx_tag_bibitem">
     [179]
    </span>
    <span class="ltx_bibblock">
     Siyao Zhang, Daocheng Fu, Zhao Zhang, Bin Yu, and Pinlong Cai.
    </span>
    <span class="ltx_bibblock">
     Trafficgpt: Viewing, processing and interacting with traffic foundation models.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib179.1.1">
      arXiv preprint arXiv:2309.06719
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib180">
    <span class="ltx_tag ltx_tag_bibitem">
     [180]
    </span>
    <span class="ltx_bibblock">
     Xiaotian Zhang, Chunyang Li, Yi Zong, Zhengyu Ying, Liang He, and Xipeng Qiu.
    </span>
    <span class="ltx_bibblock">
     Evaluating the performance of large language models on gaokao benchmark.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib180.1.1">
      arXiv preprint arXiv:2305.12474
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib181">
    <span class="ltx_tag ltx_tag_bibitem">
     [181]
    </span>
    <span class="ltx_bibblock">
     Yifan Zhang, Cheng Wei, Shangyou Wu, Zhengting He, and Wenhao Yu.
    </span>
    <span class="ltx_bibblock">
     Geogpt: Understanding and processing geospatial tasks through an autonomous gpt.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib181.1.1">
      arXiv preprint arXiv:2307.07930
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib182">
    <span class="ltx_tag ltx_tag_bibitem">
     [182]
    </span>
    <span class="ltx_bibblock">
     Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, et al.
    </span>
    <span class="ltx_bibblock">
     A survey of large language models.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib182.1.1">
      arXiv preprint arXiv:2303.18223
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib183">
    <span class="ltx_tag ltx_tag_bibitem">
     [183]
    </span>
    <span class="ltx_bibblock">
     Stephan Zheng, Alexander Trott, Sunil Srinivasa, David C Parkes, and Richard Socher.
    </span>
    <span class="ltx_bibblock">
     The ai economist: Taxation policy design via two-level deep multiagent reinforcement learning.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib183.1.1">
      Science advances
     </span>
     , 8(18):eabk2607, 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib184">
    <span class="ltx_tag ltx_tag_bibitem">
     [184]
    </span>
    <span class="ltx_bibblock">
     Yu Zheng, Licia Capra, Ouri Wolfson, and Hai Yang.
    </span>
    <span class="ltx_bibblock">
     Urban computing: concepts, methodologies, and applications.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib184.1.1">
      ACM Transactions on Intelligent Systems and Technology (TIST)
     </span>
     , 5(3):1–55, 2014.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib185">
    <span class="ltx_tag ltx_tag_bibitem">
     [185]
    </span>
    <span class="ltx_bibblock">
     Yu Zheng, Quannan Li, Yukun Chen, Xing Xie, and Wei-Ying Ma.
    </span>
    <span class="ltx_bibblock">
     Understanding mobility based on gps data.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib185.1.1">
      Proceedings of the 10th international conference on Ubiquitous computing
     </span>
     , pages 312–321, 2008.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib186">
    <span class="ltx_tag ltx_tag_bibitem">
     [186]
    </span>
    <span class="ltx_bibblock">
     Yu Zheng, Yuming Lin, Liang Zhao, Tinghai Wu, Depeng Jin, and Yong Li.
    </span>
    <span class="ltx_bibblock">
     Spatial planning of urban communities via deep reinforcement learning.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib186.1.1">
      Nature Computational Science
     </span>
     , pages 1–15, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib187">
    <span class="ltx_tag ltx_tag_bibitem">
     [187]
    </span>
    <span class="ltx_bibblock">
     Yu Zheng, Yanchi Liu, Jing Yuan, and Xing Xie.
    </span>
    <span class="ltx_bibblock">
     Urban computing with taxicabs.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib187.1.1">
      Proceedings of the 13th international conference on Ubiquitous computing
     </span>
     , pages 89–98, 2011.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib188">
    <span class="ltx_tag ltx_tag_bibitem">
     [188]
    </span>
    <span class="ltx_bibblock">
     Yu Zheng, Xing Xie, Wei-Ying Ma, et al.
    </span>
    <span class="ltx_bibblock">
     Geolife: A collaborative social networking service among user, location and trajectory.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib188.1.1">
      IEEE Data Eng. Bull.
     </span>
     , 33(2):32–39, 2010.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib189">
    <span class="ltx_tag ltx_tag_bibitem">
     [189]
    </span>
    <span class="ltx_bibblock">
     Yu Zheng, Lizhu Zhang, Xing Xie, and Wei-Ying Ma.
    </span>
    <span class="ltx_bibblock">
     Mining interesting locations and travel sequences from gps trajectories.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib189.1.1">
      Proceedings of the 18th international conference on World wide web
     </span>
     , pages 791–800, 2009.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib190">
    <span class="ltx_tag ltx_tag_bibitem">
     [190]
    </span>
    <span class="ltx_bibblock">
     Xuhui Zhou, Hao Zhu, Leena Mathur, Ruohong Zhang, Haofei Yu, Zhengyang Qi, Louis-Philippe Morency, Yonatan Bisk, Daniel Fried, Graham Neubig, et al.
    </span>
    <span class="ltx_bibblock">
     Sotopia: Interactive evaluation for social intelligence in language agents.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib190.1.1">
      arXiv preprint arXiv:2310.11667
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib191">
    <span class="ltx_tag ltx_tag_bibitem">
     [191]
    </span>
    <span class="ltx_bibblock">
     Yu Zhou and Chuncheng Liu.
    </span>
    <span class="ltx_bibblock">
     The logic and innovation of building digital twin city in xiong’an new area.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib191.1.1">
      Urban Development Studies
     </span>
     , 25(10):60–67, 2018.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib192">
    <span class="ltx_tag ltx_tag_bibitem">
     [192]
    </span>
    <span class="ltx_bibblock">
     Xunyu Zhu, Jian Li, Yong Liu, Can Ma, and Weiping Wang.
    </span>
    <span class="ltx_bibblock">
     A survey on model compression for large language models.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib192.1.1">
      arXiv preprint arXiv:2308.07633
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib193">
    <span class="ltx_tag ltx_tag_bibitem">
     [193]
    </span>
    <span class="ltx_bibblock">
     Mingchen Zhuge, Haozhe Liu, Francesco Faccio, Dylan R Ashley, Róbert Csordás, Anand Gopalakrishnan, Abdullah Hamdi, Hasan Abed Al Kader Hammoud, Vincent Herrmann, Kazuki Irie, et al.
    </span>
    <span class="ltx_bibblock">
     Mindstorms in natural language-based societies of mind.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib193.1.1">
      arXiv preprint arXiv:2305.17066
     </span>
     , 2023.
    </span>
   </li>
  </ul>
 </section>
</article>
