<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2407.16030] Enhancing Temporal Understanding in LLMs for Semi-structured Tables</title><meta property="og:description" content="Temporal reasoning over tabular data presents substantial challenges for large language models (LLMs), as evidenced by recent research. In this study, we conduct a comprehensive analysis of temporal datasets to pinpoin…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Enhancing Temporal Understanding in LLMs for Semi-structured Tables">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Enhancing Temporal Understanding in LLMs for Semi-structured Tables">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2407.16030">

<!--Generated on Mon Aug  5 18:11:41 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Enhancing Temporal Understanding in LLMs for Semi-structured Tables</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Irwin Deng, Kushagra Dixit , Vivek Gupta , Dan Roth 
<br class="ltx_break">University of Pennsylvania 
<br class="ltx_break"><span id="id1.1.id1" class="ltx_text ltx_font_typewriter"> {ideng, dixitk, gvivek, danroth}@seas.upenn.edu</span>
</span><span class="ltx_author_notes">  Work done during internship at UPenn.   corresponding author </span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id2.id1" class="ltx_p">Temporal reasoning over tabular data presents substantial challenges for large language models (LLMs), as evidenced by recent research. In this study, we conduct a comprehensive analysis of temporal datasets to pinpoint the specific limitations of LLMs. Our investigation leads to enhancements in TempTabQA, a dataset specifically designed for tabular temporal question answering. We provide critical insights for improving LLM performance in temporal reasoning tasks with tabular data. Furthermore, we introduce a novel approach, C.L.E.A.R to strengthen LLM capabilities in this domain. Our findings demonstrate that our method significantly improves evidence-based reasoning across various models. Additionally, our experimental results reveal that indirect supervision with auxiliary data substantially boosts model performance in these tasks. This work contributes to a deeper understanding of LLMs’ temporal reasoning abilities over tabular data and promotes advancements in their application across diverse fields.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<figure id="S1.F1" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2407.16030/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_figure_panel ltx_img_portrait" width="322" height="481" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="S1.F1.1" class="ltx_p ltx_align_left ltx_figure_panel ltx_align_center"><span id="S1.F1.1.1" class="ltx_text ltx_font_bold">Q1 :</span> How many MLB wins did Al McBean have before turning 20? A: 0 (evidence: Born, MLB statistics)
<br class="ltx_break">
<span id="S1.F1.1.2" class="ltx_text ltx_font_bold">Q2 :</span> For how many years did Al McBean play for the Pittsburgh Pirates? A: 9 (evidence: Teams)
<br class="ltx_break">
<span id="S1.F1.1.3" class="ltx_text ltx_font_bold">Q3 :</span> What was the duration of Al McBean’s Major League Baseball career? A: 10 (evidence: MLB debut, Last MLB appearance)</p>
</div>
</div>
<figcaption class="ltx_caption ltx_align_left ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>A semi-structured table of Baseball pitcher Al McBean with follow up question answers.</figcaption>
</figure>
<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Large Language Models (LLMs) have exhibited remarkable proficiency across various natural language processing tasks. However, recent investigations reveal a notable deficiency in their ability to reason effectively over <em id="S1.p1.1.1" class="ltx_emph ltx_font_italic">tabular</em> data, particularly when <em id="S1.p1.1.2" class="ltx_emph ltx_font_italic">temporal</em> relationships are involved <cite class="ltx_cite ltx_citemacro_cite">Chen (<a href="#bib.bib3" title="" class="ltx_ref">2023</a>); Sui et al. (<a href="#bib.bib42" title="" class="ltx_ref">2024</a>)</cite>. This discrepancy between model performance and human-level understanding underscores the pressing need for innovative approaches to enhance the capabilities of LLMs in this domain.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">To explore the root causes behind the limitations in reasoning about structured or semi-structured data, we conducted a thorough analysis of TempTabQA <cite class="ltx_cite ltx_citemacro_cite">Gupta et al. (<a href="#bib.bib14" title="" class="ltx_ref">2023</a>)</cite> dataset, an important and only datasets in this domain. Through meticulous examination, we identified discrepancies in model comprehension and reasoning, leading to the development of an enhanced evaluation set. Our investigation also delved into the mechanisms through which LLMs tackle temporal reasoning tasks using conventional prompting techniques, leasing in the introduction of a novel approach, C.L.E.A.R (Comprehend, Locate, Examine, Analyze, Resolve), designed to considerably enhance temporal reasoning in LLMs.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">While prompts have been instrumental in guiding models to better reason about tasks through explicit instructions, they do not <em id="S1.p3.1.1" class="ltx_emph ltx_font_italic">inherently improve</em> task understanding. In our research, we demonstrate that despite the implementation of our novel C.L.E.A.R approach, models, though improved, still overlook crucial context—such as relevant rows in tables—and suffer from data leakage, relying more on memorization rather than grounding their decisions on the evidence. Additionally, since C.L.E.A.R lacks temporal aspects in its prompt, its effectiveness is limited. This observation necessitate for more robust solutions, where model inherently improve i.e. it’s parameters changes.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">To address these challenges, we advocate for learning through fine-tuning processes. Fine tuning on temporal data can inherently improve the model’s temporal reasoning ability. We utilized the TRAM <cite class="ltx_cite ltx_citemacro_cite">Wang and Zhao (<a href="#bib.bib44" title="" class="ltx_ref">2024</a>)</cite> dataset to engage in an indirectly supervised fine-tuning process by using Auxiliary Out of Domain(OOD) data. This approach significantly improved model <em id="S1.p4.1.1" class="ltx_emph ltx_font_italic">cross-generalization</em> performance on temporal questions on tabular data. Our findings indicate that combining our novel C.L.E.A.R prompting approach with fine-tuning on the TempTabQA test-set yields optimal results. This combination effectively addresses the limitations in LLMs’ temporal reasoning capabilities, paving the way for future advancements in the field. In summary, this paper advances the understanding and enhancement of Large Language Models’ (LLMs) abilities to reason about temporal relationships in tabular data. Our key contributions are as follows:</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">We conducted a thorough analysis of the TempTabQA test set to assess the limitations of current approaches. This analysis also led to an improved test set, enhancing the evaluation of models in temporal tabular reasoning.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">We introduce an novel approach, C.L.E.A.R (Comprehend, Locate, Examine, Analyze, Resolve), designed to significantly enhance temporal reasoning capabilities in LLMs for tabular data. Our approach grounds models in evidence, thus reducing memorization.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">Through indirect supervision technique a.k.a. auxiliary task training, we inherently improve model performance. Fine-tuning models with the auxiliary TRAM dataset leads to substantial enhancements in handling temporal questions on tabular data.</p>
</div>
</li>
</ul>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">These contributions greatly enhance LLMs’ temporal reasoning capabilities, paving the way for future research and applications in temporal reasoning over tabular data. <em id="S1.p5.1.1" class="ltx_emph ltx_font_italic">Our code and enhanced evaluation set will be released for public use.</em></p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Temporal Reasoning on Tables</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">Tables organize and record diverse types of information, making them useful for studying an entity’s timeline. They provide a chronological sequence of events, facilitating the analysis of the progression of positions, marital status changes, and awards, thereby serving as reliable sources for temporal reasoning. Entity-centric tables, like Wikipedia Infoboxes, significantly differ from unstructured data and fully structured data (e.g., SQL tables and knowledge graphs).</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">Recent studies show that Large Language Models (LLMs) struggle with reasoning over tabular data, especially concerning temporal aspects. Various datasets have been used to explore LLMs’ understanding of tabular data, including TempTabQA <cite class="ltx_cite ltx_citemacro_cite">Gupta et al. (<a href="#bib.bib14" title="" class="ltx_ref">2023</a>)</cite>, Table2vec <cite class="ltx_cite ltx_citemacro_cite">Zhang et al. (<a href="#bib.bib52" title="" class="ltx_ref">2019</a>)</cite>, TAPAS <cite class="ltx_cite ltx_citemacro_cite">Herzig et al. (<a href="#bib.bib16" title="" class="ltx_ref">2020</a>)</cite>, TaBERT <cite class="ltx_cite ltx_citemacro_cite">Yin et al. (<a href="#bib.bib47" title="" class="ltx_ref">2020</a>)</cite>, TabStruc <cite class="ltx_cite ltx_citemacro_cite">Zhang et al. (<a href="#bib.bib51" title="" class="ltx_ref">2020a</a>)</cite>, TABBIE <cite class="ltx_cite ltx_citemacro_cite">Iida et al. (<a href="#bib.bib17" title="" class="ltx_ref">2021</a>)</cite>, TabGCN <cite class="ltx_cite ltx_citemacro_cite">Pramanick and Bhattacharya (<a href="#bib.bib37" title="" class="ltx_ref">2021</a>)</cite>, and RCI <cite class="ltx_cite ltx_citemacro_cite">Glass et al. (<a href="#bib.bib12" title="" class="ltx_ref">2021</a>)</cite>. These datasets provide various contexts and challenges, aiding in the development and evaluation of models for tabular data processing.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">Among these datasets, we focus on TempTabQA, a recent and prominent dataset for temporal reasoning over tabular data. TempTabQA features temporal question-answer pairs derived from Wikipedia Infobox tables and is notable for its two distinct eval sets: the "Head" set, with pairs from popular and frequent domains, and the "Tail" set, with pairs from less common and rare domains. The eval sets include approximately 2,900 question-answer pairs, with around 1,900 in the "Head" set and 1,000 in the "Tail" set. This bifurcation enables comprehensive evaluation, assessing models’ performance across both frequent and rare domains.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Where do LLMs Fails?</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">We used Chain of Thought prompting with GPT-3.5 to analyze the TempTabQA test set and evaluate current models’ performance and limitations. Out of 1,038 examples, 339 were incorrect responses. Of these, 159 errors were due to data issues, while 180 were due to model limitations. These errors fall into the following categories:</p>
</div>
<div id="S3.p2" class="ltx_para ltx_noindent">
<p id="S3.p2.1" class="ltx_p"><span id="S3.p2.1.1" class="ltx_text ltx_font_bold">1. Tabular Data Issues (75 examples):</span> These errors were related to hallucinations, incomplete evidence extraction, missing evidence, or incorrect information extraction.</p>
</div>
<div id="S3.p3" class="ltx_para ltx_noindent">
<p id="S3.p3.1" class="ltx_p"><span id="S3.p3.1.1" class="ltx_text ltx_font_bold">2. Temporal Calculation Errors (84 examples):</span> These involved difficulties with calculations related to time, such as determining age, calculating the time between dates in different months, or assessing whether a value fell within a specified range.</p>
</div>
<div id="S3.p4" class="ltx_para ltx_noindent">
<p id="S3.p4.1" class="ltx_p"><span id="S3.p4.1.1" class="ltx_text ltx_font_bold">3. Other Errors (31 examples):</span> This category included errors stemming from common-sense reasoning, arithmetic, and other miscellaneous issues.</p>
</div>
<div id="S3.p5" class="ltx_para">
<p id="S3.p5.1" class="ltx_p">Our observations indicate that even with Chain of Thought reasoning, models generate incorrect responses consistently. The models not only produce incorrect answers but also exhibit hallucinations, struggling with temporal calculations and common-sense reasoning. This emphasizes the need for enhance models performance in this domain. The 159 data-related issues fall into these categories:</p>
</div>
<div id="S3.p6" class="ltx_para ltx_noindent">
<p id="S3.p6.1" class="ltx_p"><span id="S3.p6.1.1" class="ltx_text ltx_font_bold">1. Tables Requiring External Knowledge to Answer (75 examples):</span> These questions could not be answered correctly without additional information not present in the table, indicating a gap in the information provided in the context.</p>
</div>
<div id="S3.p7" class="ltx_para ltx_noindent">
<p id="S3.p7.1" class="ltx_p"><span id="S3.p7.1.1" class="ltx_text ltx_font_bold">2. Wrong Human Annotation or Multiple Correct Answers (42 examples):</span> These instances involved incorrect annotations by humans or questions that had multiple valid answers, but the annotations provided only one correct answer.</p>
</div>
<div id="S3.p8" class="ltx_para ltx_noindent">
<p id="S3.p8.1" class="ltx_p"><span id="S3.p8.1.1" class="ltx_text ltx_font_bold">3. Ambiguous or Incomplete Questions (14 examples):</span> These questions are either vague or lacked sufficient detail required for correct answer.</p>
</div>
<div id="S3.p9" class="ltx_para ltx_noindent">
<p id="S3.p9.1" class="ltx_p"><span id="S3.p9.1.1" class="ltx_text ltx_font_bold">4. Other Issues (28 examples):</span> This category included various problems such as questions relying on images within the HTML table or missing rows in the JSON table etc.</p>
</div>
<div id="S3.p10" class="ltx_para">
<p id="S3.p10.1" class="ltx_p">Through our analysis, we addressed all these categories of errors and created a new evaluation set designed to better assess model performance. This refined dataset eliminates the noise caused by the aforementioned issues, providing a more accurate benchmark for evaluating model capabilities. In this paper, when evaluating a model’s performance, we primarily use the model’s accuracy on the full test dataset as a basis for comparison, unless otherwise stated. This approach ensures consistency and allows for a clear assessment of improvements made through the new evaluation set.</p>
</div>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Methodology</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">Improving the temporal reasoning capabilities of Large Language Models is crucial for enhancing their performance on tasks involving time-based data. Current models often struggle with accurately interpreting and reasoning about temporal information. This limitation reduces their effectiveness in real-world applications.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.1" class="ltx_p">Our analysis revealed several key areas where current models underperform in reasoning over tabular data, especially in temporal contexts. To address these challenges, we explored two approaches. First, we developed a novel method called C.L.E.A.R (Comprehend, Locate, Examine, Analyze, Resolve). This method was inspired by our detailed examination of the TempTabQA test set. C.L.E.A.R instructs models specifically for tabular data reasoning tasks. It employs advanced prompting techniques to guide models more effectively, aiming to reduce errors and enhance accuracy in temporal question answering. Secondly, we fine-tuned models using auxiliary temporal data from unrelated domains to enhance cross-generalization. This approach boosts temporal understanding on complex temporal tasks.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>C.L.E.A.R Prompting</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">In this section, we introduce the C.L.E.A.R (Comprehend, Locate, Examine, Analyze, Resolve) technique, designed to enhance temporal reasoning over semi-structured data. C.L.E.A.R is a structured, step-by-step approach that guides the process of understanding, identifying, examining, analyzing, and resolving questions involving temporal reasoning. It ensures a comprehensive and logical extraction of information from tables (refer Fig. <a href="#A1.F2" title="Figure 2 ‣ Appendix A Appendix ‣ Enhancing Temporal Understanding in LLMs for Semi-structured Tables" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>).</p>
</div>
<div id="S4.SS1.p2" class="ltx_para ltx_noindent">
<p id="S4.SS1.p2.1" class="ltx_p"><span id="S4.SS1.p2.1.1" class="ltx_text ltx_font_bold">(a.) Comprehend:</span> The first step, Comprehend, involves applying domain knowledge to understand the given question. For example, if the question pertains to calculating time differences, it is essential to recognize that this involves subtracting the earlier year from the later year. This step ensures the correct interpretation of the question and sets the foundation for correct structural solution analysis.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para ltx_noindent">
<p id="S4.SS1.p3.1" class="ltx_p"><span id="S4.SS1.p3.1.1" class="ltx_text ltx_font_bold">(b.) Locate:</span> The Locate step focuses on identifying and extracting the relevant rows from the table that directly pertain to the question. This involves explaining the rationale behind the selection of these rows to provide transparency and clarity. For instance, if the question asks for events between specific years, only the rows corresponding to those years should be selected. The output of this step includes listing the relevant rows on new lines for clarity and ease of reference.</p>
</div>
<div id="S4.SS1.p4" class="ltx_para ltx_noindent">
<p id="S4.SS1.p4.1" class="ltx_p"><span id="S4.SS1.p4.1.1" class="ltx_text ltx_font_bold">(c.) Examine:</span> In the Examine phase, the main question is broken down into smaller, more manageable sub-questions. Each sub-question aims at extracting a specific piece of information from the table that is necessary to answer the main question. This decomposition allows for a systematic approach to solving the question, ensuring that no critical piece of information is overlooked.</p>
</div>
<div id="S4.SS1.p5" class="ltx_para ltx_noindent">
<p id="S4.SS1.p5.1" class="ltx_p"><span id="S4.SS1.p5.1.1" class="ltx_text ltx_font_bold">(d.) Analyze:</span> The Analyze step is multifaceted, involving several sub-steps:</p>
</div>
<div id="S4.SS1.p6" class="ltx_para">
<ol id="S4.I1" class="ltx_enumerate">
<li id="S4.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S4.I1.i1.p1" class="ltx_para">
<p id="S4.I1.i1.p1.1" class="ltx_p"><span id="S4.I1.i1.p1.1.1" class="ltx_text ltx_font_italic">Mark Evidence for Each Sub-Question: </span>For each sub-question, identify the specific evidence from the table that will be used to answer it. Explain the relevance of this evidence to the sub-question in detail.</p>
</div>
</li>
<li id="S4.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S4.I1.i2.p1" class="ltx_para">
<p id="S4.I1.i2.p1.1" class="ltx_p"><span id="S4.I1.i2.p1.1.1" class="ltx_text ltx_font_italic">Determine Dependencies:</span> This sub-step assesses whether the answer to a sub-question depends on information from previous sub-questions. If dependencies exist, they are stated to maintain logical coherence.</p>
</div>
</li>
<li id="S4.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S4.I1.i3.p1" class="ltx_para">
<p id="S4.I1.i3.p1.1" class="ltx_p"><span id="S4.I1.i3.p1.1.1" class="ltx_text ltx_font_italic">Reasoning for Each Sub-Question:</span> A logical explanation is provided for how the evidence leads to the answer for each sub-question. This includes detailed reasoning for transparency and to support the answer’s validity.</p>
</div>
</li>
</ol>
</div>
<div id="S4.SS1.p7" class="ltx_para ltx_noindent">
<p id="S4.SS1.p7.1" class="ltx_p"><span id="S4.SS1.p7.1.1" class="ltx_text ltx_font_bold">(e.) Resolve:</span> The final step, Resolve, involves combining and applying the answers from the sub-questions to formulate the final answer to the main question. This step includes explaining the reasoning process leading to the final answer, which may involve necessary calculations or logical deductions. This synthesis ensures the final answer is well-supported and logically derived from evidence gathered in preceding steps. Refer Figure <a href="#A1.F3" title="Figure 3 ‣ Appendix A Appendix ‣ Enhancing Temporal Understanding in LLMs for Semi-structured Tables" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> in Appendix <a href="#A1" title="Appendix A Appendix ‣ Enhancing Temporal Understanding in LLMs for Semi-structured Tables" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A</span></a> for step-by-step process of C.L.E.A.R.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Fine Tuning with Auxiliary Data</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">Fine-tuning models can significantly boost their capabilities by adjusting parameters through training on task-specific examples. In this section, we demonstrate how models’ temporal reasoning can be enhanced inherently, not only through fine-tuning on specific data but also by integrating auxiliary data sources.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">Auxiliary data, such as temporal unstructured data, does not directly relate to the main task but contains relevant logical structures and principles. This type of data enhances the model’s understanding of underlying logic, improving the overall performance. The TRAM dataset, illustrated in Figure <a href="#A1.T5" title="Table 5 ‣ Appendix A Appendix ‣ Enhancing Temporal Understanding in LLMs for Semi-structured Tables" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> in Appendix <a href="#A1" title="Appendix A Appendix ‣ Enhancing Temporal Understanding in LLMs for Semi-structured Tables" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A</span></a>, serves as an auxiliary source to boost model performance. It includes temporal questions that aid the model in grasping temporal relationships across diverse contexts.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.1" class="ltx_p">The TRAM dataset, though unrelated to tabular data temporal reasoning, enhances model temporal reasoning skills. Exposing the model to diverse temporal questions improves its ability to handle temporal relationships, boosting performance. This approach shows leveraging auxiliary data can effectively address temporal reasoning complexities and enhance model robustness in diverse scenarios.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Experimental Setup</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p"><span id="S5.p1.1.1" class="ltx_text ltx_font_bold">Models:</span> In this paper, we experimented with several state-of-the-art large language models (LLMs), including GPT-3.5-Turbo, GPT-4, PaLM-2, Mistral-2-7B, LLaMA-2-7B-chat, and Gemini 1.5 Pro Flash. These models represent the forefront in both open-source and closed-model applications, showcasing advancements in natural language understanding and generation capabilities.</p>
</div>
<div id="S5.p2" class="ltx_para ltx_noindent">
<p id="S5.p2.1" class="ltx_p"><span id="S5.p2.1.1" class="ltx_text ltx_font_bold">Prompts:</span> Prompting models with detailed instructions enhances their understanding of tasks, leading to improved responses. These prompts may include demonstrations for the model’s reference. We explore the following prompting techniques:</p>
</div>
<div id="S5.p3" class="ltx_para ltx_noindent">
<p id="S5.p3.1" class="ltx_p"><span id="S5.p3.1.1" class="ltx_text ltx_font_bold">- Chain of Thought (CoT) <cite class="ltx_cite ltx_citemacro_cite">Wei et al. (<a href="#bib.bib45" title="" class="ltx_ref">2023</a>)</cite>:</span> CoT prompts guide the model through a series of interconnected thoughts or reasoning steps, encouraging coherent and structured responses. We apply CoT in both zero-shot (Z.S) and few-shot (F.S) settings to evaluate its impact on model performance.</p>
</div>
<div id="S5.p4" class="ltx_para ltx_noindent">
<p id="S5.p4.1" class="ltx_p"><span id="S5.p4.1.1" class="ltx_text ltx_font_bold">- Faithful Chain of Thought (F-CoT) <cite class="ltx_cite ltx_citemacro_cite">Lyu et al. (<a href="#bib.bib27" title="" class="ltx_ref">2023</a>)</cite>:</span> F-CoT extends CoT by emphasizing fidelity to the initial prompt throughout response generation to maintain consistency and accuracy in model outputs. We apply F-CoT in both zero-shot and few-shot scenarios to evaluate its effectiveness.</p>
</div>
<div id="S5.p5" class="ltx_para ltx_noindent">
<p id="S5.p5.1" class="ltx_p"><span id="S5.p5.1.1" class="ltx_text ltx_font_bold">- Program of Thought (PoT) <cite class="ltx_cite ltx_citemacro_cite">Chen et al. (<a href="#bib.bib6" title="" class="ltx_ref">2023</a>)</cite>:</span> PoT provides the model with a predefined sequence of operations, akin to a program, to generate structured and task-specific responses. Like CoT and F-CoT, PoT is evaluated in zero-shot and few-shot contexts to enhance model performance.</p>
</div>
<div id="S5.p6" class="ltx_para ltx_noindent">
<p id="S5.p6.1" class="ltx_p"><span id="S5.p6.1.1" class="ltx_text ltx_font_bold">Auxiliary Data:</span> In our experiments, we utilize several unstructured temporal reasoning datasets to assess the temporal reasoning capabilities of language models:</p>
</div>
<div id="S5.p7" class="ltx_para ltx_noindent">
<p id="S5.p7.1" class="ltx_p"><span id="S5.p7.1.1" class="ltx_text ltx_font_bold">- DATE Understanding <cite class="ltx_cite ltx_citemacro_cite">Srivastava et al. (<a href="#bib.bib40" title="" class="ltx_ref">2023</a>)</cite>:</span> This dataset evaluates a model’s ability to comprehend, manipulate, and reason about dates in diverse formats and contexts. Tasks include Date Format Conversion, Date Arithmetic, Date Recognition, Relative Date Interpretation, and Time Reasoning.</p>
</div>
<div id="S5.p8" class="ltx_para ltx_noindent">
<p id="S5.p8.1" class="ltx_p"><span id="S5.p8.1.1" class="ltx_text ltx_font_bold">- Temporal Sequences <cite class="ltx_cite ltx_citemacro_cite">Srivastava et al. (<a href="#bib.bib40" title="" class="ltx_ref">2023</a>)</cite>:</span> This dataset tests language models on logical deduction tasks. Models are given a series of events and their durations, and they deduce the possible timing of additional activities.</p>
</div>
<div id="S5.p9" class="ltx_para ltx_noindent">
<p id="S5.p9.1" class="ltx_p"><span id="S5.p9.1.1" class="ltx_text ltx_font_bold">- TRAM dataset <cite class="ltx_cite ltx_citemacro_cite">Wang and Zhao (<a href="#bib.bib44" title="" class="ltx_ref">2024</a>)</cite>:</span> This benchmark dataset comprises ten distinct datasets, each focusing on different temporal aspects: order, arithmetic, frequency, and duration. The TRAM dataset aims to evaluate language models’ temporal reasoning capabilities comprehensively. Table <a href="#A1.T5" title="Table 5 ‣ Appendix A Appendix ‣ Enhancing Temporal Understanding in LLMs for Semi-structured Tables" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> shows examples of questions from the TRAM dataset, highlighting the variety and complexity of temporal reasoning tasks included.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Results and Analysis</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">In this section, we present the results of enhancing temporal reasoning in Large Language Models (LLMs) for tabular data tasks. We evaluate the effectiveness of two strategies: C.L.E.A.R (Comprehend, Locate, Examine, Analyze, Resolve), a novel method tailored for tabular data reasoning, and the integration of out-of-domain temporal data for model fine-tuning.</p>
</div>
<section id="S6.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1 </span>C.L.E.A.R Prompting</h3>

<div id="S6.SS1.p1" class="ltx_para">
<p id="S6.SS1.p1.1" class="ltx_p">We analyzed C.L.E.A.R prompting against effective techniques like CoT, F-CoT, and PoT in zero-shot and few-shot settings. Our goal was to evaluate their performance across various models and determine the most effective approach.</p>
</div>
<figure id="S6.T1" class="ltx_table">
<table id="S6.T1.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S6.T1.1.1" class="ltx_tr">
<td id="S6.T1.1.1.1" class="ltx_td ltx_align_left ltx_border_tt" style="padding-left:5.9pt;padding-right:5.9pt;" rowspan="2"><span id="S6.T1.1.1.1.1" class="ltx_text ltx_font_bold">Prompt</span></td>
<td id="S6.T1.1.1.2" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:5.9pt;padding-right:5.9pt;" rowspan="2"><span id="S6.T1.1.1.2.1" class="ltx_text ltx_font_bold">No FT</span></td>
<td id="S6.T1.1.1.3" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:5.9pt;padding-right:5.9pt;" colspan="2"><span id="S6.T1.1.1.3.1" class="ltx_text ltx_font_bold">TRAM</span></td>
<td id="S6.T1.1.1.4" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:5.9pt;padding-right:5.9pt;" colspan="2"><span id="S6.T1.1.1.4.1" class="ltx_text ltx_font_bold">TempTabQA</span></td>
</tr>
<tr id="S6.T1.1.2" class="ltx_tr">
<td id="S6.T1.1.2.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.9pt;padding-right:5.9pt;"><span id="S6.T1.1.2.1.1" class="ltx_text ltx_font_bold">100</span></td>
<td id="S6.T1.1.2.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.9pt;padding-right:5.9pt;"><span id="S6.T1.1.2.2.1" class="ltx_text ltx_font_bold">1000</span></td>
<td id="S6.T1.1.2.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.9pt;padding-right:5.9pt;"><span id="S6.T1.1.2.3.1" class="ltx_text ltx_font_bold">100</span></td>
<td id="S6.T1.1.2.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.9pt;padding-right:5.9pt;"><span id="S6.T1.1.2.4.1" class="ltx_text ltx_font_bold">1000</span></td>
</tr>
<tr id="S6.T1.1.3" class="ltx_tr">
<td id="S6.T1.1.3.1" class="ltx_td ltx_border_t" style="padding-left:5.9pt;padding-right:5.9pt;"></td>
<td id="S6.T1.1.3.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.9pt;padding-right:5.9pt;" colspan="5"><span id="S6.T1.1.3.2.1" class="ltx_text ltx_font_bold">GPT-3.5 turbo</span></td>
</tr>
<tr id="S6.T1.1.4" class="ltx_tr">
<td id="S6.T1.1.4.1" class="ltx_td ltx_align_left" style="padding-left:5.9pt;padding-right:5.9pt;"><span id="S6.T1.1.4.1.1" class="ltx_text ltx_font_bold">C.L.E.A.R</span></td>
<td id="S6.T1.1.4.2" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;"><span id="S6.T1.1.4.2.1" class="ltx_text ltx_font_bold">77.99%</span></td>
<td id="S6.T1.1.4.3" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;"><span id="S6.T1.1.4.3.1" class="ltx_text ltx_font_bold">77.92%</span></td>
<td id="S6.T1.1.4.4" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">76.12%</td>
<td id="S6.T1.1.4.5" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;"><span id="S6.T1.1.4.5.1" class="ltx_text ltx_font_bold">80.89%</span></td>
<td id="S6.T1.1.4.6" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;"><span id="S6.T1.1.4.6.1" class="ltx_text ltx_font_bold">82.04%</span></td>
</tr>
<tr id="S6.T1.1.5" class="ltx_tr">
<td id="S6.T1.1.5.1" class="ltx_td ltx_align_left" style="padding-left:5.9pt;padding-right:5.9pt;"><span id="S6.T1.1.5.1.1" class="ltx_text ltx_font_bold">F.S. CoT</span></td>
<td id="S6.T1.1.5.2" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">73.49%</td>
<td id="S6.T1.1.5.3" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">75.53%</td>
<td id="S6.T1.1.5.4" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;"><span id="S6.T1.1.5.4.1" class="ltx_text ltx_font_bold">76.19%</span></td>
<td id="S6.T1.1.5.5" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">77.81%</td>
<td id="S6.T1.1.5.6" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">79.47%</td>
</tr>
<tr id="S6.T1.1.6" class="ltx_tr">
<td id="S6.T1.1.6.1" class="ltx_td ltx_align_left" style="padding-left:5.9pt;padding-right:5.9pt;"><span id="S6.T1.1.6.1.1" class="ltx_text ltx_font_bold">F.S. F-CoT</span></td>
<td id="S6.T1.1.6.2" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">70.54%</td>
<td id="S6.T1.1.6.3" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">71.13%</td>
<td id="S6.T1.1.6.4" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">72.72%</td>
<td id="S6.T1.1.6.5" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">77.85%</td>
<td id="S6.T1.1.6.6" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">76.57%</td>
</tr>
<tr id="S6.T1.1.7" class="ltx_tr">
<td id="S6.T1.1.7.1" class="ltx_td ltx_align_left" style="padding-left:5.9pt;padding-right:5.9pt;"><span id="S6.T1.1.7.1.1" class="ltx_text ltx_font_bold">F.S. PoT</span></td>
<td id="S6.T1.1.7.2" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">70.13%</td>
<td id="S6.T1.1.7.3" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">70.58%</td>
<td id="S6.T1.1.7.4" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">69.75%</td>
<td id="S6.T1.1.7.5" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">79.37%</td>
<td id="S6.T1.1.7.6" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">77.57%</td>
</tr>
<tr id="S6.T1.1.8" class="ltx_tr">
<td id="S6.T1.1.8.1" class="ltx_td ltx_align_left" style="padding-left:5.9pt;padding-right:5.9pt;"><span id="S6.T1.1.8.1.1" class="ltx_text ltx_font_bold">Z.S. CoT</span></td>
<td id="S6.T1.1.8.2" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">65.84%</td>
<td id="S6.T1.1.8.3" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">68.64%</td>
<td id="S6.T1.1.8.4" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">69.61%</td>
<td id="S6.T1.1.8.5" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">73.73%</td>
<td id="S6.T1.1.8.6" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">72.72%</td>
</tr>
<tr id="S6.T1.1.9" class="ltx_tr">
<td id="S6.T1.1.9.1" class="ltx_td ltx_align_left" style="padding-left:5.9pt;padding-right:5.9pt;"><span id="S6.T1.1.9.1.1" class="ltx_text ltx_font_bold">Z.S. F-CoT</span></td>
<td id="S6.T1.1.9.2" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">64.38%</td>
<td id="S6.T1.1.9.3" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">67.32%</td>
<td id="S6.T1.1.9.4" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">65.91%</td>
<td id="S6.T1.1.9.5" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">71.27%</td>
<td id="S6.T1.1.9.6" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">71.69%</td>
</tr>
<tr id="S6.T1.1.10" class="ltx_tr">
<td id="S6.T1.1.10.1" class="ltx_td ltx_align_left" style="padding-left:5.9pt;padding-right:5.9pt;"><span id="S6.T1.1.10.1.1" class="ltx_text ltx_font_bold">Z.S. PoT</span></td>
<td id="S6.T1.1.10.2" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">65.39%</td>
<td id="S6.T1.1.10.3" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">67.39%</td>
<td id="S6.T1.1.10.4" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">68.05%</td>
<td id="S6.T1.1.10.5" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">72.17%</td>
<td id="S6.T1.1.10.6" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">72.76%</td>
</tr>
<tr id="S6.T1.1.11" class="ltx_tr">
<td id="S6.T1.1.11.1" class="ltx_td ltx_border_t" style="padding-left:5.9pt;padding-right:5.9pt;"></td>
<td id="S6.T1.1.11.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.9pt;padding-right:5.9pt;" colspan="5"><span id="S6.T1.1.11.2.1" class="ltx_text ltx_font_bold">LLAMA 7B</span></td>
</tr>
<tr id="S6.T1.1.12" class="ltx_tr">
<td id="S6.T1.1.12.1" class="ltx_td ltx_align_left" style="padding-left:5.9pt;padding-right:5.9pt;"><span id="S6.T1.1.12.1.1" class="ltx_text ltx_font_bold">C.L.E.A.R</span></td>
<td id="S6.T1.1.12.2" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">59.33%</td>
<td id="S6.T1.1.12.3" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">61.65%</td>
<td id="S6.T1.1.12.4" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">59.85%</td>
<td id="S6.T1.1.12.5" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">63.69%</td>
<td id="S6.T1.1.12.6" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">63.17%</td>
</tr>
<tr id="S6.T1.1.13" class="ltx_tr">
<td id="S6.T1.1.13.1" class="ltx_td ltx_align_left" style="padding-left:5.9pt;padding-right:5.9pt;"><span id="S6.T1.1.13.1.1" class="ltx_text ltx_font_bold">F.S. CoT</span></td>
<td id="S6.T1.1.13.2" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">61.51%</td>
<td id="S6.T1.1.13.3" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">64.87%</td>
<td id="S6.T1.1.13.4" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">63.66%</td>
<td id="S6.T1.1.13.5" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">67.22%</td>
<td id="S6.T1.1.13.6" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;"><span id="S6.T1.1.13.6.1" class="ltx_text ltx_font_bold">68.64%</span></td>
</tr>
<tr id="S6.T1.1.14" class="ltx_tr">
<td id="S6.T1.1.14.1" class="ltx_td ltx_align_left" style="padding-left:5.9pt;padding-right:5.9pt;"><span id="S6.T1.1.14.1.1" class="ltx_text ltx_font_bold">F.S. F-CoT</span></td>
<td id="S6.T1.1.14.2" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">61.96%</td>
<td id="S6.T1.1.14.3" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">61.54%</td>
<td id="S6.T1.1.14.4" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">64.24%</td>
<td id="S6.T1.1.14.5" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">66.77%</td>
<td id="S6.T1.1.14.6" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">67.32%</td>
</tr>
<tr id="S6.T1.1.15" class="ltx_tr">
<td id="S6.T1.1.15.1" class="ltx_td ltx_align_left" style="padding-left:5.9pt;padding-right:5.9pt;"><span id="S6.T1.1.15.1.1" class="ltx_text ltx_font_bold">F.S. PoT</span></td>
<td id="S6.T1.1.15.2" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">62.69%</td>
<td id="S6.T1.1.15.3" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">64.04%</td>
<td id="S6.T1.1.15.4" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">66.08%</td>
<td id="S6.T1.1.15.5" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;"><span id="S6.T1.1.15.5.1" class="ltx_text ltx_font_bold">67.43%</span></td>
<td id="S6.T1.1.15.6" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">65.94%</td>
</tr>
<tr id="S6.T1.1.16" class="ltx_tr">
<td id="S6.T1.1.16.1" class="ltx_td ltx_align_left" style="padding-left:5.9pt;padding-right:5.9pt;"><span id="S6.T1.1.16.1.1" class="ltx_text ltx_font_bold">Z.S. CoT</span></td>
<td id="S6.T1.1.16.2" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">61.65%</td>
<td id="S6.T1.1.16.3" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">62.48%</td>
<td id="S6.T1.1.16.4" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">61.79%</td>
<td id="S6.T1.1.16.5" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">63.07%</td>
<td id="S6.T1.1.16.6" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">65.21%</td>
</tr>
<tr id="S6.T1.1.17" class="ltx_tr">
<td id="S6.T1.1.17.1" class="ltx_td ltx_align_left" style="padding-left:5.9pt;padding-right:5.9pt;"><span id="S6.T1.1.17.1.1" class="ltx_text ltx_font_bold">Z.S. F-CoT</span></td>
<td id="S6.T1.1.17.2" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;"><span id="S6.T1.1.17.2.1" class="ltx_text ltx_font_bold">63.93%</span></td>
<td id="S6.T1.1.17.3" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;"><span id="S6.T1.1.17.3.1" class="ltx_text ltx_font_bold">66.98%</span></td>
<td id="S6.T1.1.17.4" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;"><span id="S6.T1.1.17.4.1" class="ltx_text ltx_font_bold">69.40%</span></td>
<td id="S6.T1.1.17.5" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">63.38%</td>
<td id="S6.T1.1.17.6" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">64.31%</td>
</tr>
<tr id="S6.T1.1.18" class="ltx_tr">
<td id="S6.T1.1.18.1" class="ltx_td ltx_align_left" style="padding-left:5.9pt;padding-right:5.9pt;"><span id="S6.T1.1.18.1.1" class="ltx_text ltx_font_bold">Z.S. PoT</span></td>
<td id="S6.T1.1.18.2" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">63.34%</td>
<td id="S6.T1.1.18.3" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">63.69%</td>
<td id="S6.T1.1.18.4" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">64.76%</td>
<td id="S6.T1.1.18.5" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">65.07%</td>
<td id="S6.T1.1.18.6" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">65.42%</td>
</tr>
<tr id="S6.T1.1.19" class="ltx_tr">
<td id="S6.T1.1.19.1" class="ltx_td ltx_border_t" style="padding-left:5.9pt;padding-right:5.9pt;"></td>
<td id="S6.T1.1.19.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.9pt;padding-right:5.9pt;" colspan="5"><span id="S6.T1.1.19.2.1" class="ltx_text ltx_font_bold">PALM 2</span></td>
</tr>
<tr id="S6.T1.1.20" class="ltx_tr">
<td id="S6.T1.1.20.1" class="ltx_td ltx_align_left" style="padding-left:5.9pt;padding-right:5.9pt;"><span id="S6.T1.1.20.1.1" class="ltx_text ltx_font_bold">C.L.E.A.R</span></td>
<td id="S6.T1.1.20.2" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;"><span id="S6.T1.1.20.2.1" class="ltx_text ltx_font_bold">80.06%</span></td>
<td id="S6.T1.1.20.3" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;"><span id="S6.T1.1.20.3.1" class="ltx_text ltx_font_bold">81.97%</span></td>
<td id="S6.T1.1.20.4" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;"><span id="S6.T1.1.20.4.1" class="ltx_text ltx_font_bold">83.28%</span></td>
<td id="S6.T1.1.20.5" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;"><span id="S6.T1.1.20.5.1" class="ltx_text ltx_font_bold">85.01%</span></td>
<td id="S6.T1.1.20.6" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;"><span id="S6.T1.1.20.6.1" class="ltx_text ltx_font_bold">85.01%</span></td>
</tr>
<tr id="S6.T1.1.21" class="ltx_tr">
<td id="S6.T1.1.21.1" class="ltx_td ltx_align_left" style="padding-left:5.9pt;padding-right:5.9pt;"><span id="S6.T1.1.21.1.1" class="ltx_text ltx_font_bold">F.S. CoT</span></td>
<td id="S6.T1.1.21.2" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">77.40%</td>
<td id="S6.T1.1.21.3" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">81.14%</td>
<td id="S6.T1.1.21.4" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">82.24%</td>
<td id="S6.T1.1.21.5" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">80.17%</td>
<td id="S6.T1.1.21.6" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">81.59%</td>
</tr>
<tr id="S6.T1.1.22" class="ltx_tr">
<td id="S6.T1.1.22.1" class="ltx_td ltx_align_left" style="padding-left:5.9pt;padding-right:5.9pt;"><span id="S6.T1.1.22.1.1" class="ltx_text ltx_font_bold">F.S. F-CoT</span></td>
<td id="S6.T1.1.22.2" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">75.63%</td>
<td id="S6.T1.1.22.3" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">75.35%</td>
<td id="S6.T1.1.22.4" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">78.82%</td>
<td id="S6.T1.1.22.5" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">82.45%</td>
<td id="S6.T1.1.22.6" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">82.21%</td>
</tr>
<tr id="S6.T1.1.23" class="ltx_tr">
<td id="S6.T1.1.23.1" class="ltx_td ltx_align_left" style="padding-left:5.9pt;padding-right:5.9pt;"><span id="S6.T1.1.23.1.1" class="ltx_text ltx_font_bold">F.S. PoT</span></td>
<td id="S6.T1.1.23.2" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">76.01%</td>
<td id="S6.T1.1.23.3" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">75.98%</td>
<td id="S6.T1.1.23.4" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">76.25%</td>
<td id="S6.T1.1.23.5" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">84.56%</td>
<td id="S6.T1.1.23.6" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">80.27%</td>
</tr>
<tr id="S6.T1.1.24" class="ltx_tr">
<td id="S6.T1.1.24.1" class="ltx_td ltx_align_left" style="padding-left:5.9pt;padding-right:5.9pt;"><span id="S6.T1.1.24.1.1" class="ltx_text ltx_font_bold">Z.S. CoT</span></td>
<td id="S6.T1.1.24.2" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">70.13%</td>
<td id="S6.T1.1.24.3" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">73.97%</td>
<td id="S6.T1.1.24.4" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">74.42%</td>
<td id="S6.T1.1.24.5" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">78.89%</td>
<td id="S6.T1.1.24.6" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">76.74%</td>
</tr>
<tr id="S6.T1.1.25" class="ltx_tr">
<td id="S6.T1.1.25.1" class="ltx_td ltx_align_left" style="padding-left:5.9pt;padding-right:5.9pt;"><span id="S6.T1.1.25.1.1" class="ltx_text ltx_font_bold">Z.S. F-CoT</span></td>
<td id="S6.T1.1.25.2" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">69.75%</td>
<td id="S6.T1.1.25.3" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">74.04%</td>
<td id="S6.T1.1.25.4" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">74.90%</td>
<td id="S6.T1.1.25.5" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">75.22%</td>
<td id="S6.T1.1.25.6" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">75.94%</td>
</tr>
<tr id="S6.T1.1.26" class="ltx_tr">
<td id="S6.T1.1.26.1" class="ltx_td ltx_align_left" style="padding-left:5.9pt;padding-right:5.9pt;"><span id="S6.T1.1.26.1.1" class="ltx_text ltx_font_bold">Z.S. PoT</span></td>
<td id="S6.T1.1.26.2" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">71.24%</td>
<td id="S6.T1.1.26.3" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">74.32%</td>
<td id="S6.T1.1.26.4" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">76.29%</td>
<td id="S6.T1.1.26.5" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">79.09%</td>
<td id="S6.T1.1.26.6" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">79.13%</td>
</tr>
<tr id="S6.T1.1.27" class="ltx_tr">
<td id="S6.T1.1.27.1" class="ltx_td ltx_border_t" style="padding-left:5.9pt;padding-right:5.9pt;"></td>
<td id="S6.T1.1.27.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.9pt;padding-right:5.9pt;" colspan="5"><span id="S6.T1.1.27.2.1" class="ltx_text ltx_font_bold">MISTRAL-2 7B</span></td>
</tr>
<tr id="S6.T1.1.28" class="ltx_tr">
<td id="S6.T1.1.28.1" class="ltx_td ltx_align_left" style="padding-left:5.9pt;padding-right:5.9pt;"><span id="S6.T1.1.28.1.1" class="ltx_text ltx_font_bold">C.L.E.A.R</span></td>
<td id="S6.T1.1.28.2" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;"><span id="S6.T1.1.28.2.1" class="ltx_text ltx_font_bold">69.33%</span></td>
<td id="S6.T1.1.28.3" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;"><span id="S6.T1.1.28.3.1" class="ltx_text ltx_font_bold">73.52%</span></td>
<td id="S6.T1.1.28.4" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;"><span id="S6.T1.1.28.4.1" class="ltx_text ltx_font_bold">72.41%</span></td>
<td id="S6.T1.1.28.5" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">74.80%</td>
<td id="S6.T1.1.28.6" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">73.87%</td>
</tr>
<tr id="S6.T1.1.29" class="ltx_tr">
<td id="S6.T1.1.29.1" class="ltx_td ltx_align_left" style="padding-left:5.9pt;padding-right:5.9pt;"><span id="S6.T1.1.29.1.1" class="ltx_text ltx_font_bold">F.S. CoT</span></td>
<td id="S6.T1.1.29.2" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">69.23%</td>
<td id="S6.T1.1.29.3" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">70.61%</td>
<td id="S6.T1.1.29.4" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">71.13%</td>
<td id="S6.T1.1.29.5" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">73.31%</td>
<td id="S6.T1.1.29.6" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;"><span id="S6.T1.1.29.6.1" class="ltx_text ltx_font_bold">75.63%</span></td>
</tr>
<tr id="S6.T1.1.30" class="ltx_tr">
<td id="S6.T1.1.30.1" class="ltx_td ltx_align_left" style="padding-left:5.9pt;padding-right:5.9pt;"><span id="S6.T1.1.30.1.1" class="ltx_text ltx_font_bold">F.S. F-CoT</span></td>
<td id="S6.T1.1.30.2" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">68.19%</td>
<td id="S6.T1.1.30.3" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">71.06%</td>
<td id="S6.T1.1.30.4" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">70.02%</td>
<td id="S6.T1.1.30.5" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;"><span id="S6.T1.1.30.5.1" class="ltx_text ltx_font_bold">74.84%</span></td>
<td id="S6.T1.1.30.6" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">75.25%</td>
</tr>
<tr id="S6.T1.1.31" class="ltx_tr">
<td id="S6.T1.1.31.1" class="ltx_td ltx_align_left" style="padding-left:5.9pt;padding-right:5.9pt;"><span id="S6.T1.1.31.1.1" class="ltx_text ltx_font_bold">F.S. PoT</span></td>
<td id="S6.T1.1.31.2" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">67.60%</td>
<td id="S6.T1.1.31.3" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">70.51%</td>
<td id="S6.T1.1.31.4" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">69.99%</td>
<td id="S6.T1.1.31.5" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">74.35%</td>
<td id="S6.T1.1.31.6" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">73.59%</td>
</tr>
<tr id="S6.T1.1.32" class="ltx_tr">
<td id="S6.T1.1.32.1" class="ltx_td ltx_align_left" style="padding-left:5.9pt;padding-right:5.9pt;"><span id="S6.T1.1.32.1.1" class="ltx_text ltx_font_bold">Z.S. CoT</span></td>
<td id="S6.T1.1.32.2" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">65.25%</td>
<td id="S6.T1.1.32.3" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">66.22%</td>
<td id="S6.T1.1.32.4" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">70.37%</td>
<td id="S6.T1.1.32.5" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">71.62%</td>
<td id="S6.T1.1.32.6" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">71.48%</td>
</tr>
<tr id="S6.T1.1.33" class="ltx_tr">
<td id="S6.T1.1.33.1" class="ltx_td ltx_align_left" style="padding-left:5.9pt;padding-right:5.9pt;"><span id="S6.T1.1.33.1.1" class="ltx_text ltx_font_bold">Z.S. F-CoT</span></td>
<td id="S6.T1.1.33.2" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">66.56%</td>
<td id="S6.T1.1.33.3" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">71.13%</td>
<td id="S6.T1.1.33.4" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">69.51%</td>
<td id="S6.T1.1.33.5" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">67.08%</td>
<td id="S6.T1.1.33.6" class="ltx_td ltx_align_center" style="padding-left:5.9pt;padding-right:5.9pt;">71.10%</td>
</tr>
<tr id="S6.T1.1.34" class="ltx_tr">
<td id="S6.T1.1.34.1" class="ltx_td ltx_align_left ltx_border_bb" style="padding-left:5.9pt;padding-right:5.9pt;"><span id="S6.T1.1.34.1.1" class="ltx_text ltx_font_bold">Z.S. PoT</span></td>
<td id="S6.T1.1.34.2" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:5.9pt;padding-right:5.9pt;">64.31%</td>
<td id="S6.T1.1.34.3" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:5.9pt;padding-right:5.9pt;">66.63%</td>
<td id="S6.T1.1.34.4" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:5.9pt;padding-right:5.9pt;">66.98%</td>
<td id="S6.T1.1.34.5" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:5.9pt;padding-right:5.9pt;">71.69%</td>
<td id="S6.T1.1.34.6" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:5.9pt;padding-right:5.9pt;">71.65%</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Model’s performance on various prompts without fine-tuning, with fine-tuning on auxiliary data (TRAM), and with fine-tuning on the TempTabQA dataset using 100 and 1000 examples. The best result is highlighted in bold.</figcaption>
</figure>
<div id="S6.SS1.p2" class="ltx_para">
<p id="S6.SS1.p2.1" class="ltx_p">As shown in Table <a href="#S6.T1" title="Table 1 ‣ 6.1 C.L.E.A.R Prompting ‣ 6 Results and Analysis ‣ Enhancing Temporal Understanding in LLMs for Semi-structured Tables" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, C.L.E.A.R consistently outperforms other techniques across various models without fine-tuning, except for LLaMA-2. For GPT-3.5 Turbo, our method achieves a 4.5% performance boost compared to the next best technique. For PaLM-2, it leads to a 2.7% improvement.</p>
</div>
<div id="S6.SS1.p3" class="ltx_para">
<p id="S6.SS1.p3.1" class="ltx_p">These findings highlight C.L.E.A.R prompting’s effectiveness in enhancing model performance, particularly in scenarios where fine-tuning is not feasible. Significant performance gains observed with GPT-3.5 Turbo and PaLM-2 demonstrate its potential to improve temporal reasoning and overall task comprehension in large language models.</p>
</div>
</section>
<section id="S6.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2 </span>Efficacy of C.L.E.A.R</h3>

<div id="S6.SS2.p1" class="ltx_para">
<p id="S6.SS2.p1.1" class="ltx_p">The results in Section <a href="#S6.SS1" title="6.1 C.L.E.A.R Prompting ‣ 6 Results and Analysis ‣ Enhancing Temporal Understanding in LLMs for Semi-structured Tables" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6.1</span></a> demonstrate that our method is more effective than other prompting techniques. However, is C.L.E.A.R <em id="S6.SS2.p1.1.1" class="ltx_emph ltx_font_italic">trustworthy?</em> Does it really enhance the model’s <em id="S6.SS2.p1.1.2" class="ltx_emph ltx_font_italic">evidence-based reasoning capabilities?</em> <cite class="ltx_cite ltx_citemacro_cite">Gupta et al. (<a href="#bib.bib13" title="" class="ltx_ref">2021</a>)</cite>. Our experiments compare C.L.E.A.R with Zero Shot and Few Shot Chain of Thought (CoT) approaches across tasks highlighting model deficiencies. Below are each of task descriptions:</p>
<ol id="S6.I1" class="ltx_enumerate">
<li id="S6.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S6.I1.i1.p1" class="ltx_para">
<p id="S6.I1.i1.p1.1" class="ltx_p"><span id="S6.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Original Table:</span> The model uses the original table to answer the question, testing its ability to effectively utilize the provided data.</p>
</div>
</li>
<li id="S6.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S6.I1.i2.p1" class="ltx_para">
<p id="S6.I1.i2.p1.1" class="ltx_p"><span id="S6.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Without Table:</span> The model is asked to answer the question without access to the table, testing whether the model has memorized the answers or can deduce them independently. Here, an ideal model’s performance should suffer as it doesn’t use pre-trained knowledge.</p>
</div>
</li>
<li id="S6.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S6.I1.i3.p1" class="ltx_para">
<p id="S6.I1.i3.p1.1" class="ltx_p"><span id="S6.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">Altered Entity Name:</span> The table and question are provided to the model with an altered entity name. This checks the model’s reasoning ability without relying on memorized data.</p>
</div>
</li>
<li id="S6.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span> 
<div id="S6.I1.i4.p1" class="ltx_para">
<p id="S6.I1.i4.p1.1" class="ltx_p"><span id="S6.I1.i4.p1.1.1" class="ltx_text ltx_font_bold">Missing Relevant Rows:</span> The model is given the original table with relevant rows deleted. This evaluates whether the model can use external knowledge to answer questions. Responses are evaluated against gold answers.</p>
</div>
</li>
<li id="S6.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">5.</span> 
<div id="S6.I1.i5.p1" class="ltx_para">
<p id="S6.I1.i5.p1.1" class="ltx_p"><span id="S6.I1.i5.p1.1.1" class="ltx_text ltx_font_bold">Information Absence Detection:</span> The model receives the original table with relevant rows deleted. This task evaluates the model’s accuracy in identifying missing information.</p>
</div>
</li>
</ol>
</div>
<div id="S6.SS2.p2" class="ltx_para ltx_noindent">
<p id="S6.SS2.p2.1" class="ltx_p">For the last two tasks i.e. Missing Relevant Rows and Information Absence Detection, we perform evaluations in two settings:</p>
<ul id="S6.I2" class="ltx_itemize">
<li id="S6.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I2.i1.p1" class="ltx_para">
<p id="S6.I2.i1.p1.1" class="ltx_p"><span id="S6.I2.i1.p1.1.1" class="ltx_text ltx_font_bold">Original Prompt:</span> The model is tested with the original prompt to see if it can detect missing information or use external knowledge.</p>
</div>
</li>
<li id="S6.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I2.i2.p1" class="ltx_para">
<p id="S6.I2.i2.p1.1" class="ltx_p"><span id="S6.I2.i2.p1.1.1" class="ltx_text ltx_font_bold">Updated Prompt:</span> The model is explicitly instructed that the information may or may not be present, to see if explicit instructions improve performance.</p>
</div>
</li>
</ul>
</div>
<div id="S6.SS2.p3" class="ltx_para">
<p id="S6.SS2.p3.1" class="ltx_p">We aim to assess if C.L.E.A.R prompting improves evidence-based reasoning in models beyond accuracy. This analysis evaluates its effectiveness in addressing specific reasoning challenges and enhancing model reliability across diverse contexts.</p>
</div>
<section id="S6.SS2.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Results and Analysis.</h4>

<div id="S6.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="S6.SS2.SSS0.Px1.p1.1" class="ltx_p">We tested zero-shot Chain of Thought (CoT), few-shot CoT, and C.L.E.A.R prompting techniques across various tasks. In Table <a href="#S6.T2" title="Table 2 ‣ Results and Analysis. ‣ 6.2 Efficacy of C.L.E.A.R ‣ 6 Results and Analysis ‣ Enhancing Temporal Understanding in LLMs for Semi-structured Tables" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, C.L.E.A.R consistently outperforms other methods on most tasks, except for LLaMA-2 and Mistral-2 models, which show varied results. GPT 4O achieves the highest accuracy at 85.08%, marking a 2.39% improvement over few-shot CoT.</p>
</div>
<div id="S6.SS2.SSS0.Px1.p2" class="ltx_para">
<p id="S6.SS2.SSS0.Px1.p2.1" class="ltx_p"><span id="S6.SS2.SSS0.Px1.p2.1.1" class="ltx_text ltx_font_bold">(a) Without Table.</span> In this task, when evaluated without table access, C.L.E.A.R’s performance declines across all models using original labels. This indicates that it mitigates memorization issues seen in other techniques by emphasizing contextual reliance. Specifically, we observe a decrease of <a href="~" title="" class="ltx_ref ltx_url ltx_font_typewriter">~</a>4% for GPT-4O and GPT-3.5 Turbo, and an 11.04% decrease for Llama.</p>
</div>
<div id="S6.SS2.SSS0.Px1.p3" class="ltx_para">
<p id="S6.SS2.SSS0.Px1.p3.1" class="ltx_p"><span id="S6.SS2.SSS0.Px1.p3.1.1" class="ltx_text ltx_font_bold">(b) Altered Table Entity.</span> C.L.E.A.R performs best overall in this task, except for LLaMA-2, PaLM, and Mistral-2. GPT 4O provides best accuracy of 82.62% which is a bosst of 6.26% in comparision of few shot CoT. LLaMA-2 7B and Mistral-2 7B show weaker performance mainly due to their smaller size, which generally leads to less effective adherence to instructions compared to larger models. For models GPT 3.5 turbo and Gemini 1.5 pro flash, we observe a gain of 4.15% and 8.51% respectively.</p>
</div>
<figure id="S6.T2" class="ltx_table">
<table id="S6.T2.17" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S6.T2.17.18" class="ltx_tr">
<td id="S6.T2.17.18.1" class="ltx_td ltx_align_left ltx_border_tt" style="padding-left:2.7pt;padding-right:2.7pt;" rowspan="2"><span id="S6.T2.17.18.1.1" class="ltx_text ltx_font_bold">Models</span></td>
<td id="S6.T2.17.18.2" class="ltx_td ltx_align_left ltx_border_tt" style="padding-left:2.7pt;padding-right:2.7pt;" rowspan="2"><span id="S6.T2.17.18.2.1" class="ltx_text ltx_font_bold">Task (expected)</span></td>
<td id="S6.T2.17.18.3" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:2.7pt;padding-right:2.7pt;" colspan="3"><span id="S6.T2.17.18.3.1" class="ltx_text ltx_font_bold">Prompts</span></td>
</tr>
<tr id="S6.T2.17.19" class="ltx_tr">
<td id="S6.T2.17.19.1" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S6.T2.17.19.1.1" class="ltx_text ltx_font_bold">Z.S CoT</span></td>
<td id="S6.T2.17.19.2" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S6.T2.17.19.2.1" class="ltx_text ltx_font_bold">F.S CoT</span></td>
<td id="S6.T2.17.19.3" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S6.T2.17.19.3.1" class="ltx_text ltx_font_bold">C.L.E.A.R</span></td>
</tr>
<tr id="S6.T2.1.1" class="ltx_tr">
<td id="S6.T2.1.1.2" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:2.7pt;padding-right:2.7pt;" rowspan="3"><span id="S6.T2.1.1.2.1" class="ltx_text ltx_font_bold">GPT 4O</span></td>
<td id="S6.T2.1.1.1" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S6.T2.1.1.1.1" class="ltx_text ltx_font_bold">Original Table (<math id="S6.T2.1.1.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S6.T2.1.1.1.1.m1.1a"><mo stretchy="false" id="S6.T2.1.1.1.1.m1.1.1" xref="S6.T2.1.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S6.T2.1.1.1.1.m1.1b"><ci id="S6.T2.1.1.1.1.m1.1.1.cmml" xref="S6.T2.1.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.1.1.1.1.m1.1c">\uparrow</annotation></semantics></math>)</span></td>
<td id="S6.T2.1.1.3" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.7pt;padding-right:2.7pt;">75.80%</td>
<td id="S6.T2.1.1.4" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.7pt;padding-right:2.7pt;">82.69%</td>
<td id="S6.T2.1.1.5" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S6.T2.1.1.5.1" class="ltx_text ltx_font_bold">85.08%</span></td>
</tr>
<tr id="S6.T2.2.2" class="ltx_tr">
<td id="S6.T2.2.2.1" class="ltx_td ltx_align_left" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S6.T2.2.2.1.1" class="ltx_text ltx_font_bold">Without Table (<math id="S6.T2.2.2.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S6.T2.2.2.1.1.m1.1a"><mo stretchy="false" id="S6.T2.2.2.1.1.m1.1.1" xref="S6.T2.2.2.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S6.T2.2.2.1.1.m1.1b"><ci id="S6.T2.2.2.1.1.m1.1.1.cmml" xref="S6.T2.2.2.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.2.2.1.1.m1.1c">\downarrow</annotation></semantics></math>)</span></td>
<td id="S6.T2.2.2.2" class="ltx_td ltx_align_right" style="padding-left:2.7pt;padding-right:2.7pt;">75.91%</td>
<td id="S6.T2.2.2.3" class="ltx_td ltx_align_right" style="padding-left:2.7pt;padding-right:2.7pt;">73.31%</td>
<td id="S6.T2.2.2.4" class="ltx_td ltx_align_right" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S6.T2.2.2.4.1" class="ltx_text ltx_font_bold">69.44%</span></td>
</tr>
<tr id="S6.T2.3.3" class="ltx_tr">
<td id="S6.T2.3.3.1" class="ltx_td ltx_align_left" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S6.T2.3.3.1.1" class="ltx_text ltx_font_bold">Altered Name Entity (<math id="S6.T2.3.3.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S6.T2.3.3.1.1.m1.1a"><mo stretchy="false" id="S6.T2.3.3.1.1.m1.1.1" xref="S6.T2.3.3.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S6.T2.3.3.1.1.m1.1b"><ci id="S6.T2.3.3.1.1.m1.1.1.cmml" xref="S6.T2.3.3.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.3.3.1.1.m1.1c">\uparrow</annotation></semantics></math>)</span></td>
<td id="S6.T2.3.3.2" class="ltx_td ltx_align_right" style="padding-left:2.7pt;padding-right:2.7pt;">74.94%</td>
<td id="S6.T2.3.3.3" class="ltx_td ltx_align_right" style="padding-left:2.7pt;padding-right:2.7pt;">76.36%</td>
<td id="S6.T2.3.3.4" class="ltx_td ltx_align_right" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S6.T2.3.3.4.1" class="ltx_text ltx_font_bold">82.62%</span></td>
</tr>
<tr id="S6.T2.4.4" class="ltx_tr">
<td id="S6.T2.4.4.2" class="ltx_td ltx_align_left" style="padding-left:2.7pt;padding-right:2.7pt;" rowspan="3"><span id="S6.T2.4.4.2.1" class="ltx_text ltx_font_bold">GPT 3.5</span></td>
<td id="S6.T2.4.4.1" class="ltx_td ltx_align_left" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S6.T2.4.4.1.1" class="ltx_text ltx_font_bold">Original Table (<math id="S6.T2.4.4.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S6.T2.4.4.1.1.m1.1a"><mo stretchy="false" id="S6.T2.4.4.1.1.m1.1.1" xref="S6.T2.4.4.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S6.T2.4.4.1.1.m1.1b"><ci id="S6.T2.4.4.1.1.m1.1.1.cmml" xref="S6.T2.4.4.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.4.4.1.1.m1.1c">\uparrow</annotation></semantics></math>)</span></td>
<td id="S6.T2.4.4.3" class="ltx_td ltx_align_right" style="padding-left:2.7pt;padding-right:2.7pt;">65.56%</td>
<td id="S6.T2.4.4.4" class="ltx_td ltx_align_right" style="padding-left:2.7pt;padding-right:2.7pt;">73.35%</td>
<td id="S6.T2.4.4.5" class="ltx_td ltx_align_right" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S6.T2.4.4.5.1" class="ltx_text ltx_font_bold">78.05%</span></td>
</tr>
<tr id="S6.T2.5.5" class="ltx_tr">
<td id="S6.T2.5.5.1" class="ltx_td ltx_align_left" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S6.T2.5.5.1.1" class="ltx_text ltx_font_bold">Without Table (<math id="S6.T2.5.5.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S6.T2.5.5.1.1.m1.1a"><mo stretchy="false" id="S6.T2.5.5.1.1.m1.1.1" xref="S6.T2.5.5.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S6.T2.5.5.1.1.m1.1b"><ci id="S6.T2.5.5.1.1.m1.1.1.cmml" xref="S6.T2.5.5.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.5.5.1.1.m1.1c">\downarrow</annotation></semantics></math>)</span></td>
<td id="S6.T2.5.5.2" class="ltx_td ltx_align_right" style="padding-left:2.7pt;padding-right:2.7pt;">62.27%</td>
<td id="S6.T2.5.5.3" class="ltx_td ltx_align_right" style="padding-left:2.7pt;padding-right:2.7pt;">62.10%</td>
<td id="S6.T2.5.5.4" class="ltx_td ltx_align_right" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S6.T2.5.5.4.1" class="ltx_text ltx_font_bold">58.22%</span></td>
</tr>
<tr id="S6.T2.6.6" class="ltx_tr">
<td id="S6.T2.6.6.1" class="ltx_td ltx_align_left" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S6.T2.6.6.1.1" class="ltx_text ltx_font_bold">Altered Name Entity(<math id="S6.T2.6.6.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S6.T2.6.6.1.1.m1.1a"><mo stretchy="false" id="S6.T2.6.6.1.1.m1.1.1" xref="S6.T2.6.6.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S6.T2.6.6.1.1.m1.1b"><ci id="S6.T2.6.6.1.1.m1.1.1.cmml" xref="S6.T2.6.6.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.6.6.1.1.m1.1c">\uparrow</annotation></semantics></math>)</span></td>
<td id="S6.T2.6.6.2" class="ltx_td ltx_align_right" style="padding-left:2.7pt;padding-right:2.7pt;">61.09%</td>
<td id="S6.T2.6.6.3" class="ltx_td ltx_align_right" style="padding-left:2.7pt;padding-right:2.7pt;">67.95%</td>
<td id="S6.T2.6.6.4" class="ltx_td ltx_align_right" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S6.T2.6.6.4.1" class="ltx_text ltx_font_bold">72.10%</span></td>
</tr>
<tr id="S6.T2.7.7" class="ltx_tr">
<td id="S6.T2.7.7.2" class="ltx_td ltx_align_left" style="padding-left:2.7pt;padding-right:2.7pt;" rowspan="3"><span id="S6.T2.7.7.2.1" class="ltx_text ltx_font_bold">Llama</span></td>
<td id="S6.T2.7.7.1" class="ltx_td ltx_align_left" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S6.T2.7.7.1.1" class="ltx_text ltx_font_bold">Original Table (<math id="S6.T2.7.7.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S6.T2.7.7.1.1.m1.1a"><mo stretchy="false" id="S6.T2.7.7.1.1.m1.1.1" xref="S6.T2.7.7.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S6.T2.7.7.1.1.m1.1b"><ci id="S6.T2.7.7.1.1.m1.1.1.cmml" xref="S6.T2.7.7.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.7.7.1.1.m1.1c">\uparrow</annotation></semantics></math>)</span></td>
<td id="S6.T2.7.7.3" class="ltx_td ltx_align_right" style="padding-left:2.7pt;padding-right:2.7pt;">62.31%</td>
<td id="S6.T2.7.7.4" class="ltx_td ltx_align_right" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S6.T2.7.7.4.1" class="ltx_text ltx_font_bold">62.41%</span></td>
<td id="S6.T2.7.7.5" class="ltx_td ltx_align_right" style="padding-left:2.7pt;padding-right:2.7pt;">59.12%</td>
</tr>
<tr id="S6.T2.8.8" class="ltx_tr">
<td id="S6.T2.8.8.1" class="ltx_td ltx_align_left" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S6.T2.8.8.1.1" class="ltx_text ltx_font_bold">Without Table (<math id="S6.T2.8.8.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S6.T2.8.8.1.1.m1.1a"><mo stretchy="false" id="S6.T2.8.8.1.1.m1.1.1" xref="S6.T2.8.8.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S6.T2.8.8.1.1.m1.1b"><ci id="S6.T2.8.8.1.1.m1.1.1.cmml" xref="S6.T2.8.8.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.8.8.1.1.m1.1c">\downarrow</annotation></semantics></math>)</span></td>
<td id="S6.T2.8.8.2" class="ltx_td ltx_align_right" style="padding-left:2.7pt;padding-right:2.7pt;">54.69%</td>
<td id="S6.T2.8.8.3" class="ltx_td ltx_align_right" style="padding-left:2.7pt;padding-right:2.7pt;">42.85%</td>
<td id="S6.T2.8.8.4" class="ltx_td ltx_align_right" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S6.T2.8.8.4.1" class="ltx_text ltx_font_bold">31.81%</span></td>
</tr>
<tr id="S6.T2.17.20" class="ltx_tr">
<td id="S6.T2.17.20.1" class="ltx_td ltx_align_left" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S6.T2.17.20.1.1" class="ltx_text ltx_font_bold">Altered Name Entity</span></td>
<td id="S6.T2.17.20.2" class="ltx_td ltx_align_right" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S6.T2.17.20.2.1" class="ltx_text ltx_font_bold">66.87%</span></td>
<td id="S6.T2.17.20.3" class="ltx_td ltx_align_right" style="padding-left:2.7pt;padding-right:2.7pt;">60.78%</td>
<td id="S6.T2.17.20.4" class="ltx_td ltx_align_right" style="padding-left:2.7pt;padding-right:2.7pt;">58.15%</td>
</tr>
<tr id="S6.T2.9.9" class="ltx_tr">
<td id="S6.T2.9.9.2" class="ltx_td ltx_align_left" style="padding-left:2.7pt;padding-right:2.7pt;" rowspan="3"><span id="S6.T2.9.9.2.1" class="ltx_text ltx_font_bold">Palm 2</span></td>
<td id="S6.T2.9.9.1" class="ltx_td ltx_align_left" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S6.T2.9.9.1.1" class="ltx_text ltx_font_bold">Original Table (<math id="S6.T2.9.9.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S6.T2.9.9.1.1.m1.1a"><mo stretchy="false" id="S6.T2.9.9.1.1.m1.1.1" xref="S6.T2.9.9.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S6.T2.9.9.1.1.m1.1b"><ci id="S6.T2.9.9.1.1.m1.1.1.cmml" xref="S6.T2.9.9.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.9.9.1.1.m1.1c">\uparrow</annotation></semantics></math>)</span></td>
<td id="S6.T2.9.9.3" class="ltx_td ltx_align_right" style="padding-left:2.7pt;padding-right:2.7pt;">69.75%</td>
<td id="S6.T2.9.9.4" class="ltx_td ltx_align_right" style="padding-left:2.7pt;padding-right:2.7pt;">77.29%</td>
<td id="S6.T2.9.9.5" class="ltx_td ltx_align_right" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S6.T2.9.9.5.1" class="ltx_text ltx_font_bold">79.58%</span></td>
</tr>
<tr id="S6.T2.10.10" class="ltx_tr">
<td id="S6.T2.10.10.1" class="ltx_td ltx_align_left" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S6.T2.10.10.1.1" class="ltx_text ltx_font_bold">Without Table (<math id="S6.T2.10.10.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S6.T2.10.10.1.1.m1.1a"><mo stretchy="false" id="S6.T2.10.10.1.1.m1.1.1" xref="S6.T2.10.10.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S6.T2.10.10.1.1.m1.1b"><ci id="S6.T2.10.10.1.1.m1.1.1.cmml" xref="S6.T2.10.10.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.10.10.1.1.m1.1c">\downarrow</annotation></semantics></math>)</span></td>
<td id="S6.T2.10.10.2" class="ltx_td ltx_align_right" style="padding-left:2.7pt;padding-right:2.7pt;">66.63%</td>
<td id="S6.T2.10.10.3" class="ltx_td ltx_align_right" style="padding-left:2.7pt;padding-right:2.7pt;">63.24%</td>
<td id="S6.T2.10.10.4" class="ltx_td ltx_align_right" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S6.T2.10.10.4.1" class="ltx_text ltx_font_bold">60.26%</span></td>
</tr>
<tr id="S6.T2.11.11" class="ltx_tr">
<td id="S6.T2.11.11.1" class="ltx_td ltx_align_left" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S6.T2.11.11.1.1" class="ltx_text ltx_font_bold">Altered Name Entity (<math id="S6.T2.11.11.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S6.T2.11.11.1.1.m1.1a"><mo stretchy="false" id="S6.T2.11.11.1.1.m1.1.1" xref="S6.T2.11.11.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S6.T2.11.11.1.1.m1.1b"><ci id="S6.T2.11.11.1.1.m1.1.1.cmml" xref="S6.T2.11.11.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.11.11.1.1.m1.1c">\uparrow</annotation></semantics></math>)</span></td>
<td id="S6.T2.11.11.2" class="ltx_td ltx_align_right" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S6.T2.11.11.2.1" class="ltx_text ltx_font_bold">82.10%</span></td>
<td id="S6.T2.11.11.3" class="ltx_td ltx_align_right" style="padding-left:2.7pt;padding-right:2.7pt;">71.34%</td>
<td id="S6.T2.11.11.4" class="ltx_td ltx_align_right" style="padding-left:2.7pt;padding-right:2.7pt;">74.97%</td>
</tr>
<tr id="S6.T2.12.12" class="ltx_tr">
<td id="S6.T2.12.12.2" class="ltx_td ltx_align_left" style="padding-left:2.7pt;padding-right:2.7pt;" rowspan="3"><span id="S6.T2.12.12.2.1" class="ltx_text ltx_font_bold">MISTRAL-2</span></td>
<td id="S6.T2.12.12.1" class="ltx_td ltx_align_left" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S6.T2.12.12.1.1" class="ltx_text ltx_font_bold">Original Table (<math id="S6.T2.12.12.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S6.T2.12.12.1.1.m1.1a"><mo stretchy="false" id="S6.T2.12.12.1.1.m1.1.1" xref="S6.T2.12.12.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S6.T2.12.12.1.1.m1.1b"><ci id="S6.T2.12.12.1.1.m1.1.1.cmml" xref="S6.T2.12.12.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.12.12.1.1.m1.1c">\uparrow</annotation></semantics></math>)</span></td>
<td id="S6.T2.12.12.3" class="ltx_td ltx_align_right" style="padding-left:2.7pt;padding-right:2.7pt;">64.87%</td>
<td id="S6.T2.12.12.4" class="ltx_td ltx_align_right" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S6.T2.12.12.4.1" class="ltx_text ltx_font_bold">69.37%</span></td>
<td id="S6.T2.12.12.5" class="ltx_td ltx_align_right" style="padding-left:2.7pt;padding-right:2.7pt;">69.30%</td>
</tr>
<tr id="S6.T2.13.13" class="ltx_tr">
<td id="S6.T2.13.13.1" class="ltx_td ltx_align_left" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S6.T2.13.13.1.1" class="ltx_text ltx_font_bold">Without Table (<math id="S6.T2.13.13.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S6.T2.13.13.1.1.m1.1a"><mo stretchy="false" id="S6.T2.13.13.1.1.m1.1.1" xref="S6.T2.13.13.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S6.T2.13.13.1.1.m1.1b"><ci id="S6.T2.13.13.1.1.m1.1.1.cmml" xref="S6.T2.13.13.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.13.13.1.1.m1.1c">\downarrow</annotation></semantics></math>)</span></td>
<td id="S6.T2.13.13.2" class="ltx_td ltx_align_right" style="padding-left:2.7pt;padding-right:2.7pt;">56.87%</td>
<td id="S6.T2.13.13.3" class="ltx_td ltx_align_right" style="padding-left:2.7pt;padding-right:2.7pt;">52.58%</td>
<td id="S6.T2.13.13.4" class="ltx_td ltx_align_right" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S6.T2.13.13.4.1" class="ltx_text ltx_font_bold">49.36%</span></td>
</tr>
<tr id="S6.T2.14.14" class="ltx_tr">
<td id="S6.T2.14.14.1" class="ltx_td ltx_align_left" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S6.T2.14.14.1.1" class="ltx_text ltx_font_bold">Altered Name Entity (<math id="S6.T2.14.14.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S6.T2.14.14.1.1.m1.1a"><mo stretchy="false" id="S6.T2.14.14.1.1.m1.1.1" xref="S6.T2.14.14.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S6.T2.14.14.1.1.m1.1b"><ci id="S6.T2.14.14.1.1.m1.1.1.cmml" xref="S6.T2.14.14.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.14.14.1.1.m1.1c">\uparrow</annotation></semantics></math>)</span></td>
<td id="S6.T2.14.14.2" class="ltx_td ltx_align_right" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S6.T2.14.14.2.1" class="ltx_text ltx_font_bold">74.87%</span></td>
<td id="S6.T2.14.14.3" class="ltx_td ltx_align_right" style="padding-left:2.7pt;padding-right:2.7pt;">63.55%</td>
<td id="S6.T2.14.14.4" class="ltx_td ltx_align_right" style="padding-left:2.7pt;padding-right:2.7pt;">64.83%</td>
</tr>
<tr id="S6.T2.15.15" class="ltx_tr">
<td id="S6.T2.15.15.2" class="ltx_td ltx_align_left ltx_border_bb" style="padding-left:2.7pt;padding-right:2.7pt;" rowspan="3"><span id="S6.T2.15.15.2.1" class="ltx_text"><span id="S6.T2.15.15.2.1.1" class="ltx_text"></span> <span id="S6.T2.15.15.2.1.2" class="ltx_text">
<span id="S6.T2.15.15.2.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S6.T2.15.15.2.1.2.1.1" class="ltx_tr">
<span id="S6.T2.15.15.2.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S6.T2.15.15.2.1.2.1.1.1.1" class="ltx_text ltx_font_bold">GEMINI 1.5</span></span></span>
</span></span> <span id="S6.T2.15.15.2.1.3" class="ltx_text"></span></span></td>
<td id="S6.T2.15.15.1" class="ltx_td ltx_align_left" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S6.T2.15.15.1.1" class="ltx_text ltx_font_bold">Original Table (<math id="S6.T2.15.15.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S6.T2.15.15.1.1.m1.1a"><mo stretchy="false" id="S6.T2.15.15.1.1.m1.1.1" xref="S6.T2.15.15.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S6.T2.15.15.1.1.m1.1b"><ci id="S6.T2.15.15.1.1.m1.1.1.cmml" xref="S6.T2.15.15.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.15.15.1.1.m1.1c">\uparrow</annotation></semantics></math>)</span></td>
<td id="S6.T2.15.15.3" class="ltx_td ltx_align_right" style="padding-left:2.7pt;padding-right:2.7pt;">73.17%</td>
<td id="S6.T2.15.15.4" class="ltx_td ltx_align_right" style="padding-left:2.7pt;padding-right:2.7pt;">80.34%</td>
<td id="S6.T2.15.15.5" class="ltx_td ltx_align_right" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S6.T2.15.15.5.1" class="ltx_text ltx_font_bold">83.28%</span></td>
</tr>
<tr id="S6.T2.16.16" class="ltx_tr">
<td id="S6.T2.16.16.1" class="ltx_td ltx_align_left" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S6.T2.16.16.1.1" class="ltx_text ltx_font_bold">Without Table (<math id="S6.T2.16.16.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S6.T2.16.16.1.1.m1.1a"><mo stretchy="false" id="S6.T2.16.16.1.1.m1.1.1" xref="S6.T2.16.16.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S6.T2.16.16.1.1.m1.1b"><ci id="S6.T2.16.16.1.1.m1.1.1.cmml" xref="S6.T2.16.16.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.16.16.1.1.m1.1c">\downarrow</annotation></semantics></math>)</span></td>
<td id="S6.T2.16.16.2" class="ltx_td ltx_align_right" style="padding-left:2.7pt;padding-right:2.7pt;">70.85%</td>
<td id="S6.T2.16.16.3" class="ltx_td ltx_align_right" style="padding-left:2.7pt;padding-right:2.7pt;">69.19%</td>
<td id="S6.T2.16.16.4" class="ltx_td ltx_align_right" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S6.T2.16.16.4.1" class="ltx_text ltx_font_bold">68.64%</span></td>
</tr>
<tr id="S6.T2.17.17" class="ltx_tr">
<td id="S6.T2.17.17.1" class="ltx_td ltx_align_left ltx_border_bb" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S6.T2.17.17.1.1" class="ltx_text ltx_font_bold">Altered Name Entity (<math id="S6.T2.17.17.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S6.T2.17.17.1.1.m1.1a"><mo stretchy="false" id="S6.T2.17.17.1.1.m1.1.1" xref="S6.T2.17.17.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S6.T2.17.17.1.1.m1.1b"><ci id="S6.T2.17.17.1.1.m1.1.1.cmml" xref="S6.T2.17.17.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.17.17.1.1.m1.1c">\uparrow</annotation></semantics></math>)</span></td>
<td id="S6.T2.17.17.2" class="ltx_td ltx_align_right ltx_border_bb" style="padding-left:2.7pt;padding-right:2.7pt;">79.02%</td>
<td id="S6.T2.17.17.3" class="ltx_td ltx_align_right ltx_border_bb" style="padding-left:2.7pt;padding-right:2.7pt;">71.24%</td>
<td id="S6.T2.17.17.4" class="ltx_td ltx_align_right ltx_border_bb" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S6.T2.17.17.4.1" class="ltx_text ltx_font_bold">79.75%</span></td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>This table provides a comparison among C.L.E.A.R, zero-shot CoT, and few-shot CoT prompts across Original Table, No Table, and Altered Named Entity tasks in evidence-based reasoning. We evaluate performance using GPT-4o, GPT-3.5 Turbo, LLAMA-7B-Chat, PaLM-2, MISTRAL-7B, and Gemini 1.5 Pro Fash models in our experiments.</figcaption>
</figure>
<div id="S6.SS2.SSS0.Px1.p4" class="ltx_para">
<p id="S6.SS2.SSS0.Px1.p4.1" class="ltx_p"><span id="S6.SS2.SSS0.Px1.p4.1.1" class="ltx_text ltx_font_bold">(c) Missing Relevant Row.</span> We observe in Table <a href="#S6.T3" title="Table 3 ‣ Results and Analysis. ‣ 6.2 Efficacy of C.L.E.A.R ‣ 6 Results and Analysis ‣ Enhancing Temporal Understanding in LLMs for Semi-structured Tables" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, C.L.E.A.R outperforms others across all models with the original prompt. It shows the largest performance decline compared to zero-shot and few-shot CoT. This trend continues with the modified prompt, where our method remains superior, except for GPT-4, where zero-shot performs slightly better. Prompting creates an additional drop of <a href="~" title="" class="ltx_ref ltx_url ltx_font_typewriter">~</a>1-5% in all models. Explicitly informing the model about the availability of information promotes context-driven responses over reliance on memorized data.</p>
</div>
<div id="S6.SS2.SSS0.Px1.p5" class="ltx_para">
<p id="S6.SS2.SSS0.Px1.p5.1" class="ltx_p"><span id="S6.SS2.SSS0.Px1.p5.1.1" class="ltx_text ltx_font_bold">(d) Information Absence Detection</span> In Table <a href="#S6.T3" title="Table 3 ‣ Results and Analysis. ‣ 6.2 Efficacy of C.L.E.A.R ‣ 6 Results and Analysis ‣ Enhancing Temporal Understanding in LLMs for Semi-structured Tables" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, our method outperforms zero-shot and few-shot CoT with the original prompt across all models. Llama achieves the highest accuracy at 40.05%, followed by GPT-3.5 at 31.71%. With the updated prompt, our technique consistently performs best for all models. Gemini 1.5 Pro Flash achieves the highest accuracy at 91.45%, with GPT-4O close behind at 90.65</p>
</div>
<figure id="S6.T3" class="ltx_table">
<table id="S6.T3.2" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S6.T3.2.3" class="ltx_tr">
<td id="S6.T3.2.3.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" style="padding-left:2.1pt;padding-right:2.1pt;"><span id="S6.T3.2.3.1.1" class="ltx_text ltx_font_bold">Models</span></td>
<td id="S6.T3.2.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:2.1pt;padding-right:2.1pt;" colspan="3"><span id="S6.T3.2.3.2.1" class="ltx_text ltx_font_bold">Original Prompt</span></td>
<td id="S6.T3.2.3.3" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:2.1pt;padding-right:2.1pt;" colspan="3"><span id="S6.T3.2.3.3.1" class="ltx_text ltx_font_bold">Updated Prompt</span></td>
</tr>
<tr id="S6.T3.2.4" class="ltx_tr">
<td id="S6.T3.2.4.1" class="ltx_td ltx_border_r ltx_border_t" style="padding-left:2.1pt;padding-right:2.1pt;"></td>
<td id="S6.T3.2.4.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.1pt;padding-right:2.1pt;" colspan="2"><span id="S6.T3.2.4.2.1" class="ltx_text ltx_font_bold">CoT</span></td>
<td id="S6.T3.2.4.3" class="ltx_td ltx_border_r ltx_border_t" style="padding-left:2.1pt;padding-right:2.1pt;"></td>
<td id="S6.T3.2.4.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.1pt;padding-right:2.1pt;" colspan="2"><span id="S6.T3.2.4.4.1" class="ltx_text ltx_font_bold">CoT</span></td>
<td id="S6.T3.2.4.5" class="ltx_td ltx_border_t" style="padding-left:2.1pt;padding-right:2.1pt;"></td>
</tr>
<tr id="S6.T3.2.5" class="ltx_tr">
<td id="S6.T3.2.5.1" class="ltx_td ltx_border_r" style="padding-left:2.1pt;padding-right:2.1pt;"></td>
<td id="S6.T3.2.5.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.1pt;padding-right:2.1pt;"><span id="S6.T3.2.5.2.1" class="ltx_text ltx_font_bold">Z.S</span></td>
<td id="S6.T3.2.5.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.1pt;padding-right:2.1pt;"><span id="S6.T3.2.5.3.1" class="ltx_text ltx_font_bold">F.S</span></td>
<td id="S6.T3.2.5.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.1pt;padding-right:2.1pt;"><span id="S6.T3.2.5.4.1" class="ltx_text ltx_font_bold">C.L.E.A.R</span></td>
<td id="S6.T3.2.5.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.1pt;padding-right:2.1pt;"><span id="S6.T3.2.5.5.1" class="ltx_text ltx_font_bold">Z.S</span></td>
<td id="S6.T3.2.5.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.1pt;padding-right:2.1pt;"><span id="S6.T3.2.5.6.1" class="ltx_text ltx_font_bold">F.S</span></td>
<td id="S6.T3.2.5.7" class="ltx_td ltx_align_center" style="padding-left:2.1pt;padding-right:2.1pt;"><span id="S6.T3.2.5.7.1" class="ltx_text ltx_font_bold">C.L.E.A.R</span></td>
</tr>
<tr id="S6.T3.1.1" class="ltx_tr">
<td id="S6.T3.1.1.2" class="ltx_td ltx_border_r ltx_border_t" style="padding-left:2.1pt;padding-right:2.1pt;"></td>
<td id="S6.T3.1.1.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.1pt;padding-right:2.1pt;" colspan="6"><span id="S6.T3.1.1.1.1" class="ltx_text ltx_font_bold">Missing Relevant Rows (Lower (<math id="S6.T3.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S6.T3.1.1.1.1.m1.1a"><mo stretchy="false" id="S6.T3.1.1.1.1.m1.1.1" xref="S6.T3.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S6.T3.1.1.1.1.m1.1b"><ci id="S6.T3.1.1.1.1.m1.1.1.cmml" xref="S6.T3.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T3.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math>) is better)</span></td>
</tr>
<tr id="S6.T3.2.6" class="ltx_tr">
<td id="S6.T3.2.6.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:2.1pt;padding-right:2.1pt;"><span id="S6.T3.2.6.1.1" class="ltx_text ltx_font_bold">GPT 4O</span></td>
<td id="S6.T3.2.6.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.1pt;padding-right:2.1pt;">69.71%</td>
<td id="S6.T3.2.6.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.1pt;padding-right:2.1pt;">70.89%</td>
<td id="S6.T3.2.6.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.1pt;padding-right:2.1pt;"><span id="S6.T3.2.6.4.1" class="ltx_text ltx_font_bold">62.82%</span></td>
<td id="S6.T3.2.6.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.1pt;padding-right:2.1pt;"><span id="S6.T3.2.6.5.1" class="ltx_text ltx_font_bold">6.89%</span></td>
<td id="S6.T3.2.6.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.1pt;padding-right:2.1pt;">8.34%</td>
<td id="S6.T3.2.6.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.1pt;padding-right:2.1pt;">7.30%</td>
</tr>
<tr id="S6.T3.2.7" class="ltx_tr">
<td id="S6.T3.2.7.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:2.1pt;padding-right:2.1pt;"><span id="S6.T3.2.7.1.1" class="ltx_text ltx_font_bold">GPT 3.5</span></td>
<td id="S6.T3.2.7.2" class="ltx_td ltx_align_center" style="padding-left:2.1pt;padding-right:2.1pt;">60.06%</td>
<td id="S6.T3.2.7.3" class="ltx_td ltx_align_center" style="padding-left:2.1pt;padding-right:2.1pt;">56.59%</td>
<td id="S6.T3.2.7.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.1pt;padding-right:2.1pt;"><span id="S6.T3.2.7.4.1" class="ltx_text ltx_font_bold">49.46%</span></td>
<td id="S6.T3.2.7.5" class="ltx_td ltx_align_center" style="padding-left:2.1pt;padding-right:2.1pt;">11.60%</td>
<td id="S6.T3.2.7.6" class="ltx_td ltx_align_center" style="padding-left:2.1pt;padding-right:2.1pt;">13.05%</td>
<td id="S6.T3.2.7.7" class="ltx_td ltx_align_center" style="padding-left:2.1pt;padding-right:2.1pt;"><span id="S6.T3.2.7.7.1" class="ltx_text ltx_font_bold">11.39%</span></td>
</tr>
<tr id="S6.T3.2.8" class="ltx_tr">
<td id="S6.T3.2.8.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:2.1pt;padding-right:2.1pt;"><span id="S6.T3.2.8.1.1" class="ltx_text ltx_font_bold">LLAMA 7B</span></td>
<td id="S6.T3.2.8.2" class="ltx_td ltx_align_center" style="padding-left:2.1pt;padding-right:2.1pt;">64.42%</td>
<td id="S6.T3.2.8.3" class="ltx_td ltx_align_center" style="padding-left:2.1pt;padding-right:2.1pt;">37.69%</td>
<td id="S6.T3.2.8.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.1pt;padding-right:2.1pt;"><span id="S6.T3.2.8.4.1" class="ltx_text ltx_font_bold">24.92%</span></td>
<td id="S6.T3.2.8.5" class="ltx_td ltx_align_center" style="padding-left:2.1pt;padding-right:2.1pt;">26.10%</td>
<td id="S6.T3.2.8.6" class="ltx_td ltx_align_center" style="padding-left:2.1pt;padding-right:2.1pt;">16.13%</td>
<td id="S6.T3.2.8.7" class="ltx_td ltx_align_center" style="padding-left:2.1pt;padding-right:2.1pt;"><span id="S6.T3.2.8.7.1" class="ltx_text ltx_font_bold">11.18%</span></td>
</tr>
<tr id="S6.T3.2.9" class="ltx_tr">
<td id="S6.T3.2.9.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:2.1pt;padding-right:2.1pt;"><span id="S6.T3.2.9.1.1" class="ltx_text ltx_font_bold">PALM 2</span></td>
<td id="S6.T3.2.9.2" class="ltx_td ltx_align_center" style="padding-left:2.1pt;padding-right:2.1pt;">78.40%</td>
<td id="S6.T3.2.9.3" class="ltx_td ltx_align_center" style="padding-left:2.1pt;padding-right:2.1pt;">61.68%</td>
<td id="S6.T3.2.9.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.1pt;padding-right:2.1pt;"><span id="S6.T3.2.9.4.1" class="ltx_text ltx_font_bold">55.90%</span></td>
<td id="S6.T3.2.9.5" class="ltx_td ltx_align_center" style="padding-left:2.1pt;padding-right:2.1pt;">10.90%</td>
<td id="S6.T3.2.9.6" class="ltx_td ltx_align_center" style="padding-left:2.1pt;padding-right:2.1pt;">8.27%</td>
<td id="S6.T3.2.9.7" class="ltx_td ltx_align_center" style="padding-left:2.1pt;padding-right:2.1pt;"><span id="S6.T3.2.9.7.1" class="ltx_text ltx_font_bold">7.58%</span></td>
</tr>
<tr id="S6.T3.2.10" class="ltx_tr">
<td id="S6.T3.2.10.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:2.1pt;padding-right:2.1pt;"><span id="S6.T3.2.10.1.1" class="ltx_text ltx_font_bold">MISTRAL-2</span></td>
<td id="S6.T3.2.10.2" class="ltx_td ltx_align_center" style="padding-left:2.1pt;padding-right:2.1pt;">69.92%</td>
<td id="S6.T3.2.10.3" class="ltx_td ltx_align_center" style="padding-left:2.1pt;padding-right:2.1pt;">50.85%</td>
<td id="S6.T3.2.10.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.1pt;padding-right:2.1pt;"><span id="S6.T3.2.10.4.1" class="ltx_text ltx_font_bold">39.84%</span></td>
<td id="S6.T3.2.10.5" class="ltx_td ltx_align_center" style="padding-left:2.1pt;padding-right:2.1pt;">16.44%</td>
<td id="S6.T3.2.10.6" class="ltx_td ltx_align_center" style="padding-left:2.1pt;padding-right:2.1pt;">13.08%</td>
<td id="S6.T3.2.10.7" class="ltx_td ltx_align_center" style="padding-left:2.1pt;padding-right:2.1pt;"><span id="S6.T3.2.10.7.1" class="ltx_text ltx_font_bold">10.76%</span></td>
</tr>
<tr id="S6.T3.2.11" class="ltx_tr">
<td id="S6.T3.2.11.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:2.1pt;padding-right:2.1pt;"><span id="S6.T3.2.11.1.1" class="ltx_text ltx_font_bold">GEMINI 1.5</span></td>
<td id="S6.T3.2.11.2" class="ltx_td ltx_align_center" style="padding-left:2.1pt;padding-right:2.1pt;">76.25%</td>
<td id="S6.T3.2.11.3" class="ltx_td ltx_align_center" style="padding-left:2.1pt;padding-right:2.1pt;">68.05%</td>
<td id="S6.T3.2.11.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.1pt;padding-right:2.1pt;"><span id="S6.T3.2.11.4.1" class="ltx_text ltx_font_bold">57.29%</span></td>
<td id="S6.T3.2.11.5" class="ltx_td ltx_align_center" style="padding-left:2.1pt;padding-right:2.1pt;">9.07%</td>
<td id="S6.T3.2.11.6" class="ltx_td ltx_align_center" style="padding-left:2.1pt;padding-right:2.1pt;">8.45%</td>
<td id="S6.T3.2.11.7" class="ltx_td ltx_align_center" style="padding-left:2.1pt;padding-right:2.1pt;"><span id="S6.T3.2.11.7.1" class="ltx_text ltx_font_bold">7.34%</span></td>
</tr>
<tr id="S6.T3.2.2" class="ltx_tr">
<td id="S6.T3.2.2.2" class="ltx_td ltx_border_r ltx_border_t" style="padding-left:2.1pt;padding-right:2.1pt;"></td>
<td id="S6.T3.2.2.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.1pt;padding-right:2.1pt;" colspan="6"><span id="S6.T3.2.2.1.1" class="ltx_text ltx_font_bold">Information Absence Detection (Higher (<math id="S6.T3.2.2.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S6.T3.2.2.1.1.m1.1a"><mo stretchy="false" id="S6.T3.2.2.1.1.m1.1.1" xref="S6.T3.2.2.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S6.T3.2.2.1.1.m1.1b"><ci id="S6.T3.2.2.1.1.m1.1.1.cmml" xref="S6.T3.2.2.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T3.2.2.1.1.m1.1c">\uparrow</annotation></semantics></math>) is better</span></td>
</tr>
<tr id="S6.T3.2.12" class="ltx_tr">
<td id="S6.T3.2.12.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:2.1pt;padding-right:2.1pt;"><span id="S6.T3.2.12.1.1" class="ltx_text ltx_font_bold">GPT 4O</span></td>
<td id="S6.T3.2.12.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.1pt;padding-right:2.1pt;">19.45%</td>
<td id="S6.T3.2.12.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.1pt;padding-right:2.1pt;">22.71%</td>
<td id="S6.T3.2.12.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.1pt;padding-right:2.1pt;"><span id="S6.T3.2.12.4.1" class="ltx_text ltx_font_bold">25.16%</span></td>
<td id="S6.T3.2.12.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.1pt;padding-right:2.1pt;">89.89%</td>
<td id="S6.T3.2.12.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.1pt;padding-right:2.1pt;">88.85%</td>
<td id="S6.T3.2.12.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.1pt;padding-right:2.1pt;"><span id="S6.T3.2.12.7.1" class="ltx_text ltx_font_bold">90.65%</span></td>
</tr>
<tr id="S6.T3.2.13" class="ltx_tr">
<td id="S6.T3.2.13.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:2.1pt;padding-right:2.1pt;"><span id="S6.T3.2.13.1.1" class="ltx_text ltx_font_bold">GPT 3.5</span></td>
<td id="S6.T3.2.13.2" class="ltx_td ltx_align_center" style="padding-left:2.1pt;padding-right:2.1pt;">27.83%</td>
<td id="S6.T3.2.13.3" class="ltx_td ltx_align_center" style="padding-left:2.1pt;padding-right:2.1pt;">29.73%</td>
<td id="S6.T3.2.13.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.1pt;padding-right:2.1pt;"><span id="S6.T3.2.13.4.1" class="ltx_text ltx_font_bold">31.71%</span></td>
<td id="S6.T3.2.13.5" class="ltx_td ltx_align_center" style="padding-left:2.1pt;padding-right:2.1pt;">79.75%</td>
<td id="S6.T3.2.13.6" class="ltx_td ltx_align_center" style="padding-left:2.1pt;padding-right:2.1pt;">79.47%</td>
<td id="S6.T3.2.13.7" class="ltx_td ltx_align_center" style="padding-left:2.1pt;padding-right:2.1pt;"><span id="S6.T3.2.13.7.1" class="ltx_text ltx_font_bold">82.07%</span></td>
</tr>
<tr id="S6.T3.2.14" class="ltx_tr">
<td id="S6.T3.2.14.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:2.1pt;padding-right:2.1pt;"><span id="S6.T3.2.14.1.1" class="ltx_text ltx_font_bold">LLAMA 7B</span></td>
<td id="S6.T3.2.14.2" class="ltx_td ltx_align_center" style="padding-left:2.1pt;padding-right:2.1pt;">25.37%</td>
<td id="S6.T3.2.14.3" class="ltx_td ltx_align_center" style="padding-left:2.1pt;padding-right:2.1pt;">34.96%</td>
<td id="S6.T3.2.14.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.1pt;padding-right:2.1pt;"><span id="S6.T3.2.14.4.1" class="ltx_text ltx_font_bold">40.05%</span></td>
<td id="S6.T3.2.14.5" class="ltx_td ltx_align_center" style="padding-left:2.1pt;padding-right:2.1pt;">61.72%</td>
<td id="S6.T3.2.14.6" class="ltx_td ltx_align_center" style="padding-left:2.1pt;padding-right:2.1pt;">61.96%</td>
<td id="S6.T3.2.14.7" class="ltx_td ltx_align_center" style="padding-left:2.1pt;padding-right:2.1pt;"><span id="S6.T3.2.14.7.1" class="ltx_text ltx_font_bold">62.34%</span></td>
</tr>
<tr id="S6.T3.2.15" class="ltx_tr">
<td id="S6.T3.2.15.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:2.1pt;padding-right:2.1pt;"><span id="S6.T3.2.15.1.1" class="ltx_text ltx_font_bold">PALM 2</span></td>
<td id="S6.T3.2.15.2" class="ltx_td ltx_align_center" style="padding-left:2.1pt;padding-right:2.1pt;">19.21%</td>
<td id="S6.T3.2.15.3" class="ltx_td ltx_align_center" style="padding-left:2.1pt;padding-right:2.1pt;">23.68%</td>
<td id="S6.T3.2.15.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.1pt;padding-right:2.1pt;"><span id="S6.T3.2.15.4.1" class="ltx_text ltx_font_bold">29.11%</span></td>
<td id="S6.T3.2.15.5" class="ltx_td ltx_align_center" style="padding-left:2.1pt;padding-right:2.1pt;">86.43%</td>
<td id="S6.T3.2.15.6" class="ltx_td ltx_align_center" style="padding-left:2.1pt;padding-right:2.1pt;">86.78%</td>
<td id="S6.T3.2.15.7" class="ltx_td ltx_align_center" style="padding-left:2.1pt;padding-right:2.1pt;"><span id="S6.T3.2.15.7.1" class="ltx_text ltx_font_bold">88.44%</span></td>
</tr>
<tr id="S6.T3.2.16" class="ltx_tr">
<td id="S6.T3.2.16.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:2.1pt;padding-right:2.1pt;"><span id="S6.T3.2.16.1.1" class="ltx_text ltx_font_bold">MISTRAL-2</span></td>
<td id="S6.T3.2.16.2" class="ltx_td ltx_align_center" style="padding-left:2.1pt;padding-right:2.1pt;">21.05%</td>
<td id="S6.T3.2.16.3" class="ltx_td ltx_align_center" style="padding-left:2.1pt;padding-right:2.1pt;">29.42%</td>
<td id="S6.T3.2.16.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.1pt;padding-right:2.1pt;"><span id="S6.T3.2.16.4.1" class="ltx_text ltx_font_bold">32.71%</span></td>
<td id="S6.T3.2.16.5" class="ltx_td ltx_align_center" style="padding-left:2.1pt;padding-right:2.1pt;">75.42%</td>
<td id="S6.T3.2.16.6" class="ltx_td ltx_align_center" style="padding-left:2.1pt;padding-right:2.1pt;">74.49%</td>
<td id="S6.T3.2.16.7" class="ltx_td ltx_align_center" style="padding-left:2.1pt;padding-right:2.1pt;"><span id="S6.T3.2.16.7.1" class="ltx_text ltx_font_bold">77.09%</span></td>
</tr>
<tr id="S6.T3.2.17" class="ltx_tr">
<td id="S6.T3.2.17.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" style="padding-left:2.1pt;padding-right:2.1pt;"><span id="S6.T3.2.17.1.1" class="ltx_text ltx_font_bold">GEMINI 1.5</span></td>
<td id="S6.T3.2.17.2" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:2.1pt;padding-right:2.1pt;">15.82%</td>
<td id="S6.T3.2.17.3" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:2.1pt;padding-right:2.1pt;">22.33%</td>
<td id="S6.T3.2.17.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="padding-left:2.1pt;padding-right:2.1pt;"><span id="S6.T3.2.17.4.1" class="ltx_text ltx_font_bold">25.23%</span></td>
<td id="S6.T3.2.17.5" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:2.1pt;padding-right:2.1pt;">89.48%</td>
<td id="S6.T3.2.17.6" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:2.1pt;padding-right:2.1pt;">87.61%</td>
<td id="S6.T3.2.17.7" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:2.1pt;padding-right:2.1pt;"><span id="S6.T3.2.17.7.1" class="ltx_text ltx_font_bold">91.45%</span></td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>This table compares C.L.E.A.R, zero-shot CoT, and few-shot CoT prompts for tasks involving Missing Relevant Rows and Information Absence Detection in evidence-based reasoning, considering both original and changed prompts. Experimental evaluations are conducted using GPT-4o, GPT-3.5 Turbo, LLAMA-7B-Chat, PaLM-2, MISTRAL-7B, and Gemini 1.5 Pro Fash models.</figcaption>
</figure>
</section>
</section>
<section id="S6.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.3 </span>Auxiliary Data Fine Tuning</h3>

<div id="S6.SS3.p1" class="ltx_para">
<p id="S6.SS3.p1.1" class="ltx_p">C.L.E.A.R enhances the model’s capacity to process and reason with context. It facilitates effective instruction for models to handle temporal questions and improve evidence-based reasoning. However, prompting alone does not adjust their inherent parameters, so models do not intrinsically improve. Innate enhancement in models requires fine-tuning, so that their parameters better reflect improved temporal reasoning capabilities. We suggest fine-tuning the model on simple auxiliary data to enhance its ability to reason across diverse data formats and improve overall reasoning capabilities.</p>
</div>
<section id="S6.SS3.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Why TRAM dataset?</h4>

<div id="S6.SS3.SSS0.Px1.p1" class="ltx_para">
<p id="S6.SS3.SSS0.Px1.p1.1" class="ltx_p">We evaluated the impact of fine-tuning GPT-3.5 Turbo using the auxiliary datasets discussed in Section <a href="#S5" title="5 Experimental Setup ‣ Enhancing Temporal Understanding in LLMs for Semi-structured Tables" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, along with the TempTabQA dataset. For this evaluation, we fine-tuned with 100 examples from each dataset.</p>
</div>
<figure id="S6.T4" class="ltx_table">
<table id="S6.T4.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S6.T4.1.1" class="ltx_tr">
<td id="S6.T4.1.1.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S6.T4.1.1.1.1" class="ltx_text ltx_font_bold">Train Dataset</span></td>
<td id="S6.T4.1.1.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S6.T4.1.1.2.1" class="ltx_text ltx_font_bold">Exact Match</span></td>
</tr>
<tr id="S6.T4.1.2" class="ltx_tr">
<td id="S6.T4.1.2.1" class="ltx_td ltx_align_left ltx_border_t">No fine-tuning</td>
<td id="S6.T4.1.2.2" class="ltx_td ltx_align_center ltx_border_t">73.49%</td>
</tr>
<tr id="S6.T4.1.3" class="ltx_tr">
<td id="S6.T4.1.3.1" class="ltx_td ltx_align_left">DATE</td>
<td id="S6.T4.1.3.2" class="ltx_td ltx_align_center">74.28%</td>
</tr>
<tr id="S6.T4.1.4" class="ltx_tr">
<td id="S6.T4.1.4.1" class="ltx_td ltx_align_left">Temporal Sequences</td>
<td id="S6.T4.1.4.2" class="ltx_td ltx_align_center">74.42%</td>
</tr>
<tr id="S6.T4.1.5" class="ltx_tr">
<td id="S6.T4.1.5.1" class="ltx_td ltx_align_left">TRAM</td>
<td id="S6.T4.1.5.2" class="ltx_td ltx_align_center">75.53%</td>
</tr>
<tr id="S6.T4.1.6" class="ltx_tr">
<td id="S6.T4.1.6.1" class="ltx_td ltx_align_left ltx_border_bb">TempTabQA</td>
<td id="S6.T4.1.6.2" class="ltx_td ltx_align_center ltx_border_bb">77.81%</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>This table showcases the performance of GPT-3.5 Turbo following fine-tuning on auxiliary datasets within a zero-shot chain-of-thought (CoT) setting."</figcaption>
</figure>
<div id="S6.SS3.SSS0.Px1.p2" class="ltx_para">
<p id="S6.SS3.SSS0.Px1.p2.1" class="ltx_p"><span id="S6.SS3.SSS0.Px1.p2.1.1" class="ltx_text ltx_font_italic">Analysis.</span> Table <a href="#S6.T4" title="Table 4 ‣ Why TRAM dataset? ‣ 6.3 Auxiliary Data Fine Tuning ‣ 6 Results and Analysis ‣ Enhancing Temporal Understanding in LLMs for Semi-structured Tables" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> shows that the TRAM dataset offers the largest performance improvement among auxiliary datasets. While DATE and Temporal Sequences datasets provide gains of less than 1.01%, TRAM achieves a significant 2.04% boost compared to the base model without fine-tuning. These findings emphasize TRAM’s unique advantages. DATE focuses solely on date-based reasoning, and Temporal Sequences on temporal reasoning across events. In contrast, TRAM includes 10 sub-datasets covering diverse temporal reasoning tasks. It includes tasks such as <em id="S6.SS3.SSS0.Px1.p2.1.2" class="ltx_emph ltx_font_italic">Ordering, Frequency, Duration, Typical time, Ambiguity Resolution, Arithmetic, Relations, Temporal NLI, Causality and Storytelling</em>. Each task have multiple question type including <em id="S6.SS3.SSS0.Px1.p2.1.3" class="ltx_emph ltx_font_italic">Commonsense, Facts, Reading Comprehension, Application, Computation, Direct &amp; Multi-step Comparison, Interpretation, Calender shift, Long-term, Mid-term &amp; Short-term shift, Date Computation, 12 &amp; 24 hour adjustment, Week Identification etc</em>. (For more information on TRAM, refer to Table <a href="#A1.T6" title="Table 6 ‣ Appendix A Appendix ‣ Enhancing Temporal Understanding in LLMs for Semi-structured Tables" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> in Appendix <a href="#A1" title="Appendix A Appendix ‣ Enhancing Temporal Understanding in LLMs for Semi-structured Tables" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A</span></a>). This diversity enhances performance by exposing models to varied temporal scenarios, improving overall comprehension in temporal domain.</p>
</div>
<div id="S6.SS3.SSS0.Px1.p3" class="ltx_para">
<p id="S6.SS3.SSS0.Px1.p3.1" class="ltx_p">The TRAM dataset’s significant gains highlight the importance of diverse auxiliary data for fine-tuning. By covering a wide range of temporal reasoning tasks, TRAM helps models grasp nuanced temporal relationships, enhancing performance across various challenges. This finding suggests that future efforts in model fine-tuning should consider leveraging similarly diverse datasets to maximize performance improvements.</p>
</div>
</section>
<section id="S6.SS3.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Fine-tuning on TRAM.</h4>

<div id="S6.SS3.SSS0.Px2.p1" class="ltx_para">
<p id="S6.SS3.SSS0.Px2.p1.1" class="ltx_p">We analyzed fine-tuning models on subsets of the TRAM dataset and TempTabQA, each with 100 and 1000 examples (evenly sampled across tasks), as shown in Table <a href="#S6.T1" title="Table 1 ‣ 6.1 C.L.E.A.R Prompting ‣ 6 Results and Analysis ‣ Enhancing Temporal Understanding in LLMs for Semi-structured Tables" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<div id="S6.SS3.SSS0.Px2.p2" class="ltx_para">
<p id="S6.SS3.SSS0.Px2.p2.1" class="ltx_p"><span id="S6.SS3.SSS0.Px2.p2.1.1" class="ltx_text ltx_font_italic">Analysis.</span> Our findings reveal that, on the TRAM dataset with fine-tuning on 100 examples, C.L.E.A.R outperforms all models except for LLAMA-2 7B. This trend is consistent with 1000 examples, where it slightly trails behind the few-shot CoT for GPT-3.5 turbo by a negligible margin of 0.07%.When fine-tuning models on TempTabQA with 100 examples and 1000 examples, our method demonstrates superior performance for GPT 3.5 turbo and PaLM-2, but underperforms for LLAMA-2 7B and Mistral-2 7B.</p>
</div>
<div id="S6.SS3.SSS0.Px2.p3" class="ltx_para">
<p id="S6.SS3.SSS0.Px2.p3.1" class="ltx_p">Our findings show that fine-tuning models with auxiliary data significantly improves performance, close to that of task-specific fine-tuning. This method enhances models’ ability to reason about temporal information and can be applied across various tasks. Additionally, auxiliary data typically provides richer resources compared to task-specific datasets. This scalability enables fine-tuning on larger datasets beyond traditional methods. <span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Due to computational limits, especially with GPT and Gemini models, we fine-tuned LLMs on just 1000 examples.</span></span></span></p>
</div>
</section>
</section>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Comparison with Related Work</h2>

<section id="S7.SS0.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Tabular Reasoning</h4>

<div id="S7.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S7.SS0.SSS0.Px1.p1.1" class="ltx_p">Recent research has extensively explored large language models’ applications with semi-structured tabular data <cite class="ltx_cite ltx_citemacro_cite">Chen et al. (<a href="#bib.bib7" title="" class="ltx_ref">2020b</a>); Gupta et al. (<a href="#bib.bib15" title="" class="ltx_ref">2020</a>); Zhang and Balog (<a href="#bib.bib54" title="" class="ltx_ref">2019</a>)</cite>, covering areas such as question answering and semantic parsing <cite class="ltx_cite ltx_citemacro_cite">Zhang et al. (<a href="#bib.bib56" title="" class="ltx_ref">2020b</a>); Zhang and Balog (<a href="#bib.bib55" title="" class="ltx_ref">2020</a>); Pasupat and Liang (<a href="#bib.bib36" title="" class="ltx_ref">2015</a>); Krishnamurthy et al. (<a href="#bib.bib24" title="" class="ltx_ref">2017</a>); Abbas et al. (<a href="#bib.bib1" title="" class="ltx_ref">2016</a>); Sun et al. (<a href="#bib.bib43" title="" class="ltx_ref">2016</a>); Chen et al. (<a href="#bib.bib9" title="" class="ltx_ref">2020c</a>); Lin et al. (<a href="#bib.bib26" title="" class="ltx_ref">2020</a>); Zayats et al. (<a href="#bib.bib50" title="" class="ltx_ref">2021</a>); Oguz et al. (<a href="#bib.bib34" title="" class="ltx_ref">2020</a>); Chen et al. (<a href="#bib.bib4" title="" class="ltx_ref">2021b</a>); Iyyer et al. (<a href="#bib.bib19" title="" class="ltx_ref">2017</a>)</cite>, as well as table-to-text generation <cite class="ltx_cite ltx_citemacro_cite">Parikh et al. (<a href="#bib.bib35" title="" class="ltx_ref">2020</a>); Li et al. (<a href="#bib.bib25" title="" class="ltx_ref">2021</a>); Nan et al. (<a href="#bib.bib29" title="" class="ltx_ref">2021</a>); Yoran et al. (<a href="#bib.bib48" title="" class="ltx_ref">2021</a>); Chen et al. (<a href="#bib.bib5" title="" class="ltx_ref">2020a</a>)</cite>. Various datasets and models have emerged to handle semi-structured data, including Table2vec <cite class="ltx_cite ltx_citemacro_cite">Zhang et al. (<a href="#bib.bib52" title="" class="ltx_ref">2019</a>)</cite>, TAPAS <cite class="ltx_cite ltx_citemacro_cite">Herzig et al. (<a href="#bib.bib16" title="" class="ltx_ref">2020</a>)</cite>, TaBERT <cite class="ltx_cite ltx_citemacro_cite">Yin et al. (<a href="#bib.bib47" title="" class="ltx_ref">2020</a>)</cite>, TabStruc <cite class="ltx_cite ltx_citemacro_cite">Zhang et al. (<a href="#bib.bib51" title="" class="ltx_ref">2020a</a>)</cite>, TABBIE <cite class="ltx_cite ltx_citemacro_cite">Iida et al. (<a href="#bib.bib17" title="" class="ltx_ref">2021</a>)</cite>, TabGCN <cite class="ltx_cite ltx_citemacro_cite">Pramanick and Bhattacharya (<a href="#bib.bib37" title="" class="ltx_ref">2021</a>)</cite>, and RCI <cite class="ltx_cite ltx_citemacro_cite">Glass et al. (<a href="#bib.bib12" title="" class="ltx_ref">2021</a>)</cite>, all aimed at improving understanding and representation of tabular data. Research has also focused on fine-tuning models for enhanced inference on tabular data, as demonstrated by studies <cite class="ltx_cite ltx_citemacro_cite">Yu et al. (<a href="#bib.bib49" title="" class="ltx_ref">2018</a>); Eisenschlos et al. (<a href="#bib.bib11" title="" class="ltx_ref">2020</a>); Neeraja et al. (<a href="#bib.bib31" title="" class="ltx_ref">2021</a>)</cite>, showcasing targeted techniques to boost model performance.</p>
</div>
<div id="S7.SS0.SSS0.Px1.p2" class="ltx_para">
<p id="S7.SS0.SSS0.Px1.p2.1" class="ltx_p">Recently, <cite class="ltx_cite ltx_citemacro_cite">Srivastava et al. (<a href="#bib.bib41" title="" class="ltx_ref">2024</a>)</cite> introduced EEDP, a novel approach for financial document Question Answering. EEDP retrieves finance domain information, extracts relevant table rows, and decomposes mathematical tasks into atomic operations. Our method similarly involves understanding table data and extracting relevant rows, but we differentiate by systematically addressing sub-problems based on extracted evidence. This targeted approach makes our method well-suited for temporal tabular reasoning.</p>
</div>
</section>
<section id="S7.SS0.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Temporal Reasoning</h4>

<div id="S7.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S7.SS0.SSS0.Px2.p1.1" class="ltx_p">In temporal question answering, recent datasets like TIME-SENSITIVEQA <cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a href="#bib.bib8" title="" class="ltx_ref">2021c</a>)</cite> and TORQUE <cite class="ltx_cite ltx_citemacro_citep">(Ning et al., <a href="#bib.bib32" title="" class="ltx_ref">2020</a>)</cite> focus on entity-specific reading comprehension with time-sensitive questions. Other datasets like TEMPQA-WD <cite class="ltx_cite ltx_citemacro_citep">(Neelam et al., <a href="#bib.bib30" title="" class="ltx_ref">2022</a>)</cite>, CRONQUESTIONS <cite class="ltx_cite ltx_citemacro_citep">(Saxena et al., <a href="#bib.bib38" title="" class="ltx_ref">2021</a>)</cite>, and TEMPQUESTIONS <cite class="ltx_cite ltx_citemacro_citep">(Jia et al., <a href="#bib.bib20" title="" class="ltx_ref">2018a</a>)</cite> explore temporal links in knowledge graph embeddings. There are also open-domain <cite class="ltx_cite ltx_citemacro_citep">(Zhang and Choi, <a href="#bib.bib53" title="" class="ltx_ref">2021</a>)</cite> and cloze-form <cite class="ltx_cite ltx_citemacro_citep">(Dhingra et al., <a href="#bib.bib10" title="" class="ltx_ref">2022</a>)</cite> question-answering tasks, and event-centric datasets <cite class="ltx_cite ltx_citemacro_citep">(Ning et al., <a href="#bib.bib33" title="" class="ltx_ref">2018</a>; Wen et al., <a href="#bib.bib46" title="" class="ltx_ref">2021</a>; Chen et al., <a href="#bib.bib2" title="" class="ltx_ref">2021a</a>)</cite>. Models like CRONKBQA <cite class="ltx_cite ltx_citemacro_citep">(Saxena et al., <a href="#bib.bib38" title="" class="ltx_ref">2021</a>)</cite>, TEQUILA <cite class="ltx_cite ltx_citemacro_citep">(Jia et al., <a href="#bib.bib21" title="" class="ltx_ref">2018b</a>)</cite>, and others <cite class="ltx_cite ltx_citemacro_citep">(Jia et al., <a href="#bib.bib22" title="" class="ltx_ref">2021</a>; Shang et al., <a href="#bib.bib39" title="" class="ltx_ref">2021</a>; Mavromatis et al., <a href="#bib.bib28" title="" class="ltx_ref">2021</a>; Kannen et al., <a href="#bib.bib23" title="" class="ltx_ref">2022</a>)</cite> have been tailored for knowledge-based question answering with temporal considerations, often integrating temporal aspects during pre-training <cite class="ltx_cite ltx_citemacro_citep">(Dhingra et al., <a href="#bib.bib10" title="" class="ltx_ref">2022</a>; Iv et al., <a href="#bib.bib18" title="" class="ltx_ref">2022</a>)</cite>. Additionally, temporal reasoning across structured and unstructured data has seen advancements with works such as TempTabQA <cite class="ltx_cite ltx_citemacro_cite">Gupta et al. (<a href="#bib.bib14" title="" class="ltx_ref">2023</a>)</cite>, TRAM <cite class="ltx_cite ltx_citemacro_cite">Wang and Zhao (<a href="#bib.bib44" title="" class="ltx_ref">2024</a>)</cite>, Temporal Sequencescite <cite class="ltx_cite ltx_citemacro_cite">Srivastava et al. (<a href="#bib.bib40" title="" class="ltx_ref">2023</a>)</cite>, and DATE understanding <cite class="ltx_cite ltx_citemacro_cite">Srivastava et al. (<a href="#bib.bib40" title="" class="ltx_ref">2023</a>)</cite>, all addressing the challenge of handling temporal information effectively.</p>
</div>
<div id="S7.SS0.SSS0.Px2.p2" class="ltx_para">
<p id="S7.SS0.SSS0.Px2.p2.1" class="ltx_p">Our work focuses on enhancing temporal reasoning in tabular data. We introduce a novel prompting method to improve language models’ temporal reasoning abilities with tabular data. Additionally, we demonstrate the effectiveness of augmenting models’ temporal understanding using auxiliary data, a novel approach in the field. This combined approach significantly enhances temporal inference, paving the way for future advancements.</p>
</div>
</section>
</section>
<section id="S8" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8 </span>Conclusion and Future Work</h2>

<div id="S8.p1" class="ltx_para">
<p id="S8.p1.1" class="ltx_p">Our results demonstrate that C.L.E.A.R (Comprehend, Locate, Examine, Analyze, Resolve) prompting significantly enhances model performance, particularly in understanding tabular data and tasks requiring temporal reasoning. It promotes grounding LLMs in evidence context rather than relying solely on pre-trained knowledge. Moreover, fine-tuning LLMs with auxiliary temporal data has proven highly effective in enhancing temporal understanding. This study validates that integrating auxiliary data strengthens models’ temporal reasoning capabilities, thereby enhancing the robustness of large language models. For Future, we propose <span id="S8.p1.1.1" class="ltx_text ltx_font_bold">(a.) Generation of Synthetic Data:</span> Creating synthetic training data from temporal aspects of tabular data enhances model performance through diverse temporal exposure. <span id="S8.p1.1.2" class="ltx_text ltx_font_bold">(b.) Neuro-symbolic Learning:</span> Integrating neural networks with symbolic reasoning improves models’ understanding of temporal information for more effective solutions. <span id="S8.p1.1.3" class="ltx_text ltx_font_bold">(c.) Expanding C.L.E.A.R Prompting Applications:</span> Applying C.L.E.A.R prompting to diverse tasks and domains validates its versatility in natural language processing, enhancing reasoning with temporal information. <span id="S8.p1.1.4" class="ltx_text ltx_font_bold">(d.) Integration with Existing Models:</span> Seamlessly integrating C.L.E.A.R prompting and auxiliary data into existing models maximizes benefits without architectural changes.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Limitations</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">The experiments in this paper have been conducted exclusively on the English language. This study can be extended to a multilingual setting to evaluate the approach’s effectiveness across different languages. Additionally, the temporal datasets used in our study are limited to simple, entity-centric tables. Since structured data can exist in more complex forms, such as hierarchical tables, further research is necessary to assess the impact of our methods on these more complex structures.</p>
</div>
<div id="Sx1.p2" class="ltx_para">
<p id="Sx1.p2.1" class="ltx_p">Moreover, our computational limitations restricted us to fine-tuning models on only 1000 samples of auxiliary data. To fully understand the potential improvements from fine-tuning on auxiliary data, it is essential to explore the effects of fine-tuning on larger datasets. Future work should focus on overcoming these limitations to provide a comprehensive evaluation of our approach.</p>
</div>
</section>
<section id="Sx2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Ethics Statement</h2>

<div id="Sx2.p1" class="ltx_para">
<p id="Sx2.p1.1" class="ltx_p">We confirm that our work adheres to the highest ethical standards in research and publication. We will publicly release our code and enhanced evaluation set to enable the research community to validate and build upon our findings. We are committed to the responsible and fair use of computational linguistics methodologies. The claims in our paper accurately reflect the experimental results. While using black-box large language models introduces some stochasticity, we mitigate this by maintaining a fixed temperature. We utilize an AI assistive tools for writing while ensuring absence of bias. We provide comprehensive details on annotations, dataset splits, models used, and prompting methods tried, ensuring the reproducibility of our work.</p>
</div>
</section>
<section id="S9" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">9 </span>Acknowledgement</h2>

<div id="S9.p1" class="ltx_para">
<p id="S9.p1.1" class="ltx_p">Research was sponsored by the Army Research Office and was accomplished under Grant Number W911NF-20-1-0080. The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of the Army Research Office or the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for Government purposes notwithstanding any copyright notation herein. This work was partially funded by ONR Contract N00014-23-1-2365.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Abbas et al. (2016)</span>
<span class="ltx_bibblock">
Faheem Abbas, M. K. Malik, M. Rashid, and Rizwan Zafar. 2016.

</span>
<span class="ltx_bibblock">Wikiqa — a question answering system on wikipedia using freebase, dbpedia and infobox.

</span>
<span class="ltx_bibblock"><em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">2016 Sixth International Conference on Innovative Computing Technology (INTECH)</em>, pages 185–193.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2021a)</span>
<span class="ltx_bibblock">
Muhao Chen, Hongming Zhang, Qiang Ning, Manling Li, Heng Ji, Kathleen McKeown, and Dan Roth. 2021a.

</span>
<span class="ltx_bibblock">Event-centric natural language understanding.

</span>
<span class="ltx_bibblock">In <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics</em>.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen (2023)</span>
<span class="ltx_bibblock">
Wenhu Chen. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2023.findings-eacl.83" title="" class="ltx_ref ltx_href">Large language models are few(1)-shot table reasoners</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">Findings of the Association for Computational Linguistics: EACL 2023</em>, pages 1120–1130, Dubrovnik, Croatia. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2021b)</span>
<span class="ltx_bibblock">
Wenhu Chen, Ming-Wei Chang, Eva Schlinger, William Yang Wang, and William W. Cohen. 2021b.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://openreview.net/forum?id=MmCRswl1UYl" title="" class="ltx_ref ltx_href">Open question answering over tables and text</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations</em>.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2020a)</span>
<span class="ltx_bibblock">
Wenhu Chen, Jianshu Chen, Yu Su, Zhiyu Chen, and William Yang Wang. 2020a.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2020.acl-main.708" title="" class="ltx_ref ltx_href">Logical natural language generation from open-domain tables</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</em>, pages 7929–7942, Online. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2023)</span>
<span class="ltx_bibblock">
Wenhu Chen, Xueguang Ma, Xinyi Wang, and William W. Cohen. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2211.12588" title="" class="ltx_ref ltx_href">Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks</a>.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2020b)</span>
<span class="ltx_bibblock">
Wenhu Chen, Hongmin Wang, Jianshu Chen, Yunkai Zhang, Hong Wang, Shiyang Li, Xiyou Zhou, and William Yang Wang. 2020b.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://openreview.net/forum?id=rkeJRhNYDH" title="" class="ltx_ref ltx_href">Tabfact: A large-scale dataset for table-based fact verification</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations</em>.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2021c)</span>
<span class="ltx_bibblock">
Wenhu Chen, Xinyi Wang, and William Yang Wang. 2021c.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://openreview.net/forum?id=9-LSfSU74n-" title="" class="ltx_ref ltx_href">A dataset for answering time-sensitive questions</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2)</em>.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2020c)</span>
<span class="ltx_bibblock">
Wenhu Chen, Hanwen Zha, Zhiyu Chen, Wenhan Xiong, Hong Wang, and William Yang Wang. 2020c.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2020.findings-emnlp.91" title="" class="ltx_ref ltx_href">HybridQA: A dataset of multi-hop question answering over tabular and textual data</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">Findings of the Association for Computational Linguistics: EMNLP 2020</em>, pages 1026–1036, Online. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dhingra et al. (2022)</span>
<span class="ltx_bibblock">
Bhuwan Dhingra, Jeremy R. Cole, Julian Martin Eisenschlos, Daniel Gillick, Jacob Eisenstein, and William W. Cohen. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1162/tacl_a_00459" title="" class="ltx_ref ltx_href">Time-aware language models as temporal knowledge bases</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">Transactions of the Association for Computational Linguistics</em>, 10:257–273.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Eisenschlos et al. (2020)</span>
<span class="ltx_bibblock">
Julian Eisenschlos, Syrine Krichene, and Thomas Müller. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2020.findings-emnlp.27" title="" class="ltx_ref ltx_href">Understanding tables with intermediate pre-training</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">Findings of the Association for Computational Linguistics: EMNLP 2020</em>, pages 281–296, Online. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Glass et al. (2021)</span>
<span class="ltx_bibblock">
Michael Glass, Mustafa Canim, Alfio Gliozzo, Saneem Chemmengath, Vishwajeet Kumar, Rishav Chakravarti, Avi Sil, Feifei Pan, Samarth Bharadwaj, and Nicolas Rodolfo Fauceglia. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2021.naacl-main.96" title="" class="ltx_ref ltx_href">Capturing row and column semantics in transformer based question answering over tables</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</em>, pages 1212–1224, Online. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gupta et al. (2021)</span>
<span class="ltx_bibblock">
Vivek Gupta, Riyaz A. Bhat, Atreya Ghosal, Manish Srivastava, Maneesh Singh, and Vivek Srikumar. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2108.00578" title="" class="ltx_ref ltx_href">Is my model using the right evidence? systematic probes for examining evidence-based tabular reasoning</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2108.00578.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gupta et al. (2023)</span>
<span class="ltx_bibblock">
Vivek Gupta, Pranshu Kandoi, Mahek Vora, Shuo Zhang, Yujie He, Ridho Reinanda, and Vivek Srikumar. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2023.emnlp-main.149" title="" class="ltx_ref ltx_href">TempTabQA: Temporal question answering for semi-structured tables</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</em>, pages 2431–2453, Singapore. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gupta et al. (2020)</span>
<span class="ltx_bibblock">
Vivek Gupta, Maitrey Mehta, Pegah Nokhiz, and Vivek Srikumar. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2020.acl-main.210" title="" class="ltx_ref ltx_href">INFOTABS: Inference on tables as semi-structured data</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</em>, pages 2309–2324, Online. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Herzig et al. (2020)</span>
<span class="ltx_bibblock">
Jonathan Herzig, Pawel Krzysztof Nowak, Thomas Müller, Francesco Piccinno, and Julian Eisenschlos. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2020.acl-main.398" title="" class="ltx_ref ltx_href">Tapas: Weakly supervised table parsing via pre-training</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</em>. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Iida et al. (2021)</span>
<span class="ltx_bibblock">
Hiroshi Iida, Dung Thai, Varun Manjunatha, and Mohit Iyyer. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2105.02584" title="" class="ltx_ref ltx_href">Tabbie: Pretrained representations of tabular data</a>.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Iv et al. (2022)</span>
<span class="ltx_bibblock">
Robert Iv, Alexandre Passos, Sameer Singh, and Ming-Wei Chang. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2022.naacl-main.269" title="" class="ltx_ref ltx_href">FRUIT: Faithfully reflecting updated information in text</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</em>, pages 3670–3686, Seattle, United States. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Iyyer et al. (2017)</span>
<span class="ltx_bibblock">
Mohit Iyyer, Wen-tau Yih, and Ming-Wei Chang. 2017.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/P17-1167" title="" class="ltx_ref ltx_href">Search-based neural structured learning for sequential question answering</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pages 1821–1831, Vancouver, Canada. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jia et al. (2018a)</span>
<span class="ltx_bibblock">
Zhen Jia, Abdalghani Abujabal, Rishiraj Saha Roy, Jannik Strötgen, and Gerhard Weikum. 2018a.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1145/3184558.3191536" title="" class="ltx_ref ltx_href">Tempquestions: A benchmark for temporal question answering</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">Companion Proceedings of the The Web Conference 2018</em>, WWW ’18, page 1057–1062, Republic and Canton of Geneva, CHE. International World Wide Web Conferences Steering Committee.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jia et al. (2018b)</span>
<span class="ltx_bibblock">
Zhen Jia, Abdalghani Abujabal, Rishiraj Saha Roy, Jannik Strötgen, and Gerhard Weikum. 2018b.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1145/3269206.3269247" title="" class="ltx_ref ltx_href">TEQUILA: Temporal Question Answering over Knowledge Bases</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 27th ACM International Conference on Information and Knowledge Management</em>, CIKM ’18, pages 1807–1810, New York, NY, USA. ACM.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jia et al. (2021)</span>
<span class="ltx_bibblock">
Zhen Jia, Soumajit Pramanik, Rishiraj Saha Roy, and Gerhard Weikum. 2021.

</span>
<span class="ltx_bibblock">Complex temporal question answering on knowledge graphs.

</span>
<span class="ltx_bibblock">In <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management</em>, pages 792–802.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kannen et al. (2022)</span>
<span class="ltx_bibblock">
Nithish Kannen, Udit Sharma, Sumit Neelam, Dinesh Khandelwal, Shajith Ikbal, Hima Karanam, and L Venkata Subramaniam. 2022.

</span>
<span class="ltx_bibblock">Targeted extraction of temporal facts from textual resources for improved temporal question answering over knowledge bases.

</span>
<span class="ltx_bibblock"><em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2203.11054</em>.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Krishnamurthy et al. (2017)</span>
<span class="ltx_bibblock">
Jayant Krishnamurthy, Pradeep Dasigi, and Matt Gardner. 2017.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/D17-1160" title="" class="ltx_ref ltx_href">Neural semantic parsing with type constraints for semi-structured tables</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</em>, pages 1516–1526, Copenhagen, Denmark. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2021)</span>
<span class="ltx_bibblock">
Tongliang Li, Lei Fang, Jian-Guang Lou, and Zhoujun Li. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2021.findings-emnlp.107" title="" class="ltx_ref ltx_href">TWT: Table with written text for controlled data-to-text generation</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">Findings of the Association for Computational Linguistics: EMNLP 2021</em>, pages 1244–1254, Punta Cana, Dominican Republic. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin et al. (2020)</span>
<span class="ltx_bibblock">
Xi Victoria Lin, Richard Socher, and Caiming Xiong. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2020.findings-emnlp.438" title="" class="ltx_ref ltx_href">Bridging textual and tabular data for cross-domain text-to-SQL semantic parsing</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">Findings of the Association for Computational Linguistics: EMNLP 2020</em>, pages 4870–4888, Online. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lyu et al. (2023)</span>
<span class="ltx_bibblock">
Qing Lyu, Shreya Havaldar, Adam Stein, Li Zhang, Delip Rao, Eric Wong, Marianna Apidianaki, and Chris Callison-Burch. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2023.ijcnlp-main.20" title="" class="ltx_ref ltx_href">Faithful chain-of-thought reasoning</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 13th International Joint Conference on Natural Language Processing and the 3rd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pages 305–329, Nusa Dua, Bali. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mavromatis et al. (2021)</span>
<span class="ltx_bibblock">
Costas Mavromatis, Prasanna Lakkur Subramanyam, Vassilis N. Ioannidis, Soji Adeshina, Phillip R. Howard, Tetiana Grinberg, Nagib Hakim, and George Karypis. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2112.05785" title="" class="ltx_ref ltx_href">Tempoqr: Temporal question reasoning over knowledge graphs</a>.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nan et al. (2021)</span>
<span class="ltx_bibblock">
Linyong Nan, Dragomir Radev, Rui Zhang, Amrit Rau, Abhinand Sivaprasad, Chiachun Hsieh, Xiangru Tang, Aadit Vyas, Neha Verma, Pranav Krishna, Yangxiaokang Liu, Nadia Irwanto, Jessica Pan, Faiaz Rahman, Ahmad Zaidi, Mutethia Mutuma, Yasin Tarabar, Ankit Gupta, Tao Yu, Yi Chern Tan, Xi Victoria Lin, Caiming Xiong, Richard Socher, and Nazneen Fatema Rajani. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2021.naacl-main.37" title="" class="ltx_ref ltx_href">DART: Open-domain structured data record to text generation</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</em>, pages 432–447, Online. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Neelam et al. (2022)</span>
<span class="ltx_bibblock">
Sumit Neelam, Udit Sharma, Hima Karanam, Shajith Ikbal, Pavan Kapanipathi, Ibrahim Abdelaziz, Nandana Mihindukulasooriya, Young-Suk Lee, Santosh Srivastava, Cezar Pendus, Saswati Dana, Dinesh Garg, Achille Fokoue, G P Shrivatsa Bhargav, Dinesh Khandelwal, Srinivas Ravishankar, Sairam Gurajada, Maria Chang, Rosario Uceda-Sosa, Salim Roukos, Alexander Gray, Guilherme Lima, Ryan Riegel, Francois Luus, and L Venkata Subramaniam. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2201.05793" title="" class="ltx_ref ltx_href">A benchmark for generalizable and interpretable temporal question answering over knowledge bases</a>.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Neeraja et al. (2021)</span>
<span class="ltx_bibblock">
J. Neeraja, Vivek Gupta, and Vivek Srikumar. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2021.naacl-main.224" title="" class="ltx_ref ltx_href">Incorporating external knowledge to enhance tabular reasoning</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</em>, pages 2799–2809, Online. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ning et al. (2020)</span>
<span class="ltx_bibblock">
Qiang Ning, Hao Wu, Rujun Han, Nanyun Peng, Matt Gardner, and Dan Roth. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2020.emnlp-main.88" title="" class="ltx_ref ltx_href">TORQUE: A reading comprehension dataset of temporal ordering questions</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>, pages 1158–1172, Online. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ning et al. (2018)</span>
<span class="ltx_bibblock">
Qiang Ning, Ben Zhou, Zhili Feng, Haoruo Peng, and Dan Roth. 2018.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/D18-2013" title="" class="ltx_ref ltx_href">CogCompTime: A tool for understanding time in natural language</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</em>, pages 72–77, Brussels, Belgium. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Oguz et al. (2020)</span>
<span class="ltx_bibblock">
Barlas Oguz, Xilun Chen, Vladimir Karpukhin, Stan Peshterliev, Dmytro Okhonko, Michael Schlichtkrull, Sonal Gupta, Yashar Mehdad, and Scott Yih. 2020.

</span>
<span class="ltx_bibblock"><a href="%22https://arxiv.org/abs/2012.14610%22" title="" class="ltx_ref ltx_href">Unified open-domain question answering with structured and unstructured knowledge</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2012.14610</em>.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Parikh et al. (2020)</span>
<span class="ltx_bibblock">
Ankur Parikh, Xuezhi Wang, Sebastian Gehrmann, Manaal Faruqui, Bhuwan Dhingra, Diyi Yang, and Dipanjan Das. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2020.emnlp-main.89" title="" class="ltx_ref ltx_href">ToTTo: A controlled table-to-text generation dataset</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>, pages 1173–1186, Online. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pasupat and Liang (2015)</span>
<span class="ltx_bibblock">
Panupong Pasupat and Percy Liang. 2015.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.3115/v1/P15-1142" title="" class="ltx_ref ltx_href">Compositional semantic parsing on semi-structured tables</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</em>, pages 1470–1480, Beijing, China. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pramanick and Bhattacharya (2021)</span>
<span class="ltx_bibblock">
Aniket Pramanick and Indrajit Bhattacharya. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2021.eacl-main.102" title="" class="ltx_ref ltx_href">Joint learning of representations for web-tables, entities and types using graph convolutional network</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume</em>, pages 1197–1206, Online. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Saxena et al. (2021)</span>
<span class="ltx_bibblock">
Apoorv Saxena, Soumen Chakrabarti, and Partha Talukdar. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2021.acl-long.520" title="" class="ltx_ref ltx_href">Question answering over temporal knowledge graphs</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</em>, pages 6663–6676, Online. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shang et al. (2021)</span>
<span class="ltx_bibblock">
Chao Shang, Peng Qi, Guangtao Wang, Jing Huang, Youzheng Wu, and Bowen Zhou. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://openreview.net/forum?id=li-3nHhT0xc" title="" class="ltx_ref ltx_href">Open temporal relation extraction for question answering</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">3rd Conference on Automated Knowledge Base Construction</em>.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Srivastava et al. (2023)</span>
<span class="ltx_bibblock">
Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal Md Shoeb, and Abubakar Abid. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2206.04615" title="" class="ltx_ref ltx_href">Beyond the imitation game: Quantifying and extrapolating the capabilities of language models</a>.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Srivastava et al. (2024)</span>
<span class="ltx_bibblock">
Pragya Srivastava, Manuj Malik, Vivek Gupta, Tanuja Ganu, and Dan Roth. 2024.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2402.11194" title="" class="ltx_ref ltx_href">Evaluating llms’ mathematical reasoning in financial document question answering</a>.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sui et al. (2024)</span>
<span class="ltx_bibblock">
Yuan Sui, Mengyu Zhou, Mingjie Zhou, Shi Han, and Dongmei Zhang. 2024.

</span>
<span class="ltx_bibblock">Table meets llm: Can large language models understand structured table data? a benchmark and empirical study.

</span>
<span class="ltx_bibblock">In <em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 17th ACM International Conference on Web Search and Data Mining</em>, pages 645–654.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et al. (2016)</span>
<span class="ltx_bibblock">
Huan Sun, Hao Ma, Xiaodong He, Scott Wen-tau Yih, Yu Su, and Xifeng Yan. 2016.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.microsoft.com/en-us/research/publication/table-cell-search-for-question-answering/" title="" class="ltx_ref ltx_href">Table cell search for question answering</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">Proceedings of the companion publication of the 25th international conference on World Wide Web</em>. ACM - Association for Computing Machinery.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang and Zhao (2024)</span>
<span class="ltx_bibblock">
Yuqing Wang and Yun Zhao. 2024.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2310.00835" title="" class="ltx_ref ltx_href">Tram: Benchmarking temporal reasoning for large language models</a>.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et al. (2023)</span>
<span class="ltx_bibblock">
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le, and Denny Zhou. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2201.11903" title="" class="ltx_ref ltx_href">Chain-of-thought prompting elicits reasoning in large language models</a>.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wen et al. (2021)</span>
<span class="ltx_bibblock">
Haoyang Wen, Yanru Qu, Heng Ji, Qiang Ning, Jiawei Han, Avi Sil, Hanghang Tong, and Dan Roth. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2021.naacl-main.6" title="" class="ltx_ref ltx_href">Event time extraction and propagation via graph attention networks</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</em>, pages 62–73, Online. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yin et al. (2020)</span>
<span class="ltx_bibblock">
Pengcheng Yin, Graham Neubig, Wen tau Yih, and Sebastian Riedel. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2005.08314" title="" class="ltx_ref ltx_href">Tabert: Pretraining for joint understanding of textual and tabular data</a>.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yoran et al. (2021)</span>
<span class="ltx_bibblock">
Ori Yoran, Alon Talmor, and Jonathan Berant. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/pdf/2107.07261.pdf" title="" class="ltx_ref ltx_href">Turning tables: Generating examples from semi-structured tables for endowing language models with reasoning skills</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib48.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2107.07261. Version 1.</em>

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al. (2018)</span>
<span class="ltx_bibblock">
Tao Yu, Rui Zhang, Kai Yang, Michihiro Yasunaga, Dongxu Wang, Zifan Li, James Ma, Irene Li, Qingning Yao, Shanelle Roman, Zilin Zhang, and Dragomir Radev. 2018.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/D18-1425" title="" class="ltx_ref ltx_href">Spider: A large-scale human-labeled dataset for complex and cross-domain semantic parsing and text-to-SQL task</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib49.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</em>, pages 3911–3921, Brussels, Belgium. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zayats et al. (2021)</span>
<span class="ltx_bibblock">
Vicky Zayats, Kristina Toutanova, and Mari Ostendorf. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2021.eacl-main.253" title="" class="ltx_ref ltx_href">Representations for question answering from documents with tables and text</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib50.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume</em>, pages 2895–2906, Online. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2020a)</span>
<span class="ltx_bibblock">
Hongzhi Zhang, Yingyao Wang, Sirui Wang, Xuezhi Cao, Fuzheng Zhang, and Zhongyuan Wang. 2020a.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2020.emnlp-main.126" title="" class="ltx_ref ltx_href">Table fact verification with structure-aware transformer</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib51.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>, pages 1624–1629, Online. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2019)</span>
<span class="ltx_bibblock">
Li Zhang, Shuo Zhang, and Krisztian Balog. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1145/3331184.3331333" title="" class="ltx_ref ltx_href">Table2vec: Neural word and entity embeddings for table population and retrieval</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib52.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval</em>, SIGIR ’19. ACM.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang and Choi (2021)</span>
<span class="ltx_bibblock">
Michael Zhang and Eunsol Choi. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2021.emnlp-main.586" title="" class="ltx_ref ltx_href">SituatedQA: Incorporating extra-linguistic contexts into QA</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib53.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</em>, pages 7371–7387, Online and Punta Cana, Dominican Republic. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang and Balog (2019)</span>
<span class="ltx_bibblock">
Shuo Zhang and Krisztian Balog. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1145/3357384.3357932" title="" class="ltx_ref ltx_href">Auto-completion for data cells in relational tables</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib54.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 28th ACM International Conference on Information and Knowledge Management</em>, CIKM ’19, pages 761–770, New York, NY, USA. ACM.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang and Balog (2020)</span>
<span class="ltx_bibblock">
Shuo Zhang and Krisztian Balog. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1145/3372117" title="" class="ltx_ref ltx_href">Web table extraction, retrieval, and augmentation: A survey</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib55.1.1" class="ltx_emph ltx_font_italic">ACM Trans. Intell. Syst. Technol.</em>, 11(2):13:1–13:35.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2020b)</span>
<span class="ltx_bibblock">
Shuo Zhang, Zhuyun Dai, Krisztian Balog, and Jamie Callan. 2020b.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1145/3397271.3401205" title="" class="ltx_ref ltx_href">Summarizing and exploring tabular data in conversational search</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib56.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval</em>, SIGIR ’20, pages 1537–1540, New York, NY, USA. Association for Computing Machinery.

</span>
</li>
</ul>
</section>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Appendix</h2>

<figure id="A1.T5" class="ltx_table">
<table id="A1.T5.19" class="ltx_tabular ltx_align_middle">
<tr id="A1.T5.19.20" class="ltx_tr">
<td id="A1.T5.19.20.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.19.20.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.19.20.1.1.1" class="ltx_p" style="width:71.1pt;"><span id="A1.T5.19.20.1.1.1.1" class="ltx_text ltx_font_bold">Ordering</span></span>
</span>
</td>
<td id="A1.T5.19.20.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.19.20.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.19.20.2.1.1" class="ltx_p" style="width:384.1pt;"><span id="A1.T5.19.20.2.1.1.1" class="ltx_text ltx_font_bold">Q</span>: Arrange the following events in chronological order: (1) Brusilov Offensive by Russia. (2) Kamehameha I of the Island of Hawaii defeats the Oahuans at the Battle of Nu’uanu. (3) The Kuomintang, the Chinese nationalist party, is founded. (4) Emperor Claudius dies and is succeeded by his grand nephew Nero. (5) St. Norbert and 29 companions make their solemn vows marking the beginning of the Premonstratensian Order.</span>
</span>
</td>
</tr>
<tr id="A1.T5.2.2" class="ltx_tr">
<td id="A1.T5.2.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.2.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.2.2.3.1.1" class="ltx_p" style="width:71.1pt;">(Facts)</span>
</span>
</td>
<td id="A1.T5.2.2.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.2.2.2.2" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.2.2.2.2.2" class="ltx_p" style="width:384.1pt;"><span id="A1.T5.2.2.2.2.2.1" class="ltx_text ltx_font_bold">A</span>. (1), (2), (4), (5), (3) <math id="A1.T5.1.1.1.1.1.m1.1" class="ltx_align_left" alttext="\times" display="inline"><semantics id="A1.T5.1.1.1.1.1.m1.1a"><mo mathcolor="#FF0000" id="A1.T5.1.1.1.1.1.m1.1.1" xref="A1.T5.1.1.1.1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="A1.T5.1.1.1.1.1.m1.1b"><times id="A1.T5.1.1.1.1.1.m1.1.1.cmml" xref="A1.T5.1.1.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="A1.T5.1.1.1.1.1.m1.1c">\times</annotation></semantics></math>  <span id="A1.T5.2.2.2.2.2.2" class="ltx_text ltx_align_left ltx_font_bold">B</span>. (4), (5), (2), (3), (1) <span id="A1.T5.2.2.2.2.2.3" class="ltx_text ltx_align_left ltx_font_bold" style="color:#00FF00;">✓</span>  <span id="A1.T5.2.2.2.2.2.4" class="ltx_text ltx_align_left ltx_font_bold">C</span>. (3), (1), (2), (4), (5) <math id="A1.T5.2.2.2.2.2.m2.1" class="ltx_align_left" alttext="\times" display="inline"><semantics id="A1.T5.2.2.2.2.2.m2.1a"><mo mathcolor="#FF0000" id="A1.T5.2.2.2.2.2.m2.1.1" xref="A1.T5.2.2.2.2.2.m2.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="A1.T5.2.2.2.2.2.m2.1b"><times id="A1.T5.2.2.2.2.2.m2.1.1.cmml" xref="A1.T5.2.2.2.2.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="A1.T5.2.2.2.2.2.m2.1c">\times</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr id="A1.T5.19.21" class="ltx_tr">
<td id="A1.T5.19.21.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.19.21.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.19.21.1.1.1" class="ltx_p" style="width:71.1pt;"><span id="A1.T5.19.21.1.1.1.1" class="ltx_text ltx_font_bold">Frequency</span></span>
</span>
</td>
<td id="A1.T5.19.21.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.19.21.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.19.21.2.1.1" class="ltx_p" style="width:384.1pt;"><span id="A1.T5.19.21.2.1.1.1" class="ltx_text ltx_font_bold">Q</span>: It is also a love story, between Ace and Tobio, a trans woman. How often do they break up?</span>
</span>
</td>
</tr>
<tr id="A1.T5.4.4" class="ltx_tr">
<td id="A1.T5.4.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.4.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.4.4.3.1.1" class="ltx_p" style="width:71.1pt;">(Commonsense)</span>
</span>
</td>
<td id="A1.T5.4.4.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.4.4.2.2" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.4.4.2.2.2" class="ltx_p" style="width:384.1pt;"><span id="A1.T5.4.4.2.2.2.1" class="ltx_text ltx_font_bold">A</span>. Once <span id="A1.T5.4.4.2.2.2.2" class="ltx_text ltx_align_left ltx_font_bold" style="color:#00FF00;">✓</span>  <span id="A1.T5.4.4.2.2.2.3" class="ltx_text ltx_align_left ltx_font_bold">B</span>. Always <math id="A1.T5.3.3.1.1.1.m1.1" class="ltx_align_left" alttext="\times" display="inline"><semantics id="A1.T5.3.3.1.1.1.m1.1a"><mo mathcolor="#FF0000" id="A1.T5.3.3.1.1.1.m1.1.1" xref="A1.T5.3.3.1.1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="A1.T5.3.3.1.1.1.m1.1b"><times id="A1.T5.3.3.1.1.1.m1.1.1.cmml" xref="A1.T5.3.3.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="A1.T5.3.3.1.1.1.m1.1c">\times</annotation></semantics></math>  <span id="A1.T5.4.4.2.2.2.4" class="ltx_text ltx_align_left ltx_font_bold">C</span>. Once per week <math id="A1.T5.4.4.2.2.2.m2.1" class="ltx_align_left" alttext="\times" display="inline"><semantics id="A1.T5.4.4.2.2.2.m2.1a"><mo mathcolor="#FF0000" id="A1.T5.4.4.2.2.2.m2.1.1" xref="A1.T5.4.4.2.2.2.m2.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="A1.T5.4.4.2.2.2.m2.1b"><times id="A1.T5.4.4.2.2.2.m2.1.1.cmml" xref="A1.T5.4.4.2.2.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="A1.T5.4.4.2.2.2.m2.1c">\times</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr id="A1.T5.19.22" class="ltx_tr">
<td id="A1.T5.19.22.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.19.22.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.19.22.1.1.1" class="ltx_p" style="width:71.1pt;"><span id="A1.T5.19.22.1.1.1.1" class="ltx_text ltx_font_bold">Duration</span></span>
</span>
</td>
<td id="A1.T5.19.22.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.19.22.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.19.22.2.1.1" class="ltx_p" style="width:384.1pt;"><span id="A1.T5.19.22.2.1.1.1" class="ltx_text ltx_font_bold">Q</span>: While Yoga Session gave attendees time to plant an entire garden, Jazz Concert was enough to water a few plants, and Board Game Night was merely smelling a flower. Which event was the longest?</span>
</span>
</td>
</tr>
<tr id="A1.T5.6.6" class="ltx_tr">
<td id="A1.T5.6.6.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.6.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.6.6.3.1.1" class="ltx_p" style="width:71.1pt;">(Analogy Inference)</span>
</span>
</td>
<td id="A1.T5.6.6.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.6.6.2.2" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.6.6.2.2.2" class="ltx_p" style="width:384.1pt;"><span id="A1.T5.6.6.2.2.2.1" class="ltx_text ltx_font_bold">A</span>. Jazz Concert <math id="A1.T5.5.5.1.1.1.m1.1" class="ltx_align_left" alttext="\times" display="inline"><semantics id="A1.T5.5.5.1.1.1.m1.1a"><mo mathcolor="#FF0000" id="A1.T5.5.5.1.1.1.m1.1.1" xref="A1.T5.5.5.1.1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="A1.T5.5.5.1.1.1.m1.1b"><times id="A1.T5.5.5.1.1.1.m1.1.1.cmml" xref="A1.T5.5.5.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="A1.T5.5.5.1.1.1.m1.1c">\times</annotation></semantics></math>  <span id="A1.T5.6.6.2.2.2.2" class="ltx_text ltx_align_left ltx_font_bold">B</span>. Board Game Night <math id="A1.T5.6.6.2.2.2.m2.1" class="ltx_align_left" alttext="\times" display="inline"><semantics id="A1.T5.6.6.2.2.2.m2.1a"><mo mathcolor="#FF0000" id="A1.T5.6.6.2.2.2.m2.1.1" xref="A1.T5.6.6.2.2.2.m2.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="A1.T5.6.6.2.2.2.m2.1b"><times id="A1.T5.6.6.2.2.2.m2.1.1.cmml" xref="A1.T5.6.6.2.2.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="A1.T5.6.6.2.2.2.m2.1c">\times</annotation></semantics></math>  <span id="A1.T5.6.6.2.2.2.3" class="ltx_text ltx_align_left ltx_font_bold">C</span>. Yoga Session <span id="A1.T5.6.6.2.2.2.4" class="ltx_text ltx_align_left ltx_font_bold" style="color:#00FF00;">✓</span></span>
</span>
</td>
</tr>
<tr id="A1.T5.19.23" class="ltx_tr">
<td id="A1.T5.19.23.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.19.23.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.19.23.1.1.1" class="ltx_p" style="width:71.1pt;"><span id="A1.T5.19.23.1.1.1.1" class="ltx_text ltx_font_bold">Typical Time</span></span>
</span>
</td>
<td id="A1.T5.19.23.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.19.23.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.19.23.2.1.1" class="ltx_p" style="width:384.1pt;"><span id="A1.T5.19.23.2.1.1.1" class="ltx_text ltx_font_bold">Q</span>: Which event typically happens earlier: morning yoga or farmer starting their day?</span>
</span>
</td>
</tr>
<tr id="A1.T5.8.8" class="ltx_tr">
<td id="A1.T5.8.8.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.8.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.8.8.3.1.1" class="ltx_p" style="width:71.1pt;">(Comparison)</span>
</span>
</td>
<td id="A1.T5.8.8.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.8.8.2.2" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.8.8.2.2.2" class="ltx_p" style="width:384.1pt;"><span id="A1.T5.8.8.2.2.2.1" class="ltx_text ltx_font_bold">A</span>. Morning yoga <math id="A1.T5.7.7.1.1.1.m1.1" class="ltx_align_left" alttext="\times" display="inline"><semantics id="A1.T5.7.7.1.1.1.m1.1a"><mo mathcolor="#FF0000" id="A1.T5.7.7.1.1.1.m1.1.1" xref="A1.T5.7.7.1.1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="A1.T5.7.7.1.1.1.m1.1b"><times id="A1.T5.7.7.1.1.1.m1.1.1.cmml" xref="A1.T5.7.7.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="A1.T5.7.7.1.1.1.m1.1c">\times</annotation></semantics></math>  <span id="A1.T5.8.8.2.2.2.2" class="ltx_text ltx_align_left ltx_font_bold">B</span>. Farmer starting their day <span id="A1.T5.8.8.2.2.2.3" class="ltx_text ltx_align_left ltx_font_bold" style="color:#00FF00;">✓</span>  <span id="A1.T5.8.8.2.2.2.4" class="ltx_text ltx_align_left ltx_font_bold">C</span>.Around the same time<math id="A1.T5.8.8.2.2.2.m2.1" class="ltx_align_left" alttext="\times" display="inline"><semantics id="A1.T5.8.8.2.2.2.m2.1a"><mo mathcolor="#FF0000" id="A1.T5.8.8.2.2.2.m2.1.1" xref="A1.T5.8.8.2.2.2.m2.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="A1.T5.8.8.2.2.2.m2.1b"><times id="A1.T5.8.8.2.2.2.m2.1.1.cmml" xref="A1.T5.8.8.2.2.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="A1.T5.8.8.2.2.2.m2.1c">\times</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr id="A1.T5.19.24" class="ltx_tr">
<td id="A1.T5.19.24.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.19.24.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.19.24.1.1.1" class="ltx_p" style="width:71.1pt;"><span id="A1.T5.19.24.1.1.1.1" class="ltx_text ltx_font_bold">Ambiguity Resolution</span></span>
</span>
</td>
<td id="A1.T5.19.24.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.19.24.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.19.24.2.1.1" class="ltx_p" style="width:384.1pt;"><span id="A1.T5.19.24.2.1.1.1" class="ltx_text ltx_font_bold">Q</span>: The dynasty which fell in 1830 had risen to power roughly 90 years earlier. When was its establishment?</span>
</span>
</td>
</tr>
<tr id="A1.T5.10.10" class="ltx_tr">
<td id="A1.T5.10.10.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.10.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.10.10.3.1.1" class="ltx_p" style="width:71.1pt;">(Long-term Shift)</span>
</span>
</td>
<td id="A1.T5.10.10.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.10.10.2.2" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.10.10.2.2.2" class="ltx_p" style="width:384.1pt;"><span id="A1.T5.10.10.2.2.2.1" class="ltx_text ltx_font_bold">A</span>. 1742 <math id="A1.T5.9.9.1.1.1.m1.1" class="ltx_align_left" alttext="\times" display="inline"><semantics id="A1.T5.9.9.1.1.1.m1.1a"><mo mathcolor="#FF0000" id="A1.T5.9.9.1.1.1.m1.1.1" xref="A1.T5.9.9.1.1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="A1.T5.9.9.1.1.1.m1.1b"><times id="A1.T5.9.9.1.1.1.m1.1.1.cmml" xref="A1.T5.9.9.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="A1.T5.9.9.1.1.1.m1.1c">\times</annotation></semantics></math>  <span id="A1.T5.10.10.2.2.2.2" class="ltx_text ltx_align_left ltx_font_bold">B</span>. 1745 <math id="A1.T5.10.10.2.2.2.m2.1" class="ltx_align_left" alttext="\times" display="inline"><semantics id="A1.T5.10.10.2.2.2.m2.1a"><mo mathcolor="#FF0000" id="A1.T5.10.10.2.2.2.m2.1.1" xref="A1.T5.10.10.2.2.2.m2.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="A1.T5.10.10.2.2.2.m2.1b"><times id="A1.T5.10.10.2.2.2.m2.1.1.cmml" xref="A1.T5.10.10.2.2.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="A1.T5.10.10.2.2.2.m2.1c">\times</annotation></semantics></math>  <span id="A1.T5.10.10.2.2.2.3" class="ltx_text ltx_align_left ltx_font_bold">C</span> 1740 <span id="A1.T5.10.10.2.2.2.4" class="ltx_text ltx_align_left ltx_font_bold" style="color:#00FF00;">✓</span></span>
</span>
</td>
</tr>
<tr id="A1.T5.19.25" class="ltx_tr">
<td id="A1.T5.19.25.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.19.25.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.19.25.1.1.1" class="ltx_p" style="width:71.1pt;"><span id="A1.T5.19.25.1.1.1.1" class="ltx_text ltx_font_bold">Arithmetic</span></span>
</span>
</td>
<td id="A1.T5.19.25.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.19.25.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.19.25.2.1.1" class="ltx_p" style="width:384.1pt;"><span id="A1.T5.19.25.2.1.1.1" class="ltx_text ltx_font_bold">Q</span>: In which week of year 2007 does the date 10-12-2007 occur?</span>
</span>
</td>
</tr>
<tr id="A1.T5.13.13" class="ltx_tr">
<td id="A1.T5.13.13.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.13.13.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.13.13.4.1.1" class="ltx_p" style="width:71.1pt;">(Week Identification)</span>
</span>
</td>
<td id="A1.T5.13.13.3" class="ltx_td ltx_align_justify ltx_align_top" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.13.13.3.3" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.13.13.3.3.3" class="ltx_p" style="width:384.1pt;"><span id="A1.T5.13.13.3.3.3.1" class="ltx_text ltx_font_bold">A</span>.Week41 <span id="A1.T5.13.13.3.3.3.2" class="ltx_text ltx_align_left ltx_font_bold" style="color:#00FF00;">✓</span>  <span id="A1.T5.13.13.3.3.3.3" class="ltx_text ltx_align_left ltx_font_bold">B</span>.Week28 <math id="A1.T5.11.11.1.1.1.m1.1" class="ltx_align_left" alttext="\times" display="inline"><semantics id="A1.T5.11.11.1.1.1.m1.1a"><mo mathcolor="#FF0000" id="A1.T5.11.11.1.1.1.m1.1.1" xref="A1.T5.11.11.1.1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="A1.T5.11.11.1.1.1.m1.1b"><times id="A1.T5.11.11.1.1.1.m1.1.1.cmml" xref="A1.T5.11.11.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="A1.T5.11.11.1.1.1.m1.1c">\times</annotation></semantics></math>  <span id="A1.T5.13.13.3.3.3.4" class="ltx_text ltx_align_left ltx_font_bold">C</span>.Week5 <math id="A1.T5.12.12.2.2.2.m2.1" class="ltx_align_left" alttext="\times" display="inline"><semantics id="A1.T5.12.12.2.2.2.m2.1a"><mo mathcolor="#FF0000" id="A1.T5.12.12.2.2.2.m2.1.1" xref="A1.T5.12.12.2.2.2.m2.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="A1.T5.12.12.2.2.2.m2.1b"><times id="A1.T5.12.12.2.2.2.m2.1.1.cmml" xref="A1.T5.12.12.2.2.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="A1.T5.12.12.2.2.2.m2.1c">\times</annotation></semantics></math>  <span id="A1.T5.13.13.3.3.3.5" class="ltx_text ltx_align_left ltx_font_bold">D</span>.Week10 <math id="A1.T5.13.13.3.3.3.m3.1" class="ltx_align_left" alttext="\times" display="inline"><semantics id="A1.T5.13.13.3.3.3.m3.1a"><mo mathcolor="#FF0000" id="A1.T5.13.13.3.3.3.m3.1.1" xref="A1.T5.13.13.3.3.3.m3.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="A1.T5.13.13.3.3.3.m3.1b"><times id="A1.T5.13.13.3.3.3.m3.1.1.cmml" xref="A1.T5.13.13.3.3.3.m3.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="A1.T5.13.13.3.3.3.m3.1c">\times</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr id="A1.T5.19.26" class="ltx_tr">
<td id="A1.T5.19.26.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.19.26.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.19.26.1.1.1" class="ltx_p" style="width:71.1pt;"><span id="A1.T5.19.26.1.1.1.1" class="ltx_text ltx_font_bold">Temporal Relation</span></span>
</span>
</td>
<td id="A1.T5.19.26.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.19.26.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.19.26.2.1.1" class="ltx_p" style="width:384.1pt;"><span id="A1.T5.19.26.2.1.1.1" class="ltx_text ltx_font_bold">Q</span>: It added that the Ministry of Economic Affairs and Finance was assigned to draw up practical procedure for
the ceding, while the Ministry of Welfare and Social Security would be responsible for identifying the
beneficiaries in two months. What is the relationship between the event ‘added’ and the event ‘ceding’?</span>
</span>
</td>
</tr>
<tr id="A1.T5.15.15" class="ltx_tr">
<td id="A1.T5.15.15.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.15.15.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.15.15.3.1.1" class="ltx_p" style="width:71.1pt;"></span>
</span>
</td>
<td id="A1.T5.15.15.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.15.15.2.2" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.15.15.2.2.2" class="ltx_p" style="width:384.1pt;"><span id="A1.T5.15.15.2.2.2.1" class="ltx_text ltx_font_bold">A</span>. IS_INCLUDED <math id="A1.T5.14.14.1.1.1.m1.1" class="ltx_align_left" alttext="\times" display="inline"><semantics id="A1.T5.14.14.1.1.1.m1.1a"><mo mathcolor="#FF0000" id="A1.T5.14.14.1.1.1.m1.1.1" xref="A1.T5.14.14.1.1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="A1.T5.14.14.1.1.1.m1.1b"><times id="A1.T5.14.14.1.1.1.m1.1.1.cmml" xref="A1.T5.14.14.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="A1.T5.14.14.1.1.1.m1.1c">\times</annotation></semantics></math>  <span id="A1.T5.15.15.2.2.2.2" class="ltx_text ltx_align_left ltx_font_bold">B</span>. SIMULTANEOUS <math id="A1.T5.15.15.2.2.2.m2.1" class="ltx_align_left" alttext="\times" display="inline"><semantics id="A1.T5.15.15.2.2.2.m2.1a"><mo mathcolor="#FF0000" id="A1.T5.15.15.2.2.2.m2.1.1" xref="A1.T5.15.15.2.2.2.m2.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="A1.T5.15.15.2.2.2.m2.1b"><times id="A1.T5.15.15.2.2.2.m2.1.1.cmml" xref="A1.T5.15.15.2.2.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="A1.T5.15.15.2.2.2.m2.1c">\times</annotation></semantics></math>  <span id="A1.T5.15.15.2.2.2.3" class="ltx_text ltx_align_left ltx_font_bold">C</span>. AFTER <span id="A1.T5.15.15.2.2.2.4" class="ltx_text ltx_align_left ltx_font_bold" style="color:#00FF00;">✓</span></span>
</span>
</td>
</tr>
<tr id="A1.T5.19.27" class="ltx_tr">
<td id="A1.T5.19.27.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.19.27.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.19.27.1.1.1" class="ltx_p" style="width:71.1pt;"><span id="A1.T5.19.27.1.1.1.1" class="ltx_text ltx_font_bold">Temporal NLI</span></span>
</span>
</td>
<td id="A1.T5.19.27.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.19.27.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.19.27.2.1.1" class="ltx_p" style="width:384.1pt;"><span id="A1.T5.19.27.2.1.1.1" class="ltx_text ltx_font_bold">Q</span>: Premise: Two guys playing football on a campus green.
Hypothesis: They are practicing before the big game tomorrow</span>
</span>
</td>
</tr>
<tr id="A1.T5.17.17" class="ltx_tr">
<td id="A1.T5.17.17.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.17.17.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.17.17.3.1.1" class="ltx_p" style="width:71.1pt;"></span>
</span>
</td>
<td id="A1.T5.17.17.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.17.17.2.2" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.17.17.2.2.2" class="ltx_p" style="width:384.1pt;"><span id="A1.T5.17.17.2.2.2.1" class="ltx_text ltx_font_bold">A</span>. Entailment <math id="A1.T5.16.16.1.1.1.m1.1" class="ltx_align_left" alttext="\times" display="inline"><semantics id="A1.T5.16.16.1.1.1.m1.1a"><mo mathcolor="#FF0000" id="A1.T5.16.16.1.1.1.m1.1.1" xref="A1.T5.16.16.1.1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="A1.T5.16.16.1.1.1.m1.1b"><times id="A1.T5.16.16.1.1.1.m1.1.1.cmml" xref="A1.T5.16.16.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="A1.T5.16.16.1.1.1.m1.1c">\times</annotation></semantics></math>  <span id="A1.T5.17.17.2.2.2.2" class="ltx_text ltx_align_left ltx_font_bold">B</span>. Neutral <span id="A1.T5.17.17.2.2.2.3" class="ltx_text ltx_align_left ltx_font_bold" style="color:#00FF00;">✓</span>  <span id="A1.T5.17.17.2.2.2.4" class="ltx_text ltx_align_left ltx_font_bold">C</span>. Contradiction<math id="A1.T5.17.17.2.2.2.m2.1" class="ltx_align_left" alttext="\times" display="inline"><semantics id="A1.T5.17.17.2.2.2.m2.1a"><mo mathcolor="#FF0000" id="A1.T5.17.17.2.2.2.m2.1.1" xref="A1.T5.17.17.2.2.2.m2.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="A1.T5.17.17.2.2.2.m2.1b"><times id="A1.T5.17.17.2.2.2.m2.1.1.cmml" xref="A1.T5.17.17.2.2.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="A1.T5.17.17.2.2.2.m2.1c">\times</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr id="A1.T5.19.28" class="ltx_tr">
<td id="A1.T5.19.28.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.19.28.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.19.28.1.1.1" class="ltx_p" style="width:71.1pt;"><span id="A1.T5.19.28.1.1.1.1" class="ltx_text ltx_font_bold">Temporal Causality</span></span>
</span>
</td>
<td id="A1.T5.19.28.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.19.28.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.19.28.2.1.1" class="ltx_p" style="width:384.1pt;"><span id="A1.T5.19.28.2.1.1.1" class="ltx_text ltx_font_bold">Q</span>: The seasons changed from summer to autumn. What’s the more plausible RESULT?</span>
</span>
</td>
</tr>
<tr id="A1.T5.18.18" class="ltx_tr">
<td id="A1.T5.18.18.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.18.18.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.18.18.2.1.1" class="ltx_p" style="width:71.1pt;">(Effect)</span>
</span>
</td>
<td id="A1.T5.18.18.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.18.18.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.18.18.1.1.1" class="ltx_p" style="width:384.1pt;"><span id="A1.T5.18.18.1.1.1.1" class="ltx_text ltx_font_bold">A</span>. People evacuated their homes. <math id="A1.T5.18.18.1.1.1.m1.1" class="ltx_align_left" alttext="\times" display="inline"><semantics id="A1.T5.18.18.1.1.1.m1.1a"><mo mathcolor="#FF0000" id="A1.T5.18.18.1.1.1.m1.1.1" xref="A1.T5.18.18.1.1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="A1.T5.18.18.1.1.1.m1.1b"><times id="A1.T5.18.18.1.1.1.m1.1.1.cmml" xref="A1.T5.18.18.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="A1.T5.18.18.1.1.1.m1.1c">\times</annotation></semantics></math>  <span id="A1.T5.18.18.1.1.1.2" class="ltx_text ltx_align_left ltx_font_bold">B</span>. Leaves fell from the trees. <span id="A1.T5.18.18.1.1.1.3" class="ltx_text ltx_align_left ltx_font_bold" style="color:#00FF00;">✓</span></span>
</span>
</td>
</tr>
<tr id="A1.T5.19.29" class="ltx_tr">
<td id="A1.T5.19.29.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.19.29.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.19.29.1.1.1" class="ltx_p" style="width:71.1pt;"><span id="A1.T5.19.29.1.1.1.1" class="ltx_text ltx_font_bold">Temporal Storytelling</span></span>
</span>
</td>
<td id="A1.T5.19.29.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.19.29.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.19.29.2.1.1" class="ltx_p" style="width:384.1pt;"><span id="A1.T5.19.29.2.1.1.1" class="ltx_text ltx_font_bold">Q</span>: There is a huge clock in my living room. I turned the clock back one hour for daylight savings. My wife
also turned the clock back one hour for daylight savings. Our 2 kids each turned the clock back one hour for daylight savings. Which of the two endings is the most plausible correct ending to the story?</span>
</span>
</td>
</tr>
<tr id="A1.T5.19.19" class="ltx_tr">
<td id="A1.T5.19.19.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.19.19.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.19.19.2.1.1" class="ltx_p" style="width:71.1pt;"></span>
</span>
</td>
<td id="A1.T5.19.19.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.19.19.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.19.19.1.1.1" class="ltx_p" style="width:384.1pt;"><span id="A1.T5.19.19.1.1.1.1" class="ltx_text ltx_font_bold">A</span>. Then we wondered why it got so dark so early. <span id="A1.T5.19.19.1.1.1.2" class="ltx_text ltx_align_left ltx_font_bold ltx_align_center" style="color:#00FF00;">✓</span>  <span id="A1.T5.19.19.1.1.1.3" class="ltx_text ltx_align_left ltx_font_bold ltx_align_center">B</span>. The kids were not happy <math id="A1.T5.19.19.1.1.1.m1.1" class="ltx_align_left ltx_centering" alttext="\times" display="inline"><semantics id="A1.T5.19.19.1.1.1.m1.1a"><mo mathcolor="#FF0000" id="A1.T5.19.19.1.1.1.m1.1.1" xref="A1.T5.19.19.1.1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="A1.T5.19.19.1.1.1.m1.1b"><times id="A1.T5.19.19.1.1.1.m1.1.1.cmml" xref="A1.T5.19.19.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="A1.T5.19.19.1.1.1.m1.1c">\times</annotation></semantics></math></span>
</span>
</td>
</tr>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 5: </span>Examples Questions in TRAM Dataset.</figcaption>
</figure>
<figure id="A1.T6" class="ltx_table">
<table id="A1.T6.10" class="ltx_tabular ltx_align_middle">
<tr id="A1.T6.1.1" class="ltx_tr">
<td id="A1.T6.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.1.1.2.1.1" class="ltx_p" style="width:42.7pt;"><span id="A1.T6.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Task</span></span>
</span>
</td>
<td id="A1.T6.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.1.1.3.1.1" class="ltx_p" style="width:28.5pt;"><span id="A1.T6.1.1.3.1.1.1" class="ltx_text ltx_font_bold">Data Size</span></span>
</span>
</td>
<td id="A1.T6.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.1.1.1.1.1" class="ltx_p" style="width:199.2pt;"><math id="A1.T6.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\#" display="inline"><semantics id="A1.T6.1.1.1.1.1.m1.1a"><mi mathvariant="normal" id="A1.T6.1.1.1.1.1.m1.1.1" xref="A1.T6.1.1.1.1.1.m1.1.1.cmml">#</mi><annotation-xml encoding="MathML-Content" id="A1.T6.1.1.1.1.1.m1.1b"><ci id="A1.T6.1.1.1.1.1.m1.1.1.cmml" xref="A1.T6.1.1.1.1.1.m1.1.1">#</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T6.1.1.1.1.1.m1.1c">\#</annotation></semantics></math><span id="A1.T6.1.1.1.1.1.1" class="ltx_text ltx_align_left ltx_font_bold"> Problem Types</span></span>
</span>
</td>
<td id="A1.T6.1.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.1.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.1.1.4.1.1" class="ltx_p" style="width:28.5pt;"><span id="A1.T6.1.1.4.1.1.1" class="ltx_text ltx_font_bold">Metrics</span></span>
</span>
</td>
<td id="A1.T6.1.1.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.1.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.1.1.5.1.1" class="ltx_p" style="width:56.9pt;"><span id="A1.T6.1.1.5.1.1.1" class="ltx_text ltx_font_bold">Answer Type</span></span>
</span>
</td>
<td id="A1.T6.1.1.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.1.1.6.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.1.1.6.1.1" class="ltx_p" style="width:56.9pt;"><span id="A1.T6.1.1.6.1.1.1" class="ltx_text ltx_font_bold">Text Sources</span></span>
</span>
</td>
</tr>
<tr id="A1.T6.10.11" class="ltx_tr">
<td id="A1.T6.10.11.1" class="ltx_td ltx_align_center ltx_align_top ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;" colspan="6">Foundational Temporal Understanding Tasks</td>
</tr>
<tr id="A1.T6.2.2" class="ltx_tr">
<td id="A1.T6.2.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.2.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.2.2.2.1.1" class="ltx_p" style="width:42.7pt;">Ordering</span>
</span>
</td>
<td id="A1.T6.2.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.2.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.2.2.3.1.1" class="ltx_p" style="width:28.5pt;">29,462</span>
</span>
</td>
<td id="A1.T6.2.2.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.2.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.2.2.4.1.1" class="ltx_p" style="width:199.2pt;">Commonsense, Facts</span>
</span>
</td>
<td id="A1.T6.2.2.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.2.2.5.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.2.2.5.1.1" class="ltx_p" style="width:28.5pt;">Acc.</span>
</span>
</td>
<td id="A1.T6.2.2.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.2.2.6.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.2.2.6.1.1" class="ltx_p" style="width:56.9pt;">3-Way MC</span>
</span>
</td>
<td id="A1.T6.2.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.2.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.2.2.1.1.1" class="ltx_p" style="width:56.9pt;">MCTACO<sup id="A1.T6.2.2.1.1.1.1" class="ltx_sup"><span id="A1.T6.2.2.1.1.1.1.1" class="ltx_text ltx_font_italic">1</span></sup>, Wikipedia, Misc.</span>
</span>
</td>
</tr>
<tr id="A1.T6.4.4" class="ltx_tr">
<td id="A1.T6.4.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.4.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.4.4.3.1.1" class="ltx_p" style="width:42.7pt;">Frequency</span>
</span>
</td>
<td id="A1.T6.4.4.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.4.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.4.4.4.1.1" class="ltx_p" style="width:28.5pt;">4,658</span>
</span>
</td>
<td id="A1.T6.4.4.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.4.4.5.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.4.4.5.1.1" class="ltx_p" style="width:199.2pt;">Commonsense, Reading Comprehension, Application, Computation, Comparison, Facts</span>
</span>
</td>
<td id="A1.T6.4.4.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.4.4.6.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.4.4.6.1.1" class="ltx_p" style="width:28.5pt;">Acc.</span>
</span>
</td>
<td id="A1.T6.4.4.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.4.4.7.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.4.4.7.1.1" class="ltx_p" style="width:56.9pt;">3-Way MC</span>
</span>
</td>
<td id="A1.T6.4.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.4.4.2.2" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.4.4.2.2.2" class="ltx_p" style="width:56.9pt;">MCTACO<sup id="A1.T6.4.4.2.2.2.1" class="ltx_sup"><span id="A1.T6.4.4.2.2.2.1.1" class="ltx_text ltx_font_italic">1</span></sup>, SQuAD<sup id="A1.T6.4.4.2.2.2.2" class="ltx_sup"><span id="A1.T6.4.4.2.2.2.2.1" class="ltx_text ltx_font_italic">2</span></sup>, Misc.</span>
</span>
</td>
</tr>
<tr id="A1.T6.10.12" class="ltx_tr">
<td id="A1.T6.10.12.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.10.12.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.10.12.1.1.1" class="ltx_p" style="width:42.7pt;">Duration</span>
</span>
</td>
<td id="A1.T6.10.12.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.10.12.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.10.12.2.1.1" class="ltx_p" style="width:28.5pt;">7,232</span>
</span>
</td>
<td id="A1.T6.10.12.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.10.12.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.10.12.3.1.1" class="ltx_p" style="width:199.2pt;">Commonsense, Reading Comprehension, Analogy Inference, Computation, Direct Comparison, Multi-step Comparison, Facts</span>
</span>
</td>
<td id="A1.T6.10.12.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.10.12.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.10.12.4.1.1" class="ltx_p" style="width:28.5pt;">Acc.</span>
</span>
</td>
<td id="A1.T6.10.12.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.10.12.5.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.10.12.5.1.1" class="ltx_p" style="width:56.9pt;">3-Way MC</span>
</span>
</td>
<td id="A1.T6.10.12.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.10.12.6.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.10.12.6.1.1" class="ltx_p" style="width:56.9pt;">Same</span>
</span>
</td>
</tr>
<tr id="A1.T6.10.13" class="ltx_tr">
<td id="A1.T6.10.13.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.10.13.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.10.13.1.1.1" class="ltx_p" style="width:42.7pt;">Typical Time</span>
</span>
</td>
<td id="A1.T6.10.13.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.10.13.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.10.13.2.1.1" class="ltx_p" style="width:28.5pt;">13,018</span>
</span>
</td>
<td id="A1.T6.10.13.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.10.13.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.10.13.3.1.1" class="ltx_p" style="width:199.2pt;">Commonsense, Comparison, Facts, Reading Comprehension</span>
</span>
</td>
<td id="A1.T6.10.13.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.10.13.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.10.13.4.1.1" class="ltx_p" style="width:28.5pt;">Acc.</span>
</span>
</td>
<td id="A1.T6.10.13.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.10.13.5.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.10.13.5.1.1" class="ltx_p" style="width:56.9pt;">3-Way MC</span>
</span>
</td>
<td id="A1.T6.10.13.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.10.13.6.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.10.13.6.1.1" class="ltx_p" style="width:56.9pt;">Same</span>
</span>
</td>
</tr>
<tr id="A1.T6.10.14" class="ltx_tr">
<td id="A1.T6.10.14.1" class="ltx_td ltx_align_center ltx_align_top ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;" colspan="6">Temporal Interpretation and Computation Tasks</td>
</tr>
<tr id="A1.T6.10.15" class="ltx_tr">
<td id="A1.T6.10.15.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.10.15.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.10.15.1.1.1" class="ltx_p" style="width:42.7pt;">Amb. Res.</span>
</span>
</td>
<td id="A1.T6.10.15.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.10.15.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.10.15.2.1.1" class="ltx_p" style="width:28.5pt;">3,649</span>
</span>
</td>
<td id="A1.T6.10.15.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.10.15.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.10.15.3.1.1" class="ltx_p" style="width:199.2pt;">Interpretation, Calendar shift, Long-term shift, Mid-term shift, Short-term shift</span>
</span>
</td>
<td id="A1.T6.10.15.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.10.15.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.10.15.4.1.1" class="ltx_p" style="width:28.5pt;">Acc.</span>
</span>
</td>
<td id="A1.T6.10.15.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.10.15.5.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.10.15.5.1.1" class="ltx_p" style="width:56.9pt;">3-Way MC</span>
</span>
</td>
<td id="A1.T6.10.15.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.10.15.6.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.10.15.6.1.1" class="ltx_p" style="width:56.9pt;">Misc.</span>
</span>
</td>
</tr>
<tr id="A1.T6.10.16" class="ltx_tr">
<td id="A1.T6.10.16.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.10.16.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.10.16.1.1.1" class="ltx_p" style="width:42.7pt;">Arithmetic</span>
</span>
</td>
<td id="A1.T6.10.16.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.10.16.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.10.16.2.1.1" class="ltx_p" style="width:28.5pt;">15,629</span>
</span>
</td>
<td id="A1.T6.10.16.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.10.16.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.10.16.3.1.1" class="ltx_p" style="width:199.2pt;">Application, Date Computation, 12-hour Adjustment, 24-hour Adjustment, Month Shift, Week Identification, Year Shift, Time Computation, Time Zone Conversion</span>
</span>
</td>
<td id="A1.T6.10.16.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.10.16.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.10.16.4.1.1" class="ltx_p" style="width:28.5pt;">Acc.</span>
</span>
</td>
<td id="A1.T6.10.16.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.10.16.5.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.10.16.5.1.1" class="ltx_p" style="width:56.9pt;">4-Way MC</span>
</span>
</td>
<td id="A1.T6.10.16.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.10.16.6.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.10.16.6.1.1" class="ltx_p" style="width:56.9pt;">Same</span>
</span>
</td>
</tr>
<tr id="A1.T6.10.17" class="ltx_tr">
<td id="A1.T6.10.17.1" class="ltx_td ltx_align_center ltx_align_top ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;" colspan="6">Advanced Temporal and Conceptual Understanding Tasks</td>
</tr>
<tr id="A1.T6.5.5" class="ltx_tr">
<td id="A1.T6.5.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.5.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.5.5.2.1.1" class="ltx_p" style="width:42.7pt;">Relation</span>
</span>
</td>
<td id="A1.T6.5.5.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.5.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.5.5.3.1.1" class="ltx_p" style="width:28.5pt;">102,462</span>
</span>
</td>
<td id="A1.T6.5.5.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.5.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.5.5.4.1.1" class="ltx_p" style="width:199.2pt;">-</span>
</span>
</td>
<td id="A1.T6.5.5.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.5.5.5.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.5.5.5.1.1" class="ltx_p" style="width:28.5pt;">Acc./F1</span>
</span>
</td>
<td id="A1.T6.5.5.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.5.5.6.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.5.5.6.1.1" class="ltx_p" style="width:56.9pt;">3-Way MC</span>
</span>
</td>
<td id="A1.T6.5.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.5.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.5.5.1.1.1" class="ltx_p" style="width:56.9pt;">TempEval-3<sup id="A1.T6.5.5.1.1.1.1" class="ltx_sup"><span id="A1.T6.5.5.1.1.1.1.1" class="ltx_text ltx_font_italic">3</span></sup></span>
</span>
</td>
</tr>
<tr id="A1.T6.7.7" class="ltx_tr">
<td id="A1.T6.7.7.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.7.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.7.7.3.1.1" class="ltx_p" style="width:42.7pt;">Temporal NLI</span>
</span>
</td>
<td id="A1.T6.7.7.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.7.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.7.7.4.1.1" class="ltx_p" style="width:28.5pt;">282,144</span>
</span>
</td>
<td id="A1.T6.7.7.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.7.7.5.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.7.7.5.1.1" class="ltx_p" style="width:199.2pt;">-</span>
</span>
</td>
<td id="A1.T6.7.7.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.7.7.6.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.7.7.6.1.1" class="ltx_p" style="width:28.5pt;">Acc./F1</span>
</span>
</td>
<td id="A1.T6.7.7.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.7.7.7.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.7.7.7.1.1" class="ltx_p" style="width:56.9pt;">3-Way MC</span>
</span>
</td>
<td id="A1.T6.7.7.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.7.7.2.2" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.7.7.2.2.2" class="ltx_p" style="width:56.9pt;">MNLI<sup id="A1.T6.7.7.2.2.2.1" class="ltx_sup"><span id="A1.T6.7.7.2.2.2.1.1" class="ltx_text ltx_font_italic">4</span></sup>, SNLI<sup id="A1.T6.7.7.2.2.2.2" class="ltx_sup"><span id="A1.T6.7.7.2.2.2.2.1" class="ltx_text ltx_font_italic">5</span></sup></span>
</span>
</td>
</tr>
<tr id="A1.T6.8.8" class="ltx_tr">
<td id="A1.T6.8.8.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.8.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.8.8.2.1.1" class="ltx_p" style="width:42.7pt;">Causality</span>
</span>
</td>
<td id="A1.T6.8.8.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.8.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.8.8.3.1.1" class="ltx_p" style="width:28.5pt;">1,200</span>
</span>
</td>
<td id="A1.T6.8.8.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.8.8.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.8.8.4.1.1" class="ltx_p" style="width:199.2pt;">Cause, Effect</span>
</span>
</td>
<td id="A1.T6.8.8.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.8.8.5.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.8.8.5.1.1" class="ltx_p" style="width:28.5pt;">Acc.</span>
</span>
</td>
<td id="A1.T6.8.8.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.8.8.6.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.8.8.6.1.1" class="ltx_p" style="width:56.9pt;">2-Way MC</span>
</span>
</td>
<td id="A1.T6.8.8.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.8.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.8.8.1.1.1" class="ltx_p" style="width:56.9pt;">COPA<sup id="A1.T6.8.8.1.1.1.1" class="ltx_sup"><span id="A1.T6.8.8.1.1.1.1.1" class="ltx_text ltx_font_italic">6</span></sup>, Misc.</span>
</span>
</td>
</tr>
<tr id="A1.T6.10.10" class="ltx_tr">
<td id="A1.T6.10.10.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.10.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.10.10.3.1.1" class="ltx_p" style="width:42.7pt;">Storytelling</span>
</span>
</td>
<td id="A1.T6.10.10.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.10.10.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.10.10.4.1.1" class="ltx_p" style="width:28.5pt;">67,214</span>
</span>
</td>
<td id="A1.T6.10.10.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.10.10.5.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.10.10.5.1.1" class="ltx_p" style="width:199.2pt;">-</span>
</span>
</td>
<td id="A1.T6.10.10.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.10.10.6.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.10.10.6.1.1" class="ltx_p" style="width:28.5pt;">Acc.</span>
</span>
</td>
<td id="A1.T6.10.10.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.10.10.7.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.10.10.7.1.1" class="ltx_p" style="width:56.9pt;">2-Way MC</span>
</span>
</td>
<td id="A1.T6.10.10.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.10.10.2.2" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.10.10.2.2.2" class="ltx_p" style="width:56.9pt;">ROC<sup id="A1.T6.10.10.2.2.2.1" class="ltx_sup"><span id="A1.T6.10.10.2.2.2.1.1" class="ltx_text ltx_font_italic">7</span></sup>, SCT<sup id="A1.T6.10.10.2.2.2.2" class="ltx_sup"><span id="A1.T6.10.10.2.2.2.2.1" class="ltx_text ltx_font_italic">8</span></sup></span>
</span>
</td>
</tr>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 6: </span>Overview of tasks in TRAM.</figcaption>
</figure>
<figure id="A1.F2" class="ltx_figure"><img src="/html/2407.16030/assets/prompt-example.drawio.png" id="A1.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="538" height="423" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Prompt Example</figcaption>
</figure>
<figure id="A1.F3" class="ltx_figure"><img src="/html/2407.16030/assets/clear-working.drawio.png" id="A1.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="538" height="419" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>The figure illustrates the step-by-step process of C.L.E.A.R instruction. The reference table is provided in Figure <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Enhancing Temporal Understanding in LLMs for Semi-structured Tables" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a></figcaption>
</figure>
<figure id="A1.F4" class="ltx_figure"><svg id="A1.F4.pic1" class="ltx_picture ltx_centering" height="572.58" overflow="visible" version="1.1" width="600"><g transform="translate(0,572.58) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#404040" fill-opacity="1.0"><path d="M 0 5.91 L 0 566.68 C 0 569.94 2.64 572.58 5.91 572.58 L 594.09 572.58 C 597.36 572.58 600 569.94 600 566.68 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#FFFFFF" fill-opacity="1.0"><path d="M 1.97 5.91 L 1.97 566.68 C 1.97 568.85 3.73 570.61 5.91 570.61 L 594.09 570.61 C 596.27 570.61 598.03 568.85 598.03 566.68 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignObject width="556.69" height="545.02" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">
<span id="A1.F4.pic1.1.1.1.1.1" class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:402.3pt;">
<span id="A1.F4.pic1.1.1.1.1.1.1" class="ltx_block ltx_minipage ltx_align_middle" style="width:426.8pt;">
<span id="A1.F4.pic1.1.1.1.1.1.1.1" class="ltx_p ltx_align_left ltx_align_center"><span id="A1.F4.pic1.1.1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Input :</span></span>
<span id="A1.F4.pic1.1.1.1.1.1.1.2" class="ltx_p ltx_align_left ltx_align_center">Given an entity-centric table and corresponding question, follow the steps below exactly to answer the question:</span>
<span id="A1.F4.pic1.1.1.1.1.1.1.3" class="ltx_p ltx_align_left ltx_align_center"><span id="A1.F4.pic1.1.1.1.1.1.1.3.1" class="ltx_text ltx_font_bold">Step 1.</span> Comprehend Information: Apply domain knowledge to understand how to approach and answer the question.</span>
<span id="A1.F4.pic1.1.1.1.1.1.1.4" class="ltx_p ltx_align_left ltx_align_center"><span id="A1.F4.pic1.1.1.1.1.1.1.4.1" class="ltx_text ltx_font_bold">Step 2.</span> Locate Relevant Rows: Identify and extract any rows from the table that could be relevant to the question. Explain why these rows are selected. Also output the relevant rows verbatim.</span>
<span id="A1.F4.pic1.1.1.1.1.1.1.5" class="ltx_p ltx_align_left ltx_align_center"><span id="A1.F4.pic1.1.1.1.1.1.1.5.1" class="ltx_text ltx_font_bold">Step 3.</span> Examine the Question: Determine whether the original question can be solved by a simple table lookup. If not, break down the original question into between 2 and 4 smaller, more manageable sub-questions. Assume each sub-problem can be solved using the provided evidence. Explain how one could approach solving each sub-problem.</span>
<span id="A1.F4.pic1.1.1.1.1.1.1.6" class="ltx_p ltx_align_left ltx_align_center"><span id="A1.F4.pic1.1.1.1.1.1.1.6.1" class="ltx_text ltx_font_bold">Step 4.</span> Analyze Sub-Questions: Answer each sub-question using evidence from the table. Explain the step-by-step reasoning process that leads to each answer. Include any calculations or logical deduction to arrive at each conclusion, no matter how simple.</span>
<span id="A1.F4.pic1.1.1.1.1.1.1.7" class="ltx_p ltx_align_left ltx_align_center"><span id="A1.F4.pic1.1.1.1.1.1.1.7.1" class="ltx_text ltx_font_bold">Step 5.</span> Resolve to Form the Final Answer: Using the answers to each sub-question, answer the original question. Explain the step-by-step reasoning process that leads to this final answer. Include any calculations or logical deduction to arrive at each conclusion, no matter how simple. Clearly state the final answer using "Final Answer:", providing the answer as concisely as possible without unnecessary information.</span>
<span id="A1.F4.pic1.1.1.1.1.1.1.8" class="ltx_p ltx_align_left ltx_align_center">Each table-question pair is presented as a table (identified by "Table:") followed by a question (identified by "Q:"). Tables are presented in a linear format, with columns separated by tabs, rows separated by newlines, and subsections separated by double newlines. If necessary, assume the current date is December, 2022.</span>
<span id="A1.F4.pic1.1.1.1.1.1.1.9" class="ltx_p ltx_align_left ltx_align_center">========================</span>
<span id="A1.F4.pic1.1.1.1.1.1.1.10" class="ltx_p ltx_align_left ltx_align_center"><span id="A1.F4.pic1.1.1.1.1.1.1.10.1" class="ltx_text ltx_font_bold">Table:</span></span>
<span id="A1.F4.pic1.1.1.1.1.1.1.11" class="ltx_p ltx_align_left ltx_align_center">Title Bette Davis</span>
<span id="A1.F4.pic1.1.1.1.1.1.1.12" class="ltx_p ltx_align_left ltx_align_center">Died  October 6, 1989 | (1989-10-06) | (aged 81) |</span>
<span id="A1.F4.pic1.1.1.1.1.1.1.13" class="ltx_p ltx_align_left ltx_align_center">Neuilly-sur-Seine, France</span>
<span id="A1.F4.pic1.1.1.1.1.1.1.14" class="ltx_p ltx_align_left ltx_align_center">Resting place  Forest Lawn Memorial Park</span>
<span id="A1.F4.pic1.1.1.1.1.1.1.15" class="ltx_p ltx_align_left ltx_align_center">Occupation  Actress</span>
<span id="A1.F4.pic1.1.1.1.1.1.1.16" class="ltx_p ltx_align_left ltx_align_center">Years active  1929-1989</span>
<span id="A1.F4.pic1.1.1.1.1.1.1.17" class="ltx_p ltx_align_left ltx_align_center">Political party Democratic</span>
<span id="A1.F4.pic1.1.1.1.1.1.1.18" class="ltx_p ltx_align_left ltx_align_center">Spouse(s)  Harmon Oscar Nelson | ( | married | 1932; | divorced | 1938) | Arthur Farnsworth | ( | married | 1940; died 1943) | William Grant Sherry | ( | married | 1945; | divorced | 1950) | Gary Merrill | ( | married | 1950; | divorced | 1960)</span>
<span id="A1.F4.pic1.1.1.1.1.1.1.19" class="ltx_p ltx_align_left ltx_align_center">Children  3, including B. D. Hyman</span>
<span id="A1.F4.pic1.1.1.1.1.1.1.20" class="ltx_p ltx_align_left ltx_align_center">Bette Davis  [’BETTEDavis (cropped).jpg | Publicity photo, 1935’]</span>
<span id="A1.F4.pic1.1.1.1.1.1.1.21" class="ltx_p ltx_align_left ltx_align_center"><span id="A1.F4.pic1.1.1.1.1.1.1.21.1" class="ltx_text ltx_font_bold">Question:</span> How many years after Davis’s career began did she take the photo?</span>
</span>
</span></foreignObject></g></g></svg>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Example 1 from TempTabQA head set with C.L.E.A.R prompting on GPT 3.5 turbo : Input</figcaption>
</figure>
<figure id="A1.F5" class="ltx_figure"><svg id="A1.F5.pic1" class="ltx_picture ltx_centering" height="480.89" overflow="visible" version="1.1" width="600"><g transform="translate(0,480.89) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#404040" fill-opacity="1.0"><path d="M 0 5.91 L 0 474.99 C 0 478.25 2.64 480.89 5.91 480.89 L 594.09 480.89 C 597.36 480.89 600 478.25 600 474.99 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#FFFFFF" fill-opacity="1.0"><path d="M 1.97 5.91 L 1.97 474.99 C 1.97 477.16 3.73 478.92 5.91 478.92 L 594.09 478.92 C 596.27 478.92 598.03 477.16 598.03 474.99 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignObject width="556.69" height="453.33" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">
<span id="A1.F5.pic1.1.1.1.1.1" class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:402.3pt;">
<span id="A1.F5.pic1.1.1.1.1.1.1" class="ltx_block ltx_minipage ltx_align_middle" style="width:426.8pt;">
<span id="A1.F5.pic1.1.1.1.1.1.1.1" class="ltx_p ltx_align_left ltx_align_center"><span id="A1.F5.pic1.1.1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Response :</span></span>
<span id="A1.F5.pic1.1.1.1.1.1.1.2" class="ltx_p ltx_align_left ltx_align_center"><span id="A1.F5.pic1.1.1.1.1.1.1.2.1" class="ltx_text ltx_font_bold">Step 1.</span> Comprehend Information
Domain Knowledge:</span>
<span id="A1.F5.pic1.1.1.1.1.1.1.3" class="ltx_p ltx_align_left ltx_align_center">- The question asks "how many years", so the answer should be a length of time in years</span>
<span id="A1.F5.pic1.1.1.1.1.1.1.4" class="ltx_p ltx_align_left ltx_align_center">- To determine the time between two years, take the absolute value of the difference between the two years.</span>
<span id="A1.F5.pic1.1.1.1.1.1.1.5" class="ltx_p ltx_align_left ltx_align_center"><span id="A1.F5.pic1.1.1.1.1.1.1.5.1" class="ltx_text ltx_font_bold">Step 2.</span> Locate Relevant Rows</span>
<span id="A1.F5.pic1.1.1.1.1.1.1.6" class="ltx_p ltx_align_left ltx_align_center">- "Title Bette Davis": This indicates that the information in the table is about Bette Davis.
- "Years active 1929-1989": This provides the start and end year of Bette Davis’s career.
- "Bette Davis [’BETTEDavis (cropped).jpg | Publicity photo, 1935’]": This provides the year the photo was taken.</span>
<span id="A1.F5.pic1.1.1.1.1.1.1.7" class="ltx_p ltx_align_left ltx_align_center"><span id="A1.F5.pic1.1.1.1.1.1.1.7.1" class="ltx_text ltx_font_bold">Step 3.</span> Examine the Question
OQ) How many years after Davis’s career began did she take the photo? The table doesn’t provide this information. To determine the time between these two events, we need to know the following:</span>
<span id="A1.I1" class="ltx_itemize ltx_align_left ltx_centering">
<span id="A1.I1.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="A1.I1.i1.p1" class="ltx_para">
<span id="A1.I1.i1.p1.1" class="ltx_p">SQ1) When did Davis’s career begin?</span>
</span></span>
<span id="A1.I1.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="A1.I1.i2.p1" class="ltx_para">
<span id="A1.I1.i2.p1.1" class="ltx_p">SQ2) When did Davis take the photo? :
Davis took the photo in 1935</span>
</span></span>
</span>
<span id="A1.F5.pic1.1.1.1.1.1.1.8" class="ltx_p ltx_align_left ltx_align_center">SQ1) When did Davis’s career begin?</span>
<span id="A1.F5.pic1.1.1.1.1.1.1.9" class="ltx_p ltx_align_left ltx_align_center">The table gives the range years spanning Davis’s career. We can determine the begin year of her career by looking at the start year of this range.</span>
<span id="A1.F5.pic1.1.1.1.1.1.1.10" class="ltx_p ltx_align_left ltx_align_center">SQ2) When did Davis take the photo?</span>
<span id="A1.F5.pic1.1.1.1.1.1.1.11" class="ltx_p ltx_align_left ltx_align_center">The table provides the year the photo was taken.</span>
<span id="A1.F5.pic1.1.1.1.1.1.1.12" class="ltx_p ltx_align_left ltx_align_center"><span id="A1.F5.pic1.1.1.1.1.1.1.12.1" class="ltx_text ltx_font_bold">Step 4.</span> Answer Sub-Questions
SQ1) Davis’s career lasted from 1929 to 1989. Therefore, her career began in 1929.
SQ2) The photo was taken in 1935.</span>
<span id="A1.F5.pic1.1.1.1.1.1.1.13" class="ltx_p ltx_align_left ltx_align_center"><span id="A1.F5.pic1.1.1.1.1.1.1.13.1" class="ltx_text ltx_font_bold">Step 5.</span> Synthesize to Form the Final Answer
OQ) How many years after Davis’s career began did she take the photo?
Davis’s career began in 1929</span>
<span id="A1.F5.pic1.1.1.1.1.1.1.14" class="ltx_p ltx_align_left ltx_align_center">(SQ1), and she took the photo in 1935</span>
<span id="A1.F5.pic1.1.1.1.1.1.1.15" class="ltx_p ltx_align_left ltx_align_center">(SQ2). To get the number of years between these two events, take the absolute value of the difference between the two years.</span>
<span id="A1.F5.pic1.1.1.1.1.1.1.16" class="ltx_p ltx_align_left ltx_align_center">The absolute value of (1929-1935) is 6.</span>
<span id="A1.F5.pic1.1.1.1.1.1.1.17" class="ltx_p ltx_align_left ltx_align_center">Therefore, the photo was taken 6 years after Davis’s career began.</span>
<span id="A1.F5.pic1.1.1.1.1.1.1.18" class="ltx_p ltx_align_left ltx_align_center"><span id="A1.F5.pic1.1.1.1.1.1.1.18.1" class="ltx_text ltx_font_bold">Final Answer: 6</span></span>
</span>
</span></foreignObject></g></g></svg>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Example 1 from TempTabQA head set with C.L.E.A.R prompting on GPT 3.5 turbo : Response</figcaption>
</figure>
<figure id="A1.F6" class="ltx_figure"><svg id="A1.F6.pic1" class="ltx_picture ltx_centering" height="636.31" overflow="visible" version="1.1" width="600"><g transform="translate(0,636.31) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#404040" fill-opacity="1.0"><path d="M 0 5.91 L 0 630.4 C 0 633.67 2.64 636.31 5.91 636.31 L 594.09 636.31 C 597.36 636.31 600 633.67 600 630.4 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#FFFFFF" fill-opacity="1.0"><path d="M 1.97 5.91 L 1.97 630.4 C 1.97 632.58 3.73 634.34 5.91 634.34 L 594.09 634.34 C 596.27 634.34 598.03 632.58 598.03 630.4 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignObject width="556.69" height="608.75" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">
<span id="A1.F6.pic1.1.1.1.1.1" class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:402.3pt;">
<span id="A1.F6.pic1.1.1.1.1.1.1" class="ltx_block ltx_minipage ltx_align_middle" style="width:426.8pt;">
<span id="A1.F6.pic1.1.1.1.1.1.1.1" class="ltx_p ltx_align_left ltx_align_center"><span id="A1.F6.pic1.1.1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Input :</span></span>
<span id="A1.F6.pic1.1.1.1.1.1.1.2" class="ltx_p ltx_align_left ltx_align_center">Given an entity-centric table and corresponding question, follow the steps below exactly to answer the question:</span>
<span id="A1.F6.pic1.1.1.1.1.1.1.3" class="ltx_p ltx_align_left ltx_align_center"><span id="A1.F6.pic1.1.1.1.1.1.1.3.1" class="ltx_text ltx_font_bold">Step 1.</span> Comprehend Information: Apply domain knowledge to understand how to approach and answer the question.</span>
<span id="A1.F6.pic1.1.1.1.1.1.1.4" class="ltx_p ltx_align_left ltx_align_center"><span id="A1.F6.pic1.1.1.1.1.1.1.4.1" class="ltx_text ltx_font_bold">Step 2.</span> Locate Relevant Rows: Identify and extract any rows from the table that could be relevant to the question. Explain why these rows are selected. Also output the relevant rows verbatim.</span>
<span id="A1.F6.pic1.1.1.1.1.1.1.5" class="ltx_p ltx_align_left ltx_align_center"><span id="A1.F6.pic1.1.1.1.1.1.1.5.1" class="ltx_text ltx_font_bold">Step 3.</span> Examine the Question: Determine whether the original question can be solved by a simple table lookup. If not, break down the original question into between 2 and 4 smaller, more manageable sub-questions. Assume each sub-problem can be solved using the provided evidence. Explain how one could approach solving each sub-problem.</span>
<span id="A1.F6.pic1.1.1.1.1.1.1.6" class="ltx_p ltx_align_left ltx_align_center"><span id="A1.F6.pic1.1.1.1.1.1.1.6.1" class="ltx_text ltx_font_bold">Step 4.</span> Analyze Sub-Questions: Answer each sub-question using evidence from the table. Explain the step-by-step reasoning process that leads to each answer. Include any calculations or logical deduction to arrive at each conclusion, no matter how simple.</span>
<span id="A1.F6.pic1.1.1.1.1.1.1.7" class="ltx_p ltx_align_left ltx_align_center"><span id="A1.F6.pic1.1.1.1.1.1.1.7.1" class="ltx_text ltx_font_bold">Step 5.</span> Resolve to Form the Final Answer: Using the answers to each sub-question, answer the original question. Explain the step-by-step reasoning process that leads to this final answer. Include any calculations or logical deduction to arrive at each conclusion, no matter how simple. Clearly state the final answer using "Final Answer:", providing the answer as concisely as possible without unnecessary information.</span>
<span id="A1.F6.pic1.1.1.1.1.1.1.8" class="ltx_p ltx_align_left ltx_align_center">Each table-question pair is presented as a table (identified by "Table:") followed by a question (identified by "Q:"). Tables are presented in a linear format, with columns separated by tabs, rows separated by newlines, and subsections separated by double newlines. If necessary, assume the current date is December, 2022.</span>
<span id="A1.F6.pic1.1.1.1.1.1.1.9" class="ltx_p ltx_align_left ltx_align_center">========================</span>
<span id="A1.F6.pic1.1.1.1.1.1.1.10" class="ltx_p ltx_align_left ltx_align_center"><span id="A1.F6.pic1.1.1.1.1.1.1.10.1" class="ltx_text ltx_font_bold">Table:</span></span>
<span id="A1.F6.pic1.1.1.1.1.1.1.11" class="ltx_p ltx_align_left ltx_align_center">Title  Dwight Bernard</span>
<span id="A1.F6.pic1.1.1.1.1.1.1.12" class="ltx_p ltx_align_left ltx_align_center">Dwight Bernard  [’Dwight Bernard.jpg’]</span>
<span id="A1.F6.pic1.1.1.1.1.1.1.13" class="ltx_p ltx_align_left ltx_align_center">Pitcher</span>
<span id="A1.F6.pic1.1.1.1.1.1.1.14" class="ltx_p ltx_align_left ltx_align_center">Born  | ( | 1952-05-31 | ) | May 31, 1952 | (age 70) | Mount Vernon, Illinois</span>
<span id="A1.F6.pic1.1.1.1.1.1.1.15" class="ltx_p ltx_align_left ltx_align_center">Batted  | Right | Threw | Right</span>
<span id="A1.F6.pic1.1.1.1.1.1.1.16" class="ltx_p ltx_align_left ltx_align_center">MLB debut</span>
<span id="A1.F6.pic1.1.1.1.1.1.1.17" class="ltx_p ltx_align_left ltx_align_center">MLB debut  [’June 29, 1978, for the New York Mets’]</span>
<span id="A1.F6.pic1.1.1.1.1.1.1.18" class="ltx_p ltx_align_left ltx_align_center">Last MLB appearance</span>
<span id="A1.F6.pic1.1.1.1.1.1.1.19" class="ltx_p ltx_align_left ltx_align_center">Last MLB appearance  [’October 2, 1982, for the Milwaukee Brewers’]</span>
<span id="A1.F6.pic1.1.1.1.1.1.1.20" class="ltx_p ltx_align_left ltx_align_center">MLB statistics</span>
<span id="A1.F6.pic1.1.1.1.1.1.1.21" class="ltx_p ltx_align_left ltx_align_center">Win-loss record  4-8</span>
<span id="A1.F6.pic1.1.1.1.1.1.1.22" class="ltx_p ltx_align_left ltx_align_center">Earned run average  4.14</span>
<span id="A1.F6.pic1.1.1.1.1.1.1.23" class="ltx_p ltx_align_left ltx_align_center">Strikeouts  92</span>
<span id="A1.F6.pic1.1.1.1.1.1.1.24" class="ltx_p ltx_align_left ltx_align_center">Teams</span>
<span id="A1.F6.pic1.1.1.1.1.1.1.25" class="ltx_p ltx_align_left ltx_align_center">Teams  [’New York Mets (1978-1979) | Milwaukee Brewers (1981-1982)’]</span>
<span id="A1.F6.pic1.1.1.1.1.1.1.26" class="ltx_p ltx_align_left ltx_align_center"><span id="A1.F6.pic1.1.1.1.1.1.1.26.1" class="ltx_text ltx_font_bold">Question:</span> In what year did Dwight Bernard start playing with the last team he was associated with?</span>
</span>
</span></foreignObject></g></g></svg>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Example 2 from TempTabQA tail set with C.L.E.A.R prompting on GPT 3.5 turbo : Input</figcaption>
</figure>
<figure id="A1.F7" class="ltx_figure"><svg id="A1.F7.pic1" class="ltx_picture ltx_centering" height="633.39" overflow="visible" version="1.1" width="600"><g transform="translate(0,633.39) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#404040" fill-opacity="1.0"><path d="M 0 5.91 L 0 627.48 C 0 630.75 2.64 633.39 5.91 633.39 L 594.09 633.39 C 597.36 633.39 600 630.75 600 627.48 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#FFFFFF" fill-opacity="1.0"><path d="M 1.97 5.91 L 1.97 627.48 C 1.97 629.66 3.73 631.42 5.91 631.42 L 594.09 631.42 C 596.27 631.42 598.03 629.66 598.03 627.48 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignObject width="556.69" height="605.83" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">
<span id="A1.F7.pic1.1.1.1.1.1" class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:402.3pt;">
<span id="A1.F7.pic1.1.1.1.1.1.1" class="ltx_block ltx_minipage ltx_align_middle" style="width:426.8pt;">
<span id="A1.F7.pic1.1.1.1.1.1.1.1" class="ltx_p"><span id="A1.F7.pic1.1.1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Response :</span></span>
<span id="A1.F7.pic1.1.1.1.1.1.1.2" class="ltx_p ltx_align_left ltx_align_center"><span id="A1.F7.pic1.1.1.1.1.1.1.2.1" class="ltx_text ltx_font_bold">Step 1.</span> Comprehend Information</span>
<span id="A1.F7.pic1.1.1.1.1.1.1.3" class="ltx_p ltx_align_left ltx_align_center">Domain Knowledge:</span>
<span id="A1.F7.pic1.1.1.1.1.1.1.4" class="ltx_p ltx_align_left ltx_align_center">- The question asks "In what year", so the answer should be a year.</span>
<span id="A1.F7.pic1.1.1.1.1.1.1.5" class="ltx_p ltx_align_left ltx_align_center">- To determine the last team someone was associated with, identify the one that occurred most recently.</span>
<span id="A1.F7.pic1.1.1.1.1.1.1.6" class="ltx_p ltx_align_left ltx_align_center">- Given an event spanning a range of years, the start is the first number in that range.</span>
<span id="A1.F7.pic1.1.1.1.1.1.1.7" class="ltx_p ltx_align_left ltx_align_center"><span id="A1.F7.pic1.1.1.1.1.1.1.7.1" class="ltx_text ltx_font_bold">Step 2.</span> Locate Relevant Rows</span>
<span id="A1.F7.pic1.1.1.1.1.1.1.8" class="ltx_p ltx_align_left ltx_align_center">- "Title  Dwight Bernard": This indicates that the information in the table is about Dwight Bernard.</span>
<span id="A1.F7.pic1.1.1.1.1.1.1.9" class="ltx_p ltx_align_left ltx_align_center">- "Teams  [’New York Mets (1978-1979) | Milwaukee Brewers (1981-1982)’]": This provides a list of all teams Dwight Bernard played with and the years he played with each.</span>
<span id="A1.F7.pic1.1.1.1.1.1.1.10" class="ltx_p ltx_align_left ltx_align_center"><span id="A1.F7.pic1.1.1.1.1.1.1.10.1" class="ltx_text ltx_font_bold">Step 3.</span> Examine the Question</span>
<span id="A1.F7.pic1.1.1.1.1.1.1.11" class="ltx_p ltx_align_left ltx_align_center">OQ) In what year did Dwight Bernard start playing with the last team he was associated with? The table doesn’t provide this information. To determine this, we need to know the following:</span>
<span id="A1.I2" class="ltx_itemize ltx_align_left ltx_centering">
<span id="A1.I2.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="A1.I2.i1.p1" class="ltx_para">
<span id="A1.I2.i1.p1.1" class="ltx_p">SQ1) What was the last team Dwight Bernard was associated with?</span>
</span></span>
<span id="A1.I2.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="A1.I2.i2.p1" class="ltx_para">
<span id="A1.I2.i2.p1.1" class="ltx_p">SQ2) When did Dwight Bernard start playing for this team?</span>
</span></span>
</span>
<span id="A1.F7.pic1.1.1.1.1.1.1.12" class="ltx_p ltx_align_left ltx_align_center">SQ1) What was the last team Dwight Bernard was associated with?</span>
<span id="A1.F7.pic1.1.1.1.1.1.1.13" class="ltx_p ltx_align_left ltx_align_center">The table doesn’t provide this information. However, the table provides a list of all teams Bernard was associated with and the years he was associated with each team. We can determine the last team Dwight Bernard was associated with by comparing the last year he was associated with each of his teams.</span>
<span id="A1.F7.pic1.1.1.1.1.1.1.14" class="ltx_p ltx_align_left ltx_align_center">SQ2) When did Dwight Bernard start playing for this team?</span>
<span id="A1.F7.pic1.1.1.1.1.1.1.15" class="ltx_p ltx_align_left ltx_align_center">The table provides the range of years Bernard was associated with each of his teams. We can determine the year he started playing for that team by looking at the start year in the range.</span>
<span id="A1.F7.pic1.1.1.1.1.1.1.16" class="ltx_p ltx_align_left ltx_align_center"><span id="A1.F7.pic1.1.1.1.1.1.1.16.1" class="ltx_text ltx_font_bold">Step 4.</span> Analyze Sub-Questions</span>
<span id="A1.F7.pic1.1.1.1.1.1.1.17" class="ltx_p ltx_align_left ltx_align_center">SQ1) The only teams Dwight Bernard has played with are the New York Mets and Milwaukee Brewers. Bernard played for the Mets from 1978 to 1979 and the Brewers from 1981 to 1982. He was associated with the Brewers in 1982, which is more recent than the Mets in 1979; therefore, the last team he was associated with is the Brewers.</span>
<span id="A1.F7.pic1.1.1.1.1.1.1.18" class="ltx_p ltx_align_left ltx_align_center">SQ2) He played with the Brewers from 1981 to 1982, so he started playing for the Brewers in 1981.
<span id="A1.F7.pic1.1.1.1.1.1.1.18.1" class="ltx_text ltx_font_bold">Step 5.</span> Resolve to Form the Final Answer</span>
<span id="A1.F7.pic1.1.1.1.1.1.1.19" class="ltx_p ltx_align_left ltx_align_center">OQ) In what year did Dwight Bernard start playing with the last team he was associated with?</span>
<span id="A1.F7.pic1.1.1.1.1.1.1.20" class="ltx_p ltx_align_left ltx_align_center">The last team Dwight Bernard was associated with was the Brewers (SQ1), which he started playing for in 1981 (SQ2).</span>
<span id="A1.F7.pic1.1.1.1.1.1.1.21" class="ltx_p ltx_align_left ltx_align_center">Therefore, Dwight Bernard started playing with the last team he was associated with in 1981.</span>
<span id="A1.F7.pic1.1.1.1.1.1.1.22" class="ltx_p ltx_align_left ltx_align_center"><span id="A1.F7.pic1.1.1.1.1.1.1.22.1" class="ltx_text ltx_font_bold">Final Answer: 1981</span></span>
</span>
</span></foreignObject></g></g></svg>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Example 2 from TempTabQA tail set with C.L.E.A.R prompting on GPT 3.5 turbo : Response</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2407.16029" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2407.16030" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2407.16030">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2407.16030" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2407.16031" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Mon Aug  5 18:11:41 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
