<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Joint Modeling of Search and Recommendations Via an Unified Contextual Recommender (UniCoRn)</title>
<!--Generated on Mon Aug 19 20:16:26 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="Search,  Recommendations,  Personalization" lang="en" name="keywords"/>
<base href="/html/2408.10394v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2408.10394v1#S1" title="In Joint Modeling of Search and Recommendations Via an Unified Contextual Recommender (UniCoRn)"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2408.10394v1#S2" title="In Joint Modeling of Search and Recommendations Via an Unified Contextual Recommender (UniCoRn)"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Proposed Approach</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2408.10394v1#S3" title="In Joint Modeling of Search and Recommendations Via an Unified Contextual Recommender (UniCoRn)"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2408.10394v1#S4" title="In Joint Modeling of Search and Recommendations Via an Unified Contextual Recommender (UniCoRn)"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Authors Bio</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">Joint Modeling of Search and Recommendations Via an Unified Contextual Recommender (UniCoRn)</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Moumita Bhattacharya
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:mbhattacharya@netflix.com">mbhattacharya@netflix.com</a>
</span>
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/1234-5678-9012" title="ORCID identifier">1234-5678-9012</a></span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id1.1.id1">Netflix Research</span><span class="ltx_text ltx_affiliation_city" id="id2.2.id2">Los Gatos</span><span class="ltx_text ltx_affiliation_state" id="id3.3.id3">CA</span><span class="ltx_text ltx_affiliation_country" id="id4.4.id4">USA</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Vito Ostuni
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:vostuni@netflix.com">vostuni@netflix.com</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id5.1.id1">Netflix Research</span><span class="ltx_text ltx_affiliation_city" id="id6.2.id2">Los Gatos</span><span class="ltx_text ltx_affiliation_state" id="id7.3.id3">CA</span><span class="ltx_text ltx_affiliation_country" id="id8.4.id4">USA</span>
</span></span></span>
<span class="ltx_author_before"> and </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Sudarshan Lamkhede
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:slamkhede@netflix.com">slamkhede@netflix.com</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id9.1.id1">Netflix Research</span><span class="ltx_text ltx_affiliation_city" id="id10.2.id2">Los Gatos</span><span class="ltx_text ltx_affiliation_state" id="id11.3.id3">CA</span><span class="ltx_text ltx_affiliation_country" id="id12.4.id4">USA</span>
</span></span></span>
</div>
<div class="ltx_dates">(2024; 2024)</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p class="ltx_p" id="id13.id1">Search and recommendation systems are essential in many services, and they are often developed separately, leading to complex maintenance and technical debt. In this paper, we present a unified deep learning model that efficiently handles key aspects of both tasks.</p>
</div>
<div class="ltx_keywords">Search, Recommendations, Personalization
</div>
<span class="ltx_note ltx_note_frontmatter ltx_role_copyright" id="id1"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">copyright: </span>acmlicensed</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_journalyear" id="id2"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">journalyear: </span>2024</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_doi" id="id3"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">doi: </span>XXXXXXX.XXXXXXX</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_conference" id="id4"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">conference: </span>Make sure to enter the correct
conference title from your rights confirmation emai; June 03–05,
2024; Woodstock, NY</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_isbn" id="id5"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">isbn: </span>978-1-4503-XXXX-X/18/06</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_journalyear" id="id6"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">journalyear: </span>2024</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_copyright" id="id7"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">copyright: </span>rightsretained</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_conference" id="id8"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">conference: </span>18th ACM Conference on Recommender Systems; October 14–18, 2024; Bari, Italy</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_booktitle" id="id9"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">booktitle: </span>18th ACM Conference on Recommender Systems (RecSys ’24), October 14–18, 2024, Bari, Italy</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_doi" id="id10"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">doi: </span>10.1145/3640457.3688034</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_isbn" id="id11"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">isbn: </span>979-8-4007-0505-2/24/10</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_ccs" id="id12"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Information systems Learning to rank</span></span></span>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">In real-world applications, teams often develop separate models to solve search and recommendation tasks. Throughout various services, it is common to have query-driven item searches, item-to-item similarity-based recommendations as well as other kinds of more traditional recommendations. It is often the case that teams develop bespoke models for each use case, which can rapidly result in systems management overhead and hidden technical debt in maintaining a large number of specialized models. As observed by <cite class="ltx_cite ltx_citemacro_citep">(Sculley et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.10394v1#bib.bib7" title="">2015</a>; Menezes et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.10394v1#bib.bib5" title="">2023</a>)</cite>, this complexity can lead to increased long-term costs, and reduced reliability and effectiveness of ML systems. Moreover, we argue that these different applications can benefit from each other <cite class="ltx_cite ltx_citemacro_citep">(Zamani and Croft, <a class="ltx_ref" href="https://arxiv.org/html/2408.10394v1#bib.bib8" title="">2018</a>)</cite>. In this talk, we will describe a series of practical solutions and modeling approaches that we built to leverage one single deep learning model to serve both search and certain recommendations tasks. Additionally, we share approaches that we took to personalize search results at scale, while also improving the recommendation use cases served by this unified model.</p>
</div>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="275" id="S1.F1.g1" src="x1.png" width="689"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1. </span>Unified Contextual Ranker (UniCoRn) powering multiple different search and recommendation tasks</figcaption>
</figure>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Proposed Approach</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1"><span class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" id="S2.p1.1.1">Model Unification</span><span class="ltx_text ltx_font_bold" id="S2.p1.1.2">:</span> Prior to developing the approach presented here, we had several models powering different applications on the Netflix product. With our approach we were able to unify some of these models. For example, we trained a model that exclusively powered Netflix Search canvas (<span class="ltx_text ltx_font_italic" id="S2.p1.1.3">Query-Video-Recommendations</span>), where when a member types in a query, we show videos that are relevant to the query <cite class="ltx_cite ltx_citemacro_citep">(Lamkhede and Kofler, <a class="ltx_ref" href="https://arxiv.org/html/2408.10394v1#bib.bib4" title="">2021</a>)</cite>. Similarly, we trained a separate model that generated recommendations for a given video when a user clicks on it to show other videos that are similar to it (<span class="ltx_text ltx_font_italic" id="S2.p1.1.4">Video-Video-Recommendations</span>). We trained yet another model to power recommendations on PreQuery or anticipatory search canvas (<span class="ltx_text ltx_font_italic" id="S2.p1.1.5">Profile-Video-Recommendations</span> <cite class="ltx_cite ltx_citemacro_citep">(Bhattacharya and Lamkhede, <a class="ltx_ref" href="https://arxiv.org/html/2408.10394v1#bib.bib2" title="">2022</a>)</cite>). As we consider search and recommendation as ”two sides of the same coin”, we embarked into a journey of unification of all these different models, such that not only we consolidate the tech stack, but also be able to use just one trained model to serve all these different types of applications across different parts of the Netflix product, as shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2408.10394v1#S1.F1" title="Figure 1 ‣ 1. Introduction ‣ Joint Modeling of Search and Recommendations Via an Unified Contextual Recommender (UniCoRn)"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">One of the key differences between a traditional search ranking model and a traditional recommender system is the input context. Search is centered around an explicit textual <span class="ltx_text ltx_font_italic" id="S2.p2.1.1">query</span> context, while recommendations are driven by the <span class="ltx_text ltx_font_italic" id="S2.p2.1.2">user context</span> and/or other context such as <span class="ltx_text ltx_font_italic" id="S2.p2.1.3">source item</span>. More specifically, when a user visits the Search PreQuery page they are shown a list of recommendations that are personalized for them. As soon as the user types something, they are shown search results relevant to their query. We approached these two separate context driven tasks as one task with a <span class="ltx_text ltx_font_bold" id="S2.p2.1.4">shared broader context definition</span>.</p>
</div>
<div class="ltx_para" id="S2.p3">
<p class="ltx_p" id="S2.p3.1">We develop a model that has in its <span class="ltx_text ltx_font_bold" id="S2.p3.1.1">context</span> the following information: <span class="ltx_text ltx_font_italic" id="S2.p3.1.2">user id</span>, <span class="ltx_text ltx_font_italic" id="S2.p3.1.3">query</span>, <span class="ltx_text ltx_font_italic" id="S2.p3.1.4">country</span>, <span class="ltx_text ltx_font_italic" id="S2.p3.1.5">source entity id</span> and <span class="ltx_text ltx_font_italic" id="S2.p3.1.6">task</span>. Note, <span class="ltx_text ltx_font_italic" id="S2.p3.1.7">entity id</span> here refers to the <span class="ltx_text ltx_font_italic" id="S2.p3.1.8">id</span> of a video or a game. The <span class="ltx_text ltx_font_bold" id="S2.p3.1.9">output</span> of this model is a probability score for positive engagement with an entity, which we will refer to as <span class="ltx_text ltx_font_italic" id="S2.p3.1.10">target entity id</span> from here on. This model is trained on a dataset that is gathered from engagements pertaining to all the different tasks, which was possible because of the broadened context.</p>
</div>
<div class="ltx_para" id="S2.p4">
<p class="ltx_p" id="S2.p4.1">For some tasks, only certain contexts are available. For example, for the search task, we have <span class="ltx_text ltx_font_italic" id="S2.p4.1.1">query</span>, <span class="ltx_text ltx_font_italic" id="S2.p4.1.2">user id</span>, <span class="ltx_text ltx_font_italic" id="S2.p4.1.3">country</span> and <span class="ltx_text ltx_font_italic" id="S2.p4.1.4">task</span> contexts available but we don’t have any <span class="ltx_text ltx_font_italic" id="S2.p4.1.5">source entity id</span> information. Similarly, for Video-Video Recommendations tasks we don’t have <span class="ltx_text ltx_font_italic" id="S2.p4.1.6">query</span> in the context. We developed different heuristics to impute missing contexts for each tasks. Specifically, for search tasks we impute null value to the missing context, whereas for certain recommendations tasks such video-video or entity-video recommendations, we impute the missing <span class="ltx_text ltx_font_italic" id="S2.p4.1.7">query</span> context by leveraging tokens of the display names of the entity. This imputation approach reduces missing context, which helps with improved cross-application learning.</p>
</div>
<div class="ltx_para" id="S2.p5">
<p class="ltx_p" id="S2.p5.1">We use several features, which can be broadly classified into two types: (1) context specific features (such as query length, source entity id embedding) and (2) context and <span class="ltx_text ltx_font_italic" id="S2.p5.1.1">target entity id</span> features (such as number of clicks of the <span class="ltx_text ltx_font_italic" id="S2.p5.1.2">target entity id</span> for a given query). These features are either categorical or real valued numeric features. We trained a deep learning model, where all these features are fed in the input layer and each categorical feature is leveraged to learn corresponding embedding layers. The model architecture includes residual connections and feature crossing. We use a binary cross entropy loss, with an Adam optimizer.</p>
</div>
<div class="ltx_para" id="S2.p6">
<p class="ltx_p" id="S2.p6.1">Once trained, this model then can generate different ranked results for different types of context. For example, the same model can show videos for a query, while on PreQuery recommend personalized videos for the user. In fact, after a series of experiments and improvements we have one model that currently powers <span class="ltx_text ltx_font_italic" id="S2.p6.1.1">Netflix Search</span>, <span class="ltx_text ltx_font_italic" id="S2.p6.1.2">Personalized Pre-query canvas</span>, <span class="ltx_text ltx_font_italic" id="S2.p6.1.3">More Like this Canvas</span>, among others. We will refer to this proposed unified contextual model as <span class="ltx_text ltx_font_italic" id="S2.p6.1.4">UniCoRn</span> from here on. With this unification we were able to achieve either a lift or parity in performance for different tasks.</p>
</div>
<div class="ltx_para" id="S2.p7">
<p class="ltx_p" id="S2.p7.1">Our work shows how training one model on a larger dataset and having individual tasks share data among them performs better than the individual models trained on their own, as each task benefits from auxiliary ones. A few things in our setup that enables such information passing among the different tasks, thus making it possible for us to serve both search and recommendations tasks via one model are: (1) adding the task type as context and having features that are specific to different tasks helps the model to learn trade-offs between the different tasks. (2) Imputing in missing contexts wherever possible helps better feature coverage and enable the model to learn across different tasks better. (3) Feature crossing also helps with cross task learning.</p>
</div>
<div class="ltx_para" id="S2.p8">
<p class="ltx_p" id="S2.p8.1"><span class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" id="S2.p8.1.1">Personalization of the Unified Model</span><span class="ltx_text ltx_font_bold" id="S2.p8.1.2">:</span> A single model powering both Search and Recommendation tasks, gives us the advantage of easily leveraging the personalization capabilities typical of the Recommendation task in the Search task. However, blindly applying personalization to Search may incur undesirable consequences where personalization takes over query relevance. Therefore, we need to control for context relevance and personalization accordingly. A fully personalized search experience also poses serving challenges as we need to meet strict latency requirements. The low latency constraint is due to the nature of our instant results experience where we return results for each keystroke <cite class="ltx_cite ltx_citemacro_citep">(Lamkhede and Das, <a class="ltx_ref" href="https://arxiv.org/html/2408.10394v1#bib.bib3" title="">2019</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S2.p9">
<p class="ltx_p" id="S2.p9.1">We took an incremental approach to personalize the unified model. We started with a semi-personalized model based on user clustering, where the user cluster assignment is a context level feature. Although this experience was not fully personalized, it had the advantage of still enabling results caching. We then moved to a more powerful fully personalized model, first relying on separate recommendation model’s outputs used as features. More details about these approaches are in <cite class="ltx_cite ltx_citemacro_citep">(Ostuni et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.10394v1#bib.bib6" title="">2023</a>)</cite>. Subsequently, we developed an end-to-end architecture, which incorporated a pre-trained user and item representations model that was fine-tuned with UniCoRn. These personalization approaches with appropriate model architecture led to significant improvements in the offline metrics for both search and recommendations tasks. Specifically, the lift from a vanilla non-personalized UniCoRn to a fully personalized one was  7% and  10% for search and a recommendations, respectively.</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>Conclusion</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">This work demonstrates that a single unified model, aware of diverse contexts, can perform and improve both search and recommendation tasks. Additionally, incorporating personalization within this model benefits both applications, while optimally trading-off relevance and personalization.</p>
</div>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>Authors Bio</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">Moumita Bhattacharya and Vito Ostuni are research scientist at Netflix where they work on Search and Recommendation algorithms. Sudarshan Lamkhede is a Engineering Manager at Netflix leading the Foundation Model and Search Algorithms team.</p>
</div>
<div class="ltx_acknowledgements">
<h6 class="ltx_title ltx_title_acknowledgements">Acknowledgements.</h6>
We are thankful to our collaborators Roger Menezes, Gary Yeh, Manjesh Nilange, Jinning Zhong, Guru Tahasildar, Christoph Kofler and Raveesh Bhalla as well as internal reviewer Justin Basilico.

</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bhattacharya and Lamkhede (2022)</span>
<span class="ltx_bibblock">
Moumita Bhattacharya and
Sudarshan Lamkhede. 2022.

</span>
<span class="ltx_bibblock">Augmenting Netflix Search with In-Session Adapted
Recommendations. In <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">Proceedings of the 16th ACM
Conference on Recommender Systems</em> <em class="ltx_emph ltx_font_italic" id="bib.bib2.2.2">(RecSys ’22)</em>.
Association for Computing Machinery,
New York, NY, USA, 542–545.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3523227.3547407" title="">https://doi.org/10.1145/3523227.3547407</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lamkhede and Das (2019)</span>
<span class="ltx_bibblock">
Sudarshan Lamkhede and
Sudeep Das. 2019.

</span>
<span class="ltx_bibblock">Challenges in Search on Streaming Services: Netflix
Case Study. In <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">Proceedings of the 42nd
International ACM SIGIR Conference on Research and Development in Information
Retrieval</em> (Paris, France) <em class="ltx_emph ltx_font_italic" id="bib.bib3.2.2">(SIGIR’19)</em>.
Association for Computing Machinery,
New York, NY, USA, 1371–1374.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3331184.3331440" title="">https://doi.org/10.1145/3331184.3331440</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lamkhede and Kofler (2021)</span>
<span class="ltx_bibblock">
Sudarshan Dnyaneshwar Lamkhede and
Christoph Kofler. 2021.

</span>
<span class="ltx_bibblock">Recommendations and Results Organization in Netflix
Search. In <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">Proceedings of the 15th ACM Conference
on Recommender Systems</em> (Amsterdam, Netherlands)
<em class="ltx_emph ltx_font_italic" id="bib.bib4.2.2">(RecSys ’21)</em>. Association for
Computing Machinery, New York, NY, USA,
577–579.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3460231.3474602" title="">https://doi.org/10.1145/3460231.3474602</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Menezes et al<span class="ltx_text" id="bib.bib5.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Roger Menezes, Rahul Jha,
Gary Yeh, and Sudarshan Lamkhede.
2023.

</span>
<span class="ltx_bibblock">Lessons Learnt From Consolidating ML Models in a
Large Scale Recommendation System.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://netflixtechblog.medium.com/lessons-learnt-from-consolidating-ml-models-in-a-large-scale-recommendation-system-870c5ea5eb4a" title="">https://netflixtechblog.medium.com/lessons-learnt-from-consolidating-ml-models-in-a-large-scale-recommendation-system-870c5ea5eb4a</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ostuni et al<span class="ltx_text" id="bib.bib6.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Vito Ostuni, Christoph
Kofler, Manjesh Nilange, Sudarshan
Lamkhede, and Dan Zylberglejd.
2023.

</span>
<span class="ltx_bibblock">Search Personalization at Netflix. In
<em class="ltx_emph ltx_font_italic" id="bib.bib6.3.1">Companion Proceedings of the ACM Web Conference
2023</em> <em class="ltx_emph ltx_font_italic" id="bib.bib6.4.2">(WWW ’23 Companion)</em>.
Association for Computing Machinery,
New York, NY, USA, 756–758.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3543873.3587675" title="">https://doi.org/10.1145/3543873.3587675</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sculley et al<span class="ltx_text" id="bib.bib7.2.2.1">.</span> (2015)</span>
<span class="ltx_bibblock">
David Sculley, Gary Holt,
Daniel Golovin, Eugene Davydov,
Todd Phillips, Dietmar Ebner,
Vinay Chaudhary, Michael Young,
Jean-Francois Crespo, and Dan
Dennison. 2015.

</span>
<span class="ltx_bibblock">Hidden technical debt in machine learning systems.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib7.3.1">Advances in neural information processing
systems</em> 28 (2015).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zamani and Croft (2018)</span>
<span class="ltx_bibblock">
Hamed Zamani and W Bruce
Croft. 2018.

</span>
<span class="ltx_bibblock">Joint modeling and optimization of search and
recommendation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">arXiv preprint arXiv:1807.05631</em>
(2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Mon Aug 19 20:16:26 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
