<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2402.07792] Empowering Federated Learning for Massive Models with NVIDIA FLARE</title><meta property="og:description" content="In the ever-evolving landscape of artificial intelligence (AI) and large language models (LLMs), handling and leveraging data effectively has become a critical challenge. Most state-of-the-art machine learning algorith…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Empowering Federated Learning for Massive Models with NVIDIA FLARE">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Empowering Federated Learning for Massive Models with NVIDIA FLARE">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2402.07792">

<!--Generated on Tue Mar  5 13:19:46 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">Empowering Federated Learning for Massive Models with NVIDIA FLARE</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Holger R. Roth, Ziyue Xu, Yuan-Ting Hsieh, Adithya Renduchintala, Isaac Yang, Zhihong Zhang, Yuhong Wen, Sean Yang, Kevin Lu, Kristopher Kersten, Camir Ricketts, Daguang Xu, Chester Chen, Yan Cheng, Andrew Feng
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id1.1.id1" class="ltx_text ltx_affiliation_institution">NVIDIA Corporation</span><span id="id2.2.id2" class="ltx_text ltx_affiliation_city">Santa Clara</span><span id="id3.3.id3" class="ltx_text ltx_affiliation_country">USA</span>
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p id="id4.id1" class="ltx_p">In the ever-evolving landscape of artificial intelligence (AI) and large language models (LLMs), handling and leveraging data effectively has become a critical challenge. Most state-of-the-art machine learning algorithms are data-centric. However, as the lifeblood of model performance, necessary data cannot always be centralized due to various factors such as privacy, regulation, geopolitics, copyright issues, and the sheer effort required to move vast datasets. In this paper, we explore how federated learning enabled by NVIDIA FLARE can address these challenges with easy and scalable integration capabilities, enabling parameter-efficient and full supervised fine-tuning of LLMs for natural language processing and biopharmaceutical applications to enhance their accuracy and robustness.</p>
</div>
<div class="ltx_keywords">
<span id="id5.id1" class="ltx_text" style="font-size:90%;">Federated Learning, Massive Models, Large Language Models, Natural language Processing, Biopharma, Drug Discovery, Privacy.</span>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Data management and utilization are pivotal challenges in the dynamic realm of artificial intelligence (AI) and large language models (LLMs). Contemporary machine learning algorithms often rely on data-centric approaches and face obstacles in centralized data handling due to multifaceted concerns such as privacy, regulatory constraints, geopolitical factors, copyright issues, and the considerable logistical demands associated with moving extensive datasets.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">This paper delves into the practical application of federated learning (FL), particularly exploring the capabilities offered by NVIDIA FLARE<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a target="_blank" href="https://github.com/NVIDIA/NVFlare" title="" class="ltx_ref ltx_url" style="color:#0000FF;">https://github.com/NVIDIA/NVFlare</a></span></span></span> (NVFlare)  <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib29" title="" class="ltx_ref">roth2022nvidia, </a>)</cite> in addressing these challenges. Through seamless and scalable integration, NVFlare facilitates parameter-efficient fine-tuning (PEFT) <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib13" title="" class="ltx_ref">he2021towards, </a>; <a href="#bib.bib8" title="" class="ltx_ref">ding2023parameter, </a>)</cite> and full supervised fine-tuning (SFT). With a specific focus on applications in natural language processing (NLP) and biopharma utilizing modern LLM architectures. The aim is to enhance the accuracy and robustness of these models by applying FL in real-world situations.</p>
</div>
<section id="S1.SS0.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">The Data Challenge</h4>

<div id="S1.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S1.SS0.SSS0.Px1.p1.1" class="ltx_p">The need to access data from multiple sources is a common scenario in many LLM tasks. Consider scenarios like gathering reports from different hospitals for medical research or collecting financial data from diverse institutions for analysis. Centralizing such data may be impractical and hindered by privacy concerns, regulatory hurdles, etc. FL offers an elegant solution to this issue <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib26" title="" class="ltx_ref">rieke2020future, </a>)</cite>.</p>
</div>
</section>
<section id="S1.SS0.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Federated Learning</h4>

<div id="S1.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S1.SS0.SSS0.Px2.p1.1" class="ltx_p">FL has emerged as a practical solution to tackle data challenges. Instead of centrally training models with access to raw data, FL facilitates sharing model updates rather than raw data itself. This means that participating clients can train models locally using their own private datasets to compute a local model update. These local updates are then combined globally to update the model parameters. This approach maintains the privacy of individual datasets while enabling the global model to benefit from the collective knowledge gained during training. The result is the training of more robust and generalizable models <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib6" title="" class="ltx_ref">dayan2021federated, </a>)</cite>.</p>
</div>
<div id="S1.SS0.SSS0.Px2.p2" class="ltx_para">
<p id="S1.SS0.SSS0.Px2.p2.1" class="ltx_p">FL provides several options for training AI models. Essentially, it allows for the training of a global model while ensuring the privacy and governance of the data involved. Moreover, FL can be tailored to meet the specific needs of each client, thus enabling the creation of personalized models. Additionally, FL infrastructure extends beyond training and can also be utilized for tasks such as inference and federated evaluation.</p>
</div>
</section>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Methods</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1. </span>FL Framework</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">NVFlare is an open-source framework that allows researchers and data scientists to seamlessly move their machine learning and deep learning workflows into a federated paradigm. Furthermore, it empowers platform developers to construct secure and privacy-preserving solutions for collaborative multiparty distributed workflows.
NVFlare is a lightweight, flexible, and scalable FL framework implemented in Python. Notably, it remains agnostic to the underlying training library, allowing developers to use PyTorch, TensorFlow, or even pure NumPy for their data science workflows in a federated setting.
In the NVFlare ecosystem, a standard FL workflow, like the well-known federated averaging (FedAvg) algorithm <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib22" title="" class="ltx_ref">mcmahan2017communication, </a>)</cite>, involves the following key steps. Each FL client receives an initial global model from the FL server and conducts local training on their data. Next, the clients transmit model updates to the server for aggregation. The server, in turn, applies these aggregated updates to refine the global model for subsequent training rounds. This procedure is repeated until convergence is achieved.
While NVFlare finds frequent use in federated deep learning <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib6" title="" class="ltx_ref">dayan2021federated, </a>; <a href="#bib.bib28" title="" class="ltx_ref">roth2020federated, </a>; <a href="#bib.bib32" title="" class="ltx_ref">sarma2021federated, </a>; <a href="#bib.bib10" title="" class="ltx_ref">guo2022auto, </a>; <a href="#bib.bib35" title="" class="ltx_ref">sun2023communication, </a>; <a href="#bib.bib39" title="" class="ltx_ref">wang2023condistfl, </a>; <a href="#bib.bib17" title="" class="ltx_ref">jiang2023fair, </a>; <a href="#bib.bib41" title="" class="ltx_ref">xu2022closing, </a>)</cite>, its versatility extends to supporting general federated computing across diverse clients. It provides the <span id="S2.SS1.p1.1.1" class="ltx_text ltx_font_italic">Controller Programming API</span>, enabling researchers to craft flexible workflows for orchestrating client collaboration. FedAvg <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib22" title="" class="ltx_ref">mcmahan2017communication, </a>)</cite> and cyclic weight transfer <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib3" title="" class="ltx_ref">chang2018distributed, </a>)</cite> are examples of such workflows.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">At the heart of NVFlare lies the concept of collaboration through ”tasks.” An FL controller assigns tasks (e.g., deep-learning training with model weights) to one or more FL clients, processes returned results (e.g., model weight updates), and may assign additional tasks based on these results and other factors (e.g., a pre-configured number of training rounds). This task-based interaction repeats until the experiment’s objectives are met.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2. </span>Easy Adaptation of ML Workflows via Client API</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">The NVFlare <span id="S2.SS2.p1.1.1" class="ltx_text ltx_font_italic">Client API</span> offers a convenient solution for users looking to transition their centralized, local training code to FL with several advantages:</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<ul id="S2.I1" class="ltx_itemize">
<li id="S2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i1.p1" class="ltx_para">
<p id="S2.I1.i1.p1.1" class="ltx_p"><span id="S2.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Minimal Code Changes:</span> Users can achieve the transition with only a few lines of code adjustments, eliminating the need for a comprehensive restructuring or implementation of a new class.</p>
</div>
</li>
<li id="S2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i2.p1" class="ltx_para">
<p id="S2.I1.i2.p1.1" class="ltx_p"><span id="S2.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Simplicity:</span> The <span id="S2.I1.i2.p1.1.2" class="ltx_text ltx_font_italic">Client API</span> minimizes the introduction of new NVFlare-specific concepts to users, streamlining the adaptation process by leveraging familiar programming constructs.</p>
</div>
</li>
<li id="S2.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i3.p1" class="ltx_para">
<p id="S2.I1.i3.p1.1" class="ltx_p"><span id="S2.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">Flexibility:</span> Users can easily adapt existing local training code written in various frameworks such as PyTorch, PyTorch Lightning, and HuggingFace, making the transition seamless and efficient.</p>
</div>
</li>
</ul>
</div>
<div id="S2.SS2.p3" class="ltx_para ltx_noindent">
<p id="S2.SS2.p3.1" class="ltx_p">The general structure of a popular FL workflow, such as <span id="S2.SS2.p3.1.1" class="ltx_text ltx_font_italic">FedAvg</span> is as follows:</p>
</div>
<div id="S2.SS2.p4" class="ltx_para">
<span id="S2.SS2.p4.1" class="ltx_inline-block ltx_framed ltx_framed_rectangle" style="border-color: #000000;">
<span id="S2.I2" class="ltx_enumerate">
<span id="S2.I2.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">(1)</span> 
<span id="S2.I2.i1.p1" class="ltx_para">
<span id="S2.I2.i1.p1.1" class="ltx_p">FL server initializes an initial model.</span>
</span></span>
<span id="S2.I2.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">(2)</span> 
<span id="S2.I2.i2.p1" class="ltx_para">
<span id="S2.I2.i2.p1.1" class="ltx_p"><span id="S2.I2.i2.p1.1.1" class="ltx_text ltx_font_italic">For each round (global iteration):</span></span>
<span id="S2.I2.i2.I1" class="ltx_enumerate">
<span id="S2.I2.i2.I1.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">(a)</span> 
<span id="S2.I2.i2.I1.i1.p1" class="ltx_para">
<span id="S2.I2.i2.I1.i1.p1.1" class="ltx_p">FL server sends the global model to clients.</span>
</span></span>
<span id="S2.I2.i2.I1.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">(b)</span> 
<span id="S2.I2.i2.I1.i2.p1" class="ltx_para">
<span id="S2.I2.i2.I1.i2.p1.1" class="ltx_p">Each FL client starts with this global model and trains on their own data.</span>
</span></span>
<span id="S2.I2.i2.I1.i3" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">(c)</span> 
<span id="S2.I2.i2.I1.i3.p1" class="ltx_para">
<span id="S2.I2.i2.I1.i3.p1.1" class="ltx_p">Each FL client sends back their model update.</span>
</span></span>
<span id="S2.I2.i2.I1.i4" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">(d)</span> 
<span id="S2.I2.i2.I1.i4.p1" class="ltx_para">
<span id="S2.I2.i2.I1.i4.p1.1" class="ltx_p">FL server aggregates all the updates and produces a new global model.</span>
</span></span>
</span>
</span></span>
</span>
</span>
</div>
<div id="S2.SS2.p5" class="ltx_para ltx_noindent">
<p id="S2.SS2.p5.1" class="ltx_p">On the client side, the training workflow is as follows:</p>
</div>
<div id="S2.SS2.p6" class="ltx_para">
<span id="S2.SS2.p6.1" class="ltx_inline-block ltx_framed ltx_framed_rectangle" style="border-color: #000000;">
<span id="S2.I3" class="ltx_enumerate">
<span id="S2.I3.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">(1)</span> 
<span id="S2.I3.i1.p1" class="ltx_para">
<span id="S2.I3.i1.p1.1" class="ltx_p">Receive the model from the FL server.</span>
</span></span>
<span id="S2.I3.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">(2)</span> 
<span id="S2.I3.i2.p1" class="ltx_para">
<span id="S2.I3.i2.p1.1" class="ltx_p">Perform local training on the received global model and/or evaluate the received global model for model selection.</span>
</span></span>
<span id="S2.I3.i3" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">(3)</span> 
<span id="S2.I3.i3.p1" class="ltx_para">
<span id="S2.I3.i3.p1.1" class="ltx_p">Send the new model back to the FL server.</span>
</span></span>
</span>
</span>
</div>
<div id="S2.SS2.p7" class="ltx_para ltx_noindent">
<p id="S2.SS2.p7.1" class="ltx_p">To convert a centralized training code to FL, we need to adapt the code to execute the following steps:</p>
</div>
<div id="S2.SS2.p8" class="ltx_para">
<span id="S2.SS2.p8.1" class="ltx_inline-block ltx_framed ltx_framed_rectangle" style="border-color: #000000;">
<span id="S2.I4" class="ltx_enumerate">
<span id="S2.I4.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">(1)</span> 
<span id="S2.I4.i1.p1" class="ltx_para">
<span id="S2.I4.i1.p1.1" class="ltx_p">Obtain the required information from the received model.</span>
</span></span>
<span id="S2.I4.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">(2)</span> 
<span id="S2.I4.i2.p1" class="ltx_para">
<span id="S2.I4.i2.p1.1" class="ltx_p">Run local training.</span>
</span></span>
<span id="S2.I4.i3" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">(3)</span> 
<span id="S2.I4.i3.p1" class="ltx_para">
<span id="S2.I4.i3.p1.1" class="ltx_p">Put the results in a new model to be sent back to the FL server.</span>
</span></span>
</span>
</span>
</div>
<div id="S2.SS2.p9" class="ltx_para ltx_noindent">
<p id="S2.SS2.p9.1" class="ltx_p">For a general use case, there are three essential methods for the <span id="S2.SS2.p9.1.1" class="ltx_text ltx_font_italic">Client API</span>:</p>
</div>
<div id="S2.SS2.p10" class="ltx_para">
<ul id="S2.I5" class="ltx_itemize">
<li id="S2.I5.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I5.i1.p1" class="ltx_para">
<p id="S2.I5.i1.p1.1" class="ltx_p"><span id="S2.I5.i1.p1.1.1" class="ltx_text ltx_font_typewriter">init()</span>: Initializes NVFlare Client API environment.</p>
</div>
</li>
<li id="S2.I5.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I5.i2.p1" class="ltx_para">
<p id="S2.I5.i2.p1.1" class="ltx_p"><span id="S2.I5.i2.p1.1.1" class="ltx_text ltx_font_typewriter">receive()</span>: Receives model from the FL server.</p>
</div>
</li>
<li id="S2.I5.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I5.i3.p1" class="ltx_para">
<p id="S2.I5.i3.p1.1" class="ltx_p"><span id="S2.I5.i3.p1.1.1" class="ltx_text ltx_font_typewriter">send()</span>: Sends the model to the FL server.</p>
</div>
</li>
</ul>
</div>
<div id="S2.SS2.p11" class="ltx_para ltx_noindent">
<p id="S2.SS2.p11.1" class="ltx_p">With these simple methods, the developers can use the <span id="S2.SS2.p11.1.1" class="ltx_text ltx_font_italic">Client API</span> to change their centralized training code to an FL scenario with five lines of code changes as shown in Listing <a href="#LST1" title="Listing 1 ‣ 2.2. Easy Adaptation of ML Workflows via Client API ‣ 2. Methods ‣ Empowering Federated Learning for Massive Models with NVIDIA FLARE" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<figure id="LST1" class="ltx_float ltx_lstlisting">
<div id="LST1.1" class="ltx_listing ltx_lst_language_Python ltx_lst_numbers_left ltx_lstlisting ltx_listing" style="background-color:#F2F2EB;">
<div class="ltx_listing_data"><a href="data:text/plain;base64,ICAgIGltcG9ydCBudmZsYXJlLmNsaWVudCBhcyBmbGFyZQoKICAgIGZsYXJlLmluaXQoKSAjIDEuIEluaXRpYWxpemVzIE5WRmxhcmUgQ2xpZW50IEFQSSBlbnZpcm9ubWVudC4KICAgIGlucHV0X21vZGVsID0gZmxhcmUucmVjZWl2ZSgpICMgMi4gUmVjZWl2ZXMgbW9kZWwgZnJvbSB0aGUgRkwgc2VydmVyLgogICAgcGFyYW1zID0gaW5wdXRfbW9kZWwucGFyYW1zICMgMy4gT2J0YWluIHRoZSByZXF1aXJlZCBpbmZvcm1hdGlvbiBmcm9tIHRoZSByZWNlaXZlZCBtb2RlbC4KCiAgICAjIG9yaWdpbmFsIGxvY2FsIHRyYWluaW5nIGNvZGUKICAgIG5ld19wYXJhbXMgPSBsb2NhbF90cmFpbihwYXJhbXMpCgogICAgb3V0cHV0X21vZGVsID0gZmxhcmUuRkxNb2RlbChwYXJhbXM9bmV3X3BhcmFtcykgIyA0LiBQdXQgdGhlIHJlc3VsdHMgaW4gYSBuZXcgYEZMTW9kZWxgCiAgICBmbGFyZS5zZW5kKG91dHB1dF9tb2RlbCkgIyA1LiBTZW5kcyB0aGUgbW9kZWwgdG8gdGhlIEZMIHNlcnZlci4=" download="">⬇</a></div>
<div id="lstnumberx1" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">1</span><span id="lstnumberx1.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;">    </span><span id="lstnumberx1.2" class="ltx_text ltx_lst_keyword ltx_font_typewriter" style="font-size:70%;color:#FF00FF;">import</span><span id="lstnumberx1.3" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;"> </span><span id="lstnumberx1.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">nvflare</span><span id="lstnumberx1.5" class="ltx_text ltx_font_typewriter" style="font-size:70%;">.</span><span id="lstnumberx1.6" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">client</span><span id="lstnumberx1.7" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;"> </span><span id="lstnumberx1.8" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">as</span><span id="lstnumberx1.9" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;"> </span><span id="lstnumberx1.10" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">flare</span>
</div>
<div id="lstnumberx2" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">2</span>
</div>
<div id="lstnumberx3" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">3</span><span id="lstnumberx3.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;">    </span><span id="lstnumberx3.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">flare</span><span id="lstnumberx3.3" class="ltx_text ltx_font_typewriter" style="font-size:70%;">.</span><span id="lstnumberx3.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">init</span><span id="lstnumberx3.5" class="ltx_text ltx_font_typewriter" style="font-size:70%;">()</span><span id="lstnumberx3.6" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;"> </span><span id="lstnumberx3.7" class="ltx_text ltx_lst_comment ltx_font_typewriter" style="font-size:70%;color:#009900;">#<span id="lstnumberx3.7.1" class="ltx_text ltx_lst_space"> </span>1.<span id="lstnumberx3.7.2" class="ltx_text ltx_lst_space"> </span>Initializes<span id="lstnumberx3.7.3" class="ltx_text ltx_lst_space"> </span>NVFlare<span id="lstnumberx3.7.4" class="ltx_text ltx_lst_space"> </span>Client<span id="lstnumberx3.7.5" class="ltx_text ltx_lst_space"> </span>API<span id="lstnumberx3.7.6" class="ltx_text ltx_lst_space"> </span>environment.</span>
</div>
<div id="lstnumberx4" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">4</span><span id="lstnumberx4.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;">    </span><span id="lstnumberx4.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">input_model</span><span id="lstnumberx4.3" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;"> </span><span id="lstnumberx4.4" class="ltx_text ltx_font_typewriter" style="font-size:70%;">=</span><span id="lstnumberx4.5" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;"> </span><span id="lstnumberx4.6" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">flare</span><span id="lstnumberx4.7" class="ltx_text ltx_font_typewriter" style="font-size:70%;">.</span><span id="lstnumberx4.8" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">receive</span><span id="lstnumberx4.9" class="ltx_text ltx_font_typewriter" style="font-size:70%;">()</span><span id="lstnumberx4.10" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;"> </span><span id="lstnumberx4.11" class="ltx_text ltx_lst_comment ltx_font_typewriter" style="font-size:70%;color:#009900;">#<span id="lstnumberx4.11.1" class="ltx_text ltx_lst_space"> </span>2.<span id="lstnumberx4.11.2" class="ltx_text ltx_lst_space"> </span>Receives<span id="lstnumberx4.11.3" class="ltx_text ltx_lst_space"> </span>model<span id="lstnumberx4.11.4" class="ltx_text ltx_lst_space"> </span>from<span id="lstnumberx4.11.5" class="ltx_text ltx_lst_space"> </span>the<span id="lstnumberx4.11.6" class="ltx_text ltx_lst_space"> </span>FL<span id="lstnumberx4.11.7" class="ltx_text ltx_lst_space"> </span>server.</span>
</div>
<div id="lstnumberx5" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">5</span><span id="lstnumberx5.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;">    </span><span id="lstnumberx5.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">params</span><span id="lstnumberx5.3" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;"> </span><span id="lstnumberx5.4" class="ltx_text ltx_font_typewriter" style="font-size:70%;">=</span><span id="lstnumberx5.5" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;"> </span><span id="lstnumberx5.6" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">input_model</span><span id="lstnumberx5.7" class="ltx_text ltx_font_typewriter" style="font-size:70%;">.</span><span id="lstnumberx5.8" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">params</span><span id="lstnumberx5.9" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;"> </span><span id="lstnumberx5.10" class="ltx_text ltx_lst_comment ltx_font_typewriter" style="font-size:70%;color:#009900;">#<span id="lstnumberx5.10.1" class="ltx_text ltx_lst_space"> </span>3.<span id="lstnumberx5.10.2" class="ltx_text ltx_lst_space"> </span>Obtain<span id="lstnumberx5.10.3" class="ltx_text ltx_lst_space"> </span>the<span id="lstnumberx5.10.4" class="ltx_text ltx_lst_space"> </span>required<span id="lstnumberx5.10.5" class="ltx_text ltx_lst_space"> </span>information<span id="lstnumberx5.10.6" class="ltx_text ltx_lst_space"> </span>from<span id="lstnumberx5.10.7" class="ltx_text ltx_lst_space"> </span>the<span id="lstnumberx5.10.8" class="ltx_text ltx_lst_space"> </span>received<span id="lstnumberx5.10.9" class="ltx_text ltx_lst_space"> </span>model.</span>
</div>
<div id="lstnumberx6" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">6</span>
</div>
<div id="lstnumberx7" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">7</span><span id="lstnumberx7.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;">    </span><span id="lstnumberx7.2" class="ltx_text ltx_lst_comment ltx_font_typewriter" style="font-size:70%;color:#009900;">#<span id="lstnumberx7.2.1" class="ltx_text ltx_lst_space"> </span>original<span id="lstnumberx7.2.2" class="ltx_text ltx_lst_space"> </span>local<span id="lstnumberx7.2.3" class="ltx_text ltx_lst_space"> </span>training<span id="lstnumberx7.2.4" class="ltx_text ltx_lst_space"> </span>code</span>
</div>
<div id="lstnumberx8" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">8</span><span id="lstnumberx8.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;">    </span><span id="lstnumberx8.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">new_params</span><span id="lstnumberx8.3" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;"> </span><span id="lstnumberx8.4" class="ltx_text ltx_font_typewriter" style="font-size:70%;">=</span><span id="lstnumberx8.5" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;"> </span><span id="lstnumberx8.6" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">local_train</span><span id="lstnumberx8.7" class="ltx_text ltx_font_typewriter" style="font-size:70%;">(</span><span id="lstnumberx8.8" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">params</span><span id="lstnumberx8.9" class="ltx_text ltx_font_typewriter" style="font-size:70%;">)</span>
</div>
<div id="lstnumberx9" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">9</span>
</div>
<div id="lstnumberx10" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">10</span><span id="lstnumberx10.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;">    </span><span id="lstnumberx10.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">output_model</span><span id="lstnumberx10.3" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;"> </span><span id="lstnumberx10.4" class="ltx_text ltx_font_typewriter" style="font-size:70%;">=</span><span id="lstnumberx10.5" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;"> </span><span id="lstnumberx10.6" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">flare</span><span id="lstnumberx10.7" class="ltx_text ltx_font_typewriter" style="font-size:70%;">.</span><span id="lstnumberx10.8" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">FLModel</span><span id="lstnumberx10.9" class="ltx_text ltx_font_typewriter" style="font-size:70%;">(</span><span id="lstnumberx10.10" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">params</span><span id="lstnumberx10.11" class="ltx_text ltx_font_typewriter" style="font-size:70%;">=</span><span id="lstnumberx10.12" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">new_params</span><span id="lstnumberx10.13" class="ltx_text ltx_font_typewriter" style="font-size:70%;">)</span><span id="lstnumberx10.14" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;"> </span><span id="lstnumberx10.15" class="ltx_text ltx_lst_comment ltx_font_typewriter" style="font-size:70%;color:#009900;">#<span id="lstnumberx10.15.1" class="ltx_text ltx_lst_space"> </span>4.<span id="lstnumberx10.15.2" class="ltx_text ltx_lst_space"> </span>Put<span id="lstnumberx10.15.3" class="ltx_text ltx_lst_space"> </span>the<span id="lstnumberx10.15.4" class="ltx_text ltx_lst_space"> </span>results<span id="lstnumberx10.15.5" class="ltx_text ltx_lst_space"> </span>in<span id="lstnumberx10.15.6" class="ltx_text ltx_lst_space"> </span>a<span id="lstnumberx10.15.7" class="ltx_text ltx_lst_space"> </span>new<span id="lstnumberx10.15.8" class="ltx_text ltx_lst_space"> </span>‘FLModel‘</span>
</div>
<div id="lstnumberx11" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">11</span><span id="lstnumberx11.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;">    </span><span id="lstnumberx11.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">flare</span><span id="lstnumberx11.3" class="ltx_text ltx_font_typewriter" style="font-size:70%;">.</span><span id="lstnumberx11.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">send</span><span id="lstnumberx11.5" class="ltx_text ltx_font_typewriter" style="font-size:70%;">(</span><span id="lstnumberx11.6" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">output_model</span><span id="lstnumberx11.7" class="ltx_text ltx_font_typewriter" style="font-size:70%;">)</span><span id="lstnumberx11.8" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;"> </span><span id="lstnumberx11.9" class="ltx_text ltx_lst_comment ltx_font_typewriter" style="font-size:70%;color:#009900;">#<span id="lstnumberx11.9.1" class="ltx_text ltx_lst_space"> </span>5.<span id="lstnumberx11.9.2" class="ltx_text ltx_lst_space"> </span>Sends<span id="lstnumberx11.9.3" class="ltx_text ltx_lst_space"> </span>the<span id="lstnumberx11.9.4" class="ltx_text ltx_lst_space"> </span>model<span id="lstnumberx11.9.5" class="ltx_text ltx_lst_space"> </span>to<span id="lstnumberx11.9.6" class="ltx_text ltx_lst_space"> </span>the<span id="lstnumberx11.9.7" class="ltx_text ltx_lst_space"> </span>FL<span id="lstnumberx11.9.8" class="ltx_text ltx_lst_space"> </span>server.</span>
</div>
</div>
<figcaption class="ltx_caption" style="background-color:#F2F2EB;"><span class="ltx_tag ltx_tag_float">Listing 1: </span>Client API example.</figcaption>
</figure>
<div id="S2.SS2.p12" class="ltx_para ltx_noindent">
<p id="S2.SS2.p12.1" class="ltx_p">If using standardized training frameworks such as PyTorch Lightning, the conversion to FL can be even more streamlined. As an example in this paper, we use the GPT model from NVIDIA NeMo framework<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a target="_blank" href="https://www.nvidia.com/en-us/ai-data-science/generative-ai/nemo-framework" title="" class="ltx_ref ltx_url" style="color:#0000FF;">https://www.nvidia.com/en-us/ai-data-science/generative-ai/nemo-framework</a></span></span></span> <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib12" title="" class="ltx_ref">Harper_NeMo_a_toolkit, </a>)</cite> to show the application of PEFT and SFT for NLP tasks. NeMo leverages PyTorch Lightning for model training. One notable feature of NVFlare is the <span id="S2.SS2.p12.1.1" class="ltx_text ltx_font_italic">Lightning Client API</span>, which significantly simplifies the process of converting local training scripts to run in FL scenarios. With just a few lines of code changes, one can seamlessly integrate methods like PEFT and SFT. As shown in Listing <a href="#LST2" title="Listing 2 ‣ 2.2. Easy Adaptation of ML Workflows via Client API ‣ 2. Methods ‣ Empowering Federated Learning for Massive Models with NVIDIA FLARE" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, the <span id="S2.SS2.p12.1.2" class="ltx_text ltx_font_italic">Lightning trainer</span> can be adapted to run FL just by calling <span id="S2.SS2.p12.1.3" class="ltx_text ltx_font_typewriter">flare.patch(trainer)</span>.
Next, an extra while loop (<span id="S2.SS2.p12.1.4" class="ltx_text ltx_font_typewriter">while flare.is_running:</span>) is added to allow reusing the same trainer object each round of FL.
Optionally, we call <span id="S2.SS2.p12.1.5" class="ltx_text ltx_font_typewriter">trainer.validate(model)</span> to evaluate the global model received from the FL server at the current round on the client’s data. This is useful for enabling global model selection on the server based on validation scores received from each client.</p>
</div>
<figure id="LST2" class="ltx_float ltx_lstlisting">
<div id="LST2.1" class="ltx_listing ltx_lst_language_Python ltx_lst_numbers_left ltx_lstlisting ltx_listing" style="background-color:#F2F2EB;">
<div class="ltx_listing_data"><a href="data:text/plain;base64,ICAgIGltcG9ydCBudmZsYXJlLmNsaWVudC5saWdodG5pbmcgYXMgZmxhcmUKCiAgICAuLi4KICAgICMgMS4gZmxhcmUgcGF0Y2gKICAgIGZsYXJlLnBhdGNoKHRyYWluZXIpCgogICAgIyAyLiBBZGQgd2hpbGUgbG9vcCB0byBrZWVwIHJlY2VpdmluZyB0aGUgbW9kZWwgaW4gZWFjaCBGTCByb3VuZC4KICAgICMgTm90ZSwgYWZ0ZXIgYGZsYXJlLnBhdGNoYCB0aGUgdHJhaW5lci5maXQvdmFsaWRhdGUgd2lsbCBnZXQgdGhlCiAgICAjIGdsb2JhbCBtb2RlbCBpbnRlcm5hbGx5IGF0IGVhY2ggcm91bmQuCiAgICB3aGlsZSBmbGFyZS5pc19ydW5uaW5nKCk6CiAgICAgICAgIyAob3B0aW9uYWwpOiBnZXQgdGhlIEZMIHN5c3RlbSBpbmZvCiAgICAgICAgZmxfc3lzX2luZm8gPSBmbGFyZS5zeXN0ZW1faW5mbygpCiAgICAgICAgcHJpbnQoIi0tLSBmbF9zeXNfaW5mbyAtLS0iKQogICAgICAgIHByaW50KGZsX3N5c19pbmZvKQoKICAgICAgICAjIDMuIGV2YWx1YXRlIHRoZSBjdXJyZW50IGdsb2JhbCBtb2RlbCB0byBhbGxvdyBzZXJ2ZXItc2lkZSBtb2RlbCBzZWxlY3Rpb24uCiAgICAgICAgcHJpbnQoIi0tLSB2YWxpZGF0ZSBnbG9iYWwgbW9kZWwgLS0tIikKICAgICAgICB0cmFpbmVyLnZhbGlkYXRlKG1vZGVsKQoKICAgICAgICAjIDQuIFBlcmZvcm0gbG9jYWwgdHJhaW5pbmcgc3RhcnRpbmcgd2l0aCB0aGUgcmVjZWl2ZWQgZ2xvYmFsIG1vZGVsLgogICAgICAgIHByaW50KCItLS0gdHJhaW4gbmV3IG1vZGVsIC0tLSIpCiAgICAgICAgdHJhaW5lci5maXQobW9kZWwp" download="">⬇</a></div>
<div id="lstnumberx12" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">1</span><span id="lstnumberx12.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;">    </span><span id="lstnumberx12.2" class="ltx_text ltx_lst_keyword ltx_font_typewriter" style="font-size:70%;color:#FF00FF;">import</span><span id="lstnumberx12.3" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;"> </span><span id="lstnumberx12.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">nvflare</span><span id="lstnumberx12.5" class="ltx_text ltx_font_typewriter" style="font-size:70%;">.</span><span id="lstnumberx12.6" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">client</span><span id="lstnumberx12.7" class="ltx_text ltx_font_typewriter" style="font-size:70%;">.</span><span id="lstnumberx12.8" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">lightning</span><span id="lstnumberx12.9" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;"> </span><span id="lstnumberx12.10" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">as</span><span id="lstnumberx12.11" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;"> </span><span id="lstnumberx12.12" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">flare</span>
</div>
<div id="lstnumberx13" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">2</span>
</div>
<div id="lstnumberx14" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">3</span><span id="lstnumberx14.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;">    </span><span id="lstnumberx14.2" class="ltx_text ltx_font_typewriter" style="font-size:70%;">...</span>
</div>
<div id="lstnumberx15" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">4</span><span id="lstnumberx15.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;">    </span><span id="lstnumberx15.2" class="ltx_text ltx_lst_comment ltx_font_typewriter" style="font-size:70%;color:#009900;">#<span id="lstnumberx15.2.1" class="ltx_text ltx_lst_space"> </span>1.<span id="lstnumberx15.2.2" class="ltx_text ltx_lst_space"> </span>flare<span id="lstnumberx15.2.3" class="ltx_text ltx_lst_space"> </span>patch</span>
</div>
<div id="lstnumberx16" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">5</span><span id="lstnumberx16.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;">    </span><span id="lstnumberx16.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">flare</span><span id="lstnumberx16.3" class="ltx_text ltx_font_typewriter" style="font-size:70%;">.</span><span id="lstnumberx16.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">patch</span><span id="lstnumberx16.5" class="ltx_text ltx_font_typewriter" style="font-size:70%;">(</span><span id="lstnumberx16.6" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">trainer</span><span id="lstnumberx16.7" class="ltx_text ltx_font_typewriter" style="font-size:70%;">)</span>
</div>
<div id="lstnumberx17" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">6</span>
</div>
<div id="lstnumberx18" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">7</span><span id="lstnumberx18.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;">    </span><span id="lstnumberx18.2" class="ltx_text ltx_lst_comment ltx_font_typewriter" style="font-size:70%;color:#009900;">#<span id="lstnumberx18.2.1" class="ltx_text ltx_lst_space"> </span>2.<span id="lstnumberx18.2.2" class="ltx_text ltx_lst_space"> </span>Add<span id="lstnumberx18.2.3" class="ltx_text ltx_lst_space"> </span>while<span id="lstnumberx18.2.4" class="ltx_text ltx_lst_space"> </span>loop<span id="lstnumberx18.2.5" class="ltx_text ltx_lst_space"> </span>to<span id="lstnumberx18.2.6" class="ltx_text ltx_lst_space"> </span>keep<span id="lstnumberx18.2.7" class="ltx_text ltx_lst_space"> </span>receiving<span id="lstnumberx18.2.8" class="ltx_text ltx_lst_space"> </span>the<span id="lstnumberx18.2.9" class="ltx_text ltx_lst_space"> </span>model<span id="lstnumberx18.2.10" class="ltx_text ltx_lst_space"> </span>in<span id="lstnumberx18.2.11" class="ltx_text ltx_lst_space"> </span>each<span id="lstnumberx18.2.12" class="ltx_text ltx_lst_space"> </span>FL<span id="lstnumberx18.2.13" class="ltx_text ltx_lst_space"> </span>round.</span>
</div>
<div id="lstnumberx19" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">8</span><span id="lstnumberx19.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;">    </span><span id="lstnumberx19.2" class="ltx_text ltx_lst_comment ltx_font_typewriter" style="font-size:70%;color:#009900;">#<span id="lstnumberx19.2.1" class="ltx_text ltx_lst_space"> </span>Note,<span id="lstnumberx19.2.2" class="ltx_text ltx_lst_space"> </span>after<span id="lstnumberx19.2.3" class="ltx_text ltx_lst_space"> </span>‘flare.patch‘<span id="lstnumberx19.2.4" class="ltx_text ltx_lst_space"> </span>the<span id="lstnumberx19.2.5" class="ltx_text ltx_lst_space"> </span>trainer.fit/validate<span id="lstnumberx19.2.6" class="ltx_text ltx_lst_space"> </span>will<span id="lstnumberx19.2.7" class="ltx_text ltx_lst_space"> </span>get<span id="lstnumberx19.2.8" class="ltx_text ltx_lst_space"> </span>the</span>
</div>
<div id="lstnumberx20" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">9</span><span id="lstnumberx20.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;">    </span><span id="lstnumberx20.2" class="ltx_text ltx_lst_comment ltx_font_typewriter" style="font-size:70%;color:#009900;">#<span id="lstnumberx20.2.1" class="ltx_text ltx_lst_space"> </span>global<span id="lstnumberx20.2.2" class="ltx_text ltx_lst_space"> </span>model<span id="lstnumberx20.2.3" class="ltx_text ltx_lst_space"> </span>internally<span id="lstnumberx20.2.4" class="ltx_text ltx_lst_space"> </span>at<span id="lstnumberx20.2.5" class="ltx_text ltx_lst_space"> </span>each<span id="lstnumberx20.2.6" class="ltx_text ltx_lst_space"> </span>round.</span>
</div>
<div id="lstnumberx21" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">10</span><span id="lstnumberx21.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;">    </span><span id="lstnumberx21.2" class="ltx_text ltx_lst_keyword ltx_font_typewriter" style="font-size:70%;color:#FF00FF;">while</span><span id="lstnumberx21.3" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;"> </span><span id="lstnumberx21.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">flare</span><span id="lstnumberx21.5" class="ltx_text ltx_font_typewriter" style="font-size:70%;">.</span><span id="lstnumberx21.6" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">is_running</span><span id="lstnumberx21.7" class="ltx_text ltx_font_typewriter" style="font-size:70%;">():</span>
</div>
<div id="lstnumberx22" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">11</span><span id="lstnumberx22.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;">        </span><span id="lstnumberx22.2" class="ltx_text ltx_lst_comment ltx_font_typewriter" style="font-size:70%;color:#009900;">#<span id="lstnumberx22.2.1" class="ltx_text ltx_lst_space"> </span>(optional):<span id="lstnumberx22.2.2" class="ltx_text ltx_lst_space"> </span>get<span id="lstnumberx22.2.3" class="ltx_text ltx_lst_space"> </span>the<span id="lstnumberx22.2.4" class="ltx_text ltx_lst_space"> </span>FL<span id="lstnumberx22.2.5" class="ltx_text ltx_lst_space"> </span>system<span id="lstnumberx22.2.6" class="ltx_text ltx_lst_space"> </span>info</span>
</div>
<div id="lstnumberx23" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">12</span><span id="lstnumberx23.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;">        </span><span id="lstnumberx23.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">fl_sys_info</span><span id="lstnumberx23.3" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;"> </span><span id="lstnumberx23.4" class="ltx_text ltx_font_typewriter" style="font-size:70%;">=</span><span id="lstnumberx23.5" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;"> </span><span id="lstnumberx23.6" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">flare</span><span id="lstnumberx23.7" class="ltx_text ltx_font_typewriter" style="font-size:70%;">.</span><span id="lstnumberx23.8" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">system_info</span><span id="lstnumberx23.9" class="ltx_text ltx_font_typewriter" style="font-size:70%;">()</span>
</div>
<div id="lstnumberx24" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">13</span><span id="lstnumberx24.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;">        </span><span id="lstnumberx24.2" class="ltx_text ltx_lst_keyword ltx_font_typewriter" style="font-size:70%;color:#FF00FF;">print</span><span id="lstnumberx24.3" class="ltx_text ltx_font_typewriter" style="font-size:70%;">(</span><span id="lstnumberx24.4" class="ltx_text ltx_lst_string ltx_font_typewriter" style="font-size:70%;color:#9400D1;">"---<span id="lstnumberx24.4.1" class="ltx_text ltx_lst_space"> </span>fl_sys_info<span id="lstnumberx24.4.2" class="ltx_text ltx_lst_space"> </span>---"</span><span id="lstnumberx24.5" class="ltx_text ltx_font_typewriter" style="font-size:70%;">)</span>
</div>
<div id="lstnumberx25" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">14</span><span id="lstnumberx25.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;">        </span><span id="lstnumberx25.2" class="ltx_text ltx_lst_keyword ltx_font_typewriter" style="font-size:70%;color:#FF00FF;">print</span><span id="lstnumberx25.3" class="ltx_text ltx_font_typewriter" style="font-size:70%;">(</span><span id="lstnumberx25.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">fl_sys_info</span><span id="lstnumberx25.5" class="ltx_text ltx_font_typewriter" style="font-size:70%;">)</span>
</div>
<div id="lstnumberx26" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">15</span>
</div>
<div id="lstnumberx27" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">16</span><span id="lstnumberx27.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;">        </span><span id="lstnumberx27.2" class="ltx_text ltx_lst_comment ltx_font_typewriter" style="font-size:70%;color:#009900;">#<span id="lstnumberx27.2.1" class="ltx_text ltx_lst_space"> </span>3.<span id="lstnumberx27.2.2" class="ltx_text ltx_lst_space"> </span>evaluate<span id="lstnumberx27.2.3" class="ltx_text ltx_lst_space"> </span>the<span id="lstnumberx27.2.4" class="ltx_text ltx_lst_space"> </span>current<span id="lstnumberx27.2.5" class="ltx_text ltx_lst_space"> </span>global<span id="lstnumberx27.2.6" class="ltx_text ltx_lst_space"> </span>model<span id="lstnumberx27.2.7" class="ltx_text ltx_lst_space"> </span>to<span id="lstnumberx27.2.8" class="ltx_text ltx_lst_space"> </span>allow<span id="lstnumberx27.2.9" class="ltx_text ltx_lst_space"> </span>server-side<span id="lstnumberx27.2.10" class="ltx_text ltx_lst_space"> </span>model<span id="lstnumberx27.2.11" class="ltx_text ltx_lst_space"> </span>selection.</span>
</div>
<div id="lstnumberx28" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">17</span><span id="lstnumberx28.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;">        </span><span id="lstnumberx28.2" class="ltx_text ltx_lst_keyword ltx_font_typewriter" style="font-size:70%;color:#FF00FF;">print</span><span id="lstnumberx28.3" class="ltx_text ltx_font_typewriter" style="font-size:70%;">(</span><span id="lstnumberx28.4" class="ltx_text ltx_lst_string ltx_font_typewriter" style="font-size:70%;color:#9400D1;">"---<span id="lstnumberx28.4.1" class="ltx_text ltx_lst_space"> </span>validate<span id="lstnumberx28.4.2" class="ltx_text ltx_lst_space"> </span>global<span id="lstnumberx28.4.3" class="ltx_text ltx_lst_space"> </span>model<span id="lstnumberx28.4.4" class="ltx_text ltx_lst_space"> </span>---"</span><span id="lstnumberx28.5" class="ltx_text ltx_font_typewriter" style="font-size:70%;">)</span>
</div>
<div id="lstnumberx29" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">18</span><span id="lstnumberx29.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;">        </span><span id="lstnumberx29.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">trainer</span><span id="lstnumberx29.3" class="ltx_text ltx_font_typewriter" style="font-size:70%;">.</span><span id="lstnumberx29.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">validate</span><span id="lstnumberx29.5" class="ltx_text ltx_font_typewriter" style="font-size:70%;">(</span><span id="lstnumberx29.6" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">model</span><span id="lstnumberx29.7" class="ltx_text ltx_font_typewriter" style="font-size:70%;">)</span>
</div>
<div id="lstnumberx30" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">19</span>
</div>
<div id="lstnumberx31" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">20</span><span id="lstnumberx31.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;">        </span><span id="lstnumberx31.2" class="ltx_text ltx_lst_comment ltx_font_typewriter" style="font-size:70%;color:#009900;">#<span id="lstnumberx31.2.1" class="ltx_text ltx_lst_space"> </span>4.<span id="lstnumberx31.2.2" class="ltx_text ltx_lst_space"> </span>Perform<span id="lstnumberx31.2.3" class="ltx_text ltx_lst_space"> </span>local<span id="lstnumberx31.2.4" class="ltx_text ltx_lst_space"> </span>training<span id="lstnumberx31.2.5" class="ltx_text ltx_lst_space"> </span>starting<span id="lstnumberx31.2.6" class="ltx_text ltx_lst_space"> </span>with<span id="lstnumberx31.2.7" class="ltx_text ltx_lst_space"> </span>the<span id="lstnumberx31.2.8" class="ltx_text ltx_lst_space"> </span>received<span id="lstnumberx31.2.9" class="ltx_text ltx_lst_space"> </span>global<span id="lstnumberx31.2.10" class="ltx_text ltx_lst_space"> </span>model.</span>
</div>
<div id="lstnumberx32" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">21</span><span id="lstnumberx32.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;">        </span><span id="lstnumberx32.2" class="ltx_text ltx_lst_keyword ltx_font_typewriter" style="font-size:70%;color:#FF00FF;">print</span><span id="lstnumberx32.3" class="ltx_text ltx_font_typewriter" style="font-size:70%;">(</span><span id="lstnumberx32.4" class="ltx_text ltx_lst_string ltx_font_typewriter" style="font-size:70%;color:#9400D1;">"---<span id="lstnumberx32.4.1" class="ltx_text ltx_lst_space"> </span>train<span id="lstnumberx32.4.2" class="ltx_text ltx_lst_space"> </span>new<span id="lstnumberx32.4.3" class="ltx_text ltx_lst_space"> </span>model<span id="lstnumberx32.4.4" class="ltx_text ltx_lst_space"> </span>---"</span><span id="lstnumberx32.5" class="ltx_text ltx_font_typewriter" style="font-size:70%;">)</span>
</div>
<div id="lstnumberx33" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">22</span><span id="lstnumberx33.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;">        </span><span id="lstnumberx33.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">trainer</span><span id="lstnumberx33.3" class="ltx_text ltx_font_typewriter" style="font-size:70%;">.</span><span id="lstnumberx33.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">fit</span><span id="lstnumberx33.5" class="ltx_text ltx_font_typewriter" style="font-size:70%;">(</span><span id="lstnumberx33.6" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">model</span><span id="lstnumberx33.7" class="ltx_text ltx_font_typewriter" style="font-size:70%;">)</span>
</div>
</div>
<figcaption class="ltx_caption" style="background-color:#F2F2EB;"><span class="ltx_tag ltx_tag_float">Listing 2: </span>Pythorch Lightning Client API example.</figcaption>
</figure>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3. </span>Server Workflow Implementation</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">NVFlare’s collaborative computing is achieved through the <span id="S2.SS3.p1.1.1" class="ltx_text ltx_font_italic">Controller</span>/<span id="S2.SS3.p1.1.2" class="ltx_text ltx_font_italic">Executor</span> interactions. The diagram in Fig. <a href="#S2.F1" title="Figure 1 ‣ 2.3. Server Workflow Implementation ‣ 2. Methods ‣ Empowering Federated Learning for Massive Models with NVIDIA FLARE" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> shows how the <span id="S2.SS3.p1.1.3" class="ltx_text ltx_font_italic">Controller</span> and <span id="S2.SS3.p1.1.4" class="ltx_text ltx_font_italic">Executor</span> interact.
The <span id="S2.SS3.p1.1.5" class="ltx_text ltx_font_italic">Controller</span> is a class that controls or coordinates the <span id="S2.SS3.p1.1.6" class="ltx_text ltx_font_italic">Executors</span> to get a job done. It is run on the FL server (highlighted on the right).
A <span id="S2.SS3.p1.1.7" class="ltx_text ltx_font_italic">Executor</span> is capable of performing tasks. <span id="S2.SS3.p1.1.8" class="ltx_text ltx_font_italic">Executors</span> run on FL clients and execute the client API described above. In its control logic (it’s <span id="S2.SS3.p1.1.9" class="ltx_text ltx_font_typewriter">run()</span> routine), the <span id="S2.SS3.p1.1.10" class="ltx_text ltx_font_italic">Controller</span> assigns tasks to <span id="S2.SS3.p1.1.11" class="ltx_text ltx_font_italic">Executors</span> and processes task results from the <span id="S2.SS3.p1.1.12" class="ltx_text ltx_font_italic">Executors</span>. This allows the easy integration of additional data filters (for example, for adding homomorphic encryption <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib43" title="" class="ltx_ref">zhang2020batchcrypt, </a>)</cite> or differential privacy filters <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib19" title="" class="ltx_ref">li2019privacy, </a>)</cite> to the task data or results received or produced by the server or clients).</p>
</div>
<div id="S2.SS3.p2" class="ltx_para">
<p id="S2.SS3.p2.1" class="ltx_p">In Listing <a href="#LST3" title="Listing 3 ‣ 2.3. Server Workflow Implementation ‣ 2. Methods ‣ Empowering Federated Learning for Massive Models with NVIDIA FLARE" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, we show a simplified implementation of the FedAvg <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib22" title="" class="ltx_ref">mcmahan2017communication, </a>)</cite> algorithm with NVFlare<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>Scheduled for upcoming 2.5.0 release of NVFlare.</span></span></span>. The <span id="S2.SS3.p2.1.1" class="ltx_text ltx_font_typewriter">run()</span> routine implements the main algorithmic logic. Subroutines, like <span id="S2.SS3.p2.1.2" class="ltx_text ltx_font_typewriter">sample_clients()</span> and <span id="S2.SS3.p2.1.3" class="ltx_text ltx_font_typewriter">scatter_and_gather_model()</span> utilize the <span id="S2.SS3.p2.1.4" class="ltx_text ltx_font_italic">communicator</span> object, native to each <span id="S2.SS3.p2.1.5" class="ltx_text ltx_font_italic">Controller</span> to get the list of available clients, distribute the current global model to the clients, and collect their results. For simplicity, we do not show the implementation of the aggregation, model update, and saving routines.</p>
</div>
<figure id="S2.F1" class="ltx_figure"><img src="/html/2402.07792/assets/x1.png" id="S2.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="438" height="245" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1. </span>Server workflow <span id="S2.F1.4.1" class="ltx_text ltx_font_italic">Controller</span> and <span id="S2.F1.5.2" class="ltx_text ltx_font_italic">Executor</span> with <span id="S2.F1.6.3" class="ltx_text ltx_font_italic">Client API</span>. </figcaption>
</figure>
<figure id="LST3" class="ltx_float ltx_lstlisting">
<div id="LST3.1" class="ltx_listing ltx_lst_language_Python ltx_lst_numbers_left ltx_lstlisting ltx_listing" style="background-color:#F2F2EB;">
<div class="ltx_listing_data"><a href="data:text/plain;base64,CmNsYXNzIEZlZEF2ZyhDb250cm9sbGVyKToKICAgZGVmIF9faW5pdF9fKHNlbGYsCiAgICAgICAgICAgICAgICBtaW5fY2xpZW50czogaW50LAogICAgICAgICAgICAgICAgbnVtX3JvdW5kczogaW50CiAgICAgICAgICAgICAgICApOgogICAgICAgIHNlbGYubW9kZWwgPSAuLi4gIyBpbml0aWFsaXplIHRoZSBnbG9iYWwgbW9kZWwKICAgICAgICAuLi4KCiAgICBkZWYgcnVuKHNlbGYpIC0+IE5vbmU6CiAgICAgICAgc2VsZi5pbmZvKCJTdGFydCBGZWRBdmcuIikKCiAgICAgICAgZm9yIF9jdXJyZW50X3JvdW5kIGluIHJhbmdlKHNlbGYuX251bV9yb3VuZHMpOgogICAgICAgICAgICBzZWxmLmluZm8oZiJSb3VuZCB7c2VsZi5fY3VycmVudF9yb3VuZH0gc3RhcnRlZC4iKQogICAgICAgICAgICAjIDEuIHNhbXBsZSB0aGUgYXZhaWxhYmxlIGNsaWVudHMKICAgICAgICAgICAgY2xpZW50cyA9IHNlbGYuc2FtcGxlX2NsaWVudHMoc2VsZi5fbWluX2NsaWVudHMpCiAgICAgICAgICAgICMgMi4gc2VuZCB0aGUgY3VycmVudCBnbG9iYWwgbW9kZWwgdG8gY2xpZW50cyBhbmQgcmVjZWl2ZSB0aGUgbW9kZWwgdXBkYXRlcwogICAgICAgICAgICByZXN1bHRzID0gc2VsZi5zY2F0dGVyX2FuZF9nYXRoZXJfbW9kZWwodGFyZ2V0cz1jbGllbnRzKQogICAgICAgICAgICAjIDMuIGFnZ3JlZ2F0ZSB0aGUgcmVzdWx0cwogICAgICAgICAgICBhZ2dyZWdhdGVfcmVzdWx0cyA9IHNlbGYuYWdncmVnYXRlKHJlc3VsdHMpCiAgICAgICAgICAgICMgNC4gdXBkYXRlIHRoZSBjdXJyZW50IGdsb2JhbCBtb2RlbAogICAgICAgICAgICBzZWxmLnVwZGF0ZV9tb2RlbChhZ2dyZWdhdGVfcmVzdWx0cykKICAgICAgICAgICAgIyA1LiBzYXZlIHRoZSBjdXJyZW50IGdsb2JhbCBtb2RlbAogICAgICAgICAgICBzZWxmLnNhdmVfbW9kZWwoKQoKICAgICAgICBzZWxmLmluZm8oIkZpbmlzaGVkIEZlZEF2Zy4iKQoKICAgIGRlZiBzYW1wbGVfY2xpZW50cyhtaW5fY2xpZW50cyk6CiAgICAgICAgIyBhZGQgb3B0aW9uYWwgcmFuZG9tIHNhbXBsaW5nIHN0cmF0ZWd5CiAgICAgICAgcmV0dXJuIHNlbGYuY29tbXVuaWNhdG9yLmdldF9jbGllbnRzKClbMDptaW5fY2xpZW50c10KCiAgICBkZWYgc2NhdHRlcl9hbmRfZ2F0aGVyX21vZGVsKHRhZ2V0cywgZGF0YSk6CiAgICAgICAgcmV0dXJuIHNlbGYuY29tbXVuaWNhdG9yLmJyb2FkY2FzdF9hbmRfd2FpdCgKICAgICAgICAgICAgdGFza19uYW1lPSJ0cmFpbiIsCiAgICAgICAgICAgIG1pbl9yZXNwb25zZXM9c2VsZi5taW5fY2xpZW50cywKICAgICAgICAgICAgZGF0YT1zZWxmLm1vZGVsLAogICAgICAgICAgICB0YXJnZXRzPXRhcmdldHMsCiAgICAgICAgICAgIGNhbGxiYWNrPU5vbmUpCiAgICAuLi4=" download="">⬇</a></div>
<div id="lstnumberx34" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">1</span>
</div>
<div id="lstnumberx35" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">2</span><span id="lstnumberx35.1" class="ltx_text ltx_lst_keyword ltx_font_typewriter" style="font-size:70%;color:#FF00FF;">class</span><span id="lstnumberx35.2" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;"> </span><span id="lstnumberx35.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">FedAvg</span><span id="lstnumberx35.4" class="ltx_text ltx_font_typewriter" style="font-size:70%;">(</span><span id="lstnumberx35.5" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">Controller</span><span id="lstnumberx35.6" class="ltx_text ltx_font_typewriter" style="font-size:70%;">):</span>
</div>
<div id="lstnumberx36" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">3</span><span id="lstnumberx36.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;">   </span><span id="lstnumberx36.2" class="ltx_text ltx_lst_keyword ltx_font_typewriter" style="font-size:70%;color:#FF00FF;">def</span><span id="lstnumberx36.3" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;"> </span><span id="lstnumberx36.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">__init__</span><span id="lstnumberx36.5" class="ltx_text ltx_font_typewriter" style="font-size:70%;">(</span><span id="lstnumberx36.6" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">self</span><span id="lstnumberx36.7" class="ltx_text ltx_font_typewriter" style="font-size:70%;">,</span>
</div>
<div id="lstnumberx37" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">4</span><span id="lstnumberx37.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;">                </span><span id="lstnumberx37.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">min_clients</span><span id="lstnumberx37.3" class="ltx_text ltx_font_typewriter" style="font-size:70%;">:</span><span id="lstnumberx37.4" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;"> </span><span id="lstnumberx37.5" class="ltx_text ltx_lst_keyword ltx_lst_keywords2 ltx_font_typewriter" style="font-size:70%;color:#FF00FF;">int</span><span id="lstnumberx37.6" class="ltx_text ltx_font_typewriter" style="font-size:70%;">,</span>
</div>
<div id="lstnumberx38" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">5</span><span id="lstnumberx38.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;">                </span><span id="lstnumberx38.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">num_rounds</span><span id="lstnumberx38.3" class="ltx_text ltx_font_typewriter" style="font-size:70%;">:</span><span id="lstnumberx38.4" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;"> </span><span id="lstnumberx38.5" class="ltx_text ltx_lst_keyword ltx_lst_keywords2 ltx_font_typewriter" style="font-size:70%;color:#FF00FF;">int</span>
</div>
<div id="lstnumberx39" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">6</span><span id="lstnumberx39.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;">                </span><span id="lstnumberx39.2" class="ltx_text ltx_font_typewriter" style="font-size:70%;">):</span>
</div>
<div id="lstnumberx40" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">7</span><span id="lstnumberx40.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;">        </span><span id="lstnumberx40.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">self</span><span id="lstnumberx40.3" class="ltx_text ltx_font_typewriter" style="font-size:70%;">.</span><span id="lstnumberx40.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">model</span><span id="lstnumberx40.5" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;"> </span><span id="lstnumberx40.6" class="ltx_text ltx_font_typewriter" style="font-size:70%;">=</span><span id="lstnumberx40.7" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;"> </span><span id="lstnumberx40.8" class="ltx_text ltx_font_typewriter" style="font-size:70%;">...</span><span id="lstnumberx40.9" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;"> </span><span id="lstnumberx40.10" class="ltx_text ltx_lst_comment ltx_font_typewriter" style="font-size:70%;color:#009900;">#<span id="lstnumberx40.10.1" class="ltx_text ltx_lst_space"> </span>initialize<span id="lstnumberx40.10.2" class="ltx_text ltx_lst_space"> </span>the<span id="lstnumberx40.10.3" class="ltx_text ltx_lst_space"> </span>global<span id="lstnumberx40.10.4" class="ltx_text ltx_lst_space"> </span>model</span>
</div>
<div id="lstnumberx41" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">8</span><span id="lstnumberx41.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;">        </span><span id="lstnumberx41.2" class="ltx_text ltx_font_typewriter" style="font-size:70%;">...</span>
</div>
<div id="lstnumberx42" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">9</span>
</div>
<div id="lstnumberx43" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">10</span><span id="lstnumberx43.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;">    </span><span id="lstnumberx43.2" class="ltx_text ltx_lst_keyword ltx_font_typewriter" style="font-size:70%;color:#FF00FF;">def</span><span id="lstnumberx43.3" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;"> </span><span id="lstnumberx43.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">run</span><span id="lstnumberx43.5" class="ltx_text ltx_font_typewriter" style="font-size:70%;">(</span><span id="lstnumberx43.6" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">self</span><span id="lstnumberx43.7" class="ltx_text ltx_font_typewriter" style="font-size:70%;">)</span><span id="lstnumberx43.8" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;"> </span><span id="lstnumberx43.9" class="ltx_text ltx_font_typewriter" style="font-size:70%;">-&gt;</span><span id="lstnumberx43.10" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;"> </span><span id="lstnumberx43.11" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">None</span><span id="lstnumberx43.12" class="ltx_text ltx_font_typewriter" style="font-size:70%;">:</span>
</div>
<div id="lstnumberx44" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">11</span><span id="lstnumberx44.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;">        </span><span id="lstnumberx44.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">self</span><span id="lstnumberx44.3" class="ltx_text ltx_font_typewriter" style="font-size:70%;">.</span><span id="lstnumberx44.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">info</span><span id="lstnumberx44.5" class="ltx_text ltx_font_typewriter" style="font-size:70%;">(</span><span id="lstnumberx44.6" class="ltx_text ltx_lst_string ltx_font_typewriter" style="font-size:70%;color:#9400D1;">"Start<span id="lstnumberx44.6.1" class="ltx_text ltx_lst_space"> </span>FedAvg."</span><span id="lstnumberx44.7" class="ltx_text ltx_font_typewriter" style="font-size:70%;">)</span>
</div>
<div id="lstnumberx45" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">12</span>
</div>
<div id="lstnumberx46" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">13</span><span id="lstnumberx46.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;">        </span><span id="lstnumberx46.2" class="ltx_text ltx_lst_keyword ltx_font_typewriter" style="font-size:70%;color:#FF00FF;">for</span><span id="lstnumberx46.3" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;"> </span><span id="lstnumberx46.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">_current_round</span><span id="lstnumberx46.5" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;"> </span><span id="lstnumberx46.6" class="ltx_text ltx_lst_keyword ltx_font_typewriter" style="font-size:70%;color:#FF00FF;">in</span><span id="lstnumberx46.7" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;"> </span><span id="lstnumberx46.8" class="ltx_text ltx_lst_keyword ltx_lst_keywords2 ltx_font_typewriter" style="font-size:70%;color:#FF00FF;">range</span><span id="lstnumberx46.9" class="ltx_text ltx_font_typewriter" style="font-size:70%;">(</span><span id="lstnumberx46.10" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">self</span><span id="lstnumberx46.11" class="ltx_text ltx_font_typewriter" style="font-size:70%;">.</span><span id="lstnumberx46.12" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">_num_rounds</span><span id="lstnumberx46.13" class="ltx_text ltx_font_typewriter" style="font-size:70%;">):</span>
</div>
<div id="lstnumberx47" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">14</span><span id="lstnumberx47.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;">            </span><span id="lstnumberx47.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">self</span><span id="lstnumberx47.3" class="ltx_text ltx_font_typewriter" style="font-size:70%;">.</span><span id="lstnumberx47.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">info</span><span id="lstnumberx47.5" class="ltx_text ltx_font_typewriter" style="font-size:70%;">(</span><span id="lstnumberx47.6" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">f</span><span id="lstnumberx47.7" class="ltx_text ltx_lst_string ltx_font_typewriter" style="font-size:70%;color:#9400D1;">"Round<span id="lstnumberx47.7.1" class="ltx_text ltx_lst_space"> </span>{self._current_round}<span id="lstnumberx47.7.2" class="ltx_text ltx_lst_space"> </span>started."</span><span id="lstnumberx47.8" class="ltx_text ltx_font_typewriter" style="font-size:70%;">)</span>
</div>
<div id="lstnumberx48" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">15</span><span id="lstnumberx48.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;">            </span><span id="lstnumberx48.2" class="ltx_text ltx_lst_comment ltx_font_typewriter" style="font-size:70%;color:#009900;">#<span id="lstnumberx48.2.1" class="ltx_text ltx_lst_space"> </span>1.<span id="lstnumberx48.2.2" class="ltx_text ltx_lst_space"> </span>sample<span id="lstnumberx48.2.3" class="ltx_text ltx_lst_space"> </span>the<span id="lstnumberx48.2.4" class="ltx_text ltx_lst_space"> </span>available<span id="lstnumberx48.2.5" class="ltx_text ltx_lst_space"> </span>clients</span>
</div>
<div id="lstnumberx49" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">16</span><span id="lstnumberx49.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;">            </span><span id="lstnumberx49.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">clients</span><span id="lstnumberx49.3" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;"> </span><span id="lstnumberx49.4" class="ltx_text ltx_font_typewriter" style="font-size:70%;">=</span><span id="lstnumberx49.5" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;"> </span><span id="lstnumberx49.6" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">self</span><span id="lstnumberx49.7" class="ltx_text ltx_font_typewriter" style="font-size:70%;">.</span><span id="lstnumberx49.8" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">sample_clients</span><span id="lstnumberx49.9" class="ltx_text ltx_font_typewriter" style="font-size:70%;">(</span><span id="lstnumberx49.10" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">self</span><span id="lstnumberx49.11" class="ltx_text ltx_font_typewriter" style="font-size:70%;">.</span><span id="lstnumberx49.12" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">_min_clients</span><span id="lstnumberx49.13" class="ltx_text ltx_font_typewriter" style="font-size:70%;">)</span>
</div>
<div id="lstnumberx50" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">17</span><span id="lstnumberx50.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;">            </span><span id="lstnumberx50.2" class="ltx_text ltx_lst_comment ltx_font_typewriter" style="font-size:70%;color:#009900;">#<span id="lstnumberx50.2.1" class="ltx_text ltx_lst_space"> </span>2.<span id="lstnumberx50.2.2" class="ltx_text ltx_lst_space"> </span>send<span id="lstnumberx50.2.3" class="ltx_text ltx_lst_space"> </span>the<span id="lstnumberx50.2.4" class="ltx_text ltx_lst_space"> </span>current<span id="lstnumberx50.2.5" class="ltx_text ltx_lst_space"> </span>global<span id="lstnumberx50.2.6" class="ltx_text ltx_lst_space"> </span>model<span id="lstnumberx50.2.7" class="ltx_text ltx_lst_space"> </span>to<span id="lstnumberx50.2.8" class="ltx_text ltx_lst_space"> </span>clients<span id="lstnumberx50.2.9" class="ltx_text ltx_lst_space"> </span>and<span id="lstnumberx50.2.10" class="ltx_text ltx_lst_space"> </span>receive<span id="lstnumberx50.2.11" class="ltx_text ltx_lst_space"> </span>the<span id="lstnumberx50.2.12" class="ltx_text ltx_lst_space"> </span>model<span id="lstnumberx50.2.13" class="ltx_text ltx_lst_space"> </span>updates</span>
</div>
<div id="lstnumberx51" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">18</span><span id="lstnumberx51.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;">            </span><span id="lstnumberx51.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">results</span><span id="lstnumberx51.3" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;"> </span><span id="lstnumberx51.4" class="ltx_text ltx_font_typewriter" style="font-size:70%;">=</span><span id="lstnumberx51.5" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;"> </span><span id="lstnumberx51.6" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">self</span><span id="lstnumberx51.7" class="ltx_text ltx_font_typewriter" style="font-size:70%;">.</span><span id="lstnumberx51.8" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">scatter_and_gather_model</span><span id="lstnumberx51.9" class="ltx_text ltx_font_typewriter" style="font-size:70%;">(</span><span id="lstnumberx51.10" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">targets</span><span id="lstnumberx51.11" class="ltx_text ltx_font_typewriter" style="font-size:70%;">=</span><span id="lstnumberx51.12" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">clients</span><span id="lstnumberx51.13" class="ltx_text ltx_font_typewriter" style="font-size:70%;">)</span>
</div>
<div id="lstnumberx52" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">19</span><span id="lstnumberx52.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;">            </span><span id="lstnumberx52.2" class="ltx_text ltx_lst_comment ltx_font_typewriter" style="font-size:70%;color:#009900;">#<span id="lstnumberx52.2.1" class="ltx_text ltx_lst_space"> </span>3.<span id="lstnumberx52.2.2" class="ltx_text ltx_lst_space"> </span>aggregate<span id="lstnumberx52.2.3" class="ltx_text ltx_lst_space"> </span>the<span id="lstnumberx52.2.4" class="ltx_text ltx_lst_space"> </span>results</span>
</div>
<div id="lstnumberx53" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">20</span><span id="lstnumberx53.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;">            </span><span id="lstnumberx53.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">aggregate_results</span><span id="lstnumberx53.3" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;"> </span><span id="lstnumberx53.4" class="ltx_text ltx_font_typewriter" style="font-size:70%;">=</span><span id="lstnumberx53.5" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;"> </span><span id="lstnumberx53.6" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">self</span><span id="lstnumberx53.7" class="ltx_text ltx_font_typewriter" style="font-size:70%;">.</span><span id="lstnumberx53.8" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">aggregate</span><span id="lstnumberx53.9" class="ltx_text ltx_font_typewriter" style="font-size:70%;">(</span><span id="lstnumberx53.10" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">results</span><span id="lstnumberx53.11" class="ltx_text ltx_font_typewriter" style="font-size:70%;">)</span>
</div>
<div id="lstnumberx54" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">21</span><span id="lstnumberx54.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;">            </span><span id="lstnumberx54.2" class="ltx_text ltx_lst_comment ltx_font_typewriter" style="font-size:70%;color:#009900;">#<span id="lstnumberx54.2.1" class="ltx_text ltx_lst_space"> </span>4.<span id="lstnumberx54.2.2" class="ltx_text ltx_lst_space"> </span>update<span id="lstnumberx54.2.3" class="ltx_text ltx_lst_space"> </span>the<span id="lstnumberx54.2.4" class="ltx_text ltx_lst_space"> </span>current<span id="lstnumberx54.2.5" class="ltx_text ltx_lst_space"> </span>global<span id="lstnumberx54.2.6" class="ltx_text ltx_lst_space"> </span>model</span>
</div>
<div id="lstnumberx55" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">22</span><span id="lstnumberx55.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;">            </span><span id="lstnumberx55.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">self</span><span id="lstnumberx55.3" class="ltx_text ltx_font_typewriter" style="font-size:70%;">.</span><span id="lstnumberx55.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">update_model</span><span id="lstnumberx55.5" class="ltx_text ltx_font_typewriter" style="font-size:70%;">(</span><span id="lstnumberx55.6" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">aggregate_results</span><span id="lstnumberx55.7" class="ltx_text ltx_font_typewriter" style="font-size:70%;">)</span>
</div>
<div id="lstnumberx56" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">23</span><span id="lstnumberx56.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;">            </span><span id="lstnumberx56.2" class="ltx_text ltx_lst_comment ltx_font_typewriter" style="font-size:70%;color:#009900;">#<span id="lstnumberx56.2.1" class="ltx_text ltx_lst_space"> </span>5.<span id="lstnumberx56.2.2" class="ltx_text ltx_lst_space"> </span>save<span id="lstnumberx56.2.3" class="ltx_text ltx_lst_space"> </span>the<span id="lstnumberx56.2.4" class="ltx_text ltx_lst_space"> </span>current<span id="lstnumberx56.2.5" class="ltx_text ltx_lst_space"> </span>global<span id="lstnumberx56.2.6" class="ltx_text ltx_lst_space"> </span>model</span>
</div>
<div id="lstnumberx57" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">24</span><span id="lstnumberx57.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;">            </span><span id="lstnumberx57.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">self</span><span id="lstnumberx57.3" class="ltx_text ltx_font_typewriter" style="font-size:70%;">.</span><span id="lstnumberx57.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">save_model</span><span id="lstnumberx57.5" class="ltx_text ltx_font_typewriter" style="font-size:70%;">()</span>
</div>
<div id="lstnumberx58" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">25</span>
</div>
<div id="lstnumberx59" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">26</span><span id="lstnumberx59.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;">        </span><span id="lstnumberx59.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">self</span><span id="lstnumberx59.3" class="ltx_text ltx_font_typewriter" style="font-size:70%;">.</span><span id="lstnumberx59.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">info</span><span id="lstnumberx59.5" class="ltx_text ltx_font_typewriter" style="font-size:70%;">(</span><span id="lstnumberx59.6" class="ltx_text ltx_lst_string ltx_font_typewriter" style="font-size:70%;color:#9400D1;">"Finished<span id="lstnumberx59.6.1" class="ltx_text ltx_lst_space"> </span>FedAvg."</span><span id="lstnumberx59.7" class="ltx_text ltx_font_typewriter" style="font-size:70%;">)</span>
</div>
<div id="lstnumberx60" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">27</span>
</div>
<div id="lstnumberx61" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">28</span><span id="lstnumberx61.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;">    </span><span id="lstnumberx61.2" class="ltx_text ltx_lst_keyword ltx_font_typewriter" style="font-size:70%;color:#FF00FF;">def</span><span id="lstnumberx61.3" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;"> </span><span id="lstnumberx61.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">sample_clients</span><span id="lstnumberx61.5" class="ltx_text ltx_font_typewriter" style="font-size:70%;">(</span><span id="lstnumberx61.6" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">min_clients</span><span id="lstnumberx61.7" class="ltx_text ltx_font_typewriter" style="font-size:70%;">):</span>
</div>
<div id="lstnumberx62" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">29</span><span id="lstnumberx62.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;">        </span><span id="lstnumberx62.2" class="ltx_text ltx_lst_comment ltx_font_typewriter" style="font-size:70%;color:#009900;">#<span id="lstnumberx62.2.1" class="ltx_text ltx_lst_space"> </span>add<span id="lstnumberx62.2.2" class="ltx_text ltx_lst_space"> </span>optional<span id="lstnumberx62.2.3" class="ltx_text ltx_lst_space"> </span>random<span id="lstnumberx62.2.4" class="ltx_text ltx_lst_space"> </span>sampling<span id="lstnumberx62.2.5" class="ltx_text ltx_lst_space"> </span>strategy</span>
</div>
<div id="lstnumberx63" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">30</span><span id="lstnumberx63.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;">        </span><span id="lstnumberx63.2" class="ltx_text ltx_lst_keyword ltx_font_typewriter" style="font-size:70%;color:#FF00FF;">return</span><span id="lstnumberx63.3" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;"> </span><span id="lstnumberx63.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">self</span><span id="lstnumberx63.5" class="ltx_text ltx_font_typewriter" style="font-size:70%;">.</span><span id="lstnumberx63.6" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">communicator</span><span id="lstnumberx63.7" class="ltx_text ltx_font_typewriter" style="font-size:70%;">.</span><span id="lstnumberx63.8" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">get_clients</span><span id="lstnumberx63.9" class="ltx_text ltx_font_typewriter" style="font-size:70%;">()[0:</span><span id="lstnumberx63.10" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">min_clients</span><span id="lstnumberx63.11" class="ltx_text ltx_font_typewriter" style="font-size:70%;">]</span>
</div>
<div id="lstnumberx64" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">31</span>
</div>
<div id="lstnumberx65" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">32</span><span id="lstnumberx65.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;">    </span><span id="lstnumberx65.2" class="ltx_text ltx_lst_keyword ltx_font_typewriter" style="font-size:70%;color:#FF00FF;">def</span><span id="lstnumberx65.3" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;"> </span><span id="lstnumberx65.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">scatter_and_gather_model</span><span id="lstnumberx65.5" class="ltx_text ltx_font_typewriter" style="font-size:70%;">(</span><span id="lstnumberx65.6" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">tagets</span><span id="lstnumberx65.7" class="ltx_text ltx_font_typewriter" style="font-size:70%;">,</span><span id="lstnumberx65.8" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;"> </span><span id="lstnumberx65.9" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">data</span><span id="lstnumberx65.10" class="ltx_text ltx_font_typewriter" style="font-size:70%;">):</span>
</div>
<div id="lstnumberx66" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">33</span><span id="lstnumberx66.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;">        </span><span id="lstnumberx66.2" class="ltx_text ltx_lst_keyword ltx_font_typewriter" style="font-size:70%;color:#FF00FF;">return</span><span id="lstnumberx66.3" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;"> </span><span id="lstnumberx66.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">self</span><span id="lstnumberx66.5" class="ltx_text ltx_font_typewriter" style="font-size:70%;">.</span><span id="lstnumberx66.6" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">communicator</span><span id="lstnumberx66.7" class="ltx_text ltx_font_typewriter" style="font-size:70%;">.</span><span id="lstnumberx66.8" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">broadcast_and_wait</span><span id="lstnumberx66.9" class="ltx_text ltx_font_typewriter" style="font-size:70%;">(</span>
</div>
<div id="lstnumberx67" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">34</span><span id="lstnumberx67.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;">            </span><span id="lstnumberx67.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">task_name</span><span id="lstnumberx67.3" class="ltx_text ltx_font_typewriter" style="font-size:70%;">=</span><span id="lstnumberx67.4" class="ltx_text ltx_lst_string ltx_font_typewriter" style="font-size:70%;color:#9400D1;">"train"</span><span id="lstnumberx67.5" class="ltx_text ltx_font_typewriter" style="font-size:70%;">,</span>
</div>
<div id="lstnumberx68" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">35</span><span id="lstnumberx68.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;">            </span><span id="lstnumberx68.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">min_responses</span><span id="lstnumberx68.3" class="ltx_text ltx_font_typewriter" style="font-size:70%;">=</span><span id="lstnumberx68.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">self</span><span id="lstnumberx68.5" class="ltx_text ltx_font_typewriter" style="font-size:70%;">.</span><span id="lstnumberx68.6" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">min_clients</span><span id="lstnumberx68.7" class="ltx_text ltx_font_typewriter" style="font-size:70%;">,</span>
</div>
<div id="lstnumberx69" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">36</span><span id="lstnumberx69.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;">            </span><span id="lstnumberx69.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">data</span><span id="lstnumberx69.3" class="ltx_text ltx_font_typewriter" style="font-size:70%;">=</span><span id="lstnumberx69.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">self</span><span id="lstnumberx69.5" class="ltx_text ltx_font_typewriter" style="font-size:70%;">.</span><span id="lstnumberx69.6" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">model</span><span id="lstnumberx69.7" class="ltx_text ltx_font_typewriter" style="font-size:70%;">,</span>
</div>
<div id="lstnumberx70" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">37</span><span id="lstnumberx70.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;">            </span><span id="lstnumberx70.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">targets</span><span id="lstnumberx70.3" class="ltx_text ltx_font_typewriter" style="font-size:70%;">=</span><span id="lstnumberx70.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">targets</span><span id="lstnumberx70.5" class="ltx_text ltx_font_typewriter" style="font-size:70%;">,</span>
</div>
<div id="lstnumberx71" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">38</span><span id="lstnumberx71.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;">            </span><span id="lstnumberx71.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">callback</span><span id="lstnumberx71.3" class="ltx_text ltx_font_typewriter" style="font-size:70%;">=</span><span id="lstnumberx71.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:70%;">None</span><span id="lstnumberx71.5" class="ltx_text ltx_font_typewriter" style="font-size:70%;">)</span>
</div>
<div id="lstnumberx72" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">39</span><span id="lstnumberx72.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:70%;">    </span><span id="lstnumberx72.2" class="ltx_text ltx_font_typewriter" style="font-size:70%;">...</span>
</div>
</div>
<figcaption class="ltx_caption" style="background-color:#F2F2EB;"><span class="ltx_tag ltx_tag_float">Listing 3: </span>Federated averaging workflow controller example.</figcaption>
</figure>
<div id="S2.SS3.p3" class="ltx_para">
<p id="S2.SS3.p3.1" class="ltx_p">Due to the separation of the controller logic and the communication object (<span id="S2.SS3.p3.1.1" class="ltx_text ltx_font_typewriter">self.communicator)</span>, it is possible to run an NVFlare <span id="S2.SS3.p3.1.2" class="ltx_text ltx_font_italic">Controller</span> both on the server and the clients, allowing a straightforward implementation of alternative communication strategies such as split learning <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib11" title="" class="ltx_ref">gupta2018distributed, </a>)</cite> or swarm learning <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib40" title="" class="ltx_ref">warnat2021swarm, </a>)</cite>.</p>
</div>
</section>
<section id="S2.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.4. </span>Scalable Model Training via Streaming</h3>

<figure id="S2.F2" class="ltx_figure"><img src="/html/2402.07792/assets/x2.png" id="S2.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="438" height="139" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2. </span>Data streaming API. </figcaption>
</figure>
<div id="S2.SS4.p1" class="ltx_para">
<p id="S2.SS4.p1.1" class="ltx_p">As FL or AI tasks in general become more and more complex, their model sizes increase <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib33" title="" class="ltx_ref">smith2022using, </a>)</cite>. The size of mainstream LLMs can be enormous, ranging from a few billion parameters to tens of billions of parameters, which leads to a significant increase in model sizes that need to be communicated during FL training. However, using native communication protocols directly can introduce inefficiencies and instability issues. Furthermore, protocols such as gRPC have hard size limits (2 GB) for single messages. Typical model sizes of modern LLMs exceed those limits and can even reach hundreds of GB. NVFlare supports large models as long as the system memory of servers and clients can handle it. However, it requires special considerations because the network bandwidth and, thus, the time to transmit such a large amount of data during an NVFlare job runtime varies significantly.</p>
</div>
<div id="S2.SS4.p2" class="ltx_para">
<p id="S2.SS4.p2.1" class="ltx_p">In the NVFlare 2.4.0 release, communication capabilities have been significantly enhanced through our new <span id="S2.SS4.p2.1.1" class="ltx_text ltx_font_italic">data streaming API</span>. Our streaming API has four different variations: byte streaming, blob streaming, file streaming, and object streaming, which can work together with different communication protocols (drivers gRPC, HTTP, TCP, etc.). The “Streamable Framed Message” (SFM) layer manages the drivers and connections and sends messages. One can change the driver without affecting the upper-layer applications. In other words, one can switch between gRPC, TCP, HTTP, etc., and the applications built on top will work without any changes. One can even build customer drivers that suit their needs.</p>
</div>
<div id="S2.SS4.p3" class="ltx_para">
<p id="S2.SS4.p3.1" class="ltx_p">As illustrated in Fig. <a href="#S2.F2" title="Figure 2 ‣ 2.4. Scalable Model Training via Streaming ‣ 2. Methods ‣ Empowering Federated Learning for Massive Models with NVIDIA FLARE" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, the large model is now divided into 1 megabyte (MB) chunks and streamed to the target (server or client), bringing a complete transformation to the overall system with the introduction of a new streaming layer designed to handle large data transfers. Once the message arrives at the target end-point, the object is re-assembled to restore the original message payload. Refer to Section <a href="#S4.SS1" title="4.1. Large message streaming ‣ 4. Results ‣ Empowering Federated Learning for Massive Models with NVIDIA FLARE" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a> for quantitative results on large data streaming.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>Applications</h2>

<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1. </span>Adaption of Foundational LLMs</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">Foundational LLMs are pre-trained on a vast amount of general text data <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib2" title="" class="ltx_ref">brown2020language, </a>)</cite>. However, they may not be specialized for specific domains or downstream tasks. Further fine-tuning allows these models to adapt and specialize for particular domains and tasks, making them more effective and accurate in delivering domain- and task-specific results, which is essential to harness their potential and adapt them to various applications’ diverse and evolving needs.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">PEFT and SFT are two vital approaches that aim to tailor foundational LLMs to specific domains and tasks efficiently and effectively. Both targets achieve domain and task-specific adaptation based on foundational LLMs. SFT fine-tunes all LLM parameters, while PEFT tries to add adaptation parameters/layers while keeping the LLM parameters fixed, making it a cost-effective and resource-efficient option. These techniques play a pivotal role in harnessing the power of LLMs for a multitude of applications, offering tailored and resource-aware solutions for a wide range of applications.</p>
</div>
<figure id="S3.F3" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F3.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2402.07792/assets/x3.png" id="S3.F3.sf1.g1" class="ltx_graphics ltx_img_landscape" width="222" height="161" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>PEFT</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F3.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2402.07792/assets/x4.png" id="S3.F3.sf2.g1" class="ltx_graphics ltx_img_landscape" width="222" height="161" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>SFT</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3. </span>Federated parameter-efficient fine-tuning (PEFT) and full supervised fine-tuning (SFT) with global model and <math id="S3.F3.2.m1.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S3.F3.2.m1.1b"><mi id="S3.F3.2.m1.1.1" xref="S3.F3.2.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.F3.2.m1.1c"><ci id="S3.F3.2.m1.1.1.cmml" xref="S3.F3.2.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.2.m1.1d">n</annotation></semantics></math> clients. </figcaption>
</figure>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2. </span>FL for LLM Adaptations</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">As with other AI techniques, the performance of LLMs benefits from larger and more diverse datasets. More data usually translates to better accuracy, improved robustness, and generalizability.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">As shown in Fig. <a href="#S3.F3" title="Figure 3 ‣ 3.1. Adaption of Foundational LLMs ‣ 3. Applications ‣ Empowering Federated Learning for Massive Models with NVIDIA FLARE" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, using PEFT, the parameters of the foundational LLMs are frozen and remain fixed during training and evaluation, while additional parameters are injected for customization. Hence, only these injected parameters are tuned at local clients and aggregated globally. Using SFT, on the other hand, all the parameters of the LLMs are fine-tuned and communicated for aggregation.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.1" class="ltx_p">As SFT fine-tunes the entire network, the whole model must be transferred and aggregated. This transmission challenge must be properly addressed to enable SFT with recent LLMs in FL using NVFlare’s data streaming API (see Section <a href="#S2.SS4" title="2.4. Scalable Model Training via Streaming ‣ 2. Methods ‣ Empowering Federated Learning for Massive Models with NVIDIA FLARE" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.4</span></a>).</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3. </span>Federated Protein Embeddings and Task Model Fitting</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">Next, we explore obtaining protein-learned representations in the form of embeddings using an ESM-style pre-trained model <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib23" title="" class="ltx_ref">meier2021language, </a>)</cite>. The model is trained with NVIDIA’s BioNeMo framework<span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><a target="_blank" href="https://www.nvidia.com/en-us/clara/bionemo" title="" class="ltx_ref ltx_url" style="color:#0000FF;">https://www.nvidia.com/en-us/clara/bionemo</a></span></span></span> for LLM training and inference.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.1" class="ltx_p">Using BioNeMo, users can obtain numerical vector representations of protein sequences called embeddings. Protein embeddings can then be used for visualization or making downstream predictions.</p>
</div>
<div id="S3.SS3.p3" class="ltx_para">
<p id="S3.SS3.p3.1" class="ltx_p">Here, we are interested in training a neural network to predict subcellular location from an embedding.</p>
</div>
<section id="S3.SS3.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Subcellular Location Prediction</h4>

<div id="S3.SS3.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS3.SSS0.Px1.p1.1" class="ltx_p">The data we will be using comes from the work by Stärk et al. <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib34" title="" class="ltx_ref">stark2021light, </a>)</cite>. In this paper, the authors developed a machine learning algorithm to predict the subcellular location of proteins from sequence through protein language models that are similar to those hosted by BioNeMo. Protein subcellular location refers to where the protein localizes in the cell; for example, a protein may be expressed in the ‘Nucleus’ or the ‘Cytoplasm.’ Knowing where proteins localize can provide insights into the underlying mechanisms of cellular processes and help identify potential targets for drug development. Figure <a href="#S3.F4" title="Figure 4 ‣ Model Architecure ‣ 3.3. Federated Protein Embeddings and Task Model Fitting ‣ 3. Applications ‣ Empowering Federated Learning for Massive Models with NVIDIA FLARE" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> includes a few examples of subcellular locations in an animal cell.</p>
</div>
<div id="S3.SS3.SSS0.Px1.p2" class="ltx_para">
<p id="S3.SS3.SSS0.Px1.p2.1" class="ltx_p">We will utilize FASTA<span id="footnote5" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span><a target="_blank" href="https://en.wikipedia.org/wiki/FASTA_format" title="" class="ltx_ref ltx_url" style="color:#0000FF;">https://en.wikipedia.org/wiki/FASTA˙format</a></span></span></span> sequences for our target input sequences in a benchmark dataset called “Fitness Landscape Inference for Proteins” (FLIP) <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib5" title="" class="ltx_ref">dallago2021flip, </a>)</cite>. FLIP encompasses experimental data across adeno-associated virus stability for gene therapy, protein domain B1 stability and immunoglobulin binding, and thermostability from multiple protein families.</p>
</div>
</section>
<section id="S3.SS3.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Model Architecure</h4>

<div id="S3.SS3.SSS0.Px2.p1" class="ltx_para">
<p id="S3.SS3.SSS0.Px2.p1.1" class="ltx_p">We utilize the <span id="S3.SS3.SSS0.Px2.p1.1.1" class="ltx_text ltx_font_italic">ESM-1nv</span> model developed using the BioNeMo framework. The model uses an architecture called “Bidirectional Encoder Representations from Transformers” (BERT) and is based on the ESM-1 model <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib27" title="" class="ltx_ref">rives2021biological, </a>; <a href="#bib.bib7" title="" class="ltx_ref">devlin2018bert, </a>)</cite>. Pre-norm layer normalization and GELU <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib14" title="" class="ltx_ref">hendrycks2016gaussian, </a>)</cite> activation are used throughout. The model has six layers, 12 attention heads, a hidden space dimension of 768, and contains 44M parameters. The input sequence length is limited to 512 amino acids.</p>
</div>
<div id="S3.SS3.SSS0.Px2.p2" class="ltx_para">
<p id="S3.SS3.SSS0.Px2.p2.1" class="ltx_p">In Section <a href="#S4.SS4" title="4.4. Subcellular Structure Prediction ‣ 4. Results ‣ Empowering Federated Learning for Massive Models with NVIDIA FLARE" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.4</span></a>, we show results for running federated inference to extract protein embeddings from the clients’ local data, followed by the application of FedAvg to training an MLP for the downstream subcellular location prediction task.</p>
</div>
<figure id="S3.F4" class="ltx_figure"><img src="/html/2402.07792/assets/fig/cell-48542_1280.png" id="S3.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="568" height="264" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4. </span>Cross section of an animal cell <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib25" title="" class="ltx_ref">cellimage, </a>)</cite>. </figcaption>
</figure>
</section>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>Results</h2>

<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1. </span>Large message streaming</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">We have extensively tested the streaming feature across regions and cloud providers, including AWS and Azure, to test the transfer of large model sizes. This example used a randomly initialized model consisting of a dictionary of 64 keys. Each key held a 2GB floating-point number array (resulting in a total model size of 128GB). This message size is much larger than commonly used modern LLMs, such as the <span id="S4.SS1.p1.1.1" class="ltx_text ltx_font_italic">LLama-2</span> 7B parameter model<span id="footnote6" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span><a target="_blank" href="https://huggingface.co/meta-llama/Llama-2-7b" title="" class="ltx_ref ltx_url" style="color:#0000FF;">https://huggingface.co/meta-llama/Llama-2-7b</a></span></span></span> <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib37" title="" class="ltx_ref">touvron2023llama, </a>)</cite>, which requires checkpoint sizes of 13.5GB to store all its parameters. Even large models such as <span id="S4.SS1.p1.1.2" class="ltx_text ltx_font_italic">CodeLlama</span> 70B parameter model<span id="footnote7" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span><a target="_blank" href="https://huggingface.co/codellama/CodeLlama-70b-hf" title="" class="ltx_ref ltx_url" style="color:#0000FF;">https://huggingface.co/codellama/CodeLlama-70b-hf</a></span></span></span> <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib30" title="" class="ltx_ref">roziere2023code, </a>)</cite>, which takes <math id="S4.SS1.p1.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S4.SS1.p1.1.m1.1a"><mo id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><csymbol cd="latexml" id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">\sim</annotation></semantics></math>140GB to store their checkpoints, are similar to our experiment.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p">In the following, we are using two clients: <span id="S4.SS1.p2.1.1" class="ltx_text ltx_font_italic">Site-1</span> with a fast connection and <span id="S4.SS1.p2.1.2" class="ltx_text ltx_font_italic">Site-2</span> with a slower one<span id="footnote8" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span>The server was deployed on Azure with  900GB RAM. Each client had <math id="footnote8.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="footnote8.m1.1b"><mo id="footnote8.m1.1.1" xref="footnote8.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="footnote8.m1.1c"><csymbol cd="latexml" id="footnote8.m1.1.1.cmml" xref="footnote8.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="footnote8.m1.1d">\sim</annotation></semantics></math>380GB RAM.</span></span></span>. Figure <a href="#S4.F5" title="Figure 5 ‣ 4.1. Large message streaming ‣ 4. Results ‣ Empowering Federated Learning for Massive Models with NVIDIA FLARE" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> illustrates the server’s and clients’ memory usage during the FL training run over three rounds.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p id="S4.SS1.p3.2" class="ltx_p">The local training task was to add a small number to those arrays. The aggregator on the server side was not changed. This job required at least two clients and ran three rounds to finish. During the experiment, the server used over 512GB, i.e., 128GB <math id="S4.SS1.p3.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.SS1.p3.1.m1.1a"><mo id="S4.SS1.p3.1.m1.1.1" xref="S4.SS1.p3.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.1.m1.1b"><times id="S4.SS1.p3.1.m1.1.1.cmml" xref="S4.SS1.p3.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.1.m1.1c">\times</annotation></semantics></math> 2 (clients) <math id="S4.SS1.p3.2.m2.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.SS1.p3.2.m2.1a"><mo id="S4.SS1.p3.2.m2.1.1" xref="S4.SS1.p3.2.m2.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.2.m2.1b"><times id="S4.SS1.p3.2.m2.1.1.cmml" xref="S4.SS1.p3.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.2.m2.1c">\times</annotation></semantics></math> 2 (model and runtime space). Although most of the time, the server was using less than 512GB, there were a few peaks that reached 700GB or more.</p>
</div>
<div id="S4.SS1.p4" class="ltx_para">
<p id="S4.SS1.p4.2" class="ltx_p">The <span id="S4.SS1.p4.2.1" class="ltx_text ltx_font_italic">Site-1</span> client, with its fast bandwidth connection with the server, received and sent the models in about 100 minutes and entered a nearly idle state with little CPU and memory usage after the communication ended. Both clients used about 256GB, i.e., <math id="S4.SS1.p4.1.m1.1" class="ltx_Math" alttext="128GB\times 2" display="inline"><semantics id="S4.SS1.p4.1.m1.1a"><mrow id="S4.SS1.p4.1.m1.1.1" xref="S4.SS1.p4.1.m1.1.1.cmml"><mrow id="S4.SS1.p4.1.m1.1.1.2" xref="S4.SS1.p4.1.m1.1.1.2.cmml"><mn id="S4.SS1.p4.1.m1.1.1.2.2" xref="S4.SS1.p4.1.m1.1.1.2.2.cmml">128</mn><mo lspace="0em" rspace="0em" id="S4.SS1.p4.1.m1.1.1.2.1" xref="S4.SS1.p4.1.m1.1.1.2.1.cmml">​</mo><mi id="S4.SS1.p4.1.m1.1.1.2.3" xref="S4.SS1.p4.1.m1.1.1.2.3.cmml">G</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p4.1.m1.1.1.2.1a" xref="S4.SS1.p4.1.m1.1.1.2.1.cmml">​</mo><mi id="S4.SS1.p4.1.m1.1.1.2.4" xref="S4.SS1.p4.1.m1.1.1.2.4.cmml">B</mi></mrow><mo lspace="0.222em" rspace="0.222em" id="S4.SS1.p4.1.m1.1.1.1" xref="S4.SS1.p4.1.m1.1.1.1.cmml">×</mo><mn id="S4.SS1.p4.1.m1.1.1.3" xref="S4.SS1.p4.1.m1.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p4.1.m1.1b"><apply id="S4.SS1.p4.1.m1.1.1.cmml" xref="S4.SS1.p4.1.m1.1.1"><times id="S4.SS1.p4.1.m1.1.1.1.cmml" xref="S4.SS1.p4.1.m1.1.1.1"></times><apply id="S4.SS1.p4.1.m1.1.1.2.cmml" xref="S4.SS1.p4.1.m1.1.1.2"><times id="S4.SS1.p4.1.m1.1.1.2.1.cmml" xref="S4.SS1.p4.1.m1.1.1.2.1"></times><cn type="integer" id="S4.SS1.p4.1.m1.1.1.2.2.cmml" xref="S4.SS1.p4.1.m1.1.1.2.2">128</cn><ci id="S4.SS1.p4.1.m1.1.1.2.3.cmml" xref="S4.SS1.p4.1.m1.1.1.2.3">𝐺</ci><ci id="S4.SS1.p4.1.m1.1.1.2.4.cmml" xref="S4.SS1.p4.1.m1.1.1.2.4">𝐵</ci></apply><cn type="integer" id="S4.SS1.p4.1.m1.1.1.3.cmml" xref="S4.SS1.p4.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p4.1.m1.1c">128GB\times 2</annotation></semantics></math> (for model and runtime space), but at the end of receiving large models and at the beginning of sending large models, these two clients required more than 378GB, i.e., 128GB <math id="S4.SS1.p4.2.m2.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.SS1.p4.2.m2.1a"><mo id="S4.SS1.p4.2.m2.1.1" xref="S4.SS1.p4.2.m2.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.p4.2.m2.1b"><times id="S4.SS1.p4.2.m2.1.1.cmml" xref="S4.SS1.p4.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p4.2.m2.1c">\times</annotation></semantics></math> 3.</p>
</div>
<figure id="S4.F5" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F5.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2402.07792/assets/fig/128GB_server.png" id="S4.F5.sf1.g1" class="ltx_graphics ltx_img_landscape" width="198" height="148" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>Server</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F5.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2402.07792/assets/fig/128GB_site1.png" id="S4.F5.sf2.g1" class="ltx_graphics ltx_img_landscape" width="198" height="148" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>Site-1</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F5.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2402.07792/assets/fig/128GB_site2.png" id="S4.F5.sf3.g1" class="ltx_graphics ltx_img_landscape" width="198" height="148" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(c) </span>Site-2</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5. </span>Memory usage during streaming of a 128GB large model. </figcaption>
</figure>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2. </span>Federated PEFT Performance</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">For PEFT, we utilize NeMo’s PEFT methods. With a single line of configuration change, you can experiment with various PEFT techniques, such as p-tuning <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib20" title="" class="ltx_ref">liu2023gpt, </a>)</cite>, adapters <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib15" title="" class="ltx_ref">houlsby2019parameter, </a>)</cite>, or Low-Rank Adaptation (LoRA) <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib16" title="" class="ltx_ref">hu2021lora, </a>)</cite>, all of which introduce a small number of trainable parameters to the LLM. These parameters condition the model to generate the desired output for the downstream task. These approaches minimize resource utilization by training a smaller subset of parameters compared to full-finetuning. We train a GPT Megatron model with 345 million parameters on a financial sentiment prediction task <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib21" title="" class="ltx_ref">malo2014good, </a>)</cite> using LoRA. In total, this data contains 1,800 pairs of headlines and corresponding sentiment labels. We use a Dirichlet sampling strategy <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib38" title="" class="ltx_ref">wang2020federated, </a>)</cite> for creating a heterogeneous data partition among the clients. Examples of how the training data is distributed among the three clients using different values of <math id="S4.SS2.p1.1.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S4.SS2.p1.1.m1.1a"><mi id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><ci id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">\alpha</annotation></semantics></math> are shown in Fig. <a href="#S4.F6" title="Figure 6 ‣ 4.2. Federated PEFT Performance ‣ 4. Results ‣ Empowering Federated Learning for Massive Models with NVIDIA FLARE" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>.</p>
</div>
<figure id="S4.F6" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F6.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2402.07792/assets/x5.png" id="S4.F6.sf1.g1" class="ltx_graphics ltx_img_landscape" width="152" height="114" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span><math id="S4.F6.sf1.2.m1.1" class="ltx_centering" alttext="\alpha=1.0" display="inline"><semantics id="S4.F6.sf1.2.m1.1b"><mrow id="S4.F6.sf1.2.m1.1.1" xref="S4.F6.sf1.2.m1.1.1.cmml"><mi id="S4.F6.sf1.2.m1.1.1.2" xref="S4.F6.sf1.2.m1.1.1.2.cmml">α</mi><mo id="S4.F6.sf1.2.m1.1.1.1" xref="S4.F6.sf1.2.m1.1.1.1.cmml">=</mo><mn id="S4.F6.sf1.2.m1.1.1.3" xref="S4.F6.sf1.2.m1.1.1.3.cmml">1.0</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.F6.sf1.2.m1.1c"><apply id="S4.F6.sf1.2.m1.1.1.cmml" xref="S4.F6.sf1.2.m1.1.1"><eq id="S4.F6.sf1.2.m1.1.1.1.cmml" xref="S4.F6.sf1.2.m1.1.1.1"></eq><ci id="S4.F6.sf1.2.m1.1.1.2.cmml" xref="S4.F6.sf1.2.m1.1.1.2">𝛼</ci><cn type="float" id="S4.F6.sf1.2.m1.1.1.3.cmml" xref="S4.F6.sf1.2.m1.1.1.3">1.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F6.sf1.2.m1.1d">\alpha=1.0</annotation></semantics></math></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F6.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2402.07792/assets/x6.png" id="S4.F6.sf2.g1" class="ltx_graphics ltx_img_landscape" width="152" height="114" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span><math id="S4.F6.sf2.2.m1.1" class="ltx_centering" alttext="\alpha=5.0" display="inline"><semantics id="S4.F6.sf2.2.m1.1b"><mrow id="S4.F6.sf2.2.m1.1.1" xref="S4.F6.sf2.2.m1.1.1.cmml"><mi id="S4.F6.sf2.2.m1.1.1.2" xref="S4.F6.sf2.2.m1.1.1.2.cmml">α</mi><mo id="S4.F6.sf2.2.m1.1.1.1" xref="S4.F6.sf2.2.m1.1.1.1.cmml">=</mo><mn id="S4.F6.sf2.2.m1.1.1.3" xref="S4.F6.sf2.2.m1.1.1.3.cmml">5.0</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.F6.sf2.2.m1.1c"><apply id="S4.F6.sf2.2.m1.1.1.cmml" xref="S4.F6.sf2.2.m1.1.1"><eq id="S4.F6.sf2.2.m1.1.1.1.cmml" xref="S4.F6.sf2.2.m1.1.1.1"></eq><ci id="S4.F6.sf2.2.m1.1.1.2.cmml" xref="S4.F6.sf2.2.m1.1.1.2">𝛼</ci><cn type="float" id="S4.F6.sf2.2.m1.1.1.3.cmml" xref="S4.F6.sf2.2.m1.1.1.3">5.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F6.sf2.2.m1.1d">\alpha=5.0</annotation></semantics></math></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F6.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2402.07792/assets/x7.png" id="S4.F6.sf3.g1" class="ltx_graphics ltx_img_landscape" width="152" height="114" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(c) </span><math id="S4.F6.sf3.2.m1.1" class="ltx_centering" alttext="\alpha=10.0" display="inline"><semantics id="S4.F6.sf3.2.m1.1b"><mrow id="S4.F6.sf3.2.m1.1.1" xref="S4.F6.sf3.2.m1.1.1.cmml"><mi id="S4.F6.sf3.2.m1.1.1.2" xref="S4.F6.sf3.2.m1.1.1.2.cmml">α</mi><mo id="S4.F6.sf3.2.m1.1.1.1" xref="S4.F6.sf3.2.m1.1.1.1.cmml">=</mo><mn id="S4.F6.sf3.2.m1.1.1.3" xref="S4.F6.sf3.2.m1.1.1.3.cmml">10.0</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.F6.sf3.2.m1.1c"><apply id="S4.F6.sf3.2.m1.1.1.cmml" xref="S4.F6.sf3.2.m1.1.1"><eq id="S4.F6.sf3.2.m1.1.1.1.cmml" xref="S4.F6.sf3.2.m1.1.1.1"></eq><ci id="S4.F6.sf3.2.m1.1.1.2.cmml" xref="S4.F6.sf3.2.m1.1.1.2">𝛼</ci><cn type="float" id="S4.F6.sf3.2.m1.1.1.3.cmml" xref="S4.F6.sf3.2.m1.1.1.3">10.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F6.sf3.2.m1.1d">\alpha=10.0</annotation></semantics></math></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6. </span>Simulation of different data distributions among clients. </figcaption>
</figure>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">Figure <a href="#S4.F7" title="Figure 7 ‣ 4.2. Federated PEFT Performance ‣ 4. Results ‣ Empowering Federated Learning for Massive Models with NVIDIA FLARE" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> shows examples of how the training data is distributed among the three clients when using different <math id="S4.SS2.p2.1.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S4.SS2.p2.1.m1.1a"><mi id="S4.SS2.p2.1.m1.1.1" xref="S4.SS2.p2.1.m1.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.1.m1.1b"><ci id="S4.SS2.p2.1.m1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.1.m1.1c">\alpha</annotation></semantics></math> values. The lines show the mean accuracy of local models during training, and shaded areas indicate the 95% confidence interval.</p>
</div>
<figure id="S4.F7" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F7.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2402.07792/assets/x8.png" id="S4.F7.sf1.g1" class="ltx_graphics ltx_img_landscape" width="152" height="114" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span><math id="S4.F7.sf1.2.m1.1" class="ltx_centering" alttext="\alpha=1.0" display="inline"><semantics id="S4.F7.sf1.2.m1.1b"><mrow id="S4.F7.sf1.2.m1.1.1" xref="S4.F7.sf1.2.m1.1.1.cmml"><mi id="S4.F7.sf1.2.m1.1.1.2" xref="S4.F7.sf1.2.m1.1.1.2.cmml">α</mi><mo id="S4.F7.sf1.2.m1.1.1.1" xref="S4.F7.sf1.2.m1.1.1.1.cmml">=</mo><mn id="S4.F7.sf1.2.m1.1.1.3" xref="S4.F7.sf1.2.m1.1.1.3.cmml">1.0</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.F7.sf1.2.m1.1c"><apply id="S4.F7.sf1.2.m1.1.1.cmml" xref="S4.F7.sf1.2.m1.1.1"><eq id="S4.F7.sf1.2.m1.1.1.1.cmml" xref="S4.F7.sf1.2.m1.1.1.1"></eq><ci id="S4.F7.sf1.2.m1.1.1.2.cmml" xref="S4.F7.sf1.2.m1.1.1.2">𝛼</ci><cn type="float" id="S4.F7.sf1.2.m1.1.1.3.cmml" xref="S4.F7.sf1.2.m1.1.1.3">1.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F7.sf1.2.m1.1d">\alpha=1.0</annotation></semantics></math></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F7.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2402.07792/assets/x9.png" id="S4.F7.sf2.g1" class="ltx_graphics ltx_img_landscape" width="152" height="114" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span><math id="S4.F7.sf2.2.m1.1" class="ltx_centering" alttext="\alpha=5.0" display="inline"><semantics id="S4.F7.sf2.2.m1.1b"><mrow id="S4.F7.sf2.2.m1.1.1" xref="S4.F7.sf2.2.m1.1.1.cmml"><mi id="S4.F7.sf2.2.m1.1.1.2" xref="S4.F7.sf2.2.m1.1.1.2.cmml">α</mi><mo id="S4.F7.sf2.2.m1.1.1.1" xref="S4.F7.sf2.2.m1.1.1.1.cmml">=</mo><mn id="S4.F7.sf2.2.m1.1.1.3" xref="S4.F7.sf2.2.m1.1.1.3.cmml">5.0</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.F7.sf2.2.m1.1c"><apply id="S4.F7.sf2.2.m1.1.1.cmml" xref="S4.F7.sf2.2.m1.1.1"><eq id="S4.F7.sf2.2.m1.1.1.1.cmml" xref="S4.F7.sf2.2.m1.1.1.1"></eq><ci id="S4.F7.sf2.2.m1.1.1.2.cmml" xref="S4.F7.sf2.2.m1.1.1.2">𝛼</ci><cn type="float" id="S4.F7.sf2.2.m1.1.1.3.cmml" xref="S4.F7.sf2.2.m1.1.1.3">5.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F7.sf2.2.m1.1d">\alpha=5.0</annotation></semantics></math></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F7.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2402.07792/assets/x10.png" id="S4.F7.sf3.g1" class="ltx_graphics ltx_img_landscape" width="152" height="114" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(c) </span><math id="S4.F7.sf3.2.m1.1" class="ltx_centering" alttext="\alpha=10.0" display="inline"><semantics id="S4.F7.sf3.2.m1.1b"><mrow id="S4.F7.sf3.2.m1.1.1" xref="S4.F7.sf3.2.m1.1.1.cmml"><mi id="S4.F7.sf3.2.m1.1.1.2" xref="S4.F7.sf3.2.m1.1.1.2.cmml">α</mi><mo id="S4.F7.sf3.2.m1.1.1.1" xref="S4.F7.sf3.2.m1.1.1.1.cmml">=</mo><mn id="S4.F7.sf3.2.m1.1.1.3" xref="S4.F7.sf3.2.m1.1.1.3.cmml">10.0</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.F7.sf3.2.m1.1c"><apply id="S4.F7.sf3.2.m1.1.1.cmml" xref="S4.F7.sf3.2.m1.1.1"><eq id="S4.F7.sf3.2.m1.1.1.1.cmml" xref="S4.F7.sf3.2.m1.1.1.1"></eq><ci id="S4.F7.sf3.2.m1.1.1.2.cmml" xref="S4.F7.sf3.2.m1.1.1.2">𝛼</ci><cn type="float" id="S4.F7.sf3.2.m1.1.1.3.cmml" xref="S4.F7.sf3.2.m1.1.1.3">10.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F7.sf3.2.m1.1d">\alpha=10.0</annotation></semantics></math></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7. </span>PEFT accuracy curves on clients using their “Local” data alone versus the accuracy when training a joint model using “FL” that can learn from the data available at all sites without having to centralize the data. </figcaption>
</figure>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.1" class="ltx_p">Example input headlines from the financial sentiment prediction tasks and the predictions from the trained global model are shown in <span id="S4.SS2.p3.1.1" class="ltx_text ltx_font_typewriter ltx_font_bold">bold</span>:</p>
</div>
<div id="S4.SS2.p4" class="ltx_para">
<ul id="S4.I1" class="ltx_itemize">
<li id="S4.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i1.p1" class="ltx_para">
<p id="S4.I1.i1.p1.1" class="ltx_p"><span id="S4.I1.i1.p1.1.1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">The products have a low salt and fat content.
<br class="ltx_break"><span id="S4.I1.i1.p1.1.1.1" class="ltx_text ltx_font_bold">sentiment: neutral</span></span><span id="S4.I1.i1.p1.1.2" class="ltx_text" style="font-size:90%;"></span></p>
</div>
</li>
<li id="S4.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i2.p1" class="ltx_para">
<p id="S4.I1.i2.p1.1" class="ltx_p"><span id="S4.I1.i2.p1.1.1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">The agreement is valid for four years.
<br class="ltx_break"><span id="S4.I1.i2.p1.1.1.1" class="ltx_text ltx_font_bold">sentiment: neutral</span></span><span id="S4.I1.i2.p1.1.2" class="ltx_text" style="font-size:90%;"></span></p>
</div>
</li>
<li id="S4.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i3.p1" class="ltx_para">
<p id="S4.I1.i3.p1.1" class="ltx_p"><span id="S4.I1.i3.p1.1.1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">Diluted EPS rose to EUR3 .68 from EUR0 .50.
<br class="ltx_break"><span id="S4.I1.i3.p1.1.1.1" class="ltx_text ltx_font_bold">sentiment: positive</span></span><span id="S4.I1.i3.p1.1.2" class="ltx_text" style="font-size:90%;"></span></p>
</div>
</li>
<li id="S4.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i4.p1" class="ltx_para">
<p id="S4.I1.i4.p1.1" class="ltx_p"><span id="S4.I1.i4.p1.1.1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">The company is well positioned in Brazil and Uruguay.
<br class="ltx_break"><span id="S4.I1.i4.p1.1.1.1" class="ltx_text ltx_font_bold">sentiment: positive</span></span><span id="S4.I1.i4.p1.1.2" class="ltx_text" style="font-size:90%;"></span></p>
</div>
</li>
<li id="S4.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i5.p1" class="ltx_para">
<p id="S4.I1.i5.p1.1" class="ltx_p"><span id="S4.I1.i5.p1.1.1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">Profit before taxes decreased by 9% to EUR 187.8 mn in the first nine months of 2008, compared to EUR 207.1 mn a year earlier.
<br class="ltx_break"><span id="S4.I1.i5.p1.1.1.1" class="ltx_text ltx_font_bold">sentiment: negative</span></span><span id="S4.I1.i5.p1.1.2" class="ltx_text" style="font-size:90%;"></span></p>
</div>
</li>
</ul>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3. </span>Federated SFT Performance</h3>

<figure id="S4.F8" class="ltx_figure"><img src="/html/2402.07792/assets/x11.png" id="S4.F8.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="438" height="190" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8. </span>SFT validation loss curve. </figcaption>
</figure>
<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">For SFT, we conducted experiments using the <span id="S4.SS3.p1.1.1" class="ltx_text ltx_font_italic">nemo-megatron-gpt-1.3B<span id="footnote9" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note"><span id="footnote9.1.1.1" class="ltx_text ltx_font_upright">9</span></span><a target="_blank" href="https://huggingface.co/nvidia/nemo-megatron-gpt-1.3B" title="" class="ltx_ref ltx_url ltx_font_upright" style="color:#0000FF;">https://huggingface.co/nvidia/nemo-megatron-gpt-1.3B</a></span></span></span></span> model, SFT for five rounds, training on three open datasets Alpaca<span id="footnote10" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">10</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">10</sup><span class="ltx_tag ltx_tag_note">10</span><a target="_blank" href="https://huggingface.co/datasets/tatsu-lab/alpaca" title="" class="ltx_ref ltx_url" style="color:#0000FF;">https://huggingface.co/datasets/tatsu-lab/alpaca</a></span></span></span> <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib36" title="" class="ltx_ref">alpaca, </a>)</cite>, databricks-dolly-15k<span id="footnote11" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">11</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">11</sup><span class="ltx_tag ltx_tag_note">11</span><a target="_blank" href="https://huggingface.co/datasets/databricks/databricks-dolly-15k" title="" class="ltx_ref ltx_url" style="color:#0000FF;">https://huggingface.co/datasets/databricks/databricks-dolly-15k</a></span></span></span> <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib4" title="" class="ltx_ref">DatabricksBlog2023DollyV2, </a>)</cite>, OpenAssistant Conversations<span id="footnote12" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">12</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">12</sup><span class="ltx_tag ltx_tag_note">12</span><a target="_blank" href="https://huggingface.co/datasets/OpenAssistant/oasst1" title="" class="ltx_ref ltx_url" style="color:#0000FF;">https://huggingface.co/datasets/OpenAssistant/oasst1</a></span></span></span> <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib18" title="" class="ltx_ref">kopf2023openassistant, </a>)</cite>, one for each client.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.1" class="ltx_p">Figure <a href="#S4.F8" title="Figure 8 ‣ 4.3. Federated SFT Performance ‣ 4. Results ‣ Empowering Federated Learning for Massive Models with NVIDIA FLARE" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> illustrates the validation curves under all experiment settings: local-only training on each of the three datasets, on a combined dataset, and federated learning with all three clients training together using the FedAvg algorithm. Smooth curves represent local training, while “step curves”, identified by red dots, are for FL - the “steps” are due to global model aggregation and update at the beginning of each FL round.</p>
</div>
<div id="S4.SS3.p3" class="ltx_para">
<p id="S4.SS3.p3.2" class="ltx_p">Evaluating LLMs can be a non-trivial task. Following popular benchmark tasks, we perform three language modeling tasks under zero-shot settings, including HellaSwag (H) <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib42" title="" class="ltx_ref">zellers2019hellaswag, </a>)</cite>, PIQA (P) <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib1" title="" class="ltx_ref">bisk2020piqa, </a>)</cite>, and WinoGrande (W) <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib31" title="" class="ltx_ref">sakaguchi2021winogrande, </a>)</cite>. Table <a href="#S4.T1" title="Table 1 ‣ 4.3. Federated SFT Performance ‣ 4. Results ‣ Empowering Federated Learning for Massive Models with NVIDIA FLARE" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> shows the results of each SFT model, with “BaseModel” representing the model before SFT.
We utilize both “unnormalized” (<math id="S4.SS3.p3.1.m1.1" class="ltx_Math" alttext="*_{\mathrm{acc}}" display="inline"><semantics id="S4.SS3.p3.1.m1.1a"><msub id="S4.SS3.p3.1.m1.1.1" xref="S4.SS3.p3.1.m1.1.1.cmml"><mo id="S4.SS3.p3.1.m1.1.1.2" xref="S4.SS3.p3.1.m1.1.1.2.cmml">∗</mo><mi id="S4.SS3.p3.1.m1.1.1.3" xref="S4.SS3.p3.1.m1.1.1.3.cmml">acc</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.1.m1.1b"><apply id="S4.SS3.p3.1.m1.1.1.cmml" xref="S4.SS3.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS3.p3.1.m1.1.1.1.cmml" xref="S4.SS3.p3.1.m1.1.1">subscript</csymbol><times id="S4.SS3.p3.1.m1.1.1.2.cmml" xref="S4.SS3.p3.1.m1.1.1.2"></times><ci id="S4.SS3.p3.1.m1.1.1.3.cmml" xref="S4.SS3.p3.1.m1.1.1.3">acc</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.1.m1.1c">*_{\mathrm{acc}}</annotation></semantics></math>) and “normalized” (<math id="S4.SS3.p3.2.m2.1" class="ltx_Math" alttext="*_{\mathrm{\widehat{acc}}}" display="inline"><semantics id="S4.SS3.p3.2.m2.1a"><msub id="S4.SS3.p3.2.m2.1.1" xref="S4.SS3.p3.2.m2.1.1.cmml"><mo id="S4.SS3.p3.2.m2.1.1.2" xref="S4.SS3.p3.2.m2.1.1.2.cmml">∗</mo><mover accent="true" id="S4.SS3.p3.2.m2.1.1.3" xref="S4.SS3.p3.2.m2.1.1.3.cmml"><mi id="S4.SS3.p3.2.m2.1.1.3.2" xref="S4.SS3.p3.2.m2.1.1.3.2.cmml">acc</mi><mo id="S4.SS3.p3.2.m2.1.1.3.1" xref="S4.SS3.p3.2.m2.1.1.3.1.cmml">^</mo></mover></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.2.m2.1b"><apply id="S4.SS3.p3.2.m2.1.1.cmml" xref="S4.SS3.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS3.p3.2.m2.1.1.1.cmml" xref="S4.SS3.p3.2.m2.1.1">subscript</csymbol><times id="S4.SS3.p3.2.m2.1.1.2.cmml" xref="S4.SS3.p3.2.m2.1.1.2"></times><apply id="S4.SS3.p3.2.m2.1.1.3.cmml" xref="S4.SS3.p3.2.m2.1.1.3"><ci id="S4.SS3.p3.2.m2.1.1.3.1.cmml" xref="S4.SS3.p3.2.m2.1.1.3.1">^</ci><ci id="S4.SS3.p3.2.m2.1.1.3.2.cmml" xref="S4.SS3.p3.2.m2.1.1.3.2">acc</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.2.m2.1c">*_{\mathrm{\widehat{acc}}}</annotation></semantics></math>) metrics and compute their mean for overall evaluation <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib9" title="" class="ltx_ref">eval-harness, </a>)</cite>.
As shown, FL can help achieve the best overall performance compared to the models fine-tuned on the individual datasets by effectively combining updates from diverse sources without having to centralize the data as in the “Combined” setting.</p>
</div>
<figure id="S4.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1. </span>Model performance on three benchmark tasks: HellaSwag (H), PIQA (P), and WinoGrande (W). </figcaption>
<table id="S4.T1.5" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T1.5.5" class="ltx_tr">
<th id="S4.T1.5.5.6" class="ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_tt"></th>
<td id="S4.T1.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><math id="S4.T1.1.1.1.m1.1" class="ltx_Math" alttext="H_{\mathrm{acc}}" display="inline"><semantics id="S4.T1.1.1.1.m1.1a"><msub id="S4.T1.1.1.1.m1.1.1" xref="S4.T1.1.1.1.m1.1.1.cmml"><mi mathsize="90%" id="S4.T1.1.1.1.m1.1.1.2" xref="S4.T1.1.1.1.m1.1.1.2.cmml">H</mi><mi mathsize="90%" id="S4.T1.1.1.1.m1.1.1.3" xref="S4.T1.1.1.1.m1.1.1.3.cmml">acc</mi></msub><annotation-xml encoding="MathML-Content" id="S4.T1.1.1.1.m1.1b"><apply id="S4.T1.1.1.1.m1.1.1.cmml" xref="S4.T1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.1.1.1.m1.1.1.1.cmml" xref="S4.T1.1.1.1.m1.1.1">subscript</csymbol><ci id="S4.T1.1.1.1.m1.1.1.2.cmml" xref="S4.T1.1.1.1.m1.1.1.2">𝐻</ci><ci id="S4.T1.1.1.1.m1.1.1.3.cmml" xref="S4.T1.1.1.1.m1.1.1.3">acc</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.1.1.1.m1.1c">H_{\mathrm{acc}}</annotation></semantics></math></td>
<td id="S4.T1.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><math id="S4.T1.2.2.2.m1.1" class="ltx_Math" alttext="H_{\mathrm{\widehat{acc}}}" display="inline"><semantics id="S4.T1.2.2.2.m1.1a"><msub id="S4.T1.2.2.2.m1.1.1" xref="S4.T1.2.2.2.m1.1.1.cmml"><mi mathsize="90%" id="S4.T1.2.2.2.m1.1.1.2" xref="S4.T1.2.2.2.m1.1.1.2.cmml">H</mi><mover accent="true" id="S4.T1.2.2.2.m1.1.1.3" xref="S4.T1.2.2.2.m1.1.1.3.cmml"><mi mathsize="90%" id="S4.T1.2.2.2.m1.1.1.3.2" xref="S4.T1.2.2.2.m1.1.1.3.2.cmml">acc</mi><mo mathsize="90%" id="S4.T1.2.2.2.m1.1.1.3.1" xref="S4.T1.2.2.2.m1.1.1.3.1.cmml">^</mo></mover></msub><annotation-xml encoding="MathML-Content" id="S4.T1.2.2.2.m1.1b"><apply id="S4.T1.2.2.2.m1.1.1.cmml" xref="S4.T1.2.2.2.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.2.2.2.m1.1.1.1.cmml" xref="S4.T1.2.2.2.m1.1.1">subscript</csymbol><ci id="S4.T1.2.2.2.m1.1.1.2.cmml" xref="S4.T1.2.2.2.m1.1.1.2">𝐻</ci><apply id="S4.T1.2.2.2.m1.1.1.3.cmml" xref="S4.T1.2.2.2.m1.1.1.3"><ci id="S4.T1.2.2.2.m1.1.1.3.1.cmml" xref="S4.T1.2.2.2.m1.1.1.3.1">^</ci><ci id="S4.T1.2.2.2.m1.1.1.3.2.cmml" xref="S4.T1.2.2.2.m1.1.1.3.2">acc</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.2.2.2.m1.1c">H_{\mathrm{\widehat{acc}}}</annotation></semantics></math></td>
<td id="S4.T1.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><math id="S4.T1.3.3.3.m1.1" class="ltx_Math" alttext="P_{\mathrm{acc}}" display="inline"><semantics id="S4.T1.3.3.3.m1.1a"><msub id="S4.T1.3.3.3.m1.1.1" xref="S4.T1.3.3.3.m1.1.1.cmml"><mi mathsize="90%" id="S4.T1.3.3.3.m1.1.1.2" xref="S4.T1.3.3.3.m1.1.1.2.cmml">P</mi><mi mathsize="90%" id="S4.T1.3.3.3.m1.1.1.3" xref="S4.T1.3.3.3.m1.1.1.3.cmml">acc</mi></msub><annotation-xml encoding="MathML-Content" id="S4.T1.3.3.3.m1.1b"><apply id="S4.T1.3.3.3.m1.1.1.cmml" xref="S4.T1.3.3.3.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.3.3.3.m1.1.1.1.cmml" xref="S4.T1.3.3.3.m1.1.1">subscript</csymbol><ci id="S4.T1.3.3.3.m1.1.1.2.cmml" xref="S4.T1.3.3.3.m1.1.1.2">𝑃</ci><ci id="S4.T1.3.3.3.m1.1.1.3.cmml" xref="S4.T1.3.3.3.m1.1.1.3">acc</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.3.3.3.m1.1c">P_{\mathrm{acc}}</annotation></semantics></math></td>
<td id="S4.T1.4.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><math id="S4.T1.4.4.4.m1.1" class="ltx_Math" alttext="P_{\mathrm{\widehat{acc}}}" display="inline"><semantics id="S4.T1.4.4.4.m1.1a"><msub id="S4.T1.4.4.4.m1.1.1" xref="S4.T1.4.4.4.m1.1.1.cmml"><mi mathsize="90%" id="S4.T1.4.4.4.m1.1.1.2" xref="S4.T1.4.4.4.m1.1.1.2.cmml">P</mi><mover accent="true" id="S4.T1.4.4.4.m1.1.1.3" xref="S4.T1.4.4.4.m1.1.1.3.cmml"><mi mathsize="90%" id="S4.T1.4.4.4.m1.1.1.3.2" xref="S4.T1.4.4.4.m1.1.1.3.2.cmml">acc</mi><mo mathsize="90%" id="S4.T1.4.4.4.m1.1.1.3.1" xref="S4.T1.4.4.4.m1.1.1.3.1.cmml">^</mo></mover></msub><annotation-xml encoding="MathML-Content" id="S4.T1.4.4.4.m1.1b"><apply id="S4.T1.4.4.4.m1.1.1.cmml" xref="S4.T1.4.4.4.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.4.4.4.m1.1.1.1.cmml" xref="S4.T1.4.4.4.m1.1.1">subscript</csymbol><ci id="S4.T1.4.4.4.m1.1.1.2.cmml" xref="S4.T1.4.4.4.m1.1.1.2">𝑃</ci><apply id="S4.T1.4.4.4.m1.1.1.3.cmml" xref="S4.T1.4.4.4.m1.1.1.3"><ci id="S4.T1.4.4.4.m1.1.1.3.1.cmml" xref="S4.T1.4.4.4.m1.1.1.3.1">^</ci><ci id="S4.T1.4.4.4.m1.1.1.3.2.cmml" xref="S4.T1.4.4.4.m1.1.1.3.2">acc</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.4.4.4.m1.1c">P_{\mathrm{\widehat{acc}}}</annotation></semantics></math></td>
<td id="S4.T1.5.5.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><math id="S4.T1.5.5.5.m1.1" class="ltx_Math" alttext="W_{\mathrm{acc}}" display="inline"><semantics id="S4.T1.5.5.5.m1.1a"><msub id="S4.T1.5.5.5.m1.1.1" xref="S4.T1.5.5.5.m1.1.1.cmml"><mi mathsize="90%" id="S4.T1.5.5.5.m1.1.1.2" xref="S4.T1.5.5.5.m1.1.1.2.cmml">W</mi><mi mathsize="90%" id="S4.T1.5.5.5.m1.1.1.3" xref="S4.T1.5.5.5.m1.1.1.3.cmml">acc</mi></msub><annotation-xml encoding="MathML-Content" id="S4.T1.5.5.5.m1.1b"><apply id="S4.T1.5.5.5.m1.1.1.cmml" xref="S4.T1.5.5.5.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.5.5.5.m1.1.1.1.cmml" xref="S4.T1.5.5.5.m1.1.1">subscript</csymbol><ci id="S4.T1.5.5.5.m1.1.1.2.cmml" xref="S4.T1.5.5.5.m1.1.1.2">𝑊</ci><ci id="S4.T1.5.5.5.m1.1.1.3.cmml" xref="S4.T1.5.5.5.m1.1.1.3">acc</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.5.5.5.m1.1c">W_{\mathrm{acc}}</annotation></semantics></math></td>
<td id="S4.T1.5.5.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span id="S4.T1.5.5.7.1" class="ltx_text" style="font-size:90%;">Mean</span></td>
</tr>
<tr id="S4.T1.5.6.1" class="ltx_tr">
<th id="S4.T1.5.6.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="S4.T1.5.6.1.1.1" class="ltx_text" style="font-size:90%;">BaseModel</span></th>
<td id="S4.T1.5.6.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.5.6.1.2.1" class="ltx_text" style="font-size:90%;">0.357</span></td>
<td id="S4.T1.5.6.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.5.6.1.3.1" class="ltx_text" style="font-size:90%;">0.439</span></td>
<td id="S4.T1.5.6.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.5.6.1.4.1" class="ltx_text" style="font-size:90%;">0.683</span></td>
<td id="S4.T1.5.6.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.5.6.1.5.1" class="ltx_text" style="font-size:90%;">0.689</span></td>
<td id="S4.T1.5.6.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.5.6.1.6.1" class="ltx_text" style="font-size:90%;">0.537</span></td>
<td id="S4.T1.5.6.1.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.5.6.1.7.1" class="ltx_text" style="font-size:90%;">0.541</span></td>
</tr>
<tr id="S4.T1.5.7.2" class="ltx_tr">
<th id="S4.T1.5.7.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="S4.T1.5.7.2.1.1" class="ltx_text" style="font-size:90%;">Alpaca</span></th>
<td id="S4.T1.5.7.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.5.7.2.2.1" class="ltx_text" style="font-size:90%;">0.372</span></td>
<td id="S4.T1.5.7.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.5.7.2.3.1" class="ltx_text" style="font-size:90%;">0.451</span></td>
<td id="S4.T1.5.7.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.5.7.2.4.1" class="ltx_text" style="font-size:90%;">0.675</span></td>
<td id="S4.T1.5.7.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.5.7.2.5.1" class="ltx_text" style="font-size:90%;">0.687</span></td>
<td id="S4.T1.5.7.2.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.5.7.2.6.1" class="ltx_text" style="font-size:90%;">0.550</span></td>
<td id="S4.T1.5.7.2.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.5.7.2.7.1" class="ltx_text" style="font-size:90%;">0.547</span></td>
</tr>
<tr id="S4.T1.5.8.3" class="ltx_tr">
<th id="S4.T1.5.8.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r"><span id="S4.T1.5.8.3.1.1" class="ltx_text" style="font-size:90%;">Dolly</span></th>
<td id="S4.T1.5.8.3.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.5.8.3.2.1" class="ltx_text" style="font-size:90%;">0.376</span></td>
<td id="S4.T1.5.8.3.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.5.8.3.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.474</span></td>
<td id="S4.T1.5.8.3.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.5.8.3.4.1" class="ltx_text" style="font-size:90%;">0.671</span></td>
<td id="S4.T1.5.8.3.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.5.8.3.5.1" class="ltx_text" style="font-size:90%;">0.667</span></td>
<td id="S4.T1.5.8.3.6" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.5.8.3.6.1" class="ltx_text" style="font-size:90%;">0.529</span></td>
<td id="S4.T1.5.8.3.7" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.5.8.3.7.1" class="ltx_text" style="font-size:90%;">0.543</span></td>
</tr>
<tr id="S4.T1.5.9.4" class="ltx_tr">
<th id="S4.T1.5.9.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r"><span id="S4.T1.5.9.4.1.1" class="ltx_text" style="font-size:90%;">Oasst1</span></th>
<td id="S4.T1.5.9.4.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.5.9.4.2.1" class="ltx_text" style="font-size:90%;">0.370</span></td>
<td id="S4.T1.5.9.4.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.5.9.4.3.1" class="ltx_text" style="font-size:90%;">0.452</span></td>
<td id="S4.T1.5.9.4.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.5.9.4.4.1" class="ltx_text" style="font-size:90%;">0.657</span></td>
<td id="S4.T1.5.9.4.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.5.9.4.5.1" class="ltx_text" style="font-size:90%;">0.655</span></td>
<td id="S4.T1.5.9.4.6" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.5.9.4.6.1" class="ltx_text" style="font-size:90%;">0.506</span></td>
<td id="S4.T1.5.9.4.7" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.5.9.4.7.1" class="ltx_text" style="font-size:90%;">0.528</span></td>
</tr>
<tr id="S4.T1.5.10.5" class="ltx_tr">
<th id="S4.T1.5.10.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="S4.T1.5.10.5.1.1" class="ltx_text" style="font-size:90%;">Combined</span></th>
<td id="S4.T1.5.10.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.5.10.5.2.1" class="ltx_text" style="font-size:90%;">0.370</span></td>
<td id="S4.T1.5.10.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.5.10.5.3.1" class="ltx_text" style="font-size:90%;">0.453</span></td>
<td id="S4.T1.5.10.5.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.5.10.5.4.1" class="ltx_text" style="font-size:90%;">0.685</span></td>
<td id="S4.T1.5.10.5.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.5.10.5.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.690</span></td>
<td id="S4.T1.5.10.5.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.5.10.5.6.1" class="ltx_text" style="font-size:90%;">0.548</span></td>
<td id="S4.T1.5.10.5.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.5.10.5.7.1" class="ltx_text" style="font-size:90%;">0.549</span></td>
</tr>
<tr id="S4.T1.5.11.6" class="ltx_tr">
<th id="S4.T1.5.11.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_l ltx_border_r"><span id="S4.T1.5.11.6.1.1" class="ltx_text" style="font-size:90%;">FedAvg</span></th>
<td id="S4.T1.5.11.6.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S4.T1.5.11.6.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.377</span></td>
<td id="S4.T1.5.11.6.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S4.T1.5.11.6.3.1" class="ltx_text" style="font-size:90%;">0.469</span></td>
<td id="S4.T1.5.11.6.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S4.T1.5.11.6.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.688</span></td>
<td id="S4.T1.5.11.6.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S4.T1.5.11.6.5.1" class="ltx_text" style="font-size:90%;">0.687</span></td>
<td id="S4.T1.5.11.6.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S4.T1.5.11.6.6.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.560</span></td>
<td id="S4.T1.5.11.6.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S4.T1.5.11.6.7.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.556</span></td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4. </span>Subcellular Structure Prediction</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.1" class="ltx_p">First, we run federated inference of the ESM-1nv model to extract embeddings, which requires a GPU with at least 12GB memory.</p>
</div>
<div id="S4.SS4.p2" class="ltx_para">
<p id="S4.SS4.p2.1" class="ltx_p">Next, we want to classify proteins for their subcellular location. Hence, we train a simple <span id="S4.SS4.p2.1.1" class="ltx_text ltx_font_italic">scikit-learn</span> <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib24" title="" class="ltx_ref">scikit-learn, </a>)</cite> Multi-layer Perceptron (MPL) classifier on top of the extracted ESM-1nv features using FedAvg. The MLP model uses a network of hidden layers to fit the input embedding vectors to the model classes (the cellular locations above). The results in Fig. <a href="#S4.F9" title="Figure 9 ‣ 4.4. Subcellular Structure Prediction ‣ 4. Results ‣ Empowering Federated Learning for Massive Models with NVIDIA FLARE" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a> show the local (clients train on their local data alone) and global (using FedAvg) model performances varying the number of 32 hidden units of the MLP from one layer with 32 hidden units to four layers containing 512, 256, 128, and 64 units, respectively.</p>
</div>
<div id="S4.SS4.p3" class="ltx_para">
<p id="S4.SS4.p3.1" class="ltx_p">As the MLP parameters increase, the local models tend to overfit to the training data, while the FL models can benefit from the larger effective training set sizes and perform well on the test sets.</p>
</div>
<figure id="S4.F9" class="ltx_figure"><img src="/html/2402.07792/assets/x12.png" id="S4.F9.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="456" height="159" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9. </span>Subcellular Structure Prediction of local and global models (using FL). The bar plots show the mean and standard deviation error of the accuracy across clients. </figcaption>
</figure>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5. </span>Conclusion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">FL presents exciting opportunities for customizing foundational LLMs and tackling data challenges while prioritizing privacy. Fine-tuning techniques, which aim to adapt foundational LLMs for specific domains and tasks, can be seamlessly applied within an FL paradigm, leveraging the broader availability of diverse distributed datasets. NVFlare offers communication support to facilitate collaborative LLM training. These techniques, when combined with advancements in model development, pave the way for more adaptable and efficient LLMs.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">This paper primarily highlights NVFlare’s new features, demonstrating its capability to simplify and scale the adaptation of LLMs with popular fine-tuning approaches like PEFT and SFT within FL, thereby supporting federated training of massive models. Two key features stand out: the <span id="S5.p2.1.1" class="ltx_text ltx_font_italic">Client API</span> and the ability to stream large datasets.</p>
</div>
<div id="S5.p3" class="ltx_para">
<p id="S5.p3.1" class="ltx_p">Utilizing the <span id="S5.p3.1.1" class="ltx_text ltx_font_italic">Client API</span>, it becomes straightforward to translate existing code developed for centralized training into a federated scenario. It avoids the need for a major restructuring of the training code to fit certain client class structures as required by other FL frameworks.</p>
</div>
<div id="S5.p4" class="ltx_para">
<p id="S5.p4.1" class="ltx_p">The <span id="S5.p4.1.1" class="ltx_text ltx_font_italic">Streaming API</span> enables the communication of arbitrary large message sizes, paving the way for enabling FL for massive models, such as modern LLMs.</p>
</div>
<div id="S5.p5" class="ltx_para">
<p id="S5.p5.1" class="ltx_p">FL holds promise for collaborative learning, preserving privacy, and enhancing model performance. With NVFlare, federated workflows can be seamlessly transitioned into real-world production environments. For further details, please visit the code repository at <a target="_blank" href="https://github.com/NVIDIA/NVFlare" title="" class="ltx_ref ltx_url" style="color:#0000FF;">https://github.com/NVIDIA/NVFlare</a>.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Y. Bisk, R. Zellers, J. Gao, Y. Choi, et al.

</span>
<span class="ltx_bibblock">Piqa: Reasoning about physical commonsense in natural language.

</span>
<span class="ltx_bibblock">In <span id="bib.bib1.1.1" class="ltx_text ltx_font_italic">Proceedings of the AAAI conference on artificial intelligence</span>, volume 34, pages 7432–7439, 2020.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell, et al.

</span>
<span class="ltx_bibblock">Language models are few-shot learners.

</span>
<span class="ltx_bibblock"><span id="bib.bib2.1.1" class="ltx_text ltx_font_italic">Advances in neural information processing systems</span>, 33:1877–1901, 2020.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
K. Chang, N. Balachandar, C. Lam, D. Yi, J. Brown, A. Beers, B. Rosen, D. L. Rubin, and J. Kalpathy-Cramer.

</span>
<span class="ltx_bibblock">Distributed deep learning networks among institutions for medical imaging.

</span>
<span class="ltx_bibblock"><span id="bib.bib3.1.1" class="ltx_text ltx_font_italic">Journal of the American Medical Informatics Association</span>, 25(8):945–954, 2018.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
M. Conover, M. Hayes, A. Mathur, J. Xie, J. Wan, S. Shah, A. Ghodsi, P. Wendell, M. Zaharia, and R. Xin.

</span>
<span class="ltx_bibblock">Free dolly: Introducing the world’s first truly open instruction-tuned llm, 2023.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
C. Dallago, J. Mou, K. E. Johnston, B. J. Wittmann, N. Bhattacharya, S. Goldman, A. Madani, and K. K. Yang.

</span>
<span class="ltx_bibblock">Flip: Benchmark tasks in fitness landscape inference for proteins.

</span>
<span class="ltx_bibblock"><span id="bib.bib5.1.1" class="ltx_text ltx_font_italic">bioRxiv</span>, pages 2021–11, 2021.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
I. Dayan, H. R. Roth, A. Zhong, A. Harouni, A. Gentili, A. Z. Abidin, A. Liu, A. B. Costa, B. J. Wood, C.-S. Tsai, et al.

</span>
<span class="ltx_bibblock">Federated learning for predicting clinical outcomes in patients with covid-19.

</span>
<span class="ltx_bibblock"><span id="bib.bib6.1.1" class="ltx_text ltx_font_italic">Nature medicine</span>, 27(10):1735–1743, 2021.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova.

</span>
<span class="ltx_bibblock">Bert: Pre-training of deep bidirectional transformers for language understanding.

</span>
<span class="ltx_bibblock"><span id="bib.bib7.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1810.04805</span>, 2018.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
N. Ding, Y. Qin, G. Yang, F. Wei, Z. Yang, Y. Su, S. Hu, Y. Chen, C.-M. Chan, W. Chen, et al.

</span>
<span class="ltx_bibblock">Parameter-efficient fine-tuning of large-scale pre-trained language models.

</span>
<span class="ltx_bibblock"><span id="bib.bib8.1.1" class="ltx_text ltx_font_italic">Nature Machine Intelligence</span>, 5(3):220–235, 2023.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
L. Gao, J. Tow, B. Abbasi, S. Biderman, S. Black, A. DiPofi, C. Foster, L. Golding, J. Hsu, A. Le Noac’h, H. Li, K. McDonell, N. Muennighoff, C. Ociepa, J. Phang, L. Reynolds, H. Schoelkopf, A. Skowron, L. Sutawika, E. Tang, A. Thite, B. Wang, K. Wang, and A. Zou.

</span>
<span class="ltx_bibblock">A framework for few-shot language model evaluation, 12 2023.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
P. Guo, D. Yang, A. Hatamizadeh, A. Xu, Z. Xu, W. Li, C. Zhao, D. Xu, S. Harmon, E. Turkbey, et al.

</span>
<span class="ltx_bibblock">Auto-fedrl: Federated hyperparameter optimization for multi-institutional medical image segmentation.

</span>
<span class="ltx_bibblock">In <span id="bib.bib10.1.1" class="ltx_text ltx_font_italic">European Conference on Computer Vision</span>, pages 437–455. Springer, 2022.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
O. Gupta and R. Raskar.

</span>
<span class="ltx_bibblock">Distributed learning of deep neural network over multiple agents.

</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text ltx_font_italic">Journal of Network and Computer Applications</span>, 116:1–8, 2018.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
E. Harper, S. Majumdar, O. Kuchaiev, L. Jason, Y. Zhang, E. Bakhturina, V. Noroozi, S. Subramanian, K. Nithin, H. Jocelyn, F. Jia, J. Balam, X. Yang, M. Livne, Y. Dong, S. Naren, and B. Ginsburg.

</span>
<span class="ltx_bibblock">NeMo: a toolkit for Conversational AI and Large Language Models.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
J. He, C. Zhou, X. Ma, T. Berg-Kirkpatrick, and G. Neubig.

</span>
<span class="ltx_bibblock">Towards a unified view of parameter-efficient transfer learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2110.04366</span>, 2021.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
D. Hendrycks and K. Gimpel.

</span>
<span class="ltx_bibblock">Gaussian error linear units (gelus).

</span>
<span class="ltx_bibblock"><span id="bib.bib14.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1606.08415</span>, 2016.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
N. Houlsby, A. Giurgiu, S. Jastrzebski, B. Morrone, Q. De Laroussilhe, A. Gesmundo, M. Attariyan, and S. Gelly.

</span>
<span class="ltx_bibblock">Parameter-efficient transfer learning for nlp.

</span>
<span class="ltx_bibblock">In <span id="bib.bib15.1.1" class="ltx_text ltx_font_italic">International Conference on Machine Learning</span>, pages 2790–2799. PMLR, 2019.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
E. J. Hu, Y. Shen, P. Wallis, Z. Allen-Zhu, Y. Li, S. Wang, L. Wang, and W. Chen.

</span>
<span class="ltx_bibblock">Lora: Low-rank adaptation of large language models.

</span>
<span class="ltx_bibblock"><span id="bib.bib16.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2106.09685</span>, 2021.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
M. Jiang, H. R. Roth, W. Li, D. Yang, C. Zhao, V. Nath, D. Xu, Q. Dou, and Z. Xu.

</span>
<span class="ltx_bibblock">Fair federated medical image segmentation via client contribution estimation.

</span>
<span class="ltx_bibblock">In <span id="bib.bib17.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</span>, pages 16302–16311, 2023.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
A. Köpf, Y. Kilcher, D. von Rütte, S. Anagnostidis, Z.-R. Tam, K. Stevens, A. Barhoum, N. M. Duc, O. Stanley, R. Nagyfi, et al.

</span>
<span class="ltx_bibblock">Openassistant conversations–democratizing large language model alignment.

</span>
<span class="ltx_bibblock"><span id="bib.bib18.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2304.07327</span>, 2023.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
W. Li, F. Milletarì, D. Xu, N. Rieke, J. Hancox, W. Zhu, M. Baust, Y. Cheng, S. Ourselin, M. J. Cardoso, et al.

</span>
<span class="ltx_bibblock">Privacy-preserving federated brain tumour segmentation.

</span>
<span class="ltx_bibblock">In <span id="bib.bib19.1.1" class="ltx_text ltx_font_italic">International workshop on machine learning in medical imaging</span>, pages 133–141. Springer, 2019.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
X. Liu, Y. Zheng, Z. Du, M. Ding, Y. Qian, Z. Yang, and J. Tang.

</span>
<span class="ltx_bibblock">Gpt understands, too.

</span>
<span class="ltx_bibblock"><span id="bib.bib20.1.1" class="ltx_text ltx_font_italic">AI Open</span>, 2023.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
P. Malo, A. Sinha, P. Korhonen, J. Wallenius, and P. Takala.

</span>
<span class="ltx_bibblock">Good debt or bad debt: Detecting semantic orientations in economic texts.

</span>
<span class="ltx_bibblock"><span id="bib.bib21.1.1" class="ltx_text ltx_font_italic">Journal of the Association for Information Science and Technology</span>, 65(4):782–796, 2014.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas.

</span>
<span class="ltx_bibblock">Communication-efficient learning of deep networks from decentralized data.

</span>
<span class="ltx_bibblock">In <span id="bib.bib22.1.1" class="ltx_text ltx_font_italic">Artificial intelligence and statistics</span>, pages 1273–1282. PMLR, 2017.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
J. Meier, R. Rao, R. Verkuil, J. Liu, T. Sercu, and A. Rives.

</span>
<span class="ltx_bibblock">Language models enable zero-shot prediction of the effects of mutations on protein function.

</span>
<span class="ltx_bibblock"><span id="bib.bib23.1.1" class="ltx_text ltx_font_italic">bioRxiv</span>, 2021.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay.

</span>
<span class="ltx_bibblock">Scikit-learn: Machine learning in Python.

</span>
<span class="ltx_bibblock"><span id="bib.bib24.1.1" class="ltx_text ltx_font_italic">Journal of Machine Learning Research</span>, 12:2825–2830, 2011.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
Pixabay.

</span>
<span class="ltx_bibblock">Cross section of an animal cell, .

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
N. Rieke, J. Hancox, W. Li, F. Milletari, H. R. Roth, S. Albarqouni, S. Bakas, M. N. Galtier, B. A. Landman, K. Maier-Hein, et al.

</span>
<span class="ltx_bibblock">The future of digital health with federated learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib26.1.1" class="ltx_text ltx_font_italic">NPJ digital medicine</span>, 3(1):1–7, 2020.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
A. Rives, J. Meier, T. Sercu, S. Goyal, Z. Lin, J. Liu, D. Guo, M. Ott, C. L. Zitnick, J. Ma, et al.

</span>
<span class="ltx_bibblock">Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences.

</span>
<span class="ltx_bibblock"><span id="bib.bib27.1.1" class="ltx_text ltx_font_italic">Proceedings of the National Academy of Sciences</span>, 118(15):e2016239118, 2021.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
H. R. Roth, K. Chang, P. Singh, N. Neumark, W. Li, V. Gupta, S. Gupta, L. Qu, A. Ihsani, B. C. Bizzo, et al.

</span>
<span class="ltx_bibblock">Federated learning for breast density classification: A real-world implementation.

</span>
<span class="ltx_bibblock">In <span id="bib.bib28.1.1" class="ltx_text ltx_font_italic">Domain Adaptation and Representation Transfer, and Distributed and Collaborative Learning</span>, pages 181–191. Springer, 2020.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
H. R. Roth, Y. Cheng, Y. Wen, I. Yang, Z. Xu, Y.-T. Hsieh, K. Kersten, A. Harouni, C. Zhao, K. Lu, et al.

</span>
<span class="ltx_bibblock">Nvidia flare: Federated learning from simulation to real-world.

</span>
<span class="ltx_bibblock"><span id="bib.bib29.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2210.13291</span>, 2022.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
B. Roziere, J. Gehring, F. Gloeckle, S. Sootla, I. Gat, X. E. Tan, Y. Adi, J. Liu, T. Remez, J. Rapin, et al.

</span>
<span class="ltx_bibblock">Code llama: Open foundation models for code.

</span>
<span class="ltx_bibblock"><span id="bib.bib30.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2308.12950</span>, 2023.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
K. Sakaguchi, R. L. Bras, C. Bhagavatula, and Y. Choi.

</span>
<span class="ltx_bibblock">Winogrande: An adversarial winograd schema challenge at scale.

</span>
<span class="ltx_bibblock"><span id="bib.bib31.1.1" class="ltx_text ltx_font_italic">Communications of the ACM</span>, 64(9):99–106, 2021.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
K. V. Sarma, S. Harmon, T. Sanford, H. R. Roth, Z. Xu, J. Tetreault, D. Xu, M. G. Flores, A. G. Raman, R. Kulkarni, et al.

</span>
<span class="ltx_bibblock">Federated learning improves site performance in multicenter deep learning without data sharing.

</span>
<span class="ltx_bibblock"><span id="bib.bib32.1.1" class="ltx_text ltx_font_italic">Journal of the American Medical Informatics Association</span>, 28(6):1259–1264, 2021.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
S. Smith, M. Patwary, B. Norick, P. LeGresley, S. Rajbhandari, J. Casper, Z. Liu, S. Prabhumoye, G. Zerveas, V. Korthikanti, et al.

</span>
<span class="ltx_bibblock">Using deepspeed and megatron to train megatron-turing nlg 530b, a large-scale generative language model.

</span>
<span class="ltx_bibblock"><span id="bib.bib33.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2201.11990</span>, 2022.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
H. Stärk, C. Dallago, M. Heinzinger, and B. Rost.

</span>
<span class="ltx_bibblock">Light attention predicts protein location from the language of life.

</span>
<span class="ltx_bibblock"><span id="bib.bib34.1.1" class="ltx_text ltx_font_italic">Bioinformatics Advances</span>, 1(1):vbab035, 2021.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
J. Sun, Z. Xu, D. Yang, V. Nath, W. Li, C. Zhao, D. Xu, Y. Chen, and H. R. Roth.

</span>
<span class="ltx_bibblock">Communication-efficient vertical federated learning with limited overlapping samples.

</span>
<span class="ltx_bibblock"><span id="bib.bib35.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2303.16270</span>, 2023.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
R. Taori, I. Gulrajani, T. Zhang, Y. Dubois, X. Li, C. Guestrin, P. Liang, and T. B. Hashimoto.

</span>
<span class="ltx_bibblock">Stanford alpaca: An instruction-following llama model.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/tatsu-lab/stanford_alpaca" title="" class="ltx_ref ltx_url" style="color:#0000FF;">https://github.com/tatsu-lab/stanford˙alpaca</a>, 2023.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
H. Touvron, L. Martin, K. Stone, P. Albert, A. Almahairi, Y. Babaei, N. Bashlykov, S. Batra, P. Bhargava, S. Bhosale, et al.

</span>
<span class="ltx_bibblock">Llama 2: Open foundation and fine-tuned chat models.

</span>
<span class="ltx_bibblock"><span id="bib.bib37.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2307.09288</span>, 2023.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
H. Wang, M. Yurochkin, Y. Sun, D. Papailiopoulos, and Y. Khazaeni.

</span>
<span class="ltx_bibblock">Federated learning with matched averaging.

</span>
<span class="ltx_bibblock"><span id="bib.bib38.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2002.06440</span>, 2020.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
P. Wang, C. Shen, W. Wang, M. Oda, C.-S. Fuh, K. Mori, and H. R. Roth.

</span>
<span class="ltx_bibblock">Condistfl: Conditional distillation for federated learning from partially annotated data.

</span>
<span class="ltx_bibblock">In <span id="bib.bib39.1.1" class="ltx_text ltx_font_italic">International Conference on Medical Image Computing and Computer-Assisted Intervention</span>, pages 311–321. Springer, 2023.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
S. Warnat-Herresthal, H. Schultze, K. L. Shastry, S. Manamohan, S. Mukherjee, V. Garg, R. Sarveswara, K. Händler, P. Pickkers, N. A. Aziz, et al.

</span>
<span class="ltx_bibblock">Swarm learning for decentralized and confidential clinical machine learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib40.1.1" class="ltx_text ltx_font_italic">Nature</span>, 594(7862):265–270, 2021.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
A. Xu, W. Li, P. Guo, D. Yang, H. R. Roth, A. Hatamizadeh, C. Zhao, D. Xu, H. Huang, and Z. Xu.

</span>
<span class="ltx_bibblock">Closing the generalization gap of cross-silo federated medical image segmentation.

</span>
<span class="ltx_bibblock">In <span id="bib.bib41.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</span>, pages 20866–20875, 2022.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
R. Zellers, A. Holtzman, Y. Bisk, A. Farhadi, and Y. Choi.

</span>
<span class="ltx_bibblock">Hellaswag: Can a machine really finish your sentence?

</span>
<span class="ltx_bibblock"><span id="bib.bib42.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1905.07830</span>, 2019.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
C. Zhang, S. Li, J. Xia, W. Wang, F. Yan, and Y. Liu.

</span>
<span class="ltx_bibblock">Batchcrypt: Efficient homomorphic encryption for <math id="bib.bib43.1.m1.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib43.1.m1.1a"><mo stretchy="false" id="bib.bib43.1.m1.1.1" xref="bib.bib43.1.m1.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib43.1.m1.1b"><ci id="bib.bib43.1.m1.1.1.cmml" xref="bib.bib43.1.m1.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib43.1.m1.1c">\{</annotation></semantics></math>Cross-Silo<math id="bib.bib43.2.m2.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib43.2.m2.1a"><mo stretchy="false" id="bib.bib43.2.m2.1.1" xref="bib.bib43.2.m2.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib43.2.m2.1b"><ci id="bib.bib43.2.m2.1.1.cmml" xref="bib.bib43.2.m2.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib43.2.m2.1c">\}</annotation></semantics></math> federated learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib43.3.1" class="ltx_text ltx_font_italic">2020 USENIX Annual Technical Conference (USENIX ATC 20)</span>, pages 493–506, 2020.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2402.07791" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2402.07792" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2402.07792">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2402.07792" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2402.07793" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Tue Mar  5 13:19:46 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
