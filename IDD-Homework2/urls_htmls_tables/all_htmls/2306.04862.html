<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2306.04862] A Systematic Literature Review on Client Selection in Federated Learning</title><meta property="og:description" content="With the arising concerns of privacy within machine learning, federated learning (FL) was invented in 2017, in which the clients, such as mobile devices, train a model and send the update to the centralized server. Cho…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="A Systematic Literature Review on Client Selection in Federated Learning">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="A Systematic Literature Review on Client Selection in Federated Learning">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2306.04862">

<!--Generated on Mon Feb 26 20:43:46 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="systematic literature review,  software metric,  federated learning,  client selection,  neural network">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">A Systematic Literature Review on Client Selection in Federated Learning</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Carl Smestad
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id1.1.id1" class="ltx_text ltx_affiliation_institution">Norwegian University of Science and Technology</span><span id="id2.2.id2" class="ltx_text ltx_affiliation_city">Trondheim</span><span id="id3.3.id3" class="ltx_text ltx_affiliation_country">Norway</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:carl.smestad@gmail.com">carl.smestad@gmail.com</a>
</span></span></span>
<span class="ltx_author_before"> and </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Jingyue Li
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id4.1.id1" class="ltx_text ltx_affiliation_institution">Norwegian University of Science and Technology</span><span id="id5.2.id2" class="ltx_text ltx_affiliation_city">Trondheim</span><span id="id6.3.id3" class="ltx_text ltx_affiliation_country">Norway</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:jingyue.li@ntnu.no">jingyue.li@ntnu.no</a>
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p id="id7.id1" class="ltx_p">With the arising concerns of privacy within machine learning, federated learning (FL) was invented in 2017, in which the clients, such as mobile devices, train a model and send the update to the centralized server. Choosing clients randomly for FL can harm learning performance due to different reasons. Many studies have proposed approaches to address the challenges of client selection of FL. However, no systematic literature review (SLR) on this topic existed.
This SLR investigates the state of the art of client selection in FL and answers the challenges, solutions, and metrics to evaluate the solutions. We systematically reviewed 47 primary studies. The main challenges found in client selection are heterogeneity, resource allocation, communication costs, and fairness. The client selection schemes aim to improve the original random selection algorithm by focusing on one or several of the aforementioned challenges.
The most common metric used is testing accuracy versus communication rounds, as testing accuracy measures the successfulness of the learning and preferably in as few communication rounds as possible, as they are very expensive.
Although several possible improvements can be made with the current state of client selection, the most beneficial ones are evaluating the impact of unsuccessful clients and gaining a more theoretical understanding of the impact of fairness in FL.</p>
</div>
<div class="ltx_keywords">systematic literature review, software metric, federated learning, client selection, neural network
</div>
<span id="id1" class="ltx_note ltx_note_frontmatter ltx_role_copyright"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">copyright: </span>none</span></span></span><span id="id2" class="ltx_note ltx_note_frontmatter ltx_role_ccs"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Computing methodologies Distributed artificial intelligence</span></span></span><span id="id3" class="ltx_note ltx_note_frontmatter ltx_role_ccs"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Computing methodologies Neural networks</span></span></span><span id="id4" class="ltx_note ltx_note_frontmatter ltx_role_ccs"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Computing methodologies Distributed algorithms</span></span></span>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Machine learning (ML) has increased in popularity in recent years amongst businesses and research. Also, cellphones and tablets are the primary computing devices for many people <cite class="ltx_cite ltx_citemacro_citep">(Anderson, <a href="#bib.bib6" title="" class="ltx_ref">2015</a>)</cite>. These devices are equipped with powerful sensors such as cameras, microphones, and GPS, resulting in a vast amount of private data. With this increased concern regarding personal- and data privacy, a new paradigm for machine learning arose named decentralized learning, with the most prominent technique being federated learning (FL).</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">FL was introduced in 2017 by <cite class="ltx_cite ltx_citemacro_citet">McMahan et al<span class="ltx_text">.</span> (<a href="#bib.bib39" title="" class="ltx_ref">2017</a>)</cite>, which is a decentralized ML paradigm that leaves the training data distributed on mobile devices and learns a shared model by aggregating locally-computed updates <cite class="ltx_cite ltx_citemacro_citep">(Ma et al<span class="ltx_text">.</span>, <a href="#bib.bib38" title="" class="ltx_ref">2022</a>)</cite>. Instead of sending private data to a centralized server (CS), the clients compute or train a model on their device and send the update to the centralized server. The server randomly selects a fixed-size subset of clients and provides them with an initial global model before they train and send the updates. As the client devices have different data, randomly selecting them might lead to several challenges.
As the FL models are meant to be trained on smartphones and IoT devices, the expensive cost of communication must be
considered by reducing the number of communication rounds and reducing the size of
the transmitted messages <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib29" title="" class="ltx_ref">2020a</a>)</cite>.
Another culprit of FL is that it is performed synchronously, which implies
that one round of training is finished when every edge device in the network has sent its
model. This results in an effect known as the straggler effect, where the network is as fast as
the slowest edge <cite class="ltx_cite ltx_citemacro_citep">(Qu et al<span class="ltx_text">.</span>, <a href="#bib.bib44" title="" class="ltx_ref">2022</a>)</cite>. Assuming there is an algorithm that selects the fastest clients and there are no slow clients inducing the straggler effect, and the communication cost and communication rounds are at a minuscule level, it would be natural to assume that this algorithm would be ideal and that not much more could be done in order to improve it. <span id="S1.p2.1.1" class="ltx_text ltx_font_bold">However, client selection is much more complicated than that.</span></p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">To ensure good learning, one must also consider the data heterogeneity, resource allocation, and fairness between the clients. Likely, the selected clients do not have the same data distribution, which might lead to heavy biases within the learning.
Thus, choosing the ”best” clients is an integral part of a well-functioning
federated learning network, but it is certainly not trivial. There are many issues to consider for
defining the best client selection algorithm.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">As pointed out by <cite class="ltx_cite ltx_citemacro_citet">McMahan et al<span class="ltx_text">.</span> (<a href="#bib.bib39" title="" class="ltx_ref">2017</a>)</cite>, only a fraction of clients are selected for efficiency, as their experiments show diminishing returns for adding more clients beyond a certain point.
If the algorithm chooses to include every client as opposed to only a subset, there might be a lot of included clients who do not add value to the training while increasing the cost of communication. Perhaps some of the clients will not even finish training, which will make the entire round of learning fail. Therefore, only a subset of clients must be included during client selection.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">Hence, we are motivated to examine how studies have tried to improve client selection, as many problems can be addressed by better strategies than random selection. We focus on answering the following research questions (RQs):</p>
</div>
<div id="S1.p6" class="ltx_para">
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p"><span id="S1.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">RQ1: What are the main challenges in client selection?</span></p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p"><span id="S1.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">RQ2: How are clients selected in federated learning?</span></p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p"><span id="S1.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">RQ3: Which metrics are important for measuring client selection?</span></p>
</div>
</li>
<li id="S1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i4.p1" class="ltx_para">
<p id="S1.I1.i4.p1.1" class="ltx_p"><span id="S1.I1.i4.p1.1.1" class="ltx_text ltx_font_bold">RQ4: What can be improved with the current client selection?</span></p>
</div>
</li>
</ul>
</div>
<div id="S1.p7" class="ltx_para">
<p id="S1.p7.1" class="ltx_p">To answer the research questions, a systematic literature review (SLR) was conducted by following the guidelines by <cite class="ltx_cite ltx_citemacro_citet">Kitchenham and Charters (<a href="#bib.bib23" title="" class="ltx_ref">2007</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citet">Wohlin (<a href="#bib.bib54" title="" class="ltx_ref">2014</a>)</cite>. One iteration of backward and forward-snowballing was performed on a set of six papers, resulting in 47 primary studies to review after the quality assessment and study selection. The contributions of this SLR are as follows.</p>
</div>
<div id="S1.p8" class="ltx_para">
<ul id="S1.I2" class="ltx_itemize">
<li id="S1.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I2.i1.p1" class="ltx_para">
<p id="S1.I2.i1.p1.1" class="ltx_p">It summarizes the main challenges in terms of client selection for FL. The main challenges are heterogeneity, resource allocation, communication costs, and fairness.</p>
</div>
</li>
<li id="S1.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I2.i2.p1" class="ltx_para">
<p id="S1.I2.i2.p1.1" class="ltx_p">It summarizes the important metrics for measuring client selection in regard to the main challenges. The most commonly used metrics are testing accuracy and communication rounds.</p>
</div>
</li>
<li id="S1.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I2.i3.p1" class="ltx_para">
<p id="S1.I2.i3.p1.1" class="ltx_p">It discusses possible future work within the field of client selection for FL.</p>
</div>
</li>
</ul>
</div>
<div id="S1.p9" class="ltx_para">
<p id="S1.p9.1" class="ltx_p">The rest of the paper is organized as follows. The related work is presented in section <a href="#S2" title="2. Related Work ‣ A Systematic Literature Review on Client Selection in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. The research methodology and implementation are presented in section <a href="#S3" title="3. Research Design and Implementation ‣ A Systematic Literature Review on Client Selection in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. Section <a href="#S4" title="4. Research Results ‣ A Systematic Literature Review on Client Selection in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> shows the results of this SLR, and section <a href="#S5" title="5. Discussion ‣ A Systematic Literature Review on Client Selection in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> discusses the results. Lastly, section <a href="#S6" title="6. Conclusions and Future Work ‣ A Systematic Literature Review on Client Selection in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> concludes the study and proposes future work.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Related Work</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">There are several literature reviews and surveys related to FL. <cite class="ltx_cite ltx_citemacro_citet">Hou et al<span class="ltx_text">.</span> (<a href="#bib.bib19" title="" class="ltx_ref">2021</a>)</cite> performed an SLR of blockchain-based FL and specialized in the architectures and applications. They identified four security issues in FL which motivate the use of blockchain. The study mentioned the Internet of Things (IoT), medicine, and the Internet of Vehicles (IoV) as promising fields for application but did not mention client selection.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citet">Pfitzner et al<span class="ltx_text">.</span> (<a href="#bib.bib43" title="" class="ltx_ref">2021</a>)</cite> conducted an SLR of FL in a medical context. They focused on the areas that were promising for digital health applications. <cite class="ltx_cite ltx_citemacro_citet">Antunes et al<span class="ltx_text">.</span> (<a href="#bib.bib7" title="" class="ltx_ref">2022</a>)</cite> did an SLR of FL for healthcare and focused on the architecture and remaining issues regarding applying FL to electronic health records (EHR). Both <cite class="ltx_cite ltx_citemacro_citet">Pfitzner et al<span class="ltx_text">.</span> (<a href="#bib.bib43" title="" class="ltx_ref">2021</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citet">Antunes et al<span class="ltx_text">.</span> (<a href="#bib.bib7" title="" class="ltx_ref">2022</a>)</cite> focused on the security perspective and did not summarize client selection issues.
<cite class="ltx_cite ltx_citemacro_citet">Lo et al<span class="ltx_text">.</span> (<a href="#bib.bib35" title="" class="ltx_ref">2021</a>)</cite> performed an SLR of FL from a software engineering perspective. They focused on what FL is, the different applications, general challenges, and how they are addressed. The five most common challenges were communication efficiency, statistical heterogeneity, system heterogeneity, data security, and client device security. The study noticed that client selection is mostly server-based but did not discuss it further.
<cite class="ltx_cite ltx_citemacro_citet">Liu et al<span class="ltx_text">.</span> (<a href="#bib.bib34" title="" class="ltx_ref">2020</a>)</cite> conducted an SLR of FL but from a model quality perspective. The study presents several algorithms types, such as neural networks, decision trees, etc., with corresponding client-side algorithms but does not consider client selection.
<cite class="ltx_cite ltx_citemacro_citet">Shaheen et al<span class="ltx_text">.</span> (<a href="#bib.bib47" title="" class="ltx_ref">2022</a>)</cite> investigated the applications, challenges and research trends of FL. The study underwent 105 research studies and discovered that the most promising application is within the healthcare domain. They reported data imbalance, system heterogeneity, expensive communication, privacy concerns, statistical heterogeneity, and resource allocation as the main challenges of implementing FL. However, they did not relate any of these challenges to client selection.
<cite class="ltx_cite ltx_citemacro_citet">Witt et al<span class="ltx_text">.</span> (<a href="#bib.bib53" title="" class="ltx_ref">2022</a>)</cite> wrote an SLR of FL from the incentivization methods perspective. This study also discusses blockchain as a possible improvement but does not mention client selection outside the scope of blockchain.
<cite class="ltx_cite ltx_citemacro_citet">Hosseinzadeh et al<span class="ltx_text">.</span> (<a href="#bib.bib17" title="" class="ltx_ref">2022a</a>)</cite> did an SLR of FL with emphasis on IoT, focusing on the evaluation factors and the future and open challenges of FL-based IoT. The study mentions a possible client selection method but does not focus on the topic.
<cite class="ltx_cite ltx_citemacro_citet">Lo et al<span class="ltx_text">.</span> (<a href="#bib.bib36" title="" class="ltx_ref">2022</a>)</cite> reviewed the different architectural patterns to design FL systems. The study reports 15 architectural patterns, where one of which is the client selector. The study provides a high-level overview of possible solutions, such as resource-based, data-based, and performance-based client selection, as well as some of the benefits and drawbacks of the pattern.
<cite class="ltx_cite ltx_citemacro_citet">Abreha et al<span class="ltx_text">.</span> (<a href="#bib.bib3" title="" class="ltx_ref">2022</a>)</cite> systematically surveyed FL in edge computing.
The survey reports the main challenges as communication cost, reliability, privacy, and administrative policies. It also discusses client selection to a small degree by mentioning existing studies on the topic.
<cite class="ltx_cite ltx_citemacro_citet">Ali et al<span class="ltx_text">.</span> (<a href="#bib.bib5" title="" class="ltx_ref">2021</a>)</cite> conducted an SLR of incentive-driven FL and the associated security challenges. Some incentive mechanisms include auction theory and blockchain but do not touch on the topic of client selection and possibly how to incentivize clients.
<cite class="ltx_cite ltx_citemacro_citet">Ma et al<span class="ltx_text">.</span> (<a href="#bib.bib38" title="" class="ltx_ref">2022</a>)</cite> reviewed the state-of-the-art in solving non-
<br class="ltx_break">independant and identically distributed (Non-IID) data in FL and addressed future trends for the topic. When the datasets are not independent and identically distributed, it leads to less correlation and dependencies because samples of the datasets do not have the same probability distribution. Non-IID data is one of the largest challenges in FL, and the study discusses ways to improve it through, e.g., data enhancements and data selection.
One of these methods is client selection, but the survey does not go more into depth than linking to relevant papers.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>Research Design and Implementation</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">To summarize the state of the art of client selection of FL and to answer our research questions, we performed a systematic literature review based upon the guidelines <cite class="ltx_cite ltx_citemacro_citep">(Kitchenham and Charters, <a href="#bib.bib23" title="" class="ltx_ref">2007</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citep">(Wohlin, <a href="#bib.bib54" title="" class="ltx_ref">2014</a>)</cite>.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1. </span>Search Strategy</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">Generally, the SLR approach for generating a search strategy is to break down the research questions into searchable terms and generate a list of synonyms, abbreviations, and alternative spellings.
As there exist a vast amount of studies on the topic of FL, this process became unmanageable. Thus, the strategy used in this paper is based on the guidelines for snowballing in SLR by <cite class="ltx_cite ltx_citemacro_citet">Wohlin (<a href="#bib.bib54" title="" class="ltx_ref">2014</a>)</cite>, as shown in Figure
<a href="#S3.F1" title="Figure 1 ‣ 3.1. Search Strategy ‣ 3. Research Design and Implementation ‣ A Systematic Literature Review on Client Selection in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, which includes the following main steps:</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<ul id="S3.I1" class="ltx_itemize">
<li id="S3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i1.p1" class="ltx_para">
<p id="S3.I1.i1.p1.1" class="ltx_p">Step 1: Generate a start set of studies (including only papers that will be a part of the final analysis)</p>
</div>
</li>
<li id="S3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i2.p1" class="ltx_para">
<p id="S3.I1.i2.p1.1" class="ltx_p">Step 2: Perform backward- and forward snowballing</p>
</div>
</li>
<li id="S3.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i3.p1" class="ltx_para">
<p id="S3.I1.i3.p1.1" class="ltx_p">Step 3: Decide to include or exclude the study</p>
</div>
</li>
<li id="S3.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i4.p1" class="ltx_para">
<p id="S3.I1.i4.p1.1" class="ltx_p">Step 4: Iterate until finding no new papers</p>
</div>
</li>
</ul>
</div>
<figure id="S3.F1" class="ltx_figure"><img src="/html/2306.04862/assets/Images/Snowballing-transformed.png" id="S3.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="240" height="184" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1. </span>Illustration of snowballing in SLR <cite class="ltx_cite ltx_citemacro_citep">(Wohlin, <a href="#bib.bib54" title="" class="ltx_ref">2014</a>)</cite></figcaption>
</figure>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.1" class="ltx_p">To start the snowballing procedure, a starting set was needed. Google Scholar was used to generate this starting set by using relevant terms such as ”Federated Learning” and ”Client Selection in Federated Learning.”
The results are listed below.</p>
</div>
<div id="S3.SS1.p4" class="ltx_para">
<ul id="S3.I2" class="ltx_itemize">
<li id="S3.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I2.i1.p1" class="ltx_para">
<p id="S3.I2.i1.p1.1" class="ltx_p">”Communication-Efficient Learning of Deep Networks from Decentralized Data” <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib39" title="" class="ltx_ref">2017</a>)</cite></p>
</div>
</li>
<li id="S3.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I2.i2.p1" class="ltx_para">
<p id="S3.I2.i2.p1.1" class="ltx_p">”Client Selection for Federated Learning with Heterogeneous Resources in Mobile Edge” <cite class="ltx_cite ltx_citemacro_citep">(Nishio and Yonetani, <a href="#bib.bib41" title="" class="ltx_ref">2019</a>)</cite></p>
</div>
</li>
<li id="S3.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I2.i3.p1" class="ltx_para">
<p id="S3.I2.i3.p1.1" class="ltx_p">”Client selection and bandwidth allocation in wireless federated learning networks: A long-term perspective” <cite class="ltx_cite ltx_citemacro_citep">(Xu and Wang, <a href="#bib.bib55" title="" class="ltx_ref">2021</a>)</cite></p>
</div>
</li>
<li id="S3.I2.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I2.i4.p1" class="ltx_para">
<p id="S3.I2.i4.p1.1" class="ltx_p">”Federated Learning in a Medical Context: A Systematic Literature Review” <cite class="ltx_cite ltx_citemacro_citep">(Pfitzner et al<span class="ltx_text">.</span>, <a href="#bib.bib43" title="" class="ltx_ref">2021</a>)</cite></p>
</div>
</li>
<li id="S3.I2.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I2.i5.p1" class="ltx_para">
<p id="S3.I2.i5.p1.1" class="ltx_p">”A Systematic Literature Review of Blockchain-based Federated Learning: Architectures, Applications and Issues” <cite class="ltx_cite ltx_citemacro_citep">(Hou et al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2021</a>)</cite></p>
</div>
</li>
<li id="S3.I2.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I2.i6.p1" class="ltx_para">
<p id="S3.I2.i6.p1.1" class="ltx_p">”A state-of-the-art survey on solving non-IID data in Federated Learning” <cite class="ltx_cite ltx_citemacro_citep">(Ma et al<span class="ltx_text">.</span>, <a href="#bib.bib38" title="" class="ltx_ref">2022</a>)</cite></p>
</div>
</li>
</ul>
</div>
<div id="S3.SS1.p5" class="ltx_para">
<p id="S3.SS1.p5.1" class="ltx_p">When starting to perform forward and backward snowballing on the starting set, it was apparent that there were too many papers to add as <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib39" title="" class="ltx_ref">2017</a>)</cite> is the first paper on federated learning and is cited by almost every relevant paper in the field.
The paper provided a definition name for devices in FL, namely ”clients.” By investigating several studies, it was clear that, despite FL being a young field within machine learning, a consensus existed on using the term ”Client Selection” for choosing the appropriate devices. Thus, a substring search on Google Scholar with the ”cited by” feature was conducted with that substring to choose the most relevant studies.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2. </span>Study Selection and Quality Assessment</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">We defined including and exclusion criteria to identify primary studies. For a paper to be included, it has to fulfil all the following inclusion criteria:</p>
<ul id="S3.I3" class="ltx_itemize">
<li id="S3.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I3.i1.p1" class="ltx_para">
<p id="S3.I3.i1.p1.1" class="ltx_p">Written in English</p>
</div>
</li>
<li id="S3.I3.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I3.i2.p1" class="ltx_para">
<p id="S3.I3.i2.p1.1" class="ltx_p">Published after 2017 because 2017 is the origin of federated learning appeared in <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib39" title="" class="ltx_ref">2017</a>)</cite></p>
</div>
</li>
<li id="S3.I3.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I3.i3.p1" class="ltx_para">
<p id="S3.I3.i3.p1.1" class="ltx_p">Discusses client selection in Federated Learning</p>
</div>
</li>
<li id="S3.I3.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I3.i4.p1" class="ltx_para">
<p id="S3.I3.i4.p1.1" class="ltx_p">Peer-reviewed</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">According to <cite class="ltx_cite ltx_citemacro_citep">(Higgins et al<span class="ltx_text">.</span>, <a href="#bib.bib16" title="" class="ltx_ref">2019</a>)</cite>, quality can be seen as to which extent the study minimizes bias and maximizes internal and external validity.
Table <a href="#S3.T1" title="Table 1 ‣ 3.2. Study Selection and Quality Assessment ‣ 3. Research Design and Implementation ‣ A Systematic Literature Review on Client Selection in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> shows the different quality assessment criteria for empirical and non-empirical sources <cite class="ltx_cite ltx_citemacro_citep">(Mohanani et al<span class="ltx_text">.</span>, <a href="#bib.bib40" title="" class="ltx_ref">2020</a>)</cite>. For each selected paper, we assessed its quality according to the quality assessment criteria and awarded one point for <span id="S3.SS2.p2.1.1" class="ltx_text ltx_font_italic">yes</span> and zero points for <span id="S3.SS2.p2.1.2" class="ltx_text ltx_font_italic">no</span>. We awarded half a point if it was uncertain whether or not the study fulfilled the criterion.
Then an average was generated for each paper. A paper has to have an average of 0.5 or more to be accepted as the primary study.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.1" class="ltx_p">By applying the selection and quality assessment criteria, a total of 47 papers were chosen as primary studies for data extraction and synthesis.</p>
</div>
<figure id="S3.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1. </span>Quality assessment criteria based on <cite class="ltx_cite ltx_citemacro_citep">(Mohanani et al<span class="ltx_text">.</span>, <a href="#bib.bib40" title="" class="ltx_ref">2020</a>)</cite></figcaption>
<table id="S3.T1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S3.T1.1.1.1" class="ltx_tr">
<th id="S3.T1.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column"><span id="S3.T1.1.1.1.1.1" class="ltx_text ltx_font_bold">Quality Criteria</span></th>
<th id="S3.T1.1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column"><span id="S3.T1.1.1.1.2.1" class="ltx_text ltx_font_bold">Empirical</span></th>
<th id="S3.T1.1.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column"><span id="S3.T1.1.1.1.3.1" class="ltx_text ltx_font_bold">Non-empirical</span></th>
<td id="S3.T1.1.1.1.4" class="ltx_td"></td>
</tr>
<tr id="S3.T1.1.2.2" class="ltx_tr">
<td id="S3.T1.1.2.2.1" class="ltx_td ltx_align_left ltx_border_t">Was the motivation for the study provided?</td>
<td id="S3.T1.1.2.2.2" class="ltx_td ltx_align_center ltx_border_t">X</td>
<td id="S3.T1.1.2.2.3" class="ltx_td ltx_align_center ltx_border_t">X</td>
<td id="S3.T1.1.2.2.4" class="ltx_td"></td>
</tr>
<tr id="S3.T1.1.3.3" class="ltx_tr">
<td id="S3.T1.1.3.3.1" class="ltx_td ltx_align_left">Is the relevance to the industry discussed?</td>
<td id="S3.T1.1.3.3.2" class="ltx_td ltx_align_center">X</td>
<td id="S3.T1.1.3.3.3" class="ltx_td ltx_align_center">X</td>
<td id="S3.T1.1.3.3.4" class="ltx_td"></td>
</tr>
<tr id="S3.T1.1.4.4" class="ltx_tr">
<td id="S3.T1.1.4.4.1" class="ltx_td ltx_align_left">Are the most important sources linked to or discussed?</td>
<td id="S3.T1.1.4.4.2" class="ltx_td ltx_align_center">X</td>
<td id="S3.T1.1.4.4.3" class="ltx_td ltx_align_center">X</td>
<td id="S3.T1.1.4.4.4" class="ltx_td"></td>
</tr>
<tr id="S3.T1.1.5.5" class="ltx_tr">
<td id="S3.T1.1.5.5.1" class="ltx_td ltx_align_left">Is the aim (e.g., objectives, research goal) reported?</td>
<td id="S3.T1.1.5.5.2" class="ltx_td ltx_align_center">X</td>
<td id="S3.T1.1.5.5.3" class="ltx_td ltx_align_center">X</td>
<td id="S3.T1.1.5.5.4" class="ltx_td"></td>
</tr>
<tr id="S3.T1.1.6.6" class="ltx_tr">
<td id="S3.T1.1.6.6.1" class="ltx_td ltx_align_left">Was the research method or design described?</td>
<td id="S3.T1.1.6.6.2" class="ltx_td ltx_align_center">X</td>
<td id="S3.T1.1.6.6.3" class="ltx_td"></td>
<td id="S3.T1.1.6.6.4" class="ltx_td"></td>
</tr>
<tr id="S3.T1.1.7.7" class="ltx_tr">
<td id="S3.T1.1.7.7.1" class="ltx_td ltx_align_left">Were any threats to validity clearly stated?</td>
<td id="S3.T1.1.7.7.2" class="ltx_td ltx_align_center">X</td>
<td id="S3.T1.1.7.7.3" class="ltx_td"></td>
<td id="S3.T1.1.7.7.4" class="ltx_td"></td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3. </span>Data Synthesis</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">Data synthesis involves collating and summarizing the results of the primary studies <cite class="ltx_cite ltx_citemacro_citep">(Kitchenham and Charters, <a href="#bib.bib23" title="" class="ltx_ref">2007</a>)</cite>. SLRs within IT and software engineering are generally qualitative in nature.
Based on the overview of data synthesis provided by <cite class="ltx_cite ltx_citemacro_citep">(van den Berg et al<span class="ltx_text">.</span>, <a href="#bib.bib50" title="" class="ltx_ref">2013</a>)</cite>, we synthesize the data in a spreadsheet, where the common themes, patterns, and finding between the extracted information can be viewed.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.1" class="ltx_p">For each RQ, relevant data were extracted and put into their respective columns according to the research question.
Lastly, a list was manually generated based on the challenges and themes that were created for answering the research questions. The data synthesis process was recorded and available at <span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a target="_blank" href="https://docs.google.com/spreadsheets/d/1jIGpbkOcXazFRcR_Rds0mTshX0NDCIXU9Wgw3SECAiw/edit?usp=sharing" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://docs.google.com/spreadsheets/d/1jIGpbkOcXazFRcR_Rds0mTshX0NDCIXU9Wgw3SECAiw/edit?usp=sharing</a></span></span></span>.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>Research Results</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">This section presents the results of each research question.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1. </span>RQ1: What are the main challenges in client selection?</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">Results show that 23 studies tried to improve upon heterogeneity, 13 studies revolved around resource allocation, eight studies focused on communication costs, and three studies had fairness as the main challenge.
The distribution of the challenges can be seen in Figure <a href="#S4.F2" title="Figure 2 ‣ 4.1. RQ1: What are the main challenges in client selection? ‣ 4. Research Results ‣ A Systematic Literature Review on Client Selection in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. Several studies report more than one challenge, but it has been assigned to the challenge it focuses mostly on.</p>
</div>
<figure id="S4.F2" class="ltx_figure"><svg id="S4.F2.pic1" class="ltx_picture ltx_centering" height="1" overflow="visible" version="1.1" width="1"><g transform="translate(0,1) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><foreignObject width="0" height="0" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S4.F2.pic1.1.1.1.1" class="ltx_ERROR undefined">\pie</span></foreignObject></g></svg>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2. </span>Distribution of challenges reported from the primary studies</figcaption>
</figure>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2. </span>Heterogeneity</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">In FL, the training is executed on the client’s local devices. This will result in differences between the clients as they will have different datasets and availability.
This is the most common challenge found in FL, and <cite class="ltx_cite ltx_citemacro_citet">McMahan et al<span class="ltx_text">.</span> (<a href="#bib.bib39" title="" class="ltx_ref">2017</a>)</cite> reported heterogeneity as the main challenge. Almost half of the primary studies tried to improve it through different measures.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citet">Ma et al<span class="ltx_text">.</span> (<a href="#bib.bib38" title="" class="ltx_ref">2022</a>)</cite> conducted a state-of-the-art survey on solving non-IID data in FL and concluded that data heterogeneity could be divided into the following categories: feature distribution skew, label distribution skew, same label (different features), same feature (different labels) and quantity skew. <cite class="ltx_cite ltx_citemacro_citet">Cho et al<span class="ltx_text">.</span> (<a href="#bib.bib11" title="" class="ltx_ref">2022</a>)</cite> report that heterogeneity also might arise due to partial client participation, as only a small fraction of client nodes participate in each round of training.
If the client selection algorithm selects an improper subset of clients with poor-quality data, this will result in an inefficient trained model <cite class="ltx_cite ltx_citemacro_citep">(Saha et al<span class="ltx_text">.</span>, <a href="#bib.bib46" title="" class="ltx_ref">2022</a>)</cite>.
<cite class="ltx_cite ltx_citemacro_citet">Ma et al<span class="ltx_text">.</span> (<a href="#bib.bib37" title="" class="ltx_ref">2021</a>)</cite> reported label distribution skew as one of the most significant parameters which lead to performance degradation, while <cite class="ltx_cite ltx_citemacro_citet">Rai et al<span class="ltx_text">.</span> (<a href="#bib.bib45" title="" class="ltx_ref">2022</a>)</cite> reported skewed data as one of the most critical factors. <cite class="ltx_cite ltx_citemacro_citet">Zhang et al<span class="ltx_text">.</span> (<a href="#bib.bib61" title="" class="ltx_ref">2021b</a>)</cite> reported that heterogeneity / Non-IID might bring the biases of some clients into the model training and cause accuracy degradation. This claim is supported by <cite class="ltx_cite ltx_citemacro_citet">Zhang et al<span class="ltx_text">.</span> (<a href="#bib.bib60" title="" class="ltx_ref">2021a</a>)</cite>, who claim an urgent need for client selection strategies that promise data unbiasedness in FL. <cite class="ltx_cite ltx_citemacro_citet">Li et al<span class="ltx_text">.</span> (<a href="#bib.bib27" title="" class="ltx_ref">2022b</a>)</cite> analyzed the limitations of the state-of-the-art client selection in regard to heterogeneity and concluded that due to under-exploited statistical- and system efficiency, not all the model updates would contribute to the model training equally. As various clients have diverse data sizes and importance, uploading unimportant updates significantly degrades the system’s efficiency. According to <cite class="ltx_cite ltx_citemacro_citet">Li et al<span class="ltx_text">.</span> (<a href="#bib.bib31" title="" class="ltx_ref">2022a</a>)</cite>, a significant problem with utilizing FL with IoT is that the local data of sensors are constantly changing. This will have a similar effect as device failures and might lead to skewed distributed data, which leads to model degradation. There might also exist label noise on some clients, which exists naturally. This will lead to unnecessary information being exchanged <cite class="ltx_cite ltx_citemacro_citep">(Yang et al<span class="ltx_text">.</span>, <a href="#bib.bib56" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.1" class="ltx_p">To summarize, the key findings for the challenge of heterogeneity are as follows.</p>
<ul id="S4.I1" class="ltx_itemize">
<li id="S4.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i1.p1" class="ltx_para">
<p id="S4.I1.i1.p1.1" class="ltx_p">48.93% of the studies reported heterogeneity as the main challenge for FL.</p>
</div>
</li>
<li id="S4.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i2.p1" class="ltx_para">
<p id="S4.I1.i2.p1.1" class="ltx_p">It might result in an inefficient trained model, performance- and accuracy-degradation.</p>
</div>
</li>
<li id="S4.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i3.p1" class="ltx_para">
<p id="S4.I1.i3.p1.1" class="ltx_p">Heterogeneity might increase biases and unnecessary exchange of information.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3. </span>Resource Allocation</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">Resource allocation was the second most common problem in the primary studies.
This is due to several reasons, but the main one is due to the fact that the training process becomes inefficient when some clients have limited computational resources <cite class="ltx_cite ltx_citemacro_citep">(Nishio and Yonetani, <a href="#bib.bib41" title="" class="ltx_ref">2019</a>)</cite>.
<cite class="ltx_cite ltx_citemacro_citet">Xu and Wang (<a href="#bib.bib55" title="" class="ltx_ref">2021</a>)</cite> state that a considerable challenge in resource allocation is that learning rounds are temporally interdependent and have varying significance toward the final learning outcome.
According to <cite class="ltx_cite ltx_citemacro_citet">Yu et al<span class="ltx_text">.</span> (<a href="#bib.bib57" title="" class="ltx_ref">2022</a>)</cite>, it is unnecessary to select more clients than needed, and it is beneficial to have fewer clients. Still, the challenge consists of the trade-off between the number of clients, energy consumption, and resource allocation. Furthermore, within hierarchical federated learning (HFL), unique challenges exist, such as clients sometimes being inaccessible to the edge servers.
Due to differences in resources and hardware specifications, the ”straggler effect” is bound to happen <cite class="ltx_cite ltx_citemacro_citep">(Qu et al<span class="ltx_text">.</span>, <a href="#bib.bib44" title="" class="ltx_ref">2022</a>)</cite>. <cite class="ltx_cite ltx_citemacro_citet">Zhang et al<span class="ltx_text">.</span> (<a href="#bib.bib59" title="" class="ltx_ref">2021c</a>)</cite> stated that clients are constrained by personal energy and computation that may reduce the efficiency of ML training tasks. This is because the training and transmission of large models are very energy-consuming and might be difficult on low-energy edge devices. During training, there might be changes in client resources due to volatility of client population, client data, and training status <cite class="ltx_cite ltx_citemacro_citep">(Shi et al<span class="ltx_text">.</span>, <a href="#bib.bib48" title="" class="ltx_ref">2022</a>)</cite>. The topic of energy consumption within FL is important, as training and transmission of large models are energy-consuming, while edge devices generally have little energy. <cite class="ltx_cite ltx_citemacro_citet">Zeng et al<span class="ltx_text">.</span> (<a href="#bib.bib58" title="" class="ltx_ref">2020</a>)</cite> propose a client selection policy of giving the lowest priority to clients with poor communication capacity and a bad channel.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.1" class="ltx_p">To summarize, the key findings for the challenge of resource allocation are as follows.</p>
<ul id="S4.I2" class="ltx_itemize">
<li id="S4.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i1.p1" class="ltx_para">
<p id="S4.I2.i1.p1.1" class="ltx_p">27.65% of the studies reported resource allocation as the main challenge of FL.</p>
</div>
</li>
<li id="S4.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i2.p1" class="ltx_para">
<p id="S4.I2.i2.p1.1" class="ltx_p">The training process becomes inefficient when some clients have limited computational resources.</p>
</div>
</li>
<li id="S4.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i3.p1" class="ltx_para">
<p id="S4.I2.i3.p1.1" class="ltx_p">Training and transmission of large models are very energy-consuming and difficult for low-energy devices.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4. </span>Communication costs</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.1" class="ltx_p">The third most common problem was the communication costs in FL. The communication cost is essential as every time the global model updates, it needs to receive the local aggregation of all the selected clients. According to <cite class="ltx_cite ltx_citemacro_citet">Tan et al<span class="ltx_text">.</span> (<a href="#bib.bib49" title="" class="ltx_ref">2022</a>)</cite>, the communication power required to reach convergence makes up a large portion of the cost.
One of the challenges is that a client with low computing power might not return the local model update on time, leading to a long convergence time <cite class="ltx_cite ltx_citemacro_citep">(Ko et al<span class="ltx_text">.</span>, <a href="#bib.bib24" title="" class="ltx_ref">2021</a>)</cite>.
Studies <cite class="ltx_cite ltx_citemacro_citep">(Hosseinzadeh et al<span class="ltx_text">.</span>, <a href="#bib.bib18" title="" class="ltx_ref">2022b</a>; Li et al<span class="ltx_text">.</span>, <a href="#bib.bib28" title="" class="ltx_ref">2022c</a>)</cite> state that the trade-off between communication costs and accuracy is a challenge. <cite class="ltx_cite ltx_citemacro_citet">Asad et al<span class="ltx_text">.</span> (<a href="#bib.bib8" title="" class="ltx_ref">2022</a>)</cite> state that another challenge is the long distance between the different clients and the global server, which results in increased bandwidth usage.</p>
</div>
<div id="S4.SS4.p2" class="ltx_para">
<p id="S4.SS4.p2.1" class="ltx_p">By default, FL is done synchronously. This implies that a round of communication / global model updates is only executed once every client has uploaded their model. This leads to an effect known as the straggler effect, where the system is only as fast as the slowest link <cite class="ltx_cite ltx_citemacro_citep">(Zhu et al<span class="ltx_text">.</span>, <a href="#bib.bib62" title="" class="ltx_ref">2022</a>)</cite>. This issue is also addressed by <cite class="ltx_cite ltx_citemacro_citet">Qu et al<span class="ltx_text">.</span> (<a href="#bib.bib44" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
<div id="S4.SS4.p3" class="ltx_para">
<p id="S4.SS4.p3.1" class="ltx_p">Another fundamental challenge with communication costs is the energy usage of clients in FL. As vast amounts of data are generated from mobile and edge devices, these devices are energy-restricted. It is imperative to improve the energy efficiency of the systems <cite class="ltx_cite ltx_citemacro_citep">(Zeng et al<span class="ltx_text">.</span>, <a href="#bib.bib58" title="" class="ltx_ref">2020</a>)</cite>.</p>
</div>
<div id="S4.SS4.p4" class="ltx_para">
<p id="S4.SS4.p4.1" class="ltx_p">According to <cite class="ltx_cite ltx_citemacro_citet">Deng et al<span class="ltx_text">.</span> (<a href="#bib.bib12" title="" class="ltx_ref">2022</a>)</cite>, clients’ hardware conditions and data resources can vary significantly, which might lead to negative performance.</p>
</div>
<div id="S4.SS4.p5" class="ltx_para">
<p id="S4.SS4.p5.1" class="ltx_p">To summarize, the key findings for the challenge of communication costs are as follows.</p>
<ul id="S4.I3" class="ltx_itemize">
<li id="S4.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I3.i1.p1" class="ltx_para">
<p id="S4.I3.i1.p1.1" class="ltx_p">17.02% of the studies reported communication costs as the main challenge of FL.</p>
</div>
</li>
<li id="S4.I3.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I3.i2.p1" class="ltx_para">
<p id="S4.I3.i2.p1.1" class="ltx_p">Clients with low power or slow will lead to long convergence time. As FL is done synchronously, this implies that the learning is as fast as the slowest client.</p>
</div>
</li>
<li id="S4.I3.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I3.i3.p1" class="ltx_para">
<p id="S4.I3.i3.p1.1" class="ltx_p">The possibly long distance between clients and servers will result in increased bandwidth usage.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S4.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.5. </span>Fairness</h3>

<div id="S4.SS5.p1" class="ltx_para">
<p id="S4.SS5.p1.1" class="ltx_p">The last common problem encountered was fairness. Only three studies reported it as the main challenge which they tried to solve. However, fairness is a researched topic within several similar fields, such as Resource Allocation (RA) and ML. In the context of resource allocation, the problem is defined as allocating a scarce shared resource among many users. For machine learning, it is typically defined as the protection of some specific attribute(s) by, e.g., preprocessing the data to remove information about the protected attribute <cite class="ltx_cite ltx_citemacro_citep">(Feldman, <a href="#bib.bib14" title="" class="ltx_ref">2015</a>)</cite>.</p>
</div>
<div id="S4.SS5.p2" class="ltx_para">
<p id="S4.SS5.p2.1" class="ltx_p">In the context of FL, if the client selection algorithm always selects the fastest devices, it might boost the training process. However, as stated by <cite class="ltx_cite ltx_citemacro_citet">Huang et al<span class="ltx_text">.</span> (<a href="#bib.bib21" title="" class="ltx_ref">2021</a>)</cite> ” <span id="S4.SS5.p2.1.1" class="ltx_text ltx_font_italic">But clients with low priority are simply being deprived of chances to participate at the same time, which we refer to it as an unfair selection.</span>”
It might result in undesirable effects, such as omitting some portions of data. Also, if there are less data involved, data diversity will not be guaranteed and might hurt the performance of model training.
<cite class="ltx_cite ltx_citemacro_citet">Jee Cho et al<span class="ltx_text">.</span> (<a href="#bib.bib22" title="" class="ltx_ref">2020</a>)</cite> state that by focusing on improving fairness, the uniformity of performance across clients will be improved as well. <cite class="ltx_cite ltx_citemacro_citet">Li et al<span class="ltx_text">.</span> (<a href="#bib.bib30" title="" class="ltx_ref">2020b</a>)</cite> define fairness in FL as follows:</p>
</div>
<div id="S4.SS5.p3" class="ltx_para">
<blockquote id="S4.SS5.p3.5" class="ltx_quote">
<p id="S4.SS5.p3.5.5" class="ltx_p"><span id="S4.SS5.p3.5.5.1" class="ltx_text ltx_font_bold">Definition 1</span> <span id="S4.SS5.p3.5.5.2" class="ltx_text ltx_font_italic">(Fairness of performance distribution)</span>. For trained models <span id="S4.SS5.p3.5.5.3" class="ltx_text ltx_font_italic">w</span> and <math id="S4.SS5.p3.1.1.m1.1" class="ltx_Math" alttext="\tilde{w}" display="inline"><semantics id="S4.SS5.p3.1.1.m1.1a"><mover accent="true" id="S4.SS5.p3.1.1.m1.1.1" xref="S4.SS5.p3.1.1.m1.1.1.cmml"><mi id="S4.SS5.p3.1.1.m1.1.1.2" xref="S4.SS5.p3.1.1.m1.1.1.2.cmml">w</mi><mo id="S4.SS5.p3.1.1.m1.1.1.1" xref="S4.SS5.p3.1.1.m1.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="S4.SS5.p3.1.1.m1.1b"><apply id="S4.SS5.p3.1.1.m1.1.1.cmml" xref="S4.SS5.p3.1.1.m1.1.1"><ci id="S4.SS5.p3.1.1.m1.1.1.1.cmml" xref="S4.SS5.p3.1.1.m1.1.1.1">~</ci><ci id="S4.SS5.p3.1.1.m1.1.1.2.cmml" xref="S4.SS5.p3.1.1.m1.1.1.2">𝑤</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p3.1.1.m1.1c">\tilde{w}</annotation></semantics></math>,
<math id="S4.SS5.p3.2.2.m2.1" class="ltx_Math" alttext="w" display="inline"><semantics id="S4.SS5.p3.2.2.m2.1a"><mi id="S4.SS5.p3.2.2.m2.1.1" xref="S4.SS5.p3.2.2.m2.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="S4.SS5.p3.2.2.m2.1b"><ci id="S4.SS5.p3.2.2.m2.1.1.cmml" xref="S4.SS5.p3.2.2.m2.1.1">𝑤</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p3.2.2.m2.1c">w</annotation></semantics></math> provides a more fair solution to the federated learning objective (<a href="#S4.E1" title="In 4.5. Fairness ‣ 4. Research Results ‣ A Systematic Literature Review on Client Selection in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>) than model <math id="S4.SS5.p3.3.3.m3.1" class="ltx_Math" alttext="\tilde{w}" display="inline"><semantics id="S4.SS5.p3.3.3.m3.1a"><mover accent="true" id="S4.SS5.p3.3.3.m3.1.1" xref="S4.SS5.p3.3.3.m3.1.1.cmml"><mi id="S4.SS5.p3.3.3.m3.1.1.2" xref="S4.SS5.p3.3.3.m3.1.1.2.cmml">w</mi><mo id="S4.SS5.p3.3.3.m3.1.1.1" xref="S4.SS5.p3.3.3.m3.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="S4.SS5.p3.3.3.m3.1b"><apply id="S4.SS5.p3.3.3.m3.1.1.cmml" xref="S4.SS5.p3.3.3.m3.1.1"><ci id="S4.SS5.p3.3.3.m3.1.1.1.cmml" xref="S4.SS5.p3.3.3.m3.1.1.1">~</ci><ci id="S4.SS5.p3.3.3.m3.1.1.2.cmml" xref="S4.SS5.p3.3.3.m3.1.1.2">𝑤</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p3.3.3.m3.1c">\tilde{w}</annotation></semantics></math>, if the
performance of model <span id="S4.SS5.p3.5.5.4" class="ltx_text ltx_font_italic">w</span> on the <span id="S4.SS5.p3.5.5.5" class="ltx_text ltx_font_italic">m</span> devices, <math id="S4.SS5.p3.4.4.m4.3" class="ltx_Math" alttext="\{a1,\dots,a_{m}\}" display="inline"><semantics id="S4.SS5.p3.4.4.m4.3a"><mrow id="S4.SS5.p3.4.4.m4.3.3.2" xref="S4.SS5.p3.4.4.m4.3.3.3.cmml"><mo stretchy="false" id="S4.SS5.p3.4.4.m4.3.3.2.3" xref="S4.SS5.p3.4.4.m4.3.3.3.cmml">{</mo><mrow id="S4.SS5.p3.4.4.m4.2.2.1.1" xref="S4.SS5.p3.4.4.m4.2.2.1.1.cmml"><mi id="S4.SS5.p3.4.4.m4.2.2.1.1.2" xref="S4.SS5.p3.4.4.m4.2.2.1.1.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.SS5.p3.4.4.m4.2.2.1.1.1" xref="S4.SS5.p3.4.4.m4.2.2.1.1.1.cmml">​</mo><mn id="S4.SS5.p3.4.4.m4.2.2.1.1.3" xref="S4.SS5.p3.4.4.m4.2.2.1.1.3.cmml">1</mn></mrow><mo id="S4.SS5.p3.4.4.m4.3.3.2.4" xref="S4.SS5.p3.4.4.m4.3.3.3.cmml">,</mo><mi mathvariant="normal" id="S4.SS5.p3.4.4.m4.1.1" xref="S4.SS5.p3.4.4.m4.1.1.cmml">…</mi><mo id="S4.SS5.p3.4.4.m4.3.3.2.5" xref="S4.SS5.p3.4.4.m4.3.3.3.cmml">,</mo><msub id="S4.SS5.p3.4.4.m4.3.3.2.2" xref="S4.SS5.p3.4.4.m4.3.3.2.2.cmml"><mi id="S4.SS5.p3.4.4.m4.3.3.2.2.2" xref="S4.SS5.p3.4.4.m4.3.3.2.2.2.cmml">a</mi><mi id="S4.SS5.p3.4.4.m4.3.3.2.2.3" xref="S4.SS5.p3.4.4.m4.3.3.2.2.3.cmml">m</mi></msub><mo stretchy="false" id="S4.SS5.p3.4.4.m4.3.3.2.6" xref="S4.SS5.p3.4.4.m4.3.3.3.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS5.p3.4.4.m4.3b"><set id="S4.SS5.p3.4.4.m4.3.3.3.cmml" xref="S4.SS5.p3.4.4.m4.3.3.2"><apply id="S4.SS5.p3.4.4.m4.2.2.1.1.cmml" xref="S4.SS5.p3.4.4.m4.2.2.1.1"><times id="S4.SS5.p3.4.4.m4.2.2.1.1.1.cmml" xref="S4.SS5.p3.4.4.m4.2.2.1.1.1"></times><ci id="S4.SS5.p3.4.4.m4.2.2.1.1.2.cmml" xref="S4.SS5.p3.4.4.m4.2.2.1.1.2">𝑎</ci><cn type="integer" id="S4.SS5.p3.4.4.m4.2.2.1.1.3.cmml" xref="S4.SS5.p3.4.4.m4.2.2.1.1.3">1</cn></apply><ci id="S4.SS5.p3.4.4.m4.1.1.cmml" xref="S4.SS5.p3.4.4.m4.1.1">…</ci><apply id="S4.SS5.p3.4.4.m4.3.3.2.2.cmml" xref="S4.SS5.p3.4.4.m4.3.3.2.2"><csymbol cd="ambiguous" id="S4.SS5.p3.4.4.m4.3.3.2.2.1.cmml" xref="S4.SS5.p3.4.4.m4.3.3.2.2">subscript</csymbol><ci id="S4.SS5.p3.4.4.m4.3.3.2.2.2.cmml" xref="S4.SS5.p3.4.4.m4.3.3.2.2.2">𝑎</ci><ci id="S4.SS5.p3.4.4.m4.3.3.2.2.3.cmml" xref="S4.SS5.p3.4.4.m4.3.3.2.2.3">𝑚</ci></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p3.4.4.m4.3c">\{a1,\dots,a_{m}\}</annotation></semantics></math>, is more uniform than the performance of
model <math id="S4.SS5.p3.5.5.m5.1" class="ltx_Math" alttext="\tilde{w}" display="inline"><semantics id="S4.SS5.p3.5.5.m5.1a"><mover accent="true" id="S4.SS5.p3.5.5.m5.1.1" xref="S4.SS5.p3.5.5.m5.1.1.cmml"><mi id="S4.SS5.p3.5.5.m5.1.1.2" xref="S4.SS5.p3.5.5.m5.1.1.2.cmml">w</mi><mo id="S4.SS5.p3.5.5.m5.1.1.1" xref="S4.SS5.p3.5.5.m5.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="S4.SS5.p3.5.5.m5.1b"><apply id="S4.SS5.p3.5.5.m5.1.1.cmml" xref="S4.SS5.p3.5.5.m5.1.1"><ci id="S4.SS5.p3.5.5.m5.1.1.1.cmml" xref="S4.SS5.p3.5.5.m5.1.1.1">~</ci><ci id="S4.SS5.p3.5.5.m5.1.1.2.cmml" xref="S4.SS5.p3.5.5.m5.1.1.2">𝑤</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p3.5.5.m5.1c">\tilde{w}</annotation></semantics></math> on the <span id="S4.SS5.p3.5.5.6" class="ltx_text ltx_font_italic">m</span> devices.</p>
</blockquote>
</div>
<div id="S4.SS5.p4" class="ltx_para">
<blockquote id="S4.SS5.p4.4" class="ltx_quote">
<p id="S4.SS5.p4.1.1" class="ltx_p">Note: Decoupling is the main benefit of FL. The FL algorithms may involve hundreds to millions of remote devices learning locally by minimizing the objective function <math id="S4.SS5.p4.1.1.m1.1" class="ltx_Math" alttext="f(w)" display="inline"><semantics id="S4.SS5.p4.1.1.m1.1a"><mrow id="S4.SS5.p4.1.1.m1.1.2" xref="S4.SS5.p4.1.1.m1.1.2.cmml"><mi id="S4.SS5.p4.1.1.m1.1.2.2" xref="S4.SS5.p4.1.1.m1.1.2.2.cmml">f</mi><mo lspace="0em" rspace="0em" id="S4.SS5.p4.1.1.m1.1.2.1" xref="S4.SS5.p4.1.1.m1.1.2.1.cmml">​</mo><mrow id="S4.SS5.p4.1.1.m1.1.2.3.2" xref="S4.SS5.p4.1.1.m1.1.2.cmml"><mo stretchy="false" id="S4.SS5.p4.1.1.m1.1.2.3.2.1" xref="S4.SS5.p4.1.1.m1.1.2.cmml">(</mo><mi id="S4.SS5.p4.1.1.m1.1.1" xref="S4.SS5.p4.1.1.m1.1.1.cmml">w</mi><mo stretchy="false" id="S4.SS5.p4.1.1.m1.1.2.3.2.2" xref="S4.SS5.p4.1.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS5.p4.1.1.m1.1b"><apply id="S4.SS5.p4.1.1.m1.1.2.cmml" xref="S4.SS5.p4.1.1.m1.1.2"><times id="S4.SS5.p4.1.1.m1.1.2.1.cmml" xref="S4.SS5.p4.1.1.m1.1.2.1"></times><ci id="S4.SS5.p4.1.1.m1.1.2.2.cmml" xref="S4.SS5.p4.1.1.m1.1.2.2">𝑓</ci><ci id="S4.SS5.p4.1.1.m1.1.1.cmml" xref="S4.SS5.p4.1.1.m1.1.1">𝑤</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p4.1.1.m1.1c">f(w)</annotation></semantics></math> (1) <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib30" title="" class="ltx_ref">2020b</a>)</cite>:</p>
<table id="S4.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(1)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E1.m1.2" class="ltx_Math" alttext="\textrm{min}_{w}f(w)=\sum_{k=1}^{m}p_{k}F_{k}(w)" display="block"><semantics id="S4.E1.m1.2a"><mrow id="S4.E1.m1.2.3" xref="S4.E1.m1.2.3.cmml"><mrow id="S4.E1.m1.2.3.2" xref="S4.E1.m1.2.3.2.cmml"><msub id="S4.E1.m1.2.3.2.2" xref="S4.E1.m1.2.3.2.2.cmml"><mtext id="S4.E1.m1.2.3.2.2.2" xref="S4.E1.m1.2.3.2.2.2a.cmml">min</mtext><mi id="S4.E1.m1.2.3.2.2.3" xref="S4.E1.m1.2.3.2.2.3.cmml">w</mi></msub><mo lspace="0em" rspace="0em" id="S4.E1.m1.2.3.2.1" xref="S4.E1.m1.2.3.2.1.cmml">​</mo><mi id="S4.E1.m1.2.3.2.3" xref="S4.E1.m1.2.3.2.3.cmml">f</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.2.3.2.1a" xref="S4.E1.m1.2.3.2.1.cmml">​</mo><mrow id="S4.E1.m1.2.3.2.4.2" xref="S4.E1.m1.2.3.2.cmml"><mo stretchy="false" id="S4.E1.m1.2.3.2.4.2.1" xref="S4.E1.m1.2.3.2.cmml">(</mo><mi id="S4.E1.m1.1.1" xref="S4.E1.m1.1.1.cmml">w</mi><mo stretchy="false" id="S4.E1.m1.2.3.2.4.2.2" xref="S4.E1.m1.2.3.2.cmml">)</mo></mrow></mrow><mo rspace="0.111em" id="S4.E1.m1.2.3.1" xref="S4.E1.m1.2.3.1.cmml">=</mo><mrow id="S4.E1.m1.2.3.3" xref="S4.E1.m1.2.3.3.cmml"><munderover id="S4.E1.m1.2.3.3.1" xref="S4.E1.m1.2.3.3.1.cmml"><mo movablelimits="false" id="S4.E1.m1.2.3.3.1.2.2" xref="S4.E1.m1.2.3.3.1.2.2.cmml">∑</mo><mrow id="S4.E1.m1.2.3.3.1.2.3" xref="S4.E1.m1.2.3.3.1.2.3.cmml"><mi id="S4.E1.m1.2.3.3.1.2.3.2" xref="S4.E1.m1.2.3.3.1.2.3.2.cmml">k</mi><mo id="S4.E1.m1.2.3.3.1.2.3.1" xref="S4.E1.m1.2.3.3.1.2.3.1.cmml">=</mo><mn id="S4.E1.m1.2.3.3.1.2.3.3" xref="S4.E1.m1.2.3.3.1.2.3.3.cmml">1</mn></mrow><mi id="S4.E1.m1.2.3.3.1.3" xref="S4.E1.m1.2.3.3.1.3.cmml">m</mi></munderover><mrow id="S4.E1.m1.2.3.3.2" xref="S4.E1.m1.2.3.3.2.cmml"><msub id="S4.E1.m1.2.3.3.2.2" xref="S4.E1.m1.2.3.3.2.2.cmml"><mi id="S4.E1.m1.2.3.3.2.2.2" xref="S4.E1.m1.2.3.3.2.2.2.cmml">p</mi><mi id="S4.E1.m1.2.3.3.2.2.3" xref="S4.E1.m1.2.3.3.2.2.3.cmml">k</mi></msub><mo lspace="0em" rspace="0em" id="S4.E1.m1.2.3.3.2.1" xref="S4.E1.m1.2.3.3.2.1.cmml">​</mo><msub id="S4.E1.m1.2.3.3.2.3" xref="S4.E1.m1.2.3.3.2.3.cmml"><mi id="S4.E1.m1.2.3.3.2.3.2" xref="S4.E1.m1.2.3.3.2.3.2.cmml">F</mi><mi id="S4.E1.m1.2.3.3.2.3.3" xref="S4.E1.m1.2.3.3.2.3.3.cmml">k</mi></msub><mo lspace="0em" rspace="0em" id="S4.E1.m1.2.3.3.2.1a" xref="S4.E1.m1.2.3.3.2.1.cmml">​</mo><mrow id="S4.E1.m1.2.3.3.2.4.2" xref="S4.E1.m1.2.3.3.2.cmml"><mo stretchy="false" id="S4.E1.m1.2.3.3.2.4.2.1" xref="S4.E1.m1.2.3.3.2.cmml">(</mo><mi id="S4.E1.m1.2.2" xref="S4.E1.m1.2.2.cmml">w</mi><mo stretchy="false" id="S4.E1.m1.2.3.3.2.4.2.2" xref="S4.E1.m1.2.3.3.2.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E1.m1.2b"><apply id="S4.E1.m1.2.3.cmml" xref="S4.E1.m1.2.3"><eq id="S4.E1.m1.2.3.1.cmml" xref="S4.E1.m1.2.3.1"></eq><apply id="S4.E1.m1.2.3.2.cmml" xref="S4.E1.m1.2.3.2"><times id="S4.E1.m1.2.3.2.1.cmml" xref="S4.E1.m1.2.3.2.1"></times><apply id="S4.E1.m1.2.3.2.2.cmml" xref="S4.E1.m1.2.3.2.2"><csymbol cd="ambiguous" id="S4.E1.m1.2.3.2.2.1.cmml" xref="S4.E1.m1.2.3.2.2">subscript</csymbol><ci id="S4.E1.m1.2.3.2.2.2a.cmml" xref="S4.E1.m1.2.3.2.2.2"><mtext id="S4.E1.m1.2.3.2.2.2.cmml" xref="S4.E1.m1.2.3.2.2.2">min</mtext></ci><ci id="S4.E1.m1.2.3.2.2.3.cmml" xref="S4.E1.m1.2.3.2.2.3">𝑤</ci></apply><ci id="S4.E1.m1.2.3.2.3.cmml" xref="S4.E1.m1.2.3.2.3">𝑓</ci><ci id="S4.E1.m1.1.1.cmml" xref="S4.E1.m1.1.1">𝑤</ci></apply><apply id="S4.E1.m1.2.3.3.cmml" xref="S4.E1.m1.2.3.3"><apply id="S4.E1.m1.2.3.3.1.cmml" xref="S4.E1.m1.2.3.3.1"><csymbol cd="ambiguous" id="S4.E1.m1.2.3.3.1.1.cmml" xref="S4.E1.m1.2.3.3.1">superscript</csymbol><apply id="S4.E1.m1.2.3.3.1.2.cmml" xref="S4.E1.m1.2.3.3.1"><csymbol cd="ambiguous" id="S4.E1.m1.2.3.3.1.2.1.cmml" xref="S4.E1.m1.2.3.3.1">subscript</csymbol><sum id="S4.E1.m1.2.3.3.1.2.2.cmml" xref="S4.E1.m1.2.3.3.1.2.2"></sum><apply id="S4.E1.m1.2.3.3.1.2.3.cmml" xref="S4.E1.m1.2.3.3.1.2.3"><eq id="S4.E1.m1.2.3.3.1.2.3.1.cmml" xref="S4.E1.m1.2.3.3.1.2.3.1"></eq><ci id="S4.E1.m1.2.3.3.1.2.3.2.cmml" xref="S4.E1.m1.2.3.3.1.2.3.2">𝑘</ci><cn type="integer" id="S4.E1.m1.2.3.3.1.2.3.3.cmml" xref="S4.E1.m1.2.3.3.1.2.3.3">1</cn></apply></apply><ci id="S4.E1.m1.2.3.3.1.3.cmml" xref="S4.E1.m1.2.3.3.1.3">𝑚</ci></apply><apply id="S4.E1.m1.2.3.3.2.cmml" xref="S4.E1.m1.2.3.3.2"><times id="S4.E1.m1.2.3.3.2.1.cmml" xref="S4.E1.m1.2.3.3.2.1"></times><apply id="S4.E1.m1.2.3.3.2.2.cmml" xref="S4.E1.m1.2.3.3.2.2"><csymbol cd="ambiguous" id="S4.E1.m1.2.3.3.2.2.1.cmml" xref="S4.E1.m1.2.3.3.2.2">subscript</csymbol><ci id="S4.E1.m1.2.3.3.2.2.2.cmml" xref="S4.E1.m1.2.3.3.2.2.2">𝑝</ci><ci id="S4.E1.m1.2.3.3.2.2.3.cmml" xref="S4.E1.m1.2.3.3.2.2.3">𝑘</ci></apply><apply id="S4.E1.m1.2.3.3.2.3.cmml" xref="S4.E1.m1.2.3.3.2.3"><csymbol cd="ambiguous" id="S4.E1.m1.2.3.3.2.3.1.cmml" xref="S4.E1.m1.2.3.3.2.3">subscript</csymbol><ci id="S4.E1.m1.2.3.3.2.3.2.cmml" xref="S4.E1.m1.2.3.3.2.3.2">𝐹</ci><ci id="S4.E1.m1.2.3.3.2.3.3.cmml" xref="S4.E1.m1.2.3.3.2.3.3">𝑘</ci></apply><ci id="S4.E1.m1.2.2.cmml" xref="S4.E1.m1.2.2">𝑤</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E1.m1.2c">\textrm{min}_{w}f(w)=\sum_{k=1}^{m}p_{k}F_{k}(w)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S4.SS5.p4.4.4" class="ltx_p">where <span id="S4.SS5.p4.4.4.1" class="ltx_text ltx_font_italic">m</span> is the total number of devices, <math id="S4.SS5.p4.2.2.m1.1" class="ltx_Math" alttext="p_{k}\geq 0" display="inline"><semantics id="S4.SS5.p4.2.2.m1.1a"><mrow id="S4.SS5.p4.2.2.m1.1.1" xref="S4.SS5.p4.2.2.m1.1.1.cmml"><msub id="S4.SS5.p4.2.2.m1.1.1.2" xref="S4.SS5.p4.2.2.m1.1.1.2.cmml"><mi id="S4.SS5.p4.2.2.m1.1.1.2.2" xref="S4.SS5.p4.2.2.m1.1.1.2.2.cmml">p</mi><mi id="S4.SS5.p4.2.2.m1.1.1.2.3" xref="S4.SS5.p4.2.2.m1.1.1.2.3.cmml">k</mi></msub><mo id="S4.SS5.p4.2.2.m1.1.1.1" xref="S4.SS5.p4.2.2.m1.1.1.1.cmml">≥</mo><mn id="S4.SS5.p4.2.2.m1.1.1.3" xref="S4.SS5.p4.2.2.m1.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS5.p4.2.2.m1.1b"><apply id="S4.SS5.p4.2.2.m1.1.1.cmml" xref="S4.SS5.p4.2.2.m1.1.1"><geq id="S4.SS5.p4.2.2.m1.1.1.1.cmml" xref="S4.SS5.p4.2.2.m1.1.1.1"></geq><apply id="S4.SS5.p4.2.2.m1.1.1.2.cmml" xref="S4.SS5.p4.2.2.m1.1.1.2"><csymbol cd="ambiguous" id="S4.SS5.p4.2.2.m1.1.1.2.1.cmml" xref="S4.SS5.p4.2.2.m1.1.1.2">subscript</csymbol><ci id="S4.SS5.p4.2.2.m1.1.1.2.2.cmml" xref="S4.SS5.p4.2.2.m1.1.1.2.2">𝑝</ci><ci id="S4.SS5.p4.2.2.m1.1.1.2.3.cmml" xref="S4.SS5.p4.2.2.m1.1.1.2.3">𝑘</ci></apply><cn type="integer" id="S4.SS5.p4.2.2.m1.1.1.3.cmml" xref="S4.SS5.p4.2.2.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p4.2.2.m1.1c">p_{k}\geq 0</annotation></semantics></math>, <math id="S4.SS5.p4.3.3.m2.1" class="ltx_Math" alttext="\sum_{k}p_{k}=1" display="inline"><semantics id="S4.SS5.p4.3.3.m2.1a"><mrow id="S4.SS5.p4.3.3.m2.1.1" xref="S4.SS5.p4.3.3.m2.1.1.cmml"><mrow id="S4.SS5.p4.3.3.m2.1.1.2" xref="S4.SS5.p4.3.3.m2.1.1.2.cmml"><msub id="S4.SS5.p4.3.3.m2.1.1.2.1" xref="S4.SS5.p4.3.3.m2.1.1.2.1.cmml"><mo id="S4.SS5.p4.3.3.m2.1.1.2.1.2" xref="S4.SS5.p4.3.3.m2.1.1.2.1.2.cmml">∑</mo><mi id="S4.SS5.p4.3.3.m2.1.1.2.1.3" xref="S4.SS5.p4.3.3.m2.1.1.2.1.3.cmml">k</mi></msub><msub id="S4.SS5.p4.3.3.m2.1.1.2.2" xref="S4.SS5.p4.3.3.m2.1.1.2.2.cmml"><mi id="S4.SS5.p4.3.3.m2.1.1.2.2.2" xref="S4.SS5.p4.3.3.m2.1.1.2.2.2.cmml">p</mi><mi id="S4.SS5.p4.3.3.m2.1.1.2.2.3" xref="S4.SS5.p4.3.3.m2.1.1.2.2.3.cmml">k</mi></msub></mrow><mo id="S4.SS5.p4.3.3.m2.1.1.1" xref="S4.SS5.p4.3.3.m2.1.1.1.cmml">=</mo><mn id="S4.SS5.p4.3.3.m2.1.1.3" xref="S4.SS5.p4.3.3.m2.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS5.p4.3.3.m2.1b"><apply id="S4.SS5.p4.3.3.m2.1.1.cmml" xref="S4.SS5.p4.3.3.m2.1.1"><eq id="S4.SS5.p4.3.3.m2.1.1.1.cmml" xref="S4.SS5.p4.3.3.m2.1.1.1"></eq><apply id="S4.SS5.p4.3.3.m2.1.1.2.cmml" xref="S4.SS5.p4.3.3.m2.1.1.2"><apply id="S4.SS5.p4.3.3.m2.1.1.2.1.cmml" xref="S4.SS5.p4.3.3.m2.1.1.2.1"><csymbol cd="ambiguous" id="S4.SS5.p4.3.3.m2.1.1.2.1.1.cmml" xref="S4.SS5.p4.3.3.m2.1.1.2.1">subscript</csymbol><sum id="S4.SS5.p4.3.3.m2.1.1.2.1.2.cmml" xref="S4.SS5.p4.3.3.m2.1.1.2.1.2"></sum><ci id="S4.SS5.p4.3.3.m2.1.1.2.1.3.cmml" xref="S4.SS5.p4.3.3.m2.1.1.2.1.3">𝑘</ci></apply><apply id="S4.SS5.p4.3.3.m2.1.1.2.2.cmml" xref="S4.SS5.p4.3.3.m2.1.1.2.2"><csymbol cd="ambiguous" id="S4.SS5.p4.3.3.m2.1.1.2.2.1.cmml" xref="S4.SS5.p4.3.3.m2.1.1.2.2">subscript</csymbol><ci id="S4.SS5.p4.3.3.m2.1.1.2.2.2.cmml" xref="S4.SS5.p4.3.3.m2.1.1.2.2.2">𝑝</ci><ci id="S4.SS5.p4.3.3.m2.1.1.2.2.3.cmml" xref="S4.SS5.p4.3.3.m2.1.1.2.2.3">𝑘</ci></apply></apply><cn type="integer" id="S4.SS5.p4.3.3.m2.1.1.3.cmml" xref="S4.SS5.p4.3.3.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p4.3.3.m2.1c">\sum_{k}p_{k}=1</annotation></semantics></math>, and the local objective <math id="S4.SS5.p4.4.4.m3.1" class="ltx_Math" alttext="F_{k}" display="inline"><semantics id="S4.SS5.p4.4.4.m3.1a"><msub id="S4.SS5.p4.4.4.m3.1.1" xref="S4.SS5.p4.4.4.m3.1.1.cmml"><mi id="S4.SS5.p4.4.4.m3.1.1.2" xref="S4.SS5.p4.4.4.m3.1.1.2.cmml">F</mi><mi id="S4.SS5.p4.4.4.m3.1.1.3" xref="S4.SS5.p4.4.4.m3.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS5.p4.4.4.m3.1b"><apply id="S4.SS5.p4.4.4.m3.1.1.cmml" xref="S4.SS5.p4.4.4.m3.1.1"><csymbol cd="ambiguous" id="S4.SS5.p4.4.4.m3.1.1.1.cmml" xref="S4.SS5.p4.4.4.m3.1.1">subscript</csymbol><ci id="S4.SS5.p4.4.4.m3.1.1.2.cmml" xref="S4.SS5.p4.4.4.m3.1.1.2">𝐹</ci><ci id="S4.SS5.p4.4.4.m3.1.1.3.cmml" xref="S4.SS5.p4.4.4.m3.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p4.4.4.m3.1c">F_{k}</annotation></semantics></math>’s can be defined by empirical risks over local data.</p>
</blockquote>
</div>
<div id="S4.SS5.p5" class="ltx_para">
<p id="S4.SS5.p5.1" class="ltx_p">Through this definition, it becomes apparent that learned models which might be biased towards devices with large numbers of data points or commonly occurring devices are unfair.</p>
</div>
<div id="S4.SS5.p6" class="ltx_para">
<p id="S4.SS5.p6.1" class="ltx_p">According to <cite class="ltx_cite ltx_citemacro_citet">Ma et al<span class="ltx_text">.</span> (<a href="#bib.bib38" title="" class="ltx_ref">2022</a>)</cite>, differences in data distribution and uncertainty in data quality are challenging in FL and data selection might exacerbate the unfairness of FL.
There are several different methods for prioritizing clients. If one selects all the ”fast” devices, it might result in faster training but will deprive slower clients of the chance to participate. If the selection is one-sided, it will bring negative side effects, such as neutralizing some portions of data <cite class="ltx_cite ltx_citemacro_citep">(Huang et al<span class="ltx_text">.</span>, <a href="#bib.bib21" title="" class="ltx_ref">2021</a>)</cite>. In addition, clients may not provide honest results through various attacks, such as Byzantine attacks, which minimizes the effect of actual results of honest clients and reduces fairness <cite class="ltx_cite ltx_citemacro_citep">(Wan et al<span class="ltx_text">.</span>, <a href="#bib.bib51" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
<div id="S4.SS5.p7" class="ltx_para">
<p id="S4.SS5.p7.1" class="ltx_p">To summarize, the key findings for the challenge of fairness are as follows.</p>
<ul id="S4.I4" class="ltx_itemize">
<li id="S4.I4.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I4.i1.p1" class="ltx_para">
<p id="S4.I4.i1.p1.1" class="ltx_p">6.38% of the studies reported fairness as the main challenge of FL.</p>
</div>
</li>
<li id="S4.I4.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I4.i2.p1" class="ltx_para">
<p id="S4.I4.i2.p1.1" class="ltx_p">Selecting only the fastest clients might result in an unfair selection, as slower clients are deprived of the chance to participate.</p>
</div>
</li>
<li id="S4.I4.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I4.i3.p1" class="ltx_para">
<p id="S4.I4.i3.p1.1" class="ltx_p">An unfair selection might lead to heavy biases as some portions of the data are neutralized.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S4.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.6. </span>RQ2: How are clients selected in federated learning</h3>

<div id="S4.SS6.p1" class="ltx_para">
<p id="S4.SS6.p1.1" class="ltx_p">The different solutions are presented in this subsection and divided into their respective challenges. A summary of the findings is shown in Table <a href="#S4.T2" title="Table 2 ‣ 4.6.4. Fairness ‣ 4.6. RQ2: How are clients selected in federated learning ‣ 4. Research Results ‣ A Systematic Literature Review on Client Selection in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<section id="S4.SS6.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.6.1. </span>Heterogeneity</h4>

<div id="S4.SS6.SSS1.p1" class="ltx_para">
<p id="S4.SS6.SSS1.p1.1" class="ltx_p">The most common approach to address this issue is to try to select a subset of clients who together give a more homogenous dataset <cite class="ltx_cite ltx_citemacro_citep">(Cho et al<span class="ltx_text">.</span>, <a href="#bib.bib11" title="" class="ltx_ref">2022</a>)</cite>. <cite class="ltx_cite ltx_citemacro_citet">Ma et al<span class="ltx_text">.</span> (<a href="#bib.bib38" title="" class="ltx_ref">2022</a>)</cite> performed a state-of-the-art survey on solving non-IID data in FL and mentioned <cite class="ltx_cite ltx_citemacro_citep">(Wang and Kantarci, <a href="#bib.bib52" title="" class="ltx_ref">2020</a>)</cite> as a possible solution through client selection.
They proposed selecting clients with small data heterogeneity based on Thompson sampling. <cite class="ltx_cite ltx_citemacro_citet">Abdulrahman et al<span class="ltx_text">.</span> (<a href="#bib.bib2" title="" class="ltx_ref">2021</a>)</cite> suggested a similar algorithm of selecting a subset of clients who together form a homogeneous subset. <cite class="ltx_cite ltx_citemacro_citet">Zhang et al<span class="ltx_text">.</span> (<a href="#bib.bib61" title="" class="ltx_ref">2021b</a>)</cite> proposed to measure the degrees of non-IID data present in each client and then select the clients with the lowest degrees. <cite class="ltx_cite ltx_citemacro_citet">Li et al<span class="ltx_text">.</span> (<a href="#bib.bib27" title="" class="ltx_ref">2022b</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citet">Saha et al<span class="ltx_text">.</span> (<a href="#bib.bib46" title="" class="ltx_ref">2022</a>)</cite> had similar ideas but suggested a more holistic approach by also including the system heterogeneity (e.g., resources) as well. <cite class="ltx_cite ltx_citemacro_citet">Lin et al<span class="ltx_text">.</span> (<a href="#bib.bib32" title="" class="ltx_ref">2022</a>)</cite> propose to dynamically update the selection weights according to the impact of the client’s data.</p>
</div>
<div id="S4.SS6.SSS1.p2" class="ltx_para">
<p id="S4.SS6.SSS1.p2.1" class="ltx_p">Clustered Federated Learning (CFL) was introduced as an efficient scheme to balance out the non-IID data, and <cite class="ltx_cite ltx_citemacro_citet">Albaseer et al<span class="ltx_text">.</span> (<a href="#bib.bib4" title="" class="ltx_ref">2021</a>)</cite> suggest leveraging the devices’ heterogeneity to schedule them based on round latency and bandwidth to select clients. According to <cite class="ltx_cite ltx_citemacro_citet">Li et al<span class="ltx_text">.</span> (<a href="#bib.bib31" title="" class="ltx_ref">2022a</a>)</cite>, this type of approach works well within IoT due to the advantage of naturally clustered factory devices.
<cite class="ltx_cite ltx_citemacro_citet">Lee et al<span class="ltx_text">.</span> (<a href="#bib.bib26" title="" class="ltx_ref">2022</a>)</cite> also find clusters of clients who together have near IID data through being distribution-aware.
In order to address the issue of label distribution skew, <cite class="ltx_cite ltx_citemacro_citet">Ma et al<span class="ltx_text">.</span> (<a href="#bib.bib37" title="" class="ltx_ref">2021</a>)</cite> suggested a method where you check the similarity between the aggregated data distribution of the selected clients and compare it to the global data distribution. <cite class="ltx_cite ltx_citemacro_citet">Rai et al<span class="ltx_text">.</span> (<a href="#bib.bib45" title="" class="ltx_ref">2022</a>)</cite> suggest giving each client an irrelevance score which improves the data distribution skewness. <cite class="ltx_cite ltx_citemacro_citet">Cao et al<span class="ltx_text">.</span> (<a href="#bib.bib10" title="" class="ltx_ref">2022</a>)</cite> have an interesting approach to clustering clients by grouping them according to classes of data and then randomly selecting one client within every group. Another promising approach suggested by <cite class="ltx_cite ltx_citemacro_citet">Balakrishnan et al<span class="ltx_text">.</span> (<a href="#bib.bib9" title="" class="ltx_ref">2022</a>)</cite> is to introduce diversity into client selection by measuring how a subset of clients can represent the whole when aggregated on the server for each communication round.</p>
</div>
<div id="S4.SS6.SSS1.p3" class="ltx_para">
<p id="S4.SS6.SSS1.p3.1" class="ltx_p">Generally, the studies try to keep an unbiased client selection in order to promote fairness. However, <cite class="ltx_cite ltx_citemacro_citet">Cho et al<span class="ltx_text">.</span> (<a href="#bib.bib11" title="" class="ltx_ref">2022</a>)</cite> report that biasing the client selection towards choosing clients with higher local losses resulted in an improvement in the partial client participation problem. <cite class="ltx_cite ltx_citemacro_citet">Abdulrahman et al<span class="ltx_text">.</span> (<a href="#bib.bib2" title="" class="ltx_ref">2021</a>)</cite> suggested another approach to the same problem but suggested a multicriteria-based approach to predict if they were capable of performing the FL task.</p>
</div>
<div id="S4.SS6.SSS1.p4" class="ltx_para">
<p id="S4.SS6.SSS1.p4.1" class="ltx_p">Other studies, such as <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al<span class="ltx_text">.</span>, <a href="#bib.bib60" title="" class="ltx_ref">2021a</a>)</cite>, suggest strengthening client selection with cryptographic methods such as homomorphic encryption (HE).
<cite class="ltx_cite ltx_citemacro_citet">Pang et al<span class="ltx_text">.</span> (<a href="#bib.bib42" title="" class="ltx_ref">2022</a>)</cite> bring forward the idea of selecting clients at different global iterations to guarantee the completion of the FL job. Lastly, <cite class="ltx_cite ltx_citemacro_citet">Guo et al<span class="ltx_text">.</span> (<a href="#bib.bib15" title="" class="ltx_ref">2021</a>)</cite> take into account both model weight divergence and local model training loss for selecting clients.</p>
</div>
</section>
<section id="S4.SS6.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.6.2. </span>Resource Allocation</h4>

<div id="S4.SS6.SSS2.p1" class="ltx_para">
<p id="S4.SS6.SSS2.p1.1" class="ltx_p">In order to improve the effect of some clients having limited resources, <cite class="ltx_cite ltx_citemacro_citet">Nishio and Yonetani (<a href="#bib.bib41" title="" class="ltx_ref">2019</a>)</cite> suggest an algorithm that manages clients based on their resource conditions. Thus, allowing as many client updates as possible. <cite class="ltx_cite ltx_citemacro_citet">Xu and Wang (<a href="#bib.bib55" title="" class="ltx_ref">2021</a>)</cite> create an algorithm that utilizes bandwidth allocation under long-term client energy constraints by using available wireless channel information in order to improve resource allocation. To deal with the resource allocation problem, <cite class="ltx_cite ltx_citemacro_citet">Yu et al<span class="ltx_text">.</span> (<a href="#bib.bib57" title="" class="ltx_ref">2022</a>)</cite> suggest maximizing the number of clients while minimizing the energy consumption by the clients by allocating a set amount of resources in terms of CPU and transmission power.</p>
</div>
<div id="S4.SS6.SSS2.p2" class="ltx_para">
<p id="S4.SS6.SSS2.p2.1" class="ltx_p">Within HFL, <cite class="ltx_cite ltx_citemacro_citet">Qu et al<span class="ltx_text">.</span> (<a href="#bib.bib44" title="" class="ltx_ref">2022</a>)</cite> propose a client selection scheme with a network operator that learns the number of successful participating clients while dealing with a limited resource budget. Similarly, <cite class="ltx_cite ltx_citemacro_citep">(Deng et al<span class="ltx_text">.</span>, <a href="#bib.bib12" title="" class="ltx_ref">2022</a>; Kuang et al<span class="ltx_text">.</span>, <a href="#bib.bib25" title="" class="ltx_ref">2021</a>; Liu et al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2022</a>)</cite> suggested evaluating the learning quality of clients on a limited resource budget and then selecting the best clients. <cite class="ltx_cite ltx_citemacro_citet">Shi et al<span class="ltx_text">.</span> (<a href="#bib.bib48" title="" class="ltx_ref">2022</a>)</cite> suggest that clients should be selected by considering and quantifying factors such as the relative impact of clients’ data and resource differences and then selecting the clients with the most significant score.</p>
</div>
<div id="S4.SS6.SSS2.p3" class="ltx_para">
<p id="S4.SS6.SSS2.p3.1" class="ltx_p">Another method to deal with resource allocation is to focus on minimizing energy consumption and training delays in order to encourage more clients to participate in model updating. This may be done through reinforcement learning that learns to select the best subset of clients <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al<span class="ltx_text">.</span>, <a href="#bib.bib59" title="" class="ltx_ref">2021c</a>)</cite>. <cite class="ltx_cite ltx_citemacro_citet">Du et al<span class="ltx_text">.</span> (<a href="#bib.bib13" title="" class="ltx_ref">2022</a>)</cite> propose an algorithm that utilizes fuzzy logic by considering the number of local data, computing capability, and network resources of each client.</p>
</div>
</section>
<section id="S4.SS6.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.6.3. </span>Communication Costs</h4>

<div id="S4.SS6.SSS3.p1" class="ltx_para">
<p id="S4.SS6.SSS3.p1.1" class="ltx_p">As communication cost is a vital challenge in FL, many attempts have been executed in order to improve it.
<cite class="ltx_cite ltx_citemacro_citet">Ko et al<span class="ltx_text">.</span> (<a href="#bib.bib24" title="" class="ltx_ref">2021</a>)</cite> developed a joint client selection algorithm that selects appropriate devices and allocates suitable amounts of resources to reduce convergence time due to high communication costs.
<cite class="ltx_cite ltx_citemacro_citet">Hosseinzadeh et al<span class="ltx_text">.</span> (<a href="#bib.bib18" title="" class="ltx_ref">2022b</a>)</cite> suggested a distributed client selection algorithm where the client devices participate in aggregation, resulting in lower communication costs while maintaining the low loss. <cite class="ltx_cite ltx_citemacro_citet">Li et al<span class="ltx_text">.</span> (<a href="#bib.bib28" title="" class="ltx_ref">2022c</a>)</cite> had a similar approach where they selected a subset of clients to participate in each round of training, and the remaining clients did not have to do any training, resulting in both lower computing and communication resources.</p>
</div>
<div id="S4.SS6.SSS3.p2" class="ltx_para">
<p id="S4.SS6.SSS3.p2.1" class="ltx_p">Another proposed solution is proposed by <cite class="ltx_cite ltx_citemacro_citet">Asad et al<span class="ltx_text">.</span> (<a href="#bib.bib8" title="" class="ltx_ref">2022</a>)</cite>, where there is a 3-way hierarchical framework to improve communication efficiency. It creates a cluster head that is responsible for communication with the global server, and local devices communicate with the cluster head. This will lead to model downloading and uploading requiring less bandwidth due to the short distances from the source to the destination. To tackle the energy consumption challenge, <cite class="ltx_cite ltx_citemacro_citet">Zeng et al<span class="ltx_text">.</span> (<a href="#bib.bib58" title="" class="ltx_ref">2020</a>)</cite> suggested only selecting the clients who provide significant information with each round. This would enable them to select fewer clients and end up with lower total energy consumption. In order to omit the ”straggler effect” introduced through synchronous FL, <cite class="ltx_cite ltx_citemacro_citet">Zhu et al<span class="ltx_text">.</span> (<a href="#bib.bib62" title="" class="ltx_ref">2022</a>)</cite> suggest an asynchronous approach where the server did not have to wait for all clients to be finished with their training. <cite class="ltx_cite ltx_citemacro_citet">Tan et al<span class="ltx_text">.</span> (<a href="#bib.bib49" title="" class="ltx_ref">2022</a>)</cite> proposed to utilize stochastic integer programming that selects clients in a reputation-aware manner.</p>
</div>
</section>
<section id="S4.SS6.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.6.4. </span>Fairness</h4>

<div id="S4.SS6.SSS4.p1" class="ltx_para">
<p id="S4.SS6.SSS4.p1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citet">Huang et al<span class="ltx_text">.</span> (<a href="#bib.bib21" title="" class="ltx_ref">2021</a>)</cite> promote a fairness-guaranteed client selection algorithm. They conclude that the final accuracy may increase by focusing on fairness but might sacrifice training efficiency. Whereas <cite class="ltx_cite ltx_citemacro_citet">Jee Cho et al<span class="ltx_text">.</span> (<a href="#bib.bib22" title="" class="ltx_ref">2020</a>)</cite> suggest improving fairness through biased client selection by selecting the ones with higher local loss.
<cite class="ltx_cite ltx_citemacro_citet">Wan et al<span class="ltx_text">.</span> (<a href="#bib.bib51" title="" class="ltx_ref">2022</a>)</cite> propose to select the most honest and useful clients by utilizing a multi-armed bandit approach, resulting in dishonest clients being filtered out.</p>
</div>
<figure id="S4.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2. </span>Solutions compared to challenges</figcaption>
<table id="S4.T2.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T2.1.1.1" class="ltx_tr">
<th id="S4.T2.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r"><span id="S4.T2.1.1.1.1.1" class="ltx_text ltx_font_bold">Challenge</span></th>
<th id="S4.T2.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S4.T2.1.1.1.2.1" class="ltx_text ltx_font_bold">Solution(s)</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T2.1.2.1" class="ltx_tr">
<th id="S4.T2.1.2.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">Heterogeneity</th>
<td id="S4.T2.1.2.1.2" class="ltx_td ltx_align_left ltx_border_t">
<table id="S4.T2.1.2.1.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T2.1.2.1.2.1.1" class="ltx_tr">
<td id="S4.T2.1.2.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">- Select subset of client to make up homogeneous dataset</td>
</tr>
<tr id="S4.T2.1.2.1.2.1.2" class="ltx_tr">
<td id="S4.T2.1.2.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">- Measure degrees of non-IID data and select lowest values</td>
</tr>
<tr id="S4.T2.1.2.1.2.1.3" class="ltx_tr">
<td id="S4.T2.1.2.1.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">- Balance out non-IID data through clustered FL</td>
</tr>
<tr id="S4.T2.1.2.1.2.1.4" class="ltx_tr">
<td id="S4.T2.1.2.1.2.1.4.1" class="ltx_td ltx_nopad_r ltx_align_left">- Give clients an irrelevance score and base selection of that</td>
</tr>
<tr id="S4.T2.1.2.1.2.1.5" class="ltx_tr">
<td id="S4.T2.1.2.1.2.1.5.1" class="ltx_td ltx_nopad_r ltx_align_left">- Select a subset of clients who represent the entire set</td>
</tr>
<tr id="S4.T2.1.2.1.2.1.6" class="ltx_tr">
<td id="S4.T2.1.2.1.2.1.6.1" class="ltx_td ltx_nopad_r ltx_align_left">- Utilize cryptography and weight divergence</td>
</tr>
</table>
</td>
</tr>
<tr id="S4.T2.1.3.2" class="ltx_tr">
<th id="S4.T2.1.3.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">Resource Allocation</th>
<td id="S4.T2.1.3.2.2" class="ltx_td ltx_align_left ltx_border_t">
<table id="S4.T2.1.3.2.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T2.1.3.2.2.1.1" class="ltx_tr">
<td id="S4.T2.1.3.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">- Base selection on resource conditions</td>
</tr>
<tr id="S4.T2.1.3.2.2.1.2" class="ltx_tr">
<td id="S4.T2.1.3.2.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">- Maximize the amount of clients by minimizing energy consumption</td>
</tr>
<tr id="S4.T2.1.3.2.2.1.3" class="ltx_tr">
<td id="S4.T2.1.3.2.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">- Encourage clients to participate in model updating</td>
</tr>
<tr id="S4.T2.1.3.2.2.1.4" class="ltx_tr">
<td id="S4.T2.1.3.2.2.1.4.1" class="ltx_td ltx_nopad_r ltx_align_left">- Utilize fuzzy logic by considering several resource factors</td>
</tr>
</table>
</td>
</tr>
<tr id="S4.T2.1.4.3" class="ltx_tr">
<th id="S4.T2.1.4.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">Communication Costs</th>
<td id="S4.T2.1.4.3.2" class="ltx_td ltx_align_left ltx_border_t">
<table id="S4.T2.1.4.3.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T2.1.4.3.2.1.1" class="ltx_tr">
<td id="S4.T2.1.4.3.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">- Joint client selection algorithm to reduce convergence time</td>
</tr>
<tr id="S4.T2.1.4.3.2.1.2" class="ltx_tr">
<td id="S4.T2.1.4.3.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">- Distributed client selection where the clients decide to participate</td>
</tr>
<tr id="S4.T2.1.4.3.2.1.3" class="ltx_tr">
<td id="S4.T2.1.4.3.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">- Only active clients should perform training</td>
</tr>
<tr id="S4.T2.1.4.3.2.1.4" class="ltx_tr">
<td id="S4.T2.1.4.3.2.1.4.1" class="ltx_td ltx_nopad_r ltx_align_left">- 3-way hierarchical framework to improve efficiency</td>
</tr>
<tr id="S4.T2.1.4.3.2.1.5" class="ltx_tr">
<td id="S4.T2.1.4.3.2.1.5.1" class="ltx_td ltx_nopad_r ltx_align_left">- Select the client with the most significant information each round</td>
</tr>
<tr id="S4.T2.1.4.3.2.1.6" class="ltx_tr">
<td id="S4.T2.1.4.3.2.1.6.1" class="ltx_td ltx_nopad_r ltx_align_left">- Asynchronous FL</td>
</tr>
</table>
</td>
</tr>
<tr id="S4.T2.1.5.4" class="ltx_tr">
<th id="S4.T2.1.5.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">Fairness</th>
<td id="S4.T2.1.5.4.2" class="ltx_td ltx_align_left ltx_border_t">
<table id="S4.T2.1.5.4.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T2.1.5.4.2.1.1" class="ltx_tr">
<td id="S4.T2.1.5.4.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">- Fairness-guaranteed client selection algorithm</td>
</tr>
<tr id="S4.T2.1.5.4.2.1.2" class="ltx_tr">
<td id="S4.T2.1.5.4.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">- Improve fairness through biased client selection</td>
</tr>
<tr id="S4.T2.1.5.4.2.1.3" class="ltx_tr">
<td id="S4.T2.1.5.4.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">- Select honest clients</td>
</tr>
</table>
</td>
</tr>
</tbody>
</table>
</figure>
</section>
</section>
<section id="S4.SS7" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.7. </span>RQ3: Which metrics are important for measuring client selection?</h3>

<div id="S4.SS7.p1" class="ltx_para">
<p id="S4.SS7.p1.1" class="ltx_p">The relevant metrics regarding client selection entirely depend on the problem the study is trying to improve upon. The different key metrics for each of the main challenges in client selection are summarized in Table <a href="#S4.T3" title="Table 3 ‣ 4.7.4. Fairness ‣ 4.7. RQ3: Which metrics are important for measuring client selection? ‣ 4. Research Results ‣ A Systematic Literature Review on Client Selection in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<section id="S4.SS7.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.7.1. </span>Heterogeneity</h4>

<div id="S4.SS7.SSS1.p1" class="ltx_para">
<p id="S4.SS7.SSS1.p1.1" class="ltx_p">The most common metric used is measuring the test accuracy against the number of communication rounds. Out of the 20 studies which reported heterogeneity as the biggest challenge, 14 used this metric to measure the success of their client selection. This metric was also utilized by the original FL paper <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib39" title="" class="ltx_ref">2017</a>)</cite> and is directly comparable to the standard within regular machine learning, where ”Test Accuracy vs. Epoch” is very commonly seen.
The main difference stems from FL having many clients send their model updates to a global server and then aggregate them. In that regard, a communication round corresponds to one epoch of the global server.</p>
</div>
<div id="S4.SS7.SSS1.p2" class="ltx_para">
<p id="S4.SS7.SSS1.p2.1" class="ltx_p">Studies <cite class="ltx_cite ltx_citemacro_citep">(Cao et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2022</a>; Li et al<span class="ltx_text">.</span>, <a href="#bib.bib31" title="" class="ltx_ref">2022a</a>)</cite> included a similar metric: the number of communication rounds up to a given threshold accuracy. This approach’s main benefit is that it focuses more on minimizing the number of communication rounds, which are very costly in FL. Lastly, <cite class="ltx_cite ltx_citemacro_citet">Abdulrahman et al<span class="ltx_text">.</span> (<a href="#bib.bib2" title="" class="ltx_ref">2021</a>)</cite> looked into how many selected clients are able to finish training without dropping out.</p>
</div>
</section>
<section id="S4.SS7.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.7.2. </span>Resource Allocation</h4>

<div id="S4.SS7.SSS2.p1" class="ltx_para">
<p id="S4.SS7.SSS2.p1.1" class="ltx_p">For the challenge of resource allocation, the most common metric seen is also ”Testing Accuracy vs. Communication Rounds.” This is as expected, as it directly measures how well the FL-algorithm performs.</p>
</div>
<div id="S4.SS7.SSS2.p2" class="ltx_para">
<p id="S4.SS7.SSS2.p2.1" class="ltx_p">Some studies supplement it with other metrics such as energy, delay, and client consumption <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al<span class="ltx_text">.</span>, <a href="#bib.bib59" title="" class="ltx_ref">2021c</a>)</cite>. For mobile edge computing (MEC) systems, the energy is the basis of the client training model, and delay determines the iteration speed and convergence speed of the global model.</p>
</div>
</section>
<section id="S4.SS7.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.7.3. </span>Communication costs</h4>

<div id="S4.SS7.SSS3.p1" class="ltx_para">
<p id="S4.SS7.SSS3.p1.1" class="ltx_p">As already stated in section <a href="#S4.SS4" title="4.4. Communication costs ‣ 4. Research Results ‣ A Systematic Literature Review on Client Selection in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.4</span></a>, the cost of communication between clients and the global server is one of the most expensive parts of FL. Thus, utilizing the right metrics to validate the reduced cost is vital.</p>
</div>
<div id="S4.SS7.SSS3.p2" class="ltx_para">
<p id="S4.SS7.SSS3.p2.1" class="ltx_p">The typical ”Testing Accuracy vs. Communication Rounds” is commonly seen in the studies, as higher testing accuracy in fewer communication rounds will lead to lower costs. Another beneficial metric is convergence time and latency, reported by <cite class="ltx_cite ltx_citemacro_citet">Ko et al<span class="ltx_text">.</span> (<a href="#bib.bib24" title="" class="ltx_ref">2021</a>)</cite>, as reducing the time spent in communication will lead to lower costs.
Furthermore, <cite class="ltx_cite ltx_citemacro_citet">Tan et al<span class="ltx_text">.</span> (<a href="#bib.bib49" title="" class="ltx_ref">2022</a>)</cite> introduced the cost of hiring clients as an essential metric, as it was simply overlooked in existing studies and contributed a large part of the overall costs.</p>
</div>
</section>
<section id="S4.SS7.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.7.4. </span>Fairness</h4>

<div id="S4.SS7.SSS4.p1" class="ltx_para">
<p id="S4.SS7.SSS4.p1.1" class="ltx_p">Other than the already discussed ”testing accuracy vs. communication rounds” metric, <cite class="ltx_cite ltx_citemacro_citet">Huang et al<span class="ltx_text">.</span> (<a href="#bib.bib21" title="" class="ltx_ref">2021</a>)</cite> utilized different metrics for measuring improved fairness.
For instance, they included metrics such as the availability of the client and mathematically measured the long-term fairness through constraints.</p>
</div>
<figure id="S4.T3" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3. </span>Metrics compared to challenges</figcaption>
<table id="S4.T3.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T3.1.1.1" class="ltx_tr">
<th id="S4.T3.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r"><span id="S4.T3.1.1.1.1.1" class="ltx_text ltx_font_bold">Challenge</span></th>
<th id="S4.T3.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S4.T3.1.1.1.2.1" class="ltx_text ltx_font_bold">Metric(s)</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T3.1.2.1" class="ltx_tr">
<th id="S4.T3.1.2.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">Heterogeneity</th>
<td id="S4.T3.1.2.1.2" class="ltx_td ltx_align_left ltx_border_t">
<table id="S4.T3.1.2.1.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T3.1.2.1.2.1.1" class="ltx_tr">
<td id="S4.T3.1.2.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">- Testing accuracy vs communication rounds</td>
</tr>
<tr id="S4.T3.1.2.1.2.1.2" class="ltx_tr">
<td id="S4.T3.1.2.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">- Communication rounds until threshold accuracy</td>
</tr>
<tr id="S4.T3.1.2.1.2.1.3" class="ltx_tr">
<td id="S4.T3.1.2.1.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">- Number of selected client able to finish training</td>
</tr>
</table>
</td>
</tr>
<tr id="S4.T3.1.3.2" class="ltx_tr">
<th id="S4.T3.1.3.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">Resource Allocation</th>
<td id="S4.T3.1.3.2.2" class="ltx_td ltx_align_left ltx_border_t">
<table id="S4.T3.1.3.2.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T3.1.3.2.2.1.1" class="ltx_tr">
<td id="S4.T3.1.3.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">- Testing accuracy vs communication rounds</td>
</tr>
<tr id="S4.T3.1.3.2.2.1.2" class="ltx_tr">
<td id="S4.T3.1.3.2.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">- Energy, delay, and client consumption</td>
</tr>
</table>
</td>
</tr>
<tr id="S4.T3.1.4.3" class="ltx_tr">
<th id="S4.T3.1.4.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">Communication Costs</th>
<td id="S4.T3.1.4.3.2" class="ltx_td ltx_align_left ltx_border_t">
<table id="S4.T3.1.4.3.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T3.1.4.3.2.1.1" class="ltx_tr">
<td id="S4.T3.1.4.3.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">- Testing accuracy vs communication rounds</td>
</tr>
<tr id="S4.T3.1.4.3.2.1.2" class="ltx_tr">
<td id="S4.T3.1.4.3.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">- Convergence time vs latency</td>
</tr>
<tr id="S4.T3.1.4.3.2.1.3" class="ltx_tr">
<td id="S4.T3.1.4.3.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">- Cost of hiring clients</td>
</tr>
</table>
</td>
</tr>
<tr id="S4.T3.1.5.4" class="ltx_tr">
<th id="S4.T3.1.5.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">Fairness</th>
<td id="S4.T3.1.5.4.2" class="ltx_td ltx_align_left ltx_border_t">
<table id="S4.T3.1.5.4.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T3.1.5.4.2.1.1" class="ltx_tr">
<td id="S4.T3.1.5.4.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">- Testing accuracy vs communication rounds</td>
</tr>
<tr id="S4.T3.1.5.4.2.1.2" class="ltx_tr">
<td id="S4.T3.1.5.4.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">- Availability of clients</td>
</tr>
<tr id="S4.T3.1.5.4.2.1.3" class="ltx_tr">
<td id="S4.T3.1.5.4.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">- Long-term fairness constraints</td>
</tr>
</table>
</td>
</tr>
</tbody>
</table>
</figure>
</section>
</section>
<section id="S4.SS8" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.8. </span>RQ4: What can be improved with the current client selection?</h3>

<div id="S4.SS8.p1" class="ltx_para">
<p id="S4.SS8.p1.1" class="ltx_p">There are a lot of improvements that can be made with the current client selection. As decentralized learning is still pretty young, there is room for improvement within all discussed challenges in this SLR.</p>
</div>
<section id="S4.SS8.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.8.1. </span>Heterogeneity</h4>

<div id="S4.SS8.SSS1.p1" class="ltx_para">
<p id="S4.SS8.SSS1.p1.1" class="ltx_p">For hierarchical federated learning (HFL), <cite class="ltx_cite ltx_citemacro_citet">Albaseer et al<span class="ltx_text">.</span> (<a href="#bib.bib4" title="" class="ltx_ref">2021</a>)</cite> suggested looking into finding the optimal thresholds for splitting clusters of clients, which certainly would improve the communication efficiency of the learning network.</p>
</div>
</section>
<section id="S4.SS8.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.8.2. </span>Resource Allocation</h4>

<div id="S4.SS8.SSS2.p1" class="ltx_para">
<p id="S4.SS8.SSS2.p1.1" class="ltx_p">The primary studies reported several measures for possible future work which seem exciting and beneficial for the current client selection schemes.
<cite class="ltx_cite ltx_citemacro_citet">Xu and Wang (<a href="#bib.bib55" title="" class="ltx_ref">2021</a>)</cite> stated that selecting clients as late as possible improves the efficiency of the client selection, but there is a lack of theoretical and practical research on the topic.</p>
</div>
<div id="S4.SS8.SSS2.p2" class="ltx_para">
<p id="S4.SS8.SSS2.p2.1" class="ltx_p">The most commonly suggested improvement was reported by three of the studies <cite class="ltx_cite ltx_citemacro_citep">(Shi et al<span class="ltx_text">.</span>, <a href="#bib.bib48" title="" class="ltx_ref">2022</a>; Lin et al<span class="ltx_text">.</span>, <a href="#bib.bib32" title="" class="ltx_ref">2022</a>; Rai et al<span class="ltx_text">.</span>, <a href="#bib.bib45" title="" class="ltx_ref">2022</a>)</cite>. They suggested looking into the effect of unsuccessful clients (or free-riders) and how to quantify the impact. These types of clients bring a lot of overhead costs into the learning network, and exploring the effects and solutions to those would undoubtedly improve the current client selection.
None of the primary studies focused mainly on the effect of unsuccessful clients. However, studies <cite class="ltx_cite ltx_citemacro_citep">(Huang et al<span class="ltx_text">.</span>, <a href="#bib.bib20" title="" class="ltx_ref">2022</a>; Shi et al<span class="ltx_text">.</span>, <a href="#bib.bib48" title="" class="ltx_ref">2022</a>)</cite> focused on optimizing client selection for volatile FL. This volatility stems from the dynamic of clients’ data and the unreliable nature of clients (e.g., unintentional shutdown and network instability). Therefore, some work has been done on the topic, but there is certainly a gap that may be improved more. Those studies focus much more on the client’s ability to enter and leave training rather than the effect of unsuccessful clients.</p>
</div>
</section>
<section id="S4.SS8.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.8.3. </span>Communication Costs</h4>

<div id="S4.SS8.SSS3.p1" class="ltx_para">
<p id="S4.SS8.SSS3.p1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citet">Ko et al<span class="ltx_text">.</span> (<a href="#bib.bib24" title="" class="ltx_ref">2021</a>)</cite> discussed the possibility of creating an incentive mechanism to encourage more computing power to FL. So far, there are no incentives for the client devices to allocate more resources to learning than necessary. Thus, giving them some sort of incentive mechanism would increase computational power and improve the problem of resource allocation.
Perhaps it would make it easier to create a more homogenous resource distribution amongst the clients.</p>
</div>
</section>
<section id="S4.SS8.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.8.4. </span>Fairness</h4>

<div id="S4.SS8.SSS4.p1" class="ltx_para">
<p id="S4.SS8.SSS4.p1.1" class="ltx_p">Even though only two studies reported fairness as the main challenge, studies, such as <cite class="ltx_cite ltx_citemacro_citep">(Jee Cho et al<span class="ltx_text">.</span>, <a href="#bib.bib22" title="" class="ltx_ref">2020</a>; Zhu et al<span class="ltx_text">.</span>, <a href="#bib.bib62" title="" class="ltx_ref">2022</a>; Cho et al<span class="ltx_text">.</span>, <a href="#bib.bib11" title="" class="ltx_ref">2022</a>)</cite>, mention it as a possibly important factor that could promise a higher accuracy. Others mentioned it as a possible future direction for their work. For instance, <cite class="ltx_cite ltx_citemacro_citet">Shi et al<span class="ltx_text">.</span> (<a href="#bib.bib48" title="" class="ltx_ref">2022</a>)</cite> reported that fairness might play an essential role in FL training and that studying it in a volatile context would be beneficial.
As already discussed in section <a href="#S4.SS6" title="4.6. RQ2: How are clients selected in federated learning ‣ 4. Research Results ‣ A Systematic Literature Review on Client Selection in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.6</span></a>, studies already focus on fairness in client selection, but there is still a knowledge gap within the topic. <cite class="ltx_cite ltx_citemacro_citet">Huang et al<span class="ltx_text">.</span> (<a href="#bib.bib21" title="" class="ltx_ref">2021</a>)</cite> looked into the trade-off between fairness and training accuracy but concluded that they could not quantify the relationship and that looking further into analyzing the fairness factor for FL would be worthy of investigation.</p>
</div>
</section>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5. </span>Discussion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">This section discusses how the SLR compares to the related work as well as the limitations of the study.</p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1. </span>Comparison to Related Work</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">To our knowledge, there currently does not exist any SLR focusing solely on client selection. The previous work has focused either on general FL challenges or the application of FL. Therefore, the main benefit of this SLR is its focus on FL from the perspective of client selection.
However, there are a lot of similarities between the related work and this review, as they all encompass the challenges within FL. The value of this review to the industry is as a reference for the different client selection techniques and how they impact overall learning. There is also value in viewing possible future directions for client selection when looking into what can be improved.</p>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<p id="S5.SS1.p2.1" class="ltx_p">This review has found a couple of areas that researchers may look more into from the perspective of client selection. Firstly, there are a vast amount of different client selection schemes proposed for FL, which all claim to outperform the state-of-the-art of random selection. It would be beneficial to compare these selection schemes with possible application cases in order to form an improved state-of-the-art solution for client selection.
Secondly, the topic of fairness is not thoroughly explored. Several studies mention fairness as an important factor, but there does not exist much research on the topic of exploring the trade-offs and benefits of focusing on it.</p>
</div>
<div id="S5.SS1.p3" class="ltx_para">
<p id="S5.SS1.p3.1" class="ltx_p">Although FL is a relatively new field within machine learning, it already shows promising prospects within several application domains, such as healthcare, natural language processing, smart cities and IoT.
For certain industries, it might be more trivial to implement a well-functioning system as the developers know the types of devices on which the algorithm will be implemented, but this is not the case for applications such as IoT and edge computing.
In those fields, the developers do not necessarily know much about the client devices which will perform the learning, thus making it much more difficult to tackle the several challenges reported by the related work and found in this SLR.</p>
</div>
<div id="S5.SS1.p4" class="ltx_para">
<p id="S5.SS1.p4.1" class="ltx_p">Client selection is an integral part of a well-functioning FL system, as it may be utilized to improve the challenges of heterogeneity, resource allocation, communication costs, and fairness.
Despite the previous- and related work conducted on the topic, there is no de facto standard for the client selection algorithm within any application of FL.
Even within a subset of any challenge, such as the issue of clients dropping out during training, multiple possible solutions exist, such as asynchronous FL, partial aggregation of dropped-out clients, and resource-aware FL. Within each category, there exist many algorithms to tackle the challenge through client selection, which shows the importance of exploring the topic further and possibly finding the best approach.</p>
</div>
<div id="S5.SS1.p5" class="ltx_para">
<p id="S5.SS1.p5.1" class="ltx_p">For academia and industry, this SLR may assist in several ways. Firstly, it can be used as a reference guide for the most prominent existing challenges and their consequences for learning. Secondly, for each given challenge, the SLR presents several different possible existing solutions to tackle it. This is especially valuable to the industry when deciding to implement an FL system and deciding whether or not their ecosystem is well-suited for it. The SLR also provides guidelines to mitigate some of the challenges.</p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2. </span>Limitations</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">Although the guidelines for systematic reviews by <cite class="ltx_cite ltx_citemacro_citep">(Kitchenham and Charters, <a href="#bib.bib23" title="" class="ltx_ref">2007</a>)</cite> were followed, several points may have been improved. We might miss some primary studies in the study search stage because there were many studies on the topic of FL. For instance, performing the forward snowballing procedure on the original FL-paper <cite class="ltx_cite ltx_citemacro_citet">McMahan et al<span class="ltx_text">.</span> (<a href="#bib.bib39" title="" class="ltx_ref">2017</a>)</cite> resulted in around 7000 studies. Even though there is plenty of academic research on the topic, we did not look into any grey literature as a possible source. There certainly may exist many exciting discussions and ideas on FL which are not discussed in academic journals but in blogs and newspapers. We might exclude papers that are relevant to the study during the paper selection process. To mitigate this risk, the papers’ inclusion and exclusion are cross-checked and agreed upon by both authors.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6. </span>Conclusions and Future Work</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">We performed an SLR and summarized the challenges, solutions, and metrics for evaluating the solutions and possible future work of client selection in FL. Information from 47 primary studies is analyzed and synthesized. This study is the only SLR, as far as the author is aware, focusing solely on client selection in FL.</p>
</div>
<div id="S6.p2" class="ltx_para">
<p id="S6.p2.1" class="ltx_p">The SLR delights several possible future research challenges we want to focus on. The most beneficial ones regard the impact of unsuccessful clients or fairness. Improving one of those challenges could benefit FL, as the training efficiency might increase, and the communication costs would be reduced. The communication cost is also one of the most significant problems in FL. Thus, improving it would be beneficial.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">        




</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Abdulrahman et al<span id="bib.bib2.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Sawsan Abdulrahman, Hanine
Tout, Azzam Mourad, and Chamseddine
Talhi. 2021.

</span>
<span class="ltx_bibblock">FedMCCS: Multicriteria Client Selection
Model for Optimal IoT Federated Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib2.3.1" class="ltx_emph ltx_font_italic">IEEE Internet of Things Journal</em>
8, 6 (March
2021), 4723–4735.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1109/JIOT.2020.3028742" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/JIOT.2020.3028742</a>

</span>
<span class="ltx_bibblock">Conference Name: IEEE Internet of Things Journal.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Abreha et al<span id="bib.bib3.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Haftay Gebreslasie Abreha,
Mohammad Hayajneh, and Mohamed Adel
Serhani. 2022.

</span>
<span class="ltx_bibblock">Federated Learning in Edge Computing: A
Systematic Survey.

</span>
<span class="ltx_bibblock"><em id="bib.bib3.3.1" class="ltx_emph ltx_font_italic">Sensors</em> 22,
2 (Jan. 2022),
450.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.3390/s22020450" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.3390/s22020450</a>

</span>
<span class="ltx_bibblock">Number: 2 Publisher: Multidisciplinary Digital Publishing Institute.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Albaseer et al<span id="bib.bib4.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Abdullatif Albaseer,
Mohamed Abdallah, Ala Al-Fuqaha, and
Aiman Erbad. 2021.

</span>
<span class="ltx_bibblock">Client Selection Approach in Support of
Clustered Federated Learning over Wireless Edge Networks. In
<em id="bib.bib4.3.1" class="ltx_emph ltx_font_italic">2021 IEEE Global Communications Conference
(GLOBECOM)</em>. 1–6.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/GLOBECOM46510.2021.9685938" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/GLOBECOM46510.2021.9685938</a>

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ali et al<span id="bib.bib5.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Asad Ali, Inaam Ilahi,
Adnan Qayyum, Ihab Mohammed,
Ala Al-Fuqaha, and Junaid Qadir.
2021.

</span>
<span class="ltx_bibblock">Incentive-Driven Federated Learning and
Associated Security Challenges: A Systematic Review.

</span>
<span class="ltx_bibblock">(2021), 30.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Anderson (2015)</span>
<span class="ltx_bibblock">
Monica Anderson.
2015.

</span>
<span class="ltx_bibblock"><em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">Technology device ownership: 2015</em>.

</span>
<span class="ltx_bibblock">Report. Pew Research Center.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://apo.org.au/node/58353" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://apo.org.au/node/58353</a>

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Antunes et al<span id="bib.bib7.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Rodolfo Stoffel Antunes,
Cristiano André da Costa, Arne Küderle,
Imrana Abdullahi Yari, and Björn
Eskofier. 2022.

</span>
<span class="ltx_bibblock">Federated Learning for Healthcare: Systematic
Review and Architecture Proposal.

</span>
<span class="ltx_bibblock"><em id="bib.bib7.3.1" class="ltx_emph ltx_font_italic">ACM Transactions on Intelligent Systems and
Technology</em> 13, 4 (May
2022), 54:1–54:23.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3501813" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3501813</a>

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Asad et al<span id="bib.bib8.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Muhammad Asad, Ahmed
Moustafa, Fethi A. Rabhi, and Muhammad
Aslam. 2022.

</span>
<span class="ltx_bibblock">THF: 3-Way Hierarchical Framework for
Efficient Client Selection and Resource Management in Federated
Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib8.3.1" class="ltx_emph ltx_font_italic">IEEE Internet of Things Journal</em>
9, 13 (July
2022), 11085–11097.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1109/JIOT.2021.3126828" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/JIOT.2021.3126828</a>

</span>
<span class="ltx_bibblock">Conference Name: IEEE Internet of Things Journal.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Balakrishnan et al<span id="bib.bib9.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Ravikumar Balakrishnan,
Tian Li, Tianyi Zhou,
Nageen Himayat, Virginia Smith, and
Jeffrey Bilmes. 2022.

</span>
<span class="ltx_bibblock">DIVERSE CLIENT SELECTION FOR FEDERATED
LEARNING VIA SUBMODULAR MAXIMIZATION.

</span>
<span class="ltx_bibblock">(2022), 18.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cao et al<span id="bib.bib10.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Mei Cao, Yujie Zhang,
Zezhong Ma, and Mengying Zhao.
2022.

</span>
<span class="ltx_bibblock">C2S: Class-aware client selection for effective
aggregation in federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib10.3.1" class="ltx_emph ltx_font_italic">High-Confidence Computing</em>
2, 3 (Sept.
2022), 100068.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1016/j.hcc.2022.100068" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1016/j.hcc.2022.100068</a>

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cho et al<span id="bib.bib11.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Yae Jee Cho, Jianyu Wang,
and Gauri Joshi. 2022.

</span>
<span class="ltx_bibblock">Towards Understanding Biased Client
Selection in Federated Learning. In
<em id="bib.bib11.3.1" class="ltx_emph ltx_font_italic">Proceedings of The 25th International
Conference on Artificial Intelligence and Statistics</em>.
PMLR, 10351–10375.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://proceedings.mlr.press/v151/jee-cho22a.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://proceedings.mlr.press/v151/jee-cho22a.html</a>

</span>
<span class="ltx_bibblock">ISSN: 2640-3498.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Deng et al<span id="bib.bib12.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Yongheng Deng, Feng Lyu,
Ju Ren, Huaqing Wu,
Yuezhi Zhou, Yaoxue Zhang, and
Xuemin Shen. 2022.

</span>
<span class="ltx_bibblock">AUCTION: Automated and Quality-Aware
Client Selection Framework for Efficient Federated Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib12.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Parallel and Distributed
Systems</em> 33, 8 (Aug.
2022), 1996–2009.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1109/TPDS.2021.3134647" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/TPDS.2021.3134647</a>

</span>
<span class="ltx_bibblock">Conference Name: IEEE Transactions on Parallel and Distributed
Systems.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Du et al<span id="bib.bib13.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Zhaoyang Du, Celimuge Wu,
Tsutomu Yoshinage, Lei Zhong, and
Yusheng Ji. 2022.

</span>
<span class="ltx_bibblock">On-device federated learning with fuzzy logic based
client selection. In <em id="bib.bib13.3.1" class="ltx_emph ltx_font_italic">Proceedings of the
Conference on Research in Adaptive and Convergent Systems</em>
<em id="bib.bib13.4.2" class="ltx_emph ltx_font_italic">(RACS ’22)</em>. Association for
Computing Machinery, New York, NY, USA,
64–70.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3538641.3561490" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3538641.3561490</a>

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Feldman (2015)</span>
<span class="ltx_bibblock">
Michael Feldman.
2015.

</span>
<span class="ltx_bibblock"><em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">Computational Fairness: Preventing
Machine-Learned Discrimination</em>.

</span>
<span class="ltx_bibblock">Thesis.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://scholarship.tricolib.brynmawr.edu/handle/10066/17628" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://scholarship.tricolib.brynmawr.edu/handle/10066/17628</a>

</span>
<span class="ltx_bibblock">Accepted: 2016-01-19T17:37:36Z.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guo et al<span id="bib.bib15.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Yingya Guo, Kai Huang,
and Jianshan Chen. 2021.

</span>
<span class="ltx_bibblock">WCL: Client Selection in Federated
Learning with a Combination of Model Weight Divergence and Client
Training Loss for Internet Traffic Classification.

</span>
<span class="ltx_bibblock"><em id="bib.bib15.3.1" class="ltx_emph ltx_font_italic">Wireless Communications and Mobile
Computing</em> 2021 (Dec.
2021), e3381998.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1155/2021/3381998" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1155/2021/3381998</a>

</span>
<span class="ltx_bibblock">Publisher: Hindawi.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Higgins et al<span id="bib.bib16.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Julian P. T. Higgins,
James Thomas, Jacqueline Chandler,
Miranda Cumpston, Tianjing Li,
Matthew J. Page, and Vivian A. Welch.
2019.

</span>
<span class="ltx_bibblock"><em id="bib.bib16.3.1" class="ltx_emph ltx_font_italic">Cochrane Handbook for Systematic
Reviews of Interventions</em>.

</span>
<span class="ltx_bibblock">John Wiley &amp; Sons.

</span>
<span class="ltx_bibblock">

</span>
<span class="ltx_bibblock">Google-Books-ID: cTqyDwAAQBAJ.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hosseinzadeh et al<span id="bib.bib17.2.2.1" class="ltx_text">.</span> (2022a)</span>
<span class="ltx_bibblock">
Mehdi Hosseinzadeh, Atefeh
Hemmati, and Amir Masoud Rahmani.
2022a.

</span>
<span class="ltx_bibblock">Federated learning-based IoT: A systematic
literature review.

</span>
<span class="ltx_bibblock"><em id="bib.bib17.3.1" class="ltx_emph ltx_font_italic">International Journal of Communication
Systems</em> 35, 11 (2022),
e5185.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1002/dac.5185" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1002/dac.5185</a>

</span>
<span class="ltx_bibblock">_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/dac.5185.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hosseinzadeh et al<span id="bib.bib18.2.2.1" class="ltx_text">.</span> (2022b)</span>
<span class="ltx_bibblock">
Minoo Hosseinzadeh,
Nathaniel Hudson, Sam Heshmati, and
Hana Khamfroush. 2022b.

</span>
<span class="ltx_bibblock">Communication-Loss Trade-Off in Federated
Learning: A Distributed Client Selection Algorithm. In
<em id="bib.bib18.3.1" class="ltx_emph ltx_font_italic">2022 IEEE 19th Annual Consumer
Communications &amp; Networking Conference (CCNC)</em>.
1–6.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/CCNC49033.2022.9700601" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/CCNC49033.2022.9700601</a>

</span>
<span class="ltx_bibblock">ISSN: 2331-9860.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hou et al<span id="bib.bib19.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Dongkun Hou, Jie Zhang,
Ka Lok Man, Jieming Ma, and
Zitian Peng. 2021.

</span>
<span class="ltx_bibblock">A Systematic Literature Review of
Blockchain-based Federated Learning: Architectures, Applications
and Issues. In <em id="bib.bib19.3.1" class="ltx_emph ltx_font_italic">2021 2nd Information
Communication Technologies Conference (ICTC)</em>.
302–307.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/ICTC51749.2021.9441499" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/ICTC51749.2021.9441499</a>

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et al<span id="bib.bib20.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Tiansheng Huang, Weiwei
Lin, Li Shen, Keqin Li, and
Albert Y. Zomaya. 2022.

</span>
<span class="ltx_bibblock">Stochastic Client Selection for Federated
Learning With Volatile Clients.

</span>
<span class="ltx_bibblock"><em id="bib.bib20.3.1" class="ltx_emph ltx_font_italic">IEEE Internet of Things Journal</em>
9, 20 (Oct.
2022), 20055–20070.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1109/JIOT.2022.3172113" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/JIOT.2022.3172113</a>

</span>
<span class="ltx_bibblock">Conference Name: IEEE Internet of Things Journal.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et al<span id="bib.bib21.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Tiansheng Huang, Weiwei
Lin, Wentai Wu, Ligang He,
Keqin Li, and Albert Y. Zomaya.
2021.

</span>
<span class="ltx_bibblock">An Efficiency-Boosting Client Selection
Scheme for Federated Learning With Fairness Guarantee.

</span>
<span class="ltx_bibblock"><em id="bib.bib21.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Parallel and Distributed
Systems</em> 32, 7 (July
2021), 1552–1564.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1109/TPDS.2020.3040887" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/TPDS.2020.3040887</a>

</span>
<span class="ltx_bibblock">Conference Name: IEEE Transactions on Parallel and Distributed
Systems.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jee Cho et al<span id="bib.bib22.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Yae Jee Cho, Samarth
Gupta, Gauri Joshi, and Osman Yağan.
2020.

</span>
<span class="ltx_bibblock">Bandit-based Communication-Efficient Client
Selection Strategies for Federated Learning. In
<em id="bib.bib22.3.1" class="ltx_emph ltx_font_italic">2020 54th Asilomar Conference on Signals,
Systems, and Computers</em>. 1066–1069.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/IEEECONF51394.2020.9443523" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/IEEECONF51394.2020.9443523</a>

</span>
<span class="ltx_bibblock">ISSN: 2576-2303.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kitchenham and Charters (2007)</span>
<span class="ltx_bibblock">
Barbara Kitchenham and
Stuart Charters. 2007.

</span>
<span class="ltx_bibblock">Guidelines for performing Systematic Literature
Reviews in Software Engineering.

</span>
<span class="ltx_bibblock">2 (Jan. 2007).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ko et al<span id="bib.bib24.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Haneul Ko, Jaewook Lee,
Sangwon Seo, Sangheon Pack, and
Victor C. M. Leung. 2021.

</span>
<span class="ltx_bibblock">Joint Client Selection and Bandwidth
Allocation Algorithm for Federated Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib24.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Mobile Computing</em>
(2021), 1–1.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1109/TMC.2021.3136611" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/TMC.2021.3136611</a>

</span>
<span class="ltx_bibblock">Conference Name: IEEE Transactions on Mobile Computing.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kuang et al<span id="bib.bib25.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Junqian Kuang, Miao Yang,
Hongbin Zhu, and Hua Qian.
2021.

</span>
<span class="ltx_bibblock">Client Selection with Bandwidth Allocation in
Federated Learning. In <em id="bib.bib25.3.1" class="ltx_emph ltx_font_italic">2021 IEEE Global
Communications Conference (GLOBECOM)</em>. 01–06.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/GLOBECOM46510.2021.9685090" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/GLOBECOM46510.2021.9685090</a>

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee et al<span id="bib.bib26.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Jaewook Lee, Haneul Ko,
Sangwon Seo, and Sangheon Pack.
2022.

</span>
<span class="ltx_bibblock">Data Distribution-Aware Online Client
Selection Algorithm for Federated Learning in Heterogeneous
Networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib26.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Vehicular Technology</em>
(2022), 1–11.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1109/TVT.2022.3205307" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/TVT.2022.3205307</a>

</span>
<span class="ltx_bibblock">Conference Name: IEEE Transactions on Vehicular Technology.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib27.2.2.1" class="ltx_text">.</span> (2022b)</span>
<span class="ltx_bibblock">
Chenning Li, Zeng Xiao,
Mi Zhang, and Zhichao Cao.
2022b.

</span>
<span class="ltx_bibblock">PyramidFL | Proceedings of the 28th
Annual International Conference on Mobile Computing And
Networking.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://dl.acm.org/doi/10.1145/3495243.3517017" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://dl.acm.org/doi/10.1145/3495243.3517017</a>

</span>
<span class="ltx_bibblock">Archive Location: world.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib28.2.2.1" class="ltx_text">.</span> (2022c)</span>
<span class="ltx_bibblock">
Pengfei Li, Yunfeng Zhao,
Liandong Chen, Kai Cheng,
Chuyue Xie, Xiaofei Wang, and
Qinghua Hu. 2022c.

</span>
<span class="ltx_bibblock">Uncertainty Measured Active Client
Selection for Federated Learning in Smart Grid. In
<em id="bib.bib28.3.1" class="ltx_emph ltx_font_italic">2022 IEEE International Conference on Smart
Internet of Things (SmartIoT)</em>. 148–153.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/SmartIoT55134.2022.00032" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/SmartIoT55134.2022.00032</a>

</span>
<span class="ltx_bibblock">ISSN: 2770-2677.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib29.2.2.1" class="ltx_text">.</span> (2020a)</span>
<span class="ltx_bibblock">
Tian Li, Anit Kumar Sahu,
Ameet Talwalkar, and Virginia Smith.
2020a.

</span>
<span class="ltx_bibblock">Federated Learning: Challenges, Methods, and
Future Directions.

</span>
<span class="ltx_bibblock"><em id="bib.bib29.3.1" class="ltx_emph ltx_font_italic">IEEE Signal Processing Magazine</em>
37, 3 (May
2020), 50–60.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1109/MSP.2020.2975749" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/MSP.2020.2975749</a>

</span>
<span class="ltx_bibblock">Conference Name: IEEE Signal Processing Magazine.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib30.2.2.1" class="ltx_text">.</span> (2020b)</span>
<span class="ltx_bibblock">
Tian Li, Maziar Sanjabi,
Ahmad Beirami, and Virginia Smith.
2020b.

</span>
<span class="ltx_bibblock">Fair Resource Allocation in Federated
Learning.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/arXiv.1905.10497" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.1905.10497</a>

</span>
<span class="ltx_bibblock">arXiv:1905.10497 [cs, stat].

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib31.2.2.1" class="ltx_text">.</span> (2022a)</span>
<span class="ltx_bibblock">
Zonghang Li, Yihong He,
Hongfang Yu, Jiawen Kang,
Xiaoping Li, Zenglin Xu, and
Dusit Niyato. 2022a.

</span>
<span class="ltx_bibblock">Data Heterogeneity-Robust Federated
Learning via Group Client Selection in Industrial IoT.

</span>
<span class="ltx_bibblock"><em id="bib.bib31.3.1" class="ltx_emph ltx_font_italic">IEEE Internet of Things Journal</em>
9, 18 (Sept.
2022), 17844–17857.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1109/JIOT.2022.3161943" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/JIOT.2022.3161943</a>

</span>
<span class="ltx_bibblock">Conference Name: IEEE Internet of Things Journal.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin et al<span id="bib.bib32.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Weiwei Lin, Yinhai Xu,
Bo Liu, Dongdong Li,
Tiansheng Huang, and Fang Shi.
2022.

</span>
<span class="ltx_bibblock">Contribution-based Federated Learning client
selection.

</span>
<span class="ltx_bibblock"><em id="bib.bib32.3.1" class="ltx_emph ltx_font_italic">International Journal of Intelligent
Systems</em> 37, 10 (2022),
7235–7260.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1002/int.22879" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1002/int.22879</a>

</span>
<span class="ltx_bibblock">_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/int.22879.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al<span id="bib.bib33.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Tingting Liu, Haibo Zhou,
Jun Li, Feng Shu, and
Zhu Han. 2022.

</span>
<span class="ltx_bibblock">Uplink and Downlink Decoupled 5G/B5G
Vehicular Networks: A Federated Learning Assisted Client
Selection Method.

</span>
<span class="ltx_bibblock"><em id="bib.bib33.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Vehicular Technology</em>
(2022), 1–13.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1109/TVT.2022.3207916" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/TVT.2022.3207916</a>

</span>
<span class="ltx_bibblock">Conference Name: IEEE Transactions on Vehicular Technology.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al<span id="bib.bib34.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Yi Liu, Li Zhang,
Ning Ge, and Guanghao Li.
2020.

</span>
<span class="ltx_bibblock">A Systematic Literature Review on Federated
Learning: From A Model Quality Perspective.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/arXiv.2012.01973" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2012.01973</a>

</span>
<span class="ltx_bibblock">arXiv:2012.01973 [cs].

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lo et al<span id="bib.bib35.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Sin Kit Lo, Qinghua Lu,
Chen Wang, Hye-Young Paik, and
Liming Zhu. 2021.

</span>
<span class="ltx_bibblock">A Systematic Literature Review on Federated
Machine Learning: From a Software Engineering Perspective.

</span>
<span class="ltx_bibblock"><em id="bib.bib35.3.1" class="ltx_emph ltx_font_italic">Comput. Surveys</em> 54,
5 (May 2021),
95:1–95:39.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3450288" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3450288</a>

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lo et al<span id="bib.bib36.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Sin Kit Lo, Qinghua Lu,
Liming Zhu, Hye-Young Paik,
Xiwei Xu, and Chen Wang.
2022.

</span>
<span class="ltx_bibblock">Architectural patterns for the design of federated
learning systems.

</span>
<span class="ltx_bibblock"><em id="bib.bib36.3.1" class="ltx_emph ltx_font_italic">Journal of Systems and Software</em>
191 (Sept. 2022),
111357.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1016/j.jss.2022.111357" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1016/j.jss.2022.111357</a>

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ma et al<span id="bib.bib37.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Jiahua Ma, Xinghua Sun,
Wenchao Xia, Xijun Wang,
Xiang Chen, and Hongbo Zhu.
2021.

</span>
<span class="ltx_bibblock">Client Selection Based on Label Quantity
Information for Federated Learning. In <em id="bib.bib37.3.1" class="ltx_emph ltx_font_italic">2021
IEEE 32nd Annual International Symposium on Personal, Indoor and
Mobile Radio Communications (PIMRC)</em>. 1–6.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/PIMRC50174.2021.9569487" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/PIMRC50174.2021.9569487</a>

</span>
<span class="ltx_bibblock">ISSN: 2166-9589.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ma et al<span id="bib.bib38.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Xiaodong Ma, Jia Zhu,
Zhihao Lin, Shanxuan Chen, and
Yangjie Qin. 2022.

</span>
<span class="ltx_bibblock">A state-of-the-art survey on solving non-IID data
in Federated Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib38.3.1" class="ltx_emph ltx_font_italic">Future Generation Computer Systems</em>
135 (Oct. 2022),
244–258.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1016/j.future.2022.05.003" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1016/j.future.2022.05.003</a>

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McMahan et al<span id="bib.bib39.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Brendan McMahan, Eider
Moore, Daniel Ramage, Seth Hampson,
and Blaise Aguera y Arcas.
2017.

</span>
<span class="ltx_bibblock">Communication-Efficient Learning of Deep
Networks from Decentralized Data. In
<em id="bib.bib39.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 20th International
Conference on Artificial Intelligence and Statistics</em>.
PMLR, 1273–1282.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://proceedings.mlr.press/v54/mcmahan17a.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://proceedings.mlr.press/v54/mcmahan17a.html</a>

</span>
<span class="ltx_bibblock">ISSN: 2640-3498.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mohanani et al<span id="bib.bib40.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Rahul Mohanani, Iflaah
Salman, Burak Turhan, Pilar Rodríguez,
and Paul Ralph. 2020.

</span>
<span class="ltx_bibblock">Cognitive Biases in Software Engineering: A
Systematic Mapping Study.

</span>
<span class="ltx_bibblock"><em id="bib.bib40.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Software Engineering</em>
46, 12 (Dec.
2020), 1318–1339.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1109/TSE.2018.2877759" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/TSE.2018.2877759</a>

</span>
<span class="ltx_bibblock">Conference Name: IEEE Transactions on Software Engineering.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nishio and Yonetani (2019)</span>
<span class="ltx_bibblock">
Takayuki Nishio and Ryo
Yonetani. 2019.

</span>
<span class="ltx_bibblock">Client Selection for Federated Learning with
Heterogeneous Resources in Mobile Edge. In
<em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">ICC 2019 - 2019 IEEE International
Conference on Communications (ICC)</em>. 1–7.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/ICC.2019.8761315" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/ICC.2019.8761315</a>

</span>
<span class="ltx_bibblock">ISSN: 1938-1883.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pang et al<span id="bib.bib42.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Jinlong Pang, Jieling Yu,
Ruiting Zhou, and John C.S. Lui.
2022.

</span>
<span class="ltx_bibblock">An Incentive Auction for Heterogeneous
Client Selection in Federated Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib42.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Mobile Computing</em>
(2022), 1–17.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1109/TMC.2022.3182876" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/TMC.2022.3182876</a>

</span>
<span class="ltx_bibblock">Conference Name: IEEE Transactions on Mobile Computing.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pfitzner et al<span id="bib.bib43.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Bjarne Pfitzner, Nico
Steckhan, and Bert Arnrich.
2021.

</span>
<span class="ltx_bibblock">Federated Learning in a Medical Context: A
Systematic Literature Review.

</span>
<span class="ltx_bibblock"><em id="bib.bib43.3.1" class="ltx_emph ltx_font_italic">ACM Transactions on Internet Technology</em>
21, 2 (June
2021), 50:1–50:31.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3412357" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3412357</a>

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qu et al<span id="bib.bib44.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Zhe Qu, Rui Duan,
Lixing Chen, Jie Xu,
Zhuo Lu, and Yao Liu.
2022.

</span>
<span class="ltx_bibblock">Context-Aware Online Client Selection for
Hierarchical Federated Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib44.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Parallel and Distributed
Systems</em> 33, 12 (Dec.
2022), 4353–4367.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1109/TPDS.2022.3186960" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/TPDS.2022.3186960</a>

</span>
<span class="ltx_bibblock">Conference Name: IEEE Transactions on Parallel and Distributed
Systems.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rai et al<span id="bib.bib45.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Sumit Rai, Arti Kumari,
and Dilip K. Prasad. 2022.

</span>
<span class="ltx_bibblock">Client Selection in Federated Learning under
Imperfections in Environment.

</span>
<span class="ltx_bibblock"><em id="bib.bib45.3.1" class="ltx_emph ltx_font_italic">AI</em> 3, 1
(March 2022), 124–145.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.3390/ai3010008" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.3390/ai3010008</a>

</span>
<span class="ltx_bibblock">Number: 1 Publisher: Multidisciplinary Digital Publishing Institute.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Saha et al<span id="bib.bib46.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Rituparna Saha, Sudip
Misra, Aishwariya Chakraborty,
Chandranath Chatterjee, and Pallav Kumar
Deb. 2022.

</span>
<span class="ltx_bibblock">Data-Centric Client Selection for Federated
Learning over Distributed Edge Networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib46.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Parallel and Distributed
Systems</em> (2022), 1–12.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1109/TPDS.2022.3217271" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/TPDS.2022.3217271</a>

</span>
<span class="ltx_bibblock">Conference Name: IEEE Transactions on Parallel and Distributed
Systems.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shaheen et al<span id="bib.bib47.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Momina Shaheen,
Muhammad Shoaib Farooq, Tariq Umer, and
Byung-Seo Kim. 2022.

</span>
<span class="ltx_bibblock">Applications of Federated Learning; Taxonomy,
Challenges, and Research Trends.

</span>
<span class="ltx_bibblock"><em id="bib.bib47.3.1" class="ltx_emph ltx_font_italic">Electronics</em> 11,
4 (Jan. 2022),
670.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.3390/electronics11040670" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.3390/electronics11040670</a>

</span>
<span class="ltx_bibblock">Number: 4 Publisher: Multidisciplinary Digital Publishing Institute.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shi et al<span id="bib.bib48.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Fang Shi, Chunchao Hu,
Weiwei Lin, Lisheng Fan,
Tiansheng Huang, and Wentai Wu.
2022.

</span>
<span class="ltx_bibblock">VFedCS: Optimizing Client Selection for
Volatile Federated Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib48.3.1" class="ltx_emph ltx_font_italic">IEEE Internet of Things Journal</em>
(2022), 1–1.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1109/JIOT.2022.3195073" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/JIOT.2022.3195073</a>

</span>
<span class="ltx_bibblock">Conference Name: IEEE Internet of Things Journal.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tan et al<span id="bib.bib49.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Xavier Tan, Wei Chong Ng,
Wei Yang Bryan Lim, Zehui Xiong,
Dusit Niyato, and Han Yu.
2022.

</span>
<span class="ltx_bibblock">Reputation-Aware Federated Learning Client
Selection based on Stochastic Integer Programming.

</span>
<span class="ltx_bibblock"><em id="bib.bib49.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Big Data</em>
(2022), 1–12.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1109/TBDATA.2022.3191332" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/TBDATA.2022.3191332</a>

</span>
<span class="ltx_bibblock">Conference Name: IEEE Transactions on Big Data.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">van den Berg et al<span id="bib.bib50.2.2.1" class="ltx_text">.</span> (2013)</span>
<span class="ltx_bibblock">
Tobias van den Berg,
Martijn W. Heymans, Stephanie S. Leone,
David Vergouw, Jill A. Hayden,
Arianne P. Verhagen, and Henrica CW de
Vet. 2013.

</span>
<span class="ltx_bibblock">Overview of data-synthesis in systematic reviews of
studies on outcome prediction models.

</span>
<span class="ltx_bibblock"><em id="bib.bib50.3.1" class="ltx_emph ltx_font_italic">BMC Medical Research Methodology</em>
13, 1 (Dec.
2013), 1–10.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1186/1471-2288-13-42" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1186/1471-2288-13-42</a>

</span>
<span class="ltx_bibblock">Number: 1 Publisher: BioMed Central.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wan et al<span id="bib.bib51.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Wei Wan, Shengshan Hu,
Jianrong Lu, Leo Yu Zhang,
Hai Jin, and Yuanyuan He.
2022.

</span>
<span class="ltx_bibblock">Shielding Federated Learning: Robust
Aggregation with Adaptive Client Selection.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/arXiv.2204.13256" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2204.13256</a>

</span>
<span class="ltx_bibblock">arXiv:2204.13256 [cs].

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang and Kantarci (2020)</span>
<span class="ltx_bibblock">
Yuwei Wang and Burak
Kantarci. 2020.

</span>
<span class="ltx_bibblock">A Novel Reputation-aware Client Selection
Scheme for Federated Learning within Mobile Environments. In
<em id="bib.bib52.1.1" class="ltx_emph ltx_font_italic">2020 IEEE 25th International Workshop on
Computer Aided Modeling and Design of Communication Links and
Networks (CAMAD)</em>. 1–6.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/CAMAD50429.2020.9209263" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/CAMAD50429.2020.9209263</a>

</span>
<span class="ltx_bibblock">ISSN: 2378-4873.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Witt et al<span id="bib.bib53.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Leon Witt, Mathis Heyer,
Kentaroh Toyoda, Wojciech Samek, and
Dan Li. 2022.

</span>
<span class="ltx_bibblock">Decentral and Incentivized Federated Learning
Frameworks: A Systematic Literature Review.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/arXiv.2205.07855" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2205.07855</a>

</span>
<span class="ltx_bibblock">arXiv:2205.07855 [cs].

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wohlin (2014)</span>
<span class="ltx_bibblock">
Claes Wohlin.
2014.

</span>
<span class="ltx_bibblock">Guidelines for snowballing in systematic literature
studies and a replication in software engineering. In
<em id="bib.bib54.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 18th International
Conference on Evaluation and Assessment in Software Engineering -
EASE ’14</em>. ACM Press, London,
England, United Kingdom, 1–10.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/2601248.2601268" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/2601248.2601268</a>

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu and Wang (2021)</span>
<span class="ltx_bibblock">
Jie Xu and Heqiang
Wang. 2021.

</span>
<span class="ltx_bibblock">Client Selection and Bandwidth Allocation in
Wireless Federated Learning Networks: A Long-Term
Perspective.

</span>
<span class="ltx_bibblock"><em id="bib.bib55.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Wireless
Communications</em> 20, 2
(Feb. 2021), 1188–1200.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1109/TWC.2020.3031503" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/TWC.2020.3031503</a>

</span>
<span class="ltx_bibblock">Conference Name: IEEE Transactions on Wireless Communications.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al<span id="bib.bib56.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Miao Yang, Hua Qian,
Ximin Wang, Yong Zhou, and
Hongbin Zhu. 2022.

</span>
<span class="ltx_bibblock">Client Selection for Federated Learning
With Label Noise.

</span>
<span class="ltx_bibblock"><em id="bib.bib56.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Vehicular Technology</em>
71, 2 (Feb.
2022), 2193–2197.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1109/TVT.2021.3131852" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/TVT.2021.3131852</a>

</span>
<span class="ltx_bibblock">Conference Name: IEEE Transactions on Vehicular Technology.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al<span id="bib.bib57.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Liangkun Yu, Rana
Albelaihi, Xiang Sun, Nirwan Ansari,
and Michael Devetsikiotis.
2022.

</span>
<span class="ltx_bibblock">Jointly Optimizing Client Selection and
Resource Management in Wireless Federated Learning for Internet
of Things.

</span>
<span class="ltx_bibblock"><em id="bib.bib57.3.1" class="ltx_emph ltx_font_italic">IEEE Internet of Things Journal</em>
9, 6 (March
2022), 4385–4395.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1109/JIOT.2021.3103715" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/JIOT.2021.3103715</a>

</span>
<span class="ltx_bibblock">Conference Name: IEEE Internet of Things Journal.

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zeng et al<span id="bib.bib58.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Qunsong Zeng, Yuqing Du,
Kaibin Huang, and Kin K. Leung.
2020.

</span>
<span class="ltx_bibblock">Energy-Efficient Radio Resource Allocation
for Federated Edge Learning. In <em id="bib.bib58.3.1" class="ltx_emph ltx_font_italic">2020 IEEE
International Conference on Communications Workshops (ICC
Workshops)</em>. 1–6.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/ICCWorkshops49005.2020.9145118" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/ICCWorkshops49005.2020.9145118</a>

</span>
<span class="ltx_bibblock">ISSN: 2474-9133.

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span id="bib.bib59.2.2.1" class="ltx_text">.</span> (2021c)</span>
<span class="ltx_bibblock">
Hangjia Zhang, Zhijun
Xie, Roozbeh Zarei, Tao Wu, and
Kewei Chen. 2021c.

</span>
<span class="ltx_bibblock">Adaptive Client Selection in Resource
Constrained Federated Learning Systems: A Deep Reinforcement
Learning Approach.

</span>
<span class="ltx_bibblock"><em id="bib.bib59.3.1" class="ltx_emph ltx_font_italic">IEEE Access</em> 9
(2021), 98423–98432.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1109/ACCESS.2021.3095915" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/ACCESS.2021.3095915</a>

</span>
<span class="ltx_bibblock">Conference Name: IEEE Access.

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span id="bib.bib60.2.2.1" class="ltx_text">.</span> (2021a)</span>
<span class="ltx_bibblock">
Shulai Zhang, Zirui Li,
Quan Chen, Wenli Zheng,
Jingwen Leng, and Minyi Guo.
2021a.

</span>
<span class="ltx_bibblock">Dubhe: Towards Data Unbiasedness with
Homomorphic Encryption in Federated Learning Client Selection.
In <em id="bib.bib60.3.1" class="ltx_emph ltx_font_italic">50th International Conference on Parallel
Processing</em>. ACM, Lemont IL USA,
1–10.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3472456.3473513" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3472456.3473513</a>

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span id="bib.bib61.2.2.1" class="ltx_text">.</span> (2021b)</span>
<span class="ltx_bibblock">
Wenyu Zhang, Xiumin Wang,
Pan Zhou, Weiwei Wu, and
Xinglin Zhang. 2021b.

</span>
<span class="ltx_bibblock">Client Selection for Federated Learning
With Non-IID Data in Mobile Edge Computing.

</span>
<span class="ltx_bibblock"><em id="bib.bib61.3.1" class="ltx_emph ltx_font_italic">IEEE Access</em> 9
(2021), 24462–24474.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1109/ACCESS.2021.3056919" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/ACCESS.2021.3056919</a>

</span>
<span class="ltx_bibblock">Conference Name: IEEE Access.

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu et al<span id="bib.bib62.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Hongbin Zhu, Miao Yang,
Junqian Kuang, Hua Qian, and
Yong Zhou. 2022.

</span>
<span class="ltx_bibblock">Client Selection for Asynchronous Federated
Learning with Fairness Consideration. In
<em id="bib.bib62.3.1" class="ltx_emph ltx_font_italic">2022 IEEE International Conference on
Communications Workshops (ICC Workshops)</em>.
800–805.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/ICCWorkshops53468.2022.9814669" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/ICCWorkshops53468.2022.9814669</a>

</span>
<span class="ltx_bibblock">ISSN: 2694-2941.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2306.04861" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2306.04862" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2306.04862">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2306.04862" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2306.04863" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Mon Feb 26 20:43:46 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
