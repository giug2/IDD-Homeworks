<article class="ltx_document ltx_authors_1line">
 <h1 class="ltx_title ltx_title_document">
  Large Language Model based Multi-Agents: A Survey of Progress and Challenges
 </h1>
 <div class="ltx_authors">
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Taicheng Guo
    <sup class="ltx_sup" id="id14.2.id1">
     1
    </sup>
   </span>
  </span>
  <span class="ltx_author_before">
  </span>
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Xiuying Chen
    <sup class="ltx_sup" id="id15.2.id1">
     2
    </sup>
   </span>
  </span>
  <span class="ltx_author_before">
  </span>
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Yaqi Wang
    <sup class="ltx_sup" id="id16.2.id1">
     3
    </sup>
   </span>
   <span class="ltx_author_notes">
    This work was done when Yaqi and Ruidi were visiting students at the University of Notre Dame.
   </span>
  </span>
  <span class="ltx_author_before">
  </span>
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Ruidi Chang
    <sup class="ltx_sup" id="id17.2.id1">
     4
    </sup>
    <span class="ltx_note ltx_role_footnotemark" id="footnotex1">
     <sup class="ltx_note_mark">
      1
     </sup>
     <span class="ltx_note_outer">
      <span class="ltx_note_content">
       <sup class="ltx_note_mark">
        1
       </sup>
       <span class="ltx_note_type">
        footnotemark:
       </span>
       <span class="ltx_tag ltx_tag_note">
        1
       </span>
      </span>
     </span>
    </span>
   </span>
  </span>
  <span class="ltx_author_before">
  </span>
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Shichao Pei
    <sup class="ltx_sup" id="id18.2.id1">
     5
    </sup>
   </span>
  </span>
  <span class="ltx_author_before">
  </span>
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    <br class="ltx_break"/>
    Nitesh V. Chawla
    <sup class="ltx_sup" id="id19.2.id1">
     1
    </sup>
   </span>
  </span>
  <span class="ltx_author_before">
  </span>
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Olaf Wiest
    <sup class="ltx_sup" id="id20.2.id1">
     1
    </sup>
   </span>
  </span>
  <span class="ltx_author_before">
  </span>
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Xiangliang Zhang
    <sup class="ltx_sup" id="id21.7.id1">
     1
    </sup>
    <sup class="ltx_sup" id="id22.8.id2">
     1
    </sup>
    University of Notre Dame
    <br class="ltx_break"/>
    <sup class="ltx_sup" id="id23.9.id3">
     2
    </sup>
    King Abdullah University of Science and Technology
    <br class="ltx_break"/>
    <sup class="ltx_sup" id="id24.10.id4">
     3
    </sup>
    Southern University of Science and Technology
    <br class="ltx_break"/>
    <sup class="ltx_sup" id="id25.11.id5">
     4
    </sup>
    Unaffliated
    <br class="ltx_break"/>
    <sup class="ltx_sup" id="id26.12.id6">
     5
    </sup>
    University of Massachusetts Boston
{tguo2, nchawla, owiest, xzhang33}@nd.edu,
xiuying.chen@kaust.edu.sa,
ywang84@nd.edu, ruidic@alumni.cmu.edu, shichao.pei@umb.edu
   </span>
   <span class="ltx_author_notes">
    Corresponding author.
   </span>
  </span>
 </div>
 <div class="ltx_abstract">
  <h6 class="ltx_title ltx_title_abstract">
   Abstract
  </h6>
  <p class="ltx_p" id="id27.id1">
   Large Language Models (LLMs) have achieved remarkable success across a wide array of tasks. Due to the impressive planning and reasoning abilities of LLMs, they have been used as autonomous agents to do many tasks automatically. Recently, based on the development of using one LLM as a single planning or decision-making agent, LLM-based multi-agent systems have achieved considerable progress in complex problem-solving and world simulation.
To provide the community with an overview of this dynamic field, we present this survey to offer an in-depth discussion on the essential aspects of multi-agent systems based on LLMs, as well as the challenges. Our goal is for readers to gain substantial insights on the following questions: What domains and environments do LLM-based multi-agents simulate? How are these agents profiled and how do they communicate? What mechanisms contribute to the growth of agents’ capacities? For those interested in delving into this field of study, we also summarize the commonly used datasets or benchmarks for them to have convenient access. To keep researchers updated on the latest studies, we maintain an open-source
   <a class="ltx_ref ltx_href" href="https://github.com/taichengguo/LLM_MultiAgents_Survey_Papers" target="_blank" title="">
    GitHub repository
   </a>
   , dedicated to outlining the research on LLM-based multi-agent systems.
  </p>
 </div>
 <section class="ltx_section" id="S1">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    1
   </span>
   Introduction
  </h2>
  <div class="ltx_para" id="S1.p1">
   <p class="ltx_p" id="S1.p1.1">
    Large Language Models (LLMs) have recently shown remarkable potential in reaching a level of reasoning and planning capabilities comparable to humans.
This ability exactly aligns with the expectations of humans for autonomous agents that can perceive the surroundings, make decisions, and take actions in response
    <cite class="ltx_cite ltx_citemacro_cite">
     Xi
     <span class="ltx_text ltx_font_italic">
      et al.
     </span>
     (
     <a class="ltx_ref" href="#bib.bib70" title="">
      2023
     </a>
     ); Wooldridge and Jennings (
     <a class="ltx_ref" href="#bib.bib67" title="">
      1995
     </a>
     ); Russell and Norvig (
     <a class="ltx_ref" href="#bib.bib56" title="">
      2009
     </a>
     ); Guo
     <span class="ltx_text ltx_font_italic">
      et al.
     </span>
     (
     <a class="ltx_ref" href="#bib.bib22" title="">
      2023
     </a>
     ); Liang
     <span class="ltx_text ltx_font_italic">
      et al.
     </span>
     (
     <a class="ltx_ref" href="#bib.bib42" title="">
      2023
     </a>
     )
    </cite>
    . Hence, LLM-based agent has been studied and rapidly developed to understand and generate human-like instructions, facilitating sophisticated interactions and decision-making in a wide range of contexts
    <cite class="ltx_cite ltx_citemacro_cite">
     Yao
     <span class="ltx_text ltx_font_italic">
      et al.
     </span>
     (
     <a class="ltx_ref" href="#bib.bib77" title="">
      2023
     </a>
     ); Shinn
     <span class="ltx_text ltx_font_italic">
      et al.
     </span>
     (
     <a class="ltx_ref" href="#bib.bib57" title="">
      2023
     </a>
     ); Li
     <span class="ltx_text ltx_font_italic">
      et al.
     </span>
     (
     <a class="ltx_ref" href="#bib.bib37" title="">
      2023d
     </a>
     )
    </cite>
    . Timely survey papers systematically summarize the progress of LLM-based agents, as seen in works
    <cite class="ltx_cite ltx_citemacro_cite">
     Xi
     <span class="ltx_text ltx_font_italic">
      et al.
     </span>
     (
     <a class="ltx_ref" href="#bib.bib70" title="">
      2023
     </a>
     ); Wang
     <span class="ltx_text ltx_font_italic">
      et al.
     </span>
     (
     <a class="ltx_ref" href="#bib.bib62" title="">
      2023b
     </a>
     )
    </cite>
    .
   </p>
  </div>
  <figure class="ltx_figure" id="S1.F1">
   <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="582" id="S1.F1.1.g1" src="/html/2402.01680/assets/img/trend_example.png" width="857"/>
   <figcaption class="ltx_caption">
    <span class="ltx_tag ltx_tag_figure">
     Figure 1:
    </span>
    The rising trend in the research field of LLM-based Multi-Agents. For Problem Solving and World Simulation, we categorize current work into several categories and count the number of papers of different types at 3-month intervals. The number at each leaf node denotes the count of papers within that category.
   </figcaption>
  </figure>
  <div class="ltx_para" id="S1.p2">
   <p class="ltx_p" id="S1.p2.1">
    Based on the inspiring capabilities of the single LLM-based agent, LLM-based Multi-Agents have been proposed to leverage the collective intelligence and specialized profiles and skills of multiple agents.
    <span class="ltx_text" id="S1.p2.1.1" style="color:#000000;">
     Compared to systems using a single LLM-powered agent, multi-agent systems offer advanced capabilities by
     <span class="ltx_text ltx_framed ltx_framed_underline" id="S1.p2.1.1.1">
      1)
     </span>
     specializing LLMs into various distinct agents, each with different capabilities, and
     <span class="ltx_text ltx_framed ltx_framed_underline" id="S1.p2.1.1.2">
      2)
     </span>
     enabling interactions among these diverse agents to simulate complex real-world environments effectively. In this context, multiple autonomous agents collaboratively engage in planning, discussions, and decision-making, mirroring the cooperative nature of human group work in problem-solving tasks. This approach capitalizes on the communicative capabilities of LLMs, leveraging their ability to generate text for communication and respond to textual inputs. Furthermore, it exploits LLMs’ extensive knowledge across various domains and their latent potential to specialize in specific tasks. Recent research has demonstrated promising results in utilizing LLM-based multi-agents for solving various tasks,
    </span>
    such as software development
    <cite class="ltx_cite ltx_citemacro_cite">
     Hong
     <span class="ltx_text ltx_font_italic">
      et al.
     </span>
     (
     <a class="ltx_ref" href="#bib.bib24" title="">
      2023
     </a>
     ); Qian
     <span class="ltx_text ltx_font_italic">
      et al.
     </span>
     (
     <a class="ltx_ref" href="#bib.bib54" title="">
      2023
     </a>
     )
    </cite>
    , multi-robot systems
    <cite class="ltx_cite ltx_citemacro_cite">
     Mandi
     <span class="ltx_text ltx_font_italic">
      et al.
     </span>
     (
     <a class="ltx_ref" href="#bib.bib47" title="">
      2023
     </a>
     ); Zhang
     <span class="ltx_text ltx_font_italic">
      et al.
     </span>
     (
     <a class="ltx_ref" href="#bib.bib81" title="">
      2023c
     </a>
     )
    </cite>
    , society simulation
    <cite class="ltx_cite ltx_citemacro_cite">
     Park
     <span class="ltx_text ltx_font_italic">
      et al.
     </span>
     (
     <a class="ltx_ref" href="#bib.bib53" title="">
      2023
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib52" title="">
      2022
     </a>
     )
    </cite>
    , policy simulation
    <cite class="ltx_cite ltx_citemacro_cite">
     Xiao
     <span class="ltx_text ltx_font_italic">
      et al.
     </span>
     (
     <a class="ltx_ref" href="#bib.bib71" title="">
      2023
     </a>
     ); Hua
     <span class="ltx_text ltx_font_italic">
      et al.
     </span>
     (
     <a class="ltx_ref" href="#bib.bib26" title="">
      2023
     </a>
     )
    </cite>
    , and game simulation
    <cite class="ltx_cite ltx_citemacro_cite">
     Xu
     <span class="ltx_text ltx_font_italic">
      et al.
     </span>
     (
     <a class="ltx_ref" href="#bib.bib76" title="">
      2023c
     </a>
     ); Wang
     <span class="ltx_text ltx_font_italic">
      et al.
     </span>
     (
     <a class="ltx_ref" href="#bib.bib63" title="">
      2023c
     </a>
     )
    </cite>
    .
    <span class="ltx_text" id="S1.p2.1.2" style="color:#000000;">
     Due to the nature of interdisciplinary study in this field, it has attracted a diverse range of researchers, expanding beyond AI experts to include those from social science, psychology, and policy research. The volume of research papers is rapidly increasing,
    </span>
    as shown in Fig.
    <a class="ltx_ref" href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Large Language Model based Multi-Agents: A Survey of Progress and Challenges">
     <span class="ltx_text ltx_ref_tag">
      1
     </span>
    </a>
    (inspired by the design in
    <cite class="ltx_cite ltx_citemacro_cite">
     Gao
     <span class="ltx_text ltx_font_italic">
      et al.
     </span>
     (
     <a class="ltx_ref" href="#bib.bib19" title="">
      2023b
     </a>
     )
    </cite>
    ),
thus broadening the impact of LLM-based Multi-Agent research.
Nonetheless, earlier efforts were undertaken independently, resulting in an absence of a systematic review to summarize them, establish comprehensive
    <span class="ltx_text" id="S1.p2.1.3" style="color:#000000;">
     blueprint of this field
    </span>
    , and examine future research challenges. This underscores the significance of our work and serves as the motivation behind presenting this survey paper, dedicated to the research on LLM-based multi-agent systems.
   </p>
  </div>
  <div class="ltx_para" id="S1.p3">
   <p class="ltx_p" id="S1.p3.1">
    We expect that our survey can make significant contributions to both the research and development of LLMs and to a wider range of interdisciplinary studies employing LLMs. Readers will gain a comprehensive overview of LLM-based Multi-Agent (LLM-MA) systems, grasp the fundamental concepts involved in establishing multi-agent systems based on LLMs, and catch the latest research trends and applications in this dynamic field. We recognize that this field is in its early stages and is rapidly evolving with fresh methodologies and applications. To provide a sustainable resource complementing our survey paper, we maintain an open-source GitHub repository
    <span class="ltx_note ltx_role_footnote" id="footnote1">
     <sup class="ltx_note_mark">
      1
     </sup>
     <span class="ltx_note_outer">
      <span class="ltx_note_content">
       <sup class="ltx_note_mark">
        1
       </sup>
       <span class="ltx_tag ltx_tag_note">
        1
       </span>
       <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/taichengguo/LLM_MultiAgents_Survey_Papers" style="font-size:70%;" target="_blank" title="">
        https://github.com/taichengguo/LLM_MultiAgents_Survey_Papers
       </a>
      </span>
     </span>
    </span>
    .
We hope that our survey will inspire further exploration and innovation in this field,
as well as applications across a wide array of research disciplines.
   </p>
  </div>
  <div class="ltx_para" id="S1.p4">
   <p class="ltx_p" id="S1.p4.1">
    To assist individuals from various backgrounds in understanding LLM-MA techniques and to complement existing surveys by tackling unresolved questions, we have organized our survey paper in the following manner. After laying out the background knowledge in Section
    <a class="ltx_ref" href="#S2" title="2 Background ‣ Large Language Model based Multi-Agents: A Survey of Progress and Challenges">
     <span class="ltx_text ltx_ref_tag">
      2
     </span>
    </a>
    , we address a pivotal question:
    <em class="ltx_emph ltx_font_italic" id="S1.p4.1.1">
     How are LLM-MA systems aligned with the collaborative task-solving environment
    </em>
    ? To answer this, we present a comprehensive schema for positioning, differentiating, and connecting various aspects of LLM-MA systems in
    <span class="ltx_text ltx_font_bold" id="S1.p4.1.2">
     Section
     <a class="ltx_ref" href="#S3" title="3 Dissecting LLM-MA Systems: Interface, Profiling, Communication, and Capabilities ‣ Large Language Model based Multi-Agents: A Survey of Progress and Challenges">
      <span class="ltx_text ltx_ref_tag">
       3
      </span>
     </a>
    </span>
    . We delve into this question by discussing: 1) the
    <span class="ltx_text ltx_font_bold" id="S1.p4.1.3">
     agents-environment interface
    </span>
    , which details how agents interact with the task environment; 2)
    <span class="ltx_text ltx_font_bold" id="S1.p4.1.4">
     agent profiling
    </span>
    , which explains how an agent is characterized by an LLM to behave in specific ways; 3)
    <span class="ltx_text ltx_font_bold" id="S1.p4.1.5">
     agent communication
    </span>
    , which examines how agents exchange messages and collaborate; and 4)
    <span class="ltx_text ltx_font_bold" id="S1.p4.1.6">
     agent capability acquisition
    </span>
    , which explores how agents develop their abilities to effectively solve problems.
An additional perspective for reviewing studies about LLM-MA is their application. In
    <span class="ltx_text ltx_font_bold" id="S1.p4.1.7">
     Section
     <a class="ltx_ref" href="#S4" title="4 Applications ‣ Large Language Model based Multi-Agents: A Survey of Progress and Challenges">
      <span class="ltx_text ltx_ref_tag">
       4
      </span>
     </a>
    </span>
    , we categorize current
    <span class="ltx_text ltx_font_bold" id="S1.p4.1.8">
     applications
    </span>
    into two primary streams: multi-agents for
    <span class="ltx_text ltx_font_bold" id="S1.p4.1.9">
     problem-solving
    </span>
    and multi-agents for
    <span class="ltx_text ltx_font_bold" id="S1.p4.1.10">
     world simulation
    </span>
    .
To guide individuals in identifying appropriate
    <span class="ltx_text ltx_font_bold" id="S1.p4.1.11">
     tools and resources
    </span>
    , we present open-source implementation frameworks for studying LLM-MA, as well as the usable datasets and benchmarks in
    <span class="ltx_text ltx_font_bold" id="S1.p4.1.12">
     Section
     <a class="ltx_ref" href="#S5" title="5 Implementation Tools and Resources ‣ Large Language Model based Multi-Agents: A Survey of Progress and Challenges">
      <span class="ltx_text ltx_ref_tag">
       5
      </span>
     </a>
    </span>
    .
Based on the previous summary, we open the discussion for future research challenges and opportunities in Section
    <a class="ltx_ref" href="#S6" title="6 Challenges and Opportunities ‣ Large Language Model based Multi-Agents: A Survey of Progress and Challenges">
     <span class="ltx_text ltx_ref_tag">
      6
     </span>
    </a>
    . The conclusions are summarized in Section
    <a class="ltx_ref" href="#S7" title="7 Conclusion ‣ Large Language Model based Multi-Agents: A Survey of Progress and Challenges">
     <span class="ltx_text ltx_ref_tag">
      7
     </span>
    </a>
    .
   </p>
  </div>
 </section>
 <section class="ltx_section" id="S2">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    2
   </span>
   Background
  </h2>
  <section class="ltx_subsection" id="S2.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     2.1
    </span>
    Single-Agent Systems Powered LLMs
   </h3>
   <div class="ltx_para" id="S2.SS1.p1">
    <p class="ltx_p" id="S2.SS1.p1.1">
     We introduce the background by first outlining the capabilities of a single-agent system based on LLMs, following the discussion presented in
     <cite class="ltx_cite ltx_citemacro_cite">
      Weng (
      <a class="ltx_ref" href="#bib.bib65" title="">
       2023
      </a>
      )
     </cite>
     .
    </p>
   </div>
   <section class="ltx_paragraph" id="S2.SS1.SSS0.Px1">
    <h5 class="ltx_title ltx_title_paragraph">
     Decision-making Thought:
    </h5>
    <div class="ltx_para" id="S2.SS1.SSS0.Px1.p1">
     <p class="ltx_p" id="S2.SS1.SSS0.Px1.p1.1">
      This term denotes the capability of LLM-based agents, guided by prompts, to break down complex tasks into smaller subgoals
      <cite class="ltx_cite ltx_citemacro_cite">
       Khot
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib30" title="">
        2023
       </a>
       )
      </cite>
      , think through each part methodically (sometimes exploring multiple paths)
      <cite class="ltx_cite ltx_citemacro_cite">
       Yao
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib77" title="">
        2023
       </a>
       )
      </cite>
      , and learn from past experiences
      <cite class="ltx_cite ltx_citemacro_cite">
       Shinn
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib57" title="">
        2023
       </a>
       )
      </cite>
      to perform better decision-making on complex tasks. This capability enhances the autonomy of a single LLM-based agent and bolsters its effectiveness in problem-solving.
     </p>
    </div>
   </section>
   <section class="ltx_paragraph" id="S2.SS1.SSS0.Px2">
    <h5 class="ltx_title ltx_title_paragraph">
     Tool-use:
    </h5>
    <div class="ltx_para" id="S2.SS1.SSS0.Px2.p1">
     <p class="ltx_p" id="S2.SS1.SSS0.Px2.p1.1">
      LLM-based agents’ tool-use capability allows them to leverage external tools and resources to accomplish tasks, enhancing their functional capabilities and operate more effectively in diverse and dynamic environments
      <cite class="ltx_cite ltx_citemacro_cite">
       Li
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib37" title="">
        2023d
       </a>
       ); Ruan
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib55" title="">
        2023
       </a>
       ); Gao
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib19" title="">
        2023b
       </a>
       )
      </cite>
      .
     </p>
    </div>
   </section>
   <section class="ltx_paragraph" id="S2.SS1.SSS0.Px3">
    <h5 class="ltx_title ltx_title_paragraph">
     Memory:
    </h5>
    <div class="ltx_para" id="S2.SS1.SSS0.Px3.p1">
     <p class="ltx_p" id="S2.SS1.SSS0.Px3.p1.1">
      This ability refers to the capability of LLM-based agent for conducting in-context learning
      <cite class="ltx_cite ltx_citemacro_cite">
       Dong
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib13" title="">
        2023a
       </a>
       )
      </cite>
      as short memory or external vector database
      <cite class="ltx_cite ltx_citemacro_cite">
       Lewis
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib32" title="">
        2021
       </a>
       )
      </cite>
      as long memory to preserve and retrieve information over prolonged periods
      <cite class="ltx_cite ltx_citemacro_cite">
       Wang
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib62" title="">
        2023b
       </a>
       )
      </cite>
      . This ability enables a single LLM-based agent to maintain contextual coherence and enhance learning from interactions.
     </p>
    </div>
   </section>
  </section>
  <section class="ltx_subsection" id="S2.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     2.2
    </span>
    Single-Agent VS. Multi-Agent Systems
   </h3>
   <div class="ltx_para" id="S2.SS2.p1">
    <p class="ltx_p" id="S2.SS2.p1.1">
     Single-Agent systems empowered by LLMs have shown inspiring cognitive abilities
     <cite class="ltx_cite ltx_citemacro_cite">
      Sumers
      <span class="ltx_text ltx_font_italic">
       et al.
      </span>
      (
      <a class="ltx_ref" href="#bib.bib58" title="">
       2023
      </a>
      )
     </cite>
     .
The construction of such systems concentrates on formulating their internal mechanisms and interactions with the external environment. Conversely,
LLM-MA systems emphasize diverse agent profiles, inter-agent interactions, and collective decision-making processes. From this perspective, more dynamic and complex tasks can be tackled by the collaboration of multiple autonomous agents, each of which is equipped with unique strategies and behaviors, and engaged in communication with one another.
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="S3">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    3
   </span>
   Dissecting LLM-MA Systems: Interface, Profiling, Communication, and Capabilities
  </h2>
  <div class="ltx_para" id="S3.p1">
   <p class="ltx_p" id="S3.p1.1">
    In this section, we delve into the intricacies of LLM-MA systems, where multiple autonomous agents engage in collaborative activities akin to human group dynamics in problem-solving scenarios.
    <span class="ltx_text" id="S3.p1.1.1" style="color:#000000;">
     A critical inquiry we address is how these LLM-MA systems are aligned to their operational environments and the collective objectives they are designed to achieve. To shed light on this, we present the general architecture of these systems in Fig.
     <a class="ltx_ref" href="#S3.F2" title="Figure 2 ‣ 3 Dissecting LLM-MA Systems: Interface, Profiling, Communication, and Capabilities ‣ Large Language Model based Multi-Agents: A Survey of Progress and Challenges">
      <span class="ltx_text ltx_ref_tag">
       2
      </span>
     </a>
     .
    </span>
    Our analysis dissects the operational framework of these systems, focusing on four key aspects: the agents-environment interface, agent profiling, agent communication, and agent capability acquisition.
   </p>
  </div>
  <figure class="ltx_figure" id="S3.F2">
   <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="299" id="S3.F2.g1" src="/html/2402.01680/assets/img/LLM-MA.png" width="437"/>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     Figure 2:
    </span>
    The Architecture of LLM-MA Systems.
   </figcaption>
  </figure>
  <section class="ltx_subsection" id="S3.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     3.1
    </span>
    Agents-Environment Interface
   </h3>
   <div class="ltx_para" id="S3.SS1.p1">
    <p class="ltx_p" id="S3.SS1.p1.1">
     <span class="ltx_text" id="S3.SS1.p1.1.1" style="color:#000000;">
      The operational environments defines the specific contexts or settings in which the LLM-MA systems are deployed and interact.
For example, these environments can be like software development
      <cite class="ltx_cite ltx_citemacro_cite">
       Hong
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib24" title="">
        2023
       </a>
       )
      </cite>
      , gaming
      <cite class="ltx_cite ltx_citemacro_cite">
       Mao
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib48" title="">
        2023
       </a>
       )
      </cite>
      , and various other domains such as financial markets
      <cite class="ltx_cite ltx_citemacro_cite">
       Li
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib40" title="">
        2023g
       </a>
       )
      </cite>
      or even social behavior modeling
      <cite class="ltx_cite ltx_citemacro_cite">
       Park
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib53" title="">
        2023
       </a>
       )
      </cite>
      . The LLM-based agents perceive and act within the environment, which in turn influences their behavior and decision making. For example, in the Werewolf Game simulation, the sandbox environment sets the game’s framework, including transitions from day to night, discussion periods, voting mechanics, and reward rules. Agents, such as werewolves and the Seer, perform specific actions like killing or checking roles. Following these actions, agents receive feedback from the environment, informing them of the game’s current state. This information guides the agents in adjusting their strategies over time, responding to the evolving gameplay and interactions with other agents.
     </span>
     The Agents-Environment Interface refers to the way in which agents interact with and perceive the environment. It’s through this interface that agents understand their surroundings, make decisions, and learn from the outcomes of their actions.
We categorize the current interfaces in LLM-MA systems into three types,
     <em class="ltx_emph ltx_font_italic" id="S3.SS1.p1.1.2">
      Sandbox, Physcial
     </em>
     , and
     <em class="ltx_emph ltx_font_italic" id="S3.SS1.p1.1.3">
      None
     </em>
     , as detailed in Table
     <a class="ltx_ref" href="#S3.T1" title="Table 1 ‣ Agents Adjustment to Complex Problems: ‣ 3.4 Agents Capabilities Acquisition ‣ 3 Dissecting LLM-MA Systems: Interface, Profiling, Communication, and Capabilities ‣ Large Language Model based Multi-Agents: A Survey of Progress and Challenges">
      <span class="ltx_text ltx_ref_tag">
       1
      </span>
     </a>
     .
The
     <em class="ltx_emph ltx_font_bold ltx_font_italic" id="S3.SS1.p1.1.4">
      Sandbox
     </em>
     refers to a simulated or virtual environment built by human where agents can interact more freely and experiment with various actions and strategies. This kind of interface is widely used in software development (code interpreter as simulated environment)
     <cite class="ltx_cite ltx_citemacro_cite">
      Hong
      <span class="ltx_text ltx_font_italic">
       et al.
      </span>
      (
      <a class="ltx_ref" href="#bib.bib24" title="">
       2023
      </a>
      )
     </cite>
     , gaming (using game rules as simulated environment)
     <cite class="ltx_cite ltx_citemacro_cite">
      Mao
      <span class="ltx_text ltx_font_italic">
       et al.
      </span>
      (
      <a class="ltx_ref" href="#bib.bib48" title="">
       2023
      </a>
      )
     </cite>
     , etc. The
     <em class="ltx_emph ltx_font_bold ltx_font_italic" id="S3.SS1.p1.1.5">
      Physical
     </em>
     is a real-world environment where agents interact with physical entities and obey real-world physics and constraints. In physical space, agents normally need to take actions that can have direct physical outcomes. For example, in tasks such as sweeping the floor, making sandwiches, packing groceries, and arranging cabinets, robotic agents are required to perform actions iteratively, observe the physical environment, and continuously refine their actions
     <cite class="ltx_cite ltx_citemacro_cite">
      Mandi
      <span class="ltx_text ltx_font_italic">
       et al.
      </span>
      (
      <a class="ltx_ref" href="#bib.bib47" title="">
       2023
      </a>
      )
     </cite>
     . Lastly,
     <em class="ltx_emph ltx_font_bold ltx_font_italic" id="S3.SS1.p1.1.6">
      None
     </em>
     refers to scenarios where there is no specific external environment, and agents do not interact with any environment. For example, many applications
     <cite class="ltx_cite ltx_citemacro_cite">
      Du
      <span class="ltx_text ltx_font_italic">
       et al.
      </span>
      (
      <a class="ltx_ref" href="#bib.bib15" title="">
       2023
      </a>
      ); Xiong
      <span class="ltx_text ltx_font_italic">
       et al.
      </span>
      (
      <a class="ltx_ref" href="#bib.bib73" title="">
       2023
      </a>
      ); Chan
      <span class="ltx_text ltx_font_italic">
       et al.
      </span>
      (
      <a class="ltx_ref" href="#bib.bib5" title="">
       2023
      </a>
      )
     </cite>
     utilize multiple agents to debate a question to reach a consensus. These applications primarily focus on communication among agents and do not depend on the external environment.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S3.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     3.2
    </span>
    Agents Profiling
   </h3>
   <div class="ltx_para" id="S3.SS2.p1">
    <p class="ltx_p" id="S3.SS2.p1.1">
     In LLM-MA systems, agents are defined by their traits, actions, and skills, which are tailored to meet specific goals. Across various systems, agents assume distinct roles, each with comprehensive descriptions encompassing characteristics, capabilities, behaviors, and constraints. For instance, in gaming environments, agents might be profiled as players with varying roles and skills, each contributing differently to the game’s objectives. In software development, agents could take on the roles of product managers and engineers, each with responsibilities and expertise that guide the development process. Similarly, in a debating platform, agents might be designated as proponents, opponents, or judges, each with unique functions and strategies to fulfill their roles effectively. These profiles are crucial for defining the agents’ interactions and effectiveness within their respective environments. Table
     <a class="ltx_ref" href="#S3.T1" title="Table 1 ‣ Agents Adjustment to Complex Problems: ‣ 3.4 Agents Capabilities Acquisition ‣ 3 Dissecting LLM-MA Systems: Interface, Profiling, Communication, and Capabilities ‣ Large Language Model based Multi-Agents: A Survey of Progress and Challenges">
      <span class="ltx_text ltx_ref_tag">
       1
      </span>
     </a>
     lists the agent
     <em class="ltx_emph ltx_font_bold ltx_font_italic" id="S3.SS2.p1.1.1">
      Profiles
     </em>
     in recent LLM-MA works.
    </p>
   </div>
   <div class="ltx_para" id="S3.SS2.p2">
    <p class="ltx_p" id="S3.SS2.p2.1">
     Regarding the
     <em class="ltx_emph ltx_font_bold ltx_font_italic" id="S3.SS2.p2.1.1">
      Agent Profiling Methods
     </em>
     , we
categorized them into three types:
     <em class="ltx_emph ltx_font_italic" id="S3.SS2.p2.1.2">
      Pre-defined, Model-Generated
     </em>
     , and
     <em class="ltx_emph ltx_font_italic" id="S3.SS2.p2.1.3">
      Data-Derived
     </em>
     .
In the
     <em class="ltx_emph ltx_font_bold ltx_font_italic" id="S3.SS2.p2.1.4">
      Pre-defined
     </em>
     cases, agent profiles are explicitly defined by the system designers.
The
     <em class="ltx_emph ltx_font_bold ltx_font_italic" id="S3.SS2.p2.1.5">
      Model-Generated
     </em>
     method creates agent profiles by models, e.g., large language models. The
     <em class="ltx_emph ltx_font_bold ltx_font_italic" id="S3.SS2.p2.1.6">
      Data-Derived
     </em>
     method involves constructing agent profiles based on pre-existing datasets.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S3.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     3.3
    </span>
    Agents Communication
   </h3>
   <div class="ltx_para" id="S3.SS3.p1">
    <p class="ltx_p" id="S3.SS3.p1.1">
     The communication between agents in LLM-MA systems is the critical infrastructure supporting collective intelligence. We dissect agent communication from three perspectives: 1)
     <em class="ltx_emph ltx_font_italic" id="S3.SS3.p1.1.1">
      Communication Paradigms
     </em>
     : the styles and methods of interaction between agents; 2)
     <em class="ltx_emph ltx_font_italic" id="S3.SS3.p1.1.2">
      Communication Structure
     </em>
     : the organization and architecture of communication networks within the multi-agent system; and 3)
     <em class="ltx_emph ltx_font_italic" id="S3.SS3.p1.1.3">
      Communication Content
     </em>
     exchanged between agents.
    </p>
   </div>
   <section class="ltx_paragraph" id="S3.SS3.SSS0.Px1">
    <h5 class="ltx_title ltx_title_paragraph">
     Communication Paradigms:
    </h5>
    <div class="ltx_para" id="S3.SS3.SSS0.Px1.p1">
     <p class="ltx_p" id="S3.SS3.SSS0.Px1.p1.1">
      Current LLM-MA systems mainly take three paradigms for communication:
      <em class="ltx_emph ltx_font_italic" id="S3.SS3.SSS0.Px1.p1.1.1">
       Cooperative
      </em>
      ,
      <em class="ltx_emph ltx_font_italic" id="S3.SS3.SSS0.Px1.p1.1.2">
       Debate
      </em>
      , and
      <em class="ltx_emph ltx_font_italic" id="S3.SS3.SSS0.Px1.p1.1.3">
       Competitive
      </em>
      .
      <em class="ltx_emph ltx_font_bold ltx_font_italic" id="S3.SS3.SSS0.Px1.p1.1.4">
       Cooperative
      </em>
      agents work together towards a shared goal or objectives, typically exchanging information to enhance a collective solution. The
      <em class="ltx_emph ltx_font_bold ltx_font_italic" id="S3.SS3.SSS0.Px1.p1.1.5">
       Debate
      </em>
      paradigm is employed when agents engage in argumentative interactions, presenting and defending their own viewpoints or solutions, and critiquing those of others. This paradigm is ideal for reaching a consensus or a more refined solution.
      <em class="ltx_emph ltx_font_bold ltx_font_italic" id="S3.SS3.SSS0.Px1.p1.1.6">
       Competitive
      </em>
      agents work towards their own goals that might be in conflict with the goals of other agents.
     </p>
    </div>
    <figure class="ltx_figure" id="S3.F3">
     <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="243" id="S3.F3.g1" src="/html/2402.01680/assets/img/Agent_communication.png" width="264"/>
     <figcaption class="ltx_caption ltx_centering">
      <span class="ltx_tag ltx_tag_figure">
       Figure 3:
      </span>
      The Agent Communication Structure.
     </figcaption>
    </figure>
   </section>
   <section class="ltx_paragraph" id="S3.SS3.SSS0.Px2">
    <h5 class="ltx_title ltx_title_paragraph">
     Communication Structure:
    </h5>
    <div class="ltx_para" id="S3.SS3.SSS0.Px2.p1">
     <p class="ltx_p" id="S3.SS3.SSS0.Px2.p1.1">
      Fig.
      <a class="ltx_ref" href="#S3.F3" title="Figure 3 ‣ Communication Paradigms: ‣ 3.3 Agents Communication ‣ 3 Dissecting LLM-MA Systems: Interface, Profiling, Communication, and Capabilities ‣ Large Language Model based Multi-Agents: A Survey of Progress and Challenges">
       <span class="ltx_text ltx_ref_tag">
        3
       </span>
      </a>
      shows four typical communication structures in LLM-MA systems.
      <em class="ltx_emph ltx_font_bold ltx_font_italic" id="S3.SS3.SSS0.Px2.p1.1.1">
       Layered
      </em>
      communication is structured hierarchically, with agents at each level having distinct roles and primarily interacting within their layer or with adjacent layers.
      <cite class="ltx_cite ltx_citemacro_cite">
       Liu
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib45" title="">
        2023
       </a>
       )
      </cite>
      introduces a framework called Dynamic LLM-Agent Network (DyLAN), which organizes agents in a multi-layered feed-forward network. This setup facilitates dynamic interactions, incorporating features like inference-time agent selection and an early-stopping mechanism, which collectively enhance the efficiency of cooperation among agents.
      <em class="ltx_emph ltx_font_bold ltx_font_italic" id="S3.SS3.SSS0.Px2.p1.1.2">
       Decentralized
      </em>
      communication operates on a peer-to-peer network, where agents directly communicate with each other, a structure commonly employed in world simulation applications.
      <em class="ltx_emph ltx_font_bold ltx_font_italic" id="S3.SS3.SSS0.Px2.p1.1.3">
       Centralized
      </em>
      communication involves a central agent or a group of central agents coordinating the system’s communication, with other agents primarily interacting through this central node.
      <em class="ltx_emph ltx_font_bold ltx_font_italic" id="S3.SS3.SSS0.Px2.p1.1.4">
       Shared Message Pool
      </em>
      is proposed by MetaGPT
      <cite class="ltx_cite ltx_citemacro_cite">
       Hong
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib24" title="">
        2023
       </a>
       )
      </cite>
      to improve the communication efficiency. This communication structure maintains a shared message pool where agents publish messages and subscribe to relevant messages based on their profiles, thereby boosting communication efficiency.
     </p>
    </div>
   </section>
   <section class="ltx_paragraph" id="S3.SS3.SSS0.Px3">
    <h5 class="ltx_title ltx_title_paragraph">
     Communication Content:
    </h5>
    <div class="ltx_para" id="S3.SS3.SSS0.Px3.p1">
     <p class="ltx_p" id="S3.SS3.SSS0.Px3.p1.1">
      In LLM-MA systems, the Communication Content typically takes the form of text. The specific content varies widely and depends on the particular application. For example, in software development, agents may communicate with each other about code segments. In simulations of games like Werewolf, agents might discuss their analyses, suspicions, or strategies.
     </p>
    </div>
   </section>
  </section>
  <section class="ltx_subsection" id="S3.SS4">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     3.4
    </span>
    Agents Capabilities Acquisition
   </h3>
   <div class="ltx_para" id="S3.SS4.p1">
    <p class="ltx_p" id="S3.SS4.p1.1">
     The Agents Capabilities Acquisition is a crucial process in LLM-MA, enabling agents to learn and evolve dynamically. In this context, there are two fundamental concepts: the types of
     <em class="ltx_emph ltx_font_bold ltx_font_italic" id="S3.SS4.p1.1.1">
      feedback
     </em>
     from which agents should learn to enhance their capabilities, and the
     <em class="ltx_emph ltx_font_bold ltx_font_italic" id="S3.SS4.p1.1.2">
      strategies
     </em>
     for agents to
     <em class="ltx_emph ltx_font_bold ltx_font_italic" id="S3.SS4.p1.1.3">
      adjust
     </em>
     themselves to effectively solve complex problems.
    </p>
   </div>
   <section class="ltx_paragraph" id="S3.SS4.SSS0.Px1">
    <h5 class="ltx_title ltx_title_paragraph">
     Feedback:
    </h5>
    <div class="ltx_para" id="S3.SS4.SSS0.Px1.p1">
     <p class="ltx_p" id="S3.SS4.SSS0.Px1.p1.1">
      Feedback involves the critical information that agents receive about the outcome of their actions, helping the agents learn the potential impact of their actions and adapt to complex and dynamic problems. In most studies, the format of feedback provided to agents is textual. Based on the sources from which agents receive this feedback, it can be categorized into four types.
      <span class="ltx_text ltx_font_bold" id="S3.SS4.SSS0.Px1.p1.1.1">
       1) Feedback from Environment
      </span>
      , e.g., from either real world environments or virtual environments
      <cite class="ltx_cite ltx_citemacro_cite">
       Wang
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib62" title="">
        2023b
       </a>
       )
      </cite>
      . It is prevalent in most LLM-MA for problem-solving scenarios, including Software Development (agents obtain feedback from Code Interpreter), and Embodied multi-agents systems (robots obtain feedback from real-world or Simulated environments).
      <span class="ltx_text ltx_font_bold" id="S3.SS4.SSS0.Px1.p1.1.2">
       2) Feedback from Agents Interactions
      </span>
      means that the feedback comes from the judgement of other agents or from agents communications. It is common in problem-solving scenarios like science debates, where agents learn to critically evaluate and refine the conclusions through communications. In world simulation scenarios such as Game Simulation, agents learn to refine strategies based on previous interactions between other agents.
      <span class="ltx_text ltx_font_bold" id="S3.SS4.SSS0.Px1.p1.1.3">
       3) Human Feedback
      </span>
      comes directly from humans and is crucial for aligning the multi-agent system with human values and preferences. This kind of feedback is widely used in most “Human-in-the-loop” applications
      <cite class="ltx_cite ltx_citemacro_cite">
       Wang
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib60" title="">
        2021
       </a>
       )
      </cite>
      . Last
      <span class="ltx_text ltx_font_bold" id="S3.SS4.SSS0.Px1.p1.1.4">
       4) None
      </span>
      . In some cases, there is no feedback provided to the agents. This often happens for world simulation works focused on analyzing simulated results rather than the planning capabilities of agents. In such scenarios, like propagation simulation, the emphasis is on result analysis, and hence, feedback is not a component of the system.
     </p>
    </div>
   </section>
   <section class="ltx_paragraph" id="S3.SS4.SSS0.Px2">
    <h5 class="ltx_title ltx_title_paragraph">
     Agents Adjustment to Complex Problems:
    </h5>
    <div class="ltx_para" id="S3.SS4.SSS0.Px2.p1">
     <p class="ltx_p" id="S3.SS4.SSS0.Px2.p1.1">
      To enhance their capabilities, agents in LLM-MA systems can adapt through three main solutions.
      <span class="ltx_text ltx_font_bold" id="S3.SS4.SSS0.Px2.p1.1.1">
       1) Memory.
      </span>
      Most LLM-MA systems leverage a memory module for agents to adjust their behavior. Agents store information from previous interactions and feedback in their memory. When performing actions, they can retrieve relevant, valuable memories, particularly those containing successful actions for similar past goals, as highlighted in
      <cite class="ltx_cite ltx_citemacro_cite">
       Wang
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib62" title="">
        2023b
       </a>
       )
      </cite>
      . This process aids in enhancing their current actions.
      <span class="ltx_text ltx_font_bold" id="S3.SS4.SSS0.Px2.p1.1.2">
       2) Self-Evolution.
      </span>
      Instead of only relying on the historical records to decide subsequent actions as seen in
      <em class="ltx_emph ltx_font_italic" id="S3.SS4.SSS0.Px2.p1.1.3">
       Memory
      </em>
      -based solutions, agents can dynamically self-evolve by modifying themselves such as altering their initial goals and planning strategies, and training themselves based on feedback or communication logs.
      <cite class="ltx_cite ltx_citemacro_cite">
       Nascimento
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib51" title="">
        2023
       </a>
       )
      </cite>
      proposes a self-control loop process to allow each agent in the multi-agents systems to be self-managed and self-adaptive to dynamic environments, thereby improving the cooperation efficiency of multiple agents.
      <cite class="ltx_cite ltx_citemacro_cite">
       Zhang
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib80" title="">
        2023b
       </a>
       )
      </cite>
      introduces ProAgent which anticipates teammates’ decisions and dynamically adjusts each agent’s strategies based on the communication logs between agents, facilitating mutual understanding and improving collaborative planning capability.
      <cite class="ltx_cite ltx_citemacro_cite">
       Wang
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib61" title="">
        2023a
       </a>
       )
      </cite>
      discusses a
      <em class="ltx_emph ltx_font_italic" id="S3.SS4.SSS0.Px2.p1.1.4">
       Learning through Communication
      </em>
      (LTC) paradigm, using the communication logs of multi-agents to generate datasets to train or fine-tune LLMs. LTC enables continuous adaptation and improvement of agents through interaction with their environments and other agents, breaking the limits of in-context learning or supervised fine-tuning, which don’t fully utilize the feedback received during interactions with the environment and external tools for continuous training. Self-Evolution enables agents’ autonomous adjustment in their profiles or goals, rather than just learning from historical interactions.
      <span class="ltx_text ltx_font_bold" id="S3.SS4.SSS0.Px2.p1.1.5">
       3) Dynamic Generation.
      </span>
      In some scenarios, the system can generate new agents on-the-fly during its operation
      <cite class="ltx_cite ltx_citemacro_cite">
       Chen
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib6" title="">
        2023a
       </a>
       ,
       <a class="ltx_ref" href="#bib.bib8" title="">
        c
       </a>
       )
      </cite>
      . This capability enables the system to scale and adapt effectively, as it can introduce agents that are specifically designed to address current needs and challenges.
     </p>
    </div>
    <div class="ltx_para" id="S3.SS4.SSS0.Px2.p2">
     <p class="ltx_p" id="S3.SS4.SSS0.Px2.p2.1">
      With the scaling up LLM-MA with a larger number of agents, the escalating complexity of managing various kinds of agents has been a critical problem.
      <em class="ltx_emph ltx_font_italic" id="S3.SS4.SSS0.Px2.p2.1.1">
       Agents Orchestration
      </em>
      emerged as a pivotal challenge and began to gain attention in
      <cite class="ltx_cite ltx_citemacro_cite">
       Moura (
       <a class="ltx_ref" href="#bib.bib49" title="">
        2023
       </a>
       ); Dibia (
       <a class="ltx_ref" href="#bib.bib12" title="">
        2023
       </a>
       )
      </cite>
      . We will further discuss this topic in Section
      <a class="ltx_ref" href="#S6.SS4" title="6.4 Scaling Up LLM-MA Systems ‣ 6 Challenges and Opportunities ‣ Large Language Model based Multi-Agents: A Survey of Progress and Challenges">
       <span class="ltx_text ltx_ref_tag">
        6.4
       </span>
      </a>
      .
     </p>
    </div>
    <figure class="ltx_table" id="S3.T1">
     <div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S3.T1.1" style="width:649.7pt;height:867.2pt;vertical-align:-0.6pt;">
      <span class="ltx_transformed_inner" style="transform:translate(-225.8pt,301.1pt) scale(0.59,0.59) ;">
       <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1">
        <tbody class="ltx_tbody">
         <tr class="ltx_tr" id="S3.T1.1.1.1.1">
          <td class="ltx_td ltx_border_r ltx_border_tt" id="S3.T1.1.1.1.1.1">
          </td>
          <td class="ltx_td ltx_border_tt" id="S3.T1.1.1.1.1.2">
          </td>
          <td class="ltx_td ltx_border_r ltx_border_tt" id="S3.T1.1.1.1.1.3">
          </td>
          <td class="ltx_td ltx_border_r ltx_border_tt" id="S3.T1.1.1.1.1.4">
          </td>
          <td class="ltx_td ltx_border_r ltx_border_tt" id="S3.T1.1.1.1.1.5">
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2" id="S3.T1.1.1.1.1.6">
           <span class="ltx_text" id="S3.T1.1.1.1.1.6.1" style="color:#4472C4;">
            <span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.1.6.1.1">
             Agents Profiling
            </span>
           </span>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2" id="S3.T1.1.1.1.1.7">
           <span class="ltx_text" id="S3.T1.1.1.1.1.7.1" style="color:#548135;">
            <span class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.1.1.7.1.1">
             <span class="ltx_tr" id="S3.T1.1.1.1.1.7.1.1.1">
              <span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.1.1.7.1.1.1.1">
               <span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.1.7.1.1.1.1.1">
                Agents
               </span>
              </span>
             </span>
             <span class="ltx_tr" id="S3.T1.1.1.1.1.7.1.1.2">
              <span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.1.1.7.1.1.2.1">
               <span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.1.7.1.1.2.1.1">
                Communication
               </span>
              </span>
             </span>
            </span>
           </span>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S3.T1.1.1.1.1.8">
           <span class="ltx_text" id="S3.T1.1.1.1.1.8.1" style="color:#FF00FF;">
            <span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.1.8.1.1">
             Agents Capabilities Acquisition
            </span>
           </span>
          </td>
         </tr>
         <tr class="ltx_tr" id="S3.T1.1.1.2.2">
          <td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.2.2.1">
           <span class="ltx_text ltx_font_bold" id="S3.T1.1.1.2.2.1.1">
            Motivation
           </span>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r" colspan="2" id="S3.T1.1.1.2.2.2">
           <span class="ltx_text ltx_font_bold" id="S3.T1.1.1.2.2.2.1">
            Research Domain &amp; Goals
           </span>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.2.2.3">
           <span class="ltx_text ltx_font_bold" id="S3.T1.1.1.2.2.3.1">
            Work
           </span>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.2.2.4">
           <span class="ltx_text" id="S3.T1.1.1.2.2.4.1" style="color:#BF9000;">
            <span class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.2.2.4.1.1">
             <span class="ltx_tr" id="S3.T1.1.1.2.2.4.1.1.1">
              <span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.2.2.4.1.1.1.1">
               <span class="ltx_text ltx_font_bold" id="S3.T1.1.1.2.2.4.1.1.1.1.1">
                Agents-Env.
               </span>
              </span>
             </span>
             <span class="ltx_tr" id="S3.T1.1.1.2.2.4.1.1.2">
              <span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.2.2.4.1.1.2.1">
               <span class="ltx_text ltx_font_bold" id="S3.T1.1.1.2.2.4.1.1.2.1.1">
                Interface
               </span>
              </span>
             </span>
            </span>
           </span>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.2.2.5">
           <span class="ltx_text" id="S3.T1.1.1.2.2.5.1" style="color:#4472C4;">
            <span class="ltx_text ltx_font_bold" id="S3.T1.1.1.2.2.5.1.1">
             <span class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.2.2.5.1.1.1">
              <span class="ltx_tr" id="S3.T1.1.1.2.2.5.1.1.1.1">
               <span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.2.2.5.1.1.1.1.1">
                Profiling
               </span>
              </span>
              <span class="ltx_tr" id="S3.T1.1.1.2.2.5.1.1.1.2">
               <span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.2.2.5.1.1.1.2.1">
                methods
               </span>
              </span>
             </span>
            </span>
           </span>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.2.2.6">
           <span class="ltx_text" id="S3.T1.1.1.2.2.6.1" style="color:#4472C4;">
            <span class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.2.2.6.1.1">
             <span class="ltx_tr" id="S3.T1.1.1.2.2.6.1.1.1">
              <span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.2.2.6.1.1.1.1">
               <span class="ltx_text ltx_font_bold" id="S3.T1.1.1.2.2.6.1.1.1.1.1">
                Profiles
               </span>
              </span>
             </span>
             <span class="ltx_tr" id="S3.T1.1.1.2.2.6.1.1.2">
              <span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.2.2.6.1.1.2.1">
               <span class="ltx_text ltx_font_bold" id="S3.T1.1.1.2.2.6.1.1.2.1.1">
                (examples)
               </span>
              </span>
             </span>
            </span>
           </span>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.2.2.7">
           <span class="ltx_text" id="S3.T1.1.1.2.2.7.1" style="color:#548135;">
            <span class="ltx_text ltx_font_bold" id="S3.T1.1.1.2.2.7.1.1">
             Paradigms
            </span>
           </span>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.2.2.8">
           <span class="ltx_text" id="S3.T1.1.1.2.2.8.1" style="color:#548135;">
            <span class="ltx_text ltx_font_bold" id="S3.T1.1.1.2.2.8.1.1">
             Structure
            </span>
           </span>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.2.2.9">
           <span class="ltx_text" id="S3.T1.1.1.2.2.9.1" style="color:#FF00FF;">
            <span class="ltx_text ltx_font_bold" id="S3.T1.1.1.2.2.9.1.1">
             Feedback from
            </span>
           </span>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.2.2.10">
           <span class="ltx_text" id="S3.T1.1.1.2.2.10.1" style="color:#FF00FF;">
            <span class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.2.2.10.1.1">
             <span class="ltx_tr" id="S3.T1.1.1.2.2.10.1.1.1">
              <span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.2.2.10.1.1.1.1">
               <span class="ltx_text ltx_font_bold" id="S3.T1.1.1.2.2.10.1.1.1.1.1">
                Agents
               </span>
              </span>
             </span>
             <span class="ltx_tr" id="S3.T1.1.1.2.2.10.1.1.2">
              <span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.2.2.10.1.1.2.1">
               <span class="ltx_text ltx_font_bold" id="S3.T1.1.1.2.2.10.1.1.2.1.1">
                Adjustment
               </span>
              </span>
             </span>
            </span>
           </span>
          </td>
         </tr>
         <tr class="ltx_tr" id="S3.T1.1.1.3.3">
          <td class="ltx_td ltx_border_r ltx_border_t" id="S3.T1.1.1.3.3.1">
          </td>
          <td class="ltx_td ltx_border_r ltx_border_t" colspan="2" id="S3.T1.1.1.3.3.2">
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.3.3.3">
           <cite class="ltx_cite ltx_citemacro_cite">
            Qian
            <span class="ltx_text ltx_font_italic">
             et al.
            </span>
            <span class="ltx_text" id="S3.T1.1.1.3.3.3.1.1.1.1" style="font-size:70%;">
             (
            </span>
            <a class="ltx_ref" href="#bib.bib54" title="">
             2023
            </a>
            <span class="ltx_text" id="S3.T1.1.1.3.3.3.2.2.2.1" style="font-size:70%;">
             )
            </span>
           </cite>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.3.3.4">
           Sandbox
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.3.3.5">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.3.3.5.1">
            <tr class="ltx_tr" id="S3.T1.1.1.3.3.5.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.3.3.5.1.1.1">
              Pre-defined,
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.3.3.5.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.3.3.5.1.2.1">
              Model-Generated
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.3.3.6">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.3.3.6.1">
            <tr class="ltx_tr" id="S3.T1.1.1.3.3.6.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.3.3.6.1.1.1">
              CTO,
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.3.3.6.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.3.3.6.1.2.1">
              programmer
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.3.3.7">
           Cooperative
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.3.3.8">
           Layered
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.3.3.9">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.3.3.9.1">
            <tr class="ltx_tr" id="S3.T1.1.1.3.3.9.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.3.3.9.1.1.1">
              Environment,
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.3.3.9.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.3.3.9.1.2.1">
              Agent interaction,
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.3.3.9.1.3">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.3.3.9.1.3.1">
              Human
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.3.3.10">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.3.3.10.1">
            <tr class="ltx_tr" id="S3.T1.1.1.3.3.10.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.3.3.10.1.1.1">
              Memory,
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.3.3.10.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.3.3.10.1.2.1">
              Self-Evolution
             </td>
            </tr>
           </table>
          </td>
         </tr>
         <tr class="ltx_tr" id="S3.T1.1.1.4.4">
          <td class="ltx_td ltx_border_r" id="S3.T1.1.1.4.4.1">
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r" colspan="2" id="S3.T1.1.1.4.4.2">
           Software development
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.4.4.3">
           <cite class="ltx_cite ltx_citemacro_cite">
            Hong
            <span class="ltx_text ltx_font_italic">
             et al.
            </span>
            <span class="ltx_text" id="S3.T1.1.1.4.4.3.1.1.1.1" style="font-size:70%;">
             (
            </span>
            <a class="ltx_ref" href="#bib.bib24" title="">
             2023
            </a>
            <span class="ltx_text" id="S3.T1.1.1.4.4.3.2.2.2.1" style="font-size:70%;">
             )
            </span>
           </cite>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.4.4.4">
           Sandbox
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.4.4.5">
           Pre-defined
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.4.4.6">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.4.4.6.1">
            <tr class="ltx_tr" id="S3.T1.1.1.4.4.6.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.4.4.6.1.1.1">
              Product Manager,
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.4.4.6.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.4.4.6.1.2.1">
              Engineer
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.4.4.7">
           Cooperative
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.4.4.8">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.4.4.8.1">
            <tr class="ltx_tr" id="S3.T1.1.1.4.4.8.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.4.4.8.1.1.1">
              Layered,
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.4.4.8.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.4.4.8.1.2.1">
              Shared Message Pool
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.4.4.9">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.4.4.9.1">
            <tr class="ltx_tr" id="S3.T1.1.1.4.4.9.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.4.4.9.1.1.1">
              Environment,
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.4.4.9.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.4.4.9.1.2.1">
              Agent interaction,
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.4.4.9.1.3">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.4.4.9.1.3.1">
              Human
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.4.4.10">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.4.4.10.1">
            <tr class="ltx_tr" id="S3.T1.1.1.4.4.10.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.4.4.10.1.1.1">
              Memory,
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.4.4.10.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.4.4.10.1.2.1">
              Self-Evolution
             </td>
            </tr>
           </table>
          </td>
         </tr>
         <tr class="ltx_tr" id="S3.T1.1.1.5.5">
          <td class="ltx_td ltx_border_r" id="S3.T1.1.1.5.5.1">
          </td>
          <td class="ltx_td ltx_border_r" colspan="2" id="S3.T1.1.1.5.5.2">
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.5.5.3">
           <cite class="ltx_cite ltx_citemacro_cite">
            Dong
            <span class="ltx_text ltx_font_italic">
             et al.
            </span>
            <span class="ltx_text" id="S3.T1.1.1.5.5.3.1.1.1.1" style="font-size:70%;">
             (
            </span>
            <a class="ltx_ref" href="#bib.bib14" title="">
             2023b
            </a>
            <span class="ltx_text" id="S3.T1.1.1.5.5.3.2.2.2.1" style="font-size:70%;">
             )
            </span>
           </cite>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.5.5.4">
           Sandbox
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.5.5.5">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.5.5.5.1">
            <tr class="ltx_tr" id="S3.T1.1.1.5.5.5.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.5.5.5.1.1.1">
              Pre-defined,
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.5.5.5.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.5.5.5.1.2.1">
              Model-Generated
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.5.5.6">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.5.5.6.1">
            <tr class="ltx_tr" id="S3.T1.1.1.5.5.6.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.5.5.6.1.1.1">
              Analyst,
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.5.5.6.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.5.5.6.1.2.1">
              coder
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.5.5.7">
           Cooperative
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.5.5.8">
           Layered
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.5.5.9">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.5.5.9.1">
            <tr class="ltx_tr" id="S3.T1.1.1.5.5.9.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.5.5.9.1.1.1">
              Environment,
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.5.5.9.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.5.5.9.1.2.1">
              Agent interaction
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.5.5.10">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.5.5.10.1">
            <tr class="ltx_tr" id="S3.T1.1.1.5.5.10.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.5.5.10.1.1.1">
              Memory,
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.5.5.10.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.5.5.10.1.2.1">
              Self-Evolution
             </td>
            </tr>
           </table>
          </td>
         </tr>
         <tr class="ltx_tr" id="S3.T1.1.1.6.6">
          <td class="ltx_td ltx_border_r" id="S3.T1.1.1.6.6.1">
          </td>
          <td class="ltx_td ltx_border_r ltx_border_t" id="S3.T1.1.1.6.6.2">
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.6.6.3">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.6.6.3.1">
            <tr class="ltx_tr" id="S3.T1.1.1.6.6.3.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.6.6.3.1.1.1">
              Multi-robot
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.6.6.3.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.6.6.3.1.2.1">
              planning
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.6.6.4">
           <cite class="ltx_cite ltx_citemacro_cite">
            Chen
            <span class="ltx_text ltx_font_italic">
             et al.
            </span>
            <span class="ltx_text" id="S3.T1.1.1.6.6.4.1.1.1.1" style="font-size:70%;">
             (
            </span>
            <a class="ltx_ref" href="#bib.bib9" title="">
             2023d
            </a>
            <span class="ltx_text" id="S3.T1.1.1.6.6.4.2.2.2.1" style="font-size:70%;">
             )
            </span>
           </cite>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.6.6.5">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.6.6.5.1">
            <tr class="ltx_tr" id="S3.T1.1.1.6.6.5.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.6.6.5.1.1.1">
              Sandbox,
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.6.6.5.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.6.6.5.1.2.1">
              Physical
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.6.6.6">
           Pre-defined
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.6.6.7">
           Robots
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.6.6.8">
           Cooperative
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.6.6.9">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.6.6.9.1">
            <tr class="ltx_tr" id="S3.T1.1.1.6.6.9.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.6.6.9.1.1.1">
              Centralized,
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.6.6.9.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.6.6.9.1.2.1">
              Decentralized
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.6.6.10">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.6.6.10.1">
            <tr class="ltx_tr" id="S3.T1.1.1.6.6.10.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.6.6.10.1.1.1">
              Environment,
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.6.6.10.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.6.6.10.1.2.1">
              Agent interaction
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.6.6.11">
           Memory
          </td>
         </tr>
         <tr class="ltx_tr" id="S3.T1.1.1.7.7">
          <td class="ltx_td ltx_border_r" id="S3.T1.1.1.7.7.1">
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.7.7.2">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.7.7.2.1">
            <tr class="ltx_tr" id="S3.T1.1.1.7.7.2.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.7.7.2.1.1.1">
              Embodied
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.7.7.2.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.7.7.2.1.2.1">
              Agents
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.7.7.3">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.7.7.3.1">
            <tr class="ltx_tr" id="S3.T1.1.1.7.7.3.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.7.7.3.1.1.1">
              Multi-robot
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.7.7.3.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.7.7.3.1.2.1">
              collaboration
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.7.7.4">
           <cite class="ltx_cite ltx_citemacro_cite">
            Mandi
            <span class="ltx_text ltx_font_italic">
             et al.
            </span>
            <span class="ltx_text" id="S3.T1.1.1.7.7.4.1.1.1.1" style="font-size:70%;">
             (
            </span>
            <a class="ltx_ref" href="#bib.bib47" title="">
             2023
            </a>
            <span class="ltx_text" id="S3.T1.1.1.7.7.4.2.2.2.1" style="font-size:70%;">
             )
            </span>
           </cite>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.7.7.5">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.7.7.5.1">
            <tr class="ltx_tr" id="S3.T1.1.1.7.7.5.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.7.7.5.1.1.1">
              Sandbox,
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.7.7.5.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.7.7.5.1.2.1">
              Physical
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.7.7.6">
           Pre-defined
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.7.7.7">
           Robots
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.7.7.8">
           Cooperative
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.7.7.9">
           Decentralized
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.7.7.10">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.7.7.10.1">
            <tr class="ltx_tr" id="S3.T1.1.1.7.7.10.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.7.7.10.1.1.1">
              Environment,
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.7.7.10.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.7.7.10.1.2.1">
              Agent interaction
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.7.7.11">
           Memory
          </td>
         </tr>
         <tr class="ltx_tr" id="S3.T1.1.1.8.8">
          <td class="ltx_td ltx_border_r" id="S3.T1.1.1.8.8.1">
          </td>
          <td class="ltx_td ltx_border_r" id="S3.T1.1.1.8.8.2">
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.8.8.3">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.8.8.3.1">
            <tr class="ltx_tr" id="S3.T1.1.1.8.8.3.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.8.8.3.1.1.1">
              Multi-Agents
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.8.8.3.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.8.8.3.1.2.1">
              cooperation
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.8.8.4">
           <cite class="ltx_cite ltx_citemacro_cite">
            Zhang
            <span class="ltx_text ltx_font_italic">
             et al.
            </span>
            <span class="ltx_text" id="S3.T1.1.1.8.8.4.1.1.1.1" style="font-size:70%;">
             (
            </span>
            <a class="ltx_ref" href="#bib.bib81" title="">
             2023c
            </a>
            <span class="ltx_text" id="S3.T1.1.1.8.8.4.2.2.2.1" style="font-size:70%;">
             )
            </span>
           </cite>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.8.8.5">
           Sandbox
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.8.8.6">
           Pre-defined
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.8.8.7">
           Robots
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.8.8.8">
           Cooperative
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.8.8.9">
           Decentralized
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.8.8.10">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.8.8.10.1">
            <tr class="ltx_tr" id="S3.T1.1.1.8.8.10.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.8.8.10.1.1.1">
              Environment,
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.8.8.10.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.8.8.10.1.2.1">
              Agent interaction
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.8.8.11">
           Memory
          </td>
         </tr>
         <tr class="ltx_tr" id="S3.T1.1.1.9.9">
          <td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.9.9.1">
           <span class="ltx_text" id="S3.T1.1.1.9.9.1.1">
            <span class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.9.9.1.1.1">
             <span class="ltx_tr" id="S3.T1.1.1.9.9.1.1.1.1">
              <span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.9.9.1.1.1.1.1">
               Problem
              </span>
             </span>
             <span class="ltx_tr" id="S3.T1.1.1.9.9.1.1.1.2">
              <span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.9.9.1.1.1.2.1">
               Solving
              </span>
             </span>
            </span>
           </span>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.9.9.2">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.9.9.2.1">
            <tr class="ltx_tr" id="S3.T1.1.1.9.9.2.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.9.9.2.1.1.1">
              Science
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.9.9.2.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.9.9.2.1.2.1">
              Experiments
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.9.9.3">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.9.9.3.1">
            <tr class="ltx_tr" id="S3.T1.1.1.9.9.3.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.9.9.3.1.1.1">
              Optimization
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.9.9.3.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.9.9.3.1.2.1">
              of MOF
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.9.9.4">
           <cite class="ltx_cite ltx_citemacro_cite">
            Zheng
            <span class="ltx_text ltx_font_italic">
             et al.
            </span>
            <span class="ltx_text" id="S3.T1.1.1.9.9.4.1.1.1.1" style="font-size:70%;">
             (
            </span>
            <a class="ltx_ref" href="#bib.bib85" title="">
             2023
            </a>
            <span class="ltx_text" id="S3.T1.1.1.9.9.4.2.2.2.1" style="font-size:70%;">
             )
            </span>
           </cite>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.9.9.5">
           Physical
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.9.9.6">
           Pre-defined
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.9.9.7">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.9.9.7.1">
            <tr class="ltx_tr" id="S3.T1.1.1.9.9.7.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.9.9.7.1.1.1">
              Strategy planers,
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.9.9.7.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.9.9.7.1.2.1">
              literature
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.9.9.7.1.3">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.9.9.7.1.3.1">
              collector, coder
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.9.9.8">
           Cooperative
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.9.9.9">
           Centralized
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.9.9.10">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.9.9.10.1">
            <tr class="ltx_tr" id="S3.T1.1.1.9.9.10.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.9.9.10.1.1.1">
              Environment,
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.9.9.10.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.9.9.10.1.2.1">
              Human
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.9.9.11">
           Memory
          </td>
         </tr>
         <tr class="ltx_tr" id="S3.T1.1.1.10.10">
          <td class="ltx_td ltx_border_r" id="S3.T1.1.1.10.10.1">
          </td>
          <td class="ltx_td ltx_border_r ltx_border_t" id="S3.T1.1.1.10.10.2">
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.10.10.3">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.10.10.3.1">
            <tr class="ltx_tr" id="S3.T1.1.1.10.10.3.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.10.10.3.1.1.1">
              Improving
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.10.10.3.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.10.10.3.1.2.1">
              Factuality
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.10.10.4">
           <cite class="ltx_cite ltx_citemacro_cite">
            Du
            <span class="ltx_text ltx_font_italic">
             et al.
            </span>
            <span class="ltx_text" id="S3.T1.1.1.10.10.4.1.1.1.1" style="font-size:70%;">
             (
            </span>
            <a class="ltx_ref" href="#bib.bib15" title="">
             2023
            </a>
            <span class="ltx_text" id="S3.T1.1.1.10.10.4.2.2.2.1" style="font-size:70%;">
             )
            </span>
           </cite>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.10.10.5">
           None
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.10.10.6">
           Pre-defined
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.10.10.7">
           Agents
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.10.10.8">
           Debate
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.10.10.9">
           Decentralized
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.10.10.10">
           Agent interaction
          </td>
          <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.10.10.11">
           Memory
          </td>
         </tr>
         <tr class="ltx_tr" id="S3.T1.1.1.11.11">
          <td class="ltx_td ltx_border_r" id="S3.T1.1.1.11.11.1">
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.11.11.2">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.11.11.2.1">
            <tr class="ltx_tr" id="S3.T1.1.1.11.11.2.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.11.11.2.1.1.1">
              Science
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.11.11.2.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.11.11.2.1.2.1">
              Debate
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.11.11.3">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.11.11.3.1">
            <tr class="ltx_tr" id="S3.T1.1.1.11.11.3.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.11.11.3.1.1.1">
              Examining,
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.11.11.3.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.11.11.3.1.2.1">
              Inter-Consistency
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.11.11.4">
           <cite class="ltx_cite ltx_citemacro_cite">
            Xiong
            <span class="ltx_text ltx_font_italic">
             et al.
            </span>
            <span class="ltx_text" id="S3.T1.1.1.11.11.4.1.1.1.1" style="font-size:70%;">
             (
            </span>
            <a class="ltx_ref" href="#bib.bib73" title="">
             2023
            </a>
            <span class="ltx_text" id="S3.T1.1.1.11.11.4.2.2.2.1" style="font-size:70%;">
             )
            </span>
           </cite>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.11.11.5">
           None
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.11.11.6">
           Pre-defined
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.11.11.7">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.11.11.7.1">
            <tr class="ltx_tr" id="S3.T1.1.1.11.11.7.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.11.11.7.1.1.1">
              Proponent,
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.11.11.7.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.11.11.7.1.2.1">
              Opponent,
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.11.11.7.1.3">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.11.11.7.1.3.1">
              Judge
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.11.11.8">
           Debate
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.11.11.9">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.11.11.9.1">
            <tr class="ltx_tr" id="S3.T1.1.1.11.11.9.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.11.11.9.1.1.1">
              Centralized,
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.11.11.9.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.11.11.9.1.2.1">
              Decentralized
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.11.11.10">
           Agent interaction
          </td>
          <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.11.11.11">
           Memory
          </td>
         </tr>
         <tr class="ltx_tr" id="S3.T1.1.1.12.12">
          <td class="ltx_td ltx_border_r" id="S3.T1.1.1.12.12.1">
          </td>
          <td class="ltx_td ltx_border_r" id="S3.T1.1.1.12.12.2">
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.12.12.3">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.12.12.3.1">
            <tr class="ltx_tr" id="S3.T1.1.1.12.12.3.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.12.12.3.1.1.1">
              Evaluators
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.12.12.3.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.12.12.3.1.2.1">
              for debates
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.12.12.4">
           <cite class="ltx_cite ltx_citemacro_cite">
            Chan
            <span class="ltx_text ltx_font_italic">
             et al.
            </span>
            <span class="ltx_text" id="S3.T1.1.1.12.12.4.1.1.1.1" style="font-size:70%;">
             (
            </span>
            <a class="ltx_ref" href="#bib.bib5" title="">
             2023
            </a>
            <span class="ltx_text" id="S3.T1.1.1.12.12.4.2.2.2.1" style="font-size:70%;">
             )
            </span>
           </cite>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.12.12.5">
           None
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.12.12.6">
           Pre-defined
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.12.12.7">
           Agents
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.12.12.8">
           Debate
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.12.12.9">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.12.12.9.1">
            <tr class="ltx_tr" id="S3.T1.1.1.12.12.9.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.12.12.9.1.1.1">
              Centralized,
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.12.12.9.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.12.12.9.1.2.1">
              Decentralized
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.12.12.10">
           Agent interaction
          </td>
          <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.12.12.11">
           Memory
          </td>
         </tr>
         <tr class="ltx_tr" id="S3.T1.1.1.13.13">
          <td class="ltx_td ltx_border_r" id="S3.T1.1.1.13.13.1">
          </td>
          <td class="ltx_td ltx_border_r" id="S3.T1.1.1.13.13.2">
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.13.13.3">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.13.13.3.1">
            <tr class="ltx_tr" id="S3.T1.1.1.13.13.3.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.13.13.3.1.1.1">
              Multi-Agents
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.13.13.3.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.13.13.3.1.2.1">
              for Medication
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.13.13.4">
           <cite class="ltx_cite ltx_citemacro_cite">
            Tang
            <span class="ltx_text ltx_font_italic">
             et al.
            </span>
            <span class="ltx_text" id="S3.T1.1.1.13.13.4.1.1.1.1" style="font-size:70%;">
             (
            </span>
            <a class="ltx_ref" href="#bib.bib59" title="">
             2023
            </a>
            <span class="ltx_text" id="S3.T1.1.1.13.13.4.2.2.2.1" style="font-size:70%;">
             )
            </span>
           </cite>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.13.13.5">
           None
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.13.13.6">
           Pre-defined
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.13.13.7">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.13.13.7.1">
            <tr class="ltx_tr" id="S3.T1.1.1.13.13.7.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.13.13.7.1.1.1">
              Cardiology,
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.13.13.7.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.13.13.7.1.2.1">
              Surgery
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.13.13.8">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.13.13.8.1">
            <tr class="ltx_tr" id="S3.T1.1.1.13.13.8.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.13.13.8.1.1.1">
              Debate,
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.13.13.8.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.13.13.8.1.2.1">
              Cooperative
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.13.13.9">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.13.13.9.1">
            <tr class="ltx_tr" id="S3.T1.1.1.13.13.9.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.13.13.9.1.1.1">
              Centralized,
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.13.13.9.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.13.13.9.1.2.1">
              Decentralized
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.13.13.10">
           Agent interaction
          </td>
          <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.13.13.11">
           Memory
          </td>
         </tr>
         <tr class="ltx_tr" id="S3.T1.1.1.14.14">
          <td class="ltx_td ltx_border_r ltx_border_t" id="S3.T1.1.1.14.14.1">
          </td>
          <td class="ltx_td ltx_border_r ltx_border_t" id="S3.T1.1.1.14.14.2">
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.14.14.3">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.14.14.3.1">
            <tr class="ltx_tr" id="S3.T1.1.1.14.14.3.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.14.14.3.1.1.1">
              Modest Community
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.14.14.3.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.14.14.3.1.2.1">
              (25 persons)
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.14.14.4">
           <cite class="ltx_cite ltx_citemacro_cite">
            Park
            <span class="ltx_text ltx_font_italic">
             et al.
            </span>
            <span class="ltx_text" id="S3.T1.1.1.14.14.4.1.1.1.1" style="font-size:70%;">
             (
            </span>
            <a class="ltx_ref" href="#bib.bib53" title="">
             2023
            </a>
            <span class="ltx_text" id="S3.T1.1.1.14.14.4.2.2.2.1" style="font-size:70%;">
             )
            </span>
           </cite>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.14.14.5">
           Sandbox
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.14.14.6">
           Model-generated
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.14.14.7">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.14.14.7.1">
            <tr class="ltx_tr" id="S3.T1.1.1.14.14.7.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.14.14.7.1.1.1">
              Pharmacy,
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.14.14.7.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.14.14.7.1.2.1">
              shopkeeper
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.14.14.8">
           -
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.14.14.9">
           -
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.14.14.10">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.14.14.10.1">
            <tr class="ltx_tr" id="S3.T1.1.1.14.14.10.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.14.14.10.1.1.1">
              Environment,
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.14.14.10.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.14.14.10.1.2.1">
              Agent interaction
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.14.14.11">
           Memory
          </td>
         </tr>
         <tr class="ltx_tr" id="S3.T1.1.1.15.15">
          <td class="ltx_td ltx_border_r" id="S3.T1.1.1.15.15.1">
          </td>
          <td class="ltx_td ltx_border_r" id="S3.T1.1.1.15.15.2">
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.15.15.3">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.15.15.3.1">
            <tr class="ltx_tr" id="S3.T1.1.1.15.15.3.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.15.15.3.1.1.1">
              Online community
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.15.15.3.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.15.15.3.1.2.1">
              (1000 persons)
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.15.15.4">
           <cite class="ltx_cite ltx_citemacro_cite">
            Park
            <span class="ltx_text ltx_font_italic">
             et al.
            </span>
            <span class="ltx_text" id="S3.T1.1.1.15.15.4.1.1.1.1" style="font-size:70%;">
             (
            </span>
            <a class="ltx_ref" href="#bib.bib52" title="">
             2022
            </a>
            <span class="ltx_text" id="S3.T1.1.1.15.15.4.2.2.2.1" style="font-size:70%;">
             )
            </span>
           </cite>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.15.15.5">
           None
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.15.15.6">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.15.15.6.1">
            <tr class="ltx_tr" id="S3.T1.1.1.15.15.6.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.15.15.6.1.1.1">
              Pre-defined,
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.15.15.6.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.15.15.6.1.2.1">
              Model-generated
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.15.15.7">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.15.15.7.1">
            <tr class="ltx_tr" id="S3.T1.1.1.15.15.7.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.15.15.7.1.1.1">
              Camping,
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.15.15.7.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.15.15.7.1.2.1">
              fishing
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.15.15.8">
           -
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.15.15.9">
           -
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.15.15.10">
           Agent interaction
          </td>
          <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.15.15.11">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.15.15.11.1">
            <tr class="ltx_tr" id="S3.T1.1.1.15.15.11.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.15.15.11.1.1.1">
              Dynamic
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.15.15.11.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.15.15.11.1.2.1">
              Generation
             </td>
            </tr>
           </table>
          </td>
         </tr>
         <tr class="ltx_tr" id="S3.T1.1.1.16.16">
          <td class="ltx_td ltx_border_r" id="S3.T1.1.1.16.16.1">
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.16.16.2">
           Society
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.16.16.3">
           Emotion propagation
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.16.16.4">
           <cite class="ltx_cite ltx_citemacro_cite">
            Gao
            <span class="ltx_text ltx_font_italic">
             et al.
            </span>
            <span class="ltx_text" id="S3.T1.1.1.16.16.4.1.1.1.1" style="font-size:70%;">
             (
            </span>
            <a class="ltx_ref" href="#bib.bib18" title="">
             2023a
            </a>
            <span class="ltx_text" id="S3.T1.1.1.16.16.4.2.2.2.1" style="font-size:70%;">
             )
            </span>
           </cite>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.16.16.5">
           None
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.16.16.6">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.16.16.6.1">
            <tr class="ltx_tr" id="S3.T1.1.1.16.16.6.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.16.16.6.1.1.1">
              Pre-defined,
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.16.16.6.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.16.16.6.1.2.1">
              Model-generated
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.16.16.7">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.16.16.7.1">
            <tr class="ltx_tr" id="S3.T1.1.1.16.16.7.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.16.16.7.1.1.1">
              Real-world
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.16.16.7.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.16.16.7.1.2.1">
              user
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.16.16.8">
           -
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.16.16.9">
           -
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.16.16.10">
           Agent interaction
          </td>
          <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.16.16.11">
           Memory
          </td>
         </tr>
         <tr class="ltx_tr" id="S3.T1.1.1.17.17">
          <td class="ltx_td ltx_border_r" id="S3.T1.1.1.17.17.1">
          </td>
          <td class="ltx_td ltx_border_r" id="S3.T1.1.1.17.17.2">
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.17.17.3">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.17.17.3.1">
            <tr class="ltx_tr" id="S3.T1.1.1.17.17.3.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.17.17.3.1.1.1">
              Real-time
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.17.17.3.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.17.17.3.1.2.1">
              social interactions
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.17.17.4">
           <cite class="ltx_cite ltx_citemacro_cite">
            Kaiya
            <span class="ltx_text ltx_font_italic">
             et al.
            </span>
            <span class="ltx_text" id="S3.T1.1.1.17.17.4.1.1.1.1" style="font-size:70%;">
             (
            </span>
            <a class="ltx_ref" href="#bib.bib29" title="">
             2023
            </a>
            <span class="ltx_text" id="S3.T1.1.1.17.17.4.2.2.2.1" style="font-size:70%;">
             )
            </span>
           </cite>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.17.17.5">
           Sandbox
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.17.17.6">
           Pre-defined
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.17.17.7">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.17.17.7.1">
            <tr class="ltx_tr" id="S3.T1.1.1.17.17.7.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.17.17.7.1.1.1">
              Real-world
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.17.17.7.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.17.17.7.1.2.1">
              user
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.17.17.8">
           -
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.17.17.9">
           -
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.17.17.10">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.17.17.10.1">
            <tr class="ltx_tr" id="S3.T1.1.1.17.17.10.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.17.17.10.1.1.1">
              Environment,
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.17.17.10.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.17.17.10.1.2.1">
              Agent interaction
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.17.17.11">
           Memory
          </td>
         </tr>
         <tr class="ltx_tr" id="S3.T1.1.1.18.18">
          <td class="ltx_td ltx_border_r" id="S3.T1.1.1.18.18.1">
          </td>
          <td class="ltx_td ltx_border_r" id="S3.T1.1.1.18.18.2">
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.18.18.3">
           Opinion dynamics
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.18.18.4">
           <cite class="ltx_cite ltx_citemacro_cite">
            Li
            <span class="ltx_text ltx_font_italic">
             et al.
            </span>
            <span class="ltx_text" id="S3.T1.1.1.18.18.4.1.1.1.1" style="font-size:70%;">
             (
            </span>
            <a class="ltx_ref" href="#bib.bib34" title="">
             2023a
            </a>
            <span class="ltx_text" id="S3.T1.1.1.18.18.4.2.2.2.1" style="font-size:70%;">
             )
            </span>
           </cite>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.18.18.5">
           None
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.18.18.6">
           Pre-defined
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.18.18.7">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.18.18.7.1">
            <tr class="ltx_tr" id="S3.T1.1.1.18.18.7.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.18.18.7.1.1.1">
              NIN, NINL,
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.18.18.7.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.18.18.7.1.2.1">
              NIL
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.18.18.8">
           -
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.18.18.9">
           -
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.18.18.10">
           Agent interaction
          </td>
          <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.18.18.11">
           Memory
          </td>
         </tr>
         <tr class="ltx_tr" id="S3.T1.1.1.19.19">
          <td class="ltx_td ltx_border_r" id="S3.T1.1.1.19.19.1">
          </td>
          <td class="ltx_td ltx_border_r ltx_border_t" id="S3.T1.1.1.19.19.2">
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.19.19.3">
           WereWolf
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.19.19.4">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.19.19.4.1">
            <tr class="ltx_tr" id="S3.T1.1.1.19.19.4.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.19.19.4.1.1.1">
              <cite class="ltx_cite ltx_citemacro_cite">
               Xu
               <span class="ltx_text ltx_font_italic">
                et al.
               </span>
               <span class="ltx_text" id="S3.T1.1.1.19.19.4.1.1.1.1.1.1.1" style="font-size:70%;">
                (
               </span>
               <a class="ltx_ref" href="#bib.bib75" title="">
                2023b
               </a>
               <span class="ltx_text" id="S3.T1.1.1.19.19.4.1.1.1.2.2.2.1" style="font-size:70%;">
                )
               </span>
              </cite>
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.19.19.4.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.19.19.4.1.2.1">
              <cite class="ltx_cite ltx_citemacro_cite">
               Xu
               <span class="ltx_text ltx_font_italic">
                et al.
               </span>
               <span class="ltx_text" id="S3.T1.1.1.19.19.4.1.2.1.1.1.1.1" style="font-size:70%;">
                (
               </span>
               <a class="ltx_ref" href="#bib.bib76" title="">
                2023c
               </a>
               <span class="ltx_text" id="S3.T1.1.1.19.19.4.1.2.1.2.2.2.1" style="font-size:70%;">
                )
               </span>
              </cite>
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.19.19.5">
           Sandbox
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.19.19.6">
           Pre-defined
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.19.19.7">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.19.19.7.1">
            <tr class="ltx_tr" id="S3.T1.1.1.19.19.7.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.19.19.7.1.1.1">
              Seer,
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.19.19.7.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.19.19.7.1.2.1">
              werewolf,
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.19.19.7.1.3">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.19.19.7.1.3.1">
              villager
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.19.19.8">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.19.19.8.1">
            <tr class="ltx_tr" id="S3.T1.1.1.19.19.8.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.19.19.8.1.1.1">
              Cooperative,
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.19.19.8.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.19.19.8.1.2.1">
              Debate,
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.19.19.8.1.3">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.19.19.8.1.3.1">
              Competitive
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.19.19.9">
           Decentralized
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.19.19.10">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.19.19.10.1">
            <tr class="ltx_tr" id="S3.T1.1.1.19.19.10.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.19.19.10.1.1.1">
              Environment,
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.19.19.10.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.19.19.10.1.2.1">
              Agent interaction
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.19.19.11">
           Memory
          </td>
         </tr>
         <tr class="ltx_tr" id="S3.T1.1.1.20.20">
          <td class="ltx_td ltx_border_r" id="S3.T1.1.1.20.20.1">
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.20.20.2">
           Gaming
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.20.20.3">
           Avalon
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.20.20.4">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.20.20.4.1">
            <tr class="ltx_tr" id="S3.T1.1.1.20.20.4.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.20.20.4.1.1.1">
              <cite class="ltx_cite ltx_citemacro_cite">
               Light
               <span class="ltx_text ltx_font_italic">
                et al.
               </span>
               <span class="ltx_text" id="S3.T1.1.1.20.20.4.1.1.1.1.1.1.1" style="font-size:70%;">
                (
               </span>
               <a class="ltx_ref" href="#bib.bib43" title="">
                2023a
               </a>
               <span class="ltx_text" id="S3.T1.1.1.20.20.4.1.1.1.2.2.2.1" style="font-size:70%;">
                )
               </span>
              </cite>
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.20.20.4.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.20.20.4.1.2.1">
              <cite class="ltx_cite ltx_citemacro_cite">
               Wang
               <span class="ltx_text ltx_font_italic">
                et al.
               </span>
               <span class="ltx_text" id="S3.T1.1.1.20.20.4.1.2.1.1.1.1.1" style="font-size:70%;">
                (
               </span>
               <a class="ltx_ref" href="#bib.bib63" title="">
                2023c
               </a>
               <span class="ltx_text" id="S3.T1.1.1.20.20.4.1.2.1.2.2.2.1" style="font-size:70%;">
                )
               </span>
              </cite>
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.20.20.5">
           Sandbox
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.20.20.6">
           Pre-defined
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.20.20.7">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.20.20.7.1">
            <tr class="ltx_tr" id="S3.T1.1.1.20.20.7.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.20.20.7.1.1.1">
              Servant,
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.20.20.7.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.20.20.7.1.2.1">
              Merlin,
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.20.20.7.1.3">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.20.20.7.1.3.1">
              Assassin
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.20.20.8">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.20.20.8.1">
            <tr class="ltx_tr" id="S3.T1.1.1.20.20.8.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.20.20.8.1.1.1">
              Cooperative,
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.20.20.8.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.20.20.8.1.2.1">
              Debate,
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.20.20.8.1.3">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.20.20.8.1.3.1">
              Competitive
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.20.20.9">
           Decentralized
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.20.20.10">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.20.20.10.1">
            <tr class="ltx_tr" id="S3.T1.1.1.20.20.10.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.20.20.10.1.1.1">
              Environment,
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.20.20.10.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.20.20.10.1.2.1">
              Agent interaction
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.20.20.11">
           Memory
          </td>
         </tr>
         <tr class="ltx_tr" id="S3.T1.1.1.21.21">
          <td class="ltx_td ltx_border_r" id="S3.T1.1.1.21.21.1">
          </td>
          <td class="ltx_td ltx_border_r" id="S3.T1.1.1.21.21.2">
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.21.21.3">
           Welfare Diplomacy
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.21.21.4">
           <cite class="ltx_cite ltx_citemacro_cite">
            Mukobi
            <span class="ltx_text ltx_font_italic">
             et al.
            </span>
            <span class="ltx_text" id="S3.T1.1.1.21.21.4.1.1.1.1" style="font-size:70%;">
             (
            </span>
            <a class="ltx_ref" href="#bib.bib50" title="">
             2023
            </a>
            <span class="ltx_text" id="S3.T1.1.1.21.21.4.2.2.2.1" style="font-size:70%;">
             )
            </span>
           </cite>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.21.21.5">
           Sandbox
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.21.21.6">
           Pre-defined
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.21.21.7">
           Countries
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.21.21.8">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.21.21.8.1">
            <tr class="ltx_tr" id="S3.T1.1.1.21.21.8.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.21.21.8.1.1.1">
              Cooperative,
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.21.21.8.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.21.21.8.1.2.1">
              Competitive
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.21.21.9">
           Decentralized
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.21.21.10">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.21.21.10.1">
            <tr class="ltx_tr" id="S3.T1.1.1.21.21.10.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.21.21.10.1.1.1">
              Environment,
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.21.21.10.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.21.21.10.1.2.1">
              Agent interaction
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.21.21.11">
           Memory
          </td>
         </tr>
         <tr class="ltx_tr" id="S3.T1.1.1.22.22">
          <td class="ltx_td ltx_border_r" id="S3.T1.1.1.22.22.1">
          </td>
          <td class="ltx_td ltx_border_r ltx_border_t" id="S3.T1.1.1.22.22.2">
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.22.22.3">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.22.22.3.1">
            <tr class="ltx_tr" id="S3.T1.1.1.22.22.3.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.22.22.3.1.1.1">
              Human behavior
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.22.22.3.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.22.22.3.1.2.1">
              Simulation
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.22.22.4">
           <cite class="ltx_cite ltx_citemacro_cite">
            Aher
            <span class="ltx_text ltx_font_italic">
             et al.
            </span>
            <span class="ltx_text" id="S3.T1.1.1.22.22.4.1.1.1.1" style="font-size:70%;">
             (
            </span>
            <a class="ltx_ref" href="#bib.bib2" title="">
             2023
            </a>
            <span class="ltx_text" id="S3.T1.1.1.22.22.4.2.2.2.1" style="font-size:70%;">
             )
            </span>
           </cite>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.22.22.5">
           Sandbox
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.22.22.6">
           Pre-defined
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.22.22.7">
           Humans
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.22.22.8">
           -
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.22.22.9">
           -
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.22.22.10">
           Agent interaction
          </td>
          <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.22.22.11">
           Memory
          </td>
         </tr>
         <tr class="ltx_tr" id="S3.T1.1.1.23.23">
          <td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.23.23.1">
           <span class="ltx_text" id="S3.T1.1.1.23.23.1.1">
            <span class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.23.23.1.1.1">
             <span class="ltx_tr" id="S3.T1.1.1.23.23.1.1.1.1">
              <span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.23.23.1.1.1.1.1">
               World
              </span>
             </span>
             <span class="ltx_tr" id="S3.T1.1.1.23.23.1.1.1.2">
              <span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.23.23.1.1.1.2.1">
               Simulation
              </span>
             </span>
            </span>
           </span>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.23.23.2">
           <span class="ltx_text" id="S3.T1.1.1.23.23.2.1">
            Psychology
           </span>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.23.23.3">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.23.23.3.1">
            <tr class="ltx_tr" id="S3.T1.1.1.23.23.3.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.23.23.3.1.1.1">
              Collaboration
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.23.23.3.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.23.23.3.1.2.1">
              Exploring
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.23.23.4">
           <cite class="ltx_cite ltx_citemacro_cite">
            Zhang
            <span class="ltx_text ltx_font_italic">
             et al.
            </span>
            <span class="ltx_text" id="S3.T1.1.1.23.23.4.1.1.1.1" style="font-size:70%;">
             (
            </span>
            <a class="ltx_ref" href="#bib.bib82" title="">
             2023d
            </a>
            <span class="ltx_text" id="S3.T1.1.1.23.23.4.2.2.2.1" style="font-size:70%;">
             )
            </span>
           </cite>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.23.23.5">
           None
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.23.23.6">
           Pre-defined
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.23.23.7">
           Agents
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.23.23.8">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.23.23.8.1">
            <tr class="ltx_tr" id="S3.T1.1.1.23.23.8.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.23.23.8.1.1.1">
              Cooperative,
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.23.23.8.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.23.23.8.1.2.1">
              Debate
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.23.23.9">
           Decentralized
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.23.23.10">
           Agent interaction
          </td>
          <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.23.23.11">
           Memory
          </td>
         </tr>
         <tr class="ltx_tr" id="S3.T1.1.1.24.24">
          <td class="ltx_td ltx_border_r" id="S3.T1.1.1.24.24.1">
          </td>
          <td class="ltx_td ltx_border_r ltx_border_t" id="S3.T1.1.1.24.24.2">
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.24.24.3">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.24.24.3.1">
            <tr class="ltx_tr" id="S3.T1.1.1.24.24.3.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.24.24.3.1.1.1">
              Macroeconomic
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.24.24.3.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.24.24.3.1.2.1">
              simulation
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.24.24.4">
           <cite class="ltx_cite ltx_citemacro_cite">
            Li
            <span class="ltx_text ltx_font_italic">
             et al.
            </span>
            <span class="ltx_text" id="S3.T1.1.1.24.24.4.1.1.1.1" style="font-size:70%;">
             (
            </span>
            <a class="ltx_ref" href="#bib.bib38" title="">
             2023e
            </a>
            <span class="ltx_text" id="S3.T1.1.1.24.24.4.2.2.2.1" style="font-size:70%;">
             )
            </span>
           </cite>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.24.24.5">
           None
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.24.24.6">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.24.24.6.1">
            <tr class="ltx_tr" id="S3.T1.1.1.24.24.6.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.24.24.6.1.1.1">
              Pre-defined,
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.24.24.6.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.24.24.6.1.2.1">
              Model-generated
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.24.24.7">
           Labor
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.24.24.8">
           Cooperative
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.24.24.9">
           Decentralized
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.24.24.10">
           Agent interaction
          </td>
          <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.24.24.11">
           Memory
          </td>
         </tr>
         <tr class="ltx_tr" id="S3.T1.1.1.25.25">
          <td class="ltx_td ltx_border_r" id="S3.T1.1.1.25.25.1">
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.25.25.2">
           Economy
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.25.25.3">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.25.25.3.1">
            <tr class="ltx_tr" id="S3.T1.1.1.25.25.3.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.25.25.3.1.1.1">
              Information
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.25.25.3.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.25.25.3.1.2.1">
              Marketplaces
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.25.25.4">
           <cite class="ltx_cite ltx_citemacro_cite">
            Anonymous
            <span class="ltx_text" id="S3.T1.1.1.25.25.4.1.1.1.1" style="font-size:70%;">
             (
            </span>
            <a class="ltx_ref" href="#bib.bib4" title="">
             2023
            </a>
            <span class="ltx_text" id="S3.T1.1.1.25.25.4.2.2.2.1" style="font-size:70%;">
             )
            </span>
           </cite>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.25.25.5">
           Sandbox
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.25.25.6">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.25.25.6.1">
            <tr class="ltx_tr" id="S3.T1.1.1.25.25.6.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.25.25.6.1.1.1">
              Pre-defined,
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.25.25.6.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.25.25.6.1.2.1">
              Data-Derived
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.25.25.7">
           Buyer
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.25.25.8">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.25.25.8.1">
            <tr class="ltx_tr" id="S3.T1.1.1.25.25.8.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.25.25.8.1.1.1">
              Cooperative,
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.25.25.8.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.25.25.8.1.2.1">
              Competitive
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.25.25.9">
           Decentralized
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.25.25.10">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.25.25.10.1">
            <tr class="ltx_tr" id="S3.T1.1.1.25.25.10.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.25.25.10.1.1.1">
              Environment,
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.25.25.10.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.25.25.10.1.2.1">
              Agent interaction
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.25.25.11">
           Memory
          </td>
         </tr>
         <tr class="ltx_tr" id="S3.T1.1.1.26.26">
          <td class="ltx_td ltx_border_r" id="S3.T1.1.1.26.26.1">
          </td>
          <td class="ltx_td ltx_border_r" id="S3.T1.1.1.26.26.2">
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.26.26.3">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.26.26.3.1">
            <tr class="ltx_tr" id="S3.T1.1.1.26.26.3.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.26.26.3.1.1.1">
              Improving
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.26.26.3.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.26.26.3.1.2.1">
              financial trading
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.26.26.4">
           <cite class="ltx_cite ltx_citemacro_cite">
            Li
            <span class="ltx_text ltx_font_italic">
             et al.
            </span>
            <span class="ltx_text" id="S3.T1.1.1.26.26.4.1.1.1.1" style="font-size:70%;">
             (
            </span>
            <a class="ltx_ref" href="#bib.bib40" title="">
             2023g
            </a>
            <span class="ltx_text" id="S3.T1.1.1.26.26.4.2.2.2.1" style="font-size:70%;">
             )
            </span>
           </cite>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.26.26.5">
           Physical
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.26.26.6">
           Pre-defined
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.26.26.7">
           Trader
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.26.26.8">
           Debate
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.26.26.9">
           Decentralized
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.26.26.10">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.26.26.10.1">
            <tr class="ltx_tr" id="S3.T1.1.1.26.26.10.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.26.26.10.1.1.1">
              Environment,
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.26.26.10.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.26.26.10.1.2.1">
              Agent interaction
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.26.26.11">
           Memory
          </td>
         </tr>
         <tr class="ltx_tr" id="S3.T1.1.1.27.27">
          <td class="ltx_td ltx_border_r" id="S3.T1.1.1.27.27.1">
          </td>
          <td class="ltx_td ltx_border_r" id="S3.T1.1.1.27.27.2">
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.27.27.3">
           Economic theories
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.27.27.4">
           <cite class="ltx_cite ltx_citemacro_cite">
            Zhao
            <span class="ltx_text ltx_font_italic">
             et al.
            </span>
            <span class="ltx_text" id="S3.T1.1.1.27.27.4.1.1.1.1" style="font-size:70%;">
             (
            </span>
            <a class="ltx_ref" href="#bib.bib84" title="">
             2023
            </a>
            <span class="ltx_text" id="S3.T1.1.1.27.27.4.2.2.2.1" style="font-size:70%;">
             )
            </span>
           </cite>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.27.27.5">
           Sandbox
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.27.27.6">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.27.27.6.1">
            <tr class="ltx_tr" id="S3.T1.1.1.27.27.6.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.27.27.6.1.1.1">
              Pre-defined,
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.27.27.6.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.27.27.6.1.2.1">
              Model-Generated
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.27.27.7">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.27.27.7.1">
            <tr class="ltx_tr" id="S3.T1.1.1.27.27.7.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.27.27.7.1.1.1">
              Restaurant,
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.27.27.7.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.27.27.7.1.2.1">
              Customer
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.27.27.8">
           Competitive
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.27.27.9">
           Decentralized
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.27.27.10">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.27.27.10.1">
            <tr class="ltx_tr" id="S3.T1.1.1.27.27.10.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.27.27.10.1.1.1">
              Environment,
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.27.27.10.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.27.27.10.1.2.1">
              Agent interaction
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.27.27.11">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.27.27.11.1">
            <tr class="ltx_tr" id="S3.T1.1.1.27.27.11.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.27.27.11.1.1.1">
              Memory,
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.27.27.11.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.27.27.11.1.2.1">
              Self-Evolution
             </td>
            </tr>
           </table>
          </td>
         </tr>
         <tr class="ltx_tr" id="S3.T1.1.1.28.28">
          <td class="ltx_td ltx_border_r" id="S3.T1.1.1.28.28.1">
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.28.28.2" rowspan="2">
           <span class="ltx_text" id="S3.T1.1.1.28.28.2.1">
            <span class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.28.28.2.1.1">
             <span class="ltx_tr" id="S3.T1.1.1.28.28.2.1.1.1">
              <span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.28.28.2.1.1.1.1">
               Recommender
              </span>
             </span>
             <span class="ltx_tr" id="S3.T1.1.1.28.28.2.1.1.2">
              <span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.28.28.2.1.1.2.1">
               Systems
              </span>
             </span>
            </span>
           </span>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.28.28.3">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.28.28.3.1">
            <tr class="ltx_tr" id="S3.T1.1.1.28.28.3.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.28.28.3.1.1.1">
              Simulating
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.28.28.3.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.28.28.3.1.2.1">
              user behaviors
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.28.28.4">
           <cite class="ltx_cite ltx_citemacro_cite">
            Zhang
            <span class="ltx_text ltx_font_italic">
             et al.
            </span>
            <span class="ltx_text" id="S3.T1.1.1.28.28.4.1.1.1.1" style="font-size:70%;">
             (
            </span>
            <a class="ltx_ref" href="#bib.bib79" title="">
             2023a
            </a>
            <span class="ltx_text" id="S3.T1.1.1.28.28.4.2.2.2.1" style="font-size:70%;">
             )
            </span>
           </cite>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.28.28.5">
           Sandbox
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.28.28.6">
           Data-Derived
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.28.28.7">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.28.28.7.1">
            <tr class="ltx_tr" id="S3.T1.1.1.28.28.7.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.28.28.7.1.1.1">
              Users from
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.28.28.7.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.28.28.7.1.2.1">
              MovieLens-1M
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.28.28.8">
           -
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.28.28.9">
           -
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.28.28.10">
           Environment
          </td>
          <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.28.28.11">
           Memory
          </td>
         </tr>
         <tr class="ltx_tr" id="S3.T1.1.1.29.29">
          <td class="ltx_td ltx_border_r" id="S3.T1.1.1.29.29.1">
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.29.29.2">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.29.29.2.1">
            <tr class="ltx_tr" id="S3.T1.1.1.29.29.2.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.29.29.2.1.1.1">
              Simulating user-item
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.29.29.2.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.29.29.2.1.2.1">
              interactions
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.29.29.3">
           <cite class="ltx_cite ltx_citemacro_cite">
            Zhang
            <span class="ltx_text ltx_font_italic">
             et al.
            </span>
            <span class="ltx_text" id="S3.T1.1.1.29.29.3.1.1.1.1" style="font-size:70%;">
             (
            </span>
            <a class="ltx_ref" href="#bib.bib83" title="">
             2023e
            </a>
            <span class="ltx_text" id="S3.T1.1.1.29.29.3.2.2.2.1" style="font-size:70%;">
             )
            </span>
           </cite>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.29.29.4">
           Sandbox
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.29.29.5">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.29.29.5.1">
            <tr class="ltx_tr" id="S3.T1.1.1.29.29.5.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.29.29.5.1.1.1">
              Pre-defined,
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.29.29.5.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.29.29.5.1.2.1">
              Data-Derived
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.29.29.6">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.29.29.6.1">
            <tr class="ltx_tr" id="S3.T1.1.1.29.29.6.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.29.29.6.1.1.1">
              User Agents
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.29.29.6.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.29.29.6.1.2.1">
              Item Agents
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.29.29.7">
           Cooperative
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.29.29.8">
           Decentralized
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.29.29.9">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.29.29.9.1">
            <tr class="ltx_tr" id="S3.T1.1.1.29.29.9.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.29.29.9.1.1.1">
              Environment,
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.29.29.9.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.29.29.9.1.2.1">
              Agent interaction
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.29.29.10">
           Memory
          </td>
         </tr>
         <tr class="ltx_tr" id="S3.T1.1.1.30.30">
          <td class="ltx_td ltx_border_r" id="S3.T1.1.1.30.30.1">
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.30.30.2" rowspan="2">
           <span class="ltx_text" id="S3.T1.1.1.30.30.2.1">
            <span class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.30.30.2.1.1">
             <span class="ltx_tr" id="S3.T1.1.1.30.30.2.1.1.1">
              <span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.30.30.2.1.1.1.1">
               Policy
              </span>
             </span>
             <span class="ltx_tr" id="S3.T1.1.1.30.30.2.1.1.2">
              <span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.30.30.2.1.1.2.1">
               Making
              </span>
             </span>
            </span>
           </span>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.30.30.3">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.30.30.3.1">
            <tr class="ltx_tr" id="S3.T1.1.1.30.30.3.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.30.30.3.1.1.1">
              Public
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.30.30.3.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.30.30.3.1.2.1">
              Administration
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.30.30.4">
           <cite class="ltx_cite ltx_citemacro_cite">
            Xiao
            <span class="ltx_text ltx_font_italic">
             et al.
            </span>
            <span class="ltx_text" id="S3.T1.1.1.30.30.4.1.1.1.1" style="font-size:70%;">
             (
            </span>
            <a class="ltx_ref" href="#bib.bib71" title="">
             2023
            </a>
            <span class="ltx_text" id="S3.T1.1.1.30.30.4.2.2.2.1" style="font-size:70%;">
             )
            </span>
           </cite>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.30.30.5">
           None
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.30.30.6">
           Pre-defined
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.30.30.7">
           Residents
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.30.30.8">
           Cooperative
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.30.30.9">
           Decentralized
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.30.30.10">
           Agent interaction
          </td>
          <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.30.30.11">
           Memory
          </td>
         </tr>
         <tr class="ltx_tr" id="S3.T1.1.1.31.31">
          <td class="ltx_td ltx_border_r" id="S3.T1.1.1.31.31.1">
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.31.31.2">
           War Simulation
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.31.31.3">
           <cite class="ltx_cite ltx_citemacro_cite">
            Hua
            <span class="ltx_text ltx_font_italic">
             et al.
            </span>
            <span class="ltx_text" id="S3.T1.1.1.31.31.3.1.1.1.1" style="font-size:70%;">
             (
            </span>
            <a class="ltx_ref" href="#bib.bib26" title="">
             2023
            </a>
            <span class="ltx_text" id="S3.T1.1.1.31.31.3.2.2.2.1" style="font-size:70%;">
             )
            </span>
           </cite>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.31.31.4">
           None
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.31.31.5">
           Pre-defined
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.31.31.6">
           Countries
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.31.31.7">
           Competitive
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.31.31.8">
           Decentralized
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.31.31.9">
           Agent interaction
          </td>
          <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.31.31.10">
           Memory
          </td>
         </tr>
         <tr class="ltx_tr" id="S3.T1.1.1.32.32">
          <td class="ltx_td ltx_border_r" id="S3.T1.1.1.32.32.1">
          </td>
          <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S3.T1.1.1.32.32.2" rowspan="2">
           <span class="ltx_text" id="S3.T1.1.1.32.32.2.1">
            <span class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.32.32.2.1.1">
             <span class="ltx_tr" id="S3.T1.1.1.32.32.2.1.1.1">
              <span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.32.32.2.1.1.1.1">
               Disease
              </span>
             </span>
            </span>
           </span>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.32.32.3">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.32.32.3.1">
            <tr class="ltx_tr" id="S3.T1.1.1.32.32.3.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.32.32.3.1.1.1">
              Human Behaviors
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.32.32.3.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.32.32.3.1.2.1">
              to epidemics
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.32.32.4">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.32.32.4.1">
            <tr class="ltx_tr" id="S3.T1.1.1.32.32.4.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.32.32.4.1.1.1">
              <span class="ltx_text" id="S3.T1.1.1.32.32.4.1.1.1.1" style="font-size:70%;">
               [Ghaffarzadegan
              </span>
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.32.32.4.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.32.32.4.1.2.1">
              <em class="ltx_emph ltx_font_italic" id="S3.T1.1.1.32.32.4.1.2.1.1" style="font-size:70%;">
               et al.
              </em>
              <span class="ltx_text" id="S3.T1.1.1.32.32.4.1.2.1.2" style="font-size:70%;">
               , 2023]
              </span>
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.32.32.5">
           Sandbox
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.32.32.6">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.32.32.6.1">
            <tr class="ltx_tr" id="S3.T1.1.1.32.32.6.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.32.32.6.1.1.1">
              Pre-defined,
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.32.32.6.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.32.32.6.1.2.1">
              Model-Generated
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.32.32.7">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.32.32.7.1">
            <tr class="ltx_tr" id="S3.T1.1.1.32.32.7.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.32.32.7.1.1.1">
              Conformity
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.32.32.7.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.32.32.7.1.2.1">
              traits
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.32.32.8">
           Cooperative
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.32.32.9">
           Decentralized
          </td>
          <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.32.32.10">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.32.32.10.1">
            <tr class="ltx_tr" id="S3.T1.1.1.32.32.10.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.32.32.10.1.1.1">
              Environment,
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.32.32.10.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.32.32.10.1.2.1">
              Agent interaction
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.32.32.11">
           Memory
          </td>
         </tr>
         <tr class="ltx_tr" id="S3.T1.1.1.33.33">
          <td class="ltx_td ltx_border_bb ltx_border_r" id="S3.T1.1.1.33.33.1">
          </td>
          <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S3.T1.1.1.33.33.2">
           Public health
          </td>
          <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S3.T1.1.1.33.33.3">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.33.33.3.1">
            <tr class="ltx_tr" id="S3.T1.1.1.33.33.3.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.33.33.3.1.1.1">
              <span class="ltx_text" id="S3.T1.1.1.33.33.3.1.1.1.1" style="font-size:70%;">
               [Williams
              </span>
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.33.33.3.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.33.33.3.1.2.1">
              <em class="ltx_emph ltx_font_italic" id="S3.T1.1.1.33.33.3.1.2.1.1" style="font-size:70%;">
               et al.
              </em>
              <span class="ltx_text" id="S3.T1.1.1.33.33.3.1.2.1.2" style="font-size:70%;">
               , 2023]
              </span>
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S3.T1.1.1.33.33.4">
           Sandbox
          </td>
          <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S3.T1.1.1.33.33.5">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.33.33.5.1">
            <tr class="ltx_tr" id="S3.T1.1.1.33.33.5.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.33.33.5.1.1.1">
              Pre-defined,
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.33.33.5.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.33.33.5.1.2.1">
              Model-Generated
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S3.T1.1.1.33.33.6">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.33.33.6.1">
            <tr class="ltx_tr" id="S3.T1.1.1.33.33.6.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.33.33.6.1.1.1">
              Adults aged
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.33.33.6.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.33.33.6.1.2.1">
              18 to 64
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S3.T1.1.1.33.33.7">
           Cooperative
          </td>
          <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S3.T1.1.1.33.33.8">
           Decentralized
          </td>
          <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S3.T1.1.1.33.33.9">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.33.33.9.1">
            <tr class="ltx_tr" id="S3.T1.1.1.33.33.9.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.33.33.9.1.1.1">
              Environment,
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.33.33.9.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.33.33.9.1.2.1">
              Agent interaction
             </td>
            </tr>
           </table>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S3.T1.1.1.33.33.10">
           <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.33.33.10.1">
            <tr class="ltx_tr" id="S3.T1.1.1.33.33.10.1.1">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.33.33.10.1.1.1">
              Memory,
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.33.33.10.1.2">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.33.33.10.1.2.1">
              Dynamic
             </td>
            </tr>
            <tr class="ltx_tr" id="S3.T1.1.1.33.33.10.1.3">
             <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.33.33.10.1.3.1">
              Generation
             </td>
            </tr>
           </table>
          </td>
         </tr>
        </tbody>
       </table>
      </span>
     </div>
     <figcaption class="ltx_caption ltx_centering">
      <span class="ltx_tag ltx_tag_table">
       Table 1:
      </span>
      Summary of the LLM-MA studies. We categorize current work according to their motivation, research domains and goals, and detail each work from different aspects regarding Agents-Environment Interface, Agents Profiling, Agents Communication and Agents Capability Acquisition.
“-” denotes that a particular element is not specifically mentioned in this work.
     </figcaption>
    </figure>
   </section>
  </section>
 </section>
 <section class="ltx_section" id="S4">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    4
   </span>
   Applications
  </h2>
  <div class="ltx_para" id="S4.p1">
   <p class="ltx_p" id="S4.p1.1">
    LLM-MA systems have been used in a wide range of applications. We summarize two kinds of applications in Table
    <a class="ltx_ref" href="#S3.T1" title="Table 1 ‣ Agents Adjustment to Complex Problems: ‣ 3.4 Agents Capabilities Acquisition ‣ 3 Dissecting LLM-MA Systems: Interface, Profiling, Communication, and Capabilities ‣ Large Language Model based Multi-Agents: A Survey of Progress and Challenges">
     <span class="ltx_text ltx_ref_tag">
      1
     </span>
    </a>
    :
    <span class="ltx_text ltx_font_bold" id="S4.p1.1.1">
     Problem Solving
    </span>
    and
    <span class="ltx_text ltx_font_bold" id="S4.p1.1.2">
     World Simulation
    </span>
    . We elaborate on these applications below. Note that this is a fast growing research field and new applications appear almost everyday. We maintain an
    <a class="ltx_ref ltx_href" href="https://github.com/taichengguo/LLM_MultiAgents_Survey_Papers" target="_blank" title="">
     open source repository
    </a>
    to report the latest work.
   </p>
  </div>
  <section class="ltx_subsection" id="S4.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     4.1
    </span>
    LLM-MA for Problem Solving
   </h3>
   <div class="ltx_para" id="S4.SS1.p1">
    <p class="ltx_p" id="S4.SS1.p1.1">
     The main motivation of using LLM-MA for problem solving is to harness the collective capabilities of agents with specialized expertise. These agents, each acting as individuals, collaborate to address complex problems effectively, such as software development, embodied agents, science experiments and science debate. These application examples are introduced next.
    </p>
   </div>
   <section class="ltx_subsubsection" id="S4.SS1.SSS1">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      4.1.1
     </span>
     Software Development
    </h4>
    <div class="ltx_para" id="S4.SS1.SSS1.p1">
     <p class="ltx_p" id="S4.SS1.SSS1.p1.1">
      Given that software development is a complex endeavor requiring the collaboration of various roles like product managers, programmers, and testers, LLM-MA systems are typically set to emulate these distinct roles and collaborate to address the intricate challenge. Following the waterfall or Standardized Operating Procedures (SOPs) workflow of the software development, the communication structure among agents is usually layered. Agents generally interact with the code interpreter, other agents or human to iteratively refine the generated code.
      <cite class="ltx_cite ltx_citemacro_cite">
       Li
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib35" title="">
        2023b
       </a>
       )
      </cite>
      first proposes a simple role-play agent framework, which utilizes the interplay of two roles to realize autonomous programming based on one-sentence user instruction. It provides insights into the “cognitive” processes of communicative agents.
      <cite class="ltx_cite ltx_citemacro_cite">
       Dong
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib14" title="">
        2023b
       </a>
       )
      </cite>
      makes LLMs work as distinct “experts” for sub-tasks in software development, autonomously collaborating to generate code. Moreover,
      <cite class="ltx_cite ltx_citemacro_cite">
       Qian
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib54" title="">
        2023
       </a>
       )
      </cite>
      presents an end-to-end framework for software development, utilizing multiple agents for software development without incorporating advanced human teamwork experience.
      <cite class="ltx_cite ltx_citemacro_cite">
       Hong
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib24" title="">
        2023
       </a>
       )
      </cite>
      first incorporates human workflow insights for more controlled and validated performance. It encodes SOPs into prompts to enhance structured coordination.
      <cite class="ltx_cite ltx_citemacro_cite">
       Huang
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib27" title="">
        2023a
       </a>
       )
      </cite>
      delves deeper into multi-agent based programming by solving the problem of balancing code snippet generation with effective test case generation, execution, and optimization.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S4.SS1.SSS2">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      4.1.2
     </span>
     Embodied Agents
    </h4>
    <div class="ltx_para" id="S4.SS1.SSS2.p1">
     <p class="ltx_p" id="S4.SS1.SSS2.p1.1">
      Most embodied agents applications inherently utilize multiple robots working together to perform complex real-world planning and manipulation tasks such as warehouse management with heterogeneous robot capabilities. Hence, LLM-MA can be used to model robots with different capabilities and cooperate with each other to solve real-world physical tasks.
      <cite class="ltx_cite ltx_citemacro_cite">
       Dasgupta
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib11" title="">
        2023
       </a>
       )
      </cite>
      first explores the potential to use LLM as an action planner for embedded agents.
      <cite class="ltx_cite ltx_citemacro_cite">
       Mandi
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib47" title="">
        2023
       </a>
       )
      </cite>
      introduces RoCo, a novel approach for multi-robot collaboration that uses LLMs for high-level communication and low-level path planning. Each robotic arm is equipped with an LLM, cooperating with inverse kinematics and collision checking. Experimental results demonstrate the adaptability and success of RoCo in collaborative tasks.
      <cite class="ltx_cite ltx_citemacro_cite">
       Zhang
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib81" title="">
        2023c
       </a>
       )
      </cite>
      presents CoELA, a Cooperative Embodied Language Agent, managing discussions and task planning in an LLM-MA setting. This challenging setting is featured with decentralized control, complex partial observation, costly communication, and multi-objective long-horizon tasks.
      <cite class="ltx_cite ltx_citemacro_cite">
       Chen
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib9" title="">
        2023d
       </a>
       )
      </cite>
      investigates communication challenges in scenarios involving a large number of robots, as assigning each robot an LLM will be costly and unpractical due to the long context. The study compares four communication frameworks, centralized, decentralized, and two hybrid models, to evaluate their effectiveness in coordinating complex multi-agent tasks.
      <cite class="ltx_cite ltx_citemacro_cite">
       Yu
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib78" title="">
        2023
       </a>
       )
      </cite>
      proposes Co-NavGPT for multi-robot cooperative visual target navigation, integrating LLM as a global planner to assign frontier goals to each robot.
      <cite class="ltx_cite ltx_citemacro_cite">
       Chen
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib7" title="">
        2023b
       </a>
       )
      </cite>
      proposes an LLM-based consensus-seeking framework, which can be applied as a cooperative planner to a multi-robot aggregation task.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S4.SS1.SSS3">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      4.1.3
     </span>
     Science Experiments
    </h4>
    <div class="ltx_para" id="S4.SS1.SSS3.p1">
     <p class="ltx_p" id="S4.SS1.SSS3.p1.1">
      Like multiple agents play as different specialists and cooperate to solve the Software Development and Embodied Agents problem, multiple agents can also be used to form a science team to conduct science experiments. One important difference from previous applications lies in the crucial role of human oversight, due to the high expenses of the science experiments and the hallucination of the LLM agents. Human experts are at the center of these agents to process the information of agents and give feedback to the agents.
      <cite class="ltx_cite ltx_citemacro_cite">
       Zheng
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib85" title="">
        2023
       </a>
       )
      </cite>
      utilizes multiple LLM-based agents, each focusing on specific tasks for the science experiments including strategy planning, literature search, coding, robotic operations, and labware design. All these agents interact with humans to work collaboratively to optimize the synthesis process of complex materials.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S4.SS1.SSS4">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      4.1.4
     </span>
     Science Debate
    </h4>
    <div class="ltx_para" id="S4.SS1.SSS4.p1">
     <p class="ltx_p" id="S4.SS1.SSS4.p1.1">
      LLM-MA can be set for science debating scenarios, where agents debate with each other to enhance the collective reasoning capabilities in tasks such as Massive Multitask Language Understanding (MMLU)
      <cite class="ltx_cite ltx_citemacro_cite">
       Hendrycks
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib23" title="">
        2020
       </a>
       )
      </cite>
      , Math problems
      <cite class="ltx_cite ltx_citemacro_cite">
       Cobbe
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib10" title="">
        2021
       </a>
       )
      </cite>
      , and StrategyQA
      <cite class="ltx_cite ltx_citemacro_cite">
       Geva
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib20" title="">
        2021
       </a>
       )
      </cite>
      . The main idea is that each agent initially offers its own analysis of a problem, which is then followed by a joint debating process. Through multiple rounds of debate, the agents converge on a single, consensus answer.
      <cite class="ltx_cite ltx_citemacro_cite">
       Du
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib15" title="">
        2023
       </a>
       )
      </cite>
      leverages the multi-agents debate process on a set of six different reasoning and factual accuracy tasks and demonstrates that LLM-MA debating can improve factuality.
      <cite class="ltx_cite ltx_citemacro_cite">
       Xiong
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib73" title="">
        2023
       </a>
       )
      </cite>
      focuses on the commonsense reasoning tasks and formulates a three-stage debate to align with real-world scenarios including fair debate, mismatched debate, and roundtable debate. The paper also analyzes the inter-consistency between different LLMs and claims that debating can improve the inter-consistency.
      <cite class="ltx_cite ltx_citemacro_cite">
       Tang
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib59" title="">
        2023
       </a>
       )
      </cite>
      also utilizes multiple LLM-based agents as distinct domain experts to do the collaborative discussion on a medical report to reach a consensus for medical diagnosis.
     </p>
    </div>
   </section>
  </section>
  <section class="ltx_subsection" id="S4.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     4.2
    </span>
    LLM-MA for World Simulation
   </h3>
   <div class="ltx_para" id="S4.SS2.p1">
    <p class="ltx_p" id="S4.SS2.p1.1">
     Another mainstream application scenario of LLM-MA is the world simulation. Research in this area is rapidly growing and spans a diverse range of fields including social sciences, gaming, psychology, economics, policy-making, etc.
The key reason for employing LLM-MA in world simulations lies in their exceptional role-playing abilities, which are crucial for realistically depicting various roles and viewpoints in a simulated world.
The environment of world simulation projects is usually crafted to reflect the specific scenario being simulated, with agents designed in various profiles to match this context. Unlike the problem solving systems that focus on agent cooperation, world simulation systems involve diverse methods of agent management and communication, reflecting the complexity and variety of real-world interactions.
Next, we explore simulations conducted in diverse fields.
    </p>
   </div>
   <section class="ltx_subsubsection" id="S4.SS2.SSS1">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      4.2.1
     </span>
     Societal Simulation
    </h4>
    <div class="ltx_para" id="S4.SS2.SSS1.p1">
     <p class="ltx_p" id="S4.SS2.SSS1.p1.1">
      In societal simulation, LLM-MA models are used to simulate social behaviors, aiming to explore the potential social dynamics and propagation, test social science theories, and populate virtual spaces and communities with realistic social phenomena
      <cite class="ltx_cite ltx_citemacro_cite">
       Park
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib53" title="">
        2023
       </a>
       )
      </cite>
      . Leveraging LLM’s capabilities, agents with unique profiles engage in extensive communication, generating rich behavioral data for in-depth social science analysis.
     </p>
    </div>
    <div class="ltx_para" id="S4.SS2.SSS1.p2">
     <p class="ltx_p" id="S4.SS2.SSS1.p2.1">
      The scale of societal simulation has expanded over time, beginning with smaller, more intimate settings and progressing to larger, more intricate ones.
Initial work by
      <cite class="ltx_cite ltx_citemacro_cite">
       Park
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib53" title="">
        2023
       </a>
       )
      </cite>
      introduces generative agents within an interactive sandbox environment reminiscent of the sims, allowing end users to engage with a modest community of 25 agents through natural language.
At the same time,
      <cite class="ltx_cite ltx_citemacro_cite">
       Park
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib52" title="">
        2022
       </a>
       )
      </cite>
      develops Social Simulacra, which constructs a simulated community of 1,000 personas. This system takes a designer’s vision for a community—its goals, rules, and member personas—and simulates it, generating behaviors like posting, replying, and even anti-social actions.
Building on this,
      <cite class="ltx_cite ltx_citemacro_cite">
       Gao
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib18" title="">
        2023a
       </a>
       )
      </cite>
      takes the concept further by constructing vast networks comprising 8,563 and 17,945 agents, respectively, designed to simulate social networks focused on the topics of Gender Discrimination and Nuclear Energy. This evolution showcases the increasing complexity and size of simulated environments in recent research.
Recent studies such as
      <cite class="ltx_cite ltx_citemacro_cite">
       Chen
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib7" title="">
        2023b
       </a>
       ); Kaiya
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib29" title="">
        2023
       </a>
       ); Li
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib34" title="">
        2023a
       </a>
       ,
       <a class="ltx_ref" href="#bib.bib39" title="">
        f
       </a>
       ); Ziems
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib88" title="">
        2023
       </a>
       )
      </cite>
      highlight the evolving complexity in multi-agent systems, LLM impacts on social networks, and their integration into social science research.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S4.SS2.SSS2">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      4.2.2
     </span>
     Gaming
    </h4>
    <div class="ltx_para" id="S4.SS2.SSS2.p1">
     <p class="ltx_p" id="S4.SS2.SSS2.p1.1">
      LLM-MA is well-suited for creating simulated gaming environments, allowing agents to assume various roles within games. This technology enables the development of controlled, scalable, and dynamic settings that closely mimic human interactions, making it ideal for testing a range of game theory hypotheses
      <cite class="ltx_cite ltx_citemacro_cite">
       Mao
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib48" title="">
        2023
       </a>
       ); Xu
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib75" title="">
        2023b
       </a>
       )
      </cite>
      .
Most games simulated by LLM-MA rely heavily on natural language communication, offering a sandbox environment within different game settings for exploring or testing game theory hypotheses including reasoning, cooperation, persuasion, deception, leadership, etc.
     </p>
    </div>
    <div class="ltx_para" id="S4.SS2.SSS2.p2">
     <p class="ltx_p" id="S4.SS2.SSS2.p2.1">
      <cite class="ltx_cite ltx_citemacro_cite">
       Akata
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib3" title="">
        2023
       </a>
       )
      </cite>
      leverages behavioral game theory to examine LLMs’ behavior in interactive social settings, particularly their performance in games like the iterated Prisoner’s Dilemma and Battle of the Sexes. Furthermore,
      <cite class="ltx_cite ltx_citemacro_cite">
       Xu
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib75" title="">
        2023b
       </a>
       )
      </cite>
      proposes a framework using ChatArena library
      <cite class="ltx_cite ltx_citemacro_cite">
       Wu
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib69" title="">
        2023b
       </a>
       )
      </cite>
      for engaging LLMs in communication games like Werewolf, using retrieval and reflection on past communications for improvement, as well as the Chain-of-Thought mechanism
      <cite class="ltx_cite ltx_citemacro_cite">
       Wei
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib64" title="">
        2022
       </a>
       )
      </cite>
      .
      <cite class="ltx_cite ltx_citemacro_cite">
       Light
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib44" title="">
        2023b
       </a>
       )
      </cite>
      explores the potential of LLM agents in playing Resistance Avalon, introducing AVALONBENCH, a comprehensive game environment and benchmark for further developing advanced LLMs and multi-agent frameworks.
      <cite class="ltx_cite ltx_citemacro_cite">
       Wang
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib63" title="">
        2023c
       </a>
       )
      </cite>
      also focuses on the capabilities of LLM Agents in dealing with misinformation in the Avalon game, proposing the Recursive Contemplation (ReCon) framework to enhance LLMs’ ability to discern and counteract deceptive information.
      <cite class="ltx_cite ltx_citemacro_cite">
       Xu
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib76" title="">
        2023c
       </a>
       )
      </cite>
      introduces a framework combining LLMs with reinforcement learning (RL) to develop strategic language agents for the Werewolf game. It introduces a new approach to use RL policy in the case that the action and state sets are not predefined but in the natural language setting.
      <cite class="ltx_cite ltx_citemacro_cite">
       Mukobi
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib50" title="">
        2023
       </a>
       )
      </cite>
      designs the “Welfare Diplomacy”, a general-sum variant of the zero-sum board game Diplomacy, where players must balance military conquest and domestic welfare. It also offers an open-source benchmark, aiming to help improve the cooperation ability of multi-agent AI systems. On top of that, there is a work
      <cite class="ltx_cite ltx_citemacro_cite">
       Li
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib36" title="">
        2023c
       </a>
       )
      </cite>
      in a multi-agent cooperative text game testing the agents’ Theory of Mind (ToM), the ability to reason about the concealed mental states of others and is fundamental to human social interactions, collaborations, and communications.
      <cite class="ltx_cite ltx_citemacro_cite">
       Fan
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib16" title="">
        2023
       </a>
       )
      </cite>
      comprehensively assesses the capability of LLMs as rational players, and identifies the weaknesses of LLM-based Agents that even in the explicit game process, agents may still overlook or modify refined beliefs when taking actions.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S4.SS2.SSS3">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      4.2.3
     </span>
     Psychology
    </h4>
    <div class="ltx_para" id="S4.SS2.SSS3.p1">
     <p class="ltx_p" id="S4.SS2.SSS3.p1.1">
      In psychological simulation studies, like in the societal simulation, multiple agents are utilized to simulate humans with various traits and thought processes. However, unlike societal simulations, one approach in psychology involves directly applying psychological experiments to these agents. This method focuses on observing and analyzing their varied behaviors through statistical methods. Here, each agent operates independently, without interacting with others, essentially representing different individuals. Another approach aligns more closely with societal simulations, where multiple agents interact and communicate with each other. In this scenario, psychological theories are applied to understand and analyze the emergent behavioral patterns. This method facilitates the study of interpersonal dynamics and group behaviors, providing insights into how individual psychological traits influence collective actions.
      <cite class="ltx_cite ltx_citemacro_cite">
       Ma
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib46" title="">
        2023
       </a>
       )
      </cite>
      explores the psychological implications and outcomes of employing LLM-based conversational agents for mental well-being support. It emphasizes the need for carefully evaluating the use of LLM-based agents in mental health applications from a psychological perspective.
      <cite class="ltx_cite ltx_citemacro_cite">
       Kovač
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib31" title="">
        2023
       </a>
       )
      </cite>
      introduces a tool named SocialAI school for creating interactive environments simulating social interactions. It draws from developmental psychology to understand how agents can acquire, demonstrate, and evolve social skills such as joint attention, communication, and cultural learning.
      <cite class="ltx_cite ltx_citemacro_cite">
       Zhang
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib82" title="">
        2023d
       </a>
       )
      </cite>
      explores how LLM agents, with distinct traits and thinking patterns, emulate human-like social behaviors such as conformity and majority rule. This integration of psychology into the understanding of agent collaboration offers a novel lens for examining and enhancing the mechanisms behind LLM-based multi-agents systems.
      <cite class="ltx_cite ltx_citemacro_cite">
       Aher
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib2" title="">
        2023
       </a>
       )
      </cite>
      introduces Turing Experiments to evaluate the extent to which large language models can simulate different aspects of human behaviors. The Turing Experiments replicate classical experiments and phenomena in psychology, economics, and sociology using a question-answering format to mimic experimental conditions. They also design a prompt that is used to simulate the responses of multiple
different individuals by varying the name. By simulating various kinds of individuals via LLM, they show that larger models replicate human behavior more faithfully, but they also reveal a hyper-accuracy distortion, especially in knowledge-based tasks.
     </p>
    </div>
    <figure class="ltx_table" id="S4.T2">
     <div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T2.1" style="width:390.3pt;height:269.7pt;vertical-align:-0.5pt;">
      <span class="ltx_transformed_inner" style="transform:translate(-183.3pt,126.4pt) scale(0.515662686845703,0.515662686845703) ;">
       <table class="ltx_tabular ltx_align_middle" id="S4.T2.1.1">
        <tbody class="ltx_tbody">
         <tr class="ltx_tr" id="S4.T2.1.1.1.1">
          <td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T2.1.1.1.1.1">
           <span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.1.1.1">
            Motivation
           </span>
          </td>
          <td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T2.1.1.1.1.2">
           <span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.1.2.1">
            Domain
           </span>
          </td>
          <td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T2.1.1.1.1.3">
           <span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.1.3.1">
            Datasets and Benchmarks
           </span>
          </td>
          <td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T2.1.1.1.1.4">
           <span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.1.4.1">
            Used by
           </span>
          </td>
          <td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.1.1.1.1.5">
           <span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.1.5.1">
            Data Link
           </span>
          </td>
         </tr>
         <tr class="ltx_tr" id="S4.T2.1.1.2.2">
          <td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T2.1.1.2.2.1" rowspan="13">
           <span class="ltx_text" id="S4.T2.1.1.2.2.1.1">
            Problem Solving
           </span>
          </td>
          <td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T2.1.1.2.2.2" rowspan="3">
           <span class="ltx_text" id="S4.T2.1.1.2.2.2.1">
            Software Development
           </span>
          </td>
          <td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T2.1.1.2.2.3">
           HumanEval
          </td>
          <td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T2.1.1.2.2.4">
           <cite class="ltx_cite ltx_citemacro_cite">
            Hong
            <span class="ltx_text ltx_font_italic">
             et al.
            </span>
            (
            <a class="ltx_ref" href="#bib.bib24" title="">
             2023
            </a>
            )
           </cite>
          </td>
          <td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.1.1.2.2.5">
           <a class="ltx_ref ltx_href" href="https://github.com/openai/human-eval" target="_blank" title="">
            Link
           </a>
          </td>
         </tr>
         <tr class="ltx_tr" id="S4.T2.1.1.3.3">
          <td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.1.1.3.3.1">
           MBPP
          </td>
          <td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.1.1.3.3.2">
           <cite class="ltx_cite ltx_citemacro_cite">
            Hong
            <span class="ltx_text ltx_font_italic">
             et al.
            </span>
            (
            <a class="ltx_ref" href="#bib.bib24" title="">
             2023
            </a>
            )
           </cite>
          </td>
          <td class="ltx_td ltx_align_left" id="S4.T2.1.1.3.3.3">
           <a class="ltx_ref ltx_href" href="https://github.com/google-research/google-research/tree/master/mbpp" target="_blank" title="">
            Link
           </a>
          </td>
         </tr>
         <tr class="ltx_tr" id="S4.T2.1.1.4.4">
          <td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.1.1.4.4.1">
           SoftwareDev
          </td>
          <td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.1.1.4.4.2">
           <cite class="ltx_cite ltx_citemacro_cite">
            Hong
            <span class="ltx_text ltx_font_italic">
             et al.
            </span>
            (
            <a class="ltx_ref" href="#bib.bib24" title="">
             2023
            </a>
            )
           </cite>
          </td>
          <td class="ltx_td ltx_align_left" id="S4.T2.1.1.4.4.3">
           <a class="ltx_ref ltx_href" href="https://github.com/geekan/MetaGPT" target="_blank" title="">
            Link
           </a>
          </td>
         </tr>
         <tr class="ltx_tr" id="S4.T2.1.1.5.5">
          <td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T2.1.1.5.5.1" rowspan="4">
           <span class="ltx_text" id="S4.T2.1.1.5.5.1.1">
            Embodied AI
           </span>
          </td>
          <td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T2.1.1.5.5.2">
           RoCoBench
          </td>
          <td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T2.1.1.5.5.3">
           <cite class="ltx_cite ltx_citemacro_cite">
            Mandi
            <span class="ltx_text ltx_font_italic">
             et al.
            </span>
            (
            <a class="ltx_ref" href="#bib.bib47" title="">
             2023
            </a>
            )
           </cite>
          </td>
          <td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.1.1.5.5.4">
           <a class="ltx_ref ltx_href" href="https://github.com/MandiZhao/robot-collab/tree/main/rocobench" target="_blank" title="">
            Link
           </a>
          </td>
         </tr>
         <tr class="ltx_tr" id="S4.T2.1.1.6.6">
          <td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.1.1.6.6.1">
           Communicative Watch-And-Help (C-WAH)
          </td>
          <td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.1.1.6.6.2">
           <cite class="ltx_cite ltx_citemacro_cite">
            Zhang
            <span class="ltx_text ltx_font_italic">
             et al.
            </span>
            (
            <a class="ltx_ref" href="#bib.bib81" title="">
             2023c
            </a>
            )
           </cite>
          </td>
          <td class="ltx_td ltx_align_left" id="S4.T2.1.1.6.6.3">
           <a class="ltx_ref ltx_href" href="https://github.com/UMass-Foundation-Model/Co-LLM-Agents/" target="_blank" title="">
            Link
           </a>
          </td>
         </tr>
         <tr class="ltx_tr" id="S4.T2.1.1.7.7">
          <td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.1.1.7.7.1">
           ThreeDWorld Multi-Agent Transport (TDW-MAT)
          </td>
          <td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.1.1.7.7.2">
           <cite class="ltx_cite ltx_citemacro_cite">
            Zhang
            <span class="ltx_text ltx_font_italic">
             et al.
            </span>
            (
            <a class="ltx_ref" href="#bib.bib81" title="">
             2023c
            </a>
            )
           </cite>
          </td>
          <td class="ltx_td ltx_align_left" id="S4.T2.1.1.7.7.3">
           <a class="ltx_ref ltx_href" href="https://github.com/UMass-Foundation-Model/Co-LLM-Agents/" target="_blank" title="">
            Link
           </a>
          </td>
         </tr>
         <tr class="ltx_tr" id="S4.T2.1.1.8.8">
          <td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.1.1.8.8.1">
           HM3D v0.2
          </td>
          <td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.1.1.8.8.2">
           <cite class="ltx_cite ltx_citemacro_cite">
            Yu
            <span class="ltx_text ltx_font_italic">
             et al.
            </span>
            (
            <a class="ltx_ref" href="#bib.bib78" title="">
             2023
            </a>
            )
           </cite>
          </td>
          <td class="ltx_td ltx_align_left" id="S4.T2.1.1.8.8.3">
           <a class="ltx_ref ltx_href" href="https://aihabitat.org/datasets/hm3d-semantics/" target="_blank" title="">
            Link
           </a>
          </td>
         </tr>
         <tr class="ltx_tr" id="S4.T2.1.1.9.9">
          <td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T2.1.1.9.9.1" rowspan="6">
           <span class="ltx_text" id="S4.T2.1.1.9.9.1.1">
            Science Debate
           </span>
          </td>
          <td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T2.1.1.9.9.2">
           MMLU
          </td>
          <td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T2.1.1.9.9.3">
           <cite class="ltx_cite ltx_citemacro_cite">
            Tang
            <span class="ltx_text ltx_font_italic">
             et al.
            </span>
            (
            <a class="ltx_ref" href="#bib.bib59" title="">
             2023
            </a>
            )
           </cite>
          </td>
          <td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.1.1.9.9.4">
           <a class="ltx_ref ltx_href" href="https://github.com/hendrycks/test" target="_blank" title="">
            Link
           </a>
          </td>
         </tr>
         <tr class="ltx_tr" id="S4.T2.1.1.10.10">
          <td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.1.1.10.10.1">
           MedQA
          </td>
          <td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.1.1.10.10.2">
           <cite class="ltx_cite ltx_citemacro_cite">
            Tang
            <span class="ltx_text ltx_font_italic">
             et al.
            </span>
            (
            <a class="ltx_ref" href="#bib.bib59" title="">
             2023
            </a>
            )
           </cite>
          </td>
          <td class="ltx_td ltx_align_left" id="S4.T2.1.1.10.10.3">
           <a class="ltx_ref ltx_href" href="https://github.com/jind11/MedQA" target="_blank" title="">
            Link
           </a>
          </td>
         </tr>
         <tr class="ltx_tr" id="S4.T2.1.1.11.11">
          <td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.1.1.11.11.1">
           PubMedQA
          </td>
          <td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.1.1.11.11.2">
           <cite class="ltx_cite ltx_citemacro_cite">
            Tang
            <span class="ltx_text ltx_font_italic">
             et al.
            </span>
            (
            <a class="ltx_ref" href="#bib.bib59" title="">
             2023
            </a>
            )
           </cite>
          </td>
          <td class="ltx_td ltx_align_left" id="S4.T2.1.1.11.11.3">
           <a class="ltx_ref ltx_href" href="https://github.com/pubmedqa/pubmedqa" target="_blank" title="">
            Link
           </a>
          </td>
         </tr>
         <tr class="ltx_tr" id="S4.T2.1.1.12.12">
          <td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.1.1.12.12.1">
           GSM8K
          </td>
          <td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.1.1.12.12.2">
           <cite class="ltx_cite ltx_citemacro_cite">
            Du
            <span class="ltx_text ltx_font_italic">
             et al.
            </span>
            (
            <a class="ltx_ref" href="#bib.bib15" title="">
             2023
            </a>
            )
           </cite>
          </td>
          <td class="ltx_td ltx_align_left" id="S4.T2.1.1.12.12.3">
           <a class="ltx_ref ltx_href" href="https://github.com/openai/grade-school-math" target="_blank" title="">
            Link
           </a>
          </td>
         </tr>
         <tr class="ltx_tr" id="S4.T2.1.1.13.13">
          <td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.1.1.13.13.1">
           StrategyQA
          </td>
          <td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.1.1.13.13.2">
           <cite class="ltx_cite ltx_citemacro_cite">
            Xiong
            <span class="ltx_text ltx_font_italic">
             et al.
            </span>
            (
            <a class="ltx_ref" href="#bib.bib73" title="">
             2023
            </a>
            )
           </cite>
          </td>
          <td class="ltx_td ltx_align_left" id="S4.T2.1.1.13.13.3">
           <a class="ltx_ref ltx_href" href="https://github.com/eladsegal/strategyqa" target="_blank" title="">
            Link
           </a>
          </td>
         </tr>
         <tr class="ltx_tr" id="S4.T2.1.1.14.14">
          <td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.1.1.14.14.1">
           Chess Move Validity
          </td>
          <td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.1.1.14.14.2">
           <cite class="ltx_cite ltx_citemacro_cite">
            Du
            <span class="ltx_text ltx_font_italic">
             et al.
            </span>
            (
            <a class="ltx_ref" href="#bib.bib15" title="">
             2023
            </a>
            )
           </cite>
          </td>
          <td class="ltx_td ltx_align_left" id="S4.T2.1.1.14.14.3">
           <a class="ltx_ref ltx_href" href="https://github.com/google/BIG-bench" target="_blank" title="">
            Link
           </a>
          </td>
         </tr>
         <tr class="ltx_tr" id="S4.T2.1.1.15.15">
          <td class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="S4.T2.1.1.15.15.1" rowspan="15">
           <span class="ltx_text" id="S4.T2.1.1.15.15.1.1">
            World Simulation
           </span>
          </td>
          <td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T2.1.1.15.15.2" rowspan="3">
           <span class="ltx_text" id="S4.T2.1.1.15.15.2.1">
            Society
           </span>
          </td>
          <td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T2.1.1.15.15.3">
           SOTOPIA
          </td>
          <td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T2.1.1.15.15.4">
           <cite class="ltx_cite ltx_citemacro_cite">
            Zhou
            <span class="ltx_text ltx_font_italic">
             et al.
            </span>
            (
            <a class="ltx_ref" href="#bib.bib87" title="">
             2023b
            </a>
            )
           </cite>
          </td>
          <td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.1.1.15.15.5">
           /
          </td>
         </tr>
         <tr class="ltx_tr" id="S4.T2.1.1.16.16">
          <td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.1.1.16.16.1">
           Gender Discrimination
          </td>
          <td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.1.1.16.16.2">
           <cite class="ltx_cite ltx_citemacro_cite">
            Gao
            <span class="ltx_text ltx_font_italic">
             et al.
            </span>
            (
            <a class="ltx_ref" href="#bib.bib18" title="">
             2023a
            </a>
            )
           </cite>
          </td>
          <td class="ltx_td ltx_align_left" id="S4.T2.1.1.16.16.3">
           /
          </td>
         </tr>
         <tr class="ltx_tr" id="S4.T2.1.1.17.17">
          <td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.1.1.17.17.1">
           Nuclear Energy
          </td>
          <td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.1.1.17.17.2">
           <cite class="ltx_cite ltx_citemacro_cite">
            Gao
            <span class="ltx_text ltx_font_italic">
             et al.
            </span>
            (
            <a class="ltx_ref" href="#bib.bib18" title="">
             2023a
            </a>
            )
           </cite>
          </td>
          <td class="ltx_td ltx_align_left" id="S4.T2.1.1.17.17.3">
           /
          </td>
         </tr>
         <tr class="ltx_tr" id="S4.T2.1.1.18.18">
          <td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T2.1.1.18.18.1" rowspan="6">
           <span class="ltx_text" id="S4.T2.1.1.18.18.1.1">
            Gaming
           </span>
          </td>
          <td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T2.1.1.18.18.2">
           Werewolf
          </td>
          <td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T2.1.1.18.18.3">
           <cite class="ltx_cite ltx_citemacro_cite">
            Xu
            <span class="ltx_text ltx_font_italic">
             et al.
            </span>
            (
            <a class="ltx_ref" href="#bib.bib75" title="">
             2023b
            </a>
            )
           </cite>
          </td>
          <td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.1.1.18.18.4">
           /
          </td>
         </tr>
         <tr class="ltx_tr" id="S4.T2.1.1.19.19">
          <td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.1.1.19.19.1">
           Avalon
          </td>
          <td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.1.1.19.19.2">
           <cite class="ltx_cite ltx_citemacro_cite">
            Light
            <span class="ltx_text ltx_font_italic">
             et al.
            </span>
            (
            <a class="ltx_ref" href="#bib.bib44" title="">
             2023b
            </a>
            )
           </cite>
          </td>
          <td class="ltx_td ltx_align_left" id="S4.T2.1.1.19.19.3">
           /
          </td>
         </tr>
         <tr class="ltx_tr" id="S4.T2.1.1.20.20">
          <td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.1.1.20.20.1">
           Welfare Diplomacy
          </td>
          <td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.1.1.20.20.2">
           <cite class="ltx_cite ltx_citemacro_cite">
            Mukobi
            <span class="ltx_text ltx_font_italic">
             et al.
            </span>
            (
            <a class="ltx_ref" href="#bib.bib50" title="">
             2023
            </a>
            )
           </cite>
          </td>
          <td class="ltx_td ltx_align_left" id="S4.T2.1.1.20.20.3">
           /
          </td>
         </tr>
         <tr class="ltx_tr" id="S4.T2.1.1.21.21">
          <td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.1.1.21.21.1">
           Layout in the Overcooked-AI environment
          </td>
          <td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.1.1.21.21.2">
           <cite class="ltx_cite ltx_citemacro_cite">
            Agashe
            <span class="ltx_text ltx_font_italic">
             et al.
            </span>
            (
            <a class="ltx_ref" href="#bib.bib1" title="">
             2023
            </a>
            )
           </cite>
          </td>
          <td class="ltx_td ltx_align_left" id="S4.T2.1.1.21.21.3">
           /
          </td>
         </tr>
         <tr class="ltx_tr" id="S4.T2.1.1.22.22">
          <td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.1.1.22.22.1">
           Chameleon
          </td>
          <td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.1.1.22.22.2">
           <cite class="ltx_cite ltx_citemacro_cite">
            Xu
            <span class="ltx_text ltx_font_italic">
             et al.
            </span>
            (
            <a class="ltx_ref" href="#bib.bib74" title="">
             2023a
            </a>
            )
           </cite>
          </td>
          <td class="ltx_td ltx_align_left" id="S4.T2.1.1.22.22.3">
           <a class="ltx_ref ltx_href" href="https://github.com/cathyxl/MAgIC" target="_blank" title="">
            Link
           </a>
          </td>
         </tr>
         <tr class="ltx_tr" id="S4.T2.1.1.23.23">
          <td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.1.1.23.23.1">
           Undercover
          </td>
          <td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.1.1.23.23.2">
           <cite class="ltx_cite ltx_citemacro_cite">
            Xu
            <span class="ltx_text ltx_font_italic">
             et al.
            </span>
            (
            <a class="ltx_ref" href="#bib.bib74" title="">
             2023a
            </a>
            )
           </cite>
          </td>
          <td class="ltx_td ltx_align_left" id="S4.T2.1.1.23.23.3">
           <a class="ltx_ref ltx_href" href="https://github.com/cathyxl/MAgIC" target="_blank" title="">
            Link
           </a>
          </td>
         </tr>
         <tr class="ltx_tr" id="S4.T2.1.1.24.24">
          <td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T2.1.1.24.24.1" rowspan="3">
           <span class="ltx_text" id="S4.T2.1.1.24.24.1.1">
            Psychology
           </span>
          </td>
          <td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T2.1.1.24.24.2">
           Ultimatum Game TE
          </td>
          <td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T2.1.1.24.24.3">
           <cite class="ltx_cite ltx_citemacro_cite">
            Aher
            <span class="ltx_text ltx_font_italic">
             et al.
            </span>
            (
            <a class="ltx_ref" href="#bib.bib2" title="">
             2023
            </a>
            )
           </cite>
          </td>
          <td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.1.1.24.24.4">
           <a class="ltx_ref ltx_href" href="https://github.com/microsoft/turing-experiments/tree/main" target="_blank" title="">
            Link
           </a>
          </td>
         </tr>
         <tr class="ltx_tr" id="S4.T2.1.1.25.25">
          <td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.1.1.25.25.1">
           Garden Path TE
          </td>
          <td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.1.1.25.25.2">
           <cite class="ltx_cite ltx_citemacro_cite">
            Aher
            <span class="ltx_text ltx_font_italic">
             et al.
            </span>
            (
            <a class="ltx_ref" href="#bib.bib2" title="">
             2023
            </a>
            )
           </cite>
          </td>
          <td class="ltx_td ltx_align_left" id="S4.T2.1.1.25.25.3">
           <a class="ltx_ref ltx_href" href="https://github.com/microsoft/turing-experiments/tree/main" target="_blank" title="">
            Link
           </a>
          </td>
         </tr>
         <tr class="ltx_tr" id="S4.T2.1.1.26.26">
          <td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.1.1.26.26.1">
           Wisdom of Crowds TE
          </td>
          <td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.1.1.26.26.2">
           <cite class="ltx_cite ltx_citemacro_cite">
            Aher
            <span class="ltx_text ltx_font_italic">
             et al.
            </span>
            (
            <a class="ltx_ref" href="#bib.bib2" title="">
             2023
            </a>
            )
           </cite>
          </td>
          <td class="ltx_td ltx_align_left" id="S4.T2.1.1.26.26.3">
           <a class="ltx_ref ltx_href" href="https://github.com/microsoft/turing-experiments/tree/main" target="_blank" title="">
            Link
           </a>
          </td>
         </tr>
         <tr class="ltx_tr" id="S4.T2.1.1.27.27">
          <td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T2.1.1.27.27.1" rowspan="2">
           <span class="ltx_text" id="S4.T2.1.1.27.27.1.1">
            Recommender System
           </span>
          </td>
          <td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T2.1.1.27.27.2">
           MovieLens-1M
          </td>
          <td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T2.1.1.27.27.3">
           <cite class="ltx_cite ltx_citemacro_cite">
            Zhang
            <span class="ltx_text ltx_font_italic">
             et al.
            </span>
            (
            <a class="ltx_ref" href="#bib.bib79" title="">
             2023a
            </a>
            )
           </cite>
          </td>
          <td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.1.1.27.27.4">
           <a class="ltx_ref ltx_href" href="https://github.com/LehengTHU/Agent4Rec/tree/master/datasets/ml-1m" target="_blank" title="">
            Link
           </a>
          </td>
         </tr>
         <tr class="ltx_tr" id="S4.T2.1.1.28.28">
          <td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.1.1.28.28.1">
           Amazon review dataset
          </td>
          <td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.1.1.28.28.2">
           <cite class="ltx_cite ltx_citemacro_cite">
            Zhang
            <span class="ltx_text ltx_font_italic">
             et al.
            </span>
            (
            <a class="ltx_ref" href="#bib.bib83" title="">
             2023e
            </a>
            )
           </cite>
          </td>
          <td class="ltx_td ltx_align_left" id="S4.T2.1.1.28.28.3">
           /
          </td>
         </tr>
         <tr class="ltx_tr" id="S4.T2.1.1.29.29">
          <td class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="S4.T2.1.1.29.29.1">
           Policy Making
          </td>
          <td class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="S4.T2.1.1.29.29.2">
           Board Connectivity Evaluation
          </td>
          <td class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="S4.T2.1.1.29.29.3">
           <cite class="ltx_cite ltx_citemacro_cite">
            Hua
            <span class="ltx_text ltx_font_italic">
             et al.
            </span>
            (
            <a class="ltx_ref" href="#bib.bib26" title="">
             2023
            </a>
            )
           </cite>
          </td>
          <td class="ltx_td ltx_align_left ltx_border_b ltx_border_t" id="S4.T2.1.1.29.29.4">
           <a class="ltx_ref ltx_href" href="https://github.com/agiresearch/WarAgent" target="_blank" title="">
            Link
           </a>
          </td>
         </tr>
        </tbody>
       </table>
      </span>
     </div>
     <figcaption class="ltx_caption ltx_centering">
      <span class="ltx_tag ltx_tag_table">
       Table 2:
      </span>
      Datasets and Benchmarks commonly used in LLM-MA studies. “ / ” denotes the unavailability of data link.
     </figcaption>
    </figure>
   </section>
   <section class="ltx_subsubsection" id="S4.SS2.SSS4">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      4.2.4
     </span>
     Economy
    </h4>
    <div class="ltx_para" id="S4.SS2.SSS4.p1">
     <p class="ltx_p" id="S4.SS2.SSS4.p1.1">
      LLM-MA is used to simulate economic and financial trading environments mainly because it can serve as implicit computational models of humans. In these simulations, agents are provided with endowments, and information, and set with pre-defined preferences, allowing for an exploration of their actions in economic and financial contexts. This is similar to the way economists model ’homo economicus’, the characterization of man in some economic theories as a rational person who pursues wealth for his own self-interest
      <cite class="ltx_cite ltx_citemacro_cite">
       Horton (
       <a class="ltx_ref" href="#bib.bib25" title="">
        2023
       </a>
       )
      </cite>
      .
There are several studies demonstrate the diverse applications of LLM-MA in simulating economic scenarios, encompassing macroeconomic activities, information marketplaces, financial trading, and virtual town simulations. Agents interact in cooperative or debate, decentralized environments.
      <cite class="ltx_cite ltx_citemacro_cite">
       Li
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib38" title="">
        2023e
       </a>
       )
      </cite>
      employs LLMs for macroeconomic simulation, featuring prompt-engineering-driven agents that emulate human-like decision-making, thereby enhancing the realism of economic simulations compared to rule-based or other AI agents.
      <cite class="ltx_cite ltx_citemacro_cite">
       Anonymous (
       <a class="ltx_ref" href="#bib.bib4" title="">
        2023
       </a>
       )
      </cite>
      explores the buyer’s inspection paradox in an information marketplace, reveals improved decision-making and answer quality when agents temporarily access information before purchase.
      <cite class="ltx_cite ltx_citemacro_cite">
       Li
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib40" title="">
        2023g
       </a>
       )
      </cite>
      presents an LLM-MA framework for financial trading, emphasizing a layered memory system, debate mechanisms, and individualized trading characters, thereby fortifying decision-making robustness.
      <cite class="ltx_cite ltx_citemacro_cite">
       Zhao
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib84" title="">
        2023
       </a>
       )
      </cite>
      utilizes LLM-based Agents to simulate a virtual town with restaurant and customer agents, yielding insights aligned with sociological and economic theories. These studies collectively illuminate the broad spectrum of applications and advancements in employing LLMs for diverse economic simulation scenarios.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S4.SS2.SSS5">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      4.2.5
     </span>
     Recommender Systems
    </h4>
    <div class="ltx_para" id="S4.SS2.SSS5.p1">
     <p class="ltx_p" id="S4.SS2.SSS5.p1.1">
      The use of the LLM-MA in recommender systems is similar to that in psychology since studies in both fields involve the consideration of extrinsic and intrinsic human factors such as cognitive processes and personality
      <cite class="ltx_cite ltx_citemacro_cite">
       Lex and Schedl (
       <a class="ltx_ref" href="#bib.bib33" title="">
        2022
       </a>
       )
      </cite>
      . One way to use LLM-MA in recommender systems is to directly introduce items to multiple LLM-based agents within diverse traits and conduct statistics of the preferences of different agents. Another way is to treat both users and items as agents and the user-item communication as interactions, simulating the preference propagation. To bridge the gap between offline metrics and real-world performance in recommendation systems, Agent4Rec
      <cite class="ltx_cite ltx_citemacro_cite">
       Zhang
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib79" title="">
        2023a
       </a>
       )
      </cite>
      introduces a simulation platform based on LLM-MA. 1000 generative agents are initialized with the MovieLens-1M dataset to simulate complex user interactions in a recommendation environment.
Agent4Rec shows that LLM-MA can effectively mimic real user preferences and behaviors, provide insights into phenomena like the filter bubble effect, and help uncover causal relationships in recommendation tasks. In Agent4Rec work, agents are used to simulate users and they do not communicate with each other. Different from Agent4Rec work,
      <cite class="ltx_cite ltx_citemacro_cite">
       Zhang
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib83" title="">
        2023e
       </a>
       )
      </cite>
      treats both users and items as agents, optimizing them collectively to reflect and adjust to real-world interaction disparities. This work emphasizes simulating user-item interactions and propagates preferences among agents, capturing the collaborative filtering essence.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S4.SS2.SSS6">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      4.2.6
     </span>
     Policy Making
    </h4>
    <div class="ltx_para" id="S4.SS2.SSS6.p1">
     <p class="ltx_p" id="S4.SS2.SSS6.p1.1">
      Similar to simulations in gaming and economic scenarios, Policy Making requires strong decision-making capabilities to realistic and dynamic complex problems. LLM-MA can be used to simulate the policy making via simulating a virtual government or simulating the impact of various policies on different communities. These simulations provide valuable insights into how policies are formulated and their potential effects, aiding policymakers in understanding and anticipating the consequences of their decisions
      <cite class="ltx_cite ltx_citemacro_cite">
       Farmer and Axtell (
       <a class="ltx_ref" href="#bib.bib17" title="">
        2022
       </a>
       )
      </cite>
      .
The research outlined in
      <cite class="ltx_cite ltx_citemacro_cite">
       Xiao
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib71" title="">
        2023
       </a>
       )
      </cite>
      is centered on simulating a township water pollution crisis. It simulated a town located on an island including a demographic structure of different agents and township head and advisor. Within the water pollution crisis simulation, this work provides an in-depth analysis of how a virtual government entity might respond to such a public administration challenge and how information transfer in the social network in this crisis.
      <cite class="ltx_cite ltx_citemacro_cite">
       Hua
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib26" title="">
        2023
       </a>
       )
      </cite>
      introduces WarAgent to simulate key historical conflicts and provides insights for conflict resolution and understanding, with potential applications in preventing future international conflicts.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S4.SS2.SSS7">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      4.2.7
     </span>
     Disease Propagation Simulation
    </h4>
    <div class="ltx_para" id="S4.SS2.SSS7.p1">
     <p class="ltx_p" id="S4.SS2.SSS7.p1.1">
      Leveraging the societal simulation capabilities of LLM-MA can also be used to simulate disease propagation.
The most recent study in
      <cite class="ltx_cite ltx_citemacro_cite">
       Williams
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib66" title="">
        2023
       </a>
       )
      </cite>
      delves into the use of LLM-MA in simulating disease spread.
The research showcases through various simulations how these LLM-based agents can accurately emulate human responses to disease outbreaks, including behaviors like self-quarantine and isolation during heightened case numbers.
The collective behavior of these agents mirrors the complex patterns of multiple waves typically seen in pandemics, eventually stabilizing into an endemic state.
Impressively, their actions contribute to the attenuation of the epidemic curve.
      <cite class="ltx_cite ltx_citemacro_cite">
       Ghaffarzadegan
       <span class="ltx_text ltx_font_italic">
        et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib21" title="">
        2023
       </a>
       )
      </cite>
      also discusses the epidemic propagation simulation and decomposes the simulation into two parts: the Mechanistic Model which represents the information or propagation of the virus and the Decision-Making Model which represents the agents’ decision-making process when facing the virus.
     </p>
    </div>
   </section>
  </section>
 </section>
 <section class="ltx_section" id="S5">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    5
   </span>
   Implementation Tools and Resources
  </h2>
  <section class="ltx_subsection" id="S5.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     5.1
    </span>
    Multi-Agents Framework
   </h3>
   <div class="ltx_para" id="S5.SS1.p1">
    <p class="ltx_p" id="S5.SS1.p1.1">
     We provide a detailed introduction to three open-source multi-agent frameworks: MetaGPT
     <cite class="ltx_cite ltx_citemacro_cite">
      Hong
      <span class="ltx_text ltx_font_italic">
       et al.
      </span>
      (
      <a class="ltx_ref" href="#bib.bib24" title="">
       2023
      </a>
      )
     </cite>
     , CAMEL
     <cite class="ltx_cite ltx_citemacro_cite">
      Li
      <span class="ltx_text ltx_font_italic">
       et al.
      </span>
      (
      <a class="ltx_ref" href="#bib.bib35" title="">
       2023b
      </a>
      )
     </cite>
     , and Autogen
     <cite class="ltx_cite ltx_citemacro_cite">
      Wu
      <span class="ltx_text ltx_font_italic">
       et al.
      </span>
      (
      <a class="ltx_ref" href="#bib.bib68" title="">
       2023a
      </a>
      )
     </cite>
     .
They are all frameworks that utilize language models for complex task-solving with a focus on multi-agent collaboration, but they differ in their approaches and applications.
    </p>
   </div>
   <div class="ltx_para" id="S5.SS1.p2">
    <p class="ltx_p" id="S5.SS1.p2.1">
     MetaGPT is designed to embed human workflow processes into the operation of language model agents, thereby reducing the hallucination problem that often arises in complex tasks.
It does this by encoding Standard Operating Procedures into the system and using an assembly line approach to assign specific roles to different agents.
    </p>
   </div>
   <div class="ltx_para" id="S5.SS1.p3">
    <p class="ltx_p" id="S5.SS1.p3.1">
     CAMEL, or Communicative Agent Framework, is oriented towards facilitating autonomous cooperation among agents. It uses a novel technique called inception prompting to guide conversational agents towards fulfilling tasks that are consistent with human objectives. This framework also serves as a tool for generating and studying conversational data, helping researchers understand how communicative agents behave and interact.
    </p>
   </div>
   <div class="ltx_para" id="S5.SS1.p4">
    <p class="ltx_p" id="S5.SS1.p4.1">
     AutoGen is a versatile framework that allows for the creation of applications using language models.
It is distinctive for its high level of customization, enabling developers to program agents using both natural language and code to define how these agents interact.
This versatility enables its use in diverse fields, from technical areas such as coding and mathematics to consumer-focused sectors like entertainment.
    </p>
   </div>
   <div class="ltx_para" id="S5.SS1.p5">
    <p class="ltx_p" id="S5.SS1.p5.1">
     More recently,
     <cite class="ltx_cite ltx_citemacro_cite">
      Chen
      <span class="ltx_text ltx_font_italic">
       et al.
      </span>
      (
      <a class="ltx_ref" href="#bib.bib8" title="">
       2023c
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib6" title="">
       a
      </a>
      )
     </cite>
     introduce frameworks for dynamic multi-agent collaboration, while
     <cite class="ltx_cite ltx_citemacro_cite">
      Zhou
      <span class="ltx_text ltx_font_italic">
       et al.
      </span>
      (
      <a class="ltx_ref" href="#bib.bib86" title="">
       2023a
      </a>
      ); Li
      <span class="ltx_text ltx_font_italic">
       et al.
      </span>
      (
      <a class="ltx_ref" href="#bib.bib41" title="">
       2023h
      </a>
      ); Xie
      <span class="ltx_text ltx_font_italic">
       et al.
      </span>
      (
      <a class="ltx_ref" href="#bib.bib72" title="">
       2023
      </a>
      )
     </cite>
     present platforms and libraries for building autonomous agents, emphasizing their adaptability in task-solving and social simulations.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S5.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     5.2
    </span>
    Datasets and Benchmarks
   </h3>
   <div class="ltx_para" id="S5.SS2.p1">
    <p class="ltx_p" id="S5.SS2.p1.1">
     We summarize commonly used datasets or benchmarks for LLM-MA study in Table
     <a class="ltx_ref" href="#S4.T2" title="Table 2 ‣ 4.2.3 Psychology ‣ 4.2 LLM-MA for World Simulation ‣ 4 Applications ‣ Large Language Model based Multi-Agents: A Survey of Progress and Challenges">
      <span class="ltx_text ltx_ref_tag">
       2
      </span>
     </a>
     . We observe that different research applications use different datasets and benchmarks. In the Problem solving scenarios, most datasets and benchmarks are used to evaluate the planning and reasoning capabilities by Multiple agents cooperation or debate. In World Simulation scenarios, datasets and benchmarks are used to evaluate the alignment between the simulated world and real-world or analyze the behaviors of different agents. However, in certain research applications like Science Team operations for experiments and economic modeling, there is still a need for comprehensive benchmarks. The development of such benchmarks would greatly enhance the ability to gauge the success and applicability of LLM-MA in these complex and dynamic fields.
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="S6">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    6
   </span>
   Challenges and Opportunities
  </h2>
  <div class="ltx_para" id="S6.p1">
   <p class="ltx_p" id="S6.p1.1">
    Studies of LLM-MA frameworks and applications are
advancing rapidly, giving rise to numerous challenges and opportunities. We identified several critical challenges and potential areas for future study.
   </p>
  </div>
  <section class="ltx_subsection" id="S6.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     6.1
    </span>
    Advancing into Multi-Modal Environment
   </h3>
   <div class="ltx_para" id="S6.SS1.p1">
    <p class="ltx_p" id="S6.SS1.p1.1">
     Most previous work on LLM-MA has been focused on text-based environments, excelling in processing and generating text. However, there is a notable lack in multi-modal settings, where agents would interact with and interpret data from multiple sensory inputs and generate multiple outputs such as images, audio, video, and physical actions. Integrating LLMs into multi-modal environments presents additional challenges, such as processing diverse data types and enabling agents to understand each other and respond to more than just textual information.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S6.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     6.2
    </span>
    Addressing Hallucination
   </h3>
   <div class="ltx_para" id="S6.SS2.p1">
    <p class="ltx_p" id="S6.SS2.p1.1">
     The hallucination problem is a significant challenge in LLMs and single LLM-based Agent systems. It refers to the phenomenon where the model generates text that is factually incorrect
     <cite class="ltx_cite ltx_citemacro_cite">
      Huang
      <span class="ltx_text ltx_font_italic">
       et al.
      </span>
      (
      <a class="ltx_ref" href="#bib.bib28" title="">
       2023b
      </a>
      )
     </cite>
     . However, this problem takes on an added layer of complexity in a multi-agent setting. In such scenarios, one agent’s hallucination can have a cascading effect. This is due to the interconnected nature of multi-agent systems, where misinformation from one agent can be accepted and further propagated by others in the network.
Therefore, detecting and mitigating hallucinations in LLM-MA is not just a crucial task but also presents a unique set of challenges. It involves not only correcting inaccuracies at the level of individual agents but also managing the flow of information between agents to prevent the spread of these inaccuracies throughout the system.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S6.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     6.3
    </span>
    Acquiring Collective Intelligence
   </h3>
   <div class="ltx_para" id="S6.SS3.p1">
    <p class="ltx_p" id="S6.SS3.p1.1">
     In traditional multi-agent systems, agents often use reinforcement learning to learn from offline training datasets.
However, LLM-MA systems mainly learn from instant feedback, such as interactions with the environment or humans, as we discussed in Section
     <a class="ltx_ref" href="#S3" title="3 Dissecting LLM-MA Systems: Interface, Profiling, Communication, and Capabilities ‣ Large Language Model based Multi-Agents: A Survey of Progress and Challenges">
      <span class="ltx_text ltx_ref_tag">
       3
      </span>
     </a>
     .
This learning style requires a reliable interactive environment and it would be tricky to design such an interactive environment for many tasks, limiting the scalability of LLM-MA systems. Moreover, the prevailing approaches in current research involve employing Memory and Self-Evolution techniques to adjust agents based on feedback. While effective for individual agents, these methods do not fully capitalize on the potential collective intelligence of the agent network. They adjust agents in isolation, overlooking the synergistic effects that can emerge from coordinated multi-agent interactions. Hence, jointly adjusting multiple agents and achieving optimal collective intelligence is still a critical challenge for LLM-MA.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S6.SS4">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     6.4
    </span>
    Scaling Up LLM-MA Systems
   </h3>
   <div class="ltx_para" id="S6.SS4.p1">
    <p class="ltx_p" id="S6.SS4.p1.1">
     LLM-MA systems are composed of a number of individual LLM-based agents, posing a significant challenge of scalability regarding the number of agents.
From the computational complexity perspective, each LLM-based agent, typically built on large language models like GPT-4, demands substantial computational power and memory. Scaling up the number of these agents in an LLM-MA system significantly increases resource requirements. In scenarios with limited computational resource, it would be challenging to develop these LLM-MA systems.
    </p>
   </div>
   <div class="ltx_para" id="S6.SS4.p2">
    <p class="ltx_p" id="S6.SS4.p2.1">
     Additionally, as the number of agents in an LLM-MA system increases, additional complexities and research opportunities emerge, particularly in areas like efficient agent coordination, communication, and understanding the scaling laws of multi-agents. For instance, with more LLM-based agents, the intricacy of ensuring effective coordination and communication rises significantly.
As highlighted in
     <cite class="ltx_cite ltx_citemacro_cite">
      Dibia (
      <a class="ltx_ref" href="#bib.bib12" title="">
       2023
      </a>
      )
     </cite>
     , designing advanced Agents Orchestration methodologies is increasingly important. These methodologies aim to optimize agents workflows, task assignments tailored to different agents, and communication patterns across agents such as communication constraints between agents. Effective Agents Orchestration facilitates harmonious operation among agents, minimizing conflicts and redundancies.
Additionally, exploring and defining the scaling laws that govern the behavior and efficiency of multi-agent systems as they grow larger remains an important area of research. These aspects highlight the need for innovative solutions to optimize LLM-MA systems, making them both effective and resource-efficient.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S6.SS5">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     6.5
    </span>
    Evaluation and Benchmarks
   </h3>
   <div class="ltx_para" id="S6.SS5.p1">
    <p class="ltx_p" id="S6.SS5.p1.1">
     We have summarized the datasets and benchmarks currently available for LLM-MA in Table
     <a class="ltx_ref" href="#S4.T2" title="Table 2 ‣ 4.2.3 Psychology ‣ 4.2 LLM-MA for World Simulation ‣ 4 Applications ‣ Large Language Model based Multi-Agents: A Survey of Progress and Challenges">
      <span class="ltx_text ltx_ref_tag">
       2
      </span>
     </a>
     . This is a starting point, and far from being comprehensive. We identify two significant challenges in evaluating LLM-MA systems and benchmarking their performance against each other.
Firstly, as discussed in
     <cite class="ltx_cite ltx_citemacro_cite">
      Xu
      <span class="ltx_text ltx_font_italic">
       et al.
      </span>
      (
      <a class="ltx_ref" href="#bib.bib74" title="">
       2023a
      </a>
      )
     </cite>
     , much of the existing research focuses on evaluating individual agents’ understanding and reasoning within narrowly defined scenarios. This focus tends to overlook the broader and more complex emergent behaviors that are integral to multi-agent systems.
Secondly, there is a notable shortfall in the development of comprehensive benchmarks across several research domains, such as Science Team for Experiment Operations, Economic analysis, and Disease propagation simulation. This gap presents an obstacle to accurately assessing and benchmarking the full capabilities of LLM-MA systems in these varied and crucial fields.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S6.SS6">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     6.6
    </span>
    Applications and Beyond
   </h3>
   <div class="ltx_para" id="S6.SS6.p1">
    <p class="ltx_p" id="S6.SS6.p1.1">
     The potential of LLM-MA systems extends far beyond their current applications, holding great promise for advanced computational problem-solving in fields such as finance, education, healthcare, environmental science, urban planning and so on. As we have discussed, LLM-MA systems possess the capability to tackle complex problems and simulate various aspects of the real world. While the current role-playing capabilities of LLMs may have limitations, ongoing advancements in LLM technology suggest a bright future. It is anticipated to have more sophisticated methodologies, applications, datasets, and benchmarks tailored for diverse research fields.
Furthermore, there are opportunities to explore LLM-MA systems from various theoretical perspectives, such as Cognitive Science
     <cite class="ltx_cite ltx_citemacro_cite">
      Sumers
      <span class="ltx_text ltx_font_italic">
       et al.
      </span>
      (
      <a class="ltx_ref" href="#bib.bib58" title="">
       2023
      </a>
      )
     </cite>
     , Symbolic Artificial Intelligence, Cybernetics, Complex Systems, and Collective Intelligence. Such a multi-faceted approach could contribute to a more comprehensive understanding and innovative applications in this rapidly evolving field.
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="S7">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    7
   </span>
   Conclusion
  </h2>
  <div class="ltx_para" id="S7.p1">
   <p class="ltx_p" id="S7.p1.1">
    LLM-based Multi-Agents have shown inspiring collective intelligence and rapidly garnered increasing interest among researchers.
In this survey, we first systematically review the development of LLM-MA systems by positioning, differentiating, and connecting them from various aspects, regarding the agents-environment interface, the characterization of agents by LLMs, the strategies for managing agent communication and the paradigms for capability acquisition. We also summarized LLM-MA applications for problem-solving and world simulation. By also highlighting the commonly used datasets and benchmarks and discussing challenges and future opportunities, we hope that this survey can serve as a useful resource for researchers across various research fields, inspiring future research to explore the potential of LLM-based Multi-Agents.
   </p>
  </div>
 </section>
 <section class="ltx_bibliography" id="bib">
  <h2 class="ltx_title ltx_title_bibliography">
   References
  </h2>
  <ul class="ltx_biblist">
   <li class="ltx_bibitem" id="bib.bib1">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Agashe
     <span class="ltx_text ltx_font_italic" id="bib.bib1.2.2.1">
      et al.
     </span>
     [2023]
    </span>
    <span class="ltx_bibblock">
     Saaket Agashe, Yue Fan, and Xin Eric Wang.
    </span>
    <span class="ltx_bibblock">
     Evaluating multi-agent coordination abilities in large language models, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib2">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Aher
     <span class="ltx_text ltx_font_italic" id="bib.bib2.2.2.1">
      et al.
     </span>
     [2023]
    </span>
    <span class="ltx_bibblock">
     Gati Aher, Rosa I. Arriaga, and Adam Tauman Kalai.
    </span>
    <span class="ltx_bibblock">
     Using large language models to simulate multiple humans and replicate human subject studies, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib3">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Akata
     <span class="ltx_text ltx_font_italic" id="bib.bib3.2.2.1">
      et al.
     </span>
     [2023]
    </span>
    <span class="ltx_bibblock">
     Elif Akata, Lion Schulz, Julian Coda-Forno, Seong Joon Oh, Matthias Bethge, and Eric Schulz.
    </span>
    <span class="ltx_bibblock">
     Playing repeated games with large language models.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib3.3.1">
      arXiv preprint arXiv:2305.16867
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib4">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Anonymous [2023]
    </span>
    <span class="ltx_bibblock">
     Anonymous.
    </span>
    <span class="ltx_bibblock">
     Rethinking the buyer’s inspection paradox in information markets with language agents.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib4.1.1">
      Submitted to The Twelfth International Conference on Learning Representations
     </span>
     , 2023.
    </span>
    <span class="ltx_bibblock">
     under review.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib5">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chan
     <span class="ltx_text ltx_font_italic" id="bib.bib5.2.2.1">
      et al.
     </span>
     [2023]
    </span>
    <span class="ltx_bibblock">
     Chi-Min Chan, Weize Chen, Yusheng Su, Jianxuan Yu, Wei Xue, Shanghang Zhang, Jie Fu, and Zhiyuan Liu.
    </span>
    <span class="ltx_bibblock">
     Chateval: Towards better llm-based evaluators through multi-agent debate, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib6">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chen
     <span class="ltx_text ltx_font_italic" id="bib.bib6.2.2.1">
      et al.
     </span>
     [2023a]
    </span>
    <span class="ltx_bibblock">
     Guangyao Chen, Siwei Dong, Yu Shu, Ge Zhang, Jaward Sesay, Börje F Karlsson, Jie Fu, and Yemin Shi.
    </span>
    <span class="ltx_bibblock">
     Autoagents: A framework for automatic agent generation.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib6.3.1">
      arXiv preprint arXiv:2309.17288
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib7">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chen
     <span class="ltx_text ltx_font_italic" id="bib.bib7.2.2.1">
      et al.
     </span>
     [2023b]
    </span>
    <span class="ltx_bibblock">
     Huaben Chen, Wenkang Ji, Lufeng Xu, and Shiyu Zhao.
    </span>
    <span class="ltx_bibblock">
     Multi-agent consensus seeking via large language models.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib7.3.1">
      arXiv preprint arXiv:2310.20151
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib8">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chen
     <span class="ltx_text ltx_font_italic" id="bib.bib8.2.2.1">
      et al.
     </span>
     [2023c]
    </span>
    <span class="ltx_bibblock">
     Weize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei Yuan, Chen Qian, Chi-Min Chan, Yujia Qin, Yaxi Lu, Ruobing Xie, et al.
    </span>
    <span class="ltx_bibblock">
     Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors in agents.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib8.3.1">
      arXiv preprint arXiv:2308.10848
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib9">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chen
     <span class="ltx_text ltx_font_italic" id="bib.bib9.2.2.1">
      et al.
     </span>
     [2023d]
    </span>
    <span class="ltx_bibblock">
     Yongchao Chen, Jacob Arkin, Yang Zhang, Nicholas Roy, and Chuchu Fan.
    </span>
    <span class="ltx_bibblock">
     Scalable multi-robot collaboration with large language models: Centralized or decentralized systems?
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib9.3.1">
      arXiv preprint arXiv:2309.15943
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib10">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Cobbe
     <span class="ltx_text ltx_font_italic" id="bib.bib10.2.2.1">
      et al.
     </span>
     [2021]
    </span>
    <span class="ltx_bibblock">
     Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et al.
    </span>
    <span class="ltx_bibblock">
     Training verifiers to solve math word problems.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib10.3.1">
      arXiv preprint arXiv:2110.14168
     </span>
     , 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib11">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Dasgupta
     <span class="ltx_text ltx_font_italic" id="bib.bib11.2.2.1">
      et al.
     </span>
     [2023]
    </span>
    <span class="ltx_bibblock">
     Ishita Dasgupta, Christine Kaeser-Chen, Kenneth Marino, Arun Ahuja, Sheila Babayan, Felix Hill, and Rob Fergus.
    </span>
    <span class="ltx_bibblock">
     Collaborating with language models for embodied reasoning.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib11.3.1">
      arXiv preprint arXiv:2302.00763
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib12">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Dibia [2023]
    </span>
    <span class="ltx_bibblock">
     Victor Dibia.
    </span>
    <span class="ltx_bibblock">
     Multi-agent llm applications — a review of current research, tools, and challenges.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://newsletter.victordibia.com/p/multi-agent-llm-applications-a-review" target="_blank" title="">
      https://newsletter.victordibia.com/p/multi-agent-llm-applications-a-review
     </a>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib13">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Dong
     <span class="ltx_text ltx_font_italic" id="bib.bib13.2.2.1">
      et al.
     </span>
     [2023a]
    </span>
    <span class="ltx_bibblock">
     Qingxiu Dong, Lei Li, Damai Dai, Ce Zheng, Zhiyong Wu, Baobao Chang, Xu Sun, Jingjing Xu, Lei Li, and Zhifang Sui.
    </span>
    <span class="ltx_bibblock">
     A survey on in-context learning, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib14">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Dong
     <span class="ltx_text ltx_font_italic" id="bib.bib14.2.2.1">
      et al.
     </span>
     [2023b]
    </span>
    <span class="ltx_bibblock">
     Yihong Dong, Xue Jiang, Zhi Jin, and Ge Li.
    </span>
    <span class="ltx_bibblock">
     Self-collaboration code generation via chatgpt, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib15">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Du
     <span class="ltx_text ltx_font_italic" id="bib.bib15.2.2.1">
      et al.
     </span>
     [2023]
    </span>
    <span class="ltx_bibblock">
     Yilun Du, Shuang Li, Antonio Torralba, Joshua B. Tenenbaum, and Igor Mordatch.
    </span>
    <span class="ltx_bibblock">
     Improving factuality and reasoning in language models through multiagent debate, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib16">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Fan
     <span class="ltx_text ltx_font_italic" id="bib.bib16.2.2.1">
      et al.
     </span>
     [2023]
    </span>
    <span class="ltx_bibblock">
     Caoyun Fan, Jindou Chen, Yaohui Jin, and Hao He.
    </span>
    <span class="ltx_bibblock">
     Can large language models serve as rational players in game theory? a systematic analysis.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib16.3.1">
      arXiv preprint arXiv:2312.05488
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib17">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Farmer and Axtell [2022]
    </span>
    <span class="ltx_bibblock">
     J. Doyne Farmer and Robert L. Axtell.
    </span>
    <span class="ltx_bibblock">
     Agent-Based Modeling in Economics and Finance: Past, Present, and Future.
    </span>
    <span class="ltx_bibblock">
     INET Oxford Working Papers 2022-10, Institute for New Economic Thinking at the Oxford Martin School, University of Oxford, June 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib18">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Gao
     <span class="ltx_text ltx_font_italic" id="bib.bib18.3.2.1">
      et al.
     </span>
     [2023a]
    </span>
    <span class="ltx_bibblock">
     Chen Gao, Xiaochong Lan, Zhihong Lu, Jinzhu Mao, Jinghua Piao, Huandong Wang, Depeng Jin, and Yong Li.
    </span>
    <span class="ltx_bibblock">
     S
     <sup class="ltx_sup" id="bib.bib18.4.1">
      3
     </sup>
     : Social-network simulation system with large language model-empowered agents.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib18.5.1">
      arXiv preprint arXiv:2307.14984
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib19">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Gao
     <span class="ltx_text ltx_font_italic" id="bib.bib19.2.2.1">
      et al.
     </span>
     [2023b]
    </span>
    <span class="ltx_bibblock">
     Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, Jiawei Sun, and Haofen Wang.
    </span>
    <span class="ltx_bibblock">
     Retrieval-augmented generation for large language models: A survey.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib19.3.1">
      arXiv preprint arXiv:2312.10997
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib20">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Geva
     <span class="ltx_text ltx_font_italic" id="bib.bib20.2.2.1">
      et al.
     </span>
     [2021]
    </span>
    <span class="ltx_bibblock">
     Mor Geva, Daniel Khashabi, Elad Segal, Tushar Khot, Dan Roth, and Jonathan Berant.
    </span>
    <span class="ltx_bibblock">
     Did aristotle use a laptop? a question answering benchmark with implicit reasoning strategies, 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib21">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Ghaffarzadegan
     <span class="ltx_text ltx_font_italic" id="bib.bib21.2.2.1">
      et al.
     </span>
     [2023]
    </span>
    <span class="ltx_bibblock">
     Navid Ghaffarzadegan, Aritra Majumdar, Ross Williams, and Niyousha Hosseinichimeh.
    </span>
    <span class="ltx_bibblock">
     Generative agent-based modeling: Unveiling social system dynamics through coupling mechanistic models with generative artificial intelligence.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib21.3.1">
      arXiv preprint arXiv:2309.11456
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib22">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Guo
     <span class="ltx_text ltx_font_italic" id="bib.bib22.2.2.1">
      et al.
     </span>
     [2023]
    </span>
    <span class="ltx_bibblock">
     Taicheng Guo, Kehan Guo, Zhengwen Liang, Zhichun Guo, Nitesh V Chawla, Olaf Wiest, Xiangliang Zhang, et al.
    </span>
    <span class="ltx_bibblock">
     What indeed can gpt models do in chemistry? a comprehensive benchmark on eight tasks.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib22.3.1">
      arXiv preprint arXiv:2305.18365
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib23">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Hendrycks
     <span class="ltx_text ltx_font_italic" id="bib.bib23.2.2.1">
      et al.
     </span>
     [2020]
    </span>
    <span class="ltx_bibblock">
     Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt.
    </span>
    <span class="ltx_bibblock">
     Measuring massive multitask language understanding.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib23.3.1">
      arXiv preprint arXiv:2009.03300
     </span>
     , 2020.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib24">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Hong
     <span class="ltx_text ltx_font_italic" id="bib.bib24.2.2.1">
      et al.
     </span>
     [2023]
    </span>
    <span class="ltx_bibblock">
     Sirui Hong, Xiawu Zheng, Jonathan Chen, Yuheng Cheng, Ceyao Zhang, Zili Wang, Steven Ka Shing Yau, Zijuan Lin, Liyang Zhou, Chenyu Ran, et al.
    </span>
    <span class="ltx_bibblock">
     Metagpt: Meta programming for multi-agent collaborative framework.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib24.3.1">
      arXiv preprint arXiv:2308.00352
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib25">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Horton [2023]
    </span>
    <span class="ltx_bibblock">
     John J Horton.
    </span>
    <span class="ltx_bibblock">
     Large language models as simulated economic agents: What can we learn from homo silicus?
    </span>
    <span class="ltx_bibblock">
     Technical report, National Bureau of Economic Research, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib26">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Hua
     <span class="ltx_text ltx_font_italic" id="bib.bib26.2.2.1">
      et al.
     </span>
     [2023]
    </span>
    <span class="ltx_bibblock">
     Wenyue Hua, Lizhou Fan, Lingyao Li, Kai Mei, Jianchao Ji, Yingqiang Ge, Libby Hemphill, and Yongfeng Zhang.
    </span>
    <span class="ltx_bibblock">
     War and peace (waragent): Large language model-based multi-agent simulation of world wars, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib27">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Huang
     <span class="ltx_text ltx_font_italic" id="bib.bib27.2.2.1">
      et al.
     </span>
     [2023a]
    </span>
    <span class="ltx_bibblock">
     Dong Huang, Qingwen Bu, Jie M. Zhang, Michael Luck, and Heming Cui.
    </span>
    <span class="ltx_bibblock">
     Agentcoder: Multi-agent-based code generation with iterative testing and optimisation, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib28">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Huang
     <span class="ltx_text ltx_font_italic" id="bib.bib28.2.2.1">
      et al.
     </span>
     [2023b]
    </span>
    <span class="ltx_bibblock">
     Lei Huang, Weijiang Yu, Weitao Ma, Weihong Zhong, Zhangyin Feng, Haotian Wang, Qianglong Chen, Weihua Peng, Xiaocheng Feng, Bing Qin, et al.
    </span>
    <span class="ltx_bibblock">
     A survey on hallucination in large language models: Principles, taxonomy, challenges, and open questions.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib28.3.1">
      arXiv preprint arXiv:2311.05232
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib29">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Kaiya
     <span class="ltx_text ltx_font_italic" id="bib.bib29.2.2.1">
      et al.
     </span>
     [2023]
    </span>
    <span class="ltx_bibblock">
     Zhao Kaiya, Michelangelo Naim, Jovana Kondic, Manuel Cortes, Jiaxin Ge, Shuying Luo, Guangyu Robert Yang, and Andrew Ahn.
    </span>
    <span class="ltx_bibblock">
     Lyfe agents: Generative agents for low-cost real-time social interactions.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib29.3.1">
      arXiv preprint arXiv:2310.02172
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib30">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Khot
     <span class="ltx_text ltx_font_italic" id="bib.bib30.2.2.1">
      et al.
     </span>
     [2023]
    </span>
    <span class="ltx_bibblock">
     Tushar Khot, Harsh Trivedi, Matthew Finlayson, Yao Fu, Kyle Richardson, Peter Clark, and Ashish Sabharwal.
    </span>
    <span class="ltx_bibblock">
     Decomposed prompting: A modular approach for solving complex tasks, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib31">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Kovač
     <span class="ltx_text ltx_font_italic" id="bib.bib31.2.2.1">
      et al.
     </span>
     [2023]
    </span>
    <span class="ltx_bibblock">
     Grgur Kovač, Rémy Portelas, Peter Ford Dominey, and Pierre-Yves Oudeyer.
    </span>
    <span class="ltx_bibblock">
     The socialai school: Insights from developmental psychology towards artificial socio-cultural agents.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib31.3.1">
      arXiv preprint arXiv:2307.07871
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib32">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Lewis
     <span class="ltx_text ltx_font_italic" id="bib.bib32.2.2.1">
      et al.
     </span>
     [2021]
    </span>
    <span class="ltx_bibblock">
     Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen tau Yih, Tim Rocktäschel, Sebastian Riedel, and Douwe Kiela.
    </span>
    <span class="ltx_bibblock">
     Retrieval-augmented generation for knowledge-intensive nlp tasks, 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib33">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Lex and Schedl [2022]
    </span>
    <span class="ltx_bibblock">
     Elisabeth Lex and Markus Schedl.
    </span>
    <span class="ltx_bibblock">
     Psychology-informed recommender systems: A human-centric perspective on recommender systems.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib33.1.1">
      Proceedings of the 2022 Conference on Human Information Interaction and Retrieval
     </span>
     , CHIIR ’22, page 367–368, New York, NY, USA, 2022. Association for Computing Machinery.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib34">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Li
     <span class="ltx_text ltx_font_italic" id="bib.bib34.2.2.1">
      et al.
     </span>
     [2023a]
    </span>
    <span class="ltx_bibblock">
     Chao Li, Xing Su, Chao Fan, Haoying Han, Cong Xue, and Chunmo Zheng.
    </span>
    <span class="ltx_bibblock">
     Quantifying the impact of large language models on collective opinion dynamics.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib34.3.1">
      arXiv preprint arXiv:2308.03313
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib35">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Li
     <span class="ltx_text ltx_font_italic" id="bib.bib35.2.2.1">
      et al.
     </span>
     [2023b]
    </span>
    <span class="ltx_bibblock">
     Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii Khizbullin, and Bernard Ghanem.
    </span>
    <span class="ltx_bibblock">
     Camel: Communicative agents for” mind” exploration of large scale language model society.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib35.3.1">
      arXiv preprint arXiv:2303.17760
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib36">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Li
     <span class="ltx_text ltx_font_italic" id="bib.bib36.2.2.1">
      et al.
     </span>
     [2023c]
    </span>
    <span class="ltx_bibblock">
     Huao Li, Yu Quan Chong, Simon Stepputtis, Joseph Campbell, Dana Hughes, Michael Lewis, and Katia Sycara.
    </span>
    <span class="ltx_bibblock">
     Theory of mind for multi-agent collaboration via large language models, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib37">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Li
     <span class="ltx_text ltx_font_italic" id="bib.bib37.2.2.1">
      et al.
     </span>
     [2023d]
    </span>
    <span class="ltx_bibblock">
     Minghao Li, Yingxiu Zhao, Bowen Yu, Feifan Song, Hangyu Li, Haiyang Yu, Zhoujun Li, Fei Huang, and Yongbin Li.
    </span>
    <span class="ltx_bibblock">
     Api-bank: A comprehensive benchmark for tool-augmented llms, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib38">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Li
     <span class="ltx_text ltx_font_italic" id="bib.bib38.2.2.1">
      et al.
     </span>
     [2023e]
    </span>
    <span class="ltx_bibblock">
     Nian Li, Chen Gao, Yong Li, and Qingmin Liao.
    </span>
    <span class="ltx_bibblock">
     Large language model-empowered agents for simulating macroeconomic activities, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib39">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Li
     <span class="ltx_text ltx_font_italic" id="bib.bib39.2.2.1">
      et al.
     </span>
     [2023f]
    </span>
    <span class="ltx_bibblock">
     Siyu Li, Jin Yang, and Kui Zhao.
    </span>
    <span class="ltx_bibblock">
     Are you in a masquerade? exploring the behavior and impact of large language model driven social bots in online social networks.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib39.3.1">
      arXiv preprint arXiv:2307.10337
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib40">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Li
     <span class="ltx_text ltx_font_italic" id="bib.bib40.2.2.1">
      et al.
     </span>
     [2023g]
    </span>
    <span class="ltx_bibblock">
     Yang Li, Yangyang Yu, Haohang Li, Zhi Chen, and Khaldoun Khashanah.
    </span>
    <span class="ltx_bibblock">
     Tradinggpt: Multi-agent system with layered memory and distinct characters for enhanced financial trading performance, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib41">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Li
     <span class="ltx_text ltx_font_italic" id="bib.bib41.2.2.1">
      et al.
     </span>
     [2023h]
    </span>
    <span class="ltx_bibblock">
     Yuan Li, Yixuan Zhang, and Lichao Sun.
    </span>
    <span class="ltx_bibblock">
     Metaagents: Simulating interactions of human behaviors for llm-based task-oriented coordination via collaborative generative agents.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib41.3.1">
      arXiv preprint arXiv:2310.06500
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib42">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Liang
     <span class="ltx_text ltx_font_italic" id="bib.bib42.2.2.1">
      et al.
     </span>
     [2023]
    </span>
    <span class="ltx_bibblock">
     Zhenwen Liang, Wenhao Yu, Tanmay Rajpurohit, Peter Clark, Xiangliang Zhang, and Ashwin Kaylan.
    </span>
    <span class="ltx_bibblock">
     Let gpt be a math tutor: Teaching math word problem solvers with customized exercise generation.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib42.3.1">
      arXiv preprint arXiv:2305.14386
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib43">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Light
     <span class="ltx_text ltx_font_italic" id="bib.bib43.2.2.1">
      et al.
     </span>
     [2023a]
    </span>
    <span class="ltx_bibblock">
     Jonathan Light, Min Cai, Sheng Shen, and Ziniu Hu.
    </span>
    <span class="ltx_bibblock">
     Avalonbench: Evaluating llms playing the game of avalon, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib44">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Light
     <span class="ltx_text ltx_font_italic" id="bib.bib44.2.2.1">
      et al.
     </span>
     [2023b]
    </span>
    <span class="ltx_bibblock">
     Jonathan Light, Min Cai, Sheng Shen, and Ziniu Hu.
    </span>
    <span class="ltx_bibblock">
     From text to tactic: Evaluating llms playing the game of avalon.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib44.3.1">
      arXiv preprint arXiv:2310.05036
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib45">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Liu
     <span class="ltx_text ltx_font_italic" id="bib.bib45.2.2.1">
      et al.
     </span>
     [2023]
    </span>
    <span class="ltx_bibblock">
     Zijun Liu, Yanzhe Zhang, Peng Li, Yang Liu, and Diyi Yang.
    </span>
    <span class="ltx_bibblock">
     Dynamic llm-agent network: An llm-agent collaboration framework with agent team optimization.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib45.3.1">
      arXiv preprint arXiv:2310.02170
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib46">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Ma
     <span class="ltx_text ltx_font_italic" id="bib.bib46.2.2.1">
      et al.
     </span>
     [2023]
    </span>
    <span class="ltx_bibblock">
     Zilin Ma, Yiyang Mei, and Zhaoyuan Su.
    </span>
    <span class="ltx_bibblock">
     Understanding the benefits and challenges of using large language model-based conversational agents for mental well-being support.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib46.3.1">
      arXiv preprint arXiv:2307.15810
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib47">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Mandi
     <span class="ltx_text ltx_font_italic" id="bib.bib47.2.2.1">
      et al.
     </span>
     [2023]
    </span>
    <span class="ltx_bibblock">
     Zhao Mandi, Shreeya Jain, and Shuran Song.
    </span>
    <span class="ltx_bibblock">
     Roco: Dialectic multi-robot collaboration with large language models.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib47.3.1">
      arXiv preprint arXiv:2307.04738
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib48">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Mao
     <span class="ltx_text ltx_font_italic" id="bib.bib48.2.2.1">
      et al.
     </span>
     [2023]
    </span>
    <span class="ltx_bibblock">
     Shaoguang Mao, Yuzhe Cai, Yan Xia, Wenshan Wu, Xun Wang, Fengyi Wang, Tao Ge, and Furu Wei.
    </span>
    <span class="ltx_bibblock">
     Alympics: Language agents meet game theory.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib48.3.1">
      arXiv preprint arXiv:2311.03220
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib49">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Moura [2023]
    </span>
    <span class="ltx_bibblock">
     João Moura.
    </span>
    <span class="ltx_bibblock">
     Crewai.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/joaomdmoura/crewAI" target="_blank" title="">
      https://github.com/joaomdmoura/crewAI
     </a>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib50">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Mukobi
     <span class="ltx_text ltx_font_italic" id="bib.bib50.2.2.1">
      et al.
     </span>
     [2023]
    </span>
    <span class="ltx_bibblock">
     Gabriel Mukobi, Hannah Erlebach, Niklas Lauffer, Lewis Hammond, Alan Chan, and Jesse Clifton.
    </span>
    <span class="ltx_bibblock">
     Welfare diplomacy: Benchmarking language model cooperation.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib50.3.1">
      arXiv preprint arXiv:2310.08901
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib51">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Nascimento
     <span class="ltx_text ltx_font_italic" id="bib.bib51.2.2.1">
      et al.
     </span>
     [2023]
    </span>
    <span class="ltx_bibblock">
     Nathalia Nascimento, Paulo Alencar, and Donald Cowan.
    </span>
    <span class="ltx_bibblock">
     Self-adaptive large language model (llm)-based multiagent systems.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib51.3.1">
      2023 IEEE International Conference on Autonomic Computing and Self-Organizing Systems Companion (ACSOS-C)
     </span>
     , pages 104–109. IEEE, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib52">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Park
     <span class="ltx_text ltx_font_italic" id="bib.bib52.2.2.1">
      et al.
     </span>
     [2022]
    </span>
    <span class="ltx_bibblock">
     Joon Sung Park, Lindsay Popowski, Carrie Cai, Meredith Ringel Morris, Percy Liang, and Michael S Bernstein.
    </span>
    <span class="ltx_bibblock">
     Social simulacra: Creating populated prototypes for social computing systems.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib52.3.1">
      Proceedings of the 35th Annual ACM Symposium on User Interface Software and Technology
     </span>
     , pages 1–18, 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib53">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Park
     <span class="ltx_text ltx_font_italic" id="bib.bib53.2.2.1">
      et al.
     </span>
     [2023]
    </span>
    <span class="ltx_bibblock">
     Joon Sung Park, Joseph C O’Brien, Carrie J Cai, Meredith Ringel Morris, Percy Liang, and Michael S Bernstein.
    </span>
    <span class="ltx_bibblock">
     Generative agents: Interactive simulacra of human behavior.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib53.3.1">
      arXiv preprint arXiv:2304.03442
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib54">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Qian
     <span class="ltx_text ltx_font_italic" id="bib.bib54.2.2.1">
      et al.
     </span>
     [2023]
    </span>
    <span class="ltx_bibblock">
     Chen Qian, Xin Cong, Wei Liu, Cheng Yang, Weize Chen, Yusheng Su, Yufan Dang, Jiahao Li, Juyuan Xu, Dahai Li, Zhiyuan Liu, and Maosong Sun.
    </span>
    <span class="ltx_bibblock">
     Communicative agents for software development, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib55">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Ruan
     <span class="ltx_text ltx_font_italic" id="bib.bib55.2.2.1">
      et al.
     </span>
     [2023]
    </span>
    <span class="ltx_bibblock">
     Jingqing Ruan, Yihong Chen, Bin Zhang, Zhiwei Xu, Tianpeng Bao, Guoqing Du, Shiwei Shi, Hangyu Mao, Ziyue Li, Xingyu Zeng, and Rui Zhao.
    </span>
    <span class="ltx_bibblock">
     Tptu: Large language model-based ai agents for task planning and tool usage, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib56">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Russell and Norvig [2009]
    </span>
    <span class="ltx_bibblock">
     Stuart Russell and Peter Norvig.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib56.1.1">
      Artificial Intelligence: A Modern Approach
     </span>
     .
    </span>
    <span class="ltx_bibblock">
     Prentice Hall Press, USA, 3rd edition, 2009.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib57">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Shinn
     <span class="ltx_text ltx_font_italic" id="bib.bib57.2.2.1">
      et al.
     </span>
     [2023]
    </span>
    <span class="ltx_bibblock">
     Noah Shinn, Federico Cassano, Edward Berman, Ashwin Gopinath, Karthik Narasimhan, and Shunyu Yao.
    </span>
    <span class="ltx_bibblock">
     Reflexion: Language agents with verbal reinforcement learning, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib58">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Sumers
     <span class="ltx_text ltx_font_italic" id="bib.bib58.2.2.1">
      et al.
     </span>
     [2023]
    </span>
    <span class="ltx_bibblock">
     Theodore R Sumers, Shunyu Yao, Karthik Narasimhan, and Thomas L Griffiths.
    </span>
    <span class="ltx_bibblock">
     Cognitive architectures for language agents.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib58.3.1">
      arXiv preprint arXiv:2309.02427
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib59">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Tang
     <span class="ltx_text ltx_font_italic" id="bib.bib59.2.2.1">
      et al.
     </span>
     [2023]
    </span>
    <span class="ltx_bibblock">
     Xiangru Tang, Anni Zou, Zhuosheng Zhang, Yilun Zhao, Xingyao Zhang, Arman Cohan, and Mark Gerstein.
    </span>
    <span class="ltx_bibblock">
     Medagents: Large language models as collaborators for zero-shot medical reasoning, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib60">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang
     <span class="ltx_text ltx_font_italic" id="bib.bib60.2.2.1">
      et al.
     </span>
     [2021]
    </span>
    <span class="ltx_bibblock">
     Zijie J. Wang, Dongjin Choi, Shenyu Xu, and Diyi Yang.
    </span>
    <span class="ltx_bibblock">
     Putting humans in the natural language processing loop: A survey, 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib61">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang
     <span class="ltx_text ltx_font_italic" id="bib.bib61.2.2.1">
      et al.
     </span>
     [2023a]
    </span>
    <span class="ltx_bibblock">
     Kuan Wang, Yadong Lu, Michael Santacroce, Yeyun Gong, Chao Zhang, and Yelong Shen.
    </span>
    <span class="ltx_bibblock">
     Adapting llm agents through communication, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib62">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang
     <span class="ltx_text ltx_font_italic" id="bib.bib62.2.2.1">
      et al.
     </span>
     [2023b]
    </span>
    <span class="ltx_bibblock">
     Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, Wayne Xin Zhao, Zhewei Wei, and Ji-Rong Wen.
    </span>
    <span class="ltx_bibblock">
     A survey on large language model based autonomous agents, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib63">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang
     <span class="ltx_text ltx_font_italic" id="bib.bib63.2.2.1">
      et al.
     </span>
     [2023c]
    </span>
    <span class="ltx_bibblock">
     Shenzhi Wang, Chang Liu, Zilong Zheng, Siyuan Qi, Shuo Chen, Qisen Yang, Andrew Zhao, Chaofei Wang, Shiji Song, and Gao Huang.
    </span>
    <span class="ltx_bibblock">
     Avalon’s game of thoughts: Battle against deception through recursive contemplation.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib63.3.1">
      arXiv preprint arXiv:2310.01320
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib64">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wei
     <span class="ltx_text ltx_font_italic" id="bib.bib64.2.2.1">
      et al.
     </span>
     [2022]
    </span>
    <span class="ltx_bibblock">
     Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al.
    </span>
    <span class="ltx_bibblock">
     Chain-of-thought prompting elicits reasoning in large language models.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib64.3.1">
      Advances in Neural Information Processing Systems
     </span>
     , 35:24824–24837, 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib65">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Weng [2023]
    </span>
    <span class="ltx_bibblock">
     Lilian Weng.
    </span>
    <span class="ltx_bibblock">
     Llm powered autonomous agents.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://lilianweng.github.io/posts/2023-06-23-agent/" target="_blank" title="">
      https://lilianweng.github.io/posts/2023-06-23-agent/
     </a>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib66">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Williams
     <span class="ltx_text ltx_font_italic" id="bib.bib66.2.2.1">
      et al.
     </span>
     [2023]
    </span>
    <span class="ltx_bibblock">
     Ross Williams, Niyousha Hosseinichimeh, Aritra Majumdar, and Navid Ghaffarzadegan.
    </span>
    <span class="ltx_bibblock">
     Epidemic modeling with generative agents.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib66.3.1">
      arXiv preprint arXiv:2307.04986
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib67">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wooldridge and Jennings [1995]
    </span>
    <span class="ltx_bibblock">
     Michael Wooldridge and Nicholas R. Jennings.
    </span>
    <span class="ltx_bibblock">
     Intelligent agents: theory and practice.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib67.1.1">
      The Knowledge Engineering Review
     </span>
     , 10:115 – 152, 1995.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib68">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wu
     <span class="ltx_text ltx_font_italic" id="bib.bib68.2.2.1">
      et al.
     </span>
     [2023a]
    </span>
    <span class="ltx_bibblock">
     Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Shaokun Zhang, Erkang Zhu, Beibin Li, Li Jiang, Xiaoyun Zhang, and Chi Wang.
    </span>
    <span class="ltx_bibblock">
     Autogen: Enabling next-gen llm applications via multi-agent conversation framework.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib68.3.1">
      arXiv preprint arXiv:2308.08155
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib69">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wu
     <span class="ltx_text ltx_font_italic" id="bib.bib69.2.2.1">
      et al.
     </span>
     [2023b]
    </span>
    <span class="ltx_bibblock">
     Yuxiang Wu, Zhengyao Jiang, Akbir Khan, Yao Fu, Laura Ruis, Edward Grefenstette, and Tim Rocktäschel.
    </span>
    <span class="ltx_bibblock">
     Chatarena: Multi-agent language game environments for large language models.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib69.3.1">
      GitHub repository
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib70">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Xi
     <span class="ltx_text ltx_font_italic" id="bib.bib70.2.2.1">
      et al.
     </span>
     [2023]
    </span>
    <span class="ltx_bibblock">
     Zhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding, Boyang Hong, Ming Zhang, Junzhe Wang, Senjie Jin, Enyu Zhou, Rui Zheng, Xiaoran Fan, Xiao Wang, Limao Xiong, Yuhao Zhou, Weiran Wang, Changhao Jiang, Yicheng Zou, Xiangyang Liu, Zhangyue Yin, Shihan Dou, Rongxiang Weng, Wensen Cheng, Qi Zhang, Wenjuan Qin, Yongyan Zheng, Xipeng Qiu, Xuanjing Huang, and Tao Gui.
    </span>
    <span class="ltx_bibblock">
     The rise and potential of large language model based agents: A survey, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib71">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Xiao
     <span class="ltx_text ltx_font_italic" id="bib.bib71.2.2.1">
      et al.
     </span>
     [2023]
    </span>
    <span class="ltx_bibblock">
     Bushi Xiao, Ziyuan Yin, and Zixuan Shan.
    </span>
    <span class="ltx_bibblock">
     Simulating public administration crisis: A novel generative agent-based simulation system to lower technology barriers in social science research.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib71.3.1">
      arXiv preprint arXiv:2311.06957
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib72">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Xie
     <span class="ltx_text ltx_font_italic" id="bib.bib72.2.2.1">
      et al.
     </span>
     [2023]
    </span>
    <span class="ltx_bibblock">
     Tianbao Xie, Fan Zhou, Zhoujun Cheng, Peng Shi, Luoxuan Weng, Yitao Liu, Toh Jing Hua, Junning Zhao, Qian Liu, Che Liu, et al.
    </span>
    <span class="ltx_bibblock">
     Openagents: An open platform for language agents in the wild.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib72.3.1">
      arXiv preprint arXiv:2310.10634
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib73">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Xiong
     <span class="ltx_text ltx_font_italic" id="bib.bib73.2.2.1">
      et al.
     </span>
     [2023]
    </span>
    <span class="ltx_bibblock">
     Kai Xiong, Xiao Ding, Yixin Cao, Ting Liu, and Bing Qin.
    </span>
    <span class="ltx_bibblock">
     Examining inter-consistency of large language models collaboration: An in-depth analysis via debate, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib74">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Xu
     <span class="ltx_text ltx_font_italic" id="bib.bib74.2.2.1">
      et al.
     </span>
     [2023a]
    </span>
    <span class="ltx_bibblock">
     Lin Xu, Zhiyuan Hu, Daquan Zhou, Hongyu Ren, Zhen Dong, Kurt Keutzer, See Kiong Ng, and Jiashi Feng.
    </span>
    <span class="ltx_bibblock">
     Magic: Investigation of large language model powered multi-agent in cognition, adaptability, rationality and collaboration, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib75">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Xu
     <span class="ltx_text ltx_font_italic" id="bib.bib75.2.2.1">
      et al.
     </span>
     [2023b]
    </span>
    <span class="ltx_bibblock">
     Yuzhuang Xu, Shuo Wang, Peng Li, Fuwen Luo, Xiaolong Wang, Weidong Liu, and Yang Liu.
    </span>
    <span class="ltx_bibblock">
     Exploring large language models for communication games: An empirical study on werewolf.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib75.3.1">
      arXiv preprint arXiv:2309.04658
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib76">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Xu
     <span class="ltx_text ltx_font_italic" id="bib.bib76.2.2.1">
      et al.
     </span>
     [2023c]
    </span>
    <span class="ltx_bibblock">
     Zelai Xu, Chao Yu, Fei Fang, Yu Wang, and Yi Wu.
    </span>
    <span class="ltx_bibblock">
     Language agents with reinforcement learning for strategic play in the werewolf game.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib76.3.1">
      arXiv preprint arXiv:2310.18940
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib77">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Yao
     <span class="ltx_text ltx_font_italic" id="bib.bib77.2.2.1">
      et al.
     </span>
     [2023]
    </span>
    <span class="ltx_bibblock">
     Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L. Griffiths, Yuan Cao, and Karthik Narasimhan.
    </span>
    <span class="ltx_bibblock">
     Tree of thoughts: Deliberate problem solving with large language models, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib78">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Yu
     <span class="ltx_text ltx_font_italic" id="bib.bib78.2.2.1">
      et al.
     </span>
     [2023]
    </span>
    <span class="ltx_bibblock">
     Bangguo Yu, Hamidreza Kasaei, and Ming Cao.
    </span>
    <span class="ltx_bibblock">
     Co-navgpt: Multi-robot cooperative visual semantic navigation using large language models, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib79">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhang
     <span class="ltx_text ltx_font_italic" id="bib.bib79.2.2.1">
      et al.
     </span>
     [2023a]
    </span>
    <span class="ltx_bibblock">
     An Zhang, Leheng Sheng, Yuxin Chen, Hao Li, Yang Deng, Xiang Wang, and Tat-Seng Chua.
    </span>
    <span class="ltx_bibblock">
     On generative agents in recommendation, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib80">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhang
     <span class="ltx_text ltx_font_italic" id="bib.bib80.2.2.1">
      et al.
     </span>
     [2023b]
    </span>
    <span class="ltx_bibblock">
     Ceyao Zhang, Kaijie Yang, Siyi Hu, Zihao Wang, Guanghe Li, Yihang Sun, Cheng Zhang, Zhaowei Zhang, Anji Liu, Song-Chun Zhu, et al.
    </span>
    <span class="ltx_bibblock">
     Proagent: Building proactive cooperative ai with large language models.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib80.3.1">
      arXiv preprint arXiv:2308.11339
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib81">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhang
     <span class="ltx_text ltx_font_italic" id="bib.bib81.2.2.1">
      et al.
     </span>
     [2023c]
    </span>
    <span class="ltx_bibblock">
     Hongxin Zhang, Weihua Du, Jiaming Shan, Qinhong Zhou, Yilun Du, Joshua B Tenenbaum, Tianmin Shu, and Chuang Gan.
    </span>
    <span class="ltx_bibblock">
     Building cooperative embodied agents modularly with large language models.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib81.3.1">
      arXiv preprint arXiv:2307.02485
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib82">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhang
     <span class="ltx_text ltx_font_italic" id="bib.bib82.2.2.1">
      et al.
     </span>
     [2023d]
    </span>
    <span class="ltx_bibblock">
     Jintian Zhang, Xin Xu, and Shumin Deng.
    </span>
    <span class="ltx_bibblock">
     Exploring collaboration mechanisms for llm agents: A social psychology view, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib83">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhang
     <span class="ltx_text ltx_font_italic" id="bib.bib83.2.2.1">
      et al.
     </span>
     [2023e]
    </span>
    <span class="ltx_bibblock">
     Junjie Zhang, Yupeng Hou, Ruobing Xie, Wenqi Sun, Julian McAuley, Wayne Xin Zhao, Leyu Lin, and Ji-Rong Wen.
    </span>
    <span class="ltx_bibblock">
     Agentcf: Collaborative learning with autonomous language agents for recommender systems, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib84">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhao
     <span class="ltx_text ltx_font_italic" id="bib.bib84.2.2.1">
      et al.
     </span>
     [2023]
    </span>
    <span class="ltx_bibblock">
     Qinlin Zhao, Jindong Wang, Yixuan Zhang, Yiqiao Jin, Kaijie Zhu, Hao Chen, and Xing Xie.
    </span>
    <span class="ltx_bibblock">
     Competeai: Understanding the competition behaviors in large language model-based agents, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib85">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zheng
     <span class="ltx_text ltx_font_italic" id="bib.bib85.2.2.1">
      et al.
     </span>
     [2023]
    </span>
    <span class="ltx_bibblock">
     Zhiling Zheng, Oufan Zhang, Ha L. Nguyen, Nakul Rampal, Ali H. Alawadhi, Zichao Rong, Teresa Head-Gordon, Christian Borgs, Jennifer T. Chayes, and Omar M. Yaghi.
    </span>
    <span class="ltx_bibblock">
     Chatgpt research group for optimizing the crystallinity of mofs and cofs.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib85.3.1">
      ACS Central Science
     </span>
     , 9(11):2161–2170, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib86">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhou
     <span class="ltx_text ltx_font_italic" id="bib.bib86.2.2.1">
      et al.
     </span>
     [2023a]
    </span>
    <span class="ltx_bibblock">
     Wangchunshu Zhou, Yuchen Eleanor Jiang, Long Li, Jialong Wu, Tiannan Wang, Shi Qiu, Jintian Zhang, Jing Chen, Ruipu Wu, Shuai Wang, et al.
    </span>
    <span class="ltx_bibblock">
     Agents: An open-source framework for autonomous language agents.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib86.3.1">
      arXiv preprint arXiv:2309.07870
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib87">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhou
     <span class="ltx_text ltx_font_italic" id="bib.bib87.2.2.1">
      et al.
     </span>
     [2023b]
    </span>
    <span class="ltx_bibblock">
     Xuhui Zhou, Hao Zhu, Leena Mathur, Ruohong Zhang, Haofei Yu, Zhengyang Qi, Louis-Philippe Morency, Yonatan Bisk, Daniel Fried, Graham Neubig, and Maarten Sap.
    </span>
    <span class="ltx_bibblock">
     Sotopia: Interactive evaluation for social intelligence in language agents, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib88">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Ziems
     <span class="ltx_text ltx_font_italic" id="bib.bib88.2.2.1">
      et al.
     </span>
     [2023]
    </span>
    <span class="ltx_bibblock">
     Caleb Ziems, Omar Shaikh, Zhehao Zhang, William Held, Jiaao Chen, and Diyi Yang.
    </span>
    <span class="ltx_bibblock">
     Can large language models transform computational social science?
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib88.3.1">
      Computational Linguistics
     </span>
     , pages 1–53, 2023.
    </span>
   </li>
  </ul>
 </section>
</article>
