<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2409.04849] FedModule: A Modular Federated Learning Framework</title><meta property="og:description" content="Federated learning (FL) has been widely adopted across various applications, such as healthcare, finance, and smart cities. However, as experimental scenarios become more complex, existing FL frameworks and benchmarks …">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="FedModule: A Modular Federated Learning Framework">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="FedModule: A Modular Federated Learning Framework">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2409.04849">

<!--Generated on Sun Oct  6 00:51:36 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">FedModule: A Modular Federated Learning Framework</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Chuyi Chen, Zhe Zhang, Yanchao Zhao
<br class="ltx_break">
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, China
<br class="ltx_break">Email: yczhao@nuaa.edu.cn

</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">Federated learning (FL) has been widely adopted across various applications, such as healthcare, finance, and smart cities. However, as experimental scenarios become more complex, existing FL frameworks and benchmarks have struggled to keep pace. This paper introduces FedModule<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>code is available at https://github.com/NUAA-SmartSensing/async-FL</span></span></span>, a flexible and extensible FL experimental framework that has been open-sourced to support diverse FL paradigms and provide comprehensive benchmarks for complex experimental scenarios. FedModule adheres to the ”one code, all scenarios” principle and employs a modular design that breaks the FL process into individual components, allowing for the seamless integration of different FL paradigms. The framework supports synchronous, asynchronous, and personalized federated learning, with over 20 implemented algorithms. Experiments conducted on public datasets demonstrate the flexibility and extensibility of FedModule. The framework offers multiple execution modes—including linear, threaded, process-based, and distributed—enabling users to tailor their setups to various experimental needs. Additionally, FedModule provides extensive logging and testing capabilities, which facilitate detailed performance analysis of FL algorithms. Comparative evaluations against existing FL toolkits, such as TensorFlow Federated, PySyft, Flower, and FLGo, highlight FedModule’s superior scalability, flexibility, and comprehensive benchmark support. By addressing the limitations of current FL frameworks, FedModule marks a significant advancement in FL experimentation, providing researchers and practitioners with a robust tool for developing and evaluating FL algorithms across a wide range of scenarios.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Nowadays, Federated Learning (FL)<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> has been widely used in various applications, such as healthcare, finance, and smart cities<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>. In FL, the data are distributed among multiple clients, and the model is trained on the data of the clients without uploading the data to the server. The server aggregates the model updates from the clients and updates the global model. Massive research has been conducted to improve the performance of FL, such as communication-efficient algorithms<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>, secure aggregation<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>, model personalization<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>, and client heterogeneity<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>. However, as the depth and width of FL research methods evolve, experimental scenarios become increasingly complex, yet the associated experimental frameworks and benchmarks have not kept pace. The lack of a unified experimental framework and benchmark makes it difficult to compare the performance of different FL algorithms and reproduce the results of existing algorithms<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>. This has become a bottleneck in the development of FL research.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Recently, several FL frameworks have been proposed to address this issue<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>. For example, TensorFlow Federated(TFF)<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> provides a simulation environment for FL algorithms, and PySyft and Flower provide a distributed computing environment for FL. However, these frameworks are designed for specific scenarios and lack flexibility. For example, TFF is designed for FL algorithms based on synchronous federated learning, and PySyft is designed for FL algorithms with differential privacy. These frameworks are not suitable for comparing the performance of FL algorithms in different scenarios. For instance, when comparing synchronous algorithms with asynchronous algorithms, or synchronous algorithms with personalized algorithms, the existing frameworks face significant challenges in implementing these algorithms. Furthermore, they lack the necessary benchmarks for conducting experiments. Therefore, it is necessary to design a flexible and extensible FL experimental framework that supports various federated learning paradigms and provides a rich set of benchmarks to address complex and varied experimental scenarios.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2409.04849/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="368" height="317" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>The conceptual diagram of FedModule illustrates how the framework conducts FL experiments. FedModule selects modules from the Module Repository via a process called Module Construction to build the three main roles in federated learning: clients, server, and client manager.</figcaption>
</figure>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Thus, we propose our framework—FedModule. FedModule decomposes Federated Learning into individual modules, enabling it to seamlessly expand to support new paradigms and benchmarks. As illustrated in Fig. <a href="#S1.F1" title="Figure 1 ‣ I Introduction ‣ FedModule: A Modular Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, FedModule assembles various roles according to user requirements, with each module being replaceable and extendable to accommodate new federated learning paradigms. For instance, if a user wishes to implement round-robin scheduling instead of random scheduling, they can simply specify the round-robin scheduling algorithm module in the configuration, and the server will utilize the designated algorithm. Subsequently, when FedModule assembles the server, it integrates this module, enabling the server to apply the specified scheduling algorithm during the training process.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">Furthermore, the FedModule framework adheres to the ”one code, all scenarios” principle, enabling users to switch seamlessly between different execution modes and experimental scenarios by implementing their required code only once. Our main contributions are as follows:</p>
</div>
<div id="S1.p5" class="ltx_para">
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">We developed a modular federated learning framework with an extensive set of modules that can be combined to offer various execution modes and a wide range of benchmarks.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">FedModule encompasses multiple federated learning paradigms, including synchronous, asynchronous, and personalized federated learning, with over 20 implemented algorithms supporting these paradigms.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">We assessed the performance of FedModule across multiple benchmarks, demonstrating its flexibility and extensibility. Moreover, we tested the execution modes, and the results validated the effectiveness of each mode, offering users diverse configuration options for their experiments.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Related Work</span>
</h2>

<figure id="S2.F2" class="ltx_figure"><img src="/html/2409.04849/assets/x2.png" id="S2.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="291" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>System Overview</figcaption>
</figure>
<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">Since Google introduced Federated Learning in 2017<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>, numerous Federated Learning algorithms have been proposed. However, the development of frameworks suitable for related experiments has not progressed as quickly, with only a limited number of frameworks being introduced. TensorFlow Federated(TFF)<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> is a widely used FL framework that provides a simulation environment for FL algorithms. It is principally intended to simulate the training process of a limited number of homogeneous clients. However, its interface is highly coupled, which constrains its extensibility and flexibility.
PySyft<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> and Flower<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> are two other FL frameworks that provide a distributed computing environment for FL. PySyft is a research platform primarily designed for data science applications based on differential privacy. Due to its rapid development cycles, certain versions lack support for FL, not to mention more complex variants of FL paradigms. Flower is a specialized experimental platform for FL that primarily offers users the capability to conduct large-scale FL experiments and explore diverse scenarios involving heterogeneous devices. However, it should be noted that Flower only supports synchronous FL and does not extend to variant paradigms such as asynchronous FL and personalized FL. In addition, these frameworks two lack benchmarks for evaluating the performance of FL algorithms. Additionally, the lightweight framework FLGO <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> has recently garnered considerable attention due to its extensive baseline and benchmark support. However, its reliance on a linear execution method to simulate the FL training process limits its applicability, particularly in time-sensitive scenarios where FLGO fails to offer adequate support.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">Although these frameworks have contributed significantly to the field of FL experimentation, they each suffer from certain limitations. Specifically, their lack of scalability and flexibility highlights the urgent need for a more advanced framework. Thus, we propose FedModule, a framework designed with a modular structure and adhering to the ”one code, all scenarios” principle.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Framework Design</span>
</h2>

<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS1.4.1.1" class="ltx_text">III-A</span> </span><span id="S3.SS1.5.2" class="ltx_text ltx_font_italic">System Overview</span>
</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">FedModule consists of two kernels: the Framework Core and the Module Repository. The Framework Core is responsible for creating essential components, such as server, FL benchmark, and message queue, and managing the whole running process. The Module Repository contains various modules, such as updater, scheduler, and mode. Each module can be loaded dynamically to support different federated learning paradigms.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">As shown in <a href="#S2.F2" title="In II Related Work ‣ FedModule: A Modular Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">2</span></a>, the workflow of FedModule is as follows. First, the Framework Core generates the essential components, including server, FL benchmark, message queue, client manager. Then, each component can be assembled and extended according to the user’s configuration through the Module Repository to meet different experimental scenarios. After the assembly, the client manager organizes clients to participate in training according to the configuration. It is important to note that, to improve the adaptability of the framework, a variety of methods are available to organize clients, which will be discussed in more detail in <a href="#S3.SS3" title="III-C Custiomize Execution Mode ‣ III Framework Design ‣ FedModule: A Modular Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">III-C</span></span></a>. During the FL process, the server and the clients communicate through the message queue. This approach decouples the server and the clients, facilitating better extensibility of the framework. In the end, the Framework Core collects the results of the training process and gives the final results to the user.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS2.4.1.1" class="ltx_text">III-B</span> </span><span id="S3.SS2.5.2" class="ltx_text ltx_font_italic">Framework Core &amp; Module Repository</span>
</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">In our framework, the Framework Core and Module Repository are essential elements that significantly enhance its flexibility and extensibility. The Framework Core deconstructs the entire federated learning (FL) process into discrete modules, allowing them to be assembled into various FL paradigms much like assembling Lego bricks. Specifically, as shown in Fig. <a href="#S2.F2" title="Figure 2 ‣ II Related Work ‣ FedModule: A Modular Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, the Framework Core segments the FL process into four primary components: the FL benchmark, message queue, server, and client manager, along with other functional modules stored in the Module Repository. The FL benchmark is responsible for setting up experimental scenarios, including training models, configuring data distribution, and managing client heterogeneity, among other settings. The server and clients correspond to the server and client entities in FL. The Client Manager is a management class designed to control clients, allowing users to set the client’s execution mode and providing interfaces to start and stop clients. This functionality enables the simulation of real-world scenarios where clients may join or leave the network at any time. The message queue acts as middleware facilitating communication between clients and the server. Using a message queue instead of direct point-to-point connections offers two main advantages: it decouples the communication module from the server, simplifying extensions to the communication module; and it abstracts the underlying communication details, allowing users to transmit data through the provided interfaces without dealing with low-level complexities.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">When the framework core creates these four components, it sends the user-specified modules to the Module Repository. The Module Repository employs a tool function we developed, called the Module Locator, to locate the required modules. Upon receiving the module paths specified by the user, the Module Locator sequentially loads the relevant packages step-by-step and returns the final required module.</p>
</div>
<figure id="S3.F3" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F3.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2409.04849/assets/x3.png" id="S3.F3.sf1.g1" class="ltx_graphics ltx_img_square" width="212" height="207" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.sf1.2.1.1" class="ltx_text" style="font-size:80%;">(a)</span> </span><span id="S3.F3.sf1.3.2" class="ltx_text" style="font-size:80%;">The transformation of parallel clients into sequential execution.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F3.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2409.04849/assets/x4.png" id="S3.F3.sf2.g1" class="ltx_graphics ltx_img_square" width="193" height="212" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.sf2.2.1.1" class="ltx_text" style="font-size:80%;">(b)</span> </span><span id="S3.F3.sf2.3.2" class="ltx_text" style="font-size:80%;">The Communication framework for distributed mode.</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>The illustration of the timeslice mode and distributed mode in FedModule.</figcaption>
</figure>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS3.4.1.1" class="ltx_text">III-C</span> </span><span id="S3.SS3.5.2" class="ltx_text ltx_font_italic">Custiomize Execution Mode</span>
</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">To facilitate the slogan of ”one code, all scenarios”, we make clients to be organized in various ways. Specifically, we utilize the dynamic language feature of Python to implement the execution mode of the clients. Clients can choose their execution mode based on the configuration file. The execution mode can be linear (which means that the clients are running in a linear order, like for loop), thread, process, or even distributed. Despite the variety of execution modes, the client only needs to be implemented once to run in all modes, which is what we advocate as ”one code, all scenarios”. This design not only simplifies the implementation of the client, but also enhances the flexibility of the framework, making it much easier for researchers to develop.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.1" class="ltx_p">The implementation of the client follows parallel design principles, inheriting from the thread/process class, with users only needing to implement the run method. Most of the operating modes in our framework are based on processes or threads, which can naturally run such client implementations. However, the linear execution mode cannot be directly supported by the thread/process class, as it requires the clients to run sequentially. Moreover, the distributed mode is more complex than the other modes, as it requires the clients to run on different machines. To address these challenges, we have designed separate solutions specifically for these two modes.</p>
</div>
<section id="S3.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS3.SSS1.4.1.1" class="ltx_text">III-C</span>1 </span>Timeslice Mode</h4>

<div id="S3.SS3.SSS1.p1" class="ltx_para">
<p id="S3.SS3.SSS1.p1.1" class="ltx_p">Transforming a group of parallel clients into sequential execution is extremely challenging, as it is not possible to inform the clients of each other’s execution times in order to enforce a linear order. However, thanks to the dynamic nature of Python, we designed an innovative timeline-based solution, which we called the timeslice mechanism. In order to reconstruct the entire training process to achieve sequential operation, we split the entire FL process into multiple tasks and discretize time into time slices, where a time slice is considered the smallest time unit in the mechanism, and each task corresponds to a different number of time slices. As illustrated in Fig. <a href="#S3.F3.sf1" title="Figure 3(a) ‣ Figure 3 ‣ III-B Framework Core &amp; Module Repository ‣ III Framework Design ‣ FedModule: A Modular Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3(a)</span></a>, after reaching a specific time slice, the timeslice mechanism will then proceed to sequentially activate the clients that are required to run at that particular slice. Additionally, it will record the subsequent time slice, which will be utilized to determine the call sequence for each client, based on the feedback provided regarding the running time.</p>
</div>
<div id="S3.SS3.SSS1.p2" class="ltx_para">
<p id="S3.SS3.SSS1.p2.1" class="ltx_p">In regard to the conversion of clients running in parallel into discrete tasks that can be invoked by the Timeslice mechanism, we employ the Python’s dynamic code modification capabilities and generator functions. In FedModule, the client is composed of numerous task functions, and the tasks themselves are connected by the delay_simulate function. Therefore, by tracking the usage of the delay_simulate function within the client, we can split the client into different tasks. However, since tasks utilize shared variables, it is necessary to alter the code’s stack space when invoking tasks. This presents a significant challenge, but Python’s generator functions offer a solution through the yield keyword, which enables the pausing and resuming of execution in generators. This insight allows us to shift our focus from the initial problem of “how to split a complete run function into multiple task functions that share a stack but can be invoked independently” to a new problem of “how to track the delay_simulate function and convert it and the functions that call it into generator functions.” In order to address this issue, it is necessary to perform a static analysis of the syntax tree in order to obtain the function execution chain. Following this, the relevant functions can be converted into generator functions, which will then transform the raw run function into one that meets the requisite linear execution requirements.</p>
</div>
</section>
<section id="S3.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS3.SSS2.4.1.1" class="ltx_text">III-C</span>2 </span>Distributed Mode</h4>

<div id="S3.SS3.SSS2.p1" class="ltx_para">
<p id="S3.SS3.SSS2.p1.1" class="ltx_p">The distributed execution mode permits the execution of users’ code on distributed machines, thereby addressing the requirements of large-scale experiments. We run a sub-client manager class on each device, which manages the number of clients running on each device. Furthermore, a main client manager class operates on the server to facilitate the coordination of the sub-client managers and oversee the management of clients on each device. Compared to other execution modes, the communication issues faced by the distributed mode are more complex, so we designed a suitable distributed communication framework for this purpose. As shown in Fig. <a href="#S3.F3.sf2" title="Figure 3(b) ‣ Figure 3 ‣ III-B Framework Core &amp; Module Repository ‣ III Framework Design ‣ FedModule: A Modular Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3(b)</span></a>, the distributed communication framework is comprised of two main components: the intra-device communication and the inter-device communication. The intra-device communication employs the adapter pattern to wrap the existing communication method, rendering data transmission transparent to the client, whereas the inter-device communication is responsible for the actual communication. The inter-device communication is also modular, with the user able to select the desired communication method, such as socket, MQTT, or HTTP, based on the specific requirements of the experiment.</p>
</div>
</section>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS4.4.1.1" class="ltx_text">III-D</span> </span><span id="S3.SS4.5.2" class="ltx_text ltx_font_italic">Other Features</span>
</h3>

<section id="S3.SS4.SSSx1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Config File</h4>

<div id="S3.SS4.SSSx1.p1" class="ltx_para">
<p id="S3.SS4.SSSx1.p1.1" class="ltx_p">In contrast to other platforms that employ command-line arguments, FedModule utilizes configuration files for parameter configuration. This approach is advantageous in the context of an evolving FL experimental environment, where the number of required hyperparameters is increasing. Configuration files offer a convenient management and review solution, as well as a more efficient means of reuse and extension. The configuration file is divided into several sections, including the client, server, clientmanager and so on. Each section contains the corresponding hyperparameters, which can be easily modified by the user. The configuration file is loaded by the Framework Core and passed to the corresponding components, which then utilize the hyperparameters to configure the components.</p>
</div>
</section>
<section id="S3.SS4.SSSx2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">DatasetPreLoad Mechanism</h4>

<div id="S3.SS4.SSSx2.p1" class="ltx_para">
<p id="S3.SS4.SSSx2.p1.1" class="ltx_p">We found that when multiple FL clients are executed in parallel on a single device, the primary limiting factor in client processing speed shifts from computational power to the rate of input/output operations. This is due to the necessity for clients to read data from the disk, which is a time-consuming process that has the potential to significantly impact the overall performance of the FL process. To address this issue, we designed the DatasetPreLoad Mechanism, which is responsible for loading the dataset into memory before clients begin training. The FedModule will create a shared memory space for the dataset which can be accessed by all clients. This approach significantly reduces the time required for the clients to read data from the disk, thereby enhancing the overall performance of the FL process.</p>
</div>
</section>
<section id="S3.SS4.SSSx3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Abundant Log and Test</h4>

<div id="S3.SS4.SSSx3.p1" class="ltx_para">
<p id="S3.SS4.SSSx3.p1.1" class="ltx_p">FedModule provides a comprehensive set of diagnostic logs and tests, which facilitates a detailed understanding of the performance of FL algorithms. The logs comprise both online and offline logs, which document the training process and the final results, respectively. The Wandb integration into the framework enables users to visualize the training process online and collect device information.
During the training process, the framework will collect pertinent data, including information regarding data distribution, loss, and accuracy. Furthermore, a comprehensive set of test methods is provided, enabling users to assess the performance of FL algorithms according to a range of metrics. These include detailed accuracy on each class or task, average accuracy of the clients, and other relevant measures.</p>
</div>
<figure id="S3.T1" class="ltx_table">

<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE I: </span>The comparison of different FL frameworks</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<table id="S3.T1.1" class="ltx_tabular ltx_centering ltx_figure_panel ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T1.1.1.1" class="ltx_tr">
<th id="S3.T1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt"><span id="S3.T1.1.1.1.1.1" class="ltx_text ltx_font_bold">Framework</span></th>
<th id="S3.T1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt"><span id="S3.T1.1.1.1.2.1" class="ltx_text ltx_font_bold">FedModule</span></th>
<th id="S3.T1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt"><span id="S3.T1.1.1.1.3.1" class="ltx_text ltx_font_bold">TFF</span></th>
<th id="S3.T1.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt"><span id="S3.T1.1.1.1.4.1" class="ltx_text ltx_font_bold">Syft</span></th>
<th id="S3.T1.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt"><span id="S3.T1.1.1.1.5.1" class="ltx_text ltx_font_bold">Flower</span></th>
<th id="S3.T1.1.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S3.T1.1.1.1.6.1" class="ltx_text ltx_font_bold">FLGo</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T1.1.2.1" class="ltx_tr">
<td id="S3.T1.1.2.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.1.2.1.1.1" class="ltx_text ltx_font_bold">Scalability</span></td>
<td id="S3.T1.1.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">✓</td>
<td id="S3.T1.1.2.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">✗</td>
<td id="S3.T1.1.2.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">✓</td>
<td id="S3.T1.1.2.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">✓</td>
<td id="S3.T1.1.2.1.6" class="ltx_td ltx_align_center ltx_border_t">✗</td>
</tr>
<tr id="S3.T1.1.3.2" class="ltx_tr">
<td id="S3.T1.1.3.2.1" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T1.1.3.2.1.1" class="ltx_text ltx_font_bold">Flexibility</span></td>
<td id="S3.T1.1.3.2.2" class="ltx_td ltx_align_center ltx_border_r">✓</td>
<td id="S3.T1.1.3.2.3" class="ltx_td ltx_align_center ltx_border_r">✗</td>
<td id="S3.T1.1.3.2.4" class="ltx_td ltx_align_center ltx_border_r">✗</td>
<td id="S3.T1.1.3.2.5" class="ltx_td ltx_align_center ltx_border_r">▲</td>
<td id="S3.T1.1.3.2.6" class="ltx_td ltx_align_center">▲</td>
</tr>
<tr id="S3.T1.1.4.3" class="ltx_tr">
<td id="S3.T1.1.4.3.1" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T1.1.4.3.1.1" class="ltx_text ltx_font_bold">Benchmark</span></td>
<td id="S3.T1.1.4.3.2" class="ltx_td ltx_align_center ltx_border_r">✓</td>
<td id="S3.T1.1.4.3.3" class="ltx_td ltx_align_center ltx_border_r">✗</td>
<td id="S3.T1.1.4.3.4" class="ltx_td ltx_align_center ltx_border_r">✓</td>
<td id="S3.T1.1.4.3.5" class="ltx_td ltx_align_center ltx_border_r">✗</td>
<td id="S3.T1.1.4.3.6" class="ltx_td ltx_align_center">✓</td>
</tr>
<tr id="S3.T1.1.5.4" class="ltx_tr">
<td id="S3.T1.1.5.4.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S3.T1.1.5.4.1.1" class="ltx_text ltx_font_bold">Baselines</span></td>
<td id="S3.T1.1.5.4.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">✓</td>
<td id="S3.T1.1.5.4.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">✗</td>
<td id="S3.T1.1.5.4.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">✗</td>
<td id="S3.T1.1.5.4.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">✗</td>
<td id="S3.T1.1.5.4.6" class="ltx_td ltx_align_center ltx_border_bb">✓</td>
</tr>
</tbody>
</table>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="S3.T1.2" class="ltx_p ltx_figure_panel ltx_align_center"><span id="S3.T1.2.1" class="ltx_text" style="font-size:80%;">✓ represents that the framework has the corresponding feature, ▲ represents that the framework has partial support for the corresponding feature, and ✗ represents that the framework does not have the corresponding feature.</span></p>
</div>
</div>
</figure>
</section>
</section>
<section id="S3.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS5.4.1.1" class="ltx_text">III-E</span> </span><span id="S3.SS5.5.2" class="ltx_text ltx_font_italic">FL Framework Comparison</span>
</h3>

<div id="S3.SS5.p1" class="ltx_para">
<p id="S3.SS5.p1.1" class="ltx_p">We compare our framework with other existing FL toolkits, namely TFF, Syft, flower, and FLGo. Table <a href="#S3.T1" title="Table I ‣ Abundant Log and Test ‣ III-D Other Features ‣ III Framework Design ‣ FedModule: A Modular Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a> gives an overview and a more detailed comparison is provided in the following.</p>
</div>
<div id="S3.SS5.p2" class="ltx_para">
<p id="S3.SS5.p2.1" class="ltx_p"><span id="S3.SS5.p2.1.1" class="ltx_text ltx_font_bold">Scalability</span> enables the framework to support large-scale experiments. FedModule offers a diverse set of execution modes to accommodate various experimental requirements and hardware conditions, and supports distributed execution mode, which can run clients on different machines. TFF and FLGo do not support distributed execution mode, which limits their scalability.</p>
</div>
<div id="S3.SS5.p3" class="ltx_para">
<p id="S3.SS5.p3.1" class="ltx_p"><span id="S3.SS5.p3.1.1" class="ltx_text ltx_font_bold">Flexibility</span> allows the framework to support various FL paradigms and experimental scenarios. FedModule uses configuration files to define these scenarios, making it easy to customize and adapt paradigms and scenarios as needed. In contrast, TFF, Flower, and Syft support only synchronous federated learning, which limits their flexibility. FLGo runs clients sequentially, which makes it inadequate for time-sensitive experiments.</p>
</div>
<div id="S3.SS5.p4" class="ltx_para">
<p id="S3.SS5.p4.1" class="ltx_p"><span id="S3.SS5.p4.1.1" class="ltx_text ltx_font_bold">Benchmark</span> refers to the framework’s ability to provide a comprehensive set of benchmarks for evaluating the performance of FL algorithms. FedModule offers a diverse range of benchmarks, including various datasets and configurable client heterogeneity. In contrast, TFF, Syft, and Flower do not provide benchmarks, which significantly limits their usability. While FLGo does include benchmarks, the variety and number are limited.</p>
</div>
<div id="S3.SS5.p5" class="ltx_para">
<p id="S3.SS5.p5.1" class="ltx_p"><span id="S3.SS5.p5.1.1" class="ltx_text ltx_font_bold">Baselines</span> refer to the basic standard FL algorithms that a framework provides. Both FedModule and FLGo offer baselines for comparing the performance of FL algorithms. In contrast, TFF and Syft do not provide baselines, which significantly limits their usability. Flower offers only a limited number of baselines.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">Evaluation</span>
</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">In this section, we conduct experiments to show the ability of FedModule on different federated learning paradigms and benchmarks. We also open-source the config files and code of the experiments to facilitate the reproduction of the results<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>code is available at https://github.com/NUAA-SmartSensing/FedModule-Exp</span></span></span>.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS1.4.1.1" class="ltx_text">IV-A</span> </span><span id="S4.SS1.5.2" class="ltx_text ltx_font_italic">Experimental Setup</span>
</h3>

<section id="S4.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS1.SSS1.4.1.1" class="ltx_text">IV-A</span>1 </span>Datasets</h4>

<div id="S4.SS1.SSS1.p1" class="ltx_para">
<p id="S4.SS1.SSS1.p1.1" class="ltx_p">In the experiments, we used a total of 4 datasets: CIFAR10 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>, FashionMNIST <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>, SVHN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>, and UCIHAR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>. The CIFAR10 dataset contains 60,000 32x32 color images divided into 10 classes, with 6,000 images per class. It is split into 50,000 training images and 10,000 test images. FashionMNIST includes 60,000 28x28 grayscale images organized into 10 classes, with 6,000 images per class, and is divided into 50,000 training images and 10,000 test images. The SVHN dataset includes 73,257 32x32 color images across 10 classes, with 65,000 images for training and 13,257 for testing. Lastly, the UCIHAR dataset consists of 10,299 instances, split into 7,352 training instances and 2,947 test instances, with each instance having 561 features across 6 classes.</p>
</div>
</section>
<section id="S4.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS1.SSS2.4.1.1" class="ltx_text">IV-A</span>2 </span>Training Settings</h4>

<div id="S4.SS1.SSS2.p1" class="ltx_para">
<p id="S4.SS1.SSS2.p1.1" class="ltx_p">Most experiments were conducted on a server equipped with an NVIDIA RTX4090 GPU and an NVIDIA RTX2090 GPU, running Ubuntu 21.04.</p>
</div>
<div id="S4.SS1.SSS2.p2" class="ltx_para">
<p id="S4.SS1.SSS2.p2.1" class="ltx_p">Convolutional Neural Networks (CNNs) <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">cnn</span>]</cite> were trained on the FashionMNIST and UCIHAR datasets, while the ResNet-18 architecture <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> was used for the CIFAR10 and SVHN datasets. Stochastic Gradient Descent (SGD) was employed as the optimizer, with the learning rate set to 0.01. The CNN model utilized in the experiments includes two convolutional layers, two pooling layers, and two fully connected layers. Each selected client undergoes local training for 2 epochs. The batch sizes for the datasets are set to 64 for FashionMNIST, 64 for UCIHAR, and 128 for the remaining dataset. For a comprehensive overview of the hyperparameter settings, please refer to Table <a href="#S4.T2" title="Table II ‣ IV-A2 Training Settings ‣ IV-A Experimental Setup ‣ IV Evaluation ‣ FedModule: A Modular Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a>. Further details on the hyperparameter configurations for each baseline can be found in our open-source repository.</p>
</div>
<figure id="S4.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE II: </span>Hyper-parameters settings</figcaption>
<figure id="S4.T3.st1" class="ltx_table ltx_align_center">
<table id="S4.T3.st1.2" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T3.st1.2.1.1" class="ltx_tr">
<th id="S4.T3.st1.2.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt"><span id="S4.T3.st1.2.1.1.1.1" class="ltx_text ltx_font_bold">Hyperparameter</span></th>
<td id="S4.T3.st1.2.1.1.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T3.st1.2.1.1.2.1" class="ltx_text ltx_font_bold">CIFAR10</span></td>
<td id="S4.T3.st1.2.1.1.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T3.st1.2.1.1.3.1" class="ltx_text ltx_font_bold">EMNIST</span></td>
<td id="S4.T3.st1.2.1.1.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T3.st1.2.1.1.4.1" class="ltx_text ltx_font_bold">FashionMNIST</span></td>
<td id="S4.T3.st1.2.1.1.5" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T3.st1.2.1.1.5.1" class="ltx_text ltx_font_bold">SVHN</span></td>
<td id="S4.T3.st1.2.1.1.6" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T3.st1.2.1.1.6.1" class="ltx_text ltx_font_bold">UCIHAR</span></td>
</tr>
<tr id="S4.T3.st1.2.2.2" class="ltx_tr">
<th id="S4.T3.st1.2.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Global Epochs</th>
<td id="S4.T3.st1.2.2.2.2" class="ltx_td ltx_align_center ltx_border_t">200</td>
<td id="S4.T3.st1.2.2.2.3" class="ltx_td ltx_align_center ltx_border_t">200</td>
<td id="S4.T3.st1.2.2.2.4" class="ltx_td ltx_align_center ltx_border_t">200</td>
<td id="S4.T3.st1.2.2.2.5" class="ltx_td ltx_align_center ltx_border_t">200</td>
<td id="S4.T3.st1.2.2.2.6" class="ltx_td ltx_align_center ltx_border_t">150</td>
</tr>
<tr id="S4.T3.st1.2.3.3" class="ltx_tr">
<th id="S4.T3.st1.2.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Client Numbers</th>
<td id="S4.T3.st1.2.3.3.2" class="ltx_td ltx_align_center">30</td>
<td id="S4.T3.st1.2.3.3.3" class="ltx_td ltx_align_center">30</td>
<td id="S4.T3.st1.2.3.3.4" class="ltx_td ltx_align_center">30</td>
<td id="S4.T3.st1.2.3.3.5" class="ltx_td ltx_align_center">30</td>
<td id="S4.T3.st1.2.3.3.6" class="ltx_td ltx_align_center">30</td>
</tr>
<tr id="S4.T3.st1.2.4.4" class="ltx_tr">
<th id="S4.T3.st1.2.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Model</th>
<td id="S4.T3.st1.2.4.4.2" class="ltx_td ltx_align_center">ResNet-18</td>
<td id="S4.T3.st1.2.4.4.3" class="ltx_td ltx_align_center">CNN</td>
<td id="S4.T3.st1.2.4.4.4" class="ltx_td ltx_align_center">CNN</td>
<td id="S4.T3.st1.2.4.4.5" class="ltx_td ltx_align_center">ResNet-18</td>
<td id="S4.T3.st1.2.4.4.6" class="ltx_td ltx_align_center">CNN</td>
</tr>
<tr id="S4.T3.st1.2.5.5" class="ltx_tr">
<th id="S4.T3.st1.2.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Batch Size</th>
<td id="S4.T3.st1.2.5.5.2" class="ltx_td ltx_align_center">64</td>
<td id="S4.T3.st1.2.5.5.3" class="ltx_td ltx_align_center">64</td>
<td id="S4.T3.st1.2.5.5.4" class="ltx_td ltx_align_center">64</td>
<td id="S4.T3.st1.2.5.5.5" class="ltx_td ltx_align_center">128</td>
<td id="S4.T3.st1.2.5.5.6" class="ltx_td ltx_align_center">128</td>
</tr>
<tr id="S4.T3.st1.2.6.6" class="ltx_tr">
<th id="S4.T3.st1.2.6.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Local Epochs</th>
<td id="S4.T3.st1.2.6.6.2" class="ltx_td ltx_align_center">2</td>
<td id="S4.T3.st1.2.6.6.3" class="ltx_td ltx_align_center">2</td>
<td id="S4.T3.st1.2.6.6.4" class="ltx_td ltx_align_center">2</td>
<td id="S4.T3.st1.2.6.6.5" class="ltx_td ltx_align_center">2</td>
<td id="S4.T3.st1.2.6.6.6" class="ltx_td ltx_align_center">2</td>
</tr>
<tr id="S4.T3.st1.2.7.7" class="ltx_tr">
<th id="S4.T3.st1.2.7.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Optimizer</th>
<td id="S4.T3.st1.2.7.7.2" class="ltx_td ltx_align_center">SGD</td>
<td id="S4.T3.st1.2.7.7.3" class="ltx_td ltx_align_center">SGD</td>
<td id="S4.T3.st1.2.7.7.4" class="ltx_td ltx_align_center">SGD</td>
<td id="S4.T3.st1.2.7.7.5" class="ltx_td ltx_align_center">SGD</td>
<td id="S4.T3.st1.2.7.7.6" class="ltx_td ltx_align_center">SGD</td>
</tr>
<tr id="S4.T3.st1.2.8.8" class="ltx_tr">
<th id="S4.T3.st1.2.8.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">Learning Rate</th>
<td id="S4.T3.st1.2.8.8.2" class="ltx_td ltx_align_center ltx_border_bb">0.01</td>
<td id="S4.T3.st1.2.8.8.3" class="ltx_td ltx_align_center ltx_border_bb">0.01</td>
<td id="S4.T3.st1.2.8.8.4" class="ltx_td ltx_align_center ltx_border_bb">0.01</td>
<td id="S4.T3.st1.2.8.8.5" class="ltx_td ltx_align_center ltx_border_bb">0.01</td>
<td id="S4.T3.st1.2.8.8.6" class="ltx_td ltx_align_center ltx_border_bb">0.01</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S4.T3.st1.3.1.1" class="ltx_text" style="font-size:80%;">(a)</span> </span><span id="S4.T3.st1.4.2" class="ltx_text" style="font-size:80%;">Dataset Related</span></figcaption>
</figure>
</figure>
</section>
<section id="S4.SS1.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS1.SSS3.4.1.1" class="ltx_text">IV-A</span>3 </span>Baselines</h4>

<div id="S4.SS1.SSS3.p1" class="ltx_para">
<p id="S4.SS1.SSS3.p1.1" class="ltx_p">We employ the following baseline methods in our experiments: FedAvg <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>, FedProx <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>, FedAdam <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>, FedNova <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>, FedAsync <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>, TWAFL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>, FedVC <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>, EAFL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>, PFedMe <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>, and FedDL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>. Specifically, FedProx, FedAdam, and FedNova are utilized in Sections <a href="#S4.SS3" title="IV-C Experimental Validation on Diverse Datasets ‣ IV Evaluation ‣ FedModule: A Modular Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">IV-C</span></span></a> and <a href="#S4.SS6" title="IV-F Abundant Log and Test ‣ IV Evaluation ‣ FedModule: A Modular Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">IV-F</span></span></a>; FedAsync, TWAFL, FedVC and EAFL are used in Sections <a href="#S4.SS4" title="IV-D Support for Client Heterogeneity ‣ IV Evaluation ‣ FedModule: A Modular Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">IV-D</span></span></a> and <a href="#S4.SS5" title="IV-E Different FL Paradigms ‣ IV Evaluation ‣ FedModule: A Modular Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">IV-E</span></span></a>; and PFedMe, and FedDL are employed in Section <a href="#S4.SS5" title="IV-E Different FL Paradigms ‣ IV Evaluation ‣ FedModule: A Modular Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">IV-E</span></span></a>.</p>
</div>
</section>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS2.4.1.1" class="ltx_text">IV-B</span> </span><span id="S4.SS2.5.2" class="ltx_text ltx_font_italic">Performance of Different Execution Modes</span>
</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">FedModule provides users with the option of selecting different runtime modes, which are designed to accommodate the specific experimental requirements of the user, taking into account the characteristics of the experimental hardware and the available memory. In this section, we evaluate the performance of different execution modes in FedModule. We present the performance of FedAvg using five different execution modes: linear, thread, process, MQMT, and distributed. The dataset employed is CIFAR10. The results are shown in Fig. <a href="#S4.F4.sf1" title="Figure 4(a) ‣ Figure 4 ‣ IV-B Performance of Different Execution Modes ‣ IV Evaluation ‣ FedModule: A Modular Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4(a)</span></a>.</p>
</div>
<figure id="S4.F4" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F4.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2409.04849/assets/x5.png" id="S4.F4.sf1.g1" class="ltx_graphics ltx_img_landscape" width="221" height="166" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F4.sf1.2.1.1" class="ltx_text" style="font-size:80%;">(a)</span> </span><span id="S4.F4.sf1.3.2" class="ltx_text" style="font-size:80%;">Time</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F4.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2409.04849/assets/x6.png" id="S4.F4.sf2.g1" class="ltx_graphics ltx_img_landscape" width="221" height="166" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F4.sf2.2.1.1" class="ltx_text" style="font-size:80%;">(b)</span> </span><span id="S4.F4.sf2.3.2" class="ltx_text" style="font-size:80%;">Memory</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>The experiments of execution modes on FashionMNIST in FedModule.</figcaption>
</figure>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">As shown in the Fig<a href="#S4.F4.sf1" title="Figure 4(a) ‣ Figure 4 ‣ IV-B Performance of Different Execution Modes ‣ IV Evaluation ‣ FedModule: A Modular Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4(a)</span></a>, we used the same random seed for all experiments, resulting in nearly identical accuracy across all excution modes. The execution times for each mode, in ascending order, are as follows: process, mpmt, distributed, timeslice, and thread. The process mode has the shortest execution time because each process operates independently without communication delays between the client and server. The mpmt (multi-process multi-threading) mode, which employs multiple parallel processes to handle client operations, is faster than distributed, timeslice and thread modes. In the distributed mode, additional communication time between devices is introduced compared to the process mode. The thread mode experiences the longest execution time due to the overhead from frequent thread context switching.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.1" class="ltx_p">Regarding memory consumption, as shown in Fig. <a href="#S4.F4.sf2" title="Figure 4(b) ‣ Figure 4 ‣ IV-B Performance of Different Execution Modes ‣ IV Evaluation ‣ FedModule: A Modular Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4(b)</span></a>, the distributed mode has the highest memory usage, followed by process, mpmt, thread, and timeslice. The process mode consumes less memory than the distributed mode because the latter requires additional space to handle inter-device communication. The timeslice mode, due to its non-native sequential execution, requires extra space compared to the thread mode to store the stack information for each client.</p>
</div>
<div id="S4.SS2.p4" class="ltx_para">
<p id="S4.SS2.p4.1" class="ltx_p">The results indicate that FedModule allows users to choose the most appropriate execution mode based on their specific needs, showcasing its flexibility and extensibility, which make it adaptable to various experimental scenarios.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS3.4.1.1" class="ltx_text">IV-C</span> </span><span id="S4.SS3.5.2" class="ltx_text ltx_font_italic">Experimental Validation on Diverse Datasets</span>
</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">Our framework enables seamless switching between different datasets, requiring users to simply configure the appropriate model and parameters without needing to write additional code. We support a wide range of datasets, including not only commonly used datasets but also mixed datasets, streaming datasets, and others. We conducted experiments using several datasets, and the results are presented in Fig. <a href="#S4.F5" title="Figure 5 ‣ IV-C Experimental Validation on Diverse Datasets ‣ IV Evaluation ‣ FedModule: A Modular Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>.</p>
</div>
<figure id="S4.F5" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S4.F5.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2409.04849/assets/x7.png" id="S4.F5.sf1.g1" class="ltx_graphics ltx_img_landscape" width="110" height="83" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F5.sf1.2.1.1" class="ltx_text" style="font-size:80%;">(a)</span> </span><span id="S4.F5.sf1.3.2" class="ltx_text" style="font-size:80%;">CIFAR10</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S4.F5.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2409.04849/assets/x8.png" id="S4.F5.sf2.g1" class="ltx_graphics ltx_img_landscape" width="110" height="83" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F5.sf2.2.1.1" class="ltx_text" style="font-size:80%;">(b)</span> </span><span id="S4.F5.sf2.3.2" class="ltx_text" style="font-size:80%;">FashionMNIST</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S4.F5.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2409.04849/assets/x9.png" id="S4.F5.sf3.g1" class="ltx_graphics ltx_img_landscape" width="110" height="83" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F5.sf3.2.1.1" class="ltx_text" style="font-size:80%;">(c)</span> </span><span id="S4.F5.sf3.3.2" class="ltx_text" style="font-size:80%;">UCIHAR</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S4.F5.sf4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2409.04849/assets/x10.png" id="S4.F5.sf4.g1" class="ltx_graphics ltx_img_landscape" width="110" height="83" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F5.sf4.2.1.1" class="ltx_text" style="font-size:80%;">(d)</span> </span><span id="S4.F5.sf4.3.2" class="ltx_text" style="font-size:80%;">SVHN</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Performance of baselines on different datasets.</figcaption>
</figure>
<figure id="S4.F6" class="ltx_figure"><img src="/html/2409.04849/assets/x11.png" id="S4.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="368" height="276" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Comparison of time overhead between scenarios with and without dataset preloading.</figcaption>
</figure>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.1" class="ltx_p">Moreover, FedModule supports loading datasets into memory to enhance experimental speed. We compared the performance with and without dataset preloading, as shown in Fig. <a href="#S4.F6" title="Figure 6 ‣ IV-C Experimental Validation on Diverse Datasets ‣ IV Evaluation ‣ FedModule: A Modular Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>. Experiments on FedAvg in mpmt mode revealed that when clients run concurrently, I/O operations consume a substantial portion of the runtime, thus slowing down the experiments and increasing the divergence between simulation and real-world scenarios. The results show that preloading datasets accelerated the process by 3.6x times compared to loading data during training, validating the effectiveness of this feature and demonstrating its potential to significantly reduce simulation distortions.</p>
</div>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS4.4.1.1" class="ltx_text">IV-D</span> </span><span id="S4.SS4.5.2" class="ltx_text ltx_font_italic">Support for Client Heterogeneity</span>
</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.1" class="ltx_p">Moreover, FedModule allows the configuration of client heterogeneity to support custom benchmarks. In this section, we will adjust the data heterogeneity and system heterogeneity of the clients to showcase the framework’s capabilities.</p>
</div>
<div id="S4.SS4.p2" class="ltx_para">
<p id="S4.SS4.p2.2" class="ltx_p">In previous experiments, we used the Dirichlet distribution to configure the data heterogeneity of the clients. In this subsection, we implemented finer-grained configurations by directly specifying the classes and quantities of data each client holds. Of the 30 clients, 10 were assigned data from 3 classes, another 10 were assigned data from 5 classes, and the remaining 10 were assigned data from 7 classes, with all clients maintaining the same total amount of data. Fig. <a href="#S4.F7" title="Figure 7 ‣ IV-D Support for Client Heterogeneity ‣ IV Evaluation ‣ FedModule: A Modular Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> shows the performance of the FedAvg algorithm across three types of data distributions: independent and identically distributed (i.i.d.), Dirichlet (<math id="S4.SS4.p2.1.m1.1" class="ltx_Math" alttext="\beta=0.5" display="inline"><semantics id="S4.SS4.p2.1.m1.1a"><mrow id="S4.SS4.p2.1.m1.1.1" xref="S4.SS4.p2.1.m1.1.1.cmml"><mi id="S4.SS4.p2.1.m1.1.1.2" xref="S4.SS4.p2.1.m1.1.1.2.cmml">β</mi><mo id="S4.SS4.p2.1.m1.1.1.1" xref="S4.SS4.p2.1.m1.1.1.1.cmml">=</mo><mn id="S4.SS4.p2.1.m1.1.1.3" xref="S4.SS4.p2.1.m1.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.1.m1.1b"><apply id="S4.SS4.p2.1.m1.1.1.cmml" xref="S4.SS4.p2.1.m1.1.1"><eq id="S4.SS4.p2.1.m1.1.1.1.cmml" xref="S4.SS4.p2.1.m1.1.1.1"></eq><ci id="S4.SS4.p2.1.m1.1.1.2.cmml" xref="S4.SS4.p2.1.m1.1.1.2">𝛽</ci><cn type="float" id="S4.SS4.p2.1.m1.1.1.3.cmml" xref="S4.SS4.p2.1.m1.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.1.m1.1c">\beta=0.5</annotation></semantics></math>), and a custom-defined distribution. Fig. <a href="#S4.F9.sf1" title="Figure 9(a) ‣ Figure 9 ‣ IV-F Abundant Log and Test ‣ IV Evaluation ‣ FedModule: A Modular Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9(a)</span></a> provides a detailed view of the client-specific data distribution under the Dirichlet distribution (<math id="S4.SS4.p2.2.m2.1" class="ltx_Math" alttext="\beta=0.5" display="inline"><semantics id="S4.SS4.p2.2.m2.1a"><mrow id="S4.SS4.p2.2.m2.1.1" xref="S4.SS4.p2.2.m2.1.1.cmml"><mi id="S4.SS4.p2.2.m2.1.1.2" xref="S4.SS4.p2.2.m2.1.1.2.cmml">β</mi><mo id="S4.SS4.p2.2.m2.1.1.1" xref="S4.SS4.p2.2.m2.1.1.1.cmml">=</mo><mn id="S4.SS4.p2.2.m2.1.1.3" xref="S4.SS4.p2.2.m2.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.2.m2.1b"><apply id="S4.SS4.p2.2.m2.1.1.cmml" xref="S4.SS4.p2.2.m2.1.1"><eq id="S4.SS4.p2.2.m2.1.1.1.cmml" xref="S4.SS4.p2.2.m2.1.1.1"></eq><ci id="S4.SS4.p2.2.m2.1.1.2.cmml" xref="S4.SS4.p2.2.m2.1.1.2">𝛽</ci><cn type="float" id="S4.SS4.p2.2.m2.1.1.3.cmml" xref="S4.SS4.p2.2.m2.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.2.m2.1c">\beta=0.5</annotation></semantics></math>).</p>
</div>
<div id="S4.SS4.p3" class="ltx_para">
<p id="S4.SS4.p3.1" class="ltx_p">In the asynchronous experiments described in Section <a href="#S4.SS5" title="IV-E Different FL Paradigms ‣ IV Evaluation ‣ FedModule: A Modular Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">IV-E</span></span></a>, we introduced system heterogeneity among the clients. As shown in Fig. <a href="#S4.F8.sf1" title="Figure 8(a) ‣ Figure 8 ‣ IV-D Support for Client Heterogeneity ‣ IV Evaluation ‣ FedModule: A Modular Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8(a)</span></a>, we configured three types of clients with varying computational speeds: the first type has computational power equivalent to that of a real machine, the second type operates at 20% of the first type’s computational performance, and the third type operates at 10% of the first type’s computational performance.</p>
</div>
<figure id="S4.F7" class="ltx_figure"><img src="/html/2409.04849/assets/x12.png" id="S4.F7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="368" height="276" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Performance of FedAvg on the FashionMNIST evaluated under three different data distributions.</figcaption>
</figure>
<figure id="S4.F8" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F8.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2409.04849/assets/x13.png" id="S4.F8.sf1.g1" class="ltx_graphics ltx_img_landscape" width="221" height="166" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F8.sf1.2.1.1" class="ltx_text" style="font-size:80%;">(a)</span> </span><span id="S4.F8.sf1.3.2" class="ltx_text" style="font-size:80%;">Asynchronous</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F8.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2409.04849/assets/x14.png" id="S4.F8.sf2.g1" class="ltx_graphics ltx_img_landscape" width="221" height="166" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F8.sf2.2.1.1" class="ltx_text" style="font-size:80%;">(b)</span> </span><span id="S4.F8.sf2.3.2" class="ltx_text" style="font-size:80%;">Personalized</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>The illustration of different paradigms on FashionMNIST in FedModule.</figcaption>
</figure>
</section>
<section id="S4.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS5.4.1.1" class="ltx_text">IV-E</span> </span><span id="S4.SS5.5.2" class="ltx_text ltx_font_italic">Different FL Paradigms</span>
</h3>

<div id="S4.SS5.p1" class="ltx_para">
<p id="S4.SS5.p1.1" class="ltx_p">FedModule supports various FL paradigms, including asynchronous and personalized FL. Our experiments demonstrate the framework’s versatility in these paradigms, as shown in Fig. <a href="#S4.F8" title="Figure 8 ‣ IV-D Support for Client Heterogeneity ‣ IV Evaluation ‣ FedModule: A Modular Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>. For the asynchronous FL paradigm (Fig. <a href="#S4.F8.sf1" title="Figure 8(a) ‣ Figure 8 ‣ IV-D Support for Client Heterogeneity ‣ IV Evaluation ‣ FedModule: A Modular Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8(a)</span></a>), we evaluated four different acceleration algorithms: FedAsync, a fully asynchronous algorithm where the server aggregates updates immediately upon receipt; FedVC, a semi-asynchronous algorithm where the server aggregates updates only after collecting a sufficient number; EAFL, another semi-asynchronous algorithm that groups clients and performs asynchronous aggregation within groups and semi-asynchronous aggregation between groups; and TWAFL, a synchronous acceleration algorithm where clients upload only specific model parameters at designated rounds. For the personalized FL paradigm (Fig. <a href="#S4.F8.sf2" title="Figure 8(b) ‣ Figure 8 ‣ IV-D Support for Client Heterogeneity ‣ IV Evaluation ‣ FedModule: A Modular Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8(b)</span></a>), we tested two algorithms: PFedMe, which involves a global model, and FedDL, which aggregates parameters by grouping based on parameter similarity and operates without a global model. These experiments demonstrate the extensive applicability of our framework, accommodating a wide range of federated learning variants. Furthermore, we are actively developing security-related FL paradigms to support experiments focusing on security aspects.</p>
</div>
</section>
<section id="S4.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS6.4.1.1" class="ltx_text">IV-F</span> </span><span id="S4.SS6.5.2" class="ltx_text ltx_font_italic">Abundant Log and Test</span>
</h3>

<div id="S4.SS6.p1" class="ltx_para">
<p id="S4.SS6.p1.1" class="ltx_p">In the previous experimental section, we demonstrated some of the comprehensive data recording capabilities of FedModule, such as tracking test accuracy over time and by logical criteria (Figs. <a href="#S4.F8.sf1" title="Figure 8(a) ‣ Figure 8 ‣ IV-D Support for Client Heterogeneity ‣ IV Evaluation ‣ FedModule: A Modular Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8(a)</span></a> and <a href="#S4.F5.sf2" title="Figure 5(b) ‣ Figure 5 ‣ IV-C Experimental Validation on Diverse Datasets ‣ IV Evaluation ‣ FedModule: A Modular Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5(b)</span></a>), as well as recording the average accuracy across clients (Fig. <a href="#S4.F8.sf2" title="Figure 8(b) ‣ Figure 8 ‣ IV-D Support for Client Heterogeneity ‣ IV Evaluation ‣ FedModule: A Modular Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8(b)</span></a>). In this section, we present additional experimental records. As shown in the figure, Fig. <a href="#S4.F9.sf1" title="Figure 9(a) ‣ Figure 9 ‣ IV-F Abundant Log and Test ‣ IV Evaluation ‣ FedModule: A Modular Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9(a)</span></a> shows the data distribution of the experiment, while Figs <a href="#S4.F9.sf2" title="Figure 9(b) ‣ Figure 9 ‣ IV-F Abundant Log and Test ‣ IV Evaluation ‣ FedModule: A Modular Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9(b)</span></a>, <a href="#S4.F9.sf3" title="Figure 9(c) ‣ Figure 9 ‣ IV-F Abundant Log and Test ‣ IV Evaluation ‣ FedModule: A Modular Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9(c)</span></a> and <a href="#S4.F9.sf4" title="Figure 9(d) ‣ Figure 9 ‣ IV-F Abundant Log and Test ‣ IV Evaluation ‣ FedModule: A Modular Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9(d)</span></a> depict various device performance metrics during the experiment, such as GPU usage and memory consumption. Additionally, FedModule saves the configuration details of each experiment upon completion and provides an outline summarizing the experiment.</p>
</div>
<figure id="S4.F9" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F9.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2409.04849/assets/x15.png" id="S4.F9.sf1.g1" class="ltx_graphics ltx_img_landscape" width="221" height="132" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F9.sf1.2.1.1" class="ltx_text" style="font-size:80%;">(a)</span> </span><span id="S4.F9.sf1.3.2" class="ltx_text" style="font-size:80%;">Data distribution</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F9.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2409.04849/assets/x16.png" id="S4.F9.sf2.g1" class="ltx_graphics ltx_img_landscape" width="221" height="166" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F9.sf2.2.1.1" class="ltx_text" style="font-size:80%;">(b)</span> </span><span id="S4.F9.sf2.3.2" class="ltx_text" style="font-size:80%;">Power GPU utilization</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F9.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2409.04849/assets/x17.png" id="S4.F9.sf3.g1" class="ltx_graphics ltx_img_landscape" width="221" height="166" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F9.sf3.2.1.1" class="ltx_text" style="font-size:80%;">(c)</span> </span><span id="S4.F9.sf3.3.2" class="ltx_text" style="font-size:80%;">GPU memory allocated</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F9.sf4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2409.04849/assets/x18.png" id="S4.F9.sf4.g1" class="ltx_graphics ltx_img_landscape" width="221" height="166" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F9.sf4.2.1.1" class="ltx_text" style="font-size:80%;">(d)</span> </span><span id="S4.F9.sf4.3.2" class="ltx_text" style="font-size:80%;">Network traffic</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9: </span>The illustration of the log and device information in FedModule.</figcaption>
</figure>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">Conclusion</span>
</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this work, we introduce FedModule, a modular FL framework that adheres to the ”one code, all scenarios” principle. FedModule decouples the FL training process into multiple independent components, allowing each component to select functional modules based on user requirements to construct specific FL experiments. This modular design enables seamless switching between different FL paradigms and benchmarks. We conducted extensive experiments demonstrating FedModule’s capability to support existing algorithms and validating the effectiveness of its features. In the future, we plan to implement more algorithms within FedModule to further enhance its applicability.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas, “Communication-efficient learning of deep networks from decentralized data,” in <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">Proc. of PLMR AISTATS</em>, 2017, pp. 1273–1282.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
T. Li, A. K. Sahu, M. Zaheer, M. Sanjabi, A. Talwalkar, and V. Smith, “Federated optimization in heterogeneous networks,” in <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Proc. of MLSys</em>, 2020, pp. 429–450.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
K. Cheng, T. Fan, Y. Jin, Y. Liu, T. Chen, D. Papadopoulos, and Q. Yang, “Secureboost: A lossless federated learning framework,” <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">IEEE intelligent systems</em>, vol. 36, no. 6, pp. 87–98, 2021.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
S. P. Ramu, P. Boopalan, Q.-V. Pham, P. K. R. Maddikunta, T. Huynh-The, M. Alazab, T. T. Nguyen, and T. R. Gadekallu, “Federated learning enabled digital twins for smart cities: Concepts, recent advances, and future directions,” <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Sustainable Cities and Society</em>, vol. 79, p. 103663, 2022.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
C. Xie, S. Koyejo, and I. Gupta, “Asynchronous federated optimization,” <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1903.03934</em>, 2019.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Z. Z. Chuyi Chen and Y. Zhao, “Leave no one behind: Unleashing stragglers’ potential for accurate and realtime asynchronous federated learning,” in <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">Proc. of IWQoS</em>, 2024, pp. 1–10.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
K. Bonawitz, V. Ivanov, B. Kreuter, A. Marcedone, H. B. McMahan, S. Patel, D. Ramage, A. Segal, and K. Seth, “Practical secure aggregation for federated learning on user-held data,” <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1611.04482</em>, 2016.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
C. T. Dinh, N. H. Tran, and T. D. Nguyen, “Personalized federated learning with moreau envelopes,” in <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">Proc. of NIPS</em>, 2020.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
T. Nishio and R. Yonetani, “Client selection for federated learning with heterogeneous resources in mobile edge,” in <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">Proc. of IEEE ICC</em>, 2019, pp. 1–7.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Z. Wang, X. Fan, Z. Peng, X. Li, Z. Yang, M. Feng, Z. Yang, X. Liu, and C. Wang, “Flgo: A fully customizable federated learning platform,” <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2306.12079</em>, 2023.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
D. J. Beutel, T. Topal, A. Mathur, X. Qiu, J. Fernandez-Marques, Y. Gao, L. Sani, K. H. Li, T. Parcollet, P. P. B. de Gusmão <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Flower: A friendly federated learning research framework,” <em id="bib.bib11.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2007.14390</em>, 2020.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
K. Bonawitz, “Towards federated learning at scale: Syste m design,” <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1902.01046</em>, 2019.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
T. Ryffel, A. Trask, M. Dahl, B. Wagner, J. Mancuso, D. Rueckert, and J. Passerat-Palmbach, “A generic framework for privacy preserving deep learning,” <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1811.04017</em>, 2018.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
A. Krizhevsky, “Learning multiple layers of features from tiny images,” <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">Master’s thesis, University of Tront</em>, 2009.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
H. Xiao, K. Rasul, and R. Vollgraf, “Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms,” <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1708.07747</em>, 2017.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Y. Netzer, T. Wang, A. Coates, A. Bissacco, B. Wu, A. Y. Ng <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Reading digits in natural images with unsupervised feature learning,” in <em id="bib.bib16.2.2" class="ltx_emph ltx_font_italic">NIPS workshop on deep learning and unsupervised feature learning</em>, vol. 2011, no. 2, 2011, p. 4.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
E. Bulbul, A. Cetin, and I. A. Dogru, “Human activity recognition using smartphones,” in <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">Proc. of ismsit</em>, 2018, pp. 1–6.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner, “Gradient-based learning applied to document recognition,” <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE</em>, vol. 86, no. 11, pp. 2278–2324, 1998.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image recognition,” in <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">Proc. of IEEE CVPR</em>, 2016, pp. 770–778.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
S. J. Reddi, Z. Charles, M. Zaheer, Z. Garrett, K. Rush, J. Konečný, S. Kumar, and H. B. McMahan, “Adaptive federated optimization,” in <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">Proc. of ICLR</em>, 2021.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
J. Wang, Q. Liu, H. Liang, G. Joshi, and H. V. Poor, “Tackling the objective inconsistency problem in heterogeneous federated optimization,” in <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">Proc. of MIT Press NeurIPS</em>, 2020.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Y. Chen, X. Sun, and Y. Jin, “Communication-efficient federated deep learning with layerwise asynchronous model update and temporally weighted aggregation,” <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Neural Networks and Learning Systems</em>, vol. 31, no. 10, pp. 4229–4238, 2019.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Y. Zhou, X. Pang, Z. Wang, J. Hu, P. Sun, and K. Ren, “Towards efficient asynchronous federated learning in heterogeneous edge environments,” in <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">Proc. of IEEE INFOCOM</em>, 2024.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
L. Tu, X. Ouyang, J. Zhou, Y. He, and G. Xing, “Feddl: Federated learning via dynamic layer sharing for human activity recognition,” in <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 19th ACM Conference on Embedded Networked Sensor Systems</em>, 2021, pp. 15–28.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2409.04848" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2409.04849" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2409.04849">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2409.04849" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2409.04850" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sun Oct  6 00:51:36 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
