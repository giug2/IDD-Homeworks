<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Insuring Uninsurable Risks from AI: Government as Insurer of Last Resort</title>
<!--Generated on Sat Sep  7 18:38:19 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="AI Policy,  Liability,  Insurance,  Mechanism Design,  ICML" lang="en" name="keywords"/>
<base href="/html/2409.06672v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.06672v1#S1" title="In Insuring Uninsurable Risks from AI: Government as Insurer of Last Resort"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Background</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.06672v1#S2" title="In Insuring Uninsurable Risks from AI: Government as Insurer of Last Resort"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>A Risk-Priced Indemnification Program</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.06672v1#S3" title="In Insuring Uninsurable Risks from AI: Government as Insurer of Last Resort"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Quadratic Financing for Safety Research</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.06672v1#S4" title="In Insuring Uninsurable Risks from AI: Government as Insurer of Last Resort"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Closing Remarks and Further Research</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<h1 class="ltx_title ltx_title_document">Insuring Uninsurable Risks from AI: Government as Insurer of Last Resort</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Cristian Trout
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id1.id1"><span class="ltx_text ltx_font_italic" id="id1.id1.1">Many experts believe that AI systems will sooner or later pose uninsurable risks, including existential risks. This creates an extreme judgment-proof problem: few if any parties can be held accountable ex post in the event of such a catastrophe. This paper proposes a novel solution: a government-provided, mandatory indemnification program for AI developers. The program uses risk-priced indemnity fees to induce socially optimal levels of care. Risk-estimates are determined by surveying experts, including indemnified developers. The Bayesian Truth Serum mechanism is employed to incent honest and effortful responses. Compared to alternatives, this approach arguably better leverages all private information, and provides a clearer signal to indemnified developers regarding what risks they must mitigate to lower their fees. It’s recommended that collected fees be used to help fund the safety research developers need, employing a fund matching mechanism (Quadratic Financing) to induce an optimal supply of this public good. Under Quadratic Financing, safety research projects would compete for private contributions from developers, signaling how much each is to be supplemented with public funds.</span></p>
</div>
<div class="ltx_keywords">AI Policy, Liability, Insurance, Mechanism Design, ICML
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Background</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Many experts believe AI systems will, sooner or later, pose uninsurable risks, including existential risks <cite class="ltx_cite ltx_citemacro_citep">(Grace et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.06672v1#bib.bib7" title="">2024</a>; Bengio et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.06672v1#bib.bib2" title="">2024</a>)</cite>. If so, it will be impossible to hold accountable the parties liable for such harms (or their insurers).</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Weil <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2409.06672v1#bib.bib16" title="">2024</a>)</cite> proposes to solve this extreme judgment proof-problem by assigning punitive damages to harms that are <span class="ltx_text ltx_font_italic" id="S1.p2.1.1">correlated</span> with uninsurable risks (where the correlation would be estimated by courts and juries). While of interest, this solution has several problems. First, is it’s novelty: this would be an unprecedented application of punitive damages that may violate the Due Process Clause <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2409.06672v1#bib.bib16" title="">2024</a>, 40-44, 50-53)</cite>, requiring a major doctrinal shift that would cut across all of tort law. Second, correlates of uninsurable risks might be difficult to find. Third, given the high uncertainty involved, correlation estimations by courts will likely be <span class="ltx_text ltx_font_italic" id="S1.p2.1.2">ad hoc</span>, high variance, and fail to leverage all available information. Fourth and finally, punitive damages for correlated risks will send a very oblique and noisy signal to liable parties: its effectiveness at actually inducing greater care taken is doubtful. Liable parties might find powerful legal teams to be a safer investment than investments in safety.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">Historically, the solution to uninsurable (albeit, non-existential risks) has been for government to step into its role as insurer of last resort <cite class="ltx_cite ltx_citemacro_citep">(Moss, <a class="ltx_ref" href="https://arxiv.org/html/2409.06672v1#bib.bib10" title="">2004</a>)</cite>, as seen in government provided reinsurance for terrorism risk insurance <cite class="ltx_cite ltx_citemacro_citep">(Federal Insurance Office, <a class="ltx_ref" href="https://arxiv.org/html/2409.06672v1#bib.bib6" title="">2022</a>)</cite> or indemnification schemes for nuclear power operators <cite class="ltx_cite ltx_citemacro_citep">(Commission, <a class="ltx_ref" href="https://arxiv.org/html/2409.06672v1#bib.bib5" title="">2021</a>, sec. 3.2)</cite>. Such programs can be in the government’s interest for several reasons. First, by creating a more predictable legal environment and making insurance more affordable, they spur the economy (or particular industry) in the short-term while protecting it against future shocks by increasing insurance uptake <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2409.06672v1#bib.bib5" title="">2021</a>, sec. 1.1)</cite><cite class="ltx_cite ltx_citemacro_citep">(Michel-Kerjan &amp; Pedell, <a class="ltx_ref" href="https://arxiv.org/html/2409.06672v1#bib.bib9" title="">2006</a>, 6, 7)</cite><cite class="ltx_cite ltx_citemacro_citep">(Hubbard et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.06672v1#bib.bib8" title="">2005</a>, 178)</cite>. Second, by encouraging or mandating <span class="ltx_text ltx_font_italic" id="S1.p3.1.1">ex ante</span> contributions from the private sector, governments can lower their financial exposure to risk <cite class="ltx_cite ltx_citemacro_citep">(Carroll et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.06672v1#bib.bib4" title="">2004</a>)</cite>. Governments cannot credibly commit to <span class="ltx_text ltx_font_italic" id="S1.p3.1.2">not</span> bail out a critical economic sector or <span class="ltx_text ltx_font_italic" id="S1.p3.1.3">not</span> provide relief to victims in the event of a major disaster: the government is always implicitly exposed to such risk.<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>This financial reason, based on <span class="ltx_text ltx_font_italic" id="footnote1.1">ex post</span> costs to governments, will not apply to existential risks: governments are also judgment-proof in the face of such risks.</span></span></span> Third, governments might mitigate the moral hazard it generates as implicit insurer (or lender) of last resort (see e.g. the “Too Big To Fail” effect <cite class="ltx_cite ltx_citemacro_citep">(Strahan, <a class="ltx_ref" href="https://arxiv.org/html/2409.06672v1#bib.bib13" title="">2013</a>)</cite>).</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">In the context of solving the judgment-proof problem, this last reason is the most interesting. While such programs might reduce moral hazard over the baseline (no program), current programs can only have done so in a crude manner due to their crude pricing. For example, in the commercial nuclear power case, indemnity fees were charged per plant and set by simply multiplying the maximum power output of said plant by fixed multipliers <cite class="ltx_cite ltx_citemacro_citep">(Commission, <a class="ltx_ref" href="https://arxiv.org/html/2409.06672v1#bib.bib5" title="">2021</a>, sec. 3.2)</cite>. This cannot have encouraged operators to take greater care along any dimension other than their choice of maximum power output at the initial design stage.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">Risk-based pricing is wanted. A government agency could make risk estimates, but this would be costly and the agency would struggle to collapse the information asymmetry between itself and the well-resourced private actors it insures. This paper proposes another solution, leveraging advances in mechanism design: a survey mechanism, the Bayesian Truth Serum <cite class="ltx_cite ltx_citemacro_citep">(Prelec, <a class="ltx_ref" href="https://arxiv.org/html/2409.06672v1#bib.bib12" title="">2004</a>)</cite>, could be used to reliably extract and aggregate honest risk estimates from experts, <span class="ltx_text ltx_font_italic" id="S1.p5.1.1">including the parties insured</span>. This, it’s argued, better leverages all available information than other solutions.</p>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">It’s further argued that if accurate risk-based pricing can be had, a government indemnification program is preferable over Weil’s punitive damage regime for producing less litigation and more robustly signaling to insureds of what risks they must mitigate. From the insured’s perspective, it would also more consistently transform large and uncertain <span class="ltx_text ltx_font_italic" id="S1.p6.1.1">ex post</span> costs into manageable and certain <span class="ltx_text ltx_font_italic" id="S1.p6.1.2">ex ante</span> costs.</p>
</div>
<div class="ltx_para" id="S1.p7">
<p class="ltx_p" id="S1.p7.1">Finally, this paper proposes using a contribution matching mechanism, Quadratic Financing <cite class="ltx_cite ltx_citemacro_citep">(Buterin et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.06672v1#bib.bib3" title="">2019</a>)</cite>, to redistribute collected fees <span class="ltx_text ltx_font_italic" id="S1.p7.1.1">back</span> to industry, funding the research required to reduce its uninsurable risks.</p>
</div>
<div class="ltx_para" id="S1.p8">
<p class="ltx_p" id="S1.p8.1">Mechanism design has long been recognized as a tool for governance (see e.g. the FCC’s auctioning of the electromagnetic spectrum <cite class="ltx_cite ltx_citemacro_citep">(Zaretsky, <a class="ltx_ref" href="https://arxiv.org/html/2409.06672v1#bib.bib17" title="">1998</a>)</cite>), but has seen few sophisticated applications (to this author’s knowledge). As a contribution to the literature on regulatory design, this paper hopes to mark out fertile ground for regulatory innovation at the intersection of tort law and mechanism design, resulting in a governance regime distinct from traditional command and control regulation, performance-based regulation, or a regime reliant solely on tort law.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>A Risk-Priced Indemnification Program</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">An indemnification program is preferred over reinsurance as this removes the intermediary of insurers, allowing the government to directly manipulate incentives of risk-generating parties. Elsewhere I’ve argued that it’s developers (e.g. OpenAI) who should be strictly and exclusively liable for said risks, largely based on their being least-cost avoiders <cite class="ltx_cite ltx_citemacro_citep">(Trout, <a class="ltx_ref" href="https://arxiv.org/html/2409.06672v1#bib.bib14" title="">2024</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">I’ll call this proposed scheme the AI Disaster Insurance Program (AIDIP). Participation would be mandatory for developers of AI models trained over a certain effective compute<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>Effective compute = FLOPs * an algorithmic efficiency factor, as estimated by a government agency such as the U.S. Artificial Intelligence Safety Institute.</span></span></span> threshold. The core of the program is a risk-priced indemnity fee that developers must pay per training run. It’s recommended the fee be a function of effective compute.<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>Cf. the industry’s currently voluntary “responsible scaling policies” e.g. <cite class="ltx_cite ltx_citemacro_citep">(Anthropic, <a class="ltx_ref" href="https://arxiv.org/html/2409.06672v1#bib.bib1" title="">2023</a>)</cite>.</span></span></span></p>
</div>
<figure class="ltx_figure" id="S2.F1">
<p class="ltx_p ltx_align_center" id="S2.F1.1"><span class="ltx_text" id="S2.F1.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="288" id="S2.F1.1.1.g1" src="x1.png" width="830"/></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>The AI Disaster Insurance Program in schematic form.</figcaption>
</figure>
<div class="ltx_para" id="S2.p3">
<p class="ltx_p" id="S2.p3.1">A government agency (such as the Department of Homeland Security) would estimate the disutility of various disaster scenarios, but risk-estimation would rely on a survey of public and private experts, <span class="ltx_text ltx_font_italic" id="S2.p3.1.1">including indemnified developers</span>. The Bayesian Truth Serum (BTS) is employed to incentivize <span class="ltx_text ltx_font_italic" id="S2.p3.1.2">effortful</span> and <span class="ltx_text ltx_font_italic" id="S2.p3.1.3">honest</span> risk-estimations from respondents <cite class="ltx_cite ltx_citemacro_citep">(Prelec, <a class="ltx_ref" href="https://arxiv.org/html/2409.06672v1#bib.bib12" title="">2004</a>)</cite>. BTS rewards responses with high information scores – i.e. responses that are surprisingly common relative to respondents’ predictions of how other respondents will respond. Scaling the BTS payout incents greater effort in information gathering. Honest reporting is a Bayes-Nash equilibrium under BTS – i.e. absent other incentives, a respondent will maximize their expected payout by reporting honestly <span class="ltx_text ltx_font_italic" id="S2.p3.1.4">if</span> they believe a large enough majority of other respondents will also report honestly.</p>
</div>
<div class="ltx_para" id="S2.p4">
<p class="ltx_p" id="S2.p4.1">A developer (who must pay the fee) obviously has a conflicting incentive to lie (underreport the risks), and can expect other developers to lie. This conflict of interest can be overcome by dramatically scaling BTS’ payout or potentially removed entirely by silencing the developer’s risk-estimation when their <span class="ltx_text ltx_font_italic" id="S2.p4.1.1">individualized</span> fee is calculated. (This second option puts developers in a prisoner’s dilemma: they could lower their fees by coordinating, but it’s individually rational to defect, increasing fees for one’s competitors.) An expectation of overwhelming honesty can be created by ensuring the vast majority of respondents are <span class="ltx_text ltx_font_italic" id="S2.p4.1.2">not</span> developers but instead independent experts with no conflicts of interest. Where there are no conflicts of interest, relevant insurers and government agencies (such as the newly formed U.S. Artificial Intelligence Safety Institute) could also be respondents.</p>
</div>
<div class="ltx_para" id="S2.p5">
<p class="ltx_p" id="S2.p5.1">The survey should be run at regular intervals (e.g. yearly), with the fee scale fixed for that interval. Any developer who wants to train a new frontier AI model during the current window must have participated in the last survey. A small discount on the fee could be offered for having participated in the last several surveys. The government sets the industry’s agenda in its choice of survey questions (e.g. “For an AI trained on compute <span class="ltx_text ltx_font_italic" id="S2.p5.1.1">x</span>, what’s the likelihood of disaster <span class="ltx_text ltx_font_italic" id="S2.p5.1.2">D</span> within time frame <span class="ltx_text ltx_font_italic" id="S2.p5.1.3">t</span>?”), clearly signaling to indemnifieds what risks they must mitigate to lower their fees.</p>
</div>
<div class="ltx_para" id="S2.p6">
<p class="ltx_p" id="S2.p6.1">To defend against BTS’ (not unusual) vulnerability to collusion, collusion should be heavily fined; whistleblowers, modestly rewarded. Participants would also have to be barred from conducting their own surveys of experts just before the government survey, lest they short-circuit BTS.<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>For BTS to reliably induce honest reporting, it’s critical that participants’ estimates of how other participants will respond be based on a participant’s private information regarding the topic in question, not a recent survey of the other participants.</span></span></span></p>
</div>
<div class="ltx_para" id="S2.p7">
<p class="ltx_p" id="S2.p7.1">Using BTS to solve the information asymmetry between the government and indemnifieds has several advantages over relying heavily on government risk estimates and inspecting indemnifieds. It should be cheaper, incenting parties to compete to provide the most informative risk-estimates, all while more reliably aggregating a wider range of private information. It should also be more secure – developers can divulge the <span class="ltx_text ltx_font_italic" id="S2.p7.1.1">risk implications</span> of their private information <span class="ltx_text ltx_font_italic" id="S2.p7.1.2">without</span> exposing security-sensitive information. Finally, it creates a more cooperative relationship between developers and the government, lending the regime greater legitimacy.</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Quadratic Financing for Safety Research</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">It’s recommended that revenue from the insurance program be used to fund AI related programs in the public’s interest. One such program should aim to directly help developers shoulder the cost of the Safety Research (SR) they need to reduce their fees.</p>
</div>
<div class="ltx_para" id="S3.p2">
<p class="ltx_p" id="S3.p2.1">Because SR is a public good, developers face a coordination problem. Note that the coordination problem for supplying SR is greatly simplified by the liability and indemnification regime: instead of countless potential victims needing to coordinate, only <span class="ltx_text ltx_font_italic" id="S3.p2.1.1">developers</span> need coordinate. To help them solve their coordination problem, ensure an optimal supply of SR, and contribute its own fair share of funds, it’s recommended the government employ a fund-matching mechanism, Quadratic Finance (QF), designed to achieve all the above <cite class="ltx_cite ltx_citemacro_citep">(Buterin et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.06672v1#bib.bib3" title="">2019</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S3.p3">
<p class="ltx_p" id="S3.p3.1">Under QF, developers and partnered research institutions would propose various SR projects. Developers then choose to fund to whatever extent whichever projects it likes, knowing the government will top-up a project’s total funds according to the QF formula. This top-up scales quadratically in the number of contributors to a project. As with BTS, QF will require basic defenses against collusion (multiple private contributors funding each other in order to receive a higher top-up) and fraud (one private contributor pretending to be multiple).</p>
</div>
<div class="ltx_para" id="S3.p4">
<p class="ltx_p" id="S3.p4.1">Projects would essentially be competing for private contributions, signaling where to send public funds. Because of the agenda setting achieved by the liability and insurance program, projects would require minimal vetting. The market then determines which projects achieve that agenda most effectively.</p>
</div>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Closing Remarks and Further Research</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">This paper proposes internalizing the negative externalities of uninsurable risks from AI through a risk-priced government insurance program (or from another angle, a Pigouvian tax). Revenue from this program then flows back to industry through an SR funding program.</p>
</div>
<div class="ltx_para" id="S4.p2">
<p class="ltx_p" id="S4.p2.1">The overall regime is market-based in that it has private actors compete to provide the most well-informed risk-estimations, and the most effective research projects to reduce said risks. This approach, it’s argued, is cheaper, more responsive to new information, and more effective at protecting the public than alternative solutions to this extreme judgment-proof problem.</p>
</div>
<div class="ltx_para" id="S4.p3">
<p class="ltx_p" id="S4.p3.1">While this paper focuses on elaborating the details of the market mechanisms core to this novel governance regime, it should be emphasized that the robust liability channeling, as discussed further in Trout <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2409.06672v1#bib.bib14" title="">2024</a>)</cite>, is no less critical. Without channeling responsibility onto a few, well-resourced, and well-informed private actors these market mechanisms would likely be much less reliable (for appearing less legitimate, being costlier to administer and police, and returning a noisier signal).</p>
</div>
<div class="ltx_para" id="S4.p4">
<p class="ltx_p" id="S4.p4.1">As with quasi-regulation via insurance <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2409.06672v1#bib.bib14" title="">2024</a>)</cite>, the goal here is not to fully substitute for regulation, but rather to produce effective risk-modeling and safety design for this emerging technology. Once available, well-calibrated regulation is much easier to develop.</p>
</div>
<div class="ltx_para" id="S4.p5">
<p class="ltx_p" id="S4.p5.1">As was done with the Terrorism Risk Insurance Program and Price-Anderson Act, this indemnification and funding program should include sunset mechanisms (an expiration date and or mechanisms for making private actors take ever greater responsibility for managing the risks of their activities, as this becomes possible). This would help ensure the program doesn’t outlive its utility and is iterated on to meet changing needs.</p>
</div>
<div class="ltx_para" id="S4.p6">
<p class="ltx_p" id="S4.p6.1">While confident in the theoretical soundness of its claims, the paper acknowledges the need for further empirical research into the effectiveness of BTS and QF. Available studies align with theoretical expectations <cite class="ltx_cite ltx_citemacro_citep">(Weaver &amp; Prelec, <a class="ltx_ref" href="https://arxiv.org/html/2409.06672v1#bib.bib15" title="">2013</a>; Pasquini, <a class="ltx_ref" href="https://arxiv.org/html/2409.06672v1#bib.bib11" title="">2022</a>)</cite>, but more tests are needed.</p>
</div>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_title_section">Acknowledgements</h2>
<div class="ltx_para" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1">Thanks to Andy Haupt, Thomas Larsen, and Mackenzie Arnold for helpful guidance early on. Thanks to Mackenzie Arnold, Gabriel Weil, Trevor Levin, Janet Egan, and Ketan Ramakrishnan for helpful feedback. Special thanks to Warren Zhu for extensive help working through various mechanism design questions.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Anthropic (2023)</span>
<span class="ltx_bibblock">
Anthropic.

</span>
<span class="ltx_bibblock">Anthropic’s Responsible Scaling Policy, 2023.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.anthropic.com/news/anthropics-responsible-scaling-policy" title="">https://www.anthropic.com/news/anthropics-responsible-scaling-policy</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bengio et al. (2024)</span>
<span class="ltx_bibblock">
Bengio, Y., Hinton, G., Yao, A., Song, D., Abbeel, P., Darrell, T., Harari, Y. N., Zhang, Y.-Q., Xue, L., Shalev-Shwartz, S., Hadfield, G., Clune, J., Maharaj, T., Hutter, F., Baydin, A. G., McIlraith, S., Gao, Q., Acharya, A., Krueger, D., Dragan, A., Torr, P., Russell, S., Kahneman, D., Brauner, J., and Mindermann, S.

</span>
<span class="ltx_bibblock">Managing extreme AI risks amid rapid progress.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">Science</em>, 384(6698):842–845, May 2024.

</span>
<span class="ltx_bibblock">ISSN 0036-8075, 1095-9203.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1126/science.adn0117</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2310.17688" title="">http://arxiv.org/abs/2310.17688</a>.

</span>
<span class="ltx_bibblock">arXiv:2310.17688 [cs].

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Buterin et al. (2019)</span>
<span class="ltx_bibblock">
Buterin, V., Hitzig, Z., and Weyl, E. G.

</span>
<span class="ltx_bibblock">A Flexible Design for Funding Public Goods.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">Management Science</em>, 65(11):5171–5187, November 2019.

</span>
<span class="ltx_bibblock">ISSN 0025-1909, 1526-5501.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1287/mnsc.2019.3337</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/1809.06421" title="">http://arxiv.org/abs/1809.06421</a>.

</span>
<span class="ltx_bibblock">arXiv:1809.06421 [econ, q-fin].

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Carroll et al. (2004)</span>
<span class="ltx_bibblock">
Carroll, S. J., LaTourrette, T., Chow, B. G., Jones, G. S., and Martin, C.

</span>
<span class="ltx_bibblock">Assessing the Effectiveness of the Terrorism Risk Insurance Act.

</span>
<span class="ltx_bibblock">Technical report, RAND Corporation, January 2004.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.rand.org/pubs/research_briefs/RB9153.html" title="">https://www.rand.org/pubs/research_briefs/RB9153.html</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Commission (2021)</span>
<span class="ltx_bibblock">
Commission, U. S. N. R.

</span>
<span class="ltx_bibblock">The Price-Anderson Act: 2021 Report to Congress, Public Liability Insurance and Indemnity Requirements for an Evolving Commercial Nuclear Industry.

</span>
<span class="ltx_bibblock">2021.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.nrc.gov/docs/ML2133/ML21335A064.pdf" title="">https://www.nrc.gov/docs/ML2133/ML21335A064.pdf</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Federal Insurance Office (2022)</span>
<span class="ltx_bibblock">
Federal Insurance Office, U. D. o. t. T.

</span>
<span class="ltx_bibblock">Report on the Effectiveness of the Terrorism Risk Insurance Program.

</span>
<span class="ltx_bibblock">Technical report, June 2022.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://home.treasury.gov/system/files/311/2022%20Program%20Effectiveness%20Report%20%28FINAL%29.pdf" title="">https://home.treasury.gov/system/files/311/2022%20Program%20Effectiveness%20Report%20%28FINAL%29.pdf</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Grace et al. (2024)</span>
<span class="ltx_bibblock">
Grace, K., Stewart, H., Sandkühler, J. F., Thomas, S., Weinstein-Raun, B., and Brauner, J.

</span>
<span class="ltx_bibblock">Thousands of AI Authors on the Future of AI, April 2024.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2401.02843" title="">http://arxiv.org/abs/2401.02843</a>.

</span>
<span class="ltx_bibblock">arXiv:2401.02843 [cs].

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hubbard et al. (2005)</span>
<span class="ltx_bibblock">
Hubbard, R. G., Deal, B., and Hess, P.

</span>
<span class="ltx_bibblock">The Economic Effects of Federal Participation in Terrorism Risk.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">Risk Management and Insurance Review</em>, 8(2):177–209, 2005.

</span>
<span class="ltx_bibblock">ISSN 1540-6296.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1111/j.1540-6296.2005.00056.x</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1540-6296.2005.00056.x" title="">https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1540-6296.2005.00056.x</a>.

</span>
<span class="ltx_bibblock">_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1540-6296.2005.00056.x.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Michel-Kerjan &amp; Pedell (2006)</span>
<span class="ltx_bibblock">
Michel-Kerjan, E. and Pedell, B.

</span>
<span class="ltx_bibblock">How Does the Corporate World Cope with Mega-Terrorism? Puzzling Evidence from Terrorism Insurance Markets.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">Journal of Applied Corporate Finance</em>, 18(4):61–75, 2006.

</span>
<span class="ltx_bibblock">ISSN 1745-6622.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1111/j.1745-6622.2006.00112.x</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1745-6622.2006.00112.x" title="">https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1745-6622.2006.00112.x</a>.

</span>
<span class="ltx_bibblock">_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1745-6622.2006.00112.x.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Moss (2004)</span>
<span class="ltx_bibblock">
Moss, D. A.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">When All Else Fails: Government as the Ultimate Risk Manager</em>.

</span>
<span class="ltx_bibblock">Harvard University Press, October 2004.

</span>
<span class="ltx_bibblock">ISBN 978-0-674-01609-5.

</span>
<span class="ltx_bibblock">Google-Books-ID: PEdOEAAAQBAJ.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pasquini (2022)</span>
<span class="ltx_bibblock">
Pasquini, R. A.

</span>
<span class="ltx_bibblock">Quadratic Funding and Matching Funds Requirements, July 2022.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2010.01193" title="">http://arxiv.org/abs/2010.01193</a>.

</span>
<span class="ltx_bibblock">arXiv:2010.01193 [econ, q-fin].

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Prelec (2004)</span>
<span class="ltx_bibblock">
Prelec, D.

</span>
<span class="ltx_bibblock">A Bayesian Truth Serum for Subjective Data.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">Science</em>, 306(5695):462–466, October 2004.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1126/science.1102081</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.science.org/doi/abs/10.1126/science.1102081" title="">https://www.science.org/doi/abs/10.1126/science.1102081</a>.

</span>
<span class="ltx_bibblock">Publisher: American Association for the Advancement of Science.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Strahan (2013)</span>
<span class="ltx_bibblock">
Strahan, P. E.

</span>
<span class="ltx_bibblock">Too Big to Fail: Causes, Consequences, and Policy Responses.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">Annual Review of Financial Economics</em>, 5(Volume 5, 2013):43–61, November 2013.

</span>
<span class="ltx_bibblock">ISSN 1941-1367, 1941-1375.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1146/annurev-financial-110112-121025</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.annualreviews.org/content/journals/10.1146/annurev-financial-110112-121025" title="">https://www.annualreviews.org/content/journals/10.1146/annurev-financial-110112-121025</a>.

</span>
<span class="ltx_bibblock">Publisher: Annual Reviews.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Trout (2024)</span>
<span class="ltx_bibblock">
Trout, C.

</span>
<span class="ltx_bibblock">Liability and Insurance for Catastrophic Losses: the Nuclear Power Precedent and Lessons for AI.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">Generative AI and Law Workshop at the International Conference on Machine Learning</em>, Vienna, Austria, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Weaver &amp; Prelec (2013)</span>
<span class="ltx_bibblock">
Weaver, R. and Prelec, D.

</span>
<span class="ltx_bibblock">Creating Truth-Telling Incentives with the Bayesian Truth Serum.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">Journal of Marketing Research</em>, 50(3):289–302, June 2013.

</span>
<span class="ltx_bibblock">ISSN 0022-2437.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1509/jmr.09.0039</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1509/jmr.09.0039" title="">https://doi.org/10.1509/jmr.09.0039</a>.

</span>
<span class="ltx_bibblock">Publisher: SAGE Publications Inc.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Weil (2024)</span>
<span class="ltx_bibblock">
Weil, G.

</span>
<span class="ltx_bibblock">Tort Law as a Tool for Mitigating Catastrophic Risk from Artificial Intelligence, January 2024.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://papers.ssrn.com/abstract=4694006" title="">https://papers.ssrn.com/abstract=4694006</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zaretsky (1998)</span>
<span class="ltx_bibblock">
Zaretsky, A.

</span>
<span class="ltx_bibblock">Auctions and the Success of Economic Theory, 1998.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.stlouisfed.org/publications/regional-economist/january-1998/going-once-going-twice-sold-auctions-and-the-success-of-economic-theory" title="">https://www.stlouisfed.org/publications/regional-economist/january-1998/going-once-going-twice-sold-auctions-and-the-success-of-economic-theory</a>.

</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Sat Sep  7 18:38:19 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
